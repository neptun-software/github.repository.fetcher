{
  "metadata": {
    "timestamp": 1736548736129,
    "page": 15,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA=="
  },
  "repositories": [
    {
      "nameWithOwner": "redis/redis",
      "stars": 67660,
      "defaultBranch": "unstable",
      "files": [
        {
          "name": ".codespell",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.4,
          "content": "# We set commands.c's merge driver to `binary` so when it conflicts during a\n# merge git will leave the local version unmodified. This way our Makefile\n# will rebuild it based on src/commands/*.json before trying to compile it.\n# Otherwise the file gets modified and gets the same timestamp as the .json\n# files. So the Makefile doesn't attempt to rebuild it before compiling.\nsrc/commands.c merge=binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.58,
          "content": ".*.swp\n*.o\n*.xo\n*.so\n*.d\n*.log\ndump.rdb\nredis-benchmark\nredis-check-aof\nredis-check-rdb\nredis-check-dump\nredis-cli\nredis-sentinel\nredis-server\ndoc-tools\nrelease\nmisc/*\nsrc/release.h\nappendonly.aof*\nappendonlydir\nSHORT_TERM_TODO\nrelease.h\nsrc/transfer.sh\nsrc/configs\nredis.ds\nsrc/redis.conf\nsrc/nodes.conf\ndeps/lua/src/lua\ndeps/lua/src/luac\ndeps/lua/src/liblua.a\ndeps/hdr_histogram/libhdrhistogram.a\ndeps/fpconv/libfpconv.a\ndeps/fast_float/libfast_float.a\ntests/tls/*\n.make-*\n.prerequisites\n*.dSYM\nMakefile.dep\n.vscode/*\n.idea/*\n.ccls\n.ccls-cache/*\ncompile_commands.json\nredis.code-workspace\n"
        },
        {
          "name": "00-RELEASENOTES",
          "type": "blob",
          "size": 0.61,
          "content": "Hello! This file is just a placeholder, since this is the \"unstable\" branch\nof Redis, the place where all the development happens.\n\nThere is no release notes for this branch, it gets forked into another branch\nevery time there is a partial feature freeze in order to eventually create\na new stable release.\n\nUsually \"unstable\" is stable enough for you to use it in development environments\nhowever you should never use it in production environments. It is possible\nto download the latest stable release here:\n\n    https://download.redis.io/redis-stable.tar.gz\n\nMore information is available at https://redis.io\n\nHappy hacking!\n"
        },
        {
          "name": "BUGS",
          "type": "blob",
          "size": 0.05,
          "content": "Please check https://github.com/redis/redis/issues\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 4.91,
          "content": "Contributor Covenant Code of Conduct\nOur Pledge\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\nOur Standards\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\nand learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\noverall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\nadvances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\naddress, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\nprofessional setting\n\nEnforcement Responsibilities\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\nScope\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\nEnforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nthis email address: redis@redis.io.\nAll complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\nEnforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n2. Warning\nCommunity Impact: A violation through a single incident or series\nof actions.\nConsequence: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including\nsustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within\nthe community.\nAttribution\nThis Code of Conduct is adapted from the Contributor Covenant,\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla's code of conduct\nenforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.01,
          "content": "By contributing code to the Redis project in any form you agree to the Redis Software Grant and\nContributor License Agreement attached below. Only contributions made under the Redis Software Grant\nand Contributor License Agreement may be accepted by Redis, and any contribution is subject to the\nterms of the Redis dual-license under RSALv2/SSPLv1 as described in the LICENSE.txt file included in\nthe Redis source distribution.\n\n# REDIS SOFTWARE GRANT AND CONTRIBUTOR LICENSE AGREEMENT\n\nTo specify the intellectual property license granted in any Contribution, Redis Ltd., (\"**Redis**\")\nrequires a Software Grant and Contributor License Agreement (\"**Agreement**\"). This Agreement is for\nyour protection as a contributor as well as the protection of Redis and its users; it does not\nchange your rights to use your own Contribution for any other purpose.\n\nBy making any Contribution, You accept and agree to the following terms and conditions for the\nContribution. Except for the license granted in this Agreement to Redis and the recipients of the\nsoftware distributed by Redis, You reserve all right, title, and interest in and to Your\nContribution.\n\n1. **Definitions**\n\n    1.1. \"**You**\" (or \"**Your**\") means the copyright owner or legal entity authorized by the\n    copyright owner that is entering into this Agreement with Redis. For legal entities, the entity\n    making a Contribution and all other entities that Control, are Controlled by, or are under\n    common Control with that entity are considered to be a single contributor. For the purposes of\n    this definition, \"**Control**\" means (i) the power, direct or indirect, to cause the direction\n    or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty\n    percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n\n    1.2. \"**Contribution**\" means the code, documentation, or any original work of authorship,\n    including any modifications or additions to an existing work described above.\n\n2. \"**Work**\" means any software project stewarded by Redis.\n\n3. **Grant of Copyright License**. Subject to the terms and conditions of this Agreement, You grant\n   to Redis and to the recipients of the software distributed by Redis a perpetual, worldwide,\n   non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare\n   derivative works of, publicly display, publicly perform, sublicense, and distribute Your\n   Contribution and such derivative works.\n\n4. **Grant of Patent License**. Subject to the terms and conditions of this Agreement, You grant to\n   Redis and to the recipients of the software distributed by Redis a perpetual, worldwide,\n   non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent\n   license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable by You that are necessarily\n   infringed by Your Contribution alone or by a combination of Your Contribution with the Work to\n   which such Contribution was submitted. If any entity institutes patent litigation against You or\n   any other entity (including a cross-claim or counterclaim in a lawsuit) alleging that your\n   Contribution, or the Work to which you have contributed, constitutes a direct or contributory\n   patent infringement, then any patent licenses granted to the claimant entity under this Agreement\n   for that Contribution or Work terminate as of the date such litigation is filed.\n\n5. **Representations and Warranties**. You represent and warrant that: (i) You are legally entitled\n   to grant the above licenses; and (ii) if You are an entity, each employee or agent designated by\n   You is authorized to submit the Contribution on behalf of You; and (iii) your Contribution is\n   Your original work, and that it will not infringe on any third party's intellectual property\n   right(s).\n\n6. **Disclaimer**. You are not expected to provide support for Your Contribution, except to the\n   extent You desire to provide support. You may provide support for free, for a fee, or not at all.\n   Unless required by applicable law or agreed to in writing, You provide Your Contribution on an\n   \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,\n   including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT,\n   MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE.\n\n7. **Enforceability**. Nothing in this Agreement will be construed as creating any joint venture,\n   employment relationship, or partnership between You and Redis. If any provision of this Agreement\n   is held to be unenforceable, the remaining provisions of this Agreement will not be affected.\n   This represents the entire agreement between You and Redis relating to the Contribution.\n\n# IMPORTANT: HOW TO USE REDIS GITHUB ISSUES\n\nGitHub issues SHOULD ONLY BE USED to report bugs and for DETAILED feature\nrequests. Everything else should be asked on Discord:\n      \n    https://discord.com/invite/redis\n\nPLEASE DO NOT POST GENERAL QUESTIONS that are not about bugs or suspected\nbugs in the GitHub issues system. We'll be delighted to help you and provide\nall the support on Discord.\n\nThere is also an active community of Redis users at Stack Overflow:\n\n    https://stackoverflow.com/questions/tagged/redis\n\nIssues and pull requests for documentation belong on the redis-doc repo:\n\n    https://github.com/redis/redis-doc\n\nIf you are reporting a security bug or vulnerability, see SECURITY.md.\n\n# How to provide a patch for a new feature\n\n1. If it is a major feature or a semantical change, please don't start coding\nstraight away: if your feature is not a conceptual fit you'll lose a lot of\ntime writing the code without any reason. Start by posting in the mailing list\nand creating an issue at Github with the description of, exactly, what you want\nto accomplish and why. Use cases are important for features to be accepted.\nHere you can see if there is consensus about your idea.\n\n2. If in step 1 you get an acknowledgment from the project leaders, use the\n   following procedure to submit a patch:\n\n    a. Fork Redis on GitHub ( https://docs.github.com/en/github/getting-started-with-github/fork-a-repo )\n    b. Create a topic branch (git checkout -b my_branch)\n    c. Push to your branch (git push origin my_branch)\n    d. Initiate a pull request on GitHub ( https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request )\n    e. Done :)\n\n3. Keep in mind that we are very overloaded, so issues and PRs sometimes wait\nfor a *very* long time. However this is not a lack of interest, as the project\ngets more and more users, we find ourselves in a constant need to prioritize\ncertain issues/PRs over others. If you think your issue/PR is very important\ntry to popularize it, have other users commenting and sharing their point of\nview, and so forth. This helps.\n\n4. For minor fixes - open a pull request on GitHub.\n\nAdditional information on the RSALv2/SSPLv1 dual-license is also found in the LICENSE.txt file.\n"
        },
        {
          "name": "INSTALL",
          "type": "blob",
          "size": 0.01,
          "content": "See README\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 36.61,
          "content": "Starting on March 20th, 2024, Redis follows a dual-licensing model with all Redis project code\ncontributions under version 7.4 and subsequent releases governed by the Redis Software Grant and\nContributor License Agreement. After this date, contributions are subject to the user's choice of\nthe Redis Source Available License v2 (RSALv2) or the Server Side Public License v1 (SSPLv1), as\nfollows:\n\n\n1. Redis Source Available License 2.0 (RSALv2) Agreement\n========================================================\n\nLast Update: December 30, 2023\n\nAcceptance\n----------\n\nThis Agreement sets forth the terms and conditions on which the Licensor\nmakes available the Software. By installing, downloading, accessing,\nUsing, or distributing any of the Software, You agree to all of the\nterms and conditions of this Agreement.\n\nIf You are receiving the Software on behalf of Your Company, You\nrepresent and warrant that You have the authority to agree to this\nAgreement on behalf of such entity.\n\nThe Licensor reserves the right to update this Agreement from time to\ntime.\n\nThe terms below have the meanings set forth below for purposes of this\nAgreement:\n\nDefinitions\n-----------\n\nAgreement: this Redis Source Available License 2.0 Agreement.\n\nControl: ownership, directly or indirectly, of substantially all the\nassets of an entity, or the power to direct its management and policies\nby vote, contract, or otherwise.\n\nLicense: the License as described in the License paragraph below.\n\nLicensor: the entity offering these terms, which includes Redis Ltd. on\nbehalf of itself and its subsidiaries and affiliates worldwide.\n\nModify, Modified, or Modification: copy from or adapt all or part of the\nwork in a fashion requiring copyright permission other than making an\nexact copy. The resulting work is called a Modified version of the\nearlier work.\n\nRedis: the Redis software as described in redis.com redis.io.\n\nSoftware: certain Software components designed to work with Redis and\nprovided to You under this Agreement.\n\nTrademark: the trademarks, service marks, and any other similar rights.\n\nUse: anything You do with the Software requiring one of Your Licenses.\n\nYou: the recipient of the Software, the individual or entity on whose\nbehalf You are agreeing to this Agreement.\n\nYour Company: any legal entity, sole proprietorship, or other kind of\norganization that You work for, plus all organizations that have control\nover, are under the control of, or are under common control with that\norganization.\n\nYour Licenses: means all the Licenses granted to You for the Software\nunder this Agreement.\n\nLicense\n-------\n\nThe Licensor grants You a non-exclusive, royalty-free, worldwide,\nnon-sublicensable, non-transferable license to use, copy, distribute,\nmake available, and prepare derivative works of the Software, in each\ncase subject to the limitations and conditions below.\n\nLimitations\n-----------\n\nYou may not make the functionality of the Software or a Modified version\navailable to third parties as a service or distribute the Software or a\nModified version in a manner that makes the functionality of the\nSoftware available to third parties.\n\nMaking the functionality of the Software or Modified version available\nto third parties includes, without limitation, enabling third parties to\ninteract with the functionality of the Software or Modified version in\ndistributed form or remotely through a computer network, offering a\nproduct or service, the value of which entirely or primarily derives\nfrom the value of the Software or Modified version, or offering a\nproduct or service that accomplishes for users the primary purpose of\nthe Software or Modified version.\n\nYou may not alter, remove, or obscure any licensing, copyright, or other\nnotices of the Licensor in the Software. Any use of the Licensor's\nTrademarks is subject to applicable law.\n\nPatents\n-------\n\nThe Licensor grants You a License, under any patent claims the Licensor\ncan License, or becomes able to License, to make, have made, use, sell,\noffer for sale, import and have imported the Software, in each case\nsubject to the limitations and conditions in this License. This License\ndoes not cover any patent claims that You cause to be infringed by\nModifications or additions to the Software. If You or Your Company make\nany written claim that the Software infringes or contributes to\ninfringement of any patent, your patent License for the Software granted\nunder this Agreement ends immediately. If Your Company makes such a\nclaim, your patent License ends immediately for work on behalf of Your\nCompany.\n\nNotices\n-------\n\nYou must ensure that anyone who gets a copy of any part of the Software\nfrom You also gets a copy of the terms and conditions in this Agreement.\n\nIf You modify the Software, You must include in any Modified copies of\nthe Software prominent notices stating that You have Modified the\nSoftware.\n\nNo Other Rights\n---------------\n\nThe terms and conditions of this Agreement do not imply any Licenses\nother than those expressly granted in this Agreement.\n\nTermination\n-----------\n\nIf You Use the Software in violation of this Agreement, such Use is not\nLicensed, and Your Licenses will automatically terminate. If the\nLicensor provides You with a notice of your violation, and You cease all\nviolations of this License no later than 30 days after You receive that\nnotice, Your Licenses will be reinstated retroactively. However, if You\nviolate this Agreement after such reinstatement, any additional\nviolation of this Agreement will cause your Licenses to terminate\nautomatically and permanently.\n\nNo Liability\n------------\n\nAs far as the law allows, the Software comes as is, without any\nwarranty or condition, and the Licensor will not be liable to You for\nany damages arising out of this Agreement or the Use or nature of the\nSoftware, under any kind of legal claim.\n\nGoverning Law and Jurisdiction\n------------------------------\n\nIf You are located in Asia, Pacific, Americas, or other jurisdictions\nnot listed below, the Agreement will be construed and enforced in all\nrespects in accordance with the laws of the State of California, U.S.A.,\nwithout reference to its choice of law rules. The courts located in the\nCounty of Santa Clara, California, have exclusive jurisdiction for all\npurposes relating to this Agreement.\n\nIf You are located in Israel, the Agreement will be construed and\nenforced in all respects in accordance with the laws of the State of\nIsrael without reference to its choice of law rules. The courts located\nin the Central District of the State of Israel have exclusive\njurisdiction for all purposes relating to this Agreement.\n\nIf You are located in Europe, United Kingdom, Middle East or Africa, the\nAgreement will be construed and enforced in all respects in accordance\nwith the laws of England and Wales without reference to its choice of\nlaw rules. The competent courts located in London, England, have\nexclusive jurisdiction for all purposes relating to this Agreement.\n\n\n\n2. Server Side Public License (SSPL)\n====================================\n\n                     Server Side Public License\n                     VERSION 1, OCTOBER 16, 2018\n\n                    Copyright (c) 2018 MongoDB, Inc.\n\n  Everyone is permitted to copy and distribute verbatim copies of this\n  license document, but changing it is not allowed.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to Server Side Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\n  works, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\n  License.  Each licensee is addressed as \"you\". \"Licensees\" and\n  \"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work in\n  a fashion requiring copyright permission, other than the making of an\n  exact copy. The resulting work is called a \"modified version\" of the\n  earlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based on\n  the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\n  permission, would make you directly or secondarily liable for\n  infringement under applicable copyright law, except executing it on a\n  computer or modifying a private copy. Propagation includes copying,\n  distribution (with or without modification), making available to the\n  public, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\n  parties to make or receive copies. Mere interaction with a user through a\n  computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\" to the\n  extent that it includes a convenient and prominently visible feature that\n  (1) displays an appropriate copyright notice, and (2) tells the user that\n  there is no warranty for the work (except to the extent that warranties\n  are provided), that licensees may convey the work under this License, and\n  how to view a copy of this License. If the interface presents a list of\n  user commands or options, such as a menu, a prominent item in the list\n  meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work for\n  making modifications to it. \"Object code\" means any non-source form of a\n  work.\n\n  A \"Standard Interface\" means an interface that either is an official\n  standard defined by a recognized standards body, or, in the case of\n  interfaces specified for a particular programming language, one that is\n  widely used among developers working in that language.  The \"System\n  Libraries\" of an executable work include anything, other than the work as\n  a whole, that (a) is included in the normal form of packaging a Major\n  Component, but which is not part of that Major Component, and (b) serves\n  only to enable use of the work with that Major Component, or to implement\n  a Standard Interface for which an implementation is available to the\n  public in source code form. A \"Major Component\", in this context, means a\n  major essential component (kernel, window system, and so on) of the\n  specific operating system (if any) on which the executable work runs, or\n  a compiler used to produce the work, or an object code interpreter used\n  to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all the\n  source code needed to generate, install, and (for an executable work) run\n  the object code and to modify the work, including scripts to control\n  those activities. However, it does not include the work's System\n  Libraries, or general-purpose tools or generally available free programs\n  which are used unmodified in performing those activities but which are\n  not part of the work. For example, Corresponding Source includes\n  interface definition files associated with source files for the work, and\n  the source code for shared libraries and dynamically linked subprograms\n  that the work is specifically designed to require, such as by intimate\n  data communication or control flow between those subprograms and other\n  parts of the work.\n\n  The Corresponding Source need not include anything that users can\n  regenerate automatically from other parts of the Corresponding Source.\n\n  The Corresponding Source for a work in source code form is that same work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\n  copyright on the Program, and are irrevocable provided the stated\n  conditions are met. This License explicitly affirms your unlimited\n  permission to run the unmodified Program, subject to section 13. The\n  output from running a covered work is covered by this License only if the\n  output, given its content, constitutes a covered work. This License\n  acknowledges your rights of fair use or other equivalent, as provided by\n  copyright law.  Subject to section 13, you may make, run and propagate\n  covered works that you do not convey, without conditions so long as your\n  license otherwise remains in force. You may convey covered works to\n  others for the sole purpose of having them make modifications exclusively\n  for you, or provide you with facilities for running those works, provided\n  that you comply with the terms of this License in conveying all\n  material for which you do not control copyright. Those thus making or\n  running the covered works for you must do so exclusively on your\n  behalf, under your direction and control, on terms that prohibit them\n  from making any copies of your copyrighted material outside their\n  relationship with you.\n\n  Conveying under any other circumstances is permitted solely under the\n  conditions stated below. Sublicensing is not allowed; section 10 makes it\n  unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\n  measure under any applicable law fulfilling obligations under article 11\n  of the WIPO copyright treaty adopted on 20 December 1996, or similar laws\n  prohibiting or restricting circumvention of such measures.\n\n  When you convey a covered work, you waive any legal power to forbid\n  circumvention of technological measures to the extent such circumvention is\n  effected by exercising rights under this License with respect to the\n  covered work, and you disclaim any intention to limit operation or\n  modification of the work as a means of enforcing, against the work's users,\n  your or third parties' legal rights to forbid circumvention of\n  technological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\n  receive it, in any medium, provided that you conspicuously and\n  appropriately publish on each copy an appropriate copyright notice; keep\n  intact all notices stating that this License and any non-permissive terms\n  added in accord with section 7 apply to the code; keep intact all notices\n  of the absence of any warranty; and give all recipients a copy of this\n  License along with the Program.  You may charge any price or no price for\n  each copy that you convey, and you may offer support or warranty\n  protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\n  produce it from the Program, in the form of source code under the terms\n  of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified it,\n    and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is released\n    under this License and any conditions added under section 7. This\n    requirement modifies the requirement in section 4 to \"keep intact all\n    notices\".\n\n    c) You must license the entire work, as a whole, under this License to\n    anyone who comes into possession of a copy. This License will therefore\n    apply, along with any applicable section 7 additional terms, to the\n    whole of the work, and all its parts, regardless of how they are\n    packaged. This License gives no permission to license the work in any\n    other way, but it does not invalidate such permission if you have\n    separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your work\n    need not make them do so.\n\n  A compilation of a covered work with other separate and independent\n  works, which are not by their nature extensions of the covered work, and\n  which are not combined with it such as to form a larger program, in or on\n  a volume of a storage or distribution medium, is called an \"aggregate\" if\n  the compilation and its resulting copyright are not used to limit the\n  access or legal rights of the compilation's users beyond what the\n  individual works permit. Inclusion of a covered work in an aggregate does\n  not cause this License to apply to the other parts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms of\n  sections 4 and 5, provided that you also convey the machine-readable\n  Corresponding Source under the terms of this License, in one of these\n  ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium customarily\n    used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a written\n    offer, valid for at least three years and valid for as long as you\n    offer spare parts or customer support for that product model, to give\n    anyone who possesses the object code either (1) a copy of the\n    Corresponding Source for all the software in the product that is\n    covered by this License, on a durable physical medium customarily used\n    for software interchange, for a price no more than your reasonable cost\n    of physically performing this conveying of source, or (2) access to\n    copy the Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source. This alternative is\n    allowed only occasionally and noncommercially, and only if you received\n    the object code with such an offer, in accord with subsection 6b.\n\n    d) Convey the object code by offering access from a designated place\n    (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge. You need not require recipients to copy the\n    Corresponding Source along with the object code. If the place to copy\n    the object code is a network server, the Corresponding Source may be on\n    a different server (operated by you or a third party) that supports\n    equivalent copying facilities, provided you maintain clear directions\n    next to the object code saying where to find the Corresponding Source.\n    Regardless of what server hosts the Corresponding Source, you remain\n    obligated to ensure that it is available for as long as needed to\n    satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided you\n    inform other peers where the object code and Corresponding Source of\n    the work are being offered to the general public at no charge under\n    subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\n  from the Corresponding Source as a System Library, need not be included\n  in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\n  tangible personal property which is normally used for personal, family,\n  or household purposes, or (2) anything designed or sold for incorporation\n  into a dwelling. In determining whether a product is a consumer product,\n  doubtful cases shall be resolved in favor of coverage. For a particular\n  product received by a particular user, \"normally used\" refers to a\n  typical or common use of that class of product, regardless of the status\n  of the particular user or of the way in which the particular user\n  actually uses, or expects or is expected to use, the product. A product\n  is a consumer product regardless of whether the product has substantial\n  commercial, industrial or non-consumer uses, unless such uses represent\n  the only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\n  procedures, authorization keys, or other information required to install\n  and execute modified versions of a covered work in that User Product from\n  a modified version of its Corresponding Source. The information must\n  suffice to ensure that the continued functioning of the modified object\n  code is in no case prevented or interfered with solely because\n  modification has been made.\n\n  If you convey an object code work under this section in, or with, or\n  specifically for use in, a User Product, and the conveying occurs as part\n  of a transaction in which the right of possession and use of the User\n  Product is transferred to the recipient in perpetuity or for a fixed term\n  (regardless of how the transaction is characterized), the Corresponding\n  Source conveyed under this section must be accompanied by the\n  Installation Information. But this requirement does not apply if neither\n  you nor any third party retains the ability to install modified object\n  code on the User Product (for example, the work has been installed in\n  ROM).\n\n  The requirement to provide Installation Information does not include a\n  requirement to continue to provide support service, warranty, or updates\n  for a work that has been modified or installed by the recipient, or for\n  the User Product in which it has been modified or installed. Access\n  to a network may be denied when the modification itself materially\n  and adversely affects the operation of the network or violates the\n  rules and protocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided, in\n  accord with this section must be in a format that is publicly documented\n  (and with an implementation available to the public in source code form),\n  and must require no special password or key for unpacking, reading or\n  copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\n  License by making exceptions from one or more of its conditions.\n  Additional permissions that are applicable to the entire Program shall be\n  treated as though they were included in this License, to the extent that\n  they are valid under applicable law. If additional permissions apply only\n  to part of the Program, that part may be used separately under those\n  permissions, but the entire Program remains governed by this License\n  without regard to the additional permissions.  When you convey a copy of\n  a covered work, you may at your option remove any additional permissions\n  from that copy, or from any part of it. (Additional permissions may be\n  written to require their own removal in certain cases when you modify the\n  work.) You may place additional permissions on material, added by you to\n  a covered work, for which you have or can give appropriate copyright\n  permission.\n\n  Notwithstanding any other provision of this License, for material you add\n  to a covered work, you may (if authorized by the copyright holders of\n  that material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some trade\n    names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that material\n    by anyone who conveys the material (or modified versions of it) with\n    contractual assumptions of liability to the recipient, for any\n    liability that these contractual assumptions directly impose on those\n    licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\n  restrictions\" within the meaning of section 10. If the Program as you\n  received it, or any part of it, contains a notice stating that it is\n  governed by this License along with a term that is a further restriction,\n  you may remove that term. If a license document contains a further\n  restriction but permits relicensing or conveying under this License, you\n  may add to a covered work material governed by the terms of that license\n  document, provided that the further restriction does not survive such\n  relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you must\n  place, in the relevant source files, a statement of the additional terms\n  that apply to those files, or a notice indicating where to find the\n  applicable terms.  Additional terms, permissive or non-permissive, may be\n  stated in the form of a separately written license, or stated as\n  exceptions; the above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\n  provided under this License. Any attempt otherwise to propagate or modify\n  it is void, and will automatically terminate your rights under this\n  License (including any patent licenses granted under the third paragraph\n  of section 11).\n\n  However, if you cease all violation of this License, then your license\n  from a particular copyright holder is reinstated (a) provisionally,\n  unless and until the copyright holder explicitly and finally terminates\n  your license, and (b) permanently, if the copyright holder fails to\n  notify you of the violation by some reasonable means prior to 60 days\n  after the cessation.\n\n  Moreover, your license from a particular copyright holder is reinstated\n  permanently if the copyright holder notifies you of the violation by some\n  reasonable means, this is the first time you have received notice of\n  violation of this License (for any work) from that copyright holder, and\n  you cure the violation prior to 30 days after your receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\n  licenses of parties who have received copies or rights from you under\n  this License. If your rights have been terminated and not permanently\n  reinstated, you do not qualify to receive new licenses for the same\n  material under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or run a\n  copy of the Program. Ancillary propagation of a covered work occurring\n  solely as a consequence of using peer-to-peer transmission to receive a\n  copy likewise does not require acceptance. However, nothing other than\n  this License grants you permission to propagate or modify any covered\n  work. These actions infringe copyright if you do not accept this License.\n  Therefore, by modifying or propagating a covered work, you indicate your\n  acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically receives\n  a license from the original licensors, to run, modify and propagate that\n  work, subject to this License. You are not responsible for enforcing\n  compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\n  organization, or substantially all assets of one, or subdividing an\n  organization, or merging organizations. If propagation of a covered work\n  results from an entity transaction, each party to that transaction who\n  receives a copy of the work also receives whatever licenses to the work\n  the party's predecessor in interest had or could give under the previous\n  paragraph, plus a right to possession of the Corresponding Source of the\n  work from the predecessor in interest, if the predecessor has it or can\n  get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the rights\n  granted or affirmed under this License. For example, you may not impose a\n  license fee, royalty, or other charge for exercise of rights granted\n  under this License, and you may not initiate litigation (including a\n  cross-claim or counterclaim in a lawsuit) alleging that any patent claim\n  is infringed by making, using, selling, offering for sale, or importing\n  the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\n  License of the Program or a work on which the Program is based. The work\n  thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims owned or\n  controlled by the contributor, whether already acquired or hereafter\n  acquired, that would be infringed by some manner, permitted by this\n  License, of making, using, or selling its contributor version, but do not\n  include claims that would be infringed only as a consequence of further\n  modification of the contributor version. For purposes of this definition,\n  \"control\" includes the right to grant patent sublicenses in a manner\n  consistent with the requirements of this License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\n  patent license under the contributor's essential patent claims, to make,\n  use, sell, offer for sale, import and otherwise run, modify and propagate\n  the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\n  agreement or commitment, however denominated, not to enforce a patent\n  (such as an express permission to practice a patent or covenant not to\n  sue for patent infringement). To \"grant\" such a patent license to a party\n  means to make such an agreement or commitment not to enforce a patent\n  against the party.\n\n  If you convey a covered work, knowingly relying on a patent license, and\n  the Corresponding Source of the work is not available for anyone to copy,\n  free of charge and under the terms of this License, through a publicly\n  available network server or other readily accessible means, then you must\n  either (1) cause the Corresponding Source to be so available, or (2)\n  arrange to deprive yourself of the benefit of the patent license for this\n  particular work, or (3) arrange, in a manner consistent with the\n  requirements of this License, to extend the patent license to downstream\n  recipients. \"Knowingly relying\" means you have actual knowledge that, but\n  for the patent license, your conveying the covered work in a country, or\n  your recipient's use of the covered work in a country, would infringe\n  one or more identifiable patents in that country that you have reason\n  to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\n  arrangement, you convey, or propagate by procuring conveyance of, a\n  covered work, and grant a patent license to some of the parties receiving\n  the covered work authorizing them to use, propagate, modify or convey a\n  specific copy of the covered work, then the patent license you grant is\n  automatically extended to all recipients of the covered work and works\n  based on it.\n\n  A patent license is \"discriminatory\" if it does not include within the\n  scope of its coverage, prohibits the exercise of, or is conditioned on\n  the non-exercise of one or more of the rights that are specifically\n  granted under this License. You may not convey a covered work if you are\n  a party to an arrangement with a third party that is in the business of\n  distributing software, under which you make payment to the third party\n  based on the extent of your activity of conveying the work, and under\n  which the third party grants, to any of the parties who would receive the\n  covered work from you, a discriminatory patent license (a) in connection\n  with copies of the covered work conveyed by you (or copies made from\n  those copies), or (b) primarily for and in connection with specific\n  products or compilations that contain the covered work, unless you\n  entered into that arrangement, or that patent license was granted, prior\n  to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting any\n  implied license or other defenses to infringement that may otherwise be\n  available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\n  otherwise) that contradict the conditions of this License, they do not\n  excuse you from the conditions of this License. If you cannot use,\n  propagate or convey a covered work so as to satisfy simultaneously your\n  obligations under this License and any other pertinent obligations, then\n  as a consequence you may not use, propagate or convey it at all. For\n  example, if you agree to terms that obligate you to collect a royalty for\n  further conveying from those to whom you convey the Program, the only way\n  you could satisfy both those terms and this License would be to refrain\n  entirely from conveying the Program.\n\n  13. Offering the Program as a Service.\n\n  If you make the functionality of the Program or a modified version\n  available to third parties as a service, you must make the Service Source\n  Code available via network download to everyone at no charge, under the\n  terms of this License. Making the functionality of the Program or\n  modified version available to third parties as a service includes,\n  without limitation, enabling third parties to interact with the\n  functionality of the Program or modified version remotely through a\n  computer network, offering a service the value of which entirely or\n  primarily derives from the value of the Program or modified version, or\n  offering a service that accomplishes for users the primary purpose of the\n  Program or modified version.\n\n  \"Service Source Code\" means the Corresponding Source for the Program or\n  the modified version, and the Corresponding Source for all programs that\n  you use to make the Program or modified version available as a service,\n  including, without limitation, management software, user interfaces,\n  application program interfaces, automation software, monitoring software,\n  backup software, storage software and hosting software, all such that a\n  user could run an instance of the service using the Service Source Code\n  you make available.\n\n  14. Revised Versions of this License.\n\n  MongoDB, Inc. may publish revised and/or new versions of the Server Side\n  Public License from time to time. Such new versions will be similar in\n  spirit to the present version, but may differ in detail to address new\n  problems or concerns.\n\n  Each version is given a distinguishing version number. If the Program\n  specifies that a certain numbered version of the Server Side Public\n  License \"or any later version\" applies to it, you have the option of\n  following the terms and conditions either of that numbered version or of\n  any later version published by MongoDB, Inc. If the Program does not\n  specify a version number of the Server Side Public License, you may\n  choose any version ever published by MongoDB, Inc.\n\n  If the Program specifies that a proxy can decide which future versions of\n  the Server Side Public License can be used, that proxy's public statement\n  of acceptance of a version permanently authorizes you to choose that\n  version for the Program.\n\n  Later license versions may give you additional or different permissions.\n  However, no additional obligations are imposed on any author or copyright\n  holder as a result of your choosing to follow a later version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\n  APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\n  HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\n  OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\n  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n  PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\n  IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\n  ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\n  WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\n  THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING\n  ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF\n  THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO\n  LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU\n  OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\n  PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\n  POSSIBILITY OF SUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided above\n  cannot be given local legal effect according to their terms, reviewing\n  courts shall apply local law that most closely approximates an absolute\n  waiver of all civil liability in connection with the Program, unless a\n  warranty or assumption of liability accompanies a copy of the Program in\n  return for a fee.\n\n                        END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "MANIFESTO",
          "type": "blob",
          "size": 6.73,
          "content": "[Note: this is the Redis manifesto, for general information about\n       installing and running Redis read the README file instead.]\n\nRedis Manifesto\n===============\n\n1 - A DSL for Abstract Data Types. Redis is a DSL (Domain Specific Language)\n    that manipulates abstract data types and implemented as a TCP daemon.\n    Commands manipulate a key space where keys are binary-safe strings and\n    values are different kinds of abstract data types. Every data type\n    represents an abstract version of a fundamental data structure. For instance\n    Redis Lists are an abstract representation of linked lists. In Redis, the\n    essence of a data type isn't just the kind of operations that the data types\n    support, but also the space and time complexity of the data type and the\n    operations performed upon it.\n\n2 - Memory storage is #1. The Redis data set, composed of defined key-value\n    pairs, is primarily stored in the computer's memory. The amount of memory in\n    all kinds of computers, including entry-level servers, is increasing\n    significantly each year. Memory is fast, and allows Redis to have very\n    predictable performance. Datasets composed of 10k or 40 millions keys will\n    perform similarly. Complex data types like Redis Sorted Sets are easy to\n    implement and manipulate in memory with good performance, making Redis very\n    simple. Redis will continue to explore alternative options (where data can\n    be optionally stored on disk, say) but the main goal of the project remains\n    the development of an in-memory database.\n\n3 - Fundamental data structures for a fundamental API. The Redis API is a direct\n    consequence of fundamental data structures. APIs can often be arbitrary but\n    not an API that resembles the nature of fundamental data structures. If we\n    ever meet intelligent life forms from another part of the universe, they'll\n    likely know, understand and recognize the same basic data structures we have\n    in our computer science books. Redis will avoid intermediate layers in API,\n    so that the complexity is obvious and more complex operations can be\n    performed as the sum of the basic operations.\n\n4 - We believe in code efficiency. Computers get faster and faster, yet we\n    believe that abusing computing capabilities is not wise: the amount of\n    operations you can do for a given amount of energy remains anyway a\n    significant parameter: it allows to do more with less computers and, at\n    the same time, having a smaller environmental impact. Similarly Redis is\n    able to \"scale down\" to smaller devices. It is perfectly usable in a\n    Raspberry Pi and other small ARM based computers. Faster code having\n    just the layers of abstractions that are really needed will also result,\n    often, in more predictable performances. We think likewise about memory\n    usage, one of the fundamental goals of the Redis project is to\n    incrementally build more and more memory efficient data structures, so that\n    problems that were not approachable in RAM in the past will be perfectly\n    fine to handle in the future.\n\n5 - Code is like a poem; it's not just something we write to reach some\n    practical result. Sometimes people that are far from the Redis philosophy\n    suggest using other code written by other authors (frequently in other\n    languages) in order to implement something Redis currently lacks. But to us\n    this is like if Shakespeare decided to end Enrico IV using the Paradiso from\n    the Divina Commedia. Is using any external code a bad idea? Not at all. Like\n    in \"One Thousand and One Nights\" smaller self contained stories are embedded\n    in a bigger story, we'll be happy to use beautiful self contained libraries\n    when needed. At the same time, when writing the Redis story we're trying to\n    write smaller stories that will fit in to other code.\n\n6 - We're against complexity. We believe designing systems is a fight against\n    complexity. We'll accept to fight the complexity when it's worthwhile but\n    we'll try hard to recognize when a small feature is not worth 1000s of lines\n    of code. Most of the time the best way to fight complexity is by not\n    creating it at all. Complexity is also a form of lock-in: code that is\n    very hard to understand cannot be modified by users in an independent way\n    regardless of the license. One of the main Redis goals is to remain\n    understandable, enough for a single programmer to have a clear idea of how\n    it works in detail just reading the source code for a couple of weeks.\n\n7 - Threading is not a silver bullet. Instead of making Redis threaded we\n    believe on the idea of an efficient (mostly) single threaded Redis core.\n    Multiple of such cores, that may run in the same computer or may run\n    in multiple computers, are abstracted away as a single big system by\n    higher order protocols and features: Redis Cluster and the upcoming\n    Redis Proxy are our main goals. A shared nothing approach is not just\n    much simpler (see the previous point in this document), is also optimal\n    in NUMA systems. In the specific case of Redis it allows for each instance\n    to have a more limited amount of data, making the Redis persist-by-fork\n    approach more sounding. In the future we may explore parallelism only for\n    I/O, which is the low hanging fruit: minimal complexity could provide an\n    improved single process experience.\n\n8 - Two levels of API. The Redis API has two levels: 1) a subset of the API fits\n    naturally into a distributed version of Redis and 2) a more complex API that\n    supports multi-key operations. Both are useful if used judiciously but\n    there's no way to make the more complex multi-keys API distributed in an\n    opaque way without violating our other principles. We don't want to provide\n    the illusion of something that will work magically when actually it can't in\n    all cases. Instead we'll provide commands to quickly migrate keys from one\n    instance to another to perform multi-key operations and expose the\n    trade-offs to the user.\n\n9 - We optimize for joy. We believe writing code is a lot of hard work, and the\n    only way it can be worth is by enjoying it. When there is no longer joy in\n    writing code, the best thing to do is stop. To prevent this, we'll avoid\n    taking paths that will make Redis less of a joy to develop.\n\n10 - All the above points are put together in what we call opportunistic\n     programming: trying to get the most for the user with minimal increases\n     in complexity (hanging fruits). Solve 95% of the problem with 5% of the\n     code when it is acceptable. Avoid a fixed schedule but follow the flow of\n     user requests, inspiration, Redis internal readiness for certain features\n     (sometimes many past changes reach a critical point making a previously\n     complex feature very easy to obtain).\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.31,
          "content": "# Top level makefile, the real stuff is at ./src/Makefile and in ./modules/Makefile\n\nSUBDIRS = src\nifeq ($(BUILD_WITH_MODULES), yes)\n\tSUBDIRS += modules\nendif\n\ndefault: all\n\n.DEFAULT:\n\tfor dir in $(SUBDIRS); do $(MAKE) -C $$dir $@; done\n\ninstall:\n\tfor dir in $(SUBDIRS); do $(MAKE) -C $$dir $@; done\n\n.PHONY: install\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.27,
          "content": "This README is just a fast *quick start* document. You can find more detailed documentation at [redis.io](https://redis.io).\n\nWhat is Redis?\n---\n\nRedis is often referred to as a *data structures* server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a *server-client* model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way.\n\nData structures implemented into Redis have a few special properties:\n\n* Redis cares to store them on disk, even if they are always served and modified into the server memory. This means that Redis is fast, but that it is also non-volatile.\n* The implementation of data structures emphasizes memory efficiency, so data structures inside Redis will likely use less memory compared to the same data structure modelled using a high-level programming language.\n* Redis offers a number of features that are natural to find in a database, like replication, tunable levels of durability, clustering, and high availability.\n\nAnother good example is to think of Redis as a more complex version of memcached, where the operations are not just SETs and GETs, but operations that work with complex data types like Lists, Sets, ordered data structures, and so forth.\n\nIf you want to know more, this is a list of selected starting points:\n\n* Introduction to Redis data types. https://redis.io/docs/latest/develop/data-types/\n\n* The full list of Redis commands. https://redis.io/commands\n* There is much more inside the official Redis documentation. https://redis.io/documentation\n\nWhat is Redis Community Edition?\n---\n\nRedis OSS was renamed Redis Community Edition (CE) with the v7.4 release.\n\nRedis Ltd. also offers [Redis Software](https://redis.io/enterprise/), a self-managed software with additional compliance, reliability, and resiliency for enterprise scaling,\nand [Redis Cloud](https://redis.io/cloud/), a fully managed service integrated with Google Cloud, Azure, and AWS for production-ready apps.\n\nRead more about the differences between Redis Community Edition and Redis [here](https://redis.io/comparisons/oss-vs-enterprise/).\n\nBuilding Redis\n---\n\nRedis can be compiled and used on Linux, OSX, OpenBSD, NetBSD, FreeBSD.\nWe support big endian and little endian architectures, and both 32 bit\nand 64 bit systems.\n\nIt may compile on Solaris derived systems (for instance SmartOS) but our\nsupport for this platform is *best effort* and Redis is not guaranteed to\nwork as well as in Linux, OSX, and \\*BSD.\n\nIt is as simple as:\n\n    % make\n\nTo build with TLS support, you'll need OpenSSL development libraries (e.g.\nlibssl-dev on Debian/Ubuntu) and run:\n\n    % make BUILD_TLS=yes\n\nTo build with systemd support, you'll need systemd development libraries (such \nas libsystemd-dev on Debian/Ubuntu or systemd-devel on CentOS) and run:\n\n    % make USE_SYSTEMD=yes\n\nTo append a suffix to Redis program names, use:\n\n    % make PROG_SUFFIX=\"-alt\"\n\nYou can build a 32 bit Redis binary using:\n\n    % make 32bit\n\nAfter building Redis, it is a good idea to test it using:\n\n    % make test\n\nIf TLS is built, running the tests with TLS enabled (you will need `tcl-tls`\ninstalled):\n\n    % ./utils/gen-test-certs.sh\n    % ./runtest --tls\n\n\nFixing build problems with dependencies or cached build options\n---\n\nRedis has some dependencies which are included in the `deps` directory.\n`make` does not automatically rebuild dependencies even if something in\nthe source code of dependencies changes.\n\nWhen you update the source code with `git pull` or when code inside the\ndependencies tree is modified in any other way, make sure to use the following\ncommand in order to really clean everything and rebuild from scratch:\n\n    % make distclean\n\nThis will clean: jemalloc, lua, hiredis, linenoise and other dependencies.\n\nAlso if you force certain build options like 32bit target, no C compiler\noptimizations (for debugging purposes), and other similar build time options,\nthose options are cached indefinitely until you issue a `make distclean`\ncommand.\n\nFixing problems building 32 bit binaries\n---\n\nIf after building Redis with a 32 bit target you need to rebuild it\nwith a 64 bit target, or the other way around, you need to perform a\n`make distclean` in the root directory of the Redis distribution.\n\nIn case of build errors when trying to build a 32 bit binary of Redis, try\nthe following steps:\n\n* Install the package libc6-dev-i386 (also try g++-multilib).\n* Try using the following command line instead of `make 32bit`:\n  `make CFLAGS=\"-m32 -march=native\" LDFLAGS=\"-m32\"`\n\nAllocator\n---\n\nSelecting a non-default memory allocator when building Redis is done by setting\nthe `MALLOC` environment variable. Redis is compiled and linked against libc\nmalloc by default, with the exception of jemalloc being the default on Linux\nsystems. This default was picked because jemalloc has proven to have fewer\nfragmentation problems than libc malloc.\n\nTo force compiling against libc malloc, use:\n\n    % make MALLOC=libc\n\nTo compile against jemalloc on Mac OS X systems, use:\n\n    % make MALLOC=jemalloc\n\nMonotonic clock\n---\n\nBy default, Redis will build using the POSIX clock_gettime function as the\nmonotonic clock source.  On most modern systems, the internal processor clock\ncan be used to improve performance.  Cautions can be found here: \n    http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/\n\nTo build with support for the processor's internal instruction clock, use:\n\n    % make CFLAGS=\"-DUSE_PROCESSOR_CLOCK\"\n\nVerbose build\n---\n\nRedis will build with a user-friendly colorized output by default.\nIf you want to see a more verbose output, use the following:\n\n    % make V=1\n\nRunning Redis\n---\n\nTo run Redis with the default configuration, just type:\n\n    % cd src\n    % ./redis-server\n\nIf you want to provide your redis.conf, you have to run it using an additional\nparameter (the path of the configuration file):\n\n    % cd src\n    % ./redis-server /path/to/redis.conf\n\nIt is possible to alter the Redis configuration by passing parameters directly\nas options using the command line. Examples:\n\n    % ./redis-server --port 9999 --replicaof 127.0.0.1 6379\n    % ./redis-server /etc/redis/6379.conf --loglevel debug\n\nAll the options in redis.conf are also supported as options using the command\nline, with exactly the same name.\n\nRunning Redis with TLS\n---\n\nPlease consult the [TLS.md](TLS.md) file for more information on\nhow to use Redis with TLS.\n\nPlaying with Redis\n---\n\nYou can use redis-cli to play with Redis. Start a redis-server instance,\nthen in another terminal try the following:\n\n    % cd src\n    % ./redis-cli\n    redis> ping\n    PONG\n    redis> set foo bar\n    OK\n    redis> get foo\n    \"bar\"\n    redis> incr mycounter\n    (integer) 1\n    redis> incr mycounter\n    (integer) 2\n    redis>\n\nYou can find the list of all the available commands at https://redis.io/commands.\n\nInstalling Redis\n---\n\nIn order to install Redis binaries into /usr/local/bin, just use:\n\n    % make install\n\nYou can use `make PREFIX=/some/other/directory install` if you wish to use a\ndifferent destination.\n\n`make install` will just install binaries in your system, but will not configure\ninit scripts and configuration files in the appropriate place. This is not\nneeded if you just want to play a bit with Redis, but if you are installing\nit the proper way for a production system, we have a script that does this\nfor Ubuntu and Debian systems:\n\n    % cd utils\n    % ./install_server.sh\n\n_Note_: `install_server.sh` will not work on Mac OSX; it is built for Linux only.\n\nThe script will ask you a few questions and will setup everything you need\nto run Redis properly as a background daemon that will start again on\nsystem reboots.\n\nYou'll be able to stop and start Redis using the script named\n`/etc/init.d/redis_<portnumber>`, for instance `/etc/init.d/redis_6379`.\n\nCode contributions\n---\n\nBy contributing code to the Redis project in any form, including sending a pull request via GitHub,\na code fragment or patch via private email or public discussion groups, you agree to release your\ncode under the terms of the [Redis Software Grant and Contributor License Agreement][1]. Redis software\ncontains contributions to the original Redis core project, which are owned by their contributors and\nlicensed under the 3BSD license. Any copy of that license in this repository applies only to those\ncontributions. Redis releases all Redis Community Edition versions from 7.4.x and thereafter under the\nRSALv2/SSPL dual-license as described in the [LICENSE.txt][2] file included in the Redis Community Edition source distribution.\n\nPlease see the [CONTRIBUTING.md][1] file in this source distribution for more information. For\nsecurity bugs and vulnerabilities, please see [SECURITY.md][3].\n\n[1]: https://github.com/redis/redis/blob/unstable/CONTRIBUTING.md\n[2]: https://github.com/redis/redis/blob/unstable/LICENSE.txt\n[3]: https://github.com/redis/redis/blob/unstable/SECURITY.md\n\nRedis Trademarks\n---\n\nThe purpose of a trademark is to identify the goods and services of a person or company without\ncausing confusion. As the registered owner of its name and logo, Redis accepts certain limited uses\nof its trademarks but it has requirements that must be followed as described in its Trademark\nGuidelines available at: https://redis.com/legal/trademark-guidelines/.\n\nRedis internals\n===\n\nIf you are reading this README you are likely in front of a GitHub page\nor you just untarred the Redis distribution tar ball. In both the cases\nyou are basically one step away from the source code, so here we explain\nthe Redis source code layout, what is in each file as a general idea, the\nmost important functions and structures inside the Redis server and so forth.\nWe keep all the discussion at a high level without digging into the details\nsince this document would be huge otherwise and our code base changes\ncontinuously, but a general idea should be a good starting point to\nunderstand more. Moreover most of the code is heavily commented and easy\nto follow.\n\nSource code layout\n---\n\nThe Redis root directory just contains this README, the Makefile which\ncalls the real Makefile inside the `src` directory and an example\nconfiguration for Redis and Redis Sentinel. You can find a few shell\nscripts that are used in order to execute the Redis, Redis Cluster and\nRedis Sentinel unit tests, which are implemented inside the `tests`\ndirectory.\n\nInside the root are the following important directories:\n\n* `src`: contains the Redis implementation, written in C.\n* `tests`: contains the unit tests, implemented in Tcl.\n* `deps`: contains libraries Redis uses. Everything needed to compile Redis is inside this directory; your system just needs to provide `libc`, a POSIX compatible interface and a C compiler. Notably `deps` contains a copy of `jemalloc`, which is the default allocator of Redis under Linux. Note that under `deps` there are also things which started with the Redis project, but for which the main repository is not `redis/redis`.\n\nThere are a few more directories but they are not very important for our goals\nhere. We'll focus mostly on `src`, where the Redis implementation is contained,\nexploring what there is inside each file. The order in which files are\nexposed is the logical one to follow in order to disclose different layers\nof complexity incrementally.\n\nNote: lately Redis was refactored quite a bit. Function names and file\nnames have been changed, so you may find that this documentation reflects the\n`unstable` branch more closely. For instance, in Redis 3.0 the `server.c`\nand `server.h` files were named `redis.c` and `redis.h`. However the overall\nstructure is the same. Keep in mind that all the new developments and pull\nrequests should be performed against the `unstable` branch.\n\nserver.h\n---\n\nThe simplest way to understand how a program works is to understand the\ndata structures it uses. So we'll start from the main header file of\nRedis, which is `server.h`.\n\nAll the server configuration and in general all the shared state is\ndefined in a global structure called `server`, of type `struct redisServer`.\nA few important fields in this structure are:\n\n* `server.db` is an array of Redis databases, where data is stored.\n* `server.commands` is the command table.\n* `server.clients` is a linked list of clients connected to the server.\n* `server.master` is a special client, the master, if the instance is a replica.\n\nThere are tons of other fields. Most fields are commented directly inside\nthe structure definition.\n\nAnother important Redis data structure is the one defining a client.\nIn the past it was called `redisClient`, now just `client`. The structure\nhas many fields, here we'll just show the main ones:\n```c\nstruct client {\n    int fd;\n    sds querybuf;\n    int argc;\n    robj **argv;\n    redisDb *db;\n    int flags;\n    list *reply;\n    // ... many other fields ...\n    char buf[PROTO_REPLY_CHUNK_BYTES];\n}\n```\nThe client structure defines a *connected client*:\n\n* The `fd` field is the client socket file descriptor.\n* `argc` and `argv` are populated with the command the client is executing, so that functions implementing a given Redis command can read the arguments.\n* `querybuf` accumulates the requests from the client, which are parsed by the Redis server according to the Redis protocol and executed by calling the implementations of the commands the client is executing.\n* `reply` and `buf` are dynamic and static buffers that accumulate the replies the server sends to the client. These buffers are incrementally written to the socket as soon as the file descriptor is writable.\n\nAs you can see in the client structure above, arguments in a command\nare described as `robj` structures. The following is the full `robj`\nstructure, which defines a *Redis object*:\n\n```c\nstruct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or\n                            * LFU data (least significant 8 bits frequency\n                            * and most significant 16 bits access time). */\n    int refcount;\n    void *ptr;\n};\n```\n\nBasically this structure can represent all the basic Redis data types like\nstrings, lists, sets, sorted sets and so forth. The interesting thing is that\nit has a `type` field, so that it is possible to know what type a given\nobject has, and a `refcount`, so that the same object can be referenced\nin multiple places without allocating it multiple times. Finally the `ptr`\nfield points to the actual representation of the object, which might vary\neven for the same type, depending on the `encoding` used.\n\nRedis objects are used extensively in the Redis internals, however in order\nto avoid the overhead of indirect accesses, recently in many places\nwe just use plain dynamic strings not wrapped inside a Redis object.\n\nserver.c\n---\n\nThis is the entry point of the Redis server, where the `main()` function\nis defined. The following are the most important steps in order to startup\nthe Redis server.\n\n* `initServerConfig()` sets up the default values of the `server` structure.\n* `initServer()` allocates the data structures needed to operate, setup the listening socket, and so forth.\n* `aeMain()` starts the event loop which listens for new connections.\n\nThere are two special functions called periodically by the event loop:\n\n1. `serverCron()` is called periodically (according to `server.hz` frequency), and performs tasks that must be performed from time to time, like checking for timed out clients.\n2. `beforeSleep()` is called every time the event loop fired, Redis served a few requests, and is returning back into the event loop.\n\nInside server.c you can find code that handles other vital things of the Redis server:\n\n* `call()` is used in order to call a given command in the context of a given client.\n* `activeExpireCycle()` handles eviction of keys with a time to live set via the `EXPIRE` command.\n* `performEvictions()` is called when a new write command should be performed but Redis is out of memory according to the `maxmemory` directive.\n* The global variable `redisCommandTable` defines all the Redis commands, specifying the name of the command, the function implementing the command, the number of arguments required, and other properties of each command.\n\ncommands.c\n---\nThis file is auto generated by utils/generate-command-code.py, the content is based on the JSON files in the src/commands folder.\nThese are meant to be the single source of truth about the Redis commands, and all the metadata about them.\nThese JSON files are not meant to be used by anyone directly, instead that metadata can be obtained via the `COMMAND` command.\n\nnetworking.c\n---\n\nThis file defines all the I/O functions with clients, masters and replicas\n(which in Redis are just special clients):\n\n* `createClient()` allocates and initializes a new client.\n* The `addReply*()` family of functions are used by command implementations in order to append data to the client structure, that will be transmitted to the client as a reply for a given command executed.\n* `writeToClient()` transmits the data pending in the output buffers to the client and is called by the *writable event handler* `sendReplyToClient()`.\n* `readQueryFromClient()` is the *readable event handler* and accumulates data read from the client into the query buffer.\n* `processInputBuffer()` is the entry point in order to parse the client query buffer according to the Redis protocol. Once commands are ready to be processed, it calls `processCommand()` which is defined inside `server.c` in order to actually execute the command.\n* `freeClient()` deallocates, disconnects and removes a client.\n\naof.c and rdb.c\n---\n\nAs you can guess from the names, these files implement the RDB and AOF\npersistence for Redis. Redis uses a persistence model based on the `fork()`\nsystem call in order to create a process with the same (shared) memory\ncontent of the main Redis process. This secondary process dumps the content\nof the memory on disk. This is used by `rdb.c` to create the snapshots\non disk and by `aof.c` in order to perform the AOF rewrite when the\nappend only file gets too big.\n\nThe implementation inside `aof.c` has additional functions in order to\nimplement an API that allows commands to append new commands into the AOF\nfile as clients execute them.\n\nThe `call()` function defined inside `server.c` is responsible for calling\nthe functions that in turn will write the commands into the AOF.\n\ndb.c\n---\n\nCertain Redis commands operate on specific data types; others are general.\nExamples of generic commands are `DEL` and `EXPIRE`. They operate on keys\nand not on their values specifically. All those generic commands are\ndefined inside `db.c`.\n\nMoreover `db.c` implements an API in order to perform certain operations\non the Redis dataset without directly accessing the internal data structures.\n\nThe most important functions inside `db.c` which are used in many command\nimplementations are the following:\n\n* `lookupKeyRead()` and `lookupKeyWrite()` are used in order to get a pointer to the value associated to a given key, or `NULL` if the key does not exist.\n* `dbAdd()` and its higher level counterpart `setKey()` create a new key in a Redis database.\n* `dbDelete()` removes a key and its associated value.\n* `emptyData()` removes an entire single database or all the databases defined.\n\nThe rest of the file implements the generic commands exposed to the client.\n\nobject.c\n---\n\nThe `robj` structure defining Redis objects was already described. Inside\n`object.c` there are all the functions that operate with Redis objects at\na basic level, like functions to allocate new objects, handle the reference\ncounting and so forth. Notable functions inside this file:\n\n* `incrRefCount()` and `decrRefCount()` are used in order to increment or decrement an object reference count. When it drops to 0 the object is finally freed.\n* `createObject()` allocates a new object. There are also specialized functions to allocate string objects having a specific content, like `createStringObjectFromLongLong()` and similar functions.\n\nThis file also implements the `OBJECT` command.\n\nreplication.c\n---\n\nThis is one of the most complex files inside Redis, it is recommended to\napproach it only after getting a bit familiar with the rest of the code base.\nIn this file there is the implementation of both the master and replica role\nof Redis.\n\nOne of the most important functions inside this file is `replicationFeedSlaves()` that writes commands to the clients representing replica instances connected\nto our master, so that the replicas can get the writes performed by the clients:\nthis way their data set will remain synchronized with the one in the master.\n\nThis file also implements both the `SYNC` and `PSYNC` commands that are\nused in order to perform the first synchronization between masters and\nreplicas, or to continue the replication after a disconnection.\n\nScript\n---\n\nThe script unit is composed of 3 units:\n* `script.c` - integration of scripts with Redis (commands execution, set replication/resp, ...)\n* `script_lua.c` - responsible to execute Lua code, uses `script.c` to interact with Redis from within the Lua code.\n* `function_lua.c` - contains the Lua engine implementation, uses `script_lua.c` to execute the Lua code.\n* `functions.c` - contains Redis Functions implementation (`FUNCTION` command), uses `functions_lua.c` if the function it wants to invoke needs the Lua engine.\n* `eval.c` - contains the `eval` implementation using `script_lua.c` to invoke the Lua code.\n\n\nOther C files\n---\n\n* `t_hash.c`, `t_list.c`, `t_set.c`, `t_string.c`, `t_zset.c` and `t_stream.c` contains the implementation of the Redis data types. They implement both an API to access a given data type, and the client command implementations for these data types.\n* `ae.c` implements the Redis event loop, it's a self contained library which is simple to read and understand.\n* `sds.c` is the Redis string library, check https://github.com/antirez/sds for more information.\n* `anet.c` is a library to use POSIX networking in a simpler way compared to the raw interface exposed by the kernel.\n* `dict.c` is an implementation of a non-blocking hash table which rehashes incrementally.\n* `cluster.c` implements the Redis Cluster. Probably a good read only after being very familiar with the rest of the Redis code base. If you want to read `cluster.c` make sure to read the [Redis Cluster specification][4].\n\n[4]: https://redis.io/docs/latest/operate/oss_and_stack/reference/cluster-spec/\n\nAnatomy of a Redis command\n---\n\nAll the Redis commands are defined in the following way:\n\n```c\nvoid foobarCommand(client *c) {\n    printf(\"%s\",c->argv[1]->ptr); /* Do something with the argument. */\n    addReply(c,shared.ok); /* Reply something to the client. */\n}\n```\n\nThe command function is referenced by a JSON file, together with its metadata, see `commands.c` described above for details.\nThe command flags are documented in the comment above the `struct redisCommand` in `server.h`.\nFor other details, please refer to the `COMMAND` command. https://redis.io/commands/command/\n\nAfter the command operates in some way, it returns a reply to the client,\nusually using `addReply()` or a similar function defined inside `networking.c`.\n\nThere are tons of command implementations inside the Redis source code\nthat can serve as examples of actual commands implementations (e.g. pingCommand). Writing\na few toy commands can be a good exercise to get familiar with the code base.\n\nThere are also many other files not described here, but it is useless to\ncover everything. We just want to help you with the first steps.\nEventually you'll find your way inside the Redis code base :-)\n\nEnjoy!\n"
        },
        {
          "name": "REDISCONTRIBUTIONS.txt",
          "type": "blob",
          "size": 1.76,
          "content": "Copyright (c) 2006-Present, Redis Ltd. and Contributors\nAll rights reserved.\n\nNote: Continued Applicability of the BSD-3-Clause License\n\nDespite the shift to the dual-licensing model with Redis Community Edition version 7.4 (RSALv2 or SSPLv1), portions of\nRedis Community Edition remain available subject to the BSD-3-Clause License (BSD). See below for the full BSD\nlicense:\n\nRedistribution and use in source and binary forms, with or without modification, are permitted\nprovided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this list of conditions\nand the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions\nand the following disclaimer in the documentation and/or other materials provided with the\ndistribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse\nor promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\nIN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF\nTHE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.45,
          "content": "# Security Policy\n\n## Supported Versions\n\nRedis is generally backward compatible with very few exceptions, so we\nrecommend users to always use the latest version to experience stability,\nperformance and security.\n\nWe generally backport security issues to a single previous major version,\nunless this is not possible or feasible with a reasonable effort.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 7.4.x   | :white_check_mark: |\n| 7.2.x   | :white_check_mark: |\n| < 7.2.x | :x:                |\n| 6.2.x   | :white_check_mark: |\n| < 6.2.x | :x:                |\n\n## Reporting a Vulnerability\n\nIf you believe you've discovered a serious vulnerability, please contact the\nRedis core team at redis@redis.io. We will evaluate your report and if\nnecessary issue a fix and an advisory. If the issue was previously undisclosed,\nwe'll also mention your name in the credits.\n\n## Responsible Disclosure\n\nIn some cases, we may apply a responsible disclosure process to reported or\notherwise discovered vulnerabilities. We will usually do that for a critical\nvulnerability, and only if we have a good reason to believe information about\nit is not yet public.\n\nThis process involves providing an early notification about the vulnerability,\nits impact and mitigations to a short list of vendors under a time-limited\nembargo on public disclosure.\n\nIf you believe you should be on the list, please contact us and we will\nconsider your request based on the above criteria.\n"
        },
        {
          "name": "TLS.md",
          "type": "blob",
          "size": 3.54,
          "content": "TLS Support\n===========\n\nGetting Started\n---------------\n\n### Building\n\nTo build with TLS support you'll need OpenSSL development libraries (e.g.\nlibssl-dev on Debian/Ubuntu).\n\nTo build TLS support as Redis built-in:\nRun `make BUILD_TLS=yes`.\n\nOr to build TLS as Redis module:\nRun `make BUILD_TLS=module`.\n\nNote that sentinel mode does not support TLS module.\n\n### Tests\n\nTo run Redis test suite with TLS, you'll need TLS support for TCL (i.e.\n`tcl-tls` package on Debian/Ubuntu).\n\n1. Run `./utils/gen-test-certs.sh` to generate a root CA and a server\n   certificate.\n\n2. Run `./runtest --tls` or `./runtest-cluster --tls` to run Redis and Redis\n   Cluster tests in TLS mode.\n\n3. Run `./runtest --tls-module` or `./runtest-cluster --tls-module` to\n   run Redis and Redis cluster tests in TLS mode with Redis module.\n\n### Running manually\n\nTo manually run a Redis server with TLS mode (assuming `gen-test-certs.sh` was\ninvoked so sample certificates/keys are available):\n\nFor TLS built-in mode:\n    ./src/redis-server --tls-port 6379 --port 0 \\\n        --tls-cert-file ./tests/tls/redis.crt \\\n        --tls-key-file ./tests/tls/redis.key \\\n        --tls-ca-cert-file ./tests/tls/ca.crt\n\nFor TLS module mode:\n    ./src/redis-server --tls-port 6379 --port 0 \\\n        --tls-cert-file ./tests/tls/redis.crt \\\n        --tls-key-file ./tests/tls/redis.key \\\n        --tls-ca-cert-file ./tests/tls/ca.crt \\\n        --loadmodule src/redis-tls.so\n\nTo connect to this Redis server with `redis-cli`:\n\n    ./src/redis-cli --tls \\\n        --cert ./tests/tls/redis.crt \\\n        --key ./tests/tls/redis.key \\\n        --cacert ./tests/tls/ca.crt\n\nThis will disable TCP and enable TLS on port 6379. It's also possible to have\nboth TCP and TLS available, but you'll need to assign different ports.\n\nTo make a Replica connect to the master using TLS, use `--tls-replication yes`,\nand to make Redis Cluster use TLS across nodes use `--tls-cluster yes`.\n\nConnections\n-----------\n\nAll socket operations now go through a connection abstraction layer that hides\nI/O and read/write event handling from the caller.\n\n**Multi-threading I/O is not currently supported for TLS**, as a TLS connection\nneeds to do its own manipulation of AE events which is not thread safe. The\nsolution is probably to manage independent AE loops for I/O threads and longer\nterm association of connections with threads. This may potentially improve\noverall performance as well.\n\nSync IO for TLS is currently implemented in a hackish way, i.e. making the\nsocket blocking and configuring socket-level timeout.  This means the timeout\nvalue may not be so accurate, and there would be a lot of syscall overhead.\nHowever I believe that getting rid of syncio completely in favor of pure async\nwork is probably a better move than trying to fix that. For replication it would\nprobably not be so hard. For cluster keys migration it might be more difficult,\nbut there are probably other good reasons to improve that part anyway.\n\nTo-Do List\n----------\n\n- [ ] redis-benchmark support. The current implementation is a mix of using\n  hiredis for parsing and basic networking (establishing connections), but\n  directly manipulating sockets for most actions. This will need to be cleaned\n  up for proper TLS support. The best approach is probably to migrate to hiredis\n  async mode.\n- [ ] redis-cli `--slave` and `--rdb` support.\n\nMulti-port\n----------\n\nConsider the implications of allowing TLS to be configured on a separate port,\nmaking Redis listening on multiple ports:\n\n1. Startup banner port notification\n2. Proctitle\n3. How slaves announce themselves\n4. Cluster bus port calculation\n"
        },
        {
          "name": "deps",
          "type": "tree",
          "content": null
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "redis.conf",
          "type": "blob",
          "size": 106.18,
          "content": "# Redis configuration file example.\n#\n# Note that in order to read the configuration file, Redis must be\n# started with the file path as first argument:\n#\n# ./redis-server /path/to/redis.conf\n\n# Note on units: when memory size is needed, it is possible to specify\n# it in the usual form of 1k 5GB 4M and so forth:\n#\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n#\n# units are case insensitive so 1GB 1Gb 1gB are all the same.\n\n################################## INCLUDES ###################################\n\n# Include one or more other config files here.  This is useful if you\n# have a standard template that goes to all Redis servers but also need\n# to customize a few per-server settings.  Include files can include\n# other files, so use this wisely.\n#\n# Note that option \"include\" won't be rewritten by command \"CONFIG REWRITE\"\n# from admin or Redis Sentinel. Since Redis always uses the last processed\n# line as value of a configuration directive, you'd better put includes\n# at the beginning of this file to avoid overwriting config change at runtime.\n#\n# If instead you are interested in using includes to override configuration\n# options, it is better to use include as the last line.\n#\n# Included paths may contain wildcards. All files matching the wildcards will\n# be included in alphabetical order.\n# Note that if an include path contains a wildcards but no files match it when\n# the server is started, the include statement will be ignored and no error will\n# be emitted.  It is safe, therefore, to include wildcard files from empty\n# directories.\n#\n# include /path/to/local.conf\n# include /path/to/other.conf\n# include /path/to/fragments/*.conf\n#\n\n################################## MODULES #####################################\n\n# Load modules at startup. If the server is not able to load modules\n# it will abort. It is possible to use multiple loadmodule directives.\n#\n# loadmodule /path/to/my_module.so\n# loadmodule /path/to/other_module.so\n# loadmodule /path/to/args_module.so [arg [arg ...]]\n\n################################## NETWORK #####################################\n\n# By default, if no \"bind\" configuration directive is specified, Redis listens\n# for connections from all available network interfaces on the host machine.\n# It is possible to listen to just one or multiple selected interfaces using\n# the \"bind\" configuration directive, followed by one or more IP addresses.\n# Each address can be prefixed by \"-\", which means that redis will not fail to\n# start if the address is not available. Being not available only refers to\n# addresses that does not correspond to any network interface. Addresses that\n# are already in use will always fail, and unsupported protocols will always BE\n# silently skipped.\n#\n# Examples:\n#\n# bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses\n# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6\n# bind * -::*                     # like the default, all available interfaces\n#\n# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the\n# internet, binding to all the interfaces is dangerous and will expose the\n# instance to everybody on the internet. So by default we uncomment the\n# following bind directive, that will force Redis to listen only on the\n# IPv4 and IPv6 (if available) loopback interface addresses (this means Redis\n# will only be able to accept client connections from the same host that it is\n# running on).\n#\n# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES\n# COMMENT OUT THE FOLLOWING LINE.\n#\n# You will also need to set a password unless you explicitly disable protected\n# mode.\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nbind 127.0.0.1 -::1\n\n# By default, outgoing connections (from replica to master, from Sentinel to\n# instances, cluster bus, etc.) are not bound to a specific local address. In\n# most cases, this means the operating system will handle that based on routing\n# and the interface through which the connection goes out.\n#\n# Using bind-source-addr it is possible to configure a specific address to bind\n# to, which may also affect how the connection gets routed.\n#\n# Example:\n#\n# bind-source-addr 10.0.0.1\n\n# Protected mode is a layer of security protection, in order to avoid that\n# Redis instances left open on the internet are accessed and exploited.\n#\n# When protected mode is on and the default user has no password, the server\n# only accepts local connections from the IPv4 address (127.0.0.1), IPv6 address\n# (::1) or Unix domain sockets.\n#\n# By default protected mode is enabled. You should disable it only if\n# you are sure you want clients from other hosts to connect to Redis\n# even if no authentication is configured.\nprotected-mode yes\n\n# Redis uses default hardened security configuration directives to reduce the\n# attack surface on innocent users. Therefore, several sensitive configuration\n# directives are immutable, and some potentially-dangerous commands are blocked.\n#\n# Configuration directives that control files that Redis writes to (e.g., 'dir'\n# and 'dbfilename') and that aren't usually modified during runtime\n# are protected by making them immutable.\n#\n# Commands that can increase the attack surface of Redis and that aren't usually\n# called by users are blocked by default.\n#\n# These can be exposed to either all connections or just local ones by setting\n# each of the configs listed below to either of these values:\n#\n# no    - Block for any connection (remain immutable)\n# yes   - Allow for any connection (no protection)\n# local - Allow only for local connections. Ones originating from the\n#         IPv4 address (127.0.0.1), IPv6 address (::1) or Unix domain sockets.\n#\n# enable-protected-configs no\n# enable-debug-command no\n# enable-module-command no\n\n# Accept connections on the specified port, default is 6379 (IANA #815344).\n# If port 0 is specified Redis will not listen on a TCP socket.\nport 6379\n\n# TCP listen() backlog.\n#\n# In high requests-per-second environments you need a high backlog in order\n# to avoid slow clients connection issues. Note that the Linux kernel\n# will silently truncate it to the value of /proc/sys/net/core/somaxconn so\n# make sure to raise both the value of somaxconn and tcp_max_syn_backlog\n# in order to get the desired effect.\ntcp-backlog 511\n\n# Unix socket.\n#\n# Specify the path for the Unix socket that will be used to listen for\n# incoming connections. There is no default, so Redis will not listen\n# on a unix socket when not specified.\n#\n# unixsocket /run/redis.sock\n# unixsocketperm 700\n\n# Close the connection after a client is idle for N seconds (0 to disable)\ntimeout 0\n\n# TCP keepalive.\n#\n# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence\n# of communication. This is useful for two reasons:\n#\n# 1) Detect dead peers.\n# 2) Force network equipment in the middle to consider the connection to be\n#    alive.\n#\n# On Linux, the specified value (in seconds) is the period used to send ACKs.\n# Note that to close the connection the double of the time is needed.\n# On other kernels the period depends on the kernel configuration.\n#\n# A reasonable value for this option is 300 seconds, which is the new\n# Redis default starting with Redis 3.2.1.\ntcp-keepalive 300\n\n# Apply OS-specific mechanism to mark the listening socket with the specified\n# ID, to support advanced routing and filtering capabilities.\n#\n# On Linux, the ID represents a connection mark.\n# On FreeBSD, the ID represents a socket cookie ID.\n# On OpenBSD, the ID represents a route table ID.\n#\n# The default value is 0, which implies no marking is required.\n# socket-mark-id 0\n\n################################# TLS/SSL #####################################\n\n# By default, TLS/SSL is disabled. To enable it, the \"tls-port\" configuration\n# directive can be used to define TLS-listening ports. To enable TLS on the\n# default port, use:\n#\n# port 0\n# tls-port 6379\n\n# Configure a X.509 certificate and private key to use for authenticating the\n# server to connected clients, masters or cluster peers.  These files should be\n# PEM formatted.\n#\n# tls-cert-file redis.crt\n# tls-key-file redis.key\n#\n# If the key file is encrypted using a passphrase, it can be included here\n# as well.\n#\n# tls-key-file-pass secret\n\n# Normally Redis uses the same certificate for both server functions (accepting\n# connections) and client functions (replicating from a master, establishing\n# cluster bus connections, etc.).\n#\n# Sometimes certificates are issued with attributes that designate them as\n# client-only or server-only certificates. In that case it may be desired to use\n# different certificates for incoming (server) and outgoing (client)\n# connections. To do that, use the following directives:\n#\n# tls-client-cert-file client.crt\n# tls-client-key-file client.key\n#\n# If the key file is encrypted using a passphrase, it can be included here\n# as well.\n#\n# tls-client-key-file-pass secret\n\n# Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange,\n# required by older versions of OpenSSL (<3.0). Newer versions do not require\n# this configuration and recommend against it.\n#\n# tls-dh-params-file redis.dh\n\n# Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL\n# clients and peers.  Redis requires an explicit configuration of at least one\n# of these, and will not implicitly use the system wide configuration.\n#\n# tls-ca-cert-file ca.crt\n# tls-ca-cert-dir /etc/ssl/certs\n\n# By default, clients (including replica servers) on a TLS port are required\n# to authenticate using valid client side certificates.\n#\n# If \"no\" is specified, client certificates are not required and not accepted.\n# If \"optional\" is specified, client certificates are accepted and must be\n# valid if provided, but are not required.\n#\n# tls-auth-clients no\n# tls-auth-clients optional\n\n# By default, a Redis replica does not attempt to establish a TLS connection\n# with its master.\n#\n# Use the following directive to enable TLS on replication links.\n#\n# tls-replication yes\n\n# By default, the Redis Cluster bus uses a plain TCP connection. To enable\n# TLS for the bus protocol, use the following directive:\n#\n# tls-cluster yes\n\n# By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended\n# that older formally deprecated versions are kept disabled to reduce the attack surface.\n# You can explicitly specify TLS versions to support.\n# Allowed values are case insensitive and include \"TLSv1\", \"TLSv1.1\", \"TLSv1.2\",\n# \"TLSv1.3\" (OpenSSL >= 1.1.1) or any combination.\n# To enable only TLSv1.2 and TLSv1.3, use:\n#\n# tls-protocols \"TLSv1.2 TLSv1.3\"\n\n# Configure allowed ciphers.  See the ciphers(1ssl) manpage for more information\n# about the syntax of this string.\n#\n# Note: this configuration applies only to <= TLSv1.2.\n#\n# tls-ciphers DEFAULT:!MEDIUM\n\n# Configure allowed TLSv1.3 ciphersuites.  See the ciphers(1ssl) manpage for more\n# information about the syntax of this string, and specifically for TLSv1.3\n# ciphersuites.\n#\n# tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256\n\n# When choosing a cipher, use the server's preference instead of the client\n# preference. By default, the server follows the client's preference.\n#\n# tls-prefer-server-ciphers yes\n\n# By default, TLS session caching is enabled to allow faster and less expensive\n# reconnections by clients that support it. Use the following directive to disable\n# caching.\n#\n# tls-session-caching no\n\n# Change the default number of TLS sessions cached. A zero value sets the cache\n# to unlimited size. The default size is 20480.\n#\n# tls-session-cache-size 5000\n\n# Change the default timeout of cached TLS sessions. The default timeout is 300\n# seconds.\n#\n# tls-session-cache-timeout 60\n\n################################# GENERAL #####################################\n\n# By default Redis does not run as a daemon. Use 'yes' if you need it.\n# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.\n# When Redis is supervised by upstart or systemd, this parameter has no impact.\ndaemonize no\n\n# If you run Redis from upstart or systemd, Redis can interact with your\n# supervision tree. Options:\n#   supervised no      - no supervision interaction\n#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode\n#                        requires \"expect stop\" in your upstart job config\n#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET\n#                        on startup, and updating Redis status on a regular\n#                        basis.\n#   supervised auto    - detect upstart or systemd method based on\n#                        UPSTART_JOB or NOTIFY_SOCKET environment variables\n# Note: these supervision methods only signal \"process is ready.\"\n#       They do not enable continuous pings back to your supervisor.\n#\n# The default is \"no\". To run under upstart/systemd, you can simply uncomment\n# the line below:\n#\n# supervised auto\n\n# If a pid file is specified, Redis writes it where specified at startup\n# and removes it at exit.\n#\n# When the server runs non daemonized, no pid file is created if none is\n# specified in the configuration. When the server is daemonized, the pid file\n# is used even if not specified, defaulting to \"/var/run/redis.pid\".\n#\n# Creating a pid file is best effort: if Redis is not able to create it\n# nothing bad happens, the server will start and run normally.\n#\n# Note that on modern Linux systems \"/run/redis.pid\" is more conforming\n# and should be used instead.\npidfile /var/run/redis_6379.pid\n\n# Specify the server verbosity level.\n# This can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\n# nothing (nothing is logged)\nloglevel notice\n\n# Specify the log file name. Also the empty string can be used to force\n# Redis to log on the standard output. Note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile \"\"\n\n# To enable logging to the system logger, just set 'syslog-enabled' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# Specify the syslog identity.\n# syslog-ident redis\n\n# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.\n# syslog-facility local0\n\n# To disable the built in crash log, which will possibly produce cleaner core\n# dumps when they are needed, uncomment the following:\n#\n# crash-log-enabled no\n\n# To disable the fast memory check that's run as part of the crash log, which\n# will possibly let redis terminate sooner, uncomment the following:\n#\n# crash-memcheck-enabled no\n\n# Set the number of databases. The default database is DB 0, you can select\n# a different one on a per-connection basis using SELECT <dbid> where\n# dbid is a number between 0 and 'databases'-1\ndatabases 16\n\n# By default Redis shows an ASCII art logo only when started to log to the\n# standard output and if the standard output is a TTY and syslog logging is\n# disabled. Basically this means that normally a logo is displayed only in\n# interactive sessions.\n#\n# However it is possible to force the pre-4.0 behavior and always show a\n# ASCII art logo in startup logs by setting the following option to yes.\nalways-show-logo no\n\n# To avoid logging personal identifiable information (PII) into server log file,\n# uncomment the following:\n#\n# hide-user-data-from-log yes\n\n# By default, Redis modifies the process title (as seen in 'top' and 'ps') to\n# provide some runtime information. It is possible to disable this and leave\n# the process name as executed by setting the following to no.\nset-proc-title yes\n\n# When changing the process title, Redis uses the following template to construct\n# the modified title.\n#\n# Template variables are specified in curly brackets. The following variables are\n# supported:\n#\n# {title}           Name of process as executed if parent, or type of child process.\n# {listen-addr}     Bind address or '*' followed by TCP or TLS port listening on, or\n#                   Unix socket if only that's available.\n# {server-mode}     Special mode, i.e. \"[sentinel]\" or \"[cluster]\".\n# {port}            TCP port listening on, or 0.\n# {tls-port}        TLS port listening on, or 0.\n# {unixsocket}      Unix domain socket listening on, or \"\".\n# {config-file}     Name of configuration file used.\n#\nproc-title-template \"{title} {listen-addr} {server-mode}\"\n\n# Set the local environment which is used for string comparison operations, and \n# also affect the performance of Lua scripts. Empty String indicates the locale \n# is derived from the environment variables.\nlocale-collate \"\"\n\n################################ SNAPSHOTTING  ################################\n\n# Save the DB to disk.\n#\n# save <seconds> <changes> [<seconds> <changes> ...]\n#\n# Redis will save the DB if the given number of seconds elapsed and it\n# surpassed the given number of write operations against the DB.\n#\n# Snapshotting can be completely disabled with a single empty string argument\n# as in following example:\n#\n# save \"\"\n#\n# Unless specified otherwise, by default Redis will save the DB:\n#   * After 3600 seconds (an hour) if at least 1 change was performed\n#   * After 300 seconds (5 minutes) if at least 100 changes were performed\n#   * After 60 seconds if at least 10000 changes were performed\n#\n# You can set these explicitly by uncommenting the following line.\n#\n# save 3600 1 300 100 60 10000\n\n# By default Redis will stop accepting writes if RDB snapshots are enabled\n# (at least one save point) and the latest background save failed.\n# This will make the user aware (in a hard way) that data is not persisting\n# on disk properly, otherwise chances are that no one will notice and some\n# disaster will happen.\n#\n# If the background saving process will start working again Redis will\n# automatically allow writes again.\n#\n# However if you have setup your proper monitoring of the Redis server\n# and persistence, you may want to disable this feature so that Redis will\n# continue to work as usual even if there are problems with disk,\n# permissions, and so forth.\nstop-writes-on-bgsave-error yes\n\n# Compress string objects using LZF when dump .rdb databases?\n# By default compression is enabled as it's almost always a win.\n# If you want to save some CPU in the saving child set it to 'no' but\n# the dataset will likely be bigger if you have compressible values or keys.\nrdbcompression yes\n\n# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.\n# This makes the format more resistant to corruption but there is a performance\n# hit to pay (around 10%) when saving and loading RDB files, so you can disable it\n# for maximum performances.\n#\n# RDB files created with checksum disabled have a checksum of zero that will\n# tell the loading code to skip the check.\nrdbchecksum yes\n\n# Enables or disables full sanitization checks for ziplist and listpack etc when\n# loading an RDB or RESTORE payload. This reduces the chances of a assertion or\n# crash later on while processing commands.\n# Options:\n#   no         - Never perform full sanitization\n#   yes        - Always perform full sanitization\n#   clients    - Perform full sanitization only for user connections.\n#                Excludes: RDB files, RESTORE commands received from the master\n#                connection, and client connections which have the\n#                skip-sanitize-payload ACL flag.\n# The default should be 'clients' but since it currently affects cluster\n# resharding via MIGRATE, it is temporarily set to 'no' by default.\n#\n# sanitize-dump-payload no\n\n# The filename where to dump the DB\ndbfilename dump.rdb\n\n# Remove RDB files used by replication in instances without persistence\n# enabled. By default this option is disabled, however there are environments\n# where for regulations or other security concerns, RDB files persisted on\n# disk by masters in order to feed replicas, or stored on disk by replicas\n# in order to load them for the initial synchronization, should be deleted\n# ASAP. Note that this option ONLY WORKS in instances that have both AOF\n# and RDB persistence disabled, otherwise is completely ignored.\n#\n# An alternative (and sometimes better) way to obtain the same effect is\n# to use diskless replication on both master and replicas instances. However\n# in the case of replicas, diskless is not always an option.\nrdb-del-sync-files no\n\n# The working directory.\n#\n# The DB will be written inside this directory, with the filename specified\n# above using the 'dbfilename' configuration directive.\n#\n# The Append Only File will also be created inside this directory.\n#\n# Note that you must specify a directory here, not a file name.\ndir ./\n\n################################# REPLICATION #################################\n\n# Master-Replica replication. Use replicaof to make a Redis instance a copy of\n# another Redis server. A few things to understand ASAP about Redis replication.\n#\n#   +------------------+      +---------------+\n#   |      Master      | ---> |    Replica    |\n#   | (receive writes) |      |  (exact copy) |\n#   +------------------+      +---------------+\n#\n# 1) Redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of replicas.\n# 2) Redis replicas are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. You may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) Replication is automatic and does not need user intervention. After a\n#    network partition replicas automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# replicaof <masterip> <masterport>\n\n# If the master is password protected (using the \"requirepass\" configuration\n# directive below) it is possible to tell the replica to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the replica request.\n#\n# masterauth <master-password>\n#\n# However this is not enough if you are using Redis ACLs (for Redis version\n# 6 or greater), and the default user is not capable of running the PSYNC\n# command and/or other commands needed for replication. In this case it's\n# better to configure a special user to use with replication, and specify the\n# masteruser configuration as such:\n#\n# masteruser <username>\n#\n# When masteruser is specified, the replica will authenticate against its\n# master using the new AUTH form: AUTH <username> <password>.\n\n# When a replica loses its connection with the master, or when the replication\n# is still in progress, the replica can act in two different ways:\n#\n# 1) if replica-serve-stale-data is set to 'yes' (the default) the replica will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) If replica-serve-stale-data is set to 'no' the replica will reply with error\n#    \"MASTERDOWN Link with MASTER is down and replica-serve-stale-data is set to 'no'\"\n#    to all data access commands, excluding commands such as:\n#    INFO, REPLICAOF, AUTH, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE,\n#    UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST,\n#    HOST and LATENCY.\n#\nreplica-serve-stale-data yes\n\n# You can configure a replica instance to accept writes or not. Writing against\n# a replica instance may be useful to store some ephemeral data (because data\n# written on a replica will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# Since Redis 2.6 by default replicas are read-only.\n#\n# Note: read only replicas are not designed to be exposed to untrusted clients\n# on the internet. It's just a protection layer against misuse of the instance.\n# Still a read only replica exports by default all the administrative commands\n# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve\n# security of read only replicas using 'rename-command' to shadow all the\n# administrative / dangerous commands.\nreplica-read-only yes\n\n# Replication SYNC strategy: disk or socket.\n#\n# New replicas and reconnecting replicas that are not able to continue the\n# replication process just receiving differences, need to do what is called a\n# \"full synchronization\". An RDB file is transmitted from the master to the\n# replicas.\n#\n# The transmission can happen in two different ways:\n#\n# 1) Disk-backed: The Redis master creates a new process that writes the RDB\n#                 file on disk. Later the file is transferred by the parent\n#                 process to the replicas incrementally.\n# 2) Diskless: The Redis master creates a new process that directly writes the\n#              RDB file to replica sockets, without touching the disk at all.\n#\n# With disk-backed replication, while the RDB file is generated, more replicas\n# can be queued and served with the RDB file as soon as the current child\n# producing the RDB file finishes its work. With diskless replication instead\n# once the transfer starts, new replicas arriving will be queued and a new\n# transfer will start when the current one terminates.\n#\n# When diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple\n# replicas will arrive and the transfer can be parallelized.\n#\n# With slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync yes\n\n# When diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that transfers the RDB via socket\n# to the replicas.\n#\n# This is important since once the transfer starts, it is not possible to serve\n# new replicas arriving, that will be queued for the next RDB transfer, so the\n# server waits a delay in order to let more replicas arrive.\n#\n# The delay is specified in seconds, and by default is 5 seconds. To disable\n# it entirely just set it to 0 seconds and the transfer will start ASAP.\nrepl-diskless-sync-delay 5\n\n# When diskless replication is enabled with a delay, it is possible to let\n# the replication start before the maximum delay is reached if the maximum\n# number of replicas expected have connected. Default of 0 means that the\n# maximum is not defined and Redis will wait the full delay.\nrepl-diskless-sync-max-replicas 0\n\n# -----------------------------------------------------------------------------\n# WARNING: Since in this setup the replica does not immediately store an RDB on\n# disk, it may cause data loss during failovers. RDB diskless load + Redis\n# modules not handling I/O reads may cause Redis to abort in case of I/O errors\n# during the initial synchronization stage with the master.\n# -----------------------------------------------------------------------------\n#\n# Replica can load the RDB it reads from the replication link directly from the\n# socket, or store the RDB to a file and read that file after it was completely\n# received from the master.\n#\n# In many cases the disk is slower than the network, and storing and loading\n# the RDB file may increase replication time (and even increase the master's\n# Copy on Write memory and replica buffers).\n# However, when parsing the RDB file directly from the socket, in order to avoid\n# data loss it's only safe to flush the current dataset when the new dataset is\n# fully loaded in memory, resulting in higher memory usage.\n# For this reason we have the following options:\n#\n# \"disabled\"    - Don't use diskless load (store the rdb file to the disk first)\n# \"swapdb\"      - Keep current db contents in RAM while parsing the data directly\n#                 from the socket. Replicas in this mode can keep serving current\n#                 dataset while replication is in progress, except for cases where\n#                 they can't recognize master as having a data set from same\n#                 replication history.\n#                 Note that this requires sufficient memory, if you don't have it,\n#                 you risk an OOM kill.\n# \"on-empty-db\" - Use diskless load only when current dataset is empty. This is \n#                 safer and avoid having old and new dataset loaded side by side\n#                 during replication.\nrepl-diskless-load disabled\n\n# Master send PINGs to its replicas in a predefined interval. It's possible to\n# change this interval with the repl_ping_replica_period option. The default\n# value is 10 seconds.\n#\n# repl-ping-replica-period 10\n\n# The following option sets the replication timeout for:\n#\n# 1) Bulk transfer I/O during SYNC, from the point of view of replica.\n# 2) Master timeout from the point of view of replicas (data, pings).\n# 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).\n#\n# It is important to make sure that this value is greater than the value\n# specified for repl-ping-replica-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the replica. The default\n# value is 60 seconds.\n#\n# repl-timeout 60\n\n# Disable TCP_NODELAY on the replica socket after SYNC?\n#\n# If you select \"yes\" Redis will use a smaller number of TCP packets and\n# less bandwidth to send data to replicas. But this can add a delay for\n# the data to appear on the replica side, up to 40 milliseconds with\n# Linux kernels using a default configuration.\n#\n# If you select \"no\" the delay for data to appear on the replica side will\n# be reduced but more bandwidth will be used for replication.\n#\n# By default we optimize for low latency, but in very high traffic conditions\n# or when the master and replicas are many hops away, turning this to \"yes\" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# Set the replication backlog size. The backlog is a buffer that accumulates\n# replica data when replicas are disconnected for some time, so that when a\n# replica wants to reconnect again, often a full resync is not needed, but a\n# partial resync is enough, just passing the portion of data the replica\n# missed while disconnected.\n#\n# The bigger the replication backlog, the longer the replica can endure the\n# disconnect and later be able to perform a partial resynchronization.\n#\n# The backlog is only allocated if there is at least one replica connected.\n#\n# repl-backlog-size 1mb\n\n# After a master has no connected replicas for some time, the backlog will be\n# freed. The following option configures the amount of seconds that need to\n# elapse, starting from the time the last replica disconnected, for the backlog\n# buffer to be freed.\n#\n# Note that replicas never free the backlog for timeout, since they may be\n# promoted to masters later, and should be able to correctly \"partially\n# resynchronize\" with other replicas: hence they should always accumulate backlog.\n#\n# A value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# The replica priority is an integer number published by Redis in the INFO\n# output. It is used by Redis Sentinel in order to select a replica to promote\n# into a master if the master is no longer working correctly.\n#\n# A replica with a low priority number is considered better for promotion, so\n# for instance if there are three replicas with priority 10, 100, 25 Sentinel\n# will pick the one with priority 10, that is the lowest.\n#\n# However a special priority of 0 marks the replica as not able to perform the\n# role of master, so a replica with priority of 0 will never be selected by\n# Redis Sentinel for promotion.\n#\n# By default the priority is 100.\nreplica-priority 100\n\n# The propagation error behavior controls how Redis will behave when it is\n# unable to handle a command being processed in the replication stream from a master\n# or processed while reading from an AOF file. Errors that occur during propagation\n# are unexpected, and can cause data inconsistency. However, there are edge cases\n# in earlier versions of Redis where it was possible for the server to replicate or persist\n# commands that would fail on future versions. For this reason the default behavior\n# is to ignore such errors and continue processing commands.\n#\n# If an application wants to ensure there is no data divergence, this configuration\n# should be set to 'panic' instead. The value can also be set to 'panic-on-replicas'\n# to only panic when a replica encounters an error on the replication stream. One of\n# these two panic values will become the default value in the future once there are\n# sufficient safety mechanisms in place to prevent false positive crashes.\n#\n# propagation-error-behavior ignore\n\n# Replica ignore disk write errors controls the behavior of a replica when it is\n# unable to persist a write command received from its master to disk. By default,\n# this configuration is set to 'no' and will crash the replica in this condition.\n# It is not recommended to change this default, however in order to be compatible\n# with older versions of Redis this config can be toggled to 'yes' which will just\n# log a warning and execute the write command it got from the master.\n#\n# replica-ignore-disk-write-errors no\n\n# -----------------------------------------------------------------------------\n# By default, Redis Sentinel includes all replicas in its reports. A replica\n# can be excluded from Redis Sentinel's announcements. An unannounced replica\n# will be ignored by the 'sentinel replicas <master>' command and won't be\n# exposed to Redis Sentinel's clients.\n#\n# This option does not change the behavior of replica-priority. Even with\n# replica-announced set to 'no', the replica can be promoted to master. To\n# prevent this behavior, set replica-priority to 0.\n#\n# replica-announced yes\n\n# It is possible for a master to stop accepting writes if there are less than\n# N replicas connected, having a lag less or equal than M seconds.\n#\n# The N replicas need to be in \"online\" state.\n#\n# The lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the replica, that is usually sent every second.\n#\n# This option does not GUARANTEE that N replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough replicas\n# are available, to the specified number of seconds.\n#\n# For example to require at least 3 replicas with a lag <= 10 seconds use:\n#\n# min-replicas-to-write 3\n# min-replicas-max-lag 10\n#\n# Setting one or the other to 0 disables the feature.\n#\n# By default min-replicas-to-write is set to 0 (feature disabled) and\n# min-replicas-max-lag is set to 10.\n\n# A Redis master is able to list the address and port of the attached\n# replicas in different ways. For example the \"INFO replication\" section\n# offers this information, which is used, among other tools, by\n# Redis Sentinel in order to discover replica instances.\n# Another place where this info is available is in the output of the\n# \"ROLE\" command of a master.\n#\n# The listed IP address and port normally reported by a replica is\n# obtained in the following way:\n#\n#   IP: The address is auto detected by checking the peer address\n#   of the socket used by the replica to connect with the master.\n#\n#   Port: The port is communicated by the replica during the replication\n#   handshake, and is normally the port that the replica is using to\n#   listen for connections.\n#\n# However when port forwarding or Network Address Translation (NAT) is\n# used, the replica may actually be reachable via different IP and port\n# pairs. The following two options can be used by a replica in order to\n# report to its master a specific set of IP and port, so that both INFO\n# and ROLE will report those values.\n#\n# There is no need to use both the options if you need to override just\n# the port or the IP address.\n#\n# replica-announce-ip 5.5.5.5\n# replica-announce-port 1234\n\n############################### KEYS TRACKING #################################\n\n# Redis implements server assisted support for client side caching of values.\n# This is implemented using an invalidation table that remembers, using\n# a radix key indexed by key name, what clients have which keys. In turn\n# this is used in order to send invalidation messages to clients. Please\n# check this page to understand more about the feature:\n#\n#   https://redis.io/docs/latest/develop/use/client-side-caching/\n#\n# When tracking is enabled for a client, all the read only queries are assumed\n# to be cached: this will force Redis to store information in the invalidation\n# table. When keys are modified, such information is flushed away, and\n# invalidation messages are sent to the clients. However if the workload is\n# heavily dominated by reads, Redis could use more and more memory in order\n# to track the keys fetched by many clients.\n#\n# For this reason it is possible to configure a maximum fill value for the\n# invalidation table. By default it is set to 1M of keys, and once this limit\n# is reached, Redis will start to evict keys in the invalidation table\n# even if they were not modified, just to reclaim memory: this will in turn\n# force the clients to invalidate the cached values. Basically the table\n# maximum size is a trade off between the memory you want to spend server\n# side to track information about who cached what, and the ability of clients\n# to retain cached objects in memory.\n#\n# If you set the value to 0, it means there are no limits, and Redis will\n# retain as many keys as needed in the invalidation table.\n# In the \"stats\" INFO section, you can find information about the number of\n# keys in the invalidation table at every given moment.\n#\n# Note: when key tracking is used in broadcasting mode, no memory is used\n# in the server side so this setting is useless.\n#\n# tracking-table-max-keys 1000000\n\n################################## SECURITY ###################################\n\n# Warning: since Redis is pretty fast, an outside user can try up to\n# 1 million passwords per second against a modern box. This means that you\n# should use very strong passwords, otherwise they will be very easy to break.\n# Note that because the password is really a shared secret between the client\n# and the server, and should not be memorized by any human, the password\n# can be easily a long string from /dev/urandom or whatever, so by using a\n# long and unguessable password no brute force attack will be possible.\n\n# Redis ACL users are defined in the following format:\n#\n#   user <username> ... acl rules ...\n#\n# For example:\n#\n#   user worker +@list +@connection ~jobs:* on >ffa9203c493aa99\n#\n# The special username \"default\" is used for new connections. If this user\n# has the \"nopass\" rule, then new connections will be immediately authenticated\n# as the \"default\" user without the need of any password provided via the\n# AUTH command. Otherwise if the \"default\" user is not flagged with \"nopass\"\n# the connections will start in not authenticated state, and will require\n# AUTH (or the HELLO command AUTH option) in order to be authenticated and\n# start to work.\n#\n# The ACL rules that describe what a user can do are the following:\n#\n#  on           Enable the user: it is possible to authenticate as this user.\n#  off          Disable the user: it's no longer possible to authenticate\n#               with this user, however the already authenticated connections\n#               will still work.\n#  skip-sanitize-payload    RESTORE dump-payload sanitization is skipped.\n#  sanitize-payload         RESTORE dump-payload is sanitized (default).\n#  +<command>   Allow the execution of that command.\n#               May be used with `|` for allowing subcommands (e.g \"+config|get\")\n#  -<command>   Disallow the execution of that command.\n#               May be used with `|` for blocking subcommands (e.g \"-config|set\")\n#  +@<category> Allow the execution of all the commands in such category\n#               with valid categories are like @admin, @set, @sortedset, ...\n#               and so forth, see the full list in the server.c file where\n#               the Redis command table is described and defined.\n#               The special category @all means all the commands, but currently\n#               present in the server, and that will be loaded in the future\n#               via modules.\n#  +<command>|first-arg  Allow a specific first argument of an otherwise\n#                        disabled command. It is only supported on commands with\n#                        no sub-commands, and is not allowed as negative form\n#                        like -SELECT|1, only additive starting with \"+\". This\n#                        feature is deprecated and may be removed in the future.\n#  allcommands  Alias for +@all. Note that it implies the ability to execute\n#               all the future commands loaded via the modules system.\n#  nocommands   Alias for -@all.\n#  ~<pattern>   Add a pattern of keys that can be mentioned as part of\n#               commands. For instance ~* allows all the keys. The pattern\n#               is a glob-style pattern like the one of KEYS.\n#               It is possible to specify multiple patterns.\n# %R~<pattern>  Add key read pattern that specifies which keys can be read \n#               from.\n# %W~<pattern>  Add key write pattern that specifies which keys can be\n#               written to. \n#  allkeys      Alias for ~*\n#  resetkeys    Flush the list of allowed keys patterns.\n#  &<pattern>   Add a glob-style pattern of Pub/Sub channels that can be\n#               accessed by the user. It is possible to specify multiple channel\n#               patterns.\n#  allchannels  Alias for &*\n#  resetchannels            Flush the list of allowed channel patterns.\n#  ><password>  Add this password to the list of valid password for the user.\n#               For example >mypass will add \"mypass\" to the list.\n#               This directive clears the \"nopass\" flag (see later).\n#  <<password>  Remove this password from the list of valid passwords.\n#  nopass       All the set passwords of the user are removed, and the user\n#               is flagged as requiring no password: it means that every\n#               password will work against this user. If this directive is\n#               used for the default user, every new connection will be\n#               immediately authenticated with the default user without\n#               any explicit AUTH command required. Note that the \"resetpass\"\n#               directive will clear this condition.\n#  resetpass    Flush the list of allowed passwords. Moreover removes the\n#               \"nopass\" status. After \"resetpass\" the user has no associated\n#               passwords and there is no way to authenticate without adding\n#               some password (or setting it as \"nopass\" later).\n#  reset        Performs the following actions: resetpass, resetkeys, resetchannels,\n#               allchannels (if acl-pubsub-default is set), off, clearselectors, -@all.\n#               The user returns to the same state it has immediately after its creation.\n# (<options>)   Create a new selector with the options specified within the\n#               parentheses and attach it to the user. Each option should be \n#               space separated. The first character must be ( and the last \n#               character must be ).\n# clearselectors            Remove all of the currently attached selectors. \n#                           Note this does not change the \"root\" user permissions,\n#                           which are the permissions directly applied onto the\n#                           user (outside the parentheses).\n#\n# ACL rules can be specified in any order: for instance you can start with\n# passwords, then flags, or key patterns. However note that the additive\n# and subtractive rules will CHANGE MEANING depending on the ordering.\n# For instance see the following example:\n#\n#   user alice on +@all -DEBUG ~* >somepassword\n#\n# This will allow \"alice\" to use all the commands with the exception of the\n# DEBUG command, since +@all added all the commands to the set of the commands\n# alice can use, and later DEBUG was removed. However if we invert the order\n# of two ACL rules the result will be different:\n#\n#   user alice on -DEBUG +@all ~* >somepassword\n#\n# Now DEBUG was removed when alice had yet no commands in the set of allowed\n# commands, later all the commands are added, so the user will be able to\n# execute everything.\n#\n# Basically ACL rules are processed left-to-right.\n#\n# The following is a list of command categories and their meanings:\n# * keyspace - Writing or reading from keys, databases, or their metadata \n#     in a type agnostic way. Includes DEL, RESTORE, DUMP, RENAME, EXISTS, DBSIZE,\n#     KEYS, EXPIRE, TTL, FLUSHALL, etc. Commands that may modify the keyspace,\n#     key or metadata will also have `write` category. Commands that only read\n#     the keyspace, key or metadata will have the `read` category.\n# * read - Reading from keys (values or metadata). Note that commands that don't\n#     interact with keys, will not have either `read` or `write`.\n# * write - Writing to keys (values or metadata)\n# * admin - Administrative commands. Normal applications will never need to use\n#     these. Includes REPLICAOF, CONFIG, DEBUG, SAVE, MONITOR, ACL, SHUTDOWN, etc.\n# * dangerous - Potentially dangerous (each should be considered with care for\n#     various reasons). This includes FLUSHALL, MIGRATE, RESTORE, SORT, KEYS,\n#     CLIENT, DEBUG, INFO, CONFIG, SAVE, REPLICAOF, etc.\n# * connection - Commands affecting the connection or other connections.\n#     This includes AUTH, SELECT, COMMAND, CLIENT, ECHO, PING, etc.\n# * blocking - Potentially blocking the connection until released by another\n#     command.\n# * fast - Fast O(1) commands. May loop on the number of arguments, but not the\n#     number of elements in the key.\n# * slow - All commands that are not Fast.\n# * pubsub - PUBLISH / SUBSCRIBE related\n# * transaction - WATCH / MULTI / EXEC related commands.\n# * scripting - Scripting related.\n# * set - Data type: sets related.\n# * sortedset - Data type: zsets related.\n# * list - Data type: lists related.\n# * hash - Data type: hashes related.\n# * string - Data type: strings related.\n# * bitmap - Data type: bitmaps related.\n# * hyperloglog - Data type: hyperloglog related.\n# * geo - Data type: geo related.\n# * stream - Data type: streams related.\n#\n# For more information about ACL configuration please refer to\n# the Redis web site at https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/\n\n# ACL LOG\n#\n# The ACL Log tracks failed commands and authentication events associated\n# with ACLs. The ACL Log is useful to troubleshoot failed commands blocked\n# by ACLs. The ACL Log is stored in memory. You can reclaim memory with\n# ACL LOG RESET. Define the maximum entry length of the ACL Log below.\nacllog-max-len 128\n\n# Using an external ACL file\n#\n# Instead of configuring users here in this file, it is possible to use\n# a stand-alone file just listing users. The two methods cannot be mixed:\n# if you configure users here and at the same time you activate the external\n# ACL file, the server will refuse to start.\n#\n# The format of the external ACL user file is exactly the same as the\n# format that is used inside redis.conf to describe users.\n#\n# aclfile /etc/redis/users.acl\n\n# IMPORTANT NOTE: starting with Redis 6 \"requirepass\" is just a compatibility\n# layer on top of the new ACL system. The option effect will be just setting\n# the password for the default user. Clients will still authenticate using\n# AUTH <password> as usually, or more explicitly with AUTH default <password>\n# if they follow the new protocol: both will work.\n#\n# The requirepass is not compatible with aclfile option and the ACL LOAD\n# command, these will cause requirepass to be ignored.\n#\n# requirepass foobared\n\n# New users are initialized with restrictive permissions by default, via the\n# equivalent of this ACL rule 'off resetkeys -@all'. Starting with Redis 6.2, it\n# is possible to manage access to Pub/Sub channels with ACL rules as well. The\n# default Pub/Sub channels permission if new users is controlled by the\n# acl-pubsub-default configuration directive, which accepts one of these values:\n#\n# allchannels: grants access to all Pub/Sub channels\n# resetchannels: revokes access to all Pub/Sub channels\n#\n# From Redis 7.0, acl-pubsub-default defaults to 'resetchannels' permission.\n#\n# acl-pubsub-default resetchannels\n\n# Command renaming (DEPRECATED).\n#\n# ------------------------------------------------------------------------\n# WARNING: avoid using this option if possible. Instead use ACLs to remove\n# commands from the default user, and put them only in some admin user you\n# create for administrative purposes.\n# ------------------------------------------------------------------------\n#\n# It is possible to change the name of dangerous commands in a shared\n# environment. For instance the CONFIG command may be renamed into something\n# hard to guess so that it will still be available for internal-use tools\n# but not available for general clients.\n#\n# Example:\n#\n# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n#\n# It is also possible to completely kill a command by renaming it into\n# an empty string:\n#\n# rename-command CONFIG \"\"\n#\n# Please note that changing the name of commands that are logged into the\n# AOF file or transmitted to replicas may cause problems.\n\n################################### CLIENTS ####################################\n\n# Set the max number of connected clients at the same time. By default\n# this limit is set to 10000 clients, however if the Redis server is not\n# able to configure the process file limit to allow for the specified limit\n# the max number of allowed clients is set to the current file limit\n# minus 32 (as Redis reserves a few file descriptors for internal uses).\n#\n# Once the limit is reached Redis will close all the new connections sending\n# an error 'max number of clients reached'.\n#\n# IMPORTANT: When Redis Cluster is used, the max number of connections is also\n# shared with the cluster bus: every node in the cluster will use two\n# connections, one incoming and another outgoing. It is important to size the\n# limit accordingly in case of very large clusters.\n#\n# maxclients 10000\n\n############################## MEMORY MANAGEMENT ################################\n\n# Set a memory usage limit to the specified amount of bytes.\n# When the memory limit is reached Redis will try to remove keys\n# according to the eviction policy selected (see maxmemory-policy).\n#\n# If Redis can't remove keys according to the policy, or if the policy is\n# set to 'noeviction', Redis will start to reply with errors to commands\n# that would use more memory, like SET, LPUSH, and so on, and will continue\n# to reply to read-only commands like GET.\n#\n# This option is usually useful when using Redis as an LRU or LFU cache, or to\n# set a hard memory limit for an instance (using the 'noeviction' policy).\n#\n# WARNING: If you have replicas attached to an instance with maxmemory on,\n# the size of the output buffers needed to feed the replicas are subtracted\n# from the used memory count, so that network problems / resyncs will\n# not trigger a loop where keys are evicted, and in turn the output\n# buffer of replicas is full with DELs of keys evicted triggering the deletion\n# of more keys, and so forth until the database is completely emptied.\n#\n# In short... if you have replicas attached it is suggested that you set a lower\n# limit for maxmemory so that there is some free RAM on the system for replica\n# output buffers (but this is not needed if the policy is 'noeviction').\n#\n# maxmemory <bytes>\n\n# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory\n# is reached. You can select one from the following behaviors:\n#\n# volatile-lru -> Evict using approximated LRU, only keys with an expire set.\n# allkeys-lru -> Evict any key using approximated LRU.\n# volatile-lfu -> Evict using approximated LFU, only keys with an expire set.\n# allkeys-lfu -> Evict any key using approximated LFU.\n# volatile-random -> Remove a random key having an expire set.\n# allkeys-random -> Remove a random key, any key.\n# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)\n# noeviction -> Don't evict anything, just return an error on write operations.\n#\n# LRU means Least Recently Used\n# LFU means Least Frequently Used\n#\n# Both LRU, LFU and volatile-ttl are implemented using approximated\n# randomized algorithms.\n#\n# Note: with any of the above policies, when there are no suitable keys for\n# eviction, Redis will return an error on write operations that require\n# more memory. These are usually commands that create new keys, add data or\n# modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE,\n# SORT (due to the STORE argument), and EXEC (if the transaction includes any\n# command that requires memory).\n#\n# The default is:\n#\n# maxmemory-policy noeviction\n\n# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated\n# algorithms (in order to save memory), so you can tune it for speed or\n# accuracy. By default Redis will check five keys and pick the one that was\n# used least recently, you can change the sample size using the following\n# configuration directive.\n#\n# The default of 5 produces good enough results. 10 Approximates very closely\n# true LRU but costs more CPU. 3 is faster but not very accurate. The maximum\n# value that can be set is 64.\n#\n# maxmemory-samples 5\n\n# Eviction processing is designed to function well with the default setting.\n# If there is an unusually large amount of write traffic, this value may need to\n# be increased.  Decreasing this value may reduce latency at the risk of\n# eviction processing effectiveness\n#   0 = minimum latency, 10 = default, 100 = process without regard to latency\n#\n# maxmemory-eviction-tenacity 10\n\n# Starting from Redis 5, by default a replica will ignore its maxmemory setting\n# (unless it is promoted to master after a failover or manually). It means\n# that the eviction of keys will be just handled by the master, sending the\n# DEL commands to the replica as keys evict in the master side.\n#\n# This behavior ensures that masters and replicas stay consistent, and is usually\n# what you want, however if your replica is writable, or you want the replica\n# to have a different memory setting, and you are sure all the writes performed\n# to the replica are idempotent, then you may change this default (but be sure\n# to understand what you are doing).\n#\n# Note that since the replica by default does not evict, it may end using more\n# memory than the one set via maxmemory (there are certain buffers that may\n# be larger on the replica, or data structures may sometimes take more memory\n# and so forth). So make sure you monitor your replicas and make sure they\n# have enough memory to never hit a real out-of-memory condition before the\n# master hits the configured maxmemory setting.\n#\n# replica-ignore-maxmemory yes\n\n# Redis reclaims expired keys in two ways: upon access when those keys are\n# found to be expired, and also in background, in what is called the\n# \"active expire key\". The key space is slowly and interactively scanned\n# looking for expired keys to reclaim, so that it is possible to free memory\n# of keys that are expired and will never be accessed again in a short time.\n#\n# The default effort of the expire cycle will try to avoid having more than\n# ten percent of expired keys still in memory, and will try to avoid consuming\n# more than 25% of total memory and to add latency to the system. However\n# it is possible to increase the expire \"effort\" that is normally set to\n# \"1\", to a greater value, up to the value \"10\". At its maximum value the\n# system will use more CPU, longer cycles (and technically may introduce\n# more latency), and will tolerate less already expired keys still present\n# in the system. It's a tradeoff between memory, CPU and latency.\n#\n# active-expire-effort 1\n\n############################# LAZY FREEING ####################################\n\n# Redis has two primitives to delete keys. One is called DEL and is a blocking\n# deletion of the object. It means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. If the key deleted is associated with a small object, the time needed\n# in order to execute the DEL command is very small and comparable to most other\n# O(1) or O(log_N) commands in Redis. However if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# For the above reasons Redis also offers non blocking deletion primitives\n# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and\n# FLUSHDB commands, in order to reclaim memory in background. Those commands\n# are executed in constant time. Another thread will incrementally free the\n# object in the background as fast as possible.\n#\n# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.\n# It's up to the design of the application to understand when it is a good\n# idea to use one or the other. However the Redis server sometimes has to\n# delete keys or flush the whole database as a side effect of other operations.\n# Specifically Redis deletes objects independently of a user call in the\n# following scenarios:\n#\n# 1) On eviction, because of the maxmemory and maxmemory policy configurations,\n#    in order to make room for new data, without going over the specified\n#    memory limit.\n# 2) Because of expire: when a key with an associated time to live (see the\n#    EXPIRE command) must be deleted from memory.\n# 3) Because of a side effect of a command that stores data on a key that may\n#    already exist. For example the RENAME command may delete the old key\n#    content when it is replaced with another one. Similarly SUNIONSTORE\n#    or SORT with STORE option may delete existing keys. The SET command\n#    itself removes any old content of the specified key in order to replace\n#    it with the specified string.\n# 4) During replication, when a replica performs a full resynchronization with\n#    its master, the content of the whole database is removed in order to\n#    load the RDB file just transferred.\n#\n# In all the above cases the default is to delete objects in a blocking way,\n# like if DEL was called. However you can configure each case specifically\n# in order to instead release memory in a non-blocking way like if UNLINK\n# was called, using the following configuration directives.\n\nlazyfree-lazy-eviction no\nlazyfree-lazy-expire no\nlazyfree-lazy-server-del no\nreplica-lazy-flush no\n\n# It is also possible, for the case when to replace the user code DEL calls\n# with UNLINK calls is not easy, to modify the default behavior of the DEL\n# command to act exactly like UNLINK, using the following configuration\n# directive:\n\nlazyfree-lazy-user-del no\n\n# FLUSHDB, FLUSHALL, SCRIPT FLUSH and FUNCTION FLUSH support both asynchronous and synchronous\n# deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the\n# commands. When neither flag is passed, this directive will be used to determine\n# if the data should be deleted asynchronously.\n\nlazyfree-lazy-user-flush no\n\n################################ THREADED I/O #################################\n\n# Redis is mostly single threaded, however there are certain threaded\n# operations such as UNLINK, slow I/O accesses and other things that are\n# performed on side threads.\n#\n# Now it is also possible to handle Redis clients socket reads and writes\n# in different I/O threads. Since especially writing is so slow, normally\n# Redis users use pipelining in order to speed up the Redis performances per\n# core, and spawn multiple instances in order to scale more. Using I/O\n# threads it is possible to easily speedup several times Redis without resorting\n# to pipelining nor sharding of the instance.\n#\n# By default threading is disabled, we suggest enabling it only in machines\n# that have at least 4 or more cores, leaving at least one spare core.\n# We also recommend using threaded I/O only if you actually have performance\n# problems, with Redis instances being able to use a quite big percentage of\n# CPU time, otherwise there is no point in using this feature.\n#\n# So for instance if you have a four cores boxes, try to use 3 I/O\n# threads, if you have a 8 cores, try to use 7 threads. In order to\n# enable I/O threads use the following configuration directive:\n#\n# io-threads 4\n#\n# Setting io-threads to 1 will just use the main thread as usual.\n# When I/O threads are enabled, we not only use threads for writes, that\n# is to thread the write(2) syscall and transfer the client buffers to the\n# socket, but also use threads for reads and protocol parsing.\n#\n# NOTE: If you want to test the Redis speedup using redis-benchmark, make\n# sure you also run the benchmark itself in threaded mode, using the\n# --threads option to match the number of Redis threads, otherwise you'll not\n# be able to notice the improvements.\n\n############################ KERNEL OOM CONTROL ##############################\n\n# On Linux, it is possible to hint the kernel OOM killer on what processes\n# should be killed first when out of memory.\n#\n# Enabling this feature makes Redis actively control the oom_score_adj value\n# for all its processes, depending on their role. The default scores will\n# attempt to have background child processes killed before all others, and\n# replicas killed before masters.\n#\n# Redis supports these options:\n#\n# no:       Don't make changes to oom-score-adj (default).\n# yes:      Alias to \"relative\" see below.\n# absolute: Values in oom-score-adj-values are written as is to the kernel.\n# relative: Values are used relative to the initial value of oom_score_adj when\n#           the server starts and are then clamped to a range of -1000 to 1000.\n#           Because typically the initial value is 0, they will often match the\n#           absolute values.\noom-score-adj no\n\n# When oom-score-adj is used, this directive controls the specific values used\n# for master, replica and background child processes. Values range -2000 to\n# 2000 (higher means more likely to be killed).\n#\n# Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities)\n# can freely increase their value, but not decrease it below its initial\n# settings. This means that setting oom-score-adj to \"relative\" and setting the\n# oom-score-adj-values to positive values will always succeed.\noom-score-adj-values 0 200 800\n\n\n#################### KERNEL transparent hugepage CONTROL ######################\n\n# Usually the kernel Transparent Huge Pages control is set to \"madvise\" or\n# \"never\" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which\n# case this config has no effect. On systems in which it is set to \"always\",\n# redis will attempt to disable it specifically for the redis process in order\n# to avoid latency problems specifically with fork(2) and CoW.\n# If for some reason you prefer to keep it enabled, you can set this config to\n# \"no\" and the kernel global to \"always\".\n\ndisable-thp yes\n\n############################## APPEND ONLY MODE ###############################\n\n# By default Redis asynchronously dumps the dataset on disk. This mode is\n# good enough in many applications, but an issue with the Redis process or\n# a power outage may result into a few minutes of writes lost (depending on\n# the configured save points).\n#\n# The Append Only File is an alternative persistence mode that provides\n# much better durability. For instance using the default data fsync policy\n# (see later in the config file) Redis can lose just one second of writes in a\n# dramatic event like a server power outage, or a single write if something\n# wrong with the Redis process itself happens, but the operating system is\n# still running correctly.\n#\n# AOF and RDB persistence can be enabled at the same time without problems.\n# If the AOF is enabled on startup Redis will load the AOF, that is the file\n# with the better durability guarantees.\n#\n# Note that changing this value in a config file of an existing database and\n# restarting the server can lead to data loss. A conversion needs to be done\n# by setting it via CONFIG command on a live server first.\n#\n# Please check https://redis.io/docs/latest/operate/oss_and_stack/management/persistence/ for more information.\n\nappendonly no\n\n# The base name of the append only file.\n#\n# Redis 7 and newer use a set of append-only files to persist the dataset\n# and changes applied to it. There are two basic types of files in use:\n#\n# - Base files, which are a snapshot representing the complete state of the\n#   dataset at the time the file was created. Base files can be either in\n#   the form of RDB (binary serialized) or AOF (textual commands).\n# - Incremental files, which contain additional commands that were applied\n#   to the dataset following the previous file.\n#\n# In addition, manifest files are used to track the files and the order in\n# which they were created and should be applied.\n#\n# Append-only file names are created by Redis following a specific pattern.\n# The file name's prefix is based on the 'appendfilename' configuration\n# parameter, followed by additional information about the sequence and type.\n#\n# For example, if appendfilename is set to appendonly.aof, the following file\n# names could be derived:\n#\n# - appendonly.aof.1.base.rdb as a base file.\n# - appendonly.aof.1.incr.aof, appendonly.aof.2.incr.aof as incremental files.\n# - appendonly.aof.manifest as a manifest file.\n\nappendfilename \"appendonly.aof\"\n\n# For convenience, Redis stores all persistent append-only files in a dedicated\n# directory. The name of the directory is determined by the appenddirname\n# configuration parameter.\n\nappenddirname \"appendonlydir\"\n\n# The fsync() call tells the Operating System to actually write data on disk\n# instead of waiting for more data in the output buffer. Some OS will really flush\n# data on disk, some other OS will just try to do it ASAP.\n#\n# Redis supports three different modes:\n#\n# no: don't fsync, just let the OS flush the data when it wants. Faster.\n# always: fsync after every write to the append only log. Slow, Safest.\n# everysec: fsync only one time every second. Compromise.\n#\n# The default is \"everysec\", as that's usually the right compromise between\n# speed and data safety. It's up to you to understand if you can relax this to\n# \"no\" that will let the operating system flush the output buffer when\n# it wants, for better performances (but if you can live with the idea of\n# some data loss consider the default persistence mode that's snapshotting),\n# or on the contrary, use \"always\" that's very slow but a bit safer than\n# everysec.\n#\n# More details please check the following article:\n# http://antirez.com/post/redis-persistence-demystified.html\n#\n# If unsure, use \"everysec\".\n\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# When the AOF fsync policy is set to always or everysec, and a background\n# saving process (a background save or AOF log background rewriting) is\n# performing a lot of I/O against the disk, in some Linux configurations\n# Redis may block too long on the fsync() call. Note that there is no fix for\n# this currently, as even performing fsync in a different thread will block\n# our synchronous write(2) call.\n#\n# In order to mitigate this problem it's possible to use the following option\n# that will prevent fsync() from being called in the main process while a\n# BGSAVE or BGREWRITEAOF is in progress.\n#\n# This means that while another child is saving, the durability of Redis is\n# the same as \"appendfsync no\". In practical terms, this means that it is\n# possible to lose up to 30 seconds of log in the worst scenario (with the\n# default Linux settings).\n#\n# If you have latency problems turn this to \"yes\". Otherwise leave it as\n# \"no\" that is the safest pick from the point of view of durability.\n\nno-appendfsync-on-rewrite no\n\n# Automatic rewrite of the append only file.\n# Redis is able to automatically rewrite the log file implicitly calling\n# BGREWRITEAOF when the AOF log size grows by the specified percentage.\n#\n# This is how it works: Redis remembers the size of the AOF file after the\n# latest rewrite (if no rewrite has happened since the restart, the size of\n# the AOF at startup is used).\n#\n# This base size is compared to the current size. If the current size is\n# bigger than the specified percentage, the rewrite is triggered. Also\n# you need to specify a minimal size for the AOF file to be rewritten, this\n# is useful to avoid rewriting the AOF file even if the percentage increase\n# is reached but it is still pretty small.\n#\n# Specify a percentage of zero in order to disable the automatic AOF\n# rewrite feature.\n\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# An AOF file may be found to be truncated at the end during the Redis\n# startup process, when the AOF data gets loaded back into memory.\n# This may happen when the system where Redis is running\n# crashes, especially when an ext4 filesystem is mounted without the\n# data=ordered option (however this can't happen when Redis itself\n# crashes or aborts but the operating system still works correctly).\n#\n# Redis can either exit with an error when this happens, or load as much\n# data as possible (the default now) and start if the AOF file is found\n# to be truncated at the end. The following option controls this behavior.\n#\n# If aof-load-truncated is set to yes, a truncated AOF file is loaded and\n# the Redis server starts emitting a log to inform the user of the event.\n# Otherwise if the option is set to no, the server aborts with an error\n# and refuses to start. When the option is set to no, the user requires\n# to fix the AOF file using the \"redis-check-aof\" utility before to restart\n# the server.\n#\n# Note that if the AOF file will be found to be corrupted in the middle\n# the server will still exit with an error. This option only applies when\n# Redis will try to read more data from the AOF file but not enough bytes\n# will be found.\naof-load-truncated yes\n\n# Redis can create append-only base files in either RDB or AOF formats. Using\n# the RDB format is always faster and more efficient, and disabling it is only\n# supported for backward compatibility purposes.\naof-use-rdb-preamble yes\n\n# Redis supports recording timestamp annotations in the AOF to support restoring\n# the data from a specific point-in-time. However, using this capability changes\n# the AOF format in a way that may not be compatible with existing AOF parsers.\naof-timestamp-enabled no\n\n################################ SHUTDOWN #####################################\n\n# Maximum time to wait for replicas when shutting down, in seconds.\n#\n# During shut down, a grace period allows any lagging replicas to catch up with\n# the latest replication offset before the master exists. This period can\n# prevent data loss, especially for deployments without configured disk backups.\n#\n# The 'shutdown-timeout' value is the grace period's duration in seconds. It is\n# only applicable when the instance has replicas. To disable the feature, set\n# the value to 0.\n#\n# shutdown-timeout 10\n\n# When Redis receives a SIGINT or SIGTERM, shutdown is initiated and by default\n# an RDB snapshot is written to disk in a blocking operation if save points are configured.\n# The options used on signaled shutdown can include the following values:\n# default:  Saves RDB snapshot only if save points are configured.\n#           Waits for lagging replicas to catch up.\n# save:     Forces a DB saving operation even if no save points are configured.\n# nosave:   Prevents DB saving operation even if one or more save points are configured.\n# now:      Skips waiting for lagging replicas.\n# force:    Ignores any errors that would normally prevent the server from exiting.\n#\n# Any combination of values is allowed as long as \"save\" and \"nosave\" are not set simultaneously.\n# Example: \"nosave force now\"\n#\n# shutdown-on-sigint default\n# shutdown-on-sigterm default\n\n################ NON-DETERMINISTIC LONG BLOCKING COMMANDS #####################\n\n# Maximum time in milliseconds for EVAL scripts, functions and in some cases\n# modules' commands before Redis can start processing or rejecting other clients.\n#\n# If the maximum execution time is reached Redis will start to reply to most\n# commands with a BUSY error.\n#\n# In this state Redis will only allow a handful of commands to be executed.\n# For instance, SCRIPT KILL, FUNCTION KILL, SHUTDOWN NOSAVE and possibly some\n# module specific 'allow-busy' commands.\n#\n# SCRIPT KILL and FUNCTION KILL will only be able to stop a script that did not\n# yet call any write commands, so SHUTDOWN NOSAVE may be the only way to stop\n# the server in the case a write command was already issued by the script when\n# the user doesn't want to wait for the natural termination of the script.\n#\n# The default is 5 seconds. It is possible to set it to 0 or a negative value\n# to disable this mechanism (uninterrupted execution). Note that in the past\n# this config had a different name, which is now an alias, so both of these do\n# the same:\n# lua-time-limit 5000\n# busy-reply-threshold 5000\n\n################################ REDIS CLUSTER  ###############################\n\n# Normal Redis instances can't be part of a Redis Cluster; only nodes that are\n# started as cluster nodes can. In order to start a Redis instance as a\n# cluster node enable the cluster support uncommenting the following:\n#\n# cluster-enabled yes\n\n# Every cluster node has a cluster configuration file. This file is not\n# intended to be edited by hand. It is created and updated by Redis nodes.\n# Every Redis Cluster node requires a different cluster configuration file.\n# Make sure that instances running in the same system do not have\n# overlapping cluster configuration file names.\n#\n# cluster-config-file nodes-6379.conf\n\n# Cluster node timeout is the amount of milliseconds a node must be unreachable\n# for it to be considered in failure state.\n# Most other internal time limits are a multiple of the node timeout.\n#\n# cluster-node-timeout 15000\n\n# The cluster port is the port that the cluster bus will listen for inbound connections on. When set \n# to the default value, 0, it will be bound to the command port + 10000. Setting this value requires \n# you to specify the cluster bus port when executing cluster meet.\n# cluster-port 0\n\n# A replica of a failing master will avoid to start a failover if its data\n# looks too old.\n#\n# There is no simple way for a replica to actually have an exact measure of\n# its \"data age\", so the following two checks are performed:\n#\n# 1) If there are multiple replicas able to failover, they exchange messages\n#    in order to try to give an advantage to the replica with the best\n#    replication offset (more data from the master processed).\n#    Replicas will try to get their rank by offset, and apply to the start\n#    of the failover a delay proportional to their rank.\n#\n# 2) Every single replica computes the time of the last interaction with\n#    its master. This can be the last ping or command received (if the master\n#    is still in the \"connected\" state), or the time that elapsed since the\n#    disconnection with the master (if the replication link is currently down).\n#    If the last interaction is too old, the replica will not try to failover\n#    at all.\n#\n# The point \"2\" can be tuned by user. Specifically a replica will not perform\n# the failover if, since the last interaction with the master, the time\n# elapsed is greater than:\n#\n#   (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period\n#\n# So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor\n# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the\n# replica will not try to failover if it was not able to talk with the master\n# for longer than 310 seconds.\n#\n# A large cluster-replica-validity-factor may allow replicas with too old data to failover\n# a master, while a too small value may prevent the cluster from being able to\n# elect a replica at all.\n#\n# For maximum availability, it is possible to set the cluster-replica-validity-factor\n# to a value of 0, which means, that replicas will always try to failover the\n# master regardless of the last time they interacted with the master.\n# (However they'll always try to apply a delay proportional to their\n# offset rank).\n#\n# Zero is the only value able to guarantee that when all the partitions heal\n# the cluster will always be able to continue.\n#\n# cluster-replica-validity-factor 10\n\n# Cluster replicas are able to migrate to orphaned masters, that are masters\n# that are left without working replicas. This improves the cluster ability\n# to resist to failures as otherwise an orphaned master can't be failed over\n# in case of failure if it has no working replicas.\n#\n# Replicas migrate to orphaned masters only if there are still at least a\n# given number of other working replicas for their old master. This number\n# is the \"migration barrier\". A migration barrier of 1 means that a replica\n# will migrate only if there is at least 1 other working replica for its master\n# and so forth. It usually reflects the number of replicas you want for every\n# master in your cluster.\n#\n# Default is 1 (replicas migrate only if their masters remain with at least\n# one replica). To disable migration just set it to a very large value or\n# set cluster-allow-replica-migration to 'no'.\n# A value of 0 can be set but is useful only for debugging and dangerous\n# in production.\n#\n# cluster-migration-barrier 1\n\n# Turning off this option allows to use less automatic cluster configuration.\n# It both disables migration to orphaned masters and migration from masters\n# that became empty.\n#\n# Default is 'yes' (allow automatic migrations).\n#\n# cluster-allow-replica-migration yes\n\n# By default Redis Cluster nodes stop accepting queries if they detect there\n# is at least a hash slot uncovered (no available node is serving it).\n# This way if the cluster is partially down (for example a range of hash slots\n# are no longer covered) all the cluster becomes, eventually, unavailable.\n# It automatically returns available as soon as all the slots are covered again.\n#\n# However sometimes you want the subset of the cluster which is working,\n# to continue to accept queries for the part of the key space that is still\n# covered. In order to do so, just set the cluster-require-full-coverage\n# option to no.\n#\n# cluster-require-full-coverage yes\n\n# This option, when set to yes, prevents replicas from trying to failover its\n# master during master failures. However the replica can still perform a\n# manual failover, if forced to do so.\n#\n# This is useful in different scenarios, especially in the case of multiple\n# data center operations, where we want one side to never be promoted if not\n# in the case of a total DC failure.\n#\n# cluster-replica-no-failover no\n\n# This option, when set to yes, allows nodes to serve read traffic while the\n# cluster is in a down state, as long as it believes it owns the slots.\n#\n# This is useful for two cases.  The first case is for when an application\n# doesn't require consistency of data during node failures or network partitions.\n# One example of this is a cache, where as long as the node has the data it\n# should be able to serve it.\n#\n# The second use case is for configurations that don't meet the recommended\n# three shards but want to enable cluster mode and scale later. A\n# master outage in a 1 or 2 shard configuration causes a read/write outage to the\n# entire cluster without this option set, with it set there is only a write outage.\n# Without a quorum of masters, slot ownership will not change automatically.\n#\n# cluster-allow-reads-when-down no\n\n# This option, when set to yes, allows nodes to serve pubsub shard traffic while\n# the cluster is in a down state, as long as it believes it owns the slots.\n#\n# This is useful if the application would like to use the pubsub feature even when\n# the cluster global stable state is not OK. If the application wants to make sure only\n# one shard is serving a given channel, this feature should be kept as yes.\n#\n# cluster-allow-pubsubshard-when-down yes\n\n# Cluster link send buffer limit is the limit on the memory usage of an individual\n# cluster bus link's send buffer in bytes. Cluster links would be freed if they exceed\n# this limit. This is to primarily prevent send buffers from growing unbounded on links\n# toward slow peers (E.g. PubSub messages being piled up).\n# This limit is disabled by default. Enable this limit when 'mem_cluster_links' INFO field\n# and/or 'send-buffer-allocated' entries in the 'CLUSTER LINKS` command output continuously increase.\n# Minimum limit of 1gb is recommended so that cluster link buffer can fit in at least a single\n# PubSub message by default. (client-query-buffer-limit default value is 1gb)\n#\n# cluster-link-sendbuf-limit 0\n \n# Clusters can configure their announced hostname using this config. This is a common use case for \n# applications that need to use TLS Server Name Indication (SNI) or dealing with DNS based\n# routing. By default this value is only shown as additional metadata in the CLUSTER SLOTS\n# command, but can be changed using 'cluster-preferred-endpoint-type' config. This value is \n# communicated along the clusterbus to all nodes, setting it to an empty string will remove \n# the hostname and also propagate the removal.\n#\n# cluster-announce-hostname \"\"\n\n# Clusters can configure an optional nodename to be used in addition to the node ID for\n# debugging and admin information. This name is broadcasted between nodes, so will be used\n# in addition to the node ID when reporting cross node events such as node failures.\n# cluster-announce-human-nodename \"\"\n\n# Clusters can advertise how clients should connect to them using either their IP address,\n# a user defined hostname, or by declaring they have no endpoint. Which endpoint is\n# shown as the preferred endpoint is set by using the cluster-preferred-endpoint-type\n# config with values 'ip', 'hostname', or 'unknown-endpoint'. This value controls how\n# the endpoint returned for MOVED/ASKING requests as well as the first field of CLUSTER SLOTS. \n# If the preferred endpoint type is set to hostname, but no announced hostname is set, a '?' \n# will be returned instead.\n#\n# When a cluster advertises itself as having an unknown endpoint, it's indicating that\n# the server doesn't know how clients can reach the cluster. This can happen in certain \n# networking situations where there are multiple possible routes to the node, and the \n# server doesn't know which one the client took. In this case, the server is expecting\n# the client to reach out on the same endpoint it used for making the last request, but use\n# the port provided in the response.\n#\n# cluster-preferred-endpoint-type ip\n\n# In order to setup your cluster make sure to read the documentation\n# available at https://redis.io web site.\n\n########################## CLUSTER DOCKER/NAT support  ########################\n\n# In certain deployments, Redis Cluster nodes address discovery fails, because\n# addresses are NAT-ted or because ports are forwarded (the typical case is\n# Docker and other containers).\n#\n# In order to make Redis Cluster working in such environments, a static\n# configuration where each node knows its public address is needed. The\n# following four options are used for this scope, and are:\n#\n# * cluster-announce-ip\n# * cluster-announce-port\n# * cluster-announce-tls-port\n# * cluster-announce-bus-port\n#\n# Each instructs the node about its address, client ports (for connections\n# without and with TLS) and cluster message bus port. The information is then\n# published in the header of the bus packets so that other nodes will be able to\n# correctly map the address of the node publishing the information.\n#\n# If tls-cluster is set to yes and cluster-announce-tls-port is omitted or set\n# to zero, then cluster-announce-port refers to the TLS port. Note also that\n# cluster-announce-tls-port has no effect if tls-cluster is set to no.\n#\n# If the above options are not used, the normal Redis Cluster auto-detection\n# will be used instead.\n#\n# Note that when remapped, the bus port may not be at the fixed offset of\n# clients port + 10000, so you can specify any port and bus-port depending\n# on how they get remapped. If the bus-port is not set, a fixed offset of\n# 10000 will be used as usual.\n#\n# Example:\n#\n# cluster-announce-ip 10.1.1.5\n# cluster-announce-tls-port 6379\n# cluster-announce-port 0\n# cluster-announce-bus-port 6380\n\n################################## SLOW LOG ###################################\n\n# The Redis Slow Log is a system to log queries that exceeded a specified\n# execution time. The execution time does not include the I/O operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# You can configure the slow log with two parameters: one tells Redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. When a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# The following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. Note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# There is no limit to this length. Just be aware that it will consume memory.\n# You can reclaim memory used by the slow log with SLOWLOG RESET.\nslowlog-max-len 128\n\n################################ LATENCY MONITOR ##############################\n\n# The Redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a Redis instance.\n#\n# Via the LATENCY command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# The system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. When its value is set\n# to zero, the latency monitor is turned off.\n#\n# By default latency monitoring is disabled since it is mostly not needed\n# if you don't have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. Latency\n# monitoring can easily be enabled at runtime using the command\n# \"CONFIG SET latency-monitor-threshold <milliseconds>\" if needed.\nlatency-monitor-threshold 0\n\n################################ LATENCY TRACKING ##############################\n\n# The Redis extended latency monitoring tracks the per command latencies and enables\n# exporting the percentile distribution via the INFO latencystats command,\n# and cumulative latency distributions (histograms) via the LATENCY command.\n#\n# By default, the extended latency monitoring is enabled since the overhead\n# of keeping track of the command latency is very small.\n# latency-tracking yes\n\n# By default the exported latency percentiles via the INFO latencystats command\n# are the p50, p99, and p999.\n# latency-tracking-info-percentiles 50 99 99.9\n\n############################# EVENT NOTIFICATION ##############################\n\n# Redis can notify Pub/Sub clients about events happening in the key space.\n# This feature is documented at https://redis.io/docs/latest/develop/use/keyspace-notifications/\n#\n# For instance if keyspace events notification is enabled, and a client\n# performs a DEL operation on key \"foo\" stored in the Database 0, two\n# messages will be published via Pub/Sub:\n#\n# PUBLISH __keyspace@0__:foo del\n# PUBLISH __keyevent@0__:del foo\n#\n# It is possible to select the events that Redis will notify among a set\n# of classes. Every class is identified by a single character:\n#\n#  K     Keyspace events, published with __keyspace@<db>__ prefix.\n#  E     Keyevent events, published with __keyevent@<db>__ prefix.\n#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n#  $     String commands\n#  l     List commands\n#  s     Set commands\n#  h     Hash commands\n#  z     Sorted set commands\n#  x     Expired events (events generated every time a key expires)\n#  e     Evicted events (events generated when a key is evicted for maxmemory)\n#  n     New key events (Note: not included in the 'A' class)\n#  t     Stream commands\n#  d     Module key type events\n#  m     Key-miss events (Note: It is not included in the 'A' class)\n#  A     Alias for g$lshzxetd, so that the \"AKE\" string means all the events\n#        (Except key-miss events which are excluded from 'A' due to their\n#         unique nature).\n#\n#  The \"notify-keyspace-events\" takes as argument a string that is composed\n#  of zero or multiple characters. The empty string means that notifications\n#  are disabled.\n#\n#  Example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events Elg\n#\n#  Example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events Ex\n#\n#  By default all notifications are disabled because most users don't need\n#  this feature and the feature has some overhead. Note that if you don't\n#  specify at least one of K or E, no events will be delivered.\nnotify-keyspace-events \"\"\n\n############################### ADVANCED CONFIG ###############################\n\n# Hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. These thresholds can be configured using the following directives.\nhash-max-listpack-entries 512\nhash-max-listpack-value 64\n\n# Lists are also encoded in a special way to save a lot of space.\n# The number of entries allowed per internal list node can be specified\n# as a fixed maximum size or a maximum number of elements.\n# For a fixed maximum size, use -5 through -1, meaning:\n# -5: max size: 64 Kb  <-- not recommended for normal workloads\n# -4: max size: 32 Kb  <-- not recommended\n# -3: max size: 16 Kb  <-- probably not recommended\n# -2: max size: 8 Kb   <-- good\n# -1: max size: 4 Kb   <-- good\n# Positive numbers mean store up to _exactly_ that number of elements\n# per list node.\n# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),\n# but if your use case is unique, adjust the settings as necessary.\nlist-max-listpack-size -2\n\n# Lists may also be compressed.\n# Compress depth is the number of quicklist ziplist nodes from *each* side of\n# the list to *exclude* from compression.  The head and tail of the list\n# are always uncompressed for fast push/pop operations.  Settings are:\n# 0: disable all list compression\n# 1: depth 1 means \"don't start compressing until after 1 node into the list,\n#    going from either the head or tail\"\n#    So: [head]->node->node->...->node->[tail]\n#    [head], [tail] will always be uncompressed; inner nodes will compress.\n# 2: [head]->[next]->node->node->...->node->[prev]->[tail]\n#    2 here means: don't compress head or head->next or tail->prev or tail,\n#    but compress all nodes between them.\n# 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail]\n# etc.\nlist-compress-depth 0\n\n# Sets have a special encoding when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# The following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# Sets containing non-integer values are also encoded using a memory efficient\n# data structure when they have a small number of entries, and the biggest entry\n# does not exceed a given threshold. These thresholds can be configured using\n# the following directives.\nset-max-listpack-entries 128\nset-max-listpack-value 64\n\n# Similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. This encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-listpack-entries 128\nzset-max-listpack-value 64\n\n# HyperLogLog sparse representation bytes limit. The limit includes the\n# 16 bytes header. When a HyperLogLog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# A value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# The suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much PFADD,\n# which is O(N) with the sparse encoding. The value can be raised to\n# ~ 10000 when CPU is not a concern, but space is, and the data set is\n# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# Streams macro node max size / items. The stream data structure is a radix\n# tree of big nodes that encode multiple items inside. Using this configuration\n# it is possible to configure how big a single node can be in bytes, and the\n# maximum number of items it may contain before switching to a new node when\n# appending new stream entries. If any of the following settings are set to\n# zero, the limit is ignored, so for instance it is possible to set just a\n# max entries limit by setting max-bytes to 0 and max-entries to the desired\n# value.\nstream-node-max-bytes 4096\nstream-node-max-entries 100\n\n# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in\n# order to help rehashing the main Redis hash table (the one mapping top-level\n# keys to values). The hash table implementation Redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing \"steps\" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# The default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# If unsure:\n# use \"activerehashing no\" if you have hard latency requirements and it is\n# not a good thing in your environment that Redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use \"activerehashing yes\" if you don't have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# The client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a Pub/Sub client can't consume messages as fast as the\n# publisher can produce them).\n#\n# The limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including MONITOR clients\n# replica -> replica clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# The syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# A client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# So for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# By default normal clients are not limited because they don't receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# Instead there is a default limit for pubsub and replica clients, since\n# subscribers and replicas receive data in a push fashion.\n#\n# Note that it doesn't make sense to set the replica clients output buffer\n# limit lower than the repl-backlog-size config (partial sync will succeed\n# and then replica will get disconnected).\n# Such a configuration is ignored (the size of repl-backlog-size will be used).\n# This doesn't have memory consumption implications since the replica client\n# will share the backlog buffers memory.\n#\n# Both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit replica 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# Client query buffers accumulate new commands. They are limited to a fixed\n# amount by default in order to avoid that a protocol desynchronization (for\n# instance due to a bug in the client) will lead to unbound memory usage in\n# the query buffer. However you can configure it here if you have very special\n# needs, such as a command with huge argument, or huge multi/exec requests or alike.\n#\n# client-query-buffer-limit 1gb\n\n# In some scenarios client connections can hog up memory leading to OOM\n# errors or data eviction. To avoid this we can cap the accumulated memory\n# used by all client connections (all pubsub and normal clients). Once we\n# reach that limit connections will be dropped by the server freeing up\n# memory. The server will attempt to drop the connections using the most \n# memory first. We call this mechanism \"client eviction\".\n#\n# Client eviction is configured using the maxmemory-clients setting as follows:\n# 0 - client eviction is disabled (default)\n#\n# A memory value can be used for the client eviction threshold,\n# for example:\n# maxmemory-clients 1g\n#\n# A percentage value (between 1% and 100%) means the client eviction threshold\n# is based on a percentage of the maxmemory setting. For example to set client\n# eviction at 5% of maxmemory:\n# maxmemory-clients 5%\n\n# In the Redis protocol, bulk requests, that are, elements representing single\n# strings, are normally limited to 512 mb. However you can change this limit\n# here, but must be 1mb or greater\n#\n# proto-max-bulk-len 512mb\n\n# Redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# Not all tasks are performed with the same frequency, but Redis checks for\n# tasks to perform according to the specified \"hz\" value.\n#\n# By default \"hz\" is set to 10. Raising the value will use more CPU when\n# Redis is idle, but at the same time will make Redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# The range is between 1 and 500, however a value over 100 is usually not\n# a good idea. Most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# Normally it is useful to have an HZ value which is proportional to the\n# number of clients connected. This is useful in order, for instance, to\n# avoid too many clients are processed for each background task invocation\n# in order to avoid latency spikes.\n#\n# Since the default HZ value by default is conservatively set to 10, Redis\n# offers, and enables by default, the ability to use an adaptive HZ value\n# which will temporarily raise when there are many connected clients.\n#\n# When dynamic HZ is enabled, the actual configured HZ will be used\n# as a baseline, but multiples of the configured HZ value will be actually\n# used as needed once more clients are connected. In this way an idle\n# instance will use very little CPU time while a busy instance will be\n# more responsive.\ndynamic-hz yes\n\n# When a child rewrites the AOF file, if the following option is enabled\n# the file will be fsync-ed every 4 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n\n# When redis saves RDB file, if the following option is enabled\n# the file will be fsync-ed every 4 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\nrdb-save-incremental-fsync yes\n\n# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good\n# idea to start with the default settings and only change them after investigating\n# how to improve the performances and how the keys LFU change over time, which\n# is possible to inspect via the OBJECT FREQ command.\n#\n# There are two tunable parameters in the Redis LFU implementation: the\n# counter logarithm factor and the counter decay time. It is important to\n# understand what the two parameters mean before changing them.\n#\n# The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis\n# uses a probabilistic increment with logarithmic behavior. Given the value\n# of the old counter, when a key is accessed, the counter is incremented in\n# this way:\n#\n# 1. A random number R between 0 and 1 is extracted.\n# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).\n# 3. The counter is incremented only if R < P.\n#\n# The default lfu-log-factor is 10. This is a table of how the frequency\n# counter changes with a different number of accesses with different\n# logarithmic factors:\n#\n# +--------+------------+------------+------------+------------+------------+\n# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n# +--------+------------+------------+------------+------------+------------+\n# | 0      | 104        | 255        | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 1      | 18         | 49         | 255        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 10     | 10         | 18         | 142        | 255        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n# | 100    | 8          | 11         | 49         | 143        | 255        |\n# +--------+------------+------------+------------+------------+------------+\n#\n# NOTE: The above table was obtained by running the following commands:\n#\n#   redis-benchmark -n 1000000 incr foo\n#   redis-cli object freq foo\n#\n# NOTE 2: The counter initial value is 5 in order to give new objects a chance\n# to accumulate hits.\n#\n# The counter decay time is the time, in minutes, that must elapse in order\n# for the key counter to be decremented.\n#\n# The default value for the lfu-decay-time is 1. A special value of 0 means we\n# will never decay the counter.\n#\n# lfu-log-factor 10\n# lfu-decay-time 1\n\n\n# The maximum number of new client connections accepted per event-loop cycle. This configuration\n# is set independently for TLS connections.\n#\n# By default, up to 10 new connection will be accepted per event-loop cycle for normal connections\n# and up to 1 new connection per event-loop cycle for TLS connections.\n#\n# Adjusting this to a larger number can slightly improve efficiency for new connections\n# at the risk of causing timeouts for regular commands on established connections.  It is\n# not advised to change this without ensuring that all clients have limited connection\n# pools and exponential backoff in the case of command/connection timeouts. \n#\n# If your application is establishing a large number of new connections per second you should\n# also consider tuning the value of tcp-backlog, which allows the kernel to buffer more\n# pending connections before dropping or rejecting connections. \n#\n# max-new-connections-per-cycle 10\n# max-new-tls-connections-per-cycle 1\n\n\n########################### ACTIVE DEFRAGMENTATION #######################\n#\n# What is active defragmentation?\n# -------------------------------\n#\n# Active (online) defragmentation allows a Redis server to compact the\n# spaces left between small allocations and deallocations of data in memory,\n# thus allowing to reclaim back memory.\n#\n# Fragmentation is a natural process that happens with every allocator (but\n# less so with Jemalloc, fortunately) and certain workloads. Normally a server\n# restart is needed in order to lower the fragmentation, or at least to flush\n# away all the data and create it again. However thanks to this feature\n# implemented by Oran Agra for Redis 4.0 this process can happen at runtime\n# in a \"hot\" way, while the server is running.\n#\n# Basically when the fragmentation is over a certain level (see the\n# configuration options below) Redis will start to create new copies of the\n# values in contiguous memory regions by exploiting certain specific Jemalloc\n# features (in order to understand if an allocation is causing fragmentation\n# and to allocate it in a better place), and at the same time, will release the\n# old copies of the data. This process, repeated incrementally for all the keys\n# will cause the fragmentation to drop back to normal values.\n#\n# Important things to understand:\n#\n# 1. This feature is disabled by default, and only works if you compiled Redis\n#    to use the copy of Jemalloc we ship with the source code of Redis.\n#    This is the default with Linux builds.\n#\n# 2. You never need to enable this feature if you don't have fragmentation\n#    issues.\n#\n# 3. Once you experience fragmentation, you can enable this feature when\n#    needed with the command \"CONFIG SET activedefrag yes\".\n#\n# The configuration parameters are able to fine tune the behavior of the\n# defragmentation process. If you are not sure about what they mean it is\n# a good idea to leave the defaults untouched.\n\n# Active defragmentation is disabled by default\n# activedefrag no\n\n# Minimum amount of fragmentation waste to start active defrag\n# active-defrag-ignore-bytes 100mb\n\n# Minimum percentage of fragmentation to start active defrag\n# active-defrag-threshold-lower 10\n\n# Maximum percentage of fragmentation at which we use maximum effort\n# active-defrag-threshold-upper 100\n\n# Minimal effort for defrag in CPU percentage, to be used when the lower\n# threshold is reached\n# active-defrag-cycle-min 1\n\n# Maximal effort for defrag in CPU percentage, to be used when the upper\n# threshold is reached\n# active-defrag-cycle-max 25\n\n# Maximum number of set/hash/zset/list fields that will be processed from\n# the main dictionary scan\n# active-defrag-max-scan-fields 1000\n\n# Jemalloc background thread for purging will be enabled by default\njemalloc-bg-thread yes\n\n# It is possible to pin different threads and processes of Redis to specific\n# CPUs in your system, in order to maximize the performances of the server.\n# This is useful both in order to pin different Redis threads in different\n# CPUs, but also in order to make sure that multiple Redis instances running\n# in the same host will be pinned to different CPUs.\n#\n# Normally you can do this using the \"taskset\" command, however it is also\n# possible to this via Redis configuration directly, both in Linux and FreeBSD.\n#\n# You can pin the server/IO threads, bio threads, aof rewrite child process, and\n# the bgsave child process. The syntax to specify the cpu list is the same as\n# the taskset command:\n#\n# Set redis server/io threads to cpu affinity 0,2,4,6:\n# server-cpulist 0-7:2\n#\n# Set bio threads to cpu affinity 1,3:\n# bio-cpulist 1,3\n#\n# Set aof rewrite child process to cpu affinity 8,9,10,11:\n# aof-rewrite-cpulist 8-11\n#\n# Set bgsave child process to cpu affinity 1,10,11\n# bgsave-cpulist 1,10-11\n\n# In some cases redis will emit warnings and even refuse to start if it detects\n# that the system is in bad state, it is possible to suppress these warnings\n# by setting the following config which takes a space delimited list of warnings\n# to suppress\n#\n# ignore-warnings ARM64-COW-BUG\n"
        },
        {
          "name": "runtest",
          "type": "blob",
          "size": 0.27,
          "content": "#!/bin/sh\nTCL_VERSIONS=\"8.5 8.6 8.7\"\nTCLSH=\"\"\n\nfor VERSION in $TCL_VERSIONS; do\n\tTCL=`which tclsh$VERSION 2>/dev/null` && TCLSH=$TCL\ndone\n\nif [ -z $TCLSH ]\nthen\n    echo \"You need tcl 8.5 or newer in order to run the Redis test\"\n    exit 1\nfi\n$TCLSH tests/test_helper.tcl \"${@}\"\n"
        },
        {
          "name": "runtest-cluster",
          "type": "blob",
          "size": 0.28,
          "content": "#!/bin/sh\nTCL_VERSIONS=\"8.5 8.6 8.7\"\nTCLSH=\"\"\n\nfor VERSION in $TCL_VERSIONS; do\n\tTCL=`which tclsh$VERSION 2>/dev/null` && TCLSH=$TCL\ndone\n\nif [ -z $TCLSH ]\nthen\n    echo \"You need tcl 8.5 or newer in order to run the Redis Cluster test\"\n    exit 1\nfi\n$TCLSH tests/cluster/run.tcl $*\n"
        },
        {
          "name": "runtest-moduleapi",
          "type": "blob",
          "size": 1.76,
          "content": "#!/bin/sh\nTCL_VERSIONS=\"8.5 8.6 8.7\"\nTCLSH=\"\"\n[ -z \"$MAKE\" ] && MAKE=make\n\nfor VERSION in $TCL_VERSIONS; do\n\tTCL=`which tclsh$VERSION 2>/dev/null` && TCLSH=$TCL\ndone\n\nif [ -z $TCLSH ]\nthen\n    echo \"You need tcl 8.5 or newer in order to run the Redis ModuleApi test\"\n    exit 1\nfi\n\n$MAKE -C tests/modules && \\\n$TCLSH tests/test_helper.tcl \\\n--single unit/moduleapi/commandfilter \\\n--single unit/moduleapi/basics \\\n--single unit/moduleapi/fork \\\n--single unit/moduleapi/testrdb \\\n--single unit/moduleapi/infotest \\\n--single unit/moduleapi/moduleconfigs \\\n--single unit/moduleapi/infra \\\n--single unit/moduleapi/propagate \\\n--single unit/moduleapi/hooks \\\n--single unit/moduleapi/misc \\\n--single unit/moduleapi/blockonkeys \\\n--single unit/moduleapi/blockonbackground \\\n--single unit/moduleapi/scan \\\n--single unit/moduleapi/datatype \\\n--single unit/moduleapi/auth \\\n--single unit/moduleapi/keyspace_events \\\n--single unit/moduleapi/blockedclient \\\n--single unit/moduleapi/getkeys \\\n--single unit/moduleapi/test_lazyfree \\\n--single unit/moduleapi/defrag \\\n--single unit/moduleapi/keyspecs \\\n--single unit/moduleapi/hash \\\n--single unit/moduleapi/zset \\\n--single unit/moduleapi/list \\\n--single unit/moduleapi/stream \\\n--single unit/moduleapi/mallocsize \\\n--single unit/moduleapi/datatype2 \\\n--single unit/moduleapi/cluster \\\n--single unit/moduleapi/aclcheck \\\n--single unit/moduleapi/subcommands \\\n--single unit/moduleapi/reply \\\n--single unit/moduleapi/cmdintrospection \\\n--single unit/moduleapi/eventloop \\\n--single unit/moduleapi/timer \\\n--single unit/moduleapi/publish \\\n--single unit/moduleapi/usercall \\\n--single unit/moduleapi/postnotifications \\\n--single unit/moduleapi/async_rm_call \\\n--single unit/moduleapi/moduleauth \\\n--single unit/moduleapi/rdbloadsave \\\n--single unit/moduleapi/crash \\\n\"${@}\"\n"
        },
        {
          "name": "runtest-sentinel",
          "type": "blob",
          "size": 0.28,
          "content": "#!/bin/sh\nTCL_VERSIONS=\"8.5 8.6 8.7\"\nTCLSH=\"\"\n\nfor VERSION in $TCL_VERSIONS; do\n\tTCL=`which tclsh$VERSION 2>/dev/null` && TCLSH=$TCL\ndone\n\nif [ -z $TCLSH ]\nthen\n    echo \"You need tcl 8.5 or newer in order to run the Redis Sentinel test\"\n    exit 1\nfi\n$TCLSH tests/sentinel/run.tcl $*\n"
        },
        {
          "name": "sentinel.conf",
          "type": "blob",
          "size": 14.49,
          "content": "# Example sentinel.conf\n\n# By default protected mode is disabled in sentinel mode. Sentinel is reachable\n# from interfaces different than localhost. Make sure the sentinel instance is\n# protected from the outside world via firewalling or other means.\nprotected-mode no\n\n# port <sentinel-port>\n# The port that this sentinel instance will run on\nport 26379\n\n# By default Redis Sentinel does not run as a daemon. Use 'yes' if you need it.\n# Note that Redis will write a pid file in /var/run/redis-sentinel.pid when\n# daemonized.\ndaemonize no\n\n# When running daemonized, Redis Sentinel writes a pid file in\n# /var/run/redis-sentinel.pid by default. You can specify a custom pid file\n# location here.\npidfile /var/run/redis-sentinel.pid\n\n# Specify the server verbosity level.\n# This can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably)\n# warning (only very important / critical messages are logged)\n# nothing (nothing is logged)\nloglevel notice\n\n# Specify the log file name. Also the empty string can be used to force\n# Sentinel to log on the standard output. Note that if you use standard\n# output for logging but daemonize, logs will be sent to /dev/null\nlogfile \"\"\n\n# To enable logging to the system logger, just set 'syslog-enabled' to yes,\n# and optionally update the other syslog parameters to suit your needs.\n# syslog-enabled no\n\n# Specify the syslog identity.\n# syslog-ident sentinel\n\n# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.\n# syslog-facility local0\n\n# sentinel announce-ip <ip>\n# sentinel announce-port <port>\n#\n# The above two configuration directives are useful in environments where,\n# because of NAT, Sentinel is reachable from outside via a non-local address.\n#\n# When announce-ip is provided, the Sentinel will claim the specified IP address\n# in HELLO messages used to gossip its presence, instead of auto-detecting the\n# local address as it usually does.\n#\n# Similarly when announce-port is provided and is valid and non-zero, Sentinel\n# will announce the specified TCP port.\n#\n# The two options don't need to be used together, if only announce-ip is\n# provided, the Sentinel will announce the specified IP and the server port\n# as specified by the \"port\" option. If only announce-port is provided, the\n# Sentinel will announce the auto-detected local IP and the specified port.\n#\n# Example:\n#\n# sentinel announce-ip 1.2.3.4\n\n# dir <working-directory>\n# Every long running process should have a well-defined working directory.\n# For Redis Sentinel to chdir to /tmp at startup is the simplest thing\n# for the process to don't interfere with administrative tasks such as\n# unmounting filesystems.\ndir /tmp\n\n# sentinel monitor <master-name> <ip> <redis-port> <quorum>\n#\n# Tells Sentinel to monitor this master, and to consider it in O_DOWN\n# (Objectively Down) state only if at least <quorum> sentinels agree.\n#\n# Note that whatever is the ODOWN quorum, a Sentinel will require to\n# be elected by the majority of the known Sentinels in order to\n# start a failover, so no failover can be performed in minority.\n#\n# Replicas are auto-discovered, so you don't need to specify replicas in\n# any way. Sentinel itself will rewrite this configuration file adding\n# the replicas using additional configuration options.\n# Also note that the configuration file is rewritten when a\n# replica is promoted to master.\n#\n# Note: master name should not include special characters or spaces.\n# The valid charset is A-z 0-9 and the three characters \".-_\".\nsentinel monitor mymaster 127.0.0.1 6379 2\n\n# sentinel auth-pass <master-name> <password>\n#\n# Set the password to use to authenticate with the master and replicas.\n# Useful if there is a password set in the Redis instances to monitor.\n#\n# Note that the master password is also used for replicas, so it is not\n# possible to set a different password in masters and replicas instances\n# if you want to be able to monitor these instances with Sentinel.\n#\n# However you can have Redis instances without the authentication enabled\n# mixed with Redis instances requiring the authentication (as long as the\n# password set is the same for all the instances requiring the password) as\n# the AUTH command will have no effect in Redis instances with authentication\n# switched off.\n#\n# Example:\n#\n# sentinel auth-pass mymaster MySUPER--secret-0123passw0rd\n\n# sentinel auth-user <master-name> <username>\n#\n# This is useful in order to authenticate to instances having ACL capabilities,\n# that is, running Redis 6.0 or greater. When just auth-pass is provided the\n# Sentinel instance will authenticate to Redis using the old \"AUTH <pass>\"\n# method. When also an username is provided, it will use \"AUTH <user> <pass>\".\n# In the Redis servers side, the ACL to provide just minimal access to\n# Sentinel instances, should be configured along the following lines:\n#\n#     user sentinel-user >somepassword +client +subscribe +publish \\\n#                        +ping +info +multi +slaveof +config +client +exec on\n\n# sentinel down-after-milliseconds <master-name> <milliseconds>\n#\n# Number of milliseconds the master (or any attached replica or sentinel) should\n# be unreachable (as in, not acceptable reply to PING, continuously, for the\n# specified period) in order to consider it in S_DOWN state (Subjectively\n# Down).\n#\n# Default is 30 seconds.\nsentinel down-after-milliseconds mymaster 30000\n\n# IMPORTANT NOTE: starting with Redis 6.2 ACL capability is supported for\n# Sentinel mode, please refer to the Redis website https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/\n# for more details.\n\n# Sentinel's ACL users are defined in the following format:\n#\n#   user <username> ... acl rules ...\n#\n# For example:\n#\n#   user worker +@admin +@connection ~* on >ffa9203c493aa99\n#\n# For more information about ACL configuration please refer to the Redis\n# website at https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ and redis server configuration \n# template redis.conf.\n\n# ACL LOG\n#\n# The ACL Log tracks failed commands and authentication events associated\n# with ACLs. The ACL Log is useful to troubleshoot failed commands blocked \n# by ACLs. The ACL Log is stored in memory. You can reclaim memory with \n# ACL LOG RESET. Define the maximum entry length of the ACL Log below.\nacllog-max-len 128\n\n# Using an external ACL file\n#\n# Instead of configuring users here in this file, it is possible to use\n# a stand-alone file just listing users. The two methods cannot be mixed:\n# if you configure users here and at the same time you activate the external\n# ACL file, the server will refuse to start.\n#\n# The format of the external ACL user file is exactly the same as the\n# format that is used inside redis.conf to describe users.\n#\n# aclfile /etc/redis/sentinel-users.acl\n\n# requirepass <password>\n#\n# You can configure Sentinel itself to require a password, however when doing\n# so Sentinel will try to authenticate with the same password to all the\n# other Sentinels. So you need to configure all your Sentinels in a given\n# group with the same \"requirepass\" password. Check the following documentation\n# for more info: https://redis.io/docs/latest/operate/oss_and_stack/management/sentinel/\n#\n# IMPORTANT NOTE: starting with Redis 6.2 \"requirepass\" is a compatibility\n# layer on top of the ACL system. The option effect will be just setting\n# the password for the default user. Clients will still authenticate using\n# AUTH <password> as usually, or more explicitly with AUTH default <password>\n# if they follow the new protocol: both will work.\n#\n# New config files are advised to use separate authentication control for\n# incoming connections (via ACL), and for outgoing connections (via\n# sentinel-user and sentinel-pass) \n#\n# The requirepass is not compatible with aclfile option and the ACL LOAD\n# command, these will cause requirepass to be ignored.\n\n# sentinel sentinel-user <username>\n#\n# You can configure Sentinel to authenticate with other Sentinels with specific\n# user name. \n\n# sentinel sentinel-pass <password>\n#\n# The password for Sentinel to authenticate with other Sentinels. If sentinel-user\n# is not configured, Sentinel will use 'default' user with sentinel-pass to authenticate.\n\n# sentinel parallel-syncs <master-name> <numreplicas>\n#\n# How many replicas we can reconfigure to point to the new replica simultaneously\n# during the failover. Use a low number if you use the replicas to serve query\n# to avoid that all the replicas will be unreachable at about the same\n# time while performing the synchronization with the master.\nsentinel parallel-syncs mymaster 1\n\n# sentinel failover-timeout <master-name> <milliseconds>\n#\n# Specifies the failover timeout in milliseconds. It is used in many ways:\n#\n# - The time needed to re-start a failover after a previous failover was\n#   already tried against the same master by a given Sentinel, is two\n#   times the failover timeout.\n#\n# - The time needed for a replica replicating to a wrong master according\n#   to a Sentinel current configuration, to be forced to replicate\n#   with the right master, is exactly the failover timeout (counting since\n#   the moment a Sentinel detected the misconfiguration).\n#\n# - The time needed to cancel a failover that is already in progress but\n#   did not produced any configuration change (SLAVEOF NO ONE yet not\n#   acknowledged by the promoted replica).\n#\n# - The maximum time a failover in progress waits for all the replicas to be\n#   reconfigured as replicas of the new master. However even after this time\n#   the replicas will be reconfigured by the Sentinels anyway, but not with\n#   the exact parallel-syncs progression as specified.\n#\n# Default is 3 minutes.\nsentinel failover-timeout mymaster 180000\n\n# SCRIPTS EXECUTION\n#\n# sentinel notification-script and sentinel reconfig-script are used in order\n# to configure scripts that are called to notify the system administrator\n# or to reconfigure clients after a failover. The scripts are executed\n# with the following rules for error handling:\n#\n# If script exits with \"1\" the execution is retried later (up to a maximum\n# number of times currently set to 10).\n#\n# If script exits with \"2\" (or an higher value) the script execution is\n# not retried.\n#\n# If script terminates because it receives a signal the behavior is the same\n# as exit code 1.\n#\n# A script has a maximum running time of 60 seconds. After this limit is\n# reached the script is terminated with a SIGKILL and the execution retried.\n\n# NOTIFICATION SCRIPT\n#\n# sentinel notification-script <master-name> <script-path>\n# \n# Call the specified notification script for any sentinel event that is\n# generated in the WARNING level (for instance -sdown, -odown, and so forth).\n# This script should notify the system administrator via email, SMS, or any\n# other messaging system, that there is something wrong with the monitored\n# Redis systems.\n#\n# The script is called with just two arguments: the first is the event type\n# and the second the event description.\n#\n# The script must exist and be executable in order for sentinel to start if\n# this option is provided.\n#\n# Example:\n#\n# sentinel notification-script mymaster /var/redis/notify.sh\n\n# CLIENTS RECONFIGURATION SCRIPT\n#\n# sentinel client-reconfig-script <master-name> <script-path>\n#\n# When the master changed because of a failover a script can be called in\n# order to perform application-specific tasks to notify the clients that the\n# configuration has changed and the master is at a different address.\n# \n# The following arguments are passed to the script:\n#\n# <master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port>\n#\n# <state> is currently always \"start\"\n# <role> is either \"leader\" or \"observer\"\n# \n# The arguments from-ip, from-port, to-ip, to-port are used to communicate\n# the old address of the master and the new address of the elected replica\n# (now a master).\n#\n# This script should be resistant to multiple invocations.\n#\n# Example:\n#\n# sentinel client-reconfig-script mymaster /var/redis/reconfig.sh\n\n# SECURITY\n#\n# By default SENTINEL SET will not be able to change the notification-script\n# and client-reconfig-script at runtime. This avoids a trivial security issue\n# where clients can set the script to anything and trigger a failover in order\n# to get the program executed.\n\nsentinel deny-scripts-reconfig yes\n\n# REDIS COMMANDS RENAMING (DEPRECATED)\n#\n# WARNING: avoid using this option if possible, instead use ACLs.\n#\n# Sometimes the Redis server has certain commands, that are needed for Sentinel\n# to work correctly, renamed to unguessable strings. This is often the case\n# of CONFIG and SLAVEOF in the context of providers that provide Redis as\n# a service, and don't want the customers to reconfigure the instances outside\n# of the administration console.\n#\n# In such case it is possible to tell Sentinel to use different command names\n# instead of the normal ones. For example if the master \"mymaster\", and the\n# associated replicas, have \"CONFIG\" all renamed to \"GUESSME\", I could use:\n#\n# SENTINEL rename-command mymaster CONFIG GUESSME\n#\n# After such configuration is set, every time Sentinel would use CONFIG it will\n# use GUESSME instead. Note that there is no actual need to respect the command\n# case, so writing \"config guessme\" is the same in the example above.\n#\n# SENTINEL SET can also be used in order to perform this configuration at runtime.\n#\n# In order to set a command back to its original name (undo the renaming), it\n# is possible to just rename a command to itself:\n#\n# SENTINEL rename-command mymaster CONFIG CONFIG\n\n# HOSTNAMES SUPPORT\n#\n# Normally Sentinel uses only IP addresses and requires SENTINEL MONITOR\n# to specify an IP address. Also, it requires the Redis replica-announce-ip\n# keyword to specify only IP addresses.\n#\n# You may enable hostnames support by enabling resolve-hostnames. Note\n# that you must make sure your DNS is configured properly and that DNS\n# resolution does not introduce very long delays.\n#\nSENTINEL resolve-hostnames no\n\n# When resolve-hostnames is enabled, Sentinel still uses IP addresses\n# when exposing instances to users, configuration files, etc. If you want\n# to retain the hostnames when announced, enable announce-hostnames below.\n#\nSENTINEL announce-hostnames no\n\n# When master_reboot_down_after_period is set to 0, Sentinel does not fail over\n# when receiving a -LOADING response from a master. This was the only supported\n# behavior before version 7.0.\n#\n# Otherwise, Sentinel will use this value as the time (in ms) it is willing to\n# accept a -LOADING response after a master has been rebooted, before failing\n# over.\n\nSENTINEL master-reboot-down-after-period mymaster 0\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "ByteByteGoHq/system-design-101",
      "stars": 67439,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.78,
          "content": "# Byte-compiled / optimized / DLL files\n*.epub\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# IPython notebook\n.ipynb_checkpoints\n\n# Repo scratch directory\nscratch/\n\n# IPython Notebook templates\ntemplate.ipynb"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.74,
          "content": "Contributing\n============\n\nThank you for your interest in contributing! Here are some guidelines to follow when submitting pull requests:\n\n## Pull Requests\n\n* Each pull request should focus on a single topic or concept.\n* Avoid making changes across multiple topics in the same PR.\n* Give your PR a clear title summarizing the topic you are addressing.\n* If you notice typos or issues in diagrams, please open a separate issue instead of fixing the images directly. We will update the source images and republish fixes.\n\n### GitHub Pull Requests Docs\n\nIf you are not familiar with pull requests, review the [pull request docs](https://help.github.com/articles/using-pull-requests/).\n\n## Translations\n\nRefer to [TRANSLATIONS.md](translations/TRANSLATIONS.md)\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 0.88,
          "content": "## License\n\n<p xmlns:cc=\"http://creativecommons.org/ns#\" >This work is licensed under <a href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">CC BY-NC-ND 4.0<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1\"></a></p>\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 82.84,
          "content": "<p>\n  <a href=\"https://blog.bytebytego.com/?utm_source=site\"><img src=\"images/banner.jpg\" /> </a>\n</p>\n\n<p align=\"center\">\n  【\n  <a href=\"https://www.youtube.com/channel/UCZgt6AzoyjslHTC9dz0UoTw\">\n    👨🏻‍💻 YouTube\n  </a> | \n  <a href=\"https://blog.bytebytego.com/?utm_source=site\">\n    📮 Newsletter\n  </a> 】\n</p>\n\n<a href=\"https://trendshift.io/repositories/3709\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/3709\" alt=\"ByteByteGoHq%2Fsystem-design-101 | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n# System Design 101\n\nExplain complex systems using visuals and simple terms. \n\nWhether you're preparing for a System Design Interview or you simply want to understand how systems work beneath the surface, we hope this repository will help you achieve that.\n\n# Table of Contents\n\n<!-- TOC toc.levels=2 -->\n\n- [Communication protocols](#communication-protocols)\n  - [REST API vs. GraphQL](#rest-api-vs-graphql)\n  - [How does gRPC work?](#how-does-grpc-work)\n  - [What is a webhook?](#what-is-a-webhook)\n  - [How to improve API performance?](#how-to-improve-api-performance)\n  - [HTTP 1.0 -\\> HTTP 1.1 -\\> HTTP 2.0 -\\> HTTP 3.0 (QUIC)](#http-10---http-11---http-20---http-30-quic)\n  - [SOAP vs REST vs GraphQL vs RPC](#soap-vs-rest-vs-graphql-vs-rpc)\n  - [Code First vs. API First](#code-first-vs-api-first)\n  - [HTTP status codes](#http-status-codes)\n  - [What does API gateway do?](#what-does-api-gateway-do)\n  - [How do we design effective and safe APIs?](#how-do-we-design-effective-and-safe-apis)\n  - [TCP/IP encapsulation](#tcpip-encapsulation)\n  - [Why is Nginx called a “reverse” proxy?](#why-is-nginx-called-a-reverse-proxy)\n  - [What are the common load-balancing algorithms?](#what-are-the-common-load-balancing-algorithms)\n  - [URL, URI, URN - Do you know the differences?](#url-uri-urn---do-you-know-the-differences)\n- [CI/CD](#cicd)\n  - [CI/CD Pipeline Explained in Simple Terms](#cicd-pipeline-explained-in-simple-terms)\n  - [Netflix Tech Stack (CI/CD Pipeline)](#netflix-tech-stack-cicd-pipeline)\n- [Architecture patterns](#architecture-patterns)\n  - [MVC, MVP, MVVM, MVVM-C, and VIPER](#mvc-mvp-mvvm-mvvm-c-and-viper)\n  - [18 Key Design Patterns Every Developer Should Know](#18-key-design-patterns-every-developer-should-know)\n- [Database](#database)\n  - [A nice cheat sheet of different databases in cloud services](#a-nice-cheat-sheet-of-different-databases-in-cloud-services)\n  - [8 Data Structures That Power Your Databases](#8-data-structures-that-power-your-databases)\n  - [How is an SQL statement executed in the database?](#how-is-an-sql-statement-executed-in-the-database)\n  - [CAP theorem](#cap-theorem)\n  - [Types of Memory and Storage](#types-of-memory-and-storage)\n  - [Visualizing a SQL query](#visualizing-a-sql-query)\n  - [SQL language](#sql-language)\n- [Cache](#cache)\n  - [Data is cached everywhere](#data-is-cached-everywhere)\n  - [Why is Redis so fast?](#why-is-redis-so-fast)\n  - [How can Redis be used?](#how-can-redis-be-used)\n  - [Top caching strategies](#top-caching-strategies)\n- [Microservice architecture](#microservice-architecture)\n  - [What does a typical microservice architecture look like?](#what-does-a-typical-microservice-architecture-look-like)\n  - [Microservice Best Practices](#microservice-best-practices)\n  - [What tech stack is commonly used for microservices?](#what-tech-stack-is-commonly-used-for-microservices)\n  - [Why is Kafka fast](#why-is-kafka-fast)\n- [Payment systems](#payment-systems)\n  - [How to learn payment systems?](#how-to-learn-payment-systems)\n  - [Why is the credit card called “the most profitable product in banks”? How does VISA/Mastercard make money?](#why-is-the-credit-card-called-the-most-profitable-product-in-banks-how-does-visamastercard-make-money)\n  - [How does VISA work when we swipe a credit card at a merchant’s shop?](#how-does-visa-work-when-we-swipe-a-credit-card-at-a-merchants-shop)\n  - [Payment Systems Around The World Series (Part 1): Unified Payments Interface (UPI) in India](#payment-systems-around-the-world-series-part-1-unified-payments-interface-upi-in-india)\n- [DevOps](#devops)\n  - [DevOps vs. SRE vs. Platform Engineering. What is the difference?](#devops-vs-sre-vs-platform-engineering-what-is-the-difference)\n  - [What is k8s (Kubernetes)?](#what-is-k8s-kubernetes)\n  - [Docker vs. Kubernetes. Which one should we use?](#docker-vs-kubernetes-which-one-should-we-use)\n  - [How does Docker work?](#how-does-docker-work)\n- [GIT](#git)\n  - [How Git Commands work](#how-git-commands-work)\n  - [How does Git Work?](#how-does-git-work)\n  - [Git merge vs. Git rebase](#git-merge-vs-git-rebase)\n- [Cloud Services](#cloud-services)\n  - [A nice cheat sheet of different cloud services (2023 edition)](#a-nice-cheat-sheet-of-different-cloud-services-2023-edition)\n  - [What is cloud native?](#what-is-cloud-native)\n- [Developer productivity tools](#developer-productivity-tools)\n  - [Visualize JSON files](#visualize-json-files)\n  - [Automatically turn code into architecture diagrams](#automatically-turn-code-into-architecture-diagrams)\n- [Linux](#linux)\n  - [Linux file system explained](#linux-file-system-explained)\n  - [18 Most-used Linux Commands You Should Know](#18-most-used-linux-commands-you-should-know)\n- [Security](#security)\n  - [How does HTTPS work?](#how-does-https-work)\n  - [Oauth 2.0 Explained With Simple Terms.](#oauth-20-explained-with-simple-terms)\n  - [Top 4 Forms of Authentication Mechanisms](#top-4-forms-of-authentication-mechanisms)\n  - [Session, cookie, JWT, token, SSO, and OAuth 2.0 - what are they?](#session-cookie-jwt-token-sso-and-oauth-20---what-are-they)\n  - [How to store passwords safely in the database and how to validate a password?](#how-to-store-passwords-safely-in-the-database-and-how-to-validate-a-password)\n  - [Explaining JSON Web Token (JWT) to a 10 year old Kid](#explaining-json-web-token-jwt-to-a-10-year-old-kid)\n  - [How does Google Authenticator (or other types of 2-factor authenticators) work?](#how-does-google-authenticator-or-other-types-of-2-factor-authenticators-work)\n- [Real World Case Studies](#real-world-case-studies)\n  - [Netflix's Tech Stack](#netflixs-tech-stack)\n  - [Twitter Architecture 2022](#twitter-architecture-2022)\n  - [Evolution of Airbnb’s microservice architecture over the past 15 years](#evolution-of-airbnbs-microservice-architecture-over-the-past-15-years)\n  - [Monorepo vs. Microrepo.](#monorepo-vs-microrepo)\n  - [How will you design the Stack Overflow website?](#how-will-you-design-the-stack-overflow-website)\n  - [Why did Amazon Prime Video monitoring move from serverless to monolithic? How can it save 90% cost?](#why-did-amazon-prime-video-monitoring-move-from-serverless-to-monolithic-how-can-it-save-90-cost)\n  - [How does Disney Hotstar capture 5 Billion Emojis during a tournament?](#how-does-disney-hotstar-capture-5-billion-emojis-during-a-tournament)\n  - [How Discord Stores Trillions Of Messages](#how-discord-stores-trillions-of-messages)\n  - [How do video live streamings work on YouTube, TikTok live, or Twitch?](#how-do-video-live-streamings-work-on-youtube-tiktok-live-or-twitch)\n\n<!-- /TOC -->\n\n## Communication protocols\n\nArchitecture styles define how different components of an application programming interface (API) interact with one another. As a result, they ensure efficiency, reliability, and ease of integration with other systems by providing a standard approach to designing and building APIs. Here are the most used styles:\n\n<p>\n  <img src=\"images/api-architecture-styles.png\" style=\"width: 640px\">\n</p>\n\n- SOAP: \n\n  Mature, comprehensive, XML-based\n  \n  Best for enterprise applications \n\n- RESTful: \n\n  Popular, easy-to-implement, HTTP methods \n\n  Ideal for web services \n\n- GraphQL: \n\n  Query language, request specific data \n\n  Reduces network overhead, faster responses \n\n- gRPC: \n\n  Modern, high-performance, Protocol Buffers \n\n  Suitable for microservices architectures \n\n- WebSocket: \n\n  Real-time, bidirectional, persistent connections \n\n  Perfect for low-latency data exchange \n\n- Webhook: \n\n  Event-driven, HTTP callbacks, asynchronous \n\n  Notifies systems when events occur\n\n\n### REST API vs. GraphQL\n\nWhen it comes to API design, REST and GraphQL each have their own strengths and weaknesses.\n\nThe diagram below shows a quick comparison between REST and GraphQL.\n\n<p>\n  <img src=\"images/graphQL.jpg\">\n</p>\n\nREST\n\n- Uses standard HTTP methods like GET, POST, PUT, DELETE for CRUD operations.\n- Works well when you need simple, uniform interfaces between separate services/applications.\n- Caching strategies are straightforward to implement.\n- The downside is it may require multiple roundtrips to assemble related data from separate endpoints.\n\nGraphQL\n\n- Provides a single endpoint for clients to query for precisely the data they need.\n- Clients specify the exact fields required in nested queries, and the server returns optimized payloads containing just those fields.\n- Supports Mutations for modifying data and Subscriptions for real-time notifications.\n- Great for aggregating data from multiple sources and works well with rapidly evolving frontend requirements.\n- However, it shifts complexity to the client side and can allow abusive queries if not properly safeguarded\n- Caching strategies can be more complicated than REST.\n\nThe best choice between REST and GraphQL depends on the specific requirements of the application and development team. GraphQL is a good fit for complex or frequently changing frontend needs, while REST suits applications where simple and consistent contracts are preferred.\n\nNeither API approach is a silver bullet. Carefully evaluating requirements and tradeoffs is important to pick the right style. Both REST and GraphQL are valid options for exposing data and powering modern applications.\n\n\n### How does gRPC work?\n\nRPC (Remote Procedure Call) is called “**remote**” because it enables communications between remote services when services are deployed to different servers under microservice architecture. From the user’s point of view, it acts like a local function call.\n\nThe diagram below illustrates the overall data flow for **gRPC**.\n\n<p>\n  <img src=\"images/grpc.jpg\">\n</p>\n\nStep 1: A REST call is made from the client. The request body is usually in JSON format.\n\nSteps 2 - 4: The order service (gRPC client) receives the REST call, transforms it, and makes an RPC call to the payment service. gRPC encodes the **client stub** into a binary format and sends it to the low-level transport layer.\n\nStep 5: gRPC sends the packets over the network via HTTP2. Because of binary encoding and network optimizations, gRPC is said to be 5X faster than JSON.\n\nSteps 6 - 8: The payment service (gRPC server) receives the packets from the network, decodes them, and invokes the server application.\n\nSteps 9 - 11: The result is returned from the server application, and gets encoded and sent to the transport layer.\n\nSteps 12 - 14: The order service receives the packets, decodes them, and sends the result to the client application.\n\n### What is a webhook?\n\nThe diagram below shows a comparison between polling and Webhook. \n\n<p>\n  <img src=\"images/webhook.jpeg\" style=\"width: 680px\" />\n</p>\n\nAssume we run an eCommerce website. The clients send orders to the order service via the API gateway, which goes to the payment service for payment transactions. The payment service then talks to an external payment service provider (PSP) to complete the transactions. \n\nThere are two ways to handle communications with the external PSP. \n\n**1. Short polling** \n\nAfter sending the payment request to the PSP, the payment service keeps asking the PSP about the payment status. After several rounds, the PSP finally returns with the status. \n\nShort polling has two drawbacks: \n* Constant polling of the status requires resources from the payment service. \n* The External service communicates directly with the payment service, creating security vulnerabilities. \n\n**2. Webhook** \n\nWe can register a webhook with the external service. It means: call me back at a certain URL when you have updates on the request. When the PSP has completed the processing, it will invoke the HTTP request to update the payment status.\n\nIn this way, the programming paradigm is changed, and the payment service doesn’t need to waste resources to poll the payment status anymore.\n\nWhat if the PSP never calls back? We can set up a housekeeping job to check payment status every hour.\n\nWebhooks are often referred to as reverse APIs or push APIs because the server sends HTTP requests to the client. We need to pay attention to 3 things when using a webhook:\n\n1. We need to design a proper API for the external service to call.\n2. We need to set up proper rules in the API gateway for security reasons.\n3. We need to register the correct URL at the external service.\n\n### How to improve API performance?\n\nThe diagram below shows 5 common tricks to improve API performance.\n\n<p>\n  <img src=\"images/api-performance.jpg\">\n</p>\n\nPagination\n\nThis is a common optimization when the size of the result is large. The results are streaming back to the client to improve the service responsiveness.\n\nAsynchronous Logging\n\nSynchronous logging deals with the disk for every call and can slow down the system. Asynchronous logging sends logs to a lock-free buffer first and immediately returns. The logs will be flushed to the disk periodically. This significantly reduces the I/O overhead.\n\nCaching\n\nWe can store frequently accessed data into a cache. The client can query the cache first instead of visiting the database directly. If there is a cache miss, the client can query from the database. Caches like Redis store data in memory, so the data access is much faster than the database.\n\nPayload Compression\n\nThe requests and responses can be compressed using gzip etc so that the transmitted data size is much smaller. This speeds up the upload and download.\n\nConnection Pool\n\nWhen accessing resources, we often need to load data from the database. Opening the closing db connections adds significant overhead. So we should connect to the db via a pool of open connections. The connection pool is responsible for managing the connection lifecycle.\n\n### HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)\n\nWhat problem does each generation of HTTP solve?\n\nThe diagram below illustrates the key features.\n\n<p>\n  <img src=\"images/http3.jpg\" />\n</p>\n\n- HTTP 1.0 was finalized and fully documented in 1996. Every request to the same server requires a separate TCP connection.\n\n- HTTP 1.1 was published in 1997. A TCP connection can be left open for reuse (persistent connection), but it doesn’t solve the HOL (head-of-line) blocking issue. \n\n  HOL blocking - when the number of allowed parallel requests in the browser is used up, subsequent requests need to wait for the former ones to complete.\n\n- HTTP 2.0 was published in 2015. It addresses HOL issue through request multiplexing, which eliminates HOL blocking at the application layer, but HOL still exists at the transport (TCP) layer.\n\n  As you can see in the diagram, HTTP 2.0 introduced the concept of HTTP “streams”: an abstraction that allows multiplexing different HTTP exchanges onto the same TCP connection. Each stream doesn’t need to be sent in order.\n\n- HTTP 3.0 first draft was published in 2020. It is the proposed successor to HTTP 2.0. It uses QUIC instead of TCP for the underlying transport protocol, thus removing HOL blocking in the transport layer. \n\nQUIC is based on UDP. It introduces streams as first-class citizens at the transport layer. QUIC streams share the same QUIC connection, so no additional handshakes and slow starts are required to create new ones, but QUIC streams are delivered independently such that in most cases packet loss affecting one stream doesn't affect others.\n\n### SOAP vs REST vs GraphQL vs RPC\n\nThe diagram below illustrates the API timeline and API styles comparison.\n\nOver time, different API architectural styles are released. Each of them has its own patterns of standardizing data exchange. \n\nYou can check out the use cases of each style in the diagram.\n\n<p>\n  <img src=\"images/SOAP vs REST vs GraphQL vs RPC.jpeg\" />\n</p>\n\n\n### Code First vs. API First \n\nThe diagram below shows the differences between code-first development and API-first development. Why do we want to consider API first design?\n\n<p>\n  <img src=\"images/api_first.jpg\" style=\"width: 680px\" />\n</p>\n\n\n- Microservices increase system complexity and we have separate services to serve different functions of the system. While this kind of architecture facilitates decoupling and segregation of duty, we need to handle the various communications among services. \n\nIt is better to think through the system's complexity before writing the code and carefully defining the boundaries of the services.\n\n- Separate functional teams need to speak the same language and the dedicated functional teams are only responsible for their own components and services. It is recommended that the organization speak the same language via API design. \n\nWe can mock requests and responses to validate the API design before writing code.\n\n- Improve software quality and developer productivity Since we have ironed out most of the uncertainties when the project starts, the overall development process is smoother, and the software quality is greatly improved. \n\nDevelopers are happy about the process as well because they can focus on functional development instead of negotiating sudden changes.\n\nThe possibility of having surprises toward the end of the project lifecycle is reduced.\n\nBecause we have designed the API first, the tests can be designed while the code is being developed. In a way, we also have TDD (Test Driven Design) when using API first development.\n\n### HTTP status codes\n\n<p>\n  <img src=\"images/http-status-code.jpg\" style=\"width: 540px\" />\n</p>\n\n\nThe response codes for HTTP are divided into five categories: \n\nInformational (100-199) \nSuccess (200-299) \nRedirection (300-399) \nClient Error (400-499) \nServer Error (500-599) \n\n### What does API gateway do? \n\nThe diagram below shows the details. \n\n<p>\n  <img src=\"images/api_gateway.jpg\" style=\"width: 520px\" />\n</p>\n\nStep 1 - The client sends an HTTP request to the API gateway. \n\nStep 2 - The API gateway parses and validates the attributes in the HTTP request. \n\nStep 3 - The API gateway performs allow-list/deny-list checks. \n\nStep 4 - The API gateway talks to an identity provider for authentication and authorization. \n\nStep 5 - The rate limiting rules are applied to the request. If it is over the limit, the request is rejected. \n\nSteps 6 and 7 - Now that the request has passed basic checks, the API gateway finds the relevant service to route to by path matching. \n\nStep 8 - The API gateway transforms the request into the appropriate protocol and sends it to backend microservices. \n\nSteps 9-12: The API gateway can handle errors properly, and deals with faults if the error takes a longer time to recover (circuit break). It can also leverage ELK (Elastic-Logstash-Kibana) stack for logging and monitoring. We sometimes cache data in the API gateway. \n\n### How do we design effective and safe APIs?\n\nThe diagram below shows typical API designs with a shopping cart example. \n\n<p>\n  <img src=\"images/safe-apis.jpg\" />\n</p>\n\n\nNote that API design is not just URL path design. Most of the time, we need to choose the proper resource names, identifiers, and path patterns. It is equally important to design proper HTTP header fields or to design effective rate-limiting rules within the API gateway. \n\n### TCP/IP encapsulation \n\nHow is data sent over the network? Why do we need so many layers in the OSI model?\n\nThe diagram below shows how data is encapsulated and de-encapsulated when transmitting over the network.\n\n<p>\n  <img src=\"images/osi model.jpeg\" />\n</p>\n\nStep 1: When Device A sends data to Device B over the network via the HTTP protocol, it is first added an HTTP header at the application layer.\n\nStep 2: Then a TCP or a UDP header is added to the data. It is encapsulated into TCP segments at the transport layer. The header contains the source port, destination port, and sequence number.\n\nStep 3: The segments are then encapsulated with an IP header at the network layer. The IP header contains the source/destination IP addresses.\n\nStep 4: The IP datagram is added a MAC header at the data link layer, with source/destination MAC addresses.\n\nStep 5: The encapsulated frames are sent to the physical layer and sent over the network in binary bits.\n\nSteps 6-10: When Device B receives the bits from the network, it performs the de-encapsulation process, which is a reverse processing of the encapsulation process. The headers are removed layer by layer, and eventually, Device B can read the data.\n\nWe need layers in the network model because each layer focuses on its own responsibilities. Each layer can rely on the headers for processing instructions and does not need to know the meaning of the data from the last layer.\n\n### Why is Nginx called a “reverse” proxy?\n\nThe diagram below shows the differences between a 𝐟𝐨𝐫𝐰𝐚𝐫𝐝 𝐩𝐫𝐨𝐱𝐲 and a 𝐫𝐞𝐯𝐞𝐫𝐬𝐞 𝐩𝐫𝐨𝐱𝐲.\n\n<p>\n  <img src=\"images/Forward Proxy v.s. Reverse Proxy2x.jpg\" style=\"width: 720px\" />\n</p>\n\nA forward proxy is a server that sits between user devices and the internet.\n\nA forward proxy is commonly used for: \n\n1. Protecting clients\n2. Circumventing browsing restrictions\n3. Blocking access to certain content\n\nA reverse proxy is a server that accepts a request from the client, forwards the request to web servers, and returns the results to the client as if the proxy server had processed the request.\n\nA reverse proxy is good for:\n\n1. Protecting servers\n2. Load balancing\n3. Caching static contents\n4. Encrypting and decrypting SSL communications\n\n### What are the common load-balancing algorithms?\n\nThe diagram below shows 6 common algorithms. \n\n<p>\n  <img src=\"images/lb-algorithms.jpg\" />\n</p>\n\n- Static Algorithms \n\n1. Round robin\n\n    The client requests are sent to different service instances in sequential order. The services are usually required to be stateless. \n\n3. Sticky round-robin\n\n    This is an improvement of the round-robin algorithm. If Alice’s first request goes to service A, the following requests go to service A as well. \n\n4. Weighted round-robin\n\n    The admin can specify the weight for each service. The ones with a higher weight handle more requests than others. \n\n6. Hash\n\n    This algorithm applies a hash function on the incoming requests’ IP or URL. The requests are routed to relevant instances based on the hash function result. \n\n- Dynamic Algorithms\n\n5. Least connections\n\n    A new request is sent to the service instance with the least concurrent connections. \n\n7. Least response time\n\n    A new request is sent to the service instance with the fastest response time.\n\n### URL, URI, URN - Do you know the differences? \n\nThe diagram below shows a comparison of URL, URI, and URN. \n\n<p>\n  <img src=\"images/url-uri-urn.jpg\" />\n</p>\n\n- URI \n\nURI stands for Uniform Resource Identifier. It identifies a logical or physical resource on the web. URL and URN are subtypes of URI. URL locates a resource, while URN names a resource. \n\nA URI is composed of the following parts: \nscheme:[//authority]path[?query][#fragment] \n\n- URL \n\nURL stands for Uniform Resource Locator, the key concept of HTTP. It is the address of a unique resource on the web. It can be used with other protocols like FTP and JDBC. \n\n- URN \n\nURN stands for Uniform Resource Name. It uses the urn scheme. URNs cannot be used to locate a resource. A simple example given in the diagram is composed of a namespace and a namespace-specific string. \n\nIf you would like to learn more detail on the subject, I would recommend [W3C’s clarification](https://www.w3.org/TR/uri-clarification/).\n\n## CI/CD\n\n### CI/CD Pipeline Explained in Simple Terms\n\n<p>\n  <img src=\"images/ci-cd-pipeline.jpg\" style=\"width: 680px\" />\n</p>\n\nSection 1 - SDLC with CI/CD\n\nThe software development life cycle (SDLC) consists of several key stages: development, testing, deployment, and maintenance. CI/CD automates and integrates these stages to enable faster and more reliable releases.\n\nWhen code is pushed to a git repository, it triggers an automated build and test process. End-to-end (e2e) test cases are run to validate the code. If tests pass, the code can be automatically deployed to staging/production. If issues are found, the code is sent back to development for bug fixing. This automation provides fast feedback to developers and reduces the risk of bugs in production.\n\nSection 2 - Difference between CI and CD\n\nContinuous Integration (CI) automates the build, test, and merge process. It runs tests whenever code is committed to detect integration issues early. This encourages frequent code commits and rapid feedback.\n\nContinuous Delivery (CD) automates release processes like infrastructure changes and deployment. It ensures software can be released reliably at any time through automated workflows. CD may also automate the manual testing and approval steps required before production deployment.\n\nSection 3 - CI/CD Pipeline\n\nA typical CI/CD pipeline has several connected stages:\n- The developer commits code changes to the source control\n- CI server detects changes and triggers the build\n- Code is compiled, and tested (unit, integration tests)\n- Test results reported to the developer\n- On success, artifacts are deployed to staging environments\n- Further testing may be done on staging before release\n- CD system deploys approved changes to production\n\n### Netflix Tech Stack (CI/CD Pipeline)\n\n<p>\n  <img src=\"images/netflix-ci-cd.jpg\" style=\"width: 720px\" />\n</p>\n\nPlanning: Netflix Engineering uses JIRA for planning and Confluence for documentation. \n\nCoding: Java is the primary programming language for the backend service, while other languages are used for different use cases.  \n\nBuild: Gradle is mainly used for building, and Gradle plugins are built to support various use cases.  \n\nPackaging: Package and dependencies are packed into an Amazon Machine Image (AMI) for release. \n\nTesting: Testing emphasizes the production culture's focus on building chaos tools.  \n\nDeployment: Netflix uses its self-built Spinnaker for canary rollout deployment.  \n\nMonitoring: The monitoring metrics are centralized in Atlas, and Kayenta is used to detect anomalies.  \n\nIncident report: Incidents are dispatched according to priority, and PagerDuty is used for incident handling. \n\n## Architecture patterns\n\n### MVC, MVP, MVVM, MVVM-C, and VIPER\nThese architecture patterns are among the most commonly used in app development, whether on iOS or Android platforms. Developers have introduced them to overcome the limitations of earlier patterns. So, how do they differ? \n\n<p>\n  <img src=\"images/client arch patterns.png\" style=\"width: 720px\" />\n</p>\n\n- MVC, the oldest pattern, dates back almost 50 years \n- Every pattern has a \"view\" (V) responsible for displaying content and receiving user input \n- Most patterns include a \"model\" (M) to manage business data \n- \"Controller,\" \"presenter,\" and \"view-model\" are translators that mediate between the view and the model (\"entity\" in the VIPER pattern)\n\n### 18 Key Design Patterns Every Developer Should Know\n\nPatterns are reusable solutions to common design problems, resulting in a smoother, more efficient development process. They serve as blueprints for building better software structures. These are some of the most popular patterns: \n\n<p>\n  <img src=\"images/18-oo-patterns.png\" />\n</p>\n\n- Abstract Factory: Family Creator - Makes groups of related items. \n- Builder: Lego Master - Builds objects step by step, keeping creation and appearance separate. \n- Prototype: Clone Maker - Creates copies of fully prepared examples. \n- Singleton: One and Only - A special class with just one instance. \n- Adapter: Universal Plug - Connects things with different interfaces. \n- Bridge: Function Connector - Links how an object works to what it does. \n- Composite: Tree Builder - Forms tree-like structures of simple and complex parts. \n- Decorator: Customizer - Adds features to objects without changing their core. \n- Facade: One-Stop-Shop - Represents a whole system with a single, simplified interface. \n- Flyweight: Space Saver - Shares small, reusable items efficiently. \n- Proxy: Stand-In Actor - Represents another object, controlling access or actions. \n- Chain of Responsibility: Request Relay - Passes a request through a chain of objects until handled. \n- Command: Task Wrapper - Turns a request into an object, ready for action. \n- Iterator: Collection Explorer - Accesses elements in a collection one by one. \n- Mediator: Communication Hub - Simplifies interactions between different classes. \n- Memento: Time Capsule - Captures and restores an object's state. \n- Observer: News Broadcaster - Notifies classes about changes in other objects. \n- Visitor: Skillful Guest - Adds new operations to a class without altering it.\n\n## Database\n\n### A nice cheat sheet of different databases in cloud services\n\n<p>\n  <img src=\"images/cloud-dbs2.png\" />\n</p>\n\nChoosing the right database for your project is a complex task. Many database options, each suited to distinct use cases, can quickly lead to decision fatigue. \n\nWe hope this cheat sheet provides high-level direction to pinpoint the right service that aligns with your project's needs and avoid potential pitfalls. \n\nNote: Google has limited documentation for their database use cases. Even though we did our best to look at what was available and arrived at the best option, some of the entries may need to be more accurate. \n\n### 8 Data Structures That Power Your Databases\n\nThe answer will vary depending on your use case. Data can be indexed in memory or on disk. Similarly, data formats vary, such as numbers, strings, geographic coordinates, etc. The system might be write-heavy or read-heavy. All of these factors affect your choice of database index format. \n\n<p>\n  <img src=\"images/8-ds-db.jpg\" />\n</p>\n\nThe following are some of the most popular data structures used for indexing data: \n\n- Skiplist: a common in-memory index type. Used in Redis \n- Hash index: a very common implementation of the “Map” data structure (or “Collection”) \n- SSTable: immutable on-disk “Map” implementation \n- LSM tree: Skiplist + SSTable. High write throughput \n- B-tree: disk-based solution. Consistent read/write performance \n- Inverted index: used for document indexing. Used in Lucene \n- Suffix tree: for string pattern search \n- R-tree: multi-dimension search, such as finding the nearest neighbor \n\n### How is an SQL statement executed in the database?\n\nThe diagram below shows the process. Note that the architectures for different databases are different, the diagram demonstrates some common designs.\n\n<p>\n  <img src=\"images/sql execution order in db.jpeg\" style=\"width: 580px\" />\n</p>\n\n\nStep 1 - A SQL statement is sent to the database via a transport layer protocol (e.g.TCP).\n\nStep 2 - The SQL statement is sent to the command parser, where it goes through syntactic and semantic analysis, and a query tree is generated afterward.\n\nStep 3 - The query tree is sent to the optimizer. The optimizer creates an execution plan. \n\nStep 4 - The execution plan is sent to the executor. The executor retrieves data from the execution.\n\nStep 5 - Access methods provide the data fetching logic required for execution, retrieving data from the storage engine. \n\nStep 6 - Access methods decide whether the SQL statement is read-only. If the query is read-only (SELECT statement), it is passed to the buffer manager for further processing. The buffer manager looks for the data in the cache or data files.\n\nStep 7 - If the statement is an UPDATE or INSERT, it is passed to the transaction manager for further processing.\n\nStep 8 - During a transaction, the data is in lock mode. This is guaranteed by the lock manager. It also ensures the transaction’s ACID properties. \n\n###  CAP theorem\n\nThe CAP theorem is one of the most famous terms in computer science, but I bet different developers have different understandings. Let’s examine what it is and why it can be confusing. \n\n<p>\n  <img src=\"images/cap theorem.jpeg\" />\n</p>\n\nCAP theorem states that a distributed system can't provide more than two of these three guarantees simultaneously.\n\n**Consistency**: consistency means all clients see the same data at the same time no matter which node they connect to.\n\n**Availability**: availability means any client that requests data gets a response even if some of the nodes are down.\n\n**Partition Tolerance**: a partition indicates a communication break between two nodes. Partition tolerance means the system continues to operate despite network partitions. \n\nThe “2 of 3” formulation can be useful, **but this simplification could be misleading**.\n\n1. Picking a database is not easy. Justifying our choice purely based on the CAP theorem is not enough. For example, companies don't choose Cassandra for chat applications simply because it is an AP system. There is a list of good characteristics that make Cassandra a desirable option for storing chat messages. We need to dig deeper.\n\n2. “CAP prohibits only a tiny part of the design space: perfect availability and consistency in the presence of partitions, which are rare”. Quoted from the paper: CAP Twelve Years Later: How the “Rules” Have Changed.\n\n3. The theorem is about 100% availability and consistency. A more realistic discussion would be the trade-offs between latency and consistency when there is no network partition. See PACELC theorem for more details.\n\n**Is the CAP theorem actually useful?**\n\nI think it is still useful as it opens our minds to a set of tradeoff discussions, but it is only part of the story. We need to dig deeper when picking the right database.\n\n### Types of Memory and Storage\n\n<p>\n  <img src=\"images/Types_of_Memory_and_Storage.jpeg\" style=\"width: 420px\" />\n</p>\n\n\n### Visualizing a SQL query\n\n<p>\n  <img src=\"images/sql-execution-order.jpg\" style=\"width: 580px\" />\n</p>\n\nSQL statements are executed by the database system in several steps, including: \n\n- Parsing the SQL statement and checking its validity \n- Transforming the SQL into an internal representation, such as relational algebra \n- Optimizing the internal representation and creating an execution plan that utilizes index information \n- Executing the plan and returning the results \n\nThe execution of SQL is highly complex and involves many considerations, such as: \n\n- The use of indexes and caches \n- The order of table joins \n- Concurrency control \n- Transaction management \n\n### SQL language \n\nIn 1986, SQL (Structured Query Language) became a standard. Over the next 40 years, it became the dominant language for relational database management systems. Reading the latest standard (ANSI SQL 2016) can be time-consuming. How can I learn it? \n\n<p>\n  <img src=\"images/how-to-learn-sql.jpg\" />\n</p>\n\nThere are 5 components of the SQL language: \n\n- DDL: data definition language, such as CREATE, ALTER, DROP \n- DQL: data query language, such as SELECT \n- DML: data manipulation language, such as INSERT, UPDATE, DELETE \n- DCL: data control language, such as GRANT, REVOKE \n- TCL: transaction control language, such as COMMIT, ROLLBACK \n\nFor a backend engineer, you may need to know most of it. As a data analyst, you may need to have a good understanding of DQL. Select the topics that are most relevant to you. \n\n## Cache\n\n### Data is cached everywhere\n\nThis diagram illustrates where we cache data in a typical architecture.\n\n<p>\n  <img src=\"images/where do we cache data.jpeg\" style=\"width: 720px\" />\n</p>\n\n\nThere are **multiple layers** along the flow.\n\n1. Client apps: HTTP responses can be cached by the browser. We request data over HTTP for the first time, and it is returned with an expiry policy in the HTTP header; we request data again, and the client app tries to retrieve the data from the browser cache first.\n2. CDN: CDN caches static web resources. The clients can retrieve data from a CDN node nearby.\n3. Load Balancer: The load Balancer can cache resources as well.\n4. Messaging infra: Message brokers store messages on disk first, and then consumers retrieve them at their own pace. Depending on the retention policy, the data is cached in Kafka clusters for a period of time.\n5. Services: There are multiple layers of cache in a service. If the data is not cached in the CPU cache, the service will try to retrieve the data from memory. Sometimes the service has a second-level cache to store data on disk.\n6. Distributed Cache: Distributed cache like Redis holds key-value pairs for multiple services in memory. It provides much better read/write performance than the database.\n7. Full-text Search: we sometimes need to use full-text searches like Elastic Search for document search or log search. A copy of data is indexed in the search engine as well.\n8. Database: Even in the database, we have different levels of caches:\n- WAL(Write-ahead Log): data is written to WAL first before building the B tree index\n- Bufferpool: A memory area allocated to cache query results\n- Materialized View: Pre-compute query results and store them in the database tables for better query performance\n- Transaction log: record all the transactions and database updates\n- Replication Log: used to record the replication state in a database cluster\n\n### Why is Redis so fast? \n\nThere are 3 main reasons as shown in the diagram below.\n\n<p>\n  <img src=\"images/why_redis_fast.jpeg\" />\n</p>\n\n\n1. Redis is a RAM-based data store. RAM access is at least 1000 times faster than random disk access.\n2. Redis leverages IO multiplexing and single-threaded execution loop for execution efficiency.\n3. Redis leverages several efficient lower-level data structures.\n\nQuestion: Another popular in-memory store is Memcached. Do you know the differences between Redis and Memcached?\n\nYou might have noticed the style of this diagram is different from my previous posts. Please let me know which one you prefer.\n\n### How can Redis be used?\n\n<p>\n  <img src=\"images/top-redis-use-cases.jpg\" style=\"width: 520px\" />\n</p>\n\n\nThere is more to Redis than just caching. \n\nRedis can be used in a variety of scenarios as shown in the diagram. \n\n- Session \n\n  We can use Redis to share user session data among different services. \n\n- Cache \n\n  We can use Redis to cache objects or pages, especially for hotspot data. \n\n- Distributed lock \n\n  We can use a Redis string to acquire locks among distributed services. \n\n- Counter \n\n  We can count how many likes or how many reads for articles. \n\n- Rate limiter \n\n  We can apply a rate limiter for certain user IPs. \n\n- Global ID generator \n\n  We can use Redis Int for global ID. \n\n- Shopping cart \n\n  We can use Redis Hash to represent key-value pairs in a shopping cart. \n\n- Calculate user retention \n\n  We can use Bitmap to represent the user login daily and calculate user retention. \n\n- Message queue \n\n  We can use List for a message queue. \n\n- Ranking \n\n  We can use ZSet to sort the articles. \n\n### Top caching strategies\n\nDesigning large-scale systems usually requires careful consideration of caching. \nBelow are five caching strategies that are frequently utilized. \n\n<p>\n  <img src=\"images/top_caching_strategy.jpeg\" style=\"width: 680px\" />\n</p>\n\n\n\n## Microservice architecture\n\n### What does a typical microservice architecture look like? \n\n<p>\n  <img src=\"images/typical-microservice-arch.jpg\" style=\"width: 520px\" />\n</p>\n\n\nThe diagram below shows a typical microservice architecture. \n\n- Load Balancer: This distributes incoming traffic across multiple backend services. \n- CDN (Content Delivery Network): CDN is a group of geographically distributed servers that hold static content for faster delivery. The clients look for content in CDN first, then progress  to backend services.\n- API Gateway: This handles incoming requests and routes them to the relevant services. It talks to the identity provider and service discovery.\n- Identity Provider: This handles authentication and authorization for users. \n- Service Registry & Discovery: Microservice registration and discovery happen in this component, and the API gateway looks for relevant services in this component to talk to. \n- Management: This component is responsible for monitoring the services.\n- Microservices: Microservices are designed and deployed in different domains. Each domain has its own database. The API gateway talks to the microservices via REST API or other protocols, and the microservices within the same domain talk to each other using RPC (Remote Procedure Call).\n\nBenefits of microservices:\n\n- They can be quickly designed, deployed, and horizontally scaled.\n- Each domain can be independently maintained by a dedicated team.\n- Business requirements can be customized in each domain and better supported, as a result.\n\n### Microservice Best Practices\n\nA picture is worth a thousand words: 9 best practices for developing microservices.\n\n<p>\n  <img src=\"images/microservice-best-practices.jpeg\" />\n</p>\n\n \nWhen we develop microservices, we need to follow the following best practices: \n\n1. Use separate data storage for each microservice \n2. Keep code at a similar level of maturity \n3. Separate build for each microservice \n4. Assign each microservice with a single responsibility \n5. Deploy into containers \n6. Design stateless services \n7. Adopt domain-driven design\n8. Design micro frontend \n9. Orchestrating microservices \n\n### What tech stack is commonly used for microservices?\n\nBelow you will find a diagram showing the microservice tech stack, both for the development phase and for production.\n\n<p>\n  <img src=\"images/microservice-tech.jpeg\" />\n</p>\n\n\n▶️ 𝐏𝐫𝐞-𝐏𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧\n\n- Define API - This establishes a contract between frontend and backend. We can use Postman or OpenAPI for this.\n- Development - Node.js or react is popular for frontend development, and java/python/go for backend development. Also, we need to change the configurations in the API gateway according to API definitions.\n- Continuous Integration - JUnit and Jenkins for automated testing. The code is packaged into a Docker image and deployed as microservices.\n\n▶️ 𝐏𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧\n\n- NGinx is a common choice for load balancers. Cloudflare provides CDN (Content Delivery Network). \n- API Gateway - We can use spring boot for the gateway, and use Eureka/Zookeeper for service discovery.\n- The microservices are deployed on clouds. We have options among AWS, Microsoft Azure, or Google GCP.\nCache and Full-text Search - Redis is a common choice for caching key-value pairs. Elasticsearch is used for full-text search.\n- Communications - For services to talk to each other, we can use messaging infra Kafka or RPC.\n- Persistence - We can use MySQL or PostgreSQL for a relational database, and Amazon S3 for object store. We can also use Cassandra for the wide-column store if necessary.\n- Management & Monitoring - To manage so many microservices, the common Ops tools include Prometheus, Elastic Stack, and Kubernetes.\n\n### Why is Kafka fast\n\nThere are many design decisions that contributed to Kafka’s performance. In this post, we’ll focus on two. We think these two carried the most weight.\n\n<p>\n  <img src=\"images/why_is_kafka_fast.jpeg\" />\n</p>\n\n1. The first one is Kafka’s reliance on Sequential I/O.\n2. The second design choice that gives Kafka its performance advantage is its focus on efficiency: zero copy principle.\n \nThe diagram illustrates how the data is transmitted between producer and consumer, and what zero-copy means.\n \n- Step 1.1 - 1.3: Producer writes data to the disk \n- Step 2: Consumer reads data without zero-copy\n\n2.1 The data is loaded from disk to OS cache\n\n2.2 The data is copied from OS cache to Kafka application\n\n2.3 Kafka application copies the data into the socket buffer \n\n2.4 The data is copied from socket buffer to network card\n\n2.5 The network card sends data out to the consumer\n\n \n- Step 3: Consumer reads data with zero-copy\n\n3.1: The data is loaded from disk to OS cache\n3.2 OS cache directly copies the data to the network card via sendfile() command\n3.3 The network card sends data out to the consumer\n \nZero copy is a shortcut to save the multiple data copies between application context and kernel context.\n\n## Payment systems\n\n### How to learn payment systems?\n\n<p>\n  <img src=\"images/learn-payments.jpg\" />\n</p>\n\n###  Why is the credit card called “the most profitable product in banks”? How does VISA/Mastercard make money? \n\nThe diagram below shows the economics of the credit card payment flow.\n\n<p>\n  <img src=\"images/how does visa makes money.jpg\" style=\"width: 640px\" />\n</p>\n\n1.&nbsp;&nbsp;The cardholder pays a merchant $100 to buy a product.\n\n2.&nbsp;The merchant benefits from the use of the credit card with higher sales volume and needs to compensate the issuer and the card network for providing the payment service. The acquiring bank sets a fee with the merchant, called the “merchant discount fee.”\n\n3 - 4. The acquiring bank keeps $0.25 as the acquiring markup, and $1.75 is paid to the issuing bank as the interchange fee. The merchant discount fee should cover the interchange fee. \n\n  The interchange fee is set by the card network because it is less efficient for each issuing bank to negotiate fees with each merchant.\n\n5.&nbsp;&nbsp;The card network sets up the network assessments and fees with each bank, which pays the card network for its services every month. For example, VISA charges a 0.11% assessment, plus a $0.0195 usage fee, for every swipe.\n\n6.&nbsp;&nbsp;The cardholder pays the issuing bank for its services.\n\nWhy should the issuing bank be compensated?\n\n- The issuer pays the merchant even if the cardholder fails to pay the issuer. \n- The issuer pays the merchant before the cardholder pays the issuer.\n- The issuer has other operating costs, including managing customer accounts, providing statements, fraud detection, risk management, clearing & settlement, etc. \n\n### How does VISA work when we swipe a credit card at a merchant’s shop?\n\n<p>\n  <img src=\"images/visa_payment.jpeg\" />\n</p>\n\n\nVISA, Mastercard, and American Express act as card networks for the clearing and settling of funds. The card acquiring bank and the card issuing bank can be – and often are – different. If banks were to settle transactions one by one without an intermediary, each bank would have to settle the transactions with all the other banks. This is quite inefficient.   \n \nThe diagram below shows VISA’s role in the credit card payment process. There are two flows involved. Authorization flow happens when the customer swipes the credit card. Capture and settlement flow happens when the merchant wants to get the money at the end of the day.\n \n- Authorization Flow\n\nStep 0: The card issuing bank issues credit cards to its customers. \n \nStep 1: The cardholder wants to buy a product and swipes the credit card at the Point of Sale (POS) terminal in the merchant’s shop.\n \nStep 2: The POS terminal sends the transaction to the acquiring bank, which has provided the POS terminal.\n \nSteps 3 and 4: The acquiring bank sends the transaction to the card network, also called the card scheme. The card network sends the transaction to the issuing bank for approval.\n \nSteps 4.1, 4.2 and 4.3: The issuing bank freezes the money if the transaction is approved. The approval or rejection is sent back to the acquirer, as well as the POS terminal. \n \n- Capture and Settlement Flow\n\nSteps 1 and 2: The merchant wants to collect the money at the end of the day, so they hit ”capture” on the POS terminal. The transactions are sent to the acquirer in batch. The acquirer sends the batch file with transactions to the card network.\n \nStep 3: The card network performs clearing for the transactions collected from different acquirers, and sends the clearing files to different issuing banks.\n \nStep 4: The issuing banks confirm the correctness of the clearing files, and transfer money to the relevant acquiring banks.\n \nStep 5: The acquiring bank then transfers money to the merchant’s bank. \n \nStep 4: The card network clears up the transactions from different acquiring banks. Clearing is a process in which mutual offset transactions are netted, so the number of total transactions is reduced.\n \nIn the process, the card network takes on the burden of talking to each bank and receives service fees in return.\n\n### Payment Systems Around The World Series (Part 1): Unified Payments Interface (UPI) in India\n\n\nWhat’s UPI? UPI is an instant real-time payment system developed by the National Payments Corporation of India.\n\nIt accounts for 60% of digital retail transactions in India today.\n\nUPI = payment markup language + standard for interoperable payments\n\n\n<p>\n  <img src=\"images/how-does-upi-work.png\"  style=\"width: 600px\" />\n</p>\n\n\n## DevOps\n\n###  DevOps vs. SRE vs. Platform Engineering. What is the difference?\n\nThe concepts of DevOps, SRE, and Platform Engineering have emerged at different times and have been developed by various individuals and organizations. \n\n<p>\n  <img src=\"images/devops-sre-platform.jpg\" />\n</p>\n\nDevOps as a concept was introduced in 2009 by Patrick Debois and Andrew Shafer at the Agile conference. They sought to bridge the gap between software development and operations by promoting a collaborative culture and shared responsibility for the entire software development lifecycle. \n\nSRE, or Site Reliability Engineering, was pioneered by Google in the early 2000s to address operational challenges in managing large-scale, complex systems. Google developed SRE practices and tools, such as the Borg cluster management system and the Monarch monitoring system, to improve the reliability and efficiency of their services. \n\nPlatform Engineering is a more recent concept, building on the foundation of SRE engineering. The precise origins of Platform Engineering are less clear, but it is generally understood to be an extension of the DevOps and SRE practices, with a focus on delivering a comprehensive platform for product development that supports the entire business perspective. \n\nIt's worth noting that while these concepts emerged at different times. They are all related to the broader trend of improving collaboration, automation, and efficiency in software development and operations. \n\n### What is k8s (Kubernetes)?\n\nK8s is a container orchestration system. It is used for container deployment and management. Its design is greatly impacted by Google’s internal system Borg.\n\n<p>\n  <img src=\"images/k8s.jpeg\" style=\"width: 680px\" />\n</p>\n\nA k8s cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node.\n\nThe worker node(s) host the Pods that are the components of the application workload. The control plane manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers, and a cluster usually runs multiple nodes, providing fault tolerance and high availability.\n\n- Control Plane Components\n\n1. API Server\n\n    The API server talks to all the components in the k8s cluster. All the operations on pods are executed by talking to the API server.\n\n2. Scheduler\n\n    The scheduler watches pod workloads and assigns loads on newly created pods.\n\n3. Controller Manager\n\n    The controller manager runs the controllers, including Node Controller, Job Controller, EndpointSlice Controller, and ServiceAccount Controller.\n\n4. Etcd\n    \n    etcd is a key-value store used as Kubernetes' backing store for all cluster data.\n\n- Nodes\n\n1. Pods\n\n    A pod is a group of containers and is the smallest unit that k8s administers. Pods have a single IP address applied to every container within the pod.\n\n2. Kubelet\n\n    An agent that runs on each node in the cluster. It ensures containers are running in a Pod.\n\n3. Kube Proxy\n\n    Kube-proxy is a network proxy that runs on each node in your cluster. It routes traffic coming into a node from the service. It forwards requests for work to the correct containers.\n\n### Docker vs. Kubernetes. Which one should we use? \n\n<p>\n  <img src=\"images/docker-vs-k8s.jpg\" style=\"width: 680px\" />\n</p>\n\n\nWhat is Docker ? \n\nDocker is an open-source platform that allows you to package, distribute, and run applications in isolated containers. It focuses on containerization, providing lightweight environments that encapsulate applications and their dependencies. \n\nWhat is Kubernetes ? \n\nKubernetes, often referred to as K8s, is an open-source container orchestration platform. It provides a framework for automating the deployment, scaling, and management of containerized applications across a cluster of nodes. \n\nHow are both different from each other ? \n\nDocker: Docker operates at the individual container level on a single operating system host. \n\nYou must manually manage each host and setting up networks, security policies, and storage for multiple related containers can be complex. \n\nKubernetes: Kubernetes operates at the cluster level. It manages multiple containerized applications across multiple hosts, providing automation for tasks like load balancing, scaling, and ensuring the desired state of applications. \n\nIn short, Docker focuses on containerization and running containers on individual hosts, while Kubernetes specializes in managing and orchestrating containers at scale across a cluster of hosts. \n\n### How does Docker work? \n\nThe diagram below shows the architecture of Docker and how it works when we run “docker build”, “docker pull” \nand “docker run”. \n\n<p>\n  <img src=\"images/docker.jpg\" style=\"width: 680px\" />\n</p>\n\nThere are 3 components in Docker architecture: \n\n- Docker client \n    \n    The docker client talks to the Docker daemon. \n\n- Docker host \n\n    The Docker daemon listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. \n\n- Docker registry \n\n    A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use. \n\nLet’s take the “docker run” command as an example. \n\n  1. Docker pulls the image from the registry. \n  1. Docker creates a new container. \n  1. Docker allocates a read-write filesystem to the container. \n  1. Docker creates a network interface to connect the container to the default network. \n  1. Docker starts the container.\n\n## GIT\n\n### How Git Commands work\n\nTo begin with, it's essential to identify where our code is stored. The common assumption is that there are only two locations - one on a remote server like Github and the other on our local machine. However, this isn't entirely accurate. Git maintains three local storages on our machine, which means that our code can be found in four places: \n\n<p>\n  <img src=\"images/git-commands.png\" style=\"width: 600px\" />\n</p>\n\n\n- Working directory: where we edit files \n- Staging area: a temporary location where files are kept for the next commit \n- Local repository: contains the code that has been committed \n- Remote repository: the remote server that stores the code \n\nMost Git commands primarily move files between these four locations. \n\n### How does Git Work?\n\nThe diagram below shows the Git workflow. \n\n<p>\n  <img src=\"images/git-workflow.jpeg\" style=\"width: 520px\" />\n</p>\n\n\nGit is a distributed version control system. \n\nEvery developer maintains a local copy of the main repository and edits and commits to the local copy. \n\nThe commit is very fast because the operation doesn’t interact with the remote repository. \n\nIf the remote repository crashes, the files can be recovered from the local repositories. \n\n### Git merge vs. Git rebase\n\nWhat are the differences?\n\n<p>\n  <img src=\"images/git-merge-git-rebase.jpeg\" style=\"width: 680px\" />\n</p>\n\n\nWhen we **merge changes** from one Git branch to another, we can use ‘git merge’ or ‘git rebase’. The diagram below shows how the two commands work.\n\n**Git merge**\n\nThis creates a new commit G’ in the main branch. G’ ties the histories of both main and feature branches.\n\nGit merge is **non-destructive**. Neither the main nor the feature branch is changed.\n\n**Git rebase**\n\nGit rebase moves the feature branch histories to the head of the main branch. It creates new commits E’, F’, and G’ for each commit in the feature branch.\n\nThe benefit of rebase is that it has a linear **commit history**.\n\nRebase can be dangerous if “the golden rule of git rebase” is not followed.\n\n**The Golden Rule of Git Rebase**\n\nNever use it on public branches!\n\n## Cloud Services\n\n### A nice cheat sheet of different cloud services (2023 edition)\n\n<p>\n  <img src=\"images/cloud-compare.jpg\" />\n</p>\n\n\n### What is cloud native?\n\nBelow is a diagram showing the evolution of architecture and processes since the 1980s. \n\n<p>\n  <img src=\"images/cloud-native.jpeg\" style=\"width: 640px\" />\n</p>\n\nOrganizations can build and run scalable applications on public, private, and hybrid clouds using cloud native technologies. \n\nThis means the applications are designed to leverage cloud features, so they are resilient to load and easy to scale. \n\nCloud native includes 4 aspects: \n\n1. Development process \n\n    This has progressed from waterfall to agile to DevOps. \n\n2. Application Architecture \n\n    The architecture has gone from monolithic to microservices. Each service is designed to be small, adaptive to the limited resources in cloud containers. \n\n3. Deployment & packaging \n\n    The applications used to be deployed on physical servers. Then around 2000, the applications that were not sensitive to latency were usually deployed on virtual servers. With cloud native applications, they are packaged into docker images and deployed in containers. \n\n4. Application infrastructure \n\n    The applications are massively deployed on cloud infrastructure instead of self-hosted servers. \n\n## Developer productivity tools\n\n### Visualize JSON files\n\nNested JSON files are hard to read.\n\n**JsonCrack** generates graph diagrams from JSON files and makes them easy to read.\n\nAdditionally, the generated diagrams can be downloaded as images.\n\n<p>\n  <img src=\"images/json-cracker.jpeg\" />\n</p>\n\n\n### Automatically turn code into architecture diagrams\n\n<p>\n  <img src=\"images/diagrams_as_code.jpeg\" style=\"width: 640px\" />\n</p>\n\n\nWhat does it do?\n\n- Draw the cloud system architecture in Python code.\n- Diagrams can also be rendered directly inside the Jupyter Notebooks.\n- No design tools are needed. \n- Supports the following providers: AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud, etc. \n \n[Github repo](https://github.com/mingrammer/diagrams)\n\n## Linux\n\n### Linux file system explained\n\n<p>\n  <img src=\"images/linux-file-systems.jpg\" style=\"width: 680px\" />\n</p>\n\nThe Linux file system used to resemble an unorganized town where individuals constructed their houses wherever they pleased. However, in 1994, the Filesystem Hierarchy Standard (FHS) was introduced to bring order to the Linux file system.\n\nBy implementing a standard like the FHS, software can ensure a consistent layout across various Linux distributions. Nonetheless, not all Linux distributions strictly adhere to this standard. They often incorporate their own unique elements or cater to specific requirements.\nTo become proficient in this standard, you can begin by exploring. Utilize commands such as \"cd\" for navigation and \"ls\" for listing directory contents. Imagine the file system as a tree, starting from the root (/). With time, it will become second nature to you, transforming you into a skilled Linux administrator.\n\n### 18 Most-used Linux Commands You Should Know \n\nLinux commands are instructions for interacting with the operating system. They help manage files, directories, system processes, and many other aspects of the system. You need to become familiar with these commands in order to navigate and maintain Linux-based systems efficiently and effectively. \n\nThis diagram below shows popular Linux commands: \n\n<p>\n  <img src=\"images/18 Most-Used Linux Commands You Should Know-01.jpeg\" style=\"width: 680px\" />\n</p>\n\n\n- ls - List files and directories \n- cd - Change the current directory \n- mkdir - Create a new directory \n- rm - Remove files or directories \n- cp - Copy files or directories \n- mv - Move or rename files or directories \n- chmod - Change file or directory permissions \n- grep - Search for a pattern in files \n- find - Search for files and directories \n- tar - manipulate tarball archive files \n- vi - Edit files using text editors \n- cat - display the content of files \n- top - Display processes and resource usage \n- ps - Display processes information \n- kill - Terminate a process by sending a signal \n- du - Estimate file space usage \n- ifconfig - Configure network interfaces  \n- ping - Test network connectivity between hosts \n\n## Security\n\n### How does HTTPS work?\n\nHypertext Transfer Protocol Secure (HTTPS) is an extension of the Hypertext Transfer Protocol (HTTP.) HTTPS transmits encrypted data using Transport Layer Security (TLS.) If the data is hijacked online, all the hijacker gets is binary code. \n\n<p>\n  <img src=\"images/https.jpg\" />\n</p>\n\n\nHow is the data encrypted and decrypted?\n\nStep 1 - The client (browser) and the server establish a TCP connection.\n\nStep 2 - The client sends a “client hello” to the server. The message contains a set of necessary encryption algorithms (cipher suites) and the latest TLS version it can support. The server responds with a “server hello” so the browser knows whether it can support the algorithms and TLS version.\n\nThe server then sends the SSL certificate to the client. The certificate contains the public key, host name, expiry dates, etc. The client validates the certificate. \n\nStep 3 - After validating the SSL certificate, the client generates a session key and encrypts it using the public key. The server receives the encrypted session key and decrypts it with the private key. \n\nStep 4 - Now that both the client and the server hold the same session key (symmetric encryption), the encrypted data is transmitted in a secure bi-directional channel.\n\nWhy does HTTPS switch to symmetric encryption during data transmission? There are two main reasons:\n\n1. Security: The asymmetric encryption goes only one way. This means that if the server tries to send the encrypted data back to the client, anyone can decrypt the data using the public key.\n\n2. Server resources: The asymmetric encryption adds quite a lot of mathematical overhead. It is not suitable for data transmissions in long sessions.\n\n### Oauth 2.0 Explained With Simple Terms. \n\nOAuth 2.0 is a powerful and secure framework that allows different applications to securely interact with each other on behalf of users without sharing sensitive credentials. \n\n<p>\n  <img src=\"images/oAuth2.jpg\" />\n</p>\n\nThe entities involved in OAuth are the User, the Server, and the Identity Provider (IDP). \n\nWhat Can an OAuth Token Do? \n\nWhen you use OAuth, you get an OAuth token that represents your identity and permissions. This token can do a few important things: \n\nSingle Sign-On (SSO): With an OAuth token, you can log into multiple services or apps using just one login, making life easier and safer. \n\nAuthorization Across Systems: The OAuth token allows you to share your authorization or access rights across various systems, so you don't have to log in separately everywhere. \n\nAccessing User Profile: Apps with an OAuth token can access certain parts of your user profile that you allow, but they won't see everything. \n\nRemember, OAuth 2.0 is all about keeping you and your data safe while making your online experiences seamless and hassle-free across different applications and services.\n\n### Top 4 Forms of Authentication Mechanisms \n\n<p>\n  <img src=\"images/top4-most-used-auth.jpg\" />\n</p>\n\n1. SSH Keys: \n   \n    Cryptographic keys are used to access remote systems and servers securely \n\n1. OAuth Tokens: \n\n    Tokens that provide limited access to user data on third-party applications \n\n1. SSL Certificates: \n  \n    Digital certificates ensure secure and encrypted communication between servers and clients \n\n1. Credentials: \n\n    User authentication information is used to verify and grant access to various systems and services\n\n### Session, cookie, JWT, token, SSO, and OAuth 2.0 - what are they?\n\nThese terms are all related to user identity management. When you log into a website, you declare who you are (identification). Your identity is verified (authentication), and you are granted the necessary permissions (authorization). Many solutions have been proposed in the past, and the list keeps growing.\n\n<p>\n  <img src=\"images/session.jpeg\" />\n</p>\n\nFrom simple to complex, here is my understanding of user identity management:\n\n- WWW-Authenticate is the most basic method. You are asked for the username and password by the browser. As a result of the inability to control the login life cycle, it is seldom used today.\n\n- A finer control over the login life cycle is session-cookie. The server maintains session storage, and the browser keeps the ID of the session. A cookie usually only works with browsers and is not mobile app friendly.\n\n- To address the compatibility issue, the token can be used. The client sends the token to the server, and the server validates the token. The downside is that the token needs to be encrypted and decrypted, which may be time-consuming.\n\n- JWT is a standard way of representing tokens. This information can be verified and trusted because it is digitally signed. Since JWT contains the signature, there is no need to save session information on the server side.\n\n- By using SSO (single sign-on), you can sign on only once and log in to multiple websites. It uses CAS (central authentication service) to maintain cross-site information.\n\n- By using OAuth 2.0, you can authorize one website to access your information on another website.\n\n### How to store passwords safely in the database and how to validate a password? \n\n<p>\n  <img src=\"images/salt.jpg\" style=\"width: 720px\" />\n</p>\n\n \n**Things NOT to do**\n\n- Storing passwords in plain text is not a good idea because anyone with internal access can see them.\n\n- Storing password hashes directly is not sufficient because it is pruned to precomputation attacks, such as rainbow tables. \n\n- To mitigate precomputation attacks, we salt the passwords. \n\n**What is salt?**\n\nAccording to OWASP guidelines, “a salt is a unique, randomly generated string that is added to each password as part of the hashing process”.\n \n**How to store a password and salt?**\n\n1. the hash result is unique to each password.\n1. The password can be stored in the database using the following format: hash(password + salt).\n\n**How to validate a password?**\n\nTo validate a password, it can go through the following process:\n\n1. A client enters the password.\n1. The system fetches the corresponding salt from the database.\n1. The system appends the salt to the password and hashes it. Let’s call the hashed value H1.\n1. The system compares H1 and H2, where H2 is the hash stored in the database. If they are the same, the password is valid. \n\n### Explaining JSON Web Token (JWT) to a 10 year old Kid\n\n<p>\n  <img src=\"images/jwt.jpg\" />\n</p>\n\nImagine you have a special box called a JWT. Inside this box, there are three parts: a header, a payload, and a signature.\n\nThe header is like the label on the outside of the box. It tells us what type of box it is and how it's secured. It's usually written in a format called JSON, which is just a way to organize information using curly braces { } and colons : .\n\nThe payload is like the actual message or information you want to send. It could be your name, age, or any other data you want to share. It's also written in JSON format, so it's easy to understand and work with.\nNow, the signature is what makes the JWT secure. It's like a special seal that only the sender knows how to create. The signature is created using a secret code, kind of like a password. This signature ensures that nobody can tamper with the contents of the JWT without the sender knowing about it.\n\nWhen you want to send the JWT to a server, you put the header, payload, and signature inside the box. Then you send it over to the server. The server can easily read the header and payload to understand who you are and what you want to do.\n\n### How does Google Authenticator (or other types of 2-factor authenticators) work?\n\nGoogle Authenticator is commonly used for logging into our accounts when 2-factor authentication is enabled. How does it guarantee security?\n \nGoogle Authenticator is a software-based authenticator that implements a two-step verification service. The diagram below provides detail. \n\n<p>\n  <img src=\"images/google_authenticate.jpeg\" />\n</p>\n\n\nThere are two stages involved:\n\n- Stage 1 - The user enables Google two-step verification. \n- Stage 2 - The user uses the authenticator for logging in, etc.\n\nLet’s look at these stages.\n \n**Stage 1**\n\nSteps 1 and 2: Bob opens the web page to enable two-step verification. The front end requests a secret key. The authentication service generates the secret key for Bob and stores it in the database.\n \nStep 3: The authentication service returns a URI to the front end. The URI is composed of a key issuer, username, and secret key. The URI is displayed in the form of a QR code on the web page.\n \nStep 4: Bob then uses Google Authenticator to scan the generated QR code. The secret key is stored in the authenticator.\n\n**Stage 2**\nSteps 1 and 2: Bob wants to log into a website with Google two-step verification. For this, he needs the password. Every 30 seconds, Google Authenticator generates a 6-digit password using TOTP (Time-based One Time Password) algorithm. Bob uses the password to enter the website.\n \nSteps 3 and 4: The frontend sends the password Bob enters to the backend for authentication. The authentication service reads the secret key from the database and generates a 6-digit password using the same TOTP algorithm as the client.\n \nStep 5: The authentication service compares the two passwords generated by the client and the server, and returns the comparison result to the frontend. Bob can proceed with the login process only if the two passwords match.\n \nIs this authentication mechanism safe? \n\n- Can the secret key be obtained by others? \n\n    We need to make sure the secret key is transmitted using HTTPS. The authenticator client and the database store the secret key, and we need to make sure the secret keys are encrypted.\n\n- Can the 6-digit password be guessed by hackers?\n    \n    No. The password has 6 digits, so the generated password has 1 million potential combinations. Plus, the password changes every 30 seconds. If hackers want to guess the password in 30 seconds, they need to enter 30,000 combinations per second.\n\n\n##  Real World Case Studies\n\n### Netflix's Tech Stack\n\nThis post is based on research from many Netflix engineering blogs and open-source projects. If you come across any inaccuracies, please feel free to inform us.\n\n<p>\n  <img src=\"images/netflix tech stack.png\" style=\"width: 680px\" />\n</p>\n\n**Mobile and web**: Netflix has adopted Swift and Kotlin to build native mobile apps. For its web application, it uses React.\n\n**Frontend/server communication**: Netflix uses GraphQL.\n\n**Backend services**: Netflix relies on ZUUL, Eureka, the Spring Boot framework, and other technologies.\n\n**Databases**: Netflix utilizes EV cache, Cassandra, CockroachDB, and other databases.\n\n**Messaging/streaming**: Netflix employs Apache Kafka and Fink for messaging and streaming purposes.\n\n**Video storage**: Netflix uses S3 and Open Connect for video storage.\n\n**Data processing**: Netflix utilizes Flink and Spark for data processing, which is then visualized using Tableau. Redshift is used for processing structured data warehouse information.\n\n**CI/CD**: Netflix employs various tools such as JIRA, Confluence, PagerDuty, Jenkins, Gradle, Chaos Monkey, Spinnaker, Atlas, and more for CI/CD processes.\n\n### Twitter Architecture 2022\n\nYes, this is the real Twitter architecture. It is posted by Elon Musk and redrawn by us for better readability. \n\n<p>\n  <img src=\"images/twitter-arch.jpeg\" />\n</p>\n\n\n### Evolution of Airbnb’s microservice architecture over the past 15 years\n\nAirbnb’s microservice architecture went through 3 main stages. \n\n<p>\n  <img src=\"images/airbnb_arch.jpeg\" />\n</p>\n\n\nMonolith (2008 - 2017)\n\nAirbnb began as a simple marketplace for hosts and guests. This is built in a Ruby on Rails application - the monolith. \n\nWhat’s the challenge?\n\n- Confusing team ownership + unowned code\n- Slow deployment \n\nMicroservices (2017 - 2020)\n\nMicroservice aims to solve those challenges. In the microservice architecture, key services include:\n\n- Data fetching service\n- Business logic data service\n- Write workflow service\n- UI aggregation service\n- Each service had one owning team\n\nWhat’s the challenge?\n\nHundreds of services and dependencies were difficult for humans to manage.\n\nMicro + macroservices (2020 - present)\n\nThis is what Airbnb is working on now. The micro and macroservice hybrid model focuses on the unification of APIs.\n\n### Monorepo vs. Microrepo. \n\nWhich is the best? Why do different companies choose different options? \n\n<p>\n  <img src=\"images/monorepo-microrepo.jpg\" />\n</p>\n\n\nMonorepo isn't new; Linux and Windows were both created using Monorepo. To improve scalability and build speed, Google developed its internal dedicated toolchain to scale it faster and strict coding quality standards to keep it consistent. \n\nAmazon and Netflix are major ambassadors of the Microservice philosophy. This approach naturally separates the service code into separate repositories. It scales faster but can lead to governance pain points later on. \n\nWithin Monorepo, each service is a folder, and every folder has a BUILD config and OWNERS permission control. Every service member is responsible for their own folder. \n\nOn the other hand, in Microrepo, each service is responsible for its repository, with the build config and permissions typically set for the entire repository. \n\nIn Monorepo, dependencies are shared across the entire codebase regardless of your business, so when there's a version upgrade, every codebase upgrades their version. \n\nIn Microrepo, dependencies are controlled within each repository. Businesses choose when to upgrade their versions based on their own schedules. \n\nMonorepo has a standard for check-ins. Google's code review process is famously known for setting a high bar, ensuring a coherent quality standard for Monorepo, regardless of the business. \n\nMicrorepo can either set its own standard or adopt a shared standard by incorporating the best practices. It can scale faster for business, but the code quality might be a bit different. \nGoogle engineers built Bazel, and Meta built Buck. There are other open-source tools available, including Nx, Lerna, and others. \n\nOver the years, Microrepo has had more supported tools, including Maven and Gradle for Java, NPM for NodeJS, and CMake for C/C++, among others. \n\n### How will you design the Stack Overflow website? \n\nIf your answer is on-premise servers and monolith (on the bottom of the following image), you would likely fail the interview, but that's how it is built in reality!\n\n<p>\n  <img src=\"images/stackoverflow.jpg\" />\n</p>\n\n\n**What people think it should look like**\n\nThe interviewer is probably expecting something like the top portion of the picture.\n\n- Microservice is used to decompose the system into small components.\n- Each service has its own database. Use cache heavily.\n- The service is sharded.\n- The services talk to each other asynchronously through message queues.\n- The service is implemented using Event Sourcing with CQRS.\n- Showing off knowledge in distributed systems such as eventual consistency, CAP theorem, etc.\n\n**What it actually is**\n\nStack Overflow serves all the traffic with only 9 on-premise web servers, and it’s on monolith! It has its own servers and does not run on the cloud.\n\nThis is contrary to all our popular beliefs these days. \n\n### Why did Amazon Prime Video monitoring move from serverless to monolithic? How can it save 90% cost?\n\nThe diagram below shows the architecture comparison before and after the migration. \n\n<p>\n  <img src=\"images/serverless-to-monolithic.jpeg\" />\n</p>\n\n\nWhat is Amazon Prime Video Monitoring Service? \n\nPrime Video service needs to monitor the quality of thousands of live streams. The monitoring tool automatically analyzes the streams in real time and identifies quality issues like block corruption, video freeze, and sync problems. This is an important process for customer satisfaction. \n\nThere are 3 steps: media converter, defect detector, and real-time notification. \n\n- What is the problem with the old architecture? \n\n  The old architecture was based on Amazon Lambda, which was good for building services quickly. However, it was not cost-effective when running the architecture at a high scale. The two most expensive operations are: \n\n1. The orchestration workflow - AWS step functions charge users by state transitions and the orchestration performs multiple state transitions every second. \n\n2. Data passing between distributed components - the intermediate data is stored in Amazon S3 so that the next stage can download. The download can be costly when the volume is high. \n\n- Monolithic architecture saves 90% cost \n\n  A monolithic architecture is designed to address the cost issues. There are still 3 components, but the media converter and defect detector are deployed in the same process, saving the cost of passing data over the network. Surprisingly, this approach to deployment architecture change led to 90% cost savings! \n\nThis is an interesting and unique case study because microservices have become a go-to and fashionable choice in the tech industry. It's good to see that we are having more discussions about evolving the architecture and having more honest discussions about its pros and cons. Decomposing components into distributed microservices comes with a cost. \n\n- What did Amazon leaders say about this? \n  \n  Amazon CTO Werner Vogels: “Building **evolvable software systems** is a strategy, not a religion. And revisiting your architecture with an open mind is a must.” \n\nEx Amazon VP Sustainability Adrian Cockcroft: “The Prime Video team had followed a path I call **Serverless First**…I don’t advocate **Serverless Only**”. \n\n### How does Disney Hotstar capture 5 Billion Emojis during a tournament?\n\n<p>\n  <img src=\"images/hotstar_emojis.jpeg\" style=\"width: 720px\" />\n</p>\n\n\n1. Clients send emojis through standard HTTP requests. You can think of Golang Service as a typical Web Server. Golang is chosen because it supports concurrency well. Threads in Golang are lightweight.\n\n2. Since the write volume is very high, Kafka (message queue) is used as a buffer.\n\n3. Emoji data are aggregated by a streaming processing service called Spark. It aggregates data every 2 seconds, which is configurable. There is a trade-off to be made based on the interval. A shorter interval means emojis are delivered to other clients faster but it also means more computing resources are needed.\n\n4. Aggregated data is written to another Kafka. \n\n5. The PubSub consumers pull aggregated emoji data from Kafka. \n\n6. Emojis are delivered to other clients in real-time through the PubSub infrastructure. The PubSub infrastructure is interesting. Hotstar considered the following protocols: Socketio, NATS, MQTT, and gRPC, and settled with MQTT.\n \nA similar design is adopted by LinkedIn which streams a million likes/sec.\n\n### How Discord Stores Trillions Of Messages \n\nThe diagram below shows the evolution of message storage at Discord: \n\n<p>\n  <img src=\"images/discord-store-messages.jpg\" />\n</p>\n\n\nMongoDB ➡️ Cassandra ➡️ ScyllaDB \n\nIn 2015, the first version of Discord was built on top of a single MongoDB replica. Around Nov 2015, MongoDB stored 100 million messages and the RAM couldn’t hold the data and index any longer. The latency became unpredictable. Message storage needs to be moved to another database. Cassandra was chosen. \n\nIn 2017, Discord had 12 Cassandra nodes and stored billions of messages. \n\nAt the beginning of 2022, it had 177 nodes with trillions of messages. At this point, latency was unpredictable, and maintenance operations became too expensive to run. \n\nThere are several reasons for the issue: \n\n- Cassandra uses the LSM tree for the internal data structure. The reads are more expensive than the writes. There can be many concurrent reads on a server with hundreds of users, resulting in hotspots. \n- Maintaining clusters, such as compacting SSTables, impacts performance. \n- Garbage collection pauses would cause significant latency spikes \n\nScyllaDB is Cassandra compatible database written in C++. Discord redesigned its architecture to have a monolithic API, a data service written in Rust, and ScyllaDB-based storage. \n\nThe p99 read latency in ScyllaDB is 15ms compared to 40-125ms in Cassandra. The p99 write latency is 5ms compared to 5-70ms in Cassandra. \n\n### How do video live streamings work on YouTube, TikTok live, or Twitch?\n \nLive streaming differs from regular streaming because the video content is sent via the internet in real-time, usually with a latency of just a few seconds.\n \nThe diagram below explains what happens behind the scenes to make this possible.\n\n<p>\n  <img src=\"images/live_streaming_updated.jpg\" style=\"width: 640px\" />\n</p>\n\n \nStep 1: The raw video data is captured by a microphone and camera. The data is sent to the server side.\n \nStep 2: The video data is compressed and encoded. For example, the compressing algorithm separates the background and other video elements. After compression, the video is encoded to standards such as H.264. The size of the video data is much smaller after this step.\n \nStep 3: The encoded data is divided into smaller segments, usually seconds in length, so it takes much less time to download or stream.\n \nStep 4: The segmented data is sent to the streaming server. The streaming server needs to support different devices and network conditions. This is called ‘Adaptive Bitrate Streaming.’ This means we need to produce multiple files at different bitrates in steps 2 and 3.\n \nStep 5: The live streaming data is pushed to edge servers supported by CDN (Content Delivery Network.) Millions of viewers can watch the video from an edge server nearby. CDN significantly lowers data transmission latency. \n \nStep 6: The viewers’ devices decode and decompress the video data and play the video in a video player.\n \nSteps 7 and 8: If the video needs to be stored for replay, the encoded data is sent to a storage server, and viewers can request a replay from it later.\n \nStandard protocols for live streaming include:\n\n- RTMP (Real-Time Messaging Protocol): This was originally developed by Macromedia to transmit data between a Flash player and a server. Now it is used for streaming video data over the internet. Note that video conferencing applications like Skype use RTC (Real-Time Communication) protocol for lower latency.\n- HLS (HTTP Live Streaming): It requires the H.264 or H.265 encoding. Apple devices accept only HLS format.\n- DASH (Dynamic Adaptive Streaming over HTTP): DASH does not support Apple devices.\n- Both HLS and DASH support adaptive bitrate streaming.\n\n## License\n\n<p xmlns:cc=\"http://creativecommons.org/ns#\" >This work is licensed under <a href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">CC BY-NC-ND 4.0<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1\"></a></p>\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "translations",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "bregman-arie/devops-exercises",
      "stars": 67298,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.07,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n*.pyc\n\n#Jetbrain's ides.\n.idea"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.15,
          "content": "language: \"python\"\npython:\n    - \"3.8\"\ninstall:\n    - pip install flake8\nscript:\n    - flake8 --max-line-length=100 .\n    - python tests/syntax_lint.py\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.7,
          "content": "## How to contribute\n\nUse pull requests to contribute to the project.\n\nStick to the following format:\n\n\\<details>\n<summary>[Question]</summary><br><b>\n\n[Answer]\n\\</b></details>\n\n* If you added several questions and you would like to know how many questions are there you can use the script \"count_questions.sh\" in scripts directory.\n\n## What to avoid\n\n* Avoid adding installation questions. Those are the worst type of questions...\n* Don't copy questions and answers from other sources. They probably worked hard for adding them.\n* If you add new images, make sure they are free and can be used.\n\n## Before submitting the pull request\n\nYou can test your changes locally with the script `run_ci.sh` in scripts directory.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 15.59,
          "content": "THE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS CREATIVE COMMONS PUBLIC LICENSE (\"CCPL\" OR \"LICENSE\"). THE WORK IS PROTECTED BY COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS AUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED.\n\nBY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE TO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY BE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND CONDITIONS.\n\n1. Definitions\n\"Adaptation\" means a work based upon the Work, or upon the Work and other pre-existing works, such as a translation, adaptation, derivative work, arrangement of music or other alterations of a literary or artistic work, or phonogram or performance and includes cinematographic adaptations or any other form in which the Work may be recast, transformed, or adapted including in any form recognizably derived from the original, except that a work that constitutes a Collection will not be considered an Adaptation for the purpose of this License. For the avoidance of doubt, where the Work is a musical work, performance or phonogram, the synchronization of the Work in timed-relation with a moving image (\"syncing\") will be considered an Adaptation for the purpose of this License.\n\"Collection\" means a collection of literary or artistic works, such as encyclopedias and anthologies, or performances, phonograms or broadcasts, or other works or subject matter other than works listed in Section 1(f) below, which, by reason of the selection and arrangement of their contents, constitute intellectual creations, in which the Work is included in its entirety in unmodified form along with one or more other contributions, each constituting separate and independent works in themselves, which together are assembled into a collective whole. A work that constitutes a Collection will not be considered an Adaptation (as defined above) for the purposes of this License.\n\"Distribute\" means to make available to the public the original and copies of the Work through sale or other transfer of ownership.\n\"Licensor\" means the individual, individuals, entity or entities that offer(s) the Work under the terms of this License.\n\"Original Author\" means, in the case of a literary or artistic work, the individual, individuals, entity or entities who created the Work or if no individual or entity can be identified, the publisher; and in addition (i) in the case of a performance the actors, singers, musicians, dancers, and other persons who act, sing, deliver, declaim, play in, interpret or otherwise perform literary or artistic works or expressions of folklore; (ii) in the case of a phonogram the producer being the person or legal entity who first fixes the sounds of a performance or other sounds; and, (iii) in the case of broadcasts, the organization that transmits the broadcast.\n\"Work\" means the literary and/or artistic work offered under the terms of this License including without limitation any production in the literary, scientific and artistic domain, whatever may be the mode or form of its expression including digital form, such as a book, pamphlet and other writing; a lecture, address, sermon or other work of the same nature; a dramatic or dramatico-musical work; a choreographic work or entertainment in dumb show; a musical composition with or without words; a cinematographic work to which are assimilated works expressed by a process analogous to cinematography; a work of drawing, painting, architecture, sculpture, engraving or lithography; a photographic work to which are assimilated works expressed by a process analogous to photography; a work of applied art; an illustration, map, plan, sketch or three-dimensional work relative to geography, topography, architecture or science; a performance; a broadcast; a phonogram; a compilation of data to the extent it is protected as a copyrightable work; or a work performed by a variety or circus performer to the extent it is not otherwise considered a literary or artistic work.\n\"You\" means an individual or entity exercising rights under this License who has not previously violated the terms of this License with respect to the Work, or who has received express permission from the Licensor to exercise rights under this License despite a previous violation.\n\"Publicly Perform\" means to perform public recitations of the Work and to communicate to the public those public recitations, by any means or process, including by wire or wireless means or public digital performances; to make available to the public Works in such a way that members of the public may access these Works from a place and at a place individually chosen by them; to perform the Work to the public by any means or process and the communication to the public of the performances of the Work, including by public digital performance; to broadcast and rebroadcast the Work by any means including signs, sounds or images.\n\"Reproduce\" means to make copies of the Work by any means including without limitation by sound or visual recordings and the right of fixation and reproducing fixations of the Work, including storage of a protected performance or phonogram in digital form or other electronic medium.\n\n2. Fair Dealing Rights. \nNothing in this License is intended to reduce, limit, or restrict any uses free from copyright or rights arising from limitations or exceptions that are provided for in connection with the copyright protection under copyright law or other applicable laws.\n\n3. License Grant. \nSubject to the terms and conditions of this License, Licensor hereby grants You a worldwide, royalty-free, non-exclusive, perpetual (for the duration of the applicable copyright) license to exercise the rights in the Work as stated below:\n\nto Reproduce the Work, to incorporate the Work into one or more Collections, and to Reproduce the Work as incorporated in the Collections; and,\nto Distribute and Publicly Perform the Work including as incorporated in Collections.\nThe above rights may be exercised in all media and formats whether now known or hereafter devised. The above rights include the right to make such modifications as are technically necessary to exercise the rights in other media and formats, but otherwise you have no rights to make Adaptations. Subject to 8(f), all rights not expressly granted by Licensor are hereby reserved, including but not limited to the rights set forth in Section 4(d).\n\n4. Restrictions. \nThe license granted in Section 3 above is expressly made subject to and limited by the following restrictions:\n\nYou may Distribute or Publicly Perform the Work only under the terms of this License. You must include a copy of, or the Uniform Resource Identifier (URI) for, this License with every copy of the Work You Distribute or Publicly Perform. You may not offer or impose any terms on the Work that restrict the terms of this License or the ability of the recipient of the Work to exercise the rights granted to that recipient under the terms of the License. You may not sublicense the Work. You must keep intact all notices that refer to this License and to the disclaimer of warranties with every copy of the Work You Distribute or Publicly Perform. When You Distribute or Publicly Perform the Work, You may not impose any effective technological measures on the Work that restrict the ability of a recipient of the Work from You to exercise the rights granted to that recipient under the terms of the License. This Section 4(a) applies to the Work as incorporated in a Collection, but this does not require the Collection apart from the Work itself to be made subject to the terms of this License. If You create a Collection, upon notice from any Licensor You must, to the extent practicable, remove from the Collection any credit as required by Section 4(c), as requested.\nYou may not exercise any of the rights granted to You in Section 3 above in any manner that is primarily intended for or directed toward commercial advantage or private monetary compensation. The exchange of the Work for other copyrighted works by means of digital file-sharing or otherwise shall not be considered to be intended for or directed toward commercial advantage or private monetary compensation, provided there is no payment of any monetary compensation in connection with the exchange of copyrighted works.\nIf You Distribute, or Publicly Perform the Work or Collections, You must, unless a request has been made pursuant to Section 4(a), keep intact all copyright notices for the Work and provide, reasonable to the medium or means You are utilizing: (i) the name of the Original Author (or pseudonym, if applicable) if supplied, and/or if the Original Author and/or Licensor designate another party or parties (e.g., a sponsor institute, publishing entity, journal) for attribution (\"Attribution Parties\") in Licensor's copyright notice, terms of service or by other reasonable means, the name of such party or parties; (ii) the title of the Work if supplied; (iii) to the extent reasonably practicable, the URI, if any, that Licensor specifies to be associated with the Work, unless such URI does not refer to the copyright notice or licensing information for the Work. The credit required by this Section 4(c) may be implemented in any reasonable manner; provided, however, that in the case of a Collection, at a minimum such credit will appear, if a credit for all contributing authors of Collection appears, then as part of these credits and in a manner at least as prominent as the credits for the other contributing authors. For the avoidance of doubt, You may only use the credit required by this Section for the purpose of attribution in the manner set out above and, by exercising Your rights under this License, You may not implicitly or explicitly assert or imply any connection with, sponsorship or endorsement by the Original Author, Licensor and/or Attribution Parties, as appropriate, of You or Your use of the Work, without the separate, express prior written permission of the Original Author, Licensor and/or Attribution Parties.\nFor the avoidance of doubt:\n\nNon-waivable Compulsory License Schemes. In those jurisdictions in which the right to collect royalties through any statutory or compulsory licensing scheme cannot be waived, the Licensor reserves the exclusive right to collect such royalties for any exercise by You of the rights granted under this License;\nWaivable Compulsory License Schemes. In those jurisdictions in which the right to collect royalties through any statutory or compulsory licensing scheme can be waived, the Licensor reserves the exclusive right to collect such royalties for any exercise by You of the rights granted under this License if Your exercise of such rights is for a purpose or use which is otherwise than noncommercial as permitted under Section 4(b) and otherwise waives the right to collect royalties through any statutory or compulsory licensing scheme; and,\nVoluntary License Schemes. The Licensor reserves the right to collect royalties, whether individually or, in the event that the Licensor is a member of a collecting society that administers voluntary licensing schemes, via that society, from any exercise by You of the rights granted under this License that is for a purpose or use which is otherwise than noncommercial as permitted under Section 4(b).\nExcept as otherwise agreed in writing by the Licensor or as may be otherwise permitted by applicable law, if You Reproduce, Distribute or Publicly Perform the Work either by itself or as part of any Collections, You must not distort, mutilate, modify or take other derogatory action in relation to the Work which would be prejudicial to the Original Author's honor or reputation.\n\n5. Representations, Warranties and Disclaimer\nUNLESS OTHERWISE MUTUALLY AGREED BY THE PARTIES IN WRITING, LICENSOR OFFERS THE WORK AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE WORK, EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NONINFRINGEMENT, OR THE ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OF ABSENCE OF ERRORS, WHETHER OR NOT DISCOVERABLE. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES, SO SUCH EXCLUSION MAY NOT APPLY TO YOU.\n\n6. Limitation on Liability. \nEXCEPT TO THE EXTENT REQUIRED BY APPLICABLE LAW, IN NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n7. Termination\nThis License and the rights granted hereunder will terminate automatically upon any breach by You of the terms of this License. Individuals or entities who have received Collections from You under this License, however, will not have their licenses terminated provided such individuals or entities remain in full compliance with those licenses. Sections 1, 2, 5, 6, 7, and 8 will survive any termination of this License.\nSubject to the above terms and conditions, the license granted here is perpetual (for the duration of the applicable copyright in the Work). Notwithstanding the above, Licensor reserves the right to release the Work under different license terms or to stop distributing the Work at any time; provided, however that any such election will not serve to withdraw this License (or any other license that has been, or is required to be, granted under the terms of this License), and this License will continue in full force and effect unless terminated as stated above.\n\n8. Miscellaneous\nEach time You Distribute or Publicly Perform the Work or a Collection, the Licensor offers to the recipient a license to the Work on the same terms and conditions as the license granted to You under this License.\nIf any provision of this License is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this License, and without further action by the parties to this agreement, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.\nNo term or provision of this License shall be deemed waived and no breach consented to unless such waiver or consent shall be in writing and signed by the party to be charged with such waiver or consent.\nThis License constitutes the entire agreement between the parties with respect to the Work licensed here. There are no understandings, agreements or representations with respect to the Work not specified here. Licensor shall not be bound by any additional provisions that may appear in any communication from You. This License may not be modified without the mutual written agreement of the Licensor and You.\nThe rights granted under, and the subject matter referenced, in this License were drafted utilizing the terminology of the Berne Convention for the Protection of Literary and Artistic Works (as amended on September 28, 1979), the Rome Convention of 1961, the WIPO Copyright Treaty of 1996, the WIPO Performances and Phonograms Treaty of 1996 and the Universal Copyright Convention (as revised on July 24, 1971). These rights and subject matter take effect in the relevant jurisdiction in which the License terms are sought to be enforced according to the corresponding provisions of the implementation of those treaty provisions in the applicable national law. If the standard suite of rights granted under applicable copyright law includes additional rights not granted under this License, such additional rights are deemed to be included in the License; this License is not intended to restrict the license of any rights under applicable law.\n"
        },
        {
          "name": "README-zh_CN.md",
          "type": "blob",
          "size": 115.4,
          "content": "<p align=\"center\"><img src=\"images/devops_exercises.png\"/></p>\n\n:information_source: &nbsp;此存储库包含有关各种技术主题的问题和练习，有时与 DevOps 和 SRE 相关\n\n:bar_chart: &nbsp;当前有 **2624** 个问题\n\n:warning: &nbsp;您可以使用这些来准备面试，但大多数问题和练习并不代表实际的面试。请阅读[常见问题](faq.md)了解更多详情\n\n:page_facing_up: &nbsp;不同的面试官专注于不同的事情。 有些人将重点放在你的简历上，而另一些人可能将重点放在方案问题或特定的技术问题上。 在这个仓库，我尽力覆盖各种类型的 DevOps 问题，供你练习和测试你的知识\n\n:pencil: &nbsp;你可以通过提交拉取请求来添加更多练习:) 在[此处](CONTRIBUTING.md)阅读贡献指南\n\n****\n\n<!-- ALL-TOPICS-LIST:START -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<center>\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"topics/devops/README.md\"><img src=\"images/devops.png\" width=\"75px;\" height=\"75px;\" alt=\"DevOps\" /><br /><b>DevOps</b></a></td>\n    <td align=\"center\"><a href=\"topics/git/README.md\"><img src=\"images/git.png\" width=\"75px;\" height=\"75px;\" alt=\"Git\"/><br /><b>Git</b></a></td>\n    <td align=\"center\"><a href=\"#network\"><img src=\"images/network.png\" width=\"75px;\" height=\"75px;\" alt=\"Network\"/><br /><b>Network</b></a></td>\n    <td align=\"center\"><a href=\"#hardware\"><img src=\"images/hardware.png\" width=\"75px;\" height=\"75px;\" alt=\"Hardware\"/><br /><b>Hardware</b></a></td>\n    <td align=\"center\"><a href=\"topics/kubernetes/README.md\"><img src=\"images/kubernetes.png\" width=\"75px;\" height=\"75px;\" alt=\"kubernetes\"/><br /><b>Kubernetes</b></a></td>\n  </tr>\n\n  <tr>\n    <td align=\"center\"><a href=\"topics/software_development/README.md\"><img src=\"images/programming.png\" width=\"75px;\" height=\"75px;\" alt=\"programming\"/><br /><b>Software Development</b></a></td>\n    <td align=\"center\"><a href=\"https://github.com/bregman-arie/python-exercises\"><img src=\"images/python.png\" width=\"75px;\" height=\"75px;\" alt=\"Python\"/><br /><b>Python</b></a></td>\n    <td align=\"center\"><a href=\"https://github.com/bregman-arie/go-exercises\"><img src=\"images/Go.png\" width=\"75px;\" height=\"75px;\" alt=\"go\"/><br /><b>Go</b></a></td>\n    <td align=\"center\"><a href=\"topics/perl/README.md\"><img src=\"images/perl.png\" width=\"75px;\" height=\"75px;\" alt=\"perl\"/><br /><b>Perl</b></a></td>\n    <td align=\"center\"><a href=\"#regex\"><img src=\"images/regex.png\" width=\"75px;\" height=\"75px;\" alt=\"RegEx\"/><br /><b>Regex</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/cloud/README.md\"><img src=\"images/cloud.png\" width=\"75px;\" height=\"75px;\" alt=\"Cloud\"/><br /><b>Cloud</b></a></td>\n      <td align=\"center\"><a href=\"topics/aws/README.md\"><img src=\"images/aws.png\" width=\"100px;\" height=\"75px;\" alt=\"aws\"/><br /><b>AWS</b></a></td>\n      <td align=\"center\"><a href=\"topics/azure/README.md\"><img src=\"images/azure.png\" width=\"75px;\" height=\"75px;\" alt=\"azure\"/><br /><b>Azure</b></a></td>\n      <td align=\"center\"><a href=\"topics/gcp/README.md\"><img src=\"images/googlecloud.png\" width=\"70px;\" height=\"70px;\" alt=\"Google Cloud Platform\"/><br /><b>Google Cloud Platform</b></a></td>\n      <td align=\"center\"><a href=\"#openstack/README.md\"><img src=\"images/openstack.png\" width=\"75px;\" height=\"75px;\" alt=\"openstack\"/><br /><b>OpenStack</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"#operating-system\"><img src=\"images/os.png\" width=\"75px;\" height=\"75px;\" alt=\"Operating System\"/><br /><b>Operating System</b></a></td>\n      <td align=\"center\"><a href=\"topics/linux/README.md\"><img src=\"images/logos/linux.png\" width=\"75px;\" height=\"75px;\" alt=\"Linux\"/><br /><b>Linux</b></a></td>\n      <td align=\"center\"><a href=\"#virtualization\"><img src=\"images/virtualization.png\" width=\"75px;\" height=\"75px;\" alt=\"Virtualization\"/><br /><b>Virtualization</b></a></td>\n      <td align=\"center\"><a href=\"topics/dns/README.md\"><img src=\"images/dns.png\" width=\"75px;\" height=\"75px;\" alt=\"DNS\"/><br /><b>DNS</b></a></td>\n      <td align=\"center\"><a href=\"topics/shell/README.md\"><img src=\"images/bash.png\" width=\"75px;\" height=\"75px;\" alt=\"Bash\"/><br /><b>Shell Scripting</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/databases/README.md\"><img src=\"images/databases.png\" width=\"75px;\" height=\"75px;\" alt=\"Databases\"/><br /><b>Databases</b></a></td>\n      <td align=\"center\"><a href=\"#sql\"><img src=\"images/sql.png\" width=\"75px;\" height=\"75px;\" alt=\"sql\"/><br /><b>SQL</b></a></td>\n      <td align=\"center\"><a href=\"#mongo\"><img src=\"images/mongo.png\" width=\"75px;\" height=\"75px;\" alt=\"Mongo\"/><br /><b>Mongo</b></a></td>\n      <td align=\"center\"><a href=\"#testing\"><img src=\"images/testing.png\" width=\"75px;\" height=\"75px;\" alt=\"Testing\"/><br /><b>Testing</b></a></td>\n      <td align=\"center\"><a href=\"#big-data\"><img src=\"images/big-data.png\" width=\"75px;\" height=\"75px;\" alt=\"Big Data\"/><br /><b>Big Data</b></a></td>\n\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/cicd/README.md\"><img src=\"images/cicd.png\" width=\"75px;\" height=\"75px;\" alt=\"cicd\"/><br /><b>CI/CD</b></a></td>\n      <td align=\"center\"><a href=\"#certificates\"><img src=\"images/certificates.png\" width=\"75px;\" height=\"75px;\" alt=\"Certificates\"/><br /><b>Certificates</b></a></td>\n      <td align=\"center\"><a href=\"topics/containers/README.md\"><img src=\"images/containers.png\" width=\"75px;\" height=\"75px;\" alt=\"Containers\"/><br /><b>Containers</b></a></td>\n      <td align=\"center\"><a href=\"topics/openshift/README.md\"><img src=\"images/openshift.png\" width=\"75px;\" height=\"75px;\" alt=\"OpenShift\"/><br /><b>OpenShift</b></a></td>\n      <td align=\"center\"><a href=\"#storage\"><img src=\"images/storage.png\" width=\"75px;\" height=\"75px;\" alt=\"Storage\"/><br /><b>Storage</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/terraform/README.md\"><img src=\"images/terraform.png\" width=\"75px;\" height=\"75px;\" alt=\"Terraform\"/><br /><b>Terraform</b></a></td>\n      <td align=\"center\"><a href=\"#puppet\"><img src=\"images/puppet.png\" width=\"75px;\" height=\"75px;\" alt=\"puppet\"/><br /><b>Puppet</b></a></td>\n      <td align=\"center\"><a href=\"#distributed\"><img src=\"images/distributed.png\" width=\"75px;\" height=\"75px;\" alt=\"Distributed\"/><br /><b>Distributed</b></a></td>\n      <td align=\"center\"><a href=\"#questions-you-ask\"><img src=\"images/you.png\" width=\"75px;\" height=\"75px;\" alt=\"you\"/><br /><b>Questions you can ask</b></a></td>\n      <td align=\"center\"><a href=\"topics/ansible/README.md\"><img src=\"images/ansible.png\" width=\"75px;\" height=\"75px;\" alt=\"ansible\"/><br /><b>Ansible</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/observability/README.md\"><img src=\"images/observability.png\" width=\"75px;\" height=\"75px;\" alt=\"observability\"/><br /><b>Observability</b></a></td>\n      <td align=\"center\"><a href=\"#prometheus\"><img src=\"images/prometheus.png\" width=\"75px;\" height=\"75px;\" alt=\"Prometheus\"/><br /><b>Prometheus</b></a></td>\n      <td align=\"center\"><a href=\"topics/circleci/README.md\"><img src=\"images/logos/circleci.png\" width=\"70px;\" height=\"70px;\" alt=\"Circle CI\"/><br /><b>Circle CI</b></a></td>\n      <td align=\"center\"><a href=\"topics/datadog/README.md\"><img src=\"images/logos/datadog.png\" width=\"80px;\" height=\"80px;\" alt=\"DataDog\"/><br /><b></b></a></td>\n      <td align=\"center\"><a href=\"topics/grafana/README.md\"><img src=\"images/logos/grafana.png\" width=\"80px;\" height=\"80px;\" alt=\"Grafana\"/><br /><b>Grafana</b></a></td>\n  </tr>\n\n  <tr>\n    <td align=\"center\"><a href=\"topics/argo/README.md\"><img src=\"images/logos/argo.png\" width=\"80px;\" height=\"80px;\" alt=\"Argo\"/><br /><b>Argo</b></a></td>\n    <td align=\"center\"><a href=\"topics/soft_skills/README.md\"><img src=\"images/HR.png\" width=\"75px;\" height=\"75px;\" alt=\"HR\"/><br /><b>Soft Skills</b></a></td>\n    <td align=\"center\"><a href=\"topics/security/README.md\"><img src=\"images/security.png\" width=\"75px;\" height=\"75px;\" alt=\"security\"/><br /><b>Security</b></a></td>\n    <td align=\"center\"><a href=\"#system-design\"><img src=\"images/design.png\" width=\"75px;\" height=\"75px;\" alt=\"Design\"/><br /><b>System Design</b></a></td>\n   </tr>\n\n   <tr>\n    <td align=\"center\"><a href=\"topics/chaos_engineering/README.md\"><img src=\"images/logos/chaos_engineering.png\" width=\"75px;\" height=\"75px;\" alt=\"Chaos Engineering\"/><br /><b>Chaos Engineering</b></a></td>\n    <td align=\"center\"><a href=\"#Misc\"><img src=\"images/general.png\" width=\"75px;\" height=\"75px;\" alt=\"Misc\"/><br /><b>Misc</b></a></td>\n    <td align=\"center\"><a href=\"#elastic\"><img src=\"images/elastic.png\" width=\"75px;\" height=\"75px;\" alt=\"Elastic\"/><br /><b>Elastic</b></a></td>\n    <td align=\"center\"><a href=\"topics/kafka/README.md\"><img src=\"images/logos/kafka.png\" width=\"85px;\" height=\"80px;\" alt=\"Kafka\"/><br /><b>Kafka</b></a></td>\n   </tr>\n\n</table>\n</center>\n<!-- markdownlint-enable -->\n<!-- prettier-ignore-end -->\n<!-- ALL-TOPICS-LIST:END -->\n\n## 网络\n\n<details>\n<summary>一般来说，你需要什么才能进行交流？</summary><br><b>\n\n  - 一种共同的语言（供两端理解）\n  - 与你想要沟通的人交流的方法\n  - 一个连接（以便通信内容能够到达接收者）\n\n</b></details>\n\n<details>\n<summary>什么是 TCP/IP？</summary><br><b>\n\n一组协议，定义了两个或多个设备如何相互通信。\n\n了解更多关于TCP/IP, 阅读 [这里](http://www.penguintutor.com/linux/basic-network-reference)\n\n</b></details>\n\n<details>\n<summary>什么是以太网？</summary><br><b>\n\n以太网简单地指的是当今最常见的局域网（LAN）类型。与跨越较大地理区域的广域网（WAN）相对，LAN是一个连接在小范围内的计算机网络，比如你的办公室、大学校园或者家庭。\n\n</b></details>\n\n<details>\n<summary>什么是 MAC 地址？它有什么用途？</summary><br><b>\n\nMAC地址是用于识别网络上各个设备的唯一标识号码或代码。\n\n通过以太网发送的数据包始终来自一个 MAC 地址并发送到一个 MAC 地址。如果网络适配器接收到一个数据包，它会将该数据包的目标 MAC 地址与适配器自身的 MAC 地址进行比较。\n\n</b></details>\n\n<details>\n<summary>这个 MAC 地址是在什么时候使用的？: ff:ff:ff:ff:ff:ff</summary><br><b>\n\n当设备向广播 MAC 地址（FF:FF:FF:FF:FF:FF）发送数据包时，它会传递给本地网络上的所有站点。以太网广播用于在数据链路层通过 ARP 解析 IP 地址到 MAC 地址。\n</b></details>\n\n<details>\n<summary>什么是 IP 地址？</summary><br><b>\n\n互联网协议地址（IP 地址）是分配给连接到使用互联网协议进行通信的计算机网络上的每个设备的数字标签。IP地址具有两个主要功能：主机或网络接口识别和位置寻址。\n</b></details>\n\n<details>\n<summary>解释子网掩码并举例说明</summary><br><b>\n\n子网掩码是一个32位的数字，用于屏蔽 IP 地址并将 IP 地址分为网络地址和主机地址。子网掩码通过将网络位设置为全部\"1\"，将主机位设置为全部\"0\"来生成。在给定的网络中，总可用主机地址中始终保留两个用于特定目的，并且不能分配给任何主机。这些是第一个地址，被保留作为网络地址（也称为网络 ID），以及最后一个用于网络广播的地址。\n\n[例子](https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09)\n\n</b></details>\n\n<details>\n<summary>私有 IP 地址是什么？在哪些场景/系统设计中应该使用它？</summary><br><b>\n私有IP地址被分配给同一网络中的主机，以便彼此通信。正如“私有”这个名字所暗示的那样，拥有私有IP地址的设备无法被来自任何外部网络的设备访问到。例如，如果我住在一个宿舍，并且我希望我的室友们加入我托管的游戏服务器，我会要求他们通过我的服务器的私有IP地址加入，因为该网络是局域网。\n</b></details>\n\n<details>\n<summary>什么是公共 IP 地址？在哪些场景/系统设计中，应该使用它？</summary><br><b>\n公共IP地址是面向公众的 IP 地址。如果你正在托管一个游戏服务器，希望你的朋友加入，你会给他们提供你的公共IP地址，以便他们的计算机能够识别和定位到你的网络和服务器，从而进行连接。在与与您连接到同一网络的朋友玩耍时，并不需要使用面向公众的IP地址，在这种情况下，您将使用私有IP地址。为了使某人能够连接到内部位置的服务器上，您需要设置端口转发来告诉路由器允许来自公共域名和网络之间的流量通信。\n</b></details>\n\n<details>\n<summary>解释 OSI 模型。有哪几层？每层负责什么？</summary><br><b>\n\n- 应用程序：用户端（ HTTP 在此）。\n- 演示：建立应用层实体之间的上下文（加密在这里）。\n- 会话：建立、管理和终止连接。\n- 传输：将可变长度的数据序列从源主机传输到目标主机（ TCP 和 UDP 在此）。\n- 网络：将数据报从一个网络传输到另一个网络（ IP 在此）。\n- 数据链路：提供两个直接连接的节点之间的链接（MAC在此）。\n- 物理特性：数据连接的电气和物理规格（位数在此）。\n\n您可以在 [penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference) 阅读有关OSI模型的更多信息。\n</b></details>\n\n<details>\n<summary>对于以下每个确定其属于哪个 OSI 层：\n\n  * 错误更正\n  * 数据包路由\n  * 电缆和电信号\n  * MAC 地址\n  * IP 地址\n  * 终止连接\n  * 3 次握手</summary><br><b>\n  * 错误纠正 - 数据链路\n  * 数据包路由 - 网络\n  * 电缆和电信号 - 物理\n  * MAC 地址 - 数据链路\n  * IP 地址 - 网络\n  * 终止连接 - 会话\n  * 3次握手 - 传输\n</b></details>\n\n<details>\n<summary>你熟悉哪些交付计划？</summary><br><b>\n\n单播：一对一的通信，其中有一个发送者和一个接收者。\n\n广播：向网络中的所有人发送消息。地址 ff:ff:ff:ff:ff:ff 用于广播。\n           使用广播的两个常见协议是 ARP 和 DHCP。\n\n多播：向一组订阅者发送消息。它可以是一对多或多对多的。\n</b></details>\n\n<details>\n<summary>什么是 CSMA/CD？它在现代以太网网络中使用吗？</summary><br><b>\n\nCSMA/CD 代表载波侦听多路访问冲突检测。\n其主要目标是管理对共享介质/总线的访问，每次只有一个主机可以传输。\n\nCSMA/CD 算法：\n\n1. 在发送帧之前，它会检查是否有另一个主机正在传输帧。\n2. 如果没有人在传输，它就开始传输帧。\n3. 如果两个主机同时传输，就会发生碰撞。\n4. 两个主机都停止发送帧，并向所有人发送一个“干扰信号”，通知大家发生了碰撞。\n5. 他们正在等待一个随机的时间再次发送它。\n6. 一旦每个主机等待了随机时间，它们会再次尝试发送帧，从而重新开始循环。\n</b></details>\n\n<details>\n<summary>描述以下网络设备及其之间的区别：\n\n  * 路由器\n  * 交换机\n  * 集线器</summary><br><b>\n\n路由器、交换机和集线器都是用于连接局域网（LAN）中的设备的网络设备。然而，每个设备的操作方式不同，并且具有其特定的使用情况。以下是对每个设备及其之间区别的简要描述：\n\n1. 路由器：一种网络设备，用于连接多个网络段。它在OSI模型的网络层（第3层）上运行，并使用路由协议来指导网络之间的数据传输。路由器使用IP地址来识别设备并将数据包定向到正确的目标位置。\n2. 交换机：一种网络设备，用于连接局域网上的多个设备。它在OSI模型的数据链路层（第二层）工作，并使用MAC地址来识别设备并将数据包定向到正确的目标。交换机可以使同一网络上的设备更高效地相互通信，并且可以防止多个设备同时发送数据时可能发生的数据碰撞。\n3. 集线器：一种网络设备，通过单根电缆连接多个设备，并用于在不分割网络的情况下连接多个设备。然而，与交换机不同的是，它在OSI模型的物理层（第1层）上运行，并且只是将数据包广播到所有连接到它的设备，无论该设备是否为预期接收者。这意味着可能会发生数据碰撞，并且网络效率可能因此受到影响。由于交换机更高效并提供更好的网络性能，所以现代网络设置通常不使用集线器。\n</b></details>\n\n<details>\n<summary>什么是“冲突域”？</summary><br><b>\n冲突域是一个网络段，在这个网络段中，设备可能会因为试图同时传输数据而相互干扰。当两个设备同时传输数据时，可能会发生碰撞，导致数据丢失或损坏。在冲突域中，所有设备共享同样的带宽，并且任何设备都有可能干扰其他设备的数据传输。\n</b></details>\n\n<details>\n<summary>什么是“广播域”？</summary><br><b>\n广播域是一个网络段，其中所有设备可以通过发送广播消息相互通信。广播消息是一条发送给网络中所有设备而不是特定设备的消息。在广播域中，所有设备都可以接收和处理广播消息，无论该消息是否针对它们。\n</b></details>\n\n<details>\n<summary>连接到一个交换机的三台计算机。有多少个冲突域？有多少个广播域？</summary><br><b>\n\n三个冲突域和一个广播域\n</b></details>\n\n<details>\n<summary>路由器是如何工作的？</summary><br><b>\n\n路由器是一种物理或虚拟设备，用于在两个或多个分组交换的计算机网络之间传递信息。路由器检查给定数据包的目标互联网协议地址（IP地址），计算它到达目的地的最佳路径，然后相应地转发它。\n\n</b></details>\n\n<details>\n<summary>什么是NAT？</summary><br><b>\n\n网络地址转换（NAT）是一个过程，其中一个或多个本地IP地址被翻译成一个或多个全局IP地址，反之亦然，以便为本地主机提供互联网访问。\n\n</b></details>\n\n<details>\n<summary>什么是代理？它是如何工作的？我们为什么需要它？</summary><br><b>\n\n代理服务器充当您和互联网之间的网关。它是一个中介服务器，将最终用户与他们浏览的网站分离开来。\n\n如果您使用代理服务器，互联网流量将通过代理服务器传输到您请求的地址。然后，该请求再次通过相同的代理服务器返回（有一些例外情况），然后代理服务器将从网站接收到的数据转发给您。\n\n代理服务器根据您的使用情况、需求或公司政策提供不同级别的功能、安全性和隐私保护。\n</b></details>\n\n<details>\n<summary>TCP 是什么？它如何工作？三次握手是什么？</summary><br><b>\n\nTCP 三次握手，又称为三向握手，在 TCP/IP 网络中用于建立服务器和客户端之间的连接的过程。\n\n三次握手主要用于创建 TCP 套接字连接。它在以下情况下起作用：\n\n- 一个客户节点通过IP网络向同一网络或外部网络上的服务器发送SYN数据包。该数据包的目标是询问/推断服务器是否对新连接开放。\n- 目标服务器必须具有可以接受和发起新连接的开放端口。当服务器从客户节点收到SYN数据包时，它会响应并返回确认收据 - ACK 数据包或 SYN/ACK 数据包。\n- 客户端节点接收到来自服务器的 SYN/ACK，并用一个 ACK数据包作出响应。\n</b></details>\n\n<details>\n<summary>什么是往返延迟或往返时间？</summary><br><b>\n\n摘自 [维基百科](https://en.wikipedia.org/wiki/Round-trip_delay)：\"发送信号所需的时间加上收到信号确认所需的时间\"。\n\n附加问题：局域网的 RTT 是多少？\n</b></details>\n\n<details>\n<summary>SSL 握手是如何进行的？</summary><br><b>\nSSL 握手是在客户端和服务器之间建立安全连接的过程。\n\n1. 客户端向服务器发送一个Client Hello消息，其中包括客户端的SSL/TLS协议版本、客户端支持的加密算法列表和一个随机值。\n2. 服务器响应一个Server Hello消息，其中包括服务器的SSL/TLS协议版本、一个随机值和会话ID。\n3. 服务器发送一个证书消息，其中包含了服务器的证书。\n4. 服务器发送 Server Hello Done 信息，表示服务器已完成服务器 Hello 阶段的信息发送。\n5. 客户发送包含客户公钥的客户密钥交换信息。\n6. 客户端发送 \"更改密码规格 \"报文，通知服务器客户端即将发送使用新密码规格加密的报文。\n7. 客户端发送一个加密的握手消息，其中包含使用服务器的公钥加密的预主密钥。\n8. 服务器发送 \"更改密码规格 \"信息，通知客户端服务器即将发送使用新密码规格加密的信息。\n9. 服务器发送加密握手信息，其中包含用客户机公钥加密的预主密钥。\n10. 客户端和服务器现在可以交换应用数据。\n</b></details>\n\n<details>\n<summary>TCP 和 UDP 有什么区别？</summary><br><b>\n\nTCP 在客户端和服务器之间建立连接，以保证数据包的顺序，而 UDP 不在客户端和服务器之间建立连接，也不处理数据包顺序。这使得 UDP 比 TCP 更轻便，是流媒体等服务的理想选择。\n\n[Penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference) 提供了很好的解释。\n</b></details>\n\n<details>\n<summary>您熟悉哪些 TCP/IP 协议？</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释“默认网关”</summary><br><b>\n\n默认网关是一个接入点或 IP 路由器，联网计算机利用它将信息发送到另一个网络或互联网上的计算机。\n</b></details>\n\n<details>\n<summary>什么是 ARP？它是如何工作的？</summary><br><b>\n\nARP 是地址解析协议（Address Resolution Protocol）的缩写。当您尝试 ping 本地网络上的一个 IP 地址（如 192.168.1.1）时，您的系统必须将 IP 地址 192.168.1.1 转换为 MAC 地址。这就需要使用 ARP 来解析该地址，ARP 也因此而得名。\n\n系统会保存一个 ARP 查找表，其中存储了哪些 IP 地址与哪些 MAC 地址相关联的信息。当试图向某个 IP 地址发送数据包时，系统会首先查询该表，看是否已经知道该 MAC 地址。如果有缓存值，则不使用 ARP。\n</b></details>\n\n<details>\n<summary>什么是 TTL？它有助于防止什么？</summary><br><b>\n\n- TTL（生存时间）是IP（Internet Protocol，互联网协议）数据包中的一个值，它决定了在被丢弃之前数据包可以经过多少跳或路由器。每次通过路由器转发数据包时，TTL值会减少一。当TTL值达到零时，数据包将被丢弃，并向发送方发送ICMP（Internet Control Message Protocol，互联网控制消息协议）消息以指示该数据包已过期。\n- TTL 用于防止数据包在网络中无限循环，否则会造成拥塞并降低网络性能。\n- 它还有助于防止数据包陷入路由环路，即数据包在同一组路由器之间不断往返而永远无法到达目的地。\n- 此外，TTL 还可用于帮助检测和防止 IP 欺骗攻击，在这种攻击中，攻击者试图通过使用虚假或伪造的 IP 地址来冒充网络上的其他设备。通过限制数据包的跳数，TTL 可以帮助防止数据包被路由到不合法的目的地。\n</b></details>\n\n<details>\n<summary>什么是 DHCP？它是如何工作的？</summary><br><b>\n\n它代表动态主机配置协议，为主机分配 IP 地址、子网掩码和网关。它是这样工作的：\n\n* 主机在进入网络时广播一条寻找 DHCP 服务器的信息（DHCP DISCOVER）。\n* DHCP 服务器会以数据包的形式发回要约信息，其中包含租用时间、子网掩码、IP 地址等信息（DHCP OFFER）。\n* 根据接受的提议，客户端会发送回复广播，让所有 DHCP 服务器都知道（DHCP 请求）。\n* 服务器发送确认（DHCP ACK）\n\n更多信息 [此处](https://linuxjourney.com/lesson/dhcp-overview)\n</b></details>\n\n<details>\n<summary>同一个网络中可以有两个 DHCP 服务器吗？它是如何工作的？</summary><br><b>\n\n可以在同一网络上安装两个 DHCP 服务器，但不建议这样做，而且必须仔细配置，以防止冲突和配置问题。\n- 在同一网络上配置两个 DHCP 服务器时，两个服务器都有可能为同一设备分配 IP 地址和其他网络配置设置，从而导致冲突和连接问题。此外，如果 DHCP 服务器配置了不同的网络设置或选项，网络上的设备可能会收到冲突或不一致的配置设置。\n- 不过，在某些情况下，可能有必要在同一网络中设置两个 DHCP 服务器，例如在大型网络中，一个 DHCP 服务器可能无法处理所有请求。在这种情况下，可以将 DHCP 服务器配置为不同的 IP 地址范围或不同的子网，这样它们就不会相互干扰。\n</b></details>\n\n<details>\n<summary>什么是 SSL 隧道？它是如何工作的？</summary><br><b>\n\n- SSL（安全套接字层）隧道是一种技术，用于在互联网等不安全网络上的两个端点之间建立安全的加密连接。SSL 隧道是通过将流量封装在 SSL 连接中创建的，SSL 连接可提供保密性、完整性和身份验证。\n\n下面介绍 SSL 隧道的工作原理：\n\n1. 客户端启动与服务器的 SSL 连接，其中包括建立 SSL 会话的握手过程。\n2. SSL 会话建立后，客户端和服务器会协商加密参数，如加密算法和密钥长度，然后交换数字证书，以验证彼此的身份。\n3. 客户端随后通过 SSL 隧道将流量发送到服务器，服务器解密流量并将其转发到目标位置。\n4. 服务器通过 SSL 隧道将流量发送回客户端，客户端对流量进行解密并将其转发给应用程序。\n</b></details>\n\n<details>\n<summary>什么是套接字？在哪里可以看到系统中的套接字列表？</summary><br><b>\n\n- 套接字是一种软件端点，可使进程之间通过网络进行双向通信。套接字为网络通信提供了一个标准化接口，允许应用程序在网络上发送和接收数据。查看 Linux 系统上打开的套接字列表：\n***netstat -an***\n- 该命令显示所有打开套接字的列表，以及它们的协议、本地地址、外来地址和状态。\n</b></details>\n\n<details>\n<summary>什么是 IPv6？如果我们有 IPv4，为什么还要考虑使用它？</summary><br><b>\n\n- IPv6（互联网协议版本 6）是互联网协议（IP）的最新版本，用于识别网络上的设备并与之通信。IPv6 地址是 128 位地址，用十六进制表示，如 2001:0db8:85a3:0000:0000:8a2e:0370:7334。\n\n我们应该考虑使用 IPv6 而不是 IPv4 有几个原因：\n\n1. 地址空间：IPv4 的地址空间有限，在世界上许多地方已经耗尽。IPv6 提供了更大的地址空间，可提供数万亿个唯一的 IP 地址。\n2. 安全性：IPv6 包含对 IPsec 的内置支持，为网络流量提供端到端加密和身份验证。\n3. 性能：IPv6 包括一些有助于提高网络性能的功能，例如组播路由，它允许将一个数据包同时发送到多个目的地。\n4. 简化网络配置：IPv6 包含可简化网络配置的功能，例如无状态自动配置，它允许设备自动配置自己的 IPv6 地址，而无需 DHCP 服务器。\n5. 更好的移动性支持：IPv6 包含可改进移动性支持的功能，如移动 IPv6，它允许设备在不同网络之间移动时保持其 IPv6 地址。\n</b></details>\n\n<details>\n<summary>什么是 VLAN？</summary><br><b>\n\n- VLAN（虚拟局域网）是一种逻辑网络，它将物理网络上的一组设备组合在一起，而不管它们的物理位置如何。创建 VLAN 的方法是配置网络交换机，为连接到交换机上特定端口或端口组的设备发送的帧分配特定的 VLAN ID。\n</b></details>\n\n<details>\n<summary>什么是 MTU？</summary><br><b>\n\t\nMTU 是最大传输单元（Maximum Transmission Unit）的缩写。它是指单个事务中可发送的最大 PDU（协议数据单元）的大小。\n</b></details>\n\n<details>\n<summary>如果发送的数据包大于 MTU，会发生什么情况？</summary><br><b>\n\t\n在 IPv4 协议中，路由器可以对 PDU 进行分片，然后通过事务发送所有已分片的 PDU。\n\t\n使用 IPv6 协议时，它会向用户计算机发出错误信息。\n</b></details>\n\n<details>\n<summary>真还是假？Ping 使用 UDP 是因为它不在乎连接是否可靠</summary><br><b>\n\n错。Ping 实际上使用的是 ICMP（互联网控制报文协议），这是一种用于发送与网络通信有关的诊断信息和控制信息的网络协议。\n</b></details>\n\n<details>\n<summary>什么是 SDN？</summary><br><b>\n\n- SDN 是软件定义网络（Software-Defined Networking）的缩写。它是一种网络管理方法，强调网络控制的集中化，使管理员能够通过软件抽象来管理网络行为。\n- 在传统网络中，路由器、交换机和防火墙等网络设备需要使用专用软件或命令行界面进行单独配置和管理。相比之下，SDN 将网络控制平面与数据平面分开，允许管理员通过集中式软件控制器管理网络行为。\n</b></details>\n\n<details>\n<summary>什么是 ICMP？它有什么用途？</summary><br><b>\n\n- ICMP 是 Internet Control Message Protocol 的缩写。它是 IP 网络中用于诊断和控制的协议。它是互联网协议套件的一部分，在网络层运行。\n\nICMP消息被用于各种目的，包括：\n1. 错误报告：ICMP消息用于报告网络中发生的错误，例如无法将数据包传递到其目的地。\n2. Ping：ICMP 用于发送 ping 信息，该信息用于测试主机或网络是否可连接，并测量数据包的往返时间。\n3. 路径 MTU 发现：ICMP 用于发现路径的最大传输单元（MTU），即无需分片即可传输的最大数据包大小。\n4. 跟踪路由跟踪路由实用程序使用 ICMP 跟踪数据包通过网络的路径。\n5. 路由器发现ICMP 用于发现网络中的路由器。\n</b></details>\n\n<details>\n<summary>什么是 NAT？它是如何工作的？</summary><br><b>\n\nNAT 是网络地址转换的缩写。它是一种在传输信息前将多个本地专用地址映射到一个公共地址的方法。希望多个设备使用一个 IP 地址的组织和大多数家用路由器一样，都会使用 NAT。\n例如，你电脑的私有 IP 可能是 192.168.1.100，但你的路由器会将流量映射到它的公共 IP（如 1.1.1.1）。互联网上的任何设备都会看到来自公共 IP（1.1.1.1）而不是私人 IP（192.168.1.100）的流量。\n</b></details>\n\n<details>\n<summary>下列协议中使用的端口号分别是？\n\n  * SSH\n  * SMTP\n  * HTTP\n  * DNS\n  * HTTPS\n  * FTP\n  * SFTP\n</summary><br><b>\n\n  * SSH - 22\n  * SMTP - 25\n  * HTTP - 80\n  * DNS - 53\n  * HTTPS - 443\n  * FTP - 21\n  * SFTP - 22\n</b></details>\n\n<details>\n<summary>哪些因素会影响网络性能？</summary><br><b>\n\n有几个因素会影响网络性能，包括：\n\n1. 带宽：网络连接的可用带宽会极大地影响其性能。带宽有限的网络可能会出现数据传输速率慢、延迟高和响应速度差等问题。\n2. 延迟：延迟是指数据从网络中的一个点传输到另一个点时发生的延迟。高延迟会导致网络性能缓慢，尤其是视频会议和在线游戏等实时应用。\n3. 网络拥塞：当太多设备同时使用网络时，就会出现网络拥塞，导致数据传输速率缓慢和网络性能低下。\n4. 数据包丢失：当数据包在传输过程中丢失时，就会出现丢包现象。这会导致网络速度变慢，整体网络性能降低。\n5. 网络拓扑：网络的物理布局，包括交换机、路由器和其他网络设备的位置，都会影响网络性能。\n6. 网络协议：不同的网络协议具有不同的性能特征，会影响网络性能。例如，TCP 是一种可靠的协议，可以保证数据的传输，但也会因错误检查和重传所需的开销而导致性能降低。\n7. 网络安全：防火墙和加密等安全措施会影响网络性能，尤其是在需要大量处理能力或引入额外延迟的情况下。\n8. 距离：网络设备之间的物理距离会影响网络性能，尤其是无线网络，信号强度和干扰会影响连接性和数据传输速率。\n</b></details>\n\n<details>\n<summary>什么是 APIPA？</summary><br><b>\n\nAPIPA 是分配给设备的一组 IP 地址\n当主 DHCP 服务器无法访问时分配给设备的 IP 地址\n\n</b></details>\n\n<details>\n<summary>APIPA 使用哪个 IP 范围？</summary><br><b>\n\nAPIPA 使用的 IP 范围是169.254.0.1 - 169.254.255.254.\n\n</b></details>\n\n#### 控制平面和数据平面\n\n<details>\n<summary>\"控制平面\"是指什么？</summary><br><b>\n\n控制平面是网络的一部分，它决定如何将数据包路由和转发到不同的位置。\n</b></details>\n\n<details>\n<summary>数据平面 \"指的是什么？</summary><br><b>\n\n数据平面是网络中实际转发数据/数据包的部分。\n</b></details>\n\n<details>\n<summary>管理平面 \"指的是什么？</summary><br><b>\n\n它指的是监测和管理功能。\n</b></details>\n\n<details>\n<summary>创建路由表属于哪个平面（数据、控制......）？</summary><br><b>\n\n控制平面。\n</b></details>\n\n<details>\n<summary>解释生成树协议（STP）。</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是链路聚合？为什么要使用？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是非对称路由？如何处理？</summary><br><b>\n</b></details>\n\n<details>\n<summary>您熟悉哪些覆盖（隧道）协议？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 GRE？它是如何运作的？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 VXLAN？它是如何工作的？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 SNAT？</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 OSPF。</summary><br><b>\n\n\nOSPF（开放式最短路径优先）是一种路由协议，可在各种类型的路由器上实施。一般来说，大多数现代路由器都支持 OSPF，包括思科、瞻博网络和华为等供应商的路由器。该协议设计用于基于 IP 的网络，包括 IPv4 和 IPv6。此外，它采用分层网络设计，将路由器分组为区域，每个区域都有自己的拓扑图和路由表。这种设计有助于减少路由器之间需要交换的路由信息量，提高网络的可扩展性。\n\nOSPF 4 路由器类型有\n  * Internal Router\n  * Area Border Routers\n  * Autonomous Systems Boundary Routers\n  * Backbone Routers\n\n  了解有关 OSPF 路由器类型的更多信息： https://www.educba.com/ospf-router-types\n</b></details>\n\n<details>\n<summary>什么是延迟？</summary><br><b>\n\t\n延迟是指信息从信息源到达目的地所需的时间。\n</b></details>\n\n<details>\n<summary>什么是带宽？</summary><br><b>\n\t\n带宽是通信信道的容量，用于衡量后者在特定时间段内可处理的数据量。带宽越大，意味着处理的流量越多，数据传输量也就越大。\n</b></details>\n\n<details>\n<summary>什么是吞吐量？</summary><br><b>\n\t\n吞吐量是指在一定时间内通过任何传输通道传输的实际数据量。\n</b></details>\n\n<details>\n<summary>在进行搜索查询时，延迟和吞吐量哪个更重要？如何确保我们对全球基础设施进行管理？\n</summary><br><b>\n\n延迟。要获得良好的延迟，搜索查询应转发到最近的数据中心。\n</b></details>\n\n<details>\n<summary>上传视频时，延迟和吞吐量哪个更重要？如何确保这一点？</summary><br><b>\n\n吞吐量。为获得良好的吞吐量，上传数据流应被路由到未充分利用的链路。\n</b></details>\n\n<details>\n<summary>转发请求时还需要考虑哪些因素（除了延迟和吞吐量）？</summary><br><b>\n\n* 保持缓存更新（这意味着请求可能不会被转发到最近的数据中心）\n</b></details>\n\n<details>\n<summary>解释 Spine & Leaf</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是网络拥塞？什么原因会导致网络拥塞？</summary><br><b>\n\n当网络上需要传输的数据过多，而网络容量不足以满足需求时，就会出现网络拥塞。 </br>\n这会导致延迟和数据包丢失增加。原因可能是多方面的，如网络使用率高、文件传输量大、恶意软件、硬件问题或网络设计问题。</br>\n为防止网络拥塞，必须监控网络使用情况，并实施策略来限制或管理需求。\n</b></details>\n\n<details>\n<summary>关于 UDP 数据包格式，您能告诉我什么？TCP 数据包格式如何？有何不同？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是指数后退算法？在哪里使用？</summary><br><b>\n</b></details>\n\n<details>\n<summary>使用汉明码，以下数据字 100111010001101 的码字是什么？</summary><br><b>\n\n00110011110100011101\n</b></details>\n\n<details>\n<summary>举例说明应用层中的协议</summary><br><b>\n\n* 超文本传输协议（HTTP）--用于互联网上的网页\n* 简单邮件传输协议（SMTP）--用于电子邮件传输\n* 电信网络（TELNET）--终端模拟，允许客户端访问 telnet 服务器\n* 文件传输协议（FTP）--便于在任何两台机器之间传输文件\n* 域名系统 (DNS) - 域名转换\n* 动态主机配置协议（DHCP）--为主机分配 IP 地址、子网掩码和网关\n* 简单网络管理协议（SNMP）--收集网络设备数据\n</b></details>\n\n<details>\n<summary>举例说明网络层中的协议</summary><br><b>\n\n* 互联网协议 (IP) - 协助将数据包从一台机器路由到另一台机器\n* 互联网控制消息协议（ICMP）--让人知道发生了什么，如错误信息和调试信息\n</b></details>\n\n<details>\n<summary>什么是 HSTS？</summary><br><b>\nHTTP 严格传输安全（HTTP Strict Transport Security）是一种网络服务器指令，它通过在开始时发送并返回给浏览器的响应标头，告知用户代理和网络浏览器如何处理其连接。这将强制通过 HTTPS 加密连接，忽略任何脚本通过 HTTP 加载该域中任何资源的调用。\n\n阅读更多 [此处](https://www.globalsign.com/en/blog/what-is-hsts-and-how-do-i-use-it#:~:text=HTTP%20Strict%20Transport%20Security%20(HSTS,and%20back%20to%20the%20browser.)\n</b></details>\n\n#### 网络 - 其他\n\n<details>\n<summary>什么是互联网？它和万维网一样吗？</summary><br><b>\n\n互联网是一个由网络组成的网络，在全球范围内传输大量数据。<br>\n万维网是一个运行在数百万服务器上的应用程序，它位于互联网之上，可通过所谓的网络浏览器访问\n</b></details>\n\n<details>\n<summary>什么是ISP?</summary><br><b>\n\nISP（互联网服务提供商）是当地的互联网公司。\n</b></details>\n\n\n## DevOps\n\n<a name=\"devops-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是 DevOps? DevOps 帮助我们完成什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>DevOps 的反模式是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是持续集成?</summary><br><b>\n\n开发人员经常将代码集成到共享仓库中的一种开发实践。 它的范围可以从每天或每周进行几次更改，到大规模在一个小时内进行几次更改。\n\n验证每段代码（更改/补丁），以使更改可以安全地合并。 如今，使用自动构建来确保代码可以集成的测试更改是一种常见的做法。 它可以是一个运行在不同级别（单元，功能等）的多个测试的构建，也可以是所有或某些必须通过以将更改合并到存储库中的多个单独的构建。\n</b></details>\n\n<details>\n<summary>什么是持续部署?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是持续交付?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你认为CI / CD的最佳做法是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你将用于以下哪些系统和/或工具？：\n\n\n  * CI/CD\n  * 基础架构\n  * 配置管理\n  * 监控 & 报警\n  * 日志\n  * 代码审查\n  * 代码覆盖率\n  * 测试集</summary><br><b>\n  * CI/CD - Jenkins, Circle CI, Travis\n  * 基础架构 - Terraform, CloudFormation\n  * 配置管理 - Ansible, Puppet, Chef\n  * 监控 & 报警 - Prometheus, Nagios\n  * 日志 - Logstash, Graylog, Fluentd\n  * 代码审查 - Gerrit, Review Board\n  * 代码覆盖率 - Cobertura, Clover, JaCoCo\n  * 测试集 - Robot, Serenity, Gauge\n</b></details>\n\n<details>\n<summary>你在选择工具/技术时是怎么考虑的?</summary><br><b>\n\n你可以使用以下一项或全部：\n   * 成熟与尖端\n   * 社区规模\n   * 体系结构方面-代理与无代理，主控与无主控等\n</b></details>\n\n<details>\n<summary>解释可变基础架构与不变基础架构</summary><br><b>\n\n在可变的基础架构原则中，更改将应用到现有基础架构之上并随着时间的推移而变化\n基础架构建立了变化的历史。 Ansible，Puppet和Chef这些工具\n遵循可变的基础架构原则。\n\n在不变的基础架构原则中，每项更改实际上都是新的基础架构。 所以改变\n到服务器将导致新服务器而不是更新服务器。 Terraform是\n遵循不变的基础架构原则的一个例子。\n</b></details>\n\n<details>\n<summary>你熟悉什么方式来交付软件?</summary><br><b>\n  * 存档 - 将你所有的应用文件收集到一个存档中（例如tar），并将其交付给用户。\n  * 打包 - 取决于操作系统，你可以使用OS软件包格式（例如，在RHEL / Fefodra中为RPM）来交付软件，并使用标准打包程序命令来安装，卸载和更新它\n  * 映像 - VM或容器映像，其中包已包含在其中，以便成功运行。\n</b></details>\n\n<details>\n<summary>什么是缓存? 缓存是怎么工作的? 为什么缓存很重要?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下无状态和有状态</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是HTTP及其工作方式?</summary><br><b>\n</b></details>\n\n<details>\n<summary>描述一下设置某些类型的Web服务器的工作流程 (Apache, IIS, Tomact, ...)</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下监控. 它是什么? 为什么监控是重要的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉那些监控方法?</summary><br><b>\n</b></details>\n\n<a name=\"devops-advanced\"></a>\n#### 高级\n\n<details>\n<summary>告诉我你是如何执行CI / CD资源的计划容量 (如服务器, 存储, 等等.)</summary><br><b>\n</b></details>\n\n<details>\n<summary>你将如何为依赖于其他多个应用程序的应用程序构建/实现CD?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何衡量CI / CD的质量？ 有那些你正在使用的指标吗？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是配置漂移？ 它引起什么问题？</summary><br><b>\n\n当配置和软件完全相同的服务器环境中的某个服务器上发生配置漂移\n或服务器正在应用其他服务器无法获得的更新或配置，并且随着时间的推移，这些服务器将变为\n略有不同。\n\n这种情形可能会导致难以识别和重现的错误。\n</b></details>\n\n<details>\n<summary>怎样处理配置漂移?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你是否有跨项目变更测试的经验？ (又名交叉依赖)</summary><br><b>\n\n注意：交叉依赖是指你对单独的项目进行了两个或多个更改，并且你希望在相互构建中对其进行测试，而不是分别测试每个更改。\n</b></details>\n\n<details>\n<summary>在哪种情况下，你希望使用SQL?</summary><br><b>\n  * 同类数据，预计不会发生变化\n  * ACID合规性很重要\n</b></details>\n\n\n## Jenkins\n\n<a name=\"jenkins-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是 Jenkins? 你用它来做什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>相比其他的竞争者 jenkins 有什么优势? 你能把jenkins 和下面的系统做一个比较吗?:\n\n  * Travis\n  * Bamboo\n  * Teamcity\n  * CircleCI</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下:\n\n  * Job\n  * Build\n  * Plugin\n  * Slave\n  * Executor</summary><br><b>\n</b></details>\n\n<details>\n<summary> 你在 Jenkins 用过什么插件?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下 CI/CD 你在 Jenkins 是怎么实现他们的 </summary><br><b>\n</b></details>\n\n<details>\n<summary>有什么类型的工作？ 你使用了哪些类型，为什么？</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何向用户报告构建结果？ 你熟悉什么那些方式？</summary><br><b>\n</b></details>\n\n<details>\n<summary>每次有更改提交，你都需要运行单元测试。 详细描述管道的环境以及每个阶段将执行的操作</summary><br><b>\n</b></details>\n\n<details>\n<summary>怎样保护 Jenkins?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能描述一些 Jenkins 最佳实践吗?</summary><br><b>\n</b></details>\n\n<a name=\"jenkins-advanced\"></a>\n#### 高级\n\n<details>\n<summary>如何为一个特定的构建获取多个从属?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你的组织中有四个团队。 如何优先考虑每个团队的建设？ 例如，x团队的工作将始终在y团队之前运行</summary><br><b>\n</b></details>\n\n<details>\n<summary>你有部署 Jenkins 插件的经验吗? 你能描述一下吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如果你要管理许多工作，你可能使用Jenkins UI。 你如何每周/每月管理数百个作业的创建和删除？</summary><br><b>\n</b></details>\n\n<details>\n<summary>Jenkins 有那些限制?</summary><br><b>\n\n  * 测试交叉依赖关系（来自多个项目的变更）\n  * 从任何阶段开始构建（尽管cloudbees实现了称为检查点的东西）\n</b></details>\n\n<details>\n<summary>你是如何实施从某个阶段而不是从最开始构建的选项？</summary><br><b>\n</b></details>\n\n<details>\n<summary>你曾经写过 Jenkins 脚本吗? 如果有，有哪些? 分别是怎么样工作的？</summary><br><b>\n</b></details>\n\n## Cloud \n\n<a name=\"cloud-beginner\"></a>\n#### 初级\n\n<details>\n<summary>云计算的优势是什么？ 至少列出3个优势</summary><br><b>\n</b></details>\n\n<details>\n<summary>他们分别是那种类型的云计算?</summary><br><b>\n\nIAAS\nPAAS\nSAAS\n</b></details>\n\n<details>\n<summary>解释一下以下云计算部署：\n\n  * Public\n  * Hybrid\n  * Private</summary><br><b>\n</b></details>\n\n\n## AWS\n\n<a name=\"aws-beginner\"></a>\n#### 初级\n\n##### 全局基础设施\n\n<details>\n<summary>解释以下\n\n  * 可用区\n  * 区域\n  * 边缘位置</summary><br><b>\n</b>\n<b>\nAWS区域是遍布全球不同地理位置的数据中心，每个区域彼此完全独立。\n在每个区域内，有多个隔离的位置，称为可用区。 多个可用区可确保其中之一发生故障时具有高可用性。\n\n边缘位置基本上是内容传递网络，它缓存数据并确保较低的延迟和更快地传递给任何位置的用户。 他们位于世界主要城市。\n</b>\n</details>\n\n##### S3\n \n<details>\n<summary>解释一下什么是S3，以及它用来干嘛</summary><br>\n<b>\nS3代表3 S（Simple Storage Service）。\nS3是一种对象存储服务，它是快速，可伸缩和持久的。 S3使客户能够上传，下载或存储最大5 TB的文件或对象。 同时每个文件的最大大小为5 GB（如果大小超过5 GB，则分段上传）。\n</b>\n</details>\n\n<details>\n<summary>什么是存储桶?</summary><br><b>\nS3存储桶是一种资源，类似于文件系统中的文件夹，并且允许存储由数据及其元数据组成的对象。\n</b></details>\n\n<details>\n<summary>对还是错? 存储桶必须全局唯一</summary><br><b>\nTrue\n</b></details>\n\n<details>\n<summary>S3 中 包含哪些对象 ?\n  * 另一种问法: 在对象上下文中解释键，值，版本ID和元数据</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下数据一致性</summary><br><b>\n</b></details>\n\n<details>\n<summary>你可以在s3上托管动态网站吗？ 静态网站呢?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你在S3上下文中采取了哪些安全措施?</summary><br><b>\n</b></details>\n\n##### CloudFront\n\n<details>\n<summary>解释一下什么是CloudFront及其用途</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下\n  * 域\n  * 边缘位置\n  * 分布</summary><br><b>\n</b></details>\n\n<details>\n<summary>CDN用户可以使用哪些交付方式?</summary><br><b>\n</b></details>\n\n<details>\n<summary>对还是错? 在TTL的生命周期内缓存对象</summary><br><b>\n</b></details>\n\n\n##### EC2\n\n<details>\n<summary>你创建了哪种类型的实例?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何为给定的EC2实例增加RAM?</summary><br><b>\n\n停止实例，使其实例类型与所需的RAM匹配，然后启动实例。\n</b></details>\n\n<details>\n<summary>什么是 AMI?</summary><br><b>\n</b></details>\n\n<details>\n<summary>EC2实例有多少个存储选项?</summary><br><b>\n</b></details>\n\n<details>\n<summary>EC2实例停止或终止时会发生什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是安全组?</summary><br><b>\n</b></details>\n\n\n<details>\n<summary>如何将实例迁移到另一个可用性区域?</summary><br><b>\n</b></details>\n\n\n<details>\n<summary>什么是安全组?</summary><br><b>\n</b></details>\n\n\n<details>\n<summary>什么是竞价型实例?</summary><br><b>\n</b></details>\n  \n\n## 网络\n\n<a name=\"network-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是以太网?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是一个 MAC 地址? 它用来干嘛?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么时候这个 MAC 地址会被用来使用?: ff:ff:ff:ff:ff:ff</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是一个 IP 地址? 什么是子网?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下 OSI 模型. 有那些层? 每层负责什么?</summary><br><b>\n\n\n应用层：用户端（HTTP在这一层）\n表示层：在应用程序层实体之间建立上下文（加密在这一层）\n会话层：建立，管理和终止连接\n传输层：将可变长度的数据序列从源传输到目标主机（TCP和UDP在这一层）\n网络层：将数据报从一个网络传输到另一个网络（IP 层在这里）\n数据链接层：提供两个直接连接的节点之间的链接（MAC在这一层）\n物理层：数据连接的电气和物理规格（比特在这一一层）\n</b></details>\n\n<details>\n<summary>你熟悉哪些传送方案?</summary><br><b>\n单位广播：一对一通信，其中有一个发送方和一个接收方。\n\n广播：向网络中的所有人发送消息。 地址ff：ff：ff：ff：ff：ff：ff用于广播。\n            使用广播的两个常见协议是ARP和DHCP。\n\n组播：向一组订户发送消息。 它可以是一对多或多对多。\n</b></details>\n\n<details>\n<summary>什么是 CSMA/CD? 在现代以太网中有使用吗?</summary><br><b>\n\nCSMA / CD代表载波侦听多路访问/冲突检测。\n它的主要重点是管理对共享媒体/总线的访问，在该共享媒体/总线上，在给定的时间点只能传输一个主机。\n\nCSMA / CD算法：\n\n1. 在发送帧之前，它会检查其他主机是否已经在发送帧。\n2. 如果没有人发送，它将开始发送帧。\n3. 如果两个主机同时传输，则发生冲突。\n4. 双方主机均停止发送帧，并向每个人发送“干扰信号”，通知每个人发生冲突\n5. 他们正在等待随机时间，然后再次发送\n6. 一旦每个主机等待一段随机时间，他们就会尝试再次发送帧\n</b></details>\n\n<details>\n<summary>描述以下网络设备及其之间的区别：\n\n  * 路由器\n  * 交换机\n  * 集线器</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 NAT?</summary><br><b>\n</b></details>\n\n<details>\n<summary>TCP 和 UDP 两者之间有那些区别?</summary><br><b>\n</b></details>\n\n<details>\n<summary>TCP 是怎样工作的? 什么是 3 次握手?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 ARP? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 TTL?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是DHCP? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是SSL 隧道? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是套接字? 在哪里可以看到系统中的套接字列表?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是IPv6? 如果我们拥有IPv4，为什么要考虑使用它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是VLAN?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是MTU?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是SDN?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是ICMP? 它有什么用途?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是NAT? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<a name=\"network-advanced\"></a>\n#### 高级\n\n<details>\n<summary>解释一下生成树协议 (STP)</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是链路聚合? 为什么使用它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是非对称路由? 怎样处理它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些叠加（隧道）协议?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是GRE? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是VXLAN? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是SNAT?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下 OSPF</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下 Spine & Leaf</summary><br><b>\n</b></details>\n\n<details>\n<summary>使用海明码, 100111010001101 会编码成什么码?</summary><br><b>\n\n00110011110100011101\n</b></details>\n\n## Linux\n\n<a name=\"linux-beginner\"></a>\n#### 初级\n\n<details>\n<summary>你有那些 Linux 经验? 当你可以在多个操作系统上设置应用程序时，你希望在哪个操作系统上进行设置以及为什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下每个命令的作用，并举例说明如何使用它\n\n  * ls\n  * rm \n  * rmdir (你能使用 <code>rm</code>完成同样的结果吗?)\n  * grep\n  * wc\n  * curl\n  * touch\n  * man\n  * nslookup or dig\n  * df</summary><br><b>\n</b></details>\n\n<details>\n<summary>运行命令 <code>df</code> 你会得到 \"找不到命令\". 可能出现什么问题以及如何修复它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何确保服务将在你选择的操作系统上启动?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何定期安排任务?</summary><br><b>\n\n你能使用命令 <code>cron</code> 和 <code>at</code>.\n对于cron，使用以下格式安排任务：\n\n<minute> <hour> <day of month> <month> <day of week> <command to execute>\n\n任务存储在cron文件中。\n</b></details>\n\n<details>\n<summary>你过去是否安排了任务？ 什么样的任务？</summary><br><b>\n\n通常，你将安排批处理作业。\n\n</b></details>\n\n##### 权限\n\n<details>\n<summary>怎样改变一个文件的权限?</summary><br><b>\n\n使用 `chmod` 命令.\n\n</b></details>\n\n<details>\n<summary>下面的权限意味着什么?:\n\n  * 777\n  * 644\n  * 750</summary><br><b>\n\n777 - 所有人有读和写和可执行权限（意味着你很懒）\n644 - 拥有者有读和写的权限、其他人只有读权限\n750 - 拥有者有所有权限, 组成员可以读和执行权限、其他人没有权限\n</b></details>\n\n<details>\n<summary>解释一下什么是setgid, setuid 和 sticky bit</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何在不向其提供登录系统功能的情况下将新用户添加到系统?</summary><br><b>\n\n  * adduser user_name --shell=/bin/false --no-create-home\n\n</b></details>\n\n<details>\n<summary>在使用systemd的系统上，如何显示日志?</summary>\n\n  * journalctl\n\n</b></details>\n\n##### 调试\n\n<details>\n<summary>你正在使用什么进行故障排除和调试 <b>网络</b> 问题?</summary><br><b>\n\n<code>dstat -t</code> 非常适合辨别网络和磁盘问题。\n<code>netstat -tnlaup</code> 可用于查看哪些进程在哪些端口上运行。\n<code>lsof -i -P</code> 可以用于与netstat相同的目的。\n<code>ngrep -d any metafilter</code> 用于将正则表达式与数据包的载荷相匹配。\n<code>tcpdump</code> 用于捕获数据包\n<code>wireshark</code> 与tcpdump相同的概念，但带有GUI（可选）。\n</b></details>\n\n<details>\n<summary>你正在使用什么进行故障排除和调试 <b>磁盘 & 文件系统</b> 问题?</summary><br><b>\n\n<code>dstat -t</code> 非常适合辨别网络和磁盘问题。\n<code>opensnoop</code> 可以用来查看正在系统上打开哪些文件（实时）。\n</b></details>\n\n<details>\n<summary>你正在使用什么进行故障排除和调试 <b>进程</b> 问题?</summary><br><b>\n\n<code>strace</code> 非常适合了解你的程序的功能。 它打印你的程序执行的每个系统调用。\n</b></details>\n\n<details>\n<summary>你正在使用什么来调试CPU相关问题?</summary><br><b>\n\n<code>top</code> 显示每个进程消耗多少CPU占比\n<code>perf</code> 是采样分析器的理想选择，通常来说，找出哪些CPU周期被“浪费”了\n<code>flamegraphs</code> 非常适合CPU消耗可视化（http://www.brendangregg.com/flamegraphs.html）\n</b></details>\n\n<details>\n<summary>你收到一个电话，说“我的系统运行缓慢” - 你将如何处理?</summary><br><b>\n\n1. 使用<code>top</code>检查是否有任何资源消耗你的CPU或RAM。\n2. 运行<code>dstat -t</code>来检查它是否与磁盘或网络有关。\n3. 使用<code>iostat</code>检查 I/O 统计信息\n</b></details>\n\n<details>\n<summary>什么是Linux内核模块以及如何加载新模块?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是KVM?</summary><br><b>\n</b></details>\n\n<details>\n<summary>SSH和SSL之间的区别是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>SSH端口转发是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释重定向</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是通配符？ 你能举一个使用它们的例子吗？</summary><br><b>\n</b></details>\n\n<details>\n<summary>我们在以下每个命令中使用grep做什么？\n\n  * <code>grep '[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}' some_file</code>\n  * <code>grep -E \"error|failure\" some_file</code>\n  * <code>grep '[0-9]$' some_file</code>\n</summary><br><b>\n\n1. 一个 IP 地址\n2. 单词 \"error\" 或 \"failure\"\n3. 以数字结尾的行\n</b></details>\n\n<details>\n<summary>告诉我你了解所有有关Linux启动过程的知识</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是退出码? 你熟悉那些退出码?</summary><br><b>\n\n退出码（或返回码）表示子进程返回其父进程的码。\n\n0是退出码，表示成功，而大于1的码表示错误。\n每个数字都有不同的含义，具体取决于应用程序的开发方式。\n\n我认为这是一篇可以了解更多的好博客：https://shapeshed.com/unix-exit-codes\n</b></details>\n\n<details>\n<summary>软链接和硬链接之间的区别是什么?</summary><br><b>\n\n硬链接是使用相同inode的相同文件。\n软链接是使用不同inode的另一个文件的快捷方式。\n\n可以在不同的文件系统之间创建软链接，而硬链接只能在同一文件系统内创建。\n</b></details>\n\n<details>\n<summary>什么是交换分区? 它用来做什么的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你试图创建一个新文件，但显示“文件系统已满”。 你使用df检查是否有可用空间，你看到还有20％的空间。 可能是什么问题?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你对LVM有什么了解?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下关于LVM:\n\n  * PV\n  * VG\n  * LV</summary><br><b>\n</b></details>\n\n<details>\n<summary>RAID用于什么用途？ 你能否解释RAID 0、1、5和10之间的区别？</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是懒卸载?</summary><br><b>\n</b></details>\n\n<details>\n<summary>修复以下命令：\n\n  * sed \"s/1/2/g' /tmp/myFile\n  * find . -iname \\*.yaml -exec sed -i \"s/1/2/g\" {} ;</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下每个路径中存储的内容以及是否有一些独特之处</summary><br><b>\n\n  * /tmp\n  * /var/log\n  * /bin\n  * /proc\n  * /usr/local\n</b></details>\n\n<details>\n<summary>你能在 /etc/services 找到什么 </summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 chroot?</summary><br><b>\n</b></details>\n\n##### 进程\n\n<details>\n<summary>如何在后台运行进程以及为什么要优先运行?</summary><br><b>\n\n你可以通过在命令末尾指定＆来实现。至于为什么，因为一些命令/过程会占用大量的时间来完成执行或永远运行\n</b></details>\n\n<details>\n<summary>你如何查找特定进程占用的内存量?</summary><br><b>\n</b></details>\n\n<details>\n<summary>运行“ kill”时使用什么信号 <process id>'?</summary><br><b>\n\n默认信号为SIGTERM（15）。 该信号可以优雅地终止进程，这意味着它可以保存当前状态配置。\n</b></details>\n\n<details>\n<summary>你熟悉哪些信号?</summary><br><b>\n\nSIGTERM - 终止进程的默认信号\nSIGHUP - 常用用法是重新加载配置\nSIGKILL - 不能捕获或忽略的信号\n\n运行 `kill -l` 查看所有可用的信号\n</b></details>\n\n<details>\n<summary>什么是 trap?</summary><br><b>\n</b></details>\n\n<details>\n<summary>当你按下Ctrl + C会发生什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是守护程序?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Linux中进程的可能状态是什么?</summary><br><b>\n\nRunning（运行态）\nWaiting (等待态))\nStopped（暂停态）\nTerminated（终止态）\nZombie（假死态）\n</b></details>\n\n<details>\n<summary>什么是僵尸进程? 你是如何避免的?</summary>\n</b></details>\n\n<details>\n<summary>什么是初始进程?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何更改进程的优先级？ 你为什么想这么做?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能解释一下网络进程/连接如何建立以及如何终止?</summary><br></b>\n</b></details>\n\n<details>\n<summary>什么是系统调用？ 你熟悉哪些系统调用?</summary><br><b>\n</b></details>\n\n<details>\n<summary><code>strace</code> 做什么的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>查找所有以“ .yml”结尾的文件，并替换每个文件中的2分之一的数字</summary><br><b>\n\nind /some_dir -iname \\*.yml -print0 | xargs -0 -r sed -i \"s/1/2/g\"\n</b></details>\n\n<details>\n<summary>如何查看系统有多少可用内存？ 如何检查每个进程的内存消耗?</summary><br><b>\n\n你可以使用命令<code>top</code> 和 <code>free</code>\n</b></details>\n\n<details>\n<summary>你如何将一个50行的文件拆分为两个25行的文件?</summary><br><b>\n\n你可以使用 <code>split</code> 命令就像这样<code>split -l 25 some_file</code>\n</b></details>\n\n<details>\n<summary>什么是文件描述符? 你熟悉那些文件描述符?</summary><br><b>\nKerberos\n文件描述符，也称为文件处理程序，是一个唯一的编号，用于标识操作系统中的打开文件。\n\n在 Linux (和 Unix) 前三个描述符是:\n  * 0 - 输入的默认数据流\n  * 1 - 输出的默认数据流\n  * 2 - 与错误相关的输出的默认数据流\n\n这有一篇好的文章关于这个主题的: https://www.computerhope.com/jargon/f/file-descriptor.htm\n</b></details>\n\n<details>\n<summary>什么是 inode?</summary><br><b>\n\nLinux中的每个文件（和目录）都有一个索引节点，即与文件相关的存储元数据信息的数据结构\n，例如文件的大小，所有者，权限等。\n</b></details>\n\n<details>\n<summary>如何列出活动的网络连接?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是NTP? 它是用来干什么的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是SELiunx?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是Kerberos?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是nftables?</summary><br><b>\n</b></details>\n\n<details>\n<summary>firewalld守护程序负责什么?</summary><br><b>\n</b></details>\n\n##### Network\n\n<details>\n<summary>什么是网络名称空间? 它用来干什么的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何将Linux服务器变成路由器?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是路由表? 你是怎样查看它的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是数据包嗅探器？ 你过去曾经使用过吗？ 如果是，你使用了哪些数据包嗅探器以及用于什么目的？</summary><br><b>\n</b></details>\n\n##### DNS\n\n<details>\n<summary>文件 <code>/etc/resolv.conf</code> 用来做什么的? 它包含那些内容?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 \"A record\"?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是 PTR 记录?</summary><br><b>\n\nA记录将域名指向IP地址，而PTR记录则相反，并将IP地址解析为域名。\n</b></details>\n\n<details>\n<summary>什么是 MX 记录?</summary><br><b>\n</b></details>\n\n<details>\n<summary>DNS是使用TCP还是UDP?</summary><br><b>\n</b></details>\n\n##### Packaging\n\n<details>\n<summary>你有打包经验吗? 你能解释一下它是怎么工作的</summary><br><b>\n</b></details>\n\n<details>\n<summary>RPM: 解释特定格式（应包括什么内容）</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何列出包内容?</summary><br><b>\n</b></details>\n\n<a name=\"linux-advanced\"></a>\n#### 高级\n\n<details>\n<summary>当你执行 <code>ls</code>发生了什么? 提供一个详细的答案</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能描述流程的创建方式吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>以下块做什么?:\n\n```\nopen(\"/my/file\") = 5\nread(5, \"file content\")\n```\n</summary><br><b>\n\n系统调用正在读 <code>/my/file</code>文件 以及 5 是文件描述符数字.\n</b></details>\n\n<details>\n<summary>进程和线程的区别是什么?</summary><br><b>\n</b></details>\n\n##### Network\n\n<details>\n<summary>当你运行 <code>ip a</code> 你看到一个设备叫做 'lo'. 它是什么以及为什么我们需要它?</summary><br><b>\n</b></details>\n\n<details>\n<summary><code>traceroute</code> 命令做什么的? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是网络绑定? 你熟悉什么类型?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何链接两个单独的网络名称空间，以便你可以从另一个命名空间ping一个命名空间上的接口?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是cgroup？ 在什么情况下你会使用它们？</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何创建一定大小的文件?</summary><br><b>\n\n这有一些方式去做:\n  \n  * dd if=/dev/urandom of=new_file.txt bs=2MB count=1\n  * truncate -s 2M new_file.txt\n  * fallocate -l 2097152 new_file.txt\n</b></details>\n\n<details>\n<summary>以下系统调用之间有什么区别?: exec(), fork(), vfork() and clone()?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释流程描述符和任务结构</summary><br><b>\n</b></details>\n\n<details>\n<summary>线程和进程之间有什么区别?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释内核线程</summary><br><b>\n</b></details>\n\n<details>\n<summary>使用套接字系统调用时会发生什么?</summary><br><b>\n\n这有一篇好的文章关于这个主题的: https://ops.tips/blog/how-linux-creates-sockets\n</b></details>\n\n\n## Ansible\n\n<a name=\"ansible-beginner\"></a>\n#### 初级\n\n<details>\n<summary>在Ansible中描述以下每个组件，包括它们之间的关系：\n\n  * Task\n  * Module\n  * Play\n  * Playbook\n  * Role</summary><br><b>\n\n任务 – 调用特定的Ansible模块\n模块 – Ansible在你自己的主机或远程主机上执行的实际代码单元。 模块按类别（数据库，文件，网络等）编制索引，也称为任务插件。\n\nPlay – 在给定主机上执行的一个或多个任务\n\nPlaybook – 一个或多个Play。 每个Play可以在相同或不同的主机上执行\n\n角色 – Ansible角色使你可以基于某些功能/服务对资源进行分组，以便可以轻松地重用它们。 在角色中，你具有变量，默认值，文件，模板，处理程序，任务和元数据的目录。 然后，你只需在剧本中指定角色即可使用该角色。\n</b></details>\n\n<details>\n<summary>你熟悉哪些Ansible最佳做法? 至少列出 3 条</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是清单文件以及如何定义一个?</summary><br><b>\n\n清单文件定义了在其上执行Ansible任务的主机和/或主机组。\n\n一个清单文件的例子\n\n192.168.1.2\n192.168.1.3\n192.168.1.4\n\n[web_servers]\n190.40.2.20\n190.40.2.21\n190.40.2.22\n</b></details>\n\n<details>\n<summary>什么是动态清单文件? 什么时候使用?</summary><br><br>\n\n动态清单文件可跟踪来自一个或多个来源（例如云提供商和CMDB系统）的主机。\n\n应该使用当使用外部源时，尤其是在环境中的主机正在自动启动和关闭，而无需跟踪这些源中的所有更改。\n</b></details>\n\n<details>\n<summary>你只想在特定的次要操作系统上运行Ansible Play，你将如何实现?</summary><br><b>\n</b></details>\n\n<details>\n<summary>写任务创建目录 ‘/tmp/new_directory’</summary><br><b>\n\n```\n- name: Create a new directory\n  file:\n      path: \"/tmp/new_directory\"\n      state: directory\n```\n</b></details>\n\n<details>\n<summary>接下来的Play会有什么结果?</summary><br><b>\n\n```\n---\n- name: Print information about my host\n  hosts: localhost\n  gather_facts: 'no'\n\n  tasks:\n      - name: Print hostname\n        debug:\n            msg: \"It's me, {{ ansible_hostname }}\"\n```\n\n提供完成的代码后，请始终进行彻底检查。 如果你的回答是“这将失败”，那么你是对的。 我们正在使用一个事实（ansible_hostname），\n这是我们正在运行的主机上收集到的信息。 但是在这种情况下，我们禁用了事实收集（gather_facts：no），因此该变量将是未定义的，这将导致失败。\n</b></details>\n\n<details>\n<summary>如果系统上存在文件 \"/tmp/mario\"，则编写 playbook 以在所有主机上安装 \"zlib\" 和 \"vim\" .</summary><br><b>\n\n```\n---\n- hosts: all\n  vars:\n      mario_file: /tmp/mario\n      package_list:\n          - 'zlib'\n          - 'vim'\n  tasks:\n      - name: Check for mario file\n        stat:\n            path: \"{{ mario_file }}\"\n        register: mario_f\n\n      - name: Install zlib and vim if mario file exists\n        become: \"yes\"\n        package:\n            name: \"{{ item }}\"\n            state: present\n        with_items: \"{{ package_list }}\"\n        when: mario_f.stat.exists\n```\n\n</b></details>\n\n<details>\n<summary>编写一个 playbook ，将文件 \"/tmp/system_info\" 部署到除控制器组之外的所有主机上，并具有以下内容：</summary><br><b>\n\n  ```\n  我是 <HOSTNAME> 我的操作系统是 <OS>\n  ```\n\n  替换 <HOSTNAME> 和  <OS> 以及正在运行的特定主机的实际数据 The playbook 部署system_info文件\n\n```\n---\n- name: Deploy /tmp/system_info file\n  hosts: all:!controllers\n  tasks:\n      - name: Deploy /tmp/system_info\n        template:\n            src: system_info.j2 \n            dest: /tmp/system_info\n```\n\nThe content of the system_info.j2 template\n\n```\n# {{ ansible_managed }}\nI'm {{ ansible_hostname }} and my operating system is {{ ansible_distribution }}\n```\n\n</b></details>\n\n<details>\n<summary>变量 \"whoami\" 在以下位置定义：\n\n  * 角色默认设置 -> whoami: mario\n  * 额外的变量（使用 -e 传递给Ansible CLI的变量）-> whoami: toad\n  * 托管事实 -> whoami: luigi\n  * 广告资源变量（与哪种类型无关）-> whoami: browser\n\n根据可变优先级，将使用哪个？\n</summary><br><b>\n\n正确的答案是 ‘toad’。\n\n变量优先级是关于变量在不同位置设置时如何相互覆盖的。 如果你到目前为止还没有体验过，我相信你会在某个时候确定的，这使它成为一个有用的话题。\n\n在我们的问题上下文中，顺序将是额外的var（始终覆盖任何其他变量）-> 主机事实 -> 库存变量 -> 角色默认值（最弱）。\n\n完整的列表可以在上面的链接中找到。 另外，请注意Ansible 1.x和2.x之间存在显着差异。\n</b></details>\n\n<details>\n<summary>对于以下每个语句，确定对还是错:\n\n  * 模块是任务的集合\n  * 最好使用shell或命令而不是特定的模块\n  * 主机事实会覆盖 play 变量\n  * 角色可能包括以下内容：var，meta 和 handler\n  * 通过从外部来源提取信息来生成动态清单\n  * 最佳做法是使用2个空格而不是4个缩进\n  * 用来触发处理程序的“通知”\n  * \"hosts：all：！controllers\"表示 \"仅在控制器组主机上运行\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是ansible-pull?  与ansible-playbook相比有何不同?</summary><br><b>\n</b></details>\n\n\n<a name=\"ansible-advanced\"></a>\n#### 高级\n\n<details>\n<summary>什么是过滤器？ 你有写过滤器的经验吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>编写过滤器来转化字符串大写</summary><br><b>\n\n<code>\ndef cap(self, string):\n    return string.capitalize()\n</code>\n</b></details>\n\n<details>\n<summary>你如何测试基于Ansible的项目?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是回调插件？ 使用回调插件可以实现什么？</summary><br><b>\n</b></details>\n\n\n## Terraform\n\n<a name=\"terraform-beginner\"></a>\n#### 初级\n\n<details>\n<summary>你能解释一下什么是Terraform? 它是怎么工作的?</summary><br><b>\n\n读 [这里](https://www.terraform.io/intro/index.html#what-is-terraform-)\n</b></details>\n\n<details>\n<summary>什么使基础架构代码受益?</summary><br><b>\n\n- 供应，修改和删除基础架构的全自动过程\n- 基础结构的版本控制，可让你快速回滚到以前的版本\n- 通过自动化测试和代码审查来验证基础架构的质量和稳定性\n- 减少基础架构任务的重复性\n</b></details>\n\n<details>\n<summary>为什么选择Terraform，而不选择其他技术？ （例如，Ansible，Puppet，CloufFormation)</summary><br><b>\n\n常见的错误答案是说 Ansible 和 Puppet 是配置管理工具而 Terraform 是置备工具。 尽管从技术上讲是正确的，但这并不意味着 Ansible 和 Puppet 不能\n用于配置基础结构。 另外，这根本没有解释为什么应该在 CloudFormation上 使用 Terraform。\n\nTerraform与其他工具相比的优势：\n\n  * 它遵循不变的基础架构方法，该方法具有避免配置随时间变化的优势\n  * Ansible和Puppet具有更多的过程性（你提到了每个步骤要执行的操作），而Terraform是声明性的，因为你描述的是总体所需的状态，而不是每个资源或任务的状态。 你可以举一个在每个工具中从1台服务器转到2台服务器的示例。 在terrform中，你指定2，在Ansible和puppet中，你仅需配置1个其他服务器，因此你需要明确确保仅配置另一台服务器。\n</b></details>\n\n<details>\n<summary>解释什么是\"Terraform configuration\"</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下每个:\n\n  * Provider\n  * Resource\n  * Provisioner\n  </summary>\n</b></details>\n\n<details>\n<summary><code>terraform.tfstate</code> 文件用来做什么?</summary><br><b> \n\n它跟踪创建的资源的ID，以便Terraform知道它正在管理什么。\n</b></details>\n\n<details>\n<summary>解释以下命令的作用:\n\n  * <code>terraform init</code>\n  * <code>terraform plan</code>\n  * <code>terraform validate</code>\n  * <code>terraform apply</code>\n</summary><br><b>\n\n<code>terraform init</code> 扫描你的代码以查明你正在使用哪些提供程序并下载它们。\n<code>terraform plan</code> 可以让你在实际执行操作之前先查看terraform即将执行的操作。\n<code>terraform apply</code> 将提供指定的.tf文件资源。\n</b></details>\n\n<details>\n<summary>如何记下一个由外部源或者通过 <code>terraform apply</code>改变的变量?</summary><br><b>\n\n你用这种方式: <code>variable “my_var” {}</code>\n</b></details>\n\n<details>\n<summary>举例说明几种Terraform最佳实践</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下隐式和显式依赖项在Terraform中如何工作</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是<code>local-exec</code> and <code>remote-exec</code> in the context of provisioners?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是\"tainted 资源\"?</summary><br><b>\n\n这是成功创建的资源，但在配置期间失败。 Terraform将失败，并将该资源标记为“tainted”。\n</b></details>\n\n<details>\n<summary><code>terraform taint</code> 做了什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Terraform支持哪些类型的变量?</summary><br><b>\n\nStrimg\nInteger\nMap\nList\n</b></details>\n\n<details>\n<summary>什么是输出变量以及 <code>terraform output</code> 做了什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 Modules</summary>\n</b></details>\n\n<details>\n<summary>什么是 Terraform Registry?</summary><br><b>\n</b></details>\n\n<a name=\"terraform-advanced\"></a>\n#### 高级\n\n<details>\n<summary>解释 \"Remote State\". 什么时候使用它以及如何使用它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 \"State Locking\"</summary><br><b>\n</b></details>\n\n## Docker\n\n<a name=\"docker-beginner\"></a>\n\n#### 初级\n\n<details>\n<summary>什么是Docker? 你用它做什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>容器与VM有何不同?</summary><br><b>\n\n容器和虚拟机之间的主要区别是容器使你可以虚拟化\n操作系统上有多个工作负载，而对于VM，则将硬件虚拟化为\n在多台计算机上运行各自的操作系统。\n</b></details>\n\n<details>\n<summary>在哪种情况下，你将使用容器，而在哪种情况下，则更喜欢使用虚拟机?</summary><br><b>\n\n在以下情况下，你应该选择虚拟机：\n   * 你需要运行一个需要操作系统所有资源和功能的应用程序\n   * 你需要完全隔离和安全\n\n在以下情况下，你应该选择容器：\n   * 你需要快速启动的轻量级解决方案\n   * 运行单个应用程序的多个版本或实例\n</b></details>\n\n<details>\n<summary>解释一下 Docker 架构</summary><br><b>\n</b></details>\n\n<details>\n<summary>详细描述一下当运行`docker run hello-world`时背后发生了什么?</summary><br><b>\n\nDocker CLI 将你的请求传递给Docker守护程序。\nDocker 守护程序从 Docker Hub 下载映像\nDocker 守护程序使用下载的映像创建一个新容器\nDocker 守护程序将输出从容器重定向到 Docker CLI，后者将其重定向到标准输出\n</b></details>\n\n<details>\n<summary>你怎样运行容器?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉那些与容器相关的最佳实践?</summary><br><b>\n</b></details>\n\n<details>\n<summary>`docker commit` 干什么的? 什么时候需要使用它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何将数据从一个容器转移到另一个容器?</summary><br><b>\n</b></details>\n\n<details>\n<summary>容器存在时容器的数据会发生什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下每个命令的作用\n\n* docker run\n* docker rm\n* docker ps\n* docker build\n* docker commit</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何删除未运行的旧容器?</summary><br><b>\n</b></details>\n\n##### Dockerfile\n\n<details>\n<summary>什么是 Dockerfile</summary><br><b>\n</b></details>\n\n<details>\n<summary>Dockerfile中 ADD 和 COPY 之间的区别是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Dockerfile中 CMD 和 RUN 之间的区别是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下什么是 Docker compose 以及它用来做什么</summary><br><b>\n</b></details>\n\n<details>\n<summary>Docker compose，Docker swarm 和 Kubernetes 有什么区别?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 Docker interlock</summary><br><b>\n</b></details>\n\n<details>\n<summary>Docker Hub 和 Docker Cloud 之间的区别是什么?</summary><br><b>\n\nDocker Hub是一个本地 Docker 注册表服务，可让你运行 pull 和 push 命令以从 Docker Hub 安装和部署 Docker映像。\n\nDocker Cloud构建在Docker Hub之上，因此Docker Cloud提供了\n与Docker Hub相比，你拥有更多的可选/功能。 一个例子是\n群管理，这意味着你可以在Docker Cloud中创建新的群。\n</b></details>\n\n<details>\n<summary>存储 Docker 镜像的位置在哪里?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下镜像层</summary><br><b>\n</b></details>\n\n<a name=\"docker-advanced\"></a>\n#### 高级\n\n<details>\n<summary>你如何在Docker中管理持久性存储?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何从容器内部连接到容器运行所在的主机的本地主机? </summary><br><b>\n</b></details>\n\n<details>\n<summary>如何将文件从Docker容器复制到主机，反之亦然?</summary><br><b>\n</b></details>\n\n## Kubernetes\n\n<a name=\"kubernetes-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是Kubernetes?</summary><br><b>\n</b></details>\n\n<details>\n<summary>为什么Docker还不够？ 为什么我们需要Kubernetes?</summary><br><b>\n</b></details>\n\n<details>\n<summary>描述一下 Kuberenets 的架构</summary><br><b>\n</b></details>\n\n<details>\n<summary>你是怎样监控你的 Kuberenets?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是kubectl? 你如何使用它?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是kubconfig? 你用它来做什么?</summary><br><b>\n</b></details>\n\n##### Users\n\n<details>\n<summary>你如何创建用户？ 用户信息的存储位置?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你知道如何不使用 adduser/useradd 命令创建新用户吗?</summary><br><b>\n</b></details>\n\n## Coding\n\n<a name=\"coding-beginner\"></a>\n#### 初级\n\n<details>\n<summary>你更喜欢将哪种编程语言用于与DevOps相关的任务？ 为什么要专门这个?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是面向对象编程? 它为什么如此重要?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下递归</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下什么是设计模式，并详细描述其中的三个</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 big O 符号</summary><br><b>\n</b></details>\n\n##### Strings\n\n<details>\n<summary>用你想要的任何语言，编写一个函数来确定给定的字符串是否是回文串</summary><br><b>\n</b></details>\n\n<a name=\"coding-advanced\"></a>\n#### 高级\n\n<details>\n<summary>给定3种设计模式。 你知道如何以你选择的任何语言实现（提供示例）这些设计模式?</summary><br><b>\n</b></details>\n\n## Python\n\n<a name=\"python-beginner\"></a>\n#### 初级\n\n<details>\n<summary>Python编程语言的一些特点是什么?</summary><br><b>\n\n```\n1. 这是一种由 Guido Van Rosum 于1991年创建的高级通用编程语言。\n2. 语言被解释为CPython（用C语言编写）最常用/维护的实现。\n3. 它是强类型的。 类型系统是鸭子类型和渐进式的。\n4. Python注重可读性，并使用空格/缩进代替括号{}\n5. python 包管理器称为PIP“ pip install packages”，具有超过200.000可用的软件包。\n6. Python 附带安装了pip和一个大的标准库，为程序员提供了许多预置的解决方案。\n7. 在python中，“一切”都是一个对象。\n\n还有许多其他特性，但这是每个python程序员都应该知道的主要特性。\n\n```\n</b></details>\n\n<details>\n<summary>Python支持哪些数据类型，哪些是可变的？ 如何显示某个数据类型是可变的?</summary><br><b>\n\n可变数据类型是:\n\n    List\n    Dictionary\n    Set\n    \n不可变数据类型是:\n\n    Numbers (int, float, ...)\n    String\n    Bool\n    Tuple\n    Frozenset\n\n通常，你可以使用函数hash（）来检查对象的可变性，如果它是可哈希的，则是不可变的，尽管由于用户定义的对象可能是可变的且可哈希的，所以它并不总是按预期工作\n</b></details>\n\n<details>\n<summary>什么是PEP8? 举例说明3种风格指南</summary><br><b>\n\nPEP8是Python的编码约定和样式指南的列表\n\n5 种样式指南:\n\n1. 将所有行限制为最多79个字符。\n2. 用两个空行包围顶级函数和类定义。\n3. 制作一个元素的元组时使用逗号\n4. 使用空格（而不是制表符）进行缩进\n5. 每个缩进级别使用4个空格\n</b></details>\n\n<details>\n<summary>解释一下继承以及如何在Python中使用它</summary><br><b>\n\n```\n根据定义，继承是一种机制，其中一个对象充当另一个对象的基础，并保留其所有对象属性。\n\n因此，如果B类继承自A类，那么A类的每个特征也将在B类中提供。A类将是“基类”，B类将是“派生类”。\n当你有几个共享相同功能的类时，这很方便。\n\n基本语法:\n\nclass Base: pass\n\nclass Derived(Base): pass\n\nA more forged example:\n\nclass Animal:\n    def __init__(self):\n        print(\"and I'm alive!\")\n\n    def eat(self, food):\n        print(\"ñom ñom ñom\", food)\n\nclass Human(Animal):\n    def __init__(self, name):\n        print('My name is ', name)\n        super().__init__()\n\n    def write_poem(self):\n        print('Foo bar bar foo foo bar!')\n\nclass Dog(Animal):\n    def __init__(self, name):\n        print('My name is', name)\n        super().__init__()\n\n    def bark(self):\n        print('woof woof')\n\n\nmichael = Human('Michael')\nmichael.eat('Spam')\nmichael.write_poem()\n\nbruno = Dog('Bruno')\nbruno.eat('bone')\nbruno.bark()\n\n>>> My name is  Michael\n>>> and I'm alive!\n>>> ñom ñom ñom Spam\n>>> Foo bar bar foo foo bar!\n>>> My name is Bruno\n>>> and I'm alive!\n>>> ñom ñom ñom bone\n>>> woof woof\n\n调用super（）会调用Base方法，因此，调用super().__init__() 就是调用 Animal__init__。\n\n有一个称为 MetaClasses 的更高级的python功能，可帮助程序员直接控制类的创建。\n\n```\n\n</b></details>\n\n<details>\n<summary> 什么是一个错误? 什么是一个异常? 你熟悉哪些异常类型?</summary><br><b>\n\n```\n\n＃ 请注意，你通常不需要了解编译过程，而只需知道一切都来自哪里\n＃ 并给出完整的答案表明你真正知道你在说什么。\n\n通常，每个编译过程都有两个步骤。\n    - 分析\n    - 产生代码.\n    \n    Analysis can be broken into:\n        1. 词法分析   (标记源代码)\n        2. 语法分析 (如果语法正确，请检查标记是否合法，tldr)\n           \n               for i in 'foo'\n                          ^\n             SyntaxError: invalid syntax\n        \n        We missed ':'\n        \n        \n        3. 语义分析  (上下文分析，合法语法仍然会触发错误，你是否尝试过除以0，哈希可变对象或使用未声明的函数?)\n          \n                 1/0\n                ZeroDivisionError: division by zero\n        \n    这三个分析步骤负责错误处理。\n    \n    第二步将负责错误，主要是语法错误，这是最常见的错误。\n    第三步将负责异常。\n    \n    如我们所见，异常是语义错误，有许多内置的异常：\n\n        ImportError\n        ValueError\n        KeyError\n        FileNotFoundError\n        IndentationError\n        IndexError\n        ...\n    \n    你还可以具有用户定义的异常，这些异常必须直接或间接地从Exception类继承。\n\n    常见例子:\n        \n    class DividedBy2Error(Exception):\n        def __init__(self, message):\n            self.message = message\n    \n    \n    def division(dividend,divisor):\n        if divisor == 2:\n            raise DividedBy2Error('I dont want you to divide by 2!')\n        return dividend / divisor\n    \n    division(100, 2)\n    \n    >>> __main__.DividedBy2Error: I dont want you to divide by 2!\n\n```\n\n\n</b></details>\n\n<details>\n<summary>解释 异常处理以及如何在Python中使用它</summary><br><b>\n</b></details>\n\n<details>\n<summary>编写一个可以恢复字符串的程序（例如，pizza -> azzip）</summary><br><b>\n\n```\n最简单的是 str[::-1] 但不是效率最高的.\n\n\"经典\" 方式:\n\nfoo = ''\n\nfor char in 'pizza':\n    foo = char + foo\n\n>> 'azzip'   \n\n```\n\n</b></details>\n\n<details>\n<summary>编写一个函数以返回一个或多个数字的和。 用户将决定要使用多少个数字</summary><br><b>\n\n首先，你询问用户要使用的数字量。 使用while循环，每个循环将amount_of_numbers减1，直到amount_of_numbers变为0。 在while循环中，你想询问用户一个数字，该数字将在每次循环运行时添加一个变量。\n\n```\ndef return_sum():\n\tamount_of_numbers = int(input(\"How many numbers? \"))\n\ttotal_sum = 0\n\twhile amount_of_numbers != 0:\n\t\tnum = int(input(\"Input a number. \"))\n\t\ttotal_sum += num\n\t\tamount_of_numbers -= 1\n\treturn total_sum\n\n```\n</b></details>\n\n<details>\n<summary>如何将两个排序列表合并为一个排序列表?</summary><br><b>\n</b></details>\n\n<details>\n<summary> _ 在 Python 中用于什么?</summary><br><b>\n\n1. i18n中的翻译查询\n2. 将最后执行的表达式或语句的结果保存在交互式解释器中。\n3. 作为通用“可丢弃”变量名。 例如：x，y，_ = get_data（）（使用了x和y，但是由于我们不关心第三个变量，因此我们将其“扔掉了”）。\n</b></details>\n\n##### Algorithms Implementation\n\n<details>\n<summary>你可以在Python中实现“二分法搜索”吗?</summary><br><b>\n</b></details>\n\n##### Files\n\n<details>\n<summary>如何写文件?</summary><br><b>\n\n```\nwith open('file.txt', 'w') as file:\n    file.write(\"My insightful comment\")\n```\n</b></details>\n\n<details>\n<summary>如何反转文件?</summary><br><b>\n</b></details>\n\n#### Regex\n\n<details>\n<summary>如何在Python中执行与正则表达式相关的操作？ （匹配模式，替代字符串等）</summary><br><b>\n\n使用 re 模式\n</b></details>\n\n<details>\n<summary>如何用 \"blue\" 替换字符串 \"green\"?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何找到一个变量中的所有IP地址？ 如何在文件中找到它们?</summary><br><b>\n</b></details>\n\n<details>\n<summary>按每个嵌套列表的第二项对列表列表进行排序</summary><br><b>\n\n```\nli = [[1, 4], [2, 1], [3, 9], [4, 2], [4, 5]]\n\nsorted(x, key=lambda l: l[1])\n```\n</b></details>\n\n<details>\n<summary>你可以编写一个函数来打印给定目录中的所有文件吗？ 包括子目录</summary><br><b>\n</b></details>\n\n<details>\n<summary>你有下面的列表: <code>[{'name': 'Mario', 'food': ['mushrooms', 'goombas']}, {'name': 'Luigi', 'food': ['mushrooms', 'turtles']}]</code>\n  获取所有的食物类型，最后输出: {'mushrooms', 'goombas', 'turtles'}</summary><br><b>\n\n```\nbrothers_menu =  \\\n[{'name': 'Mario', 'food': ['mushrooms', 'goombas']}, {'name': 'Luigi', 'food': ['mushrooms', 'turtles']}]\n\n# \"经典\" 方式\ndef get_food(brothers_menu) -> set:\n    temp = []\n\n    for brother in brothers_menu:\n        for food in brother['food']:\n            temp.append(food)\n\n    return set(temp)\n\n# 一直先行方式 (Using list comprehension)\nset([food for bro in x for food in bro['food']])\n```\n\n</b></details>\n\n<details>\n<summary>什么是List 加强？ 它比典型的循环更好吗？ 为什么？ 你能示范如何使用它吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>怎样反转 string?</summary><br><b>\n\n最简短的方式是: <code>my_string[::-1]</code> 但是这不是效率最高的. <br>\n经典方式是:\n```\ndef reverse_string(string):\n    temp = \"\"\n    for char in string:\n        temp =  char + temp\n    return temp\n```\n</b></details>\n\n<details>\n<summary>如何按值对字典排序?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何按键对字典排序?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释数据序列化以及如何使用Python执行</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何在Python中处理参数解析?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释什么是GIL</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是迭代器? 为什么使用迭代器?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下方法的类型以及如何使用它们:\n\n  * Static method\n  * Class method\n  * instance method</summary><br><b>\n</b></details>\n\n<details>\n<summary>怎样反转 list?</summary><br><b>\n</b></details>\n\n<details>\n<summary>空的 <code>return</code> 返回什么?</summary><br><b>\n</b></details>\n\n##### Time Complexity\n\n<details>\n<summary>描述操作的时间复杂度<code>access</code>, <code>search</code> <code>insert</code> and <code>remove</code> 下面的数据结构:</summary><br><b>\n\n  * Stack\n  * Queue\n  * Linked List\n  * Binary Search Tree\n</b></details>\n\n<details>\n<summary>以下算法的最好，最差和平均情况的复杂度是什么?:\n\n  * Quicksort\n  * Mergesort\n  * Bucket Sort\n  * Radix Sort\n  </summary>\n</b></details>\n\n<a name=\"python-advanced\"></a>\n#### 高级\n\n<details>\n<summary>解释什么是装饰器</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能展示如何编写和使用装饰器吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>编写脚本来确定给定端口上是否可以访问给定主机</summary><br><b>\n</b></details>\n\n<details>\n<summary>这个查询熟悉数据类吗？ 你能解释一下他们是干什么用的吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下上下文管理</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下缓冲协议</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下描述符</summary><br><b>\n</b></details>\n\n<details>\n<summary>你有抓取网络（爬虫）的经验吗？ 你能描述一下你用过什么以及用什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你可以在Python中实现链接链表吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你已经创建了一个网页，用户可以在其中上传文档。 但是，根据文档大小，读取上传文件的功能会运行很长时间，并且用户必须等待读取操作完成才能继续使用该网站。 你怎么能解决这个问题?</summary><br><b>\n</b></details>\n\n## Prometheus\n\n<a name=\"prometheus-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是Prometheus? Prometheus的主要特点是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>描述 Prometheus 架构和组件</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能否将 Prometheus 与其他解决方案（例如InfluxDB）进行比较?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是an Alert?</summary><br><b>\n</b></details>\n\n<details>\n<summary>描述以下Prometheus组件:\n\n  * Prometheus server\n  * Push Gateway\n  * Alert Manager</summary><br><b>\n\n负责抓取存储数据的Prometheus服务器推送网关用于短期作业警报管理负责警报 ;）\n</b></details>\n\n<details>\n<summary>什么是一个实例? 什么是一个作业?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Prometheus支持哪些核心指标类型?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是一个 exporter? 它用来做什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些Prometheus最佳做法？ 至少命名三个</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何在给定时间内获得总请求?</summary><br><b>\n</b></details>\n\n<a name=\"prometheus-advanced\"></a>\n#### 高级\n\n<details>\n<summary>你如何加入两个指标?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何编写返回标签值的查询?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何将cpu_user_seconds转换为cpu使用率（百分比）?</summary><br><b>\n</b></details>\n\n## Git\n\n<a name=\"git-beginner\"></a>\n#### 初级\n\n<details>\n<summary><code>git pull</code> 和 <code>git fetch</code>的区别是什么?</summary><br><b>\n\n简单来说, git pull = git fetch + git merge\n\n当你运行git pull时，它会从远程或中央获取所有更改\n存储库，并将其附加到本地存储库中的相应分支。\n\ngit fetch从远程存储库获取所有更改，将更改存储在\n本地存储库中的单独分支\n</b></details>\n\n<details>\n<summary>解释以下: <code>git 目录</code>, <code>工作目录</code> 和 <code>暂存区</code></summary><br><b>\n\nGit目录是Git存储项目的元数据和对象数据库的地方。 这是Git最重要的部分，当你从另一台计算机克隆存储库时，它就是复制的。\n\n工作目录是项目一个版本的单个签出。 这些文件将从Git目录中的压缩数据库中拉出，并放置在磁盘上供你使用或修改。\n\n暂存区是一个简单文件，通常包含在你的Git目录中，用于存储有关下一次提交的内容的信息。 有时称为索引，但将其称为暂存区已成为标准。\n\n答案来自 [git-scm.com](https://git-scm.com/book/en/v1/Getting-Started-Git-Basics#_the_three_states)\n</b></details>\n\n<details>\n<summary>怎么解决 git merge 冲突?</summary><br><b>\n\n<p>\n首先，打开有冲突的文件，然后确定有什么冲突。\n接下来，根据你的公司或团队接受的是什么，你可以与自己的\n同事解决冲突或自行解决\n解决冲突后，使用 git add <file_name> 添加文件。\n最后，运行`git rebase --continue`。\n</p>\n</b></details>\n\n<details>\n<summary><code>git reset</code> 和 <code>git revert</code>区别是什么?</summary><br><b>\n\n<p>\n\n`git revert` 创建一个新的提交，撤消上一次提交的更改。\n\n`git reset` 根据使用情况，可以修改索引或更改分支头当前指向的提交。\n</p>\n</b></details>\n\n<details>\n<summary>你想将提交移至顶部。 你将如何实现?</summary><br><b>\n\n使用 <code>git rebase></code> 命令\n</b></details>\n\n<details>\n<summary>那种情形你会使用 <code>git rebase</code>?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些合并策略?</summary><br><b>\n\n提及两个或三个就足够了，最好提到“递归”作为默认值。\n\nrecursive\nresolve\nours\ntheirs\n\n这篇文章解释是最好的: https://git-scm.com/docs/merge-strategies\n</b></details>\n\n<details>\n<summary>在提交更改之前，如何查看已完成的更改?</summary><br><b>\n\n<code>git diff</code>\n</b></details>\n\n<details>\n<summary>如何将特定文件还原为先前的提交?</summary><br><b>\n\n```\ngit checkout HEAD~1 -- /path/of/the/file\n```\n</b></details>\n\n\n<a name=\"git-advanced\"></a>\n#### 高级\n\n<details>\n<summary>解释 Git octopus merge</summary><br><b>\n\n也许不错，它是：\n\n  * 对于合并多个分支的情况（以及此类用例的默认情况）非常有用\n  * 主要用于将主题分支捆绑在一起\n\n有一篇文章关于 Octopus merge: http://www.freblogg.com/2016/12/git-octopus-merge.html\n</b></details>\n\n## Go\n\n<a name=\"go-beginner\"></a>\n#### 初级\n\n<details>\n<summary>Go编程语言有哪些特点?</summary><br><b>\n\n  * 强类型和静态类型 - 变量的类型不能随时间更改，必须在编译时进行定义\n  * 简单\n  * 快速编译时间\n  * 内置并发\n  * 垃圾回收\n  * 平台无关\n  * 编译为独立的二进制文件 - 你运行应用程序所需的所有内容都将被编译为一个二进制文件。 对于运行时的版本管理非常有用。\n\nGo 而且有一个很好的社区.\n</b></details>\n\n<details>\n<summary><code>var x int = 2</code> 和 <code>x := 2</code>区别是什么?</summary><br><b>\n\n结果相同，变量值为2。\n\nwith <code>var x int = 2</code> we are setting the variable type to integer while with <code>x := 2</code> we are letting Go figure out by itself the type.\n</b></details>\n\n<details>\n<summary>对还是错? 在Go中，我们可以重新声明变量，并且一旦声明就必须使用它.</summary>\n\n错. 我们不能重新声明变量，必须使用声明的变量。\n</b></details>\n\n<details>\n<summary>你使用了哪些Go库?</summary><br><b>\n\n应该根据你的使用情况回答此问题，一些示例是：\n  * fmt - formatted I/O\n</b></details>\n\n<details>\n<summary>下面代码块有什么问题? 怎么解决?\n\n```go\nfunc main() {\n    var x float32 = 13.5\n    var y int\n    y = x\n}\n```\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>下面的代码块尝试将整数101转换为字符串，但相反，我们得到“ e”。 这是为什么？ 怎么解决?\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    var x int = 101\n    var y string\n    y = string(x)\n    fmt.Println(y)\n}\n```\n</summary><br><b>\n\n它看起来在101处设置了什么unicode值，并将其用于将整数转换为字符串。\n如果要获取“ 101”，则应使用“ strconv” 软件包，然后替换 <code>y = string(x)</code> with <code>y = strconv.Itoa(x)</code>\n</b></details>\n\n<details>\n<summary>以下代码块什么是错的?:\n\n```\npackage main\n\nfunc main() {\n    var x = 2\n    var y = 3\n    const someConst = x + y\n}\n```\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>以下代码块的输出是什么？:\n\n```go   \npackage main\n\nimport \"fmt\"\n\nconst (\n\tx = iota\n\ty = iota\n)\nconst z = iota\n\nfunc main() {\n\tfmt.Printf(\"%v\\n\", x)\n\tfmt.Printf(\"%v\\n\", y)\n\tfmt.Printf(\"%v\\n\", z)\n}\n```\n</summary><br><b>\n</b></details>\n\n<details>\n<summary> _ 在 Go 中的用途是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>以下代码块的输出是什么？:\n\n```go\npackage main\n\nimport \"fmt\"\n\nconst (\n\t_ = iota + 3\n\tx\n)\n\nfunc main() {\n\tfmt.Printf(\"%v\\n\", x)\n}\n```\n</summary><br><b>\n</b></details>\n\n## Mongo\n\n<a name=\"mongo-beginner\"></a>\n#### 初级\n\n<details>\n<summary>MongoDB有什么优势？ 换句话说，为什么选择 MongoDB 而不选择 NoSQL 的其他实现?</summary><br><b>\n</b></details>\n\n<details>\n<summary>SQL和NoSQL之间的区别是什么?</summary><br><b>\n\n主要区别在于SQL数据库是结构化的（数据以带有行和列的表格-像是Excel电子表格表格），而NoSQL是\n非结构化的，并且数据存储会根据NoSQL DB的设置方式而有所不同，例如\n作为键值对，面向文档等\n</b></details>\n\n<details>\n<summary>在哪种情况下，这个查询希望使用 NoSQL/Mongo 而不是SQL?</summary><br><b>\n\n  * 经常变化的异构数据\n  * 数据一致性和完整性不是重中之重\n  * 最好，如果数据库需要快速扩展\n</b></details>\n\n<details>\n<summary>什么是一个文档? 什么是一个集合?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是一个聚合?</summary><br><b>\n</b></details>\n\n<details>\n<summary>那个更好? 嵌入文档还是引用?</summary><br><b>\n</b></details>\n\n##### Queries\n\n<details>\n<summary>解释这个查询: <code>db.books.find({\"name\": /abc/})</code></summary><br><b>\n</b></details>\n\n<details>\n<summary>解释这个查询: <code>db.books.find().sort({x:1})</code></summary><br><b>\n</b></details>\n\n## OpenShift\n\n<a name=\"openshift-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是OpenShift? 你用过吗？ 如果有，是怎样使用的？</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能解释一下 OpenShift 和 Kubernetes 之间的区别吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>定义 Pods 以及解释什么是有状态的 pods</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些类型的构建策略?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释标签是什么以及它们的用途</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释什么是注释以及它们与标签的区别</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释什么是Downward API</summary><br><b>\n</b></details>\n\n## Shell 脚本\n\n<a name=\"shell-scripting-beginner\"></a>\n#### 初级\n\n<details>\n<summary>告诉我你使用Shell脚本的经验</summary><br><b>\n</b></details>\n\n<details>\n<summary>脚本中的这一行是什么意思?: <code>#!/bin/bash</code></summary><br><b>\n</b></details>\n\n<details>\n<summary>你倾向于在编写的每个脚本中包含什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>对还是错?: 当某个命令行失败时，默认情况下，该脚本将退出并且不会继续运行</summary><br><b>\n\n取决于所使用的语言和设置，例如在Bash中，默认情况下，脚本将继续运行。\n</b></details>\n\n<details>\n<summary>今天，我们拥有Ansible之类的工具和技术。 为什么还会有人使用Shell脚本?</summary><br><b>\n</b></details>\n\n<details>\n<summary>说出下面每个命令的结果是什么：\n\n  * <code>echo $0</code>\n  * <code>echo $?</code>\n  * <code>echo $$</code>\n  * <code>echo $@</code>\n  * <code>echo $#</code></summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何调试Shell脚本?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何在Shell脚本中从用户获得输入?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下条件语句以及如何使用它们</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是循环? 你熟悉哪些类型的循环?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释 <code>continue</code> 和 <code>break</code>. 你什么时候使用它们?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何将命令的输出存储在变量中?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何检查可变长度?</summary><br><b>\n</b></details>\n\n<details>\n<summary>单引号和双引号之间的区别是什么?</summary><br><b>\n</b></details>\n\n<a name=\"shell-scripting-advanced\"></a>\n#### 高级\n\n<details>\n<summary>解释以下代码:\n\n<code>:(){ :|:& };:</code>\n\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能举一些Bash最佳实践的例子吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是三元运算符？ 你如何在bash中使用它?</summary><br><b>\n\n使用 if/else 的一种简短方法。 一个例子:\n\n[[ $a = 1 ]] && b=\"yes, equal\" || b=\"nope\"\n</b></details>\n\n## SQL\n\n<a name=\"sql-beginner\"></a>\n#### 初级\n\n<details>\n<summary>SQL 代表什么?</summary><br><b>\n\nStructured Query Language（结构化查询语言）\n\n</b></details>\n\n<details>\n<summary>SQL 和 NoSQL 有那些不同</summary><br><b>\n\n主要区别在于SQL数据库是结构化的（数据以\n带有行和列的表格-像是Excel电子表格表格），而NoSQL是\n非结构化的，并且数据存储会根据NoSQL DB的设置方式而有所不同，例如\n作为键值对，面向文档等\n</b></details>\n\n<details>\n<summary>数据库符合ACID的含义是什么?</summary><br>\n\nACID代表原子性，一致性，隔离性，耐久性。为了符合ACID，数据库必须满足四个标准中的每个标准\n\n**原子性** - 数据库发生更改时，它整体上应该成功或失败。\n\n例如，如果你要更新表，则更新应完全执行。如果仅部分执行，则\n更新被视为整体失败，并且不会通过-数据库将恢复为原始状态\n更新发生之前的状态。还应该提到的是，原子性确保每个\n事务以其自身的独立“单元”完成 - 如果任何部分失败，则整个语句都会失败。\n\n**一致性** - 对数据库所做的任何更改都应将其从一种有效状态转变为另一种有效状态。\n\n例如，如果你对数据库进行了更改，则不应破坏它。通过检查和约束来保持一致性\n在数据库中预定义。例如，如果你尝试将列的值从字符串更改为int\n应该是数据类型字符串，一致的数据库将不允许该事务通过，并且该操作将\n不执行\n\n**隔离** - 确保数据库不会被“更新中”-因为多个事务正在运行\n同时，它仍应保持数据库处于与按顺序运行事务相同的状态。\n\n例如，假设有20个人同时对数据库进行了更改。在\n当你执行查询时，已完成20项更改中的15项，但仍有5项正在进行中。你应该\n仅看到已完成的15个更改 - 随着更改的进行，你将看不到数据库的更新中。\n\n**耐用性** - 更改一旦提交，无论发生什么情况都将保持提交状态\n（电源故障，系统崩溃等）。这意味着所有已完成的交易\n必须记录在非挥发性内存中。\n\n请注意，SQL本质上符合ACID。某些NoSQL DB可能符合ACID，具体取决于\n它们的工作方式，但是根据一般经验，NoSQL DB不被视为符合ACID\n</details>\n\n<details>\n<summary>什么时候最好使用SQL/NoSQL？</summary><br><b>\n\nSQL - 当数据完整性至关重要时，最适合使用。 由于符合ACID，SQL通常由许多业务实现特别是金融领域。\n\nNoSQL - 非常适合你需要快速扩展的情况。 请记住NoSQL是为Web应用程序设计的\n，如果你需要快速将相同信息散布到多台服务器，它将会很好的用\n此外，由于 NoSQL 不遵守具有列和行结构的严格表\n关系数据库所要求的，你可以将不同的数据类型存储在一起。\n</b></details>\n\n<details>\n<summary>什么是笛卡尔积?</summary><br>\n\n笛卡尔积是指第一个表中的所有行都与第二个表中的所有行连接在一起时的结果\n表。 这可以通过不定义要联接的键来隐式完成，也可以通过以下方式显式地完成：\n在两个表上调用CROSS JOIN，如下所示：\n\nSelect * from customers **CROSS JOIN** orders;\n\n请注意，笛卡尔积也可能是一件坏事 - 执行联接时\n在两个都没有唯一键的表上，这可能会导致返回信息\n是不正确的。\n</details>\n\n##### SQL Specific Questions\n\n对于这些问题，我们将使用下面显示的“客户和订单”表：\n\n**Customers**\n\nCustomer_ID | Customer_Name | Items_in_cart | Cash_spent_to_Date\n------------ | ------------- | ------------- | -------------\n100204 | John Smith | 0 | 20.00\n100205 | Jane Smith | 3 | 40.00\n100206 | Bobby Frank | 1 | 100.20\n\n**ORDERS**\n\nCustomer_ID | Order_ID | Item | Price | Date_sold\n------------ | ------------- | ------------- | ------------- | -------------\n100206 | A123 | Rubber Ducky | 2.20 | 2019-09-18\n100206 | A123 | Bubble Bath | 8.00 | 2019-09-18\n100206 | Q987 | 80-Pack TP | 90.00 | 2019-09-20\n100205 | Z001 | Cat Food - Tuna Fish | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Chicken | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Beef | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Kitty quesadilla | 10.00 | 2019-08-05\n100204 | X202 | Coffee | 20.00 | 2019-04-29\n\n<details>\n<summary>我如何从该表中选择所有字段?</summary><br><b>\n\nSelect * <br>\nFrom Customers;\n</b></details>\n\n<details>\n<summary>约翰的购物车中有几件？</summary><br><b>\n\nSelect Items_in_cart <br>\nFrom Customers <br>\nWhere Customer_Name = \"John Smith\";\n</b></details>\n\n<details>\n<summary>所有客户花费的所有现金的总和是多少?</summary><br><b>\n\nSelect SUM(Cash_spent_to_Date) as SUM_CASH <br>\nFrom Customers;\n</b></details>\n\n<details>\n<summary>在购物车有商品的有多少人?</summary><br><b>\n\nSelect count(1) as Number_of_People_w_items <br>\nFrom Customers <br>\nwhere Items_in_cart > 0;\n</b></details>\n\n<details>\n<summary>你如何将客户表加入订单表?</summary><br><b>\n\n你可以加入他们的唯一键。 在这种情况下，唯一键为中的Customer_ID\n客户表和订单表\n</b></details>\n\n<details>\n<summary>你如何显示哪些客户订购了哪些物品?</summary><br><b>\n\nSelect c.Customer_Name, o.Item <br>\nFrom Customers c <br>\nLeft Join Orders o <br>\n  On c.Customer_ID = o.Customer_ID;\n\n</b></details>\n\n<a name=\"sql-advanced\"></a>\n#### 高级\n\n<details>\n<summary>使用with语句，你将如何显示谁订购了猫粮以及花费的总金额?</summary><br><b>\n\nwith cat_food as ( <br>\nSelect Customer_ID, SUM(Price) as TOTAL_PRICE <br>\nFrom Orders <br>\nWhere Item like \"%Cat Food%\" <br>\nGroup by Customer_ID <br>\n) <br>\nSelect Customer_name, TOTAL_PRICE <br>\nFrom Customers c <br>\nInner JOIN cat_food f <br>\n  ON c.Customer_ID = f.Customer_ID <br>\nwhere c.Customer_ID in (Select Customer_ID from cat_food);\n\n尽管这是一个简单的声明，但“ with”子句在\n在连接到另一个表之前，需要在一个表上运行一个复杂的查询。 用语句很好，\n因为你在运行查询时会创建一个伪临时文件，而不是创建一个新表。\n\n目前尚无法获得所有猫粮的总和，因此我们使用了with语句来创建\n伪表检索每个客户花费的价格总和，然后正常加入该表。\n\n</b></details>\n\n## Azure\n\n<a name=\"azure-beginner\"></a>\n#### 初级\n\n<details>\n<summary>解释一下可用性集和可用性区域</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是Azure资源管理器？ 你可以描述ARM模板的格式吗？</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下Azure托管磁盘</summary><br><b>\n</b></details>\n\n## GCP\n\n<a name=\"gcp-beginner\"></a>\n#### 初级\n\n<details>\n<summary>GCP的主要组件和服务是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些GCP管理工具?</summary><br><b>\n</b></details>\n\n<details>\n<summary>告诉我对GCP联网了解多少</summary><br><b>\n</b></details>\n\n## OpenStack\n\n<a name=\"openstack-beginner\"></a>\n#### 初级\n\n<details>\n<summary>告诉我你使用OpenStack的经验。 你认为OpenStack的优缺点是什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉OpenStack的哪些组件/项目?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你能告诉我以下每个组件/项目负责什么吗?:\n\n  * Nova\n  * Neutron\n  * Cinder\n  * Glance\n  * Keystone</summary><br><b>\n</b></details>\n\n<details>\n<summary>详细描述如何使用可以从云外部访问的IP来启动实例</summary><br><b>\n</b></details>\n\n<details>\n<summary>你收到客户打来的电话，说：“我可以ping我的实例，但不能连接（ssh）它”。 可能是什么问题？</summary><br><b>\n</b></details>\n\n<details>\n<summary>OpenStack支持哪些类型的网络？</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何调试OpenStack存储问题？ （工具，日志等）</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何调试OpenStack计算问题？ （工具，日志等）</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉 TripleO吗? 它有那些优点?</summary><br><b>\n</b></details>\n\n##### 网络\n\n<details>\n<summary>什么是供应商网络?</summary><br><b>\n</b></details>\n\n<details>\n<summary>L2和L3中存在哪些组件和服务?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是ML2 plug-in? 解释一下它的架构</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是L2 代理? 它是怎么工作的以及它主要负责什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是L3 代理? 它是怎么工作的以及它主要负责什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释元数据代理是怎么工作的以及它主要负责什么</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何调试OpenStack网络问题？ （工具，日志等）</summary><br><b>\n</b></details>\n\n<a name=\"openstack-advanced\"></a>\n#### 中级\n\n##### 网络\n\n<details>\n<summary>解释 BGP 动态路由</summary>\n</b></details>\n\n## 安全\n\n<a name=\"security-beginner\"></a>\n#### 初级\n\n<details>\n<summary>你能描述一下DevSecOps的核心原理吗?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些DevOps安全最佳实践?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你熟悉哪些安全技术?</summary><br><b>\n</b></details>\n\n<details>\n<summary>如何在不同的工具和平台中管理密码?</summary><br><b>\n</b></details>\n\n<details>\n<summary>你如何识别和管理漏洞?</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是权限限制?</summary><br><b>\n</b></details>\n\n## Puppet\n\n<a name=\"puppet-beginner\"></a>\n#### 初级\n\n<details>\n<summary>什么是Puppet? 它是怎么工作的?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下 Puppet 结构</summary><br><b>\n</b></details>\n\n<details>\n<summary>你可以将Puppet与其他配置管理工具进行比较吗？ 你为什么选择使用Puppet？</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释以下:\n\n  * Module\n  * Manifest\n  * Node</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下Facter</summary><br><b>\n</b></details>\n\n<details>\n<summary>什么是MCollective?</summary><br><b>\n</b></details>\n\n<a name=\"puppet-advanced\"></a>\n#### 中级\n\n<details>\n<summary>你有编写模块的经验吗？ 你创建了哪个模块以及用于什么?</summary><br><b>\n</b></details>\n\n<details>\n<summary>解释一下什么是Hiera</summary><br><b>\n</b></details>\n\n## 场景\n\n方案是没有口头回答的问题，需要你满足以下条件之一：\n\n* 设置环境\n* 编写脚本\n* 设计和/或开发基础设施项目\n\n这些问题通常作为应聘者的一项家庭任务作为候选，可以将多个主题结合在一起。\n在下面，你可以找到一些场景问题：\n\n* [Elasticsearch & Kibana on AWS](scenarios/elk_kibana_aws.md)\n* [Ansible, Minikube and Docker](scenarios/ansible_minikube_docker.md)\n* [Cloud Slack bot](scenarios/cloud_slack_bot.md)\n* [Writing Jenkins Scripts](scenarios/jenkins_scripts.md)\n* [Writing Jenkins Pipelines](scenarios/jenkins_pipelines.md)\n\n<!-- {% endraw %} -->"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 174.97,
          "content": "<p align=\"center\"><img src=\"images/devops_exercises.png\"/></p>\n\n:information_source: &nbsp;This repo contains questions and exercises on various technical topics, sometimes related to DevOps and SRE\n\n:bar_chart: &nbsp;There are currently **2624** exercises and questions\n\n:warning: &nbsp;You can use these for preparing for an interview but most of the questions and exercises don't represent an actual interview. Please read [FAQ page](faq.md) for more details\n\n:stop_sign: &nbsp;If you are interested in pursuing a career as DevOps engineer, learning some of the concepts mentioned here would be useful, but you should know it's not about learning all the topics and technologies mentioned in this repository\n\n:pencil: &nbsp;You can add more exercises by submitting pull requests :) Read about contribution guidelines [here](CONTRIBUTING.md)\n\n****\n\n<!-- ALL-TOPICS-LIST:START -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<center>\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"topics/devops/README.md\"><img src=\"images/devops.png\" width=\"75px;\" height=\"75px;\" alt=\"DevOps\" /><br /><b>DevOps</b></a></td>\n    <td align=\"center\"><a href=\"topics/git/README.md\"><img src=\"images/git.png\" width=\"75px;\" height=\"75px;\" alt=\"Git\"/><br /><b>Git</b></a></td>\n    <td align=\"center\"><a href=\"#network\"><img src=\"images/network.png\" width=\"75px;\" height=\"75px;\" alt=\"Network\"/><br /><b>Network</b></a></td>\n    <td align=\"center\"><a href=\"#hardware\"><img src=\"images/hardware.png\" width=\"75px;\" height=\"75px;\" alt=\"Hardware\"/><br /><b>Hardware</b></a></td>\n    <td align=\"center\"><a href=\"topics/kubernetes/README.md\"><img src=\"images/kubernetes.png\" width=\"75px;\" height=\"75px;\" alt=\"kubernetes\"/><br /><b>Kubernetes</b></a></td>\n  </tr>\n\n  <tr>\n    <td align=\"center\"><a href=\"topics/software_development/README.md\"><img src=\"images/programming.png\" width=\"75px;\" height=\"75px;\" alt=\"programming\"/><br /><b>Software Development</b></a></td>\n    <td align=\"center\"><a href=\"https://github.com/bregman-arie/python-exercises\"><img src=\"images/python.png\" width=\"75px;\" height=\"75px;\" alt=\"Python\"/><br /><b>Python</b></a></td>\n    <td align=\"center\"><a href=\"https://github.com/bregman-arie/go-exercises\"><img src=\"images/Go.png\" width=\"75px;\" height=\"75px;\" alt=\"go\"/><br /><b>Go</b></a></td>\n    <td align=\"center\"><a href=\"topics/perl/README.md\"><img src=\"images/perl.png\" width=\"75px;\" height=\"75px;\" alt=\"perl\"/><br /><b>Perl</b></a></td>\n    <td align=\"center\"><a href=\"#regex\"><img src=\"images/regex.png\" width=\"75px;\" height=\"75px;\" alt=\"RegEx\"/><br /><b>Regex</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/cloud/README.md\"><img src=\"images/cloud.png\" width=\"75px;\" height=\"75px;\" alt=\"Cloud\"/><br /><b>Cloud</b></a></td>\n      <td align=\"center\"><a href=\"topics/aws/README.md\"><img src=\"images/aws.png\" width=\"100px;\" height=\"75px;\" alt=\"aws\"/><br /><b>AWS</b></a></td>\n      <td align=\"center\"><a href=\"topics/azure/README.md\"><img src=\"images/azure.png\" width=\"75px;\" height=\"75px;\" alt=\"azure\"/><br /><b>Azure</b></a></td>\n      <td align=\"center\"><a href=\"topics/gcp/README.md\"><img src=\"images/googlecloud.png\" width=\"70px;\" height=\"70px;\" alt=\"Google Cloud Platform\"/><br /><b>Google Cloud Platform</b></a></td>\n      <td align=\"center\"><a href=\"#openstack/README.md\"><img src=\"images/openstack.png\" width=\"75px;\" height=\"75px;\" alt=\"openstack\"/><br /><b>OpenStack</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"#operating-system\"><img src=\"images/os.png\" width=\"75px;\" height=\"75px;\" alt=\"Operating System\"/><br /><b>Operating System</b></a></td>\n      <td align=\"center\"><a href=\"topics/linux/README.md\"><img src=\"images/logos/linux.png\" width=\"75px;\" height=\"75px;\" alt=\"Linux\"/><br /><b>Linux</b></a></td>\n      <td align=\"center\"><a href=\"#virtualization\"><img src=\"images/virtualization.png\" width=\"75px;\" height=\"75px;\" alt=\"Virtualization\"/><br /><b>Virtualization</b></a></td>\n      <td align=\"center\"><a href=\"topics/dns/README.md\"><img src=\"images/dns.png\" width=\"75px;\" height=\"75px;\" alt=\"DNS\"/><br /><b>DNS</b></a></td>\n      <td align=\"center\"><a href=\"topics/shell/README.md\"><img src=\"images/bash.png\" width=\"75px;\" height=\"75px;\" alt=\"Bash\"/><br /><b>Shell Scripting</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/databases/README.md\"><img src=\"images/databases.png\" width=\"75px;\" height=\"75px;\" alt=\"Databases\"/><br /><b>Databases</b></a></td>\n      <td align=\"center\"><a href=\"#sql\"><img src=\"images/sql.png\" width=\"75px;\" height=\"75px;\" alt=\"sql\"/><br /><b>SQL</b></a></td>\n      <td align=\"center\"><a href=\"#mongo\"><img src=\"images/mongo.png\" width=\"75px;\" height=\"75px;\" alt=\"Mongo\"/><br /><b>Mongo</b></a></td>\n      <td align=\"center\"><a href=\"#testing\"><img src=\"images/testing.png\" width=\"75px;\" height=\"75px;\" alt=\"Testing\"/><br /><b>Testing</b></a></td>\n      <td align=\"center\"><a href=\"#big-data\"><img src=\"images/big-data.png\" width=\"75px;\" height=\"75px;\" alt=\"Big Data\"/><br /><b>Big Data</b></a></td>\n\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/cicd/README.md\"><img src=\"images/cicd.png\" width=\"75px;\" height=\"75px;\" alt=\"cicd\"/><br /><b>CI/CD</b></a></td>\n      <td align=\"center\"><a href=\"#certificates\"><img src=\"images/certificates.png\" width=\"75px;\" height=\"75px;\" alt=\"Certificates\"/><br /><b>Certificates</b></a></td>\n      <td align=\"center\"><a href=\"topics/containers/README.md\"><img src=\"images/containers.png\" width=\"75px;\" height=\"75px;\" alt=\"Containers\"/><br /><b>Containers</b></a></td>\n      <td align=\"center\"><a href=\"topics/openshift/README.md\"><img src=\"images/openshift.png\" width=\"75px;\" height=\"75px;\" alt=\"OpenShift\"/><br /><b>OpenShift</b></a></td>\n      <td align=\"center\"><a href=\"#storage\"><img src=\"images/storage.png\" width=\"75px;\" height=\"75px;\" alt=\"Storage\"/><br /><b>Storage</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/terraform/README.md\"><img src=\"images/terraform.png\" width=\"75px;\" height=\"75px;\" alt=\"Terraform\"/><br /><b>Terraform</b></a></td>\n      <td align=\"center\"><a href=\"#puppet\"><img src=\"images/puppet.png\" width=\"75px;\" height=\"75px;\" alt=\"puppet\"/><br /><b>Puppet</b></a></td>\n      <td align=\"center\"><a href=\"#distributed\"><img src=\"images/distributed.png\" width=\"75px;\" height=\"75px;\" alt=\"Distributed\"/><br /><b>Distributed</b></a></td>\n      <td align=\"center\"><a href=\"#questions-you-ask\"><img src=\"images/you.png\" width=\"75px;\" height=\"75px;\" alt=\"you\"/><br /><b>Questions you can ask</b></a></td>\n      <td align=\"center\"><a href=\"topics/ansible/README.md\"><img src=\"images/ansible.png\" width=\"75px;\" height=\"75px;\" alt=\"ansible\"/><br /><b>Ansible</b></a></td>\n  </tr>\n\n  <tr>\n      <td align=\"center\"><a href=\"topics/observability/README.md\"><img src=\"images/observability.png\" width=\"75px;\" height=\"75px;\" alt=\"observability\"/><br /><b>Observability</b></a></td>\n      <td align=\"center\"><a href=\"#prometheus\"><img src=\"images/prometheus.png\" width=\"75px;\" height=\"75px;\" alt=\"Prometheus\"/><br /><b>Prometheus</b></a></td>\n      <td align=\"center\"><a href=\"topics/circleci/README.md\"><img src=\"images/logos/circleci.png\" width=\"70px;\" height=\"70px;\" alt=\"Circle CI\"/><br /><b>Circle CI</b></a></td>\n      <td align=\"center\"><a href=\"topics/datadog/README.md\"><img src=\"images/logos/datadog.png\" width=\"80px;\" height=\"80px;\" alt=\"DataDog\"/><br /><b></b></a></td>\n      <td align=\"center\"><a href=\"topics/grafana/README.md\"><img src=\"images/logos/grafana.png\" width=\"80px;\" height=\"80px;\" alt=\"Grafana\"/><br /><b>Grafana</b></a></td>\n  </tr>\n\n  <tr>\n    <td align=\"center\"><a href=\"topics/argo/README.md\"><img src=\"images/logos/argo.png\" width=\"80px;\" height=\"80px;\" alt=\"Argo\"/><br /><b>Argo</b></a></td>\n    <td align=\"center\"><a href=\"topics/soft_skills/README.md\"><img src=\"images/HR.png\" width=\"75px;\" height=\"75px;\" alt=\"HR\"/><br /><b>Soft Skills</b></a></td>\n    <td align=\"center\"><a href=\"topics/security/README.md\"><img src=\"images/security.png\" width=\"75px;\" height=\"75px;\" alt=\"security\"/><br /><b>Security</b></a></td>\n    <td align=\"center\"><a href=\"#system-design\"><img src=\"images/design.png\" width=\"75px;\" height=\"75px;\" alt=\"Design\"/><br /><b>System Design</b></a></td>\n   </tr>\n\n   <tr>\n    <td align=\"center\"><a href=\"topics/chaos_engineering/README.md\"><img src=\"images/logos/chaos_engineering.png\" width=\"75px;\" height=\"75px;\" alt=\"Chaos Engineering\"/><br /><b>Chaos Engineering</b></a></td>\n    <td align=\"center\"><a href=\"#Misc\"><img src=\"images/general.png\" width=\"75px;\" height=\"75px;\" alt=\"Misc\"/><br /><b>Misc</b></a></td>\n    <td align=\"center\"><a href=\"#elastic\"><img src=\"images/elastic.png\" width=\"75px;\" height=\"75px;\" alt=\"Elastic\"/><br /><b>Elastic</b></a></td>\n    <td align=\"center\"><a href=\"topics/kafka/README.md\"><img src=\"images/logos/kafka.png\" width=\"85px;\" height=\"80px;\" alt=\"Kafka\"/><br /><b>Kafka</b></a></td>\n    <td align=\"center\"><a href=\"topics/node/node_questions_basic.md\"><img src=\"images/nodejs.png\" width=\"85px;\" height=\"80px;\" alt=\"NodeJs\"/><br /><b>NodeJs</b></a></td>\n   </tr>\n   \n</table>\n</center>\n<!-- markdownlint-enable -->\n<!-- prettier-ignore-end -->\n<!-- ALL-TOPICS-LIST:END -->\n\n## Network\n\n<details>\n<summary>In general, what do you need in order to communicate?</summary><br><b>\n\n  - A common language (for the two ends to understand)\n  - A way to address who you want to communicate with\n  - A Connection (so the content of the communication can reach the recipients)\n\n</b></details>\n\n<details>\n<summary>What is TCP/IP?</summary><br><b>\n\nA set of protocols that define how two or more devices can communicate with each other.\n\nTo learn more about TCP/IP, read [here](http://www.penguintutor.com/linux/basic-network-reference)\n\n</b></details>\n\n<details>\n<summary>What is Ethernet?</summary><br><b>\n\nEthernet simply refers to the most common type of Local Area Network (LAN) used today. A LAN—in contrast to a WAN (Wide Area Network), which spans a larger geographical area—is a connected network of computers in a small area, like your office, college campus, or even home.\n\n</b></details>\n\n<details>\n<summary>What is a MAC address? What is it used for?</summary><br><b>\n\nA MAC address is a unique identification number or code used to identify individual devices on the network.\n\nPackets that are sent on the ethernet are always coming from a MAC address and sent to a MAC address. If a network adapter is receiving a packet, it is comparing the packet’s destination MAC address to the adapter’s own MAC address.\n\n</b></details>\n\n<details>\n<summary>When is this MAC address used?: ff:ff:ff:ff:ff:ff</summary><br><b>\n\nWhen a device sends a packet to the broadcast MAC address (FF:FF:FF:FF:FF:FF​), it is delivered to all stations on the local network. Ethernet broadcasts are used to resolve IP addresses to MAC addresses (by ARP) at the data link layer.\n</b></details>\n\n<details>\n<summary>What is an IP address?</summary><br><b>\n\nAn Internet Protocol address (IP address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.An IP address serves two main functions: host or network interface identification and location addressing.\n</b></details>\n\n<details>\n<summary>Explain the subnet mask and give an example</summary><br><b>\n\nA Subnet mask is a 32-bit number that masks an IP address and divides the IP addresses into network addresses and host addresses. Subnet Mask is made by setting network bits to all \"1\"s and setting host bits to all \"0\"s. Within a given network, out of the total usable host addresses, two are always reserved for specific purposes and cannot be allocated to any host. These are the first address, which is reserved as a network address (a.k.a network ID), and the last address used for network broadcast.\n\n[Example](https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09)\n\n</b></details>\n\n<details>\n<summary>What is a private IP address? In which scenarios/system designs, one should use it?</summary><br><b>\nPrivate IP addresses are assigned to the hosts in the same network to communicate with one another. As the name \"private\" suggests, the devices having the private IP addresses assigned can't be reached by the devices from any external network. For example, if I am living in a hostel and I want my hostel mates to join the game server I have hosted, I will ask them to join via my server's private IP address, since the network is local to the hostel.\n</b></details>\n\n<details>\n<summary>What is a public IP address? In which scenarios/system designs, one should use it?</summary><br><b>\nA public IP address is a public-facing IP address. In the event that you were hosting a game server that you want your friends to join, you will give your friends your public IP address to allow their computers to identify and locate your network and server in order for the connection to take place. One time that you would not need to use a public-facing IP address is in the event that you were playing with friends who were connected to the same network as you, in that case, you would use a private IP address. In order for someone to be able to connect to your server that is located internally, you will have to set up a port forward to tell your router to allow traffic from the public domain into your network and vice versa.\n</b></details>\n\n<details>\n<summary>Explain the OSI model. What layers there are? What each layer is responsible for?</summary><br><b>\n\n- Application: user end (HTTP is here)\n- Presentation: establishes context between application-layer entities (Encryption is here)\n- Session: establishes, manages, and terminates the connections\n- Transport: transfers variable-length data sequences from a source to a destination host (TCP & UDP are here)\n- Network: transfers datagrams from one network to another (IP is here)\n- Data link: provides a link between two directly connected nodes (MAC is here)\n- Physical: the electrical and physical spec of the data connection (Bits are here)\n\nYou can read more about the OSI model in [penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference)\n</b></details>\n\n<details>\n<summary>For each of the following determines to which OSI layer it belongs:\n\n  * Error correction\n  * Packets routing\n  * Cables and electrical signals\n  * MAC address\n  * IP address\n  * Terminate connections\n  * 3 way handshake</summary><br><b>\n  * Error correction - Data link\n  * Packets routing - Network\n  * Cables and electrical signals - Physical\n  * MAC address - Data link\n  * IP address - Network\n  * Terminate connections - Session\n  * 3-way handshake - Transport\n</b></details>\n\n<details>\n<summary>What delivery schemes are you familiar with?</summary><br><b>\n\nUnicast: One-to-one communication where there is one sender and one receiver.\n\nBroadcast: Sending a message to everyone in the network. The address ff:ff:ff:ff:ff:ff is used for broadcasting.\n           Two common protocols which use broadcast are ARP and DHCP.\n\nMulticast: Sending a message to a group of subscribers. It can be one-to-many or many-to-many.\n</b></details>\n\n<details>\n<summary>What is CSMA/CD? Is it used in modern ethernet networks?</summary><br><b>\n\nCSMA/CD stands for Carrier Sense Multiple Access / Collision Detection.\nIts primary focus is to manage access to a shared medium/bus where only one host can transmit at a given point in time.\n\nCSMA/CD algorithm:\n\n1. Before sending a frame, it checks whether another host is already transmitting a frame.\n2. If no one is transmitting, it starts transmitting the frame.\n3. If two hosts transmit at the same time, we have a collision.\n4. Both hosts stop sending the frame and they send everyone a 'jam signal' notifying everyone that a collision occurred\n5. They are waiting for a random time before sending it again\n6. Once each host waited for a random time, they try to send the frame again and so the cycle starts again\n</b></details>\n\n<details>\n<summary>Describe the following network devices and the difference between them:\n\n  * router\n  * switch\n  * hub</summary><br><b>\n\nA router, switch, and hub are all network devices used to connect devices in a local area network (LAN). However, each device operates differently and has its specific use cases. Here is a brief description of each device and the differences between them:\n\n1. Router: a network device that connects multiple network segments together. It operates at the network layer (Layer 3) of the OSI model and uses routing protocols to direct data between networks. Routers use IP addresses to identify devices and route data packets to the correct destination.\n2. Switch: a network device that connects multiple devices on a LAN. It operates at the data link layer (Layer 2) of the OSI model and uses MAC addresses to identify devices and direct data packets to the correct destination. Switches allow devices on the same network to communicate with each other more efficiently and can prevent data collisions that can occur when multiple devices send data simultaneously.\n3. Hub: a network device that connects multiple devices through a single cable and is used to connect multiple devices without segmenting a network. However, unlike a switch, it operates at the physical layer (Layer 1) of the OSI model and simply broadcasts data packets to all devices connected to it, regardless of whether the device is the intended recipient or not. This means that data collisions can occur, and the network's efficiency can suffer as a result. Hubs are generally not used in modern network setups, as switches are more efficient and provide better network performance.\n</b></details>\n\n<details>\n<summary>What is a \"Collision Domain\"?</summary><br><b>\nA collision domain is a network segment in which devices can potentially interfere with each other by attempting to transmit data at the same time. When two devices transmit data at the same time, it can cause a collision, resulting in lost or corrupted data. In a collision domain, all devices share the same bandwidth, and any device can potentially interfere with the transmission of data by other devices.\n</b></details>\n\n<details>\n<summary>What is a \"Broadcast Domain\"?</summary><br><b>\nA broadcast domain is a network segment in which all devices can communicate with each other by sending broadcast messages. A broadcast message is a message that is sent to all devices in a network rather than a specific device. In a broadcast domain, all devices can receive and process broadcast messages, regardless of whether the message was intended for them or not.\n</b></details>\n\n<details>\n<summary>three computers connected to a switch. How many collision domains are there? How many broadcast domains?</summary><br><b>\n\nThree collision domains and one broadcast domain\n</b></details>\n\n<details>\n<summary>How does a router work?</summary><br><b>\n\nA router is a physical or virtual appliance that passes information between two or more packet-switched computer networks. A router inspects a given data packet's destination Internet Protocol address (IP address), calculates the best way for it to reach its destination, and then forwards it accordingly.\n\n</b></details>\n\n<details>\n<summary>What is NAT?</summary><br><b>\n\n Network Address Translation (NAT) is a process in which one or more local IP addresses are translated into one or more Global IP address and vice versa in order to provide Internet access to the local hosts.\n\n</b></details>\n\n<details>\n<summary>What is a proxy? How does it work? What do we need it for?</summary><br><b>\n\nA proxy server acts as a gateway between you and the internet. It’s an intermediary server separating end users from the websites they browse.\n\nIf you’re using a proxy server, internet traffic flows through the proxy server on its way to the address you requested. The request then comes back through that same proxy server (there are exceptions to this rule), and then the proxy server forwards the data received from the website to you.\n\nProxy servers provide varying levels of functionality, security, and privacy depending on your use case, needs, or company policy.\n</b></details>\n\n<details>\n<summary>What is TCP? How does it work? What is the 3-way handshake?</summary><br><b>\n\nTCP 3-way handshake or three-way handshake is a process that is used in a TCP/IP network to make a connection between server and client.\n\nA three-way handshake is primarily used to create a TCP socket connection. It works when:\n\n- A client node sends an SYN data packet over an IP network to a server on the same or an external network. The objective of this packet is to ask/infer if the server is open for new connections.\n- The target server must have open ports that can accept and initiate new connections. When the server receives the SYN packet from the client node, it responds and returns a confirmation receipt – the ACK packet or SYN/ACK packet.\n- The client node receives the SYN/ACK from the server and responds with an ACK packet.\n</b></details>\n\n<details>\n<summary>What is round-trip delay or round-trip time?</summary><br><b>\n\nFrom [wikipedia](https://en.wikipedia.org/wiki/Round-trip_delay): \"the length of time it takes for a signal to be sent plus the length of time it takes for an acknowledgment of that signal to be received\"\n\nBonus question: what is the RTT of LAN?\n</b></details>\n\n<details>\n<summary>How does an SSL handshake work?</summary><br><b>\nSSL handshake is a process that establishes a secure connection between a client and a server.\n\n1. The client sends a Client Hello message to the server, which includes the client's version of the SSL/TLS protocol, a list of the cryptographic algorithms supported by the client, and a random value.\n2. The server responds with a Server Hello message, which includes the server's version of the SSL/TLS protocol, a random value, and a session ID.\n3. The server sends a Certificate message, which contains the server's certificate.\n4. The server sends a Server Hello Done message, which indicates that the server is done sending messages for the Server Hello phase.\n5. The client sends a Client Key Exchange message, which contains the client's public key.\n6. The client sends a Change Cipher Spec message, which notifies the server that the client is about to send a message encrypted with the new cipher spec.\n7. The client sends an Encrypted Handshake Message, which contains the pre-master secret encrypted with the server's public key.\n8. The server sends a Change Cipher Spec message, which notifies the client that the server is about to send a message encrypted with the new cipher spec.\n9. The server sends an Encrypted Handshake Message, which contains the pre-master secret encrypted with the client's public key.\n10. The client and server can now exchange application data.\n</b></details>\n\n<details>\n<summary>What is the difference between TCP and UDP?</summary><br><b>\n\nTCP establishes a connection between the client and the server to guarantee the order of the packages, on the other hand, UDP does not establish a connection between the client and server and doesn't handle package orders. This makes UDP more lightweight than TCP and a perfect candidate for services like streaming.\n\n[Penguintutor.com](http://www.penguintutor.com/linux/basic-network-reference) provides a good explanation.\n</b></details>\n\n<details>\n<summary>What TCP/IP protocols are you familiar with?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain the \"default gateway\"</summary><br><b>\n\nA default gateway serves as an access point or IP router that a networked computer uses to send information to a computer in another network or the internet.\n</b></details>\n\n<details>\n<summary>What is ARP? How does it work?</summary><br><b>\n\nARP stands for Address Resolution Protocol. When you try to ping an IP address on your local network, say 192.168.1.1, your system has to turn the IP address 192.168.1.1 into a MAC address. This involves using ARP to resolve the address, hence its name.\n\nSystems keep an ARP look-up table where they store information about what IP addresses are associated with what MAC addresses. When trying to send a packet to an IP address, the system will first consult this table to see if it already knows the MAC address. If there is a value cached, ARP is not used.\n</b></details>\n\n<details>\n<summary>What is TTL? What does it help to prevent?</summary><br><b>\n\n- TTL (Time to Live) is a value in an IP (Internet Protocol) packet that determines how many hops or routers a packet can travel before it is discarded. Each time a packet is forwarded by a router, the TTL value is decreased by one. When the TTL value reaches zero, the packet is dropped, and an ICMP (Internet Control Message Protocol) message is sent back to the sender indicating that the packet has expired.\n- TTL is used to prevent packets from circulating indefinitely in the network, which can cause congestion and degrade network performance.\n- It also helps to prevent packets from being trapped in routing loops, where packets continuously travel between the same set of routers without ever reaching their destination.\n- In addition, TTL can be used to help detect and prevent IP spoofing attacks, where an attacker attempts to impersonate another device on the network by using a false or fake IP address. By limiting the number of hops that a packet can travel, TTL can help prevent packets from being routed to destinations that are not legitimate.\n</b></details>\n\n<details>\n<summary>What is DHCP? How does it work?</summary><br><b>\n\nIt stands for Dynamic Host Configuration Protocol and allocates IP addresses, subnet masks, and gateways to hosts. This is how it works:\n\n* A host upon entering a network broadcasts a message in search of a DHCP server (DHCP DISCOVER)\n* An offer message is sent back by the DHCP server as a packet containing lease time, subnet mask, IP addresses, etc (DHCP OFFER)\n* Depending on which offer is accepted, the client sends back a reply broadcast letting all DHCP servers know (DHCP REQUEST)\n* The server sends an acknowledgment (DHCP ACK)\n\nRead more [here](https://linuxjourney.com/lesson/dhcp-overview)\n</b></details>\n\n<details>\n<summary>Can you have two DHCP servers on the same network? How does it work?</summary><br><b>\n\nIt is possible to have two DHCP servers on the same network, however, it is not recommended, and it is important to configure them carefully to prevent conflicts and configuration problems.\n- When two DHCP servers are configured on the same network, there is a risk that both servers will assign IP addresses and other network configuration settings to the same device, which can cause conflicts and connectivity issues. Additionally, if the DHCP servers are configured with different network settings or options, devices on the network may receive conflicting or inconsistent configuration settings.\n- However, in some cases, it may be necessary to have two DHCP servers on the same network, such as in large networks where one DHCP server may not be able to handle all the requests. In such cases, DHCP servers can be configured to serve different IP address ranges or different subnets, so they do not interfere with each other.\n</b></details>\n\n<details>\n<summary>What is SSL tunneling? How does it work?</summary><br><b>\n\n- SSL (Secure Sockets Layer) tunneling is a technique used to establish a secure, encrypted connection between two endpoints over an insecure network, such as the Internet. The SSL tunnel is created by encapsulating the traffic within an SSL connection, which provides confidentiality, integrity, and authentication.\n\nHere's how SSL tunneling works:\n\n1. A client initiates an SSL connection to a server, which involves a handshake process to establish the SSL session.\n2. Once the SSL session is established, the client and server negotiate encryption parameters, such as the encryption algorithm and key length, then exchange digital certificates to authenticate each other.\n3. The client then sends traffic through the SSL tunnel to the server, which decrypts the traffic and forwards it to its destination.\n4. The server sends traffic back through the SSL tunnel to the client, which decrypts the traffic and forwards it to the application.\n</b></details>\n\n<details>\n<summary>What is a socket? Where can you see the list of sockets in your system?</summary><br><b>\n\n- A socket is a software endpoint that enables two-way communication between processes over a network. Sockets provide a standardized interface for network communication, allowing applications to send and receive data across a network. To view the list of open sockets on a Linux system: \n***netstat -an***\n- This command displays a list of all open sockets, along with their protocol, local address, foreign address, and state.\n</b></details>\n\n<details>\n<summary>What is IPv6? Why should we consider using it if we have IPv4?</summary><br><b>\n\n- IPv6 (Internet Protocol version 6) is the latest version of the Internet Protocol (IP), which is used to identify and communicate with devices on a network. IPv6 addresses are 128-bit addresses and are expressed in hexadecimal notation, such as 2001:0db8:85a3:0000:0000:8a2e:0370:7334.\n\nThere are several reasons why we should consider using IPv6 over IPv4:\n\n1. Address space: IPv4 has a limited address space, which has been exhausted in many parts of the world. IPv6 provides a much larger address space, allowing for trillions of unique IP addresses.\n2. Security: IPv6 includes built-in support for IPsec, which provides end-to-end encryption and authentication for network traffic.\n3. Performance: IPv6 includes features that can help to improve network performance, such as multicast routing, which allows a single packet to be sent to multiple destinations simultaneously.\n4. Simplified network configuration: IPv6 includes features that can simplify network configuration, such as stateless autoconfiguration, which allows devices to automatically configure their own IPv6 addresses without the need for a DHCP server.\n5. Better mobility support: IPv6 includes features that can improve mobility support, such as Mobile IPv6, which allows devices to maintain their IPv6 addresses as they move between different networks.\n</b></details>\n\n<details>\n<summary>What is VLAN?</summary><br><b>\n\n- A VLAN (Virtual Local Area Network) is a logical network that groups together a set of devices on a physical network, regardless of their physical location. VLANs are created by configuring network switches to assign a specific VLAN ID to frames sent by devices connected to a specific port or group of ports on the switch.\n</b></details>\n\n<details>\n<summary>What is MTU?</summary><br><b>\n\t\nMTU stands for Maximum Transmission Unit. It's the size of the largest PDU (protocol Data Unit) that can be sent in a single transaction.\n</b></details>\n\n<details>\n<summary>What happens if you send a packet that is bigger than the MTU?</summary><br><b>\n\t\nWith the IPv4 protocol, the router can fragment the PDU and then send all the fragmented PDU through the transaction.\n\t\nWith IPv6 protocol, it issues an error to the user's computer.\n</b></details>\n\n<details>\n<summary>True or False? Ping is using UDP because it doesn't care about reliable connection</summary><br><b>\n\nFalse. Ping is actually using ICMP (Internet Control Message Protocol) which is a network protocol used to send diagnostic messages and control messages related to network communication.\n</b></details>\n\n<details>\n<summary>What is SDN?</summary><br><b>\n\n- SDN stands for Software-Defined Networking. It is an approach to network management that emphasizes the centralization of network control, enabling administrators to manage network behavior through a software abstraction.\n- In a traditional network, network devices such as routers, switches, and firewalls are configured and managed individually, using specialized software or command-line interfaces. In contrast, SDN separates the network control plane from the data plane, allowing administrators to manage network behavior through a centralized software controller.\n</b></details>\n\n<details>\n<summary>What is ICMP? What is it used for?</summary><br><b>\n\n- ICMP stands for Internet Control Message Protocol. It is a protocol used for diagnostic and control purposes in IP networks. It is a part of the Internet Protocol suite, operating at the network layer.\n\nICMP messages are used for a variety of purposes, including:\n1. Error reporting: ICMP messages are used to report errors that occur in the network, such as a packet that could not be delivered to its destination.\n2. Ping: ICMP is used to send ping messages, which are used to test whether a host or network is reachable and to measure the round-trip time for packets.\n3. Path MTU discovery: ICMP is used to discover the Maximum Transmission Unit (MTU) of a path, which is the largest packet size that can be transmitted without fragmentation.\n4. Traceroute: ICMP is used by the traceroute utility to trace the path that packets take through the network.\n5. Router discovery: ICMP is used to discover the routers in a network.\n</b></details>\n\n<details>\n<summary>What is NAT? How does it work?</summary><br><b>\n\nNAT stands for Network Address Translation. It’s a way to map multiple local private addresses to a public one before transferring the information. Organizations that want multiple devices to employ a single IP address use NAT, as do most home routers.\nFor example, your computer's private IP could be 192.168.1.100, but your router maps the traffic to its public IP (e.g. 1.1.1.1). Any device on the internet would see the traffic coming from your public IP (1.1.1.1) instead of your private IP (192.168.1.100).\n</b></details>\n\n<details>\n<summary>Which port number is used in each of the following protocols?:\n\n  * SSH\n  * SMTP\n  * HTTP\n  * DNS\n  * HTTPS\n  * FTP\n  * SFTP\n</summary><br><b>\n\n  * SSH - 22\n  * SMTP - 25\n  * HTTP - 80\n  * DNS - 53\n  * HTTPS - 443\n  * FTP - 21\n  * SFTP - 22\n</b></details>\n\n<details>\n<summary>Which factors affect network performance?</summary><br><b>\n\nSeveral factors can affect network performance, including:\n\n1. Bandwidth: The available bandwidth of a network connection can significantly impact its performance. Networks with limited bandwidth can experience slow data transfer rates, high latency, and poor responsiveness.\n2. Latency: Latency refers to the delay that occurs when data is transmitted from one point in a network to another. High latency can result in slow network performance, especially for real-time applications like video conferencing and online gaming.\n3. Network congestion: When too many devices are using a network at the same time, network congestion can occur, leading to slow data transfer rates and poor network performance.\n4. Packet loss: Packet loss occurs when packets of data are dropped during transmission. This can result in slower network speeds and lower overall network performance.\n5. Network topology: The physical layout of a network, including the placement of switches, routers, and other network devices, can impact network performance.\n6. Network protocol: Different network protocols have different performance characteristics, which can impact network performance. For example, TCP is a reliable protocol that can guarantee the delivery of data, but it can also result in slower performance due to the overhead required for error checking and retransmission.\n7. Network security: Security measures such as firewalls and encryption can impact network performance, especially if they require significant processing power or introduce additional latency.\n8. Distance: The physical distance between devices on a network can impact network performance, especially for wireless networks where signal strength and interference can affect connectivity and data transfer rates.\n</b></details>\n\n<details>\n<summary>What is APIPA?</summary><br><b>\n\nAPIPA is a set of IP addresses that devices are allocated\nwhen the main DHCP server is not reachable\n\n</b></details>\n\n<details>\n<summary>What IP range does APIPA use?</summary><br><b>\n\nAPIPA uses the IP range: 169.254.0.1 - 169.254.255.254.\n\n</b></details>\n\n#### Control Plane and Data Plane\n\n<details>\n<summary>What does \"control plane\" refer to?</summary><br><b>\n\nThe control plane is a part of the network that decides how to route and forward packets to a different location.\n</b></details>\n\n<details>\n<summary>What does \"data plane\" refer to?</summary><br><b>\n\nThe data plane is a part of the network that actually forwards the data/packets.\n</b></details>\n\n<details>\n<summary>What does \"management plane\" refer to?</summary><br><b>\n\nIt refers to monitoring and management functions.\n</b></details>\n\n<details>\n<summary>To which plane (data, control, ...) does creating routing tables belong to?</summary><br><b>\n\nControl Plane.\n</b></details>\n\n<details>\n<summary>Explain Spanning Tree Protocol (STP).</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is link aggregation? Why is it used?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is Asymmetric Routing? How to deal with it?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What overlay (tunnel) protocols are you familiar with?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is GRE? How does it work?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is VXLAN? How does it work?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is SNAT?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain OSPF.</summary><br><b>\n\n\nOSPF (Open Shortest Path First) is a routing protocol that can be implemented on various types of routers. In general, OSPF is supported on most modern routers, including those from vendors such as Cisco, Juniper, and Huawei. The protocol is designed to work with IP-based networks, including both IPv4 and IPv6. Also, it uses a hierarchical network design, where routers are grouped into areas, with each area having its own topology map and routing table. This design helps to reduce the amount of routing information that needs to be exchanged between routers and improve network scalability.\n\nThe OSPF 4 Types of routers are:\n  * Internal Router\n  * Area Border Routers\n  * Autonomous Systems Boundary Routers\n  * Backbone Routers\n\n  Learn more about OSPF router types: https://www.educba.com/ospf-router-types/\n</b></details>\n\n<details>\n<summary>What is latency?</summary><br><b>\n\t\nLatency is the time taken for information to reach its destination from the source.\n</b></details>\n\n<details>\n<summary>What is bandwidth?</summary><br><b>\n\t\nBandwidth is the capacity of a communication channel to measure how much data the latter can handle over a specific time period. More bandwidth would imply more traffic handling and thus more data transfer.\n</b></details>\n\n<details>\n<summary>What is throughput?</summary><br><b>\n\t\nThroughput refers to the measurement of the real amount of data transferred over a certain period of time across any transmission channel.\n</b></details>\n\n<details>\n<summary>When performing a search query, what is more important, latency or throughput? And how to ensure that we manage global infrastructure?\n</summary><br><b>\n\nLatency. To have good latency, a search query should be forwarded to the closest data center.\n</b></details>\n\n<details>\n<summary>When uploading a video, what is more important, latency or throughput? And how to assure that?</summary><br><b>\n\nThroughput. To have good throughput, the upload stream should be routed to an underutilized link.\n</b></details>\n\n<details>\n<summary>What other considerations (except latency and throughput) are there when forwarding requests?</summary><br><b>\n\n* Keep caches updated (which means the request could be forwarded not to the closest data center)\n</b></details>\n\n<details>\n<summary>Explain Spine & Leaf</summary><br><b>\n\"Spine & Leaf\" is a networking topology commonly used in data center environments to connect multiple switches and manage network traffic efficiently. It is also known as \"spine-leaf\" architecture or \"leaf-spine\" topology. This design provides high bandwidth, low latency, and scalability, making it ideal for modern data centers handling large volumes of data and traffic.\n\nWithin a Spine & Leaf network there are two main tipology of switches:\n\n* Spine Switches: Spine switches are high-performance switches arranged in a spine layer. These switches act as the core of the network and are typically interconnected with each leaf switch. Each spine switch is connected to all the leaf switches in the data center.\n* Leaf Switches: Leaf switches are connected to end devices like servers, storage arrays, and other networking equipment. Each leaf switch is connected to every spine switch in the data center. This creates a non-blocking, full-mesh connectivity between leaf and spine switches, ensuring any leaf switch can communicate with any other leaf switch with maximum throughput.\n\nThe Spine & Leaf architecture has become increasingly popular in data centers due to its ability to handle the demands of modern cloud computing, virtualization, and big data applications, providing a scalable, high-performance, and reliable network infrastructure\n</b></details>\n\n<details>\n<summary>What is Network Congestion? What can cause it?</summary><br><b>\n\nNetwork congestion occurs when there is too much data to transmit on a network and it doesn't have enough capacity to handle the demand. </br>\nThis can lead to increased latency and packet loss. The causes can be multiple, such as high network usage, large file transfers, malware, hardware issues, or network design problems. </br>\nTo prevent network congestion, it's important to monitor your network usage and implement strategies to limit or manage the demand.\n</b></details>\n\n<details>\n<summary>What can you tell me about the UDP packet format? What about the TCP packet format? How is it different?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the exponential backoff algorithm? Where is it used?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Using Hamming code, what would be the code word for the following data word 100111010001101?</summary><br><b>\n\n00110011110100011101\n</b></details>\n\n<details>\n<summary>Give examples of protocols found in the application layer</summary><br><b>\n\n* Hypertext Transfer Protocol (HTTP) - used for the webpages on the internet\n* Simple Mail Transfer Protocol (SMTP) - email transmission\n* Telecommunications Network - (TELNET) - terminal emulation to allow a client access to a telnet server\n* File Transfer Protocol (FTP) - facilitates the transfer of files between any two machines\n* Domain Name System (DNS) - domain name translation\n* Dynamic Host Configuration Protocol (DHCP) - allocates IP addresses, subnet masks, and gateways to hosts\n* Simple Network Management Protocol (SNMP) - gathers data on devices on the network\n</b></details>\n\n<details>\n<summary>Give examples of protocols found in the Network Layer</summary><br><b>\n\n* Internet Protocol (IP) - assists in routing packets from one machine to another\n* Internet Control Message Protocol (ICMP) - lets one know what is going such as error messages and debugging information\n</b></details>\n\n<details>\n<summary>What is HSTS?</summary><br><b>\nHTTP Strict Transport Security is a web server directive that informs user agents and web browsers how to handle its connection through a response header sent at the very beginning and back to the browser. This forces connections over HTTPS encryption, disregarding any script's call to load any resource in that domain over HTTP.\n\nRead more [here](https://www.globalsign.com/en/blog/what-is-hsts-and-how-do-i-use-it#:~:text=HTTP%20Strict%20Transport%20Security%20(HSTS,and%20back%20to%20the%20browser.)\n</b></details>\n\n#### Network - Misc\n\n<details>\n<summary>What is the Internet? Is it the same as the World Wide Web?</summary><br><b>\n\nThe internet refers to a network of networks, transferring huge amounts of data around the globe.<br>\nThe World Wide Web is an application running on millions of servers, on top of the internet, accessed through what is known as the web browser\n</b></details>\n\n<details>\n<summary>What is the ISP?</summary><br><b>\n\nISP (Internet Service Provider) is the local internet company provider.\n</b></details>\n\n## Operating System\n\n### Operating System Exercises\n\n|Name|Topic|Objective & Instructions|Solution|Comments|\n|--------|--------|------|----|----|\n|Fork 101|Fork|[Link](topics/os/fork_101.md)|[Link](topics/os/solutions/fork_101_solution.md)\n|Fork 102|Fork|[Link](topics/os/fork_102.md)|[Link](topics/os/solutions/fork_102_solution.md)\n\n### Operating System - Self Assessment\n\n<details>\n<summary>What is an operating system?</summary><br><b>\n\nFrom the book \"Operating Systems: Three Easy Pieces\":\n\n\"responsible for making it easy to run programs (even allowing you to seemingly run many at the same time), allowing programs to share memory, enabling programs to interact with devices, and other fun stuff like that\".\n</b></details>\n\n#### Operating System - Process\n\n<details>\n<summary>Can you explain what is a process?</summary><br><b>\n\nA process is a running program. A program is one or more instructions and the program (or process) is executed by the operating system.\n</b></details>\n\n<details>\n<summary>If you had to design an API for processes in an operating system, what would this API look like?</summary><br><b>\n\nIt would support the following:\n\n* Create - allow to create new processes\n* Delete - allow to remove/destroy processes\n* State - allow to check the state of the process, whether it's running, stopped, waiting, etc.\n* Stop - allow to stop a running process\n</b></details>\n\n<details>\n<summary>How a process is created?</summary><br><b>\n\n* The OS is reading program's code and any additional relevant data\n* Program's code is loaded into the memory or more specifically, into the address space of the process.\n* Memory is allocated for program's stack (aka run-time stack). The stack also initialized by the OS with data like argv, argc and parameters to main()\n* Memory is allocated for program's heap which is required for dynamically allocated data like the data structures linked lists and hash tables\n* I/O initialization tasks are performed, like in Unix/Linux based systems, where each process has 3 file descriptors (input, output and error)\n* OS is running the program, starting from main()\n</b></details>\n\n<details>\n<summary>True or False? The loading of the program into the memory is done eagerly (all at once)</summary><br><b>\n\nFalse. It was true in the past but today's operating systems perform lazy loading, which means only the relevant pieces required for the process to run are loaded first.\n</b></details>\n\n<details>\n<summary>What are different states of a process?</summary><br><b>\n\n* Running - it's executing instructions\n* Ready - it's ready to run, but for different reasons it's on hold\n* Blocked - it's waiting for some operation to complete, for example I/O disk request\n</b></details>\n\n<details>\n<summary>What are some reasons for a process to become blocked?</summary><br><b>\n\n  - I/O operations (e.g. Reading from a disk)\n  - Waiting for a packet from a network\n</b></details>\n\n<details>\n<summary>What is Inter Process Communication (IPC)?</summary><br><b>\n\nInter-process communication (IPC) refers to the mechanisms provided by an operating system that allow processes to manage shared data.\n</b></details>\n\n<details>\n<summary>What is \"time sharing\"?</summary><br><b>\n\nEven when using a system with one physical CPU, it's possible to allow multiple users to work on it and run programs. This is possible with time sharing, where computing resources are shared in a way it seems to the user, the system has multiple CPUs, but in fact it's simply one CPU shared by applying multiprogramming and multi-tasking.\n</b></details>\n\n<details>\n<summary>What is \"space sharing\"?</summary><br><b>\n\nSomewhat the opposite of time sharing. While in time sharing a resource is used for a while by one entity and then the same resource can be used by another resource, in space sharing the space is shared by multiple entities but in a way where it's not being transferred between them.<br>\nIt's used by one entity, until this entity decides to get rid of it. Take for example storage. In storage, a file is yours, until you decide to delete it.\n</b></details>\n\n<details>\n<summary>What component determines which process runs at a given moment in time?</summary><br><b>\n\nCPU scheduler\n</b></details>\n\n#### Operating System - Memory\n\n<details>\n<summary>What is \"virtual memory\" and what purpose does serve?</summary><br><b>\n\nVirtual memory combines your computer's RAM with temporary space on your hard disk. When RAM runs low, virtual memory helps to move data from RAM to a space called a paging file. Moving data to paging file can free up the RAM, so your computer can complete its work. In general, the more RAM your computer has, the faster the programs run.\nhttps://www.minitool.com/lib/virtual-memory.html\n</b></details>\n\n<details>\n<summary>What is demand paging?</summary><br><b>\n\nDemand paging is a memory management technique where pages are loaded into physical memory only when accessed by a process. It optimizes memory usage by loading pages on demand, reducing startup latency and space overhead. However, it introduces some latency when accessing pages for the first time. Overall, it’s a cost-effective approach for managing memory resources in operating systems. \n</b></details>\n\n<details>\n<summary>What is copy-on-write?</summary><br><b>\nCopy-on-write (COW) is a resource management concept, with the goal to reduce unnecessary copying of information. It is a concept, which is implemented for instance within the POSIX fork syscall, which creates a duplicate process of the calling process.\n\nThe idea:\n1. If resources are shared between 2 or more entities (for example shared memory segments between 2 processes), the resources don't need to be copied for every entity, but rather every entity has a READ operation access permission on the shared resource. (the shared segments are marked as read-only) \n(Think of every entity having a pointer to the location of the shared resource, which can be dereferenced to read its value)\n2. If one entity would perform a WRITE operation on a shared resource, a problem would arise, since the resource also would be permanently changed for ALL other entities sharing it.\n(Think of a process modifying some variables on the stack, or allocatingy some data dynamically on the heap, these changes to the shared resource would also apply for ALL other processes, this is definitely an undesirable behaviour)\n3. As a solution only, if a WRITE operation is about to be performed on a shared resource, this resource gets COPIED first and then the changes are applied.\n</b></details>\n\n<details>\n<summary>What is a kernel, and what does it do?</summary><br><b>\n\nThe kernel is part of the operating system and is responsible for tasks like:\n\n  * Allocating memory\n  * Schedule processes\n  * Control CPU\n</b></details>\n\n<details>\n<summary>True or False? Some pieces of the code in the kernel are loaded into protected areas of the memory so applications can't overwrite them.</summary><br><b>\n\nTrue\n</b></details>\n\n<details>\n<summary>What is POSIX?</summary><br><b>\n\nPOSIX (Portable Operating System Interface) is a set of standards that define the interface between a Unix-like operating system and application programs.\n</b></details>\n\n<details>\n<summary>Explain what is Semaphore and what its role in operating systems.</summary><br><b>\n\nA semaphore is a synchronization primitive used in operating systems and concurrent programming to control access to shared resources. It's a variable or abstract data type that acts as a counter or a signaling mechanism for managing access to resources by multiple processes or threads.\n</b></details>\n\n<details>\n<summary>What is cache? What is buffer?</summary><br><b>\n\nCache: Cache is usually used when processes are reading and writing to the disk to make the process faster, by making similar data used by different programs easily accessible.\nBuffer: Reserved place in RAM, which is used to hold data for temporary purposes.\n</b></details>\n\n## Virtualization\n\n<details>\n<summary>What is Virtualization?</summary><br><b>\n\nVirtualization uses software to create an abstraction layer over computer hardware, that allows the hardware elements of a single computer - processors, memory, storage and more - to be divided into multiple virtual computers, commonly called virtual machines (VMs).\n</b></details>\n\n<details>\n<summary>What is a hypervisor?</summary><br><b>\n\nRed Hat: \"A hypervisor is software that creates and runs virtual machines (VMs). A hypervisor, sometimes called a virtual machine monitor (VMM), isolates the hypervisor operating system and resources from the virtual machines and enables the creation and management of those VMs.\"\n\nRead more [here](https://www.redhat.com/en/topics/virtualization/what-is-a-hypervisor)\n</b></details>\n\n<details>\n<summary>What types of hypervisors are there?</summary><br><b>\n\nHosted hypervisors and bare-metal hypervisors.\n</b></details>\n\n<details>\n<summary>What are the advantages and disadvantges of bare-metal hypervisor over a hosted hypervisor?</summary><br><b>\n\nDue to having its own drivers and a direct access to hardware components, a baremetal hypervisor will often have better performances along with stability and scalability.\n\nOn the other hand, there will probably be some limitation regarding loading (any) drivers so a hosted hypervisor will usually benefit from having a better hardware compatibility.\n</b></details>\n\n<details>\n<summary>What types of virtualization are there?</summary><br><b>\n\nOperating system virtualization\nNetwork functions virtualization\nDesktop virtualization\n</b></details>\n\n<details>\n<summary>Is containerization is a type of Virtualization?</summary><br><b>\n\nYes, it's a operating-system-level virtualization, where the kernel is shared and allows to use multiple isolated user-spaces instances.\n</b></details>\n\n<details>\n<summary>How the introduction of virtual machines changed the industry and the way applications were deployed?</summary><br><b>\n\nThe introduction of virtual machines allowed companies to deploy multiple business applications on the same hardware, while each application is separated from each other in secured way, where each is running on its own separate operating system.\n</b></details>\n\n#### Virtual Machines\n\n<details>\n<summary>Do we need virtual machines in the age of containers? Are they still relevant?</summary><br><b>\n\nYes, virtual machines are still relevant even in the age of containers. While containers provide a lightweight and portable alternative to virtual machines, they do have certain limitations. Virtual machines still matter because they offer isolation and security, can run different operating systems, and are good for legacy apps. Containers limitations for example are sharing the host kernel.\n</b></details>\n\n## Prometheus\n\n<details>\n<summary>What is Prometheus? What are some of Prometheus's main features?</summary><br><b>\n\nPrometheus is a popular open-source systems monitoring and alerting toolkit, originally developed at SoundCloud. It is designed to collect and store time-series data, and to allow for querying and analysis of that data using a powerful query language called PromQL. Prometheus is frequently used to monitor cloud-native applications, microservices, and other modern infrastructure.\n\nSome of the main features of Prometheus include:\n\n    1. Data model: Prometheus uses a flexible data model that allows users to organize and label their time-series data in a way that makes sense for their particular use case. Labels are used to identify different dimensions of the data, such as the source of the data or the environment in which it was collected.\n\n    2. Pull-based architecture: Prometheus uses a pull-based model to collect data from targets, meaning that the Prometheus server actively queries its targets for metrics data at regular intervals. This architecture is more scalable and reliable than a push-based model, which would require every target to push data to the server.\n\n    3. Time-series database: Prometheus stores all of its data in a time-series database, which allows users to perform queries over time ranges and to aggregate and analyze their data in various ways. The database is optimized for write-heavy workloads, and can handle a high volume of data with low latency.\n\n    4. Alerting: Prometheus includes a powerful alerting system that allows users to define rules based on their metrics data and to send alerts when certain conditions are met. Alerts can be sent via email, chat, or other channels, and can be customized to include specific details about the problem.\n\n    5. Visualization: Prometheus has a built-in graphing and visualization tool, called PromDash, which allows users to create custom dashboards to monitor their systems and applications. PromDash supports a variety of graph types and visualization options, and can be customized using CSS and JavaScript.\n\nOverall, Prometheus is a powerful and flexible tool for monitoring and analyzing systems and applications, and is widely used in the industry for cloud-native monitoring and observability.\n\n</b></details>\n\n<details>\n<summary>In what scenarios it might be better to NOT use Prometheus?</summary><br><b>\n\nFrom Prometheus documentation: \"if you need 100% accuracy, such as for per-request billing\".\n</b></details>\n\n<details>\n<summary>Describe Prometheus architecture and components</summary><br><b>\n\nThe Prometheus architecture consists of four major components:\n\n    1. Prometheus Server: The Prometheus server is responsible for collecting and storing metrics data. It has a simple built-in storage layer that allows it to store time-series data in a time-ordered database.\n\n    2. Client Libraries: Prometheus provides a range of client libraries that enable applications to expose their metrics data in a format that can be ingested by the Prometheus server. These libraries are available for a range of programming languages, including Java, Python, and Go.\n\n    3. Exporters: Exporters are software components that expose existing metrics from third-party systems and make them available for ingestion by the Prometheus server. Prometheus provides exporters for a range of popular technologies, including MySQL, PostgreSQL, and Apache.\n\n    4. Alertmanager: The Alertmanager component is responsible for processing alerts generated by the Prometheus server. It can handle alerts from multiple sources and provides a range of features for deduplicating, grouping, and routing alerts to appropriate channels.\n\nOverall, the Prometheus architecture is designed to be highly scalable and resilient. The server and client libraries can be deployed in a distributed fashion to support monitoring across large-scale, highly dynamic environments\n</b></details>\n\n<details>\n<summary>Can you compare Prometheus to other solutions like InfluxDB for example?</summary><br><b>\n\nCompared to other monitoring solutions, such as InfluxDB, Prometheus is known for its high performance and scalability. It can handle large volumes of data and can easily be integrated with other tools in the monitoring ecosystem. InfluxDB, on the other hand, is known for its ease of use and simplicity. It has a user-friendly interface and provides easy-to-use APIs for collecting and querying data.\n\nAnother popular solution, Nagios, is a more traditional monitoring system that relies on a push-based model for collecting data. Nagios has been around for a long time and is known for its stability and reliability. However, compared to Prometheus, Nagios lacks some of the more advanced features, such as multi-dimensional data model and powerful query language.\n\nOverall, the choice of a monitoring solution depends on the specific needs and requirements of the organization. While Prometheus is a great choice for large-scale monitoring and alerting, InfluxDB may be a better fit for smaller environments that require ease of use and simplicity. Nagios remains a solid choice for organizations that prioritize stability and reliability over advanced features.\n</b></details>\n\n<details>\n<summary>What is an Alert?</summary><br><b>\nIn Prometheus, an alert is a notification triggered when a specific condition or threshold is met. Alerts can be configured to trigger when certain metrics cross a certain threshold or when specific events occur. Once an alert is triggered, it can be routed to various channels, such as email, pager, or chat, to notify relevant teams or individuals to take appropriate action. Alerts are a critical component of any monitoring system, as they allow teams to proactively detect and respond to issues before they impact users or cause system downtime.\n</b></details>\n\n<details>\n<summary>What is an Instance? What is a Job?</summary><br><b>\n\nIn Prometheus, an instance refers to a single target that is being monitored. For example, a single server or service. A job is a set of instances that perform the same function, such as a set of web servers serving the same application. Jobs allow you to define and manage a group of targets together.\n\nIn essence, an instance is an individual target that Prometheus collects metrics from, while a job is a collection of similar instances that can be managed as a group.\n</b></details>\n\n<details>\n<summary>What core metrics types Prometheus supports?</summary><br><b>\nPrometheus supports several types of metrics, including:\n\n    1. Counter: A monotonically increasing value used for tracking counts of events or samples. Examples include the number of requests processed or the total number of errors encountered.\n\n    2. Gauge: A value that can go up or down, such as CPU usage or memory usage. Unlike counters, gauge values can be arbitrary, meaning they can go up and down based on changes in the system being monitored.\n\n    3. Histogram: A set of observations or events that are divided into buckets based on their value. Histograms help in analyzing the distribution of a metric, such as request latencies or response sizes.\n\n    4. Summary: A summary is similar to a histogram, but instead of buckets, it provides a set of quantiles for the observed values. Summaries are useful for monitoring the distribution of request latencies or response sizes over time.\n\nPrometheus also supports various functions and operators for aggregating and manipulating metrics, such as sum, max, min, and rate. These features make it a powerful tool for monitoring and alerting on system metrics.\n</b></details>\n\n<details>\n<summary>What is an exporter? What is it used for?</summary><br><b>\nThe exporter serves as a bridge between the third-party system or application and Prometheus, making it possible for Prometheus to monitor and collect data from that system or application.\n\nThe exporter acts as a server, listening on a specific network port for requests from Prometheus to scrape metrics. It collects metrics from the third-party system or application and transforms them into a format that can be understood by Prometheus. The exporter then exposes these metrics to Prometheus via an HTTP endpoint, making them available for collection and analysis.\n\nExporters are commonly used to monitor various types of infrastructure components such as databases, web servers, and storage systems. For example, there are exporters available for monitoring popular databases such as MySQL and PostgreSQL, as well as web servers like Apache and Nginx.\n\nOverall, exporters are a critical component of the Prometheus ecosystem, allowing for the monitoring of a wide range of systems and applications, and providing a high degree of flexibility and extensibility to the platform.\n</b></details>\n\n<details>\n<summary>Which Prometheus best practices?</summary><br><b>\nHere are three of them:\n\n    1. Label carefully: Careful and consistent labeling of metrics is crucial for effective querying and alerting. Labels should be clear, concise, and include all relevant information about the metric.\n\n    2. Keep metrics simple: The metrics exposed by exporters should be simple and focus on a single aspect of the system being monitored. This helps avoid confusion and ensures that the metrics are easily understandable by all members of the team.\n\n    3. Use alerting sparingly: While alerting is a powerful feature of Prometheus, it should be used sparingly and only for the most critical issues. Setting up too many alerts can lead to alert fatigue and result in important alerts being ignored. It is recommended to set up only the most important alerts and adjust the thresholds over time based on the actual frequency of alerts.\n</b></details>\n\n<details>\n<summary>How to get total requests in a given period of time?</summary><br><b>\nTo get the total requests in a given period of time using Prometheus, you can use the *sum* function along with the *rate* function. Here is an example query that will give you the total number of requests in the last hour:\n\n```\nsum(rate(http_requests_total[1h]))\n```\nIn this query, *http_requests_total* is the name of the metric that tracks the total number of HTTP requests, and the *rate* function calculates the per-second rate of requests over the last hour. The *sum* function then adds up all of the requests to give you the total number of requests in the last hour.\n\nYou can adjust the time range by changing the duration in the *rate* function. For example, if you wanted to get the total number of requests in the last day, you could change the function to *rate(http_requests_total[1d])*.\n</b></details>\n\n<details>\n<summary>What HA in Prometheus means?</summary><br><b>\n\nHA stands for High Availability. This means that the system is designed to be highly reliable and always available, even in the face of failures or other issues. In practice, this typically involves setting up multiple instances of Prometheus and ensuring that they are all synchronized and able to work together seamlessly. This can be achieved through a variety of techniques, such as load balancing, replication, and failover mechanisms. By implementing HA in Prometheus, users can ensure that their monitoring data is always available and up-to-date, even in the face of hardware or software failures, network issues, or other problems that might otherwise cause downtime or data loss.\n</b></details>\n\n<details>\n<summary>How do you join two metrics?</summary><br><b>\nIn Prometheus, joining two metrics can be achieved using the *join()* function. The *join()* function combines two or more time series based on their label values. It takes two mandatory arguments: *on* and *table*. The on argument specifies the labels to join *on* and the *table* argument specifies the time series to join.\n\nHere's an example of how to join two metrics using the *join()* function:\n\n```\nsum_series(\n  join(\n    on(service, instance) request_count_total,\n    on(service, instance) error_count_total,\n  )\n)\n```\nIn this example, the *join()* function combines the *request_count_total* and *error_count_total* time series based on their *service* and *instance* label values. The *sum_series()* function then calculates the sum of the resulting time series\n</b></details>\n\n<details>\n<summary>How to write a query that returns the value of a label?</summary><br><b>\nTo write a query that returns the value of a label in Prometheus, you can use the *label_values* function. The *label_values* function takes two arguments: the name of the label and the name of the metric.\n\nFor example, if you have a metric called *http_requests_total* with a label called *method*, and you want to return all the values of the *method* label, you can use the following query:\n\n```\nlabel_values(http_requests_total, method)\n```\n\nThis will return a list of all the values for the *method* label in the *http_requests_total* metric. You can then use this list in further queries or to filter your data.\n</b></details>\n\n<details>\n<summary>How do you convert cpu_user_seconds to cpu usage in percentage?</summary><br><b>\nTo convert *cpu_user_seconds* to CPU usage in percentage, you need to divide it by the total elapsed time and the number of CPU cores, and then multiply by 100. The formula is as follows:\n\n```\n100 * sum(rate(process_cpu_user_seconds_total{job=\"<job-name>\"}[<time-period>])) by (instance) / (<time-period> * <num-cpu-cores>)\n```\n\nHere, *<job-name>* is the name of the job you want to query, *<time-period>* is the time range you want to query (e.g. *5m*, *1h*), and *<num-cpu-cores>* is the number of CPU cores on the machine you are querying.\n\nFor example, to get the CPU usage in percentage for the last 5 minutes for a job named *my-job* running on a machine with 4 CPU cores, you can use the following query:\n\n```\n100 * sum(rate(process_cpu_user_seconds_total{job=\"my-job\"}[5m])) by (instance) / (5m * 4)\n```\n</b></details>\n\n## Go\n\n<details>\n<summary>What are some characteristics of the Go programming language?</summary><br><b>\n\n  * Strong and static typing - the type of the variables can't be changed over time and they have to be defined at compile time\n  * Simplicity\n  * Fast compile times\n  * Built-in concurrency\n  * Garbage collected\n  * Platform independent\n  * Compile to standalone binary - anything you need to run your app will be compiled into one binary. Very useful for version management in run-time.\n\nGo also has good community.\n</b></details>\n\n<details>\n<summary>What is the difference between <code>var x int = 2</code> and <code>x := 2</code>?</summary><br><b>\n\nThe result is the same, a variable with the value 2.\n\nWith <code>var x int = 2</code> we are setting the variable type to integer while with <code>x := 2</code> we are letting Go figure out by itself the type.\n</b></details>\n\n<details>\n<summary>True or False? In Go we can redeclare variables and once declared we must use it.</summary>\n\nFalse. We can't redeclare variables but yes, we must used declared variables.\n</b></details>\n\n<details>\n<summary>What libraries of Go have you used?</summary><br><b>\n\nThis should be answered based on your usage but some examples are:\n\n  * fmt - formatted I/O\n</b></details>\n\n<details>\n<summary>What is the problem with the following block of code? How to fix it?\n\n```\nfunc main() {\n    var x float32 = 13.5\n    var y int\n    y = x\n}\n```\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>The following block of code tries to convert the integer 101 to a string but instead we get \"e\". Why is that? How to fix it?\n\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    var x int = 101\n    var y string\n    y = string(x)\n    fmt.Println(y)\n}\n```\n</summary><br><b>\n\nIt looks what unicode value is set at 101 and uses it for converting the integer to a string.\nIf you want to get \"101\" you should use the package \"strconv\" and replace <code>y = string(x)</code> with <code>y = strconv.Itoa(x)</code>\n</b></details>\n\n<details>\n<summary>What is wrong with the following code?:\n\n```\npackage main\n\nfunc main() {\n    var x = 2\n    var y = 3\n    const someConst = x + y\n}\n```\n</summary><br><b>\n\nConstants in Go can only be declared using constant expressions.\nBut `x`, `y` and their sum is variable.\n<br>\n<code>const initializer x + y is not a constant</code>\n</b></details>\n\n<details>\n<summary>What will be the output of the following block of code?:\n\n```go\npackage main\n\nimport \"fmt\"\n\nconst (\n\tx = iota\n\ty = iota\n)\nconst z = iota\n\nfunc main() {\n\tfmt.Printf(\"%v\\n\", x)\n\tfmt.Printf(\"%v\\n\", y)\n\tfmt.Printf(\"%v\\n\", z)\n}\n```\n</summary><br><b>\n\nGo's iota identifier is used in const declarations to simplify definitions of incrementing numbers. Because it can be used in expressions, it provides a generality beyond that of simple enumerations.\n<br>\n`x` and `y` in the first iota group, `z` in the second.\n<br>\n[Iota page in Go Wiki](https://github.com/golang/go/wiki/Iota)\n</b></details>\n\n<details>\n<summary>What _ is used for in Go?</summary><br><b>\n\nIt avoids having to declare all the variables for the returns values.\nIt is called the [blank identifier](https://golang.org/doc/effective_go.html#blank).\n<br>\n[answer in SO](https://stackoverflow.com/questions/27764421/what-is-underscore-comma-in-a-go-declaration#answer-27764432)\n</b></details>\n\n<details>\n<summary>What will be the output of the following block of code?:\n\n```go\npackage main\n\nimport \"fmt\"\n\nconst (\n\t_ = iota + 3\n\tx\n)\n\nfunc main() {\n\tfmt.Printf(\"%v\\n\", x)\n}\n```\n</summary><br><b>\n\nSince the first iota is declared with the value `3` (` + 3`), the next one has the value `4`\n</b></details>\n\n<details>\n<summary>What will be the output of the following block of code?:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\n\twg.Add(1)\n\tgo func() {\n\t\ttime.Sleep(time.Second * 2)\n\t\tfmt.Println(\"1\")\n\t\twg.Done()\n\t}()\n\n\tgo func() {\n\t\tfmt.Println(\"2\")\n\t}()\n\n\twg.Wait()\n\tfmt.Println(\"3\")\n}\n```\n</summary><br><b>\n\nOutput: 2 1 3\n\n[Aritcle about sync/waitgroup](https://tutorialedge.net/golang/go-waitgroup-tutorial/)\n\n[Golang package sync](https://golang.org/pkg/sync/)\n</b></details>\n\n<details>\n<summary>What will be the output of the following block of code?:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc mod1(a []int) {\n\tfor i := range a {\n\t\ta[i] = 5\n\t}\n\n\tfmt.Println(\"1:\", a)\n}\n\nfunc mod2(a []int) {\n\ta = append(a, 125) // !\n\n\tfor i := range a {\n\t\ta[i] = 5\n\t}\n\n\tfmt.Println(\"2:\", a)\n}\n\nfunc main() {\n\ts1 := []int{1, 2, 3, 4}\n\tmod1(s1)\n\tfmt.Println(\"1:\", s1)\n\n\ts2 := []int{1, 2, 3, 4}\n\tmod2(s2)\n\tfmt.Println(\"2:\", s2)\n}\n```\n</summary><br><b>\n\nOutput: <code><br>\n1 [5 5 5 5]<br>\n1 [5 5 5 5]<br>\n2 [5 5 5 5 5]<br>\n2 [1 2 3 4]<br>\n</code>\n\nIn `mod1` a is link, and when we're using `a[i]`, we're changing `s1` value to.\nBut in `mod2`, `append` creates new slice, and we're changing only `a` value, not `s2`.\n\n[Aritcle about arrays](https://golangbot.com/arrays-and-slices/),\n[Blog post about `append`](https://blog.golang.org/slices)\n</b></details>\n\n<details>\n<summary>What will be the output of the following block of code?:\n\n```go\npackage main\n\nimport (\n\t\"container/heap\"\n\t\"fmt\"\n)\n\n// An IntHeap is a min-heap of ints.\ntype IntHeap []int\n\nfunc (h IntHeap) Len() int           { return len(h) }\nfunc (h IntHeap) Less(i, j int) bool { return h[i] < h[j] }\nfunc (h IntHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\n\nfunc (h *IntHeap) Push(x interface{}) {\n\t// Push and Pop use pointer receivers because they modify the slice's length,\n\t// not just its contents.\n\t*h = append(*h, x.(int))\n}\n\nfunc (h *IntHeap) Pop() interface{} {\n\told := *h\n\tn := len(old)\n\tx := old[n-1]\n\t*h = old[0 : n-1]\n\treturn x\n}\n\nfunc main() {\n\th := &IntHeap{4, 8, 3, 6}\n\theap.Init(h)\n\theap.Push(h, 7)\n\n  fmt.Println((*h)[0])\n}\n```\n</summary><br><b>\n\nOutput: 3\n\n[Golang container/heap package](https://golang.org/pkg/container/heap/)\n</b></details>\n\n## Mongo\n\n<details>\n<summary>What are the advantages of MongoDB? Or in other words, why choosing MongoDB and not other implementation of NoSQL?</summary><br><b>\n\nMongoDB advantages are as following:\n- Schemaless\n- Easy to scale-out\n- No complex joins\n- Structure of a single object is clear\n\n</b></details>\n\n<details>\n<summary>What is the difference between SQL and NoSQL?</summary><br><b>\n\nThe main difference is that SQL databases are structured (data is stored in the form of\ntables with rows and columns - like an excel spreadsheet table) while NoSQL is\nunstructured, and the data storage can vary depending on how the NoSQL DB is set up, such\nas key-value pair, document-oriented, etc.\n</b></details>\n\n<details>\n<summary>In what scenarios would you prefer to use NoSQL/Mongo over SQL?</summary><br><b>\n\n  * Heterogeneous data which changes often\n  * Data consistency and integrity is not top priority\n  * Best if the database needs to scale rapidly\n</b></details>\n\n<details>\n<summary>What is a document? What is a collection?</summary><br><b>\n\n  * A document is a record in MongoDB, which is stored in BSON (Binary JSON) format and is the basic unit of data in MongoDB.\n  * A collection is a group of related documents stored in a single database in MongoDB.\n</b></details>\n\n<details>\n<summary>What is an aggregator?</summary><br><b>\n\n  * An aggregator is a framework in MongoDB that performs operations on a set of data to return a single computed result.\n</b></details>\n\n<details>\n<summary>What is better? Embedded documents or referenced?</summary><br><b>\n\n  * There is no definitive answer to which is better, it depends on the specific use case and requirements. Some explanations : Embedded documents provide atomic updates, while referenced documents allow for better normalization.\n</b></details>\n\n<details>\n<summary>Have you performed data retrieval optimizations in Mongo? If not, can you think about ways to optimize a slow data retrieval?</summary><br><b>\n\n  * Some ways to optimize data retrieval in MongoDB are: indexing, proper schema design, query optimization and database load balancing.\n</b></details>\n\n##### Queries\n\n<details>\n<summary>Explain this query: <code>db.books.find({\"name\": /abc/})</code></summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain this query: <code>db.books.find().sort({x:1})</code></summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the difference between find() and find_one()?</code></summary><br><b>\n\t\n  * `find()` returns all documents that match the query conditions.\n  * find_one() returns only one document that matches the query conditions (or null if no match is found).\n</b></details>\n\n<details>\n<summary>How can you export data from Mongo DB?</code></summary><br><b>\n\n* mongoexport\n* programming languages\n</b></details>\n\n## SQL\n\n### SQL Exercises\n\n|Name|Topic|Objective & Instructions|Solution|Comments|\n|--------|--------|------|----|----|\n| Functions vs. Comparisons | Query Improvements | [Exercise](topics/sql/improve_query.md) | [Solution](topics/sql/solutions/improve_query.md)\n\n### SQL Self Assessment\n\n<details>\n<summary>What is SQL?</summary><br><b>\n\nSQL (Structured Query Language) is a standard language for relational databases (like MySQL, MariaDB, ...).<br>\nIt's used for reading, updating, removing and creating data in a relational database.\n</b></details>\n\n<details>\n<summary>How is SQL Different from NoSQL</summary><br><b>\n\nThe main difference is that SQL databases are structured (data is stored in the form of\ntables with rows and columns - like an excel spreadsheet table) while NoSQL is\nunstructured, and the data storage can vary depending on how the NoSQL DB is set up, such\nas key-value pair, document-oriented, etc.\n</b></details>\n\n<details>\n<summary>When is it best to use SQL? NoSQL?</summary><br><b>\n\nSQL - Best used when data integrity is crucial. SQL is typically implemented with many\nbusinesses and areas within the finance field due to it's ACID compliance.\n\nNoSQL - Great if you need to scale things quickly. NoSQL was designed with web applications\nin mind, so it works great if you need to quickly spread the same information around to\nmultiple servers\n\nAdditionally, since NoSQL does not adhere to the strict table with columns and rows structure\nthat Relational Databases require, you can store different data types together.\n</b></details>\n\n##### Practical SQL - Basics\n\nFor these questions, we will be using the Customers and Orders tables shown below:\n\n**Customers**\n\nCustomer_ID | Customer_Name | Items_in_cart | Cash_spent_to_Date\n------------ | ------------- | ------------- | -------------\n100204 | John Smith | 0 | 20.00\n100205 | Jane Smith | 3 | 40.00\n100206 | Bobby Frank | 1 | 100.20\n\n**ORDERS**\n\nCustomer_ID | Order_ID | Item | Price | Date_sold\n------------ | ------------- | ------------- | ------------- | -------------\n100206 | A123 | Rubber Ducky | 2.20 | 2019-09-18\n100206 | A123 | Bubble Bath | 8.00 | 2019-09-18\n100206 | Q987 | 80-Pack TP | 90.00 | 2019-09-20\n100205 | Z001 | Cat Food - Tuna Fish | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Chicken | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Beef | 10.00 | 2019-08-05\n100205 | Z001 | Cat Food - Kitty quesadilla | 10.00 | 2019-08-05\n100204 | X202 | Coffee | 20.00 | 2019-04-29\n\n<details>\n<summary>How would I select all fields from this table?</summary><br><b>\n\nSelect * <br>\nFrom Customers;\n</b></details>\n\n<details>\n<summary>How many items are in John's cart?</summary><br><b>\n\nSelect Items_in_cart <br>\nFrom Customers <br>\nWhere Customer_Name = \"John Smith\";\n</b></details>\n\n<details>\n<summary>What is the sum of all the cash spent across all customers?</summary><br><b>\n\nSelect SUM(Cash_spent_to_Date) as SUM_CASH <br>\nFrom Customers;\n</b></details>\n\n<details>\n<summary>How many people have items in their cart?</summary><br><b>\n\nSelect count(1) as Number_of_People_w_items <br>\nFrom Customers <br>\nwhere Items_in_cart > 0;\n</b></details>\n\n<details>\n<summary>How would you join the customer table to the order table?</summary><br><b>\n\nYou would join them on the unique key. In this case, the unique key is Customer_ID in\nboth the Customers table and Orders table\n</b></details>\n\n<details>\n<summary>How would you show which customer ordered which items?</summary><br><b>\n\nSelect c.Customer_Name, o.Item <br>\nFrom Customers c <br>\nLeft Join Orders o <br>\n  On c.Customer_ID = o.Customer_ID;\n\n</b></details>\n\n<details>\n<summary>Using a with statement, how would you show who ordered cat food, and the total amount of money spent?</summary><br><b>\n\nwith cat_food as ( <br>\nSelect Customer_ID, SUM(Price) as TOTAL_PRICE <br>\nFrom Orders <br>\nWhere Item like \"%Cat Food%\" <br>\nGroup by Customer_ID <br>\n) <br>\nSelect Customer_name, TOTAL_PRICE <br>\nFrom Customers c <br>\nInner JOIN cat_food f <br>\n  ON c.Customer_ID = f.Customer_ID <br>\nwhere c.Customer_ID in (Select Customer_ID from cat_food);\n\nAlthough this was a simple statement, the \"with\" clause really shines when\na complex query needs to be run on a table before joining to another. With statements are nice,\nbecause you create a pseudo temp when running your query, instead of creating a whole new table.\n\nThe Sum of all the purchases of cat food weren't readily available, so we used a with statement to create\nthe pseudo table to retrieve the sum of the prices spent by each customer, then join the table normally.\n</b></details>\n\n<details>\n<summary>Which of the following queries would you use?\n\n```\nSELECT count(*)                             SELECT count(*)\nFROM shawarma_purchases                     FROM shawarma_purchases\nWHERE                               vs.     WHERE\n  YEAR(purchased_at) == '2017'              purchased_at >= '2017-01-01' AND\n                                            purchased_at <= '2017-31-12'\n```\n</summary><br><b>\n\n```\nSELECT count(*)\nFROM shawarma_purchases\nWHERE\n  purchased_at >= '2017-01-01' AND\n  purchased_at <= '2017-31-12'\n```\n\nWhen you use a function (`YEAR(purchased_at)`) it has to scan the whole database as opposed to using indexes and basically the column as it is, in its natural state.\n</b></details>\n\n## OpenStack\n\n<details>\n<summary>What components/projects of OpenStack are you familiar with?</summary><br><b>\nI’m most familiar with several core OpenStack components:\n\n- Nova for compute resource provisioning, including VM lifecycle management.\n- Neutron for networking, focusing on creating and managing networks, subnets, and routers.\n- Cinder for block storage, used to attach and manage storage volumes.\n- Keystone for identity services, handling authentication and authorization.\n\nI’ve implemented these in past projects, configuring them for scalability and security to support multi-tenant environments.\n \n</b></details>\n\n<details>\n<summary>Can you tell me what each of the following services/projects is responsible for?:\n\n  - Nova\n  - Neutron\n  - Cinder\n  - Glance\n  - Keystone</summary><br><b>\n\n  * Nova - Manage virtual instances\n  * Neutron - Manage networking by providing Network as a service (NaaS)\n  * Cinder - Block Storage\n  * Glance - Manage images for virtual machines and containers (search, get and register)\n  * Keystone - Authentication service across the cloud\n</b></details>\n\n<details>\n<summary>Identify the service/project used for each of the following:\n\n  * Copy or snapshot instances\n  * GUI for viewing and modifying resources\n  * Block Storage\n  * Manage virtual instances\n</summary><br><b>\n\n  * Glance - Images Service. Also used for copying or snapshot instances\n  * Horizon - GUI for viewing and modifying resources\n  * Cinder - Block Storage\n  * Nova - Manage virtual instances\n</b></details>\n\n<details>\n<summary>What is a tenant/project?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Determine true or false:\n\n  * OpenStack is free to use\n  * The service responsible for networking is Glance\n  * The purpose of tenant/project is to share resources between different projects and users of OpenStack</summary><br><b>\n</b></details>\n\n<details>\n<summary>Describe in detail how you bring up an instance with a floating IP</summary><br><b>\n</b></details>\n\n<details>\n<summary>You get a call from a customer saying: \"I can ping my instance but can't connect (ssh) it\". What might be the problem?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What types of networks OpenStack supports?</summary><br><b>\n</b></details>\n\n<details>\n<summary>How do you debug OpenStack storage issues? (tools, logs, ...)</summary><br><b>\n</b></details>\n\n<details>\n<summary>How do you debug OpenStack compute issues? (tools, logs, ...)</summary><br><b>\n</b></details>\n\n#### OpenStack Deployment & TripleO\n\n<details>\n<summary>Have you deployed OpenStack in the past? If yes, can you describe how you did it?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Are you familiar with TripleO? How is it different from Devstack or Packstack?</summary><br><b>\n\nYou can read about TripleO right [here](https://docs.openstack.org/tripleo-docs/latest)\n</b></details>\n\n#### OpenStack Compute\n\n<details>\n<summary>Can you describe Nova in detail?</summary><br><b>\n\n  * Used to provision and manage virtual instances\n  * It supports Multi-Tenancy in different levels - logging, end-user control, auditing, etc.\n  * Highly scalable\n  * Authentication can be done using internal system or LDAP\n  * Supports multiple types of block storage\n  * Tries to be hardware and hypervisor agnostice\n</b></details>\n\n<details>\n<summary>What do you know about Nova architecture and components?</summary><br><b>\n\n  * nova-api - the server which serves metadata and compute APIs\n  * the different Nova components communicate by using a queue (Rabbitmq usually) and a database\n  * a request for creating an instance is inspected by nova-scheduler which determines where the instance will be created and running\n  * nova-compute is the component responsible for communicating with the hypervisor for creating the instance and manage its lifecycle\n</b></details>\n\n#### OpenStack Networking (Neutron)\n\n<details>\n<summary>Explain Neutron in detail</summary><br><b>\n\n  * One of the core component of OpenStack and a standalone project\n  * Neutron focused on delivering networking as a service\n  * With Neutron, users can set up networks in the cloud and configure and manage a variety of network services\n  * Neutron interacts with:\n      * Keystone - authorize API calls\n      * Nova - nova communicates with neutron to plug NICs into a network\n      * Horizon - supports networking entities in the dashboard and also provides topology view which includes networking details\n</b></details>\n\n<details>\n<summary>Explain each of the following components:\n\n  - neutron-dhcp-agent\n  - neutron-l3-agent\n  - neutron-metering-agent\n  - neutron-*-agtent\n  - neutron-server</summary><br><b>\n\n\n  * neutron-l3-agent - L3/NAT forwarding (provides external network access for VMs for example)\n  * neutron-dhcp-agent - DHCP services\n  * neutron-metering-agent - L3 traffic metering\n  * neutron-*-agtent - manages local vSwitch configuration on each compute (based on chosen plugin)\n  * neutron-server - exposes networking API and passes requests to other plugins if required\n</b></details>\n\n<details>\n<summary>Explain these network types:\n\n  - Management Network\n  - Guest Network\n  - API Network\n  - External Network</summary><br><b>\n\n  * Management Network - used for internal communication between OpenStack components. Any IP address in this network is accessible only within the datacetner\n  * Guest Network - used for communication between instances/VMs\n  * API Network - used for services API communication. Any IP address in this network is publicly accessible\n  * External Network - used for public communication. Any IP address in this network is accessible by anyone on the internet\n</b></details>\n\n<details>\n<summary>In which order should you remove the following entities:\n\n  * Network\n  * Port\n  * Router\n  * Subnet</summary><br><b>\n\n  - Port\n  - Subnet\n  - Router\n  - Network\n\nThere are many reasons for that. One for example: you can't remove router if there are active ports assigned to it.\n</b></details>\n\n<details>\n<summary>What is a provider network?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What components and services exist for L2 and L3?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the ML2 plug-in? Explain its architecture</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the L2 agent? How does it works and what is it responsible for?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the L3 agent? How does it works and what is it responsible for?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain what the Metadata agent is responsible for</summary><br><b>\n</b></details>\n\n<details>\n<summary>What networking entities Neutron supports?</summary><br><b>\n</b></details>\n\n<details>\n<summary>How do you debug OpenStack networking issues? (tools, logs, ...)</summary><br><b>\n</b></details>\n\n#### OpenStack - Glance\n\n<details>\n<summary>Explain Glance in detail</summary><br><b>\n\n  * Glance is the OpenStack image service\n  * It handles requests related to instances disks and images\n  * Glance also used for creating snapshots for quick instances backups\n  * Users can use Glance to create new images or upload existing ones\n</b></details>\n\n<details>\n<summary>Describe Glance architecture</summary><br><b>\n\n  * glance-api - responsible for handling image API calls such as retrieval and storage. It consists of two APIs: 1. registry-api - responsible for internal requests 2. user API - can be accessed publicly\n  * glance-registry - responsible for handling image metadata requests (e.g. size, type, etc). This component is private which means it's not available publicly\n  * metadata definition service - API for custom metadata\n  * database - for storing images metadata\n  * image repository - for storing images. This can be a filesystem, swift object storage, HTTP, etc.\n</b></details>\n\n#### OpenStack - Swift\n\n<details>\n<summary>Explain Swift in detail</summary><br><b>\n\n  * Swift is Object Store service and is an highly available, distributed and consistent store designed for storing a lot of data\n  * Swift is distributing data across multiple servers while writing it to multiple disks\n  * One can choose to add additional servers to scale the cluster. All while swift maintaining integrity of the information and data replications.\n</b></details>\n\n<details>\n<summary>Can users store by default an object of 100GB in size?</summary><br><b>\n\nNot by default. Object Storage API limits the maximum to 5GB per object but it can be adjusted.\n</b></details>\n\n<details>\n<summary>Explain the following in regards to Swift:\n\n  * Container\n  * Account\n  * Object\n</summary><br><b>\n\n  - Container - Defines a namespace for objects.\n  - Account - Defines a namespace for containers\n  - Object - Data content (e.g. image, document, ...)\n</b></details>\n\n<details>\n<summary>True or False? there can be two objects with the same name in the same container but not in two different containers</summary><br><b>\n\nFalse. Two objects can have the same name if they are in different containers.\n</b></details>\n\n#### OpenStack - Cinder\n\n<details>\n<summary>Explain Cinder in detail</summary><br><b>\n\n  * Cinder is OpenStack Block Storage service\n  * It basically provides used with storage resources they can consume with other services such as Nova\n  * One of the most used implementations of storage supported by Cinder is LVM\n  * From user perspective this is transparent which means the user doesn't know where, behind the scenes, the storage is located or what type of storage is used\n</b></details>\n\n<details>\n<summary>Describe Cinder's components</summary><br><b>\n\n  * cinder-api - receives API requests\n  * cinder-volume - manages attached block devices\n  * cinder-scheduler - responsible for storing volumes\n</b></details>\n\n#### OpenStack - Keystone\n\n<details>\n<summary>Can you describe the following concepts in regards to Keystone?\n\n  - Role\n  - Tenant/Project\n  - Service\n  - Endpoint\n  - Token\n</summary><br><b>\n\n  - Role - A list of rights and privileges determining what a user or a project can perform\n  - Tenant/Project - Logical representation of a group of resources isolated from other groups of resources. It can be an account, organization, ...\n  - Service - An endpoint which the user can use for accessing different resources\n  - Endpoint - a network address which can be used to access a certain OpenStack service\n  - Token - Used for access resources while describing which resources can be accessed by using a scope\n</b></details>\n\n<details>\n<summary>What are the properties of a service? In other words, how a service is identified?</summary><br><b>\n\nUsing:\n  - Name\n  - ID number\n  - Type\n  - Description\n</b></details>\n\n<details>\n<summary>Explain the following:\n  - PublicURL\n  - InternalURL\n  - AdminURL</summary><br><b>\n\n  - PublicURL - Publicly accessible through public internet\n  - InternalURL - Used for communication between services\n  - AdminURL - Used for administrative management\n</b></details>\n\n<details>\n<summary>What is a service catalog?</summary><br><b>\n\nA list of services and their endpoints\n</b></details>\n\n#### OpenStack Advanced - Services\n\n<details>\n<summary>Describe each of the following services\n\n  * Swift\n  * Sahara\n  * Ironic\n  * Trove\n  * Aodh\n  * Ceilometer\n</summary><br><b>\n\n  * Swift - highly available, distributed, eventually consistent object/blob store\n  * Sahara - Manage Hadoop Clusters\n  * Ironic - Bare Metal Provisioning\n  * Trove - Database as a service that runs on OpenStack\n  * Aodh - Alarms Service\n  * Ceilometer - Track and monitor usage\n</b></details>\n\n<details>\n<summary>Identify the service/project used for each of the following:\n\n  * Database as a service which runs on OpenStack\n  * Bare Metal Provisioning\n  * Track and monitor usage\n  * Alarms Service\n  * Manage Hadoop Clusters\n  * highly available, distributed, eventually consistent object/blob store\n</summary><br><b>\n\n  * Database as a service which runs on OpenStack - Trove\n  * Bare Metal Provisioning - Ironic\n  * Track and monitor usage - Ceilometer\n  * Alarms Service - Aodh\n  * Manage Hadoop Clusters\n  * Manage Hadoop Clusters - Sahara\n  * highly available, distributed, eventually consistent object/blob store - Swift\n</b></details>\n\n#### OpenStack Advanced - Keystone\n\n<details>\n<summary>Can you describe Keystone service in detail?</summary><br><b>\n\n  * You can't have OpenStack deployed without Keystone\n  * It Provides identity, policy and token services\n    * The authentication provided is for both users and services\n    * The authorization supported is token-based and user-based.\n  * There is a policy defined based on RBAC stored in a JSON file and each line in that file defines the level of access to apply\n</b></details>\n\n<details>\n<summary>Describe Keystone architecture</summary><br><b>\n\n  * There is a service API and admin API through which Keystone gets requests\n  * Keystone has four backends:\n    * Token Backend - Temporary Tokens for users and services\n    * Policy Backend - Rules management and authorization\n    * Identity Backend - users and groups (either standalone DB, LDAP, ...)\n    * Catalog Backend - Endpoints\n  * It has pluggable environment where you can integrate with:\n    * LDAP\n    * KVS (Key Value Store)\n    * SQL\n    * PAM\n    * Memcached\n</b></details>\n\n<details>\n<summary>Describe the Keystone authentication process</summary><br><b>\n\n  * Keystone gets a call/request and checks whether it's from an authorized user, using username, password and authURL\n  * Once confirmed, Keystone provides a token.\n  * A token contains a list of user's projects so there is no to authenticate every time and a token can submitted instead\n</b></details>\n\n#### OpenStack Advanced - Compute (Nova)\n\n<details>\n<summary>What each of the following does?:\n\n  * nova-api\n  * nova-compuate\n  * nova-conductor\n  * nova-cert\n  * nova-consoleauth\n  * nova-scheduler\n</summary><br><b>\n\n  * nova-api - responsible for managing requests/calls\n  * nova-compute - responsible for managing instance lifecycle\n  * nova-conductor - Mediates between nova-compute and the database so nova-compute doesn't access it directly\n</b></details>\n\n<details>\n<summary>What types of Nova proxies are you familiar with?</summary><br><b>\n\n  * Nova-novncproxy - Access through VNC connections\n  * Nova-spicehtml5proxy - Access through SPICE\n  * Nova-xvpvncproxy - Access through a VNC connection\n</b></details>\n\n#### OpenStack Advanced - Networking (Neutron)\n\n<details>\n<summary>Explain BGP dynamic routing</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the role of network namespaces in OpenStack?</summary><br><b>\n</b></details>\n\n#### OpenStack Advanced - Horizon\n\n<details>\n<summary>Can you describe Horizon in detail?</summary><br><b>\n\n  * Django-based project focusing on providing an OpenStack dashboard and the ability to create additional customized dashboards\n  * You can use it to access the different OpenStack services resources - instances, images, networks, ...\n    * By accessing the dashboard, users can use it to list, create, remove and modify the different resources\n  * It's also highly customizable and you can modify or add to it based on your needs\n</b></details>\n\n<details>\n<summary>What can you tell about Horizon architecture?</summary><br><b>\n\n  * API is backward compatible\n  * There are three type of dashboards: user, system and settings\n  * It provides core support for all OpenStack core projects such as Neutron, Nova, etc. (out of the box, no need to install extra packages or plugins)\n  * Anyone can extend the dashboards and add new components\n  * Horizon provides templates and core classes from which one can build its own dashboard\n</b></details>\n\n## Puppet\n\n<details>\n<summary>What is Puppet? How does it works?</summary><br><b> \n\n  * Puppet is a configuration management tool ensuring that all systems are configured to a desired and predictable state.\n</b></details>\n<details>\n<summary>Explain Puppet architecture</summary><br><b>\n\n  * Puppet has a primary-secondary node architecture. The clients are distributed across the network and communicate with the primary-secondary environment where Puppet modules are present. The client agent sends a certificate with its ID to the server; the server then signs that certificate and sends it back to the client. This authentication allows for secure and verifiable communication between the client and the master. \n</b></details>\n\n<details>\n<summary>Can you compare Puppet to other configuration management tools? Why did you chose to use Puppet?</summary><br><b>\n\n  * Puppet is often compared to other configuration management tools like Chef, Ansible, SaltStack, and cfengine. The choice to use Puppet often depends on an organization's needs, such as ease of use, scalability, and community support.\n</b></details>\n\n<details>\n<summary>Explain the following:\n\n  * Module\n  * Manifest\n  * Node\n</summary><br><b>\n  \n  * Modules - are a collection of manifests, templates, and files\n  * Manifests - are the actual codes for configuring the clients\n  * Node - allows you to assign specific configurations to specific nodes\n</b></details>\n\n<details>\n<summary>Explain Facter</summary><br><b>\n\n  * Facter is a standalone tool in Puppet that collects information about a system and its configuration, such as the operating system, IP addresses, memory, and network interfaces. This information can be used in Puppet manifests to make decisions about how resources should be managed, and to customize the behavior of Puppet based on the characteristics of the system. Facter is integrated into Puppet, and its facts can be used within Puppet manifests to make decisions about resource management.\n</b></details>\n\n<details>\n<summary>What is MCollective?</summary><br><b>\n\n  * MCollective is a middleware system that integrates with Puppet to provide orchestration, remote execution, and parallel job execution capabilities.\n</b></details>\n\n<details>\n<summary>Do you have experience with writing modules? Which module have you created and for what?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain what is Hiera</summary><br><b>\n\n  * Hiera is a hierarchical data store in Puppet that is used to separate data from code, allowing data to be more easily separated, managed, and reused.\n</b></details>\n\n## Elastic\n\n<details>\n<summary>What is the Elastic Stack?</summary><br><b>\n\nThe Elastic Stack consists of:\n\n  * Elasticsearch\n  * Kibana\n  * Logstash\n  * Beats\n  * Elastic Hadoop\n  * APM Server\n\nElasticsearch, Logstash and Kibana are also known as the ELK stack.\n</b></details>\n\n<details>\n<summary>Explain what is Elasticsearch</summary><br><b>\n\nFrom the official [docs](https://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html):\n\n\"Elasticsearch is a distributed document store. Instead of storing information as rows of columnar data, Elasticsearch stores complex data structures that have been serialized as JSON documents\"\n</b></details>\n\n<details>\n<summary>What is Logstash?</summary><br><b>\n\t\nFrom the [blog](https://logit.io/blog/post/the-top-50-elk-stack-and-elasticsearch-interview-questions):\n\n\"Logstash is a powerful, flexible pipeline that collects, enriches and transports data. It works as an extract, transform & load (ETL) tool for collecting log messages.\"\n</b></details>\n\n<details>\n<summary>Explain what beats are</summary><br><b>\n\nBeats are lightweight data shippers. These data shippers installed on the client where the data resides.\nExamples of beats: Filebeat, Metricbeat, Auditbeat. There are much more.<br>\n</b></details>\n\n<details>\n<summary>What is Kibana?</summary><br><b>\n\nFrom the official docs:\n\n\"Kibana is an open source analytics and visualization platform designed to work with Elasticsearch. You use Kibana to search, view, and interact with data stored in Elasticsearch indices. You can easily perform advanced data analysis and visualize your data in a variety of charts, tables, and maps.\"\n</b></details>\n\n<details>\n<summary>Describe what happens from the moment an app logged some information until it's displayed to the user in a dashboard when the Elastic stack is used</summary><br><b>\n\nThe process may vary based on the chosen architecture and the processing you may want to apply to the logs. One possible workflow is:\n\n1. The data logged by the application is picked by filebeat and sent to logstash\n2. Logstash process the log based on the defined filters. Once done, the output is sent to Elasticsearch\n2. Elasticsearch stores the document it got and the document is indexed for quick future access\n4. The user creates visualizations in Kibana which based on the indexed data\n5. The user creates a dashboard which composed out of the visualization created in the previous step\n</b></details>\n\n##### Elasticsearch\n\n<details>\n<summary>What is a data node?</summary><br><b>\n\nThis is where data is stored and also where different processing takes place (e.g. when you search for a data).\n</b></details>\n\n<details>\n<summary>What is a master node?</summary><br><b>\n\nPart of a master node responsibilities:\n  * Track the status of all the nodes in the cluster\n  * Verify replicas are working and the data is available from every data node.\n  * No hot nodes (no data node that works much harder than other nodes)\n\nWhile there can be multiple master nodes in reality only of them is the elected master node.\n</b></details>\n\n<details>\n<summary>What is an ingest node?</summary><br><b>\n\nA node which responsible for processing the data according to ingest pipeline. In case you don't need to use \nlogstash then this node can receive data from beats and process it, similarly to how it can be processed \nin Logstash.\n</b></details>\n\n<details>\n<summary>What is Coordinating only node?</summary><br><b>\n\nFrom the official docs:\n\nCoordinating only nodes can benefit large clusters by offloading the coordinating node role from data and master-eligible nodes. They join the cluster and receive the full cluster state, like every other node, and they use the cluster state to route requests directly to the appropriate place(s).\n\n</b></details>\n\n<details>\n<summary>How data is stored in Elasticsearch?</summary><br><b>\n\n* Data is stored in an index\n* The index is spread across the cluster using shards\n</b></details>\n\n<details>\n<summary>What is an Index?</summary><br><b>\n\nIndex in Elasticsearch is in most cases compared to a whole database from the SQL/NoSQL world.<br>\nYou can choose to have one index to hold all the data of your app or have multiple indices where each index holds different type of your app (e.g. index for each service your app is running).\n\nThe official docs also offer a great explanation (in general, it's really good documentation, as every project should have):\n\n\"An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data\"\n</b></details>\n\n<details>\n<summary>Explain Shards</summary><br><b>\n\nAn index is split into shards and documents are hashed to a particular shard. Each shard may be on a different node in a cluster and each one of the shards is a self contained index.<br>\nThis allows Elasticsearch to scale to an entire cluster of servers.\n</b></details>\n\n<details>\n<summary>What is an Inverted Index?</summary><br><b>\n\nFrom the official docs:\n\n\"An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in.\"\n</b></details>\n\n<details>\n<summary>What is a Document?</summary><br><b>\n\nContinuing with the comparison to SQL/NoSQL a Document in Elasticsearch is a row in table in the case of SQL or a document in a collection in the case of NoSQL.\nAs in NoSQL a document is a JSON object which holds data on a unit in your app. What is this unit depends on the your app. If your app related to book then each document describes a book. If you are app is about shirts then each document is a shirt.\n</b></details>\n\n<details>\n<summary>You check the health of your elasticsearch cluster and it's red. What does it mean? What can cause the status to be yellow instead of green?</summary><br><b>\n\nRed means some data is unavailable in your cluster. Some shards of your indices are unassigned. \nThere are some other states for the cluster.\nYellow means that you have unassigned shards in the cluster. You can be in this state if you have single node and your indices have replicas.\nGreen means that all shards in the cluster are assigned to nodes and your cluster is healthy. \n</b></details>\n\n<details>\n<summary>True or False? Elasticsearch indexes all data in every field and each indexed field has the same data structure for unified and quick query ability</summary><br><b>\n\nFalse.\nFrom the official docs:\n\n\"Each indexed field has a dedicated, optimized data structure. For example, text fields are stored in inverted indices, and numeric and geo fields are stored in BKD trees.\"\n</b></details>\n\n<details>\n<summary>What reserved fields a document has?</summary><br><b>\n\n  * _index\n  * _id\n  * _type\n</b></details>\n\n<details>\n<summary>Explain Mapping</summary><br><b>\n</b></details>\n\n<details>\n<summary>What are the advantages of defining your own mapping? (or: when would you use your own mapping?)</summary><br><b>\n\n* You can optimize fields for partial matching\n* You can define custom formats of known fields (e.g. date)\n* You can perform language-specific analysis\n</b></details>\n\n<details>\n<summary>Explain Replicas</summary><br><b>\n\nIn a network/cloud environment where failures can be expected any time, it is very useful and highly recommended to have a failover mechanism in case a shard/node somehow goes offline or disappears for whatever reason.\nTo this end, Elasticsearch allows you to make one or more copies of your index’s shards into what are called replica shards, or replicas for short.\n</b></details>\n\n<details>\n<summary>Can you explain Term Frequency & Document Frequency?</summary><br><b>\n\nTerm Frequency is how often a term appears in a given document and Document Frequency is how often a term appears in all documents. They both are used for determining the relevance of a term by calculating Term Frequency / Document Frequency.\n</b></details>\n\n<details>\n<summary>You check \"Current Phase\" under \"Index lifecycle management\" and you see it's set to \"hot\". What does it mean?</summary><br><b>\n\n\"The index is actively being written to\".\nMore about the phases [here](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/ilm-policy-definition.html)\n</b></details>\n\n<details>\n<summary>What this command does? <code>curl -X PUT \"localhost:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d'{ \"name\": \"John Doe\" }'</code></summary><br><b>\n\nIt creates customer index if it doesn't exists and adds a new document with the field name which is set to \"John Dow\". Also, if it's the first document it will get the ID 1.\n</b></details>\n\n<details>\n<summary>What will happen if you run the previous command twice? What about running it 100 times?</code></summary><br><b>\n\n1. If name value was different then it would update \"name\" to the new value\n2. In any case, it bumps version field by one\n</b></details>\n\n<details>\n<summary>What is the Bulk API? What would you use it for?</code></summary><br><b>\n\nBulk API is used when you need to index multiple documents. For high number of documents it would be significantly faster to use rather than individual requests since there are less network roundtrips.\n</b></details>\n\n##### Query DSL\n\n<details>\n<summary>Explain Elasticsearch query syntax (Booleans, Fields, Ranges)</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain what is Relevance Score</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain Query Context and Filter Context</summary><br><b>\n\nFrom the official docs:\n\n\"In the query context, a query clause answers the question “How well does this document match this query clause?” Besides deciding whether or not the document matches, the query clause also calculates a relevance score in the _score meta-field.\"\n\n\"In a filter context, a query clause answers the question “Does this document match this query clause?” The answer is a simple Yes or No — no scores are calculated. Filter context is mostly used for filtering structured data\"\n</b></details>\n\n<details>\n<summary>Describe how would an architecture of production environment with large amounts of data would be different from a small-scale environment</summary><br><b>\n\nThere are several possible answers for this question. One of them is as follows:\n\nA small-scale architecture of elastic will consist of the elastic stack as it is. This means we will have beats, logstash, elastcsearch and kibana.<br>\nA production environment with large amounts of data can include some kind of buffering component (e.g. Reddis or RabbitMQ) and also security component such as Nginx.\n</b></details>\n\n##### Logstash\n\n<details>\n<summary>What are Logstash plugins? What plugins types are there?</summary><br><b>\n\n  * Input Plugins - how to collect data from different sources\n  * Filter Plugins - processing data\n  * Output Plugins - push data to different outputs/services/platforms\n</b></details>\n\n<details>\n<summary>What is grok?</summary><br><b>\n\nA logstash plugin which modifies information in one format and immerse it in another.\n</b></details>\n\n<details>\n<summary>How grok works?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What grok patterns are you familiar with?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is `_grokparsefailure?`</summary><br><b>\n</b></details>\n\n<details>\n<summary>How do you test or debug grok patterns?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What are Logstash Codecs? What codecs are there?</summary><br><b>\n</b></details>\n\n##### Kibana\n\n<details>\n<summary>What can you find under \"Discover\" in Kibana?</summary><br><b>\n\nThe raw data as it is stored in the index. You can search and filter it.\n</b></details>\n\n<details>\n<summary>You see in Kibana, after clicking on Discover, \"561 hits\". What does it mean?</summary><br><b>\n\nTotal number of documents matching the search results. If not query used then simply the total number of documents.\n</b></details>\n\n<details>\n<summary>What can you find under \"Visualize\"?</summary><br><b>\n\n\"Visualize\" is where you can create visual representations for your data (pie charts, graphs, ...)\n</b></details>\n\n<details>\n<summary>What visualization types are supported/included in Kibana?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What visualization type would you use for statistical outliers</summary><br><b>\n</b></details>\n\n<details>\n<summary>Describe in detail how do you create a dashboard in Kibana</summary><br><b>\n</b></details>\n\n#### Filebeat\n\n<details>\n<summary>What is Filebeat?</summary><br><b>\n\nFilebeat is used to monitor the logging directories inside of VMs or mounted as a sidecar if exporting logs from containers, and then forward these logs onward for further processing, usually to logstash.\n</b></details>\n\n<details>\n<summary>If one is using ELK, is it a must to also use filebeat? In what scenarios it's useful to use filebeat?</summary><br><b>\n\nFilebeat is a typical component of the ELK stack, since it was developed by Elastic to work with the other products (Logstash and Kibana). It's possible to send logs directly to logstash, though this often requires coding changes for the application. Particularly for legacy applications with little test coverage, it might be a better option to use filebeat, since you don't need to make any changes to the application code.\n</b></details>\n\n<details>\n<summary>What is a harvester?</summary><br><b>\n\nRead [here](https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html#harvester)\n</b></details>\n\n<details>\n<summary>True or False? a single harvester harvest multiple files, according to the limits set in filebeat.yml</summary><br><b>\n\nFalse. One harvester harvests one file.\n</b></details>\n\n<details>\n<summary>What are filebeat modules?</summary><br><b>\n\nThese are pre-configured modules for specific types of logging locations (eg, Traefik, Fargate, HAProxy) to make it easy to configure forwarding logs using filebeat. They have different configurations based on where you're collecting logs from.\n</b></details>\n\n#### Elastic Stack\n\n<details>\n<summary>How do you secure an Elastic Stack?</summary><br><b>\n\nYou can generate certificates with the provided elastic utils and change configuration to enable security using certificates model.\n</b></details>\n\n## Distributed\n\n<details>\n<summary>Explain Distributed Computing (or Distributed System)</summary><br><b>\n\nAccording to Martin Kleppmann:\n\n\"Many processes running on many machines...only message-passing via an unreliable network with variable delays, and the system may suffer from partial failures, unreliable clocks, and process pauses.\"\n\nAnother definition: \"Systems that are physically separated, but logically connected\"\n</b></details>\n\n<details>\n<summary>What can cause a system to fail?</summary><br><b>\n\n* Network\n* CPU\n* Memory\n* Disk\n</b></details>\n\n<details>\n<summary>Do you know what is \"CAP theorem\"? (aka as Brewer's theorem)</summary><br><b>\n\nAccording to the CAP theorem, it's not possible for a distributed data store to provide more than two of the following at the same time:\n\n* Availability: Every request receives a response (it doesn't has to be the most recent data)\n* Consistency: Every request receives a response with the latest/most recent data\n* Partition tolerance: Even if some the data is lost/dropped, the system keeps running\n</b></details>\n\n<details>\n<summary>What are the problems with the following design? How to improve it?<br>\n<img src=\"images/distributed/distributed_design_standby.png\" width=\"500x;\" height=\"350px;\"/>\n</summary><br><b>\n1. The transition can take time. In other words, noticeable downtime.\n2. Standby server is a waste of resources - if first application server is running then the standby does nothing\n</b></details>\n\n<details>\n<summary>What are the problems with the following design? How to improve it?<br>\n<img src=\"images/distributed/distributed_design_lb.png\" width=\"700x;\" height=\"350px;\"/>\n</summary><br><b>\nIssues:\nIf load balancer dies , we lose the ability to communicate with the application.\n\nWays to improve:\n* Add another load balancer\n* Use DNS A record for both load balancers\n* Use message queue\n</b></details>\n\n<details>\n<summary>What is \"Shared-Nothing\" architecture?</summary><br><b>\n\nIt's an architecture in which data is and retrieved from a single, non-shared, source usually exclusively connected to one node as opposed to architectures where the request can get to one of many nodes and the data will be retrieved from one shared location (storage, memory, ...).\n</b></details>\n\n<details>\n<summary>Explain the Sidecar Pattern (Or sidecar proxy)</summary><br><b>\n</b></details>\n\n## Misc\n\n|Name|Topic|Objective & Instructions|Solution|Comments|\n|--------|--------|------|----|----|\n| Highly Available \"Hello World\" | [Exercise](topics/devops/ha_hello_world.md) | [Solution](topics/devops/solutions/ha_hello_world.md)\n\n<details>\n<summary>What happens when you type in a URL in an address bar in a browser?</summary><br><b>\n\n1. The browser searches for the record of the domain name IP address in the DNS in the following order:\n  * Browser cache\n  * Operating system cache\n  * The DNS server configured on the user's system (can be ISP DNS, public DNS, ...)\n2. If it couldn't find a DNS record locally, a full DNS resolution is started.\n3. It connects to the server using the TCP protocol\n4. The browser sends an HTTP request to the server\n5. The server sends an HTTP response back to the browser\n6. The browser renders the response (e.g. HTML)\n7. The browser then sends subsequent requests as needed to the server to get the embedded links, javascript, images in the HTML and then steps 3 to 5 are repeated.\n\nTODO: add more details!\n</b></details>\n\n#### API\n\n<details>\n<summary>Explain what is an API</summary><br><b>\n\nI like this definition from [blog.christianposta.com](https://blog.christianposta.com/microservices/api-gateways-are-going-through-an-identity-crisis):\n\n\"An explicitly and purposefully defined interface designed to be invoked over a network that enables software developers to get programmatic access to data and functionality within an organization in a controlled and comfortable way.\"\n</b></details>\n\n<details>\n<summary>What is an API specification?</summary><br><b>\n\nFrom [swagger.io](https://swagger.io/resources/articles/difference-between-api-documentation-specification):\n\n\"An API specification provides a broad understanding of how an API behaves and how the API links with other APIs. It explains how the API functions and the results to expect when using the API\"\n</b></details>\n\n<details>\n<summary>True or False? API Definition is the same as API Specification</summary><br><b>\n\nFalse. From [swagger.io](https://swagger.io/resources/articles/difference-between-api-documentation-specification):\n\n\"An API definition is similar to an API specification in that it provides an understanding of how an API is organized and how the API functions. But the API definition is aimed at machine consumption instead of human consumption of APIs.\"\n</b></details>\n\n<details>\n<summary>What is an API gateway?</summary><br><b>\n\nAn API gateway is like the gatekeeper that controls how different parts talk to each other and how information is exchanged between them.\n\nThe API gateway provides a single point of entry for all clients, and it can perform several tasks, including routing requests to the appropriate backend service, load balancing, security and authentication, rate limiting, caching, and monitoring.\n\nBy using an API gateway, organizations can simplify the management of their APIs, ensure consistent security and governance, and improve the performance and scalability of their backend services. They are also commonly used in microservices architectures, where there are many small, independent services that need to be accessed by different clients.\n</b></details>\n\n<details>\n<summary>What are the advantages of using/implementing an API gateway?</summary><br><b>\n\nAdvantages:\n\n  - Simplifies API management: Provides a single entry point for all requests, which simplifies the management and monitoring of multiple APIs.\n  - Improves security: Able to implement security features like authentication, authorization, and encryption to protect the backend services from unauthorized access.\n  - Enhances scalability: Can handle traffic spikes and distribute requests to backend services in a way that maximizes resource utilization and improves overall system performance.\n  - Enables service composition: Can combine different backend services into a single API, providing more granular control over the services that clients can access.\n  - Facilitates integration with external systems:  Can be used to expose internal services to external partners or customers, making it easier to integrate with external systems and enabling new business models.\n\n</b></details>\n\n<details>\n<summary>What is a Payload in API?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is Automation? How it's related or different from Orchestration?</summary><br><b>\n\nAutomation is the act of automating tasks to reduce human intervention or interaction in regards to IT technology and systems.<br>\nWhile automation focuses on a task level, Orchestration is the process of automating processes and/or workflows which consists of multiple tasks that usually across multiple systems.\n</b></details>\n\n<details>\n<summary>Tell me about interesting bugs you've found and also fixed</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is a Debugger and how it works?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What services an application might have?</summary><br><b>\n\n  * Authorization\n  * Logging\n  * Authentication\n  * Ordering\n  * Front-end\n  * Back-end\n  ...\n</b></details>\n\n<details>\n<summary>What is Metadata?</summary><br><b>\n\nData about data. Basically, it describes the type of information that an underlying data will hold.\n</b></details>\n\n<details>\n<summary>You can use one of the following formats: JSON, YAML, XML. Which one would you use? Why?</summary><br><b>\n\nI can't answer this for you :)\n</b></details>\n\n<details>\n<summary>What's KPI?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What's OKR?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What's DSL (Domain Specific Language)?</summary><br><b>\n\nDomain Specific Language (DSLs) are used to create a customised language that represents the domain such that domain experts can easily interpret it.\n</b></details>\n\n<details>\n<summary>What's the difference between KPI and OKR?</summary><br><b>\n</b></details>\n\n#### YAML\n\n<details>\n<summary>What is YAML?</summary><br><b>\n\nData serialization language used by many technologies today like Kubernetes, Ansible, etc.\n</b></details>\n\n<details>\n<summary>True or False? Any valid JSON file is also a valid YAML file</summary><br><b>\n\nTrue. Because YAML is superset of JSON.\n</b></details>\n\n<details>\n<summary>What is the format of the following data?\n\n```\n{\n    applications: [\n        {\n            name: \"my_app\",\n            language: \"python\",\n            version: 20.17\n        }\n    ]\n}\n```\n</summary><br><b>\nJSON\n</b></details>\n\n<details>\n<summary>What is the format of the following data?\n\n```\napplications:\n  - app: \"my_app\"\n    language: \"python\"\n    version: 20.17\n```\n</summary><br><b>\nYAML\n</b></details>\n\n<details>\n<summary>How to write a multi-line string with YAML? What use cases is it good for?</summary><br><b>\n\n```\nsomeMultiLineString: |\n  look mama\n  I can write a multi-line string\n  I love YAML\n```\n\nIt's good for use cases like writing a shell script where each line of the script is a different command.\n</b></details>\n\n<details>\n<summary>What is the difference between <code>someMultiLineString: |</code> to <code>someMultiLineString: ></code>?</summary><br><b>\n\nusing `>` will make the multi-line string to fold into a single line\n\n```\nsomeMultiLineString: >\n  This is actually\n  a single line\n  do not let appearances fool you\n```\n</b></details>\n\n<details>\n<summary>What are placeholders in YAML?</summary><br><b>\n\nThey allow you reference values instead of directly writing them and it is used like this:\n\n```\nusername: {{ my.user_name }}\n```\n</b></details>\n\n<details>\n<summary>How can you define multiple YAML components in one file?</summary><br><b>\n\nUsing this: `---`\nFor Examples:\n\n```\ndocument_number: 1\n---\ndocument_number: 2\n```\n</b></details>\n\n#### Firmware\n\n<details>\n<summary>Explain what is a firmware</summary><br><b>\n\n[Wikipedia](https://en.wikipedia.org/wiki/Firmware): \"In computing, firmware is a specific class of computer software that provides the low-level control for a device's specific hardware. Firmware, such as the BIOS of a personal computer, may contain basic functions of a device, and may provide hardware abstraction services to higher-level software such as operating systems.\"\n</b></details>\n\n## Cassandra\n\n<details>\n<summary>When running a cassandra cluster, how often do you need to run nodetool repair in order to keep the cluster consistent?\n\n  * Within the columnFamily GC-grace Once a week\n  * Less than the compacted partition minimum bytes\n  * Depended on the compaction strategy\n</summary><br><b>\n</b></details>\n\n## HTTP\n\n<details>\n<summary>What is HTTP?</summary><br><b>\n\n[Avinetworks](https://avinetworks.com/glossary/layer-7/): HTTP stands for Hypertext Transfer Protocol. HTTP uses TCP port 80 to enable internet communication. It is part of the Application Layer (L7) in OSI Model. \n</b></details>\n\n<details>\n<summary>Describe HTTP request lifecycle</summary><br><b>\n\n* Resolve host by request to DNS resolver\n* Client SYN\n* Server SYN+ACK\n* Client SYN\n* HTTP request\n* HTTP response\n</b></details>\n\n<details>\n<summary>True or False? HTTP is stateful</summary><br><b>\n\nFalse. It doesn't maintain state for incoming request.\n</b></details>\n\n<details>\n<summary>How HTTP request looks like?</summary><br><b>\n\nIt consists of:\n\n * Request line - request type\n * Headers - content info like length, encoding, etc.\n * Body (not always included)\n</b></details>\n\n<details>\n<summary>What HTTP method types are there?</summary><br><b>\n\n* GET\n* POST\n* HEAD\n* PUT\n* DELETE\n* CONNECT\n* OPTIONS\n* TRACE\n</b></details>\n\n<details>\n<summary>What HTTP response codes are there?</summary><br><b>\n\n* 1xx - informational\n* 2xx - Success\n* 3xx - Redirect\n* 4xx - Error, client fault\n* 5xx - Error, server fault\n</b></details>\n\n<details>\n<summary>What is HTTPS?</summary><br><b>\n\n\nHTTPS is a secure version of the HTTP protocol used to transfer data between a web browser and a web server. It encrypts the communication using SSL/TLS encryption to ensure that the data is private and secure.\n\nLearn more: https://www.cloudflare.com/learning/ssl/why-is-http-not-secure/\n</b></details>\n\n<details>\n<summary>Explain HTTP Cookies</summary><br><b>\n\nHTTP is stateless. To share state, we can use Cookies.\n\nTODO: explain what is actually a Cookie\n</b></details>\n\n<details>\n<summary>What is HTTP Pipelining?</summary><br><b>\n</b></details>\n\n<details>\n<summary>You get \"504 Gateway Timeout\" error from an HTTP server. What does it mean?</summary><br><b>\n\nThe server didn't receive a response from another server it communicates with in a timely manner.\n</b></details>\n\n<details>\n<summary>What is a proxy?</summary><br><b>\n\nA proxy is a server that acts as a middleman between a client device and a destination server. It can help improve privacy, security, and performance by hiding the client's IP address, filtering content, and caching frequently accessed data. \n  - Proxies can be used for load balancing, distributing traffic across multiple servers to help prevent server overload and improve website or application performance. They can also be used for data analysis, as they can log requests and traffic, providing useful insights into user behavior and preferences.\n</b></details>\n\n<details>\n<summary>What is a reverse proxy?</summary><br><b>\n\nA reverse proxy is a type of proxy server that sits between a client and a server, but it is used to manage traffic going in the opposite direction of a traditional forward proxy. In a forward proxy, the client sends requests to the proxy server, which then forwards them to the destination server. However, in a reverse proxy, the client sends requests to the destination server, but the requests are intercepted by the reverse proxy before they reach the server. \n  - They're commonly used to improve web server performance, provide high availability and fault tolerance, and enhance security by preventing direct access to the back-end server. They are often used in large-scale web applications and high-traffic websites to manage and distribute requests to multiple servers, resulting in improved scalability and reliability.\n</b></details>\n\n<details>\n<summary>When you publish a project, you usually publish it with a license. What types of licenses are you familiar with and which one do you prefer to use?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain what is \"X-Forwarded-For\"</summary><br><b>\n\n[Wikipedia](https://en.wikipedia.org/wiki/X-Forwarded-For): \"The X-Forwarded-For (XFF) HTTP header field is a common method for identifying the originating IP address of a client connecting to a web server through an HTTP proxy or load balancer.\"\n</b></details>\n\n#### Load Balancers\n\n<details>\n<summary>What is a load balancer?</summary><br><b>\n\nA load balancer accepts (or denies) incoming network traffic from a client, and based on some criteria (application related, network, etc.) it distributes those communications out to servers (at least one).\n</b></details>\n\n<details>\n<summary>Why to used a load balancer?</summary><br><b>\n\n* Scalability - using a load balancer, you can possibly add more servers in the backend to handle more requests/traffic from the clients, as opposed to using one server.\n* Redundancy - if one server in the backend dies, the load balancer will keep forwarding the traffic/requests to the second server so users won't even notice one of the servers in the backend is down.\n</b></details>\n\n<details>\n<summary>What load balancer techniques/algorithms are you familiar with?</summary><br><b>\n\n  * Round Robin\n  * Weighted Round Robin\n  * Least Connection\n  * Weighted Least Connection\n  * Resource Based\n  * Fixed Weighting\n  * Weighted Response Time\n  * Source IP Hash\n  * URL Hash\n</b></details>\n\n<details>\n<summary>What are the drawbacks of round robin algorithm in load balancing?</summary><br><b>\n\n  * A simple round robin algorithm knows nothing about the load and the spec of each server it forwards the requests to. It is possible, that multiple heavy workloads requests will get to the same server while other servers will got only lightweight requests which will result in one server doing most of the work, maybe even crashing at some point because it unable to handle all the heavy workloads requests by its own.\n  * Each request from the client creates a whole new session. This might be a problem for certain scenarios where you would like to perform multiple operations where the server has to know about the result of operation so basically, being sort of aware of the history it has with the client. In round robin, first request might hit server X, while second request might hit server Y and ask to continue processing the data that was processed on server X already.\n</b></details>\n\n<details>\n<summary>What is an Application Load Balancer?</summary><br><b>\n</b></details>\n\n<details>\n<summary>In which scenarios would you use ALB?</summary><br><b>\n</b></details>\n\n<details>\n<summary>At what layers a load balancer can operate?</summary><br><b>\n\nL4 and L7\n</b></details>\n\n<details>\n<summary>Can you perform load balancing without using a dedicated load balancer instance?</summary><br><b>\n\nYes, you can use DNS for performing load balancing.\n</b></details>\n\n<details>\n<summary>What is DNS load balancing? What its advantages? When would you use it?</summary><br><b>\n</b></details>\n\n#### Load Balancers - Sticky Sessions\n\n<details>\n<summary>What are sticky sessions? What are their pros and cons?</summary><br><b>\n\nRecommended read:\n  * [Red Hat Article](https://access.redhat.com/solutions/900933)\n\nCons:\n  * Can cause uneven load on instance (since requests routed to the same instances)\nPros:\n  * Ensures in-proc sessions are not lost when a new request is created\n</b></details>\n\n<details>\n<summary>Name one use case for using sticky sessions</summary><br><b>\n\nYou would like to make sure the user doesn't lose the current session data.\n</b></details>\n\n<details>\n<summary>What sticky sessions use for enabling the \"stickiness\"?</summary><br><b>\n\nCookies. There are application based cookies and duration based cookies.\n</b></details>\n\n<details>\n<summary>Explain application-based cookies</summary><br><b>\n\n* Generated by the application and/or the load balancer\n* Usually allows to include custom data\n</b></details>\n\n<details>\n<summary>Explain duration-based cookies</summary><br><b>\n\n* Generated by the load balancer\n* Session is not sticky anymore once the duration elapsed\n</b></details>\n\n#### Load Balancers - Load Balancing Algorithms\n\n<details>\n<summary>Explain each of the following load balancing techniques\n\n  * Round Robin\n  * Weighted Round Robin\n  * Least Connection\n  * Weighted Least Connection\n  * Resource Based\n  * Fixed Weighting\n  * Weighted Response Time\n  * Source IP Hash\n  * URL Hash\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain use case for connection draining?</summary><br><b>\nTo ensure that a Classic Load Balancer stops sending requests to instances that are de-registering or unhealthy, while keeping the existing connections open, use connection draining. This enables the load balancer to complete in-flight requests made to instances that are de-registering or unhealthy.\n\nThe maximum timeout value can be set between 1 and 3,600 seconds on both GCP and AWS.\n\n</b></details>\n\n#### Licenses\n\n<details>\n<summary>Are you familiar with \"Creative Commons\"? What do you know about it?</summary><br><b>\n\nThe Creative Commons license is a set of copyright licenses that allow creators to share their work with the public while retaining some control over how it can be used. The license was developed as a response to the restrictive standards of traditional copyright laws, which limited access of creative works. Its creators to choose the terms under which their works can be shared, distributed, and used by others. They're six main types of Creative Commons licenses, each with different levels of restrictions and permissions, the six licenses are:\n\n  * Attribution (CC BY): Allows others to distribute, remix, and build upon the work, even commercially, as long as they credit the original creator.\n  * Attribution-ShareAlike (CC BY-SA): Allows others to remix and build upon the work, even commercially, as long as they credit the original creator and release any new creations under the same license.\n  * Attribution-NoDerivs (CC BY-ND): Allows others to distribute the work, even commercially, but they cannot remix or change it in any way and must credit the original creator.\n  * Attribution-NonCommercial (CC BY-NC): Allows others to remix and build upon the work, but they cannot use it commercially and must credit the original creator.\n  * Attribution-NonCommercial-ShareAlike (CC BY-NC-SA): Allows others to remix and build upon the work, but they cannot use it commercially, must credit the original creator, and must release any new creations under the same license.\n  * Attribution-NonCommercial-NoDerivs (CC BY-NC-ND): Allows others to download and share the work, but they cannot use it commercially, remix or change it in any way, and must credit the original creator.\n\nSimply stated, the Creative Commons licenses are a way for creators to share their work with the public while retaining some control over how it can be used. The licenses promote creativity, innovation, and collaboration, while also respecting the rights of creators while still encouraging the responsible use of creative works.\n\nMore information: https://creativecommons.org/licenses/\n</b></details>\n\n<details>\n<summary>Explain the differences between copyleft and permissive licenses</summary><br><b>\n\nIn Copyleft, any derivative work must use the same licensing while in permissive licensing there are no such condition. GPL-3 is an example of copyleft license while BSD is an example of permissive license.\n</b></details>\n\n#### Random\n\n<details>\n<summary>How a search engine works?</summary><br><b>\n</b></details>\n\n<details>\n<summary>How auto completion works?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is faster than RAM?</summary><br><b>\n\nCPU cache.\n[Source](https://www.enterprisestorageforum.com/hardware/cache-memory/)\n</b></details>\n\n<details>\n<summary>What is a memory leak?</summary><br><b>\n\nA memory leak is a programming error that occurs when a program fails to release memory that is no longer needed, causing the program to consume increasing amounts of memory over time.\n\nThe leaks can lead to a variety of problems, including system crashes, performance degradation, and instability. Usually occurring after failed maintenance on older systems and compatibility with new components over time.\n</b></details>\n\n<details>\n<summary>What is your favorite protocol?</summary><br><b>\n\nSSH\nHTTP\nDHCP\nDNS\n...\n</b></details>\n\n<details>\n<summary>What is Cache API?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the C10K problem? Is it relevant today?</summary><br><b>\n\nhttps://idiallo.com/blog/c10k-2016\n</b></details>\n\n## Storage\n\n<details>\n<summary>What types of storage are there?</summary><br><b>\n\n  * File\n  * Block\n  * Object\n</b></details>\n\n<details>\n<summary>Explain Object Storage</summary><br><b>\n\n- Data is divided to self-contained objects\n- Objects can contain metadata\n</b></details>\n\n<details>\n<summary>What are the pros and cons of object storage?</summary><br><b>\n\nPros:\n  - Usually with object storage, you pay for what you use as opposed to other storage types where you pay for the storage space you allocate\n  - Scalable storage: Object storage mostly based on a model where what you use, is what you get and you can add storage as need\nCons:\n  - Usually performs slower than other types of storage\n  - No granular modification: to change an object, you have re-create it\n</b></details>\n\n<details>\n<summary>What are some use cases for using object storage?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain File Storage</summary><br><b>\n\n- File Storage used for storing data in files, in a hierarchical structure\n- Some of the devices for file storage: hard drive, flash drive, cloud-based file storage\n- Files usually organized in directories\n</b></details>\n\n<details>\n<summary>What are the pros and cons of File Storage?</summary><br><b>\n\nPros:\n- Users have full control of their own files and can run variety of operations on the files: delete, read, write and move.\n- Security mechanism allows for users to have a better control at things such as file locking\n</b></details>\n\n<details>\n<summary>What are some examples of file storage?</summary><br><b>\n\nLocal filesystem\nDropbox\nGoogle Drive\n</b></details>\n\n<details>\n<summary>What types of storage devices are there?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain IOPS</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain storage throughput</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is a filesystem?</summary><br><b>\n\nA file system is a way for computers and other electronic devices to organize and store data files. It provides a structure that helps to organize data into files and directories, making it easier to find and manage information. A file system is crucial for providing a way to store and manage data in an organized manner.\n\nCommonly used filed systems:\n  Windows:\n  * NTFS\n  * exFAT\n\n  Mac OS:\n  * HFS+\n  *APFS\n\n</b></details>\n\n<details>\n<summary>Explain Dark Data</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain MBR</summary><br><b>\n</b></details>\n\n<a name=\"questions-you-ask\"></a>\n## Questions you CAN ask\n\nA list of questions you as a candidate can ask the interviewer during or after the interview.\nThese are only a suggestion, use them carefully. Not every interviewer will be able to answer these (or happy to) which should be perhaps a red flag warning for your regarding working in such place but that's really up to you.\n\n<details>\n<summary>What do you like about working here?</summary><br><b>\n</b></details>\n\n<details>\n<summary>How does the company promote personal growth?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the current level of technical debt you are dealing with?</summary><br><b>\n\nBe careful when asking this question - all companies, regardless of size, have some level of tech debt.\nPhrase the question in the light that all companies have the deal with this, but you want to see the current\npain points they are dealing with <br>\n\nThis is a great way to figure how managers deal with unplanned work, and how good they are at\nsetting expectations with projects.\n</b></details>\n\n<details>\n<summary>Why I should NOT join you? (or 'what you don't like about working here?')</summary><br><b>\n</b></details>\n\n<details>\n<summary>What was your favorite project you've worked on?</summary><br><b>\n\nThis can give you insights in some of the cool projects a company is working on, and if\nyou would enjoy working on projects like these. This is also a good way to see if\nthe managers are allowing employees to learn and grow with projects outside of the\nnormal work you'd do.\n</b></details>\n\n<details>\n<summary>If you could change one thing about your day to day, what would it be?</summary><br><b>\n\nSimilar to the tech debt question, this helps you identify any pain points with the company.\nAdditionally, it can be a great way to show how you'd be an asset to the team.<br>\n\nFor Example, if they mention they have problem X, and you've solved that in the past,\nyou can show how you'd be able to mitigate that problem.\n</b></details>\n\n<details>\n<summary>Let's say that we agree and you hire me to this position, after X months, what do you expect that I have achieved?</summary><br><b>\n\nNot only this will tell you what is expected from you, it will also provide big hint on the type of work you are going to do in the first months of your job.\n</b></details>\n\n## Testing\n\n<details>\n<summary>Explain white-box testing</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain black-box testing</summary><br><b>\n</b></details>\n\n<details>\n<summary>What are unit tests?</summary><br><b>\n\nUnit test are a software testing technique that involves systimatically breaking down a system and testing each individual part of the assembly. These tests are automated and can be run repeatedly to allow developers to catch edge case scenarios or bugs quickly while developing.\n\nThe main objective of unit tests are to verify each function is producing proper outputs given a set of inputs.\n</b></details>\n\n<details>\n<summary>What types of tests would you run to test a web application?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain test harness?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is A/B testing?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is network simulation and how do you perform it?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What types of performances tests are you familiar with?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain the following types of tests:\n\n  * Load Testing\n  * Stress Testing\n  * Capacity Testing\n  * Volume Testing\n  * Endurance Testing\n</summary><br><b>\n</b></details>\n\n## Regex\n\nGiven a text file, perform the following exercises\n\n#### Extract\n\n<details>\n<summary>Extract all the numbers</summary><br><b>\n\n  - \"\\d+\"\n</b></details>\n\n<details>\n<summary>Extract the first word of each line</summary><br><b>\n\n  - \"^\\w+\"\nBonus: extract the last word of each line\n\n  - \"\\w+(?=\\W*$)\" (in most cases, depends on line formatting)\n</b></details>\n\n<details>\n<summary>Extract all the IP addresses</summary><br><b>\n\n  - \"\\b(?:\\d{1,3}\\ .){3}\\d{1,3}\\b\" IPV4:(This format looks for 1 to 3 digit sequence 3 times)\n</b></details>\n\n<details>\n<summary>Extract dates in the format of yyyy-mm-dd or yyyy-dd-mm</summary><br><b>\n</b></details>\n\n<details>\n<summary>Extract email addresses</summary><br><b>\n\n  - \"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\ .[A-Za-z]{2,}\\b\"\n</b></details>\n\n#### Replace\n\n<details>\n<summary>Replace tabs with four spaces</summary><br><b>\n</b></details>\n\n<details>\n<summary>Replace 'red' with 'green'</summary><br><b>\n</b></details>\n\n## System Design\n\n<details>\n<summary>Explain what a \"single point of failure\" is. </summary><br><b>\nA \"single point of failure\", in a system or organization, if it were to fail would cause the entire system to fail or significantly disrupt it's operation. In other words, it is a vulnerability where there\nis no backup in place to compensate for the failure.\n</b></details>\n\n<details>\n<summary>What is CDN?</summary><br><b>\n\nCDN (Content Delivery Network) responsible for distributing content geographically. Part of it, is what is known as edge locations, aka cache proxies, that allows users to get their content quickly due to cache features and geographical distribution.\n</b></details>\n\n<details>\n<summary>Explain Multi-CDN</summary><br><b>\n\nIn single CDN, the whole content is originated from content delivery network.<br>\nIn multi-CDN, content is distributed across multiple different CDNs, each might be on a completely different provider/cloud.\n</b></details>\n\n<details>\n<summary>What are the benefits of Multi-CDN over a single CDN?</summary><br><b>\n\n* Resiliency: Relying on one CDN means no redundancy. With multiple CDNs you don't need to worry about your CDN being down\n* Flexibility in Costs: Using one CDN enforces you to specific rates of that CDN. With multiple CDNs you can take into consideration using less expensive CDNs to deliver the content.\n* Performance: With Multi-CDN there is bigger potential in choosing better locations which more close to the client asking the content\n* Scale: With multiple CDNs, you can scale services to support more extreme conditions\n</b></details>\n\n<details>\n<summary>Explain \"3-Tier Architecture\" (including pros and cons)</summary><br><b>\nA \"3-Tier Architecture\" is a pattern used in software development for designing and structuring applications. It divides the application into 3 interconnected layers: Presentation, Business logic and Data storage.  \nPROS: \n* Scalability\n* Security\n* Reusability\nCONS:\n* Complexity\n* Performance overhead\n* Cost and development time\n</b></details>\n\n<details>\n<summary>Explain Mono-repo vs. Multi-repo.What are the cons and pros of each approach?</summary><br><b>\nIn a Mono-repo, all the code for an organization is stored in a single,centralized repository.\nPROS (Mono-repo):\n* Unified tooling\n* Code Sharing\nCONS (Mono-repo):\n* Increased complexity\n* Slower cloning\n\nIn a Multi-repo setup, each component is stored in it's own separate repository. Each repository has it's own version control history.\nPROS (Multi-repo):\n* Simpler to manage\n* Different teams and developers can work on different parts of the project independently, making parallel development easier.\nCONS (Multi-repo):\n* Code duplication\n* Integration challenges\n</b></details>\n\n<details>\n<summary>What are the drawbacks of monolithic architecture?</summary><br><b>\n\n* Not suitable for frequent code changes and the ability to deploy new features\n* Not designed for today's infrastructure (like public clouds)\n* Scaling a team to work monolithic architecture is more challenging\n* If a single component in this architecture fails, then the entire application fails.\n</b></details>\n\n<details>\n<summary>What are the advantages of microservices architecture over a monolithic architecture?</summary><br><b>\n\n* Each of the services individually fail without escalating into an application-wide outage.\n* Each service can be developed and maintained by a separate team and this team can choose its own tools and coding language\n</b></details>\n\n<details>\n<summary>What's a service mesh?</summary><br><b>\nIt is a layer that facilitates communication management and control between microservices in a containerized application. It handles tasks such as load balancing, encryption, and monitoring.\n</b></details>\n\n<details>\n<summary>Explain \"Loose Coupling\"</summary><br><b>\nIn \"Loose Coupling\", components of a system communicate with each other with a little understanding of each other's internal workings. This improves scalability and ease of modification in complex systems.\n</b></details>\n\n<details>\n<summary>What is a message queue? When is it used?</summary><br><b>\nIt is a communication mechanism used in distributed systems to enable asynchronous communication between different components. It is generally used when the systems use a microservices approach.\n</b></details>\n\n#### Scalability\n\n<details>\n<summary>Explain Scalability</summary><br><b>\n\nThe ability easily grow in size and capacity based on demand and usage.\n</b></details>\n\n<details>\n<summary>Explain Elasticity</summary><br><b>\n\nThe ability to grow but also to reduce based on what is required\n</b></details>\n\n<details>\n<summary>Explain Disaster Recovery</summary><br><b>\n\n\nDisaster recovery is the process of restoring critical business systems and data after a disruptive event. The goal is to minimize the impact and resume normal business activities quickly. This involves creating a plan, testing it, backing up critical data, and storing it in safe locations. In case of a disaster, the plan is then executed, backups are restored, and systems are hopefully brought back online. The recovery process may take hours or days depending on the damages of infrastructure. This makes business planning important, as a well-designed and tested disaster recovery plan can minimize the impact of a disaster and keep operations going.\n</b></details>\n\n<details>\n<summary>Explain Fault Tolerance and High Availability</summary><br><b>\n\nFault Tolerance - The ability to self-heal and return to normal capacity. Also the ability to withstand a failure and remain functional.\n\nHigh Availability - Being able to access a resource (in some use cases, using different platforms)\n</b></details>\n\n<details>\n<summary>What is the difference between high availability and Disaster Recovery?</summary><br><b>\n\n[wintellect.com](https://www.wintellect.com/high-availability-vs-disaster-recovery): \"High availability, simply put, is eliminating single points of failure and disaster recovery is the process of getting a system back to an operational state when a system is rendered inoperative. In essence, disaster recovery picks up when high availability fails, so HA first.\"\n</b></details>\n\n<details>\n<summary>Explain Vertical Scaling</summary><br><b>\n\nVertical Scaling is the process of adding resources to increase power of existing servers. For example, adding more CPUs, adding more RAM, etc.\n</b></details>\n\n<details>\n<summary>What are the disadvantages of Vertical Scaling?</summary><br><b>\n\nWith vertical scaling alone, the component still remains a single point of failure.\nIn addition, it has hardware limit where if you don't have more resources, you might not be able to scale vertically.\n</b></details>\n\n<details>\n<summary>Which type of cloud services usually support vertical scaling?</summary><br><b>\n\nDatabases, cache. It's common mostly for non-distributed systems.\n</b></details>\n\n<details>\n<summary>Explain Horizontal Scaling</summary><br><b>\n\nHorizontal Scaling is the process of adding more resources that will be able handle requests as one unit\n</b></details>\n\n<details>\n<summary>What is the disadvantage of Horizontal Scaling? What is often required in order to perform Horizontal Scaling?</summary><br><b>\n\nA load balancer. You can add more resources, but if you would like them to be part of the process, you have to serve them the requests/responses.\nAlso, data inconsistency is a concern with horizontal scaling.\n</b></details>\n\n<details>\n<summary>Explain in which use cases will you use vertical scaling and in which use cases you will use horizontal scaling</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain Resiliency and what ways are there to make a system more resilient</summary><br><b>\n</b></details>\n\n<details>\n<summary>Explain \"Consistent Hashing\"</summary><br><b>\n</b></details>\n\n<details>\n<summary>How would you update each of the services in the following drawing without having app (foo.com) downtime?<br>\n<img src=\"images/design/cdn-no-downtime.png\" width=\"300x;\" height=\"400px;\"/>\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is the problem with the following architecture and how would you fix it?<br>\n<img src=\"images/design/producers_consumers_issue.png\" width=\"400x;\" height=\"300px;\"/>\n</summary><br><b>\n\nThe load on the producers or consumers may be high which will then cause them to hang or crash.<br>\nInstead of working in \"push mode\", the consumers can pull tasks only when they are ready to handle them. It can be fixed by using a streaming platform like Kafka, Kinesis, etc. This platform will make sure to handle the high load/traffic and pass tasks/messages to consumers only when the ready to get them.\n\n<img src=\"images/design/producers_consumers_fix.png\" width=\"300x;\" height=\"200px;\"/>\n</b></details>\n\n<details>\n<summary>Users report that there is huge spike in process time when adding little bit more data to process as an input. What might be the problem?<br>\n<img src=\"images/design/input-process-output.png\" width=\"300x;\" height=\"200px;\"/>\n</summary><br><b>\n</b></details>\n\n<details>\n<summary>How would you scale the architecture from the previous question to hundreds of users?</summary><br><b>\n</b></details>\n\n#### Cache\n\n<details>\n<summary>What is \"cache\"? In which cases would you use it?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is \"distributed cache\"?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is a \"cache replacement policy\"?</summary><br><b>\n\nTake a look [here](https://en.wikipedia.org/wiki/Cache_replacement_policies)\n</b></details>\n\n<details>\n<summary>Which cache replacement policies are you familiar with?</summary><br><b>\n\nYou can find a list [here](https://en.wikipedia.org/wiki/Cache_replacement_policies)\n</b></details>\n\n<details>\n<summary>Explain the following cache policies:\n\n  * FIFO\n  * LIFO\n  * LRU</summary><br><b>\n\nRead about it [here](https://en.wikipedia.org/wiki/Cache_replacement_policies)\n</b></details>\n\n<details>\n<summary>Why not writing everything to cache instead of a database/datastore?</summary><br><b>\nCaching and databases serve different purposes and are optimized for different use cases.\n\nCaching is used to speed up read operations by storing frequently accessed data in memory or on a fast storage medium. By keeping data close to the application, caching reduces the latency and overhead of accessing data from a slower, more distant storage system such as a database or disk.\n\nOn the other hand, databases are optimized for storing and managing persistent data. Databases are designed to handle concurrent read and write operations, enforce consistency and integrity constraints, and provide features such as indexing and querying.\n</b></details>\n\n#### Migrations\n\n<details>\n<summary>How you prepare for a migration? (or plan a migration)</summary><br><b>\n\nYou can mention:\n\nroll-back & roll-forward\ncut over\ndress rehearsals\nDNS redirection\n</b></details>\n\n<details>\n<summary>Explain \"Branch by Abstraction\" technique</summary><br><b>\n</b></details>\n\n#### Design a system\n\n<details>\n<summary>Can you design a video streaming website?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Can you design a photo upload website?</summary><br><b>\n</b></details>\n\n<details>\n<summary>How would you build a URL shortener?</summary><br><b>\n</b></details>\n\n#### More System Design Questions\n\nAdditional exercises can be found in [system-design-notebook repository](https://github.com/bregman-arie/system-design-notebook).\n\n<p align=\"center\"><a href=\"https://github.com/bregman-arie/system-design-notebook\"><img src=\"images/system_design_notebook.png\"/></a></p>\n\n## Hardware\n\n<details>\n<summary>What is a CPU?</summary><br><b>\n\nA central processing unit (CPU) performs basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions in the program. This contrasts with external components such as main memory and I/O circuitry, and specialized processors such as graphics processing units (GPUs).\n</b></details>\n\n<details>\n<summary>What is RAM?</summary><br><b>\n\nRAM (Random Access Memory) is the hardware in a computing device where the operating system (OS), application programs and data in current use are kept so they can be quickly reached by the device's processor. RAM is the main memory in a computer. It is much faster to read from and write to than other kinds of storage, such as a hard disk drive (HDD), solid-state drive (SSD) or optical drive.\n</b></details>\n\n<details>\n<summary>What is a GPU?</summary><br><b>\nA GPU, or Graphics Processing Unit, is a specialized electronic circuit designed to expedite image and video processing for display on a computer screen.\n\n</b></details>\n\n<details>\n<summary>What is an embedded system?</summary><br><b>\n\nAn embedded system is a computer system - a combination of a computer processor, computer memory, and input/output peripheral devices—that has a dedicated function within a larger mechanical or electronic system. It is embedded as part of a complete device often including electrical or electronic hardware and mechanical parts. \n</b></details>\n\n<details>\n<summary>Can you give an example of an embedded system?</summary><br><b>\n\nA common example of an embedded system is a microwave oven's digital control panel, which is managed by a microcontroller.\n\nWhen committed to a certain goal, Raspberry Pi can serve as an embedded system.\n\n</b></details>\n\n<details>\n<summary>What types of storage are there?</summary><br><b>\n\nThere are several types of storage, including hard disk drives (HDDs), solid-state drives (SSDs), and optical drives (CD/DVD/Blu-ray). Other types of storage include USB flash drives, memory cards, and network-attached storage (NAS).\n</b></details>\n\n<details>\n<summary>What are some considerations DevOps teams should keep in mind when selecting hardware for their job?</summary><br>\n\nChoosing the right DevOps hardware is essential for ensuring streamlined CI/CD pipelines, timely feedback loops, and consistent service availability. Here's a distilled guide on what DevOps teams should consider:\n\n1. **Understanding Workloads**:\n    - **CPU**: Consider the need for multi-core or high-frequency CPUs based on your tasks.\n    - **RAM**: Enough memory is vital for activities like large-scale coding or intensive automation.\n    - **Storage**: Evaluate storage speed and capacity. SSDs might be preferable for swift operations.\n\n2. **Expandability**:\n    - **Horizontal Growth**: Check if you can boost capacity by adding more devices.\n    - **Vertical Growth**: Determine if upgrades (like RAM, CPU) to individual machines are feasible.\n\n3. **Connectivity Considerations**:\n    - **Data Transfer**: Ensure high-speed network connections for activities like code retrieval and data transfers.\n    - **Speed**: Aim for low-latency networks, particularly important for distributed tasks.\n    - **Backup Routes**: Think about having backup network routes to avoid downtimes.\n\n4. **Consistent Uptime**:\n    - Plan for hardware backups like RAID configurations, backup power sources, or alternate network connections to ensure continuous service.\n\n5. **System Compatibility**:\n    - Make sure your hardware aligns with your software, operating system, and intended platforms.\n\n6. **Power Efficiency**:\n    - Hardware that uses energy efficiently can reduce costs in long-term, especially in large setups.\n\n7. **Safety Measures**:\n    - Explore hardware-level security features, such as TPM, to enhance protection.\n\n8. **Overseeing & Control**:\n    - Tools like ILOM can be beneficial for remote handling.\n    - Make sure the hardware can be seamlessly monitored for health and performance.\n\n9. **Budgeting**:\n    - Consider both initial expenses and long-term costs when budgeting.\n\n10. **Support & Community**:\n    - Choose hardware from reputable vendors known for reliable support.\n    - Check for available drivers, updates, and community discussions around the hardware.\n\n11. **Planning Ahead**:\n    - Opt for hardware that can cater to both present and upcoming requirements.\n\n12. **Operational Environment**:\n    - **Temperature Control**: Ensure cooling systems to manage heat from high-performance units.\n    - **Space Management**: Assess hardware size considering available rack space.\n    - **Reliable Power**: Factor in consistent and backup power sources.\n\n13. **Cloud Coordination**:\n    - If you're leaning towards a hybrid cloud setup, focus on how local hardware will mesh with cloud resources.\n\n14. **Life Span of Hardware**:\n    - Be aware of the hardware's expected duration and when you might need replacements or upgrades.\n\n15. **Optimized for Virtualization**:\n    - If utilizing virtual machines or containers, ensure the hardware is compatible and optimized for such workloads.\n\n16. **Adaptability**:\n    - Modular hardware allows individual component replacements, offering more flexibility.\n\n17. **Avoiding Single Vendor Dependency**:\n    - Try to prevent reliance on a single vendor unless there are clear advantages.\n\n18. **Eco-Friendly Choices**:\n    - Prioritize sustainably produced hardware that's energy-efficient and environmentally responsible.\n\nIn essence, DevOps teams should choose hardware that is compatible with their tasks, versatile, gives good performance, and stays within their budget. Furthermore, long-term considerations such as maintenance, potential upgrades, and compatibility with impending technological shifts must be prioritized.\n\n</details>\n\n<details>\n<summary>What is the role of hardware in disaster recovery planning and implementation?</summary><br>\n\nHardware is critical in disaster recovery (DR) solutions. While the broader scope of DR includes things like standard procedures, norms, and human roles, it's the hardware that keeps business processes running smoothly. Here's an outline of how hardware works with DR:\n\n1. **Storing Data and Ensuring Its Duplication**:\n    - **Backup Equipment**: Devices like tape storage, backup servers, and external HDDs keep essential data stored safely at a different location.\n    - **Disk Arrays**: Systems such as RAID offer a safety net. If one disk crashes, the others compensate.\n\n2. **Alternate Systems for Recovery**:\n    - **Backup Servers**: These step in when the main servers falter, maintaining service flow.\n    - **Traffic Distributors**: Devices like load balancers share traffic across servers. If a server crashes, they reroute users to operational ones.\n\n3. **Alternate Operation Hubs**:\n    - **Ready-to-use Centers**: Locations equipped and primed to take charge immediately when the main center fails.\n    - **Basic Facilities**: Locations with necessary equipment but lacking recent data, taking longer to activate.\n    - **Semi-prepped Facilities**: Locations somewhat prepared with select systems and data, taking a moderate duration to activate.\n\n4. **Power Backup Mechanisms**:\n    - **Instant Power Backup**: Devices like UPS offer power during brief outages, ensuring no abrupt shutdowns.\n    - **Long-term Power Solutions**: Generators keep vital systems operational during extended power losses.\n\n5. **Networking Equipment**:\n    - **Backup Internet Connections**: Having alternatives ensures connectivity even if one provider faces issues.\n    - **Secure Connection Tools**: Devices ensuring safe remote access, especially crucial during DR situations.\n\n6. **On-site Physical Setup**:\n    - **Organized Housing**: Structures like racks to neatly store and manage hardware.\n    - **Emergency Temperature Control**: Backup cooling mechanisms to counter server overheating in HVAC malfunctions.\n\n7. **Alternate Communication Channels**:\n    - **Orbit-based Phones**: Handy when regular communication methods falter.\n    - **Direct Communication Devices**: Devices like radios useful when primary systems are down.\n\n8. **Protection Mechanisms**:\n    - **Electronic Barriers & Alert Systems**: Devices like firewalls and intrusion detection keep DR systems safeguarded.\n    - **Physical Entry Control**: Systems controlling entry and monitoring, ensuring only cleared personnel have access.\n\n9. **Uniformity and Compatibility in Hardware**:\n    - It's simpler to manage and replace equipment in emergencies if hardware configurations are consistent and compatible.\n\n10. **Equipment for Trials and Upkeep**:\n    - DR drills might use specific equipment to ensure the primary systems remain unaffected. This verifies the equipment's readiness and capacity to manage real crises.\n\nIn summary, while software and human interventions are important in disaster recovery operations, it is the hardware that provides the underlying support. It is critical for efficient disaster recovery plans to keep this hardware resilient, duplicated, and routinely assessed.\n\n</details>\n\n<details>\n<summary>What is a RAID?</summary><br>\n<b>\nRAID is an acronym that stands for \"Redundant Array of Independent Disks.\" It is a technique that combines numerous hard drives into a single device known as an array in order to improve performance, expand storage capacity, and/or offer redundancy to prevent data loss. RAID levels (for example, RAID 0, RAID 1, and RAID 5) provide varied benefits in terms of performance, redundancy, and storage efficiency.\n\n</b></details>\n\n<details>\n<summary>What is a microcontroller?</summary><br>\n<b>\nA microcontroller is a small integrated circuit that controls certain tasks in an embedded system. It typically includes a CPU, memory, and input/output peripherals.\n\n</b></details>\n\n<details>\n<summary>What is a Network Interface Controller or NIC?</summary><br><b>\nA Network Interface Controller (NIC) is a piece of hardware that connects a computer to a network and allows it to communicate with other devices.\n\n</b></details>\n\n<details>\n<summary>What is a DMA?</summary><br><b>\n\nDirect memory access (DMA) is a feature of computer systems that allows certain hardware subsystems to access main system memory independently of the central processing unit (CPU).DMA enables devices to share and receive data from the main memory in a computer. It does this while still allowing the CPU to perform other tasks.\n</b></details>\n\n<details>\n<summary>What is a Real-Time Operating Systems?</summary><br><b>\n\nA real-time operating system (RTOS) is an operating system (OS) for real-time computing applications that processes data and events that have critically defined time constraints. An RTOS is distinct from a time-sharing operating system, such as Unix, which manages the sharing of system resources with a scheduler, data buffers, or fixed task prioritization in a multitasking or multiprogramming environment. Processing time requirements need to be fully understood and bound rather than just kept as a minimum. All processing must occur within the defined constraints. Real-time operating systems are event-driven and preemptive, meaning the OS can monitor the relevant priority of competing tasks, and make changes to the task priority. Event-driven systems switch between tasks based on their priorities, while time-sharing systems switch the task based on clock interrupts.\n</b></details>\n\n<details>\n<summary>List of interrupt types</summary><br><b>\n\nThere are six classes of interrupts possible:\n* External\n* Machine check\n* I/O\n* Program\n* Restart\n* Supervisor call (SVC)\n</b></details>\n\n## Big Data\n\n<details>\n<summary>Explain what is exactly Big Data</summary><br><b>\n\nAs defined by Doug Laney:\n\n* Volume: Extremely large volumes of data\n* Velocity: Real time, batch, streams of data\n* Variety: Various forms of data, structured, semi-structured and unstructured\n* Veracity or Variability: Inconsistent, sometimes inaccurate, varying data\n</b></details>\n\n<details>\n<summary>What is DataOps? How is it related to DevOps?</summary><br><b>\n\n DataOps seeks to reduce the end-to-end cycle time of data analytics, from the origin of ideas to the literal creation of charts, graphs and models that create value. \n DataOps combines Agile development, DevOps and statistical process controls and applies them to data analytics.\n</b></details>\n\n<details>\n<summary>What is Data Architecture?</summary><br><b>\n\nAn answer from [talend.com](https://www.talend.com/resources/what-is-data-architecture):\n\n\"Data architecture is the process of standardizing how organizations collect, store, transform, distribute, and use data. The goal is to deliver relevant data to people who need it, when they need it, and help them make sense of it.\"\n</b></details>\n\n<details>\n<summary>Explain the different formats of data</summary><br><b>\n\n* Structured - data that has defined format and length (e.g. numbers, words)\n* Semi-structured - Doesn't conform to a specific format but is self-describing (e.g. XML, SWIFT)\n* Unstructured - does not follow a specific format (e.g. images, test messages)\n</b></details>\n\n<details>\n<summary>What is a Data Warehouse?</summary><br><b>\n\n[Wikipedia's explanation on Data Warehouse](https://en.wikipedia.org/wiki/Data_warehouse)\n[Amazon's explanation on Data Warehouse](https://aws.amazon.com/data-warehouse)\n</b></details>\n\n<details>\n<summary>What is Data Lake?</summary><br><b>\n\n[Data Lake - Wikipedia](https://en.wikipedia.org/wiki/Data_lake)\n</b></details>\n\n<details>\n<summary>Can you explain the difference between a data lake and a data warehouse?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is \"Data Versioning\"? What models of \"Data Versioning\" are there?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is ETL?</summary><br><b>\n</b></details>\n\n#### Apache Hadoop\n\n<details>\n<summary>Explain what is Hadoop</summary><br><b>\n\n[Apache Hadoop - Wikipedia](https://en.wikipedia.org/wiki/Apache_Hadoop)\n</b></details>\n\n<details>\n<summary>Explain Hadoop YARN</summary><br><b>\n\nResponsible for managing the compute resources in clusters and scheduling users' applications\n</b></details>\n\n<details>\n<summary>Explain Hadoop MapReduce</summary><br><b>\n\nA programming model for large-scale data processing\n</b></details>\n\n<details>\n<summary>Explain Hadoop Distributed File Systems (HDFS)</summary><br><b>\n\n* Distributed file system providing high aggregate bandwidth across the cluster.\n* For a user it looks like a regular file system structure but behind the scenes it's distributed across multiple machines in a cluster\n* Typical file size is TB and it can scale and supports millions of files\n* It's fault tolerant which means it provides automatic recovery from faults\n* It's best suited for running long batch operations rather than live analysis\n</b></details>\n\n<details>\n<summary>What do you know about HDFS architecture?</summary><br><b>\n\n[HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n* Master-slave architecture\n* Namenode - master, Datanodes - slaves\n* Files split into blocks\n* Blocks stored on datanodes\n* Namenode controls all metadata\n</b></details>\n\n## Ceph\n\n<details>\n<summary>Explain what is Ceph</summary><br><b>\nCeph is an Open-Source Distributed Storage System designed to provide excellent performance, reliability, and scalability. It's often used in cloud computing environments and Data Centers.\n</b></details>\n\n<details>\n<summary>True or False? Ceph favor consistency and correctness over performances</summary><br><b>\nTrue\n</b></details>\n\n<details>\n<summary>Which services or types of storage Ceph supports?</summary><br><b>\n\n* Object (RGW)\n* Block (RBD)\n* File (CephFS)\n</b></details>\n\n<details>\n<summary>What is RADOS?</summary><br><b>\n\n* Reliable Autonomic Distributed Object Storage\n* Provides low-level data object storage service\n* Strong Consistency\n* Simplifies design and implementation of higher layers (block, file, object)\n</b></details>\n\n<details>\n<summary>Describe RADOS software components</summary><br><b>\n\n* Monitor\n  * Central authority for authentication, data placement, policy\n  * Coordination point for all other cluster components\n  * Protect critical cluster state with Paxos\n* Manager\n  * Aggregates real-time metrics (throughput, disk usage, etc.)\n  * Host for pluggable management functions\n  * 1 active, 1+ standby per cluster\n* OSD (Object Storage Daemon)\n  * Stores data on an HDD or SSD\n  * Services client IO requests\n</b></details>\n\n<details>\n<summary>What is the workflow of retrieving data from Ceph?</summary><br><b>\nThe work flow is as follows:\n\n1. The client sends a request to the ceph cluster to retrieve data:\n> **Client could be any of the following**\n>> * Ceph Block Device\n>> * Ceph Object Gateway\n>> * Any third party ceph client\n\n\n2. The client retrieves the latest cluster map from the Ceph Monitor\n3. The client uses the CRUSH algorithm to map the object to a placement group. The placement group is then assigned to a OSD.\n4. Once the placement group and the OSD Daemon are determined, the client can retrieve the data from the appropriate OSD\n\n\n</b></details>\n\n<details>\n<summary>What is the workflow of writing data to Ceph?</summary><br><b>\nThe work flow is as follows:\n\n1. The client sends a request to the ceph cluster to retrieve data\n2. The client retrieves the latest cluster map from the Ceph Monitor\n3. The client uses the CRUSH algorithm to map the object to a placement group. The placement group is then assigned to a Ceph OSD Daemon dynamically.\n4. The client sends the data to the primary OSD of the determined placement group. If the data is stored in an erasure-coded pool, the primary OSD is responsible for encoding the object into data chunks and coding chunks, and distributing them to the other OSDs. \n\n</b></details>\n\n<details>\n<summary>What are \"Placement Groups\"?</summary><br><b>\n</b></details>\n\n<details>\n<summary>Describe in the detail the following: Objects -> Pool -> Placement Groups -> OSDs</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is OMAP?</summary><br><b>\n</b></details>\n\n<details>\n<summary>What is a metadata server? How it works?</summary><br><b>\n</b></details>\n\n## Packer\n\n<details>\n<summary>What is Packer? What is it used for?</summary><br><b>\n\nIn general, Packer automates machine images creation.\nIt allows you to focus on configuration prior to deployment while making the images. This allows you start the instances much faster in most cases.\n</b></details>\n\n<details>\n<summary>Packer follows a \"configuration->deployment\" model or \"deployment->configuration\"?</summary><br><b>\n\nA configuration->deployment which has some advantages like:\n\n1. Deployment Speed - you configure once prior to deployment instead of configuring every time you deploy. This allows you to start instances/services much quicker.\n2. More immutable infrastructure - with configuration->deployment it's not likely to have very different deployments since most of the configuration is done prior to the deployment. Issues like dependencies errors are handled/discovered prior to deployment in this model.\n</b></details>\n\n## Release\n\n<details>\n<summary>Explain Semantic Versioning</summary><br><b>\n\n[This](https://semver.org/) page explains it perfectly:\n\n```\nGiven a version number MAJOR.MINOR.PATCH, increment the:\n\nMAJOR version when you make incompatible API changes\nMINOR version when you add functionality in a backwards compatible manner\nPATCH version when you make backwards compatible bug fixes\nAdditional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.\n```\n</b></details>\n\n## Certificates\n\nIf you are looking for a way to prepare for a certain exam this is the section for you. Here you'll find a list of certificates, each references to a separate file with focused questions that will help you to prepare to the exam. Good luck :)\n\n#### AWS\n\n* [Cloud Practitioner](certificates/aws-cloud-practitioner.md) (Latest update: 2020)\n* [Solutions Architect Associate](certificates/aws-solutions-architect-associate.md) (Latest update: 2021)\n* [Cloud SysOps Administration Associate](certificates/aws-cloud-sysops-associate.md) (Latest update: Oct 2022)\n\n\n#### Azure\n\n* [AZ-900](certificates/azure-fundamentals-az-900.md) (Latest update: 2021)\n\n#### Kubernetes\n\n* [Certified Kubernetes Administrator (CKA)](topics/kubernetes/CKA.md) (Latest update: 2022)\n\n## Additional DevOps and SRE Projects\n\n<p align=\"center\"><a href=\"https://github.com/bregman-arie/sre-checklist\"><img width=\"500px\" src=\"images/sre_checklist.png\"/></a></p>\n\n<p align=\"center\"><a href=\"https://github.com/bregman-arie/howtheydevops\"><img src=\"images/how_they_devops.png\"/></a></p>\n<p align=\"center\"><a href=\"https://github.com/bregman-arie/devops-resources\"><img src=\"images/devops_resources.png\"/></a></p>\n<p align=\"center\"><a href=\"https://github.com/bregman-arie/infraverse\"><img src=\"images/infraverse.png\"/></a></p>\n\n## Credits\n\nThanks to all of our amazing [contributors](https://github.com/bregman-arie/devops-exercises/graphs/contributors) who make it easy for everyone to learn new things :)\n\nLogos credits can be found [here](credits.md)\n\n## License\n\n[![License: CC BY-NC-ND 3.0](https://img.shields.io/badge/License-CC%20BY--NC--ND%203.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/3.0/)\n"
        },
        {
          "name": "certificates",
          "type": "tree",
          "content": null
        },
        {
          "name": "coding",
          "type": "tree",
          "content": null
        },
        {
          "name": "credits.md",
          "type": "blob",
          "size": 2.05,
          "content": "## Credits\n\nJenkins logo created by <a href='https://twitter.com/ks_nenasheva'>Ksenia Nenasheva</a> and published through <a href=\"https://jenkins.io\">jenkins.io</a> is licensed under <a href=\"https://creativecommons.org/licenses/by-sa/3.0/\">cc by-sa 3.0</a><br>\nGit Logo by <a href=\"https://twitter.com/jasonlong\">Jason Long</a> is licensed under the <a href=\"https://creativecommons.org/licenses/by/3.0/\">Creative Commons Attribution 3.0 Unported License</a><br>\nTerraform logo created by <a href=\"https://www.hashicorp.com\">Hashicorp®</a><br>\nDocker logo created by <a href=\"https://www.docker.com\">Docker®</a><br>\nThe Python logo is a trademark of the Python Software Foundation®<br>\nPuppet logo created by <a href=\"https://puppet.com\">Puppet®</a><br>\nBash logo created by Prospect One<br>\nOpenStack logo created by and a trademark of The <a href=\"https://www.openstack.org\">OpenStack Foundation®</a><br>\nLinux, Kubernetes and Prometheus logos are trademarks of The Linux Foundation®<br>\nMongo logo is a trademark of <a href=\"http://www.mongodb.com\">Mongo®</a><br>\nDistributed logo by <a href=\"https://www.iconfinder.com/Flatart\">Flatart</a><br>\nChallenge icon by Elizabeth Arostegui in Technology Mix\n\"Question you ask\" (man raising hand) and \"Database\" icons by [Webalys](https://www.iconfinder.com/webalys)\nTesting logo by [Flatart](https://www.iconfinder.com/Flatart)<br>\nGoogle Cloud Plataform Logo created by <a href=\"https://about.google/\">Google®</a><br>\nVirtualBox Logo created by <a href=\"http://www.iconarchive.com/artist/dakirby309.html\">dAKirby309</a>, under the <a href=\"https://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-Noncommercial 4.0 License</a>.\nCertificates logo by <a href=\"https://www.iconfinder.com/Flatart\">Flatart</a><br>\nStorage icon by <a href=\"https://www.iconfinder.com/iconic_hub\">Dinosoftlab</a><br>\nCI/CD icon made made by <a href=\"https://www.flaticon.com/authors/freepik\" title=\"Freepik\">Freepik</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a></div>\nChaos Engineering logo made by Arie Bregman\n"
        },
        {
          "name": "exercises",
          "type": "tree",
          "content": null
        },
        {
          "name": "faq.md",
          "type": "blob",
          "size": 6.55,
          "content": "## FAQ\n\nMost frequently asked questions.\n\n### What is the purpose of repository?\n\nLearning, of course.\n\n### My goal is to prepare for a DevOps interviews. Should I use this repository?\n\nOverall, this repository should help you learn some concepts but, don't assume at any point that your interview will include similar questions to those that included in this repository.\nRegarding interviews, I've added a couple of suggestions [here](prepare_for_interview.md)<br>\n\n### Will you stop at some point adding questions and exercises?\n\nAll good things come to an end...\n\n### How do I become a better DevOps Engineer?\n\nThat's a great question.<br>\nI don't have a definitive answer for this question, I'm exploring it myself from time to time. What I believe helps is to:\n\n  * Practice - Practicing DevOps practically should be the primary way to become a DevOps engineer in my opinion\n  * Read - blogs, books, ... anything that can enrich your knowledge about DevOps or related DevOps topics\n  * Participate - there are great DevOps communities. I personally like [Reddit DevOps community](https://www.reddit.com/r/devops). Visiting there, I learn quite a lot on different topics.\n  * Share - This is one of the reasons I created this project. Primary goal was to help others but a secondary goal quickly became to learn more. By asking questions, you actually learn better a certain topic. Try it out, take a certain subject and try to come up with questions you would ask someone to test his/her skills about that topic.\n\n### Why most of the questions don't have answers?\n\n1. Because we need more contributors\n2. Because often asking questions is easier than answering them\n\n### Where can I find answers to some of the questions in this repository?\n\n1. Search for them using search engines, documentation pages, ... this is part of being a DevOps engineer\n2. Use the communities: many people will be happy to help and answer your questions\n3. Ask us. If you want, you can contact me or start a discussion on this project.\n\n### Where the questions and answers are coming from?\n\nWell, everywhere! - past experience, colleagues, contributors, ... but please note we do not allow copying interview questions from interview questions sites to here. There are people who worked hard on adding those to their sites and we respect that.<br>\nAs an evidence, we did deny pull requests with copied content from other sites.\n\n### What are the top DevOps skills required for being a DevOps Engineer?\n\nIt's a hard question and the reason is that if you'll ask 20 different people, you'll probably get at least 10 different answers but here is what I believe is common today:\n\n* OS - DevOps require you good understanding of operating system concepts. The level required is mainly depends on the company although in my opinion it should be the same level. You should understand how the operating system works, how to troubleshoot and debug issues, etc.\n* Programming is part of DevOps. The level again depends on the company. Some will require you to know basic level of scripting while others deep understanding of common algorithms, data structure, design patterns etc.\n* Cloud and Containers - while not 100% must in all companies/positions, this skill is on the rise every year and many (if not most) of the positions/companies require this skill. This specifically means: AWS/Azure/GCP, Docker/Podman, Kubernetes, ...\n* CI/CD - Be able to to answer questions like \"Why do we need CI/CD?\" and \"What ways and models are there to perform CI/CD?\". Eventually, practice assembling such processes and workflow, using whatever tools you feel comfortable with.\n\n### I feel like there are some questions that shouldn't be included in this project\n\nIs that a question? :)<br>\nIf you don't like some of the questions or think that some questions should be removed you can open an issue or submit a PR and we can discuss it there. We don't have rules against deleting questions (for now :P)\n\n### Can I copy the questions from here to my site?\n\nYou can (although I have no idea why would you want to), but:\n\n* Not without attribution. Many people worked hard on adding these questions and they deserve a proper credit for their work\n* Not if you plan to make money out of it. Directly or indirectly (e.g. ADS) as this is a free content and we would like it to stay this way :)\n\nSame goes for copying questions from different sources to this repository. We saw it happened already with a couple of pull requests and we rejected them. We will not merge pull requests with copied questions and answers from other sources.\n\n### Can I add questions and/or answers to this project?\n\nI'll simply imagine you didn't ask that on an open source project... :)\n\n### Why can't I add installation questions?\n\nIn general, I prefer questions added to this repository will have certain educational value for the user. Either regarding a certain concept or even a very general question, but one that will make the user research on a certain topic and will make him eventually more familiar with some of its core concepts.<br>\nI know that this is not the case for every question in this repo as of today (e.g. questions about specific commands) but this is definitely something to aspire for.\n\nI see little to none value in what is known as \"Installation Questions\". Let's say I ask you \"how to install Jenkins?\". Should I conclude from your answer that you are familiar with what is Jenkins and/or how it works? In other words, is there a value in knowing how to install Jenkins? In my opinion, no.\n\n### Where can I practice coding?\n\nPersonally, I really like the following sites\n\n* [HackerRank](https://www.hackerrank.com)\n* [LeetCode](https://leetcode.com)\n* [Exercism](https://exercism.io)\n\n### How to learn more DevOps?\n\nI listed some roadmaps in [devops-resources](https://github.com/bregman-arie/devops-resources)\n\n### Why some questions repeat themselves?\n\nIf you see two identical questions, that's a bug.<br>\nIf you see two similar questions, that's a feature :D (= it's intentional)\n\nFor example:\n\n1. What is horizontal scaling?\n2. The act of adding additional instances to the pool to handle scaling is called ________ scaling\n\nYou are right, both ask about horizontal scaling but it's done from a different angle in every question and in addition, I do believe repetition helps you to learn something in a way where you are not fixed on the way it's asked, rather you understand the concept itself.\n\n### Are you open for making big changes in the repository?\n\nAbsolutely. Don't be afraid to raise ideas and start discussions.<br>\nI'll be more than happy to discuss any change you think we should make to improve the learning experience\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "prepare_for_interview.md",
          "type": "blob",
          "size": 11.35,
          "content": "## How to prepare for DevOps/SRE/Production Engineer interviews?\n \nNote: the following is opinionated.\n \n### Skills you should have\n \n#### Linux\n \nEvery DevOps Engineer should have a deep understanding of at least one operating system and if you have the option to choose then I would say it should definitely be Linux as I believe it's a requirement of at least 90% of the DevOps jobs postings out there. In addition, Linux is almost integral part of any sub-area or domain in DevOps like Cloud, Containers, etc.\n \nUsually, the followup question is \"How extensive should my knowledge be?\" Out of all the DevOps skills, I would say this, along with coding, should be your strongest skills. Be familiar with OS processes, debugging tools, filesystem, networking, ... know your operating system, understand how it works, how to troubleshoot issues, etc.\n\nNot long ago, I've created a list of Linux resources right [here](https://dev.to/abregman/collection-of-linux-resources-3nhk). There are some good sites there that you can use for learning more about Linux.\n \n#### Programming\n \nMy personal belief is that any DevOps engineer should know programming, at least to some degree. Having this skill you can automate manual processes, improve some of the open source tools you are using today or build new tools & projects to provide a solution to existing problems. Knowing how to code = a lot of power.\n\nWhen it comes to interviews you'll notice that the level of knowledge very much depends on the company or position you are interviewing for. Some will require you just to be able to write simple scripts while others will deep dive into complex algorithms and data structures.\n\nThe best way to practice this skill is by doing some actual coding - scripts, online challenges, CLI tools, web applications, ... just code :)\n\nAlso, the following is probably clear to most people but let's still clarify it: when given the chance to choose any language for answering coding tasks/questions, choose the one you have experience with! Some candidates prefer to choose the language they think the company is using and this is a huge mistake since giving the right answer is always better than a wrong answer, no matter which language you have used :)\n \nI recommend the following sites for practicing coding:\n                                                 \n* [HackerRank](https://www.hackerrank.com)\n* [LeetCode](https://leetcode.com)               \n* [Exercism](https://exercism.io)\n \nStarting your own project is also a good idea. More on that later on.\n\n#### Architecture and Design\n  \nThis is also an important aspect of DevOps. You should be able to describe how to design different systems, workflows, and architectures. Also, the scale is an important aspect of that. A design which might work for a dozen of hosts or X amount of data, will not necessarily work well with bigger scale.\n \nSome ideas for you to explore: \n                               \n* How to design and implement a CI pipeline (or pipelines) for verifying PRs, run multiple different types of tests, package the project and deploy it somewhere\n* How to design and implement secured ELK architecture which will get logs from 10,000 apps and will display the data eventually to the user\n* Microservices designs are also quite popular these days\n\nIn general, you should be able to describe some designs, projects, architectures, ... you performed.\n\n#### Tooling\n\nSome interviews will focus on specific tools or technologies. Which tools? this is mainly based on a combination of what you mentioned in your C.V & those that are mentioned in the job posting and used in the company. Here are some questions I believe anyone should know to answer regarding the tools he/she is familiar with:\n                               \n* What the tool does? What it allows us to achieve that we couldn't do without it?                            \n* What its advantages over other tools in the same area, with the same purpose? Why you specifically using it?\n* How it works?\n* How to use it?\n* Best practices you apply/use when using it\n                               \nLet's deep dive into practical preparation steps\n                               \n### Scenarios || Challenges || Tasks              \n                               \nThis is a very common way to interview today for DevOps roles. The candidate is given a task which represents a common task of DevOps Engineers or a piece of common knowledge and the candidate has several hours or days to accomplish the task.<br>\n                               \nThis is a great way to prepare for interviews and I recommend to try it out before actually interviewing. How? Take requirements from job posts and convert them into scenarios. Let's see an example:\n                               \n\"Knowledge in CI/CD\" -> Scenario: create a CI/CD pipeline for a project.\n                               \nAt this point, some people ask: \"but what project?\" and the answer is: what about GitHub? it has only 9125912851285192 projects...and a free way to set up CI to any of them (also a great way to learn how to collaborate with others :) )\n                               \nLet's convert another scenario:\n\n\"Experience with provisioning servers\" -> Scenario: provision a server (to make it more interesting: create a web server).\n\nAnd the last example:                                                                                                                                                        \n\"Experience with scripting\" -> Scenario: write a script. Don't waste too much time thinking \"what script should I write?\". Simply automate something you are doing manually or even implement your own version of common small utils.\n  \n### Start your own DevOps project\n  \nStarting a DevOps project is a good idea because:\n  \n* It will make you practice coding\n* It will be something you can add to your resume and talk about with the interviewer\n* Depends on size and complexity, it can teach you something about design in general\n* Depends on adoption, it can teach you about managing Open Source projects\n  \nSame here, don't overthink what your project should be about. Just go and build something :)\n  \n### Sample interview questions\n  \nMake a sample list of interview questions on various topics/areas like technical, company, role, ... and try to answer them.\nSee if you can manage to answer them in a fluent, detailed way.\n  \nBetter yet, ask a good friend/colleague to challenge you with some questions. Your self-awareness might be an obstacle in objective self-review of your knowledge :)\n  \n### Networking\n  \nFor those who attend technical meetups and conferences, it can be a great opportunity to chat with people from other companies on their interviewing process. But don't start with it, it can be quite awkward. Say at least hello first... (:\n  \nDoing so can give you a lot of information on what to expect from an interview at some companies or how to better prepare.\n  \n### Know your resume\n  \nIt may sound trivial but the idea here is simple: be ready to answer any question regarding any line you included in your resume.\nSometimes candidates surprised when they are asked on a skill or line which seems to be not related to the position but the simple truth is: if you mentioned something on your resume, it's only fair to ask you about it.\n\n### Know the company\n\nBe familiar with the company you are interviewing at. Some ideas:\n\n  * What the company does?\n  * What products it has?\n  * Why its products are unique (or better than other products)? This can also be a good question for you to ask\n\n### Books\n\nFrom my experience, this is not done by many candidates but it's one of the best ways to deep dive into topics like operating system, virtualization, scale, distributed systems, etc.    \n\nIn most cases, you will do fine without reading books but for the AAA interviews (hardest level) you'll want to read some books and overall if you inspire to be better DevOps Engineer, books (also articles, blog posts) is a great way develop yourself :)\n\n### Consider starting in non-DevOps position\n\nWhile not a preparation step, you should know that landing DevOps as a first position can be challenging. No, it's not impossible but still, since DevOps covers many different practices, tools, ... it can be quite challenging and also overwhelming for someone to try and achieve it as a first position.<br>\nA possible path to becoming a DevOps engineer is to start with actually a different (but related) position and switch from there after 1-2 years or more.\n\nSome ideas:\n\n* System Administrator - This is perfect because every DevOps Engineer should have a solid understanding of the OS and sysadmins know their OS :)\n* Software Developer/Engineer - A DevOps should have coding skills and this position will provide more than the required knowledge in most cases\n* QA Engineer - This is a more tricky one because IMHO there are less overlapping areas/skills with DevOps Engineer. Sure, DevOps engineers should have some knowledge about testing but usually, it seems their solid skills/background is mainly composed out of system internals and coding skills.\n                                                                           \n### What to expect from a DevOps interview?                                \n                                                                           \nDevOps interviews can be very different. Some will include design questions, some will focus on coding, others will include short technical questions and you might even have an interview where the interviewer only goes over your resume and discussing your past experience.\n                                                                           \nThere are a couple of things you can do about it so it will be a less overwhelming experience:\n                                                                           \n1. You can and probably should ask the HR (in some cases even the team lead) how the interview process looks like. Some will be kind enough to even tell you how to prepare.\n2. Usually, the job posting gives more than a hint on where the focus will be and what you should focus on in your preparations so read it carefully.\n3. There are plenty of sites that have notes or a summary of the interview process in different companies, especially big enterprises.\n                                                                           \n### Don't forget to be an interviewer as well                              \n                                                                           \nSome people tend to look at interviews as a one-way road of \"Determining whether a candidate is qualified\" but in reality, a candidate should also determine whether\nthe company he/she is interviewing at, is the right place for him/her.            \n                                                                                                                 \n* Do I care about team size? More specifically, do I care about being a one-man show or being part of a bigger team?\n* Do I care about work-life balance?                                       \n* Do I care about personal growth and how it's practically done?           \n* Do I care about knowing what are my responsibilities as part of the role?                                                                                                  \nIf you do, you should also play the interviewer role :)\n\n### One Last Thing                                \n                                                  \n[Good luck](https://youtu.be/AFUrG1-BAt4?t=59) :)\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "topics",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "junegunn/fzf",
      "stars": 67034,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1,
          "content": "bin/fzf\nbin/fzf.exe\ndist\ntarget\npkg\nGemfile.lock\n.DS_Store\ndoc/tags\nvendor\ngopath\n*.zwc\nfzf\ntmp\n*.patch\n"
        },
        {
          "name": ".goreleaser.yml",
          "type": "blob",
          "size": 2.24,
          "content": "---\nversion: 2\nproject_name: fzf\n\nbefore:\n  hooks:\n    - go mod download\n\nbuilds:\n  - id: fzf\n    goos:\n      - darwin\n      - linux\n      - windows\n      - freebsd\n      - openbsd\n    goarch:\n      - amd64\n      - arm\n      - arm64\n      - loong64\n      - ppc64le\n      - s390x\n    goarm:\n      - 5\n      - 6\n      - 7\n    flags:\n      - -trimpath\n    ldflags:\n      - \"-s -w -X main.version={{ .Version }} -X main.revision={{ .ShortCommit }}\"\n    ignore:\n      - goos: freebsd\n        goarch: arm\n      - goos: openbsd\n        goarch: arm\n      - goos: freebsd\n        goarch: arm64\n      - goos: openbsd\n        goarch: arm64\n\n# .goreleaser.yaml\nnotarize:\n  macos:\n    - # Whether this configuration is enabled or not.\n      #\n      # Default: false.\n      # Templates: allowed.\n      enabled: \"{{ not .IsSnapshot }}\"\n\n      # Before notarizing, we need to sign the binary.\n      # This blocks defines the configuration for doing so.\n      sign:\n        # The .p12 certificate file path or its base64'd contents.\n        certificate: \"{{.Env.MACOS_SIGN_P12}}\"\n\n        # The password to be used to open the certificate.\n        password: \"{{.Env.MACOS_SIGN_PASSWORD}}\"\n\n      # Then, we notarize the binaries.\n      notarize:\n        # The issuer ID.\n        # Its the UUID you see when creating the App Store Connect key.\n        issuer_id: \"{{.Env.MACOS_NOTARY_ISSUER_ID}}\"\n\n        # Key ID.\n        # You can see it in the list of App Store Connect Keys.\n        # It will also be in the ApiKey filename.\n        key_id: \"{{.Env.MACOS_NOTARY_KEY_ID}}\"\n\n        # The .p8 key file path or its base64'd contents.\n        key: \"{{.Env.MACOS_NOTARY_KEY}}\"\n\n        # Whether to wait for the notarization to finish.\n        # Not recommended, as it could take a really long time.\n        wait: true\n\narchives:\n  - name_template: \"{{ .ProjectName }}-{{ .Version }}-{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}\"\n    builds:\n      - fzf\n    format: tar.gz\n    format_overrides:\n      - goos: windows\n        format: zip\n    files:\n      - non-existent*\n\nrelease:\n  github:\n    owner: junegunn\n    name: fzf\n  prerelease: auto\n  name_template: '{{ .Version }}'\n\nsnapshot:\n  name_template: \"{{ .Version }}-devel\"\n\nchangelog:\n  sort: asc\n  filters:\n    exclude:\n      - README\n      - test\n"
        },
        {
          "name": ".rubocop.yml",
          "type": "blob",
          "size": 0.56,
          "content": "Layout/LineLength:\n  Enabled: false\nMetrics:\n  Enabled: false\nLint/ShadowingOuterLocalVariable:\n  Enabled: false\nStyle/MethodCallWithArgsParentheses:\n  Enabled: true\n  AllowedMethods:\n    - assert\n    - exit\n    - paste\n    - puts\n    - raise\n    - refute\n    - require\n    - send_keys\n  AllowedPatterns:\n    - ^assert_\n    - ^refute_\nStyle/NumericPredicate:\n  Enabled: false\nStyle/StringConcatenation:\n  Enabled: false\nStyle/OptionalBooleanParameter:\n  Enabled: false\nStyle/WordArray:\n  MinSize: 1\nMinitest/AssertEqual:\n  Enabled: false\nNaming/VariableNumber:\n  Enabled: false\n"
        },
        {
          "name": ".tool-versions",
          "type": "blob",
          "size": 0.01,
          "content": "golang 1.20.13\n"
        },
        {
          "name": "ADVANCED.md",
          "type": "blob",
          "size": 27.01,
          "content": "Advanced fzf examples\n======================\n\n* *Last update: 2024/06/24*\n* *Requires fzf 0.54.0 or later*\n\n---\n\n<!-- vim-markdown-toc GFM -->\n\n* [Introduction](#introduction)\n* [Display modes](#display-modes)\n    * [`--height`](#--height)\n    * [`--tmux`](#--tmux)\n* [Dynamic reloading of the list](#dynamic-reloading-of-the-list)\n    * [Updating the list of processes by pressing CTRL-R](#updating-the-list-of-processes-by-pressing-ctrl-r)\n    * [Toggling between data sources](#toggling-between-data-sources)\n    * [Toggling with a single key binding](#toggling-with-a-single-key-binding)\n* [Ripgrep integration](#ripgrep-integration)\n    * [Using fzf as the secondary filter](#using-fzf-as-the-secondary-filter)\n    * [Using fzf as interactive Ripgrep launcher](#using-fzf-as-interactive-ripgrep-launcher)\n    * [Switching to fzf-only search mode](#switching-to-fzf-only-search-mode)\n    * [Switching between Ripgrep mode and fzf mode](#switching-between-ripgrep-mode-and-fzf-mode)\n    * [Switching between Ripgrep mode and fzf mode using a single key binding](#switching-between-ripgrep-mode-and-fzf-mode-using-a-single-key-binding)\n* [Log tailing](#log-tailing)\n* [Key bindings for git objects](#key-bindings-for-git-objects)\n    * [Files listed in `git status`](#files-listed-in-git-status)\n    * [Branches](#branches)\n    * [Commit hashes](#commit-hashes)\n* [Color themes](#color-themes)\n    * [fzf Theme Playground](#fzf-theme-playground)\n    * [Generating fzf color theme from Vim color schemes](#generating-fzf-color-theme-from-vim-color-schemes)\n\n<!-- vim-markdown-toc -->\n\nIntroduction\n------------\n\nfzf is an interactive [Unix filter][filter] program that is designed to be\nused with other Unix tools. It reads a list of items from the standard input,\nallows you to select a subset of the items, and prints the selected ones to\nthe standard output. You can think of it as an interactive version of *grep*,\nand it's already useful even if you don't know any of its options.\n\n```sh\n# 1. ps:   Feed the list of processes to fzf\n# 2. fzf:  Interactively select a process using fuzzy matching algorithm\n# 3. awk:  Take the PID from the selected line\n# 3. kill: Kill the process with the PID\nps -ef | fzf | awk '{print $2}' | xargs kill -9\n```\n\n[filter]: https://en.wikipedia.org/wiki/Filter_(software)\n\nWhile the above example succinctly summarizes the fundamental concept of fzf,\nyou can build much more sophisticated interactive workflows using fzf once you\nlearn its wide variety of features.\n\n- To see the full list of options and features, see `man fzf`\n- To see the latest additions, see [CHANGELOG.md](CHANGELOG.md)\n\nThis document will guide you through some examples that will familiarize you\nwith the advanced features of fzf.\n\nDisplay modes\n-------------\n\n### `--height`\n\nfzf by default opens in fullscreen mode, but it's not always desirable.\nOftentimes, you want to see the current context of the terminal while using\nfzf. `--height` is an option for opening fzf below the cursor in\nnon-fullscreen mode so you can still see the previous commands and their\nresults above it.\n\n```sh\nfzf --height=40%\n```\n\n![image](https://user-images.githubusercontent.com/700826/113379893-c184c680-93b5-11eb-9676-c7c0a2f01748.png)\n\nYou might also want to experiment with other layout options such as\n`--layout=reverse`, `--info=inline`, `--border`, `--margin`, etc.\n\n```sh\nfzf --height=40% --layout=reverse\nfzf --height=40% --layout=reverse --info=inline\nfzf --height=40% --layout=reverse --info=inline --border\nfzf --height=40% --layout=reverse --info=inline --border --margin=1\nfzf --height=40% --layout=reverse --info=inline --border --margin=1 --padding=1\n```\n\n![image](https://user-images.githubusercontent.com/700826/113379932-dfeac200-93b5-11eb-9e28-df1a2ee71f90.png)\n\n*(See `Layout` section of the man page to see the full list of options)*\n\nBut you definitely don't want to repeat `--height=40% --layout=reverse\n--info=inline --border --margin=1 --padding=1` every time you use fzf. You\ncould write a wrapper script or shell alias, but there is an easier option.\nDefine `$FZF_DEFAULT_OPTS` like so:\n\n```sh\nexport FZF_DEFAULT_OPTS=\"--height=40% --layout=reverse --info=inline --border --margin=1 --padding=1\"\n```\n\n### `--tmux`\n\n(Requires tmux 3.3 or later)\n\nIf you're using tmux, you can open fzf in a tmux popup using `--tmux` option.\n\n```sh\n# Open fzf in a tmux popup at the center of the screen with 70% width and height\nfzf --tmux 70%\n```\n\n![image](https://github.com/junegunn/fzf/assets/700826/9c365405-c700-49b2-8985-60d822ed4cff)\n\n`--tmux` option is silently ignored if you're not on tmux. So if you're trying\nto avoid opening fzf in fullscreen, try specifying both `--height` and `--tmux`.\n\n```sh\n# --tmux is specified later so it takes precedence over --height when on tmux.\n# If you're not on tmux, --tmux is ignored and --height is used instead.\nfzf  --height 70% --tmux 70%\n```\n\nYou can also specify the position, width, and height of the popup window in\nthe following format:\n\n* `[center|top|bottom|left|right][,SIZE[%]][,SIZE[%][,border-native]]`\n\n```sh\n# 100% width and 60% height\nfzf --tmux 100%,60% --border horizontal\n```\n\n![image](https://github.com/junegunn/fzf/assets/700826/f80d3514-d69f-42f2-a8de-a392a562bfcf)\n\n```sh\n# On the right (50% width)\nfzf --tmux right\n```\n\n![image](https://github.com/junegunn/fzf/assets/700826/4033ade4-7efa-421b-a3fb-a430d197098a)\n\n```sh\n# On the left (40% width and 70% height)\nfzf --tmux left,40%,70%\n```\n\n![image](https://github.com/junegunn/fzf/assets/700826/efe43881-2bf0-49ea-ab2e-1377f778cd52)\n\n> [!TIP]\n> You might also want to check out my tmux plugins which support this popup\n> window layout.\n>\n> - https://github.com/junegunn/tmux-fzf-url\n> - https://github.com/junegunn/tmux-fzf-maccy\n\nDynamic reloading of the list\n-----------------------------\n\nfzf can dynamically update the candidate list using an arbitrary program with\n`reload` bindings (The design document for `reload` can be found\n[here][reload]).\n\n[reload]: https://github.com/junegunn/fzf/issues/1750\n\n### Updating the list of processes by pressing CTRL-R\n\nThis example shows how you can set up a binding for dynamically updating the\nlist without restarting fzf.\n\n```sh\n(date; ps -ef) |\n  fzf --bind='ctrl-r:reload(date; ps -ef)' \\\n      --header=$'Press CTRL-R to reload\\n\\n' --header-lines=2 \\\n      --preview='echo {}' --preview-window=down,3,wrap \\\n      --layout=reverse --height=80% | awk '{print $2}' | xargs kill -9\n```\n\n![image](https://user-images.githubusercontent.com/700826/113465047-200c7c00-946c-11eb-918c-268f37a900c8.png)\n\n- The initial command is `(date; ps -ef)`. It prints the current date and\n  time, and the list of the processes.\n- With `--header` option, you can show any message as the fixed header.\n- To disallow selecting the first two lines (`date` and `ps` header), we use\n  `--header-lines=2` option.\n- `--bind='ctrl-r:reload(date; ps -ef)'` binds CTRL-R to `reload` action that\n  runs `date; ps -ef`, so we can update the list of the processes by pressing\n  CTRL-R.\n- We use simple `echo {}` preview option, so we can see the entire line on the\n  preview window below even if it's too long\n\n### Toggling between data sources\n\nYou're not limited to just one reload binding. Set up multiple bindings so\nyou can switch between data sources.\n\n```sh\nfind * | fzf --prompt 'All> ' \\\n             --header 'CTRL-D: Directories / CTRL-F: Files' \\\n             --bind 'ctrl-d:change-prompt(Directories> )+reload(find * -type d)' \\\n             --bind 'ctrl-f:change-prompt(Files> )+reload(find * -type f)'\n```\n\n![image](https://user-images.githubusercontent.com/700826/113465073-4af6d000-946c-11eb-858f-2372c0955f67.png)\n\n![image](https://user-images.githubusercontent.com/700826/113465072-46321c00-946c-11eb-9b6f-cda3951df579.png)\n\n### Toggling with a single key binding\n\nThe above example uses two different key bindings to toggle between two modes,\nbut can we just use a single key binding?\n\nTo make a key binding behave differently each time it is pressed, we need:\n\n1. a way to store the current state. i.e. \"which mode are we in?\"\n2. and a way to dynamically perform different actions depending on the state.\n\nThe following example shows how to 1. store the current mode in the prompt\nstring, 2. and use this information (`$FZF_PROMPT`) to determine which\nactions to perform using the `transform` action.\n\n```sh\nfd --type file |\n  fzf --prompt 'Files> ' \\\n      --header 'CTRL-T: Switch between Files/Directories' \\\n      --bind 'ctrl-t:transform:[[ ! $FZF_PROMPT =~ Files ]] &&\n              echo \"change-prompt(Files> )+reload(fd --type file)\" ||\n              echo \"change-prompt(Directories> )+reload(fd --type directory)\"' \\\n      --preview '[[ $FZF_PROMPT =~ Files ]] && bat --color=always {} || tree -C {}'\n```\n\nRipgrep integration\n-------------------\n\n### Using fzf as the secondary filter\n\n* Requires [bat][bat]\n* Requires [Ripgrep][rg]\n\n[bat]: https://github.com/sharkdp/bat\n[rg]: https://github.com/BurntSushi/ripgrep\n\nfzf is pretty fast for filtering a list that you will rarely have to think\nabout its performance. But it is not the right tool for searching for text\ninside many large files, and in that case you should definitely use something\nlike [Ripgrep][rg].\n\nIn the next example, Ripgrep is the primary filter that searches for the given\ntext in files, and fzf is used as the secondary fuzzy filter that adds\ninteractivity to the workflow. And we use [bat][bat] to show the matching line in\nthe preview window.\n\nThis is a bash script and it will not run as expected on other non-compliant\nshells. To avoid the compatibility issue, let's save this snippet as a script\nfile called `rfv`.\n\n```bash\n#!/usr/bin/env bash\n\n# 1. Search for text in files using Ripgrep\n# 2. Interactively narrow down the list using fzf\n# 3. Open the file in Vim\nrg --color=always --line-number --no-heading --smart-case \"${*:-}\" |\n  fzf --ansi \\\n      --color \"hl:-1:underline,hl+:-1:underline:reverse\" \\\n      --delimiter : \\\n      --preview 'bat --color=always {1} --highlight-line {2}' \\\n      --preview-window 'up,60%,border-bottom,+{2}+3/3,~3' \\\n      --bind 'enter:become(vim {1} +{2})'\n```\n\nAnd run it with an initial query string.\n\n```sh\n# Make the script executable\nchmod +x rfv\n\n# Run it with the initial query \"algo\"\n./rfv algo\n```\n\n> Ripgrep will perform the initial search and list all the lines that contain\n`algo`. Then we further narrow down the list on fzf.\n\n![image](https://user-images.githubusercontent.com/700826/113683873-a42a6200-96ff-11eb-9666-26ce4091b0e4.png)\n\nI know it's a lot to digest, let's try to break down the code.\n\n- Ripgrep prints the matching lines in the following format\n  ```\n  man/man1/fzf.1:54:.BI \"--algo=\" TYPE\n  man/man1/fzf.1:55:Fuzzy matching algorithm (default: v2)\n  man/man1/fzf.1:58:.BR v2 \"     Optimal scoring algorithm (quality)\"\n  src/pattern_test.go:7:  \"github.com/junegunn/fzf/src/algo\"\n  ```\n  The first token delimited by `:` is the file path, and the second token is\n  the line number of the matching line. They respectively correspond to `{1}`\n  and `{2}` in the preview command.\n    - `--preview 'bat --color=always {1} --highlight-line {2}'`\n- As we run `rg` with `--color=always` option, we should tell fzf to parse\n  ANSI color codes in the input by setting `--ansi`.\n- We customize how fzf colors various text elements using `--color` option.\n  `-1` tells fzf to keep the original color from the input. See `man fzf` for\n  available color options.\n- The value of `--preview-window` option consists of 5 components delimited\n  by `,`\n    1. `up` — Position of the preview window\n    1. `60%` — Size of the preview window\n    1. `border-bottom` — Preview window border only on the bottom side\n    1. `+{2}+3/3` — Scroll offset of the preview contents\n    1. `~3` — Fixed header\n- Let's break down the latter two. We want to display the bat output in the\n  preview window with a certain scroll offset so that the matching line is\n  positioned near the center of the preview window.\n    - `+{2}` — The base offset is extracted from the second token\n    - `+3` — We add 3 lines to the base offset to compensate for the header\n      part of `bat` output\n        - ```\n          ───────┬──────────────────────────────────────────────────────────\n                 │ File: CHANGELOG.md\n          ───────┼──────────────────────────────────────────────────────────\n             1   │ CHANGELOG\n             2   │ =========\n             3   │\n             4   │ 0.26.0\n             5   │ ------\n          ```\n    - `/3` adjusts the offset so that the matching line is shown at a third\n      position in the window\n    - `~3` makes the top three lines fixed header so that they are always\n      visible regardless of the scroll offset\n- Instead of using shell script to process the final output of fzf, we use\n  `become(...)` action which was added in [fzf 0.38.0][0.38.0] to turn fzf\n  into a new process that opens the file with `vim` (`vim {1}`) and move the\n  cursor to the line (`+{2}`).\n\n[0.38.0]: https://github.com/junegunn/fzf/blob/master/CHANGELOG.md#0380\n\n### Using fzf as interactive Ripgrep launcher\n\nWe have learned that we can bind `reload` action to a key (e.g.\n`--bind=ctrl-r:execute(ps -ef)`). In the next example, we are going to **bind\n`reload` action to `change` event** so that whenever the user *changes* the\nquery string on fzf, `reload` action is triggered.\n\nHere is a variation of the above `rfv` script. fzf will restart Ripgrep every\ntime the user updates the query string on fzf. Searching and filtering is\ncompletely done by Ripgrep, and fzf merely provides the interactive interface.\nSo we lose the \"fuzziness\", but the performance will be better on larger\nprojects, and it will free up memory as you narrow down the results.\n\n```bash\n#!/usr/bin/env bash\n\n# 1. Search for text in files using Ripgrep\n# 2. Interactively restart Ripgrep with reload action\n# 3. Open the file in Vim\nRG_PREFIX=\"rg --column --line-number --no-heading --color=always --smart-case \"\nINITIAL_QUERY=\"${*:-}\"\nfzf --ansi --disabled --query \"$INITIAL_QUERY\" \\\n    --bind \"start:reload:$RG_PREFIX {q}\" \\\n    --bind \"change:reload:sleep 0.1; $RG_PREFIX {q} || true\" \\\n    --delimiter : \\\n    --preview 'bat --color=always {1} --highlight-line {2}' \\\n    --preview-window 'up,60%,border-bottom,+{2}+3/3,~3' \\\n    --bind 'enter:become(vim {1} +{2})'\n```\n\n![image](https://user-images.githubusercontent.com/700826/113684212-f9ff0a00-96ff-11eb-8737-7bb571d320cc.png)\n\n- Instead of starting fzf in the usual `rg ... | fzf` form, we make it start\n  the initial Ripgrep process immediately via `start:reload` binding for the\n  consistency of the code.\n- Filtering is no longer a responsibility of fzf; hence `--disabled`\n- `{q}` in the reload command evaluates to the query string on fzf prompt.\n- `sleep 0.1` in the reload command is for \"debouncing\". This small delay will\n  reduce the number of intermediate Ripgrep processes while we're typing in\n  a query.\n\n### Switching to fzf-only search mode\n\nIn the previous example, we lost fuzzy matching capability as we completely\ndelegated search functionality to Ripgrep. But we can dynamically switch to\nfzf-only search mode by *\"unbinding\"* `reload` action from `change` event.\n\n```sh\n#!/usr/bin/env bash\n\n# Two-phase filtering with Ripgrep and fzf\n#\n# 1. Search for text in files using Ripgrep\n# 2. Interactively restart Ripgrep with reload action\n#    * Press alt-enter to switch to fzf-only filtering\n# 3. Open the file in Vim\nRG_PREFIX=\"rg --column --line-number --no-heading --color=always --smart-case \"\nINITIAL_QUERY=\"${*:-}\"\nfzf --ansi --disabled --query \"$INITIAL_QUERY\" \\\n    --bind \"start:reload:$RG_PREFIX {q}\" \\\n    --bind \"change:reload:sleep 0.1; $RG_PREFIX {q} || true\" \\\n    --bind \"alt-enter:unbind(change,alt-enter)+change-prompt(2. fzf> )+enable-search+clear-query\" \\\n    --color \"hl:-1:underline,hl+:-1:underline:reverse\" \\\n    --prompt '1. ripgrep> ' \\\n    --delimiter : \\\n    --preview 'bat --color=always {1} --highlight-line {2}' \\\n    --preview-window 'up,60%,border-bottom,+{2}+3/3,~3' \\\n    --bind 'enter:become(vim {1} +{2})'\n```\n\n* Phase 1. Filtering with Ripgrep\n![image](https://user-images.githubusercontent.com/700826/119213880-735e8a80-bafd-11eb-8493-123e4be24fbc.png)\n* Phase 2. Filtering with fzf\n![image](https://user-images.githubusercontent.com/700826/119213887-7e191f80-bafd-11eb-98c9-71a1af9d7aab.png)\n\n- We added `--prompt` option to show that fzf is initially running in \"Ripgrep\n  launcher mode\".\n- We added `alt-enter` binding that\n    1. unbinds `change` event, so Ripgrep is no longer restarted on key press\n    2. changes the prompt to `2. fzf>`\n    3. enables search functionality of fzf\n    4. clears the current query string that was used to start Ripgrep process\n    5. and unbinds `alt-enter` itself as this is a one-off event\n- We reverted `--color` option for customizing how the matching chunks are\n  displayed in the second phase\n\n### Switching between Ripgrep mode and fzf mode\n\n[fzf 0.30.0][0.30.0] added `rebind` action so we can \"rebind\" the bindings\nthat were previously \"unbound\" via `unbind`.\n\nThis is an improved version of the previous example that allows us to switch\nbetween Ripgrep launcher mode and fzf-only filtering mode via CTRL-R and\nCTRL-F.\n\n```sh\n#!/usr/bin/env bash\n\n# Switch between Ripgrep launcher mode (CTRL-R) and fzf filtering mode (CTRL-F)\nrm -f /tmp/rg-fzf-{r,f}\nRG_PREFIX=\"rg --column --line-number --no-heading --color=always --smart-case \"\nINITIAL_QUERY=\"${*:-}\"\nfzf --ansi --disabled --query \"$INITIAL_QUERY\" \\\n    --bind \"start:reload($RG_PREFIX {q})+unbind(ctrl-r)\" \\\n    --bind \"change:reload:sleep 0.1; $RG_PREFIX {q} || true\" \\\n    --bind \"ctrl-f:unbind(change,ctrl-f)+change-prompt(2. fzf> )+enable-search+rebind(ctrl-r)+transform-query(echo {q} > /tmp/rg-fzf-r; cat /tmp/rg-fzf-f)\" \\\n    --bind \"ctrl-r:unbind(ctrl-r)+change-prompt(1. ripgrep> )+disable-search+reload($RG_PREFIX {q} || true)+rebind(change,ctrl-f)+transform-query(echo {q} > /tmp/rg-fzf-f; cat /tmp/rg-fzf-r)\" \\\n    --color \"hl:-1:underline,hl+:-1:underline:reverse\" \\\n    --prompt '1. ripgrep> ' \\\n    --delimiter : \\\n    --header '╱ CTRL-R (ripgrep mode) ╱ CTRL-F (fzf mode) ╱' \\\n    --preview 'bat --color=always {1} --highlight-line {2}' \\\n    --preview-window 'up,60%,border-bottom,+{2}+3/3,~3' \\\n    --bind 'enter:become(vim {1} +{2})'\n```\n\n- To restore the query string when switching between modes, we store the\n  current query in `/tmp/rg-fzf-{r,f}` files and restore the query using\n  `transform-query` action which was added in [fzf 0.36.0][0.36.0].\n- Also note that we unbind `ctrl-r` binding on `start` event which is\n  triggered once when fzf starts.\n\n[0.30.0]: https://github.com/junegunn/fzf/blob/master/CHANGELOG.md#0300\n[0.36.0]: https://github.com/junegunn/fzf/blob/master/CHANGELOG.md#0360\n\n### Switching between Ripgrep mode and fzf mode using a single key binding\n\nIn contrast to the previous version, we use just one hotkey to toggle between\nripgrep and fzf mode. This is achieved by using the `$FZF_PROMPT` as a state\nwithin the `transform` action, a feature introduced in [fzf 0.45.0][0.45.0]. A\nmore detailed explanation of this feature can be found in a previous section -\n[Toggling with a single keybinding](#toggling-with-a-single-key-binding).\n\n[0.45.0]: https://github.com/junegunn/fzf/blob/master/CHANGELOG.md#0450\n\nWhen using the `transform` action, the placeholder (`\\{q}`) should be escaped to\nprevent immediate evaluation.\n\n```sh\n#!/usr/bin/env bash\n\n# Switch between Ripgrep mode and fzf filtering mode (CTRL-T)\nrm -f /tmp/rg-fzf-{r,f}\nRG_PREFIX=\"rg --column --line-number --no-heading --color=always --smart-case \"\nINITIAL_QUERY=\"${*:-}\"\nfzf --ansi --disabled --query \"$INITIAL_QUERY\" \\\n    --bind \"start:reload:$RG_PREFIX {q}\" \\\n    --bind \"change:reload:sleep 0.1; $RG_PREFIX {q} || true\" \\\n    --bind 'ctrl-t:transform:[[ ! $FZF_PROMPT =~ ripgrep ]] &&\n      echo \"rebind(change)+change-prompt(1. ripgrep> )+disable-search+transform-query:echo \\{q} > /tmp/rg-fzf-f; cat /tmp/rg-fzf-r\" ||\n      echo \"unbind(change)+change-prompt(2. fzf> )+enable-search+transform-query:echo \\{q} > /tmp/rg-fzf-r; cat /tmp/rg-fzf-f\"' \\\n    --color \"hl:-1:underline,hl+:-1:underline:reverse\" \\\n    --prompt '1. ripgrep> ' \\\n    --delimiter : \\\n    --header 'CTRL-T: Switch between ripgrep/fzf' \\\n    --preview 'bat --color=always {1} --highlight-line {2}' \\\n    --preview-window 'up,60%,border-bottom,+{2}+3/3,~3' \\\n    --bind 'enter:become(vim {1} +{2})'\n```\n\nLog tailing\n-----------\n\nfzf can run long-running preview commands and render partial results before\ncompletion. And when you specify `follow` flag in `--preview-window` option,\nfzf will \"`tail -f`\" the result, automatically scrolling to the bottom.\n\n```bash\n# With \"follow\", preview window will automatically scroll to the bottom.\n# \"\\033[2J\" is an ANSI escape sequence for clearing the screen.\n# When fzf reads this code it clears the previous preview contents.\nfzf --preview-window follow --preview 'for i in $(seq 100000); do\n  echo \"$i\"\n  sleep 0.01\n  (( i % 300 == 0 )) && printf \"\\033[2J\"\ndone'\n```\n\n![image](https://user-images.githubusercontent.com/700826/113473303-dd669600-94a3-11eb-88a9-1f61b996bb0e.png)\n\nAdmittedly, that was a silly example. Here's a practical one for browsing\nKubernetes pods.\n\n```bash\npods() {\n  command='kubectl get pods --all-namespaces' fzf \\\n    --info=inline --layout=reverse --header-lines=1 \\\n    --prompt \"$(kubectl config current-context | sed 's/-context$//')> \" \\\n    --header $'╱ Enter (kubectl exec) ╱ CTRL-O (open log in editor) ╱ CTRL-R (reload) ╱\\n\\n' \\\n    --bind 'start:reload:$command' \\\n    --bind 'ctrl-r:reload:$command' \\\n    --bind 'ctrl-/:change-preview-window(80%,border-bottom|hidden|)' \\\n    --bind 'enter:execute:kubectl exec -it --namespace {1} {2} -- bash' \\\n    --bind 'ctrl-o:execute:${EDITOR:-vim} <(kubectl logs --all-containers --namespace {1} {2})' \\\n    --preview-window up:follow \\\n    --preview 'kubectl logs --follow --all-containers --tail=10000 --namespace {1} {2}' \"$@\"\n}\n```\n\n![image](https://user-images.githubusercontent.com/700826/113473547-1d7a4880-94a5-11eb-98ef-9aa6f0ed215a.png)\n\n- The preview window will *\"log tail\"* the pod\n    - Holding on to a large amount of log will consume a lot of memory. So we\n      limited the initial log amount with `--tail=10000`.\n- `execute` bindings allow you to run any command without leaving fzf\n    - Press enter key on a pod to `kubectl exec` into it\n    - Press CTRL-O to open the log in your editor\n- Press CTRL-R to reload the pod list\n- Press CTRL-/ repeatedly to rotate through a different sets of preview\n  window options\n    1. `80%,border-bottom`\n    1. `hidden`\n    1. Empty string after `|` translates to the default options from `--preview-window`\n\nKey bindings for git objects\n----------------------------\n\nOftentimes, you want to put the identifiers of various Git object to the\ncommand-line. For example, it is common to write commands like these:\n\n```sh\ngit checkout [SOME_COMMIT_HASH or BRANCH or TAG]\ngit diff [SOME_COMMIT_HASH or BRANCH or TAG] [SOME_COMMIT_HASH or BRANCH or TAG]\n```\n\n[fzf-git.sh](https://github.com/junegunn/fzf-git.sh) project defines a set of\nfzf-based key bindings for Git objects. I strongly recommend that you check\nthem out because they are seriously useful.\n\n### Files listed in `git status`\n\n<kbd>CTRL-G</kbd><kbd>CTRL-F</kbd>\n\n![image](https://user-images.githubusercontent.com/700826/113473779-a9d93b00-94a6-11eb-87b5-f62a8d0a0efc.png)\n\n### Branches\n\n<kbd>CTRL-G</kbd><kbd>CTRL-B</kbd>\n\n![image](https://user-images.githubusercontent.com/700826/113473758-87dfb880-94a6-11eb-82f4-9218103f10bd.png)\n\n### Commit hashes\n\n<kbd>CTRL-G</kbd><kbd>CTRL-H</kbd>\n\n![image](https://user-images.githubusercontent.com/700826/113473765-91692080-94a6-11eb-8d38-ed4d41f27ac1.png)\n\nColor themes\n------------\n\nYou can customize how fzf colors the text elements with `--color` option. Here\nare a few color themes. Note that you need a terminal emulator that can\ndisplay 24-bit colors.\n\n```sh\n# junegunn/seoul256.vim (dark)\nexport FZF_DEFAULT_OPTS='--color=bg+:#3F3F3F,bg:#4B4B4B,border:#6B6B6B,spinner:#98BC99,hl:#719872,fg:#D9D9D9,header:#719872,info:#BDBB72,pointer:#E12672,marker:#E17899,fg+:#D9D9D9,preview-bg:#3F3F3F,prompt:#98BEDE,hl+:#98BC99'\n```\n\n![seoul256](https://user-images.githubusercontent.com/700826/113475011-2c192d80-94ae-11eb-9d17-1e5867bae01f.png)\n\n```sh\n# junegunn/seoul256.vim (light)\nexport FZF_DEFAULT_OPTS='--color=bg+:#D9D9D9,bg:#E1E1E1,border:#C8C8C8,spinner:#719899,hl:#719872,fg:#616161,header:#719872,info:#727100,pointer:#E12672,marker:#E17899,fg+:#616161,preview-bg:#D9D9D9,prompt:#0099BD,hl+:#719899'\n```\n\n![seoul256-light](https://user-images.githubusercontent.com/700826/113475022-389d8600-94ae-11eb-905f-0939dd535837.png)\n\n```sh\n# morhetz/gruvbox\nexport FZF_DEFAULT_OPTS='--color=bg+:#3c3836,bg:#32302f,spinner:#fb4934,hl:#928374,fg:#ebdbb2,header:#928374,info:#8ec07c,pointer:#fb4934,marker:#fb4934,fg+:#ebdbb2,prompt:#fb4934,hl+:#fb4934'\n```\n\n![gruvbox](https://user-images.githubusercontent.com/700826/113475042-494dfc00-94ae-11eb-9322-cd03a027305a.png)\n\n```sh\n# arcticicestudio/nord-vim\nexport FZF_DEFAULT_OPTS='--color=bg+:#3B4252,bg:#2E3440,spinner:#81A1C1,hl:#616E88,fg:#D8DEE9,header:#616E88,info:#81A1C1,pointer:#81A1C1,marker:#81A1C1,fg+:#D8DEE9,prompt:#81A1C1,hl+:#81A1C1'\n```\n\n![nord](https://user-images.githubusercontent.com/700826/113475063-67b3f780-94ae-11eb-9b24-5f0d22b63399.png)\n\n```sh\n# tomasr/molokai\nexport FZF_DEFAULT_OPTS='--color=bg+:#293739,bg:#1B1D1E,border:#808080,spinner:#E6DB74,hl:#7E8E91,fg:#F8F8F2,header:#7E8E91,info:#A6E22E,pointer:#A6E22E,marker:#F92672,fg+:#F8F8F2,prompt:#F92672,hl+:#F92672'\n```\n\n![molokai](https://user-images.githubusercontent.com/700826/113475085-8619f300-94ae-11eb-85e4-2766fc3246bf.png)\n\n### fzf Theme Playground\n\n[fzf Theme Playground](https://vitormv.github.io/fzf-themes/) created by\n[Vitor Mello](https://github.com/vitormv) is a webpage where you can\ninteractively create fzf themes.\n\n### Generating fzf color theme from Vim color schemes\n\nThe Vim plugin of fzf can generate `--color` option from the current color\nscheme according to `g:fzf_colors` variable. You can find the detailed\nexplanation [here](https://github.com/junegunn/fzf/blob/master/README-VIM.md#explanation-of-gfzf_colors).\n\nHere is an example. Add this to your Vim configuration file.\n\n```vim\nlet g:fzf_colors =\n\\ { 'fg':         ['fg', 'Normal'],\n  \\ 'bg':         ['bg', 'Normal'],\n  \\ 'preview-bg': ['bg', 'NormalFloat'],\n  \\ 'hl':         ['fg', 'Comment'],\n  \\ 'fg+':        ['fg', 'CursorLine', 'CursorColumn', 'Normal'],\n  \\ 'bg+':        ['bg', 'CursorLine', 'CursorColumn'],\n  \\ 'hl+':        ['fg', 'Statement'],\n  \\ 'info':       ['fg', 'PreProc'],\n  \\ 'border':     ['fg', 'Ignore'],\n  \\ 'prompt':     ['fg', 'Conditional'],\n  \\ 'pointer':    ['fg', 'Exception'],\n  \\ 'marker':     ['fg', 'Keyword'],\n  \\ 'spinner':    ['fg', 'Label'],\n  \\ 'header':     ['fg', 'Comment'] }\n```\n\nThen you can see how the `--color` option is generated by printing the result\nof `fzf#wrap()`.\n\n```vim\n:echo fzf#wrap()\n```\n\nUse this command to append `export FZF_DEFAULT_OPTS=\"...\"` line to the end of\nthe current file.\n\n```vim\n:call append('$', printf('export FZF_DEFAULT_OPTS=\"%s\"', matchstr(fzf#wrap().options, \"--color[^']*\")))\n```\n"
        },
        {
          "name": "BUILD.md",
          "type": "blob",
          "size": 1.68,
          "content": "Building fzf\n============\n\nBuild instructions\n------------------\n\n### Prerequisites\n\n- Go 1.20 or above\n\n### Using Makefile\n\n```sh\n# Build fzf binary for your platform in target\nmake\n\n# Build fzf binary and copy it to bin directory\nmake install\n\n# Build fzf binaries and archives for all platforms using goreleaser\nmake build\n\n# Publish GitHub release\nmake release\n```\n\n> [!WARNING]\n> Makefile uses git commands to determine the version and the revision\n> information for `fzf --version`. So if you're building fzf from an\n> environment where its git information is not available, you have to manually\n> set `$FZF_VERSION` and `$FZF_REVISION`.\n>\n> e.g. `FZF_VERSION=0.24.0 FZF_REVISION=tarball make`\n\n> [!TIP]\n> To build fzf with profiling options enabled, set `TAGS=pprof`\n>\n> ```sh\n> TAGS=pprof make clean install\n> fzf --profile-cpu /tmp/cpu.pprof --profile-mem /tmp/mem.pprof \\\n>     --profile-block /tmp/block.pprof --profile-mutex /tmp/mutex.pprof\n> ```\n\nThird-party libraries used\n--------------------------\n\n- [rivo/uniseg](https://github.com/rivo/uniseg)\n    - Licensed under [MIT](https://raw.githubusercontent.com/rivo/uniseg/master/LICENSE.txt)\n- [mattn/go-shellwords](https://github.com/mattn/go-shellwords)\n    - Licensed under [MIT](http://mattn.mit-license.org)\n- [mattn/go-isatty](https://github.com/mattn/go-isatty)\n    - Licensed under [MIT](http://mattn.mit-license.org)\n- [tcell](https://github.com/gdamore/tcell)\n    - Licensed under [Apache License 2.0](https://github.com/gdamore/tcell/blob/master/LICENSE)\n- [fastwalk](https://github.com/charlievieth/fastwalk)\n    - Licensed under [MIT](https://raw.githubusercontent.com/charlievieth/fastwalk/master/LICENSE)\n\nLicense\n-------\n\n[MIT](LICENSE)\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 90.07,
          "content": "CHANGELOG\n=========\n\n0.58.0\n------\n\nThis version introduces three new border types, `--list-border`, `--input-border`, and `--header-border`, offering much greater flexibility for customizing the user interface.\n\nAlso, fzf now offers three \"style presets\" for easier customization, which can be activated using the `--style=[default|minimal|full]` option.\n\n- Style presets (#4160)\n    - `--style=full`\n    - `--style=default`\n    - `--style=minimal`\n- Border and label for the list section (#4148)\n    - Options\n        - `--list-border[=STYLE]`\n        - `--list-label=LABEL`\n        - `--list-label-pos=COL[:bottom]`\n    - Colors\n        - `list-fg`\n        - `list-bg`\n        - `list-border`\n        - `list-label`\n    - Actions\n        - `change-list-label`\n        - `transform-list-label`\n- Border and label for the input section (prompt line and info line) (#4154)\n    - Options\n        - `--input-border[=STYLE]`\n        - `--input-label=LABEL`\n        - `--input-label-pos=COL[:bottom]`\n    - Colors\n        - `input-fg` (`query`)\n        - `input-bg`\n        - `input-border`\n        - `input-label`\n    - Actions\n        - `change-input-label`\n        - `transform-input-label`\n- Border and label for the header section (#4159)\n    - Options\n        - `--header-border[=STYLE]`\n        - `--header-label=LABEL`\n        - `--header-label-pos=COL[:bottom]`\n    - Colors\n        - `header-fg` (`header`)\n        - `header-bg`\n        - `header-border`\n        - `header-label`\n    - Actions\n        - `change-header-label`\n        - `transform-header-label`\n- Added `--preview-border[=STYLE]` as short for `--preview-window=border[-STYLE]`\n- Added new preview border style `line` which draws a single separator line between the preview window and the rest of the interface\n- You can specify `border-native` to `--tmux` so that native tmux border is used instead of `--border`. This can be useful if you start a different program from inside the popup.\n  ```sh\n  fzf --tmux border-native --bind 'enter:execute:less {}'\n  ```\n- Added `toggle-multi-line` action\n- Added `toggle-hscroll` action\n\n0.57.0\n------\n- You can now resize the preview window by dragging the border\n- Built-in walker improvements\n    - `--walker-root` can take multiple directory arguments. e.g. `--walker-root include src lib`\n    - `--walker-skip` can handle multi-component patterns. e.g. `--walker-skip target/build`\n- Removed long processing delay when displaying images in the preview window\n- `FZF_PREVIEW_*` environment variables are exported to all child processes (#4098)\n- Bug fixes in fish scripts\n\n0.56.3\n------\n- Bug fixes in zsh scripts\n    - fix(zsh): handle backtick trigger edge case (#4090)\n    - revert(zsh): remove 'fc -RI' call in the history widget (#4093)\n    - Thanks to @LangLangBart for the contributions\n\n0.56.2\n------\n- Bug fixes\n    - Fixed abnormal scrolling behavior when `--wrap` is set (#4083)\n    - [zsh] Fixed warning message when `ksh_arrays` is set (#4084)\n\n0.56.1\n------\n- Bug fixes and improvements\n    - Fixed a race condition which would cause fzf to present stale results after `reload` (#4070)\n    - `page-up` and `page-down` actions now work correctly with multi-line items (#4069)\n    - `{n}` is allowed in `SCROLL` expression in `--preview-window` (#4079)\n    - [zsh] Fixed regression in history loading with shared option (#4071)\n    - [zsh] Better command extraction in zsh completion (#4082)\n- Thanks to @LangLangBart, @jaydee-coder, @alex-huff, and @vejkse for the contributions\n\n0.56.0\n------\n- Added `--gap[=N]` option to display empty lines between items.\n    - This can be useful to visually separate adjacent multi-line items.\n      ```sh\n      # All bash functions, highlighted\n      declare -f | perl -0777 -pe 's/^}\\n/}\\0/gm' |\n        bat --plain --language bash --color always |\n        fzf --read0 --ansi --reverse --multi --highlight-line --gap\n      ```\n    - Or just to make the list easier to read. For single-line items, you probably want to set `--color gutter:-1` as well to hide the gutter.\n      ```sh\n      fzf --info inline-right --gap --color gutter:-1\n      ```\n- Added `noinfo` option to `--preview-window` to hide the scroll indicator in the preview window\n- Bug fixes\n    - Thanks to @LangLangBart, @akinomyoga, and @charlievieth for fixing the bugs\n\n0.55.0\n------\n_Release highlights: https://junegunn.github.io/fzf/releases/0.55.0/_\n\n- Added `exact-boundary-match` type to the search syntax. When a search term is single-quoted, fzf will search for the exact occurrences of the string with both ends at word boundaries.\n  ```sh\n  fzf --query \"'here'\" << EOF\n  come here\n  not there\n  EOF\n  ```\n- [bash] Fuzzy path completion is enabled for all commands\n    - 1. If the default completion is not already set\n    - 2. And if the current bash supports `complete -D` option\n    - However, fuzzy completion for some commands can be \"dynamically\" disabled by the dynamic completion loader\n    - See the comment in `__fzf_default_completion` function for more information\n- Comments are now allowed in `$FZF_DEFAULT_OPTS` and `$FZF_DEFAULT_OPTS_FILE`\n  ```sh\n  export FZF_DEFAULT_OPTS='\n    # Layout options\n    --layout=reverse\n    --info=inline-right   # Show info on the right side of the prompt line\n    # ...\n  '\n  ```\n- Hyperlinks (OSC 8) are now supported in the preview window and in the main window\n  ```sh\n  printf '<< \\e]8;;http://github.com/junegunn/fzf\\e\\\\Link to \\e[32mfz\\e[0mf\\e]8;;\\e\\\\ >>' | fzf --ansi\n\n  fzf --preview \"printf '<< \\e]8;;http://github.com/junegunn/fzf\\e\\\\Link to \\e[32mfz\\e[0mf\\e]8;;\\e\\\\ >>'\"\n  ```\n- The default `--ellipsis` is now `··` instead of `..`.\n- [vim] A spec can have `exit` callback that is called with the exit status of fzf\n    - This can be used to clean up temporary resources or restore the original state when fzf is closed without a selection\n- Fixed `--tmux bottom` when the status line is not at the bottom\n- Fixed extra scroll offset in multi-line mode (`--read0` or `--wrap`)\n- Added fallback `ps` command for `kill` completion on Cygwin\n\n0.54.3\n------\n- Fixed incompatibility of adaptive height specification and 'start:reload'\n  ```sh\n  # A regression in 0.54.0 would cause this to fail\n  fzf --height '~100%' --bind 'start:reload:seq 10'\n  ```\n- Environment variables are now available to `$FZF_DEFAULT_COMMAND`\n  ```sh\n  FZF_DEFAULT_COMMAND='echo $FZF_QUERY' fzf --query foo\n  ```\n\n0.54.2\n------\n- Fixed incorrect syntax highlighting of truncated multi-line entries\n- Updated GoReleaser to 2.1.0 to simplify notarization of macOS binaries\n    - macOS archives will be in `tar.gz` format instead of `zip` format since we no longer notarize the zip files but binaries\n- (Windows) Reverted a mintty fix in 0.54.0\n    - As a result, mouse may not work on mintty in fullscreen mode. However, fzf will correctly read non-ASCII input in fullscreen mode (`--no-height`).\n    - fzf unfortunately cannot read non-ASCII input when not in fullscreen mode on Windows. So if you need to input non-ASCII characters, add `--no-height` to your `$FZF_DEFAULT_OPTS`.\n    - Any help in fixing this issue will be appreciated (#3799, #3847).\n\n0.54.1\n------\n- Updated [fastwalk](https://github.com/charlievieth/fastwalk) dependency for built-in directory walker\n    - [fastwalk: add optional sorting and improve documentation](https://github.com/charlievieth/fastwalk/pull/27)\n    - [fastwalk: only check if MSYSTEM is set during MSYS/MSYS2](https://github.com/charlievieth/fastwalk/pull/28)\n    - Thanks to @charlievieth\n- Reverted ALT-C binding of fish to use `cd` instead of `builtin cd`\n    - `builtin cd` was introduced to work around a bug of `cd` coming from `zoxide init --cmd cd fish` where it cannot handle `--` argument.\n    - However, the default `cd` of fish is actually a wrapper function for supporting `cd -`, so we want to use it instead.\n    - See [#3928](https://github.com/junegunn/fzf/pull/3928) for more information and consider helping zoxide fix the bug.\n\n0.54.0\n------\n_Release highlights: https://junegunn.github.io/fzf/releases/0.54.0/_\n\n- Implemented line wrap of long items\n    - `--wrap` option enables line wrap\n    - `--wrap-sign` customizes the sign for wrapped lines (default: `↳ `)\n    - `toggle-wrap` action toggles line wrap\n      ```sh\n      history | fzf --tac --wrap --bind 'ctrl-/:toggle-wrap' --wrap-sign $'\\t↳ '\n      ```\n    - fzf by default binds `CTRL-/` and `ALT-/` to `toggle-wrap`\n- Updated shell integration scripts to leverage line wrap\n    - CTRL-R binding includes `--wrap-sign $'\\t↳ '` to indent wrapped lines\n    - `kill **` completion uses `--wrap` to show the whole line by default\n      instead of showing it in the preview window\n- Added `--info-command` option for customizing the info line\n  ```sh\n  # Prepend the current cursor position in yellow\n  fzf --info-command='echo -e \"\\x1b[33;1m$FZF_POS\\x1b[m/$FZF_INFO 💛\"'\n  ```\n    - `$FZF_INFO` is set to the original info text\n    - ANSI color codes are supported\n- Pointer and marker signs can be set to empty strings\n  ```sh\n  # Minimal style\n  fzf --pointer '' --marker '' --prompt '' --info hidden\n  ```\n- Better cache management and improved rendering for `--tail`\n- Improved `--sync` behavior\n    - When `--sync` is provided, fzf will not render the interface until the initial filtering and the associated actions (bound to any of `start`, `load`, `result`, or `focus`) are complete.\n      ```sh\n      # fzf will not render intermediate states\n      (sleep 1; seq 1000000; sleep 1) |\n        fzf --sync --query 5 --listen --bind start:up,load:up,result:up,focus:change-header:Ready\n      ```\n- GET endpoint is now available from `execute` and `transform` actions (it used to timeout due to lock conflict)\n  ```sh\n  fzf --listen --sync --bind 'focus:transform-header:curl -s localhost:$FZF_PORT?limit=0 | jq .'\n  ```\n- Added `offset-middle` action to place the current item is in the middle of the screen\n- fzf will not start the initial reader when `reload` or `reload-sync` is bound to `start` event. `fzf < /dev/null` or `: | fzf` are no longer required and extraneous `load` event will not fire due to the empty list.\n  ```sh\n  # Now this will work as expected. Previously, this would print an invalid header line.\n  # `fzf < /dev/null` or `: | fzf` would fix the problem, but then an extraneous \n  # `load` event would fire and the header would be prematurely updated.\n  fzf --header 'Loading ...' --header-lines 1 \\\n      --bind 'start:reload:sleep 1; ps -ef' \\\n      --bind 'load:change-header:Loaded!'\n  ```\n- Fixed mouse support on Windows\n- Fixed crash when using `--tiebreak=end` with very long items\n- zsh 5.0 compatibility (thanks to @LangLangBart)\n- Fixed `--walker-skip` to also skip symlinks to directories\n- Fixed `result` event not fired when input stream is not complete\n- New tags will have `v` prefix so that they are available on https://proxy.golang.org/\n\n0.53.0\n------\n_Release highlights: https://junegunn.github.io/fzf/releases/0.53.0/_\n\n- Multi-line display\n    - See [Processing multi-line items](https://junegunn.github.io/fzf/tips/processing-multi-line-items/)\n    - fzf can now display multi-line items\n      ```sh\n      # All bash functions, highlighted\n      declare -f | perl -0777 -pe 's/^}\\n/}\\0/gm' |\n        bat --plain --language bash --color always |\n        fzf --read0 --ansi --reverse --multi --highlight-line\n\n      # Ripgrep multi-line output\n      rg --pretty bash | perl -0777 -pe 's/\\n\\n/\\n\\0/gm' |\n        fzf --read0 --ansi --multi --highlight-line --reverse --tmux 70%\n      ```\n        - To disable multi-line display, use `--no-multi-line`\n    - CTRL-R bindings of bash, zsh, and fish have been updated to leverage multi-line display\n    - The default `--pointer` and `--marker` have been changed from `>` to Unicode bar characters as they look better with multi-line items\n    - Added `--marker-multi-line` to customize the select marker for multi-line entries with the default set to `╻┃╹`\n      ```\n      ╻First line\n      ┃...\n      ╹Last line\n      ```\n- Native tmux integration\n    - Added `--tmux` option to replace fzf-tmux script and simplify distribution\n      ```sh\n      # --tmux [center|top|bottom|left|right][,SIZE[%]][,SIZE[%]]\n      # Center, 100% width and 70% height\n      fzf --tmux 100%,70% --border horizontal --padding 1,2\n\n      # Left, 30% width\n      fzf --tmux left,30%\n\n      # Bottom, 50% height\n      fzf --tmux bottom,50%\n      ```\n        - To keep the implementation simple, it only uses popups. You need tmux 3.3 or later.\n    - To use `--tmux` in Vim plugin:\n      ```vim\n      let g:fzf_layout = { 'tmux': '100%,70%' }\n      ```\n- Added support for endless input streams\n    - See [Browsing log stream with fzf](https://junegunn.github.io/fzf/tips/browsing-log-streams/)\n    - Added `--tail=NUM` option to limit the number of items to keep in memory. This is useful when you want to browse an endless stream of data (e.g. log stream) with fzf while limiting memory usage.\n      ```sh\n      # Interactive filtering of a log stream\n      tail -f *.log | fzf --tail 100000 --tac --no-sort --exact\n      ```\n- Better Windows Support\n    - fzf now works on Git bash (mintty) out of the box via winpty integration\n    - Many fixes and improvements for Windows\n- man page is now embedded in the binary; `fzf --man` to see it\n- Changed the default `--scroll-off` to 3, as we think it's a better default\n- Process started by `execute` action now directly writes to and reads from `/dev/tty`. Manual `/dev/tty` redirection for interactive programs is no longer required.\n  ```sh\n  # Vim will work fine without /dev/tty redirection\n  ls | fzf --bind 'space:execute:vim {}' > selected\n  ```\n- Added `print(...)` action to queue an arbitrary string to be printed on exit. This was mainly added to work around the limitation of `--expect` where it's not compatible with `--bind` on the same key and it would ignore other actions bound to it.\n  ```sh\n  # This doesn't work as expected because --expect is not compatible with --bind\n  fzf --multi --expect ctrl-y --bind 'ctrl-y:select-all'\n\n  # This is something you can do instead\n  fzf --multi --bind 'enter:print()+accept,ctrl-y:select-all+print(ctrl-y)+accept'\n  ```\n    - We also considered making them compatible, but realized that some users may have been relying on the current behavior.\n- [`NO_COLOR`](https://no-color.org/) environment variable is now respected. If the variable is set, fzf defaults to `--no-color` unless otherwise specified.\n\n0.52.1\n------\n- Fixed a critical bug in the Windows version\n    - Windows users are strongly encouraged to upgrade to this version\n\n0.52.0\n------\n- Added `--highlight-line` to highlight the whole current line (à la `set cursorline` of Vim)\n- Added color names for selected lines: `selected-fg`, `selected-bg`, and `selected-hl`\n  ```sh\n  fzf --border --multi --info inline-right --layout reverse --marker ▏ --pointer ▌ --prompt '▌ '  \\\n      --highlight-line --color gutter:-1,selected-bg:238,selected-fg:146,current-fg:189\n  ```\n- Added `click-header` event that is triggered when the header section is clicked. When the event is triggered, `$FZF_CLICK_HEADER_COLUMN` and `$FZF_CLICK_HEADER_LINE` are set.\n  ```sh\n  fd --type f |\n    fzf --header $'[Files] [Directories]' --header-first \\\n        --bind 'click-header:transform:\n          (( FZF_CLICK_HEADER_COLUMN <= 7 )) && echo \"reload(fd --type f)\"\n          (( FZF_CLICK_HEADER_COLUMN >= 9 )) && echo \"reload(fd --type d)\"\n        '\n  ```\n- Add `$FZF_COMPLETION_{DIR,PATH}_OPTS` for separately customizing the behavior of fuzzy completion\n  ```sh\n  # Set --walker options without 'follow' not to follow symbolic links\n  FZF_COMPLETION_PATH_OPTS=\"--walker=file,dir,hidden\"\n  FZF_COMPLETION_DIR_OPTS=\"--walker=dir,hidden\"\n  ```\n- Fixed Windows argument escaping\n- Bug fixes and improvements\n- The code was heavily refactored to allow using fzf as a library in Go programs. The API is still experimental and subject to change.\n    - https://gist.github.com/junegunn/193990b65be48a38aac6ac49d5669170\n\n0.51.0\n------\n- Added a new environment variable `$FZF_POS` exported to the child processes. It's the vertical position of the cursor in the list starting from 1.\n  ```sh\n  # Toggle selection to the top or to the bottom\n  seq 30 | fzf --multi --bind 'load:pos(10)' \\\n    --bind 'shift-up:transform:for _ in $(seq $FZF_POS $FZF_MATCH_COUNT); do echo -n +toggle+up; done' \\\n    --bind 'shift-down:transform:for _ in $(seq 1 $FZF_POS); do echo -n +toggle+down; done'\n  ```\n- Added `--with-shell` option to start child processes with a custom shell command and flags\n  ```sh\n  gem list | fzf --with-shell 'ruby -e' \\\n    --preview 'pp Gem::Specification.find_by_name({1})' \\\n    --bind 'ctrl-o:execute-silent:\n        spec = Gem::Specification.find_by_name({1})\n        [spec.homepage, *spec.metadata.filter { _1.end_with?(\"uri\") }.values].uniq.each do\n          system \"open\", _1\n        end\n    '\n  ```\n- Added `change-multi` action for dynamically changing `--multi` option\n    - `change-multi` - enable multi-select mode with no limit\n    - `change-multi(NUM)` - enable multi-select mode with a limit\n    - `change-multi(0)` - disable multi-select mode\n- Windows improvements\n    - `become` action is now supported on Windows\n        - Unlike in *nix, this does not use `execve(2)`. Instead it spawns a new process and waits for it to finish, so the exact behavior may differ.\n    - Fixed argument escaping for Windows cmd.exe. No redundant escaping of backslashes.\n- Bug fixes and improvements\n\n0.50.0\n------\n- Search performance optimization. You can observe 50%+ improvement in some scenarios.\n  ```\n  $ rg --line-number --no-heading --smart-case . > $DATA\n\n  $ wc < $DATA\n   5520118 26862362 897487793\n\n  $ hyperfine -w 1 -L bin fzf-0.49.0,fzf-7ce6452,fzf-a5447b8,fzf '{bin} --filter \"///\" < $DATA | head -30'\n  Summary\n    fzf --filter \"///\" < $DATA | head -30 ran\n      1.16 ± 0.03 times faster than fzf-a5447b8 --filter \"///\" < $DATA | head -30\n      1.23 ± 0.03 times faster than fzf-7ce6452 --filter \"///\" < $DATA | head -30\n      1.52 ± 0.03 times faster than fzf-0.49.0 --filter \"///\" < $DATA | head -30\n  ```\n- Added `jump` and `jump-cancel` events that are triggered when leaving `jump` mode\n  ```sh\n  # Default behavior\n  fzf --bind space:jump\n\n  # Same as jump-accept action\n  fzf --bind space:jump,jump:accept\n\n  # Accept on jump, abort on cancel\n  fzf --bind space:jump,jump:accept,jump-cancel:abort\n\n  # Change header on jump-cancel\n  fzf --bind 'space:change-header(Type jump label)+jump,jump-cancel:change-header:Jump cancelled'\n  ```\n- Added a new environment variable `$FZF_KEY` exported to the child processes. It's the name of the last key pressed.\n  ```sh\n  fzf --bind 'space:jump,jump:accept,jump-cancel:transform:[[ $FZF_KEY =~ ctrl-c ]] && echo abort'\n  ```\n- fzf can be built with profiling options. See [BUILD.md](BUILD.md) for more information.\n- Bug fixes\n\n0.49.0\n------\n- Ingestion performance improved by around 40% (more or less depending on options)\n- `--info=hidden` and `--info=inline-right` will no longer hide the horizontal separator by default. This gives you more flexibility in customizing the layout.\n    ```sh\n    fzf --border --info=inline-right\n    fzf --border --info=inline-right --separator ═\n    fzf --border --info=inline-right --no-separator\n    fzf --border --info=hidden\n    fzf --border --info=hidden --separator ━\n    fzf --border --info=hidden --no-separator\n    ```\n- Added two environment variables exported to the child processes\n    - `FZF_PREVIEW_LABEL`\n    - `FZF_BORDER_LABEL`\n    ```sh\n    # Use the current value of $FZF_PREVIEW_LABEL to determine which actions to perform\n    git ls-files |\n      fzf --header 'Press CTRL-P to change preview mode' \\\n          --bind='ctrl-p:transform:[[ $FZF_PREVIEW_LABEL =~ cat ]] \\\n          && echo \"change-preview(git log --color=always \\{})+change-preview-label([[ log ]])\" \\\n          || echo \"change-preview(bat --color=always \\{})+change-preview-label([[ cat ]])\"'\n    ```\n- Renamed `track` action to `track-current` to highlight the difference between the global tracking state set by `--track` and a one-off tracking action\n    - `track` is still available as an alias\n- Added `untrack-current` and `toggle-track-current` actions\n    - `*-current` actions are no-op when the global tracking state is set\n- Bug fixes and minor improvements\n\n0.48.1\n------\n- CTRL-T and ALT-C bindings can be disabled by setting `FZF_CTRL_T_COMMAND` and `FZF_ALT_C_COMMAND` to empty strings respectively when sourcing the script\n    ```sh\n    # bash\n    FZF_CTRL_T_COMMAND= FZF_ALT_C_COMMAND= eval \"$(fzf --bash)\"\n\n    # zsh\n    FZF_CTRL_T_COMMAND= FZF_ALT_C_COMMAND= eval \"$(fzf --zsh)\"\n\n    # fish\n    fzf --fish | FZF_CTRL_T_COMMAND= FZF_ALT_C_COMMAND= source\n    ```\n    - Setting the variables after sourcing the script will have no effect\n- Bug fixes\n\n0.48.0\n------\n- Shell integration scripts are now embedded in the fzf binary. This simplifies the distribution, and the users are less likely to have problems caused by using incompatible scripts and binaries.\n    - bash\n      ```sh\n      # Set up fzf key bindings and fuzzy completion\n      eval \"$(fzf --bash)\"\n      ```\n    - zsh\n      ```sh\n      # Set up fzf key bindings and fuzzy completion\n      eval \"$(fzf --zsh)\"\n      ```\n    - fish\n      ```fish\n      # Set up fzf key bindings\n      fzf --fish | source\n      ```\n- Added options for customizing the behavior of the built-in walker\n    | Option               | Description                                       | Default              |\n    | ---                  | ---                                               | ---                  |\n    | `--walker=OPTS`      | Walker options (`[file][,dir][,follow][,hidden]`) | `file,follow,hidden` |\n    | `--walker-root=DIR`  | Root directory from which to start walker         | `.`                  |\n    | `--walker-skip=DIRS` | Comma-separated list of directory names to skip   | `.git,node_modules`  |\n    - Examples\n        ```sh\n        # Built-in walker is only used by standalone fzf when $FZF_DEFAULT_COMMAND is not set\n        unset FZF_DEFAULT_COMMAND\n\n        fzf # default: --walker=file,follow,hidden --walker-root=. --walker-skip=.git,node_modules\n        fzf --walker=file,dir,hidden,follow --walker-skip=.git,node_modules,target\n\n        # Walker options in $FZF_DEFAULT_OPTS\n        export FZF_DEFAULT_OPTS=\"--walker=file,dir,hidden,follow --walker-skip=.git,node_modules,target\"\n        fzf\n\n        # Reading from STDIN; --walker is ignored\n        seq 100 | fzf --walker=dir\n\n        # Reading from $FZF_DEFAULT_COMMAND; --walker is ignored\n        export FZF_DEFAULT_COMMAND='seq 100'\n        fzf --walker=dir\n        ```\n- Shell integration scripts have been updated to use the built-in walker with these new options and they are now much faster out of the box.\n\n0.47.0\n------\n- Replaced [\"the default find command\"][find] with a built-in directory walker to simplify the code and to achieve better performance and consistent behavior across platforms.\n  This doesn't affect you if you have `$FZF_DEFAULT_COMMAND` set.\n    - Breaking changes:\n        - Unlike [the previous \"find\" command][find], the new traversal code will list hidden files, but hidden directories will still be ignored\n        - No filtering of `devtmpfs` or `proc` types\n        - Traversal is parallelized, so the order of the entries will be different each time\n    - You may wonder why fzf implements directory walker anyway when it's a filter program following the [Unix philosophy][unix].\n      But fzf has had [the walker code for years][walker] to tackle the performance problem on Windows. And I decided to use the same approach on different platforms as well for the benefits listed above.\n    - Built-in walker is using the excellent [charlievieth/fastwalk][fastwalk] library, which easily outperforms its competitors and supports safely following symlinks.\n- Added `$FZF_DEFAULT_OPTS_FILE` to allow managing default options in a file\n    - See [#3618](https://github.com/junegunn/fzf/pull/3618)\n    - Option precedence from lower to higher\n        1. Options read from `$FZF_DEFAULT_OPTS_FILE`\n        1. Options from `$FZF_DEFAULT_OPTS`\n        1. Options from command-line arguments\n- Bug fixes and improvements\n\n[find]: https://github.com/junegunn/fzf/blob/0.46.1/src/constants.go#L60-L64\n[walker]: https://github.com/junegunn/fzf/pull/1847\n[fastwalk]: https://github.com/charlievieth/fastwalk\n[unix]: https://en.wikipedia.org/wiki/Unix_philosophy\n\n0.46.1\n------\n- Bug fixes and improvements\n- Fixed Windows binaries\n- Downgraded Go version to 1.20 to support older versions of Windows\n    - https://tip.golang.org/doc/go1.21#windows\n- Updated [rivo/uniseg](https://github.com/rivo/uniseg) dependency to v0.4.6\n\n0.46.0\n------\n- Added two new events\n    - `result` - triggered when the filtering for the current query is complete and the result list is ready\n    - `resize` - triggered when the terminal size is changed\n- fzf now exports the following environment variables to the child processes\n  | Variable           | Description                                                 |\n  | ---                | ---                                                         |\n  | `FZF_LINES`        | Number of lines fzf takes up excluding padding and margin   |\n  | `FZF_COLUMNS`      | Number of columns fzf takes up excluding padding and margin |\n  | `FZF_TOTAL_COUNT`  | Total number of items                                       |\n  | `FZF_MATCH_COUNT`  | Number of matched items                                     |\n  | `FZF_SELECT_COUNT` | Number of selected items                                    |\n  | `FZF_QUERY`        | Current query string                                        |\n  | `FZF_PROMPT`       | Prompt string                                               |\n  | `FZF_ACTION`       | The name of the last action performed                       |\n  - This allows you to write sophisticated transformations like so\n    ```sh\n    # Script to dynamically resize the preview window\n    transformer='\n      # 1 line for info, another for prompt, and 2 more lines for preview window border\n      lines=$(( FZF_LINES - FZF_MATCH_COUNT - 4 ))\n      if [[ $FZF_MATCH_COUNT -eq 0 ]]; then\n        echo \"change-preview-window:hidden\"\n      elif [[ $lines -gt 3 ]]; then\n        echo \"change-preview-window:$lines\"\n      elif [[ $FZF_PREVIEW_LINES -ne 3 ]]; then\n        echo \"change-preview-window:3\"\n      fi\n    '\n    seq 10000 | fzf --preview 'seq {} 10000' --preview-window up \\\n                    --bind \"result:transform:$transformer\" \\\n                    --bind \"resize:transform:$transformer\"\n    ```\n  - And we're phasing out `{fzf:prompt}` and `{fzf:action}`\n- Changed [mattn/go-runewidth](https://github.com/mattn/go-runewidth) dependency to [rivo/uniseg](https://github.com/rivo/uniseg) for accurate results\n    - Set `--ambidouble` if your terminal displays ambiguous width characters (e.g. box-drawing characters for borders) as 2 columns\n    - `RUNEWIDTH_EASTASIAN=1` is still respected for backward compatibility, but it's recommended that you use this new option instead\n- Bug fixes\n\n0.45.0\n------\n- Added `transform` action to conditionally perform a series of actions\n  ```sh\n  # Disallow selecting an empty line\n  echo -e \"1. Hello\\n2. Goodbye\\n\\n3. Exit\" |\n    fzf --height '~100%' --reverse --header 'Select one' \\\n        --bind 'enter:transform:[[ -n {} ]] && echo accept || echo \"change-header:Invalid selection\"'\n\n  # Move cursor past the empty line\n  echo -e \"1. Hello\\n2. Goodbye\\n\\n3. Exit\" |\n    fzf --height '~100%' --reverse --header 'Select one' \\\n        --bind 'enter:transform:[[ -n {} ]] && echo accept || echo \"change-header:Invalid selection\"' \\\n        --bind 'focus:transform:[[ -n {} ]] && exit; [[ {fzf:action} =~ up$ ]] && echo up || echo down'\n\n  # A single key binding to toggle between modes\n  fd --type file |\n    fzf --prompt 'Files> ' \\\n        --header 'CTRL-T: Switch between Files/Directories' \\\n        --bind 'ctrl-t:transform:[[ ! {fzf:prompt} =~ Files ]] &&\n                  echo \"change-prompt(Files> )+reload(fd --type file)\" ||\n                  echo \"change-prompt(Directories> )+reload(fd --type directory)\"'\n  ```\n- Added placeholder expressions\n    - `{fzf:action}` - The name of the last action performed\n    - `{fzf:prompt}` - Prompt string (including ANSI color codes)\n    - `{fzf:query}` - Synonym for `{q}`\n- Added support for negative height\n  ```sh\n  # Terminal height minus 1, so you can still see the command line\n  fzf --height=-1\n  ```\n  - This handles a terminal resize better than `--height=$(($(tput lines) - 1))`\n- Added `accept-or-print-query` action that acts like `accept` but prints the\n  current query when there's no match for the query\n  ```sh\n  # You can make CTRL-R paste the current query when there's no match\n  export FZF_CTRL_R_OPTS='--bind enter:accept-or-print-query'\n  ```\n  - Note that there are alternative ways to implement the same strategy\n    ```sh\n    # 'become' is apparently more versatile but it's not available on Windows.\n    export FZF_CTRL_R_OPTS='--bind \"enter:become:if [ -z {} ]; then echo {q}; else echo {}; fi\"'\n\n    # Using the new 'transform' action\n    export FZF_CTRL_R_OPTS='--bind \"enter:transform:[ -z {} ] && echo print-query || echo accept\"'\n    ```\n- Added `show-header` and `hide-header` actions\n- Bug fixes\n\n0.44.1\n------\n- Fixed crash when preview window is hidden on `focus` event\n\n0.44.0\n------\n- (Experimental) Sixel image support in preview window (not available on Windows)\n    - [bin/fzf-preview.sh](bin/fzf-preview.sh) is added to demonstrate how to\n      display an image using Kitty image protocol or Sixel. You can use it\n      like so:\n      ```sh\n      fzf --preview='fzf-preview.sh {}'\n      ```\n- (Experimental) iTerm2 inline image protocol support in preview window (not available on Windows)\n  ```sh\n  # Using https://iterm2.com/utilities/imgcat\n  fzf --preview 'imgcat -W $FZF_PREVIEW_COLUMNS -H $FZF_PREVIEW_LINES {}'\n  ```\n- HTTP server can be configured to accept remote connections\n  ```sh\n  # FZF_API_KEY is required for a non-localhost listen address\n  export FZF_API_KEY=\"$(head -c 32 /dev/urandom | base64)\"\n  fzf --listen 0.0.0.0:6266\n  ```\n    - To allow remote process execution, use `--listen-unsafe` instead\n      (`execute*`, `reload*`, `become`, `preview`, `change-preview`, `transform-*`)\n      ```sh\n      fzf --listen-unsafe 0.0.0.0:6266\n      ```\n- Bug fixes\n\n0.43.0\n------\n- (Experimental) Added support for Kitty image protocol in the preview window\n  (not available on Windows)\n  ```sh\n  fzf --preview='\n    if file --mime-type {} | grep -qF image/; then\n      # --transfer-mode=memory is the fastest option but if you want fzf to be able\n      # to redraw the image on terminal resize or on 'change-preview-window',\n      # you need to use --transfer-mode=stream.\n      kitty icat --clear --transfer-mode=memory --unicode-placeholder --stdin=no --place=${FZF_PREVIEW_COLUMNS}x${FZF_PREVIEW_LINES}@0x0 {} | sed \\$d\n    else\n      bat --color=always {}\n    fi\n  '\n  ```\n- (Experimental) `--listen` server can report program state in JSON format (`GET /`)\n  ```sh\n  # fzf server started in \"headless\" mode\n  fzf --listen 6266 2> /dev/null\n\n  # Get program state\n  curl localhost:6266 | jq .\n\n  # Increase the number of items returned (default: 100)\n  curl localhost:6266?limit=1000 | jq .\n  ```\n- `--listen` server can be secured by setting `$FZF_API_KEY` environment\n  variable.\n  ```sh\n  export FZF_API_KEY=\"$(head -c 32 /dev/urandom | base64)\"\n\n  # Server\n  fzf --listen 6266\n\n  # Client\n  curl localhost:6266 -H \"x-api-key: $FZF_API_KEY\" -d 'change-query(yo)'\n  ```\n- Added `toggle-header` action\n- Added mouse events for `--bind`\n    - `scroll-up` (bound to `up`)\n    - `scroll-down` (bound to `down`)\n    - `shift-scroll-up` (bound to `toggle+up`)\n    - `shift-scroll-down` (bound to `toggle+down`)\n    - `shift-left-click` (bound to `toggle`)\n    - `shift-right-click` (bound to `toggle`)\n    - `preview-scroll-up` (bound to `preview-up`)\n    - `preview-scroll-down` (bound to `preview-down`)\n    ```sh\n    # Twice faster scrolling both in the main window and the preview window\n    fzf --bind 'scroll-up:up+up,scroll-down:down+down' \\\n        --bind 'preview-scroll-up:preview-up+preview-up' \\\n        --bind 'preview-scroll-down:preview-down+preview-down' \\\n        --preview 'cat {}'\n    ```\n- Added `offset-up` and `offset-down` actions\n  ```sh\n  # Scrolling will behave similarly to CTRL-E and CTRL-Y of vim\n  fzf --bind scroll-up:offset-up,scroll-down:offset-down \\\n      --bind ctrl-y:offset-up,ctrl-e:offset-down \\\n      --scroll-off=5\n  ```\n- Shell extensions\n    - Updated bash completion for fzf options\n    - bash key bindings no longer requires perl; it will use awk or mawk\n      instead if perl is not found\n    - Basic context-aware completion for ssh command\n    - Applied `--scheme=path` for better ordering of the result\n- Bug fixes and improvements\n\n0.42.0\n------\n- Added new info style: `--info=right`\n- Added new info style: `--info=inline-right`\n- Added new border style `thinblock` which uses symbols for legacy computing\n  [one eighth block elements](https://en.wikipedia.org/wiki/Symbols_for_Legacy_Computing)\n    - Similarly to `block`, this style is suitable when using a different\n      background color because the window is completely contained within the border.\n      ```sh\n      BAT_THEME=GitHub fzf --info=right --border=thinblock --preview-window=border-thinblock \\\n          --margin=3 --scrollbar=▏▕ --preview='bat --color=always --style=numbers {}' \\\n          --color=light,query:238,fg:238,bg:251,bg+:249,gutter:251,border:248,preview-bg:253\n      ```\n    - This style may not render correctly depending on the font and the\n      terminal emulator.\n\n0.41.1\n------\n- Fixed a bug where preview window is not updated when `--disabled` is set and\n  a reload is triggered by `change:reload` binding\n\n0.41.0\n------\n- Added color name `preview-border` and `preview-scrollbar`\n- Added new border style `block` which uses [block elements](https://en.wikipedia.org/wiki/Block_Elements)\n- `--scrollbar` can take two characters, one for the main window, the other\n  for the preview window\n- Putting it altogether:\n  ```sh\n  fzf-tmux -p 80% --padding 1,2 --preview 'bat --style=plain --color=always {}' \\\n      --color 'bg:237,bg+:235,gutter:237,border:238,scrollbar:236' \\\n      --color 'preview-bg:235,preview-border:236,preview-scrollbar:234' \\\n      --preview-window 'border-block' --border block --scrollbar '▌▐'\n  ```\n- Bug fixes and improvements\n\n0.40.0\n------\n- Added `zero` event that is triggered when there's no match\n  ```sh\n  # Reload the candidate list when there's no match\n  echo $RANDOM | fzf --bind 'zero:reload(echo $RANDOM)+clear-query' --height 3\n  ```\n- New actions\n    - Added `track` action which makes fzf track the current item when the\n      search result is updated. If the user manually moves the cursor, or the\n      item is not in the updated search result, tracking is automatically\n      disabled. Tracking is useful when you want to see the surrounding items\n      by deleting the query string.\n      ```sh\n      # Narrow down the list with a query, point to a command,\n      # and hit CTRL-T to see its surrounding commands.\n      export FZF_CTRL_R_OPTS=\"\n        --preview 'echo {}' --preview-window up:3:hidden:wrap\n        --bind 'ctrl-/:toggle-preview'\n        --bind 'ctrl-t:track+clear-query'\n        --bind 'ctrl-y:execute-silent(echo -n {2..} | pbcopy)+abort'\n        --color header:italic\n        --header 'Press CTRL-Y to copy command into clipboard'\"\n      ```\n    - Added `change-header(...)`\n    - Added `transform-header(...)`\n    - Added `toggle-track` action\n- Fixed `--track` behavior when used with `--tac`\n    - However, using `--track` with `--tac` is not recommended. The resulting\n      behavior can be very confusing.\n- Bug fixes and improvements\n\n0.39.0\n------\n- Added `one` event that is triggered when there's only one match\n  ```sh\n  # Automatically select the only match\n  seq 10 | fzf --bind one:accept\n  ```\n- Added `--track` option that makes fzf track the current selection when the\n  result list is updated. This can be useful when browsing logs using fzf with\n  sorting disabled.\n  ```sh\n  git log --oneline --graph --color=always | nl |\n      fzf --ansi --track --no-sort --layout=reverse-list\n  ```\n- If you use `--listen` option without a port number fzf will automatically\n  allocate an available port and export it as `$FZF_PORT` environment\n  variable.\n  ```sh\n  # Automatic port assignment\n  fzf --listen --bind 'start:execute-silent:echo $FZF_PORT > /tmp/fzf-port'\n\n  # Say hello\n  curl \"localhost:$(cat /tmp/fzf-port)\" -d 'preview:echo Hello, fzf is listening on $FZF_PORT.'\n  ```\n- A carriage return and a line feed character will be rendered as dim ␍ and\n  ␊ respectively.\n  ```sh\n  printf \"foo\\rbar\\nbaz\" | fzf --read0 --preview 'echo {}'\n  ```\n- fzf will stop rendering a non-displayable characters as a space. This will\n  likely cause less glitches in the preview window.\n  ```sh\n  fzf --preview 'head -1000 /dev/random'\n  ```\n- Bug fixes and improvements\n\n0.38.0\n------\n- New actions\n    - `become(...)` - Replace the current fzf process with the specified\n      command using `execve(2)` system call.\n      See https://github.com/junegunn/fzf#turning-into-a-different-process for\n      more information.\n      ```sh\n      # Open selected files in Vim\n      fzf --multi --bind 'enter:become(vim {+})'\n\n      # Open the file in Vim and go to the line\n      git grep --line-number . |\n          fzf --delimiter : --nth 3.. --bind 'enter:become(vim {1} +{2})'\n      ```\n        - This action is not supported on Windows\n    - `show-preview`\n    - `hide-preview`\n- Bug fixes\n    - `--preview-window 0,hidden` should not execute the preview command until\n      `toggle-preview` action is triggered\n\n0.37.0\n------\n- Added a way to customize the separator of inline info\n  ```sh\n  fzf --info 'inline: ╱ ' --prompt '╱ ' --color prompt:bright-yellow\n  ```\n- New event\n    - `focus` - Triggered when the focus changes due to a vertical cursor\n      movement or a search result update\n      ```sh\n      fzf --bind 'focus:transform-preview-label:echo [ {} ]' --preview 'cat {}'\n\n      # Any action bound to the event runs synchronously and thus can make the interface sluggish\n      # e.g. lolcat isn't one of the fastest programs, and every cursor movement in\n      #      fzf will be noticeably affected by its execution time\n      fzf --bind 'focus:transform-preview-label:echo [ {} ] | lolcat -f' --preview 'cat {}'\n\n      # Beware not to introduce an infinite loop\n      seq 10 | fzf --bind 'focus:up' --cycle\n      ```\n- New actions\n    - `change-border-label`\n    - `change-preview-label`\n    - `transform-border-label`\n    - `transform-preview-label`\n- Bug fixes and improvements\n\n0.36.0\n------\n- Added `--listen=HTTP_PORT` option to start HTTP server. It allows external\n  processes to send actions to perform via POST method.\n  ```sh\n  # Start HTTP server on port 6266\n  fzf --listen 6266\n\n  # Send actions to the server\n  curl -XPOST localhost:6266 -d 'reload(seq 100)+change-prompt(hundred> )'\n  ```\n- Added draggable scrollbar to the main search window and the preview window\n  ```sh\n  # Hide scrollbar\n  fzf --no-scrollbar\n\n  # Customize scrollbar\n  fzf --scrollbar ┆ --color scrollbar:blue\n  ```\n- New event\n    - Added `load` event that is triggered when the input stream is complete\n      and the initial processing of the list is complete.\n      ```sh\n      # Change the prompt to \"loaded\" when the input stream is complete\n      (seq 10; sleep 1; seq 11 20) | fzf --prompt 'Loading> ' --bind 'load:change-prompt:Loaded> '\n\n      # You can use it instead of 'start' event without `--sync` if asynchronous\n      # trigger is not an issue.\n      (seq 10; sleep 1; seq 11 20) | fzf --bind 'load:last'\n      ```\n- New actions\n    - Added `pos(...)` action to move the cursor to the numeric position\n        - `first` and `last` are equivalent to `pos(1)` and `pos(-1)` respectively\n      ```sh\n      # Put the cursor on the 10th item\n      seq 100 | fzf --sync --bind 'start:pos(10)'\n\n      # Put the cursor on the 10th to last item\n      seq 100 | fzf --sync --bind 'start:pos(-10)'\n      ```\n    - Added `reload-sync(...)` action which replaces the current list only after\n      the reload process is complete. This is useful when the command takes\n      a while to produce the initial output and you don't want fzf to run against\n      an empty list while the command is running.\n      ```sh\n      # You can still filter and select entries from the initial list for 3 seconds\n      seq 100 | fzf --bind 'load:reload-sync(sleep 3; seq 1000)+unbind(load)'\n      ```\n    - Added `next-selected` and `prev-selected` actions to move between selected\n      items\n      ```sh\n      # `next-selected` will move the pointer to the next selected item below the current line\n      # `prev-selected` will move the pointer to the previous selected item above the current line\n      seq 10 | fzf --multi --bind ctrl-n:next-selected,ctrl-p:prev-selected\n\n      # Both actions respect --layout option\n      seq 10 | fzf --multi --bind ctrl-n:next-selected,ctrl-p:prev-selected --layout reverse\n      ```\n    - Added `change-query(...)` action that simply changes the query string to the\n      given static string. This can be useful when used with `--listen`.\n      ```sh\n      curl localhost:6266 -d \"change-query:$(date)\"\n      ```\n    - Added `transform-prompt(...)` action for transforming the prompt string\n      using an external command\n      ```sh\n      # Press space to change the prompt string using an external command\n      # (only the first line of the output is taken)\n      fzf --bind 'space:reload(ls),load:transform-prompt(printf \"%s> \" \"$(date)\")'\n      ```\n    - Added `transform-query(...)` action for transforming the query string using\n      an external command\n      ```sh\n      # Press space to convert the query to uppercase letters\n      fzf --bind 'space:transform-query(tr \"[:lower:]\" \"[:upper:]\" <<< {q})'\n\n      # Bind it to 'change' event for automatic conversion\n      fzf --bind 'change:transform-query(tr \"[:lower:]\" \"[:upper:]\" <<< {q})'\n\n      # Can only type numbers\n      fzf --bind 'change:transform-query(sed \"s/[^0-9]//g\" <<< {q})'\n      ```\n    - `put` action can optionally take an argument string\n      ```sh\n      # a will put 'alpha' on the prompt, ctrl-b will put 'bravo'\n      fzf --bind 'a:put+put(lpha),ctrl-b:put(bravo)'\n      ```\n- Added color name `preview-label` for `--preview-label` (defaults to `label`\n  for `--border-label`)\n- Better support for (Windows) terminals where each box-drawing character\n  takes 2 columns. Set `RUNEWIDTH_EASTASIAN` environment variable to `0` or `1`.\n    - On Vim, the variable will be automatically set if `&ambiwidth` is `double`\n- Behavior changes\n    - fzf will always execute the preview command if the command template\n      contains `{q}` even when it's empty. If you prefer the old behavior,\n      you'll have to check if `{q}` is empty in your command.\n      ```sh\n      # This will show // even when the query is empty\n      : | fzf --preview 'echo /{q}/'\n\n      # But if you don't want it,\n      : | fzf --preview '[ -n {q} ] || exit; echo /{q}/'\n      ```\n    - `double-click` will behave the same as `enter` unless otherwise specified,\n      so you don't have to repeat the same action twice in `--bind` in most cases.\n      ```sh\n      # No need to bind 'double-click' to the same action\n      fzf --bind 'enter:execute:less {}' # --bind 'double-click:execute:less {}'\n      ```\n    - If the color for `separator` is not specified, it will default to the\n      color for `border`. Same holds true for `scrollbar`. This is to reduce\n      the number of configuration items required to achieve a consistent color\n      scheme.\n    - If `follow` flag is specified in `--preview-window` option, fzf will\n      automatically scroll to the bottom of the streaming preview output. But\n      when the user manually scrolls the window, the following stops. With\n      this version, fzf will resume following if the user scrolls the window\n      to the bottom.\n    - Default border style on Windows is changed to `sharp` because some\n      Windows terminals are not capable of displaying `rounded` border\n      characters correctly.\n- Minor bug fixes and improvements\n\n0.35.1\n------\n- Fixed a bug where fzf with `--tiebreak=chunk` crashes on inverse match query\n- Fixed a bug where clicking above fzf would paste escape sequences\n\n0.35.0\n------\n- Added `start` event that is triggered only once when fzf finder starts.\n  Since fzf consumes the input stream asynchronously, the input list is not\n  available unless you use `--sync`.\n  ```sh\n  seq 100 | fzf --multi --sync --bind 'start:last+select-all+preview(echo welcome)'\n  ```\n- Added `--border-label` and `--border-label-pos` for putting label on the border\n  ```sh\n  # ANSI color codes are supported\n  # (with https://github.com/busyloop/lolcat)\n  label=$(curl -s http://metaphorpsum.com/sentences/1 | lolcat -f)\n\n  # Border label at the center\n  fzf --height=10 --border --border-label=\"╢ $label ╟\" --color=label:italic:black\n\n  # Left-aligned (positive integer)\n  fzf --height=10 --border --border-label=\"╢ $label ╟\" --border-label-pos=3 --color=label:italic:black\n\n  # Right-aligned (negative integer) on the bottom line (:bottom)\n  fzf --height=10 --border --border-label=\"╢ $label ╟\" --border-label-pos=-3:bottom --color=label:italic:black\n  ```\n- Also added `--preview-label` and `--preview-label-pos` for the border of the\n  preview window\n  ```sh\n  fzf --preview 'cat {}' --border --preview-label=' Preview ' --preview-label-pos=2\n  ```\n- Info panel (match counter) will be followed by a horizontal separator by\n  default\n    - Use `--no-separator` or `--separator=''` to hide the separator\n    - You can specify an arbitrary string that is repeated to form the\n      horizontal separator. e.g. `--separator=╸`\n    - The color of the separator can be customized via `--color=separator:...`\n    - ANSI color codes are also supported\n  ```sh\n  fzf --separator=╸ --color=separator:green\n  fzf --separator=$(lolcat -f -F 1.4 <<< ▁▁▂▃▄▅▆▆▅▄▃▂▁▁) --info=inline\n  ```\n- Added `--border=bold` and `--border=double` along with\n  `--preview-window=border-bold` and `--preview-window=border-double`\n\n0.34.0\n------\n- Added support for adaptive `--height`. If the `--height` value is prefixed\n  with `~`, fzf will automatically determine the height in the range according\n  to the input size.\n  ```sh\n  seq 1 | fzf --height ~70% --border --padding 1 --margin 1\n  seq 10 | fzf --height ~70% --border --padding 1 --margin 1\n  seq 100 | fzf --height ~70% --border --padding 1 --margin 1\n  ```\n    - There are a few limitations\n        - Not compatible with percent top/bottom margin/padding\n          ```sh\n          # This is not allowed (top/bottom margin in percent value)\n          fzf --height ~50% --border --margin 5%,10%\n\n          # This is allowed (top/bottom margin in fixed value)\n          fzf --height ~50% --border --margin 2,10%\n          ```\n        - fzf will not start until it can determine the right height for the input\n          ```sh\n          # fzf will open immediately\n          (sleep 2; seq 10) | fzf --height 50%\n\n          # fzf will open after 2 seconds\n          (sleep 2; seq 10) | fzf --height ~50%\n          (sleep 2; seq 1000) | fzf --height ~50%\n          ```\n- Fixed tcell renderer used to render full-screen fzf on Windows\n- ~~`--no-clear` is deprecated. Use `reload` action instead.~~\n\n0.33.0\n------\n- Added `--scheme=[default|path|history]` option to choose scoring scheme\n    - (Experimental)\n    - We updated the scoring algorithm in 0.32.0, however we have learned that\n      this new scheme (`default`) is not always giving the optimal result\n    - `path`: Additional bonus point is only given to the characters after\n      path separator. You might want to choose this scheme if you have many\n      files with spaces in their paths.\n    - `history`: No additional bonus points are given so that we give more\n      weight to the chronological ordering. This is equivalent to the scoring\n      scheme before 0.32.0. This also sets `--tiebreak=index`.\n- ANSI color sequences with colon delimiters are now supported.\n  ```sh\n  printf \"\\e[38;5;208mOption 1\\e[m\\nOption 2\" | fzf --ansi\n  printf \"\\e[38:5:208mOption 1\\e[m\\nOption 2\" | fzf --ansi\n  ```\n- Support `border-{up,down}` as the synonyms for `border-{top,bottom}` in\n  `--preview-window`\n- Added support for ANSI `strikethrough`\n  ```sh\n  printf \"\\e[9mdeleted\" | fzf --ansi\n  fzf --color fg+:strikethrough\n  ```\n\n0.32.1\n------\n- Fixed incorrect ordering of `--tiebreak=chunk`\n- fzf-tmux will show fzf border instead of tmux popup border (requires tmux 3.3)\n  ```sh\n  fzf-tmux -p70%\n  fzf-tmux -p70% --color=border:bright-red\n  fzf-tmux -p100%,60% --color=border:bright-yellow --border=horizontal --padding 1,5 --margin 1,0\n  fzf-tmux -p70%,100% --color=border:bright-green --border=vertical\n\n  # Key bindings (CTRL-T, CTRL-R, ALT-C) will use these options\n  export FZF_TMUX_OPTS='-p100%,60% --color=border:green --border=horizontal --padding 1,5 --margin 1,0'\n  ```\n\n0.32.0\n------\n- Updated the scoring algorithm\n    - Different bonus points to different categories of word boundaries\n      (listed higher to lower bonus point)\n        - Word after whitespace characters or beginning of the string\n        - Word after common delimiter characters (`/,:;|`)\n        - Word after other non-word characters\n      ```sh\n      # foo/bar.sh` is preferred over `foo-bar.sh` on `bar`\n      fzf --query=bar --height=4 << EOF\n      foo-bar.sh\n      foo/bar.sh\n      EOF\n      ```\n- Added a new tiebreak `chunk`\n    - Favors the line with shorter matched chunk. A chunk is a set of\n      consecutive non-whitespace characters.\n    - Unlike the default `length`, this scheme works well with tabular input\n      ```sh\n      # length prefers item #1, because the whole line is shorter,\n      # chunk prefers item #2, because the matched chunk (\"foo\") is shorter\n      fzf --height=6 --header-lines=2 --tiebreak=chunk --reverse --query=fo << \"EOF\"\n      N | Field1 | Field2 | Field3\n      - | ------ | ------ | ------\n      1 | hello  | foobar | baz\n      2 | world  | foo    | bazbaz\n      EOF\n      ```\n    - If the input does not contain any spaces, `chunk` is equivalent to\n      `length`. But we're not going to set it as the default because it is\n      computationally more expensive.\n- Bug fixes and improvements\n\n0.31.0\n------\n- Added support for an alternative preview window layout that is activated\n  when the size of the preview window is smaller than a certain threshold.\n  ```sh\n  # If the width of the preview window is smaller than 50 columns,\n  # it will be displayed above the search window.\n  fzf --preview 'cat {}' --preview-window 'right,50%,border-left,<50(up,30%,border-bottom)'\n\n  # Or you can just hide it like so\n  fzf --preview 'cat {}' --preview-window '<50(hidden)'\n  ```\n- fzf now uses SGR mouse mode to properly support mouse on larger terminals\n- You can now use characters that do not satisfy `unicode.IsGraphic` constraint\n  for `--marker`, `--pointer`, and `--ellipsis`. Allows Nerd Fonts and stuff.\n  Use at your own risk.\n- Bug fixes and improvements\n- Shell extension\n    - `kill` completion now requires trigger sequence (`**`) for consistency\n\n0.30.0\n------\n- Fixed cursor flickering over the screen by hiding it during rendering\n- Added `--ellipsis` option. You can take advantage of it to make fzf\n  effectively search non-visible parts of the item.\n  ```sh\n  # Search against hidden line numbers on the far right\n  nl /usr/share/dict/words                  |\n    awk '{printf \"%s%1000s\\n\", $2, $1}'     |\n    fzf --nth=-1 --no-hscroll --ellipsis='' |\n    awk '{print $2}'\n  ```\n- Added `rebind` action for restoring bindings after `unbind`\n- Bug fixes and improvements\n\n0.29.0\n------\n- Added `change-preview(...)` action to change the `--preview` command\n    - cf. `preview(...)` is a one-off action that doesn't change the default\n      preview command\n- Added `change-preview-window(...)` action\n    - You can rotate through the different options separated by `|`\n      ```sh\n      fzf --preview 'cat {}' --preview-window right:40% \\\n          --bind 'ctrl-/:change-preview-window(right,70%|down,40%,border-top|hidden|)'\n      ```\n- Fixed rendering of the prompt line when overflow occurs with `--info=inline`\n\n0.28.0\n------\n- Added `--header-first` option to print header before the prompt line\n  ```sh\n  fzf --header $'Welcome to fzf\\n▔▔▔▔▔▔▔▔▔▔▔▔▔▔' --reverse --height 30% --border --header-first\n  ```\n- Added `--scroll-off=LINES` option (similar to `scrolloff` option of Vim)\n    - You can set it to a very large number so that the cursor stays in the\n      middle of the screen while scrolling\n      ```sh\n      fzf --scroll-off=5\n      fzf --scroll-off=999\n      ```\n- Fixed bug where preview window is not updated on `reload` (#2644)\n- fzf on Windows will also use `$SHELL` to execute external programs\n    - See #2638 and #2647\n    - Thanks to @rashil2000, @vovcacik, and @janlazo\n\n0.27.3\n------\n- Preview window is `hidden` by default when there are `preview` bindings but\n  `--preview` command is not given\n- Fixed bug where `{n}` is not properly reset on `reload`\n- Fixed bug where spinner is not displayed on `reload`\n- Enhancements in tcell renderer for Windows (#2616)\n- Vim plugin\n    - `sinklist` is added as a synonym to `sink*` so that it's easier to add\n      a function to a spec dictionary\n      ```vim\n      let spec = { 'source': 'ls', 'options': ['--multi', '--preview', 'cat {}'] }\n      function spec.sinklist(matches)\n        echom string(a:matches)\n      endfunction\n\n      call fzf#run(fzf#wrap(spec))\n      ```\n    - Vim 7 compatibility\n\n0.27.2\n------\n- 16 base ANSI colors can be specified by their names\n  ```sh\n  fzf --color fg:3,fg+:11\n  fzf --color fg:yellow,fg+:bright-yellow\n  ```\n- Fix bug where `--read0` not properly displaying long lines\n\n0.27.1\n------\n- Added `unbind` action. In the following Ripgrep launcher example, you can\n  use `unbind(reload)` to switch to fzf-only filtering mode.\n    - See https://github.com/junegunn/fzf/blob/master/ADVANCED.md#switching-to-fzf-only-search-mode\n- Vim plugin\n    - Vim plugin will stop immediately even when the source command hasn't finished\n      ```vim\n      \" fzf will read the stream file while allowing other processes to append to it\n      call fzf#run({'source': 'cat /dev/null > /tmp/stream; tail -f /tmp/stream'})\n      ```\n    - It is now possible to open popup window relative to the current window\n      ```vim\n      let g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6, 'relative': v:true, 'yoffset': 1.0 } }\n      ```\n\n0.27.0\n------\n- More border options for `--preview-window`\n  ```sh\n  fzf --preview 'cat {}' --preview-window border-left\n  fzf --preview 'cat {}' --preview-window border-left --border horizontal\n  fzf --preview 'cat {}' --preview-window top:border-bottom\n  fzf --preview 'cat {}' --preview-window top:border-horizontal\n  ```\n- Automatically set `/dev/tty` as STDIN on execute action\n  ```sh\n  # Redirect /dev/tty to suppress \"Vim: Warning: Input is not from a terminal\"\n  # ls | fzf --bind \"enter:execute(vim {} < /dev/tty)\"\n\n  # \"< /dev/tty\" part is no longer needed\n  ls | fzf --bind \"enter:execute(vim {})\"\n  ```\n- Bug fixes and improvements\n- Signed and notarized macOS binaries\n  (Huge thanks to [BACKERS.md](https://github.com/junegunn/junegunn/blob/main/BACKERS.md)!)\n\n0.26.0\n------\n- Added support for fixed header in preview window\n  ```sh\n  # Display top 3 lines as the fixed header\n  fzf --preview 'bat --style=header,grid --color=always {}' --preview-window '~3'\n  ```\n- More advanced preview offset expression to better support the fixed header\n  ```sh\n  # Preview with bat, matching line in the middle of the window below\n  # the fixed header of the top 3 lines\n  #\n  #   ~3    Top 3 lines as the fixed header\n  #   +{2}  Base scroll offset extracted from the second field\n  #   +3    Extra offset to compensate for the 3-line header\n  #   /2    Put in the middle of the preview area\n  #\n  git grep --line-number '' |\n    fzf --delimiter : \\\n        --preview 'bat --style=full --color=always --highlight-line {2} {1}' \\\n        --preview-window '~3:+{2}+3/2'\n  ```\n- Added `select` and `deselect` action for unconditionally selecting or\n  deselecting a single item in `--multi` mode. Complements `toggle` action.\n- Significant performance improvement in ANSI code processing\n- Bug fixes and improvements\n- Built with Go 1.16\n\n0.25.1\n------\n- Added `close` action\n    - Close preview window if open, abort fzf otherwise\n- Bug fixes and improvements\n\n0.25.0\n------\n- Text attributes set in `--color` are not reset when fzf sees another\n  `--color` option for the same element. This allows you to put custom text\n  attributes in your `$FZF_DEFAULT_OPTS` and still have those attributes\n  even when you override the colors.\n\n  ```sh\n  # Default colors and attributes\n  fzf\n\n  # Apply custom text attributes\n  export FZF_DEFAULT_OPTS='--color fg+:italic,hl:-1:underline,hl+:-1:reverse:underline'\n\n  fzf\n\n  # Different colors but you still have the attributes\n  fzf --color hl:176,hl+:177\n\n  # Write \"regular\" if you want to clear the attributes\n  fzf --color hl:176:regular,hl+:177:regular\n  ```\n- Renamed `--phony` to `--disabled`\n- You can dynamically enable and disable the search functionality using the\n  new `enable-search`, `disable-search`, and `toggle-search` actions\n- You can assign a different color to the query string for when search is disabled\n  ```sh\n  fzf --color query:#ffffff,disabled:#999999 --bind space:toggle-search\n  ```\n- Added `last` action to move the cursor to the last match\n    - The opposite action `top` is renamed to `first`, but `top` is still\n      recognized as a synonym for backward compatibility\n- Added `preview-top` and `preview-bottom` actions\n- Extended support for alt key chords: alt with any case-sensitive single character\n  ```sh\n  fzf --bind alt-,:first,alt-.:last\n  ```\n\n0.24.4\n------\n- Added `--preview-window` option `follow`\n  ```sh\n  # Preview window will automatically scroll to the bottom\n  fzf --preview-window follow --preview 'for i in $(seq 100000); do\n    echo \"$i\"\n    sleep 0.01\n    (( i % 300 == 0 )) && printf \"\\033[2J\"\n  done'\n  ```\n- Added `change-prompt` action\n  ```sh\n  fzf --prompt 'foo> ' --bind $'a:change-prompt:\\x1b[31mbar> '\n  ```\n- Bug fixes and improvements\n\n0.24.3\n------\n- Added `--padding` option\n  ```sh\n  fzf --margin 5% --padding 5% --border --preview 'cat {}' \\\n      --color bg:#222222,preview-bg:#333333\n  ```\n\n0.24.2\n------\n- Bug fixes and improvements\n\n0.24.1\n------\n- Fixed broken `--color=[bw|no]` option\n\n0.24.0\n------\n- Real-time rendering of preview window\n  ```sh\n  # fzf can render preview window before the command completes\n  fzf --preview 'sleep 1; for i in $(seq 100); do echo $i; sleep 0.01; done'\n\n  # Preview window can process ANSI escape sequence (CSI 2 J) for clearing the display\n  fzf --preview 'for i in $(seq 100000); do\n    (( i % 200 == 0 )) && printf \"\\033[2J\"\n    echo \"$i\"\n    sleep 0.01\n  done'\n  ```\n- Updated `--color` option to support text styles\n  - `regular` / `bold` / `dim` / `underline` / `italic` / `reverse` / `blink`\n    ```sh\n    # * Set -1 to keep the original color\n    # * Multiple style attributes can be combined\n    # * Italic style may not be supported by some terminals\n    rg --line-number --no-heading --color=always \"\" |\n      fzf --ansi --prompt \"Rg: \" \\\n          --color fg+:italic,hl:underline:-1,hl+:italic:underline:reverse:-1 \\\n          --color pointer:reverse,prompt:reverse,input:159 \\\n          --pointer '  '\n    ```\n- More `--border` options\n  - `vertical`, `top`, `bottom`, `left`, `right`\n  - Updated Vim plugin to use these new `--border` options\n    ```vim\n    \" Floating popup window in the center of the screen\n    let g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6 } }\n\n    \" Popup with 100% width\n    let g:fzf_layout = { 'window': { 'width': 1.0, 'height': 0.5, 'border': 'horizontal' } }\n\n    \" Popup with 100% height\n    let g:fzf_layout = { 'window': { 'width': 0.5, 'height': 1.0, 'border': 'vertical' } }\n\n    \" Similar to 'down' layout, but it uses a popup window and doesn't affect the window layout\n    let g:fzf_layout = { 'window': { 'width': 1.0, 'height': 0.5, 'yoffset': 1.0, 'border': 'top' } }\n\n    \" Opens on the right;\n    \"   'highlight' option is still supported but it will only take the foreground color of the group\n    let g:fzf_layout = { 'window': { 'width': 0.5, 'height': 1.0, 'xoffset': 1.0, 'border': 'left', 'highlight': 'Comment' } }\n    ```\n- To indicate if `--multi` mode is enabled, fzf will print the number of\n  selected items even when no item is selected\n  ```sh\n  seq 100 | fzf\n    # 100/100\n  seq 100 | fzf --multi\n    # 100/100 (0)\n  seq 100 | fzf --multi 5\n    # 100/100 (0/5)\n  ```\n- Since 0.24.0, release binaries will be uploaded to https://github.com/junegunn/fzf/releases\n\n0.23.1\n------\n- Added `--preview-window` options for disabling flags\n    - `nocycle`\n    - `nohidden`\n    - `nowrap`\n    - `default`\n- Built with Go 1.14.9 due to performance regression\n    - https://github.com/golang/go/issues/40727\n\n0.23.0\n------\n- Support preview scroll offset relative to window height\n  ```sh\n  git grep --line-number '' |\n    fzf --delimiter : \\\n        --preview 'bat --style=numbers --color=always --highlight-line {2} {1}' \\\n        --preview-window +{2}-/2\n  ```\n- Added `--preview-window` option for sharp edges (`--preview-window sharp`)\n- Added `--preview-window` option for cyclic scrolling (`--preview-window cycle`)\n- Reduced vertical padding around the preview window when `--preview-window\n  noborder` is used\n- Added actions for preview window\n    - `preview-half-page-up`\n    - `preview-half-page-down`\n- Vim\n    - Popup width and height can be given in absolute integer values\n    - Added `fzf#exec()` function for getting the path of fzf executable\n        - It also downloads the latest binary if it's not available by running\n          `./install --bin`\n- Built with Go 1.15.2\n    - We no longer provide 32-bit binaries\n\n0.22.0\n------\n- Added more options for `--bind`\n    - `backward-eof` event\n      ```sh\n      # Aborts when you delete backward when the query prompt is already empty\n      fzf --bind backward-eof:abort\n      ```\n    - `refresh-preview` action\n      ```sh\n      # Rerun preview command when you hit '?'\n      fzf --preview 'echo $RANDOM' --bind '?:refresh-preview'\n      ```\n    - `preview` action\n      ```sh\n      # Default preview command with an extra preview binding\n      fzf --preview 'file {}' --bind '?:preview:cat {}'\n\n      # A preview binding with no default preview command\n      # (Preview window is initially empty)\n      fzf --bind '?:preview:cat {}'\n\n      # Preview window hidden by default, it appears when you first hit '?'\n      fzf --bind '?:preview:cat {}' --preview-window hidden\n      ```\n- Added preview window option for setting the initial scroll offset\n  ```sh\n  # Initial scroll offset is set to the line number of each line of\n  # git grep output *minus* 5 lines\n  git grep --line-number '' |\n    fzf --delimiter : --preview 'nl {1}' --preview-window +{2}-5\n  ```\n- Added support for ANSI colors in `--prompt` string\n- Smart match of accented characters\n    - An unaccented character in the query string will match both accented and\n      unaccented characters, while an accented character will only match\n      accented characters. This is similar to how \"smart-case\" match works.\n- Vim plugin\n    - `tmux` layout option for using fzf-tmux\n      ```vim\n      let g:fzf_layout = { 'tmux': '-p90%,60%' }\n      ```\n\n0.21.1\n------\n- Shell extension\n    - CTRL-R will remove duplicate commands\n- fzf-tmux\n    - Supports tmux popup window (require tmux 3.2 or above)\n        - ```sh\n          # 50% width and height\n          fzf-tmux -p\n\n          # 80% width and height\n          fzf-tmux -p 80%\n\n          # 80% width and 40% height\n          fzf-tmux -p 80%,40%\n          fzf-tmux -w 80% -h 40%\n\n          # Window position\n          fzf-tmux -w 80% -h 40% -x 0 -y 0\n          fzf-tmux -w 80% -h 40% -y 1000\n\n          # Write ordinary fzf options after --\n          fzf-tmux -p -- --reverse --info=inline --margin 2,4 --border\n          ```\n        - On macOS, you can build the latest tmux from the source with\n          `brew install tmux --HEAD`\n- Bug fixes\n    - Fixed Windows file traversal not to include directories\n    - Fixed ANSI colors with `--keep-right`\n    - Fixed _fzf_complete for zsh\n- Built with Go 1.14.1\n\n0.21.0\n------\n- `--height` option is now available on Windows as well (@kelleyma49)\n- Added `--pointer` and `--marker` options\n- Added `--keep-right` option that keeps the right end of the line visible\n  when it's too long\n- Style changes\n    - `--border` will now print border with rounded corners around the\n      finder instead of printing horizontal lines above and below it.\n      The previous style is available via `--border=horizontal`\n    - Unicode spinner\n- More keys and actions for `--bind`\n- Added PowerShell script for downloading Windows binary\n- Vim plugin: Built-in floating windows support\n  ```vim\n  let g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6 } }\n  ```\n- bash: Various improvements in key bindings (CTRL-T, CTRL-R, ALT-C)\n    - CTRL-R will start with the current command-line as the initial query\n    - CTRL-R properly supports multi-line commands\n- Fuzzy completion API changed\n  ```sh\n  # Previous: fzf arguments given as a single string argument\n  # - This style is still supported, but it's deprecated\n  _fzf_complete \"--multi --reverse --prompt=\\\"doge> \\\"\" \"$@\" < <(\n    echo foo\n  )\n\n  # New API: multiple fzf arguments before \"--\"\n  # - Easier to write multiple options\n  _fzf_complete --multi --reverse --prompt=\"doge> \" -- \"$@\" < <(\n    echo foo\n  )\n  ```\n- Bug fixes and improvements\n\n0.20.0\n------\n- Customizable preview window color (`preview-fg` and `preview-bg` for `--color`)\n  ```sh\n  fzf --preview 'cat {}' \\\n      --color 'fg:#bbccdd,fg+:#ddeeff,bg:#334455,preview-bg:#223344,border:#778899' \\\n      --border --height 20 --layout reverse --info inline\n  ```\n- Removed the immediate flicking of the screen on `reload` action.\n  ```sh\n  : | fzf --bind 'change:reload:seq {q}' --phony\n  ```\n- Added `clear-query` and `clear-selection` actions for `--bind`\n- It is now possible to split a composite bind action over multiple `--bind`\n  expressions by prefixing the later ones with `+`.\n  ```sh\n  fzf --bind 'ctrl-a:up+up'\n\n  # Can be now written as\n  fzf --bind 'ctrl-a:up' --bind 'ctrl-a:+up'\n\n  # This is useful when you need to write special execute/reload form (i.e. `execute:...`)\n  # to avoid parse errors and add more actions to the same key\n  fzf --multi --bind 'ctrl-l:select-all+execute:less {+f}' --bind 'ctrl-l:+deselect-all'\n  ```\n- Fixed parse error of `--bind` expression where concatenated execute/reload\n  action contains `+` character.\n  ```sh\n  fzf --multi --bind 'ctrl-l:select-all+execute(less {+f})+deselect-all'\n  ```\n- Fixed bugs of reload action\n    - Not triggered when there's no match even when the command doesn't have\n      any placeholder expressions\n    - Screen not properly cleared when `--header-lines` not filled on reload\n\n0.19.0\n------\n\n- Added `--phony` option which completely disables search functionality.\n  Useful when you want to use fzf only as a selector interface. See below.\n- Added \"reload\" action for dynamically updating the input list without\n  restarting fzf. See https://github.com/junegunn/fzf/issues/1750 to learn\n  more about it.\n  ```sh\n  # Using fzf as the selector interface for ripgrep\n  RG_PREFIX=\"rg --column --line-number --no-heading --color=always --smart-case \"\n  INITIAL_QUERY=\"foo\"\n  FZF_DEFAULT_COMMAND=\"$RG_PREFIX '$INITIAL_QUERY' || true\" \\\n    fzf --bind \"change:reload:$RG_PREFIX {q} || true\" \\\n        --ansi --phony --query \"$INITIAL_QUERY\"\n  ```\n- `--multi` now takes an optional integer argument which indicates the maximum\n  number of items that can be selected\n  ```sh\n  seq 100 | fzf --multi 3 --reverse --height 50%\n  ```\n- If a placeholder expression for `--preview` and `execute` action (and the\n  new `reload` action) contains `f` flag, it is replaced to the\n  path of a temporary file that holds the evaluated list. This is useful\n  when you multi-select a large number of items and the length of the\n  evaluated string may exceed [`ARG_MAX`][argmax].\n  ```sh\n  # Press CTRL-A to select 100K items and see the sum of all the numbers\n  seq 100000 | fzf --multi --bind ctrl-a:select-all \\\n                   --preview \"awk '{sum+=\\$1} END {print sum}' {+f}\"\n  ```\n- `deselect-all` no longer deselects unmatched items. It is now consistent\n  with `select-all` and `toggle-all` in that it only affects matched items.\n- Due to the limitation of bash, fuzzy completion is enabled by default for\n  a fixed set of commands. A helper function for easily setting up fuzzy\n  completion for any command is now provided.\n  ```sh\n  # usage: _fzf_setup_completion path|dir COMMANDS...\n  _fzf_setup_completion path git kubectl\n  ```\n- Info line style can be changed by `--info=STYLE`\n    - `--info=default`\n    - `--info=inline` (same as old `--inline-info`)\n    - `--info=hidden`\n- Preview window border can be disabled by adding `noborder` to\n  `--preview-window`.\n- When you transform the input with `--with-nth`, the trailing white spaces\n  are removed.\n- `ctrl-\\`, `ctrl-]`, `ctrl-^`, and `ctrl-/` can now be used with `--bind`\n- See https://github.com/junegunn/fzf/milestone/15?closed=1 for more details\n\n[argmax]: https://unix.stackexchange.com/questions/120642/what-defines-the-maximum-size-for-a-command-single-argument\n\n0.18.0\n------\n\n- Added placeholder expression for zero-based item index: `{n}` and `{+n}`\n    - `fzf --preview 'echo {n}: {}'`\n- Added color option for the gutter: `--color gutter:-1`\n- Added `--no-unicode` option for drawing borders in non-Unicode, ASCII\n  characters\n- `FZF_PREVIEW_LINES` and `FZF_PREVIEW_COLUMNS` are exported to preview process\n    - fzf still overrides `LINES` and `COLUMNS` as before, but they may be\n      reset by the default shell.\n- Bug fixes and improvements\n    - See https://github.com/junegunn/fzf/milestone/14?closed=1\n- Built with Go 1.12.1\n\n0.17.5\n------\n\n- Bug fixes and improvements\n    - See https://github.com/junegunn/fzf/milestone/13?closed=1\n- Search query longer than the screen width is allowed (up to 300 chars)\n- Built with Go 1.11.1\n\n0.17.4\n------\n\n- Added `--layout` option with a new layout called `reverse-list`.\n    - `--layout=reverse` is a synonym for `--reverse`\n    - `--layout=default` is a synonym for `--no-reverse`\n- Preview window will be updated even when there is no match for the query\n  if any of the placeholder expressions (e.g. `{q}`, `{+}`) evaluates to\n  a non-empty string.\n- More keys for binding: `shift-{up,down}`, `alt-{up,down,left,right}`\n- fzf can now start even when `/dev/tty` is not available by making an\n  educated guess.\n- Updated the default command for Windows.\n- Fixes and improvements on bash/zsh completion\n- install and uninstall scripts now supports generating files under\n  `XDG_CONFIG_HOME` on `--xdg` flag.\n\nSee https://github.com/junegunn/fzf/milestone/12?closed=1 for the full list of\nchanges.\n\n0.17.3\n------\n- `$LINES` and `$COLUMNS` are exported to preview command so that the command\n  knows the exact size of the preview window.\n- Better error messages when the default command or `$FZF_DEFAULT_COMMAND`\n  fails.\n- Reverted #1061 to avoid having duplicate entries in the list when find\n  command detected a file system loop (#1120). The default command now\n  requires that find supports `-fstype` option.\n- fzf now distinguishes mouse left click and right click (#1130)\n    - Right click is now bound to `toggle` action by default\n    - `--bind` understands `left-click` and `right-click`\n- Added `replace-query` action (#1137)\n    - Replaces query string with the current selection\n- Added `accept-non-empty` action (#1162)\n    - Same as accept, except that it prevents fzf from exiting without any\n      selection\n\n0.17.1\n------\n\n- Fixed custom background color of preview window (#1046)\n- Fixed background color issues of Windows binary\n- Fixed Windows binary to execute command using cmd.exe with no parsing and\n  escaping (#1072)\n- Added support for `window` layout on Vim 8 using Vim 8 terminal (#1055)\n\n0.17.0-2\n--------\n\nA maintenance release for auxiliary scripts. fzf binaries are not updated.\n\n- Experimental support for the builtin terminal of Vim 8\n    - fzf can now run inside GVim\n- Updated Vim plugin to better handle `&shell` issue on fish\n- Fixed a bug of fzf-tmux where invalid output is generated\n- Fixed fzf-tmux to work even when `tput` does not work\n\n0.17.0\n------\n- Performance optimization\n- One can match literal spaces in extended-search mode with a space prepended\n  by a backslash.\n- `--expect` is now additive and can be specified multiple times.\n\n0.16.11\n-------\n- Performance optimization\n- Fixed missing preview update\n\n0.16.10\n-------\n- Fixed invalid handling of ANSI colors in preview window\n- Further improved `--ansi` performance\n\n0.16.9\n------\n- Memory and performance optimization\n    - Around 20% performance improvement for general use cases\n    - Up to 5x faster processing of `--ansi`\n    - Up to 50% reduction of memory usage\n- Bug fixes and usability improvements\n    - Fixed handling of bracketed paste mode\n    - [ERROR] on info line when the default command failed\n    - More efficient rendering of preview window\n    - `--no-clear` updated for repetitive relaunching scenarios\n\n0.16.8\n------\n- New `change` event and `top` action for `--bind`\n    - `fzf --bind change:top`\n        - Move cursor to the top result whenever the query string is changed\n    - `fzf --bind 'ctrl-w:unix-word-rubout+top,ctrl-u:unix-line-discard+top'`\n        - `top` combined with `unix-word-rubout` and `unix-line-discard`\n- Fixed inconsistent tiebreak scores when `--nth` is used\n- Proper display of tab characters in `--prompt`\n- Fixed not to `--cycle` on page-up/page-down to prevent overshoot\n- Git revision in `--version` output\n- Basic support for Cygwin environment\n- Many fixes in Vim plugin on Windows/Cygwin (thanks to @janlazo)\n\n0.16.7\n------\n- Added support for `ctrl-alt-[a-z]` key chords\n- CTRL-Z (SIGSTOP) now works with fzf\n- fzf will export `$FZF_PREVIEW_WINDOW` so that the scripts can use it\n- Bug fixes and improvements in Vim plugin and shell extensions\n\n0.16.6\n------\n- Minor bug fixes and improvements\n- Added `--no-clear` option for scripting purposes\n\n0.16.5\n------\n- Minor bug fixes\n- Added `toggle-preview-wrap` action\n- Built with Go 1.8\n\n0.16.4\n------\n- Added `--border` option to draw border above and below the finder\n- Bug fixes and improvements\n\n0.16.3\n------\n- Fixed a bug where fzf incorrectly display the lines when straddling tab\n  characters are trimmed\n- Placeholder expression used in `--preview` and `execute` action can\n  optionally take `+` flag to be used with multiple selections\n    - e.g. `git log --oneline | fzf --multi --preview 'git show {+1}'`\n- Added `execute-silent` action for executing a command silently without\n  switching to the alternate screen. This is useful when the process is\n  short-lived and you're not interested in its output.\n    - e.g. `fzf --bind 'ctrl-y:execute!(echo -n {} | pbcopy)'`\n- `ctrl-space` is allowed in `--bind`\n\n0.16.2\n------\n- Dropped ncurses dependency\n- Binaries for freebsd, openbsd, arm5, arm6, arm7, and arm8\n- Official 24-bit color support\n- Added support for composite actions in `--bind`. Multiple actions can be\n  chained using `+` separator.\n    - e.g. `fzf --bind 'ctrl-y:execute(echo -n {} | pbcopy)+abort'`\n- `--preview-window` with size 0 is allowed. This is used to make fzf execute\n  preview command in the background without displaying the result.\n- Minor bug fixes and improvements\n\n0.16.1\n------\n- Fixed `--height` option to properly fill the window with the background\n  color\n- Added `half-page-up` and `half-page-down` actions\n- Added `-L` flag to the default find command\n\n0.16.0\n------\n- *Added `--height HEIGHT[%]` option*\n    - fzf can now display finder without occupying the full screen\n- Preview window will truncate long lines by default. Line wrap can be enabled\n  by `:wrap` flag in `--preview-window`.\n- Latin script letters will be normalized before matching so that it's easier\n  to match against accented letters. e.g. `sodanco` can match `Só Danço Samba`.\n    - Normalization can be disabled via `--literal`\n- Added `--filepath-word` to make word-wise movements/actions (`alt-b`,\n  `alt-f`, `alt-bs`, `alt-d`) respect path separators\n\n0.15.9\n------\n- Fixed rendering glitches introduced in 0.15.8\n- The default escape delay is reduced to 50ms and is configurable via\n  `$ESCDELAY`\n- Scroll indicator at the top-right corner of the preview window is always\n  displayed when there's overflow\n- Can now be built with ncurses 6 or tcell to support extra features\n    - *ncurses 6*\n        - Supports more than 256 color pairs\n        - Supports italics\n    - *tcell*\n        - 24-bit color support\n    - See https://github.com/junegunn/fzf/blob/master/BUILD.md\n\n0.15.8\n------\n- Updated ANSI processor to handle more VT-100 escape sequences\n- Added `--no-bold` (and `--bold`) option\n- Improved escape sequence processing for WSL\n- Added support for `alt-[0-9]`, `f11`, and `f12` for `--bind` and `--expect`\n\n0.15.7\n------\n- Fixed panic when color is disabled and header lines contain ANSI colors\n\n0.15.6\n------\n- Windows binaries! (@kelleyma49)\n- Fixed the bug where header lines are cleared when preview window is toggled\n- Fixed not to display ^N and ^O on screen\n- Fixed cursor keys (or any key sequence that starts with ESC) on WSL by\n  making fzf wait for additional keystrokes after ESC for up to 100ms\n\n0.15.5\n------\n- Setting foreground color will no longer set background color to black\n    - e.g. `fzf --color fg:153`\n- `--tiebreak=end` will consider relative position instead of absolute distance\n- Updated `fzf#wrap` function to respect `g:fzf_colors`\n\n0.15.4\n------\n- Added support for range expression in preview and execute action\n    - e.g. `ls -l | fzf --preview=\"echo user={3} when={-4..-2}; cat {-1}\" --header-lines=1`\n    - `{q}` will be replaced to the single-quoted string of the current query\n- Fixed to properly handle unicode whitespace characters\n- Display scroll indicator in preview window\n- Inverse search term will use exact matcher by default\n    - This is a breaking change, but I believe it makes much more sense. It is\n      almost impossible to predict which entries will be filtered out due to\n      a fuzzy inverse term. You can still perform inverse-fuzzy-match by\n      prepending `!'` to the term.\n\n0.15.3\n------\n- Added support for more ANSI attributes: dim, underline, blink, and reverse\n- Fixed race condition in `toggle-preview`\n\n0.15.2\n------\n- Preview window is now scrollable\n    - With mouse scroll or with bindable actions\n        - `preview-up`\n        - `preview-down`\n        - `preview-page-up`\n        - `preview-page-down`\n- Updated ANSI processor to support high intensity colors and ignore\n  some VT100-related escape sequences\n\n0.15.1\n------\n- Fixed panic when the pattern occurs after 2^15-th column\n- Fixed rendering delay when displaying extremely long lines\n\n0.15.0\n------\n- Improved fuzzy search algorithm\n    - Added `--algo=[v1|v2]` option so one can still choose the old algorithm\n      which values the search performance over the quality of the result\n- Advanced scoring criteria\n- `--read0` to read input delimited by ASCII NUL character\n- `--print0` to print output delimited by ASCII NUL character\n\n0.13.5\n------\n- Memory and performance optimization\n    - Up to 2x performance with half the amount of memory\n\n0.13.4\n------\n- Performance optimization\n    - Memory footprint for ascii string is reduced by 60%\n    - 15 to 20% improvement of query performance\n    - Up to 45% better performance of `--nth` with non-regex delimiters\n- Fixed invalid handling of `hidden` property of `--preview-window`\n\n0.13.3\n------\n- Fixed duplicate rendering of the last line in preview window\n\n0.13.2\n------\n- Fixed race condition where preview window is not properly cleared\n\n0.13.1\n------\n- Fixed UI issue with large `--preview` output with many ANSI codes\n\n0.13.0\n------\n- Added preview feature\n    - `--preview CMD`\n    - `--preview-window POS[:SIZE][:hidden]`\n- `{}` in execute action is now replaced to the single-quoted (instead of\n  double-quoted) string of the current line\n- Fixed to ignore control characters for bracketed paste mode\n\n0.12.2\n------\n\n- 256-color capability detection does not require `256` in `$TERM`\n- Added `print-query` action\n- More named keys for binding; <kbd>F1</kbd> ~ <kbd>F10</kbd>,\n  <kbd>ALT-/</kbd>, <kbd>ALT-space</kbd>, and <kbd>ALT-enter</kbd>\n- Added `jump` and `jump-accept` actions that implement [EasyMotion][em]-like\n  movement\n  ![][jump]\n\n[em]: https://github.com/easymotion/vim-easymotion\n[jump]: https://cloud.githubusercontent.com/assets/700826/15367574/b3999dc4-1d64-11e6-85da-28ceeb1a9bc2.png\n\n0.12.1\n------\n\n- Ranking algorithm introduced in 0.12.0 is now universally applied\n- Fixed invalid cache reference in exact mode\n- Fixes and improvements in Vim plugin and shell extensions\n\n0.12.0\n------\n\n- Enhanced ranking algorithm\n- Minor bug fixes\n\n0.11.4\n------\n\n- Added `--hscroll-off=COL` option (default: 10) (#513)\n- Some fixes in Vim plugin and shell extensions\n\n0.11.3\n------\n\n- Graceful exit on SIGTERM (#482)\n- `$SHELL` instead of `sh` for `execute` action and `$FZF_DEFAULT_COMMAND` (#481)\n- Changes in fuzzy completion API\n    - [`_fzf_compgen_{path,dir}`](https://github.com/junegunn/fzf/commit/9617647)\n    - [`_fzf_complete_COMMAND_post`](https://github.com/junegunn/fzf/commit/8206746)\n      for post-processing\n\n0.11.2\n------\n\n- `--tiebreak` now accepts comma-separated list of sort criteria\n    - Each criterion should appear only once in the list\n    - `index` is only allowed at the end of the list\n    - `index` is implicitly appended to the list when not specified\n    - Default is `length` (or equivalently `length,index`)\n- `begin` criterion will ignore leading whitespaces when calculating the index\n- Added `toggle-in` and `toggle-out` actions\n    - Switch direction depending on `--reverse`-ness\n    - `export FZF_DEFAULT_OPTS=\"--bind tab:toggle-out,shift-tab:toggle-in\"`\n- Reduced the initial delay when `--tac` is not given\n    - fzf defers the initial rendering of the screen up to 100ms if the input\n      stream is ongoing to prevent unnecessary redraw during the initial\n      phase. However, 100ms delay is quite noticeable and might give the\n      impression that fzf is not snappy enough. This commit reduces the\n      maximum delay down to 20ms when `--tac` is not specified, in which case\n      the input list quickly fills the entire screen.\n\n0.11.1\n------\n\n- Added `--tabstop=SPACES` option\n\n0.11.0\n------\n\n- Added OR operator for extended-search mode\n- Added `--execute-multi` action\n- Fixed incorrect cursor position when unicode wide characters are used in\n  `--prompt`\n- Fixes and improvements in shell extensions\n\n0.10.9\n------\n\n- Extended-search mode is now enabled by default\n    - `--extended-exact` is deprecated and instead we have `--exact` for\n      orthogonally controlling \"exactness\" of search\n- Fixed not to display non-printable characters\n- Added `double-click` for `--bind` option\n- More robust handling of SIGWINCH\n\n0.10.8\n------\n\n- Fixed panic when trying to set colors after colors are disabled (#370)\n\n0.10.7\n------\n\n- Fixed unserialized interrupt handling during execute action which often\n  caused invalid memory access and crash\n- Changed `--tiebreak=length` (default) to use trimmed length when `--nth` is\n  used\n\n0.10.6\n------\n\n- Replaced `--header-file` with `--header` option\n- `--header` and `--header-lines` can be used together\n- Changed exit status\n    - 0: Okay\n    - 1: No match\n    - 2: Error\n    - 130: Interrupted\n- 64-bit linux binary is statically-linked with ncurses to avoid\n  compatibility issues.\n\n0.10.5\n------\n\n- `'`-prefix to unquote the term in `--extended-exact` mode\n- Backward scan when `--tiebreak=end` is set\n\n0.10.4\n------\n\n- Fixed to remove ANSI code from output when `--with-nth` is set\n\n0.10.3\n------\n\n- Fixed slow performance of `--with-nth` when used with `--delimiter`\n    - Regular expression engine of Golang as of now is very slow, so the fixed\n      version will treat the given delimiter pattern as a plain string instead\n      of a regular expression unless it contains special characters and is\n      a valid regular expression.\n    - Simpler regular expression for delimiter for better performance\n\n0.10.2\n------\n\n### Fixes and improvements\n\n- Improvement in perceived response time of queries\n    - Eager, efficient rune array conversion\n- Graceful exit when failed to initialize ncurses (invalid $TERM)\n- Improved ranking algorithm when `--nth` option is set\n- Changed the default command not to fail when there are files whose names\n  start with dash\n\n0.10.1\n------\n\n### New features\n\n- Added `--margin` option\n- Added options for sticky header\n    - `--header-file`\n    - `--header-lines`\n- Added `cancel` action which clears the input or closes the finder when the\n  input is already empty\n    - e.g. `export FZF_DEFAULT_OPTS=\"--bind esc:cancel\"`\n- Added `delete-char/eof` action to differentiate `CTRL-D` and `DEL`\n\n### Minor improvements/fixes\n\n- Fixed to allow binding colon and comma keys\n- Fixed ANSI processor to handle color regions spanning multiple lines\n\n0.10.0\n------\n\n### New features\n\n- More actions for `--bind`\n    - `select-all`\n    - `deselect-all`\n    - `toggle-all`\n    - `ignore`\n- `execute(...)` action for running arbitrary command without leaving fzf\n    - `fzf --bind \"ctrl-m:execute(less {})\"`\n    - `fzf --bind \"ctrl-t:execute(tmux new-window -d 'vim {}')\"`\n    - If the command contains parentheses, use any of the follows alternative\n      notations to avoid parse errors\n        - `execute[...]`\n        - `execute~...~`\n        - `execute!...!`\n        - `execute@...@`\n        - `execute#...#`\n        - `execute$...$`\n        - `execute%...%`\n        - `execute^...^`\n        - `execute&...&`\n        - `execute*...*`\n        - `execute;...;`\n        - `execute/.../`\n        - `execute|...|`\n        - `execute:...`\n            - This is the special form that frees you from parse errors as it\n              does not expect the closing character\n            - The catch is that it should be the last one in the\n              comma-separated list\n- Added support for optional search history\n    - `--history HISTORY_FILE`\n        - When used, `CTRL-N` and `CTRL-P` are automatically remapped to\n          `next-history` and `previous-history`\n    - `--history-size MAX_ENTRIES` (default: 1000)\n- Cyclic scrolling can be enabled with `--cycle`\n- Fixed the bug where the spinner was not spinning on idle input stream\n    - e.g. `sleep 100 | fzf`\n\n### Minor improvements/fixes\n\n- Added synonyms for key names that can be specified for `--bind`,\n  `--toggle-sort`, and `--expect`\n- Fixed the color of multi-select marker on the current line\n- Fixed to allow `^pattern$` in extended-search mode\n\n\n0.9.13\n------\n\n### New features\n\n- Color customization with the extended `--color` option\n\n### Bug fixes\n\n- Fixed premature termination of Reader in the presence of a long line which\n  is longer than 64KB\n\n0.9.12\n------\n\n### New features\n\n- Added `--bind` option for custom key bindings\n\n### Bug fixes\n\n- Fixed to update \"inline-info\" immediately after terminal resize\n- Fixed ANSI code offset calculation\n\n0.9.11\n------\n\n### New features\n\n- Added `--inline-info` option for saving screen estate (#202)\n     - Useful inside Neovim\n     - e.g. `let $FZF_DEFAULT_OPTS = $FZF_DEFAULT_OPTS.' --inline-info'`\n\n### Bug fixes\n\n- Invalid mutation of input on case conversion (#209)\n- Smart-case for each term in extended-search mode (#208)\n- Fixed double-click result when scroll offset is positive\n\n0.9.10\n------\n\n### Improvements\n\n- Performance optimization\n- Less aggressive memoization to limit memory usage\n\n### New features\n\n- Added color scheme for light background: `--color=light`\n\n0.9.9\n-----\n\n### New features\n\n- Added `--tiebreak` option (#191)\n- Added `--no-hscroll` option (#193)\n- Visual indication of `--toggle-sort` (#194)\n\n0.9.8\n-----\n\n### Bug fixes\n\n- Fixed Unicode case handling (#186)\n- Fixed to terminate on RuneError (#185)\n\n0.9.7\n-----\n\n### New features\n\n- Added `--toggle-sort` option (#173)\n    - `--toggle-sort=ctrl-r` is applied to `CTRL-R` shell extension\n\n### Bug fixes\n\n- Fixed to print empty line if `--expect` is set and fzf is completed by\n  `--select-1` or `--exit-0` (#172)\n- Fixed to allow comma character as an argument to `--expect` option\n\n0.9.6\n-----\n\n### New features\n\n#### Added `--expect` option (#163)\n\nIf you provide a comma-separated list of keys with `--expect` option, fzf will\nallow you to select the match and complete the finder when any of the keys is\npressed. Additionally, fzf will print the name of the key pressed as the first\nline of the output so that your script can decide what to do next based on the\ninformation.\n\n```sh\nfzf --expect=ctrl-v,ctrl-t,alt-s,f1,f2,~,@\n```\n\nThe updated vim plugin uses this option to implement\n[ctrlp](https://github.com/kien/ctrlp.vim)-compatible key bindings.\n\n### Bug fixes\n\n- Fixed to ignore ANSI escape code `\\e[K` (#162)\n\n0.9.5\n-----\n\n### New features\n\n#### Added `--ansi` option (#150)\n\nIf you give `--ansi` option to fzf, fzf will interpret ANSI color codes from\nthe input, display the item with the ANSI colors (true colors are not\nsupported), and strips the codes from the output. This option is off by\ndefault as it entails some overhead.\n\n### Improvements\n\n#### Reduced initial memory footprint (#151)\n\nBy removing unnecessary copy of pointers, fzf will use significantly smaller\namount of memory when it's started. The difference is hugely noticeable when\nthe input is extremely large. (e.g. `locate / | fzf`)\n\n### Bug fixes\n\n- Fixed panic on `--no-sort --filter ''` (#149)\n\n0.9.4\n-----\n\n### New features\n\n#### Added `--tac` option to reverse the order of the input.\n\nOne might argue that this option is unnecessary since we can already put `tac`\nor `tail -r` in the command pipeline to achieve the same result. However, the\nadvantage of `--tac` is that it does not block until the input is complete.\n\n### *Backward incompatible changes*\n\n#### Changed behavior on `--no-sort`\n\n`--no-sort` option will no longer reverse the display order within finder. You\nmay want to use the new `--tac` option with `--no-sort`.\n\n```\nhistory | fzf +s --tac\n```\n\n### Improvements\n\n#### `--filter` will not block when sort is disabled\n\nWhen fzf works in filtering mode (`--filter`) and sort is disabled\n(`--no-sort`), there's no need to block until input is complete. The new\nversion of fzf will print the matches on-the-fly when the following condition\nis met:\n\n    --filter TERM --no-sort [--no-tac --no-sync]\n\nor simply:\n\n    -f TERM +s\n\nThis change removes unnecessary delay in the use cases like the following:\n\n    fzf -f xxx +s | head -5\n\nHowever, in this case, fzf processes the lines sequentially, so it cannot\nutilize multiple cores, and fzf will run slightly slower than the previous\nmode of execution where filtering is done in parallel after the entire input\nis loaded. If the user is concerned about this performance problem, one can\nadd `--sync` option to re-enable buffering.\n\n0.9.3\n-----\n\n### New features\n- Added `--sync` option for multi-staged filtering\n\n### Improvements\n- `--select-1` and `--exit-0` will start finder immediately when the condition\n  cannot be met\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.49,
          "content": "FROM ubuntu:24.04\nRUN apt-get update -y && apt install -y git make golang zsh fish ruby tmux\nRUN gem install --no-document -v 5.22.3 minitest\nRUN echo '. /usr/share/bash-completion/completions/git' >> ~/.bashrc\nRUN echo '. ~/.bashrc' >> ~/.bash_profile\n\n# Do not set default PS1\nRUN rm -f /etc/bash.bashrc\nCOPY . /fzf\nRUN cd /fzf && make install && ./install --all\nENV LANG=C.UTF-8\nCMD [\"bash\", \"-ic\", \"tmux new 'set -o pipefail; ruby /fzf/test/test_go.rb | tee out && touch ok' && cat out && [ -e ok ]\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.06,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2013-2024 Junegunn Choi\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 5.22,
          "content": "GO             ?= go\nGOOS           ?= $(shell $(GO) env GOOS)\n\nMAKEFILE       := $(realpath $(lastword $(MAKEFILE_LIST)))\nROOT_DIR       := $(shell dirname $(MAKEFILE))\nSOURCES        := $(wildcard *.go src/*.go src/*/*.go shell/*sh man/man1/*.1) $(MAKEFILE)\n\nifdef FZF_VERSION\nVERSION        := $(FZF_VERSION)\nelse\nVERSION        := $(shell git describe --abbrev=0 2> /dev/null | sed \"s/^v//\")\nendif\nifeq ($(VERSION),)\n$(error Not on git repository; cannot determine $$FZF_VERSION)\nendif\nVERSION_TRIM   := $(shell echo $(VERSION) | sed \"s/^v//; s/-.*//\")\nVERSION_REGEX  := $(subst .,\\.,$(VERSION_TRIM))\n\nifdef FZF_REVISION\nREVISION       := $(FZF_REVISION)\nelse\nREVISION       := $(shell git log -n 1 --pretty=format:%h --abbrev=8 -- $(SOURCES) 2> /dev/null)\nendif\nifeq ($(REVISION),)\n$(error Not on git repository; cannot determine $$FZF_REVISION)\nendif\nBUILD_FLAGS    := -a -ldflags \"-s -w -X main.version=$(VERSION) -X main.revision=$(REVISION)\" -tags \"$(TAGS)\" -trimpath\n\nBINARY32       := fzf-$(GOOS)_386\nBINARY64       := fzf-$(GOOS)_amd64\nBINARYS390     := fzf-$(GOOS)_s390x\nBINARYARM5     := fzf-$(GOOS)_arm5\nBINARYARM6     := fzf-$(GOOS)_arm6\nBINARYARM7     := fzf-$(GOOS)_arm7\nBINARYARM8     := fzf-$(GOOS)_arm8\nBINARYPPC64LE  := fzf-$(GOOS)_ppc64le\nBINARYRISCV64  := fzf-$(GOOS)_riscv64\nBINARYLOONG64  := fzf-$(GOOS)_loong64\n\n# https://en.wikipedia.org/wiki/Uname\nUNAME_M := $(shell uname -m)\nifeq ($(UNAME_M),x86_64)\n\tBINARY := $(BINARY64)\nelse ifeq ($(UNAME_M),amd64)\n\tBINARY := $(BINARY64)\nelse ifeq ($(UNAME_M),s390x)\n\tBINARY := $(BINARYS390)\nelse ifeq ($(UNAME_M),i686)\n\tBINARY := $(BINARY32)\nelse ifeq ($(UNAME_M),i386)\n\tBINARY := $(BINARY32)\nelse ifeq ($(UNAME_M),armv5l)\n\tBINARY := $(BINARYARM5)\nelse ifeq ($(UNAME_M),armv6l)\n\tBINARY := $(BINARYARM6)\nelse ifeq ($(UNAME_M),armv7l)\n\tBINARY := $(BINARYARM7)\nelse ifeq ($(UNAME_M),armv8l)\n\t# armv8l is always 32-bit and should implement the armv7 ISA, so\n\t# just use the same filename as for armv7.\n\tBINARY := $(BINARYARM7)\nelse ifeq ($(UNAME_M),arm64)\n\tBINARY := $(BINARYARM8)\nelse ifeq ($(UNAME_M),aarch64)\n\tBINARY := $(BINARYARM8)\nelse ifeq ($(UNAME_M),ppc64le)\n\tBINARY := $(BINARYPPC64LE)\nelse ifeq ($(UNAME_M),riscv64)\n\tBINARY := $(BINARYRISCV64)\nelse ifeq ($(UNAME_M),loongarch64)\n\tBINARY := $(BINARYLOONG64)\nelse\n$(error Build on $(UNAME_M) is not supported, yet.)\nendif\n\nall: target/$(BINARY)\n\ntest: $(SOURCES)\n\tSHELL=/bin/sh GOOS= $(GO) test -v -tags \"$(TAGS)\" \\\n\t\t\t\tgithub.com/junegunn/fzf/src \\\n\t\t\t\tgithub.com/junegunn/fzf/src/algo \\\n\t\t\t\tgithub.com/junegunn/fzf/src/tui \\\n\t\t\t\tgithub.com/junegunn/fzf/src/util\n\nbench:\n\tcd src && SHELL=/bin/sh GOOS= $(GO) test -v -tags \"$(TAGS)\" -run=Bench -bench=. -benchmem\n\nlint: $(SOURCES) test/test_go.rb\n\t[ -z \"$$(gofmt -s -d src)\" ] || (gofmt -s -d src; exit 1)\n\trubocop --require rubocop-minitest --require rubocop-performance\n\ninstall: bin/fzf\n\ngenerate:\n\tPATH=$(PATH):$(GOPATH)/bin $(GO) generate ./...\n\nbuild:\n\tgoreleaser build --clean --snapshot --skip=post-hooks\n\nrelease:\n\t# Make sure that the tests pass and the build works\n\tTAGS=tcell make test\n\tmake test build clean\n\nifndef GITHUB_TOKEN\n\t$(error GITHUB_TOKEN is not defined)\nendif\n\n\t# Check if we are on master branch\nifneq ($(shell git symbolic-ref --short HEAD),master)\n\t$(error Not on master branch)\nendif\n\n\t# Check if version numbers are properly updated\n\tgrep -q ^$(VERSION_REGEX)$$ CHANGELOG.md\n\tgrep -qF '\"fzf $(VERSION_TRIM)\"' man/man1/fzf.1\n\tgrep -qF '\"fzf $(VERSION_TRIM)\"' man/man1/fzf-tmux.1\n\tgrep -qF $(VERSION) install\n\tgrep -qF $(VERSION) install.ps1\n\n\t# Make release note out of CHANGELOG.md\n\tmkdir -p tmp\n\tsed -n '/^$(VERSION_REGEX)$$/,/^[0-9]/p' CHANGELOG.md | tail -r | \\\n\t\tsed '1,/^ *$$/d' | tail -r | sed 1,2d | tee tmp/release-note\n\n\t# Push to temp branch first so that install scripts always works on master branch\n\tgit checkout -B temp master\n\tgit push origin temp --follow-tags --force\n\n\t# Make a GitHub release\n\tgoreleaser --clean --release-notes tmp/release-note\n\n\t# Push to master\n\tgit checkout master\n\tgit push origin master\n\n\t# Delete temp branch\n\tgit push origin --delete temp\n\nclean:\n\t$(RM) -r dist target\n\ntarget/$(BINARY32): $(SOURCES)\n\tGOARCH=386 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARY64): $(SOURCES)\n\tGOARCH=amd64 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYS390): $(SOURCES)\n\tGOARCH=s390x $(GO) build $(BUILD_FLAGS) -o $@\n# https://github.com/golang/go/wiki/GoArm\ntarget/$(BINARYARM5): $(SOURCES)\n\tGOARCH=arm GOARM=5 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYARM6): $(SOURCES)\n\tGOARCH=arm GOARM=6 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYARM7): $(SOURCES)\n\tGOARCH=arm GOARM=7 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYARM8): $(SOURCES)\n\tGOARCH=arm64 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYPPC64LE): $(SOURCES)\n\tGOARCH=ppc64le $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYRISCV64): $(SOURCES)\n\tGOARCH=riscv64 $(GO) build $(BUILD_FLAGS) -o $@\n\ntarget/$(BINARYLOONG64): $(SOURCES)\n\tGOARCH=loong64 $(GO) build $(BUILD_FLAGS) -o $@\n\nbin/fzf: target/$(BINARY) | bin\n\t-rm -f bin/fzf\n\tcp -f target/$(BINARY) bin/fzf\n\ndocker:\n\tdocker build -t fzf-ubuntu .\n\tdocker run -it fzf-ubuntu tmux\n\ndocker-test:\n\tdocker build -t fzf-ubuntu .\n\tdocker run -it fzf-ubuntu\n\nupdate:\n\t$(GO) get -u\n\t$(GO) mod tidy\n\n.PHONY: all generate build release test bench lint install clean docker docker-test update\n"
        },
        {
          "name": "README-VIM.md",
          "type": "blob",
          "size": 17.48,
          "content": "FZF Vim integration\n===================\n\nInstallation\n------------\n\nOnce you have fzf installed, you can enable it inside Vim simply by adding the\ndirectory to `&runtimepath` in your Vim configuration file. The path may\ndiffer depending on the package manager.\n\n```vim\n\" If installed using Homebrew\nset rtp+=/usr/local/opt/fzf\n\n\" If installed using Homebrew on Apple Silicon\nset rtp+=/opt/homebrew/opt/fzf\n\n\" If you have cloned fzf on ~/.fzf directory\nset rtp+=~/.fzf\n```\n\nIf you use [vim-plug](https://github.com/junegunn/vim-plug), the same can be\nwritten as:\n\n```vim\n\" If installed using Homebrew\nPlug '/usr/local/opt/fzf'\n\n\" If installed using Homebrew on Apple Silicon\nPlug '/opt/homebrew/opt/fzf'\n\n\" If you have cloned fzf on ~/.fzf directory\nPlug '~/.fzf'\n```\n\nBut if you want the latest Vim plugin file from GitHub rather than the one\nincluded in the package, write:\n\n```vim\nPlug 'junegunn/fzf'\n```\n\nThe Vim plugin will pick up fzf binary available on the system. If fzf is not\nfound on `$PATH`, it will ask you if it should download the latest binary for\nyou.\n\nTo make sure that you have the latest version of the binary, set up\npost-update hook like so:\n\n```vim\nPlug 'junegunn/fzf', { 'do': { -> fzf#install() } }\n```\n\nSummary\n-------\n\nThe Vim plugin of fzf provides two core functions, and `:FZF` command which is\nthe basic file selector command built on top of them.\n\n1. **`fzf#run([spec dict])`**\n    - Starts fzf inside Vim with the given spec\n    - `:call fzf#run({'source': 'ls'})`\n2. **`fzf#wrap([spec dict]) -> (dict)`**\n    - Takes a spec for `fzf#run` and returns an extended version of it with\n      additional options for addressing global preferences (`g:fzf_xxx`)\n        - `:echo fzf#wrap({'source': 'ls'})`\n    - We usually *wrap* a spec with `fzf#wrap` before passing it to `fzf#run`\n        - `:call fzf#run(fzf#wrap({'source': 'ls'}))`\n3. **`:FZF [fzf_options string] [path string]`**\n    - Basic fuzzy file selector\n    - A reference implementation for those who don't want to write VimScript\n      to implement custom commands\n    - If you're looking for more such commands, check out [fzf.vim](https://github.com/junegunn/fzf.vim) project.\n\nThe most important of all is `fzf#run`, but it would be easier to understand\nthe whole if we start off with `:FZF` command.\n\n`:FZF[!]`\n---------\n\n```vim\n\" Look for files under current directory\n:FZF\n\n\" Look for files under your home directory\n:FZF ~\n\n\" With fzf command-line options\n:FZF --reverse --info=inline /tmp\n\n\" Bang version starts fzf in fullscreen mode\n:FZF!\n```\n\nSimilarly to [ctrlp.vim](https://github.com/kien/ctrlp.vim), use enter key,\n`CTRL-T`, `CTRL-X` or `CTRL-V` to open selected files in the current window,\nin new tabs, in horizontal splits, or in vertical splits respectively.\n\nNote that the environment variables `FZF_DEFAULT_COMMAND` and\n`FZF_DEFAULT_OPTS` also apply here.\n\n### Configuration\n\n- `g:fzf_action`\n    - Customizable extra key bindings for opening selected files in different ways\n- `g:fzf_layout`\n    - Determines the size and position of fzf window\n- `g:fzf_colors`\n    - Customizes fzf colors to match the current color scheme\n- `g:fzf_history_dir`\n    - Enables history feature\n\n#### Examples\n\n```vim\n\" This is the default extra key bindings\nlet g:fzf_action = {\n  \\ 'ctrl-t': 'tab split',\n  \\ 'ctrl-x': 'split',\n  \\ 'ctrl-v': 'vsplit' }\n\n\" An action can be a reference to a function that processes selected lines\nfunction! s:build_quickfix_list(lines)\n  call setqflist(map(copy(a:lines), '{ \"filename\": v:val, \"lnum\": 1 }'))\n  copen\n  cc\nendfunction\n\nlet g:fzf_action = {\n  \\ 'ctrl-q': function('s:build_quickfix_list'),\n  \\ 'ctrl-t': 'tab split',\n  \\ 'ctrl-x': 'split',\n  \\ 'ctrl-v': 'vsplit' }\n\n\" Default fzf layout\n\" - Popup window (center of the screen)\nlet g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6 } }\n\n\" - Popup window (center of the current window)\nlet g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6, 'relative': v:true } }\n\n\" - Popup window (anchored to the bottom of the current window)\nlet g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6, 'relative': v:true, 'yoffset': 1.0 } }\n\n\" - down / up / left / right\nlet g:fzf_layout = { 'down': '40%' }\n\n\" - Window using a Vim command\nlet g:fzf_layout = { 'window': 'enew' }\nlet g:fzf_layout = { 'window': '-tabnew' }\nlet g:fzf_layout = { 'window': '10new' }\n\n\" Customize fzf colors to match your color scheme\n\" - fzf#wrap translates this to a set of `--color` options\nlet g:fzf_colors =\n\\ { 'fg':      ['fg', 'Normal'],\n  \\ 'bg':      ['bg', 'Normal'],\n  \\ 'hl':      ['fg', 'Comment'],\n  \\ 'fg+':     ['fg', 'CursorLine', 'CursorColumn', 'Normal'],\n  \\ 'bg+':     ['bg', 'CursorLine', 'CursorColumn'],\n  \\ 'hl+':     ['fg', 'Statement'],\n  \\ 'info':    ['fg', 'PreProc'],\n  \\ 'border':  ['fg', 'Ignore'],\n  \\ 'prompt':  ['fg', 'Conditional'],\n  \\ 'pointer': ['fg', 'Exception'],\n  \\ 'marker':  ['fg', 'Keyword'],\n  \\ 'spinner': ['fg', 'Label'],\n  \\ 'header':  ['fg', 'Comment'] }\n\n\" Enable per-command history\n\" - History files will be stored in the specified directory\n\" - When set, CTRL-N and CTRL-P will be bound to 'next-history' and\n\"   'previous-history' instead of 'down' and 'up'.\nlet g:fzf_history_dir = '~/.local/share/fzf-history'\n```\n\n##### Explanation of `g:fzf_colors`\n\n`g:fzf_colors` is a dictionary mapping fzf elements to a color specification\nlist:\n\n    element: [ component, group1 [, group2, ...] ]\n\n- `element` is an fzf element to apply a color to:\n\n  | Element                     | Description                                           |\n  | ---                         | ---                                                   |\n  | `fg`  / `bg`  / `hl`        | Item (foreground / background / highlight)            |\n  | `fg+` / `bg+` / `hl+`       | Current item (foreground / background / highlight)    |\n  | `preview-fg` / `preview-bg` | Preview window text and background                    |\n  | `hl`  / `hl+`               | Highlighted substrings (normal / current)             |\n  | `gutter`                    | Background of the gutter on the left                  |\n  | `pointer`                   | Pointer to the current line (`>`)                     |\n  | `marker`                    | Multi-select marker (`>`)                             |\n  | `border`                    | Border around the window (`--border` and `--preview`) |\n  | `header`                    | Header (`--header` or `--header-lines`)               |\n  | `info`                      | Info line (match counters)                            |\n  | `spinner`                   | Streaming input indicator                             |\n  | `query`                     | Query string                                          |\n  | `disabled`                  | Query string when search is disabled                  |\n  | `prompt`                    | Prompt before query (`> `)                            |\n  | `pointer`                   | Pointer to the current line (`>`)                     |\n\n- `component` specifies the component (`fg` / `bg`) from which to extract the\n  color when considering each of the following highlight groups\n\n- `group1 [, group2, ...]` is a list of highlight groups that are searched (in\n  order) for a matching color definition\n\nFor example, consider the following specification:\n\n```vim\n  'prompt':  ['fg', 'Conditional', 'Comment'],\n```\n\nThis means we color the **prompt**\n- using the `fg` attribute of the `Conditional` if it exists,\n- otherwise use the `fg` attribute of the `Comment` highlight group if it exists,\n- otherwise fall back to the default color settings for the **prompt**.\n\nYou can examine the color option generated according the setting by printing\nthe result of `fzf#wrap()` function like so:\n\n```vim\n:echo fzf#wrap()\n```\n\n`fzf#run`\n---------\n\n`fzf#run()` function is the core of Vim integration. It takes a single\ndictionary argument, *a spec*, and starts fzf process accordingly. At the very\nleast, specify `sink` option to tell what it should do with the selected\nentry.\n\n```vim\ncall fzf#run({'sink': 'e'})\n```\n\nWe haven't specified the `source`, so this is equivalent to starting fzf on\ncommand line without standard input pipe; fzf will traverse the file system\nunder the current directory to get the list of files. (If\n`$FZF_DEFAULT_COMMAND` is set, fzf will use the output of the command\ninstead.) When you select one, it will open it with the sink, `:e` command. If\nyou want to open it in a new tab, you can pass `:tabedit` command instead as\nthe sink.\n\n```vim\ncall fzf#run({'sink': 'tabedit'})\n```\n\nYou can use any shell command as the source to generate the list. The\nfollowing example will list the files managed by git. It's equivalent to\nrunning `git ls-files | fzf` on shell.\n\n```vim\ncall fzf#run({'source': 'git ls-files', 'sink': 'e'})\n```\n\nfzf options can be specified as `options` entry in spec dictionary.\n\n```vim\ncall fzf#run({'sink': 'tabedit', 'options': '--multi --reverse'})\n```\n\nYou can also pass a layout option if you don't want fzf window to take up the\nentire screen.\n\n```vim\n\" up / down / left / right / window are allowed\ncall fzf#run({'source': 'git ls-files', 'sink': 'e', 'left': '40%'})\ncall fzf#run({'source': 'git ls-files', 'sink': 'e', 'window': '30vnew'})\n```\n\n`source` doesn't have to be an external shell command, you can pass a Vim\narray as the source. In the next example, we pass the names of color\nschemes as the source to implement a color scheme selector.\n\n```vim\ncall fzf#run({'source': map(split(globpath(&rtp, 'colors/*.vim')),\n            \\               'fnamemodify(v:val, \":t:r\")'),\n            \\ 'sink': 'colo', 'left': '25%'})\n```\n\nThe following table summarizes the available options.\n\n| Option name                | Type          | Description                                                           |\n| -------------------------- | ------------- | ----------------------------------------------------------------      |\n| `source`                   | string        | External command to generate input to fzf (e.g. `find .`)             |\n| `source`                   | list          | Vim list as input to fzf                                              |\n| `sink`                     | string        | Vim command to handle the selected item (e.g. `e`, `tabe`)            |\n| `sink`                     | funcref       | Function to be called with each selected item                         |\n| `sinklist` (or `sink*`)    | funcref       | Similar to `sink`, but takes the list of output lines at once         |\n| `exit`                     | funcref       | Function to be called with the exit status of fzf (e.g. 0, 1, 2, 130) |\n| `options`                  | string/list   | Options to fzf                                                        |\n| `dir`                      | string        | Working directory                                                     |\n| `up`/`down`/`left`/`right` | number/string | (Layout) Window position and size (e.g. `20`, `50%`)                  |\n| `tmux`                     | string        | (Layout) `--tmux` options (e.g. `90%,70%`)                            |\n| `window` (Vim 8 / Neovim)  | string        | (Layout) Command to open fzf window (e.g. `vertical aboveleft 30new`) |\n| `window` (Vim 8 / Neovim)  | dict          | (Layout) Popup window settings (e.g. `{'width': 0.9, 'height': 0.6}`) |\n\n`options` entry can be either a string or a list. For simple cases, string\nshould suffice, but prefer to use list type to avoid escaping issues.\n\n```vim\ncall fzf#run({'options': '--reverse --prompt \"C:\\\\Program Files\\\\\"'})\ncall fzf#run({'options': ['--reverse', '--prompt', 'C:\\Program Files\\']})\n```\n\nWhen `window` entry is a dictionary, fzf will start in a popup window. The\nfollowing options are allowed:\n\n- Required:\n    - `width` [float range [0 ~ 1]] or [integer range [8 ~ ]]\n    - `height` [float range [0 ~ 1]] or [integer range [4 ~ ]]\n- Optional:\n    - `yoffset` [float default 0.5 range [0 ~ 1]]\n    - `xoffset` [float default 0.5 range [0 ~ 1]]\n    - `relative` [boolean default v:false]\n    - `border` [string default `rounded` (`sharp` on Windows)]: Border style\n        - `rounded` / `sharp` / `horizontal` / `vertical` / `top` / `bottom` / `left` / `right` / `no[ne]`\n\n`fzf#wrap`\n----------\n\nWe have seen that several aspects of `:FZF` command can be configured with\na set of global option variables; different ways to open files\n(`g:fzf_action`), window position and size (`g:fzf_layout`), color palette\n(`g:fzf_colors`), etc.\n\nSo how can we make our custom `fzf#run` calls also respect those variables?\nSimply by *\"wrapping\"* the spec dictionary with `fzf#wrap` before passing it\nto `fzf#run`.\n\n- **`fzf#wrap([name string], [spec dict], [fullscreen bool]) -> (dict)`**\n    - All arguments are optional. Usually we only need to pass a spec dictionary.\n    - `name` is for managing history files. It is ignored if\n      `g:fzf_history_dir` is not defined.\n    - `fullscreen` can be either `0` or `1` (default: 0).\n\n`fzf#wrap` takes a spec and returns an extended version of it (also\na dictionary) with additional options for addressing global preferences. You\ncan examine the return value of it like so:\n\n```vim\necho fzf#wrap({'source': 'ls'})\n```\n\nAfter we *\"wrap\"* our spec, we pass it to `fzf#run`.\n\n```vim\ncall fzf#run(fzf#wrap({'source': 'ls'}))\n```\n\nNow it supports `CTRL-T`, `CTRL-V`, and `CTRL-X` key bindings (configurable\nvia `g:fzf_action`) and it opens fzf window according to `g:fzf_layout`\nsetting.\n\nTo make it easier to use, let's define `LS` command.\n\n```vim\ncommand! LS call fzf#run(fzf#wrap({'source': 'ls'}))\n```\n\nType `:LS` and see how it works.\n\nWe would like to make `:LS!` (bang version) open fzf in fullscreen, just like\n`:FZF!`. Add `-bang` to command definition, and use `<bang>` value to set\nthe last `fullscreen` argument of `fzf#wrap` (see `:help <bang>`).\n\n```vim\n\" On :LS!, <bang> evaluates to '!', and '!0' becomes 1\ncommand! -bang LS call fzf#run(fzf#wrap({'source': 'ls'}, <bang>0))\n```\n\nOur `:LS` command will be much more useful if we can pass a directory argument\nto it, so that something like `:LS /tmp` is possible.\n\n```vim\ncommand! -bang -complete=dir -nargs=? LS\n    \\ call fzf#run(fzf#wrap({'source': 'ls', 'dir': <q-args>}, <bang>0))\n```\n\nLastly, if you have enabled `g:fzf_history_dir`, you might want to assign\na unique name to our command and pass it as the first argument to `fzf#wrap`.\n\n```vim\n\" The query history for this command will be stored as 'ls' inside g:fzf_history_dir.\n\" The name is ignored if g:fzf_history_dir is not defined.\ncommand! -bang -complete=dir -nargs=? LS\n    \\ call fzf#run(fzf#wrap('ls', {'source': 'ls', 'dir': <q-args>}, <bang>0))\n```\n\n### Global options supported by `fzf#wrap`\n\n- `g:fzf_layout`\n- `g:fzf_action`\n    - **Works only when no custom `sink` (or `sinklist`) is provided**\n        - Having custom sink usually means that each entry is not an ordinary\n          file path (e.g. name of color scheme), so we can't blindly apply the\n          same strategy (i.e. `tabedit some-color-scheme` doesn't make sense)\n- `g:fzf_colors`\n- `g:fzf_history_dir`\n\nTips\n----\n\n### fzf inside terminal buffer\n\nOn the latest versions of Vim and Neovim, fzf will start in a terminal buffer.\nIf you find the default ANSI colors to be different, consider configuring the\ncolors using `g:terminal_ansi_colors` in regular Vim or `g:terminal_color_x`\nin Neovim.\n\n```vim\n\" Terminal colors for seoul256 color scheme\nif has('nvim')\n  let g:terminal_color_0 = '#4e4e4e'\n  let g:terminal_color_1 = '#d68787'\n  let g:terminal_color_2 = '#5f865f'\n  let g:terminal_color_3 = '#d8af5f'\n  let g:terminal_color_4 = '#85add4'\n  let g:terminal_color_5 = '#d7afaf'\n  let g:terminal_color_6 = '#87afaf'\n  let g:terminal_color_7 = '#d0d0d0'\n  let g:terminal_color_8 = '#626262'\n  let g:terminal_color_9 = '#d75f87'\n  let g:terminal_color_10 = '#87af87'\n  let g:terminal_color_11 = '#ffd787'\n  let g:terminal_color_12 = '#add4fb'\n  let g:terminal_color_13 = '#ffafaf'\n  let g:terminal_color_14 = '#87d7d7'\n  let g:terminal_color_15 = '#e4e4e4'\nelse\n  let g:terminal_ansi_colors = [\n    \\ '#4e4e4e', '#d68787', '#5f865f', '#d8af5f',\n    \\ '#85add4', '#d7afaf', '#87afaf', '#d0d0d0',\n    \\ '#626262', '#d75f87', '#87af87', '#ffd787',\n    \\ '#add4fb', '#ffafaf', '#87d7d7', '#e4e4e4'\n  \\ ]\nendif\n```\n\n### Starting fzf in a popup window\n\n```vim\n\" Required:\n\" - width [float range [0 ~ 1]] or [integer range [8 ~ ]]\n\" - height [float range [0 ~ 1]] or [integer range [4 ~ ]]\n\"\n\" Optional:\n\" - xoffset [float default 0.5 range [0 ~ 1]]\n\" - yoffset [float default 0.5 range [0 ~ 1]]\n\" - relative [boolean default v:false]\n\" - border [string default 'rounded']: Border style\n\"   - 'rounded' / 'sharp' / 'horizontal' / 'vertical' / 'top' / 'bottom' / 'left' / 'right'\nlet g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6 } }\n```\n\nAlternatively, you can make fzf open in a tmux popup window (requires tmux 3.2\nor above) by putting `--tmux` option value in `tmux` key.\n\n```vim\n\" See `--tmux` option in `man fzf` for available options\n\" [center|top|bottom|left|right][,SIZE[%]][,SIZE[%]]\nif exists('$TMUX')\n  let g:fzf_layout = { 'tmux': '90%,70%' }\nelse\n  let g:fzf_layout = { 'window': { 'width': 0.9, 'height': 0.6 } }\nendif\n```\n\n### Hide statusline\n\nWhen fzf starts in a terminal buffer, the file type of the buffer is set to\n`fzf`. So you can set up `FileType fzf` autocmd to customize the settings of\nthe window.\n\nFor example, if you open fzf on the bottom on the screen (e.g. `{'down':\n'40%'}`), you might want to temporarily disable the statusline for a cleaner\nlook.\n\n```vim\nlet g:fzf_layout = { 'down': '30%' }\nautocmd! FileType fzf\nautocmd  FileType fzf set laststatus=0 noshowmode noruler\n  \\| autocmd BufLeave <buffer> set laststatus=2 showmode ruler\n```\n\n[License](LICENSE)\n------------------\n\nThe MIT License (MIT)\n\nCopyright (c) 2013-2024 Junegunn Choi\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 39.54,
          "content": "<div align=\"center\">\n<sup>Special thanks to:</sup>\n<br>\n<br>\n<a href=\"https://warp.dev/?utm_source=github&utm_medium=referral&utm_campaign=fzf_20240209\">\n  <div>\n    <img src=\"https://raw.githubusercontent.com/junegunn/i/master/warp.png\" width=\"300\" alt=\"Warp\">\n  </div>\n  <b>Warp is a modern, Rust-based terminal with AI built in so you and your team can build great software, faster.</b>\n  <div>\n    <sup>Visit warp.dev to learn more.</sup>\n  </div>\n</a>\n<br>\n<hr>\n</div>\n<br>\n\n<img src=\"https://raw.githubusercontent.com/junegunn/i/master/fzf.png\" height=\"170\" alt=\"fzf - a command-line fuzzy finder\"> [![github-actions](https://github.com/junegunn/fzf/workflows/Test%20fzf%20on%20Linux/badge.svg)](https://github.com/junegunn/fzf/actions)\n===\n\nfzf is a general-purpose command-line fuzzy finder.\n\n<img src=\"https://raw.githubusercontent.com/junegunn/i/master/fzf-preview.png\" width=640>\n\nIt's an interactive filter program for any kind of list; files, command\nhistory, processes, hostnames, bookmarks, git commits, etc. It implements\na \"fuzzy\" matching algorithm, so you can quickly type in patterns with omitted\ncharacters and still get the results you want.\n\nHighlights\n----------\n\n- 📦 **Portable** — Distributed as a single binary for easy installation\n- ⚡ **Blazingly fast** — Highly optimized code instantly processes millions of items\n- 🛠️ **Extremely versatile** — Fully customizable via an event-action binding mechanism\n- 🔋 **Batteries included** — Includes integration with bash, zsh, fish, Vim, and Neovim\n\nSponsors ❤️\n-----------\n\nI would like to thank all the sponsors of this project who make it possible for me to continue to improve fzf.\n\nIf you'd like to sponsor this project, please visit https://github.com/sponsors/junegunn.\n\n<!-- sponsors --><a href=\"https://github.com/miyanokomiya\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;miyanokomiya.png\" width=\"60px\" alt=\"User avatar: miyanokomiya\" /></a><a href=\"https://github.com/jonhoo\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jonhoo.png\" width=\"60px\" alt=\"User avatar: Jon Gjengset\" /></a><a href=\"https://github.com/AceofSpades5757\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AceofSpades5757.png\" width=\"60px\" alt=\"User avatar: Kyle L. Davis\" /></a><a href=\"https://github.com/Frederick888\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Frederick888.png\" width=\"60px\" alt=\"User avatar: Frederick Zhang\" /></a><a href=\"https://github.com/moritzdietz\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;moritzdietz.png\" width=\"60px\" alt=\"User avatar: Moritz Dietz\" /></a><a href=\"https://github.com/mikker\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mikker.png\" width=\"60px\" alt=\"User avatar: Mikkel Malmberg\" /></a><a href=\"https://github.com/pldubouilh\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pldubouilh.png\" width=\"60px\" alt=\"User avatar: Pierre Dubouilh\" /></a><a href=\"https://github.com/trantor\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;trantor.png\" width=\"60px\" alt=\"User avatar: Fulvio Scapin\" /></a><a href=\"https://github.com/rcorre\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;rcorre.png\" width=\"60px\" alt=\"User avatar: Ryan Roden-Corrent\" /></a><a href=\"https://github.com/blissdev\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;blissdev.png\" width=\"60px\" alt=\"User avatar: Jordan Arentsen\" /></a><a href=\"https://github.com/aexvir\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;aexvir.png\" width=\"60px\" alt=\"User avatar: Alex Viscreanu\" /></a><a href=\"https://github.com/dbalatero\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;dbalatero.png\" width=\"60px\" alt=\"User avatar: David Balatero\" /></a><a href=\"https://github.com/moobar\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;moobar.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/benelan\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;benelan.png\" width=\"60px\" alt=\"User avatar: Ben Elan\" /></a><a href=\"https://github.com/pawelduda\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pawelduda.png\" width=\"60px\" alt=\"User avatar: Paweł Duda\" /></a><a href=\"https://github.com/pbwn\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pbwn.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/pyrho\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pyrho.png\" width=\"60px\" alt=\"User avatar: Damien Rajon\" /></a><a href=\"https://github.com/ArtBIT\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ArtBIT.png\" width=\"60px\" alt=\"User avatar: ArtBIT\" /></a><a href=\"https://github.com/da-moon\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;da-moon.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/hovissimo\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;hovissimo.png\" width=\"60px\" alt=\"User avatar: Hovis\" /></a><a href=\"https://github.com/Yarden-zamir\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Yarden-zamir.png\" width=\"60px\" alt=\"User avatar: Yarden zamir\" /></a><a href=\"https://github.com/dariusjonda\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;dariusjonda.png\" width=\"60px\" alt=\"User avatar: Darius Jonda\" /></a><a href=\"https://github.com/cristiand391\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;cristiand391.png\" width=\"60px\" alt=\"User avatar: Cristian Dominguez\" /></a><a href=\"https://github.com/eliangcs\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;eliangcs.png\" width=\"60px\" alt=\"User avatar: Chang-Hung Liang\" /></a><a href=\"https://github.com/asphaltbuffet\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;asphaltbuffet.png\" width=\"60px\" alt=\"User avatar: Ben Lechlitner\" /></a><a href=\"https://github.com/looshch\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;looshch.png\" width=\"60px\" alt=\"User avatar: george looshch\" /></a><a href=\"https://github.com/kg8m\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;kg8m.png\" width=\"60px\" alt=\"User avatar: Takumi KAGIYAMA\" /></a><a href=\"https://github.com/polm\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;polm.png\" width=\"60px\" alt=\"User avatar: Paul OLeary McCann\" /></a><a href=\"https://github.com/rbeeger\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;rbeeger.png\" width=\"60px\" alt=\"User avatar: Robert Beeger\" /></a><a href=\"https://github.com/yowayb\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;yowayb.png\" width=\"60px\" alt=\"User avatar: Yoway Buorn\" /></a><a href=\"https://github.com/scalisi\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;scalisi.png\" width=\"60px\" alt=\"User avatar: Josh Scalisi\" /></a><a href=\"https://github.com/alecbcs\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;alecbcs.png\" width=\"60px\" alt=\"User avatar: Alec Scott\" /></a><a href=\"https://github.com/thnxdev\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;thnxdev.png\" width=\"60px\" alt=\"User avatar: thanks.dev\" /></a><a href=\"https://github.com/artursapek\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;artursapek.png\" width=\"60px\" alt=\"User avatar: Artur Sapek\" /></a><a href=\"https://github.com/ramnes\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ramnes.png\" width=\"60px\" alt=\"User avatar: Guillaume Gelin\" /></a><a href=\"https://github.com/jyc\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jyc.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/roblevy\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;roblevy.png\" width=\"60px\" alt=\"User avatar: Rob Levy\" /></a><a href=\"https://github.com/glozow\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;glozow.png\" width=\"60px\" alt=\"User avatar: Gloria Zhao\" /></a><a href=\"https://github.com/toupeira\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;toupeira.png\" width=\"60px\" alt=\"User avatar: Markus Koller\" /></a><a href=\"https://github.com/rkpatel33\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;rkpatel33.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/jamesob\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jamesob.png\" width=\"60px\" alt=\"User avatar: jamesob\" /></a><a href=\"https://github.com/jlebray\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jlebray.png\" width=\"60px\" alt=\"User avatar: Johan Le Bray\" /></a><a href=\"https://github.com/panosl1\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;panosl1.png\" width=\"60px\" alt=\"User avatar: Panos Lampropoulos\" /></a><a href=\"https://github.com/bespinian\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bespinian.png\" width=\"60px\" alt=\"User avatar: bespinian\" /></a><a href=\"https://github.com/scosu\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;scosu.png\" width=\"60px\" alt=\"User avatar: Markus Schneider-Pargmann\" /></a><a href=\"https://github.com/smithbm2316\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;smithbm2316.png\" width=\"60px\" alt=\"User avatar: Ben Smith\" /></a><a href=\"https://github.com/charlieegan3\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;charlieegan3.png\" width=\"60px\" alt=\"User avatar: Charlie Egan\" /></a><a href=\"https://github.com/thobbs\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;thobbs.png\" width=\"60px\" alt=\"User avatar: Tyler Hobbs\" /></a><a href=\"https://github.com/neilparikh\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;neilparikh.png\" width=\"60px\" alt=\"User avatar: Neil Parikh\" /></a><a href=\"https://github.com/shkm\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;shkm.png\" width=\"60px\" alt=\"User avatar: Jamie Schembri\" /></a><a href=\"https://github.com/BasedScience\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;BasedScience.png\" width=\"60px\" alt=\"User avatar: dockien\" /></a><a href=\"https://github.com/RussellGilmore\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;RussellGilmore.png\" width=\"60px\" alt=\"User avatar: Russell Gilmore\" /></a><a href=\"https://github.com/meribold\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;meribold.png\" width=\"60px\" alt=\"User avatar: Lukas Waymann\" /></a><a href=\"https://github.com/terminaldweller\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;terminaldweller.png\" width=\"60px\" alt=\"User avatar: Farzad Sadeghi\" /></a><a href=\"https://github.com/jaydee-coder\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jaydee-coder.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/TaNorbs\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;TaNorbs.png\" width=\"60px\" alt=\"User avatar: Norbs\" /></a><a href=\"https://github.com/iveteran\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;iveteran.png\" width=\"60px\" alt=\"User avatar: Yu\" /></a><a href=\"https://github.com/fvalasiad\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;fvalasiad.png\" width=\"60px\" alt=\"User avatar: Fotios Valasiadis\" /></a><a href=\"https://github.com/chillax\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;chillax.png\" width=\"60px\" alt=\"User avatar: Joonas Korhonen\" /></a><a href=\"https://github.com/brpaz\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;brpaz.png\" width=\"60px\" alt=\"User avatar: Bruno Paz\" /></a><a href=\"https://github.com/flanaras\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;flanaras.png\" width=\"60px\" alt=\"User avatar: Filippos Lanaras\" /></a><a href=\"https://github.com/freshleafmedia\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;freshleafmedia.png\" width=\"60px\" alt=\"User avatar: Freshleaf Media\" /></a><a href=\"https://github.com/Unambiguous\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Unambiguous.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/timobenn\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;timobenn.png\" width=\"60px\" alt=\"User avatar: Timothy Bennett\" /></a><!-- sponsors -->\n\nTable of Contents\n-----------------\n\n<!-- vim-markdown-toc GFM -->\n\n* [Installation](#installation)\n    * [Using Homebrew](#using-homebrew)\n    * [Linux packages](#linux-packages)\n    * [Windows packages](#windows-packages)\n    * [Using git](#using-git)\n    * [Binary releases](#binary-releases)\n    * [Setting up shell integration](#setting-up-shell-integration)\n    * [Vim/Neovim plugin](#vimneovim-plugin)\n* [Upgrading fzf](#upgrading-fzf)\n* [Building fzf](#building-fzf)\n* [Usage](#usage)\n    * [Using the finder](#using-the-finder)\n    * [Display modes](#display-modes)\n        * [`--height` mode](#--height-mode)\n        * [`--tmux` mode](#--tmux-mode)\n    * [Search syntax](#search-syntax)\n    * [Environment variables](#environment-variables)\n    * [Options](#options)\n    * [Demo](#demo)\n* [Examples](#examples)\n* [Key bindings for command-line](#key-bindings-for-command-line)\n* [Fuzzy completion for bash and zsh](#fuzzy-completion-for-bash-and-zsh)\n    * [Files and directories](#files-and-directories)\n    * [Process IDs](#process-ids)\n    * [Host names](#host-names)\n    * [Environment variables / Aliases](#environment-variables--aliases)\n    * [Customizing fzf options for completion](#customizing-fzf-options-for-completion)\n    * [Customizing completion source for paths and directories](#customizing-completion-source-for-paths-and-directories)\n    * [Supported commands](#supported-commands)\n    * [Custom fuzzy completion](#custom-fuzzy-completion)\n* [Vim plugin](#vim-plugin)\n* [Advanced topics](#advanced-topics)\n    * [Performance](#performance)\n    * [Executing external programs](#executing-external-programs)\n    * [Turning into a different process](#turning-into-a-different-process)\n    * [Reloading the candidate list](#reloading-the-candidate-list)\n        * [1. Update the list of processes by pressing CTRL-R](#1-update-the-list-of-processes-by-pressing-ctrl-r)\n        * [2. Switch between sources by pressing CTRL-D or CTRL-F](#2-switch-between-sources-by-pressing-ctrl-d-or-ctrl-f)\n        * [3. Interactive ripgrep integration](#3-interactive-ripgrep-integration)\n    * [Preview window](#preview-window)\n    * [Previewing an image](#previewing-an-image)\n* [Tips](#tips)\n    * [Respecting `.gitignore`](#respecting-gitignore)\n    * [Fish shell](#fish-shell)\n    * [fzf Theme Playground](#fzf-theme-playground)\n* [Related projects](#related-projects)\n* [License](#license)\n\n<!-- vim-markdown-toc -->\n\nInstallation\n------------\n\n### Using Homebrew\n\nYou can use [Homebrew](https://brew.sh/) (on macOS or Linux) to install fzf.\n\n```sh\nbrew install fzf\n```\n\n> [!IMPORTANT]\n> To set up shell integration (key bindings and fuzzy completion),\n> see [the instructions below](#setting-up-shell-integration).\n\nfzf is also available [via MacPorts][portfile]: `sudo port install fzf`\n\n[portfile]: https://github.com/macports/macports-ports/blob/master/sysutils/fzf/Portfile\n\n### Linux packages\n\n| Package Manager | Linux Distribution      | Command                            |\n| --------------- | ----------------------- | ---------------------------------- |\n| APK             | Alpine Linux            | `sudo apk add fzf`                 |\n| APT             | Debian 9+/Ubuntu 19.10+ | `sudo apt install fzf`             |\n| Conda           |                         | `conda install -c conda-forge fzf` |\n| DNF             | Fedora                  | `sudo dnf install fzf`             |\n| Nix             | NixOS, etc.             | `nix-env -iA nixpkgs.fzf`          |\n| Pacman          | Arch Linux              | `sudo pacman -S fzf`               |\n| pkg             | FreeBSD                 | `pkg install fzf`                  |\n| pkgin           | NetBSD                  | `pkgin install fzf`                |\n| pkg_add         | OpenBSD                 | `pkg_add fzf`                      |\n| Portage         | Gentoo                  | `emerge --ask app-shells/fzf`      |\n| Spack           |                         | `spack install fzf`                |\n| XBPS            | Void Linux              | `sudo xbps-install -S fzf`         |\n| Zypper          | openSUSE                | `sudo zypper install fzf`          |\n\n> [!IMPORTANT]\n> To set up shell integration (key bindings and fuzzy completion),\n> see [the instructions below](#setting-up-shell-integration).\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/fzf.svg?columns=3)](https://repology.org/project/fzf/versions)\n\n### Windows packages\n\nOn Windows, fzf is available via [Chocolatey][choco], [Scoop][scoop],\n[Winget][winget], and [MSYS2][msys2]:\n\n| Package manager | Command                               |\n| --------------- | ------------------------------------- |\n| Chocolatey      | `choco install fzf`                   |\n| Scoop           | `scoop install fzf`                   |\n| Winget          | `winget install fzf`                  |\n| MSYS2 (pacman)  | `pacman -S $MINGW_PACKAGE_PREFIX-fzf` |\n\n[choco]: https://chocolatey.org/packages/fzf\n[scoop]: https://github.com/ScoopInstaller/Main/blob/master/bucket/fzf.json\n[winget]: https://github.com/microsoft/winget-pkgs/tree/master/manifests/j/junegunn/fzf\n[msys2]: https://packages.msys2.org/base/mingw-w64-fzf\n\n### Using git\n\nAlternatively, you can \"git clone\" this repository to any directory and run\n[install](https://github.com/junegunn/fzf/blob/master/install) script.\n\n```sh\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf\n~/.fzf/install\n```\n\nThe install script will add lines to your shell configuration file to modify\n`$PATH` and set up shell integration.\n\n### Binary releases\n\nYou can download the official fzf binaries from the releases page.\n\n* https://github.com/junegunn/fzf/releases\n\n### Setting up shell integration\n\nAdd the following line to your shell configuration file.\n\n* bash\n  ```sh\n  # Set up fzf key bindings and fuzzy completion\n  eval \"$(fzf --bash)\"\n  ```\n* zsh\n  ```sh\n  # Set up fzf key bindings and fuzzy completion\n  source <(fzf --zsh)\n  ```\n* fish\n  ```fish\n  # Set up fzf key bindings\n  fzf --fish | source\n  ```\n\n> [!NOTE]\n> `--bash`, `--zsh`, and `--fish` options are only available in fzf 0.48.0 or\n> later. If you have an older version of fzf, or want finer control, you can\n> source individual script files in the [/shell](/shell) directory. The\n> location of the files may vary depending on the package manager you use.\n> Please refer to the package documentation for more information.\n> (e.g. `apt show fzf`)\n\n> [!TIP]\n> You can disable CTRL-T or ALT-C binding by setting `FZF_CTRL_T_COMMAND` or\n> `FZF_ALT_C_COMMAND` to an empty string when sourcing the script.\n> For example, to disable ALT-C binding:\n>\n> * bash: `FZF_ALT_C_COMMAND= eval \"$(fzf --bash)\"`\n> * zsh: `FZF_ALT_C_COMMAND= source <(fzf --zsh)`\n> * fish: `fzf --fish | FZF_ALT_C_COMMAND= source`\n>\n> Setting the variables after sourcing the script will have no effect.\n\n### Vim/Neovim plugin\n\nIf you use [vim-plug](https://github.com/junegunn/vim-plug), add this to\nyour Vim configuration file:\n\n```vim\nPlug 'junegunn/fzf', { 'do': { -> fzf#install() } }\nPlug 'junegunn/fzf.vim'\n```\n\n* `junegunn/fzf` provides the basic library functions\n    * `fzf#install()` makes sure that you have the latest binary\n* `junegunn/fzf.vim` is [a separate project](https://github.com/junegunn/fzf.vim)\n  that provides a variety of useful commands\n\nTo learn more about the Vim integration, see [README-VIM.md](README-VIM.md).\n\n> [!TIP]\n> If you use Neovim and prefer Lua-based plugins, check out\n> [fzf-lua](https://github.com/ibhagwan/fzf-lua).\n\nUpgrading fzf\n-------------\n\nfzf is being actively developed, and you might want to upgrade it once in a\nwhile. Please follow the instruction below depending on the installation\nmethod used.\n\n- git: `cd ~/.fzf && git pull && ./install`\n- brew: `brew update; brew upgrade fzf`\n- macports: `sudo port upgrade fzf`\n- chocolatey: `choco upgrade fzf`\n- vim-plug: `:PlugUpdate fzf`\n\nBuilding fzf\n------------\n\nSee [BUILD.md](BUILD.md).\n\nUsage\n-----\n\nfzf will launch interactive finder, read the list from STDIN, and write the\nselected item to STDOUT.\n\n```sh\nfind * -type f | fzf > selected\n```\n\nWithout STDIN pipe, fzf will traverse the file system under the current\ndirectory to get the list of files.\n\n```sh\nvim $(fzf)\n```\n\n> [!NOTE]\n> You can override the default behavior\n> * Either by setting `$FZF_DEFAULT_COMMAND` to a command that generates the desired list\n> * Or by setting `--walker`, `--walker-root`, and `--walker-skip` options in `$FZF_DEFAULT_OPTS`\n\n> [!WARNING]\n> A more robust solution would be to use `xargs` but we've presented\n> the above as it's easier to grasp\n> ```sh\n> fzf --print0 | xargs -0 -o vim\n> ```\n\n> [!TIP]\n> fzf also has the ability to turn itself into a different process.\n>\n> ```sh\n> fzf --bind 'enter:become(vim {})'\n> ```\n>\n> *See [Turning into a different process](#turning-into-a-different-process)\n> for more information.*\n\n### Using the finder\n\n- `CTRL-K` / `CTRL-J` (or `CTRL-P` / `CTRL-N`) to move cursor up and down\n- `Enter` key to select the item, `CTRL-C` / `CTRL-G` / `ESC` to exit\n- On multi-select mode (`-m`), `TAB` and `Shift-TAB` to mark multiple items\n- Emacs style key bindings\n- Mouse: scroll, click, double-click; shift-click and shift-scroll on\n  multi-select mode\n\n### Display modes\n\nfzf by default runs in fullscreen mode, but there are other display modes.\n\n#### `--height` mode\n\nWith `--height HEIGHT[%]`, fzf will start below the cursor with the given height.\n\n```sh\nfzf --height 40%\n```\n\n`reverse` layout and `--border` goes well with this option.\n\n```sh\nfzf --height 40% --layout reverse --border\n```\n\nBy prepending `~` to the height, you're setting the maximum height.\n\n```sh\n# Will take as few lines as possible to display the list\nseq 3 | fzf --height ~100%\nseq 3000 | fzf --height ~100%\n```\n\nHeight value can be a negative number.\n\n```sh\n# Screen height - 3\nfzf --height -3\n```\n\n#### `--tmux` mode\n\nWith `--tmux` option, fzf will start in a tmux popup.\n\n```sh\n# --tmux [center|top|bottom|left|right][,SIZE[%]][,SIZE[%][,border-native]]\n\nfzf --tmux center         # Center, 50% width and height\nfzf --tmux 80%            # Center, 80% width and height\nfzf --tmux 100%,50%       # Center, 100% width and 50% height\nfzf --tmux left,40%       # Left, 40% width\nfzf --tmux left,40%,90%   # Left, 40% width, 90% height\nfzf --tmux top,40%        # Top, 40% height\nfzf --tmux bottom,80%,40% # Bottom, 80% height, 40% height\n```\n\n`--tmux` is silently ignored when you're not on tmux.\n\n> [!NOTE]\n> If you're stuck with an old version of tmux that doesn't support popup,\n> or if you want to open fzf in a regular tmux pane, check out\n> [fzf-tmux](bin/fzf-tmux) script.\n\n> [!TIP]\n> You can add these options to `$FZF_DEFAULT_OPTS` so that they're applied by\n> default. For example,\n>\n> ```sh\n> # Open in tmux popup if on tmux, otherwise use --height mode\n> export FZF_DEFAULT_OPTS='--height 40% --tmux bottom,40% --layout reverse --border top'\n> ```\n\n### Search syntax\n\nUnless otherwise specified, fzf starts in \"extended-search mode\" where you can\ntype in multiple search terms delimited by spaces. e.g. `^music .mp3$ sbtrkt\n!fire`\n\n| Token     | Match type                              | Description                                  |\n| --------- | --------------------------------------  | ------------------------------------------   |\n| `sbtrkt`  | fuzzy-match                             | Items that match `sbtrkt`                    |\n| `'wild`   | exact-match (quoted)                    | Items that include `wild`                    |\n| `'wild'`  | exact-boundary-match (quoted both ends) | Items that include `wild` at word boundaries |\n| `^music`  | prefix-exact-match                      | Items that start with `music`                |\n| `.mp3$`   | suffix-exact-match                      | Items that end with `.mp3`                   |\n| `!fire`   | inverse-exact-match                     | Items that do not include `fire`             |\n| `!^music` | inverse-prefix-exact-match              | Items that do not start with `music`         |\n| `!.mp3$`  | inverse-suffix-exact-match              | Items that do not end with `.mp3`            |\n\nIf you don't prefer fuzzy matching and do not wish to \"quote\" every word,\nstart fzf with `-e` or `--exact` option. Note that when  `--exact` is set,\n`'`-prefix \"unquotes\" the term.\n\nA single bar character term acts as an OR operator. For example, the following\nquery matches entries that start with `core` and end with either `go`, `rb`,\nor `py`.\n\n```\n^core go$ | rb$ | py$\n```\n\n### Environment variables\n\n- `FZF_DEFAULT_COMMAND`\n    - Default command to use when input is tty\n    - e.g. `export FZF_DEFAULT_COMMAND='fd --type f'`\n- `FZF_DEFAULT_OPTS`\n    - Default options\n    - e.g. `export FZF_DEFAULT_OPTS=\"--layout=reverse --inline-info\"`\n- `FZF_DEFAULT_OPTS_FILE`\n    - If you prefer to manage default options in a file, set this variable to\n      point to the location of the file\n    - e.g. `export FZF_DEFAULT_OPTS_FILE=~/.fzfrc`\n\n> [!WARNING]\n> `FZF_DEFAULT_COMMAND` is not used by shell integration due to the\n> slight difference in requirements.\n>\n> * `CTRL-T` runs `$FZF_CTRL_T_COMMAND` to get a list of files and directories\n> * `ALT-C` runs `$FZF_ALT_C_COMMAND` to get a list of directories\n> * `vim ~/**<tab>` runs `fzf_compgen_path()` with the prefix (`~/`) as the first argument\n> * `cd foo**<tab>` runs `fzf_compgen_dir()` with the prefix (`foo`) as the first argument\n>\n> The available options are described later in this document.\n\n### Options\n\nSee the man page (`man fzf`) for the full list of options.\n\n### Demo\nIf you learn by watching videos, check out this screencast by [@samoshkin](https://github.com/samoshkin) to explore `fzf` features.\n\n<a title=\"fzf - command-line fuzzy finder\" href=\"https://www.youtube.com/watch?v=qgG5Jhi_Els\">\n  <img src=\"https://i.imgur.com/vtG8olE.png\" width=\"640\">\n</a>\n\nExamples\n--------\n\n* [Wiki page of examples](https://github.com/junegunn/fzf/wiki/examples)\n    * *Disclaimer: The examples on this page are maintained by the community\n      and are not thoroughly tested*\n* [Advanced fzf examples](https://github.com/junegunn/fzf/blob/master/ADVANCED.md)\n\nKey bindings for command-line\n-----------------------------\n\nBy [setting up shell integration](#setting-up-shell-integration), you can use\nthe following key bindings in bash, zsh, and fish.\n\n- `CTRL-T` - Paste the selected files and directories onto the command-line\n    - The list is generated using `--walker file,dir,follow,hidden` option\n        - You can override the behavior by setting `FZF_CTRL_T_COMMAND` to a custom command that generates the desired list\n        - Or you can set `--walker*` options in `FZF_CTRL_T_OPTS`\n    - Set `FZF_CTRL_T_OPTS` to pass additional options to fzf\n      ```sh\n      # Preview file content using bat (https://github.com/sharkdp/bat)\n      export FZF_CTRL_T_OPTS=\"\n        --walker-skip .git,node_modules,target\n        --preview 'bat -n --color=always {}'\n        --bind 'ctrl-/:change-preview-window(down|hidden|)'\"\n      ```\n    - Can be disabled by setting `FZF_CTRL_T_COMMAND` to an empty string when\n      sourcing the script\n- `CTRL-R` - Paste the selected command from history onto the command-line\n    - If you want to see the commands in chronological order, press `CTRL-R`\n      again which toggles sorting by relevance\n    - Press `CTRL-/` or `ALT-/` to toggle line wrapping\n    - Set `FZF_CTRL_R_OPTS` to pass additional options to fzf\n      ```sh\n      # CTRL-Y to copy the command into clipboard using pbcopy\n      export FZF_CTRL_R_OPTS=\"\n        --bind 'ctrl-y:execute-silent(echo -n {2..} | pbcopy)+abort'\n        --color header:italic\n        --header 'Press CTRL-Y to copy command into clipboard'\"\n      ```\n- `ALT-C` - cd into the selected directory\n    - The list is generated using `--walker dir,follow,hidden` option\n    - Set `FZF_ALT_C_COMMAND` to override the default command\n        - Or you can set `--walker-*` options in `FZF_ALT_C_OPTS`\n    - Set `FZF_ALT_C_OPTS` to pass additional options to fzf\n      ```sh\n      # Print tree structure in the preview window\n      export FZF_ALT_C_OPTS=\"\n        --walker-skip .git,node_modules,target\n        --preview 'tree -C {}'\"\n      ```\n    - Can be disabled by setting `FZF_ALT_C_COMMAND` to an empty string when\n      sourcing the script\n\nDisplay modes for these bindings can be separately configured via\n`FZF_{CTRL_T,CTRL_R,ALT_C}_OPTS` or globally via `FZF_DEFAULT_OPTS`.\n(e.g. `FZF_CTRL_R_OPTS='--tmux bottom,60% --height 60% --border top'`)\n\nMore tips can be found on [the wiki page](https://github.com/junegunn/fzf/wiki/Configuring-shell-key-bindings).\n\nFuzzy completion for bash and zsh\n---------------------------------\n\n### Files and directories\n\nFuzzy completion for files and directories can be triggered if the word before\nthe cursor ends with the trigger sequence, which is by default `**`.\n\n- `COMMAND [DIRECTORY/][FUZZY_PATTERN]**<TAB>`\n\n```sh\n# Files under the current directory\n# - You can select multiple items with TAB key\nvim **<TAB>\n\n# Files under parent directory\nvim ../**<TAB>\n\n# Files under parent directory that match `fzf`\nvim ../fzf**<TAB>\n\n# Files under your home directory\nvim ~/**<TAB>\n\n\n# Directories under current directory (single-selection)\ncd **<TAB>\n\n# Directories under ~/github that match `fzf`\ncd ~/github/fzf**<TAB>\n```\n\n### Process IDs\n\nFuzzy completion for PIDs is provided for kill command.\n\n```sh\n# Can select multiple processes with <TAB> or <Shift-TAB> keys\nkill -9 **<TAB>\n```\n\n### Host names\n\nFor ssh and telnet commands, fuzzy completion for hostnames is provided. The\nnames are extracted from /etc/hosts and ~/.ssh/config.\n\n```sh\nssh **<TAB>\ntelnet **<TAB>\n```\n\n### Environment variables / Aliases\n\n```sh\nunset **<TAB>\nexport **<TAB>\nunalias **<TAB>\n```\n\n### Customizing fzf options for completion\n\n```sh\n# Use ~~ as the trigger sequence instead of the default **\nexport FZF_COMPLETION_TRIGGER='~~'\n\n# Options to fzf command\nexport FZF_COMPLETION_OPTS='--border --info=inline'\n\n# Options for path completion (e.g. vim **<TAB>)\nexport FZF_COMPLETION_PATH_OPTS='--walker file,dir,follow,hidden'\n\n# Options for directory completion (e.g. cd **<TAB>)\nexport FZF_COMPLETION_DIR_OPTS='--walker dir,follow'\n\n# Advanced customization of fzf options via _fzf_comprun function\n# - The first argument to the function is the name of the command.\n# - You should make sure to pass the rest of the arguments ($@) to fzf.\n_fzf_comprun() {\n  local command=$1\n  shift\n\n  case \"$command\" in\n    cd)           fzf --preview 'tree -C {} | head -200'   \"$@\" ;;\n    export|unset) fzf --preview \"eval 'echo \\$'{}\"         \"$@\" ;;\n    ssh)          fzf --preview 'dig {}'                   \"$@\" ;;\n    *)            fzf --preview 'bat -n --color=always {}' \"$@\" ;;\n  esac\n}\n```\n\n### Customizing completion source for paths and directories\n\n```sh\n# Use fd (https://github.com/sharkdp/fd) for listing path candidates.\n# - The first argument to the function ($1) is the base path to start traversal\n# - See the source code (completion.{bash,zsh}) for the details.\n_fzf_compgen_path() {\n  fd --hidden --follow --exclude \".git\" . \"$1\"\n}\n\n# Use fd to generate the list for directory completion\n_fzf_compgen_dir() {\n  fd --type d --hidden --follow --exclude \".git\" . \"$1\"\n}\n```\n\n### Supported commands\n\nOn bash, fuzzy completion is enabled only for a predefined set of commands\n(`complete | grep _fzf` to see the list). But you can enable it for other\ncommands as well by using `_fzf_setup_completion` helper function.\n\n```sh\n# usage: _fzf_setup_completion path|dir|var|alias|host COMMANDS...\n_fzf_setup_completion path ag git kubectl\n_fzf_setup_completion dir tree\n```\n\n### Custom fuzzy completion\n\n_**(Custom completion API is experimental and subject to change)**_\n\nFor a command named _\"COMMAND\"_, define `_fzf_complete_COMMAND` function using\n`_fzf_complete` helper.\n\n```sh\n# Custom fuzzy completion for \"doge\" command\n#   e.g. doge **<TAB>\n_fzf_complete_doge() {\n  _fzf_complete --multi --reverse --prompt=\"doge> \" -- \"$@\" < <(\n    echo very\n    echo wow\n    echo such\n    echo doge\n  )\n}\n```\n\n- The arguments before `--` are the options to fzf.\n- After `--`, simply pass the original completion arguments unchanged (`\"$@\"`).\n- Then, write a set of commands that generates the completion candidates and\n  feed its output to the function using process substitution (`< <(...)`).\n\nzsh will automatically pick up the function using the naming convention but in\nbash you have to manually associate the function with the command using the\n`complete` command.\n\n```sh\n[ -n \"$BASH\" ] && complete -F _fzf_complete_doge -o default -o bashdefault doge\n```\n\nIf you need to post-process the output from fzf, define\n`_fzf_complete_COMMAND_post` as follows.\n\n```sh\n_fzf_complete_foo() {\n  _fzf_complete --multi --reverse --header-lines=3 -- \"$@\" < <(\n    ls -al\n  )\n}\n\n_fzf_complete_foo_post() {\n  awk '{print $NF}'\n}\n\n[ -n \"$BASH\" ] && complete -F _fzf_complete_foo -o default -o bashdefault foo\n```\n\nVim plugin\n----------\n\nSee [README-VIM.md](README-VIM.md).\n\nAdvanced topics\n---------------\n\n### Performance\n\nfzf is fast. Performance should not be a problem in most use cases. However,\nyou might want to be aware of the options that can affect performance.\n\n- `--ansi` tells fzf to extract and parse ANSI color codes in the input, and it\n  makes the initial scanning slower. So it's not recommended that you add it\n  to your `$FZF_DEFAULT_OPTS`.\n- `--nth` makes fzf slower because it has to tokenize each line.\n- `--with-nth` makes fzf slower as fzf has to tokenize and reassemble each\n  line.\n\n### Executing external programs\n\nYou can set up key bindings for starting external processes without leaving\nfzf (`execute`, `execute-silent`).\n\n```bash\n# Press F1 to open the file with less without leaving fzf\n# Press CTRL-Y to copy the line to clipboard and aborts fzf (requires pbcopy)\nfzf --bind 'f1:execute(less -f {}),ctrl-y:execute-silent(echo {} | pbcopy)+abort'\n```\n\nSee *KEY BINDINGS* section of the man page for details.\n\n### Turning into a different process\n\n`become(...)` is similar to `execute(...)`/`execute-silent(...)` described\nabove, but instead of executing the command and coming back to fzf on\ncomplete, it turns fzf into a new process for the command.\n\n```sh\nfzf --bind 'enter:become(vim {})'\n```\n\nCompared to the seemingly equivalent command substitution `vim \"$(fzf)\"`, this\napproach has several advantages:\n\n* Vim will not open an empty file when you terminate fzf with\n  <kbd>CTRL-C</kbd>\n* Vim will not open an empty file when you press <kbd>ENTER</kbd> on an empty\n  result\n* Can handle multiple selections even when they have whitespaces\n  ```sh\n  fzf --multi --bind 'enter:become(vim {+})'\n  ```\n\nTo be fair, running `fzf --print0 | xargs -0 -o vim` instead of `vim \"$(fzf)\"`\nresolves all of the issues mentioned. Nonetheless, `become(...)` still offers\nadditional benefits in different scenarios.\n\n* You can set up multiple bindings to handle the result in different ways\n  without any wrapping script\n  ```sh\n  fzf --bind 'enter:become(vim {}),ctrl-e:become(emacs {})'\n  ```\n  * Previously, you would have to use `--expect=ctrl-e` and check the first\n    line of the output of fzf\n* You can easily build the subsequent command using the field index\n  expressions of fzf\n  ```sh\n  # Open the file in Vim and go to the line\n  git grep --line-number . |\n      fzf --delimiter : --nth 3.. --bind 'enter:become(vim {1} +{2})'\n  ```\n\n### Reloading the candidate list\n\nBy binding `reload` action to a key or an event, you can make fzf dynamically\nreload the candidate list. See https://github.com/junegunn/fzf/issues/1750 for\nmore details.\n\n#### 1. Update the list of processes by pressing CTRL-R\n\n```sh\nps -ef |\n  fzf --bind 'ctrl-r:reload(ps -ef)' \\\n      --header 'Press CTRL-R to reload' --header-lines=1 \\\n      --height=50% --layout=reverse\n```\n\n#### 2. Switch between sources by pressing CTRL-D or CTRL-F\n\n```sh\nFZF_DEFAULT_COMMAND='find . -type f' \\\n  fzf --bind 'ctrl-d:reload(find . -type d),ctrl-f:reload(eval \"$FZF_DEFAULT_COMMAND\")' \\\n      --height=50% --layout=reverse\n```\n\n#### 3. Interactive ripgrep integration\n\nThe following example uses fzf as the selector interface for ripgrep. We bound\n`reload` action to `change` event, so every time you type on fzf, the ripgrep\nprocess will restart with the updated query string denoted by the placeholder\nexpression `{q}`. Also, note that we used `--disabled` option so that fzf\ndoesn't perform any secondary filtering.\n\n```sh\n: | rg_prefix='rg --column --line-number --no-heading --color=always --smart-case' \\\n    fzf --bind 'start:reload:$rg_prefix \"\"' \\\n        --bind 'change:reload:$rg_prefix {q} || true' \\\n        --bind 'enter:become(vim {1} +{2})' \\\n        --ansi --disabled \\\n        --height=50% --layout=reverse\n```\n\nIf ripgrep doesn't find any matches, it will exit with a non-zero exit status,\nand fzf will warn you about it. To suppress the warning message, we added\n`|| true` to the command, so that it always exits with 0.\n\nSee [\"Using fzf as interactive Ripgrep launcher\"](https://github.com/junegunn/fzf/blob/master/ADVANCED.md#using-fzf-as-interactive-ripgrep-launcher)\nfor more sophisticated examples.\n\n### Preview window\n\nWhen the `--preview` option is set, fzf automatically starts an external process\nwith the current line as the argument and shows the result in the split window.\nYour `$SHELL` is used to execute the command with `$SHELL -c COMMAND`.\nThe window can be scrolled using the mouse or custom key bindings.\n\n```bash\n# {} is replaced with the single-quoted string of the focused line\nfzf --preview 'cat {}'\n```\n\nPreview window supports ANSI colors, so you can use any program that\nsyntax-highlights the content of a file, such as\n[Bat](https://github.com/sharkdp/bat) or\n[Highlight](https://gitlab.com/saalen/highlight):\n\n```bash\nfzf --preview 'bat --color=always {}' --preview-window '~3'\n```\n\nYou can customize the size, position, and border of the preview window using\n`--preview-window` option, and the foreground and background color of it with\n`--color` option. For example,\n\n```bash\nfzf --height 40% --layout reverse --info inline --border \\\n    --preview 'file {}' --preview-window up,1,border-horizontal \\\n    --bind 'ctrl-/:change-preview-window(50%|hidden|)' \\\n    --color 'fg:#bbccdd,fg+:#ddeeff,bg:#334455,preview-bg:#223344,border:#778899'\n```\n\nSee the man page (`man fzf`) for the full list of options.\n\nMore advanced examples can be found [here](https://github.com/junegunn/fzf/blob/master/ADVANCED.md).\n\n> [!WARNING]\n> Since fzf is a general-purpose text filter rather than a file finder, **it is\n> not a good idea to add `--preview` option to your `$FZF_DEFAULT_OPTS`**.\n>\n> ```sh\n> # *********************\n> # ** DO NOT DO THIS! **\n> # *********************\n> export FZF_DEFAULT_OPTS='--preview \"bat --style=numbers --color=always --line-range :500 {}\"'\n>\n> # bat doesn't work with any input other than the list of files\n> ps -ef | fzf\n> seq 100 | fzf\n> history | fzf\n> ```\n\n### Previewing an image\n\nfzf can display images in the preview window using one of the following protocols:\n\n* [Kitty graphics protocol](https://sw.kovidgoyal.net/kitty/graphics-protocol/)\n* [iTerm2 inline images protocol](https://iterm2.com/documentation-images.html)\n* [Sixel](https://en.wikipedia.org/wiki/Sixel)\n\nSee [bin/fzf-preview.sh](bin/fzf-preview.sh) script for more information.\n\n```sh\nfzf --preview 'fzf-preview.sh {}'\n```\n\nTips\n----\n\n### Respecting `.gitignore`\n\nYou can use [fd](https://github.com/sharkdp/fd),\n[ripgrep](https://github.com/BurntSushi/ripgrep), or [the silver\nsearcher](https://github.com/ggreer/the_silver_searcher) to traverse the file\nsystem while respecting `.gitignore`.\n\n```sh\n# Feed the output of fd into fzf\nfd --type f --strip-cwd-prefix | fzf\n\n# Setting fd as the default source for fzf\nexport FZF_DEFAULT_COMMAND='fd --type f --strip-cwd-prefix'\n\n# Now fzf (w/o pipe) will use the fd command to generate the list\nfzf\n\n# To apply the command to CTRL-T as well\nexport FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\n```\n\nIf you want the command to follow symbolic links and don't want it to exclude\nhidden files, use the following command:\n\n```sh\nexport FZF_DEFAULT_COMMAND='fd --type f --strip-cwd-prefix --hidden --follow --exclude .git'\n```\n\n### Fish shell\n\n`CTRL-T` key binding of fish, unlike those of bash and zsh, will use the last\ntoken on the command-line as the root directory for the recursive search. For\ninstance, hitting `CTRL-T` at the end of the following command-line\n\n```sh\nls /var/\n```\n\nwill list all files and directories under `/var/`.\n\nWhen using a custom `FZF_CTRL_T_COMMAND`, use the unexpanded `$dir` variable to\nmake use of this feature. `$dir` defaults to `.` when the last token is not a\nvalid directory. Example:\n\n```sh\nset -g FZF_CTRL_T_COMMAND \"command find -L \\$dir -type f 2> /dev/null | sed '1d; s#^\\./##'\"\n```\n\n### fzf Theme Playground\n\n[fzf Theme Playground](https://vitormv.github.io/fzf-themes/) created by\n[Vitor Mello](https://github.com/vitormv) is a webpage where you can\ninteractively create fzf themes.\n\nRelated projects\n----------------\n\nhttps://github.com/junegunn/fzf/wiki/Related-projects\n\n[License](LICENSE)\n------------------\n\nThe MIT License (MIT)\n\nCopyright (c) 2013-2024 Junegunn Choi\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.51,
          "content": "module github.com/junegunn/fzf\n\nrequire (\n\tgithub.com/charlievieth/fastwalk v1.0.9\n\tgithub.com/gdamore/tcell/v2 v2.7.4\n\tgithub.com/junegunn/go-shellwords v0.0.0-20240813092932-a62c48c52e97\n\tgithub.com/mattn/go-isatty v0.0.20\n\tgithub.com/rivo/uniseg v0.4.7\n\tgolang.org/x/sys v0.29.0\n\tgolang.org/x/term v0.28.0\n)\n\nrequire (\n\tgithub.com/gdamore/encoding v1.0.0 // indirect\n\tgithub.com/lucasb-eyer/go-colorful v1.2.0 // indirect\n\tgithub.com/mattn/go-runewidth v0.0.15 // indirect\n\tgolang.org/x/text v0.14.0 // indirect\n)\n\ngo 1.20\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 5.14,
          "content": "github.com/charlievieth/fastwalk v1.0.9 h1:Odb92AfoReO3oFBfDGT5J+nwgzQPF/gWAw6E6/lkor0=\ngithub.com/charlievieth/fastwalk v1.0.9/go.mod h1:yGy1zbxog41ZVMcKA/i8ojXLFsuayX5VvwhQVoj9PBI=\ngithub.com/gdamore/encoding v1.0.0 h1:+7OoQ1Bc6eTm5niUzBa0Ctsh6JbMW6Ra+YNuAtDBdko=\ngithub.com/gdamore/encoding v1.0.0/go.mod h1:alR0ol34c49FCSBLjhosxzcPHQbf2trDkoo5dl+VrEg=\ngithub.com/gdamore/tcell/v2 v2.7.4 h1:sg6/UnTM9jGpZU+oFYAsDahfchWAFW8Xx2yFinNSAYU=\ngithub.com/gdamore/tcell/v2 v2.7.4/go.mod h1:dSXtXTSK0VsW1biw65DZLZ2NKr7j0qP/0J7ONmsraWg=\ngithub.com/junegunn/go-shellwords v0.0.0-20240813092932-a62c48c52e97 h1:rqzLixVo1c/GQW6px9j1xQmlvQIn+lf/V6M1UQ7IFzw=\ngithub.com/junegunn/go-shellwords v0.0.0-20240813092932-a62c48c52e97/go.mod h1:6EILKtGpo5t+KLb85LNZLAF6P9LKp78hJI80PXMcn3c=\ngithub.com/lucasb-eyer/go-colorful v1.2.0 h1:1nnpGOrhyZZuNyfu1QjKiUICQ74+3FNCN69Aj6K7nkY=\ngithub.com/lucasb-eyer/go-colorful v1.2.0/go.mod h1:R4dSotOR9KMtayYi1e77YzuveK+i7ruzyGqttikkLy0=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/mattn/go-runewidth v0.0.15 h1:UNAjwbU9l54TA3KzvqLGxwWjHmMgBUVhBiTjelZgg3U=\ngithub.com/mattn/go-runewidth v0.0.15/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=\ngithub.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=\ngithub.com/rivo/uniseg v0.4.3/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=\ngithub.com/rivo/uniseg v0.4.7 h1:WUdvkW8uEhrYfLC4ZzdpI2ztxP1I582+49Oc5Mq64VQ=\ngithub.com/rivo/uniseg v0.4.7/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.17.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.29.0 h1:TPYlXGxvx1MGTn2GiZDhnjPA9wZzZeGKHHmKhHYvgaU=\ngolang.org/x/sys v0.29.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.17.0/go.mod h1:lLRBjIVuehSbZlaOtGMbcMncT+aqLLLmKrsjNrUguwk=\ngolang.org/x/term v0.28.0 h1:/Ts8HFuMR2E6IP/jlo7QVLZHggjKQbhu/7H0LJFr3Gg=\ngolang.org/x/term v0.28.0/go.mod h1:Sw/lC2IAUZ92udQNf3WodGtn4k/XoLyZoh8v/8uiwek=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.14.0 h1:ScX5w1eTa3QqT8oi6+ziP7dTV1S2+ALU0bI+0zXKWiQ=\ngolang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\n"
        },
        {
          "name": "install",
          "type": "blob",
          "size": 10.25,
          "content": "#!/usr/bin/env bash\n\nset -u\n\nversion=0.57.0\nauto_completion=\nkey_bindings=\nupdate_config=2\nshells=\"bash zsh fish\"\nprefix='~/.fzf'\nprefix_expand=~/.fzf\nfish_dir=${XDG_CONFIG_HOME:-$HOME/.config}/fish\n\nhelp() {\n  cat << EOF\nusage: $0 [OPTIONS]\n\n    --help               Show this message\n    --bin                Download fzf binary only; Do not generate ~/.fzf.{bash,zsh}\n    --all                Download fzf binary and update configuration files\n                         to enable key bindings and fuzzy completion\n    --xdg                Generate files under \\$XDG_CONFIG_HOME/fzf\n    --[no-]key-bindings  Enable/disable key bindings (CTRL-T, CTRL-R, ALT-C)\n    --[no-]completion    Enable/disable fuzzy completion (bash & zsh)\n    --[no-]update-rc     Whether or not to update shell configuration files\n\n    --no-bash            Do not set up bash configuration\n    --no-zsh             Do not set up zsh configuration\n    --no-fish            Do not set up fish configuration\nEOF\n}\n\nfor opt in \"$@\"; do\n  case $opt in\n    --help)\n      help\n      exit 0\n      ;;\n    --all)\n      auto_completion=1\n      key_bindings=1\n      update_config=1\n      ;;\n    --xdg)\n      prefix='\"${XDG_CONFIG_HOME:-$HOME/.config}\"/fzf/fzf'\n      prefix_expand=${XDG_CONFIG_HOME:-$HOME/.config}/fzf/fzf\n      mkdir -p \"${XDG_CONFIG_HOME:-$HOME/.config}/fzf\"\n      ;;\n    --key-bindings)    key_bindings=1    ;;\n    --no-key-bindings) key_bindings=0    ;;\n    --completion)      auto_completion=1 ;;\n    --no-completion)   auto_completion=0 ;;\n    --update-rc)       update_config=1   ;;\n    --no-update-rc)    update_config=0   ;;\n    --bin)             ;;\n    --no-bash)         shells=${shells/bash/} ;;\n    --no-zsh)          shells=${shells/zsh/} ;;\n    --no-fish)         shells=${shells/fish/} ;;\n    *)\n      echo \"unknown option: $opt\"\n      help\n      exit 1\n      ;;\n  esac\ndone\n\ncd \"$(dirname \"${BASH_SOURCE[0]}\")\"\nfzf_base=$(pwd)\nfzf_base_esc=$(printf %q \"$fzf_base\")\n\nask() {\n  while true; do\n    read -p \"$1 ([y]/n) \" -r\n    REPLY=${REPLY:-\"y\"}\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n      return 1\n    elif [[ $REPLY =~ ^[Nn]$ ]]; then\n      return 0\n    fi\n  done\n}\n\ncheck_binary() {\n  echo -n \"  - Checking fzf executable ... \"\n  local output\n  output=$(FZF_DEFAULT_OPTS= \"$fzf_base\"/bin/fzf --version 2>&1)\n  if [ $? -ne 0 ]; then\n    echo \"Error: $output\"\n    binary_error=\"Invalid binary\"\n  else\n    output=${output/ */}\n    if [ \"$version\" != \"$output\" ]; then\n      echo \"$output != $version\"\n      binary_error=\"Invalid version\"\n    else\n      echo \"$output\"\n      binary_error=\"\"\n      return 0\n    fi\n  fi\n  rm -f \"$fzf_base\"/bin/fzf\n  return 1\n}\n\nlink_fzf_in_path() {\n  if which_fzf=\"$(command -v fzf)\"; then\n    echo \"  - Found in \\$PATH\"\n    echo \"  - Creating symlink: bin/fzf -> $which_fzf\"\n    (cd \"$fzf_base\"/bin && rm -f fzf && ln -sf \"$which_fzf\" fzf)\n    check_binary && return\n  fi\n  return 1\n}\n\ntry_curl() {\n  command -v curl > /dev/null &&\n  if [[ $1 =~ tar.gz$ ]]; then\n    curl -fL $1 | tar --no-same-owner -xzf -\n  else\n    local temp=${TMPDIR:-/tmp}/fzf.zip\n    curl -fLo \"$temp\" $1 && unzip -o \"$temp\" && rm -f \"$temp\"\n  fi\n}\n\ntry_wget() {\n  command -v wget > /dev/null &&\n  if [[ $1 =~ tar.gz$ ]]; then\n    wget -O - $1 | tar --no-same-owner -xzf -\n  else\n    local temp=${TMPDIR:-/tmp}/fzf.zip\n    wget -O \"$temp\" $1 && unzip -o \"$temp\" && rm -f \"$temp\"\n  fi\n}\n\ndownload() {\n  echo \"Downloading bin/fzf ...\"\n  if [ -x \"$fzf_base\"/bin/fzf ]; then\n    echo \"  - Already exists\"\n    check_binary && return\n  fi\n  link_fzf_in_path && return\n  mkdir -p \"$fzf_base\"/bin && cd \"$fzf_base\"/bin\n  if [ $? -ne 0 ]; then\n    binary_error=\"Failed to create bin directory\"\n    return\n  fi\n\n  local url\n  url=https://github.com/junegunn/fzf/releases/download/v$version/${1}\n  set -o pipefail\n  if ! (try_curl $url || try_wget $url); then\n    set +o pipefail\n    binary_error=\"Failed to download with curl and wget\"\n    return\n  fi\n  set +o pipefail\n\n  if [ ! -f fzf ]; then\n    binary_error=\"Failed to download ${1}\"\n    return\n  fi\n\n  chmod +x fzf && check_binary\n}\n\n# Try to download binary executable\narchi=$(uname -sm)\nbinary_available=1\nbinary_error=\"\"\ncase \"$archi\" in\n  Darwin\\ arm64)      download fzf-$version-darwin_arm64.tar.gz  ;;\n  Darwin\\ x86_64)     download fzf-$version-darwin_amd64.tar.gz  ;;\n  Linux\\ armv5*)      download fzf-$version-linux_armv5.tar.gz   ;;\n  Linux\\ armv6*)      download fzf-$version-linux_armv6.tar.gz   ;;\n  Linux\\ armv7*)      download fzf-$version-linux_armv7.tar.gz   ;;\n  Linux\\ armv8*)      download fzf-$version-linux_arm64.tar.gz   ;;\n  Linux\\ aarch64*)    download fzf-$version-linux_arm64.tar.gz   ;;\n  Linux\\ loongarch64) download fzf-$version-linux_loong64.tar.gz ;;\n  Linux\\ ppc64le)     download fzf-$version-linux_ppc64le.tar.gz ;;\n  Linux\\ *64)         download fzf-$version-linux_amd64.tar.gz   ;;\n  Linux\\ s390x)       download fzf-$version-linux_s390x.tar.gz   ;;\n  FreeBSD\\ *64)       download fzf-$version-freebsd_amd64.tar.gz ;;\n  OpenBSD\\ *64)       download fzf-$version-openbsd_amd64.tar.gz ;;\n  CYGWIN*\\ *64)       download fzf-$version-windows_amd64.zip    ;;\n  MINGW*\\ *64)        download fzf-$version-windows_amd64.zip    ;;\n  MSYS*\\ *64)         download fzf-$version-windows_amd64.zip    ;;\n  Windows*\\ *64)      download fzf-$version-windows_amd64.zip    ;;\n  *)                  binary_available=0 binary_error=1          ;;\nesac\n\ncd \"$fzf_base\"\nif [ -n \"$binary_error\" ]; then\n  if [ $binary_available -eq 0 ]; then\n    echo \"No prebuilt binary for $archi ...\"\n  else\n    echo \"  - $binary_error !!!\"\n  fi\n  if command -v go > /dev/null; then\n    echo -n \"Building binary (go install github.com/junegunn/fzf) ... \"\n    if [ -z \"${GOPATH-}\" ]; then\n      export GOPATH=\"${TMPDIR:-/tmp}/fzf-gopath\"\n      mkdir -p \"$GOPATH\"\n    fi\n    if go install -ldflags \"-s -w -X main.version=$version -X main.revision=go-install\" github.com/junegunn/fzf; then\n      echo \"OK\"\n      cp \"$GOPATH/bin/fzf\" \"$fzf_base/bin/\"\n    else\n      echo \"Failed to build binary. Installation failed.\"\n      exit 1\n    fi\n  else\n    echo \"go executable not found. Installation failed.\"\n    exit 1\n  fi\nfi\n\n[[ \"$*\" =~ \"--bin\" ]] && exit 0\n\nfor s in $shells; do\n  if ! command -v \"$s\" > /dev/null; then\n    shells=${shells/$s/}\n  fi\ndone\n\nif [[ ${#shells} -lt 3 ]]; then\n  echo \"No shell configuration to be updated.\"\n  exit 0\nfi\n\n# Auto-completion\nif [ -z \"$auto_completion\" ]; then\n  ask \"Do you want to enable fuzzy auto-completion?\"\n  auto_completion=$?\nfi\n\n# Key-bindings\nif [ -z \"$key_bindings\" ]; then\n  ask \"Do you want to enable key bindings?\"\n  key_bindings=$?\nfi\n\necho\nfor shell in $shells; do\n  [[ \"$shell\" = fish ]] && continue\n  src=${prefix_expand}.${shell}\n  echo -n \"Generate $src ... \"\n\n  fzf_completion=\"source \\\"$fzf_base/shell/completion.${shell}\\\"\"\n  if [ $auto_completion -eq 0 ]; then\n    fzf_completion=\"# $fzf_completion\"\n  fi\n\n  fzf_key_bindings=\"source \\\"$fzf_base/shell/key-bindings.${shell}\\\"\"\n  if [ $key_bindings -eq 0 ]; then\n    fzf_key_bindings=\"# $fzf_key_bindings\"\n  fi\n\n  cat > \"$src\" << EOF\n# Setup fzf\n# ---------\nif [[ ! \"\\$PATH\" == *$fzf_base_esc/bin* ]]; then\n  PATH=\"\\${PATH:+\\${PATH}:}$fzf_base/bin\"\nfi\n\nEOF\n\n  if [[ $auto_completion -eq 1 ]] && [[ $key_bindings -eq 1 ]]; then\n    if [[ \"$shell\" = zsh ]]; then\n      echo \"source <(fzf --$shell)\" >> \"$src\"\n    else\n      echo \"eval \\\"\\$(fzf --$shell)\\\"\" >> \"$src\"\n    fi\n  else\n    cat >> \"$src\" << EOF\n# Auto-completion\n# ---------------\n$fzf_completion\n\n# Key bindings\n# ------------\n$fzf_key_bindings\nEOF\n  fi\n  echo \"OK\"\ndone\n\n# fish\nif [[ \"$shells\" =~ fish ]]; then\n  echo -n \"Update fish_user_paths ... \"\n  fish << EOF\n  echo \\$fish_user_paths | \\grep \"$fzf_base\"/bin > /dev/null\n  or set --universal fish_user_paths \\$fish_user_paths \"$fzf_base\"/bin\nEOF\n  [ $? -eq 0 ] && echo \"OK\" || echo \"Failed\"\nfi\n\nappend_line() {\n  local update line file pat lines\n  update=\"$1\"\n  line=\"$2\"\n  file=\"$3\"\n  pat=\"${4:-}\"\n  lines=\"\"\n\n  echo \"Update $file:\"\n  echo \"  - $line\"\n  if [ -f \"$file\" ]; then\n    if [ $# -lt 4 ]; then\n      lines=$(\\grep -nF \"$line\" \"$file\")\n    else\n      lines=$(\\grep -nF \"$pat\" \"$file\")\n    fi\n  fi\n\n  if [ -n \"$lines\" ]; then\n    echo \"    - Already exists:\"\n    sed 's/^/        Line /' <<< \"$lines\"\n\n    update=0\n    if ! \\grep -qv \"^[0-9]*:[[:space:]]*#\" <<< \"$lines\" ; then\n      echo \"    - But they all seem to be commented\"\n      ask  \"    - Continue modifying $file?\"\n      update=$?\n    fi\n  fi\n\n  set -e\n  if [ \"$update\" -eq 1 ]; then\n    [ -f \"$file\" ] && echo >> \"$file\"\n    echo \"$line\" >> \"$file\"\n    echo \"    + Added\"\n  else\n    echo \"    ~ Skipped\"\n  fi\n\n  echo\n  set +e\n}\n\ncreate_file() {\n  local file=\"$1\"\n  shift\n  echo \"Create $file:\"\n  for line in \"$@\"; do\n    echo \"    $line\"\n    echo \"$line\" >> \"$file\"\n  done\n  echo\n}\n\nif [ $update_config -eq 2 ]; then\n  echo\n  ask \"Do you want to update your shell configuration files?\"\n  update_config=$?\nfi\necho\nfor shell in $shells; do\n  [[ \"$shell\" = fish ]] && continue\n  [ $shell = zsh ] && dest=${ZDOTDIR:-~}/.zshrc || dest=~/.bashrc\n  append_line $update_config \"[ -f ${prefix}.${shell} ] && source ${prefix}.${shell}\" \"$dest\" \"${prefix}.${shell}\"\ndone\n\nif [ $key_bindings -eq 1 ] && [[ \"$shells\" =~ fish ]]; then\n  bind_file=\"${fish_dir}/functions/fish_user_key_bindings.fish\"\n  if [ ! -e \"$bind_file\" ]; then\n    mkdir -p \"${fish_dir}/functions\"\n    create_file \"$bind_file\" \\\n      'function fish_user_key_bindings' \\\n      '  fzf --fish | source' \\\n      'end'\n  else\n    echo \"Check $bind_file:\"\n    lno=$(\\grep -nF \"fzf_key_bindings\" \"$bind_file\" | sed 's/:.*//' | tr '\\n' ' ')\n    if [[ -n $lno ]]; then\n      echo \"  ** Found 'fzf_key_bindings' in line #$lno\"\n      echo \"  ** You have to replace the line to 'fzf --fish | source'\"\n      echo\n    else\n      echo \"  - Clear\"\n      echo\n      append_line $update_config \"fzf --fish | source\" \"$bind_file\"\n    fi\n  fi\nfi\n\nif [ $update_config -eq 1 ]; then\n  echo 'Finished. Restart your shell or reload config file.'\n  if [[ \"$shells\" =~ bash ]]; then\n    echo -n '   source ~/.bashrc  # bash'\n    [[ \"$archi\" =~ Darwin ]] && echo -n '  (.bashrc should be loaded from .bash_profile)'\n    echo\n  fi\n  [[ \"$shells\" =~ zsh ]]  && echo \"   source ${ZDOTDIR:-~}/.zshrc   # zsh\"\n  [[ \"$shells\" =~ fish ]] && [ $key_bindings -eq 1 ] && echo '   fzf_key_bindings  # fish'\n  echo\n  echo 'Use uninstall script to remove fzf.'\n  echo\nfi\necho 'For more information, see: https://github.com/junegunn/fzf'\n"
        },
        {
          "name": "install.ps1",
          "type": "blob",
          "size": 1.84,
          "content": "$version=\"0.57.0\"\n\n$fzf_base=Split-Path -Parent $MyInvocation.MyCommand.Definition\n\nfunction check_binary () {\n  Write-Host \"  - Checking fzf executable ... \" -NoNewline\n  $output=cmd /c $fzf_base\\bin\\fzf.exe --version 2>&1\n  if (-not $?) {\n    Write-Host \"Error: $output\"\n    $binary_error=\"Invalid binary\"\n  } else {\n    $output=(-Split $output)[0]\n    if ($version -ne $output) {\n      Write-Host \"$output != $version\"\n      $binary_error=\"Invalid version\"\n    } else {\n      Write-Host \"$output\"\n      $binary_error=\"\"\n      return 1\n    }\n  }\n  Remove-Item \"$fzf_base\\bin\\fzf.exe\"\n  return 0\n}\n\nfunction download {\n  param($file)\n  Write-Host \"Downloading bin/fzf ...\"\n  if (Test-Path \"$fzf_base\\bin\\fzf.exe\") {\n    Write-Host \"  - Already exists\"\n    if (check_binary) {\n      return\n    }\n  }\n  if (-not (Test-Path \"$fzf_base\\bin\")) {\n    md \"$fzf_base\\bin\"\n  }\n  if (-not $?) {\n    $binary_error=\"Failed to create bin directory\"\n    return\n  }\n  cd \"$fzf_base\\bin\"\n  $url=\"https://github.com/junegunn/fzf/releases/download/v$version/$file\"\n  $temp=$env:TMP + \"\\fzf.zip\"\n  [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n  if ($PSVersionTable.PSVersion.Major -ge 3) {\n    Invoke-WebRequest -Uri $url -OutFile $temp\n  } else {\n    (New-Object Net.WebClient).DownloadFile($url, $ExecutionContext.SessionState.Path.GetUnresolvedProviderPathFromPSPath(\"$temp\"))\n  }\n  if ($?) {\n    (Microsoft.PowerShell.Archive\\Expand-Archive -Path $temp -DestinationPath .); (Remove-Item $temp)\n  } else {\n    $binary_error=\"Failed to download with powershell\"\n  }\n  if (-not (Test-Path fzf.exe)) {\n    $binary_error=\"Failed to download $file\"\n    return\n  }\n  echo y | icacls $fzf_base\\bin\\fzf.exe /grant Administrator:F ; check_binary >$null\n}\n\ndownload \"fzf-$version-windows_amd64.zip\"\n\nWrite-Host 'For more information, see: https://github.com/junegunn/fzf'\n"
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 1.92,
          "content": "package main\n\nimport (\n\t_ \"embed\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\n\tfzf \"github.com/junegunn/fzf/src\"\n\t\"github.com/junegunn/fzf/src/protector\"\n)\n\nvar version = \"0.57\"\nvar revision = \"devel\"\n\n//go:embed shell/key-bindings.bash\nvar bashKeyBindings []byte\n\n//go:embed shell/completion.bash\nvar bashCompletion []byte\n\n//go:embed shell/key-bindings.zsh\nvar zshKeyBindings []byte\n\n//go:embed shell/completion.zsh\nvar zshCompletion []byte\n\n//go:embed shell/key-bindings.fish\nvar fishKeyBindings []byte\n\n//go:embed man/man1/fzf.1\nvar manPage []byte\n\nfunc printScript(label string, content []byte) {\n\tfmt.Println(\"### \" + label + \" ###\")\n\tfmt.Println(strings.TrimSpace(string(content)))\n\tfmt.Println(\"### end: \" + label + \" ###\")\n}\n\nfunc exit(code int, err error) {\n\tif code == fzf.ExitError && err != nil {\n\t\tfmt.Fprintln(os.Stderr, err.Error())\n\t}\n\tos.Exit(code)\n}\n\nfunc main() {\n\tprotector.Protect()\n\n\toptions, err := fzf.ParseOptions(true, os.Args[1:])\n\tif err != nil {\n\t\texit(fzf.ExitError, err)\n\t\treturn\n\t}\n\tif options.Bash {\n\t\tprintScript(\"key-bindings.bash\", bashKeyBindings)\n\t\tprintScript(\"completion.bash\", bashCompletion)\n\t\treturn\n\t}\n\tif options.Zsh {\n\t\tprintScript(\"key-bindings.zsh\", zshKeyBindings)\n\t\tprintScript(\"completion.zsh\", zshCompletion)\n\t\treturn\n\t}\n\tif options.Fish {\n\t\tprintScript(\"key-bindings.fish\", fishKeyBindings)\n\t\tfmt.Println(\"fzf_key_bindings\")\n\t\treturn\n\t}\n\tif options.Help {\n\t\tfmt.Print(fzf.Usage)\n\t\treturn\n\t}\n\tif options.Version {\n\t\tif len(revision) > 0 {\n\t\t\tfmt.Printf(\"%s (%s)\\n\", version, revision)\n\t\t} else {\n\t\t\tfmt.Println(version)\n\t\t}\n\t\treturn\n\t}\n\tif options.Man {\n\t\tfile := fzf.WriteTemporaryFile([]string{string(manPage)}, \"\\n\")\n\t\tif len(file) == 0 {\n\t\t\tfmt.Print(string(manPage))\n\t\t\treturn\n\t\t}\n\t\tdefer os.Remove(file)\n\t\tcmd := exec.Command(\"man\", file)\n\t\tcmd.Stdin = os.Stdin\n\t\tcmd.Stdout = os.Stdout\n\t\tif err := cmd.Run(); err != nil {\n\t\t\tfmt.Print(string(manPage))\n\t\t}\n\t\treturn\n\t}\n\n\tcode, err := fzf.Run(options)\n\texit(code, err)\n}\n"
        },
        {
          "name": "man",
          "type": "tree",
          "content": null
        },
        {
          "name": "plugin",
          "type": "tree",
          "content": null
        },
        {
          "name": "shell",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "typos.toml",
          "type": "blob",
          "size": 0.21,
          "content": "# See https://github.com/crate-ci/typos/blob/master/docs/reference.md to configure typos\n[default.extend-words]\nba = \"ba\"\nfo = \"fo\"\nenew = \"enew\"\ntabe = \"tabe\"\nIterm = \"Iterm\"\n\n[files]\nextend-exclude = [\"README.md\"]\n"
        },
        {
          "name": "uninstall",
          "type": "blob",
          "size": 2.46,
          "content": "#!/usr/bin/env bash\n\nxdg=0\nprefix='~/.fzf'\nprefix_expand=~/.fzf\nfish_dir=${XDG_CONFIG_HOME:-$HOME/.config}/fish\n\nhelp() {\n  cat << EOF\nusage: $0 [OPTIONS]\n\n    --help               Show this message\n    --xdg                Remove files generated under \\$XDG_CONFIG_HOME/fzf\nEOF\n}\n\nfor opt in \"$@\"; do\n  case $opt in\n    --help)\n      help\n      exit 0\n      ;;\n    --xdg)\n      xdg=1\n      prefix='\"${XDG_CONFIG_HOME:-$HOME/.config}\"/fzf/fzf'\n      prefix_expand=${XDG_CONFIG_HOME:-$HOME/.config}/fzf/fzf\n      ;;\n    *)\n      echo \"unknown option: $opt\"\n      help\n      exit 1\n      ;;\n  esac\ndone\n\nask() {\n  while true; do\n    read -p \"$1 ([y]/n) \" -r\n    REPLY=${REPLY:-\"y\"}\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n      return 0\n    elif [[ $REPLY =~ ^[Nn]$ ]]; then\n      return 1\n    fi\n  done\n}\n\nremove() {\n  echo \"Remove $1\"\n  rm -f \"$1\"\n}\n\nremove_line() {\n  src=$1\n  echo \"Remove from $1:\"\n\n  shift\n  line_no=1\n  match=0\n  while [ -n \"$1\" ]; do\n    line=$(sed -n \"$line_no,\\$p\" \"$src\" | \\grep -m1 -nF \"$1\")\n    if [ $? -ne 0 ]; then\n      shift\n      line_no=1\n      continue\n    fi\n    line_no=$(( $(sed 's/:.*//' <<< \"$line\") + line_no - 1 ))\n    content=$(sed 's/^[0-9]*://' <<< \"$line\")\n    match=1\n    echo    \"  - Line #$line_no: $content\"\n    [ \"$content\" = \"$1\" ] || ask \"    - Remove?\"\n    if [ $? -eq 0 ]; then\n      temp=$(mktemp)\n      awk -v n=$line_no 'NR == n {next} {print}' \"$src\" > \"$temp\" &&\n        cat \"$temp\" > \"$src\" && rm -f \"$temp\" || break\n      echo  \"      - Removed\"\n    else\n      echo  \"      - Skipped\"\n      line_no=$(( line_no + 1 ))\n    fi\n  done\n  [ $match -eq 0 ] && echo \"  - Nothing found\"\n  echo\n}\n\nfor shell in bash zsh; do\n  shell_config=${prefix_expand}.${shell}\n  remove \"${shell_config}\"\n  remove_line ~/.${shell}rc \\\n    \"[ -f ${prefix}.${shell} ] && source ${prefix}.${shell}\" \\\n    \"source ${prefix}.${shell}\"\ndone\n\nbind_file=\"${fish_dir}/functions/fish_user_key_bindings.fish\"\nif [ -f \"$bind_file\" ]; then\n  remove_line \"$bind_file\" \"fzf_key_bindings\"\n  remove_line \"$bind_file\" \"fzf --fish | source\"\nfi\n\nif [ -d \"${fish_dir}/functions\" ]; then\n  remove \"${fish_dir}/functions/fzf.fish\"\n  remove \"${fish_dir}/functions/fzf_key_bindings.fish\"\n\n  if [ -z \"$(ls -A \"${fish_dir}/functions\")\" ]; then\n    rmdir \"${fish_dir}/functions\"\n  else\n    echo \"Can't delete non-empty directory: \\\"${fish_dir}/functions\\\"\"\n  fi\nfi\n\nconfig_dir=$(dirname \"$prefix_expand\")\nif [[ \"$xdg\" = 1 ]] && [[ \"$config_dir\" = */fzf ]] && [[ -d \"$config_dir\" ]]; then\n  rmdir \"$config_dir\"\nfi\n"
        }
      ]
    },
    {
      "nameWithOwner": "binary-husky/gpt_academic",
      "stars": 66821,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.15,
          "content": "*.h linguist-detectable=false\n*.cpp linguist-detectable=false\n*.tex linguist-detectable=false\n*.cs linguist-detectable=false\n*.tps linguist-detectable=false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.35,
          "content": "# Byte-compiled / optimized / DLL files\r\n__pycache__/\r\n*.py[cod]\r\n*$py.class\r\n\r\n# C extensions\r\n*.so\r\n\r\n# Distribution / packaging\r\n.Python\r\nbuild/\r\ndevelop-eggs/\r\ndist/\r\ndownloads/\r\neggs/\r\n.eggs/\r\nlib/\r\nlib64/\r\nparts/\r\nsdist/\r\nvar/\r\nwheels/\r\npip-wheel-metadata/\r\nshare/python-wheels/\r\n*.egg-info/\r\n.installed.cfg\r\n*.egg\r\nMANIFEST\r\n\r\n# PyInstaller\r\n#  Usually these files are written by a python script from a template\r\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\r\n*.manifest\r\n*.spec\r\n# Installer logs\r\npip-log.txt\r\npip-delete-this-directory.txt\r\n\r\n# Unit test / coverage reports\r\nhtmlcov/\r\n.tox/\r\n.nox/\r\n.coverage\r\n.coverage.*\r\n.cache\r\nnosetests.xml\r\ncoverage.xml\r\n*.cover\r\n*.py,cover\r\n.hypothesis/\r\n.pytest_cache/\r\n\r\n# Translations\r\n*.mo\r\n*.pot\r\ngithub\r\n.github\r\nTEMP\r\nTRASH\r\n\r\n# Django stuff:\r\n*.log\r\nlocal_settings.py\r\ndb.sqlite3\r\ndb.sqlite3-journal\r\n\r\n# Flask stuff:\r\ninstance/\r\n.webassets-cache\r\n\r\n# Scrapy stuff:\r\n.scrapy\r\n\r\n# Sphinx documentation\r\ndocs/_build/\r\n\r\n# PyBuilder\r\ntarget/\r\n\r\n# Jupyter Notebook\r\n.ipynb_checkpoints\r\n\r\n# IPython\r\nprofile_default/\r\nipython_config.py\r\n\r\n# pyenv\r\n.python-version\r\n\r\n# pipenv\r\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\r\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\r\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\r\n#   install all needed dependencies.\r\n#Pipfile.lock\r\n\r\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\r\n__pypackages__/\r\n\r\n# Celery stuff\r\ncelerybeat-schedule\r\ncelerybeat.pid\r\n\r\n# SageMath parsed files\r\n*.sage.py\r\n\r\n# Environments\r\n.env\r\n.venv\r\nenv/\r\nvenv/\r\nENV/\r\nenv.bak/\r\nvenv.bak/\r\n\r\n# Spyder project settings\r\n.spyderproject\r\n.spyproject\r\n\r\n# Rope project settings\r\n.ropeproject\r\n\r\n# mkdocs documentation\r\n/site\r\n\r\n# mypy\r\n.mypy_cache/\r\n.dmypy.json\r\ndmypy.json\r\n\r\n# Pyre type checker\r\n.pyre/\r\n\r\n# macOS files\r\n.DS_Store\r\n\r\n.vscode\r\n.idea\r\n\r\nhistory\r\nssr_conf\r\nconfig_private.py\r\ngpt_log\r\nprivate.md\r\nprivate_upload\r\nother_llms\r\ncradle*\r\ndebug*\r\nprivate*\r\ncrazy_functions/test_project/pdf_and_word\r\ncrazy_functions/test_samples\r\nrequest_llms/jittorllms\r\nmulti-language\r\nrequest_llms/moss\r\nmedia\r\nflagged\r\nrequest_llms/ChatGLM-6b-onnx-u8s8\r\n.pre-commit-config.yaml\r\ntest.*\r\ntemp.*\r\nobjdump*\r\n*.min.*.js\r\nTODO\r\nexperimental_mods\r\nsearch_results\r\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.61,
          "content": "# 此Dockerfile适用于“无本地模型”的迷你运行环境构建\n# 如果需要使用chatglm等本地模型或者latex运行依赖，请参考 docker-compose.yml\n# - 如何构建: 先修改 `config.py`， 然后 `docker build -t gpt-academic . `\n# - 如何运行(Linux下): `docker run --rm -it --net=host gpt-academic `\n# - 如何运行(其他操作系统，选择任意一个固定端口50923): `docker run --rm -it -e WEB_PORT=50923 -p 50923:50923 gpt-academic `\nFROM python:3.11\n\n\n# 非必要步骤，更换pip源 （以下三行，可以删除）\nRUN echo '[global]' > /etc/pip.conf && \\\n    echo 'index-url = https://mirrors.aliyun.com/pypi/simple/' >> /etc/pip.conf && \\\n    echo 'trusted-host = mirrors.aliyun.com' >> /etc/pip.conf\n\n\n# 语音输出功能（以下两行，第一行更换阿里源，第二行安装ffmpeg，都可以删除）\nRUN UBUNTU_VERSION=$(awk -F= '/^VERSION_CODENAME=/{print $2}' /etc/os-release); echo \"deb https://mirrors.aliyun.com/debian/ $UBUNTU_VERSION main non-free contrib\" > /etc/apt/sources.list; apt-get update\nRUN apt-get install ffmpeg -y\nRUN apt-get clean\n\n\n# 进入工作路径（必要）\nWORKDIR /gpt\n\n\n# 安装大部分依赖，利用Docker缓存加速以后的构建 （以下两行，可以删除）\nCOPY requirements.txt ./\nRUN pip3 install -r requirements.txt\n\n\n# 装载项目文件，安装剩余依赖（必要）\nCOPY . .\nRUN pip3 install -r requirements.txt\n\n\n# 非必要步骤，用于预热模块（可以删除）\nRUN python3  -c 'from check_proxy import warm_up_modules; warm_up_modules()'\nRUN python3 -m pip cache purge\n\n\n# 启动（必要）\nCMD [\"python3\", \"-u\", \"main.py\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.98,
          "content": "                    GNU GENERAL PUBLIC LICENSE\r\n                       Version 3, 29 June 2007\r\n\r\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\r\n Everyone is permitted to copy and distribute verbatim copies\r\n of this license document, but changing it is not allowed.\r\n\r\n                            Preamble\r\n\r\n  The GNU General Public License is a free, copyleft license for\r\nsoftware and other kinds of works.\r\n\r\n  The licenses for most software and other practical works are designed\r\nto take away your freedom to share and change the works.  By contrast,\r\nthe GNU General Public License is intended to guarantee your freedom to\r\nshare and change all versions of a program--to make sure it remains free\r\nsoftware for all its users.  We, the Free Software Foundation, use the\r\nGNU General Public License for most of our software; it applies also to\r\nany other work released this way by its authors.  You can apply it to\r\nyour programs, too.\r\n\r\n  When we speak of free software, we are referring to freedom, not\r\nprice.  Our General Public Licenses are designed to make sure that you\r\nhave the freedom to distribute copies of free software (and charge for\r\nthem if you wish), that you receive source code or can get it if you\r\nwant it, that you can change the software or use pieces of it in new\r\nfree programs, and that you know you can do these things.\r\n\r\n  To protect your rights, we need to prevent others from denying you\r\nthese rights or asking you to surrender the rights.  Therefore, you have\r\ncertain responsibilities if you distribute copies of the software, or if\r\nyou modify it: responsibilities to respect the freedom of others.\r\n\r\n  For example, if you distribute copies of such a program, whether\r\ngratis or for a fee, you must pass on to the recipients the same\r\nfreedoms that you received.  You must make sure that they, too, receive\r\nor can get the source code.  And you must show them these terms so they\r\nknow their rights.\r\n\r\n  Developers that use the GNU GPL protect your rights with two steps:\r\n(1) assert copyright on the software, and (2) offer you this License\r\ngiving you legal permission to copy, distribute and/or modify it.\r\n\r\n  For the developers' and authors' protection, the GPL clearly explains\r\nthat there is no warranty for this free software.  For both users' and\r\nauthors' sake, the GPL requires that modified versions be marked as\r\nchanged, so that their problems will not be attributed erroneously to\r\nauthors of previous versions.\r\n\r\n  Some devices are designed to deny users access to install or run\r\nmodified versions of the software inside them, although the manufacturer\r\ncan do so.  This is fundamentally incompatible with the aim of\r\nprotecting users' freedom to change the software.  The systematic\r\npattern of such abuse occurs in the area of products for individuals to\r\nuse, which is precisely where it is most unacceptable.  Therefore, we\r\nhave designed this version of the GPL to prohibit the practice for those\r\nproducts.  If such problems arise substantially in other domains, we\r\nstand ready to extend this provision to those domains in future versions\r\nof the GPL, as needed to protect the freedom of users.\r\n\r\n  Finally, every program is threatened constantly by software patents.\r\nStates should not allow patents to restrict development and use of\r\nsoftware on general-purpose computers, but in those that do, we wish to\r\navoid the special danger that patents applied to a free program could\r\nmake it effectively proprietary.  To prevent this, the GPL assures that\r\npatents cannot be used to render the program non-free.\r\n\r\n  The precise terms and conditions for copying, distribution and\r\nmodification follow.\r\n\r\n                       TERMS AND CONDITIONS\r\n\r\n  0. Definitions.\r\n\r\n  \"This License\" refers to version 3 of the GNU General Public License.\r\n\r\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\r\nworks, such as semiconductor masks.\r\n\r\n  \"The Program\" refers to any copyrightable work licensed under this\r\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\r\n\"recipients\" may be individuals or organizations.\r\n\r\n  To \"modify\" a work means to copy from or adapt all or part of the work\r\nin a fashion requiring copyright permission, other than the making of an\r\nexact copy.  The resulting work is called a \"modified version\" of the\r\nearlier work or a work \"based on\" the earlier work.\r\n\r\n  A \"covered work\" means either the unmodified Program or a work based\r\non the Program.\r\n\r\n  To \"propagate\" a work means to do anything with it that, without\r\npermission, would make you directly or secondarily liable for\r\ninfringement under applicable copyright law, except executing it on a\r\ncomputer or modifying a private copy.  Propagation includes copying,\r\ndistribution (with or without modification), making available to the\r\npublic, and in some countries other activities as well.\r\n\r\n  To \"convey\" a work means any kind of propagation that enables other\r\nparties to make or receive copies.  Mere interaction with a user through\r\na computer network, with no transfer of a copy, is not conveying.\r\n\r\n  An interactive user interface displays \"Appropriate Legal Notices\"\r\nto the extent that it includes a convenient and prominently visible\r\nfeature that (1) displays an appropriate copyright notice, and (2)\r\ntells the user that there is no warranty for the work (except to the\r\nextent that warranties are provided), that licensees may convey the\r\nwork under this License, and how to view a copy of this License.  If\r\nthe interface presents a list of user commands or options, such as a\r\nmenu, a prominent item in the list meets this criterion.\r\n\r\n  1. Source Code.\r\n\r\n  The \"source code\" for a work means the preferred form of the work\r\nfor making modifications to it.  \"Object code\" means any non-source\r\nform of a work.\r\n\r\n  A \"Standard Interface\" means an interface that either is an official\r\nstandard defined by a recognized standards body, or, in the case of\r\ninterfaces specified for a particular programming language, one that\r\nis widely used among developers working in that language.\r\n\r\n  The \"System Libraries\" of an executable work include anything, other\r\nthan the work as a whole, that (a) is included in the normal form of\r\npackaging a Major Component, but which is not part of that Major\r\nComponent, and (b) serves only to enable use of the work with that\r\nMajor Component, or to implement a Standard Interface for which an\r\nimplementation is available to the public in source code form.  A\r\n\"Major Component\", in this context, means a major essential component\r\n(kernel, window system, and so on) of the specific operating system\r\n(if any) on which the executable work runs, or a compiler used to\r\nproduce the work, or an object code interpreter used to run it.\r\n\r\n  The \"Corresponding Source\" for a work in object code form means all\r\nthe source code needed to generate, install, and (for an executable\r\nwork) run the object code and to modify the work, including scripts to\r\ncontrol those activities.  However, it does not include the work's\r\nSystem Libraries, or general-purpose tools or generally available free\r\nprograms which are used unmodified in performing those activities but\r\nwhich are not part of the work.  For example, Corresponding Source\r\nincludes interface definition files associated with source files for\r\nthe work, and the source code for shared libraries and dynamically\r\nlinked subprograms that the work is specifically designed to require,\r\nsuch as by intimate data communication or control flow between those\r\nsubprograms and other parts of the work.\r\n\r\n  The Corresponding Source need not include anything that users\r\ncan regenerate automatically from other parts of the Corresponding\r\nSource.\r\n\r\n  The Corresponding Source for a work in source code form is that\r\nsame work.\r\n\r\n  2. Basic Permissions.\r\n\r\n  All rights granted under this License are granted for the term of\r\ncopyright on the Program, and are irrevocable provided the stated\r\nconditions are met.  This License explicitly affirms your unlimited\r\npermission to run the unmodified Program.  The output from running a\r\ncovered work is covered by this License only if the output, given its\r\ncontent, constitutes a covered work.  This License acknowledges your\r\nrights of fair use or other equivalent, as provided by copyright law.\r\n\r\n  You may make, run and propagate covered works that you do not\r\nconvey, without conditions so long as your license otherwise remains\r\nin force.  You may convey covered works to others for the sole purpose\r\nof having them make modifications exclusively for you, or provide you\r\nwith facilities for running those works, provided that you comply with\r\nthe terms of this License in conveying all material for which you do\r\nnot control copyright.  Those thus making or running the covered works\r\nfor you must do so exclusively on your behalf, under your direction\r\nand control, on terms that prohibit them from making any copies of\r\nyour copyrighted material outside their relationship with you.\r\n\r\n  Conveying under any other circumstances is permitted solely under\r\nthe conditions stated below.  Sublicensing is not allowed; section 10\r\nmakes it unnecessary.\r\n\r\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\r\n\r\n  No covered work shall be deemed part of an effective technological\r\nmeasure under any applicable law fulfilling obligations under article\r\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\r\nsimilar laws prohibiting or restricting circumvention of such\r\nmeasures.\r\n\r\n  When you convey a covered work, you waive any legal power to forbid\r\ncircumvention of technological measures to the extent such circumvention\r\nis effected by exercising rights under this License with respect to\r\nthe covered work, and you disclaim any intention to limit operation or\r\nmodification of the work as a means of enforcing, against the work's\r\nusers, your or third parties' legal rights to forbid circumvention of\r\ntechnological measures.\r\n\r\n  4. Conveying Verbatim Copies.\r\n\r\n  You may convey verbatim copies of the Program's source code as you\r\nreceive it, in any medium, provided that you conspicuously and\r\nappropriately publish on each copy an appropriate copyright notice;\r\nkeep intact all notices stating that this License and any\r\nnon-permissive terms added in accord with section 7 apply to the code;\r\nkeep intact all notices of the absence of any warranty; and give all\r\nrecipients a copy of this License along with the Program.\r\n\r\n  You may charge any price or no price for each copy that you convey,\r\nand you may offer support or warranty protection for a fee.\r\n\r\n  5. Conveying Modified Source Versions.\r\n\r\n  You may convey a work based on the Program, or the modifications to\r\nproduce it from the Program, in the form of source code under the\r\nterms of section 4, provided that you also meet all of these conditions:\r\n\r\n    a) The work must carry prominent notices stating that you modified\r\n    it, and giving a relevant date.\r\n\r\n    b) The work must carry prominent notices stating that it is\r\n    released under this License and any conditions added under section\r\n    7.  This requirement modifies the requirement in section 4 to\r\n    \"keep intact all notices\".\r\n\r\n    c) You must license the entire work, as a whole, under this\r\n    License to anyone who comes into possession of a copy.  This\r\n    License will therefore apply, along with any applicable section 7\r\n    additional terms, to the whole of the work, and all its parts,\r\n    regardless of how they are packaged.  This License gives no\r\n    permission to license the work in any other way, but it does not\r\n    invalidate such permission if you have separately received it.\r\n\r\n    d) If the work has interactive user interfaces, each must display\r\n    Appropriate Legal Notices; however, if the Program has interactive\r\n    interfaces that do not display Appropriate Legal Notices, your\r\n    work need not make them do so.\r\n\r\n  A compilation of a covered work with other separate and independent\r\nworks, which are not by their nature extensions of the covered work,\r\nand which are not combined with it such as to form a larger program,\r\nin or on a volume of a storage or distribution medium, is called an\r\n\"aggregate\" if the compilation and its resulting copyright are not\r\nused to limit the access or legal rights of the compilation's users\r\nbeyond what the individual works permit.  Inclusion of a covered work\r\nin an aggregate does not cause this License to apply to the other\r\nparts of the aggregate.\r\n\r\n  6. Conveying Non-Source Forms.\r\n\r\n  You may convey a covered work in object code form under the terms\r\nof sections 4 and 5, provided that you also convey the\r\nmachine-readable Corresponding Source under the terms of this License,\r\nin one of these ways:\r\n\r\n    a) Convey the object code in, or embodied in, a physical product\r\n    (including a physical distribution medium), accompanied by the\r\n    Corresponding Source fixed on a durable physical medium\r\n    customarily used for software interchange.\r\n\r\n    b) Convey the object code in, or embodied in, a physical product\r\n    (including a physical distribution medium), accompanied by a\r\n    written offer, valid for at least three years and valid for as\r\n    long as you offer spare parts or customer support for that product\r\n    model, to give anyone who possesses the object code either (1) a\r\n    copy of the Corresponding Source for all the software in the\r\n    product that is covered by this License, on a durable physical\r\n    medium customarily used for software interchange, for a price no\r\n    more than your reasonable cost of physically performing this\r\n    conveying of source, or (2) access to copy the\r\n    Corresponding Source from a network server at no charge.\r\n\r\n    c) Convey individual copies of the object code with a copy of the\r\n    written offer to provide the Corresponding Source.  This\r\n    alternative is allowed only occasionally and noncommercially, and\r\n    only if you received the object code with such an offer, in accord\r\n    with subsection 6b.\r\n\r\n    d) Convey the object code by offering access from a designated\r\n    place (gratis or for a charge), and offer equivalent access to the\r\n    Corresponding Source in the same way through the same place at no\r\n    further charge.  You need not require recipients to copy the\r\n    Corresponding Source along with the object code.  If the place to\r\n    copy the object code is a network server, the Corresponding Source\r\n    may be on a different server (operated by you or a third party)\r\n    that supports equivalent copying facilities, provided you maintain\r\n    clear directions next to the object code saying where to find the\r\n    Corresponding Source.  Regardless of what server hosts the\r\n    Corresponding Source, you remain obligated to ensure that it is\r\n    available for as long as needed to satisfy these requirements.\r\n\r\n    e) Convey the object code using peer-to-peer transmission, provided\r\n    you inform other peers where the object code and Corresponding\r\n    Source of the work are being offered to the general public at no\r\n    charge under subsection 6d.\r\n\r\n  A separable portion of the object code, whose source code is excluded\r\nfrom the Corresponding Source as a System Library, need not be\r\nincluded in conveying the object code work.\r\n\r\n  A \"User Product\" is either (1) a \"consumer product\", which means any\r\ntangible personal property which is normally used for personal, family,\r\nor household purposes, or (2) anything designed or sold for incorporation\r\ninto a dwelling.  In determining whether a product is a consumer product,\r\ndoubtful cases shall be resolved in favor of coverage.  For a particular\r\nproduct received by a particular user, \"normally used\" refers to a\r\ntypical or common use of that class of product, regardless of the status\r\nof the particular user or of the way in which the particular user\r\nactually uses, or expects or is expected to use, the product.  A product\r\nis a consumer product regardless of whether the product has substantial\r\ncommercial, industrial or non-consumer uses, unless such uses represent\r\nthe only significant mode of use of the product.\r\n\r\n  \"Installation Information\" for a User Product means any methods,\r\nprocedures, authorization keys, or other information required to install\r\nand execute modified versions of a covered work in that User Product from\r\na modified version of its Corresponding Source.  The information must\r\nsuffice to ensure that the continued functioning of the modified object\r\ncode is in no case prevented or interfered with solely because\r\nmodification has been made.\r\n\r\n  If you convey an object code work under this section in, or with, or\r\nspecifically for use in, a User Product, and the conveying occurs as\r\npart of a transaction in which the right of possession and use of the\r\nUser Product is transferred to the recipient in perpetuity or for a\r\nfixed term (regardless of how the transaction is characterized), the\r\nCorresponding Source conveyed under this section must be accompanied\r\nby the Installation Information.  But this requirement does not apply\r\nif neither you nor any third party retains the ability to install\r\nmodified object code on the User Product (for example, the work has\r\nbeen installed in ROM).\r\n\r\n  The requirement to provide Installation Information does not include a\r\nrequirement to continue to provide support service, warranty, or updates\r\nfor a work that has been modified or installed by the recipient, or for\r\nthe User Product in which it has been modified or installed.  Access to a\r\nnetwork may be denied when the modification itself materially and\r\nadversely affects the operation of the network or violates the rules and\r\nprotocols for communication across the network.\r\n\r\n  Corresponding Source conveyed, and Installation Information provided,\r\nin accord with this section must be in a format that is publicly\r\ndocumented (and with an implementation available to the public in\r\nsource code form), and must require no special password or key for\r\nunpacking, reading or copying.\r\n\r\n  7. Additional Terms.\r\n\r\n  \"Additional permissions\" are terms that supplement the terms of this\r\nLicense by making exceptions from one or more of its conditions.\r\nAdditional permissions that are applicable to the entire Program shall\r\nbe treated as though they were included in this License, to the extent\r\nthat they are valid under applicable law.  If additional permissions\r\napply only to part of the Program, that part may be used separately\r\nunder those permissions, but the entire Program remains governed by\r\nthis License without regard to the additional permissions.\r\n\r\n  When you convey a copy of a covered work, you may at your option\r\nremove any additional permissions from that copy, or from any part of\r\nit.  (Additional permissions may be written to require their own\r\nremoval in certain cases when you modify the work.)  You may place\r\nadditional permissions on material, added by you to a covered work,\r\nfor which you have or can give appropriate copyright permission.\r\n\r\n  Notwithstanding any other provision of this License, for material you\r\nadd to a covered work, you may (if authorized by the copyright holders of\r\nthat material) supplement the terms of this License with terms:\r\n\r\n    a) Disclaiming warranty or limiting liability differently from the\r\n    terms of sections 15 and 16 of this License; or\r\n\r\n    b) Requiring preservation of specified reasonable legal notices or\r\n    author attributions in that material or in the Appropriate Legal\r\n    Notices displayed by works containing it; or\r\n\r\n    c) Prohibiting misrepresentation of the origin of that material, or\r\n    requiring that modified versions of such material be marked in\r\n    reasonable ways as different from the original version; or\r\n\r\n    d) Limiting the use for publicity purposes of names of licensors or\r\n    authors of the material; or\r\n\r\n    e) Declining to grant rights under trademark law for use of some\r\n    trade names, trademarks, or service marks; or\r\n\r\n    f) Requiring indemnification of licensors and authors of that\r\n    material by anyone who conveys the material (or modified versions of\r\n    it) with contractual assumptions of liability to the recipient, for\r\n    any liability that these contractual assumptions directly impose on\r\n    those licensors and authors.\r\n\r\n  All other non-permissive additional terms are considered \"further\r\nrestrictions\" within the meaning of section 10.  If the Program as you\r\nreceived it, or any part of it, contains a notice stating that it is\r\ngoverned by this License along with a term that is a further\r\nrestriction, you may remove that term.  If a license document contains\r\na further restriction but permits relicensing or conveying under this\r\nLicense, you may add to a covered work material governed by the terms\r\nof that license document, provided that the further restriction does\r\nnot survive such relicensing or conveying.\r\n\r\n  If you add terms to a covered work in accord with this section, you\r\nmust place, in the relevant source files, a statement of the\r\nadditional terms that apply to those files, or a notice indicating\r\nwhere to find the applicable terms.\r\n\r\n  Additional terms, permissive or non-permissive, may be stated in the\r\nform of a separately written license, or stated as exceptions;\r\nthe above requirements apply either way.\r\n\r\n  8. Termination.\r\n\r\n  You may not propagate or modify a covered work except as expressly\r\nprovided under this License.  Any attempt otherwise to propagate or\r\nmodify it is void, and will automatically terminate your rights under\r\nthis License (including any patent licenses granted under the third\r\nparagraph of section 11).\r\n\r\n  However, if you cease all violation of this License, then your\r\nlicense from a particular copyright holder is reinstated (a)\r\nprovisionally, unless and until the copyright holder explicitly and\r\nfinally terminates your license, and (b) permanently, if the copyright\r\nholder fails to notify you of the violation by some reasonable means\r\nprior to 60 days after the cessation.\r\n\r\n  Moreover, your license from a particular copyright holder is\r\nreinstated permanently if the copyright holder notifies you of the\r\nviolation by some reasonable means, this is the first time you have\r\nreceived notice of violation of this License (for any work) from that\r\ncopyright holder, and you cure the violation prior to 30 days after\r\nyour receipt of the notice.\r\n\r\n  Termination of your rights under this section does not terminate the\r\nlicenses of parties who have received copies or rights from you under\r\nthis License.  If your rights have been terminated and not permanently\r\nreinstated, you do not qualify to receive new licenses for the same\r\nmaterial under section 10.\r\n\r\n  9. Acceptance Not Required for Having Copies.\r\n\r\n  You are not required to accept this License in order to receive or\r\nrun a copy of the Program.  Ancillary propagation of a covered work\r\noccurring solely as a consequence of using peer-to-peer transmission\r\nto receive a copy likewise does not require acceptance.  However,\r\nnothing other than this License grants you permission to propagate or\r\nmodify any covered work.  These actions infringe copyright if you do\r\nnot accept this License.  Therefore, by modifying or propagating a\r\ncovered work, you indicate your acceptance of this License to do so.\r\n\r\n  10. Automatic Licensing of Downstream Recipients.\r\n\r\n  Each time you convey a covered work, the recipient automatically\r\nreceives a license from the original licensors, to run, modify and\r\npropagate that work, subject to this License.  You are not responsible\r\nfor enforcing compliance by third parties with this License.\r\n\r\n  An \"entity transaction\" is a transaction transferring control of an\r\norganization, or substantially all assets of one, or subdividing an\r\norganization, or merging organizations.  If propagation of a covered\r\nwork results from an entity transaction, each party to that\r\ntransaction who receives a copy of the work also receives whatever\r\nlicenses to the work the party's predecessor in interest had or could\r\ngive under the previous paragraph, plus a right to possession of the\r\nCorresponding Source of the work from the predecessor in interest, if\r\nthe predecessor has it or can get it with reasonable efforts.\r\n\r\n  You may not impose any further restrictions on the exercise of the\r\nrights granted or affirmed under this License.  For example, you may\r\nnot impose a license fee, royalty, or other charge for exercise of\r\nrights granted under this License, and you may not initiate litigation\r\n(including a cross-claim or counterclaim in a lawsuit) alleging that\r\nany patent claim is infringed by making, using, selling, offering for\r\nsale, or importing the Program or any portion of it.\r\n\r\n  11. Patents.\r\n\r\n  A \"contributor\" is a copyright holder who authorizes use under this\r\nLicense of the Program or a work on which the Program is based.  The\r\nwork thus licensed is called the contributor's \"contributor version\".\r\n\r\n  A contributor's \"essential patent claims\" are all patent claims\r\nowned or controlled by the contributor, whether already acquired or\r\nhereafter acquired, that would be infringed by some manner, permitted\r\nby this License, of making, using, or selling its contributor version,\r\nbut do not include claims that would be infringed only as a\r\nconsequence of further modification of the contributor version.  For\r\npurposes of this definition, \"control\" includes the right to grant\r\npatent sublicenses in a manner consistent with the requirements of\r\nthis License.\r\n\r\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\r\npatent license under the contributor's essential patent claims, to\r\nmake, use, sell, offer for sale, import and otherwise run, modify and\r\npropagate the contents of its contributor version.\r\n\r\n  In the following three paragraphs, a \"patent license\" is any express\r\nagreement or commitment, however denominated, not to enforce a patent\r\n(such as an express permission to practice a patent or covenant not to\r\nsue for patent infringement).  To \"grant\" such a patent license to a\r\nparty means to make such an agreement or commitment not to enforce a\r\npatent against the party.\r\n\r\n  If you convey a covered work, knowingly relying on a patent license,\r\nand the Corresponding Source of the work is not available for anyone\r\nto copy, free of charge and under the terms of this License, through a\r\npublicly available network server or other readily accessible means,\r\nthen you must either (1) cause the Corresponding Source to be so\r\navailable, or (2) arrange to deprive yourself of the benefit of the\r\npatent license for this particular work, or (3) arrange, in a manner\r\nconsistent with the requirements of this License, to extend the patent\r\nlicense to downstream recipients.  \"Knowingly relying\" means you have\r\nactual knowledge that, but for the patent license, your conveying the\r\ncovered work in a country, or your recipient's use of the covered work\r\nin a country, would infringe one or more identifiable patents in that\r\ncountry that you have reason to believe are valid.\r\n\r\n  If, pursuant to or in connection with a single transaction or\r\narrangement, you convey, or propagate by procuring conveyance of, a\r\ncovered work, and grant a patent license to some of the parties\r\nreceiving the covered work authorizing them to use, propagate, modify\r\nor convey a specific copy of the covered work, then the patent license\r\nyou grant is automatically extended to all recipients of the covered\r\nwork and works based on it.\r\n\r\n  A patent license is \"discriminatory\" if it does not include within\r\nthe scope of its coverage, prohibits the exercise of, or is\r\nconditioned on the non-exercise of one or more of the rights that are\r\nspecifically granted under this License.  You may not convey a covered\r\nwork if you are a party to an arrangement with a third party that is\r\nin the business of distributing software, under which you make payment\r\nto the third party based on the extent of your activity of conveying\r\nthe work, and under which the third party grants, to any of the\r\nparties who would receive the covered work from you, a discriminatory\r\npatent license (a) in connection with copies of the covered work\r\nconveyed by you (or copies made from those copies), or (b) primarily\r\nfor and in connection with specific products or compilations that\r\ncontain the covered work, unless you entered into that arrangement,\r\nor that patent license was granted, prior to 28 March 2007.\r\n\r\n  Nothing in this License shall be construed as excluding or limiting\r\nany implied license or other defenses to infringement that may\r\notherwise be available to you under applicable patent law.\r\n\r\n  12. No Surrender of Others' Freedom.\r\n\r\n  If conditions are imposed on you (whether by court order, agreement or\r\notherwise) that contradict the conditions of this License, they do not\r\nexcuse you from the conditions of this License.  If you cannot convey a\r\ncovered work so as to satisfy simultaneously your obligations under this\r\nLicense and any other pertinent obligations, then as a consequence you may\r\nnot convey it at all.  For example, if you agree to terms that obligate you\r\nto collect a royalty for further conveying from those to whom you convey\r\nthe Program, the only way you could satisfy both those terms and this\r\nLicense would be to refrain entirely from conveying the Program.\r\n\r\n  13. Use with the GNU Affero General Public License.\r\n\r\n  Notwithstanding any other provision of this License, you have\r\npermission to link or combine any covered work with a work licensed\r\nunder version 3 of the GNU Affero General Public License into a single\r\ncombined work, and to convey the resulting work.  The terms of this\r\nLicense will continue to apply to the part which is the covered work,\r\nbut the special requirements of the GNU Affero General Public License,\r\nsection 13, concerning interaction through a network will apply to the\r\ncombination as such.\r\n\r\n  14. Revised Versions of this License.\r\n\r\n  The Free Software Foundation may publish revised and/or new versions of\r\nthe GNU General Public License from time to time.  Such new versions will\r\nbe similar in spirit to the present version, but may differ in detail to\r\naddress new problems or concerns.\r\n\r\n  Each version is given a distinguishing version number.  If the\r\nProgram specifies that a certain numbered version of the GNU General\r\nPublic License \"or any later version\" applies to it, you have the\r\noption of following the terms and conditions either of that numbered\r\nversion or of any later version published by the Free Software\r\nFoundation.  If the Program does not specify a version number of the\r\nGNU General Public License, you may choose any version ever published\r\nby the Free Software Foundation.\r\n\r\n  If the Program specifies that a proxy can decide which future\r\nversions of the GNU General Public License can be used, that proxy's\r\npublic statement of acceptance of a version permanently authorizes you\r\nto choose that version for the Program.\r\n\r\n  Later license versions may give you additional or different\r\npermissions.  However, no additional obligations are imposed on any\r\nauthor or copyright holder as a result of your choosing to follow a\r\nlater version.\r\n\r\n  15. Disclaimer of Warranty.\r\n\r\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\r\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\r\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\r\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\r\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\r\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\r\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\r\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\r\n\r\n  16. Limitation of Liability.\r\n\r\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\r\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\r\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\r\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\r\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\r\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\r\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\r\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\r\nSUCH DAMAGES.\r\n\r\n  17. Interpretation of Sections 15 and 16.\r\n\r\n  If the disclaimer of warranty and limitation of liability provided\r\nabove cannot be given local legal effect according to their terms,\r\nreviewing courts shall apply local law that most closely approximates\r\nan absolute waiver of all civil liability in connection with the\r\nProgram, unless a warranty or assumption of liability accompanies a\r\ncopy of the Program in return for a fee.\r\n\r\n                     END OF TERMS AND CONDITIONS\r\n\r\n            How to Apply These Terms to Your New Programs\r\n\r\n  If you develop a new program, and you want it to be of the greatest\r\npossible use to the public, the best way to achieve this is to make it\r\nfree software which everyone can redistribute and change under these terms.\r\n\r\n  To do so, attach the following notices to the program.  It is safest\r\nto attach them to the start of each source file to most effectively\r\nstate the exclusion of warranty; and each file should have at least\r\nthe \"copyright\" line and a pointer to where the full notice is found.\r\n\r\n    <one line to give the program's name and a brief idea of what it does.>\r\n    Copyright (C) <year>  <name of author>\r\n\r\n    This program is free software: you can redistribute it and/or modify\r\n    it under the terms of the GNU General Public License as published by\r\n    the Free Software Foundation, either version 3 of the License, or\r\n    (at your option) any later version.\r\n\r\n    This program is distributed in the hope that it will be useful,\r\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n    GNU General Public License for more details.\r\n\r\n    You should have received a copy of the GNU General Public License\r\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\r\n\r\nAlso add information on how to contact you by electronic and paper mail.\r\n\r\n  If the program does terminal interaction, make it output a short\r\nnotice like this when it starts in an interactive mode:\r\n\r\n    <program>  Copyright (C) <year>  <name of author>\r\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\r\n    This is free software, and you are welcome to redistribute it\r\n    under certain conditions; type `show c' for details.\r\n\r\nThe hypothetical commands `show w' and `show c' should show the appropriate\r\nparts of the General Public License.  Of course, your program's commands\r\nmight be different; for a GUI interface, you would use an \"about box\".\r\n\r\n  You should also get your employer (if you work as a programmer) or school,\r\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\r\nFor more information on this, and how to apply and follow the GNU GPL, see\r\n<https://www.gnu.org/licenses/>.\r\n\r\n  The GNU General Public License does not permit incorporating your program\r\ninto proprietary programs.  If your program is a subroutine library, you\r\nmay consider it more useful to permit linking proprietary applications with\r\nthe library.  If this is what you want to do, use the GNU Lesser General\r\nPublic License instead of this License.  But first, please read\r\n<https://www.gnu.org/licenses/why-not-lgpl.html>.\r\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 27.51,
          "content": "> [!IMPORTANT]\n> `frontier开发分支`最新动态(2024.12.9): 更新对话时间线功能，优化xelatex论文翻译  \n> `wiki文档`最新动态(2024.12.5): 更新ollama接入指南  \n> `master主分支`最新动态(2024.12.19): 更新3.91版本，更新release页一键安装脚本  \n>\n> 2024.10.10: 突发停电，紧急恢复了提供[whl包](https://drive.google.com/file/d/19U_hsLoMrjOlQSzYS3pzWX9fTzyusArP/view?usp=sharing)的文件服务器  \n> 2024.10.8: 版本3.90加入对llama-index的初步支持，版本3.80加入插件二级菜单功能（详见wiki）  \n> 2024.5.1: 加入Doc2x翻译PDF论文的功能，[查看详情](https://github.com/binary-husky/gpt_academic/wiki/Doc2x)  \n> 2024.3.11: 全力支持Qwen、GLM、DeepseekCoder等中文大语言模型！ SoVits语音克隆模块，[查看详情](https://www.bilibili.com/video/BV1Rp421S7tF/) \n> 2024.1.17: 安装依赖时，请选择`requirements.txt`中**指定的版本**。 安装命令：`pip install -r requirements.txt`。本项目完全开源免费，您可通过订阅[在线服务](https://github.com/binary-husky/gpt_academic/wiki/online)的方式鼓励本项目的发展。\n\n<br>\n\n<div align=center>\n<h1 aligh=\"center\">\n<img src=\"docs/logo.png\" width=\"40\"> GPT 学术优化 (GPT Academic)\n</h1>\n\n[![Github][Github-image]][Github-url]\n[![License][License-image]][License-url]\n[![Releases][Releases-image]][Releases-url]\n[![Installation][Installation-image]][Installation-url]\n[![Wiki][Wiki-image]][Wiki-url]\n[![PR][PRs-image]][PRs-url]\n\n[Github-image]: https://img.shields.io/badge/github-12100E.svg?style=flat-square\n[License-image]: https://img.shields.io/github/license/binary-husky/gpt_academic?label=License&style=flat-square&color=orange\n[Releases-image]: https://img.shields.io/github/release/binary-husky/gpt_academic?label=Release&style=flat-square&color=blue\n[Installation-image]: https://img.shields.io/badge/dynamic/json?color=blue&url=https://raw.githubusercontent.com/binary-husky/gpt_academic/master/version&query=$.version&label=Installation&style=flat-square\n[Wiki-image]: https://img.shields.io/badge/wiki-项目文档-black?style=flat-square\n[PRs-image]: https://img.shields.io/badge/PRs-welcome-pink?style=flat-square\n\n[Github-url]: https://github.com/binary-husky/gpt_academic\n[License-url]: https://github.com/binary-husky/gpt_academic/blob/master/LICENSE\n[Releases-url]: https://github.com/binary-husky/gpt_academic/releases\n[Installation-url]: https://github.com/binary-husky/gpt_academic#installation\n[Wiki-url]: https://github.com/binary-husky/gpt_academic/wiki\n[PRs-url]: https://github.com/binary-husky/gpt_academic/pulls\n\n\n</div>\n<br>\n\n**如果喜欢这个项目，请给它一个Star；如果您发明了好用的快捷键或插件，欢迎发pull requests！**\n\nIf you like this project, please give it a Star.\nRead this in [English](docs/README.English.md) | [日本語](docs/README.Japanese.md) | [한국어](docs/README.Korean.md) | [Русский](docs/README.Russian.md) | [Français](docs/README.French.md). All translations have been provided by the project itself. To translate this project to arbitrary language with GPT, read and run [`multi_language.py`](multi_language.py) (experimental).\n<br>\n\n> [!NOTE]\n> 1.本项目中每个文件的功能都在[自译解报告](https://github.com/binary-husky/gpt_academic/wiki/GPT‐Academic项目自译解报告)`self_analysis.md`详细说明。随着版本的迭代，您也可以随时自行点击相关函数插件，调用GPT重新生成项目的自我解析报告。常见问题请查阅wiki。\n>    [![常规安装方法](https://img.shields.io/static/v1?label=&message=常规安装方法&color=gray)](#installation)  [![一键安装脚本](https://img.shields.io/static/v1?label=&message=一键安装脚本&color=gray)](https://github.com/binary-husky/gpt_academic/releases)  [![配置说明](https://img.shields.io/static/v1?label=&message=配置说明&color=gray)](https://github.com/binary-husky/gpt_academic/wiki/项目配置说明) [![wiki](https://img.shields.io/static/v1?label=&message=wiki&color=gray)]([https://github.com/binary-husky/gpt_academic/wiki/项目配置说明](https://github.com/binary-husky/gpt_academic/wiki))\n>\n> 2.本项目兼容并鼓励尝试国内中文大语言基座模型如通义千问，智谱GLM等。支持多个api-key共存，可在配置文件中填写如`API_KEY=\"openai-key1,openai-key2,azure-key3,api2d-key4\"`。需要临时更换`API_KEY`时，在输入区输入临时的`API_KEY`然后回车键提交即可生效。\n\n<br><br>\n\n<div align=\"center\">\n\n功能（⭐= 近期新增功能） | 描述\n--- | ---\n⭐[接入新模型](https://github.com/binary-husky/gpt_academic/wiki/%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%E6%A8%A1%E5%9E%8B) | 百度[千帆](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Nlks5zkzu)与文心一言, 通义千问[Qwen](https://modelscope.cn/models/qwen/Qwen-7B-Chat/summary)，上海AI-Lab[书生](https://github.com/InternLM/InternLM)，讯飞[星火](https://xinghuo.xfyun.cn/)，[LLaMa2](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)，[智谱GLM4](https://open.bigmodel.cn/)，DALLE3, [DeepseekCoder](https://coder.deepseek.com/)\n⭐支持mermaid图像渲染 | 支持让GPT生成[流程图](https://www.bilibili.com/video/BV18c41147H9/)、状态转移图、甘特图、饼状图、GitGraph等等（3.7版本）\n⭐Arxiv论文精细翻译 ([Docker](https://github.com/binary-husky/gpt_academic/pkgs/container/gpt_academic_with_latex)) | [插件] 一键[以超高质量翻译arxiv论文](https://www.bilibili.com/video/BV1dz4y1v77A/)，目前最好的论文翻译工具\n⭐[实时语音对话输入](https://github.com/binary-husky/gpt_academic/blob/master/docs/use_audio.md) | [插件] 异步[监听音频](https://www.bilibili.com/video/BV1AV4y187Uy/)，自动断句，自动寻找回答时机\n⭐AutoGen多智能体插件 | [插件] 借助微软AutoGen，探索多Agent的智能涌现可能！\n⭐虚空终端插件 | [插件] 能够使用自然语言直接调度本项目其他插件\n润色、翻译、代码解释 | 一键润色、翻译、查找论文语法错误、解释代码\n[自定义快捷键](https://www.bilibili.com/video/BV14s4y1E7jN) | 支持自定义快捷键\n模块化设计 | 支持自定义强大的[插件](https://github.com/binary-husky/gpt_academic/tree/master/crazy_functions)，插件支持[热更新](https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97)\n[程序剖析](https://www.bilibili.com/video/BV1cj411A7VW) | [插件] 一键剖析Python/C/C++/Java/Lua/...项目树 或 [自我剖析](https://www.bilibili.com/video/BV1cj411A7VW)\n读论文、[翻译](https://www.bilibili.com/video/BV1KT411x7Wn)论文 | [插件] 一键解读latex/pdf论文全文并生成摘要\nLatex全文[翻译](https://www.bilibili.com/video/BV1nk4y1Y7Js/)、[润色](https://www.bilibili.com/video/BV1FT411H7c5/) | [插件] 一键翻译或润色latex论文\n批量注释生成 | [插件] 一键批量生成函数注释\nMarkdown[中英互译](https://www.bilibili.com/video/BV1yo4y157jV/) | [插件] 看到上面5种语言的[README](https://github.com/binary-husky/gpt_academic/blob/master/docs/README.English.md)了吗？就是出自他的手笔\n[PDF论文全文翻译功能](https://www.bilibili.com/video/BV1KT411x7Wn) | [插件] PDF论文提取题目&摘要+翻译全文（多线程）\n[Arxiv小助手](https://www.bilibili.com/video/BV1LM4y1279X) | [插件] 输入arxiv文章url即可一键翻译摘要+下载PDF\nLatex论文一键校对 | [插件] 仿Grammarly对Latex文章进行语法、拼写纠错+输出对照PDF\n[谷歌学术统合小助手](https://www.bilibili.com/video/BV19L411U7ia) | [插件] 给定任意谷歌学术搜索页面URL，让gpt帮你[写relatedworks](https://www.bilibili.com/video/BV1GP411U7Az/)\n互联网信息聚合+GPT | [插件] 一键[让GPT从互联网获取信息](https://www.bilibili.com/video/BV1om4y127ck)回答问题，让信息永不过时\n公式/图片/表格显示 | 可以同时显示公式的[tex形式和渲染形式](https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png)，支持公式、代码高亮\n启动暗色[主题](https://github.com/binary-husky/gpt_academic/issues/173) | 在浏览器url后面添加```/?__theme=dark```可以切换dark主题\n[多LLM模型](https://www.bilibili.com/video/BV1wT411p7yf)支持 | 同时被GPT3.5、GPT4、[清华ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)、[复旦MOSS](https://github.com/OpenLMLab/MOSS)伺候的感觉一定会很不错吧？\n更多LLM模型接入，支持[huggingface部署](https://huggingface.co/spaces/qingxu98/gpt-academic) | 加入Newbing接口(新必应)，引入清华[Jittorllms](https://github.com/Jittor/JittorLLMs)支持[LLaMA](https://github.com/facebookresearch/llama)和[盘古α](https://openi.org.cn/pangu/)\n⭐[void-terminal](https://github.com/binary-husky/void-terminal) pip包 | 脱离GUI，在Python中直接调用本项目的所有函数插件（开发中）\n更多新功能展示 (图像生成等) …… | 见本文档结尾处 ……\n</div>\n\n\n- 新界面（修改`config.py`中的LAYOUT选项即可实现“左右布局”和“上下布局”的切换）\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/279702205-d81137c3-affd-4cd1-bb5e-b15610389762.gif\" width=\"700\" >\n</div>\n\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/70ff1ec5-e589-4561-a29e-b831079b37fb.gif\" width=\"700\" >\n</div>\n\n\n- 所有按钮都通过读取functional.py动态生成，可随意加自定义功能，解放剪贴板\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/231975334-b4788e91-4887-412f-8b43-2b9c5f41d248.gif\" width=\"700\" >\n</div>\n\n- 润色/纠错\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/231980294-f374bdcb-3309-4560-b424-38ef39f04ebd.gif\" width=\"700\" >\n</div>\n\n- 如果输出包含公式，会以tex形式和渲染形式同时显示，方便复制和阅读\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png\" width=\"700\" >\n</div>\n\n- 懒得看项目代码？直接把整个工程炫ChatGPT嘴里\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png\" width=\"700\" >\n</div>\n\n- 多种大语言模型混合调用（ChatGLM + OpenAI-GPT3.5 + GPT4）\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/232537274-deca0563-7aa6-4b5d-94a2-b7c453c47794.png\" width=\"700\" >\n</div>\n\n<br><br>\n\n# Installation\n\n```mermaid\nflowchart TD\n    A{\"安装方法\"} --> W1(\"I. 🔑直接运行 (Windows, Linux or MacOS)\")\n    W1 --> W11[\"1. Python pip包管理依赖\"]\n    W1 --> W12[\"2. Anaconda包管理依赖（推荐⭐）\"]\n\n    A --> W2[\"II. 🐳使用Docker (Windows, Linux or MacOS)\"]\n\n    W2 --> k1[\"1. 部署项目全部能力的大镜像（推荐⭐）\"]\n    W2 --> k2[\"2. 仅在线模型（GPT, GLM4等）镜像\"]\n    W2 --> k3[\"3. 在线模型 + Latex的大镜像\"]\n\n    A --> W4[\"IV. 🚀其他部署方法\"]\n    W4 --> C1[\"1. Windows/MacOS 一键安装运行脚本（推荐⭐）\"]\n    W4 --> C2[\"2. Huggingface, Sealos远程部署\"]\n    W4 --> C4[\"3. ... 其他 ...\"]\n```\n\n### 安装方法I：直接运行 (Windows, Linux or MacOS)\n\n1. 下载项目\n\n    ```sh\n    git clone --depth=1 https://github.com/binary-husky/gpt_academic.git\n    cd gpt_academic\n    ```\n\n2. 配置API_KEY等变量\n\n    在`config.py`中，配置API KEY等变量。[特殊网络环境设置方法](https://github.com/binary-husky/gpt_academic/issues/1)、[Wiki-项目配置说明](https://github.com/binary-husky/gpt_academic/wiki/项目配置说明)。\n\n    「 程序会优先检查是否存在名为`config_private.py`的私密配置文件，并用其中的配置覆盖`config.py`的同名配置。如您能理解以上读取逻辑，我们强烈建议您在`config.py`同路径下创建一个名为`config_private.py`的新配置文件，并使用`config_private.py`配置项目，从而确保自动更新时不会丢失配置 」。\n\n    「 支持通过`环境变量`配置项目，环境变量的书写格式参考`docker-compose.yml`文件或者我们的[Wiki页面](https://github.com/binary-husky/gpt_academic/wiki/项目配置说明)。配置读取优先级: `环境变量` > `config_private.py` > `config.py` 」。\n\n\n3. 安装依赖\n    ```sh\n    # （选择I: 如熟悉python, python推荐版本 3.9 ~ 3.11）备注：使用官方pip源或者阿里pip源, 临时换源方法：python -m pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/\n    python -m pip install -r requirements.txt\n\n    # （选择II: 使用Anaconda）步骤也是类似的 (https://www.bilibili.com/video/BV1rc411W7Dr)：\n    conda create -n gptac_venv python=3.11    # 创建anaconda环境\n    conda activate gptac_venv                 # 激活anaconda环境\n    python -m pip install -r requirements.txt # 这个步骤和pip安装一样的步骤\n    ```\n\n\n<details><summary>如果需要支持清华ChatGLM系列/复旦MOSS/RWKV作为后端，请点击展开此处</summary>\n<p>\n\n【可选步骤】如果需要支持清华ChatGLM系列/复旦MOSS作为后端，需要额外安装更多依赖（前提条件：熟悉Python + 用过Pytorch + 电脑配置够强）：\n\n```sh\n# 【可选步骤I】支持清华ChatGLM3。清华ChatGLM备注：如果遇到\"Call ChatGLM fail 不能正常加载ChatGLM的参数\" 错误，参考如下： 1：以上默认安装的为torch+cpu版，使用cuda需要卸载torch重新安装torch+cuda； 2：如因本机配置不够无法加载模型，可以修改request_llm/bridge_chatglm.py中的模型精度, 将 AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True) 都修改为 AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True)\npython -m pip install -r request_llms/requirements_chatglm.txt\n\n# 【可选步骤II】支持清华ChatGLM4 注意：此模型至少需要24G显存\npython -m pip install -r request_llms/requirements_chatglm4.txt\n# 可使用modelscope下载ChatGLM4模型\n# pip install modelscope\n# modelscope download --model ZhipuAI/glm-4-9b-chat --local_dir ./THUDM/glm-4-9b-chat\n\n# 【可选步骤III】支持复旦MOSS\npython -m pip install -r request_llms/requirements_moss.txt\ngit clone --depth=1 https://github.com/OpenLMLab/MOSS.git request_llms/moss  # 注意执行此行代码时，必须处于项目根路径\n\n# 【可选步骤IV】支持RWKV Runner\n参考wiki：https://github.com/binary-husky/gpt_academic/wiki/%E9%80%82%E9%85%8DRWKV-Runner\n\n# 【可选步骤V】确保config.py配置文件的AVAIL_LLM_MODELS包含了期望的模型，目前支持的全部模型如下(jittorllms系列目前仅支持docker方案)：\nAVAIL_LLM_MODELS = [\"gpt-3.5-turbo\", \"api2d-gpt-3.5-turbo\", \"gpt-4\", \"api2d-gpt-4\", \"chatglm\", \"moss\"] # + [\"jittorllms_rwkv\", \"jittorllms_pangualpha\", \"jittorllms_llama\"]\n\n# 【可选步骤VI】支持本地模型INT8,INT4量化（这里所指的模型本身不是量化版本，目前deepseek-coder支持，后面测试后会加入更多模型量化选择）\npip install bitsandbyte\n# windows用户安装bitsandbytes需要使用下面bitsandbytes-windows-webui\npython -m pip install bitsandbytes --prefer-binary --extra-index-url=https://jllllll.github.io/bitsandbytes-windows-webui\npip install -U git+https://github.com/huggingface/transformers.git\npip install -U git+https://github.com/huggingface/accelerate.git\npip install peft\n```\n\n</p>\n</details>\n\n\n\n4. 运行\n    ```sh\n    python main.py\n    ```\n\n### 安装方法II：使用Docker\n\n0. 部署项目的全部能力（这个是包含cuda和latex的大型镜像。但如果您网速慢、硬盘小，则不推荐该方法部署完整项目）\n[![fullcapacity](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-all-capacity.yml/badge.svg?branch=master)](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-all-capacity.yml)\n\n    ``` sh\n    # 修改docker-compose.yml，保留方案0并删除其他方案。然后运行：\n    docker-compose up\n    ```\n\n1. 仅ChatGPT + GLM4 + 文心一言+spark等在线模型（推荐大多数人选择）\n[![basic](https://github.com/binary-husky/gpt_academic/actions/workflows/build-without-local-llms.yml/badge.svg?branch=master)](https://github.com/binary-husky/gpt_academic/actions/workflows/build-without-local-llms.yml)\n[![basiclatex](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-latex.yml/badge.svg?branch=master)](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-latex.yml)\n[![basicaudio](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-audio-assistant.yml/badge.svg?branch=master)](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-audio-assistant.yml)\n\n    ``` sh\n    # 修改docker-compose.yml，保留方案1并删除其他方案。然后运行：\n    docker-compose up\n    ```\n\nP.S. 如果需要依赖Latex的插件功能，请见Wiki。另外，您也可以直接使用方案4或者方案0获取Latex功能。\n\n2. ChatGPT + GLM3 + MOSS + LLAMA2 + 通义千问（需要熟悉[Nvidia Docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian)运行时）\n[![chatglm](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-chatglm.yml/badge.svg?branch=master)](https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-chatglm.yml)\n\n    ``` sh\n    # 修改docker-compose.yml，保留方案2并删除其他方案。然后运行：\n    docker-compose up\n    ```\n\n\n### 安装方法III：其他部署方法\n1. **Windows一键运行脚本**。\n完全不熟悉python环境的Windows用户可以下载[Release](https://github.com/binary-husky/gpt_academic/releases)中发布的一键运行脚本安装无本地模型的版本。脚本贡献来源：[oobabooga](https://github.com/oobabooga/one-click-installers)。\n\n2. 使用第三方API、Azure等、文心一言、星火等，见[Wiki页面](https://github.com/binary-husky/gpt_academic/wiki/项目配置说明)\n\n3. 云服务器远程部署避坑指南。\n请访问[云服务器远程部署wiki](https://github.com/binary-husky/gpt_academic/wiki/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9C%E7%A8%8B%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97)\n\n4. 在其他平台部署&二级网址部署\n    - 使用Sealos[一键部署](https://github.com/binary-husky/gpt_academic/issues/993)。\n    - 使用WSL2（Windows Subsystem for Linux 子系统）。请访问[部署wiki-2](https://github.com/binary-husky/gpt_academic/wiki/%E4%BD%BF%E7%94%A8WSL2%EF%BC%88Windows-Subsystem-for-Linux-%E5%AD%90%E7%B3%BB%E7%BB%9F%EF%BC%89%E9%83%A8%E7%BD%B2)\n    - 如何在二级网址（如`http://localhost/subpath`）下运行。请访问[FastAPI运行说明](docs/WithFastapi.md)\n\n<br><br>\n\n# Advanced Usage\n### I：自定义新的便捷按钮（学术快捷键）\n\n现在已可以通过UI中的`界面外观`菜单中的`自定义菜单`添加新的便捷按钮。如果需要在代码中定义，请使用任意文本编辑器打开`core_functional.py`，添加如下条目即可：\n\n```python\n\"超级英译中\": {\n    # 前缀，会被加在你的输入之前。例如，用来描述你的要求，例如翻译、解释代码、润色等等\n    \"Prefix\": \"请翻译把下面一段内容成中文，然后用一个markdown表格逐一解释文中出现的专有名词：\\n\\n\",\n\n    # 后缀，会被加在你的输入之后。例如，配合前缀可以把你的输入内容用引号圈起来。\n    \"Suffix\": \"\",\n},\n```\n\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/226899272-477c2134-ed71-4326-810c-29891fe4a508.png\" width=\"500\" >\n</div>\n\n### II：自定义函数插件\n编写强大的函数插件来执行任何你想得到的和想不到的任务。\n本项目的插件编写、调试难度很低，只要您具备一定的python基础知识，就可以仿照我们提供的模板实现自己的插件功能。\n详情请参考[函数插件指南](https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97)。\n\n<br><br>\n\n# Updates\n### I：动态\n\n1. 对话保存功能。在函数插件区调用 `保存当前的对话` 即可将当前对话保存为可读+可复原的html文件，\n另外在函数插件区（下拉菜单）调用 `载入对话历史存档` ，即可还原之前的会话。\nTip：不指定文件直接点击 `载入对话历史存档` 可以查看历史html存档缓存。\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/235222390-24a9acc0-680f-49f5-bc81-2f3161f1e049.png\" width=\"500\" >\n</div>\n\n2. ⭐Latex/Arxiv论文翻译功能⭐\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/002a1a75-ace0-4e6a-94e2-ec1406a746f1\" height=\"250\" > ===>\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/9fdcc391-f823-464f-9322-f8719677043b\" height=\"250\" >\n</div>\n\n3. 虚空终端（从自然语言输入中，理解用户意图+自动调用其他插件）\n\n- 步骤一：输入 “ 请调用插件翻译PDF论文，地址为https://openreview.net/pdf?id=rJl0r3R9KX ”\n- 步骤二：点击“虚空终端”\n\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/66f1b044-e9ff-4eed-9126-5d4f3668f1ed\" width=\"500\" >\n</div>\n\n4. 模块化功能设计，简单的接口却能支持强大的功能\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/229288270-093643c1-0018-487a-81e6-1d7809b6e90f.png\" height=\"400\" >\n<img src=\"https://user-images.githubusercontent.com/96192199/227504931-19955f78-45cd-4d1c-adac-e71e50957915.png\" height=\"400\" >\n</div>\n\n5. 译解其他开源项目\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png\" height=\"250\" >\n<img src=\"https://user-images.githubusercontent.com/96192199/226969067-968a27c1-1b9c-486b-8b81-ab2de8d3f88a.png\" height=\"250\" >\n</div>\n\n6. 装饰[live2d](https://github.com/fghrsh/live2d_demo)的小功能（默认关闭，需要修改`config.py`）\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/96192199/236432361-67739153-73e8-43fe-8111-b61296edabd9.png\" width=\"500\" >\n</div>\n\n7. OpenAI图像生成\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/bc7ab234-ad90-48a0-8d62-f703d9e74665\" width=\"500\" >\n</div>\n\n8. 基于mermaid的流图、脑图绘制\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/c518b82f-bd53-46e2-baf5-ad1b081c1da4\" width=\"500\" >\n</div>\n\n9. Latex全文校对纠错\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/651ccd98-02c9-4464-91e1-77a6b7d1b033\" height=\"200\" > ===>\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/476f66d9-7716-4537-b5c1-735372c25adb\" height=\"200\">\n</div>\n\n10. 语言、主题切换\n<div align=\"center\">\n<img src=\"https://github.com/binary-husky/gpt_academic/assets/96192199/b6799499-b6fb-4f0c-9c8e-1b441872f4e8\" width=\"500\" >\n</div>\n\n\n\n### II：版本:\n- version 3.80(TODO): 优化AutoGen插件主题并设计一系列衍生插件\n- version 3.70: 引入Mermaid绘图，实现GPT画脑图等功能   \n- version 3.60: 引入AutoGen作为新一代插件的基石\n- version 3.57: 支持GLM3，星火v3，文心一言v4，修复本地模型的并发BUG\n- version 3.56: 支持动态追加基础功能按钮，新汇报PDF汇总页面\n- version 3.55: 重构前端界面，引入悬浮窗口与菜单栏\n- version 3.54: 新增动态代码解释器（Code Interpreter）（待完善）\n- version 3.53: 支持动态选择不同界面主题，提高稳定性&解决多用户冲突问题\n- version 3.50: 使用自然语言调用本项目的所有函数插件（虚空终端），支持插件分类，改进UI，设计新主题\n- version 3.49: 支持百度千帆平台和文心一言\n- version 3.48: 支持阿里达摩院通义千问，上海AI-Lab书生，讯飞星火\n- version 3.46: 支持完全脱手操作的实时语音对话\n- version 3.45: 支持自定义ChatGLM2微调模型\n- version 3.44: 正式支持Azure，优化界面易用性\n- version 3.4: +arxiv论文翻译、latex论文批改功能\n- version 3.3: +互联网信息综合功能\n- version 3.2: 函数插件支持更多参数接口 (保存对话功能, 解读任意语言代码+同时询问任意的LLM组合)\n- version 3.1: 支持同时问询多个gpt模型！支持api2d，支持多个apikey负载均衡\n- version 3.0: 对chatglm和其他小型llm的支持\n- version 2.6: 重构了插件结构，提高了交互性，加入更多插件\n- version 2.5: 自更新，解决总结大工程源代码时文本过长、token溢出的问题\n- version 2.4: 新增PDF全文翻译功能; 新增输入区切换位置的功能\n- version 2.3: 增强多线程交互性\n- version 2.2: 函数插件支持热重载\n- version 2.1: 可折叠式布局\n- version 2.0: 引入模块化函数插件\n- version 1.0: 基础功能\n\nGPT Academic开发者QQ群：`610599535`\n\n- 已知问题\n    - 某些浏览器翻译插件干扰此软件前端的运行\n    - 官方Gradio目前有很多兼容性问题，请**务必使用`requirement.txt`安装Gradio**\n\n```mermaid\ntimeline LR\n    title GPT-Academic项目发展历程\n    section 2.x\n        1.0~2.2: 基础功能: 引入模块化函数插件: 可折叠式布局: 函数插件支持热重载\n        2.3~2.5: 增强多线程交互性: 新增PDF全文翻译功能: 新增输入区切换位置的功能: 自更新\n        2.6: 重构了插件结构: 提高了交互性: 加入更多插件\n    section 3.x\n        3.0~3.1: 对chatglm支持: 对其他小型llm支持: 支持同时问询多个gpt模型: 支持多个apikey负载均衡\n        3.2~3.3: 函数插件支持更多参数接口: 保存对话功能: 解读任意语言代码: 同时询问任意的LLM组合: 互联网信息综合功能\n        3.4: 加入arxiv论文翻译: 加入latex论文批改功能\n        3.44: 正式支持Azure: 优化界面易用性\n        3.46: 自定义ChatGLM2微调模型: 实时语音对话\n        3.49: 支持阿里达摩院通义千问: 上海AI-Lab书生: 讯飞星火: 支持百度千帆平台 & 文心一言\n        3.50: 虚空终端: 支持插件分类: 改进UI: 设计新主题\n        3.53: 动态选择不同界面主题: 提高稳定性: 解决多用户冲突问题\n        3.55: 动态代码解释器: 重构前端界面: 引入悬浮窗口与菜单栏\n        3.56: 动态追加基础功能按钮: 新汇报PDF汇总页面\n        3.57: GLM3, 星火v3: 支持文心一言v4: 修复本地模型的并发BUG\n        3.60: 引入AutoGen\n        3.70: 引入Mermaid绘图: 实现GPT画脑图等功能\n        3.80(TODO): 优化AutoGen插件主题: 设计衍生插件\n\n```\n\n\n### III：主题\n可以通过修改`THEME`选项（config.py）变更主题\n1. `Chuanhu-Small-and-Beautiful` [网址](https://github.com/GaiZhenbiao/ChuanhuChatGPT/)\n\n\n### IV：本项目的开发分支\n\n1. `master` 分支: 主分支，稳定版\n2. `frontier` 分支: 开发分支，测试版\n3. 如何[接入其他大模型](request_llms/README.md)\n4. 访问GPT-Academic的[在线服务并支持我们](https://github.com/binary-husky/gpt_academic/wiki/online)\n\n### V：参考与学习\n\n```\n代码中参考了很多其他优秀项目中的设计，顺序不分先后：\n\n# 清华ChatGLM2-6B:\nhttps://github.com/THUDM/ChatGLM2-6B\n\n# 清华JittorLLMs:\nhttps://github.com/Jittor/JittorLLMs\n\n# ChatPaper:\nhttps://github.com/kaixindelele/ChatPaper\n\n# Edge-GPT:\nhttps://github.com/acheong08/EdgeGPT\n\n# ChuanhuChatGPT:\nhttps://github.com/GaiZhenbiao/ChuanhuChatGPT\n\n# Oobabooga one-click installer:\nhttps://github.com/oobabooga/one-click-installers\n\n# More：\nhttps://github.com/gradio-app/gradio\nhttps://github.com/fghrsh/live2d_demo\n```\n"
        },
        {
          "name": "check_proxy.py",
          "type": "blob",
          "size": 10.02,
          "content": "from loguru import logger\n\ndef check_proxy(proxies, return_ip=False):\n    \"\"\"\n    检查代理配置并返回结果。\n\n    Args:\n        proxies (dict): 包含http和https代理配置的字典。\n        return_ip (bool, optional): 是否返回代理的IP地址。默认为False。\n\n    Returns:\n        str or None: 检查的结果信息或代理的IP地址（如果`return_ip`为True）。\n    \"\"\"\n    import requests\n    proxies_https = proxies['https'] if proxies is not None else '无'\n    ip = None\n    try:\n        response = requests.get(\"https://ipapi.co/json/\", proxies=proxies, timeout=4)  # ⭐ 执行GET请求以获取代理信息\n        data = response.json()\n        if 'country_name' in data:\n            country = data['country_name']\n            result = f\"代理配置 {proxies_https}, 代理所在地：{country}\"\n            if 'ip' in data:\n                ip = data['ip']\n        elif 'error' in data:\n            alternative, ip = _check_with_backup_source(proxies)  # ⭐ 调用备用方法检查代理配置\n            if alternative is None:\n                result = f\"代理配置 {proxies_https}, 代理所在地：未知，IP查询频率受限\"\n            else:\n                result = f\"代理配置 {proxies_https}, 代理所在地：{alternative}\"\n        else:\n            result = f\"代理配置 {proxies_https}, 代理数据解析失败：{data}\"\n\n        if not return_ip:\n            logger.warning(result)\n            return result\n        else:\n            return ip\n    except:\n        result = f\"代理配置 {proxies_https}, 代理所在地查询超时，代理可能无效\"\n        if not return_ip:\n            logger.warning(result)\n            return result\n        else:\n            return ip\n\ndef _check_with_backup_source(proxies):\n    \"\"\"\n    通过备份源检查代理，并获取相应信息。\n\n    Args:\n        proxies (dict): 包含代理信息的字典。\n\n    Returns:\n        tuple: 代理信息(geo)和IP地址(ip)的元组。\n    \"\"\"\n    import random, string, requests\n    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=32))\n    try:\n        res_json = requests.get(f\"http://{random_string}.edns.ip-api.com/json\", proxies=proxies, timeout=4).json()  # ⭐ 执行代理检查和备份源请求\n        return res_json['dns']['geo'], res_json['dns']['ip']\n    except:\n        return None, None\n\ndef backup_and_download(current_version, remote_version):\n    \"\"\"\n    一键更新协议：备份当前版本，下载远程版本并解压缩。\n\n    Args:\n        current_version (str): 当前版本号。\n        remote_version (str): 远程版本号。\n\n    Returns:\n        str: 新版本目录的路径。\n    \"\"\"\n    from toolbox import get_conf\n    import shutil\n    import os\n    import requests\n    import zipfile\n    os.makedirs(f'./history', exist_ok=True)\n    backup_dir = f'./history/backup-{current_version}/'\n    new_version_dir = f'./history/new-version-{remote_version}/'\n    if os.path.exists(new_version_dir):\n        return new_version_dir\n    os.makedirs(new_version_dir)\n    shutil.copytree('./', backup_dir, ignore=lambda x, y: ['history'])\n    proxies = get_conf('proxies')\n    try:    r = requests.get('https://github.com/binary-husky/chatgpt_academic/archive/refs/heads/master.zip', proxies=proxies, stream=True)\n    except: r = requests.get('https://public.agent-matrix.com/publish/master.zip', proxies=proxies, stream=True)\n    zip_file_path = backup_dir+'/master.zip'  # ⭐ 保存备份文件的路径\n    with open(zip_file_path, 'wb+') as f:\n        f.write(r.content)\n    dst_path = new_version_dir\n    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n        for zip_info in zip_ref.infolist():\n            dst_file_path = os.path.join(dst_path, zip_info.filename)\n            if os.path.exists(dst_file_path):\n                os.remove(dst_file_path)\n            zip_ref.extract(zip_info, dst_path)\n    return new_version_dir\n\n\ndef patch_and_restart(path):\n    \"\"\"\n    一键更新协议：覆盖和重启\n\n    Args:\n        path (str): 新版本代码所在的路径\n\n    注意事项:\n        如果您的程序没有使用config_private.py私密配置文件，则会将config.py重命名为config_private.py以避免配置丢失。\n\n    更新流程:\n        - 复制最新版本代码到当前目录\n        - 更新pip包依赖\n        - 如果更新失败，则提示手动安装依赖库并重启\n    \"\"\"\n    from distutils import dir_util\n    import shutil\n    import os\n    import sys\n    import time\n    import glob\n    from shared_utils.colorful import log亮黄, log亮绿, log亮红\n\n    if not os.path.exists('config_private.py'):\n        log亮黄('由于您没有设置config_private.py私密配置，现将您的现有配置移动至config_private.py以防止配置丢失，',\n              '另外您可以随时在history子文件夹下找回旧版的程序。')\n        shutil.copyfile('config.py', 'config_private.py')\n\n    path_new_version = glob.glob(path + '/*-master')[0]\n    dir_util.copy_tree(path_new_version, './')  # ⭐ 将最新版本代码复制到当前目录\n\n    log亮绿('代码已经更新，即将更新pip包依赖……')\n    for i in reversed(range(5)): time.sleep(1); log亮绿(i)\n\n    try:\n        import subprocess\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'])\n    except:\n        log亮红('pip包依赖安装出现问题，需要手动安装新增的依赖库 `python -m pip install -r requirements.txt`，然后在用常规的`python main.py`的方式启动。')\n\n    log亮绿('更新完成，您可以随时在history子文件夹下找回旧版的程序，5s之后重启')\n    log亮红('假如重启失败，您可能需要手动安装新增的依赖库 `python -m pip install -r requirements.txt`，然后在用常规的`python main.py`的方式启动。')\n    log亮绿(' ------------------------------ -----------------------------------')\n\n    for i in reversed(range(8)): time.sleep(1); log亮绿(i)\n    os.execl(sys.executable, sys.executable, *sys.argv)  # 重启程序\n\n\ndef get_current_version():\n    \"\"\"\n    获取当前的版本号。\n\n    Returns:\n        str: 当前的版本号。如果无法获取版本号，则返回空字符串。\n    \"\"\"\n    import json\n    try:\n        with open('./version', 'r', encoding='utf8') as f:\n            current_version = json.loads(f.read())['version']  # ⭐ 从读取的json数据中提取版本号\n    except:\n        current_version = \"\"\n    return current_version\n\n\ndef auto_update(raise_error=False):\n    \"\"\"\n    一键更新协议：查询版本和用户意见\n\n    Args:\n        raise_error (bool, optional): 是否在出错时抛出错误。默认为 False。\n\n    Returns:\n        None\n    \"\"\"\n    try:\n        from toolbox import get_conf\n        import requests\n        import json\n        proxies = get_conf('proxies')\n        try:    response = requests.get(\"https://raw.githubusercontent.com/binary-husky/chatgpt_academic/master/version\", proxies=proxies, timeout=5)\n        except: response = requests.get(\"https://public.agent-matrix.com/publish/version\", proxies=proxies, timeout=5)\n        remote_json_data = json.loads(response.text)\n        remote_version = remote_json_data['version']\n        if remote_json_data[\"show_feature\"]:\n            new_feature = \"新功能：\" + remote_json_data[\"new_feature\"]\n        else:\n            new_feature = \"\"\n        with open('./version', 'r', encoding='utf8') as f:\n            current_version = f.read()\n            current_version = json.loads(current_version)['version']\n        if (remote_version - current_version) >= 0.01-1e-5:\n            from shared_utils.colorful import log亮黄\n            log亮黄(f'\\n新版本可用。新版本:{remote_version}，当前版本:{current_version}。{new_feature}')  # ⭐ 在控制台打印新版本信息\n            logger.info('（1）Github更新地址:\\nhttps://github.com/binary-husky/chatgpt_academic\\n')\n            user_instruction = input('（2）是否一键更新代码（Y+回车=确认，输入其他/无输入+回车=不更新）？')\n            if user_instruction in ['Y', 'y']:\n                path = backup_and_download(current_version, remote_version)  # ⭐ 备份并下载文件\n                try:\n                    patch_and_restart(path)  # ⭐ 执行覆盖并重启操作\n                except:\n                    msg = '更新失败。'\n                    if raise_error:\n                        from toolbox import trimmed_format_exc\n                        msg += trimmed_format_exc()\n                    logger.warning(msg)\n            else:\n                logger.info('自动更新程序：已禁用')\n                return\n        else:\n            return\n    except:\n        msg = '自动更新程序：已禁用。建议排查：代理网络配置。'\n        if raise_error:\n            from toolbox import trimmed_format_exc\n            msg += trimmed_format_exc()\n        logger.info(msg)\n\ndef warm_up_modules():\n    \"\"\"\n    预热模块，加载特定模块并执行预热操作。\n    \"\"\"\n    logger.info('正在执行一些模块的预热 ...')\n    from toolbox import ProxyNetworkActivate\n    from request_llms.bridge_all import model_info\n    with ProxyNetworkActivate(\"Warmup_Modules\"):\n        enc = model_info[\"gpt-3.5-turbo\"]['tokenizer']\n        enc.encode(\"模块预热\", disallowed_special=())\n        enc = model_info[\"gpt-4\"]['tokenizer']\n        enc.encode(\"模块预热\", disallowed_special=())\n\ndef warm_up_vectordb():\n    \"\"\"\n    执行一些模块的预热操作。\n\n    本函数主要用于执行一些模块的预热操作，确保在后续的流程中能够顺利运行。\n\n    ⭐ 关键作用：预热模块\n\n    Returns:\n        None\n    \"\"\"\n    logger.info('正在执行一些模块的预热 ...')\n    from toolbox import ProxyNetworkActivate\n    with ProxyNetworkActivate(\"Warmup_Modules\"):\n        import nltk\n        with ProxyNetworkActivate(\"Warmup_Modules\"): nltk.download(\"punkt\")\n\n\nif __name__ == '__main__':\n    import os\n    os.environ['no_proxy'] = '*'  # 避免代理网络产生意外污染\n    from toolbox import get_conf\n    proxies = get_conf('proxies')\n    check_proxy(proxies)"
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 16,
          "content": "\"\"\"\n    以下所有配置也都支持利用环境变量覆写，环境变量配置格式见docker-compose.yml。\n    读取优先级：环境变量 > config_private.py > config.py\n    --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n    All the following configurations also support using environment variables to override,\n    and the environment variable configuration format can be seen in docker-compose.yml.\n    Configuration reading priority: environment variable > config_private.py > config.py\n\"\"\"\n\n# [step 1-1]>> ( 接入GPT等模型 ) API_KEY = \"sk-123456789xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx123456789\"。极少数情况下，还需要填写组织（格式如org-123456789abcdefghijklmno的），请向下翻，找 API_ORG 设置项\nAPI_KEY = \"在此处填写APIKEY\"    # 可同时填写多个API-KEY，用英文逗号分割，例如API_KEY = \"sk-openaikey1,sk-openaikey2,fkxxxx-api2dkey3,azure-apikey4\"\n\n# [step 1-2]>> ( 接入通义 qwen-max ) 接入通义千问在线大模型，api-key获取地址 https://dashscope.console.aliyun.com/\nDASHSCOPE_API_KEY = \"\" # 阿里灵积云API_KEY\n\n# [step 2]>> 改为True应用代理，如果直接在海外服务器部署，此处不修改；如果使用本地或无地域限制的大模型时，此处也不需要修改\nUSE_PROXY = False\nif USE_PROXY:\n    \"\"\"\n    代理网络的地址，打开你的代理软件查看代理协议(socks5h / http)、地址(localhost)和端口(11284)\n    填写格式是 [协议]://  [地址] :[端口]，填写之前不要忘记把USE_PROXY改成True，如果直接在海外服务器部署，此处不修改\n            <配置教程&视频教程> https://github.com/binary-husky/gpt_academic/issues/1>\n    [协议] 常见协议无非socks5h/http; 例如 v2**y 和 ss* 的默认本地协议是socks5h; 而cl**h 的默认本地协议是http\n    [地址] 填localhost或者127.0.0.1（localhost意思是代理软件安装在本机上）\n    [端口] 在代理软件的设置里找。虽然不同的代理软件界面不一样，但端口号都应该在最显眼的位置上\n    \"\"\"\n    proxies = {\n        #          [协议]://  [地址]  :[端口]\n        \"http\":  \"socks5h://localhost:11284\",  # 再例如  \"http\":  \"http://127.0.0.1:7890\",\n        \"https\": \"socks5h://localhost:11284\",  # 再例如  \"https\": \"http://127.0.0.1:7890\",\n    }\nelse:\n    proxies = None\n\n# [step 3]>> 模型选择是 (注意: LLM_MODEL是默认选中的模型, 它*必须*被包含在AVAIL_LLM_MODELS列表中 )\nLLM_MODEL = \"gpt-3.5-turbo-16k\" # 可选 ↓↓↓\nAVAIL_LLM_MODELS = [\"qwen-max\", \"o1-mini\", \"o1-mini-2024-09-12\", \"o1\", \"o1-2024-12-17\", \"o1-preview\", \"o1-preview-2024-09-12\",\n                    \"gpt-4-1106-preview\", \"gpt-4-turbo-preview\", \"gpt-4-vision-preview\",\n                    \"gpt-4o\", \"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\",\n                    \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo\", \"azure-gpt-3.5\",\n                    \"gpt-4\", \"gpt-4-32k\", \"azure-gpt-4\", \"glm-4\", \"glm-4v\", \"glm-3-turbo\",\n                    \"gemini-1.5-pro\", \"chatglm3\", \"chatglm4\"\n                    ]\n\nEMBEDDING_MODEL = \"text-embedding-3-small\"\n\n# --- --- --- ---\n# P.S. 其他可用的模型还包括\n# AVAIL_LLM_MODELS = [\n#   \"glm-4-0520\", \"glm-4-air\", \"glm-4-airx\", \"glm-4-flash\",\n#   \"qianfan\", \"deepseekcoder\",\n#   \"spark\", \"sparkv2\", \"sparkv3\", \"sparkv3.5\", \"sparkv4\",\n#   \"qwen-turbo\", \"qwen-plus\", \"qwen-local\",\n#   \"moonshot-v1-128k\", \"moonshot-v1-32k\", \"moonshot-v1-8k\",\n#   \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-0125\", \"gpt-4o-2024-05-13\"\n#   \"claude-3-haiku-20240307\",\"claude-3-sonnet-20240229\",\"claude-3-opus-20240229\", \"claude-2.1\", \"claude-instant-1.2\",\n#   \"moss\", \"llama2\", \"chatglm_onnx\", \"internlm\", \"jittorllms_pangualpha\", \"jittorllms_llama\",\n#   \"deepseek-chat\" ,\"deepseek-coder\",\n#   \"gemini-1.5-flash\",\n#   \"yi-34b-chat-0205\",\"yi-34b-chat-200k\",\"yi-large\",\"yi-medium\",\"yi-spark\",\"yi-large-turbo\",\"yi-large-preview\",\n#   \"grok-beta\",\n# ]\n# --- --- --- ---\n# 此外，您还可以在接入one-api/vllm/ollama/Openroute时，\n# 使用\"one-api-*\",\"vllm-*\",\"ollama-*\",\"openrouter-*\"前缀直接使用非标准方式接入的模型，例如\n# AVAIL_LLM_MODELS = [\"one-api-claude-3-sonnet-20240229(max_token=100000)\", \"ollama-phi3(max_token=4096)\",\"openrouter-openai/gpt-4o-mini\",\"openrouter-openai/chatgpt-4o-latest\"]\n# --- --- --- ---\n\n\n# --------------- 以下配置可以优化体验 ---------------\n\n# 重新URL重新定向，实现更换API_URL的作用（高危设置! 常规情况下不要修改! 通过修改此设置，您将把您的API-KEY和对话隐私完全暴露给您设定的中间人！）\n# 格式: API_URL_REDIRECT = {\"https://api.openai.com/v1/chat/completions\": \"在这里填写重定向的api.openai.com的URL\"}\n# 举例: API_URL_REDIRECT = {\"https://api.openai.com/v1/chat/completions\": \"https://reverse-proxy-url/v1/chat/completions\", \"http://localhost:11434/api/chat\": \"在这里填写您ollama的URL\"}\nAPI_URL_REDIRECT = {}\n\n\n# 多线程函数插件中，默认允许多少路线程同时访问OpenAI。Free trial users的限制是每分钟3次，Pay-as-you-go users的限制是每分钟3500次\n# 一言以蔽之：免费（5刀）用户填3，OpenAI绑了信用卡的用户可以填 16 或者更高。提高限制请查询：https://platform.openai.com/docs/guides/rate-limits/overview\nDEFAULT_WORKER_NUM = 3\n\n\n# 色彩主题, 可选 [\"Default\", \"Chuanhu-Small-and-Beautiful\", \"High-Contrast\"]\n# 更多主题, 请查阅Gradio主题商店: https://huggingface.co/spaces/gradio/theme-gallery 可选 [\"Gstaff/Xkcd\", \"NoCrypt/Miku\", ...]\nTHEME = \"Default\"\nAVAIL_THEMES = [\"Default\", \"Chuanhu-Small-and-Beautiful\", \"High-Contrast\", \"Gstaff/Xkcd\", \"NoCrypt/Miku\"]\n\n\n# 默认的系统提示词（system prompt）\nINIT_SYS_PROMPT = \"Serve me as a writing and programming assistant.\"\n\n\n# 对话窗的高度 （仅在LAYOUT=\"TOP-DOWN\"时生效）\nCHATBOT_HEIGHT = 1115\n\n\n# 代码高亮\nCODE_HIGHLIGHT = True\n\n\n# 窗口布局\nLAYOUT = \"LEFT-RIGHT\"   # \"LEFT-RIGHT\"（左右布局） # \"TOP-DOWN\"（上下布局）\n\n\n# 暗色模式 / 亮色模式\nDARK_MODE = True\n\n\n# 发送请求到OpenAI后，等待多久判定为超时\nTIMEOUT_SECONDS = 30\n\n\n# 网页的端口, -1代表随机端口\nWEB_PORT = -1\n\n\n# 是否自动打开浏览器页面\nAUTO_OPEN_BROWSER = True\n\n\n# 如果OpenAI不响应（网络卡顿、代理失败、KEY失效），重试的次数限制\nMAX_RETRY = 2\n\n\n# 插件分类默认选项\nDEFAULT_FN_GROUPS = ['对话', '编程', '学术', '智能体']\n\n\n# 定义界面上“询问多个GPT模型”插件应该使用哪些模型，请从AVAIL_LLM_MODELS中选择，并在不同模型之间用`&`间隔，例如\"gpt-3.5-turbo&chatglm3&azure-gpt-4\"\nMULTI_QUERY_LLM_MODELS = \"gpt-3.5-turbo&chatglm3\"\n\n\n# 选择本地模型变体（只有当AVAIL_LLM_MODELS包含了对应本地模型时，才会起作用）\n# 如果你选择Qwen系列的模型，那么请在下面的QWEN_MODEL_SELECTION中指定具体的模型\n# 也可以是具体的模型路径\nQWEN_LOCAL_MODEL_SELECTION = \"Qwen/Qwen-1_8B-Chat-Int8\"\n\n\n# 百度千帆（LLM_MODEL=\"qianfan\"）\nBAIDU_CLOUD_API_KEY = ''\nBAIDU_CLOUD_SECRET_KEY = ''\nBAIDU_CLOUD_QIANFAN_MODEL = 'ERNIE-Bot'    # 可选 \"ERNIE-Bot-4\"(文心大模型4.0), \"ERNIE-Bot\"(文心一言), \"ERNIE-Bot-turbo\", \"BLOOMZ-7B\", \"Llama-2-70B-Chat\", \"Llama-2-13B-Chat\", \"Llama-2-7B-Chat\", \"ERNIE-Speed-128K\", \"ERNIE-Speed-8K\", \"ERNIE-Lite-8K\"\n\n\n# 如果使用ChatGLM3或ChatGLM4本地模型，请把 LLM_MODEL=\"chatglm3\" 或LLM_MODEL=\"chatglm4\"，并在此处指定模型路径\nCHATGLM_LOCAL_MODEL_PATH = \"THUDM/glm-4-9b-chat\" # 例如\"/home/hmp/ChatGLM3-6B/\"\n\n# 如果使用ChatGLM2微调模型，请把 LLM_MODEL=\"chatglmft\"，并在此处指定模型路径\nCHATGLM_PTUNING_CHECKPOINT = \"\" # 例如\"/home/hmp/ChatGLM2-6B/ptuning/output/6b-pt-128-1e-2/checkpoint-100\"\n\n\n# 本地LLM模型如ChatGLM的执行方式 CPU/GPU\nLOCAL_MODEL_DEVICE = \"cpu\" # 可选 \"cuda\"\nLOCAL_MODEL_QUANT = \"FP16\" # 默认 \"FP16\" \"INT4\" 启用量化INT4版本 \"INT8\" 启用量化INT8版本\n\n\n# 设置gradio的并行线程数（不需要修改）\nCONCURRENT_COUNT = 100\n\n\n# 是否在提交时自动清空输入框\nAUTO_CLEAR_TXT = False\n\n\n# 加一个live2d装饰\nADD_WAIFU = False\n\n\n# 设置用户名和密码（不需要修改）（相关功能不稳定，与gradio版本和网络都相关，如果本地使用不建议加这个）\n# [(\"username\", \"password\"), (\"username2\", \"password2\"), ...]\nAUTHENTICATION = []\n\n\n# 如果需要在二级路径下运行（常规情况下，不要修改!!）\n# （举例 CUSTOM_PATH = \"/gpt_academic\"，可以让软件运行在 http://ip:port/gpt_academic/ 下。）\nCUSTOM_PATH = \"/\"\n\n\n# HTTPS 秘钥和证书（不需要修改）\nSSL_KEYFILE = \"\"\nSSL_CERTFILE = \"\"\n\n\n# 极少数情况下，openai的官方KEY需要伴随组织编码（格式如org-xxxxxxxxxxxxxxxxxxxxxxxx）使用\nAPI_ORG = \"\"\n\n\n# 如果需要使用Slack Claude，使用教程详情见 request_llms/README.md\nSLACK_CLAUDE_BOT_ID = ''\nSLACK_CLAUDE_USER_TOKEN = ''\n\n\n# 如果需要使用AZURE（方法一：单个azure模型部署）详情请见额外文档 docs\\use_azure.md\nAZURE_ENDPOINT = \"https://你亲手写的api名称.openai.azure.com/\"\nAZURE_API_KEY = \"填入azure openai api的密钥\"    # 建议直接在API_KEY处填写，该选项即将被弃用\nAZURE_ENGINE = \"填入你亲手写的部署名\"            # 读 docs\\use_azure.md\n\n\n# 如果需要使用AZURE（方法二：多个azure模型部署+动态切换）详情请见额外文档 docs\\use_azure.md\nAZURE_CFG_ARRAY = {}\n\n\n# 阿里云实时语音识别 配置难度较高\n# 参考 https://github.com/binary-husky/gpt_academic/blob/master/docs/use_audio.md\nENABLE_AUDIO = False\nALIYUN_TOKEN=\"\"     # 例如 f37f30e0f9934c34a992f6f64f7eba4f\nALIYUN_APPKEY=\"\"    # 例如 RoPlZrM88DnAFkZK\nALIYUN_ACCESSKEY=\"\" # （无需填写）\nALIYUN_SECRET=\"\"    # （无需填写）\n\n\n# GPT-SOVITS 文本转语音服务的运行地址（将语言模型的生成文本朗读出来）\nTTS_TYPE = \"EDGE_TTS\" # EDGE_TTS / LOCAL_SOVITS_API / DISABLE\nGPT_SOVITS_URL = \"\"\nEDGE_TTS_VOICE = \"zh-CN-XiaoxiaoNeural\"\n\n\n# 接入讯飞星火大模型 https://console.xfyun.cn/services/iat\nXFYUN_APPID = \"00000000\"\nXFYUN_API_SECRET = \"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\"\nXFYUN_API_KEY = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\n\n# 接入智谱大模型\nZHIPUAI_API_KEY = \"\"\nZHIPUAI_MODEL = \"\" # 此选项已废弃，不再需要填写\n\n\n# Claude API KEY\nANTHROPIC_API_KEY = \"\"\n\n\n# 月之暗面 API KEY\nMOONSHOT_API_KEY = \"\"\n\n\n# 零一万物(Yi Model) API KEY\nYIMODEL_API_KEY = \"\"\n\n# 深度求索(DeepSeek) API KEY，默认请求地址为\"https://api.deepseek.com/v1/chat/completions\"\nDEEPSEEK_API_KEY = \"\"\n\n\n# 紫东太初大模型 https://ai-maas.wair.ac.cn\nTAICHU_API_KEY = \"\"\n\n# Grok API KEY\nGROK_API_KEY = \"\"\n\n# Mathpix 拥有执行PDF的OCR功能，但是需要注册账号\nMATHPIX_APPID = \"\"\nMATHPIX_APPKEY = \"\"\n\n\n# DOC2X的PDF解析服务，注册账号并获取API KEY: https://doc2x.noedgeai.com/login\nDOC2X_API_KEY = \"\"\n\n\n# 自定义API KEY格式\nCUSTOM_API_KEY_PATTERN = \"\"\n\n\n# Google Gemini API-Key\nGEMINI_API_KEY = ''\n\n\n# HUGGINGFACE的TOKEN，下载LLAMA时起作用 https://huggingface.co/docs/hub/security-tokens\nHUGGINGFACE_ACCESS_TOKEN = \"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\"\n\n\n# GROBID服务器地址（填写多个可以均衡负载），用于高质量地读取PDF文档\n# 获取方法：复制以下空间https://huggingface.co/spaces/qingxu98/grobid，设为public，然后GROBID_URL = \"https://(你的hf用户名如qingxu98)-(你的填写的空间名如grobid).hf.space\"\nGROBID_URLS = [\n    \"https://qingxu98-grobid.hf.space\",\"https://qingxu98-grobid2.hf.space\",\"https://qingxu98-grobid3.hf.space\",\n    \"https://qingxu98-grobid4.hf.space\",\"https://qingxu98-grobid5.hf.space\", \"https://qingxu98-grobid6.hf.space\",\n    \"https://qingxu98-grobid7.hf.space\", \"https://qingxu98-grobid8.hf.space\",\n]\n\n\n# Searxng互联网检索服务（这是一个huggingface空间，请前往huggingface复制该空间，然后把自己新的空间地址填在这里）\nSEARXNG_URLS = [ f\"https://kaletianlre-beardvs{i}dd.hf.space/\" for i in range(1,5) ]\n\n\n# 是否允许通过自然语言描述修改本页的配置，该功能具有一定的危险性，默认关闭\nALLOW_RESET_CONFIG = False\n\n\n# 在使用AutoGen插件时，是否使用Docker容器运行代码\nAUTOGEN_USE_DOCKER = False\n\n\n# 临时的上传文件夹位置，请尽量不要修改\nPATH_PRIVATE_UPLOAD = \"private_upload\"\n\n\n# 日志文件夹的位置，请尽量不要修改\nPATH_LOGGING = \"gpt_log\"\n\n\n# 存储翻译好的arxiv论文的路径，请尽量不要修改\nARXIV_CACHE_DIR = \"gpt_log/arxiv_cache\"\n\n\n# 除了连接OpenAI之外，还有哪些场合允许使用代理，请尽量不要修改\nWHEN_TO_USE_PROXY = [\"Connect_OpenAI\", \"Download_LLM\", \"Download_Gradio_Theme\", \"Connect_Grobid\",\n                     \"Warmup_Modules\", \"Nougat_Download\", \"AutoGen\", \"Connect_OpenAI_Embedding\"]\n\n\n# 启用插件热加载\nPLUGIN_HOT_RELOAD = False\n\n\n# 自定义按钮的最大数量限制\nNUM_CUSTOM_BASIC_BTN = 4\n\n\n# 媒体智能体的服务地址（这是一个huggingface空间，请前往huggingface复制该空间，然后把自己新的空间地址填在这里）\nDAAS_SERVER_URLS = [ f\"https://niuziniu-biligpt{i}.hf.space/stream\" for i in range(1,5) ]\n\n\n\n\"\"\"\n--------------- 配置关联关系说明 ---------------\n\n在线大模型配置关联关系示意图\n│\n├── \"gpt-3.5-turbo\" 等openai模型\n│   ├── API_KEY\n│   ├── CUSTOM_API_KEY_PATTERN（不常用）\n│   ├── API_ORG（不常用）\n│   └── API_URL_REDIRECT（不常用）\n│\n├── \"azure-gpt-3.5\" 等azure模型（单个azure模型，不需要动态切换）\n│   ├── API_KEY\n│   ├── AZURE_ENDPOINT\n│   ├── AZURE_API_KEY\n│   ├── AZURE_ENGINE\n│   └── API_URL_REDIRECT\n│\n├── \"azure-gpt-3.5\" 等azure模型（多个azure模型，需要动态切换，高优先级）\n│   └── AZURE_CFG_ARRAY\n│\n├── \"spark\" 星火认知大模型 spark & sparkv2\n│   ├── XFYUN_APPID\n│   ├── XFYUN_API_SECRET\n│   └── XFYUN_API_KEY\n│\n├── \"claude-3-opus-20240229\" 等claude模型\n│   └── ANTHROPIC_API_KEY\n│\n├── \"stack-claude\"\n│   ├── SLACK_CLAUDE_BOT_ID\n│   └── SLACK_CLAUDE_USER_TOKEN\n│\n├── \"qianfan\" 百度千帆大模型库\n│   ├── BAIDU_CLOUD_QIANFAN_MODEL\n│   ├── BAIDU_CLOUD_API_KEY\n│   └── BAIDU_CLOUD_SECRET_KEY\n│\n├── \"glm-4\", \"glm-3-turbo\", \"zhipuai\" 智谱AI大模型\n│   └── ZHIPUAI_API_KEY\n│\n├── \"yi-34b-chat-0205\", \"yi-34b-chat-200k\" 等零一万物(Yi Model)大模型\n│   └── YIMODEL_API_KEY\n│\n├── \"qwen-turbo\" 等通义千问大模型\n│   └──  DASHSCOPE_API_KEY\n│\n├── \"Gemini\"\n│   └──  GEMINI_API_KEY\n│\n└── \"one-api-...(max_token=...)\" 用一种更方便的方式接入one-api多模型管理界面\n    ├── AVAIL_LLM_MODELS\n    ├── API_KEY\n    └── API_URL_REDIRECT\n\n\n本地大模型示意图\n│\n├── \"chatglm4\"\n├── \"chatglm3\"\n├── \"chatglm\"\n├── \"chatglm_onnx\"\n├── \"chatglmft\"\n├── \"internlm\"\n├── \"moss\"\n├── \"jittorllms_pangualpha\"\n├── \"jittorllms_llama\"\n├── \"deepseekcoder\"\n├── \"qwen-local\"\n├──  RWKV的支持见Wiki\n└── \"llama2\"\n\n\n用户图形界面布局依赖关系示意图\n│\n├── CHATBOT_HEIGHT 对话窗的高度\n├── CODE_HIGHLIGHT 代码高亮\n├── LAYOUT 窗口布局\n├── DARK_MODE 暗色模式 / 亮色模式\n├── DEFAULT_FN_GROUPS 插件分类默认选项\n├── THEME 色彩主题\n├── AUTO_CLEAR_TXT 是否在提交时自动清空输入框\n├── ADD_WAIFU 加一个live2d装饰\n└── ALLOW_RESET_CONFIG 是否允许通过自然语言描述修改本页的配置，该功能具有一定的危险性\n\n\n插件在线服务配置依赖关系示意图\n│\n├── 互联网检索\n│   └── SEARXNG_URLS\n│\n├── 语音功能\n│   ├── ENABLE_AUDIO\n│   ├── ALIYUN_TOKEN\n│   ├── ALIYUN_APPKEY\n│   ├── ALIYUN_ACCESSKEY\n│   └── ALIYUN_SECRET\n│\n└── PDF文档精准解析\n    ├── GROBID_URLS\n    ├── MATHPIX_APPID\n    └── MATHPIX_APPKEY\n\n\n\"\"\"\n"
        },
        {
          "name": "core_functional.py",
          "type": "blob",
          "size": 9.47,
          "content": "# 'primary' 颜色对应 theme.py 中的 primary_hue\n# 'secondary' 颜色对应 theme.py 中的 neutral_hue\n# 'stop' 颜色对应 theme.py 中的 color_er\nimport importlib\nfrom toolbox import clear_line_break\nfrom toolbox import apply_gpt_academic_string_mask_langbased\nfrom toolbox import build_gpt_academic_masked_string_langbased\nfrom textwrap import dedent\n\ndef get_core_functions():\n    return {\n\n        \"学术语料润色\": {\n            # [1*] 前缀字符串，会被加在你的输入之前。例如，用来描述你的要求，例如翻译、解释代码、润色等等。\n            #      这里填一个提示词字符串就行了，这里为了区分中英文情景搞复杂了一点\n            \"Prefix\":   build_gpt_academic_masked_string_langbased(\n                            text_show_english=\n                                r\"Below is a paragraph from an academic paper. Polish the writing to meet the academic style, \"\n                                r\"improve the spelling, grammar, clarity, concision and overall readability. When necessary, rewrite the whole sentence. \"\n                                r\"Firstly, you should provide the polished paragraph (in English). \"\n                                r\"Secondly, you should list all your modification and explain the reasons to do so in markdown table.\",\n                            text_show_chinese=\n                                r\"作为一名中文学术论文写作改进助理，你的任务是改进所提供文本的拼写、语法、清晰、简洁和整体可读性，\"\n                                r\"同时分解长句，减少重复，并提供改进建议。请先提供文本的更正版本，然后在markdown表格中列出修改的内容，并给出修改的理由:\"\n                        ) + \"\\n\\n\",\n            # [2*] 后缀字符串，会被加在你的输入之后。例如，配合前缀可以把你的输入内容用引号圈起来\n            \"Suffix\":   r\"\",\n            # [3] 按钮颜色 (可选参数，默认 secondary)\n            \"Color\":    r\"secondary\",\n            # [4] 按钮是否可见 (可选参数，默认 True，即可见)\n            \"Visible\": True,\n            # [5] 是否在触发时清除历史 (可选参数，默认 False，即不处理之前的对话历史)\n            \"AutoClearHistory\": False,\n            # [6] 文本预处理 （可选参数，默认 None，举例：写个函数移除所有的换行符）\n            \"PreProcess\": None,\n            # [7] 模型选择 （可选参数。如不设置，则使用当前全局模型；如设置，则用指定模型覆盖全局模型。）\n            # \"ModelOverride\": \"gpt-3.5-turbo\", # 主要用途：强制点击此基础功能按钮时，使用指定的模型。\n        },\n\n\n        \"总结绘制脑图\": {\n            # 前缀，会被加在你的输入之前。例如，用来描述你的要求，例如翻译、解释代码、润色等等\n            \"Prefix\":   '''\"\"\"\\n\\n''',\n            # 后缀，会被加在你的输入之后。例如，配合前缀可以把你的输入内容用引号圈起来\n            \"Suffix\":\n                # dedent() 函数用于去除多行字符串的缩进\n                dedent(\"\\n\\n\"+r'''\n                    \"\"\"\n\n                    使用mermaid flowchart对以上文本进行总结，概括上述段落的内容以及内在逻辑关系，例如：\n\n                    以下是对以上文本的总结，以mermaid flowchart的形式展示：\n                    ```mermaid\n                    flowchart LR\n                        A[\"节点名1\"] --> B(\"节点名2\")\n                        B --> C{\"节点名3\"}\n                        C --> D[\"节点名4\"]\n                        C --> |\"箭头名1\"| E[\"节点名5\"]\n                        C --> |\"箭头名2\"| F[\"节点名6\"]\n                    ```\n\n                    注意：\n                    （1）使用中文\n                    （2）节点名字使用引号包裹，如[\"Laptop\"]\n                    （3）`|` 和 `\"`之间不要存在空格\n                    （4）根据情况选择flowchart LR（从左到右）或者flowchart TD（从上到下）\n                '''),\n        },\n\n\n        \"查找语法错误\": {\n            \"Prefix\":   r\"Help me ensure that the grammar and the spelling is correct. \"\n                        r\"Do not try to polish the text, if no mistake is found, tell me that this paragraph is good. \"\n                        r\"If you find grammar or spelling mistakes, please list mistakes you find in a two-column markdown table, \"\n                        r\"put the original text the first column, \"\n                        r\"put the corrected text in the second column and highlight the key words you fixed. \"\n                        r\"Finally, please provide the proofreaded text.\"\"\\n\\n\"\n                        r\"Example:\"\"\\n\"\n                        r\"Paragraph: How is you? Do you knows what is it?\"\"\\n\"\n                        r\"| Original sentence | Corrected sentence |\"\"\\n\"\n                        r\"| :--- | :--- |\"\"\\n\"\n                        r\"| How **is** you? | How **are** you? |\"\"\\n\"\n                        r\"| Do you **knows** what **is** **it**? | Do you **know** what **it** **is** ? |\"\"\\n\\n\"\n                        r\"Below is a paragraph from an academic paper. \"\n                        r\"You need to report all grammar and spelling mistakes as the example before.\"\n                        + \"\\n\\n\",\n            \"Suffix\":   r\"\",\n            \"PreProcess\": clear_line_break,    # 预处理：清除换行符\n        },\n\n\n        \"中译英\": {\n            \"Prefix\":   r\"Please translate following sentence to English:\" + \"\\n\\n\",\n            \"Suffix\":   r\"\",\n        },\n\n\n        \"学术英中互译\": {\n            \"Prefix\":   build_gpt_academic_masked_string_langbased(\n                            text_show_chinese=\n                                r\"I want you to act as a scientific English-Chinese translator, \"\n                                r\"I will provide you with some paragraphs in one language \"\n                                r\"and your task is to accurately and academically translate the paragraphs only into the other language. \"\n                                r\"Do not repeat the original provided paragraphs after translation. \"\n                                r\"You should use artificial intelligence tools, \"\n                                r\"such as natural language processing, and rhetorical knowledge \"\n                                r\"and experience about effective writing techniques to reply. \"\n                                r\"I'll give you my paragraphs as follows, tell me what language it is written in, and then translate:\",\n                            text_show_english=\n                                r\"你是经验丰富的翻译，请把以下学术文章段落翻译成中文，\"\n                                r\"并同时充分考虑中文的语法、清晰、简洁和整体可读性，\"\n                                r\"必要时，你可以修改整个句子的顺序以确保翻译后的段落符合中文的语言习惯。\"\n                                r\"你需要翻译的文本如下：\"\n                        ) + \"\\n\\n\",\n            \"Suffix\":   r\"\",\n        },\n\n\n        \"英译中\": {\n            \"Prefix\":   r\"翻译成地道的中文：\" + \"\\n\\n\",\n            \"Suffix\":   r\"\",\n            \"Visible\":  False,\n        },\n\n\n        \"找图片\": {\n            \"Prefix\":   r\"我需要你找一张网络图片。使用Unsplash API(https://source.unsplash.com/960x640/?<英语关键词>)获取图片URL，\"\n                        r\"然后请使用Markdown格式封装，并且不要有反斜线，不要用代码块。现在，请按以下描述给我发送图片：\" + \"\\n\\n\",\n            \"Suffix\":   r\"\",\n            \"Visible\":  False,\n        },\n\n\n        \"解释代码\": {\n            \"Prefix\":   r\"请解释以下代码：\" + \"\\n```\\n\",\n            \"Suffix\":   \"\\n```\\n\",\n        },\n\n\n        \"参考文献转Bib\": {\n            \"Prefix\":   r\"Here are some bibliography items, please transform them into bibtex style.\"\n                        r\"Note that, reference styles maybe more than one kind, you should transform each item correctly.\"\n                        r\"Items need to be transformed:\" + \"\\n\\n\",\n            \"Visible\":  False,\n            \"Suffix\":   r\"\",\n        }\n    }\n\n\ndef handle_core_functionality(additional_fn, inputs, history, chatbot):\n    import core_functional\n    importlib.reload(core_functional)    # 热更新prompt\n    core_functional = core_functional.get_core_functions()\n    addition = chatbot._cookies['customize_fn_overwrite']\n    if additional_fn in addition:\n        # 自定义功能\n        inputs = addition[additional_fn][\"Prefix\"] + inputs + addition[additional_fn][\"Suffix\"]\n        return inputs, history\n    else:\n        # 预制功能\n        if \"PreProcess\" in core_functional[additional_fn]:\n            if core_functional[additional_fn][\"PreProcess\"] is not None:\n                inputs = core_functional[additional_fn][\"PreProcess\"](inputs)  # 获取预处理函数（如果有的话）\n        # 为字符串加上上面定义的前缀和后缀。\n        inputs = apply_gpt_academic_string_mask_langbased(\n            string = core_functional[additional_fn][\"Prefix\"] + inputs + core_functional[additional_fn][\"Suffix\"],\n            lang_reference = inputs,\n        )\n        if core_functional[additional_fn].get(\"AutoClearHistory\", False):\n            history = []\n        return inputs, history\n\nif __name__ == \"__main__\":\n    t = get_core_functions()[\"总结绘制脑图\"]\n    print(t[\"Prefix\"] + t[\"Suffix\"])"
        },
        {
          "name": "crazy_functional.py",
          "type": "blob",
          "size": 33.33,
          "content": "from toolbox import HotReload  # HotReload 的意思是热更新，修改函数插件后，不需要重启程序，代码直接生效\nfrom toolbox import trimmed_format_exc\nfrom loguru import logger\n\ndef get_crazy_functions():\n    from crazy_functions.读文章写摘要 import 读文章写摘要\n    from crazy_functions.生成函数注释 import 批量生成函数注释\n    from crazy_functions.SourceCode_Analyse import 解析项目本身\n    from crazy_functions.SourceCode_Analyse import 解析一个Python项目\n    from crazy_functions.SourceCode_Analyse import 解析一个Matlab项目\n    from crazy_functions.SourceCode_Analyse import 解析一个C项目的头文件\n    from crazy_functions.SourceCode_Analyse import 解析一个C项目\n    from crazy_functions.SourceCode_Analyse import 解析一个Golang项目\n    from crazy_functions.SourceCode_Analyse import 解析一个Rust项目\n    from crazy_functions.SourceCode_Analyse import 解析一个Java项目\n    from crazy_functions.SourceCode_Analyse import 解析一个前端项目\n    from crazy_functions.高级功能函数模板 import 高阶功能模板函数\n    from crazy_functions.高级功能函数模板 import Demo_Wrap\n    from crazy_functions.Latex_Project_Polish import Latex英文润色\n    from crazy_functions.询问多个大语言模型 import 同时问询\n    from crazy_functions.SourceCode_Analyse import 解析一个Lua项目\n    from crazy_functions.SourceCode_Analyse import 解析一个CSharp项目\n    from crazy_functions.总结word文档 import 总结word文档\n    from crazy_functions.解析JupyterNotebook import 解析ipynb文件\n    from crazy_functions.Conversation_To_File import 载入对话历史存档\n    from crazy_functions.Conversation_To_File import 对话历史存档\n    from crazy_functions.Conversation_To_File import Conversation_To_File_Wrap\n    from crazy_functions.Conversation_To_File import 删除所有本地对话历史记录\n    from crazy_functions.辅助功能 import 清除缓存\n    from crazy_functions.Markdown_Translate import Markdown英译中\n    from crazy_functions.批量总结PDF文档 import 批量总结PDF文档\n    from crazy_functions.PDF_Translate import 批量翻译PDF文档\n    from crazy_functions.谷歌检索小助手 import 谷歌检索小助手\n    from crazy_functions.理解PDF文档内容 import 理解PDF文档内容标准文件输入\n    from crazy_functions.Latex_Project_Polish import Latex中文润色\n    from crazy_functions.Latex_Project_Polish import Latex英文纠错\n    from crazy_functions.Markdown_Translate import Markdown中译英\n    from crazy_functions.虚空终端 import 虚空终端\n    from crazy_functions.生成多种Mermaid图表 import Mermaid_Gen\n    from crazy_functions.PDF_Translate_Wrap import PDF_Tran\n    from crazy_functions.Latex_Function import Latex英文纠错加PDF对比\n    from crazy_functions.Latex_Function import Latex翻译中文并重新编译PDF\n    from crazy_functions.Latex_Function import PDF翻译中文并重新编译PDF\n    from crazy_functions.Latex_Function_Wrap import Arxiv_Localize\n    from crazy_functions.Latex_Function_Wrap import PDF_Localize\n    from crazy_functions.Internet_GPT import 连接网络回答问题\n    from crazy_functions.Internet_GPT_Wrap import NetworkGPT_Wrap\n    from crazy_functions.Image_Generate import 图片生成_DALLE2, 图片生成_DALLE3, 图片修改_DALLE2\n    from crazy_functions.Image_Generate_Wrap import ImageGen_Wrap\n    from crazy_functions.SourceCode_Comment import 注释Python项目\n    from crazy_functions.SourceCode_Comment_Wrap import SourceCodeComment_Wrap\n    from crazy_functions.VideoResource_GPT import 多媒体任务\n\n    function_plugins = {\n        \"多媒体智能体\": {\n            \"Group\": \"智能体\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"【仅测试】多媒体任务\",\n            \"Function\": HotReload(多媒体任务),\n        },\n        \"虚空终端\": {\n            \"Group\": \"对话|编程|学术|智能体\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"使用自然语言实现您的想法\",\n            \"Function\": HotReload(虚空终端),\n        },\n        \"解析整个Python项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"解析一个Python项目的所有源文件(.py) | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Python项目),\n        },\n        \"注释Python项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"上传一系列python源文件(或者压缩包), 为这些代码添加docstring | 输入参数为路径\",\n            \"Function\": HotReload(注释Python项目),\n            \"Class\": SourceCodeComment_Wrap,\n        },\n        \"载入对话历史存档（先上传存档或输入路径）\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"载入对话历史存档 | 输入参数为路径\",\n            \"Function\": HotReload(载入对话历史存档),\n        },\n        \"删除所有本地对话历史记录（谨慎操作）\": {\n            \"Group\": \"对话\",\n            \"AsButton\": False,\n            \"Info\": \"删除所有本地对话历史记录，谨慎操作 | 不需要输入参数\",\n            \"Function\": HotReload(删除所有本地对话历史记录),\n        },\n        \"清除所有缓存文件（谨慎操作）\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"清除所有缓存文件，谨慎操作 | 不需要输入参数\",\n            \"Function\": HotReload(清除缓存),\n        },\n        \"生成多种Mermaid图表(从当前对话或路径(.pdf/.md/.docx)中生产图表）\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\" : \"基于当前对话或文件生成多种Mermaid图表,图表类型由模型判断\",\n            \"Function\": None,\n            \"Class\": Mermaid_Gen\n        },\n        \"Arxiv论文翻译\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"Arixv论文精细翻译 | 输入参数arxiv论文的ID，比如1812.10695\",\n            \"Function\": HotReload(Latex翻译中文并重新编译PDF),  # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n            \"Class\": Arxiv_Localize,    # 新一代插件需要注册Class\n        },\n        \"批量总结Word文档\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"批量总结word文档 | 输入参数为路径\",\n            \"Function\": HotReload(总结word文档),\n        },\n        \"解析整个Matlab项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"解析一个Matlab项目的所有源文件(.m) | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Matlab项目),\n        },\n        \"解析整个C++项目头文件\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个C++项目的所有头文件(.h/.hpp) | 输入参数为路径\",\n            \"Function\": HotReload(解析一个C项目的头文件),\n        },\n        \"解析整个C++项目（.cpp/.hpp/.c/.h）\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个C++项目的所有源文件（.cpp/.hpp/.c/.h）| 输入参数为路径\",\n            \"Function\": HotReload(解析一个C项目),\n        },\n        \"解析整个Go项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个Go项目的所有源文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Golang项目),\n        },\n        \"解析整个Rust项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个Rust项目的所有源文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Rust项目),\n        },\n        \"解析整个Java项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个Java项目的所有源文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Java项目),\n        },\n        \"解析整个前端项目（js,ts,css等）\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个前端项目的所有源文件（js,ts,css等） | 输入参数为路径\",\n            \"Function\": HotReload(解析一个前端项目),\n        },\n        \"解析整个Lua项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个Lua项目的所有源文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析一个Lua项目),\n        },\n        \"解析整个CSharp项目\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"解析一个CSharp项目的所有源文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析一个CSharp项目),\n        },\n        \"解析Jupyter Notebook文件\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"解析Jupyter Notebook文件 | 输入参数为路径\",\n            \"Function\": HotReload(解析ipynb文件),\n            \"AdvancedArgs\": True,  # 调用时，唤起高级参数输入区（默认False）\n            \"ArgsReminder\": \"若输入0，则不解析notebook中的Markdown块\",  # 高级参数输入区的显示提示\n        },\n        \"读Tex论文写摘要\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"读取Tex论文并写摘要 | 输入参数为路径\",\n            \"Function\": HotReload(读文章写摘要),\n        },\n        \"翻译README或MD\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"将Markdown翻译为中文 | 输入参数为路径或URL\",\n            \"Function\": HotReload(Markdown英译中),\n        },\n        \"翻译Markdown或README（支持Github链接）\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"将Markdown或README翻译为中文 | 输入参数为路径或URL\",\n            \"Function\": HotReload(Markdown英译中),\n        },\n        \"批量生成函数注释\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"批量生成函数的注释 | 输入参数为路径\",\n            \"Function\": HotReload(批量生成函数注释),\n        },\n        \"保存当前的对话\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"保存当前的对话 | 不需要输入参数\",\n            \"Function\": HotReload(对话历史存档),    # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n            \"Class\": Conversation_To_File_Wrap     # 新一代插件需要注册Class\n        },\n        \"[多线程Demo]解析此项目本身（源码自译解）\": {\n            \"Group\": \"对话|编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"多线程解析并翻译此项目的源码 | 不需要输入参数\",\n            \"Function\": HotReload(解析项目本身),\n        },\n        \"查互联网后回答\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,  # 加入下拉菜单中\n            # \"Info\": \"连接网络回答问题（需要访问谷歌）| 输入参数是一个问题\",\n            \"Function\": HotReload(连接网络回答问题),\n            \"Class\": NetworkGPT_Wrap     # 新一代插件需要注册Class\n        },\n        \"历史上的今天\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"Info\": \"查看历史上的今天事件 (这是一个面向开发者的插件Demo) | 不需要输入参数\",\n            \"Function\": None,\n            \"Class\": Demo_Wrap, # 新一代插件需要注册Class\n        },\n        \"精准翻译PDF论文\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Info\": \"精准翻译PDF论文为中文 | 输入参数为路径\",\n            \"Function\": HotReload(批量翻译PDF文档), # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n            \"Class\": PDF_Tran,  # 新一代插件需要注册Class\n        },\n        \"询问多个GPT模型\": {\n            \"Group\": \"对话\",\n            \"Color\": \"stop\",\n            \"AsButton\": True,\n            \"Function\": HotReload(同时问询),\n        },\n        \"批量总结PDF文档\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"批量总结PDF文档的内容 | 输入参数为路径\",\n            \"Function\": HotReload(批量总结PDF文档),\n        },\n        \"谷歌学术检索助手（输入谷歌学术搜索页url）\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"使用谷歌学术检索助手搜索指定URL的结果 | 输入参数为谷歌学术搜索页的URL\",\n            \"Function\": HotReload(谷歌检索小助手),\n        },\n        \"理解PDF文档内容 （模仿ChatPDF）\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"理解PDF文档的内容并进行回答 | 输入参数为路径\",\n            \"Function\": HotReload(理解PDF文档内容标准文件输入),\n        },\n        \"英文Latex项目全文润色（输入路径或上传压缩包）\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"对英文Latex项目全文进行润色处理 | 输入参数为路径或上传压缩包\",\n            \"Function\": HotReload(Latex英文润色),\n        },\n\n        \"中文Latex项目全文润色（输入路径或上传压缩包）\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"对中文Latex项目全文进行润色处理 | 输入参数为路径或上传压缩包\",\n            \"Function\": HotReload(Latex中文润色),\n        },\n        # 已经被新插件取代\n        # \"英文Latex项目全文纠错（输入路径或上传压缩包）\": {\n        #     \"Group\": \"学术\",\n        #     \"Color\": \"stop\",\n        #     \"AsButton\": False,  # 加入下拉菜单中\n        #     \"Info\": \"对英文Latex项目全文进行纠错处理 | 输入参数为路径或上传压缩包\",\n        #     \"Function\": HotReload(Latex英文纠错),\n        # },\n        # 已经被新插件取代\n        # \"Latex项目全文中译英（输入路径或上传压缩包）\": {\n        #     \"Group\": \"学术\",\n        #     \"Color\": \"stop\",\n        #     \"AsButton\": False,  # 加入下拉菜单中\n        #     \"Info\": \"对Latex项目全文进行中译英处理 | 输入参数为路径或上传压缩包\",\n        #     \"Function\": HotReload(Latex中译英)\n        # },\n        # 已经被新插件取代\n        # \"Latex项目全文英译中（输入路径或上传压缩包）\": {\n        #     \"Group\": \"学术\",\n        #     \"Color\": \"stop\",\n        #     \"AsButton\": False,  # 加入下拉菜单中\n        #     \"Info\": \"对Latex项目全文进行英译中处理 | 输入参数为路径或上传压缩包\",\n        #     \"Function\": HotReload(Latex英译中)\n        # },\n        \"批量Markdown中译英（输入路径或上传压缩包）\": {\n            \"Group\": \"编程\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,  # 加入下拉菜单中\n            \"Info\": \"批量将Markdown文件中文翻译为英文 | 输入参数为路径或上传压缩包\",\n            \"Function\": HotReload(Markdown中译英),\n        },\n        \"Latex英文纠错+高亮修正位置 [需Latex]\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"AdvancedArgs\": True,\n            \"ArgsReminder\": \"如果有必要, 请在此处追加更细致的矫错指令（使用英文）。\",\n            \"Function\": HotReload(Latex英文纠错加PDF对比),\n        },\n        \"📚Arxiv论文精细翻译（输入arxivID）[需Latex]\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"AdvancedArgs\": True,\n            \"ArgsReminder\": r\"如果有必要, 请在此处给出自定义翻译命令, 解决部分词汇翻译不准确的问题。 \"\n                            r\"例如当单词'agent'翻译不准确时, 请尝试把以下指令复制到高级参数区: \"\n                            r'If the term \"agent\" is used in this section, it should be translated to \"智能体\". ',\n            \"Info\": \"Arixv论文精细翻译 | 输入参数arxiv论文的ID，比如1812.10695\",\n            \"Function\": HotReload(Latex翻译中文并重新编译PDF),  # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n            \"Class\": Arxiv_Localize,    # 新一代插件需要注册Class\n        },\n        \"📚本地Latex论文精细翻译（上传Latex项目）[需Latex]\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"AdvancedArgs\": True,\n            \"ArgsReminder\": r\"如果有必要, 请在此处给出自定义翻译命令, 解决部分词汇翻译不准确的问题。 \"\n                            r\"例如当单词'agent'翻译不准确时, 请尝试把以下指令复制到高级参数区: \"\n                            r'If the term \"agent\" is used in this section, it should be translated to \"智能体\". ',\n            \"Info\": \"本地Latex论文精细翻译 | 输入参数是路径\",\n            \"Function\": HotReload(Latex翻译中文并重新编译PDF),\n        },\n        \"PDF翻译中文并重新编译PDF（上传PDF）[需Latex]\": {\n            \"Group\": \"学术\",\n            \"Color\": \"stop\",\n            \"AsButton\": False,\n            \"AdvancedArgs\": True,\n            \"ArgsReminder\": r\"如果有必要, 请在此处给出自定义翻译命令, 解决部分词汇翻译不准确的问题。 \"\n                            r\"例如当单词'agent'翻译不准确时, 请尝试把以下指令复制到高级参数区: \"\n                            r'If the term \"agent\" is used in this section, it should be translated to \"智能体\". ',\n            \"Info\": \"PDF翻译中文，并重新编译PDF | 输入参数为路径\",\n            \"Function\": HotReload(PDF翻译中文并重新编译PDF),   # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n            \"Class\": PDF_Localize   # 新一代插件需要注册Class\n        }\n    }\n\n    function_plugins.update(\n        {\n            \"🎨图片生成（DALLE2/DALLE3, 使用前切换到GPT系列模型）\": {\n                \"Group\": \"对话\",\n                \"Color\": \"stop\",\n                \"AsButton\": False,\n                \"Info\": \"使用 DALLE2/DALLE3 生成图片 | 输入参数字符串，提供图像的内容\",\n                \"Function\": HotReload(图片生成_DALLE2),   # 当注册Class后，Function旧接口仅会在“虚空终端”中起作用\n                \"Class\": ImageGen_Wrap  # 新一代插件需要注册Class\n            },\n        }\n    )\n\n    function_plugins.update(\n        {\n            \"🎨图片修改_DALLE2 （使用前请切换模型到GPT系列）\": {\n                \"Group\": \"对话\",\n                \"Color\": \"stop\",\n                \"AsButton\": False,\n                \"AdvancedArgs\": False,  # 调用时，唤起高级参数输入区（默认False）\n                # \"Info\": \"使用DALLE2修改图片 | 输入参数字符串，提供图像的内容\",\n                \"Function\": HotReload(图片修改_DALLE2),\n            },\n        }\n    )\n\n\n\n\n\n\n\n\n\n    # -=--=- 尚未充分测试的实验性插件 & 需要额外依赖的插件 -=--=-\n    try:\n        from crazy_functions.下载arxiv论文翻译摘要 import 下载arxiv论文并翻译摘要\n\n        function_plugins.update(\n            {\n                \"一键下载arxiv论文并翻译摘要（先在input输入编号，如1812.10695）\": {\n                    \"Group\": \"学术\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,  # 加入下拉菜单中\n                    # \"Info\": \"下载arxiv论文并翻译摘要 | 输入参数为arxiv编号如1812.10695\",\n                    \"Function\": HotReload(下载arxiv论文并翻译摘要),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    # try:\n    #     from crazy_functions.联网的ChatGPT import 连接网络回答问题\n\n    #     function_plugins.update(\n    #         {\n    #             \"连接网络回答问题（输入问题后点击该插件，需要访问谷歌）\": {\n    #                 \"Group\": \"对话\",\n    #                 \"Color\": \"stop\",\n    #                 \"AsButton\": False,  # 加入下拉菜单中\n    #                 # \"Info\": \"连接网络回答问题（需要访问谷歌）| 输入参数是一个问题\",\n    #                 \"Function\": HotReload(连接网络回答问题),\n    #             }\n    #         }\n    #     )\n    #     from crazy_functions.联网的ChatGPT_bing版 import 连接bing搜索回答问题\n\n    #     function_plugins.update(\n    #         {\n    #             \"连接网络回答问题（中文Bing版，输入问题后点击该插件）\": {\n    #                 \"Group\": \"对话\",\n    #                 \"Color\": \"stop\",\n    #                 \"AsButton\": False,  # 加入下拉菜单中\n    #                 \"Info\": \"连接网络回答问题（需要访问中文Bing）| 输入参数是一个问题\",\n    #                 \"Function\": HotReload(连接bing搜索回答问题),\n    #             }\n    #         }\n    #     )\n    # except:\n    #     logger.error(trimmed_format_exc())\n    #     logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.SourceCode_Analyse import 解析任意code项目\n\n        function_plugins.update(\n            {\n                \"解析项目源代码（手动指定和筛选源代码文件类型）\": {\n                    \"Group\": \"编程\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,  # 调用时，唤起高级参数输入区（默认False）\n                    \"ArgsReminder\": '输入时用逗号隔开, *代表通配符, 加了^代表不匹配; 不输入代表全部匹配。例如: \"*.c, ^*.cpp, config.toml, ^*.toml\"',  # 高级参数输入区的显示提示\n                    \"Function\": HotReload(解析任意code项目),\n                },\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.询问多个大语言模型 import 同时问询_指定模型\n\n        function_plugins.update(\n            {\n                \"询问多个GPT模型（手动指定询问哪些模型）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,  # 调用时，唤起高级参数输入区（默认False）\n                    \"ArgsReminder\": \"支持任意数量的llm接口，用&符号分隔。例如chatglm&gpt-3.5-turbo&gpt-4\",  # 高级参数输入区的显示提示\n                    \"Function\": HotReload(同时问询_指定模型),\n                },\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n\n\n    try:\n        from crazy_functions.总结音视频 import 总结音视频\n\n        function_plugins.update(\n            {\n                \"批量总结音视频（输入路径或上传压缩包）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,\n                    \"ArgsReminder\": \"调用openai api 使用whisper-1模型, 目前支持的格式:mp4, m4a, wav, mpga, mpeg, mp3。此处可以输入解析提示，例如：解析为简体中文（默认）。\",\n                    \"Info\": \"批量总结音频或视频 | 输入参数为路径\",\n                    \"Function\": HotReload(总结音视频),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.数学动画生成manim import 动画生成\n\n        function_plugins.update(\n            {\n                \"数学动画生成（Manim）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Info\": \"按照自然语言描述生成一个动画 | 输入参数是一段话\",\n                    \"Function\": HotReload(动画生成),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.Markdown_Translate import Markdown翻译指定语言\n\n        function_plugins.update(\n            {\n                \"Markdown翻译（指定翻译成何种语言）\": {\n                    \"Group\": \"编程\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,\n                    \"ArgsReminder\": \"请输入要翻译成哪种语言，默认为Chinese。\",\n                    \"Function\": HotReload(Markdown翻译指定语言),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.知识库问答 import 知识库文件注入\n\n        function_plugins.update(\n            {\n                \"构建知识库（先上传文件素材,再运行此插件）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,\n                    \"ArgsReminder\": \"此处待注入的知识库名称id, 默认为default。文件进入知识库后可长期保存。可以通过再次调用本插件的方式，向知识库追加更多文档。\",\n                    \"Function\": HotReload(知识库文件注入),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.知识库问答 import 读取知识库作答\n\n        function_plugins.update(\n            {\n                \"知识库文件注入（构建知识库后,再运行此插件）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"AdvancedArgs\": True,\n                    \"ArgsReminder\": \"待提取的知识库名称id, 默认为default, 您需要构建知识库后再运行此插件。\",\n                    \"Function\": HotReload(读取知识库作答),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.交互功能函数模板 import 交互功能模板函数\n\n        function_plugins.update(\n            {\n                \"交互功能模板Demo函数（查找wallhaven.cc的壁纸）\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Function\": HotReload(交互功能模板函数),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n\n    try:\n        from toolbox import get_conf\n\n        ENABLE_AUDIO = get_conf(\"ENABLE_AUDIO\")\n        if ENABLE_AUDIO:\n            from crazy_functions.语音助手 import 语音助手\n\n            function_plugins.update(\n                {\n                    \"实时语音对话\": {\n                        \"Group\": \"对话\",\n                        \"Color\": \"stop\",\n                        \"AsButton\": True,\n                        \"Info\": \"这是一个时刻聆听着的语音对话助手 | 没有输入参数\",\n                        \"Function\": HotReload(语音助手),\n                    }\n                }\n            )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.批量翻译PDF文档_NOUGAT import 批量翻译PDF文档\n\n        function_plugins.update(\n            {\n                \"精准翻译PDF文档（NOUGAT）\": {\n                    \"Group\": \"学术\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Function\": HotReload(批量翻译PDF文档),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.函数动态生成 import 函数动态生成\n\n        function_plugins.update(\n            {\n                \"动态代码解释器（CodeInterpreter）\": {\n                    \"Group\": \"智能体\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Function\": HotReload(函数动态生成),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.多智能体 import 多智能体终端\n\n        function_plugins.update(\n            {\n                \"AutoGen多智能体终端（仅供测试）\": {\n                    \"Group\": \"智能体\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Function\": HotReload(多智能体终端),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.互动小游戏 import 随机小游戏\n\n        function_plugins.update(\n            {\n                \"随机互动小游戏（仅供测试）\": {\n                    \"Group\": \"智能体\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Function\": HotReload(随机小游戏),\n                }\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n    try:\n        from crazy_functions.Rag_Interface import Rag问答\n\n        function_plugins.update(\n            {\n                \"Rag智能召回\": {\n                    \"Group\": \"对话\",\n                    \"Color\": \"stop\",\n                    \"AsButton\": False,\n                    \"Info\": \"将问答数据记录到向量库中，作为长期参考。\",\n                    \"Function\": HotReload(Rag问答),\n                },\n            }\n        )\n    except:\n        logger.error(trimmed_format_exc())\n        logger.error(\"Load function plugin failed\")\n\n\n    # try:\n    #     from crazy_functions.高级功能函数模板 import 测试图表渲染\n    #     function_plugins.update({\n    #         \"绘制逻辑关系（测试图表渲染）\": {\n    #             \"Group\": \"智能体\",\n    #             \"Color\": \"stop\",\n    #             \"AsButton\": True,\n    #             \"Function\": HotReload(测试图表渲染)\n    #         }\n    #     })\n    # except:\n    #     logger.error(trimmed_format_exc())\n    #     print('Load function plugin failed')\n\n\n    \"\"\"\n    设置默认值:\n    - 默认 Group = 对话\n    - 默认 AsButton = True\n    - 默认 AdvancedArgs = False\n    - 默认 Color = secondary\n    \"\"\"\n    for name, function_meta in function_plugins.items():\n        if \"Group\" not in function_meta:\n            function_plugins[name][\"Group\"] = \"对话\"\n        if \"AsButton\" not in function_meta:\n            function_plugins[name][\"AsButton\"] = True\n        if \"AdvancedArgs\" not in function_meta:\n            function_plugins[name][\"AdvancedArgs\"] = False\n        if \"Color\" not in function_meta:\n            function_plugins[name][\"Color\"] = \"secondary\"\n\n    return function_plugins\n\n\n\n\ndef get_multiplex_button_functions():\n    \"\"\"多路复用主提交按钮的功能映射\n    \"\"\"\n    return {\n        \"常规对话\":\n            \"\",\n\n        \"多模型对话\": \n            \"询问多个GPT模型\", # 映射到上面的 `询问多个GPT模型` 插件\n\n        \"智能召回 RAG\": \n            \"Rag智能召回\", # 映射到上面的 `Rag智能召回` 插件\n\n        \"多媒体查询\": \n            \"多媒体智能体\", # 映射到上面的 `多媒体智能体` 插件\n    }\n"
        },
        {
          "name": "crazy_functions",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 14.94,
          "content": "## ===================================================\n#                docker-compose.yml\n## ===================================================\n# 1. 请在以下方案中选择任意一种，然后删除其他的方案\n# 2. 修改你选择的方案中的environment环境变量，详情请见github wiki或者config.py\n# 3. 选择一种暴露服务端口的方法，并对相应的配置做出修改：\n    # 「方法1: 适用于Linux，很方便，可惜windows不支持」与宿主的网络融合为一体，这个是默认配置\n    # network_mode: \"host\"\n    # 「方法2: 适用于所有系统包括Windows和MacOS」端口映射，把容器的端口映射到宿主的端口（注意您需要先删除network_mode: \"host\"，再追加以下内容）\n    # ports:\n    #   - \"12345:12345\"  # 注意！12345必须与WEB_PORT环境变量相互对应\n# 4. 最后`docker-compose up`运行\n# 5. 如果希望使用显卡，请关注 LOCAL_MODEL_DEVICE 和 英伟达显卡运行时 选项\n## ===================================================\n# 1. Please choose one of the following options and delete the others.\n# 2. Modify the environment variables in the selected option, see GitHub wiki or config.py for more details.\n# 3. Choose a method to expose the server port and make the corresponding configuration changes:\n    # [Method 1: Suitable for Linux, convenient, but not supported for Windows] Fusion with the host network, this is the default configuration\n    # network_mode: \"host\"\n    # [Method 2: Suitable for all systems including Windows and MacOS] Port mapping, mapping the container port to the host port (note that you need to delete network_mode: \"host\" first, and then add the following content)\n    # ports:\n    # - \"12345: 12345\" # Note! 12345 must correspond to the WEB_PORT environment variable.\n# 4. Finally, run `docker-compose up`.\n# 5. If you want to use a graphics card, pay attention to the LOCAL_MODEL_DEVICE and Nvidia GPU runtime options.\n## ===================================================\n\n## ===================================================\n## 「方案零」 部署项目的全部能力（这个是包含cuda和latex的大型镜像。如果您网速慢、硬盘小或没有显卡，则不推荐使用这个）\n## ===================================================\nversion: '3'\nservices:\n  gpt_academic_full_capability:\n    image: ghcr.io/binary-husky/gpt_academic_with_all_capacity:master\n    environment:\n      # 请查阅 `config.py`或者 github wiki 以查看所有的配置信息\n      API_KEY:                  '  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                        '\n      # USE_PROXY:                '  True                                                                       '\n      # proxies:                  '  { \"http\": \"http://localhost:10881\", \"https\": \"http://localhost:10881\", }   '\n      LLM_MODEL:                '  gpt-3.5-turbo                                                              '\n      AVAIL_LLM_MODELS:         '  [\"gpt-3.5-turbo\", \"gpt-4\", \"qianfan\", \"sparkv2\", \"spark\", \"chatglm\"]       '\n      BAIDU_CLOUD_API_KEY :     '  bTUtwEAveBrQipEowUvDwYWq                                                   '\n      BAIDU_CLOUD_SECRET_KEY :  '  jqXtLvXiVw6UNdjliATTS61rllG8Iuni                                           '\n      XFYUN_APPID:              '  53a8d816                                                                   '\n      XFYUN_API_SECRET:         '  MjMxNDQ4NDE4MzM0OSNlNjQ2NTlhMTkx                                           '\n      XFYUN_API_KEY:            '  95ccdec285364869d17b33e75ee96447                                           '\n      ENABLE_AUDIO:             '  False                                                                      '\n      DEFAULT_WORKER_NUM:       '  20                                                                         '\n      WEB_PORT:                 '  12345                                                                      '\n      ADD_WAIFU:                '  False                                                                      '\n      ALIYUN_APPKEY:            '  RxPlZrM88DnAFkZK                                                           '\n      THEME:                    '  Chuanhu-Small-and-Beautiful                                                '\n      ALIYUN_ACCESSKEY:         '  LTAI5t6BrFUzxRXVGUWnekh1                                                   '\n      ALIYUN_SECRET:            '  eHmI20SVWIwQZxCiTD2bGQVspP9i68                                             '\n      # LOCAL_MODEL_DEVICE:       '  cuda                                                                       '\n\n    # 加载英伟达显卡运行时\n    # runtime: nvidia\n    # deploy:\n    #     resources:\n    #       reservations:\n    #         devices:\n    #           - driver: nvidia\n    #             count: 1\n    #             capabilities: [gpu]\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 「WEB_PORT暴露方法2: 适用于所有系统」端口映射\n    # ports:\n    #   - \"12345:12345\"  # 12345必须与WEB_PORT相互对应\n\n    # 启动容器后，运行main.py主程序\n    command: >\n      bash -c \"python3 -u main.py\"\n\n\n## ===================================================\n## 「方案一」 如果不需要运行本地模型（仅 chatgpt, azure, 星火, 千帆, claude 等在线大模型服务）\n## ===================================================\nversion: '3'\nservices:\n  gpt_academic_nolocalllms:\n    image: ghcr.io/binary-husky/gpt_academic_nolocal:master # (Auto Built by Dockerfile: docs/GithubAction+NoLocal)\n    environment:\n      # 请查阅 `config.py` 以查看所有的配置信息\n      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                            '\n      USE_PROXY:                '    True                                                                                           '\n      proxies:                  '    { \"http\": \"socks5h://localhost:10880\", \"https\": \"socks5h://localhost:10880\", }                 '\n      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '\n      AVAIL_LLM_MODELS:         '    [\"gpt-3.5-turbo\", \"api2d-gpt-3.5-turbo\", \"gpt-4\", \"api2d-gpt-4\", \"sparkv2\", \"qianfan\"]         '\n      WEB_PORT:                 '    22303                                                                                          '\n      ADD_WAIFU:                '    True                                                                                           '\n      # THEME:                    '    Chuanhu-Small-and-Beautiful                                                                    '\n      # DEFAULT_WORKER_NUM:       '    10                                                                                             '\n      # AUTHENTICATION:           '    [(\"username\", \"passwd\"), (\"username2\", \"passwd2\")]                                             '\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 启动命令\n    command: >\n      bash -c \"python3 -u main.py\"\n\n\n### ===================================================\n### 「方案二」 如果需要运行ChatGLM + Qwen + MOSS等本地模型\n### ===================================================\nversion: '3'\nservices:\n  gpt_academic_with_chatglm:\n    image: ghcr.io/binary-husky/gpt_academic_chatglm_moss:master  # (Auto Built by Dockerfile: docs/Dockerfile+ChatGLM)\n    environment:\n      # 请查阅 `config.py` 以查看所有的配置信息\n      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                            '\n      USE_PROXY:                '    True                                                                                           '\n      proxies:                  '    { \"http\": \"socks5h://localhost:10880\", \"https\": \"socks5h://localhost:10880\", }                 '\n      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '\n      AVAIL_LLM_MODELS:         '    [\"chatglm\", \"qwen\", \"moss\", \"gpt-3.5-turbo\", \"gpt-4\", \"newbing\"]                               '\n      LOCAL_MODEL_DEVICE:       '    cuda                                                                                           '\n      DEFAULT_WORKER_NUM:       '    10                                                                                             '\n      WEB_PORT:                 '    12303                                                                                          '\n      ADD_WAIFU:                '    True                                                                                           '\n      # AUTHENTICATION:           '    [(\"username\", \"passwd\"), (\"username2\", \"passwd2\")]                                             '\n\n    # 显卡的使用，nvidia0指第0个GPU\n    runtime: nvidia\n    devices:\n      - /dev/nvidia0:/dev/nvidia0\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 启动命令\n    command: >\n      bash -c \"python3 -u main.py\"\n\n    # P.S. 通过对 command 进行微调，可以便捷地安装额外的依赖\n    # command: >\n    #   bash -c \"pip install -r request_llms/requirements_qwen.txt && python3 -u main.py\"\n\n\n### ===================================================\n### 「方案三」 如果需要运行ChatGPT + LLAMA + 盘古 + RWKV本地模型\n### ===================================================\nversion: '3'\nservices:\n  gpt_academic_with_rwkv:\n    image: ghcr.io/binary-husky/gpt_academic_jittorllms:master\n    environment:\n      # 请查阅 `config.py` 以查看所有的配置信息\n      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,fkxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  '\n      USE_PROXY:                '    True                                                                                           '\n      proxies:                  '    { \"http\": \"socks5h://localhost:10880\", \"https\": \"socks5h://localhost:10880\", }                 '\n      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '\n      AVAIL_LLM_MODELS:         '    [\"gpt-3.5-turbo\", \"newbing\", \"jittorllms_rwkv\", \"jittorllms_pangualpha\", \"jittorllms_llama\"]   '\n      LOCAL_MODEL_DEVICE:       '    cuda                                                                                           '\n      DEFAULT_WORKER_NUM:       '    10                                                                                             '\n      WEB_PORT:                 '    12305                                                                                          '\n      ADD_WAIFU:                '    True                                                                                           '\n      # AUTHENTICATION:           '    [(\"username\", \"passwd\"), (\"username2\", \"passwd2\")]                                             '\n\n    # 显卡的使用，nvidia0指第0个GPU\n    runtime: nvidia\n    devices:\n      - /dev/nvidia0:/dev/nvidia0\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 启动命令\n    command: >\n      python3 -u main.py\n\n\n## ===================================================\n## 「方案四」 ChatGPT + Latex\n## ===================================================\nversion: '3'\nservices:\n  gpt_academic_with_latex:\n    image: ghcr.io/binary-husky/gpt_academic_with_latex:master  # (Auto Built by Dockerfile: docs/GithubAction+NoLocal+Latex)\n    # 对于ARM64设备，请将以上镜像名称替换为 ghcr.io/binary-husky/gpt_academic_with_latex_arm:master\n    environment:\n      # 请查阅 `config.py` 以查看所有的配置信息\n      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                              '\n      USE_PROXY:                '    True                                                                             '\n      proxies:                  '    { \"http\": \"socks5h://localhost:10880\", \"https\": \"socks5h://localhost:10880\", }   '\n      LLM_MODEL:                '    gpt-3.5-turbo                                                                    '\n      AVAIL_LLM_MODELS:         '    [\"gpt-3.5-turbo\", \"gpt-4\"]                                                       '\n      LOCAL_MODEL_DEVICE:       '    cuda                                                                             '\n      DEFAULT_WORKER_NUM:       '    10                                                                               '\n      WEB_PORT:                 '    12303                                                                            '\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 启动命令\n    command: >\n      bash -c \"python3 -u main.py\"\n\n\n## ===================================================\n## 「方案五」 ChatGPT + 语音助手 （请先阅读 docs/use_audio.md）\n## ===================================================\nversion: '3'\nservices:\n  gpt_academic_with_audio:\n    image: ghcr.io/binary-husky/gpt_academic_audio_assistant:master\n    environment:\n      # 请查阅 `config.py` 以查看所有的配置信息\n      API_KEY:                  '    fk195831-IdP0Pb3W6DCMUIbQwVX6MsSiyxwqybyS                        '\n      USE_PROXY:                '    False                                                            '\n      proxies:                  '    None                                                             '\n      LLM_MODEL:                '    gpt-3.5-turbo                                                    '\n      AVAIL_LLM_MODELS:         '    [\"gpt-3.5-turbo\", \"gpt-4\"]                                       '\n      ENABLE_AUDIO:             '    True                                                             '\n      LOCAL_MODEL_DEVICE:       '    cuda                                                             '\n      DEFAULT_WORKER_NUM:       '    20                                                               '\n      WEB_PORT:                 '    12343                                                            '\n      ADD_WAIFU:                '    True                                                             '\n      THEME:                    '    Chuanhu-Small-and-Beautiful                                      '\n      ALIYUN_APPKEY:            '    RoP1ZrM84DnAFkZK                                                 '\n      ALIYUN_TOKEN:             '    f37f30e0f9934c34a992f6f64f7eba4f                                 '\n      # (无需填写) ALIYUN_ACCESSKEY:         '    LTAI5q6BrFUzoRXVGUWnekh1                                         '\n      # (无需填写) ALIYUN_SECRET:            '    eHmI20AVWIaQZ0CiTD2bGQVsaP9i68                                   '\n\n    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合\n    network_mode: \"host\"\n\n    # 启动命令\n    command: >\n      bash -c \"python3 -u main.py\"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 24.21,
          "content": "import os; os.environ['no_proxy'] = '*' # 避免代理网络产生意外污染\n\nhelp_menu_description = \\\n\"\"\"Github源代码开源和更新[地址🚀](https://github.com/binary-husky/gpt_academic),\n感谢热情的[开发者们❤️](https://github.com/binary-husky/gpt_academic/graphs/contributors).\n</br></br>常见问题请查阅[项目Wiki](https://github.com/binary-husky/gpt_academic/wiki),\n如遇到Bug请前往[Bug反馈](https://github.com/binary-husky/gpt_academic/issues).\n</br></br>普通对话使用说明: 1. 输入问题; 2. 点击提交\n</br></br>基础功能区使用说明: 1. 输入文本; 2. 点击任意基础功能区按钮\n</br></br>函数插件区使用说明: 1. 输入路径/问题, 或者上传文件; 2. 点击任意函数插件区按钮\n</br></br>虚空终端使用说明: 点击虚空终端, 然后根据提示输入指令, 再次点击虚空终端\n</br></br>如何保存对话: 点击保存当前的对话按钮\n</br></br>如何语音对话: 请阅读Wiki\n</br></br>如何临时更换API_KEY: 在输入区输入临时API_KEY后提交（网页刷新后失效）\"\"\"\n\nfrom loguru import logger\ndef enable_log(PATH_LOGGING):\n    from shared_utils.logging import setup_logging\n    setup_logging(PATH_LOGGING)\n\ndef encode_plugin_info(k, plugin)->str:\n    import copy\n    from themes.theme import to_cookie_str\n    plugin_ = copy.copy(plugin)\n    plugin_.pop(\"Function\", None)\n    plugin_.pop(\"Class\", None)\n    plugin_.pop(\"Button\", None)\n    plugin_[\"Info\"] = plugin.get(\"Info\", k)\n    if plugin.get(\"AdvancedArgs\", False):\n        plugin_[\"Label\"] = f\"插件[{k}]的高级参数说明：\" + plugin.get(\"ArgsReminder\", f\"没有提供高级参数功能说明\")\n    else:\n        plugin_[\"Label\"] = f\"插件[{k}]不需要高级参数。\"\n    return to_cookie_str(plugin_)\n\ndef main():\n    import gradio as gr\n    if gr.__version__ not in ['3.32.12']:\n        raise ModuleNotFoundError(\"使用项目内置Gradio获取最优体验! 请运行 `pip install -r requirements.txt` 指令安装内置Gradio及其他依赖, 详情信息见requirements.txt.\")\n\n    # 一些基础工具\n    from toolbox import format_io, find_free_port, on_file_uploaded, on_report_generated, get_conf, ArgsGeneralWrapper, DummyWith\n\n    # 对话、日志记录\n    enable_log(get_conf(\"PATH_LOGGING\"))\n\n    # 对话句柄\n    from request_llms.bridge_all import predict\n\n    # 读取配置\n    proxies, WEB_PORT, LLM_MODEL, CONCURRENT_COUNT, AUTHENTICATION = get_conf('proxies', 'WEB_PORT', 'LLM_MODEL', 'CONCURRENT_COUNT', 'AUTHENTICATION')\n    CHATBOT_HEIGHT, LAYOUT, AVAIL_LLM_MODELS, AUTO_CLEAR_TXT = get_conf('CHATBOT_HEIGHT', 'LAYOUT', 'AVAIL_LLM_MODELS', 'AUTO_CLEAR_TXT')\n    ENABLE_AUDIO, AUTO_CLEAR_TXT, PATH_LOGGING, AVAIL_THEMES, THEME, ADD_WAIFU = get_conf('ENABLE_AUDIO', 'AUTO_CLEAR_TXT', 'PATH_LOGGING', 'AVAIL_THEMES', 'THEME', 'ADD_WAIFU')\n    NUM_CUSTOM_BASIC_BTN, SSL_KEYFILE, SSL_CERTFILE = get_conf('NUM_CUSTOM_BASIC_BTN', 'SSL_KEYFILE', 'SSL_CERTFILE')\n    DARK_MODE, INIT_SYS_PROMPT, ADD_WAIFU, TTS_TYPE = get_conf('DARK_MODE', 'INIT_SYS_PROMPT', 'ADD_WAIFU', 'TTS_TYPE')\n    if LLM_MODEL not in AVAIL_LLM_MODELS: AVAIL_LLM_MODELS += [LLM_MODEL]\n\n    # 如果WEB_PORT是-1, 则随机选取WEB端口\n    PORT = find_free_port() if WEB_PORT <= 0 else WEB_PORT\n    from check_proxy import get_current_version\n    from themes.theme import adjust_theme, advanced_css, theme_declaration, js_code_clear, js_code_show_or_hide, js_code_show_or_hide_group2\n    from themes.theme import js_code_for_toggle_darkmode\n    from themes.theme import load_dynamic_theme, to_cookie_str, from_cookie_str, assign_user_uuid\n    title_html = f\"<h1 align=\\\"center\\\">GPT 学术优化 {get_current_version()}</h1>{theme_declaration}\"\n\n\n    # 一些普通功能模块\n    from core_functional import get_core_functions\n    functional = get_core_functions()\n\n    # 高级函数插件\n    from crazy_functional import get_crazy_functions, get_multiplex_button_functions\n    DEFAULT_FN_GROUPS = get_conf('DEFAULT_FN_GROUPS')\n    plugins = get_crazy_functions()\n    all_plugin_groups = list(set([g for _, plugin in plugins.items() for g in plugin['Group'].split('|')]))\n    match_group = lambda tags, groups: any([g in groups for g in tags.split('|')])\n\n    # 处理markdown文本格式的转变\n    gr.Chatbot.postprocess = format_io\n\n    # 做一些外观色彩上的调整\n    set_theme = adjust_theme()\n\n    # 代理与自动更新\n    from check_proxy import check_proxy, auto_update, warm_up_modules\n    proxy_info = check_proxy(proxies)\n\n    # 切换布局\n    gr_L1 = lambda: gr.Row().style()\n    gr_L2 = lambda scale, elem_id: gr.Column(scale=scale, elem_id=elem_id, min_width=400)\n    if LAYOUT == \"TOP-DOWN\":\n        gr_L1 = lambda: DummyWith()\n        gr_L2 = lambda scale, elem_id: gr.Row()\n        CHATBOT_HEIGHT /= 2\n\n    cancel_handles = []\n    customize_btns = {}\n    predefined_btns = {}\n    from shared_utils.cookie_manager import make_cookie_cache, make_history_cache\n    with gr.Blocks(title=\"GPT 学术优化\", theme=set_theme, analytics_enabled=False, css=advanced_css) as app_block:\n        gr.HTML(title_html)\n        secret_css = gr.Textbox(visible=False, elem_id=\"secret_css\")\n        register_advanced_plugin_init_arr = \"\"\n\n        cookies, web_cookie_cache = make_cookie_cache() # 定义 后端state（cookies）、前端（web_cookie_cache）两兄弟\n        with gr_L1():\n            with gr_L2(scale=2, elem_id=\"gpt-chat\"):\n                chatbot = gr.Chatbot(label=f\"当前模型：{LLM_MODEL}\", elem_id=\"gpt-chatbot\")\n                if LAYOUT == \"TOP-DOWN\":  chatbot.style(height=CHATBOT_HEIGHT)\n                history, _, _ = make_history_cache() # 定义 后端state（history）、前端（history_cache）、后端setter（history_cache_update）三兄弟\n            with gr_L2(scale=1, elem_id=\"gpt-panel\"):\n                with gr.Accordion(\"输入区\", open=True, elem_id=\"input-panel\") as area_input_primary:\n                    with gr.Row():\n                        txt = gr.Textbox(show_label=False, placeholder=\"Input question here.\", elem_id='user_input_main').style(container=False)\n                    with gr.Row(elem_id=\"gpt-submit-row\"):\n                        multiplex_submit_btn = gr.Button(\"提交\", elem_id=\"elem_submit_visible\", variant=\"primary\")\n                        multiplex_sel = gr.Dropdown(\n                            choices=get_multiplex_button_functions().keys(), value=\"常规对话\",\n                            interactive=True, label='', show_label=False,\n                            elem_classes='normal_mut_select', elem_id=\"gpt-submit-dropdown\").style(container=False)\n                        submit_btn = gr.Button(\"提交\", elem_id=\"elem_submit\", variant=\"primary\", visible=False)\n                    with gr.Row():\n                        resetBtn = gr.Button(\"重置\", elem_id=\"elem_reset\", variant=\"secondary\"); resetBtn.style(size=\"sm\")\n                        stopBtn = gr.Button(\"停止\", elem_id=\"elem_stop\", variant=\"secondary\"); stopBtn.style(size=\"sm\")\n                        clearBtn = gr.Button(\"清除\", elem_id=\"elem_clear\", variant=\"secondary\", visible=False); clearBtn.style(size=\"sm\")\n                    if ENABLE_AUDIO:\n                        with gr.Row():\n                            audio_mic = gr.Audio(source=\"microphone\", type=\"numpy\", elem_id=\"elem_audio\", streaming=True, show_label=False).style(container=False)\n                    with gr.Row():\n                        status = gr.Markdown(f\"Tip: 按Enter提交, 按Shift+Enter换行。支持将文件直接粘贴到输入区。\", elem_id=\"state-panel\")\n\n                with gr.Accordion(\"基础功能区\", open=True, elem_id=\"basic-panel\") as area_basic_fn:\n                    with gr.Row():\n                        for k in range(NUM_CUSTOM_BASIC_BTN):\n                            customize_btn = gr.Button(\"自定义按钮\" + str(k+1), visible=False, variant=\"secondary\", info_str=f'基础功能区: 自定义按钮')\n                            customize_btn.style(size=\"sm\")\n                            customize_btns.update({\"自定义按钮\" + str(k+1): customize_btn})\n                        for k in functional:\n                            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\n                            variant = functional[k][\"Color\"] if \"Color\" in functional[k] else \"secondary\"\n                            functional[k][\"Button\"] = gr.Button(k, variant=variant, info_str=f'基础功能区: {k}')\n                            functional[k][\"Button\"].style(size=\"sm\")\n                            predefined_btns.update({k: functional[k][\"Button\"]})\n                with gr.Accordion(\"函数插件区\", open=True, elem_id=\"plugin-panel\") as area_crazy_fn:\n                    with gr.Row():\n                        gr.Markdown(\"<small>插件可读取“输入区”文本/路径作为参数（上传文件自动修正路径）</small>\")\n                    with gr.Row(elem_id=\"input-plugin-group\"):\n                        plugin_group_sel = gr.Dropdown(choices=all_plugin_groups, label='', show_label=False, value=DEFAULT_FN_GROUPS,\n                                                      multiselect=True, interactive=True, elem_classes='normal_mut_select').style(container=False)\n                    with gr.Row():\n                        for index, (k, plugin) in enumerate(plugins.items()):\n                            if not plugin.get(\"AsButton\", True): continue\n                            visible = True if match_group(plugin['Group'], DEFAULT_FN_GROUPS) else False\n                            variant = plugins[k][\"Color\"] if \"Color\" in plugin else \"secondary\"\n                            info = plugins[k].get(\"Info\", k)\n                            btn_elem_id = f\"plugin_btn_{index}\"\n                            plugin['Button'] = plugins[k]['Button'] = gr.Button(k, variant=variant,\n                                visible=visible, info_str=f'函数插件区: {info}', elem_id=btn_elem_id).style(size=\"sm\")\n                            plugin['ButtonElemId'] = btn_elem_id\n                    with gr.Row():\n                        with gr.Accordion(\"更多函数插件\", open=True):\n                            dropdown_fn_list = []\n                            for k, plugin in plugins.items():\n                                if not match_group(plugin['Group'], DEFAULT_FN_GROUPS): continue\n                                if not plugin.get(\"AsButton\", True): dropdown_fn_list.append(k)     # 排除已经是按钮的插件\n                                elif plugin.get('AdvancedArgs', False): dropdown_fn_list.append(k)  # 对于需要高级参数的插件，亦在下拉菜单中显示\n                            with gr.Row():\n                                dropdown = gr.Dropdown(dropdown_fn_list, value=r\"点击这里输入「关键词」搜索插件\", label=\"\", show_label=False).style(container=False)\n                            with gr.Row():\n                                plugin_advanced_arg = gr.Textbox(show_label=True, label=\"高级参数输入区\", visible=False, elem_id=\"advance_arg_input_legacy\",\n                                                                 placeholder=\"这里是特殊函数插件的高级参数输入区\").style(container=False)\n                            with gr.Row():\n                                switchy_bt = gr.Button(r\"请先从插件列表中选择\", variant=\"secondary\", elem_id=\"elem_switchy_bt\").style(size=\"sm\")\n                    with gr.Row():\n                        with gr.Accordion(\"点击展开“文件下载区”。\", open=False) as area_file_up:\n                            file_upload = gr.Files(label=\"任何文件, 推荐上传压缩文件(zip, tar)\", file_count=\"multiple\", elem_id=\"elem_upload\")\n\n\n        # 左上角工具栏定义\n        from themes.gui_toolbar import define_gui_toolbar\n        checkboxes, checkboxes_2, max_length_sl, theme_dropdown, system_prompt, file_upload_2, md_dropdown, top_p, temperature = \\\n            define_gui_toolbar(AVAIL_LLM_MODELS, LLM_MODEL, INIT_SYS_PROMPT, THEME, AVAIL_THEMES, ADD_WAIFU, help_menu_description, js_code_for_toggle_darkmode)\n\n        # 浮动菜单定义\n        from themes.gui_floating_menu import define_gui_floating_menu\n        area_input_secondary, txt2, area_customize, _, resetBtn2, clearBtn2, stopBtn2 = \\\n            define_gui_floating_menu(customize_btns, functional, predefined_btns, cookies, web_cookie_cache)\n        \n        # 浮动时间线定义\n        gr.Spark()\n\n        # 插件二级菜单的实现\n        from themes.gui_advanced_plugin_class import define_gui_advanced_plugin_class\n        new_plugin_callback, route_switchy_bt_with_arg, usr_confirmed_arg = \\\n            define_gui_advanced_plugin_class(plugins)\n\n        # 功能区显示开关与功能区的互动\n        def fn_area_visibility(a):\n            ret = {}\n            ret.update({area_input_primary: gr.update(visible=(\"浮动输入区\" not in a))})\n            ret.update({area_input_secondary: gr.update(visible=(\"浮动输入区\" in a))})\n            ret.update({plugin_advanced_arg: gr.update(visible=(\"插件参数区\" in a))})\n            if \"浮动输入区\" in a: ret.update({txt: gr.update(value=\"\")})\n            return ret\n        checkboxes.select(fn_area_visibility, [checkboxes], [area_basic_fn, area_crazy_fn, area_input_primary, area_input_secondary, txt, txt2, plugin_advanced_arg] )\n        checkboxes.select(None, [checkboxes], None, _js=js_code_show_or_hide)\n\n        # 功能区显示开关与功能区的互动\n        def fn_area_visibility_2(a):\n            ret = {}\n            ret.update({area_customize: gr.update(visible=(\"自定义菜单\" in a))})\n            return ret\n        checkboxes_2.select(fn_area_visibility_2, [checkboxes_2], [area_customize] )\n        checkboxes_2.select(None, [checkboxes_2], None, _js=js_code_show_or_hide_group2)\n\n        # 整理反复出现的控件句柄组合\n        input_combo = [cookies, max_length_sl, md_dropdown, txt, txt2, top_p, temperature, chatbot, history, system_prompt, plugin_advanced_arg]\n        input_combo_order = [\"cookies\", \"max_length_sl\", \"md_dropdown\", \"txt\", \"txt2\", \"top_p\", \"temperature\", \"chatbot\", \"history\", \"system_prompt\", \"plugin_advanced_arg\"]\n        output_combo = [cookies, chatbot, history, status]\n        predict_args = dict(fn=ArgsGeneralWrapper(predict), inputs=[*input_combo, gr.State(True)], outputs=output_combo)\n        \n        # 提交按钮、重置按钮\n        multiplex_submit_btn.click(\n            None, [multiplex_sel], None, _js=\"\"\"(multiplex_sel)=>multiplex_function_begin(multiplex_sel)\"\"\")\n        txt.submit(\n            None, [multiplex_sel], None, _js=\"\"\"(multiplex_sel)=>multiplex_function_begin(multiplex_sel)\"\"\")\n        multiplex_sel.select(\n            None, [multiplex_sel], None, _js=f\"\"\"(multiplex_sel)=>run_multiplex_shift(multiplex_sel)\"\"\")\n        cancel_handles.append(submit_btn.click(**predict_args))\n        resetBtn.click(None, None, [chatbot, history, status], _js= \"\"\"clear_conversation\"\"\")   # 先在前端快速清除chatbot&status\n        resetBtn2.click(None, None, [chatbot, history, status], _js=\"\"\"clear_conversation\"\"\")  # 先在前端快速清除chatbot&status\n        # reset_server_side_args = (lambda history: ([], [], \"已重置\"), [history], [chatbot, history, status])\n        # resetBtn.click(*reset_server_side_args)    # 再在后端清除history\n        # resetBtn2.click(*reset_server_side_args)   # 再在后端清除history\n        clearBtn.click(None, None, [txt, txt2], _js=js_code_clear)\n        clearBtn2.click(None, None, [txt, txt2], _js=js_code_clear)\n        if AUTO_CLEAR_TXT:\n            submit_btn.click(None, None, [txt, txt2], _js=js_code_clear)\n        # 基础功能区的回调函数注册\n        for k in functional:\n            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\n            click_handle = functional[k][\"Button\"].click(fn=ArgsGeneralWrapper(predict), inputs=[*input_combo, gr.State(True), gr.State(k)], outputs=output_combo)\n            cancel_handles.append(click_handle)\n        for btn in customize_btns.values():\n            click_handle = btn.click(fn=ArgsGeneralWrapper(predict), inputs=[*input_combo, gr.State(True), gr.State(btn.value)], outputs=output_combo)\n            cancel_handles.append(click_handle)\n        # 文件上传区，接收文件后与chatbot的互动\n        file_upload.upload(on_file_uploaded, [file_upload, chatbot, txt, txt2, checkboxes, cookies], [chatbot, txt, txt2, cookies]).then(None, None, None,   _js=r\"()=>{toast_push('上传完毕 ...'); cancel_loading_status();}\")\n        file_upload_2.upload(on_file_uploaded, [file_upload_2, chatbot, txt, txt2, checkboxes, cookies], [chatbot, txt, txt2, cookies]).then(None, None, None, _js=r\"()=>{toast_push('上传完毕 ...'); cancel_loading_status();}\")\n        # 函数插件-固定按钮区\n        for k in plugins:\n            register_advanced_plugin_init_arr += f\"\"\"register_plugin_init(\"{k}\",\"{encode_plugin_info(k, plugins[k])}\");\"\"\"\n            if plugins[k].get(\"Class\", None):\n                plugins[k][\"JsMenu\"] = plugins[k][\"Class\"]().get_js_code_for_generating_menu(k)\n                register_advanced_plugin_init_arr += \"\"\"register_advanced_plugin_init_code(\"{k}\",\"{gui_js}\");\"\"\".format(k=k, gui_js=plugins[k][\"JsMenu\"])\n            if not plugins[k].get(\"AsButton\", True): continue\n            if plugins[k].get(\"Class\", None) is None:\n                assert plugins[k].get(\"Function\", None) is not None\n                click_handle = plugins[k][\"Button\"].click(None, inputs=[], outputs=None, _js=f\"\"\"()=>run_classic_plugin_via_id(\"{plugins[k][\"ButtonElemId\"]}\")\"\"\")\n            else:\n                click_handle = plugins[k][\"Button\"].click(None, inputs=[], outputs=None, _js=f\"\"\"()=>run_advanced_plugin_launch_code(\"{k}\")\"\"\")\n\n        # 函数插件-下拉菜单与随变按钮的互动（新版-更流畅）\n        dropdown.select(None, [dropdown], None, _js=f\"\"\"(dropdown)=>run_dropdown_shift(dropdown)\"\"\")\n\n        # 模型切换时的回调\n        def on_md_dropdown_changed(k):\n            return {chatbot: gr.update(label=\"当前模型：\"+k)}\n        md_dropdown.select(on_md_dropdown_changed, [md_dropdown], [chatbot])\n\n        # 主题修改\n        def on_theme_dropdown_changed(theme, secret_css):\n            adjust_theme, css_part1, _, adjust_dynamic_theme = load_dynamic_theme(theme)\n            if adjust_dynamic_theme:\n                css_part2 = adjust_dynamic_theme._get_theme_css()\n            else:\n                css_part2 = adjust_theme()._get_theme_css()\n            return css_part2 + css_part1\n        theme_handle = theme_dropdown.select(on_theme_dropdown_changed, [theme_dropdown, secret_css], [secret_css]) # , _js=\"\"\"change_theme_prepare\"\"\")\n        theme_handle.then(None, [theme_dropdown, secret_css], None, _js=\"\"\"change_theme\"\"\")\n\n        switchy_bt.click(None, [switchy_bt], None, _js=\"(switchy_bt)=>on_flex_button_click(switchy_bt)\")\n        # 随变按钮的回调函数注册\n        def route(request: gr.Request, k, *args, **kwargs):\n            if k not in [r\"点击这里搜索插件列表\", r\"请先从插件列表中选择\"]:\n                if plugins[k].get(\"Class\", None) is None:\n                    assert plugins[k].get(\"Function\", None) is not None\n                    yield from ArgsGeneralWrapper(plugins[k][\"Function\"])(request, *args, **kwargs)\n        # 旧插件的高级参数区确认按钮（隐藏）\n        old_plugin_callback = gr.Button(r\"未选定任何插件\", variant=\"secondary\", visible=False, elem_id=\"old_callback_btn_for_plugin_exe\")\n        click_handle_ng = old_plugin_callback.click(route, [switchy_bt, *input_combo], output_combo)\n        click_handle_ng.then(on_report_generated, [cookies, file_upload, chatbot], [cookies, file_upload, chatbot]).then(None, [switchy_bt], None, _js=r\"(fn)=>on_plugin_exe_complete(fn)\")\n        cancel_handles.append(click_handle_ng)\n        # 新一代插件的高级参数区确认按钮（隐藏）\n        click_handle_ng = new_plugin_callback.click(route_switchy_bt_with_arg,\n            [\n                gr.State([\"new_plugin_callback\", \"usr_confirmed_arg\"] + input_combo_order), # 第一个参数: 指定了后续参数的名称\n                new_plugin_callback, usr_confirmed_arg, *input_combo                        # 后续参数: 真正的参数\n            ], output_combo)\n        click_handle_ng.then(on_report_generated, [cookies, file_upload, chatbot], [cookies, file_upload, chatbot]).then(None, [switchy_bt], None, _js=r\"(fn)=>on_plugin_exe_complete(fn)\")\n        cancel_handles.append(click_handle_ng)\n        # 终止按钮的回调函数注册\n        stopBtn.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\n        stopBtn2.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\n        plugins_as_btn = {name:plugin for name, plugin in plugins.items() if plugin.get('Button', None)}\n        def on_group_change(group_list):\n            btn_list = []\n            fns_list = []\n            if not group_list: # 处理特殊情况：没有选择任何插件组\n                return [*[plugin['Button'].update(visible=False) for _, plugin in plugins_as_btn.items()], gr.Dropdown.update(choices=[])]\n            for k, plugin in plugins.items():\n                if plugin.get(\"AsButton\", True):\n                    btn_list.append(plugin['Button'].update(visible=match_group(plugin['Group'], group_list))) # 刷新按钮\n                    if plugin.get('AdvancedArgs', False): dropdown_fn_list.append(k) # 对于需要高级参数的插件，亦在下拉菜单中显示\n                elif match_group(plugin['Group'], group_list): fns_list.append(k) # 刷新下拉列表\n            return [*btn_list, gr.Dropdown.update(choices=fns_list)]\n        plugin_group_sel.select(fn=on_group_change, inputs=[plugin_group_sel], outputs=[*[plugin['Button'] for name, plugin in plugins_as_btn.items()], dropdown])\n\n        # 是否启动语音输入功能\n        if ENABLE_AUDIO:\n            from crazy_functions.live_audio.audio_io import RealtimeAudioDistribution\n            rad = RealtimeAudioDistribution()\n            def deal_audio(audio, cookies):\n                rad.feed(cookies['uuid'].hex, audio)\n            audio_mic.stream(deal_audio, inputs=[audio_mic, cookies])\n\n        # 生成当前浏览器窗口的uuid（刷新失效）\n        app_block.load(assign_user_uuid, inputs=[cookies], outputs=[cookies])\n\n        # 初始化（前端）\n        from shared_utils.cookie_manager import load_web_cookie_cache__fn_builder\n        load_web_cookie_cache = load_web_cookie_cache__fn_builder(customize_btns, cookies, predefined_btns)\n        app_block.load(load_web_cookie_cache, inputs = [web_cookie_cache, cookies],\n            outputs = [web_cookie_cache, cookies, *customize_btns.values(), *predefined_btns.values()], _js=\"\"\"persistent_cookie_init\"\"\")\n        app_block.load(None, inputs=[], outputs=None, _js=f\"\"\"()=>GptAcademicJavaScriptInit(\"{DARK_MODE}\",\"{INIT_SYS_PROMPT}\",\"{ADD_WAIFU}\",\"{LAYOUT}\",\"{TTS_TYPE}\")\"\"\")    # 配置暗色主题或亮色主题\n        app_block.load(None, inputs=[], outputs=None, _js=\"\"\"()=>{REP}\"\"\".replace(\"REP\", register_advanced_plugin_init_arr))\n\n    # Gradio的inbrowser触发不太稳定，回滚代码到原始的浏览器打开函数\n    def run_delayed_tasks():\n        import threading, webbrowser, time\n        logger.info(f\"如果浏览器没有自动打开，请复制并转到以下URL：\")\n        if DARK_MODE:   logger.info(f\"\\t「暗色主题已启用（支持动态切换主题）」: http://localhost:{PORT}\")\n        else:           logger.info(f\"\\t「亮色主题已启用（支持动态切换主题）」: http://localhost:{PORT}\")\n\n        def auto_updates(): time.sleep(0); auto_update()\n        def open_browser(): time.sleep(2); webbrowser.open_new_tab(f\"http://localhost:{PORT}\")\n        def warm_up_mods(): time.sleep(6); warm_up_modules()\n\n        threading.Thread(target=auto_updates, name=\"self-upgrade\", daemon=True).start() # 查看自动更新\n        threading.Thread(target=warm_up_mods, name=\"warm-up\",      daemon=True).start() # 预热tiktoken模块\n        if get_conf('AUTO_OPEN_BROWSER'):\n            threading.Thread(target=open_browser, name=\"open-browser\", daemon=True).start() # 打开浏览器页面\n\n    # 运行一些异步任务：自动更新、打开浏览器页面、预热tiktoken模块\n    run_delayed_tasks()\n\n    # 最后，正式开始服务\n    from shared_utils.fastapi_server import start_app\n    start_app(app_block, CONCURRENT_COUNT, AUTHENTICATION, PORT, SSL_KEYFILE, SSL_CERTFILE)\n\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "name": "multi_language.py",
          "type": "blob",
          "size": 21.91,
          "content": "\"\"\"\n    Translate this project to other languages (experimental, please open an issue if there is any bug)\n\n\n    Usage:\n        1. modify config.py, set your LLM_MODEL and API_KEY(s) to provide access to OPENAI (or any other LLM model provider)\n\n        2. modify LANG (below ↓)\n            LANG = \"English\"\n\n        3. modify TransPrompt (below ↓)\n            TransPrompt = f\"Replace each json value `#` with translated results in English, e.g., \\\"原始文本\\\":\\\"TranslatedText\\\". Keep Json format. Do not answer #.\"\n\n        4. Run `python multi_language.py`.\n            Note: You need to run it multiple times to increase translation coverage because GPT makes mistakes sometimes.\n           (You can also run `CACHE_ONLY=True python multi_language.py` to use cached translation mapping)\n\n        5. Find the translated program in `multi-language\\English\\*`\n\n    P.S.\n\n        - The translation mapping will be stored in `docs/translation_xxxx.json`, you can revised mistaken translation there.\n\n        - If you would like to share your `docs/translation_xxxx.json`, (so that everyone can use the cached & revised translation mapping), please open a Pull Request\n\n        - If there is any translation error in `docs/translation_xxxx.json`, please open a Pull Request\n\n        - Welcome any Pull Request, regardless of language\n\"\"\"\n\nimport os\nimport json\nimport functools\nimport re\nimport pickle\nimport time\nfrom toolbox import get_conf\n\nCACHE_ONLY = os.environ.get('CACHE_ONLY', False)\n\nCACHE_FOLDER = get_conf('PATH_LOGGING')\n\nblacklist = ['multi-language', CACHE_FOLDER, '.git', 'private_upload', 'multi_language.py', 'build', '.github', '.vscode', '__pycache__', 'venv']\n\n# LANG = \"TraditionalChinese\"\n# TransPrompt = f\"Replace each json value `#` with translated results in Traditional Chinese, e.g., \\\"原始文本\\\":\\\"翻譯後文字\\\". Keep Json format. Do not answer #.\"\n\n# LANG = \"Japanese\"\n# TransPrompt = f\"Replace each json value `#` with translated results in Japanese, e.g., \\\"原始文本\\\":\\\"テキストの翻訳\\\". Keep Json format. Do not answer #.\"\n\nLANG = \"English\"\nTransPrompt = f\"Replace each json value `#` with translated results in English, e.g., \\\"原始文本\\\":\\\"TranslatedText\\\". Keep Json format. Do not answer #.\"\n\n\nif not os.path.exists(CACHE_FOLDER):\n    os.makedirs(CACHE_FOLDER)\n\n\ndef lru_file_cache(maxsize=128, ttl=None, filename=None):\n    \"\"\"\n    Decorator that caches a function's return value after being called with given arguments.\n    It uses a Least Recently Used (LRU) cache strategy to limit the size of the cache.\n    maxsize: Maximum size of the cache. Defaults to 128.\n    ttl: Time-to-Live of the cache. If a value hasn't been accessed for `ttl` seconds, it will be evicted from the cache.\n    filename: Name of the file to store the cache in. If not supplied, the function name + \".cache\" will be used.\n    \"\"\"\n    cache_path = os.path.join(CACHE_FOLDER, f\"{filename}.cache\") if filename is not None else None\n\n    def decorator_function(func):\n        cache = {}\n        _cache_info = {\n            \"hits\": 0,\n            \"misses\": 0,\n            \"maxsize\": maxsize,\n            \"currsize\": 0,\n            \"ttl\": ttl,\n            \"filename\": cache_path,\n        }\n\n        @functools.wraps(func)\n        def wrapper_function(*args, **kwargs):\n            key = str((args, frozenset(kwargs)))\n            if key in cache:\n                if _cache_info[\"ttl\"] is None or (cache[key][1] + _cache_info[\"ttl\"]) >= time.time():\n                    _cache_info[\"hits\"] += 1\n                    print(f'Warning, reading cache, last read {(time.time()-cache[key][1])//60} minutes ago'); time.sleep(2)\n                    cache[key][1] = time.time()\n                    return cache[key][0]\n                else:\n                    del cache[key]\n\n            result = func(*args, **kwargs)\n            cache[key] = [result, time.time()]\n            _cache_info[\"misses\"] += 1\n            _cache_info[\"currsize\"] += 1\n\n            if _cache_info[\"currsize\"] > _cache_info[\"maxsize\"]:\n                oldest_key = None\n                for k in cache:\n                    if oldest_key is None:\n                        oldest_key = k\n                    elif cache[k][1] < cache[oldest_key][1]:\n                        oldest_key = k\n                del cache[oldest_key]\n                _cache_info[\"currsize\"] -= 1\n\n            if cache_path is not None:\n                with open(cache_path, \"wb\") as f:\n                    pickle.dump(cache, f)\n\n            return result\n\n        def cache_info():\n            return _cache_info\n\n        wrapper_function.cache_info = cache_info\n\n        if cache_path is not None and os.path.exists(cache_path):\n            with open(cache_path, \"rb\") as f:\n                cache = pickle.load(f)\n            _cache_info[\"currsize\"] = len(cache)\n\n        return wrapper_function\n\n    return decorator_function\n\ndef contains_chinese(string):\n    \"\"\"\n    Returns True if the given string contains Chinese characters, False otherwise.\n    \"\"\"\n    chinese_regex = re.compile(u'[\\u4e00-\\u9fff]+')\n    return chinese_regex.search(string) is not None\n\ndef split_list(lst, n_each_req):\n    \"\"\"\n    Split a list into smaller lists, each with a maximum number of elements.\n    :param lst: the list to split\n    :param n_each_req: the maximum number of elements in each sub-list\n    :return: a list of sub-lists\n    \"\"\"\n    result = []\n    for i in range(0, len(lst), n_each_req):\n        result.append(lst[i:i + n_each_req])\n    return result\n\ndef map_to_json(map, language):\n    dict_ = read_map_from_json(language)\n    dict_.update(map)\n    with open(f'docs/translate_{language.lower()}.json', 'w', encoding='utf8') as f:\n        json.dump(dict_, f, indent=4, ensure_ascii=False)\n\ndef read_map_from_json(language):\n    if os.path.exists(f'docs/translate_{language.lower()}.json'):\n        with open(f'docs/translate_{language.lower()}.json', 'r', encoding='utf8') as f:\n            res = json.load(f)\n            res = {k:v for k, v in res.items() if v is not None and contains_chinese(k)}\n            return res\n    return {}\n\ndef advanced_split(splitted_string, spliter, include_spliter=False):\n    splitted_string_tmp = []\n    for string_ in splitted_string:\n        if spliter in string_:\n            splitted = string_.split(spliter)\n            for i, s in enumerate(splitted):\n                if include_spliter:\n                    if i != len(splitted)-1:\n                        splitted[i] += spliter\n                splitted[i] = splitted[i].strip()\n            for i in reversed(range(len(splitted))):\n                if not contains_chinese(splitted[i]):\n                    splitted.pop(i)\n            splitted_string_tmp.extend(splitted)\n        else:\n            splitted_string_tmp.append(string_)\n    splitted_string = splitted_string_tmp\n    return splitted_string_tmp\n\ncached_translation = {}\ncached_translation = read_map_from_json(language=LANG)\n\ndef trans(word_to_translate, language, special=False):\n    if len(word_to_translate) == 0: return {}\n    from crazy_functions.crazy_utils import request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency\n    from toolbox import get_conf, ChatBotWithCookies, load_chat_cookies\n\n    cookies = load_chat_cookies()\n    llm_kwargs = {\n        'api_key': cookies['api_key'],\n        'llm_model': cookies['llm_model'],\n        'top_p':1.0,\n        'max_length': None,\n        'temperature':0.4,\n    }\n    import random\n    N_EACH_REQ = random.randint(16, 32)\n    word_to_translate_split = split_list(word_to_translate, N_EACH_REQ)\n    inputs_array = [str(s) for s in word_to_translate_split]\n    inputs_show_user_array = inputs_array\n    history_array = [[] for _ in inputs_array]\n    if special: #  to English using CamelCase Naming Convention\n        sys_prompt_array = [f\"Translate following names to English with CamelCase naming convention. Keep original format\" for _ in inputs_array]\n    else:\n        sys_prompt_array = [f\"Translate following sentences to {LANG}. E.g., You should translate sentences to the following format ['translation of sentence 1', 'translation of sentence 2']. Do NOT answer with Chinese!\" for _ in inputs_array]\n    chatbot = ChatBotWithCookies(llm_kwargs)\n    gpt_say_generator = request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency(\n        inputs_array,\n        inputs_show_user_array,\n        llm_kwargs,\n        chatbot,\n        history_array,\n        sys_prompt_array,\n    )\n    while True:\n        try:\n            gpt_say = next(gpt_say_generator)\n            print(gpt_say[1][0][1])\n        except StopIteration as e:\n            result = e.value\n            break\n    translated_result = {}\n    for i, r in enumerate(result):\n        if i%2 == 1:\n            try:\n                res_before_trans = eval(result[i-1])\n                res_after_trans = eval(result[i])\n                if len(res_before_trans) != len(res_after_trans):\n                    raise RuntimeError\n                for a,b in zip(res_before_trans, res_after_trans):\n                    translated_result[a] = b\n            except:\n                # try:\n                    # res_before_trans = word_to_translate_split[(i-1)//2]\n                    # res_after_trans = [s for s in result[i].split(\"', '\")]\n                #     for a,b in zip(res_before_trans, res_after_trans):\n                #         translated_result[a] = b\n                # except:\n                print('GPT answers with unexpected format, some words may not be translated, but you can try again later to increase translation coverage.')\n                res_before_trans = eval(result[i-1])\n                for a in res_before_trans:\n                    translated_result[a] = None\n    return translated_result\n\n\ndef trans_json(word_to_translate, language, special=False):\n    if len(word_to_translate) == 0: return {}\n    from crazy_functions.crazy_utils import request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency\n    from toolbox import get_conf, ChatBotWithCookies, load_chat_cookies\n\n    cookies = load_chat_cookies()\n    llm_kwargs = {\n        'api_key': cookies['api_key'],\n        'llm_model': cookies['llm_model'],\n        'top_p':1.0,\n        'max_length': None,\n        'temperature':0.4,\n    }\n    import random\n    N_EACH_REQ = random.randint(16, 32)\n    random.shuffle(word_to_translate)\n    word_to_translate_split = split_list(word_to_translate, N_EACH_REQ)\n    inputs_array = [{k:\"#\" for k in s} for s in word_to_translate_split]\n    inputs_array = [ json.dumps(i, ensure_ascii=False)  for i in inputs_array]\n\n    inputs_show_user_array = inputs_array\n    history_array = [[] for _ in inputs_array]\n    sys_prompt_array = [TransPrompt for _ in inputs_array]\n    chatbot = ChatBotWithCookies(llm_kwargs)\n    gpt_say_generator = request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency(\n        inputs_array,\n        inputs_show_user_array,\n        llm_kwargs,\n        chatbot,\n        history_array,\n        sys_prompt_array,\n    )\n    while True:\n        try:\n            gpt_say = next(gpt_say_generator)\n            print(gpt_say[1][0][1])\n        except StopIteration as e:\n            result = e.value\n            break\n    translated_result = {}\n    for i, r in enumerate(result):\n        if i%2 == 1:\n            try:\n                translated_result.update(json.loads(result[i]))\n            except:\n                print(result[i])\n    print(result)\n    return translated_result\n\n\ndef step_1_core_key_translate():\n    LANG_STD = 'std'\n    def extract_chinese_characters(file_path):\n        syntax = []\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n            import ast\n            root = ast.parse(content)\n            for node in ast.walk(root):\n                if isinstance(node, ast.Name):\n                    if contains_chinese(node.id): syntax.append(node.id)\n                if isinstance(node, ast.Import):\n                    for n in node.names:\n                        if contains_chinese(n.name): syntax.append(n.name)\n                elif isinstance(node, ast.ImportFrom):\n                    for n in node.names:\n                        if contains_chinese(n.name): syntax.append(n.name)\n                        # if node.module is None: print(node.module)\n                        for k in node.module.split('.'):\n                            if contains_chinese(k): syntax.append(k)\n            return syntax\n\n    def extract_chinese_characters_from_directory(directory_path):\n        chinese_characters = []\n        for root, dirs, files in os.walk(directory_path):\n            if any([b in root for b in blacklist]):\n                continue\n            print(files)\n            for file in files:\n                if file.endswith('.py'):\n                    file_path = os.path.join(root, file)\n                    chinese_characters.extend(extract_chinese_characters(file_path))\n        return chinese_characters\n\n    directory_path = './'\n    chinese_core_names = extract_chinese_characters_from_directory(directory_path)\n    chinese_core_keys = [name for name in chinese_core_names]\n    chinese_core_keys_norepeat = []\n    for d in chinese_core_keys:\n        if d not in chinese_core_keys_norepeat: chinese_core_keys_norepeat.append(d)\n    need_translate = []\n    cached_translation = read_map_from_json(language=LANG_STD)\n    cached_translation_keys = list(cached_translation.keys())\n    for d in chinese_core_keys_norepeat:\n        if d not in cached_translation_keys:\n            need_translate.append(d)\n\n    if CACHE_ONLY:\n        need_translate_mapping = {}\n    else:\n        need_translate_mapping = trans(need_translate, language=LANG_STD, special=True)\n    map_to_json(need_translate_mapping, language=LANG_STD)\n    cached_translation = read_map_from_json(language=LANG_STD)\n    cached_translation = dict(sorted(cached_translation.items(), key=lambda x: -len(x[0])))\n\n    chinese_core_keys_norepeat_mapping = {}\n    for k in chinese_core_keys_norepeat:\n        chinese_core_keys_norepeat_mapping.update({k:cached_translation[k]})\n    chinese_core_keys_norepeat_mapping = dict(sorted(chinese_core_keys_norepeat_mapping.items(), key=lambda x: -len(x[0])))\n\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    # copy\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    def copy_source_code():\n\n        from toolbox import get_conf\n        import shutil\n        import os\n        try: shutil.rmtree(f'./multi-language/{LANG}/')\n        except: pass\n        os.makedirs(f'./multi-language', exist_ok=True)\n        backup_dir = f'./multi-language/{LANG}/'\n        shutil.copytree('./', backup_dir, ignore=lambda x, y: blacklist)\n    copy_source_code()\n\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    # primary key replace\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    directory_path = f'./multi-language/{LANG}/'\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                syntax = []\n                # read again\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n\n                for k, v in chinese_core_keys_norepeat_mapping.items():\n                    content = content.replace(k, v)\n\n                with open(file_path, 'w', encoding='utf-8') as f:\n                    f.write(content)\n\n\ndef step_2_core_key_translate():\n\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n    # step2\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n    def load_string(strings, string_input):\n        string_ = string_input.strip().strip(',').strip().strip('.').strip()\n        if string_.startswith('[Local Message]'):\n            string_ = string_.replace('[Local Message]', '')\n            string_ = string_.strip().strip(',').strip().strip('.').strip()\n        splitted_string = [string_]\n        # --------------------------------------\n        splitted_string = advanced_split(splitted_string, spliter=\"，\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"。\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"）\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"（\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"(\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\")\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"<\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\">\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"[\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"]\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"【\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"】\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"？\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"：\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\":\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\",\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"#\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"\\n\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\";\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"`\", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"   \", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"- \", include_spliter=False)\n        splitted_string = advanced_split(splitted_string, spliter=\"---\", include_spliter=False)\n\n        # --------------------------------------\n        for j, s in enumerate(splitted_string): # .com\n            if '.com' in s: continue\n            if '\\'' in s: continue\n            if '\\\"' in s: continue\n            strings.append([s,0])\n\n\n    def get_strings(node):\n        strings = []\n        # recursively traverse the AST\n        for child in ast.iter_child_nodes(node):\n            node = child\n            if isinstance(child, ast.Str):\n                if contains_chinese(child.s):\n                    load_string(strings=strings, string_input=child.s)\n            elif isinstance(child, ast.AST):\n                strings.extend(get_strings(child))\n        return strings\n\n    string_literals = []\n    directory_path = f'./multi-language/{LANG}/'\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                syntax = []\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    # comments\n                    comments_arr = []\n                    for code_sp in content.splitlines():\n                        comments = re.findall(r'#.*$', code_sp)\n                        for comment in comments:\n                            load_string(strings=comments_arr, string_input=comment)\n                    string_literals.extend(comments_arr)\n\n                    # strings\n                    import ast\n                    tree = ast.parse(content)\n                    res = get_strings(tree, )\n                    string_literals.extend(res)\n\n    [print(s) for s in string_literals]\n    chinese_literal_names = []\n    chinese_literal_names_norepeat = []\n    for string, offset in string_literals:\n        chinese_literal_names.append(string)\n    chinese_literal_names_norepeat = []\n    for d in chinese_literal_names:\n        if d not in chinese_literal_names_norepeat: chinese_literal_names_norepeat.append(d)\n    need_translate = []\n    cached_translation = read_map_from_json(language=LANG)\n    cached_translation_keys = list(cached_translation.keys())\n    for d in chinese_literal_names_norepeat:\n        if d not in cached_translation_keys:\n            need_translate.append(d)\n\n    if CACHE_ONLY:\n        up = {}\n    else:\n        up = trans_json(need_translate, language=LANG, special=False)\n    map_to_json(up, language=LANG)\n    cached_translation = read_map_from_json(language=LANG)\n    LANG_STD = 'std'\n    cached_translation.update(read_map_from_json(language=LANG_STD))\n    cached_translation = dict(sorted(cached_translation.items(), key=lambda x: -len(x[0])))\n\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    # literal key replace\n    # =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n    directory_path = f'./multi-language/{LANG}/'\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                syntax = []\n                # read again\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n\n                for k, v in cached_translation.items():\n                    if v is None: continue\n                    if '\"' in v:\n                        v = v.replace('\"', \"`\")\n                    if '\\'' in v:\n                        v = v.replace('\\'', \"`\")\n                    content = content.replace(k, v)\n\n                with open(file_path, 'w', encoding='utf-8') as f:\n                    f.write(content)\n\n                if file.strip('.py') in cached_translation:\n                    file_new = cached_translation[file.strip('.py')] + '.py'\n                    file_path_new = os.path.join(root, file_new)\n                    with open(file_path_new, 'w', encoding='utf-8') as f:\n                        f.write(content)\n                    os.remove(file_path)\nstep_1_core_key_translate()\nstep_2_core_key_translate()\nprint('Finished, checkout generated results at ./multi-language/')"
        },
        {
          "name": "request_llms",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.78,
          "content": "https://public.agent-matrix.com/publish/gradio-3.32.12-py3-none-any.whl\nfastapi==0.110\ngradio-client==0.8\npypdf2==2.12.1\nhttpx<=0.25.2\nzhipuai==2.0.1\ntiktoken>=0.3.3\nrequests[socks]\npydantic==2.9.2\nprotobuf==3.20\ntransformers>=4.27.1,<4.42\nscipdf_parser>=0.52\nspacy==3.7.4\nanthropic>=0.18.1\npython-markdown-math\npymdown-extensions>=10.14\nwebsocket-client\nbeautifulsoup4\nprompt_toolkit\nlatex2mathml\npython-docx\nmdtex2html\ndashscope\npyautogen\ncolorama\nMarkdown\npygments\nedge-tts>=7.0.0\npymupdf\nopenai\nrjsmin\nloguru\narxiv\nnumpy\nrich\n\n\nllama-index-core==0.10.68\nllama-index-legacy==0.9.48\nllama-index-readers-file==0.1.33\nllama-index-readers-llama-parse==0.1.6\nllama-index-embeddings-azure-openai==0.1.10\nllama-index-embeddings-openai==0.1.10\nllama-parse==0.4.9\nmdit-py-plugins>=0.3.3\nlinkify-it-py==2.0.3"
        },
        {
          "name": "shared_utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "themes",
          "type": "tree",
          "content": null
        },
        {
          "name": "toolbox.py",
          "type": "blob",
          "size": 39.46,
          "content": "\nimport importlib\nimport time\nimport inspect\nimport re\nimport os\nimport base64\nimport gradio\nimport shutil\nimport glob\nimport json\nimport uuid\nfrom loguru import logger\nfrom functools import wraps\nfrom textwrap import dedent\nfrom shared_utils.config_loader import get_conf\nfrom shared_utils.config_loader import set_conf\nfrom shared_utils.config_loader import set_multi_conf\nfrom shared_utils.config_loader import read_single_conf_with_lru_cache\nfrom shared_utils.advanced_markdown_format import format_io\nfrom shared_utils.advanced_markdown_format import markdown_convertion\nfrom shared_utils.key_pattern_manager import select_api_key\nfrom shared_utils.key_pattern_manager import is_any_api_key\nfrom shared_utils.key_pattern_manager import what_keys\nfrom shared_utils.connect_void_terminal import get_chat_handle\nfrom shared_utils.connect_void_terminal import get_plugin_handle\nfrom shared_utils.connect_void_terminal import get_plugin_default_kwargs\nfrom shared_utils.connect_void_terminal import get_chat_default_kwargs\nfrom shared_utils.text_mask import apply_gpt_academic_string_mask\nfrom shared_utils.text_mask import build_gpt_academic_masked_string\nfrom shared_utils.text_mask import apply_gpt_academic_string_mask_langbased\nfrom shared_utils.text_mask import build_gpt_academic_masked_string_langbased\nfrom shared_utils.map_names import map_friendly_names_to_model\nfrom shared_utils.map_names import map_model_to_friendly_names\nfrom shared_utils.map_names import read_one_api_model_name\nfrom shared_utils.handle_upload import html_local_file\nfrom shared_utils.handle_upload import html_local_img\nfrom shared_utils.handle_upload import file_manifest_filter_type\nfrom shared_utils.handle_upload import extract_archive\nfrom typing import List\npj = os.path.join\ndefault_user_name = \"default_user\"\n\n\"\"\"\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n第一部分\n函数插件输入输出接驳区\n    - ChatBotWithCookies:   带Cookies的Chatbot类，为实现更多强大的功能做基础\n    - ArgsGeneralWrapper:   装饰器函数，用于重组输入参数，改变输入参数的顺序与结构\n    - update_ui:            刷新界面用 yield from update_ui(chatbot, history)\n    - CatchException:       将插件中出的所有问题显示在界面上\n    - HotReload:            实现插件的热更新\n    - trimmed_format_exc:   打印traceback，为了安全而隐藏绝对地址\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n\"\"\"\n\n\nclass ChatBotWithCookies(list):\n    def __init__(self, cookie):\n        \"\"\"\n        cookies = {\n            'top_p': top_p,\n            'temperature': temperature,\n            'lock_plugin': bool,\n            \"files_to_promote\": [\"file1\", \"file2\"],\n            \"most_recent_uploaded\": {\n                \"path\": \"uploaded_path\",\n                \"time\": time.time(),\n                \"time_str\": \"timestr\",\n            }\n        }\n        \"\"\"\n        self._cookies = cookie\n\n    def write_list(self, list):\n        for t in list:\n            self.append(t)\n\n    def get_list(self):\n        return [t for t in self]\n\n    def get_cookies(self):\n        return self._cookies\n\n    def get_user(self):\n        return self._cookies.get(\"user_name\", default_user_name)\n\ndef ArgsGeneralWrapper(f):\n    \"\"\"\n    装饰器函数ArgsGeneralWrapper，用于重组输入参数，改变输入参数的顺序与结构。\n    该装饰器是大多数功能调用的入口。\n    函数示意图：https://mermaid.live/edit#pako:eNqNVFtPGkEY_StkntoEDQtLoTw0sWqapjQxVWPabmOm7AiEZZcsQ9QiiW012qixqdeqqIn10geBh6ZR8PJnmAWe-hc6l3VhrWnLEzNzzvnO953ZyYOYoSIQAWOaMR5LQBN7hvoU3UN_g5iu7imAXEyT4wUF3Pd0dT3y9KGYYUJsmK8V0GPGs0-QjkyojZgwk0Fm82C2dVghX08U8EaoOHjOfoEMU0XmADRhOksVWnNLjdpM82qFzB6S5Q_WWsUhuqCc3JtAsVR_OoMnhyZwXgHWwbS1d4gnsLVZJp-P6mfVxveqAgqC70Jz_pQCOGDKM5xFdNNPDdilF6uSU_hOYqu4a3MHYDZLDzq5fodrC3PWcEaFGPUaRiqJWK_W9g9rvRITa4dhy_0nw67SiePMp3oSR6PPn41DGgllkvkizYwsrmtaejTFd8V4yekGmT1zqrt4XGlAy8WTuiPULF01LksZvukSajfQQRAxmYi5S0D81sDcyzapVdn6sYFHkjhhGyel3frVQnvsnbR23lEjlhIlaOJiFPWzU5G4tfNJo8ejwp47-TbvJkKKZvmxA6SKo16oaazJysfG6klr9T0pbTW2ZqzlL_XaT8fYbQLXe4mSmvoCZXMaa7FePW6s7jVqK9bujvse3WFjY5_Z4KfsA4oiPY4T7Drvn1tLJTbG1to1qR79ulgk89-oJbvZzbIwJty6u20LOReWa9BvwserUd9s9MIKc3x5TUWEoAhUyJK5y85w_yG-dFu_R9waoU7K581y8W_qLle35-rG9Nxcrz8QHRsc0K-r9NViYRT36KsFvCCNzDRMqvSVyzOKAnACpZECIvSvCs2UAhS9QHEwh43BST0GItjMIS_I8e-sLwnj9A262cxA_ZVh0OUY1LJiDSJ5MAEiUijYLUtBORR6KElyQPaCSRDpksNSd8AfluSgHPaFC17wjrOlbgbzyyFf4IFPDvoD_sJvnkdK-g\n    \"\"\"\n    def decorated(request: gradio.Request, cookies:dict, max_length:int, llm_model:str,\n                  txt:str, txt2:str, top_p:float, temperature:float, chatbot:list,\n                  json_history:str, system_prompt:str, plugin_advanced_arg:dict, *args):\n        txt_passon = txt\n        history = json.loads(json_history) if json_history else []\n        if txt == \"\" and txt2 != \"\": txt_passon = txt2\n        # 引入一个有cookie的chatbot\n        if request.username is not None:\n            user_name = request.username\n        else:\n            user_name = default_user_name\n        embed_model = get_conf(\"EMBEDDING_MODEL\")\n        cookies.update({\n            'top_p': top_p,\n            'api_key': cookies['api_key'],\n            'llm_model': llm_model,\n            'embed_model': embed_model,\n            'temperature': temperature,\n            'user_name': user_name,\n        })\n        llm_kwargs = {\n            'api_key': cookies['api_key'],\n            'llm_model': llm_model,\n            'embed_model': embed_model,\n            'top_p': top_p,\n            'max_length': max_length,\n            'temperature': temperature,\n            'client_ip': request.client.host,\n            'most_recent_uploaded': cookies.get('most_recent_uploaded')\n        }\n        if isinstance(plugin_advanced_arg, str):\n            plugin_kwargs = {\"advanced_arg\": plugin_advanced_arg}\n        else:\n            plugin_kwargs = plugin_advanced_arg\n        chatbot_with_cookie = ChatBotWithCookies(cookies)\n        chatbot_with_cookie.write_list(chatbot)\n\n        if cookies.get('lock_plugin', None) is None:\n            # 正常状态\n            if len(args) == 0:  # 插件通道\n                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)\n            else:               # 对话通道，或者基础功能通道\n                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, *args)\n        else:\n            # 处理少数情况下的特殊插件的锁定状态\n            module, fn_name = cookies['lock_plugin'].split('->')\n            f_hot_reload = getattr(importlib.import_module(module, fn_name), fn_name)\n            yield from f_hot_reload(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)\n            # 判断一下用户是否错误地通过对话通道进入，如果是，则进行提醒\n            final_cookies = chatbot_with_cookie.get_cookies()\n            # len(args) != 0 代表“提交”键对话通道，或者基础功能通道\n            if len(args) != 0 and 'files_to_promote' in final_cookies and len(final_cookies['files_to_promote']) > 0:\n                chatbot_with_cookie.append(\n                    [\"检测到**滞留的缓存文档**，请及时处理。\", \"请及时点击“**保存当前对话**”获取所有滞留文档。\"])\n                yield from update_ui(chatbot_with_cookie, final_cookies['history'], msg=\"检测到被滞留的缓存文档\")\n\n    return decorated\n\n\ndef update_ui(chatbot:ChatBotWithCookies, history:list, msg:str=\"正常\", **kwargs):  # 刷新界面\n    \"\"\"\n    刷新用户界面\n    \"\"\"\n    assert isinstance(history, list), \"history必须是一个list\"\n    assert isinstance(\n        chatbot, ChatBotWithCookies\n    ), \"在传递chatbot的过程中不要将其丢弃。必要时, 可用clear将其清空, 然后用for+append循环重新赋值。\"\n    cookies = chatbot.get_cookies()\n    # 备份一份History作为记录\n    cookies.update({\"history\": history})\n    # 解决插件锁定时的界面显示问题\n    if cookies.get(\"lock_plugin\", None):\n        label = (\n            cookies.get(\"llm_model\", \"\")\n            + \" | \"\n            + \"正在锁定插件\"\n            + cookies.get(\"lock_plugin\", None)\n        )\n        chatbot_gr = gradio.update(value=chatbot, label=label)\n        if cookies.get(\"label\", \"\") != label:\n            cookies[\"label\"] = label  # 记住当前的label\n    elif cookies.get(\"label\", None):\n        chatbot_gr = gradio.update(value=chatbot, label=cookies.get(\"llm_model\", \"\"))\n        cookies[\"label\"] = None  # 清空label\n    else:\n        chatbot_gr = chatbot\n\n    history = [str(history_item) for history_item in history] # ensure all items are string\n    json_history = json.dumps(history, ensure_ascii=False)\n    yield cookies, chatbot_gr, json_history, msg\n\n\ndef update_ui_lastest_msg(lastmsg:str, chatbot:ChatBotWithCookies, history:list, delay:float=1, msg:str=\"正常\"):  # 刷新界面\n    \"\"\"\n    刷新用户界面\n    \"\"\"\n    if len(chatbot) == 0:\n        chatbot.append([\"update_ui_last_msg\", lastmsg])\n    chatbot[-1] = list(chatbot[-1])\n    chatbot[-1][-1] = lastmsg\n    yield from update_ui(chatbot=chatbot, history=history, msg=msg)\n    time.sleep(delay)\n\n\ndef trimmed_format_exc():\n    import os, traceback\n\n    str = traceback.format_exc()\n    current_path = os.getcwd()\n    replace_path = \".\"\n    return str.replace(current_path, replace_path)\n\n\ndef trimmed_format_exc_markdown():\n    return '\\n\\n```\\n' + trimmed_format_exc() + '```'\n\n\nclass FriendlyException(Exception):\n    def generate_error_html(self):\n        return dedent(f\"\"\"\n            <div class=\"center-div\" style=\"color: crimson;text-align: center;\">\n                {\"<br>\".join(self.args)}\n            </div>\n        \"\"\")\n\n\ndef CatchException(f):\n    \"\"\"\n    装饰器函数，捕捉函数f中的异常并封装到一个生成器中返回，并显示到聊天当中。\n    \"\"\"\n\n    @wraps(f)\n    def decorated(main_input:str, llm_kwargs:dict, plugin_kwargs:dict,\n                  chatbot_with_cookie:ChatBotWithCookies, history:list, *args, **kwargs):\n        try:\n            yield from f(main_input, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, *args, **kwargs)\n        except FriendlyException as e:\n            tb_str = '```\\n' + trimmed_format_exc() + '```'\n            if len(chatbot_with_cookie) == 0:\n                chatbot_with_cookie.clear()\n                chatbot_with_cookie.append([\"插件调度异常:\\n\" + tb_str, None])\n            chatbot_with_cookie[-1] = [chatbot_with_cookie[-1][0], e.generate_error_html()]\n            yield from update_ui(chatbot=chatbot_with_cookie, history=history, msg=f'异常')  # 刷新界面\n        except Exception as e:\n            tb_str = '```\\n' + trimmed_format_exc() + '```'\n            if len(chatbot_with_cookie) == 0:\n                chatbot_with_cookie.clear()\n                chatbot_with_cookie.append([\"插件调度异常\", \"异常原因\"])\n            chatbot_with_cookie[-1] = [chatbot_with_cookie[-1][0], f\"[Local Message] 插件调用出错: \\n\\n{tb_str} \\n\"]\n            yield from update_ui(chatbot=chatbot_with_cookie, history=history, msg=f'异常 {e}')  # 刷新界面\n\n    return decorated\n\n\ndef HotReload(f):\n    \"\"\"\n    HotReload的装饰器函数，用于实现Python函数插件的热更新。\n    函数热更新是指在不停止程序运行的情况下，更新函数代码，从而达到实时更新功能。\n    在装饰器内部，使用wraps(f)来保留函数的元信息，并定义了一个名为decorated的内部函数。\n    内部函数通过使用importlib模块的reload函数和inspect模块的getmodule函数来重新加载并获取函数模块，\n    然后通过getattr函数获取函数名，并在新模块中重新加载函数。\n    最后，使用yield from语句返回重新加载过的函数，并在被装饰的函数上执行。\n    最终，装饰器函数返回内部函数。这个内部函数可以将函数的原始定义更新为最新版本，并执行函数的新版本。\n    \"\"\"\n    if get_conf(\"PLUGIN_HOT_RELOAD\"):\n\n        @wraps(f)\n        def decorated(*args, **kwargs):\n            fn_name = f.__name__\n            f_hot_reload = getattr(importlib.reload(inspect.getmodule(f)), fn_name)\n            yield from f_hot_reload(*args, **kwargs)\n\n        return decorated\n    else:\n        return f\n\n\n\"\"\"\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n第二部分\n其他小工具:\n    - write_history_to_file:    将结果写入markdown文件中\n    - regular_txt_to_markdown:  将普通文本转换为Markdown格式的文本。\n    - report_exception:         向chatbot中添加简单的意外错误信息\n    - text_divide_paragraph:    将文本按照段落分隔符分割开，生成带有段落标签的HTML代码。\n    - markdown_convertion:      用多种方式组合，将markdown转化为好看的html\n    - format_io:                接管gradio默认的markdown处理方式\n    - on_file_uploaded:         处理文件的上传（自动解压）\n    - on_report_generated:      将生成的报告自动投射到文件上传区\n    - clip_history:             当历史上下文过长时，自动截断\n    - get_conf:                 获取设置\n    - select_api_key:           根据当前的模型类别，抽取可用的api-key\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n\"\"\"\n\n\ndef get_reduce_token_percent(text:str):\n    \"\"\"\n    * 此函数未来将被弃用\n    \"\"\"\n    try:\n        # text = \"maximum context length is 4097 tokens. However, your messages resulted in 4870 tokens\"\n        pattern = r\"(\\d+)\\s+tokens\\b\"\n        match = re.findall(pattern, text)\n        EXCEED_ALLO = 500  # 稍微留一点余地，否则在回复时会因余量太少出问题\n        max_limit = float(match[0]) - EXCEED_ALLO\n        current_tokens = float(match[1])\n        ratio = max_limit / current_tokens\n        assert ratio > 0 and ratio < 1\n        return ratio, str(int(current_tokens - max_limit))\n    except:\n        return 0.5, \"不详\"\n\n\ndef write_history_to_file(\n    history:list, file_basename:str=None, file_fullname:str=None, auto_caption:bool=True\n):\n    \"\"\"\n    将对话记录history以Markdown格式写入文件中。如果没有指定文件名，则使用当前时间生成文件名。\n    \"\"\"\n    import os\n    import time\n\n    if file_fullname is None:\n        if file_basename is not None:\n            file_fullname = pj(get_log_folder(), file_basename)\n        else:\n            file_fullname = pj(get_log_folder(), f\"GPT-Academic-{gen_time_str()}.md\")\n    os.makedirs(os.path.dirname(file_fullname), exist_ok=True)\n    with open(file_fullname, \"w\", encoding=\"utf8\") as f:\n        f.write(\"# GPT-Academic Report\\n\")\n        for i, content in enumerate(history):\n            try:\n                if type(content) != str:\n                    content = str(content)\n            except:\n                continue\n            if i % 2 == 0 and auto_caption:\n                f.write(\"## \")\n            try:\n                f.write(content)\n            except:\n                # remove everything that cannot be handled by utf8\n                f.write(content.encode(\"utf-8\", \"ignore\").decode())\n            f.write(\"\\n\\n\")\n    res = os.path.abspath(file_fullname)\n    return res\n\n\ndef regular_txt_to_markdown(text:str):\n    \"\"\"\n    将普通文本转换为Markdown格式的文本。\n    \"\"\"\n    text = text.replace(\"\\n\", \"\\n\\n\")\n    text = text.replace(\"\\n\\n\\n\", \"\\n\\n\")\n    text = text.replace(\"\\n\\n\\n\", \"\\n\\n\")\n    return text\n\n\ndef report_exception(chatbot:ChatBotWithCookies, history:list, a:str, b:str):\n    \"\"\"\n    向chatbot中添加错误信息\n    \"\"\"\n    chatbot.append((a, b))\n    history.extend([a, b])\n\n\ndef find_free_port()->int:\n    \"\"\"\n    返回当前系统中可用的未使用端口。\n    \"\"\"\n    import socket\n    from contextlib import closing\n\n    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n        s.bind((\"\", 0))\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        return s.getsockname()[1]\n\n\ndef find_recent_files(directory:str)->List[str]:\n    \"\"\"\n    Find files that is created with in one minutes under a directory with python, write a function\n    \"\"\"\n    import os\n    import time\n\n    current_time = time.time()\n    one_minute_ago = current_time - 60\n    recent_files = []\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n    for filename in os.listdir(directory):\n        file_path = pj(directory, filename)\n        if file_path.endswith(\".log\"):\n            continue\n        created_time = os.path.getmtime(file_path)\n        if created_time >= one_minute_ago:\n            if os.path.isdir(file_path):\n                continue\n            recent_files.append(file_path)\n\n    return recent_files\n\n\ndef file_already_in_downloadzone(file:str, user_path:str):\n    try:\n        parent_path = os.path.abspath(user_path)\n        child_path = os.path.abspath(file)\n        if os.path.samefile(os.path.commonpath([parent_path, child_path]), parent_path):\n            return True\n        else:\n            return False\n    except:\n        return False\n\n\ndef promote_file_to_downloadzone(file:str, rename_file:str=None, chatbot:ChatBotWithCookies=None):\n    # 将文件复制一份到下载区\n    import shutil\n\n    if chatbot is not None:\n        user_name = get_user(chatbot)\n    else:\n        user_name = default_user_name\n    if not os.path.exists(file):\n        raise FileNotFoundError(f\"文件{file}不存在\")\n    user_path = get_log_folder(user_name, plugin_name=None)\n    if file_already_in_downloadzone(file, user_path):\n        new_path = file\n    else:\n        user_path = get_log_folder(user_name, plugin_name=\"downloadzone\")\n        if rename_file is None:\n            rename_file = f\"{gen_time_str()}-{os.path.basename(file)}\"\n        new_path = pj(user_path, rename_file)\n        # 如果已经存在，先删除\n        if os.path.exists(new_path) and not os.path.samefile(new_path, file):\n            os.remove(new_path)\n        # 把文件复制过去\n        if not os.path.exists(new_path):\n            shutil.copyfile(file, new_path)\n    # 将文件添加到chatbot cookie中\n    if chatbot is not None:\n        if \"files_to_promote\" in chatbot._cookies:\n            current = chatbot._cookies[\"files_to_promote\"]\n        else:\n            current = []\n        if new_path not in current:  # 避免把同一个文件添加多次\n            chatbot._cookies.update({\"files_to_promote\": [new_path] + current})\n    return new_path\n\n\ndef disable_auto_promotion(chatbot:ChatBotWithCookies):\n    chatbot._cookies.update({\"files_to_promote\": []})\n    return\n\n\ndef del_outdated_uploads(outdate_time_seconds:float, target_path_base:str=None):\n    if target_path_base is None:\n        user_upload_dir = get_conf(\"PATH_PRIVATE_UPLOAD\")\n    else:\n        user_upload_dir = target_path_base\n    current_time = time.time()\n    one_hour_ago = current_time - outdate_time_seconds\n    # Get a list of all subdirectories in the user_upload_dir folder\n    # Remove subdirectories that are older than one hour\n    for subdirectory in glob.glob(f\"{user_upload_dir}/*\"):\n        subdirectory_time = os.path.getmtime(subdirectory)\n        if subdirectory_time < one_hour_ago:\n            try:\n                shutil.rmtree(subdirectory)\n            except:\n                pass\n    return\n\n\n\ndef to_markdown_tabs(head: list, tabs: list, alignment=\":---:\", column=False, omit_path=None):\n    \"\"\"\n    Args:\n        head: 表头：[]\n        tabs: 表值：[[列1], [列2], [列3], [列4]]\n        alignment: :--- 左对齐， :---: 居中对齐， ---: 右对齐\n        column: True to keep data in columns, False to keep data in rows (default).\n    Returns:\n        A string representation of the markdown table.\n    \"\"\"\n    if column:\n        transposed_tabs = list(map(list, zip(*tabs)))\n    else:\n        transposed_tabs = tabs\n    # Find the maximum length among the columns\n    max_len = max(len(column) for column in transposed_tabs)\n\n    tab_format = \"| %s \"\n    tabs_list = \"\".join([tab_format % i for i in head]) + \"|\\n\"\n    tabs_list += \"\".join([tab_format % alignment for i in head]) + \"|\\n\"\n\n    for i in range(max_len):\n        row_data = [tab[i] if i < len(tab) else \"\" for tab in transposed_tabs]\n        row_data = file_manifest_filter_type(row_data, filter_=None)\n        # for dat in row_data:\n        #     if (omit_path is not None) and os.path.exists(dat):\n        #         dat = os.path.relpath(dat, omit_path)\n        tabs_list += \"\".join([tab_format % i for i in row_data]) + \"|\\n\"\n\n    return tabs_list\n\n\ndef on_file_uploaded(\n    request: gradio.Request, files:List[str], chatbot:ChatBotWithCookies,\n    txt:str, txt2:str, checkboxes:List[str], cookies:dict\n):\n    \"\"\"\n    当文件被上传时的回调函数\n    \"\"\"\n    if len(files) == 0:\n        return chatbot, txt\n\n    # 创建工作路径\n    user_name = default_user_name if not request.username else request.username\n    time_tag = gen_time_str()\n    target_path_base = get_upload_folder(user_name, tag=time_tag)\n    os.makedirs(target_path_base, exist_ok=True)\n\n    # 移除过时的旧文件从而节省空间&保护隐私\n    outdate_time_seconds = 3600  # 一小时\n    del_outdated_uploads(outdate_time_seconds, get_upload_folder(user_name))\n\n    # 逐个文件转移到目标路径\n    upload_msg = \"\"\n    for file in files:\n        file_origin_name = os.path.basename(file.orig_name)\n        this_file_path = pj(target_path_base, file_origin_name)\n        shutil.move(file.name, this_file_path)\n        upload_msg += extract_archive(\n            file_path=this_file_path, dest_dir=this_file_path + \".extract\"\n        )\n\n    # 整理文件集合 输出消息\n    files = glob.glob(f\"{target_path_base}/**/*\", recursive=True)\n    moved_files = [fp for fp in files]\n    max_file_to_show = 10\n    if len(moved_files) > max_file_to_show:\n        moved_files = moved_files[:max_file_to_show//2] + [f'... ( 📌省略{len(moved_files) - max_file_to_show}个文件的显示 ) ...'] + \\\n                      moved_files[-max_file_to_show//2:]\n    moved_files_str = to_markdown_tabs(head=[\"文件\"], tabs=[moved_files], omit_path=target_path_base)\n    chatbot.append(\n        [\n            \"我上传了文件，请查收\",\n            f\"[Local Message] 收到以下文件 （上传到路径：{target_path_base}）: \" +\n            f\"\\n\\n{moved_files_str}\" +\n            f\"\\n\\n调用路径参数已自动修正到: \\n\\n{txt}\" +\n            f\"\\n\\n现在您点击任意函数插件时，以上文件将被作为输入参数\" +\n            upload_msg,\n        ]\n    )\n\n    txt, txt2 = target_path_base, \"\"\n    if \"浮动输入区\" in checkboxes:\n        txt, txt2 = txt2, txt\n\n    # 记录近期文件\n    cookies.update(\n        {\n            \"most_recent_uploaded\": {\n                \"path\": target_path_base,\n                \"time\": time.time(),\n                \"time_str\": time_tag,\n            }\n        }\n    )\n    return chatbot, txt, txt2, cookies\n\n\ndef generate_file_link(report_files:List[str]):\n    file_links = \"\"\n    for f in report_files:\n        file_links += (\n            f'<br/><a href=\"file={os.path.abspath(f)}\" target=\"_blank\">{f}</a>'\n        )\n    return file_links\n\n\ndef on_report_generated(cookies:dict, files:List[str], chatbot:ChatBotWithCookies):\n    if \"files_to_promote\" in cookies:\n        report_files = cookies[\"files_to_promote\"]\n        cookies.pop(\"files_to_promote\")\n    else:\n        report_files = []\n    if len(report_files) == 0:\n        return cookies, None, chatbot\n    file_links = \"\"\n    for f in report_files:\n        file_links += (\n            f'<br/><a href=\"file={os.path.abspath(f)}\" target=\"_blank\">{f}</a>'\n        )\n    chatbot.append([\"报告如何远程获取？\", f\"报告已经添加到右侧“文件下载区”（可能处于折叠状态），请查收。{file_links}\"])\n    return cookies, report_files, chatbot\n\n\ndef load_chat_cookies():\n    API_KEY, LLM_MODEL, AZURE_API_KEY = get_conf(\n        \"API_KEY\", \"LLM_MODEL\", \"AZURE_API_KEY\"\n    )\n    AZURE_CFG_ARRAY, NUM_CUSTOM_BASIC_BTN = get_conf(\n        \"AZURE_CFG_ARRAY\", \"NUM_CUSTOM_BASIC_BTN\"\n    )\n\n    # deal with azure openai key\n    if is_any_api_key(AZURE_API_KEY):\n        if is_any_api_key(API_KEY):\n            API_KEY = API_KEY + \",\" + AZURE_API_KEY\n        else:\n            API_KEY = AZURE_API_KEY\n    if len(AZURE_CFG_ARRAY) > 0:\n        for azure_model_name, azure_cfg_dict in AZURE_CFG_ARRAY.items():\n            if not azure_model_name.startswith(\"azure\"):\n                raise ValueError(\"AZURE_CFG_ARRAY中配置的模型必须以azure开头\")\n            AZURE_API_KEY_ = azure_cfg_dict[\"AZURE_API_KEY\"]\n            if is_any_api_key(AZURE_API_KEY_):\n                if is_any_api_key(API_KEY):\n                    API_KEY = API_KEY + \",\" + AZURE_API_KEY_\n                else:\n                    API_KEY = AZURE_API_KEY_\n\n    customize_fn_overwrite_ = {}\n    for k in range(NUM_CUSTOM_BASIC_BTN):\n        customize_fn_overwrite_.update(\n            {\n                \"自定义按钮\"\n                + str(k + 1): {\n                    \"Title\": r\"\",\n                    \"Prefix\": r\"请在自定义菜单中定义提示词前缀.\",\n                    \"Suffix\": r\"请在自定义菜单中定义提示词后缀\",\n                }\n            }\n        )\n\n    EMBEDDING_MODEL = get_conf(\"EMBEDDING_MODEL\")\n    return {\n        \"api_key\": API_KEY,\n        \"llm_model\": LLM_MODEL,\n        \"embed_model\": EMBEDDING_MODEL,\n        \"customize_fn_overwrite\": customize_fn_overwrite_,\n    }\n\n\ndef clear_line_break(txt):\n    txt = txt.replace(\"\\n\", \" \")\n    txt = txt.replace(\"  \", \" \")\n    txt = txt.replace(\"  \", \" \")\n    return txt\n\n\nclass DummyWith:\n    \"\"\"\n    这段代码定义了一个名为DummyWith的空上下文管理器，\n    它的作用是……额……就是不起作用，即在代码结构不变得情况下取代其他的上下文管理器。\n    上下文管理器是一种Python对象，用于与with语句一起使用，\n    以确保一些资源在代码块执行期间得到正确的初始化和清理。\n    上下文管理器必须实现两个方法，分别为 __enter__()和 __exit__()。\n    在上下文执行开始的情况下，__enter__()方法会在代码块被执行前被调用，\n    而在上下文执行结束时，__exit__()方法则会被调用。\n    \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        return\n\n\ndef run_gradio_in_subpath(demo, auth, port, custom_path):\n    \"\"\"\n    把gradio的运行地址更改到指定的二次路径上\n    \"\"\"\n\n    def is_path_legal(path: str) -> bool:\n        \"\"\"\n        check path for sub url\n        path: path to check\n        return value: do sub url wrap\n        \"\"\"\n        if path == \"/\":\n            return True\n        if len(path) == 0:\n            logger.info(\n                \"ilegal custom path: {}\\npath must not be empty\\ndeploy on root url\".format(\n                    path\n                )\n            )\n            return False\n        if path[0] == \"/\":\n            if path[1] != \"/\":\n                logger.info(\"deploy on sub-path {}\".format(path))\n                return True\n            return False\n        logger.info(\n            \"ilegal custom path: {}\\npath should begin with '/'\\ndeploy on root url\".format(\n                path\n            )\n        )\n        return False\n\n    if not is_path_legal(custom_path):\n        raise RuntimeError(\"Ilegal custom path\")\n    import uvicorn\n    import gradio as gr\n    from fastapi import FastAPI\n\n    app = FastAPI()\n    if custom_path != \"/\":\n\n        @app.get(\"/\")\n        def read_main():\n            return {\"message\": f\"Gradio is running at: {custom_path}\"}\n\n    app = gr.mount_gradio_app(app, demo, path=custom_path)\n    uvicorn.run(app, host=\"0.0.0.0\", port=port)  # , auth=auth\n\n\ndef clip_history(inputs, history, tokenizer, max_token_limit):\n    \"\"\"\n    reduce the length of history by clipping.\n    this function search for the longest entries to clip, little by little,\n    until the number of token of history is reduced under threshold.\n    通过裁剪来缩短历史记录的长度。\n    此函数逐渐地搜索最长的条目进行剪辑，\n    直到历史记录的标记数量降低到阈值以下。\n    \"\"\"\n    import numpy as np\n    from request_llms.bridge_all import model_info\n\n    def get_token_num(txt):\n        return len(tokenizer.encode(txt, disallowed_special=()))\n\n    input_token_num = get_token_num(inputs)\n\n    if max_token_limit < 5000:\n        output_token_expect = 256  # 4k & 2k models\n    elif max_token_limit < 9000:\n        output_token_expect = 512  # 8k models\n    else:\n        output_token_expect = 1024  # 16k & 32k models\n\n    if input_token_num < max_token_limit * 3 / 4:\n        # 当输入部分的token占比小于限制的3/4时，裁剪时\n        # 1. 把input的余量留出来\n        max_token_limit = max_token_limit - input_token_num\n        # 2. 把输出用的余量留出来\n        max_token_limit = max_token_limit - output_token_expect\n        # 3. 如果余量太小了，直接清除历史\n        if max_token_limit < output_token_expect:\n            history = []\n            return history\n    else:\n        # 当输入部分的token占比 > 限制的3/4时，直接清除历史\n        history = []\n        return history\n\n    everything = [\"\"]\n    everything.extend(history)\n    n_token = get_token_num(\"\\n\".join(everything))\n    everything_token = [get_token_num(e) for e in everything]\n\n    # 截断时的颗粒度\n    delta = max(everything_token) // 16\n\n    while n_token > max_token_limit:\n        where = np.argmax(everything_token)\n        encoded = tokenizer.encode(everything[where], disallowed_special=())\n        clipped_encoded = encoded[: len(encoded) - delta]\n        everything[where] = tokenizer.decode(clipped_encoded)[\n            :-1\n        ]  # -1 to remove the may-be illegal char\n        everything_token[where] = get_token_num(everything[where])\n        n_token = get_token_num(\"\\n\".join(everything))\n\n    history = everything[1:]\n    return history\n\n\n\"\"\"\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n第三部分\n其他小工具:\n    - zip_folder:    把某个路径下所有文件压缩，然后转移到指定的另一个路径中（gpt写的）\n    - gen_time_str:  生成时间戳\n    - ProxyNetworkActivate: 临时地启动代理网络（如果有）\n    - objdump/objload: 快捷的调试函数\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n\"\"\"\n\n\ndef zip_folder(source_folder, dest_folder, zip_name):\n    import zipfile\n    import os\n\n    # Make sure the source folder exists\n    if not os.path.exists(source_folder):\n        logger.info(f\"{source_folder} does not exist\")\n        return\n\n    # Make sure the destination folder exists\n    if not os.path.exists(dest_folder):\n        logger.info(f\"{dest_folder} does not exist\")\n        return\n\n    # Create the name for the zip file\n    zip_file = pj(dest_folder, zip_name)\n\n    # Create a ZipFile object\n    with zipfile.ZipFile(zip_file, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n        # Walk through the source folder and add files to the zip file\n        for foldername, subfolders, filenames in os.walk(source_folder):\n            for filename in filenames:\n                filepath = pj(foldername, filename)\n                zipf.write(filepath, arcname=os.path.relpath(filepath, source_folder))\n\n    # Move the zip file to the destination folder (if it wasn't already there)\n    if os.path.dirname(zip_file) != dest_folder:\n        os.rename(zip_file, pj(dest_folder, os.path.basename(zip_file)))\n        zip_file = pj(dest_folder, os.path.basename(zip_file))\n\n    logger.info(f\"Zip file created at {zip_file}\")\n\n\ndef zip_result(folder):\n    t = gen_time_str()\n    zip_folder(folder, get_log_folder(), f\"{t}-result.zip\")\n    return pj(get_log_folder(), f\"{t}-result.zip\")\n\n\ndef gen_time_str():\n    import time\n\n    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n\n\ndef get_log_folder(user=default_user_name, plugin_name=\"shared\"):\n    if user is None:\n        user = default_user_name\n    PATH_LOGGING = get_conf(\"PATH_LOGGING\")\n    if plugin_name is None:\n        _dir = pj(PATH_LOGGING, user)\n    else:\n        _dir = pj(PATH_LOGGING, user, plugin_name)\n    if not os.path.exists(_dir):\n        os.makedirs(_dir)\n    return _dir\n\n\ndef get_upload_folder(user=default_user_name, tag=None):\n    PATH_PRIVATE_UPLOAD = get_conf(\"PATH_PRIVATE_UPLOAD\")\n    if user is None:\n        user = default_user_name\n    if tag is None or len(tag) == 0:\n        target_path_base = pj(PATH_PRIVATE_UPLOAD, user)\n    else:\n        target_path_base = pj(PATH_PRIVATE_UPLOAD, user, tag)\n    return target_path_base\n\n\ndef is_the_upload_folder(string):\n    PATH_PRIVATE_UPLOAD = get_conf(\"PATH_PRIVATE_UPLOAD\")\n    pattern = r\"^PATH_PRIVATE_UPLOAD[\\\\/][A-Za-z0-9_-]+[\\\\/]\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2}$\"\n    pattern = pattern.replace(\"PATH_PRIVATE_UPLOAD\", PATH_PRIVATE_UPLOAD)\n    if re.match(pattern, string):\n        return True\n    else:\n        return False\n\n\ndef get_user(chatbotwithcookies:ChatBotWithCookies):\n    return chatbotwithcookies._cookies.get(\"user_name\", default_user_name)\n\n\nclass ProxyNetworkActivate:\n    \"\"\"\n    这段代码定义了一个名为ProxyNetworkActivate的空上下文管理器, 用于给一小段代码上代理\n    \"\"\"\n\n    def __init__(self, task=None) -> None:\n        self.task = task\n        if not task:\n            # 不给定task, 那么我们默认代理生效\n            self.valid = True\n        else:\n            # 给定了task, 我们检查一下\n            from toolbox import get_conf\n\n            WHEN_TO_USE_PROXY = get_conf(\"WHEN_TO_USE_PROXY\")\n            self.valid = task in WHEN_TO_USE_PROXY\n\n    def __enter__(self):\n        if not self.valid:\n            return self\n        from toolbox import get_conf\n\n        proxies = get_conf(\"proxies\")\n        if \"no_proxy\" in os.environ:\n            os.environ.pop(\"no_proxy\")\n        if proxies is not None:\n            if \"http\" in proxies:\n                os.environ[\"HTTP_PROXY\"] = proxies[\"http\"]\n            if \"https\" in proxies:\n                os.environ[\"HTTPS_PROXY\"] = proxies[\"https\"]\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        os.environ[\"no_proxy\"] = \"*\"\n        if \"HTTP_PROXY\" in os.environ:\n            os.environ.pop(\"HTTP_PROXY\")\n        if \"HTTPS_PROXY\" in os.environ:\n            os.environ.pop(\"HTTPS_PROXY\")\n        return\n\n\ndef Singleton(cls):\n    \"\"\"\n    一个单实例装饰器\n    \"\"\"\n    _instance = {}\n\n    def _singleton(*args, **kargs):\n        if cls not in _instance:\n            _instance[cls] = cls(*args, **kargs)\n        return _instance[cls]\n\n    return _singleton\n\n\ndef get_pictures_list(path):\n    file_manifest = [f for f in glob.glob(f\"{path}/**/*.jpg\", recursive=True)]\n    file_manifest += [f for f in glob.glob(f\"{path}/**/*.jpeg\", recursive=True)]\n    file_manifest += [f for f in glob.glob(f\"{path}/**/*.png\", recursive=True)]\n    return file_manifest\n\n\ndef have_any_recent_upload_image_files(chatbot:ChatBotWithCookies, pop:bool=False):\n    _5min = 5 * 60\n    if chatbot is None:\n        return False, None  # chatbot is None\n    if pop:\n        most_recent_uploaded = chatbot._cookies.pop(\"most_recent_uploaded\", None)\n    else:\n        most_recent_uploaded = chatbot._cookies.get(\"most_recent_uploaded\", None)\n    # most_recent_uploaded 是一个放置最新上传图像的路径\n    if not most_recent_uploaded:\n        return False, None  # most_recent_uploaded is None\n    if time.time() - most_recent_uploaded[\"time\"] < _5min:\n        path = most_recent_uploaded[\"path\"]\n        file_manifest = get_pictures_list(path)\n        if len(file_manifest) == 0:\n            return False, None\n        return True, file_manifest  # most_recent_uploaded is new\n    else:\n        return False, None  # most_recent_uploaded is too old\n\n# Claude3 model supports graphic context dialogue, reads all images\ndef every_image_file_in_path(chatbot:ChatBotWithCookies):\n    if chatbot is None:\n        return False, []  # chatbot is None\n    most_recent_uploaded = chatbot._cookies.get(\"most_recent_uploaded\", None)\n    if not most_recent_uploaded:\n        return False, []  # most_recent_uploaded is None\n    path = most_recent_uploaded[\"path\"]\n    file_manifest = get_pictures_list(path)\n    if len(file_manifest) == 0:\n        return False, []\n    return True, file_manifest\n\n# Function to encode the image\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n\ndef get_max_token(llm_kwargs):\n    from request_llms.bridge_all import model_info\n\n    return model_info[llm_kwargs[\"llm_model\"]][\"max_token\"]\n\n\ndef check_packages(packages=[]):\n    import importlib.util\n\n    for p in packages:\n        spam_spec = importlib.util.find_spec(p)\n        if spam_spec is None:\n            raise ModuleNotFoundError\n\n\ndef map_file_to_sha256(file_path):\n    import hashlib\n\n    with open(file_path, 'rb') as file:\n        content = file.read()\n\n    # Calculate the SHA-256 hash of the file contents\n    sha_hash = hashlib.sha256(content).hexdigest()\n\n    return sha_hash\n\n\ndef check_repeat_upload(new_pdf_path, pdf_hash):\n    '''\n    检查历史上传的文件是否与新上传的文件相同，如果相同则返回(True, 重复文件路径)，否则返回(False，None)\n    '''\n    from toolbox import get_conf\n    import PyPDF2\n\n    user_upload_dir = os.path.dirname(os.path.dirname(new_pdf_path))\n    file_name = os.path.basename(new_pdf_path)\n\n    file_manifest = [f for f in glob.glob(f'{user_upload_dir}/**/{file_name}', recursive=True)]\n\n    for saved_file in file_manifest:\n        with open(new_pdf_path, 'rb') as file1, open(saved_file, 'rb') as file2:\n            reader1 = PyPDF2.PdfFileReader(file1)\n            reader2 = PyPDF2.PdfFileReader(file2)\n\n            # 比较页数是否相同\n            if reader1.getNumPages() != reader2.getNumPages():\n                continue\n\n            # 比较每一页的内容是否相同\n            for page_num in range(reader1.getNumPages()):\n                page1 = reader1.getPage(page_num).extractText()\n                page2 = reader2.getPage(page_num).extractText()\n                if page1 != page2:\n                    continue\n\n        maybe_project_dir = glob.glob('{}/**/{}'.format(get_log_folder(), pdf_hash + \".tag\"), recursive=True)\n\n\n        if len(maybe_project_dir) > 0:\n            return True, os.path.dirname(maybe_project_dir[0])\n\n    # 如果所有页的内容都相同，返回 True\n    return False, None\n\ndef log_chat(llm_model: str, input_str: str, output_str: str):\n    try:\n        if output_str and input_str and llm_model:\n            uid = str(uuid.uuid4().hex)\n            input_str = input_str.rstrip('\\n')\n            output_str = output_str.rstrip('\\n')\n            logger.bind(chat_msg=True).info(dedent(\n            \"\"\"\n            ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n            [UID]\n            {uid}\n            [Model]\n            {llm_model}\n            [Query]\n            {input_str}\n            [Response]\n            {output_str}\n            ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n            \"\"\").format(uid=uid, llm_model=llm_model, input_str=input_str, output_str=output_str))\n    except:\n        logger.error(trimmed_format_exc())\n"
        },
        {
          "name": "version",
          "type": "blob",
          "size": 0.2,
          "content": "{\n  \"version\": 3.91,\n  \"show_feature\": true,\n  \"new_feature\": \"优化前端并修复TTS的BUG <-> 添加时间线回溯功能 <-> 支持chatgpt-4o-latest <-> 增加RAG组件 <-> 升级多合一主提交键\"\n}\n"
        }
      ]
    },
    {
      "nameWithOwner": "syncthing/syncthing",
      "stars": 66750,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 0.27,
          "content": "comment: false\n\ncoverage:\n  range: \"40...100\"\n  precision: 1\n  status:\n    patch:\n      default:\n        informational: true\n    project:\n      default:\n        informational: true\n\ngithub_checks:\n  annotations: false\n\nignore:\n  - \"**.pb.go\"\n  - \"**_mocked.go\"\n  - \"**/mocks/*\"\n"
        },
        {
          "name": ".deepsource.toml",
          "type": "blob",
          "size": 0.22,
          "content": "version = 1\n\nexclude_patterns = [\"**/*.pb.go\"]\ntest_patterns = [\"**/*_test.go\"]\n\n[[analyzers]]\nname = \"go\"\nenabled = true\n\n  [analyzers.meta]\n  import_paths = [\"github.com/syncthing/syncthing\"]\n  build_tags = [\"noassets\"]\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.2,
          "content": "# Text files use LF line endings in this repository\n*   text=auto\n\n# Except the dependencies, which we leave alone\nvendor/**   -text=auto\n\n# Diffs on these files are meaningless\n*.svg           -diff\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.22,
          "content": "/syncthing\n/stdiscosrv\n*.tar.gz\n*.zip\n*.asc\n*.deb\n*.exe\n.jshintrc\ncoverage.out\nfiles/pidx\nbin\nperfstats*.csv\ncoverage.xml\nsyncthing.sig\nRELEASE\ndeb\n*.bz2\n/repos\n/proto/scripts/protoc-gen-gosyncthing\n/gui/next-gen-gui\n/compat.json\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.57,
          "content": "linters:\n  enable-all: true\n  disable:\n    - cyclop\n    - depguard\n    - exhaustive\n    - exhaustruct\n    - funlen\n    - gci\n    - gochecknoglobals\n    - gochecknoinits\n    - gocognit\n    - goconst\n    - gocyclo\n    - godox\n    - gofmt\n    - goimports\n    - gomoddirectives\n    - inamedparam\n    - interfacebloat\n    - ireturn\n    - lll\n    - maintidx\n    - nestif\n    - nonamedreturns\n    - paralleltest\n    - protogetter\n    - scopelint\n    - tagalign\n    - tagliatelle\n    - testpackage\n    - varnamelen\n    - wsl\n\nissues:\n  exclude-dirs:\n    - internal/gen\n    - cmd/dev\n    - repos"
        },
        {
          "name": ".policy.yml",
          "type": "blob",
          "size": 2.89,
          "content": "# This is the policy-bot configuration for this repository. It controls\n# which approvals are required for any given pull request. The format is\n# described at https://github.com/palantir/policy-bot. The syntax of the\n# policy can be verified by the bot:\n# curl https://pb.syncthing.net/api/validate -X PUT -T .policy.yml\n\n# The policy below is what is required for any pull request.\npolicy:\n  approval:\n    - subject is conventional commit\n    - project metadata requires maintainer approval\n    - or:\n      - is approved by a syncthing contributor\n      - is a translation or dependency update by a contributor\n      - is a trivial change by a contributor\n\n  # Additionally, contributors can disapprove of a PR\n  disapproval:\n    requires:\n      teams:\n        - syncthing/contributors\n\n# The rules for the policy are described below.\n\napproval_rules:\n\n  # All commits (PRs before squashing) should have a valid conventional\n  # commit type subject.\n  - name: subject is conventional commit\n    requires:\n      conditions:\n        title:\n          matches:\n            - '^(feat|fix|docs|chore|refactor|build): [a-z].+'\n            - '^(feat|fix|docs|chore|refactor|build)\\(\\w+(, \\w+)*\\): [a-z].+'\n\n  # Changes to important project metadata and documentation, including this\n  # policy, require signoff by a maintainer\n  - name: project metadata requires maintainer approval\n    if:\n      changed_files:\n        paths:\n          - ^[^/]+\\.md\n          - ^\\.policy\\.yml\n          - ^\\.github/\n          - ^LICENSE\n    requires:\n      count: 1\n      teams:\n        - syncthing/maintainers\n    options:\n      ignore_update_merges: true\n      allow_contributor: true\n\n  # Regular pull requests require approval by an active contributor\n  - name: is approved by a syncthing contributor\n    requires:\n      count: 1\n      teams:\n        - syncthing/contributors\n    options:\n      ignore_update_merges: true\n      allow_contributor: true\n\n  # Changes to some files (translations, dependencies, compatibility) do not\n  # require approval if they were proposed by a contributor and have a\n  # matching commit subject\n  - name: is a translation or dependency update by a contributor\n    if:\n      only_changed_files:\n        paths:\n          - ^gui/default/assets/lang/\n          - ^go\\.mod$\n          - ^go\\.sum$\n          - ^compat\\.yaml$\n      title:\n        matches:\n          - '^chore\\(gui\\):'\n          - '^build\\(deps\\):'\n          - '^build\\(compat\\):'\n      has_author_in:\n        teams:\n          - syncthing/contributors\n\n  # If the change is small and the label \"trivial\" is added, we accept that\n  # on trust. These PRs can be audited after the fact as appropriate.\n  # Features are not trivial.\n  - name: is a trivial change by a contributor\n    if:\n      modified_lines:\n        total: \"< 25\"\n      title:\n        not_matches:\n          - '^feat'\n      has_labels:\n        - trivial\n      has_author_in:\n        teams:\n          - syncthing/contributors\n"
        },
        {
          "name": ".yamlfmt",
          "type": "blob",
          "size": 0.07,
          "content": "line_ending: lf\nformatter:\n  type: basic\n  retain_line_breaks: true\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 17.27,
          "content": "# This is the official list of Syncthing authors for copyright purposes.\n#\n# THIS FILE IS MOSTLY AUTO GENERATED. IF YOU'VE MADE A COMMIT TO THE\n# REPOSITORY YOU WILL BE ADDED HERE AUTOMATICALLY WITHOUT THE NEED FOR\n# ANY MANUAL ACTION.\n#\n# That said, you are welcome to correct your name or add a nickname / GitHub\n# user name as appropriate. The format is:\n#\n#    Name Name Name (nickname) <email1@example.com> <email2@example.com>\n#\n# The in-GUI authors list is periodically automatically updated from the\n# contents of this file.\n#\n\nAaron Bieber (qbit) <qbit@deftly.net>\nAdam Piggott (ProactiveServices) <aD@simplypeachy.co.uk> <simplypeachy@users.noreply.github.com> <ProactiveServices@users.noreply.github.com> <adam@proactiveservices.co.uk>\nAdel Qalieh (adelq) <aqalieh95@gmail.com> <adelq@users.noreply.github.com>\nAlan Pope <alan@popey.com>\nAlberto Donato <albertodonato@users.noreply.github.com>\nAleksey Vasenev <margtu-fivt@ya.ru>\nAlessandro G. (alessandro.g89) <alessandro.g89@gmail.com>\nAlex Ionescu <github@ionescu.sh>\nAlex Lindeman <139387+aelindeman@users.noreply.github.com>\nAlex Xu <alex.hello71@gmail.com>\nAlexander Graf (alex2108) <register-github@alex-graf.de>\nAlexander Seiler <seileralex@gmail.com>\nAlexandre Alves <alexandrealvesdb.contact@gmail.com>\nAlexandre Viau (aviau) <alexandre@alexandreviau.net> <aviau@debian.org>\nAman Gupta <aman@tmm1.net>\nAnatoli Babenia <anatoli@rainforce.org>\nAnderson Mesquita (andersonvom) <andersonvom@gmail.com>\nAndreas Sommer <andreas.sommer87@googlemail.com>\nandresvia <andres.via@gmail.com>\nAndrew Dunham (andrew-d) <andrew@du.nham.ca>\nAndrew Meyer <andrewm.bpi@gmail.com>\nAndrew Rabert (nvllsvm) <ar@nullsum.net> <6550543+nvllsvm@users.noreply.github.com>\nAndrey D (scienmind) <scintertech@cryptolab.net> <scienmind@users.noreply.github.com>\nAndré Colomb (acolomb) <src@andre.colomb.de> <github.com@andre.colomb.de>\nandyleap <andyleap@gmail.com>\nAnjan Momi <anjan@momi.ca>\nAnthony Goeckner <agoeckner@users.noreply.github.com>\nAntoine Lamielle (0x010C) <antoine.lamielle@0x010c.fr> <gh@0x010c.fr>\nAntony Male (canton7) <antony.male@gmail.com>\nAnur <anurnomeru@163.com>\nAranjedeath <Aranjedeath@users.noreply.github.com>\nArkadiusz Tymiński <gevleeog@gmail.com>\nAroun <login@b-vo.fr>\nArthur Axel fREW Schmidt (frioux) <frew@afoolishmanifesto.com> <frioux@gmail.com>\nArtur Zubilewicz <AkaZecik@users.noreply.github.com>\nAudrius Butkevicius (AudriusButkevicius) <audrius.butkevicius@gmail.com> <github@audrius.rocks>\nAurélien Rainone <476650+arl@users.noreply.github.com>\nBAHADIR YILMAZ <bahadiryilmaz32@gmail.com>\nBart De Vries (mogwa1) <devriesb@gmail.com>\nBeat Reichenbach <44111292+beatreichenbach@users.noreply.github.com>\nBen Curthoys (bencurthoys) <ben@bencurthoys.com>\nBen Schulz (uok) <ueomkail@gmail.com> <uok@users.noreply.github.com>\nBen Shepherd (benshep) <bjashepherd@gmail.com>\nBen Sidhom (bsidhom) <bsidhom@gmail.com>\nBenedikt Heine (bebehei) <bebe@bebehei.de>\nBenedikt Morbach <benedikt.morbach@googlemail.com>\nBenjamin Nater <17193640+bn4t@users.noreply.github.com>\nBenno Fünfstück <benno.fuenfstueck@gmail.com>\nBenny Ng (tpng) <benny.tpng@gmail.com>\nboomsquared <54829195+boomsquared@users.noreply.github.com>\nBoqin Qin <bobbqqin@bupt.edu.cn>\nBoris Rybalkin <ribalkin@gmail.com>\nBrandon Philips (philips) <brandon@ifup.org>\nBrendan Long (brendanlong) <self@brendanlong.com>\nBrian R. Becker (brbecker) <brbecker@gmail.com>\nbt90 <btom1990@googlemail.com>\nCaleb Callaway (cqcallaw) <enlightened.despot@gmail.com>\nCarsten Hagemann (carstenhag) <moter8@gmail.com> <carsten@chagemann.de>\nCatfriend1 <16361913+Catfriend1@users.noreply.github.com>\nCathryne Linenweaver (Cathryne) <cathryne.linenweaver@gmail.com> <Cathryne@users.noreply.github.com> <katrinleinweber@MAC.local>\nCedric Staniewski (xduugu) <cedric@gmx.ca>\nchenrui <rui@meetup.com>\nChih-Hsuan Yen <yan12125@gmail.com> <1937689+yan12125@users.noreply.github.com>\nChoongkyu <choongkyu.kim+gh@gmail.com> <vapidlyrapid+gh@gmail.com>\nChris Howie (cdhowie) <me@chrishowie.com>\nChris Joel (cdata) <chris@scriptolo.gy>\nChris Tonkinson <chris@masterbran.ch>\nChristian Kujau <ckujau@users.noreply.github.com>\nChristian Prescott <me@christianprescott.com>\nchucic <chucic@seznam.cz>\ncjc7373 <niuchangcun@gmail.com>\nColin Kennedy (moshen) <moshen.colin@gmail.com>\nCromefire_ <tim.l@nghorst.net> <26320625+cromefire@users.noreply.github.com>\ncui fliter <imcusg@gmail.com>\nCyprien Devillez <cypx@users.noreply.github.com>\nd-volution <49024624+d-volution@users.noreply.github.com>\nDale Visser <dale.visser@live.com>\nDan <benda.daniel@gmail.com>\nDaniel Barczyk <46358936+DanielBarczyk@users.noreply.github.com>\nDaniel Bergmann (brgmnn) <dan.arne.bergmann@gmail.com> <brgmnn@users.noreply.github.com>\nDaniel Harte (norgeous) <daniel@harte.me> <daniel@danielharte.co.uk> <norgeous@users.noreply.github.com>\nDaniel Martí (mvdan) <mvdan@mvdan.cc>\nDaniel Padrta <64928366+danpadcz@users.noreply.github.com>\nDarshil Chanpura (dtchanpura) <dtchanpura@gmail.com> <dcprime314@gmail.com>\nDavid Rimmer (dinosore) <dinosore@dbrsoftware.co.uk>\ndeepsource-autofix[bot] <62050782+deepsource-autofix[bot]@users.noreply.github.com>\nDeflateAwning <11021263+DeflateAwning@users.noreply.github.com>\nDenis A. (dva) <denisva@gmail.com>\nDennis Wilson (snnd) <dw@risu.io>\ndependabot-preview[bot] <dependabot-preview[bot]@users.noreply.github.com> <27856297+dependabot-preview[bot]@users.noreply.github.com>\ndependabot[bot] <dependabot[bot]@users.noreply.github.com> <49699333+dependabot[bot]@users.noreply.github.com>\nderekriemer <derek.riemer@colorado.edu>\nDerRockWolf <50499906+DerRockWolf@users.noreply.github.com>\ndesbma <desbma@users.noreply.github.com>\nDevon G. Redekopp <devon@redekopp.com>\ndiemade <spamkill@posteo.ch>\ndigital <didev@dinid.net>\nDimitri Papadopoulos Orfanos <3234522+DimitriPapadopoulos@users.noreply.github.com>\nDmitry Saveliev (dsaveliev) <d.e.saveliev@gmail.com>\nDomenic Horner <domenic@tgxn.net>\nDominik Heidler (asdil12) <dominik@heidler.eu>\nElias Jarlebring (jarlebring) <jarlebring@gmail.com>\nElliot Huffman <thelich2@gmail.com>\nEmil Hessman (ceh) <emil@hessman.se>\nEmil Lundberg <emil@emlun.se>\nEng Zer Jun <engzerjun@gmail.com>\nentity0xfe <109791748+entity0xfe@users.noreply.github.com> <entity0xfe@my.domain>\nEric Lesiuta <elesiuta@gmail.com>\nEric P <eric@kastelo.net>\nErik Meitner (WSGCSysadmin) <e.meitner@willystreet.coop>\nEvan Spensley <94762716+0evan@users.noreply.github.com>\nEvgeny Kuznetsov <evgeny@kuznetsov.md>\nFederico Castagnini (facastagnini) <federico.castagnini@gmail.com>\nFelix <53702818+f-eliks@users.noreply.github.com>\nFelix Ableitner (Nutomic) <me@nutomic.com>\nFelix Lampe <mail@flampe.de>\nFelix Unterpaintner (bigbear2nd) <bigbear2nd@gmail.com>\nFrancois-Xavier Gsell (zukoo) <fxgsell@gmail.com>\nFrank Isemann (fti7) <frank@isemann.name>\nGahl Saraf <saraf.gahl@gmail.com> <gahl@raftt.io>\ngeorgespatton <georgespatton@users.noreply.github.com>\nghjklw <malo@jaffre.info>\nGilli Sigurdsson (gillisig) <gilli@vx.is>\nGleb Sinyavskiy <zhulik.gleb@gmail.com>\nGraham Miln (grahammiln) <graham.miln@dssw.co.uk> <graham.miln@miln.eu>\ngreatroar <61184462+greatroar@users.noreply.github.com>\nGreg <gco@jazzhaiku.com>\nguangwu <guoguangwu@magic-shield.com>\ngudvinr <gudvinr@gmail.com>\nGusted <postmaster@gusted.xyz> <williamzijl7@hotmail.com>\nHan Boetes <han@boetes.org>\nHansK-p <42314815+HansK-p@users.noreply.github.com>\nHarrison Jones (harrisonhjones) <harrisonhjones@users.noreply.github.com>\nHeiko Zuerker (Smiley73) <heiko@zuerker.org>\nHireworks <129852174+hireworksltd@users.noreply.github.com>\nHugo Locurcio <hugo.locurcio@hugo.pro>\nIain Barnett <iainspeed@gmail.com>\nIan Johnson (anonymouse64) <ian.johnson@canonical.com> <person.uwsome@gmail.com>\nignacy123 <ignacy.buczek@onet.pl>\nIkko Ashimine <eltociear@gmail.com>\nIlya Brin <464157+ilyabrin@users.noreply.github.com>\nIskander Sharipov (Alex) <quasilyte@gmail.com>\nJaakko Hannikainen (jgke) <jgke@jgke.fi>\nJacek Szafarkiewicz (hadogenes) <szafar@linux.pl>\nJack Croft <jccroft1@users.noreply.github.com>\nJacob <jyundt@gmail.com>\nJake Peterson (acogdev) <jake@acogdev.com>\nJakob Borg (calmh) <jakob@nym.se> <jakob@kastelo.net> <jborg@coreweave.com>\nJames O'Beirne <wild-github@au92.org>\nJames Patterson (jpjp) <jamespatterson@operamail.com> <jpjp@users.noreply.github.com>\njanost <janost@tuta.io>\nJaroslav Lichtblau <svetlemodry@users.noreply.github.com>\nJaroslav Malec (dzarda) <dzardacz@gmail.com>\njaseg <githubaccount@jaseg.net>\nJaspitta <ste.scarpitta@gmail.com>\nJauder Ho <jauderho@users.noreply.github.com>\nJaya Chithra (jayachithra) <s.k.jayachithra@gmail.com>\nJaya Kumar <jaya.kumar@ict.nl>\nJeffery To <jeffery.to@gmail.com>\njelle van der Waa <jelle@vdwaa.nl>\nJens Diemer (jedie) <github.com@jensdiemer.de> <git@jensdiemer.de>\nJerry Jacobs (xor-gate) <jerry.jacobs@xor-gate.org> <xor-gate@users.noreply.github.com>\nJesse Lucas <jesse@jesselucas.com>\nJochen Voss (seehuhn) <voss@seehuhn.de>\nJohan Andersson <j@i19.se>\nJohan Vromans (sciurius) <jvromans@squirrel.nl>\nJohn Rinehart (fuzzybear3965) <johnrichardrinehart@gmail.com>\nJonas Thelemann <e-mail@jonas-thelemann.de>\nJonathan <artback@protonmail.com> <jonagn@gmail.com>\nJonathan Cross <jcross@gmail.com>\nJonta <359397+Jonta@users.noreply.github.com>\nJose Manuel Delicado (jmdaweb) <jmdaweb@hotmail.com> <jmdaweb@users.noreply.github.com>\njtagcat <git-514635f7@jtag.cat> <git-12dbd862@jtag.cat>\nJulian Lehrhuber <jul13579@users.noreply.github.com>\nJörg Thalheim <Mic92@users.noreply.github.com>\nJędrzej Kula <kula.jedrek@gmail.com>\nK.B.Dharun Krishna <kbdharunkrishna@gmail.com>\nKalle Laine <pahakalle@protonmail.com>\nKapil Sareen <kapilsareen584@gmail.com>\nKarol Różycki (krozycki) <rozycki.karol@gmail.com>\nKebin Liu <lkebin@gmail.com>\nKeith Harrison <keithh@protonmail.com>\nKeith Turner <kturner@apache.org>\nKelong Cong (kc1212) <kc04bc@gmx.com> <kc1212@users.noreply.github.com>\nKen'ichi Kamada (kamadak) <kamada@nanohz.org>\nKevin Allen (ironmig) <kma1660@gmail.com>\nKevin Bushiri (keevBush) <keevbush@gmail.com> <36192217+keevBush@users.noreply.github.com>\nKevin White, Jr. (kwhite17) <kevinwhite1710@gmail.com>\nklemens <ka7@github.com>\nKurt Fitzner (Kudalufi) <kurt@va1der.ca> <kurt.fitzner@gmail.com>\nkylosus <33132401+kylosus@users.noreply.github.com>\nLars K.W. Gohlke (lkwg82) <lkwg82@gmx.de>\nLars Lehtonen <lars.lehtonen@gmail.com>\nLaurent Arnoud <laurent@spkdev.net>\nLaurent Etiemble (letiemble) <laurent.etiemble@gmail.com> <laurent.etiemble@monobjc.net>\nLeo Arias (elopio) <yo@elopio.net>\nLiu Siyuan (liusy182) <liusy182@gmail.com> <liusy182@hotmail.com>\nLode Hoste (Zillode) <zillode@zillode.be>\nLord Landon Agahnim (LordLandon) <lordlandon@gmail.com>\nLSmithx2 <42276854+lsmithx2@users.noreply.github.com>\nluchenhan <168071714+luchenhan@users.noreply.github.com>\nLukas Lihotzki <lukas@lihotzki.de>\nLuke Hamburg <1992842+luckman212@users.noreply.github.com>\nluzpaz <luzpaz@users.noreply.github.com>\nMajed Abdulaziz (majedev) <majed.alhajry@gmail.com>\nMarc Laporte (marclaporte) <marc@marclaporte.com> <marc@laporte.name>\nMarc Pujol (kilburn) <kilburn@la3.org>\nMarcin Dziadus (marcindziadus) <dziadus.marcin@gmail.com>\nmarco-m <marco.molteni@laposte.net>\nMarcus Legendre <marcus.legendre@gmail.com>\nMario Majila <mariustshipichik@gmail.com>\nMark Pulford (mpx) <mark@kyne.com.au>\nMartchus <martchus@gmx.net>\nMartin Polehla <p0l0us@users.noreply.github.com>\nMateusz Naściszewski (mateon1) <matin1111@wp.pl>\nMateusz Ż <thedead4fun@live.com>\nMatic Potočnik <hairyfotr@gmail.com>\nMatt Burke (burkemw3) <mburke@amplify.com> <burkemw3@gmail.com>\nMatt Robenolt <matt@ydekproductions.com>\nMatteo Ruina <matteo.ruina@gmail.com>\nMaurizio Tomasi <ziotom78@gmail.com>\nMax <github@germancoding.com>\nMax Schulze (kralo) <max.schulze@online.de> <kralo@users.noreply.github.com>\nmaxice8 <30738253+maxice8@users.noreply.github.com>\nMaximAL <almaximal@ya.ru>\nMaxime Thirouin <m@moox.io>\nMaximilian <maxi.rostock@outlook.de> <public@complexvector.space>\nmclang <1721600+mclang@users.noreply.github.com>\nMichael Jephcote (Rewt0r) <rewt0r@gmx.com> <Rewt0r@users.noreply.github.com>\nMichael Ploujnikov (plouj) <ploujj@gmail.com>\nMichael Rienstra <mrienstra@gmail.com>\nMichael Tilli (pyfisch) <pyfisch@gmail.com>\nMichaIng <micha@dietpi.com>\nMigelo <miha@filetki.si>\nMike Boone <mike@boonedocks.net>\nMikeLund <MikeLund@users.noreply.github.com>\nMikolajTwarog <43782609+MikolajTwarog@users.noreply.github.com>\nMingxuan Lin <gdlmx@users.noreply.github.com>\nmv1005 <49659413+mv1005@users.noreply.github.com>\nNate Morrison (nrm21) <natemorrison@gmail.com>\nNaveen <172697+naveensrinivasan@users.noreply.github.com>\nnf <nf@wh3rd.net>\nNicholas Rishel (PrototypeNM1) <rishel.nick@gmail.com> <PrototypeNM1@users.noreply.github.com>\nNick Busey <NickBusey@users.noreply.github.com>\nNico Stapelbroek <3368018+nstapelbroek@users.noreply.github.com>\nNicolas Braud-Santoni <nicolas@braud-santoni.eu>\nNicolas Perraut <n.perraut@gmail.com>\nNiels Peter Roest (Niller303) <nielsproest@hotmail.com> <seje.niels@hotmail.com>\nNils Jakobi (thunderstorm99) <jakobi.nils@gmail.com>\nNinoM4ster <ninom4ster@gmail.com>\nNitroretro <43112364+Nitroretro@users.noreply.github.com>\nNoLooseEnds <jon.koslung@gmail.com>\nOliver Freyermuth <o.freyermuth@googlemail.com>\norangekame3 <miya.org.0309@gmail.com>\notbutz <tbutz@optitool.de>\nOtiel <Otiel@users.noreply.github.com>\noverkill <22098433+0verk1ll@users.noreply.github.com>\nOyebanji Jacob Mayowa <oyebanji05@gmail.com>\nPablo <pbaeyens31+github@gmail.com>\nPascal Jungblut (pascalj) <github@pascalj.com> <mail@pascal-jungblut.com>\nPaul Brit <paulbrit44@gmail.com>\nPawel Palenica (qepasa) <pawelpalenica11@gmail.com>\nPaweł Rozlach <vespian@users.noreply.github.com>\nperewa <cavalcante.ten@gmail.com>\nPeter Badida <KeyWeeUsr@users.noreply.github.com>\nPeter Dave Hello <hsu@peterdavehello.org>\nPeter Hoeg (peterhoeg) <peter@speartail.com>\nPeter Marquardt (wwwutz) <wwwutz@gmail.com> <wwwutz@googlemail.com>\nPhani Rithvij <phanirithvij2000@gmail.com>\nPhil Davis <phil.davis@inf.org>\nPhilippe Schommers (filoozoom) <philippe@schommers.be>\nPhill Luby (pluby) <phill.luby@newredo.com>\nPier Paolo Ramon <ramonpierre@gmail.com>\nPiotr Bejda (piobpl) <piotrb10@gmail.com>\nPramodh KP (pramodhkp) <pramodh.p@directi.com> <1507241+pramodhkp@users.noreply.github.com>\nQuentin Hibon <qh.public@yahoo.com>\nRahmi Pruitt <rjpruitt16@gmail.com>\nred_led <red-led@users.noreply.github.com>\nRichard Hartmann <RichiH@users.noreply.github.com>\nRobert Carosi (nov1n) <robert@carosi.nl>\nRoberto Santalla <roobre@users.noreply.github.com>\nRobin Schoonover <robin@cornhooves.org>\nRoman Zaynetdinov (zaynetro) <romanznet@gmail.com>\nRoss Smith II (rasa) <ross@smithii.com>\nrubenbe <github-com-00ff86@vandamme.email>\nRuslan Yevdokymov <38809160+ruslanye@users.noreply.github.com>\nRyan Qian <i@bitbili.net>\nRyan Sullivan (KayoticSully) <kayoticsully@gmail.com>\nSacheendra Talluri (sacheendra) <sacheendra.t@gmail.com>\nScott Klupfel (kluppy) <kluppy@going2blue.com>\nsec65 <106604020+sec65@users.noreply.github.com>\nSergey Mishin (ralder) <ralder@yandex.ru>\nSertonix <83883937+Sertonix@users.noreply.github.com>\nSeverin von Wnuck-Lipinski <ss7@live.de>\nShaarad Dalvi <60266155+shaaraddalvi@users.noreply.github.com> <shdalv@microsoft.com>\nSimon Frei (imsodin) <freisim93@gmail.com>\nSimon Mwepu <simonmwepu@gmail.com>\nSimon Pickup <simon@pickupinfinity.com>\nSly_tom_cat <slytomcat@mail.ru>\nSonu Kumar Saw <31889738+dev-saw99@users.noreply.github.com>\nStefan Kuntz (Stefan-Code) <stefan.github@gmail.com> <Stefan.github@gmail.com>\nStefan Tatschner (rumpelsepp) <stefan@sevenbyte.org> <rumpelsepp@sevenbyte.org> <stefan@rumpelsepp.org>\nSteven Eckhoff <steven.eckhoff.opensource@gmail.com>\nSuhas Gundimeda (snugghash) <suhas.gundimeda@gmail.com> <snugghash@gmail.com>\nSven Bachmann <dev@mcbachmann.de>\nSyncthing Automation <automation@syncthing.net>\nSyncthing Release Automation <release@syncthing.net>\nTaylor Khan (nelsonkhan) <nelsonkhan@gmail.com>\nTerrance <git@terrance.allofti.me>\nThomas <9749173+uhthomas@users.noreply.github.com>\nThomas Hipp <thomashipp@gmail.com>\nTim Abell (timabell) <tim@timwise.co.uk>\nTim Howes (timhowes) <timhowes@berkeley.edu>\nTim Nordenfur <tim@gurka.se>\nTobias Frölich <40638719+tobifroe@users.noreply.github.com>\nTobias Klauser <tobias.klauser@gmail.com>\nTobias Nygren (tnn2) <tnn@nygren.pp.se>\nTobias Tom (tobiastom) <t.tom@succont.de>\nTom Jakubowski <tom@crystae.net>\nTomasz Wilczyński <5626656+tomasz1986@users.noreply.github.com> <twilczynski@naver.com>\nTommy Thorn <tommy-github-email@thorn.ws>\nTommy van der Vorst <tommy-github@pixelspark.nl> <tommy@pixelspark.nl>\nTully Robinson (tojrobinson) <tully@tojr.org>\nTyler Brazier (tylerbrazier) <tyler@tylerbrazier.com>\nTyler Kropp <kropptyler@gmail.com>\nUnrud (Unrud) <unrud@openaliasbox.org> <Unrud@users.noreply.github.com>\nvapatel2 <149737089+vapatel2@users.noreply.github.com>\nVeeti Paananen (veeti) <veeti.paananen@rojekti.fi>\nVictor Buinsky (buinsky) <vix_booja@tut.by>\nVik <63919734+ViktorOn@users.noreply.github.com>\nVil Brekin (Vilbrekin) <vilbrekin@gmail.com>\nvillekalliomaki <53118179+villekalliomaki@users.noreply.github.com>\nVladimir Rusinov <vrusinov@google.com> <vladimir.rusinov@gmail.com>\nwangguoliang <liangcszzu@163.com>\nWangXi <xib1102@icloud.com>\nWill Rouesnel <wrouesnel@wrouesnel.com>\nWilliam A. Kennington III (wkennington) <william@wkennington.com>\nwouter bolsterlee <wouter@bolsterl.ee>\nWulf Weich (wweich) <wweich@users.noreply.github.com> <wweich@gmx.de> <wulf@weich-kr.de>\nxarx00 <xarx00@users.noreply.github.com>\nXavier O. (damajor) <damajor@gmail.com>\nxjtdy888 (xjtdy888) <xjtdy888@163.com>\nYannic A. (eipiminus1) <eipiminusone+github@gmail.com> <eipiminus1@users.noreply.github.com>\n佛跳墙 <daoquan@qq.com>\n落心 <luoxin.ttt@gmail.com>\n"
        },
        {
          "name": "CONDUCT.md",
          "type": "blob",
          "size": 3.15,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\neducation, socio-economic status, nationality, personal appearance, race,\nreligion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at security@syncthing.net. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.27,
          "content": "## Reporting Bugs\n\nPlease file bugs in the [GitHub Issue\nTracker](https://github.com/syncthing/syncthing/issues). Include at\nleast the following:\n\n - What happened\n\n - What did you expect to happen instead of what *did* happen, if it's\n   not crazy obvious\n\n - What operating system, operating system version and version of\n   Syncthing you are running\n\n - The same for other connected devices, where relevant\n\n - Screenshot if the issue concerns something visible in the GUI\n\n - Console log entries, where possible and relevant\n\nIf you're not sure whether something is relevant, erring on the side of\ntoo much information will never get you yelled at. :)\n\n## Contributing Translations\n\nAll translations are done via\n[Weblate](https://hosted.weblate.org/projects/syncthing/). If you wish\nto contribute to a translation, just head over there and sign up.\nBefore every release, the language resources are updated from the\nlatest info on Weblate.\n\nNote that the previously used service at\n[Transifex](https://www.transifex.com/projects/p/syncthing/) is being\nretired and we kindly ask you to sign up on Weblate for continued\ninvolvement.\n\n## Contributing Code\n\nEvery contribution is welcome. If you want to contribute but are unsure\nwhere to start, any open issues are fair game! See the [Contribution\nGuidelines](https://docs.syncthing.net/dev/contributing.html) for the full\nstory on committing code.\n\n## Contributing Documentation\n\nUpdates to the [documentation site](https://docs.syncthing.net/) can be\nmade as pull requests on the [documentation\nrepository](https://github.com/syncthing/docs).\n\n## Licensing\n\nAll contributions are made available under the same license as the already\nexisting material being contributed to. For most of the project and unless\notherwise stated this means MPLv2, but there are exceptions:\n\n- Certain commands (under cmd/...) may have a separate license, indicated by\n  the presence of a LICENSE file in the corresponding directory.\n\n- The documentation (man/...) is licensed under the Creative Commons\n  Attribution 4.0 International License.\n\n- Projects under vendor/... are copyright by and licensed from their\n  respective original authors. Contributions should be made to the original\n  project, not here.\n\nRegardless of the license in effect, you retain the copyright to your\ncontribution.\n\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.71,
          "content": "ARG GOVERSION=latest\n\n#\n# Maybe build Syncthing. This is a bit ugly as we can't make an entire\n# section of the Dockerfile conditional, so we end up always pulling the\n# golang image as builder. Then we check if the executable we need already\n# exists (pre-built) otherwise we build it.\n#\n\nFROM golang:$GOVERSION AS builder\nARG BUILD_USER\nARG BUILD_HOST\nARG TARGETARCH\n\nWORKDIR /src\nCOPY . .\n\nENV CGO_ENABLED=0\nRUN if [ ! -f syncthing-linux-$TARGETARCH ] ; then \\\n    go run build.go -no-upgrade build syncthing ; \\\n    mv syncthing syncthing-linux-$TARGETARCH ; \\\n  fi\n\n#\n# The rest of the Dockerfile uses the binary from the builder, prebuilt or\n# not.\n#\n\nFROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing\"\n\nEXPOSE 8384 22000/tcp 22000/udp 21027/udp\n\nVOLUME [\"/var/syncthing\"]\n\nRUN apk add --no-cache ca-certificates curl libcap su-exec tzdata\n\nCOPY --from=builder /src/syncthing-linux-$TARGETARCH /bin/syncthing\nCOPY --from=builder /src/script/docker-entrypoint.sh /bin/entrypoint.sh\n\nENV PUID=1000 PGID=1000 HOME=/var/syncthing\n\nHEALTHCHECK --interval=1m --timeout=10s \\\n  CMD curl -fkLsS -m 2 127.0.0.1:8384/rest/noauth/health | grep -o --color=never OK || exit 1\n\nENV STGUIADDRESS=0.0.0.0:8384\nENV STHOMEDIR=/var/syncthing/config\nRUN chmod 755 /bin/entrypoint.sh\nENTRYPOINT [\"/bin/entrypoint.sh\", \"/bin/syncthing\"]\n"
        },
        {
          "name": "Dockerfile.builder",
          "type": "blob",
          "size": 0.71,
          "content": "ARG GOVERSION=latest\nFROM golang:$GOVERSION\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Builder\"\n\n# FPM to build Debian packages\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n\tlocales rubygems ruby-dev build-essential git \\\n\t&& apt-get clean \\\n\t&& rm -rf /var/lib/apt/lists/* \\\n\t&& gem install fpm\n"
        },
        {
          "name": "Dockerfile.stcrashreceiver",
          "type": "blob",
          "size": 0.59,
          "content": "FROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Crash Receiver\"\n\nEXPOSE 8080\n\nCOPY stcrashreceiver-linux-${TARGETARCH} /bin/stcrashreceiver\n\nENTRYPOINT [ \"/bin/stcrashreceiver\" ]\n"
        },
        {
          "name": "Dockerfile.stdiscosrv",
          "type": "blob",
          "size": 1.21,
          "content": "ARG GOVERSION=latest\nFROM golang:$GOVERSION AS builder\nARG BUILD_USER\nARG BUILD_HOST\nARG TARGETARCH\n\nWORKDIR /src\nCOPY . .\n\nENV CGO_ENABLED=0\nRUN if [ ! -f stdiscosrv-linux-$TARGETARCH ] ; then \\\n    go run build.go -no-upgrade build stdiscosrv ; \\\n    mv stdiscosrv stdiscosrv-linux-$TARGETARCH ; \\\n  fi\n\nFROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Discovery Server\"\n\nEXPOSE 19200 8443\n\nVOLUME [\"/var/stdiscosrv\"]\n\nRUN apk add --no-cache ca-certificates su-exec\n\nCOPY --from=builder /src/stdiscosrv-linux-$TARGETARCH /bin/stdiscosrv\nCOPY --from=builder /src/script/docker-entrypoint.sh /bin/entrypoint.sh\n\nENV PUID=1000 PGID=1000 HOME=/var/stdiscosrv\n\nHEALTHCHECK --interval=1m --timeout=10s \\\n  CMD nc -z localhost 8443 || exit 1\n\nWORKDIR /var/stdiscosrv\nENTRYPOINT [\"/bin/entrypoint.sh\", \"/bin/stdiscosrv\"]\n"
        },
        {
          "name": "Dockerfile.strelaypoolsrv",
          "type": "blob",
          "size": 0.61,
          "content": "FROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Relay Pool Server\"\n\nEXPOSE 8080\n\nCOPY strelaypoolsrv-linux-${TARGETARCH} /bin/strelaypoolsrv\n\nENTRYPOINT [\"/bin/strelaypoolsrv\", \"-listen\", \":8080\"]\n"
        },
        {
          "name": "Dockerfile.strelaysrv",
          "type": "blob",
          "size": 1.21,
          "content": "ARG GOVERSION=latest\nFROM golang:$GOVERSION AS builder\nARG BUILD_USER\nARG BUILD_HOST\nARG TARGETARCH\n\nWORKDIR /src\nCOPY . .\n\nENV CGO_ENABLED=0\nRUN if [ ! -f strelaysrv-linux-$TARGETARCH ] ; then \\\n    go run build.go -no-upgrade build strelaysrv ; \\\n    mv strelaysrv strelaysrv-linux-$TARGETARCH ; \\\n  fi\n\nFROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Relay Server\"\n\nEXPOSE 22067 22070\n\nVOLUME [\"/var/strelaysrv\"]\n\nRUN apk add --no-cache ca-certificates su-exec\n\nCOPY --from=builder /src/strelaysrv-linux-$TARGETARCH /bin/strelaysrv\nCOPY --from=builder /src/script/docker-entrypoint.sh /bin/entrypoint.sh\n\nENV PUID=1000 PGID=1000 HOME=/var/strelaysrv\n\nHEALTHCHECK --interval=1m --timeout=10s \\\n  CMD nc -z localhost 22067 || exit 1\n\nWORKDIR /var/strelaysrv\nENTRYPOINT [\"/bin/entrypoint.sh\", \"/bin/strelaysrv\"]\n"
        },
        {
          "name": "Dockerfile.stupgrades",
          "type": "blob",
          "size": 0.57,
          "content": "FROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Upgrades\"\n\nEXPOSE 8080\n\nCOPY stupgrades-linux-${TARGETARCH} /bin/stupgrades\n\nENTRYPOINT [ \"/bin/stupgrades\" ]\n"
        },
        {
          "name": "Dockerfile.ursrv",
          "type": "blob",
          "size": 0.57,
          "content": "FROM alpine\nARG TARGETARCH\n\nLABEL org.opencontainers.image.authors=\"The Syncthing Project\" \\\n      org.opencontainers.image.url=\"https://syncthing.net\" \\\n      org.opencontainers.image.documentation=\"https://docs.syncthing.net\" \\\n      org.opencontainers.image.source=\"https://github.com/syncthing/syncthing\" \\\n      org.opencontainers.image.vendor=\"The Syncthing Project\" \\\n      org.opencontainers.image.licenses=\"MPL-2.0\" \\\n      org.opencontainers.image.title=\"Syncthing Usage Reporting Server\"\n\nEXPOSE 8080\n\nCOPY ursrv-linux-${TARGETARCH} /bin/ursrv\n\nENTRYPOINT [ \"/bin/ursrv\" ]\n"
        },
        {
          "name": "GOALS.md",
          "type": "blob",
          "size": 3.43,
          "content": "# The Syncthing Goals\n\nSyncthing is a **continuous file synchronization program**. It synchronizes\nfiles between two or more computers. We strive to fulfill the goals below.\nThe goals are listed in order of importance, the most important one being\nthe first.\n\n> \"Syncing files\" here is precise. It means we specifically exclude things\n> that are not files - calendar items, instant messages, and so on. If those\n> are in fact stored as files on disk, they can of course be synced as\n> files.\n\nSyncthing should be:\n\n### 1. Safe From Data Loss\n\nProtecting the user's data is paramount. We take every reasonable precaution\nto avoid corrupting the user's files.\n\n> This is the overriding goal, without which synchronizing files becomes\n> pointless. This means that we do not make unsafe trade offs for the sake\n> of performance or, in some cases, even usability.\n\n### 2. Secure Against Attackers\n\nAgain, protecting the user's data is paramount. Regardless of our other\ngoals, we must never allow the user's data to be susceptible to eavesdropping\nor modification by unauthorized parties.\n\n> This should be understood in context. It is not necessarily reasonable to\n> expect Syncthing to be resistant against well equipped state level\n> attackers. We will, however, do our best. Note also that this is different\n> from anonymity which is not, currently, a goal.\n\n### 3. Easy to Use\n\nSyncthing should be approachable, understandable, and inclusive.\n\n> Complex concepts and maths form the base of Syncthing's functionality.\n> This should nonetheless be abstracted or hidden to a degree where\n> Syncthing is usable by the general public.\n\n### 4. Automatic\n\nUser interaction should be required only when absolutely necessary.\n\n> Specifically this means that changes to files are picked up without\n> prompting, conflicts are resolved without prompting and connections are\n> maintained without prompting. We only prompt the user when it is required\n> to fulfill one of the (overriding) Secure, Safe or Easy goals.\n\n### 5. Universally Available\n\nSyncthing should run on every common computer. We are mindful that the\nlatest technology is not always available to every individual.\n\n> Computers include desktops, laptops, servers, virtual machines, small\n> general purpose computers such as Raspberry Pis and, *where possible*,\n> tablets and phones. NAS appliances, toasters, cars, firearms, thermostats,\n> and so on may include computing capabilities but it is not our goal for\n> Syncthing to run smoothly on these devices.\n\n### 6. For Individuals\n\nSyncthing is primarily about empowering the individual user with safe,\nsecure, and easy to use file synchronization.\n\n> We acknowledge that it's also useful in an enterprise setting and include\n> functionality to support that. If this is in conflict with the\n> requirements of the individual, those will however take priority.\n\n### 7. Everything Else\n\nThere are many things we care about that don't make it on to the list. It is\nfine to optimize for these values as well, as long as they are not in\nconflict with the stated goals above.\n\n> For example, performance is a thing we care about. We just don't care more\n> about it than safety, security, etc. Maintainability of the code base and\n> providing entertainment value for the maintainers are also things that\n> matter. It is understood that there are aspects of Syncthing that are\n> suboptimal or even in opposition with the goals above. However, we\n> continuously strive to align Syncthing more and more with these goals.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 16.33,
          "content": "Mozilla Public License Version 2.0\n==================================\n\n1. Definitions\n--------------\n\n1.1. \"Contributor\"\n    means each individual or legal entity that creates, contributes to\n    the creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n    means the combination of the Contributions of others (if any) used\n    by a Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n    means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n    means Source Code Form to which the initial Contributor has attached\n    the notice in Exhibit A, the Executable Form of such Source Code\n    Form, and Modifications of such Source Code Form, in each case\n    including portions thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n    means\n\n    (a) that the initial Contributor has attached the notice described\n        in Exhibit B to the Covered Software; or\n\n    (b) that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the\n        terms of a Secondary License.\n\n1.6. \"Executable Form\"\n    means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n    means a work that combines Covered Software with other material, in\n    a separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n    means this document.\n\n1.9. \"Licensable\"\n    means having the right to grant, to the maximum extent possible,\n    whether at the time of the initial grant or subsequently, any and\n    all of the rights conveyed by this License.\n\n1.10. \"Modifications\"\n    means any of the following:\n\n    (a) any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered\n        Software; or\n\n    (b) any new file in Source Code Form that contains any Covered\n        Software.\n\n1.11. \"Patent Claims\" of a Contributor\n    means any patent claim(s), including without limitation, method,\n    process, and apparatus claims, in any patent Licensable by such\n    Contributor that would be infringed, but for the grant of the\n    License, by the making, using, selling, offering for sale, having\n    made, import, or transfer of either its Contributions or its\n    Contributor Version.\n\n1.12. \"Secondary License\"\n    means either the GNU General Public License, Version 2.0, the GNU\n    Lesser General Public License, Version 2.1, the GNU Affero General\n    Public License, Version 3.0, or any later versions of those\n    licenses.\n\n1.13. \"Source Code Form\"\n    means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n    means an individual or a legal entity exercising rights under this\n    License. For legal entities, \"You\" includes any entity that\n    controls, is controlled by, or is under common control with You. For\n    purposes of this definition, \"control\" means (a) the power, direct\n    or indirect, to cause the direction or management of such entity,\n    whether by contract or otherwise, or (b) ownership of more than\n    fifty percent (50%) of the outstanding shares or beneficial\n    ownership of such entity.\n\n2. License Grants and Conditions\n--------------------------------\n\n2.1. Grants\n\nEach Contributor hereby grants You a world-wide, royalty-free,\nnon-exclusive license:\n\n(a) under intellectual property rights (other than patent or trademark)\n    Licensable by such Contributor to use, reproduce, make available,\n    modify, display, perform, distribute, and otherwise exploit its\n    Contributions, either on an unmodified basis, with Modifications, or\n    as part of a Larger Work; and\n\n(b) under Patent Claims of such Contributor to make, use, sell, offer\n    for sale, have made, import, and otherwise transfer either its\n    Contributions or its Contributor Version.\n\n2.2. Effective Date\n\nThe licenses granted in Section 2.1 with respect to any Contribution\nbecome effective for each Contribution on the date the Contributor first\ndistributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\nThe licenses granted in this Section 2 are the only rights granted under\nthis License. No additional rights or licenses will be implied from the\ndistribution or licensing of Covered Software under this License.\nNotwithstanding Section 2.1(b) above, no patent license is granted by a\nContributor:\n\n(a) for any code that a Contributor has removed from Covered Software;\n    or\n\n(b) for infringements caused by: (i) Your and any other third party's\n    modifications of Covered Software, or (ii) the combination of its\n    Contributions with other software (except as part of its Contributor\n    Version); or\n\n(c) under Patent Claims infringed by Covered Software in the absence of\n    its Contributions.\n\nThis License does not grant any rights in the trademarks, service marks,\nor logos of any Contributor (except as may be necessary to comply with\nthe notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\nNo Contributor makes additional grants as a result of Your choice to\ndistribute the Covered Software under a subsequent version of this\nLicense (see Section 10.2) or under the terms of a Secondary License (if\npermitted under the terms of Section 3.3).\n\n2.5. Representation\n\nEach Contributor represents that the Contributor believes its\nContributions are its original creation(s) or it has sufficient rights\nto grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\nThis License is not intended to limit any rights You have under\napplicable copyright doctrines of fair use, fair dealing, or other\nequivalents.\n\n2.7. Conditions\n\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted\nin Section 2.1.\n\n3. Responsibilities\n-------------------\n\n3.1. Distribution of Source Form\n\nAll distribution of Covered Software in Source Code Form, including any\nModifications that You create or to which You contribute, must be under\nthe terms of this License. You must inform recipients that the Source\nCode Form of the Covered Software is governed by the terms of this\nLicense, and how they can obtain a copy of this License. You may not\nattempt to alter or restrict the recipients' rights in the Source Code\nForm.\n\n3.2. Distribution of Executable Form\n\nIf You distribute Covered Software in Executable Form then:\n\n(a) such Covered Software must also be made available in Source Code\n    Form, as described in Section 3.1, and You must inform recipients of\n    the Executable Form how they can obtain a copy of such Source Code\n    Form by reasonable means in a timely manner, at a charge no more\n    than the cost of distribution to the recipient; and\n\n(b) You may distribute such Executable Form under the terms of this\n    License, or sublicense it under different terms, provided that the\n    license for the Executable Form does not attempt to limit or alter\n    the recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\nYou may create and distribute a Larger Work under terms of Your choice,\nprovided that You also comply with the requirements of this License for\nthe Covered Software. If the Larger Work is a combination of Covered\nSoftware with a work governed by one or more Secondary Licenses, and the\nCovered Software is not Incompatible With Secondary Licenses, this\nLicense permits You to additionally distribute such Covered Software\nunder the terms of such Secondary License(s), so that the recipient of\nthe Larger Work may, at their option, further distribute the Covered\nSoftware under the terms of either this License or such Secondary\nLicense(s).\n\n3.4. Notices\n\nYou may not remove or alter the substance of any license notices\n(including copyright notices, patent notices, disclaimers of warranty,\nor limitations of liability) contained within the Source Code Form of\nthe Covered Software, except that You may alter any license notices to\nthe extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\nYou may choose to offer, and to charge a fee for, warranty, support,\nindemnity or liability obligations to one or more recipients of Covered\nSoftware. However, You may do so only on Your own behalf, and not on\nbehalf of any Contributor. You must make it absolutely clear that any\nsuch warranty, support, indemnity, or liability obligation is offered by\nYou alone, and You hereby agree to indemnify every Contributor for any\nliability incurred by such Contributor as a result of warranty, support,\nindemnity or liability terms You offer. You may include additional\ndisclaimers of warranty and limitations of liability specific to any\njurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n---------------------------------------------------\n\nIf it is impossible for You to comply with any of the terms of this\nLicense with respect to some or all of the Covered Software due to\nstatute, judicial order, or regulation then You must: (a) comply with\nthe terms of this License to the maximum extent possible; and (b)\ndescribe the limitations and the code they affect. Such description must\nbe placed in a text file included with all distributions of the Covered\nSoftware under this License. Except to the extent prohibited by statute\nor regulation, such description must be sufficiently detailed for a\nrecipient of ordinary skill to be able to understand it.\n\n5. Termination\n--------------\n\n5.1. The rights granted under this License will terminate automatically\nif You fail to comply with any of its terms. However, if You become\ncompliant, then the rights granted under this License from a particular\nContributor are reinstated (a) provisionally, unless and until such\nContributor explicitly and finally terminates Your grants, and (b) on an\nongoing basis, if such Contributor fails to notify You of the\nnon-compliance by some reasonable means prior to 60 days after You have\ncome back into compliance. Moreover, Your grants from a particular\nContributor are reinstated on an ongoing basis if such Contributor\nnotifies You of the non-compliance by some reasonable means, this is the\nfirst time You have received notice of non-compliance with this License\nfrom such Contributor, and You become compliant prior to 30 days after\nYour receipt of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\ninfringement claim (excluding declaratory judgment actions,\ncounter-claims, and cross-claims) alleging that a Contributor Version\ndirectly or indirectly infringes any patent, then the rights granted to\nYou by any and all Contributors for the Covered Software under Section\n2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all\nend user license agreements (excluding distributors and resellers) which\nhave been validly granted by You or Your distributors under this License\nprior to termination shall survive termination.\n\n************************************************************************\n*                                                                      *\n*  6. Disclaimer of Warranty                                           *\n*  -------------------------                                           *\n*                                                                      *\n*  Covered Software is provided under this License on an \"as is\"       *\n*  basis, without warranty of any kind, either expressed, implied, or  *\n*  statutory, including, without limitation, warranties that the       *\n*  Covered Software is free of defects, merchantable, fit for a        *\n*  particular purpose or non-infringing. The entire risk as to the     *\n*  quality and performance of the Covered Software is with You.        *\n*  Should any Covered Software prove defective in any respect, You     *\n*  (not any Contributor) assume the cost of any necessary servicing,   *\n*  repair, or correction. This disclaimer of warranty constitutes an   *\n*  essential part of this License. No use of any Covered Software is   *\n*  authorized under this License except under this disclaimer.         *\n*                                                                      *\n************************************************************************\n\n************************************************************************\n*                                                                      *\n*  7. Limitation of Liability                                          *\n*  --------------------------                                          *\n*                                                                      *\n*  Under no circumstances and under no legal theory, whether tort      *\n*  (including negligence), contract, or otherwise, shall any           *\n*  Contributor, or anyone who distributes Covered Software as          *\n*  permitted above, be liable to You for any direct, indirect,         *\n*  special, incidental, or consequential damages of any character      *\n*  including, without limitation, damages for lost profits, loss of    *\n*  goodwill, work stoppage, computer failure or malfunction, or any    *\n*  and all other commercial damages or losses, even if such party      *\n*  shall have been informed of the possibility of such damages. This   *\n*  limitation of liability shall not apply to liability for death or   *\n*  personal injury resulting from such party's negligence to the       *\n*  extent applicable law prohibits such limitation. Some               *\n*  jurisdictions do not allow the exclusion or limitation of           *\n*  incidental or consequential damages, so this exclusion and          *\n*  limitation may not apply to You.                                    *\n*                                                                      *\n************************************************************************\n\n8. Litigation\n-------------\n\nAny litigation relating to this License may be brought only in the\ncourts of a jurisdiction where the defendant maintains its principal\nplace of business and such litigation shall be governed by laws of that\njurisdiction, without reference to its conflict-of-law provisions.\nNothing in this Section shall prevent a party's ability to bring\ncross-claims or counter-claims.\n\n9. Miscellaneous\n----------------\n\nThis License represents the complete agreement concerning the subject\nmatter hereof. If any provision of this License is held to be\nunenforceable, such provision shall be reformed only to the extent\nnecessary to make it enforceable. Any law or regulation which provides\nthat the language of a contract shall be construed against the drafter\nshall not be used to construe this License against a Contributor.\n\n10. Versions of the License\n---------------------------\n\n10.1. New Versions\n\nMozilla Foundation is the license steward. Except as provided in Section\n10.3, no one other than the license steward has the right to modify or\npublish new versions of this License. Each version will be given a\ndistinguishing version number.\n\n10.2. Effect of New Versions\n\nYou may distribute the Covered Software under the terms of the version\nof the License under which You originally received the Covered Software,\nor under the terms of any subsequent version published by the license\nsteward.\n\n10.3. Modified Versions\n\nIf you create software not governed by this License, and you want to\ncreate a new license for such software, you may create and use a\nmodified version of this License if you rename the license and remove\nany references to the name of the license steward (except to note that\nsuch modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\nLicenses\n\nIf You choose to distribute Source Code Form that is Incompatible With\nSecondary Licenses under the terms of this version of the License, the\nnotice described in Exhibit B of this License must be attached.\n\nExhibit A - Source Code Form License Notice\n-------------------------------------------\n\n  This Source Code Form is subject to the terms of the Mozilla Public\n  License, v. 2.0. If a copy of the MPL was not distributed with this\n  file, You can obtain one at https://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular\nfile, then You may include the notice in a location (such as a LICENSE\nfile in a relevant directory) where a recipient would be likely to look\nfor such a notice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n---------------------------------------------------------\n\n  This Source Code Form is \"Incompatible With Secondary Licenses\", as\n  defined by the Mozilla Public License, v. 2.0.\n"
        },
        {
          "name": "README-Docker.md",
          "type": "blob",
          "size": 3.69,
          "content": "# Docker Container for Syncthing\n\nUse the Dockerfile in this repo, or pull the `syncthing/syncthing` image\nfrom Docker Hub.\n\nUse the `/var/syncthing` volume to have the synchronized files available on the\nhost. You can add more folders and map them as you prefer.\n\nNote that Syncthing runs as UID 1000 and GID 1000 by default. These may be\naltered with the `PUID` and `PGID` environment variables. In addition\nthe name of the Syncthing instance can be optionally defined by using\n`--hostname=syncthing` parameter.\n\nTo grant Syncthing additional capabilities without running as root, use the\n`PCAP` environment variable with the same syntax as that for `setcap(8)`.\nFor example, `PCAP=cap_chown,cap_fowner+ep`.\n\nTo set a different umask value, use the `UMASK` environment variable. For\nexample `UMASK=002`.\n\n## Example Usage\n\n**Docker cli**\n```\n$ docker pull syncthing/syncthing\n$ docker run -p 8384:8384 -p 22000:22000/tcp -p 22000:22000/udp -p 21027:21027/udp \\\n    -v /wherever/st-sync:/var/syncthing \\\n    --hostname=my-syncthing \\\n    syncthing/syncthing:latest\n```\n\n**Docker compose**\n```yml\n---\nversion: \"3\"\nservices:\n  syncthing:\n    image: syncthing/syncthing\n    container_name: syncthing\n    hostname: my-syncthing\n    environment:\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - /wherever/st-sync:/var/syncthing\n    ports:\n      - 8384:8384 # Web UI\n      - 22000:22000/tcp # TCP file transfers\n      - 22000:22000/udp # QUIC file transfers\n      - 21027:21027/udp # Receive local discovery broadcasts\n    restart: unless-stopped\n    healthcheck:\n      test: curl -fkLsS -m 2 127.0.0.1:8384/rest/noauth/health | grep -o --color=never OK || exit 1\n      interval: 1m\n      timeout: 10s\n      retries: 3\n```\n\n## Discovery\n\nNote that Docker's default network mode prevents local IP addresses from\nbeing discovered, as Syncthing is only able to see the internal IP of the\ncontainer on the `172.17.0.0/16` subnet. This will result in poor transfer rates\nif local device addresses are not manually configured.\n\nIt is therefore advisable to use the [host network mode](https://docs.docker.com/network/host/) instead:\n\n**Docker cli**\n```\n$ docker pull syncthing/syncthing\n$ docker run --network=host \\\n    -v /wherever/st-sync:/var/syncthing \\\n    syncthing/syncthing:latest\n```\n\n**Docker compose**\n```yml\n---\nversion: \"3\"\nservices:\n  syncthing:\n    image: syncthing/syncthing\n    container_name: syncthing\n    hostname: my-syncthing\n    environment:\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - /wherever/st-sync:/var/syncthing\n    network_mode: host\n    restart: unless-stopped\n    healthcheck:\n      test: curl -fkLsS -m 2 127.0.0.1:8384/rest/noauth/health | grep -o --color=never OK || exit 1\n      interval: 1m\n      timeout: 10s\n      retries: 3\n```\n\nBe aware that syncthing alone is now in control of what interfaces and ports it\nlistens on. You can edit the syncthing configuration to change the defaults if\nthere are conflicts.\n\n## GUI Security\n\nBy default Syncthing inside the Docker image listens on 0.0.0.0:8384 to\nallow GUI connections via the Docker proxy. This is set by the\n`STGUIADDRESS` environment variable in the Dockerfile, as it differs from\nwhat Syncthing would otherwise use by default. This means you should set up\nauthentication in the GUI, like for any other externally reachable Syncthing\ninstance. If you do not require the GUI, or you use host networking, you can\nunset the `STGUIADDRESS` variable to have Syncthing fall back to listening\non 127.0.0.1:\n\n```\n$ docker pull syncthing/syncthing\n$ docker run -e STGUIADDRESS= \\\n    -v /wherever/st-sync:/var/syncthing \\\n    syncthing/syncthing:latest\n```\n\nWith the environment variable unset Syncthing will follow what is set in the\nconfiguration file / GUI settings dialog.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.91,
          "content": "[![Syncthing][14]][15]\n\n---\n\n[![MPLv2 License](https://img.shields.io/badge/license-MPLv2-blue.svg?style=flat-square)](https://www.mozilla.org/MPL/2.0/)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/88/badge)](https://bestpractices.coreinfrastructure.org/projects/88)\n[![Go Report Card](https://goreportcard.com/badge/github.com/syncthing/syncthing)](https://goreportcard.com/report/github.com/syncthing/syncthing)\n\n## Goals\n\nSyncthing is a **continuous file synchronization program**. It synchronizes\nfiles between two or more computers. We strive to fulfill the goals below.\nThe goals are listed in order of importance, the most important ones first.\nThis is the summary version of the goal list - for more\ncommentary, see the full [Goals document][13].\n\nSyncthing should be:\n\n1. **Safe From Data Loss**\n\n   Protecting the user's data is paramount. We take every reasonable\n   precaution to avoid corrupting the user's files.\n\n2. **Secure Against Attackers**\n\n   Again, protecting the user's data is paramount. Regardless of our other\n   goals, we must never allow the user's data to be susceptible to\n   eavesdropping or modification by unauthorized parties.\n\n3. **Easy to Use**\n\n   Syncthing should be approachable, understandable, and inclusive.\n\n4. **Automatic**\n\n   User interaction should be required only when absolutely necessary.\n\n5. **Universally Available**\n\n   Syncthing should run on every common computer. We are mindful that the\n   latest technology is not always available to every individual.\n\n6. **For Individuals**\n\n   Syncthing is primarily about empowering the individual user with safe,\n   secure, and easy to use file synchronization.\n\n7. **Everything Else**\n\n   There are many things we care about that don't make it on to the list. It\n   is fine to optimize for these values, as long as they are not in conflict\n   with the stated goals above.\n\n## Getting Started\n\nTake a look at the [getting started guide][2].\n\nThere are a few examples for keeping Syncthing running in the background\non your system in [the etc directory][3]. There are also several [GUI\nimplementations][11] for Windows, Mac, and Linux.\n\n## Docker\n\nTo run Syncthing in Docker, see [the Docker README][16].\n\n## Getting in Touch\n\nThe first and best point of contact is the [Forum][8].\nIf you've found something that is clearly a\nbug, feel free to report it in the [GitHub issue tracker][10].\n\nIf you believe that you’ve found a Syncthing-related security vulnerability,\nplease report it by emailing security@syncthing.net. Do not report it in the\nForum or issue tracker.\n\n## Building\n\nBuilding Syncthing from source is easy. After extracting the source bundle from\na release or checking out git, you just need to run `go run build.go` and the\nbinaries are created in `./bin`. There's [a guide][5] with more details on the\nbuild process.\n\n## Signed Releases\n\nRelease binaries are GPG signed with the key available from\nhttps://syncthing.net/security/. There is also a built-in automatic\nupgrade mechanism (disabled in some distribution channels) which uses a\ncompiled in ECDSA signature. macOS and Windows binaries are also\ncode-signed.\n\n## Documentation\n\nPlease see the Syncthing [documentation site][6] [[source]][17].\n\nAll code is licensed under the [MPLv2 License][7].\n\n[1]: https://docs.syncthing.net/specs/bep-v1.html\n[2]: https://docs.syncthing.net/intro/getting-started.html\n[3]: https://github.com/syncthing/syncthing/blob/main/etc\n[5]: https://docs.syncthing.net/dev/building.html\n[6]: https://docs.syncthing.net/\n[7]: https://github.com/syncthing/syncthing/blob/main/LICENSE\n[8]: https://forum.syncthing.net/\n[10]: https://github.com/syncthing/syncthing/issues\n[11]: https://docs.syncthing.net/users/contrib.html#gui-wrappers\n[13]: https://github.com/syncthing/syncthing/blob/main/GOALS.md\n[14]: assets/logo-text-128.png\n[15]: https://syncthing.net/\n[16]: https://github.com/syncthing/syncthing/blob/main/README-Docker.md\n[17]: https://github.com/syncthing/docs\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "buf.gen.yaml",
          "type": "blob",
          "size": 0.28,
          "content": "version: v2\nmanaged:\n  enabled: true\n  override:\n    - file_option: go_package_prefix\n      value: github.com/syncthing/syncthing/internal/gen\nplugins:\n  - remote: buf.build/protocolbuffers/go:v1.35.1\n    out: .\n    opt: module=github.com/syncthing/syncthing\ninputs:\n  - directory: proto\n"
        },
        {
          "name": "buf.yaml",
          "type": "blob",
          "size": 0.14,
          "content": "version: v2\nmodules:\n  - path: proto\n    name: github.com/syncthing/syncthing\nlint:\n  use:\n    - STANDARD\nbreaking:\n  use:\n    - WIRE_JSON\n"
        },
        {
          "name": "build.go",
          "type": "blob",
          "size": 41.55,
          "content": "// Copyright (C) 2014 The Syncthing Authors.\n//\n// This Source Code Form is subject to the terms of the Mozilla Public\n// License, v. 2.0. If a copy of the MPL was not distributed with this file,\n// You can obtain one at https://mozilla.org/MPL/2.0/.\n\n//go:build tools\n// +build tools\n\npackage main\n\nimport (\n\t\"archive/tar\"\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"compress/flate\"\n\t\"compress/gzip\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/user\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"text/template\"\n\t\"time\"\n\n\tbuildpkg \"github.com/syncthing/syncthing/lib/build\"\n\t\"github.com/syncthing/syncthing/lib/upgrade\"\n\t\"sigs.k8s.io/yaml\"\n)\n\nvar (\n\tgoarch         string\n\tgoos           string\n\tnoupgrade      bool\n\tversion        string\n\tgoCmd          string\n\trace           bool\n\tdebug          = os.Getenv(\"BUILDDEBUG\") != \"\"\n\textraTags      string\n\tinstallSuffix  string\n\tpkgdir         string\n\tcc             string\n\trun            string\n\tbenchRun       string\n\tbuildOut       string\n\tdebugBinary    bool\n\tcoverage       bool\n\tlong           bool\n\ttimeout        = \"120s\"\n\tlongTimeout    = \"600s\"\n\tnumVersions    = 5\n\twithNextGenGUI = os.Getenv(\"BUILD_NEXT_GEN_GUI\") != \"\"\n)\n\ntype target struct {\n\tname              string\n\tdebname           string\n\tdebdeps           []string\n\tdebpre            string\n\tdescription       string\n\tbuildPkgs         []string\n\tbinaryName        string\n\tarchiveFiles      []archiveFile\n\tsystemdService    string\n\tinstallationFiles []archiveFile\n\ttags              []string\n}\n\ntype archiveFile struct {\n\tsrc  string\n\tdst  string\n\tperm os.FileMode\n}\n\nvar targets = map[string]target{\n\t\"all\": {\n\t\t// Only valid for the \"build\" and \"install\" commands as it lacks all\n\t\t// the archive creation stuff. buildPkgs gets filled out in init()\n\t},\n\t\"syncthing\": {\n\t\t// The default target for \"build\", \"install\", \"tar\", \"zip\", \"deb\", etc.\n\t\tname:        \"syncthing\",\n\t\tdebname:     \"syncthing\",\n\t\tdebdeps:     []string{\"libc6\", \"procps\"},\n\t\tdescription: \"Open Source Continuous File Synchronization\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/syncthing\"},\n\t\tbinaryName:  \"syncthing\", // .exe will be added automatically for Windows builds\n\t\tarchiveFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"{{binary}}\", perm: 0o755},\n\t\t\t{src: \"README.md\", dst: \"README.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"AUTHORS.txt\", perm: 0o644},\n\t\t\t// All files from etc/ and extra/ added automatically in init().\n\t\t},\n\t\tsystemdService: \"syncthing@*.service\",\n\t\tinstallationFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"deb/usr/bin/{{binary}}\", perm: 0o755},\n\t\t\t{src: \"README.md\", dst: \"deb/usr/share/doc/syncthing/README.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"deb/usr/share/doc/syncthing/LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"deb/usr/share/doc/syncthing/AUTHORS.txt\", perm: 0o644},\n\t\t\t{src: \"man/syncthing.1\", dst: \"deb/usr/share/man/man1/syncthing.1\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-config.5\", dst: \"deb/usr/share/man/man5/syncthing-config.5\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-stignore.5\", dst: \"deb/usr/share/man/man5/syncthing-stignore.5\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-device-ids.7\", dst: \"deb/usr/share/man/man7/syncthing-device-ids.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-event-api.7\", dst: \"deb/usr/share/man/man7/syncthing-event-api.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-faq.7\", dst: \"deb/usr/share/man/man7/syncthing-faq.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-networking.7\", dst: \"deb/usr/share/man/man7/syncthing-networking.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-rest-api.7\", dst: \"deb/usr/share/man/man7/syncthing-rest-api.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-security.7\", dst: \"deb/usr/share/man/man7/syncthing-security.7\", perm: 0o644},\n\t\t\t{src: \"man/syncthing-versioning.7\", dst: \"deb/usr/share/man/man7/syncthing-versioning.7\", perm: 0o644},\n\t\t\t{src: \"etc/linux-systemd/system/syncthing@.service\", dst: \"deb/lib/systemd/system/syncthing@.service\", perm: 0o644},\n\t\t\t{src: \"etc/linux-systemd/user/syncthing.service\", dst: \"deb/usr/lib/systemd/user/syncthing.service\", perm: 0o644},\n\t\t\t{src: \"etc/linux-sysctl/30-syncthing.conf\", dst: \"deb/usr/lib/sysctl.d/30-syncthing.conf\", perm: 0o644},\n\t\t\t{src: \"etc/firewall-ufw/syncthing\", dst: \"deb/etc/ufw/applications.d/syncthing\", perm: 0o644},\n\t\t\t{src: \"etc/linux-desktop/syncthing-start.desktop\", dst: \"deb/usr/share/applications/syncthing-start.desktop\", perm: 0o644},\n\t\t\t{src: \"etc/linux-desktop/syncthing-ui.desktop\", dst: \"deb/usr/share/applications/syncthing-ui.desktop\", perm: 0o644},\n\t\t\t{src: \"assets/logo-32.png\", dst: \"deb/usr/share/icons/hicolor/32x32/apps/syncthing.png\", perm: 0o644},\n\t\t\t{src: \"assets/logo-64.png\", dst: \"deb/usr/share/icons/hicolor/64x64/apps/syncthing.png\", perm: 0o644},\n\t\t\t{src: \"assets/logo-128.png\", dst: \"deb/usr/share/icons/hicolor/128x128/apps/syncthing.png\", perm: 0o644},\n\t\t\t{src: \"assets/logo-256.png\", dst: \"deb/usr/share/icons/hicolor/256x256/apps/syncthing.png\", perm: 0o644},\n\t\t\t{src: \"assets/logo-512.png\", dst: \"deb/usr/share/icons/hicolor/512x512/apps/syncthing.png\", perm: 0o644},\n\t\t\t{src: \"assets/logo-only.svg\", dst: \"deb/usr/share/icons/hicolor/scalable/apps/syncthing.svg\", perm: 0o644},\n\t\t},\n\t},\n\t\"stdiscosrv\": {\n\t\tname:        \"stdiscosrv\",\n\t\tdebname:     \"syncthing-discosrv\",\n\t\tdebdeps:     []string{\"libc6\"},\n\t\tdebpre:      \"cmd/stdiscosrv/scripts/preinst\",\n\t\tdescription: \"Syncthing Discovery Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/stdiscosrv\"},\n\t\tbinaryName:  \"stdiscosrv\", // .exe will be added automatically for Windows builds\n\t\tarchiveFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"{{binary}}\", perm: 0o755},\n\t\t\t{src: \"cmd/stdiscosrv/README.md\", dst: \"README.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"AUTHORS.txt\", perm: 0o644},\n\t\t},\n\t\tsystemdService: \"stdiscosrv.service\",\n\t\tinstallationFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"deb/usr/bin/{{binary}}\", perm: 0o755},\n\t\t\t{src: \"cmd/stdiscosrv/README.md\", dst: \"deb/usr/share/doc/syncthing-discosrv/README.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"deb/usr/share/doc/syncthing-discosrv/LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"deb/usr/share/doc/syncthing-discosrv/AUTHORS.txt\", perm: 0o644},\n\t\t\t{src: \"man/stdiscosrv.1\", dst: \"deb/usr/share/man/man1/stdiscosrv.1\", perm: 0o644},\n\t\t\t{src: \"cmd/stdiscosrv/etc/linux-systemd/stdiscosrv.service\", dst: \"deb/lib/systemd/system/stdiscosrv.service\", perm: 0o644},\n\t\t\t{src: \"cmd/stdiscosrv/etc/linux-systemd/default\", dst: \"deb/etc/default/syncthing-discosrv\", perm: 0o644},\n\t\t\t{src: \"cmd/stdiscosrv/etc/firewall-ufw/stdiscosrv\", dst: \"deb/etc/ufw/applications.d/stdiscosrv\", perm: 0o644},\n\t\t},\n\t},\n\t\"strelaysrv\": {\n\t\tname:        \"strelaysrv\",\n\t\tdebname:     \"syncthing-relaysrv\",\n\t\tdebdeps:     []string{\"libc6\"},\n\t\tdebpre:      \"cmd/strelaysrv/scripts/preinst\",\n\t\tdescription: \"Syncthing Relay Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/strelaysrv\"},\n\t\tbinaryName:  \"strelaysrv\", // .exe will be added automatically for Windows builds\n\t\tarchiveFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"{{binary}}\", perm: 0o755},\n\t\t\t{src: \"cmd/strelaysrv/README.md\", dst: \"README.txt\", perm: 0o644},\n\t\t\t{src: \"cmd/strelaysrv/LICENSE\", dst: \"LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"AUTHORS.txt\", perm: 0o644},\n\t\t},\n\t\tsystemdService: \"strelaysrv.service\",\n\t\tinstallationFiles: []archiveFile{\n\t\t\t{src: \"{{binary}}\", dst: \"deb/usr/bin/{{binary}}\", perm: 0o755},\n\t\t\t{src: \"cmd/strelaysrv/README.md\", dst: \"deb/usr/share/doc/syncthing-relaysrv/README.txt\", perm: 0o644},\n\t\t\t{src: \"cmd/strelaysrv/LICENSE\", dst: \"deb/usr/share/doc/syncthing-relaysrv/LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"LICENSE\", dst: \"deb/usr/share/doc/syncthing-relaysrv/LICENSE.txt\", perm: 0o644},\n\t\t\t{src: \"AUTHORS\", dst: \"deb/usr/share/doc/syncthing-relaysrv/AUTHORS.txt\", perm: 0o644},\n\t\t\t{src: \"man/strelaysrv.1\", dst: \"deb/usr/share/man/man1/strelaysrv.1\", perm: 0o644},\n\t\t\t{src: \"cmd/strelaysrv/etc/linux-systemd/strelaysrv.service\", dst: \"deb/lib/systemd/system/strelaysrv.service\", perm: 0o644},\n\t\t\t{src: \"cmd/strelaysrv/etc/linux-systemd/default\", dst: \"deb/etc/default/syncthing-relaysrv\", perm: 0o644},\n\t\t\t{src: \"cmd/strelaysrv/etc/firewall-ufw/strelaysrv\", dst: \"deb/etc/ufw/applications.d/strelaysrv\", perm: 0o644},\n\t\t},\n\t},\n\t\"strelaypoolsrv\": {\n\t\tname:        \"strelaypoolsrv\",\n\t\tdescription: \"Syncthing Relay Pool Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/infra/strelaypoolsrv\"},\n\t\tbinaryName:  \"strelaypoolsrv\",\n\t},\n\t\"stupgrades\": {\n\t\tname:        \"stupgrades\",\n\t\tdescription: \"Syncthing Upgrade Check Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/infra/stupgrades\"},\n\t\tbinaryName:  \"stupgrades\",\n\t},\n\t\"stcrashreceiver\": {\n\t\tname:        \"stcrashreceiver\",\n\t\tdescription: \"Syncthing Crash Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/infra/stcrashreceiver\"},\n\t\tbinaryName:  \"stcrashreceiver\",\n\t},\n\t\"ursrv\": {\n\t\tname:        \"ursrv\",\n\t\tdescription: \"Syncthing Usage Reporting Server\",\n\t\tbuildPkgs:   []string{\"github.com/syncthing/syncthing/cmd/infra/ursrv\"},\n\t\tbinaryName:  \"ursrv\",\n\t},\n}\n\nfunc initTargets() {\n\tall := targets[\"all\"]\n\tpkgs, _ := filepath.Glob(\"cmd/*\")\n\tfor _, pkg := range pkgs {\n\t\tif files, err := filepath.Glob(pkg + \"/*.go\"); err != nil || len(files) == 0 {\n\t\t\t// No go files in the directory\n\t\t\tcontinue\n\t\t}\n\t\tall.buildPkgs = append(all.buildPkgs, fmt.Sprintf(\"github.com/syncthing/syncthing/%s\", pkg))\n\t}\n\ttargets[\"all\"] = all\n\n\t// The \"syncthing\" target includes a few more files found in the \"etc\"\n\t// and \"extra\" dirs.\n\tsyncthingPkg := targets[\"syncthing\"]\n\tfor _, file := range listFiles(\"etc\") {\n\t\tsyncthingPkg.archiveFiles = append(syncthingPkg.archiveFiles, archiveFile{src: file, dst: file, perm: 0o644})\n\t}\n\tfor _, file := range listFiles(\"extra\") {\n\t\tsyncthingPkg.archiveFiles = append(syncthingPkg.archiveFiles, archiveFile{src: file, dst: file, perm: 0o644})\n\t}\n\tfor _, file := range listFiles(\"extra\") {\n\t\tsyncthingPkg.installationFiles = append(syncthingPkg.installationFiles, archiveFile{src: file, dst: \"deb/usr/share/doc/syncthing/\" + filepath.Base(file), perm: 0o644})\n\t}\n\ttargets[\"syncthing\"] = syncthingPkg\n}\n\nfunc main() {\n\tlog.SetFlags(0)\n\n\tparseFlags()\n\n\tif debug {\n\t\tt0 := time.Now()\n\t\tdefer func() {\n\t\t\tlog.Println(\"... build completed in\", time.Since(t0))\n\t\t}()\n\t}\n\n\tinitTargets()\n\n\t// Invoking build.go with no parameters at all builds everything (incrementally),\n\t// which is what you want for maximum error checking during development.\n\tif flag.NArg() == 0 {\n\t\trunCommand(\"install\", targets[\"all\"])\n\t} else {\n\t\t// with any command given but not a target, the target is\n\t\t// \"syncthing\". So \"go run build.go install\" is \"go run build.go install\n\t\t// syncthing\" etc.\n\t\ttargetName := \"syncthing\"\n\t\tif flag.NArg() > 1 {\n\t\t\ttargetName = flag.Arg(1)\n\t\t}\n\t\ttarget, ok := targets[targetName]\n\t\tif !ok {\n\t\t\tlog.Fatalln(\"Unknown target\", target)\n\t\t}\n\n\t\trunCommand(flag.Arg(0), target)\n\t}\n}\n\nfunc runCommand(cmd string, target target) {\n\tvar tags []string\n\tif noupgrade {\n\t\ttags = []string{\"noupgrade\"}\n\t}\n\ttags = append(tags, strings.Fields(extraTags)...)\n\n\tswitch cmd {\n\tcase \"install\":\n\t\tinstall(target, tags)\n\t\tmetalintShort()\n\n\tcase \"build\":\n\t\tbuild(target, tags)\n\n\tcase \"test\":\n\t\ttest(strings.Fields(extraTags), \"github.com/syncthing/syncthing/lib/...\", \"github.com/syncthing/syncthing/cmd/...\")\n\n\tcase \"bench\":\n\t\tbench(strings.Fields(extraTags), \"github.com/syncthing/syncthing/lib/...\", \"github.com/syncthing/syncthing/cmd/...\")\n\n\tcase \"integration\":\n\t\tintegration(false)\n\n\tcase \"integrationbench\":\n\t\tintegration(true)\n\n\tcase \"assets\":\n\t\trebuildAssets()\n\n\tcase \"update-deps\":\n\t\tupdateDependencies()\n\n\tcase \"proto\":\n\t\tproto()\n\n\tcase \"testmocks\":\n\t\ttestmocks()\n\n\tcase \"translate\":\n\t\ttranslate()\n\n\tcase \"transifex\":\n\t\ttransifex()\n\n\tcase \"weblate\":\n\t\tweblate()\n\n\tcase \"tar\":\n\t\tbuildTar(target, tags)\n\t\twriteCompatJSON()\n\n\tcase \"zip\":\n\t\tbuildZip(target, tags)\n\t\twriteCompatJSON()\n\n\tcase \"deb\":\n\t\tbuildDeb(target)\n\n\tcase \"vet\":\n\t\tmetalintShort()\n\n\tcase \"lint\":\n\t\tmetalintShort()\n\n\tcase \"metalint\":\n\t\tmetalint()\n\n\tcase \"version\":\n\t\tfmt.Println(getVersion())\n\n\tcase \"changelog\":\n\t\tvers, err := currentAndLatestVersions(numVersions)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfor _, ver := range vers {\n\t\t\tunderline := strings.Repeat(\"=\", len(ver))\n\t\t\tmsg, err := tagMessage(ver)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tfmt.Printf(\"%s\\n%s\\n\\n%s\\n\\n\", ver, underline, msg)\n\t\t}\n\n\tdefault:\n\t\tlog.Fatalf(\"Unknown command %q\", cmd)\n\t}\n}\n\nfunc parseFlags() {\n\tflag.StringVar(&goarch, \"goarch\", runtime.GOARCH, \"GOARCH\")\n\tflag.StringVar(&goos, \"goos\", runtime.GOOS, \"GOOS\")\n\tflag.StringVar(&goCmd, \"gocmd\", \"go\", \"Specify `go` command\")\n\tflag.BoolVar(&noupgrade, \"no-upgrade\", noupgrade, \"Disable upgrade functionality\")\n\tflag.StringVar(&version, \"version\", getVersion(), \"Set compiled in version string\")\n\tflag.BoolVar(&race, \"race\", race, \"Use race detector\")\n\tflag.StringVar(&extraTags, \"tags\", extraTags, \"Extra tags, space separated\")\n\tflag.StringVar(&installSuffix, \"installsuffix\", installSuffix, \"Install suffix, optional\")\n\tflag.StringVar(&pkgdir, \"pkgdir\", \"\", \"Set -pkgdir parameter for `go build`\")\n\tflag.StringVar(&cc, \"cc\", os.Getenv(\"CC\"), \"Set CC environment variable for `go build`\")\n\tflag.BoolVar(&debugBinary, \"debug-binary\", debugBinary, \"Create unoptimized binary to use with delve, set -gcflags='-N -l' and omit -ldflags\")\n\tflag.BoolVar(&coverage, \"coverage\", coverage, \"Write coverage profile of tests to coverage.txt\")\n\tflag.BoolVar(&long, \"long\", long, \"Run tests without the -short flag\")\n\tflag.IntVar(&numVersions, \"num-versions\", numVersions, \"Number of versions for changelog command\")\n\tflag.StringVar(&run, \"run\", \"\", \"Specify which tests to run\")\n\tflag.StringVar(&benchRun, \"bench\", \"\", \"Specify which benchmarks to run\")\n\tflag.BoolVar(&withNextGenGUI, \"with-next-gen-gui\", withNextGenGUI, \"Also build 'newgui'\")\n\tflag.StringVar(&buildOut, \"build-out\", \"\", \"Set the '-o' value for 'go build'\")\n\tflag.Parse()\n}\n\nfunc test(tags []string, pkgs ...string) {\n\tlazyRebuildAssets()\n\n\targs := []string{\"test\", \"-tags\", strings.Join(tags, \" \")}\n\tif long {\n\t\ttimeout = longTimeout\n\t} else {\n\t\targs = append(args, \"-short\")\n\t}\n\targs = append(args, \"-timeout\", timeout)\n\n\tif runtime.GOARCH == \"amd64\" {\n\t\tswitch runtime.GOOS {\n\t\tcase buildpkg.Darwin, buildpkg.Linux, buildpkg.FreeBSD: // , \"windows\": # See https://github.com/golang/go/issues/27089\n\t\t\targs = append(args, \"-race\")\n\t\t}\n\t}\n\n\tif coverage {\n\t\targs = append(args, \"-covermode\", \"atomic\", \"-coverprofile\", \"coverage.txt\", \"-coverpkg\", strings.Join(pkgs, \",\"))\n\t}\n\n\targs = append(args, runArgs()...)\n\n\trunPrint(goCmd, append(args, pkgs...)...)\n}\n\nfunc bench(tags []string, pkgs ...string) {\n\tlazyRebuildAssets()\n\targs := append([]string{\"test\", \"-run\", \"NONE\", \"-tags\", strings.Join(tags, \" \")}, benchArgs()...)\n\trunPrint(goCmd, append(args, pkgs...)...)\n}\n\nfunc integration(bench bool) {\n\tlazyRebuildAssets()\n\targs := []string{\"test\", \"-v\", \"-timeout\", \"60m\", \"-tags\"}\n\ttags := \"integration\"\n\tif bench {\n\t\ttags += \",benchmark\"\n\t}\n\targs = append(args, tags)\n\targs = append(args, runArgs()...)\n\tif bench {\n\t\tif run == \"\" {\n\t\t\targs = append(args, \"-run\", \"Benchmark\")\n\t\t}\n\t\targs = append(args, benchArgs()...)\n\t}\n\targs = append(args, \"./test\")\n\tfmt.Println(args)\n\trunPrint(goCmd, args...)\n}\n\nfunc runArgs() []string {\n\tif run == \"\" {\n\t\treturn nil\n\t}\n\treturn []string{\"-run\", run}\n}\n\nfunc benchArgs() []string {\n\tif benchRun == \"\" {\n\t\treturn []string{\"-bench\", \".\"}\n\t}\n\treturn []string{\"-bench\", benchRun}\n}\n\nfunc install(target target, tags []string) {\n\tif (target.name == \"syncthing\" || target.name == \"\") && !withNextGenGUI {\n\t\tlog.Println(\"Notice: Next generation GUI will not be built; see --with-next-gen-gui.\")\n\t}\n\n\tlazyRebuildAssets()\n\n\ttags = append(target.tags, tags...)\n\n\tcwd, err := os.Getwd()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tos.Setenv(\"GOBIN\", filepath.Join(cwd, \"bin\"))\n\n\tsetBuildEnvVars()\n\n\t// On Windows generate a special file which the Go compiler will\n\t// automatically use when generating Windows binaries to set things like\n\t// the file icon, version, etc.\n\tif goos == \"windows\" {\n\t\tsysoPath, err := shouldBuildSyso(cwd)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Warning: Windows binaries will not have file information encoded: %v\", err)\n\t\t}\n\t\tdefer shouldCleanupSyso(sysoPath)\n\t}\n\n\targs := []string{\"install\", \"-v\"}\n\targs = appendParameters(args, tags, target.buildPkgs...)\n\trunPrint(goCmd, args...)\n}\n\nfunc build(target target, tags []string) {\n\tif (target.name == \"syncthing\" || target.name == \"\") && !withNextGenGUI {\n\t\tlog.Println(\"Notice: Next generation GUI will not be built; see --with-next-gen-gui.\")\n\t}\n\n\tlazyRebuildAssets()\n\ttags = append(target.tags, tags...)\n\n\trmr(target.BinaryName())\n\n\tsetBuildEnvVars()\n\n\t// On Windows generate a special file which the Go compiler will\n\t// automatically use when generating Windows binaries to set things like\n\t// the file icon, version, etc.\n\tif goos == \"windows\" {\n\t\tcwd, err := os.Getwd()\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tsysoPath, err := shouldBuildSyso(cwd)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Warning: Windows binaries will not have file information encoded: %v\", err)\n\t\t}\n\t\tdefer shouldCleanupSyso(sysoPath)\n\t}\n\n\targs := []string{\"build\", \"-v\"}\n\tif buildOut != \"\" {\n\t\targs = append(args, \"-o\", buildOut)\n\t}\n\targs = appendParameters(args, tags, target.buildPkgs...)\n\trunPrint(goCmd, args...)\n}\n\nfunc setBuildEnvVars() {\n\tos.Setenv(\"GOOS\", goos)\n\tos.Setenv(\"GOARCH\", goarch)\n\tos.Setenv(\"CC\", cc)\n\tif os.Getenv(\"CGO_ENABLED\") == \"\" {\n\t\tswitch goos {\n\t\tcase \"darwin\", \"solaris\":\n\t\tdefault:\n\t\t\tos.Setenv(\"CGO_ENABLED\", \"0\")\n\t\t}\n\t}\n}\n\nfunc appendParameters(args []string, tags []string, pkgs ...string) []string {\n\tif pkgdir != \"\" {\n\t\targs = append(args, \"-pkgdir\", pkgdir)\n\t}\n\tif len(tags) > 0 {\n\t\targs = append(args, \"-tags\", strings.Join(tags, \" \"))\n\t}\n\tif installSuffix != \"\" {\n\t\targs = append(args, \"-installsuffix\", installSuffix)\n\t}\n\tif race {\n\t\targs = append(args, \"-race\")\n\t}\n\n\tif !debugBinary {\n\t\t// Regular binaries get version tagged and skip some debug symbols\n\t\targs = append(args, \"-trimpath\", \"-ldflags\", ldflags(tags))\n\t} else {\n\t\t// -gcflags to disable optimizations and inlining. Skip -ldflags\n\t\t// because `Could not launch program: decoding dwarf section info at\n\t\t// offset 0x0: too short` on 'dlv exec ...' see\n\t\t// https://github.com/go-delve/delve/issues/79\n\t\targs = append(args, \"-gcflags\", \"all=-N -l\")\n\t}\n\n\treturn append(args, pkgs...)\n}\n\nfunc buildTar(target target, tags []string) {\n\tname := archiveName(target)\n\tfilename := name + \".tar.gz\"\n\n\tfor _, tag := range tags {\n\t\tif tag == \"noupgrade\" {\n\t\t\tname += \"-noupgrade\"\n\t\t\tbreak\n\t\t}\n\t}\n\n\tbuild(target, tags)\n\tcodesign(target)\n\n\tfor i := range target.archiveFiles {\n\t\ttarget.archiveFiles[i].src = strings.Replace(target.archiveFiles[i].src, \"{{binary}}\", target.BinaryName(), 1)\n\t\ttarget.archiveFiles[i].dst = strings.Replace(target.archiveFiles[i].dst, \"{{binary}}\", target.BinaryName(), 1)\n\t\ttarget.archiveFiles[i].dst = name + \"/\" + target.archiveFiles[i].dst\n\t}\n\n\ttarGz(filename, target.archiveFiles)\n\tfmt.Println(filename)\n}\n\nfunc buildZip(target target, tags []string) {\n\tname := archiveName(target)\n\tfilename := name + \".zip\"\n\n\tfor _, tag := range tags {\n\t\tif tag == \"noupgrade\" {\n\t\t\tname += \"-noupgrade\"\n\t\t\tbreak\n\t\t}\n\t}\n\n\tbuild(target, tags)\n\tcodesign(target)\n\n\tfor i := range target.archiveFiles {\n\t\ttarget.archiveFiles[i].src = strings.Replace(target.archiveFiles[i].src, \"{{binary}}\", target.BinaryName(), 1)\n\t\ttarget.archiveFiles[i].dst = strings.Replace(target.archiveFiles[i].dst, \"{{binary}}\", target.BinaryName(), 1)\n\t\ttarget.archiveFiles[i].dst = name + \"/\" + target.archiveFiles[i].dst\n\t}\n\n\tzipFile(filename, target.archiveFiles)\n\tfmt.Println(filename)\n}\n\nfunc buildDeb(target target) {\n\tos.RemoveAll(\"deb\")\n\n\t// \"goarch\" here is set to whatever the Debian packages expect. We correct\n\t// it to what we actually know how to build and keep the Debian variant\n\t// name in \"debarch\".\n\tdebarch := goarch\n\tswitch goarch {\n\tcase \"i386\":\n\t\tgoarch = \"386\"\n\tcase \"armel\", \"armhf\":\n\t\tgoarch = \"arm\"\n\t}\n\n\tbuild(target, []string{\"noupgrade\"})\n\n\tfor i := range target.installationFiles {\n\t\ttarget.installationFiles[i].src = strings.Replace(target.installationFiles[i].src, \"{{binary}}\", target.BinaryName(), 1)\n\t\ttarget.installationFiles[i].dst = strings.Replace(target.installationFiles[i].dst, \"{{binary}}\", target.BinaryName(), 1)\n\t}\n\n\tfor _, af := range target.installationFiles {\n\t\tif err := copyFile(af.src, af.dst, af.perm); err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}\n\n\tmaintainer := \"Syncthing Release Management <release@syncthing.net>\"\n\tdebver := version\n\tif strings.HasPrefix(debver, \"v\") {\n\t\tdebver = debver[1:]\n\t\t// Debian interprets dashes as separator between main version and\n\t\t// Debian package version, and thus thinks 0.14.26-rc.1 is better\n\t\t// than just 0.14.26. This rectifies that.\n\t\tdebver = strings.Replace(debver, \"-\", \"~\", -1)\n\t}\n\targs := []string{\n\t\t\"-t\", \"deb\",\n\t\t\"-s\", \"dir\",\n\t\t\"-C\", \"deb\",\n\t\t\"-n\", target.debname,\n\t\t\"-v\", debver,\n\t\t\"-a\", debarch,\n\t\t\"-m\", maintainer,\n\t\t\"--vendor\", maintainer,\n\t\t\"--description\", target.description,\n\t\t\"--url\", \"https://syncthing.net/\",\n\t\t\"--license\", \"MPL-2\",\n\t}\n\tfor _, dep := range target.debdeps {\n\t\targs = append(args, \"-d\", dep)\n\t}\n\tif target.systemdService != \"\" {\n\t\tdebpost, err := createPostInstScript(target)\n\t\tdefer os.Remove(debpost)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\targs = append(args, \"--after-upgrade\", debpost)\n\t}\n\tif target.debpre != \"\" {\n\t\targs = append(args, \"--before-install\", target.debpre)\n\t}\n\trunPrint(\"fpm\", args...)\n}\n\nfunc createPostInstScript(target target) (string, error) {\n\tscriptname := filepath.Join(\"script\", \"deb-post-inst.template\")\n\tt, err := template.ParseFiles(scriptname)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tscriptname = strings.TrimSuffix(scriptname, \".template\")\n\tw, err := os.Create(scriptname)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdefer w.Close()\n\tif err = t.Execute(w, struct {\n\t\tService, Command string\n\t}{\n\t\ttarget.systemdService, target.binaryName,\n\t}); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn scriptname, nil\n}\n\nfunc shouldBuildSyso(dir string) (string, error) {\n\ttype M map[string]interface{}\n\tversion := getVersion()\n\tversion = strings.TrimPrefix(version, \"v\")\n\tmajor, minor, patch := semanticVersion()\n\tbs, err := json.Marshal(M{\n\t\t\"FixedFileInfo\": M{\n\t\t\t\"FileVersion\": M{\n\t\t\t\t\"Major\": major,\n\t\t\t\t\"Minor\": minor,\n\t\t\t\t\"Patch\": patch,\n\t\t\t},\n\t\t\t\"ProductVersion\": M{\n\t\t\t\t\"Major\": major,\n\t\t\t\t\"Minor\": minor,\n\t\t\t\t\"Patch\": patch,\n\t\t\t},\n\t\t},\n\t\t\"StringFileInfo\": M{\n\t\t\t\"CompanyName\":      \"The Syncthing Authors\",\n\t\t\t\"FileDescription\":  \"Syncthing - Open Source Continuous File Synchronization\",\n\t\t\t\"FileVersion\":      version,\n\t\t\t\"InternalName\":     \"syncthing\",\n\t\t\t\"LegalCopyright\":   \"The Syncthing Authors\",\n\t\t\t\"OriginalFilename\": \"syncthing\",\n\t\t\t\"ProductName\":      \"Syncthing\",\n\t\t\t\"ProductVersion\":   version,\n\t\t},\n\t\t\"IconPath\": \"assets/logo.ico\",\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tjsonPath := filepath.Join(dir, \"versioninfo.json\")\n\terr = os.WriteFile(jsonPath, bs, 0o644)\n\tif err != nil {\n\t\treturn \"\", errors.New(\"failed to create \" + jsonPath + \": \" + err.Error())\n\t}\n\n\tdefer func() {\n\t\tif err := os.Remove(jsonPath); err != nil {\n\t\t\tlog.Printf(\"Warning: unable to remove generated %s: %v. Please remove it manually.\", jsonPath, err)\n\t\t}\n\t}()\n\n\tsysoPath := filepath.Join(dir, \"cmd\", \"syncthing\", \"resource.syso\")\n\n\t// See https://github.com/josephspurrier/goversioninfo#command-line-flags\n\tarmOption := \"\"\n\tif strings.Contains(goarch, \"arm\") {\n\t\tarmOption = \"-arm=true\"\n\t}\n\n\tif _, err := runError(\"goversioninfo\", \"-o\", sysoPath, armOption); err != nil {\n\t\treturn \"\", errors.New(\"failed to create \" + sysoPath + \": \" + err.Error())\n\t}\n\n\treturn sysoPath, nil\n}\n\nfunc shouldCleanupSyso(sysoFilePath string) {\n\tif sysoFilePath == \"\" {\n\t\treturn\n\t}\n\tif err := os.Remove(sysoFilePath); err != nil {\n\t\tlog.Printf(\"Warning: unable to remove generated %s: %v. Please remove it manually.\", sysoFilePath, err)\n\t}\n}\n\n// copyFile copies a file from src to dst, ensuring the containing directory\n// exists. The permission bits are copied as well. If dst already exists and\n// the contents are identical to src the modification time is not updated.\nfunc copyFile(src, dst string, perm os.FileMode) error {\n\tin, err := os.ReadFile(src)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tout, err := os.ReadFile(dst)\n\tif err != nil {\n\t\t// The destination probably doesn't exist, we should create\n\t\t// it.\n\t\tgoto copy\n\t}\n\n\tif bytes.Equal(in, out) {\n\t\t// The permission bits may have changed without the contents\n\t\t// changing so we always mirror them.\n\t\tos.Chmod(dst, perm)\n\t\treturn nil\n\t}\n\ncopy:\n\tos.MkdirAll(filepath.Dir(dst), 0o777)\n\tif err := os.WriteFile(dst, in, perm); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc listFiles(dir string) []string {\n\tvar res []string\n\tfilepath.Walk(dir, func(path string, fi os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif fi.Mode().IsRegular() {\n\t\t\tres = append(res, path)\n\t\t}\n\t\treturn nil\n\t})\n\treturn res\n}\n\nfunc rebuildAssets() {\n\tos.Setenv(\"SOURCE_DATE_EPOCH\", fmt.Sprint(buildStamp()))\n\trunPrint(goCmd, \"generate\", \"github.com/syncthing/syncthing/lib/api/auto\", \"github.com/syncthing/syncthing/cmd/infra/strelaypoolsrv/auto\")\n}\n\nfunc lazyRebuildAssets() {\n\tshouldRebuild := shouldRebuildAssets(\"lib/api/auto/gui.files.go\", \"gui\") ||\n\t\tshouldRebuildAssets(\"cmd/infra/strelaypoolsrv/auto/gui.files.go\", \"cmd/infra/strelaypoolsrv/gui\")\n\n\tif withNextGenGUI {\n\t\tshouldRebuild = buildNextGenGUI() || shouldRebuild\n\t}\n\n\tif shouldRebuild {\n\t\trebuildAssets()\n\t}\n}\n\nfunc buildNextGenGUI() bool {\n\t// Check if we need to run the npm process, and if so also set the flag\n\t// to rebuild Go assets afterwards. The index.html is regenerated every\n\t// time by the build process. This assumes the new GUI ends up in\n\t// next-gen-gui/dist/next-gen-gui.\n\n\tif !shouldRebuildAssets(\"gui/next-gen-gui/index.html\", \"next-gen-gui\") {\n\t\t// The GUI is up to date.\n\t\treturn false\n\t}\n\n\trunPrintInDir(\"next-gen-gui\", \"npm\", \"install\")\n\trunPrintInDir(\"next-gen-gui\", \"npm\", \"run\", \"build\", \"--\", \"--prod\", \"--subresource-integrity\")\n\n\trmr(\"gui/tech-ui\")\n\n\tfor _, src := range listFiles(\"next-gen-gui/dist\") {\n\t\trel, _ := filepath.Rel(\"next-gen-gui/dist\", src)\n\t\tdst := filepath.Join(\"gui\", rel)\n\t\tif err := copyFile(src, dst, 0o644); err != nil {\n\t\t\tfmt.Println(\"copy:\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc shouldRebuildAssets(target, srcdir string) bool {\n\tinfo, err := os.Stat(target)\n\tif err != nil {\n\t\t// If the file doesn't exist, we must rebuild it\n\t\treturn true\n\t}\n\n\t// Check if any of the files in gui/ are newer than the asset file. If\n\t// so we should rebuild it.\n\tcurrentBuild := info.ModTime()\n\tassetsAreNewer := false\n\tstop := errors.New(\"no need to iterate further\")\n\tfilepath.Walk(srcdir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif info.ModTime().After(currentBuild) {\n\t\t\tassetsAreNewer = true\n\t\t\treturn stop\n\t\t}\n\t\treturn nil\n\t})\n\n\treturn assetsAreNewer\n}\n\nfunc updateDependencies() {\n\t// Figure out desired Go version\n\tbs, err := os.ReadFile(\"go.mod\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tre := regexp.MustCompile(`(?m)^go\\s+([0-9.]+)`)\n\tmatches := re.FindSubmatch(bs)\n\tif len(matches) != 2 {\n\t\tlog.Fatal(\"failed to parse go.mod\")\n\t}\n\tgoVersion := string(matches[1])\n\n\trunPrint(goCmd, \"get\", \"-u\", \"./...\")\n\trunPrint(goCmd, \"mod\", \"tidy\", \"-go=\"+goVersion, \"-compat=\"+goVersion)\n\n\t// We might have updated the protobuf package and should regenerate to match.\n\tproto()\n}\n\nfunc proto() {\n\t// buf needs to be installed\n\t// https://buf.build/docs/installation/\n\trunPrint(\"buf\", \"generate\")\n}\n\nfunc testmocks() {\n\targs := []string{\n\t\t\"generate\",\n\t\t\"github.com/syncthing/syncthing/lib/config\",\n\t\t\"github.com/syncthing/syncthing/lib/connections\",\n\t\t\"github.com/syncthing/syncthing/lib/discover\",\n\t\t\"github.com/syncthing/syncthing/lib/events\",\n\t\t\"github.com/syncthing/syncthing/lib/logger\",\n\t\t\"github.com/syncthing/syncthing/lib/model\",\n\t\t\"github.com/syncthing/syncthing/lib/protocol\",\n\t}\n\trunPrint(goCmd, args...)\n}\n\nfunc translate() {\n\tos.Chdir(\"gui/default/assets/lang\")\n\trunPipe(\"lang-en-new.json\", goCmd, \"run\", \"../../../../script/translate.go\", \"lang-en.json\", \"../../../\")\n\tos.Remove(\"lang-en.json\")\n\terr := os.Rename(\"lang-en-new.json\", \"lang-en.json\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tos.Chdir(\"../../../..\")\n}\n\nfunc transifex() {\n\tos.Chdir(\"gui/default/assets/lang\")\n\trunPrint(goCmd, \"run\", \"../../../../script/transifexdl.go\")\n}\n\nfunc weblate() {\n\tos.Chdir(\"gui/default/assets/lang\")\n\trunPrint(goCmd, \"run\", \"../../../../script/weblatedl.go\")\n}\n\nfunc ldflags(tags []string) string {\n\tb := new(strings.Builder)\n\tb.WriteString(\"-w\")\n\tfmt.Fprintf(b, \" -X github.com/syncthing/syncthing/lib/build.Version=%s\", version)\n\tfmt.Fprintf(b, \" -X github.com/syncthing/syncthing/lib/build.Stamp=%d\", buildStamp())\n\tfmt.Fprintf(b, \" -X github.com/syncthing/syncthing/lib/build.User=%s\", buildUser())\n\tfmt.Fprintf(b, \" -X github.com/syncthing/syncthing/lib/build.Host=%s\", buildHost())\n\tfmt.Fprintf(b, \" -X github.com/syncthing/syncthing/lib/build.Tags=%s\", strings.Join(tags, \",\"))\n\tif v := os.Getenv(\"EXTRA_LDFLAGS\"); v != \"\" {\n\t\tfmt.Fprintf(b, \" %s\", v)\n\t}\n\treturn b.String()\n}\n\nfunc rmr(paths ...string) {\n\tfor _, path := range paths {\n\t\tif debug {\n\t\t\tlog.Println(\"rm -r\", path)\n\t\t}\n\t\tos.RemoveAll(path)\n\t}\n}\n\nfunc getReleaseVersion() (string, error) {\n\tbs, err := os.ReadFile(\"RELEASE\")\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(bytes.TrimSpace(bs)), nil\n}\n\nfunc getGitVersion() (string, error) {\n\t// The current version as Git sees it\n\tbs, err := runError(\"git\", \"describe\", \"--always\", \"--dirty\", \"--abbrev=8\")\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tvcur := string(bs)\n\n\t// The closest current tag name\n\tbs, err = runError(\"git\", \"describe\", \"--always\", \"--abbrev=0\")\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tv0 := string(bs)\n\n\t// To be more semantic-versionish and ensure proper ordering in our\n\t// upgrade process, we make sure there's only one hyphen in the version.\n\n\tversionRe := regexp.MustCompile(`-([0-9]{1,3}-g[0-9a-f]{5,10}(-dirty)?)`)\n\tif m := versionRe.FindStringSubmatch(vcur); len(m) > 0 {\n\t\tsuffix := strings.ReplaceAll(m[1], \"-\", \".\")\n\n\t\tif strings.Contains(v0, \"-\") {\n\t\t\t// We're based of a tag with a prerelease string. We can just\n\t\t\t// add our dev stuff directly.\n\t\t\treturn fmt.Sprintf(\"%s.dev.%s\", v0, suffix), nil\n\t\t}\n\n\t\t// We're based on a release version. We need to bump the patch\n\t\t// version and then add a -dev prerelease string.\n\t\tnext := nextPatchVersion(v0)\n\t\treturn fmt.Sprintf(\"%s-dev.%s\", next, suffix), nil\n\t}\n\treturn vcur, nil\n}\n\nfunc getVersion() string {\n\t// First try for a RELEASE file,\n\tif ver, err := getReleaseVersion(); err == nil {\n\t\treturn ver\n\t}\n\t// ... then see if we have a Git tag.\n\tif ver, err := getGitVersion(); err == nil {\n\t\tif strings.Contains(ver, \"-\") {\n\t\t\t// The version already contains a hash and stuff. See if we can\n\t\t\t// find a current branch name to tack onto it as well.\n\t\t\treturn ver + getBranchSuffix()\n\t\t}\n\t\treturn ver\n\t}\n\t// This seems to be a dev build.\n\treturn \"unknown-dev\"\n}\n\nfunc semanticVersion() (major, minor, patch int) {\n\tr := regexp.MustCompile(`v(\\d+)\\.(\\d+).(\\d+)`)\n\tmatches := r.FindStringSubmatch(getVersion())\n\tif len(matches) != 4 {\n\t\treturn 0, 0, 0\n\t}\n\n\tvar ints [3]int\n\tfor i, s := range matches[1:] {\n\t\tints[i], _ = strconv.Atoi(s)\n\t}\n\treturn ints[0], ints[1], ints[2]\n}\n\nfunc getBranchSuffix() string {\n\tbs, err := runError(\"git\", \"branch\", \"-a\", \"--contains\")\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\n\tbranches := strings.Split(string(bs), \"\\n\")\n\tif len(branches) == 0 {\n\t\treturn \"\"\n\t}\n\n\tbranch := \"\"\n\tfor i, candidate := range branches {\n\t\tif strings.HasPrefix(candidate, \"*\") {\n\t\t\t// This is the current branch. Select it!\n\t\t\tbranch = strings.TrimLeft(candidate, \" \\t*\")\n\t\t\tbreak\n\t\t} else if i == 0 {\n\t\t\t// Otherwise the first branch in the list will do.\n\t\t\tbranch = strings.TrimSpace(branch)\n\t\t}\n\t}\n\n\tif branch == \"\" {\n\t\treturn \"\"\n\t}\n\n\t// The branch name may be on the form \"remotes/origin/foo\" from which we\n\t// just want \"foo\".\n\tparts := strings.Split(branch, \"/\")\n\tif len(parts) == 0 || len(parts[len(parts)-1]) == 0 {\n\t\treturn \"\"\n\t}\n\n\tbranch = parts[len(parts)-1]\n\tswitch branch {\n\tcase \"release\", \"main\":\n\t\t// these are not special\n\t\treturn \"\"\n\t}\n\tif strings.HasPrefix(branch, \"release-\") {\n\t\t// release branches are not special\n\t\treturn \"\"\n\t}\n\n\tvalidBranchRe := regexp.MustCompile(`^[a-zA-Z0-9_.-]+$`)\n\tif !validBranchRe.MatchString(branch) {\n\t\t// There's some odd stuff in the branch name. Better skip it.\n\t\treturn \"\"\n\t}\n\n\treturn \"-\" + branch\n}\n\nfunc buildStamp() int64 {\n\t// If SOURCE_DATE_EPOCH is set, use that.\n\tif s, _ := strconv.ParseInt(os.Getenv(\"SOURCE_DATE_EPOCH\"), 10, 64); s > 0 {\n\t\treturn s\n\t}\n\n\t// Try to get the timestamp of the latest commit.\n\tbs, err := runError(\"git\", \"show\", \"-s\", \"--format=%ct\")\n\tif err != nil {\n\t\t// Fall back to \"now\".\n\t\treturn time.Now().Unix()\n\t}\n\n\ts, _ := strconv.ParseInt(string(bs), 10, 64)\n\treturn s\n}\n\nfunc buildUser() string {\n\tif v := os.Getenv(\"BUILD_USER\"); v != \"\" {\n\t\treturn v\n\t}\n\n\tu, err := user.Current()\n\tif err != nil {\n\t\treturn \"unknown-user\"\n\t}\n\treturn strings.Replace(u.Username, \" \", \"-\", -1)\n}\n\nfunc buildHost() string {\n\tif v := os.Getenv(\"BUILD_HOST\"); v != \"\" {\n\t\treturn v\n\t}\n\n\th, err := os.Hostname()\n\tif err != nil {\n\t\treturn \"unknown-host\"\n\t}\n\treturn h\n}\n\nfunc buildArch() string {\n\tos := goos\n\tif os == \"darwin\" {\n\t\tos = \"macos\"\n\t}\n\treturn fmt.Sprintf(\"%s-%s\", os, goarch)\n}\n\nfunc archiveName(target target) string {\n\treturn fmt.Sprintf(\"%s-%s-%s\", target.name, buildArch(), version)\n}\n\nfunc runError(cmd string, args ...string) ([]byte, error) {\n\tif debug {\n\t\tt0 := time.Now()\n\t\tlog.Println(\"runError:\", cmd, strings.Join(args, \" \"))\n\t\tdefer func() {\n\t\t\tlog.Println(\"... in\", time.Since(t0))\n\t\t}()\n\t}\n\tecmd := exec.Command(cmd, args...)\n\tbs, err := ecmd.CombinedOutput()\n\treturn bytes.TrimSpace(bs), err\n}\n\nfunc runPrint(cmd string, args ...string) {\n\trunPrintInDir(\".\", cmd, args...)\n}\n\nfunc runPrintInDir(dir string, cmd string, args ...string) {\n\tif debug {\n\t\tt0 := time.Now()\n\t\tlog.Println(\"runPrint:\", cmd, strings.Join(args, \" \"))\n\t\tdefer func() {\n\t\t\tlog.Println(\"... in\", time.Since(t0))\n\t\t}()\n\t}\n\tecmd := exec.Command(cmd, args...)\n\tecmd.Stdout = os.Stdout\n\tecmd.Stderr = os.Stderr\n\tecmd.Dir = dir\n\terr := ecmd.Run()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc runPipe(file, cmd string, args ...string) {\n\tif debug {\n\t\tt0 := time.Now()\n\t\tlog.Println(\"runPipe:\", cmd, strings.Join(args, \" \"))\n\t\tdefer func() {\n\t\t\tlog.Println(\"... in\", time.Since(t0))\n\t\t}()\n\t}\n\tfd, err := os.Create(file)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tecmd := exec.Command(cmd, args...)\n\tecmd.Stdout = fd\n\tecmd.Stderr = os.Stderr\n\terr = ecmd.Run()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfd.Close()\n}\n\nfunc tarGz(out string, files []archiveFile) {\n\tfd, err := os.Create(out)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tgw, err := gzip.NewWriterLevel(fd, gzip.BestCompression)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\ttw := tar.NewWriter(gw)\n\n\tfor _, f := range files {\n\t\tsf, err := os.Open(f.src)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\tinfo, err := sf.Stat()\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\th := &tar.Header{\n\t\t\tName:    f.dst,\n\t\t\tSize:    info.Size(),\n\t\t\tMode:    int64(info.Mode()),\n\t\t\tModTime: info.ModTime(),\n\t\t}\n\n\t\terr = tw.WriteHeader(h)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\t_, err = io.Copy(tw, sf)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tsf.Close()\n\t}\n\n\terr = tw.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = gw.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = fd.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc zipFile(out string, files []archiveFile) {\n\tfd, err := os.Create(out)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tzw := zip.NewWriter(fd)\n\n\tvar fw *flate.Writer\n\n\t// Register the deflator.\n\tzw.RegisterCompressor(zip.Deflate, func(out io.Writer) (io.WriteCloser, error) {\n\t\tvar err error\n\t\tif fw == nil {\n\t\t\t// Creating a flate compressor for every file is\n\t\t\t// expensive, create one and reuse it.\n\t\t\tfw, err = flate.NewWriter(out, flate.BestCompression)\n\t\t} else {\n\t\t\tfw.Reset(out)\n\t\t}\n\t\treturn fw, err\n\t})\n\n\tfor _, f := range files {\n\t\tsf, err := os.Open(f.src)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\tinfo, err := sf.Stat()\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\tfh, err := zip.FileInfoHeader(info)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfh.Name = filepath.ToSlash(f.dst)\n\t\tfh.Method = zip.Deflate\n\n\t\tif strings.HasSuffix(f.dst, \".txt\") {\n\t\t\t// Text file. Read it and convert line endings.\n\t\t\tbs, err := io.ReadAll(sf)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tbs = bytes.Replace(bs, []byte{'\\n'}, []byte{'\\r', '\\n'}, -1)\n\t\t\tfh.UncompressedSize = uint32(len(bs))\n\t\t\tfh.UncompressedSize64 = uint64(len(bs))\n\n\t\t\tof, err := zw.CreateHeader(fh)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tof.Write(bs)\n\t\t} else {\n\t\t\t// Binary file. Copy verbatim.\n\t\t\tof, err := zw.CreateHeader(fh)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\t_, err = io.Copy(of, sf)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t}\n\t}\n\n\terr = zw.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = fd.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc codesign(target target) {\n\tswitch goos {\n\tcase \"windows\":\n\t\twindowsCodesign(target.BinaryName())\n\tcase \"darwin\":\n\t\tmacosCodesign(target.BinaryName())\n\t}\n}\n\nfunc macosCodesign(file string) {\n\tif pass := os.Getenv(\"CODESIGN_KEYCHAIN_PASS\"); pass != \"\" {\n\t\tbs, err := runError(\"security\", \"unlock-keychain\", \"-p\", pass)\n\t\tif err != nil {\n\t\t\tlog.Println(\"Codesign: unlocking keychain failed:\", string(bs))\n\t\t\treturn\n\t\t}\n\t}\n\n\tif id := os.Getenv(\"CODESIGN_IDENTITY\"); id != \"\" {\n\t\tbs, err := runError(\"codesign\", \"--options=runtime\", \"-s\", id, file)\n\t\tif err != nil {\n\t\t\tlog.Println(\"Codesign: signing failed:\", string(bs))\n\t\t\treturn\n\t\t}\n\t\tlog.Println(\"Codesign: successfully signed\", file)\n\t}\n}\n\nfunc windowsCodesign(file string) {\n\tst := \"signtool.exe\"\n\n\tif path := os.Getenv(\"CODESIGN_SIGNTOOL\"); path != \"\" {\n\t\tst = path\n\t}\n\n\tfor i, algo := range []string{\"sha1\", \"sha256\"} {\n\t\targs := []string{\"sign\", \"/fd\", algo}\n\t\tif f := os.Getenv(\"CODESIGN_CERTIFICATE_FILE\"); f != \"\" {\n\t\t\targs = append(args, \"/f\", f)\n\t\t} else if b := os.Getenv(\"CODESIGN_CERTIFICATE_BASE64\"); b != \"\" {\n\t\t\t// Decode the PFX certificate from base64.\n\t\t\tbs, err := base64.RawStdEncoding.DecodeString(b)\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"Codesign: signing failed: decoding base64:\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Write it to a temporary file\n\t\t\tf, err := os.CreateTemp(\"\", \"codesign-*.pfx\")\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"Codesign: signing failed: creating temp file:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t_ = f.Chmod(0o600) // best effort remove other users' access\n\t\t\tdefer os.Remove(f.Name())\n\t\t\tif _, err := f.Write(bs); err != nil {\n\t\t\t\tlog.Println(\"Codesign: signing failed: writing temp file:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif err := f.Close(); err != nil {\n\t\t\t\tlog.Println(\"Codesign: signing failed: closing temp file:\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Use that when signing\n\t\t\targs = append(args, \"/f\", f.Name())\n\t\t}\n\t\tif p := os.Getenv(\"CODESIGN_CERTIFICATE_PASSWORD\"); p != \"\" {\n\t\t\targs = append(args, \"/p\", p)\n\t\t}\n\t\tif tr := os.Getenv(\"CODESIGN_TIMESTAMP_SERVER\"); tr != \"\" {\n\t\t\tswitch algo {\n\t\t\tcase \"sha256\":\n\t\t\t\targs = append(args, \"/tr\", tr, \"/td\", algo)\n\t\t\tdefault:\n\t\t\t\targs = append(args, \"/t\", tr)\n\t\t\t}\n\t\t}\n\t\tif i > 0 {\n\t\t\targs = append(args, \"/as\")\n\t\t}\n\t\targs = append(args, file)\n\n\t\tbs, err := runError(st, args...)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Codesign: signing failed: %v: %s\", err, string(bs))\n\t\t\treturn\n\t\t}\n\t\tlog.Println(\"Codesign: successfully signed\", file, \"using\", algo)\n\t}\n}\n\nfunc metalint() {\n\tlazyRebuildAssets()\n\trunPrint(goCmd, \"test\", \"-run\", \"Metalint\", \"./meta\")\n}\n\nfunc metalintShort() {\n\tlazyRebuildAssets()\n\trunPrint(goCmd, \"test\", \"-short\", \"-run\", \"Metalint\", \"./meta\")\n}\n\nfunc (t target) BinaryName() string {\n\tif goos == \"windows\" {\n\t\treturn t.binaryName + \".exe\"\n\t}\n\treturn t.binaryName\n}\n\nfunc currentAndLatestVersions(n int) ([]string, error) {\n\tbs, err := runError(\"git\", \"tag\", \"--sort\", \"taggerdate\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlines := strings.Split(string(bs), \"\\n\")\n\treverseStrings(lines)\n\n\t// The one at the head is the latest version. We always keep that one.\n\t// Then we filter out remaining ones with dashes (pre-releases etc).\n\n\tlatest := lines[:1]\n\tnonPres := filterStrings(lines[1:], func(s string) bool { return !strings.Contains(s, \"-\") })\n\tvers := append(latest, nonPres...)\n\treturn vers[:n], nil\n}\n\nfunc reverseStrings(ss []string) {\n\tfor i := 0; i < len(ss)/2; i++ {\n\t\tss[i], ss[len(ss)-1-i] = ss[len(ss)-1-i], ss[i]\n\t}\n}\n\nfunc filterStrings(ss []string, op func(string) bool) []string {\n\tn := ss[:0]\n\tfor _, s := range ss {\n\t\tif op(s) {\n\t\t\tn = append(n, s)\n\t\t}\n\t}\n\treturn n\n}\n\nfunc tagMessage(tag string) (string, error) {\n\thash, err := runError(\"git\", \"rev-parse\", tag)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tobj, err := runError(\"git\", \"cat-file\", \"-p\", string(hash))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn trimTagMessage(string(obj), tag), nil\n}\n\nfunc trimTagMessage(msg, tag string) string {\n\tfirstBlank := strings.Index(msg, \"\\n\\n\")\n\tif firstBlank > 0 {\n\t\tmsg = msg[firstBlank+2:]\n\t}\n\tmsg = strings.TrimPrefix(msg, tag)\n\tbeginSig := strings.Index(msg, \"-----BEGIN PGP\")\n\tif beginSig > 0 {\n\t\tmsg = msg[:beginSig]\n\t}\n\treturn strings.TrimSpace(msg)\n}\n\nfunc nextPatchVersion(ver string) string {\n\tparts := strings.SplitN(ver, \"-\", 2)\n\tdigits := strings.Split(parts[0], \".\")\n\tn, _ := strconv.Atoi(digits[len(digits)-1])\n\tdigits[len(digits)-1] = strconv.Itoa(n + 1)\n\treturn strings.Join(digits, \".\")\n}\n\nfunc writeCompatJSON() {\n\tbs, err := os.ReadFile(\"compat.yaml\")\n\tif err != nil {\n\t\tlog.Fatal(\"Reading compat.yaml:\", err)\n\t}\n\n\tvar entries []upgrade.ReleaseCompatibility\n\tif err := yaml.Unmarshal(bs, &entries); err != nil {\n\t\tlog.Fatal(\"Parsing compat.yaml:\", err)\n\t}\n\n\trt := runtime.Version()\n\tfor _, e := range entries {\n\t\tif !strings.HasPrefix(rt, e.Runtime) {\n\t\t\tcontinue\n\t\t}\n\t\tbs, _ := json.MarshalIndent(e, \"\", \"  \")\n\t\tif err := os.WriteFile(\"compat.json\", bs, 0o644); err != nil {\n\t\t\tlog.Fatal(\"Writing compat.json:\", err)\n\t\t}\n\t\treturn\n\t}\n\n\tlog.Fatalf(\"runtime %v not found in compat.yaml\", rt)\n}\n"
        },
        {
          "name": "build.ps1",
          "type": "blob",
          "size": 0.26,
          "content": "function build {\n    go run build.go @args\n}\n\n$cmd, $rest = $args\nswitch ($cmd) {\n    \"test\" {\n        $env:LOGGER_DISCARD=1\n        build test\n    }\n\n    \"bench\" {\n        $env:LOGGER_DISCARD=1\n        build bench\n    }\n\n    default {\n        build @rest\n    }\n}\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.48,
          "content": "#!/usr/bin/env bash\nset -euo pipefail\nIFS=$'\\n\\t'\n\nscript() {\n\tname=\"$1\"\n\tshift\n\tgo run \"script/$name.go\" \"$@\"\n}\n\nbuild() {\n\tgo run build.go \"$@\"\n}\n\ncase \"${1:-default}\" in\n\ttest)\n\t\tLOGGER_DISCARD=1 build test\n\t\t;;\n\n\tbench)\n\t\tLOGGER_DISCARD=1 build bench\n\t\t;;\n\n\tprerelease)\n\t\tscript authors\n\t\tbuild weblate\n\t\tpushd man ; ./refresh.sh ; popd\n\t\tgit add -A gui man AUTHORS\n\t\tgit commit -m 'chore(gui, man, authors): update docs, translations, and contributors'\n\t\t;;\n\n\t*)\n\t\tbuild \"$@\"\n\t\t;;\nesac\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "compat.yaml",
          "type": "blob",
          "size": 0.98,
          "content": "- runtime: go1.21\n  requirements:\n    # See https://en.wikipedia.org/wiki/MacOS_version_history#Releases\n    #\n    # macOS 10.15 (Catalina) per https://go.dev/doc/go1.22#darwin\n    darwin: \"19\"\n    # Per https://go.dev/doc/go1.23#linux\n    linux: \"2.6.32\"\n    # Windows 10's initial release was 10.0.10240.16405, per\n    # https://learn.microsoft.com/en-us/windows/release-health/release-information\n    # and Windows 11's initial release was 10.0.22000.194 per\n    # https://learn.microsoft.com/en-us/windows/release-health/windows11-release-information\n    #\n    # Windows 10/Windows Server 2016 per https://go.dev/doc/go1.21#windows\n    windows: \"10.0\"\n\n- runtime: go1.22\n  requirements:\n    darwin: \"19\"\n    linux: \"2.6.32\"\n    windows: \"10.0\"\n\n- runtime: go1.23\n  requirements:\n    # macOS 11 (Big Sur) per https://tip.golang.org/doc/go1.23#darwin\n    darwin: \"20\"\n    linux: \"2.6.32\"\n    windows: \"10.0\"\n\n- runtime: go1.24\n  requirements:\n    darwin: \"20\"\n    linux: \"3.2\"\n    windows: \"10.0\"\n"
        },
        {
          "name": "etc",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 4.25,
          "content": "module github.com/syncthing/syncthing\n\ngo 1.22.0\n\nrequire (\n\tgithub.com/AudriusButkevicius/recli v0.0.7-0.20220911121932-d000ce8fbf0f\n\tgithub.com/alecthomas/kong v1.6.0\n\tgithub.com/aws/aws-sdk-go v1.55.5\n\tgithub.com/calmh/incontainer v1.0.0\n\tgithub.com/calmh/xdr v1.2.0\n\tgithub.com/ccding/go-stun v0.1.5\n\tgithub.com/chmduquesne/rollinghash v4.0.0+incompatible\n\tgithub.com/d4l3k/messagediff v1.2.1\n\tgithub.com/getsentry/raven-go v0.2.0\n\tgithub.com/go-ldap/ldap/v3 v3.4.10\n\tgithub.com/gobwas/glob v0.2.3\n\tgithub.com/greatroar/blobloom v0.8.0\n\tgithub.com/hashicorp/golang-lru/v2 v2.0.7\n\tgithub.com/jackpal/gateway v1.0.16\n\tgithub.com/jackpal/go-nat-pmp v1.0.2\n\tgithub.com/julienschmidt/httprouter v1.3.0\n\tgithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51\n\tgithub.com/maruel/panicparse/v2 v2.4.0\n\tgithub.com/maxbrunsfeld/counterfeiter/v6 v6.8.1\n\tgithub.com/maxmind/geoipupdate/v6 v6.1.0\n\tgithub.com/miscreant/miscreant.go v0.0.0-20200214223636-26d376326b75\n\tgithub.com/oschwald/geoip2-golang v1.11.0\n\tgithub.com/pierrec/lz4/v4 v4.1.22\n\tgithub.com/prometheus/client_golang v1.20.5\n\tgithub.com/puzpuzpuz/xsync/v3 v3.4.0\n\tgithub.com/quic-go/quic-go v0.48.2\n\tgithub.com/rabbitmq/amqp091-go v1.10.0\n\tgithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475\n\tgithub.com/shirou/gopsutil/v4 v4.24.12\n\tgithub.com/syncthing/notify v0.0.0-20210616190510-c6b7342338d2\n\tgithub.com/syndtr/goleveldb v1.0.1-0.20220721030215-126854af5e6d\n\tgithub.com/thejerf/suture/v4 v4.0.6\n\tgithub.com/urfave/cli v1.22.16\n\tgithub.com/vitrun/qart v0.0.0-20160531060029-bf64b92db6b0\n\tgithub.com/willabides/kongplete v0.4.0\n\tgo.uber.org/automaxprocs v1.6.0\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/net v0.33.0\n\tgolang.org/x/sys v0.28.0\n\tgolang.org/x/text v0.21.0\n\tgolang.org/x/time v0.8.0\n\tgolang.org/x/tools v0.28.0\n\tgoogle.golang.org/protobuf v1.36.1\n\tsigs.k8s.io/yaml v1.4.0\n)\n\nrequire (\n\tgithub.com/Azure/go-ntlmssp v0.0.0-20221128193559-754e69321358 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cenkalti/backoff/v4 v4.3.0 // indirect\n\tgithub.com/certifi/gocertifi v0.0.0-20210507211836-431795d63e8d // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/cpuguy83/go-md2man/v2 v2.0.5 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/ebitengine/purego v0.8.1 // indirect\n\tgithub.com/fsnotify/fsnotify v1.7.0 // indirect\n\tgithub.com/go-asn1-ber/asn1-ber v1.5.7 // indirect\n\tgithub.com/go-ole/go-ole v1.3.0 // indirect\n\tgithub.com/go-task/slim-sprig/v3 v3.0.0 // indirect\n\tgithub.com/gofrs/flock v0.12.1 // indirect\n\tgithub.com/golang/snappy v0.0.4 // indirect\n\tgithub.com/google/pprof v0.0.0-20241009165004-a3522334989c // indirect\n\tgithub.com/google/uuid v1.6.0 // indirect\n\tgithub.com/hashicorp/errwrap v1.1.0 // indirect\n\tgithub.com/hashicorp/go-multierror v1.1.1 // indirect\n\tgithub.com/jmespath/go-jmespath v0.4.0 // indirect\n\tgithub.com/klauspost/compress v1.17.11 // indirect\n\tgithub.com/lufia/plan9stats v0.0.0-20240909124753-873cd0166683 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/nxadm/tail v1.4.11 // indirect\n\tgithub.com/onsi/ginkgo/v2 v2.20.2 // indirect\n\tgithub.com/oschwald/maxminddb-golang v1.13.1 // indirect\n\tgithub.com/pkg/errors v0.9.1 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/posener/complete v1.2.3 // indirect\n\tgithub.com/power-devops/perfstat v0.0.0-20240221224432-82ca36839d55 // indirect\n\tgithub.com/prometheus/client_model v0.6.1 // indirect\n\tgithub.com/prometheus/common v0.60.0 // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgithub.com/riywo/loginshell v0.0.0-20200815045211-7d26008be1ab // indirect\n\tgithub.com/russross/blackfriday/v2 v2.1.0 // indirect\n\tgithub.com/stretchr/objx v0.5.2 // indirect\n\tgithub.com/stretchr/testify v1.10.0 // indirect\n\tgithub.com/tklauser/go-sysconf v0.3.14 // indirect\n\tgithub.com/tklauser/numcpus v0.9.0 // indirect\n\tgithub.com/yusufpapurcu/wmi v1.2.4 // indirect\n\tgo.uber.org/mock v0.4.0 // indirect\n\tgolang.org/x/exp v0.0.0-20241009180824-f66d83c29e7c // indirect\n\tgolang.org/x/mod v0.22.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n\n// https://github.com/gobwas/glob/pull/55\nreplace github.com/gobwas/glob v0.2.3 => github.com/calmh/glob v0.0.0-20220615080505-1d823af5017b\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 35.9,
          "content": "github.com/AudriusButkevicius/recli v0.0.7-0.20220911121932-d000ce8fbf0f h1:GmH5lT+moM7PbAJFBq57nH9WJ+wRnBXr/tyaYWbSAx8=\ngithub.com/AudriusButkevicius/recli v0.0.7-0.20220911121932-d000ce8fbf0f/go.mod h1:Nhfib1j/VFnLrXL9cHgA+/n2O6P5THuWelOnbfPNd78=\ngithub.com/Azure/go-ntlmssp v0.0.0-20221128193559-754e69321358 h1:mFRzDkZVAjdal+s7s0MwaRv9igoPqLRdzOLzw/8Xvq8=\ngithub.com/Azure/go-ntlmssp v0.0.0-20221128193559-754e69321358/go.mod h1:chxPXzSsl7ZWRAuOIE23GDNzjWuZquvFlgA8xmpunjU=\ngithub.com/BurntSushi/toml v1.4.0/go.mod h1:ukJfTF/6rtPPRCnwkur4qwRxa8vTRFBF0uk2lLoLwho=\ngithub.com/alecthomas/assert/v2 v2.11.0 h1:2Q9r3ki8+JYXvGsDyBXwH3LcJ+WK5D0gc5E8vS6K3D0=\ngithub.com/alecthomas/assert/v2 v2.11.0/go.mod h1:Bze95FyfUr7x34QZrjL+XP+0qgp/zg8yS+TtBj1WA3k=\ngithub.com/alecthomas/kong v1.6.0 h1:mwOzbdMR7uv2vul9J0FU3GYxE7ls/iX1ieMg5WIM6gE=\ngithub.com/alecthomas/kong v1.6.0/go.mod h1:p2vqieVMeTAnaC83txKtXe8FLke2X07aruPWXyMPQrU=\ngithub.com/alecthomas/repr v0.4.0 h1:GhI2A8MACjfegCPVq9f1FLvIBS+DrQ2KQBFZP1iFzXc=\ngithub.com/alecthomas/repr v0.4.0/go.mod h1:Fr0507jx4eOXV7AlPV6AVZLYrLIuIeSOWtW57eE/O/4=\ngithub.com/alexbrainman/sspi v0.0.0-20231016080023-1a75b4708caa h1:LHTHcTQiSGT7VVbI0o4wBRNQIgn917usHWOd6VAffYI=\ngithub.com/alexbrainman/sspi v0.0.0-20231016080023-1a75b4708caa/go.mod h1:cEWa1LVoE5KvSD9ONXsZrj0z6KqySlCCNKHlLzbqAt4=\ngithub.com/aws/aws-sdk-go v1.55.5 h1:KKUZBfBoyqy5d3swXyiC7Q76ic40rYcbqH7qjh59kzU=\ngithub.com/aws/aws-sdk-go v1.55.5/go.mod h1:eRwEWoyTWFMVYVQzKMNHWP5/RV4xIUGMQfXQHfHkpNU=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/calmh/glob v0.0.0-20220615080505-1d823af5017b h1:Fjm4GuJ+TGMgqfGHN42IQArJb77CfD/mAwLbDUoJe6g=\ngithub.com/calmh/glob v0.0.0-20220615080505-1d823af5017b/go.mod h1:91K7jfEsgJSyfSrX+gmrRfZMtntx6JsHolWubGXDopg=\ngithub.com/calmh/incontainer v1.0.0 h1:g2cTUtZuFGmMGX8GoykPkN1Judj2uw8/3/aEtq4Z/rg=\ngithub.com/calmh/incontainer v1.0.0/go.mod h1:eOhqnw15c9X+4RNBe0W3HlUZFfX16O0EDsCOInTndHY=\ngithub.com/calmh/xdr v1.2.0 h1:GaGSNH4ZDw9kNdYqle6+RcAENiaQ8/611Ok+jQbBEeU=\ngithub.com/calmh/xdr v1.2.0/go.mod h1:vO5+lCx/8xz7Ekd/ZLf+xuy7c1x6FMO1pBJyjDebwyg=\ngithub.com/ccding/go-stun v0.1.5 h1:qEM367nnezmj7dv+SdT52prv5x6HUTG3nlrjX5aitlo=\ngithub.com/ccding/go-stun v0.1.5/go.mod h1:cCZjJ1J3WFSJV6Wj8Y9Di8JMTsEXh6uv2eNmLzKaUeM=\ngithub.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=\ngithub.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=\ngithub.com/certifi/gocertifi v0.0.0-20210507211836-431795d63e8d h1:S2NE3iHSwP0XV47EEXL8mWmRdEfGscSJ+7EgePNgt0s=\ngithub.com/certifi/gocertifi v0.0.0-20210507211836-431795d63e8d/go.mod h1:sGbDF6GwGcLpkNXPUTkMRoywsNa/ol15pxFe6ERfguA=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chmduquesne/rollinghash v4.0.0+incompatible h1:hnREQO+DXjqIw3rUTzWN7/+Dpw+N5Um8zpKV0JOEgbo=\ngithub.com/chmduquesne/rollinghash v4.0.0+incompatible/go.mod h1:Uc2I36RRfTAf7Dge82bi3RU0OQUmXT9iweIcPqvr8A0=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.5 h1:ZtcqGrnekaHpVLArFSe4HK5DoKx1T0rq2DwVB0alcyc=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.5/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=\ngithub.com/d4l3k/messagediff v1.2.1 h1:ZcAIMYsUg0EAp9X+tt8/enBE/Q8Yd5kzPynLyKptt9U=\ngithub.com/d4l3k/messagediff v1.2.1/go.mod h1:Oozbb1TVXFac9FtSIxHBMnBCq2qeH/2KkEQxENCrlLo=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/ebitengine/purego v0.8.1 h1:sdRKd6plj7KYW33EH5As6YKfe8m9zbN9JMrOjNVF/BE=\ngithub.com/ebitengine/purego v0.8.1/go.mod h1:iIjxzd6CiRiOG0UyXP+V1+jWqUXVjPKLAI0mRfJZTmQ=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.9/go.mod h1:znqG4EE+3YCdAaPaxE2ZRY/06pZUdp0tY4IgpuI1SZQ=\ngithub.com/fsnotify/fsnotify v1.5.4/go.mod h1:OVB6XrOHzAwXMpEM7uPOzcehqUV2UqJxmVXmkdnm1bU=\ngithub.com/fsnotify/fsnotify v1.6.0/go.mod h1:sl3t1tCWJFWoRz9R8WJCbQihKKwmorjAbSClcnxKAGw=\ngithub.com/fsnotify/fsnotify v1.7.0 h1:8JEhPFa5W2WU7YfeZzPNqzMP6Lwt7L2715Ggo0nosvA=\ngithub.com/fsnotify/fsnotify v1.7.0/go.mod h1:40Bi/Hjc2AVfZrqy+aj+yEI+/bRxZnMJyTJwOpGvigM=\ngithub.com/getsentry/raven-go v0.2.0 h1:no+xWJRb5ZI7eE8TWgIq1jLulQiIoLG0IfYxv5JYMGs=\ngithub.com/getsentry/raven-go v0.2.0/go.mod h1:KungGk8q33+aIAZUIVWZDr2OfAEBsO49PX4NzFV5kcQ=\ngithub.com/go-asn1-ber/asn1-ber v1.5.7 h1:DTX+lbVTWaTw1hQ+PbZPlnDZPEIs0SS/GCZAl535dDk=\ngithub.com/go-asn1-ber/asn1-ber v1.5.7/go.mod h1:hEBeB/ic+5LoWskz+yKT7vGhhPYkProFKoKdwZRWMe0=\ngithub.com/go-ldap/ldap/v3 v3.4.10 h1:ot/iwPOhfpNVgB1o+AVXljizWZ9JTp7YF5oeyONmcJU=\ngithub.com/go-ldap/ldap/v3 v3.4.10/go.mod h1:JXh4Uxgi40P6E9rdsYqpUtbW46D9UTjJ9QSwGRznplY=\ngithub.com/go-logr/logr v1.4.2 h1:6pFjapn8bFcIbiKo3XT4j/BhANplGihG6tvd+8rYgrY=\ngithub.com/go-logr/logr v1.4.2/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-ole/go-ole v1.2.6/go.mod h1:pprOEPIfldk/42T2oK7lQ4v4JSDwmV0As9GaiUsvbm0=\ngithub.com/go-ole/go-ole v1.3.0 h1:Dt6ye7+vXGIKZ7Xtk4s6/xVdGDQynvom7xCFEdWr6uE=\ngithub.com/go-ole/go-ole v1.3.0/go.mod h1:5LS6F96DhAwUc7C+1HLexzMXY1xGRSryjyPPKW6zv78=\ngithub.com/go-task/slim-sprig v0.0.0-20210107165309-348f09dbbbc0/go.mod h1:fyg7847qk6SyHyPtNmDHnmrv/HOrqktSC+C9fM+CJOE=\ngithub.com/go-task/slim-sprig/v3 v3.0.0 h1:sUs3vkvUymDpBKi3qH1YSqBQk9+9D/8M2mN1vB6EwHI=\ngithub.com/go-task/slim-sprig/v3 v3.0.0/go.mod h1:W848ghGpv3Qj3dhTPRyJypKRiqCdHZiAzKg9hl15HA8=\ngithub.com/gofrs/flock v0.12.1 h1:MTLVXXHf8ekldpJk3AKicLij9MdwOWkZ+a/jHHZby9E=\ngithub.com/gofrs/flock v0.12.1/go.mod h1:9zxTsyu5xtJ9DK+1tFZyibEV7y3uwDxPPfbxeeHCoD0=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/pprof v0.0.0-20210407192527-94a9f03dee38/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20241009165004-a3522334989c h1:NDovD0SMpBYXlE1zJmS1q55vWB/fUQBcPAqAboZSccA=\ngithub.com/google/pprof v0.0.0-20241009165004-a3522334989c/go.mod h1:vavhavw2zAxS5dIdcRluK6cSGGPlZynqzFM8NdvU144=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/gorilla/securecookie v1.1.1/go.mod h1:ra0sb63/xPlUeL+yeDciTfxMRAA+MP+HVt/4epWDjd4=\ngithub.com/gorilla/sessions v1.2.1/go.mod h1:dk2InVEVJ0sfLlnXv9EAgkf6ecYs/i80K/zI+bUmuGM=\ngithub.com/greatroar/blobloom v0.8.0 h1:I9RlEkfqK9/6f1v9mFmDYegDQ/x0mISCpiNpAm23Pt4=\ngithub.com/greatroar/blobloom v0.8.0/go.mod h1:mjMJ1hh1wjGVfr93QIHJ6FfDNVrA0IELv8OvMHJxHKs=\ngithub.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=\ngithub.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/go-multierror v1.0.0/go.mod h1:dHtQlpGsu+cZNNAkkCN/P3hoUDHhCYQXV3UM06sGGrk=\ngithub.com/hashicorp/go-multierror v1.1.1 h1:H5DkEtf6CXdFp0N0Em5UCwQpXMWke8IA0+lD48awMYo=\ngithub.com/hashicorp/go-multierror v1.1.1/go.mod h1:iw975J/qwKPdAO1clOe2L8331t/9/fmwbPZ6JB6eMoM=\ngithub.com/hashicorp/go-uuid v1.0.2/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-uuid v1.0.3 h1:2gKiV6YVmrJ1i2CKKa9obLvRieoRGviZFL26PcT/Co8=\ngithub.com/hashicorp/go-uuid v1.0.3/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/golang-lru/v2 v2.0.7 h1:a+bsQ5rvGLjzHuww6tVxozPZFVghXaHOwFs4luLUK2k=\ngithub.com/hashicorp/golang-lru/v2 v2.0.7/go.mod h1:QeFd9opnmA6QUJc5vARoKUSoFhyfM2/ZepoAG6RGpeM=\ngithub.com/hexops/gotextdiff v1.0.3 h1:gitA9+qJrrTCsiCl7+kh75nPqQt1cx4ZkudSTLoUqJM=\ngithub.com/hexops/gotextdiff v1.0.3/go.mod h1:pSWU5MAI3yDq+fZBTazCSJysOMbxWL1BSow5/V2vxeg=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/ianlancetaylor/demangle v0.0.0-20200824232613-28f6c0f3b639/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/jackpal/gateway v1.0.16 h1:mTBRuHSW8qviVqX7kXnxKevqlfS/OA01ys6k6fxSX7w=\ngithub.com/jackpal/gateway v1.0.16/go.mod h1:IOn1OUbso/cGYmnCBZbCEqhNCLSz0xxdtIpUpri5/nA=\ngithub.com/jackpal/go-nat-pmp v1.0.2 h1:KzKSgb7qkJvOUTqYl9/Hg/me3pWgBmERKrTGD7BdWus=\ngithub.com/jackpal/go-nat-pmp v1.0.2/go.mod h1:QPH045xvCAeXUZOxsnwmrtiCoxIr9eob+4orBN1SBKc=\ngithub.com/jcmturner/aescts/v2 v2.0.0 h1:9YKLH6ey7H4eDBXW8khjYslgyqG2xZikXP0EQFKrle8=\ngithub.com/jcmturner/aescts/v2 v2.0.0/go.mod h1:AiaICIRyfYg35RUkr8yESTqvSy7csK90qZ5xfvvsoNs=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0 h1:lltnkeZGL0wILNvrNiVCR6Ro5PGU/SeBvVO/8c/iPbo=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0/go.mod h1:b0TnjGOvI/n42bZa+hmXL+kFJZsFT7G4t3HTlQ184QM=\ngithub.com/jcmturner/gofork v1.7.6 h1:QH0l3hzAU1tfT3rZCnW5zXl+orbkNMMRGJfdJjHVETg=\ngithub.com/jcmturner/gofork v1.7.6/go.mod h1:1622LH6i/EZqLloHfE7IeZ0uEJwMSUyQ/nDd82IeqRo=\ngithub.com/jcmturner/goidentity/v6 v6.0.1 h1:VKnZd2oEIMorCTsFBnJWbExfNN7yZr3EhJAxwOkZg6o=\ngithub.com/jcmturner/goidentity/v6 v6.0.1/go.mod h1:X1YW3bgtvwAXju7V3LCIMpY0Gbxyjn/mY9zx4tFonSg=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4 h1:x1Sv4HaTpepFkXbt2IkL29DXRf8sOfZXo8eRKh687T8=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4/go.mod h1:1btQEpgT6k+unzCwX1KdWMEwPPkkgBtP+F6aCACiMrs=\ngithub.com/jcmturner/rpc/v2 v2.0.3 h1:7FXXj8Ti1IaVFpSAziCZWNzbNuZmnvw/i6CqLNdWfZY=\ngithub.com/jcmturner/rpc/v2 v2.0.3/go.mod h1:VUJYCIDm3PVOEHw8sgt091/20OJjskO/YJki3ELg/Hc=\ngithub.com/jmespath/go-jmespath v0.4.0 h1:BEgLn5cpjn8UN1mAw4NjwDrS35OdebyEtFe+9YPoQUg=\ngithub.com/jmespath/go-jmespath v0.4.0/go.mod h1:T8mJZnbsbmF+m6zOOFylbeCJqk5+pHWvzYPziyZiYoo=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1 h1:shLQSRRSCCPj3f2gpwzGwWFoC7ycTf1rcQZHOlsJ6N8=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1/go.mod h1:L3OGu8Wl2/fWfCI6z80xFu9LTZmf1ZRjMHUOPmWr69U=\ngithub.com/julienschmidt/httprouter v1.3.0 h1:U0609e9tgbseu3rBINet9P48AI/D3oJs4dN7jwJOQ1U=\ngithub.com/julienschmidt/httprouter v1.3.0/go.mod h1:JR6WtHb+2LUe8TCKY3cZOxFyyO8IZAc4RVcycCCAKdM=\ngithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51 h1:Z9n2FFNUXsshfwJMBgNA0RU6/i7WVaAegv3PtuIHPMs=\ngithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51/go.mod h1:CzGEWj7cYgsdH8dAjBGEr58BoE7ScuLd+fwFZ44+/x8=\ngithub.com/klauspost/compress v1.17.11 h1:In6xLpyWOi1+C7tXUUWv2ot1QvBjxevKAaI6IXrJmUc=\ngithub.com/klauspost/compress v1.17.11/go.mod h1:pMDklpSncoRMuLFrf1W9Ss9KT+0rH90U12bZKk7uwG0=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/kylelemons/godebug v1.1.0 h1:RPNrshWIDI6G2gRW9EHilWtl7Z6Sb1BR0xunSBf0SNc=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/lufia/plan9stats v0.0.0-20240909124753-873cd0166683 h1:7UMa6KCCMjZEMDtTVdcGu0B1GmmC7QJKiCCjyTAWQy0=\ngithub.com/lufia/plan9stats v0.0.0-20240909124753-873cd0166683/go.mod h1:ilwx/Dta8jXAgpFYFvSWEMwxmbWXyiUHkd5FwyKhb5k=\ngithub.com/maruel/panicparse/v2 v2.4.0 h1:yQKMIbQ0DKfinzVkTkcUzQyQ60UCiNnYfR7PWwTs2VI=\ngithub.com/maruel/panicparse/v2 v2.4.0/go.mod h1:nOY2OKe8csO3F3SA5+hsxot05JLgukrF54B9x88fVp4=\ngithub.com/maxbrunsfeld/counterfeiter/v6 v6.8.1 h1:NicmruxkeqHjDv03SfSxqmaLuisddudfP3h5wdXFbhM=\ngithub.com/maxbrunsfeld/counterfeiter/v6 v6.8.1/go.mod h1:eyp4DdUJAKkr9tvxR3jWhw2mDK7CWABMG5r9uyaKC7I=\ngithub.com/maxmind/geoipupdate/v6 v6.1.0 h1:sdtTHzzQNJlXF5+fd/EoPTucRHyMonYt/Cok8xzzfqA=\ngithub.com/maxmind/geoipupdate/v6 v6.1.0/go.mod h1:cZYCDzfMzTY4v6dKRdV7KTB6SStxtn3yFkiJ1btTGGc=\ngithub.com/miscreant/miscreant.go v0.0.0-20200214223636-26d376326b75 h1:cUVxyR+UfmdEAZGJ8IiKld1O0dbGotEnkMolG5hfMSY=\ngithub.com/miscreant/miscreant.go v0.0.0-20200214223636-26d376326b75/go.mod h1:pBbZyGwC5i16IBkjVKoy/sznA8jPD/K9iedwe1ESE6w=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/nxadm/tail v1.4.4/go.mod h1:kenIhsEOeOJmVchQTgglprH7qJGnHDVpk1VPCcaMI8A=\ngithub.com/nxadm/tail v1.4.8/go.mod h1:+ncqLTQzXmGhMZNUePPaPqPvBxHAIsmXswZKocGu+AU=\ngithub.com/nxadm/tail v1.4.11 h1:8feyoE3OzPrcshW5/MJ4sGESc5cqmGkGCWlco4l0bqY=\ngithub.com/nxadm/tail v1.4.11/go.mod h1:OTaG3NK980DZzxbRq6lEuzgU+mug70nY11sMd4JXXHc=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.12.1/go.mod h1:zj2OWP4+oCPe1qIXoGWkgMRwljMUYCdkwsT2108oapk=\ngithub.com/onsi/ginkgo v1.16.4/go.mod h1:dX+/inL/fNMqNlz0e9LfyB9TswhZpCVdJM/Z6Vvnwo0=\ngithub.com/onsi/ginkgo v1.16.5 h1:8xi0RTUf59SOSfEtZMvwTvXYMzG4gV23XVHOZiXNtnE=\ngithub.com/onsi/ginkgo v1.16.5/go.mod h1:+E8gABHa3K6zRBolWtd+ROzc/U5bkGt0FwiG042wbpU=\ngithub.com/onsi/ginkgo/v2 v2.1.3/go.mod h1:vw5CSIxN1JObi/U8gcbwft7ZxR2dgaR70JSE3/PpL4c=\ngithub.com/onsi/ginkgo/v2 v2.20.2 h1:7NVCeyIWROIAheY21RLS+3j2bb52W0W82tkberYytp4=\ngithub.com/onsi/ginkgo/v2 v2.20.2/go.mod h1:K9gyxPIlb+aIvnZ8bd9Ak+YP18w3APlR+5coaZoE2ag=\ngithub.com/onsi/gomega v1.7.1/go.mod h1:XdKZgCCFLUoM/7CFJVPcG8C1xQ1AJ0vpAezJrB7JYyY=\ngithub.com/onsi/gomega v1.10.1/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=\ngithub.com/onsi/gomega v1.17.0/go.mod h1:HnhC7FXeEQY45zxNK3PPoIUhzk/80Xly9PcubAlGdZY=\ngithub.com/onsi/gomega v1.19.0/go.mod h1:LY+I3pBVzYsTBU1AnDwOSxaYi9WoWiqgwooUqq9yPro=\ngithub.com/onsi/gomega v1.34.1 h1:EUMJIKUjM8sKjYbtxQI9A4z2o+rruxnzNvpknOXie6k=\ngithub.com/onsi/gomega v1.34.1/go.mod h1:kU1QgUvBDLXBJq618Xvm2LUX6rSAfRaFRTcdOeDLwwY=\ngithub.com/oschwald/geoip2-golang v1.11.0 h1:hNENhCn1Uyzhf9PTmquXENiWS6AlxAEnBII6r8krA3w=\ngithub.com/oschwald/geoip2-golang v1.11.0/go.mod h1:P9zG+54KPEFOliZ29i7SeYZ/GM6tfEL+rgSn03hYuUo=\ngithub.com/oschwald/maxminddb-golang v1.13.1 h1:G3wwjdN9JmIK2o/ermkHM+98oX5fS+k5MbwsmL4MRQE=\ngithub.com/oschwald/maxminddb-golang v1.13.1/go.mod h1:K4pgV9N/GcK694KSTmVSDTODk4IsCNThNdTmnaBZ/F8=\ngithub.com/pierrec/lz4/v4 v4.1.22 h1:cKFw6uJDK+/gfw5BcDL0JL5aBsAFdsIT18eRtLj7VIU=\ngithub.com/pierrec/lz4/v4 v4.1.22/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/posener/complete v1.2.3 h1:NP0eAhjcjImqslEwo/1hq7gpajME0fTLTezBKDqfXqo=\ngithub.com/posener/complete v1.2.3/go.mod h1:WZIdtGGp+qx0sLrYKtIRAruyNpv6hFCicSgv7Sy7s/s=\ngithub.com/power-devops/perfstat v0.0.0-20240221224432-82ca36839d55 h1:o4JXh1EVt9k/+g42oCprj/FisM4qX9L3sZB3upGN2ZU=\ngithub.com/power-devops/perfstat v0.0.0-20240221224432-82ca36839d55/go.mod h1:OmDBASR4679mdNQnz2pUhc2G8CO2JrUAVFDRBDP/hJE=\ngithub.com/prashantv/gostub v1.1.0 h1:BTyx3RfQjRHnUWaGF9oQos79AlQ5k8WNktv7VGvVH4g=\ngithub.com/prashantv/gostub v1.1.0/go.mod h1:A5zLQHz7ieHGG7is6LLXLz7I8+3LZzsrV0P1IAHhP5U=\ngithub.com/prometheus/client_golang v1.20.5 h1:cxppBPuYhUnsO6yo/aoRol4L7q7UFfdm+bR9r+8l63Y=\ngithub.com/prometheus/client_golang v1.20.5/go.mod h1:PIEt8X02hGcP8JWbeHyeZ53Y/jReSnHgO035n//V5WE=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.60.0 h1:+V9PAREWNvJMAuJ1x1BaWl9dewMW4YrHZQbx0sJNllA=\ngithub.com/prometheus/common v0.60.0/go.mod h1:h0LYf1R1deLSKtD4Vdg8gy4RuOvENW2J/h19V5NADQw=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/puzpuzpuz/xsync/v3 v3.4.0 h1:DuVBAdXuGFHv8adVXjWWZ63pJq+NRXOWVXlKDBZ+mJ4=\ngithub.com/puzpuzpuz/xsync/v3 v3.4.0/go.mod h1:VjzYrABPabuM4KyBh1Ftq6u8nhwY5tBPKP9jpmh0nnA=\ngithub.com/quic-go/quic-go v0.48.2 h1:wsKXZPeGWpMpCGSWqOcqpW2wZYic/8T3aqiOID0/KWE=\ngithub.com/quic-go/quic-go v0.48.2/go.mod h1:yBgs3rWBOADpga7F+jJsb6Ybg1LSYiQvwWlLX+/6HMs=\ngithub.com/rabbitmq/amqp091-go v1.10.0 h1:STpn5XsHlHGcecLmMFCtg7mqq0RnD+zFr4uzukfVhBw=\ngithub.com/rabbitmq/amqp091-go v1.10.0/go.mod h1:Hy4jKW5kQART1u+JkDTF9YYOQUHXqMuhrgxOEeS7G4o=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 h1:N/ElC8H3+5XpJzTSTfLsJV/mx9Q9g7kxmchpfZyxgzM=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=\ngithub.com/riywo/loginshell v0.0.0-20200815045211-7d26008be1ab h1:ZjX6I48eZSFetPb41dHudEyVr5v953N15TsNZXlkcWY=\ngithub.com/riywo/loginshell v0.0.0-20200815045211-7d26008be1ab/go.mod h1:/PfPXh0EntGc3QAAyUaviy4S9tzy4Zp0e2ilq4voC6E=\ngithub.com/rogpeppe/go-internal v1.10.0 h1:TMyTOH3F/DB16zRVcYyreMH6GnZZrwQVAoYjRBZyWFQ=\ngithub.com/rogpeppe/go-internal v1.10.0/go.mod h1:UQnix2H7Ngw/k4C5ijL5+65zddjncjaFoBhdsK/akog=\ngithub.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/sclevine/spec v1.4.0 h1:z/Q9idDcay5m5irkZ28M7PtQM4aOISzOpj4bUPkDee8=\ngithub.com/sclevine/spec v1.4.0/go.mod h1:LvpgJaFyvQzRvc1kaDs0bulYwzC70PbiYjC4QnFHkOM=\ngithub.com/shirou/gopsutil/v4 v4.24.12 h1:qvePBOk20e0IKA1QXrIIU+jmk+zEiYVVx06WjBRlZo4=\ngithub.com/shirou/gopsutil/v4 v4.24.12/go.mod h1:DCtMPAad2XceTeIAbGyVfycbYQNBGk2P8cvDi7/VN9o=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2 h1:xuMeJ0Sdp5ZMRXx/aWO6RZxdr3beISkG5/G/aIRr3pY=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.2/go.mod h1:R6va5+xMeoiuVRoj+gSkQ7d3FALtqAAGI1FQKckRals=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/syncthing/notify v0.0.0-20210616190510-c6b7342338d2 h1:F4snRP//nIuTTW9LYEzVH4HVwDG9T3M4t8y/2nqMbiY=\ngithub.com/syncthing/notify v0.0.0-20210616190510-c6b7342338d2/go.mod h1:J0q59IWjLtpRIJulohwqEZvjzwOfTEPp8SVhDJl+y0Y=\ngithub.com/syndtr/goleveldb v1.0.1-0.20220721030215-126854af5e6d h1:vfofYNRScrDdvS342BElfbETmL1Aiz3i2t0zfRj16Hs=\ngithub.com/syndtr/goleveldb v1.0.1-0.20220721030215-126854af5e6d/go.mod h1:RRCYJbIwD5jmqPI9XoAFR0OcDxqUctll6zUj/+B4S48=\ngithub.com/thejerf/suture/v4 v4.0.6 h1:QsuCEsCqb03xF9tPAsWAj8QOAJBgQI1c0VqJNaingg8=\ngithub.com/thejerf/suture/v4 v4.0.6/go.mod h1:gu9Y4dXNUWFrByqRt30Rm9/UZ0wzRSt9AJS6xu/ZGxU=\ngithub.com/tklauser/go-sysconf v0.3.14 h1:g5vzr9iPFFz24v2KZXs/pvpvh8/V9Fw6vQK5ZZb78yU=\ngithub.com/tklauser/go-sysconf v0.3.14/go.mod h1:1ym4lWMLUOhuBOPGtRcJm7tEGX4SCYNEEEtghGG/8uY=\ngithub.com/tklauser/numcpus v0.9.0 h1:lmyCHtANi8aRUgkckBgoDk1nHCux3n2cgkJLXdQGPDo=\ngithub.com/tklauser/numcpus v0.9.0/go.mod h1:SN6Nq1O3VychhC1npsWostA+oW+VOQTxZrS604NSRyI=\ngithub.com/urfave/cli v1.20.0/go.mod h1:70zkFmudgCuE/ngEzBv17Jvp/497gISqfk5gWijbERA=\ngithub.com/urfave/cli v1.22.16 h1:MH0k6uJxdwdeWQTwhSO42Pwr4YLrNLwBtg1MRgTqPdQ=\ngithub.com/urfave/cli v1.22.16/go.mod h1:EeJR6BKodywf4zciqrdw6hpCPk68JO9z5LazXZMn5Po=\ngithub.com/vitrun/qart v0.0.0-20160531060029-bf64b92db6b0 h1:okhMind4q9H1OxF44gNegWkiP4H/gsTFLalHFa4OOUI=\ngithub.com/vitrun/qart v0.0.0-20160531060029-bf64b92db6b0/go.mod h1:TTbGUfE+cXXceWtbTHq6lqcTvYPBKLNejBEbnUsQJtU=\ngithub.com/willabides/kongplete v0.4.0 h1:eivXxkp5ud5+4+NVN9e4goxC5mSh3n1RHov+gsblM2g=\ngithub.com/willabides/kongplete v0.4.0/go.mod h1:0P0jtWD9aTsqPSUAl4de35DLghrr57XcayPyvqSi2X8=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngithub.com/yusufpapurcu/wmi v1.2.4 h1:zFUKzehAFReQwLys1b/iSMl+JQGSCSjtVqQn9bBrPo0=\ngithub.com/yusufpapurcu/wmi v1.2.4/go.mod h1:SBZ9tNy3G9/m5Oi98Zks0QjeHVDvuK0qfxQmPyzfmi0=\ngo.uber.org/automaxprocs v1.6.0 h1:O3y2/QNTOdbF+e/dpXNNW7Rx2hZ4sTIPyybbxyNqTUs=\ngo.uber.org/automaxprocs v1.6.0/go.mod h1:ifeIMSnPZuznNm6jmdzmU3/bfk01Fe2fotchwEFJ8r8=\ngo.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=\ngo.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=\ngo.uber.org/mock v0.4.0 h1:VcM4ZOtdbR4f6VXfiOpwpVJDL6lCReaZ6mw31wqh7KU=\ngo.uber.org/mock v0.4.0/go.mod h1:a6FSlNadKUHUa9IP5Vyt1zh4fC7uAwxMutEAscFbkZc=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.6.0/go.mod h1:OFC/31mSvZgRz0V1QTNCzfAI1aIRzbiufJtkMIlEp58=\ngolang.org/x/crypto v0.13.0/go.mod h1:y6Z2r+Rw4iayiXXAIxJIDAJ1zMW4yaTpebo8fPOliYc=\ngolang.org/x/crypto v0.19.0/go.mod h1:Iy9bg/ha4yyC70EfRS8jz+B6ybOBKMaSxLj6P6oBDfU=\ngolang.org/x/crypto v0.23.0/go.mod h1:CKFgDieR+mRhux2Lsu27y0fO304Db0wZe70UKqHu0v8=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20241009180824-f66d83c29e7c h1:7dEasQXItcW1xKJ2+gg5VOiBnqWrJc+rq0DPKyvvdbY=\ngolang.org/x/exp v0.0.0-20241009180824-f66d83c29e7c/go.mod h1:NQtJDoLvd6faHhE7m4T/1IY708gDefGGjR/iUW8yQQ8=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/mod v0.12.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/mod v0.15.0/go.mod h1:hTbmBsO62+eylJbnUtE2MGJUyE7QWk4xUqPFrRgJ+7c=\ngolang.org/x/mod v0.17.0/go.mod h1:hTbmBsO62+eylJbnUtE2MGJUyE7QWk4xUqPFrRgJ+7c=\ngolang.org/x/mod v0.22.0 h1:D4nJWe9zXqHOmWqj4VMOJhvzj7bEZg4wEYa759z1pH4=\ngolang.org/x/mod v0.22.0/go.mod h1:6SkKJ3Xj0I0BrPOZoBy3bdMptDDU9oJrpohJ3eWZ1fY=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200114155413-6afb5195e5aa/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200520004742-59133d7f0dd7/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210428140749-89ef3d95e781/go.mod h1:OJAsFXCWl8Ukc7SiCT/9KSuxbyM7479/AVlXFRxuMCk=\ngolang.org/x/net v0.0.0-20220225172249-27dd8689420f/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=\ngolang.org/x/net v0.0.0-20220607020251-c690dde0001d/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.7.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.10.0/go.mod h1:0qNGK6F8kojg2nk9dLZ2mShWaEBan6FAoqfSigmmuDg=\ngolang.org/x/net v0.15.0/go.mod h1:idbUs1IY1+zTqbi8yxTbhexhEEk5ur9LInksu6HrEpk=\ngolang.org/x/net v0.21.0/go.mod h1:bIjVDfnllIU7BJ2DNgfnXvpSvtn8VRwhlsaeUTyUS44=\ngolang.org/x/net v0.25.0/go.mod h1:JkAGAh7GEvH74S6FOH42FLoXpXbE/aqXSrIQjXgsiwM=\ngolang.org/x/net v0.33.0 h1:74SYHlV8BIgHIFC/LrYkOGIwL19eTYXQ5wc6TBuO36I=\ngolang.org/x/net v0.33.0/go.mod h1:HXLR5J+9DxmrqMwG9qjGCxZ+zKXxBru04zlTvWlWuN4=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.3.0/go.mod h1:FU7BRWz2tNW+3quACPkgCx/L+uEAv1htQ0V83Z9Rj+Y=\ngolang.org/x/sync v0.6.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sync v0.7.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180926160741-c2ed4eda69e7/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190904154756-749cb33beabd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190916202348-b4ddaad3f8a3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191120155948-bd437916bb0e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201204225414-ed752295db88/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210112080510-489259a85091/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211216021012-1d35b9e2eb4e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220412211240-33da011f77ad/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220908164124-27713097b956/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.1.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.12.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.17.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.20.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/telemetry v0.0.0-20240228155512-f48c80bd79b2/go.mod h1:TeRTkGYfJXctD9OcfyVLyj2J3IxLnKwHJR8f4D8a3YE=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.8.0/go.mod h1:xPskH00ivmX89bAKVGSKKtLOWNx2+17Eiy94tnKShWo=\ngolang.org/x/term v0.12.0/go.mod h1:owVbMEjm3cBLCHdkQu9b1opXd4ETQWc3BhuQGKgXgvU=\ngolang.org/x/term v0.17.0/go.mod h1:lLRBjIVuehSbZlaOtGMbcMncT+aqLLLmKrsjNrUguwk=\ngolang.org/x/term v0.20.0/go.mod h1:8UkIAJTvZgivsXaD6/pH6U9ecQzZ45awqEOzuCvwpFY=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.9.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=\ngolang.org/x/text v0.13.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=\ngolang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/text v0.15.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/time v0.8.0 h1:9i3RxcPv3PZnitoVGMPDKZSq1xW1gK1Xy3ArNOGZfEg=\ngolang.org/x/time v0.8.0/go.mod h1:3BpzKBy/shNhVucY/MWOyx10tF3SFh9QdLuxbVysPQM=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20201224043029-2b0845dc783e/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=\ngolang.org/x/tools v0.13.0/go.mod h1:HvlwmtVNQAhOuCjW7xxvovg8wbNq7LwfXh/k7wXUl58=\ngolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d/go.mod h1:aiJjzUbINMkxbQROHiO6hDPo2LHcIPhhQsa9DLh0yGk=\ngolang.org/x/tools v0.28.0 h1:WuB6qZ4RPCQo5aP3WdKZS7i595EdWqWR8vqJTlwTVK8=\ngolang.org/x/tools v0.28.0/go.mod h1:dcIOrVd3mfQKTgrDVQHqCPMWy6lnhfhtX3hLXYVLfRw=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20220517211312-f3a8303e98df/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.36.1 h1:yBPeRvTftaleIgM3PZ/WBIZ7XM/eEYAaEyCwvyjq/gk=\ngoogle.golang.org/protobuf v1.36.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 h1:uRGJdciOHaEIrze2W8Q3AKkepLTh2hOroT7a+7czfdQ=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nsigs.k8s.io/yaml v1.4.0 h1:Mk1wCc2gy/F0THH0TAp1QYyJNzRm2KCLy3o5ASXVI5E=\nsigs.k8s.io/yaml v1.4.0/go.mod h1:Ejl7/uTz7PSA4eKMyQCUTnhZYNmLIl+5c2lQPGR2BPY=\n"
        },
        {
          "name": "gui",
          "type": "tree",
          "content": null
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "man",
          "type": "tree",
          "content": null
        },
        {
          "name": "meta",
          "type": "tree",
          "content": null
        },
        {
          "name": "next-gen-gui",
          "type": "tree",
          "content": null
        },
        {
          "name": "proto",
          "type": "tree",
          "content": null
        },
        {
          "name": "script",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools.go",
          "type": "blob",
          "size": 0.37,
          "content": "// This file is never built. It serves to establish dependencies on tools\n// used by go generate and build.go. See\n// https://github.com/golang/go/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module\n\n//go:build tools\n// +build tools\n\npackage tools\n\nimport (\n\t_ \"github.com/calmh/xdr\"\n\t_ \"github.com/maxbrunsfeld/counterfeiter/v6\"\n\t_ \"golang.org/x/tools/cmd/goimports\"\n)\n"
        }
      ]
    },
    {
      "nameWithOwner": "abi/screenshot-to-code",
      "stars": 66705,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.06,
          "content": "# Auto detect text files and perform LF normalization\n* text=auto\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.17,
          "content": ".aider*\n\n# Project-related files\n\n# Run logs\nbackend/run_logs/*\n\n# Weird Docker setup related files\nbackend/backend/*\n\n# Env vars\nfrontend/.env.local\n.env\n\n# Mac files\n.DS_Store\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "Evaluation.md",
          "type": "blob",
          "size": 1.17,
          "content": "## Evaluating models and prompts\n\nEvaluation dataset consists of 16 screenshots. A Python script for running screenshot-to-code on the dataset and a UI for rating outputs is included. With this set up, we can compare and evaluate various models and prompts.\n\n### Running evals\n\n- Input screenshots should be located at `backend/evals_data/inputs` and the outputs will be `backend/evals_data/outputs`. If you want to modify this, modify `EVALS_DIR` in `backend/evals/config.py`. You can download the input screenshot dataset here: TODO.\n- Set a stack and model (`STACK` var, `MODEL` var) in `backend/run_evals.py`\n- Run `OPENAI_API_KEY=sk-... python run_evals.py` - this runs the screenshot-to-code on the input dataset in parallel but it will still take a few minutes to complete.\n- Once the script is done, you can find the outputs in `backend/evals_data/outputs`.\n\n### Rating evals\n\nIn order to view and rate the outputs, visit your front-end at `/evals`.\n\n- Rate each output on a scale of 1-4\n- You can also print the page as PDF to share your results with others.\n\nGenerally, I run three tests for each model/prompt + stack combo and take the average score out of those tests to evaluate.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04,
          "content": "MIT License\n\nCopyright (c) 2023 Abi Raja\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.41,
          "content": "# screenshot-to-code\n\nA simple tool to convert screenshots, mockups and Figma designs into clean, functional code using AI. **Now supporting Claude Sonnet 3.5 and Gemini 2.0 Flash!**\n\nhttps://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045\n\nSupported stacks:\n\n- HTML + Tailwind\n- HTML + CSS\n- React + Tailwind\n- Vue + Tailwind\n- Bootstrap\n- Ionic + Tailwind\n- SVG\n\nSupported AI models:\n\n- Claude Sonnet 3.5 - Best model!\n- GPT-4o - also recommended!\n- DALL-E 3 or Flux Schnell (using Replicate) for image generation\n\nSee the [Examples](#-examples) section below for more demos.\n\nWe also just added experimental support for taking a video/screen recording of a website in action and turning that into a functional prototype.\n\n![google in app quick 3](https://github.com/abi/screenshot-to-code/assets/23818/8758ffa4-9483-4b9b-bb66-abd6d1594c33)\n\n[Learn more about video here](https://github.com/abi/screenshot-to-code/wiki/Screen-Recording-to-Code).\n\n[Follow me on Twitter for updates](https://twitter.com/_abi_).\n\n## 🌍  Hosted Version\n\n[Try it live on the hosted version (paid)](https://screenshottocode.com). If you're a large or medium enterprise (50+ employees), [book a meeting to explore custom enterprise plans](https://cal.com/abi-raja-wy2pfh/30min).\n\n## 🛠 Getting Started\n\nThe app has a React/Vite frontend and a FastAPI backend.\n\nKeys needed:\n\n- [OpenAI API key with access to GPT-4](https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md) or Anthropic key (optional)\n- Both are recommended so you can compare results from both Claude and GPT4o\n\nIf you'd like to run the app with Ollama open source models (not recommended due to poor quality results), [follow this comment](https://github.com/abi/screenshot-to-code/issues/354#issuecomment-2435479853).\n\nRun the backend (I use Poetry for package management - `pip install poetry` if you don't have it):\n\n```bash\ncd backend\necho \"OPENAI_API_KEY=sk-your-key\" > .env\necho \"ANTHROPIC_API_KEY=your-key\" > .env\npoetry install\npoetry shell\npoetry run uvicorn main:app --reload --port 7001\n```\nYou can also set up the keys using the settings dialog on the front-end (click the gear icon after loading the frontend).\n\nRun the frontend:\n\n```bash\ncd frontend\nyarn\nyarn dev\n```\n\nOpen http://localhost:5173 to use the app.\n\nIf you prefer to run the backend on a different port, update VITE_WS_BACKEND_URL in `frontend/.env.local`\n\nFor debugging purposes, if you don't want to waste GPT4-Vision credits, you can run the backend in mock mode (which streams a pre-recorded response):\n\n```bash\nMOCK=true poetry run uvicorn main:app --reload --port 7001\n```\n\n## Docker\n\nIf you have Docker installed on your system, in the root directory, run:\n\n```bash\necho \"OPENAI_API_KEY=sk-your-key\" > .env\ndocker-compose up -d --build\n```\n\nThe app will be up and running at http://localhost:5173. Note that you can't develop the application with this setup as the file changes won't trigger a rebuild.\n\n## 🙋‍♂️ FAQs\n\n- **I'm running into an error when setting up the backend. How can I fix it?** [Try this](https://github.com/abi/screenshot-to-code/issues/3#issuecomment-1814777959). If that still doesn't work, open an issue.\n- **How do I get an OpenAI API key?** See https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md\n- **How can I configure an OpenAI proxy?** - If you're not able to access the OpenAI API directly (due to e.g. country restrictions), you can try a VPN or you can configure the OpenAI base URL to use a proxy: Set OPENAI_BASE_URL in the `backend/.env` or directly in the UI in the settings dialog. Make sure the URL has \"v1\" in the path so it should look like this: `https://xxx.xxxxx.xxx/v1`\n- **How can I update the backend host that my front-end connects to?** - Configure VITE_HTTP_BACKEND_URL and VITE_WS_BACKEND_URL in front/.env.local For example, set VITE_HTTP_BACKEND_URL=http://124.10.20.1:7001\n- **Seeing UTF-8 errors when running the backend?** - On windows, open the .env file with notepad++, then go to Encoding and select UTF-8.\n- **How can I provide feedback?** For feedback, feature requests and bug reports, open an issue or ping me on [Twitter](https://twitter.com/_abi_).\n\n## 📚 Examples\n\n**NYTimes**\n\n| Original                                                                                                                                                        | Replica                                                                                                                                                         |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| <img width=\"1238\" alt=\"Screenshot 2023-11-20 at 12 54 03 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/3b644dfa-9ca6-4148-84a7-3405b6671922\"> | <img width=\"1414\" alt=\"Screenshot 2023-11-20 at 12 59 56 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/26201c9f-1a28-4f35-a3b1-1f04e2b8ce2a\"> |\n\n**Instagram page (with not Taylor Swift pics)**\n\nhttps://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1\n\n**Hacker News** but it gets the colors wrong at first so we nudge it\n\nhttps://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d\n"
        },
        {
          "name": "Troubleshooting.md",
          "type": "blob",
          "size": 1.81,
          "content": "### Getting an OpenAI API key with GPT-4 model access\n\nYou don't need a ChatGPT Pro account. Screenshot to code uses API keys from your OpenAI developer account. In order to get access to the GPT4 Vision model, log into your OpenAI account and then, follow these instructions:\n\n1. Open [OpenAI Dashboard](https://platform.openai.com/)\n1. Go to Settings > Billing\n1. Click at the Add payment details\n<img width=\"900\" alt=\"285636868-c80deb92-ab47-45cd-988f-deee67fbd44d\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/4e0f4b77-9578-4f9a-803c-c12b1502f3d7\">\n\n4. You have to buy some credits. The minimum is $5.\n5. Go to Settings > Limits and check at the bottom of the page, your current tier has to be \"Tier 1\" to have GPT4 access\n<img width=\"900\" alt=\"285636973-da38bd4d-8a78-4904-8027-ca67d729b933\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/8d07cd84-0cf9-4f88-bc00-80eba492eadf\">\n\n6. Navigate to OpenAI [api keys](https://platform.openai.com/api-keys) page and create and copy a new secret key.\n7. Go to Screenshot to code and paste it in the Settings dialog under OpenAI key (gear icon). Your key is only stored in your browser. Never stored on our servers.\n\n## Still not working?\n\n- Some users have also reported that it can take upto 30 minutes after your credit purchase for the GPT4 vision model to be activated.\n- You need to add credits to your account AND set it to renew when credits run out in order to be upgraded to Tier 1. Make sure your \"Settings > Limits\" page shows that you are at Tier 1.\n\nIf you've followed these steps, and it still doesn't work, feel free to open a Github issue. We only provide support for the open source version since we don't have debugging logs on the hosted version. If you're looking to use the hosted version, we recommend getting a paid subscription on screenshottocode.com\n"
        },
        {
          "name": "backend",
          "type": "tree",
          "content": null
        },
        {
          "name": "blog",
          "type": "tree",
          "content": null
        },
        {
          "name": "design-docs.md",
          "type": "blob",
          "size": 0.19,
          "content": "## Version History\n\nVersion history is stored as a tree on the client-side.\n\n![Screenshot to Code](https://github.com/abi/screenshot-to-code/assets/23818/e35644aa-b90a-4aa7-8027-b8732796fd7c)\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.59,
          "content": "version: '3.9'\n\nservices:\n  backend:\n    build: \n      context: ./backend\n      dockerfile: Dockerfile\n    \n    env_file:\n      - .env\n    \n    # or \n    # environment:\n      #- BACKEND_PORT=7001   # if you change the port, make sure to also change the VITE_WS_BACKEND_URL at frontend/.env.local\n      # - OPENAI_API_KEY=your_openai_api_key\n    \n    ports:\n      - \"${BACKEND_PORT:-7001}:${BACKEND_PORT:-7001}\"\n\n    command: poetry run uvicorn main:app --host 0.0.0.0 --port ${BACKEND_PORT:-7001}\n  \n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    ports:\n      - \"5173:5173\"\n"
        },
        {
          "name": "frontend",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "josephmisiti/awesome-machine-learning",
      "stars": 66569,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.04,
          "content": "Creative Commons Legal Code\n\nNo need \n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 194.07,
          "content": "# Awesome Machine Learning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Track Awesome List](https://www.trackawesomelist.com/badge.svg)](https://www.trackawesomelist.com/josephmisiti/awesome-machine-learning/)\n\nA curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by `awesome-php`.\n\n_If you want to contribute to this list (please do), send me a pull request or contact me [@josephmisiti](https://twitter.com/josephmisiti)._\nAlso, a listed repository should be deprecated if:\n\n* Repository's owner explicitly says that \"this library is not maintained\".\n* Not committed for a long time (2~3 years).\n\nFurther resources:\n\n* For a list of free machine learning books available for download, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md).\n\n* For a list of professional machine learning events, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/events.md).\n\n* For a list of (mostly) free machine learning courses available online, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/courses.md).\n\n* For a list of blogs and newsletters on data science and machine learning, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/blogs.md).\n\n* For a list of free-to-attend meetups and local events, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/meetups.md).\n\n## Table of Contents\n\n### Frameworks and Libraries\n<!-- MarkdownTOC depth=4 -->\n<!-- Contents-->\n- [Awesome Machine Learning ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](#awesome-machine-learning-)\n  - [Table of Contents](#table-of-contents)\n    - [Frameworks and Libraries](#frameworks-and-libraries)\n    - [Tools](#tools)\n  - [APL](#apl)\n      - [General-Purpose Machine Learning](#apl-general-purpose-machine-learning)\n  - [C](#c)\n      - [General-Purpose Machine Learning](#c-general-purpose-machine-learning)\n      - [Computer Vision](#c-computer-vision)\n  - [C++](#cpp)\n      - [Computer Vision](#cpp-computer-vision)\n      - [General-Purpose Machine Learning](#cpp-general-purpose-machine-learning)\n      - [Natural Language Processing](#cpp-natural-language-processing)\n      - [Speech Recognition](#cpp-speech-recognition)\n      - [Sequence Analysis](#cpp-sequence-analysis)\n      - [Gesture Detection](#cpp-gesture-detection)\n      - [Reinforcement Learning](#cpp-reinforcement-learning)\n  - [Common Lisp](#common-lisp)\n      - [General-Purpose Machine Learning](#common-lisp-general-purpose-machine-learning)\n  - [Clojure](#clojure)\n      - [Natural Language Processing](#clojure-natural-language-processing)\n      - [General-Purpose Machine Learning](#clojure-general-purpose-machine-learning)\n      - [Deep Learning](#clojure-deep-learning)\n      - [Data Analysis](#clojure-data-analysis--data-visualization)\n      - [Data Visualization](#clojure-data-visualization)\n      - [Interop](#clojure-interop)\n      - [Misc](#clojure-misc)\n      - [Extra](#clojure-extra)\n  - [Crystal](#crystal)\n      - [General-Purpose Machine Learning](#crystal-general-purpose-machine-learning)\n  - [Elixir](#elixir)\n      - [General-Purpose Machine Learning](#elixir-general-purpose-machine-learning)\n      - [Natural Language Processing](#elixir-natural-language-processing)\n  - [Erlang](#erlang)\n      - [General-Purpose Machine Learning](#erlang-general-purpose-machine-learning)\n  - [Fortran](#fortran)\n      - [General-Purpose Machine Learning](#fortran-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#fortran-data-analysis--data-visualization)\n  - [Go](#go)\n      - [Natural Language Processing](#go-natural-language-processing)\n      - [General-Purpose Machine Learning](#go-general-purpose-machine-learning)\n      - [Spatial analysis and geometry](#go-spatial-analysis-and-geometry)\n      - [Data Analysis / Data Visualization](#go-data-analysis--data-visualization)\n      - [Computer vision](#go-computer-vision)\n      - [Reinforcement learning](#go-reinforcement-learning)\n  - [Haskell](#haskell)\n      - [General-Purpose Machine Learning](#haskell-general-purpose-machine-learning)\n  - [Java](#java)\n      - [Natural Language Processing](#java-natural-language-processing)\n      - [General-Purpose Machine Learning](#java-general-purpose-machine-learning)\n      - [Speech Recognition](#java-speech-recognition)\n      - [Data Analysis / Data Visualization](#java-data-analysis--data-visualization)\n      - [Deep Learning](#java-deep-learning)\n  - [Javascript](#javascript)\n      - [Natural Language Processing](#javascript-natural-language-processing)\n      - [Data Analysis / Data Visualization](#javascript-data-analysis--data-visualization)\n      - [General-Purpose Machine Learning](#javascript-general-purpose-machine-learning)\n      - [Misc](#javascript-misc)\n      - [Demos and Scripts](#javascript-demos-and-scripts)\n  - [Julia](#julia)\n      - [General-Purpose Machine Learning](#julia-general-purpose-machine-learning)\n      - [Natural Language Processing](#julia-natural-language-processing)\n      - [Data Analysis / Data Visualization](#julia-data-analysis--data-visualization)\n      - [Misc Stuff / Presentations](#julia-misc-stuff--presentations)\n  - [Kotlin](#kotlin)\n      - [Deep Learning](#kotlin-deep-learning)\n  - [Lua](#lua)\n      - [General-Purpose Machine Learning](#lua-general-purpose-machine-learning)\n      - [Demos and Scripts](#lua-demos-and-scripts)\n  - [Matlab](#matlab)\n      - [Computer Vision](#matlab-computer-vision)\n      - [Natural Language Processing](#matlab-natural-language-processing)\n      - [General-Purpose Machine Learning](#matlab-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#matlab-data-analysis--data-visualization)\n  - [.NET](#net)\n      - [Computer Vision](#net-computer-vision)\n      - [Natural Language Processing](#net-natural-language-processing)\n      - [General-Purpose Machine Learning](#net-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#net-data-analysis--data-visualization)\n  - [Objective C](#objective-c)\n    - [General-Purpose Machine Learning](#objective-c-general-purpose-machine-learning)\n  - [OCaml](#ocaml)\n    - [General-Purpose Machine Learning](#ocaml-general-purpose-machine-learning)\n  - [OpenCV](#opencv)\n    - [Computer Vision](#opencv-Computer-Vision)\n    - [Text-Detection](#Text-Character-Number-Detection)\n  - [Perl](#perl)\n    - [Data Analysis / Data Visualization](#perl-data-analysis--data-visualization)\n    - [General-Purpose Machine Learning](#perl-general-purpose-machine-learning)\n  - [Perl 6](#perl-6)\n    - [Data Analysis / Data Visualization](#perl-6-data-analysis--data-visualization)\n    - [General-Purpose Machine Learning](#perl-6-general-purpose-machine-learning)\n  - [PHP](#php)\n    - [Natural Language Processing](#php-natural-language-processing)\n    - [General-Purpose Machine Learning](#php-general-purpose-machine-learning)\n  - [Python](#python)\n      - [Computer Vision](#python-computer-vision)\n      - [Natural Language Processing](#python-natural-language-processing)\n      - [General-Purpose Machine Learning](#python-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#python-data-analysis--data-visualization)\n      - [Misc Scripts / iPython Notebooks / Codebases](#python-misc-scripts--ipython-notebooks--codebases)\n      - [Neural Networks](#python-neural-networks)\n      - [Survival Analysis](#python-survival-analysis)\n      - [Federated Learning](#python-federated-learning)\n      - [Kaggle Competition Source Code](#python-kaggle-competition-source-code)\n      - [Reinforcement Learning](#python-reinforcement-learning)\n      - [Speech Recognition](#python-speech-recognition)\n  - [Ruby](#ruby)\n      - [Natural Language Processing](#ruby-natural-language-processing)\n      - [General-Purpose Machine Learning](#ruby-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#ruby-data-analysis--data-visualization)\n      - [Misc](#ruby-misc)\n  - [Rust](#rust)\n      - [General-Purpose Machine Learning](#rust-general-purpose-machine-learning)\n      - [Deep Learning](#rust-deep-learning)\n      - [Natural Language Processing](#rust-natural-language-processing)\n  - [R](#r)\n      - [General-Purpose Machine Learning](#r-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#r-data-analysis--data-visualization)\n  - [SAS](#sas)\n      - [General-Purpose Machine Learning](#sas-general-purpose-machine-learning)\n      - [Data Analysis / Data Visualization](#sas-data-analysis--data-visualization)\n      - [Natural Language Processing](#sas-natural-language-processing)\n      - [Demos and Scripts](#sas-demos-and-scripts)\n  - [Scala](#scala)\n      - [Natural Language Processing](#scala-natural-language-processing)\n      - [Data Analysis / Data Visualization](#scala-data-analysis--data-visualization)\n      - [General-Purpose Machine Learning](#scala-general-purpose-machine-learning)\n  - [Scheme](#scheme)\n      - [Neural Networks](#scheme-neural-networks)\n  - [Swift](#swift)\n      - [General-Purpose Machine Learning](#swift-general-purpose-machine-learning)\n  - [TensorFlow](#tensorflow)\n      - [General-Purpose Machine Learning](#tensorflow-general-purpose-machine-learning)\n\n### [Tools](#tools-1)\n\n- [Neural Networks](#tools-neural-networks)\n- [Misc](#tools-misc)\n\n\n[Credits](#credits)\n\n<!-- /MarkdownTOC -->\n\n<a name=\"apl\"></a>\n## APL\n\n<a name=\"apl-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n* [naive-apl](https://github.com/mattcunningham/naive-apl) - Naive Bayesian Classifier implementation in APL. **[Deprecated]**\n\n<a name=\"c\"></a>\n## C\n\n<a name=\"c-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n* [Darknet](https://github.com/pjreddie/darknet) - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation.\n* [Recommender](https://github.com/GHamrouni/Recommender) - A C library for product recommendations/suggestions using collaborative filtering (CF).\n* [Hybrid Recommender System](https://github.com/SeniorSA/hybrid-rs-trainner) - A hybrid recommender system based upon scikit-learn algorithms. **[Deprecated]**\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It's written in C programming language and comes with Python programming language bindings.\n* [cONNXr](https://github.com/alrevuelta/cONNXr) - An `ONNX` runtime written in pure C (99) with zero dependencies focused on small embedded devices. Run inference on your machine learning models no matter which framework you train it with. Easy to install and compiles everywhere, even in very old devices.\n* [libonnx](https://github.com/xboot/libonnx) - A lightweight, portable pure C99 onnx inference engine for embedded devices with hardware acceleration support.\n\n<a name=\"c-computer-vision\"></a>\n#### Computer Vision\n\n* [CCV](https://github.com/liuliu/ccv) - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.\n* [VLFeat](http://www.vlfeat.org/) - VLFeat is an open and portable library of computer vision algorithms, which has a Matlab toolbox.\n\n<a name=\"cpp\"></a>\n## C++\n\n<a name=\"cpp-computer-vision\"></a>\n#### Computer Vision\n\n* [DLib](http://dlib.net/imaging.html) - DLib has C++ and Python interfaces for face detection and training general object detectors.\n* [EBLearn](http://eblearn.sourceforge.net/) - Eblearn is an object-oriented C++ library that implements various machine learning models **[Deprecated]**\n* [OpenCV](https://opencv.org) - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS.\n* [VIGRA](https://github.com/ukoethe/vigra) - VIGRA is a genertic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings.\n* [Openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) - A real-time multi-person keypoint detection library for body, face, hands, and foot estimation\n\n<a name=\"cpp-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Speedster](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) -Automatically apply SOTA optimization techniques to achieve the maximum inference speed-up on your hardware. [DEEP LEARNING]\n* [BanditLib](https://github.com/jkomiyama/banditlib) - A simple Multi-armed Bandit library. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING]\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, contains fast inference implementation and supports CPU and GPU (even multi-GPU) computation.\n* [CNTK](https://github.com/Microsoft/CNTK) - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph.\n* [CUDA](https://code.google.com/p/cuda-convnet/) - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING]\n* [DeepDetect](https://github.com/jolibrain/deepdetect) - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications.\n* [Distributed Machine learning Tool Kit (DMTK)](http://www.dmtk.io/) - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding.\n* [DLib](http://dlib.net/ml.html) - A suite of ML tools designed to be easy to imbed in other applications.\n* [DSSTNE](https://github.com/amznlabs/amazon-dsstne) - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility.\n* [DyNet](https://github.com/clab/dynet) - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python.\n* [Fido](https://github.com/FidoProject/Fido) - A highly-modular C++ machine learning library for embedded electronics and robotics.\n* [igraph](http://igraph.org/) - General purpose graph library.\n* [Intel® oneAPI Data Analytics Library](https://github.com/oneapi-src/oneDAL) - A high performance software library developed by Intel and optimized for Intel's architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes.\n* [LightGBM](https://github.com/Microsoft/LightGBM) - Microsoft's fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks.\n* [libfm](https://github.com/srendle/libfm) - A generic approach that allows to mimic most factorization models by feature engineering.\n* [MLDB](https://mldb.ai) - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs.\n* [mlpack](https://www.mlpack.org/) - A scalable C++ machine learning library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [N2D2](https://github.com/CEA-LIST/N2D2) - CEA-List's CAD framework for designing and simulating Deep Neural Network, and building full DNN-based applications on embedded platforms\n* [oneDNN](https://github.com/oneapi-src/oneDNN) - An open-source cross-platform performance library for deep learning applications.\n* [ParaMonte](https://github.com/cdslaborg/paramonte) - A general-purpose library with C/C++ interface for Bayesian data analysis and visualization via serial/parallel Monte Carlo and MCMC simulations. Documentation can be found [here](https://www.cdslab.org/paramonte/).\n* [proNet-core](https://github.com/cnclabs/proNet-core) - A general-purpose network embedding framework: pair-wise representations optimization Network Edit.\n* [PyCaret](https://github.com/pycaret/pycaret) - An open-source, low-code machine learning library in Python that automates machine learning workflows.\n* [PyCUDA](https://mathema.tician.de/software/pycuda/) - Python interface to CUDA\n* [ROOT](https://root.cern.ch) - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage.\n* [shark](http://image.diku.dk/shark/sphinx_pages/build/html/index.html) - A fast, modular, feature-rich open-source C++ machine learning library.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [sofia-ml](https://code.google.com/archive/p/sofia-ml) - Suite of fast incremental algorithms.\n* [Stan](http://mc-stan.org/) - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling.\n* [Timbl](https://languagemachines.github.io/timbl/) - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP.\n* [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) - A fast out-of-core learning system.\n* [Warp-CTC](https://github.com/baidu-research/warp-ctc) - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU.\n* [XGBoost](https://github.com/dmlc/xgboost) - A parallelized optimized general purpose gradient boosting library.\n* [ThunderGBM](https://github.com/Xtra-Computing/thundergbm) - A fast library for GBDTs and Random Forests on GPUs.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - A fast SVM library on GPUs and CPUs.\n* [LKYDeepNN](https://github.com/mosdeo/LKYDeepNN) - A header-only C++11 Neural Network library. Low dependency, native traditional chinese document.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertising and recommender systems.\n* [Featuretools](https://github.com/featuretools/featuretools) - A library for automated feature engineering. It excels at transforming transactional and relational datasets into feature matrices for machine learning using reusable feature engineering \"primitives\".\n* [skynet](https://github.com/Tyill/skynet) - A library for learning neural networks, has C-interface, net set in JSON. Written in C++ with bindings in Python, C++ and C#.\n* [Feast](https://github.com/gojek/feast) - A feature store for the management, discovery, and access of machine learning features. Feast provides a consistent view of feature data for both model training and model serving.\n* [Hopsworks](https://github.com/logicalclocks/hopsworks) - A data-intensive platform for AI with the industry's first open-source feature store. The Hopsworks Feature Store provides both a feature warehouse for training and batch based on Apache Hive and a feature serving database, based on MySQL Cluster, for online applications.\n* [Polyaxon](https://github.com/polyaxon/polyaxon) - A platform for reproducible and scalable machine learning and deep learning.\n* [QuestDB](https://questdb.io/) - A relational column-oriented database designed for real-time analytics on time series and event data.\n* [Phoenix](https://phoenix.arize.com) - Uncover insights, surface problems, monitor and fine tune your generative LLM, CV and tabular models.\n* [XAD](https://github.com/auto-differentiation/XAD) - Comprehensive backpropagation tool for C++.\n* [Truss](https://truss.baseten.co) - An open source framework for packaging and serving ML models.\n\n<a name=\"cpp-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [BLLIP Parser](https://github.com/BLLIP/bllip-parser) - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser).\n* [colibri-core](https://github.com/proycon/colibri-core) - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [CRF++](https://taku910.github.io/crfpp/) - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks. **[Deprecated]**\n* [CRFsuite](http://www.chokkan.org/software/crfsuite/) - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. **[Deprecated]**\n* [frog](https://github.com/LanguageMachines/frog) - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer.\n* [libfolia](https://github.com/LanguageMachines/libfolia) - C++ library for the [FoLiA format](https://proycon.github.io/folia/)\n* [MeTA](https://github.com/meta-toolkit/meta) - [MeTA : ModErn Text Analysis](https://meta-toolkit.org/) is a C++ Data Sciences Toolkit that facilitates mining big text data.\n* [MIT Information Extraction Toolkit](https://github.com/mit-nlp/MITIE) - C, C++, and Python tools for named entity recognition and relation extraction\n* [ucto](https://github.com/LanguageMachines/ucto) - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format.\n\n<a name=\"cpp-speech-recognition\"></a>\n#### Speech Recognition\n* [Kaldi](https://github.com/kaldi-asr/kaldi) - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.\n\n<a name=\"cpp-sequence-analysis\"></a>\n#### Sequence Analysis\n* [ToPS](https://github.com/ayoshiaki/tops) - This is an object-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet. **[Deprecated]**\n\n<a name=\"cpp-gesture-detection\"></a>\n#### Gesture Detection\n* [grt](https://github.com/nickgillian/grt) - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition.\n\n<a name=\"cpp-reinforcement-learning\"></a>\n#### Reinforcement Learning\n* [RLtools](https://github.com/rl-tools/rl-tools) - The fastest deep reinforcement learning library for continuous control, implemented header-only in pure, dependency-free C++ (Python bindings available as well).\n\n<a name=\"common-lisp\"></a>\n## Common Lisp\n\n<a name=\"common-lisp-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [mgl](https://github.com/melisgl/mgl/) - Neural networks (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes.\n* [mgl-gpr](https://github.com/melisgl/mgl-gpr/) - Evolutionary algorithms. **[Deprecated]**\n* [cl-libsvm](https://github.com/melisgl/cl-libsvm/) - Wrapper for the libsvm support vector machine library. **[Deprecated]**\n* [cl-online-learning](https://github.com/masatoi/cl-online-learning) - Online learning algorithms (Perceptron, AROW, SCW, Logistic Regression).\n* [cl-random-forest](https://github.com/masatoi/cl-random-forest) - Implementation of Random Forest in Common Lisp.\n\n<a name=\"clojure\"></a>\n## Clojure\n\n<a name=\"clojure-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Clojure-openNLP](https://github.com/dakrone/clojure-opennlp) - Natural Language Processing in Clojure (opennlp).\n* [Infections-clj](https://github.com/r0man/inflections-clj) - Rails-like inflection library for Clojure and ClojureScript.\n\n<a name=\"clojure-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [scicloj.ml](https://github.com/scicloj/scicloj.ml) -  A idiomatic Clojure machine learning library based on tech.ml.dataset with a unique approach for immutable data processing pipelines.\n* [clj-ml](https://github.com/joshuaeckroth/clj-ml/) - A machine learning library for Clojure built on top of Weka and friends.\n* [clj-boost](https://gitlab.com/alanmarazzi/clj-boost) - Wrapper for XGBoost\n* [Touchstone](https://github.com/ptaoussanis/touchstone) - Clojure A/B testing library.\n* [Clojush](https://github.com/lspector/Clojush) - The Push programming language and the PushGP genetic programming system implemented in Clojure.\n* [lambda-ml](https://github.com/cloudkj/lambda-ml) - Simple, concise implementations of machine learning techniques and utilities in Clojure.\n* [Infer](https://github.com/aria42/infer) - Inference and machine learning in Clojure. **[Deprecated]**\n* [Encog](https://github.com/jimpil/enclog) - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets). **[Deprecated]**\n* [Fungp](https://github.com/vollmerm/fungp) - A genetic programming library for Clojure. **[Deprecated]**\n* [Statistiker](https://github.com/clojurewerkz/statistiker) - Basic Machine Learning algorithms in Clojure. **[Deprecated]**\n* [clortex](https://github.com/htm-community/clortex) - General Machine Learning library using Numenta’s Cortical Learning Algorithm. **[Deprecated]**\n* [comportex](https://github.com/htm-community/comportex) - Functionally composable Machine Learning library using Numenta’s Cortical Learning Algorithm. **[Deprecated]**\n\n<a name=\"clojure-deep-learning\"></a>\n#### Deep Learning\n* [MXNet](https://mxnet.apache.org/versions/1.7.0/api/clojure) - Bindings to Apache MXNet - part of the MXNet project\n* [Deep Diamond](https://github.com/uncomplicate/deep-diamond) - A fast Clojure Tensor & Deep Learning library\n* [jutsu.ai](https://github.com/hswick/jutsu.ai) - Clojure wrapper for deeplearning4j with some added syntactic sugar.\n* [cortex](https://github.com/originrose/cortex) - Neural networks, regression and feature learning in Clojure.\n* [Flare](https://github.com/aria42/flare) - Dynamic Tensor Graph library in Clojure (think PyTorch, DynNet, etc.)\n* [dl4clj](https://github.com/yetanalytics/dl4clj) - Clojure wrapper for Deeplearning4j.\n\n<a name=\"clojure-data-analysis--data-visualization\"></a>\n#### Data Analysis\n* [tech.ml.dataset](https://github.com/techascent/tech.ml.dataset) - Clojure dataframe library and pipeline for data processing and machine learning\n* [Tablecloth](https://github.com/scicloj/tablecloth) - A dataframe grammar wrapping tech.ml.dataset, inspired by several R libraries\n* [Panthera](https://github.com/alanmarazzi/panthera) - Clojure API wrapping Python's Pandas library\n* [Incanter](http://incanter.org/) - Incanter is a Clojure-based, R-like platform for statistical computing and graphics.\n* [PigPen](https://github.com/Netflix/PigPen) - Map-Reduce for Clojure.\n* [Geni](https://github.com/zero-one-group/geni) - a Clojure dataframe library that runs on Apache Spark\n\n<a name=\"clojure-data-visualization\"></a>\n#### Data Visualization\n* [Hanami](https://github.com/jsa-aerial/hanami) : Clojure(Script) library and framework for creating interactive visualization applications based in Vega-Lite (VGL) and/or Vega (VG) specifications. Automatic framing and layouts along with a powerful templating system for abstracting visualization specs\n* [Saite](https://github.com/jsa-aerial/saite) -  Clojure(Script) client/server application for dynamic interactive explorations and the creation of live shareable documents capturing them using Vega/Vega-Lite, CodeMirror, markdown, and LaTeX\n* [Oz](https://github.com/metasoarous/oz) - Data visualisation using Vega/Vega-Lite and Hiccup, and a live-reload platform for literate-programming\n* [Envision](https://github.com/clojurewerkz/envision) - Clojure Data Visualisation library, based on Statistiker and D3.\n* [Pink Gorilla Notebook](https://github.com/pink-gorilla/gorilla-notebook) - A Clojure/Clojurescript notebook application/-library based on Gorilla-REPL\n* [clojupyter](https://github.com/clojupyter/clojupyter) -  A Jupyter kernel for Clojure - run Clojure code in Jupyter Lab, Notebook and Console.\n* [notespace](https://github.com/scicloj/notespace) - Notebook experience in your Clojure namespace\n* [Delight](https://github.com/datamechanics/delight) - A listener that streams your spark events logs to delight, a free and improved spark UI\n\n<a name=\"clojure-interop\"></a>\n#### Interop\n\n* [Java Interop](https://clojure.org/reference/java_interop) - Clojure has Native Java Interop from which Java's ML ecosystem can be accessed\n* [JavaScript Interop](https://clojurescript.org/reference/javascript-api) - ClojureScript has Native JavaScript Interop from which JavaScript's ML ecosystem can be accessed\n* [Libpython-clj](https://github.com/clj-python/libpython-clj) - Interop with Python\n* [ClojisR](https://github.com/scicloj/clojisr) - Interop with R and Renjin (R on the JVM)\n\n<a name=\"clojure-misc\"></a>\n#### Misc\n* [Neanderthal](https://neanderthal.uncomplicate.org/) - Fast Clojure Matrix Library (native CPU, GPU, OpenCL, CUDA)\n* [kixistats](https://github.com/MastodonC/kixi.stats) - A library of statistical distribution sampling and transducing functions\n* [fastmath](https://github.com/generateme/fastmath) - A collection of functions for mathematical and statistical computing, macine learning, etc., wrapping several JVM libraries\n* [matlib](https://github.com/atisharma/matlib) - A Clojure library of optimisation and control theory tools and convenience functions based on Neanderthal.\n\n<a name=\"clojure-extra\"></a>\n#### Extra\n* [Scicloj](https://scicloj.github.io/pages/libraries/) - Curated list of ML related resources for Clojure.\n\n<a name=\"crystal\"></a>\n## Crystal\n\n<a name=\"crystal-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [machine](https://github.com/mathieulaporte/machine) - Simple machine learning algorithm.\n* [crystal-fann](https://github.com/NeuraLegion/crystal-fann) - FANN (Fast Artificial Neural Network) binding.\n\n<a name=\"elixir\"></a>\n## Elixir\n\n<a name=\"elixir-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Simple Bayes](https://github.com/fredwu/simple_bayes) - A Simple Bayes / Naive Bayes implementation in Elixir.\n* [emel](https://github.com/mrdimosthenis/emel) - A simple and functional machine learning library written in Elixir.\n* [Tensorflex](https://github.com/anshuman23/tensorflex) - Tensorflow bindings for the Elixir programming language.\n\n<a name=\"elixir-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Stemmer](https://github.com/fredwu/stemmer) - An English (Porter2) stemming implementation in Elixir.\n\n<a name=\"erlang\"></a>\n## Erlang\n\n<a name=\"erlang-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Disco](https://github.com/discoproject/disco/) - Map Reduce in Erlang. **[Deprecated]**\n\n<a name=\"fortran\"></a>\n## Fortran\n\n<a name=\"fortran-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [neural-fortran](https://github.com/modern-fortran/neural-fortran) - A parallel neural net microframework.\nRead the paper [here](https://arxiv.org/abs/1902.06714).\n\n<a name=\"fortran-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [ParaMonte](https://github.com/cdslaborg/paramonte) - A general-purpose Fortran library for Bayesian data analysis and visualization via serial/parallel Monte Carlo and MCMC simulations. Documentation can be found [here](https://www.cdslab.org/paramonte/).\n\n<a name=\"go\"></a>\n## Go\n\n<a name=\"go-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Cybertron](https://github.com/nlpodyssey/cybertron) - Cybertron: the home planet of the Transformers in Go.\n* [snowball](https://github.com/tebeka/snowball) - Snowball Stemmer for Go.\n* [word-embedding](https://github.com/ynqa/word-embedding) - Word Embeddings: the full implementation of word2vec, GloVe in Go.\n* [sentences](https://github.com/neurosnap/sentences) - Golang implementation of Punkt sentence tokenizer.\n* [go-ngram](https://github.com/Lazin/go-ngram) - In-memory n-gram index with compression. *[Deprecated]*\n* [paicehusk](https://github.com/Rookii/paicehusk) - Golang implementation of the Paice/Husk Stemming Algorithm. *[Deprecated]*\n* [go-porterstemmer](https://github.com/reiver/go-porterstemmer) - A native Go clean room implementation of the Porter Stemming algorithm. **[Deprecated]**\n\n<a name=\"go-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Spago](https://github.com/nlpodyssey/spago) - Self-contained Machine Learning and Natural Language Processing library in Go.\n* [birdland](https://github.com/rlouf/birdland) - A recommendation library in Go.\n* [eaopt](https://github.com/MaxHalford/eaopt) - An evolutionary optimization library.\n* [leaves](https://github.com/dmitryikh/leaves) - A pure Go implementation of the prediction part of GBRTs, including XGBoost and LightGBM.\n* [gobrain](https://github.com/goml/gobrain) - Neural Networks written in Go.\n* [go-featureprocessing](https://github.com/nikolaydubina/go-featureprocessing) - Fast and convenient feature processing for low latency machine learning in Go.\n* [go-mxnet-predictor](https://github.com/songtianyi/go-mxnet-predictor) - Go binding for MXNet c_predict_api to do inference with a pre-trained model.\n* [go-ml-benchmarks](https://github.com/nikolaydubina/go-ml-benchmarks) — benchmarks of machine learning inference for Go.\n* [go-ml-transpiler](https://github.com/znly/go-ml-transpiler) - An open source Go transpiler for machine learning models.\n* [golearn](https://github.com/sjwhitworth/golearn) - Machine learning for Go.\n* [goml](https://github.com/cdipaolo/goml) - Machine learning library written in pure Go.\n* [gorgonia](https://github.com/gorgonia/gorgonia) - Deep learning in Go.\n* [goro](https://github.com/aunum/goro) - A high-level machine learning library in the vein of Keras.\n* [gorse](https://github.com/zhenghaoz/gorse) - An offline recommender system backend based on collaborative filtering written in Go.\n* [therfoo](https://github.com/therfoo/therfoo) - An embedded deep learning library for Go.\n* [neat](https://github.com/jinyeom/neat) - Plug-and-play, parallel Go framework for NeuroEvolution of Augmenting Topologies (NEAT). **[Deprecated]**\n* [go-pr](https://github.com/daviddengcn/go-pr) - Pattern recognition package in Go lang. **[Deprecated]**\n* [go-ml](https://github.com/alonsovidales/go_ml) - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution. **[Deprecated]**\n* [GoNN](https://github.com/fxsjy/gonn) - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN. **[Deprecated]**\n* [bayesian](https://github.com/jbrukh/bayesian) - Naive Bayesian Classification for Golang. **[Deprecated]**\n* [go-galib](https://github.com/thoj/go-galib) - Genetic Algorithms library written in Go / Golang. **[Deprecated]**\n* [Cloudforest](https://github.com/ryanbressler/CloudForest) - Ensembles of decision trees in Go/Golang. **[Deprecated]**\n* [go-dnn](https://github.com/sudachen/go-dnn) - Deep Neural Networks for Golang (powered by MXNet)\n\n<a name=\"go-spatial-analysis-and-geometry\"></a>\n#### Spatial analysis and geometry\n\n* [go-geom](https://github.com/twpayne/go-geom) - Go library to handle geometries.\n* [gogeo](https://github.com/golang/geo) - Spherical geometry in Go.\n\n<a name=\"go-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [dataframe-go](https://github.com/rocketlaunchr/dataframe-go) - Dataframes for machine-learning and statistics (similar to pandas).\n* [gota](https://github.com/go-gota/gota) - Dataframes.\n* [gonum/mat](https://godoc.org/gonum.org/v1/gonum/mat) - A linear algebra package for Go.\n* [gonum/optimize](https://godoc.org/gonum.org/v1/gonum/optimize) - Implementations of optimization algorithms.\n* [gonum/plot](https://godoc.org/gonum.org/v1/plot) - A plotting library.\n* [gonum/stat](https://godoc.org/gonum.org/v1/gonum/stat) - A statistics library.\n* [SVGo](https://github.com/ajstarks/svgo) - The Go Language library for SVG generation.\n* [glot](https://github.com/arafatk/glot) - Glot is a plotting library for Golang built on top of gnuplot.\n* [globe](https://github.com/mmcloughlin/globe) - Globe wireframe visualization.\n* [gonum/graph](https://godoc.org/gonum.org/v1/gonum/graph) - General-purpose graph library.\n* [go-graph](https://github.com/StepLg/go-graph) - Graph library for Go/Golang language. **[Deprecated]**\n* [RF](https://github.com/fxsjy/RF.go) - Random forests implementation in Go. **[Deprecated]**\n\n<a name=\"go-computer-vision\"></a>\n#### Computer vision\n\n* [GoCV](https://github.com/hybridgroup/gocv) - Package for computer vision using OpenCV 4 and beyond.\n\n<a name=\"go-reinforcement-learning\"></a>\n#### Reinforcement learning\n\n* [gold](https://github.com/aunum/gold) - A reinforcement learning library.\n* [stable-baselines3](https://github.com/DLR-RM/stable-baselines3) - PyTorch implementations of Stable Baselines (deep) reinforcement learning algorithms.\n\n<a name=\"haskell\"></a>\n## Haskell\n\n<a name=\"haskell-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n* [haskell-ml](https://github.com/ajtulloch/haskell-ml) - Haskell implementations of various ML algorithms. **[Deprecated]**\n* [HLearn](https://github.com/mikeizbicki/HLearn) - a suite of libraries for interpreting machine learning models according to their algebraic structure. **[Deprecated]**\n* [hnn](https://github.com/alpmestan/HNN) - Haskell Neural Network library.\n* [hopfield-networks](https://github.com/ajtulloch/hopfield-networks) - Hopfield Networks for unsupervised learning in Haskell. **[Deprecated]**\n* [DNNGraph](https://github.com/ajtulloch/dnngraph) - A DSL for deep neural networks. **[Deprecated]**\n* [LambdaNet](https://github.com/jbarrow/LambdaNet) - Configurable Neural Networks in Haskell. **[Deprecated]**\n\n<a name=\"java\"></a>\n## Java\n\n<a name=\"java-natural-language-processing\"></a>\n#### Natural Language Processing\n* [Cortical.io](https://www.cortical.io/) - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain.\n* [IRIS](https://github.com/cortical-io/Iris) - [Cortical.io's](https://cortical.io) FREE NLP, Retina API Analysis Tool (written in JavaFX!) - [See the Tutorial Video](https://www.youtube.com/watch?v=CsF4pd7fGF0).\n* [CoreNLP](https://nlp.stanford.edu/software/corenlp.shtml) - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words.\n* [Stanford Parser](https://nlp.stanford.edu/software/lex-parser.shtml) - A natural language parser is a program that works out the grammatical structure of sentences.\n* [Stanford POS Tagger](https://nlp.stanford.edu/software/tagger.shtml) - A Part-Of-Speech Tagger (POS Tagger).\n* [Stanford Name Entity Recognizer](https://nlp.stanford.edu/software/CRF-NER.shtml) - Stanford NER is a Java implementation of a Named Entity Recognizer.\n* [Stanford Word Segmenter](https://nlp.stanford.edu/software/segmenter.shtml) - Tokenization of raw text is a standard pre-processing step for many NLP tasks.\n* [Tregex, Tsurgeon and Semgrex](https://nlp.stanford.edu/software/tregex.shtml) - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for \"tree regular expressions\").\n* [Stanford Phrasal: A Phrase-Based Translation System](https://nlp.stanford.edu/phrasal/)\n* [Stanford English Tokenizer](https://nlp.stanford.edu/software/tokenizer.shtml) - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java.\n* [Stanford Tokens Regex](https://nlp.stanford.edu/software/tokensregex.shtml) - A tokenizer divides text into a sequence of tokens, which roughly correspond to \"words\".\n* [Stanford Temporal Tagger](https://nlp.stanford.edu/software/sutime.shtml) - SUTime is a library for recognizing and normalizing time expressions.\n* [Stanford SPIED](https://nlp.stanford.edu/software/patternslearning.shtml) - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion.\n* [Twitter Text Java](https://github.com/twitter/twitter-text/tree/master/java) - A Java implementation of Twitter's text processing library.\n* [MALLET](http://mallet.cs.umass.edu/) - A Java-based package for statistical natural language processing, document classification, clustering, topic modelling, information extraction, and other machine learning applications to text.\n* [OpenNLP](https://opennlp.apache.org/) - A machine learning based toolkit for the processing of natural language text.\n* [LingPipe](http://alias-i.com/lingpipe/index.html) - A tool kit for processing text using computational linguistics.\n* [ClearTK](https://github.com/ClearTK/cleartk) - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. **[Deprecated]**\n* [Apache cTAKES](https://ctakes.apache.org/) - Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text.\n* [NLP4J](https://github.com/emorynlp/nlp4j) - The NLP4J project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. **[Deprecated]**\n* [CogcompNLP](https://github.com/CogComp/cogcomp-nlp) - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois' Cognitive Computation Group, for example `illinois-core-utilities` which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, `illinois-edison` a library for feature extraction from illinois-core-utilities data structures and many other packages.\n\n<a name=\"java-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [aerosolve](https://github.com/airbnb/aerosolve) - A machine learning library by Airbnb designed from the ground up to be human friendly.\n* [AMIDST Toolbox](http://www.amidsttoolbox.com/) - A Java Toolbox for Scalable Probabilistic Machine Learning.\n* [Chips-n-Salsa](https://github.com/cicirello/Chips-n-Salsa) - A Java library for genetic algorithms, evolutionary computation, and stochastic local search, with a focus on self-adaptation / self-tuning, as well as parallel execution.\n* [Datumbox](https://github.com/datumbox/datumbox-framework) - Machine Learning framework for rapid development of Machine Learning and Statistical applications.\n* [ELKI](https://elki-project.github.io/) - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.)\n* [Encog](https://github.com/encog/encog-java-core) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trainings using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [H2O](https://github.com/h2oai/h2o-3) - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON.\n* [htm.java](https://github.com/numenta/htm.java) - General Machine Learning library using Numenta’s Cortical Learning Algorithm.\n* [liblinear-java](https://github.com/bwaldvogel/liblinear-java) - Java version of liblinear.\n* [Mahout](https://github.com/apache/mahout) - Distributed machine learning.\n* [Meka](http://meka.sourceforge.net/) - An open source implementation of methods for multi-label classification and evaluation (extension to Weka).\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark.\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Neuroph](http://neuroph.sourceforge.net/) - Neuroph is lightweight Java neural network framework.\n* [ORYX](https://github.com/oryxproject/oryx) - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning.\n* [Samoa](https://samoa.incubator.apache.org/) SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms.\n* [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib/) - RankLib is a library of learning to rank algorithms. **[Deprecated]**\n* [rapaio](https://github.com/padreati/rapaio) - statistics, data mining and machine learning toolbox in Java.\n* [RapidMiner](https://rapidminer.com) - RapidMiner integration into Java code.\n* [Stanford Classifier](https://nlp.stanford.edu/software/classifier.shtml) - A classifier is a machine learning tool that will take data items and place them into one of k classes.\n* [Smile](https://haifengl.github.io/) - Statistical Machine Intelligence & Learning Engine.\n* [SystemML](https://github.com/apache/systemml) - flexible, scalable machine learning (ML) language.\n* [Tribou](https://tribuo.org) - A machine learning library written in Java by Oracle.\n* [Weka](https://www.cs.waikato.ac.nz/ml/weka/) - Weka is a collection of machine learning algorithms for data mining tasks.\n* [LBJava](https://github.com/CogComp/lbjava) - Learning Based Java is a modelling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer's application.\n* [knn-java-library](https://github.com/felipexw/knn-java-library) - Just a simple implementation of K-Nearest Neighbors algorithm using with a bunch of similarity measures.\n\n<a name=\"java-speech-recognition\"></a>\n#### Speech Recognition\n* [CMU Sphinx](https://cmusphinx.github.io) - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library.\n\n<a name=\"java-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Hadoop](https://github.com/apache/hadoop) - Hadoop/HDFS.\n* [Onyx](https://github.com/onyx-platform/onyx) - Distributed, masterless, high performance, fault tolerant data processing. Written entirely in Clojure.\n* [Spark](https://github.com/apache/spark) - Spark is a fast and general engine for large-scale data processing.\n* [Storm](https://storm.apache.org/) - Storm is a distributed realtime computation system.\n* [Impala](https://github.com/cloudera/impala) - Real-time Query for Hadoop.\n* [DataMelt](https://jwork.org/dmelt/) - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization.\n* [Dr. Michael Thomas Flanagan's Java Scientific Library.](https://www.ee.ucl.ac.uk/~mflanaga/java/) **[Deprecated]**\n\n<a name=\"java-deep-learning\"></a>\n#### Deep Learning\n\n* [Deeplearning4j](https://github.com/deeplearning4j/deeplearning4j) - Scalable deep learning for industry with parallel GPUs.\n* [Keras Beginner Tutorial](https://victorzhou.com/blog/keras-neural-network-tutorial/) - Friendly guide on using Keras to implement a simple Neural Network in Python.\n* [deepjavalibrary/djl](https://github.com/deepjavalibrary/djl) - Deep Java Library (DJL) is an open-source, high-level, engine-agnostic Java framework for deep learning, designed to be easy to get started with and simple to use for Java developers.\n\n<a name=\"javascript\"></a>\n## JavaScript\n\n<a name=\"javascript-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Twitter-text](https://github.com/twitter/twitter-text) - A JavaScript implementation of Twitter's text processing library.\n* [natural](https://github.com/NaturalNode/natural) - General natural language facilities for node.\n* [Knwl.js](https://github.com/loadfive/Knwl.js) - A Natural Language Processor in JS.\n* [Retext](https://github.com/retextjs/retext) - Extensible system for analyzing and manipulating natural language.\n* [NLP Compromise](https://github.com/spencermountain/compromise) - Natural Language processing in the browser.\n* [nlp.js](https://github.com/axa-group/nlp.js) - An NLP library built in node over Natural, with entity extraction, sentiment analysis, automatic language identify, and so more.\n\n\n\n<a name=\"javascript-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [D3.js](https://d3js.org/)\n* [High Charts](https://www.highcharts.com/)\n* [NVD3.js](http://nvd3.org/)\n* [dc.js](https://dc-js.github.io/dc.js/)\n* [chartjs](https://www.chartjs.org/)\n* [dimple](http://dimplejs.org/)\n* [amCharts](https://www.amcharts.com/)\n* [D3xter](https://github.com/NathanEpstein/D3xter) - Straight forward plotting built on D3. **[Deprecated]**\n* [statkit](https://github.com/rigtorp/statkit) - Statistics kit for JavaScript. **[Deprecated]**\n* [datakit](https://github.com/nathanepstein/datakit) - A lightweight framework for data analysis in JavaScript\n* [science.js](https://github.com/jasondavies/science.js/) - Scientific and statistical computing in JavaScript. **[Deprecated]**\n* [Z3d](https://github.com/NathanEpstein/Z3d) - Easily make interactive 3d plots built on Three.js **[Deprecated]**\n* [Sigma.js](http://sigmajs.org/) - JavaScript library dedicated to graph drawing.\n* [C3.js](https://c3js.org/) - customizable library based on D3.js for easy chart drawing.\n* [Datamaps](https://datamaps.github.io/) - Customizable SVG map/geo visualizations using D3.js. **[Deprecated]**\n* [ZingChart](https://www.zingchart.com/) - library written on Vanilla JS for big data visualization.\n* [cheminfo](https://www.cheminfo.org/) - Platform for data visualization and analysis, using the [visualizer](https://github.com/npellet/visualizer) project.\n* [Learn JS Data](http://learnjsdata.com/)\n* [AnyChart](https://www.anychart.com/)\n* [FusionCharts](https://www.fusioncharts.com/)\n* [Nivo](https://nivo.rocks) - built on top of the awesome d3 and Reactjs libraries\n\n\n<a name=\"javascript-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Auto ML](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file! **[Deprecated]**\n* [Convnet.js](https://cs.stanford.edu/people/karpathy/convnetjs/) - ConvNetJS is a JavaScript library for training Deep Learning models[DEEP LEARNING] **[Deprecated]**\n* [Clusterfck](https://harthur.github.io/clusterfck/) - Agglomerative hierarchical clustering implemented in JavaScript for Node.js and the browser. **[Deprecated]**\n* [Clustering.js](https://github.com/emilbayes/clustering.js) - Clustering algorithms implemented in JavaScript for Node.js and the browser. **[Deprecated]**\n* [Decision Trees](https://github.com/serendipious/nodejs-decision-tree-id3) - NodeJS Implementation of Decision Tree using ID3 Algorithm. **[Deprecated]**\n* [DN2A](https://github.com/antoniodeluca/dn2a.js) - Digital Neural Networks Architecture. **[Deprecated]**\n* [figue](https://code.google.com/archive/p/figue) - K-means, fuzzy c-means and agglomerative clustering.\n* [Gaussian Mixture Model](https://github.com/lukapopijac/gaussian-mixture-model) - Unsupervised machine learning with multivariate Gaussian mixture model.\n* [Node-fann](https://github.com/rlidwka/node-fann) - FANN (Fast Artificial Neural Network Library) bindings for Node.js **[Deprecated]**\n* [Keras.js](https://github.com/transcranial/keras-js) - Run Keras models in the browser, with GPU support provided by WebGL 2.\n* [Kmeans.js](https://github.com/emilbayes/kMeans.js) - Simple JavaScript implementation of the k-means algorithm, for node.js and the browser. **[Deprecated]**\n* [LDA.js](https://github.com/primaryobjects/lda) - LDA topic modelling for Node.js\n* [Learning.js](https://github.com/yandongliu/learningjs) - JavaScript implementation of logistic regression/c4.5 decision tree **[Deprecated]**\n* [machinelearn.js](https://github.com/machinelearnjs/machinelearnjs) - Machine Learning library for the web, Node.js and developers\n* [mil-tokyo](https://github.com/mil-tokyo) - List of several machine learning libraries.\n* [Node-SVM](https://github.com/nicolaspanel/node-svm) - Support Vector Machine for Node.js\n* [Brain](https://github.com/harthur/brain) - Neural networks in JavaScript **[Deprecated]**\n* [Brain.js](https://github.com/BrainJS/brain.js) - Neural networks in JavaScript - continued community fork of [Brain](https://github.com/harthur/brain).\n* [Bayesian-Bandit](https://github.com/omphalos/bayesian-bandit.js) - Bayesian bandit implementation for Node and the browser. **[Deprecated]**\n* [Synaptic](https://github.com/cazala/synaptic) - Architecture-free neural network library for Node.js and the browser.\n* [kNear](https://github.com/NathanEpstein/kNear) - JavaScript implementation of the k nearest neighbors algorithm for supervised learning.\n* [NeuralN](https://github.com/totemstech/neuraln) - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. **[Deprecated]**\n* [kalman](https://github.com/itamarwe/kalman) - Kalman filter for JavaScript. **[Deprecated]**\n* [shaman](https://github.com/luccastera/shaman) - Node.js library with support for both simple and multiple linear regression. **[Deprecated]**\n* [ml.js](https://github.com/mljs/ml) - Machine learning and numerical analysis tools for Node.js and the Browser!\n* [ml5](https://github.com/ml5js/ml5-library) - Friendly machine learning for the web!\n* [Pavlov.js](https://github.com/NathanEpstein/Pavlov.js) - Reinforcement learning using Markov Decision Processes.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [TensorFlow.js](https://js.tensorflow.org/) - A WebGL accelerated, browser based JavaScript library for training and deploying ML models.\n* [JSMLT](https://github.com/jsmlt/jsmlt) - Machine learning toolkit with classification and clustering for Node.js; supports visualization (see [visualml.io](https://visualml.io)).\n* [xgboost-node](https://github.com/nuanio/xgboost-node) - Run XGBoost model and make predictions in Node.js.\n* [Netron](https://github.com/lutzroeder/netron) - Visualizer for machine learning models.\n* [tensor-js](https://github.com/Hoff97/tensorjs) - A deep learning library for the browser, accelerated by WebGL and WebAssembly.\n* [WebDNN](https://github.com/mil-tokyo/webdnn) - Fast Deep Neural Network JavaScript Framework. WebDNN uses next generation JavaScript API, WebGPU for GPU execution, and WebAssembly for CPU execution.\n* [WebNN](https://webnn.dev) - A new web standard that allows web apps and frameworks to accelerate deep neural networks with on-device hardware such as GPUs, CPUs, or purpose-built AI accelerators.\n\n<a name=\"javascript-misc\"></a>\n#### Misc\n\n* [stdlib](https://github.com/stdlib-js/stdlib) - A standard library for JavaScript and Node.js, with an emphasis on numeric computing. The library provides a collection of robust, high performance libraries for mathematics, statistics, streams, utilities, and more.\n* [sylvester](https://github.com/jcoglan/sylvester) - Vector and Matrix math for JavaScript. **[Deprecated]**\n* [simple-statistics](https://github.com/simple-statistics/simple-statistics) - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in Node.js.\n* [regression-js](https://github.com/Tom-Alexander/regression-js) - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data.\n* [Lyric](https://github.com/flurry/Lyric) - Linear Regression library. **[Deprecated]**\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [MLPleaseHelp](https://github.com/jgreenemi/MLPleaseHelp) - MLPleaseHelp is a simple ML resource search engine. You can use this search engine right now at [https://jgreenemi.github.io/MLPleaseHelp/](https://jgreenemi.github.io/MLPleaseHelp/), provided via GitHub Pages.\n* [Pipcook](https://github.com/alibaba/pipcook) - A JavaScript application framework for machine learning and its engineering.\n\n<a name=\"javascript-demos-and-scripts\"></a>\n#### Demos and Scripts\n* [The Bot](https://github.com/sta-ger/TheBot) - Example of how the neural network learns to predict the angle between two points created with [Synaptic](https://github.com/cazala/synaptic).\n* [Half Beer](https://github.com/sta-ger/HalfBeer) - Beer glass classifier created with [Synaptic](https://github.com/cazala/synaptic).\n* [NSFWJS](http://nsfwjs.com) - Indecent content checker with TensorFlow.js\n* [Rock Paper Scissors](https://rps-tfjs.netlify.com/) - Rock Paper Scissors trained in the browser with TensorFlow.js\n* [Heroes Wear Masks](https://heroeswearmasks.fun/) - A fun TensorFlow.js-based oracle that tells, whether one wears a face mask or not. It can even tell when one wears the mask incorrectly.\n\n<a name=\"julia\"></a>\n## Julia\n\n<a name=\"julia-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [MachineLearning](https://github.com/benhamner/MachineLearning.jl) - Julia Machine Learning library. **[Deprecated]**\n* [MLBase](https://github.com/JuliaStats/MLBase.jl) - A set of functions to support the development of machine learning algorithms.\n* [PGM](https://github.com/JuliaStats/PGM.jl) - A Julia framework for probabilistic graphical models.\n* [DA](https://github.com/trthatcher/DiscriminantAnalysis.jl) - Julia package for Regularized Discriminant Analysis.\n* [Regression](https://github.com/lindahua/Regression.jl) - Algorithms for regression analysis (e.g. linear regression and logistic regression). **[Deprecated]**\n* [Local Regression](https://github.com/JuliaStats/Loess.jl) - Local regression, so smooooth!\n* [Naive Bayes](https://github.com/nutsiepully/NaiveBayes.jl) - Simple Naive Bayes implementation in Julia. **[Deprecated]**\n* [Mixed Models](https://github.com/dmbates/MixedModels.jl) - A Julia package for fitting (statistical) mixed-effects models.\n* [Simple MCMC](https://github.com/fredo-dedup/SimpleMCMC.jl) - basic MCMC sampler implemented in Julia. **[Deprecated]**\n* [Distances](https://github.com/JuliaStats/Distances.jl) - Julia module for Distance evaluation.\n* [Decision Tree](https://github.com/bensadeghi/DecisionTree.jl) - Decision Tree Classifier and Regressor.\n* [Neural](https://github.com/compressed/BackpropNeuralNet.jl) - A neural network in Julia.\n* [MCMC](https://github.com/doobwa/MCMC.jl) - MCMC tools for Julia. **[Deprecated]**\n* [Mamba](https://github.com/brian-j-smith/Mamba.jl) - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia.\n* [GLM](https://github.com/JuliaStats/GLM.jl) - Generalized linear models in Julia.\n* [Gaussian Processes](https://github.com/STOR-i/GaussianProcesses.jl) - Julia package for Gaussian processes.\n* [Online Learning](https://github.com/lendle/OnlineLearning.jl) **[Deprecated]**\n* [GLMNet](https://github.com/simonster/GLMNet.jl) - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet.\n* [Clustering](https://github.com/JuliaStats/Clustering.jl) - Basic functions for clustering data: k-means, dp-means, etc.\n* [SVM](https://github.com/JuliaStats/SVM.jl) - SVM for Julia. **[Deprecated]**\n* [Kernel Density](https://github.com/JuliaStats/KernelDensity.jl) - Kernel density estimators for Julia.\n* [MultivariateStats](https://github.com/JuliaStats/MultivariateStats.jl) - Methods for dimensionality reduction.\n* [NMF](https://github.com/JuliaStats/NMF.jl) - A Julia package for non-negative matrix factorization.\n* [ANN](https://github.com/EricChiang/ANN.jl) - Julia artificial neural networks. **[Deprecated]**\n* [Mocha](https://github.com/pluskid/Mocha.jl) - Deep Learning framework for Julia inspired by Caffe. **[Deprecated]**\n* [XGBoost](https://github.com/dmlc/XGBoost.jl) - eXtreme Gradient Boosting Package in Julia.\n* [ManifoldLearning](https://github.com/wildart/ManifoldLearning.jl) - A Julia package for manifold learning and nonlinear dimensionality reduction.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [Merlin](https://github.com/hshindo/Merlin.jl) - Flexible Deep Learning Framework in Julia.\n* [ROCAnalysis](https://github.com/davidavdav/ROCAnalysis.jl) - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers.\n* [GaussianMixtures](https://github.com/davidavdav/GaussianMixtures.jl) - Large scale Gaussian Mixture Models.\n* [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl) - Julia implementation of the scikit-learn API.\n* [Knet](https://github.com/denizyuret/Knet.jl) - Koç University Deep Learning Framework.\n* [Flux](https://fluxml.ai/) - Relax! Flux is the ML library that doesn't make you tensor\n* [MLJ](https://github.com/alan-turing-institute/MLJ.jl) - A Julia machine learning framework.\n\n<a name=\"julia-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Topic Models](https://github.com/slycoder/TopicModels.jl) - TopicModels for Julia. **[Deprecated]**\n* [Text Analysis](https://github.com/JuliaText/TextAnalysis.jl) - Julia package for text analysis.\n* [Word Tokenizers](https://github.com/JuliaText/WordTokenizers.jl) - Tokenizers for Natural Language Processing in Julia\n* [Corpus Loaders](https://github.com/JuliaText/CorpusLoaders.jl) - A Julia package providing a variety of loaders for various NLP corpora.\n* [Embeddings](https://github.com/JuliaText/Embeddings.jl) - Functions and data dependencies for loading various word embeddings\n* [Languages](https://github.com/JuliaText/Languages.jl) - Julia package for working with various human languages\n* [WordNet](https://github.com/JuliaText/WordNet.jl) - A Julia package for Princeton's WordNet\n\n<a name=\"julia-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [Graph Layout](https://github.com/IainNZ/GraphLayout.jl) - Graph layout algorithms in pure Julia.\n* [LightGraphs](https://github.com/JuliaGraphs/LightGraphs.jl) - Graph modelling and analysis.\n* [Data Frames Meta](https://github.com/JuliaData/DataFramesMeta.jl) - Metaprogramming tools for DataFrames.\n* [Julia Data](https://github.com/nfoti/JuliaData) - library for working with tabular data in Julia. **[Deprecated]**\n* [Data Read](https://github.com/queryverse/ReadStat.jl) - Read files from Stata, SAS, and SPSS.\n* [Hypothesis Tests](https://github.com/JuliaStats/HypothesisTests.jl) - Hypothesis tests for Julia.\n* [Gadfly](https://github.com/GiovineItalia/Gadfly.jl) - Crafty statistical graphics for Julia.\n* [Stats](https://github.com/JuliaStats/StatsKit.jl) - Statistical tests for Julia.\n* [RDataSets](https://github.com/johnmyleswhite/RDatasets.jl) - Julia package for loading many of the data sets available in R.\n* [DataFrames](https://github.com/JuliaData/DataFrames.jl) - library for working with tabular data in Julia.\n* [Distributions](https://github.com/JuliaStats/Distributions.jl) - A Julia package for probability distributions and associated functions.\n* [Data Arrays](https://github.com/JuliaStats/DataArrays.jl) - Data structures that allow missing values. **[Deprecated]**\n* [Time Series](https://github.com/JuliaStats/TimeSeries.jl) - Time series toolkit for Julia.\n* [Sampling](https://github.com/lindahua/Sampling.jl) - Basic sampling algorithms for Julia.\n\n<a name=\"julia-misc-stuff--presentations\"></a>\n#### Misc Stuff / Presentations\n\n* [DSP](https://github.com/JuliaDSP/DSP.jl) - Digital Signal Processing (filtering, periodograms, spectrograms, window functions).\n* [JuliaCon Presentations](https://github.com/JuliaCon/presentations) - Presentations for JuliaCon.\n* [SignalProcessing](https://github.com/JuliaDSP/DSP.jl) - Signal Processing tools for Julia.\n* [Images](https://github.com/JuliaImages/Images.jl) - An image library for Julia.\n* [DataDeps](https://github.com/oxinabox/DataDeps.jl) - Reproducible data setup for reproducible science.\n\n<a name=\"kotlin\"></a>\n## Kotlin\n\n<a name=\"kotlin-deep-learning\"></a>\n#### Deep Learning\n* [KotlinDL](https://github.com/JetBrains/KotlinDL) - Deep learning framework written in Kotlin.\n\n<a name=\"lua\"></a>\n## Lua\n\n<a name=\"lua-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Torch7](http://torch.ch/)\n  * [cephes](https://github.com/deepmind/torch-cephes) - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy. **[Deprecated]**\n  * [autograd](https://github.com/twitter/torch-autograd) - Autograd automatically differentiates native Torch code. Inspired by the original Python version.\n  * [graph](https://github.com/torch/graph) - Graph package for Torch. **[Deprecated]**\n  * [randomkit](https://github.com/deepmind/torch-randomkit) - Numpy's randomkit, wrapped for Torch. **[Deprecated]**\n  * [signal](https://github.com/soumith/torch-signal) - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stft.\n  * [nn](https://github.com/torch/nn) - Neural Network package for Torch.\n  * [torchnet](https://github.com/torchnet/torchnet) - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programming.\n  * [nngraph](https://github.com/torch/nngraph) - This package provides graphical computation for nn library in Torch7.\n  * [nnx](https://github.com/clementfarabet/lua---nnx) - A completely unstable and experimental package that extends Torch's builtin nn library.\n  * [rnn](https://github.com/Element-Research/rnn) - A Recurrent Neural Network library that extends Torch's nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.\n  * [dpnn](https://github.com/Element-Research/dpnn) - Many useful features that aren't part of the main nn package.\n  * [dp](https://github.com/nicholas-leonard/dp) - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns. **[Deprecated]**\n  * [optim](https://github.com/torch/optim) - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.\n  * [unsup](https://github.com/koraykv/unsup) - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, ...), and self-contained algorithms (k-means, PCA). **[Deprecated]**\n  * [manifold](https://github.com/clementfarabet/manifold) - A package to manipulate manifolds.\n  * [svm](https://github.com/koraykv/torch-svm) - Torch-SVM library. **[Deprecated]**\n  * [lbfgs](https://github.com/clementfarabet/lbfgs) - FFI Wrapper for liblbfgs. **[Deprecated]**\n  * [vowpalwabbit](https://github.com/clementfarabet/vowpal_wabbit) - An old vowpalwabbit interface to torch. **[Deprecated]**\n  * [OpenGM](https://github.com/clementfarabet/lua---opengm) - OpenGM is a C++ library for graphical modelling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM. **[Deprecated]**\n  * [spaghetti](https://github.com/MichaelMathieu/lua---spaghetti) - Spaghetti (sparse linear) module for torch7 by @MichaelMathieu **[Deprecated]**\n  * [LuaSHKit](https://github.com/ocallaco/LuaSHkit) - A Lua wrapper around the Locality sensitive hashing library SHKit **[Deprecated]**\n  * [kernel smoothing](https://github.com/rlowrance/kernel-smoothers) - KNN, kernel-weighted average, local linear regression smoothers. **[Deprecated]**\n  * [cutorch](https://github.com/torch/cutorch) - Torch CUDA Implementation.\n  * [cunn](https://github.com/torch/cunn) - Torch CUDA Neural Network Implementation.\n  * [imgraph](https://github.com/clementfarabet/lua---imgraph) - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images. **[Deprecated]**\n  * [videograph](https://github.com/clementfarabet/videograph) - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos. **[Deprecated]**\n  * [saliency](https://github.com/marcoscoffier/torch-saliency) - code and tools around integral images. A library for finding interest points based on fast integral histograms. **[Deprecated]**\n  * [stitch](https://github.com/marcoscoffier/lua---stitch) - allows us to use hugin to stitch images and apply same stitching to a video sequence. **[Deprecated]**\n  * [sfm](https://github.com/marcoscoffier/lua---sfm) - A bundle adjustment/structure from motion package. **[Deprecated]**\n  * [fex](https://github.com/koraykv/fex) - A package for feature extraction in Torch. Provides SIFT and dSIFT modules. **[Deprecated]**\n  * [OverFeat](https://github.com/sermanet/OverFeat) - A state-of-the-art generic dense feature extractor. **[Deprecated]**\n  * [wav2letter](https://github.com/facebookresearch/wav2letter) - a simple and efficient end-to-end Automatic Speech Recognition (ASR) system from Facebook AI Research.\n* [Numeric Lua](http://numlua.luaforge.net/)\n* [Lunatic Python](https://labix.org/lunatic-python)\n* [SciLua](http://scilua.org/)\n* [Lua - Numerical Algorithms](https://bitbucket.org/lucashnegri/lna) **[Deprecated]**\n* [Lunum](https://github.com/jzrake/lunum) **[Deprecated]**\n* [Keras GPT Copilot](https://github.com/fabprezja/keras-gpt-copilot) - A python package that integrates an LLM copilot inside the keras model development workflow.\n\n<a name=\"lua-demos-and-scripts\"></a>\n#### Demos and Scripts\n* [Core torch7 demos repository](https://github.com/e-lab/torch7-demos).\n  * linear-regression, logistic-regression\n  * face detector (training and detection as separate demos)\n  * mst-based-segmenter\n  * train-a-digit-classifier\n  * train-autoencoder\n  * optical flow demo\n  * train-on-housenumbers\n  * train-on-cifar\n  * tracking with deep nets\n  * kinect demo\n  * filter-bank visualization\n  * saliency-networks\n* [Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)](https://github.com/soumith/galaxyzoo)\n* [torch-datasets](https://github.com/rosejn/torch-datasets) - Scripts to load several popular datasets including:\n  * BSR 500\n  * CIFAR-10\n  * COIL\n  * Street View House Numbers\n  * MNIST\n  * NORB\n* [Atari2600](https://github.com/fidlej/aledataset) - Scripts to generate a dataset with static frames from the Arcade Learning Environment.\n\n\n\n<a name=\"matlab\"></a>\n## Matlab\n\n<a name=\"matlab-computer-vision\"></a>\n#### Computer Vision\n\n* [Contourlets](http://www.ifp.illinois.edu/~minhdo/software/contourlet_toolbox.tar) - MATLAB source code that implements the contourlet transform and its utility functions.\n* [Shearlets](https://www3.math.tu-berlin.de/numerik/www.shearlab.org/software) - MATLAB code for shearlet transform.\n* [Curvelets](http://www.curvelet.org/software.html) - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles.\n* [Bandlets](http://www.cmap.polytechnique.fr/~peyre/download/) - MATLAB code for bandlet transform.\n* [mexopencv](https://kyamagu.github.io/mexopencv/) - Collection and a development kit of MATLAB mex functions for OpenCV library.\n\n<a name=\"matlab-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [NLP](https://amplab.cs.berkeley.edu/an-nlp-library-for-matlab/) - A NLP library for Matlab.\n\n<a name=\"matlab-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Training a deep autoencoder or a classifier\non MNIST digits](https://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) - Training a deep autoencoder or a classifier\non MNIST digits[DEEP LEARNING].\n* [Convolutional-Recursive Deep Learning for 3D Object Classification](https://www.socher.org/index.php/Main/Convolutional-RecursiveDeepLearningFor3DObjectClassification) - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING].\n* [Spider](https://people.kyb.tuebingen.mpg.de/spider/) - The spider is intended to be a complete object orientated environment for machine learning in Matlab.\n* [LibSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/#matlab) - A Library for Support Vector Machines.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - An Open-Source SVM Library on GPUs and CPUs\n* [LibLinear](https://www.csie.ntu.edu.tw/~cjlin/liblinear/#download) - A Library for Large Linear Classification.\n* [Machine Learning Module](https://github.com/josephmisiti/machine-learning-module) - Class on machine w/ PDF, lectures, code\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [Pattern Recognition Toolbox](https://github.com/covartech/PRT) - A complete object-oriented environment for machine learning in Matlab.\n* [Pattern Recognition and Machine Learning](https://github.com/PRML/PRMLT) - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB.\n* [MXNet](https://github.com/apache/incubator-mxnet/) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [Machine Learning in MatLab/Octave](https://github.com/trekhleb/machine-learning-octave) - Examples of popular machine learning algorithms (neural networks, linear/logistic regressions, K-Means, etc.) with code examples and mathematics behind them being explained.\n\n\n<a name=\"matlab-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [ParaMonte](https://github.com/cdslaborg/paramonte) - A general-purpose MATLAB library for Bayesian data analysis and visualization via serial/parallel Monte Carlo and MCMC simulations. Documentation can be found [here](https://www.cdslab.org/paramonte/).\n* [matlab_bgl](https://www.cs.purdue.edu/homes/dgleich/packages/matlab_bgl/) - MatlabBGL is a Matlab package for working with graphs.\n* [gaimc](https://www.mathworks.com/matlabcentral/fileexchange/24134-gaimc---graph-algorithms-in-matlab-code) - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL's mex functions.\n\n<a name=\"net\"></a>\n## .NET\n\n<a name=\"net-computer-vision\"></a>\n#### Computer Vision\n\n* [OpenCVDotNet](https://code.google.com/archive/p/opencvdotnet) - A wrapper for the OpenCV project to be used with .NET applications.\n* [Emgu CV](http://www.emgu.com/wiki/index.php/Main_Page) - Cross platform wrapper of OpenCV which can be compiled in Mono to be run on Windows, Linus, Mac OS X, iOS, and Android.\n* [AForge.NET](http://www.aforgenet.com/framework/) - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub.\n* [Accord.NET](http://accord-framework.net) - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android.\n\n<a name=\"net-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Stanford.NLP for .NET](https://github.com/sergey-tihon/Stanford.NLP.NET/) - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package.\n\n<a name=\"net-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Accord-Framework](http://accord-framework.net/) -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications.\n* [Accord.MachineLearning](https://www.nuget.org/packages/Accord.MachineLearning/) - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework.\n* [DiffSharp](https://diffsharp.github.io/DiffSharp/) - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization.\n* [Encog](https://www.nuget.org/packages/encog-dotnet-core/) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [GeneticSharp](https://github.com/giacomelli/GeneticSharp) - Multi-platform genetic algorithm library for .NET Core and .NET Framework. The library has several implementations of GA operators, like: selection, crossover, mutation, reinsertion and termination.\n* [Infer.NET](https://dotnet.github.io/infer/) - Infer.NET is a framework for running Bayesian inference in graphical models. One can use Infer.NET to solve many different kinds of machine learning problems, from standard problems like classification, recommendation or clustering through customized solutions to domain-specific problems. Infer.NET has been used in a wide variety of domains including information retrieval, bioinformatics, epidemiology, vision, and many others.\n* [ML.NET](https://github.com/dotnet/machinelearning) - ML.NET is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers. ML.NET was originally developed in Microsoft Research and evolved into a significant framework over the last decade and is used across many product groups in Microsoft like Windows, Bing, PowerPoint, Excel and more.\n* [Neural Network Designer](https://sourceforge.net/projects/nnd/) - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feedback. The chat bots can even scrape the internet for information to return in their output as well as to use for learning.\n* [Synapses](https://github.com/mrdimosthenis/Synapses) - Neural network library in F#.\n* [Vulpes](https://github.com/fsprojects/Vulpes) - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase.\n* [MxNet.Sharp](https://github.com/tech-quantum/MxNet.Sharp) - .NET Standard bindings for Apache MxNet with Imperative, Symbolic and Gluon Interface for developing, training and deploying Machine Learning models in C#. https://mxnet.tech-quantum.com/\n\n<a name=\"net-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [numl](https://www.nuget.org/packages/numl/) - numl is a machine learning library intended to ease the use of using standard modelling techniques for both prediction and clustering.\n* [Math.NET Numerics](https://www.nuget.org/packages/MathNet.Numerics/) - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and everyday use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin.\n* [Sho](https://www.microsoft.com/en-us/research/project/sho-the-net-playground-for-data/) - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development.\n\n<a name=\"objective-c\"></a>\n## Objective C\n\n<a name=\"objective-c-general-purpose-machine-learning\"></a>\n### General-Purpose Machine Learning\n\n* [YCML](https://github.com/yconst/YCML) - A Machine Learning framework for Objective-C and Swift (OS X / iOS).\n* [MLPNeuralNet](https://github.com/nikolaypavlov/MLPNeuralNet) - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural networks. It is built on top of the Apple's Accelerate Framework, using vectorized operations and hardware acceleration if available. **[Deprecated]**\n* [MAChineLearning](https://github.com/gianlucabertani/MAChineLearning) - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it's 20 times faster than its Java equivalent. Includes sample code for use from Swift.\n* [BPN-NeuralNetwork](https://github.com/Kalvar/ios-BPN-NeuralNetwork) - It implemented 3 layers of neural networks ( Input Layer, Hidden Layer and Output Layer ) and it was named Back Propagation Neural Networks (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. **[Deprecated]**\n* [Multi-Perceptron-NeuralNetwork](https://github.com/Kalvar/ios-Multi-Perceptron-NeuralNetwork) - It implemented multi-perceptrons neural network (ニューラルネットワーク) based on Back Propagation Neural Networks (BPN) and designed unlimited-hidden-layers.\n* [KRHebbian-Algorithm](https://github.com/Kalvar/ios-KRHebbian-Algorithm) - It is a non-supervisory and self-learning algorithm (adjust the weights) in the neural network of Machine Learning. **[Deprecated]**\n* [KRKmeans-Algorithm](https://github.com/Kalvar/ios-KRKmeans-Algorithm) - It implemented K-Means  clustering and classification algorithm. It could be used in data mining and image compression. **[Deprecated]**\n* [KRFuzzyCMeans-Algorithm](https://github.com/Kalvar/ios-KRFuzzyCMeans-Algorithm) - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. **[Deprecated]**\n\n<a name=\"ocaml\"></a>\n## OCaml\n\n<a name=\"ocaml-general-purpose-machine-learning\"></a>\n### General-Purpose Machine Learning\n\n* [Oml](https://github.com/rleonid/oml) - A general statistics and machine learning library.\n* [GPR](https://mmottl.github.io/gpr/) - Efficient Gaussian Process Regression in OCaml.\n* [Libra-Tk](https://libra.cs.uoregon.edu) - Algorithms for learning and inference with discrete probabilistic models.\n* [TensorFlow](https://github.com/LaurentMazare/tensorflow-ocaml) - OCaml bindings for TensorFlow.\n\n<a name=\"opencv\"></a>\n## OpenCV\n\n<a name=\"opencv-ComputerVision and Text Detection\"></a>\n### OpenSource-Computer-Vision\n\n* [OpenCV](https://github.com/opencv/opencv) - A OpenSource Computer Vision Library\n\n<a name=\"perl\"></a>\n## Perl\n\n<a name=\"perl-data-analysis--data-visualization\"></a>\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning), a pluggable architecture for data and image processing, which can\nbe [used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n<a name=\"perl-general-purpose-machine-learning\"></a>\n### General-Purpose Machine Learning\n\n* [MXnet for Deep Learning, in Perl](https://github.com/apache/incubator-mxnet/tree/master/perl-package),\nalso [released in CPAN](https://metacpan.org/pod/AI::MXNet).\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\nusing AWS machine learning platform from Perl.\n* [Algorithm::SVMLight](https://metacpan.org/pod/Algorithm::SVMLight),\n  implementation of Support Vector Machines with SVMLight under it. **[Deprecated]**\n* Several machine learning and artificial intelligence models are\n  included in the [`AI`](https://metacpan.org/search?size=20&q=AI)\n  namespace. For instance, you can\n  find [Naïve Bayes](https://metacpan.org/pod/AI::NaiveBayes).\n\n<a name=\"perl6\"></a>\n## Perl 6\n\n* [Support Vector Machines](https://github.com/titsuki/p6-Algorithm-LibSVM)\n* [Naïve Bayes](https://github.com/titsuki/p6-Algorithm-NaiveBayes)\n\n<a name=\"perl-6-data-analysis--data-visualization\"></a>\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\na pluggable architecture for data and image processing, which can\nbe\n[used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n<a name=\"perl-6-general-purpose-machine-learning\"></a>\n### General-Purpose Machine Learning\n\n<a name=\"php\"></a>\n## PHP\n\n<a name=\"php-natural-language-processing\"></a>\n### Natural Language Processing\n\n* [jieba-php](https://github.com/fukuball/jieba-php) - Chinese Words Segmentation Utilities.\n\n<a name=\"php-general-purpose-machine-learning\"></a>\n### General-Purpose Machine Learning\n\n* [PHP-ML](https://gitlab.com/php-ai/php-ml) - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder) - A library for machine learning that builds predictions using a linear regression.\n* [Rubix ML](https://github.com/RubixML) - A high-level machine learning (ML) library that lets you build programs that learn from data using the PHP language.\n* [19 Questions](https://github.com/fulldecent/19-questions) - A machine learning / bayesian inference assigning attributes to objects.\n\n<a name=\"python\"></a>\n## Python\n\n<a name=\"python-computer-vision\"></a>\n#### Computer Vision\n\n* [Scikit-Image](https://github.com/scikit-image/scikit-image) - A collection of algorithms for image processing in Python.\n* [Scikit-Opt](https://github.com/guofei9987/scikit-opt) - Swarm Intelligence in Python (Genetic Algorithm, Particle Swarm Optimization, Simulated Annealing, Ant Colony Algorithm, Immune Algorithm, Artificial Fish Swarm Algorithm in Python)\n* [SimpleCV](http://simplecv.org/) - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux.\n* [Vigranumpy](https://github.com/ukoethe/vigra) - Python bindings for the VIGRA C++ computer vision library.\n* [OpenFace](https://cmusatyalab.github.io/openface/) - Free and open source face recognition with deep neural networks.\n* [PCV](https://github.com/jesolem/PCV) - Open source Python module for computer vision. **[Deprecated]**\n* [face_recognition](https://github.com/ageitgey/face_recognition) - Face recognition library that recognizes and manipulates faces from Python or from the command line.\n* [deepface](https://github.com/serengil/deepface) - A lightweight face recognition and facial attribute analysis (age, gender, emotion and race) framework for Python covering cutting-edge models such as VGG-Face, FaceNet, OpenFace, DeepFace, DeepID, Dlib and ArcFace.\n* [retinaface](https://github.com/serengil/retinaface) - deep learning based cutting-edge facial detector for Python coming with facial landmarks\n* [dockerface](https://github.com/natanielruiz/dockerface) - Easy to install and use deep learning Faster R-CNN face detection for images and video in a docker container. **[Deprecated]**\n* [Detectron](https://github.com/facebookresearch/Detectron) - FAIR's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework. **[Deprecated]**\n* [detectron2](https://github.com/facebookresearch/detectron2) - FAIR's next-generation research platform for object detection and segmentation. It is a ground-up rewrite of the previous version, Detectron, and is powered by the PyTorch deep learning framework.\n* [albumentations](https://github.com/albu/albumentations) - А fast and framework agnostic image augmentation library that implements a diverse set of augmentation techniques. Supports classification, segmentation, detection out of the box. Was used to win a number of Deep Learning competitions at Kaggle, Topcoder and those that were a part of the CVPR workshops.\n* [pytessarct](https://github.com/madmaze/pytesseract) - Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and \"read\" the text embedded in images. Python-tesseract is a wrapper for [Google's Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract).\n* [imutils](https://github.com/jrosebr1/imutils) - A library containing Convenience functions to make basic image processing operations such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and Python.\n* [PyTorchCV](https://github.com/donnyyou/PyTorchCV) - A PyTorch-Based Framework for Deep Learning in Computer Vision.\n* [joliGEN](https://github.com/jolibrain/joliGEN) - Generative AI Image Toolset with GANs and Diffusion for Real-World Applications.\n* [Self-supervised learning](https://pytorch-lightning-bolts.readthedocs.io/en/latest/self_supervised_models.html)\n* [neural-style-pt](https://github.com/ProGamerGov/neural-style-pt) - A PyTorch implementation of Justin Johnson's neural-style (neural style transfer).\n* [Detecto](https://github.com/alankbi/detecto) - Train and run a computer vision model with 5-10 lines of code.\n* [neural-dream](https://github.com/ProGamerGov/neural-dream) - A PyTorch implementation of DeepDream.\n* [Openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) - A real-time multi-person keypoint detection library for body, face, hands, and foot estimation\n* [Deep High-Resolution-Net](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch) - A PyTorch implementation of CVPR2019 paper \"Deep High-Resolution Representation Learning for Human Pose Estimation\"\n* [TF-GAN](https://github.com/tensorflow/gan) - TF-GAN is a lightweight library for training and evaluating Generative Adversarial Networks (GANs).\n* [dream-creator](https://github.com/ProGamerGov/dream-creator) - A PyTorch implementation of DeepDream. Allows individuals to quickly and easily train their own custom GoogleNet models with custom datasets for DeepDream.\n* [Lucent](https://github.com/greentfrapp/lucent) - Tensorflow and OpenAI Clarity's Lucid adapted for PyTorch.\n* [lightly](https://github.com/lightly-ai/lightly) - Lightly is a computer vision framework for self-supervised learning.\n* [Learnergy](https://github.com/gugarosa/learnergy) - Energy-based machine learning models built upon PyTorch.\n* [OpenVisionAPI](https://github.com/openvisionapi) - Open source computer vision API based on open source models.\n* [IoT Owl](https://github.com/Ret2Me/IoT-Owl) - Light face detection and recognition system with huge possibilities, based on Microsoft Face API and TensorFlow made for small IoT devices like raspberry pi.\n* [Exadel CompreFace](https://github.com/exadel-inc/CompreFace) - face recognition system that can be easily integrated into any system without prior machine learning skills. CompreFace provides REST API for face recognition, face verification, face detection, face mask detection, landmark detection, age, and gender recognition and is easily deployed with docker.\n* [computer-vision-in-action](https://github.com/Charmve/computer-vision-in-action) - as known as ``L0CV``, is a new generation of computer vision open source online learning media, a cross-platform interactive learning framework integrating graphics, source code and HTML. the L0CV ecosystem — Notebook, Datasets, Source Code, and from Diving-in to Advanced — as well as the L0CV Hub.\n* [timm](https://github.com/rwightman/pytorch-image-models) - PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3/V2, RegNet, DPN, CSPNet, and more.\n* [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) - A PyTorch-based toolkit that offers pre-trained segmentation models for computer vision tasks. It simplifies the development of image segmentation applications by providing a collection of popular architecture implementations, such as UNet and PSPNet, along with pre-trained weights, making it easier for researchers and developers to achieve high-quality pixel-level object segmentation in images.\n* [segmentation_models](https://github.com/qubvel/segmentation_models) - A TensorFlow Keras-based toolkit that offers pre-trained segmentation models for computer vision tasks. It simplifies the development of image segmentation applications by providing a collection of popular architecture implementations, such as UNet and PSPNet, along with pre-trained weights, making it easier for researchers and developers to achieve high-quality pixel-level object segmentation in images.\n* [MLX](https://github.com/ml-explore/mlx)- MLX is an array framework for machine learning on Apple silicon, developed by Apple machine learning research.\n\n<a name=\"python-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [pkuseg-python](https://github.com/lancopku/pkuseg-python) - A better version of Jieba, developed by Peking University.\n* [NLTK](https://www.nltk.org/) - A leading platform for building Python programs to work with human language data.\n* [Pattern](https://github.com/clips/pattern) - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others.\n* [Quepy](https://github.com/machinalis/quepy) - A python framework to transform natural language questions to queries in a database query language.\n* [TextBlob](http://textblob.readthedocs.io/en/dev/) - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both.\n* [YAlign](https://github.com/machinalis/yalign) - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. **[Deprecated]**\n* [jieba](https://github.com/fxsjy/jieba#jieba-1) - Chinese Words Segmentation Utilities.\n* [SnowNLP](https://github.com/isnowfy/snownlp) - A library for processing Chinese text.\n* [spammy](https://github.com/tasdikrahman/spammy) - A library for email Spam filtering built on top of NLTK\n* [loso](https://github.com/fangpenlin/loso) - Another Chinese segmentation library. **[Deprecated]**\n* [genius](https://github.com/duanhongyi/genius) - A Chinese segment based on Conditional Random Field.\n* [KoNLPy](http://konlpy.org) - A Python package for Korean natural language processing.\n* [nut](https://github.com/pprett/nut) - Natural language Understanding Toolkit. **[Deprecated]**\n* [Rosetta](https://github.com/columbia-applied-data-science/rosetta) - Text processing tools and wrappers (e.g. Vowpal Wabbit)\n* [BLLIP Parser](https://pypi.org/project/bllipparser/) - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser). **[Deprecated]**\n* [PyNLPl](https://github.com/proycon/pynlpl) - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for [FoLiA](https://proycon.github.io/folia/), but also ARPA language models, Moses phrasetables, GIZA++ alignments.\n* [PySS3](https://github.com/sergioburdisso/pyss3) - Python package that implements a novel white-box machine learning model for text classification, called SS3. Since SS3 has the ability to visually explain its rationale, this package also comes with easy-to-use interactive visualizations tools ([online demos](http://tworld.io/ss3/)).\n* [python-ucto](https://github.com/proycon/python-ucto) - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages).\n* [python-frog](https://github.com/proycon/python-frog) - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)\n* [python-zpar](https://github.com/EducationalTestingService/python-zpar) - Python bindings for [ZPar](https://github.com/frcchang/zpar), a statistical part-of-speech-tagger, constituency parser, and dependency parser for English.\n* [colibri-core](https://github.com/proycon/colibri-core) - Python binding to C++ library for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [spaCy](https://github.com/explosion/spaCy) - Industrial strength NLP with Python and Cython.\n* [PyStanfordDependencies](https://github.com/dmcc/PyStanfordDependencies) - Python interface for converting Penn Treebank trees to Stanford Dependencies.\n* [Distance](https://github.com/doukremt/distance) - Levenshtein and Hamming distance computation. **[Deprecated]**\n* [Fuzzy Wuzzy](https://github.com/seatgeek/fuzzywuzzy) - Fuzzy String Matching in Python.\n* [Neofuzz](https://github.com/x-tabdeveloping/neofuzz) - Blazing fast, lightweight and customizable fuzzy and semantic text search in Python with fuzzywuzzy/thefuzz compatible API.\n* [jellyfish](https://github.com/jamesturk/jellyfish) - a python library for doing approximate and phonetic matching of strings.\n* [editdistance](https://pypi.org/project/editdistance/) - fast implementation of edit distance.\n* [textacy](https://github.com/chartbeat-labs/textacy) - higher-level NLP built on Spacy.\n* [stanford-corenlp-python](https://github.com/dasmith/stanford-corenlp-python) - Python wrapper for [Stanford CoreNLP](https://github.com/stanfordnlp/CoreNLP) **[Deprecated]**\n* [CLTK](https://github.com/cltk/cltk) - The Classical Language Toolkit.\n* [Rasa](https://github.com/RasaHQ/rasa) - A \"machine learning framework to automate text-and voice-based conversations.\"\n* [yase](https://github.com/PPACI/yase) - Transcode sentence (or other sequence) to list of word vector.\n* [Polyglot](https://github.com/aboSamoor/polyglot) - Multilingual text (NLP) processing toolkit.\n* [DrQA](https://github.com/facebookresearch/DrQA) - Reading Wikipedia to answer open-domain questions.\n* [Dedupe](https://github.com/dedupeio/dedupe) - A python library for accurate and scalable fuzzy matching, record deduplication and entity-resolution.\n* [Snips NLU](https://github.com/snipsco/snips-nlu) - Natural Language Understanding library for intent classification and entity extraction\n* [NeuroNER](https://github.com/Franck-Dernoncourt/NeuroNER) - Named-entity recognition using neural networks providing state-of-the-art-results\n* [DeepPavlov](https://github.com/deepmipt/DeepPavlov/) - conversational AI library with many pre-trained Russian NLP models.\n* [BigARTM](https://github.com/bigartm/bigartm) - topic modelling platform.\n* [NALP](https://github.com/gugarosa/nalp) - A Natural Adversarial Language Processing framework built over Tensorflow.\n* [DL Translate](https://github.com/xhlulu/dl-translate) - A deep learning-based translation library between 50 languages, built with `transformers`.\n* [Haystack](https://github.com/deepset-ai/haystack) - A framework for building industrial-strength applications with Transformer models and LLMs.\n* [CometLLM](https://github.com/comet-ml/comet-llm) - Track, log, visualize and evaluate your LLM prompts and prompt chains.\n* [Transformers](https://github.com/huggingface/transformers) - A deep learning library containing thousands of pre-trained models on different tasks. The goto place for anything related to Large Language Models.\n\n<a name=\"python-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n * [XAD](https://pypi.org/project/xad/) -> Fast and easy-to-use backpropagation tool.\n * [Aim](https://github.com/aimhubio/aim) -> An easy-to-use & supercharged open-source AI metadata tracker.\n * [RexMex](https://github.com/AstraZeneca/rexmex) -> A general purpose recommender metrics library for fair evaluation.\n * [ChemicalX](https://github.com/AstraZeneca/chemicalx) -> A PyTorch based deep learning library for drug pair scoring\n * [Microsoft ML for Apache Spark](https://github.com/Azure/mmlspark) -> A distributed machine learning framework Apache Spark\n * [Shapley](https://github.com/benedekrozemberczki/shapley) -> A data-driven framework to quantify the value of classifiers in a machine learning ensemble.\n * [igel](https://github.com/nidhaloff/igel) -> A delightful machine learning tool that allows you to train/fit, test and use models **without writing code**\n * [ML Model building](https://github.com/Shanky-21/Machine_learning) -> A Repository Containing Classification, Clustering, Regression, Recommender Notebooks with illustration to make them.\n * [ML/DL project template](https://github.com/PyTorchLightning/deep-learning-project-template)\n * [PyTorch Frame](https://github.com/pyg-team/pytorch-frame) -> A Modular Framework for Multi-Modal Tabular Learning.\n * [PyTorch Geometric](https://github.com/pyg-team/pytorch_geometric) -> Graph Neural Network Library for PyTorch.\n * [PyTorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) -> A temporal extension of PyTorch Geometric for dynamic graph representation learning.\n * [Little Ball of Fur](https://github.com/benedekrozemberczki/littleballoffur) -> A graph sampling extension library for NetworkX with a Scikit-Learn like API.\n * [Karate Club](https://github.com/benedekrozemberczki/karateclub) -> An unsupervised machine learning extension library for NetworkX with a Scikit-Learn like API.\n* [Auto_ViML](https://github.com/AutoViML/Auto_ViML) -> Automatically Build Variant Interpretable ML models fast! Auto_ViML is pronounced \"auto vimal\", is a comprehensive and scalable Python AutoML toolkit with imbalanced handling, ensembling, stacking and built-in feature selection. Featured in <a href=\"https://towardsdatascience.com/why-automl-is-an-essential-new-tool-for-data-scientists-2d9ab4e25e46?source=friends_link&sk=d03a0cc55c23deb497d546d6b9be0653\">Medium article</a>.\n* [PyOD](https://github.com/yzhao062/pyod) -> Python Outlier Detection, comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. Featured for Advanced models, including Neural Networks/Deep Learning and Outlier Ensembles.\n* [steppy](https://github.com/neptune-ml/steppy) -> Lightweight, Python library for fast and reproducible machine learning experimentation. Introduces a very simple interface that enables clean machine learning pipeline design.\n* [steppy-toolkit](https://github.com/neptune-ml/steppy-toolkit) -> Curated collection of the neural networks, transformers and models that make your machine learning work faster and more effective.\n* [CNTK](https://github.com/Microsoft/CNTK) - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. Documentation can be found [here](https://docs.microsoft.com/cognitive-toolkit/).\n* [Couler](https://github.com/couler-proj/couler) - Unified interface for constructing and managing machine learning workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.\n* [auto_ml](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning for production and analytics. Lets you focus on the fun parts of ML, while outputting production-ready code, and detailed analytics of your dataset and results. Includes support for NLP, XGBoost, CatBoost, LightGBM, and soon, deep learning.\n* [dtaidistance](https://github.com/wannesm/dtaidistance) - High performance library for time series distances (DTW) and time series clustering.\n* [einops](https://github.com/arogozhnikov/einops) - Deep learning operations reinvented (for pytorch, tensorflow, jax and others).\n* [machine learning](https://github.com/jeff1evesque/machine-learning) - automated build consisting of a [web-interface](https://github.com/jeff1evesque/machine-learning#web-interface), and set of [programmatic-interface](https://github.com/jeff1evesque/machine-learning#programmatic-interface) API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore.\n* [XGBoost](https://github.com/dmlc/xgboost) - Python bindings for eXtreme Gradient Boosting (Tree) Library.\n* [ChefBoost](https://github.com/serengil/chefboost) - a lightweight decision tree framework for Python with categorical feature support covering regular decision tree algorithms such as ID3, C4.5, CART, CHAID and regression tree; also some advanved bagging and boosting techniques such as gradient boosting, random forest and adaboost.\n* [Apache SINGA](https://singa.apache.org) - An Apache Incubating project for developing an open source machine learning library.\n* [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) - Book/iPython notebooks on Probabilistic Programming in Python.\n* [Featureforge](https://github.com/machinalis/featureforge) A set of tools for creating and testing machine learning features, with a scikit-learn compatible API.\n* [MLlib in Apache Spark](http://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - A service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Towhee](https://towhee.io) - A Python module that encode unstructured data into embeddings.\n* [scikit-learn](https://scikit-learn.org/) - A Python module for machine learning built on top of SciPy.\n* [metric-learn](https://github.com/metric-learn/metric-learn) - A Python module for metric learning.\n* [OpenMetricLearning](https://github.com/OML-Team/open-metric-learning) - A PyTorch-based framework to train and validate the models producing high-quality embeddings.\n* [Intel(R) Extension for Scikit-learn](https://github.com/intel/scikit-learn-intelex) - A seamless way to speed up your Scikit-learn applications with no accuracy loss and code changes.\n* [SimpleAI](https://github.com/simpleai-team/simpleai) Python implementation of many of the artificial intelligence algorithms described in the book \"Artificial Intelligence, a Modern Approach\". It focuses on providing an easy to use, well documented and tested library.\n* [astroML](https://www.astroml.org/) - Machine Learning and Data Mining for Astronomy.\n* [graphlab-create](https://turi.com/products/create/docs/) - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame.\n* [BigML](https://bigml.com) - A library that contacts external servers.\n* [pattern](https://github.com/clips/pattern) - Web mining module for Python.\n* [NuPIC](https://github.com/numenta/nupic) - Numenta Platform for Intelligent Computing.\n* [Pylearn2](https://github.com/lisa-lab/pylearn2) - A Machine Learning library based on [Theano](https://github.com/Theano/Theano). **[Deprecated]**\n* [keras](https://github.com/keras-team/keras) - High-level neural networks frontend for [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/CNTK) and [Theano](https://github.com/Theano/Theano).\n* [Lasagne](https://github.com/Lasagne/Lasagne) - Lightweight library to build and train neural networks in Theano.\n* [hebel](https://github.com/hannes-brt/hebel) - GPU-Accelerated Deep Learning Library in Python. **[Deprecated]**\n* [Chainer](https://github.com/chainer/chainer) - Flexible neural network framework.\n* [prophet](https://facebook.github.io/prophet/) - Fast and automated time series forecasting framework by Facebook.\n* [gensim](https://github.com/RaRe-Technologies/gensim) - Topic Modelling for Humans.\n* [tweetopic](https://centre-for-humanities-computing.github.io/tweetopic/) - Blazing fast short-text-topic-modelling for Python.\n* [topicwizard](https://github.com/x-tabdeveloping/topic-wizard) - Interactive topic model visualization/interpretation framework.\n* [topik](https://github.com/ContinuumIO/topik) - Topic modelling toolkit. **[Deprecated]**\n* [PyBrain](https://github.com/pybrain/pybrain) - Another Python Machine Learning Library.\n* [Brainstorm](https://github.com/IDSIA/brainstorm) - Fast, flexible and fun neural networks. This is the successor of PyBrain.\n* [Surprise](https://surpriselib.com) - A scikit for building and analyzing recommender systems.\n* [implicit](https://implicit.readthedocs.io/en/latest/quickstart.html) - Fast Python Collaborative Filtering for Implicit Datasets.\n* [LightFM](https://making.lyst.com/lightfm/docs/home.html) -  A Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback.\n* [Crab](https://github.com/muricoca/crab) - A flexible, fast recommender engine. **[Deprecated]**\n* [python-recsys](https://github.com/ocelma/python-recsys) - A Python library for implementing a Recommender System.\n* [thinking bayes](https://github.com/AllenDowney/ThinkBayes) - Book on Bayesian Analysis.\n* [Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/williamFalcon/pix2pix-keras) - Implementation of image to image (pix2pix) translation from the paper by [isola et al](https://arxiv.org/pdf/1611.07004.pdf).[DEEP LEARNING]\n* [Restricted Boltzmann Machines](https://github.com/echen/restricted-boltzmann-machines) -Restricted Boltzmann Machines in Python. [DEEP LEARNING]\n* [Bolt](https://github.com/pprett/bolt) - Bolt Online Learning Toolbox. **[Deprecated]**\n* [CoverTree](https://github.com/patvarilly/CoverTree) - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree **[Deprecated]**\n* [nilearn](https://github.com/nilearn/nilearn) - Machine learning for NeuroImaging in Python.\n* [neuropredict](https://github.com/raamana/neuropredict) - Aimed at novice machine learners and non-expert programmers, this package offers easy (no coding needed) and comprehensive machine learning (evaluation and full report of predictive performance WITHOUT requiring you to code) in Python for NeuroImaging and any other type of features. This is aimed at absorbing much of the ML workflow, unlike other packages like nilearn and pymvpa, which require you to learn their API and code to produce anything useful.\n* [imbalanced-learn](https://imbalanced-learn.org/stable/) - Python module to perform under sampling and oversampling with various techniques.\n* [imbalanced-ensemble](https://github.com/ZhiningLiu1998/imbalanced-ensemble) - Python toolbox for quick implementation, modification, evaluation, and visualization of ensemble learning algorithms for class-imbalanced data. Supports out-of-the-box multi-class imbalanced (long-tailed) classification.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [Pyevolve](https://github.com/perone/Pyevolve) - Genetic algorithm framework. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [breze](https://github.com/breze-no-salt/breze) - Theano based library for deep and recurrent neural networks.\n* [Cortex](https://github.com/cortexlabs/cortex) - Open source platform for deploying machine learning models in production.\n* [pyhsmm](https://github.com/mattjj/pyhsmm) - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations.\n* [SKLL](https://github.com/EducationalTestingService/skll) - A wrapper around scikit-learn that makes it simpler to conduct experiments.\n* [neurolab](https://github.com/zueve/neurolab)\n* [Spearmint](https://github.com/HIPS/Spearmint) - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. **[Deprecated]**\n* [Pebl](https://github.com/abhik/pebl/) - Python Environment for Bayesian Learning. **[Deprecated]**\n* [Theano](https://github.com/Theano/Theano/) - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python.\n* [TensorFlow](https://github.com/tensorflow/tensorflow/) - Open source software library for numerical computation using data flow graphs.\n* [pomegranate](https://github.com/jmschrei/pomegranate) - Hidden Markov Models for Python, implemented in Cython for speed and efficiency.\n* [python-timbl](https://github.com/proycon/python-timbl) - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit.\n* [deap](https://github.com/deap/deap) - Evolutionary algorithm framework.\n* [pydeep](https://github.com/andersbll/deeppy) - Deep Learning In Python. **[Deprecated]**\n* [mlxtend](https://github.com/rasbt/mlxtend) - A library consisting of useful tools for data science and machine learning tasks.\n* [neon](https://github.com/NervanaSystems/neon) - Nervana's [high-performance](https://github.com/soumith/convnet-benchmarks) Python-based Deep Learning framework [DEEP LEARNING]. **[Deprecated]**\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search.\n* [Neural Networks and Deep Learning](https://github.com/mnielsen/neural-networks-and-deep-learning) - Code samples for my book \"Neural Networks and Deep Learning\" [DEEP LEARNING].\n* [Annoy](https://github.com/spotify/annoy) - Approximate nearest neighbours implementation.\n* [TPOT](https://github.com/EpistasisLab/tpot) - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning.\n* [pgmpy](https://github.com/pgmpy/pgmpy) A python library for working with Probabilistic Graphical Models.\n* [DIGITS](https://github.com/NVIDIA/DIGITS) - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models.\n* [Orange](https://orange.biolab.si/) - Open source data visualization and data analysis for novices and experts.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [milk](https://github.com/luispedro/milk) - Machine learning toolkit focused on supervised classification. **[Deprecated]**\n* [TFLearn](https://github.com/tflearn/tflearn) - Deep learning library featuring a higher-level API for TensorFlow.\n* [REP](https://github.com/yandex/rep) - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. **[Deprecated]**\n* [rgf_python](https://github.com/RGF-team/rgf) - Python bindings for Regularized Greedy Forest (Tree) Library.\n* [skbayes](https://github.com/AmazaspShumik/sklearn-bayes) - Python package for Bayesian Machine Learning with scikit-learn API.\n* [fuku-ml](https://github.com/fukuball/fuku-ml) - Simple machine learning library, including Perceptron, Regression, Support Vector Machine, Decision Tree and more, it's easy to use and easy to learn for beginners.\n* [Xcessiv](https://github.com/reiinakano/xcessiv) - A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling.\n* [PyTorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration\n* [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) - The lightweight PyTorch wrapper for high-performance AI research.\n* [PyTorch Lightning Bolts](https://github.com/PyTorchLightning/pytorch-lightning-bolts) - Toolbox of models, callbacks, and datasets for AI/ML researchers.\n* [skorch](https://github.com/skorch-dev/skorch) - A scikit-learn compatible neural network library that wraps PyTorch.\n* [ML-From-Scratch](https://github.com/eriklindernoren/ML-From-Scratch) - Implementations of Machine Learning models from scratch in Python with a focus on transparency. Aims to showcase the nuts and bolts of ML in an accessible way.\n* [Edward](http://edwardlib.org/) - A library for probabilistic modelling, inference, and criticism. Built on top of TensorFlow.\n* [xRBM](https://github.com/omimo/xRBM) - A library for Restricted Boltzmann Machine (RBM) and its conditional variants in Tensorflow.\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, well documented and supports CPU and GPU (even multi-GPU) computation.\n* [stacked_generalization](https://github.com/fukatani/stacked_generalization) - Implementation of machine learning stacking technique as a handy library in Python.\n* [modAL](https://github.com/modAL-python/modAL) - A modular active learning framework for Python, built on top of scikit-learn.\n* [Cogitare](https://github.com/cogitare-ai/cogitare): A Modern, Fast, and Modular Deep Learning and Machine Learning framework for Python.\n* [Parris](https://github.com/jgreenemi/Parris) - Parris, the automated infrastructure setup tool for machine learning algorithms.\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It's written in C programming language and comes with Python programming language bindings.\n* [Turi Create](https://github.com/apple/turicreate) - Machine learning from Apple. Turi Create simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.\n* [mlens](https://github.com/flennerhag/mlens) - A high performance, memory efficient, maximally parallelized ensemble learning, integrated with scikit-learn.\n* [Thampi](https://github.com/scoremedia/thampi) - Machine Learning Prediction System on AWS Lambda\n* [MindsDB](https://github.com/mindsdb/mindsdb) - Open Source framework to streamline use of neural networks.\n* [Microsoft Recommenders](https://github.com/Microsoft/Recommenders): Examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repo contains some of the latest state of the art algorithms from Microsoft Research as well as from other companies and institutions.\n* [StellarGraph](https://github.com/stellargraph/stellargraph): Machine Learning on Graphs, a Python library for machine learning on graph-structured (network-structured) data.\n* [BentoML](https://github.com/bentoml/bentoml): Toolkit for package and deploy machine learning models for serving in production\n* [MiraiML](https://github.com/arthurpaulino/miraiml): An asynchronous engine for continuous & autonomous machine learning, built for real-time usage.\n* [numpy-ML](https://github.com/ddbourgin/numpy-ml): Reference implementations of ML models written in numpy\n* [Neuraxle](https://github.com/Neuraxio/Neuraxle): A framework providing the right abstractions to ease research, development, and deployment of your ML pipelines.\n* [Cornac](https://github.com/PreferredAI/cornac) - A comparative framework for multimodal recommender systems with a focus on models leveraging auxiliary data.\n* [JAX](https://github.com/google/jax) - JAX is Autograd and XLA, brought together for high-performance machine learning research.\n* [Catalyst](https://github.com/catalyst-team/catalyst) - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing. Being able to research/develop something new, rather than write another regular train loop.\n* [Fastai](https://github.com/fastai/fastai) - High-level wrapper built on the top of Pytorch which supports vision, text, tabular data and collaborative filtering.\n* [scikit-multiflow](https://github.com/scikit-multiflow/scikit-multiflow) - A machine learning framework for multi-output/multi-label and stream data.\n* [Lightwood](https://github.com/mindsdb/lightwood) - A Pytorch based framework that breaks down machine learning problems into smaller blocks that can be glued together seamlessly with objective to build predictive models with one line of code.\n* [bayeso](https://github.com/jungtaekkim/bayeso) - A simple, but essential Bayesian optimization package, written in Python.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides explanations and markdown reports.\n* [evostra](https://github.com/alirezamika/evostra) - A fast Evolution Strategy implementation in Python.\n* [Determined](https://github.com/determined-ai/determined) - Scalable deep learning training platform, including integrated support for distributed training, hyperparameter tuning, experiment tracking, and model management.\n* [PySyft](https://github.com/OpenMined/PySyft) - A Python library for secure and private Deep Learning built on PyTorch and TensorFlow.\n* [PyGrid](https://github.com/OpenMined/PyGrid/) - Peer-to-peer network of data owners and data scientists who can collectively train AI models using PySyft\n* [sktime](https://github.com/alan-turing-institute/sktime) - A unified framework for machine learning with time series\n* [OPFython](https://github.com/gugarosa/opfython) - A Python-inspired implementation of the Optimum-Path Forest classifier.\n* [Opytimizer](https://github.com/gugarosa/opytimizer) - Python-based meta-heuristic optimization techniques.\n* [Gradio](https://github.com/gradio-app/gradio) - A Python library for quickly creating and sharing demos of models. Debug models interactively in your browser, get feedback from collaborators, and generate public links without deploying anything.\n* [Hub](https://github.com/activeloopai/Hub) - Fastest unstructured dataset management for TensorFlow/PyTorch. Stream & version-control data. Store even petabyte-scale data in a single numpy-like array on the cloud accessible on any machine. Visit [activeloop.ai](https://activeloop.ai) for more info.\n* [Synthia](https://github.com/dmey/synthia) - Multidimensional synthetic data generation in Python.\n* [ByteHub](https://github.com/bytehub-ai/bytehub) - An easy-to-use, Python-based feature store. Optimized for time-series data.\n* [Backprop](https://github.com/backprop-ai/backprop) - Backprop makes it simple to use, finetune, and deploy state-of-the-art ML models.\n* [River](https://github.com/online-ml/river): A framework for general purpose online machine learning.\n* [FEDOT](https://github.com/nccr-itmo/FEDOT): An AutoML framework for the automated design of composite modelling pipelines. It can handle classification, regression, and time series forecasting tasks on different types of data (including multi-modal datasets).\n* [Sklearn-genetic-opt](https://github.com/rodrigo-arenas/Sklearn-genetic-opt): An AutoML package for hyperparameters tuning using evolutionary algorithms, with built-in callbacks, plotting, remote logging and more.\n* [Evidently](https://github.com/evidentlyai/evidently): Interactive reports to analyze machine learning models during validation or production monitoring.\n* [Streamlit](https://github.com/streamlit/streamlit): Streamlit is an framework to create beautiful data apps in hours, not weeks.\n* [Optuna](https://github.com/optuna/optuna): Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning.\n* [Deepchecks](https://github.com/deepchecks/deepchecks): Validation & testing of machine learning models and data during model development, deployment, and production. This includes checks and suites related to various types of issues, such as model performance, data integrity, distribution mismatches, and more.\n* [Shapash](https://github.com/MAIF/shapash) : Shapash is a Python library that provides several types of visualization that display explicit labels that everyone can understand.\n* [Eurybia](https://github.com/MAIF/eurybia): Eurybia monitors data and model drift over time and securizes model deployment with data validation.\n* [Colossal-AI](https://github.com/hpcaitech/ColossalAI): An open-source deep learning system for large-scale model training and inference with high efficiency and low cost.\n* [dirty_cat](https://github.com/dirty-cat/dirty_cat) - facilitates machine-learning on dirty, non-curated categories. It provides transformers and encoders robust to morphological variants, such as typos.\n* [Upgini](https://github.com/upgini/upgini): Free automated data & feature enrichment library for machine learning - automatically searches through thousands of ready-to-use features from public and community shared data sources and enriches your training dataset with only the accuracy improving features.\n* [AutoML-Implementation-for-Static-and-Dynamic-Data-Analytics](https://github.com/Western-OC2-Lab/AutoML-Implementation-for-Static-and-Dynamic-Data-Analytics): A tutorial to help machine learning researchers to automatically obtain optimized machine learning models with the optimal learning performance on any specific task.\n* [SKBEL](https://github.com/robinthibaut/skbel): A Python library for Bayesian Evidential Learning (BEL) in order to estimate the uncertainty of a prediction.\n* [NannyML](https://bit.ly/nannyml-github-machinelearning): Python library capable of fully capturing the impact of data drift on performance. Allows estimation of post-deployment model performance without access to targets.\n* [cleanlab](https://github.com/cleanlab/cleanlab): The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels.\n* [AutoGluon](https://github.com/awslabs/autogluon): AutoML for Image, Text, Tabular, Time-Series, and MultiModal Data.\n* [PyBroker](https://github.com/edtechre/pybroker) - Algorithmic Trading with Machine Learning.\n* [Frouros](https://github.com/IFCA/frouros): Frouros is an open source Python library for drift detection in machine learning systems.\n* [CometML](https://github.com/comet-ml/comet-examples): The best-in-class MLOps platform with experiment tracking, model production monitoring, a model registry, and data lineage from training straight through to production.\n* [Okrolearn](https://github.com/Okerew/okrolearn): A python machine learning library created to combine powefull data analasys feautures with tensors and machine learning components, while mantaining support for other libraries.\n* [Opik](https://github.com/comet-ml/opik): Evaluate, trace, test, and ship LLM applications across your dev and production lifecycles.\n\n<a name=\"python-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n* [DataComPy](https://github.com/capitalone/datacompy) - A library to compare Pandas, Polars, and Spark data frames. It provides stats and lets users adjust for match accuracy.\n* [DataVisualization](https://github.com/Shanky-21/Data_visualization) - A GitHub Repository Where you can Learn Datavisualizatoin Basics to Intermediate level.\n* [Cartopy](https://scitools.org.uk/cartopy/docs/latest/) - Cartopy is a Python package designed for geospatial data processing in order to produce maps and other geospatial data analyses.\n* [SciPy](https://www.scipy.org/) - A Python-based ecosystem of open-source software for mathematics, science, and engineering.\n* [NumPy](https://www.numpy.org/) - A fundamental package for scientific computing with Python.\n* [AutoViz](https://github.com/AutoViML/AutoViz) AutoViz performs automatic visualization of any dataset with a single line of Python code. Give it any input file (CSV, txt or JSON) of any size and AutoViz will visualize it. See <a href=\"https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad?source=friends_link&sk=c9e9503ec424b191c6096d7e3f515d10\">Medium article</a>.\n* [Numba](https://numba.pydata.org/) - Python JIT (just in time) compiler to LLVM aimed at scientific Python by the developers of Cython and NumPy.\n* [Mars](https://github.com/mars-project/mars) - A tensor-based framework for large-scale data computation which is often regarded as a parallel and distributed version of NumPy.\n* [NetworkX](https://networkx.github.io/) - A high-productivity software for complex networks.\n* [igraph](https://igraph.org/python/) - binding to igraph library - General purpose graph library.\n* [Pandas](https://pandas.pydata.org/) - A library providing high-performance, easy-to-use data structures and data analysis tools.\n* [ParaMonte](https://github.com/cdslaborg/paramonte) - A general-purpose Python library for Bayesian data analysis and visualization via serial/parallel Monte Carlo and MCMC simulations. Documentation can be found [here](https://www.cdslab.org/paramonte/).\n* [Vaex](https://github.com/vaexio/vaex) - A high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. Documentation can be found [here](https://vaex.io/docs/index.html).\n* [Open Mining](https://github.com/mining/mining) - Business Intelligence (BI) in Python (Pandas web interface) **[Deprecated]**\n* [PyMC](https://github.com/pymc-devs/pymc) - Markov Chain Monte Carlo sampling toolkit.\n* [zipline](https://github.com/quantopian/zipline) - A Pythonic algorithmic trading library.\n* [PyDy](https://www.pydy.org/) - Short for Python Dynamics, used to assist with workflow in the modelling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib.\n* [SymPy](https://github.com/sympy/sympy) - A Python library for symbolic mathematics.\n* [statsmodels](https://github.com/statsmodels/statsmodels) - Statistical modelling and econometrics in Python.\n* [astropy](https://www.astropy.org/) - A community Python library for Astronomy.\n* [matplotlib](https://matplotlib.org/) - A Python 2D plotting library.\n* [bokeh](https://github.com/bokeh/bokeh) - Interactive Web Plotting for Python.\n* [plotly](https://plot.ly/python/) - Collaborative web plotting for Python and matplotlib.\n* [altair](https://github.com/altair-viz/altair) - A Python to Vega translator.\n* [d3py](https://github.com/mikedewar/d3py) - A plotting library for Python, based on [D3.js](https://d3js.org/).\n* [PyDexter](https://github.com/D3xterjs/pydexter) - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser.\n* [ggplot](https://github.com/yhat/ggpy) - Same API as ggplot2 for R. **[Deprecated]**\n* [ggfortify](https://github.com/sinhrks/ggfortify) - Unified interface to ggplot2 popular R packages.\n* [Kartograph.py](https://github.com/kartograph/kartograph.py) - Rendering beautiful SVG maps in Python.\n* [pygal](http://pygal.org/en/stable/) - A Python SVG Charts Creator.\n* [PyQtGraph](https://github.com/pyqtgraph/pyqtgraph) - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy.\n* [pycascading](https://github.com/twitter/pycascading) **[Deprecated]**\n* [Petrel](https://github.com/AirSage/Petrel) - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python.\n* [Blaze](https://github.com/blaze/blaze) - NumPy and Pandas interface to Big Data.\n* [emcee](https://github.com/dfm/emcee) - The Python ensemble sampling toolkit for affine-invariant MCMC.\n* [windML](https://github.com/cigroup-ol/windml) - A Python Framework for Wind Energy Analysis and Prediction.\n* [vispy](https://github.com/vispy/vispy) - GPU-based high-performance interactive OpenGL 2D/3D data visualization library.\n* [cerebro2](https://github.com/numenta/nupic.cerebro2) A web-based visualization and debugging platform for NuPIC. **[Deprecated]**\n* [NuPIC Studio](https://github.com/htm-community/nupic.studio) An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! **[Deprecated]**\n* [SparklingPandas](https://github.com/sparklingpandas/sparklingpandas) Pandas on PySpark (POPS).\n* [Seaborn](https://seaborn.pydata.org/) - A python visualization library based on matplotlib.\n* [ipychart](https://github.com/nicohlr/ipychart) - The power of Chart.js in Jupyter Notebook.\n* [bqplot](https://github.com/bloomberg/bqplot) - An API for plotting in Jupyter (IPython).\n* [pastalog](https://github.com/rewonc/pastalog) - Simple, realtime visualization of neural network training performance.\n* [Superset](https://github.com/apache/incubator-superset) - A data exploration platform designed to be visual, intuitive, and interactive.\n* [Dora](https://github.com/nathanepstein/dora) - Tools for exploratory data analysis in Python.\n* [Ruffus](http://www.ruffus.org.uk) - Computation Pipeline library for python.\n* [SOMPY](https://github.com/sevamoo/SOMPY) - Self Organizing Map written in Python (Uses neural networks for data analysis).\n* [somoclu](https://github.com/peterwittek/somoclu) Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API.\n* [HDBScan](https://github.com/lmcinnes/hdbscan) - implementation of the hdbscan algorithm in Python - used for clustering\n* [visualize_ML](https://github.com/ayush1997/visualize_ML) - A python package for data exploration and data analysis. **[Deprecated]**\n* [scikit-plot](https://github.com/reiinakano/scikit-plot) - A visualization library for quick and easy generation of common plots in data analysis and machine learning.\n* [Bowtie](https://github.com/jwkvam/bowtie) - A dashboard library for interactive visualizations using flask socketio and react.\n* [lime](https://github.com/marcotcr/lime) - Lime is about explaining what machine learning classifiers (or models) are doing. It is able to explain any black box classifier, with two or more classes.\n* [PyCM](https://github.com/sepandhaghighi/pycm) - PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n* [Dash](https://github.com/plotly/dash) - A framework for creating analytical web applications built on top of Plotly.js, React, and Flask\n* [Lambdo](https://github.com/asavinov/lambdo) - A workflow engine for solving machine learning problems by combining in one analysis pipeline (i) feature engineering and machine learning (ii) model training and prediction (iii) table population and column evaluation via user-defined (Python) functions.\n* [TensorWatch](https://github.com/microsoft/tensorwatch) - Debugging and visualization tool for machine learning and data science. It extensively leverages Jupyter Notebook to show real-time visualizations of data in running processes such as machine learning training.\n* [dowel](https://github.com/rlworkgroup/dowel) - A little logger for machine learning research. Output any object to the terminal, CSV, TensorBoard, text logs on disk, and more with just one call to `logger.log()`.\n\n<a name=\"python-misc-scripts--ipython-notebooks--codebases\"></a>\n#### Misc Scripts / iPython Notebooks / Codebases\n* [MiniGrad](https://github.com/kennysong/minigrad) – A minimal, educational, Pythonic implementation of autograd (~100 loc).\n* [Map/Reduce implementations of common ML algorithms](https://github.com/Yannael/BigDataAnalytics_INFOH515): Jupyter notebooks that cover how to implement from scratch different ML algorithms (ordinary least squares, gradient descent, k-means, alternating least squares), using Python NumPy, and how to then make these implementations scalable using Map/Reduce and Spark.\n* [BioPy](https://github.com/jaredthecoder/BioPy) - Biologically-Inspired and Machine Learning Algorithms in Python. **[Deprecated]**\n* [CAEs for Data Assimilation](https://github.com/julianmack/Data_Assimilation) - Convolutional autoencoders for 3D image/field compression applied to reduced order [Data Assimilation](https://en.wikipedia.org/wiki/Data_assimilation).\n* [handsonml](https://github.com/ageron/handson-ml) - Fundamentals of machine learning in python.\n* [SVM Explorer](https://github.com/plotly/dash-svm) - Interactive SVM Explorer, using Dash and scikit-learn\n* [pattern_classification](https://github.com/rasbt/pattern_classification)\n* [thinking stats 2](https://github.com/Wavelets/ThinkStats2)\n* [hyperopt](https://github.com/hyperopt/hyperopt-sklearn)\n* [numpic](https://github.com/numenta/nupic)\n* [2012-paper-diginorm](https://github.com/dib-lab/2012-paper-diginorm)\n* [A gallery of interesting IPython notebooks](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n* [ipython-notebooks](https://github.com/ogrisel/notebooks)\n* [data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks) - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.\n* [decision-weights](https://github.com/CamDavidsonPilon/decision-weights)\n* [Sarah Palin LDA](https://github.com/Wavelets/sarah-palin-lda) - Topic Modelling the Sarah Palin emails.\n* [Diffusion Segmentation](https://github.com/Wavelets/diffusion-segmentation) - A collection of image segmentation algorithms based on diffusion methods.\n* [Scipy Tutorials](https://github.com/Wavelets/scipy-tutorials) - SciPy tutorials. This is outdated, check out scipy-lecture-notes.\n* [Crab](https://github.com/marcelcaraciolo/crab) - A recommendation engine library for Python.\n* [BayesPy](https://github.com/maxsklar/BayesPy) - Bayesian Inference Tools in Python.\n* [scikit-learn tutorials](https://github.com/GaelVaroquaux/scikit-learn-tutorial) - Series of notebooks for learning scikit-learn.\n* [sentiment-analyzer](https://github.com/madhusudancs/sentiment-analyzer) - Tweets Sentiment Analyzer\n* [sentiment_classifier](https://github.com/kevincobain2000/sentiment_classifier) - Sentiment classifier using word sense disambiguation.\n* [group-lasso](https://github.com/fabianp/group_lasso) - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model.\n* [jProcessing](https://github.com/kevincobain2000/jProcessing) - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary & parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO--8859-1 configured) in Python.\n* [mne-python-notebooks](https://github.com/mne-tools/mne-python-notebooks) - IPython notebooks for EEG/MEG data processing using mne-python.\n* [Neon Course](https://github.com/NervanaSystems/neon_course) - IPython notebooks for a complete course around understanding Nervana's Neon.\n* [pandas cookbook](https://github.com/jvns/pandas-cookbook) - Recipes for using Python's pandas library.\n* [climin](https://github.com/BRML/climin) - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others.\n* [Allen Downey’s Data Science Course](https://github.com/AllenDowney/DataScience) - Code for Data Science at Olin College, Spring 2014.\n* [Allen Downey’s Think Bayes Code](https://github.com/AllenDowney/ThinkBayes) - Code repository for Think Bayes.\n* [Allen Downey’s Think Complexity Code](https://github.com/AllenDowney/ThinkComplexity) - Code for Allen Downey's book Think Complexity.\n* [Allen Downey’s Think OS Code](https://github.com/AllenDowney/ThinkOS) - Text and supporting code for Think OS: A Brief Introduction to Operating Systems.\n* [Python Programming for the Humanities](https://www.karsdorp.io/python-course/) - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP.\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [Optunity examples](http://optunity.readthedocs.io/en/latest/notebooks/index.html) - Examples demonstrating how to use Optunity in synergy with machine learning libraries.\n* [Dive into Machine Learning  with Python Jupyter notebook and scikit-learn](https://github.com/hangtwenty/dive-into-machine-learning) - \"I learned Python by hacking first, and getting serious *later.* I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.\"\n* [TDB](https://github.com/ericjang/tdb) - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow.\n* [Suiron](https://github.com/kendricktan/suiron/) - Machine Learning for RC Cars.\n* [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos) - IPython notebooks from Data School's video tutorials on scikit-learn.\n* [Practical XGBoost in Python](https://parrotprediction.teachable.com/p/practical-xgboost-in-python) - comprehensive online course about using XGBoost in Python.\n* [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python) - Notebooks and code for the book \"Introduction to Machine Learning with Python\"\n* [Pydata book](https://github.com/wesm/pydata-book) - Materials and IPython notebooks for \"Python for Data Analysis\" by Wes McKinney, published by O'Reilly Media\n* [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) - Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained\n* [Prodmodel](https://github.com/prodmodel/prodmodel) - Build tool for data science pipelines.\n* [the-elements-of-statistical-learning](https://github.com/maitbayev/the-elements-of-statistical-learning) - This repository contains Jupyter notebooks implementing the algorithms found in the book and summary of the textbook.\n* [Hyperparameter-Optimization-of-Machine-Learning-Algorithms](https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms) - Code for hyperparameter tuning/optimization of machine learning and deep learning algorithms.\n* [Heart_Disease-Prediction](https://github.com/ShivamChoudhary17/Heart_Disease) - Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n* [Flight Fare Prediction](https://github.com/ShivamChoudhary17/Flight_Fare_Prediction) - This basically to gauge the understanding of Machine Learning Workflow and Regression technique in specific.\n* [Keras Tuner](https://github.com/keras-team/keras-tuner) - An easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search.\n\n\n\n<a name=\"python-neural-networks\"></a>\n#### Neural Networks\n\n* [Kinho](https://github.com/kinhosz/Neural) - Simple API for Neural Network. Better for image processing with CPU/GPU + Transfer Learning.\n* [nn_builder](https://github.com/p-christ/nn_builder) - nn_builder is a python package that lets you build neural networks in 1 line\n* [NeuralTalk](https://github.com/karpathy/neuraltalk) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.\n* [NeuralTalk](https://github.com/karpathy/neuraltalk2) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. **[Deprecated]**\n* [Neuron](https://github.com/molcik/python-neuron) - Neuron is simple class for time series predictions. It's utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg–Marquardt algorithm. **[Deprecated]**\n* [Data Driven Code](https://github.com/atmb4u/data-driven-code) - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments.\n* [Machine Learning, Data Science and Deep Learning with Python](https://www.manning.com/livevideo/machine-learning-data-science-and-deep-learning-with-python) - LiveVideo course that covers machine learning, Tensorflow, artificial intelligence, and neural networks.\n* [TResNet: High Performance GPU-Dedicated Architecture](https://github.com/mrT23/TResNet) - TResNet models were designed and optimized to give the best speed-accuracy tradeoff out there on GPUs.\n* [TResNet: Simple and powerful neural network library for python](https://github.com/zueve/neurolab) - Variety of supported types of Artificial Neural Network and learning algorithms.\n* [Jina AI](https://jina.ai/) An easier way to build neural search in the cloud. Compatible with Jupyter Notebooks.\n* [sequitur](https://github.com/shobrook/sequitur) PyTorch library for creating and training sequence autoencoders in just two lines of code\n\n\n<a name=\"python-spiking-neural-networks\"></a>\n#### Spiking Neural Networks\n\n* [Rockpool](https://github.com/synsense/rockpool) - A machine learning library for spiking neural networks. Supports training with both torch and jax pipelines, and deployment to neuromorphic hardware.\n* [Sinabs](https://github.com/synsense/sinabs) - A deep learning library for spiking neural networks which is based on PyTorch, focuses on fast training and supports inference on neuromorphic hardware.\n* [Tonic](https://github.com/neuromorphs/tonic) - A library that makes downloading publicly available neuromorphic datasets a breeze and provides event-based data transformation/augmentation pipelines.\n\n<a name=\"python-survival-analysis\"></a>\n#### Python Survival Analysis\n* [lifelines](https://github.com/CamDavidsonPilon/lifelines) - lifelines is a complete survival analysis library, written in pure Python\n* [Scikit-Survival](https://github.com/sebp/scikit-survival) - scikit-survival is a Python module for survival analysis built on top of scikit-learn. It allows doing survival analysis while utilizing the power of scikit-learn, e.g., for pre-processing or doing cross-validation.\n\n<a name=\"python-federated-learning\"></a>\n#### Federated Learning\n* [Flower](https://flower.dev/) - A unified approach to federated learning, analytics, and evaluation. Federate any workload, any ML framework, and any programming language.\n* [PySyft](https://github.com/OpenMined/PySyft) - A Python library for secure and private Deep Learning.\n* [Tensorflow-Federated](https://www.tensorflow.org/federated) A federated learning framework for machine learning and other computations on decentralized data.\n\n<a name=\"python-kaggle-competition-source-code\"></a>\n#### Kaggle Competition Source Code\n* [open-solution-home-credit](https://github.com/neptune-ml/open-solution-home-credit) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Home-Credit-Default-Risk) for [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk).\n* [open-solution-googleai-object-detection](https://github.com/neptune-ml/open-solution-googleai-object-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Google-AI-Object-Detection-Challenge) for [Google AI Open Images - Object Detection Track](https://www.kaggle.com/c/google-ai-open-images-object-detection-track).\n* [open-solution-salt-identification](https://github.com/neptune-ml/open-solution-salt-identification) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Salt-Detection) for [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge).\n* [open-solution-ship-detection](https://github.com/neptune-ml/open-solution-ship-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Ships) for [Airbus Ship Detection Challenge](https://www.kaggle.com/c/airbus-ship-detection).\n* [open-solution-data-science-bowl-2018](https://github.com/neptune-ml/open-solution-data-science-bowl-2018) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Data-Science-Bowl-2018) for [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018).\n* [open-solution-value-prediction](https://github.com/neptune-ml/open-solution-value-prediction) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Santander-Value-Prediction-Challenge) for [Santander Value Prediction Challenge](https://www.kaggle.com/c/santander-value-prediction-challenge).\n* [open-solution-toxic-comments](https://github.com/neptune-ml/open-solution-toxic-comments) -> source code for [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n* [wiki challenge](https://github.com/hammer/wikichallenge) - An implementation of Dell Zhang's solution to Wikipedia's Participation Challenge on Kaggle.\n* [kaggle insults](https://github.com/amueller/kaggle_insults) - Kaggle Submission for \"Detecting Insults in Social Commentary\".\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [kaggle-cifar](https://github.com/zygmuntz/kaggle-cifar) - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet.\n* [kaggle-blackbox](https://github.com/zygmuntz/kaggle-blackbox) - Deep learning made easy.\n* [kaggle-accelerometer](https://github.com/zygmuntz/kaggle-accelerometer) - Code for Accelerometer Biometric Competition at Kaggle.\n* [kaggle-advertised-salaries](https://github.com/zygmuntz/kaggle-advertised-salaries) - Predicting job salaries from ads - a Kaggle competition.\n* [kaggle amazon](https://github.com/zygmuntz/kaggle-amazon) - Amazon access control challenge.\n* [kaggle-bestbuy_big](https://github.com/zygmuntz/kaggle-bestbuy_big) - Code for the Best Buy competition at Kaggle.\n* [kaggle-bestbuy_small](https://github.com/zygmuntz/kaggle-bestbuy_small)\n* [Kaggle Dogs vs. Cats](https://github.com/kastnerkyle/kaggle-dogs-vs-cats) - Code for Kaggle Dogs vs. Cats competition.\n* [Kaggle Galaxy Challenge](https://github.com/benanne/kaggle-galaxies) - Winning solution for the Galaxy Challenge on Kaggle.\n* [Kaggle Gender](https://github.com/zygmuntz/kaggle-gender) - A Kaggle competition: discriminate gender based on handwriting.\n* [Kaggle Merck](https://github.com/zygmuntz/kaggle-merck) - Merck challenge at Kaggle.\n* [Kaggle Stackoverflow](https://github.com/zygmuntz/kaggle-stackoverflow) - Predicting closed questions on Stack Overflow.\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [wine-quality](https://github.com/zygmuntz/wine-quality) - Predicting wine quality.\n\n<a name=\"python-reinforcement-learning\"></a>\n#### Reinforcement Learning\n* [DeepMind Lab](https://github.com/deepmind/lab) - DeepMind Lab is a 3D learning environment based on id Software's Quake III Arena via ioquake3 and other open source software. Its primary purpose is to act as a testbed for research in artificial intelligence, especially deep reinforcement learning.\n* [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) - A library for developing and comparing reinforcement learning algorithms (successor of [gym])(https://github.com/openai/gym).\n* [Serpent.AI](https://github.com/SerpentAI/SerpentAI) - Serpent.AI is a game agent framework that allows you to turn any video game you own into a sandbox to develop AI and machine learning experiments. For both researchers and hobbyists.\n* [ViZDoom](https://github.com/mwydmuch/ViZDoom) - ViZDoom allows developing AI bots that play Doom using only the visual information (the screen buffer). It is primarily intended for research in machine visual learning, and deep reinforcement learning, in particular.\n* [Roboschool](https://github.com/openai/roboschool) - Open-source software for robot simulation, integrated with OpenAI Gym.\n* [Retro](https://github.com/openai/retro) - Retro Games in Gym\n* [SLM Lab](https://github.com/kengz/SLM-Lab) - Modular Deep Reinforcement Learning framework in PyTorch.\n* [Coach](https://github.com/NervanaSystems/coach) - Reinforcement Learning Coach by Intel® AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms\n* [garage](https://github.com/rlworkgroup/garage) - A toolkit for reproducible reinforcement learning research\n* [metaworld](https://github.com/rlworkgroup/metaworld) - An open source robotics benchmark for meta- and multi-task reinforcement learning\n* [acme](https://deepmind.com/research/publications/Acme) - An Open Source Distributed Framework for Reinforcement Learning that makes build and train your agents easily.\n* [Spinning Up](https://spinningup.openai.com) - An educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning\n* [Maze](https://github.com/enlite-ai/maze) - Application-oriented deep reinforcement learning framework addressing real-world decision problems.\n* [RLlib](https://github.com/ray-project/ray) - RLlib is an industry level, highly scalable RL library for tf and torch, based on Ray. It's used by companies like Amazon and Microsoft to solve real-world decision making problems at scale.\n* [DI-engine](https://github.com/opendilab/DI-engine) - DI-engine is a generalized Decision Intelligence engine. It supports most basic deep reinforcement learning (DRL) algorithms, such as DQN, PPO, SAC, and domain-specific algorithms like QMIX in multi-agent RL, GAIL in inverse RL, and RND in exploration problems.\n\n<a name=\"python-speech-recognition\"></a>\n#### Speech Recognition\n* [EspNet](https://github.com/espnet/espnet) - ESPnet is an end-to-end speech processing toolkit for tasks like speech recognition, translation, and enhancement, using PyTorch and Kaldi-style data processing.\n\n<a name=\"ruby\"></a>\n## Ruby\n\n<a name=\"ruby-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Awesome NLP with Ruby](https://github.com/arbox/nlp-with-ruby) - Curated link list for practical natural language processing in Ruby.\n* [Treat](https://github.com/louismullie/treat) - Text Retrieval and Annotation Toolkit, definitely the most comprehensive toolkit I’ve encountered so far for Ruby.\n* [Stemmer](https://github.com/aurelian/ruby-stemmer) - Expose libstemmer_c to Ruby. **[Deprecated]**\n* [Raspell](https://sourceforge.net/projects/raspell/) - raspell is an interface binding for ruby. **[Deprecated]**\n* [UEA Stemmer](https://github.com/ealdent/uea-stemmer) - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing.\n* [Twitter-text-rb](https://github.com/twitter/twitter-text/tree/master/rb) - A library that does auto linking and extraction of usernames, lists and hashtags in tweets.\n\n<a name=\"ruby-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Awesome Machine Learning with Ruby](https://github.com/arbox/machine-learning-with-ruby) - Curated list of ML related resources for Ruby.\n* [Ruby Machine Learning](https://github.com/tsycho/ruby-machine-learning) - Some Machine Learning algorithms, implemented in Ruby. **[Deprecated]**\n* [Machine Learning Ruby](https://github.com/mizoR/machine-learning-ruby) **[Deprecated]**\n* [jRuby Mahout](https://github.com/vasinov/jruby_mahout) - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. **[Deprecated]**\n* [CardMagic-Classifier](https://github.com/cardmagic/classifier) - A general classifier module to allow Bayesian and other types of classifications.\n* [rb-libsvm](https://github.com/febeling/rb-libsvm) - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines.\n* [Scoruby](https://github.com/asafschers/scoruby) - Creates Random Forest classifiers from PMML files.\n* [rumale](https://github.com/yoshoku/rumale) - Rumale is a machine learning library in Ruby\n\n<a name=\"ruby-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [rsruby](https://github.com/alexgutteridge/rsruby) - Ruby - R bridge.\n* [data-visualization-ruby](https://github.com/chrislo/data_visualisation_ruby) - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby. **[Deprecated]**\n* [ruby-plot](https://www.ruby-toolbox.com/projects/ruby-plot) - gnuplot wrapper for Ruby, especially for plotting ROC curves into SVG files. **[Deprecated]**\n* [plot-rb](https://github.com/zuhao/plotrb) - A plotting library in Ruby built on top of Vega and D3. **[Deprecated]**\n* [scruffy](https://github.com/delano/scruffy) - A beautiful graphing toolkit for Ruby.\n* [SciRuby](http://sciruby.com/)\n* [Glean](https://github.com/glean/glean) - A data management tool for humans. **[Deprecated]**\n* [Bioruby](https://github.com/bioruby/bioruby)\n* [Arel](https://github.com/nkallen/arel) **[Deprecated]**\n\n<a name=\"ruby-misc\"></a>\n#### Misc\n\n* [Big Data For Chimps](https://github.com/infochimps-labs/big_data_for_chimps)\n* [Listof](https://github.com/kevincobain2000/listof) - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, JSON or hash. [Demo/Search for a list](http://kevincobain2000.github.io/listof/)\n\n\n<a name=\"rust\"></a>\n## Rust\n\n<a name=\"rust-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n* [smartcore](https://github.com/smartcorelib/smartcore) - \"The Most Advanced Machine Learning Library In Rust.\"\n* [linfa](https://github.com/rust-ml/linfa) - a comprehensive toolkit to build Machine Learning applications with Rust\n* [deeplearn-rs](https://github.com/tedsta/deeplearn-rs) - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license.\n* [rustlearn](https://github.com/maciejkula/rustlearn) - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests.\n* [rusty-machine](https://github.com/AtheMathmo/rusty-machine) - a pure-rust machine learning library.\n* [leaf](https://github.com/autumnai/leaf) - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [**[Deprecated]**](https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb#.s0a3uy4cc)\n* [RustNN](https://github.com/jackm321/RustNN) - RustNN is a feedforward neural network library. **[Deprecated]**\n* [RusticSOM](https://github.com/avinashshenoy97/RusticSOM) - A Rust library for Self Organising Maps (SOM).\n* [candle](https://github.com/huggingface/candle) - Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use.\n* [linfa](https://github.com/rust-ml/linfa) - `linfa` aims to provide a comprehensive toolkit to build Machine Learning applications with Rust\n* [delta](https://github.com/delta-rs/delta) - An open source machine learning framework in Rust Δ\n\n#### Deep Learning\n\n* [tch-rs](https://github.com/LaurentMazare/tch-rs) - Rust bindings for the C++ API of PyTorch\n* [dfdx](https://github.com/coreylowman/dfdx) - Deep learning in Rust, with shape checked tensors and neural networks\n* [burn](https://github.com/tracel-ai/burn) - Burn is a new comprehensive dynamic Deep Learning Framework built using Rust with extreme flexibility, compute efficiency and portability as its primary goals\n\n#### Natural Language Processing\n\n* [huggingface/tokenizers](https://github.com/huggingface/tokenizers) - Fast State-of-the-Art Tokenizers optimized for Research and Production\n* [rust-bert](https://github.com/guillaume-be/rust-bert) - Rust native ready-to-use NLP pipelines and transformer-based models (BERT, DistilBERT, GPT2,...)\n\n<a name=\"r\"></a>\n## R\n\n<a name=\"r-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [ahaz](https://cran.r-project.org/web/packages/ahaz/index.html) - ahaz: Regularization for semiparametric additive hazards regression. **[Deprecated]**\n* [arules](https://cran.r-project.org/web/packages/arules/index.html) - arules: Mining Association Rules and Frequent Itemsets\n* [biglasso](https://cran.r-project.org/web/packages/biglasso/index.html) - biglasso: Extending Lasso Model Fitting to Big Data in R.\n* [bmrm](https://cran.r-project.org/web/packages/bmrm/index.html) - bmrm: Bundle Methods for Regularized Risk Minimization Package.\n* [Boruta](https://cran.r-project.org/web/packages/Boruta/index.html) - Boruta: A wrapper algorithm for all-relevant feature selection.\n* [bst](https://cran.r-project.org/web/packages/bst/index.html) - bst: Gradient Boosting.\n* [C50](https://cran.r-project.org/web/packages/C50/index.html) - C50: C5.0 Decision Trees and Rule-Based Models.\n* [caret](https://topepo.github.io/caret/index.html) - Classification and Regression Training: Unified interface to ~150 ML algorithms in R.\n* [caretEnsemble](https://cran.r-project.org/web/packages/caretEnsemble/index.html) - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. **[Deprecated]**\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box for R.\n* [Clever Algorithms For Machine Learning](https://machinelearningmastery.com/)\n* [CORElearn](https://cran.r-project.org/web/packages/CORElearn/index.html) - CORElearn: Classification, regression, feature evaluation and ordinal evaluation.\n-* [CoxBoost](https://cran.r-project.org/web/packages/CoxBoost/index.html) - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks **[Deprecated]**\n* [Cubist](https://cran.r-project.org/web/packages/Cubist/index.html) - Cubist: Rule- and Instance-Based Regression Modelling.\n* [e1071](https://cran.r-project.org/web/packages/e1071/index.html) - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien\n* [earth](https://cran.r-project.org/web/packages/earth/index.html) - earth: Multivariate Adaptive Regression Spline Models\n* [elasticnet](https://cran.r-project.org/web/packages/elasticnet/index.html) - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA.\n* [ElemStatLearn](https://cran.r-project.org/web/packages/ElemStatLearn/index.html) - ElemStatLearn: Data sets, functions and examples from the book: \"The Elements of Statistical Learning, Data Mining, Inference, and Prediction\" by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction\" by Trevor Hastie, Robert Tibshirani and Jerome Friedman.\n* [evtree](https://cran.r-project.org/web/packages/evtree/index.html) - evtree: Evolutionary Learning of Globally Optimal Trees.\n* [forecast](https://cran.r-project.org/web/packages/forecast/index.html) - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models.\n* [forecastHybrid](https://cran.r-project.org/web/packages/forecastHybrid/index.html) - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the \"forecast\" package.\n* [fpc](https://cran.r-project.org/web/packages/fpc/index.html) - fpc: Flexible procedures for clustering.\n* [frbs](https://cran.r-project.org/web/packages/frbs/index.html) - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks. **[Deprecated]**\n* [GAMBoost](https://cran.r-project.org/web/packages/GAMBoost/index.html) - GAMBoost: Generalized linear and additive models by likelihood based boosting. **[Deprecated]**\n* [gamboostLSS](https://cran.r-project.org/web/packages/gamboostLSS/index.html) - gamboostLSS: Boosting Methods for GAMLSS.\n* [gbm](https://cran.r-project.org/web/packages/gbm/index.html) - gbm: Generalized Boosted Regression Models.\n* [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html) - glmnet: Lasso and elastic-net regularized generalized linear models.\n* [glmpath](https://cran.r-project.org/web/packages/glmpath/index.html) - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model.\n* [GMMBoost](https://cran.r-project.org/web/packages/GMMBoost/index.html) - GMMBoost: Likelihood-based Boosting for Generalized mixed models. **[Deprecated]**\n* [grplasso](https://cran.r-project.org/web/packages/grplasso/index.html) - grplasso: Fitting user specified models with Group Lasso penalty.\n* [grpreg](https://cran.r-project.org/web/packages/grpreg/index.html) - grpreg: Regularization paths for regression models with grouped covariates.\n* [h2o](https://cran.r-project.org/web/packages/h2o/index.html) - A framework for fast, parallel, and distributed machine learning algorithms at scale -- Deeplearning, Random forests, GBM, KMeans, PCA, GLM.\n* [hda](https://cran.r-project.org/web/packages/hda/index.html) - hda: Heteroscedastic Discriminant Analysis. **[Deprecated]**\n* [Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/)\n* [ipred](https://cran.r-project.org/web/packages/ipred/index.html) - ipred: Improved Predictors.\n* [kernlab](https://cran.r-project.org/web/packages/kernlab/index.html) - kernlab: Kernel-based Machine Learning Lab.\n* [klaR](https://cran.r-project.org/web/packages/klaR/index.html) - klaR: Classification and visualization.\n* [L0Learn](https://cran.r-project.org/web/packages/L0Learn/index.html) - L0Learn: Fast algorithms for best subset selection.\n* [lars](https://cran.r-project.org/web/packages/lars/index.html) - lars: Least Angle Regression, Lasso and Forward Stagewise. **[Deprecated]**\n* [lasso2](https://cran.r-project.org/web/packages/lasso2/index.html) - lasso2: L1 constrained estimation aka ‘lasso’.\n* [LiblineaR](https://cran.r-project.org/web/packages/LiblineaR/index.html) - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library.\n* [LogicReg](https://cran.r-project.org/web/packages/LogicReg/index.html) - LogicReg: Logic Regression.\n* [Machine Learning For Hackers](https://github.com/johnmyleswhite/ML_for_Hackers)\n* [maptree](https://cran.r-project.org/web/packages/maptree/index.html) - maptree: Mapping, pruning, and graphing tree models. **[Deprecated]**\n* [mboost](https://cran.r-project.org/web/packages/mboost/index.html) - mboost: Model-Based Boosting.\n* [medley](https://www.kaggle.com/general/3661) - medley: Blending regression models, using a greedy stepwise approach.\n* [mlr](https://cran.r-project.org/web/packages/mlr/index.html) - mlr: Machine Learning in R.\n* [ncvreg](https://cran.r-project.org/web/packages/ncvreg/index.html) - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models.\n* [nnet](https://cran.r-project.org/web/packages/nnet/index.html) - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models. **[Deprecated]**\n* [pamr](https://cran.r-project.org/web/packages/pamr/index.html) - pamr: Pam: prediction analysis for microarrays. **[Deprecated]**\n* [party](https://cran.r-project.org/web/packages/party/index.html) - party: A Laboratory for Recursive Partitioning\n* [partykit](https://cran.r-project.org/web/packages/partykit/index.html) - partykit: A Toolkit for Recursive Partitioning.\n* [penalized](https://cran.r-project.org/web/packages/penalized/index.html) - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model.\n* [penalizedLDA](https://cran.r-project.org/web/packages/penalizedLDA/index.html) - penalizedLDA: Penalized classification using Fisher's linear discriminant. **[Deprecated]**\n* [penalizedSVM](https://cran.r-project.org/web/packages/penalizedSVM/index.html) - penalizedSVM: Feature Selection SVM using penalty functions.\n* [quantregForest](https://cran.r-project.org/web/packages/quantregForest/index.html) - quantregForest: Quantile Regression Forests.\n* [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) - randomForest: Breiman and Cutler's random forests for classification and regression.\n* [randomForestSRC](https://cran.r-project.org/web/packages/randomForestSRC/index.html) - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC).\n* [rattle](https://cran.r-project.org/web/packages/rattle/index.html) - rattle: Graphical user interface for data mining in R.\n* [rda](https://cran.r-project.org/web/packages/rda/index.html) - rda: Shrunken Centroids Regularized Discriminant Analysis.\n* [rdetools](https://cran.r-project.org/web/packages/rdetools/index.html) - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces. **[Deprecated]**\n* [REEMtree](https://cran.r-project.org/web/packages/REEMtree/index.html) - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data. **[Deprecated]**\n* [relaxo](https://cran.r-project.org/web/packages/relaxo/index.html) - relaxo: Relaxed Lasso. **[Deprecated]**\n* [rgenoud](https://cran.r-project.org/web/packages/rgenoud/index.html) - rgenoud: R version of GENetic Optimization Using Derivatives\n* [Rmalschains](https://cran.r-project.org/web/packages/Rmalschains/index.html) - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R.\n* [rminer](https://cran.r-project.org/web/packages/rminer/index.html) - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression. **[Deprecated]**\n* [ROCR](https://cran.r-project.org/web/packages/ROCR/index.html) - ROCR: Visualizing the performance of scoring classifiers. **[Deprecated]**\n* [RoughSets](https://cran.r-project.org/web/packages/RoughSets/index.html) - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories. **[Deprecated]**\n* [rpart](https://cran.r-project.org/web/packages/rpart/index.html) - rpart: Recursive Partitioning and Regression Trees.\n* [RPMM](https://cran.r-project.org/web/packages/RPMM/index.html) - RPMM: Recursively Partitioned Mixture Model.\n* [RSNNS](https://cran.r-project.org/web/packages/RSNNS/index.html) - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS).\n* [RWeka](https://cran.r-project.org/web/packages/RWeka/index.html) - RWeka: R/Weka interface.\n* [RXshrink](https://cran.r-project.org/web/packages/RXshrink/index.html) - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression.\n* [sda](https://cran.r-project.org/web/packages/sda/index.html) - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection. **[Deprecated]**\n* [spectralGraphTopology](https://cran.r-project.org/web/packages/spectralGraphTopology/index.html) - spectralGraphTopology: Learning Graphs from Data via Spectral Constraints.\n* [SuperLearner](https://github.com/ecpolley/SuperLearner) - Multi-algorithm ensemble learning packages.\n* [svmpath](https://cran.r-project.org/web/packages/svmpath/index.html) - svmpath: svmpath: the SVM Path algorithm. **[Deprecated]**\n* [tgp](https://cran.r-project.org/web/packages/tgp/index.html) - tgp: Bayesian treed Gaussian process models. **[Deprecated]**\n* [tree](https://cran.r-project.org/web/packages/tree/index.html) - tree: Classification and regression trees.\n* [varSelRF](https://cran.r-project.org/web/packages/varSelRF/index.html) - varSelRF: Variable selection using random forests.\n* [XGBoost.R](https://github.com/tqchen/xgboost/tree/master/R-package) - R binding for eXtreme Gradient Boosting (Tree) Library.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R.\n* [igraph](https://igraph.org/r/) - binding to igraph library - General purpose graph library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, JavaScript and more.\n* [TDSP-Utilities](https://github.com/Azure/Azure-TDSP-Utilities) - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modelling and Reporting (AMR).\n\n<a name=\"r-data-analysis--data-visualization\"></a>\n#### Data Manipulation | Data Analysis | Data Visualization\n\n* [data.table](https://rdatatable.gitlab.io/data.table/) - `data.table` provides a high-performance version of base R’s `data.frame` with syntax and feature enhancements for ease of use, convenience and programming speed.\n* [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) - A data manipulation package that helps to solve the most common data manipulation problems.\n* [ggplot2](https://ggplot2.tidyverse.org/) - A data visualization package based on the grammar of graphics.\n* [tmap](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html) for visualizing geospatial data with static maps and [leaflet](https://rstudio.github.io/leaflet/) for interactive maps\n* [tm](https://www.rdocumentation.org/packages/tm/) and [quanteda](https://quanteda.io/) are the main packages for managing,  analyzing, and visualizing textual data.\n* [shiny](https://shiny.rstudio.com/) is the basis for truly interactive displays and dashboards in R. However, some measure of interactivity can be achieved with [htmlwidgets](https://www.htmlwidgets.org/) bringing javascript libraries to R. These include, [plotly](https://plot.ly/r/), [dygraphs](http://rstudio.github.io/dygraphs), [highcharter](http://jkunst.com/highcharter/), and several others.\n\n<a name=\"sas\"></a>\n## SAS\n\n<a name=\"sas-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Visual Data Mining and Machine Learning](https://www.sas.com/en_us/software/visual-data-mining-machine-learning.html) - Interactive, automated, and programmatic modelling with the latest machine learning algorithms in and end-to-end analytics environment, from data prep to deployment. Free trial available.\n* [Enterprise Miner](https://www.sas.com/en_us/software/enterprise-miner.html) - Data mining and machine learning that creates deployable models using a GUI or code.\n* [Factory Miner](https://www.sas.com/en_us/software/factory-miner.html) - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI.\n\n<a name=\"sas-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [SAS/STAT](https://www.sas.com/en_us/software/stat.html) - For conducting advanced statistical analysis.\n* [University Edition](https://www.sas.com/en_us/software/university-edition.html) - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses.\n\n<a name=\"sas-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [Contextual Analysis](https://www.sas.com/en_us/software/contextual-analysis.html) - Add structure to unstructured text using a GUI.\n* [Sentiment Analysis](https://www.sas.com/en_us/software/sentiment-analysis.html) - Extract sentiment from text using a GUI.\n* [Text Miner](https://www.sas.com/en_us/software/text-miner.html) - Text mining using a GUI or code.\n\n<a name=\"sas-demos-and-scripts\"></a>\n#### Demos and Scripts\n\n* [ML_Tables](https://github.com/sassoftware/enlighten-apply/tree/master/ML_tables) - Concise cheat sheets containing machine learning best practices.\n* [enlighten-apply](https://github.com/sassoftware/enlighten-apply) - Example code and materials that illustrate applications of SAS machine learning techniques.\n* [enlighten-integration](https://github.com/sassoftware/enlighten-integration) - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R.\n* [enlighten-deep](https://github.com/sassoftware/enlighten-deep) - Example code and materials that illustrate using neural networks with several hidden layers in SAS.\n* [dm-flow](https://github.com/sassoftware/dm-flow) - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics.\n\n\n<a name=\"scala\"></a>\n## Scala\n\n<a name=\"scala-natural-language-processing\"></a>\n#### Natural Language Processing\n\n* [ScalaNLP](http://www.scalanlp.org/) - ScalaNLP is a suite of machine learning and numerical computing libraries.\n* [Breeze](https://github.com/scalanlp/breeze) - Breeze is a numerical processing library for Scala.\n* [Chalk](https://github.com/scalanlp/chalk) - Chalk is a natural language processing library. **[Deprecated]**\n* [FACTORIE](https://github.com/factorie/factorie) - FACTORIE is a toolkit for deployable probabilistic modelling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference.\n* [Montague](https://github.com/Workday/upshot-montague) - Montague is a semantic parsing library for Scala with an easy-to-use DSL.\n* [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) - Natural language processing library built on top of Apache Spark ML to provide simple, performant, and accurate NLP annotations for machine learning pipelines, that scale easily in a distributed environment.\n\n<a name=\"scala-data-analysis--data-visualization\"></a>\n#### Data Analysis / Data Visualization\n\n* [NDScala](https://github.com/SciScala/NDScala) - N-dimensional arrays in Scala 3. Think NumPy ndarray, but with compile-time type-checking/inference over shapes, tensor/axis labels & numeric data types\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Scalding](https://github.com/twitter/scalding) - A Scala API for Cascading.\n* [Summing Bird](https://github.com/twitter/summingbird) - Streaming MapReduce with Scalding and Storm.\n* [Algebird](https://github.com/twitter/algebird) - Abstract Algebra for Scala.\n* [xerial](https://github.com/xerial/xerial) - Data management utilities for Scala. **[Deprecated]**\n* [PredictionIO](https://github.com/apache/predictionio) - PredictionIO, a machine learning server for software developers and data engineers.\n* [BIDMat](https://github.com/BIDData/BIDMat) - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis.\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Spark Notebook](http://spark-notebook.io) - Interactive and Reactive Data Science using Scala and Spark.\n\n<a name=\"scala-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Microsoft ML for Apache Spark](https://github.com/Azure/mmlspark) -> A distributed machine learning framework Apache Spark\n* [ONNX-Scala](https://github.com/EmergentOrder/onnx-scala) - An ONNX (Open Neural Network eXchange) API and backend for typeful, functional deep learning in Scala (3).\n* [DeepLearning.scala](https://deeplearning.thoughtworks.school/) - Creating statically typed dynamic neural networks from object-oriented & functional programming constructs.\n* [Conjecture](https://github.com/etsy/Conjecture) - Scalable Machine Learning in Scalding.\n* [brushfire](https://github.com/stripe/brushfire) - Distributed decision tree ensemble learning in Scala.\n* [ganitha](https://github.com/tresata/ganitha) - Scalding powered machine learning. **[Deprecated]**\n* [adam](https://github.com/bigdatagenomics/adam) - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed.\n* [bioscala](https://github.com/bioscala/bioscala) - Bioinformatics for the Scala programming language\n* [BIDMach](https://github.com/BIDData/BIDMach) - CPU and GPU-accelerated Machine Learning Library.\n* [Figaro](https://github.com/p2t2/figaro) - a Scala library for constructing probabilistic models.\n* [H2O Sparkling Water](https://github.com/h2oai/sparkling-water) - H2O and Spark interoperability.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [DynaML](https://github.com/transcendent-ai-labs/DynaML) - Scala Library/REPL for Machine Learning Research.\n* [Saul](https://github.com/CogComp/saul) - Flexible Declarative Learning-Based Programming.\n* [SwiftLearner](https://github.com/valdanylchuk/swiftlearner/) - Simply written algorithms to help study ML or write your own implementations.\n* [Smile](https://haifengl.github.io/) - Statistical Machine Intelligence and Learning Engine.\n* [doddle-model](https://github.com/picnicml/doddle-model) - An in-memory machine learning library built on top of Breeze. It provides immutable objects and exposes its functionality through a scikit-learn-like API.\n* [TensorFlow Scala](https://github.com/eaplatanios/tensorflow_scala) - Strongly-typed Scala API for TensorFlow.\n* [isolation-forest](https://github.com/linkedin/isolation-forest) - A distributed Spark/Scala implementation of the isolation forest algorithm for unsupervised outlier detection, featuring support for scalable training and ONNX export for easy cross-platform inference.\n\n<a name=\"scheme\"></a>\n## Scheme\n\n<a name=\"scheme-neural-networks\"></a>\n#### Neural Networks\n\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line, implemented in [CHICKEN Scheme](https://www.call-cc.org/).\n\n<a name=\"swift\"></a>\n## Swift\n\n<a name=\"swift-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n\n* [Bender](https://github.com/xmartlabs/Bender) - Fast Neural Networks framework built on top of Metal. Supports TensorFlow models.\n* [Swift AI](https://github.com/Swift-AI/Swift-AI) - Highly optimized artificial intelligence and machine learning library written in Swift.\n* [Swift for Tensorflow](https://github.com/tensorflow/swift) - a next-generation platform for machine learning, incorporating the latest research across machine learning, compilers, differentiable programming, systems design, and beyond.\n* [BrainCore](https://github.com/alejandro-isaza/BrainCore) - The iOS and OS X neural network framework.\n* [swix](https://github.com/stsievert/swix) - A bare bones library that includes a general matrix language and wraps some OpenCV for iOS development. **[Deprecated]**\n* [AIToolbox](https://github.com/KevinCoble/AIToolbox) - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians.\n* [MLKit](https://github.com/Somnibyte/MLKit) - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression.\n* [Swift Brain](https://github.com/vlall/Swift-Brain) - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc...\n* [Perfect TensorFlow](https://github.com/PerfectlySoft/Perfect-TensorFlow) - Swift Language Bindings of TensorFlow. Using native TensorFlow models on both macOS / Linux.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder-swift) - A library for machine learning that builds predictions using a linear regression.\n* [Awesome CoreML](https://github.com/SwiftBrain/awesome-CoreML-models) - A curated list of pretrained CoreML models.\n* [Awesome Core ML Models](https://github.com/likedan/Awesome-CoreML-Models) - A curated list of machine learning models in CoreML format.\n\n<a name=\"tensorflow\"></a>\n## TensorFlow\n\n<a name=\"tensorflow-general-purpose-machine-learning\"></a>\n#### General-Purpose Machine Learning\n* [Awesome Keras](https://github.com/markusschanta/awesome-keras) - A curated list of awesome Keras projects, libraries and resources.\n* [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow) - A list of all things related to TensorFlow.\n* [Golden TensorFlow](https://golden.com/wiki/TensorFlow) - A page of content on TensorFlow, including academic papers and links to related topics.\n\n<a name=\"tools\"></a>\n## Tools\n\n<a name=\"tools-neural-networks\"></a>\n#### Neural Networks\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line\n\n<a name=\"tools-misc\"></a>\n#### Misc\n\n* [Wallaroo.AI](https://wallaroo.ai/) - Production AI plaftorm for deploying, managing, and observing any model at scale across any environment from cloud to edge. Let's go from python notebook to inferencing in minutes. \n* [Infinity](https://github.com/infiniflow/infinity) - The AI-native database built for LLM applications, providing incredibly fast vector and full-text search. Developed using C++20\n* [Synthical](https://synthical.com) - AI-powered collaborative research environment. You can use it to get recommendations of articles based on reading history, simplify papers, find out what articles are trending, search articles by meaning (not just keywords), create and share folders of articles, see lists of articles from specific companies and universities, and add highlights.\n* [Humanloop](https://humanloop.com) – Humanloop is a platform for prompt experimentation, finetuning models for better performance, cost optimization, and collecting model generated data and user feedback.\n* [Qdrant](https://qdrant.tech) – Qdrant is [open source](https://github.com/qdrant/qdrant) vector similarity search engine with extended filtering support, written in Rust.\n* [milvus](https://milvus.io) – Milvus is [open source](https://github.com/milvus-io/milvus) vector database for production AI, written in Go and C++, scalable and blazing fast for billions of embedding vectors.\n* [Weaviate](https://www.semi.technology/developers/weaviate/current/) – Weaviate is an [open source](https://github.com/semi-technologies/weaviate) vector search engine and vector database. Weaviate uses machine learning to vectorize and store data, and to find answers to natural language queries. With Weaviate you can also bring your custom ML models to production scale.\n* [txtai](https://github.com/neuml/txtai) - Build semantic search applications and workflows.\n* [MLReef](https://about.mlreef.com/) - MLReef is an end-to-end development platform using the power of git to give structure and deep collaboration possibilities to the ML development process.\n* [Chroma](https://www.trychroma.com/) - Chroma - the AI-native open-source embedding database\n* [Pinecone](https://www.pinecone.io/) - Vector database for applications that require real-time, scalable vector embedding and similarity search.\n* [CatalyzeX](https://chrome.google.com/webstore/detail/code-finder-for-research/aikkeehnlfpamidigaffhfmgbkdeheil) - Browser extension ([Chrome](https://chrome.google.com/webstore/detail/code-finder-for-research/aikkeehnlfpamidigaffhfmgbkdeheil) and [Firefox](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/)) that automatically finds and shows code implementations for machine learning papers anywhere: Google, Twitter, Arxiv, Scholar, etc.\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) - All-in-one web-based IDE for machine learning and data science. The workspace is deployed as a docker container and is preloaded with a variety of popular data science libraries (e.g., Tensorflow, PyTorch) and dev tools (e.g., Jupyter, VS Code).\n* [Notebooks](https://github.com/rlan/notebooks) - A starter kit for Jupyter notebooks and machine learning. Companion docker images consist of all combinations of python versions, machine learning frameworks (Keras, PyTorch and Tensorflow) and CPU/CUDA versions.\n* [DVC](https://github.com/iterative/dvc) - Data Science Version Control is an open-source version control system for machine learning projects with pipelines support. It makes ML projects reproducible and shareable.\n* [DVClive](https://github.com/iterative/dvclive) - Python library for experiment metrics logging into simply formatted local files.\n* [VDP](https://github.com/instill-ai/vdp) - open source visual data ETL to streamline the end-to-end visual data processing pipeline: extract unstructured visual data from pre-built data sources, transform it into analysable structured insights by Vision AI models imported from various ML platforms, and load the insights into warehouses or applications.\n* [Kedro](https://github.com/quantumblacklabs/kedro/) - Kedro is a data and development workflow framework that implements best practices for data pipelines with an eye towards productionizing machine learning models.\n* [Hamilton](https://github.com/dagworks-inc/hamilton) - a lightweight library to define data transformations as a directed-acyclic graph (DAG). It helps author reliable feature engineering and machine learning pipelines, and more.\n* [guild.ai](https://guild.ai/) - Tool to log, analyze, compare and \"optimize\" experiments. It's cross-platform and framework independent, and provided integrated visualizers such as tensorboard.\n* [Sacred](https://github.com/IDSIA/sacred) - Python tool to help  you configure, organize, log and reproduce experiments. Like a notebook lab in the context of Chemistry/Biology. The community has built multiple add-ons leveraging the proposed standard.\n* [Comet](https://www.comet.com/) -  ML platform for tracking experiments, hyper-parameters, artifacts and more. It's deeply integrated with over 15+ deep learning frameworks and orchestration tools. Users can also use the platform to monitor their models in production.\n* [MLFlow](https://mlflow.org/) - platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. Framework and language agnostic, take a look at all the built-in integrations.\n* [Weights & Biases](https://www.wandb.com/) - Machine learning experiment tracking, dataset versioning, hyperparameter search, visualization, and collaboration\n* More tools to improve the ML lifecycle: [Catalyst](https://github.com/catalyst-team/catalyst), [PachydermIO](https://www.pachyderm.io/). The following are GitHub-alike and targeting teams [Weights & Biases](https://www.wandb.com/), [Neptune.ai](https://neptune.ai/), [Comet.ml](https://www.comet.ml/), [Valohai.ai](https://valohai.com/), [DAGsHub](https://DAGsHub.com/).\n* [Arize AI](https://www.arize.com) - Model validation and performance monitoring, drift detection, explainability, visualization across structured and unstructured data\n* [MachineLearningWithTensorFlow2ed](https://www.manning.com/books/machine-learning-with-tensorflow-second-edition) - a book on general purpose machine learning techniques regression, classification, unsupervised clustering, reinforcement learning, auto encoders, convolutional neural networks, RNNs, LSTMs, using TensorFlow 1.14.1.\n* [m2cgen](https://github.com/BayesWitnesses/m2cgen) - A tool that allows the conversion of ML models into native code (Java, C, Python, Go, JavaScript, Visual Basic, C#, R, PowerShell, PHP, Dart) with zero dependencies.\n* [CML](https://github.com/iterative/cml) - A library for doing continuous integration with ML projects. Use GitHub Actions & GitLab CI to train and evaluate models in production like environments and automatically generate visual reports with metrics and graphs in pull/merge requests. Framework & language agnostic.\n* [Pythonizr](https://pythonizr.com) - An online tool to generate boilerplate machine learning code that uses scikit-learn.\n* [Flyte](https://flyte.org/) - Flyte makes it easy to create concurrent, scalable, and maintainable workflows for machine learning and data processing.\n* [Chaos Genius](https://github.com/chaos-genius/chaos_genius/) - ML powered analytics engine for outlier/anomaly detection and root cause analysis.\n* [MLEM](https://github.com/iterative/mlem) - Version and deploy your ML models following GitOps principles\n* [DockerDL](https://github.com/matifali/dockerdl) - Ready to use deeplearning docker images.\n* [Aqueduct](https://github.com/aqueducthq/aqueduct) - Aqueduct enables you to easily define, run, and manage AI & ML tasks on any cloud infrastructure.\n* [Ambrosia](https://github.com/reactorsh/ambrosia) - Ambrosia helps you clean up your LLM datasets using _other_ LLMs.\n\n<a name=\"books\"></a>\n## Books\n\n* [Distributed Machine Learning Patterns](https://github.com/terrytangyuan/distributed-ml-patterns)  - This book teaches you how to take machine learning models from your personal laptop to large distributed clusters. You’ll explore key concepts and patterns behind successful distributed machine learning systems, and learn technologies like TensorFlow, Kubernetes, Kubeflow, and Argo Workflows directly from a key maintainer and contributor, with real-world scenarios and hands-on projects.\n* [Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning) - Grokking Machine Learning teaches you how to apply ML to your projects using only standard Python code and high school-level math.\n* [Machine Learning Bookcamp](https://www.manning.com/books/machine-learning-bookcamp) - Learn the essentials of machine learning by completing a carefully designed set of real-world projects.\n* [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1098125975) - Through a recent series of breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This bestselling book uses concrete examples, minimal theory, and production-ready Python frameworks (Scikit-Learn, Keras, and TensorFlow) to help you gain an intuitive understanding of the concepts and tools for building intelligent systems.\n\n\n<a name=\"credits\"></a>\n* [Netron](https://netron.app/) - An opensource viewer for neural network, deep learning and machine learning models\n* [Teachable Machine](https://teachablemachine.withgoogle.com/) - Train Machine Learning models on the fly to recognize your own images, sounds, & poses.\n* [Model Zoo](https://modelzoo.co/) - Discover open source deep learning code and pretrained models.\n\n## Credits\n\n* Some of the python libraries were cut-and-pasted from [vinta](https://github.com/vinta/awesome-python)\n* References for Go were mostly cut-and-pasted from [gopherdata](https://github.com/gopherdata/resources/tree/master/tooling)\n"
        },
        {
          "name": "blogs.md",
          "type": "blob",
          "size": 3.69,
          "content": "Blogs/Podcasts\n===============\n\n* [Hacker News for Data Science](https://www.datatau.com/news)\n* [LightTag's Labeled Data Blog](https://lighttag.io/blog)\n* [Freecodecamp articles](https://www.freecodecamp.org/news/tag/machine-learning/)\n* [Fennel Blog](https://fennel.ai/blog/)\n\nPodcasts\n--------\n\n* [The O'Reilly Data Show](http://radar.oreilly.com/tag/oreilly-data-show-podcast)\n* [Partially Derivative](http://partiallyderivative.com/)\n* [The Talking Machines](https://www.thetalkingmachines.com/)\n* [The Data Skeptic](https://dataskeptic.com/)\n* [Linear Digressions](https://lineardigressions.com)\n* [Data Stories](http://datastori.es/)\n* [Learning Machines 101](https://www.learningmachines101.com/)\n* [TWIMLAI](https://twimlai.com/shows/)\n* [Machine Learning Guide](http://ocdevel.com/podcasts/machine-learning)\n* [DataTalks.Club](https://anchor.fm/datatalksclub)\n* [Super Data Science Podcast with Jon Krohn](https://www.youtube.com/@SuperDataScienceWithJonKrohn)\n\nNewsletters\n-----------\n\n* [AI Digest](https://aidigest.net/). A weekly newsletter to keep up to date with AI, machine learning, and data science. [Archive](https://aidigest.net/digests).\n* [DataTalks.Club](https://datatalks.club). A weekly newsletter about data-related things. [Archive](https://us19.campaign-archive.com/home/?u=0d7822ab98152f5afc118c176&id=97178021aa)\n* [The Batch](https://read.deeplearning.ai/the-batch/) Andrew Ng's weekly AI newsletter for engineers, executives, and enthusiasts including updates on recent AI research developments.\n* [BuzzRobot AI Newsletter](https://buzzrobot.substack.com/). Exclusive talks by top researchers on cutting-edge artificial intelligence papers.\n* [Air Around AI](https://airaroundai.substack.com/). Air Around AI is a weekly newsletter of the top news, best tutorials, product launches and super tips on AI, for leaders and changemakers.\n\nPractice Questions\n-----------\n\n* [bnomial](https://today.bnomial.com/). Solve one Machine Learning questions daily and win exciting prizes.\n\nData Science / Statistics\n-------------------------\n\n* https://blog.dominodatalab.com\n* https://ahmedbesbes.com/\n* https://jeremykun.com/\n* https://iamtrask.github.io/\n* https://blog.explainmydata.com/\n* https://statmodeling.stat.columbia.edu\n* https://simplystatistics.org/\n* https://www.evanmiller.org/\n* https://jakevdp.github.io/\n* http://wesmckinney.com\n* https://www.overkillanalytics.net/\n* https://newton.cx/~peter/\n* https://mbakker7.github.io/exploratory_computing_with_python/\n* https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/\n* https://colah.github.io/\n* https://sebastianraschka.com/\n* http://dogdogfish.com/\n* https://www.johnmyleswhite.com/\n* http://drewconway.com/zia/\n* https://bugra.github.io/\n* http://opendata.cern.ch/\n* https://alexanderetz.com/\n* http://www.sumsar.net/\n* https://www.countbayesie.com\n* https://karpathy.github.io/  https://medium.com/@karpathy\n* http://blog.kaggle.com/\n* https://www.danvk.org/\n* http://hunch.net/\n* http://www.randalolson.com/blog/\n* https://www.johndcook.com/blog/r_language_for_programmers/\n* https://www.dataschool.io/\n* https://www.datasciencecentral.com\n* https://mubaris.com\n* https://distill.pub\n* http://blog.shakirm.com/\n* https://www.cs.ox.ac.uk/people/yarin.gal/website/blog.html\n* [LightTag NLP Blog](https://www.lighttag.io/blog)\n* https://datatalks.club/articles.html\n* https://www.nbshare.io/notebooks/data-science/\n\nMath\n----\n\n* https://www.allendowney.com/blog/\n* https://healthyalgorithms.com/\n* https://petewarden.com/\n* https://blog.mrtz.org\n* https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/videos\n* https://www.youtube.com/channel/UCr22xikWUK2yUW4YxOKXclQ/videos\n\nSecurity Related\n----------------\n\n* https://jordan-wright.com/blog/\n"
        },
        {
          "name": "books.md",
          "type": "blob",
          "size": 16.49,
          "content": "The following is a list of free and/or open source books on machine learning, statistics, data mining, etc.\n\n## Machine Learning / Data Mining\n\n* [Distributed Machine Learning Patterns](https://github.com/terrytangyuan/distributed-ml-patterns)  - Book (free to read online) + Code\n* [The Hundred-Page Machine Learning Book](http://themlbook.com/wiki/doku.php)\n* [Real World Machine Learning](https://www.manning.com/books/real-world-machine-learning) [Free Chapters]\n* [An Introduction To Statistical Learning With Applications In R](https://drive.usercontent.google.com/download?id=106d-rN7cXpyAkgrUqjcPONNCyO-rX7MQ&export=download) - Book + R Code\n* [An Introduction To Statistical Learning With Applications In Python](https://drive.usercontent.google.com/download?id=1ajFkHO6zjrdGNqhqW1jKBZdiNGh_8YQ1&export=download) - Book + Python Code\n* [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) - Book\n* [Computer Age Statistical Inference (CASI)](https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf) ([Permalink as of October 2017](https://perma.cc/J8JG-ZVFW)) - Book\n* [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) - Book + IPython Notebooks\n* [Think Bayes](https://greenteapress.com/wp/think-bayes/) - Book + Python Code\n* [Information Theory, Inference, and Learning Algorithms](http://www.inference.phy.cam.ac.uk/mackay/itila/book.html)\n* [Gaussian Processes for Machine Learning](http://www.gaussianprocess.org/gpml/chapters/)\n* [Data Intensive Text Processing w/ MapReduce](https://lintool.github.io/MapReduceAlgorithms/)\n* [Reinforcement Learning: - An Introduction](http://incompleteideas.net/book/the-book-2nd.html) ([Permalink to Nov 2017 Draft](https://perma.cc/83ER-64M3))\n* [Mining Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/book.pdf)\n* [A First Encounter with Machine Learning](https://www.ics.uci.edu/~welling/teaching/273ASpring10/IntroMLBook.pdf)\n* [Pattern Recognition and Machine Learning](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)\n* [Machine Learning & Bayesian Reasoning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf)\n* [Introduction to Machine Learning](https://alex.smola.org/drafts/thebook.pdf) - Alex Smola and S.V.N. Vishwanathan\n* [A Probabilistic Theory of Pattern Recognition](https://www.szit.bme.hu/~gyorfi/pbook.pdf)\n* [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf)\n* [Forecasting: principles and practice](https://otexts.com/fpp2/)\n* [Practical Artificial Intelligence Programming in Java](https://www.saylor.org/site/wp-content/uploads/2011/11/CS405-1.1-WATSON.pdf)\n* [Introduction to Machine Learning](https://arxiv.org/pdf/0904.3664v1.pdf) - Amnon Shashua\n* [Reinforcement Learning](https://www.intechopen.com/books/reinforcement_learning)\n* [Machine Learning](https://www.intechopen.com/books/machine_learning)\n* [A Quest for AI](https://ai.stanford.edu/~nilsson/QAI/qai.pdf)\n* [Introduction to Applied Bayesian Statistics and Estimation for Social Scientists](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.177.857&rep=rep1&type=pdf) - Scott M. Lynch\n* [Bayesian Modeling, Inference and Prediction](https://users.soe.ucsc.edu/~draper/draper-BMIP-dec2005.pdf)\n* [A Course in Machine Learning](http://ciml.info/)\n* [Machine Learning, Neural and Statistical Classification](https://www1.maths.leeds.ac.uk/~charles/statlog/)\n* [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage) Book+MatlabToolBox\n* [R Programming for Data Science](https://leanpub.com/rprogramming)\n* [Data Mining - Practical Machine Learning Tools and Techniques](https://cdn.preterhuman.net/texts/science_and_technology/artificial_intelligence/Data%20Mining%20Practical%20Machine%20Learning%20Tools%20and%20Techniques%202d%20ed%20-%20Morgan%20Kaufmann.pdf) Book\n* [Machine Learning with TensorFlow](https://www.manning.com/books/machine-learning-with-tensorflow) Early book access\n* [Machine Learning Systems](https://www.manning.com/books/machine-learning-systems) Early book access\n* [Hands‑On Machine Learning with Scikit‑Learn and TensorFlow](http://index-of.es/Varios-2/Hands%20on%20Machine%20Learning%20with%20Scikit%20Learn%20and%20Tensorflow.pdf) - Aurélien Géron\n* [R for Data Science: Import, Tidy, Transform, Visualize, and Model Data](https://r4ds.had.co.nz/) - Wickham and Grolemund. Great introduction on how to use R language. \n* [Advanced R](http://adv-r.had.co.nz/) - Hadley Wickham. More advanced usage of R for programming.\n* [Graph-Powered Machine Learning](https://www.manning.com/books/graph-powered-machine-learning) - Alessandro Negro. Combining graph theory and models to improve machine learning projects.\n* [Machine Learning for Dummies](https://mscdss.ds.unipi.gr/wp-content/uploads/2018/02/Untitled-attachment-00056-2-1.pdf)\n* [Machine Learning for Mortals (Mere and Otherwise)](https://www.manning.com/books/machine-learning-for-mortals-mere-and-otherwise) - Early access book that provides basics of machine learning and using R programming language.\n* [Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning) - Early access book that introduces the most valuable machine learning techniques.\n- [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/) - Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar\n- [Understanding Machine Learning](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - Shai Shalev-Shwartz and Shai Ben-David\n- [Fighting Churn With Data](https://www.manning.com/books/fighting-churn-with-data)  [Free Chapter] Carl Gold - Hands on course in applied data science in Python and SQL, taught through the use case of customer churn.\n- [Machine Learning Bookcamp](https://www.manning.com/books/machine-learning-bookcamp) - Alexey Grigorev - a project-based approach on learning machine learning (early access).\n- [AI Summer](https://theaisummer.com/) A blog to help you learn Deep Learning an Artificial Intelligence\n- [Mathematics for Machine Learning](https://mml-book.github.io/)\n- [Approaching Almost any Machine learning problem Abhishek Thakur](https://github.com/abhishekkrthakur/approachingalmost)\n- [MLOps Engineering at Scale](https://www.manning.com/books/mlops-engineering-at-scale) - Carl Osipov - Guide to bringing your experimental machine learning code to production using serverless capabilities from major cloud providers.\n- [AI-Powered Search](https://www.manning.com/books/ai-powered-search) - Trey Grainger, Doug Turnbull, Max Irwin - Early access book that teaches you how to build search engines that automatically understand the intention of a query in order to deliver significantly better results.\n- [Ensemble Methods for Machine Learning](https://www.manning.com/books/ensemble-methods-for-machine-learning) - Gautam Kunapuli - Early access book that teaches you to implement the most important ensemble machine learning methods from scratch.\n- [Machine Learning Engineering in Action](https://www.manning.com/books/machine-learning-engineering-in-action) - Ben Wilson - Field-tested tips, tricks, and design patterns for building Machine Learning projects that are deployable, maintainable, and secure from concept to production.\n- [Privacy-Preserving Machine Learning](https://www.manning.com/books/privacy-preserving-machine-learning) - J. Morris Chang, Di Zhuang, G. Dumindu Samaraweera - Keep sensitive user data safe and secure, without sacrificing the accuracy of your machine learning models.\n- [Automated Machine Learning in Action](https://www.manning.com/books/automated-machine-learning-in-action) - Qingquan Song, Haifeng Jin, and Xia Hu - Optimize every stage of your machine learning pipelines with powerful automation components and cutting-edge tools like AutoKeras and Keras Tuner.\n- [Distributed Machine Learning Patterns](https://www.manning.com/books/distributed-machine-learning-patterns) - Yuan Tang - Practical patterns for scaling machine learning from your laptop to a distributed cluster.\n- [Human-in-the-Loop Machine Learning: Active learning and annotation for human-centered AI](https://www.manning.com/books/human-in-the-loop-machine-learning) - Robert (Munro) Monarch - a practical guide to optimizing the entire machine learning process, including techniques for annotation, active learning, transfer learning, and using machine learning to optimize every step of the process.\n- [Feature Engineering Bookcamp](https://www.manning.com/books/feature-engineering-bookcamp) - Maurucio Aniche - This book’s practical case-studies reveal feature engineering techniques that upgrade your data wrangling—and your ML results.\n- [Metalearning: Applications to Automated Machine Learning and Data Mining](https://link.springer.com/content/pdf/10.1007/978-3-030-67024-5.pdf) - Pavel Brazdil, Jan N. van Rijn, Carlos Soares, Joaquin Vanschoren\n- [Managing Machine Learning Projects: From design to deployment](https://www.manning.com/books/managing-machine-learning-projects) - Simon Thompson\n- [Causal AI](https://www.manning.com/books/causal-machine-learning) - Robert Ness - Practical introduction to building AI models that can reason about causality.\n- [Bayesian Optimization in Action](https://www.manning.com/books/bayesian-optimization-in-action) - Quan Nguyen - Book about building Bayesian optimization systems from the ground up.\n- [Machine Learning Algorithms in Depth](https://www.manning.com/books/machine-learning-algorithms-in-depth) - Vadim Smolyakov - Book about practical implementations of dozens of ML algorithms.\n- [Optimization Algorithms](https://www.manning.com/books/optimization-algorithms) - Alaa Khamis - Book about how to solve design, planning, and control problems using modern machine learning and AI techniques.\n- [Practical Gradient Boosting](https://www.amazon.com/dp/B0BL1HRD6Z) by Guillaume Saupin\n- [Machine Learning System Design](https://www.manning.com/books/machine-learning-system-design) - Valerii Babushkin and Arseny Kravchenko - A book about planning and designing successful ML applications.\n- [Fight Fraud with Machine Learning](https://www.manning.com/books/fight-fraud-with-machine-learning) - by Ashish Ranjan Jha - A book about developing scalable and tunable models that can spot and stop fraudulent activity.\n- [Machine Learning for Drug Discovery](https://www.manning.com/books/machine-learning-for-drug-discovery) - by Noah Flynn - A book that introduces the machine learning and deep learning techniques that drive modern medical research.\n\n## Deep Learning\n\n* [Deep Learning - An MIT Press book](https://www.deeplearningbook.org/)\n* [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)\n* [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition) Early access book\n* [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition) Early access book\n* [Deep Learning with JavaScript](https://www.manning.com/books/deep-learning-with-javascript) Early access book\n* [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) Early access book\n* [Deep Learning for Search](https://www.manning.com/books/deep-learning-for-search) Early access book\n* [Deep Learning and the Game of Go](https://www.manning.com/books/deep-learning-and-the-game-of-go) Early access book\n* [Machine Learning for Business](https://www.manning.com/books/machine-learning-for-business) Early access book\n* [Probabilistic Deep Learning with Python](https://www.manning.com/books/probabilistic-deep-learning-with-python) Early access book\n* [Deep Learning with Structured Data](https://www.manning.com/books/deep-learning-with-structured-data) Early access book\n* [Deep Learning](https://www.deeplearningbook.org/)[Ian Goodfellow, Yoshua Bengio and Aaron Courville]\n* [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition) \n* [Inside Deep Learning](https://www.manning.com/books/inside-deep-learning) Early access book\n* [Math and Architectures of Deep Learning](https://www.manning.com/books/math-and-architectures-of-deep-learning) Early access book\n* [Deep Learning for Natural Lanuage Processing](https://www.manning.com/books/deep-learning-for-natural-language-processing) Early access book\n\n## Natural Language Processing\n\n* [Coursera Course Book on NLP](http://www.cs.columbia.edu/~mcollins/notes-spring2013.html)\n* [NLTK](https://www.nltk.org/book/)\n* [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/promo/)\n* [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action) Early access book\n* [Natural Language Processing in Action, Second Edition](https://www.manning.com/books/natural-language-processing-in-action-second-edition) Early access book\n* [Real-World Natural Language Processing](https://www.manning.com/books/real-world-natural-language-processing) Early access book\n* [Essential Natural Language Processing](https://www.manning.com/books/essential-natural-language-processing) Early access book\n* [Deep Learning for Natural Lanuage Processing](https://www.manning.com/books/deep-learning-for-natural-language-processing) Early access book\n* [Natural Language Processing in Action, Second Edition](https://www.manning.com/books/natural-language-processing-in-action-second-edition) Early access book\n* [Getting Started with Natural Language Processing in Action](https://www.manning.com/books/getting-started-with-natural-language-processing) Early access book\n* [Transfer Learnin for Natural Language Processing](https://www.manning.com/books/transfer-learning-for-natural-language-processing) by Paul Azunre\n\n\n## Information Retrieval\n\n* [An Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf)\n\n## Neural Networks\n\n* [A Brief Introduction to Neural Networks](http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf)\n* [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)\n* [Graph Neural Networks in Action](https://www.manning.com/books/graph-neural-networks-in-action)\n\n## Probability & Statistics\n\n* [Think Stats](https://www.greenteapress.com/thinkstats/) - Book + Python Code\n* [From Algorithms to Z-Scores](http://heather.cs.ucdavis.edu/probstatbook) - Book\n* [The Art of R Programming](http://heather.cs.ucdavis.edu/~matloff/132/NSPpart.pdf) - Book (Not Finished)\n* [Introduction to statistical thought](https://people.math.umass.edu/~lavine/Book/book.pdf)\n* [Basic Probability Theory](https://www.math.uiuc.edu/~r-ash/BPT/BPT.pdf)\n* [Introduction to probability](https://math.dartmouth.edu/~prob/prob/prob.pdf) - By Dartmouth College\n* [Probability & Statistics Cookbook](http://statistics.zone/)\n* [Introduction to Probability](http://athenasc.com/probbook.html) -  Book and course by MIT\n* [The Elements of Statistical Learning: Data Mining, Inference, and Prediction.](https://web.stanford.edu/~hastie/ElemStatLearn/) - Book\n* [An Introduction to Statistical Learning with Applications in R](https://www-bcf.usc.edu/~gareth/ISL/) - Book\n* [Introduction to Probability and Statistics Using R](http://ipsur.r-forge.r-project.org/book/download/IPSUR.pdf) - Book\n* [Advanced R Programming](http://adv-r.had.co.nz) - Book\n* [Practical Regression and Anova using R](https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf) - Book\n* [R practicals](http://www.columbia.edu/~cjd11/charles_dimaggio/DIRE/resources/R/practicalsBookNoAns.pdf) - Book\n* [The R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf) - Book\n* [Probability Theory: The Logic of Science](https://bayes.wustl.edu/etj/prob/book.pdf) - By Jaynes\n\n## Linear Algebra\n\n* [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)\n* [Linear Algebra by Shilov](https://cosmathclub.files.wordpress.com/2014/10/georgi-shilov-linear-algebra4.pdf)\n* [Linear Algebra Done Wrong](https://www.math.brown.edu/~treil/papers/LADW/LADW.html)\n* [Linear Algebra, Theory, and Applications](https://math.byu.edu/~klkuttle/Linearalgebra.pdf)\n* [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)\n* [Applied Numerical Computing](https://www.seas.ucla.edu/~vandenbe/ee133a.html)\n\n## Calculus\n\n* [Calculus Made Easy](https://github.com/lahorekid/Calculus/blob/master/Calculus%20Made%20Easy.pdf)\n* [calculus by ron larson](https://www.pdfdrive.com/calculus-e183995561.html)\n* [Active Calculus by Matt Boelkins](https://scholarworks.gvsu.edu/books/20/)\n"
        },
        {
          "name": "courses.md",
          "type": "blob",
          "size": 8.98,
          "content": "The following is a list of free or paid online courses on machine learning, statistics, data-mining, etc.\n\n## Machine-Learning / Data Mining\n\n* [Artificial Intelligence (Columbia University)](https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0) - free\n* [Machine Learning (Columbia University)](https://www.edx.org/course/machine-learning-columbiax-csmm-102x-0) - free\n* [Machine Learning (Stanford University)](https://www.coursera.org/learn/machine-learning) - free\n* [Deep Learning Specialization (by Andrew Ng, deeplearning.ai)](https://www.coursera.org/specializations/deep-learning) - Courses: I Neural Networks and Deep Learning; II Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization; III Structuring Machine Learning Projects; IV Convolutional Neural Networks; V Sequence Models; Paid for grading/certification, financial aid available, free to audit\n* [Deep Learning Nano Degree on Udacity](https://www.udacity.com/course/deep-learning-nanodegree--nd101) - $\n* [Intro to Deep Learning (MIT)](http://introtodeeplearning.com/)\n* [Stanford's CS20 Tensorflow for Deep Learning Research](http://web.stanford.edu/class/cs20si/)\n* [fast.ai](https://www.fast.ai/) - deep learning MOOC\n* [Full-Stack Deep Learning](https://fullstackdeeplearning.com/) \n* [Amazon's MLU-Explain](https://mlu-explain.github.io/) - Visual, Interactive Explanations of Core Machine Learning Concepts\n* [Machine Learning Specialization (University of Washington)](https://www.coursera.org/specializations/machine-learning) - Courses: Machine Learning Foundations: A Case Study Approach, Machine Learning: Regression, Machine Learning: Classification, Machine Learning: Clustering & Retrieval, Machine Learning: Recommender Systems & Dimensionality Reduction,Machine Learning Capstone: An Intelligent Application with Deep Learning; free\n* [Machine Learning Course (2014-15 session) (by Nando de Freitas, University of Oxford)](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/) - Lecture slides and video recordings.\n* [Learning from Data (by Yaser S. Abu-Mostafa, Caltech)](http://www.work.caltech.edu/telecourse.html) - Lecture videos available\n* [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) - free\n* [Probabilistic Graphical Models (by Prof. Daphne Koller, Stanford)](https://www.coursera.org/specializations/probabilistic-graphical-models) Coursera Specialization\n* [Reinforcement Learning Course (by David Silver, DeepMind)](https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-) - YouTube playlist and [lecture slides](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html).\n* [Keras in Motion](https://www.manning.com/livevideo/keras-in-motion) $\n* [Stanford's CS231n: CNNs for Visual Recognition](https://www.youtube.com/watch?v=vT1JzLTH4G4&index=1&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) - Spring 2017 iteration, instructors (Fei-Fei Li, Justin Johnson, Serena Yeung), or [Winter 2016 edition](https://www.youtube.com/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) instructors (Fei-Fei Li, Andrej Karpathy, Justin Johnson). [Course website](http://cs231n.github.io/) has supporting material.\n* [University of California, Berkeley's CS294: Deep Reinforcement Learning](https://www.youtube.com/watch?v=8jQIKgTzQd4&list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX) - Fall 2017 edition. [Course website](http://rll.berkeley.edu/deeprlcourse/) has lecture slides and other related material.\n* [Machine Learning (Georgia Tech) on Udacity](https://www.udacity.com/course/machine-learning--ud262) - free\n* [Reinforcement Learning (Georgia Tech) on Udacity ](https://www.udacity.com/course/reinforcement-learning--ud600) - free\n* [Machine Learning for Trading](https://www.udacity.com/course/machine-learning-for-trading--ud501) - free\n* [Mining of Massive Datasets](https://www.youtube.com/watch?v=xoA5v9AO7S0&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV) (YouTube playlist) - Course [website](http://mmds.org/) has info about accompanying book, free chapters, and Stanford's [MOOC](https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about)\n* [Machine Learning Crash Course (Google)](https://developers.google.com/machine-learning/crash-course/) - free\n* [Machine Learning Mini Bootcamp Course (LambdaSchool)](https://lambdaschool.com/courses/data-science/intro/) - free and $\n* [Microsoft Professional Program for Artificial Intelligence](https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/) - free \n* [Open Machine Learning Course](https://github.com/Yorko/mlcourse.ai) with [articles](https://medium.com/open-machine-learning-course) on Medium \n* [Machine Learning A-Z (Udemy)](https://www.udemy.com/machinelearning/) - Hands-On Python & R In Data Science\n* [Deep Learning Crash Course](https://www.manning.com/livevideo/deep-learning-crash-course) - $\n* [Reinforcement Learning in Motion](https://www.manning.com/livevideo/reinforcement-learning-in-motion) - $\n* [Udemy A-Z Machine learning course](https://www.udemy.com/course/machinelearning/) - $\n* [Statistics and Probability-Khan Academy](https://www.khanacademy.org/math/statistics-probability) - free\n* [Math and Architectures of Deep Learning](https://www.manning.com/books/math-and-architectures-of-deep-learning) - $\n* [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition) - $\n* [Transfer Learning for Natural Language Processing](https://www.manning.com/books/transfer-learning-for-natural-language-processing) - $\n* [Grokking Artificial Intelligence Algorithms](https://www.manning.com/books/grokking-artificial-intelligence-algorithms) - $\n* [Learn ML from experts at Google](https://ai.google/education/) - free\n* [Kaggle courses on ML,AI and DS(certificate)](https://www.kaggle.com/learn/overview) - free\n* [Ml with python(Cognitive classes)](https://cognitiveclass.ai/courses/machine-learning-with-python) - free\n* [Intro to Data science(Cognitive classes)](https://cognitiveclass.ai/courses/data-science-101) - free\n* [Machine Learning for Business](https://www.manning.com/books/machine-learning-for-business) - $\n* [Transfer Learning for Natural Language Processing](https://www.manning.com/books/transfer-learning-for-natural-language-processing) - $\n* [In-depth introduction to machine learning in 15 hours of expert videos (by Prof. Trevor Hastie, Prof. Rob Tibshirani, Stanford)](https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/) - free\n* [Data Scientist in Python (Dataquest)](https://www.dataquest.io/path/data-scientist/) - free and $\n* [AI Expert Roadmap - Roadmap to becoming an Artificial Intelligence Expert](https://github.com/AMAI-GmbH/AI-Expert-Roadmap) - free\n* [Semi-Supervised Deep Learning with GANs for Melanoma Detection](https://www.manning.com/liveproject/semi-supervised-deep-learning-with-gans-for-melanoma-detection) - $\n* [Interpretable AI](https://www.manning.com/books/interpretable-ai) - $\n* [Deploying a Deep Learning Model on Web and Mobile Applications Using TensorFlow](https://www.manning.com/liveproject/deploying-a-deep-learning-model-on-web-and-mobile-applications-using-tensorflow) - $ Hands-on project\n* [Complete Data Science and ML Course](https://www.scaler.com/data-science-course/) - $\n* [ML Observability Fundamentals](https://arize.com/ml-observability-fundamentals/) - free\n* [Introduction to Data-Centric AI (MIT)](https://dcai.csail.mit.edu/) - free\n* [Data science course with placement](https://brainalyst.in/data-science-course-placement-guarantee)\n* [DATA VISUALIZATION COURSE](https://brainalyst.in/data-visualization-courses-online/)\n* [DATA VISUALIZATION PYTHON COURSE](https://brainalyst.in/data-visualization-python/)\n* [DATA SCIENCE WITH R PROGRAMMING](https://brainalyst.in/data-science-with-r/)\n* [DATA SCIENCE WITH PYTHON](https://brainalyst.in/data-science-with-python-course/)\n* [DATA SCIENCE 360 TRAINING COURSE](https://brainalyst.in/data-science-360-training-course/)\n* [BIG DATA & CLOUD COMPUTING COURSE](https://brainalyst.in/big-data-cloud-computing-courses/)\n* [FULL STACK DATA SCIENCE PROGRAM](https://brainalyst.in/full-stack-data-science-course-program/)\n* [Mathematics for Machine Learning Specialization (Imperial College London via Coursera)](https://www.coursera.org/specializations/mathematics-machine-learning?action=enroll) - $ but financial aid available\n* [Machine Learning Engineering for Production (MLOps) Specialization (DeepLearning.ai)](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops) - $ but financial aid available\n* [LLMOps: Building Real-World Applications With Large Language Models](https://www.comet.com/site/llm-course/) - free\n* [Prompt Engineering for Vision Models on DeepLearningAI](https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/) - free\n* [Data Science Machine Learning Course on Scaler](https://www.scaler.com/courses/data-science-machine-learning-course/) - $\n* [LabEx Machine Learning Skill Tree](https://labex.io/skilltrees/ml) - free and $ Hands-on labs\n"
        },
        {
          "name": "events.md",
          "type": "blob",
          "size": 0.46,
          "content": "The following is a list of professional events on Machine Learning and Artificial Intelligence\n\n## Machine Learning and Artificial Intelligence\n\n* [AI & ML Events](https://aiml.events) - The best upcoming hand-picked conferences and exhibitions in the field of artificial intelligence and machine learning\n* [Codementor Events](https:///www.codementor.io/events) - The best developer-focused free virtual events platform, ranging from technical to career related topics"
        },
        {
          "name": "meetups.md",
          "type": "blob",
          "size": 0.77,
          "content": "The following is a list of free-to-attend meetups and local events on Machine Learning\n\n- [India](#india)\n    -   [Bangalore](#bangalore)\n- [United States](#unitedstates)\n    -   [New York City](#newyorkcity)\n    -   [San Francisco](#sanfrancisco)\n\n \n      \n<a name=\"india\"></a>\n## India\n\n<a name=\"bangalore\"></a>\n### Bangalore\n* [Bangalore Machine Learning Meetup (BangML)](https://www.meetup.com/BangML/)\n\n\n<a name=\"unitedstates\"></a>\n## United States\n\n<a name=\"newyorkcity\"></a>\n### New York City\n* [New York City Artificial Intelligence and Machine Learning Meetups](https://www.meetup.com/nyc-artificial-intelligence-machine-learning/)\n\n<a name=\"sanfrancisco\"></a>\n### San Francisco\n* [San Francisco Bay Area Machine Learning Meetup](https://www.meetup.com/sf-bayarea-machine-learning/)\n\n"
        },
        {
          "name": "ml-curriculum.md",
          "type": "blob",
          "size": 2.66,
          "content": "# How would your curriculum for a machine learning beginner look like?\nIf I had to put together a study plan for a beginner, I would probably start with an easy-going intro course such as\n\n- Andrew Ng's [Machine Learning Course on Coursera](https://www.coursera.org/learn/machine-learning)\n\nNext, I would recommend a good intro book on 'Data Mining' (data mining is essentially about extracting knowledge from data, mainly using machine learning algorithms). I can highly recommend the following book written by one of my former professors:\n\n- P.-N. Tan, M. Steinbach, and V. Kumar. [Introduction to Data Mining](https://www-users.cs.umn.edu/~kumar/dmbook/index.php), (Second Edition).\n\nThis book will provide you with a great overview of what's currently out there; you will not only learn about different machine learning techniques, but also learn how to \"understand\" and \"handle\" and interpret data -- remember; without \"good,\" informative data, a machine learning algorithm is practically worthless. Additionally, you will learn about alternative techniques since machine learning is not always the only and best solution to a problem\n\n> if all you have is a hammer, everything looks like a nail ...\n\nNow, After completing the Coursera course, you will have a basic understanding of ML and broadened your understanding via the Data Mining book.\nI don't want to self-advertise here, but I think my book would be a good follow-up to learn ML in more depth, understand the algorithms, learn about different data processing pipelines and evaluation techniques, best practices, and learn how to put in into action using Python, NumPy, scikit-learn, and Theano so that you can start working on your personal projects.\n\nWhile you work on your individual projects, I would maybe deepen your (statistical learning) knowledge via one of the three below:\n\n\n- T. Hastie, R. Tibshirani, J. Friedman, T. Hastie, J. Friedman, and R. Tibshirani. [The Elements of Statistical Learning](https://statweb.stanford.edu/~tibs/ElemStatLearn/), volume 2. Springer, 2009.\n- C. M. Bishop et al. [Pattern Recognition and Machine Learning](https://www.springer.com/us/book/9780387310732), volume 1. Springer New York, 2006.\n- Duda, Richard O., Peter E. Hart, and David G. Stork. [Pattern Classification](https://www.wiley.com/WileyCDA/WileyTitle/productCd-0471056693.html). John Wiley & Sons, 2012.\n\nWhen you are through all of that and still hungry to learn more, I recommend\n\n\n- And in-between, if you are looking for a less technical yet very inspirational free-time read, I highly recommend [Pedro Domingo's The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World](https://homes.cs.washington.edu/~pedrod/)\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "hoppscotch/hoppscotch",
      "stars": 66437,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.03,
          "content": "node_modules\n**/*/node_modules\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2,
          "content": "# EditorConfig is awesome: https://EditorConfig.org\n\nroot = true\n\n[*]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n"
        },
        {
          "name": ".env.example",
          "type": "blob",
          "size": 2.9,
          "content": "#-----------------------Backend Config------------------------------#\n# Prisma Config\nDATABASE_URL=postgresql://postgres:testpass@hoppscotch-db:5432/hoppscotch\n\n# Auth Tokens Config\nJWT_SECRET=\"secret1233\"\nTOKEN_SALT_COMPLEXITY=10\nMAGIC_LINK_TOKEN_VALIDITY= 3\n# Default validity is 7 days (604800000 ms) in ms\nREFRESH_TOKEN_VALIDITY=\"604800000\"\n# Default validity is 1 day (86400000 ms) in ms\nACCESS_TOKEN_VALIDITY=\"86400000\"\nSESSION_SECRET='add some secret here'\n# Reccomended to be true, set to false if you are using http\n# Note: Some auth providers may not support http requests\nALLOW_SECURE_COOKIES=true\n\n# Sensitive Data Encryption Key while storing in Database (32 character)\nDATA_ENCRYPTION_KEY=\"data encryption key with 32 char\"\n\n# Hoppscotch App Domain Config\nREDIRECT_URL=\"http://localhost:3000\"\nWHITELISTED_ORIGINS=\"http://localhost:3170,http://localhost:3000,http://localhost:3100\"\nVITE_ALLOWED_AUTH_PROVIDERS=GOOGLE,GITHUB,MICROSOFT,EMAIL\n\n# Google Auth Config\nGOOGLE_CLIENT_ID=\"************************************************\"\nGOOGLE_CLIENT_SECRET=\"************************************************\"\nGOOGLE_CALLBACK_URL=\"http://localhost:3170/v1/auth/google/callback\"\nGOOGLE_SCOPE=\"email,profile\"\n\n# Github Auth Config\nGITHUB_CLIENT_ID=\"************************************************\"\nGITHUB_CLIENT_SECRET=\"************************************************\"\nGITHUB_CALLBACK_URL=\"http://localhost:3170/v1/auth/github/callback\"\nGITHUB_SCOPE=\"user:email\"\n\n# Microsoft Auth Config\nMICROSOFT_CLIENT_ID=\"************************************************\"\nMICROSOFT_CLIENT_SECRET=\"************************************************\"\nMICROSOFT_CALLBACK_URL=\"http://localhost:3170/v1/auth/microsoft/callback\"\nMICROSOFT_SCOPE=\"user.read\"\nMICROSOFT_TENANT=\"common\"\n\n# Mailer config\nMAILER_SMTP_ENABLE=\"true\"\nMAILER_USE_CUSTOM_CONFIGS=\"false\"\nMAILER_ADDRESS_FROM='\"From Name Here\" <from@example.com>'\n\nMAILER_SMTP_URL=\"smtps://user@domain.com:pass@smtp.domain.com\" # used if custom mailer configs is false\n\n# The following are used if custom mailer configs is true\nMAILER_SMTP_HOST=\"smtp.domain.com\"\nMAILER_SMTP_PORT=\"587\"\nMAILER_SMTP_SECURE=\"true\"\nMAILER_SMTP_USER=\"user@domain.com\"\nMAILER_SMTP_PASSWORD=\"pass\"\nMAILER_TLS_REJECT_UNAUTHORIZED=\"true\"\n\n# Rate Limit Config\nRATE_LIMIT_TTL=60 # In seconds\nRATE_LIMIT_MAX=100 # Max requests per IP\n\n\n#-----------------------Frontend Config------------------------------#\n\n\n# Base URLs\nVITE_BASE_URL=http://localhost:3000\nVITE_SHORTCODE_BASE_URL=http://localhost:3000\nVITE_ADMIN_URL=http://localhost:3100\n\n# Backend URLs\nVITE_BACKEND_GQL_URL=http://localhost:3170/graphql\nVITE_BACKEND_WS_URL=ws://localhost:3170/graphql\nVITE_BACKEND_API_URL=http://localhost:3170/v1\n\n# Terms Of Service And Privacy Policy Links (Optional)\nVITE_APP_TOS_LINK=https://docs.hoppscotch.io/support/terms\nVITE_APP_PRIVACY_POLICY_LINK=https://docs.hoppscotch.io/support/privacy\n\n# Set to `true` for subpath based access\nENABLE_SUBPATH_BASED_ACCESS=false\n"
        },
        {
          "name": ".firebaserc",
          "type": "blob",
          "size": 0.05,
          "content": "{\n  \"projects\": {\n    \"default\": \"postwoman-api\"\n  }\n}\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.02,
          "content": "* text=auto eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.43,
          "content": "# Firebase\n.firebase\n\n### Node ###\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n.pnpm-debug.log*\n\n# Diagnostic reports (https://nodejs.org/api/report.html)\nreport.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n*.env\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n*.lcov\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# TypeScript v1 declaration files\ntypings/\n\n# Snowpack dependency directory (https://snowpack.dev/)\nweb_modules/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Optional stylelint cache\n.stylelintcache\n\n# Microbundle cache\n.rpt2_cache/\n.rts2_cache_cjs/\n.rts2_cache_es/\n.rts2_cache_umd/\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# dotenv environment variable files\n.env\n.env.*\n\n# parcel-bundler cache (https://parceljs.org/)\n.cache\n.parcel-cache\n\n# Next.js build output\n.next\nout\n\n# Nuxt.js build / generate output\n.nuxt\ndist\n\n# Gatsby files\n.cache/\n# Comment in the public line in if your project uses Gatsby and not Next.js\n# https://nextjs.org/blog/next-9-1#public-directory-support\n# public\n\n# vuepress build output\n.vuepress/dist\n\n# vuepress v2.x temp and cache directory\n.temp\n\n# Docusaurus cache and generated files\n.docusaurus\n\n# Serverless directories\n.serverless/\n\n# FuseBox cache\n.fusebox/\n\n# DynamoDB Local files\n.dynamodb/\n\n# TernJS port file\n.tern-port\n\n# Stores VSCode versions used for testing VSCode extensions\n.vscode-test\n\n# yarn v2\n.yarn/cache\n.yarn/unplugged\n.yarn/build-state.yml\n.yarn/install-state.gz\n.pnp.*\n\n### Node Patch ###\n# Serverless Webpack directories\n.webpack/\n\n# SvelteKit build / generate output\n.svelte-kit\n\n# IDE / Editor\n.idea\n\n# Service worker\nsw.*\n\n# Mac OSX\n.DS_Store\n\n# Vim swap files\n*.swp\n\n# Build data\n.hoppscotch\n\n# File explorer\n.directory\n\n# Tests screenshots\ntests/*/screenshots\n\n# Tests videos\ntests/*/videos\n\n# Local Netlify folder\n.netlify\n\n# PNPM\n.pnpm-store\n\n# GQL SDL generated for the frontends\ngql-gen/\n"
        },
        {
          "name": ".husky",
          "type": "tree",
          "content": null
        },
        {
          "name": ".npmrc",
          "type": "blob",
          "size": 0.04,
          "content": "shamefully-hoist=false\nsave-prefix=''\n"
        },
        {
          "name": ".prettierignore",
          "type": "blob",
          "size": 0.08,
          "content": ".dependabot\n.github\n.nuxt\n.hoppscotch\n.vscode\npackage-lock.json\nnode_modules\ndist"
        },
        {
          "name": ".prettierrc.js",
          "type": "blob",
          "size": 0.13,
          "content": "module.exports = {\n  semi: false,\n  trailingComma: \"es5\",\n  singleQuote: false,\n  printWidth: 80,\n  useTabs: false,\n  tabWidth: 2\n}\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.1,
          "content": "# Changelog\n\nVisit [releases](https://github.com/hoppscotch/hoppscotch/releases) for full changelog.\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 1.06,
          "content": "# CODEOWNERS is prioritized from bottom to top\n\n# Packages\n/packages/codemirror-lang-graphql/                      @AndrewBastin\n/packages/hoppscotch-cli/                               @jamesgeorge007\n/packages/hoppscotch-data/                              @AndrewBastin\n/packages/hoppscotch-js-sandbox/                        @jamesgeorge007\n/packages/hoppscotch-selfhost-web/                      @jamesgeorge007\n/packages/hoppscotch-selfhost-desktop/                  @AndrewBastin\n/packages/hoppscotch-sh-admin/                          @JoelJacobStephen\n/packages/hoppscotch-backend/                           @balub\n\n# READMEs and other documentation files\n*.md                                                    @liyasthomas\n\n# Self Host deployment related files\n*.Dockerfile                                            @balub\ndocker-compose.yml                                      @balub\ndocker-compose.deploy.yml                               @balub\n*.Caddyfile                                             @balub\n.dockerignore                                           @balub\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.36,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nsupport@hoppscotch.io.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.69,
          "content": "# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Make sure you do not expose environment variables or other sensitive information in your PR.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.03,
          "content": "MIT License\n\nCopyright (c) 2022\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.28,
          "content": "<div align=\"center\">\n  <a href=\"https://hoppscotch.io\">\n    <img\n      src=\"https://avatars.githubusercontent.com/u/56705483\"\n      alt=\"Hoppscotch\"\n      height=\"64\"\n    />\n  </a>\n  <h3>\n    <b>\n      Hoppscotch\n    </b>\n  </h3>\n  <b>\n    Open Source API Development Ecosystem\n  </b>\n  <p>\n\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen?logo=github)](CODE_OF_CONDUCT.md) [![Website](https://img.shields.io/website?url=https%3A%2F%2Fhoppscotch.io&logo=hoppscotch)](https://hoppscotch.io) [![Tests](https://github.com/hoppscotch/hoppscotch/actions/workflows/tests.yml/badge.svg)](https://github.com/hoppscotch/hoppscotch/actions) [![Tweet](https://img.shields.io/twitter/url?url=https%3A%2F%2Fhoppscotch.io%2F)](https://twitter.com/share?text=%F0%9F%91%BD%20Hoppscotch%20%E2%80%A2%20Open%20source%20API%20development%20ecosystem%20-%20Helps%20you%20create%20requests%20faster,%20saving%20precious%20time%20on%20development.&url=https://hoppscotch.io&hashtags=hoppscotch&via=hoppscotch_io)\n\n  </p>\n  <p>\n    <sub>\n      Built with ❤︎ by\n      <a href=\"https://github.com/hoppscotch/hoppscotch/graphs/contributors\">\n        contributors\n      </a>\n    </sub>\n  </p>\n  <br />\n  <p>\n    <a href=\"https://hoppscotch.io\">\n      <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"./packages/hoppscotch-common/public/images/banner-dark.png\">\n        <source media=\"(prefers-color-scheme: light)\" srcset=\"./packages/hoppscotch-common/public/images/banner-light.png\">\n        <img alt=\"Hoppscotch\" src=\"./packages/hoppscotch-common/public/images/banner-dark.png\">\n      </picture>\n    </a>\n  </p>\n</div>\n\n_We highly recommend you take a look at the [**Hoppscotch Documentation**](https://docs.hoppscotch.io) to learn more about the app._\n\n#### **Support**\n\n[![Chat on Discord](https://img.shields.io/badge/chat-Discord-7289DA?logo=discord)](https://hoppscotch.io/discord) [![Chat on Telegram](https://img.shields.io/badge/chat-Telegram-2CA5E0?logo=telegram)](https://hoppscotch.io/telegram) [![Discuss on GitHub](https://img.shields.io/badge/discussions-GitHub-333333?logo=github)](https://github.com/hoppscotch/hoppscotch/discussions)\n\n### **Features**\n\n❤️ **Lightweight:** Crafted with minimalistic UI design.\n\n⚡️ **Fast:** Send requests and get responses in real time.\n\n🗄️ **HTTP Methods:** Request methods define the type of action you are requesting to be performed.\n\n- `GET` - Requests retrieve resource information\n- `POST` - The server creates a new entry in a database\n- `PUT` - Updates an existing resource\n- `PATCH` - Very similar to `PUT` but makes a partial update on a resource\n- `DELETE` - Deletes resource or related component\n- `HEAD` - Retrieve response headers identical to those of a GET request, but without the response body.\n- `CONNECT` - Establishes a tunnel to the server identified by the target resource\n- `OPTIONS` - Describe the communication options for the target resource\n- `TRACE` - Performs a message loop-back test along the path to the target resource\n- `<custom>` - Some APIs use custom request methods such as `LIST`. Type in your custom methods.\n\n🌈 **Theming:** Customizable combinations for background, foreground, and accent colors — [customize now](https://hoppscotch.io/settings).\n\n- Choose a theme: System preference, Light, Dark, and Black\n- Choose accent colors: Green, Teal, Blue, Indigo, Purple, Yellow, Orange, Red, and Pink\n- Distraction-free Zen mode\n\n_Customized themes are synced with your cloud/local session._\n\n🔥 **PWA:** Install as a [Progressive Web App](https://web.dev/progressive-web-apps) on your device.\n\n- Instant loading with Service Workers\n- Offline support\n- Low RAM/memory and CPU usage\n- Add to Home Screen\n- Desktop PWA\n\n🚀 **Request:** Retrieve response from endpoint instantly.\n\n1. Choose `method`\n2. Enter `URL`\n3. Send\n\n- Copy/share public \"Share URL\"\n- Generate/copy request code snippets for 10+ languages and frameworks\n- Import `cURL`\n- Label requests\n\n🔌 **WebSocket:** Establish full-duplex communication channels over a single TCP connection.\n\n📡 **Server-Sent Events:** Receive a stream of updates from a server over an HTTP connection without resorting to polling.\n\n🌩 **Socket.IO:** Send and Receive data with the SocketIO server.\n\n🦟 **MQTT:** Subscribe and Publish to topics of an MQTT Broker.\n\n🔮 **GraphQL:** GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\n\n- Set endpoint and get schema\n- Multi-column docs\n- Set custom request headers\n- Query schema\n- Get query response\n\n🔐 **Authorization:** Allows to identify the end-user.\n\n- None\n- Basic\n- Bearer Token\n- OAuth 2.0\n- OIDC Access Token/PKCE\n\n📢 **Headers:** Describes the format the body of your request is being sent in.\n\n📫 **Parameters:** Use request parameters to set varying parts in simulated requests.\n\n📃 **Request Body:** Used to send and receive data via the REST API.\n\n- Set `Content Type`\n- FormData, JSON, and many more\n- Toggle between key-value and RAW input parameter list\n\n📮 **Response:** Contains the status line, headers, and the message/response body.\n\n- Copy the response to the clipboard\n- Download the response as a file\n- View response headers\n- View raw and preview HTML, image, JSON, and XML responses\n\n⏰ **History:** Request entries are synced with your cloud/local session storage.\n\n📁 **Collections:** Keep your API requests organized with collections and folders. Reuse them with a single click.\n\n- Unlimited collections, folders, and requests\n- Nested folders\n- Export and import as a file or GitHub gist\n\n_Collections are synced with your cloud/local session storage._\n\n📜 **Pre-Request Scripts:** Snippets of code associated with a request that is executed before the request is sent.\n\n- Set environment variables\n- Include timestamp in the request headers\n- Send a random alphanumeric string in the URL parameters\n- Any JavaScript functions\n\n👨‍👩‍👧‍👦 **Teams:** Helps you collaborate across your teams to design, develop, and test APIs faster.\n\n- Create unlimited teams\n- Create unlimited shared collections\n- Create unlimited team members\n- Role-based access control\n- Cloud sync\n- Multiple devices\n\n👥 **Workspaces:** Organize your personal and team collections environments into workspaces. Easily switch between workspaces to manage multiple projects.\n\n- Create unlimited workspaces\n- Switch between personal and team workspaces\n\n⌨️ **Keyboard Shortcuts:** Optimized for efficiency.\n\n> **[Read our documentation on Keyboard Shortcuts](https://docs.hoppscotch.io/documentation/features/shortcuts)**\n\n🌐 **Proxy:** Enable Proxy Mode from Settings to access blocked APIs.\n\n- Hide your IP address\n- Fixes [`CORS`](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) (Cross-Origin Resource Sharing) issues\n- Access APIs served in non-HTTPS (`http://`) endpoints\n- Use your Proxy URL\n\n_Official proxy server is hosted by Hoppscotch - **[GitHub](https://github.com/hoppscotch/proxyscotch)** - **[Privacy Policy](https://docs.hoppscotch.io/support/privacy)**._\n\n🌎 **i18n:** Experience the app in your language.\n\nHelp us to translate Hoppscotch. Please read [`TRANSLATIONS`](TRANSLATIONS.md) for details on our [`CODE OF CONDUCT`](CODE_OF_CONDUCT.md) and the process for submitting pull requests to us.\n\n☁️ **Auth + Sync:** Sign in and sync your data in real-time across all your devices.\n\n**Sign in with:**\n\n- GitHub\n- Google\n- Microsoft\n- Email\n- SSO (Single Sign-On)[^EE]\n\n**🔄 Synchronize your data:** Handoff to continue tasks on your other devices.\n\n- Workspaces\n- History\n- Collections\n- Environments\n- Settings\n\n✅ **Post-Request Tests:** Write tests associated with a request that is executed after the request's response.\n\n- Check the status code as an integer\n- Filter response headers\n- Parse the response data\n- Set environment variables\n- Write JavaScript code\n\n🌱 **Environments:** Environment variables allow you to store and reuse values in your requests and scripts.\n\n- Unlimited environments and variables\n- Initialize through the pre-request script\n- Export as / import from GitHub gist\n\n<details>\n  <summary><i>Use-cases</i></summary>\n\n---\n\n- By storing a value in a variable, you can reference it throughout your request section\n- If you need to update the value, you only have to change it in one place\n- Using variables increases your ability to work efficiently and minimizes the likelihood of error\n\n---\n\n</details>\n\n🚚 **Bulk Edit:** Edit key-value pairs in bulk.\n\n- Entries are separated by newline\n- Keys and values are separated by `:`\n- Prepend `#` to any row you want to add but keep disabled\n\n🎛️ **Admin dashboard:** Manage your team and invite members.\n\n- Insights\n- Manage users\n- Manage teams\n\n📦 **Add-ons:** Official add-ons for hoppscotch.\n\n- **[Hoppscotch CLI](https://github.com/hoppscotch/hoppscotch/tree/main/packages/hoppscotch-cli)** - Command-line interface for Hoppscotch.\n- **[Proxy](https://github.com/hoppscotch/proxyscotch)** - A simple proxy server created for Hoppscotch.\n- **[Browser Extensions](https://github.com/hoppscotch/hoppscotch-extension)** - Browser extensions that enhance your Hoppscotch experience.\n\n  [![Firefox](https://raw.github.com/alrra/browser-logos/master/src/firefox/firefox_16x16.png) **Firefox**](https://addons.mozilla.org/en-US/firefox/addon/hoppscotch) &nbsp;|&nbsp; [![Chrome](https://raw.github.com/alrra/browser-logos/master/src/chrome/chrome_16x16.png) **Chrome**](https://chrome.google.com/webstore/detail/hoppscotch-extension-for-c/amknoiejhlmhancpahfcfcfhllgkpbld)\n\n  > **Extensions fix `CORS` issues.**\n\n_Add-ons are developed and maintained under **[Hoppscotch Organization](https://github.com/hoppscotch)**._\n\n**For a complete list of features, please read our [documentation](https://docs.hoppscotch.io).**\n\n## **Demo**\n\n[hoppscotch.io](https://hoppscotch.io)\n\n## **Usage**\n\n1. Provide your API endpoint in the URL field\n2. Click \"Send\" to simulate the request\n3. View the response\n\n## **Developing**\n\nFollow our [self-hosting documentation](https://docs.hoppscotch.io/documentation/self-host/getting-started) to get started with the development environment.\n\n## **Contributing**\n\nPlease contribute using [GitHub Flow](https://guides.github.com/introduction/flow). Create a branch, add commits, and [open a pull request](https://github.com/hoppscotch/hoppscotch/compare).\n\nPlease read [`CONTRIBUTING`](CONTRIBUTING.md) for details on our [`CODE OF CONDUCT`](CODE_OF_CONDUCT.md), and the process for submitting pull requests to us.\n\n## **Continuous Integration**\n\nWe use [GitHub Actions](https://github.com/features/actions) for continuous integration. Check out our [build workflows](https://github.com/hoppscotch/hoppscotch/actions).\n\n## **Changelog**\n\nSee the [`CHANGELOG`](CHANGELOG.md) file for details.\n\n## **Authors**\n\nThis project owes its existence to the collective efforts of all those who contribute — [contribute now](CONTRIBUTING.md).\n\n<div align=\"center\">\n  <a href=\"https://github.com/hoppscotch/hoppscotch/graphs/contributors\">\n    <img src=\"https://opencollective.com/hoppscotch/contributors.svg?width=840&button=false\"\n      alt=\"Contributors\"\n      width=\"100%\" />\n  </a>\n</div>\n\n## **License**\n\nThis project is licensed under the [MIT License](https://opensource.org/licenses/MIT) — see the [`LICENSE`](LICENSE) file for details.\n\n[^EE]: Enterprise edition feature. [Learn more](https://docs.hoppscotch.io/documentation/self-host/getting-started).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.74,
          "content": "# Security Policy\n\nThis document outlines security procedures and general policies for the Hoppscotch project.\n\n- [Security Policy](#security-policy)\n  - [Reporting a security vulnerability](#reporting-a-security-vulnerability)\n  - [What is not a valid vulnerability](#what-is-not-a-valid-vulnerability)\n  - [Incident response process](#incident-response-process)\n\n## Reporting a security vulnerability\n\nWe use [Github Security Advisories](https://github.com/hoppscotch/hoppscotch/security/advisories) to manage vulnerability reports and collaboration.\nSomeone from the Hoppscotch team shall report to you within 48 hours of the disclosure of the vulnerability in GHSA. If no response was received, please reach out to\nHoppscotch Support at support@hoppscotch.io along with the GHSA advisory link.\n\n> NOTE: Since we have multiple open source components, Advisories may move into the relevant repo (for example, an XSS in a UI component might be part of [`@hoppscotch/ui`](https://github.com/hoppscotch/ui)).\n> If in doubt, open your report in `hoppscotch/hoppscotch` GHSA.\n\n**Do not create a GitHub issue ticket to report a security vulnerability!**\n\nThe Hoppscotch team takes all security vulnerability reports in Hoppscotch seriously. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions.\n\n## What is not a valid vulnerability\nWe receive many reports about different sections of the Hoppscotch platform. Hence, we have a fine line we have drawn defining what is considered valid vulnerability.\nPlease refrain from opening an advisory if it describes the following:\n\n- A vulnerability in a dependency of Hoppscotch (unless you have practical attack with it on the Hoppscotch codebase)\n- Reports of vulnerabilities related to old runtimes (like NodeJS) or container images used by the codebase\n- Vulnerabilities present when using Hoppscotch in anything other than the defined minimum requirements that Hoppscotch supports.\n\nHoppscotch Team ensures security support for:\n- Modern Browsers (Chrome/Firefox/Safari/Edge) with versions up to 1 year old.\n- Windows versions on or above Windows 10 on Intel and ARM.\n- macOS versions dating back up to 2 years on Intel and Apple Silicon.\n- Popular Linux distributions with up-to-date packages with preference to x86/64 CPUs.\n- Docker/OCI Runtimes (preference to Docker and Podman) dating back up to 1 year.\n\n## Incident response process\n\nIn case an incident is discovered or reported, we will follow the following  process to contain, respond, and remediate:\n\n1. Confirm the problem and determine the affected versions.\n2. Audit code to find any potential similar problems.\n3. Prepare fixes for all releases still under maintenance. These fixes will be deployed as fast as possible to production.\n"
        },
        {
          "name": "TRANSLATIONS.md",
          "type": "blob",
          "size": 2.57,
          "content": "# Translations\n\nThanks for showing your interest in helping us to translate the software.\n\n## Creating a new translation\n\nBefore you start working on a new language, please look through the [open pull requests](https://github.com/hoppscotch/hoppscotch/pulls) to see if anyone is already working on a translation. If you find one, please join the discussion and help us keep the existing translations up to date.\n\nif there is no existing translation, you can create a new one by following these steps:\n\n1. **[Fork the repository](https://github.com/hoppscotch/hoppscotch/fork).**\n2. **Checkout the `main` branch for latest translations.**\n3. **Create a new branch for your translation with base branch `main`.**\n4. **Create target language file in the [`/packages/hoppscotch-common/locales`](https://github.com/hoppscotch/hoppscotch/tree/main/packages/hoppscotch-common/locales) directory.**\n5. **Copy the contents of the source file [`/packages/hoppscotch-common/locales/en.json`](https://github.com/hoppscotch/hoppscotch/blob/main/packages/hoppscotch-common/locales/en.json) to the target language file.**\n6. **Translate the strings in the target language file.**\n7. **Add your language entry to [`/packages/hoppscotch-common/languages.json`](https://github.com/hoppscotch/hoppscotch/blob/main/packages/hoppscotch-common/languages.json).**\n8. **Save and commit changes.**\n9. **Send a pull request.**\n\n_You may send a pull request before all steps above are complete: e.g., you may want to ask for help with translations, or getting tests to pass. However, your pull request will not be merged until all steps above are complete._\n\nCompleting an initial translation of the whole site is a fairly large task. One way to break that task up is to work with other translators through pull requests on your fork. You can also [add collaborators to your fork](https://help.github.com/en/github/setting-up-and-managing-your-github-user-account/inviting-collaborators-to-a-personal-repository) if you'd like to invite other translators to commit directly to your fork and share responsibility for merging pull requests.\n\n## Updating a translation\n\n### Corrections\n\nIf you notice spelling or grammar errors, typos, or opportunities for better phrasing, open a pull request with your suggested fix. If you see a problem that you aren't sure of or don't have time to fix, [open an issue](https://github.com/hoppscotch/hoppscotch/issues/new/choose).\n\n### Broken links\n\nWhen tests find broken links, try to fix them across all translations. Ideally, only update the linked URLs, so that translation changes will definitely not be necessary.\n"
        },
        {
          "name": "aio-multiport-setup.Caddyfile",
          "type": "blob",
          "size": 0.22,
          "content": "{\n\tadmin off\n\tpersist_config off\n}\n\n:3000 {\n\ttry_files {path} /\n\troot * /site/selfhost-web\n\tfile_server\n}\n\n:3100 {\n\ttry_files {path} /\n\troot * /site/sh-admin-multiport-setup\n\tfile_server\n}\n\n:3170 {\n\treverse_proxy localhost:8080\n}\n"
        },
        {
          "name": "aio-subpath-access.Caddyfile",
          "type": "blob",
          "size": 0.56,
          "content": "{\n  admin off\n  persist_config off\n}\n\n:{$HOPP_AIO_ALTERNATE_PORT:80} {\n\t# Serve the `selfhost-web` SPA by default\n\troot * /site/selfhost-web\n\tfile_server\n\n\thandle_path /admin* {\n\t\troot * /site/sh-admin-subpath-access\n\t\tfile_server\n\n\t\t# Ensures any non-existent file in the server is routed to the SPA\n\t\ttry_files {path} /\n\t}\n\n\t# Handle requests under `/backend*` path\n\thandle_path /backend* {\n\t\treverse_proxy localhost:8080\n\t}\n\n\t# Catch-all route for unknown paths, serves `selfhost-web` SPA\n\thandle {\n\t\troot * /site/selfhost-web\n\t\tfile_server\n\t\ttry_files {path} /\n\t}\n}\n"
        },
        {
          "name": "aio_run.mjs",
          "type": "blob",
          "size": 2.03,
          "content": "#!/usr/local/bin/node\n// @ts-check\n\nimport { execSync, spawn } from \"child_process\"\nimport fs from \"fs\"\nimport process from \"process\"\n\nfunction runChildProcessWithPrefix(command, args, prefix) {\n  const childProcess = spawn(command, args);\n\n  childProcess.stdout.on('data', (data) => {\n    const output = data.toString().trim().split('\\n');\n    output.forEach((line) => {\n      console.log(`${prefix} | ${line}`);\n    });\n  });\n\n  childProcess.stderr.on('data', (data) => {\n    const error = data.toString().trim().split('\\n');\n    error.forEach((line) => {\n      console.error(`${prefix} | ${line}`);\n    });\n  });\n\n  childProcess.on('close', (code) => {\n    console.log(`${prefix} Child process exited with code ${code}`);\n  });\n\n  childProcess.on('error', (stuff) => {\n    console.log(\"error\")\n    console.log(stuff)\n  })\n\n  return childProcess\n}\n\nconst envFileContent = Object.entries(process.env)\n  .filter(([env]) => env.startsWith(\"VITE_\"))\n  .map(([env, val]) => `${env}=${\n    (val.startsWith(\"\\\"\") && val.endsWith(\"\\\"\"))\n      ? val\n      : `\"${val}\"`\n  }`)\n  .join(\"\\n\")\n\nfs.writeFileSync(\"build.env\", envFileContent)\n\nexecSync(`npx import-meta-env -x build.env -e build.env -p \"/site/**/*\"`)\n\nfs.rmSync(\"build.env\")\n\nconst caddyFileName = process.env.ENABLE_SUBPATH_BASED_ACCESS === 'true' ? 'aio-subpath-access.Caddyfile' : 'aio-multiport-setup.Caddyfile'\nconst caddyProcess = runChildProcessWithPrefix(\"caddy\", [\"run\", \"--config\", `/etc/caddy/${caddyFileName}`, \"--adapter\", \"caddyfile\"], \"App/Admin Dashboard Caddy\")\nconst backendProcess = runChildProcessWithPrefix(\"node\", [\"/dist/backend/dist/main.js\"], \"Backend Server\")\n\ncaddyProcess.on(\"exit\", (code) => {\n  console.log(`Exiting process because Caddy Server exited with code ${code}`)\n  process.exit(code)\n})\n\nbackendProcess.on(\"exit\", (code) => {\n  console.log(`Exiting process because Backend Server exited with code ${code}`)\n  process.exit(code)\n})\n\nprocess.on('SIGINT', () => {\n  console.log(\"SIGINT received, exiting...\")\n\n  caddyProcess.kill(\"SIGINT\")\n  backendProcess.kill(\"SIGINT\")\n\n  process.exit(0)\n})\n"
        },
        {
          "name": "commitlint.config.js",
          "type": "blob",
          "size": 0.07,
          "content": "module.exports = {\n  extends: [\"@commitlint/config-conventional\"],\n}\n"
        },
        {
          "name": "docker-compose.deploy.yml",
          "type": "blob",
          "size": 1.31,
          "content": "# THIS IS NOT TO BE USED FOR PERSONAL DEPLOYMENTS!\n# Internal Docker Compose Image used for internal testing deployments\n\nservices:\n  hoppscotch-db:\n    image: postgres:15\n    user: postgres\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: testpass\n      POSTGRES_DB: hoppscotch\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"sh -c 'pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}'\"\n        ]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n\n  hoppscotch-aio:\n    container_name: hoppscotch-aio\n    build:\n      dockerfile: prod.Dockerfile\n      context: .\n      target: aio\n    environment:\n      # DATABASE_URL is read from the .env file to allow the backend to connect with an external database.\n      # This allows the backend to retain existing data and prevents database resets during deployments.\n      # DATABASE_URL=postgresql://postgres:testpass@hoppscotch-db:5432/hoppscotch\n      - ENABLE_SUBPATH_BASED_ACCESS=true\n    env_file:\n      - ./.env\n    depends_on:\n      hoppscotch-db:\n        condition: service_healthy\n    command: [\"sh\", \"-c\", \"pnpm exec prisma migrate deploy && node /usr/src/app/aio_run.mjs\"]\n    healthcheck:\n      test:\n        - CMD\n        - curl\n        - '-f'\n        - 'http://localhost:80'\n      interval: 2s\n      timeout: 10s\n      retries: 30\n\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 4.41,
          "content": "# To make it easier to self-host, we have a preset docker compose config that also\n# has a container with a Postgres instance running.\n# You can tweak around this file to match your instances\n\nservices:\n  # This service runs the backend app in the port 3170\n  hoppscotch-backend:\n    container_name: hoppscotch-backend\n    build:\n      dockerfile: prod.Dockerfile\n      context: .\n      target: backend\n    env_file:\n      - ./.env\n    restart: always\n    environment:\n      # Edit the below line to match your PostgresDB URL if you have an outside DB (make sure to update the .env file as well)\n      - DATABASE_URL=postgresql://postgres:testpass@hoppscotch-db:5432/hoppscotch?connect_timeout=300\n      - PORT=8080\n    volumes:\n      # Uncomment the line below when modifying code. Only applicable when using the \"dev\" target.\n      # - ./packages/hoppscotch-backend/:/usr/src/app\n      - /usr/src/app/node_modules/\n    depends_on:\n      hoppscotch-db:\n        condition: service_healthy\n    ports:\n      - \"3180:80\"\n      - \"3170:3170\"\n\n  # The main hoppscotch app. This will be hosted at port 3000\n  # NOTE: To do TLS or play around with how the app is hosted, you can look into the Caddyfile for\n  #       the SH admin dashboard server at packages/hoppscotch-selfhost-web/Caddyfile\n  hoppscotch-app:\n    container_name: hoppscotch-app\n    build:\n      dockerfile: prod.Dockerfile\n      context: .\n      target: app\n    env_file:\n      - ./.env\n    depends_on:\n      - hoppscotch-backend\n    ports:\n      - \"3080:80\"\n      - \"3000:3000\"\n\n  # The Self Host dashboard for managing the app. This will be hosted at port 3100\n  # NOTE: To do TLS or play around with how the app is hosted, you can look into the Caddyfile for\n  #       the SH admin dashboard server at packages/hoppscotch-sh-admin/Caddyfile\n  hoppscotch-sh-admin:\n    container_name: hoppscotch-sh-admin\n    build:\n      dockerfile: prod.Dockerfile\n      context: .\n      target: sh_admin\n    env_file:\n      - ./.env\n    depends_on:\n      - hoppscotch-backend\n    ports:\n      - \"3280:80\"\n      - \"3100:3100\"\n\n  # The service that spins up all 3 services at once in one container\n  hoppscotch-aio:\n    container_name: hoppscotch-aio\n    restart: unless-stopped\n    build:\n      dockerfile: prod.Dockerfile\n      context: .\n      target: aio\n    env_file:\n      - ./.env\n    depends_on:\n      hoppscotch-db:\n        condition: service_healthy\n    ports:\n      - \"3000:3000\"\n      - \"3100:3100\"\n      - \"3170:3170\"\n      - \"3080:80\"\n\n  # The preset DB service, you can delete/comment the below lines if\n  # you are using an external postgres instance\n  # This will be exposed at port 5432\n  hoppscotch-db:\n    image: postgres:15\n    ports:\n      - \"5432:5432\"\n    user: postgres\n    environment:\n      # The default user defined by the docker image\n      POSTGRES_USER: postgres\n      # NOTE: Please UPDATE THIS PASSWORD!\n      POSTGRES_PASSWORD: testpass\n      POSTGRES_DB: hoppscotch\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"sh -c 'pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}'\",\n        ]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n\n  # All the services listed below are deprececated\n  hoppscotch-old-backend:\n    container_name: hoppscotch-old-backend\n    build:\n      dockerfile: packages/hoppscotch-backend/Dockerfile\n      context: .\n      target: prod\n    env_file:\n      - ./.env\n    restart: always\n    environment:\n      # Edit the below line to match your PostgresDB URL if you have an outside DB (make sure to update the .env file as well)\n      - DATABASE_URL=postgresql://postgres:testpass@hoppscotch-db:5432/hoppscotch?connect_timeout=300\n      - PORT=3000\n    volumes:\n      # Uncomment the line below when modifying code. Only applicable when using the \"dev\" target.\n      # - ./packages/hoppscotch-backend/:/usr/src/app\n      - /usr/src/app/node_modules/\n    depends_on:\n      hoppscotch-db:\n        condition: service_healthy\n    ports:\n      - \"3170:3000\"\n\n  hoppscotch-old-app:\n    container_name: hoppscotch-old-app\n    build:\n      dockerfile: packages/hoppscotch-selfhost-web/Dockerfile\n      context: .\n    env_file:\n      - ./.env\n    depends_on:\n      - hoppscotch-old-backend\n    ports:\n      - \"3000:8080\"\n\n  hoppscotch-old-sh-admin:\n    container_name: hoppscotch-old-sh-admin\n    build:\n      dockerfile: packages/hoppscotch-sh-admin/Dockerfile\n      context: .\n    env_file:\n      - ./.env\n    depends_on:\n      - hoppscotch-old-backend\n    ports:\n      - \"3100:8080\"\n"
        },
        {
          "name": "firebase.json",
          "type": "blob",
          "size": 0.43,
          "content": "{\n  \"firestore\": {\n    \"rules\": \"firestore.rules\",\n    \"indexes\": \"firestore.indexes.json\"\n  },\n  \"hosting\": {\n    \"predeploy\": [\n      \"mv .env.example .env && npm install -g pnpm && pnpm i && pnpm run generate\"\n    ],\n    \"public\": \"packages/hoppscotch-web/dist\",\n    \"ignore\": [\"firebase.json\", \"**/.*\", \"**/node_modules/**\"],\n    \"rewrites\": [\n      {\n        \"source\": \"**\",\n        \"destination\": \"/index.html\"\n      }\n    ]\n  }\n}\n"
        },
        {
          "name": "firestore.indexes.json",
          "type": "blob",
          "size": 0.04,
          "content": "{\n  \"indexes\": [],\n  \"fieldOverrides\": []\n}\n"
        },
        {
          "name": "firestore.rules",
          "type": "blob",
          "size": 0.53,
          "content": "service cloud.firestore {\n  match /databases/{database}/documents {\n    // Make sure the uid of the requesting user matches name of the user\n    // document. The wildcard expression {userId} makes the userId variable\n    // available in rules.\n    match /users/{userId} {\n      allow read, write, create, update, delete: if request.auth.uid != null && request.auth.uid == userId;\n    }\n    match /users/{userId}/{document=**} {\n    \tallow read, write, create, update, delete: if request.auth.uid != null && request.auth.uid == userId;\n    }\n  }\n}\n"
        },
        {
          "name": "healthcheck.sh",
          "type": "blob",
          "size": 0.4,
          "content": "#!/bin/sh\n\ncurlCheck() {\n  if ! curl -s --head \"$1\" | head -n 1 | grep -q \"HTTP/1.[01] [23]..\"; then\n    echo \"URL request failed!\"\n    exit 1\n  else\n    echo \"URL request succeeded!\"\n  fi\n}\n\nif [ \"$ENABLE_SUBPATH_BASED_ACCESS\" = \"true\" ]; then\n  curlCheck \"http://localhost:80/backend/ping\"\nelse\n  curlCheck \"http://localhost:3000\"\n  curlCheck \"http://localhost:3100\"\n  curlCheck \"http://localhost:3170/ping\"\nfi\n"
        },
        {
          "name": "jsconfig.json",
          "type": "blob",
          "size": 0.2,
          "content": "{\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"~/*\": [\"./*\"],\n      \"@/*\": [\"./*\"],\n      \"~~/*\": [\"./*\"],\n      \"@@/*\": [\"./*\"]\n    }\n  },\n  \"exclude\": [\"node_modules\", \".nuxt\", \"dist\"]\n}\n"
        },
        {
          "name": "netlify.toml",
          "type": "blob",
          "size": 1.39,
          "content": "[build.environment]\n  NODE_VERSION = \"14\"\n  NPM_FLAGS = \"--prefix=/dev/null\"\n\n[build]\n  base = \"/\"\n  publish = \"packages/hoppscotch-web/dist\"\n  command = \"npx pnpm i --store=node_modules/.pnpm-store && npx pnpm run generate\"\n\n[[headers]]\n  for = \"/*\"\n  [headers.values]\n    X-Frame-Options = \"SAMEORIGIN\"\n    X-XSS-Protection = \"1; mode=block\"\n\n[[redirects]]\n  from = \"/discord\"\n  to = \"https://discord.gg/GAMWxmR\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/telegram\"\n  to = \"https://t.me/hoppscotch\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/beta\"\n  to = \"https://forms.gle/XPYDMp8m6JHNWcYp9\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/careers\"\n  to = \"https://company.hoppscotch.io/careers\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/newsletter\"\n  to = \"http://eepurl.com/hy0eWH\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/twitter\"\n  to = \"https://twitter.com/hoppscotch_io\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/github\"\n  to = \"https://github.com/hoppscotch/hoppscotch\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/announcements\"\n  to = \"https://company.hoppscotch.io/announcements\"\n  status = 301\n  force = true\n\n[[redirects]]\n  from = \"/robots.txt\"\n  to = \"/robots.txt\"\n  status = 200\n\n[[redirects]]\n  from = \"/sitemap.xml\"\n  to = \"/sitemap.xml\"\n  status = 200\n\n[[redirects]]\n  from = \"/*\"\n  to = \"/index.html\"\n  status = 200\n"
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 1.63,
          "content": "{\n  \"name\": \"hoppscotch-app\",\n  \"version\": \"3.0.1\",\n  \"description\": \"Open source API development ecosystem\",\n  \"author\": \"Hoppscotch (support@hoppscotch.io)\",\n  \"private\": true,\n  \"license\": \"MIT\",\n  \"scripts\": {\n    \"preinstall\": \"npx only-allow pnpm\",\n    \"prepare\": \"husky\",\n    \"dev\": \"pnpm -r do-dev\",\n    \"gen-gql\": \"cross-env GQL_SCHEMA_EMIT_LOCATION='../../../gql-gen/backend-schema.gql' pnpm -r generate-gql-sdl\",\n    \"generate\": \"pnpm -r do-build-prod\",\n    \"start\": \"http-server packages/hoppscotch-selfhost-web/dist -p 3000\",\n    \"lint\": \"pnpm -r do-lint\",\n    \"typecheck\": \"pnpm -r do-typecheck\",\n    \"lintfix\": \"pnpm -r do-lintfix\",\n    \"pre-commit\": \"pnpm -r do-lint && pnpm -r do-typecheck\",\n    \"test\": \"pnpm -r do-test\",\n    \"generate-ui\": \"pnpm -r do-build-ui\"\n  },\n  \"workspaces\": [\n    \"./packages/*\"\n  ],\n  \"devDependencies\": {\n    \"@commitlint/cli\": \"19.5.0\",\n    \"@commitlint/config-conventional\": \"19.5.0\",\n    \"@hoppscotch/ui\": \"0.2.2\",\n    \"@types/node\": \"22.7.6\",\n    \"cross-env\": \"7.0.3\",\n    \"http-server\": \"14.1.1\",\n    \"husky\": \"9.1.6\",\n    \"lint-staged\": \"15.2.10\"\n  },\n  \"pnpm\": {\n    \"overrides\": {\n      \"cookie\": \"0.7.2\",\n      \"cross-spawn\": \"7.0.6\",\n      \"vue\": \"3.5.12\",\n      \"@nestjs-modules/mailer>mjml\": \"5.0.0-alpha.4\",\n      \"subscriptions-transport-ws>ws\": \"7.5.10\",\n      \"braces\": \"3.0.3\",\n      \"send\": \"0.19.0\",\n      \"pug\": \"3.0.3\",\n      \"body-parser\": \"1.20.3\",\n      \"path-to-regexp@3.2.0\": \"3.3.0\",\n      \"micromatch@<4.0.8\": \"4.0.8\",\n      \"dset@3.1.3\": \"3.1.4\"\n    },\n    \"packageExtensions\": {\n      \"@hoppscotch/httpsnippet\": {\n        \"dependencies\": {\n          \"ajv\": \"6.12.3\"\n        }\n      }\n    }\n  }\n}\n"
        },
        {
          "name": "packages",
          "type": "tree",
          "content": null
        },
        {
          "name": "pnpm-lock.yaml",
          "type": "blob",
          "size": 887.47,
          "content": "lockfileVersion: '9.0'\n\nsettings:\n  autoInstallPeers: true\n  excludeLinksFromLockfile: false\n\noverrides:\n  cookie: 0.7.2\n  cross-spawn: 7.0.6\n  vue: 3.5.12\n  '@nestjs-modules/mailer>mjml': 5.0.0-alpha.4\n  subscriptions-transport-ws>ws: 7.5.10\n  braces: 3.0.3\n  send: 0.19.0\n  pug: 3.0.3\n  body-parser: 1.20.3\n  path-to-regexp@3.2.0: 3.3.0\n  micromatch@<4.0.8: 4.0.8\n  dset@3.1.3: 3.1.4\n\npackageExtensionsChecksum: da57d58cd55bf5e7924e59ad5f1485b8\n\nimporters:\n\n  .:\n    devDependencies:\n      '@commitlint/cli':\n        specifier: 19.5.0\n        version: 19.5.0(@types/node@22.7.6)(typescript@5.6.3)\n      '@commitlint/config-conventional':\n        specifier: 19.5.0\n        version: 19.5.0\n      '@hoppscotch/ui':\n        specifier: 0.2.2\n        version: 0.2.2(eslint@9.12.0(jiti@2.3.3))(terser@5.34.1)(typescript@5.6.3)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.6.3))\n      '@types/node':\n        specifier: 22.7.6\n        version: 22.7.6\n      cross-env:\n        specifier: 7.0.3\n        version: 7.0.3\n      http-server:\n        specifier: 14.1.1\n        version: 14.1.1\n      husky:\n        specifier: 9.1.6\n        version: 9.1.6\n      lint-staged:\n        specifier: 15.2.10\n        version: 15.2.10\n\n  packages/codemirror-lang-graphql:\n    dependencies:\n      '@codemirror/language':\n        specifier: 6.10.1\n        version: 6.10.1\n      '@lezer/highlight':\n        specifier: 1.2.0\n        version: 1.2.0\n      '@lezer/lr':\n        specifier: 1.3.14\n        version: 1.3.14\n    devDependencies:\n      '@lezer/generator':\n        specifier: 1.5.1\n        version: 1.5.1\n      '@rollup/plugin-typescript':\n        specifier: 12.1.1\n        version: 12.1.1(rollup@3.29.4)(tslib@2.8.0)(typescript@5.2.2)\n      mocha:\n        specifier: 9.2.2\n        version: 9.2.2\n      rollup:\n        specifier: 3.29.4\n        version: 3.29.4\n      typescript:\n        specifier: 5.2.2\n        version: 5.2.2\n\n  packages/hoppscotch-agent:\n    dependencies:\n      '@hoppscotch/ui':\n        specifier: ^0.2.1\n        version: 0.2.1(eslint@9.12.0(jiti@2.3.3))(terser@5.34.1)(typescript@5.6.3)(vite@5.4.9(@types/node@22.7.5)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.6.3))\n      '@tauri-apps/api':\n        specifier: ^2.0.2\n        version: 2.0.2\n      '@tauri-apps/plugin-shell':\n        specifier: ^2.0.0\n        version: 2.0.0\n      '@vueuse/core':\n        specifier: ^11.1.0\n        version: 11.1.0(vue@3.5.12(typescript@5.6.3))\n      axios:\n        specifier: ^1.7.7\n        version: 1.7.7\n      fp-ts:\n        specifier: ^2.16.9\n        version: 2.16.9\n      vue:\n        specifier: 3.5.12\n        version: 3.5.12(typescript@5.6.3)\n    devDependencies:\n      '@iconify-json/lucide':\n        specifier: ^1.2.8\n        version: 1.2.10\n      '@tauri-apps/cli':\n        specifier: ^2.0.3\n        version: 2.0.4\n      '@types/node':\n        specifier: ^22.7.5\n        version: 22.7.5\n      '@vitejs/plugin-vue':\n        specifier: ^5.1.4\n        version: 5.1.4(vite@5.4.9(@types/node@22.7.5)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.6.3))\n      autoprefixer:\n        specifier: ^10.4.20\n        version: 10.4.20(postcss@8.4.47)\n      postcss:\n        specifier: ^8.4.47\n        version: 8.4.47\n      tailwindcss:\n        specifier: ^3.4.13\n        version: 3.4.13(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.5)(typescript@5.6.3))\n      typescript:\n        specifier: ^5.6.3\n        version: 5.6.3\n      unplugin-icons:\n        specifier: ^0.19.3\n        version: 0.19.3(@vue/compiler-sfc@3.5.12)(vue-template-compiler@2.7.16)(webpack-sources@3.2.3)\n      vite:\n        specifier: ^5.4.8\n        version: 5.4.9(@types/node@22.7.5)(sass@1.80.3)(terser@5.34.1)\n      vue-tsc:\n        specifier: ^2.1.6\n        version: 2.1.6(typescript@5.6.3)\n\n  packages/hoppscotch-backend:\n    dependencies:\n      '@apollo/server':\n        specifier: 4.11.0\n        version: 4.11.0(graphql@16.9.0)\n      '@nestjs-modules/mailer':\n        specifier: 2.0.2\n        version: 2.0.2(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(nodemailer@6.9.15)(relateurl@0.2.7)(svgo@3.3.2)(terser@5.34.1)(typescript@5.5.4)\n      '@nestjs/apollo':\n        specifier: 12.2.0\n        version: 12.2.0(@apollo/server@4.11.0(graphql@16.9.0))(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/graphql@12.2.0(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(class-transformer@0.5.1)(class-validator@0.14.1)(graphql@16.9.0)(reflect-metadata@0.2.2))(graphql@16.9.0)\n      '@nestjs/common':\n        specifier: 10.4.4\n        version: 10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1)\n      '@nestjs/config':\n        specifier: 3.2.3\n        version: 3.2.3(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(rxjs@7.8.1)\n      '@nestjs/core':\n        specifier: 10.4.4\n        version: 10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1)\n      '@nestjs/graphql':\n        specifier: 12.2.0\n        version: 12.2.0(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(class-transformer@0.5.1)(class-validator@0.14.1)(graphql@16.9.0)(reflect-metadata@0.2.2)\n      '@nestjs/jwt':\n        specifier: 10.2.0\n        version: 10.2.0(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))\n      '@nestjs/passport':\n        specifier: 10.0.3\n        version: 10.0.3(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(passport@0.7.0)\n      '@nestjs/platform-express':\n        specifier: 10.4.4\n        version: 10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4)\n      '@nestjs/schedule':\n        specifier: 4.1.1\n        version: 4.1.1(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))\n      '@nestjs/swagger':\n        specifier: 7.4.2\n        version: 7.4.2(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)\n      '@nestjs/terminus':\n        specifier: 10.2.3\n        version: 10.2.3(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@prisma/client@5.20.0(prisma@5.20.0))(reflect-metadata@0.2.2)(rxjs@7.8.1)\n      '@nestjs/throttler':\n        specifier: 6.2.1\n        version: 6.2.1(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(reflect-metadata@0.2.2)\n      '@prisma/client':\n        specifier: 5.20.0\n        version: 5.20.0(prisma@5.20.0)\n      argon2:\n        specifier: 0.41.1\n        version: 0.41.1\n      bcrypt:\n        specifier: 5.1.1\n        version: 5.1.1\n      class-transformer:\n        specifier: 0.5.1\n        version: 0.5.1\n      class-validator:\n        specifier: 0.14.1\n        version: 0.14.1\n      cookie:\n        specifier: 0.7.2\n        version: 0.7.2\n      cookie-parser:\n        specifier: 1.4.7\n        version: 1.4.7\n      cron:\n        specifier: 3.1.7\n        version: 3.1.7\n      express:\n        specifier: 4.21.1\n        version: 4.21.1\n      express-session:\n        specifier: 1.18.1\n        version: 1.18.1\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      graphql:\n        specifier: 16.9.0\n        version: 16.9.0\n      graphql-query-complexity:\n        specifier: 1.0.0\n        version: 1.0.0(graphql@16.9.0)\n      graphql-redis-subscriptions:\n        specifier: 2.6.1\n        version: 2.6.1(graphql-subscriptions@2.0.0(graphql@16.9.0))\n      graphql-subscriptions:\n        specifier: 2.0.0\n        version: 2.0.0(graphql@16.9.0)\n      handlebars:\n        specifier: 4.7.8\n        version: 4.7.8\n      io-ts:\n        specifier: 2.2.21\n        version: 2.2.21(fp-ts@2.16.9)\n      luxon:\n        specifier: 3.5.0\n        version: 3.5.0\n      nodemailer:\n        specifier: 6.9.15\n        version: 6.9.15\n      passport:\n        specifier: 0.7.0\n        version: 0.7.0\n      passport-github2:\n        specifier: 0.1.12\n        version: 0.1.12\n      passport-google-oauth20:\n        specifier: 2.0.0\n        version: 2.0.0\n      passport-jwt:\n        specifier: 4.0.1\n        version: 4.0.1\n      passport-local:\n        specifier: 1.0.0\n        version: 1.0.0\n      passport-microsoft:\n        specifier: 2.1.0\n        version: 2.1.0\n      posthog-node:\n        specifier: 4.2.0\n        version: 4.2.0\n      prisma:\n        specifier: 5.20.0\n        version: 5.20.0\n      reflect-metadata:\n        specifier: 0.2.2\n        version: 0.2.2\n      rimraf:\n        specifier: 6.0.1\n        version: 6.0.1\n      rxjs:\n        specifier: 7.8.1\n        version: 7.8.1\n    devDependencies:\n      '@nestjs/cli':\n        specifier: 10.4.5\n        version: 10.4.5(@swc/core@1.4.2)\n      '@nestjs/schematics':\n        specifier: 10.1.4\n        version: 10.1.4(chokidar@3.6.0)(typescript@5.5.4)\n      '@nestjs/testing':\n        specifier: 10.4.4\n        version: 10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/platform-express@10.4.4(@nestjs/common@10.4.4(class-transformer@0.5.1)(class-validator@0.14.1)(reflect-metadata@0.2.2)(rxjs@7.8.1))(@nestjs/core@10.4.4))\n      '@relmify/jest-fp-ts':\n        specifier: 2.1.1\n        version: 2.1.1(fp-ts@2.16.9)(io-ts@2.2.21(fp-ts@2.16.9))\n      '@types/bcrypt':\n        specifier: 5.0.2\n        version: 5.0.2\n      '@types/cookie':\n        specifier: 0.6.0\n        version: 0.6.0\n      '@types/cookie-parser':\n        specifier: 1.4.7\n        version: 1.4.7\n      '@types/express':\n        specifier: 5.0.0\n        version: 5.0.0\n      '@types/jest':\n        specifier: 29.5.13\n        version: 29.5.13\n      '@types/luxon':\n        specifier: 3.4.2\n        version: 3.4.2\n      '@types/node':\n        specifier: 22.7.5\n        version: 22.7.5\n      '@types/nodemailer':\n        specifier: 6.4.16\n        version: 6.4.16\n      '@types/passport-github2':\n        specifier: 1.2.9\n        version: 1.2.9\n      '@types/passport-google-oauth20':\n        specifier: 2.0.16\n        version: 2.0.16\n      '@types/passport-jwt':\n        specifier: 4.0.1\n        version: 4.0.1\n      '@types/passport-microsoft':\n        specifier: 1.0.3\n        version: 1.0.3\n      '@types/supertest':\n        specifier: 6.0.2\n        version: 6.0.2\n      '@typescript-eslint/eslint-plugin':\n        specifier: 8.8.1\n        version: 8.8.1(@typescript-eslint/parser@8.8.1(eslint@8.57.0)(typescript@5.5.4))(eslint@8.57.0)(typescript@5.5.4)\n      '@typescript-eslint/parser':\n        specifier: 8.8.1\n        version: 8.8.1(eslint@8.57.0)(typescript@5.5.4)\n      cross-env:\n        specifier: 7.0.3\n        version: 7.0.3\n      eslint:\n        specifier: 8.57.0\n        version: 8.57.0\n      eslint-config-prettier:\n        specifier: 9.1.0\n        version: 9.1.0(eslint@8.57.0)\n      eslint-plugin-prettier:\n        specifier: 5.2.1\n        version: 5.2.1(@types/eslint@8.56.10)(eslint-config-prettier@9.1.0(eslint@8.57.0))(eslint@8.57.0)(prettier@3.3.3)\n      jest:\n        specifier: 29.7.0\n        version: 29.7.0(@types/node@22.7.5)(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.5)(typescript@5.5.4))\n      jest-mock-extended:\n        specifier: 4.0.0-beta1\n        version: 4.0.0-beta1(@jest/globals@29.7.0)(jest@29.7.0(@types/node@22.7.5)(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.5)(typescript@5.5.4)))(typescript@5.5.4)\n      jwt:\n        specifier: link:@types/nestjs/jwt\n        version: link:@types/nestjs/jwt\n      prettier:\n        specifier: 3.3.3\n        version: 3.3.3\n      source-map-support:\n        specifier: 0.5.21\n        version: 0.5.21\n      supertest:\n        specifier: 7.0.0\n        version: 7.0.0\n      ts-jest:\n        specifier: 29.2.5\n        version: 29.2.5(@babel/core@7.25.7)(@jest/transform@29.7.0)(@jest/types@29.6.3)(babel-jest@29.7.0(@babel/core@7.25.7))(jest@29.7.0(@types/node@22.7.5)(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.5)(typescript@5.5.4)))(typescript@5.5.4)\n      ts-loader:\n        specifier: 9.5.1\n        version: 9.5.1(typescript@5.5.4)(webpack@5.94.0(@swc/core@1.4.2))\n      ts-node:\n        specifier: 10.9.2\n        version: 10.9.2(@swc/core@1.4.2)(@types/node@22.7.5)(typescript@5.5.4)\n      tsconfig-paths:\n        specifier: 4.2.0\n        version: 4.2.0\n      typescript:\n        specifier: 5.5.4\n        version: 5.5.4\n\n  packages/hoppscotch-cli:\n    dependencies:\n      aws4fetch:\n        specifier: 1.0.20\n        version: 1.0.20\n      axios:\n        specifier: 1.7.7\n        version: 1.7.7\n      chalk:\n        specifier: 5.3.0\n        version: 5.3.0\n      commander:\n        specifier: 12.1.0\n        version: 12.1.0\n      isolated-vm:\n        specifier: 5.0.1\n        version: 5.0.1\n      js-md5:\n        specifier: 0.8.3\n        version: 0.8.3\n      lodash-es:\n        specifier: 4.17.21\n        version: 4.17.21\n      papaparse:\n        specifier: 5.4.1\n        version: 5.4.1\n      qs:\n        specifier: 6.13.0\n        version: 6.13.0\n      verzod:\n        specifier: 0.2.3\n        version: 0.2.3(zod@3.23.8)\n      xmlbuilder2:\n        specifier: 3.1.1\n        version: 3.1.1\n      zod:\n        specifier: 3.23.8\n        version: 3.23.8\n    devDependencies:\n      '@hoppscotch/data':\n        specifier: workspace:^\n        version: link:../hoppscotch-data\n      '@hoppscotch/js-sandbox':\n        specifier: workspace:^\n        version: link:../hoppscotch-js-sandbox\n      '@relmify/jest-fp-ts':\n        specifier: 2.1.1\n        version: 2.1.1(fp-ts@2.16.9)(io-ts@2.2.21(fp-ts@2.16.9))\n      '@types/lodash-es':\n        specifier: 4.17.12\n        version: 4.17.12\n      '@types/papaparse':\n        specifier: 5.3.14\n        version: 5.3.14\n      '@types/qs':\n        specifier: 6.9.16\n        version: 6.9.16\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      prettier:\n        specifier: 3.3.3\n        version: 3.3.3\n      semver:\n        specifier: 7.6.3\n        version: 7.6.3\n      tsup:\n        specifier: 8.3.0\n        version: 8.3.0(@swc/core@1.4.2)(jiti@2.3.3)(postcss@8.4.47)(typescript@5.6.3)(yaml@2.5.1)\n      typescript:\n        specifier: 5.6.3\n        version: 5.6.3\n      vitest:\n        specifier: 2.1.2\n        version: 2.1.2(@types/node@22.7.6)(jsdom@25.0.1(canvas@2.11.2))(sass@1.80.3)(terser@5.34.1)\n\n  packages/hoppscotch-common:\n    dependencies:\n      '@apidevtools/swagger-parser':\n        specifier: 10.1.0\n        version: 10.1.0(openapi-types@12.1.3)\n      '@codemirror/autocomplete':\n        specifier: 6.18.1\n        version: 6.18.1(@codemirror/language@6.10.1)(@codemirror/state@6.4.1)(@codemirror/view@6.25.1)(@lezer/common@1.2.1)\n      '@codemirror/commands':\n        specifier: 6.7.0\n        version: 6.7.0\n      '@codemirror/lang-javascript':\n        specifier: 6.2.2\n        version: 6.2.2\n      '@codemirror/lang-json':\n        specifier: 6.0.1\n        version: 6.0.1\n      '@codemirror/lang-xml':\n        specifier: 6.1.0\n        version: 6.1.0\n      '@codemirror/language':\n        specifier: 6.10.1\n        version: 6.10.1\n      '@codemirror/legacy-modes':\n        specifier: 6.4.1\n        version: 6.4.1\n      '@codemirror/lint':\n        specifier: 6.8.2\n        version: 6.8.2\n      '@codemirror/merge':\n        specifier: 6.7.2\n        version: 6.7.2\n      '@codemirror/search':\n        specifier: 6.5.6\n        version: 6.5.6\n      '@codemirror/state':\n        specifier: 6.4.1\n        version: 6.4.1\n      '@codemirror/view':\n        specifier: 6.25.1\n        version: 6.25.1\n      '@hoppscotch/codemirror-lang-graphql':\n        specifier: workspace:^\n        version: link:../codemirror-lang-graphql\n      '@hoppscotch/data':\n        specifier: workspace:^\n        version: link:../hoppscotch-data\n      '@hoppscotch/httpsnippet':\n        specifier: 3.0.6\n        version: 3.0.6\n      '@hoppscotch/js-sandbox':\n        specifier: workspace:^\n        version: link:../hoppscotch-js-sandbox\n      '@hoppscotch/ui':\n        specifier: 0.2.2\n        version: 0.2.2(eslint@8.57.0)(terser@5.34.1)(typescript@5.3.3)(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue@3.5.12(typescript@5.3.3))\n      '@hoppscotch/vue-toasted':\n        specifier: 0.1.0\n        version: 0.1.0(vue@3.5.12(typescript@5.3.3))\n      '@lezer/highlight':\n        specifier: 1.2.0\n        version: 1.2.0\n      '@noble/curves':\n        specifier: 1.6.0\n        version: 1.6.0\n      '@scure/base':\n        specifier: 1.1.9\n        version: 1.1.9\n      '@shopify/lang-jsonc':\n        specifier: 1.0.0\n        version: 1.0.0\n      '@unhead/vue':\n        specifier: 1.11.10\n        version: 1.11.10(vue@3.5.12(typescript@5.3.3))\n      '@urql/core':\n        specifier: 5.0.6\n        version: 5.0.6(graphql@16.9.0)\n      '@urql/devtools':\n        specifier: 2.0.3\n        version: 2.0.3(@urql/core@5.0.6(graphql@16.9.0))(graphql@16.9.0)\n      '@urql/exchange-auth':\n        specifier: 2.2.0\n        version: 2.2.0(@urql/core@5.0.6(graphql@16.9.0))\n      '@vueuse/core':\n        specifier: 11.1.0\n        version: 11.1.0(vue@3.5.12(typescript@5.3.3))\n      acorn-walk:\n        specifier: 8.3.4\n        version: 8.3.4\n      aws4fetch:\n        specifier: 1.0.20\n        version: 1.0.20\n      axios:\n        specifier: 1.7.7\n        version: 1.7.7\n      buffer:\n        specifier: 6.0.3\n        version: 6.0.3\n      cookie-es:\n        specifier: 1.2.2\n        version: 1.2.2\n      dioc:\n        specifier: 3.0.2\n        version: 3.0.2(vue@3.5.12(typescript@5.3.3))\n      esprima:\n        specifier: 4.0.1\n        version: 4.0.1\n      events:\n        specifier: 3.3.0\n        version: 3.3.0\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      globalthis:\n        specifier: 1.0.4\n        version: 1.0.4\n      graphql:\n        specifier: 16.9.0\n        version: 16.9.0\n      graphql-language-service-interface:\n        specifier: 2.10.2\n        version: 2.10.2(@types/node@22.7.6)(graphql@16.9.0)\n      graphql-tag:\n        specifier: 2.12.6\n        version: 2.12.6(graphql@16.9.0)\n      insomnia-importers:\n        specifier: 3.6.0\n        version: 3.6.0(openapi-types@12.1.3)\n      io-ts:\n        specifier: 2.2.21\n        version: 2.2.21(fp-ts@2.16.9)\n      js-md5:\n        specifier: 0.8.3\n        version: 0.8.3\n      js-yaml:\n        specifier: 4.1.0\n        version: 4.1.0\n      jsonc-parser:\n        specifier: 3.3.1\n        version: 3.3.1\n      jsonpath-plus:\n        specifier: 10.0.0\n        version: 10.0.0\n      lodash-es:\n        specifier: 4.17.21\n        version: 4.17.21\n      lossless-json:\n        specifier: 4.0.2\n        version: 4.0.2\n      minisearch:\n        specifier: 7.1.0\n        version: 7.1.0\n      nprogress:\n        specifier: 0.2.0\n        version: 0.2.0\n      paho-mqtt:\n        specifier: 1.1.0\n        version: 1.1.0\n      path:\n        specifier: 0.12.7\n        version: 0.12.7\n      postman-collection:\n        specifier: 4.5.0\n        version: 4.5.0\n      process:\n        specifier: 0.11.10\n        version: 0.11.10\n      qs:\n        specifier: 6.13.0\n        version: 6.13.0\n      quicktype-core:\n        specifier: 23.0.170\n        version: 23.0.170\n      rxjs:\n        specifier: 7.8.1\n        version: 7.8.1\n      set-cookie-parser:\n        specifier: 2.7.0\n        version: 2.7.0\n      set-cookie-parser-es:\n        specifier: 1.0.5\n        version: 1.0.5\n      socket.io-client-v2:\n        specifier: npm:socket.io-client@2.5.0\n        version: socket.io-client@2.5.0\n      socket.io-client-v3:\n        specifier: npm:socket.io-client@3.1.3\n        version: socket.io-client@4.8.0\n      socket.io-client-v4:\n        specifier: npm:socket.io-client@4.8.0\n        version: socket.io-client@4.8.0\n      socketio-wildcard:\n        specifier: 2.0.0\n        version: 2.0.0\n      splitpanes:\n        specifier: 3.1.5\n        version: 3.1.5\n      stream-browserify:\n        specifier: 3.0.0\n        version: 3.0.0\n      subscriptions-transport-ws:\n        specifier: 0.11.0\n        version: 0.11.0(graphql@16.9.0)\n      tern:\n        specifier: 0.24.3\n        version: 0.24.3\n      timers:\n        specifier: 0.1.1\n        version: 0.1.1\n      tippy.js:\n        specifier: 6.3.7\n        version: 6.3.7\n      url:\n        specifier: 0.11.4\n        version: 0.11.4\n      util:\n        specifier: 0.12.5\n        version: 0.12.5\n      uuid:\n        specifier: 10.0.0\n        version: 10.0.0\n      verzod:\n        specifier: 0.2.3\n        version: 0.2.3(zod@3.23.8)\n      vue:\n        specifier: 3.5.12\n        version: 3.5.12(typescript@5.3.3)\n      vue-i18n:\n        specifier: 10.0.4\n        version: 10.0.4(vue@3.5.12(typescript@5.3.3))\n      vue-pdf-embed:\n        specifier: 2.1.0\n        version: 2.1.0(vue@3.5.12(typescript@5.3.3))\n      vue-router:\n        specifier: 4.4.5\n        version: 4.4.5(vue@3.5.12(typescript@5.3.3))\n      vue-tippy:\n        specifier: 6.5.0\n        version: 6.5.0(vue@3.5.12(typescript@5.3.3))\n      vuedraggable-es:\n        specifier: 4.1.1\n        version: 4.1.1(vue@3.5.12(typescript@5.3.3))\n      wonka:\n        specifier: 6.3.4\n        version: 6.3.4\n      workbox-window:\n        specifier: 7.1.0\n        version: 7.1.0\n      xml-formatter:\n        specifier: 3.6.3\n        version: 3.6.3\n      yargs-parser:\n        specifier: 21.1.1\n        version: 21.1.1\n      zod:\n        specifier: 3.23.8\n        version: 3.23.8\n    devDependencies:\n      '@esbuild-plugins/node-globals-polyfill':\n        specifier: 0.2.3\n        version: 0.2.3(esbuild@0.24.0)\n      '@esbuild-plugins/node-modules-polyfill':\n        specifier: 0.2.2\n        version: 0.2.2(esbuild@0.24.0)\n      '@graphql-codegen/add':\n        specifier: 5.0.3\n        version: 5.0.3(graphql@16.9.0)\n      '@graphql-codegen/cli':\n        specifier: 5.0.3\n        version: 5.0.3(@parcel/watcher@2.4.1)(@types/node@22.7.6)(graphql@16.9.0)(typescript@5.3.3)\n      '@graphql-codegen/typed-document-node':\n        specifier: 5.0.10\n        version: 5.0.10(graphql@16.9.0)\n      '@graphql-codegen/typescript':\n        specifier: 4.1.0\n        version: 4.1.0(graphql@16.9.0)\n      '@graphql-codegen/typescript-operations':\n        specifier: 4.3.0\n        version: 4.3.0(graphql@16.9.0)\n      '@graphql-codegen/typescript-urql-graphcache':\n        specifier: 3.1.0\n        version: 3.1.0(@urql/exchange-graphcache@6.5.1(graphql@16.9.0))(graphql-tag@2.12.6(graphql@16.9.0))(graphql@16.9.0)\n      '@graphql-codegen/urql-introspection':\n        specifier: 3.0.0\n        version: 3.0.0(graphql@16.9.0)\n      '@graphql-typed-document-node/core':\n        specifier: 3.2.0\n        version: 3.2.0(graphql@16.9.0)\n      '@iconify-json/lucide':\n        specifier: 1.2.9\n        version: 1.2.9\n      '@intlify/vite-plugin-vue-i18n':\n        specifier: 7.0.0\n        version: 7.0.0(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue-i18n@10.0.4(vue@3.5.12(typescript@5.3.3)))\n      '@relmify/jest-fp-ts':\n        specifier: 2.1.1\n        version: 2.1.1(fp-ts@2.16.9)(io-ts@2.2.21(fp-ts@2.16.9))\n      '@rushstack/eslint-patch':\n        specifier: 1.10.4\n        version: 1.10.4\n      '@types/har-format':\n        specifier: 1.2.16\n        version: 1.2.16\n      '@types/js-yaml':\n        specifier: 4.0.9\n        version: 4.0.9\n      '@types/lodash-es':\n        specifier: 4.17.12\n        version: 4.17.12\n      '@types/lossless-json':\n        specifier: 1.0.4\n        version: 1.0.4\n      '@types/nprogress':\n        specifier: 0.2.3\n        version: 0.2.3\n      '@types/paho-mqtt':\n        specifier: 1.0.10\n        version: 1.0.10\n      '@types/postman-collection':\n        specifier: 3.5.10\n        version: 3.5.10\n      '@types/qs':\n        specifier: 6.9.16\n        version: 6.9.16\n      '@types/splitpanes':\n        specifier: 2.2.6\n        version: 2.2.6(typescript@5.3.3)\n      '@types/uuid':\n        specifier: 10.0.0\n        version: 10.0.0\n      '@types/yargs-parser':\n        specifier: 21.0.3\n        version: 21.0.3\n      '@typescript-eslint/eslint-plugin':\n        specifier: 8.9.0\n        version: 8.9.0(@typescript-eslint/parser@8.9.0(eslint@8.57.0)(typescript@5.3.3))(eslint@8.57.0)(typescript@5.3.3)\n      '@typescript-eslint/parser':\n        specifier: 8.9.0\n        version: 8.9.0(eslint@8.57.0)(typescript@5.3.3)\n      '@urql/exchange-graphcache':\n        specifier: 6.5.1\n        version: 6.5.1(graphql@16.9.0)\n      '@vitejs/plugin-vue':\n        specifier: 5.1.4\n        version: 5.1.4(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue@3.5.12(typescript@5.3.3))\n      '@vue/compiler-sfc':\n        specifier: 3.5.12\n        version: 3.5.12\n      '@vue/eslint-config-typescript':\n        specifier: 13.0.0\n        version: 13.0.0(eslint-plugin-vue@9.29.0(eslint@8.57.0))(eslint@8.57.0)(typescript@5.3.3)\n      '@vue/runtime-core':\n        specifier: 3.5.12\n        version: 3.5.12\n      autoprefixer:\n        specifier: 10.4.20\n        version: 10.4.20(postcss@8.4.47)\n      cross-env:\n        specifier: 7.0.3\n        version: 7.0.3\n      dotenv:\n        specifier: 16.4.5\n        version: 16.4.5\n      eslint:\n        specifier: 8.57.0\n        version: 8.57.0\n      eslint-plugin-prettier:\n        specifier: 5.2.1\n        version: 5.2.1(@types/eslint@8.56.10)(eslint-config-prettier@9.1.0(eslint@8.57.0))(eslint@8.57.0)(prettier@3.3.3)\n      eslint-plugin-vue:\n        specifier: 9.29.0\n        version: 9.29.0(eslint@8.57.0)\n      glob:\n        specifier: 11.0.0\n        version: 11.0.0\n      jsdom:\n        specifier: 25.0.1\n        version: 25.0.1(canvas@2.11.2)\n      npm-run-all:\n        specifier: 4.1.5\n        version: 4.1.5\n      openapi-types:\n        specifier: 12.1.3\n        version: 12.1.3\n      postcss:\n        specifier: 8.4.47\n        version: 8.4.47\n      prettier:\n        specifier: 3.3.3\n        version: 3.3.3\n      prettier-plugin-tailwindcss:\n        specifier: 0.6.8\n        version: 0.6.8(prettier@3.3.3)\n      rollup-plugin-polyfill-node:\n        specifier: 0.13.0\n        version: 0.13.0(rollup@4.24.0)\n      sass:\n        specifier: 1.79.5\n        version: 1.79.5\n      tailwindcss:\n        specifier: 3.4.14\n        version: 3.4.14(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.6)(typescript@5.3.3))\n      typescript:\n        specifier: 5.3.3\n        version: 5.3.3\n      unplugin-fonts:\n        specifier: 1.1.1\n        version: 1.1.1(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))\n      unplugin-icons:\n        specifier: 0.19.3\n        version: 0.19.3(@vue/compiler-sfc@3.5.12)(vue-template-compiler@2.7.16)(webpack-sources@3.2.3)\n      unplugin-vue-components:\n        specifier: 0.27.4\n        version: 0.27.4(@babel/parser@7.25.7)(rollup@4.24.0)(vue@3.5.12(typescript@5.3.3))(webpack-sources@3.2.3)\n      vite:\n        specifier: 5.4.9\n        version: 5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1)\n      vite-plugin-checker:\n        specifier: 0.6.4\n        version: 0.6.4(eslint@8.57.0)(meow@13.2.0)(optionator@0.9.4)(typescript@5.3.3)(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue-tsc@1.8.24(typescript@5.3.3))\n      vite-plugin-fonts:\n        specifier: 0.7.0\n        version: 0.7.0(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))\n      vite-plugin-html-config:\n        specifier: 2.0.2\n        version: 2.0.2(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))\n      vite-plugin-pages:\n        specifier: 0.32.3\n        version: 0.32.3(@vue/compiler-sfc@3.5.12)(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.3.3)))\n      vite-plugin-pages-sitemap:\n        specifier: 1.7.1\n        version: 1.7.1\n      vite-plugin-pwa:\n        specifier: 0.20.5\n        version: 0.20.5(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(workbox-build@7.1.0(@types/babel__core@7.20.5))(workbox-window@7.1.0)\n      vite-plugin-vue-layouts:\n        specifier: 0.11.0\n        version: 0.11.0(vite@5.4.9(@types/node@22.7.6)(sass@1.79.5)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.3.3)))(vue@3.5.12(typescript@5.3.3))\n      vitest:\n        specifier: 2.1.3\n        version: 2.1.3(@types/node@22.7.6)(jsdom@25.0.1(canvas@2.11.2))(sass@1.79.5)(terser@5.34.1)\n      vue-tsc:\n        specifier: 1.8.24\n        version: 1.8.24(typescript@5.3.3)\n\n  packages/hoppscotch-data:\n    dependencies:\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      io-ts:\n        specifier: 2.2.21\n        version: 2.2.21(fp-ts@2.16.9)\n      lodash:\n        specifier: 4.17.21\n        version: 4.17.21\n      parser-ts:\n        specifier: 0.7.0\n        version: 0.7.0(fp-ts@2.16.9)\n      uuid:\n        specifier: 10.0.0\n        version: 10.0.0\n      verzod:\n        specifier: 0.2.3\n        version: 0.2.3(zod@3.23.8)\n      zod:\n        specifier: 3.23.8\n        version: 3.23.8\n    devDependencies:\n      '@types/lodash':\n        specifier: 4.17.10\n        version: 4.17.10\n      '@types/uuid':\n        specifier: 10.0.0\n        version: 10.0.0\n      typescript:\n        specifier: 5.6.3\n        version: 5.6.3\n      vite:\n        specifier: 5.4.9\n        version: 5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1)\n\n  packages/hoppscotch-js-sandbox:\n    dependencies:\n      '@hoppscotch/data':\n        specifier: workspace:^\n        version: link:../hoppscotch-data\n      '@types/lodash-es':\n        specifier: 4.17.12\n        version: 4.17.12\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      isolated-vm:\n        specifier: 5.0.1\n        version: 5.0.1\n      lodash:\n        specifier: 4.17.21\n        version: 4.17.21\n      lodash-es:\n        specifier: 4.17.21\n        version: 4.17.21\n    devDependencies:\n      '@digitak/esrun':\n        specifier: 3.2.26\n        version: 3.2.26\n      '@relmify/jest-fp-ts':\n        specifier: 2.1.1\n        version: 2.1.1(fp-ts@2.16.9)(io-ts@2.2.21(fp-ts@2.16.9))\n      '@types/jest':\n        specifier: 29.5.13\n        version: 29.5.13\n      '@types/lodash':\n        specifier: 4.17.10\n        version: 4.17.10\n      '@types/node':\n        specifier: 22.7.5\n        version: 22.7.5\n      '@typescript-eslint/eslint-plugin':\n        specifier: 8.9.0\n        version: 8.9.0(@typescript-eslint/parser@8.9.0(eslint@8.57.0)(typescript@5.5.4))(eslint@8.57.0)(typescript@5.5.4)\n      '@typescript-eslint/parser':\n        specifier: 8.9.0\n        version: 8.9.0(eslint@8.57.0)(typescript@5.5.4)\n      eslint:\n        specifier: 8.57.0\n        version: 8.57.0\n      eslint-config-prettier:\n        specifier: 9.1.0\n        version: 9.1.0(eslint@8.57.0)\n      eslint-plugin-prettier:\n        specifier: 5.2.1\n        version: 5.2.1(@types/eslint@8.56.10)(eslint-config-prettier@9.1.0(eslint@8.57.0))(eslint@8.57.0)(prettier@3.3.3)\n      io-ts:\n        specifier: 2.2.21\n        version: 2.2.21(fp-ts@2.16.9)\n      prettier:\n        specifier: 3.3.3\n        version: 3.3.3\n      typescript:\n        specifier: 5.5.4\n        version: 5.5.4\n      vite:\n        specifier: 5.4.9\n        version: 5.4.9(@types/node@22.7.5)(sass@1.80.3)(terser@5.34.1)\n      vitest:\n        specifier: 2.1.3\n        version: 2.1.3(@types/node@22.7.5)(jsdom@25.0.1(canvas@2.11.2))(sass@1.80.3)(terser@5.34.1)\n\n  packages/hoppscotch-selfhost-desktop:\n    dependencies:\n      '@fontsource-variable/inter':\n        specifier: 5.0.15\n        version: 5.0.15\n      '@fontsource-variable/material-symbols-rounded':\n        specifier: 5.0.16\n        version: 5.0.16\n      '@fontsource-variable/roboto-mono':\n        specifier: 5.0.16\n        version: 5.0.16\n      '@hoppscotch/common':\n        specifier: workspace:^\n        version: link:../hoppscotch-common\n      '@hoppscotch/data':\n        specifier: workspace:^\n        version: link:../hoppscotch-data\n      '@platform/auth':\n        specifier: 0.1.106\n        version: 0.1.106\n      '@tauri-apps/api':\n        specifier: 1.5.1\n        version: 1.5.1\n      '@tauri-apps/cli':\n        specifier: 1.5.6\n        version: 1.5.6\n      '@vueuse/core':\n        specifier: 10.5.0\n        version: 10.5.0(vue@3.5.12(typescript@4.9.5))\n      axios:\n        specifier: 1.7.5\n        version: 1.7.5\n      buffer:\n        specifier: 6.0.3\n        version: 6.0.3\n      dioc:\n        specifier: 3.0.2\n        version: 3.0.2(vue@3.5.12(typescript@4.9.5))\n      environments.api:\n        specifier: link:@platform/environments/environments.api\n        version: link:@platform/environments/environments.api\n      event:\n        specifier: link:@tauri-apps/api/event\n        version: link:@tauri-apps/api/event\n      fp-ts:\n        specifier: 2.16.1\n        version: 2.16.1\n      lodash-es:\n        specifier: 4.17.21\n        version: 4.17.21\n      process:\n        specifier: 0.11.10\n        version: 0.11.10\n      rxjs:\n        specifier: 7.8.1\n        version: 7.8.1\n      shell:\n        specifier: link:@tauri-apps/api/shell\n        version: link:@tauri-apps/api/shell\n      stream-browserify:\n        specifier: 3.0.0\n        version: 3.0.0\n      tauri:\n        specifier: link:@tauri-apps/api/tauri\n        version: link:@tauri-apps/api/tauri\n      tauri-plugin-store-api:\n        specifier: 0.0.0\n        version: 0.0.0\n      util:\n        specifier: 0.12.5\n        version: 0.12.5\n      verzod:\n        specifier: 0.2.3\n        version: 0.2.3(zod@3.22.4)\n      vue:\n        specifier: 3.5.12\n        version: 3.5.12(typescript@4.9.5)\n      workbox-window:\n        specifier: 6.6.0\n        version: 6.6.0\n      zod:\n        specifier: 3.22.4\n        version: 3.22.4\n    devDependencies:\n      '@graphql-codegen/add':\n        specifier: 5.0.0\n        version: 5.0.0(graphql@16.9.0)\n      '@graphql-codegen/cli':\n        specifier: 5.0.0\n        version: 5.0.0(@parcel/watcher@2.4.1)(@types/node@18.18.8)(graphql@16.9.0)(typescript@4.9.5)\n      '@graphql-codegen/typed-document-node':\n        specifier: 5.0.1\n        version: 5.0.1(graphql@16.9.0)\n      '@graphql-codegen/typescript':\n        specifier: 4.0.1\n        version: 4.0.1(graphql@16.9.0)\n      '@graphql-codegen/typescript-operations':\n        specifier: 4.0.1\n        version: 4.0.1(graphql@16.9.0)\n      '@graphql-codegen/typescript-urql-graphcache':\n        specifier: 2.4.5\n        version: 2.4.5(@urql/exchange-graphcache@7.2.0(@urql/core@5.0.6(graphql@16.9.0))(graphql@16.9.0))(graphql-tag@2.12.6(graphql@16.9.0))(graphql@16.9.0)\n      '@graphql-codegen/urql-introspection':\n        specifier: 2.2.1\n        version: 2.2.1(graphql@16.9.0)\n      '@graphql-typed-document-node/core':\n        specifier: 3.2.0\n        version: 3.2.0(graphql@16.9.0)\n      '@iconify-json/lucide':\n        specifier: 1.1.144\n        version: 1.1.144\n      '@intlify/vite-plugin-vue-i18n':\n        specifier: 6.0.1\n        version: 6.0.1(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))(vue-i18n@10.0.4(vue@3.5.12(typescript@4.9.5)))\n      '@rushstack/eslint-patch':\n        specifier: 1.3.3\n        version: 1.3.3\n      '@types/lodash-es':\n        specifier: 4.17.10\n        version: 4.17.10\n      '@types/node':\n        specifier: 18.18.8\n        version: 18.18.8\n      '@typescript-eslint/eslint-plugin':\n        specifier: 5.62.0\n        version: 5.62.0(@typescript-eslint/parser@5.62.0(eslint@8.47.0)(typescript@4.9.5))(eslint@8.47.0)(typescript@4.9.5)\n      '@typescript-eslint/parser':\n        specifier: 5.62.0\n        version: 5.62.0(eslint@8.47.0)(typescript@4.9.5)\n      '@vitejs/plugin-legacy':\n        specifier: 2.3.0\n        version: 2.3.0(terser@5.34.1)(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      '@vitejs/plugin-vue':\n        specifier: 4.3.1\n        version: 4.3.1(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@4.9.5))\n      '@vue/eslint-config-typescript':\n        specifier: 11.0.3\n        version: 11.0.3(eslint-plugin-vue@9.17.0(eslint@8.47.0))(eslint@8.47.0)(typescript@4.9.5)\n      autoprefixer:\n        specifier: 10.4.16\n        version: 10.4.16(postcss@8.4.32)\n      cross-env:\n        specifier: 7.0.3\n        version: 7.0.3\n      eslint:\n        specifier: 8.47.0\n        version: 8.47.0\n      eslint-plugin-prettier:\n        specifier: 4.2.1\n        version: 4.2.1(eslint@8.47.0)(prettier@3.3.3)\n      eslint-plugin-vue:\n        specifier: 9.17.0\n        version: 9.17.0(eslint@8.47.0)\n      npm-run-all:\n        specifier: 4.1.5\n        version: 4.1.5\n      postcss:\n        specifier: 8.4.32\n        version: 8.4.32\n      tailwindcss:\n        specifier: 3.3.6\n        version: 3.3.6(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@18.18.8)(typescript@4.9.5))\n      typescript:\n        specifier: 4.9.5\n        version: 4.9.5\n      unplugin-fonts:\n        specifier: 1.1.1\n        version: 1.1.1(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      unplugin-icons:\n        specifier: 0.14.9\n        version: 0.14.9(@vue/compiler-sfc@3.5.12)(vue-template-compiler@2.7.16)\n      unplugin-vue-components:\n        specifier: 0.21.0\n        version: 0.21.0(@babel/parser@7.25.7)(esbuild@0.24.0)(rollup@3.29.4)(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@4.9.5))(webpack@5.94.0(@swc/core@1.4.2)(esbuild@0.24.0))\n      vite:\n        specifier: 4.5.0\n        version: 4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1)\n      vite-plugin-html-config:\n        specifier: 1.0.11\n        version: 1.0.11(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-inspect:\n        specifier: 0.7.38\n        version: 0.7.38(rollup@3.29.4)(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-pages:\n        specifier: 0.26.0\n        version: 0.26.0(@vue/compiler-sfc@3.5.12)(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-pages-sitemap:\n        specifier: 1.6.1\n        version: 1.6.1\n      vite-plugin-pwa:\n        specifier: 0.13.1\n        version: 0.13.1(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))(workbox-build@7.1.0(@types/babel__core@7.20.5))(workbox-window@6.6.0)\n      vite-plugin-static-copy:\n        specifier: 0.12.0\n        version: 0.12.0(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-vue-layouts:\n        specifier: 0.7.0\n        version: 0.7.0(vite@4.5.0(@types/node@18.18.8)(sass@1.80.3)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@4.9.5)))(vue@3.5.12(typescript@4.9.5))\n      vue-tsc:\n        specifier: 1.8.8\n        version: 1.8.8(typescript@4.9.5)\n\n  packages/hoppscotch-selfhost-web:\n    dependencies:\n      '@fontsource-variable/inter':\n        specifier: 5.1.0\n        version: 5.1.0\n      '@fontsource-variable/material-symbols-rounded':\n        specifier: 5.1.2\n        version: 5.1.2\n      '@fontsource-variable/roboto-mono':\n        specifier: 5.1.0\n        version: 5.1.0\n      '@hoppscotch/common':\n        specifier: workspace:^\n        version: link:../hoppscotch-common\n      '@hoppscotch/data':\n        specifier: workspace:^\n        version: link:../hoppscotch-data\n      '@hoppscotch/ui':\n        specifier: 0.2.1\n        version: 0.2.1(eslint@8.57.0)(terser@5.34.1)(typescript@5.3.3)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.3.3))\n      '@import-meta-env/unplugin':\n        specifier: 0.6.0\n        version: 0.6.0(@import-meta-env/cli@0.7.0)(webpack-sources@3.2.3)\n      axios:\n        specifier: 1.7.7\n        version: 1.7.7\n      buffer:\n        specifier: 6.0.3\n        version: 6.0.3\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      process:\n        specifier: 0.11.10\n        version: 0.11.10\n      rxjs:\n        specifier: 7.8.1\n        version: 7.8.1\n      stream-browserify:\n        specifier: 3.0.0\n        version: 3.0.0\n      util:\n        specifier: 0.12.5\n        version: 0.12.5\n      verzod:\n        specifier: 0.2.3\n        version: 0.2.3(zod@3.23.8)\n      vue:\n        specifier: 3.5.12\n        version: 3.5.12(typescript@5.3.3)\n      workbox-window:\n        specifier: 7.1.0\n        version: 7.1.0\n      zod:\n        specifier: 3.23.8\n        version: 3.23.8\n    devDependencies:\n      '@graphql-codegen/add':\n        specifier: 5.0.3\n        version: 5.0.3(graphql@16.9.0)\n      '@graphql-codegen/cli':\n        specifier: 5.0.3\n        version: 5.0.3(@parcel/watcher@2.4.1)(@types/node@22.7.6)(graphql@16.9.0)(typescript@5.3.3)\n      '@graphql-codegen/typed-document-node':\n        specifier: 5.0.10\n        version: 5.0.10(graphql@16.9.0)\n      '@graphql-codegen/typescript':\n        specifier: 4.1.0\n        version: 4.1.0(graphql@16.9.0)\n      '@graphql-codegen/typescript-operations':\n        specifier: 4.3.0\n        version: 4.3.0(graphql@16.9.0)\n      '@graphql-codegen/typescript-urql-graphcache':\n        specifier: 3.1.0\n        version: 3.1.0(@urql/exchange-graphcache@6.5.1(graphql@16.9.0))(graphql-tag@2.12.6(graphql@16.9.0))(graphql@16.9.0)\n      '@graphql-codegen/urql-introspection':\n        specifier: 3.0.0\n        version: 3.0.0(graphql@16.9.0)\n      '@graphql-typed-document-node/core':\n        specifier: 3.2.0\n        version: 3.2.0(graphql@16.9.0)\n      '@iconify-json/lucide':\n        specifier: 1.2.8\n        version: 1.2.8\n      '@intlify/vite-plugin-vue-i18n':\n        specifier: 7.0.0\n        version: 7.0.0(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue-i18n@10.0.4(vue@3.5.12(typescript@5.3.3)))\n      '@rushstack/eslint-patch':\n        specifier: 1.10.4\n        version: 1.10.4\n      '@typescript-eslint/eslint-plugin':\n        specifier: 8.9.0\n        version: 8.9.0(@typescript-eslint/parser@8.9.0(eslint@8.57.0)(typescript@5.3.3))(eslint@8.57.0)(typescript@5.3.3)\n      '@typescript-eslint/parser':\n        specifier: 8.9.0\n        version: 8.9.0(eslint@8.57.0)(typescript@5.3.3)\n      '@urql/exchange-graphcache':\n        specifier: 6.5.1\n        version: 6.5.1(graphql@16.9.0)\n      '@vitejs/plugin-legacy':\n        specifier: 5.4.2\n        version: 5.4.2(terser@5.34.1)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      '@vitejs/plugin-vue':\n        specifier: 5.1.4\n        version: 5.1.4(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.3.3))\n      '@vue/eslint-config-typescript':\n        specifier: 13.0.0\n        version: 13.0.0(eslint-plugin-vue@9.29.0(eslint@8.57.0))(eslint@8.57.0)(typescript@5.3.3)\n      autoprefixer:\n        specifier: 10.4.20\n        version: 10.4.20(postcss@8.4.47)\n      cross-env:\n        specifier: 7.0.3\n        version: 7.0.3\n      eslint:\n        specifier: 8.57.0\n        version: 8.57.0\n      eslint-plugin-prettier:\n        specifier: 5.2.1\n        version: 5.2.1(@types/eslint@8.56.10)(eslint-config-prettier@9.1.0(eslint@8.57.0))(eslint@8.57.0)(prettier@3.3.3)\n      eslint-plugin-vue:\n        specifier: 9.29.0\n        version: 9.29.0(eslint@8.57.0)\n      npm-run-all:\n        specifier: 4.1.5\n        version: 4.1.5\n      postcss:\n        specifier: 8.4.47\n        version: 8.4.47\n      prettier-plugin-tailwindcss:\n        specifier: 0.6.8\n        version: 0.6.8(prettier@3.3.3)\n      tailwindcss:\n        specifier: 3.4.13\n        version: 3.4.13(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.6)(typescript@5.3.3))\n      typescript:\n        specifier: 5.3.3\n        version: 5.3.3\n      unplugin-fonts:\n        specifier: 1.1.1\n        version: 1.1.1(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      unplugin-icons:\n        specifier: 0.19.3\n        version: 0.19.3(@vue/compiler-sfc@3.5.12)(vue-template-compiler@2.7.16)(webpack-sources@3.2.3)\n      unplugin-vue-components:\n        specifier: 0.27.4\n        version: 0.27.4(@babel/parser@7.25.7)(rollup@3.29.4)(vue@3.5.12(typescript@5.3.3))(webpack-sources@3.2.3)\n      vite:\n        specifier: 5.4.9\n        version: 5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1)\n      vite-plugin-fonts:\n        specifier: 0.7.0\n        version: 0.7.0(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-html-config:\n        specifier: 2.0.2\n        version: 2.0.2(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-inspect:\n        specifier: 0.8.7\n        version: 0.8.7(rollup@3.29.4)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-pages:\n        specifier: 0.32.3\n        version: 0.32.3(@vue/compiler-sfc@3.5.12)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.3.3)))\n      vite-plugin-pages-sitemap:\n        specifier: 1.7.1\n        version: 1.7.1\n      vite-plugin-pwa:\n        specifier: 0.20.5\n        version: 0.20.5(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(workbox-build@7.1.0(@types/babel__core@7.20.5))(workbox-window@7.1.0)\n      vite-plugin-static-copy:\n        specifier: 2.0.0\n        version: 2.0.0(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      vite-plugin-vue-layouts:\n        specifier: 0.11.0\n        version: 0.11.0(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.3.3)))(vue@3.5.12(typescript@5.3.3))\n      vue-tsc:\n        specifier: 2.1.6\n        version: 2.1.6(typescript@5.3.3)\n\n  packages/hoppscotch-sh-admin:\n    dependencies:\n      '@fontsource-variable/inter':\n        specifier: 5.1.0\n        version: 5.1.0\n      '@fontsource-variable/material-symbols-rounded':\n        specifier: 5.1.3\n        version: 5.1.3\n      '@fontsource-variable/roboto-mono':\n        specifier: 5.1.0\n        version: 5.1.0\n      '@graphql-typed-document-node/core':\n        specifier: 3.2.0\n        version: 3.2.0(graphql@16.9.0)\n      '@hoppscotch/ui':\n        specifier: 0.2.1\n        version: 0.2.1(eslint@9.12.0(jiti@2.3.3))(terser@5.34.1)(typescript@5.6.3)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.6.3))\n      '@hoppscotch/vue-toasted':\n        specifier: 0.1.0\n        version: 0.1.0(vue@3.5.12(typescript@5.6.3))\n      '@intlify/unplugin-vue-i18n':\n        specifier: 5.2.0\n        version: 5.2.0(@vue/compiler-dom@3.5.12)(eslint@9.12.0(jiti@2.3.3))(rollup@3.29.4)(typescript@5.6.3)(vue-i18n@10.0.4(vue@3.5.12(typescript@5.6.3)))(vue@3.5.12(typescript@5.6.3))(webpack-sources@3.2.3)\n      '@types/cors':\n        specifier: 2.8.17\n        version: 2.8.17\n      '@urql/exchange-auth':\n        specifier: 2.2.0\n        version: 2.2.0(@urql/core@5.0.6(graphql@16.9.0))\n      '@urql/vue':\n        specifier: 1.4.0\n        version: 1.4.0(@urql/core@5.0.6(graphql@16.9.0))(vue@3.5.12(typescript@5.6.3))\n      '@vueuse/core':\n        specifier: 11.1.0\n        version: 11.1.0(vue@3.5.12(typescript@5.6.3))\n      axios:\n        specifier: 1.7.7\n        version: 1.7.7\n      cors:\n        specifier: 2.8.5\n        version: 2.8.5\n      date-fns:\n        specifier: 4.1.0\n        version: 4.1.0\n      fp-ts:\n        specifier: 2.16.9\n        version: 2.16.9\n      graphql:\n        specifier: 16.9.0\n        version: 16.9.0\n      io-ts:\n        specifier: 2.2.21\n        version: 2.2.21(fp-ts@2.16.9)\n      lodash-es:\n        specifier: 4.17.21\n        version: 4.17.21\n      postcss:\n        specifier: 8.4.47\n        version: 8.4.47\n      prettier-plugin-tailwindcss:\n        specifier: 0.6.8\n        version: 0.6.8(prettier@3.3.3)\n      rxjs:\n        specifier: 7.8.1\n        version: 7.8.1\n      tailwindcss:\n        specifier: 3.4.14\n        version: 3.4.14(ts-node@10.9.2(@swc/core@1.4.2)(@types/node@22.7.6)(typescript@5.6.3))\n      tippy.js:\n        specifier: 6.3.7\n        version: 6.3.7\n      ts-node-dev:\n        specifier: 2.0.0\n        version: 2.0.0(@swc/core@1.4.2)(@types/node@22.7.6)(typescript@5.6.3)\n      unplugin-icons:\n        specifier: 0.19.3\n        version: 0.19.3(@vue/compiler-sfc@3.5.12)(vue-template-compiler@2.7.16)(webpack-sources@3.2.3)\n      unplugin-vue-components:\n        specifier: 0.27.4\n        version: 0.27.4(@babel/parser@7.25.7)(rollup@3.29.4)(vue@3.5.12(typescript@5.6.3))(webpack-sources@3.2.3)\n      vue:\n        specifier: 3.5.12\n        version: 3.5.12(typescript@5.6.3)\n      vue-i18n:\n        specifier: 10.0.4\n        version: 10.0.4(vue@3.5.12(typescript@5.6.3))\n      vue-router:\n        specifier: 4.4.5\n        version: 4.4.5(vue@3.5.12(typescript@5.6.3))\n      vue-tippy:\n        specifier: 6.5.0\n        version: 6.5.0(vue@3.5.12(typescript@5.6.3))\n    devDependencies:\n      '@graphql-codegen/cli':\n        specifier: 5.0.3\n        version: 5.0.3(@parcel/watcher@2.4.1)(@types/node@22.7.6)(graphql@16.9.0)(typescript@5.6.3)\n      '@graphql-codegen/client-preset':\n        specifier: 4.4.0\n        version: 4.4.0(graphql@16.9.0)\n      '@graphql-codegen/introspection':\n        specifier: 4.0.3\n        version: 4.0.3(graphql@16.9.0)\n      '@graphql-codegen/typed-document-node':\n        specifier: 5.0.10\n        version: 5.0.10(graphql@16.9.0)\n      '@graphql-codegen/typescript':\n        specifier: 4.1.0\n        version: 4.1.0(graphql@16.9.0)\n      '@graphql-codegen/typescript-document-nodes':\n        specifier: 4.0.10\n        version: 4.0.10(graphql@16.9.0)\n      '@graphql-codegen/typescript-operations':\n        specifier: 4.3.0\n        version: 4.3.0(graphql@16.9.0)\n      '@graphql-codegen/urql-introspection':\n        specifier: 3.0.0\n        version: 3.0.0(graphql@16.9.0)\n      '@iconify-json/lucide':\n        specifier: 1.2.10\n        version: 1.2.10\n      '@import-meta-env/cli':\n        specifier: 0.7.0\n        version: 0.7.0(@import-meta-env/unplugin@0.6.0)\n      '@import-meta-env/unplugin':\n        specifier: 0.6.0\n        version: 0.6.0(@import-meta-env/cli@0.7.0)(webpack-sources@3.2.3)\n      '@types/lodash-es':\n        specifier: 4.17.12\n        version: 4.17.12\n      '@vitejs/plugin-vue':\n        specifier: 5.1.4\n        version: 5.1.4(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue@3.5.12(typescript@5.6.3))\n      '@vue/compiler-sfc':\n        specifier: 3.5.12\n        version: 3.5.12\n      dotenv:\n        specifier: 16.4.5\n        version: 16.4.5\n      graphql-tag:\n        specifier: 2.12.6\n        version: 2.12.6(graphql@16.9.0)\n      hoppscotch-backend:\n        specifier: workspace:^\n        version: link:../hoppscotch-backend\n      npm-run-all:\n        specifier: 4.1.5\n        version: 4.1.5\n      sass:\n        specifier: 1.80.3\n        version: 1.80.3\n      ts-node:\n        specifier: 10.9.2\n        version: 10.9.2(@swc/core@1.4.2)(@types/node@22.7.6)(typescript@5.6.3)\n      typescript:\n        specifier: 5.6.3\n        version: 5.6.3\n      unplugin-fonts:\n        specifier: 1.1.1\n        version: 1.1.1(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))\n      vite:\n        specifier: 5.4.9\n        version: 5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1)\n      vite-plugin-pages:\n        specifier: 0.32.3\n        version: 0.32.3(@vue/compiler-sfc@3.5.12)(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.6.3)))\n      vite-plugin-vue-layouts:\n        specifier: 0.11.0\n        version: 0.11.0(vite@5.4.9(@types/node@22.7.6)(sass@1.80.3)(terser@5.34.1))(vue-router@4.4.5(vue@3.5.12(typescript@5.6.3)))(vue@3.5.12(typescript@5.6.3))\n      vue-tsc:\n        specifier: 2.1.6\n        version: 2.1.6(typescript@5.6.3)\n\npackages:\n\n  '@0no-co/graphql.web@1.0.7':\n    resolution: {integrity: sha512-E3Qku4mTzdrlwVWGPxklDnME5ANrEGetvYw4i2GCRlppWXXE4QD66j7pwb8HelZwS6LnqEChhrSOGCXpbiu6MQ==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0\n    peerDependenciesMeta:\n      graphql:\n        optional: true\n\n  '@alloc/quick-lru@5.2.0':\n    resolution: {integrity: sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==}\n    engines: {node: '>=10'}\n\n  '@ampproject/remapping@2.3.0':\n    resolution: {integrity: sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==}\n    engines: {node: '>=6.0.0'}\n\n  '@angular-devkit/core@17.3.8':\n    resolution: {integrity: sha512-Q8q0voCGudbdCgJ7lXdnyaxKHbNQBARH68zPQV72WT8NWy+Gw/tys870i6L58NWbBaCJEUcIj/kb6KoakSRu+Q==}\n    engines: {node: ^18.13.0 || >=20.9.0, npm: ^6.11.0 || ^7.5.6 || >=8.0.0, yarn: '>= 1.13.0'}\n    peerDependencies:\n      chokidar: ^3.5.2\n    peerDependenciesMeta:\n      chokidar:\n        optional: true\n\n  '@angular-devkit/schematics-cli@17.3.8':\n    resolution: {integrity: sha512-TjmiwWJarX7oqvNiRAroQ5/LeKUatxBOCNEuKXO/PV8e7pn/Hr/BqfFm+UcYrQoFdZplmtNAfqmbqgVziKvCpA==}\n    engines: {node: ^18.13.0 || >=20.9.0, npm: ^6.11.0 || ^7.5.6 || >=8.0.0, yarn: '>= 1.13.0'}\n    hasBin: true\n\n  '@angular-devkit/schematics@17.3.8':\n    resolution: {integrity: sha512-QRVEYpIfgkprNHc916JlPuNbLzOgrm9DZalHasnLUz4P6g7pR21olb8YCyM2OTJjombNhya9ZpckcADU5Qyvlg==}\n    engines: {node: ^18.13.0 || >=20.9.0, npm: ^6.11.0 || ^7.5.6 || >=8.0.0, yarn: '>= 1.13.0'}\n\n  '@antfu/install-pkg@0.1.1':\n    resolution: {integrity: sha512-LyB/8+bSfa0DFGC06zpCEfs89/XoWZwws5ygEa5D+Xsm3OfI+aXQ86VgVG7Acyef+rSZ5HE7J8rrxzrQeM3PjQ==}\n\n  '@antfu/install-pkg@0.4.1':\n    resolution: {integrity: sha512-T7yB5QNG29afhWVkVq7XeIMBa5U/vs9mX69YqayXypPRmYzUmzwnYltplHmPtZ4HPCn+sQKeXW8I47wCbuBOjw==}\n\n  '@antfu/utils@0.5.2':\n    resolution: {integrity: sha512-CQkeV+oJxUazwjlHD0/3ZD08QWKuGQkhnrKo3e6ly5pd48VUpXbb77q0xMU4+vc2CkJnDS02Eq/M9ugyX20XZA==}\n\n  '@antfu/utils@0.7.10':\n    resolution: {integrity: sha512-+562v9k4aI80m1+VuMHehNJWLOFjBnXn3tdOitzD0il5b7smkSBal4+a3oKiQTbrwMmN/TBUMDvbdoWDehgOww==}\n\n  '@apideck/better-ajv-errors@0.3.6':\n    resolution: {integrity: sha512-P+ZygBLZtkp0qqOAJJVX4oX/sFo5JR3eBWwwuqHHhK0GIgQOKWrAfiAaWX0aArHkRWHMuggFEgAZNxVPwPZYaA==}\n    engines: {node: '>=10'}\n    peerDependencies:\n      ajv: '>=8'\n\n  '@apidevtools/json-schema-ref-parser@9.0.6':\n    resolution: {integrity: sha512-M3YgsLjI0lZxvrpeGVk9Ap032W6TPQkH6pRAZz81Ac3WUNF79VQooAFnp8umjvVzUmD93NkogxEwbSce7qMsUg==}\n\n  '@apidevtools/json-schema-ref-parser@9.1.2':\n    resolution: {integrity: sha512-r1w81DpR+KyRWd3f+rk6TNqMgedmAxZP5v5KWlXQWlgMUUtyEJch0DKEci1SorPMiSeM8XPl7MZ3miJ60JIpQg==}\n\n  '@apidevtools/openapi-schemas@2.1.0':\n    resolution: {integrity: sha512-Zc1AlqrJlX3SlpupFGpiLi2EbteyP7fXmUOGup6/DnkRgjP9bgMM/ag+n91rsv0U1Gpz0H3VILA/o3bW7Ua6BQ==}\n    engines: {node: '>=10'}\n\n  '@apidevtools/swagger-methods@3.0.2':\n    resolution: {integrity: sha512-QAkD5kK2b1WfjDS/UQn/qQkbwF31uqRjPTrsCs5ZG9BQGAkjwvqGFjjPqAuzac/IYzpPtRzjCP1WrTuAIjMrXg==}\n\n  '@apidevtools/swagger-parser@10.0.2':\n    resolution: {integrity: sha512-JFxcEyp8RlNHgBCE98nwuTkZT6eNFPc1aosWV6wPcQph72TSEEu1k3baJD4/x1qznU+JiDdz8F5pTwabZh+Dhg==}\n    peerDependencies:\n      openapi-types: '>=7'\n\n  '@apidevtools/swagger-parser@10.1.0':\n    resolution: {integrity: sha512-9Kt7EuS/7WbMAUv2gSziqjvxwDbFSg3Xeyfuj5laUODX8o/k/CpsAKiQ8W7/R88eXFTMbJYg6+7uAmOWNKmwnw==}\n    peerDependencies:\n      openapi-types: '>=7'\n\n  '@apollo/cache-control-types@1.0.3':\n    resolution: {integrity: sha512-F17/vCp7QVwom9eG7ToauIKdAxpSoadsJnqIfyryLFSkLSOEqu+eC5Z3N8OXcUVStuOMcNHlyraRsA6rRICu4g==}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/protobufjs@1.2.7':\n    resolution: {integrity: sha512-Lahx5zntHPZia35myYDBRuF58tlwPskwHc5CWBZC/4bMKB6siTBWwtMrkqXcsNwQiFSzSx5hKdRPUmemrEp3Gg==}\n    hasBin: true\n\n  '@apollo/server-gateway-interface@1.1.1':\n    resolution: {integrity: sha512-pGwCl/po6+rxRmDMFgozKQo2pbsSwE91TpsDBAOgf74CRDPXHHtM88wbwjab0wMMZh95QfR45GGyDIdhY24bkQ==}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/server-plugin-landing-page-graphql-playground@4.0.0':\n    resolution: {integrity: sha512-PBDtKI/chJ+hHeoJUUH9Kuqu58txQl00vUGuxqiC9XcReulIg7RjsyD0G1u3drX4V709bxkL5S0nTeXfRHD0qA==}\n    engines: {node: '>=14.0'}\n    deprecated: The use of GraphQL Playground in Apollo Server was supported in previous versions, but this is no longer the case as of December 31, 2022. This package exists for v4 migration purposes only. We do not intend to resolve security issues or other bugs with this package if they arise, so please migrate away from this to [Apollo Server's default Explorer](https://www.apollographql.com/docs/apollo-server/api/plugin/landing-pages) as soon as possible.\n    peerDependencies:\n      '@apollo/server': ^4.0.0\n\n  '@apollo/server@4.11.0':\n    resolution: {integrity: sha512-SWDvbbs0wl2zYhKG6aGLxwTJ72xpqp0awb2lotNpfezd9VcAvzaUizzKQqocephin2uMoaA8MguoyBmgtPzNWw==}\n    engines: {node: '>=14.16.0'}\n    peerDependencies:\n      graphql: ^16.6.0\n\n  '@apollo/usage-reporting-protobuf@4.1.1':\n    resolution: {integrity: sha512-u40dIUePHaSKVshcedO7Wp+mPiZsaU6xjv9J+VyxpoU/zL6Jle+9zWeG98tr/+SZ0nZ4OXhrbb8SNr0rAPpIDA==}\n\n  '@apollo/utils.createhash@2.0.1':\n    resolution: {integrity: sha512-fQO4/ZOP8LcXWvMNhKiee+2KuKyqIcfHrICA+M4lj/h/Lh1H10ICcUtk6N/chnEo5HXu0yejg64wshdaiFitJg==}\n    engines: {node: '>=14'}\n\n  '@apollo/utils.dropunuseddefinitions@2.0.1':\n    resolution: {integrity: sha512-EsPIBqsSt2BwDsv8Wu76LK5R1KtsVkNoO4b0M5aK0hx+dGg9xJXuqlr7Fo34Dl+y83jmzn+UvEW+t1/GP2melA==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.fetcher@2.0.1':\n    resolution: {integrity: sha512-jvvon885hEyWXd4H6zpWeN3tl88QcWnHp5gWF5OPF34uhvoR+DFqcNxs9vrRaBBSY3qda3Qe0bdud7tz2zGx1A==}\n    engines: {node: '>=14'}\n\n  '@apollo/utils.isnodelike@2.0.1':\n    resolution: {integrity: sha512-w41XyepR+jBEuVpoRM715N2ZD0xMD413UiJx8w5xnAZD2ZkSJnMJBoIzauK83kJpSgNuR6ywbV29jG9NmxjK0Q==}\n    engines: {node: '>=14'}\n\n  '@apollo/utils.keyvaluecache@2.1.1':\n    resolution: {integrity: sha512-qVo5PvUUMD8oB9oYvq4ViCjYAMWnZ5zZwEjNF37L2m1u528x5mueMlU+Cr1UinupCgdB78g+egA1G98rbJ03Vw==}\n    engines: {node: '>=14'}\n\n  '@apollo/utils.logger@2.0.1':\n    resolution: {integrity: sha512-YuplwLHaHf1oviidB7MxnCXAdHp3IqYV8n0momZ3JfLniae92eYqMIx+j5qJFX6WKJPs6q7bczmV4lXIsTu5Pg==}\n    engines: {node: '>=14'}\n\n  '@apollo/utils.printwithreducedwhitespace@2.0.1':\n    resolution: {integrity: sha512-9M4LUXV/fQBh8vZWlLvb/HyyhjJ77/I5ZKu+NBWV/BmYGyRmoEP9EVAy7LCVoY3t8BDcyCAGfxJaLFCSuQkPUg==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.removealiases@2.0.1':\n    resolution: {integrity: sha512-0joRc2HBO4u594Op1nev+mUF6yRnxoUH64xw8x3bX7n8QBDYdeYgY4tF0vJReTy+zdn2xv6fMsquATSgC722FA==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.sortast@2.0.1':\n    resolution: {integrity: sha512-eciIavsWpJ09za1pn37wpsCGrQNXUhM0TktnZmHwO+Zy9O4fu/WdB4+5BvVhFiZYOXvfjzJUcc+hsIV8RUOtMw==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.stripsensitiveliterals@2.0.1':\n    resolution: {integrity: sha512-QJs7HtzXS/JIPMKWimFnUMK7VjkGQTzqD9bKD1h3iuPAqLsxd0mUNVbkYOPTsDhUKgcvUOfOqOJWYohAKMvcSA==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.usagereporting@2.1.0':\n    resolution: {integrity: sha512-LPSlBrn+S17oBy5eWkrRSGb98sWmnEzo3DPTZgp8IQc8sJe0prDgDuppGq4NeQlpoqEHz0hQeYHAOA0Z3aQsxQ==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      graphql: 14.x || 15.x || 16.x\n\n  '@apollo/utils.withrequired@2.0.1':\n    resolution: {integrity: sha512-YBDiuAX9i1lLc6GeTy1m7DGLFn/gMnvXqlalOIMjM7DeOgIacEjjfwPqb0M1CQ2v11HhR15d1NmxJoRCfrNqcA==}\n    engines: {node: '>=14'}\n\n  '@apollographql/graphql-playground-html@1.6.29':\n    resolution: {integrity: sha512-xCcXpoz52rI4ksJSdOCxeOCn2DLocxwHf9dVT/Q90Pte1LX+LY+91SFtJF3KXVHH8kEin+g1KKCQPKBjZJfWNA==}\n\n  '@ardatan/relay-compiler@12.0.0':\n    resolution: {integrity: sha512-9anThAaj1dQr6IGmzBMcfzOQKTa5artjuPmw8NYK/fiGEMjADbSguBY2FMDykt+QhilR3wc9VA/3yVju7JHg7Q==}\n    hasBin: true\n    peerDependencies:\n      graphql: '*'\n\n  '@ardatan/sync-fetch@0.0.1':\n    resolution: {integrity: sha512-xhlTqH0m31mnsG0tIP4ETgfSB6gXDaYYsUWTrlUV93fFQPI9dd8hE0Ot6MHLCtqgB32hwJAC3YZMWlXZw7AleA==}\n    engines: {node: '>=14'}\n\n  '@babel/code-frame@7.24.2':\n    resolution: {integrity: sha512-y5+tLQyV8pg3fsiln67BVLD1P13Eg4lh5RW9mF0zUuvLrv9uIQ4MCL+CRT+FTsBlBjcIan6PGsLcBN0m3ClUyQ==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/code-frame@7.25.7':\n    resolution: {integrity: sha512-0xZJFNE5XMpENsgfHYTw8FbX4kv53mFLn2i3XPoq69LyhYSCBJtitaHx9QnsVTrsogI4Z3+HtEfZ2/GFPOtf5g==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/compat-data@7.25.7':\n    resolution: {integrity: sha512-9ickoLz+hcXCeh7jrcin+/SLWm+GkxE2kTvoYyp38p4WkdFXfQJxDFGWp/YHjiKLPx06z2A7W8XKuqbReXDzsw==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/core@7.25.7':\n    resolution: {integrity: sha512-yJ474Zv3cwiSOO9nXJuqzvwEeM+chDuQ8GJirw+pZ91sCGCyOZ3dJkVE09fTV0VEVzXyLWhh3G/AolYTPX7Mow==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/generator@7.25.7':\n    resolution: {integrity: sha512-5Dqpl5fyV9pIAD62yK9P7fcA768uVPUyrQmqpqstHWgMma4feF1x/oFysBCVZLY5wJ2GkMUCdsNDnGZrPoR6rA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-annotate-as-pure@7.25.7':\n    resolution: {integrity: sha512-4xwU8StnqnlIhhioZf1tqnVWeQ9pvH/ujS8hRfw/WOza+/a+1qv69BWNy+oY231maTCWgKWhfBU7kDpsds6zAA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-builder-binary-assignment-operator-visitor@7.25.7':\n    resolution: {integrity: sha512-12xfNeKNH7jubQNm7PAkzlLwEmCs1tfuX3UjIw6vP6QXi+leKh6+LyC/+Ed4EIQermwd58wsyh070yjDHFlNGg==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-compilation-targets@7.25.7':\n    resolution: {integrity: sha512-DniTEax0sv6isaw6qSQSfV4gVRNtw2rte8HHM45t9ZR0xILaufBRNkpMifCRiAPyvL4ACD6v0gfCwCmtOQaV4A==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-create-class-features-plugin@7.25.7':\n    resolution: {integrity: sha512-bD4WQhbkx80mAyj/WCm4ZHcF4rDxkoLFO6ph8/5/mQ3z4vAzltQXAmbc7GvVJx5H+lk5Mi5EmbTeox5nMGCsbw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/helper-create-regexp-features-plugin@7.25.7':\n    resolution: {integrity: sha512-byHhumTj/X47wJ6C6eLpK7wW/WBEcnUeb7D0FNc/jFQnQVw7DOso3Zz5u9x/zLrFVkHa89ZGDbkAa1D54NdrCQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/helper-define-polyfill-provider@0.6.2':\n    resolution: {integrity: sha512-LV76g+C502biUK6AyZ3LK10vDpDyCzZnhZFXkH1L75zHPj68+qc8Zfpx2th+gzwA2MzyK+1g/3EPl62yFnVttQ==}\n    peerDependencies:\n      '@babel/core': ^7.4.0 || ^8.0.0-0 <8.0.0\n\n  '@babel/helper-member-expression-to-functions@7.25.7':\n    resolution: {integrity: sha512-O31Ssjd5K6lPbTX9AAYpSKrZmLeagt9uwschJd+Ixo6QiRyfpvgtVQp8qrDR9UNFjZ8+DO34ZkdrN+BnPXemeA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-module-imports@7.25.7':\n    resolution: {integrity: sha512-o0xCgpNmRohmnoWKQ0Ij8IdddjyBFE4T2kagL/x6M3+4zUgc+4qTOUBoNe4XxDskt1HPKO007ZPiMgLDq2s7Kw==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-module-transforms@7.25.7':\n    resolution: {integrity: sha512-k/6f8dKG3yDz/qCwSM+RKovjMix563SLxQFo0UhRNo239SP6n9u5/eLtKD6EAjwta2JHJ49CsD8pms2HdNiMMQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/helper-optimise-call-expression@7.25.7':\n    resolution: {integrity: sha512-VAwcwuYhv/AT+Vfr28c9y6SHzTan1ryqrydSTFGjU0uDJHw3uZ+PduI8plCLkRsDnqK2DMEDmwrOQRsK/Ykjng==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-plugin-utils@7.25.7':\n    resolution: {integrity: sha512-eaPZai0PiqCi09pPs3pAFfl/zYgGaE6IdXtYvmf0qlcDTd3WCtO7JWCcRd64e0EQrcYgiHibEZnOGsSY4QSgaw==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-remap-async-to-generator@7.25.7':\n    resolution: {integrity: sha512-kRGE89hLnPfcz6fTrlNU+uhgcwv0mBE4Gv3P9Ke9kLVJYpi4AMVVEElXvB5CabrPZW4nCM8P8UyyjrzCM0O2sw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/helper-replace-supers@7.25.7':\n    resolution: {integrity: sha512-iy8JhqlUW9PtZkd4pHM96v6BdJ66Ba9yWSE4z0W4TvSZwLBPkyDsiIU3ENe4SmrzRBs76F7rQXTy1lYC49n6Lw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/helper-simple-access@7.25.7':\n    resolution: {integrity: sha512-FPGAkJmyoChQeM+ruBGIDyrT2tKfZJO8NcxdC+CWNJi7N8/rZpSxK7yvBJ5O/nF1gfu5KzN7VKG3YVSLFfRSxQ==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-skip-transparent-expression-wrappers@7.25.7':\n    resolution: {integrity: sha512-pPbNbchZBkPMD50K0p3JGcFMNLVUCuU/ABybm/PGNj4JiHrpmNyqqCphBk4i19xXtNV0JhldQJJtbSW5aUvbyA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-string-parser@7.25.7':\n    resolution: {integrity: sha512-CbkjYdsJNHFk8uqpEkpCvRs3YRp9tY6FmFY7wLMSYuGYkrdUi7r2lc4/wqsvlHoMznX3WJ9IP8giGPq68T/Y6g==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-validator-identifier@7.24.5':\n    resolution: {integrity: sha512-3q93SSKX2TWCG30M2G2kwaKeTYgEUp5Snjuj8qm729SObL6nbtUldAi37qbxkD5gg3xnBio+f9nqpSepGZMvxA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-validator-identifier@7.25.7':\n    resolution: {integrity: sha512-AM6TzwYqGChO45oiuPqwL2t20/HdMC1rTPAesnBCgPCSF1x3oN9MVUwQV2iyz4xqWrctwK5RNC8LV22kaQCNYg==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-validator-option@7.25.7':\n    resolution: {integrity: sha512-ytbPLsm+GjArDYXJ8Ydr1c/KJuutjF2besPNbIZnZ6MKUxi/uTA22t2ymmA4WFjZFpjiAMO0xuuJPqK2nvDVfQ==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helper-wrap-function@7.25.7':\n    resolution: {integrity: sha512-MA0roW3JF2bD1ptAaJnvcabsVlNQShUaThyJbCDD4bCp8NEgiFvpoqRI2YS22hHlc2thjO/fTg2ShLMC3jygAg==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/helpers@7.25.7':\n    resolution: {integrity: sha512-Sv6pASx7Esm38KQpF/U/OXLwPPrdGHNKoeblRxgZRLXnAtnkEe4ptJPDtAZM7fBLadbc1Q07kQpSiGQ0Jg6tRA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/highlight@7.24.5':\n    resolution: {integrity: sha512-8lLmua6AVh/8SLJRRVD6V8p73Hir9w5mJrhE+IPpILG31KKlI9iz5zmBYKcWPS59qSfgP9RaSBQSHHE81WKuEw==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/highlight@7.25.7':\n    resolution: {integrity: sha512-iYyACpW3iW8Fw+ZybQK+drQre+ns/tKpXbNESfrhNnPLIklLbXr7MYJ6gPEd0iETGLOK+SxMjVvKb/ffmk+FEw==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/parser@7.25.7':\n    resolution: {integrity: sha512-aZn7ETtQsjjGG5HruveUK06cU3Hljuhd9Iojm4M8WWv3wLE6OkE5PWbDUkItmMgegmccaITudyuW5RPYrYlgWw==}\n    engines: {node: '>=6.0.0'}\n    hasBin: true\n\n  '@babel/plugin-bugfix-firefox-class-in-computed-class-key@7.25.7':\n    resolution: {integrity: sha512-UV9Lg53zyebzD1DwQoT9mzkEKa922LNUp5YkTJ6Uta0RbyXaQNUgcvSt7qIu1PpPzVb6rd10OVNTzkyBGeVmxQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-bugfix-safari-class-field-initializer-scope@7.25.7':\n    resolution: {integrity: sha512-GDDWeVLNxRIkQTnJn2pDOM1pkCgYdSqPeT1a9vh9yIqu2uzzgw1zcqEb+IJOhy+dTBMlNdThrDIksr2o09qrrQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-bugfix-safari-id-destructuring-collision-in-function-expression@7.25.7':\n    resolution: {integrity: sha512-wxyWg2RYaSUYgmd9MR0FyRGyeOMQE/Uzr1wzd/g5cf5bwi9A4v6HFdDm7y1MgDtod/fLOSTZY6jDgV0xU9d5bA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-bugfix-v8-spread-parameters-in-optional-chaining@7.25.7':\n    resolution: {integrity: sha512-Xwg6tZpLxc4iQjorYsyGMyfJE7nP5MV8t/Ka58BgiA7Jw0fRqQNcANlLfdJ/yvBt9z9LD2We+BEkT7vLqZRWng==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.13.0\n\n  '@babel/plugin-bugfix-v8-static-class-fields-redefine-readonly@7.25.7':\n    resolution: {integrity: sha512-UVATLMidXrnH+GMUIuxq55nejlj02HP7F5ETyBONzP6G87fPBogG4CH6kxrSrdIuAjdwNO9VzyaYsrZPscWUrw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-proposal-class-properties@7.18.6':\n    resolution: {integrity: sha512-cumfXOF0+nzZrrN8Rf0t7M+tF6sZc7vhQwYQck9q1/5w2OExlD+b4v4RpMJFaV1Z7WcDRgO6FqvxqxGlwo+RHQ==}\n    engines: {node: '>=6.9.0'}\n    deprecated: This proposal has been merged to the ECMAScript standard and thus this plugin is no longer maintained. Please use @babel/plugin-transform-class-properties instead.\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-proposal-object-rest-spread@7.20.7':\n    resolution: {integrity: sha512-d2S98yCiLxDVmBmE8UjGcfPvNEUbA1U5q5WxaWFUGRzJSVAZqm5W6MbPct0jxnegUZ0niLeNX+IOzEs7wYg9Dg==}\n    engines: {node: '>=6.9.0'}\n    deprecated: This proposal has been merged to the ECMAScript standard and thus this plugin is no longer maintained. Please use @babel/plugin-transform-object-rest-spread instead.\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-proposal-private-property-in-object@7.21.0-placeholder-for-preset-env.2':\n    resolution: {integrity: sha512-SOSkfJDddaM7mak6cPEpswyTRnuRltl429hMraQEglW+OkovnCzsiszTmsrlY//qLFjCpQDFRvjdm2wA5pPm9w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-async-generators@7.8.4':\n    resolution: {integrity: sha512-tycmZxkGfZaxhMRbXlPXuVFpdWlXpir2W4AMhSJgRKzk/eDlIXOhb2LHWoLpDF7TEHylV5zNhykX6KAgHJmTNw==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-bigint@7.8.3':\n    resolution: {integrity: sha512-wnTnFlG+YxQm3vDxpGE57Pj0srRU4sHE/mDkt1qv2YJJSeUAec2ma4WLUnUPeKjyrfntVwe/N6dCXpU+zL3Npg==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-class-properties@7.12.13':\n    resolution: {integrity: sha512-fm4idjKla0YahUNgFNLCB0qySdsoPiZP3iQE3rky0mBUtMZ23yDJ9SJdg6dXTSDnulOVqiF3Hgr9nbXvXTQZYA==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-class-static-block@7.14.5':\n    resolution: {integrity: sha512-b+YyPmr6ldyNnM6sqYeMWE+bgJcJpO6yS4QD7ymxgH34GBPNDM/THBh8iunyvKIZztiwLH4CJZ0RxTk9emgpjw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-dynamic-import@7.8.3':\n    resolution: {integrity: sha512-5gdGbFon+PszYzqs83S3E5mpi7/y/8M9eC90MRTZfduQOYW76ig6SOSPNe41IG5LoP3FGBn2N0RjVDSQiS94kQ==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-export-namespace-from@7.8.3':\n    resolution: {integrity: sha512-MXf5laXo6c1IbEbegDmzGPwGNTsHZmEy6QGznu5Sh2UCWvueywb2ee+CCE4zQiZstxU9BMoQO9i6zUFSY0Kj0Q==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-flow@7.25.7':\n    resolution: {integrity: sha512-fyoj6/YdVtlv2ROig/J0fP7hh/wNO1MJGm1NR70Pg7jbkF+jOUL9joorqaCOQh06Y+LfgTagHzC8KqZ3MF782w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-import-assertions@7.25.7':\n    resolution: {integrity: sha512-ZvZQRmME0zfJnDQnVBKYzHxXT7lYBB3Revz1GuS7oLXWMgqUPX4G+DDbT30ICClht9WKV34QVrZhSw6WdklwZQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-import-attributes@7.25.7':\n    resolution: {integrity: sha512-AqVo+dguCgmpi/3mYBdu9lkngOBlQ2w2vnNpa6gfiCxQZLzV4ZbhsXitJ2Yblkoe1VQwtHSaNmIaGll/26YWRw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-import-meta@7.10.4':\n    resolution: {integrity: sha512-Yqfm+XDx0+Prh3VSeEQCPU81yC+JWZ2pDPFSS4ZdpfZhp4MkFMaDC1UqseovEKwSUpnIL7+vK+Clp7bfh0iD7g==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-json-strings@7.8.3':\n    resolution: {integrity: sha512-lY6kdGpWHvjoe2vk4WrAapEuBR69EMxZl+RoGRhrFGNYVK8mOPAW8VfbT/ZgrFbXlDNiiaxQnAtgVCZ6jv30EA==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-jsx@7.25.7':\n    resolution: {integrity: sha512-ruZOnKO+ajVL/MVx+PwNBPOkrnXTXoWMtte1MBpegfCArhqOe3Bj52avVj1huLLxNKYKXYaSxZ2F+woK1ekXfw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-logical-assignment-operators@7.10.4':\n    resolution: {integrity: sha512-d8waShlpFDinQ5MtvGU9xDAOzKH47+FFoney2baFIoMr952hKOLp1HR7VszoZvOsV/4+RRszNY7D17ba0te0ig==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-nullish-coalescing-operator@7.8.3':\n    resolution: {integrity: sha512-aSff4zPII1u2QD7y+F8oDsz19ew4IGEJg9SVW+bqwpwtfFleiQDMdzA/R+UlWDzfnHFCxxleFT0PMIrR36XLNQ==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-numeric-separator@7.10.4':\n    resolution: {integrity: sha512-9H6YdfkcK/uOnY/K7/aA2xpzaAgkQn37yzWUMRK7OaPOqOpGS1+n0H5hxT9AUw9EsSjPW8SVyMJwYRtWs3X3ug==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-object-rest-spread@7.8.3':\n    resolution: {integrity: sha512-XoqMijGZb9y3y2XskN+P1wUGiVwWZ5JmoDRwx5+3GmEplNyVM2s2Dg8ILFQm8rWM48orGy5YpI5Bl8U1y7ydlA==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-optional-catch-binding@7.8.3':\n    resolution: {integrity: sha512-6VPD0Pc1lpTqw0aKoeRTMiB+kWhAoT24PA+ksWSBrFtl5SIRVpZlwN3NNPQjehA2E/91FV3RjLWoVTglWcSV3Q==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-optional-chaining@7.8.3':\n    resolution: {integrity: sha512-KoK9ErH1MBlCPxV0VANkXW2/dw4vlbGDrFgz8bmUsBGYkFRcbRwMh6cIJubdPrkxRwuGdtCk0v/wPTKbQgBjkg==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-private-property-in-object@7.14.5':\n    resolution: {integrity: sha512-0wVnp9dxJ72ZUJDV27ZfbSj6iHLoytYZmh3rFcxNnvsJF3ktkzLDZPy/mA17HGsaQT3/DQsWYX1f1QGWkCoVUg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-top-level-await@7.14.5':\n    resolution: {integrity: sha512-hx++upLv5U1rgYfwe1xBQUhRmU41NEvpUvrp8jkrSCdvGSnM5/qdRMtylJ6PG5OFkBaHkbTAKTnd3/YyESRHFw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-typescript@7.25.7':\n    resolution: {integrity: sha512-rR+5FDjpCHqqZN2bzZm18bVYGaejGq5ZkpVCJLXor/+zlSrSoc4KWcHI0URVWjl/68Dyr1uwZUz/1njycEAv9g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-syntax-unicode-sets-regex@7.18.6':\n    resolution: {integrity: sha512-727YkEAPwSIQTv5im8QHz3upqp92JTWhidIC81Tdx4VJYIte/VndKf1qKrfnnhPLiPghStWfvC/iFaMCQu7Nqg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-transform-arrow-functions@7.25.7':\n    resolution: {integrity: sha512-EJN2mKxDwfOUCPxMO6MUI58RN3ganiRAG/MS/S3HfB6QFNjroAMelQo/gybyYq97WerCBAZoyrAoW8Tzdq2jWg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-async-generator-functions@7.25.7':\n    resolution: {integrity: sha512-4B6OhTrwYKHYYgcwErvZjbmH9X5TxQBsaBHdzEIB4l71gR5jh/tuHGlb9in47udL2+wVUcOz5XXhhfhVJwEpEg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-async-to-generator@7.25.7':\n    resolution: {integrity: sha512-ZUCjAavsh5CESCmi/xCpX1qcCaAglzs/7tmuvoFnJgA1dM7gQplsguljoTg+Ru8WENpX89cQyAtWoaE0I3X3Pg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-block-scoped-functions@7.25.7':\n    resolution: {integrity: sha512-xHttvIM9fvqW+0a3tZlYcZYSBpSWzGBFIt/sYG3tcdSzBB8ZeVgz2gBP7Df+sM0N1850jrviYSSeUuc+135dmQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-block-scoping@7.25.7':\n    resolution: {integrity: sha512-ZEPJSkVZaeTFG/m2PARwLZQ+OG0vFIhPlKHK/JdIMy8DbRJ/htz6LRrTFtdzxi9EHmcwbNPAKDnadpNSIW+Aow==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-class-properties@7.25.7':\n    resolution: {integrity: sha512-mhyfEW4gufjIqYFo9krXHJ3ElbFLIze5IDp+wQTxoPd+mwFb1NxatNAwmv8Q8Iuxv7Zc+q8EkiMQwc9IhyGf4g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-class-static-block@7.25.7':\n    resolution: {integrity: sha512-rvUUtoVlkDWtDWxGAiiQj0aNktTPn3eFynBcMC2IhsXweehwgdI9ODe+XjWw515kEmv22sSOTp/rxIRuTiB7zg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.12.0\n\n  '@babel/plugin-transform-classes@7.25.7':\n    resolution: {integrity: sha512-9j9rnl+YCQY0IGoeipXvnk3niWicIB6kCsWRGLwX241qSXpbA4MKxtp/EdvFxsc4zI5vqfLxzOd0twIJ7I99zg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-computed-properties@7.25.7':\n    resolution: {integrity: sha512-QIv+imtM+EtNxg/XBKL3hiWjgdLjMOmZ+XzQwSgmBfKbfxUjBzGgVPklUuE55eq5/uVoh8gg3dqlrwR/jw3ZeA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-destructuring@7.25.7':\n    resolution: {integrity: sha512-xKcfLTlJYUczdaM1+epcdh1UGewJqr9zATgrNHcLBcV2QmfvPPEixo/sK/syql9cEmbr7ulu5HMFG5vbbt/sEA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-dotall-regex@7.25.7':\n    resolution: {integrity: sha512-kXzXMMRzAtJdDEgQBLF4oaiT6ZCU3oWHgpARnTKDAqPkDJ+bs3NrZb310YYevR5QlRo3Kn7dzzIdHbZm1VzJdQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-duplicate-keys@7.25.7':\n    resolution: {integrity: sha512-by+v2CjoL3aMnWDOyCIg+yxU9KXSRa9tN6MbqggH5xvymmr9p4AMjYkNlQy4brMceBnUyHZ9G8RnpvT8wP7Cfg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-duplicate-named-capturing-groups-regex@7.25.7':\n    resolution: {integrity: sha512-HvS6JF66xSS5rNKXLqkk7L9c/jZ/cdIVIcoPVrnl8IsVpLggTjXs8OWekbLHs/VtYDDh5WXnQyeE3PPUGm22MA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-transform-dynamic-import@7.25.7':\n    resolution: {integrity: sha512-UvcLuual4h7/GfylKm2IAA3aph9rwvAM2XBA0uPKU3lca+Maai4jBjjEVUS568ld6kJcgbouuumCBhMd/Yz17w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-exponentiation-operator@7.25.7':\n    resolution: {integrity: sha512-yjqtpstPfZ0h/y40fAXRv2snciYr0OAoMXY/0ClC7tm4C/nG5NJKmIItlaYlLbIVAWNfrYuy9dq1bE0SbX0PEg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-export-namespace-from@7.25.7':\n    resolution: {integrity: sha512-h3MDAP5l34NQkkNulsTNyjdaR+OiB0Im67VU//sFupouP8Q6m9Spy7l66DcaAQxtmCqGdanPByLsnwFttxKISQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-flow-strip-types@7.25.7':\n    resolution: {integrity: sha512-q8Td2PPc6/6I73g96SreSUCKEcwMXCwcXSIAVTyTTN6CpJe0dMj8coxu1fg1T9vfBLi6Rsi6a4ECcFBbKabS5w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-for-of@7.25.7':\n    resolution: {integrity: sha512-n/TaiBGJxYFWvpJDfsxSj9lEEE44BFM1EPGz4KEiTipTgkoFVVcCmzAL3qA7fdQU96dpo4gGf5HBx/KnDvqiHw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-function-name@7.25.7':\n    resolution: {integrity: sha512-5MCTNcjCMxQ63Tdu9rxyN6cAWurqfrDZ76qvVPrGYdBxIj+EawuuxTu/+dgJlhK5eRz3v1gLwp6XwS8XaX2NiQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-json-strings@7.25.7':\n    resolution: {integrity: sha512-Ot43PrL9TEAiCe8C/2erAjXMeVSnE/BLEx6eyrKLNFCCw5jvhTHKyHxdI1pA0kz5njZRYAnMO2KObGqOCRDYSA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-literals@7.25.7':\n    resolution: {integrity: sha512-fwzkLrSu2fESR/cm4t6vqd7ebNIopz2QHGtjoU+dswQo/P6lwAG04Q98lliE3jkz/XqnbGFLnUcE0q0CVUf92w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-logical-assignment-operators@7.25.7':\n    resolution: {integrity: sha512-iImzbA55BjiovLyG2bggWS+V+OLkaBorNvc/yJoeeDQGztknRnDdYfp2d/UPmunZYEnZi6Lg8QcTmNMHOB0lGA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-member-expression-literals@7.25.7':\n    resolution: {integrity: sha512-Std3kXwpXfRV0QtQy5JJcRpkqP8/wG4XL7hSKZmGlxPlDqmpXtEPRmhF7ztnlTCtUN3eXRUJp+sBEZjaIBVYaw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-modules-amd@7.25.7':\n    resolution: {integrity: sha512-CgselSGCGzjQvKzghCvDTxKHP3iooenLpJDO842ehn5D2G5fJB222ptnDwQho0WjEvg7zyoxb9P+wiYxiJX5yA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-modules-commonjs@7.25.7':\n    resolution: {integrity: sha512-L9Gcahi0kKFYXvweO6n0wc3ZG1ChpSFdgG+eV1WYZ3/dGbJK7vvk91FgGgak8YwRgrCuihF8tE/Xg07EkL5COg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-modules-systemjs@7.25.7':\n    resolution: {integrity: sha512-t9jZIvBmOXJsiuyOwhrIGs8dVcD6jDyg2icw1VL4A/g+FnWyJKwUfSSU2nwJuMV2Zqui856El9u+ElB+j9fV1g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-modules-umd@7.25.7':\n    resolution: {integrity: sha512-p88Jg6QqsaPh+EB7I9GJrIqi1Zt4ZBHUQtjw3z1bzEXcLh6GfPqzZJ6G+G1HBGKUNukT58MnKG7EN7zXQBCODw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-named-capturing-groups-regex@7.25.7':\n    resolution: {integrity: sha512-BtAT9LzCISKG3Dsdw5uso4oV1+v2NlVXIIomKJgQybotJY3OwCwJmkongjHgwGKoZXd0qG5UZ12JUlDQ07W6Ow==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/plugin-transform-new-target@7.25.7':\n    resolution: {integrity: sha512-CfCS2jDsbcZaVYxRFo2qtavW8SpdzmBXC2LOI4oO0rP+JSRDxxF3inF4GcPsLgfb5FjkhXG5/yR/lxuRs2pySA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-nullish-coalescing-operator@7.25.7':\n    resolution: {integrity: sha512-FbuJ63/4LEL32mIxrxwYaqjJxpbzxPVQj5a+Ebrc8JICV6YX8nE53jY+K0RZT3um56GoNWgkS2BQ/uLGTjtwfw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-numeric-separator@7.25.7':\n    resolution: {integrity: sha512-8CbutzSSh4hmD+jJHIA8vdTNk15kAzOnFLVVgBSMGr28rt85ouT01/rezMecks9pkU939wDInImwCKv4ahU4IA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-object-rest-spread@7.25.7':\n    resolution: {integrity: sha512-1JdVKPhD7Y5PvgfFy0Mv2brdrolzpzSoUq2pr6xsR+m+3viGGeHEokFKsCgOkbeFOQxfB1Vt2F0cPJLRpFI4Zg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-object-super@7.25.7':\n    resolution: {integrity: sha512-pWT6UXCEW3u1t2tcAGtE15ornCBvopHj9Bps9D2DsH15APgNVOTwwczGckX+WkAvBmuoYKRCFa4DK+jM8vh5AA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-optional-catch-binding@7.25.7':\n    resolution: {integrity: sha512-m9obYBA39mDPN7lJzD5WkGGb0GO54PPLXsbcnj1Hyeu8mSRz7Gb4b1A6zxNX32ZuUySDK4G6it8SDFWD1nCnqg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-optional-chaining@7.25.7':\n    resolution: {integrity: sha512-h39agClImgPWg4H8mYVAbD1qP9vClFbEjqoJmt87Zen8pjqK8FTPUwrOXAvqu5soytwxrLMd2fx2KSCp2CHcNg==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-parameters@7.25.7':\n    resolution: {integrity: sha512-FYiTvku63me9+1Nz7TOx4YMtW3tWXzfANZtrzHhUZrz4d47EEtMQhzFoZWESfXuAMMT5mwzD4+y1N8ONAX6lMQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-private-methods@7.25.7':\n    resolution: {integrity: sha512-KY0hh2FluNxMLwOCHbxVOKfdB5sjWG4M183885FmaqWWiGMhRZq4DQRKH6mHdEucbJnyDyYiZNwNG424RymJjA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-private-property-in-object@7.25.7':\n    resolution: {integrity: sha512-LzA5ESzBy7tqj00Yjey9yWfs3FKy4EmJyKOSWld144OxkTji81WWnUT8nkLUn+imN/zHL8ZQlOu/MTUAhHaX3g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-property-literals@7.25.7':\n    resolution: {integrity: sha512-lQEeetGKfFi0wHbt8ClQrUSUMfEeI3MMm74Z73T9/kuz990yYVtfofjf3NuA42Jy3auFOpbjDyCSiIkTs1VIYw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-react-display-name@7.25.7':\n    resolution: {integrity: sha512-r0QY7NVU8OnrwE+w2IWiRom0wwsTbjx4+xH2RTd7AVdof3uurXOF+/mXHQDRk+2jIvWgSaCHKMgggfvM4dyUGA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-react-jsx@7.25.7':\n    resolution: {integrity: sha512-vILAg5nwGlR9EXE8JIOX4NHXd49lrYbN8hnjffDtoULwpL9hUx/N55nqh2qd0q6FyNDfjl9V79ecKGvFbcSA0Q==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-regenerator@7.25.7':\n    resolution: {integrity: sha512-mgDoQCRjrY3XK95UuV60tZlFCQGXEtMg8H+IsW72ldw1ih1jZhzYXbJvghmAEpg5UVhhnCeia1CkGttUvCkiMQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-reserved-words@7.25.7':\n    resolution: {integrity: sha512-3OfyfRRqiGeOvIWSagcwUTVk2hXBsr/ww7bLn6TRTuXnexA+Udov2icFOxFX9abaj4l96ooYkcNN1qi2Zvqwng==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-shorthand-properties@7.25.7':\n    resolution: {integrity: sha512-uBbxNwimHi5Bv3hUccmOFlUy3ATO6WagTApenHz9KzoIdn0XeACdB12ZJ4cjhuB2WSi80Ez2FWzJnarccriJeA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-spread@7.25.7':\n    resolution: {integrity: sha512-Mm6aeymI0PBh44xNIv/qvo8nmbkpZze1KvR8MkEqbIREDxoiWTi18Zr2jryfRMwDfVZF9foKh060fWgni44luw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-sticky-regex@7.25.7':\n    resolution: {integrity: sha512-ZFAeNkpGuLnAQ/NCsXJ6xik7Id+tHuS+NT+ue/2+rn/31zcdnupCdmunOizEaP0JsUmTFSTOPoQY7PkK2pttXw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-template-literals@7.25.7':\n    resolution: {integrity: sha512-SI274k0nUsFFmyQupiO7+wKATAmMFf8iFgq2O+vVFXZ0SV9lNfT1NGzBEhjquFmD8I9sqHLguH+gZVN3vww2AA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-typeof-symbol@7.25.7':\n    resolution: {integrity: sha512-OmWmQtTHnO8RSUbL0NTdtpbZHeNTnm68Gj5pA4Y2blFNh+V4iZR68V1qL9cI37J21ZN7AaCnkfdHtLExQPf2uA==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-unicode-escapes@7.25.7':\n    resolution: {integrity: sha512-BN87D7KpbdiABA+t3HbVqHzKWUDN3dymLaTnPFAMyc8lV+KN3+YzNhVRNdinaCPA4AUqx7ubXbQ9shRjYBl3SQ==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-unicode-property-regex@7.25.7':\n    resolution: {integrity: sha512-IWfR89zcEPQGB/iB408uGtSPlQd3Jpq11Im86vUgcmSTcoWAiQMCTOa2K2yNNqFJEBVICKhayctee65Ka8OB0w==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-unicode-regex@7.25.7':\n    resolution: {integrity: sha512-8JKfg/hiuA3qXnlLx8qtv5HWRbgyFx2hMMtpDDuU2rTckpKkGu4ycK5yYHwuEa16/quXfoxHBIApEsNyMWnt0g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/plugin-transform-unicode-sets-regex@7.25.7':\n    resolution: {integrity: sha512-YRW8o9vzImwmh4Q3Rffd09bH5/hvY0pxg+1H1i0f7APoUeg12G7+HhLj9ZFNIrYkgBXhIijPJ+IXypN0hLTIbw==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  '@babel/preset-env@7.25.7':\n    resolution: {integrity: sha512-Gibz4OUdyNqqLj+7OAvBZxOD7CklCtMA5/j0JgUEwOnaRULsPDXmic2iKxL2DX2vQduPR5wH2hjZas/Vr/Oc0g==}\n    engines: {node: '>=6.9.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0\n\n  '@babel/preset-modules@0.1.6-no-external-plugins':\n    resolution: {integrity: sha512-HrcgcIESLm9aIR842yhJ5RWan/gebQUJ6E/E5+rf0y9o6oj7w0Br+sWuL6kEQ/o/AdfvR1Je9jG18/gnpwjEyA==}\n    peerDependencies:\n      '@babel/core': ^7.0.0-0 || ^8.0.0-0 <8.0.0\n\n  '@babel/runtime@7.25.7':\n    resolution: {integrity: sha512-FjoyLe754PMiYsFaN5C94ttGiOmBNYTf6pLr4xXHAT5uctHb092PBszndLDR5XA/jghQvn4n7JMHl7dmTgbm9w==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/standalone@7.24.5':\n    resolution: {integrity: sha512-Sl8oN9bGfRlNUA2jzfzoHEZxFBDliBlwi5mPVCAWKSlBNkXXJOHpu7SDOqjF6mRoTa6GNX/1kAWG3Tr+YQ3N7A==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/template@7.25.7':\n    resolution: {integrity: sha512-wRwtAgI3bAS+JGU2upWNL9lSlDcRCqD05BZ1n3X2ONLH1WilFP6O1otQjeMK/1g0pvYcXC7b/qVUB1keofjtZA==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/traverse@7.25.7':\n    resolution: {integrity: sha512-jatJPT1Zjqvh/1FyJs6qAHL+Dzb7sTb+xr7Q+gM1b+1oBsMsQQ4FkVKb6dFlJvLlVssqkRzV05Jzervt9yhnzg==}\n    engines: {node: '>=6.9.0'}\n\n  '@babel/types@7.25.7':\n    resolution: {integrity: sha512-vwIVdXG+j+FOpkwqHRcBgHLYNL7XMkufrlaFvL9o6Ai9sJn9+PdyIL5qa0XzTZw084c+u9LOls53eoZWP/W5WQ==}\n    engines: {node: '>=6.9.0'}\n\n  '@bcoe/v8-coverage@0.2.3':\n    resolution: {integrity: sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==}\n\n  '@boringer-avatars/vue3@0.2.1':\n    resolution: {integrity: sha512-KzAfh31SDXToTvFL0tBNG5Ur+VzfD1PP4jmY5/GS+eIuObGTIAiUu9eiht0LjuAGI+0xCgnaEgsTrOx8H3vLOQ==}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@codemirror/autocomplete@6.18.1':\n    resolution: {integrity: sha512-iWHdj/B1ethnHRTwZj+C1obmmuCzquH29EbcKr0qIjA9NfDeBDJ7vs+WOHsFeLeflE4o+dHfYndJloMKHUkWUA==}\n    peerDependencies:\n      '@codemirror/language': ^6.0.0\n      '@codemirror/state': ^6.0.0\n      '@codemirror/view': ^6.0.0\n      '@lezer/common': ^1.0.0\n\n  '@codemirror/commands@6.7.0':\n    resolution: {integrity: sha512-+cduIZ2KbesDhbykV02K25A5xIVrquSPz4UxxYBemRlAT2aW8dhwUgLDwej7q/RJUHKk4nALYcR1puecDvbdqw==}\n\n  '@codemirror/lang-javascript@6.2.2':\n    resolution: {integrity: sha512-VGQfY+FCc285AhWuwjYxQyUQcYurWlxdKYT4bqwr3Twnd5wP5WSeu52t4tvvuWmljT4EmgEgZCqSieokhtY8hg==}\n\n  '@codemirror/lang-json@6.0.1':\n    resolution: {integrity: sha512-+T1flHdgpqDDlJZ2Lkil/rLiRy684WMLc74xUnjJH48GQdfJo/pudlTRreZmKwzP8/tGdKf83wlbAdOCzlJOGQ==}\n\n  '@codemirror/lang-xml@6.1.0':\n    resolution: {integrity: sha512-3z0blhicHLfwi2UgkZYRPioSgVTo9PV5GP5ducFH6FaHy0IAJRg+ixj5gTR1gnT/glAIC8xv4w2VL1LoZfs+Jg==}\n\n  '@codemirror/language@6.10.1':\n    resolution: {integrity: sha512-5GrXzrhq6k+gL5fjkAwt90nYDmjlzTIJV8THnxNFtNKWotMIlzzN+CpqxqwXOECnUdOndmSeWntVrVcv5axWRQ==}\n\n  '@codemirror/legacy-modes@6.4.1':\n    resolution: {integrity: sha512-vdg3XY7OAs5uLDx2Iw+cGfnwtd7kM+Et/eMsqAGTfT/JKiVBQZXosTzjEbWAi/FrY6DcQIz8mQjBozFHZEUWQA==}\n\n  '@codemirror/lint@6.8.2':\n    resolution: {integrity: sha512-PDFG5DjHxSEjOXk9TQYYVjZDqlZTFaDBfhQixHnQOEVDDNHUbEh/hstAjcQJaA6FQdZTD1hquXTK0rVBLADR1g==}\n\n  '@codemirror/merge@6.7.2':\n    resolution: {integrity: sha512-HSzuWoV4E+F0DROOSwGZMYIDXh+y4iA64ffRADXPBbKKSwx9bsYNM4i7qN8t0mc8H0PYNBoehOvsW2Nitmnx9g==}\n\n  '@codemirror/search@6.5.6':\n    resolution: {integrity: sha512-rpMgcsh7o0GuCDUXKPvww+muLA1pDJaFrpq/CCHtpQJYz8xopu4D1hPcKRoDD0YlF8gZaqTNIRa4VRBWyhyy7Q==}\n\n  '@codemirror/state@6.4.1':\n    resolution: {integrity: sha512-QkEyUiLhsJoZkbumGZlswmAhA7CBU02Wrz7zvH4SrcifbsqwlXShVXg65f3v/ts57W3dqyamEriMhij1Z3Zz4A==}\n\n  '@codemirror/view@6.25.1':\n    resolution: {integrity: sha512-2LXLxsQnHDdfGzDvjzAwZh2ZviNJm7im6tGpa0IONIDnFd8RZ80D2SNi8PDi6YjKcMoMRK20v6OmKIdsrwsyoQ==}\n\n  '@codemirror/view@6.34.1':\n    resolution: {integrity: sha512-t1zK/l9UiRqwUNPm+pdIT0qzJlzuVckbTEMVNFhfWkGiBQClstzg+78vedCvLSX0xJEZ6lwZbPpnljL7L6iwMQ==}\n\n  '@colors/colors@1.5.0':\n    resolution: {integrity: sha512-ooWCrlZP11i8GImSjTHYHLkvFDP48nS4+204nGb1RiX/WXYHmJA2III9/e2DWVabCESdW7hBAEzHRqUn9OUVvQ==}\n    engines: {node: '>=0.1.90'}\n\n  '@commitlint/cli@19.5.0':\n    resolution: {integrity: sha512-gaGqSliGwB86MDmAAKAtV9SV1SHdmN8pnGq4EJU4+hLisQ7IFfx4jvU4s+pk6tl0+9bv6yT+CaZkufOinkSJIQ==}\n    engines: {node: '>=v18'}\n    hasBin: true\n\n  '@commitlint/config-conventional@19.5.0':\n    resolution: {integrity: sha512-OBhdtJyHNPryZKg0fFpZNOBM1ZDbntMvqMuSmpfyP86XSfwzGw4CaoYRG4RutUPg0BTK07VMRIkNJT6wi2zthg==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/config-validator@19.5.0':\n    resolution: {integrity: sha512-CHtj92H5rdhKt17RmgALhfQt95VayrUo2tSqY9g2w+laAXyk7K/Ef6uPm9tn5qSIwSmrLjKaXK9eiNuxmQrDBw==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/ensure@19.5.0':\n    resolution: {integrity: sha512-Kv0pYZeMrdg48bHFEU5KKcccRfKmISSm9MvgIgkpI6m+ohFTB55qZlBW6eYqh/XDfRuIO0x4zSmvBjmOwWTwkg==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/execute-rule@19.5.0':\n    resolution: {integrity: sha512-aqyGgytXhl2ejlk+/rfgtwpPexYyri4t8/n4ku6rRJoRhGZpLFMqrZ+YaubeGysCP6oz4mMA34YSTaSOKEeNrg==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/format@19.5.0':\n    resolution: {integrity: sha512-yNy088miE52stCI3dhG/vvxFo9e4jFkU1Mj3xECfzp/bIS/JUay4491huAlVcffOoMK1cd296q0W92NlER6r3A==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/is-ignored@19.5.0':\n    resolution: {integrity: sha512-0XQ7Llsf9iL/ANtwyZ6G0NGp5Y3EQ8eDQSxv/SRcfJ0awlBY4tHFAvwWbw66FVUaWICH7iE5en+FD9TQsokZ5w==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/lint@19.5.0':\n    resolution: {integrity: sha512-cAAQwJcRtiBxQWO0eprrAbOurtJz8U6MgYqLz+p9kLElirzSCc0vGMcyCaA1O7AqBuxo11l1XsY3FhOFowLAAg==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/load@19.5.0':\n    resolution: {integrity: sha512-INOUhkL/qaKqwcTUvCE8iIUf5XHsEPCLY9looJ/ipzi7jtGhgmtH7OOFiNvwYgH7mA8osUWOUDV8t4E2HAi4xA==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/message@19.5.0':\n    resolution: {integrity: sha512-R7AM4YnbxN1Joj1tMfCyBryOC5aNJBdxadTZkuqtWi3Xj0kMdutq16XQwuoGbIzL2Pk62TALV1fZDCv36+JhTQ==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/parse@19.5.0':\n    resolution: {integrity: sha512-cZ/IxfAlfWYhAQV0TwcbdR1Oc0/r0Ik1GEessDJ3Lbuma/MRO8FRQX76eurcXtmhJC//rj52ZSZuXUg0oIX0Fw==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/read@19.5.0':\n    resolution: {integrity: sha512-TjS3HLPsLsxFPQj6jou8/CZFAmOP2y+6V4PGYt3ihbQKTY1Jnv0QG28WRKl/d1ha6zLODPZqsxLEov52dhR9BQ==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/resolve-extends@19.5.0':\n    resolution: {integrity: sha512-CU/GscZhCUsJwcKTJS9Ndh3AKGZTNFIOoQB2n8CmFnizE0VnEuJoum+COW+C1lNABEeqk6ssfc1Kkalm4bDklA==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/rules@19.5.0':\n    resolution: {integrity: sha512-hDW5TPyf/h1/EufSHEKSp6Hs+YVsDMHazfJ2azIk9tHPXS6UqSz1dIRs1gpqS3eMXgtkT7JH6TW4IShdqOwhAw==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/to-lines@19.5.0':\n    resolution: {integrity: sha512-R772oj3NHPkodOSRZ9bBVNq224DOxQtNef5Pl8l2M8ZnkkzQfeSTr4uxawV2Sd3ui05dUVzvLNnzenDBO1KBeQ==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/top-level@19.5.0':\n    resolution: {integrity: sha512-IP1YLmGAk0yWrImPRRc578I3dDUI5A2UBJx9FbSOjxe9sTlzFiwVJ+zeMLgAtHMtGZsC8LUnzmW1qRemkFU4ng==}\n    engines: {node: '>=v18'}\n\n  '@commitlint/types@19.5.0':\n    resolution: {integrity: sha512-DSHae2obMSMkAtTBSOulg5X7/z+rGLxcXQIkg3OmWvY6wifojge5uVMydfhUvs7yQj+V7jNmRZ2Xzl8GJyqRgg==}\n    engines: {node: '>=v18'}\n\n  '@cspotcode/source-map-support@0.8.1':\n    resolution: {integrity: sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==}\n    engines: {node: '>=12'}\n\n  '@css-inline/css-inline-android-arm-eabi@0.14.1':\n    resolution: {integrity: sha512-LNUR8TY4ldfYi0mi/d4UNuHJ+3o8yLQH9r2Nt6i4qeg1i7xswfL3n/LDLRXvGjBYqeEYNlhlBQzbPwMX1qrU6A==}\n    engines: {node: '>= 10'}\n    cpu: [arm]\n    os: [android]\n\n  '@css-inline/css-inline-android-arm64@0.14.1':\n    resolution: {integrity: sha512-tH5us0NYGoTNBHOUHVV7j9KfJ4DtFOeTLA3cM0XNoMtArNu2pmaaBMFJPqECzavfXkLc7x5Z22UPZYjoyHfvCA==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [android]\n\n  '@css-inline/css-inline-darwin-arm64@0.14.1':\n    resolution: {integrity: sha512-QE5W1YRIfRayFrtrcK/wqEaxNaqLULPI0gZB4ArbFRd3d56IycvgBasDTHPre5qL2cXCO3VyPx+80XyHOaVkag==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@css-inline/css-inline-darwin-x64@0.14.1':\n    resolution: {integrity: sha512-mAvv2sN8awNFsbvBzlFkZPbCNZ6GCWY5/YcIz7V5dPYw+bHHRbjnlkNTEZq5BsDxErVrMIGvz05PGgzuNvZvdQ==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@css-inline/css-inline-linux-arm-gnueabihf@0.14.1':\n    resolution: {integrity: sha512-AWC44xL0X7BgKvrWEqfSqkT2tJA5kwSGrAGT+m0gt11wnTYySvQ6YpX0fTY9i3ppYGu4bEdXFjyK2uY1DTQMHA==}\n    engines: {node: '>= 10'}\n    cpu: [arm]\n    os: [linux]\n\n  '@css-inline/css-inline-linux-arm64-gnu@0.14.1':\n    resolution: {integrity: sha512-drj0ciiJgdP3xKXvNAt4W+FH4KKMs8vB5iKLJ3HcH07sNZj58Sx++2GxFRS1el3p+GFp9OoYA6dgouJsGEqt0Q==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@css-inline/css-inline-linux-arm64-musl@0.14.1':\n    resolution: {integrity: sha512-FzknI+st8eA8YQSdEJU9ykcM0LZjjigBuynVF5/p7hiMm9OMP8aNhWbhZ8LKJpKbZrQsxSGS4g9Vnr6n6FiSdQ==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@css-inline/css-inline-linux-x64-gnu@0.14.1':\n    resolution: {integrity: sha512-yubbEye+daDY/4vXnyASAxH88s256pPati1DfVoZpU1V0+KP0BZ1dByZOU1ktExurbPH3gZOWisAnBE9xon0Uw==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@css-inline/css-inline-linux-x64-musl@0.14.1':\n    resolution: {integrity: sha512-6CRAZzoy1dMLPC/tns2rTt1ZwPo0nL/jYBEIAsYTCWhfAnNnpoLKVh5Nm+fSU3OOwTTqU87UkGrFJhObD/wobQ==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@css-inline/css-inline-win32-x64-msvc@0.14.1':\n    resolution: {integrity: sha512-nzotGiaiuiQW78EzsiwsHZXbxEt6DiMUFcDJ6dhiliomXxnlaPyBfZb6/FMBgRJOf6sknDt/5695OttNmbMYzg==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [win32]\n\n  '@css-inline/css-inline@0.14.1':\n    resolution: {integrity: sha512-u4eku+hnPqqHIGq/ZUQcaP0TrCbYeLIYBaK7qClNRGZbnh8RC4gVxLEIo8Pceo1nOK9E5G4Lxzlw5KnXcvflfA==}\n    engines: {node: '>= 10'}\n\n  '@digitak/esrun@3.2.26':\n    resolution: {integrity: sha512-mL0bw7NhKVghp7mVsPwnAMhCn4NGAsk0KKFmAfnrYAZ/QCXR5xLXIYP82zLMjcsQag8DD6i1c+Yrm/57StYVzg==}\n    engines: {node: '>=14.0'}\n    hasBin: true\n\n  '@digitak/grubber@3.1.4':\n    resolution: {integrity: sha512-pqsnp2BUYlDoTXWG34HWgEJse/Eo1okRgNex8IG84wHrJp8h3SakeR5WhB4VxSA2+/D+frNYJ0ch3yXzsfNDoA==}\n\n  '@esbuild-plugins/node-globals-polyfill@0.2.3':\n    resolution: {integrity: sha512-r3MIryXDeXDOZh7ih1l/yE9ZLORCd5e8vWg02azWRGj5SPTuoh69A2AIyn0Z31V/kHBfZ4HgWJ+OK3GTTwLmnw==}\n    peerDependencies:\n      esbuild: '*'\n\n  '@esbuild-plugins/node-modules-polyfill@0.2.2':\n    resolution: {integrity: sha512-LXV7QsWJxRuMYvKbiznh+U1ilIop3g2TeKRzUxOG5X3YITc8JyyTa90BmLwqqv0YnX4v32CSlG+vsziZp9dMvA==}\n    peerDependencies:\n      esbuild: '*'\n\n  '@esbuild/aix-ppc64@0.21.5':\n    resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}\n    engines: {node: '>=12'}\n    cpu: [ppc64]\n    os: [aix]\n\n  '@esbuild/aix-ppc64@0.23.1':\n    resolution: {integrity: sha512-6VhYk1diRqrhBAqpJEdjASR/+WVRtfjpqKuNw11cLiaWpAT/Uu+nokB+UJnevzy/P9C/ty6AOe0dwueMrGh/iQ==}\n    engines: {node: '>=18'}\n    cpu: [ppc64]\n    os: [aix]\n\n  '@esbuild/aix-ppc64@0.24.0':\n    resolution: {integrity: sha512-WtKdFM7ls47zkKHFVzMz8opM7LkcsIp9amDUBIAWirg70RM71WRSjdILPsY5Uv1D42ZpUfaPILDlfactHgsRkw==}\n    engines: {node: '>=18'}\n    cpu: [ppc64]\n    os: [aix]\n\n  '@esbuild/android-arm64@0.17.19':\n    resolution: {integrity: sha512-KBMWvEZooR7+kzY0BtbTQn0OAYY7CsiydT63pVEaPtVYF0hXbUaOyZog37DKxK7NF3XacBJOpYT4adIJh+avxA==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [android]\n\n  '@esbuild/android-arm64@0.18.20':\n    resolution: {integrity: sha512-Nz4rJcchGDtENV0eMKUNa6L12zz2zBDXuhj/Vjh18zGqB44Bi7MBMSXjgunJgjRhCmKOjnPuZp4Mb6OKqtMHLQ==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [android]\n\n  '@esbuild/android-arm64@0.21.5':\n    resolution: {integrity: sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [android]\n\n  '@esbuild/android-arm64@0.23.1':\n    resolution: {integrity: sha512-xw50ipykXcLstLeWH7WRdQuysJqejuAGPd30vd1i5zSyKK3WE+ijzHmLKxdiCMtH1pHz78rOg0BKSYOSB/2Khw==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [android]\n\n  '@esbuild/android-arm64@0.24.0':\n    resolution: {integrity: sha512-Vsm497xFM7tTIPYK9bNTYJyF/lsP590Qc1WxJdlB6ljCbdZKU9SY8i7+Iin4kyhV/KV5J2rOKsBQbB77Ab7L/w==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [android]\n\n  '@esbuild/android-arm@0.17.19':\n    resolution: {integrity: sha512-rIKddzqhmav7MSmoFCmDIb6e2W57geRsM94gV2l38fzhXMwq7hZoClug9USI2pFRGL06f4IOPHHpFNOkWieR8A==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [android]\n\n  '@esbuild/android-arm@0.18.20':\n    resolution: {integrity: sha512-fyi7TDI/ijKKNZTUJAQqiG5T7YjJXgnzkURqmGj13C6dCqckZBLdl4h7bkhHt/t0WP+zO9/zwroDvANaOqO5Sw==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [android]\n\n  '@esbuild/android-arm@0.21.5':\n    resolution: {integrity: sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [android]\n\n  '@esbuild/android-arm@0.23.1':\n    resolution: {integrity: sha512-uz6/tEy2IFm9RYOyvKl88zdzZfwEfKZmnX9Cj1BHjeSGNuGLuMD1kR8y5bteYmwqKm1tj8m4cb/aKEorr6fHWQ==}\n    engines: {node: '>=18'}\n    cpu: [arm]\n    os: [android]\n\n  '@esbuild/android-arm@0.24.0':\n    resolution: {integrity: sha512-arAtTPo76fJ/ICkXWetLCc9EwEHKaeya4vMrReVlEIUCAUncH7M4bhMQ+M9Vf+FFOZJdTNMXNBrWwW+OXWpSew==}\n    engines: {node: '>=18'}\n    cpu: [arm]\n    os: [android]\n\n  '@esbuild/android-x64@0.17.19':\n    resolution: {integrity: sha512-uUTTc4xGNDT7YSArp/zbtmbhO0uEEK9/ETW29Wk1thYUJBz3IVnvgEiEwEa9IeLyvnpKrWK64Utw2bgUmDveww==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [android]\n\n  '@esbuild/android-x64@0.18.20':\n    resolution: {integrity: sha512-8GDdlePJA8D6zlZYJV/jnrRAi6rOiNaCC/JclcXpB+KIuvfBN4owLtgzY2bsxnx666XjJx2kDPUmnTtR8qKQUg==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [android]\n\n  '@esbuild/android-x64@0.21.5':\n    resolution: {integrity: sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [android]\n\n  '@esbuild/android-x64@0.23.1':\n    resolution: {integrity: sha512-nlN9B69St9BwUoB+jkyU090bru8L0NA3yFvAd7k8dNsVH8bi9a8cUAUSEcEEgTp2z3dbEDGJGfP6VUnkQnlReg==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [android]\n\n  '@esbuild/android-x64@0.24.0':\n    resolution: {integrity: sha512-t8GrvnFkiIY7pa7mMgJd7p8p8qqYIz1NYiAoKc75Zyv73L3DZW++oYMSHPRarcotTKuSs6m3hTOa5CKHaS02TQ==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [android]\n\n  '@esbuild/darwin-arm64@0.17.19':\n    resolution: {integrity: sha512-80wEoCfF/hFKM6WE1FyBHc9SfUblloAWx6FJkFWTWiCoht9Mc0ARGEM47e67W9rI09YoUxJL68WHfDRYEAvOhg==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@esbuild/darwin-arm64@0.18.20':\n    resolution: {integrity: sha512-bxRHW5kHU38zS2lPTPOyuyTm+S+eobPUnTNkdJEfAddYgEcll4xkT8DB9d2008DtTbl7uJag2HuE5NZAZgnNEA==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@esbuild/darwin-arm64@0.21.5':\n    resolution: {integrity: sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@esbuild/darwin-arm64@0.23.1':\n    resolution: {integrity: sha512-YsS2e3Wtgnw7Wq53XXBLcV6JhRsEq8hkfg91ESVadIrzr9wO6jJDMZnCQbHm1Guc5t/CdDiFSSfWP58FNuvT3Q==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@esbuild/darwin-arm64@0.24.0':\n    resolution: {integrity: sha512-CKyDpRbK1hXwv79soeTJNHb5EiG6ct3efd/FTPdzOWdbZZfGhpbcqIpiD0+vwmpu0wTIL97ZRPZu8vUt46nBSw==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@esbuild/darwin-x64@0.17.19':\n    resolution: {integrity: sha512-IJM4JJsLhRYr9xdtLytPLSH9k/oxR3boaUIYiHkAawtwNOXKE8KoU8tMvryogdcT8AU+Bflmh81Xn6Q0vTZbQw==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@esbuild/darwin-x64@0.18.20':\n    resolution: {integrity: sha512-pc5gxlMDxzm513qPGbCbDukOdsGtKhfxD1zJKXjCCcU7ju50O7MeAZ8c4krSJcOIJGFR+qx21yMMVYwiQvyTyQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@esbuild/darwin-x64@0.21.5':\n    resolution: {integrity: sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@esbuild/darwin-x64@0.23.1':\n    resolution: {integrity: sha512-aClqdgTDVPSEGgoCS8QDG37Gu8yc9lTHNAQlsztQ6ENetKEO//b8y31MMu2ZaPbn4kVsIABzVLXYLhCGekGDqw==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@esbuild/darwin-x64@0.24.0':\n    resolution: {integrity: sha512-rgtz6flkVkh58od4PwTRqxbKH9cOjaXCMZgWD905JOzjFKW+7EiUObfd/Kav+A6Gyud6WZk9w+xu6QLytdi2OA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@esbuild/freebsd-arm64@0.17.19':\n    resolution: {integrity: sha512-pBwbc7DufluUeGdjSU5Si+P3SoMF5DQ/F/UmTSb8HXO80ZEAJmrykPyzo1IfNbAoaqw48YRpv8shwd1NoI0jcQ==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-arm64@0.18.20':\n    resolution: {integrity: sha512-yqDQHy4QHevpMAaxhhIwYPMv1NECwOvIpGCZkECn8w2WFHXjEwrBn3CeNIYsibZ/iZEUemj++M26W3cNR5h+Tw==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-arm64@0.21.5':\n    resolution: {integrity: sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-arm64@0.23.1':\n    resolution: {integrity: sha512-h1k6yS8/pN/NHlMl5+v4XPfikhJulk4G+tKGFIOwURBSFzE8bixw1ebjluLOjfwtLqY0kewfjLSrO6tN2MgIhA==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-arm64@0.24.0':\n    resolution: {integrity: sha512-6Mtdq5nHggwfDNLAHkPlyLBpE5L6hwsuXZX8XNmHno9JuL2+bg2BX5tRkwjyfn6sKbxZTq68suOjgWqCicvPXA==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-x64@0.17.19':\n    resolution: {integrity: sha512-4lu+n8Wk0XlajEhbEffdy2xy53dpR06SlzvhGByyg36qJw6Kpfk7cp45DR/62aPH9mtJRmIyrXAS5UWBrJT6TQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-x64@0.18.20':\n    resolution: {integrity: sha512-tgWRPPuQsd3RmBZwarGVHZQvtzfEBOreNuxEMKFcd5DaDn2PbBxfwLcj4+aenoh7ctXcbXmOQIn8HI6mCSw5MQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-x64@0.21.5':\n    resolution: {integrity: sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-x64@0.23.1':\n    resolution: {integrity: sha512-lK1eJeyk1ZX8UklqFd/3A60UuZ/6UVfGT2LuGo3Wp4/z7eRTRYY+0xOu2kpClP+vMTi9wKOfXi2vjUpO1Ro76g==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@esbuild/freebsd-x64@0.24.0':\n    resolution: {integrity: sha512-D3H+xh3/zphoX8ck4S2RxKR6gHlHDXXzOf6f/9dbFt/NRBDIE33+cVa49Kil4WUjxMGW0ZIYBYtaGCa2+OsQwQ==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@esbuild/linux-arm64@0.17.19':\n    resolution: {integrity: sha512-ct1Tg3WGwd3P+oZYqic+YZF4snNl2bsnMKRkb3ozHmnM0dGWuxcPTTntAF6bOP0Sp4x0PjSF+4uHQ1xvxfRKqg==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@esbuild/linux-arm64@0.18.20':\n    resolution: {integrity: sha512-2YbscF+UL7SQAVIpnWvYwM+3LskyDmPhe31pE7/aoTMFKKzIc9lLbyGUpmmb8a8AixOL61sQ/mFh3jEjHYFvdA==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@esbuild/linux-arm64@0.21.5':\n    resolution: {integrity: sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@esbuild/linux-arm64@0.23.1':\n    resolution: {integrity: sha512-/93bf2yxencYDnItMYV/v116zff6UyTjo4EtEQjUBeGiVpMmffDNUyD9UN2zV+V3LRV3/on4xdZ26NKzn6754g==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@esbuild/linux-arm64@0.24.0':\n    resolution: {integrity: sha512-TDijPXTOeE3eaMkRYpcy3LarIg13dS9wWHRdwYRnzlwlA370rNdZqbcp0WTyyV/k2zSxfko52+C7jU5F9Tfj1g==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@esbuild/linux-arm@0.17.19':\n    resolution: {integrity: sha512-cdmT3KxjlOQ/gZ2cjfrQOtmhG4HJs6hhvm3mWSRDPtZ/lP5oe8FWceS10JaSJC13GBd4eH/haHnqf7hhGNLerA==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [linux]\n\n  '@esbuild/linux-arm@0.18.20':\n    resolution: {integrity: sha512-/5bHkMWnq1EgKr1V+Ybz3s1hWXok7mDFUMQ4cG10AfW3wL02PSZi5kFpYKrptDsgb2WAJIvRcDm+qIvXf/apvg==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [linux]\n\n  '@esbuild/linux-arm@0.21.5':\n    resolution: {integrity: sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==}\n    engines: {node: '>=12'}\n    cpu: [arm]\n    os: [linux]\n\n  '@esbuild/linux-arm@0.23.1':\n    resolution: {integrity: sha512-CXXkzgn+dXAPs3WBwE+Kvnrf4WECwBdfjfeYHpMeVxWE0EceB6vhWGShs6wi0IYEqMSIzdOF1XjQ/Mkm5d7ZdQ==}\n    engines: {node: '>=18'}\n    cpu: [arm]\n    os: [linux]\n\n  '@esbuild/linux-arm@0.24.0':\n    resolution: {integrity: sha512-gJKIi2IjRo5G6Glxb8d3DzYXlxdEj2NlkixPsqePSZMhLudqPhtZ4BUrpIuTjJYXxvF9njql+vRjB2oaC9XpBw==}\n    engines: {node: '>=18'}\n    cpu: [arm]\n    os: [linux]\n\n  '@esbuild/linux-ia32@0.17.19':\n    resolution: {integrity: sha512-w4IRhSy1VbsNxHRQpeGCHEmibqdTUx61Vc38APcsRbuVgK0OPEnQ0YD39Brymn96mOx48Y2laBQGqgZ0j9w6SQ==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [linux]\n\n  '@esbuild/linux-ia32@0.18.20':\n    resolution: {integrity: sha512-P4etWwq6IsReT0E1KHU40bOnzMHoH73aXp96Fs8TIT6z9Hu8G6+0SHSw9i2isWrD2nbx2qo5yUqACgdfVGx7TA==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [linux]\n\n  '@esbuild/linux-ia32@0.21.5':\n    resolution: {integrity: sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [linux]\n\n  '@esbuild/linux-ia32@0.23.1':\n    resolution: {integrity: sha512-VTN4EuOHwXEkXzX5nTvVY4s7E/Krz7COC8xkftbbKRYAl96vPiUssGkeMELQMOnLOJ8k3BY1+ZY52tttZnHcXQ==}\n    engines: {node: '>=18'}\n    cpu: [ia32]\n    os: [linux]\n\n  '@esbuild/linux-ia32@0.24.0':\n    resolution: {integrity: sha512-K40ip1LAcA0byL05TbCQ4yJ4swvnbzHscRmUilrmP9Am7//0UjPreh4lpYzvThT2Quw66MhjG//20mrufm40mA==}\n    engines: {node: '>=18'}\n    cpu: [ia32]\n    os: [linux]\n\n  '@esbuild/linux-loong64@0.17.19':\n    resolution: {integrity: sha512-2iAngUbBPMq439a+z//gE+9WBldoMp1s5GWsUSgqHLzLJ9WoZLZhpwWuym0u0u/4XmZ3gpHmzV84PonE+9IIdQ==}\n    engines: {node: '>=12'}\n    cpu: [loong64]\n    os: [linux]\n\n  '@esbuild/linux-loong64@0.18.20':\n    resolution: {integrity: sha512-nXW8nqBTrOpDLPgPY9uV+/1DjxoQ7DoB2N8eocyq8I9XuqJ7BiAMDMf9n1xZM9TgW0J8zrquIb/A7s3BJv7rjg==}\n    engines: {node: '>=12'}\n    cpu: [loong64]\n    os: [linux]\n\n  '@esbuild/linux-loong64@0.21.5':\n    resolution: {integrity: sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==}\n    engines: {node: '>=12'}\n    cpu: [loong64]\n    os: [linux]\n\n  '@esbuild/linux-loong64@0.23.1':\n    resolution: {integrity: sha512-Vx09LzEoBa5zDnieH8LSMRToj7ir/Jeq0Gu6qJ/1GcBq9GkfoEAoXvLiW1U9J1qE/Y/Oyaq33w5p2ZWrNNHNEw==}\n    engines: {node: '>=18'}\n    cpu: [loong64]\n    os: [linux]\n\n  '@esbuild/linux-loong64@0.24.0':\n    resolution: {integrity: sha512-0mswrYP/9ai+CU0BzBfPMZ8RVm3RGAN/lmOMgW4aFUSOQBjA31UP8Mr6DDhWSuMwj7jaWOT0p0WoZ6jeHhrD7g==}\n    engines: {node: '>=18'}\n    cpu: [loong64]\n    os: [linux]\n\n  '@esbuild/linux-mips64el@0.17.19':\n    resolution: {integrity: sha512-LKJltc4LVdMKHsrFe4MGNPp0hqDFA1Wpt3jE1gEyM3nKUvOiO//9PheZZHfYRfYl6AwdTH4aTcXSqBerX0ml4A==}\n    engines: {node: '>=12'}\n    cpu: [mips64el]\n    os: [linux]\n\n  '@esbuild/linux-mips64el@0.18.20':\n    resolution: {integrity: sha512-d5NeaXZcHp8PzYy5VnXV3VSd2D328Zb+9dEq5HE6bw6+N86JVPExrA6O68OPwobntbNJ0pzCpUFZTo3w0GyetQ==}\n    engines: {node: '>=12'}\n    cpu: [mips64el]\n    os: [linux]\n\n  '@esbuild/linux-mips64el@0.21.5':\n    resolution: {integrity: sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==}\n    engines: {node: '>=12'}\n    cpu: [mips64el]\n    os: [linux]\n\n  '@esbuild/linux-mips64el@0.23.1':\n    resolution: {integrity: sha512-nrFzzMQ7W4WRLNUOU5dlWAqa6yVeI0P78WKGUo7lg2HShq/yx+UYkeNSE0SSfSure0SqgnsxPvmAUu/vu0E+3Q==}\n    engines: {node: '>=18'}\n    cpu: [mips64el]\n    os: [linux]\n\n  '@esbuild/linux-mips64el@0.24.0':\n    resolution: {integrity: sha512-hIKvXm0/3w/5+RDtCJeXqMZGkI2s4oMUGj3/jM0QzhgIASWrGO5/RlzAzm5nNh/awHE0A19h/CvHQe6FaBNrRA==}\n    engines: {node: '>=18'}\n    cpu: [mips64el]\n    os: [linux]\n\n  '@esbuild/linux-ppc64@0.17.19':\n    resolution: {integrity: sha512-/c/DGybs95WXNS8y3Ti/ytqETiW7EU44MEKuCAcpPto3YjQbyK3IQVKfF6nbghD7EcLUGl0NbiL5Rt5DMhn5tg==}\n    engines: {node: '>=12'}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@esbuild/linux-ppc64@0.18.20':\n    resolution: {integrity: sha512-WHPyeScRNcmANnLQkq6AfyXRFr5D6N2sKgkFo2FqguP44Nw2eyDlbTdZwd9GYk98DZG9QItIiTlFLHJHjxP3FA==}\n    engines: {node: '>=12'}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@esbuild/linux-ppc64@0.21.5':\n    resolution: {integrity: sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==}\n    engines: {node: '>=12'}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@esbuild/linux-ppc64@0.23.1':\n    resolution: {integrity: sha512-dKN8fgVqd0vUIjxuJI6P/9SSSe/mB9rvA98CSH2sJnlZ/OCZWO1DJvxj8jvKTfYUdGfcq2dDxoKaC6bHuTlgcw==}\n    engines: {node: '>=18'}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@esbuild/linux-ppc64@0.24.0':\n    resolution: {integrity: sha512-HcZh5BNq0aC52UoocJxaKORfFODWXZxtBaaZNuN3PUX3MoDsChsZqopzi5UupRhPHSEHotoiptqikjN/B77mYQ==}\n    engines: {node: '>=18'}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@esbuild/linux-riscv64@0.17.19':\n    resolution: {integrity: sha512-FC3nUAWhvFoutlhAkgHf8f5HwFWUL6bYdvLc/TTuxKlvLi3+pPzdZiFKSWz/PF30TB1K19SuCxDTI5KcqASJqA==}\n    engines: {node: '>=12'}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@esbuild/linux-riscv64@0.18.20':\n    resolution: {integrity: sha512-WSxo6h5ecI5XH34KC7w5veNnKkju3zBRLEQNY7mv5mtBmrP/MjNBCAlsM2u5hDBlS3NGcTQpoBvRzqBcRtpq1A==}\n    engines: {node: '>=12'}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@esbuild/linux-riscv64@0.21.5':\n    resolution: {integrity: sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==}\n    engines: {node: '>=12'}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@esbuild/linux-riscv64@0.23.1':\n    resolution: {integrity: sha512-5AV4Pzp80fhHL83JM6LoA6pTQVWgB1HovMBsLQ9OZWLDqVY8MVobBXNSmAJi//Csh6tcY7e7Lny2Hg1tElMjIA==}\n    engines: {node: '>=18'}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@esbuild/linux-riscv64@0.24.0':\n    resolution: {integrity: sha512-bEh7dMn/h3QxeR2KTy1DUszQjUrIHPZKyO6aN1X4BCnhfYhuQqedHaa5MxSQA/06j3GpiIlFGSsy1c7Gf9padw==}\n    engines: {node: '>=18'}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@esbuild/linux-s390x@0.17.19':\n    resolution: {integrity: sha512-IbFsFbxMWLuKEbH+7sTkKzL6NJmG2vRyy6K7JJo55w+8xDk7RElYn6xvXtDW8HCfoKBFK69f3pgBJSUSQPr+4Q==}\n    engines: {node: '>=12'}\n    cpu: [s390x]\n    os: [linux]\n\n  '@esbuild/linux-s390x@0.18.20':\n    resolution: {integrity: sha512-+8231GMs3mAEth6Ja1iK0a1sQ3ohfcpzpRLH8uuc5/KVDFneH6jtAJLFGafpzpMRO6DzJ6AvXKze9LfFMrIHVQ==}\n    engines: {node: '>=12'}\n    cpu: [s390x]\n    os: [linux]\n\n  '@esbuild/linux-s390x@0.21.5':\n    resolution: {integrity: sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==}\n    engines: {node: '>=12'}\n    cpu: [s390x]\n    os: [linux]\n\n  '@esbuild/linux-s390x@0.23.1':\n    resolution: {integrity: sha512-9ygs73tuFCe6f6m/Tb+9LtYxWR4c9yg7zjt2cYkjDbDpV/xVn+68cQxMXCjUpYwEkze2RcU/rMnfIXNRFmSoDw==}\n    engines: {node: '>=18'}\n    cpu: [s390x]\n    os: [linux]\n\n  '@esbuild/linux-s390x@0.24.0':\n    resolution: {integrity: sha512-ZcQ6+qRkw1UcZGPyrCiHHkmBaj9SiCD8Oqd556HldP+QlpUIe2Wgn3ehQGVoPOvZvtHm8HPx+bH20c9pvbkX3g==}\n    engines: {node: '>=18'}\n    cpu: [s390x]\n    os: [linux]\n\n  '@esbuild/linux-x64@0.17.19':\n    resolution: {integrity: sha512-68ngA9lg2H6zkZcyp22tsVt38mlhWde8l3eJLWkyLrp4HwMUr3c1s/M2t7+kHIhvMjglIBrFpncX1SzMckomGw==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [linux]\n\n  '@esbuild/linux-x64@0.18.20':\n    resolution: {integrity: sha512-UYqiqemphJcNsFEskc73jQ7B9jgwjWrSayxawS6UVFZGWrAAtkzjxSqnoclCXxWtfwLdzU+vTpcNYhpn43uP1w==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [linux]\n\n  '@esbuild/linux-x64@0.21.5':\n    resolution: {integrity: sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [linux]\n\n  '@esbuild/linux-x64@0.23.1':\n    resolution: {integrity: sha512-EV6+ovTsEXCPAp58g2dD68LxoP/wK5pRvgy0J/HxPGB009omFPv3Yet0HiaqvrIrgPTBuC6wCH1LTOY91EO5hQ==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [linux]\n\n  '@esbuild/linux-x64@0.24.0':\n    resolution: {integrity: sha512-vbutsFqQ+foy3wSSbmjBXXIJ6PL3scghJoM8zCL142cGaZKAdCZHyf+Bpu/MmX9zT9Q0zFBVKb36Ma5Fzfa8xA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [linux]\n\n  '@esbuild/netbsd-x64@0.17.19':\n    resolution: {integrity: sha512-CwFq42rXCR8TYIjIfpXCbRX0rp1jo6cPIUPSaWwzbVI4aOfX96OXY8M6KNmtPcg7QjYeDmN+DD0Wp3LaBOLf4Q==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [netbsd]\n\n  '@esbuild/netbsd-x64@0.18.20':\n    resolution: {integrity: sha512-iO1c++VP6xUBUmltHZoMtCUdPlnPGdBom6IrO4gyKPFFVBKioIImVooR5I83nTew5UOYrk3gIJhbZh8X44y06A==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [netbsd]\n\n  '@esbuild/netbsd-x64@0.21.5':\n    resolution: {integrity: sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [netbsd]\n\n  '@esbuild/netbsd-x64@0.23.1':\n    resolution: {integrity: sha512-aevEkCNu7KlPRpYLjwmdcuNz6bDFiE7Z8XC4CPqExjTvrHugh28QzUXVOZtiYghciKUacNktqxdpymplil1beA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [netbsd]\n\n  '@esbuild/netbsd-x64@0.24.0':\n    resolution: {integrity: sha512-hjQ0R/ulkO8fCYFsG0FZoH+pWgTTDreqpqY7UnQntnaKv95uP5iW3+dChxnx7C3trQQU40S+OgWhUVwCjVFLvg==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [netbsd]\n\n  '@esbuild/openbsd-arm64@0.23.1':\n    resolution: {integrity: sha512-3x37szhLexNA4bXhLrCC/LImN/YtWis6WXr1VESlfVtVeoFJBRINPJ3f0a/6LV8zpikqoUg4hyXw0sFBt5Cr+Q==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-arm64@0.24.0':\n    resolution: {integrity: sha512-MD9uzzkPQbYehwcN583yx3Tu5M8EIoTD+tUgKF982WYL9Pf5rKy9ltgD0eUgs8pvKnmizxjXZyLt0z6DC3rRXg==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-x64@0.17.19':\n    resolution: {integrity: sha512-cnq5brJYrSZ2CF6c35eCmviIN3k3RczmHz8eYaVlNasVqsNY+JKohZU5MKmaOI+KkllCdzOKKdPs762VCPC20g==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-x64@0.18.20':\n    resolution: {integrity: sha512-e5e4YSsuQfX4cxcygw/UCPIEP6wbIL+se3sxPdCiMbFLBWu0eiZOJ7WoD+ptCLrmjZBK1Wk7I6D/I3NglUGOxg==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-x64@0.21.5':\n    resolution: {integrity: sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-x64@0.23.1':\n    resolution: {integrity: sha512-aY2gMmKmPhxfU+0EdnN+XNtGbjfQgwZj43k8G3fyrDM/UdZww6xrWxmDkuz2eCZchqVeABjV5BpildOrUbBTqA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [openbsd]\n\n  '@esbuild/openbsd-x64@0.24.0':\n    resolution: {integrity: sha512-4ir0aY1NGUhIC1hdoCzr1+5b43mw99uNwVzhIq1OY3QcEwPDO3B7WNXBzaKY5Nsf1+N11i1eOfFcq+D/gOS15Q==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [openbsd]\n\n  '@esbuild/sunos-x64@0.17.19':\n    resolution: {integrity: sha512-vCRT7yP3zX+bKWFeP/zdS6SqdWB8OIpaRq/mbXQxTGHnIxspRtigpkUcDMlSCOejlHowLqII7K2JKevwyRP2rg==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [sunos]\n\n  '@esbuild/sunos-x64@0.18.20':\n    resolution: {integrity: sha512-kDbFRFp0YpTQVVrqUd5FTYmWo45zGaXe0X8E1G/LKFC0v8x0vWrhOWSLITcCn63lmZIxfOMXtCfti/RxN/0wnQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [sunos]\n\n  '@esbuild/sunos-x64@0.21.5':\n    resolution: {integrity: sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [sunos]\n\n  '@esbuild/sunos-x64@0.23.1':\n    resolution: {integrity: sha512-RBRT2gqEl0IKQABT4XTj78tpk9v7ehp+mazn2HbUeZl1YMdaGAQqhapjGTCe7uw7y0frDi4gS0uHzhvpFuI1sA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [sunos]\n\n  '@esbuild/sunos-x64@0.24.0':\n    resolution: {integrity: sha512-jVzdzsbM5xrotH+W5f1s+JtUy1UWgjU0Cf4wMvffTB8m6wP5/kx0KiaLHlbJO+dMgtxKV8RQ/JvtlFcdZ1zCPA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [sunos]\n\n  '@esbuild/win32-arm64@0.17.19':\n    resolution: {integrity: sha512-yYx+8jwowUstVdorcMdNlzklLYhPxjniHWFKgRqH7IFlUEa0Umu3KuYplf1HUZZ422e3NU9F4LGb+4O0Kdcaag==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@esbuild/win32-arm64@0.18.20':\n    resolution: {integrity: sha512-ddYFR6ItYgoaq4v4JmQQaAI5s7npztfV4Ag6NrhiaW0RrnOXqBkgwZLofVTlq1daVTQNhtI5oieTvkRPfZrePg==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@esbuild/win32-arm64@0.21.5':\n    resolution: {integrity: sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==}\n    engines: {node: '>=12'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@esbuild/win32-arm64@0.23.1':\n    resolution: {integrity: sha512-4O+gPR5rEBe2FpKOVyiJ7wNDPA8nGzDuJ6gN4okSA1gEOYZ67N8JPk58tkWtdtPeLz7lBnY6I5L3jdsr3S+A6A==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@esbuild/win32-arm64@0.24.0':\n    resolution: {integrity: sha512-iKc8GAslzRpBytO2/aN3d2yb2z8XTVfNV0PjGlCxKo5SgWmNXx82I/Q3aG1tFfS+A2igVCY97TJ8tnYwpUWLCA==}\n    engines: {node: '>=18'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@esbuild/win32-ia32@0.17.19':\n    resolution: {integrity: sha512-eggDKanJszUtCdlVs0RB+h35wNlb5v4TWEkq4vZcmVt5u/HiDZrTXe2bWFQUez3RgNHwx/x4sk5++4NSSicKkw==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@esbuild/win32-ia32@0.18.20':\n    resolution: {integrity: sha512-Wv7QBi3ID/rROT08SABTS7eV4hX26sVduqDOTe1MvGMjNd3EjOz4b7zeexIR62GTIEKrfJXKL9LFxTYgkyeu7g==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@esbuild/win32-ia32@0.21.5':\n    resolution: {integrity: sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==}\n    engines: {node: '>=12'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@esbuild/win32-ia32@0.23.1':\n    resolution: {integrity: sha512-BcaL0Vn6QwCwre3Y717nVHZbAa4UBEigzFm6VdsVdT/MbZ38xoj1X9HPkZhbmaBGUD1W8vxAfffbDe8bA6AKnQ==}\n    engines: {node: '>=18'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@esbuild/win32-ia32@0.24.0':\n    resolution: {integrity: sha512-vQW36KZolfIudCcTnaTpmLQ24Ha1RjygBo39/aLkM2kmjkWmZGEJ5Gn9l5/7tzXA42QGIoWbICfg6KLLkIw6yw==}\n    engines: {node: '>=18'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@esbuild/win32-x64@0.17.19':\n    resolution: {integrity: sha512-lAhycmKnVOuRYNtRtatQR1LPQf2oYCkRGkSFnseDAKPl8lu5SOsK/e1sXe5a0Pc5kHIHe6P2I/ilntNv2xf3cA==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [win32]\n\n  '@esbuild/win32-x64@0.18.20':\n    resolution: {integrity: sha512-kTdfRcSiDfQca/y9QIkng02avJ+NCaQvrMejlsB3RRv5sE9rRoeBPISaZpKxHELzRxZyLvNts1P27W3wV+8geQ==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [win32]\n\n  '@esbuild/win32-x64@0.21.5':\n    resolution: {integrity: sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==}\n    engines: {node: '>=12'}\n    cpu: [x64]\n    os: [win32]\n\n  '@esbuild/win32-x64@0.23.1':\n    resolution: {integrity: sha512-BHpFFeslkWrXWyUPnbKm+xYYVYruCinGcftSBaa8zoF9hZO4BcSCFUvHVTtzpIY6YzUnYtuEhZ+C9iEXjxnasg==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [win32]\n\n  '@esbuild/win32-x64@0.24.0':\n    resolution: {integrity: sha512-7IAFPrjSQIJrGsK6flwg7NFmwBoSTyF3rl7If0hNUFQU4ilTsEPL6GuMuU9BfIWVVGuRnuIidkSMC+c0Otu8IA==}\n    engines: {node: '>=18'}\n    cpu: [x64]\n    os: [win32]\n\n  '@eslint-community/eslint-utils@4.4.0':\n    resolution: {integrity: sha512-1/sA4dwrzBAyeUoQ6oxahHKmrZvsnLCg4RfxW3ZFGGmQkSNQPFNLV9CUEFQP1x9EYXHTo5p6xdhZM1Ne9p/AfA==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.0.0 || ^7.0.0 || >=8.0.0\n\n  '@eslint-community/regexpp@4.10.0':\n    resolution: {integrity: sha512-Cu96Sd2By9mCNTx2iyKOmq10v22jUVQv0lQnlGNy16oE9589yE+QADPbrMGCkA51cKZSg3Pu/aTJVTGfL/qjUA==}\n    engines: {node: ^12.0.0 || ^14.0.0 || >=16.0.0}\n\n  '@eslint-community/regexpp@4.11.1':\n    resolution: {integrity: sha512-m4DVN9ZqskZoLU5GlWZadwDnYo3vAEydiUayB9widCl9ffWx2IvPnp6n3on5rJmziJSw9Bv+Z3ChDVdMwXCY8Q==}\n    engines: {node: ^12.0.0 || ^14.0.0 || >=16.0.0}\n\n  '@eslint/config-array@0.18.0':\n    resolution: {integrity: sha512-fTxvnS1sRMu3+JjXwJG0j/i4RT9u4qJ+lqS/yCGap4lH4zZGzQ7tu+xZqQmcMZq5OBZDL4QRxQzRjkWcGt8IVw==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@eslint/core@0.6.0':\n    resolution: {integrity: sha512-8I2Q8ykA4J0x0o7cg67FPVnehcqWTBehu/lmY+bolPFHGjh49YzGBMXTvpqVgEbBdvNCSxj6iFgiIyHzf03lzg==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@eslint/eslintrc@2.1.4':\n    resolution: {integrity: sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@eslint/eslintrc@3.1.0':\n    resolution: {integrity: sha512-4Bfj15dVJdoy3RfZmmo86RK1Fwzn6SstsvK9JS+BaVKqC6QQQQyXekNaC+g+LKNgkQ+2VhGAzm6hO40AhMR3zQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@eslint/js@8.57.0':\n    resolution: {integrity: sha512-Ys+3g2TaW7gADOJzPt83SJtCDhMjndcDMFVQ/Tj9iA1BfJzFKD9mAUXT3OenpuPHbI6P/myECxRJrofUsDx/5g==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@eslint/js@8.57.1':\n    resolution: {integrity: sha512-d9zaMRSTIKDLhctzH12MtXvJKSSUhaHcjV+2Z+GK+EEY7XKpP5yR4x+N3TAcHTcu963nIr+TMcCb4DBCYX1z6Q==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@eslint/js@9.12.0':\n    resolution: {integrity: sha512-eohesHH8WFRUprDNyEREgqP6beG6htMeUYeCpkEgBCieCMme5r9zFWjzAJp//9S+Kub4rqE+jXe9Cp1a7IYIIA==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@eslint/object-schema@2.1.4':\n    resolution: {integrity: sha512-BsWiH1yFGjXXS2yvrf5LyuoSIIbPrGUWob917o+BTKuZ7qJdxX8aJLRxs1fS9n6r7vESrq1OUqb68dANcFXuQQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@eslint/plugin-kit@0.2.0':\n    resolution: {integrity: sha512-vH9PiIMMwvhCx31Af3HiGzsVNULDbyVkHXwlemn/B0TFj/00ho3y55efXrUZTfQipxoHC5u4xq6zblww1zm1Ig==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@faker-js/faker@5.5.3':\n    resolution: {integrity: sha512-R11tGE6yIFwqpaIqcfkcg7AICXzFg14+5h5v0TfF/9+RMDL6jhzCy/pxHVOfbALGdtVYdt6JdR21tuxEgl34dw==}\n\n  '@fontsource-variable/inter@5.0.15':\n    resolution: {integrity: sha512-CdQPQQgOVxg6ifmbrqYZeUqtQf7p2wPn6EvJ4M+vdNnsmYZgYwPPPQDNlIOU7LCUlSGaN26v6H0uA030WKn61g==}\n\n  '@fontsource-variable/inter@5.1.0':\n    resolution: {integrity: sha512-Wj2dUGP0vUpxRGQTXQTCNJO+aLcFcQm+gUPXfj/aS877bQkEPBPv9JvZJpwdm2vzelt8NTZ+ausKlBCJjh2XIg==}\n\n  '@fontsource-variable/material-symbols-rounded@5.0.16':\n    resolution: {integrity: sha512-HtH/bpUBj/9irIouf2uPaB+qf6HKpR0JFxSDK2HGaqOLsJqIxs4RJB2Y9IXASwTN50FBd1g8KZ6O5vNYEsU94A==}\n\n  '@fontsource-variable/material-symbols-rounded@5.1.2':\n    resolution: {integrity: sha512-twPi3k83tKmXw2r4VkqMLRMDvIxZlospGydYjVqfMbKPkj6VzAmc2Aw4Pweb7Tg6n04a7LuP/V+gAdyYdgBZPA==}\n\n  '@fontsource-variable/material-symbols-rounded@5.1.3':\n    resolution: {integrity: sha512-d0veYThfkhNkLKOGEaMtalfkPSvKOs6yHmkyA4nOUwDS6wcMiQt8exXbqtpXIVI61aUJoBKHP2lChHx+su4DLg==}\n\n  '@fontsource-variable/roboto-mono@5.0.16':\n    resolution: {integrity: sha512-f4/XARRCSW8aG9qR7fF+lqIMsS/xJ46fKySdlQ3BaFLzEXeioeQylkHS6DoOF+2MPZUylLQFpmnpC0q22Orp0g==}\n\n  '@fontsource-variable/roboto-mono@5.1.0':\n    resolution: {integrity: sha512-87USlDpEi7dS/ayPXwf/08vdgJKEYxdQmuZk5kCzWBtumimdwWlA9Vh36TCtYqFC+dGgDxPX/4PJK+0lxkEd5A==}\n\n  '@glideapps/ts-necessities@2.2.3':\n    resolution: {integrity: sha512-gXi0awOZLHk3TbW55GZLCPP6O+y/b5X1pBXKBVckFONSwF1z1E5ND2BGJsghQFah+pW7pkkyFb2VhUQI2qhL5w==}\n\n  '@graphql-codegen/add@5.0.0':\n    resolution: {integrity: sha512-ynWDOsK2yxtFHwcJTB9shoSkUd7YXd6ZE57f0nk7W5cu/nAgxZZpEsnTPEpZB/Mjf14YRGe2uJHQ7AfElHjqUQ==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/add@5.0.3':\n    resolution: {integrity: sha512-SxXPmramkth8XtBlAHu4H4jYcYXM/o3p01+psU+0NADQowA8jtYkK6MW5rV6T+CxkEaNZItfSmZRPgIuypcqnA==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/cli@5.0.0':\n    resolution: {integrity: sha512-A7J7+be/a6e+/ul2KI5sfJlpoqeqwX8EzktaKCeduyVKgOLA6W5t+NUGf6QumBDXU8PEOqXk3o3F+RAwCWOiqA==}\n    hasBin: true\n    peerDependencies:\n      '@parcel/watcher': ^2.1.0\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n    peerDependenciesMeta:\n      '@parcel/watcher':\n        optional: true\n\n  '@graphql-codegen/cli@5.0.3':\n    resolution: {integrity: sha512-ULpF6Sbu2d7vNEOgBtE9avQp2oMgcPY/QBYcCqk0Xru5fz+ISjcovQX29V7CS7y5wWBRzNLoXwJQGeEyWbl05g==}\n    engines: {node: '>=16'}\n    hasBin: true\n    peerDependencies:\n      '@parcel/watcher': ^2.1.0\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n    peerDependenciesMeta:\n      '@parcel/watcher':\n        optional: true\n\n  '@graphql-codegen/client-preset@4.4.0':\n    resolution: {integrity: sha512-Q0NHFK7KXLhEaRC/k82ge0dHDfeHJEvvDeV0vV3+oSurHNa/lpxQtbK2BqknZe+JDfZ1YOOvYT93XsAkYD+SQg==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/core@4.0.2':\n    resolution: {integrity: sha512-IZbpkhwVqgizcjNiaVzNAzm/xbWT6YnGgeOLwVjm4KbJn3V2jchVtuzHH09G5/WkkLSk2wgbXNdwjM41JxO6Eg==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/gql-tag-operations@4.0.10':\n    resolution: {integrity: sha512-WsBEVL3XQdBboFJJL5WxrUjkuo3B7Sa51R9NbT7PKBe0HCNstoouGZIvQJRUubttFCqTTyoFtNsoRSKB+rsRug==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/introspection@4.0.3':\n    resolution: {integrity: sha512-4cHRG15Zu4MXMF4wTQmywNf4+fkDYv5lTbzraVfliDnB8rJKcaurQpRBi11KVuQUe24YTq/Cfk4uwewfNikWoA==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/plugin-helpers@2.7.2':\n    resolution: {integrity: sha512-kln2AZ12uii6U59OQXdjLk5nOlh1pHis1R98cDZGFnfaiAbX9V3fxcZ1MMJkB7qFUymTALzyjZoXXdyVmPMfRg==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/plugin-helpers@3.1.2':\n    resolution: {integrity: sha512-emOQiHyIliVOIjKVKdsI5MXj312zmRDwmHpyUTZMjfpvxq/UVAHUJIVdVf+lnjjrI+LXBTgMlTWTgHQfmICxjg==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/plugin-helpers@5.0.4':\n    resolution: {integrity: sha512-MOIuHFNWUnFnqVmiXtrI+4UziMTYrcquljaI5f/T/Bc7oO7sXcfkAvgkNWEEi9xWreYwvuer3VHCuPI/lAFWbw==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/schema-ast@4.1.0':\n    resolution: {integrity: sha512-kZVn0z+th9SvqxfKYgztA6PM7mhnSZaj4fiuBWvMTqA+QqQ9BBed6Pz41KuD/jr0gJtnlr2A4++/0VlpVbCTmQ==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typed-document-node@5.0.1':\n    resolution: {integrity: sha512-VFkhCuJnkgtbbgzoCAwTdJe2G1H6sd3LfCrDqWUrQe53y2ukfSb5Ov1PhAIkCBStKCMQBUY9YgGz9GKR40qQ8g==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typed-document-node@5.0.10':\n    resolution: {integrity: sha512-YPDUNs6x0muoVWlbY2yEs0lGxFHMTszlGDh6klT/5rqiTDTZg3zz8Wd1ZTihkcH8+V6T0AT9qDWwcx9fcS2tvQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typescript-document-nodes@4.0.10':\n    resolution: {integrity: sha512-J0iJgDCIiefmhNb/Fb02qlPqObHD1m0oPp5zQecqvY2bz/B4kIsbVKdNp38w2sVY6mmpwL+4BQOQfUy1nioASg==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typescript-operations@4.0.1':\n    resolution: {integrity: sha512-GpUWWdBVUec/Zqo23aFLBMrXYxN2irypHqDcKjN78JclDPdreasAEPcIpMfqf4MClvpmvDLy4ql+djVAwmkjbw==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typescript-operations@4.3.0':\n    resolution: {integrity: sha512-ZORwMy8OgsiYd9EZUhTMd4/g5LvTFpx6Fh6dNN0cxFkqSc6KhjX0vhzWsyK8N9+ILaHSutT8UTrLMdJi35HzDQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typescript-urql-graphcache@2.4.5':\n    resolution: {integrity: sha512-h+Px+Cj/9MMI5I8iQbSoJUWuq7I/hSCG5yM1tur8hzqzaQMbR5FGTwxlPnHFfUljvHj/bVdwYHwvO9p+PaNvww==}\n    peerDependencies:\n      '@urql/exchange-graphcache': ^4.1.1 || ^5.0.0\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n      graphql-tag: ^2.0.0\n\n  '@graphql-codegen/typescript-urql-graphcache@3.1.0':\n    resolution: {integrity: sha512-WM4MfSzOVWRS+SxcFFB16RRG8z/NFbNlyxCoVoPQ8UC6Gb13ZMSSUJS4t1g05dIoKMtAU+takEFdE3N4SO8vBw==}\n    engines: {node: '>= 16.0.0'}\n    peerDependencies:\n      '@urql/exchange-graphcache': ^5.2.0 || ^6.0.0\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n      graphql-tag: ^2.0.0\n\n  '@graphql-codegen/typescript@4.0.1':\n    resolution: {integrity: sha512-3YziQ21dCVdnHb+Us1uDb3pA6eG5Chjv0uTK+bt9dXeMlwYBU8MbtzvQTo4qvzWVC1AxSOKj0rgfNu1xCXqJyA==}\n    peerDependencies:\n      graphql: ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/typescript@4.1.0':\n    resolution: {integrity: sha512-/fS53Nh6U6c58GTOxqfyKTLQfQv36P8II/vPw/fg0cdcWbALhRPls69P8vXUWjrElmLKzCrdusBWPp/r+AKUBQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/urql-introspection@2.2.1':\n    resolution: {integrity: sha512-/KjHSf4dQNoYZZ+G10b3lbw304ik9xHzRf/syNvoYehmwdYE5J7RnO1v1Cz78LDm2NEdsFas6vJHi0sJd/pOHg==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/urql-introspection@3.0.0':\n    resolution: {integrity: sha512-DBYfG3CO3G6MTzp+/FaXuxYS6cFSkpDMwxXKoJVqKR0jIGd/ev3Gh1pTgqxndcBu8oV9xjiaBQglKCge0EqLpQ==}\n    engines: {node: '>= 16.0.0'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/visitor-plugin-common@2.13.1':\n    resolution: {integrity: sha512-mD9ufZhDGhyrSaWQGrU1Q1c5f01TeWtSWy/cDwXYjJcHIj1Y/DG2x0tOflEfCvh5WcnmHNIw4lzDsg1W7iFJEg==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/visitor-plugin-common@4.0.1':\n    resolution: {integrity: sha512-Bi/1z0nHg4QMsAqAJhds+ForyLtk7A3HQOlkrZNm3xEkY7lcBzPtiOTLBtvziwopBsXUxqeSwVjOOFPLS5Yw1Q==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-codegen/visitor-plugin-common@5.4.0':\n    resolution: {integrity: sha512-tL7hOrO+4MiNfDiHewhRQCiH9GTAh0M9Y/BZxYGGEdnrfGgqK5pCxtjq7EY/L19VGIyU7hhzYTQ0r1HzEbB4Jw==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@graphql-tools/apollo-engine-loader@8.0.1':\n    resolution: {integrity: sha512-NaPeVjtrfbPXcl+MLQCJLWtqe2/E4bbAqcauEOQ+3sizw1Fc2CNmhHRF8a6W4D0ekvTRRXAMptXYgA2uConbrA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/batch-execute@8.5.22':\n    resolution: {integrity: sha512-hcV1JaY6NJQFQEwCKrYhpfLK8frSXDbtNMoTur98u10Cmecy1zrqNKSqhEyGetpgHxaJRqszGzKeI3RuroDN6A==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/batch-execute@9.0.4':\n    resolution: {integrity: sha512-kkebDLXgDrep5Y0gK1RN3DMUlLqNhg60OAz0lTCqrYeja6DshxLtLkj+zV4mVbBA4mQOEoBmw6g1LZs3dA84/w==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/code-file-loader@8.1.3':\n    resolution: {integrity: sha512-Qoo8VyU0ux7k20DkzL5wFm7Y6iqlG1GQ0xA4T3EQbm4B/qbENsMc38l76QnXYIVmIlKAnD9EAvzxPEQ8iv+ZPA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/delegate@10.0.21':\n    resolution: {integrity: sha512-UytyYVvDfLQbCYG1aQo8Vc67c1WhEjzW9ytYKEEqMJSdlwfMCujHmCz7EyH5DNjTAKapDHuQcN5VivKGap/Beg==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/delegate@9.0.35':\n    resolution: {integrity: sha512-jwPu8NJbzRRMqi4Vp/5QX1vIUeUPpWmlQpOkXQD2r1X45YsVceyUUBnktCrlJlDB4jPRVy7JQGwmYo3KFiOBMA==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/documents@1.0.1':\n    resolution: {integrity: sha512-aweoMH15wNJ8g7b2r4C4WRuJxZ0ca8HtNO54rkye/3duxTkW4fGBEutCx03jCIr5+a1l+4vFJNP859QnAVBVCA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-graphql-ws@0.0.14':\n    resolution: {integrity: sha512-P2nlkAsPZKLIXImFhj0YTtny5NQVGSsKnhi7PzXiaHSXc6KkzqbWZHKvikD4PObanqg+7IO58rKFpGXP7eeO+w==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-graphql-ws@1.3.0':\n    resolution: {integrity: sha512-waghXHJjJiEEiWNYLbV7aRUbdvZOelSrtTgqpwco15k9iE4CMJyy2GQihLPEkIHcqSW0EHBlH1BbWDHI7noFPw==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-http@0.1.10':\n    resolution: {integrity: sha512-hnAfbKv0/lb9s31LhWzawQ5hghBfHS+gYWtqxME6Rl0Aufq9GltiiLBcl7OVVOnkLF0KhwgbYP1mB5VKmgTGpg==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-http@1.1.6':\n    resolution: {integrity: sha512-wGKjJzbi6em8cWI3sry6T7kAgoxMXYNM+KlbsWczPvIsHvv1cqXlrP1lwC6f7Ja1FfWdU1ZIEgOv93ext7IDyQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-legacy-ws@0.0.11':\n    resolution: {integrity: sha512-4ai+NnxlNfvIQ4c70hWFvOZlSUN8lt7yc+ZsrwtNFbFPH/EroIzFMapAxM9zwyv9bH38AdO3TQxZ5zNxgBdvUw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor-legacy-ws@1.1.0':\n    resolution: {integrity: sha512-k+6ZyiaAd8SmwuzbEOfA/LVkuI1nqidhoMw+CJ7c41QGOjSMzc0VS0UZbJyeitI0n7a+uP/Meln1wjzJ2ReDtQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor@0.0.20':\n    resolution: {integrity: sha512-GdvNc4vszmfeGvUqlcaH1FjBoguvMYzxAfT6tDd4/LgwymepHhinqLNA5otqwVLW+JETcDaK7xGENzFomuE6TA==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/executor@1.3.1':\n    resolution: {integrity: sha512-tgJDdGf9SCAm64ofEMZdv925u6/J+eTmv36TGNLxgP2DpCJsZ6gnJ4A+0D28EazDXqJIvMiPd+3d+o3cCRCAnQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/git-loader@8.0.7':\n    resolution: {integrity: sha512-+s23lxHR24+zLDk9/Hfl7/8Qcal8Q1yJ8armRp1fvcJyuc0RTZv97ZoZb0tArTfME74z+kJ92Mx4SfZMd7mHSQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/github-loader@8.0.1':\n    resolution: {integrity: sha512-W4dFLQJ5GtKGltvh/u1apWRFKBQOsDzFxO9cJkOYZj1VzHCpRF43uLST4VbCfWve+AwBqOuKr7YgkHoxpRMkcg==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/graphql-file-loader@7.5.17':\n    resolution: {integrity: sha512-hVwwxPf41zOYgm4gdaZILCYnKB9Zap7Ys9OhY1hbwuAuC4MMNY9GpUjoTU3CQc3zUiPoYStyRtUGkHSJZ3HxBw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/graphql-file-loader@8.0.1':\n    resolution: {integrity: sha512-7gswMqWBabTSmqbaNyWSmRRpStWlcCkBc73E6NZNlh4YNuiyKOwbvSkOUYFOqFMfEL+cFsXgAvr87Vz4XrYSbA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/graphql-tag-pluck@8.3.2':\n    resolution: {integrity: sha512-wJKkDjXRg2qJAVhAVE96zJGMli8Ity9mKUB7gTbvJwsAniaquRqLcTXUQ19X9qVT4ACzbbp+tAfk96b2U3tfog==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/import@6.7.18':\n    resolution: {integrity: sha512-XQDdyZTp+FYmT7as3xRWH/x8dx0QZA2WZqfMF5EWb36a0PiH7WwlRQYIdyYXj8YCLpiWkeBXgBRHmMnwEYR8iQ==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/import@7.0.1':\n    resolution: {integrity: sha512-935uAjAS8UAeXThqHfYVr4HEAp6nHJ2sximZKO1RzUTq5WoALMAhhGARl0+ecm6X+cqNUwIChJbjtaa6P/ML0w==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/json-file-loader@7.4.18':\n    resolution: {integrity: sha512-AJ1b6Y1wiVgkwsxT5dELXhIVUPs/u3VZ8/0/oOtpcoyO/vAeM5rOvvWegzicOOnQw8G45fgBRMkkRfeuwVt6+w==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/json-file-loader@8.0.1':\n    resolution: {integrity: sha512-lAy2VqxDAHjVyqeJonCP6TUemrpYdDuKt25a10X6zY2Yn3iFYGnuIDQ64cv3ytyGY6KPyPB+Kp+ZfOkNDG3FQA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/load@7.8.14':\n    resolution: {integrity: sha512-ASQvP+snHMYm+FhIaLxxFgVdRaM0vrN9wW2BKInQpktwWTXVyk+yP5nQUCEGmn0RTdlPKrffBaigxepkEAJPrg==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/load@8.0.2':\n    resolution: {integrity: sha512-S+E/cmyVmJ3CuCNfDuNF2EyovTwdWfQScXv/2gmvJOti2rGD8jTt9GYVzXaxhblLivQR9sBUCNZu/w7j7aXUCA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/merge@8.4.2':\n    resolution: {integrity: sha512-XbrHAaj8yDuINph+sAfuq3QCZ/tKblrTLOpirK0+CAgNlZUCHs0Fa+xtMUURgwCVThLle1AF7svJCxFizygLsw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/merge@9.0.4':\n    resolution: {integrity: sha512-MivbDLUQ+4Q8G/Hp/9V72hbn810IJDEZQ57F01sHnlrrijyadibfVhaQfW/pNH+9T/l8ySZpaR/DpL5i+ruZ+g==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/merge@9.0.7':\n    resolution: {integrity: sha512-lbTrIuXIbUSmSumHkPRY1QX0Z8JEtmRhnIrkH7vkfeEmf0kNn/nCWvJwqokm5U7L+a+DA1wlRM4slIlbfXjJBA==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/optimize@1.4.0':\n    resolution: {integrity: sha512-dJs/2XvZp+wgHH8T5J2TqptT9/6uVzIYvA6uFACha+ufvdMBedkfR4b4GbT8jAKLRARiqRTxy3dctnwkTM2tdw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/optimize@2.0.0':\n    resolution: {integrity: sha512-nhdT+CRGDZ+bk68ic+Jw1OZ99YCDIKYA5AlVAnBHJvMawSx9YQqQAIj4refNc1/LRieGiuWvhbG3jvPVYho0Dg==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/prisma-loader@8.0.4':\n    resolution: {integrity: sha512-hqKPlw8bOu/GRqtYr0+dINAI13HinTVYBDqhwGAPIFmLr5s+qKskzgCiwbsckdrb5LWVFmVZc+UXn80OGiyBzg==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/relay-operation-optimizer@6.5.18':\n    resolution: {integrity: sha512-mc5VPyTeV+LwiM+DNvoDQfPqwQYhPV/cl5jOBjTgSniyaq8/86aODfMkrE2OduhQ5E00hqrkuL2Fdrgk0w1QJg==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/relay-operation-optimizer@7.0.1':\n    resolution: {integrity: sha512-y0ZrQ/iyqWZlsS/xrJfSir3TbVYJTYmMOu4TaSz6F4FRDTQ3ie43BlKkhf04rC28pnUOS4BO9pDcAo1D30l5+A==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/schema@10.0.4':\n    resolution: {integrity: sha512-HuIwqbKxPaJujox25Ra4qwz0uQzlpsaBOzO6CVfzB/MemZdd+Gib8AIvfhQArK0YIN40aDran/yi+E5Xf0mQww==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/schema@10.0.6':\n    resolution: {integrity: sha512-EIJgPRGzpvDFEjVp+RF1zNNYIC36BYuIeZ514jFoJnI6IdxyVyIRDLx/ykgMdaa1pKQerpfdqDnsF4JnZoDHSQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/schema@9.0.19':\n    resolution: {integrity: sha512-oBRPoNBtCkk0zbUsyP4GaIzCt8C0aCI4ycIRUL67KK5pOHljKLBBtGT+Jr6hkzA74C8Gco8bpZPe7aWFjiaK2w==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/url-loader@7.17.18':\n    resolution: {integrity: sha512-ear0CiyTj04jCVAxi7TvgbnGDIN2HgqzXzwsfcqiVg9cvjT40NcMlZ2P1lZDgqMkZ9oyLTV8Bw6j+SyG6A+xPw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/url-loader@8.0.2':\n    resolution: {integrity: sha512-1dKp2K8UuFn7DFo1qX5c1cyazQv2h2ICwA9esHblEqCYrgf69Nk8N7SODmsfWg94OEaI74IqMoM12t7eIGwFzQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/utils@10.2.3':\n    resolution: {integrity: sha512-j7x0sO0VtWVhD3FubyY42abx+g61/at5W5Y3DSOckPkBo7yVjkcnAsXoB4jiUnznhGme/o+uX5VgA8HrjyR5ZQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/utils@10.5.4':\n    resolution: {integrity: sha512-XHnyCWSlg1ccsD8s0y6ugo5GZ5TpkTiFVNPSYms5G0s6Z/xTuSmiLBfeqgkfaCwLmLaQnRCmNDL2JRnqc2R5bQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/utils@8.13.1':\n    resolution: {integrity: sha512-qIh9yYpdUFmctVqovwMdheVNJqFh+DQNWIhX87FJStfXYnmweBUDATok9fWPleKeFwxnW8IapKmY8m8toJEkAw==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/utils@9.2.1':\n    resolution: {integrity: sha512-WUw506Ql6xzmOORlriNrD6Ugx+HjVgYxt9KCXD9mHAak+eaXSwuGGPyE60hy9xaDEoXKBsG7SkG69ybitaVl6A==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/wrap@10.0.5':\n    resolution: {integrity: sha512-Cbr5aYjr3HkwdPvetZp1cpDWTGdD1Owgsb3z/ClzhmrboiK86EnQDxDvOJiQkDCPWE9lNBwj8Y4HfxroY0D9DQ==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-tools/wrap@9.4.2':\n    resolution: {integrity: sha512-DFcd9r51lmcEKn0JW43CWkkI2D6T9XI1juW/Yo86i04v43O9w2/k4/nx2XTJv4Yv+iXwUw7Ok81PGltwGJSDSA==}\n    peerDependencies:\n      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@graphql-typed-document-node/core@3.2.0':\n    resolution: {integrity: sha512-mB9oAsNCm9aM3/SOv4YtBMqZbYj10R7dkq8byBqxGY/ncFwhf2oQzMV+LCRlWoDSEBJ3COiR1yeDvMtsoOsuFQ==}\n    peerDependencies:\n      graphql: ^0.8.0 || ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0 || ^17.0.0\n\n  '@hoppscotch/httpsnippet@3.0.6':\n    resolution: {integrity: sha512-W42cXJWrPvydwImgHZAV6s60fKouQ9TeTX/vzXqjBuszccrPywOJaPUlBjMe26Xe+5xEQccjlGaVaxSVJu9nXw==}\n    engines: {node: '^14.19.1 || ^16.14.2 || ^18.0.0 '}\n    hasBin: true\n\n  '@hoppscotch/ui@0.2.1':\n    resolution: {integrity: sha512-orwItZFlOZUFfMf0B7RNAQa2ByucnXcl9ufP0aJggyFafRk/X9eyMPC6JrF/OATml/ZztksjiB2636cMYsEnSw==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@hoppscotch/ui@0.2.2':\n    resolution: {integrity: sha512-rDRfG9onpmlDCO2KjJZN6UIlFC5Ewif689guvtVCZh9a+soy9nUUTbwMHI9913oBIJpbZ4GTLHGpdCl1YHUiVQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@hoppscotch/vue-sonner@1.2.3':\n    resolution: {integrity: sha512-P1gyvHHLsPeB8lsLP5SrqwQatuwOKtbsP83sKhyIV3WL2rJj3+DiFfqo2ErNBa+Sl0gM68o1V+wuOS7zbR//6g==}\n\n  '@hoppscotch/vue-toasted@0.1.0':\n    resolution: {integrity: sha512-DIgmeTHxWwX5UeaHLEqDYNLJFGRosx/5N1fCHkaO8zt+sZv8GrHlkrIpjfKF2drmA3kKw5cY42Cw7WuCoabR3g==}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@humanfs/core@0.19.0':\n    resolution: {integrity: sha512-2cbWIHbZVEweE853g8jymffCA+NCMiuqeECeBBLm8dg2oFdjuGJhgN4UAbI+6v0CKbbhvtXA4qV8YR5Ji86nmw==}\n    engines: {node: '>=18.18.0'}\n\n  '@humanfs/node@0.16.5':\n    resolution: {integrity: sha512-KSPA4umqSG4LHYRodq31VDwKAvaTF4xmVlzM8Aeh4PlU1JQ3IG0wiA8C25d3RQ9nJyM3mBHyI53K06VVL/oFFg==}\n    engines: {node: '>=18.18.0'}\n\n  '@humanwhocodes/config-array@0.11.14':\n    resolution: {integrity: sha512-3T8LkOmg45BV5FICb15QQMsyUSWrQ8AygVfC7ZG32zOalnqrilm018ZVCw0eapXux8FtA33q8PSRSstjee3jSg==}\n    engines: {node: '>=10.10.0'}\n    deprecated: Use @eslint/config-array instead\n\n  '@humanwhocodes/module-importer@1.0.1':\n    resolution: {integrity: sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==}\n    engines: {node: '>=12.22'}\n\n  '@humanwhocodes/object-schema@2.0.3':\n    resolution: {integrity: sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==}\n    deprecated: Use @eslint/object-schema instead\n\n  '@humanwhocodes/retry@0.3.1':\n    resolution: {integrity: sha512-JBxkERygn7Bv/GbN5Rv8Ul6LVknS+5Bp6RgDC/O8gEBU/yeH5Ui5C/OlWrTb6qct7LjjfT6Re2NxB0ln0yYybA==}\n    engines: {node: '>=18.18'}\n\n  '@iconify-json/lucide@1.1.144':\n    resolution: {integrity: sha512-MdpwW2zrSmxgUUyZs5zX7GqlqoTMvK1fpIFQKkXOwsxWfijAjyEWP2oWFFdVIKUoDyMSbJzXXIwon68D/Q4PcQ==}\n\n  '@iconify-json/lucide@1.2.10':\n    resolution: {integrity: sha512-cR1xpRJ4dnoXlC0ShDjzbrZyu+ICH4OUaYl7S51MhZUO1H040s7asVqv0LsDbofSLDuzWkHCLsBabTTRL0mCUg==}\n\n  '@iconify-json/lucide@1.2.8':\n    resolution: {integrity: sha512-knmDUXky8AAQ0rnGdnBjS1mBr6c0tT7aVbBd7AJcDTcJYvx9XEeyHlabFKG03DaLbOkCy0QHwCYoeZHRDEzOFA==}\n\n  '@iconify-json/lucide@1.2.9':\n    resolution: {integrity: sha512-4gTg74GLiIPJtt4HrAoQuxRLana085kXBf2BhGDzSpPPg8xkgRemRKhhiZE0qasKyBt/nif67Rvuz/NUFWtvDg==}\n\n  '@iconify/types@1.1.0':\n    resolution: {integrity: sha512-Jh0llaK2LRXQoYsorIH8maClebsnzTcve+7U3rQUSnC11X4jtPnFuyatqFLvMxZ8MLG8dB4zfHsbPfuvxluONw==}\n\n  '@iconify/types@2.0.0':\n    resolution: {integrity: sha512-+wluvCrRhXrhyOmRDJ3q8mux9JkKy5SJ/v8ol2tu4FVjyYvtEzkc/3pK15ET6RKg4b4w4BmTk1+gsCUhf21Ykg==}\n\n  '@iconify/utils@1.0.33':\n    resolution: {integrity: sha512-vGeAqo7aGPxOQmGdVoXFUOuyN+0V7Lcrx2EvaiRjxUD1x6Om0Tvq2bdm7E24l2Pz++4S0mWMCVFXe/17EtKImQ==}\n\n  '@iconify/utils@2.1.33':\n    resolution: {integrity: sha512-jP9h6v/g0BIZx0p7XGJJVtkVnydtbgTgt9mVNcGDYwaa7UhdHdI9dvoq+gKj9sijMSJKxUPEG2JyjsgXjxL7Kw==}\n\n  '@import-meta-env/cli@0.7.0':\n    resolution: {integrity: sha512-2ARV8ZSqdB3Oh9MYyh2JlGVV16IjqlXfmyRbp2Fng8geONWh5SGPZwXLFjsqj4z1LN5KYfdDgL6dSz9PV+CxWQ==}\n    engines: {node: '>= 14'}\n    hasBin: true\n    peerDependencies:\n      '@import-meta-env/babel': ^0.5.0\n      '@import-meta-env/swc': ^0.4.5\n      '@import-meta-env/unplugin': ^0.6.0\n    peerDependenciesMeta:\n      '@import-meta-env/babel':\n        optional: true\n      '@import-meta-env/swc':\n        optional: true\n      '@import-meta-env/unplugin':\n        optional: true\n\n  '@import-meta-env/unplugin@0.6.0':\n    resolution: {integrity: sha512-oKttBqTQpAK0D6iWSR952L58+86GW7EMhfHD1ueF7xwJxfbIikvNa+oNIvdinr46m9g0aaHA0XywpZTGCCwm+g==}\n    engines: {node: '>= 14'}\n    peerDependencies:\n      '@import-meta-env/cli': ^0.7.0\n    peerDependenciesMeta:\n      '@import-meta-env/cli':\n        optional: true\n\n  '@intlify/bundle-utils@3.4.0':\n    resolution: {integrity: sha512-2UQkqiSAOSPEHMGWlybqWm4G2K0X+FyYho5AwXz6QklSX1EY5EDmOSxZmwscn2qmKBnp6OYsme5kUrnN9xrWzQ==}\n    engines: {node: '>= 12'}\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/bundle-utils@7.0.0':\n    resolution: {integrity: sha512-+/RBsYWbiZcs97RyVb4mrsSrLmIMaI6evj30jI9f1psjXx+syRbf0ab63I5SIz290EOm6TE80fTst/Xjel+D9w==}\n    engines: {node: '>= 14.16'}\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/bundle-utils@9.0.0-beta.0':\n    resolution: {integrity: sha512-xVaMrgbr60fYE1Jkq+k6grs2ZoXqh1EU71RVKkHkKh3KP7T6OYtG1Vbp1T09/jCUbv1GBd8Ir5WdZDyN+e8BpQ==}\n    engines: {node: '>= 18'}\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/core-base@10.0.4':\n    resolution: {integrity: sha512-GG428DkrrWCMhxRMRQZjuS7zmSUzarYcaHJqG9VB8dXAxw4iQDoKVQ7ChJRB6ZtsCsX3Jse1PEUlHrJiyQrOTg==}\n    engines: {node: '>= 16'}\n\n  '@intlify/message-compiler@10.0.4':\n    resolution: {integrity: sha512-AFbhEo10DP095/45EauinQJ5hJ3rJUmuuqltGguvc3WsvezZN+g8qNHLGWKu60FHQVizMrQY7VJ+zVlBXlQQkQ==}\n    engines: {node: '>= 16'}\n\n  '@intlify/message-compiler@11.0.0-rc.1':\n    resolution: {integrity: sha512-TGw2uBfuTFTegZf/BHtUQBEKxl7Q/dVGLoqRIdw8lFsp9g/53sYn5iD+0HxIzdYjbWL6BTJMXCPUHp9PxDTRPw==}\n    engines: {node: '>= 16'}\n\n  '@intlify/message-compiler@9.3.0-beta.20':\n    resolution: {integrity: sha512-hwqQXyTnDzAVZ300SU31jO0+3OJbpOdfVU6iBkrmNpS7t2HRnVACo0EwcEXzJa++4EVDreqz5OeqJbt+PeSGGA==}\n    engines: {node: '>= 16'}\n\n  '@intlify/shared@10.0.4':\n    resolution: {integrity: sha512-ukFn0I01HsSgr3VYhYcvkTCLS7rGa0gw4A4AMpcy/A9xx/zRJy7PS2BElMXLwUazVFMAr5zuiTk3MQeoeGXaJg==}\n    engines: {node: '>= 16'}\n\n  '@intlify/shared@11.0.0-rc.1':\n    resolution: {integrity: sha512-8tR1xe7ZEbkabTuE/tNhzpolygUn9OaYp9yuYAF4MgDNZg06C3Qny80bes2/e9/Wm3aVkPUlCw6WgU7mQd0yEg==}\n    engines: {node: '>= 16'}\n\n  '@intlify/shared@9.3.0-beta.20':\n    resolution: {integrity: sha512-RucSPqh8O9FFxlYUysQTerSw0b9HIRpyoN1Zjogpm0qLiHK+lBNSa5sh1nCJ4wSsNcjphzgpLQCyR60GZlRV8g==}\n    engines: {node: '>= 16'}\n\n  '@intlify/unplugin-vue-i18n@5.2.0':\n    resolution: {integrity: sha512-pmRiPY2Nj9mmSrixT69aO45XxGUr5fDBy/IIw4ajLlDTJm5TSmQKA5YNdsH0uxVDCPWy5tlQrF18hkDwI7UJvg==}\n    engines: {node: '>= 18'}\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vue: 3.5.12\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/vite-plugin-vue-i18n@6.0.1':\n    resolution: {integrity: sha512-FFVcxVU4bR9vdDLNbltM5mrhndnXMErO01i0RrpdyMegEt3Nu/YLoH0sFdjRun7/RY4vaEnhTnFvVf9uO0dQvg==}\n    engines: {node: '>= 14.6'}\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vite: ^2.9.0 || ^3.0.0\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vite:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/vite-plugin-vue-i18n@7.0.0':\n    resolution: {integrity: sha512-2TbDOQ8XD+vkc0s5OFmr+IY/k4mYMC7pzvx0xGQn+cU/ev314+yi7Z7N7rWcBgiYk1WOUalbGSo3d4nJDxOOyw==}\n    engines: {node: '>= 14.6'}\n    deprecated: This plugin support until Vite 3. If you would like to use on Vite 4, please use @intlify/unplugin-vue-i18n\n    peerDependencies:\n      petite-vue-i18n: '*'\n      vite: ^2.9.0 || ^3.0.0\n      vue-i18n: '*'\n    peerDependenciesMeta:\n      petite-vue-i18n:\n        optional: true\n      vite:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@intlify/vue-i18n-extensions@7.0.0':\n    resolution: {integrity: sha512-MtvfJnb4aklpCU5Q/dkWkBT/vGsp3qERiPIwtTq5lX4PCLHtUprAJZp8wQj5ZcwDaFCU7+yVMjYbeXpIf927cA==}\n    engines: {node: '>= 18'}\n    peerDependencies:\n      '@intlify/shared': ^9.0.0 || ^10.0.0\n      '@vue/compiler-dom': ^3.0.0\n      vue: 3.5.12\n      vue-i18n: ^9.0.0 || ^10.0.0\n    peerDependenciesMeta:\n      '@intlify/shared':\n        optional: true\n      '@vue/compiler-dom':\n        optional: true\n      vue:\n        optional: true\n      vue-i18n:\n        optional: true\n\n  '@ioredis/commands@1.2.0':\n    resolution: {integrity: sha512-Sx1pU8EM64o2BrqNpEO1CNLtKQwyhuXuqyfH7oGKCk+1a33d2r5saW8zNwm3j6BTExtjrv2BxTgzzkMwts6vGg==}\n\n  '@isaacs/cliui@8.0.2':\n    resolution: {integrity: sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==}\n    engines: {node: '>=12'}\n\n  '@istanbuljs/load-nyc-config@1.1.0':\n    resolution: {integrity: sha512-VjeHSlIzpv/NyD3N0YuHfXOPDIixcA1q2ZV98wsMqcYlPmv2n3Yb2lYP9XMElnaFVXg5A7YLTeLu6V84uQDjmQ==}\n    engines: {node: '>=8'}\n\n  '@istanbuljs/schema@0.1.3':\n    resolution: {integrity: sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==}\n    engines: {node: '>=8'}\n\n  '@jest/console@29.7.0':\n    resolution: {integrity: sha512-5Ni4CU7XHQi32IJ398EEP4RrB8eV09sXP2ROqD4bksHrnTree52PsxvX8tpL8LvTZ3pFzXyPbNQReSN41CAhOg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/core@29.7.0':\n    resolution: {integrity: sha512-n7aeXWKMnGtDA48y8TLWJPJmLmmZ642Ceo78cYWEpiD7FzDgmNDV/GCVRorPABdXLJZ/9wzzgZAlHjXjxDHGsg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    peerDependencies:\n      node-notifier: ^8.0.1 || ^9.0.0 || ^10.0.0\n    peerDependenciesMeta:\n      node-notifier:\n        optional: true\n\n  '@jest/environment@29.7.0':\n    resolution: {integrity: sha512-aQIfHDq33ExsN4jP1NWGXhxgQ/wixs60gDiKO+XVMd8Mn0NWPWgc34ZQDTb2jKaUWQ7MuwoitXAsN2XVXNMpAw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/expect-utils@29.7.0':\n    resolution: {integrity: sha512-GlsNBWiFQFCVi9QVSx7f5AgMeLxe9YCCs5PuP2O2LdjDAA8Jh9eX7lA1Jq/xdXw3Wb3hyvlFNfZIfcRetSzYcA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/expect@29.7.0':\n    resolution: {integrity: sha512-8uMeAMycttpva3P1lBHB8VciS9V0XAr3GymPpipdyQXbBcuhkLQOSe8E/p92RyAdToS6ZD1tFkX+CkhoECE0dQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/fake-timers@29.7.0':\n    resolution: {integrity: sha512-q4DH1Ha4TTFPdxLsqDXK1d3+ioSL7yL5oCMJZgDYm6i+6CygW5E5xVr/D1HdsGxjt1ZWSfUAs9OxSB/BNelWrQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/globals@29.7.0':\n    resolution: {integrity: sha512-mpiz3dutLbkW2MNFubUGUEVLkTGiqW6yLVTA+JbP6fI6J5iL9Y0Nlg8k95pcF8ctKwCS7WVxteBs29hhfAotzQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/reporters@29.7.0':\n    resolution: {integrity: sha512-DApq0KJbJOEzAFYjHADNNxAE3KbhxQB1y5Kplb5Waqw6zVbuWatSnMjE5gs8FUgEPmNsnZA3NCWl9NG0ia04Pg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    peerDependencies:\n      node-notifier: ^8.0.1 || ^9.0.0 || ^10.0.0\n    peerDependenciesMeta:\n      node-notifier:\n        optional: true\n\n  '@jest/schemas@29.6.3':\n    resolution: {integrity: sha512-mo5j5X+jIZmJQveBKeS/clAueipV7KgiX1vMgCxam1RNYiqE1w62n0/tJJnHtjW8ZHcQco5gY85jA3mi0L+nSA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/source-map@29.6.3':\n    resolution: {integrity: sha512-MHjT95QuipcPrpLM+8JMSzFx6eHp5Bm+4XeFDJlwsvVBjmKNiIAvasGK2fxz2WbGRlnvqehFbh07MMa7n3YJnw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/test-result@29.7.0':\n    resolution: {integrity: sha512-Fdx+tv6x1zlkJPcWXmMDAG2HBnaR9XPSd5aDWQVsfrZmLVT3lU1cwyxLgRmXR9yrq4NBoEm9BMsfgFzTQAbJYA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/test-sequencer@29.7.0':\n    resolution: {integrity: sha512-GQwJ5WZVrKnOJuiYiAF52UNUJXgTZx1NHjFSEB0qEMmSZKAkdMoIzw/Cj6x6NF4AvV23AUqDpFzQkN/eYCYTxw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/transform@29.7.0':\n    resolution: {integrity: sha512-ok/BTPFzFKVMwO5eOHRrvnBVHdRy9IrsrW1GpMaQ9MCnilNLXQKmAX8s1YXDFaai9xJpac2ySzV0YeRRECr2Vw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jest/types@29.6.3':\n    resolution: {integrity: sha512-u3UPsIilWKOM3F9CXtrG8LEJmNxwoCQC/XVj4IKYXvvpx7QIi/Kg1LI5uDmDpKlac62NUtX7eLjRh+jVZcLOzw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  '@jridgewell/gen-mapping@0.3.5':\n    resolution: {integrity: sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==}\n    engines: {node: '>=6.0.0'}\n\n  '@jridgewell/resolve-uri@3.1.2':\n    resolution: {integrity: sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==}\n    engines: {node: '>=6.0.0'}\n\n  '@jridgewell/set-array@1.2.1':\n    resolution: {integrity: sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==}\n    engines: {node: '>=6.0.0'}\n\n  '@jridgewell/source-map@0.3.6':\n    resolution: {integrity: sha512-1ZJTZebgqllO79ue2bm3rIGud/bOe0pP5BjSRCRxxYkEZS8STV7zN84UBbiYu7jy+eCKSnVIUgoWWE/tt+shMQ==}\n\n  '@jridgewell/sourcemap-codec@1.4.15':\n    resolution: {integrity: sha512-eF2rxCRulEKXHTRiDrDy6erMYWqNw4LPdQ8UQA4huuxaQsVeRPFl2oM8oDGxMFhJUWZf9McpLtJasDDZb/Bpeg==}\n\n  '@jridgewell/sourcemap-codec@1.5.0':\n    resolution: {integrity: sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==}\n\n  '@jridgewell/trace-mapping@0.3.25':\n    resolution: {integrity: sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==}\n\n  '@jridgewell/trace-mapping@0.3.9':\n    resolution: {integrity: sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==}\n\n  '@jsdevtools/ono@7.1.3':\n    resolution: {integrity: sha512-4JQNk+3mVzK3xh2rqd6RB4J46qUR19azEHBneZyTZM+c456qOrbbM/5xcR8huNCCcbVt7+UmizG6GuUvPvKUYg==}\n\n  '@jsep-plugin/assignment@1.2.1':\n    resolution: {integrity: sha512-gaHqbubTi29aZpVbBlECRpmdia+L5/lh2BwtIJTmtxdbecEyyX/ejAOg7eQDGNvGOUmPY7Z2Yxdy9ioyH/VJeA==}\n    engines: {node: '>= 10.16.0'}\n    peerDependencies:\n      jsep: ^0.4.0||^1.0.0\n\n  '@jsep-plugin/regex@1.0.3':\n    resolution: {integrity: sha512-XfZgry4DwEZvSFtS/6Y+R48D7qJYJK6R9/yJFyUFHCIUMEEHuJ4X95TDgJp5QkmzfLYvapMPzskV5HpIDrREug==}\n    engines: {node: '>= 10.16.0'}\n    peerDependencies:\n      jsep: ^0.4.0||^1.0.0\n\n  '@kamilkisiela/fast-url-parser@1.1.4':\n    resolution: {integrity: sha512-gbkePEBupNydxCelHCESvFSFM8XPh1Zs/OAVRW/rKpEqPAl5PbOM90Si8mv9bvnR53uPD2s/FiRxdvSejpRJew==}\n\n  '@lezer/common@1.2.1':\n    resolution: {integrity: sha512-yemX0ZD2xS/73llMZIK6KplkjIjf2EvAHcinDi/TfJ9hS25G0388+ClHt6/3but0oOxinTcQHJLDXh6w1crzFQ==}\n\n  '@lezer/generator@1.5.1':\n    resolution: {integrity: sha512-vodJv2JPwsFsiBBHE463yBhvUI9TmhIu5duF/8MH304xNS6FyWH/vTyG61pjhERm5f+VBP94co0eiN+afWcvXw==}\n    hasBin: true\n\n  '@lezer/highlight@1.2.0':\n    resolution: {integrity: sha512-WrS5Mw51sGrpqjlh3d4/fOwpEV2Hd3YOkp9DBt4k8XZQcoTHZFB7sx030A6OcahF4J1nDQAa3jXlTVVYH50IFA==}\n\n  '@lezer/javascript@1.4.16':\n    resolution: {integrity: sha512-84UXR3N7s11MPQHWgMnjb9571fr19MmXnr5zTv2XX0gHXXUvW3uPJ8GCjKrfTXmSdfktjRK0ayKklw+A13rk4g==}\n\n  '@lezer/json@1.0.2':\n    resolution: {integrity: sha512-xHT2P4S5eeCYECyKNPhr4cbEL9tc8w83SPwRC373o9uEdrvGKTZoJVAGxpOsZckMlEh9W23Pc72ew918RWQOBQ==}\n\n  '@lezer/lr@1.3.14':\n    resolution: {integrity: sha512-z5mY4LStlA3yL7aHT/rqgG614cfcvklS+8oFRFBYrs4YaWLJyKKM4+nN6KopToX0o9Hj6zmH6M5kinOYuy06ug==}\n\n  '@lezer/xml@1.0.5':\n    resolution: {integrity: sha512-VFouqOzmUWfIg+tfmpcdV33ewtK+NSwd4ngSe1aG7HFb4BN0ExyY1b8msp+ndFrnlG4V4iC8yXacjFtrwERnaw==}\n\n  '@ljharb/through@2.3.13':\n    resolution: {integrity: sha512-/gKJun8NNiWGZJkGzI/Ragc53cOdcLNdzjLaIa+GEjguQs0ulsurx8WN0jijdK9yPqDvziX995sMRLyLt1uZMQ==}\n    engines: {node: '>= 0.4'}\n\n  '@lukeed/csprng@1.1.0':\n    resolution: {integrity: sha512-Z7C/xXCiGWsg0KuKsHTKJxbWhpI3Vs5GwLfOean7MGyVFGqdRgBbAjOCh6u4bbjPc/8MJ2pZmK/0DLdCbivLDA==}\n    engines: {node: '>=8'}\n\n  '@mapbox/node-pre-gyp@1.0.11':\n    resolution: {integrity: sha512-Yhlar6v9WQgUp/He7BdgzOz8lqMQ8sU+jkCq7Wx8Myc5YFJLbEe7lgui/V7G1qB1DJykHSGwreceSaD60Y0PUQ==}\n    hasBin: true\n\n  '@microsoft/tsdoc@0.15.0':\n    resolution: {integrity: sha512-HZpPoABogPvjeJOdzCOSJsXeL/SMCBgBZMVC3X3d7YYp2gf31MfxhUoYUNwf1ERPJOnQc0wkFn9trqI6ZEdZuA==}\n\n  '@nestjs-modules/mailer@2.0.2':\n    resolution: {integrity: sha512-+z4mADQasg0H1ZaGu4zZTuKv2pu+XdErqx99PLFPzCDNTN/q9U59WPgkxVaHnsvKHNopLj5Xap7G4ZpptduoYw==}\n    peerDependencies:\n      '@nestjs/common': '>=7.0.9'\n      '@nestjs/core': '>=7.0.9'\n      nodemailer: '>=6.4.6'\n\n  '@nestjs/apollo@12.2.0':\n    resolution: {integrity: sha512-z1zpbgrxaEaIdP6luiDdQ6f4OH3/xhszakxekXFvLq77wqO3nezKvZvz/etTaSlVW5y06jaCYKhypfXVv4sgzQ==}\n    peerDependencies:\n      '@apollo/gateway': ^2.0.0\n      '@apollo/server': ^4.3.2\n      '@apollo/subgraph': ^2.0.0\n      '@as-integrations/fastify': ^1.3.0 || ^2.0.0\n      '@nestjs/common': ^9.3.8 || ^10.0.0\n      '@nestjs/core': ^9.3.8 || ^10.0.0\n      '@nestjs/graphql': ^12.0.0\n      graphql: ^16.6.0\n    peerDependenciesMeta:\n      '@apollo/gateway':\n        optional: true\n      '@apollo/subgraph':\n        optional: true\n      '@as-integrations/fastify':\n        optional: true\n\n  '@nestjs/cli@10.4.5':\n    resolution: {integrity: sha512-FP7Rh13u8aJbHe+zZ7hM0CC4785g9Pw4lz4r2TTgRtf0zTxSWMkJaPEwyjX8SK9oWK2GsYxl+fKpwVZNbmnj9A==}\n    engines: {node: '>= 16.14'}\n    hasBin: true\n    peerDependencies:\n      '@swc/cli': ^0.1.62 || ^0.3.0 || ^0.4.0\n      '@swc/core': ^1.3.62\n    peerDependenciesMeta:\n      '@swc/cli':\n        optional: true\n      '@swc/core':\n        optional: true\n\n  '@nestjs/common@10.4.4':\n    resolution: {integrity: sha512-0j2/zqRw9nvHV1GKTktER8B/hIC/Z8CYFjN/ZqUuvwayCH+jZZBhCR2oRyuvLTXdnlSmtCAg2xvQ0ULqQvzqhA==}\n    peerDependencies:\n      class-transformer: '*'\n      class-validator: '*'\n      reflect-metadata: ^0.1.12 || ^0.2.0\n      rxjs: ^7.1.0\n    peerDependenciesMeta:\n      class-transformer:\n        optional: true\n      class-validator:\n        optional: true\n\n  '@nestjs/config@3.2.3':\n    resolution: {integrity: sha512-p6yv/CvoBewJ72mBq4NXgOAi2rSQNWx3a+IMJLVKS2uiwFCOQQuiIatGwq6MRjXV3Jr+B41iUO8FIf4xBrZ4/w==}\n    peerDependencies:\n      '@nestjs/common': ^8.0.0 || ^9.0.0 || ^10.0.0\n      rxjs: ^7.1.0\n\n  '@nestjs/core@10.4.4':\n    resolution: {integrity: sha512-y9tjmAzU6LTh1cC/lWrRsCcOd80khSR0qAHAqwY2svbW+AhsR/XCzgpZrAAKJrm/dDfjLCZKyxJSayeirGcW5Q==}\n    peerDependencies:\n      '@nestjs/common': ^10.0.0\n      '@nestjs/microservices': ^10.0.0\n      '@nestjs/platform-express': ^10.0.0\n      '@nestjs/websockets': ^10.0.0\n      reflect-metadata: ^0.1.12 || ^0.2.0\n      rxjs: ^7.1.0\n    peerDependenciesMeta:\n      '@nestjs/microservices':\n        optional: true\n      '@nestjs/platform-express':\n        optional: true\n      '@nestjs/websockets':\n        optional: true\n\n  '@nestjs/graphql@12.2.0':\n    resolution: {integrity: sha512-du/aI+EXADxtJrHF1mAXR6RYRHuEWPNnJyHTmIOPW2Wx5qN32P7lQoHGD7TySATMl5aa47w05lPzxcasdUmpMQ==}\n    peerDependencies:\n      '@apollo/subgraph': ^2.0.0\n      '@nestjs/common': ^9.3.8 || ^10.0.0\n      '@nestjs/core': ^9.3.8 || ^10.0.0\n      class-transformer: '*'\n      class-validator: '*'\n      graphql: ^16.6.0\n      reflect-metadata: ^0.1.13 || ^0.2.0\n      ts-morph: ^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^20.0.0 || ^21.0.0\n    peerDependenciesMeta:\n      '@apollo/subgraph':\n        optional: true\n      class-transformer:\n        optional: true\n      class-validator:\n        optional: true\n      ts-morph:\n        optional: true\n\n  '@nestjs/jwt@10.2.0':\n    resolution: {integrity: sha512-x8cG90SURkEiLOehNaN2aRlotxT0KZESUliOPKKnjWiyJOcWurkF3w345WOX0P4MgFzUjGoZ1Sy0aZnxeihT0g==}\n    peerDependencies:\n      '@nestjs/common': ^8.0.0 || ^9.0.0 || ^10.0.0\n\n  '@nestjs/mapped-types@2.0.5':\n    resolution: {integrity: sha512-bSJv4pd6EY99NX9CjBIyn4TVDoSit82DUZlL4I3bqNfy5Gt+gXTa86i3I/i0iIV9P4hntcGM5GyO+FhZAhxtyg==}\n    peerDependencies:\n      '@nestjs/common': ^8.0.0 || ^9.0.0 || ^10.0.0\n      class-transformer: ^0.4.0 || ^0.5.0\n      class-validator: ^0.13.0 || ^0.14.0\n      reflect-metadata: ^0.1.12 || ^0.2.0\n    peerDependenciesMeta:\n      class-transformer:\n        optional: true\n      class-validator:\n        optional: true\n\n  '@nestjs/passport@10.0.3':\n    resolution: {integrity: sha512-znJ9Y4S8ZDVY+j4doWAJ8EuuVO7SkQN3yOBmzxbGaXbvcSwFDAdGJ+OMCg52NdzIO4tQoN4pYKx8W6M0ArfFRQ==}\n    peerDependencies:\n      '@nestjs/common': ^8.0.0 || ^9.0.0 || ^10.0.0\n      passport: ^0.4.0 || ^0.5.0 || ^0.6.0 || ^0.7.0\n\n  '@nestjs/platform-express@10.4.4':\n    resolution: {integrity: sha512-y52q1MxhbHaT3vAgWd08RgiYon0lJgtTa8U6g6gV0KI0IygwZhDQFJVxnrRDUdxQGIP5CKHmfQu3sk9gTNFoEA==}\n    peerDependencies:\n      '@nestjs/common': ^10.0.0\n      '@nestjs/core': ^10.0.0\n\n  '@nestjs/schedule@4.1.1':\n    resolution: {integrity: sha512-VxAnCiU4HP0wWw8IdWAVfsGC/FGjyToNjjUtXDEQL6oj+w/N5QDd2VT9k6d7Jbr8PlZuBZNdWtDKSkH5bZ+RXQ==}\n    peerDependencies:\n      '@nestjs/common': ^8.0.0 || ^9.0.0 || ^10.0.0\n      '@nestjs/core': ^8.0.0 || ^9.0.0 || ^10.0.0\n\n  '@nestjs/schematics@10.1.4':\n    resolution: {integrity: sha512-QpY8ez9cTvXXPr3/KBrtSgXQHMSV6BkOUYy2c2TTe6cBqriEdGnCYqGl8cnfrQl3632q3lveQPaZ/c127dHsEw==}\n    peerDependencies:\n      typescript: '>=4.8.2'\n\n  '@nestjs/swagger@7.4.2':\n    resolution: {integrity: sha512-Mu6TEn1M/owIvAx2B4DUQObQXqo2028R2s9rSZ/hJEgBK95+doTwS0DjmVA2wTeZTyVtXOoN7CsoM5pONBzvKQ==}\n    peerDependencies:\n      '@fastify/static': ^6.0.0 || ^7.0.0\n      '@nestjs/common': ^9.0.0 || ^10.0.0\n      '@nestjs/core': ^9.0.0 || ^10.0.0\n      class-transformer: '*'\n      class-validator: '*'\n      reflect-metadata: ^0.1.12 || ^0.2.0\n    peerDependenciesMeta:\n      '@fastify/static':\n        optional: true\n      class-transformer:\n        optional: true\n      class-validator:\n        optional: true\n\n  '@nestjs/terminus@10.2.3':\n    resolution: {integrity: sha512-iX7gXtAooePcyQqFt57aDke5MzgdkBeYgF5YsFNNFwOiAFdIQEhfv3PR0G+HlH9F6D7nBCDZt9U87Pks/qHijg==}\n    peerDependencies:\n      '@grpc/grpc-js': '*'\n      '@grpc/proto-loader': '*'\n      '@mikro-orm/core': '*'\n      '@mikro-orm/nestjs': '*'\n      '@nestjs/axios': ^1.0.0 || ^2.0.0 || ^3.0.0\n      '@nestjs/common': ^9.0.0 || ^10.0.0\n      '@nestjs/core': ^9.0.0 || ^10.0.0\n      '@nestjs/microservices': ^9.0.0 || ^10.0.0\n      '@nestjs/mongoose': ^9.0.0 || ^10.0.0\n      '@nestjs/sequelize': ^9.0.0 || ^10.0.0\n      '@nestjs/typeorm': ^9.0.0 || ^10.0.0\n      '@prisma/client': '*'\n      mongoose: '*'\n      reflect-metadata: 0.1.x || 0.2.x\n      rxjs: 7.x\n      sequelize: '*'\n      typeorm: '*'\n    peerDependenciesMeta:\n      '@grpc/grpc-js':\n        optional: true\n      '@grpc/proto-loader':\n        optional: true\n      '@mikro-orm/core':\n        optional: true\n      '@mikro-orm/nestjs':\n        optional: true\n      '@nestjs/axios':\n        optional: true\n      '@nestjs/microservices':\n        optional: true\n      '@nestjs/mongoose':\n        optional: true\n      '@nestjs/sequelize':\n        optional: true\n      '@nestjs/typeorm':\n        optional: true\n      '@prisma/client':\n        optional: true\n      mongoose:\n        optional: true\n      sequelize:\n        optional: true\n      typeorm:\n        optional: true\n\n  '@nestjs/testing@10.4.4':\n    resolution: {integrity: sha512-qRGFj51A5RM7JqA8pcyEwSLA3Y0dle/PAZ8oxP0suimoCusRY3Tk7wYqutZdCNj1ATb678SDaUZDHk2pwSv9/g==}\n    peerDependencies:\n      '@nestjs/common': ^10.0.0\n      '@nestjs/core': ^10.0.0\n      '@nestjs/microservices': ^10.0.0\n      '@nestjs/platform-express': ^10.0.0\n    peerDependenciesMeta:\n      '@nestjs/microservices':\n        optional: true\n      '@nestjs/platform-express':\n        optional: true\n\n  '@nestjs/throttler@6.2.1':\n    resolution: {integrity: sha512-vdt6VjhKC6vcLBJRUb97IuR6Htykn5kokZzmT8+S5XFOLLjUF7rzRpr+nUOhK9pi1L0hhbzSf2v2FJl4v64EJA==}\n    peerDependencies:\n      '@nestjs/common': ^7.0.0 || ^8.0.0 || ^9.0.0 || ^10.0.0\n      '@nestjs/core': ^7.0.0 || ^8.0.0 || ^9.0.0 || ^10.0.0\n      reflect-metadata: ^0.1.13 || ^0.2.0\n\n  '@noble/curves@1.6.0':\n    resolution: {integrity: sha512-TlaHRXDehJuRNR9TfZDNQ45mMEd5dwUwmicsafcIX4SsNiqnCHKjE/1alYPd/lDRVhxdhUAlv8uEhMCI5zjIJQ==}\n    engines: {node: ^14.21.3 || >=16}\n\n  '@noble/hashes@1.5.0':\n    resolution: {integrity: sha512-1j6kQFb7QRru7eKN3ZDvRcP13rugwdxZqCjbiAVZfIJwgj2A65UmT4TgARXGlXgnRkORLTDTrO19ZErt7+QXgA==}\n    engines: {node: ^14.21.3 || >=16}\n\n  '@nodelib/fs.scandir@2.1.5':\n    resolution: {integrity: sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==}\n    engines: {node: '>= 8'}\n\n  '@nodelib/fs.stat@2.0.5':\n    resolution: {integrity: sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==}\n    engines: {node: '>= 8'}\n\n  '@nodelib/fs.walk@1.2.8':\n    resolution: {integrity: sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==}\n    engines: {node: '>= 8'}\n\n  '@nuxtjs/opencollective@0.3.2':\n    resolution: {integrity: sha512-um0xL3fO7Mf4fDxcqx9KryrB7zgRM5JSlvGN5AGkP6JLM5XEKyjeAiPbNxdXVXQ16isuAhYpvP88NgL2BGd6aA==}\n    engines: {node: '>=8.0.0', npm: '>=5.0.0'}\n    hasBin: true\n\n  '@oozcitak/dom@1.15.10':\n    resolution: {integrity: sha512-0JT29/LaxVgRcGKvHmSrUTEvZ8BXvZhGl2LASRUgHqDTC1M5g1pLmVv56IYNyt3bG2CUjDkc67wnyZC14pbQrQ==}\n    engines: {node: '>=8.0'}\n\n  '@oozcitak/infra@1.0.8':\n    resolution: {integrity: sha512-JRAUc9VR6IGHOL7OGF+yrvs0LO8SlqGnPAMqyzOuFZPSZSXI7Xf2O9+awQPSMXgIWGtgUf/dA6Hs6X6ySEaWTg==}\n    engines: {node: '>=6.0'}\n\n  '@oozcitak/url@1.0.4':\n    resolution: {integrity: sha512-kDcD8y+y3FCSOvnBI6HJgl00viO/nGbQoCINmQ0h98OhnGITrWR3bOGfwYCthgcrV8AnTJz8MzslTQbC3SOAmw==}\n    engines: {node: '>=8.0'}\n\n  '@oozcitak/util@8.3.8':\n    resolution: {integrity: sha512-T8TbSnGsxo6TDBJx/Sgv/BlVJL3tshxZP7Aq5R1mSnM5OcHY2dQaxLMu2+E8u3gN0MLOzdjurqN4ZRVuzQycOQ==}\n    engines: {node: '>=8.0'}\n\n  '@parcel/watcher-android-arm64@2.4.1':\n    resolution: {integrity: sha512-LOi/WTbbh3aTn2RYddrO8pnapixAziFl6SMxHM69r3tvdSm94JtCenaKgk1GRg5FJ5wpMCpHeW+7yqPlvZv7kg==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm64]\n    os: [android]\n\n  '@parcel/watcher-darwin-arm64@2.4.1':\n    resolution: {integrity: sha512-ln41eihm5YXIY043vBrrHfn94SIBlqOWmoROhsMVTSXGh0QahKGy77tfEywQ7v3NywyxBBkGIfrWRHm0hsKtzA==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@parcel/watcher-darwin-x64@2.4.1':\n    resolution: {integrity: sha512-yrw81BRLjjtHyDu7J61oPuSoeYWR3lDElcPGJyOvIXmor6DEo7/G2u1o7I38cwlcoBHQFULqF6nesIX3tsEXMg==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@parcel/watcher-freebsd-x64@2.4.1':\n    resolution: {integrity: sha512-TJa3Pex/gX3CWIx/Co8k+ykNdDCLx+TuZj3f3h7eOjgpdKM+Mnix37RYsYU4LHhiYJz3DK5nFCCra81p6g050w==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [x64]\n    os: [freebsd]\n\n  '@parcel/watcher-linux-arm-glibc@2.4.1':\n    resolution: {integrity: sha512-4rVYDlsMEYfa537BRXxJ5UF4ddNwnr2/1O4MHM5PjI9cvV2qymvhwZSFgXqbS8YoTk5i/JR0L0JDs69BUn45YA==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm]\n    os: [linux]\n\n  '@parcel/watcher-linux-arm64-glibc@2.4.1':\n    resolution: {integrity: sha512-BJ7mH985OADVLpbrzCLgrJ3TOpiZggE9FMblfO65PlOCdG++xJpKUJ0Aol74ZUIYfb8WsRlUdgrZxKkz3zXWYA==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@parcel/watcher-linux-arm64-musl@2.4.1':\n    resolution: {integrity: sha512-p4Xb7JGq3MLgAfYhslU2SjoV9G0kI0Xry0kuxeG/41UfpjHGOhv7UoUDAz/jb1u2elbhazy4rRBL8PegPJFBhA==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@parcel/watcher-linux-x64-glibc@2.4.1':\n    resolution: {integrity: sha512-s9O3fByZ/2pyYDPoLM6zt92yu6P4E39a03zvO0qCHOTjxmt3GHRMLuRZEWhWLASTMSrrnVNWdVI/+pUElJBBBg==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [x64]\n    os: [linux]\n\n  '@parcel/watcher-linux-x64-musl@2.4.1':\n    resolution: {integrity: sha512-L2nZTYR1myLNST0O632g0Dx9LyMNHrn6TOt76sYxWLdff3cB22/GZX2UPtJnaqQPdCRoszoY5rcOj4oMTtp5fQ==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [x64]\n    os: [linux]\n\n  '@parcel/watcher-win32-arm64@2.4.1':\n    resolution: {integrity: sha512-Uq2BPp5GWhrq/lcuItCHoqxjULU1QYEcyjSO5jqqOK8RNFDBQnenMMx4gAl3v8GiWa59E9+uDM7yZ6LxwUIfRg==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@parcel/watcher-win32-ia32@2.4.1':\n    resolution: {integrity: sha512-maNRit5QQV2kgHFSYwftmPBxiuK5u4DXjbXx7q6eKjq5dsLXZ4FJiVvlcw35QXzk0KrUecJmuVFbj4uV9oYrcw==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@parcel/watcher-win32-x64@2.4.1':\n    resolution: {integrity: sha512-+DvS92F9ezicfswqrvIRM2njcYJbd5mb9CUgtrHCHmvn7pPPa+nMDRu1o1bYYz/l5IB2NVGNJWiH7h1E58IF2A==}\n    engines: {node: '>= 10.0.0'}\n    cpu: [x64]\n    os: [win32]\n\n  '@parcel/watcher@2.4.1':\n    resolution: {integrity: sha512-HNjmfLQEVRZmHRET336f20H/8kOozUGwk7yajvsonjNxbj2wBTK1WsQuHkD5yYh9RxFGL2EyDHryOihOwUoKDA==}\n    engines: {node: '>= 10.0.0'}\n\n  '@peculiar/asn1-schema@2.3.8':\n    resolution: {integrity: sha512-ULB1XqHKx1WBU/tTFIA+uARuRoBVZ4pNdOA878RDrRbBfBGcSzi5HBkdScC6ZbHn8z7L8gmKCgPC1LHRrP46tA==}\n\n  '@peculiar/json-schema@1.1.12':\n    resolution: {integrity: sha512-coUfuoMeIB7B8/NMekxaDzLhaYmp0HZNPEjYRm9goRou8UZIC3z21s0sL9AWoCw4EG876QyO3kYrc61WNF9B/w==}\n    engines: {node: '>=8.0.0'}\n\n  '@peculiar/webcrypto@1.4.6':\n    resolution: {integrity: sha512-YBcMfqNSwn3SujUJvAaySy5tlYbYm6tVt9SKoXu8BaTdKGROiJDgPR3TXpZdAKUfklzm3lRapJEAltiMQtBgZg==}\n    engines: {node: '>=10.12.0'}\n\n  '@phc/format@1.0.0':\n    resolution: {integrity: sha512-m7X9U6BG2+J+R1lSOdCiITLLrxm+cWlNI3HUFA92oLO77ObGNzaKdh8pMLqdZcshtkKuV84olNNXDfMc4FezBQ==}\n    engines: {node: '>=10'}\n\n  '@pkgjs/parseargs@0.11.0':\n    resolution: {integrity: sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==}\n    engines: {node: '>=14'}\n\n  '@pkgr/core@0.1.1':\n    resolution: {integrity: sha512-cq8o4cWH0ibXh9VGi5P20Tu9XF/0fFXl9EUinr9QfTM7a7p0oTA4iJRCQWppXR1Pg8dSM0UCItCkPwsk9qWWYA==}\n    engines: {node: ^12.20.0 || ^14.18.0 || >=16.0.0}\n\n  '@platform/auth@0.1.106':\n    resolution: {integrity: sha512-Z3lgZYBybBBki0bH2Xr8ceX49okscoowui+nkUWbs7YTWI0Cx8KnW6pwwsOVFJvG8FPEh624ItvAfacEovF6GQ==}\n    deprecated: pre-release module deprecation\n\n  '@platform/libs@0.3.2':\n    resolution: {integrity: sha512-Iwdzd/XizT0Gytnpird5aVkImnTSXM1tGHa+RI4XgLVC6ONVGTevGDCtrvY+ABO4B8UxCvVqOcabRFpQ7WwBzw==}\n\n  '@platform/util.is@0.0.165':\n    resolution: {integrity: sha512-zWh8OsTydmUZiwFT2Fqc5BYCzoO9pVVty6nTxC6YS75rWqQ5Ig0VR9ey97h4yV8DUdVXrP2XHH/ADAByHdsktA==}\n    deprecated: pre-release module deprecation\n\n  '@polka/url@1.0.0-next.25':\n    resolution: {integrity: sha512-j7P6Rgr3mmtdkeDGTe0E/aYyWEWVtc5yFXtHCRHs28/jptDEWfaVOc5T7cblqy1XKPPfCxJc/8DwQ5YgLOZOVQ==}\n\n  '@popperjs/core@2.11.8':\n    resolution: {integrity: sha512-P1st0aksCrn9sGZhp8GMYwBnQsbvAWsZAX44oXNNvLHGqAOcoVxmjZiohstwQ7SqKnbR47akdNi+uleWD8+g6A==}\n\n  '@prisma/client@5.20.0':\n    resolution: {integrity: sha512-CLv55ZuMuUawMsxoqxGtLT3bEZoa2W8L3Qnp6rDIFWy+ZBrUcOFKdoeGPSnbBqxc3SkdxJrF+D1veN/WNynZYA==}\n    engines: {node: '>=16.13'}\n    peerDependencies:\n      prisma: '*'\n    peerDependenciesMeta:\n      prisma:\n        optional: true\n\n  '@prisma/debug@5.20.0':\n    resolution: {integrity: sha512-oCx79MJ4HSujokA8S1g0xgZUGybD4SyIOydoHMngFYiwEwYDQ5tBQkK5XoEHuwOYDKUOKRn/J0MEymckc4IgsQ==}\n\n  '@prisma/engines-version@5.20.0-12.06fc58a368dc7be9fbbbe894adf8d445d208c284':\n    resolution: {integrity: sha512-Lg8AS5lpi0auZe2Mn4gjuCg081UZf88k3cn0RCwHgR+6cyHHpttPZBElJTHf83ZGsRNAmVCZCfUGA57WB4u4JA==}\n\n  '@prisma/engines@5.20.0':\n    resolution: {integrity: sha512-DtqkP+hcZvPEbj8t8dK5df2b7d3B8GNauKqaddRRqQBBlgkbdhJkxhoJTrOowlS3vaRt2iMCkU0+CSNn0KhqAQ==}\n\n  '@prisma/fetch-engine@5.20.0':\n    resolution: {integrity: sha512-JVcaPXC940wOGpCOwuqQRTz6I9SaBK0c1BAyC1pcz9xBi+dzFgUu3G/p9GV1FhFs9OKpfSpIhQfUJE9y00zhqw==}\n\n  '@prisma/get-platform@5.20.0':\n    resolution: {integrity: sha512-8/+CehTZZNzJlvuryRgc77hZCWrUDYd/PmlZ7p2yNXtmf2Una4BWnTbak3us6WVdqoz5wmptk6IhsXdG2v5fmA==}\n\n  '@protobufjs/aspromise@1.1.2':\n    resolution: {integrity: sha512-j+gKExEuLmKwvz3OgROXtrJ2UG2x8Ch2YZUxahh+s1F2HZ+wAceUNLkvy6zKCPVRkU++ZWQrdxsUeQXmcg4uoQ==}\n\n  '@protobufjs/base64@1.1.2':\n    resolution: {integrity: sha512-AZkcAA5vnN/v4PDqKyMR5lx7hZttPDgClv83E//FMNhR2TMcLUhfRUBHCmSl0oi9zMgDDqRUJkSxO3wm85+XLg==}\n\n  '@protobufjs/codegen@2.0.4':\n    resolution: {integrity: sha512-YyFaikqM5sH0ziFZCN3xDC7zeGaB/d0IUb9CATugHWbd1FRFwWwt4ld4OYMPWu5a3Xe01mGAULCdqhMlPl29Jg==}\n\n  '@protobufjs/eventemitter@1.1.0':\n    resolution: {integrity: sha512-j9ednRT81vYJ9OfVuXG6ERSTdEL1xVsNgqpkxMsbIabzSo3goCjDIveeGv5d03om39ML71RdmrGNjG5SReBP/Q==}\n\n  '@protobufjs/fetch@1.1.0':\n    resolution: {integrity: sha512-lljVXpqXebpsijW71PZaCYeIcE5on1w5DlQy5WH6GLbFryLUrBD4932W/E2BSpfRJWseIL4v/KPgBFxDOIdKpQ==}\n\n  '@protobufjs/float@1.0.2':\n    resolution: {integrity: sha512-Ddb+kVXlXst9d+R9PfTIxh1EdNkgoRe5tOX6t01f1lYWOvJnSPDBlG241QLzcyPdoNTsblLUdujGSE4RzrTZGQ==}\n\n  '@protobufjs/inquire@1.1.0':\n    resolution: {integrity: sha512-kdSefcPdruJiFMVSbn801t4vFK7KB/5gd2fYvrxhuJYg8ILrmn9SKSX2tZdV6V+ksulWqS7aXjBcRXl3wHoD9Q==}\n\n  '@protobufjs/path@1.1.2':\n    resolution: {integrity: sha512-6JOcJ5Tm08dOHAbdR3GrvP+yUUfkjG5ePsHYczMFLq3ZmMkAD98cDgcT2iA1lJ9NVwFd4tH/iSSoe44YWkltEA==}\n\n  '@protobufjs/pool@1.1.0':\n    resolution: {integrity: sha512-0kELaGSIDBKvcgS4zkjz1PeddatrjYcmMWOlAuAPwAeccUrPHdUqo/J6LiymHHEiJT5NrF1UVwxY14f+fy4WQw==}\n\n  '@protobufjs/utf8@1.1.0':\n    resolution: {integrity: sha512-Vvn3zZrhQZkkBE8LSuW3em98c0FwgO4nxzv6OdSxPKJIEKY2bGbHn+mhGIPerzI4twdxaP8/0+06HBpwf345Lw==}\n\n  '@relmify/jest-fp-ts@2.1.1':\n    resolution: {integrity: sha512-ljNGMAINGa8YjIjbkufx6qV0+1HRoX3yNJi92A/RSZifYJpaztqjNtYm9jvKPBmQuZtnkWv+Vik+zMa2rZI0TQ==}\n    peerDependencies:\n      fp-ts: 2.x\n      io-ts: 2.x\n\n  '@repeaterjs/repeater@3.0.4':\n    resolution: {integrity: sha512-AW8PKd6iX3vAZ0vA43nOUOnbq/X5ihgU+mSXXqunMkeQADGiqw/PY0JNeYtD5sr0PAy51YPgAPbDoeapv9r8WA==}\n\n  '@repeaterjs/repeater@3.0.5':\n    resolution: {integrity: sha512-l3YHBLAol6d/IKnB9LhpD0cEZWAoe3eFKUyTYWmFmCO2Q/WOckxLQAUyMZWwZV2M/m3+4vgRoaolFqaII82/TA==}\n\n  '@repeaterjs/repeater@3.0.6':\n    resolution: {integrity: sha512-Javneu5lsuhwNCryN+pXH93VPQ8g0dBX7wItHFgYiwQmzE1sVdg5tWHiOgHywzL2W21XQopa7IwIEnNbmeUJYA==}\n\n  '@rollup/plugin-babel@5.3.1':\n    resolution: {integrity: sha512-WFfdLWU/xVWKeRQnKmIAQULUI7Il0gZnBIH/ZFO069wYIfPu+8zrfp/KMW0atmELoRDq8FbiP3VCss9MhCut7Q==}\n    engines: {node: '>= 10.0.0'}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n      '@types/babel__core': ^7.1.9\n      rollup: ^1.20.0||^2.0.0\n    peerDependenciesMeta:\n      '@types/babel__core':\n        optional: true\n\n  '@rollup/plugin-inject@5.0.5':\n    resolution: {integrity: sha512-2+DEJbNBoPROPkgTDNe8/1YXWcqxbN5DTjASVIOx8HS+pITXushyNiBV56RB08zuptzz8gT3YfkqriTBVycepg==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\n    peerDependenciesMeta:\n      rollup:\n        optional: true\n\n  '@rollup/plugin-node-resolve@15.3.0':\n    resolution: {integrity: sha512-9eO5McEICxMzJpDW9OnMYSv4Sta3hmt7VtBFz5zR9273suNOydOyq/FrGeGy+KsTRFm8w0SLVhzig2ILFT63Ag==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      rollup: ^2.78.0||^3.0.0||^4.0.0\n    peerDependenciesMeta:\n      rollup:\n        optional: true\n\n  '@rollup/plugin-replace@2.4.2':\n    resolution: {integrity: sha512-IGcu+cydlUMZ5En85jxHH4qj2hta/11BHq95iHEyb2sbgiN0eCdzvUcHw5gt9pBL5lTi4JDYJ1acCoMGpTvEZg==}\n    peerDependencies:\n      rollup: ^1.20.0 || ^2.0.0\n\n  '@rollup/plugin-terser@0.4.4':\n    resolution: {integrity: sha512-XHeJC5Bgvs8LfukDwWZp7yeqin6ns8RTl2B9avbejt6tZqsqvVoWI7ZTQrcNsfKEDWBTnTxM8nMDkO2IFFbd0A==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      rollup: ^2.0.0||^3.0.0||^4.0.0\n    peerDependenciesMeta:\n      rollup:\n        optional: true\n\n  '@rollup/plugin-typescript@12.1.1':\n    resolution: {integrity: sha512-t7O653DpfB5MbFrqPe/VcKFFkvRuFNp9qId3xq4Eth5xlyymzxNpye2z8Hrl0RIMuXTSr5GGcFpkdlMeacUiFQ==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      rollup: ^2.14.0||^3.0.0||^4.0.0\n      tslib: '*'\n      typescript: '>=3.7.0'\n    peerDependenciesMeta:\n      rollup:\n        optional: true\n      tslib:\n        optional: true\n\n  '@rollup/pluginutils@3.1.0':\n    resolution: {integrity: sha512-GksZ6pr6TpIjHm8h9lSQ8pi8BE9VeubNT0OMJ3B5uZJ8pz73NPiqOtCog/x2/QzM1ENChPKxMDhiQuRHsqc+lg==}\n    engines: {node: '>= 8.0.0'}\n    peerDependencies:\n      rollup: ^1.20.0||^2.0.0\n\n  '@rollup/pluginutils@4.2.1':\n    resolution: {integrity: sha512-iKnFXr7NkdZAIHiIWE+BX5ULi/ucVFYWD6TbAV+rZctiRTY2PL6tsIKhoIOaoskiWAkgu+VsbXgUVDNLHf+InQ==}\n    engines: {node: '>= 8.0.0'}\n\n  '@rollup/pluginutils@5.1.2':\n    resolution: {integrity: sha512-/FIdS3PyZ39bjZlwqFnWqCOVnW7o963LtKMwQOD0NhQqw22gSr2YY1afu3FxRip4ZCZNsD5jq6Aaz6QV3D/Njw==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      rollup: ^1.20.0||^2.0.0||^3.0.0||^4.0.0\n    peerDependenciesMeta:\n      rollup:\n        optional: true\n\n  '@rollup/rollup-android-arm-eabi@4.24.0':\n    resolution: {integrity: sha512-Q6HJd7Y6xdB48x8ZNVDOqsbh2uByBhgK8PiQgPhwkIw/HC/YX5Ghq2mQY5sRMZWHb3VsFkWooUVOZHKr7DmDIA==}\n    cpu: [arm]\n    os: [android]\n\n  '@rollup/rollup-android-arm64@4.24.0':\n    resolution: {integrity: sha512-ijLnS1qFId8xhKjT81uBHuuJp2lU4x2yxa4ctFPtG+MqEE6+C5f/+X/bStmxapgmwLwiL3ih122xv8kVARNAZA==}\n    cpu: [arm64]\n    os: [android]\n\n  '@rollup/rollup-darwin-arm64@4.24.0':\n    resolution: {integrity: sha512-bIv+X9xeSs1XCk6DVvkO+S/z8/2AMt/2lMqdQbMrmVpgFvXlmde9mLcbQpztXm1tajC3raFDqegsH18HQPMYtA==}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@rollup/rollup-darwin-x64@4.24.0':\n    resolution: {integrity: sha512-X6/nOwoFN7RT2svEQWUsW/5C/fYMBe4fnLK9DQk4SX4mgVBiTA9h64kjUYPvGQ0F/9xwJ5U5UfTbl6BEjaQdBQ==}\n    cpu: [x64]\n    os: [darwin]\n\n  '@rollup/rollup-linux-arm-gnueabihf@4.24.0':\n    resolution: {integrity: sha512-0KXvIJQMOImLCVCz9uvvdPgfyWo93aHHp8ui3FrtOP57svqrF/roSSR5pjqL2hcMp0ljeGlU4q9o/rQaAQ3AYA==}\n    cpu: [arm]\n    os: [linux]\n\n  '@rollup/rollup-linux-arm-musleabihf@4.24.0':\n    resolution: {integrity: sha512-it2BW6kKFVh8xk/BnHfakEeoLPv8STIISekpoF+nBgWM4d55CZKc7T4Dx1pEbTnYm/xEKMgy1MNtYuoA8RFIWw==}\n    cpu: [arm]\n    os: [linux]\n\n  '@rollup/rollup-linux-arm64-gnu@4.24.0':\n    resolution: {integrity: sha512-i0xTLXjqap2eRfulFVlSnM5dEbTVque/3Pi4g2y7cxrs7+a9De42z4XxKLYJ7+OhE3IgxvfQM7vQc43bwTgPwA==}\n    cpu: [arm64]\n    os: [linux]\n\n  '@rollup/rollup-linux-arm64-musl@4.24.0':\n    resolution: {integrity: sha512-9E6MKUJhDuDh604Qco5yP/3qn3y7SLXYuiC0Rpr89aMScS2UAmK1wHP2b7KAa1nSjWJc/f/Lc0Wl1L47qjiyQw==}\n    cpu: [arm64]\n    os: [linux]\n\n  '@rollup/rollup-linux-powerpc64le-gnu@4.24.0':\n    resolution: {integrity: sha512-2XFFPJ2XMEiF5Zi2EBf4h73oR1V/lycirxZxHZNc93SqDN/IWhYYSYj8I9381ikUFXZrz2v7r2tOVk2NBwxrWw==}\n    cpu: [ppc64]\n    os: [linux]\n\n  '@rollup/rollup-linux-riscv64-gnu@4.24.0':\n    resolution: {integrity: sha512-M3Dg4hlwuntUCdzU7KjYqbbd+BLq3JMAOhCKdBE3TcMGMZbKkDdJ5ivNdehOssMCIokNHFOsv7DO4rlEOfyKpg==}\n    cpu: [riscv64]\n    os: [linux]\n\n  '@rollup/rollup-linux-s390x-gnu@4.24.0':\n    resolution: {integrity: sha512-mjBaoo4ocxJppTorZVKWFpy1bfFj9FeCMJqzlMQGjpNPY9JwQi7OuS1axzNIk0nMX6jSgy6ZURDZ2w0QW6D56g==}\n    cpu: [s390x]\n    os: [linux]\n\n  '@rollup/rollup-linux-x64-gnu@4.24.0':\n    resolution: {integrity: sha512-ZXFk7M72R0YYFN5q13niV0B7G8/5dcQ9JDp8keJSfr3GoZeXEoMHP/HlvqROA3OMbMdfr19IjCeNAnPUG93b6A==}\n    cpu: [x64]\n    os: [linux]\n\n  '@rollup/rollup-linux-x64-musl@4.24.0':\n    resolution: {integrity: sha512-w1i+L7kAXZNdYl+vFvzSZy8Y1arS7vMgIy8wusXJzRrPyof5LAb02KGr1PD2EkRcl73kHulIID0M501lN+vobQ==}\n    cpu: [x64]\n    os: [linux]\n\n  '@rollup/rollup-win32-arm64-msvc@4.24.0':\n    resolution: {integrity: sha512-VXBrnPWgBpVDCVY6XF3LEW0pOU51KbaHhccHw6AS6vBWIC60eqsH19DAeeObl+g8nKAz04QFdl/Cefta0xQtUQ==}\n    cpu: [arm64]\n    os: [win32]\n\n  '@rollup/rollup-win32-ia32-msvc@4.24.0':\n    resolution: {integrity: sha512-xrNcGDU0OxVcPTH/8n/ShH4UevZxKIO6HJFK0e15XItZP2UcaiLFd5kiX7hJnqCbSztUF8Qot+JWBC/QXRPYWQ==}\n    cpu: [ia32]\n    os: [win32]\n\n  '@rollup/rollup-win32-x64-msvc@4.24.0':\n    resolution: {integrity: sha512-fbMkAF7fufku0N2dE5TBXcNlg0pt0cJue4xBRE2Qc5Vqikxr4VCgKj/ht6SMdFcOacVA9rqF70APJ8RN/4vMJw==}\n    cpu: [x64]\n    os: [win32]\n\n  '@rushstack/eslint-patch@1.10.4':\n    resolution: {integrity: sha512-WJgX9nzTqknM393q1QJDJmoW28kUfEnybeTfVNcNAPnIx210RXm2DiXiHzfNPJNIUUb1tJnz/l4QGtJ30PgWmA==}\n\n  '@rushstack/eslint-patch@1.3.3':\n    resolution: {integrity: sha512-0xd7qez0AQ+MbHatZTlI1gu5vkG8r7MYRUJAHPAHJBmGLs16zpkrpAVLvjQKQOqaXPDUBwOiJzNc00znHSCVBw==}\n\n  '@scure/base@1.1.9':\n    resolution: {integrity: sha512-8YKhl8GHiNI/pU2VMaofa2Tor7PJRAjwQLBBuilkJ9L5+13yVbC7JO/wS7piioAvPSwR3JKM1IJ/u4xQzbcXKg==}\n\n  '@selderee/plugin-htmlparser2@0.11.0':\n    resolution: {integrity: sha512-P33hHGdldxGabLFjPPpaTxVolMrzrcegejx+0GxjrIb9Zv48D8yAIA/QTDR2dFl7Uz7urX8aX6+5bCZslr+gWQ==}\n\n  '@shopify/lang-jsonc@1.0.0':\n    resolution: {integrity: sha512-Zvj0eerl0pKoY41no0DBayDT44PVkTx0hGuD98t3v2JSzqOcyvuP3HtW/NVi8StTbKPLWObX+gqZ+u+rUR2H3g==}\n\n  '@sinclair/typebox@0.27.8':\n    resolution: {integrity: sha512-+Fj43pSMwJs4KRrH/938Uf+uAELIgVBmQzg/q1YG10djyfA3TnrU8N8XzqCh/okZdszqBQTZf96idMfE5lnwTA==}\n\n  '@sinonjs/commons@3.0.1':\n    resolution: {integrity: sha512-K3mCHKQ9sVh8o1C9cxkwxaOmXoAMlDxC1mYyHrjqOWEcBjYr76t96zL2zlj5dUGZ3HSw240X1qgH3Mjf1yJWpQ==}\n\n  '@sinonjs/fake-timers@10.3.0':\n    resolution: {integrity: sha512-V4BG07kuYSUkTCSBHG8G8TNhM+F19jXFWnQtzj+we8DrkpSBCee9Z3Ms8yiGer/dlmhe35/Xdgyo3/0rQKg7YA==}\n\n  '@socket.io/component-emitter@3.1.2':\n    resolution: {integrity: sha512-9BCxFwvbGg/RsZK9tjXd8s4UcwR0MWeFQ1XEKIQVVvAGJyINdrqKMcTRyLoK8Rse1GjzLV9cwjWV1olXRWEXVA==}\n\n  '@surma/rollup-plugin-off-main-thread@2.2.3':\n    resolution: {integrity: sha512-lR8q/9W7hZpMWweNiAKU7NQerBnzQQLvi8qnTDU/fxItPhtZVMbPV3lbCwjhIlNBe9Bbr5V+KHshvWmVSG9cxQ==}\n\n  '@swc/core-darwin-arm64@1.4.2':\n    resolution: {integrity: sha512-1uSdAn1MRK5C1m/TvLZ2RDvr0zLvochgrZ2xL+lRzugLlCTlSA+Q4TWtrZaOz+vnnFVliCpw7c7qu0JouhgQIw==}\n    engines: {node: '>=10'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@swc/core-darwin-x64@1.4.2':\n    resolution: {integrity: sha512-TYD28+dCQKeuxxcy7gLJUCFLqrwDZnHtC2z7cdeGfZpbI2mbfppfTf2wUPzqZk3gEC96zHd4Yr37V3Tvzar+lQ==}\n    engines: {node: '>=10'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@swc/core-linux-arm-gnueabihf@1.4.2':\n    resolution: {integrity: sha512-Eyqipf7ZPGj0vplKHo8JUOoU1un2sg5PjJMpEesX0k+6HKE2T8pdyeyXODN0YTFqzndSa/J43EEPXm+rHAsLFQ==}\n    engines: {node: '>=10'}\n    cpu: [arm]\n    os: [linux]\n\n  '@swc/core-linux-arm64-gnu@1.4.2':\n    resolution: {integrity: sha512-wZn02DH8VYPv3FC0ub4my52Rttsus/rFw+UUfzdb3tHMHXB66LqN+rR0ssIOZrH6K+VLN6qpTw9VizjyoH0BxA==}\n    engines: {node: '>=10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@swc/core-linux-arm64-musl@1.4.2':\n    resolution: {integrity: sha512-3G0D5z9hUj9bXNcwmA1eGiFTwe5rWkuL3DsoviTj73TKLpk7u64ND0XjEfO0huVv4vVu9H1jodrKb7nvln/dlw==}\n    engines: {node: '>=10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@swc/core-linux-x64-gnu@1.4.2':\n    resolution: {integrity: sha512-LFxn9U8cjmYHw3jrdPNqPAkBGglKE3tCZ8rA7hYyp0BFxuo7L2ZcEnPm4RFpmSCCsExFH+LEJWuMGgWERoktvg==}\n    engines: {node: '>=10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@swc/core-linux-x64-musl@1.4.2':\n    resolution: {integrity: sha512-dp0fAmreeVVYTUcb4u9njTPrYzKnbIH0EhH2qvC9GOYNNREUu2GezSIDgonjOXkHiTCvopG4xU7y56XtXj4VrQ==}\n    engines: {node: '>=10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@swc/core-win32-arm64-msvc@1.4.2':\n    resolution: {integrity: sha512-HlVIiLMQkzthAdqMslQhDkoXJ5+AOLUSTV6fm6shFKZKqc/9cJvr4S8UveNERL9zUficA36yM3bbfo36McwnvQ==}\n    engines: {node: '>=10'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@swc/core-win32-ia32-msvc@1.4.2':\n    resolution: {integrity: sha512-WCF8faPGjCl4oIgugkp+kL9nl3nUATlzKXCEGFowMEmVVCFM0GsqlmGdPp1pjZoWc9tpYanoXQDnp5IvlDSLhA==}\n    engines: {node: '>=10'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@swc/core-win32-x64-msvc@1.4.2':\n    resolution: {integrity: sha512-oV71rwiSpA5xre2C5570BhCsg1HF97SNLsZ/12xv7zayGzqr3yvFALFJN8tHKpqUdCB4FGPjoP3JFdV3i+1wUw==}\n    engines: {node: '>=10'}\n    cpu: [x64]\n    os: [win32]\n\n  '@swc/core@1.4.2':\n    resolution: {integrity: sha512-vWgY07R/eqj1/a0vsRKLI9o9klGZfpLNOVEnrv4nrccxBgYPjcf22IWwAoaBJ+wpA7Q4fVjCUM8lP0m01dpxcg==}\n    engines: {node: '>=10'}\n    peerDependencies:\n      '@swc/helpers': ^0.5.0\n    peerDependenciesMeta:\n      '@swc/helpers':\n        optional: true\n\n  '@swc/counter@0.1.3':\n    resolution: {integrity: sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==}\n\n  '@swc/types@0.1.12':\n    resolution: {integrity: sha512-wBJA+SdtkbFhHjTMYH+dEH1y4VpfGdAc2Kw/LK09i9bXd/K6j6PkDcFCEzb6iVfZMkPRrl/q0e3toqTAJdkIVA==}\n\n  '@tauri-apps/api@1.5.1':\n    resolution: {integrity: sha512-6unsZDOdlXTmauU3NhWhn+Cx0rODV+rvNvTdvolE5Kls5ybA6cqndQENDt1+FS0tF7ozCP66jwWoH6a5h90BrA==}\n    engines: {node: '>= 14.6.0', npm: '>= 6.6.0', yarn: '>= 1.19.1'}\n\n  '@tauri-apps/api@2.0.2':\n    resolution: {integrity: sha512-3wSwmG+1kr6WrgAFKK5ijkNFPp8TT3FLj3YHUb5EwMO+3FxX4uWlfSWkeeBy+Kc1RsKzugtYLuuya+98Flj+3w==}\n\n  '@tauri-apps/cli-darwin-arm64@1.5.6':\n    resolution: {integrity: sha512-NNvG3XLtciCMsBahbDNUEvq184VZmOveTGOuy0So2R33b/6FDkuWaSgWZsR1mISpOuP034htQYW0VITCLelfqg==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@tauri-apps/cli-darwin-arm64@2.0.4':\n    resolution: {integrity: sha512-siH7rOHobb16rPbc11k64p1mxIpiRCkWmzs2qmL5IX21Gx9K5onI3Tk67Oqpf2uNupbYzItrOttaDT4NHFC7tw==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [darwin]\n\n  '@tauri-apps/cli-darwin-x64@1.5.6':\n    resolution: {integrity: sha512-nkiqmtUQw3N1j4WoVjv81q6zWuZFhBLya/RNGUL94oafORloOZoSY0uTZJAoeieb3Y1YK0rCHSDl02MyV2Fi4A==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@tauri-apps/cli-darwin-x64@2.0.4':\n    resolution: {integrity: sha512-zIccfbCoZMfmUpnk6PFCV0keFyfVj1A9XV3Oiiitj/dkTZ9CQvzjhX3XC0XcK4rsTWegfr2PjSrK06aiPAROAw==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [darwin]\n\n  '@tauri-apps/cli-linux-arm-gnueabihf@1.5.6':\n    resolution: {integrity: sha512-z6SPx+axZexmWXTIVPNs4Tg7FtvdJl9EKxYN6JPjOmDZcqA13iyqWBQal2DA/GMZ1Xqo3vyJf6EoEaKaliymPQ==}\n    engines: {node: '>= 10'}\n    cpu: [arm]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-arm-gnueabihf@2.0.4':\n    resolution: {integrity: sha512-fgQqJzefOGWCBNg4yrVA82Rg4s1XQr5K0dc2rCxBhJfa696e8dQ1LDrnWq/AiO5r+uHfVaoQTIUvxxpFicYRSA==}\n    engines: {node: '>= 10'}\n    cpu: [arm]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-arm64-gnu@1.5.6':\n    resolution: {integrity: sha512-QuQjMQmpsCbzBrmtQiG4uhnfAbdFx3nzm+9LtqjuZlurc12+Mj5MTgqQ3AOwQedH3f7C+KlvbqD2AdXpwTg7VA==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-arm64-gnu@2.0.4':\n    resolution: {integrity: sha512-u8wbt5tPA9pI6j+d7jGrfOz9UVCiTp+IYzKNiIqlrDsAjqAUFaNXYHKqOUboeFWEmI4zoCWj6LgpS2OJTQ5FKg==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-arm64-musl@1.5.6':\n    resolution: {integrity: sha512-8j5dH3odweFeom7bRGlfzDApWVOT4jIq8/214Wl+JeiNVehouIBo9lZGeghZBH3XKFRwEvU23i7sRVjuh2s8mg==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-arm64-musl@2.0.4':\n    resolution: {integrity: sha512-hntF1V8e3V1hlrESm93PsghDhf3lA5pbvFrRfYxU1c+fVD/jRXGVw8BH3O1lW8MWwhEg1YdhKk01oAgsuHLuig==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-x64-gnu@1.5.6':\n    resolution: {integrity: sha512-gbFHYHfdEGW0ffk8SigDsoXks6USpilF6wR0nqB/JbWzbzFR/sBuLVNQlJl1RKNakyJHu+lsFxGy0fcTdoX8xA==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-x64-gnu@2.0.4':\n    resolution: {integrity: sha512-Iq1GGJb+oT1T0ZV8izrgf0cBtlzPCJaWcNueRbf1ZXquMf+FSTyQv+/Lo8rq5T6buOIJOH7cAOTuEWWqiCZteg==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-x64-musl@1.5.6':\n    resolution: {integrity: sha512-9v688ogoLkeFYQNgqiSErfhTreLUd8B3prIBSYUt+x4+5Kcw91zWvIh+VSxL1n3KCGGsM7cuXhkGPaxwlEh1ug==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@tauri-apps/cli-linux-x64-musl@2.0.4':\n    resolution: {integrity: sha512-9NTk6Pf0bSwXqCBdAA+PDYts9HeHebZzIo8mbRzRyUbER6QngG5HZb9Ka36Z1QWtJjdRy6uxSb4zb/9NuTeHfA==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [linux]\n\n  '@tauri-apps/cli-win32-arm64-msvc@1.5.6':\n    resolution: {integrity: sha512-DRNDXFNZb6y5IZrw+lhTTA9l4wbzO4TNRBAlHAiXUrH+pRFZ/ZJtv5WEuAj9ocVSahVw2NaK5Yaold4NPAxHog==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@tauri-apps/cli-win32-arm64-msvc@2.0.4':\n    resolution: {integrity: sha512-OF2e9oxiBFR8A8wVMOhUx9QGN/I1ZkquWC7gVQBnA56nx9PabJlDT08QBy5UD8USqZFVznnfNr2ehlheQahb3g==}\n    engines: {node: '>= 10'}\n    cpu: [arm64]\n    os: [win32]\n\n  '@tauri-apps/cli-win32-ia32-msvc@1.5.6':\n    resolution: {integrity: sha512-oUYKNR/IZjF4fsOzRpw0xesl2lOjhsQEyWlgbpT25T83EU113Xgck9UjtI7xemNI/OPCv1tPiaM1e7/ABdg5iA==}\n    engines: {node: '>= 10'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@tauri-apps/cli-win32-ia32-msvc@2.0.4':\n    resolution: {integrity: sha512-T+hCKB3rFP6q0saHHtR02hm6wr1ZPJ0Mkii3oRTxjPG6BBXoVzHNCYzvdgEGJPTA2sFuAQtJH764NRtNlDMifw==}\n    engines: {node: '>= 10'}\n    cpu: [ia32]\n    os: [win32]\n\n  '@tauri-apps/cli-win32-x64-msvc@1.5.6':\n    resolution: {integrity: sha512-RmEf1os9C8//uq2hbjXi7Vgz9ne7798ZxqemAZdUwo1pv3oLVZSz1/IvZmUHPdy2e6zSeySqWu1D0Y3QRNN+dg==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [win32]\n\n  '@tauri-apps/cli-win32-x64-msvc@2.0.4':\n    resolution: {integrity: sha512-GVaiI3KWRFLomjJmApHqihhYlkJ+7FqhumhVfBO6Z2tWzZjQyVQgTdNp0kYEuW2WoAYEj0dKY6qd4YM33xYcUA==}\n    engines: {node: '>= 10'}\n    cpu: [x64]\n    os: [win32]\n\n  '@tauri-apps/cli@1.5.6':\n    resolution: {integrity: sha512-k4Y19oVCnt7WZb2TnDzLqfs7o98Jq0tUoVMv+JQSzuRDJqaVu2xMBZ8dYplEn+EccdR5SOMyzaLBJWu38TVK1A==}\n    engines: {node: '>= 10'}\n    hasBin: true\n\n  '@tauri-apps/cli@2.0.4':\n    resolution: {integrity: sha512-Hl9eFXz+O366+6su9PfaSzu2EJdFe1p8K8ghkWmi40dz8VmSE7vsMTaOStD0I71ckSOkh2ICDX7FQTBgjlpjWw==}\n    engines: {node: '>= 10'}\n    hasBin: true\n\n  '@tauri-apps/plugin-shell@2.0.0':\n    resolution: {integrity: sha512-OpW2+ycgJLrEoZityWeWYk+6ZWP9VyiAfbO+N/O8VfLkqyOym8kXh7odKDfINx9RAotkSGBtQM4abyKfJDkcUg==}\n\n  '@trysound/sax@0.2.0':\n    resolution: {integrity: sha512-L7z9BgrNEcYyUYtF+HaEfiS5ebkh9jXqbszz7pC0hRBPaatV0XjSD3+eHrpqFemQfgwiFF0QPIarnIihIDn7OA==}\n    engines: {node: '>=10.13.0'}\n\n  '@tsconfig/node10@1.0.11':\n    resolution: {integrity: sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==}\n\n  '@tsconfig/node12@1.0.11':\n    resolution: {integrity: sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==}\n\n  '@tsconfig/node14@1.0.3':\n    resolution: {integrity: sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==}\n\n  '@tsconfig/node16@1.0.4':\n    resolution: {integrity: sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==}\n\n  '@types/babel__core@7.20.5':\n    resolution: {integrity: sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==}\n\n  '@types/babel__generator@7.6.8':\n    resolution: {integrity: sha512-ASsj+tpEDsEiFr1arWrlN6V3mdfjRMZt6LtK/Vp/kreFLnr5QH5+DhvD5nINYZXzwJvXeGq+05iUXcAzVrqWtw==}\n\n  '@types/babel__template@7.4.4':\n    resolution: {integrity: sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==}\n\n  '@types/babel__traverse@7.20.6':\n    resolution: {integrity: sha512-r1bzfrm0tomOI8g1SzvCaQHo6Lcv6zu0EA+W2kHrt8dyrHQxGzBBL4kdkzIS+jBMV+EYcMAEAqXqYaLJq5rOZg==}\n\n  '@types/bcrypt@5.0.2':\n    resolution: {integrity: sha512-6atioO8Y75fNcbmj0G7UjI9lXN2pQ/IGJ2FWT4a/btd0Lk9lQalHLKhkgKVZ3r+spnmWUKfbMi1GEe9wyHQfNQ==}\n\n  '@types/body-parser@1.19.5':\n    resolution: {integrity: sha512-fB3Zu92ucau0iQ0JMCFQE7b/dv8Ot07NI3KaZIkIUNXq82k4eBAqUaneXfleGY9JWskeS9y+u0nXMyspcuQrCg==}\n\n  '@types/connect@3.4.38':\n    resolution: {integrity: sha512-K6uROf1LD88uDQqJCktA4yzL1YYAK6NgfsI0v/mTgyPKWsX1CnJ0XPSDhViejru1GcRkLWb8RlzFYJRqGUbaug==}\n\n  '@types/conventional-commits-parser@5.0.0':\n    resolution: {integrity: sha512-loB369iXNmAZglwWATL+WRe+CRMmmBPtpolYzIebFaX4YA3x+BEfLqhUAV9WanycKI3TG1IMr5bMJDajDKLlUQ==}\n\n  '@types/cookie-parser@1.4.7':\n    resolution: {integrity: sha512-Fvuyi354Z+uayxzIGCwYTayFKocfV7TuDYZClCdIP9ckhvAu/ixDtCB6qx2TT0FKjPLf1f3P/J1rgf6lPs64mw==}\n\n  '@types/cookie@0.6.0':\n    resolution: {integrity: sha512-4Kh9a6B2bQciAhf7FSuMRRkUWecJgJu9nPnx3yzpsfXX/c50REIqpHY4C82bXP90qrLtXtkDxTZosYO3UpOwlA==}\n\n  '@types/cookiejar@2.1.5':\n    resolution: {integrity: sha512-he+DHOWReW0nghN24E1WUqM0efK4kI9oTqDm6XmK8ZPe2djZ90BSNdGnIyCLzCPw7/pogPlGbzI2wHGGmi4O/Q==}\n\n  '@types/cors@2.8.17':\n    resolution: {integrity: sha512-8CGDvrBj1zgo2qE+oS3pOCyYNqCPryMWY2bGfwA0dcfopWGgxs+78df0Rs3rc9THP4JkOhLsAa+15VdpAqkcUA==}\n\n  '@types/debug@4.1.12':\n    resolution: {integrity: sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==}\n\n  '@types/ejs@3.1.5':\n    resolution: {integrity: sha512-nv+GSx77ZtXiJzwKdsASqi+YQ5Z7vwHsTP0JY2SiQgjGckkBRKZnk8nIM+7oUZ1VCtuTz0+By4qVR7fqzp/Dfg==}\n\n  '@types/eslint@8.56.10':\n    resolution: {integrity: sha512-Shavhk87gCtY2fhXDctcfS3e6FdxWkCx1iUZ9eEUbh7rTqlZT0/IzOkCOVt0fCjcFuZ9FPYfuezTBImfHCDBGQ==}\n\n  '@types/estree@0.0.39':\n    resolution: {integrity: sha512-EYNwp3bU+98cpU4lAWYYL7Zz+2gryWH1qbdDTidVd6hkiR6weksdbMadyXKXNPEkQFhXM+hVO9ZygomHXp+AIw==}\n\n  '@types/estree@1.0.6':\n    resolution: {integrity: sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw==}\n\n  '@types/express-serve-static-core@4.19.6':\n    resolution: {integrity: sha512-N4LZ2xG7DatVqhCZzOGb1Yi5lMbXSZcmdLDe9EzSndPV2HpWYWzRbaerl2n27irrm94EPpprqa8KpskPT085+A==}\n\n  '@types/express-serve-static-core@5.0.0':\n    resolution: {integrity: sha512-AbXMTZGt40T+KON9/Fdxx0B2WK5hsgxcfXJLr5bFpZ7b4JCex2WyQPTEKdXqfHiY5nKKBScZ7yCoO6Pvgxfvnw==}\n\n  '@types/express@4.17.14':\n    resolution: {integrity: sha512-TEbt+vaPFQ+xpxFLFssxUDXj5cWCxZJjIcB7Yg0k0GMHGtgtQgpvx/MUQUeAkNbA9AAGrwkAsoeItdTgS7FMyg==}\n\n  '@types/express@5.0.0':\n    resolution: {integrity: sha512-DvZriSMehGHL1ZNLzi6MidnsDhUZM/x2pRdDIKdwbUNqqwHxMlRdkxtn6/EPKyqKpHqTl/4nRZsRNLpZxZRpPQ==}\n\n  '@types/graceful-fs@4.1.9':\n    resolution: {integrity: sha512-olP3sd1qOEe5dXTSaFvQG+02VdRXcdytWLAZsAq1PecU8uqQAhkrnbli7DagjtXKW/Bl7YJbUsa8MPcuc8LHEQ==}\n\n  '@types/har-format@1.2.16':\n    resolution: {integrity: sha512-fluxdy7ryD3MV6h8pTfTYpy/xQzCFC7m89nOH9y94cNqJ1mDIDPut7MnRHI3F6qRmh/cT2fUjG1MLdCNb4hE9A==}\n\n  '@types/http-errors@2.0.4':\n    resolution: {integrity: sha512-D0CFMMtydbJAegzOyHjtiKPLlvnm3iTZyZRSZoLq2mRhDdmLfIWOCYPfQJ4cu2erKghU++QvjcUjp/5h7hESpA==}\n\n  '@types/istanbul-lib-coverage@2.0.6':\n    resolution: {integrity: sha512-2QF/t/auWm0lsy8XtKVPG19v3sSOQlJe/YHZgfjb/KBBHOGSV+J2q/S671rcq9uTBrLAXmZpqJiaQbMT+zNU1w==}\n\n  '@types/istanbul-lib-report@3.0.3':\n    resolution: {integrity: sha512-NQn7AHQnk/RSLOxrBbGyJM/aVQ+pjj5HCgasFxc0K/KhoATfQ/47AyUl15I2yBUpihjmas+a+VJBOqecrFH+uA==}\n\n  '@types/istanbul-reports@3.0.4':\n    resolution: {integrity: sha512-pk2B1NWalF9toCRu6gjBzR69syFjP4Od8WRAX+0mmf9lAjCRicLOWc+ZrxZHx/0XRjotgkF9t6iaMJ+aXcOdZQ==}\n\n  '@types/jest@29.5.13':\n    resolution: {integrity: sha512-wd+MVEZCHt23V0/L642O5APvspWply/rGY5BcW4SUETo2UzPU3Z26qr8jC2qxpimI2jjx9h7+2cj2FwIr01bXg==}\n\n  '@types/js-yaml@4.0.9':\n    resolution: {integrity: sha512-k4MGaQl5TGo/iipqb2UDG2UwjXziSWkh0uysQelTlJpX1qGlpUZYm8PnO4DxG1qBomtJUdYJ6qR6xdIah10JLg==}\n\n  '@types/json-schema@7.0.15':\n    resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}\n\n  '@types/json-schema@7.0.9':\n    resolution: {integrity: sha512-qcUXuemtEu+E5wZSJHNxUXeCZhAfXKQ41D+duX+VYPde7xyEVZci+/oXKJL13tnRs9lR2pr4fod59GT6/X1/yQ==}\n\n  '@types/jsonwebtoken@9.0.5':\n    resolution: {integrity: sha512-VRLSGzik+Unrup6BsouBeHsf4d1hOEgYWTm/7Nmw1sXoN1+tRly/Gy/po3yeahnP4jfnQWWAhQAqcNfH7ngOkA==}\n\n  '@types/jsonwebtoken@9.0.6':\n    resolution: {integrity: sha512-/5hndP5dCjloafCXns6SZyESp3Ldq7YjH3zwzwczYnjxIT0Fqzk5ROSYVGfFyczIue7IUEj8hkvLbPoLQ18vQw==}\n\n  '@types/lodash-es@4.17.10':\n    resolution: {integrity: sha512-YJP+w/2khSBwbUSFdGsSqmDvmnN3cCKoPOL7Zjle6s30ZtemkkqhjVfFqGwPN7ASil5VyjE2GtyU/yqYY6mC0A==}\n\n  '@types/lodash-es@4.17.12':\n    resolution: {integrity: sha512-0NgftHUcV4v34VhXm8QBSftKVXtbkBG3ViCjs6+eJ5a6y6Mi/jiFGPc1sC7QK+9BFhWrURE3EOggmWaSxL9OzQ==}\n\n  '@types/lodash@4.17.10':\n    resolution: {integrity: sha512-YpS0zzoduEhuOWjAotS6A5AVCva7X4lVlYLF0FYHAY9sdraBfnatttHItlWeZdGhuEkf+OzMNg2ZYAx8t+52uQ==}\n\n  '@types/long@4.0.2':\n    resolution: {integrity: sha512-MqTGEo5bj5t157U6fA/BiDynNkn0YknVdh48CMPkTSpFTVmvao5UQmm7uEF6xBEo7qIMAlY/JSleYaE6VOdpaA==}\n\n  '@types/lossless-json@1.0.4':\n    resolution: {integrity: sha512-eHhzo0p2p9On3cTr5X0Q0XsOjJxkqYzQi5Le5ObSiJjnLlGpDQvTcQEXknCkvKOFLBLa8ny4dgJKr0ADRV8yig==}\n\n  '@types/luxon@3.4.2':\n    resolution: {integrity: sha512-TifLZlFudklWlMBfhubvgqTXRzLDI5pCbGa4P8a3wPyUQSW+1xQ5eDsreP9DWHX3tjq1ke96uYG/nwundroWcA==}\n\n  '@types/methods@1.1.4':\n    resolution: {integrity: sha512-ymXWVrDiCxTBE3+RIrrP533E70eA+9qu7zdWoHuOmGujkYtzf4HQF96b8nwHLqhuf4ykX61IGRIB38CC6/sImQ==}\n\n  '@types/mime@1.3.5':\n    resolution: {integrity: sha512-/pyBZWSLD2n0dcHE3hq8s8ZvcETHtEuF+3E7XVt0Ig2nvsVQXdghHVcEkIWjy9A0wKfTn97a/PSDYohKIlnP/w==}\n\n  '@types/mjml-core@4.15.0':\n    resolution: {integrity: sha512-jSRWTOpwRS/uHIBfGdvLl0a7MaoBZZYHKI+HhsFYChrUOKVJTnjSYsuV6wx0snv6ZaX3TUo5OP/gNsz/uzZz1A==}\n\n  '@types/mjml@4.7.4':\n    resolution: {integrity: sha512-vyi1vzWgMzFMwZY7GSZYX0GU0dmtC8vLHwpgk+NWmwbwRSrlieVyJ9sn5elodwUfklJM7yGl0zQeet1brKTWaQ==}\n\n  '@types/ms@0.7.34':\n    resolution: {integrity: sha512-nG96G3Wp6acyAgJqGasjODb+acrI7KltPiRxzHPXnP3NgI28bpQDRv53olbqGXbfcgF5aiiHmO3xpwEpS5Ld9g==}\n\n  '@types/node-fetch@2.6.11':\n    resolution: {integrity: sha512-24xFj9R5+rfQJLRyM56qh+wnVSYhyXC2tkoBndtY0U+vubqNsYXGjufB2nn8Q6gt0LrARwL6UBtMCSVCwl4B1g==}\n\n  '@types/node@17.0.45':\n    resolution: {integrity: sha512-w+tIMs3rq2afQdsPJlODhoUEKzFP1ayaoyl1CcnwtIlsVe7K7bA1NGm4s3PraqTLlXnbIN84zuBlxBWo1u9BLw==}\n\n  '@types/node@18.18.8':\n    resolution: {integrity: sha512-OLGBaaK5V3VRBS1bAkMVP2/W9B+H8meUfl866OrMNQqt7wDgdpWPp5o6gmIc9pB+lIQHSq4ZL8ypeH1vPxcPaQ==}\n\n  '@types/node@22.7.5':\n    resolution: {integrity: sha512-jML7s2NAzMWc//QSJ1a3prpk78cOPchGvXJsC3C6R6PSMoooztvRVQEz89gmBTBY1SPMaqo5teB4uNHPdetShQ==}\n\n  '@types/node@22.7.6':\n    resolution: {integrity: sha512-/d7Rnj0/ExXDMcioS78/kf1lMzYk4BZV8MZGTBKzTGZ6/406ukkbYlIsZmMPhcR5KlkunDHQLrtAVmSq7r+mSw==}\n\n  '@types/nodemailer@6.4.16':\n    resolution: {integrity: sha512-uz6hN6Pp0upXMcilM61CoKyjT7sskBoOWpptkjjJp8jIMlTdc3xG01U7proKkXzruMS4hS0zqtHNkNPFB20rKQ==}\n\n  '@types/nprogress@0.2.3':\n    resolution: {integrity: sha512-k7kRA033QNtC+gLc4VPlfnue58CM1iQLgn1IMAU8VPHGOj7oIHPp9UlhedEnD/Gl8evoCjwkZjlBORtZ3JByUA==}\n\n  '@types/oauth@0.9.4':\n    resolution: {integrity: sha512-qk9orhti499fq5XxKCCEbd0OzdPZuancneyse3KtR+vgMiHRbh+mn8M4G6t64ob/Fg+GZGpa565MF/2dKWY32A==}\n\n  '@types/paho-mqtt@1.0.10':\n    resolution: {integrity: sha512-xOEii1m7jw7mIKjufDkolpz7VlyqptUmm/YFPtLJCybrPCuLhN+WYgNpulQ/CXo7wtEW7x4uGon2v89+6g/pcA==}\n\n  '@types/papaparse@5.3.14':\n    resolution: {integrity: sha512-LxJ4iEFcpqc6METwp9f6BV6VVc43m6MfH0VqFosHvrUgfXiFe6ww7R3itkOQ+TCK6Y+Iv/+RnnvtRZnkc5Kc9g==}\n\n  '@types/passport-github2@1.2.9':\n    resolution: {integrity: sha512-/nMfiPK2E6GKttwBzwj0Wjaot8eHrM57hnWxu52o6becr5/kXlH/4yE2v2rh234WGvSgEEzIII02Nc5oC5xEHA==}\n\n  '@types/passport-google-oauth20@2.0.16':\n    resolution: {integrity: sha512-ayXK2CJ7uVieqhYOc6k/pIr5pcQxOLB6kBev+QUGS7oEZeTgIs1odDobXRqgfBPvXzl0wXCQHftV5220czZCPA==}\n\n  '@types/passport-jwt@4.0.1':\n    resolution: {integrity: sha512-Y0Ykz6nWP4jpxgEUYq8NoVZeCQPo1ZndJLfapI249g1jHChvRfZRO/LS3tqu26YgAS/laI1qx98sYGz0IalRXQ==}\n\n  '@types/passport-microsoft@1.0.3':\n    resolution: {integrity: sha512-Mqm/iTWEhnlS7RcgVlQMyMcXoqt51NbHtXZFAqcjSCZj4iUBu1MTlpw65X3xZ974K2WrlLQhOm3UMmLoUkMaMA==}\n\n  '@types/passport-oauth2@1.4.15':\n    resolution: {integrity: sha512-9cUTP/HStNSZmhxXGuRrBJfEWzIEJRub2eyJu3CvkA+8HAMc9W3aKdFhVq+Qz1hi42qn+GvSAnz3zwacDSYWpw==}\n\n  '@types/passport-strategy@0.2.38':\n    resolution: {integrity: sha512-GC6eMqqojOooq993Tmnmp7AUTbbQSgilyvpCYQjT+H6JfG/g6RGc7nXEniZlp0zyKJ0WUdOiZWLBZft9Yug1uA==}\n\n  '@types/passport@1.0.16':\n    resolution: {integrity: sha512-FD0qD5hbPWQzaM0wHUnJ/T0BBCJBxCeemtnCwc/ThhTg3x9jfrAcRUmj5Dopza+MfFS9acTe3wk7rcVnRIp/0A==}\n\n  '@types/postman-collection@3.5.10':\n    resolution: {integrity: sha512-l8xAUZNW9MzKWyeWuPgQlnyvpX8beeLqXYZTixr55Figae8/0gFb5l5GcU1y+3yeDmbXdY57cGxdvu+4OGbMdg==}\n\n  '@types/pug@2.0.10':\n    resolution: {integrity: sha512-Sk/uYFOBAB7mb74XcpizmH0KOR2Pv3D2Hmrh1Dmy5BmK3MpdSa5kqZcg6EKBdklU0bFXX9gCfzvpnyUehrPIuA==}\n\n  '@types/qs@6.9.16':\n    resolution: {integrity: sha512-7i+zxXdPD0T4cKDuxCUXJ4wHcsJLwENa6Z3dCu8cfCK743OGy5Nu1RmAGqDPsoTDINVEcdXKRvR/zre+P2Ku1A==}\n\n  '@types/ramda@0.28.15':\n    resolution: {integrity: sha512-FCaLNVZry65jW8x/FDnKgjgkCNQxgc5AYMQwdNn6yW5M+62R+0nt2Y36U43dTNora9hcquemfrY5gxhE5pcilQ==}\n\n  '@types/range-parser@1.2.7':\n    resolution: {integrity: sha512-hKormJbkJqzQGhziax5PItDUTMAM9uE2XXQmM37dyd4hVM+5aVl7oVxMVUiVQn2oCQFN/LKCZdvSM0pFRqbSmQ==}\n\n  '@types/resolve@1.20.2':\n    resolution: {integrity: sha512-60BCwRFOZCQhDncwQdxxeOEEkbc5dIMccYLwbxsS4TUNeVECQ/pBJ0j09mrHOl/JJvpRPGwO9SvE4nR2Nb/a4Q==}\n\n  '@types/sax@1.2.7':\n    resolution: {integrity: sha512-rO73L89PJxeYM3s3pPPjiPgVVcymqU490g0YO5n5By0k2Erzj6tay/4lr1CHAAU4JyOWd1rpQ8bCf6cZfHU96A==}\n\n  '@types/semver@7.5.8':\n    resolution: {integrity: sha512-I8EUhyrgfLrcTkzV3TSsGyl1tSuPrEDzr0yd5m90UgNxQkyDXULk3b6MlQqTCpZpNtWe1K0hzclnZkTcLBe2UQ==}\n\n  '@types/send@0.17.4':\n    resolution: {integrity: sha512-x2EM6TJOybec7c52BX0ZspPodMsQUd5L6PRwOunVyVUhXiBSKf3AezDL8Dgvgt5o0UfKNfuA0eMLr2wLT4AiBA==}\n\n  '@types/serve-static@1.15.7':\n    resolution: {integrity: sha512-W8Ym+h8nhuRwaKPaDw34QUkwsGi6Rc4yYqvKFo5rm2FUEhCFbzVWrxXUxuKK8TASjWsysJY0nsmNCGhCOIsrOw==}\n\n  '@types/splitpanes@2.2.6':\n    resolution: {integrity: sha512-3dV5sO1Ht74iER4jJU03mreL3f+Q2h47ZqXS6Sfbqc6hkCvsDrX1GA0NbYWRdNvZemPyTDzUoApWKeoGbALwkQ==}\n\n  '@types/stack-utils@2.0.3':\n    resolution: {integrity: sha512-9aEbYZ3TbYMznPdcdr3SmIrLXwC/AKZXQeCf9Pgao5CKb8CyHuEX5jzWPTkvregvhRJHcpRO6BFoGW9ycaOkYw==}\n\n  '@types/strip-bom@3.0.0':\n    resolution: {integrity: sha512-xevGOReSYGM7g/kUBZzPqCrR/KYAo+F0yiPc85WFTJa0MSLtyFTVTU6cJu/aV4mid7IffDIWqo69THF2o4JiEQ==}\n\n  '@types/strip-json-comments@0.0.30':\n    resolution: {integrity: sha512-7NQmHra/JILCd1QqpSzl8+mJRc8ZHz3uDm8YV1Ks9IhK0epEiTw8aIErbvH9PI+6XbqhyIQy3462nEsn7UVzjQ==}\n\n  '@types/superagent@8.1.7':\n    resolution: {integrity: sha512-NmIsd0Yj4DDhftfWvvAku482PZum4DBW7U51OvS8gvOkDDY0WT1jsVyDV3hK+vplrsYw8oDwi9QxOM7U68iwww==}\n\n  '@types/supertest@6.0.2':\n    resolution: {integrity: sha512-137ypx2lk/wTQbW6An6safu9hXmajAifU/s7szAHLN/FeIm5w7yR0Wkl9fdJMRSHwOn4HLAI0DaB2TOORuhPDg==}\n\n  '@types/trusted-types@2.0.7':\n    resolution: {integrity: sha512-ScaPdn1dQczgbl0QFTeTOmVHFULt394XJgOQNoyVhZ6r2vLnMLJfBPd53SB52T/3G36VI1/g2MZaX0cwDuXsfw==}\n\n  '@types/uuid@10.0.0':\n    resolution: {integrity: sha512-7gqG38EyHgyP1S+7+xomFtL+ZNHcKv6DwNaCZmJmo1vgMugyF3TCnXVg4t1uk89mLNwnLtnY3TpOpCOyp1/xHQ==}\n\n  '@types/validator@13.12.0':\n    resolution: {integrity: sha512-nH45Lk7oPIJ1RVOF6JgFI6Dy0QpHEzq4QecZhvguxYPDwT8c93prCMqAtiIttm39voZ+DDR+qkNnMpJmMBRqag==}\n\n  '@types/web-bluetooth@0.0.14':\n    resolution: {integrity: sha512-5d2RhCard1nQUC3aHcq/gHzWYO6K0WJmAbjO7mQJgCQKtZpgXxv1rOM6O/dBDhDYYVutk1sciOgNSe+5YyfM8A==}\n\n  '@types/web-bluetooth@0.0.18':\n    resolution: {integrity: sha512-v/ZHEj9xh82usl8LMR3GarzFY1IrbXJw5L4QfQhokjRV91q+SelFqxQWSep1ucXEZ22+dSTwLFkXeur25sPIbw==}\n\n  '@types/web-bluetooth@0.0.20':\n    resolution: {integrity: sha512-g9gZnnXVq7gM7v3tJCWV/qw7w+KeOlSHAhgF9RytFyifW6AF61hdT2ucrYhPq9hLs5JIryeupHV3qGk95dH9ow==}\n\n  '@types/ws@8.5.10':\n    resolution: {integrity: sha512-vmQSUcfalpIq0R9q7uTo2lXs6eGIpt9wtnLdMv9LVpIjCA/+ufZRozlVoVelIYixx1ugCBKDhn89vnsEGOCx9A==}\n\n  '@types/ws@8.5.12':\n    resolution: {integrity: sha512-3tPRkv1EtkDpzlgyKyI8pGsGZAGPEaXeu0DOj5DI25Ja91bdAYddYHbADRYVrZMRbfW+1l5YwXVDKohDJNQxkQ==}\n\n  '@types/yargs-parser@21.0.3':\n    resolution: {integrity: sha512-I4q9QU9MQv4oEOz4tAHJtNz1cwuLxn2F3xcc2iV5WdqLPpUnj30aUuxt1mAxYTG+oe8CZMV/+6rU4S4gRDzqtQ==}\n\n  '@types/yargs@17.0.33':\n    resolution: {integrity: sha512-WpxBCKWPLr4xSsHgz511rFJAM+wS28w2zEO1QDNY5zM/S8ok70NNfztH0xwhqKyaK0OHCbN98LDAZuy1ctxDkA==}\n\n  '@typescript-eslint/eslint-plugin@5.62.0':\n    resolution: {integrity: sha512-TiZzBSJja/LbhNPvk6yc0JrX9XqhQ0hdh6M2svYfsHGejaKFIAGd9MQ+ERIMzLGlN/kZoYIgdxFV0PuljTKXag==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      '@typescript-eslint/parser': ^5.0.0\n      eslint: ^6.0.0 || ^7.0.0 || ^8.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/eslint-plugin@7.18.0':\n    resolution: {integrity: sha512-94EQTWZ40mzBc42ATNIBimBEDltSJ9RQHCC8vc/PDbxi4k8dVwUAv4o98dk50M1zB+JGFxp43FP7f8+FP8R6Sw==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      '@typescript-eslint/parser': ^7.0.0\n      eslint: ^8.56.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/eslint-plugin@8.8.1':\n    resolution: {integrity: sha512-xfvdgA8AP/vxHgtgU310+WBnLB4uJQ9XdyP17RebG26rLtDrQJV3ZYrcopX91GrHmMoH8bdSwMRh2a//TiJ1jQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      '@typescript-eslint/parser': ^8.0.0 || ^8.0.0-alpha.0\n      eslint: ^8.57.0 || ^9.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/eslint-plugin@8.9.0':\n    resolution: {integrity: sha512-Y1n621OCy4m7/vTXNlCbMVp87zSd7NH0L9cXD8aIpOaNlzeWxIK4+Q19A68gSmTNRZn92UjocVUWDthGxtqHFg==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      '@typescript-eslint/parser': ^8.0.0 || ^8.0.0-alpha.0\n      eslint: ^8.57.0 || ^9.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/parser@5.62.0':\n    resolution: {integrity: sha512-VlJEV0fOQ7BExOsHYAGrgbEiZoi8D+Bl2+f6V2RrXerRSylnp+ZBHmPvaIa8cz0Ajx7WO7Z5RqfgYg7ED1nRhA==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.0.0 || ^7.0.0 || ^8.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/parser@7.18.0':\n    resolution: {integrity: sha512-4Z+L8I2OqhZV8qA132M4wNL30ypZGYOQVBfMgxDH/K5UX0PNqTu1c6za9ST5r9+tavvHiTWmBnKzpCJ/GlVFtg==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      eslint: ^8.56.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/parser@8.8.1':\n    resolution: {integrity: sha512-hQUVn2Lij2NAxVFEdvIGxT9gP1tq2yM83m+by3whWFsWC+1y8pxxxHUFE1UqDu2VsGi2i6RLcv4QvouM84U+ow==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      eslint: ^8.57.0 || ^9.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/parser@8.9.0':\n    resolution: {integrity: sha512-U+BLn2rqTTHnc4FL3FJjxaXptTxmf9sNftJK62XLz4+GxG3hLHm/SUNaaXP5Y4uTiuYoL5YLy4JBCJe3+t8awQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      eslint: ^8.57.0 || ^9.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/scope-manager@5.62.0':\n    resolution: {integrity: sha512-VXuvVvZeQCQb5Zgf4HAxc04q5j+WrNAtNh9OwCsCgpKqESMTu3tF/jhZ3xG6T4NZwWl65Bg8KuS2uEvhSfLl0w==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@typescript-eslint/scope-manager@7.18.0':\n    resolution: {integrity: sha512-jjhdIE/FPF2B7Z1uzc6i3oWKbGcHb87Qw7AWj6jmEqNOfDFbJWtjt/XfwCpvNkpGWlcJaog5vTR+VV8+w9JflA==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n\n  '@typescript-eslint/scope-manager@8.8.1':\n    resolution: {integrity: sha512-X4JdU+66Mazev/J0gfXlcC/dV6JI37h+93W9BRYXrSn0hrE64IoWgVkO9MSJgEzoWkxONgaQpICWg8vAN74wlA==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@typescript-eslint/scope-manager@8.9.0':\n    resolution: {integrity: sha512-bZu9bUud9ym1cabmOYH9S6TnbWRzpklVmwqICeOulTCZ9ue2/pczWzQvt/cGj2r2o1RdKoZbuEMalJJSYw3pHQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@typescript-eslint/type-utils@5.62.0':\n    resolution: {integrity: sha512-xsSQreu+VnfbqQpW5vnCJdq1Z3Q0U31qiWmRhr98ONQmcp/yhiPJFPq8MXiJVLiksmOKSjIldZzkebzHuCGzew==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: '*'\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/type-utils@7.18.0':\n    resolution: {integrity: sha512-XL0FJXuCLaDuX2sYqZUUSOJ2sG5/i1AAze+axqmLnSkNEVMVYLF+cbwlB2w8D1tinFuSikHmFta+P+HOofrLeA==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      eslint: ^8.56.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/type-utils@8.8.1':\n    resolution: {integrity: sha512-qSVnpcbLP8CALORf0za+vjLYj1Wp8HSoiI8zYU5tHxRVj30702Z1Yw4cLwfNKhTPWp5+P+k1pjmD5Zd1nhxiZA==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/type-utils@8.9.0':\n    resolution: {integrity: sha512-JD+/pCqlKqAk5961vxCluK+clkppHY07IbV3vett97KOV+8C6l+CPEPwpUuiMwgbOz/qrN3Ke4zzjqbT+ls+1Q==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/types@5.62.0':\n    resolution: {integrity: sha512-87NVngcbVXUahrRTqIK27gD2t5Cu1yuCXxbLcFtCzZGlfyVWWh8mLHkoxzjsB6DDNnvdL+fW8MiwPEJyGJQDgQ==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@typescript-eslint/types@7.18.0':\n    resolution: {integrity: sha512-iZqi+Ds1y4EDYUtlOOC+aUmxnE9xS/yCigkjA7XpTKV6nCBd3Hp/PRGGmdwnfkV2ThMyYldP1wRpm/id99spTQ==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n\n  '@typescript-eslint/types@8.8.1':\n    resolution: {integrity: sha512-WCcTP4SDXzMd23N27u66zTKMuEevH4uzU8C9jf0RO4E04yVHgQgW+r+TeVTNnO1KIfrL8ebgVVYYMMO3+jC55Q==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@typescript-eslint/types@8.9.0':\n    resolution: {integrity: sha512-SjgkvdYyt1FAPhU9c6FiYCXrldwYYlIQLkuc+LfAhCna6ggp96ACncdtlbn8FmnG72tUkXclrDExOpEYf1nfJQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@typescript-eslint/typescript-estree@5.62.0':\n    resolution: {integrity: sha512-CmcQ6uY7b9y694lKdRB8FEel7JbU/40iSAPomu++SjLMntB+2Leay2LO6i8VnJk58MtE9/nQSFIH6jpyRWyYzA==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/typescript-estree@7.18.0':\n    resolution: {integrity: sha512-aP1v/BSPnnyhMHts8cf1qQ6Q1IFwwRvAQGRvBFkWlo3/lH29OXA3Pts+c10nxRxIBrDnoMqzhgdwVe5f2D6OzA==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/typescript-estree@8.8.1':\n    resolution: {integrity: sha512-A5d1R9p+X+1js4JogdNilDuuq+EHZdsH9MjTVxXOdVFfTJXunKJR/v+fNNyO4TnoOn5HqobzfRlc70NC6HTcdg==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/typescript-estree@8.9.0':\n    resolution: {integrity: sha512-9iJYTgKLDG6+iqegehc5+EqE6sqaee7kb8vWpmHZ86EqwDjmlqNNHeqDVqb9duh+BY6WCNHfIGvuVU3Tf9Db0g==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@typescript-eslint/utils@5.62.0':\n    resolution: {integrity: sha512-n8oxjeb5aIbPFEtmQxQYOLI0i9n5ySBEY/ZEHHZqKQSFnxio1rv6dthascc9dLuwrL0RC5mPCxB7vnAVGAYWAQ==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.0.0 || ^7.0.0 || ^8.0.0\n\n  '@typescript-eslint/utils@7.18.0':\n    resolution: {integrity: sha512-kK0/rNa2j74XuHVcoCZxdFBMF+aq/vH83CXAOHieC+2Gis4mF8jJXT5eAfyD3K0sAxtPuwxaIOIOvhwzVDt/kw==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      eslint: ^8.56.0\n\n  '@typescript-eslint/utils@8.8.1':\n    resolution: {integrity: sha512-/QkNJDbV0bdL7H7d0/y0qBbV2HTtf0TIyjSDTvvmQEzeVx8jEImEbLuOA4EsvE8gIgqMitns0ifb5uQhMj8d9w==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      eslint: ^8.57.0 || ^9.0.0\n\n  '@typescript-eslint/utils@8.9.0':\n    resolution: {integrity: sha512-PKgMmaSo/Yg/F7kIZvrgrWa1+Vwn036CdNUvYFEkYbPwOH4i8xvkaRlu148W3vtheWK9ckKRIz7PBP5oUlkrvQ==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    peerDependencies:\n      eslint: ^8.57.0 || ^9.0.0\n\n  '@typescript-eslint/visitor-keys@5.62.0':\n    resolution: {integrity: sha512-07ny+LHRzQXepkGg6w0mFY41fVUNBrL2Roj/++7V1txKugfjm/Ci/qSND03r2RhlJhJYMcTn9AhhSSqQp0Ysyw==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  '@typescript-eslint/visitor-keys@7.18.0':\n    resolution: {integrity: sha512-cDF0/Gf81QpY3xYyJKDV14Zwdmid5+uuENhjH2EqFaF0ni+yAyq/LzMaIJdhNJXZI7uLzwIlA+V7oWoyn6Curg==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n\n  '@typescript-eslint/visitor-keys@8.8.1':\n    resolution: {integrity: sha512-0/TdC3aeRAsW7MDvYRwEc1Uwm0TIBfzjPFgg60UU2Haj5qsCs9cc3zNgY71edqE3LbWfF/WoZQd3lJoDXFQpag==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@typescript-eslint/visitor-keys@8.9.0':\n    resolution: {integrity: sha512-Ht4y38ubk4L5/U8xKUBfKNYGmvKvA1CANoxiTRMM+tOLk3lbF3DvzZCxJCRSE+2GdCMSh6zq9VZJc3asc1XuAA==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  '@ungap/promise-all-settled@1.1.2':\n    resolution: {integrity: sha512-sL/cEvJWAnClXw0wHk85/2L0G6Sj8UB0Ctc1TEMbKSsmpRosqhwj9gWgFRZSrBr2f9tiXISwNhCPmlfqUqyb9Q==}\n\n  '@ungap/structured-clone@1.2.0':\n    resolution: {integrity: sha512-zuVdFrMJiuCDQUMCzQaD6KL28MjnqqN8XnAqiEq9PNm/hCPTSGfrXCOfwj1ow4LFb/tNymJPwsNbVePc1xFqrQ==}\n\n  '@unhead/dom@1.11.10':\n    resolution: {integrity: sha512-nL1mdRzYVATZIYauK15zOI2YyM3YxCLfhbTqljEjDFJeiJUzTTi+a//5FHiUk84ewSucFnrwHNey/pEXFlyY1A==}\n\n  '@unhead/schema@1.11.10':\n    resolution: {integrity: sha512-lXh7cm5XtFaw3gc+ZVXTSfIHXiBpAywbjtEiOsz5TR4GxOjj2rtfOAl4C3Difk1yupP6L2otYmOZdn/i8EXSJg==}\n\n  '@unhead/shared@1.11.10':\n    resolution: {integrity: sha512-YQgZcOyo1id7drUeDPGn0R83pirvIcV+Car3/m7ZfCLL1Syab6uXmRckVRd69yVbUL4eirIm9IzzmvzM/OuGuw==}\n\n  '@unhead/vue@1.11.10':\n    resolution: {integrity: sha512-v6ddp4YEQCNILhYrx37Yt0GKRIFeTrb3VSmTbjh+URT+ua1mwgmNFTfl2ZldtTtri3tEkwSG1/5wLRq20ma70g==}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@urql/core@5.0.6':\n    resolution: {integrity: sha512-38rgSDqVNihFDauw1Pm9V7XLWIKuK8V9CKgrUF7/xEKinze8ENKP1ZeBhkG+dxWzJan7CHK+SLl46kAdvZwIlA==}\n\n  '@urql/devtools@2.0.3':\n    resolution: {integrity: sha512-TktPLiBS9LcBPHD6qcnb8wqOVcg3Bx0iCtvQ80uPpfofwwBGJmqnQTjUdEFU6kwaLOFZULQ9+Uo4831G823mQw==}\n    peerDependencies:\n      '@urql/core': '>= 1.14.0'\n      graphql: '>= 0.11.0'\n\n  '@urql/exchange-auth@2.2.0':\n    resolution: {integrity: sha512-4bJR22EYa/flbhwMBj4lU8MI4cO3ddo/DX7FygWeaeHZU+RWfnQKifCKwxIYlnoV8/CgYRM4lFSMIByYlhmWcg==}\n    peerDependencies:\n      '@urql/core': ^5.0.0\n\n  '@urql/exchange-graphcache@6.5.1':\n    resolution: {integrity: sha512-Ky77kuaTuo1H+VKZatXyNDqTMw+z03KV3Ep/6TQjktlc+0RDhEZq3rI4F/ViwqLaDUtGqPCYjmnHdoupXqdK0g==}\n\n  '@urql/exchange-graphcache@7.2.0':\n    resolution: {integrity: sha512-NPSfcHyhZnqTuu2OtBTS0b80YMQe1fOEpECZWyRd1A4WSfU/BJjsNSI/AXnG7ABGGCMtLvfTWRSlzsoLwPjwlQ==}\n    peerDependencies:\n      '@urql/core': ^5.0.0\n\n  '@urql/introspection@0.3.3':\n    resolution: {integrity: sha512-tekSLLqWnusfV6V7xaEnLJQSdXOD/lWy7f8JYQwrX+88Md+voGSCSx5WJXI7KLBN3Tat2OV08tAr8UROykls4Q==}\n    peerDependencies:\n      graphql: ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  '@urql/vue@1.4.0':\n    resolution: {integrity: sha512-Ufd6okpdqiS0MVS8nA7jdjUKFb24hNIQxAzNbHX2xnFF5UYOaRahFmlbYiquLE6TeJx3PCOrhpgb+gFHAI+MZg==}\n    peerDependencies:\n      '@urql/core': ^5.0.0\n      vue: 3.5.12\n\n  '@vitejs/plugin-legacy@2.3.0':\n    resolution: {integrity: sha512-Bh62i0gzQvvT8AeAAb78nOnqSYXypkRmQmOTImdPZ39meHR9e2une3AIFmVo4s1SDmcmJ6qj18Sa/lRc/14KaA==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n    peerDependencies:\n      terser: ^5.4.0\n      vite: ^3.0.0\n\n  '@vitejs/plugin-legacy@5.4.2':\n    resolution: {integrity: sha512-hlyyQL+wEIyOWdwsUKX+0g3kBU4AbHmVzHarLvVKiGGGqLIYjttMvvjk6zGY8RD9dab6QuFNhDoxg0YFhQ26xA==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    peerDependencies:\n      terser: ^5.4.0\n      vite: ^5.0.0\n\n  '@vitejs/plugin-vue@4.3.1':\n    resolution: {integrity: sha512-tUBEtWcF7wFtII7ayNiLNDTCE1X1afySEo+XNVMNkFXaThENyCowIEX095QqbJZGTgoOcSVDJGlnde2NG4jtbQ==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n    peerDependencies:\n      vite: ^4.0.0\n      vue: 3.5.12\n\n  '@vitejs/plugin-vue@5.1.4':\n    resolution: {integrity: sha512-N2XSI2n3sQqp5w7Y/AN/L2XDjBIRGqXko+eDp42sydYSBeJuSm5a1sLf8zakmo8u7tA8NmBgoDLA1HeOESjp9A==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    peerDependencies:\n      vite: ^5.0.0\n      vue: 3.5.12\n\n  '@vitest/expect@2.1.2':\n    resolution: {integrity: sha512-FEgtlN8mIUSEAAnlvn7mP8vzaWhEaAEvhSXCqrsijM7K6QqjB11qoRZYEd4AKSCDz8p0/+yH5LzhZ47qt+EyPg==}\n\n  '@vitest/expect@2.1.3':\n    resolution: {integrity: sha512-SNBoPubeCJhZ48agjXruCI57DvxcsivVDdWz+SSsmjTT4QN/DfHk3zB/xKsJqMs26bLZ/pNRLnCf0j679i0uWQ==}\n\n  '@vitest/mocker@2.1.2':\n    resolution: {integrity: sha512-ExElkCGMS13JAJy+812fw1aCv2QO/LBK6CyO4WOPAzLTmve50gydOlWhgdBJPx2ztbADUq3JVI0C5U+bShaeEA==}\n    peerDependencies:\n      '@vitest/spy': 2.1.2\n      msw: ^2.3.5\n      vite: ^5.0.0\n    peerDependenciesMeta:\n      msw:\n        optional: true\n      vite:\n        optional: true\n\n  '@vitest/mocker@2.1.3':\n    resolution: {integrity: sha512-eSpdY/eJDuOvuTA3ASzCjdithHa+GIF1L4PqtEELl6Qa3XafdMLBpBlZCIUCX2J+Q6sNmjmxtosAG62fK4BlqQ==}\n    peerDependencies:\n      '@vitest/spy': 2.1.3\n      msw: ^2.3.5\n      vite: ^5.0.0\n    peerDependenciesMeta:\n      msw:\n        optional: true\n      vite:\n        optional: true\n\n  '@vitest/pretty-format@2.1.2':\n    resolution: {integrity: sha512-FIoglbHrSUlOJPDGIrh2bjX1sNars5HbxlcsFKCtKzu4+5lpsRhOCVcuzp0fEhAGHkPZRIXVNzPcpSlkoZ3LuA==}\n\n  '@vitest/pretty-format@2.1.3':\n    resolution: {integrity: sha512-XH1XdtoLZCpqV59KRbPrIhFCOO0hErxrQCMcvnQete3Vibb9UeIOX02uFPfVn3Z9ZXsq78etlfyhnkmIZSzIwQ==}\n\n  '@vitest/runner@2.1.2':\n    resolution: {integrity: sha512-UCsPtvluHO3u7jdoONGjOSil+uON5SSvU9buQh3lP7GgUXHp78guN1wRmZDX4wGK6J10f9NUtP6pO+SFquoMlw==}\n\n  '@vitest/runner@2.1.3':\n    resolution: {integrity: sha512-JGzpWqmFJ4fq5ZKHtVO3Xuy1iF2rHGV4d/pdzgkYHm1+gOzNZtqjvyiaDGJytRyMU54qkxpNzCx+PErzJ1/JqQ==}\n\n  '@vitest/snapshot@2.1.2':\n    resolution: {integrity: sha512-xtAeNsZ++aRIYIUsek7VHzry/9AcxeULlegBvsdLncLmNCR6tR8SRjn8BbDP4naxtccvzTqZ+L1ltZlRCfBZFA==}\n\n  '@vitest/snapshot@2.1.3':\n    resolution: {integrity: sha512-qWC2mWc7VAXmjAkEKxrScWHWFyCQx/cmiZtuGqMi+WwqQJ2iURsVY4ZfAK6dVo6K2smKRU6l3BPwqEBvhnpQGg==}\n\n  '@vitest/spy@2.1.2':\n    resolution: {integrity: sha512-GSUi5zoy+abNRJwmFhBDC0yRuVUn8WMlQscvnbbXdKLXX9dE59YbfwXxuJ/mth6eeqIzofU8BB5XDo/Ns/qK2A==}\n\n  '@vitest/spy@2.1.3':\n    resolution: {integrity: sha512-Nb2UzbcUswzeSP7JksMDaqsI43Sj5+Kry6ry6jQJT4b5gAK+NS9NED6mDb8FlMRCX8m5guaHCDZmqYMMWRy5nQ==}\n\n  '@vitest/utils@2.1.2':\n    resolution: {integrity: sha512-zMO2KdYy6mx56btx9JvAqAZ6EyS3g49krMPPrgOp1yxGZiA93HumGk+bZ5jIZtOg5/VBYl5eBmGRQHqq4FG6uQ==}\n\n  '@vitest/utils@2.1.3':\n    resolution: {integrity: sha512-xpiVfDSg1RrYT0tX6czgerkpcKFmFOF/gCr30+Mve5V2kewCy4Prn1/NDMSRwaSmT7PRaOF83wu+bEtsY1wrvA==}\n\n  '@volar/language-core@1.10.10':\n    resolution: {integrity: sha512-nsV1o3AZ5n5jaEAObrS3MWLBWaGwUj/vAsc15FVNIv+DbpizQRISg9wzygsHBr56ELRH8r4K75vkYNMtsSNNWw==}\n\n  '@volar/language-core@1.11.1':\n    resolution: {integrity: sha512-dOcNn3i9GgZAcJt43wuaEykSluAuOkQgzni1cuxLxTV0nJKanQztp7FxyswdRILaKH+P2XZMPRp2S4MV/pElCw==}\n\n  '@volar/language-core@2.4.5':\n    resolution: {integrity: sha512-F4tA0DCO5Q1F5mScHmca0umsi2ufKULAnMOVBfMsZdT4myhVl4WdKRwCaKcfOkIEuyrAVvtq1ESBdZ+rSyLVww==}\n\n  '@volar/source-map@1.10.10':\n    resolution: {integrity: sha512-GVKjLnifV4voJ9F0vhP56p4+F3WGf+gXlRtjFZsv6v3WxBTWU3ZVeaRaEHJmWrcv5LXmoYYpk/SC25BKemPRkg==}\n\n  '@volar/source-map@1.11.1':\n    resolution: {integrity: sha512-hJnOnwZ4+WT5iupLRnuzbULZ42L7BWWPMmruzwtLhJfpDVoZLjNBxHDi2sY2bgZXCKlpU5XcsMFoYrsQmPhfZg==}\n\n  '@volar/source-map@2.4.5':\n    resolution: {integrity: sha512-varwD7RaKE2J/Z+Zu6j3mNNJbNT394qIxXwdvz/4ao/vxOfyClZpSDtLKkwWmecinkOVos5+PWkWraelfMLfpw==}\n\n  '@volar/typescript@1.10.10':\n    resolution: {integrity: sha512-4a2r5bdUub2m+mYVnLu2wt59fuoYWe7nf0uXtGHU8QQ5LDNfzAR0wK7NgDiQ9rcl2WT3fxT2AA9AylAwFtj50A==}\n\n  '@volar/typescript@1.11.1':\n    resolution: {integrity: sha512-iU+t2mas/4lYierSnoFOeRFQUhAEMgsFuQxoxvwn5EdQopw43j+J27a4lt9LMInx1gLJBC6qL14WYGlgymaSMQ==}\n\n  '@volar/typescript@2.4.5':\n    resolution: {integrity: sha512-mcT1mHvLljAEtHviVcBuOyAwwMKz1ibXTi5uYtP/pf4XxoAzpdkQ+Br2IC0NPCvLCbjPZmbf3I0udndkfB1CDg==}\n\n  '@vue/compiler-core@3.5.12':\n    resolution: {integrity: sha512-ISyBTRMmMYagUxhcpyEH0hpXRd/KqDU4ymofPgl2XAkY9ZhQ+h0ovEZJIiPop13UmR/54oA2cgMDjgroRelaEw==}\n\n  '@vue/compiler-dom@3.5.12':\n    resolution: {integrity: sha512-9G6PbJ03uwxLHKQ3P42cMTi85lDRvGLB2rSGOiQqtXELat6uI4n8cNz9yjfVHRPIu+MsK6TE418Giruvgptckg==}\n\n  '@vue/compiler-sfc@3.5.12':\n    resolution: {integrity: sha512-2k973OGo2JuAa5+ZlekuQJtitI5CgLMOwgl94BzMCsKZCX/xiqzJYzapl4opFogKHqwJk34vfsaKpfEhd1k5nw==}\n\n  '@vue/compiler-ssr@3.5.12':\n    resolution: {integrity: sha512-eLwc7v6bfGBSM7wZOGPmRavSWzNFF6+PdRhE+VFJhNCgHiF8AM7ccoqcv5kBXA2eWUfigD7byekvf/JsOfKvPA==}\n\n  '@vue/compiler-vue2@2.7.16':\n    resolution: {integrity: sha512-qYC3Psj9S/mfu9uVi5WvNZIzq+xnXMhOwbTFKKDD7b1lhpnn71jXSFdTQ+WsIEk0ONCd7VV2IMm7ONl6tbQ86A==}\n\n  '@vue/devtools-api@6.6.4':\n    resolution: {integrity: sha512-sGhTPMuXqZ1rVOk32RylztWkfXTRhuS7vgAKv0zjqk8gbsHkJ7xfFf+jbySxt7tWObEJwyKaHMikV/WGDiQm8g==}\n\n  '@vue/eslint-config-typescript@11.0.3':\n    resolution: {integrity: sha512-dkt6W0PX6H/4Xuxg/BlFj5xHvksjpSlVjtkQCpaYJBIEuKj2hOVU7r+TIe+ysCwRYFz/lGqvklntRkCAibsbPw==}\n    engines: {node: ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.2.0 || ^7.0.0 || ^8.0.0\n      eslint-plugin-vue: ^9.0.0\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@vue/eslint-config-typescript@13.0.0':\n    resolution: {integrity: sha512-MHh9SncG/sfqjVqjcuFLOLD6Ed4dRAis4HNt0dXASeAuLqIAx4YMB1/m2o4pUKK1vCt8fUvYG8KKX2Ot3BVZTg==}\n    engines: {node: ^18.18.0 || >=20.0.0}\n    peerDependencies:\n      eslint: ^8.56.0\n      eslint-plugin-vue: ^9.0.0\n      typescript: '>=4.7.4'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@vue/language-core@1.8.24':\n    resolution: {integrity: sha512-2ClHvij0WlsDWryPzXJCSpPc6rusZFNoVtRZGgGGkKCmKuIREDDKmH8j+1tYyxPYyH0qL6pZ6+IHD8KIm5nWAw==}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@vue/language-core@1.8.8':\n    resolution: {integrity: sha512-i4KMTuPazf48yMdYoebTkgSOJdFraE4pQf0B+FTOFkbB+6hAfjrSou/UmYWRsWyZV6r4Rc6DDZdI39CJwL0rWw==}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@vue/language-core@2.1.6':\n    resolution: {integrity: sha512-MW569cSky9R/ooKMh6xa2g1D0AtRKbL56k83dzus/bx//RDJk24RHWkMzbAlXjMdDNyxAaagKPRquBIxkxlCkg==}\n    peerDependencies:\n      typescript: '*'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  '@vue/reactivity@3.5.11':\n    resolution: {integrity: sha512-Nqo5VZEn8MJWlCce8XoyVqHZbd5P2NH+yuAaFzuNSR96I+y1cnuUiq7xfSG+kyvLSiWmaHTKP1r3OZY4mMD50w==}\n\n  '@vue/reactivity@3.5.12':\n    resolution: {integrity: sha512-UzaN3Da7xnJXdz4Okb/BGbAaomRHc3RdoWqTzlvd9+WBR5m3J39J1fGcHes7U3za0ruYn/iYy/a1euhMEHvTAg==}\n\n  '@vue/runtime-core@3.5.12':\n    resolution: {integrity: sha512-hrMUYV6tpocr3TL3Ad8DqxOdpDe4zuQY4HPY3X/VRh+L2myQO8MFXPAMarIOSGNu0bFAjh1yBkMPXZBqCk62Uw==}\n\n  '@vue/runtime-dom@3.5.12':\n    resolution: {integrity: sha512-q8VFxR9A2MRfBr6/55Q3umyoN7ya836FzRXajPB6/Vvuv0zOPL+qltd9rIMzG/DbRLAIlREmnLsplEF/kotXKA==}\n\n  '@vue/server-renderer@3.5.12':\n    resolution: {integrity: sha512-I3QoeDDeEPZm8yR28JtY+rk880Oqmj43hreIBVTicisFTx/Dl7JpG72g/X7YF8hnQD3IFhkky5i2bPonwrTVPg==}\n    peerDependencies:\n      vue: 3.5.12\n\n  '@vue/shared@3.5.11':\n    resolution: {integrity: sha512-W8GgysJVnFo81FthhzurdRAWP/byq3q2qIw70e0JWblzVhjgOMiC2GyovXrZTFQJnFVryYaKGP3Tc9vYzYm6PQ==}\n\n  '@vue/shared@3.5.12':\n    resolution: {integrity: sha512-L2RPSAwUFbgZH20etwrXyVyCBu9OxRSi8T/38QsvnkJyvq2LufW2lDCOzm7t/U9C1mkhJGWYfCuFBCmIuNivrg==}\n\n  '@vue/typescript@1.8.8':\n    resolution: {integrity: sha512-jUnmMB6egu5wl342eaUH236v8tdcEPXXkPgj+eI/F6JwW/lb+yAU6U07ZbQ3MVabZRlupIlPESB7ajgAGixhow==}\n\n  '@vueuse/core@10.5.0':\n    resolution: {integrity: sha512-z/tI2eSvxwLRjOhDm0h/SXAjNm8N5ld6/SC/JQs6o6kpJ6Ya50LnEL8g5hoYu005i28L0zqB5L5yAl8Jl26K3A==}\n\n  '@vueuse/core@11.1.0':\n    resolution: {integrity: sha512-P6dk79QYA6sKQnghrUz/1tHi0n9mrb/iO1WTMk/ElLmTyNqgDeSZ3wcDf6fRBGzRJbeG1dxzEOvLENMjr+E3fg==}\n\n  '@vueuse/core@8.9.4':\n    resolution: {integrity: sha512-B/Mdj9TK1peFyWaPof+Zf/mP9XuGAngaJZBwPaXBvU3aCTZlx3ltlrFFFyMV4iGBwsjSCeUCgZrtkEj9dS2Y3Q==}\n    peerDependencies:\n      '@vue/composition-api': ^1.1.0\n      vue: 3.5.12\n    peerDependenciesMeta:\n      '@vue/composition-api':\n        optional: true\n      vue:\n        optional: true\n\n  '@vueuse/metadata@10.5.0':\n    resolution: {integrity: sha512-fEbElR+MaIYyCkeM0SzWkdoMtOpIwO72x8WsZHRE7IggiOlILttqttM69AS13nrDxosnDBYdyy3C5mR1LCxHsw==}\n\n  '@vueuse/metadata@11.1.0':\n    resolution: {integrity: sha512-l9Q502TBTaPYGanl1G+hPgd3QX5s4CGnpXriVBR5fEZ/goI6fvDaVmIl3Td8oKFurOxTmbXvBPSsgrd6eu6HYg==}\n\n  '@vueuse/metadata@8.9.4':\n    resolution: {integrity: sha512-IwSfzH80bnJMzqhaapqJl9JRIiyQU0zsRGEgnxN6jhq7992cPUJIRfV+JHRIZXjYqbwt07E1gTEp0R0zPJ1aqw==}\n\n  '@vueuse/shared@10.5.0':\n    resolution: {integrity: sha512-18iyxbbHYLst9MqU1X1QNdMHIjks6wC7XTVf0KNOv5es/Ms6gjVFCAAWTVP2JStuGqydg3DT+ExpFORUEi9yhg==}\n\n  '@vueuse/shared@11.1.0':\n    resolution: {integrity: sha512-YUtIpY122q7osj+zsNMFAfMTubGz0sn5QzE5gPzAIiCmtt2ha3uQUY1+JPyL4gRCTsLPX82Y9brNbo/aqlA91w==}\n\n  '@vueuse/shared@8.9.4':\n    resolution: {integrity: sha512-wt+T30c4K6dGRMVqPddexEVLa28YwxW5OFIPmzUHICjphfAuBFTTdDoyqREZNDOFJZ44ARH1WWQNCUK8koJ+Ag==}\n    peerDependencies:\n      '@vue/composition-api': ^1.1.0\n      vue: 3.5.12\n    peerDependenciesMeta:\n      '@vue/composition-api':\n        optional: true\n      vue:\n        optional: true\n\n  '@webassemblyjs/ast@1.12.1':\n    resolution: {integrity: sha512-EKfMUOPRRUTy5UII4qJDGPpqfwjOmZ5jeGFwid9mnoqIFK+e0vqoi1qH56JpmZSzEL53jKnNzScdmftJyG5xWg==}\n\n  '@webassemblyjs/floating-point-hex-parser@1.11.6':\n    resolution: {integrity: sha512-ejAj9hfRJ2XMsNHk/v6Fu2dGS+i4UaXBXGemOfQ/JfQ6mdQg/WXtwleQRLLS4OvfDhv8rYnVwH27YJLMyYsxhw==}\n\n  '@webassemblyjs/helper-api-error@1.11.6':\n    resolution: {integrity: sha512-o0YkoP4pVu4rN8aTJgAyj9hC2Sv5UlkzCHhxqWj8butaLvnpdc2jOwh4ewE6CX0txSfLn/UYaV/pheS2Txg//Q==}\n\n  '@webassemblyjs/helper-buffer@1.12.1':\n    resolution: {integrity: sha512-nzJwQw99DNDKr9BVCOZcLuJJUlqkJh+kVzVl6Fmq/tI5ZtEyWT1KZMyOXltXLZJmDtvLCDgwsyrkohEtopTXCw==}\n\n  '@webassemblyjs/helper-numbers@1.11.6':\n    resolution: {integrity: sha512-vUIhZ8LZoIWHBohiEObxVm6hwP034jwmc9kuq5GdHZH0wiLVLIPcMCdpJzG4C11cHoQ25TFIQj9kaVADVX7N3g==}\n\n  '@webassemblyjs/helper-wasm-bytecode@1.11.6':\n    resolution: {integrity: sha512-sFFHKwcmBprO9e7Icf0+gddyWYDViL8bpPjJJl0WHxCdETktXdmtWLGVzoHbqUcY4Be1LkNfwTmXOJUFZYSJdA==}\n\n  '@webassemblyjs/helper-wasm-section@1.12.1':\n    resolution: {integrity: sha512-Jif4vfB6FJlUlSbgEMHUyk1j234GTNG9dBJ4XJdOySoj518Xj0oGsNi59cUQF4RRMS9ouBUxDDdyBVfPTypa5g==}\n\n  '@webassemblyjs/ieee754@1.11.6':\n    resolution: {integrity: sha512-LM4p2csPNvbij6U1f19v6WR56QZ8JcHg3QIJTlSwzFcmx6WSORicYj6I63f9yU1kEUtrpG+kjkiIAkevHpDXrg==}\n\n  '@webassemblyjs/leb128@1.11.6':\n    resolution: {integrity: sha512-m7a0FhE67DQXgouf1tbN5XQcdWoNgaAuoULHIfGFIEVKA6tu/edls6XnIlkmS6FrXAquJRPni3ZZKjw6FSPjPQ==}\n\n  '@webassemblyjs/utf8@1.11.6':\n    resolution: {integrity: sha512-vtXf2wTQ3+up9Zsg8sa2yWiQpzSsMyXj0qViVP6xKGCUT8p8YJ6HqI7l5eCnWx1T/FYdsv07HQs2wTFbbof/RA==}\n\n  '@webassemblyjs/wasm-edit@1.12.1':\n    resolution: {integrity: sha512-1DuwbVvADvS5mGnXbE+c9NfA8QRcZ6iKquqjjmR10k6o+zzsRVesil54DKexiowcFCPdr/Q0qaMgB01+SQ1u6g==}\n\n  '@webassemblyjs/wasm-gen@1.12.1':\n    resolution: {integrity: sha512-TDq4Ojh9fcohAw6OIMXqiIcTq5KUXTGRkVxbSo1hQnSy6lAM5GSdfwWeSxpAo0YzgsgF182E/U0mDNhuA0tW7w==}\n\n  '@webassemblyjs/wasm-opt@1.12.1':\n    resolution: {integrity: sha512-Jg99j/2gG2iaz3hijw857AVYekZe2SAskcqlWIZXjji5WStnOpVoat3gQfT/Q5tb2djnCjBtMocY/Su1GfxPBg==}\n\n  '@webassemblyjs/wasm-parser@1.12.1':\n    resolution: {integrity: sha512-xikIi7c2FHXysxXe3COrVUPSheuBtpcfhbpFj4gmu7KRLYOzANztwUU0IbsqvMqzuNK2+glRGWCEqZo1WCLyAQ==}\n\n  '@webassemblyjs/wast-printer@1.12.1':\n    resolution: {integrity: sha512-+X4WAlOisVWQMikjbcvY2e0rwPsKQ9F688lksZhBcPycBBuii3O7m8FACbDMWDojpAqvjIncrG8J0XHKyQfVeA==}\n\n  '@whatwg-node/events@0.0.3':\n    resolution: {integrity: sha512-IqnKIDWfXBJkvy/k6tzskWTc2NK3LcqHlb+KHGCrjOCH4jfQckRX0NAiIcC/vIqQkzLYw2r2CTSwAxcrtcD6lA==}\n\n  '@whatwg-node/fetch@0.8.8':\n    resolution: {integrity: sha512-CdcjGC2vdKhc13KKxgsc6/616BQ7ooDIgPeTuAiE8qfCnS0mGzcfCOoZXypQSz73nxI+GWc7ZReIAVhxoE1KCg==}\n\n  '@whatwg-node/fetch@0.9.21':\n    resolution: {integrity: sha512-Wt0jPb+04JjobK0pAAN7mEHxVHcGA9HoP3OyCsZtyAecNQeADXCZ1MihFwVwjsgaRYuGVmNlsCmLxlG6mor8Gw==}\n    engines: {node: '>=18.0.0'}\n\n  '@whatwg-node/node-fetch@0.3.6':\n    resolution: {integrity: sha512-w9wKgDO4C95qnXZRwZTfCmLWqyRnooGjcIwG0wADWjw9/HN0p7dtvtgSvItZtUyNteEvgTrd8QojNEqV6DAGTA==}\n\n  '@whatwg-node/node-fetch@0.5.26':\n    resolution: {integrity: sha512-4jXDeZ4IH4bylZ6wu14VEx0aDXXhrN4TC279v9rPmn08g4EYekcYf8wdcOOnS9STjDkb6x77/6xBUTqxGgjr8g==}\n    engines: {node: '>=18.0.0'}\n\n  '@xtuc/ieee754@1.2.0':\n    resolution: {integrity: sha512-DX8nKgqcGwsc0eJSqYt5lwP4DH5FlHnmuWWBRy7X0NcaGR0ZtuyeESgMwTYVEtxmsNGY+qit4QYT/MIYTOTPeA==}\n\n  '@xtuc/long@4.2.2':\n    resolution: {integrity: sha512-NuHqBY1PB/D8xU6s/thBgOAiAP7HOYDQ32+BFZILJ8ivkUkAHQnWfn6WhL79Owj1qmUnoN/YPhktdIoucipkAQ==}\n\n  JSONStream@1.3.5:\n    resolution: {integrity: sha512-E+iruNOY8VV9s4JEbe1aNEm6MiszPRr/UfcHMz0TQh1BXSxHK+ASV1R6W4HpjBhSeS+54PIsAMCBmwD06LLsqQ==}\n    hasBin: true\n\n  abbrev@1.1.1:\n    resolution: {integrity: sha512-nne9/IiQ/hzIhY6pdDnbBtz7DjPTKrY00P/zvPSm5pOFkl6xuGrGnXn/VtTNNfNtAfZ9/1RtehkszU9qcTii0Q==}\n\n  abort-controller@3.0.0:\n    resolution: {integrity: sha512-h8lQ8tacZYnR3vNQTgibj+tODHI5/+l06Au2Pcriv/Gmet0eaj4TwWH41sO9wnHDiQsEj19q0drzdWdeAHtweg==}\n    engines: {node: '>=6.5'}\n\n  accepts@1.3.8:\n    resolution: {integrity: sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==}\n    engines: {node: '>= 0.6'}\n\n  acorn-import-attributes@1.9.5:\n    resolution: {integrity: sha512-n02Vykv5uA3eHGM/Z2dQrcD56kL8TyDb2p1+0P83PClMnC/nc+anbQRhIOWnSq4Ke/KvDPrY3C9hDtC/A3eHnQ==}\n    peerDependencies:\n      acorn: ^8\n\n  acorn-jsx@5.3.2:\n    resolution: {integrity: sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==}\n    peerDependencies:\n      acorn: ^6.0.0 || ^7.0.0 || ^8.0.0\n\n  acorn-loose@6.1.0:\n    resolution: {integrity: sha512-FHhXoiF0Uch3IqsrnPpWwCtiv5PYvipTpT1k9lDMgQVVYc9iDuSl5zdJV358aI8twfHCYMFBRVYvAVki9wC/ng==}\n    engines: {node: '>=0.4.0'}\n\n  acorn-walk@6.2.0:\n    resolution: {integrity: sha512-7evsyfH1cLOCdAzZAd43Cic04yKydNx0cF+7tiA19p1XnLLPU4dpCQOqpjqwokFe//vS0QqfqqjCS2JkiIs0cA==}\n    engines: {node: '>=0.4.0'}\n\n  acorn-walk@8.3.4:\n    resolution: {integrity: sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==}\n    engines: {node: '>=0.4.0'}\n\n  acorn@6.4.2:\n    resolution: {integrity: sha512-XtGIhXwF8YM8bJhGxG5kXgjkEuNGLTkoYqVE+KMR+aspr4KGYmKYg7yUe3KghyQ9yheNwLnjmzh/7+gfDBmHCQ==}\n    engines: {node: '>=0.4.0'}\n    hasBin: true\n\n  acorn@7.4.1:\n    resolution: {integrity: sha512-nQyp0o1/mNdbTO1PO6kHkwSrmgZ0MT/jCCpNiwbUjGoRN4dlBhqJtoQuCnEOKzgTVwg0ZWiCoQy6SxMebQVh8A==}\n    engines: {node: '>=0.4.0'}\n    hasBin: true\n\n  acorn@8.12.1:\n    resolution: {integrity: sha512-tcpGyI9zbizT9JbV6oYE477V6mTlXvvi0T0G3SNIYE2apm/G5huBa1+K89VGeovbg+jycCrfhl3ADxErOuO6Jg==}\n    engines: {node: '>=0.4.0'}\n    hasBin: true\n\n  after@0.8.2:\n    resolution: {integrity: sha512-QbJ0NTQ/I9DI3uSJA4cbexiwQeRAfjPScqIbSjUDd9TOrcg6pTkdgziesOqxBMBzit8vFCTwrP27t13vFOORRA==}\n\n  agent-base@6.0.2:\n    resolution: {integrity: sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==}\n    engines: {node: '>= 6.0.0'}\n\n  agent-base@7.1.1:\n    resolution: {integrity: sha512-H0TSyFNDMomMNJQBn8wFV5YC/2eJ+VXECwOadZJT554xP6cODZHPX3H9QMQECxvrgiSOP1pHjy1sMWQVYJOUOA==}\n    engines: {node: '>= 14'}\n\n  aggregate-error@3.1.0:\n    resolution: {integrity: sha512-4I7Td01quW/RpocfNayFdFVk1qSuoh0E7JrbRJ16nH01HhKFQ88INq9Sd+nd72zqRySlr9BmDA8xlEJ6vJMrYA==}\n    engines: {node: '>=8'}\n\n  ajv-draft-04@1.0.0:\n    resolution: {integrity: sha512-mv00Te6nmYbRp5DCwclxtt7yV/joXJPGS7nM+97GdxvuttCOfgI3K4U25zboyeX0O+myI8ERluxQe5wljMmVIw==}\n    peerDependencies:\n      ajv: ^8.5.0\n    peerDependenciesMeta:\n      ajv:\n        optional: true\n\n  ajv-formats@2.1.1:\n    resolution: {integrity: sha512-Wx0Kx52hxE7C18hkMEggYlEifqWZtYaRgouJor+WMdPnQyEK13vgEWyVNup7SoeeoLMsr4kf5h6dOW11I15MUA==}\n    peerDependencies:\n      ajv: ^8.0.0\n    peerDependenciesMeta:\n      ajv:\n        optional: true\n\n  ajv-keywords@3.5.2:\n    resolution: {integrity: sha512-5p6WTN0DdTGVQk6VjcEju19IgaHudalcfabD7yhDGeA6bcQnmL+CpveLJq/3hvfwd1aof6L386Ougkx6RfyMIQ==}\n    peerDependencies:\n      ajv: ^6.9.1\n\n  ajv@6.12.3:\n    resolution: {integrity: sha512-4K0cK3L1hsqk9xIb2z9vs/XU+PGJZ9PNpJRDS9YLzmNdX6jmVPfamLvTJr0aDAusnHyCHO6MjzlkAsgtqp9teA==}\n\n  ajv@6.12.6:\n    resolution: {integrity: sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==}\n\n  ajv@8.12.0:\n    resolution: {integrity: sha512-sRu1kpcO9yLtYxBKvqfTeh9KzZEwO3STyX1HT+4CaDzC6HpTGYhIhPIzj9XuKU7KYDwnaeh5hcOwjy1QuJzBPA==}\n\n  ajv@8.13.0:\n    resolution: {integrity: sha512-PRA911Blj99jR5RMeTunVbNXMF6Lp4vZXnk5GQjcnUWUTsrXtekg/pnmFFI2u/I36Y/2bITGS30GZCXei6uNkA==}\n\n  ajv@8.17.1:\n    resolution: {integrity: sha512-B/gBuNg5SiMTrPkC+A2+cW0RszwxYmn6VYxB/inlBStS5nx6xHIt/ehKRhIMhqusl7a8LjQoZnjCs5vhwxOQ1g==}\n\n  alce@1.2.0:\n    resolution: {integrity: sha512-XppPf2S42nO2WhvKzlwzlfcApcXHzjlod30pKmcWjRgLOtqoe5DMuqdiYoM6AgyXksc6A6pV4v1L/WW217e57w==}\n    engines: {node: '>=0.8.0'}\n\n  ansi-align@3.0.1:\n    resolution: {integrity: sha512-IOfwwBF5iczOjp/WeY4YxyjqAFMQoZufdQWDd19SEExbVLNXqvpzSJ/M7Za4/sCPmQ0+GRquoA7bGcINcxew6w==}\n\n  ansi-colors@4.1.1:\n    resolution: {integrity: sha512-JoX0apGbHaUJBNl6yF+p6JAFYZ666/hhCGKN5t9QFjbJQKUU/g8MNbFDbvfrgKXvI1QpZplPOnwIo99lX/AAmA==}\n    engines: {node: '>=6'}\n\n  ansi-colors@4.1.3:\n    resolution: {integrity: sha512-/6w/C21Pm1A7aZitlI5Ni/2J6FFQN8i1Cvz3kHABAAbw93v/NlvKdVOqz7CCWz/3iv/JplRSEEZ83XION15ovw==}\n    engines: {node: '>=6'}\n\n  ansi-escapes@4.3.2:\n    resolution: {integrity: sha512-gKXj5ALrKWQLsYG9jlTRmR/xKluxHV+Z9QEwNIgCfM1/uwPMCuzVVnh5mwTd+OuBZcwSIMbqssNWRm1lE51QaQ==}\n    engines: {node: '>=8'}\n\n  ansi-escapes@7.0.0:\n    resolution: {integrity: sha512-GdYO7a61mR0fOlAsvC9/rIHf7L96sBc6dEWzeOu+KAea5bZyQRPIpojrVoI4AXGJS/ycu/fBTdLrUkA4ODrvjw==}\n    engines: {node: '>=18'}\n\n  ansi-regex@5.0.1:\n    resolution: {integrity: sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==}\n    engines: {node: '>=8'}\n\n  ansi-regex@6.1.0:\n    resolution: {integrity: sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==}\n    engines: {node: '>=12'}\n\n  ansi-styles@3.2.1:\n    resolution: {integrity: sha512-VT0ZI6kZRdTh8YyJw3SMbYm/u+NqfsAxEpWO0Pf9sq8/e94WxxOpPKx9FR1FlyCtOVDNOQ+8ntlqFxiRc+r5qA==}\n    engines: {node: '>=4'}\n\n  ansi-styles@4.3.0:\n    resolution: {integrity: sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==}\n    engines: {node: '>=8'}\n\n  ansi-styles@5.2.0:\n    resolution: {integrity: sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==}\n    engines: {node: '>=10'}\n\n  ansi-styles@6.2.1:\n    resolution: {integrity: sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==}\n    engines: {node: '>=12'}\n\n  any-promise@1.3.0:\n    resolution: {integrity: sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==}\n\n  anymatch@3.1.3:\n    resolution: {integrity: sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==}\n    engines: {node: '>= 8'}\n\n  apiconnect-wsdl@1.8.31:\n    resolution: {integrity: sha512-kNs26If9xCJnGolVTAt0VWIA8KrqwodQLqDRTrfc7txD54LJ+hFx638sPYEdG9jw78eifWyy+FBlS5befYSa8Q==}\n    engines: {node: '>=8'}\n\n  append-field@1.0.0:\n    resolution: {integrity: sha512-klpgFSWLW1ZEs8svjfb7g4qWY0YS5imI82dTg+QahUvJ8YqAY0P10Uk8tTyh9ZGuYEZEMaeJYCF5BFuX552hsw==}\n\n  aproba@2.0.0:\n    resolution: {integrity: sha512-lYe4Gx7QT+MKGbDsA+Z+he/Wtef0BiwDOlK/XkBrdfsh9J/jPPXbX0tE9x9cl27Tmu5gg3QUbUrQYa/y+KOHPQ==}\n\n  are-we-there-yet@2.0.0:\n    resolution: {integrity: sha512-Ci/qENmwHnsYo9xKIcUJN5LeDKdJ6R1Z1j9V/J5wyq8nh/mYPEpIKJbBZXtZjG04HiK7zV/p6Vs9952MrMeUIw==}\n    engines: {node: '>=10'}\n    deprecated: This package is no longer supported.\n\n  arg@4.1.3:\n    resolution: {integrity: sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==}\n\n  arg@5.0.2:\n    resolution: {integrity: sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==}\n\n  argon2@0.41.1:\n    resolution: {integrity: sha512-dqCW8kJXke8Ik+McUcMDltrbuAWETPyU6iq+4AhxqKphWi7pChB/Zgd/Tp/o8xRLbg8ksMj46F/vph9wnxpTzQ==}\n    engines: {node: '>=16.17.0'}\n\n  argparse@1.0.10:\n    resolution: {integrity: sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==}\n\n  argparse@2.0.1:\n    resolution: {integrity: sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==}\n\n  array-buffer-byte-length@1.0.1:\n    resolution: {integrity: sha512-ahC5W1xgou+KTXix4sAO8Ki12Q+jf4i0+tmk3sC+zgcynshkHxzpXdImBehiUYKKKDwvfFiJl1tZt6ewscS1Mg==}\n    engines: {node: '>= 0.4'}\n\n  array-flatten@1.1.1:\n    resolution: {integrity: sha512-PCVAQswWemu6UdxsDFFX/+gVeYqKAod3D3UVm91jHwynguOwAvYPhx8nNlM++NqRcK6CxxpUafjmhIdKiHibqg==}\n\n  array-ify@1.0.0:\n    resolution: {integrity: sha512-c5AMf34bKdvPhQ7tBGhqkgKNUzMr4WUs+WDtC2ZUGOUncbxKMTvqxYctiseW3+L4bA8ec+GcZ6/A/FW4m8ukng==}\n\n  array-timsort@1.0.3:\n    resolution: {integrity: sha512-/+3GRL7dDAGEfM6TseQk/U+mi18TU2Ms9I3UlLdUMhz2hbvGNTKdj9xniwXfUqgYhHxRx0+8UnKkvlNwVU+cWQ==}\n\n  array-union@2.1.0:\n    resolution: {integrity: sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==}\n    engines: {node: '>=8'}\n\n  arraybuffer.prototype.slice@1.0.3:\n    resolution: {integrity: sha512-bMxMKAjg13EBSVscxTaYA4mRc5t1UAXa2kXiGTNfZ079HIWXEkKmkgFrh/nJqamaLSrXO5H4WFFkPEaLJWbs3A==}\n    engines: {node: '>= 0.4'}\n\n  arraybuffer.slice@0.0.7:\n    resolution: {integrity: sha512-wGUIVQXuehL5TCqQun8OW81jGzAWycqzFF8lFp+GOM5BXLYj3bKNsYC4daB7n6XjCqxQA/qgTJ+8ANR3acjrog==}\n\n  asap@2.0.6:\n    resolution: {integrity: sha512-BSHWgDSAiKs50o2Re8ppvp3seVHXSRM44cdSsT9FfNEUUZLOGWVCsiWaRPWM1Znn+mqZ1OfVZ3z3DWEzSp7hRA==}\n\n  asn1js@3.0.5:\n    resolution: {integrity: sha512-FVnvrKJwpt9LP2lAMl8qZswRNm3T4q9CON+bxldk2iwk3FFpuwhx2FfinyitizWHsVYyaY+y5JzDR0rCMV5yTQ==}\n    engines: {node: '>=12.0.0'}\n\n  assert-never@1.3.0:\n    resolution: {integrity: sha512-9Z3vxQ+berkL/JJo0dK+EY3Lp0s3NtSnP3VCLsh5HDcZPrh0M+KQRK5sWhUeyPPH+/RCxZqOxLMR+YC6vlviEQ==}\n\n  assertion-error@2.0.1:\n    resolution: {integrity: sha512-Izi8RQcffqCeNVgFigKli1ssklIbpHnCYc6AknXGYoB6grJqyeby7jv12JUQgmTAnIDnbck1uxksT4dzN3PWBA==}\n    engines: {node: '>=12'}\n\n  astral-regex@2.0.0:\n    resolution: {integrity: sha512-Z7tMw1ytTXt5jqMcOP+OQteU1VuNK9Y02uuJtKQ1Sv69jXQKKg5cibLwGJow8yzZP+eAc18EmLGPal0bp36rvQ==}\n    engines: {node: '>=8'}\n\n  async-retry@1.3.3:\n    resolution: {integrity: sha512-wfr/jstw9xNi/0teMHrRW7dsz3Lt5ARhYNZ2ewpadnhaIp5mbALhOAP+EAdsC7t4Z6wqsDVv9+W6gm1Dk9mEyw==}\n\n  async@2.6.4:\n    resolution: {integrity: sha512-mzo5dfJYwAn29PeiJ0zvwTo04zj8HDJj0Mn8TD7sno7q12prdbnasKJHhkm2c1LgrhlJ0teaea8860oxi51mGA==}\n\n  async@3.2.6:\n    resolution: {integrity: sha512-htCUDlxyyCLMgaM3xXg0C0LW2xqfuQ6p05pCEIsXuyQ+a1koYKTuBMzRNwmybfLgvJDMd0r1LTn4+E0Ti6C2AA==}\n\n  asynckit@0.4.0:\n    resolution: {integrity: sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==}\n\n  at-least-node@1.0.0:\n    resolution: {integrity: sha512-+q/t7Ekv1EDY2l6Gda6LLiX14rU9TV20Wa3ofeQmwPFZbOMo9DXrLbOjFaaclkXKWidIaopwAObQDqwWtGUjqg==}\n    engines: {node: '>= 4.0.0'}\n\n  auto-bind@4.0.0:\n    resolution: {integrity: sha512-Hdw8qdNiqdJ8LqT0iK0sVzkFbzg6fhnQqqfWhBDxcHZvU75+B+ayzTy8x+k5Ix0Y92XOhOUlx74ps+bA6BeYMQ==}\n    engines: {node: '>=8'}\n\n  autoprefixer@10.4.16:\n    resolution: {integrity: sha512-7vd3UC6xKp0HLfua5IjZlcXvGAGy7cBAXTg2lyQ/8WpNhd6SiZ8Be+xm3FyBSYJx5GKcpRCzBh7RH4/0dnY+uQ==}\n    engines: {node: ^10 || ^12 || >=14}\n    hasBin: true\n    peerDependencies:\n      postcss: ^8.1.0\n\n  autoprefixer@10.4.20:\n    resolution: {integrity: sha512-XY25y5xSv/wEoqzDyXXME4AFfkZI0P23z6Fs3YgymDnKJkCGOnkL0iTxCa85UTqaSgfcqyf3UA6+c7wUvx/16g==}\n    engines: {node: ^10 || ^12 || >=14}\n    hasBin: true\n    peerDependencies:\n      postcss: ^8.1.0\n\n  available-typed-arrays@1.0.7:\n    resolution: {integrity: sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==}\n    engines: {node: '>= 0.4'}\n\n  aws4fetch@1.0.20:\n    resolution: {integrity: sha512-/djoAN709iY65ETD6LKCtyyEI04XIBP5xVvfmNxsEP0uJB5tyaGBztSryRr4HqMStr9R06PisQE7m9zDTXKu6g==}\n\n  axios@1.7.5:\n    resolution: {integrity: sha512-fZu86yCo+svH3uqJ/yTdQ0QHpQu5oL+/QE+QPSv6BZSkDAoky9vytxp7u5qk83OJFS3kEBcesWni9WTZAv3tSw==}\n\n  axios@1.7.7:\n    resolution: {integrity: sha512-S4kL7XrjgBmvdGut0sN3yJxqYzrDOnivkBiN0OFs6hLiUam3UPvswUo0kqGyhqUZGEOytHyumEdXsAkgCOUf3Q==}\n\n  babel-jest@29.7.0:\n    resolution: {integrity: sha512-BrvGY3xZSwEcCzKvKsCi2GgHqDqsYkOP4/by5xCgIwGXQxIEh+8ew3gmrE1y7XRR6LHZIj6yLYnUi/mm2KXKBg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    peerDependencies:\n      '@babel/core': ^7.8.0\n\n  babel-plugin-istanbul@6.1.1:\n    resolution: {integrity: sha512-Y1IQok9821cC9onCx5otgFfRm7Lm+I+wwxOx738M/WLPZ9Q42m4IG5W0FNX8WLL2gYMZo3JkuXIH2DOpWM+qwA==}\n    engines: {node: '>=8'}\n\n  babel-plugin-jest-hoist@29.6.3:\n    resolution: {integrity: sha512-ESAc/RJvGTFEzRwOTT4+lNDk/GNHMkKbNzsvT0qKRfDyyYTskxB5rnU2njIDYVxXCBHHEI1c0YwHob3WaYujOg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  babel-plugin-polyfill-corejs2@0.4.11:\n    resolution: {integrity: sha512-sMEJ27L0gRHShOh5G54uAAPaiCOygY/5ratXuiyb2G46FmlSpc9eFCzYVyDiPxfNbwzA7mYahmjQc5q+CZQ09Q==}\n    peerDependencies:\n      '@babel/core': ^7.4.0 || ^8.0.0-0 <8.0.0\n\n  babel-plugin-polyfill-corejs3@0.10.6:\n    resolution: {integrity: sha512-b37+KR2i/khY5sKmWNVQAnitvquQbNdWy6lJdsr0kmquCKEEUgMKK4SboVM3HtfnZilfjr4MMQ7vY58FVWDtIA==}\n    peerDependencies:\n      '@babel/core': ^7.4.0 || ^8.0.0-0 <8.0.0\n\n  babel-plugin-polyfill-regenerator@0.6.2:\n    resolution: {integrity: sha512-2R25rQZWP63nGwaAswvDazbPXfrM3HwVoBXK6HcqeKrSrL/JqcC/rDcf95l4r7LXLyxDXc8uQDa064GubtCABg==}\n    peerDependencies:\n      '@babel/core': ^7.4.0 || ^8.0.0-0 <8.0.0\n\n  babel-plugin-syntax-trailing-function-commas@7.0.0-beta.0:\n    resolution: {integrity: sha512-Xj9XuRuz3nTSbaTXWv3itLOcxyF4oPD8douBBmj7U9BBC6nEBYfyOJYQMf/8PJAFotC62UY5dFfIGEPr7WswzQ==}\n\n  babel-preset-current-node-syntax@1.1.0:\n    resolution: {integrity: sha512-ldYss8SbBlWva1bs28q78Ju5Zq1F+8BrqBZZ0VFhLBvhh6lCpC2o3gDJi/5DRLs9FgYZCnmPYIVFU4lRXCkyUw==}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  babel-preset-fbjs@3.4.0:\n    resolution: {integrity: sha512-9ywCsCvo1ojrw0b+XYk7aFvTH6D9064t0RIL1rtMf3nsa02Xw41MS7sZw216Im35xj/UY0PDBQsa1brUDDF1Ow==}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  babel-preset-jest@29.6.3:\n    resolution: {integrity: sha512-0B3bhxR6snWXJZtR/RliHTDPRgn1sNHOR0yVtq/IiQFyuOVjFS+wuio/R4gSNkyYmKmJB4wGZv2NZanmKmTnNA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    peerDependencies:\n      '@babel/core': ^7.0.0\n\n  babel-walk@3.0.0-canary-5:\n    resolution: {integrity: sha512-GAwkz0AihzY5bkwIY5QDR+LvsRQgB/B+1foMPvi0FZPMl5fjD7ICiznUiBdLYMH1QYe6vqu4gWYytZOccLouFw==}\n    engines: {node: '>= 10.0.0'}\n\n  backo2@1.0.2:\n    resolution: {integrity: sha512-zj6Z6M7Eq+PBZ7PQxl5NT665MvJdAkzp0f60nAJ+sLaSCBPMwVak5ZegFbgVCzFcCJTKFoMizvM5Ld7+JrRJHA==}\n\n  balanced-match@1.0.2:\n    resolution: {integrity: sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==}\n\n  base64-arraybuffer@0.1.4:\n    resolution: {integrity: sha512-a1eIFi4R9ySrbiMuyTGx5e92uRH5tQY6kArNcFaKBUleIoLjdjBg7Zxm3Mqm3Kmkf27HLR/1fnxX9q8GQ7Iavg==}\n    engines: {node: '>= 0.6.0'}\n\n  base64-js@1.5.1:\n    resolution: {integrity: sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==}\n\n  base64url@3.0.1:\n    resolution: {integrity: sha512-ir1UPr3dkwexU7FdV8qBBbNDRUhMmIekYMFZfi+C/sLNnRESKPl23nB9b2pltqfOQNnGzsDdId90AEtG5tCx4A==}\n    engines: {node: '>=6.0.0'}\n\n  basic-auth@2.0.1:\n    resolution: {integrity: sha512-NF+epuEdnUYVlGuhaxbbq+dvJttwLnGY+YixlXlME5KpQ5W3CnXA5cVTneY3SPbPDRkcjMbifrwmFYcClgOZeg==}\n    engines: {node: '>= 0.8'}\n\n  bcrypt@5.1.1:\n    resolution: {integrity: sha512-AGBHOG5hPYZ5Xl9KXzU5iKq9516yEmvCKDg3ecP5kX2aB6UqTeXZxk2ELnDgDm6BQSMlLt9rDB4LoSMx0rYwww==}\n    engines: {node: '>= 10.0.0'}\n\n  big-integer@1.6.52:\n    resolution: {integrity: sha512-QxD8cf2eVqJOOz63z6JIN9BzvVs/dlySa5HGSBH5xtR8dPteIRQnBxxKqkNTiT6jbDTF6jAfrd4oMcND9RGbQg==}\n    engines: {node: '>=0.6'}\n\n  binary-extensions@2.3.0:\n    resolution: {integrity: sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==}\n    engines: {node: '>=8'}\n\n  bl@4.1.0:\n    resolution: {integrity: sha512-1W07cM9gS6DcLperZfFSj+bWLtaPGSOHWhPiGzXmvVJbRLdG82sH/Kn8EtW1VqWVA54AKf2h5k5BbnIbwF3h6w==}\n\n  blob@0.0.5:\n    resolution: {integrity: sha512-gaqbzQPqOoamawKg0LGVd7SzLgXS+JH61oWprSLH+P+abTczqJbhTR8CmJ2u9/bUYNmHTGJx/UEmn6doAvvuig==}\n\n  body-parser@1.20.3:\n    resolution: {integrity: sha512-7rAxByjUMqQ3/bHJy7D6OGXvx/MMc4IqBn/X0fcM1QUcAItpZrBEYhWGem+tzXH90c+G01ypMcYJBO9Y30203g==}\n    engines: {node: '>= 0.8', npm: 1.2.8000 || >= 1.4.16}\n\n  boolbase@1.0.0:\n    resolution: {integrity: sha512-JZOSA7Mo9sNGB8+UjSgzdLtokWAky1zbztM3WRLCbZ70/3cTANmQmOdR7y2g+J0e2WXywy1yS468tY+IruqEww==}\n\n  boxen@5.1.2:\n    resolution: {integrity: sha512-9gYgQKXx+1nP8mP7CzFyaUARhg7D3n1dF/FnErWmu9l6JvGpNUN278h0aSb+QjoiKSWG+iZ3uHrcqk0qrY9RQQ==}\n    engines: {node: '>=10'}\n\n  bplist-parser@0.2.0:\n    resolution: {integrity: sha512-z0M+byMThzQmD9NILRniCUXYsYpjwnlO8N5uCFaCqIOpqRsJCrQL9NK3JsD67CN5a08nF5oIL2bD6loTdHOuKw==}\n    engines: {node: '>= 5.10.0'}\n\n  brace-expansion@1.1.11:\n    resolution: {integrity: sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==}\n\n  brace-expansion@2.0.1:\n    resolution: {integrity: sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==}\n\n  braces@3.0.3:\n    resolution: {integrity: sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==}\n    engines: {node: '>=8'}\n\n  browser-or-node@3.0.0:\n    resolution: {integrity: sha512-iczIdVJzGEYhP5DqQxYM9Hh7Ztpqqi+CXZpSmX8ALFs9ecXkQIeqRyM6TfxEfMVpwhl3dSuDvxdzzo9sUOIVBQ==}\n\n  browser-stdout@1.3.1:\n    resolution: {integrity: sha512-qhAVI1+Av2X7qelOfAIYwXONood6XlZE/fXaBSmW/T5SzLAmCgzi+eiWE7fUvbHaeNBQH13UftjpXxsfLkMpgw==}\n\n  browserslist-to-esbuild@2.1.1:\n    resolution: {integrity: sha512-KN+mty6C3e9AN8Z5dI1xeN15ExcRNeISoC3g7V0Kax/MMF9MSoYA2G7lkTTcVUFntiEjkpI0HNgqJC1NjdyNUw==}\n    engines: {node: '>=18'}\n    hasBin: true\n    peerDependencies:\n      browserslist: '*'\n\n  browserslist@4.24.0:\n    resolution: {integrity: sha512-Rmb62sR1Zpjql25eSanFGEhAxcFwfA1K0GuQcLoaJBAcENegrQut3hYdhXFF1obQfiDyqIW/cLM5HSJ/9k884A==}\n    engines: {node: ^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7}\n    hasBin: true\n\n  bs-logger@0.2.6:\n    resolution: {integrity: sha512-pd8DCoxmbgc7hyPKOvxtqNcjYoOsABPQdcCUjGp3d42VR2CX1ORhk2A87oqqu5R1kk+76nsxZupkmyd+MVtCog==}\n    engines: {node: '>= 6'}\n\n  bser@2.1.1:\n    resolution: {integrity: sha512-gQxTNE/GAfIIrmHLUE3oJyp5FO6HRBfhjnw4/wMmA63ZGDJnWBmgY/lyQBpnDUkGmAhbSe39tx2d/iTOAfglwQ==}\n\n  buffer-crc32@0.2.13:\n    resolution: {integrity: sha512-VO9Ht/+p3SN7SKWqcrgEzjGbRSJYTx+Q1pTQC0wrWqHx0vpJraQ6GtHx8tvcg1rlK1byhU5gccxgOgj7B0TDkQ==}\n\n  buffer-equal-constant-time@1.0.1:\n    resolution: {integrity: sha512-zRpUiDwd/xk6ADqPMATG8vc9VPrkck7T07OIx0gnjmJAnHnTVXNQG3vfvWNuiZIkwu9KrKdA1iJKfsfTVxE6NA==}\n\n  buffer-from@1.1.2:\n    resolution: {integrity: sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ==}\n\n  buffer@5.7.1:\n    resolution: {integrity: sha512-EHcyIPBQ4BSGlvjB16k5KgAJ27CIsHY/2JBmCRReo48y9rQ3MaUzWX3KVlBa4U7MyX02HdVj0K7C3WaB3ju7FQ==}\n\n  buffer@6.0.3:\n    resolution: {integrity: sha512-FTiCpNxtwiZZHEZbcbTIcZjERVICn9yq/pDFkTl95/AxzD1naBctN7YO68riM/gLSDY7sdrMby8hofADYuuqOA==}\n\n  bundle-name@3.0.0:\n    resolution: {integrity: sha512-PKA4BeSvBpQKQ8iPOGCSiell+N8P+Tf1DlwqmYhpe2gAhKPHn8EYOxVT+ShuGmhg8lN8XiSlS80yiExKXrURlw==}\n    engines: {node: '>=12'}\n\n  bundle-name@4.1.0:\n    resolution: {integrity: sha512-tjwM5exMg6BGRI+kNmTntNsvdZS1X8BFYS6tnJ2hdH0kVxM6/eVZ2xy+FqStSWvYmtfFMDLIxurorHwDKfDz5Q==}\n    engines: {node: '>=18'}\n\n  bundle-require@5.0.0:\n    resolution: {integrity: sha512-GuziW3fSSmopcx4KRymQEJVbZUfqlCqcq7dvs6TYwKRZiegK/2buMxQTPs6MGlNv50wms1699qYO54R8XfRX4w==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n    peerDependencies:\n      esbuild: '>=0.18'\n\n  busboy@1.6.0:\n    resolution: {integrity: sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==}\n    engines: {node: '>=10.16.0'}\n\n  bytes@3.1.2:\n    resolution: {integrity: sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==}\n    engines: {node: '>= 0.8'}\n\n  cac@6.7.14:\n    resolution: {integrity: sha512-b6Ilus+c3RrdDk+JhLKUAQfzzgLEPy6wcXqS7f/xe1EETvsDP6GORG7SFuOs6cID5YkqchW/LXZbX5bc8j7ZcQ==}\n    engines: {node: '>=8'}\n\n  call-bind@1.0.7:\n    resolution: {integrity: sha512-GHTSNSYICQ7scH7sZ+M2rFopRoLh8t2bLSW6BbgrtLsahOIB5iyAVJf9GjWK3cYTDaMj4XdBpM1cA6pIS0Kv2w==}\n    engines: {node: '>= 0.4'}\n\n  call-me-maybe@1.0.2:\n    resolution: {integrity: sha512-HpX65o1Hnr9HH25ojC1YGs7HCQLq0GCOibSaWER0eNpgJ/Z1MZv2mTc7+xh6WOPxbRVcmgbv4hGU+uSQ/2xFZQ==}\n\n  callsites@3.1.0:\n    resolution: {integrity: sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==}\n    engines: {node: '>=6'}\n\n  camel-case@4.1.2:\n    resolution: {integrity: sha512-gxGWBrTT1JuMx6R+o5PTXMmUnhnVzLQ9SNutD4YqKtI6ap897t3tKECYla6gCWEkplXnlNybEkZg9GEGxKFCgw==}\n\n  camelcase-css@2.0.1:\n    resolution: {integrity: sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==}\n    engines: {node: '>= 6'}\n\n  camelcase@5.3.1:\n    resolution: {integrity: sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==}\n    engines: {node: '>=6'}\n\n  camelcase@6.3.0:\n    resolution: {integrity: sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==}\n    engines: {node: '>=10'}\n\n  caniuse-api@3.0.0:\n    resolution: {integrity: sha512-bsTwuIg/BZZK/vreVTYYbSWoe2F+71P7K5QGEX+pT250DZbfU1MQ5prOKpPR+LL6uWKK3KMwMCAS74QB3Um1uw==}\n\n  caniuse-lite@1.0.30001667:\n    resolution: {integrity: sha512-7LTwJjcRkzKFmtqGsibMeuXmvFDfZq/nzIjnmgCGzKKRVzjD72selLDK1oPF/Oxzmt4fNcPvTDvGqSDG4tCALw==}\n\n  canvas@2.11.2:\n    resolution: {integrity: sha512-ItanGBMrmRV7Py2Z+Xhs7cT+FNt5K0vPL4p9EZ/UX/Mu7hFbkxSjKF2KVtPwX7UYWp7dRKnrTvReflgrItJbdw==}\n    engines: {node: '>=6'}\n\n  capital-case@1.0.4:\n    resolution: {integrity: sha512-ds37W8CytHgwnhGGTi88pcPyR15qoNkOpYwmMMfnWqqWgESapLqvDx6huFjQ5vqWSn2Z06173XNA7LtMOeUh1A==}\n\n  chai@5.1.2:\n    resolution: {integrity: sha512-aGtmf24DW6MLHHG5gCx4zaI3uBq3KRtxeVs0DjFH6Z0rDNbsvTxFASFvdj79pxjxZ8/5u3PIiN3IwEIQkiiuPw==}\n    engines: {node: '>=12'}\n\n  chalk@2.4.2:\n    resolution: {integrity: sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==}\n    engines: {node: '>=4'}\n\n  chalk@3.0.0:\n    resolution: {integrity: sha512-4D3B6Wf41KOYRFdszmDqMCGq5VV/uMAB273JILmO+3jAlh8X4qDtdtgCR3fxtbLEMzSx22QdhnDcJvu2u1fVwg==}\n    engines: {node: '>=8'}\n\n  chalk@4.1.2:\n    resolution: {integrity: sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==}\n    engines: {node: '>=10'}\n\n  chalk@5.3.0:\n    resolution: {integrity: sha512-dLitG79d+GV1Nb/VYcCDFivJeK1hiukt9QjRNVOsUtTy1rR1YJsmpGGTZ3qJos+uw7WmWF4wUwBd9jxjocFC2w==}\n    engines: {node: ^12.17.0 || ^14.13 || >=16.0.0}\n\n  change-case-all@1.0.14:\n    resolution: {integrity: sha512-CWVm2uT7dmSHdO/z1CXT/n47mWonyypzBbuCy5tN7uMg22BsfkhwT6oHmFCAk+gL1LOOxhdbB9SZz3J1KTY3gA==}\n\n  change-case-all@1.0.15:\n    resolution: {integrity: sha512-3+GIFhk3sNuvFAJKU46o26OdzudQlPNBCu1ZQi3cMeMHhty1bhDxu2WrEilVNYaGvqUtR1VSigFcJOiS13dRhQ==}\n\n  change-case@4.1.2:\n    resolution: {integrity: sha512-bSxY2ws9OtviILG1EiY5K7NNxkqg/JnRnFxLtKQ96JaviiIxi7djMrSd0ECT9AC+lttClmYwKw53BWpOMblo7A==}\n\n  char-regex@1.0.2:\n    resolution: {integrity: sha512-kWWXztvZ5SBQV+eRgKFeh8q5sLuZY2+8WUIzlxWVTg+oGwY14qylx1KbKzHd8P6ZYkAg0xyIDU9JMHhyJMZ1jw==}\n    engines: {node: '>=10'}\n\n  character-parser@2.2.0:\n    resolution: {integrity: sha512-+UqJQjFEFaTAs3bNsF2j2kEN1baG/zghZbdqoYEDxGZtJo9LBzl1A+m0D4n3qKx8N2FNv8/Xp6yV9mQmBuptaw==}\n\n  chardet@0.7.0:\n    resolution: {integrity: sha512-mT8iDcrh03qDGRRmoA2hmBJnxpllMR+0/0qlzjqZES6NdiWDcZkCNAk4rPFZ9Q85r27unkiNNg8ZOiwZXBHwcA==}\n\n  charset@1.0.1:\n    resolution: {integrity: sha512-6dVyOOYjpfFcL1Y4qChrAoQLRHvj2ziyhcm0QJlhOcAhykL/k1kTUPbeo+87MNRTRdk2OIIsIXbuF3x2wi5EXg==}\n    engines: {node: '>=4.0.0'}\n\n  check-disk-space@3.4.0:\n    resolution: {integrity: sha512-drVkSqfwA+TvuEhFipiR1OC9boEGZL5RrWvVsOthdcvQNXyCCuKkEiTOTXZ7qxSf/GLwq4GvzfrQD/Wz325hgw==}\n    engines: {node: '>=16'}\n\n  check-error@2.1.1:\n    resolution: {integrity: sha512-OAlb+T7V4Op9OwdkjmguYRqncdlx5JiofwOAUkmTF+jNdHwzTaTs4sRAGpzLF3oOz5xAyDGrPgeIDFQmDOTiJw==}\n    engines: {node: '>= 16'}\n\n  cheerio-select@2.1.0:\n    resolution: {integrity: sha512-9v9kG0LvzrlcungtnJtpGNxY+fzECQKhK4EGJX2vByejiMX84MFNQw4UxPJl3bFbTMw+Dfs37XaIkCwTZfLh4g==}\n\n  cheerio@1.0.0-rc.12:\n    resolution: {integrity: sha512-VqR8m68vM46BNnuZ5NtnGBKIE/DfN0cRIzg9n40EIq9NOv90ayxLBXA8fXC5gquFRGJSTRqBq25Jt2ECLR431Q==}\n    engines: {node: '>= 6'}\n\n  chokidar@3.5.3:\n    resolution: {integrity: sha512-Dr3sfKRP6oTcjf2JmUmFJfeVMvXBdegxB0iVQ5eb2V10uFJUCAS8OByZdVAyVb8xXNz3GjjTgj9kLWsZTqE6kw==}\n    engines: {node: '>= 8.10.0'}\n\n  chokidar@3.6.0:\n    resolution: {integrity: sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==}\n    engines: {node: '>= 8.10.0'}\n\n  chokidar@4.0.1:\n    resolution: {integrity: sha512-n8enUVCED/KVRQlab1hr3MVpcVMvxtZjmEa956u+4YijlmQED223XMSYj2tLuKvr4jcCTzNNMpQDUer72MMmzA==}\n    engines: {node: '>= 14.16.0'}\n\n  chownr@1.1.4:\n    resolution: {integrity: sha512-jJ0bqzaylmJtVnNgzTeSOs8DPavpbYgEr/b0YL8/2GO3xJEhInFmhKMUnEJQjZumK7KXGFhUy89PrsJWlakBVg==}\n\n  chownr@2.0.0:\n    resolution: {integrity: sha512-bIomtDF5KGpdogkLd9VspvFzk9KfpyyGlS8YFVZl7TGPBHL5snIOnxeshwVgPteQ9b4Eydl+pVbIyE1DcvCWgQ==}\n    engines: {node: '>=10'}\n\n  chrome-trace-event@1.0.4:\n    resolution: {integrity: sha512-rNjApaLzuwaOTjCiT8lSDdGN1APCiqkChLMJxJPWLunPAt5fy8xgU9/jNOchV84wfIxrA0lRQB7oCT8jrn/wrQ==}\n    engines: {node: '>=6.0'}\n\n  ci-info@3.9.0:\n    resolution: {integrity: sha512-NIxF55hv4nSqQswkAeiOi1r83xy8JldOFDTWiug55KBu9Jnblncd2U6ViHmYgHf01TPZS77NJBhBMKdWj9HQMQ==}\n    engines: {node: '>=8'}\n\n  cjs-module-lexer@1.4.1:\n    resolution: {integrity: sha512-cuSVIHi9/9E/+821Qjdvngor+xpnlwnuwIyZOaLmHBVdXL+gP+I6QQB9VkO7RI77YIcTV+S1W9AreJ5eN63JBA==}\n\n  class-transformer@0.5.1:\n    resolution: {integrity: sha512-SQa1Ws6hUbfC98vKGxZH3KFY0Y1lm5Zm0SY8XX9zbK7FJCyVEac3ATW0RIpwzW+oOfmHE5PMPufDG9hCfoEOMw==}\n\n  class-validator@0.14.1:\n    resolution: {integrity: sha512-2VEG9JICxIqTpoK1eMzZqaV+u/EiwEJkMGzTrZf6sU/fwsnOITVgYJ8yojSy6CaXtO9V0Cc6ZQZ8h8m4UBuLwQ==}\n\n  clean-stack@2.2.0:\n    resolution: {integrity: sha512-4diC9HaTE+KRAMWhDhrGOECgWZxoevMc5TlkObMqNSsVU62PYzXZ/SMTjzyGAFF1YusgxGcSWTEXBhp0CPwQ1A==}\n    engines: {node: '>=6'}\n\n  cli-boxes@2.2.1:\n    resolution: {integrity: sha512-y4coMcylgSCdVinjiDBuR8PCC2bLjyGTwEmPb9NHR/QaNU6EUOXcTY/s6VjGMD6ENSEaeQYHCY0GNGS5jfMwPw==}\n    engines: {node: '>=6'}\n\n  cli-cursor@3.1.0:\n    resolution: {integrity: sha512-I/zHAwsKf9FqGoXM4WWRACob9+SNukZTd94DWF57E4toouRulbCxcUh6RKUEOQlYTHJnzkPMySvPNaaSLNfLZw==}\n    engines: {node: '>=8'}\n\n  cli-cursor@5.0.0:\n    resolution: {integrity: sha512-aCj4O5wKyszjMmDT4tZj93kxyydN/K5zPWSCe6/0AV/AA1pqe5ZBIw0a2ZfPQV7lL5/yb5HsUreJ6UFAF1tEQw==}\n    engines: {node: '>=18'}\n\n  cli-spinners@2.9.2:\n    resolution: {integrity: sha512-ywqV+5MmyL4E7ybXgKys4DugZbX0FC6LnwrhjuykIjnK9k8OQacQ7axGKnjDXWNhns0xot3bZI5h55H8yo9cJg==}\n    engines: {node: '>=6'}\n\n  cli-table3@0.6.5:\n    resolution: {integrity: sha512-+W/5efTR7y5HRD7gACw9yQjqMVvEMLBHmboM/kPWam+H+Hmyrgjh6YncVKK122YZkXrLudzTuAukUw9FnMf7IQ==}\n    engines: {node: 10.* || >= 12.*}\n\n  cli-truncate@2.1.0:\n    resolution: {integrity: sha512-n8fOixwDD6b/ObinzTrp1ZKFzbgvKZvuz/TvejnLn1aQfC6r52XEx85FmuC+3HI+JM7coBRXUvNqEU2PHVrHpg==}\n    engines: {node: '>=8'}\n\n  cli-truncate@4.0.0:\n    resolution: {integrity: sha512-nPdaFdQ0h/GEigbPClz11D0v/ZJEwxmeVZGeMo3Z5StPtUTkA9o1lD6QwoirYiSDzbcwn2XcjwmCp68W1IS4TA==}\n    engines: {node: '>=18'}\n\n  cli-width@3.0.0:\n    resolution: {integrity: sha512-FxqpkPPwu1HjuN93Omfm4h8uIanXofW0RxVEW3k5RKx+mJJYSthzNhp32Kzxxy3YAEZ/Dc/EWN1vZRY0+kOhbw==}\n    engines: {node: '>= 10'}\n\n  cli-width@4.1.0:\n    resolution: {integrity: sha512-ouuZd4/dm2Sw5Gmqy6bGyNNNe1qt9RpmxveLSO7KcgsTnU7RXfsw+/bukWGo1abgBiMAic068rclZsO4IWmmxQ==}\n    engines: {node: '>= 12'}\n\n  cliui@6.0.0:\n    resolution: {integrity: sha512-t6wbgtoCXvAzst7QgXxJYqPt0usEfbgQdftEPbLL/cvv6HPE5VgvqCuAIDR0NgU52ds6rFwqrgakNLrHEjCbrQ==}\n\n  cliui@7.0.4:\n    resolution: {integrity: sha512-OcRE68cOsVMXp1Yvonl/fzkQOyjLSu/8bhPDfQt0e0/Eb283TKP20Fs2MqoPsr9SwA595rRCA+QMzYc9nBP+JQ==}\n\n  cliui@8.0.1:\n    resolution: {integrity: sha512-BSeNnyus75C4//NQ9gQt1/csTXyo/8Sb+afLAkzAptFuMsod9HFokGNudZpi/oQV73hnVK+sR+5PVRMd+Dr7YQ==}\n    engines: {node: '>=12'}\n\n  clone@1.0.4:\n    resolution: {integrity: sha512-JQHZ2QMW6l3aH/j6xCqQThY/9OH4D/9ls34cgkUBiEeocRTU04tHfKPBsUK1PqZCUQM7GiA0IIXJSuXHI64Kbg==}\n    engines: {node: '>=0.8'}\n\n  cluster-key-slot@1.1.2:\n    resolution: {integrity: sha512-RMr0FhtfXemyinomL4hrWcYJxmX6deFdCxpJzhDttxgO1+bcCnkk+9drydLVDmAMG7NE6aN/fl4F7ucU/90gAA==}\n    engines: {node: '>=0.10.0'}\n\n  co@4.6.0:\n    resolution: {integrity: sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ==}\n    engines: {iojs: '>= 1.0.0', node: '>= 0.12.0'}\n\n  collect-v8-coverage@1.0.2:\n    resolution: {integrity: sha512-lHl4d5/ONEbLlJvaJNtsF/Lz+WvB07u2ycqTYbdrq7UypDXailES4valYb2eWiJFxZlVmpGekfqoxQhzyFdT4Q==}\n\n  collection-utils@1.0.1:\n    resolution: {integrity: sha512-LA2YTIlR7biSpXkKYwwuzGjwL5rjWEZVOSnvdUc7gObvWe4WkjxOpfrdhoP7Hs09YWDVfg0Mal9BpAqLfVEzQg==}\n\n  color-convert@1.9.3:\n    resolution: {integrity: sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==}\n\n  color-convert@2.0.1:\n    resolution: {integrity: sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==}\n    engines: {node: '>=7.0.0'}\n\n  color-name@1.1.3:\n    resolution: {integrity: sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw==}\n\n  color-name@1.1.4:\n    resolution: {integrity: sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==}\n\n  color-support@1.1.3:\n    resolution: {integrity: sha512-qiBjkpbMLO/HL68y+lh4q0/O1MZFj2RX6X/KmMa3+gJD3z+WwI1ZzDHysvqHGS3mP6mznPckpXmw1nI9cJjyRg==}\n    hasBin: true\n\n  colord@2.9.3:\n    resolution: {integrity: sha512-jeC1axXpnb0/2nn/Y1LPuLdgXBLH7aDcHu4KEKfqw3CUhX7ZpfBSlPKyqXE6btIgEzfWtrX3/tyBCaCvXvMkOw==}\n\n  colorette@2.0.20:\n    resolution: {integrity: sha512-IfEDxwoWIjkeXL1eXcDiow4UbKjhLdq6/EuSVR9GMN7KVH3r9gQ83e73hsz1Nd1T3ijd5xv1wcWRYO+D6kCI2w==}\n\n  combined-stream@1.0.8:\n    resolution: {integrity: sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==}\n    engines: {node: '>= 0.8'}\n\n  commander@10.0.1:\n    resolution: {integrity: sha512-y4Mg2tXshplEbSGzx7amzPwKKOCGuoSRP/CjEdwwk0FOGlUbq6lKuoyDZTNZkmxHdJtp54hdfY/JUrdL7Xfdug==}\n    engines: {node: '>=14'}\n\n  commander@12.1.0:\n    resolution: {integrity: sha512-Vw8qHK3bZM9y/P10u3Vib8o/DdkvA2OtPtZvD871QKjy74Wj1WSKFILMPRPSdUSx5RFK1arlJzEtA4PkFgnbuA==}\n    engines: {node: '>=18'}\n\n  commander@2.20.3:\n    resolution: {integrity: sha512-GpVkmM8vF2vQUkj2LvZmD35JxeJOLCwJ9cUkugyk2nuhbv3+mJvpLYYt+0+USMxE+oj+ey/lJEnhZw75x/OMcQ==}\n\n  commander@4.1.1:\n    resolution: {integrity: sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==}\n    engines: {node: '>= 6'}\n\n  commander@6.2.1:\n    resolution: {integrity: sha512-U7VdrJFnJgo4xjrHpTzu0yrHPGImdsmD95ZlgYSEajAn2JKzDhDTPG9kBTefmObL2w/ngeZnilk+OV9CG3d7UA==}\n    engines: {node: '>= 6'}\n\n  commander@7.2.0:\n    resolution: {integrity: sha512-QrWXB+ZQSVPmIWIhtEO9H+gwHaMGYiF5ChvoJ+K9ZGHG/sVsa6yiesAD1GC/x46sET00Xlwo1u49RVVVzvcSkw==}\n    engines: {node: '>= 10'}\n\n  commander@8.3.0:\n    resolution: {integrity: sha512-OkTL9umf+He2DZkUq8f8J9of7yL6RJKI24dVITBmNfZBmri9zYZQrKkuXiKhyfPSu8tUhnVBB1iKXevvnlR4Ww==}\n    engines: {node: '>= 12'}\n\n  comment-json@4.2.3:\n    resolution: {integrity: sha512-SsxdiOf064DWoZLH799Ata6u7iV658A11PlWtZATDlXPpKGJnbJZ5Z24ybixAi+LUUqJ/GKowAejtC5GFUG7Tw==}\n    engines: {node: '>= 6'}\n\n  common-tags@1.8.2:\n    resolution: {integrity: sha512-gk/Z852D2Wtb//0I+kRFNKKE9dIIVirjoqPoA1wJU+XePVXZfGeBpk45+A1rKO4Q43prqWBNY/MiIeRLbPWUaA==}\n    engines: {node: '>=4.0.0'}\n\n  compare-func@2.0.0:\n    resolution: {integrity: sha512-zHig5N+tPWARooBnb0Zx1MFcdfpyJrfTJ3Y5L+IFvUm8rM74hHz66z0gw0x4tijh5CorKkKUCnW82R2vmpeCRA==}\n\n  component-bind@1.0.0:\n    resolution: {integrity: sha512-WZveuKPeKAG9qY+FkYDeADzdHyTYdIboXS59ixDeRJL5ZhxpqUnxSOwop4FQjMsiYm3/Or8cegVbpAHNA7pHxw==}\n\n  component-emitter@1.3.1:\n    resolution: {integrity: sha512-T0+barUSQRTUQASh8bx02dl+DhF54GtIDY13Y3m9oWTklKbb3Wv974meRpeZ3lp1JpLVECWWNHC4vaG2XHXouQ==}\n\n  component-inherit@0.0.3:\n    resolution: {integrity: sha512-w+LhYREhatpVqTESyGFg3NlP6Iu0kEKUHETY9GoZP/pQyW4mHFZuFWRUCIqVPZ36ueVLtoOEZaAqbCF2RDndaA==}\n\n  computeds@0.0.1:\n    resolution: {integrity: sha512-7CEBgcMjVmitjYo5q8JTJVra6X5mQ20uTThdK+0kR7UEaDrAWEQcRiBtWJzga4eRpP6afNwwLsX2SET2JhVB1Q==}\n\n  concat-map@0.0.1:\n    resolution: {integrity: sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==}\n\n  concat-stream@1.6.2:\n    resolution: {integrity: sha512-27HBghJxjiZtIk3Ycvn/4kbJk/1uZuJFfuPEns6LaEvpvG1f0hTea8lilrouyo9mVc2GWdcEZ8OLoGmSADlrCw==}\n    engines: {'0': node >= 0.8}\n\n  confbox@0.1.7:\n    resolution: {integrity: sha512-uJcB/FKZtBMCJpK8MQji6bJHgu1tixKPxRLeGkNzBoOZzpnZUJm0jm2/sBDWcuBx1dYgxV4JU+g5hmNxCyAmdA==}\n\n  confbox@0.1.8:\n    resolution: {integrity: sha512-RMtmw0iFkeR4YV+fUOSucriAQNb9g8zFR52MWCtl+cCZOFRNL6zeB395vPzFhEjjn4fMxXudmELnl/KF/WrK6w==}\n\n  consola@2.15.3:\n    resolution: {integrity: sha512-9vAdYbHj6x2fLKC4+oPH0kFzY/orMZyG2Aj+kNylHxKGJ/Ed4dpNyAQYwJOdqO4zdM7XpVHmyejQDcQHrnuXbw==}\n\n  consola@3.2.3:\n    resolution: {integrity: sha512-I5qxpzLv+sJhTVEoLYNcTW+bThDCPsit0vLNKShZx6rLtpilNpmmeTPaeqJb9ZE9dV3DGaeby6Vuhrw38WjeyQ==}\n    engines: {node: ^14.18.0 || >=16.10.0}\n\n  console-control-strings@1.1.0:\n    resolution: {integrity: sha512-ty/fTekppD2fIwRvnZAVdeOiGd1c7YXEixbgJTNzqcxJWKQnjJ/V1bNEEE6hygpM3WjwHFUVK6HTjWSzV4a8sQ==}\n\n  constant-case@3.0.4:\n    resolution: {integrity: sha512-I2hSBi7Vvs7BEuJDr5dDHfzb/Ruj3FyvFyh7KLilAjNQw3Be+xgqUBA2W6scVEcL0hL1dwPRtIqEPVUCKkSsyQ==}\n\n  constantinople@4.0.1:\n    resolution: {integrity: sha512-vCrqcSIq4//Gx74TXXCGnHpulY1dskqLTFGDmhrGxzeXL8lF8kvXv6mpNWlJj1uD4DW23D4ljAqbY4RRaaUZIw==}\n\n  content-disposition@0.5.4:\n    resolution: {integrity: sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==}\n    engines: {node: '>= 0.6'}\n\n  content-type@1.0.5:\n    resolution: {integrity: sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==}\n    engines: {node: '>= 0.6'}\n\n  conventional-changelog-angular@7.0.0:\n    resolution: {integrity: sha512-ROjNchA9LgfNMTTFSIWPzebCwOGFdgkEq45EnvvrmSLvCtAw0HSmrCs7/ty+wAeYUZyNay0YMUNYFTRL72PkBQ==}\n    engines: {node: '>=16'}\n\n  conventional-changelog-conventionalcommits@7.0.2:\n    resolution: {integrity: sha512-NKXYmMR/Hr1DevQegFB4MwfM5Vv0m4UIxKZTTYuD98lpTknaZlSRrDOG4X7wIXpGkfsYxZTghUN+Qq+T0YQI7w==}\n    engines: {node: '>=16'}\n\n  conventional-commits-parser@5.0.0:\n    resolution: {integrity: sha512-ZPMl0ZJbw74iS9LuX9YIAiW8pfM5p3yh2o/NbXHbkFuZzY5jvdi5jFycEOkmBW5H5I7nA+D6f3UcsCLP2vvSEA==}\n    engines: {node: '>=16'}\n    hasBin: true\n\n  convert-source-map@2.0.0:\n    resolution: {integrity: sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==}\n\n  cookie-es@1.2.2:\n    resolution: {integrity: sha512-+W7VmiVINB+ywl1HGXJXmrqkOhpKrIiVZV6tQuV54ZyQC7MMuBt81Vc336GMLoHBq5hV/F9eXgt5Mnx0Rha5Fg==}\n\n  cookie-parser@1.4.7:\n    resolution: {integrity: sha512-nGUvgXnotP3BsjiLX2ypbQnWoGUPIIfHQNZkkC668ntrzGWEZVW70HDEB1qnNGMicPje6EttlIgzo51YSwNQGw==}\n    engines: {node: '>= 0.8.0'}\n\n  cookie-signature@1.0.6:\n    resolution: {integrity: sha512-QADzlaHc8icV8I7vbaJXJwod9HWYp8uCqf1xa4OfNu1T7JVxQIrUgOWtHdNDtPiywmFbiS12VjotIXLrKM3orQ==}\n\n  cookie-signature@1.0.7:\n    resolution: {integrity: sha512-NXdYc3dLr47pBkpUCHtKSwIOQXLVn8dZEuywboCOJY/osA0wFSLlSawr3KN8qXJEyX66FcONTH8EIlVuK0yyFA==}\n\n  cookie@0.7.2:\n    resolution: {integrity: sha512-yki5XnKuf750l50uGTllt6kKILY4nQ1eNIQatoXEByZ5dWgnKqbnqmTrBE5B4N7lrMJKQ2ytWMiTO2o0v6Ew/w==}\n    engines: {node: '>= 0.6'}\n\n  cookiejar@2.1.4:\n    resolution: {integrity: sha512-LDx6oHrK+PhzLKJU9j5S7/Y3jM/mUHvD/DeI1WQmJn652iPC5Y4TBzC9l+5OMOXlyTTA+SmVUPm0HQUwpD5Jqw==}\n\n  core-js-compat@3.38.1:\n    resolution: {integrity: sha512-JRH6gfXxGmrzF3tZ57lFx97YARxCXPaMzPo6jELZhv88pBH5VXpQ+y0znKGlFnzuaihqhLbefxSJxWJMPtfDzw==}\n\n  core-js@3.38.1:\n    resolution: {integrity: sha512-OP35aUorbU3Zvlx7pjsFdu1rGNnD4pgw/CWoYzRY3t2EzoVT7shKHY1dlAy3f41cGIO7ZDPQimhGFTlEYkG/Hw==}\n\n  core-util-is@1.0.3:\n    resolution: {integrity: sha512-ZQBvi1DcpJ4GDqanjucZ2Hj3wEO5pZDS89BWbkcrvdxksJorwUDDZamX9ldFkp9aw2lmBDLgkObEA4DWNJ9FYQ==}\n\n  cors@2.8.5:\n    resolution: {integrity: sha512-KIHbLJqu73RGr/hnbrO9uBeixNGuvSQjul/jdFvS/KFSIH1hWVd1ng7zOHx+YrEfInLG7q4n6GHQ9cDtxv/P6g==}\n    engines: {node: '>= 0.10'}\n\n  corser@2.0.1:\n    resolution: {integrity: sha512-utCYNzRSQIZNPIcGZdQc92UVJYAhtGAteCFg0yRaFm8f0P+CPtyGyHXJcGXnffjCybUCEx3FQ2G7U3/o9eIkVQ==}\n    engines: {node: '>= 0.4.0'}\n\n  cosmiconfig-typescript-loader@5.1.0:\n    resolution: {integrity: sha512-7PtBB+6FdsOvZyJtlF3hEPpACq7RQX6BVGsgC7/lfVXnKMvNCu/XY3ykreqG5w/rBNdu2z8LCIKoF3kpHHdHlA==}\n    engines: {node: '>=v16'}\n    peerDependencies:\n      '@types/node': '*'\n      cosmiconfig: '>=8.2'\n      typescript: '>=4'\n\n  cosmiconfig@8.0.0:\n    resolution: {integrity: sha512-da1EafcpH6b/TD8vDRaWV7xFINlHlF6zKsGwS1TsuVJTZRkquaS5HTMq7uq6h31619QjbsYl21gVDOm32KM1vQ==}\n    engines: {node: '>=14'}\n\n  cosmiconfig@8.3.6:\n    resolution: {integrity: sha512-kcZ6+W5QzcJ3P1Mt+83OUv/oHFqZHIx8DuxG6eZ5RGMERoLqp4BuGjhHLYGK+Kf5XVkQvqBSmAy/nGWN3qDgEA==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      typescript: '>=4.9.5'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  cosmiconfig@9.0.0:\n    resolution: {integrity: sha512-itvL5h8RETACmOTFc4UfIyB2RfEHi71Ax6E/PivVxq9NseKbOWpeyHEOIbmAw1rs8Ak0VursQNww7lf7YtUwzg==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      typescript: '>=4.9.5'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  create-jest@29.7.0:\n    resolution: {integrity: sha512-Adz2bdH0Vq3F53KEMJOoftQFutWCukm6J24wbPWRO4k1kMY7gS7ds/uoJkNuV8wDCtWWnuwGcJwpWcih+zEW1Q==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    hasBin: true\n\n  create-require@1.1.1:\n    resolution: {integrity: sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==}\n\n  crelt@1.0.6:\n    resolution: {integrity: sha512-VQ2MBenTq1fWZUH9DJNGti7kKv6EeAuYr3cLwxUWhIu1baTaXh4Ib5W2CqHVqib4/MqbYGJqiL3Zb8GJZr3l4g==}\n\n  cron@3.1.7:\n    resolution: {integrity: sha512-tlBg7ARsAMQLzgwqVxy8AZl/qlTc5nibqYwtNGoCrd+cV+ugI+tvZC1oT/8dFH8W455YrywGykx/KMmAqOr7Jw==}\n\n  cross-env@7.0.3:\n    resolution: {integrity: sha512-+/HKd6EgcQCJGh2PSjZuUitQBQynKor4wrFbRg4DtAgS1aWO+gU52xpH7M9ScGgXSYmAVS9bIJ8EzuaGw0oNAw==}\n    engines: {node: '>=10.14', npm: '>=6', yarn: '>=1'}\n    hasBin: true\n\n  cross-fetch@3.1.8:\n    resolution: {integrity: sha512-cvA+JwZoU0Xq+h6WkMvAUqPEYy92Obet6UdKLfW60qn99ftItKjB5T+BkyWOFWe2pUyfQ+IJHmpOTznqk1M6Kg==}\n\n  cross-fetch@4.0.0:\n    resolution: {integrity: sha512-e4a5N8lVvuLgAWgnCrLr2PP0YyDOTHa9H/Rj54dirp61qXnNq46m82bRhNqIA5VccJtWBvPTFRV3TtvHUKPB1g==}\n\n  cross-inspect@1.0.0:\n    resolution: {integrity: sha512-4PFfn4b5ZN6FMNGSZlyb7wUhuN8wvj8t/VQHZdM4JsDcruGJ8L2kf9zao98QIrBPFCpdk27qst/AGTl7pL3ypQ==}\n    engines: {node: '>=16.0.0'}\n\n  cross-inspect@1.0.1:\n    resolution: {integrity: sha512-Pcw1JTvZLSJH83iiGWt6fRcT+BjZlCDRVwYLbUcHzv/CRpB7r0MlSrGbIyQvVSNyGnbt7G4AXuyCiDR3POvZ1A==}\n    engines: {node: '>=16.0.0'}\n\n  cross-spawn@7.0.6:\n    resolution: {integrity: sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==}\n    engines: {node: '>= 8'}\n\n  crypto-random-string@2.0.0:\n    resolution: {integrity: sha512-v1plID3y9r/lPhviJ1wrXpLeyUIGAZ2SHNYTEapm7/8A9nLPoyvVp3RK/EPFqn5kEznyWgYZNsRtYYIWbuG8KA==}\n    engines: {node: '>=8'}\n\n  css-declaration-sorter@7.2.0:\n    resolution: {integrity: sha512-h70rUM+3PNFuaBDTLe8wF/cdWu+dOZmb7pJt8Z2sedYbAcQVQV/tEchueg3GWxwqS0cxtbxmaHEdkNACqcvsow==}\n    engines: {node: ^14 || ^16 || >=18}\n    peerDependencies:\n      postcss: ^8.0.9\n\n  css-select@5.1.0:\n    resolution: {integrity: sha512-nwoRF1rvRRnnCqqY7updORDsuqKzqYJ28+oSMaJMMgOauh3fvwHqMS7EZpIPqK8GL+g9mKxF1vP/ZjSeNjEVHg==}\n\n  css-tree@2.2.1:\n    resolution: {integrity: sha512-OA0mILzGc1kCOCSJerOeqDxDQ4HOh+G8NbOJFOTgOCzpw7fCBubk0fEyxp8AgOL/jvLgYA/uV0cMbe43ElF1JA==}\n    engines: {node: ^10 || ^12.20.0 || ^14.13.0 || >=15.0.0, npm: '>=7.0.0'}\n\n  css-tree@2.3.1:\n    resolution: {integrity: sha512-6Fv1DV/TYw//QF5IzQdqsNDjx/wc8TrMBZsqjL9eW01tWb7R7k/mq+/VXfJCl7SoD5emsJop9cOByJZfs8hYIw==}\n    engines: {node: ^10 || ^12.20.0 || ^14.13.0 || >=15.0.0}\n\n  css-what@6.1.0:\n    resolution: {integrity: sha512-HTUrgRJ7r4dsZKU6GjmpfRK1O76h97Z8MfS1G0FozR+oF2kG6Vfe8JE6zwrkbxigziPHinCJ+gCPjA9EaBDtRw==}\n    engines: {node: '>= 6'}\n\n  cssesc@3.0.0:\n    resolution: {integrity: sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==}\n    engines: {node: '>=4'}\n    hasBin: true\n\n  cssfilter@0.0.10:\n    resolution: {integrity: sha512-FAaLDaplstoRsDR8XGYH51znUN0UY7nMc6Z9/fvE8EXGwvJE9hu7W2vHwx1+bd6gCYnln9nLbzxFTrcO9YQDZw==}\n\n  cssnano-preset-default@7.0.6:\n    resolution: {integrity: sha512-ZzrgYupYxEvdGGuqL+JKOY70s7+saoNlHSCK/OGn1vB2pQK8KSET8jvenzItcY+kA7NoWvfbb/YhlzuzNKjOhQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  cssnano-utils@5.0.0:\n    resolution: {integrity: sha512-Uij0Xdxc24L6SirFr25MlwC2rCFX6scyUmuKpzI+JQ7cyqDEwD42fJ0xfB3yLfOnRDU5LKGgjQ9FA6LYh76GWQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  cssnano@7.0.6:\n    resolution: {integrity: sha512-54woqx8SCbp8HwvNZYn68ZFAepuouZW4lTwiMVnBErM3VkO7/Sd4oTOt3Zz3bPx3kxQ36aISppyXj2Md4lg8bw==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  csso@5.0.5:\n    resolution: {integrity: sha512-0LrrStPOdJj+SPCCrGhzryycLjwcgUSHBtxNA8aIDxf0GLsRh1cKYhB00Gd1lDOS4yGH69+SNn13+TWbVHETFQ==}\n    engines: {node: ^10 || ^12.20.0 || ^14.13.0 || >=15.0.0, npm: '>=7.0.0'}\n\n  cssstyle@4.1.0:\n    resolution: {integrity: sha512-h66W1URKpBS5YMI/V8PyXvTMFT8SupJ1IzoIV8IeBC/ji8WVmrO8dGlTi+2dh6whmdk6BiKJLD/ZBkhWbcg6nA==}\n    engines: {node: '>=18'}\n\n  csstype@3.1.3:\n    resolution: {integrity: sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==}\n\n  dargs@8.1.0:\n    resolution: {integrity: sha512-wAV9QHOsNbwnWdNW2FYvE1P56wtgSbM+3SZcdGiWQILwVjACCXDCI3Ai8QlCjMDB8YK5zySiXZYBiwGmNY3lnw==}\n    engines: {node: '>=12'}\n\n  data-urls@5.0.0:\n    resolution: {integrity: sha512-ZYP5VBHshaDAiVZxjbRVcFJpc+4xGgT0bK3vzy1HLN8jTO975HEbuYzZJcHoQEY5K1a0z8YayJkyVETa08eNTg==}\n    engines: {node: '>=18'}\n\n  data-view-buffer@1.0.1:\n    resolution: {integrity: sha512-0lht7OugA5x3iJLOWFhWK/5ehONdprk0ISXqVFn/NFrDu+cuc8iADFrGQz5BnRK7LLU3JmkbXSxaqX+/mXYtUA==}\n    engines: {node: '>= 0.4'}\n\n  data-view-byte-length@1.0.1:\n    resolution: {integrity: sha512-4J7wRJD3ABAzr8wP+OcIcqq2dlUKp4DVflx++hs5h5ZKydWMI6/D/fAot+yh6g2tHh8fLFTvNOaVN357NvSrOQ==}\n    engines: {node: '>= 0.4'}\n\n  data-view-byte-offset@1.0.0:\n    resolution: {integrity: sha512-t/Ygsytq+R995EJ5PZlD4Cu56sWa8InXySaViRzw9apusqsOO2bQP+SbYzAhR0pFKoB+43lYy8rWban9JSuXnA==}\n    engines: {node: '>= 0.4'}\n\n  dataloader@2.2.2:\n    resolution: {integrity: sha512-8YnDaaf7N3k/q5HnTJVuzSyLETjoZjVmHc4AeKAzOvKHEFQKcn64OKBfzHYtE9zGjctNM7V9I0MfnUVLpi7M5g==}\n\n  date-fns@4.1.0:\n    resolution: {integrity: sha512-Ukq0owbQXxa/U3EGtsdVBkR1w7KOQ5gIBqdH2hkvknzZPYvBxb/aa6E8L7tmjFtkwZBu3UXBbjIgPo/Ez4xaNg==}\n\n  de-indent@1.0.2:\n    resolution: {integrity: sha512-e/1zu3xH5MQryN2zdVaF0OrdNLUbvWxzMbi+iNA6Bky7l1RoP8a2fIbRocyHclXt/arDrrR6lL3TqFD9pMQTsg==}\n\n  debounce@1.2.1:\n    resolution: {integrity: sha512-XRRe6Glud4rd/ZGQfiV1ruXSfbvfJedlV9Y6zOlP+2K04vBYiJEte6stfFkCP03aMnY5tsipamumUjL14fofug==}\n\n  debug@2.6.9:\n    resolution: {integrity: sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==}\n    peerDependencies:\n      supports-color: '*'\n    peerDependenciesMeta:\n      supports-color:\n        optional: true\n\n  debug@3.1.0:\n    resolution: {integrity: sha512-OX8XqP7/1a9cqkxYw2yXss15f26NKWBpDXQd0/uK/KPqdQhxbPa994hnzjcE2VqQpDslf55723cKPUOGSmMY3g==}\n    peerDependencies:\n      supports-color: '*'\n    peerDependenciesMeta:\n      supports-color:\n        optional: true\n\n  debug@3.2.7:\n    resolution: {integrity: sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==}\n    peerDependencies:\n      supports-color: '*'\n    peerDependenciesMeta:\n      supports-color:\n        optional: true\n\n  debug@4.3.3:\n    resolution: {integrity: sha512-/zxw5+vh1Tfv+4Qn7a5nsbcJKPaSvCDhojn6FEl9vupwK2VCSDtEiEtqr8DFtzYFOdz63LBkxec7DYuc2jon6Q==}\n    engines: {node: '>=6.0'}\n    peerDependencies:\n      supports-color: '*'\n    peerDependenciesMeta:\n      supports-color:\n        optional: true\n\n  debug@4.3.7:\n    resolution: {integrity: sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==}\n    engines: {node: '>=6.0'}\n    peerDependencies:\n      supports-color: '*'\n    peerDependenciesMeta:\n      supports-color:\n        optional: true\n\n  decamelize@1.2.0:\n    resolution: {integrity: sha512-z2S+W9X73hAUUki+N+9Za2lBlun89zigOyGrsax+KUQ6wKW4ZoWpEYBkGhQjwAjjDCkWxhY0VKEhk8wzY7F5cA==}\n    engines: {node: '>=0.10.0'}\n\n  decamelize@4.0.0:\n    resolution: {integrity: sha512-9iE1PgSik9HeIIw2JO94IidnE3eBoQrFJ3w7sFuzSX4DpmZ3v5sZpUiV5Swcf6mQEF+Y0ru8Neo+p+nyh2J+hQ==}\n    engines: {node: '>=10'}\n\n  decimal.js@10.4.3:\n    resolution: {integrity: sha512-VBBaLc1MgL5XpzgIP7ny5Z6Nx3UrRkIViUkPUdtl9aya5amy3De1gsUUSB1g3+3sExYNjCAsAznmukyxCb1GRA==}\n\n  decompress-response@4.2.1:\n    resolution: {integrity: sha512-jOSne2qbyE+/r8G1VU+G/82LBs2Fs4LAsTiLSHOCOMZQl2OKZ6i8i4IyHemTe+/yIXOtTcRQMzPcgyhoFlqPkw==}\n    engines: {node: '>=8'}\n\n  decompress-response@6.0.0:\n    resolution: {integrity: sha512-aW35yZM6Bb/4oJlZncMH2LCoZtJXTRxES17vE3hoRiowU2kWHaJKFkSBDnDR+cm9J+9QhXmREyIfv0pji9ejCQ==}\n    engines: {node: '>=10'}\n\n  dedent@1.5.3:\n    resolution: {integrity: sha512-NHQtfOOW68WD8lgypbLA5oT+Bt0xXJhiYvoR6SmmNXZfpzOGXwdKWmcwG8N7PwVVWV3eF/68nmD9BaJSsTBhyQ==}\n    peerDependencies:\n      babel-plugin-macros: ^3.1.0\n    peerDependenciesMeta:\n      babel-plugin-macros:\n        optional: true\n\n  deep-eql@5.0.2:\n    resolution: {integrity: sha512-h5k/5U50IJJFpzfL6nO9jaaumfjO/f2NjK/oYB2Djzm4p9L+3T9qWpZqZ2hAbLPuuYq9wrU08WQyBTL5GbPk5Q==}\n    engines: {node: '>=6'}\n\n  deep-equal@2.2.3:\n    resolution: {integrity: sha512-ZIwpnevOurS8bpT4192sqAowWM76JDKSHYzMLty3BZGSswgq6pBaH3DhCSW5xVAZICZyKdOBPjwww5wfgT/6PA==}\n    engines: {node: '>= 0.4'}\n\n  deep-extend@0.6.0:\n    resolution: {integrity: sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA==}\n    engines: {node: '>=4.0.0'}\n\n  deep-is@0.1.4:\n    resolution: {integrity: sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==}\n\n  deepmerge@4.3.1:\n    resolution: {integrity: sha512-3sUqbMEc77XqpdNO7FRyRog+eW3ph+GYCbj+rK+uYyRMuwsVy0rMiVtPn+QJlKFvWP/1PYpapqYn0Me2knFn+A==}\n    engines: {node: '>=0.10.0'}\n\n  default-browser-id@3.0.0:\n    resolution: {integrity: sha512-OZ1y3y0SqSICtE8DE4S8YOE9UZOJ8wO16fKWVP5J1Qz42kV9jcnMVFrEE/noXb/ss3Q4pZIH79kxofzyNNtUNA==}\n    engines: {node: '>=12'}\n\n  default-browser-id@5.0.0:\n    resolution: {integrity: sha512-A6p/pu/6fyBcA1TRz/GqWYPViplrftcW2gZC9q79ngNCKAeR/X3gcEdXQHl4KNXV+3wgIJ1CPkJQ3IHM6lcsyA==}\n    engines: {node: '>=18'}\n\n  default-browser@4.0.0:\n    resolution: {integrity: sha512-wX5pXO1+BrhMkSbROFsyxUm0i/cJEScyNhA4PPxc41ICuv05ZZB/MX28s8aZx6xjmatvebIapF6hLEKEcpneUA==}\n    engines: {node: '>=14.16'}\n\n  default-browser@5.2.1:\n    resolution: {integrity: sha512-WY/3TUME0x3KPYdRRxEJJvXRHV4PyPoUsxtZa78lwItwRQRHhd2U9xOscaT/YTf8uCXIAjeJOFBVEh/7FtD8Xg==}\n    engines: {node: '>=18'}\n\n  defaults@1.0.4:\n    resolution: {integrity: sha512-eFuaLoy/Rxalv2kr+lqMlUnrDWV+3j4pljOIJgLIhI058IQfWJ7vXhyEIHu+HtC738klGALYxOKDO0bQP3tg8A==}\n\n  define-data-property@1.1.4:\n    resolution: {integrity: sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==}\n    engines: {node: '>= 0.4'}\n\n  define-lazy-prop@3.0.0:\n    resolution: {integrity: sha512-N+MeXYoqr3pOgn8xfyRPREN7gHakLYjhsHhWGT3fWAiL4IkAt0iDw14QiiEm2bE30c5XX5q0FtAA3CK5f9/BUg==}\n    engines: {node: '>=12'}\n\n  define-properties@1.2.1:\n    resolution: {integrity: sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==}\n    engines: {node: '>= 0.4'}\n\n  defu@6.1.4:\n    resolution: {integrity: sha512-mEQCMmwJu317oSz8CwdIOdwf3xMif1ttiM8LTufzc3g6kR+9Pe236twL8j3IYT1F7GfRgGcW6MWxzZjLIkuHIg==}\n\n  delayed-stream@1.0.0:\n    resolution: {integrity: sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==}\n    engines: {node: '>=0.4.0'}\n\n  delegates@1.0.0:\n    resolution: {integrity: sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ==}\n\n  denque@2.1.0:\n    resolution: {integrity: sha512-HVQE3AAb/pxF8fQAoiqpvg9i3evqug3hoiwakOyZAwJm+6vZehbkYXZ0l4JxS+I3QxM97v5aaRNhj8v5oBhekw==}\n    engines: {node: '>=0.10'}\n\n  depd@2.0.0:\n    resolution: {integrity: sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==}\n    engines: {node: '>= 0.8'}\n\n  dependency-graph@0.11.0:\n    resolution: {integrity: sha512-JeMq7fEshyepOWDfcfHK06N3MhyPhz++vtqWhMT5O9A3K42rdsEDpfdVqjaqaAhsw6a+ZqeDvQVtD0hFHQWrzg==}\n    engines: {node: '>= 0.6.0'}\n\n  dequal@2.0.3:\n    resolution: {integrity: sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==}\n    engines: {node: '>=6'}\n\n  destroy@1.2.0:\n    resolution: {integrity: sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==}\n    engines: {node: '>= 0.8', npm: 1.2.8000 || >= 1.4.16}\n\n  detect-indent@6.1.0:\n    resolution: {integrity: sha512-reYkTUJAZb9gUuZ2RvVCNhVHdg62RHnJ7WJl8ftMi4diZ6NWlciOzQN88pUhSELEwflJht4oQDv0F0BMlwaYtA==}\n    engines: {node: '>=8'}\n\n  detect-libc@1.0.3:\n    resolution: {integrity: sha512-pGjwhsmsp4kL2RTz08wcOlGN83otlqHeD/Z5T8GXZB+/YcpQ/dgo+lbU8ZsGxV0HIvqqxo9l7mqYwyYMD9bKDg==}\n    engines: {node: '>=0.10'}\n    hasBin: true\n\n  detect-libc@2.0.3:\n    resolution: {integrity: sha512-bwy0MGW55bG41VqxxypOsdSdGqLwXPI/focwgTYCFMbdUiBAxLg9CFzG08sz2aqzknwiX7Hkl0bQENjg8iLByw==}\n    engines: {node: '>=8'}\n\n  detect-newline@3.1.0:\n    resolution: {integrity: sha512-TLz+x/vEXm/Y7P7wn1EJFNLxYpUD4TgMosxY6fAVJUnJMbupHBOncxyWUG9OpTaH9EBD7uFI5LfEgmMOc54DsA==}\n    engines: {node: '>=8'}\n\n  detect-node@2.1.0:\n    resolution: {integrity: sha512-T0NIuQpnTvFDATNuHN5roPwSBG83rFsuO+MXXH9/3N1eFbn4wcPjttvjMLEPWJ0RGUYgQE7cGgS3tNxbqCGM7g==}\n\n  dezalgo@1.0.4:\n    resolution: {integrity: sha512-rXSP0bf+5n0Qonsb+SVVfNfIsimO4HEtmnIpPHY8Q1UCzKlQrDMfdobr8nJOOsRgWCyMRqeSBQzmWUMq7zvVig==}\n\n  didyoumean@1.2.2:\n    resolution: {integrity: sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==}\n\n  diff-sequences@29.6.3:\n    resolution: {integrity: sha512-EjePK1srD3P08o2j4f0ExnylqRs5B9tJjcp9t1krH2qRi8CCdsYfwe9JgSLurFBWwq4uOlipzfk5fHNvwFKr8Q==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  diff@4.0.2:\n    resolution: {integrity: sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==}\n    engines: {node: '>=0.3.1'}\n\n  diff@5.0.0:\n    resolution: {integrity: sha512-/VTCrvm5Z0JGty/BWHljh+BAiw3IK+2j87NGMu8Nwc/f48WoDAC395uomO9ZD117ZOBaHmkX1oyLvkVM/aIT3w==}\n    engines: {node: '>=0.3.1'}\n\n  dioc@3.0.2:\n    resolution: {integrity: sha512-D8S1vMTtBeXeUW2dR0rJ7xiPHxp1zm1NzO2B4Aj4RAJB6E6urA0/xD/CnGs6J1JkgUZvUgaC+oedx/k5NrT+/g==}\n    peerDependencies:\n      vue: 3.5.12\n    peerDependenciesMeta:\n      vue:\n        optional: true\n\n  dir-glob@3.0.1:\n    resolution: {integrity: sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==}\n    engines: {node: '>=8'}\n\n  display-notification@2.0.0:\n    resolution: {integrity: sha512-TdmtlAcdqy1NU+j7zlkDdMnCL878zriLaBmoD9quOoq1ySSSGv03l0hXK5CvIFZlIfFI/hizqdQuW+Num7xuhw==}\n    engines: {node: '>=4'}\n\n  dlv@1.1.3:\n    resolution: {integrity: sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==}\n\n  doctrine@3.0.0:\n    resolution: {integrity: sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==}\n    engines: {node: '>=6.0.0'}\n\n  doctypes@1.1.0:\n    resolution: {integrity: sha512-LLBi6pEqS6Do3EKQ3J0NqHWV5hhb78Pi8vvESYwyOy2c31ZEZVdtitdzsQsKb7878PEERhzUk0ftqGhG6Mz+pQ==}\n\n  dom-serializer@1.4.1:\n    resolution: {integrity: sha512-VHwB3KfrcOOkelEG2ZOfxqLZdfkil8PtJi4P8N2MMXucZq2yLp75ClViUlOVwyoHEDjYU433Aq+5zWP61+RGag==}\n\n  dom-serializer@2.0.0:\n    resolution: {integrity: sha512-wIkAryiqt/nV5EQKqQpo3SToSOV9J0DnbJqwK7Wv/Trc92zIAYZ4FlMu+JPFW1DfGFt81ZTCGgDEabffXeLyJg==}\n\n  domelementtype@2.3.0:\n    resolution: {integrity: sha512-OLETBj6w0OsagBwdXnPdN0cnMfF9opN69co+7ZrbfPGrdpPVNBUj02spi6B1N7wChLQiPn4CSH/zJvXw56gmHw==}\n\n  domhandler@3.3.0:\n    resolution: {integrity: sha512-J1C5rIANUbuYK+FuFL98650rihynUOEzRLxW+90bKZRWB6A1X1Tf82GxR1qAWLyfNPRvjqfip3Q5tdYlmAa9lA==}\n    engines: {node: '>= 4'}\n\n  domhandler@4.3.1:\n    resolution: {integrity: sha512-GrwoxYN+uWlzO8uhUXRl0P+kHE4GtVPfYzVLcUxPL7KNdHKj66vvlhiweIHqYYXWlw+T8iLMp42Lm67ghw4WMQ==}\n    engines: {node: '>= 4'}\n\n  domhandler@5.0.3:\n    resolution: {integrity: sha512-cgwlv/1iFQiFnU96XXgROh8xTeetsnJiDsTc7TYCLFd9+/WNkIqPTxiM/8pSd8VIrhXGTf1Ny1q1hquVqDJB5w==}\n    engines: {node: '>= 4'}\n\n  domutils@2.8.0:\n    resolution: {integrity: sha512-w96Cjofp72M5IIhpjgobBimYEfoPjx1Vx0BSX9P30WBdZW2WIKU0T1Bd0kz2eNZ9ikjKgHbEyKx8BB6H1L3h3A==}\n\n  domutils@3.1.0:\n    resolution: {integrity: sha512-H78uMmQtI2AhgDJjWeQmHwJJ2bLPD3GMmO7Zja/ZZh84wkm+4ut+IUnUdRa8uCGX88DiVx1j6FRe1XfxEgjEZA==}\n\n  dot-case@3.0.4:\n    resolution: {integrity: sha512-Kv5nKlh6yRrdrGvxeJ2e5y2eRUpkUosIW4A2AS38zwSz27zu7ufDwQPi5Jhs3XAlGNetl3bmnGhQsMtkKJnj3w==}\n\n  dot-prop@5.3.0:\n    resolution: {integrity: sha512-QM8q3zDe58hqUqjraQOmzZ1LIH9SWQJTlEKCH4kJ2oQvLZk7RbQXvtDM2XEq3fwkV9CCvvH4LA0AV+ogFsBM2Q==}\n    engines: {node: '>=8'}\n\n  dotenv-expand@10.0.0:\n    resolution: {integrity: sha512-GopVGCpVS1UKH75VKHGuQFqS1Gusej0z4FyQkPdwjil2gNIv+LNsqBlboOzpJFZKVT95GkCyWJbBSdFEFUWI2A==}\n    engines: {node: '>=12'}\n\n  dotenv@16.4.5:\n    resolution: {integrity: sha512-ZmdL2rui+eB2YwhsWzjInR8LldtZHGDoQ1ugH85ppHKwpUHL7j7rN0Ti9NCnGiQbhaZ11FpR+7ao1dNsmduNUg==}\n    engines: {node: '>=12'}\n\n  dset@3.1.4:\n    resolution: {integrity: sha512-2QF/g9/zTaPDc3BjNcVTGoBbXBgYfMTTceLaYcFJ/W9kggFUkhxD/hMEeuLKbugyef9SqAx8cpgwlIP/jinUTA==}\n    engines: {node: '>=4'}\n\n  duplexer@0.1.2:\n    resolution: {integrity: sha512-jtD6YG370ZCIi/9GTaJKQxWTZD045+4R4hTk/x1UyoqadyJ9x9CgSi1RlVDQF8U2sxLLSnFkCaMihqljHIWgMg==}\n\n  dynamic-dedupe@0.3.0:\n    resolution: {integrity: sha512-ssuANeD+z97meYOqd50e04Ze5qp4bPqo8cCkI4TRjZkzAUgIDTrXV1R8QCdINpiI+hw14+rYazvTRdQrz0/rFQ==}\n\n  eastasianwidth@0.2.0:\n    resolution: {integrity: sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==}\n\n  ecdsa-sig-formatter@1.0.11:\n    resolution: {integrity: sha512-nagl3RYrbNv6kQkeJIpt6NJZy8twLB/2vtz6yN9Z4vRKHN4/QZJIEbqohALSgwKdnksuY3k5Addp5lg8sVoVcQ==}\n\n  ee-first@1.1.1:\n    resolution: {integrity: sha512-WMwm9LhRUo+WUaRN+vRuETqG89IgZphVSNkdFgeb6sS/E4OrDIN7t48CAewSHXc6C8lefD8KKfr5vY61brQlow==}\n\n  ejs@3.1.10:\n    resolution: {integrity: sha512-UeJmFfOrAQS8OJWPZ4qtgHyWExa088/MtK5UEyoJGFH67cDEXkZSviOiKRCZ4Xij0zxI3JECgYs3oKx+AizQBA==}\n    engines: {node: '>=0.10.0'}\n    hasBin: true\n\n  electron-to-chromium@1.5.35:\n    resolution: {integrity: sha512-hOSRInrIDm0Brzp4IHW2F/VM+638qOL2CzE0DgpnGzKW27C95IqqeqgKz/hxHGnvPxvQGpHUGD5qRVC9EZY2+A==}\n\n  emittery@0.13.1:\n    resolution: {integrity: sha512-DeWwawk6r5yR9jFgnDKYt4sLS0LmHJJi3ZOnb5/JdbYwj3nW+FxQnHIjhBKz8YLC7oRNPVM9NQ47I3CVx34eqQ==}\n    engines: {node: '>=12'}\n\n  emoji-regex@10.4.0:\n    resolution: {integrity: sha512-EC+0oUMY1Rqm4O6LLrgjtYDvcVYTy7chDnM4Q7030tP4Kwj3u/pR6gP9ygnp2CJMK5Gq+9Q2oqmrFJAz01DXjw==}\n\n  emoji-regex@8.0.0:\n    resolution: {integrity: sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==}\n\n  emoji-regex@9.2.2:\n    resolution: {integrity: sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==}\n\n  encodeurl@1.0.2:\n    resolution: {integrity: sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==}\n    engines: {node: '>= 0.8'}\n\n  encodeurl@2.0.0:\n    resolution: {integrity: sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==}\n    engines: {node: '>= 0.8'}\n\n  encoding-japanese@2.0.0:\n    resolution: {integrity: sha512-++P0RhebUC8MJAwJOsT93dT+5oc5oPImp1HubZpAuCZ5kTLnhuuBhKHj2jJeO/Gj93idPBWmIuQ9QWMe5rX3pQ==}\n    engines: {node: '>=8.10.0'}\n\n  encoding-japanese@2.1.0:\n    resolution: {integrity: sha512-58XySVxUgVlBikBTbQ8WdDxBDHIdXucB16LO5PBHR8t75D54wQrNo4cg+58+R1CtJfKnsVsvt9XlteRaR8xw1w==}\n    engines: {node: '>=8.10.0'}\n\n  end-of-stream@1.4.4:\n    resolution: {integrity: sha512-+uw1inIHVPQoaVuHzRyXd21icM+cnt4CzD5rW+NC1wjOUSTOs+Te7FOv7AhN7vS9x/oIyhLP5PR1H+phQAHu5Q==}\n\n  engine.io-client@3.5.4:\n    resolution: {integrity: sha512-ydc8uuMMDxC5KCKNJN3zZKYJk2sgyTuTZQ7Aj1DJSsLKAcizA/PzWivw8fZMIjJVBo2CJOYzntv4FSjY/Lr//g==}\n\n  engine.io-client@6.6.1:\n    resolution: {integrity: sha512-aYuoak7I+R83M/BBPIOs2to51BmFIpC1wZe6zZzMrT2llVsHy5cvcmdsJgP2Qz6smHu+sD9oexiSUAVd8OfBPw==}\n\n  engine.io-parser@2.2.1:\n    resolution: {integrity: sha512-x+dN/fBH8Ro8TFwJ+rkB2AmuVw9Yu2mockR/p3W8f8YtExwFgDvBDi0GWyb4ZLkpahtDGZgtr3zLovanJghPqg==}\n\n  engine.io-parser@5.2.3:\n    resolution: {integrity: sha512-HqD3yTBfnBxIrbnM1DoD6Pcq8NECnh8d4As1Qgh0z5Gg3jRRIqijury0CL3ghu/edArpUYiYqQiDUQBIs4np3Q==}\n    engines: {node: '>=10.0.0'}\n\n  enhanced-resolve@2.3.0:\n    resolution: {integrity: sha512-n6e4bsCpzsP0OB76X+vEWhySUQI8GHPVFVK+3QkX35tbryy2WoeGeK5kQ+oxzgDVHjIZyz5fyS60Mi3EpQLc0Q==}\n    engines: {node: '>=0.6'}\n\n  enhanced-resolve@5.17.1:\n    resolution: {integrity: sha512-LMHl3dXhTcfv8gM4kEzIUeTQ+7fpdA0l2tUf34BddXPkz2A5xJ5L/Pchd5BL6rdccM9QGvu0sWZzK1Z1t4wwyg==}\n    engines: {node: '>=10.13.0'}\n\n  entities@2.2.0:\n    resolution: {integrity: sha512-p92if5Nz619I0w+akJrLZH0MX0Pb5DX39XOwQTtXSdQQOaYH03S1uIQp4mhOZtAXrxq4ViO67YTiLBo2638o9A==}\n\n  entities@3.0.1:\n    resolution: {integrity: sha512-WiyBqoomrwMdFG1e0kqvASYfnlb0lp8M5o5Fw2OFq1hNZxxcNk8Ik0Xm7LxzBhuidnZB/UtBqVCgUz3kBOP51Q==}\n    engines: {node: '>=0.12'}\n\n  entities@4.5.0:\n    resolution: {integrity: sha512-V0hjH4dGPh9Ao5p0MoRY6BVqtwCjhz6vI5LT8AJ55H+4g9/4vbHx1I54fS0XuclLhDHArPQCiMjDxjaL8fPxhw==}\n    engines: {node: '>=0.12'}\n\n  env-paths@2.2.1:\n    resolution: {integrity: sha512-+h1lkLKhZMTYjog1VEpJNG7NZJWcuc2DDk/qsqSTRRCOXiLjeQ1d1/udrUGhqMxUgAlwKNZ0cf2uqan5GLuS2A==}\n    engines: {node: '>=6'}\n\n  environment@1.1.0:\n    resolution: {integrity: sha512-xUtoPkMggbz0MPyPiIWr1Kp4aeWJjDZ6SMvURhimjdZgsRuDplF5/s9hcgGhyXMhs+6vpnuoiZ2kFiu3FMnS8Q==}\n    engines: {node: '>=18'}\n\n  errno@0.1.8:\n    resolution: {integrity: sha512-dJ6oBr5SQ1VSd9qkk7ByRgb/1SH4JZjCHSW/mr63/QcXO9zLVxvJ6Oy13nio03rxpSnVDDjFor75SjVeZWPW/A==}\n    hasBin: true\n\n  error-ex@1.3.2:\n    resolution: {integrity: sha512-7dFHNmqeFSEt2ZBsCriorKnn3Z2pj+fd9kmI6QoWw4//DL+icEBfc0U7qJCisqrTsKTjw4fNFy2pW9OqStD84g==}\n\n  error-stack-parser-es@0.1.5:\n    resolution: {integrity: sha512-xHku1X40RO+fO8yJ8Wh2f2rZWVjqyhb1zgq1yZ8aZRQkv6OOKhKWRUaht3eSCUbAOBaKIgM+ykwFLE+QUxgGeg==}\n\n  es-abstract@1.23.3:\n    resolution: {integrity: sha512-e+HfNH61Bj1X9/jLc5v1owaLYuHdeHHSQlkhCBiTK8rBvKaULl/beGMxwrMXjpYrv4pz22BlY570vVePA2ho4A==}\n    engines: {node: '>= 0.4'}\n\n  es-define-property@1.0.0:\n    resolution: {integrity: sha512-jxayLKShrEqqzJ0eumQbVhTYQM27CfT1T35+gCgDFoL82JLsXqTJ76zv6A0YLOgEnLUMvLzsDsGIrl8NFpT2gQ==}\n    engines: {node: '>= 0.4'}\n\n  es-errors@1.3.0:\n    resolution: {integrity: sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==}\n    engines: {node: '>= 0.4'}\n\n  es-get-iterator@1.1.3:\n    resolution: {integrity: sha512-sPZmqHBe6JIiTfN5q2pEi//TwxmAFHwj/XEuYjTuse78i8KxaqMTTzxPoFKuzRpDpTJ+0NAbpfenkmH2rePtuw==}\n\n  es-module-lexer@1.5.4:\n    resolution: {integrity: sha512-MVNK56NiMrOwitFB7cqDwq0CQutbw+0BvLshJSse0MUNU+y1FC3bUS/AQg7oUng+/wKrrki7JfmwtVHkVfPLlw==}\n\n  es-object-atoms@1.0.0:\n    resolution: {integrity: sha512-MZ4iQ6JwHOBQjahnjwaC1ZtIBH+2ohjamzAO3oaHcXYup7qxjF2fixyH+Q71voWHeOkI2q/TnJao/KfXYIZWbw==}\n    engines: {node: '>= 0.4'}\n\n  es-set-tostringtag@2.0.3:\n    resolution: {integrity: sha512-3T8uNMC3OQTHkFUsFq8r/BwAXLHvU/9O9mE0fBc/MY5iq/8H7ncvO947LmYA6ldWw9Uh8Yhf25zu6n7nML5QWQ==}\n    engines: {node: '>= 0.4'}\n\n  es-to-primitive@1.2.1:\n    resolution: {integrity: sha512-QCOllgZJtaUo9miYBcLChTUaHNjJF3PYs1VidD7AwiEj1kYxKeQTctLAezAOH5ZKRH0g2IgPn6KwB4IT8iRpvA==}\n    engines: {node: '>= 0.4'}\n\n  esbuild@0.17.19:\n    resolution: {integrity: sha512-XQ0jAPFkK/u3LcVRcvVHQcTIqD6E2H1fvZMA5dQPSOWb3suUbWbfbRf94pjc0bNzRYLfIrDRQXr7X+LHIm5oHw==}\n    engines: {node: '>=12'}\n    hasBin: true\n\n  esbuild@0.18.20:\n    resolution: {integrity: sha512-ceqxoedUrcayh7Y7ZX6NdbbDzGROiyVBgC4PriJThBKSVPWnnFHZAkfI1lJT8QFkOwH4qOS2SJkS4wvpGl8BpA==}\n    engines: {node: '>=12'}\n    hasBin: true\n\n  esbuild@0.21.5:\n    resolution: {integrity: sha512-mg3OPMV4hXywwpoDxu3Qda5xCKQi+vCTZq8S9J/EpkhB2HzKXq4SNFZE3+NK93JYxc8VMSep+lOUSC/RVKaBqw==}\n    engines: {node: '>=12'}\n    hasBin: true\n\n  esbuild@0.23.1:\n    resolution: {integrity: sha512-VVNz/9Sa0bs5SELtn3f7qhJCDPCF5oMEl5cO9/SSinpE9hbPVvxbd572HH5AKiP7WD8INO53GgfDDhRjkylHEg==}\n    engines: {node: '>=18'}\n    hasBin: true\n\n  esbuild@0.24.0:\n    resolution: {integrity: sha512-FuLPevChGDshgSicjisSooU0cemp/sGXR841D5LHMB7mTVOmsEHcAxaH3irL53+8YDIeVNQEySh4DaYU/iuPqQ==}\n    engines: {node: '>=18'}\n    hasBin: true\n\n  escalade@3.1.2:\n    resolution: {integrity: sha512-ErCHMCae19vR8vQGe50xIsVomy19rg6gFu3+r3jkEO46suLMWBksvVyoGgQV+jOfl84ZSOSlmv6Gxa89PmTGmA==}\n    engines: {node: '>=6'}\n\n  escalade@3.2.0:\n    resolution: {integrity: sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==}\n    engines: {node: '>=6'}\n\n  escape-goat@3.0.0:\n    resolution: {integrity: sha512-w3PwNZJwRxlp47QGzhuEBldEqVHHhh8/tIPcl6ecf2Bou99cdAt0knihBV0Ecc7CGxYduXVBDheH1K2oADRlvw==}\n    engines: {node: '>=10'}\n\n  escape-html@1.0.3:\n    resolution: {integrity: sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==}\n\n  escape-string-applescript@1.0.0:\n    resolution: {integrity: sha512-4/hFwoYaC6TkpDn9A3pTC52zQPArFeXuIfhUtCGYdauTzXVP9H3BDr3oO/QzQehMpLDC7srvYgfwvImPFGfvBA==}\n    engines: {node: '>=0.10.0'}\n\n  escape-string-regexp@1.0.5:\n    resolution: {integrity: sha512-vbRorB5FUQWvla16U8R/qgaFIya2qGzwDrNmCZuYKrbdSUMG6I1ZCGQRefkRVhuOkIGVne7BQ35DSfo1qvJqFg==}\n    engines: {node: '>=0.8.0'}\n\n  escape-string-regexp@2.0.0:\n    resolution: {integrity: sha512-UpzcLCXolUWcNu5HtVMHYdXJjArjsF9C0aNnquZYY4uW/Vu0miy5YoWvbV345HauVvcAUnpRuhMMcqTcGOY2+w==}\n    engines: {node: '>=8'}\n\n  escape-string-regexp@4.0.0:\n    resolution: {integrity: sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==}\n    engines: {node: '>=10'}\n\n  escodegen@2.1.0:\n    resolution: {integrity: sha512-2NlIDTwUWJN0mRPQOdtQBzbUHvdGY2P1VXSyU83Q3xKxM7WHX2Ql8dKq782Q9TgQUNOLEzEYu9bzLNj1q88I5w==}\n    engines: {node: '>=6.0'}\n    hasBin: true\n\n  eslint-config-prettier@9.1.0:\n    resolution: {integrity: sha512-NSWl5BFQWEPi1j4TjVNItzYV7dZXZ+wP6I6ZhrBGpChQhZRUaElihE9uRRkcbRnNb76UMKDF3r+WTmNcGPKsqw==}\n    hasBin: true\n    peerDependencies:\n      eslint: '>=7.0.0'\n\n  eslint-plugin-prettier@4.2.1:\n    resolution: {integrity: sha512-f/0rXLXUt0oFYs8ra4w49wYZBG5GKZpAYsJSm6rnYL5uVDjd+zowwMwVZHnAjf4edNrKpCDYfXDgmRE/Ak7QyQ==}\n    engines: {node: '>=12.0.0'}\n    peerDependencies:\n      eslint: '>=7.28.0'\n      eslint-config-prettier: '*'\n      prettier: '>=2.0.0'\n    peerDependenciesMeta:\n      eslint-config-prettier:\n        optional: true\n\n  eslint-plugin-prettier@5.2.1:\n    resolution: {integrity: sha512-gH3iR3g4JfF+yYPaJYkN7jEl9QbweL/YfkoRlNnuIEHEz1vHVlCmWOS+eGGiRuzHQXdJFCOTxRgvju9b8VUmrw==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n    peerDependencies:\n      '@types/eslint': '>=8.0.0'\n      eslint: '>=8.0.0'\n      eslint-config-prettier: '*'\n      prettier: '>=3.0.0'\n    peerDependenciesMeta:\n      '@types/eslint':\n        optional: true\n      eslint-config-prettier:\n        optional: true\n\n  eslint-plugin-vue@9.17.0:\n    resolution: {integrity: sha512-r7Bp79pxQk9I5XDP0k2dpUC7Ots3OSWgvGZNu3BxmKK6Zg7NgVtcOB6OCna5Kb9oQwJPl5hq183WD0SY5tZtIQ==}\n    engines: {node: ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.2.0 || ^7.0.0 || ^8.0.0\n\n  eslint-plugin-vue@9.29.0:\n    resolution: {integrity: sha512-hamyjrBhNH6Li6R1h1VF9KHfshJlKgKEg3ARbGTn72CMNDSMhWbgC7NdkRDEh25AFW+4SDATzyNM+3gWuZii8g==}\n    engines: {node: ^14.17.0 || >=16.0.0}\n    peerDependencies:\n      eslint: ^6.2.0 || ^7.0.0 || ^8.0.0 || ^9.0.0\n\n  eslint-scope@5.1.1:\n    resolution: {integrity: sha512-2NxwbF/hZ0KpepYN0cNbo+FN6XoK7GaHlQhgx/hIZl6Va0bF45RQOOwhLIy8lQDbuCiadSLCBnH2CFYquit5bw==}\n    engines: {node: '>=8.0.0'}\n\n  eslint-scope@7.2.2:\n    resolution: {integrity: sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  eslint-scope@8.1.0:\n    resolution: {integrity: sha512-14dSvlhaVhKKsa9Fx1l8A17s7ah7Ef7wCakJ10LYk6+GYmP9yDti2oq2SEwcyndt6knfcZyhyxwY3i9yL78EQw==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  eslint-utils@2.1.0:\n    resolution: {integrity: sha512-w94dQYoauyvlDc43XnGB8lU3Zt713vNChgt4EWwhXAP2XkBvndfxF0AgIqKOOasjPIPzj9JqgwkwbCYD0/V3Zg==}\n    engines: {node: '>=6'}\n\n  eslint-visitor-keys@1.3.0:\n    resolution: {integrity: sha512-6J72N8UNa462wa/KFODt/PJ3IU60SDpC3QXC1Hjc1BXXpfL2C9R5+AU7jhe0F6GREqVMh4Juu+NY7xn+6dipUQ==}\n    engines: {node: '>=4'}\n\n  eslint-visitor-keys@3.4.3:\n    resolution: {integrity: sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  eslint-visitor-keys@4.1.0:\n    resolution: {integrity: sha512-Q7lok0mqMUSf5a/AdAZkA5a/gHcO6snwQClVNNvFKCAVlxXucdU8pKydU5ZVZjBx5xr37vGbFFWtLQYreLzrZg==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  eslint@8.47.0:\n    resolution: {integrity: sha512-spUQWrdPt+pRVP1TTJLmfRNJJHHZryFmptzcafwSvHsceV81djHOdnEeDmkdotZyLNjDhrOasNK8nikkoG1O8Q==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    deprecated: This version is no longer supported. Please see https://eslint.org/version-support for other options.\n    hasBin: true\n\n  eslint@8.57.0:\n    resolution: {integrity: sha512-dZ6+mexnaTIbSBZWgou51U6OmzIhYM2VcNdtiTtI7qPNZm35Akpr0f6vtw3w1Kmn5PYo+tZVfh13WrhpS6oLqQ==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n    deprecated: This version is no longer supported. Please see https://eslint.org/version-support for other options.\n    hasBin: true\n\n  eslint@9.12.0:\n    resolution: {integrity: sha512-UVIOlTEWxwIopRL1wgSQYdnVDcEvs2wyaO6DGo5mXqe3r16IoCNWkR29iHhyaP4cICWjbgbmFUGAhh0GJRuGZw==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n    hasBin: true\n    peerDependencies:\n      jiti: '*'\n    peerDependenciesMeta:\n      jiti:\n        optional: true\n\n  espree@10.2.0:\n    resolution: {integrity: sha512-upbkBJbckcCNBDBDXEbuhjbP68n+scUd3k/U2EkyM9nw+I/jPiL4cLF/Al06CF96wRltFda16sxDFrxsI1v0/g==}\n    engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n\n  espree@6.2.1:\n    resolution: {integrity: sha512-ysCxRQY3WaXJz9tdbWOwuWr5Y/XrPTGX9Kiz3yoUXwW0VZ4w30HTkQLaGx/+ttFjF8i+ACbArnB4ce68a9m5hw==}\n    engines: {node: '>=6.0.0'}\n\n  espree@9.6.1:\n    resolution: {integrity: sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  esprima-extract-comments@1.1.0:\n    resolution: {integrity: sha512-sBQUnvJwpeE9QnPrxh7dpI/dp67erYG4WXEAreAMoelPRpMR7NWb4YtwRPn9b+H1uLQKl/qS8WYmyaljTpjIsw==}\n    engines: {node: '>=4'}\n\n  esprima@1.2.5:\n    resolution: {integrity: sha512-S9VbPDU0adFErpDai3qDkjq8+G05ONtKzcyNrPKg/ZKa+tf879nX2KexNU95b31UoTJjRLInNBHHHjFPoCd7lQ==}\n    engines: {node: '>=0.4.0'}\n    hasBin: true\n\n  esprima@4.0.1:\n    resolution: {integrity: sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==}\n    engines: {node: '>=4'}\n    hasBin: true\n\n  esquery@1.6.0:\n    resolution: {integrity: sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==}\n    engines: {node: '>=0.10'}\n\n  esrecurse@4.3.0:\n    resolution: {integrity: sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==}\n    engines: {node: '>=4.0'}\n\n  estraverse@1.9.3:\n    resolution: {integrity: sha512-25w1fMXQrGdoquWnScXZGckOv+Wes+JDnuN/+7ex3SauFRS72r2lFDec0EKPt2YD1wUJ/IrfEex+9yp4hfSOJA==}\n    engines: {node: '>=0.10.0'}\n\n  estraverse@4.3.0:\n    resolution: {integrity: sha512-39nnKffWz8xN1BU/2c79n9nB9HDzo0niYUqx6xyqUnyoAnQyyWpOTdZEeiCch8BBu515t4wp9ZmgVfVhn9EBpw==}\n    engines: {node: '>=4.0'}\n\n  estraverse@5.3.0:\n    resolution: {integrity: sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==}\n    engines: {node: '>=4.0'}\n\n  estree-walker@0.6.1:\n    resolution: {integrity: sha512-SqmZANLWS0mnatqbSfRP5g8OXZC12Fgg1IwNtLsyHDzJizORW4khDfjPqJZsemPWBB2uqykUah5YpQ6epsqC/w==}\n\n  estree-walker@1.0.1:\n    resolution: {integrity: sha512-1fMXF3YP4pZZVozF8j/ZLfvnR8NSIljt56UhbZ5PeeDmmGHpgpdwQt7ITlGvYaQukCvuBRMLEiKiYC+oeIg4cg==}\n\n  estree-walker@2.0.2:\n    resolution: {integrity: sha512-Rfkk/Mp/DL7JVje3u18FxFujQlTNR2q6QfMSMB7AvCBx91NGj/ba3kCfza0f6dVDbw7YlRf/nDrn7pQrCCyQ/w==}\n\n  estree-walker@3.0.3:\n    resolution: {integrity: sha512-7RUKfXgSMMkzt6ZuXmqapOurLGPPfgj6l9uRZ7lRGolvk0y2yocc35LdcxKC5PQZdn2DMqioAQ2NoWcrTKmm6g==}\n\n  esutils@2.0.3:\n    resolution: {integrity: sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==}\n    engines: {node: '>=0.10.0'}\n\n  etag@1.8.1:\n    resolution: {integrity: sha512-aIL5Fx7mawVa300al2BnEE4iNvo1qETxLrPI/o05L7z6go7fCw1J6EQmbK4FmJ2AS7kgVF/KEZWufBfdClMcPg==}\n    engines: {node: '>= 0.6'}\n\n  event-stream@4.0.1:\n    resolution: {integrity: sha512-qACXdu/9VHPBzcyhdOWR5/IahhGMf0roTeZJfzz077GwylcDd90yOHLouhmv7GJ5XzPi6ekaQWd8AvPP2nOvpA==}\n\n  event-target-shim@5.0.1:\n    resolution: {integrity: sha512-i/2XbnSz/uxRCU6+NdVJgKWDTM427+MqYbkQzD321DuCQJUqOuJKIA0IM2+W2xtYHdKOmZ4dR6fExsd4SXL+WQ==}\n    engines: {node: '>=6'}\n\n  eventemitter3@3.1.2:\n    resolution: {integrity: sha512-tvtQIeLVHjDkJYnzf2dgVMxfuSGJeM/7UCG17TT4EumTfNtF+0nebF/4zWOIkCreAbtNqhGEboB6BWrwqNaw4Q==}\n\n  eventemitter3@4.0.7:\n    resolution: {integrity: sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==}\n\n  eventemitter3@5.0.1:\n    resolution: {integrity: sha512-GWkBvjiSZK87ELrYOSESUYeVIc9mvLLf/nXalMOS5dYrgZq9o5OVkbZAVM06CVxYsCwH9BDZFPlQTlPA1j4ahA==}\n\n  events@3.3.0:\n    resolution: {integrity: sha512-mQw+2fkQbALzQ7V0MY0IqdnXNOeTtP4r0lN9z7AAawCXgqea7bDii20AYrIBrFd/Hx0M2Ocz6S111CaFkUcb0Q==}\n    engines: {node: '>=0.8.x'}\n\n  execa@0.10.0:\n    resolution: {integrity: sha512-7XOMnz8Ynx1gGo/3hyV9loYNPWM94jG3+3T3Y8tsfSstFmETmENCMU/A/zj8Lyaj1lkgEepKepvd6240tBRvlw==}\n    engines: {node: '>=4'}\n\n  execa@5.1.1:\n    resolution: {integrity: sha512-8uSpZZocAZRBAPIEINJj3Lo9HyGitllczc27Eh5YYojjMFMn8yHMDMaUHE2Jqfq05D/wucwI4JGURyXt1vchyg==}\n    engines: {node: '>=10'}\n\n  execa@7.2.0:\n    resolution: {integrity: sha512-UduyVP7TLB5IcAQl+OzLyLcS/l32W/GLg+AhHJ+ow40FOk2U3SAllPwR44v4vmdFwIWqpdwxxpQbF1n5ta9seA==}\n    engines: {node: ^14.18.0 || ^16.14.0 || >=18.0.0}\n\n  execa@8.0.1:\n    resolution: {integrity: sha512-VyhnebXciFV2DESc+p6B+y0LjSm0krU4OgJN44qFAhBY0TJ+1V61tYD2+wHusZ6F9n5K+vl8k0sTy7PEfV4qpg==}\n    engines: {node: '>=16.17'}\n\n  exit@0.1.2:\n    resolution: {integrity: sha512-Zk/eNKV2zbjpKzrsQ+n1G6poVbErQxJ0LBOJXaKZ1EViLzH+hrLu9cdXI4zw9dBQJslwBEpbQ2P1oS7nDxs6jQ==}\n    engines: {node: '>= 0.8.0'}\n\n  expand-template@2.0.3:\n    resolution: {integrity: sha512-XYfuKMvj4O35f/pOXLObndIRvyQ+/+6AhODh+OKWj9S9498pHHn/IMszH+gt0fBCRWMNfk1ZSp5x3AifmnI2vg==}\n    engines: {node: '>=6'}\n\n  expect@29.7.0:\n    resolution: {integrity: sha512-2Zks0hf1VLFYI1kbh0I5jP3KHHyCHpkfyHBzsSXRFgl/Bg9mWYfMW8oD+PdMPlEwy5HNsR9JutYy6pMeOh61nw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  express-session@1.18.1:\n    resolution: {integrity: sha512-a5mtTqEaZvBCL9A9aqkrtfz+3SMDhOVUnjafjo+s7A9Txkq+SVX2DLvSp1Zrv4uCXa3lMSK3viWnh9Gg07PBUA==}\n    engines: {node: '>= 0.8.0'}\n\n  express@4.20.0:\n    resolution: {integrity: sha512-pLdae7I6QqShF5PnNTCVn4hI91Dx0Grkn2+IAsMTgMIKuQVte2dN9PeGSSAME2FR8anOhVA62QDIUaWVfEXVLw==}\n    engines: {node: '>= 0.10.0'}\n\n  express@4.21.0:\n    resolution: {integrity: sha512-VqcNGcj/Id5ZT1LZ/cfihi3ttTn+NJmkli2eZADigjq29qTlWi/hAQ43t/VLPq8+UX06FCEx3ByOYet6ZFblng==}\n    engines: {node: '>= 0.10.0'}\n\n  express@4.21.1:\n    resolution: {integrity: sha512-YSFlK1Ee0/GC8QaO91tHcDxJiE/X4FbpAyQWkxAvG6AXCuR65YzK8ua6D9hvi/TzUfZMpc+BwuM1IPw8fmQBiQ==}\n    engines: {node: '>= 0.10.0'}\n\n  extend-object@1.0.0:\n    resolution: {integrity: sha512-0dHDIXC7y7LDmCh/lp1oYkmv73K25AMugQI07r8eFopkW6f7Ufn1q+ETMsJjnV9Am14SlElkqy3O92r6xEaxPw==}\n\n  external-editor@3.1.0:\n    resolution: {integrity: sha512-hMQ4CX1p1izmuLYyZqLMO/qGNw10wSv9QDCPfzXfyFrOaCSSoRfqE1Kf1s5an66J5JZC62NewG+mK49jOCtQew==}\n    engines: {node: '>=4'}\n\n  extract-comments@1.1.0:\n    resolution: {integrity: sha512-dzbZV2AdSSVW/4E7Ti5hZdHWbA+Z80RJsJhr5uiL10oyjl/gy7/o+HI1HwK4/WSZhlq4SNKU3oUzXlM13Qx02Q==}\n    engines: {node: '>=6'}\n\n  extract-files@11.0.0:\n    resolution: {integrity: sha512-FuoE1qtbJ4bBVvv94CC7s0oTnKUGvQs+Rjf1L2SJFfS+HTVVjhPFtehPdQ0JiGPqVNfSSZvL5yzHHQq2Z4WNhQ==}\n    engines: {node: ^12.20 || >= 14.13}\n\n  fast-decode-uri-component@1.0.1:\n    resolution: {integrity: sha512-WKgKWg5eUxvRZGwW8FvfbaH7AXSh2cL+3j5fMGzUMCxWBJ3dV3a7Wz8y2f/uQ0e3B6WmodD3oS54jTQ9HVTIIg==}\n\n  fast-deep-equal@3.1.3:\n    resolution: {integrity: sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==}\n\n  fast-diff@1.3.0:\n    resolution: {integrity: sha512-VxPP4NqbUjj6MaAOafWeUn2cXWLcCtljklUtZf0Ind4XQ+QPtmA0b18zZy0jIQx+ExRVCR/ZQpBmik5lXshNsw==}\n\n  fast-glob@3.3.2:\n    resolution: {integrity: sha512-oX2ruAFQwf/Orj8m737Y5adxDQO0LAB7/S5MnxCdTNDd4p6BsyIVsv9JQsATbTSq8KHRpLwIHbVlUNatxd+1Ow==}\n    engines: {node: '>=8.6.0'}\n\n  fast-json-stable-stringify@2.1.0:\n    resolution: {integrity: sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==}\n\n  fast-levenshtein@2.0.6:\n    resolution: {integrity: sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==}\n\n  fast-querystring@1.1.2:\n    resolution: {integrity: sha512-g6KuKWmFXc0fID8WWH0jit4g0AGBoJhCkJMb1RmbsSEUNvQ+ZC8D6CUZ+GtF8nMzSPXnhiePyyqqipzNNEnHjg==}\n\n  fast-safe-stringify@2.1.1:\n    resolution: {integrity: sha512-W+KJc2dmILlPplD/H4K9l9LcAHAfPtP6BY84uVLXQ6Evcz9Lcg33Y2z1IVblT6xdY54PXYVHEv+0Wpq8Io6zkA==}\n\n  fast-uri@3.0.2:\n    resolution: {integrity: sha512-GR6f0hD7XXyNJa25Tb9BuIdN0tdr+0BMi6/CJPH3wJO1JjNG3n/VsSw38AwRdKZABm8lGbPfakLRkYzx2V9row==}\n\n  fast-url-parser@1.1.3:\n    resolution: {integrity: sha512-5jOCVXADYNuRkKFzNJ0dCCewsZiYo0dz8QNYljkOpFC6r2U4OBmKtvm/Tsuh4w1YYdDqDb31a8TVhBJ2OJKdqQ==}\n\n  fastq@1.17.1:\n    resolution: {integrity: sha512-sRVD3lWVIXWg6By68ZN7vho9a1pQcN/WBFaAAsDDFzlJjvoGx0P8z7V1t72grFJfJhu3YPZBuu25f7Kaw2jN1w==}\n\n  fb-watchman@2.0.2:\n    resolution: {integrity: sha512-p5161BqbuCaSnB8jIbzQHOlpgsPmK5rJVDfDKO91Axs5NC1uu3HRQm6wt9cd9/+GtQQIO53JdGXXoyDpTAsgYA==}\n\n  fbjs-css-vars@1.0.2:\n    resolution: {integrity: sha512-b2XGFAFdWZWg0phtAWLHCk836A1Xann+I+Dgd3Gk64MHKZO44FfoD1KxyvbSh0qZsIoXQGGlVztIY+oitJPpRQ==}\n\n  fbjs@3.0.5:\n    resolution: {integrity: sha512-ztsSx77JBtkuMrEypfhgc3cI0+0h+svqeie7xHbh1k/IKdcydnvadp/mUaGgjAOXQmQSxsqgaRhS3q9fy+1kxg==}\n\n  fd-slicer@1.1.0:\n    resolution: {integrity: sha512-cE1qsB/VwyQozZ+q1dGxR8LBYNZeofhEdUNGSMbQD3Gw2lAzX9Zb3uIU6Ebc/Fmyjo9AWWfnn0AUCHqtevs/8g==}\n\n  fdir@6.4.2:\n    resolution: {integrity: sha512-KnhMXsKSPZlAhp7+IjUkRZKPb4fUyccpDrdFXbi4QL1qkmFh9kVY09Yox+n4MaOb3lHZ1Tv829C3oaaXoMYPDQ==}\n    peerDependencies:\n      picomatch: ^3 || ^4\n    peerDependenciesMeta:\n      picomatch:\n        optional: true\n\n  figures@3.2.0:\n    resolution: {integrity: sha512-yaduQFRKLXYOGgEn6AZau90j3ggSOyiqXU0F9JZfeXYhNa+Jk4X+s45A2zg5jns87GAFa34BBm2kXw4XpNcbdg==}\n    engines: {node: '>=8'}\n\n  file-entry-cache@6.0.1:\n    resolution: {integrity: sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==}\n    engines: {node: ^10.12.0 || >=12.0.0}\n\n  file-entry-cache@8.0.0:\n    resolution: {integrity: sha512-XXTUwCvisa5oacNGRP9SfNtYBNAMi+RPwBFmblZEF7N7swHYQS6/Zfk7SRwx4D5j3CH211YNRco1DEMNVfZCnQ==}\n    engines: {node: '>=16.0.0'}\n\n  file-type@3.9.0:\n    resolution: {integrity: sha512-RLoqTXE8/vPmMuTI88DAzhMYC99I8BWv7zYP4A1puo5HIjEJ5EX48ighy4ZyKMG9EDXxBgW6e++cn7d1xuFghA==}\n    engines: {node: '>=0.10.0'}\n\n  filelist@1.0.4:\n    resolution: {integrity: sha512-w1cEuf3S+DrLCQL7ET6kz+gmlJdbq9J7yXCSjK/OZCPA+qEN1WyF4ZAf0YYJa4/shHJra2t/d/r8SV4Ji+x+8Q==}\n\n  fill-range@7.1.1:\n    resolution: {integrity: sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==}\n    engines: {node: '>=8'}\n\n  finalhandler@1.2.0:\n    resolution: {integrity: sha512-5uXcUVftlQMFnWC9qu/svkWv3GTd2PfUhK/3PLkYNAe7FbqJMt3515HaxE6eRL74GdsriiwujiawdaB1BpEISg==}\n    engines: {node: '>= 0.8'}\n\n  finalhandler@1.3.1:\n    resolution: {integrity: sha512-6BN9trH7bp3qvnrRyzsBz+g3lZxTNZTbVO2EV1CS0WIcDbawYVdYvGflME/9QP0h0pYlCDBCTjYa9nZzMDpyxQ==}\n    engines: {node: '>= 0.8'}\n\n  find-up@4.1.0:\n    resolution: {integrity: sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==}\n    engines: {node: '>=8'}\n\n  find-up@5.0.0:\n    resolution: {integrity: sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==}\n    engines: {node: '>=10'}\n\n  find-up@7.0.0:\n    resolution: {integrity: sha512-YyZM99iHrqLKjmt4LJDj58KI+fYyufRLBSYcqycxf//KpBk9FoewoGX0450m9nB44qrZnovzC2oeP5hUibxc/g==}\n    engines: {node: '>=18'}\n\n  fixpack@4.0.0:\n    resolution: {integrity: sha512-5SM1+H2CcuJ3gGEwTiVo/+nd/hYpNj9Ch3iMDOQ58ndY+VGQ2QdvaUTkd3otjZvYnd/8LF/HkJ5cx7PBq0orCQ==}\n    hasBin: true\n\n  flat-cache@3.2.0:\n    resolution: {integrity: sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==}\n    engines: {node: ^10.12.0 || >=12.0.0}\n\n  flat-cache@4.0.1:\n    resolution: {integrity: sha512-f7ccFPK3SXFHpx15UIGyRJ/FJQctuKZ0zVuN3frBo4HnK3cay9VEW0R6yPYFHC0AgqhukPzKjq22t5DmAyqGyw==}\n    engines: {node: '>=16'}\n\n  flat@5.0.2:\n    resolution: {integrity: sha512-b6suED+5/3rTpUBdG1gupIl8MPFCAMA0QXwmljLhvCUKcUvdE4gWky9zpuGCcXHOsz4J9wPGNWq6OKpmIzz3hQ==}\n    hasBin: true\n\n  flatted@3.3.1:\n    resolution: {integrity: sha512-X8cqMLLie7KsNUDSdzeN8FYK9rEt4Dt67OsG/DNGnYTSDBG4uFAJFBnUeiV+zCVAvwFy56IjM9sH51jVaEhNxw==}\n\n  follow-redirects@1.15.6:\n    resolution: {integrity: sha512-wWN62YITEaOpSK584EZXJafH1AGpO8RVgElfkuXbTOrPX4fIfOyEpW/CsiNd8JdYrAoOvafRTOEnvsO++qCqFA==}\n    engines: {node: '>=4.0'}\n    peerDependencies:\n      debug: '*'\n    peerDependenciesMeta:\n      debug:\n        optional: true\n\n  for-each@0.3.3:\n    resolution: {integrity: sha512-jqYfLp7mo9vIyQf8ykW2v7A+2N4QjeCeI5+Dz9XraiO1ign81wjiH7Fb9vSOWvQfNtmSa4H2RoQTrrXivdUZmw==}\n\n  foreground-child@3.3.0:\n    resolution: {integrity: sha512-Ld2g8rrAyMYFXBhEqMz8ZAHBi4J4uS1i/CxGMDnjyFWddMXLVcDp051DZfu+t7+ab7Wv6SMqpWmyFIj5UbfFvg==}\n    engines: {node: '>=14'}\n\n  fork-ts-checker-webpack-plugin@9.0.2:\n    resolution: {integrity: sha512-Uochze2R8peoN1XqlSi/rGUkDQpRogtLFocP9+PGu68zk1BDAKXfdeCdyVZpgTk8V8WFVQXdEz426VKjXLO1Gg==}\n    engines: {node: '>=12.13.0', yarn: '>=1.0.0'}\n    peerDependencies:\n      typescript: '>3.6.0'\n      webpack: ^5.11.0\n\n  form-data@4.0.0:\n    resolution: {integrity: sha512-ETEklSGi5t0QMZuiXoA/Q6vcnxcLQP5vdugSpuAyi6SVGi2clPPp+xgEhuMaHC+zGgn31Kd235W35f7Hykkaww==}\n    engines: {node: '>= 6'}\n\n  form-data@4.0.1:\n    resolution: {integrity: sha512-tzN8e4TX8+kkxGPK8D5u0FNmjPUjw3lwC9lSLxxoB/+GtsJG91CO8bSWy73APlgAZzZbXEYZJuxjkHH2w+Ezhw==}\n    engines: {node: '>= 6'}\n\n  formidable@3.5.1:\n    resolution: {integrity: sha512-WJWKelbRHN41m5dumb0/k8TeAx7Id/y3a+Z7QfhxP/htI9Js5zYaEDtG8uMgG0vM0lOlqnmjE99/kfpOYi/0Og==}\n\n  forwarded@0.2.0:\n    resolution: {integrity: sha512-buRG0fpBtRHSTCOASe6hD258tEubFoRLb4ZNA6NxMVHNw2gOcwHo9wyablzMzOA5z9xA9L1KNjk/Nt6MT9aYow==}\n    engines: {node: '>= 0.6'}\n\n  fp-ts@2.16.1:\n    resolution: {integrity: sha512-by7U5W8dkIzcvDofUcO42yl9JbnHTEDBrzu3pt5fKT+Z4Oy85I21K80EYJYdjQGC2qum4Vo55Ag57iiIK4FYuA==}\n\n  fp-ts@2.16.9:\n    resolution: {integrity: sha512-+I2+FnVB+tVaxcYyQkHUq7ZdKScaBlX53A41mxQtpIccsfyv8PzdzP7fzp2AY832T4aoK6UZ5WRX/ebGd8uZuQ==}\n\n  fraction.js@4.3.7:\n    resolution: {integrity: sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==}\n\n  fresh@0.5.2:\n    resolution: {integrity: sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==}\n    engines: {node: '>= 0.6'}\n\n  from@0.1.7:\n    resolution: {integrity: sha512-twe20eF1OxVxp/ML/kq2p1uc6KvFK/+vs8WjEbeKmV2He22MKm7YF2ANIt+EOqhJ5L3K/SuuPhk0hWQDjOM23g==}\n\n  fs-constants@1.0.0:\n    resolution: {integrity: sha512-y6OAwoSIf7FyjMIv94u+b5rdheZEjzR63GTyZJm5qh4Bi+2YgwLCcI/fPFZkL5PSixOt6ZNKm+w+Hfp/Bciwow==}\n\n  fs-extra@10.1.0:\n    resolution: {integrity: sha512-oRXApq54ETRj4eMiFzGnHWGy+zo5raudjuxN0b8H7s/RU2oW0Wvsx9O0ACRN/kRq9E8Vu/ReskGB5o3ji+FzHQ==}\n    engines: {node: '>=12'}\n\n  fs-extra@11.2.0:\n    resolution: {integrity: sha512-PmDi3uwK5nFuXh7XDTlVnS17xJS7vW36is2+w3xcv8SVxiB4NyATf4ctkVY5bkSjX0Y4nbvZCq1/EjtEyr9ktw==}\n    engines: {node: '>=14.14'}\n\n  fs-extra@9.1.0:\n    resolution: {integrity: sha512-hcg3ZmepS30/7BSFqRvoo3DOMQu7IjqxO5nCDt+zM9XWjb33Wg7ziNT+Qvqbuc3+gWpzO02JubVyk2G4Zvo1OQ==}\n    engines: {node: '>=10'}\n\n  fs-minipass@2.1.0:\n    resolution: {integrity: sha512-V/JgOLFCS+R6Vcq0slCuaeWEdNC3ouDlJMNIsacH2VtALiu9mV4LPrHc5cDl8k5aw6J8jwgWWpiTo5RYhmIzvg==}\n    engines: {node: '>= 8'}\n\n  fs-monkey@1.0.6:\n    resolution: {integrity: sha512-b1FMfwetIKymC0eioW7mTywihSQE4oLzQn1dB6rZB5fx/3NpNEdAWeCSMB+60/AeT0TCXsxzAlcYVEFCTAksWg==}\n\n  fs.realpath@1.0.0:\n    resolution: {integrity: sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==}\n\n  fsevents@2.3.3:\n    resolution: {integrity: sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==}\n    engines: {node: ^8.16.0 || ^10.6.0 || >=11.0.0}\n    os: [darwin]\n\n  function-bind@1.1.2:\n    resolution: {integrity: sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==}\n\n  function.prototype.name@1.1.6:\n    resolution: {integrity: sha512-Z5kx79swU5P27WEayXM1tBi5Ze/lbIyiNgU3qyXUOf9b2rgXYyF9Dy9Cx+IQv/Lc8WCG6L82zwUPpSS9hGehIg==}\n    engines: {node: '>= 0.4'}\n\n  functions-have-names@1.2.3:\n    resolution: {integrity: sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==}\n\n  gauge@3.0.2:\n    resolution: {integrity: sha512-+5J6MS/5XksCuXq++uFRsnUd7Ovu1XenbeuIuNRJxYWjgQbPuFhT14lAvsWfqfAmnwluf1OwMjz39HjfLPci0Q==}\n    engines: {node: '>=10'}\n    deprecated: This package is no longer supported.\n\n  gensync@1.0.0-beta.2:\n    resolution: {integrity: sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==}\n    engines: {node: '>=6.9.0'}\n\n  get-caller-file@2.0.5:\n    resolution: {integrity: sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==}\n    engines: {node: 6.* || 8.* || >= 10.*}\n\n  get-east-asian-width@1.3.0:\n    resolution: {integrity: sha512-vpeMIQKxczTD/0s2CdEWHcb0eeJe6TFjxb+J5xgX7hScxqrGuyjmv4c1D4A/gelKfyox0gJJwIHF+fLjeaM8kQ==}\n    engines: {node: '>=18'}\n\n  get-intrinsic@1.2.4:\n    resolution: {integrity: sha512-5uYhsJH8VJBTv7oslg4BznJYhDoRI6waYCxMmCdnTrcCrHA/fCFKoTFz2JKKE0HdDFUF7/oQuhzumXJK7paBRQ==}\n    engines: {node: '>= 0.4'}\n\n  get-own-enumerable-property-symbols@3.0.2:\n    resolution: {integrity: sha512-I0UBV/XOz1XkIJHEUDMZAbzCThU/H8DxmSfmdGcKPnVhu2VfFqr34jr9777IyaTYvxjedWhqVIilEDsCdP5G6g==}\n\n  get-package-type@0.1.0:\n    resolution: {integrity: sha512-pjzuKtY64GYfWizNAJ0fr9VqttZkNiK2iS430LtIHzjBEr6bX8Am2zm4sW4Ro5wjWW5cAlRL1qAMTcXbjNAO2Q==}\n    engines: {node: '>=8.0.0'}\n\n  get-port@5.1.1:\n    resolution: {integrity: sha512-g/Q1aTSDOxFpchXC4i8ZWvxA1lnPqx/JHqcpIw0/LX9T8x/GBbi6YnlN5nhaKIFkT8oFsscUKgDJYxfwfS6QsQ==}\n    engines: {node: '>=8'}\n\n  get-stream@3.0.0:\n    resolution: {integrity: sha512-GlhdIUuVakc8SJ6kK0zAFbiGzRFzNnY4jUuEbV9UROo4Y+0Ny4fjvcZFVTeDA4odpFyOQzaw6hXukJSq/f28sQ==}\n    engines: {node: '>=4'}\n\n  get-stream@6.0.1:\n    resolution: {integrity: sha512-ts6Wi+2j3jQjqi70w5AlN8DFnkSwC+MqmxEzdEALB2qXZYV3X/b1CTfgPLGJNMeAWxdPfU8FO1ms3NUfaHCPYg==}\n    engines: {node: '>=10'}\n\n  get-stream@8.0.1:\n    resolution: {integrity: sha512-VaUJspBffn/LMCJVoMvSAdmscJyS1auj5Zulnn5UoYcY531UWmdwhRWkcGKnGU93m5HSXP9LP2usOryrBtQowA==}\n    engines: {node: '>=16'}\n\n  get-symbol-description@1.0.2:\n    resolution: {integrity: sha512-g0QYk1dZBxGwk+Ngc+ltRH2IBp2f7zBkBMBJZCDerh6EhlhSR6+9irMCuT/09zD6qkarHUSn529sK/yL4S27mg==}\n    engines: {node: '>= 0.4'}\n\n  git-raw-commits@4.0.0:\n    resolution: {integrity: sha512-ICsMM1Wk8xSGMowkOmPrzo2Fgmfo4bMHLNX6ytHjajRJUqvHOw/TFapQ+QG75c3X/tTDDhOSRPGC52dDbNM8FQ==}\n    engines: {node: '>=16'}\n    hasBin: true\n\n  github-from-package@0.0.0:\n    resolution: {integrity: sha512-SyHy3T1v2NUXn29OsWdxmK6RwHD+vkj3v8en8AOBZ1wBQ/hCAQ5bAQTD02kW4W9tUp/3Qh6J8r9EvntiyCmOOw==}\n\n  glob-parent@5.1.2:\n    resolution: {integrity: sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==}\n    engines: {node: '>= 6'}\n\n  glob-parent@6.0.2:\n    resolution: {integrity: sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==}\n    engines: {node: '>=10.13.0'}\n\n  glob-to-regexp@0.4.1:\n    resolution: {integrity: sha512-lkX1HJXwyMcprw/5YUZc2s7DrpAiHB21/V+E1rHUrVNokkvB6bqMzT0VfV6/86ZNabt1k14YOIaT7nDvOX3Iiw==}\n\n  glob@10.3.12:\n    resolution: {integrity: sha512-TCNv8vJ+xz4QiqTpfOJA7HvYv+tNIRHKfUWw/q+v2jdgN4ebz+KY9tGx5J4rHP0o84mNP+ApH66HRX8us3Khqg==}\n    engines: {node: '>=16 || 14 >=14.17'}\n    hasBin: true\n\n  glob@10.4.2:\n    resolution: {integrity: sha512-GwMlUF6PkPo3Gk21UxkCohOv0PLcIXVtKyLlpEI28R/cO/4eNOdmLk3CMW1wROV/WR/EsZOWAfBbBOqYvs88/w==}\n    engines: {node: '>=16 || 14 >=14.18'}\n    hasBin: true\n\n  glob@11.0.0:\n    resolution: {integrity: sha512-9UiX/Bl6J2yaBbxKoEBRm4Cipxgok8kQYcOPEhScPwebu2I0HoQOuYdIO6S3hLuWoZgpDpwQZMzTFxgpkyT76g==}\n    engines: {node: 20 || >=22}\n    hasBin: true\n\n  glob@7.2.0:\n    resolution: {integrity: sha512-lmLf6gtyrPq8tTjSmrO94wBeQbFR3HbLHbuyD69wuyQkImp2hWqMGB47OX65FBkPffO641IP9jWa1z4ivqG26Q==}\n    deprecated: Glob versions prior to v9 are no longer supported\n\n  glob@7.2.3:\n    resolution: {integrity: sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==}\n    deprecated: Glob versions prior to v9 are no longer supported\n\n  global-directory@4.0.1:\n    resolution: {integrity: sha512-wHTUcDUoZ1H5/0iVqEudYW4/kAlN5cZ3j/bXn0Dpbizl9iaUVeWSHqiOjsgk6OW2bkLclbBjzewBz6weQ1zA2Q==}\n    engines: {node: '>=18'}\n\n  globals@11.12.0:\n    resolution: {integrity: sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==}\n    engines: {node: '>=4'}\n\n  globals@13.24.0:\n    resolution: {integrity: sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==}\n    engines: {node: '>=8'}\n\n  globals@14.0.0:\n    resolution: {integrity: sha512-oahGvuMGQlPw/ivIYBjVSrWAfWLBeku5tpPE2fOPLi+WHffIWbuh2tCjhyQhTBPMf5E9jDEH4FOmTYgYwbKwtQ==}\n    engines: {node: '>=18'}\n\n  globalthis@1.0.4:\n    resolution: {integrity: sha512-DpLKbNU4WylpxJykQujfCcwYWiV/Jhm50Goo0wrVILAv5jOr9d+H+UR3PhSCD2rCCEIg0uc+G+muBTwD54JhDQ==}\n    engines: {node: '>= 0.4'}\n\n  globby@11.1.0:\n    resolution: {integrity: sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==}\n    engines: {node: '>=10'}\n\n  gopd@1.0.1:\n    resolution: {integrity: sha512-d65bNlIadxvpb/A2abVdlqKqV563juRnZ1Wtk6s1sIR8uNsXR70xqIzVqxVf1eTqDunwT2MkczEeaezCKTZhwA==}\n\n  graceful-fs@4.2.11:\n    resolution: {integrity: sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==}\n\n  graphemer@1.4.0:\n    resolution: {integrity: sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==}\n\n  graphql-config@4.5.0:\n    resolution: {integrity: sha512-x6D0/cftpLUJ0Ch1e5sj1TZn6Wcxx4oMfmhaG9shM0DKajA9iR+j1z86GSTQ19fShbGvrSSvbIQsHku6aQ6BBw==}\n    engines: {node: '>= 10.0.0'}\n    peerDependencies:\n      cosmiconfig-toml-loader: ^1.0.0\n      graphql: ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n    peerDependenciesMeta:\n      cosmiconfig-toml-loader:\n        optional: true\n\n  graphql-config@5.1.3:\n    resolution: {integrity: sha512-RBhejsPjrNSuwtckRlilWzLVt2j8itl74W9Gke1KejDTz7oaA5kVd6wRn9zK9TS5mcmIYGxf7zN7a1ORMdxp1Q==}\n    engines: {node: '>= 16.0.0'}\n    peerDependencies:\n      cosmiconfig-toml-loader: ^1.0.0\n      graphql: ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n    peerDependenciesMeta:\n      cosmiconfig-toml-loader:\n        optional: true\n\n  graphql-language-service-interface@2.10.2:\n    resolution: {integrity: sha512-RKIEBPhRMWdXY3fxRs99XysTDnEgAvNbu8ov/5iOlnkZsWQNzitjtd0O0l1CutQOQt3iXoHde7w8uhCnKL4tcg==}\n    deprecated: this package has been merged into graphql-language-service\n    peerDependencies:\n      graphql: ^15.5.0 || ^16.0.0\n\n  graphql-language-service-parser@1.10.4:\n    resolution: {integrity: sha512-duDE+0aeKLFVrb9Kf28U84ZEHhHcvTjWIT6dJbIAQJWBaDoht0D4BK9EIhd94I3DtKRc1JCJb2+70y1lvP/hiA==}\n    deprecated: this package has been merged into graphql-language-service\n    peerDependencies:\n      graphql: ^15.5.0 || ^16.0.0\n\n  graphql-language-service-types@1.8.7:\n    resolution: {integrity: sha512-LP/Mx0nFBshYEyD0Ny6EVGfacJAGVx+qXtlJP4hLzUdBNOGimfDNtMVIdZANBXHXcM41MDgMHTnyEx2g6/Ttbw==}\n    deprecated: this package has been merged into graphql-language-service\n    peerDependencies:\n      graphql: ^15.5.0 || ^16.0.0\n\n  graphql-language-service-utils@2.7.1:\n    resolution: {integrity: sha512-Wci5MbrQj+6d7rfvbORrA9uDlfMysBWYaG49ST5TKylNaXYFf3ixFOa74iM1KtM9eidosUbI3E1JlWi0JaidJA==}\n    deprecated: this package has been merged into graphql-language-service\n    peerDependencies:\n      graphql: ^15.5.0 || ^16.0.0\n\n  graphql-query-complexity@1.0.0:\n    resolution: {integrity: sha512-Tj7mRIuKWjGomPaRW5E+ztY8bhYPf1v/7bkDPuzksrR3GqHeIS5jxzX8CfimlV3g9z0lT20RG9JgaUUjhRjtOA==}\n    peerDependencies:\n      graphql: ^14.6.0 || ^15.0.0 || ^16.0.0\n\n  graphql-redis-subscriptions@2.6.1:\n    resolution: {integrity: sha512-ssTviFZFB4P7nvZEPpIsP0gvBMJe5IcgR80Mjit/UFUk0snbkxG/gtNZoglQGtN+kvDx8H6MfALBSG0bm11KCA==}\n    peerDependencies:\n      graphql-subscriptions: ^1.0.0 || ^2.0.0\n\n  graphql-request@6.1.0:\n    resolution: {integrity: sha512-p+XPfS4q7aIpKVcgmnZKhMNqhltk20hfXtkaIkTfjjmiKMJ5xrt5c743cL03y/K7y1rg3WrIC49xGiEQ4mxdNw==}\n    peerDependencies:\n      graphql: 14 - 16\n\n  graphql-subscriptions@2.0.0:\n    resolution: {integrity: sha512-s6k2b8mmt9gF9pEfkxsaO1lTxaySfKoEJzEfmwguBbQ//Oq23hIXCfR1hm4kdh5hnR20RdwB+s3BCb+0duHSZA==}\n    peerDependencies:\n      graphql: ^15.7.2 || ^16.0.0\n\n  graphql-tag@2.12.6:\n    resolution: {integrity: sha512-FdSNcu2QQcWnM2VNvSCCDCVS5PpPqpzgFT8+GXzqJuoDd0CBncxCY278u4mhRO7tMgo2JjgJA5aZ+nWSQ/Z+xg==}\n    engines: {node: '>=10'}\n    peerDependencies:\n      graphql: ^0.9.0 || ^0.10.0 || ^0.11.0 || ^0.12.0 || ^0.13.0 || ^14.0.0 || ^15.0.0 || ^16.0.0\n\n  graphql-ws@5.12.1:\n    resolution: {integrity: sha512-umt4f5NnMK46ChM2coO36PTFhHouBrK9stWWBczERguwYrGnPNxJ9dimU6IyOBfOkC6Izhkg4H8+F51W/8CYDg==}\n    engines: {node: '>=10'}\n    peerDependencies:\n      graphql: '>=0.11 <=16'\n\n  graphql-ws@5.16.0:\n    resolution: {integrity: sha512-Ju2RCU2dQMgSKtArPbEtsK5gNLnsQyTNIo/T7cZNp96niC1x0KdJNZV0TIoilceBPQwfb5itrGl8pkFeOUMl4A==}\n    engines: {node: '>=10'}\n    peerDependencies:\n      graphql: '>=0.11 <=16'\n\n  graphql@16.9.0:\n    resolution: {integrity: sha512-GGTKBX4SD7Wdb8mqeDLni2oaRGYQWjWHGKPQ24ZMnUtKfcsVoiv4uX8+LJr1K6U5VW2Lu1BwJnj7uiori0YtRw==}\n    engines: {node: ^12.22.0 || ^14.16.0 || ^16.0.0 || >=17.0.0}\n\n  growl@1.10.5:\n    resolution: {integrity: sha512-qBr4OuELkhPenW6goKVXiv47US3clb3/IbuWF9KNKEijAy9oeHxU9IgzjvJhHkUzhaj7rOUD7+YGWqUjLp5oSA==}\n    engines: {node: '>=4.x'}\n\n  handlebars@4.7.8:\n    resolution: {integrity: sha512-vafaFqs8MZkRrSX7sFVUdo3ap/eNiLnb4IakshzvP56X5Nr1iGKAIqdX6tMlm6HcNRIkr6AxO5jFEoJzzpT8aQ==}\n    engines: {node: '>=0.4.7'}\n    hasBin: true\n\n  har-schema@2.0.0:\n    resolution: {integrity: sha512-Oqluz6zhGX8cyRaTQlFMPw80bSJVG2x/cFb8ZPhUILGgHka9SsokCCOQgpveePerqidZOrT14ipqfJb7ILcW5Q==}\n    engines: {node: '>=4'}\n\n  has-bigints@1.0.2:\n    resolution: {integrity: sha512-tSvCKtBr9lkF0Ex0aQiP9N+OpV4zi2r/Nee5VkRDbaqv35RLYMzbwQfFSZZH0kR+Rd6302UJZ2p/bJCEoR3VoQ==}\n\n  has-binary2@1.0.3:\n    resolution: {integrity: sha512-G1LWKhDSvhGeAQ8mPVQlqNcOB2sJdwATtZKl2pDKKHfpf/rYj24lkinxf69blJbnsvtqqNU+L3SL50vzZhXOnw==}\n\n  has-cors@1.1.0:\n    resolution: {integrity: sha512-g5VNKdkFuUuVCP9gYfDJHjK2nqdQJ7aDLTnycnc2+RvsOQbuLdF5pm7vuE5J76SEBIQjs4kQY/BWq74JUmjbXA==}\n\n  has-flag@3.0.0:\n    resolution: {integrity: sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==}\n    engines: {node: '>=4'}\n\n  has-flag@4.0.0:\n    resolution: {integrity: sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==}\n    engines: {node: '>=8'}\n\n  has-own-prop@2.0.0:\n    resolution: {integrity: sha512-Pq0h+hvsVm6dDEa8x82GnLSYHOzNDt7f0ddFa3FqcQlgzEiptPqL+XrOJNavjOzSYiYWIrgeVYYgGlLmnxwilQ==}\n    engines: {node: '>=8'}\n\n  has-property-descriptors@1.0.2:\n    resolution: {integrity: sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==}\n\n  has-proto@1.0.3:\n    resolution: {integrity: sha512-SJ1amZAJUiZS+PhsVLf5tGydlaVB8EdFpaSO4gmiUKUOxk8qzn5AIy4ZeJUmh22znIdk/uMAUT2pl3FxzVUH+Q==}\n    engines: {node: '>= 0.4'}\n\n  has-symbols@1.0.3:\n    resolution: {integrity: sha512-l3LCuF6MgDNwTDKkdYGEihYjt5pRPbEg46rtlmnSPlUbgmB8LOIrKJbYYFBSbnPaJexMKtiPO8hmeRjRz2Td+A==}\n    engines: {node: '>= 0.4'}\n\n  has-tostringtag@1.0.2:\n    resolution: {integrity: sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==}\n    engines: {node: '>= 0.4'}\n\n  has-unicode@2.0.1:\n    resolution: {integrity: sha512-8Rf9Y83NBReMnx0gFzA8JImQACstCYWUplepDa9xprwwtmgEZUF0h/i5xSA625zB/I37EtrswSST6OXxwaaIJQ==}\n\n  hasown@2.0.2:\n    resolution: {integrity: sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==}\n    engines: {node: '>= 0.4'}\n\n  he@1.2.0:\n    resolution: {integrity: sha512-F/1DnUGPopORZi0ni+CvrCgHQ5FyEAHRLSApuYWMmrbSwoN2Mn/7k+Gl38gJnR7yyDZk6WLXwiGod1JOWNDKGw==}\n    hasBin: true\n\n  header-case@2.0.4:\n    resolution: {integrity: sha512-H/vuk5TEEVZwrR0lp2zed9OCo1uAILMlx0JEMgC26rzyJJ3N1v6XkwHHXJQdR2doSjcGPM6OKPYoJgf0plJ11Q==}\n\n  hexoid@1.0.0:\n    resolution: {integrity: sha512-QFLV0taWQOZtvIRIAdBChesmogZrtuXvVWsFHZTk2SU+anspqZ2vMnoLg7IE1+Uk16N19APic1BuF8bC8c2m5g==}\n    engines: {node: '>=8'}\n\n  hookable@5.5.3:\n    resolution: {integrity: sha512-Yc+BQe8SvoXH1643Qez1zqLRmbA5rCL+sSmk6TVos0LWVfNIB7PGncdlId77WzLGSIB5KaWgTaNTs2lNVEI6VQ==}\n\n  hosted-git-info@2.8.9:\n    resolution: {integrity: sha512-mxIDAb9Lsm6DoOJ7xH+5+X4y1LU/4Hi50L9C5sIswK3JzULS4bwk1FvjdBgvYR4bzT4tuUQiC15FE2f5HbLvYw==}\n\n  html-encoding-sniffer@3.0.0:\n    resolution: {integrity: sha512-oWv4T4yJ52iKrufjnyZPkrN0CH3QnrUqdB6In1g5Fe1mia8GmF36gnfNySxoZtxD5+NmYw1EElVXiBk93UeskA==}\n    engines: {node: '>=12'}\n\n  html-encoding-sniffer@4.0.0:\n    resolution: {integrity: sha512-Y22oTqIU4uuPgEemfz7NDJz6OeKf12Lsu+QC+s3BVpda64lTiMYCyGwg5ki4vFxkMwQdeZDl2adZoqUgdFuTgQ==}\n    engines: {node: '>=18'}\n\n  html-escaper@2.0.2:\n    resolution: {integrity: sha512-H2iMtd0I4Mt5eYiapRdIDjp+XzelXQ0tFE4JS7YFwFevXXMmOp9myNrUvCg0D6ws8iqkRPBfKHgbwig1SmlLfg==}\n\n  html-to-text@9.0.5:\n    resolution: {integrity: sha512-qY60FjREgVZL03vJU6IfMV4GDjGBIoOyvuFdpBDIX9yTlDw0TjxVBQp+P8NvpdIXNJvfWBTNul7fsAQJq2FNpg==}\n    engines: {node: '>=14'}\n\n  htmlnano@2.1.1:\n    resolution: {integrity: sha512-kAERyg/LuNZYmdqgCdYvugyLWNFAm8MWXpQMz1pLpetmCbFwoMxvkSoaAMlFrOC4OKTWI4KlZGT/RsNxg4ghOw==}\n    peerDependencies:\n      cssnano: ^7.0.0\n      postcss: ^8.3.11\n      purgecss: ^6.0.0\n      relateurl: ^0.2.7\n      srcset: 5.0.1\n      svgo: ^3.0.2\n      terser: ^5.10.0\n      uncss: ^0.17.3\n    peerDependenciesMeta:\n      cssnano:\n        optional: true\n      postcss:\n        optional: true\n      purgecss:\n        optional: true\n      relateurl:\n        optional: true\n      srcset:\n        optional: true\n      svgo:\n        optional: true\n      terser:\n        optional: true\n      uncss:\n        optional: true\n\n  htmlparser2@5.0.1:\n    resolution: {integrity: sha512-vKZZra6CSe9qsJzh0BjBGXo8dvzNsq/oGvsjfRdOrrryfeD9UOBEEQdeoqCRmKZchF5h2zOBMQ6YuQ0uRUmdbQ==}\n\n  htmlparser2@7.2.0:\n    resolution: {integrity: sha512-H7MImA4MS6cw7nbyURtLPO1Tms7C5H602LRETv95z1MxO/7CP7rDVROehUYeYBUYEON94NXXDEPmZuq+hX4sog==}\n\n  htmlparser2@8.0.2:\n    resolution: {integrity: sha512-GYdjWKDkbRLkZ5geuHs5NY1puJ+PXwP7+fHPRz06Eirsb9ugf6d8kkXav6ADhcODhFFPMIXyxkxSuMf3D6NCFA==}\n\n  htmlparser2@9.1.0:\n    resolution: {integrity: sha512-5zfg6mHUoaer/97TxnGpxmbR7zJtPwIYFMZ/H5ucTlPZhKvtum05yiPK3Mgai3a0DyVxv7qYqoweaEd2nrYQzQ==}\n\n  http-errors@2.0.0:\n    resolution: {integrity: sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==}\n    engines: {node: '>= 0.8'}\n\n  http-proxy-agent@7.0.2:\n    resolution: {integrity: sha512-T1gkAiYYDWYx3V5Bmyu7HcfcvL7mUrTWiM6yOfa3PIphViJ/gFPbvidQ+veqSOHci/PxBcDabeUNCzpOODJZig==}\n    engines: {node: '>= 14'}\n\n  http-proxy@1.18.1:\n    resolution: {integrity: sha512-7mz/721AbnJwIVbnaSv1Cz3Am0ZLT/UBwkC92VlxhXv/k/BBQfM2fXElQNC27BVGr0uwUpplYPQM9LnaBMR5NQ==}\n    engines: {node: '>=8.0.0'}\n\n  http-reasons@0.1.0:\n    resolution: {integrity: sha512-P6kYh0lKZ+y29T2Gqz+RlC9WBLhKe8kDmcJ+A+611jFfxdPsbMRQ5aNmFRM3lENqFkK+HTTL+tlQviAiv0AbLQ==}\n\n  http-server@14.1.1:\n    resolution: {integrity: sha512-+cbxadF40UXd9T01zUHgA+rlo2Bg1Srer4+B4NwIHdaGxAGGv59nYRnGGDJ9LBk7alpS0US+J+bLLdQOOkJq4A==}\n    engines: {node: '>=12'}\n    hasBin: true\n\n  https-proxy-agent@5.0.1:\n    resolution: {integrity: sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==}\n    engines: {node: '>= 6'}\n\n  https-proxy-agent@7.0.5:\n    resolution: {integrity: sha512-1e4Wqeblerz+tMKPIq2EMGiiWW1dIjZOksyHWSUm1rmuvw/how9hBHZ38lAGj5ID4Ik6EdkOw7NmWPy6LAwalw==}\n    engines: {node: '>= 14'}\n\n  human-signals@2.1.0:\n    resolution: {integrity: sha512-B4FFZ6q/T2jhhksgkbEW3HBvWIfDW85snkQgawt07S7J5QXTk6BkNV+0yAeZrM5QpMAdYlocGoljn0sJ/WQkFw==}\n    engines: {node: '>=10.17.0'}\n\n  human-signals@4.3.1:\n    resolution: {integrity: sha512-nZXjEF2nbo7lIw3mgYjItAfgQXog3OjJogSbKa2CQIIvSGWcKgeJnQlNXip6NglNzYH45nSRiEVimMvYL8DDqQ==}\n    engines: {node: '>=14.18.0'}\n\n  human-signals@5.0.0:\n    resolution: {integrity: sha512-AXcZb6vzzrFAUE61HnN4mpLqd/cSIwNQjtNWR0euPm6y0iqx3G4gOXaIDdtdDwZmhwe82LA6+zinmW4UBWVePQ==}\n    engines: {node: '>=16.17.0'}\n\n  husky@9.1.6:\n    resolution: {integrity: sha512-sqbjZKK7kf44hfdE94EoX8MZNk0n7HeW37O4YrVGCF4wzgQjp+akPAkfUK5LZ6KuR/6sqeAVuXHji+RzQgOn5A==}\n    engines: {node: '>=18'}\n    hasBin: true\n\n  iconv-lite@0.4.24:\n    resolution: {integrity: sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==}\n    engines: {node: '>=0.10.0'}\n\n  iconv-lite@0.6.3:\n    resolution: {integrity: sha512-4fCk79wshMdzMp2rH06qWrJE4iolqLhCUH+OiuIgU++RB0+94NlDL81atO7GX55uUKueo0txHNtvEyI6D7WdMw==}\n    engines: {node: '>=0.10.0'}\n\n  idb@7.1.1:\n    resolution: {integrity: sha512-gchesWBzyvGHRO9W8tzUWFDycow5gwjvFKfyV9FF32Y7F50yZMp7mP+T2mJIWFx49zicqyC4uefHM17o6xKIVQ==}\n\n  ieee754@1.2.1:\n    resolution: {integrity: sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==}\n\n  ignore@5.3.1:\n    resolution: {integrity: sha512-5Fytz/IraMjqpwfd34ke28PTVMjZjJG2MPn5t7OE4eUCUNf8BAa7b5WUS9/Qvr6mwOQS7Mk6vdsMno5he+T8Xw==}\n    engines: {node: '>= 4'}\n\n  ignore@5.3.2:\n    resolution: {integrity: sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==}\n    engines: {node: '>= 4'}\n\n  immediate@3.0.6:\n    resolution: {integrity: sha512-XXOFtyqDjNDAQxVfYxuF7g9Il/IbWmmlQg2MYKOH8ExIT1qg6xc4zyS3HaEEATgs1btfzxq15ciUiY7gjSXRGQ==}\n\n  immutable@3.7.6:\n    resolution: {integrity: sha512-AizQPcaofEtO11RZhPPHBOJRdo/20MKQF9mBLnVkBoyHi1/zXK8fzVdnEpSV9gxqtnh6Qomfp3F0xT5qP/vThw==}\n    engines: {node: '>=0.8.0'}\n\n  immutable@4.3.5:\n    resolution: {integrity: sha512-8eabxkth9gZatlwl5TBuJnCsoTADlL6ftEr7A4qgdaTsPyreilDSnUk57SO+jfKcNtxPa22U5KK6DSeAYhpBJw==}\n\n  import-fresh@3.3.0:\n    resolution: {integrity: sha512-veYYhQa+D1QBKznvhUHxb8faxlrwUnxseDAbAp457E0wLNio2bOSKnjYDhMj+YiAq61xrMGhQk9iXVk5FzgQMw==}\n    engines: {node: '>=6'}\n\n  import-from@4.0.0:\n    resolution: {integrity: sha512-P9J71vT5nLlDeV8FHs5nNxaLbrpfAV5cF5srvbZfpwpcJoM/xZR3hiv+q+SAnuSmuGbXMWud063iIMx/V/EWZQ==}\n    engines: {node: '>=12.2'}\n\n  import-local@3.2.0:\n    resolution: {integrity: sha512-2SPlun1JUPWoM6t3F0dw0FkCF/jWY8kttcY4f599GLTSjh2OCuuhdTkJQsEcZzBqbXZGKMK2OqW1oZsjtf/gQA==}\n    engines: {node: '>=8'}\n    hasBin: true\n\n  import-meta-resolve@4.1.0:\n    resolution: {integrity: sha512-I6fiaX09Xivtk+THaMfAwnA3MVA5Big1WHF1Dfx9hFuvNIWpXnorlkzhcQf6ehrqQiiZECRt1poOAkPmer3ruw==}\n\n  imurmurhash@0.1.4:\n    resolution: {integrity: sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==}\n    engines: {node: '>=0.8.19'}\n\n  indent-string@4.0.0:\n    resolution: {integrity: sha512-EdDDZu4A2OyIK7Lr/2zG+w5jmbuk1DVBnEwREQvBzspBJkCEbRa8GxU1lghYcaGJCnRWibjDXlq779X1/y5xwg==}\n    engines: {node: '>=8'}\n\n  indexof@0.0.1:\n    resolution: {integrity: sha512-i0G7hLJ1z0DE8dsqJa2rycj9dBmNKgXBvotXtZYXakU9oivfB9Uj2ZBC27qqef2U58/ZLwalxa1X/RDCdkHtVg==}\n\n  inflight@1.0.6:\n    resolution: {integrity: sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==}\n    deprecated: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n\n  inherits@2.0.3:\n    resolution: {integrity: sha512-x00IRNXNy63jwGkJmzPigoySHbaqpNuzKbBOmzK+g2OdZpQ9w+sxCN+VSB3ja7IAge2OP2qpfxTjeNcyjmW1uw==}\n\n  inherits@2.0.4:\n    resolution: {integrity: sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==}\n\n  ini@1.3.8:\n    resolution: {integrity: sha512-JV/yugV2uzW5iMRSiZAyDtQd+nxtUnjeLt0acNdw98kKLrvuRVyB80tsREOE7yvGVgalhZ6RNXCmEHkUKBKxew==}\n\n  ini@4.1.1:\n    resolution: {integrity: sha512-QQnnxNyfvmHFIsj7gkPcYymR8Jdw/o7mp5ZFihxn6h8Ci6fh3Dx4E1gPjpQEpIuPo9XVNY/ZUwh4BPMjGyL01g==}\n    engines: {node: ^14.17.0 || ^16.13.0 || >=18.0.0}\n\n  inquirer@8.2.6:\n    resolution: {integrity: sha512-M1WuAmb7pn9zdFRtQYk26ZBoY043Sse0wVDdk4Bppr+JOXyQYybdtvK+l9wUibhtjdjvtoiNy8tk+EgsYIUqKg==}\n    engines: {node: '>=12.0.0'}\n\n  inquirer@9.2.15:\n    resolution: {integrity: sha512-vI2w4zl/mDluHt9YEQ/543VTCwPKWiHzKtm9dM2V0NdFcqEexDAjUHzO1oA60HRNaVifGXXM1tRRNluLVHa0Kg==}\n    engines: {node: '>=18'}\n\n  insomnia-importers@3.6.0:\n    resolution: {integrity: sha512-42FvUCwQcHg8OSr2EtppkfByPVQFhBgaxhpu7zslnvQXtf/tLU568xmAxI6fMIY0S69u2J2SyIli3x7qm+9r2w==}\n    deprecated: Package no longer supported. Use at your own risk.\n    hasBin: true\n\n  internal-slot@1.0.7:\n    resolution: {integrity: sha512-NGnrKwXzSms2qUUih/ILZ5JBqNTSa1+ZmP6flaIp6KmSElgE9qdndzS3cqjrDovwFdmwsGsLdeFgB6suw+1e9g==}\n    engines: {node: '>= 0.4'}\n\n  invariant@2.2.4:\n    resolution: {integrity: sha512-phJfQVBuaJM5raOpJjSfkiD6BpbCE4Ns//LaXl6wGYtUBY83nWS6Rf9tXm2e8VaK60JEjYldbPif/A2B1C2gNA==}\n\n  io-ts@2.2.21:\n    resolution: {integrity: sha512-zz2Z69v9ZIC3mMLYWIeoUcwWD6f+O7yP92FMVVaXEOSZH1jnVBmET/urd/uoarD1WGBY4rCj8TAyMPzsGNzMFQ==}\n    peerDependencies:\n      fp-ts: ^2.5.0\n\n  ioredis@5.4.1:\n    resolution: {integrity: sha512-2YZsvl7jopIa1gaePkeMtd9rAcSjOOjPtpcLlOeusyO+XH2SK5ZcT+UCrElPP+WVIInh2TzeI4XW9ENaSLVVHA==}\n    engines: {node: '>=12.22.0'}\n\n  ipaddr.js@1.9.1:\n    resolution: {integrity: sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==}\n    engines: {node: '>= 0.10'}\n\n  is-absolute@1.0.0:\n    resolution: {integrity: sha512-dOWoqflvcydARa360Gvv18DZ/gRuHKi2NU/wU5X1ZFzdYfH29nkiNZsF3mp4OJ3H4yo9Mx8A/uAGNzpzPN3yBA==}\n    engines: {node: '>=0.10.0'}\n\n  is-arguments@1.1.1:\n    resolution: {integrity: sha512-8Q7EARjzEnKpt/PCD7e1cgUS0a6X8u5tdSiMqXhojOdoV9TsMsiO+9VLC5vAmO8N7/GmXn7yjR8qnA6bVAEzfA==}\n    engines: {node: '>= 0.4'}\n\n  is-array-buffer@3.0.4:\n    resolution: {integrity: sha512-wcjaerHw0ydZwfhiKbXJWLDY8A7yV7KhjQOpb83hGgGfId/aQa4TOvwyzn2PuswW2gPCYEL/nEAiSVpdOj1lXw==}\n    engines: {node: '>= 0.4'}\n\n  is-arrayish@0.2.1:\n    resolution: {integrity: sha512-zz06S8t0ozoDXMG+ube26zeCTNXcKIPJZJi8hBrF4idCLms4CG9QtK7qBl1boi5ODzFpjswb5JPmHCbMpjaYzg==}\n\n  is-bigint@1.0.4:\n    resolution: {integrity: sha512-zB9CruMamjym81i2JZ3UMn54PKGsQzsJeo6xvN3HJJ4CAsQNB6iRutp2To77OfCNuoxspsIhzaPoO1zyCEhFOg==}\n\n  is-binary-path@2.1.0:\n    resolution: {integrity: sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==}\n    engines: {node: '>=8'}\n\n  is-boolean-object@1.1.2:\n    resolution: {integrity: sha512-gDYaKHJmnj4aWxyj6YHyXVpdQawtVLHU5cb+eztPGczf6cjuTdwve5ZIEfgXqH4e57An1D1AKf8CZ3kYrQRqYA==}\n    engines: {node: '>= 0.4'}\n\n  is-callable@1.2.7:\n    resolution: {integrity: sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==}\n    engines: {node: '>= 0.4'}\n\n  is-core-module@2.13.1:\n    resolution: {integrity: sha512-hHrIjvZsftOsvKSn2TRYl63zvxsgE0K+0mYMoH6gD4omR5IWB2KynivBQczo3+wF1cCkjzvptnI9Q0sPU66ilw==}\n\n  is-data-view@1.0.1:\n    resolution: {integrity: sha512-AHkaJrsUVW6wq6JS8y3JnM/GJF/9cf+k20+iDzlSaJrinEo5+7vRiteOSwBhHRiAyQATN1AmY4hwzxJKPmYf+w==}\n    engines: {node: '>= 0.4'}\n\n  is-date-object@1.0.5:\n    resolution: {integrity: sha512-9YQaSxsAiSwcvS33MBk3wTCVnWK+HhF8VZR2jRxehM16QcVOdHqPn4VPHmRK4lSr38n9JriurInLcP90xsYNfQ==}\n    engines: {node: '>= 0.4'}\n\n  is-docker@2.2.1:\n    resolution: {integrity: sha512-F+i2BKsFrH66iaUFc0woD8sLy8getkwTwtOBjvs56Cx4CgJDeKQeqfz8wAYiSb8JOprWhHH5p77PbmYCvvUuXQ==}\n    engines: {node: '>=8'}\n    hasBin: true\n\n  is-docker@3.0.0:\n    resolution: {integrity: sha512-eljcgEDlEns/7AXFosB5K/2nCM4P7FQPkGc/DWLy5rmFEWvZayGrik1d9/QIY5nJ4f9YsVvBkA6kJpHn9rISdQ==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n    hasBin: true\n\n  is-expression@4.0.0:\n    resolution: {integrity: sha512-zMIXX63sxzG3XrkHkrAPvm/OVZVSCPNkwMHU8oTX7/U3AL78I0QXCEICXUM13BIa8TYGZ68PiTKfQz3yaTNr4A==}\n\n  is-extglob@2.1.1:\n    resolution: {integrity: sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==}\n    engines: {node: '>=0.10.0'}\n\n  is-fullwidth-code-point@3.0.0:\n    resolution: {integrity: sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==}\n    engines: {node: '>=8'}\n\n  is-fullwidth-code-point@4.0.0:\n    resolution: {integrity: sha512-O4L094N2/dZ7xqVdrXhh9r1KODPJpFms8B5sGdJLPy664AgvXsreZUyCQQNItZRDlYug4xStLjNp/sz3HvBowQ==}\n    engines: {node: '>=12'}\n\n  is-fullwidth-code-point@5.0.0:\n    resolution: {integrity: sha512-OVa3u9kkBbw7b8Xw5F9P+D/T9X+Z4+JruYVNapTjPYZYUznQ5YfWeFkOj606XYYW8yugTfC8Pj0hYqvi4ryAhA==}\n    engines: {node: '>=18'}\n\n  is-generator-fn@2.1.0:\n    resolution: {integrity: sha512-cTIB4yPYL/Grw0EaSzASzg6bBy9gqCofvWN8okThAYIxKJZC+udlRAmGbM0XLeniEJSs8uEgHPGuHSe1XsOLSQ==}\n    engines: {node: '>=6'}\n\n  is-generator-function@1.0.10:\n    resolution: {integrity: sha512-jsEjy9l3yiXEQ+PsXdmBwEPcOxaXWLspKdplFUVI9vq1iZgIekeC0L167qeu86czQaxed3q/Uzuw0swL0irL8A==}\n    engines: {node: '>= 0.4'}\n\n  is-glob@4.0.3:\n    resolution: {integrity: sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==}\n    engines: {node: '>=0.10.0'}\n\n  is-inside-container@1.0.0:\n    resolution: {integrity: sha512-KIYLCCJghfHZxqjYBE7rEy0OBuTd5xCHS7tHVgvCLkx7StIoaxwNW3hCALgEUjFfeRk+MG/Qxmp/vtETEF3tRA==}\n    engines: {node: '>=14.16'}\n    hasBin: true\n\n  is-interactive@1.0.0:\n    resolution: {integrity: sha512-2HvIEKRoqS62guEC+qBjpvRubdX910WCMuJTZ+I9yvqKU2/12eSL549HMwtabb4oupdj2sMP50k+XJfB/8JE6w==}\n    engines: {node: '>=8'}\n\n  is-json@2.0.1:\n    resolution: {integrity: sha512-6BEnpVn1rcf3ngfmViLM6vjUjGErbdrL4rwlv+u1NO1XO8kqT4YGL8+19Q+Z/bas8tY90BTWMk2+fW1g6hQjbA==}\n\n  is-lower-case@2.0.2:\n    resolution: {integrity: sha512-bVcMJy4X5Og6VZfdOZstSexlEy20Sr0k/p/b2IlQJlfdKAQuMpiv5w2Ccxb8sKdRUNAG1PnHVHjFSdRDVS6NlQ==}\n\n  is-map@2.0.3:\n    resolution: {integrity: sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==}\n    engines: {node: '>= 0.4'}\n\n  is-module@1.0.0:\n    resolution: {integrity: sha512-51ypPSPCoTEIN9dy5Oy+h4pShgJmPCygKfyRCISBI+JoWT/2oJvK8QPxmwv7b/p239jXrm9M1mlQbyKJ5A152g==}\n\n  is-negative-zero@2.0.3:\n    resolution: {integrity: sha512-5KoIu2Ngpyek75jXodFvnafB6DJgr3u8uuK0LEZJjrU19DrMD3EVERaR8sjz8CCGgpZvxPl9SuE1GMVPFHx1mw==}\n    engines: {node: '>= 0.4'}\n\n  is-number-object@1.0.7:\n    resolution: {integrity: sha512-k1U0IRzLMo7ZlYIfzRu23Oh6MiIFasgpb9X76eqfFZAqwH44UI4KTBvBYIZ1dSL9ZzChTB9ShHfLkR4pdW5krQ==}\n    engines: {node: '>= 0.4'}\n\n  is-number@7.0.0:\n    resolution: {integrity: sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==}\n    engines: {node: '>=0.12.0'}\n\n  is-obj@1.0.1:\n    resolution: {integrity: sha512-l4RyHgRqGN4Y3+9JHVrNqO+tN0rV5My76uW5/nuO4K1b6vw5G8d/cmFjP9tRfEsdhZNt0IFdZuK/c2Vr4Nb+Qg==}\n    engines: {node: '>=0.10.0'}\n\n  is-obj@2.0.0:\n    resolution: {integrity: sha512-drqDG3cbczxxEJRoOXcOjtdp1J/lyp1mNn0xaznRs8+muBhgQcrnbspox5X5fOw0HnMnbfDzvnEMEtqDEJEo8w==}\n    engines: {node: '>=8'}\n\n  is-path-inside@3.0.3:\n    resolution: {integrity: sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==}\n    engines: {node: '>=8'}\n\n  is-plain-obj@2.1.0:\n    resolution: {integrity: sha512-YWnfyRwxL/+SsrWYfOpUtz5b3YD+nyfkHvjbcanzk8zgyO4ASD67uVMRt8k5bM4lLMDnXfriRhOpemw+NfT1eA==}\n    engines: {node: '>=8'}\n\n  is-potential-custom-element-name@1.0.1:\n    resolution: {integrity: sha512-bCYeRA2rVibKZd+s2625gGnGF/t7DSqDs4dP7CrLA1m7jKWz6pps0LpYLJN8Q64HtmPKJ1hrN3nzPNKFEKOUiQ==}\n\n  is-promise@2.2.2:\n    resolution: {integrity: sha512-+lP4/6lKUBfQjZ2pdxThZvLUAafmZb8OAxFb8XXtiQmS35INgr85hdOGoEs124ez1FCnZJt6jau/T+alh58QFQ==}\n\n  is-regex@1.1.4:\n    resolution: {integrity: sha512-kvRdxDsxZjhzUX07ZnLydzS1TU/TJlTUHHY4YLL87e37oUA49DfkLqgy+VjFocowy29cKvcSiu+kIv728jTTVg==}\n    engines: {node: '>= 0.4'}\n\n  is-regexp@1.0.0:\n    resolution: {integrity: sha512-7zjFAPO4/gwyQAAgRRmqeEeyIICSdmCqa3tsVHMdBzaXXRiqopZL4Cyghg/XulGWrtABTpbnYYzzIRffLkP4oA==}\n    engines: {node: '>=0.10.0'}\n\n  is-relative@1.0.0:\n    resolution: {integrity: sha512-Kw/ReK0iqwKeu0MITLFuj0jbPAmEiOsIwyIXvvbfa6QfmN9pkD1M+8pdk7Rl/dTKbH34/XBFMbgD4iMJhLQbGA==}\n    engines: {node: '>=0.10.0'}\n\n  is-set@2.0.3:\n    resolution: {integrity: sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==}\n    engines: {node: '>= 0.4'}\n\n  is-shared-array-buffer@1.0.3:\n    resolution: {integrity: sha512-nA2hv5XIhLR3uVzDDfCIknerhx8XUKnstuOERPNNIinXG7v9u+ohXF67vxm4TPTEPU6lm61ZkwP3c9PCB97rhg==}\n    engines: {node: '>= 0.4'}\n\n  is-stream@1.1.0:\n    resolution: {integrity: sha512-uQPm8kcs47jx38atAcWTVxyltQYoPT68y9aWYdV6yWXSyW8mzSat0TL6CiWdZeCdF3KrAvpVtnHbTv4RN+rqdQ==}\n    engines: {node: '>=0.10.0'}\n\n  is-stream@2.0.1:\n    resolution: {integrity: sha512-hFoiJiTl63nn+kstHGBtewWSKnQLpyb155KHheA1l39uvtO9nWIop1p3udqPcUd/xbF1VLMO4n7OI6p7RbngDg==}\n    engines: {node: '>=8'}\n\n  is-stream@3.0.0:\n    resolution: {integrity: sha512-LnQR4bZ9IADDRSkvpqMGvt/tEJWclzklNgSw48V5EAaAeDd6qGvN8ei6k5p0tvxSR171VmGyHuTiAOfxAbr8kA==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  is-string@1.0.7:\n    resolution: {integrity: sha512-tE2UXzivje6ofPW7l23cjDOMa09gb7xlAqG6jG5ej6uPV32TlWP3NKPigtaGeHNu9fohccRYvIiZMfOOnOYUtg==}\n    engines: {node: '>= 0.4'}\n\n  is-symbol@1.0.4:\n    resolution: {integrity: sha512-C/CPBqKWnvdcxqIARxyOh4v1UUEOCHpgDa0WYgpKDFMszcrPcffg5uhwSgPCLD2WWxmq6isisz87tzT01tuGhg==}\n    engines: {node: '>= 0.4'}\n\n  is-text-path@2.0.0:\n    resolution: {integrity: sha512-+oDTluR6WEjdXEJMnC2z6A4FRwFoYuvShVVEGsS7ewc0UTi2QtAKMDJuL4BDEVt+5T7MjFo12RP8ghOM75oKJw==}\n    engines: {node: '>=8'}\n\n  is-typed-array@1.1.13:\n    resolution: {integrity: sha512-uZ25/bUAlUY5fR4OKT4rZQEBrzQWYV9ZJYGGsUmEJ6thodVJ1HX64ePQ6Z0qPWP+m+Uq6e9UugrE38jeYsDSMw==}\n    engines: {node: '>= 0.4'}\n\n  is-unc-path@1.0.0:\n    resolution: {integrity: sha512-mrGpVd0fs7WWLfVsStvgF6iEJnbjDFZh9/emhRDcGWTduTfNHd9CHeUwH3gYIjdbwo4On6hunkztwOaAw0yllQ==}\n    engines: {node: '>=0.10.0'}\n\n  is-unicode-supported@0.1.0:\n    resolution: {integrity: sha512-knxG2q4UC3u8stRGyAVJCOdxFmv5DZiRcdlIaAQXAbSfJya+OhopNotLQrstBhququ4ZpuKbDc/8S6mgXgPFPw==}\n    engines: {node: '>=10'}\n\n  is-upper-case@2.0.2:\n    resolution: {integrity: sha512-44pxmxAvnnAOwBg4tHPnkfvgjPwbc5QIsSstNU+YcJ1ovxVzCWpSGosPJOZh/a1tdl81fbgnLc9LLv+x2ywbPQ==}\n\n  is-url@1.2.4:\n    resolution: {integrity: sha512-ITvGim8FhRiYe4IQ5uHSkj7pVaPDrCTkNd3yq3cV7iZAcJdHTUMPMEHcqSOy9xZ9qFenQCvi+2wjH9a1nXqHww==}\n\n  is-weakmap@2.0.2:\n    resolution: {integrity: sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==}\n    engines: {node: '>= 0.4'}\n\n  is-weakref@1.0.2:\n    resolution: {integrity: sha512-qctsuLZmIQ0+vSSMfoVvyFe2+GSEvnmZ2ezTup1SBse9+twCCeial6EEi3Nc2KFcf6+qz2FBPnjXsk8xhKSaPQ==}\n\n  is-weakset@2.0.3:\n    resolution: {integrity: sha512-LvIm3/KWzS9oRFHugab7d+M/GcBXuXX5xZkzPmN+NxihdQlZUQ4dWuSV1xR/sq6upL1TJEDrfBgRepHFdBtSNQ==}\n    engines: {node: '>= 0.4'}\n\n  is-windows@1.0.2:\n    resolution: {integrity: sha512-eXK1UInq2bPmjyX6e3VHIzMLobc4J94i4AWn+Hpq3OU5KkrRC96OAcR3PRJ/pGu6m8TRnBHP9dkXQVsT/COVIA==}\n    engines: {node: '>=0.10.0'}\n\n  is-wsl@2.2.0:\n    resolution: {integrity: sha512-fKzAra0rGJUUBwGBgNkHZuToZcn+TtXHpeCgmkMJMMYx1sQDYaCSyjJBSCa2nH1DGm7s3n1oBnohoVTBaN7Lww==}\n    engines: {node: '>=8'}\n\n  is-wsl@3.1.0:\n    resolution: {integrity: sha512-UcVfVfaK4Sc4m7X3dUSoHoozQGBEFeDC+zVo06t98xe8CzHSZZBekNXH+tu0NalHolcJ/QAGqS46Hef7QXBIMw==}\n    engines: {node: '>=16'}\n\n  isarray@1.0.0:\n    resolution: {integrity: sha512-VLghIWNM6ELQzo7zwmcg0NmTVyWKYjvIeM83yjp0wRDTmUnrM678fQbcKBo6n2CJEF0szoG//ytg+TKla89ALQ==}\n\n  isarray@2.0.1:\n    resolution: {integrity: sha512-c2cu3UxbI+b6kR3fy0nRnAhodsvR9dx7U5+znCOzdj6IfP3upFURTr0Xl5BlQZNKZjEtxrmVyfSdeE3O57smoQ==}\n\n  isarray@2.0.5:\n    resolution: {integrity: sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==}\n\n  isexe@2.0.0:\n    resolution: {integrity: sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==}\n\n  isolated-vm@5.0.1:\n    resolution: {integrity: sha512-hs7+ff59Z2zDvavfcjuot/r1gm6Bmpt+GoZxmVfxUmXaX5scOvUq/Rnme+mUtSh5lW41hH8gAuvk/yTJDYO8Fg==}\n    engines: {node: '>=18.0.0'}\n\n  isomorphic-ws@5.0.0:\n    resolution: {integrity: sha512-muId7Zzn9ywDsyXgTIafTry2sV3nySZeUDe6YedVd1Hvuuep5AsIlqK+XefWpYTyJG5e503F2xIuT2lcU6rCSw==}\n    peerDependencies:\n      ws: '*'\n\n  istanbul-lib-coverage@3.2.2:\n    resolution: {integrity: sha512-O8dpsF+r0WV/8MNRKfnmrtCWhuKjxrq2w+jpzBL5UZKTi2LeVWnWOmWRxFlesJONmc+wLAGvKQZEOanko0LFTg==}\n    engines: {node: '>=8'}\n\n  istanbul-lib-instrument@5.2.1:\n    resolution: {integrity: sha512-pzqtp31nLv/XFOzXGuvhCb8qhjmTVo5vjVk19XE4CRlSWz0KoeJ3bw9XsA7nOp9YBf4qHjwBxkDzKcME/J29Yg==}\n    engines: {node: '>=8'}\n\n  istanbul-lib-instrument@6.0.3:\n    resolution: {integrity: sha512-Vtgk7L/R2JHyyGW07spoFlB8/lpjiOLTjMdms6AFMraYt3BaJauod/NGrfnVG/y4Ix1JEuMRPDPEj2ua+zz1/Q==}\n    engines: {node: '>=10'}\n\n  istanbul-lib-report@3.0.1:\n    resolution: {integrity: sha512-GCfE1mtsHGOELCU8e/Z7YWzpmybrx/+dSTfLrvY8qRmaY6zXTKWn6WQIjaAFw069icm6GVMNkgu0NzI4iPZUNw==}\n    engines: {node: '>=10'}\n\n  istanbul-lib-source-maps@4.0.1:\n    resolution: {integrity: sha512-n3s8EwkdFIJCG3BPKBYvskgXGoy88ARzvegkitk60NxRdwltLOTaH7CUiMRXvwYorl0Q712iEjcWB+fK/MrWVw==}\n    engines: {node: '>=10'}\n\n  istanbul-reports@3.1.7:\n    resolution: {integrity: sha512-BewmUXImeuRk2YY0PVbxgKAysvhRPUQE0h5QRM++nVWyubKGV0l8qQ5op8+B2DOmwSe63Jivj0BjkPQVf8fP5g==}\n    engines: {node: '>=8'}\n\n  iterall@1.3.0:\n    resolution: {integrity: sha512-QZ9qOMdF+QLHxy1QIpUHUU1D5pS2CG2P69LF6L6CPjPYA/XMOmKV3PZpawHoAjHNyB0swdVTRxdYT4tbBbxqwg==}\n\n  iterare@1.2.1:\n    resolution: {integrity: sha512-RKYVTCjAnRthyJes037NX/IiqeidgN1xc3j1RjFfECFp28A1GVwK9nA+i0rJPaHqSZwygLzRnFlzUuHFoWWy+Q==}\n    engines: {node: '>=6'}\n\n  jackspeak@2.3.6:\n    resolution: {integrity: sha512-N3yCS/NegsOBokc8GAdM8UcmfsKiSS8cipheD/nivzr700H+nsMOxJjQnvwOcRYVuFkdH0wGUvW2WbXGmrZGbQ==}\n    engines: {node: '>=14'}\n\n  jackspeak@3.4.3:\n    resolution: {integrity: sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==}\n\n  jackspeak@4.0.2:\n    resolution: {integrity: sha512-bZsjR/iRjl1Nk1UkjGpAzLNfQtzuijhn2g+pbZb98HQ1Gk8vM9hfbxeMBP+M2/UUdwj0RqGG3mlvk2MsAqwvEw==}\n    engines: {node: 20 || >=22}\n\n  jake@10.9.2:\n    resolution: {integrity: sha512-2P4SQ0HrLQ+fw6llpLnOaGAvN2Zu6778SJMrCUwns4fOoG9ayrTiZk3VV8sCPkVZF8ab0zksVpS8FDY5pRCNBA==}\n    engines: {node: '>=10'}\n    hasBin: true\n\n  jest-changed-files@29.7.0:\n    resolution: {integrity: sha512-fEArFiwf1BpQ+4bXSprcDc3/x4HSzL4al2tozwVpDFpsxALjLYdyiIK4e5Vz66GQJIbXJ82+35PtysofptNX2w==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-circus@29.7.0:\n    resolution: {integrity: sha512-3E1nCMgipcTkCocFwM90XXQab9bS+GMsjdpmPrlelaxwD93Ad8iVEjX/vvHPdLPnFf+L40u+5+iutRdA1N9myw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-cli@29.7.0:\n    resolution: {integrity: sha512-OVVobw2IubN/GSYsxETi+gOe7Ka59EFMR/twOU3Jb2GnKKeMGJB5SGUUrEz3SFVmJASUdZUzy83sLNNQ2gZslg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    hasBin: true\n    peerDependencies:\n      node-notifier: ^8.0.1 || ^9.0.0 || ^10.0.0\n    peerDependenciesMeta:\n      node-notifier:\n        optional: true\n\n  jest-config@29.7.0:\n    resolution: {integrity: sha512-uXbpfeQ7R6TZBqI3/TxCU4q4ttk3u0PJeC+E0zbfSoSjq6bJ7buBPxzQPL0ifrkY4DNu4JUdk0ImlBUYi840eQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    peerDependencies:\n      '@types/node': '*'\n      ts-node: '>=9.0.0'\n    peerDependenciesMeta:\n      '@types/node':\n        optional: true\n      ts-node:\n        optional: true\n\n  jest-diff@29.7.0:\n    resolution: {integrity: sha512-LMIgiIrhigmPrs03JHpxUh2yISK3vLFPkAodPeo0+BuF7wA2FoQbkEg1u8gBYBThncu7e1oEDUfIXVuTqLRUjw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-docblock@29.7.0:\n    resolution: {integrity: sha512-q617Auw3A612guyaFgsbFeYpNP5t2aoUNLwBUbc/0kD1R4t9ixDbyFTHd1nok4epoVFpr7PmeWHrhvuV3XaJ4g==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-each@29.7.0:\n    resolution: {integrity: sha512-gns+Er14+ZrEoC5fhOfYCY1LOHHr0TI+rQUHZS8Ttw2l7gl+80eHc/gFf2Ktkw0+SIACDTeWvpFcv3B04VembQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-environment-node@29.7.0:\n    resolution: {integrity: sha512-DOSwCRqXirTOyheM+4d5YZOrWcdu0LNZ87ewUoywbcb2XR4wKgqiG8vNeYwhjFMbEkfju7wx2GYH0P2gevGvFw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-get-type@29.6.3:\n    resolution: {integrity: sha512-zrteXnqYxfQh7l5FHyL38jL39di8H8rHoecLH3JNxH3BwOrBsNeabdap5e0I23lD4HHI8W5VFBZqG4Eaq5LNcw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-haste-map@29.7.0:\n    resolution: {integrity: sha512-fP8u2pyfqx0K1rGn1R9pyE0/KTn+G7PxktWidOBTqFPLYX0b9ksaMFkhK5vrS3DVun09pckLdlx90QthlW7AmA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-leak-detector@29.7.0:\n    resolution: {integrity: sha512-kYA8IJcSYtST2BY9I+SMC32nDpBT3J2NvWJx8+JCuCdl/CR1I4EKUJROiP8XtCcxqgTTBGJNdbB1A8XRKbTetw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-matcher-utils@29.7.0:\n    resolution: {integrity: sha512-sBkD+Xi9DtcChsI3L3u0+N0opgPYnCRPtGcQYrgXmR+hmt/fYfWAL0xRXYU8eWOdfuLgBe0YCW3AFtnRLagq/g==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-message-util@29.7.0:\n    resolution: {integrity: sha512-GBEV4GRADeP+qtB2+6u61stea8mGcOT4mCtrYISZwfu9/ISHFJ/5zOMXYbpBE9RsS5+Gb63DW4FgmnKJ79Kf6w==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-mock-extended@4.0.0-beta1:\n    resolution: {integrity: sha512-MYcI0wQu3ceNhqKoqAJOdEfsVMamAFqDTjoLN5Y45PAG3iIm4WGnhOu0wpMjlWCexVPO71PMoNir9QrGXrnIlw==}\n    peerDependencies:\n      '@jest/globals': ^28.0.0 || ^29.0.0\n      jest: ^24.0.0 || ^25.0.0 || ^26.0.0 || ^27.0.0 || ^28.0.0 || ^29.0.0\n      typescript: ^3.0.0 || ^4.0.0 || ^5.0.0\n\n  jest-mock@29.7.0:\n    resolution: {integrity: sha512-ITOMZn+UkYS4ZFh83xYAOzWStloNzJFO2s8DWrE4lhtGD+AorgnbkiKERe4wQVBydIGPx059g6riW5Btp6Llnw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-pnp-resolver@1.2.3:\n    resolution: {integrity: sha512-+3NpwQEnRoIBtx4fyhblQDPgJI0H1IEIkX7ShLUjPGA7TtUTvI1oiKi3SR4oBR0hQhQR80l4WAe5RrXBwWMA8w==}\n    engines: {node: '>=6'}\n    peerDependencies:\n      jest-resolve: '*'\n    peerDependenciesMeta:\n      jest-resolve:\n        optional: true\n\n  jest-regex-util@29.6.3:\n    resolution: {integrity: sha512-KJJBsRCyyLNWCNBOvZyRDnAIfUiRJ8v+hOBQYGn8gDyF3UegwiP4gwRR3/SDa42g1YbVycTidUF3rKjyLFDWbg==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-resolve-dependencies@29.7.0:\n    resolution: {integrity: sha512-un0zD/6qxJ+S0et7WxeI3H5XSe9lTBBR7bOHCHXkKR6luG5mwDDlIzVQ0V5cZCuoTgEdcdwzTghYkTWfubi+nA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-resolve@29.7.0:\n    resolution: {integrity: sha512-IOVhZSrg+UvVAshDSDtHyFCCBUl/Q3AAJv8iZ6ZjnZ74xzvwuzLXid9IIIPgTnY62SJjfuupMKZsZQRsCvxEgA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-runner@29.7.0:\n    resolution: {integrity: sha512-fsc4N6cPCAahybGBfTRcq5wFR6fpLznMg47sY5aDpsoejOcVYFb07AHuSnR0liMcPTgBsA3ZJL6kFOjPdoNipQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-runtime@29.7.0:\n    resolution: {integrity: sha512-gUnLjgwdGqW7B4LvOIkbKs9WGbn+QLqRQQ9juC6HndeDiezIwhDP+mhMwHWCEcfQ5RUXa6OPnFF8BJh5xegwwQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-snapshot@29.7.0:\n    resolution: {integrity: sha512-Rm0BMWtxBcioHr1/OX5YCP8Uov4riHvKPknOGs804Zg9JGZgmIBkbtlxJC/7Z4msKYVbIJtfU+tKb8xlYNfdkw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-util@29.7.0:\n    resolution: {integrity: sha512-z6EbKajIpqGKU56y5KBUgy1dt1ihhQJgWzUlZHArA/+X2ad7Cb5iF+AK1EWVL/Bo7Rz9uurpqw6SiBCefUbCGA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-validate@29.7.0:\n    resolution: {integrity: sha512-ZB7wHqaRGVw/9hST/OuFUReG7M8vKeq0/J2egIGLdvjHCmYqGARhzXmtgi+gVeZ5uXFF219aOc3Ls2yLg27tkw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-watcher@29.7.0:\n    resolution: {integrity: sha512-49Fg7WXkU3Vl2h6LbLtMQ/HyB6rXSIX7SqvBLQmssRBGN9I0PNvPmAmCWSOY6SOvrjhI/F7/bGAv9RtnsPA03g==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest-worker@27.5.1:\n    resolution: {integrity: sha512-7vuh85V5cdDofPyxn58nrPjBktZo0u9x1g8WtjQol+jZDaE+fhN+cIvTj11GndBnMnyfrUOG1sZQxCdjKh+DKg==}\n    engines: {node: '>= 10.13.0'}\n\n  jest-worker@29.7.0:\n    resolution: {integrity: sha512-eIz2msL/EzL9UFTFFx7jBTkeZfku0yUAyZZZmJ93H2TYEiroIx2PQjEXcwYtYl8zXCxb+PAmA2hLIt/6ZEkPHw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  jest@29.7.0:\n    resolution: {integrity: sha512-NIy3oAFp9shda19hy4HK0HRTWKtPJmGdnvywu01nOqNC2vZg+Z+fvJDxpMQA88eb2I9EcafcdjYgsDthnYTvGw==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n    hasBin: true\n    peerDependencies:\n      node-notifier: ^8.0.1 || ^9.0.0 || ^10.0.0\n    peerDependenciesMeta:\n      node-notifier:\n        optional: true\n\n  jiti@1.17.1:\n    resolution: {integrity: sha512-NZIITw8uZQFuzQimqjUxIrIcEdxYDFIe/0xYfIlVXTkiBjjyBEvgasj5bb0/cHtPRD/NziPbT312sFrkI5ALpw==}\n    hasBin: true\n\n  jiti@1.21.0:\n    resolution: {integrity: sha512-gFqAIbuKyyso/3G2qhiO2OM6shY6EPP/R0+mkDbyspxKazh8BXDC5FiFsUjlczgdNz/vfra0da2y+aHrusLG/Q==}\n    hasBin: true\n\n  jiti@1.21.6:\n    resolution: {integrity: sha512-2yTgeWTWzMWkHu6Jp9NKgePDaYHbntiwvYuuJLbbN9vl7DC9DvXKOB2BC3ZZ92D3cvV/aflH0osDfwpHepQ53w==}\n    hasBin: true\n\n  jiti@2.3.3:\n    resolution: {integrity: sha512-EX4oNDwcXSivPrw2qKH2LB5PoFxEvgtv2JgwW0bU858HoLQ+kutSvjLMUqBd0PeJYEinLWhoI9Ol0eYMqj/wNQ==}\n    hasBin: true\n\n  jose@5.9.3:\n    resolution: {integrity: sha512-egLIoYSpcd+QUF+UHgobt5YzI2Pkw/H39ou9suW687MY6PmCwPmkNV/4TNjn1p2tX5xO3j0d0sq5hiYE24bSlg==}\n\n  joycon@3.1.1:\n    resolution: {integrity: sha512-34wB/Y7MW7bzjKRjUKTa46I2Z7eV62Rkhva+KkopW7Qvv/OSWBqvkSY7vusOPrNuZcUG3tApvdVgNB8POj3SPw==}\n    engines: {node: '>=10'}\n\n  js-base64@3.7.7:\n    resolution: {integrity: sha512-7rCnleh0z2CkXhH67J8K1Ytz0b2Y+yxTPL+/KOJoa20hfnVQ/3/T6W/KflYI4bRHRagNeXeU2bkNGI3v1oS/lw==}\n\n  js-md5@0.8.3:\n    resolution: {integrity: sha512-qR0HB5uP6wCuRMrWPTrkMaev7MJZwJuuw4fnwAzRgP4J4/F8RwtodOKpGp4XpqsLBFzzgqIO42efFAyz2Et6KQ==}\n\n  js-stringify@1.0.2:\n    resolution: {integrity: sha512-rtS5ATOo2Q5k1G+DADISilDA6lv79zIiwFd6CcjuIxGKLFm5C+RLImRscVap9k55i+MOZwgliw+NejvkLuGD5g==}\n\n  js-tokens@4.0.0:\n    resolution: {integrity: sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==}\n\n  js-yaml@3.14.1:\n    resolution: {integrity: sha512-okMH7OXXJ7YrN9Ok3/SXrnu4iX9yOk+25nqX4imS2npuvTYDmo/QEZoqwZkYaIDk3jVvBOTOIEgEhaLOynBS9g==}\n    hasBin: true\n\n  js-yaml@4.1.0:\n    resolution: {integrity: sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==}\n    hasBin: true\n\n  jsdom@25.0.1:\n    resolution: {integrity: sha512-8i7LzZj7BF8uplX+ZyOlIz86V6TAsSs+np6m1kpW9u0JWi4z/1t+FzcK1aek+ybTnAC4KhBL4uXCNT0wcUIeCw==}\n    engines: {node: '>=18'}\n    peerDependencies:\n      canvas: ^2.11.2\n    peerDependenciesMeta:\n      canvas:\n        optional: true\n\n  jsep@1.3.9:\n    resolution: {integrity: sha512-i1rBX5N7VPl0eYb6+mHNp52sEuaS2Wi8CDYx1X5sn9naevL78+265XJqy1qENEk7mRKwS06NHpUqiBwR7qeodw==}\n    engines: {node: '>= 10.16.0'}\n\n  jsesc@3.0.2:\n    resolution: {integrity: sha512-xKqzzWXDttJuOcawBt4KnKHHIf5oQ/Cxax+0PWFG+DFDgHNAdi+TXECADI+RYiFUMmx8792xsMbbgXj4CwnP4g==}\n    engines: {node: '>=6'}\n    hasBin: true\n\n  json-buffer@3.0.1:\n    resolution: {integrity: sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==}\n\n  json-parse-better-errors@1.0.2:\n    resolution: {integrity: sha512-mrqyZKfX5EhL7hvqcV6WG1yYjnjeuYDzDhhcAAUrq8Po85NBQBJP+ZDUT75qZQ98IkUoBqdkExkukOU7Ts2wrw==}\n\n  json-parse-even-better-errors@2.3.1:\n    resolution: {integrity: sha512-xyFwyhro/JEof6Ghe2iz2NcXoj2sloNsWr/XsERDK/oiPCfaNhl5ONfp+jQdAZRQQ0IJWNzH9zIZF7li91kh2w==}\n\n  json-schema-ref-parser@7.1.4:\n    resolution: {integrity: sha512-AD7bvav0vak1/63w3jH8F7eHId/4E4EPdMAEZhGxtjktteUv9dnNB/cJy6nVnMyoTPBJnLwFK6tiQPSTeleCtQ==}\n    deprecated: Please switch to @apidevtools/json-schema-ref-parser\n\n  json-schema-traverse@0.4.1:\n    resolution: {integrity: sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==}\n\n  json-schema-traverse@1.0.0:\n    resolution: {integrity: sha512-NM8/P9n3XjXhIZn1lLhkFaACTOURQXjWhV4BA/RnOv8xvgqtqpAX9IO4mRQxSx1Rlo4tqzeqb0sOlruaOy3dug==}\n\n  json-schema@0.4.0:\n    resolution: {integrity: sha512-es94M3nTIfsEPisRafak+HDLfHXnKBhV3vU5eqPcS3flIWqcxJWgXHXiey3YrpaNsanY5ei1VoYEbOzijuq9BA==}\n\n  json-stable-stringify-without-jsonify@1.0.1:\n    resolution: {integrity: sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==}\n\n  json-to-pretty-yaml@1.2.2:\n    resolution: {integrity: sha512-rvm6hunfCcqegwYaG5T4yKJWxc9FXFgBVrcTZ4XfSVRwa5HA/Xs+vB/Eo9treYYHCeNM0nrSUr82V/M31Urc7A==}\n    engines: {node: '>= 0.2.0'}\n\n  json5@2.2.3:\n    resolution: {integrity: sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==}\n    engines: {node: '>=6'}\n    hasBin: true\n\n  jsonc-eslint-parser@1.4.1:\n    resolution: {integrity: sha512-hXBrvsR1rdjmB2kQmUjf1rEIa+TqHBGMge8pwi++C+Si1ad7EjZrJcpgwym+QGK/pqTx+K7keFAtLlVNdLRJOg==}\n    engines: {node: '>=8.10.0'}\n\n  jsonc-eslint-parser@2.4.0:\n    resolution: {integrity: sha512-WYDyuc/uFcGp6YtM2H0uKmUwieOuzeE/5YocFJLnLfclZ4inf3mRn8ZVy1s7Hxji7Jxm6Ss8gqpexD/GlKoGgg==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  jsonc-parser@3.2.1:\n    resolution: {integrity: sha512-AilxAyFOAcK5wA1+LeaySVBrHsGQvUFCDWXKpZjzaL0PqW+xfBOttn8GNtWKFWqneyMZj41MWF9Kl6iPWLwgOA==}\n\n  jsonc-parser@3.3.1:\n    resolution: {integrity: sha512-HUgH65KyejrUFPvHFPbqOY0rsFip3Bo5wb4ngvdi1EpCYWUQDC5V+Y7mZws+DLkr4M//zQJoanu1SP+87Dv1oQ==}\n\n  jsonfile@6.1.0:\n    resolution: {integrity: sha512-5dgndWOriYSm5cnYaJNhalLNDKOqFwyDB/rr1E9ZsGciGvKPs8R2xYGCacuf3z6K1YKDz182fd+fY3cn3pMqXQ==}\n\n  jsonparse@1.3.1:\n    resolution: {integrity: sha512-POQXvpdL69+CluYsillJ7SUhKvytYjW9vG/GKpnf+xP8UWgYEM/RaMzHHofbALDiKbbP1W8UEYmgGl39WkPZsg==}\n    engines: {'0': node >= 0.2.0}\n\n  jsonpath-plus@10.0.0:\n    resolution: {integrity: sha512-v7j76HGp/ibKlXYeZ7UrfCLSNDaBWuJMA0GaMjA4sZJtCtY89qgPyToDDcl2zdeHh4B5q/B3g2pQdW76fOg/dA==}\n    engines: {node: '>=18.0.0'}\n    hasBin: true\n\n  jsonpointer@5.0.1:\n    resolution: {integrity: sha512-p/nXbhSEcu3pZRdkW1OfJhpsVtW1gd4Wa1fnQc9YLiTfAjn0312eMKimbdIQzuZl9aa9xUGaRlP9T/CJE/ditQ==}\n    engines: {node: '>=0.10.0'}\n\n  jsonwebtoken@9.0.2:\n    resolution: {integrity: sha512-PRp66vJ865SSqOlgqS8hujT5U4AOgMfhrwYIuIhfKaoSCZcirrmASQr8CX7cUg+RMih+hgznrjp99o+W4pJLHQ==}\n    engines: {node: '>=12', npm: '>=6'}\n\n  jstransformer@1.0.0:\n    resolution: {integrity: sha512-C9YK3Rf8q6VAPDCCU9fnqo3mAfOH6vUGnMcP4AQAYIEpWtfGLpwOTmZ+igtdK5y+VvI2n3CyYSzy4Qh34eq24A==}\n\n  jszip@3.10.1:\n    resolution: {integrity: sha512-xXDvecyTpGLrqFrvkrUSoxxfJI5AH7U8zxxtVclpsUtMCq4JQ290LY8AW5c7Ggnr/Y/oK+bQMbqK2qmtk3pN4g==}\n\n  juice@10.0.1:\n    resolution: {integrity: sha512-ZhJT1soxJCkOiO55/mz8yeBKTAJhRzX9WBO+16ZTqNTONnnVlUPyVBIzQ7lDRjaBdTbid+bAnyIon/GM3yp4cA==}\n    engines: {node: '>=10.0.0'}\n    hasBin: true\n\n  jwa@1.4.1:\n    resolution: {integrity: sha512-qiLX/xhEEFKUAJ6FiBMbes3w9ATzyk5W7Hvzpa/SLYdxNtng+gcurvrI7TbACjIXlsJyr05/S1oUhZrc63evQA==}\n\n  jws@3.2.2:\n    resolution: {integrity: sha512-YHlZCB6lMTllWDtSPHz/ZXTsi8S00usEV6v1tjq8tOUZzw7DpSDWVXjXDre6ed1w/pd495ODpHZYSdkRTsa0HA==}\n\n  keyv@4.5.4:\n    resolution: {integrity: sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==}\n\n  kleur@3.0.3:\n    resolution: {integrity: sha512-eTIzlVOSUR+JxdDFepEYcBMtZ9Qqdef+rnzWdRZuMbOywu5tO2w2N7rqjoANZ5k9vywhL6Br1VRjUIgTQx4E8w==}\n    engines: {node: '>=6'}\n\n  kolorist@1.8.0:\n    resolution: {integrity: sha512-Y+60/zizpJ3HRH8DCss+q95yr6145JXZo46OTpFvDZWLfRCE4qChOyk1b26nMaNpfHHgxagk9dXT5OP0Tfe+dQ==}\n\n  leac@0.6.0:\n    resolution: {integrity: sha512-y+SqErxb8h7nE/fiEX07jsbuhrpO9lL8eca7/Y1nuWV2moNlXhyd59iDGcRf6moVyDMbmTNzL40SUyrFU/yDpg==}\n\n  leven@3.1.0:\n    resolution: {integrity: sha512-qsda+H8jTaUaN/x5vzW2rzc+8Rw4TAQ/4KjB46IwK5VH+IlVeeeje/EoZRpiXvIqjFgK84QffqPztGI3VBLG1A==}\n    engines: {node: '>=6'}\n\n  levn@0.4.1:\n    resolution: {integrity: sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==}\n    engines: {node: '>= 0.8.0'}\n\n  libbase64@1.2.1:\n    resolution: {integrity: sha512-l+nePcPbIG1fNlqMzrh68MLkX/gTxk/+vdvAb388Ssi7UuUN31MI44w4Yf33mM3Cm4xDfw48mdf3rkdHszLNew==}\n\n  libbase64@1.3.0:\n    resolution: {integrity: sha512-GgOXd0Eo6phYgh0DJtjQ2tO8dc0IVINtZJeARPeiIJqge+HdsWSuaDTe8ztQ7j/cONByDZ3zeB325AHiv5O0dg==}\n\n  libmime@5.2.0:\n    resolution: {integrity: sha512-X2U5Wx0YmK0rXFbk67ASMeqYIkZ6E5vY7pNWRKtnNzqjvdYYG8xtPDpCnuUEnPU9vlgNev+JoSrcaKSUaNvfsw==}\n\n  libmime@5.3.5:\n    resolution: {integrity: sha512-nSlR1yRZ43L3cZCiWEw7ali3jY29Hz9CQQ96Oy+sSspYnIP5N54ucOPHqooBsXzwrX1pwn13VUE05q4WmzfaLg==}\n\n  libphonenumber-js@1.11.4:\n    resolution: {integrity: sha512-F/R50HQuWWYcmU/esP5jrH5LiWYaN7DpN0a/99U8+mnGGtnx8kmRE+649dQh3v+CowXXZc8vpkf5AmYkO0AQ7Q==}\n\n  libqp@2.0.1:\n    resolution: {integrity: sha512-Ka0eC5LkF3IPNQHJmYBWljJsw0UvM6j+QdKRbWyCdTmYwvIDE6a7bCm0UkTAL/K+3KXK5qXT/ClcInU01OpdLg==}\n\n  libqp@2.1.0:\n    resolution: {integrity: sha512-O6O6/fsG5jiUVbvdgT7YX3xY3uIadR6wEZ7+vy9u7PKHAlSEB6blvC1o5pHBjgsi95Uo0aiBBdkyFecj6jtb7A==}\n\n  lie@3.3.0:\n    resolution: {integrity: sha512-UaiMJzeWRlEujzAuw5LokY1L5ecNQYZKfmyZ9L7wDHb/p5etKaxXhohBcrw0EYby+G/NA52vRSN4N39dxHAIwQ==}\n\n  lilconfig@2.1.0:\n    resolution: {integrity: sha512-utWOt/GHzuUxnLKxB6dk81RoOeoNeHgbrXiuGk4yyF5qlRz+iIVWu56E2fqGHFrXz0QNUhLB/8nKqvRH66JKGQ==}\n    engines: {node: '>=10'}\n\n  lilconfig@3.1.2:\n    resolution: {integrity: sha512-eop+wDAvpItUys0FWkHIKeC9ybYrTGbU41U5K7+bttZZeohvnY7M9dZ5kB21GNWiFT2q1OoPTvncPCgSOVO5ow==}\n    engines: {node: '>=14'}\n\n  lines-and-columns@1.2.4:\n    resolution: {integrity: sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==}\n\n  linkify-it@5.0.0:\n    resolution: {integrity: sha512-5aHCbzQRADcdP+ATqnDuhhJ/MRIqDkZX5pyjFHRRysS8vZ5AbqGEoFIb6pYHPZ+L/OC2Lc+xT8uHVVR5CAK/wQ==}\n\n  lint-staged@15.2.10:\n    resolution: {integrity: sha512-5dY5t743e1byO19P9I4b3x8HJwalIznL5E1FWYnU6OWw33KxNBSLAc6Cy7F2PsFEO8FKnLwjwm5hx7aMF0jzZg==}\n    engines: {node: '>=18.12.0'}\n    hasBin: true\n\n  liquid-json@0.3.1:\n    resolution: {integrity: sha512-wUayTU8MS827Dam6MxgD72Ui+KOSF+u/eIqpatOtjnvgJ0+mnDq33uC2M7J0tPK+upe/DpUAuK4JUU89iBoNKQ==}\n    engines: {node: '>=4'}\n\n  liquidjs@10.17.0:\n    resolution: {integrity: sha512-M4MC5/nencttIJHirl5jFTkl7Yu+grIDLn3Qgl7BPAD3BsbTCQknDxlG5VXWRwslWIjk8lSZZjVq9LioILDk1Q==}\n    engines: {node: '>=14'}\n    hasBin: true\n\n  listr2@4.0.5:\n    resolution: {integrity: sha512-juGHV1doQdpNT3GSTs9IUN43QJb7KHdF9uqg7Vufs/tG9VTzpFphqF4pm/ICdAABGQxsyNn9CiYA3StkI6jpwA==}\n    engines: {node: '>=12'}\n    peerDependencies:\n      enquirer: '>= 2.3.0 < 3'\n    peerDependenciesMeta:\n      enquirer:\n        optional: true\n\n  listr2@8.2.5:\n    resolution: {integrity: sha512-iyAZCeyD+c1gPyE9qpFu8af0Y+MRtmKOncdGoA2S5EY8iFq99dmmvkNnHiWo+pj0s7yH7l3KPIgee77tKpXPWQ==}\n    engines: {node: '>=18.0.0'}\n\n  load-json-file@4.0.0:\n    resolution: {integrity: sha512-Kx8hMakjX03tiGTLAIdJ+lL0htKnXjEZN6hk/tozf/WOuYGdZBJrZ+rCJRbVCugsjB3jMLn9746NsQIf5VjBMw==}\n    engines: {node: '>=4'}\n\n  load-tsconfig@0.2.5:\n    resolution: {integrity: sha512-IXO6OCs9yg8tMKzfPZ1YmheJbZCiEsnBdcB03l0OcfK9prKnJb96siuHCr5Fl37/yo9DnKU+TLpxzTUspw9shg==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  loader-runner@4.3.0:\n    resolution: {integrity: sha512-3R/1M+yS3j5ou80Me59j7F9IMs4PXs3VqRrm0TU3AbKPxlmpoY1TNscJV/oGJXo8qCatFGTfDbY6W6ipGOYXfg==}\n    engines: {node: '>=6.11.5'}\n\n  local-pkg@0.4.3:\n    resolution: {integrity: sha512-SFppqq5p42fe2qcZQqqEOiVRXl+WCP1MdT6k7BDEW1j++sp5fIY+/fdRQitvKgB5BrBcmrs5m/L0v2FrU5MY1g==}\n    engines: {node: '>=14'}\n\n  local-pkg@0.5.0:\n    resolution: {integrity: sha512-ok6z3qlYyCDS4ZEU27HaU6x/xZa9Whf8jD4ptH5UZTQYZVYeb9bnZ3ojVhiJNLiXK1Hfc0GNbLXcmZ5plLDDBg==}\n    engines: {node: '>=14'}\n\n  locate-path@5.0.0:\n    resolution: {integrity: sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==}\n    engines: {node: '>=8'}\n\n  locate-path@6.0.0:\n    resolution: {integrity: sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==}\n    engines: {node: '>=10'}\n\n  locate-path@7.2.0:\n    resolution: {integrity: sha512-gvVijfZvn7R+2qyPX8mAuKcFGDf6Nc61GdvGafQsHL0sBIxfKzA+usWn4GFC/bk+QdwPUD4kWFJLhElipq+0VA==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  lodash-es@4.17.21:\n    resolution: {integrity: sha512-mKnC+QJ9pWVzv+C4/U3rRsHapFfHvQFoFB92e52xeyGMcX6/OlIl78je1u8vePzYZSkkogMPJ2yjxxsb89cxyw==}\n\n  lodash.camelcase@4.3.0:\n    resolution: {integrity: sha512-TwuEnCnxbc3rAvhf/LbG7tJUDzhqXyFnv3dtzLOPgCG/hODL7WFnsbwktkD7yUV0RrreP/l1PALq/YSg6VvjlA==}\n\n  lodash.debounce@4.0.8:\n    resolution: {integrity: sha512-FT1yDzDYEoYWhnSGnpE/4Kj1fLZkDFyqRb7fNt6FdYOSxlUWAtp42Eh6Wb0rGIv/m9Bgo7x4GhQbm5Ys4SG5ow==}\n\n  lodash.defaults@4.2.0:\n    resolution: {integrity: sha512-qjxPLHd3r5DnsdGacqOMU6pb/avJzdh9tFX2ymgoZE27BmjXrNy/y4LoaiTeAb+O3gL8AfpJGtqfX/ae2leYYQ==}\n\n  lodash.get@4.4.2:\n    resolution: {integrity: sha512-z+Uw/vLuy6gQe8cfaFWD7p0wVv8fJl3mbzXh33RS+0oW2wvUqiRXiQ69gLWSLpgB5/6sU+r6BlQR0MBILadqTQ==}\n\n  lodash.includes@4.3.0:\n    resolution: {integrity: sha512-W3Bx6mdkRTGtlJISOvVD/lbqjTlPPUDTMnlXZFnVwi9NKJ6tiAk6LVdlhZMm17VZisqhKcgzpO5Wz91PCt5b0w==}\n\n  lodash.isarguments@3.1.0:\n    resolution: {integrity: sha512-chi4NHZlZqZD18a0imDHnZPrDeBbTtVN7GXMwuGdRH9qotxAjYs3aVLKc7zNOG9eddR5Ksd8rvFEBc9SsggPpg==}\n\n  lodash.isboolean@3.0.3:\n    resolution: {integrity: sha512-Bz5mupy2SVbPHURB98VAcw+aHh4vRV5IPNhILUCsOzRmsTmSQ17jIuqopAentWoehktxGd9e/hbIXq980/1QJg==}\n\n  lodash.isequal@4.5.0:\n    resolution: {integrity: sha512-pDo3lu8Jhfjqls6GkMgpahsF9kCyayhgykjyLMNFTKWrpVdAQtYyB4muAMWozBB4ig/dtWAmsMxLEI8wuz+DYQ==}\n\n  lodash.isinteger@4.0.4:\n    resolution: {integrity: sha512-DBwtEWN2caHQ9/imiNeEA5ys1JoRtRfY3d7V9wkqtbycnAmTvRRmbHKDV4a0EYc678/dia0jrte4tjYwVBaZUA==}\n\n  lodash.isnumber@3.0.3:\n    resolution: {integrity: sha512-QYqzpfwO3/CWf3XP+Z+tkQsfaLL/EnUlXWVkIk5FUPc4sBdTehEqZONuyRt2P67PXAk+NXmTBcc97zw9t1FQrw==}\n\n  lodash.isplainobject@4.0.6:\n    resolution: {integrity: sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==}\n\n  lodash.isstring@4.0.1:\n    resolution: {integrity: sha512-0wJxfxH1wgO3GrbuP+dTTk7op+6L41QCXbGINEmD+ny/G/eCqGzxyCsh7159S+mgDDcoarnBw6PC1PS5+wUGgw==}\n\n  lodash.kebabcase@4.1.1:\n    resolution: {integrity: sha512-N8XRTIMMqqDgSy4VLKPnJ/+hpGZN+PHQiJnSenYqPaVV/NCqEogTnAdZLQiGKhxX+JCs8waWq2t1XHWKOmlY8g==}\n\n  lodash.memoize@4.1.2:\n    resolution: {integrity: sha512-t7j+NzmgnQzTAYXcsHYLgimltOV1MXHtlOWf6GjL9Kj8GK5FInw5JotxvbOs+IvV1/Dzo04/fCGfLVs7aXb4Ag==}\n\n  lodash.merge@4.6.2:\n    resolution: {integrity: sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==}\n\n  lodash.mergewith@4.6.2:\n    resolution: {integrity: sha512-GK3g5RPZWTRSeLSpgP8Xhra+pnjBC56q9FZYe1d5RN3TJ35dbkGy3YqBSMbyCrlbi+CM9Z3Jk5yTL7RCsqboyQ==}\n\n  lodash.omit@4.5.0:\n    resolution: {integrity: sha512-XeqSp49hNGmlkj2EJlfrQFIzQ6lXdNro9sddtQzcJY8QaoC2GO0DT7xaIokHeyM+mIT0mPMlPvkYzg2xCuHdZg==}\n\n  lodash.once@4.1.1:\n    resolution: {integrity: sha512-Sb487aTOCr9drQVL8pIxOzVhafOjZN9UU54hiN8PU3uAiSV7lx1yYNpbNmex2PK6dSJoNTSJUUswT651yww3Mg==}\n\n  lodash.snakecase@4.1.1:\n    resolution: {integrity: sha512-QZ1d4xoBHYUeuouhEq3lk3Uq7ldgyFXGBhg04+oRLnIz8o9T65Eh+8YdroUwn846zchkA9yDsDl5CVVaV2nqYw==}\n\n  lodash.sortby@4.7.0:\n    resolution: {integrity: sha512-HDWXG8isMntAyRF5vZ7xKuEvOhT4AhlRt/3czTSjvGUxjYCBVRQY48ViDHyfYz9VIoBkW4TMGQNapx+l3RUwdA==}\n\n  lodash.startcase@4.4.0:\n    resolution: {integrity: sha512-+WKqsK294HMSc2jEbNgpHpd0JfIBhp7rEV4aqXWqFr6AlXov+SlcgB1Fv01y2kGe3Gc8nMW7VA0SrGuSkRfIEg==}\n\n  lodash.uniq@4.5.0:\n    resolution: {integrity: sha512-xfBaXQd9ryd9dlSDvnvI0lvxfLJlYAZzXomUYzLKtUeOQvOP5piqAWuGtrhWeqaXK9hhoM/iyJc5AV+XfsX3HQ==}\n\n  lodash.upperfirst@4.3.1:\n    resolution: {integrity: sha512-sReKOYJIJf74dhJONhU4e0/shzi1trVbSWDOhKYE5XV2O+H7Sb2Dihwuc7xWxVl+DgFPyTqIN3zMfT9cq5iWDg==}\n\n  lodash@4.17.21:\n    resolution: {integrity: sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg==}\n\n  log-symbols@4.1.0:\n    resolution: {integrity: sha512-8XPvpAA8uyhfteu8pIvQxpJZ7SYYdpUivZpGy6sFsBuKRY/7rQGavedeB8aK+Zkyq6upMFVL/9AW6vOYzfRyLg==}\n    engines: {node: '>=10'}\n\n  log-update@4.0.0:\n    resolution: {integrity: sha512-9fkkDevMefjg0mmzWFBW8YkFP91OrizzkW3diF7CpG+S2EYdy4+TVfGwz1zeF8x7hCx1ovSPTOE9Ngib74qqUg==}\n    engines: {node: '>=10'}\n\n  log-update@6.1.0:\n    resolution: {integrity: sha512-9ie8ItPR6tjY5uYJh8K/Zrv/RMZ5VOlOWvtZdEHYSTFKZfIBPQa9tOAEeAWhd+AnIneLJ22w5fjOYtoutpWq5w==}\n    engines: {node: '>=18'}\n\n  loglevel@1.9.2:\n    resolution: {integrity: sha512-HgMmCqIJSAKqo68l0rS2AanEWfkxaZ5wNiEFb5ggm08lDs9Xl2KxBlX3PTcaD2chBM1gXAYf491/M2Rv8Jwayg==}\n    engines: {node: '>= 0.6.0'}\n\n  long@4.0.0:\n    resolution: {integrity: sha512-XsP+KhQif4bjX1kbuSiySJFNAehNxgLb6hPRGJ9QsUr8ajHkuXGdrHmFUTUUXhDwVX2R5bY4JNZEwbUiMhV+MA==}\n\n  loose-envify@1.4.0:\n    resolution: {integrity: sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==}\n    hasBin: true\n\n  lossless-json@4.0.2:\n    resolution: {integrity: sha512-+z0EaLi2UcWi8MZRxA5iTb6m4Ys4E80uftGY+yG5KNFJb5EceQXOhdW/pWJZ8m97s26u7yZZAYMcKWNztSZssA==}\n\n  loupe@3.1.2:\n    resolution: {integrity: sha512-23I4pFZHmAemUnz8WZXbYRSKYj801VDaNv9ETuMh7IrMc7VuVVSo+Z9iLE3ni30+U48iDWfi30d3twAXBYmnCg==}\n\n  lower-case-first@2.0.2:\n    resolution: {integrity: sha512-EVm/rR94FJTZi3zefZ82fLWab+GX14LJN4HrWBcuo6Evmsl9hEfnqxgcHCKb9q+mNf6EVdsjx/qucYFIIB84pg==}\n\n  lower-case@2.0.2:\n    resolution: {integrity: sha512-7fm3l3NAF9WfN6W3JOmf5drwpVqX78JtoGJ3A6W0a6ZnldM41w2fV5D490psKFTpMds8TJse/eHLFFsNHHjHgg==}\n\n  lru-cache@10.4.3:\n    resolution: {integrity: sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==}\n\n  lru-cache@11.0.1:\n    resolution: {integrity: sha512-CgeuL5uom6j/ZVrg7G/+1IXqRY8JXX4Hghfy5YE0EhoYQWvndP1kufu58cmZLNIDKnRhZrXfdS9urVWx98AipQ==}\n    engines: {node: 20 || >=22}\n\n  lru-cache@5.1.1:\n    resolution: {integrity: sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==}\n\n  lru-cache@7.18.3:\n    resolution: {integrity: sha512-jumlc0BIUrS3qJGgIkWZsyfAM7NCWiBcCDhnd+3NNM5KbBmLTgHVfWBcg6W+rLUsIpzpERPsvwUP7CckAQSOoA==}\n    engines: {node: '>=12'}\n\n  luxon@3.4.4:\n    resolution: {integrity: sha512-zobTr7akeGHnv7eBOXcRgMeCP6+uyYsczwmeRCauvpvaAltgNyTbLH/+VaEAPUeWBT+1GuNmz4wC/6jtQzbbVA==}\n    engines: {node: '>=12'}\n\n  luxon@3.5.0:\n    resolution: {integrity: sha512-rh+Zjr6DNfUYR3bPwJEnuwDdqMbxZW7LOQfUN4B54+Cl+0o5zaU9RJ6bcidfDtC1cWCZXQ+nvX8bf6bAji37QQ==}\n    engines: {node: '>=12'}\n\n  magic-string@0.25.9:\n    resolution: {integrity: sha512-RmF0AsMzgt25qzqqLc1+MbHmhdx0ojF2Fvs4XnOqz2ZOBXzzkEwc/dJQZCYHAn7v1jbVOjAZfK8msRn4BxO4VQ==}\n\n  magic-string@0.26.7:\n    resolution: {integrity: sha512-hX9XH3ziStPoPhJxLq1syWuZMxbDvGNbVchfrdCtanC7D13888bMFow61x8axrx+GfHLtVeAx2kxL7tTGRl+Ow==}\n    engines: {node: '>=12'}\n\n  magic-string@0.30.11:\n    resolution: {integrity: sha512-+Wri9p0QHMy+545hKww7YAu5NyzF8iomPL/RQazugQ9+Ez4Ic3mERMd8ZTX5rfK944j+560ZJi8iAwgak1Ac7A==}\n\n  magic-string@0.30.8:\n    resolution: {integrity: sha512-ISQTe55T2ao7XtlAStud6qwYPZjE4GK1S/BeVPus4jrq6JuOnQ00YKQC581RWhR122W7msZV263KzVeLoqidyQ==}\n    engines: {node: '>=12'}\n\n  mailparser@3.7.1:\n    resolution: {integrity: sha512-RCnBhy5q8XtB3mXzxcAfT1huNqN93HTYYyL6XawlIKycfxM/rXPg9tXoZ7D46+SgCS1zxKzw+BayDQSvncSTTw==}\n\n  mailsplit@5.4.0:\n    resolution: {integrity: sha512-wnYxX5D5qymGIPYLwnp6h8n1+6P6vz/MJn5AzGjZ8pwICWssL+CCQjWBIToOVHASmATot4ktvlLo6CyLfOXWYA==}\n\n  make-dir@3.1.0:\n    resolution: {integrity: sha512-g3FeP20LNwhALb/6Cz6Dd4F2ngze0jz7tbzrD2wAV+o9FeNHe4rL+yK2md0J/fiSf1sa1ADhXqi5+oVwOM/eGw==}\n    engines: {node: '>=8'}\n\n  make-dir@4.0.0:\n    resolution: {integrity: sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==}\n    engines: {node: '>=10'}\n\n  make-error@1.3.6:\n    resolution: {integrity: sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==}\n\n  makeerror@1.0.12:\n    resolution: {integrity: sha512-JmqCvUhmt43madlpFzG4BQzG2Z3m6tvQDNKdClZnO3VbIudJYmxsT0FNJMeiB2+JTSlTQTSbU8QdesVmwJcmLg==}\n\n  map-cache@0.2.2:\n    resolution: {integrity: sha512-8y/eV9QQZCiyn1SprXSrCmqJN0yNRATe+PO8ztwqrvrbdRLA3eYJF0yaR0YayLWkMbsQSKWS9N2gPcGEc4UsZg==}\n    engines: {node: '>=0.10.0'}\n\n  map-stream@0.0.7:\n    resolution: {integrity: sha512-C0X0KQmGm3N2ftbTGBhSyuydQ+vV1LC3f3zPvT3RXHXNZrvfPZcoXp/N5DOa8vedX/rTMm2CjTtivFg2STJMRQ==}\n\n  mdn-data@2.0.28:\n    resolution: {integrity: sha512-aylIc7Z9y4yzHYAJNuESG3hfhC+0Ibp/MAMiaOZgNv4pmEdFyfZhhhny4MNiAfWdBQ1RQ2mfDWmM1x8SvGyp8g==}\n\n  mdn-data@2.0.30:\n    resolution: {integrity: sha512-GaqWWShW4kv/G9IEucWScBx9G1/vsFZZJUO+tD26M8J8z3Kw5RDQjaoZe03YAClgeS/SWPOcb4nkFBTEi5DUEA==}\n\n  media-typer@0.3.0:\n    resolution: {integrity: sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==}\n    engines: {node: '>= 0.6'}\n\n  memfs@3.5.3:\n    resolution: {integrity: sha512-UERzLsxzllchadvbPs5aolHh65ISpKpM+ccLbOJ8/vvpBKmAWf+la7dXFy7Mr0ySHbdHrFv5kGFCUHHe6GFEmw==}\n    engines: {node: '>= 4.0.0'}\n\n  memory-fs@0.3.0:\n    resolution: {integrity: sha512-QTNXnl79X97kZ9jJk/meJrtDuvgvRakX5LU7HZW1L7MsXHuSTwoMIzN9tOLLH3Xfsj/gbsSqX/ovnsqz246zKQ==}\n\n  memorystream@0.3.1:\n    resolution: {integrity: sha512-S3UwM3yj5mtUSEfP41UZmt/0SCoVYUcU1rkXv+BQ5Ig8ndL4sPoJNBUJERafdPb5jjHJGuMgytgKvKIf58XNBw==}\n    engines: {node: '>= 0.10.0'}\n\n  mensch@0.3.4:\n    resolution: {integrity: sha512-IAeFvcOnV9V0Yk+bFhYR07O3yNina9ANIN5MoXBKYJ/RLYPurd2d0yw14MDhpr9/momp0WofT1bPUh3hkzdi/g==}\n\n  meow@12.1.1:\n    resolution: {integrity: sha512-BhXM0Au22RwUneMPwSCnyhTOizdWoIEPU9sp0Aqa1PnDMR5Wv2FGXYDjuzJEIX+Eo2Rb8xuYe5jrnm5QowQFkw==}\n    engines: {node: '>=16.10'}\n\n  meow@13.2.0:\n    resolution: {integrity: sha512-pxQJQzB6djGPXh08dacEloMFopsOqGVRKFPYvPOt9XDZ1HasbgDZA74CJGreSU4G3Ak7EFJGoiH2auq+yXISgA==}\n    engines: {node: '>=18'}\n\n  merge-descriptors@1.0.3:\n    resolution: {integrity: sha512-gaNvAS7TZ897/rVaZ0nMtAyxNyi/pdbjbAwUpFQpN70GqnVfOiXpeUUMKRBmzXaSQ8DdTX4/0ms62r2K+hE6mQ==}\n\n  merge-stream@2.0.0:\n    resolution: {integrity: sha512-abv/qOcuPfk3URPfDzmZU1LKmuw8kT+0nIHvKrKgFrwifol/doWcdA4ZqsWQ8ENrFKkd67Mfpo/LovbIUsbt3w==}\n\n  merge2@1.4.1:\n    resolution: {integrity: sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==}\n    engines: {node: '>= 8'}\n\n  meros@1.3.0:\n    resolution: {integrity: sha512-2BNGOimxEz5hmjUG2FwoxCt5HN7BXdaWyFqEwxPTrJzVdABtrL4TiHTcsWSFAxPQ/tOnEaQEJh3qWq71QRMY+w==}\n    engines: {node: '>=13'}\n    peerDependencies:\n      '@types/node': '>=13'\n    peerDependenciesMeta:\n      '@types/node':\n        optional: true\n\n  methods@1.1.2:\n    resolution: {integrity: sha512-iclAHeNqNm68zFtnZ0e+1L2yUIdvzNoauKU4WBA3VvH/vPFieF7qfRlwUZU+DA9P9bPXIS90ulxoUoCH23sV2w==}\n    engines: {node: '>= 0.6'}\n\n  micromatch@4.0.8:\n    resolution: {integrity: sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==}\n    engines: {node: '>=8.6'}\n\n  mime-db@1.52.0:\n    resolution: {integrity: sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==}\n    engines: {node: '>= 0.6'}\n\n  mime-format@2.0.1:\n    resolution: {integrity: sha512-XxU3ngPbEnrYnNbIX+lYSaYg0M01v6p2ntd2YaFksTu0vayaw5OJvbdRyWs07EYRlLED5qadUZ+xo+XhOvFhwg==}\n\n  mime-types@2.1.35:\n    resolution: {integrity: sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==}\n    engines: {node: '>= 0.6'}\n\n  mime@1.6.0:\n    resolution: {integrity: sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg==}\n    engines: {node: '>=4'}\n    hasBin: true\n\n  mime@2.6.0:\n    resolution: {integrity: sha512-USPkMeET31rOMiarsBNIHZKLGgvKc/LrjofAnBlOttf5ajRvqiRA8QsenbcooctK6d6Ts6aqZXBA+XbkKthiQg==}\n    engines: {node: '>=4.0.0'}\n    hasBin: true\n\n  mimic-fn@2.1.0:\n    resolution: {integrity: sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==}\n    engines: {node: '>=6'}\n\n  mimic-fn@4.0.0:\n    resolution: {integrity: sha512-vqiC06CuhBTUdZH+RYl8sFrL096vA45Ok5ISO6sE/Mr1jRbGH4Csnhi8f3wKVl7x8mO4Au7Ir9D3Oyv1VYMFJw==}\n    engines: {node: '>=12'}\n\n  mimic-function@5.0.1:\n    resolution: {integrity: sha512-VP79XUPxV2CigYP3jWwAUFSku2aKqBH7uTAapFWCBqutsbmDo96KY5o8uh6U+/YSIn5OxJnXp73beVkpqMIGhA==}\n    engines: {node: '>=18'}\n\n  mimic-response@2.1.0:\n    resolution: {integrity: sha512-wXqjST+SLt7R009ySCglWBCFpjUygmCIfD790/kVbiGmUgfYGuB14PiTd5DwVxSV4NcYHjzMkoj5LjQZwTQLEA==}\n    engines: {node: '>=8'}\n\n  mimic-response@3.1.0:\n    resolution: {integrity: sha512-z0yWI+4FDrrweS8Zmt4Ej5HdJmky15+L2e6Wgn3+iK5fWzb6T3fhNFq2+MeTRb064c6Wr4N/wv0DzQTjNzHNGQ==}\n    engines: {node: '>=10'}\n\n  minimatch@10.0.1:\n    resolution: {integrity: sha512-ethXTt3SGGR+95gudmqJ1eNhRO7eGEGIgYA9vnPatK4/etz2MEVDno5GMCibdMTuBMyElzIlgxMna3K94XDIDQ==}\n    engines: {node: 20 || >=22}\n\n  minimatch@3.1.2:\n    resolution: {integrity: sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==}\n\n  minimatch@4.2.1:\n    resolution: {integrity: sha512-9Uq1ChtSZO+Mxa/CL1eGizn2vRn3MlLgzhT0Iz8zaY8NdvxvB0d5QdPFmCKf7JKA9Lerx5vRrnwO03jsSfGG9g==}\n    engines: {node: '>=10'}\n\n  minimatch@4.2.3:\n    resolution: {integrity: sha512-lIUdtK5hdofgCTu3aT0sOaHsYR37viUuIc0rwnnDXImbwFRcumyLMeZaM0t0I/fgxS6s6JMfu0rLD1Wz9pv1ng==}\n    engines: {node: '>=10'}\n\n  minimatch@5.1.6:\n    resolution: {integrity: sha512-lKwV/1brpG6mBUFHtb7NUmtABCb2WZZmm2wNiOA5hAb8VdCS4B3dtMWyvcoViccwAW/COERjXLt0zP1zXUN26g==}\n    engines: {node: '>=10'}\n\n  minimatch@9.0.5:\n    resolution: {integrity: sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==}\n    engines: {node: '>=16 || 14 >=14.17'}\n\n  minimist@1.2.8:\n    resolution: {integrity: sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==}\n\n  minipass@3.3.6:\n    resolution: {integrity: sha512-DxiNidxSEK+tHG6zOIklvNOwm3hvCrbUrdtzY74U6HKTJxvIDfOUL5W5P2Ghd3DTkhhKPYGqeNUIh5qcM4YBfw==}\n    engines: {node: '>=8'}\n\n  minipass@5.0.0:\n    resolution: {integrity: sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ==}\n    engines: {node: '>=8'}\n\n  minipass@7.1.2:\n    resolution: {integrity: sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==}\n    engines: {node: '>=16 || 14 >=14.17'}\n\n  minisearch@7.1.0:\n    resolution: {integrity: sha512-tv7c/uefWdEhcu6hvrfTihflgeEi2tN6VV7HJnCjK6VxM75QQJh4t9FwJCsA2EsRS8LCnu3W87CuGPWMocOLCA==}\n\n  minizlib@2.1.2:\n    resolution: {integrity: sha512-bAxsR8BVfj60DWXHE3u30oHzfl4G7khkSuPW+qvpd7jFRHm7dLxOjUk1EHACJ/hxLY8phGJ0YhYHZo7jil7Qdg==}\n    engines: {node: '>= 8'}\n\n  mjml-accordion@5.0.0-alpha.4:\n    resolution: {integrity: sha512-Mw1DnHRJHwHLqkwAXcRLBHZMYLtw7qqDNJdxISihz5KyY2arc8MbZixoUHCd3M/2zw04J8fU5HJ8WslANrmu9g==}\n\n  mjml-body@5.0.0-alpha.4:\n    resolution: {integrity: sha512-hPa4JpaF7rmKgKdC/DqC9SM97XoXoWPAf8c+8GpSvn/9AwXnt9X0TgBoP7/sUR26N06j26+/fprB7cTiqy/glA==}\n\n  mjml-button@5.0.0-alpha.4:\n    resolution: {integrity: sha512-4rOobUMBuoDjsnqFgtLMBZMdnTmS8vMLI+ZfrvyyxaPL9RbeISZlbl3/RvxiZjAyctPh92X/PazKhHJyeSSqeg==}\n\n  mjml-carousel@5.0.0-alpha.4:\n    resolution: {integrity: sha512-cUPIFLoseSlsq0/w/gB5/sMd88P2LCPK+ISllSdvyO4Lo2+uHDlmwMxRCBBIuWJBunqVH9v2Z2MtAIOL6DqJsQ==}\n\n  mjml-cli@5.0.0-alpha.4:\n    resolution: {integrity: sha512-YXaCYxQ64I1DFmlJe5OI6S1U3jbF3CdfSw+IsOTxxY+i0lEyuiqJxLceKA2ogAwMjlZEm1BBGENqNnvDjeXmUw==}\n    hasBin: true\n\n  mjml-column@5.0.0-alpha.4:\n    resolution: {integrity: sha512-5gT0YNU+aAjpUxS39ySS2SqL+NLyXkCi4BPutzZTnmz2CvIwrBIOJVEHRAWSjNUWFfFLS4scquI8yO4g8AVfdA==}\n\n  mjml-core@5.0.0-alpha.4:\n    resolution: {integrity: sha512-QioM27JKUWhCfDbHxY1YnkgpTF0Y+hV1MHy5XeVTQlvIbEeRcO+gAPzhVooGYsKqQL/dWNM9jl34el0peRoscQ==}\n\n  mjml-divider@5.0.0-alpha.4:\n    resolution: {integrity: sha512-sPv5CARR7NX6ohbpJCzErgv3Y1rUnmtOs3SeiEgp4Y9J+O+wKaOZa/ffuNHVrxkC26U91e3zmbWItfIILPUgYA==}\n\n  mjml-group@5.0.0-alpha.4:\n    resolution: {integrity: sha512-V+YuKGwL6JMTAnvTsKQM4wF6VPiHCgo92aN9iNuY46N8oYM349pEgrHDBAWRhyZ7UAov/UoPUUJRydJk4PCGyw==}\n\n  mjml-head-attributes@5.0.0-alpha.4:\n    resolution: {integrity: sha512-EmyiNar6SeaMDcTa8gchUoONfNbUfCjI3eAwjkHy1SfDl5tXKku2W1oXCst8vtNpjoBzllHcTW81x0OpgDM4Cg==}\n\n  mjml-head-breakpoint@5.0.0-alpha.4:\n    resolution: {integrity: sha512-S8FBpMKO2wDTJscy6EtQuQRZMu1YSOD5fCZ6sHINWC2A40I1ZFsCAvlLtW/vr9P50XjgX06m1T/vTcYifMCMMQ==}\n\n  mjml-head-font@5.0.0-alpha.4:\n    resolution: {integrity: sha512-bc/bduI1BljN1rjcF8w5TOBZ+D0eBu5O0BnSqLwoct7xeoTTvYLxuTsdgoloh6Jm1vf3RMqr4ANySDrXvFkoPw==}\n\n  mjml-head-html-attributes@5.0.0-alpha.4:\n    resolution: {integrity: sha512-NJwXgE3o1E3BcVTG6+Hl/ofCZFsoKnjt//Sm/Ks+0u+aZD7VycsF+nXxBlMLOWhMQrP+JIZAok7mYE+A1ztAPg==}\n\n  mjml-head-preview@5.0.0-alpha.4:\n    resolution: {integrity: sha512-cH2VaTVapSeYd+OIfeG7yQtZVDSGqV86iUE4UHasTFpaxcPigpaS5NzAiDL9f7Pzp83q/eL6tdc3r7jX7IHkBQ==}\n\n  mjml-head-style@5.0.0-alpha.4:\n    resolution: {integrity: sha512-7WAsEctOMFOsH8WYrJ/6ZZ2x+m4SKCdpgXWoJwcIVVXiwt/I9C0iGW5b82ZJh0jaGEH5i1dsKMcMcvKnHuiTog==}\n\n  mjml-head-title@5.0.0-alpha.4:\n    resolution: {integrity: sha512-GL/LKPkqbyCb0fRrf5NL0Xx/1xX0nF5dVQsmwfH7YdGM8Syx+ging2lrOhRxUic6NE0STXz5H16c0+oisU2HCQ==}\n\n  mjml-head@5.0.0-alpha.4:\n    resolution: {integrity: sha512-QF+l4pCYbmTvFPz522k8hbzJgWGmOj16/bTwE+mhGueRRMGmVAp7gCqeNnI9PO/O8zTF7fisgseUuHmAWkCIFg==}\n\n  mjml-hero@5.0.0-alpha.4:\n    resolution: {integrity: sha512-KNjc+uEuEs5edlQxkoLnSSQw302M+GSBuGYEO1kThiFeJavZvdCeV9W+bTdeM6i7Cbn+UjfJQPPVaAo+yT6ETg==}\n\n  mjml-image@5.0.0-alpha.4:\n    resolution: {integrity: sha512-9oQJOOav9dWQcl8lUnn0ZVHCKnV/4Z8G6roT5FZBF6yKoqMCcgCJ9Sfhp3KqRzDvTVAsTnM8EzNDC+tBImD6Og==}\n\n  mjml-navbar@5.0.0-alpha.4:\n    resolution: {integrity: sha512-cMgeW1SeSlqYuMe7knVk/PXkroLwdI/jBopXetJVWFSURJij9AHto6vKmd+/aFlfPC8oWKPBKvEieCwEDgk6Lg==}\n\n  mjml-parser-xml@5.0.0-alpha.4:\n    resolution: {integrity: sha512-pk2sWuaUgiX2CwbL2qsh1g7Ry110YQMnX84KuIcEnzOQaCyuvGtOGIXuOiOthLRbVnKz15P7EsNnwHRg/d/Ihw==}\n\n  mjml-preset-core@5.0.0-alpha.4:\n    resolution: {integrity: sha512-V5I+3NJoSV/pFia5MjP5u8BgqJwHqR4KigUjGtOr5chZljyehFNOeL8ghEZ551BCzMrtMzarnChsEnkHI1Qirw==}\n\n  mjml-raw@5.0.0-alpha.4:\n    resolution: {integrity: sha512-puCKbIuMVFlFyZx1vaKy45iS3iTgFpmFcah5C+E5VnEyKDOB6su6Fs8OnuAHkq+TIdGc6q9kqI1MwlRn0Mrr8w==}\n\n  mjml-section@5.0.0-alpha.4:\n    resolution: {integrity: sha512-sbXvB9ik9i1zueCj996LvmiGn7EsZR5E8KXu08My3YxRbIoQrZtYdVOFM//858zDXtE/HB39HcLVXt1sG7GLig==}\n\n  mjml-social@5.0.0-alpha.4:\n    resolution: {integrity: sha512-lP+ykZB0wppYulBv1q0xM3kFCoYaKLyROZJgDjzvMlBRUA+p21/nu4JEjqYGdq0gQqoAhLQGW8hOUnEnS0Aydw==}\n\n  mjml-spacer@5.0.0-alpha.4:\n    resolution: {integrity: sha512-xHEunDOUL7Al3Rs5z20mwJsPllZdClriOptti5DP2hJjPkF2X/nwFTaH/kXvaPd2/CSZGHO+aQ5r/X2huV/43w==}\n\n  mjml-table@5.0.0-alpha.4:\n    resolution: {integrity: sha512-TCh5IJ6IDkv0bkn/8r7GslEpDiRaRoUonHzbFbsi1rNojayg+oOJbaUhpMh1gvBzVlmAyMeX2XGA92A1EiqJjw==}\n\n  mjml-text@5.0.0-alpha.4:\n    resolution: {integrity: sha512-yJi6D1hDaKxtJLu0M330yHn0BLo55T9+TaOw9GaWWlF28yphUZ6Ge+ppSZYeMbmzWwCUMVPPOcsYMpaLHtd7Iw==}\n\n  mjml-validator@5.0.0-alpha.4:\n    resolution: {integrity: sha512-0RWcTmUxluJc6XR/7Wmve9z4ydUGnLTUuyaHWX624V/xOaRPIThCllluh67TbSK6W2t4mwIHCdT+MgQC/wFwog==}\n\n  mjml-wrapper@5.0.0-alpha.4:\n    resolution: {integrity: sha512-sISlNUC3EVj5YMZfdQw19B9AIwCmgT8XWJ5r6HsBfYtxwdeYBHA/stygx84lEjDYPJK7U5FL65u01vfP71vM/w==}\n\n  mjml@5.0.0-alpha.4:\n    resolution: {integrity: sha512-SUdO4F/XYtXkIYKgjC3hO2oplSllb3DRsHxdNNMuyYh0y2HMxVgqjCcViCBLKc8zJrWM4NO5deZwO+8NjLcM2Q==}\n    hasBin: true\n\n  mkdirp-classic@0.5.3:\n    resolution: {integrity: sha512-gKLcREMhtuZRwRAfqP3RFW+TK4JqApVBtOIftVgjuABpAtpxhPGaDcfvbhNvD0B8iD1oUr/txX35NjcaY6Ns/A==}\n\n  mkdirp@0.5.6:\n    resolution: {integrity: sha512-FP+p8RB8OWpF3YZBCrP5gtADmtXApB5AMLn+vdyA+PyxCjrCs00mjyUozssO33cwDeT3wNGdLxJ5M//YqtHAJw==}\n    hasBin: true\n\n  mkdirp@1.0.4:\n    resolution: {integrity: sha512-vVqVZQyf3WLx2Shd0qJ9xuvqgAyKPLAiqITEtqW0oIUjzo3PePDd6fW9iFz30ef7Ysp/oiWqbhszeGWW2T6Gzw==}\n    engines: {node: '>=10'}\n    hasBin: true\n\n  mlly@1.7.0:\n    resolution: {integrity: sha512-U9SDaXGEREBYQgfejV97coK0UL1r+qnF2SyO9A3qcI8MzKnsIFKHNVEkrDyNncQTKQQumsasmeq84eNMdBfsNQ==}\n\n  mlly@1.7.1:\n    resolution: {integrity: sha512-rrVRZRELyQzrIUAVMHxP97kv+G786pHmOKzuFII8zDYahFBS7qnHh2AlYSl1GAHhaMPCz6/oHjVMcfFYgFYHgA==}\n\n  mlly@1.7.2:\n    resolution: {integrity: sha512-tN3dvVHYVz4DhSXinXIk7u9syPYaJvio118uomkovAtWBT+RdbP6Lfh/5Lvo519YMmwBafwlh20IPTXIStscpA==}\n\n  mocha@9.2.2:\n    resolution: {integrity: sha512-L6XC3EdwT6YrIk0yXpavvLkn8h+EU+Y5UcCHKECyMbdUIxyMuZj4bX4U9e1nvnvUUvQVsV2VHQr5zLdcUkhW/g==}\n    engines: {node: '>= 12.0.0'}\n    hasBin: true\n\n  mrmime@2.0.0:\n    resolution: {integrity: sha512-eu38+hdgojoyq63s+yTpN4XMBdt5l8HhMhc4VKLO9KM5caLIBvUm4thi7fFaxyTmCKeNnXZ5pAlBwCUnhA09uw==}\n    engines: {node: '>=10'}\n\n  ms@2.0.0:\n    resolution: {integrity: sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==}\n\n  ms@2.1.2:\n    resolution: {integrity: sha512-sGkPx+VjMtmA6MX27oA4FBFELFCZZ4S4XqeGOXCv68tT+jb3vk/RyaKWP0PTKyWtmLSM0b+adUTEvbs1PEaH2w==}\n\n  ms@2.1.3:\n    resolution: {integrity: sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==}\n\n  muggle-string@0.3.1:\n    resolution: {integrity: sha512-ckmWDJjphvd/FvZawgygcUeQCxzvohjFO5RxTjj4eq8kw359gFF3E1brjfI+viLMxss5JrHTDRHZvu2/tuy0Qg==}\n\n  muggle-string@0.4.1:\n    resolution: {integrity: sha512-VNTrAak/KhO2i8dqqnqnAHOa3cYBwXEZe9h+D5h/1ZqFSTEFHdM65lR7RoIqq3tBBYavsOXV84NoHXZ0AkPyqQ==}\n\n  multer@1.4.4-lts.1:\n    resolution: {integrity: sha512-WeSGziVj6+Z2/MwQo3GvqzgR+9Uc+qt8SwHKh3gvNPiISKfsMfG4SvCOFYlxxgkXt7yIV2i1yczehm0EOKIxIg==}\n    engines: {node: '>= 6.0.0'}\n\n  mute-stream@0.0.8:\n    resolution: {integrity: sha512-nnbWWOkoWyUsTjKrhgD0dcz22mdkSnpYqbEjIm2nhwhuxlSkpywJmBo8h0ZqJdkp73mb90SssHkN4rsRaBAfAA==}\n\n  mute-stream@1.0.0:\n    resolution: {integrity: sha512-avsJQhyd+680gKXyG/sQc0nXaC6rBkPOfyHYcFb9+hdkqQkR9bdnkJ0AMZhke0oesPqIO+mFFJ+IdBc7mst4IA==}\n    engines: {node: ^14.17.0 || ^16.13.0 || >=18.0.0}\n\n  mz@2.7.0:\n    resolution: {integrity: sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==}\n\n  nan@2.22.0:\n    resolution: {integrity: sha512-nbajikzWTMwsW+eSsNm3QwlOs7het9gGJU5dDZzRTQGk03vyBOauxgI4VakDzE0PtsGTmXPsXTbbjVhRwR5mpw==}\n\n  nanoid@3.3.1:\n    resolution: {integrity: sha512-n6Vs/3KGyxPQd6uO0eH4Bv0ojGSUvuLlIHtC3Y0kEO23YRge8H9x1GCzLn28YX0H66pMkxuaeESFq4tKISKwdw==}\n    engines: {node: ^10 || ^12 || ^13.7 || ^14 || >=15.0.1}\n    hasBin: true\n\n  nanoid@3.3.7:\n    resolution: {integrity: sha512-eSRppjcPIatRIMC1U6UngP8XFcz8MQWGQdt1MTBQ7NaAmvXDfvNxbvWV3x2y6CdEUciCSsDHDQZbhYaB8QEo2g==}\n    engines: {node: ^10 || ^12 || ^13.7 || ^14 || >=15.0.1}\n    hasBin: true\n\n  napi-build-utils@1.0.2:\n    resolution: {integrity: sha512-ONmRUqK7zj7DWX0D9ADe03wbwOBZxNAfF20PlGfCWQcD3+/MakShIHrMqx9YwPTfxDdF1zLeL+RGZiR9kGMLdg==}\n\n  natural-compare-lite@1.4.0:\n    resolution: {integrity: sha512-Tj+HTDSJJKaZnfiuw+iaF9skdPpTo2GtEly5JHnWV/hfv2Qj/9RKsGISQtLh2ox3l5EAGw487hnBee0sIJ6v2g==}\n\n  natural-compare@1.4.0:\n    resolution: {integrity: sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==}\n\n  negotiator@0.6.3:\n    resolution: {integrity: sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==}\n    engines: {node: '>= 0.6'}\n\n  neo-async@2.6.2:\n    resolution: {integrity: sha512-Yd3UES5mWCSqR+qNT93S3UoYUkqAZ9lLg8a7g9rimsWmYGK8cVToA4/sF3RrshdyV3sAGMXVUmpMYOw+dLpOuw==}\n\n  no-case@3.0.4:\n    resolution: {integrity: sha512-fgAN3jGAh+RoxUGZHTSOLJIqUc2wmoBwGR4tbpNAKmmovFoWq0OdRkb0VkldReO2a2iBT/OEulG9XSUc10r3zg==}\n\n  node-abi@3.62.0:\n    resolution: {integrity: sha512-CPMcGa+y33xuL1E0TcNIu4YyaZCxnnvkVaEXrsosR3FxN+fV8xvb7Mzpb7IgKler10qeMkE6+Dp8qJhpzdq35g==}\n    engines: {node: '>=10'}\n\n  node-abort-controller@3.1.1:\n    resolution: {integrity: sha512-AGK2yQKIjRuqnc6VkX2Xj5d+QW8xZ87pa1UK6yA6ouUyuxfHuMP6umE5QK7UmTeOAymo+Zx1Fxiuw9rVx8taHQ==}\n\n  node-addon-api@5.1.0:\n    resolution: {integrity: sha512-eh0GgfEkpnoWDq+VY8OyvYhFEzBk6jIYbRKdIlyTiAXIVJ8PyBaKb0rp7oDtoddbdoHWhq8wwr+XZ81F1rpNdA==}\n\n  node-addon-api@7.1.1:\n    resolution: {integrity: sha512-5m3bsyrjFWE1xf7nz7YXdN4udnVtXK6/Yfgn5qnahL6bCkf2yKt4k3nuTKAtT4r3IG8JNR2ncsIMdZuAzJjHQQ==}\n\n  node-addon-api@8.1.0:\n    resolution: {integrity: sha512-yBY+qqWSv3dWKGODD6OGE6GnTX7Q2r+4+DfpqxHSHh8x0B4EKP9+wVGLS6U/AM1vxSNNmUEuIV5EGhYwPpfOwQ==}\n    engines: {node: ^18 || ^20 || >= 21}\n\n  node-emoji@1.11.0:\n    resolution: {integrity: sha512-wo2DpQkQp7Sjm2A0cq+sN7EHKO6Sl0ctXeBdFZrL9T9+UywORbufTcTZxom8YqpLQt/FqNMUkOpkZrJVYSKD3A==}\n\n  node-fetch@2.7.0:\n    resolution: {integrity: sha512-c4FRfUm/dbcWZ7U+1Wq0AwCyFL+3nt2bEw05wfxSz+DWpWsitgmSgYmy2dQdWyKC1694ELPqMs/YzUSNozLt8A==}\n    engines: {node: 4.x || >=6.0.0}\n    peerDependencies:\n      encoding: ^0.1.0\n    peerDependenciesMeta:\n      encoding:\n        optional: true\n\n  node-gyp-build@4.8.2:\n    resolution: {integrity: sha512-IRUxE4BVsHWXkV/SFOut4qTlagw2aM8T5/vnTsmrHJvVoKueJHRc/JaFND7QDDc61kLYUJ6qlZM3sqTSyx2dTw==}\n    hasBin: true\n\n  node-int64@0.4.0:\n    resolution: {integrity: sha512-O5lz91xSOeoXP6DulyHfllpq+Eg00MWitZIbtPfoSEvqIHdl5gfcY6hYzDWnj0qD5tz52PI08u9qUvSVeUBeHw==}\n\n  node-releases@2.0.18:\n    resolution: {integrity: sha512-d9VeXT4SJ7ZeOqGX6R5EM022wpL+eWPooLI+5UpWn2jCT1aosUQEhQP214x33Wkwx3JQMvIm+tIoVOdodFS40g==}\n\n  nodemailer@6.9.13:\n    resolution: {integrity: sha512-7o38Yogx6krdoBf3jCAqnIN4oSQFx+fMa0I7dK1D+me9kBxx12D+/33wSb+fhOCtIxvYJ+4x4IMEhmhCKfAiOA==}\n    engines: {node: '>=6.0.0'}\n\n  nodemailer@6.9.15:\n    resolution: {integrity: sha512-AHf04ySLC6CIfuRtRiEYtGEXgRfa6INgWGluDhnxTZhHSKvrBu7lc1VVchQ0d8nPc4cFaZoPq8vkyNoZr0TpGQ==}\n    engines: {node: '>=6.0.0'}\n\n  nopt@5.0.0:\n    resolution: {integrity: sha512-Tbj67rffqceeLpcRXrT7vKAN8CwfPeIBgM7E6iBkmKLV7bEMwpGgYLGv0jACUsECaa/vuxP0IjEont6umdMgtQ==}\n    engines: {node: '>=6'}\n    hasBin: true\n\n  normalize-package-data@2.5.0:\n    resolution: {integrity: sha512-/5CMN3T0R4XTj4DcGaexo+roZSdSFW/0AOOTROrjxzCG1wrWXEsGbRKevjlIL+ZDE4sZlJr5ED4YW0yqmkK+eA==}\n\n  normalize-path@2.1.1:\n    resolution: {integrity: sha512-3pKJwH184Xo/lnH6oyP1q2pMd7HcypqqmRs91/6/i2CGtWwIKGCkOOMTm/zXbgTEWHw1uNpNi/igc3ePOYHb6w==}\n    engines: {node: '>=0.10.0'}\n\n  normalize-path@3.0.0:\n    resolution: {integrity: sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==}\n    engines: {node: '>=0.10.0'}\n\n  normalize-range@0.1.2:\n    resolution: {integrity: sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==}\n    engines: {node: '>=0.10.0'}\n\n  npm-run-all@4.1.5:\n    resolution: {integrity: sha512-Oo82gJDAVcaMdi3nuoKFavkIHBRVqQ1qvMb+9LHk/cF4P6B2m8aP04hGf7oL6wZ9BuGwX1onlLhpuoofSyoQDQ==}\n    engines: {node: '>= 4'}\n    hasBin: true\n\n  npm-run-path@2.0.2:\n    resolution: {integrity: sha512-lJxZYlT4DW/bRUtFh1MQIWqmLwQfAxnqWG4HhEdjMlkrJYnJn0Jrr2u3mgxqaWsdiBc76TYkTG/mhrnYTuzfHw==}\n    engines: {node: '>=4'}\n\n  npm-run-path@4.0.1:\n    resolution: {integrity: sha512-S48WzZW777zhNIrn7gxOlISNAqi9ZC/uQFnRdbeIHhZhCA6UqpkOT8T1G7BvfdgP4Er8gF4sUbaS0i7QvIfCWw==}\n    engines: {node: '>=8'}\n\n  npm-run-path@5.3.0:\n    resolution: {integrity: sha512-ppwTtiJZq0O/ai0z7yfudtBpWIoxM8yE6nHi1X47eFR2EWORqfbu6CnPlNsjeN683eT0qG6H/Pyf9fCcvjnnnQ==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  npmlog@5.0.1:\n    resolution: {integrity: sha512-AqZtDUWOMKs1G/8lwylVjrdYgqA4d9nu8hc+0gzRxlDb1I10+FHBGMXs6aiQHFdCUUlqH99MUMuLfzWDNDtfxw==}\n    deprecated: This package is no longer supported.\n\n  nprogress@0.2.0:\n    resolution: {integrity: sha512-I19aIingLgR1fmhftnbWWO3dXc0hSxqHQHQb3H8m+K3TnEn/iSeTZZOyvKXWqQESMwuUVnatlCnZdLBZZt2VSA==}\n\n  nth-check@2.1.1:\n    resolution: {integrity: sha512-lqjrjmaOoAnWfMmBPL+XNnynZh2+swxiX3WUE0s4yEHI6m+AwrK2UZOimIRl3X/4QctVqS8AiZjFqyOGrMXb/w==}\n\n  nullthrows@1.1.1:\n    resolution: {integrity: sha512-2vPPEi+Z7WqML2jZYddDIfy5Dqb0r2fze2zTxNNknZaFpVHU3mFB3R+DWeJWGVx0ecvttSGlJTI+WG+8Z4cDWw==}\n\n  nwsapi@2.2.13:\n    resolution: {integrity: sha512-cTGB9ptp9dY9A5VbMSe7fQBcl/tt22Vcqdq8+eN93rblOuE0aCFu4aZ2vMwct/2t+lFnosm8RkQW1I0Omb1UtQ==}\n\n  oauth@0.10.0:\n    resolution: {integrity: sha512-1orQ9MT1vHFGQxhuy7E/0gECD3fd2fCC+PIX+/jgmU/gI3EpRocXtmtvxCO5x3WZ443FLTLFWNDjl5MPJf9u+Q==}\n\n  object-assign@4.1.1:\n    resolution: {integrity: sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==}\n    engines: {node: '>=0.10.0'}\n\n  object-hash@3.0.0:\n    resolution: {integrity: sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==}\n    engines: {node: '>= 6'}\n\n  object-inspect@1.13.1:\n    resolution: {integrity: sha512-5qoj1RUiKOMsCCNLV1CBiPYE10sziTsnmNxkAI/rZhiD63CF7IqdFGC/XzjWjpSgLf0LxXX3bDFIh0E18f6UhQ==}\n\n  object-is@1.1.6:\n    resolution: {integrity: sha512-F8cZ+KfGlSGi09lJT7/Nd6KJZ9ygtvYC0/UYYLI9nmQKLMnydpB9yvbv9K1uSkEu7FU9vYPmVwLg328tX+ot3Q==}\n    engines: {node: '>= 0.4'}\n\n  object-keys@1.1.1:\n    resolution: {integrity: sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==}\n    engines: {node: '>= 0.4'}\n\n  object.assign@4.1.5:\n    resolution: {integrity: sha512-byy+U7gp+FVwmyzKPYhW2h5l3crpmGsxl7X2s8y43IgxvG4g3QZ6CffDtsNQy1WsmZpQbO+ybo0AlW7TY6DcBQ==}\n    engines: {node: '>= 0.4'}\n\n  on-finished@2.4.1:\n    resolution: {integrity: sha512-oVlzkg3ENAhCk2zdv7IJwd/QUD4z2RxRwpkcGY8psCVcCYZNq4wYnVWALHM+brtuJjePWiYF/ClmuDr8Ch5+kg==}\n    engines: {node: '>= 0.8'}\n\n  on-headers@1.0.2:\n    resolution: {integrity: sha512-pZAE+FJLoyITytdqK0U5s+FIpjN0JP3OzFi/u8Rx+EV5/W+JTWGXG8xFzevE7AjBfDqHv/8vL8qQsIhHnqRkrA==}\n    engines: {node: '>= 0.8'}\n\n  once@1.4.0:\n    resolution: {integrity: sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==}\n\n  onetime@5.1.2:\n    resolution: {integrity: sha512-kbpaSSGJTWdAY5KPVeMOKXSrPtr8C8C7wodJbcsd51jRnmD+GZu8Y0VoU6Dm5Z4vWr0Ig/1NKuWRKf7j5aaYSg==}\n    engines: {node: '>=6'}\n\n  onetime@6.0.0:\n    resolution: {integrity: sha512-1FlR+gjXK7X+AsAHso35MnyN5KqGwJRi/31ft6x0M194ht7S+rWAvd7PHss9xSKMzE0asv1pyIHaJYq+BbacAQ==}\n    engines: {node: '>=12'}\n\n  onetime@7.0.0:\n    resolution: {integrity: sha512-VXJjc87FScF88uafS3JllDgvAm+c/Slfz06lorj2uAY34rlUu0Nt+v8wreiImcrgAjjIHp1rXpTDlLOGw29WwQ==}\n    engines: {node: '>=18'}\n\n  ono@5.1.0:\n    resolution: {integrity: sha512-GgqRIUWErLX4l9Up0khRtbrlH8Fyj59A0nKv8V6pWEto38aUgnOGOOF7UmgFFLzFnDSc8REzaTXOc0hqEe7yIw==}\n\n  ono@6.0.1:\n    resolution: {integrity: sha512-5rdYW/106kHqLeG22GE2MHKq+FlsxMERZev9DCzQX1zwkxnFwBivSn5i17a5O/rDmOJOdf4Wyt80UZljzx9+DA==}\n\n  open@10.1.0:\n    resolution: {integrity: sha512-mnkeQ1qP5Ue2wd+aivTD3NHd/lZ96Lu0jgf0pwktLPtx6cTZiH7tyeGRRHs0zX0rbrahXPnXlUnbeXyaBBuIaw==}\n    engines: {node: '>=18'}\n\n  open@7.4.2:\n    resolution: {integrity: sha512-MVHddDVweXZF3awtlAS+6pgKLlm/JgxZ90+/NBurBoQctVOOB/zDdVjcyPzQ+0laDGbsWgrRkflI65sQeOgT9Q==}\n    engines: {node: '>=8'}\n\n  open@9.1.0:\n    resolution: {integrity: sha512-OS+QTnw1/4vrf+9hh1jc1jnYjzSG4ttTBB8UxOwAnInG3Uo4ssetzC1ihqaIHjLJnA5GGlRl6QlZXOTQhRBUvg==}\n    engines: {node: '>=14.16'}\n\n  openapi-schemas@1.0.3:\n    resolution: {integrity: sha512-KtMWcK2VtOS+nD8RKSIyScJsj8JrmVWcIX7Kjx4xEHijFYuvMTDON8WfeKOgeSb4uNG6UsqLj5Na7nKbSav9RQ==}\n    engines: {node: '>=8'}\n\n  openapi-types@1.3.5:\n    resolution: {integrity: sha512-11oi4zYorsgvg5yBarZplAqbpev5HkuVNPlZaPTknPDzAynq+lnJdXAmruGWP0s+dNYZS7bjM+xrTpJw7184Fg==}\n\n  openapi-types@12.1.3:\n    resolution: {integrity: sha512-N4YtSYJqghVu4iek2ZUvcN/0aqH1kRDuNqzcycDxhOUpg7GdvLa2F3DgS6yBNhInhv2r/6I0Flkn7CqL8+nIcw==}\n\n  opener@1.5.2:\n    resolution: {integrity: sha512-ur5UIdyw5Y7yEj9wLzhqXiy6GZ3Mwx0yGI+5sMn2r0N0v3cKJvUmFH5yPP+WXh9e0xfyzyJX95D8l088DNFj7A==}\n    hasBin: true\n\n  optionator@0.9.4:\n    resolution: {integrity: sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==}\n    engines: {node: '>= 0.8.0'}\n\n  ora@5.4.1:\n    resolution: {integrity: sha512-5b6Y85tPxZZ7QytO+BQzysW31HJku27cRIlkbAXaNx+BdcVi+LlRFmVXzeF6a7JCwJpyw5c4b+YSVImQIrBpuQ==}\n    engines: {node: '>=10'}\n\n  os-tmpdir@1.0.2:\n    resolution: {integrity: sha512-D2FR03Vir7FIu45XBY20mTb+/ZSWB00sjU9jdQXt83gDrI4Ztz5Fs7/yy74g2N5SVQY4xY1qDr4rNddwYRVX0g==}\n    engines: {node: '>=0.10.0'}\n\n  p-event@4.2.0:\n    resolution: {integrity: sha512-KXatOjCRXXkSePPb1Nbi0p0m+gQAwdlbhi4wQKJPI1HsMQS9g+Sqp2o+QHziPr7eYJyOZet836KoHEVM1mwOrQ==}\n    engines: {node: '>=8'}\n\n  p-finally@1.0.0:\n    resolution: {integrity: sha512-LICb2p9CB7FS+0eR1oqWnHhp0FljGLZCWBE9aix0Uye9W8LTQPwMTYVGWQWIw9RdQiDg4+epXQODwIYJtSJaow==}\n    engines: {node: '>=4'}\n\n  p-limit@2.3.0:\n    resolution: {integrity: sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==}\n    engines: {node: '>=6'}\n\n  p-limit@3.1.0:\n    resolution: {integrity: sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==}\n    engines: {node: '>=10'}\n\n  p-limit@4.0.0:\n    resolution: {integrity: sha512-5b0R4txpzjPWVw/cXXUResoD4hb6U/x9BH08L7nw+GN1sezDzPdxeRvpc9c433fZhBan/wusjbCsqwqm4EIBIQ==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  p-locate@4.1.0:\n    resolution: {integrity: sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==}\n    engines: {node: '>=8'}\n\n  p-locate@5.0.0:\n    resolution: {integrity: sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==}\n    engines: {node: '>=10'}\n\n  p-locate@6.0.0:\n    resolution: {integrity: sha512-wPrq66Llhl7/4AGC6I+cqxT07LhXvWL08LNXz1fENOw0Ap4sRZZ/gZpTTJ5jpurzzzfS2W/Ge9BY3LgLjCShcw==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  p-map@4.0.0:\n    resolution: {integrity: sha512-/bjOqmgETBYB5BoEeGVea8dmvHb2m9GLy1E9W43yeyfP6QQCZGFNa+XRceJEuDB6zqr+gKpIAmlLebMpykw/MQ==}\n    engines: {node: '>=10'}\n\n  p-timeout@3.2.0:\n    resolution: {integrity: sha512-rhIwUycgwwKcP9yTOOFK/AKsAopjjCakVqLHePO3CC6Mir1Z99xT+R63jZxAT5lFZLa2inS5h+ZS2GvR99/FBg==}\n    engines: {node: '>=8'}\n\n  p-try@2.2.0:\n    resolution: {integrity: sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==}\n    engines: {node: '>=6'}\n\n  p-wait-for@3.2.0:\n    resolution: {integrity: sha512-wpgERjNkLrBiFmkMEjuZJEWKKDrNfHCKA1OhyN1wg1FrLkULbviEy6py1AyJUgZ72YWFbZ38FIpnqvVqAlDUwA==}\n    engines: {node: '>=8'}\n\n  package-json-from-dist@1.0.1:\n    resolution: {integrity: sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==}\n\n  package-manager-detector@0.2.0:\n    resolution: {integrity: sha512-E385OSk9qDcXhcM9LNSe4sdhx8a9mAPrZ4sMLW+tmxl5ZuGtPUcdFu+MPP2jbgiWAZ6Pfe5soGFMd+0Db5Vrog==}\n\n  paho-mqtt@1.1.0:\n    resolution: {integrity: sha512-KPbL9KAB0ASvhSDbOrZBaccXS+/s7/LIofbPyERww8hM5Ko71GUJQ6Nmg0BWqj8phAIT8zdf/Sd/RftHU9i2HA==}\n\n  pako@0.2.9:\n    resolution: {integrity: sha512-NUcwaKxUxWrZLpDG+z/xZaCgQITkA/Dv4V/T6bw7VON6l1Xz/VnrBqrYjZQ12TamKHzITTfOEIYUj48y2KXImA==}\n\n  pako@1.0.11:\n    resolution: {integrity: sha512-4hLB8Py4zZce5s4yd9XzopqwVv/yGNhV1Bl8NTmCq1763HeK2+EwVTv+leGeL13Dnh2wfbqowVPXCIO0z4taYw==}\n\n  papaparse@5.4.1:\n    resolution: {integrity: sha512-HipMsgJkZu8br23pW15uvo6sib6wne/4woLZPlFf3rpDyMe9ywEXUsuD7+6K9PRkJlVT51j/sCOYDKGGS3ZJrw==}\n\n  param-case@3.0.4:\n    resolution: {integrity: sha512-RXlj7zCYokReqWpOPH9oYivUzLYZ5vAPIfEmCTNViosC78F8F0H9y7T7gG2M39ymgutxF5gcFEsyZQSph9Bp3A==}\n\n  parent-module@1.0.1:\n    resolution: {integrity: sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==}\n    engines: {node: '>=6'}\n\n  parse-code-context@1.0.0:\n    resolution: {integrity: sha512-OZQaqKaQnR21iqhlnPfVisFjBWjhnMl5J9MgbP8xC+EwoVqbXrq78lp+9Zb3ahmLzrIX5Us/qbvBnaS3hkH6OA==}\n    engines: {node: '>=6'}\n\n  parse-filepath@1.0.2:\n    resolution: {integrity: sha512-FwdRXKCohSVeXqwtYonZTXtbGJKrn+HNyWDYVcp5yuJlesTwNH4rsmRZ+GrKAPJ5bLpRxESMeS+Rl0VCHRvB2Q==}\n    engines: {node: '>=0.8'}\n\n  parse-json@4.0.0:\n    resolution: {integrity: sha512-aOIos8bujGN93/8Ox/jPLh7RwVnPEysynVFE+fQZyg6jKELEHwzgKdLRFHUgXJL6kylijVSBC4BvN9OmsB48Rw==}\n    engines: {node: '>=4'}\n\n  parse-json@5.2.0:\n    resolution: {integrity: sha512-ayCKvm/phCGxOkYRSCM82iDwct8/EonSEgCSxWxD7ve6jHggsFl4fZVQBPRNgQoKiuV/odhFrGzQXZwbifC8Rg==}\n    engines: {node: '>=8'}\n\n  parse5-htmlparser2-tree-adapter@7.0.0:\n    resolution: {integrity: sha512-B77tOZrqqfUfnVcOrUvfdLbz4pu4RopLD/4vmu3HUPswwTA8OH0EMW9BlWR2B0RCoiZRAHEUu7IxeP1Pd1UU+g==}\n\n  parse5@7.1.2:\n    resolution: {integrity: sha512-Czj1WaSVpaoj0wbhMzLmWD69anp2WH7FXMB9n1Sy8/ZFF9jolSQVMu1Ij5WIyGmcBmhk7EOndpO4mIpihVqAXw==}\n\n  parseley@0.12.1:\n    resolution: {integrity: sha512-e6qHKe3a9HWr0oMRVDTRhKce+bRO8VGQR3NyVwcjwrbhMmFCX9KszEV35+rn4AdilFAq9VPxP/Fe1wC9Qjd2lw==}\n\n  parseqs@0.0.6:\n    resolution: {integrity: sha512-jeAGzMDbfSHHA091hr0r31eYfTig+29g3GKKE/PPbEQ65X0lmMwlEoqmhzu0iztID5uJpZsFlUPDP8ThPL7M8w==}\n\n  parser-ts@0.7.0:\n    resolution: {integrity: sha512-YBJYgQ6j2DiKryKkYUrw0a7WiUb2DGnanffFZNz5cRTaoTncSxjKCio6ocEBSAa26jFXr0XSNjaYXUrL61BISA==}\n    peerDependencies:\n      fp-ts: ^2.14.0\n\n  parseuri@0.0.6:\n    resolution: {integrity: sha512-AUjen8sAkGgao7UyCX6Ahv0gIK2fABKmYjvP4xmy5JaKvcbTRueIqIPHLAfq30xJddqSE033IOMUSOMCcK3Sow==}\n\n  parseurl@1.3.3:\n    resolution: {integrity: sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==}\n    engines: {node: '>= 0.8'}\n\n  pascal-case@3.1.2:\n    resolution: {integrity: sha512-uWlGT3YSnK9x3BQJaOdcZwrnV6hPpd8jFH1/ucpiLRPh/2zCVJKS19E4GvYHvaCcACn3foXZ0cLB9Wrx1KGe5g==}\n\n  passport-github2@0.1.12:\n    resolution: {integrity: sha512-3nPUCc7ttF/3HSP/k9sAXjz3SkGv5Nki84I05kSQPo01Jqq1NzJACgMblCK0fGcv9pKCG/KXU3AJRDGLqHLoIw==}\n    engines: {node: '>= 0.8.0'}\n\n  passport-google-oauth20@2.0.0:\n    resolution: {integrity: sha512-KSk6IJ15RoxuGq7D1UKK/8qKhNfzbLeLrG3gkLZ7p4A6DBCcv7xpyQwuXtWdpyR0+E0mwkpjY1VfPOhxQrKzdQ==}\n    engines: {node: '>= 0.4.0'}\n\n  passport-jwt@4.0.1:\n    resolution: {integrity: sha512-UCKMDYhNuGOBE9/9Ycuoyh7vP6jpeTp/+sfMJl7nLff/t6dps+iaeE0hhNkKN8/HZHcJ7lCdOyDxHdDoxoSvdQ==}\n\n  passport-local@1.0.0:\n    resolution: {integrity: sha512-9wCE6qKznvf9mQYYbgJ3sVOHmCWoUNMVFoZzNoznmISbhnNNPhN9xfY3sLmScHMetEJeoY7CXwfhCe7argfQow==}\n    engines: {node: '>= 0.4.0'}\n\n  passport-microsoft@2.1.0:\n    resolution: {integrity: sha512-7bOcjEmZCHg5qD55iHaMD/mgBxPtXLbqAwmKox5IsqOSEU50WJk5nQKK4lxKdBHLZ0hf+gzrFgDsTybJP18/JA==}\n    engines: {node: '>= 0.4.0'}\n\n  passport-oauth2@1.8.0:\n    resolution: {integrity: sha512-cjsQbOrXIDE4P8nNb3FQRCCmJJ/utnFKEz2NX209f7KOHPoX18gF7gBzBbLLsj2/je4KrgiwLLGjf0lm9rtTBA==}\n    engines: {node: '>= 0.4.0'}\n\n  passport-strategy@1.0.0:\n    resolution: {integrity: sha512-CB97UUvDKJde2V0KDWWB3lyf6PC3FaZP7YxZ2G8OAtn9p4HI9j9JLP9qjOGZFvyl8uwNT8qM+hGnz/n16NI7oA==}\n    engines: {node: '>= 0.4.0'}\n\n  passport@0.7.0:\n    resolution: {integrity: sha512-cPLl+qZpSc+ireUvt+IzqbED1cHHkDoVYMo30jbJIdOOjQ1MQYZBPiNvmi8UM6lJuOpTPXJGZQk0DtC4y61MYQ==}\n    engines: {node: '>= 0.4.0'}\n\n  path-browserify@1.0.1:\n    resolution: {integrity: sha512-b7uo2UCUOYZcnF/3ID0lulOJi/bafxa1xPe7ZPsammBSpjSWQkjNxlt635YGS2MiR9GjvuXCtz2emr3jbsz98g==}\n\n  path-case@3.0.4:\n    resolution: {integrity: sha512-qO4qCFjXqVTrcbPt/hQfhTQ+VhFsqNKOPtytgNKkKxSoEp3XPUQ8ObFuePylOIok5gjn69ry8XiULxCwot3Wfg==}\n\n  path-exists@4.0.0:\n    resolution: {integrity: sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==}\n    engines: {node: '>=8'}\n\n  path-exists@5.0.0:\n    resolution: {integrity: sha512-RjhtfwJOxzcFmNOi6ltcbcu4Iu+FL3zEj83dk4kAS+fVpTxXLO1b38RvJgT/0QwvV/L3aY9TAnyv0EOqW4GoMQ==}\n    engines: {node: ^12.20.0 || ^14.13.1 || >=16.0.0}\n\n  path-is-absolute@1.0.1:\n    resolution: {integrity: sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==}\n    engines: {node: '>=0.10.0'}\n\n  path-key@2.0.1:\n    resolution: {integrity: sha512-fEHGKCSmUSDPv4uoj8AlD+joPlq3peND+HRYyxFz4KPw4z926S/b8rIuFs2FYJg3BwsxJf6A9/3eIdLaYC+9Dw==}\n    engines: {node: '>=4'}\n\n  path-key@3.1.1:\n    resolution: {integrity: sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==}\n    engines: {node: '>=8'}\n\n  path-key@4.0.0:\n    resolution: {integrity: sha512-haREypq7xkM7ErfgIyA0z+Bj4AGKlMSdlQE2jvJo6huWD1EdkKYV+G/T4nq0YEF2vgTT8kqMFKo1uHn950r4SQ==}\n    engines: {node: '>=12'}\n\n  path-parse@1.0.7:\n    resolution: {integrity: sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==}\n\n  path-root-regex@0.1.2:\n    resolution: {integrity: sha512-4GlJ6rZDhQZFE0DPVKh0e9jmZ5egZfxTkp7bcRDuPlJXbAwhxcl2dINPUAsjLdejqaLsCeg8axcLjIbvBjN4pQ==}\n    engines: {node: '>=0.10.0'}\n\n  path-root@0.1.1:\n    resolution: {integrity: sha512-QLcPegTHF11axjfojBIoDygmS2E3Lf+8+jI6wOVmNVenrKSo3mFdSGiIgdSHenczw3wPtlVMQaFVwGmM7BJdtg==}\n    engines: {node: '>=0.10.0'}\n\n  path-scurry@1.11.1:\n    resolution: {integrity: sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==}\n    engines: {node: '>=16 || 14 >=14.18'}\n\n  path-scurry@2.0.0:\n    resolution: {integrity: sha512-ypGJsmGtdXUOeM5u93TyeIEfEhM6s+ljAhrk5vAvSx8uyY/02OvrZnA0YNGUrPXfpJMgI1ODd3nwz8Npx4O4cg==}\n    engines: {node: 20 || >=22}\n\n  path-to-regexp@0.1.10:\n    resolution: {integrity: sha512-7lf7qcQidTku0Gu3YDPc8DJ1q7OOucfa/BSsIwjuh56VU7katFvuM8hULfkwB3Fns/rsVF7PwPKVw1sl5KQS9w==}\n\n  path-to-regexp@3.3.0:\n    resolution: {integrity: sha512-qyCH421YQPS2WFDxDjftfc1ZR5WKQzVzqsp4n9M2kQhVOo/ByahFoUNJfl58kOcEGfQ//7weFTDhm+ss8Ecxgw==}\n\n  path-type@3.0.0:\n    resolution: {integrity: sha512-T2ZUsdZFHgA3u4e5PfPbjd7HDDpxPnQb5jN0SrDsjNSuVXHJqtwTnWqG0B1jZrgmJ/7lj1EmVIByWt1gxGkWvg==}\n    engines: {node: '>=4'}\n\n  path-type@4.0.0:\n    resolution: {integrity: sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==}\n    engines: {node: '>=8'}\n\n  path2d@0.2.1:\n    resolution: {integrity: sha512-Fl2z/BHvkTNvkuBzYTpTuirHZg6wW9z8+4SND/3mDTEcYbbNKWAy21dz9D3ePNNwrrK8pqZO5vLPZ1hLF6T7XA==}\n    engines: {node: '>=6'}\n\n  path@0.12.7:\n    resolution: {integrity: sha512-aXXC6s+1w7otVF9UletFkFcDsJeO7lSZBPUQhtb5O0xJe8LtYhj/GxldoL09bBj9+ZmE2hNoHqQSFMN5fikh4Q==}\n\n  pathe@1.1.2:\n    resolution: {integrity: sha512-whLdWMYL2TwI08hn8/ZqAbrVemu0LNaNNJZX73O6qaIdCTfXutsLhMkjdENX0qhsQ9uIimo4/aQOmXkoon2nDQ==}\n\n  pathval@2.0.0:\n    resolution: {integrity: sha512-vE7JKRyES09KiunauX7nd2Q9/L7lhok4smP9RZTDeD4MVs72Dp2qNFVz39Nz5a0FVEW0BJR6C0DYrq6unoziZA==}\n    engines: {node: '>= 14.16'}\n\n  pause-stream@0.0.11:\n    resolution: {integrity: sha512-e3FBlXLmN/D1S+zHzanP4E/4Z60oFAa3O051qt1pxa7DEJWKAyil6upYVXCWadEnuoqa4Pkc9oUx9zsxYeRv8A==}\n\n  pause@0.0.1:\n    resolution: {integrity: sha512-KG8UEiEVkR3wGEb4m5yZkVCzigAD+cVEJck2CzYZO37ZGJfctvVptVO192MwrtPhzONn6go8ylnOdMhKqi4nfg==}\n\n  pdfjs-dist@4.7.76:\n    resolution: {integrity: sha512-8y6wUgC/Em35IumlGjaJOCm3wV4aY/6sqnIT3fVW/67mXsOZ9HWBn8GDKmJUK0GSzpbmX3gQqwfoFayp78Mtqw==}\n    engines: {node: '>=18'}\n\n  peberminta@0.9.0:\n    resolution: {integrity: sha512-XIxfHpEuSJbITd1H3EeQwpcZbTLHc+VVr8ANI9t5sit565tsI4/xK3KWTUFE2e6QiangUkh3B0jihzmGnNrRsQ==}\n\n  pend@1.2.0:\n    resolution: {integrity: sha512-F3asv42UuXchdzt+xXqfW1OGlVBe+mxa2mqI0pg5yAHZPvFmY3Y6drSf/GQ1A86WgWEN9Kzh/WrgKa6iGcHXLg==}\n\n  perfect-debounce@1.0.0:\n    resolution: {integrity: sha512-xCy9V055GLEqoFaHoC1SoLIaLmWctgCUaBaWxDZ7/Zx4CTyX7cJQLJOok/orfjZAh9kEYpjJa4d0KcJmCbctZA==}\n\n  picocolors@1.0.0:\n    resolution: {integrity: sha512-1fygroTLlHu66zi26VoTDv8yRgm0Fccecssto+MhsZ0D/DGW2sm8E8AjW7NU5VVTRt5GxbeZ5qBuJr+HyLYkjQ==}\n\n  picocolors@1.0.1:\n    resolution: {integrity: sha512-anP1Z8qwhkbmu7MFP5iTt+wQKXgwzf7zTyGlcdzabySa9vd0Xt392U0rVmz9poOaBj0uHJKyyo9/upk0HrEQew==}\n\n  picocolors@1.1.0:\n    resolution: {integrity: sha512-TQ92mBOW0l3LeMeyLV6mzy/kWr8lkd/hp3mTg7wYK7zJhuBStmGMBG0BdeDZS/dZx1IukaX6Bk11zcln25o1Aw==}\n\n  picomatch@2.3.1:\n    resolution: {integrity: sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==}\n    engines: {node: '>=8.6'}\n\n  picomatch@4.0.1:\n    resolution: {integrity: sha512-xUXwsxNjwTQ8K3GnT4pCJm+xq3RUPQbmkYJTP5aFIfNIvbcc/4MUxgBaaRSZJ6yGJZiGSyYlM6MzwTsRk8SYCg==}\n    engines: {node: '>=12'}\n\n  picomatch@4.0.2:\n    resolution: {integrity: sha512-M7BAV6Rlcy5u+m6oPhAPFgJTzAioX/6B0DxyvDlo9l8+T3nLKbrczg2WLUyzd45L8RqfUMyGPzekbMvX2Ldkwg==}\n    engines: {node: '>=12'}\n\n  pidtree@0.3.1:\n    resolution: {integrity: sha512-qQbW94hLHEqCg7nhby4yRC7G2+jYHY4Rguc2bjw7Uug4GIJuu1tvf2uHaZv5Q8zdt+WKJ6qK1FOI6amaWUo5FA==}\n    engines: {node: '>=0.10'}\n    hasBin: true\n\n  pidtree@0.6.0:\n    resolution: {integrity: sha512-eG2dWTVw5bzqGRztnHExczNxt5VGsE6OwTeCG3fdUf9KBsZzO3R5OIIIzWR+iZA0NtZ+RDVdaoE2dK1cn6jH4g==}\n    engines: {node: '>=0.10'}\n    hasBin: true\n\n  pify@2.3.0:\n    resolution: {integrity: sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==}\n    engines: {node: '>=0.10.0'}\n\n  pify@3.0.0:\n    resolution: {integrity: sha512-C3FsVNH1udSEX48gGX1xfvwTWfsYWj5U+8/uK15BGzIGrKoUpghX8hWZwa/OFnakBiiVNmBvemTJR5mcy7iPcg==}\n    engines: {node: '>=4'}\n\n  pirates@4.0.6:\n    resolution: {integrity: sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==}\n    engines: {node: '>= 6'}\n\n  pkg-dir@4.2.0:\n    resolution: {integrity: sha512-HRDzbaKjC+AOWVXxAU/x54COGeIv9eb+6CkDSQoNTt4XyWoIJvuPsXizxu/Fr23EiekbtZwmh1IcIG/l/a10GQ==}\n    engines: {node: '>=8'}\n\n  pkg-types@1.1.0:\n    resolution: {integrity: sha512-/RpmvKdxKf8uILTtoOhAgf30wYbP2Qw+L9p3Rvshx1JZVX+XQNZQFjlbmGHEGIm4CkVPlSn+NXmIM8+9oWQaSA==}\n\n  pkg-types@1.2.1:\n    resolution: {integrity: sha512-sQoqa8alT3nHjGuTjuKgOnvjo4cljkufdtLMnO2LBP/wRwuDlo1tkaEdMxCRhyGRPacv/ztlZgDPm2b7FAmEvw==}\n\n  pluralize@8.0.0:\n    resolution: {integrity: sha512-Nc3IT5yHzflTfbjgqWcCPpo7DaKy4FnpB0l/zCAW0Tc7jxAiuqSxHasntB3D7887LSrA93kDJ9IXovxJYxyLCA==}\n    engines: {node: '>=4'}\n\n  portfinder@1.0.32:\n    resolution: {integrity: sha512-on2ZJVVDXRADWE6jnQaX0ioEylzgBpQk8r55NE4wjXW1ZxO+BgDlY6DXwj20i0V8eB4SenDQ00WEaxfiIQPcxg==}\n    engines: {node: '>= 0.12.0'}\n\n  possible-typed-array-names@1.0.0:\n    resolution: {integrity: sha512-d7Uw+eZoloe0EHDIYoe+bQ5WXnGMOpmiZFTuMWCwpjzzkL2nTjcKiAk4hh8TjnGye2TwWOk3UXucZ+3rbmBa8Q==}\n    engines: {node: '>= 0.4'}\n\n  postcss-calc@10.0.2:\n    resolution: {integrity: sha512-DT/Wwm6fCKgpYVI7ZEWuPJ4az8hiEHtCUeYjZXqU7Ou4QqYh1Df2yCQ7Ca6N7xqKPFkxN3fhf+u9KSoOCJNAjg==}\n    engines: {node: ^18.12 || ^20.9 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.38\n\n  postcss-colormin@7.0.2:\n    resolution: {integrity: sha512-YntRXNngcvEvDbEjTdRWGU606eZvB5prmHG4BF0yLmVpamXbpsRJzevyy6MZVyuecgzI2AWAlvFi8DAeCqwpvA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-convert-values@7.0.4:\n    resolution: {integrity: sha512-e2LSXPqEHVW6aoGbjV9RsSSNDO3A0rZLCBxN24zvxF25WknMPpX8Dm9UxxThyEbaytzggRuZxaGXqaOhxQ514Q==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-discard-comments@7.0.3:\n    resolution: {integrity: sha512-q6fjd4WU4afNhWOA2WltHgCbkRhZPgQe7cXF74fuVB/ge4QbM9HEaOIzGSiMvM+g/cOsNAUGdf2JDzqA2F8iLA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-discard-duplicates@7.0.1:\n    resolution: {integrity: sha512-oZA+v8Jkpu1ct/xbbrntHRsfLGuzoP+cpt0nJe5ED2FQF8n8bJtn7Bo28jSmBYwqgqnqkuSXJfSUEE7if4nClQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-discard-empty@7.0.0:\n    resolution: {integrity: sha512-e+QzoReTZ8IAwhnSdp/++7gBZ/F+nBq9y6PomfwORfP7q9nBpK5AMP64kOt0bA+lShBFbBDcgpJ3X4etHg4lzA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-discard-overridden@7.0.0:\n    resolution: {integrity: sha512-GmNAzx88u3k2+sBTZrJSDauR0ccpE24omTQCVmaTTZFz1du6AasspjaUPMJ2ud4RslZpoFKyf+6MSPETLojc6w==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-import@15.1.0:\n    resolution: {integrity: sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      postcss: ^8.0.0\n\n  postcss-js@4.0.1:\n    resolution: {integrity: sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==}\n    engines: {node: ^12 || ^14 || >= 16}\n    peerDependencies:\n      postcss: ^8.4.21\n\n  postcss-load-config@4.0.2:\n    resolution: {integrity: sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==}\n    engines: {node: '>= 14'}\n    peerDependencies:\n      postcss: '>=8.0.9'\n      ts-node: '>=9.0.0'\n    peerDependenciesMeta:\n      postcss:\n        optional: true\n      ts-node:\n        optional: true\n\n  postcss-load-config@6.0.1:\n    resolution: {integrity: sha512-oPtTM4oerL+UXmx+93ytZVN82RrlY/wPUV8IeDxFrzIjXOLF1pN+EmKPLbubvKHT2HC20xXsCAH2Z+CKV6Oz/g==}\n    engines: {node: '>= 18'}\n    peerDependencies:\n      jiti: '>=1.21.0'\n      postcss: '>=8.0.9'\n      tsx: ^4.8.1\n      yaml: ^2.4.2\n    peerDependenciesMeta:\n      jiti:\n        optional: true\n      postcss:\n        optional: true\n      tsx:\n        optional: true\n      yaml:\n        optional: true\n\n  postcss-merge-longhand@7.0.4:\n    resolution: {integrity: sha512-zer1KoZA54Q8RVHKOY5vMke0cCdNxMP3KBfDerjH/BYHh4nCIh+1Yy0t1pAEQF18ac/4z3OFclO+ZVH8azjR4A==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-merge-rules@7.0.4:\n    resolution: {integrity: sha512-ZsaamiMVu7uBYsIdGtKJ64PkcQt6Pcpep/uO90EpLS3dxJi6OXamIobTYcImyXGoW0Wpugh7DSD3XzxZS9JCPg==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-minify-font-values@7.0.0:\n    resolution: {integrity: sha512-2ckkZtgT0zG8SMc5aoNwtm5234eUx1GGFJKf2b1bSp8UflqaeFzR50lid4PfqVI9NtGqJ2J4Y7fwvnP/u1cQog==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-minify-gradients@7.0.0:\n    resolution: {integrity: sha512-pdUIIdj/C93ryCHew0UgBnL2DtUS3hfFa5XtERrs4x+hmpMYGhbzo6l/Ir5de41O0GaKVpK1ZbDNXSY6GkXvtg==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-minify-params@7.0.2:\n    resolution: {integrity: sha512-nyqVLu4MFl9df32zTsdcLqCFfE/z2+f8GE1KHPxWOAmegSo6lpV2GNy5XQvrzwbLmiU7d+fYay4cwto1oNdAaQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-minify-selectors@7.0.4:\n    resolution: {integrity: sha512-JG55VADcNb4xFCf75hXkzc1rNeURhlo7ugf6JjiiKRfMsKlDzN9CXHZDyiG6x/zGchpjQS+UAgb1d4nqXqOpmA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-nested@6.0.1:\n    resolution: {integrity: sha512-mEp4xPMi5bSWiMbsgoPfcP74lsWLHkQbZc3sY+jWYd65CUwXrUaTp0fmNpa01ZcETKlIgUdFN/MpS2xZtqL9dQ==}\n    engines: {node: '>=12.0'}\n    peerDependencies:\n      postcss: ^8.2.14\n\n  postcss-normalize-charset@7.0.0:\n    resolution: {integrity: sha512-ABisNUXMeZeDNzCQxPxBCkXexvBrUHV+p7/BXOY+ulxkcjUZO0cp8ekGBwvIh2LbCwnWbyMPNJVtBSdyhM2zYQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-display-values@7.0.0:\n    resolution: {integrity: sha512-lnFZzNPeDf5uGMPYgGOw7v0BfB45+irSRz9gHQStdkkhiM0gTfvWkWB5BMxpn0OqgOQuZG/mRlZyJxp0EImr2Q==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-positions@7.0.0:\n    resolution: {integrity: sha512-I0yt8wX529UKIGs2y/9Ybs2CelSvItfmvg/DBIjTnoUSrPxSV7Z0yZ8ShSVtKNaV/wAY+m7bgtyVQLhB00A1NQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-repeat-style@7.0.0:\n    resolution: {integrity: sha512-o3uSGYH+2q30ieM3ppu9GTjSXIzOrRdCUn8UOMGNw7Af61bmurHTWI87hRybrP6xDHvOe5WlAj3XzN6vEO8jLw==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-string@7.0.0:\n    resolution: {integrity: sha512-w/qzL212DFVOpMy3UGyxrND+Kb0fvCiBBujiaONIihq7VvtC7bswjWgKQU/w4VcRyDD8gpfqUiBQ4DUOwEJ6Qg==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-timing-functions@7.0.0:\n    resolution: {integrity: sha512-tNgw3YV0LYoRwg43N3lTe3AEWZ66W7Dh7lVEpJbHoKOuHc1sLrzMLMFjP8SNULHaykzsonUEDbKedv8C+7ej6g==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-unicode@7.0.2:\n    resolution: {integrity: sha512-ztisabK5C/+ZWBdYC+Y9JCkp3M9qBv/XFvDtSw0d/XwfT3UaKeW/YTm/MD/QrPNxuecia46vkfEhewjwcYFjkg==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-url@7.0.0:\n    resolution: {integrity: sha512-+d7+PpE+jyPX1hDQZYG+NaFD+Nd2ris6r8fPTBAjE8z/U41n/bib3vze8x7rKs5H1uEw5ppe9IojewouHk0klQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-normalize-whitespace@7.0.0:\n    resolution: {integrity: sha512-37/toN4wwZErqohedXYqWgvcHUGlT8O/m2jVkAfAe9Bd4MzRqlBmXrJRePH0e9Wgnz2X7KymTgTOaaFizQe3AQ==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-ordered-values@7.0.1:\n    resolution: {integrity: sha512-irWScWRL6nRzYmBOXReIKch75RRhNS86UPUAxXdmW/l0FcAsg0lvAXQCby/1lymxn/o0gVa6Rv/0f03eJOwHxw==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-reduce-initial@7.0.2:\n    resolution: {integrity: sha512-pOnu9zqQww7dEKf62Nuju6JgsW2V0KRNBHxeKohU+JkHd/GAH5uvoObqFLqkeB2n20mr6yrlWDvo5UBU5GnkfA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-reduce-transforms@7.0.0:\n    resolution: {integrity: sha512-pnt1HKKZ07/idH8cpATX/ujMbtOGhUfE+m8gbqwJE05aTaNw8gbo34a2e3if0xc0dlu75sUOiqvwCGY3fzOHew==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-selector-parser@6.1.1:\n    resolution: {integrity: sha512-b4dlw/9V8A71rLIDsSwVmak9z2DuBUB7CA1/wSdelNEzqsjoSPeADTWNO09lpH49Diy3/JIZ2bSPB1dI3LJCHg==}\n    engines: {node: '>=4'}\n\n  postcss-selector-parser@6.1.2:\n    resolution: {integrity: sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==}\n    engines: {node: '>=4'}\n\n  postcss-svgo@7.0.1:\n    resolution: {integrity: sha512-0WBUlSL4lhD9rA5k1e5D8EN5wCEyZD6HJk0jIvRxl+FDVOMlJ7DePHYWGGVc5QRqrJ3/06FTXM0bxjmJpmTPSA==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >= 18}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-unique-selectors@7.0.3:\n    resolution: {integrity: sha512-J+58u5Ic5T1QjP/LDV9g3Cx4CNOgB5vz+kM6+OxHHhFACdcDeKhBXjQmB7fnIZM12YSTvsL0Opwco83DmacW2g==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  postcss-value-parser@4.2.0:\n    resolution: {integrity: sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==}\n\n  postcss@8.4.32:\n    resolution: {integrity: sha512-D/kj5JNu6oo2EIy+XL/26JEDTlIbB8hw85G8StOE6L74RQAVVP5rej6wxCNqyMbR4RkPfqvezVbPw81Ngd6Kcw==}\n    engines: {node: ^10 || ^12 || >=14}\n\n  postcss@8.4.47:\n    resolution: {integrity: sha512-56rxCq7G/XfB4EkXq9Egn5GCqugWvDFjafDOThIdMBsI15iqPqR5r15TfSr1YPYeEI19YeaXMCbY6u88Y76GLQ==}\n    engines: {node: ^10 || ^12 || >=14}\n\n  posthog-node@4.2.0:\n    resolution: {integrity: sha512-hgyCYMyzMvuF3qWMw6JvS8gT55v7Mtp5wKWcnDrw+nu39D0Tk9BXD7I0LOBp0lGlHEPaXCEVYUtviNKrhMALGA==}\n    engines: {node: '>=15.0.0'}\n\n  posthtml-parser@0.11.0:\n    resolution: {integrity: sha512-QecJtfLekJbWVo/dMAA+OSwY79wpRmbqS5TeXvXSX+f0c6pW4/SE6inzZ2qkU7oAMCPqIDkZDvd/bQsSFUnKyw==}\n    engines: {node: '>=12'}\n\n  posthtml-render@3.0.0:\n    resolution: {integrity: sha512-z+16RoxK3fUPgwaIgH9NGnK1HKY9XIDpydky5eQGgAFVXTCSezalv9U2jQuNV+Z9qV1fDWNzldcw4eK0SSbqKA==}\n    engines: {node: '>=12'}\n\n  posthtml@0.16.6:\n    resolution: {integrity: sha512-JcEmHlyLK/o0uGAlj65vgg+7LIms0xKXe60lcDOTU7oVX/3LuEuLwrQpW3VJ7de5TaFKiW4kWkaIpJL42FEgxQ==}\n    engines: {node: '>=12.0.0'}\n\n  postman-collection@4.5.0:\n    resolution: {integrity: sha512-152JSW9pdbaoJihwjc7Q8lc3nPg/PC9lPTHdMk7SHnHhu/GBJB7b2yb9zG7Qua578+3PxkQ/HYBuXpDSvsf7GQ==}\n    engines: {node: '>=10'}\n\n  postman-url-encoder@3.0.5:\n    resolution: {integrity: sha512-jOrdVvzUXBC7C+9gkIkpDJ3HIxOHTIqjpQ4C1EMt1ZGeMvSEpbFCKq23DEfgsj46vMnDgyQf+1ZLp2Wm+bKSsA==}\n    engines: {node: '>=10'}\n\n  prebuild-install@7.1.2:\n    resolution: {integrity: sha512-UnNke3IQb6sgarcZIDU3gbMeTp/9SSU1DAIkil7PrqG1vZlBtY5msYccSKSHDqa3hNg436IXK+SNImReuA1wEQ==}\n    engines: {node: '>=10'}\n    hasBin: true\n\n  prelude-ls@1.2.1:\n    resolution: {integrity: sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==}\n    engines: {node: '>= 0.8.0'}\n\n  prettier-linter-helpers@1.0.0:\n    resolution: {integrity: sha512-GbK2cP9nraSSUF9N2XwUwqfzlAFlMNYYl+ShE/V+H8a9uNl/oUqB1w2EL54Jh0OlyRSd8RfWYJ3coVS4TROP2w==}\n    engines: {node: '>=6.0.0'}\n\n  prettier-plugin-tailwindcss@0.6.8:\n    resolution: {integrity: sha512-dGu3kdm7SXPkiW4nzeWKCl3uoImdd5CTZEJGxyypEPL37Wj0HT2pLqjrvSei1nTeuQfO4PUfjeW5cTUNRLZ4sA==}\n    engines: {node: '>=14.21.3'}\n    peerDependencies:\n      '@ianvs/prettier-plugin-sort-imports': '*'\n      '@prettier/plugin-pug': '*'\n      '@shopify/prettier-plugin-liquid': '*'\n      '@trivago/prettier-plugin-sort-imports': '*'\n      '@zackad/prettier-plugin-twig-melody': '*'\n      prettier: ^3.0\n      prettier-plugin-astro: '*'\n      prettier-plugin-css-order: '*'\n      prettier-plugin-import-sort: '*'\n      prettier-plugin-jsdoc: '*'\n      prettier-plugin-marko: '*'\n      prettier-plugin-multiline-arrays: '*'\n      prettier-plugin-organize-attributes: '*'\n      prettier-plugin-organize-imports: '*'\n      prettier-plugin-sort-imports: '*'\n      prettier-plugin-style-order: '*'\n      prettier-plugin-svelte: '*'\n    peerDependenciesMeta:\n      '@ianvs/prettier-plugin-sort-imports':\n        optional: true\n      '@prettier/plugin-pug':\n        optional: true\n      '@shopify/prettier-plugin-liquid':\n        optional: true\n      '@trivago/prettier-plugin-sort-imports':\n        optional: true\n      '@zackad/prettier-plugin-twig-melody':\n        optional: true\n      prettier-plugin-astro:\n        optional: true\n      prettier-plugin-css-order:\n        optional: true\n      prettier-plugin-import-sort:\n        optional: true\n      prettier-plugin-jsdoc:\n        optional: true\n      prettier-plugin-marko:\n        optional: true\n      prettier-plugin-multiline-arrays:\n        optional: true\n      prettier-plugin-organize-attributes:\n        optional: true\n      prettier-plugin-organize-imports:\n        optional: true\n      prettier-plugin-sort-imports:\n        optional: true\n      prettier-plugin-style-order:\n        optional: true\n      prettier-plugin-svelte:\n        optional: true\n\n  prettier@3.3.3:\n    resolution: {integrity: sha512-i2tDNA0O5IrMO757lfrdQZCc2jPNDVntV0m/+4whiDfWaTKfMNgR7Qz0NAeGz/nRqF4m5/6CLzbP4/liHt12Ew==}\n    engines: {node: '>=14'}\n    hasBin: true\n\n  pretty-bytes@5.6.0:\n    resolution: {integrity: sha512-FFw039TmrBqFK8ma/7OL3sDz/VytdtJr044/QUJtH0wK9lb9jLq9tJyIxUwtQJHwar2BqtiA4iCWSwo9JLkzFg==}\n    engines: {node: '>=6'}\n\n  pretty-bytes@6.1.1:\n    resolution: {integrity: sha512-mQUvGU6aUFQ+rNvTIAcZuWGRT9a6f6Yrg9bHs4ImKF+HZCEK+plBvnAZYSIQztknZF2qnzNtr6F8s0+IuptdlQ==}\n    engines: {node: ^14.13.1 || >=16.0.0}\n\n  pretty-format@29.7.0:\n    resolution: {integrity: sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==}\n    engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n\n  preview-email@3.1.0:\n    resolution: {integrity: sha512-ZtV1YrwscEjlrUzYrTSs6Nwo49JM3pXLM4fFOBSC3wSni+bxaWlw9/Qgk75PZO8M7cX2EybmL2iwvaV3vkAttw==}\n    engines: {node: '>=14'}\n\n  prisma@5.20.0:\n    resolution: {integrity: sha512-6obb3ucKgAnsGS9x9gLOe8qa51XxvJ3vLQtmyf52CTey1Qcez3A6W6ROH5HIz5Q5bW+0VpmZb8WBohieMFGpig==}\n    engines: {node: '>=16.13'}\n    hasBin: true\n\n  process-nextick-args@2.0.1:\n    resolution: {integrity: sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag==}\n\n  process@0.11.10:\n    resolution: {integrity: sha512-cdGef/drWFoydD1JsMzuFf8100nZl+GT+yacc2bEced5f9Rjk4z+WtFUTBu9PhOi9j/jfmBPu0mMEY4wIdAF8A==}\n    engines: {node: '>= 0.6.0'}\n\n  promise@7.3.1:\n    resolution: {integrity: sha512-nolQXZ/4L+bP/UGlkfaIujX9BKxGwmQ9OT4mOt5yvy8iK1h3wqTEJCijzGANTCCl9nWjY41juyAn2K3Q1hLLTg==}\n\n  prompts@2.4.2:\n    resolution: {integrity: sha512-NxNv/kLguCA7p3jE8oL2aEBsrJWgAakBpgmgK6lpPWV+WuOmY6r2/zbAVnP+T8bQlA0nzHXSJSJW0Hq7ylaD2Q==}\n    engines: {node: '>= 6'}\n\n  proxy-addr@2.0.7:\n    resolution: {integrity: sha512-llQsMLSUDUPT44jdrU/O37qlnifitDP+ZwrmmZcoSKyLKvtZxpyV0n2/bD/N4tBAAZ/gJEdZU7KMraoK1+XYAg==}\n    engines: {node: '>= 0.10'}\n\n  proxy-from-env@1.1.0:\n    resolution: {integrity: sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg==}\n\n  prr@1.0.1:\n    resolution: {integrity: sha512-yPw4Sng1gWghHQWj0B3ZggWUm4qVbPwPFcRG8KyxiU7J2OHFSoEHKS+EZ3fv5l1t9CyCiop6l/ZYeWbrgoQejw==}\n\n  pug-attrs@3.0.0:\n    resolution: {integrity: sha512-azINV9dUtzPMFQktvTXciNAfAuVh/L/JCl0vtPCwvOA21uZrC08K/UnmrL+SXGEVc1FwzjW62+xw5S/uaLj6cA==}\n\n  pug-code-gen@3.0.3:\n    resolution: {integrity: sha512-cYQg0JW0w32Ux+XTeZnBEeuWrAY7/HNE6TWnhiHGnnRYlCgyAUPoyh9KzCMa9WhcJlJ1AtQqpEYHc+vbCzA+Aw==}\n\n  pug-error@2.1.0:\n    resolution: {integrity: sha512-lv7sU9e5Jk8IeUheHata6/UThZ7RK2jnaaNztxfPYUY+VxZyk/ePVaNZ/vwmH8WqGvDz3LrNYt/+gA55NDg6Pg==}\n\n  pug-filters@4.0.0:\n    resolution: {integrity: sha512-yeNFtq5Yxmfz0f9z2rMXGw/8/4i1cCFecw/Q7+D0V2DdtII5UvqE12VaZ2AY7ri6o5RNXiweGH79OCq+2RQU4A==}\n\n  pug-lexer@5.0.1:\n    resolution: {integrity: sha512-0I6C62+keXlZPZkOJeVam9aBLVP2EnbeDw3An+k0/QlqdwH6rv8284nko14Na7c0TtqtogfWXcRoFE4O4Ff20w==}\n\n  pug-linker@4.0.0:\n    resolution: {integrity: sha512-gjD1yzp0yxbQqnzBAdlhbgoJL5qIFJw78juN1NpTLt/mfPJ5VgC4BvkoD3G23qKzJtIIXBbcCt6FioLSFLOHdw==}\n\n  pug-load@3.0.0:\n    resolution: {integrity: sha512-OCjTEnhLWZBvS4zni/WUMjH2YSUosnsmjGBB1An7CsKQarYSWQ0GCVyd4eQPMFJqZ8w9xgs01QdiZXKVjk92EQ==}\n\n  pug-parser@6.0.0:\n    resolution: {integrity: sha512-ukiYM/9cH6Cml+AOl5kETtM9NR3WulyVP2y4HOU45DyMim1IeP/OOiyEWRr6qk5I5klpsBnbuHpwKmTx6WURnw==}\n\n  pug-runtime@3.0.1:\n    resolution: {integrity: sha512-L50zbvrQ35TkpHwv0G6aLSuueDRwc/97XdY8kL3tOT0FmhgG7UypU3VztfV/LATAvmUfYi4wNxSajhSAeNN+Kg==}\n\n  pug-strip-comments@2.0.0:\n    resolution: {integrity: sha512-zo8DsDpH7eTkPHCXFeAk1xZXJbyoTfdPlNR0bK7rpOMuhBYb0f5qUVCO1xlsitYd3w5FQTK7zpNVKb3rZoUrrQ==}\n\n  pug-walk@2.0.0:\n    resolution: {integrity: sha512-yYELe9Q5q9IQhuvqsZNwA5hfPkMJ8u92bQLIMcsMxf/VADjNtEYptU+inlufAFYcWdHlwNfZOEnOOQrZrcyJCQ==}\n\n  pug@3.0.3:\n    resolution: {integrity: sha512-uBi6kmc9f3SZ3PXxqcHiUZLmIXgfgWooKWXcwSGwQd2Zi5Rb0bT14+8CJjJgI8AB+nndLaNgHGrcc6bPIB665g==}\n\n  pump@3.0.0:\n    resolution: {integrity: sha512-LwZy+p3SFs1Pytd/jYct4wpv49HiYCqd9Rlc5ZVdk0V+8Yzv6jR5Blk3TRmPL1ft69TxP0IMZGJ+WPFU2BFhww==}\n\n  punycode.js@2.3.1:\n    resolution: {integrity: sha512-uxFIHU0YlHYhDQtV4R9J6a52SLx28BCjT+4ieh7IGbgwVJWO+km431c4yRlREUAsAmt/uMjQUyQHNEPf0M39CA==}\n    engines: {node: '>=6'}\n\n  punycode@1.4.1:\n    resolution: {integrity: sha512-jmYNElW7yvO7TV33CjSmvSiE2yco3bV2czu/OzDKdMNVZQWfxCblURLhf+47syQRBntjfLdd/H0egrzIG+oaFQ==}\n\n  punycode@2.3.1:\n    resolution: {integrity: sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==}\n    engines: {node: '>=6'}\n\n  pure-rand@6.1.0:\n    resolution: {integrity: sha512-bVWawvoZoBYpp6yIoQtQXHZjmz35RSVHnUOTefl8Vcjr8snTPY1wnpSPMWekcFwbxI6gtmT7rSYPFvz71ldiOA==}\n\n  pvtsutils@1.3.5:\n    resolution: {integrity: sha512-ARvb14YB9Nm2Xi6nBq1ZX6dAM0FsJnuk+31aUp4TrcZEdKUlSqOqsxJHUPJDNE3qiIp+iUPEIeR6Je/tgV7zsA==}\n\n  pvutils@1.1.3:\n    resolution: {integrity: sha512-pMpnA0qRdFp32b1sJl1wOJNxZLQ2cbQx+k6tjNtZ8CpvVhNqEPRgivZ2WOUev2YMajecdH7ctUPDvEe87nariQ==}\n    engines: {node: '>=6.0.0'}\n\n  q@1.5.1:\n    resolution: {integrity: sha512-kV/CThkXo6xyFEZUugw/+pIOywXcDbFYgSct5cT3gqlbkBE1SJdwy6UQoZvodiWF/ckQLZyDE/Bu1M6gVu5lVw==}\n    engines: {node: '>=0.6.0', teleport: '>=0.2.0'}\n    deprecated: |-\n      You or someone you depend on is using Q, the JavaScript Promise library that gave JavaScript developers strong feelings about promises. They can almost certainly migrate to the native JavaScript promise now. Thank you literally everyone for joining me in this bet against the odds. Be excellent to each other.\n\n      (For a CapTP with native promises, see @endo/eventual-send and @endo/captp)\n\n  qs@6.11.0:\n    resolution: {integrity: sha512-MvjoMCJwEarSbUYk5O+nmoSzSutSsTwF85zcHPQ9OrlFoZOYIjaqBAJIqIXjptyD5vThxGq52Xu/MaJzRkIk4Q==}\n    engines: {node: '>=0.6'}\n\n  qs@6.13.0:\n    resolution: {integrity: sha512-+38qI9SOr8tfZ4QmJNplMUxqjbe7LKvvZgWdExBOmd+egZTtjLB67Gu0HRX3u/XOq7UU2Nx6nsjvS16Z9uwfpg==}\n    engines: {node: '>=0.6'}\n\n  queue-microtask@1.2.3:\n    resolution: {integrity: sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==}\n\n  quicktype-core@23.0.170:\n    resolution: {integrity: sha512-ZsjveG0yJUIijUx4yQshzyQ5EAXKbFSBTQJHnJ+KoSZVxcS+m3GcmDpzrdUIRYMhgLaF11ZGvLSYi5U0xcwemw==}\n\n  ramda-adjunct@2.36.0:\n    resolution: {integrity: sha512-8w+/Hx73oByS+vo+BfAPOG3HYL2ay6O5fjrJpR7NFxMoFWksKz6vSOtvjqdfMM6MfAimHizq9tpdI0OD4xbKog==}\n    engines: {node: '>=0.10.3'}\n    peerDependencies:\n      ramda: '>= 0.19.0 <= 0.27.2'\n\n  ramda@0.27.2:\n    resolution: {integrity: sha512-SbiLPU40JuJniHexQSAgad32hfwd+DRUdwF2PlVuI5RZD0/vahUco7R8vD86J/tcEKKF9vZrUVwgtmGCqlCKyA==}\n\n  ramda@0.28.0:\n    resolution: {integrity: sha512-9QnLuG/kPVgWvMQ4aODhsBUFKOUmnbUnsSXACv+NCQZcHbeb+v8Lodp8OVxtRULN1/xOyYLLaL6npE6dMq5QTA==}\n\n  random-bytes@1.0.0:\n    resolution: {integrity: sha512-iv7LhNVO047HzYR3InF6pUcUsPQiHTM1Qal51DcGSuZFBil1aBBWG5eHPNek7bvILMaYJ/8RU1e8w1AMdHmLQQ==}\n    engines: {node: '>= 0.8'}\n\n  randombytes@2.1.0:\n    resolution: {integrity: sha512-vYl3iOX+4CKUWuxGi9Ukhie6fsqXqS9FE2Zaic4tNFD2N2QQaXOMFbuKK4QmDHC0JO6B1Zp41J0LpT0oR68amQ==}\n\n  range-parser@1.2.1:\n    resolution: {integrity: sha512-Hrgsx+orqoygnmhFbKaHE6c296J+HTAQXoxEF6gNupROmmGJRoyzfG3ccAveqCBrwr/2yxQ5BVd/GTl5agOwSg==}\n    engines: {node: '>= 0.6'}\n\n  raw-body@2.5.2:\n    resolution: {integrity: sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==}\n    engines: {node: '>= 0.8'}\n\n  rc@1.2.8:\n    resolution: {integrity: sha512-y3bGgqKj3QBdxLbLkomlohkvsA8gdAiUQlSBJnBhfn+BPxg4bc62d8TcBW15wavDfgexCgccckhcZvywyQYPOw==}\n    hasBin: true\n\n  react-is@18.3.1:\n    resolution: {integrity: sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==}\n\n  read-cache@1.0.0:\n    resolution: {integrity: sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==}\n\n  read-pkg@3.0.0:\n    resolution: {integrity: sha512-BLq/cCO9two+lBgiTYNqD6GdtK8s4NpaWrl6/rCO9w0TUS8oJl7cmToOZfRYllKTISY6nt1U7jQ53brmKqY6BA==}\n    engines: {node: '>=4'}\n\n  readable-stream@2.3.8:\n    resolution: {integrity: sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==}\n\n  readable-stream@3.6.2:\n    resolution: {integrity: sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==}\n    engines: {node: '>= 6'}\n\n  readable-stream@4.5.2:\n    resolution: {integrity: sha512-yjavECdqeZ3GLXNgRXgeQEdz9fvDDkNKyHnbHRFtOr7/LcfgBcmct7t/ET+HaCTqfh06OzoAxrkN/IfjJBVe+g==}\n    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n\n  readdirp@3.6.0:\n    resolution: {integrity: sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==}\n    engines: {node: '>=8.10.0'}\n\n  readdirp@4.0.2:\n    resolution: {integrity: sha512-yDMz9g+VaZkqBYS/ozoBJwaBhTbZo3UNYQHNRw1D3UFQB8oHB4uS/tAODO+ZLjGWmUbKnIlOWO+aaIiAxrUWHA==}\n    engines: {node: '>= 14.16.0'}\n\n  redis-errors@1.2.0:\n    resolution: {integrity: sha512-1qny3OExCf0UvUV/5wpYKf2YwPcOqXzkwKKSmKHiE6ZMQs5heeE/c8eXK+PNllPvmjgAbfnsbpkGZWy8cBpn9w==}\n    engines: {node: '>=4'}\n\n  redis-parser@3.0.0:\n    resolution: {integrity: sha512-DJnGAeenTdpMEH6uAJRK/uiyEIH9WVsUmoLwzudwGJUwZPp80PDBWPHXSAGNPwNvIXAbe7MSUB1zQFugFml66A==}\n    engines: {node: '>=4'}\n\n  reflect-metadata@0.2.2:\n    resolution: {integrity: sha512-urBwgfrvVP/eAyXx4hluJivBKzuEbSQs9rKWCrCkbSxNv8mxPcUZKeuoF3Uy4mJl3Lwprp6yy5/39VWigZ4K6Q==}\n\n  regenerate-unicode-properties@10.2.0:\n    resolution: {integrity: sha512-DqHn3DwbmmPVzeKj9woBadqmXxLvQoQIwu7nopMc72ztvxVmVk2SBhSnx67zuye5TP+lJsb/TBQsjLKhnDf3MA==}\n    engines: {node: '>=4'}\n\n  regenerate@1.4.2:\n    resolution: {integrity: sha512-zrceR/XhGYU/d/opr2EKO7aRHUeiBI8qjtfHqADTwZd6Szfy16la6kqD0MIUs5z5hx6AaKa+PixpPrR289+I0A==}\n\n  regenerator-runtime@0.13.11:\n    resolution: {integrity: sha512-kY1AZVr2Ra+t+piVaJ4gxaFaReZVH40AKNo7UCX6W+dEwBo/2oZJzqfuN1qLq1oL45o56cPaTXELwrTh8Fpggg==}\n\n  regenerator-runtime@0.14.1:\n    resolution: {integrity: sha512-dYnhHh0nJoMfnkZs6GmmhFknAGRrLznOu5nc9ML+EJxGvrx6H7teuevqVqCuPcPK//3eDrrjQhehXVx9cnkGdw==}\n\n  regenerator-transform@0.15.2:\n    resolution: {integrity: sha512-hfMp2BoF0qOk3uc5V20ALGDS2ddjQaLrdl7xrGXvAIow7qeWRM2VA2HuCHkUKk9slq3VwEwLNK3DFBqDfPGYtg==}\n\n  regexp.prototype.flags@1.5.2:\n    resolution: {integrity: sha512-NcDiDkTLuPR+++OCKB0nWafEmhg/Da8aUPLPMQbK+bxKKCm1/S5he+AqYa4PlMCVBalb4/yxIRub6qkEx5yJbw==}\n    engines: {node: '>= 0.4'}\n\n  regexp.prototype.flags@1.5.3:\n    resolution: {integrity: sha512-vqlC04+RQoFalODCbCumG2xIOvapzVMHwsyIGM/SIE8fRhFFsXeH8/QQ+s0T0kDAhKc4k30s73/0ydkHQz6HlQ==}\n    engines: {node: '>= 0.4'}\n\n  regexpu-core@6.1.1:\n    resolution: {integrity: sha512-k67Nb9jvwJcJmVpw0jPttR1/zVfnKf8Km0IPatrU/zJ5XeG3+Slx0xLXs9HByJSzXzrlz5EDvN6yLNMDc2qdnw==}\n    engines: {node: '>=4'}\n\n  regjsgen@0.8.0:\n    resolution: {integrity: sha512-RvwtGe3d7LvWiDQXeQw8p5asZUmfU1G/l6WbUXeHta7Y2PEIvBTwH6E2EfmYUK8pxcxEdEmaomqyp0vZZ7C+3Q==}\n\n  regjsparser@0.11.1:\n    resolution: {integrity: sha512-1DHODs4B8p/mQHU9kr+jv8+wIC9mtG4eBHxWxIq5mhjE3D5oORhCc6deRKzTjs9DcfRFmj9BHSDguZklqCGFWQ==}\n    hasBin: true\n\n  relateurl@0.2.7:\n    resolution: {integrity: sha512-G08Dxvm4iDN3MLM0EsP62EDV9IuhXPR6blNz6Utcp7zyV3tr4HVNINt6MpaRWbxoOHT3Q7YN2P+jaHX8vUbgog==}\n    engines: {node: '>= 0.10'}\n\n  relay-runtime@12.0.0:\n    resolution: {integrity: sha512-QU6JKr1tMsry22DXNy9Whsq5rmvwr3LSZiiWV/9+DFpuTWvp+WFhobWMc8TC4OjKFfNhEZy7mOiqUAn5atQtug==}\n\n  remedial@1.0.8:\n    resolution: {integrity: sha512-/62tYiOe6DzS5BqVsNpH/nkGlX45C/Sp6V+NtiN6JQNS1Viay7cWkazmRkrQrdFj2eshDe96SIQNIoMxqhzBOg==}\n\n  remove-trailing-separator@1.1.0:\n    resolution: {integrity: sha512-/hS+Y0u3aOfIETiaiirUFwDBDzmXPvO+jAfKTitUngIPzdKc6Z0LoFjM/CK5PL4C+eKwHohlHAb6H0VFfmmUsw==}\n\n  remove-trailing-spaces@1.0.8:\n    resolution: {integrity: sha512-O3vsMYfWighyFbTd8hk8VaSj9UAGENxAtX+//ugIst2RMk5e03h6RoIS+0ylsFxY1gvmPuAY/PO4It+gPEeySA==}\n\n  repeat-string@1.6.1:\n    resolution: {integrity: sha512-PV0dzCYDNfRi1jCDbJzpW7jNNDRuCOG/jI5ctQcGKt/clZD+YcPS3yIlWuTJMmESC8aevCFmWJy5wjAFgNqN6w==}\n    engines: {node: '>=0.10'}\n\n  require-directory@2.1.1:\n    resolution: {integrity: sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==}\n    engines: {node: '>=0.10.0'}\n\n  require-from-string@2.0.2:\n    resolution: {integrity: sha512-Xf0nWe6RseziFMu+Ap9biiUbmplq6S9/p+7w7YXP/JBHhrUDDUhwa+vANyubuqfZWTveU//DYVGsDG7RKL/vEw==}\n    engines: {node: '>=0.10.0'}\n\n  require-main-filename@2.0.0:\n    resolution: {integrity: sha512-NKN5kMDylKuldxYLSUfrbo5Tuzh4hd+2E8NPPX02mZtn1VuREQToYe/ZdlJy+J3uCpfaiGF05e7B8W0iXbQHmg==}\n\n  requires-port@1.0.0:\n    resolution: {integrity: sha512-KigOCHcocU3XODJxsu8i/j8T9tzT4adHiecwORRQ0ZZFcp7ahwXuRU1m+yuO90C5ZUyGeGfocHDI14M3L3yDAQ==}\n\n  resolve-cwd@3.0.0:\n    resolution: {integrity: sha512-OrZaX2Mb+rJCpH/6CpSqt9xFVpN++x01XnN2ie9g6P5/3xelLAkXWVADpdz1IHD/KFfEXyE6V0U01OQ3UO2rEg==}\n    engines: {node: '>=8'}\n\n  resolve-from@2.0.0:\n    resolution: {integrity: sha512-qpFcKaXsq8+oRoLilkwyc7zHGF5i9Q2/25NIgLQQ/+VVv9rU4qvr6nXVAw1DsnXJyQkZsR4Ytfbtg5ehfcUssQ==}\n    engines: {node: '>=0.10.0'}\n\n  resolve-from@4.0.0:\n    resolution: {integrity: sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==}\n    engines: {node: '>=4'}\n\n  resolve-from@5.0.0:\n    resolution: {integrity: sha512-qYg9KP24dD5qka9J47d0aVky0N+b4fTU89LN9iDnjB5waksiC49rvMB0PrUJQGoTmH50XPiqOvAjDfaijGxYZw==}\n    engines: {node: '>=8'}\n\n  resolve.exports@2.0.2:\n    resolution: {integrity: sha512-X2UW6Nw3n/aMgDVy+0rSqgHlv39WZAlZrXCdnbyEiKm17DSqHX4MmQMaST3FbeWR5FTuRcUwYAziZajji0Y7mg==}\n    engines: {node: '>=10'}\n\n  resolve@1.22.8:\n    resolution: {integrity: sha512-oKWePCxqpd6FlLvGV1VU0x7bkPmmCNolxzjMf4NczoDnQcIWrAF+cPtZn5i6n+RfD2d9i0tzpKnG6Yk168yIyw==}\n    hasBin: true\n\n  restore-cursor@3.1.0:\n    resolution: {integrity: sha512-l+sSefzHpj5qimhFSE5a8nufZYAM3sBSVMAPtYkmC+4EH2anSGaEMXSD0izRQbu9nfyQ9y5JrVmp7E8oZrUjvA==}\n    engines: {node: '>=8'}\n\n  restore-cursor@5.1.0:\n    resolution: {integrity: sha512-oMA2dcrw6u0YfxJQXm342bFKX/E4sG9rbTzO9ptUcR/e8A33cHuvStiYOwH7fszkZlZ1z/ta9AAoPk2F4qIOHA==}\n    engines: {node: '>=18'}\n\n  retry@0.13.1:\n    resolution: {integrity: sha512-XQBQ3I8W1Cge0Seh+6gjj03LbmRFWuoszgK9ooCpwYIrhhoO80pfq4cUkU5DkknwfOfFteRwlZ56PYOGYyFWdg==}\n    engines: {node: '>= 4'}\n\n  reusify@1.0.4:\n    resolution: {integrity: sha512-U9nH88a3fc/ekCF1l0/UP1IosiuIjyTh7hBvXVMHYgVcfGvt897Xguj2UOLDeI5BG2m7/uwyaLVT6fbtCwTyzw==}\n    engines: {iojs: '>=1.0.0', node: '>=0.10.0'}\n\n  rfdc@1.4.1:\n    resolution: {integrity: sha512-q1b3N5QkRUWUl7iyylaaj3kOpIT0N2i9MqIEQXP73GVsN9cw3fdx8X63cEmWhJGi2PPCF23Ijp7ktmd39rawIA==}\n\n  rimraf@2.7.1:\n    resolution: {integrity: sha512-uWjbaKIK3T1OSVptzX7Nl6PvQ3qAGtKEtVRjRuazjfL3Bx5eI409VZSqgND+4UNnmzLVdPj9FqFJNPqBZFve4w==}\n    deprecated: Rimraf versions prior to v4 are no longer supported\n    hasBin: true\n\n  rimraf@3.0.2:\n    resolution: {integrity: sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==}\n    deprecated: Rimraf versions prior to v4 are no longer supported\n    hasBin: true\n\n  rimraf@6.0.1:\n    resolution: {integrity: sha512-9dkvaxAsk/xNXSJzMgFqqMCuFgt2+KsOFek3TMLfo8NCPfWpBmqwyNn5Y+NX56QUYfCtsyhF3ayiboEoUmJk/A==}\n    engines: {node: 20 || >=22}\n    hasBin: true\n\n  rollup-plugin-inject@3.0.2:\n    resolution: {integrity: sha512-ptg9PQwzs3orn4jkgXJ74bfs5vYz1NCZlSQMBUA0wKcGp5i5pA1AO3fOUEte8enhGUC+iapTCzEWw2jEFFUO/w==}\n    deprecated: This package has been deprecated and is no longer maintained. Please use @rollup/plugin-inject.\n\n  rollup-plugin-node-polyfills@0.2.1:\n    resolution: {integrity: sha512-4kCrKPTJ6sK4/gLL/U5QzVT8cxJcofO0OU74tnB19F40cmuAKSzH5/siithxlofFEjwvw1YAhPmbvGNA6jEroA==}\n\n  rollup-plugin-polyfill-node@0.13.0:\n    resolution: {integrity: sha512-FYEvpCaD5jGtyBuBFcQImEGmTxDTPbiHjJdrYIp+mFIwgXiXabxvKUK7ZT9P31ozu2Tqm9llYQMRWsfvTMTAOw==}\n    peerDependencies:\n      rollup: ^1.20.0 || ^2.0.0 || ^3.0.0 || ^4.0.0\n\n  rollup-pluginutils@2.8.2:\n    resolution: {integrity: sha512-EEp9NhnUkwY8aif6bxgovPHMoMoNr2FulJziTndpt5H9RdwC47GSGuII9XxpSdzVGM0GWrNPHV6ie1LTNJPaLQ==}\n\n  rollup@2.79.2:\n    resolution: {integrity: sha512-fS6iqSPZDs3dr/y7Od6y5nha8dW1YnbgtsyotCVvoFGKbERG++CVRFv1meyGDE1SNItQA8BrnCw7ScdAhRJ3XQ==}\n    engines: {node: '>=10.0.0'}\n    hasBin: true\n\n  rollup@3.29.4:\n    resolution: {integrity: sha512-oWzmBZwvYrU0iJHtDmhsm662rC15FRXmcjCk1xD771dFDx5jJ02ufAQQTn0etB2emNk4J9EZg/yWKpsn9BWGRw==}\n    engines: {node: '>=14.18.0', npm: '>=8.0.0'}\n    hasBin: true\n\n  rollup@4.24.0:\n    resolution: {integrity: sha512-DOmrlGSXNk1DM0ljiQA+i+o0rSLhtii1je5wgk60j49d1jHT5YYttBv1iWOnYSTG+fZZESUOSNiAl89SIet+Cg==}\n    engines: {node: '>=18.0.0', npm: '>=8.0.0'}\n    hasBin: true\n\n  rrweb-cssom@0.7.1:\n    resolution: {integrity: sha512-TrEMa7JGdVm0UThDJSx7ddw5nVm3UJS9o9CCIZ72B1vSyEZoziDqBYP3XIoi/12lKrJR8rE3jeFHMok2F/Mnsg==}\n\n  run-applescript@3.2.0:\n    resolution: {integrity: sha512-Ep0RsvAjnRcBX1p5vogbaBdAGu/8j/ewpvGqnQYunnLd9SM0vWcPJewPKNnWFggf0hF0pwIgwV5XK7qQ7UZ8Qg==}\n    engines: {node: '>=4'}\n\n  run-applescript@5.0.0:\n    resolution: {integrity: sha512-XcT5rBksx1QdIhlFOCtgZkB99ZEouFZ1E2Kc2LHqNW13U3/74YGdkQRmThTwxy4QIyookibDKYZOPqX//6BlAg==}\n    engines: {node: '>=12'}\n\n  run-applescript@7.0.0:\n    resolution: {integrity: sha512-9by4Ij99JUr/MCFBUkDKLWK3G9HVXmabKz9U5MlIAIuvuzkiOicRYs8XJLxX+xahD+mLiiCYDqF9dKAgtzKP1A==}\n    engines: {node: '>=18'}\n\n  run-async@2.4.1:\n    resolution: {integrity: sha512-tvVnVv01b8c1RrA6Ep7JkStj85Guv/YrMcwqYQnwjsAS2cTmmPGBBjAjpCW7RrSodNSoE2/qg9O4bceNvUuDgQ==}\n    engines: {node: '>=0.12.0'}\n\n  run-async@3.0.0:\n    resolution: {integrity: sha512-540WwVDOMxA6dN6We19EcT9sc3hkXPw5mzRNGM3FkdN/vtE9NFvj5lFAPNwUDmJjXidm3v7TC1cTE7t17Ulm1Q==}\n    engines: {node: '>=0.12.0'}\n\n  run-parallel@1.2.0:\n    resolution: {integrity: sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==}\n\n  rusha@0.8.14:\n    resolution: {integrity: sha512-cLgakCUf6PedEu15t8kbsjnwIFFR2D4RfL+W3iWFJ4iac7z4B0ZI8fxy4R3J956kAI68HclCFGL8MPoUVC3qVA==}\n\n  rxjs@7.5.6:\n    resolution: {integrity: sha512-dnyv2/YsXhnm461G+R/Pe5bWP41Nm6LBXEYWI6eiFP4fiwx6WRI/CD0zbdVAudd9xwLEF2IDcKXLHit0FYjUzw==}\n\n  rxjs@7.8.1:\n    resolution: {integrity: sha512-AA3TVj+0A2iuIoQkWEK/tqFjBq2j+6PO6Y0zJcvzLAFhEFIO3HL0vls9hWLncZbAAbK0mar7oZ4V079I/qPMxg==}\n\n  safe-array-concat@1.1.2:\n    resolution: {integrity: sha512-vj6RsCsWBCf19jIeHEfkRMw8DPiBb+DMXklQ/1SGDHOMlHdPUkZXFQ2YdplS23zESTijAcurb1aSgJA3AgMu1Q==}\n    engines: {node: '>=0.4'}\n\n  safe-buffer@5.1.2:\n    resolution: {integrity: sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==}\n\n  safe-buffer@5.2.1:\n    resolution: {integrity: sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==}\n\n  safe-regex-test@1.0.3:\n    resolution: {integrity: sha512-CdASjNJPvRa7roO6Ra/gLYBTzYzzPyyBXxIMdGW3USQLyjWEls2RgW5UBTXaQVp+OrpeCK3bLem8smtmheoRuw==}\n    engines: {node: '>= 0.4'}\n\n  safer-buffer@2.1.2:\n    resolution: {integrity: sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==}\n\n  sass@1.79.5:\n    resolution: {integrity: sha512-W1h5kp6bdhqFh2tk3DsI771MoEJjvrSY/2ihJRJS4pjIyfJCw0nTsxqhnrUzaLMOJjFchj8rOvraI/YUVjtx5g==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  sass@1.80.3:\n    resolution: {integrity: sha512-ptDWyVmDMVielpz/oWy3YP3nfs7LpJTHIJZboMVs8GEC9eUmtZTZhMHlTW98wY4aEorDfjN38+Wr/XjskFWcfA==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  sax@1.4.1:\n    resolution: {integrity: sha512-+aWOz7yVScEGoKNd4PA10LZ8sk0A/z5+nXQG5giUO5rprX9jgYsTdov9qCchZiPIZezbZH+jRut8nPodFAX4Jg==}\n\n  saxes@6.0.0:\n    resolution: {integrity: sha512-xAg7SOnEhrm5zI3puOOKyy1OMcMlIJZYNJY7xLBwSze0UjhPLnWfj2GF2EpT0jmzaJKIWKHLsaSSajf35bcYnA==}\n    engines: {node: '>=v12.22.7'}\n\n  schema-utils@3.3.0:\n    resolution: {integrity: sha512-pN/yOAvcC+5rQ5nERGuwrjLlYvLTbCibnZ1I7B1LaiAz9BRBlE9GMgE/eqV30P7aJQUf7Ddimy/RsbYO/GrVGg==}\n    engines: {node: '>= 10.13.0'}\n\n  scuid@1.1.0:\n    resolution: {integrity: sha512-MuCAyrGZcTLfQoH2XoBlQ8C6bzwN88XT/0slOGz0pn8+gIP85BOAfYa44ZXQUTOwRwPU0QvgU+V+OSajl/59Xg==}\n\n  secure-compare@3.0.1:\n    resolution: {integrity: sha512-AckIIV90rPDcBcglUwXPF3kg0P0qmPsPXAj6BBEENQE1p5yA1xfmDJzfi1Tappj37Pv2mVbKpL3Z1T+Nn7k1Qw==}\n\n  selderee@0.11.0:\n    resolution: {integrity: sha512-5TF+l7p4+OsnP8BCCvSyZiSPc4x4//p5uPwK8TCnVPJYRmU2aYKMpOXvw8zM5a5JvuuCGN1jmsMwuU2W02ukfA==}\n\n  semver@5.7.2:\n    resolution: {integrity: sha512-cBznnQ9KjJqU67B52RMC65CMarK2600WFnbkcaiwWq3xy/5haFJlshgnpjovMVJ+Hff49d8GEn0b87C5pDQ10g==}\n    hasBin: true\n\n  semver@6.3.1:\n    resolution: {integrity: sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==}\n    hasBin: true\n\n  semver@7.6.3:\n    resolution: {integrity: sha512-oVekP1cKtI+CTDvHWYFUcMtsK/00wmAEfyqKfNdARm8u1wNVhSgaX7A8d4UuIlUI5e84iEwOhs7ZPYRmzU9U6A==}\n    engines: {node: '>=10'}\n    hasBin: true\n\n  send@0.19.0:\n    resolution: {integrity: sha512-dW41u5VfLXu8SJh5bwRmyYUbAoSB3c9uQh6L8h/KtsFREPWpbX1lrljJo186Jc4nmci/sGUZ9a0a0J2zgfq2hw==}\n    engines: {node: '>= 0.8.0'}\n\n  sentence-case@3.0.4:\n    resolution: {integrity: sha512-8LS0JInaQMCRoQ7YUytAo/xUu5W2XnQxV2HI/6uM6U7CITS1RqPElr30V6uIqyMKM9lJGRVFy5/4CuzcixNYSg==}\n\n  serialize-javascript@6.0.0:\n    resolution: {integrity: sha512-Qr3TosvguFt8ePWqsvRfrKyQXIiW+nGbYpy8XK24NQHE83caxWt+mIymTT19DGFbNWNLfEwsrkSmN64lVWB9ag==}\n\n  serialize-javascript@6.0.2:\n    resolution: {integrity: sha512-Saa1xPByTTq2gdeFZYLLo+RFE35NHZkAbqZeWNd3BpzppeVisAqpDjcp8dyf6uIvEqJRd46jemmyA4iFIeVk8g==}\n\n  serve-static@1.16.0:\n    resolution: {integrity: sha512-pDLK8zwl2eKaYrs8mrPZBJua4hMplRWJ1tIFksVC3FtBEBnl8dxgeHtsaMS8DhS9i4fLObaon6ABoc4/hQGdPA==}\n    engines: {node: '>= 0.8.0'}\n\n  serve-static@1.16.2:\n    resolution: {integrity: sha512-VqpjJZKadQB/PEbEwvFdO43Ax5dFBZ2UECszz8bQ7pi7wt//PWe1P6MN7eCnjsatYtBT6EuiClbjSWP2WrIoTw==}\n    engines: {node: '>= 0.8.0'}\n\n  set-blocking@2.0.0:\n    resolution: {integrity: sha512-KiKBS8AnWGEyLzofFfmvKwpdPzqiy16LvQfK3yv/fVH7Bj13/wl3JSR1J+rfgRE9q7xUJK4qvgS8raSOeLUehw==}\n\n  set-cookie-parser-es@1.0.5:\n    resolution: {integrity: sha512-nU27kVj4O6+a1wOOWB6uezxB9SWLCjEmYJr6eRBmkAZfOx/TBg2p0jkCl1dMgeYtmFRAJSGe4u9VN7dwPu9PRQ==}\n\n  set-cookie-parser@2.7.0:\n    resolution: {integrity: sha512-lXLOiqpkUumhRdFF3k1osNXCy9akgx/dyPZ5p8qAg9seJzXr5ZrlqZuWIMuY6ejOsVLE6flJ5/h3lsn57fQ/PQ==}\n\n  set-function-length@1.2.2:\n    resolution: {integrity: sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==}\n    engines: {node: '>= 0.4'}\n\n  set-function-name@2.0.2:\n    resolution: {integrity: sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==}\n    engines: {node: '>= 0.4'}\n\n  setimmediate@1.0.5:\n    resolution: {integrity: sha512-MATJdZp8sLqDl/68LfQmbP8zKPLQNV6BIZoIgrscFDQ+RsvK/BxeDQOgyxKKoh0y/8h3BqVFnCqQ/gd+reiIXA==}\n\n  setprototypeof@1.2.0:\n    resolution: {integrity: sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw==}\n\n  sha.js@2.4.11:\n    resolution: {integrity: sha512-QMEp5B7cftE7APOjk5Y6xgrbWu+WkLVQwk8JNjZ8nKRciZaByEW6MubieAiToS7+dwvrjGhH8jRXz3MVd0AYqQ==}\n    hasBin: true\n\n  shebang-command@2.0.0:\n    resolution: {integrity: sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==}\n    engines: {node: '>=8'}\n\n  shebang-regex@3.0.0:\n    resolution: {integrity: sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==}\n    engines: {node: '>=8'}\n\n  shell-quote@1.8.1:\n    resolution: {integrity: sha512-6j1W9l1iAs/4xYBI1SYOVZyFcCis9b4KCLQ8fgAGG07QvzaRLVVRQvAy85yNmmZSjYjg4MWh4gNvlPujU/5LpA==}\n\n  side-channel@1.0.6:\n    resolution: {integrity: sha512-fDW/EZ6Q9RiO8eFG8Hj+7u/oW+XrPTIChwCOM2+th2A6OblDtYYIpve9m+KvI9Z4C9qSEXlaGR6bTEYHReuglA==}\n    engines: {node: '>= 0.4'}\n\n  siginfo@2.0.0:\n    resolution: {integrity: sha512-ybx0WO1/8bSBLEWXZvEd7gMW3Sn3JFlW3TvX1nREbDLRNQNaeNN8WK0meBwPdAaOI7TtRRRJn/Es1zhrrCHu7g==}\n\n  signal-exit@3.0.7:\n    resolution: {integrity: sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==}\n\n  signal-exit@4.1.0:\n    resolution: {integrity: sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==}\n    engines: {node: '>=14'}\n\n  signedsource@1.0.0:\n    resolution: {integrity: sha512-6+eerH9fEnNmi/hyM1DXcRK3pWdoMQtlkQ+ns0ntzunjKqp5i3sKCc80ym8Fib3iaYhdJUOPdhlJWj1tvge2Ww==}\n\n  simple-concat@1.0.1:\n    resolution: {integrity: sha512-cSFtAPtRhljv69IK0hTVZQ+OfE9nePi/rtJmw5UjHeVyVroEqJXP1sFztKUy1qU+xvz3u/sfYJLa947b7nAN2Q==}\n\n  simple-get@3.1.1:\n    resolution: {integrity: sha512-CQ5LTKGfCpvE1K0n2us+kuMPbk/q0EKl82s4aheV9oXjFEz6W/Y7oQFVJuU6QG77hRT4Ghb5RURteF5vnWjupA==}\n\n  simple-get@4.0.1:\n    resolution: {integrity: sha512-brv7p5WgH0jmQJr1ZDDfKDOSeWWg+OVypG99A/5vYGPqJ6pxiaHLy8nxtFjBA7oMa01ebA9gfh1uMCFqOuXxvA==}\n\n  sirv@2.0.4:\n    resolution: {integrity: sha512-94Bdh3cC2PKrbgSOUqTiGPWVZeSiXfKOVZNJniWoqrWrRkB1CJzBU3NEbiTsPcYy1lDsANA/THzS+9WBiy5nfQ==}\n    engines: {node: '>= 10'}\n\n  sisteransi@1.0.5:\n    resolution: {integrity: sha512-bLGGlR1QxBcynn2d5YmDX4MGjlZvy2MRBDRNHLJ8VI6l6+9FUiyTFNJ0IveOSP0bcXgVDPRcfGqA0pjaqUpfVg==}\n\n  sitemap@8.0.0:\n    resolution: {integrity: sha512-+AbdxhM9kJsHtruUF39bwS/B0Fytw6Fr1o4ZAIAEqA6cke2xcoO2GleBw9Zw7nRzILVEgz7zBM5GiTJjie1G9A==}\n    engines: {node: '>=14.0.0', npm: '>=6.0.0'}\n    hasBin: true\n\n  slash@3.0.0:\n    resolution: {integrity: sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==}\n    engines: {node: '>=8'}\n\n  slice-ansi@3.0.0:\n    resolution: {integrity: sha512-pSyv7bSTC7ig9Dcgbw9AuRNUb5k5V6oDudjZoMBSr13qpLBG7tB+zgCkARjq7xIUgdz5P1Qe8u+rSGdouOOIyQ==}\n    engines: {node: '>=8'}\n\n  slice-ansi@4.0.0:\n    resolution: {integrity: sha512-qMCMfhY040cVHT43K9BFygqYbUPFZKHOg7K73mtTWJRb8pyP3fzf4Ixd5SzdEJQ6MRUg/WBnOLxghZtKKurENQ==}\n    engines: {node: '>=10'}\n\n  slice-ansi@5.0.0:\n    resolution: {integrity: sha512-FC+lgizVPfie0kkhqUScwRu1O/lF6NOgJmlCgK+/LYxDCTk8sGelYaHDhFcDN+Sn3Cv+3VSa4Byeo+IMCzpMgQ==}\n    engines: {node: '>=12'}\n\n  slice-ansi@7.1.0:\n    resolution: {integrity: sha512-bSiSngZ/jWeX93BqeIAbImyTbEihizcwNjFoRUIY/T1wWQsfsm2Vw1agPKylXvQTU7iASGdHhyqRlqQzfz+Htg==}\n    engines: {node: '>=18'}\n\n  slick@1.12.2:\n    resolution: {integrity: sha512-4qdtOGcBjral6YIBCWJ0ljFSKNLz9KkhbWtuGvUyRowl1kxfuE1x/Z/aJcaiilpb3do9bl5K7/1h9XC5wWpY/A==}\n\n  smob@1.5.0:\n    resolution: {integrity: sha512-g6T+p7QO8npa+/hNx9ohv1E5pVCmWrVCUzUXJyLdMmftX6ER0oiWY/w9knEonLpnOp6b6FenKnMfR8gqwWdwig==}\n\n  snake-case@3.0.4:\n    resolution: {integrity: sha512-LAOh4z89bGQvl9pFfNF8V146i7o7/CqFPbqzYgP+yYzDIDeS9HaNFtXABamRW+AQzEVODcvE79ljJ+8a9YSdMg==}\n\n  socket.io-client@2.5.0:\n    resolution: {integrity: sha512-lOO9clmdgssDykiOmVQQitwBAF3I6mYcQAo7hQ7AM6Ny5X7fp8hIJ3HcQs3Rjz4SoggoxA1OgrQyY8EgTbcPYw==}\n\n  socket.io-client@4.8.0:\n    resolution: {integrity: sha512-C0jdhD5yQahMws9alf/yvtsMGTaIDBnZ8Rb5HU56svyq0l5LIrGzIDZZD5pHQlmzxLuU91Gz+VpQMKgCTNYtkw==}\n    engines: {node: '>=10.0.0'}\n\n  socket.io-parser@3.3.4:\n    resolution: {integrity: sha512-z/pFQB3x+EZldRRzORYW1vwVO8m/3ILkswtnpoeU6Ve3cbMWkmHEWDAVJn4QJtchiiFTo5j7UG2QvwxvaA9vow==}\n\n  socket.io-parser@4.2.4:\n    resolution: {integrity: sha512-/GbIKmo8ioc+NIWIhwdecY0ge+qVBSMdgxGygevmdHj24bsfgtCmcUUcQ5ZzcylGFHsN3k4HB4Cgkl96KVnuew==}\n    engines: {node: '>=10.0.0'}\n\n  socketio-wildcard@2.0.0:\n    resolution: {integrity: sha512-Bf3ioZq15Z2yhFLDasRvbYitg82rwm+5AuER5kQvEQHhNFf4R4K5o/h57nEpN7A59T9FyRtTj34HZfMWAruw/A==}\n\n  sortablejs@1.14.0:\n    resolution: {integrity: sha512-pBXvQCs5/33fdN1/39pPL0NZF20LeRbLQ5jtnheIPN9JQAaufGjKdWduZn4U7wCtVuzKhmRkI0DFYHYRbB2H1w==}\n\n  source-map-js@1.2.1:\n    resolution: {integrity: sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==}\n    engines: {node: '>=0.10.0'}\n\n  source-map-support@0.5.13:\n    resolution: {integrity: sha512-SHSKFHadjVA5oR4PPqhtAVdcBWwRYVd6g6cAXnIbRiIwc2EhPrTuKUBdSLvlEKyIP3GCf89fltvcZiP9MMFA1w==}\n\n  source-map-support@0.5.21:\n    resolution: {integrity: sha512-uBHU3L3czsIyYXKX88fdrGovxdSCoTGDRZ6SYXtSRxLZUzHg5P/66Ht6uoUlHu9EZod+inXhKo3qQgwXUT/y1w==}\n\n  source-map@0.6.1:\n    resolution: {integrity: sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==}\n    engines: {node: '>=0.10.0'}\n\n  source-map@0.7.4:\n    resolution: {integrity: sha512-l3BikUxvPOcn5E74dZiq5BGsTb5yEwhaTSzccU6t4sDOH8NWJCstKO5QT2CvtFoK6F0saL7p9xHAqHOlCPJygA==}\n    engines: {node: '>= 8'}\n\n  source-map@0.8.0-beta.0:\n    resolution: {integrity: sha512-2ymg6oRBpebeZi9UUNsgQ89bhx01TcTkmNTGnNO88imTmbSgy4nfujrgVEFKWpMTEGA11EDkTt7mqObTPdigIA==}\n    engines: {node: '>= 8'}\n\n  sourcemap-codec@1.4.8:\n    resolution: {integrity: sha512-9NykojV5Uih4lgo5So5dtw+f0JgJX30KCNI8gwhz2J9A15wD0Ml6tjHKwf6fTSa6fAdVBdZeNOs9eJ71qCk8vA==}\n    deprecated: Please use @jridgewell/sourcemap-codec instead\n\n  spdx-correct@3.2.0:\n    resolution: {integrity: sha512-kN9dJbvnySHULIluDHy32WHRUu3Og7B9sbY7tsFLctQkIqnMh3hErYgdMjTYuqmcXX+lK5T1lnUt3G7zNswmZA==}\n\n  spdx-exceptions@2.5.0:\n    resolution: {integrity: sha512-PiU42r+xO4UbUS1buo3LPJkjlO7430Xn5SVAhdpzzsPHsjbYVflnnFdATgabnLude+Cqu25p6N+g2lw/PFsa4w==}\n\n  spdx-expression-parse@3.0.1:\n    resolution: {integrity: sha512-cbqHunsQWnJNE6KhVSMsMeH5H/L9EpymbzqTQ3uLwNCLZ1Q481oWaofqH7nO6V07xlXwY6PhQdQ2IedWx/ZK4Q==}\n\n  spdx-license-ids@3.0.17:\n    resolution: {integrity: sha512-sh8PWc/ftMqAAdFiBu6Fy6JUOYjqDJBJvIhpfDMyHrr0Rbp5liZqd4TjtQ/RgfLjKFZb+LMx5hpml5qOWy0qvg==}\n\n  split2@4.2.0:\n    resolution: {integrity: sha512-UcjcJOWknrNkF6PLX83qcHM6KHgVKNkV62Y8a5uYDVv9ydGQVwAHMKqHdJje1VTWpljG0WYpCDhrCdAOYH4TWg==}\n    engines: {node: '>= 10.x'}\n\n  split@1.0.1:\n    resolution: {integrity: sha512-mTyOoPbrivtXnwnIxZRFYRrPNtEFKlpB2fvjSnCQUiAA6qAZzqwna5envK4uk6OIeP17CsdF3rSBGYVBsU0Tkg==}\n\n  splitpanes@3.1.5:\n    resolution: {integrity: sha512-r3Mq2ITFQ5a2VXLOy4/Sb2Ptp7OfEO8YIbhVJqJXoFc9hc5nTXXkCvtVDjIGbvC0vdE7tse+xTM9BMjsszP6bw==}\n\n  sponge-case@1.0.1:\n    resolution: {integrity: sha512-dblb9Et4DAtiZ5YSUZHLl4XhH4uK80GhAZrVXdN4O2P4gQ40Wa5UIOPUHlA/nFd2PLblBZWUioLMMAVrgpoYcA==}\n\n  sprintf-js@1.0.3:\n    resolution: {integrity: sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==}\n\n  stack-utils@2.0.6:\n    resolution: {integrity: sha512-XlkWvfIm6RmsWtNJx+uqtKLS8eqFbxUg0ZzLXqY0caEy9l7hruX8IpiDnjsLavoBgqCCR71TqWO8MaXYheJ3RQ==}\n    engines: {node: '>=10'}\n\n  stackback@0.0.2:\n    resolution: {integrity: sha512-1XMJE5fQo1jGH6Y/7ebnwPOBEkIEnT4QF32d5R1+VXdXveM0IBMJt8zfaxX1P3QhVwrYe+576+jkANtSS2mBbw==}\n\n  standard-as-callback@2.1.0:\n    resolution: {integrity: sha512-qoRRSyROncaz1z0mvYqIE4lCd9p2R90i6GxW3uZv5ucSu8tU7B5HXUP1gG8pVZsYNVaXjk8ClXHPttLyxAL48A==}\n\n  statuses@2.0.1:\n    resolution: {integrity: sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==}\n    engines: {node: '>= 0.8'}\n\n  std-env@3.7.0:\n    resolution: {integrity: sha512-JPbdCEQLj1w5GilpiHAx3qJvFndqybBysA3qUOnznweH4QbNYUsW/ea8QzSrnh0vNsezMMw5bcVool8lM0gwzg==}\n\n  stop-iteration-iterator@1.0.0:\n    resolution: {integrity: sha512-iCGQj+0l0HOdZ2AEeBADlsRC+vsnDsZsbdSiH1yNSjcfKM7fdpCMfqAL/dwF5BLiw/XhRft/Wax6zQbhq2BcjQ==}\n    engines: {node: '>= 0.4'}\n\n  stream-browserify@3.0.0:\n    resolution: {integrity: sha512-H73RAHsVBapbim0tU2JwwOiXUj+fikfiaoYAKHF3VJfA0pe2BCzkhAHBlLG6REzE+2WNZcxOXjK7lkso+9euLA==}\n\n  stream-combiner@0.2.2:\n    resolution: {integrity: sha512-6yHMqgLYDzQDcAkL+tjJDC5nSNuNIx0vZtRZeiPh7Saef7VHX9H5Ijn9l2VIol2zaNYlYEX6KyuT/237A58qEQ==}\n\n  streamsearch@1.1.0:\n    resolution: {integrity: sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==}\n    engines: {node: '>=10.0.0'}\n\n  string-argv@0.3.2:\n    resolution: {integrity: sha512-aqD2Q0144Z+/RqG52NeHEkZauTAUWJO8c6yTftGJKO3Tja5tUgIfmIl6kExvhtxSDP7fXB6DvzkfMpCd/F3G+Q==}\n    engines: {node: '>=0.6.19'}\n\n  string-env-interpolation@1.0.1:\n    resolution: {integrity: sha512-78lwMoCcn0nNu8LszbP1UA7g55OeE4v7rCeWnM5B453rnNr4aq+5it3FEYtZrSEiMvHZOZ9Jlqb0OD0M2VInqg==}\n\n  string-length@4.0.2:\n    resolution: {integrity: sha512-+l6rNN5fYHNhZZy41RXsYptCjA2Igmq4EG7kZAYFQI1E1VTXarr6ZPXBg6eq7Y6eK4FEhY6AJlyuFIb/v/S0VQ==}\n    engines: {node: '>=10'}\n\n  string-width@4.2.3:\n    resolution: {integrity: sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==}\n    engines: {node: '>=8'}\n\n  string-width@5.1.2:\n    resolution: {integrity: sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==}\n    engines: {node: '>=12'}\n\n  string-width@7.2.0:\n    resolution: {integrity: sha512-tsaTIkKW9b4N+AEj+SVA+WhJzV7/zMhcSu78mLKWSk7cXMOSHsBKFWUs0fWwq8QyK3MgJBQRX6Gbi4kYbdvGkQ==}\n    engines: {node: '>=18'}\n\n  string.prototype.matchall@4.0.11:\n    resolution: {integrity: sha512-NUdh0aDavY2og7IbBPenWqR9exH+E26Sv8e0/eTe1tltDGZL+GtBkDAnnyBtmekfK6/Dq3MkcGtzXFEd1LQrtg==}\n    engines: {node: '>= 0.4'}\n\n  string.prototype.padend@3.1.6:\n    resolution: {integrity: sha512-XZpspuSB7vJWhvJc9DLSlrXl1mcA2BdoY5jjnS135ydXqLoqhs96JjDtCkjJEQHvfqZIp9hBuBMgI589peyx9Q==}\n    engines: {node: '>= 0.4'}\n\n  string.prototype.trim@1.2.9:\n    resolution: {integrity: sha512-klHuCNxiMZ8MlsOihJhJEBJAiMVqU3Z2nEXWfWnIqjN0gEFS9J9+IxKozWWtQGcgoa1WUZzLjKPTr4ZHNFTFxw==}\n    engines: {node: '>= 0.4'}\n\n  string.prototype.trimend@1.0.8:\n    resolution: {integrity: sha512-p73uL5VCHCO2BZZ6krwwQE3kCzM7NKmis8S//xEC6fQonchbum4eP6kR4DLEjQFO3Wnj3Fuo8NM0kOSjVdHjZQ==}\n\n  string.prototype.trimstart@1.0.8:\n    resolution: {integrity: sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==}\n    engines: {node: '>= 0.4'}\n\n  string_decoder@1.1.1:\n    resolution: {integrity: sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==}\n\n  string_decoder@1.3.0:\n    resolution: {integrity: sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==}\n\n  stringify-object@3.3.0:\n    resolution: {integrity: sha512-rHqiFh1elqCQ9WPLIC8I0Q/g/wj5J1eMkyoiD6eoQApWHP0FtlK7rqnhmabL5VUY9JQCcqwwvlOaSuutekgyrw==}\n    engines: {node: '>=4'}\n\n  strip-ansi@6.0.1:\n    resolution: {integrity: sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==}\n    engines: {node: '>=8'}\n\n  strip-ansi@7.1.0:\n    resolution: {integrity: sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==}\n    engines: {node: '>=12'}\n\n  strip-bom@3.0.0:\n    resolution: {integrity: sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==}\n    engines: {node: '>=4'}\n\n  strip-bom@4.0.0:\n    resolution: {integrity: sha512-3xurFv5tEgii33Zi8Jtp55wEIILR9eh34FAW00PZf+JnSsTmV/ioewSgQl97JHvgjoRGwPShsWm+IdrxB35d0w==}\n    engines: {node: '>=8'}\n\n  strip-comments@2.0.1:\n    resolution: {integrity: sha512-ZprKx+bBLXv067WTCALv8SSz5l2+XhpYCsVtSqlMnkAXMWDq+/ekVbl1ghqP9rUHTzv6sm/DwCOiYutU/yp1fw==}\n    engines: {node: '>=10'}\n\n  strip-eof@1.0.0:\n    resolution: {integrity: sha512-7FCwGGmx8mD5xQd3RPUvnSpUXHM3BWuzjtpD4TXsfcZ9EL4azvVVUscFYwD9nx8Kh+uCBC00XBtAykoMHwTh8Q==}\n    engines: {node: '>=0.10.0'}\n\n  strip-final-newline@2.0.0:\n    resolution: {integrity: sha512-BrpvfNAE3dcvq7ll3xVumzjKjZQ5tI1sEUIKr3Uoks0XUl45St3FlatVqef9prk4jRDzhW6WZg+3bk93y6pLjA==}\n    engines: {node: '>=6'}\n\n  strip-final-newline@3.0.0:\n    resolution: {integrity: sha512-dOESqjYr96iWYylGObzd39EuNTa5VJxyvVAEm5Jnh7KGo75V43Hk1odPQkNDyXNmUR6k+gEiDVXnjB8HJ3crXw==}\n    engines: {node: '>=12'}\n\n  strip-json-comments@2.0.1:\n    resolution: {integrity: sha512-4gB8na07fecVVkOI6Rs4e7T6NOTki5EmL7TUduTs6bu3EdnSycntVJ4re8kgZA+wx9IueI2Y11bfbgwtzuE0KQ==}\n    engines: {node: '>=0.10.0'}\n\n  strip-json-comments@3.1.1:\n    resolution: {integrity: sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==}\n    engines: {node: '>=8'}\n\n  style-mod@4.1.2:\n    resolution: {integrity: sha512-wnD1HyVqpJUI2+eKZ+eo1UwghftP6yuFheBqqe+bWCotBjC2K1YnteJILRMs3SM4V/0dLEW1SC27MWP5y+mwmw==}\n\n  stylehacks@7.0.4:\n    resolution: {integrity: sha512-i4zfNrGMt9SB4xRK9L83rlsFCgdGANfeDAYacO1pkqcE7cRHPdWHwnKZVz7WY17Veq/FvyYsRAU++Ga+qDFIww==}\n    engines: {node: ^18.12.0 || ^20.9.0 || >=22.0}\n    peerDependencies:\n      postcss: ^8.4.31\n\n  subscriptions-transport-ws@0.11.0:\n    resolution: {integrity: sha512-8D4C6DIH5tGiAIpp5I0wD/xRlNiZAPGHygzCe7VzyzUoxHtawzjNAY9SUTXU05/EY2NMY9/9GF0ycizkXr1CWQ==}\n    deprecated: The `subscriptions-transport-ws` package is no longer maintained. We recommend you use `graphql-ws` instead. For help migrating Apollo software to `graphql-ws`, see https://www.apollographql.com/docs/apollo-server/data/subscriptions/#switching-from-subscriptions-transport-ws    For general help using `graphql-ws`, see https://github.com/enisdenjo/graphql-ws/blob/master/README.md\n    peerDependencies:\n      graphql: ^15.7.2 || ^16.0.0\n\n  sucrase@3.35.0:\n    resolution: {integrity: sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==}\n    engines: {node: '>=16 || 14 >=14.17'}\n    hasBin: true\n\n  superagent@9.0.2:\n    resolution: {integrity: sha512-xuW7dzkUpcJq7QnhOsnNUgtYp3xRwpt2F7abdRYIpCsAt0hhUqia0EdxyXZQQpNmGtsCzYHryaKSV3q3GJnq7w==}\n    engines: {node: '>=14.18.0'}\n\n  supertest@7.0.0:\n    resolution: {integrity: sha512-qlsr7fIC0lSddmA3tzojvzubYxvlGtzumcdHgPwbFWMISQwL22MhM2Y3LNt+6w9Yyx7559VW5ab70dgphm8qQA==}\n    engines: {node: '>=14.18.0'}\n\n  supports-color@5.5.0:\n    resolution: {integrity: sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==}\n    engines: {node: '>=4'}\n\n  supports-color@7.2.0:\n    resolution: {integrity: sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==}\n    engines: {node: '>=8'}\n\n  supports-color@8.1.1:\n    resolution: {integrity: sha512-MpUEN2OodtUzxvKQl72cUF7RQ5EiHsGvSsVG0ia9c5RbWGL2CI4C7EpPS8UTBIplnlzZiNuV56w+FuNxy3ty2Q==}\n    engines: {node: '>=10'}\n\n  supports-preserve-symlinks-flag@1.0.0:\n    resolution: {integrity: sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==}\n    engines: {node: '>= 0.4'}\n\n  svgo@3.3.2:\n    resolution: {integrity: sha512-OoohrmuUlBs8B8o6MB2Aevn+pRIH9zDALSR+6hhqVfa6fRwG/Qw9VUMSMW9VNg2CFc/MTIfabtdOVl9ODIJjpw==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  swagger-methods@2.0.2:\n    resolution: {integrity: sha512-/RNqvBZkH8+3S/FqBPejHxJxZenaYq3MrpeXnzi06aDIS39Mqf5YCUNb/ZBjsvFFt8h9FxfKs8EXPtcYdfLiRg==}\n    deprecated: This package is no longer being maintained.\n\n  swagger-parser@8.0.3:\n    resolution: {integrity: sha512-y2gw+rTjn7Z9J+J1qwbBm0UL93k/VREDCveKBK6iGjf7KXC6QGshbnpEmeHL0ZkCgmIghsXzpNzPSbBH91BAEQ==}\n\n  swagger-ui-dist@5.17.14:\n    resolution: {integrity: sha512-CVbSfaLpstV65OnSjbXfVd6Sta3q3F7Cj/yYuvHMp1P90LztOLs6PfUnKEVAeiIVQt9u2SaPwv0LiH/OyMjHRw==}\n\n  swap-case@2.0.2:\n    resolution: {integrity: sha512-kc6S2YS/2yXbtkSMunBtKdah4VFETZ8Oh6ONSmSd9bRxhqTrtARUCBUiWXH3xVPpvR7tz2CSnkuXVE42EcGnMw==}\n\n  symbol-observable@1.2.0:\n    resolution: {integrity: sha512-e900nM8RRtGhlV36KGEU9k65K3mPb1WV70OdjfxlG2EAuM1noi/E/BaW/uMhL7bPEssK8QV57vN3esixjUvcXQ==}\n    engines: {node: '>=0.10.0'}\n\n  symbol-observable@4.0.0:\n    resolution: {integrity: sha512-b19dMThMV4HVFynSAM1++gBHAbk2Tc/osgLIBZMKsyqh34jb2e8Os7T6ZW/Bt3pJFdBTd2JwAnAAEQV7rSNvcQ==}\n    engines: {node: '>=0.10'}\n\n  symbol-tree@3.2.4:\n    resolution: {integrity: sha512-9QNk5KwDF+Bvz+PyObkmSYjI5ksVUYtjW7AU22r2NKcfLJcXp96hkDWU3+XndOsUb+AQ9QhfzfCT2O+CNWT5Tw==}\n\n  synckit@0.9.2:\n    resolution: {integrity: sha512-vrozgXDQwYO72vHjUb/HnFbQx1exDjoKzqx23aXEg2a9VIg2TSFZ8FmeZpTjUCFMYw7mpX4BE2SFu8wI7asYsw==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n\n  systemjs@6.15.1:\n    resolution: {integrity: sha512-Nk8c4lXvMB98MtbmjX7JwJRgJOL8fluecYCfCeYBznwmpOs8Bf15hLM6z4z71EDAhQVrQrI+wt1aLWSXZq+hXA==}\n\n  tailwindcss@3.3.6:\n    resolution: {integrity: sha512-AKjF7qbbLvLaPieoKeTjG1+FyNZT6KaJMJPFeQyLfIp7l82ggH1fbHJSsYIvnbTFQOlkh+gBYpyby5GT1LIdLw==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  tailwindcss@3.4.13:\n    resolution: {integrity: sha512-KqjHOJKogOUt5Bs752ykCeiwvi0fKVkr5oqsFNt/8px/tA8scFPIlkygsf6jXrfCqGHz7VflA6+yytWuM+XhFw==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  tailwindcss@3.4.14:\n    resolution: {integrity: sha512-IcSvOcTRcUtQQ7ILQL5quRDg7Xs93PdJEk1ZLbhhvJc7uj/OAhYOnruEiwnGgBvUtaUAJ8/mhSw1o8L2jCiENA==}\n    engines: {node: '>=14.0.0'}\n    hasBin: true\n\n  tapable@0.2.9:\n    resolution: {integrity: sha512-2wsvQ+4GwBvLPLWsNfLCDYGsW6xb7aeC6utq2Qh0PFwgEy7K7dsma9Jsmb2zSQj7GvYAyUGSntLtsv++GmgL1A==}\n    engines: {node: '>=0.6'}\n\n  tapable@2.2.1:\n    resolution: {integrity: sha512-GNzQvQTOIP6RyTfE2Qxb8ZVlNmw0n88vp1szwWRimP02mnTsx3Wtn5qRdqY9w2XduFNUgvOwhNnQsjwCp+kqaQ==}\n    engines: {node: '>=6'}\n\n  tar-fs@2.1.1:\n    resolution: {integrity: sha512-V0r2Y9scmbDRLCNex/+hYzvp/zyYjvFbHPNgVTKfQvVrb6guiE/fxP+XblDNR011utopbkex2nM4dHNV6GDsng==}\n\n  tar-stream@2.2.0:\n    resolution: {integrity: sha512-ujeqbceABgwMZxEJnk2HDY2DlnUZ+9oEcb1KzTVfYHio0UE6dG71n60d8D2I4qNvleWrrXpmjpt7vZeF1LnMZQ==}\n    engines: {node: '>=6'}\n\n  tar@6.2.1:\n    resolution: {integrity: sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==}\n    engines: {node: '>=10'}\n\n  tauri-plugin-store-api@0.0.0:\n    resolution: {integrity: sha512-OycAs/ElRxqMh8nATuBE8hJBPjJaeZ8o52N+X4lRxKV6VRrHZ9dRMCDBvEST5Sa1Gxk4kwUPHkBHsmXOL/kt0w==}\n\n  temp-dir@2.0.0:\n    resolution: {integrity: sha512-aoBAniQmmwtcKp/7BzsH8Cxzv8OL736p7v1ihGb5e9DJ9kTwGWHrQrVB5+lfVDzfGrdRzXch+ig7LHaY1JTOrg==}\n    engines: {node: '>=8'}\n\n  tempy@0.6.0:\n    resolution: {integrity: sha512-G13vtMYPT/J8A4X2SjdtBTphZlrp1gKv6hZiOjw14RCWg6GbHuQBGtjlx75xLbYV/wEc0D7G5K4rxKP/cXk8Bw==}\n    engines: {node: '>=10'}\n\n  tern@0.24.3:\n    resolution: {integrity: sha512-Z8uvtdWIlFn1GWy0HW5FhZ8VDryZwoJUdnjZU25C7/PBOltLIn1uv+WF3rVq6S1761YbsmbZYRP/l0ZJBCkvrw==}\n    hasBin: true\n\n  terser-webpack-plugin@5.3.10:\n    resolution: {integrity: sha512-BKFPWlPDndPs+NGGCr1U59t0XScL5317Y0UReNrHaw9/FwhPENlq6bfgs+4yPfyP51vqC1bQ4rp1EfXW5ZSH9w==}\n    engines: {node: '>= 10.13.0'}\n    peerDependencies:\n      '@swc/core': '*'\n      esbuild: '*'\n      uglify-js: '*'\n      webpack: ^5.1.0\n    peerDependenciesMeta:\n      '@swc/core':\n        optional: true\n      esbuild:\n        optional: true\n      uglify-js:\n        optional: true\n\n  terser@5.34.1:\n    resolution: {integrity: sha512-FsJZ7iZLd/BXkz+4xrRTGJ26o/6VTjQytUk8b8OxkwcD2I+79VPJlz7qss1+zE7h8GNIScFqXcDyJ/KqBYZFVA==}\n    engines: {node: '>=10'}\n    hasBin: true\n\n  test-exclude@6.0.0:\n    resolution: {integrity: sha512-cAGWPIyOHU6zlmg88jwm7VRyXnMN7iV68OGAbYDk/Mh/xC/pzVPlQtY6ngoIH/5/tciuhGfvESU8GrHrcxD56w==}\n    engines: {node: '>=8'}\n\n  text-extensions@2.4.0:\n    resolution: {integrity: sha512-te/NtwBwfiNRLf9Ijqx3T0nlqZiQ2XrrtBvu+cLL8ZRrGkO0NHTug8MYFKyoSrv/sHTaSKfilUkizV6XhxMJ3g==}\n    engines: {node: '>=8'}\n\n  text-table@0.2.0:\n    resolution: {integrity: sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==}\n\n  thenify-all@1.6.0:\n    resolution: {integrity: sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==}\n    engines: {node: '>=0.8'}\n\n  thenify@3.3.1:\n    resolution: {integrity: sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==}\n\n  through@2.3.8:\n    resolution: {integrity: sha512-w89qg7PI8wAdvX60bMDP+bFoD5Dvhm9oLheFp5O4a2QF0cSBGsBX4qZmadPMvVqlLJBBci+WqGGOAPvcDeNSVg==}\n\n  timers@0.1.1:\n    resolution: {integrity: sha512-pkJC8uIP/gxDHxNQUBUbjHyl6oZfT+ofn7tbaHW+CFIUjI+Q2MBbHcx1JSBQfhDaTcO9bNg328q0i7Vk5PismQ==}\n\n  timsort@0.3.0:\n    resolution: {integrity: sha512-qsdtZH+vMoCARQtyod4imc2nIJwg9Cc7lPRrw9CzF8ZKR0khdr8+2nX80PBhET3tcyTtJDxAffGh2rXH4tyU8A==}\n\n  tiny-inflate@1.0.3:\n    resolution: {integrity: sha512-pkY1fj1cKHb2seWDy0B16HeWyczlJA9/WW3u3c4z/NiWDsO3DOU5D7nhTLE9CF0yXv/QZFY7sEJmj24dK+Rrqw==}\n\n  tiny-invariant@1.3.3:\n    resolution: {integrity: sha512-+FbBPE1o9QAYvviau/qC5SE3caw21q3xkvWKBtja5vgqOWIHHJ3ioaq1VPfn/Szqctz2bU/oYeKd9/z5BL+PVg==}\n\n  tinybench@2.9.0:\n    resolution: {integrity: sha512-0+DUvqWMValLmha6lr4kD8iAMK1HzV0/aKnCtWb9v9641TnP/MFb7Pc2bxoxQjTXAErryXVgUOfv2YqNllqGeg==}\n\n  tinyexec@0.3.0:\n    resolution: {integrity: sha512-tVGE0mVJPGb0chKhqmsoosjsS+qUnJVGJpZgsHYQcGoPlG3B51R3PouqTgEGH2Dc9jjFyOqOpix6ZHNMXp1FZg==}\n\n  tinyglobby@0.2.9:\n    resolution: {integrity: sha512-8or1+BGEdk1Zkkw2ii16qSS7uVrQJPre5A9o/XkWPATkk23FZh/15BKFxPnlTy6vkljZxLqYCzzBMj30ZrSvjw==}\n    engines: {node: '>=12.0.0'}\n\n  tinypool@1.0.1:\n    resolution: {integrity: sha512-URZYihUbRPcGv95En+sz6MfghfIc2OJ1sv/RmhWZLouPY0/8Vo80viwPvg3dlaS9fuq7fQMEfgRRK7BBZThBEA==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n\n  tinyrainbow@1.2.0:\n    resolution: {integrity: sha512-weEDEq7Z5eTHPDh4xjX789+fHfF+P8boiFB+0vbWzpbnbsEr/GRaohi/uMKxg8RZMXnl1ItAi/IUHWMsjDV7kQ==}\n    engines: {node: '>=14.0.0'}\n\n  tinyspy@3.0.2:\n    resolution: {integrity: sha512-n1cw8k1k0x4pgA2+9XrOkFydTerNcJ1zWCO5Nn9scWHTD+5tp8dghT2x1uduQePZTZgd3Tupf+x9BxJjeJi77Q==}\n    engines: {node: '>=14.0.0'}\n\n  tippy.js@6.3.7:\n    resolution: {integrity: sha512-E1d3oP2emgJ9dRQZdf3Kkn0qJgI6ZLpyS5z6ZkY1DF3kaQaBsGZsndEpHwx+eC+tYM41HaSNvNtLx8tU57FzTQ==}\n\n  title-case@3.0.3:\n    resolution: {integrity: sha512-e1zGYRvbffpcHIrnuqT0Dh+gEJtDaxDSoG4JAIpq4oDFyooziLBIiYQv0GBT4FUAnUop5uZ1hiIAj7oAF6sOCA==}\n\n  titleize@3.0.0:\n    resolution: {integrity: sha512-KxVu8EYHDPBdUYdKZdKtU2aj2XfEx9AfjXxE/Aj0vT06w2icA09Vus1rh6eSu1y01akYg6BjIK/hxyLJINoMLQ==}\n    engines: {node: '>=12'}\n\n  tlds@1.252.0:\n    resolution: {integrity: sha512-GA16+8HXvqtfEnw/DTcwB0UU354QE1n3+wh08oFjr6Znl7ZLAeUgYzCcK+/CCrOyE0vnHR8/pu3XXG3vDijXpQ==}\n    hasBin: true\n\n  tldts-core@6.1.54:\n    resolution: {integrity: sha512-5cc42+0G0EjYRDfIJHKraaT3I5kPm7j6or3Zh1T9sF+Ftj1T+isT4thicUyQQ1bwN7/xjHQIuY2fXCoXP8Haqg==}\n\n  tldts@6.1.54:\n    resolution: {integrity: sha512-rDaL1t59gb/Lg0HPMUGdV1vAKLQcXwU74D26aMaYV4QW7mnMvShd1Vmkg3HYAPWx2JCTUmsrXt/Yl9eJ5UFBQw==}\n    hasBin: true\n\n  tmp@0.0.33:\n    resolution: {integrity: sha512-jRCJlojKnZ3addtTOjdIqoRuPEKBvNXcGYqzO6zWZX8KfKEpnGY5jfggJQ3EjKuu8D4bJRr0y+cYJFmYbImXGw==}\n    engines: {node: '>=0.6.0'}\n\n  tmpl@1.0.5:\n    resolution: {integrity: sha512-3f0uOEAQwIqGuWW2MVzYg8fV/QNnc/IpuJNG837rLuczAaLVHslWHZQj4IGiEl5Hs3kkbhwL9Ab7Hrsmuj+Smw==}\n\n  to-array@0.1.4:\n    resolution: {integrity: sha512-LhVdShQD/4Mk4zXNroIQZJC+Ap3zgLcDuwEdcmLv9CCO73NWockQDwyUnW/m8VX/EElfL6FcYx7EeutN4HJA6A==}\n\n  to-fast-properties@2.0.0:\n    resolution: {integrity: sha512-/OaKK0xYrs3DmxRYqL/yDc+FxFUVYhDlXMhRmv3z915w2HF1tnN1omB354j8VUGO/hbRzyD6Y3sA7v7GS/ceog==}\n    engines: {node: '>=4'}\n\n  to-regex-range@5.0.1:\n    resolution: {integrity: sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==}\n    engines: {node: '>=8.0'}\n\n  toidentifier@1.0.1:\n    resolution: {integrity: sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==}\n    engines: {node: '>=0.6'}\n\n  token-stream@1.0.0:\n    resolution: {integrity: sha512-VSsyNPPW74RpHwR8Fc21uubwHY7wMDeJLys2IX5zJNih+OnAnaifKHo+1LHT7DAdloQ7apeaaWg8l7qnf/TnEg==}\n\n  totalist@3.0.1:\n    resolution: {integrity: sha512-sf4i37nQ2LBx4m3wB74y+ubopq6W/dIzXg0FDGjsYnZHVa1Da8FH853wlL2gtUhg+xJXjfk3kUZS3BRoQeoQBQ==}\n    engines: {node: '>=6'}\n\n  tough-cookie@5.0.0:\n    resolution: {integrity: sha512-FRKsF7cz96xIIeMZ82ehjC3xW2E+O2+v11udrDYewUbszngYhsGa8z6YUMMzO9QJZzzyd0nGGXnML/TReX6W8Q==}\n    engines: {node: '>=16'}\n\n  tr46@0.0.3:\n    resolution: {integrity: sha512-N3WMsuqV66lT30CrXNbEjx4GEwlow3v6rr4mCcv6prnfwhS01rkgyFdjPNBYd9br7LpXV1+Emh01fHnq2Gdgrw==}\n\n  tr46@1.0.1:\n    resolution: {integrity: sha512-dTpowEjclQ7Kgx5SdBkqRzVhERQXov8/l9Ft9dVM9fmg0W0KQSVaXX9T4i6twCPNtYiZM53lpSSUAwJbFPOHxA==}\n\n  tr46@5.0.0:\n    resolution: {integrity: sha512-tk2G5R2KRwBd+ZN0zaEXpmzdKyOYksXwywulIX95MBODjSzMIuQnQ3m8JxgbhnL1LeVo7lqQKsYa1O3Htl7K5g==}\n    engines: {node: '>=18'}\n\n  tree-kill@1.2.2:\n    resolution: {integrity: sha512-L0Orpi8qGpRG//Nd+H90vFB+3iHnue1zSSGmNOOCh1GLJ7rUKVwV2HvijphGQS2UmhUZewS9VgvxYIdgr+fG1A==}\n    hasBin: true\n\n  ts-api-utils@1.3.0:\n    resolution: {integrity: sha512-UQMIo7pb8WRomKR1/+MFVLTroIvDVtMX3K6OUir8ynLyzB8Jeriont2bTAtmNPa1ekAgN7YPDyf6V+ygrdU+eQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      typescript: '>=4.2.0'\n\n  ts-essentials@10.0.2:\n    resolution: {integrity: sha512-Xwag0TULqriaugXqVdDiGZ5wuZpqABZlpwQ2Ho4GDyiu/R2Xjkp/9+zcFxL7uzeLl/QCPrflnvpVYyS3ouT7Zw==}\n    peerDependencies:\n      typescript: '>=4.5.0'\n    peerDependenciesMeta:\n      typescript:\n        optional: true\n\n  ts-interface-checker@0.1.13:\n    resolution: {integrity: sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==}\n\n  ts-jest@29.2.5:\n    resolution: {integrity: sha512-KD8zB2aAZrcKIdGk4OwpJggeLcH1FgrICqDSROWqlnJXGCXK4Mn6FcdK2B6670Xr73lHMG1kHw8R87A0ecZ+vA==}\n    engines: {node: ^14.15.0 || ^16.10.0 || ^18.0.0 || >=20.0.0}\n    hasBin: true\n    peerDependencies:\n      '@babel/core': '>=7.0.0-beta.0 <8'\n      '@jest/transform': ^29.0.0\n      '@jest/types': ^29.0.0\n      babel-jest: ^29.0.0\n      esbuild: '*'\n      jest: ^29.0.0\n      typescript: '>=4.3 <6'\n    peerDependenciesMeta:\n      '@babel/core':\n        optional: true\n      '@jest/transform':\n        optional: true\n      '@jest/types':\n        optional: true\n      babel-jest:\n        optional: true\n      esbuild:\n        optional: true\n\n  ts-loader@9.5.1:\n    resolution: {integrity: sha512-rNH3sK9kGZcH9dYzC7CewQm4NtxJTjSEVRJ2DyBZR7f8/wcta+iV44UPCXc5+nzDzivKtlzV6c9P4e+oFhDLYg==}\n    engines: {node: '>=12.0.0'}\n    peerDependencies:\n      typescript: '*'\n      webpack: ^5.0.0\n\n  ts-log@2.2.5:\n    resolution: {integrity: sha512-PGcnJoTBnVGy6yYNFxWVNkdcAuAMstvutN9MgDJIV6L0oG8fB+ZNNy1T+wJzah8RPGor1mZuPQkVfXNDpy9eHA==}\n\n  ts-node-dev@2.0.0:\n    resolution: {integrity: sha512-ywMrhCfH6M75yftYvrvNarLEY+SUXtUvU8/0Z6llrHQVBx12GiFk5sStF8UdfE/yfzk9IAq7O5EEbTQsxlBI8w==}\n    engines: {node: '>=0.8.0'}\n    hasBin: true\n    peerDependencies:\n      node-notifier: '*'\n      typescript: '*'\n    peerDependenciesMeta:\n      node-notifier:\n        optional: true\n\n  ts-node@10.9.2:\n    resolution: {integrity: sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==}\n    hasBin: true\n    peerDependencies:\n      '@swc/core': '>=1.2.50'\n      '@swc/wasm': '>=1.2.50'\n      '@types/node': '*'\n      typescript: '>=2.7'\n    peerDependenciesMeta:\n      '@swc/core':\n        optional: true\n      '@swc/wasm':\n        optional: true\n\n  ts-toolbelt@6.15.5:\n    resolution: {integrity: sha512-FZIXf1ksVyLcfr7M317jbB67XFJhOO1YqdTcuGaq9q5jLUoTikukZ+98TPjKiP2jC5CgmYdWWYs0s2nLSU0/1A==}\n\n  tsconfig-paths-webpack-plugin@4.1.0:\n    resolution: {integrity: sha512-xWFISjviPydmtmgeUAuXp4N1fky+VCtfhOkDUFIv5ea7p4wuTomI4QTrXvFBX2S4jZsmyTSrStQl+E+4w+RzxA==}\n    engines: {node: '>=10.13.0'}\n\n  tsconfig-paths@4.2.0:\n    resolution: {integrity: sha512-NoZ4roiN7LnbKn9QqE1amc9DJfzvZXxF4xDavcOWt1BPkdx+m+0gJuPM+S0vCe7zTJMYUP0R8pO2XMr+Y8oLIg==}\n    engines: {node: '>=6'}\n\n  tsconfig@7.0.0:\n    resolution: {integrity: sha512-vZXmzPrL+EmC4T/4rVlT2jNVMWCi/O4DIiSj3UHg1OE5kCKbk4mfrXc6dZksLgRM/TZlKnousKH9bbTazUWRRw==}\n\n  tslib@1.14.1:\n    resolution: {integrity: sha512-Xni35NKzjgMrwevysHTCArtLDpPvye8zV/0E4EyYn43P7/7qvQwPh9BGkHewbMulVntbigmcT7rdX3BNo9wRJg==}\n\n  tslib@2.4.1:\n    resolution: {integrity: sha512-tGyy4dAjRIEwI7BzsB0lynWgOpfqjUdq91XXAlIWD2OwKBH7oCl/GZG/HT4BOHrTlPMOASlMQ7veyTqpmRcrNA==}\n\n  tslib@2.5.3:\n    resolution: {integrity: sha512-mSxlJJwl3BMEQCUNnxXBU9jP4JBktcEGhURcPR6VQVlnP0FdDEsIaz0C35dXNGLyRfrATNofF0F5p2KPxQgB+w==}\n\n  tslib@2.6.2:\n    resolution: {integrity: sha512-AEYxH93jGFPn/a2iVAwW87VuUIkR1FVUKB77NwMF7nBTDkDrrT/Hpt/IrCJ0QXhW27jTBDcf5ZY7w6RiqTMw2Q==}\n\n  tslib@2.6.3:\n    resolution: {integrity: sha512-xNvxJEOUiWPGhUuUdQgAJPKOOJfGnIyKySOc09XkKsgdUV/3E2zvwZYdejjmRgPCgcym1juLH3226yA7sEFJKQ==}\n\n  tslib@2.7.0:\n    resolution: {integrity: sha512-gLXCKdN1/j47AiHiOkJN69hJmcbGTHI0ImLmbYLHykhgeN0jVGola9yVjFgzCUklsZQMW55o+dW7IXv3RCXDzA==}\n\n  tslib@2.8.0:\n    resolution: {integrity: sha512-jWVzBLplnCmoaTr13V9dYbiQ99wvZRd0vNWaDRg+aVYRcjDF3nDksxFDE/+fkXnKhpnUUkmx5pK/v8mCtLVqZA==}\n\n  tsup@8.3.0:\n    resolution: {integrity: sha512-ALscEeyS03IomcuNdFdc0YWGVIkwH1Ws7nfTbAPuoILvEV2hpGQAY72LIOjglGo4ShWpZfpBqP/jpQVCzqYQag==}\n    engines: {node: '>=18'}\n    hasBin: true\n    peerDependencies:\n      '@microsoft/api-extractor': ^7.36.0\n      '@swc/core': ^1\n      postcss: ^8.4.12\n      typescript: '>=4.5.0'\n    peerDependenciesMeta:\n      '@microsoft/api-extractor':\n        optional: true\n      '@swc/core':\n        optional: true\n      postcss:\n        optional: true\n      typescript:\n        optional: true\n\n  tsutils@3.21.0:\n    resolution: {integrity: sha512-mHKK3iUXL+3UF6xL5k0PEhKRUBKPBCv/+RkEOpjRWxxx27KKRBmmA60A9pgOUvMi8GKhRMPEmjBRPzs2W7O1OA==}\n    engines: {node: '>= 6'}\n    peerDependencies:\n      typescript: '>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev || >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta'\n\n  tunnel-agent@0.6.0:\n    resolution: {integrity: sha512-McnNiV1l8RYeY8tBgEpuodCC1mLUdbSN+CYBL7kJsJNInOP8UjDDEwdk6Mw60vdLLrr5NHKZhMAOSrR2NZuQ+w==}\n\n  type-check@0.4.0:\n    resolution: {integrity: sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==}\n    engines: {node: '>= 0.8.0'}\n\n  type-detect@4.0.8:\n    resolution: {integrity: sha512-0fr/mIH1dlO+x7TlcMy+bIDqKPsw/70tVyeHW787goQjhmqaZe10uwLujubK9q9Lg6Fiho1KUKDYz0Z7k7g5/g==}\n    engines: {node: '>=4'}\n\n  type-fest@0.16.0:\n    resolution: {integrity: sha512-eaBzG6MxNzEn9kiwvtre90cXaNLkmadMWa1zQMs3XORCXNbsH/OewwbxC5ia9dCxIxnTAsSxXJaa/p5y8DlvJg==}\n    engines: {node: '>=10'}\n\n  type-fest@0.20.2:\n    resolution: {integrity: sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==}\n    engines: {node: '>=10'}\n\n  type-fest@0.21.3:\n    resolution: {integrity: sha512-t0rzBq87m3fVcduHDUFhKmyyX+9eo6WQjZvf51Ea/M0Q7+T374Jp1aUiyUl0GKxp8M/OETVHSDvmkyPgvX+X2w==}\n    engines: {node: '>=10'}\n\n  type-is@1.6.18:\n    resolution: {integrity: sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==}\n    engines: {node: '>= 0.6'}\n\n  typed-array-buffer@1.0.2:\n    resolution: {integrity: sha512-gEymJYKZtKXzzBzM4jqa9w6Q1Jjm7x2d+sh19AdsD4wqnMPDYyvwpsIc2Q/835kHuo3BEQ7CjelGhfTsoBb2MQ==}\n    engines: {node: '>= 0.4'}\n\n  typed-array-byte-length@1.0.1:\n    resolution: {integrity: sha512-3iMJ9q0ao7WE9tWcaYKIptkNBuOIcZCCT0d4MRvuuH88fEoEH62IuQe0OtraD3ebQEoTRk8XCBoknUNc1Y67pw==}\n    engines: {node: '>= 0.4'}\n\n  typed-array-byte-offset@1.0.2:\n    resolution: {integrity: sha512-Ous0vodHa56FviZucS2E63zkgtgrACj7omjwd/8lTEMEPFFyjfixMZ1ZXenpgCFBBt4EC1J2XsyVS2gkG0eTFA==}\n    engines: {node: '>= 0.4'}\n\n  typed-array-length@1.0.6:\n    resolution: {integrity: sha512-/OxDN6OtAk5KBpGb28T+HZc2M+ADtvRxXrKKbUwtsLgdoxgX13hyy7ek6bFRl5+aBs2yZzB0c4CnQfAtVypW/g==}\n    engines: {node: '>= 0.4'}\n\n  typedarray@0.0.6:\n    resolution: {integrity: sha512-/aCDEGatGvZ2BIk+HmLf4ifCJFwvKFNb9/JeZPMulfgFracn9QFcAf5GO8B/mweUjSoblS5In0cWhqpfs/5PQA==}\n\n  typescript@4.9.5:\n    resolution: {integrity: sha512-1FXk9E2Hm+QzZQ7z+McJiHL4NW1F2EzMu9Nq9i3zAaGqibafqYwCVU6WyWAuyQRRzOlxou8xZSyXLEN8oKj24g==}\n    engines: {node: '>=4.2.0'}\n    hasBin: true\n\n  typescript@5.2.2:\n    resolution: {integrity: sha512-mI4WrpHsbCIcwT9cF4FZvr80QUeKvsUsUvKDoR+X/7XHQH98xYD8YHZg7ANtz2GtZt/CBq2QJ0thkGJMHfqc1w==}\n    engines: {node: '>=14.17'}\n    hasBin: true\n\n  typescript@5.3.3:\n    resolution: {integrity: sha512-pXWcraxM0uxAS+tN0AG/BF2TyqmHO014Z070UsJ+pFvYuRSq8KH8DmWpnbXe0pEPDHXZV3FcAbJkijJ5oNEnWw==}\n    engines: {node: '>=14.17'}\n    hasBin: true\n\n  typescript@5.5.4:\n    resolution: {integrity: sha512-Mtq29sKDAEYP7aljRgtPOpTvOfbwRWlS6dPRzwjdE+C0R4brX/GUyhHSecbHMFLNBLcJIPt9nl9yG5TZ1weH+Q==}\n    engines: {node: '>=14.17'}\n    hasBin: true\n\n  typescript@5.6.3:\n    resolution: {integrity: sha512-hjcS1mhfuyi4WW8IWtjP7brDrG2cuDZukyrYrSauoXGNgx0S7zceP07adYkJycEr56BOUTNPzbInooiN3fn1qw==}\n    engines: {node: '>=14.17'}\n    hasBin: true\n\n  ua-parser-js@1.0.39:\n    resolution: {integrity: sha512-k24RCVWlEcjkdOxYmVJgeD/0a1TiSpqLg+ZalVGV9lsnr4yqu0w7tX/x2xX6G4zpkgQnRf89lxuZ1wsbjXM8lw==}\n    hasBin: true\n\n  uc.micro@2.1.0:\n    resolution: {integrity: sha512-ARDJmphmdvUk6Glw7y9DQ2bFkKBHwQHLi2lsaH6PPmz/Ka9sFOBsBluozhDltWmnv9u/cF6Rt87znRTPV+yp/A==}\n\n  ufo@1.5.4:\n    resolution: {integrity: sha512-UsUk3byDzKd04EyoZ7U4DOlxQaD14JUKQl6/P7wiX4FNvUfm3XL246n9W5AmqwW5RSFJ27NAuM0iLscAOYUiGQ==}\n\n  uglify-js@3.19.3:\n    resolution: {integrity: sha512-v3Xu+yuwBXisp6QYTcH4UbH+xYJXqnq2m/LtQVWKWzYc1iehYnLixoQDN9FH6/j9/oybfd6W9Ghwkl8+UMKTKQ==}\n    engines: {node: '>=0.8.0'}\n    hasBin: true\n\n  uid-safe@2.1.5:\n    resolution: {integrity: sha512-KPHm4VL5dDXKz01UuEd88Df+KzynaohSL9fBh096KWAxSKZQDI2uBrVqtvRM4rwrIrRRKsdLNML/lnaaVSRioA==}\n    engines: {node: '>= 0.8'}\n\n  uid2@0.0.4:\n    resolution: {integrity: sha512-IevTus0SbGwQzYh3+fRsAMTVVPOoIVufzacXcHPmdlle1jUpq7BRL+mw3dgeLanvGZdwwbWhRV6XrcFNdBmjWA==}\n\n  uid@2.0.2:\n    resolution: {integrity: sha512-u3xV3X7uzvi5b1MncmZo3i2Aw222Zk1keqLA1YkHldREkAhAqi65wuPfe7lHx8H/Wzy+8CE7S7uS3jekIM5s8g==}\n    engines: {node: '>=8'}\n\n  unbox-primitive@1.0.2:\n    resolution: {integrity: sha512-61pPlCD9h51VoreyJ0BReideM3MDKMKnh6+V9L08331ipq6Q8OFXZYiqP6n/tbHx4s5I9uRhcye6BrbkizkBDw==}\n\n  unc-path-regex@0.1.2:\n    resolution: {integrity: sha512-eXL4nmJT7oCpkZsHZUOJo8hcX3GbsiDOa0Qu9F646fi8dT3XuSVopVqAcEiVzSKKH7UoDti23wNX3qGFxcW5Qg==}\n    engines: {node: '>=0.10.0'}\n\n  undici-types@5.26.5:\n    resolution: {integrity: sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==}\n\n  undici-types@6.19.8:\n    resolution: {integrity: sha512-ve2KP6f/JnbPBFyobGHuerC9g1FYGn/F8n1LWTwNxCEzd6IfqTwUQcNXgEtmmQ6DlRrC1hrSrBnCZPokRrDHjw==}\n\n  unhead@1.11.10:\n    resolution: {integrity: sha512-hypXrAI47wE3wIhkze0RMPGAWcoo45Q1+XzdqLD/OnTCzjFXQrpuE4zBy8JRexyrqp+Ud2+nFTUNf/mjfFSymw==}\n\n  unicode-canonical-property-names-ecmascript@2.0.1:\n    resolution: {integrity: sha512-dA8WbNeb2a6oQzAQ55YlT5vQAWGV9WXOsi3SskE3bcCdM0P4SDd+24zS/OCacdRq5BkdsRj9q3Pg6YyQoxIGqg==}\n    engines: {node: '>=4'}\n\n  unicode-match-property-ecmascript@2.0.0:\n    resolution: {integrity: sha512-5kaZCrbp5mmbz5ulBkDkbY0SsPOjKqVS35VpL9ulMPfSl0J0Xsm+9Evphv9CoIZFwre7aJoa94AY6seMKGVN5Q==}\n    engines: {node: '>=4'}\n\n  unicode-match-property-value-ecmascript@2.2.0:\n    resolution: {integrity: sha512-4IehN3V/+kkr5YeSSDDQG8QLqO26XpL2XP3GQtqwlT/QYSECAwFztxVHjlbh0+gjJ3XmNLS0zDsbgs9jWKExLg==}\n    engines: {node: '>=4'}\n\n  unicode-properties@1.4.1:\n    resolution: {integrity: sha512-CLjCCLQ6UuMxWnbIylkisbRj31qxHPAurvena/0iwSVbQ2G1VY5/HjV0IRabOEbDHlzZlRdCrD4NhB0JtU40Pg==}\n\n  unicode-property-aliases-ecmascript@2.1.0:\n    resolution: {integrity: sha512-6t3foTQI9qne+OZoVQB/8x8rk2k1eVy1gRXhV3oFQ5T6R1dqQ1xtin3XqSlx3+ATBkliTaR/hHyJBm+LVPNM8w==}\n    engines: {node: '>=4'}\n\n  unicode-trie@2.0.0:\n    resolution: {integrity: sha512-x7bc76x0bm4prf1VLg79uhAzKw8DVboClSN5VxJuQ+LKDOVEW9CdH+VY7SP+vX7xCYQqzzgQpFqz15zeLvAtZQ==}\n\n  unicorn-magic@0.1.0:\n    resolution: {integrity: sha512-lRfVq8fE8gz6QMBuDM6a+LO3IAzTi05H6gCVaUpir2E1Rwpo4ZUog45KpNXKC/Mn3Yb9UDuHumeFTo9iV/D9FQ==}\n    engines: {node: '>=18'}\n\n  union@0.5.0:\n    resolution: {integrity: sha512-N6uOhuW6zO95P3Mel2I2zMsbsanvvtgn6jVqJv4vbVcz/JN0OkL9suomjQGmWtxJQXOCqUJvquc1sMeNz/IwlA==}\n    engines: {node: '>= 0.8.0'}\n\n  unique-string@2.0.0:\n    resolution: {integrity: sha512-uNaeirEPvpZWSgzwsPGtU2zVSTrn/8L5q/IexZmH0eH6SA73CmAA5U4GwORTxQAZs95TAXLNqeLoPPNO5gZfWg==}\n    engines: {node: '>=8'}\n\n  universalify@2.0.1:\n    resolution: {integrity: sha512-gptHNQghINnc/vTGIk0SOFGFNXw7JVrlRUtConJRlvaw6DuX0wO5Jeko9sWrMBhh+PsYAZ7oXAiOnf/UKogyiw==}\n    engines: {node: '>= 10.0.0'}\n\n  unixify@1.0.0:\n    resolution: {integrity: sha512-6bc58dPYhCMHHuwxldQxO3RRNZ4eCogZ/st++0+fcC1nr0jiGUtAdBJ2qzmLQWSxbtz42pWt4QQMiZ9HvZf5cg==}\n    engines: {node: '>=0.10.0'}\n\n  unpipe@1.0.0:\n    resolution: {integrity: sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==}\n    engines: {node: '>= 0.8'}\n\n  unplugin-fonts@1.1.1:\n    resolution: {integrity: sha512-/Aw/rL9D2aslGGM0vi+2R2aG508RSwawLnnBuo+JDSqYc4cHJO1R1phllhN6GysEhBp/6a4B6+vSFPVapWyAAw==}\n    peerDependencies:\n      '@nuxt/kit': ^3.0.0\n      vite: ^2.0.0 || ^3.0.0 || ^4.0.0 || ^5.0.0\n    peerDependenciesMeta:\n      '@nuxt/kit':\n        optional: true\n\n  unplugin-icons@0.14.9:\n    resolution: {integrity: sha512-vPyVfNREH88dP6gszdaoGkAEFPpiScXj1A8eWN905jQgT53A3tsiPEiqJjCHOUVcsUaREt2JSudzumFOsCA78A==}\n    peerDependencies:\n      '@svgr/core': '>=5.5.0'\n      '@vue/compiler-sfc': ^3.0.2\n      vue-template-compiler: ^2.6.12\n      vue-template-es2015-compiler: ^1.9.0\n    peerDependenciesMeta:\n      '@svgr/core':\n        optional: true\n      '@vue/compiler-sfc':\n        optional: true\n      vue-template-compiler:\n        optional: true\n      vue-template-es2015-compiler:\n        optional: true\n\n  unplugin-icons@0.19.3:\n    resolution: {integrity: sha512-EUegRmsAI6+rrYr0vXjFlIP+lg4fSC4zb62zAZKx8FGXlWAGgEGBCa3JDe27aRAXhistObLPbBPhwa/0jYLFkQ==}\n    peerDependencies:\n      '@svgr/core': '>=7.0.0'\n      '@svgx/core': ^1.0.1\n      '@vue/compiler-sfc': ^3.0.2 || ^2.7.0\n      vue-template-compiler: ^2.6.12\n      vue-template-es2015-compiler: ^1.9.0\n    peerDependenciesMeta:\n      '@svgr/core':\n        optional: true\n      '@svgx/core':\n        optional: true\n      '@vue/compiler-sfc':\n        optional: true\n      vue-template-compiler:\n        optional: true\n      vue-template-es2015-compiler:\n        optional: true\n\n  unplugin-vue-components@0.21.0:\n    resolution: {integrity: sha512-U7uOMNmRJ2eAv9CNjP8QRvxs6nAe3FVQUEIUphC1FGguBp3BWSLgGAcSHaX2nQy0gFoDY2mLF2M52W/t/eDaKg==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      '@babel/parser': ^7.15.8\n      vue: 3.5.12\n    peerDependenciesMeta:\n      '@babel/parser':\n        optional: true\n\n  unplugin-vue-components@0.27.4:\n    resolution: {integrity: sha512-1XVl5iXG7P1UrOMnaj2ogYa5YTq8aoh5jwDPQhemwO/OrXW+lPQKDXd1hMz15qxQPxgb/XXlbgo3HQ2rLEbmXQ==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      '@babel/parser': ^7.15.8\n      '@nuxt/kit': ^3.2.2\n      vue: 3.5.12\n    peerDependenciesMeta:\n      '@babel/parser':\n        optional: true\n      '@nuxt/kit':\n        optional: true\n\n  unplugin@0.7.2:\n    resolution: {integrity: sha512-m7thX4jP8l5sETpLdUASoDOGOcHaOVtgNyrYlToyQUvILUtEzEnngRBrHnAX3IKqooJVmXpoa/CwQ/QqzvGaHQ==}\n    peerDependencies:\n      esbuild: '>=0.13'\n      rollup: ^2.50.0\n      vite: ^2.3.0 || ^3.0.0-0\n      webpack: 4 || 5\n    peerDependenciesMeta:\n      esbuild:\n        optional: true\n      rollup:\n        optional: true\n      vite:\n        optional: true\n      webpack:\n        optional: true\n\n  unplugin@0.9.6:\n    resolution: {integrity: sha512-YYLtfoNiie/lxswy1GOsKXgnLJTE27la/PeCGznSItk+8METYZErO+zzV9KQ/hXhPwzIJsfJ4s0m1Rl7ZCWZ4Q==}\n\n  unplugin@1.10.1:\n    resolution: {integrity: sha512-d6Mhq8RJeGA8UfKCu54Um4lFA0eSaRa3XxdAJg8tIdxbu1ubW0hBCZUL7yI2uGyYCRndvbK8FLHzqy2XKfeMsg==}\n    engines: {node: '>=14.0.0'}\n\n  unplugin@1.14.1:\n    resolution: {integrity: sha512-lBlHbfSFPToDYp9pjXlUEFVxYLaue9f9T1HC+4OHlmj+HnMDdz9oZY+erXfoCe/5V/7gKUSY2jpXPb9S7f0f/w==}\n    engines: {node: '>=14.0.0'}\n    peerDependencies:\n      webpack-sources: ^3\n    peerDependenciesMeta:\n      webpack-sources:\n        optional: true\n\n  untildify@4.0.0:\n    resolution: {integrity: sha512-KK8xQ1mkzZeg9inewmFVDNkg3l5LUhoq9kN6iWYB/CC9YMG8HA+c1Q8HwDe6dEX7kErrEVNVBO3fWsVq5iDgtw==}\n    engines: {node: '>=8'}\n\n  upath@1.2.0:\n    resolution: {integrity: sha512-aZwGpamFO61g3OlfT7OQCHqhGnW43ieH9WZeP7QxN/G/jS4jfqUkZxoryvJgVPEcrl5NL/ggHsSmLMHuH64Lhg==}\n    engines: {node: '>=4'}\n\n  update-browserslist-db@1.1.1:\n    resolution: {integrity: sha512-R8UzCaa9Az+38REPiJ1tXlImTJXlVfgHZsglwBD/k6nj76ctsH1E3q4doGrukiLQd3sGQYu56r5+lo5r94l29A==}\n    hasBin: true\n    peerDependencies:\n      browserslist: '>= 4.21.0'\n\n  upper-case-first@2.0.2:\n    resolution: {integrity: sha512-514ppYHBaKwfJRK/pNC6c/OxfGa0obSnAl106u97Ed0I625Nin96KAjttZF6ZL3e1XLtphxnqrOi9iWgm+u+bg==}\n\n  upper-case@2.0.2:\n    resolution: {integrity: sha512-KgdgDGJt2TpuwBUIjgG6lzw2GWFRCW9Qkfkiv0DxqHHLYJHmtmdUIKcZd8rHgFSjopVTlw6ggzCm1b8MFQwikg==}\n\n  uri-js@4.4.1:\n    resolution: {integrity: sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==}\n\n  urijs@1.19.11:\n    resolution: {integrity: sha512-HXgFDgDommxn5/bIv0cnQZsPhHDA90NPHD6+c/v21U5+Sx5hoP8+dP9IZXBU1gIfvdRfhG8cel9QNPeionfcCQ==}\n\n  url-join@4.0.1:\n    resolution: {integrity: sha512-jk1+QP6ZJqyOiuEI9AEWQfju/nB2Pw466kbA0LEZljHwKeMgd9WrAEgEGxjPDD2+TNbbb37rTyhEfrCXfuKXnA==}\n\n  url@0.11.4:\n    resolution: {integrity: sha512-oCwdVC7mTuWiPyjLUz/COz5TLk6wgp0RCsN+wHZ2Ekneac9w8uuV0njcbbie2ME+Vs+d6duwmYuR3HgQXs1fOg==}\n    engines: {node: '>= 0.4'}\n\n  urlpattern-polyfill@10.0.0:\n    resolution: {integrity: sha512-H/A06tKD7sS1O1X2SshBVeA5FLycRpjqiBeqGKmBwBDBy28EnRjORxTNe269KSSr5un5qyWi1iL61wLxpd+ZOg==}\n\n  urlpattern-polyfill@8.0.2:\n    resolution: {integrity: sha512-Qp95D4TPJl1kC9SKigDcqgyM2VDVO4RiJc2d4qe5GrYm+zbIQCWWKAFaJNQ4BhdFeDGwBmAxqJBwWSJDb9T3BQ==}\n\n  util-deprecate@1.0.2:\n    resolution: {integrity: sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==}\n\n  util@0.10.4:\n    resolution: {integrity: sha512-0Pm9hTQ3se5ll1XihRic3FDIku70C+iHUdT/W926rSgHV5QgXsYbKZN8MSC3tJtSkhuROzvsQjAaFENRXr+19A==}\n\n  util@0.12.5:\n    resolution: {integrity: sha512-kZf/K6hEIrWHI6XqOFUiiMa+79wE/D8Q+NCNAWclkyg3b4d2k7s0QGepNjiABc+aR3N1PAyHL7p6UcLY6LmrnA==}\n\n  utils-merge@1.0.1:\n    resolution: {integrity: sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==}\n    engines: {node: '>= 0.4.0'}\n\n  uuid@10.0.0:\n    resolution: {integrity: sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==}\n    hasBin: true\n\n  uuid@8.3.2:\n    resolution: {integrity: sha512-+NYs2QeMWy+GWFOEm9xnn6HCDp0l7QBD7ml8zLUmJ+93Q5NF0NocErnwkTkXVFNiX3/fpC6afS8Dhb/gz7R7eg==}\n    hasBin: true\n\n  uuid@9.0.1:\n    resolution: {integrity: sha512-b+1eJOlsR9K8HJpow9Ok3fiWOWSIcIzXodvv0rQjVoOVNpWMpxf1wZNpt4y9h10odCNrqnYp1OBzRktckBe3sA==}\n    hasBin: true\n\n  v8-compile-cache-lib@3.0.1:\n    resolution: {integrity: sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==}\n\n  v8-to-istanbul@9.3.0:\n    resolution: {integrity: sha512-kiGUalWN+rgBJ/1OHZsBtU4rXZOfj/7rKQxULKlIzwzQSvMJUUNgPwJEEh7gU6xEVxC0ahoOBvN2YI8GH6FNgA==}\n    engines: {node: '>=10.12.0'}\n\n  valid-data-url@3.0.1:\n    resolution: {integrity: sha512-jOWVmzVceKlVVdwjNSenT4PbGghU0SBIizAev8ofZVgivk/TVHXSbNL8LP6M3spZvkR9/QolkyJavGSX5Cs0UA==}\n    engines: {node: '>=10'}\n\n  validate-npm-package-license@3.0.4:\n    resolution: {integrity: sha512-DpKm2Ui/xN7/HQKCtpZxoRWBhZ9Z0kqtygG8XCgNQ8ZlDnxuQmWhj566j8fN4Cu3/JmbhsDo7fcAJq4s9h27Ew==}\n\n  validator@13.11.0:\n    resolution: {integrity: sha512-Ii+sehpSfZy+At5nPdnyMhx78fEoPDkR2XW/zimHEL3MyGJQOCQ7WeP20jPYRz7ZCpcKLB21NxuXHF3bxjStBQ==}\n    engines: {node: '>= 0.10'}\n\n  value-or-promise@1.0.12:\n    resolution: {integrity: sha512-Z6Uz+TYwEqE7ZN50gwn+1LCVo9ZVrpxRPOhOLnncYkY1ZzOYtrX8Fwf/rFktZ8R5mJms6EZf5TqNOMeZmnPq9Q==}\n    engines: {node: '>=12'}\n\n  vary@1.1.2:\n    resolution: {integrity: sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==}\n    engines: {node: '>= 0.8'}\n\n  verzod@0.2.3:\n    resolution: {integrity: sha512-fARgs0c/TNNtbo83/5LjriJEb3QMwBN8Ju2+BcVdiI7Y2NOa5Yhq+CrQ8UH43h0BRXcgb2JQABjkgrRCWybEtQ==}\n    engines: {node: '>=16'}\n    peerDependencies:\n      zod: ^3.22.0\n\n  vite-node@2.1.2:\n    resolution: {integrity: sha512-HPcGNN5g/7I2OtPjLqgOtCRu/qhVvBxTUD3qzitmL0SrG1cWFzxzhMDWussxSbrRYWqnKf8P2jiNhPMSN+ymsQ==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    hasBin: true\n\n  vite-node@2.1.3:\n    resolution: {integrity: sha512-I1JadzO+xYX887S39Do+paRePCKoiDrWRRjp9kkG5he0t7RXNvPAJPCQSJqbGN4uCrFFeS3Kj3sLqY8NMYBEdA==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    hasBin: true\n\n  vite-plugin-checker@0.6.4:\n    resolution: {integrity: sha512-2zKHH5oxr+ye43nReRbC2fny1nyARwhxdm0uNYp/ERy4YvU9iZpNOsueoi/luXw5gnpqRSvjcEPxXbS153O2wA==}\n    engines: {node: '>=14.16'}\n    peerDependencies:\n      eslint: '>=7'\n      meow: ^9.0.0\n      optionator: ^0.9.1\n      stylelint: '>=13'\n      typescript: '*'\n      vite: '>=2.0.0'\n      vls: '*'\n      vti: '*'\n      vue-tsc: '>=1.3.9'\n    peerDependenciesMeta:\n      eslint:\n        optional: true\n      meow:\n        optional: true\n      optionator:\n        optional: true\n      stylelint:\n        optional: true\n      typescript:\n        optional: true\n      vls:\n        optional: true\n      vti:\n        optional: true\n      vue-tsc:\n        optional: true\n\n  vite-plugin-eslint@1.8.1:\n    resolution: {integrity: sha512-PqdMf3Y2fLO9FsNPmMX+//2BF5SF8nEWspZdgl4kSt7UvHDRHVVfHvxsD7ULYzZrJDGRxR81Nq7TOFgwMnUang==}\n    peerDependencies:\n      eslint: '>=7'\n      vite: '>=2'\n\n  vite-plugin-fonts@0.7.0:\n    resolution: {integrity: sha512-fisKirkQrA2RFwcyI96SENLu1FyRYNIiC/l5DGdD8oV3OsAWGrYKs0e7/VZF6l0rm0QiYA2sOVTzYfrLAzP9cw==}\n    deprecated: renamed to `unplugin-fonts`, see https://github.com/cssninjaStudio/unplugin-fonts/releases/tag/v1.0.0\n    peerDependencies:\n      vite: ^2.0.0 || ^3.0.0 || ^4.0.0\n\n  vite-plugin-html-config@1.0.11:\n    resolution: {integrity: sha512-hUybhgI+/LQQ5q6xoMMsTvI4PBuQD/Wv6Z1vtDPVWjanS8weCIexXuLLYNGD/93f0v8W2hpNfXpmxgpZMahJ0g==}\n    engines: {node: '>=12.0.0'}\n    peerDependencies:\n      vite: '>=2.0.0'\n\n  vite-plugin-html-config@2.0.2:\n    resolution: {integrity: sha512-g09u0XsmgKyMUIp1RZSyNSkJWvIusaXxw3KylyxU3vkCq7/G8hyemLctT+4IvO42fCPlNySmrNC9g0qSoKmvpw==}\n    engines: {node: '>=12.0.0'}\n    peerDependencies:\n      vite: '>=5.0.0'\n\n  vite-plugin-inspect@0.7.38:\n    resolution: {integrity: sha512-+p6pJVtBOLGv+RBrcKAFUdx+euizg0bjL35HhPyM0MjtKlqoC5V9xkCmO9Ctc8JrTyXqODbHqiLWJKumu5zJ7g==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      '@nuxt/kit': '*'\n      vite: ^3.1.0 || ^4.0.0\n    peerDependenciesMeta:\n      '@nuxt/kit':\n        optional: true\n\n  vite-plugin-inspect@0.8.7:\n    resolution: {integrity: sha512-/XXou3MVc13A5O9/2Nd6xczjrUwt7ZyI9h8pTnUMkr5SshLcb0PJUOVq2V+XVkdeU4njsqAtmK87THZuO2coGA==}\n    engines: {node: '>=14'}\n    peerDependencies:\n      '@nuxt/kit': '*'\n      vite: ^3.1.0 || ^4.0.0 || ^5.0.0-0\n    peerDependenciesMeta:\n      '@nuxt/kit':\n        optional: true\n\n  vite-plugin-pages-sitemap@1.6.1:\n    resolution: {integrity: sha512-8Nil2Q6qltBnxL/OX19ORMFxLGM//7mlW7LG+LCR8qOygxdzEIyxyw3LBz0j5tGwJr8BDSpuBW2MkMTtP6wBTQ==}\n\n  vite-plugin-pages-sitemap@1.7.1:\n    resolution: {integrity: sha512-XtrMxDTECbEGMXWPB22I+cUB7aij6rQvVq4/q6vqCfZ34IdUyVwMexCYrcvrEBuOZF0knivfLfJUDm45mgJHWg==}\n\n  vite-plugin-pages@0.26.0:\n    resolution: {integrity: sha512-yJZvwHEt7puYIf19S89IvkDsWPjWleSied4H8hmdW6i8buCA93z1UAU1ipW1d8fNKrC4FzXsUHHbPm6+kl1p9w==}\n    peerDependencies:\n      '@vue/compiler-sfc': ^2.7.0 || ^3.0.0\n      vite: ^2.0.0 || ^3.0.0-0\n    peerDependenciesMeta:\n      '@vue/compiler-sfc':\n        optional: true\n\n  vite-plugin-pages@0.32.3:\n    resolution: {integrity: sha512-1vmKwc9e+lRBLkpTAMUNSVV3BglyE+DRa0iivpe6q3pbOCGkAHHSUp8f6yceXC8+lu/kFgH60vm5vK6IHyvdVw==}\n    peerDependencies:\n      '@solidjs/router': '*'\n      '@vue/compiler-sfc': ^2.7.0 || ^3.0.0\n      react-router: '*'\n      vite: ^2.0.0 || ^3.0.0-0 || ^4.0.0 || ^5.0.0\n      vue-router: '*'\n    peerDependenciesMeta:\n      '@solidjs/router':\n        optional: true\n      '@vue/compiler-sfc':\n        optional: true\n      react-router:\n        optional: true\n      vue-router:\n        optional: true\n\n  vite-plugin-pwa@0.13.1:\n    resolution: {integrity: sha512-NR3dIa+o2hzlzo4lF4Gu0cYvoMjSw2DdRc6Epw1yjmCqWaGuN86WK9JqZie4arNlE1ZuWT3CLiMdiX5wcmmUmg==}\n    peerDependencies:\n      vite: ^3.1.0\n      workbox-build: ^6.5.4\n      workbox-window: ^6.5.4\n\n  vite-plugin-pwa@0.20.5:\n    resolution: {integrity: sha512-aweuI/6G6n4C5Inn0vwHumElU/UEpNuO+9iZzwPZGTCH87TeZ6YFMrEY6ZUBQdIHHlhTsbMDryFARcSuOdsz9Q==}\n    engines: {node: '>=16.0.0'}\n    peerDependencies:\n      '@vite-pwa/assets-generator': ^0.2.6\n      vite: ^3.1.0 || ^4.0.0 || ^5.0.0\n      workbox-build: ^7.1.0\n      workbox-window: ^7.1.0\n    peerDependenciesMeta:\n      '@vite-pwa/assets-generator':\n        optional: true\n\n  vite-plugin-static-copy@0.12.0:\n    resolution: {integrity: sha512-5a8hCjYJdf/rl8s7ct/YWt97gXdGPGNSOoJtkY5IYhbnSq04X1gTt5GpFHKfAxhHoed1Grfw3Ed13t7AjJi7gw==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n    peerDependencies:\n      vite: ^3.0.0\n\n  vite-plugin-static-copy@2.0.0:\n    resolution: {integrity: sha512-b/quFjTUa/RY9t3geIyeeT2GtWEoRI0GawYFFjys5iMLGgVP638NTGu0RoMjwmi8MoZZ3BQw4OQvb1GpVcXZDA==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    peerDependencies:\n      vite: ^5.0.0\n\n  vite-plugin-vue-layouts@0.11.0:\n    resolution: {integrity: sha512-uh6NW7lt+aOXujK4eHfiNbeo55K9OTuB7fnv+5RVc4OBn/cZull6ThXdYH03JzKanUfgt6QZ37NbbtJ0og59qw==}\n    peerDependencies:\n      vite: ^4.0.0 || ^5.0.0\n      vue: 3.5.12\n      vue-router: ^4.0.11\n\n  vite-plugin-vue-layouts@0.7.0:\n    resolution: {integrity: sha512-k5XDmRNFo4M/GmUjhbRXj2WmJiFcGoVI8l/uZ72RHyRDQr4wE/6Zq/KFq0lqXomWQxTSzakQRUswzNwtvZLE8A==}\n    peerDependencies:\n      vite: ^2.5.0 || ^3.0.0-0\n      vue: 3.5.12\n      vue-router: ^3.5.1 || ^ 4.0.11\n\n  vite@4.5.0:\n    resolution: {integrity: sha512-ulr8rNLA6rkyFAlVWw2q5YJ91v098AFQ2R0PRFwPzREXOUJQPtFUG0t+/ZikhaOCDqFoDhN6/v8Sq0o4araFAw==}\n    engines: {node: ^14.18.0 || >=16.0.0}\n    hasBin: true\n    peerDependencies:\n      '@types/node': '>= 14'\n      less: '*'\n      lightningcss: ^1.21.0\n      sass: '*'\n      stylus: '*'\n      sugarss: '*'\n      terser: ^5.4.0\n    peerDependenciesMeta:\n      '@types/node':\n        optional: true\n      less:\n        optional: true\n      lightningcss:\n        optional: true\n      sass:\n        optional: true\n      stylus:\n        optional: true\n      sugarss:\n        optional: true\n      terser:\n        optional: true\n\n  vite@5.4.9:\n    resolution: {integrity: sha512-20OVpJHh0PAM0oSOELa5GaZNWeDjcAvQjGXy2Uyr+Tp+/D2/Hdz6NLgpJLsarPTA2QJ6v8mX2P1ZfbsSKvdMkg==}\n    engines: {node: ^18.0.0 || >=20.0.0}\n    hasBin: true\n    peerDependencies:\n      '@types/node': ^18.0.0 || >=20.0.0\n      less: '*'\n      lightningcss: ^1.21.0\n      sass: '*'\n      sass-embedded: '*'\n      stylus: '*'\n      sugarss: '*'\n      terser: ^5.4.0\n    peerDependenciesMeta:\n      '@types/node':\n        optional: true\n      less:\n        optional: true\n      lightningcss:\n        optional: true\n    "
        },
        {
          "name": "pnpm-workspace.yaml",
          "type": "blob",
          "size": 0.03,
          "content": "packages:\n  - 'packages/**'"
        },
        {
          "name": "prod.Dockerfile",
          "type": "blob",
          "size": 5.39,
          "content": "FROM node:20-alpine3.19 AS base_builder\n\nWORKDIR /usr/src/app\n\nENV HOPP_ALLOW_RUNTIME_ENV=true\n\n# Required by @hoppscotch/js-sandbox to build `isolated-vm`\nRUN apk add python3 make g++\n\nRUN npm install -g pnpm\nCOPY pnpm-lock.yaml .\nRUN pnpm fetch\n\nCOPY . .\nRUN pnpm install -f --offline\n\nRUN npm uninstall -g cross-spawn && \\\n    npm cache clean --force && \\\n    # Remove any remaining old versions\n    find /usr/local/lib/node_modules -name \"cross-spawn\" -type d -exec rm -rf {} + && \\\n    # Install cross-spawn v7 globally\n    npm install -g cross-spawn@^7.0.6 --force\n\nFROM base_builder AS backend_builder\nWORKDIR /usr/src/app/packages/hoppscotch-backend\nRUN pnpm exec prisma generate\nRUN pnpm run build\nRUN pnpm --filter=hoppscotch-backend deploy /dist/backend --prod\nWORKDIR /dist/backend\nRUN pnpm exec prisma generate\n\nFROM node:20-alpine3.19 AS backend\nRUN apk add caddy\nRUN npm install -g pnpm\n\nRUN npm uninstall -g cross-spawn && \\\n    npm cache clean --force && \\\n    # Remove any remaining old versions\n    find /usr/local/lib/node_modules -name \"cross-spawn\" -type d -exec rm -rf {} + && \\\n    # Install cross-spawn v7 globally\n    npm install -g cross-spawn@^7.0.6 --force\n\nCOPY --from=base_builder  /usr/src/app/packages/hoppscotch-backend/backend.Caddyfile /etc/caddy/backend.Caddyfile\nCOPY --from=backend_builder /dist/backend /dist/backend\nCOPY --from=base_builder /usr/src/app/packages/hoppscotch-backend/prod_run.mjs /dist/backend\n\n# Remove the env file to avoid backend copying it in and using it\nENV PRODUCTION=\"true\"\nENV PORT=8080\nENV APP_PORT=${PORT}\nENV DB_URL=${DATABASE_URL}\n\nWORKDIR /dist/backend\n\nCMD [\"node\", \"prod_run.mjs\"]\nEXPOSE 80\nEXPOSE 3170\n\nFROM base_builder AS fe_builder\nWORKDIR /usr/src/app/packages/hoppscotch-selfhost-web\nRUN pnpm run generate\n\nFROM caddy:2-alpine AS app\nCOPY --from=fe_builder /usr/src/app/packages/hoppscotch-selfhost-web/prod_run.mjs /site/prod_run.mjs\nCOPY --from=fe_builder /usr/src/app/packages/hoppscotch-selfhost-web/selfhost-web.Caddyfile /etc/caddy/selfhost-web.Caddyfile\nCOPY --from=fe_builder /usr/src/app/packages/hoppscotch-selfhost-web/dist/ /site/selfhost-web\n\nRUN apk add nodejs npm\n\nRUN npm install -g @import-meta-env/cli\n\nEXPOSE 80\nEXPOSE 3000\n\nWORKDIR /site\n\nCMD [\"/bin/sh\", \"-c\", \"node /site/prod_run.mjs && caddy run --config /etc/caddy/selfhost-web.Caddyfile --adapter caddyfile\"]\n\nFROM base_builder AS sh_admin_builder\nWORKDIR /usr/src/app/packages/hoppscotch-sh-admin\n# Generate two builds for `sh-admin`, one based on subpath-access and the regular build\nRUN pnpm run build --outDir dist-multiport-setup\nRUN pnpm run build --outDir dist-subpath-access --base /admin/\n\nFROM caddy:2-alpine AS sh_admin\n\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/prod_run.mjs /site/prod_run.mjs\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/sh-admin-multiport-setup.Caddyfile /etc/caddy/sh-admin-multiport-setup.Caddyfile\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/sh-admin-subpath-access.Caddyfile /etc/caddy/sh-admin-subpath-access.Caddyfile\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/dist-multiport-setup /site/sh-admin-multiport-setup\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/dist-subpath-access /site/sh-admin-subpath-access\n\nRUN apk add nodejs npm\n\nRUN npm install -g @import-meta-env/cli\n\nEXPOSE 80\nEXPOSE 3100\n\nWORKDIR /site\n\nCMD [\"node\",\"/site/prod_run.mjs\"]\n\nFROM node:20-alpine3.19 AS aio\n\nENV PRODUCTION=\"true\"\nENV PORT=8080\nENV APP_PORT=${PORT}\nENV DB_URL=${DATABASE_URL}\n\n# Open Containers Initiative (OCI) labels - useful for bots like Renovate\nLABEL org.opencontainers.image.source=\"https://github.com/hoppscotch/hoppscotch\" \\\n  org.opencontainers.image.url=\"https://docs.hoppscotch.io\" \\\n  org.opencontainers.image.licenses=\"MIT\"\n\n# Run this separately to use the cache from backend\nRUN apk add caddy\n\nRUN apk add tini curl\n\nRUN npm install -g pnpm\nRUN npm uninstall -g cross-spawn && \\\n    npm cache clean --force && \\\n    # Remove any remaining old versions\n    find /usr/local/lib/node_modules -name \"cross-spawn\" -type d -exec rm -rf {} + && \\\n    # Install cross-spawn v7 globally\n    npm install -g cross-spawn@^7.0.6 --force\n\n# Copy necessary files\n# Backend files\nCOPY --from=base_builder /usr/src/app/packages/hoppscotch-backend/backend.Caddyfile /etc/caddy/backend.Caddyfile\nCOPY --from=backend_builder /dist/backend /dist/backend\nCOPY --from=base_builder /usr/src/app/packages/hoppscotch-backend/prod_run.mjs /dist/backend\n\n# FE Files\nCOPY --from=base_builder /usr/src/app/aio_run.mjs /usr/src/app/aio_run.mjs\nCOPY --from=fe_builder /usr/src/app/packages/hoppscotch-selfhost-web/dist /site/selfhost-web\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/dist-multiport-setup /site/sh-admin-multiport-setup\nCOPY --from=sh_admin_builder /usr/src/app/packages/hoppscotch-sh-admin/dist-subpath-access /site/sh-admin-subpath-access\nCOPY aio-multiport-setup.Caddyfile /etc/caddy/aio-multiport-setup.Caddyfile\nCOPY aio-subpath-access.Caddyfile /etc/caddy/aio-subpath-access.Caddyfile\n\nRUN npm install -g @import-meta-env/cli\n\nENTRYPOINT [ \"tini\", \"--\" ]\nCOPY --chmod=755 healthcheck.sh /\nHEALTHCHECK --interval=2s CMD /bin/sh /healthcheck.sh\n\nWORKDIR /dist/backend\n\nCMD [\"node\", \"/usr/src/app/aio_run.mjs\"]\n\n# NOTE: Although these ports are exposed, the HOPP_ALTERNATE_AIO_PORT variable can be used to assign a user-specified port\nEXPOSE 3170\nEXPOSE 3000\nEXPOSE 3100\nEXPOSE 80\n"
        },
        {
          "name": "tailwind.config.ts",
          "type": "blob",
          "size": 0.21,
          "content": "import preset from \"@hoppscotch/ui/ui-preset\"\n\nexport default {\n  content: [\n    \"packages/hoppscotch-common/src/**/*.{vue,html}\",\n    \"packages/hoppscotch-sh-admin/src/**/*.{vue,html}\",\n  ],\n  presets: [preset],\n}\n"
        }
      ]
    },
    {
      "nameWithOwner": "enaqx/awesome-react",
      "stars": 66314,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0,
          "content": "tmp\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.21,
          "content": "# Awesome React [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA collection of awesome things regarding the React ecosystem.\n\n- [React](#react)\n  - [React General Resources](#react-general-resources)\n  - [React Tutorials](#react-tutorials)\n  - [React Frameworks](#react-frameworks)\n  - [React Component Libraries](#react-component-libraries)\n  - [React State Management and Data Fetching](#react-state-management-and-data-fetching)\n  - [React Styling](#react-styling)\n  - [React Routing](#react-routing)\n  - [React Development Tools](#react-development-tools)\n  - [React Libraries](#react-libraries)\n  - [React Testing](#react-testing)\n  - [React Awesome Components](#react-awesome-components)\n  - [React Components Sandboxes](#react-components-sandboxes)\n  - [React Forms](#react-forms)\n  - [React Tables and Grids](#react-tables-and-grids)\n  - [React Maps](#react-maps)\n  - [React Charts](#react-charts)\n  - [React Renderers](#react-renderers)\n  - [React Internationalization](#react-internationalization)\n  - [React Graphics and Animations](#react-graphics-and-animations)\n  - [React Integration](#react-integration)\n  - [React Real Apps](#react-real-apps)\n- [React Native](#react-native)\n  - [React Native General Resources](#react-native-general-resources)\n  - [React Native Navigation](#react-native-navigation)\n  - [React Native Awesome Components](#react-native-awesome-components)\n  - [React Native Libraries](#react-native-libraries)\n- [Contribution](#contribution)\n\n### React\n\n#### React General Resources\n\n- [React Official Website](https://react.dev/)\n- [React GitHub](https://github.com/facebook/react)\n- [Reactiflux Discord Channel](http://www.reactiflux.com/)\n- [React Community](https://react.dev/community)\n- [React Conferences](https://react.dev/community/conferences)\n- [React CodeSandbox Playground](https://codesandbox.io/s/new)\n\n#### React Tutorials\n\n- [React Official Tutorial](https://react.dev/learn)\n- [Using React in Visual Studio Code](https://code.visualstudio.com/docs/nodejs/reactjs-tutorial)\n- [React Interview Questions & Answers](https://github.com/sudheerj/reactjs-interview-questions)\n- [Design patterns and Component patterns for building powerful Web Apps](https://www.patterns.dev/)\n- [A simple, scalable, and powerful architecture for building production ready React applications](https://github.com/alan2207/bulletproof-react)\n- [Cheatsheets for experienced React developers getting started with TypeScript](https://github.com/typescript-cheatsheets/react-typescript-cheatsheet)\n- [The Fullstack Tutorial for GraphQL](https://github.com/howtographql/howtographql)\n\n#### React Frameworks\n\n- [next](https://github.com/vercel/next.js) - The React Framework\n- [remix](https://github.com/remix-run/remix) - Full stack web Framework that lets you focus on the user interface\n- [gatsby](https://github.com/gatsbyjs/gatsby) - Build modern websites with React\n- [react-admin](https://github.com/marmelab/react-admin) - A frontend Framework for building B2B applications\n- [refine](https://github.com/refinedev/refine) - Build your React-based CRUD applications, without constraints\n\n#### React Component Libraries\n\n- [material-ui](https://github.com/mui/material-ui) - Ready-to-use foundational React components\n- [ant-design](https://github.com/ant-design/ant-design) - An enterprise-class UI design language and React UI library\n- [shadcn-ui](https://github.com/shadcn-ui/ui) - Beautifully designed components built using Radix UI and Tailwind CSS\n- [react-bootstrap](https://github.com/react-bootstrap/react-bootstrap) - Bootstrap components built with React\n- [fluentui](https://github.com/microsoft/fluentui) - Microsoft's Fluent UI\n- [framework7](https://github.com/framework7io/framework7) - Full featured HTML framework for building iOS & Android apps\n- [ariakit](https://github.com/ariakit/ariakit) - Toolkit for building accessible web apps with React\n- [mantine](https://github.com/mantinedev/mantine) - Fully featured React components library\n- [react-email](https://github.com/resend/react-email) - Unstyled components for creating beautiful emails\n\n#### React State Management and Data Fetching\n\n- [redux](https://github.com/reduxjs/redux) - Predictable State Container for JavaScript Apps\n- [mobx](https://github.com/mobxjs/mobx) - Simple, scalable state management\n- [zustand](https://github.com/pmndrs/zustand) - Bear necessities for state management in React\n- [tanstack-query](https://github.com/TanStack/query) - Powerful asynchronous state management\n- [swr](https://github.com/vercel/swr) - React Hooks for Data Fetching\n- [apollo-client](https://github.com/apollographql/apollo-client) - A fully-featured, production ready caching GraphQL client\n- [relay](https://github.com/facebook/relay) - A framework for building data-driven React applications\n- [jotai](https://github.com/pmndrs/jotai) - Primitive and flexible state management for React\n- [xstate](https://github.com/statelyai/xstate) - State machines and statecharts for the modern web\n- [effector](https://github.com/zerobias/effector) - Business logic with ease\n- [immer](https://github.com/immerjs/immer) - Create the next immutable state by mutating the current one\n- [immutable-js](https://github.com/immutable-js/immutable-js) - Immutable persistent data collections for Javascript\n- [rxdb](https://github.com/pubkey/rxdb) - A fast, offline-first, reactive database for JavaScript Applications\n\n#### React Styling\n\n- [styled-components](https://github.com/styled-components/styled-components) - Visual primitives for the component age\n- [emotion](https://github.com/emotion-js/emotion) - CSS-in-JS library designed for high performance style composition\n- [vanilla-extract](https://github.com/seek-oss/vanilla-extract) - Zero-runtime Stylesheets-in-TypeScript\n\n#### React Routing\n\n- [react-router](https://github.com/remix-run/react-router) - Declarative routing for React\n- [wouter](https://github.com/molefrog/wouter) - A minimalist-friendly routing\n- [tanstack-router](https://github.com/TanStack/router) - Type-safe router with built-in caching & URL state management\n\n#### React Development Tools\n\n- [create-react-app](https://github.com/facebook/create-react-app) - Set up a modern Web app by running one command\n- [vite](https://github.com/vitejs/vite) - Next Generation Frontend Tooling\n- [parcel](https://github.com/parcel-bundler/parcel) - The zero configuration build tool for the web\n- [million](https://github.com/aidenybai/million) - An extremely fast and lightweight optimizing compiler\n- [reactotron](https://github.com/skellock/reactotron) - A desktop app for inspecting your React and React Native projects\n- [eslint-plugin-react](https://github.com/yannickcr/eslint-plugin-react) - React specific linting rules for ESLint\n- [why-did-you-render](https://github.com/welldone-software/why-did-you-render) - Monkey patches React to notify you about avoidable re-renders\n\n#### React Libraries\n\n- [preact](https://github.com/preactjs/preact) - Fast React alternative with the same modern API\n- [floating-ui](https://github.com/floating-ui/floating-ui) - Toolkit to create floating elements\n- [loadable-components](https://github.com/gregberge/loadable-components) - The recommended Code Splitting library for React\n- [react-uploady](https://github.com/rpldy/react-uploady) - Modern file-upload components & hooks for React\n- [downshift](https://github.com/downshift-js/downshift) - React autocomplete, combobox or select dropdown components\n- [react-error-boundary](https://github.com/bvaughn/react-error-boundary) - A React error boundary component that lets you catch errors\n\n#### React Testing\n\n- [jest](https://github.com/facebook/jest) - Delightful JavaScript Testing\n- [react-testing-library](https://github.com/testing-library/react-testing-library) - Simple and complete React DOM testing utilities\n- [cypress](https://github.com/cypress-io/cypress) - Fast, easy and reliable testing for anything that runs in a browser\n\n#### React Awesome Components\n\n- [Awesome React Components](https://github.com/brillout/awesome-react-components)\n- [react-select](https://github.com/JedWatson/react-select) - The Select Component for React\n- [react-big-calendar](https://github.com/jquense/react-big-calendar) - Calendar component\n- [react-datepicker](https://github.com/Hacker0x01/react-datepicker/) - A simple and reusable datepicker component for React\n- [react-loading-skeleton](https://github.com/dvtng/react-loading-skeleton) - Create skeleton screens that automatically adapt to your app\n- [react-qrcode](https://github.com/zpao/qrcode.react) - QR component for use with React\n- [react-archer](https://github.com/pierpo/react-archer) - Draw arrows between React elements\n- [react-icons](https://github.com/react-icons/react-icons) - SVG React icons of popular icon packs\n- [react-complex-tree](https://github.com/lukasbach/react-complex-tree) - Unopinionated Accessible Tree\n- [react-insta-stories](https://github.com/mohitk05/react-insta-stories) - A React component for Instagram like stories\n- [swiper](https://github.com/nolimits4web/swiper) - Most modern mobile touch slider\n- [keen-slider](https://github.com/rcbyr/keen-slider) - The Touch slider carousel\n- [cookie-consent-banner](https://github.com/porscheofficial/cookie-consent-banner) – The lightweight and flexible Cookie Consent Banner\n- [heart-switch](https://github.com/anatoliygatt/heart-switch) - A heart-shaped toggle switch component for React\n- [kbar](https://github.com/timc1/kbar) - Fast, portable, and extensible cmd+k interface for your site\n- [tagify](https://github.com/yairEO/tagify) - Lightweight, efficient Tags input component\n- [puck](https://github.com/measuredco/puck) - The visual editor for React\n\n#### React Components Sandboxes\n\n- [storybook](https://github.com/storybookjs/storybook) - Storybook is a frontend workshop for building UI components and pages in isolation\n- [react-styleguidist](https://github.com/styleguidist/react-styleguidist) - Isolated React component development environment with a living style guide\n- [react-cosmos](https://github.com/react-cosmos/react-cosmos) - Dev tool for creating reusable React components\n- [bit](https://github.com/teambit/bit) - A build system for development of composable software\n\n#### React Forms\n\n- [react-hook-form](https://github.com/react-hook-form/react-hook-form) - React Hooks for form state management and validation\n- [formik](https://github.com/jaredpalmer/formik) - Build forms in React, without the tears\n- [react-jsonschema-form](https://github.com/mozilla-services/react-jsonschema-form) - A React component for building Web forms from JSON Schema\n- [formily](https://github.com/alibaba/formily) - Alibaba Group Unified Form Solution\n- [vest](https://github.com/ealush/vest) - Declarative validations framework\n\n#### React Tables and Grids\n\n- [react-grid-layout](https://github.com/react-grid-layout/react-grid-layout) - A draggable and resizable grid layout with responsive breakpoints\n- [tanstack-table](https://github.com/TanStack/table) - Headless UI for building powerful tables & datagrids\n- [react-data-grid](https://github.com/adazzle/react-data-grid) - Feature-rich and customizable data grid React component\n\n#### React Maps\n\n- [react-map-gl](https://github.com/visgl/react-map-gl) - React friendly API wrapper around MapboxGL JS\n- [react-leaflet](https://github.com/PaulLeCam/react-leaflet) - React components for Leaflet maps\n\n#### React Charts\n\n- [recharts](https://github.com/recharts/recharts) - Redefined chart library built with React and D3\n- [visx](https://github.com/airbnb/visx) - Visualization components\n- [victory](https://github.com/FormidableLabs/victory) - A collection of composable React components for building interactive data visualizations\n- [react-vis](https://github.com/uber/react-vis) - Data Visualization Components\n- [nivo](https://github.com/plouc/nivo) - Provides a rich set of data visualization components built on top of the D3 and React libraries\n- [xyflow](https://github.com/xyflow/xyflow) - A customizable React component for building node-based editors and interactive diagrams\n\n#### React Renderers\n\n- [react-three-fiber](https://github.com/pmndrs/react-three-fiber) - A React renderer for Three.js\n- [ink](https://github.com/vadimdemedes/ink) - React for interactive command-line apps\n- [remotion](https://github.com/remotion-dev/remotion) - Make videos programmatically with React\n- [react-pdf](https://github.com/diegomura/react-pdf) - Create PDF files using React\n- [react-figma](https://github.com/react-figma/react-figma) - A React renderer for Figma\n\n#### React Internationalization\n\n- [formatjs](https://github.com/formatjs/formatjs) - Internationalize your web apps\n- [react-i18next](https://github.com/i18next/react-i18next) - Internationalization for React done right\n\n#### React Graphics and Animations\n\n- [react-spring](https://github.com/pmndrs/react-spring) - A spring physics based React animation library\n- [framer-motion](https://github.com/framer/motion) - Open source, production-ready animation and gesture library for React\n- [auto-animate](https://github.com/formkit/auto-animate) - A zero-config, drop-in animation utility that adds smooth transitions\n- [react-tsparticles](https://github.com/matteobruni/tsparticles) - Easily create highly customizable particles effects\n- [react-parallax-tilt](https://github.com/mkosir/react-parallax-tilt) - Easily apply tilt hover effect on React components\n- [simple-parallax-js](https://github.com/geosigno/simpleParallax.js) - The easiest way to get a parallax effect with React and JavaScript\n\n#### React Integration\n\n- [rescript-compiler](https://github.com/rescript-lang/rescript-compiler) - A robustly typed language that compiles to efficient and human-readable JavaScript\n- [react-rails](https://github.com/reactjs/react-rails) - Integrate React with Rails\n- [fulcro](https://github.com/fulcrologic/fulcro) - A library for development of web applications in clj/cljs\n- [tailwind-react](https://tw-elements.com/docs/standard/integrations/react-integration/) - Article that shows you how to integrate React application with Tailwind\n\n#### React Real Apps\n\n- [mattermost-server](https://github.com/mattermost/mattermost-server) - An open source platform for secure collaboration\n- [kibana](https://github.com/elastic/kibana) - Your window into the Elastic Stack\n- [webamp](https://github.com/captbaritone/webamp) - Winamp 2 reimplemented for the browser\n- [overreacted](https://github.com/gaearon/overreacted.io) - Personal blog by Dan Abramov\n- [wave](https://github.com/wavetermdev/waveterm) - An open-source, cross-platform terminal for seamless workflows\n\n### React Native\n\n#### React Native General Resources\n\n- [React Native Official Website](https://reactnative.dev/)\n- [React Native GitHub](https://github.com/facebook/react-native)\n- [React Native Community](https://reactnative.dev/community/overview)\n- [Expo](https://expo.dev/)\n- [Expo Snack Playground](https://snack.expo.dev/)\n\n#### React Native Navigation\n\n- [react-navigation](https://github.com/react-navigation/react-navigation) - Routing and navigation for your React Native apps\n\n#### React Native Awesome Components\n\n- [react-native-vector-icons](https://github.com/oblador/react-native-vector-icons) - Customizable Icons for React Native\n- [react-native-gifted-chat](https://github.com/FaridSafi/react-native-gifted-chat) - The most complete chat UI for React Native\n\n#### React Native Libraries\n\n- [realm-js](https://github.com/realm/realm-js) - A mobile database: an alternative to SQLite & key-value stores\n- [react-native-device-info](https://github.com/react-native-device-info/react-native-device-info) - Device Information for React Native iOS and Android\n\n### Contribution\n\nThis list began as a personal compilation of interesting things related to React. When it was initiated, React was still in beta, a special script was required to convert JSX to JS, and Flux had not yet been released. Today, React has become mainstream, with numerous developments taking place. Kindly refrain from using this list as an advertisement board or a space to promote your experiments. We focus on sharing entirely free resources here. Please feel free to propose updates for outdated projects and articles, as well as new contributions. Your input and suggestions are wholeheartedly♡ appreciated. (✿◠‿◠)\n\n[![CC0](https://i.creativecommons.org/l/by/4.0/88x31.png)](http://creativecommons.org/licenses/by/4.0/)\n"
        }
      ]
    }
  ]
}