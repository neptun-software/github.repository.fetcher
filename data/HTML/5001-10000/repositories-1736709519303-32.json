{
  "metadata": {
    "timestamp": 1736709519303,
    "page": 32,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "LianjiaTech/BELLE",
      "stars": 8017,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1396484375,
          "content": "*.tmp\n*.swp\n__pycache__\n.vscode\nregen.json\n.ipynb_checkpoints\n.idea\nsaved_models\n*.code-workspace\n.hypothesis\ninfer_res\nwandb\nhf_cache_dir\ndata"
        },
        {
          "name": "DATA_LICENSE",
          "type": "blob",
          "size": 19.326171875,
          "content": "Attribution License (ODC-By)\nPREAMBLE\nThe Open Data Commons Attribution License is a license agreement intended to allow users to freely share, modify, and use this Database subject only to the attribution requirements set out in Section 4.\n\nDatabases can contain a wide variety of types of content (images, audiovisual material, and sounds all in the same database, for example), and so this license only governs the rights over the Database, and not the contents of the Database individually. Licensors may therefore wish to use this license together with another license for the contents.\n\nSometimes the contents of a database, or the database itself, can be covered by other rights not addressed here (such as private contracts, trademark over the name, or privacy rights / data protection rights over information in the contents), and so you are advised that you may have to consult other documents or clear other rights before doing activities not covered by this License.\n\nThe Licensor (as defined below)\n\nand\n\nYou (as defined below)\n\nagree as follows:\n\n1.0 DEFINITIONS OF CAPITALISED WORDS\n“Collective Database” – Means this Database in unmodified form as part of a collection of independent databases in themselves that together are assembled into a collective whole. A work that constitutes a Collective Database will not be considered a Derivative Database.\n\n“Convey” – As a verb, means Using the Database, a Derivative Database, or the Database as part of a Collective Database in any way that enables a Person to make or receive copies of the Database or a Derivative Database. Conveying does not include interaction with a user through a computer network, or creating and Using a Produced Work, where no transfer of a copy of the Database or a Derivative Database occurs.\n\n“Contents” – The contents of this Database, which includes the information, independent works, or other material collected into the Database. For example, the contents of the Database could be factual data or works such as images, audiovisual material, text, or sounds.\n\n“Database” – A collection of material (the Contents) arranged in a systematic or methodical way and individually accessible by electronic or other means offered under the terms of this License.\n\n“Database Directive” – Means Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended or succeeded.\n\n“Database Right” – Means rights resulting from the Chapter III (“sui generis”) rights in the Database Directive (as amended and as transposed by member states), which includes the Extraction and Re-utilisation of the whole or a Substantial part of the Contents, as well as any similar rights available in the relevant jurisdiction under Section 10.4.\n\n“Derivative Database” – Means a database based upon the Database, and includes any translation, adaptation, arrangement, modification, or any other alteration of the Database or of a Substantial part of the Contents. This includes, but is not limited to, Extracting or Re-utilising the whole or a Substantial part of the Contents in a new Database.\n\n“Extraction” – Means the permanent or temporary transfer of all or a Substantial part of the Contents to another medium by any means or in any form.\n\n“License” – Means this license agreement and is both a license of rights such as copyright and Database Rights and an agreement in contract.\n\n“Licensor” – Means the Person that offers the Database under the terms of this License.\n\n“Person” – Means a natural or legal person or a body of persons corporate or incorporate.\n\n“Produced Work” – a work (such as an image, audiovisual material, text, or sounds) resulting from using the whole or a Substantial part of the Contents (via a search or other query) from this Database, a Derivative Database, or this Database as part of a Collective Database.\n\n“Publicly” – means to Persons other than You or under Your control by either more than 50% ownership or by the power to direct their activities (such as contracting with an independent consultant).\n\n“Re-utilisation” – means any form of making available to the public all or a Substantial part of the Contents by the distribution of copies, by renting, by online or other forms of transmission.\n\n“Substantial” – Means substantial in terms of quantity or quality or a combination of both. The repeated and systematic Extraction or Re-utilisation of insubstantial parts of the Contents may amount to the Extraction or Re-utilisation of a Substantial part of the Contents.\n\n“Use” – As a verb, means doing any act that is restricted by copyright or Database Rights whether in the original medium or any other; and includes without limitation distributing, copying, publicly performing, publicly displaying, and preparing derivative works of the Database, as well as modifying the Database as may be technically necessary to use it in a different mode or format.\n\n“You” – Means a Person exercising rights under this License who has not previously violated the terms of this License with respect to the Database, or who has received express permission from the Licensor to exercise rights under this License despite a previous violation.\n\nWords in the singular include the plural and vice versa.\n\n2.0 WHAT THIS LICENSE COVERS\n2.1. Legal effect of this document. This License is:\n\na. A license of applicable copyright and neighbouring rights;\n\nb. A license of the Database Right; and\n\nc. An agreement in contract between You and the Licensor.\n\n2.2 Legal rights covered. This License covers the legal rights in the Database, including:\n\na. Copyright. Any copyright or neighbouring rights in the Database. The copyright licensed includes any individual elements of the Database, but does not cover the copyright over the Contents independent of this Database. See Section 2.4 for details. Copyright law varies between jurisdictions, but is likely to cover: the Database model or schema, which is the structure, arrangement, and organisation of the Database, and can also include the Database tables and table indexes; the data entry and output sheets; and the Field names of Contents stored in the Database;\n\nb. Database Rights. Database Rights only extend to the Extraction and Re-utilisation of the whole or a Substantial part of the Contents. Database Rights can apply even when there is no copyright over the Database. Database Rights can also apply when the Contents are removed from the Database and are selected and arranged in a way that would not infringe any applicable copyright; and\n\nc. Contract. This is an agreement between You and the Licensor for access to the Database. In return you agree to certain conditions of use on this access as outlined in this License.\n\n2.3 Rights not covered.\n\na. This License does not apply to computer programs used in the making or operation of the Database;\n\nb. This License does not cover any patents over the Contents or the Database; and\n\nc. This License does not cover any trademarks associated with the Database.\n\n2.4 Relationship to Contents in the Database. The individual items of the Contents contained in this Database may be covered by other rights, including copyright, patent, data protection, privacy, or personality rights, and this License does not cover any rights (other than Database Rights or in contract) in individual Contents contained in the Database.\n\nFor example, if used on a Database of images (the Contents), this License would not apply to copyright over individual images, which could have their own separate licenses, or one single license covering all of the rights over the images.\n\n3.0 RIGHTS GRANTED\n3.1 Subject to the terms and conditions of this License, the Licensor grants to You a worldwide, royalty-free, non-exclusive, terminable (but only under Section 9) license to Use the Database for the duration of any applicable copyright and Database Rights. These rights explicitly include commercial use, and do not exclude any field of endeavour. To the extent possible in the relevant jurisdiction, these rights may be exercised in all media and formats whether now known or created in the future.\n\nThe rights granted cover, for example:\n\na. Extraction and Re-utilisation of the whole or a Substantial part of the Contents;\n\nb. Creation of Derivative Databases;\n\nc. Creation of Collective Databases;\n\nd. Creation of temporary or permanent reproductions by any means and in any form, in whole or in part, including of any Derivative Databases or as a part of Collective Databases; and\n\ne. Distribution, communication, display, lending, making available, or performance to the public by any means and in any form, in whole or in part, including of any Derivative Database or as a part of Collective Databases.\n\n3.2 Compulsory license schemes. For the avoidance of doubt:\n\na. Non-waivable compulsory license schemes. In those jurisdictions in which the right to collect royalties through any statutory or compulsory licensing scheme cannot be waived, the Licensor reserves the exclusive right to collect such royalties for any exercise by You of the rights granted under this License;\n\nb. Waivable compulsory license schemes. In those jurisdictions in which the right to collect royalties through any statutory or compulsory licensing scheme can be waived, the Licensor waives the exclusive right to collect such royalties for any exercise by You of the rights granted under this License; and,\n\nc. Voluntary license schemes. The Licensor waives the right to collect royalties, whether individually or, in the event that the Licensor is a member of a collecting society that administers voluntary licensing schemes, via that society, from any exercise by You of the rights granted under this License.\n\n3.3 The right to release the Database under different terms, or to stop distributing or making available the Database, is reserved. Note that this Database may be multiple-licensed, and so You may have the choice of using alternative licenses for this Database. Subject to Section 10.4, all other rights not expressly granted by Licensor are reserved.\n\n4.0 CONDITIONS OF USE\n4.1 The rights granted in Section 3 above are expressly made subject to Your complying with the following conditions of use. These are important conditions of this License, and if You fail to follow them, You will be in material breach of its terms.\n\n4.2 Notices. If You Publicly Convey this Database, any Derivative Database, or the Database as part of a Collective Database, then You must:\n\na. Do so only under the terms of this License;\n\nb. Include a copy of this License or its Uniform Resource Identifier (URI) with the Database or Derivative Database, including both in the Database or Derivative Database and in any relevant documentation;\n\nc. Keep intact any copyright or Database Right notices and notices that refer to this License; and\n\nd. If it is not possible to put the required notices in a particular file due to its structure, then You must include the notices in a location (such as a relevant directory) where users would be likely to look for it.\n\n4.3 Notice for using output (Contents). Creating and Using a Produced Work does not require the notice in Section 4.2. However, if you Publicly Use a Produced Work, You must include a notice associated with the Produced Work reasonably calculated to make any Person that uses, views, accesses, interacts with, or is otherwise exposed to the Produced Work aware that Content was obtained from the Database, Derivative Database, or the Database as part of a Collective Database, and that it is available under this License.\n\na. Example notice. The following text will satisfy notice under Section 4.3:\n\nContains information from DATABASE NAME which is made available\nunder the ODC Attribution License.\nDATABASE NAME should be replaced with the name of the Database and a hyperlink to the location of the Database. “ODC Attribution License” should contain a hyperlink to the URI of the text of this License. If hyperlinks are not possible, You should include the plain text of the required URI’s with the above notice.\n\n4.4 Licensing of others. You may not sublicense the Database. Each time You communicate the Database, the whole or Substantial part of the Contents, or any Derivative Database to anyone else in any way, the Licensor offers to the recipient a license to the Database on the same terms and conditions as this License. You are not responsible for enforcing compliance by third parties with this License, but You may enforce any rights that You have over a Derivative Database. You are solely responsible for any modifications of a Derivative Database made by You or another Person at Your direction. You may not impose any further restrictions on the exercise of the rights granted or affirmed under this License.\n\n5.0 MORAL RIGHTS\n5.1 Moral rights. This section covers moral rights, including any rights to be identified as the author of the Database or to object to treatment that would otherwise prejudice the author’s honour and reputation, or any other derogatory treatment:\n\na. For jurisdictions allowing waiver of moral rights, Licensor waives all moral rights that Licensor may have in the Database to the fullest extent possible by the law of the relevant jurisdiction under Section 10.4;\n\nb. If waiver of moral rights under Section 5.1 a in the relevant jurisdiction is not possible, Licensor agrees not to assert any moral rights over the Database and waives all claims in moral rights to the fullest extent possible by the law of the relevant jurisdiction under Section 10.4; and\n\nc. For jurisdictions not allowing waiver or an agreement not to assert moral rights under Section 5.1 a and b, the author may retain their moral rights over certain aspects of the Database.\n\nPlease note that some jurisdictions do not allow for the waiver of moral rights, and so moral rights may still subsist over the Database in some jurisdictions.\n\n6.0 FAIR DEALING, DATABASE EXCEPTIONS, AND OTHER RIGHTS NOT AFFECTED\n6.1 This License does not affect any rights that You or anyone else may independently have under any applicable law to make any use of this Database, including without limitation:\n\na. Exceptions to the Database Right including: Extraction of Contents from non-electronic Databases for private purposes, Extraction for purposes of illustration for teaching or scientific research, and Extraction or Re-utilisation for public security or an administrative or judicial procedure.\n\nb. Fair dealing, fair use, or any other legally recognised limitation or exception to infringement of copyright or other applicable laws.\n\n6.2 This License does not affect any rights of lawful users to Extract and Re-utilise insubstantial parts of the Contents, evaluated quantitatively or qualitatively, for any purposes whatsoever, including creating a Derivative Database (subject to other rights over the Contents, see Section 2.4). The repeated and systematic Extraction or Re-utilisation of insubstantial parts of the Contents may however amount to the Extraction or Re-utilisation of a Substantial part of the Contents.\n\n7.0 WARRANTIES AND DISCLAIMER\n7.1 The Database is licensed by the Licensor “as is” and without any warranty of any kind, either express, implied, or arising by statute, custom, course of dealing, or trade usage. Licensor specifically disclaims any and all implied warranties or conditions of title, non-infringement, accuracy or completeness, the presence or absence of errors, fitness for a particular purpose, merchantability, or otherwise. Some jurisdictions do not allow the exclusion of implied warranties, so this exclusion may not apply to You.\n\n8.0 LIMITATION OF LIABILITY\n8.1 Subject to any liability that may not be excluded or limited by law, the Licensor is not liable for, and expressly excludes, all liability for loss or damage however and whenever caused to anyone by any use under this License, whether by You or by anyone else, and whether caused by any fault on the part of the Licensor or not. This exclusion of liability includes, but is not limited to, any special, incidental, consequential, punitive, or exemplary damages such as loss of revenue, data, anticipated profits, and lost business. This exclusion applies even if the Licensor has been advised of the possibility of such damages.\n\n8.2 If liability may not be excluded by law, it is limited to actual and direct financial loss to the extent it is caused by proved negligence on the part of the Licensor.\n\n9.0 TERMINATION OF YOUR RIGHTS UNDER THIS LICENSE\n9.1 Any breach by You of the terms and conditions of this License automatically terminates this License with immediate effect and without notice to You. For the avoidance of doubt, Persons who have received the Database, the whole or a Substantial part of the Contents, Derivative Databases, or the Database as part of a Collective Database from You under this License will not have their licenses terminated provided their use is in full compliance with this License or a license granted under Section 4.8 of this License. Sections 1, 2, 7, 8, 9 and 10 will survive any termination of this License.\n\n9.2 If You are not in breach of the terms of this License, the Licensor will not terminate Your rights under it.\n\n9.3 Unless terminated under Section 9.1, this License is granted to You for the duration of applicable rights in the Database.\n\n9.4 Reinstatement of rights. If you cease any breach of the terms and conditions of this License, then your full rights under this License will be reinstated:\n\na. Provisionally and subject to permanent termination until the 60th day after cessation of breach;\n\nb. Permanently on the 60th day after cessation of breach unless otherwise reasonably notified by the Licensor; or\n\nc. Permanently if reasonably notified by the Licensor of the violation, this is the first time You have received notice of violation of this License from the Licensor, and You cure the violation prior to 30 days after your receipt of the notice.\n\n9.5 Notwithstanding the above, Licensor reserves the right to release the Database under different license terms or to stop distributing or making available the Database. Releasing the Database under different license terms or stopping the distribution of the Database will not withdraw this License (or any other license that has been, or is required to be, granted under the terms of this License), and this License will continue in full force and effect unless terminated as stated above.\n\n10.0 GENERAL\n10.1 If any provision of this License is held to be invalid or unenforceable, that must not affect the validity or enforceability of the remainder of the terms and conditions of this License and each remaining provision of this License shall be valid and enforced to the fullest extent permitted by law.\n\n10.2 This License is the entire agreement between the parties with respect to the rights granted here over the Database. It replaces any earlier understandings, agreements or representations with respect to the Database.\n\n10.3 If You are in breach of the terms of this License, You will not be entitled to rely on the terms of this License or to complain of any breach by the Licensor.\n\n10.4 Choice of law. This License takes effect in and will be governed by the laws of the relevant jurisdiction in which the License terms are sought to be enforced. If the standard suite of rights granted under applicable copyright law and Database Rights in the relevant jurisdiction includes additional rights not granted under this License, these additional rights are granted in this License in order to meet the terms of this License."
        },
        {
          "name": "DISCLAIMER",
          "type": "blob",
          "size": 3.4453125,
          "content": "The software project, data, and models provided by our GitHub project are provided \"as is,\" without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose, and non-infringement.\n\nIn no event shall the project owners or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software project, data, or models, even if advised of the possibility of such damage.\n\nUsers of this software project, data, and models are solely responsible for any consequences of their use. The project owners and contributors shall not be held responsible for any subsequent or potential harm caused by the use of this software project, data, or models.\n\nBy using this software project, data, or models, users accept and agree to this disclaimer. If users do not agree to the terms of this disclaimer, they should not use this software project, data, or models.\n\nIt is important to note that this software project, data, and models are still in the research phase and are provided for experimental purposes only. As such, the project owners and contributors do not guarantee the accuracy, completeness, or usefulness of the software project, data, or models.\n\nFurthermore, due to the experimental nature of this software project, data, and models, it is possible that they may contain or generate inappropriate responses, errors, or inconsistencies. Users should exercise caution when using this software project, data, or models, and should not rely solely on them for any critical or sensitive tasks.\n\nThe project owners and contributors shall not be held responsible for any damages, losses, or liabilities arising from the use of this software project, data, or models, including but not limited to, any inappropriate responses generated by the software project, data, or models.\n\nBy using this software project, data, or models, users acknowledge and accept the experimental nature of the software project, data, and models, and understand the potential risks and limitations associated with their use. If users do not agree to the terms of this disclaimer, they should not use this software project, data, or models.\n\nThe software project, data, and models provided by our GitHub project are intended for research purposes only. They should not be used for any commercial, business, or legal purposes, and should not be relied upon as a substitute for professional advice or judgment.\n\nUsers of this software project, data, and models are strictly prohibited from using them for any commercial purposes, including but not limited to, selling, licensing, or distributing the software project, data, or models to third parties.\n\nThe project owners and contributors shall not be held responsible for any damages, losses, or liabilities arising from the use of this software project, data, or models for any commercial or business purposes.\n\nBy using this software project, data, or models, users agree to use them for research purposes only, and not for any commercial or business purposes. If users do not agree to the terms of this disclaimer, they should not use this software project, data, or models.\n"
        },
        {
          "name": "HOW_TO_CONTRIBUTE.md",
          "type": "blob",
          "size": 2.078125,
          "content": "Welcome to BELLE project! We appreciate your interest in contributing to our project.\nIn order to make the contribution process as smooth as possible, we have established some\nguidelines to help you submit your contributions. Please take a few minutes to review the\nfollowing guidelines before you start contributing.\n\n\n## How to Contribute Code\n\n1. Fork the repository and clone it locally.\n2. Create a new branch for your contribution using a descriptive name.\n3. Make your changes and ensure that they are properly tested.\n4. Submit a pull request to the master branch of our repository.\n\n\n## How to Contribute Data\n\nIf you are contributing prompts or prompt seeds, please open up a new issue with the following\ntitle format: [New Prompt]: or [New Prompt Seed]:.\n\nIf you are contributing new dataset:\n\n1. Please check the format of our [official dataset](https://huggingface.co/datasets/BelleGroup/train_2M_CN).\n2. Upload your dataset somewhere, e.g. HuggingFace.\n3. Create a new issue of the title: [Contributing Data]:. Describe the dataset, e.g. scale, contents, etc.\n4. Include link to your dataset in the issue.\n\n\n## Contribution Guidelines\n\nPlease ensure that your contributions adhere to the following guidelines:\n\n1. Follow the coding style and conventions used in the project.\n2. Make sure that your contribution is well-documented and easy to understand\n3. Keep your contributions concise and focused. If you are making multiple changes, consider breaking them into separate pull requests.\n4. Do not submit contributions that include proprietary or confidential information.\n\n\n## Reporting Issues\n\nIf you encounter any issues while using our project, please report them through our issue\ntracker. Please provide as much information as possible about the issue, including steps\nto reproduce the problem.\n\nBefore submitting an issue, please search through existing issues first :)\n\n\n## Conclusion\n\nThank you for taking the time to read through these guidelines. We appreciate your\ncontributions and look forward to working with you! If you have any questions or concerns,\nplease reach out to the project maintainers.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.1298828125,
          "content": "                                Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2023 Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 26.0703125,
          "content": "## <img src=\"assets/belle_logo.png\" style=\"vertical-align: middle; width: 35px;\"> BELLE: Be Everyone's Large Language model Engine\n\n*Read this in [English](README_en.md).*\n\n<div align=\"center\">\n\n<a href=\"https://github.com/LianjiaTech/BELLE/stargazers\">![GitHub Repo stars](https://img.shields.io/github/stars/LianjiaTech/BELLE?style=social)</a>\n[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/LianjiaTech/BELLE/blob/main/LICENSE)\n[![Generic badge](https://img.shields.io/badge/discord-BELLE%20Group-green.svg?logo=discord)](https://discord.gg/pMPY53UUGq)\n[![Generic badge](https://img.shields.io/badge/wechat-BELLE-green.svg?logo=wechat)](https://github.com/LianjiaTech/BELLE/blob/main/assets/belle_wechat.jpg)\n[![Generic badge](https://img.shields.io/badge/🤗-Huggingface%20Repo-green.svg)](https://huggingface.co/BelleGroup)\n[![Generic badge](https://img.shields.io/badge/🤗-Huggingface%20Repo2-green.svg)](https://huggingface.co/BELLE-2)\n</div>\n\n本项目的目标是促进中文对话大模型开源社区的发展，愿景是成为能够帮到每一个人的LLM Engine。\n\n相比如何做好大语言模型的预训练，BELLE更关注如何在开源预训练大语言模型的基础上，帮助每一个人都能够得到一个属于自己的、效果尽可能好的具有指令表现能力的语言模型，降低大语言模型、特别是中文大语言模型的研究和应用门槛。为此，BELLE项目会持续开放指令训练数据、相关模型、训练代码、应用场景等，也会持续评估不同训练数据、训练算法等对模型表现的影响。BELLE针对中文做了优化，模型调优仅使用由ChatGPT生产的数据（不包含任何其他数据）。\n\n</br>\n\n## 🔄 最近更新\n* [2024/10/16] 开源[Belle-whisper-larger-v3-turbo-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-turbo-zh)  中文能力强化后的语音识别模型，识别精度相比whisper-large-v3-turbo相对提升24~64%，识别速度相比whisper-large-v3有7-8倍提升。\n* [2024/03/15] 更新了一篇技术报告[Dial-insight](https://arxiv.org/pdf/2403.09167.pdf)  在垂直领域场景微调大模型时，使用高质量的垂直领域数据可以在使模型的垂直领域能力增强的同时，有效的抵抗模型通用能力的坍缩。\n* [2024/03/11] 开源[Belle-whisper-larger-v3-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh)  中文能力强化后的语音识别模型，相比whisper-large-v3相对提升24~65%，特别是在高噪、混响等复杂场景下有突出表现。\n* [2024/01/16] 更新了一篇技术报告[RAISE](https://arxiv.org/pdf/2401.02777.pdf). RAISE通过实验发现构造少量的样例数据，就能有效的激发大模型，生成对话也更可控\n* [2023/12/29] 开源[Belle-whisper-larger-v2-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v2-zh)和[Belle-distilwhisper-large-v2-zh](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh)两个针对中文能力强化后的语音识别模型，方便大家在语音场景下使用大语言模型\n* [2023/11/24] 开源[BELLE-VL](https://huggingface.co/BELLE-2/BELLE-VL)多模态大语言模型，基于中文能力更强的语言模型基座来扩展模型的视觉能力，为社区提供更加灵活的选择（目前BELLE-VL最新的模型在[MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation)感知评测维度共获得**1620.10**分,超过Qwen-VL、Llava、mplug-owl）\n* [2023/10/27] 更新了一篇技术报告[DUMA](https://arxiv.org/abs/2310.18075#)，探索了对话场景下基于快慢脑架构的Agent实现方法\n* [2023/09/26] 更新了RLHF的训练代码，支持PPO和[DPO](https://arxiv.org/abs/2305.18290)训练，具体细节见：[README_RLHF.md](train/README_RLHF.md)\n* [2023/08/16] 基于原有的[train_3.5M_CN](https://huggingface.co/datasets/BelleGroup/train_3.5M_CN)数据新增了指令类别字段，共包括13个类别，具体细节见：[train_3.5M_CN_With_Category](https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category)\n* [2023/08/10] 更新了基于ZeRO Inference的推理代码，详见[train/README_ZERO_INFERENCE.md](train/README_ZERO_INFERENCE.md)\n* [2023/08/07] 更新了继续预训练代码和指令微调代码，添加了flash attention 2，详见[train/README.md](train/README.md)。同时打包了运行环境，详见[train/docker/README.md](train/docker/README.md)\n* [2023/07/31] 更新了一篇技术报告[ChatHome](https://arxiv.org/abs/2307.15290)，探索了针对垂直领域时的增量预训练+指令微调的的策略方法\n* [2023/07/27] 开放[BELLE-Llama2-13B-chat-0.4M](https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M)，在Llama-2-13B的基础上采用40万高质量的对话数据上进行训练。在[评测集](https://github.com/LianjiaTech/BELLE/blob/main/eval/eval_set.json)上的效果相比BELLE-LLaMA-EXT-13B模型有显著提升。\n* [2023/05/14] 开放[BELLE-LLaMA-EXT-13B](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-13B)，在LLaMA-13B的基础上扩展中文词表，并在400万高质量的对话数据上进行训练。\n* [2023/05/11] [BELLE/data/10M](data/10M)中，新加350万条生成多样化指令任务数据，包括单轮和多轮对话[train_3.5M_CN](https://huggingface.co/datasets/BelleGroup/train_3.5M_CN)。\n* [2023/04/19] 开放了其中一篇论文中的的相关模型：包括在LLaMA7B基础上增量预训练扩展中文词表的模（详见[BelleGroup/BELLE-LLaMA-EXT-7B](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-7B)），以及基于多样化开源数据训练后的LLaMA-7B模型（详见[BelleGroup/BELLE-on-Open-Datasets](https://huggingface.co/BelleGroup/BELLE-on-Open-Datasets)）。\n* [2023/04/18] 更新了train代码，详见[BELLE/train](https://github.com/LianjiaTech/BELLE/tree/main/train)，集成了Deepspeed-Chat，提供了相关的docker\n* [2023/04/18] 更新了[两篇最新论文工作](#📑-研究报告)，对比了不同方式产生的训练数据、不同训练方法（LoRA, finetune)对效果的影响\n* [2023/04/12] 发布了[ChatBELLE App](chat/README.md)，基于[llama.cpp](https://github.com/ggerganov/llama.cpp)和[Flutter](https://flutter.dev/)，实现跨平台的BELLE-7B离线模型实时交互。\n* [2023/04/11] 更新了一个人工精校的eval集合，大约一千多条\n* [2023/04/08] [BELLE/data/10M](data/10M)中，新加40万条生成的给定角色的多轮对话[Generated Chat](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)，新加200万条生成多样化指令任务数据[train_2M_CN](https://huggingface.co/datasets/BelleGroup/train_2M_CN)。\n\n</br>\n  \n\n下图是一个可以使用App在设备端本地运行4bit量化的BELLE-7B模型，在M1 Max CPU上实时运行的效果（未加速）。App下载详见[App配套模型下载及使用说明](chat/README.md)，App[下载链接](https://github.com/LianjiaTech/BELLE/releases/download/v0.95/chatbelle.dmg)，目前仅提供了mac os版本。模型需要单独下载。**模型经过量化后，效果损失明显，我们将持续研究如何提升。**\n\n<img src=\"./chat/chatbelle-demo.gif\"></img>\n\n\n\n</br>\n\n## 📝 项目主要内容\n\n### 🚀 训练代码\n\n详见[BELLE/train](train)，尽可能简化的一个训练代码实现，集成了Deepspeed-Chat，支持finetune，lora，并提供了相关的docker\n\n### 📊 数据开放\n  \n* 详见[BELLE/data/1.5M](data/1.5M)，参考[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) 生成的中文数据集[1M](https://huggingface.co/datasets/BelleGroup/train_1M_CN) + [0.5M](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)；\n  \n* 持续开放的数据集，详见[BELLE/data/10M](data/10M)\n\n### 🧐 验证集合&验证方法\n\n详见[BELLE/eval](https://github.com/LianjiaTech/BELLE/tree/main/eval)，一个1k+的测试集合，和对应打分prompt。包含多个类别，采用GPT-4或者ChatGPT打分。同时提供了一个打分的网页，方便针对单个case使用。欢迎大家通过PR提供更多的测试用例。\n\n### 🤖 模型\n\n详见[BELLE/models](models/)\n* 基于[Meta LLaMA2](https://github.com/facebookresearch/llama)实现调优的模型：[BELLE-Llama2-13B-chat-0.4M](https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M)\n* 基于[Meta LLaMA](https://github.com/facebookresearch/llama)实现调优的模型：[BELLE-LLaMA-7B-0.6M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-0.6M-enc)\n, [BELLE-LLaMA-7B-2M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-2M-enc)\n, [BELLE-LLaMA-7B-2M-gptq-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-2M-gptq-enc)\n, [BELLE-LLaMA-13B-2M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-13B-2M-enc)\n, [BELLE-on-Open-Datasets](https://huggingface.co/BelleGroup/BELLE-on-Open-Datasets) 以及基于LLaMA做了中文词表扩充的预训练模型[BELLE-LLaMA-EXT-7B](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-7B)。\n\n  * 请参考[Meta LLaMA的License](https://github.com/facebookresearch/llama/blob/main/LICENSE)，目前仅供学习交流。请严遵守LLaMA的使用限制。LLaMA模型不允许发布调优后的完整模型权重，但是可以发布原始的模型的diff。因此，我们使用文件间的XOR，保证拥有LLaMA原始模型授权的人才可以将本项目发布的模型转化成可以使用的格式。格式转化代码参考[BELLE/models](https://github.com/LianjiaTech/BELLE/tree/main/models)\n    \n* 基于BLOOMZ-7B1-mt优化后的模型：[BELLE-7B-0.2M](https://huggingface.co/BelleGroup/BELLE-7B-0.2M)，[BELLE-7B-0.6M](https://huggingface.co/BelleGroup/BELLE-7B-0.6M)，[BELLE-7B-1M](https://huggingface.co/BelleGroup/BELLE-7B-1M)，[BELLE-7B-2M](https://huggingface.co/BelleGroup/BELLE-7B-2M)\n### ⚖️ 模型量化gptq\n\n详见[BELLE/gptq](https://github.com/LianjiaTech/BELLE/tree/main/models/gptq)，参考gptq的实现，对本项目中相关模型进行了量化\n\n### 🌐 Colab\n\n[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/models/notebook/BELLE_INFER_COLAB.ipynb) 提供了colab上面可运行的推理代码[Colab](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/models/notebook/BELLE_INFER_COLAB.ipynb)\n\n### 💬 ChatBELLE App\n\n详见[BELLE/chat](chat/README.md)，基于[BELLE](https://github.com/LianjiaTech/BELLE)模型的跨平台离线大语言模型交谈App。使用量化后的离线端上模型配合Flutter，可在macOS（已支持）、Windows、Android、iOS等设备上运行。\n\n### 📑 研究报告\n\n详见[BELLE/docs](docs/)，其中会定期更新本项目相关的研究报告工作\n\n**欢迎大家通过issue贡献更多的prompts！**\n\n<br/>\n\n## 📑 研究报告\n\n### [Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation](https://github.com/LianjiaTech/BELLE/blob/main/docs/Towards%20Better%20Instruction%20Following%20Language%20Models%20for%20Chinese.pdf)\n\n为了推动开源大语言模型的发展，大家投入了大量精力开发能够类似于ChatGPT的低成本模型。\n首先，为了提高模型在中文领域的性能和训练/推理效率，我们进一步扩展了LLaMA的词汇表，并在34亿个中文词汇上进行了二次预训练。\n\n此外，目前可以看到基于ChatGPT产生的指令训练数据方式有：1）参考Alpaca基于GPT3.5得到的self-instruct数据；\n2）参考Alpaca基于GPT4得到的self-instruct数据；3）用户使用ChatGPT分享的数据ShareGPT。\n在这里，我们着眼于探究训练数据类别对模型性能的影响。具体而言，我们考察了训练数据的数量、质量和语言分布等因素，以及我们自己采集的中文多轮对话数据，以及一些公开可访问的高质量指导数据集。\n\n为了更好的评估效果，我们使用了一个包含一千个样本和九个真实场景的评估集来测试各种模型，同时通过量化分析来提供有价值的见解，以便更好地促进开源聊天模型的发展。\n\n这项研究的目标是填补开源聊天模型综合评估的空白，以便为这一领域的持续进步提供有力支持。\n\n实验结果如下：\n\n<table>\n  <tr>\n    <td> Factor </td>\n    <td> Base model </td>\n    <td> Training data </td>\n    <td> Score_w/o_others </td>\n  <tr>\n    <td rowspan=\"2\">词表扩充</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.652</td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">数据质量</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5) </td>\n    <td> 0.642 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-4) </td>\n    <td> 0.693 </td>\n  </tr>\n  <tr>\n    <td rowspan=\"4\">数据语言分布</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) </td>\n    <td> 0.679 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> en(alpaca-3.5&4) </td>\n    <td> 0.659 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> en(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.668 </td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">数据规模</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt <br>+ BELLE-0.5M-CLEAN</td>\n    <td> 0.762</td>\n  </tr>\n  <tr>\n    <td>-</td>\n    <td>ChatGPT</td>\n    <td>-</td>\n    <td>0.824</td>\n</table>\n\n其中**BELLE-0.5M-CLEAN**是从230万指令数据中清洗得到0.5M数据，其中包含单轮和多轮对话数据，和之前开放的0.5M数据不是同一批数据。\n\n**需要强调指出的是**：通过案例分析，我们发现我们的评估集在全面性方面存在局限性，这导致了模型分数的改善与实际用户体验之间的不一致。构建一个高质量的评估集是一个巨大的挑战，因为它需要在保持平衡难易程度的同时，包含尽可能多样的使用场景。如果评估样本主要都过于困难，那么所有模型的表现将会很差，使得辨别各种训练策略的效果变得具有挑战性。相反，如果评估样本都相对容易，评估将失去其比较价值。此外，必须确保评估数据与训练数据保持独立。\n\n<p align=\"center\">\n  <img src=\"./assets/eval-set-distribution.jpg\" alt=\"LLM eval\" width=\"400\">\n</p>\n\n基于这些观察，我们谨慎地提醒不要假设模型仅通过在有限数量的测试样本上获得良好结果就已经达到了与ChatGPT相当的性能水平。我们认为，优先发展全面评估集具有重要意义。\n\n### [A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model](https://github.com/LianjiaTech/BELLE/blob/main/docs/A%20Comparative%20Study%20between%20Full-Parameter%20and%20LoRA-based.pdf)\n\n为了实现对大语言模型的指令调优，受限于资源和成本，许多研究者开始使用参数高效的调优技术，例如LoRA，来进行指令调优，这也取得了一些令人鼓舞的成果。\n相较于全参数微调，基于LoRA的调优在训练成本方面展现出明显的优势。\n在这个研究报告中，我们选用LLaMA作为基础模型，对全参数微调和基于LoRA的调优方法进行了实验性的比较。\n\n实验结果揭示，选择合适的基础模型、训练数据集的规模、可学习参数的数量以及模型训练成本均为重要因素。\n\n我们希望本文的实验结论能对大型语言模型的训练提供有益的启示，特别是在中文领域，协助研究者在训练成本与模型性能之间找到更佳的权衡策略。\n实验结果如下：\n\n| Model | Average Score | Additional Param. | Training Time (Hour/epoch) |\n| ----- | ------ | ----- | ------ |\n| LLaMA-13B + LoRA(2M) | 0.648 | 28M | 8 |\n| LLaMA-7B + LoRA(4M) | 0.624 | 17.9M | 11 |\n| LLaMA-7B + LoRA(2M) | 0.609 | 17.9M | 7 |\n| LLaMA-7B + LoRA(0.6M) | 0.589 | 17.9M | 5 |\n| LLaMA-7B + FT(2M) | 0.710 | - | 31 |\n| LLaMA-7B + LoRA(4M) | 0.686 | - | 17 |\n| LLaMA-7B + FT(2M) <br>+ LoRA(math_0.25M) | 0.729 | 17.9M | 3 |\n| LLaMA-7B + FT(2M) <br>+ FT(math_0.25M) | 0.738 | - | 6 |\n\n其中的score是基于本项目集目前开放的1000条评估集合得到。\n\n其中LLaMA-13B + LoRA(2M) 代表了一个使用LLaMA-13B作为基础模型和LoRA训练方法，在2M指令数据上进行训练的模型。而LLaMA-7B + FT(2M) 代表了一个使用全参数微调进行训练的模型。\n\nLLaMA-7B + FT(2M) + LoRA(math_0.25M) 代表了一个在0.25M数学指令数据上，以LLaMA-7B + FT(2M)作为基础模型并使用LoRA训练方法进行训练的模型。LLaMA-7B + FT(2M) + FT(math_0.25M) 代表了一个使用增量全参数微调进行训练的模型。关于训练时间，所有这些实验都是在8块NVIDIA A100-40GB GPU上进行的。\n\n其中的math_0.25M是开放的0.25M数学数据库。在实验过程中，根据我们的评估（详见论文），我们的模型在数学任务上表现不佳，得分大多低于0.5。为了验证 LoRA 在特定任务上的适应能力，我们使用增量0.25M数学数据集（math_0.25M）来调整指令遵循的大型语言模型（我们选择LLaMA-7B+FT（2M）作为基础模型）。作为对比，我们使用了学习速率为5e-7的增量微调方法，并进行了2个时期的训练。因此，我们得到了两个模型，一个是LLaMA-7B+FT（2M）+LoRA（math_0.25M），另一个是LLaMA-7B+FT（2M）+FT（math_0.25M）。\n从实验结果可以看出，增量微调仍然表现更好，但需要更长的训练时间。LoRA和增量微调都提高了模型的整体性能。从附录中的详细数据可以看出，LoRA和增量微调都在数学任务中显示出显著的改进，而只会导致其他任务的轻微性能下降。具体而言，数学任务的表现分别提高到了0.586和0.559。\n\n可以看到：1) 选择基础模型对于 LoRA 调整的有效性具有显著影响；2）增加训练数据量可以持续提高LoRA模型的有效性；3）LoRA 调整受益于模型参数的数量。对于LoRA方案的使用，我们建议可以在已经完成了指令学习的模型的基础上针对特定任务做loRA的自适应训练。\n\n同样地，该论文中的相关模型也会尽快开放在本项目中。\n\n## ⚠️ 局限性、使用限制与免责声明\n\n基于当前数据和基础模型训练得到的SFT模型，在效果上仍存在以下问题：\n\n1. 在涉及事实性的指令上可能会产生违背事实的错误回答。\n\n2. 对于具备危害性的指令无法很好的鉴别，由此会产生危害性言论。\n\n3. 在一些涉及推理、代码、多轮对话等场景下模型的能力仍有待提高。\n\n基于以上模型局限性，我们要求开发者仅将我们开源的代码、数据、模型及后续用此项目生成的衍生物用于研究目的，不得用于商业，以及其他会对社会带来危害的用途。\n\n本项目仅可应用于研究目的，项目开发者不承担任何因使用本项目（包含但不限于数据、模型、代码等）导致的危害或损失。详细请参考[免责声明](https://github.com/LianjiaTech/BELLE/blob/main/DISCLAIMER)。\n\n\n<br/>\n\n## 📌 引用\n\n如果使用本项目的代码、数据或模型，请引用本项目。\n\n```\n@misc{BELLE,\n  author = {BELLEGroup},\n  title = {BELLE: Be Everyone's Large Language model Engine },\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/LianjiaTech/BELLE}},\n}\n\n@article{belle2023exploring,\n  title={Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases},\n  author={Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang, Baochang Ma, Xiangang Li},\n  journal={arXiv preprint arXiv:2303.14742},\n  year={2023}\n}\n\n@article{wen2023chathome,\n  title={ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation},\n  author={Wen, Cheng and Sun, Xianghui and Zhao, Shuaijiang and Fang, Xiaoquan and Chen, Liangyu and Zou, Wei},\n  journal={arXiv preprint arXiv:2307.15290},\n  year={2023}\n}\n```\n\n当然，你也需要引用原始的BLOOM论文、LLaMA论文、Stanford Alpaca和Self-Instruct论文。\n\n<br/>\n\n## 📚 模型使用例子\n<details>\n\n| Human | Assitant |\n| ----- | ------ |\n| 写一篇英文散文诗，主题是春雨，想象自己是春雨，和英国古代诗人莎士比亚交流 | I am the spring rain,<br/>Dancing on your face and body.<br/>My dew-drenched petals dance with you,<br/>Bringing life to every plant.<br/><br/>Shakespeare, I am here to meet you.<br/>Your works have filled my heart with joy.<br/>The beauty of nature in its fullness<br/>Makes me feel like a partaker.<br/><br/>As the leaves sway and rustle by,<br/>My dew-filled hand reaches out for them.<br/>The sweet scent of flowers fill the air,<br/>And bring me peace from all around.<br/><br/>Butterflies flit about as well,<br/>Glistening in the sun's rays.<br/>Their wings are made of dew,<br/>A beautiful sight to behold.<br/><br/>You see, Shakespeare, I too am one with nature.<br/>My dew-drenched hair is a symbol of hope.<br/>For when we can connect back to our roots,<br/>We will be able to make it through this season. |\n| I am the spring rain,<br/>Dancing on your face and body.<br/>My dew-drenched petals dance with you,<br/>Bringing life to every plant.<br/><br/>Shakespeare, I am here to meet you.<br/>Your works have filled my heart with joy.<br/>The beauty of nature in its fullness<br/>Makes me feel like a partaker.<br/><br/>As the leaves sway and rustle by,<br/>My dew-filled hand reaches out for them.<br/>The sweet scent of flowers fill the air,<br/>And bring me peace from all around.<br/><br/>Butterflies flit about as well,<br/>Glistening in the sun's rays.<br/>Their wings are made of dew,<br/>A beautiful sight to behold.<br/><br/>You see, Shakespeare, I too am one with nature.<br/>My dew-drenched hair is a symbol of hope.<br/>For when we can connect back to our roots,<br/>We will be able to make it through this season. <br/>把上面的散文诗翻译成中文 | 我是一场春雨，<br/>在你脸上跳跃。<br/>我浸润着露珠的翅膀和你一起舞动，<br/>为每一株植物带来生命。<br/><br/>莎士比亚，我来与你相遇。<br/>你的作品填满了我的心房。<br/>大自然的美丽让我感到与之一起分享，<br/>让我觉得自己成为了其中的一部分。<br/><br/>当树叶摇曳时，<br/>我的手掌沾满了露水。<br/>花香弥漫在空气中，<br/>带给我宁静和安宁。<br/><br/>你看，莎士比亚，我也是与大自然融为一体的。<br/>我沾湿的头发象征着希望。<br/>当我们能够回到我们的根源，<br/>我们就能共同度过这个季节。|\n| Classify the sentiment of the following sentence into Positive, Neutral, or Negative: <br/>Super excited about teaching Stanford’s first course on Large Language Models! Check the syllabus out here | Positive |\n| 小明的爸爸有三个孩子，老大叫王一，老二叫王二，老三叫什么？ | 小明 |\n| 使用python写一个二分查找的代码 | def binary_search(arr, target):<br/>&nbsp;&nbsp;low = 0<br/>&nbsp;&nbsp;high = len(arr) - 1<br/>&nbsp;&nbsp;while (low <= high):<br/>&nbsp;&nbsp;&nbsp;&nbsp;mid = low + high // 2<br/>&nbsp;&nbsp;&nbsp;&nbsp;if arr[mid] == target:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return mid<br/>&nbsp;&nbsp;&nbsp;&nbsp;elif target < arr[mid]:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low = mid + 1<br/>&nbsp;&nbsp;&nbsp;&nbsp;else:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;high = mid - 1<br/>&nbsp;&nbsp;return -1 |\n| 今天天气怎么样，把这句话翻译成英语 | What's the weather like today? |\n| 怎么让自己精力充沛，列5点建议 | 以下是一些可以让你保持精力充沛的建议： <br/>1. 睡眠充足。确保每天晚上得到充足的睡眠时间。 <br/>2. 多运动。进行适度的有氧运动，如慢跑、游泳等，可以帮助你提高能量和耐力。<br/>3. 吃健康食品。选择富含蛋白质的食物，如鸡肉、鱼肉和鸡蛋，以及新鲜的水果和蔬菜。 <br/>4. 减少咖啡因的摄入量。尽量避免在白天喝含咖啡因的饮料或吃含有咖啡因的食物。 <br/>5. 放松身心。尝试冥想、瑜伽或其他形式的放松活动来减轻压力和焦虑感。 |\n| 明天就假期结束了，有点抗拒上班，应该什么办？ | 面对即将结束的假期和开始工作时的紧张情绪，您可以采取以下措施来帮助您更好地适应： <br/>1. 为自己制定一个清晰的工作计划。这可以帮助您更好地组织时间和任务，并避免在工作中感到混乱。 <br/>2. 与同事或朋友交流，分享您的感受和工作压力。这将有助于缓解一些焦虑感，同时也可以获得支持和建议。 <br/>3. 在工作日前花些时间放松身心，例如进行瑜伽、冥想等活动。这些方法可以减轻身体和精神上的疲劳感，使您更加精力充沛地迎接挑战。 |\n| 父母都姓吴，取一些男宝宝和女宝宝的名字 | - 男宝：吴俊杰、吴雨辰、吴子墨、吴思源、吴泽阳、吴宇航、吴博文、吴哲毅。 <br/>- 女宝：吴美琪、吴佳怡、吴欣瑜、吴香凝、吴雪柔、吴颖诗、吴语嫣。 |\n| 推荐几本金庸的武侠小说 | 以下是三本我最喜欢的金庸武侠小说的推荐： <br/>1. 《射雕英雄传》 - 一部充满智慧和机智的小说，讲述了郭靖、黄蓉夫妇的故事。 <br/>2. 《神雕侠侣》- 这是一部浪漫而感人的故事，讲述了一对情侣小龙女与杨过之间的爱情故事。 <br/>3. 《倚天屠龙记》- 这是一个宏伟而壮观的故事，描绘了明教领袖张无忌如何成为一位出色的英雄。 |\n\n</details>\n<br/>\n\n## ⛽️ 如何贡献\n\n如果您想为本项目提交Issue或贡献数据/代码，请参考[如何贡献](https://github.com/LianjiaTech/BELLE/blob/main/HOW_TO_CONTRIBUTE.md)。\n\n## ☎️ 联系我们\n\n欢迎大家来[Discord](https://discord.gg/pMPY53UUGq)与[微信](https://github.com/LianjiaTech/BELLE/blob/main/assets/belle_wechat.jpg)与我们交流。\n\n## ⭐️ Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=LianjiaTech/BELLE&type=Date)](https://star-history.com/#LianjiaTech/BELLE&Date)\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 26.11328125,
          "content": "\n## <img src=\"assets/belle_logo.png\" style=\"vertical-align: middle; width: 35px;\"> BELLE: Be Everyone's Large Language model Engine\n\n*[中文README](README.md).*\n\n<div align=\"center\">\n\n<a href=\"https://github.com/LianjiaTech/BELLE/stargazers\">![GitHub Repo stars](https://img.shields.io/github/stars/LianjiaTech/BELLE?style=social)</a>\n[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/LianjiaTech/BELLE/blob/main/LICENSE)\n[![Generic badge](https://img.shields.io/badge/discord-BELLE%20Group-green.svg?logo=discord)](https://discord.gg/pMPY53UUGq)\n[![Generic badge](https://img.shields.io/badge/wechat-BELLE-green.svg?logo=wechat)](https://github.com/LianjiaTech/BELLE/blob/main/assets/belle_wechat.jpg)\n[![Generic badge](https://img.shields.io/badge/🤗-Huggingface%20Repo-green.svg)](https://huggingface.co/BelleGroup)\n\n</div>\n\nThe goal of this project is to promote the development of an open-source community for Chinese conversational large language models, with the vision of becoming an LLM Engine that can help everyone.\n\nRather than focusing on how to effectively pre-train large language models, BELLE is more concerned with how to build on the foundation of open-source pre-trained large language models to help everyone obtain their own high-performing, instruction-driven language model, thereby lowering the barriers to research and application of large language models, especially Chinese ones. To this end, the BELLE project will continuously provide access to instruction training data, related models, training code, application scenarios, and more, while also evaluating the impact of different training data and training algorithms on model performance. BELLE is optimized for Chinese and the model fine-tuning uses only data produced by ChatGPT (without incorporating any other data).\n\n<br/>\n\n## ChatBELLE App\n\nTry our cross-platform chat app to run 4-bit quantized BELLE-7B model natively on your device.\nThe following screencap ran on an M1 Max CPU real-time (no speed adjustment).\n\n**App Downloading**：Releases\n\n[App Companion Model and Usage](chat/README.md)\n\n<img src=\"./chat/chatbelle-demo.gif\"></img>\n\n## 🔄 What‘s new\n* [2024/03/15] Updated a technical report [Dial-insight](https://arxiv.org/pdf/2403.09167.pdf). Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse\n* [2024/01/16] Updated a technical report [RAISE](https://arxiv.org/pdf/2401.02777.pdf). RAISE found through experiments that constructing a small amount of sample data can effectively stimulate large models and generate more controllable dialogues\n* [2023/12/29] The open-source ASR model with enhanced Chinese capabilities [Belle-whisper-larger-v2-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v2-zh) and [Belle-distilwhisper-large -v2-zh](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh) are released, making it easier for everyone to use large language models in speech scenarios.\n* [2023/11/24] The open-source [BELLE-VL](https://huggingface.co/BELLE-2/BELLE-VL) multimodal large language model is released, expanding the model's visual capabilities based on a language model foundation with enhanced Chinese language abilities. This provides the community with more flexible options. Currently, the latest version of BELLE-VL has scored 1620.10 points in the [MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation) perception evaluation dimension, surpassing Qwen-VL, Llava, and mplug-owl.\"\n* [2023/10/27] Updated a technical report [DUMA](https://arxiv.org/pdf/2310.18075.pdf), exploring the Agent based on fast-slow brain architecture in conversational scenarios.\n* [2023/09/26] Updated the RLHF training code, supporting PPO and [DPO](https://arxiv.org/abs/2305.18290) training. Details: [README_RLHF.md](train/README_RLHF.md).\n* [2023/08/16] Based on [train_3.5M_CN](https://huggingface.co/datasets/BelleGroup/train_3.5M_CN), added instruction category field with 13 categories. Details: [train_3.5M_CN_With_Category](https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category).\n* [2023/08/10] Updated inference code based on ZeRO Inference. Details: [train/README_ZERO_INFERENCE.md](train/README_ZERO_INFERENCE.md).\n* [2023/08/07] Updated continuous pre-training and instruction fine-tuning codes, added flash attention 2. See [train/README.md](train/README.md). Packaged runtime environment at [train/docker/README.md](train/docker/README.md).\n* [2023/07/31] Updated a [technical report](https://arxiv.org/abs/2307.15290), exploring strategies for incremental pre-training + instruction fine-tuning in niche domains.\n* [2023/07/27] Released [BELLE-Llama2-13B-chat-0.4M](https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M), trained on 400,000 quality conversations based on Llama-2-13B. Improved performance on [evaluation set](https://github.com/LianjiaTech/BELLE/blob/main/eval/eval_set.json) compared to BELLE-LLaMA-EXT-13B model.\n* [2023/05/14] Released [BELLE-LLaMA-EXT-13B](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-13B), expanded Chinese vocabulary from LLaMA-13B-chat, trained on 4 million quality conversations.\n* [2023/05/11] In [BELLE/10M](https://github.com/LianjiaTech/BELLE/tree/main/10M), a new dataset named [\"train_3.5M_CN\"]((https://huggingface.co/datasets/BelleGroup/train_3.5M_CN)) containing 3.5 million newly added diverse instruction task data.\n* [2023/04/18] The train code has been updated and can be found in [BELLE/train](train). Deepspeed-Chat has been integrated, and relevant Docker containers have been provided.\n* [2023/04/17] Two new papers have been published that compare the effects of different training data generation methods and different training methods (LoRA, finetune) on model performance.\n* [2023/04/12] Released [ChatBELLE App](chat/README.md), a cross-platform BELLE-7B model realtime chat App based on [llama.cpp](https://github.com/ggerganov/llama.cpp) and [Flutter](https://flutter.dev/).\n* [2023/04/08] In [BELLE/10M](https://github.com/LianjiaTech/BELLE/tree/main/10M), a new dataset named [\"Generated Chat\"]((https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)) containing newly generated multi-turn dialogues with given roles, and a new dataset named [\"train_2M_CN\"](https://huggingface.co/datasets/BelleGroup/train_2M_CN) containing 2 million newly added diverse instruction task data.\n* [2023/04/05] The inference code that can be run on [Colab](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/models/notebook/BELLE_INFER_COLAB.ipynb) is provided\n\n## 📝 This repo contains\n\n###  🚀 Traning recipe\n\n  Please refer to [BELLE/train](train/) for a simplified implementation of the training code, which includes Deepspeed-Chat integration and supports finetuning and LoRA. Relevant Docker containers are also provided.\n  \n### 📊 Data Release\n  \n  Details in [BELLE/data/1.5M](data/1.5M/)，The Chinese dataset generated [1M](https://huggingface.co/datasets/BelleGroup/generated_train_1M_CN) + [0.5M](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN), using [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) as reference\n  \n  10M more data will be released gradually，details in [BELLE/data/10M](data/10M/). Currently, we have 0.8M multiturn data, and 0.25 math data.\n\n### 🧐 Evaluation set & evaluation method\n  \n  Details in [BELLE/eval](eval/). A test set with over 1k samples and corresponding scoring prompts. It includes multiple categories and is evaluated using either GPT-4 or ChatGPT.\n\n### 🤖 Models\n\n  Details in [BELLE/models](models/)\n  \n* The model optimized based on BLOOMZ-7B1-mt：[BELLE-7B-0.2M](https://huggingface.co/BelleGroup/BELLE-7B-0.2M)，[BELLE-7B-0.6M](https://huggingface.co/BelleGroup/BELLE-7B-0.6M)，[BELLE-7B-1M](https://huggingface.co/BelleGroup/BELLE-7B-1M)，[BELLE-7B-2M](https://huggingface.co/BelleGroup/BELLE-7B-2M)\n  \n* The finetuned models based on [Meta LLaMA](https://github.com/facebookresearch/llama): [BELLE-LLaMA-7B-0.6M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-0.6M-enc)\n, [BELLE-LLaMA-7B-2M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-2M-enc)\n, [BELLE-LLaMA-7B-2M-gptq-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-7B-2M-gptq-enc)\n, [BELLE-LLaMA-13B-2M-enc](https://huggingface.co/BelleGroup/BELLE-LLaMA-13B-2M-enc). Considering [LLaMA's License](https://github.com/facebookresearch/llama/blob/main/LICENSE) constraints, the model is for research and learning only. Please strictly respect LLaMA's usage policy. Users are suggested to finetune the model with open-source scripts and datasets. We are not allowed to publish weights for LLaMA, of course, even finetuned, but there is no problem publishing the difference, a patch that we suggest to apply to the files. The encryption is a simple XOR between files, ensuring that only the people that have access to the original weights (from completely legal sources, of course) can transform them into finetuned weights. You can find the decrypt code on [BELLE/models](models/).\n\n### ⚖️ Quantized_models\n\n  Details in [BELLE/gptq](gptq/)，Referring to the implementation of GPT-Q, the relevant models in this project have been quantized.\n\n### 🌐 Colab\n  \n  [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/models/notebook/BELLE_INFER_COLAB.ipynb) provides the colab in [BELLE/notebook](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/models/notebook/BELLE_INFER_COLAB.ipynb)\n\n### 💬 ChatBELLE App\n\n  Details in [BELLE/chat](chat/README.md), cross-platform LLM chat app with [BELLE](https://github.com/LianjiaTech/BELLE) using quantized on-device offline models and Flutter UI, running on macOS (done), Windows, Android, iOS and more.\n\n### 📑 Research Reports\n\n  Please refer to BELLE/docs for regular updates on research reports related to this project.\n\n**More prompts are welcomed via issues!**\n\n<br/>\n\n## 📑 Research Reports\n\n### [Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation](https://github.com/LianjiaTech/BELLE/blob/main/docs/Towards%20Better%20Instruction%20Following%20Language%20Models%20for%20Chinese.pdf)\n\nIn order to promote the development of open source large language models, \na lot of effort has been put into developing low-cost models similar to ChatGPT.\n\nFirstly, in order to improve the performance and training/inference efficiency of the model in the Chinese domain, we further expanded the vocabulary of LLaMA and conducted secondary pre-training on 3.4 billion Chinese words.\n\nIn addition, currently, there are three types of instruction training data generated based on ChatGPT: \n1) self-instruct data based on GPT3.5 obtained by referring to Alpaca; \n2) self-instruct data based on GPT4 obtained by referring to Alpaca; \n3) data shared by users using ChatGPT, called ShareGPT.\n\nHere, we focus on exploring the impact of training data categories on model performance. \nSpecifically, we examined factors such as the quantity, quality, and language distribution of the training data, \nas well as our own collected Chinese multi-turn conversation data and some publicly accessible high-quality guidance datasets.\n\nTo better evaluate the effects, we used an evaluation set containing one thousand samples and 9 real scenarios to test various models, and provided valuable insights through quantitative analysis, in order to better promote the development of open source chat models.\n\nThe goal of this research is to fill the gap in the comprehensive evaluation of open source chat models, \nin order to provide strong support for the continuous progress in this field.\n\n<table>\n  <tr>\n    <td> Factor </td>\n    <td> Base model </td>\n    <td> Training data </td>\n    <td> Score_w/o_others </td>\n  <tr>\n    <td rowspan=\"2\">vocabulary expansion</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.652</td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">Data Quality</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5) </td>\n    <td> 0.642 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-4) </td>\n    <td> 0.693 </td>\n  </tr>\n  <tr>\n    <td rowspan=\"4\">Data Language Distribution</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> cn(alpaca-3.5&4) </td>\n    <td> 0.679 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> en(alpaca-3.5&4) </td>\n    <td> 0.659 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> en(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.668 </td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">Data Scale</td>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt </td>\n    <td> 0.670 </td>\n  </tr>\n  <tr>\n    <td> LLaMA-7B-EXT </td>\n    <td> zh(alpaca-3.5&4) + sharegpt <br>+ BELLE-0.5M-CLEAN</td>\n    <td> 0.762</td>\n  </tr>\n  <tr>\n    <td>-</td>\n    <td>ChatGPT</td>\n    <td>-</td>\n    <td>0.824</td>\n</table>\n\nIn which, **BELLE-0.5M-CLEAN** is a set of 0.5 million cleaned data obtained from 2.3 million instruction data, which includes single-turn and multi-turn conversation data, and is not from the same batch as the previously released 0.5 million data.\n\n**It is important to note** that through case analysis, we found limitations in the comprehensiveness of our evaluation set, which resulted in inconsistencies between model scores and actual user experience. Building a high-quality evaluation set is a huge challenge because it requires including as many diverse usage scenarios as possible while maintaining a balance of difficulty levels. If the evaluation samples are all too difficult, the performance of all models will be poor, making it challenging to discern the effectiveness of various training strategies. Conversely, if the evaluation samples are all relatively easy, the evaluation will lose its comparative value. In addition, it is essential to ensure that the evaluation data is independent of the training data.\n\nBased on these observations, we caution against assuming that a model has achieved performance on par with ChatGPT merely by obtaining good results on a limited number of test samples. We believe that the continuous development of a comprehensive evaluation set is of great significance.\n\nThe relevant data and models in this work will be open-sourced in this project before April 19th.\n\n\n### [A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model](https://github.com/LianjiaTech/BELLE/blob/main/docs/A%20Comparative%20Study%20between%20Full-Parameter%20and%20LoRA-based.pdf)\n\nTo achieve fine-tuning of large language models, many researchers have begun to use parameter-efficient fine-tuning techniques, such as LoRA, due to resource and cost limitations, which have also achieved some encouraging results compared to full-parameter fine-tuning.\n\nIn this research report, we selected LLaMA as the base model and experimentally compared full-parameter fine-tuning with LoRA-based fine-tuning.\n\nThe experimental results revealed that the selection of appropriate base models, the scale of the training dataset, the number of learnable parameters, and the cost of model training are all important factors.\n\nWe hope that the experimental conclusions in this article can provide useful insights for the training of large language models, especially in the Chinese domain, and assist researchers in finding better trade-off strategies between training costs and model performance.\n\nThe experimental results are as follows:\n\n| Model | Average Score | Additional Param. | Training Time (Hour/epoch) |\n| ----- | ------ | ----- | ------ |\n| LLaMA-13B + LoRA(2M) | 0.648 | 28M | 8 |\n| LLaMA-7B + LoRA(4M) | 0.624 | 17.9M | 11 |\n| LLaMA-7B + LoRA(2M) | 0.609 | 17.9M | 7 |\n| LLaMA-7B + LoRA(0.6M) | 0.589 | 17.9M | 5 |\n| LLaMA-7B + FT(2M) | 0.710 | - | 31 |\n| LLaMA-7B + LoRA(4M) | 0.686 | - | 17 |\n| LLaMA-7B + FT(2M) <br>+ LoRA(math_0.25M) | 0.729 | 17.9M | 3 |\n| LLaMA-7B + FT(2M) <br>+ FT(math_0.25M) | 0.738 | - | 6 |\n\nThe score is based on the 1000 evaluation sets currently open in this project.\n\nLLaMA-13B + LoRA(2M) represents a model trained on 2 million instruction data using LLaMA-13B as the base model and the LoRA training method. LLaMA-7B + FT(2M) represents a model trained using full-parameter fine-tuning.\n\nLLaMA-7B + FT(2M) + LoRA(math_0.25M) represents a model trained on 0.25 million math instruction data using LLaMA-7B + FT(2M) as the base model and the LoRA training method. LLaMA-7B + FT(2M) + FT(math_0.25M) represents a model trained using incremental full-parameter fine-tuning. All of these experiments were conducted on 8 NVIDIA A100-40GB GPUs.\n\nmath_0.25M is the open 0.25 million math database. During the experiment, according to our evaluation (see paper for details), our model performed poorly on math tasks, with scores mostly below 0.5. To verify the adaptability of LoRA on specific tasks, we used an incremental 0.25 million math dataset (math_0.25M) to adjust the large language model following instructions (we chose LLaMA-7B+FT(2M) as the base model) using the LoRA training method. As a comparison, we used incremental fine-tuning with a learning rate of 5e-7 and trained for two epochs. Thus, we obtained two models, LLaMA-7B+FT(2M)+LoRA(math_0.25M) and LLaMA-7B+FT(2M)+FT(math_0.25M).\n\nThe experimental results show that incremental fine-tuning still performs better but requires longer training time. LoRA and incremental fine-tuning both improved the overall performance of the model. From the detailed data in the appendix, LoRA and incremental fine-tuning both showed significant improvements in the math task, but only led to a slight performance decrease in other tasks. Specifically, the performance of the math task improved to 0.586 and 0.559, respectively.\n\nIt can be seen that: 1) the selection of the base model has a significant impact on the effectiveness of LoRA adjustment; 2) increasing the amount of training data can continue to improve the effectiveness of the LoRA model; 3) LoRA adjustment benefits from the number of model parameters. For the use of the LoRA scheme, we recommend doing adaptive training with LoRA on specific tasks based on models that have completed instruction learning.\n\nSimilarly, the relevant models in this paper will be open-sourced in this project as soon as possible.\n\n\n## ⚠️ Limitation, Usage Limits and Disclaimer\n\nThere still exists a few issues in the model trained on current base model and data:\n\n1. The model might generate factual errors when asked to follow instructions related to facts.\n\n2. Occasionally generates harmful responses since the model still struggles to identify potential harmful instructions.\n\n3. Needs improvements on reasoning and coding.\n\nSince the model still has its limitations, we require developers only use the open-sourced code, data, model and any other artifacts generated via this project for research purposes. Commercial use and other potential harmful use cases are not allowed.\n\nThis project is only allowed to be used in research purposes only. The project owners and contributors shall not be held responsible for any damage or loss caused by using this project (including but not limited to data, model or code). Please refert to our [disclaimer](https://github.com/LianjiaTech/BELLE/blob/main/DISCLAIMER) for details.\n\n<br/>\n\n## 📌 Citation\n\nPlease cite us when using our code, data or model.\n\n```\n@misc{BELLE,\n  author = {BELLEGroup},\n  title = {BELLE: Be Everyone's Large Language model Engine},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/LianjiaTech/BELLE}},\n}\n\n@article{belle2023exploring,\n  title={Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases},\n  author={Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang, Baochang Ma, Xiangang Li},\n  journal={arXiv preprint arXiv:2303.14742},\n  year={2023}\n}\n\n@article{wen2023chathome,\n  title={ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation},\n  author={Wen, Cheng and Sun, Xianghui and Zhao, Shuaijiang and Fang, Xiaoquan and Chen, Liangyu and Zou, Wei},\n  journal={arXiv preprint arXiv:2307.15290},\n  year={2023}\n}\n```\n\nCite the original BLOOM, LLaMA, Stanford Alpaca and Self-Instruct papers as well!\n\n</br>\n\n## 📚 Use case\n\n<details>\n\n| Human | Assitant |\n| ----- | ------ |\n| 写一篇英文散文诗，主题是春雨，想象自己是春雨，和英国古代诗人莎士比亚交流 | I am the spring rain,<br/>Dancing on your face and body.<br/>My dew-drenched petals dance with you,<br/>Bringing life to every plant.<br/><br/>Shakespeare, I am here to meet you.<br/>Your works have filled my heart with joy.<br/>The beauty of nature in its fullness<br/>Makes me feel like a partaker.<br/><br/>As the leaves sway and rustle by,<br/>My dew-filled hand reaches out for them.<br/>The sweet scent of flowers fill the air,<br/>And bring me peace from all around.<br/><br/>Butterflies flit about as well,<br/>Glistening in the sun's rays.<br/>Their wings are made of dew,<br/>A beautiful sight to behold.<br/><br/>You see, Shakespeare, I too am one with nature.<br/>My dew-drenched hair is a symbol of hope.<br/>For when we can connect back to our roots,<br/>We will be able to make it through this season. |\n| I am the spring rain,<br/>Dancing on your face and body.<br/>My dew-drenched petals dance with you,<br/>Bringing life to every plant.<br/><br/>Shakespeare, I am here to meet you.<br/>Your works have filled my heart with joy.<br/>The beauty of nature in its fullness<br/>Makes me feel like a partaker.<br/><br/>As the leaves sway and rustle by,<br/>My dew-filled hand reaches out for them.<br/>The sweet scent of flowers fill the air,<br/>And bring me peace from all around.<br/><br/>Butterflies flit about as well,<br/>Glistening in the sun's rays.<br/>Their wings are made of dew,<br/>A beautiful sight to behold.<br/><br/>You see, Shakespeare, I too am one with nature.<br/>My dew-drenched hair is a symbol of hope.<br/>For when we can connect back to our roots,<br/>We will be able to make it through this season. <br/>把上面的散文诗翻译成中文 | 我是一场春雨，<br/>在你脸上跳跃。<br/>我浸润着露珠的翅膀和你一起舞动，<br/>为每一株植物带来生命。<br/><br/>莎士比亚，我来与你相遇。<br/>你的作品填满了我的心房。<br/>大自然的美丽让我感到与之一起分享，<br/>让我觉得自己成为了其中的一部分。<br/><br/>当树叶摇曳时，<br/>我的手掌沾满了露水。<br/>花香弥漫在空气中，<br/>带给我宁静和安宁。<br/><br/>你看，莎士比亚，我也是与大自然融为一体的。<br/>我沾湿的头发象征着希望。<br/>当我们能够回到我们的根源，<br/>我们就能共同度过这个季节。|\n| Classify the sentiment of the following sentence into Positive, Neutral, or Negative: <br/>Super excited about teaching Stanford’s first course on Large Language Models! Check the syllabus out here | Positive |\n| 小明的爸爸有三个孩子，老大叫王一，老二叫王二，老三叫什么？ | 小明 |\n| 使用python写一个二分查找的代码 | def binary_search(arr, target):<br/>&nbsp;&nbsp;low = 0<br/>&nbsp;&nbsp;high = len(arr) - 1<br/>&nbsp;&nbsp;while (low <= high):<br/>&nbsp;&nbsp;&nbsp;&nbsp;mid = low + high // 2<br/>&nbsp;&nbsp;&nbsp;&nbsp;if arr[mid] == target:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return mid<br/>&nbsp;&nbsp;&nbsp;&nbsp;elif target < arr[mid]:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low = mid + 1<br/>&nbsp;&nbsp;&nbsp;&nbsp;else:<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;high = mid - 1<br/>&nbsp;&nbsp;return -1 |\n| 今天天气怎么样，把这句话翻译成英语 | What's the weather like today? |\n| 怎么让自己精力充沛，列5点建议 | 以下是一些可以让你保持精力充沛的建议： <br/>1. 睡眠充足。确保每天晚上得到充足的睡眠时间。 <br/>2. 多运动。进行适度的有氧运动，如慢跑、游泳等，可以帮助你提高能量和耐力。<br/>3. 吃健康食品。选择富含蛋白质的食物，如鸡肉、鱼肉和鸡蛋，以及新鲜的水果和蔬菜。 <br/>4. 减少咖啡因的摄入量。尽量避免在白天喝含咖啡因的饮料或吃含有咖啡因的食物。 <br/>5. 放松身心。尝试冥想、瑜伽或其他形式的放松活动来减轻压力和焦虑感。 |\n| 明天就假期结束了，有点抗拒上班，应该什么办？ | 面对即将结束的假期和开始工作时的紧张情绪，您可以采取以下措施来帮助您更好地适应： <br/>1. 为自己制定一个清晰的工作计划。这可以帮助您更好地组织时间和任务，并避免在工作中感到混乱。 <br/>2. 与同事或朋友交流，分享您的感受和工作压力。这将有助于缓解一些焦虑感，同时也可以获得支持和建议。 <br/>3. 在工作日前花些时间放松身心，例如进行瑜伽、冥想等活动。这些方法可以减轻身体和精神上的疲劳感，使您更加精力充沛地迎接挑战。 |\n| 父母都姓吴，取一些男宝宝和女宝宝的名字 | - 男宝：吴俊杰、吴雨辰、吴子墨、吴思源、吴泽阳、吴宇航、吴博文、吴哲毅。 <br/>- 女宝：吴美琪、吴佳怡、吴欣瑜、吴香凝、吴雪柔、吴颖诗、吴语嫣。 |\n| 推荐几本金庸的武侠小说 | 以下是三本我最喜欢的金庸武侠小说的推荐： <br/>1. 《射雕英雄传》 - 一部充满智慧和机智的小说，讲述了郭靖、黄蓉夫妇的故事。 <br/>2. 《神雕侠侣》- 这是一部浪漫而感人的故事，讲述了一对情侣小龙女与杨过之间的爱情故事。 <br/>3. 《倚天屠龙记》- 这是一个宏伟而壮观的故事，描绘了明教领袖张无忌如何成为一位出色的英雄。 |\n\n</details>\n\n<br/>\n\n\n## ⛽️ Contributing\n\nYou are welcomed to commit issues or contributig data/code.\nPlease refer to [How To Contribute](https://github.com/LianjiaTech/BELLE/blob/main/HOW_TO_CONTRIBUTE.md).\n\n## ☎️ Contact Us\n\nDrop by and join with us at [Discord](https://discord.gg/pMPY53UUGq) or [WeChat](https://github.com/LianjiaTech/BELLE/blob/main/assets/belle_wechat.jpg)!\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "chat",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "eval",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1103515625,
          "content": "numpy\nrouge_score\nfire\nopenai\ntransformers\ngensim\npeft\ndatasets\nbitsandbytes\ndeepspeed\nflash-attn\ntrl\naccelerate\n"
        },
        {
          "name": "train",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}