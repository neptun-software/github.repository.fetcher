{
  "metadata": {
    "timestamp": 1736557271759,
    "page": 149,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "d2l-ai/d2l-zh",
      "stars": 64955,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.11,
          "content": "**/.ipynb_checkpoints\n**/__pycache__\ndata/\n*.json\n*.params\n*.DS_Store\n*.csv\n*egg-info*\ndist*\n_build/\ntest*.md\nrun.sh"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.17,
          "content": "[submodule \"build/mx-theme\"]\n\tpath = build/mx-theme\n\turl = https://github.com/mli/mx-theme\n[submodule \"build/utils\"]\n\tpath = build/utils\n\turl = https://github.com/d2l-ai/utils\n"
        },
        {
          "name": "INFO.md",
          "type": "blob",
          "size": 2.1,
          "content": "## 编译HTML版本\n\n所有markdown文件需要在提交前清除output，它们会在服务器上重新执行生成结果。所以需要保证每个notebook执行不要太久，目前限制是20min。\n\n在本地可以如下build html（需要GPU支持）\n\n```\nconda env update -f build/env.yml\nsource activate d2l-zh-build\nmake html\n```\n\n生成的html会在`_build/html`。\n\n如果没有改动notebook里面源代码，所以不想执行notebook，可以使用\n\n```\nmake html EVAL=0\n```\n\n但这样生成的html将不含有输出结果。\n\n## 编译PDF版本\n\n编译pdf版本需要xelatex、librsvg2-bin（svg图片转pdf）和思源字体。在Ubuntu可以这样安装。\n\n```\nsudo apt-get install texlive-full\nsudo apt-get install librsvg2-bin\n```\n\n```\nwget https://github.com/adobe-fonts/source-han-sans/releases/download/2.004R/SourceHanSansSC.zip\nwget -O SourceHanSerifSC.zip https://github.com/adobe-fonts/source-han-serif/releases/download/2.001R/09_SourceHanSerifSC.zip\n\nunzip SourceHanSansSC.zip -d SourceHanSansSC\nunzip SourceHanSerifSC.zip -d SourceHanSerifSC\n\nsudo mv SourceHanSansSC SourceHanSerifSC /usr/share/fonts/opentype/\nsudo fc-cache -f -v\n```\n\n\n这时候可以通过 `fc-list :lang=zh` 来查看安装的中文字体。\n\n同样的去下载和安装英文字体\n\n```\nwget -O source-serif-pro.zip https://www.fontsquirrel.com/fonts/download/source-serif-pro\nunzip source-serif-pro -d source-serif-pro\nsudo mv source-serif-pro /usr/share/fonts/opentype/\n\nwget -O source-sans-pro.zip https://www.fontsquirrel.com/fonts/download/source-sans-pro\nunzip source-sans-pro -d source-sans-pro\nsudo mv source-sans-pro /usr/share/fonts/opentype/\n\nwget -O source-code-pro.zip https://www.fontsquirrel.com/fonts/download/source-code-pro\nunzip source-code-pro -d source-code-pro\nsudo mv source-code-pro /usr/share/fonts/opentype/\n\nsudo fc-cache -f -v\n```\n\n然后就可以编译了。\n\n```\nmake pdf\n```\n\n## 其他安装\n\n```\npython -m spacy download en # 需已 pip install spacy\n```\n\n## 样式规范\n\n贡献请遵照本教程的[样式规范](STYLE_GUIDE.md)。\n\n## 中英文术语对照\n\n翻译请参照[中英文术语对照](TERMINOLOGY.md)。\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.56,
          "content": "# 动手学深度学习（Dive into Deep Learning，D2L.ai）\n\n[第二版：zh.D2L.ai](https://zh.d2l.ai)  | [第一版：zh-v1.D2L.ai](https://zh-v1.d2l.ai/) |  安装和使用书中源代码： [第二版](https://zh.d2l.ai/chapter_installation/index.html) [第一版](https://zh-v1.d2l.ai/chapter_prerequisite/install.html)\n\n<h5 align=\"center\"><i>理解深度学习的最佳方法是学以致用。</i></h5>\n\n<p align=\"center\">\n  <img width=\"200\"  src=\"static/frontpage/_images/eq.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/figure.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/code.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/notebook.gif\">\n</p>\n\n本开源项目代表了我们的一种尝试：我们将教给读者概念、背景知识和代码；我们将在同一个地方阐述剖析问题所需的批判性思维、解决问题所需的数学知识，以及实现解决方案所需的工程技能。\n\n我们的目标是创建一个为实现以下目标的统一资源：\n1. 所有人均可在网上免费获取；\n1. 提供足够的技术深度，从而帮助读者实际成为深度学习应用科学家：既理解数学原理，又能够实现并不断改进方法；\n1. 包含可运行的代码，为读者展示如何在实际中解决问题。这样不仅直接将数学公式对应成实际代码，而且可以修改代码、观察结果并及时获取经验；\n1. 允许我们和整个社区不断快速迭代内容，从而紧跟仍在高速发展的深度学习领域；\n1. 由包含有关技术细节问答的论坛作为补充，使大家可以相互答疑并交换经验。\n\n<h5 align=\"center\">将本书（中英文版）用作教材或参考书的大学</h5>\n<p align=\"center\">\n  <img width=\"400\"  src=\"https://d2l.ai/_images/map.png\">\n</p>\n\n如果本书对你有帮助，请Star (★) 本仓库或引用本书的英文版：\n\n```\n@book{zhang2023dive,\n    title={Dive into Deep Learning},\n    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},\n    publisher={Cambridge University Press},\n    note={\\url{https://D2L.ai}},\n    year={2023}\n}\n```\n\n## 本书的英文版\n\n虽然纸质书已出版，但深度学习领域依然在迅速发展。为了得到来自更广泛的英文开源社区的帮助，从而提升本书质量，本书的新版将继续用英文编写，并搬回中文版。\n\n欢迎关注本书的[英文开源项目](https://github.com/d2l-ai/d2l-en)。\n\n## 中英文教学资源\n\n加州大学伯克利分校 2019 年春学期 [*Introduction to Deep Learning* 课程](http://courses.d2l.ai/berkeley-stat-157/index.html)教材（同时提供含教学视频地址的[中文版课件](https://github.com/d2l-ai/berkeley-stat-157/tree/master/slides-zh)）。\n\n## 学术界推荐\n\n> <p>\"Dive into this book if you want to dive into deep learning!\"</p>\n> <b>&mdash; 韩家炜，ACM 院士、IEEE 院士，美国伊利诺伊大学香槟分校计算机系 Michael Aiken Chair 教授</b>\n\n> <p>\"This is a highly welcome addition to the machine learning literature.\"</p>\n> <b>&mdash; Bernhard Schölkopf，ACM 院士、德国国家科学院院士，德国马克斯•普朗克研究所智能系统院院长</b>\n\n> <p>\"书中代码可谓‘所学即所用’。\"</p>\n> <b>&mdash; 周志华，ACM 院士、IEEE 院士、AAAS 院士，南京大学计算机科学与技术系主任</b>\n\n> <p>\"这本书可以帮助深度学习实践者快速提升自己的能力。\"</p>\n> <b>&mdash; 张潼，ASA 院士、IMS 院士，香港科技大学计算机系和数学系教授</b>\n\n## 工业界推荐\n\n> <p>\"一本优秀的深度学习教材，值得任何想了解深度学习何以引爆人工智能革命的人关注。\"</p>\n> <b>&mdash; 黄仁勋，NVIDIA创始人 & CEO</b>\n\n> <p>\"《动手学深度学习》是最适合工业界研发工程师学习的。我毫无保留地向广大的读者们强烈推荐。\"</p>\n> <b>&mdash; 余凯，地平线公司创始人 & CEO</b>\n\n> <p>\"强烈推荐这本书！我特别赞赏这种手脑一体的学习方式。\"</p>\n> <b>&mdash; 漆远，复旦大学“浩清”教授、人工智能创新与产业研究院院长</b>\n\n> <p>\"《动手学深度学习》是一本很容易让学习者上瘾的书。\"</p>\n> <b>&mdash; 沈强，将门创投创始合伙人</b>\n\n## 贡献\n\n感谢[社区贡献者们](https://github.com/d2l-ai/d2l-zh/graphs/contributors)为每一位读者改进这本开源书。\n\n[如何贡献](https://zh.d2l.ai/chapter_appendix-tools-for-deep-learning/contributing.html) | [致谢](https://zh.d2l.ai/chapter_preface/index.html) | [讨论或报告问题](https://discuss.d2l.ai/c/chinese-version/16) | [其他](INFO.md)\n"
        },
        {
          "name": "STYLE_GUIDE.md",
          "type": "blob",
          "size": 5.95,
          "content": "# 样式规范\n\n## 文本\n\n* 章节\n    * 每章开头对全章做介绍\n    * 结构标题一致\n        * 小结\n        * 练习\n        * 扫码直达讨论区\n        * 参考文献（如有）\n    * 引用\n        * 在每节结尾处引用\n* 字符串\n    * 使用中文双引号\n* 符号描述\n    * 时刻t（不是t时刻）\n\t* 形状使用英文标点\n        * (10, 20) 不是 （10，20）\n* 空格：\n\t* 文本中中文和英文、数字、数学公式、特殊字体等之间不要加空格\n\t* 非行首的`:numref:`、`:cite:`等前留有一个英文空格（否则网页不渲染）\n\t* 代码注释同上\n* 人称\n    * 第一人称 → 我们\n    * 第二人称 → 读者、你、大家\n* 工具或部件\n    * Gluon, MXNet, NumPy, spaCy, ResNet-18, Fashion-MNIST, matplotlib\n        * 这些都作为词，不要带重音符\n    * `backward`函数\n        * 不是“`backward()`函数” （不要带括号）\n    * `for`循环\n* 术语\n    * 统一使用\n        * 函数（非方法）\n        * 实例（非对象）\n        * 区分：超参数和参数\n        * 区分：小批量随机梯度下降和随机梯度下降\n        * 权重、偏差、标签\n        * 模型训练、模型预测（推断）\n        * 训练数据集、验证数据集、测试数据集\n    * 中文优先于英文\n        * 首次出现，注明原英文术语\n            * 无须加粗\n            * 无须加引号\n    * 中英文对照统一标准\n        * https://github.com/mli/gluon-tutorials-zh/blob/master/README.md\n\n## 数学\n\n* 数学符号样式一致\n    * https://github.com/goodfeli/dlbook_notation/blob/master/notation_example.pdf\n* 书本页宽限制\n    * 每行长度\n* 引用\n    * 上式和下式\n    * 以上N式，以下N式\n* 公式末放英文标点\n    * 逗号：,\n    * 句号：.\n* 赋值符号\n    * \\leftarrow\n\n## 图片\n\n* 软件\n    * 使用OmniGraffle制图，以100%的大小导出pdf（infinite canvas），再使用pdf2svg转成svg\n* 样式\n    * 格式：\n        * svg\n        * png\n            * export resolution: 144\n    * 大小：\n        * 横向：不超过400像素\n        * 纵向：不超过200像素\n    * 粗细：\n        * StickArrow\n        * 1pt\n\t\t* arrow head size: 50%\n    * 字体：\n        * 英文：STIXGeneral, 9pt（下标和上标：6pt）\n        * 中文：PingFang SC, 9pt\n\t* 下标和上标中的数字和括号不要斜体\n    * 颜色：\n        * 非填充深蓝色（与黑相近）：\n            * 5B7DAA\n        * 填充蓝色（与黑对比）\n            * 深：66BFFF\n            * 淡：B2D9FF\n* 版权\n    * 不使用网络图片\n* 位置\n    * 两张图不可以较邻近\n        * 两张图拼一下\n* 引用\n    * 手动引用（例如，图7.1）\n* matplotlib\n    * 大小\n    * 分辨率\n\n## 代码\n\n* 使用utils.py封装多次使用函数\n    * 首次出现函数，书里给出函数实现\n* Python规范一致\n    * PEP8\n        * 二元操作符换行：操作符和后一元一起换行 (https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator)\n* 将相邻赋值语句尽可能合并为同一行\n\t* 如 num_epochs, lr = 5, 0.1\n* 变量名一致\n    * num_epochs\n        * 迭代周期\n    * num_hiddens\n        * 隐藏单元个数\n    * num_inputs\n        * 输入个数\n    * num_outputs\n        * 输出个数\n    * net\n        * 模型\n    * lr\n        * 学习率\n    * acc\n        * 准确率\n    * 迭代中\n        * 特征：X\n        * 标签：y, y_hat 或 Y, Y_hat\n        * for X, y in data_iter\n    * 数据集：\n        * 特征：features或images\n        * 标签：labels\n        * DataLoader实例：train_iter, test_iter, data_iter\n* 注释\n    * 中文\n    * 句末不加句号\n* 书本页宽限制\n    * 每行不超过78字符\n        * In [X]: 79字符不会自动换行（X = 1, ..., 9）\n    \t* In [XX]: 78字符不会自动换行（XX = 10, 11, ..., 99）\n    * 打印结果自动换行\n* imports\n    * import alphabetically\n    * from mxnet.gluon import data as gdata, loss as gloss, nn, utils as gutils\n* 打印名称\n    * epoch（从1开始计数）, lr, loss, train acc, time\n    * 5行左右\n* 打印变量\n    * 代码块最后一行尽量不用print()语句，例如`x, y`而不是`print('x:', x, 'y:', y)`\n* 字符串\n    * 使用单引号\n* 其他\n    * nd.f(x) → x.nd\n    * random_normal → random.normal\n    * multiple imports\n    * .1 → 1.0\n    * 1. → 1.0\n    * remove namescope\n\n## 超链接\n\n* 内链格式\n    * [“线性回归”](linear-reg.md)一节\n* 外链\n    * [层](http:bla)\n    * 无须暴露URL\n\n## 英翻汉的常见问题\n\n* 遇到不确定的地方，可以翻阅中文版第一版的处理方法（即我们需要遵照的出版标准），以及查阅人工翻译 http://www.jukuu.com/\n* 建立中英文术语对照表，全书术语翻译要完全一致。\n* 语法要正确（如不能缺主语、谓语）、句子要通顺（硬翻不妥就意译）、不要漏内容。\n* 代码注释要翻译。注意：i) 每行不要超过78字符，注释末尾不用加句号。 ii) # 后要空一个半角字符（英文空格）。iii) 如果注释与代码同行，# 前要空两个半角字符（英文空格）。iv）保留注释中的``符号（为了表示代码部分，如变量名、函数名等）。v）注释中中文和英文之间不要空格。vi）贪婪换行：只有当一行注释抵到78字符时再换行。\n* 不要新加空行（这样会另起一个自然段）。\n* 术语要保留英文翻译。现在很多地方漏了英文翻译。格式：*术语*（terminology）\n* 正文和代码注释均使用中文标点。例如，中文括号要用全角括号（），不是英文半角()。例外：所有表示形状的括号和逗号（逗号后紧跟半角英文空格）用英文半角，例如“(批量大小, 词数)”而不是“（批量大小，词数）”\n* 英文在标题里或句首全部不要首字母大写（即便在标题的第一个词）。除非本身是首字母大写的术语\n* 不要客气。“您”->“你”，去掉“请”\n\n"
        },
        {
          "name": "TERMINOLOGY.md",
          "type": "blob",
          "size": 3.83,
          "content": "## 英汉术语对照\n\n鞍点，saddle point\n\n变换，transform\n\n编码器，encoder\n\n标签，label\n\n步幅，stride\n\n参数，parameter\n\n长短期记忆网络，long short-term memory (LSTM)\n\n超参数，hyperparameter\n\n层序softmax，hierarchical softmax\n\n查准率，precision\n\n成本，cost\n\n词表，vocabulary\n\n词嵌入，word embedding\n\n词向量，word vector\n\n词元，token\n\n词元分析器，tokenizer\n\n词元化，tokenize\n\n汇聚层，pooling layer\n\n稠密，dense\n\n大小，size\n\n导入，import\n\n轮，epoch\n\n暂退法，dropout\n\n动量法，momentum (method)\n\n独立同分布，independent and identically distributed (i.i.d.)\n\n端到端，end-to-end\n\n多层感知机，multilayer perceptron\n\n多头注意力，multi-head attention\n\n二元分类，binary classification\n\n二元，bigram\n\n子采样，subsample\n\n发散，diverge\n\n泛化，generalization\n\n泛化误差，generalization error\n\n方差，variance\n\n分类，classification\n\n分类器，classifier\n\n负采样，negative sampling\n\n感受野，receptive field\n\n格拉姆矩阵，Gram matrix\n\n共现，co-occurrence\n\n广播，broadcast\n\n规范化，normalization\n\n过拟合，overfitting\n\n核回归，kernel regression\n\n恒等映射，identity mapping\n\n假设，hypothesis\n\n基准，baseline\n\n激活函数，activation function\n\n解码器，decoder\n\n近似法，approximate method\n\n经验风险最小化，empirical risk minimization\n\n局部最小值，local minimum\n\n卷积核，convolutional kernel\n\n卷积神经网络，convolutional neural network\n\n决策边界，decision boundary\n\n均值，mean\n\n均方误差，mean squared error\n\n均匀采样，uniform sampling\n\n块，block\n\n困惑度，perplexity\n\n拉普拉斯平滑，Laplace smoothing\n\n连结，concatenate\n\n类，class\n\n交叉熵，cross-entropy\n\n连续词袋，continous bag-of-words (CBOW)\n\n零张量，zero tensor\n\n流水线，pipeline\n\n滤波器，filter\n\n门控循环单元，gated recurrent units (GRU)\n\n目标检测，object detection\n\n偏置，bias\n\n偏导数，partial derivative\n\n偏移量，offset\n\n批量，batch\n\n齐普夫定律，Zipf's law\n\n欠拟合，underfitting\n\n情感分析，sentiment analysis\n\n全连接层，fully-connected layer\n\n权重，weight\n\n三元，trigram\n\n上采样，upsample\n\n上下文变量，context variable\n\n上下文窗口，context window\n\n上下文词，context word\n\n上下文向量，context vector\n\n实例/示例，instance\n\n收敛，converge\n\n属性，property\n\n数值方法，numerical method\n\n数据集，dataset\n\n数据示例，data instance\n\n数据样例，data example\n\n顺序分区，sequential partitioning\n\nsoftmax回归，softmax regression\n\n随机采样，random sampling\n\n损失函数，loss function\n\n双向循环神经网络，bidirectional recurrent neural network\n\n特征，feature\n\n特征图，feature map\n\n特征值，eigenvalue\n\n梯度，gradient\n\n梯度裁剪，gradient clipping\n\n梯度消失，vanishing gradients\n\n填充，padding\n\n跳元模型，skip-gram model\n\n调参，tune hyperparameter\n\n停用词，stop words\n\n通道，channel\n\n凸优化，convex optimization\n\n图像，image\n\n未知词元，unknown token\n\n无偏估计，unbiased estimate\n\n误差，error\n\n小批量，minibatch\n\n小批量梯度，minibatch gradient\n\n线性模型，linear model\n\n线性回归，linear regression\n\n协同过滤，collaborative filtering\n\n学习率，learning rate\n\n训练误差，training error\n\n循环神经网络，recurrent neural network (RNN)\n\n样例，example\n\n一维梯度下降，gradient descent in one-dimensional space\n\n一元，unigram\n\n隐藏变量，hidden variable\n\n隐藏层，hidden layer\n\n优化器，optimizer\n\n语料库，corpus\n\n运算符，operator\n\n自注意力，self-attention\n\n真实值，ground truth\n\n指标，metric\n\n支持向量机，support vector machine\n\n注意力机制，attention mechanism\n\n注意力模型，attention model\n\n注意力提示，attention cue\n\n准确率/精度，accuracy\n"
        },
        {
          "name": "chapter_appendix-tools-for-deep-learning",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_attention-mechanisms",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_computational-performance",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_computer-vision",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_convolutional-modern",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_convolutional-neural-networks",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_deep-learning-computation",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_installation",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_introduction",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_linear-networks",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_multilayer-perceptrons",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_natural-language-processing-applications",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_natural-language-processing-pretraining",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_notation",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_optimization",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_preface",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_preliminaries",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_recurrent-modern",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_recurrent-neural-networks",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_references",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.ini",
          "type": "blob",
          "size": 8.34,
          "content": "[project]\n\nname = d2l-zh\n\ntitle = 动手学深度学习\n\nauthor = Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola\n\ncopyright = 2022, All authors. Licensed under CC-BY-SA-4.0 and MIT-0.\n\nrelease = 2.0.0\n\nlang = zh\n\n[translation]\n\norigin_repo = d2l-ai/d2l-en\norigin_lang = en\ntranslator = aws\n\n[build]\n\n# A list of wildcards to indicate the markdown files that need to be evaluated as\n# Jupyter notebooks.\nnotebooks = *.md */*.md\n\n# A list of files that will be copied to the build folder.\nresources = img/ d2lzh/ d2l.bib setup.py\n\n# Files that will be skipped.\nexclusions = */*_origin.md README.md STYLE_GUIDE.md INFO.md CODE_OF_CONDUCT.md CONTRIBUTING.md contrib/*md\n\n# If True (default), then will evaluate the notebook to obtain outputs.\neval_notebook = True\n\ntabs = mxnet, pytorch, tensorflow, paddle\n\nsphinx_configs = numfig_format = {'figure': '图%%s', 'table': '表%%s', 'code-block': '列表%%s', 'section': '%%s节'}\n    latex_elements = {\n    'utf8extra' : '',\n    'inputenc'  : '',\n    'babel'     : r'''\\usepackage[english]{babel}''',\n    'preamble' : r'''\n                \\usepackage{ctex}\n                \\setmainfont{Source Serif Pro}\n                \\setsansfont{Source Sans Pro}\n                \\setmonofont{Inconsolata}\n                \\setCJKmainfont[BoldFont=Source Han Serif SC SemiBold]{Source Han Serif SC}\n                \\setCJKsansfont[BoldFont=Source Han Sans SC Medium]{Source Han Sans SC Normal}\n                \\setCJKmonofont{Source Han Sans SC Normal}\n                \\addto\\captionsenglish{\\renewcommand{\\chaptername}{}}\n                \\addto\\captionsenglish{\\renewcommand{\\contentsname}{目录}}\n                \\setlength{\\headheight}{13.6pt}\n                \\makeatletter\n                    \\fancypagestyle{normal}{\n                        \\fancyhf{}\n                        \\fancyfoot[LE,RO]{{\\py@HeaderFamily\\thepage}}\n                        \\fancyfoot[LO]{{\\py@HeaderFamily\\nouppercase{\\rightmark}}}\n                        \\fancyfoot[RE]{{\\py@HeaderFamily\\nouppercase{\\leftmark}}}\n                        \\fancyhead[LE,RO]{{\\py@HeaderFamily }}\n                     }\n                \\makeatother\n                \\CJKsetecglue{}\n                \\usepackage{zhnumber}\n\n                \\definecolor{d2lbookOutputCellBackgroundColor}{RGB}{255,255,255}\n                \\definecolor{d2lbookOutputCellBorderColor}{rgb}{.85,.85,.85}\n                \\def\\diilbookstyleoutputcell\n                   {\\sphinxcolorlet{VerbatimColor}{d2lbookOutputCellBackgroundColor}\n                    \\sphinxcolorlet{VerbatimBorderColor}{d2lbookOutputCellBorderColor}\n                    \\sphinxsetup{verbatimwithframe,verbatimborder=0.5pt}\n                   }\n\n                \\definecolor{d2lbookInputCellBackgroundColor}{rgb}{.95,.95,.95}\n                \\def\\diilbookstyleinputcell\n                   {\\sphinxcolorlet{VerbatimColor}{d2lbookInputCellBackgroundColor}\n                    \\sphinxsetup{verbatimwithframe=false,verbatimborder=0pt}\n                   }\n                ''',\n\n    'sphinxsetup': '''verbatimsep=2mm,\n                  VerbatimColor={rgb}{.95,.95,.95},\n                  VerbatimBorderColor={rgb}{.95,.95,.95},\n                  pre_border-radius=3pt,\n               ''',\n    # The font size ('10pt', '11pt' or '12pt').\n    'pointsize': '10pt',\n    # Latex figure (float) alignment\n    'figure_align': 'H',\n    'fncychap': '\\\\usepackage[Sonny]{fncychap}',\n    }\n\n\n\n[html]\n\n# A list of links that is displayed on the navbar. A link consists of three\n# items: name, URL, and a fontawesome icon\n# (https://fontawesome.com/icons?d=gallery). Items are separated by commas.\n# PDF, http://numpy.d2l.ai/d2l-en.pdf, fas fa-file-pdf,\nheader_links = MXNet, https://zh-v2.d2l.ai/d2l-zh.pdf, fas fa-file-pdf,\n               PyTorch, https://zh-v2.d2l.ai/d2l-zh-pytorch.pdf, fas fa-file-pdf,\n               Jupyter 记事本, https://zh-v2.d2l.ai/d2l-zh.zip, fas fa-download,\n               课程, https://courses.d2l.ai/zh-v2/, fas fa-user-graduate,\n               GitHub, https://github.com/d2l-ai/d2l-zh, fab fa-github,\n               English, https://d2l.ai, fas fa-external-link-alt\n\nfavicon = static/favicon.png\n\nhtml_logo = static/logo-with-text.png\n\n\n[pdf]\n\n# The file used to post-process the generated tex file.\npost_latex = ./static/post_latex/main.py\n\nlatex_logo = static/logo.png\n\nbibfile = d2l.bib\n\n[library]\n\nversion_file = d2l/__init__.py\n\n[library-mxnet]\n\nlib_file = d2l/mxnet.py\nlib_name = np\n\n# Map from d2l.xx to np.xx\nsimple_alias = ones, zeros, arange, meshgrid, sin, sinh, cos, cosh, tanh,\n               linspace, exp, log, tensor -> array, normal -> random.normal,\n               randn -> random.randn,\n               rand -> random.rand, matmul -> dot, int32, float32,\n               concat -> concatenate, stack, abs, eye\n\n# Map from d2l.xx(a, *args, **kwargs) to a.xx(*args, **kwargs)\nfluent_alias = numpy -> asnumpy, reshape, to -> as_in_context, reduce_sum -> sum,\n               argmax, astype, reduce_mean -> mean,\n\nalias =\n       size = lambda a: a.size\n       transpose = lambda a: a.T\n       nn_Module = nn.Block\n\nreverse_alias =\n       d2l.size\\(([\\w\\_\\d]+)\\) -> \\1.size\n       d2l.transpose\\(([\\w\\_\\d]+)\\) -> \\1.T\n       d2l.nn_Module -> nn.Block\n\n[library-pytorch]\n\n\nlib_file = d2l/torch.py\nlib_name = torch\n\nsimple_alias = ones, zeros, tensor, arange, meshgrid, sin, sinh, cos, cosh,\n               tanh, linspace, exp, log, normal, rand, randn, matmul, int32, float32,\n               concat -> cat, stack, abs, eye\n\nfluent_alias = numpy -> detach().numpy, size -> numel, reshape, to,\n               reduce_sum -> sum, argmax, astype -> type, transpose -> t,\n               reduce_mean -> mean\nalias =\n       nn_Module = nn.Module\n\nreverse_alias =\n       d2l.nn_Module -> nn.Module\n\n[library-tensorflow]\n\nlib_file = d2l/tensorflow.py\nlib_name = tf\n\nsimple_alias = reshape, ones, zeros, meshgrid, sin, sinh, cos, cosh, tanh,\n               linspace, exp, normal -> random.normal, rand -> random.uniform,\n               matmul, reduce_sum, reduce_mean, argmax, tensor -> constant,\n               arange -> range, astype -> cast, int32, float32, transpose,\n               concat, stack, abs, eye, log -> math.log\n\nfluent_alias = numpy,\n\nalias =\n       size = lambda a: tf.size(a).numpy()\n\nreverse_alias =\n       d2l.size\\(([\\w\\_\\d]+)\\) -> tf.size(\\1).numpy()\n       d2l.nn_Module -> tf.keras.Model\n\n[library-paddle]\nlib_file = d2l/paddle.py\nlib_name = paddle\n\nsimple_alias = ones, zeros, tensor -> to_tensor, arange, meshgrid, sin, sinh, cos, cosh,\n               tanh, linspace, exp, log, normal, rand, randn, matmul, int32, float32,\n               concat, stack, abs, eye\n\nfluent_alias = numpy -> detach().numpy, size -> numel, reshape, to,\n               reduce_sum -> sum, argmax, astype, transpose -> t,\n               reduce_mean -> mean\n\nalias =\n       nn_Module = nn.Layer\n\nreverse_alias =\n       d2l.nn_Module -> nn.Layer\n       \n[deploy]\n\nother_file_s3urls = s3://d2l-webdata/releases/d2l-zh/d2l-zh-1.0.zip\n                    s3://d2l-webdata/releases/d2l-zh/d2l-zh-1.1.zip\n                    s3://d2l-webdata/releases/d2l-zh/d2l-zh-2.0.0.zip\n\ngoogle_analytics_tracking_id = UA-96378503-2\n\n[colab]\n\ngithub_repo = mxnet, d2l-ai/d2l-zh-colab\n              pytorch, d2l-ai/d2l-zh-pytorch-colab\n              tensorflow, d2l-ai/d2l-zh-tensorflow-colab\n              paddle, d2l-ai/d2l-zh-paddle-colab\n\nreplace_svg_url = img, http://d2l.ai/_images\n\nlibs = mxnet, mxnet, -U mxnet-cu101==1.7.0\n       mxnet, d2l, git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n       pytorch, d2l, git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n       tensorflow, d2l, git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n       paddle, d2l, git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n\n\n[sagemaker]\n\ngithub_repo = mxnet, d2l-ai/d2l-zh-sagemaker\n              pytorch, d2l-ai/d2l-zh-pytorch-sagemaker\n              tensorflow, d2l-ai/d2l-zh-tensorflow-sagemaker\n              paddle, d2l-ai/d2l-zh-paddle-sagemaker\n\nkernel = mxnet, conda_mxnet_p36\n         pytorch, conda_pytorch_p36\n         tensorflow, conda_tensorflow_p36\n         paddle, conda_paddle_p36\n\nlibs = mxnet, mxnet, -U mxnet-cu101==1.7.0\n       mxnet, d2l, ..  # installing d2l\n       pytorch, d2l, .. # installing d2l\n       tensorflow, d2l, .. # installing d2l\n       paddle, d2l, .. # installing d2l\n\n\n[slides]\n\ntop_right = <img height=80px src='http://d2l.ai/_static/logo-with-text.png'/>\n\ngithub_repo = pytorch, d2l-ai/d2l-zh-pytorch-slides\n"
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "d2l.bib",
          "type": "blob",
          "size": 59.62,
          "content": "\n@InProceedings{\t  Ahmed.Aly.Gonzalez.ea.2012,\n  title\t\t= {Scalable inference in latent variable models},\n  author\t= {Ahmed, Amr and Aly, Moahmed and Gonzalez, Joseph and\n\t\t  Narayanamurthy, Shravan and Smola, Alexander J},\n  booktitle\t= {Proceedings of the fifth ACM international conference on\n\t\t  Web search and data mining},\n  pages\t\t= {123--132},\n  year\t\t= {2012},\n  organization\t= {ACM}\n}\n\n@Article{\t  Aji.McEliece.2000,\n  title\t\t= {The generalized distributive law},\n  author\t= {Aji, Srinivas M and McEliece, Robert J},\n  journal\t= {IEEE transactions on Information Theory},\n  volume\t= {46},\n  number\t= {2},\n  pages\t\t= {325--343},\n  year\t\t= {2000},\n  publisher\t= {IEEE}\n}\n\n@Article{\t  Ba.Kiros.Hinton.2016,\n  title\t\t= {Layer normalization},\n  author\t= {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey\n\t\t  E},\n  journal\t= {arXiv preprint arXiv:1607.06450},\n  year\t\t= {2016}\n}\n\n@Article{\t  Bahdanau.Cho.Bengio.2014,\n  title\t\t= {Neural machine translation by jointly learning to align\n\t\t  and translate},\n  author\t= {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},\n  journal\t= {arXiv preprint arXiv:1409.0473},\n  year\t\t= {2014}\n}\n\n@InProceedings{\t  Bay.Tuytelaars.Van-Gool.2006,\n  title\t\t= {Surf: Speeded up robust features},\n  author\t= {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},\n  booktitle\t= {European conference on computer vision},\n  pages\t\t= {404--417},\n  year\t\t= {2006},\n  organization\t= {Springer}\n}\n\n@Article{\t  Bengio.Ducharme.Vincent.ea.2003,\n  title\t\t= {A neural probabilistic language model},\n  author\t= {Bengio, Yoshua and Ducharme, R{\\'e}jean and Vincent,\n\t\t  Pascal and Jauvin, Christian},\n  journal\t= {Journal of machine learning research},\n  volume\t= {3},\n  number\t= {Feb},\n  pages\t\t= {1137--1155},\n  year\t\t= {2003}\n}\n\n@Article{\t  Bishop.1995,\n  title\t\t= {Training with noise is equivalent to Tikhonov\n\t\t  regularization},\n  author\t= {Bishop, Chris M},\n  journal\t= {Neural computation},\n  volume\t= {7},\n  number\t= {1},\n  pages\t\t= {108--116},\n  year\t\t= {1995},\n  publisher\t= {MIT Press}\n}\n\n@Book{\t\t  Bishop.2006,\n  title\t\t= {Pattern recognition and machine learning},\n  author\t= {Bishop, Christopher M},\n  year\t\t= {2006},\n  publisher\t= {springer}\n}\n\n@InProceedings{\t  Bodla.Singh.Chellappa.ea.2017,\n  title\t\t= {Soft-NMS--improving object detection with one line of\n\t\t  code},\n  author\t= {Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and\n\t\t  Davis, Larry S},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {5561--5569},\n  year\t\t= {2017}\n}\n\n@Article{\t  Bojanowski.Grave.Joulin.ea.2017,\n  title\t\t= {Enriching word vectors with subword information},\n  author\t= {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand\n\t\t  and Mikolov, Tomas},\n  journal\t= {Transactions of the Association for Computational\n\t\t  Linguistics},\n  volume\t= {5},\n  pages\t\t= {135--146},\n  year\t\t= {2017},\n  publisher\t= {MIT Press}\n}\n\n@Book{\t\t  Bollobas.1999,\n  title\t\t= {Linear analysis},\n  author\t= {Bollob{\\'a}s, B},\n  year\t\t= {1999},\n  publisher\t= {Cambridge University Press, Cambridge}\n}\n\n@Article{\t  Bowman.Angeli.Potts.ea.2015,\n  title\t\t= {A large annotated corpus for learning natural language\n\t\t  inference},\n  author\t= {Bowman, Samuel R and Angeli, Gabor and Potts, Christopher\n\t\t  and Manning, Christopher D},\n  journal\t= {arXiv preprint arXiv:1508.05326},\n  year\t\t= {2015}\n}\n\n@Book{\t\t  Boyd.Vandenberghe.2004,\n  address\t= {Cambridge, England},\n  author\t= {Stephen Boyd and Lieven Vandenberghe},\n  publisher\t= {Cambridge University Press},\n  title\t\t= {Convex Optimization},\n  year\t\t= 2004\n}\n\n@InProceedings{\t  Brown.Cocke.Della-Pietra.ea.1988,\n  title\t\t= {A statistical approach to language translation},\n  author\t= {Brown, Peter F and Cocke, John and Della Pietra, Stephen A\n\t\t  and Della Pietra, Vincent J and Jelinek, Frederick and\n\t\t  Mercer, Robert L and Roossin, Paul},\n  booktitle\t= {Coling Budapest 1988 Volume 1: International Conference on\n\t\t  Computational Linguistics},\n  year\t\t= {1988}\n}\n\n@Article{\t  Brown.Cocke.Della-Pietra.ea.1990,\n  title\t\t= {A statistical approach to machine translation},\n  author\t= {Brown, Peter F and Cocke, John and Della Pietra, Stephen A\n\t\t  and Della Pietra, Vincent J and Jelinek, Frederick and\n\t\t  Lafferty, John and Mercer, Robert L and Roossin, Paul S},\n  journal\t= {Computational linguistics},\n  volume\t= {16},\n  number\t= {2},\n  pages\t\t= {79--85},\n  year\t\t= {1990}\n}\n\n@InProceedings{\t  Brown.Sandholm.2017,\n  title\t\t= {Libratus: The Superhuman AI for No-Limit Poker.},\n  author\t= {Brown, Noam and Sandholm, Tuomas},\n  booktitle\t= {IJCAI},\n  pages\t\t= {5226--5228},\n  year\t\t= {2017}\n}\n\n@Article{\t  Campbell.Hoane-Jr.Hsu.2002,\n  title\t\t= {Deep blue},\n  author\t= {Campbell, Murray and Hoane Jr, A Joseph and Hsu,\n\t\t  Feng-hsiung},\n  journal\t= {Artificial intelligence},\n  volume\t= {134},\n  number\t= {1-2},\n  pages\t\t= {57--83},\n  year\t\t= {2002},\n  publisher\t= {Elsevier}\n}\n\n@InCollection{\t  Canny.1987,\n  title\t\t= {A computational approach to edge detection},\n  author\t= {Canny, John},\n  booktitle\t= {Readings in computer vision},\n  pages\t\t= {184--203},\n  year\t\t= {1987},\n  publisher\t= {Elsevier}\n}\n\n@InProceedings{\t  Cer.Diab.Agirre.ea.2017,\n  title\t\t= {SemEval-2017 Task 1: Semantic Textual Similarity\n\t\t  Multilingual and Crosslingual Focused Evaluation},\n  author\t= {Cer, Daniel and Diab, Mona and Agirre, Eneko and\n\t\t  Lopez-Gazpio, I{\\~n}igo and Specia, Lucia},\n  booktitle\t= {Proceedings of the 11th International Workshop on Semantic\n\t\t  Evaluation (SemEval-2017)},\n  pages\t\t= {1--14},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Cheng.Dong.Lapata.2016,\n  title\t\t= {Long Short-Term Memory-Networks for Machine Reading},\n  author\t= {Cheng, Jianpeng and Dong, Li and Lapata, Mirella},\n  booktitle\t= {Proceedings of the 2016 Conference on Empirical Methods in\n\t\t  Natural Language Processing},\n  pages\t\t= {551--561},\n  year\t\t= {2016}\n}\n\n@Article{\t  Cho.Van-Merrienboer.Bahdanau.ea.2014,\n  title\t\t= {On the properties of neural machine translation:\n\t\t  Encoder-decoder approaches},\n  author\t= {Cho, Kyunghyun and Van Merri{\\\"e}nboer, Bart and Bahdanau,\n\t\t  Dzmitry and Bengio, Yoshua},\n  journal\t= {arXiv preprint arXiv:1409.1259},\n  year\t\t= {2014}\n}\n\n@Article{\t  Cho.Van-Merrienboer.Gulcehre.ea.2014,\n  title\t\t= {Learning phrase representations using RNN encoder-decoder\n\t\t  for statistical machine translation},\n  author\t= {Cho, Kyunghyun and Van Merri{\\\"e}nboer, Bart and Gulcehre,\n\t\t  Caglar and Bahdanau, Dzmitry and Bougares, Fethi and\n\t\t  Schwenk, Holger and Bengio, Yoshua},\n  journal\t= {arXiv preprint arXiv:1406.1078},\n  year\t\t= {2014}\n}\n\n@Book{\t\t  Chowdhury.2010,\n  title\t\t= {Introduction to modern information retrieval},\n  author\t= {Chowdhury, Gobinda G},\n  year\t\t= {2010},\n  publisher\t= {Facet publishing}\n}\n\n@Article{\t  Chung.Gulcehre.Cho.ea.2014,\n  title\t\t= {Empirical evaluation of gated recurrent neural networks on\n\t\t  sequence modeling},\n  author\t= {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun\n\t\t  and Bengio, Yoshua},\n  journal\t= {arXiv preprint arXiv:1412.3555},\n  year\t\t= {2014}\n}\n\n@Article{\t  Collobert.Weston.Bottou.ea.2011,\n  title\t\t= {Natural language processing (almost) from scratch},\n  author\t= {Collobert, Ronan and Weston, Jason and Bottou, L{\\'e}on\n\t\t  and Karlen, Michael and Kavukcuoglu, Koray and Kuksa,\n\t\t  Pavel},\n  journal\t= {Journal of machine learning research},\n  volume\t= {12},\n  number\t= {ARTICLE},\n  pages\t\t= {2493--2537},\n  year\t\t= {2011}\n}\n\n@Article{\t  Csiszar.2008,\n  title\t\t= {Axiomatic characterizations of information measures},\n  author\t= {Csisz{\\'a}r, Imre},\n  journal\t= {Entropy},\n  volume\t= {10},\n  number\t= {3},\n  pages\t\t= {261--273},\n  year\t\t= {2008},\n  publisher\t= {Molecular Diversity Preservation International}\n}\n\n@InProceedings{\t  Dalal.Triggs.2005,\n  title\t\t= {Histograms of oriented gradients for human detection},\n  author\t= {Dalal, Navneet and Triggs, Bill},\n  booktitle\t= {2005 IEEE computer society conference on computer vision\n\t\t  and pattern recognition (CVPR'05)},\n  volume\t= {1},\n  pages\t\t= {886--893},\n  year\t\t= {2005},\n  organization\t= {IEEE}\n}\n\n@Article{\t  De-Cock.2011,\n  title\t\t= {Ames, Iowa: Alternative to the Boston housing data as an\n\t\t  end of semester regression project},\n  author\t= {De Cock, Dean},\n  journal\t= {Journal of Statistics Education},\n  volume\t= {19},\n  number\t= {3},\n  year\t\t= {2011},\n  publisher\t= {Taylor \\& Francis}\n}\n\n@InProceedings{\t  DeCandia.Hastorun.Jampani.ea.2007,\n  title\t\t= {Dynamo: Amazon's highly available key-value store},\n  author\t= {DeCandia, Giuseppe and Hastorun, Deniz and Jampani, Madan\n\t\t  and Kakulapati, Gunavardhan and Lakshman, Avinash and\n\t\t  Pilchin, Alex and Sivasubramanian, Swaminathan and\n\t\t  Vosshall, Peter and Vogels, Werner},\n  booktitle\t= {ACM SIGOPS operating systems review},\n  volume\t= {41},\n  number\t= {6},\n  pages\t\t= {205--220},\n  year\t\t= {2007},\n  organization\t= {ACM}\n}\n\n@Article{\t  Devlin.Chang.Lee.ea.2018,\n  title\t\t= {Bert: Pre-training of deep bidirectional transformers for\n\t\t  language understanding},\n  author\t= {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and\n\t\t  Toutanova, Kristina},\n  journal\t= {arXiv preprint arXiv:1810.04805},\n  year\t\t= {2018}\n}\n\n@InProceedings{\t  Doersch.Gupta.Efros.2015,\n  title\t\t= {Unsupervised visual representation learning by context\n\t\t  prediction},\n  author\t= {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {1422--1430},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Dosovitskiy.Beyer.Kolesnikov.ea.2021,\n  title\t\t= {An image is worth 16x16 words: Transformers for image\n\t\t  recognition at scale},\n  author\t= {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov,\n\t\t  Alexander and Weissenborn, Dirk and Zhai, Xiaohua and\n\t\t  Unterthiner, Thomas and Dehghani, Mostafa and Minderer,\n\t\t  Matthias and Heigold, Georg and Gelly, Sylvain and others},\n  booktitle\t= {International Conference on Learning Representations},\n  year\t\t= {2021}\n}\n\n@InCollection{\t  Doucet.De-Freitas.Gordon.2001,\n  title\t\t= {An introduction to sequential Monte Carlo methods},\n  author\t= {Doucet, Arnaud and De Freitas, Nando and Gordon, Neil},\n  booktitle\t= {Sequential Monte Carlo methods in practice},\n  pages\t\t= {3--14},\n  year\t\t= {2001},\n  publisher\t= {Springer}\n}\n\n@Article{\t  Duchi.Hazan.Singer.2011,\n  title\t\t= {Adaptive subgradient methods for online learning and\n\t\t  stochastic optimization},\n  author\t= {Duchi, John and Hazan, Elad and Singer, Yoram},\n  journal\t= {Journal of Machine Learning Research},\n  volume\t= {12},\n  number\t= {Jul},\n  pages\t\t= {2121--2159},\n  year\t\t= {2011}\n}\n\n@Article{\t  Dumoulin.Visin.2016,\n  title\t\t= {A guide to convolution arithmetic for deep learning},\n  author\t= {Dumoulin, Vincent and Visin, Francesco},\n  journal\t= {arXiv preprint arXiv:1603.07285},\n  year\t\t= {2016}\n}\n\n@Article{\t  Edelman.Ostrovsky.Schwarz.2007,\n  title\t\t= {Internet advertising and the generalized second-price\n\t\t  auction: Selling billions of dollars worth of keywords},\n  author\t= {Edelman, Benjamin and Ostrovsky, Michael and Schwarz,\n\t\t  Michael},\n  journal\t= {American economic review},\n  volume\t= {97},\n  number\t= {1},\n  pages\t\t= {242--259},\n  year\t\t= {2007}\n}\n\n@InProceedings{\t  Flammarion.Bach.2015,\n  title\t\t= {From averaging to acceleration, there is only a\n\t\t  step-size},\n  author\t= {Flammarion, Nicolas and Bach, Francis},\n  booktitle\t= {Conference on Learning Theory},\n  pages\t\t= {658--695},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Gatys.Ecker.Bethge.2016,\n  title\t\t= {Image style transfer using convolutional neural networks},\n  author\t= {Gatys, Leon A and Ecker, Alexander S and Bethge,\n\t\t  Matthias},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {2414--2423},\n  year\t\t= {2016}\n}\n\n@Article{\t  Ginibre.1965,\n  title\t\t= {Statistical ensembles of complex, quaternion, and real\n\t\t  matrices},\n  author\t= {Ginibre, Jean},\n  journal\t= {Journal of Mathematical Physics},\n  volume\t= {6},\n  number\t= {3},\n  pages\t\t= {440--449},\n  year\t\t= {1965},\n  publisher\t= {AIP}\n}\n\n@InProceedings{\t  Girshick.2015,\n  title\t\t= {Fast r-cnn},\n  author\t= {Girshick, Ross},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {1440--1448},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Girshick.Donahue.Darrell.ea.2014,\n  title\t\t= {Rich feature hierarchies for accurate object detection and\n\t\t  semantic segmentation},\n  author\t= {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and\n\t\t  Malik, Jitendra},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {580--587},\n  year\t\t= {2014}\n}\n\n@InProceedings{\t  Glorot.Bengio.2010,\n  title\t\t= {Understanding the difficulty of training deep feedforward\n\t\t  neural networks},\n  author\t= {Glorot, Xavier and Bengio, Yoshua},\n  booktitle\t= {Proceedings of the thirteenth international conference on\n\t\t  artificial intelligence and statistics},\n  pages\t\t= {249--256},\n  year\t\t= {2010}\n}\n\n@Article{\t  Goh.2017,\n  author\t= {Goh, Gabriel},\n  title\t\t= {Why Momentum Really Works},\n  journal\t= {Distill},\n  year\t\t= {2017},\n  url\t\t= {http://distill.pub/2017/momentum},\n  doi\t\t= {10.23915/distill.00006}\n}\n\n@Article{\t  Goldberg.Nichols.Oki.ea.1992,\n  title\t\t= {Using collaborative filtering to weave an information\n\t\t  tapestry},\n  author\t= {Goldberg, David and Nichols, David and Oki, Brian M and\n\t\t  Terry, Douglas},\n  journal\t= {Communications of the ACM},\n  volume\t= {35},\n  number\t= {12},\n  pages\t\t= {61--71},\n  year\t\t= {1992},\n  publisher\t= {Association for Computing Machinery, Inc.}\n}\n\n@Book{\t\t  Goodfellow.Bengio.Courville.2016,\n  title\t\t= {Deep Learning},\n  author\t= {Ian Goodfellow and Yoshua Bengio and Aaron Courville},\n  publisher\t= {MIT Press},\n  note\t\t= {\\url{http://www.deeplearningbook.org}},\n  year\t\t= {2016}\n}\n\n@InProceedings{\t  Goodfellow.Pouget-Abadie.Mirza.ea.2014,\n  title\t\t= {Generative adversarial nets},\n  author\t= {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi\n\t\t  and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and\n\t\t  Courville, Aaron and Bengio, Yoshua},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {2672--2680},\n  year\t\t= {2014}\n}\n\n@Article{\t  Gotmare.Keskar.Xiong.ea.2018,\n  title\t\t= {A Closer Look at Deep Learning Heuristics: Learning rate\n\t\t  restarts, Warmup and Distillation},\n  author\t= {Gotmare, Akhilesh and Keskar, Nitish Shirish and Xiong,\n\t\t  Caiming and Socher, Richard},\n  journal\t= {arXiv preprint arXiv:1810.13243},\n  year\t\t= {2018}\n}\n\n@Article{\t  Graves.2013,\n  title\t\t= {Generating sequences with recurrent neural networks},\n  author\t= {Graves, Alex},\n  journal\t= {arXiv preprint arXiv:1308.0850},\n  year\t\t= {2013}\n}\n\n@Article{\t  Graves.Schmidhuber.2005,\n  title\t\t= {Framewise phoneme classification with bidirectional LSTM\n\t\t  and other neural network architectures},\n  author\t= {Graves, Alex and Schmidhuber, J{\\\"u}rgen},\n  journal\t= {Neural networks},\n  volume\t= {18},\n  number\t= {5-6},\n  pages\t\t= {602--610},\n  year\t\t= {2005},\n  publisher\t= {Elsevier}\n}\n\n@InCollection{\t  Gunawardana.Shani.2015,\n  title\t\t= {Evaluating recommender systems},\n  author\t= {Gunawardana, Asela and Shani, Guy},\n  booktitle\t= {Recommender systems handbook},\n  pages\t\t= {265--308},\n  year\t\t= {2015},\n  publisher\t= {Springer}\n}\n\n@InProceedings{\t  Guo.Tang.Ye.ea.2017,\n  title\t\t= {DeepFM: a factorization-machine based neural network for\n\t\t  CTR prediction},\n  author\t= {Guo, Huifeng and Tang, Ruiming and Ye, Yunming and Li,\n\t\t  Zhenguo and He, Xiuqiang},\n  booktitle\t= {Proceedings of the 26th International Joint Conference on\n\t\t  Artificial Intelligence},\n  pages\t\t= {1725--1731},\n  year\t\t= {2017},\n  organization\t= {AAAI Press}\n}\n\n@Article{\t  Hadjis.Zhang.Mitliagkas.ea.2016,\n  title\t\t= {Omnivore: An optimizer for multi-device deep learning on\n\t\t  cpus and gpus},\n  author\t= {Hadjis, Stefan and Zhang, Ce and Mitliagkas, Ioannis and\n\t\t  Iter, Dan and R{\\'e}, Christopher},\n  journal\t= {arXiv preprint arXiv:1606.04487},\n  year\t\t= {2016}\n}\n\n@InProceedings{\t  Hazan.Rakhlin.Bartlett.2008,\n  title\t\t= {Adaptive online gradient descent},\n  author\t= {Hazan, Elad and Rakhlin, Alexander and Bartlett, Peter L},\n  booktitle\t= {Advances in Neural Information Processing Systems},\n  pages\t\t= {65--72},\n  year\t\t= {2008}\n}\n\n@InProceedings{\t  He.Chua.2017,\n  title\t\t= {Neural factorization machines for sparse predictive\n\t\t  analytics},\n  author\t= {He, Xiangnan and Chua, Tat-Seng},\n  booktitle\t= {Proceedings of the 40th International ACM SIGIR conference\n\t\t  on Research and Development in Information Retrieval},\n  pages\t\t= {355--364},\n  year\t\t= {2017},\n  organization\t= {ACM}\n}\n\n@InProceedings{\t  He.Gkioxari.Dollar.ea.2017,\n  title\t\t= {Mask r-cnn},\n  author\t= {He, Kaiming and Gkioxari, Georgia and Doll{\\'a}r, Piotr\n\t\t  and Girshick, Ross},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {2961--2969},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  He.Liao.Zhang.ea.2017,\n  title\t\t= {Neural collaborative filtering},\n  author\t= {He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie,\n\t\t  Liqiang and Hu, Xia and Chua, Tat-Seng},\n  booktitle\t= {Proceedings of the 26th international conference on world\n\t\t  wide web},\n  pages\t\t= {173--182},\n  year\t\t= {2017},\n  organization\t= {International World Wide Web Conferences Steering\n\t\t  Committee}\n}\n\n@InProceedings{\t  He.Zhang.Ren.ea.2015,\n  title\t\t= {Delving deep into rectifiers: Surpassing human-level\n\t\t  performance on imagenet classification},\n  author\t= {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun,\n\t\t  Jian},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {1026--1034},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  He.Zhang.Ren.ea.2016,\n  title\t\t= {Deep residual learning for image recognition},\n  author\t= {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun,\n\t\t  Jian},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {770--778},\n  year\t\t= {2016}\n}\n\n@InProceedings{\t  He.Zhang.Ren.ea.2016*1,\n  title\t\t= {Identity mappings in deep residual networks},\n  author\t= {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun,\n\t\t  Jian},\n  booktitle\t= {European conference on computer vision},\n  pages\t\t= {630--645},\n  year\t\t= {2016},\n  organization\t= {Springer}\n}\n\n@Book{\t\t  Hebb.Hebb.1949,\n  title\t\t= {The organization of behavior},\n  author\t= {Hebb, Donald Olding and Hebb, DO},\n  volume\t= {65},\n  year\t\t= {1949},\n  publisher\t= {Wiley New York}\n}\n\n@Article{\t  Hendrycks.Gimpel.2016,\n  title\t\t= {Gaussian error linear units (gelus)},\n  author\t= {Hendrycks, Dan and Gimpel, Kevin},\n  journal\t= {arXiv preprint arXiv:1606.08415},\n  year\t\t= {2016}\n}\n\n@Book{\t\t  Hennessy.Patterson.2011,\n  title\t\t= {Computer architecture: a quantitative approach},\n  author\t= {Hennessy, John L and Patterson, David A},\n  year\t\t= {2011},\n  publisher\t= {Elsevier}\n}\n\n@InProceedings{\t  Herlocker.Konstan.Borchers.ea.1999,\n  title\t\t= {An algorithmic framework for performing collaborative\n\t\t  filtering},\n  author\t= {Herlocker, Jonathan L and Konstan, Joseph A and Borchers,\n\t\t  Al and Riedl, John},\n  booktitle\t= {22nd Annual International ACM SIGIR Conference on Research\n\t\t  and Development in Information Retrieval, SIGIR 1999},\n  pages\t\t= {230--237},\n  year\t\t= {1999},\n  organization\t= {Association for Computing Machinery, Inc}\n}\n\n@Article{\t  Hidasi.Karatzoglou.Baltrunas.ea.2015,\n  title\t\t= {Session-based recommendations with recurrent neural\n\t\t  networks},\n  author\t= {Hidasi, Bal{\\'a}zs and Karatzoglou, Alexandros and\n\t\t  Baltrunas, Linas and Tikk, Domonkos},\n  journal\t= {arXiv preprint arXiv:1511.06939},\n  year\t\t= {2015}\n}\n\n@Misc{\t\t  Hochreiter.Bengio.Frasconi.ea.2001,\n  title\t\t= {Gradient flow in recurrent nets: the difficulty of\n\t\t  learning long-term dependencies},\n  author\t= {Hochreiter, Sepp and Bengio, Yoshua and Frasconi, Paolo\n\t\t  and Schmidhuber, J{\\\"u}rgen and others},\n  year\t\t= {2001},\n  publisher\t= {A field guide to dynamical recurrent neural networks. IEEE\n\t\t  Press}\n}\n\n@Article{\t  Hochreiter.Schmidhuber.1997,\n  title\t\t= {Long short-term memory},\n  author\t= {Hochreiter, Sepp and Schmidhuber, J{\\\"u}rgen},\n  journal\t= {Neural computation},\n  volume\t= {9},\n  number\t= {8},\n  pages\t\t= {1735--1780},\n  year\t\t= {1997},\n  publisher\t= {MIT Press}\n}\n\n@InProceedings{\t  Hoyer.Janzing.Mooij.ea.2009,\n  title\t\t= {Nonlinear causal discovery with additive noise models},\n  author\t= {Hoyer, Patrik O and Janzing, Dominik and Mooij, Joris M\n\t\t  and Peters, Jonas and Sch{\\\"o}lkopf, Bernhard},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {689--696},\n  year\t\t= {2009}\n}\n\n@InProceedings{\t  Hu.Koren.Volinsky.2008,\n  title\t\t= {Collaborative filtering for implicit feedback datasets},\n  author\t= {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},\n  booktitle\t= {2008 Eighth IEEE International Conference on Data Mining},\n  pages\t\t= {263--272},\n  year\t\t= {2008},\n  organization\t= {Ieee}\n}\n\n@Article{\t  Hu.Lee.Aggarwal.ea.2020,\n  title\t\t= {Text Style Transfer: A Review and Experimental\n\t\t  Evaluation},\n  author\t= {Hu, Zhiqiang and Lee, Roy Ka-Wei and Aggarwal, Charu C and\n\t\t  Zhang, Aston},\n  journal\t= {arXiv preprint arXiv:2010.12742},\n  year\t\t= {2020}\n}\n\n@InProceedings{\t  Hu.Shen.Sun.2018,\n  title\t\t= {Squeeze-and-excitation networks},\n  author\t= {Hu, Jie and Shen, Li and Sun, Gang},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {7132--7141},\n  year\t\t= {2018}\n}\n\n@InProceedings{\t  Huang.Liu.Van-Der-Maaten.ea.2017,\n  title\t\t= {Densely connected convolutional networks},\n  author\t= {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and\n\t\t  Weinberger, Kilian Q},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {4700--4708},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Ioffe.2017,\n  title\t\t= {Batch renormalization: Towards reducing minibatch\n\t\t  dependence in batch-normalized models},\n  author\t= {Ioffe, Sergey},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {1945--1953},\n  year\t\t= {2017}\n}\n\n@Article{\t  Ioffe.Szegedy.2015,\n  title\t\t= {Batch normalization: Accelerating deep network training by\n\t\t  reducing internal covariate shift},\n  author\t= {Ioffe, Sergey and Szegedy, Christian},\n  journal\t= {arXiv preprint arXiv:1502.03167},\n  year\t\t= {2015}\n}\n\n@Article{\t  Izmailov.Podoprikhin.Garipov.ea.2018,\n  title\t\t= {Averaging weights leads to wider optima and better\n\t\t  generalization},\n  author\t= {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov,\n\t\t  Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},\n  journal\t= {arXiv preprint arXiv:1803.05407},\n  year\t\t= {2018}\n}\n\n@Book{\t\t  Jaeger.2002,\n  title\t\t= {Tutorial on training recurrent neural networks, covering\n\t\t  BPPT, RTRL, EKF and the\" echo state network\" approach},\n  author\t= {Jaeger, Herbert},\n  volume\t= {5},\n  year\t\t= {2002},\n  publisher\t= {GMD-Forschungszentrum Informationstechnik Bonn}\n}\n\n@Book{\t\t  James.2007,\n  title\t\t= {The principles of psychology},\n  author\t= {James, William},\n  volume\t= {1},\n  year\t\t= {2007},\n  publisher\t= {Cosimo, Inc.}\n}\n\n@Article{\t  Jia.Song.He.ea.2018,\n  title\t\t= {Highly scalable deep learning training system with\n\t\t  mixed-precision: Training imagenet in four minutes},\n  author\t= {Jia, Xianyan and Song, Shutao and He, Wei and Wang,\n\t\t  Yangzihao and Rong, Haidong and Zhou, Feihu and Xie,\n\t\t  Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei\n\t\t  and others},\n  journal\t= {arXiv preprint arXiv:1807.11205},\n  year\t\t= {2018}\n}\n\n@InProceedings{\t  Jouppi.Young.Patil.ea.2017,\n  title\t\t= {In-datacenter performance analysis of a tensor processing\n\t\t  unit},\n  author\t= {Jouppi, Norman P and Young, Cliff and Patil, Nishant and\n\t\t  Patterson, David and Agrawal, Gaurav and Bajwa, Raminder\n\t\t  and Bates, Sarah and Bhatia, Suresh and Boden, Nan and\n\t\t  Borchers, Al and others},\n  booktitle\t= {2017 ACM/IEEE 44th Annual International Symposium on\n\t\t  Computer Architecture (ISCA)},\n  pages\t\t= {1--12},\n  year\t\t= {2017},\n  organization\t= {IEEE}\n}\n\n@Article{\t  Karras.Aila.Laine.ea.2017,\n  title\t\t= {Progressive growing of gans for improved quality,\n\t\t  stability, and variation},\n  author\t= {Karras, Tero and Aila, Timo and Laine, Samuli and\n\t\t  Lehtinen, Jaakko},\n  journal\t= {arXiv preprint arXiv:1710.10196},\n  year\t\t= {2017}\n}\n\n@Article{\t  Kim.2014,\n  title\t\t= {Convolutional neural networks for sentence\n\t\t  classification},\n  author\t= {Kim, Yoon},\n  journal\t= {arXiv preprint arXiv:1408.5882},\n  year\t\t= {2014}\n}\n\n@Article{\t  Kingma.Ba.2014,\n  title\t\t= {Adam: A method for stochastic optimization},\n  author\t= {Kingma, Diederik P and Ba, Jimmy},\n  journal\t= {arXiv preprint arXiv:1412.6980},\n  year\t\t= {2014}\n}\n\n@Book{\t\t  Koller.Friedman.2009,\n  title\t\t= {Probabilistic graphical models: principles and\n\t\t  techniques},\n  author\t= {Koller, Daphne and Friedman, Nir},\n  year\t\t= {2009},\n  publisher\t= {MIT press}\n}\n\n@Article{\t  Kolter.2008,\n  title\t\t= {Linear Algebra Review and Reference},\n  author\t= {Kolter, Zico},\n  journal\t= {Available online: http},\n  year\t\t= {2008}\n}\n\n@InProceedings{\t  Koren.2009,\n  title\t\t= {Collaborative filtering with temporal dynamics},\n  author\t= {Koren, Yehuda},\n  booktitle\t= {Proceedings of the 15th ACM SIGKDD international\n\t\t  conference on Knowledge discovery and data mining},\n  pages\t\t= {447--456},\n  year\t\t= {2009},\n  organization\t= {ACM}\n}\n\n@Article{\t  Koren.Bell.Volinsky.2009,\n  title\t\t= {Matrix factorization techniques for recommender systems},\n  author\t= {Koren, Yehuda and Bell, Robert and Volinsky, Chris},\n  journal\t= {Computer},\n  number\t= {8},\n  pages\t\t= {30--37},\n  year\t\t= {2009},\n  publisher\t= {IEEE}\n}\n\n@InProceedings{\t  Krizhevsky.Sutskever.Hinton.2012,\n  title\t\t= {Imagenet classification with deep convolutional neural\n\t\t  networks},\n  author\t= {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey\n\t\t  E},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {1097--1105},\n  year\t\t= {2012}\n}\n\n@Article{\t  Kung.1988,\n  title\t\t= {VLSI array processors},\n  author\t= {Kung, Sun Yuan},\n  journal\t= {Englewood Cliffs, NJ, Prentice Hall, 1988, 685 p. Research\n\t\t  supported by the Semiconductor Research Corp., SDIO, NSF,\n\t\t  and US Navy.},\n  year\t\t= {1988}\n}\n\n@Article{\t  LeCun.Bottou.Bengio.ea.1998,\n  title\t\t= {Gradient-based learning applied to document recognition},\n  author\t= {LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and\n\t\t  Haffner, Patrick and others},\n  journal\t= {Proceedings of the IEEE},\n  volume\t= {86},\n  number\t= {11},\n  pages\t\t= {2278--2324},\n  year\t\t= {1998},\n  publisher\t= {Taipei, Taiwan}\n}\n\n@PhDThesis{\t  Li.2017,\n  title\t\t= {Scaling Distributed Machine Learning with System and\n\t\t  Algorithm Co-design},\n  author\t= {Li, Mu},\n  year\t\t= {2017},\n  school\t= {PhD Thesis, CMU}\n}\n\n@InProceedings{\t  Li.Andersen.Park.ea.2014,\n  title\t\t= {Scaling distributed machine learning with the parameter\n\t\t  server},\n  author\t= {Li, Mu and Andersen, David G and Park, Jun Woo and Smola,\n\t\t  Alexander J and Ahmed, Amr and Josifovski, Vanja and Long,\n\t\t  James and Shekita, Eugene J and Su, Bor-Yiing},\n  booktitle\t= {11th $\\{$USENIX$\\}$ Symposium on Operating Systems Design\n\t\t  and Implementation ($\\{$OSDI$\\}$ 14)},\n  pages\t\t= {583--598},\n  year\t\t= {2014}\n}\n\n@Article{\t  Lin.Chen.Yan.2013,\n  title\t\t= {Network in network},\n  author\t= {Lin, Min and Chen, Qiang and Yan, Shuicheng},\n  journal\t= {arXiv preprint arXiv:1312.4400},\n  year\t\t= {2013}\n}\n\n@Article{\t  Lin.Feng.Santos.ea.2017,\n  title\t\t= {A structured self-attentive sentence embedding},\n  author\t= {Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira\n\t\t  dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio,\n\t\t  Yoshua},\n  journal\t= {arXiv preprint arXiv:1703.03130},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Lin.Goyal.Girshick.ea.2017,\n  title\t\t= {Focal loss for dense object detection},\n  author\t= {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He,\n\t\t  Kaiming and Doll{\\'a}r, Piotr},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {2980--2988},\n  year\t\t= {2017}\n}\n\n@Article{\t  Lin.Lv.Zhu.ea.2010,\n  title\t\t= {Imagenet classification: fast descriptor coding and\n\t\t  large-scale svm training},\n  author\t= {Lin, Yuanqing and Lv, F and Zhu, S and Yang, M and Cour, T\n\t\t  and Yu, K and Cao, L and Li, Z and Tsai, MH and Zhou, X and\n\t\t  others},\n  journal\t= {Large scale visual recognition challenge},\n  year\t\t= {2010}\n}\n\n@Article{\t  Lipton.Steinhardt.2018,\n  title\t\t= {Troubling trends in machine learning scholarship},\n  author\t= {Lipton, Zachary C and Steinhardt, Jacob},\n  journal\t= {arXiv preprint arXiv:1807.03341},\n  year\t\t= {2018}\n}\n\n@InProceedings{\t  Liu.Anguelov.Erhan.ea.2016,\n  title\t\t= {Ssd: Single shot multibox detector},\n  author\t= {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and\n\t\t  Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and\n\t\t  Berg, Alexander C},\n  booktitle\t= {European conference on computer vision},\n  pages\t\t= {21--37},\n  year\t\t= {2016},\n  organization\t= {Springer}\n}\n\n@Article{\t  Liu.Ott.Goyal.ea.2019,\n  title\t\t= {Roberta: A robustly optimized bert pretraining approach},\n  author\t= {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei\n\t\t  and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis,\n\t\t  Mike and Zettlemoyer, Luke and Stoyanov, Veselin},\n  journal\t= {arXiv preprint arXiv:1907.11692},\n  year\t\t= {2019}\n}\n\n@InProceedings{\t  Long.Shelhamer.Darrell.2015,\n  title\t\t= {Fully convolutional networks for semantic segmentation},\n  author\t= {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {3431--3440},\n  year\t\t= {2015}\n}\n\n@Article{\t  Loshchilov.Hutter.2016,\n  title\t\t= {Sgdr: Stochastic gradient descent with warm restarts},\n  author\t= {Loshchilov, Ilya and Hutter, Frank},\n  journal\t= {arXiv preprint arXiv:1608.03983},\n  year\t\t= {2016}\n}\n\n@Article{\t  Lowe.2004,\n  title\t\t= {Distinctive image features from scale-invariant\n\t\t  keypoints},\n  author\t= {Lowe, David G},\n  journal\t= {International journal of computer vision},\n  volume\t= {60},\n  number\t= {2},\n  pages\t\t= {91--110},\n  year\t\t= {2004},\n  publisher\t= {Springer}\n}\n\n@Article{\t  Luo.Wang.Shao.ea.2018,\n  title\t\t= {Towards understanding regularization in batch\n\t\t  normalization},\n  author\t= {Luo, Ping and Wang, Xinjiang and Shao, Wenqi and Peng,\n\t\t  Zhanglin},\n  journal\t= {arXiv preprint},\n  year\t\t= {2018}\n}\n\n@InProceedings{\t  Maas.Daly.Pham.ea.2011,\n  title\t\t= {Learning word vectors for sentiment analysis},\n  author\t= {Maas, Andrew L and Daly, Raymond E and Pham, Peter T and\n\t\t  Huang, Dan and Ng, Andrew Y and Potts, Christopher},\n  booktitle\t= {Proceedings of the 49th annual meeting of the association\n\t\t  for computational linguistics: Human language\n\t\t  technologies-volume 1},\n  pages\t\t= {142--150},\n  year\t\t= {2011},\n  organization\t= {Association for Computational Linguistics}\n}\n\n@InProceedings{\t  McCann.Bradbury.Xiong.ea.2017,\n  title\t\t= {Learned in translation: Contextualized word vectors},\n  author\t= {McCann, Bryan and Bradbury, James and Xiong, Caiming and\n\t\t  Socher, Richard},\n  booktitle\t= {Advances in Neural Information Processing Systems},\n  pages\t\t= {6294--6305},\n  year\t\t= {2017}\n}\n\n@Article{\t  McCulloch.Pitts.1943,\n  title\t\t= {A logical calculus of the ideas immanent in nervous\n\t\t  activity},\n  author\t= {McCulloch, Warren S and Pitts, Walter},\n  journal\t= {The bulletin of mathematical biophysics},\n  volume\t= {5},\n  number\t= {4},\n  pages\t\t= {115--133},\n  year\t\t= {1943},\n  publisher\t= {Springer}\n}\n\n@InProceedings{\t  McMahan.Holt.Sculley.ea.2013,\n  title\t\t= {Ad click prediction: a view from the trenches},\n  author\t= {McMahan, H Brendan and Holt, Gary and Sculley, David and\n\t\t  Young, Michael and Ebner, Dietmar and Grady, Julian and\n\t\t  Nie, Lan and Phillips, Todd and Davydov, Eugene and\n\t\t  Golovin, Daniel and others},\n  booktitle\t= {Proceedings of the 19th ACM SIGKDD international\n\t\t  conference on Knowledge discovery and data mining},\n  pages\t\t= {1222--1230},\n  year\t\t= {2013},\n  organization\t= {ACM}\n}\n\n@Article{\t  Merity.Xiong.Bradbury.ea.2016,\n  title\t\t= {Pointer sentinel mixture models},\n  author\t= {Merity, Stephen and Xiong, Caiming and Bradbury, James and\n\t\t  Socher, Richard},\n  journal\t= {arXiv preprint arXiv:1609.07843},\n  year\t\t= {2016}\n}\n\n@Article{\t  Mikolov.Chen.Corrado.ea.2013,\n  title\t\t= {Efficient estimation of word representations in vector\n\t\t  space},\n  author\t= {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean,\n\t\t  Jeffrey},\n  journal\t= {arXiv preprint arXiv:1301.3781},\n  year\t\t= {2013}\n}\n\n@InProceedings{\t  Mikolov.Sutskever.Chen.ea.2013,\n  title\t\t= {Distributed representations of words and phrases and their\n\t\t  compositionality},\n  author\t= {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and\n\t\t  Corrado, Greg S and Dean, Jeff},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {3111--3119},\n  year\t\t= {2013}\n}\n\n@InProceedings{\t  Mirhoseini.Pham.Le.ea.2017,\n  title\t\t= {Device placement optimization with reinforcement\n\t\t  learning},\n  author\t= {Mirhoseini, Azalia and Pham, Hieu and Le, Quoc V and\n\t\t  Steiner, Benoit and Larsen, Rasmus and Zhou, Yuefeng and\n\t\t  Kumar, Naveen and Norouzi, Mohammad and Bengio, Samy and\n\t\t  Dean, Jeff},\n  booktitle\t= {Proceedings of the 34th International Conference on\n\t\t  Machine Learning-Volume 70},\n  pages\t\t= {2430--2439},\n  year\t\t= {2017},\n  organization\t= {JMLR. org}\n}\n\n@InProceedings{\t  Mnih.Heess.Graves.ea.2014,\n  title\t\t= {Recurrent models of visual attention},\n  author\t= {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and\n\t\t  others},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {2204--2212},\n  year\t\t= {2014}\n}\n\n@Article{\t  Morey.Hoekstra.Rouder.ea.2016,\n  title\t\t= {The fallacy of placing confidence in confidence\n\t\t  intervals},\n  author\t= {Morey, Richard D and Hoekstra, Rink and Rouder, Jeffrey N\n\t\t  and Lee, Michael D and Wagenmakers, Eric-Jan},\n  journal\t= {Psychonomic bulletin \\& review},\n  volume\t= {23},\n  number\t= {1},\n  pages\t\t= {103--123},\n  year\t\t= {2016},\n  publisher\t= {Springer}\n}\n\n@Article{\t  Nadaraya.1964,\n  title\t\t= {On estimating regression},\n  author\t= {Nadaraya, Elizbar A},\n  journal\t= {Theory of Probability \\& Its Applications},\n  volume\t= {9},\n  number\t= {1},\n  pages\t\t= {141--142},\n  year\t\t= {1964},\n  publisher\t= {SIAM}\n}\n\n@Book{\t\t  Nesterov.2018,\n  title\t\t= {Lectures on convex optimization},\n  author\t= {Nesterov, Yurii},\n  volume\t= {137},\n  year\t\t= {2018},\n  publisher\t= {Springer}\n}\n\n@Misc{\t\t  Nesterov.Vial.2000,\n  title\t\t= {Confidence level solutions for stochastic programming,\n\t\t  Stochastic Programming E-Print Series},\n  author\t= {Nesterov, Yu and Vial, J-Ph},\n  year\t\t= {2000}\n}\n\n@Article{\t  Neyman.1937,\n  title\t\t= {Outline of a theory of statistical estimation based on the\n\t\t  classical theory of probability},\n  author\t= {Neyman, Jerzy},\n  journal\t= {Philosophical Transactions of the Royal Society of London.\n\t\t  Series A, Mathematical and Physical Sciences},\n  volume\t= {236},\n  number\t= {767},\n  pages\t\t= {333--380},\n  year\t\t= {1937},\n  publisher\t= {The Royal Society London}\n}\n\n@InProceedings{\t  Papineni.Roukos.Ward.ea.2002,\n  title\t\t= {BLEU: a method for automatic evaluation of machine\n\t\t  translation},\n  author\t= {Papineni, Kishore and Roukos, Salim and Ward, Todd and\n\t\t  Zhu, Wei-Jing},\n  booktitle\t= {Proceedings of the 40th annual meeting of the Association\n\t\t  for Computational Linguistics},\n  pages\t\t= {311--318},\n  year\t\t= {2002}\n}\n\n@Article{\t  Parikh.Tackstrom.Das.ea.2016,\n  title\t\t= {A decomposable attention model for natural language\n\t\t  inference},\n  author\t= {Parikh, Ankur P and T{\\\"a}ckstr{\\\"o}m, Oscar and Das,\n\t\t  Dipanjan and Uszkoreit, Jakob},\n  journal\t= {arXiv preprint arXiv:1606.01933},\n  year\t\t= {2016}\n}\n\n@InProceedings{\t  Park.Liu.Wang.ea.2019,\n  title\t\t= {Semantic image synthesis with spatially-adaptive\n\t\t  normalization},\n  author\t= {Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and\n\t\t  Zhu, Jun-Yan},\n  booktitle\t= {Proceedings of the IEEE Conference on Computer Vision and\n\t\t  Pattern Recognition},\n  pages\t\t= {2337--2346},\n  year\t\t= {2019}\n}\n\n@Article{\t  Paulus.Xiong.Socher.2017,\n  title\t\t= {A deep reinforced model for abstractive summarization},\n  author\t= {Paulus, Romain and Xiong, Caiming and Socher, Richard},\n  journal\t= {arXiv preprint arXiv:1705.04304},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Pennington.Schoenholz.Ganguli.2017,\n  title\t\t= {Resurrecting the sigmoid in deep learning through\n\t\t  dynamical isometry: theory and practice},\n  author\t= {Pennington, Jeffrey and Schoenholz, Samuel and Ganguli,\n\t\t  Surya},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {4785--4795},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Pennington.Socher.Manning.2014,\n  title\t\t= {Glove: Global vectors for word representation},\n  author\t= {Pennington, Jeffrey and Socher, Richard and Manning,\n\t\t  Christopher},\n  booktitle\t= {Proceedings of the 2014 conference on empirical methods in\n\t\t  natural language processing (EMNLP)},\n  pages\t\t= {1532--1543},\n  year\t\t= {2014}\n}\n\n@InProceedings{\t  Peters.Ammar.Bhagavatula.ea.2017,\n  title\t\t= {Semi-supervised sequence tagging with bidirectional\n\t\t  language models},\n  author\t= {Peters, Matthew and Ammar, Waleed and Bhagavatula, Chandra\n\t\t  and Power, Russell},\n  booktitle\t= {Proceedings of the 55th Annual Meeting of the Association\n\t\t  for Computational Linguistics (Volume 1: Long Papers)},\n  pages\t\t= {1756--1765},\n  year\t\t= {2017}\n}\n\n@Book{\t\t  Peters.Janzing.Scholkopf.2017,\n  title\t\t= {Elements of causal inference: foundations and learning\n\t\t  algorithms},\n  author\t= {Peters, Jonas and Janzing, Dominik and Sch{\\\"o}lkopf,\n\t\t  Bernhard},\n  year\t\t= {2017},\n  publisher\t= {MIT press}\n}\n\n@InProceedings{\t  Peters.Neumann.Iyyer.ea.2018,\n  title\t\t= {Deep Contextualized Word Representations},\n  author\t= {Peters, Matthew and Neumann, Mark and Iyyer, Mohit and\n\t\t  Gardner, Matt and Clark, Christopher and Lee, Kenton and\n\t\t  Zettlemoyer, Luke},\n  booktitle\t= {Proceedings of the 2018 Conference of the North American\n\t\t  Chapter of the Association for Computational Linguistics:\n\t\t  Human Language Technologies, Volume 1 (Long Papers)},\n  pages\t\t= {2227--2237},\n  year\t\t= {2018}\n}\n\n@Article{\t  Petersen.Pedersen.ea.2008,\n  title\t\t= {The matrix cookbook},\n  author\t= {Petersen, Kaare Brandt and Pedersen, Michael Syskind and\n\t\t  others},\n  journal\t= {Technical University of Denmark},\n  volume\t= {7},\n  number\t= {15},\n  pages\t\t= {510},\n  year\t\t= {2008}\n}\n\n@Article{\t  Polyak.1964,\n  title\t\t= {Some methods of speeding up the convergence of iteration\n\t\t  methods},\n  author\t= {Polyak, Boris T},\n  journal\t= {USSR Computational Mathematics and Mathematical Physics},\n  volume\t= {4},\n  number\t= {5},\n  pages\t\t= {1--17},\n  year\t\t= {1964},\n  publisher\t= {Elsevier}\n}\n\n@Article{\t  Quadrana.Cremonesi.Jannach.2018,\n  title\t\t= {Sequence-aware recommender systems},\n  author\t= {Quadrana, Massimo and Cremonesi, Paolo and Jannach,\n\t\t  Dietmar},\n  journal\t= {ACM Computing Surveys (CSUR)},\n  volume\t= {51},\n  number\t= {4},\n  pages\t\t= {66},\n  year\t\t= {2018},\n  publisher\t= {ACM}\n}\n\n@Article{\t  Radford.Metz.Chintala.2015,\n  title\t\t= {Unsupervised representation learning with deep\n\t\t  convolutional generative adversarial networks},\n  author\t= {Radford, Alec and Metz, Luke and Chintala, Soumith},\n  journal\t= {arXiv preprint arXiv:1511.06434},\n  year\t\t= {2015}\n}\n\n@Article{\t  Radford.Narasimhan.Salimans.ea.2018,\n  title\t\t= {Improving language understanding by generative\n\t\t  pre-training},\n  author\t= {Radford, Alec and Narasimhan, Karthik and Salimans, Tim\n\t\t  and Sutskever, Ilya},\n  journal\t= {OpenAI},\n  year\t\t= {2018}\n}\n\n@Article{\t  Radford.Wu.Child.ea.2019,\n  title\t\t= {Language models are unsupervised multitask learners},\n  author\t= {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan,\n\t\t  David and Amodei, Dario and Sutskever, Ilya},\n  journal\t= {OpenAI Blog},\n  volume\t= {1},\n  number\t= {8},\n  pages\t\t= {9},\n  year\t\t= {2019}\n}\n\n@Article{\t  Rajpurkar.Zhang.Lopyrev.ea.2016,\n  title\t\t= {Squad: 100,000+ questions for machine comprehension of\n\t\t  text},\n  author\t= {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin\n\t\t  and Liang, Percy},\n  journal\t= {arXiv preprint arXiv:1606.05250},\n  year\t\t= {2016}\n}\n\n@Article{\t  Reddi.Kale.Kumar.2019,\n  title\t\t= {On the convergence of Adam and beyond},\n  author\t= {Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},\n  journal\t= {arXiv preprint arXiv:1904.09237},\n  year\t\t= {2019}\n}\n\n@InProceedings{\t  Redmon.Divvala.Girshick.ea.2016,\n  title\t\t= {You only look once: Unified, real-time object detection},\n  author\t= {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and\n\t\t  Farhadi, Ali},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {779--788},\n  year\t\t= {2016}\n}\n\n@Article{\t  Reed.De-Freitas.2015,\n  title\t\t= {Neural programmer-interpreters},\n  author\t= {Reed, Scott and De Freitas, Nando},\n  journal\t= {arXiv preprint arXiv:1511.06279},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Ren.He.Girshick.ea.2015,\n  title\t\t= {Faster r-cnn: Towards real-time object detection with\n\t\t  region proposal networks},\n  author\t= {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun,\n\t\t  Jian},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {91--99},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Rendle.2010,\n  title\t\t= {Factorization machines},\n  author\t= {Rendle, Steffen},\n  booktitle\t= {2010 IEEE International Conference on Data Mining},\n  pages\t\t= {995--1000},\n  year\t\t= {2010},\n  organization\t= {IEEE}\n}\n\n@InProceedings{\t  Rendle.Freudenthaler.Gantner.ea.2009,\n  title\t\t= {BPR: Bayesian personalized ranking from implicit\n\t\t  feedback},\n  author\t= {Rendle, Steffen and Freudenthaler, Christoph and Gantner,\n\t\t  Zeno and Schmidt-Thieme, Lars},\n  booktitle\t= {Proceedings of the twenty-fifth conference on uncertainty\n\t\t  in artificial intelligence},\n  pages\t\t= {452--461},\n  year\t\t= {2009},\n  organization\t= {AUAI Press}\n}\n\n@Article{\t  Rumelhart.Hinton.Williams.ea.1988,\n  title\t\t= {Learning representations by back-propagating errors},\n  author\t= {Rumelhart, David E and Hinton, Geoffrey E and Williams,\n\t\t  Ronald J and others},\n  journal\t= {Cognitive modeling},\n  volume\t= {5},\n  number\t= {3},\n  pages\t\t= {1},\n  year\t\t= {1988}\n}\n\n@Book{\t\t  Russell.Norvig.2016,\n  title\t\t= {Artificial intelligence: a modern approach},\n  author\t= {Russell, Stuart J and Norvig, Peter},\n  year\t\t= {2016},\n  publisher\t= {Malaysia; Pearson Education Limited,}\n}\n\n@Article{\t  Salton.Wong.Yang.1975,\n  title\t\t= {A vector space model for automatic indexing},\n  author\t= {Salton, Gerard and Wong, Anita and Yang, Chung-Shu},\n  journal\t= {Communications of the ACM},\n  volume\t= {18},\n  number\t= {11},\n  pages\t\t= {613--620},\n  year\t\t= {1975},\n  publisher\t= {ACM}\n}\n\n@InProceedings{\t  Santurkar.Tsipras.Ilyas.ea.2018,\n  title\t\t= {How does batch normalization help optimization?},\n  author\t= {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew\n\t\t  and Madry, Aleksander},\n  booktitle\t= {Advances in Neural Information Processing Systems},\n  pages\t\t= {2483--2493},\n  year\t\t= {2018}\n}\n\n@Article{\t  Sarwar.Karypis.Konstan.ea.2001,\n  title\t\t= {Item-based collaborative filtering recommendation\n\t\t  algorithms.},\n  author\t= {Sarwar, Badrul Munir and Karypis, George and Konstan,\n\t\t  Joseph A and Riedl, John and others},\n  journal\t= {Www},\n  volume\t= {1},\n  pages\t\t= {285--295},\n  year\t\t= {2001}\n}\n\n@InProceedings{\t  Schein.Popescul.Ungar.ea.2002,\n  title\t\t= {Methods and metrics for cold-start recommendations},\n  author\t= {Schein, Andrew I and Popescul, Alexandrin and Ungar, Lyle\n\t\t  H and Pennock, David M},\n  booktitle\t= {Proceedings of the 25th annual international ACM SIGIR\n\t\t  conference on Research and development in information\n\t\t  retrieval},\n  pages\t\t= {253--260},\n  year\t\t= {2002},\n  organization\t= {ACM}\n}\n\n@Article{\t  Schuster.Paliwal.1997,\n  title\t\t= {Bidirectional recurrent neural networks},\n  author\t= {Schuster, Mike and Paliwal, Kuldip K},\n  journal\t= {IEEE Transactions on Signal Processing},\n  volume\t= {45},\n  number\t= {11},\n  pages\t\t= {2673--2681},\n  year\t\t= {1997},\n  publisher\t= {IEEE}\n}\n\n@InProceedings{\t  Sedhain.Menon.Sanner.ea.2015,\n  title\t\t= {Autorec: Autoencoders meet collaborative filtering},\n  author\t= {Sedhain, Suvash and Menon, Aditya Krishna and Sanner,\n\t\t  Scott and Xie, Lexing},\n  booktitle\t= {Proceedings of the 24th International Conference on World\n\t\t  Wide Web},\n  pages\t\t= {111--112},\n  year\t\t= {2015},\n  organization\t= {ACM}\n}\n\n@Article{\t  Sennrich.Haddow.Birch.2015,\n  title\t\t= {Neural machine translation of rare words with subword\n\t\t  units},\n  author\t= {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},\n  journal\t= {arXiv preprint arXiv:1508.07909},\n  year\t\t= {2015}\n}\n\n@Article{\t  Sergeev.Del-Balso.2018,\n  title\t\t= {Horovod: fast and easy distributed deep learning in\n\t\t  TensorFlow},\n  author\t= {Sergeev, Alexander and Del Balso, Mike},\n  journal\t= {arXiv preprint arXiv:1802.05799},\n  year\t\t= {2018}\n}\n\n@Article{\t  Shannon.1948,\n  author\t= {Shannon, Claude Elwood},\n  journal\t= {The Bell System Technical Journal},\n  month\t\t= {7},\n  number\t= 3,\n  pages\t\t= {379--423},\n  publisher\t= {Nokia Bell Labs},\n  title\t\t= {A Mathematical Theory of Communication},\n  volume\t= 27,\n  year\t\t= 1948\n}\n\n@InProceedings{\t  Shao.Yao.Sun.ea.2020,\n  title\t\t= {ControlVAE: Controllable Variational Autoencoder},\n  author\t= {Shao, Huajie and Yao, Shuochao and Sun, Dachun and Zhang,\n\t\t  Aston and Liu, Shengzhong and Liu, Dongxin and Wang, Jun\n\t\t  and Abdelzaher, Tarek},\n  booktitle\t= {Proceedings of the 37th International Conference on\n\t\t  Machine Learning},\n  year\t\t= {2020},\n  organization\t= {JMLR. org}\n}\n\n@Article{\t  Silver.Huang.Maddison.ea.2016,\n  title\t\t= {Mastering the game of Go with deep neural networks and\n\t\t  tree search},\n  author\t= {Silver, David and Huang, Aja and Maddison, Chris J and\n\t\t  Guez, Arthur and Sifre, Laurent and Van Den Driessche,\n\t\t  George and Schrittwieser, Julian and Antonoglou, Ioannis\n\t\t  and Panneershelvam, Veda and Lanctot, Marc and others},\n  journal\t= {nature},\n  volume\t= {529},\n  number\t= {7587},\n  pages\t\t= {484},\n  year\t\t= {2016},\n  publisher\t= {Nature Publishing Group}\n}\n\n@Article{\t  Simonyan.Zisserman.2014,\n  title\t\t= {Very deep convolutional networks for large-scale image\n\t\t  recognition},\n  author\t= {Simonyan, Karen and Zisserman, Andrew},\n  journal\t= {arXiv preprint arXiv:1409.1556},\n  year\t\t= {2014}\n}\n\n@Article{\t  Smola.Narayanamurthy.2010,\n  title\t\t= {An architecture for parallel topic models},\n  author\t= {Smola, Alexander and Narayanamurthy, Shravan},\n  journal\t= {Proceedings of the VLDB Endowment},\n  volume\t= {3},\n  number\t= {1-2},\n  pages\t\t= {703--710},\n  year\t\t= {2010},\n  publisher\t= {VLDB Endowment}\n}\n\n@Article{\t  Srivastava.Hinton.Krizhevsky.ea.2014,\n  title\t\t= {Dropout: a simple way to prevent neural networks from\n\t\t  overfitting},\n  author\t= {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky,\n\t\t  Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},\n  journal\t= {The Journal of Machine Learning Research},\n  volume\t= {15},\n  number\t= {1},\n  pages\t\t= {1929--1958},\n  year\t\t= {2014},\n  publisher\t= {JMLR. org}\n}\n\n@Book{\t\t  Strang.1993,\n  title\t\t= {Introduction to linear algebra},\n  author\t= {Strang, Gilbert},\n  volume\t= {3},\n  year\t\t= {1993},\n  publisher\t= {Wellesley-Cambridge Press Wellesley, MA}\n}\n\n@Article{\t  Su.Khoshgoftaar.2009,\n  title\t\t= {A survey of collaborative filtering techniques},\n  author\t= {Su, Xiaoyuan and Khoshgoftaar, Taghi M},\n  journal\t= {Advances in artificial intelligence},\n  volume\t= {2009},\n  year\t\t= {2009},\n  publisher\t= {Hindawi}\n}\n\n@InProceedings{\t  Sukhbaatar.Weston.Fergus.ea.2015,\n  title\t\t= {End-to-end memory networks},\n  author\t= {Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob\n\t\t  and others},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {2440--2448},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Sutskever.Martens.Dahl.ea.2013,\n  title\t\t= {On the importance of initialization and momentum in deep\n\t\t  learning},\n  author\t= {Sutskever, Ilya and Martens, James and Dahl, George and\n\t\t  Hinton, Geoffrey},\n  booktitle\t= {International conference on machine learning},\n  pages\t\t= {1139--1147},\n  year\t\t= {2013}\n}\n\n@InProceedings{\t  Sutskever.Vinyals.Le.2014,\n  title\t\t= {Sequence to sequence learning with neural networks},\n  author\t= {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {3104--3112},\n  year\t\t= {2014}\n}\n\n@InProceedings{\t  Szegedy.Ioffe.Vanhoucke.ea.2017,\n  title\t\t= {Inception-v4, inception-resnet and the impact of residual\n\t\t  connections on learning},\n  author\t= {Szegedy, Christian and Ioffe, Sergey and Vanhoucke,\n\t\t  Vincent and Alemi, Alexander A},\n  booktitle\t= {Thirty-First AAAI Conference on Artificial Intelligence},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Szegedy.Liu.Jia.ea.2015,\n  title\t\t= {Going deeper with convolutions},\n  author\t= {Szegedy, Christian and Liu, Wei and Jia, Yangqing and\n\t\t  Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and\n\t\t  Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich,\n\t\t  Andrew},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {1--9},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Szegedy.Vanhoucke.Ioffe.ea.2016,\n  title\t\t= {Rethinking the inception architecture for computer\n\t\t  vision},\n  author\t= {Szegedy, Christian and Vanhoucke, Vincent and Ioffe,\n\t\t  Sergey and Shlens, Jon and Wojna, Zbigniew},\n  booktitle\t= {Proceedings of the IEEE conference on computer vision and\n\t\t  pattern recognition},\n  pages\t\t= {2818--2826},\n  year\t\t= {2016}\n}\n\n@Article{\t  Tallec.Ollivier.2017,\n  title\t\t= {Unbiasing truncated backpropagation through time},\n  author\t= {Tallec, Corentin and Ollivier, Yann},\n  journal\t= {arXiv preprint arXiv:1705.08209},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Tang.Wang.2018,\n  title\t\t= {Personalized top-n sequential recommendation via\n\t\t  convolutional sequence embedding},\n  author\t= {Tang, Jiaxi and Wang, Ke},\n  booktitle\t= {Proceedings of the Eleventh ACM International Conference\n\t\t  on Web Search and Data Mining},\n  pages\t\t= {565--573},\n  year\t\t= {2018},\n  organization\t= {ACM}\n}\n\n@Article{\t  Tay.Dehghani.Bahri.ea.2020,\n  title\t\t= {Efficient transformers: A survey},\n  author\t= {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler,\n\t\t  Donald},\n  journal\t= {arXiv preprint arXiv:2009.06732},\n  year\t\t= {2020}\n}\n\n@Article{\t  Teye.Azizpour.Smith.2018,\n  title\t\t= {Bayesian uncertainty estimation for batch normalized deep\n\t\t  networks},\n  author\t= {Teye, Mattias and Azizpour, Hossein and Smith, Kevin},\n  journal\t= {arXiv preprint arXiv:1802.06455},\n  year\t\t= {2018}\n}\n\n@Article{\t  Tieleman.Hinton.2012,\n  title\t\t= {Lecture 6.5-rmsprop: Divide the gradient by a running\n\t\t  average of its recent magnitude},\n  author\t= {Tieleman, Tijmen and Hinton, Geoffrey},\n  journal\t= {COURSERA: Neural networks for machine learning},\n  volume\t= {4},\n  number\t= {2},\n  pages\t\t= {26--31},\n  year\t\t= {2012}\n}\n\n@Article{\t  Toscher.Jahrer.Bell.2009,\n  title\t\t= {The bigchaos solution to the netflix grand prize},\n  author\t= {T{\\\"o}scher, Andreas and Jahrer, Michael and Bell, Robert\n\t\t  M},\n  journal\t= {Netflix prize documentation},\n  pages\t\t= {1--52},\n  year\t\t= {2009}\n}\n\n@Article{\t  Treisman.Gelade.1980,\n  title\t\t= {A feature-integration theory of attention},\n  author\t= {Treisman, Anne M and Gelade, Garry},\n  journal\t= {Cognitive psychology},\n  volume\t= {12},\n  number\t= {1},\n  pages\t\t= {97--136},\n  year\t\t= {1980},\n  publisher\t= {Elsevier}\n}\n\n@Article{\t  Turing.1950,\n  title\t\t= {Computing machinery and intelligence},\n  author\t= {Turing, Alan},\n  journal\t= {Mind},\n  volume\t= {59},\n  number\t= {236},\n  pages\t\t= {433},\n  year\t\t= {1950}\n}\n\n@Article{\t  Uijlings.Van-De-Sande.Gevers.ea.2013,\n  title\t\t= {Selective search for object recognition},\n  author\t= {Uijlings, Jasper RR and Van De Sande, Koen EA and Gevers,\n\t\t  Theo and Smeulders, Arnold WM},\n  journal\t= {International journal of computer vision},\n  volume\t= {104},\n  number\t= {2},\n  pages\t\t= {154--171},\n  year\t\t= {2013},\n  publisher\t= {Springer}\n}\n\n@Book{\t\t  Van-Loan.Golub.1983,\n  title\t\t= {Matrix computations},\n  author\t= {Van Loan, Charles F and Golub, Gene H},\n  year\t\t= {1983},\n  publisher\t= {Johns Hopkins University Press}\n}\n\n@InProceedings{\t  Vaswani.Shazeer.Parmar.ea.2017,\n  title\t\t= {Attention is all you need},\n  author\t= {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and\n\t\t  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and\n\t\t  Kaiser, {\\L}ukasz and Polosukhin, Illia},\n  booktitle\t= {Advances in neural information processing systems},\n  pages\t\t= {5998--6008},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Wang.Davidson.Pan.ea.2016,\n  title\t\t= {Gunrock: A high-performance graph processing library on\n\t\t  the GPU},\n  author\t= {Wang, Yangzihao and Davidson, Andrew and Pan, Yuechao and\n\t\t  Wu, Yuduo and Riffel, Andy and Owens, John D},\n  booktitle\t= {ACM SIGPLAN Notices},\n  volume\t= {51},\n  number\t= {8},\n  pages\t\t= {11},\n  year\t\t= {2016},\n  organization\t= {ACM}\n}\n\n@Article{\t  Wang.Li.Liberty.ea.2018,\n  title\t\t= {Optimal Message Scheduling for Aggregation},\n  author\t= {Wang, Leyuan and Li, Mu and Liberty, Edo and Smola, Alex\n\t\t  J},\n  journal\t= {NETWORKS},\n  volume\t= {2},\n  number\t= {3},\n  pages\t\t= {2--3},\n  year\t\t= {2018}\n}\n\n@Article{\t  Warstadt.Singh.Bowman.2019,\n  title\t\t= {Neural network acceptability judgments},\n  author\t= {Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\n  journal\t= {Transactions of the Association for Computational\n\t\t  Linguistics},\n  volume\t= {7},\n  pages\t\t= {625--641},\n  year\t\t= {2019},\n  publisher\t= {MIT Press}\n}\n\n@Book{\t\t  Wasserman.2013,\n  title\t\t= {All of statistics: a concise course in statistical\n\t\t  inference},\n  author\t= {Wasserman, Larry},\n  year\t\t= {2013},\n  publisher\t= {Springer Science \\& Business Media}\n}\n\n@Article{\t  Watkins.Dayan.1992,\n  title\t\t= {Q-learning},\n  author\t= {Watkins, Christopher JCH and Dayan, Peter},\n  journal\t= {Machine learning},\n  volume\t= {8},\n  number\t= {3-4},\n  pages\t\t= {279--292},\n  year\t\t= {1992},\n  publisher\t= {Springer}\n}\n\n@Article{\t  Watson.1964,\n  title\t\t= {Smooth regression analysis},\n  author\t= {Watson, Geoffrey S},\n  journal\t= {Sankhy{\\=a}: The Indian Journal of Statistics, Series A},\n  pages\t\t= {359--372},\n  year\t\t= {1964},\n  publisher\t= {JSTOR}\n}\n\n@InProceedings{\t  Welling.Teh.2011,\n  title\t\t= {Bayesian learning via stochastic gradient Langevin\n\t\t  dynamics},\n  author\t= {Welling, Max and Teh, Yee W},\n  booktitle\t= {Proceedings of the 28th international conference on\n\t\t  machine learning (ICML-11)},\n  pages\t\t= {681--688},\n  year\t\t= {2011}\n}\n\n@Article{\t  Werbos.1990,\n  title\t\t= {Backpropagation through time: what it does and how to do\n\t\t  it},\n  author\t= {Werbos, Paul J},\n  journal\t= {Proceedings of the IEEE},\n  volume\t= {78},\n  number\t= {10},\n  pages\t\t= {1550--1560},\n  year\t\t= {1990},\n  publisher\t= {IEEE}\n}\n\n@InProceedings{\t  Wigner.1958,\n  title\t\t= {On the distribution of the roots of certain symmetric\n\t\t  matrices},\n  author\t= {Wigner, Eugene P.},\n  booktitle\t= {Ann. Math},\n  pages\t\t= {325--327},\n  year\t\t= {1958}\n}\n\n@TechReport{\t  Williams.Waterman.Patterson.2009,\n  title\t\t= {Roofline: An insightful visual performance model for\n\t\t  floating-point programs and multicore architectures},\n  author\t= {Williams, Samuel and Waterman, Andrew and Patterson,\n\t\t  David},\n  year\t\t= {2009},\n  institution\t= {Lawrence Berkeley National Lab.(LBNL), Berkeley, CA\n\t\t  (United States)}\n}\n\n@Article{\t  Wood.Gasthaus.Archambeau.ea.2011,\n  title\t\t= {The sequence memoizer},\n  author\t= {Wood, Frank and Gasthaus, Jan and Archambeau, C{\\'e}dric\n\t\t  and James, Lancelot and Teh, Yee Whye},\n  journal\t= {Communications of the ACM},\n  volume\t= {54},\n  number\t= {2},\n  pages\t\t= {91--98},\n  year\t\t= {2011},\n  publisher\t= {ACM}\n}\n\n@InProceedings{\t  Wu.Ahmed.Beutel.ea.2017,\n  title\t\t= {Recurrent recommender networks},\n  author\t= {Wu, Chao-Yuan and Ahmed, Amr and Beutel, Alex and Smola,\n\t\t  Alexander J and Jing, How},\n  booktitle\t= {Proceedings of the tenth ACM international conference on\n\t\t  web search and data mining},\n  pages\t\t= {495--503},\n  year\t\t= {2017},\n  organization\t= {ACM}\n}\n\n@Article{\t  Wu.Schuster.Chen.ea.2016,\n  title\t\t= {Google's neural machine translation system: Bridging the\n\t\t  gap between human and machine translation},\n  author\t= {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le,\n\t\t  Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and\n\t\t  Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey,\n\t\t  Klaus and others},\n  journal\t= {arXiv preprint arXiv:1609.08144},\n  year\t\t= {2016}\n}\n\n@InProceedings{\t  Xiao.Bahri.Sohl-Dickstein.ea.2018,\n  title\t\t= {Dynamical Isometry and a Mean Field Theory of CNNs: How to\n\t\t  Train 10,000-Layer Vanilla Convolutional Neural Networks},\n  author\t= {Xiao, Lechao and Bahri, Yasaman and Sohl-Dickstein, Jascha\n\t\t  and Schoenholz, Samuel and Pennington, Jeffrey},\n  booktitle\t= {International Conference on Machine Learning},\n  pages\t\t= {5393--5402},\n  year\t\t= {2018}\n}\n\n@Article{\t  Xiao.Rasul.Vollgraf.2017,\n  title\t\t= {Fashion-mnist: a novel image dataset for benchmarking\n\t\t  machine learning algorithms},\n  author\t= {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},\n  journal\t= {arXiv preprint arXiv:1708.07747},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Xiong.Wu.Alleva.ea.2018,\n  title\t\t= {The Microsoft 2017 conversational speech recognition\n\t\t  system},\n  author\t= {Xiong, Wayne and Wu, Lingfeng and Alleva, Fil and Droppo,\n\t\t  Jasha and Huang, Xuedong and Stolcke, Andreas},\n  booktitle\t= {2018 IEEE International Conference on Acoustics, Speech\n\t\t  and Signal Processing (ICASSP)},\n  pages\t\t= {5934--5938},\n  year\t\t= {2018},\n  organization\t= {IEEE}\n}\n\n@InProceedings{\t  Ye.Yin.Lee.ea.2011,\n  title\t\t= {Exploiting geographical influence for collaborative\n\t\t  point-of-interest recommendation},\n  author\t= {Ye, Mao and Yin, Peifeng and Lee, Wang-Chien and Lee,\n\t\t  Dik-Lun},\n  booktitle\t= {Proceedings of the 34th international ACM SIGIR conference\n\t\t  on Research and development in Information Retrieval},\n  pages\t\t= {325--334},\n  year\t\t= {2011},\n  organization\t= {ACM}\n}\n\n@Article{\t  You.Gitman.Ginsburg.2017,\n  title\t\t= {Large batch training of convolutional networks},\n  author\t= {You, Yang and Gitman, Igor and Ginsburg, Boris},\n  journal\t= {arXiv preprint arXiv:1708.03888},\n  year\t\t= {2017}\n}\n\n@InProceedings{\t  Zaheer.Reddi.Sachan.ea.2018,\n  title\t\t= {Adaptive methods for nonconvex optimization},\n  author\t= {Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and\n\t\t  Kale, Satyen and Kumar, Sanjiv},\n  booktitle\t= {Advances in Neural Information Processing Systems},\n  pages\t\t= {9793--9803},\n  year\t\t= {2018}\n}\n\n@Article{\t  Zeiler.2012,\n  title\t\t= {ADADELTA: an adaptive learning rate method},\n  author\t= {Zeiler, Matthew D},\n  journal\t= {arXiv preprint arXiv:1212.5701},\n  year\t\t= {2012}\n}\n\n@InProceedings{\t  Zhang.Tay.Zhang.ea.2021,\n  title\t\t= {Beyond Fully-Connected Layers with Quaternions:\n\t\t  Parameterization of Hypercomplex Multiplications with 1/n\n\t\t  Parameters},\n  author\t= {Zhang, Aston and Tay, Yi and Zhang, Shuai and Chan, Alvin\n\t\t  and Luu, Anh Tuan and Hui, Siu Cheung and Fu, Jie},\n  booktitle\t= {International Conference on Learning Representations},\n  year\t\t= {2021}\n}\n\n@Article{\t  Zhang.Yao.Sun.ea.2019,\n  title\t\t= {Deep learning based recommender system: A survey and new\n\t\t  perspectives},\n  author\t= {Zhang, Shuai and Yao, Lina and Sun, Aixin and Tay, Yi},\n  journal\t= {ACM Computing Surveys (CSUR)},\n  volume\t= {52},\n  number\t= {1},\n  pages\t\t= {5},\n  year\t\t= {2019},\n  publisher\t= {ACM}\n}\n\n@Article{\t  Zhao.Zheng.Xu.ea.2019,\n  title\t\t= {Object detection with deep learning: A review},\n  author\t= {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu,\n\t\t  Xindong},\n  journal\t= {IEEE transactions on neural networks and learning\n\t\t  systems},\n  volume\t= {30},\n  number\t= {11},\n  pages\t\t= {3212--3232},\n  year\t\t= {2019},\n  publisher\t= {IEEE}\n}\n\n@InProceedings{\t  Zhu.Kiros.Zemel.ea.2015,\n  title\t\t= {Aligning books and movies: Towards story-like visual\n\t\t  explanations by watching movies and reading books},\n  author\t= {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and\n\t\t  Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba,\n\t\t  Antonio and Fidler, Sanja},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {19--27},\n  year\t\t= {2015}\n}\n\n@InProceedings{\t  Zhu.Park.Isola.ea.2017,\n  title\t\t= {Unpaired image-to-image translation using cycle-consistent\n\t\t  adversarial networks},\n  author\t= {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and\n\t\t  Efros, Alexei A},\n  booktitle\t= {Proceedings of the IEEE international conference on\n\t\t  computer vision},\n  pages\t\t= {2223--2232},\n  year\t\t= {2017}\n}"
        },
        {
          "name": "d2l",
          "type": "tree",
          "content": null
        },
        {
          "name": "graffle",
          "type": "tree",
          "content": null
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "index.md",
          "type": "blob",
          "size": 0.89,
          "content": "《动手学深度学习》\n========================\n\n```eval_rst\n.. raw:: html\n   :file: frontpage.html\n```\n\n\n```toc\n:maxdepth: 1\n\nchapter_preface/index\nchapter_installation/index\nchapter_notation/index\n```\n\n\n```toc\n:maxdepth: 2\n:numbered:\n\nchapter_introduction/index\nchapter_preliminaries/index\nchapter_linear-networks/index\nchapter_multilayer-perceptrons/index\nchapter_deep-learning-computation/index\nchapter_convolutional-neural-networks/index\nchapter_convolutional-modern/index\nchapter_recurrent-neural-networks/index\nchapter_recurrent-modern/index\nchapter_attention-mechanisms/index\nchapter_optimization/index\nchapter_computational-performance/index\nchapter_computer-vision/index\nchapter_natural-language-processing-pretraining/index\nchapter_natural-language-processing-applications/index\nchapter_appendix-tools-for-deep-learning/index\n\n\n```\n\n\n```toc\n:maxdepth: 1\n\nchapter_references/zreferences\n```\n\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.5,
          "content": "from setuptools import setup, find_packages\nimport d2l\n\nrequirements = [\n    'jupyter==1.0.0',\n    'numpy==1.21.5',\n    'matplotlib==3.5.1',\n    'requests==2.25.1',\n    'pandas==1.2.4'\n]\n\nsetup(\n    name='d2l',\n    version=d2l.__version__,\n    python_requires='>=3.5',\n    author='D2L Developers',\n    author_email='d2l.devs@gmail.com',\n    url='https://d2l.ai',\n    description='Dive into Deep Learning',\n    license='MIT-0',\n    packages=find_packages(),\n    zip_safe=True,\n    install_requires=requirements,\n)\n"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}