{
  "metadata": {
    "timestamp": 1736557612012,
    "page": 685,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Mintplex-Labs/anything-llm",
      "stars": 30048,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.35,
          "content": "**/server/utils/agents/aibitat/example/**\n**/server/storage/documents/**\n**/server/storage/vector-cache/**\n**/server/storage/*.db\n**/server/storage/lancedb\n**/collector/hotdir/**\n**/collector/outputs/**\n**/node_modules/\n**/dist/\n**/v-env/\n**/__pycache__/\n**/.env\n**/.env.*\n**/bundleinspector.html\n**/tmp/**\n**/.log\n!docker/.env.example\n!frontend/.env.production"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.36,
          "content": "# EditorConfig is awesome: https://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n[*]\n# Non-configurable Prettier behaviors\ncharset = utf-8\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\n# Configurable Prettier behaviors\n# (change these if your Prettier config differs)\nend_of_line = lf\nindent_style = space\nindent_size = 2\nmax_line_length = 80\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.02,
          "content": "* text=auto eol=lf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.11,
          "content": "v-env\n.env\n!.env.example\n\nnode_modules\n__pycache__\nv-env\n.DS_Store\naws_cf_deploy_anything_llm.json\nyarn.lock\n*.bak\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.22,
          "content": "[submodule \"browser-extension\"]\n\tpath = browser-extension\n\turl = git@github.com:Mintplex-Labs/anythingllm-extension.git\n[submodule \"embed\"]\n\tpath = embed\n\turl = git@github.com:Mintplex-Labs/anythingllm-embed.git\n\tbranch = main\n"
        },
        {
          "name": ".hadolint.yaml",
          "type": "blob",
          "size": 0.11,
          "content": "failure-threshold: warning\nignored:\n  - DL3008\n  - DL3013\nformat: tty\ntrustedRegistries:\n  - docker.io\n  - gcr.io\n"
        },
        {
          "name": ".nvmrc",
          "type": "blob",
          "size": 0.01,
          "content": "v18.18.0\n"
        },
        {
          "name": ".prettierignore",
          "type": "blob",
          "size": 0.18,
          "content": "# defaults\n**/.git\n**/.svn\n**/.hg\n**/node_modules\n\n#frontend\nfrontend/bundleinspector.html\n**/dist\n\n#server\nserver/swagger/openapi.json\n\n#embed\n**/static/**\nembed/src/utils/chat/hljs.js\n"
        },
        {
          "name": ".prettierrc",
          "type": "blob",
          "size": 0.68,
          "content": "{\n  \"tabWidth\": 2,\n  \"useTabs\": false,\n  \"endOfLine\": \"lf\",\n  \"semi\": true,\n  \"singleQuote\": false,\n  \"printWidth\": 80,\n  \"trailingComma\": \"es5\",\n  \"bracketSpacing\": true,\n  \"bracketSameLine\": false,\n  \"overrides\": [\n    {\n      \"files\": [\"*.js\", \"*.mjs\", \"*.jsx\"],\n      \"options\": {\n        \"parser\": \"flow\",\n        \"arrowParens\": \"always\"\n      }\n    },\n    {\n      \"files\": [\"*.config.js\"],\n      \"options\": {\n        \"semi\": false,\n        \"parser\": \"flow\",\n        \"trailingComma\": \"none\"\n      }\n    },\n    {\n      \"files\": \"*.html\",\n      \"options\": {\n        \"bracketSameLine\": true\n      }\n    },\n    {\n      \"files\": \".prettierrc\",\n      \"options\": { \"parser\": \"json\" }\n    }\n  ]\n}\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "BARE_METAL.md",
          "type": "blob",
          "size": 4.69,
          "content": "# Run AnythingLLM in production without Docker\n\n> [!WARNING]\n> This method of deployment is **not supported** by the core-team and is to be used as a reference for your deployment.\n> You are fully responsible for securing your deployment and data in this mode.\n> **Any issues** experienced from bare-metal or non-containerized deployments will be **not** answered or supported.\n\nHere you can find the scripts and known working process to run AnythingLLM outside of a Docker container. This method of deployment is preferable for those using local LLMs and want native performance on their devices.\n\n### Minimum Requirements\n> [!TIP]\n> You should aim for at least 2GB of RAM. Disk storage is proportional to however much data\n> you will be storing (documents, vectors, models, etc). Minimum 10GB recommended.\n\n- NodeJS v18\n- Yarn\n\n\n## Getting started\n\n1. Clone the repo into your server as the user who the application will run as.\n`git clone git@github.com:Mintplex-Labs/anything-llm.git`\n\n2. `cd anything-llm` and run `yarn setup`. This will install all dependencies to run in production as well as debug the application.\n\n3. `cp server/.env.example server/.env` to create the basic ENV file for where instance settings will be read from on service start.\n\n4. Ensure that the `server/.env` file has _at least_ these keys to start. These values will persist and this file will be automatically written and managed after your first successful boot.\n```\nSTORAGE_DIR=\"/your/absolute/path/to/server/storage\"\n```\n\n5. Edit the `frontend/.env` file for the `VITE_BASE_API` to now be set to `/api`. This is documented in the .env for which one you should use.\n```\n# VITE_API_BASE='http://localhost:3001/api' # Use this URL when developing locally\n# VITE_API_BASE=\"https://$CODESPACE_NAME-3001.$GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN/api\" # for Github Codespaces\nVITE_API_BASE='/api' # Use this URL deploying on non-localhost address OR in docker.\n```\n\n## To start the application\n\nAnythingLLM is comprised of three main sections. The `frontend`, `server`, and `collector`. When running in production you will be running `server` and `collector` on two different processes, with a build step for compilation of the frontend.\n\n1. Build the frontend application.\n`cd frontend && yarn build` - this will produce a `frontend/dist` folder that will be used later.\n\n2. Copy `frontend/dist` to `server/public` - `cp -R frontend/dist server/public`.\nThis should create a folder in `server` named `public` which contains a top level `index.html` file and various other files/folders.\n\n_(optional)_ Build native LLM support if using `native` as your LLM.\n`cd server && npx --no node-llama-cpp download`\n\n3. Migrate and prepare your database file.\n```\ncd server && npx prisma generate --schema=./prisma/schema.prisma\ncd server && npx prisma migrate deploy --schema=./prisma/schema.prisma\n```\n\n4. Boot the server in production\n`cd server && NODE_ENV=production node index.js &` \n\n5. Boot the collection in another process\n`cd collector && NODE_ENV=production node index.js &` \n\nAnythingLLM should now be running on `http://localhost:3001`!\n\n## Updating AnythingLLM\n\nTo update AnythingLLM with future updates you can `git pull origin master` to pull in the latest code and then repeat steps 2 - 5 to deploy with all changes fully.\n\n_note_ You should ensure that each folder runs `yarn` again to ensure packages are up to date in case any dependencies were added, changed, or removed.\n\n_note_ You should `pkill node` before running an update so that you are not running multiple AnythingLLM processes on the same instance as this can cause conflicts.\n\n\n### Example update script\n\n```shell\n#!/bin/bash\n\ncd $HOME/anything-llm &&\\\ngit checkout . &&\\\ngit pull origin master &&\\\necho \"HEAD pulled to commit $(git log -1 --pretty=format:\"%h\" | tail -n 1)\"\n\necho \"Freezing current ENVs\"\ncurl -I \"http://localhost:3001/api/env-dump\" | head -n 1|cut -d$' ' -f2\n\necho \"Rebuilding Frontend\"\ncd $HOME/anything-llm/frontend && yarn && yarn build && cd $HOME/anything-llm\n\necho \"Copying to Sever Public\"\nrm -rf server/public\ncp -r frontend/dist server/public\n\necho \"Killing node processes\"\npkill node\n\necho \"Installing collector dependencies\"\ncd $HOME/anything-llm/collector && yarn\n\necho \"Installing server dependencies & running migrations\"\ncd $HOME/anything-llm/server && yarn\ncd $HOME/anything-llm/server && npx prisma migrate deploy --schema=./prisma/schema.prisma\ncd $HOME/anything-llm/server && npx prisma generate\n\necho \"Booting up services.\"\ntruncate -s 0 /logs/server.log # Or any other log file location.\ntruncate -s 0 /logs/collector.log\n\ncd $HOME/anything-llm/server\n(NODE_ENV=production node index.js) &> /logs/server.log &\n\ncd $HOME/anything-llm/collector\n(NODE_ENV=production node index.js) &> /logs/collector.log &\n```\n\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.05,
          "content": "The MIT License\n\nCopyright (c) Mintplex Labs Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.25,
          "content": "<a name=\"readme-top\"></a>\n\n<p align=\"center\">\n  <a href=\"https://anythingllm.com\"><img src=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true\" alt=\"AnythingLLM logo\"></a>\n</p>\n\n<div align='center'>\n<a href=\"https://trendshift.io/repositories/2415\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2415\" alt=\"Mintplex-Labs%2Fanything-llm | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<p align=\"center\">\n    <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br />\n    Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/6UyHPeGZAC\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.anythingllm.com\" target=\"_blank\">\n    Docs\n  </a> |\n   <a href=\"https://my.mintplexlabs.com/aio-checkout?product=anythingllm\" target=\"_blank\">\n    Hosted Instance\n  </a>\n</p>\n\n<p align=\"center\">\n  <b>English</b> · <a href='./locales/README.zh-CN.md'>简体中文</a> · <a href='./locales/README.ja-JP.md'>日本語</a>\n</p>\n\n<p align=\"center\">\n👉 AnythingLLM for desktop (Mac, Windows, & Linux)! <a href=\"https://anythingllm.com/download\" target=\"_blank\"> Download Now</a>\n</p>\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\n![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)\n\n<details>\n<summary><kbd>Watch the demo!</kbd></summary>\n\n[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)\n\n</details>\n\n### Product Overview\n\nAnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.\n\nAnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.\n\n## Cool features of AnythingLLM\n\n- 🆕 [**Custom AI Agents**](https://docs.anythingllm.com/agent/custom/introduction)\n- 🖼️ **Multi-modal support (both closed and open-source LLMs!)**\n- 👤 Multi-user instance support and permissioning _Docker version only_\n- 🦾 Agents inside your workspace (browse the web, run code, etc)\n- 💬 [Custom Embeddable Chat widget for your website](./embed/README.md) _Docker version only_\n- 📖 Multiple document type support (PDF, TXT, DOCX, etc)\n- Simple chat UI with Drag-n-Drop funcitonality and clear citations.\n- 100% Cloud deployment ready.\n- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).\n- Built-in cost & time-saving measures for managing very large documents compared to any other chat UI.\n- Full Developer API for custom integrations!\n- Much more...install and find out!\n\n### Supported LLMs, Embedder Models, Speech models, and Vector Databases\n\n**Large Language Models (LLMs):**\n\n- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)\n- [OpenAI](https://openai.com)\n- [OpenAI (Generic)](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [AWS Bedrock](https://aws.amazon.com/bedrock/)\n- [Anthropic](https://www.anthropic.com/)\n- [NVIDIA NIM (chat models)](https://build.nvidia.com/explore/discover)\n- [Google Gemini Pro](https://ai.google.dev/)\n- [Hugging Face (chat models)](https://huggingface.co/)\n- [Ollama (chat models)](https://ollama.ai/)\n- [LM Studio (all models)](https://lmstudio.ai)\n- [LocalAi (all models)](https://localai.io/)\n- [Together AI (chat models)](https://www.together.ai/)\n- [Fireworks AI  (chat models)](https://fireworks.ai/)\n- [Perplexity (chat models)](https://www.perplexity.ai/)\n- [OpenRouter (chat models)](https://openrouter.ai/)\n- [DeepSeek (chat models)](https://deepseek.com/)\n- [Mistral](https://mistral.ai/)\n- [Groq](https://groq.com/)\n- [Cohere](https://cohere.com/)\n- [KoboldCPP](https://github.com/LostRuins/koboldcpp)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n- [Apipie](https://apipie.ai/)\n- [xAI](https://x.ai/)\n- [Novita AI (chat models)](https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&utm_medium=github_readme&utm_campaign=link)\n\n**Embedder models:**\n\n- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)\n- [OpenAI](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [LocalAi (all)](https://localai.io/)\n- [Ollama (all)](https://ollama.ai/)\n- [LM Studio (all)](https://lmstudio.ai)\n- [Cohere](https://cohere.com/)\n\n**Audio Transcription models:**\n\n- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)\n- [OpenAI](https://openai.com/)\n\n**TTS (text-to-speech) support:**\n\n- Native Browser Built-in (default)\n- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)\n- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)\n- [ElevenLabs](https://elevenlabs.io/)\n- Any OpenAI Compatible TTS service.\n\n**STT (speech-to-text) support:**\n\n- Native Browser Built-in (default)\n\n**Vector Databases:**\n\n- [LanceDB](https://github.com/lancedb/lancedb) (default)\n- [Astra DB](https://www.datastax.com/products/datastax-astra)\n- [Pinecone](https://pinecone.io)\n- [Chroma](https://trychroma.com)\n- [Weaviate](https://weaviate.io)\n- [Qdrant](https://qdrant.tech)\n- [Milvus](https://milvus.io)\n- [Zilliz](https://zilliz.com)\n\n### Technical Overview\n\nThis monorepo consists of three main sections:\n\n- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.\n- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.\n- `collector`: NodeJS express server that process and parses documents from the UI.\n- `docker`: Docker instructions and build process + information for building from source.\n- `embed`: Submodule for generation & creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).\n- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).\n\n## 🛳 Self Hosting\n\nMintplex Labs & the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.\n| Docker | AWS | GCP | Digital Ocean | Render.com |\n|----------------------------------------|----|-----|---------------|------------|\n| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |\n\n| Railway  |  RepoCloud | Elestio |\n| --- | --- | --- |\n| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] |\n\n[or set up a production AnythingLLM instance without Docker →](./BARE_METAL.md)\n\n## How to setup for development\n\n- `yarn setup` To fill in the required `.env` files you'll need in each of the application sections (from root of repo).\n  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won't work right.\n- `yarn dev:server` To boot the server locally (from root of repo).\n- `yarn dev:frontend` To boot the frontend locally (from root of repo).\n- `yarn dev:collector` To then run the document collector (from root of repo).\n\n[Learn about documents](./server/storage/documents/DOCUMENTS.md)\n\n[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)\n\n## External Apps & Integrations\n\n_These are apps that are not maintained by Mintplex Labs, but are compatible with AnythingLLM. A listing here is not an endorsement._\n\n- [Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/) - A streamlined and efficient way to deploy AI systems using Docker container technology.\n- [Coolify](https://coolify.io/docs/services/anythingllm/) - Deploy AnythingLLM with a single click.\n- [GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/) - A local Word Add-in for you to use AnythingLLM in Microsoft Word.\n\n## Telemetry & Privacy\n\nAnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.\n\n<details>\n<summary><kbd>More about Telemetry & Privacy for AnythingLLM</kbd></summary>\n\n### Why?\n\nWe use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.\n\n### Opting out\n\nSet `DISABLE_TELEMETRY` in your server or docker .env settings to \"true\" to opt out of telemetry. You can also do this in-app by going to the sidebar > `Privacy` and disabling telemetry.\n\n### What do you explicitly track?\n\nWe will only track usage details that help us make product and roadmap decisions, specifically:\n\n- Type of your installation (Docker or Desktop)\n- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.\n- Type of vector database in use. Let's us know which vector database provider is the most used to prioritize changes when updates arrive for that provider.\n- Type of LLM in use. Let's us know the most popular choice and prioritize changes when updates arrive for that provider.\n- Chat is sent. This is the most regular \"event\" and gives us an idea of the daily-activity of this project across all installations. Again, only the event is sent - we have no information on the nature or content of the chat itself.\n\nYou can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. No IP or other identifying information is collected. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.\n\n[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\\(&type=code)\n\n</details>\n\n\n## 👋 Contributing\n\n- create issue\n- create PR with branch name format of `<issue number>-<short name>`\n- LGTM from core-team\n\n## 🌟 Contributors\n\n[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)\n\n## 🔗 More Products\n\n- **[VectorAdmin][vector-admin]:** An all-in-one GUI & tool-suite for managing vector databases.\n- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your entire library of OpenAI assistants into one single army commanded from a single agent.\n\n<div align=\"right\">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\nCopyright © 2025 [Mintplex Labs][profile-link]. <br />\nThis project is [MIT](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square\n[profile-link]: https://github.com/mintplex-labs\n[vector-admin]: https://github.com/mintplex-labs/vector-admin\n[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm\n[docker-btn]: ./images/deployBtns/docker.png\n[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md\n[aws-btn]: ./images/deployBtns/aws.png\n[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md\n[gcp-btn]: https://deploy.cloud.run/button.svg\n[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md\n[do-btn]: https://www.deploytodo.com/do-btn-blue.svg\n[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[railway-btn]: https://railway.app/button.svg\n[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn\n[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[repocloud-deploy]: https://repocloud.io/details/?app_id=276\n[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png\n[elestio-deploy]: https://elest.io/open-source/anythingllm\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.5,
          "content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 0.1.x   | :white_check_mark: |\n\n\n## Reporting a Vulnerability\n\nIf a security concern is found that you would like to disclose you can create a PR for it or if you would like to clear this issue before posting you can email [Core Mintplex Labs Team](mailto:team@mintplexlabs.com).\n"
        },
        {
          "name": "browser-extension",
          "type": "commit",
          "content": null
        },
        {
          "name": "cloud-deployments",
          "type": "tree",
          "content": null
        },
        {
          "name": "collector",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "embed",
          "type": "commit",
          "content": null
        },
        {
          "name": "eslint.config.js",
          "type": "blob",
          "size": 2.42,
          "content": "import globals from \"./server/node_modules/globals/index.js\"\nimport eslintRecommended from \"./server/node_modules/@eslint/js/src/index.js\"\nimport eslintConfigPrettier from \"./server/node_modules/eslint-config-prettier/index.js\"\nimport prettier from \"./server/node_modules/eslint-plugin-prettier/eslint-plugin-prettier.js\"\nimport react from \"./server/node_modules/eslint-plugin-react/index.js\"\nimport reactRefresh from \"./server/node_modules/eslint-plugin-react-refresh/index.js\"\nimport reactHooks from \"./server/node_modules/eslint-plugin-react-hooks/index.js\"\nimport ftFlow from \"./server/node_modules/eslint-plugin-ft-flow/dist/index.js\"\nimport hermesParser from \"./server/node_modules/hermes-eslint/dist/index.js\"\n\nconst reactRecommended = react.configs.recommended\nconst jsxRuntime = react.configs[\"jsx-runtime\"]\n\nexport default [\n  eslintRecommended.configs.recommended,\n  eslintConfigPrettier,\n  {\n    ignores: [\"**/*.test.js\"],\n    languageOptions: {\n      parser: hermesParser,\n      parserOptions: {\n        ecmaFeatures: { jsx: true }\n      },\n      ecmaVersion: 2020,\n      sourceType: \"module\",\n      globals: {\n        ...globals.browser,\n        ...globals.es2020,\n        ...globals.node\n      }\n    },\n    linterOptions: { reportUnusedDisableDirectives: true },\n    settings: { react: { version: \"18.2\" } },\n    plugins: {\n      ftFlow,\n      react,\n      \"jsx-runtime\": jsxRuntime,\n      \"react-hooks\": reactHooks,\n      prettier\n    },\n    rules: {\n      ...reactRecommended.rules,\n      ...reactHooks.configs.recommended.rules,\n      ...ftFlow.recommended,\n      \"no-unused-vars\": \"warn\",\n      \"no-undef\": \"warn\",\n      \"no-empty\": \"warn\",\n      \"no-extra-boolean-cast\": \"warn\",\n      \"prettier/prettier\": \"warn\"\n    }\n  },\n  {\n    files: [\"frontend/src/**/*.js\"],\n    plugins: {\n      ftFlow,\n      prettier\n    },\n    rules: {\n      \"prettier/prettier\": \"warn\"\n    }\n  },\n  {\n    files: [\n      \"server/endpoints/**/*.js\",\n      \"server/models/**/*.js\",\n      \"server/swagger/**/*.js\",\n      \"server/utils/**/*.js\",\n      \"server/index.js\"\n    ],\n    rules: {\n      \"no-undef\": \"warn\"\n    }\n  },\n  {\n    files: [\"frontend/src/**/*.jsx\"],\n    plugins: {\n      ftFlow,\n      react,\n      \"jsx-runtime\": jsxRuntime,\n      \"react-hooks\": reactHooks,\n      \"react-refresh\": reactRefresh,\n      prettier\n    },\n    rules: {\n      ...jsxRuntime.rules,\n      \"react/prop-types\": \"off\", // FIXME\n      \"react-refresh/only-export-components\": \"warn\"\n    }\n  }\n]\n"
        },
        {
          "name": "frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "locales",
          "type": "tree",
          "content": null
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 1.81,
          "content": "{\n  \"name\": \"anything-llm\",\n  \"version\": \"0.2.0\",\n  \"description\": \"The best solution for turning private documents into a chat bot using off-the-shelf tools and commercially viable AI technologies.\",\n  \"main\": \"index.js\",\n  \"type\": \"module\",\n  \"author\": \"Timothy Carambat (Mintplex Labs)\",\n  \"license\": \"MIT\",\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"scripts\": {\n    \"lint\": \"cd server && yarn lint && cd ../frontend && yarn lint && cd ../collector && yarn lint\",\n    \"setup\": \"cd server && yarn && cd ../collector && yarn && cd ../frontend && yarn && cd .. && yarn setup:envs && yarn prisma:setup && echo \\\"Please run yarn dev:server, yarn dev:collector, and yarn dev:frontend in separate terminal tabs.\\\"\",\n    \"setup:envs\": \"cp -n ./frontend/.env.example ./frontend/.env && cp -n ./server/.env.example ./server/.env.development && cp -n ./collector/.env.example ./collector/.env && cp -n ./docker/.env.example ./docker/.env && echo \\\"All ENV files copied!\\n\\\"\",\n    \"dev:server\": \"cd server && yarn dev\",\n    \"dev:collector\": \"cd collector && yarn dev\",\n    \"dev:frontend\": \"cd frontend && yarn dev\",\n    \"prisma:generate\": \"cd server && npx prisma generate\",\n    \"prisma:migrate\": \"cd server && npx prisma migrate dev --name init\",\n    \"prisma:seed\": \"cd server && npx prisma db seed\",\n    \"prisma:setup\": \"yarn prisma:generate && yarn prisma:migrate && yarn prisma:seed\",\n    \"prisma:reset\": \"truncate -s 0 server/storage/anythingllm.db && yarn prisma:migrate\",\n    \"prod:server\": \"cd server && yarn start\",\n    \"prod:frontend\": \"cd frontend && yarn build\",\n    \"generate:cloudformation\": \"node cloud-deployments/aws/cloudformation/generate.mjs\",\n    \"generate::gcp_deployment\": \"node cloud-deployments/gcp/deployment/generate.mjs\",\n    \"verify:translations\": \"cd frontend/src/locales && node verifyTranslations.mjs\"\n  },\n  \"private\": false\n}"
        },
        {
          "name": "pull_request_template.md",
          "type": "blob",
          "size": 0.78,
          "content": "\n ### Pull Request Type\n\n<!-- For change type, change [ ] to [x]. -->\n\n- [ ] ✨ feat\n- [ ] 🐛 fix\n- [ ] ♻️ refactor\n- [ ] 💄 style\n- [ ] 🔨 chore\n- [ ] 📝 docs\n\n### Relevant Issues\n\n<!-- Use \"resolves #xxx\" to auto resolve on merge. Otherwise, please use \"connect #xxx\" -->\n\nresolves #xxx\n\n\n### What is in this change?\n\n<!-- Describe the changes in this PR that are impactful to the repo. -->\n\n\n### Additional Information\n\n<!-- Add any other context about the Pull Request here that was not captured above. -->\n\n### Developer Validations\n\n<!-- All of the applicable items should be checked. -->\n\n- [ ] I ran `yarn lint` from the root of the repo & committed changes\n- [ ] Relevant documentation has been updated\n- [ ] I have tested my code functionality\n- [ ] Docker build succeeds locally\n"
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}