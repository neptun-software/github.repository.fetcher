{
  "metadata": {
    "timestamp": 1736557373269,
    "page": 352,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lllyasviel/Fooocus",
      "stars": 42503,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.68,
          "content": "__pycache__\n*.ckpt\n*.safetensors\n*.pth\n*.pt\n*.bin\n*.patch\n*.backup\n*.corrupted\n*.partial\n*.onnx\nsorted_styles.json\n/input\n/cache\n/language/default.json\n/test_imgs\nconfig.txt\nconfig_modification_tutorial.txt\nuser_path_config.txt\nuser_path_config-deprecated.txt\n/modules/*.png\n/repositories\n/fooocus_env\n/venv\n/tmp\n/ui-config.json\n/outputs\n/config.json\n/log\n/webui.settings.bat\n/embeddings\n/styles.csv\n/params.txt\n/styles.csv.bak\n/webui-user.bat\n/webui-user.sh\n/interrogate\n/user.css\n/.idea\n/notification.ogg\n/notification.mp3\n/SwinIR\n/textual_inversion\n.vscode\n/extensions\n/test/stdout.txt\n/test/stderr.txt\n/cache.json*\n/config_states/\n/node_modules\n/package-lock.json\n/.coverage*\n/auth.json\n.DS_Store"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.11,
          "content": "# Ensure that shell scripts always use lf line endings, e.g. entrypoint.sh for docker\n* text=auto\n*.sh text eol=lf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7,
          "content": "__pycache__\n*.ckpt\n*.safetensors\n*.pth\n*.pt\n*.bin\n*.patch\n*.backup\n*.corrupted\n*.partial\n*.onnx\nsorted_styles.json\nhash_cache.txt\n/input\n/cache\n/language/default.json\n/test_imgs\nconfig.txt\nconfig_modification_tutorial.txt\nuser_path_config.txt\nuser_path_config-deprecated.txt\n/modules/*.png\n/repositories\n/fooocus_env\n/venv\n/tmp\n/ui-config.json\n/outputs\n/config.json\n/log\n/webui.settings.bat\n/embeddings\n/styles.csv\n/params.txt\n/styles.csv.bak\n/webui-user.bat\n/webui-user.sh\n/interrogate\n/user.css\n/.idea\n/notification.ogg\n/notification.mp3\n/SwinIR\n/textual_inversion\n.vscode\n/extensions\n/test/stdout.txt\n/test/stderr.txt\n/cache.json*\n/config_states/\n/node_modules\n/package-lock.json\n/.coverage*\n/auth.json\n.DS_Store\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.09,
          "content": "FROM nvidia/cuda:12.4.1-base-ubuntu22.04\nENV DEBIAN_FRONTEND noninteractive\nENV CMDARGS --listen\n\nRUN apt-get update -y && \\\n\tapt-get install -y curl libgl1 libglib2.0-0 python3-pip python-is-python3 git && \\\n\tapt-get clean && \\\n\trm -rf /var/lib/apt/lists/*\n\nCOPY requirements_docker.txt requirements_versions.txt /tmp/\nRUN pip install --no-cache-dir -r /tmp/requirements_docker.txt -r /tmp/requirements_versions.txt && \\\n\trm -f /tmp/requirements_docker.txt /tmp/requirements_versions.txt\nRUN pip install --no-cache-dir xformers==0.0.23 --no-dependencies\nRUN curl -fsL -o /usr/local/lib/python3.10/dist-packages/gradio/frpc_linux_amd64_v0.2 https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64 && \\\n\tchmod +x /usr/local/lib/python3.10/dist-packages/gradio/frpc_linux_amd64_v0.2\n\nRUN adduser --disabled-password --gecos '' user && \\\n\tmkdir -p /content/app /content/data\n\nCOPY entrypoint.sh /content/\nRUN chown -R user:user /content\n\nWORKDIR /content\nUSER user\n\nCOPY --chown=user:user . /content/app\nRUN mv /content/app/models /content/app/models.org\n\nCMD [ \"sh\", \"-c\", \"/content/entrypoint.sh ${CMDARGS}\" ]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.33,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>.\n"
        },
        {
          "name": "args_manager.py",
          "type": "blob",
          "size": 3.04,
          "content": "import ldm_patched.modules.args_parser as args_parser\n\nargs_parser.parser.add_argument(\"--share\", action='store_true', help=\"Set whether to share on Gradio.\")\n\nargs_parser.parser.add_argument(\"--preset\", type=str, default=None, help=\"Apply specified UI preset.\")\nargs_parser.parser.add_argument(\"--disable-preset-selection\", action='store_true',\n                                help=\"Disables preset selection in Gradio.\")\n\nargs_parser.parser.add_argument(\"--language\", type=str, default='default',\n                                help=\"Translate UI using json files in [language] folder. \"\n                                  \"For example, [--language example] will use [language/example.json] for translation.\")\n\n# For example, https://github.com/lllyasviel/Fooocus/issues/849\nargs_parser.parser.add_argument(\"--disable-offload-from-vram\", action=\"store_true\",\n                                help=\"Force loading models to vram when the unload can be avoided. \"\n                                  \"Some Mac users may need this.\")\n\nargs_parser.parser.add_argument(\"--theme\", type=str, help=\"launches the UI with light or dark theme\", default=None)\nargs_parser.parser.add_argument(\"--disable-image-log\", action='store_true',\n                                help=\"Prevent writing images and logs to the outputs folder.\")\n\nargs_parser.parser.add_argument(\"--disable-analytics\", action='store_true',\n                                help=\"Disables analytics for Gradio.\")\n\nargs_parser.parser.add_argument(\"--disable-metadata\", action='store_true',\n                                help=\"Disables saving metadata to images.\")\n\nargs_parser.parser.add_argument(\"--disable-preset-download\", action='store_true',\n                                help=\"Disables downloading models for presets\", default=False)\n\nargs_parser.parser.add_argument(\"--disable-enhance-output-sorting\", action='store_true',\n                                help=\"Disables enhance output sorting for final image gallery.\")\n\nargs_parser.parser.add_argument(\"--enable-auto-describe-image\", action='store_true',\n                                help=\"Enables automatic description of uov and enhance image when prompt is empty\", default=False)\n\nargs_parser.parser.add_argument(\"--always-download-new-model\", action='store_true',\n                                help=\"Always download newer models\", default=False)\n\nargs_parser.parser.add_argument(\"--rebuild-hash-cache\", help=\"Generates missing model and LoRA hashes.\",\n                                type=int, nargs=\"?\", metavar=\"CPU_NUM_THREADS\", const=-1)\n\nargs_parser.parser.set_defaults(\n    disable_cuda_malloc=True,\n    in_browser=True,\n    port=None\n)\n\nargs_parser.args = args_parser.parser.parse_args()\n\n# (Disable by default because of issues like https://github.com/lllyasviel/Fooocus/issues/724)\nargs_parser.args.always_offload_from_vram = not args_parser.args.disable_offload_from_vram\n\nif args_parser.args.disable_analytics:\n    import os\n    os.environ[\"GRADIO_ANALYTICS_ENABLED\"] = \"False\"\n\nif args_parser.args.disable_in_browser:\n    args_parser.args.in_browser = False\n\nargs = args_parser.args\n"
        },
        {
          "name": "auth-example.json",
          "type": "blob",
          "size": 0.11,
          "content": "[\n    {\n        \"user\": \"sitting-duck-1\",\n        \"pass\": \"very-bad-publicly-known-password-change-it\"\n    }\n]\n"
        },
        {
          "name": "build_launcher.py",
          "type": "blob",
          "size": 0.82,
          "content": "import os\n\nwin32_root = os.path.dirname(os.path.dirname(__file__))\npython_embeded_path = os.path.join(win32_root, 'python_embeded')\n\nis_win32_standalone_build = os.path.exists(python_embeded_path) and os.path.isdir(python_embeded_path)\n\nwin32_cmd = '''\n.\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py {cmds} %*\npause\n'''\n\n\ndef build_launcher():\n    if not is_win32_standalone_build:\n        return\n\n    presets = [None, 'anime', 'realistic']\n\n    for preset in presets:\n        win32_cmd_preset = win32_cmd.replace('{cmds}', '' if preset is None else f'--preset {preset}')\n        bat_path = os.path.join(win32_root, 'run.bat' if preset is None else f'run_{preset}.bat')\n        if not os.path.exists(bat_path):\n            with open(bat_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(win32_cmd_preset)\n    return\n"
        },
        {
          "name": "css",
          "type": "tree",
          "content": null
        },
        {
          "name": "development.md",
          "type": "blob",
          "size": 0.17,
          "content": "## Running unit tests\n\nNative python:\n```\npython -m unittest tests/\n```\n\nEmbedded python (Windows zip file installation method):\n```\n..\\python_embeded\\python.exe -m unittest\n```\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 1.45,
          "content": "volumes:\n  fooocus-data:\n\nservices:\n  app:\n    build: .\n    image: ghcr.io/lllyasviel/fooocus\n    ports:\n     - \"7865:7865\"\n    environment:\n      - CMDARGS=--listen    # Arguments for launch.py.\n      - DATADIR=/content/data   # Directory which stores models, outputs dir\n      - config_path=/content/data/config.txt\n      - config_example_path=/content/data/config_modification_tutorial.txt\n      - path_checkpoints=/content/data/models/checkpoints/\n      - path_loras=/content/data/models/loras/\n      - path_embeddings=/content/data/models/embeddings/\n      - path_vae_approx=/content/data/models/vae_approx/\n      - path_upscale_models=/content/data/models/upscale_models/\n      - path_inpaint=/content/data/models/inpaint/\n      - path_controlnet=/content/data/models/controlnet/\n      - path_clip_vision=/content/data/models/clip_vision/\n      - path_fooocus_expansion=/content/data/models/prompt_expansion/fooocus_expansion/\n      - path_outputs=/content/app/outputs/    # Warning: If it is not located under '/content/app', you can't see history log!\n    volumes:\n      - fooocus-data:/content/data\n      #- ./models:/import/models   # Once you import files, you don't need to mount again.\n      #- ./outputs:/import/outputs  # Once you import files, you don't need to mount again.\n    tty: true\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              device_ids: ['0']\n              capabilities: [compute, utility]\n"
        },
        {
          "name": "docker.md",
          "type": "blob",
          "size": 5.81,
          "content": "# Fooocus on Docker\n\nThe docker image is based on NVIDIA CUDA 12.4 and PyTorch 2.1, see [Dockerfile](Dockerfile) and [requirements_docker.txt](requirements_docker.txt) for details.\n\n## Requirements\n\n- A computer with specs good enough to run Fooocus, and proprietary Nvidia drivers\n- Docker, Docker Compose, or Podman\n\n## Quick start\n\n**More information in the [notes](#notes).**\n\n### Running with Docker Compose\n\n1. Clone this repository\n2. Run the docker container with `docker compose up`.\n\n### Running with Docker\n\n```sh\ndocker run -p 7865:7865 -v fooocus-data:/content/data -it \\\n--gpus all \\\n-e CMDARGS=--listen \\\n-e DATADIR=/content/data \\\n-e config_path=/content/data/config.txt \\\n-e config_example_path=/content/data/config_modification_tutorial.txt \\\n-e path_checkpoints=/content/data/models/checkpoints/ \\\n-e path_loras=/content/data/models/loras/ \\\n-e path_embeddings=/content/data/models/embeddings/ \\\n-e path_vae_approx=/content/data/models/vae_approx/ \\\n-e path_upscale_models=/content/data/models/upscale_models/ \\\n-e path_inpaint=/content/data/models/inpaint/ \\\n-e path_controlnet=/content/data/models/controlnet/ \\\n-e path_clip_vision=/content/data/models/clip_vision/ \\\n-e path_fooocus_expansion=/content/data/models/prompt_expansion/fooocus_expansion/ \\\n-e path_outputs=/content/app/outputs/ \\\nghcr.io/lllyasviel/fooocus\n```\n### Running with Podman\n\n```sh\npodman run -p 7865:7865 -v fooocus-data:/content/data -it \\\n--security-opt=no-new-privileges --cap-drop=ALL --security-opt label=type:nvidia_container_t --device=nvidia.com/gpu=all \\\n-e CMDARGS=--listen \\\n-e DATADIR=/content/data \\\n-e config_path=/content/data/config.txt \\\n-e config_example_path=/content/data/config_modification_tutorial.txt \\\n-e path_checkpoints=/content/data/models/checkpoints/ \\\n-e path_loras=/content/data/models/loras/ \\\n-e path_embeddings=/content/data/models/embeddings/ \\\n-e path_vae_approx=/content/data/models/vae_approx/ \\\n-e path_upscale_models=/content/data/models/upscale_models/ \\\n-e path_inpaint=/content/data/models/inpaint/ \\\n-e path_controlnet=/content/data/models/controlnet/ \\\n-e path_clip_vision=/content/data/models/clip_vision/ \\\n-e path_fooocus_expansion=/content/data/models/prompt_expansion/fooocus_expansion/ \\\n-e path_outputs=/content/app/outputs/ \\\nghcr.io/lllyasviel/fooocus\n```\n\nWhen you see the message  `Use the app with http://0.0.0.0:7865/` in the console, you can access the URL in your browser.\n\nYour models and outputs are stored in the `fooocus-data` volume, which, depending on OS, is stored in `/var/lib/docker/volumes/` (or `~/.local/share/containers/storage/volumes/` when using `podman`).\n\n## Building the container locally\n\nClone the repository first, and open a terminal in the folder.\n\nBuild with `docker`:\n```sh\ndocker build . -t fooocus\n```\n\nBuild with `podman`:\n```sh\npodman build . -t fooocus\n```\n\n## Details\n\n### Update the container manually (`docker compose`)\n\nWhen you are using `docker compose up` continuously, the container is not updated to the latest version of Fooocus automatically.\nRun `git pull` before executing `docker compose build --no-cache` to build an image with the latest Fooocus version.\nYou can then start it with `docker compose up`\n\n### Import models, outputs\n\nIf you want to import files from models or the outputs folder, you can add the following bind mounts in the [docker-compose.yml](docker-compose.yml) or your preferred method of running the container:\n```\n#- ./models:/import/models   # Once you import files, you don't need to mount again.\n#- ./outputs:/import/outputs  # Once you import files, you don't need to mount again.\n```\nAfter running the container, your files will be copied into `/content/data/models` and `/content/data/outputs`\nSince `/content/data` is a persistent volume folder, your files will be persisted even when you re-run the container without the above mounts.\n\n\n### Paths inside the container\n\n|Path|Details|\n|-|-|\n|/content/app|The application stored folder|\n|/content/app/models.org|Original 'models' folder.<br> Files are copied to the '/content/app/models' which is symlinked to '/content/data/models' every time the container boots. (Existing files will not be overwritten.) |\n|/content/data|Persistent volume mount point|\n|/content/data/models|The folder is symlinked to '/content/app/models'|\n|/content/data/outputs|The folder is symlinked to '/content/app/outputs'|\n\n### Environments\n\nYou can change `config.txt` parameters by using environment variables.\n**The priority of using the environments is higher than the values defined in `config.txt`, and they will be saved to the `config_modification_tutorial.txt`**\n\nDocker specified environments are there. They are used by 'entrypoint.sh'\n|Environment|Details|\n|-|-|\n|DATADIR|'/content/data' location.|\n|CMDARGS|Arguments for [entry_with_update.py](entry_with_update.py) which is called by [entrypoint.sh](entrypoint.sh)|\n|config_path|'config.txt' location|\n|config_example_path|'config_modification_tutorial.txt' location|\n|HF_MIRROR| huggingface mirror site domain| \n\nYou can also use the same json key names and values explained in the 'config_modification_tutorial.txt' as the environments.\nSee examples in the [docker-compose.yml](docker-compose.yml)\n\n## Notes\n\n- Please keep 'path_outputs' under '/content/app'. Otherwise, you may get an error when you open the history log.\n- Docker on Mac/Windows still has issues in the form of slow volume access when you use \"bind mount\" volumes. Please refer to [this article](https://docs.docker.com/storage/volumes/#use-a-volume-with-docker-compose) for not using \"bind mount\".\n- The MPS backend (Metal Performance Shaders, Apple Silicon M1/M2/etc.) is not yet supported in Docker, see https://github.com/pytorch/pytorch/issues/81224\n- You can also use `docker compose up -d` to start the container detached and connect to the logs with `docker compose logs -f`. This way you can also close the terminal and keep the container running."
        },
        {
          "name": "entry_with_update.py",
          "type": "blob",
          "size": 1.31,
          "content": "import os\nimport sys\n\n\nroot = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(root)\nos.chdir(root)\n\n\ntry:\n    import pygit2\n    pygit2.option(pygit2.GIT_OPT_SET_OWNER_VALIDATION, 0)\n\n    repo = pygit2.Repository(os.path.abspath(os.path.dirname(__file__)))\n\n    branch_name = repo.head.shorthand\n\n    remote_name = 'origin'\n    remote = repo.remotes[remote_name]\n\n    remote.fetch()\n\n    local_branch_ref = f'refs/heads/{branch_name}'\n    local_branch = repo.lookup_reference(local_branch_ref)\n\n    remote_reference = f'refs/remotes/{remote_name}/{branch_name}'\n    remote_commit = repo.revparse_single(remote_reference)\n\n    merge_result, _ = repo.merge_analysis(remote_commit.id)\n\n    if merge_result & pygit2.GIT_MERGE_ANALYSIS_UP_TO_DATE:\n        print(\"Already up-to-date\")\n    elif merge_result & pygit2.GIT_MERGE_ANALYSIS_FASTFORWARD:\n        local_branch.set_target(remote_commit.id)\n        repo.head.set_target(remote_commit.id)\n        repo.checkout_tree(repo.get(remote_commit.id))\n        repo.reset(local_branch.target, pygit2.GIT_RESET_HARD)\n        print(\"Fast-forward merge\")\n    elif merge_result & pygit2.GIT_MERGE_ANALYSIS_NORMAL:\n        print(\"Update failed - Did you modify any file?\")\nexcept Exception as e:\n    print('Update failed.')\n    print(str(e))\n\nprint('Update succeeded.')\nfrom launch import *\n"
        },
        {
          "name": "entrypoint.sh",
          "type": "blob",
          "size": 0.62,
          "content": "#!/bin/bash\n\nORIGINALDIR=/content/app\n# Use predefined DATADIR if it is defined\n[[ x\"${DATADIR}\" == \"x\" ]] && DATADIR=/content/data\n\n# Make persistent dir from original dir\nfunction mklink () {\n\tmkdir -p $DATADIR/$1\n\tln -s $DATADIR/$1 $ORIGINALDIR\n}\n\n# Copy old files from import dir\nfunction import () {\n\t(test -d /import/$1 && cd /import/$1 && cp -Rpn . $DATADIR/$1/)\n}\n\ncd $ORIGINALDIR\n\n# models\nmklink models\n# Copy original files\n(cd $ORIGINALDIR/models.org && cp -Rpn . $ORIGINALDIR/models/)\n# Import old files\nimport models\n\n# outputs\nmklink outputs\n# Import old files\nimport outputs\n\n# Start application\npython launch.py $*\n"
        },
        {
          "name": "environment.yaml",
          "type": "blob",
          "size": 0.09,
          "content": "name: fooocus\nchannels:\n  - defaults\ndependencies:\n  - python=3.10\n  - pip=23.0\n  - packaging\n"
        },
        {
          "name": "experiments_expansion.py",
          "type": "blob",
          "size": 0.16,
          "content": "from modules.expansion import FooocusExpansion\n\nexpansion = FooocusExpansion()\n\ntext = 'a handsome man'\n\nfor i in range(64):\n    print(expansion(text, seed=i))\n"
        },
        {
          "name": "experiments_face.py",
          "type": "blob",
          "size": 0.15,
          "content": "import cv2\nimport extras.face_crop as cropper\n\n\nimg = cv2.imread('lena.png')\nresult = cropper.crop_image(img)\ncv2.imwrite('lena_result.png', result)\n"
        },
        {
          "name": "experiments_interrogate.py",
          "type": "blob",
          "size": 0.37,
          "content": "import cv2\nfrom extras.interrogate import default_interrogator as default_interrogator_photo\nfrom extras.wd14tagger import default_interrogator as default_interrogator_anime\n\nimg = cv2.imread('./test_imgs/red_box.jpg')[:, :, ::-1].copy()\nprint(default_interrogator_photo(img))\nimg = cv2.imread('./test_imgs/miku.jpg')[:, :, ::-1].copy()\nprint(default_interrogator_anime(img))\n"
        },
        {
          "name": "experiments_mask_generation.py",
          "type": "blob",
          "size": 0.62,
          "content": "# https://github.com/sail-sg/EditAnything/blob/main/sam2groundingdino_edit.py\n\nimport numpy as np\nfrom PIL import Image\n\nfrom extras.inpaint_mask import SAMOptions, generate_mask_from_image\n\noriginal_image = Image.open('cat.webp')\nimage = np.array(original_image, dtype=np.uint8)\n\nsam_options = SAMOptions(\n    dino_prompt='eye',\n    dino_box_threshold=0.3,\n    dino_text_threshold=0.25,\n    dino_erode_or_dilate=0,\n    dino_debug=False,\n    max_detections=2,\n    model_type='vit_b'\n)\n\nmask_image, _, _, _ = generate_mask_from_image(image, sam_options=sam_options)\n\nmerged_masks_img = Image.fromarray(mask_image)\nmerged_masks_img.show()\n"
        },
        {
          "name": "extras",
          "type": "tree",
          "content": null
        },
        {
          "name": "fooocus_colab.ipynb",
          "type": "blob",
          "size": 0.62,
          "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"VjYy0F2gZIPR\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"!pip install pygit2==1.15.1\\n\",\n    \"%cd /content\\n\",\n    \"!git clone https://github.com/lllyasviel/Fooocus.git\\n\",\n    \"%cd /content/Fooocus\\n\",\n    \"!python entry_with_update.py --share --always-high-vram\\n\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"accelerator\": \"GPU\",\n  \"colab\": {\n   \"gpuType\": \"T4\",\n   \"provenance\": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"name\": \"python\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 0\n}\n"
        },
        {
          "name": "fooocus_version.py",
          "type": "blob",
          "size": 0.02,
          "content": "version = '2.5.5'"
        },
        {
          "name": "javascript",
          "type": "tree",
          "content": null
        },
        {
          "name": "language",
          "type": "tree",
          "content": null
        },
        {
          "name": "launch.py",
          "type": "blob",
          "size": 6.28,
          "content": "import os\nimport ssl\nimport sys\n\nprint('[System ARGV] ' + str(sys.argv))\n\nroot = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(root)\nos.chdir(root)\n\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\nos.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\nif \"GRADIO_SERVER_PORT\" not in os.environ:\n    os.environ[\"GRADIO_SERVER_PORT\"] = \"7865\"\n\nssl._create_default_https_context = ssl._create_unverified_context\n\nimport platform\nimport fooocus_version\n\nfrom build_launcher import build_launcher\nfrom modules.launch_util import is_installed, run, python, run_pip, requirements_met, delete_folder_content\nfrom modules.model_loader import load_file_from_url\n\nREINSTALL_ALL = False\nTRY_INSTALL_XFORMERS = False\n\n\ndef prepare_environment():\n    torch_index_url = os.environ.get('TORCH_INDEX_URL', \"https://download.pytorch.org/whl/cu121\")\n    torch_command = os.environ.get('TORCH_COMMAND',\n                                   f\"pip install torch==2.1.0 torchvision==0.16.0 --extra-index-url {torch_index_url}\")\n    requirements_file = os.environ.get('REQS_FILE', \"requirements_versions.txt\")\n\n    print(f\"Python {sys.version}\")\n    print(f\"Fooocus version: {fooocus_version.version}\")\n\n    if REINSTALL_ALL or not is_installed(\"torch\") or not is_installed(\"torchvision\"):\n        run(f'\"{python}\" -m {torch_command}', \"Installing torch and torchvision\", \"Couldn't install torch\", live=True)\n\n    if TRY_INSTALL_XFORMERS:\n        if REINSTALL_ALL or not is_installed(\"xformers\"):\n            xformers_package = os.environ.get('XFORMERS_PACKAGE', 'xformers==0.0.23')\n            if platform.system() == \"Windows\":\n                if platform.python_version().startswith(\"3.10\"):\n                    run_pip(f\"install -U -I --no-deps {xformers_package}\", \"xformers\", live=True)\n                else:\n                    print(\"Installation of xformers is not supported in this version of Python.\")\n                    print(\n                        \"You can also check this and build manually: https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers#building-xformers-on-windows-by-duckness\")\n                    if not is_installed(\"xformers\"):\n                        exit(0)\n            elif platform.system() == \"Linux\":\n                run_pip(f\"install -U -I --no-deps {xformers_package}\", \"xformers\")\n\n    if REINSTALL_ALL or not requirements_met(requirements_file):\n        run_pip(f\"install -r \\\"{requirements_file}\\\"\", \"requirements\")\n\n    return\n\n\nvae_approx_filenames = [\n    ('xlvaeapp.pth', 'https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth'),\n    ('vaeapp_sd15.pth', 'https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt'),\n    ('xl-to-v1_interposer-v4.0.safetensors',\n     'https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors')\n]\n\n\ndef ini_args():\n    from args_manager import args\n    return args\n\n\nprepare_environment()\nbuild_launcher()\nargs = ini_args()\n\nif args.gpu_device_id is not None:\n    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_device_id)\n    print(\"Set device to:\", args.gpu_device_id)\n\nif args.hf_mirror is not None:\n    os.environ['HF_MIRROR'] = str(args.hf_mirror)\n    print(\"Set hf_mirror to:\", args.hf_mirror)\n\nfrom modules import config\nfrom modules.hash_cache import init_cache\n\nos.environ[\"U2NET_HOME\"] = config.path_inpaint\n\nos.environ['GRADIO_TEMP_DIR'] = config.temp_path\n\nif config.temp_path_cleanup_on_launch:\n    print(f'[Cleanup] Attempting to delete content of temp dir {config.temp_path}')\n    result = delete_folder_content(config.temp_path, '[Cleanup] ')\n    if result:\n        print(\"[Cleanup] Cleanup successful\")\n    else:\n        print(f\"[Cleanup] Failed to delete content of temp dir.\")\n\n\ndef download_models(default_model, previous_default_models, checkpoint_downloads, embeddings_downloads, lora_downloads, vae_downloads):\n    from modules.util import get_file_from_folder_list\n\n    for file_name, url in vae_approx_filenames:\n        load_file_from_url(url=url, model_dir=config.path_vae_approx, file_name=file_name)\n\n    load_file_from_url(\n        url='https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin',\n        model_dir=config.path_fooocus_expansion,\n        file_name='pytorch_model.bin'\n    )\n\n    if args.disable_preset_download:\n        print('Skipped model download.')\n        return default_model, checkpoint_downloads\n\n    if not args.always_download_new_model:\n        if not os.path.isfile(get_file_from_folder_list(default_model, config.paths_checkpoints)):\n            for alternative_model_name in previous_default_models:\n                if os.path.isfile(get_file_from_folder_list(alternative_model_name, config.paths_checkpoints)):\n                    print(f'You do not have [{default_model}] but you have [{alternative_model_name}].')\n                    print(f'Fooocus will use [{alternative_model_name}] to avoid downloading new models, '\n                          f'but you are not using the latest models.')\n                    print('Use --always-download-new-model to avoid fallback and always get new models.')\n                    checkpoint_downloads = {}\n                    default_model = alternative_model_name\n                    break\n\n    for file_name, url in checkpoint_downloads.items():\n        model_dir = os.path.dirname(get_file_from_folder_list(file_name, config.paths_checkpoints))\n        load_file_from_url(url=url, model_dir=model_dir, file_name=file_name)\n    for file_name, url in embeddings_downloads.items():\n        load_file_from_url(url=url, model_dir=config.path_embeddings, file_name=file_name)\n    for file_name, url in lora_downloads.items():\n        model_dir = os.path.dirname(get_file_from_folder_list(file_name, config.paths_loras))\n        load_file_from_url(url=url, model_dir=model_dir, file_name=file_name)\n    for file_name, url in vae_downloads.items():\n        load_file_from_url(url=url, model_dir=config.path_vae, file_name=file_name)\n\n    return default_model, checkpoint_downloads\n\n\nconfig.default_base_model_name, config.checkpoint_downloads = download_models(\n    config.default_base_model_name, config.previous_default_models, config.checkpoint_downloads,\n    config.embeddings_downloads, config.lora_downloads, config.vae_downloads)\n\nconfig.update_files()\ninit_cache(config.model_filenames, config.paths_checkpoints, config.lora_filenames, config.paths_loras)\n\nfrom webui import *\n"
        },
        {
          "name": "ldm_patched",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "notification-example.mp3",
          "type": "blob",
          "size": 37.41,
          "content": null
        },
        {
          "name": "presets",
          "type": "tree",
          "content": null
        },
        {
          "name": "readme.md",
          "type": "blob",
          "size": 32.62,
          "content": "<div align=center>\n<img src=\"https://github.com/lllyasviel/Fooocus/assets/19834515/483fb86d-c9a2-4c20-997c-46dafc124f25\">\n</div>\n\n# Fooocus\n\n[>>> Click Here to Install Fooocus <<<](#download)\n\nFooocus is an image generating software (based on [Gradio](https://www.gradio.app/) <a href='https://github.com/gradio-app/gradio'><img src='https://img.shields.io/github/stars/gradio-app/gradio'></a>).\n\nFooocus presents a rethinking of image generator designs. The software is offline, open source, and free, while at the same time, similar to many online image generators like Midjourney, the manual tweaking is not needed, and users only need to focus on the prompts and images. Fooocus has also simplified the installation: between pressing \"download\" and generating the first image, the number of needed mouse clicks is strictly limited to less than 3. Minimal GPU memory requirement is 4GB (Nvidia).\n\n**Recently many fake websites exist on Google when you search “fooocus”. Do not trust those – here is the only official source of Fooocus.**\n\n# Project Status: Limited Long-Term Support (LTS) with Bug Fixes Only\n\nThe Fooocus project, built entirely on the **Stable Diffusion XL** architecture, is now in a state of limited long-term support (LTS) with bug fixes only. As the existing functionalities are considered as nearly free of programmartic issues (Thanks to [mashb1t](https://github.com/mashb1t)'s huge efforts), future updates will focus exclusively on addressing any bugs that may arise. \n\n**There are no current plans to migrate to or incorporate newer model architectures.** However, this may change during time with the development of open-source community. For example, if the community converge to one single dominant method for image generation (which may really happen in half or one years given the current status), Fooocus may also migrate to that exact method.\n\nFor those interested in utilizing newer models such as **Flux**, we recommend exploring alternative platforms such as [WebUI Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge) (also from us), [ComfyUI/SwarmUI](https://github.com/comfyanonymous/ComfyUI). Additionally, several [excellent forks of Fooocus](https://github.com/lllyasviel/Fooocus?tab=readme-ov-file#forks) are available for experimentation.\n\nAgain, recently many fake websites exist on Google when you search “fooocus”. Do **NOT** get Fooocus from those websites – this page is the only official source of Fooocus. We never have any website like such as “fooocus.com”, “fooocus.net”, “fooocus.co”, “fooocus.ai”, “fooocus.org”, “fooocus.pro”, “fooocus.one”. Those websites are ALL FAKE. **They have ABSOLUTLY no relationship to us. Fooocus is a 100% non-commercial offline open-source software.**\n\n# Features\n\nBelow is a quick list using Midjourney's examples:\n\n| Midjourney | Fooocus |\n| - | - |\n| High-quality text-to-image without needing much prompt engineering or parameter tuning. <br> (Unknown method) | High-quality text-to-image without needing much prompt engineering or parameter tuning. <br> (Fooocus has an offline GPT-2 based prompt processing engine and lots of sampling improvements so that results are always beautiful, no matter if your prompt is as short as “house in garden” or as long as 1000 words) |\n| V1 V2 V3 V4 | Input Image -> Upscale or Variation -> Vary (Subtle) / Vary (Strong)|\n| U1 U2 U3 U4 | Input Image -> Upscale or Variation -> Upscale (1.5x) / Upscale (2x) |\n| Inpaint / Up / Down / Left / Right (Pan) | Input Image -> Inpaint or Outpaint -> Inpaint / Up / Down / Left / Right <br> (Fooocus uses its own inpaint algorithm and inpaint models so that results are more satisfying than all other software that uses standard SDXL inpaint method/model) |\n| Image Prompt | Input Image -> Image Prompt <br> (Fooocus uses its own image prompt algorithm so that result quality and prompt understanding are more satisfying than all other software that uses standard SDXL methods like standard IP-Adapters or Revisions) |\n| --style | Advanced -> Style |\n| --stylize | Advanced -> Advanced -> Guidance |\n| --niji | [Multiple launchers: \"run.bat\", \"run_anime.bat\", and \"run_realistic.bat\".](https://github.com/lllyasviel/Fooocus/discussions/679) <br> Fooocus support SDXL models on Civitai <br> (You can google search “Civitai” if you do not know about it) |\n| --quality | Advanced -> Quality |\n| --repeat | Advanced -> Image Number |\n| Multi Prompts (::) | Just use multiple lines of prompts |\n| Prompt Weights | You can use \" I am (happy:1.5)\". <br> Fooocus uses A1111's reweighting algorithm so that results are better than ComfyUI if users directly copy prompts from Civitai. (Because if prompts are written in ComfyUI's reweighting, users are less likely to copy prompt texts as they prefer dragging files) <br> To use embedding, you can use \"(embedding:file_name:1.1)\" |\n| --no | Advanced -> Negative Prompt |\n| --ar | Advanced -> Aspect Ratios |\n| InsightFace | Input Image -> Image Prompt -> Advanced -> FaceSwap |\n| Describe | Input Image -> Describe |\n\nBelow is a quick list using LeonardoAI's examples:\n\n| LeonardoAI | Fooocus |\n| - | - |\n| Prompt Magic | Advanced -> Style -> Fooocus V2 |\n| Advanced Sampler Parameters (like Contrast/Sharpness/etc) | Advanced -> Advanced -> Sampling Sharpness / etc |\n| User-friendly ControlNets | Input Image -> Image Prompt -> Advanced |\n\nAlso, [click here to browse the advanced features.](https://github.com/lllyasviel/Fooocus/discussions/117)\n\n# Download\n\n### Windows\n\nYou can directly download Fooocus with:\n\n**[>>> Click here to download <<<](https://github.com/lllyasviel/Fooocus/releases/download/v2.5.0/Fooocus_win64_2-5-0.7z)**\n\nAfter you download the file, please uncompress it and then run the \"run.bat\".\n\n![image](https://github.com/lllyasviel/Fooocus/assets/19834515/c49269c4-c274-4893-b368-047c401cc58c)\n\nThe first time you launch the software, it will automatically download models:\n\n1. It will download [default models](#models) to the folder \"Fooocus\\models\\checkpoints\" given different presets. You can download them in advance if you do not want automatic download.\n2. Note that if you use inpaint, at the first time you inpaint an image, it will download [Fooocus's own inpaint control model from here](https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch) as the file \"Fooocus\\models\\inpaint\\inpaint_v26.fooocus.patch\" (the size of this file is 1.28GB).\n\nAfter Fooocus 2.1.60, you will also have `run_anime.bat` and `run_realistic.bat`. They are different model presets (and require different models, but they will be automatically downloaded). [Check here for more details](https://github.com/lllyasviel/Fooocus/discussions/679).\n\nAfter Fooocus 2.3.0 you can also switch presets directly in the browser. Keep in mind to add these arguments if you want to change the default behavior:\n* Use `--disable-preset-selection` to disable preset selection in the browser.\n* Use `--always-download-new-model` to download missing models on preset switch. Default is fallback to `previous_default_models` defined in the corresponding preset, also see terminal output.\n\n![image](https://github.com/lllyasviel/Fooocus/assets/19834515/d386f817-4bd7-490c-ad89-c1e228c23447)\n\nIf you already have these files, you can copy them to the above locations to speed up installation.\n\nNote that if you see **\"MetadataIncompleteBuffer\" or \"PytorchStreamReader\"**, then your model files are corrupted. Please download models again.\n\nBelow is a test on a relatively low-end laptop with **16GB System RAM** and **6GB VRAM** (Nvidia 3060 laptop). The speed on this machine is about 1.35 seconds per iteration. Pretty impressive – nowadays laptops with 3060 are usually at very acceptable price.\n\n![image](https://github.com/lllyasviel/Fooocus/assets/19834515/938737a5-b105-4f19-b051-81356cb7c495)\n\nBesides, recently many other software report that Nvidia driver above 532 is sometimes 10x slower than Nvidia driver 531. If your generation time is very long, consider download [Nvidia Driver 531 Laptop](https://www.nvidia.com/download/driverResults.aspx/199991/en-us/) or [Nvidia Driver 531 Desktop](https://www.nvidia.com/download/driverResults.aspx/199990/en-us/).\n\nNote that the minimal requirement is **4GB Nvidia GPU memory (4GB VRAM)** and **8GB system memory (8GB RAM)**. This requires using Microsoft’s Virtual Swap technique, which is automatically enabled by your Windows installation in most cases, so you often do not need to do anything about it. However, if you are not sure, or if you manually turned it off (would anyone really do that?), or **if you see any \"RuntimeError: CPUAllocator\"**, you can enable it here:\n\n<details>\n<summary>Click here to see the image instructions. </summary>\n\n![image](https://github.com/lllyasviel/Fooocus/assets/19834515/2a06b130-fe9b-4504-94f1-2763be4476e9)\n\n**And make sure that you have at least 40GB free space on each drive if you still see \"RuntimeError: CPUAllocator\" !**\n\n</details>\n\nPlease open an issue if you use similar devices but still cannot achieve acceptable performances.\n\nNote that the [minimal requirement](#minimal-requirement) for different platforms is different.\n\nSee also the common problems and troubleshoots [here](troubleshoot.md).\n\n### Colab\n\n(Last tested - 2024 Aug 12 by [mashb1t](https://github.com/mashb1t))\n\n| Colab | Info\n| --- | --- |\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb) | Fooocus Official\n\nIn Colab, you can modify the last line to `!python entry_with_update.py --share --always-high-vram` or `!python entry_with_update.py --share --always-high-vram --preset anime` or `!python entry_with_update.py --share --always-high-vram --preset realistic` for Fooocus Default/Anime/Realistic Edition.\n\nYou can also change the preset in the UI. Please be aware that this may lead to timeouts after 60 seconds. If this is the case, please wait until the download has finished, change the preset to initial and back to the one you've selected or reload the page.\n\nNote that this Colab will disable refiner by default because Colab free's resources are relatively limited (and some \"big\" features like image prompt may cause free-tier Colab to disconnect). We make sure that basic text-to-image is always working on free-tier Colab.\n\nUsing `--always-high-vram` shifts resource allocation from RAM to VRAM and achieves the overall best balance between performance, flexibility and stability on the default T4 instance. Please find more information [here](https://github.com/lllyasviel/Fooocus/pull/1710#issuecomment-1989185346).\n\nThanks to [camenduru](https://github.com/camenduru) for the template!\n\n### Linux (Using Anaconda)\n\nIf you want to use Anaconda/Miniconda, you can\n\n    git clone https://github.com/lllyasviel/Fooocus.git\n    cd Fooocus\n    conda env create -f environment.yaml\n    conda activate fooocus\n    pip install -r requirements_versions.txt\n\nThen download the models: download [default models](#models) to the folder \"Fooocus\\models\\checkpoints\". **Or let Fooocus automatically download the models** using the launcher:\n\n    conda activate fooocus\n    python entry_with_update.py\n\nOr, if you want to open a remote port, use\n\n    conda activate fooocus\n    python entry_with_update.py --listen\n\nUse `python entry_with_update.py --preset anime` or `python entry_with_update.py --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Linux (Using Python Venv)\n\nYour Linux needs to have **Python 3.10** installed, and let's say your Python can be called with the command **python3** with your venv system working; you can\n\n    git clone https://github.com/lllyasviel/Fooocus.git\n    cd Fooocus\n    python3 -m venv fooocus_env\n    source fooocus_env/bin/activate\n    pip install -r requirements_versions.txt\n\nSee the above sections for model downloads. You can launch the software with:\n\n    source fooocus_env/bin/activate\n    python entry_with_update.py\n\nOr, if you want to open a remote port, use\n\n    source fooocus_env/bin/activate\n    python entry_with_update.py --listen\n\nUse `python entry_with_update.py --preset anime` or `python entry_with_update.py --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Linux (Using native system Python)\n\nIf you know what you are doing, and your Linux already has **Python 3.10** installed, and your Python can be called with the command **python3** (and Pip with **pip3**), you can\n\n    git clone https://github.com/lllyasviel/Fooocus.git\n    cd Fooocus\n    pip3 install -r requirements_versions.txt\n\nSee the above sections for model downloads. You can launch the software with:\n\n    python3 entry_with_update.py\n\nOr, if you want to open a remote port, use\n\n    python3 entry_with_update.py --listen\n\nUse `python entry_with_update.py --preset anime` or `python entry_with_update.py --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Linux (AMD GPUs)\n\nNote that the [minimal requirement](#minimal-requirement) for different platforms is different.\n\nSame with the above instructions. You need to change torch to the AMD version\n\n    pip uninstall torch torchvision torchaudio torchtext functorch xformers \n    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6\n\nAMD is not intensively tested, however. The AMD support is in beta.\n\nUse `python entry_with_update.py --preset anime` or `python entry_with_update.py --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Windows (AMD GPUs)\n\nNote that the [minimal requirement](#minimal-requirement) for different platforms is different.\n\nSame with Windows. Download the software and edit the content of `run.bat` as:\n\n    .\\python_embeded\\python.exe -m pip uninstall torch torchvision torchaudio torchtext functorch xformers -y\n    .\\python_embeded\\python.exe -m pip install torch-directml\n    .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py --directml\n    pause\n\nThen run the `run.bat`.\n\nAMD is not intensively tested, however. The AMD support is in beta.\n\nFor AMD, use `.\\python_embeded\\python.exe entry_with_update.py --directml --preset anime` or `.\\python_embeded\\python.exe entry_with_update.py --directml --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Mac\n\nNote that the [minimal requirement](#minimal-requirement) for different platforms is different.\n\nMac is not intensively tested. Below is an unofficial guideline for using Mac. You can discuss problems [here](https://github.com/lllyasviel/Fooocus/pull/129).\n\nYou can install Fooocus on Apple Mac silicon (M1 or M2) with macOS 'Catalina' or a newer version. Fooocus runs on Apple silicon computers via [PyTorch](https://pytorch.org/get-started/locally/) MPS device acceleration. Mac Silicon computers don't come with a dedicated graphics card, resulting in significantly longer image processing times compared to computers with dedicated graphics cards.\n\n1. Install the conda package manager and pytorch nightly. Read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide for instructions. Make sure pytorch recognizes your MPS device.\n1. Open the macOS Terminal app and clone this repository with `git clone https://github.com/lllyasviel/Fooocus.git`.\n1. Change to the new Fooocus directory, `cd Fooocus`.\n1. Create a new conda environment, `conda env create -f environment.yaml`.\n1. Activate your new conda environment, `conda activate fooocus`.\n1. Install the packages required by Fooocus, `pip install -r requirements_versions.txt`.\n1. Launch Fooocus by running `python entry_with_update.py`. (Some Mac M2 users may need `python entry_with_update.py --disable-offload-from-vram` to speed up model loading/unloading.) The first time you run Fooocus, it will automatically download the Stable Diffusion SDXL models and will take a significant amount of time, depending on your internet connection.\n\nUse `python entry_with_update.py --preset anime` or `python entry_with_update.py --preset realistic` for Fooocus Anime/Realistic Edition.\n\n### Docker\n\nSee [docker.md](docker.md)\n\n### Download Previous Version\n\nSee the guidelines [here](https://github.com/lllyasviel/Fooocus/discussions/1405).\n\n## Minimal Requirement\n\nBelow is the minimal requirement for running Fooocus locally. If your device capability is lower than this spec, you may not be able to use Fooocus locally. (Please let us know, in any case, if your device capability is lower but Fooocus still works.)\n\n| Operating System  | GPU                          | Minimal GPU Memory           | Minimal System Memory     | [System Swap](troubleshoot.md) | Note                                                                       |\n|-------------------|------------------------------|------------------------------|---------------------------|--------------------------------|----------------------------------------------------------------------------|\n| Windows/Linux     | Nvidia RTX 4XXX              | 4GB                          | 8GB                       | Required                       | fastest                                                                    |\n| Windows/Linux     | Nvidia RTX 3XXX              | 4GB                          | 8GB                       | Required                       | usually faster than RTX 2XXX                                               |\n| Windows/Linux     | Nvidia RTX 2XXX              | 4GB                          | 8GB                       | Required                       | usually faster than GTX 1XXX                                               |\n| Windows/Linux     | Nvidia GTX 1XXX              | 8GB (&ast; 6GB uncertain)    | 8GB                       | Required                       | only marginally faster than CPU                                            |\n| Windows/Linux     | Nvidia GTX 9XX               | 8GB                          | 8GB                       | Required                       | faster or slower than CPU                                                  |\n| Windows/Linux     | Nvidia GTX < 9XX             | Not supported                | /                         | /                              | /                                                                          |\n| Windows           | AMD GPU                      | 8GB    (updated 2023 Dec 30) | 8GB                       | Required                       | via DirectML (&ast; ROCm is on hold), about 3x slower than Nvidia RTX 3XXX |\n| Linux             | AMD GPU                      | 8GB                          | 8GB                       | Required                       | via ROCm, about 1.5x slower than Nvidia RTX 3XXX                           |\n| Mac               | M1/M2 MPS                    | Shared                       | Shared                    | Shared                         | about 9x slower than Nvidia RTX 3XXX                                       |\n| Windows/Linux/Mac | only use CPU                 | 0GB                          | 32GB                      | Required                       | about 17x slower than Nvidia RTX 3XXX                                      |\n\n&ast; AMD GPU ROCm (on hold): The AMD is still working on supporting ROCm on Windows.\n\n&ast; Nvidia GTX 1XXX 6GB uncertain: Some people report 6GB success on GTX 10XX, but some other people report failure cases.\n\n*Note that Fooocus is only for extremely high quality image generating. We will not support smaller models to reduce the requirement and sacrifice result quality.*\n\n## Troubleshoot\n\nSee the common problems [here](troubleshoot.md).\n\n## Default Models\n<a name=\"models\"></a>\n\nGiven different goals, the default models and configs of Fooocus are different:\n\n| Task      | Windows | Linux args | Main Model                  | Refiner | Config                                                                         |\n|-----------| --- | --- |-----------------------------| --- |--------------------------------------------------------------------------------|\n| General   | run.bat |  | juggernautXL_v8Rundiffusion | not used | [here](https://github.com/lllyasviel/Fooocus/blob/main/presets/default.json)   |\n| Realistic | run_realistic.bat | --preset realistic | realisticStockPhoto_v20     | not used | [here](https://github.com/lllyasviel/Fooocus/blob/main/presets/realistic.json) |\n| Anime     | run_anime.bat | --preset anime | animaPencilXL_v500          | not used | [here](https://github.com/lllyasviel/Fooocus/blob/main/presets/anime.json)     |\n\nNote that the download is **automatic** - you do not need to do anything if the internet connection is okay. However, you can download them manually if you (or move them from somewhere else) have your own preparation.\n\n## UI Access and Authentication\nIn addition to running on localhost, Fooocus can also expose its UI in two ways: \n* Local UI listener: use `--listen` (specify port e.g. with `--port 8888`). \n* API access: use `--share` (registers an endpoint at `.gradio.live`).\n\nIn both ways the access is unauthenticated by default. You can add basic authentication by creating a file called `auth.json` in the main directory, which contains a list of JSON objects with the keys `user` and `pass` (see example in [auth-example.json](./auth-example.json)).\n\n## List of \"Hidden\" Tricks\n<a name=\"tech_list\"></a>\n\n<details>\n<summary>Click to see a list of tricks. Those are based on SDXL and are not very up-to-date with latest models.</summary>\n\n1. GPT2-based [prompt expansion as a dynamic style \"Fooocus V2\".](https://github.com/lllyasviel/Fooocus/discussions/117#raw) (similar to Midjourney's hidden pre-processing and \"raw\" mode, or the LeonardoAI's Prompt Magic).\n2. Native refiner swap inside one single k-sampler. The advantage is that the refiner model can now reuse the base model's momentum (or ODE's history parameters) collected from k-sampling to achieve more coherent sampling. In Automatic1111's high-res fix and ComfyUI's node system, the base model and refiner use two independent k-samplers, which means the momentum is largely wasted, and the sampling continuity is broken. Fooocus uses its own advanced k-diffusion sampling that ensures seamless, native, and continuous swap in a refiner setup. (Update Aug 13: Actually, I discussed this with Automatic1111 several days ago, and it seems that the “native refiner swap inside one single k-sampler” is [merged]( https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/12371) into the dev branch of webui. Great!)\n3. Negative ADM guidance. Because the highest resolution level of XL Base does not have cross attentions, the positive and negative signals for XL's highest resolution level cannot receive enough contrasts during the CFG sampling, causing the results to look a bit plastic or overly smooth in certain cases. Fortunately, since the XL's highest resolution level is still conditioned on image aspect ratios (ADM), we can modify the adm on the positive/negative side to compensate for the lack of CFG contrast in the highest resolution level. (Update Aug 16, the IOS App [Draw Things](https://apps.apple.com/us/app/draw-things-ai-generation/id6444050820) will support Negative ADM Guidance. Great!)\n4. We implemented a carefully tuned variation of Section 5.1 of [\"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance\"](https://arxiv.org/pdf/2210.00939.pdf). The weight is set to very low, but this is Fooocus's final guarantee to make sure that the XL will never yield an overly smooth or plastic appearance (examples [here](https://github.com/lllyasviel/Fooocus/discussions/117#sharpness)). This can almost eliminate all cases for which XL still occasionally produces overly smooth results, even with negative ADM guidance. (Update 2023 Aug 18, the Gaussian kernel of SAG is changed to an anisotropic kernel for better structure preservation and fewer artifacts.)\n5. We modified the style templates a bit and added the \"cinematic-default\".\n6. We tested the \"sd_xl_offset_example-lora_1.0.safetensors\" and it seems that when the lora weight is below 0.5, the results are always better than XL without lora.\n7. The parameters of samplers are carefully tuned.\n8. Because XL uses positional encoding for generation resolution, images generated by several fixed resolutions look a bit better than those from arbitrary resolutions (because the positional encoding is not very good at handling int numbers that are unseen during training). This suggests that the resolutions in UI may be hard coded for best results.\n9. Separated prompts for two different text encoders seem unnecessary. Separated prompts for the base model and refiner may work, but the effects are random, and we refrain from implementing this.\n10. The DPM family seems well-suited for XL since XL sometimes generates overly smooth texture, but the DPM family sometimes generates overly dense detail in texture. Their joint effect looks neutral and appealing to human perception.\n11. A carefully designed system for balancing multiple styles as well as prompt expansion.\n12. Using automatic1111's method to normalize prompt emphasizing. This significantly improves results when users directly copy prompts from civitai.\n13. The joint swap system of the refiner now also supports img2img and upscale in a seamless way.\n14. CFG Scale and TSNR correction (tuned for SDXL) when CFG is bigger than 10.\n</details>\n\n## Customization\n\nAfter the first time you run Fooocus, a config file will be generated at `Fooocus\\config.txt`. This file can be edited to change the model path or default parameters.\n\nFor example, an edited `Fooocus\\config.txt` (this file will be generated after the first launch) may look like this:\n\n```json\n{\n    \"path_checkpoints\": \"D:\\\\Fooocus\\\\models\\\\checkpoints\",\n    \"path_loras\": \"D:\\\\Fooocus\\\\models\\\\loras\",\n    \"path_embeddings\": \"D:\\\\Fooocus\\\\models\\\\embeddings\",\n    \"path_vae_approx\": \"D:\\\\Fooocus\\\\models\\\\vae_approx\",\n    \"path_upscale_models\": \"D:\\\\Fooocus\\\\models\\\\upscale_models\",\n    \"path_inpaint\": \"D:\\\\Fooocus\\\\models\\\\inpaint\",\n    \"path_controlnet\": \"D:\\\\Fooocus\\\\models\\\\controlnet\",\n    \"path_clip_vision\": \"D:\\\\Fooocus\\\\models\\\\clip_vision\",\n    \"path_fooocus_expansion\": \"D:\\\\Fooocus\\\\models\\\\prompt_expansion\\\\fooocus_expansion\",\n    \"path_outputs\": \"D:\\\\Fooocus\\\\outputs\",\n    \"default_model\": \"realisticStockPhoto_v10.safetensors\",\n    \"default_refiner\": \"\",\n    \"default_loras\": [[\"lora_filename_1.safetensors\", 0.5], [\"lora_filename_2.safetensors\", 0.5]],\n    \"default_cfg_scale\": 3.0,\n    \"default_sampler\": \"dpmpp_2m\",\n    \"default_scheduler\": \"karras\",\n    \"default_negative_prompt\": \"low quality\",\n    \"default_positive_prompt\": \"\",\n    \"default_styles\": [\n        \"Fooocus V2\",\n        \"Fooocus Photograph\",\n        \"Fooocus Negative\"\n    ]\n}\n```\n\nMany other keys, formats, and examples are in `Fooocus\\config_modification_tutorial.txt` (this file will be generated after the first launch).\n\nConsider twice before you really change the config. If you find yourself breaking things, just delete `Fooocus\\config.txt`. Fooocus will go back to default.\n\nA safer way is just to try \"run_anime.bat\" or \"run_realistic.bat\" - they should already be good enough for different tasks.\n\n~Note that `user_path_config.txt` is deprecated and will be removed soon.~ (Edit: it is already removed.)\n\n### All CMD Flags\n\n```\nentry_with_update.py  [-h] [--listen [IP]] [--port PORT]\n                      [--disable-header-check [ORIGIN]]\n                      [--web-upload-size WEB_UPLOAD_SIZE]\n                      [--hf-mirror HF_MIRROR]\n                      [--external-working-path PATH [PATH ...]]\n                      [--output-path OUTPUT_PATH]\n                      [--temp-path TEMP_PATH] [--cache-path CACHE_PATH]\n                      [--in-browser] [--disable-in-browser]\n                      [--gpu-device-id DEVICE_ID]\n                      [--async-cuda-allocation | --disable-async-cuda-allocation]\n                      [--disable-attention-upcast]\n                      [--all-in-fp32 | --all-in-fp16]\n                      [--unet-in-bf16 | --unet-in-fp16 | --unet-in-fp8-e4m3fn | --unet-in-fp8-e5m2]\n                      [--vae-in-fp16 | --vae-in-fp32 | --vae-in-bf16]\n                      [--vae-in-cpu]\n                      [--clip-in-fp8-e4m3fn | --clip-in-fp8-e5m2 | --clip-in-fp16 | --clip-in-fp32]\n                      [--directml [DIRECTML_DEVICE]]\n                      [--disable-ipex-hijack]\n                      [--preview-option [none,auto,fast,taesd]]\n                      [--attention-split | --attention-quad | --attention-pytorch]\n                      [--disable-xformers]\n                      [--always-gpu | --always-high-vram | --always-normal-vram | --always-low-vram | --always-no-vram | --always-cpu [CPU_NUM_THREADS]]\n                      [--always-offload-from-vram]\n                      [--pytorch-deterministic] [--disable-server-log]\n                      [--debug-mode] [--is-windows-embedded-python]\n                      [--disable-server-info] [--multi-user] [--share]\n                      [--preset PRESET] [--disable-preset-selection]\n                      [--language LANGUAGE]\n                      [--disable-offload-from-vram] [--theme THEME]\n                      [--disable-image-log] [--disable-analytics]\n                      [--disable-metadata] [--disable-preset-download]\n                      [--disable-enhance-output-sorting]\n                      [--enable-auto-describe-image]\n                      [--always-download-new-model]\n                      [--rebuild-hash-cache [CPU_NUM_THREADS]]\n```\n\n## Inline Prompt Features\n\n### Wildcards\n\nExample prompt: `__color__ flower`\n\nProcessed for positive and negative prompt.\n\nSelects a random wildcard from a predefined list of options, in this case the `wildcards/color.txt` file. \nThe wildcard will be replaced with a random color (randomness based on seed). \nYou can also disable randomness and process a wildcard file from top to bottom by enabling the checkbox `Read wildcards in order` in Developer Debug Mode.\n\nWildcards can be nested and combined, and multiple wildcards can be used in the same prompt (example see `wildcards/color_flower.txt`).\n\n### Array Processing\n\nExample prompt: `[[red, green, blue]] flower`\n\nProcessed only for positive prompt.\n\nProcesses the array from left to right, generating a separate image for each element in the array. In this case 3 images would be generated, one for each color.\nIncrease the image number to 3 to generate all 3 variants.\n\nArrays can not be nested, but multiple arrays can be used in the same prompt.\nDoes support inline LoRAs as array elements!\n\n### Inline LoRAs\n\nExample prompt: `flower <lora:sunflowers:1.2>`\n\nProcessed only for positive prompt.\n\nApplies a LoRA to the prompt. The LoRA file must be located in the `models/loras` directory.\n\n## Advanced Features\n\n[Click here to browse the advanced features.](https://github.com/lllyasviel/Fooocus/discussions/117)\n\n## Forks\n\nBelow are some Forks to Fooocus:\n\n| Fooocus' forks |\n| - |\n| [fenneishi/Fooocus-Control](https://github.com/fenneishi/Fooocus-Control) </br>[runew0lf/RuinedFooocus](https://github.com/runew0lf/RuinedFooocus) </br> [MoonRide303/Fooocus-MRE](https://github.com/MoonRide303/Fooocus-MRE) </br> [metercai/SimpleSDXL](https://github.com/metercai/SimpleSDXL) </br> [mashb1t/Fooocus](https://github.com/mashb1t/Fooocus) </br> and so on ... |\n\n## Thanks\n\nMany thanks to [twri](https://github.com/twri) and [3Diva](https://github.com/3Diva) and [Marc K3nt3L](https://github.com/K3nt3L) for creating additional SDXL styles available in Fooocus. \n\nThe project starts from a mixture of [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) and [ComfyUI](https://github.com/comfyanonymous/ComfyUI) codebases.\n\nAlso, thanks [daswer123](https://github.com/daswer123) for contributing the Canvas Zoom!\n\n## Update Log\n\nThe log is [here](update_log.md).\n\n## Localization/Translation/I18N\n\nYou can put json files in the `language` folder to translate the user interface.\n\nFor example, below is the content of `Fooocus/language/example.json`:\n\n```json\n{\n  \"Generate\": \"生成\",\n  \"Input Image\": \"入力画像\",\n  \"Advanced\": \"고급\",\n  \"SAI 3D Model\": \"SAI 3D Modèle\"\n}\n```\n\nIf you add `--language example` arg, Fooocus will read `Fooocus/language/example.json` to translate the UI.\n\nFor example, you can edit the ending line of Windows `run.bat` as\n\n    .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py --language example\n\nOr `run_anime.bat` as\n\n    .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py --language example --preset anime\n\nOr `run_realistic.bat` as\n\n    .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py --language example --preset realistic\n\nFor practical translation, you may create your own file like `Fooocus/language/jp.json` or `Fooocus/language/cn.json` and then use flag `--language jp` or `--language cn`. Apparently, these files do not exist now. **We need your help to create these files!**\n\nNote that if no `--language` is given and at the same time `Fooocus/language/default.json` exists, Fooocus will always load `Fooocus/language/default.json` for translation. By default, the file `Fooocus/language/default.json` does not exist.\n"
        },
        {
          "name": "requirements_docker.txt",
          "type": "blob",
          "size": 0.03,
          "content": "torch==2.1.0\ntorchvision==0.16.0\n"
        },
        {
          "name": "requirements_versions.txt",
          "type": "blob",
          "size": 0.42,
          "content": "torchsde==0.2.6\neinops==0.8.0\ntransformers==4.42.4\nsafetensors==0.4.3\naccelerate==0.32.1\npyyaml==6.0.1\npillow==10.4.0\nscipy==1.14.0\ntqdm==4.66.4\npsutil==6.0.0\npytorch_lightning==2.3.3\nomegaconf==2.3.0\ngradio==3.41.2\npygit2==1.15.1\nopencv-contrib-python-headless==4.10.0.84\nhttpx==0.27.0\nonnxruntime==1.18.1\ntimm==1.0.7\nnumpy==1.26.4\ntokenizers==0.19.1\npackaging==24.1\nrembg==2.0.57\ngroundingdino-py==0.4.0\nsegment_anything==1.0"
        },
        {
          "name": "sdxl_styles",
          "type": "tree",
          "content": null
        },
        {
          "name": "shared.py",
          "type": "blob",
          "size": 0.02,
          "content": "gradio_root = None"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "troubleshoot.md",
          "type": "blob",
          "size": 8.68,
          "content": "Below are many common problems that people encountered:\n\n### RuntimeError: CPUAllocator\n\nSee also the section: **System Swap**\n\n### Model loaded, then paused, then nothing happens\n\nSee also the section: **System Swap**\n\n### Segmentation Fault\n\nSee also the section: **System Swap**\n\n### Aborted\n\nSee also the section: **System Swap**\n\n### core dumped\n\nSee also the section: **System Swap**\n\n### Killed\n\nSee also the section: **System Swap**\n\n### ^C, then quit\n\nSee also the section: **System Swap**\n\n### adm 2816, then stuck\n\nSee also the section: **System Swap**\n\n### Connection errored out\n\nSee also the section: **System Swap**\n\n### Error 1006\n\nSee also the section: **System Swap**\n\n### WinError 10060\n\nSee also the section: **System Swap**\n\n### Read timed out\n\nSee also the section: **System Swap**\n\n### No error, but the console close in a flash. Cannot find any error.\n\nSee also the section: **System Swap**\n\n### Model loading is extremely slow (more than 1 minute)\n\nSee also the section: **System Swap**\n\n### System Swap\n\nAll above problems are caused by the fact that you do not have enough System Swap.\n\nPlease make sure that you have at least 40GB System Swap. In fact, it does not need so much Swap, but 40Gb should be safe for you to run Fooocus in 100% success.\n\n(If you have more than 64GB RAM, then *perhaps* you do not need any System Swap, but we are not exactly sure about this.)\n\nAlso, if your system swap is on HDD, the speed of model loading will be very slow. Please try best to put system swap on SSD.\n\nIf you are using Linux/Mac, please follow your provider's instructions to set Swap Space. Herein, the \"provider\" refers to Ubuntu official, CentOS official, Mac official, etc.\n\nIf you are using Windows, you can set Swap here:\n\n![swap](https://github.com/lllyasviel/Fooocus/assets/19834515/2a06b130-fe9b-4504-94f1-2763be4476e9)\n\nIf you use both HDD and SSD, you *may* test some settings on the above step 7 to try best to put swap area on SSD, so that the speed of model loading will be faster.\n\n**Important: Microsoft Windows 10/11 by default automate system swap for you so that you do not need to touch this dangerous setting. If you do not have enough system swap, just make sure that you have at least 40GB free space on each disk.** The Microsoft Windows 10/11 will automatically make swap areas for you.\n\nAlso, if you obtain Microsoft Windows 10/11 from some unofficial Chinese or Russian provider, they may have modified the default setting of system swap to advertise some \"Enhanced Windows 10/11\" (but actually they are just making things worse rather than improve things). In those cases, you may need to manually check if your system swap setting is consistent to the above screenshot.\n\nFinally, note that you need to restart computer to activate any changes in system swap.\n\n### MetadataIncompleteBuffer\n\nSee also the section: **Model corrupted**\n\n### PytorchStreamReader failed\n\nSee also the section: **Model corrupted**\n\n### Model corrupted\n\nIf you see Model Corrupted, then your model is corrupted. Fooocus will re-download corrupted models for you if your internet connection is good. Otherwise, you may also manually download models. You can find model url and their local location in the console each time a model download is requested.\n\n### UserWarning: The operator 'aten::std_mean.correction' is not currently supported on the DML\n\nThis is a warning that you can ignore.\n\n### Torch not compiled with CUDA enabled\n\nYou are not following the official installation guide. \n\nPlease do not trust those wrong tutorials on the internet, and please only trust the official installation guide. \n\n### subprocess-exited-with-error\n\nPlease use python 3.10\n\nAlso, you are not following the official installation guide. \n\nPlease do not trust those wrong tutorials on the internet, and please only trust the official installation guide. \n\n### SSL: CERTIFICATE_VERIFY_FAILED\n\nAre you living in China? If yes, please consider turn off VPN, and/or try to download models manually.\n\nIf you get this error elsewhere in the world, then you may need to look at [this search](https://www.google.com/search?q=SSL+Certificate+Error). We cannot give very specific guide to fix this since the cause can vary a lot.\n\n### CUDA kernel errors might be asynchronously reported at some other API call\n\nA very small amount of devices does have this problem. The cause can be complicated but usually can be resolved after following these steps:\n\n1. Make sure that you are using official version and latest version installed from [here](https://github.com/lllyasviel/Fooocus#download). (Some forks and other versions are more likely to cause this problem.)\n2. Upgrade your Nvidia driver to the latest version. (Usually the version of your Nvidia driver should be 53X, not 3XX or 4XX.)\n3. If things still do not work, then perhaps it is a problem with CUDA 12. You can use CUDA 11 and Xformers to try to solve this problem. We have prepared all files for you, and please do NOT install any CUDA or other environment on you own. The only one official way to do this is: (1) Backup and delete your `python_embeded` folder (near the `run.bat`); (2) Download the \"previous_old_xformers_env.7z\" from the [release page](https://github.com/lllyasviel/Fooocus/releases/tag/release), decompress it, and put the newly extracted `python_embeded` folder near your `run.bat`; (3) run Fooocus.\n4. If it still does not work, please open an issue for us to take a look.\n\n### Found no NVIDIA driver on your system\n\nPlease upgrade your Nvidia Driver. \n\nIf you are using AMD, please follow official installation guide.\n\n### NVIDIA driver too old\n\nPlease upgrade your Nvidia Driver.\n\n### I am using Mac, the speed is very slow.\n\nSome MAC users may need `--disable-offload-from-vram` to speed up model loading.\n\nBesides, the current support for MAC is very experimental, and we encourage users to also try Diffusionbee or Drawingthings: they are developed only for MAC.\n\n### I am using Nvidia with 8GB VRAM, I get CUDA Out Of Memory\n\nIt is a BUG. Please let us know as soon as possible. Please make an issue. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I am using Nvidia with 6GB VRAM, I get CUDA Out Of Memory\n\nIt is very likely a BUG. Please let us know as soon as possible. Please make an issue. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I am using Nvidia with 4GB VRAM with Float16 support, like RTX 3050, I get CUDA Out Of Memory\n\nIt is a BUG. Please let us know as soon as possible. Please make an issue. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I am using Nvidia with 4GB VRAM without Float16 support, like GTX 960, I get CUDA Out Of Memory\n\nSupporting GPU with 4GB VRAM without fp16 is extremely difficult, and you may not be able to use SDXL. However, you may still make an issue and let us know. You may try SD1.5 in Automatic1111 or other software for your device. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I am using AMD GPU on Windows, I get CUDA Out Of Memory\n\nCurrent AMD support is very experimental for Windows. If you see this, then perhaps you cannot use Fooocus on this device on Windows.\n\nHowever, if you re able to run SDXL on this same device on any other software, please let us know immediately, and we will support it as soon as possible. If no other software can enable your device to run SDXL on Windows, then we also do not have much to help.\n\nBesides, the AMD support on Linux is slightly better because it will use ROCM. You may also try it if you are willing to change OS to linux. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I am using AMD GPU on Linux, I get CUDA Out Of Memory\n\nCurrent AMD support for Linux is better than that for Windows, but still, very experimental. However, if you re able to run SDXL on this same device on any other software, please let us know immediately, and we will support it as soon as possible. If no other software can enable your device to run SDXL on Windows, then we also do not have much to help. See also [minimal requirements](https://github.com/lllyasviel/Fooocus/tree/main?tab=readme-ov-file#minimal-requirement).\n\n### I tried flags like --lowvram or --gpu-only or --bf16 or so on, and things are not getting any better?\n\nPlease remove these flags if you are mislead by some wrong tutorials. In most cases these flags are making things worse and introducing more problems.\n\n### Fooocus suddenly becomes very slow and I have not changed anything\n\nAre you accidentally running two Fooocus at the same time?\n"
        },
        {
          "name": "update_log.md",
          "type": "blob",
          "size": 28.81,
          "content": "# [2.5.5](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.5)\n\n* Fix colab inpaint issue by moving an import statement\n\n# [2.5.4](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.4)\n\n* Fix validation for default_ip_image_* and default_inpaint_mask_sam_model\n* Fix enhance mask debugging in combination with image sorting\n* Fix loading of checkpoints and LoRAs when using multiple directories in config and then switching presets\n\n# [2.5.3](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.3)\n\n* Only load weights from non-safetensors files, preventing harmful code injection\n* Add checkbox for applying/resetting styles when describing images, also allowing multiple describe content types\n\n# [2.5.2](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.2)\n\n* Fix not adding positive prompt when styles didn't have a {prompt} placeholder in the positive prompt\n* Extend config settings for input image, see list in [PR](https://github.com/lllyasviel/Fooocus/pull/3382)\n\n# [2.5.1](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.1)\n\n* Update download URL in readme\n* Increase speed of metadata loading\n* Fix reading of metadata from jpeg, jpg and webp (exif)\n* Fix debug preprocessor\n* Update attributes and add inline prompt features section to readme\n* Add checkbox, config and handling for saving only the final enhanced image. Use config `default_save_only_final_enhanced_image`, default False.\n* Add sorting of final images when enhanced is enabled. Use argument `--disable-enhance-output-sorting` to disable.\n\n# [2.5.0](https://github.com/lllyasviel/Fooocus/releases/tag/v2.5.0)\n\nThis version includes various package updates. If the auto-update doesn't work you can do one of the following:\n1. Open a terminal in the Fooocus folder (location of config.txt) and run `git pull`\n2. Update packages\n   - Windows (installation through zip file): open a terminal in the Fooocus folder (location of config.txt) `..\\python_embeded\\python.exe -m pip install -r .\\requirements_versions.txt` (Windows using embedded python, installation method zip file) or download Fooocus again (zip file attached to this release)\n   - other: manually update the packages using `python.exe -m pip install -r requirements_versions.txt` or use the docker image\n\n---\n\n* Update python dependencies, add segment_anything\n* Add enhance feature, which offers easy image refinement steps (similar to adetailer, but based on dynamic image detection instead of specific mask detection models). See [documentation](https://github.com/lllyasviel/Fooocus/discussions/3281).\n* Rewrite async worker code, make code much more reusable to allow iterations and improve reusability\n* Improve GroundingDINO and SAM image masking\n* Fix inference tensor version counter tracking issue for GroundingDINO after using Enhance (see [discussion](https://github.com/lllyasviel/Fooocus/discussions/3213))\n* Move checkboxes Enable Mask Upload and Invert Mask When Generating from Developer Debug Mode to Inpaint Or Outpaint\n* Add persistent model cache for metadata. Use `--rebuild-hash-cache X` (X = int, number of CPU cores, default all) to manually rebuild the cache for all non-cached hashes\n* Rename `--enable-describe-uov-image` to `--enable-auto-describe-image`, now also works for enhance image upload\n* Rename checkbox `Enable Mask Upload` to `Enable Advanced Masking Features` to better hint to mask auto-generation feature\n* Get upscale model filepath by calling downloading_upscale_model() to ensure the model exists\n* Rename tab titles and translations from singular to plural\n* Rename document to documentation\n* Update default models to latest versions\n  * animaPencilXL_v400 => animaPencilXL_v500\n  * DreamShaperXL_Turbo_dpmppSdeKarras => DreamShaperXL_Turbo_v2_1\n  * SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4 => SDXL_FILM_PHOTOGRAPHY_STYLE_V1\n* Add preset for pony_v6 (using ponyDiffusionV6XL)\n* Add style `Fooocus Pony`\n* Add restart sampler ([paper](https://arxiv.org/abs/2306.14878))\n* Add config option for default_inpaint_engine_version, sets inpaint engine for pony_v6 and playground_v2.5 to None for improved results (incompatible with inpaint engine)\n* Add image editor functionality to mask upload (same as for inpaint, now correctly resizes and allows more detailed mask creation)\n\n# [2.4.3](https://github.com/lllyasviel/Fooocus/releases/tag/v2.4.3)\n\n* Fix alphas_cumprod setter for TCD sampler\n* Add parser for env var strings to expected config value types to allow override of all non-path config keys \n\n# [2.4.2](https://github.com/lllyasviel/Fooocus/releases/tag/v2.4.2)\n\n* Fix some small bugs (tcd scheduler when gamma is 0, chown in Dockerfile, update cmd args in readme, translation for aspect ratios, vae default after file reload)\n* Fix performance LoRA replacement when data is loaded from history log and inline prompt\n* Add support and preset for playground v2.5 (only works with performance Quality or Speed, use with scheduler edm_playground_v2)\n* Make textboxes (incl. positive prompt) resizable\n* Hide intermediate images when performance of Gradio would bottleneck the generation process (Extreme Speed, Lightning, Hyper-SD)\n\n# [2.4.1](https://github.com/lllyasviel/Fooocus/releases/tag/v2.4.1)\n\n* Fix some small bugs (e.g. adjust clip skip default value from 1 to 2, add type check to aspect ratios js update function)\n* Add automated docker build on push to main, tagged with `edge`. See [available docker images](https://github.com/lllyasviel/Fooocus/pkgs/container/fooocus).\n\n# [2.4.0](https://github.com/lllyasviel/Fooocus/releases/tag/v2.4.0)\n\n* Change settings tab elements to be more compact\n* Add clip skip slider\n* Add select for custom VAE\n* Add new style \"Random Style\"\n* Update default anime model to animaPencilXL_v310\n* Add button to reconnect the UI after Fooocus crashed without having to configure everything again (no page reload required)\n* Add performance \"hyper-sd\" (based on [Hyper-SDXL 4 step LoRA](https://huggingface.co/ByteDance/Hyper-SD/blob/main/Hyper-SDXL-4steps-lora.safetensors))\n* Add [AlignYourSteps](https://research.nvidia.com/labs/toronto-ai/AlignYourSteps/) scheduler by Nvidia, see \n* Add [TCD](https://github.com/jabir-zheng/TCD) sampler and scheduler (based on sgm_uniform)\n* Add NSFW image censoring (disables intermediate image preview while generating). Set config value `default_black_out_nsfw` to True to always enable.\n* Add argument `--enable-describe-uov-image` to automatically describe uploaded images for upscaling\n* Add inline lora prompt references with subfolder support, example prompt: `colorful bird <lora:toucan:1.2>`\n* Add size and aspect ratio recommendation on image describe\n* Add inpaint brush color picker, helpful when image and mask brush have the same color\n* Add automated Docker image build using Github Actions on each release.\n* Add full raw prompts to history logs\n* Change code ownership from @lllyasviel to @mashb1t for automated issue / MR notification\n\n# [2.3.1](https://github.com/lllyasviel/Fooocus/releases/tag/2.3.1)\n\n* Remove positive prompt from anime prefix to not reset prompt after switching presets\n* Fix image number being reset to 1 when switching preset, now doesn't reset anymore\n* Fix outpainting dimension calculation when extending left/right\n* Fix LoRA compatibility for LoRAs in a1111 metadata scheme\n\n# [2.3.0](https://github.com/lllyasviel/Fooocus/releases/tag/2.3.0)\n\n* Add performance \"lightning\" (based on [SDXL-Lightning 4 step LoRA](https://huggingface.co/ByteDance/SDXL-Lightning/blob/main/sdxl_lightning_4step_lora.safetensors))\n* Add preset selection to UI, disable with argument `--disable-preset-selection`. Use `--always-download-new-model` to download missing models on preset switch.\n* Improve face swap consistency by switching later in the process to (synthetic) refiner\n* Add temp path cleanup on startup\n* Add support for wildcard subdirectories\n* Add scrollable 2 column layout for styles for better structure\n* Improve Colab resource needs for T4 instances (default), positively tested with all image prompt features\n* Improve anime preset, now uses style `Fooocus Semi Realistic` instead of `Fooocus Negative` (less wet look images)\n\n# [2.2.1](https://github.com/lllyasviel/Fooocus/releases/tag/2.2.1)\n\n* Fix some small bugs (e.g. image grid, upscale fast 2x, LoRA weight width in Firefox)\n* Allow prompt weights in array syntax\n* Add steps override and metadata scheme to history log\n\n# [2.2.0](https://github.com/lllyasviel/Fooocus/releases/tag/2.2.0)\n\n* Isolate every image generation to truly allow multi-user usage\n* Add array support, changes the main prompt when increasing the image number. Syntax: `[[red, green, blue]] flower` \n* Add optional metadata to images, allowing you to regenerate and modify them later with the same parameters \n* Now supports native PNG, JPG and WEBP image generation\n* Add Docker support\n\n# [2.1.865](https://github.com/lllyasviel/Fooocus/releases/tag/2.1.865)\n\n* Various bugfixes\n* Add authentication to --listen\n\n# 2.1.864\n\n* New model list. See also discussions.\n\n# 2.1.861 (requested update)\n\n(2023 Dec 21) Hi all, the feature updating of Fooocus will be paused for about two or three weeks because we have some other workloads. See you soon and we will come back in mid or late Jan. However, you may still see updates if other collaborators are fixing bugs or solving problems.\n\n* Show image preview in Style when mouse hover.\n\n# 2.1.860 (requested update)\n\n* Allow upload inpaint mask in developer mode.\n\n# 2.1.857 (requested update)\n\n* Begin to support 8GB AMD GPU on Windows.\n\n# 2.1.854\n\n* Add a button to copy parameters to clipboard in log.\n* Allow users to load parameters directly by pasting parameters to prompt.\n\n# 2.1.853\n\n* Add Marc K3nt3L's styles. Thanks [Marc K3nt3L](https://github.com/K3nt3L)!\n\n# 2.1.852\n\n* New Log System: Log system now uses tables. If this is breaking some other browser extension or javascript developments, see also [use previous version](https://github.com/lllyasviel/Fooocus/discussions/1405).\n\n# 2.1.846\n\n* Many users reported that image quality is different from 2.1.824. We reviewed all codes and fixed several precision problems in 2.1.846.\n\n# 2.1.843\n\n* Many improvements to Canvas. Thanks CanvasZoom author!\n\n# 2.1.841\n\n* Backend maintain.\n* Fix some potential frozen after model mismatch.\n* Fix crash when cfg=1 when using anime preset.\n* Added some guidelines for troubleshoot the \"CUDA kernel errors asynchronously\" problem.\n* Fix inpaint device problem in `--always-gpu` mode.\n\n# 2.1.839\n\n* Maintained some computation codes in backend for efficiency.\n* Added a note about Seed Breaking Change.\n\n**Seed Breaking Change**: Note that 2.1.825-2.1.839 is seed breaking change. The computation float point is changed and some seeds may give slightly different results. The minor change in 2.1.825-2.1.839 do not influence image quality. See also [use previous version](https://github.com/lllyasviel/Fooocus/discussions/1405).\n\n# 2.1.837\n\n* Fix some precision-related problems.\n\n# 2.1.836\n\n* Avoid blip tokenizer download from torch hub\n\n# 2.1.831\n\n* Input Image -> Describe (Midjourney Describe)\n\n# 2.1.830\n\n* SegmindVega support.\n\n# 2.1.829\n\n* Change SDE tree to CPU on AMD/DirectMl to avoid potential problems.\n\n# 2.1.828\n\n* Allow to disable gradio analytics.\n* Use html table in log.\n* fix some SSL problems.\n\n# 2.1.826\n\n* New backend.\n* FP8 support (see also the new cmd flag list in Readme, eg, --unet-in-fp8-e4m3fn and --unet-in-fp8-e5m2).\n* Fix some MPS problems.\n* GLoRA support.\n* Turbo scheduler.\n\n# 2.1.823\n\n(2023 Nov 26) Hi all, the feature updating of Fooocus will be paused for about two or three weeks because we have some other workloads. See you soon and we will come back in mid December. However, you may still see updates if other collaborators are fixing bugs or solving problems.\n\n* Fix some potential problem when LoRAs has clip keys and user want to load those LoRAs to refiners.\n\n# 2.1.822\n\n* New inpaint system (inpaint beta test ends).\n\n# 2.1.821\n\n* New UI for LoRAs.\n* Improved preset system: normalized preset keys and file names.\n* Improved session system: now multiple users can use one Fooocus at the same time without seeing others' results.\n* Improved some computation related to model precision.\n* Improved config loading system with user-friendly prints.\n\n# 2.1.820\n\n* support \"--disable-image-log\" to prevent writing images and logs to hard drive.\n\n# 2.1.819\n\n* Allow disabling preview in dev tools.\n\n# 2.1.818\n\n* Fix preset lora failed to load when the weight is exactly one.\n\n# 2.1.817\n\n* support \"--theme dark\" and \"--theme light\".\n* added preset files \"default\" and \"lcm\", these presets exist but will not create launcher files (will not be exposed to users) to keep entry clean. The \"--preset lcm\" is equivalent to select \"Extreme Speed\" in UI, but will likely to make some online service deploying easier.\n\n# 2.1.815\n\n* Multiple loras in preset.\n\n# 2.1.814\n\n* Allow using previous preset of official SAI SDXL by modify the args to '--preset sai'. ~Note that this preset will set inpaint engine back to previous v1 to get same results like before. To change the inpaint engine to v2.6, use the dev tools -> inpaint engine -> v2.6.~ (update: it is not needed now after some tests.)\n\n# 2.1.813\n\n* Allow preset to set default inpaint engine.\n\n# 2.1.812\n\n* Allow preset to set default performance.\n* heunpp2 sampler.\n\n# 2.1.810\n\n* Added hints to config_modification_tutorial.txt\n* Removed user hacked aspect ratios in I18N english templates, but it will still be read like before.\n* fix some style sorting problem again (perhaps should try Gradio 4.0 later).\n* Refreshed I18N english templates with more keys.\n\n# 2.1.809\n\n* fix some sorting problem.\n\n# 2.1.808\n\n* Aspect ratios now show aspect ratios.\n* Added style search.\n* Added style sorting/ordering/favorites.\n\n# 2.1.807\n\n* Click on image to see it in full screen.\n\n# 2.1.806\n\n* Fix some lora problems related to clip.\n\n# 2.1.805\n\n* Responsive UI for small screens.\n* Added skip preprocessor in dev tools.\n\n# 2.1.802\n\n* Default inpaint engine changed to v2.6. You can still use inpaint engine v1 in dev tools.\n* Fix some VRAM problems.\n\n# 2.1.799\n\n* Added 'Extreme Speed' performance mode (based on LCM). The previous complicated settings are not needed now.\n\n# 2.1.798\n\n* added lcm scheduler - LCM may need to set both sampler and scheduler to \"lcm\". Other than that, see the description in 2.1.782 logs.\n\n# 2.1.797\n\n* fixed some dependency problems with facexlib and filterpy.\n\n# 2.1.793\n\n* Added many javascripts to improve user experience. Now users with small screen will always see full canvas without needing to scroll.\n\n# 2.1.790\n\n* Face swap (in line with Midjourney InsightFace): Input Image -> Image Prompt -> Advanced -> FaceSwap\n* The performance is super high. Use it carefully and never use it in any illegal things!\n* This implementation will crop faces for you and you do NOT need to crop faces before feeding images into Fooocus. (If you previously manually crop faces from images for other software, you do not need to do that now in Fooocus.)\n\n# 2.1.788\n\n* Fixed some math problems in previous versions.\n* Inpaint engine v2.6 join the beta test of Fooocus inpaint models. Use it in dev tools -> inpaint engine -> v2.6 .\n\n# 2.1.785\n\n* The `user_path_config.txt` is deprecated since 2.1.785. If you are using it right now, please use the new `config.txt` instead. See also the new documentation in the Readme.\n* The paths in `user_path_config.txt` will still be loaded in recent versions, but it will be removed soon.\n* We use very user-friendly method to automatically transfer your path settings from `user_path_config.txt` to `config.txt` and usually you do not need to do anything.\n* The new `config.txt` will never save default values so the default value changes in scripts will not be prevented by old config files.\n\n# 2.1.782\n\n2.1.782 is mainly an update for a new LoRA system that supports both SDXL loras and SD1.5 loras.\n\nNow when you load a lora, the following things will happen:\n\n1. try to load the lora to the base model, if failed (model mismatch), then try to load the lora to refiner.\n2. try to load the lora to refiner, if failed (model mismatch) then do nothing.\n\nIn this way, Fooocus 2.1.782 can benefit from all models and loras from CivitAI with both SDXL and SD1.5 ecosystem, using the unique Fooocus swap algorithm, to achieve extremely high quality results (although the default setting is already very high quality), especially in some anime use cases, if users really want to play with all these things.\n\nRecently the community also developed LCM loras. Users can use it by setting the sampler as 'LCM', scheduler as 'sgm_uniform' (Update in 2.1.798: scheduler should also be \"lcm\"), the forced overwrite of sampling step as 4 to 8, and CFG guidance as 1.0, in dev tools. Do not forget to change the LCM lora weight to 1.0 (many people forget this and report failure cases). Also, set refiner to None. If LCM's feedback in the artists community is good (not the feedback in the programmer community of Stable Diffusion), Fooocus may add some other shortcuts in the future.\n\n# 2.1.781\n\n(2023 Oct 26) Hi all, the feature updating of Fooocus will (really, really, this time) be paused for about two or three weeks because we really have some other workloads. Thanks for the passion of you all (and we in fact have kept updating even after last pausing announcement a week ago, because of many great feedbacks)  - see you soon and we will come back in mid November. However, you may still see updates if other collaborators are fixing bugs or solving problems.\n\n* Disable refiner to speed up when new users mistakenly set same model to base and refiner.\n\n# 2.1.779\n\n* Disable image grid by default because many users reports performance issues. For example, https://github.com/lllyasviel/Fooocus/issues/829 and so on. The image grid will cause problem when user hard drive is not super fast, or when user internet connection is not very good (eg, run in remote). The option is moved to dev tools if users want to use it. We will take a look at it later.\n\n# 2.1.776\n\n* Support Ctrl+Up/Down Arrow to change prompt emphasizing weights.\n\n# 2.1.750\n\n* New UI: now you can get each image during generating.\n\n# 2.1.743\n\n* Improved GPT2 by removing some tokens that may corrupt styles.\n\n# 2.1.741\n\nStyle Updates:\n\n* \"Default (Slightly Cinematic)\" as renamed to \"Fooocus Cinematic\".\n* \"Default (Slightly Cinematic)\" is canceled from default style selections. \n* Added \"Fooocus Sharp\". This style combines many CivitAI prompts that reduces SDXL blurry and improves sharpness in a relatively natural way.\n* Added \"Fooocus Enhance\". This style mainly use the very popular [default negative prompts from JuggernautXL](https://civitai.com/models/133005) and some other enhancing words. JuggernautXL's negative prompt has been proved to be very effective in many recent image posts on CivitAI to improve JuggernautXL and many other models.\n* \"Fooocus Sharp\" and \"Fooocus Enhance\" and \"Fooocus V2\" becomes the new default set of styles.\n* Removed the default text in the \"negative prompt\" input area since it is not necessary now.\n* You can reproduce previous results by using \"Fooocus Cinematic\".\n* \"Fooocus Sharp\" and \"Fooocus Enhance\" may undergo minor revision in future updates.\n\n# 2.1.739\n\n* Added support for authentication in --share mode (via auth.json).\n\n# 2.1.737\n\n* Allowed customizing resolutions in config. \n\nModifying this will make results worse if you do not understand how Positional Encoding works. \n\nYou have been warned.\n\nIf you do not know why numbers must be transformed with many Sin and Cos functions (yes, those Trigonometric functions that you learn in junior high school) before they are fed to SDXL, we do not encourage you to change this - you will become a victim of Positional Encoding. You are likely to suffer from an easy-to-fail tool, rather than getting more control.\n\nYour knowledge gained from SD1.5 (for example, resolution numbers divided by 8 or 64 are good enough for UNet) does not work in SDXL. The SDXL uses Positional Encoding. The SD1.5 does not use Positional Encoding. They are completely different. \n\nYour knowledge gained from other resources (for example, resolutions around 1024 are good enough for SDXL) is wrong. The SDXL uses Positional Encoding. People who say \"all resolutions around 1024 are good\" do not understand what is Positional Encoding. They are not intentionally misleading. They are just not aware of the fact that SDXL is using Positional Encoding. \n\nThe number 1152 must be exactly 1152, not 1152-1, not 1152+1, not 1152-8, not 1152+8. The number 1152 must be exactly 1152. Just Google what is a Positional Encoding.\n\nAgain, if you do not understand how Positional Encoding works, just do not change the resolution numbers.\n\n# 2.1.735\n\n* Fixed many problems related to torch autocast.\n\n# 2.1.733\n\n* Increased allowed random seed range.\n\n# 2.1.728\n\n* Fixed some potential numerical problems since 2.1.723\n\n# 2.1.723\n\n* Improve Fooocus Anime a bit by using better SD1.5 refining formulation.\n\n# 2.1.722\n\n* Now it is possible to translate 100% all texts in the UI.\n\n# 2.1.721\n\n* Added language/en.json to make translation easier.\n\n# 2.1.720\n\n* Added Canvas Zoom to inpaint canvas\n* Fixed the problem that image will be cropped in UI when the uploaded image is too wide.\n\n# 2.1.719\n\n* I18N\n\n# 2.1.718\n\n* Corrected handling dash in wildcard names, more wildcards (extended-color).\n\n# 2.1.717\n\n* Corrected displaying multi-line prompts in Private Log.\n\n# 2.1.716\n\n* Added support for nested wildcards, more wildcards (flower, color_flower).\n\n# 2.1.714\n\n* Fixed resolution problems.\n\n# 2.1.712\n\n* Cleaned up Private Log (most users won't need information about raw prompts).\n\n# 2.1.711\n\n* Added more information about prompts in Private Log.\n* Made wildcards in negative prompt use different seed.\n\n# 2.1.710\n\n* Added information about wildcards usage in console log.\n\n# 2.1.709\n\n* Allowed changing default values of advanced checkbox and image number.\n\n# 2.1.707\n\n* Updated Gradio to v3.41.2.\n\n# 2.1.703\n\n* Fixed many previous problems related to inpaint.\n\n# 2.1.702\n\n* Corrected reading empty negative prompt from config (it shouldn't turn into None).\n\n# 2.1.701\n\n* Updated FreeU node to v2 (gives less overcooked results).\n\n# 2.1.699\n\n* Disabled smart memory management (solves some memory issues).\n\n# 2.1.698\n\n* Added support for loading model files from subfolders.\n\n# 2.1.696\n\n* Improved wildcards implementation (using same wildcard multiple times will now return different values).\n\n**(2023 Oct 18) Again, the feature updating of Fooocus will be paused for about two or three weeks because we have some other workloads - we will come back in early or mid November. However, you may still see updates if other collaborators are fixing bugs or solving problems.**\n\n# 2.1.695 (requested emergency bug fix)\n\n* Reduced 3.4GB RAM use when swapping base model.\n* Reduced 372MB VRAM use in VAE decoding after using control model in image prompt.\n* Note that Official ComfyUI (d44a2de) will run out of VRAM when using sdxl and control-lora on 2060 6GB that does not support float16 at resolution 1024. Fooocus 2.1.695 succeeded in outputting images without OOM using exactly same devices.\n\n(2023 Oct 17) Announcement of update being paused.\n\n# 2.1.693\n\n* Putting custom styles before pre-defined styles.\n* Avoided the consusion between Fooocus Anime preset and Fooocus Anime style (Fooocus Anime style is renamed to Fooocus Masterpiece because it does not make images Anime-looking if not using with Fooocus Anime preset).\n* Fixed some minor bugs in Fooocus Anime preset's prompt emphasizing of commas.\n* Supported and documented embedding grammar (and wildcards grammar). \n* This release is a relative stable version and many features are determined now.\n\n# 2.1.687\n\n* Added support for wildcards (using files from wildcards folder - try prompts like `__color__ sports car` with different seeds).\n\n# 2.1.682\n\n* Added support for custom styles (loaded from JSON files placed in sdxl_styles folder).\n\n# 2.1.681\n\n* Added support for generate hotkey (CTRL+ENTER).\n* Added support for generate forever (RMB on Generate button).\n* Added support for playing sound when generation is finished ('notification.ogg' or 'notification.mp3').\n\n# 2.1.62\n\n* Preset system. Added anime and realistic support.\n\n# 2.1.52\n\n* removed pygit2 dependency (expect auto update) so that people will never have permission denied problems.\n\n# 2.1.50\n\n* Begin to support sd1.5 as refiner. This method scale sigmas given SD15/Xl latent scale and is probably the most correct way to do it. I am going to write a discussion soon.\n\n# 2.1.25\n\nAMD support on Linux and Windows.\n\n# 2.1.0\n\n* Image Prompt\n* Finished the \"Moving from Midjourney\" Table\n\n# 2.0.85\n\n* Speed Up Again\n\n# 2.0.80\n\n* Improved the scheduling of ADM guidance and CFG mimicking for better visual quality in high frequency domain and small objects.\n\n# 2.0.80\n\n* Rework many patches and some UI details.\n* Speed up processing.\n* Move Colab to independent branch.\n* Implemented CFG Scale and TSNR correction when CFG is bigger than 10.\n* Implemented Developer Mode with more options to debug.\n\n### 2.0.72\n\n(2023 sep 21) The feature updating of Fooocus will be paused for about two or three weeks because we have some events and travelling - we will come back in early or mid October. \n\n### 2.0.72\n\n* Allow users to choose path of models.\n\n### 2.0.65\n\n* Inpaint model released.\n\n### 2.0.50\n\n* Variation/Upscale (Midjourney Toolbar) implemented.\n\n### 2.0.16\n\n* Virtual memory system implemented. Now Colab can run both base model and refiner model with 7.8GB RAM + 5.3GB VRAM, and it never crashes.\n* If you are lucky enough to read this line, keep in mind that ComfyUI cannot do this. This is very reasonable that Fooocus is more optimized because it only need to handle a fixed pipeline, but ComfyUI need to consider arbitrary pipelines. \n* But if we just consider the optimization of this fixed workload, after 2.0.16, Fooocus has become the most optimized SDXL app, outperforming ComfyUI.\n\n### 2.0.0\n\n* V2 released.\n* completely rewrite text processing pipeline (higher image quality and prompt understanding).\n* support multi-style.\n* In 100 tests (prompts written by ChatGPT), V2 default results outperform V1 default results in 87 cases, evaluated by two human.\n* In 100 tests (prompts written by ChatGPT), V2 prompt understanding outperform V1 prompt understanding in 81 cases, evaluated by two human, in both default setting and multi/single style mode.\n* Because the above number is above 80%, we view this as a major update and directly jump to 2.0.0.\n* Some other things are renamed.\n\n### 1.0.67\n\n* Use dynamic weighting and lower weights for prompt expansion.\n\n### 1.0.64\n\n* Fixed a small OOM problem.\n\n### 1.0.62\n\n* Change prompt expansion to suffix mode for better balance of semantic and style (and debugging).\n\n### 1.0.60\n\n* Tune the balance between style and Prompt Expansion.\n\n### 1.0.56\n\n* Begin to use magic split.\n\n### 1.0.55\n\n* Minor changes of Prompt Expansion.\n\n### 1.0.52\n\n* Reduce the semantic corruption of Prompt Expansion.\n\n### 1.0.51\n\n* Speed up Prompt Expansion a bit.\n\n### 1.0.50\n\n* Prompt expansion and a \"Raw mode\" to turn it off (similar to Midjourney's \"raw\").\n\n### 1.0.45\n\n* Reworked SAG, removed unnecessary patch\n* Reworked anisotropic filters for faster compute.\n* Replaced with guided anisotropic filter for less distortion.\n\n### 1.0.41\n\n(The update of Fooocus will be paused for a period of time for AUTOMATIC1111 sd-webui 1.6.X, and some features will also be implemented as webui extensions)\n\n### 1.0.40\n\n* Behaviors reverted to 1.0.36 again (refiner steps). The 1.0.36 is too perfect and too typical; beating 1.0.36 is just impossible.\n\n### 1.0.39\n\n* Reverted unstable changes between 1.0.37 and 1.0.38 .\n* Increased refiner steps to half of sampling steps.\n\n### 1.0.36\n\n* Change gaussian kernel to anisotropic kernel.\n\n### 1.0.34\n\n* Random seed restoring.\n\n### 1.0.33\n\n* Hide items in log when images are removed.\n\n### 1.0.32\n\n* Fooocus private log\n\n### 1.0.31\n\n* Fix typo and UI.\n\n### 1.0.29\n\n* Added \"Advanced->Advanced->Advanced\" block for future development.\n\n### 1.0.29\n\n* Fix overcook problem in 1.0.28\n\n### 1.0.28\n\n* SAG implemented\n\n### 1.0.27\n\n* Fix small problem in textbox css \n\n### 1.0.25\n\n* support sys.argv --listen --share --port\n\n### 1.0.24\n\n* Taller input textbox.\n\n### 1.0.23\n\n* Added some hints on linux after UI start so users know the App does not fail.\n\n### 1.0.20\n\n* Support linux.\n\n### 1.0.20\n\n* Speed-up text encoder.\n\n### 1.0.20\n\n* Re-write UI to use async codes: (1) for faster start, and (2) for better live preview.\n* Removed opencv dependency\n* Plan to support Linux soon\n\n### 1.0.19\n\n* Unlock to allow changing model.\n\n### 1.0.17\n\n* Change default model to SDXL-1.0-vae-0.9. (This means the models will be downloaded again, but we should do it as early as possible so that all new users only need to download once. Really sorry for day-0 users. But frankly this is not too late considering that the project is just publicly available in less than 24 hours - if it has been a week then we will prefer more lightweight tricks to update.)\n\n### 1.0.16\n\n* Implemented \"Fooocus/outputs\" folder for saving user results.\n* Ignored cv2 errors when preview fails.\n* Mentioned future AMD support in Readme.\n* Created this log.\n\n### 1.0.15\n\nPublicly available.\n\n### 1.0.0\n\nInitial Version.\n"
        },
        {
          "name": "webui.py",
          "type": "blob",
          "size": 79.73,
          "content": "import gradio as gr\nimport random\nimport os\nimport json\nimport time\nimport shared\nimport modules.config\nimport fooocus_version\nimport modules.html\nimport modules.async_worker as worker\nimport modules.constants as constants\nimport modules.flags as flags\nimport modules.gradio_hijack as grh\nimport modules.style_sorter as style_sorter\nimport modules.meta_parser\nimport args_manager\nimport copy\nimport launch\nfrom extras.inpaint_mask import SAMOptions\n\nfrom modules.sdxl_styles import legal_style_names\nfrom modules.private_logger import get_current_html_path\nfrom modules.ui_gradio_extensions import reload_javascript\nfrom modules.auth import auth_enabled, check_auth\nfrom modules.util import is_json\n\ndef get_task(*args):\n    args = list(args)\n    args.pop(0)\n\n    return worker.AsyncTask(args=args)\n\ndef generate_clicked(task: worker.AsyncTask):\n    import ldm_patched.modules.model_management as model_management\n\n    with model_management.interrupt_processing_mutex:\n        model_management.interrupt_processing = False\n    # outputs=[progress_html, progress_window, progress_gallery, gallery]\n\n    if len(task.args) == 0:\n        return\n\n    execution_start_time = time.perf_counter()\n    finished = False\n\n    yield gr.update(visible=True, value=modules.html.make_progress_html(1, 'Waiting for task to start ...')), \\\n        gr.update(visible=True, value=None), \\\n        gr.update(visible=False, value=None), \\\n        gr.update(visible=False)\n\n    worker.async_tasks.append(task)\n\n    while not finished:\n        time.sleep(0.01)\n        if len(task.yields) > 0:\n            flag, product = task.yields.pop(0)\n            if flag == 'preview':\n\n                # help bad internet connection by skipping duplicated preview\n                if len(task.yields) > 0:  # if we have the next item\n                    if task.yields[0][0] == 'preview':   # if the next item is also a preview\n                        # print('Skipped one preview for better internet connection.')\n                        continue\n\n                percentage, title, image = product\n                yield gr.update(visible=True, value=modules.html.make_progress_html(percentage, title)), \\\n                    gr.update(visible=True, value=image) if image is not None else gr.update(), \\\n                    gr.update(), \\\n                    gr.update(visible=False)\n            if flag == 'results':\n                yield gr.update(visible=True), \\\n                    gr.update(visible=True), \\\n                    gr.update(visible=True, value=product), \\\n                    gr.update(visible=False)\n            if flag == 'finish':\n                if not args_manager.args.disable_enhance_output_sorting:\n                    product = sort_enhance_images(product, task)\n\n                yield gr.update(visible=False), \\\n                    gr.update(visible=False), \\\n                    gr.update(visible=False), \\\n                    gr.update(visible=True, value=product)\n                finished = True\n\n                # delete Fooocus temp images, only keep gradio temp images\n                if args_manager.args.disable_image_log:\n                    for filepath in product:\n                        if isinstance(filepath, str) and os.path.exists(filepath):\n                            os.remove(filepath)\n\n    execution_time = time.perf_counter() - execution_start_time\n    print(f'Total time: {execution_time:.2f} seconds')\n    return\n\n\ndef sort_enhance_images(images, task):\n    if not task.should_enhance or len(images) <= task.images_to_enhance_count:\n        return images\n\n    sorted_images = []\n    walk_index = task.images_to_enhance_count\n\n    for index, enhanced_img in enumerate(images[:task.images_to_enhance_count]):\n        sorted_images.append(enhanced_img)\n        if index not in task.enhance_stats:\n            continue\n        target_index = walk_index + task.enhance_stats[index]\n        if walk_index < len(images) and target_index <= len(images):\n            sorted_images += images[walk_index:target_index]\n        walk_index += task.enhance_stats[index]\n\n    return sorted_images\n\n\ndef inpaint_mode_change(mode, inpaint_engine_version):\n    assert mode in modules.flags.inpaint_options\n\n    # inpaint_additional_prompt, outpaint_selections, example_inpaint_prompts,\n    # inpaint_disable_initial_latent, inpaint_engine,\n    # inpaint_strength, inpaint_respective_field\n\n    if mode == modules.flags.inpaint_option_detail:\n        return [\n            gr.update(visible=True), gr.update(visible=False, value=[]),\n            gr.Dataset.update(visible=True, samples=modules.config.example_inpaint_prompts),\n            False, 'None', 0.5, 0.0\n        ]\n\n    if inpaint_engine_version == 'empty':\n        inpaint_engine_version = modules.config.default_inpaint_engine_version\n\n    if mode == modules.flags.inpaint_option_modify:\n        return [\n            gr.update(visible=True), gr.update(visible=False, value=[]),\n            gr.Dataset.update(visible=False, samples=modules.config.example_inpaint_prompts),\n            True, inpaint_engine_version, 1.0, 0.0\n        ]\n\n    return [\n        gr.update(visible=False, value=''), gr.update(visible=True),\n        gr.Dataset.update(visible=False, samples=modules.config.example_inpaint_prompts),\n        False, inpaint_engine_version, 1.0, 0.618\n    ]\n\n\nreload_javascript()\n\ntitle = f'Fooocus {fooocus_version.version}'\n\nif isinstance(args_manager.args.preset, str):\n    title += ' ' + args_manager.args.preset\n\nshared.gradio_root = gr.Blocks(title=title).queue()\n\nwith shared.gradio_root:\n    currentTask = gr.State(worker.AsyncTask(args=[]))\n    inpaint_engine_state = gr.State('empty')\n    with gr.Row():\n        with gr.Column(scale=2):\n            with gr.Row():\n                progress_window = grh.Image(label='Preview', show_label=True, visible=False, height=768,\n                                            elem_classes=['main_view'])\n                progress_gallery = gr.Gallery(label='Finished Images', show_label=True, object_fit='contain',\n                                              height=768, visible=False, elem_classes=['main_view', 'image_gallery'])\n            progress_html = gr.HTML(value=modules.html.make_progress_html(32, 'Progress 32%'), visible=False,\n                                    elem_id='progress-bar', elem_classes='progress-bar')\n            gallery = gr.Gallery(label='Gallery', show_label=False, object_fit='contain', visible=True, height=768,\n                                 elem_classes=['resizable_area', 'main_view', 'final_gallery', 'image_gallery'],\n                                 elem_id='final_gallery')\n            with gr.Row():\n                with gr.Column(scale=17):\n                    prompt = gr.Textbox(show_label=False, placeholder=\"Type prompt here or paste parameters.\", elem_id='positive_prompt',\n                                        autofocus=True, lines=3)\n\n                    default_prompt = modules.config.default_prompt\n                    if isinstance(default_prompt, str) and default_prompt != '':\n                        shared.gradio_root.load(lambda: default_prompt, outputs=prompt)\n\n                with gr.Column(scale=3, min_width=0):\n                    generate_button = gr.Button(label=\"Generate\", value=\"Generate\", elem_classes='type_row', elem_id='generate_button', visible=True)\n                    reset_button = gr.Button(label=\"Reconnect\", value=\"Reconnect\", elem_classes='type_row', elem_id='reset_button', visible=False)\n                    load_parameter_button = gr.Button(label=\"Load Parameters\", value=\"Load Parameters\", elem_classes='type_row', elem_id='load_parameter_button', visible=False)\n                    skip_button = gr.Button(label=\"Skip\", value=\"Skip\", elem_classes='type_row_half', elem_id='skip_button', visible=False)\n                    stop_button = gr.Button(label=\"Stop\", value=\"Stop\", elem_classes='type_row_half', elem_id='stop_button', visible=False)\n\n                    def stop_clicked(currentTask):\n                        import ldm_patched.modules.model_management as model_management\n                        currentTask.last_stop = 'stop'\n                        if (currentTask.processing):\n                            model_management.interrupt_current_processing()\n                        return currentTask\n\n                    def skip_clicked(currentTask):\n                        import ldm_patched.modules.model_management as model_management\n                        currentTask.last_stop = 'skip'\n                        if (currentTask.processing):\n                            model_management.interrupt_current_processing()\n                        return currentTask\n\n                    stop_button.click(stop_clicked, inputs=currentTask, outputs=currentTask, queue=False, show_progress=False, _js='cancelGenerateForever')\n                    skip_button.click(skip_clicked, inputs=currentTask, outputs=currentTask, queue=False, show_progress=False)\n            with gr.Row(elem_classes='advanced_check_row'):\n                input_image_checkbox = gr.Checkbox(label='Input Image', value=modules.config.default_image_prompt_checkbox, container=False, elem_classes='min_check')\n                enhance_checkbox = gr.Checkbox(label='Enhance', value=modules.config.default_enhance_checkbox, container=False, elem_classes='min_check')\n                advanced_checkbox = gr.Checkbox(label='Advanced', value=modules.config.default_advanced_checkbox, container=False, elem_classes='min_check')\n            with gr.Row(visible=modules.config.default_image_prompt_checkbox) as image_input_panel:\n                with gr.Tabs(selected=modules.config.default_selected_image_input_tab_id):\n                    with gr.Tab(label='Upscale or Variation', id='uov_tab') as uov_tab:\n                        with gr.Row():\n                            with gr.Column():\n                                uov_input_image = grh.Image(label='Image', source='upload', type='numpy', show_label=False)\n                            with gr.Column():\n                                uov_method = gr.Radio(label='Upscale or Variation:', choices=flags.uov_list, value=modules.config.default_uov_method)\n                                gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/390\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n                    with gr.Tab(label='Image Prompt', id='ip_tab') as ip_tab:\n                        with gr.Row():\n                            ip_images = []\n                            ip_types = []\n                            ip_stops = []\n                            ip_weights = []\n                            ip_ctrls = []\n                            ip_ad_cols = []\n                            for image_count in range(modules.config.default_controlnet_image_count):\n                                image_count += 1\n                                with gr.Column():\n                                    ip_image = grh.Image(label='Image', source='upload', type='numpy', show_label=False, height=300, value=modules.config.default_ip_images[image_count])\n                                    ip_images.append(ip_image)\n                                    ip_ctrls.append(ip_image)\n                                    with gr.Column(visible=modules.config.default_image_prompt_advanced_checkbox) as ad_col:\n                                        with gr.Row():\n                                            ip_stop = gr.Slider(label='Stop At', minimum=0.0, maximum=1.0, step=0.001, value=modules.config.default_ip_stop_ats[image_count])\n                                            ip_stops.append(ip_stop)\n                                            ip_ctrls.append(ip_stop)\n\n                                            ip_weight = gr.Slider(label='Weight', minimum=0.0, maximum=2.0, step=0.001, value=modules.config.default_ip_weights[image_count])\n                                            ip_weights.append(ip_weight)\n                                            ip_ctrls.append(ip_weight)\n\n                                        ip_type = gr.Radio(label='Type', choices=flags.ip_list, value=modules.config.default_ip_types[image_count], container=False)\n                                        ip_types.append(ip_type)\n                                        ip_ctrls.append(ip_type)\n\n                                        ip_type.change(lambda x: flags.default_parameters[x], inputs=[ip_type], outputs=[ip_stop, ip_weight], queue=False, show_progress=False)\n                                    ip_ad_cols.append(ad_col)\n                        ip_advanced = gr.Checkbox(label='Advanced', value=modules.config.default_image_prompt_advanced_checkbox, container=False)\n                        gr.HTML('* \\\"Image Prompt\\\" is powered by Fooocus Image Mixture Engine (v1.0.1). <a href=\"https://github.com/lllyasviel/Fooocus/discussions/557\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n\n                        def ip_advance_checked(x):\n                            return [gr.update(visible=x)] * len(ip_ad_cols) + \\\n                                [flags.default_ip] * len(ip_types) + \\\n                                [flags.default_parameters[flags.default_ip][0]] * len(ip_stops) + \\\n                                [flags.default_parameters[flags.default_ip][1]] * len(ip_weights)\n\n                        ip_advanced.change(ip_advance_checked, inputs=ip_advanced,\n                                           outputs=ip_ad_cols + ip_types + ip_stops + ip_weights,\n                                           queue=False, show_progress=False)\n\n                    with gr.Tab(label='Inpaint or Outpaint', id='inpaint_tab') as inpaint_tab:\n                        with gr.Row():\n                            with gr.Column():\n                                inpaint_input_image = grh.Image(label='Image', source='upload', type='numpy', tool='sketch', height=500, brush_color=\"#FFFFFF\", elem_id='inpaint_canvas', show_label=False)\n                                inpaint_advanced_masking_checkbox = gr.Checkbox(label='Enable Advanced Masking Features', value=modules.config.default_inpaint_advanced_masking_checkbox)\n                                inpaint_mode = gr.Dropdown(choices=modules.flags.inpaint_options, value=modules.config.default_inpaint_method, label='Method')\n                                inpaint_additional_prompt = gr.Textbox(placeholder=\"Describe what you want to inpaint.\", elem_id='inpaint_additional_prompt', label='Inpaint Additional Prompt', visible=False)\n                                outpaint_selections = gr.CheckboxGroup(choices=['Left', 'Right', 'Top', 'Bottom'], value=[], label='Outpaint Direction')\n                                example_inpaint_prompts = gr.Dataset(samples=modules.config.example_inpaint_prompts,\n                                                                     label='Additional Prompt Quick List',\n                                                                     components=[inpaint_additional_prompt],\n                                                                     visible=False)\n                                gr.HTML('* Powered by Fooocus Inpaint Engine <a href=\"https://github.com/lllyasviel/Fooocus/discussions/414\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n                                example_inpaint_prompts.click(lambda x: x[0], inputs=example_inpaint_prompts, outputs=inpaint_additional_prompt, show_progress=False, queue=False)\n\n                            with gr.Column(visible=modules.config.default_inpaint_advanced_masking_checkbox) as inpaint_mask_generation_col:\n                                inpaint_mask_image = grh.Image(label='Mask Upload', source='upload', type='numpy', tool='sketch', height=500, brush_color=\"#FFFFFF\", mask_opacity=1, elem_id='inpaint_mask_canvas')\n                                invert_mask_checkbox = gr.Checkbox(label='Invert Mask When Generating', value=modules.config.default_invert_mask_checkbox)\n                                inpaint_mask_model = gr.Dropdown(label='Mask generation model',\n                                                                 choices=flags.inpaint_mask_models,\n                                                                 value=modules.config.default_inpaint_mask_model)\n                                inpaint_mask_cloth_category = gr.Dropdown(label='Cloth category',\n                                                             choices=flags.inpaint_mask_cloth_category,\n                                                             value=modules.config.default_inpaint_mask_cloth_category,\n                                                             visible=False)\n                                inpaint_mask_dino_prompt_text = gr.Textbox(label='Detection prompt', value='', visible=False, info='Use singular whenever possible', placeholder='Describe what you want to detect.')\n                                example_inpaint_mask_dino_prompt_text = gr.Dataset(\n                                    samples=modules.config.example_enhance_detection_prompts,\n                                    label='Detection Prompt Quick List',\n                                    components=[inpaint_mask_dino_prompt_text],\n                                    visible=modules.config.default_inpaint_mask_model == 'sam')\n                                example_inpaint_mask_dino_prompt_text.click(lambda x: x[0],\n                                                                            inputs=example_inpaint_mask_dino_prompt_text,\n                                                                            outputs=inpaint_mask_dino_prompt_text,\n                                                                            show_progress=False, queue=False)\n\n                                with gr.Accordion(\"Advanced options\", visible=False, open=False) as inpaint_mask_advanced_options:\n                                    inpaint_mask_sam_model = gr.Dropdown(label='SAM model', choices=flags.inpaint_mask_sam_model, value=modules.config.default_inpaint_mask_sam_model)\n                                    inpaint_mask_box_threshold = gr.Slider(label=\"Box Threshold\", minimum=0.0, maximum=1.0, value=0.3, step=0.05)\n                                    inpaint_mask_text_threshold = gr.Slider(label=\"Text Threshold\", minimum=0.0, maximum=1.0, value=0.25, step=0.05)\n                                    inpaint_mask_sam_max_detections = gr.Slider(label=\"Maximum number of detections\", info=\"Set to 0 to detect all\", minimum=0, maximum=10, value=modules.config.default_sam_max_detections, step=1, interactive=True)\n                                generate_mask_button = gr.Button(value='Generate mask from image')\n\n                                def generate_mask(image, mask_model, cloth_category, dino_prompt_text, sam_model, box_threshold, text_threshold, sam_max_detections, dino_erode_or_dilate, dino_debug):\n                                    from extras.inpaint_mask import generate_mask_from_image\n\n                                    extras = {}\n                                    sam_options = None\n                                    if mask_model == 'u2net_cloth_seg':\n                                        extras['cloth_category'] = cloth_category\n                                    elif mask_model == 'sam':\n                                        sam_options = SAMOptions(\n                                            dino_prompt=dino_prompt_text,\n                                            dino_box_threshold=box_threshold,\n                                            dino_text_threshold=text_threshold,\n                                            dino_erode_or_dilate=dino_erode_or_dilate,\n                                            dino_debug=dino_debug,\n                                            max_detections=sam_max_detections,\n                                            model_type=sam_model\n                                        )\n\n                                    mask, _, _, _ = generate_mask_from_image(image, mask_model, extras, sam_options)\n\n                                    return mask\n\n\n                                inpaint_mask_model.change(lambda x: [gr.update(visible=x == 'u2net_cloth_seg')] +\n                                                                    [gr.update(visible=x == 'sam')] * 2 +\n                                                                    [gr.Dataset.update(visible=x == 'sam',\n                                                                                       samples=modules.config.example_enhance_detection_prompts)],\n                                                          inputs=inpaint_mask_model,\n                                                          outputs=[inpaint_mask_cloth_category,\n                                                                   inpaint_mask_dino_prompt_text,\n                                                                   inpaint_mask_advanced_options,\n                                                                   example_inpaint_mask_dino_prompt_text],\n                                                          queue=False, show_progress=False)\n\n                    with gr.Tab(label='Describe', id='describe_tab') as describe_tab:\n                        with gr.Row():\n                            with gr.Column():\n                                describe_input_image = grh.Image(label='Image', source='upload', type='numpy', show_label=False)\n                            with gr.Column():\n                                describe_methods = gr.CheckboxGroup(\n                                    label='Content Type',\n                                    choices=flags.describe_types,\n                                    value=modules.config.default_describe_content_type)\n                                describe_apply_styles = gr.Checkbox(label='Apply Styles', value=modules.config.default_describe_apply_prompts_checkbox)\n                                describe_btn = gr.Button(value='Describe this Image into Prompt')\n                                describe_image_size = gr.Textbox(label='Image Size and Recommended Size', elem_id='describe_image_size', visible=False)\n                                gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/1363\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n\n                                def trigger_show_image_properties(image):\n                                    value = modules.util.get_image_size_info(image, modules.flags.sdxl_aspect_ratios)\n                                    return gr.update(value=value, visible=True)\n\n                                describe_input_image.upload(trigger_show_image_properties, inputs=describe_input_image,\n                                                            outputs=describe_image_size, show_progress=False, queue=False)\n\n                    with gr.Tab(label='Enhance', id='enhance_tab') as enhance_tab:\n                        with gr.Row():\n                            with gr.Column():\n                                enhance_input_image = grh.Image(label='Use with Enhance, skips image generation', source='upload', type='numpy')\n                                gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/3281\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n\n                    with gr.Tab(label='Metadata', id='metadata_tab') as metadata_tab:\n                        with gr.Column():\n                            metadata_input_image = grh.Image(label='For images created by Fooocus', source='upload', type='pil')\n                            metadata_json = gr.JSON(label='Metadata')\n                            metadata_import_button = gr.Button(value='Apply Metadata')\n\n                        def trigger_metadata_preview(file):\n                            parameters, metadata_scheme = modules.meta_parser.read_info_from_image(file)\n\n                            results = {}\n                            if parameters is not None:\n                                results['parameters'] = parameters\n\n                            if isinstance(metadata_scheme, flags.MetadataScheme):\n                                results['metadata_scheme'] = metadata_scheme.value\n\n                            return results\n\n                        metadata_input_image.upload(trigger_metadata_preview, inputs=metadata_input_image,\n                                                    outputs=metadata_json, queue=False, show_progress=True)\n\n            with gr.Row(visible=modules.config.default_enhance_checkbox) as enhance_input_panel:\n                with gr.Tabs():\n                    with gr.Tab(label='Upscale or Variation'):\n                        with gr.Row():\n                            with gr.Column():\n                                enhance_uov_method = gr.Radio(label='Upscale or Variation:', choices=flags.uov_list,\n                                                              value=modules.config.default_enhance_uov_method)\n                                enhance_uov_processing_order = gr.Radio(label='Order of Processing',\n                                                                        info='Use before to enhance small details and after to enhance large areas.',\n                                                                        choices=flags.enhancement_uov_processing_order,\n                                                                        value=modules.config.default_enhance_uov_processing_order)\n                                enhance_uov_prompt_type = gr.Radio(label='Prompt',\n                                                                   info='Choose which prompt to use for Upscale or Variation.',\n                                                                   choices=flags.enhancement_uov_prompt_types,\n                                                                   value=modules.config.default_enhance_uov_prompt_type,\n                                                                   visible=modules.config.default_enhance_uov_processing_order == flags.enhancement_uov_after)\n\n                                enhance_uov_processing_order.change(lambda x: gr.update(visible=x == flags.enhancement_uov_after),\n                                                                    inputs=enhance_uov_processing_order,\n                                                                    outputs=enhance_uov_prompt_type,\n                                                                    queue=False, show_progress=False)\n                                gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/3281\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n                    enhance_ctrls = []\n                    enhance_inpaint_mode_ctrls = []\n                    enhance_inpaint_engine_ctrls = []\n                    enhance_inpaint_update_ctrls = []\n                    for index in range(modules.config.default_enhance_tabs):\n                        with gr.Tab(label=f'#{index + 1}') as enhance_tab_item:\n                            enhance_enabled = gr.Checkbox(label='Enable', value=False, elem_classes='min_check',\n                                                          container=False)\n\n                            enhance_mask_dino_prompt_text = gr.Textbox(label='Detection prompt',\n                                                                       info='Use singular whenever possible',\n                                                                       placeholder='Describe what you want to detect.',\n                                                                       interactive=True,\n                                                                       visible=modules.config.default_enhance_inpaint_mask_model == 'sam')\n                            example_enhance_mask_dino_prompt_text = gr.Dataset(\n                                samples=modules.config.example_enhance_detection_prompts,\n                                label='Detection Prompt Quick List',\n                                components=[enhance_mask_dino_prompt_text],\n                                visible=modules.config.default_enhance_inpaint_mask_model == 'sam')\n                            example_enhance_mask_dino_prompt_text.click(lambda x: x[0],\n                                                                        inputs=example_enhance_mask_dino_prompt_text,\n                                                                        outputs=enhance_mask_dino_prompt_text,\n                                                                        show_progress=False, queue=False)\n\n                            enhance_prompt = gr.Textbox(label=\"Enhancement positive prompt\",\n                                                        placeholder=\"Uses original prompt instead if empty.\",\n                                                        elem_id='enhance_prompt')\n                            enhance_negative_prompt = gr.Textbox(label=\"Enhancement negative prompt\",\n                                                                 placeholder=\"Uses original negative prompt instead if empty.\",\n                                                                 elem_id='enhance_negative_prompt')\n\n                            with gr.Accordion(\"Detection\", open=False):\n                                enhance_mask_model = gr.Dropdown(label='Mask generation model',\n                                                                 choices=flags.inpaint_mask_models,\n                                                                 value=modules.config.default_enhance_inpaint_mask_model)\n                                enhance_mask_cloth_category = gr.Dropdown(label='Cloth category',\n                                                                          choices=flags.inpaint_mask_cloth_category,\n                                                                          value=modules.config.default_inpaint_mask_cloth_category,\n                                                                          visible=modules.config.default_enhance_inpaint_mask_model == 'u2net_cloth_seg',\n                                                                          interactive=True)\n\n                                with gr.Accordion(\"SAM Options\",\n                                                  visible=modules.config.default_enhance_inpaint_mask_model == 'sam',\n                                                  open=False) as sam_options:\n                                    enhance_mask_sam_model = gr.Dropdown(label='SAM model',\n                                                                         choices=flags.inpaint_mask_sam_model,\n                                                                         value=modules.config.default_inpaint_mask_sam_model,\n                                                                         interactive=True)\n                                    enhance_mask_box_threshold = gr.Slider(label=\"Box Threshold\", minimum=0.0,\n                                                                           maximum=1.0, value=0.3, step=0.05,\n                                                                           interactive=True)\n                                    enhance_mask_text_threshold = gr.Slider(label=\"Text Threshold\", minimum=0.0,\n                                                                            maximum=1.0, value=0.25, step=0.05,\n                                                                            interactive=True)\n                                    enhance_mask_sam_max_detections = gr.Slider(label=\"Maximum number of detections\",\n                                                                                info=\"Set to 0 to detect all\",\n                                                                                minimum=0, maximum=10,\n                                                                                value=modules.config.default_sam_max_detections,\n                                                                                step=1, interactive=True)\n\n                            with gr.Accordion(\"Inpaint\", visible=True, open=False):\n                                enhance_inpaint_mode = gr.Dropdown(choices=modules.flags.inpaint_options,\n                                                                   value=modules.config.default_inpaint_method,\n                                                                   label='Method', interactive=True)\n                                enhance_inpaint_disable_initial_latent = gr.Checkbox(\n                                    label='Disable initial latent in inpaint', value=False)\n                                enhance_inpaint_engine = gr.Dropdown(label='Inpaint Engine',\n                                                                     value=modules.config.default_inpaint_engine_version,\n                                                                     choices=flags.inpaint_engine_versions,\n                                                                     info='Version of Fooocus inpaint model. If set, use performance Quality or Speed (no performance LoRAs) for best results.')\n                                enhance_inpaint_strength = gr.Slider(label='Inpaint Denoising Strength',\n                                                                     minimum=0.0, maximum=1.0, step=0.001,\n                                                                     value=1.0,\n                                                                     info='Same as the denoising strength in A1111 inpaint. '\n                                                                          'Only used in inpaint, not used in outpaint. '\n                                                                          '(Outpaint always use 1.0)')\n                                enhance_inpaint_respective_field = gr.Slider(label='Inpaint Respective Field',\n                                                                             minimum=0.0, maximum=1.0, step=0.001,\n                                                                             value=0.618,\n                                                                             info='The area to inpaint. '\n                                                                                  'Value 0 is same as \"Only Masked\" in A1111. '\n                                                                                  'Value 1 is same as \"Whole Image\" in A1111. '\n                                                                                  'Only used in inpaint, not used in outpaint. '\n                                                                                  '(Outpaint always use 1.0)')\n                                enhance_inpaint_erode_or_dilate = gr.Slider(label='Mask Erode or Dilate',\n                                                                            minimum=-64, maximum=64, step=1, value=0,\n                                                                            info='Positive value will make white area in the mask larger, '\n                                                                                 'negative value will make white area smaller. '\n                                                                                 '(default is 0, always processed before any mask invert)')\n                                enhance_mask_invert = gr.Checkbox(label='Invert Mask', value=False)\n\n                            gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/3281\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n\n                        enhance_ctrls += [\n                            enhance_enabled,\n                            enhance_mask_dino_prompt_text,\n                            enhance_prompt,\n                            enhance_negative_prompt,\n                            enhance_mask_model,\n                            enhance_mask_cloth_category,\n                            enhance_mask_sam_model,\n                            enhance_mask_text_threshold,\n                            enhance_mask_box_threshold,\n                            enhance_mask_sam_max_detections,\n                            enhance_inpaint_disable_initial_latent,\n                            enhance_inpaint_engine,\n                            enhance_inpaint_strength,\n                            enhance_inpaint_respective_field,\n                            enhance_inpaint_erode_or_dilate,\n                            enhance_mask_invert\n                        ]\n\n                        enhance_inpaint_mode_ctrls += [enhance_inpaint_mode]\n                        enhance_inpaint_engine_ctrls += [enhance_inpaint_engine]\n\n                        enhance_inpaint_update_ctrls += [[\n                            enhance_inpaint_mode, enhance_inpaint_disable_initial_latent, enhance_inpaint_engine,\n                            enhance_inpaint_strength, enhance_inpaint_respective_field\n                        ]]\n\n                        enhance_inpaint_mode.change(inpaint_mode_change, inputs=[enhance_inpaint_mode, inpaint_engine_state], outputs=[\n                            inpaint_additional_prompt, outpaint_selections, example_inpaint_prompts,\n                            enhance_inpaint_disable_initial_latent, enhance_inpaint_engine,\n                            enhance_inpaint_strength, enhance_inpaint_respective_field\n                        ], show_progress=False, queue=False)\n\n                        enhance_mask_model.change(\n                            lambda x: [gr.update(visible=x == 'u2net_cloth_seg')] +\n                                      [gr.update(visible=x == 'sam')] * 2 +\n                                      [gr.Dataset.update(visible=x == 'sam',\n                                                         samples=modules.config.example_enhance_detection_prompts)],\n                            inputs=enhance_mask_model,\n                            outputs=[enhance_mask_cloth_category, enhance_mask_dino_prompt_text, sam_options,\n                                     example_enhance_mask_dino_prompt_text],\n                            queue=False, show_progress=False)\n\n            switch_js = \"(x) => {if(x){viewer_to_bottom(100);viewer_to_bottom(500);}else{viewer_to_top();} return x;}\"\n            down_js = \"() => {viewer_to_bottom();}\"\n\n            input_image_checkbox.change(lambda x: gr.update(visible=x), inputs=input_image_checkbox,\n                                        outputs=image_input_panel, queue=False, show_progress=False, _js=switch_js)\n            ip_advanced.change(lambda: None, queue=False, show_progress=False, _js=down_js)\n\n            current_tab = gr.Textbox(value='uov', visible=False)\n            uov_tab.select(lambda: 'uov', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            inpaint_tab.select(lambda: 'inpaint', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            ip_tab.select(lambda: 'ip', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            describe_tab.select(lambda: 'desc', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            enhance_tab.select(lambda: 'enhance', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            metadata_tab.select(lambda: 'metadata', outputs=current_tab, queue=False, _js=down_js, show_progress=False)\n            enhance_checkbox.change(lambda x: gr.update(visible=x), inputs=enhance_checkbox,\n                                        outputs=enhance_input_panel, queue=False, show_progress=False, _js=switch_js)\n\n        with gr.Column(scale=1, visible=modules.config.default_advanced_checkbox) as advanced_column:\n            with gr.Tab(label='Settings'):\n                if not args_manager.args.disable_preset_selection:\n                    preset_selection = gr.Dropdown(label='Preset',\n                                                   choices=modules.config.available_presets,\n                                                   value=args_manager.args.preset if args_manager.args.preset else \"initial\",\n                                                   interactive=True)\n\n                performance_selection = gr.Radio(label='Performance',\n                                                 choices=flags.Performance.values(),\n                                                 value=modules.config.default_performance,\n                                                 elem_classes=['performance_selection'])\n\n                with gr.Accordion(label='Aspect Ratios', open=False, elem_id='aspect_ratios_accordion') as aspect_ratios_accordion:\n                    aspect_ratios_selection = gr.Radio(label='Aspect Ratios', show_label=False,\n                                                       choices=modules.config.available_aspect_ratios_labels,\n                                                       value=modules.config.default_aspect_ratio,\n                                                       info='width × height',\n                                                       elem_classes='aspect_ratios')\n\n                    aspect_ratios_selection.change(lambda x: None, inputs=aspect_ratios_selection, queue=False, show_progress=False, _js='(x)=>{refresh_aspect_ratios_label(x);}')\n                    shared.gradio_root.load(lambda x: None, inputs=aspect_ratios_selection, queue=False, show_progress=False, _js='(x)=>{refresh_aspect_ratios_label(x);}')\n\n                image_number = gr.Slider(label='Image Number', minimum=1, maximum=modules.config.default_max_image_number, step=1, value=modules.config.default_image_number)\n\n                output_format = gr.Radio(label='Output Format',\n                                         choices=flags.OutputFormat.list(),\n                                         value=modules.config.default_output_format)\n\n                negative_prompt = gr.Textbox(label='Negative Prompt', show_label=True, placeholder=\"Type prompt here.\",\n                                             info='Describing what you do not want to see.', lines=2,\n                                             elem_id='negative_prompt',\n                                             value=modules.config.default_prompt_negative)\n                seed_random = gr.Checkbox(label='Random', value=True)\n                image_seed = gr.Textbox(label='Seed', value=0, max_lines=1, visible=False) # workaround for https://github.com/gradio-app/gradio/issues/5354\n\n                def random_checked(r):\n                    return gr.update(visible=not r)\n\n                def refresh_seed(r, seed_string):\n                    if r:\n                        return random.randint(constants.MIN_SEED, constants.MAX_SEED)\n                    else:\n                        try:\n                            seed_value = int(seed_string)\n                            if constants.MIN_SEED <= seed_value <= constants.MAX_SEED:\n                                return seed_value\n                        except ValueError:\n                            pass\n                        return random.randint(constants.MIN_SEED, constants.MAX_SEED)\n\n                seed_random.change(random_checked, inputs=[seed_random], outputs=[image_seed],\n                                   queue=False, show_progress=False)\n\n                def update_history_link():\n                    if args_manager.args.disable_image_log:\n                        return gr.update(value='')\n\n                    return gr.update(value=f'<a href=\"file={get_current_html_path(output_format)}\" target=\"_blank\">\\U0001F4DA History Log</a>')\n\n                history_link = gr.HTML()\n                shared.gradio_root.load(update_history_link, outputs=history_link, queue=False, show_progress=False)\n\n            with gr.Tab(label='Styles', elem_classes=['style_selections_tab']):\n                style_sorter.try_load_sorted_styles(\n                    style_names=legal_style_names,\n                    default_selected=modules.config.default_styles)\n\n                style_search_bar = gr.Textbox(show_label=False, container=False,\n                                              placeholder=\"\\U0001F50E Type here to search styles ...\",\n                                              value=\"\",\n                                              label='Search Styles')\n                style_selections = gr.CheckboxGroup(show_label=False, container=False,\n                                                    choices=copy.deepcopy(style_sorter.all_styles),\n                                                    value=copy.deepcopy(modules.config.default_styles),\n                                                    label='Selected Styles',\n                                                    elem_classes=['style_selections'])\n                gradio_receiver_style_selections = gr.Textbox(elem_id='gradio_receiver_style_selections', visible=False)\n\n                shared.gradio_root.load(lambda: gr.update(choices=copy.deepcopy(style_sorter.all_styles)),\n                                        outputs=style_selections)\n\n                style_search_bar.change(style_sorter.search_styles,\n                                        inputs=[style_selections, style_search_bar],\n                                        outputs=style_selections,\n                                        queue=False,\n                                        show_progress=False).then(\n                    lambda: None, _js='()=>{refresh_style_localization();}')\n\n                gradio_receiver_style_selections.input(style_sorter.sort_styles,\n                                                       inputs=style_selections,\n                                                       outputs=style_selections,\n                                                       queue=False,\n                                                       show_progress=False).then(\n                    lambda: None, _js='()=>{refresh_style_localization();}')\n\n            with gr.Tab(label='Models'):\n                with gr.Group():\n                    with gr.Row():\n                        base_model = gr.Dropdown(label='Base Model (SDXL only)', choices=modules.config.model_filenames, value=modules.config.default_base_model_name, show_label=True)\n                        refiner_model = gr.Dropdown(label='Refiner (SDXL or SD 1.5)', choices=['None'] + modules.config.model_filenames, value=modules.config.default_refiner_model_name, show_label=True)\n\n                    refiner_switch = gr.Slider(label='Refiner Switch At', minimum=0.1, maximum=1.0, step=0.0001,\n                                               info='Use 0.4 for SD1.5 realistic models; '\n                                                    'or 0.667 for SD1.5 anime models; '\n                                                    'or 0.8 for XL-refiners; '\n                                                    'or any value for switching two SDXL models.',\n                                               value=modules.config.default_refiner_switch,\n                                               visible=modules.config.default_refiner_model_name != 'None')\n\n                    refiner_model.change(lambda x: gr.update(visible=x != 'None'),\n                                         inputs=refiner_model, outputs=refiner_switch, show_progress=False, queue=False)\n\n                with gr.Group():\n                    lora_ctrls = []\n\n                    for i, (enabled, filename, weight) in enumerate(modules.config.default_loras):\n                        with gr.Row():\n                            lora_enabled = gr.Checkbox(label='Enable', value=enabled,\n                                                       elem_classes=['lora_enable', 'min_check'], scale=1)\n                            lora_model = gr.Dropdown(label=f'LoRA {i + 1}',\n                                                     choices=['None'] + modules.config.lora_filenames, value=filename,\n                                                     elem_classes='lora_model', scale=5)\n                            lora_weight = gr.Slider(label='Weight', minimum=modules.config.default_loras_min_weight,\n                                                    maximum=modules.config.default_loras_max_weight, step=0.01, value=weight,\n                                                    elem_classes='lora_weight', scale=5)\n                            lora_ctrls += [lora_enabled, lora_model, lora_weight]\n\n                with gr.Row():\n                    refresh_files = gr.Button(label='Refresh', value='\\U0001f504 Refresh All Files', variant='secondary', elem_classes='refresh_button')\n            with gr.Tab(label='Advanced'):\n                guidance_scale = gr.Slider(label='Guidance Scale', minimum=1.0, maximum=30.0, step=0.01,\n                                           value=modules.config.default_cfg_scale,\n                                           info='Higher value means style is cleaner, vivider, and more artistic.')\n                sharpness = gr.Slider(label='Image Sharpness', minimum=0.0, maximum=30.0, step=0.001,\n                                      value=modules.config.default_sample_sharpness,\n                                      info='Higher value means image and texture are sharper.')\n                gr.HTML('<a href=\"https://github.com/lllyasviel/Fooocus/discussions/117\" target=\"_blank\">\\U0001F4D4 Documentation</a>')\n                dev_mode = gr.Checkbox(label='Developer Debug Mode', value=modules.config.default_developer_debug_mode_checkbox, container=False)\n\n                with gr.Column(visible=modules.config.default_developer_debug_mode_checkbox) as dev_tools:\n                    with gr.Tab(label='Debug Tools'):\n                        adm_scaler_positive = gr.Slider(label='Positive ADM Guidance Scaler', minimum=0.1, maximum=3.0,\n                                                        step=0.001, value=1.5, info='The scaler multiplied to positive ADM (use 1.0 to disable). ')\n                        adm_scaler_negative = gr.Slider(label='Negative ADM Guidance Scaler', minimum=0.1, maximum=3.0,\n                                                        step=0.001, value=0.8, info='The scaler multiplied to negative ADM (use 1.0 to disable). ')\n                        adm_scaler_end = gr.Slider(label='ADM Guidance End At Step', minimum=0.0, maximum=1.0,\n                                                   step=0.001, value=0.3,\n                                                   info='When to end the guidance from positive/negative ADM. ')\n\n                        refiner_swap_method = gr.Dropdown(label='Refiner swap method', value=flags.refiner_swap_method,\n                                                          choices=['joint', 'separate', 'vae'])\n\n                        adaptive_cfg = gr.Slider(label='CFG Mimicking from TSNR', minimum=1.0, maximum=30.0, step=0.01,\n                                                 value=modules.config.default_cfg_tsnr,\n                                                 info='Enabling Fooocus\\'s implementation of CFG mimicking for TSNR '\n                                                      '(effective when real CFG > mimicked CFG).')\n                        clip_skip = gr.Slider(label='CLIP Skip', minimum=1, maximum=flags.clip_skip_max, step=1,\n                                                 value=modules.config.default_clip_skip,\n                                                 info='Bypass CLIP layers to avoid overfitting (use 1 to not skip any layers, 2 is recommended).')\n                        sampler_name = gr.Dropdown(label='Sampler', choices=flags.sampler_list,\n                                                   value=modules.config.default_sampler)\n                        scheduler_name = gr.Dropdown(label='Scheduler', choices=flags.scheduler_list,\n                                                     value=modules.config.default_scheduler)\n                        vae_name = gr.Dropdown(label='VAE', choices=[modules.flags.default_vae] + modules.config.vae_filenames,\n                                                     value=modules.config.default_vae, show_label=True)\n\n                        generate_image_grid = gr.Checkbox(label='Generate Image Grid for Each Batch',\n                                                          info='(Experimental) This may cause performance problems on some computers and certain internet conditions.',\n                                                          value=False)\n\n                        overwrite_step = gr.Slider(label='Forced Overwrite of Sampling Step',\n                                                   minimum=-1, maximum=200, step=1,\n                                                   value=modules.config.default_overwrite_step,\n                                                   info='Set as -1 to disable. For developer debugging.')\n                        overwrite_switch = gr.Slider(label='Forced Overwrite of Refiner Switch Step',\n                                                     minimum=-1, maximum=200, step=1,\n                                                     value=modules.config.default_overwrite_switch,\n                                                     info='Set as -1 to disable. For developer debugging.')\n                        overwrite_width = gr.Slider(label='Forced Overwrite of Generating Width',\n                                                    minimum=-1, maximum=2048, step=1, value=-1,\n                                                    info='Set as -1 to disable. For developer debugging. '\n                                                         'Results will be worse for non-standard numbers that SDXL is not trained on.')\n                        overwrite_height = gr.Slider(label='Forced Overwrite of Generating Height',\n                                                     minimum=-1, maximum=2048, step=1, value=-1,\n                                                     info='Set as -1 to disable. For developer debugging. '\n                                                          'Results will be worse for non-standard numbers that SDXL is not trained on.')\n                        overwrite_vary_strength = gr.Slider(label='Forced Overwrite of Denoising Strength of \"Vary\"',\n                                                            minimum=-1, maximum=1.0, step=0.001, value=-1,\n                                                            info='Set as negative number to disable. For developer debugging.')\n                        overwrite_upscale_strength = gr.Slider(label='Forced Overwrite of Denoising Strength of \"Upscale\"',\n                                                               minimum=-1, maximum=1.0, step=0.001,\n                                                               value=modules.config.default_overwrite_upscale,\n                                                               info='Set as negative number to disable. For developer debugging.')\n\n                        disable_preview = gr.Checkbox(label='Disable Preview', value=modules.config.default_black_out_nsfw,\n                                                      interactive=not modules.config.default_black_out_nsfw,\n                                                      info='Disable preview during generation.')\n                        disable_intermediate_results = gr.Checkbox(label='Disable Intermediate Results',\n                                                      value=flags.Performance.has_restricted_features(modules.config.default_performance),\n                                                      info='Disable intermediate results during generation, only show final gallery.')\n\n                        disable_seed_increment = gr.Checkbox(label='Disable seed increment',\n                                                             info='Disable automatic seed increment when image number is > 1.',\n                                                             value=False)\n                        read_wildcards_in_order = gr.Checkbox(label=\"Read wildcards in order\", value=False)\n\n                        black_out_nsfw = gr.Checkbox(label='Black Out NSFW', value=modules.config.default_black_out_nsfw,\n                                                     interactive=not modules.config.default_black_out_nsfw,\n                                                     info='Use black image if NSFW is detected.')\n\n                        black_out_nsfw.change(lambda x: gr.update(value=x, interactive=not x),\n                                              inputs=black_out_nsfw, outputs=disable_preview, queue=False,\n                                              show_progress=False)\n\n                        if not args_manager.args.disable_image_log:\n                            save_final_enhanced_image_only = gr.Checkbox(label='Save only final enhanced image',\n                                                                         value=modules.config.default_save_only_final_enhanced_image)\n\n                        if not args_manager.args.disable_metadata:\n                            save_metadata_to_images = gr.Checkbox(label='Save Metadata to Images', value=modules.config.default_save_metadata_to_images,\n                                                                  info='Adds parameters to generated images allowing manual regeneration.')\n                            metadata_scheme = gr.Radio(label='Metadata Scheme', choices=flags.metadata_scheme, value=modules.config.default_metadata_scheme,\n                                                       info='Image Prompt parameters are not included. Use png and a1111 for compatibility with Civitai.',\n                                                       visible=modules.config.default_save_metadata_to_images)\n\n                            save_metadata_to_images.change(lambda x: gr.update(visible=x), inputs=[save_metadata_to_images], outputs=[metadata_scheme],\n                                                           queue=False, show_progress=False)\n\n                    with gr.Tab(label='Control'):\n                        debugging_cn_preprocessor = gr.Checkbox(label='Debug Preprocessors', value=False,\n                                                                info='See the results from preprocessors.')\n                        skipping_cn_preprocessor = gr.Checkbox(label='Skip Preprocessors', value=False,\n                                                               info='Do not preprocess images. (Inputs are already canny/depth/cropped-face/etc.)')\n\n                        mixing_image_prompt_and_vary_upscale = gr.Checkbox(label='Mixing Image Prompt and Vary/Upscale',\n                                                                           value=False)\n                        mixing_image_prompt_and_inpaint = gr.Checkbox(label='Mixing Image Prompt and Inpaint',\n                                                                      value=False)\n\n                        controlnet_softness = gr.Slider(label='Softness of ControlNet', minimum=0.0, maximum=1.0,\n                                                        step=0.001, value=0.25,\n                                                        info='Similar to the Control Mode in A1111 (use 0.0 to disable). ')\n\n                        with gr.Tab(label='Canny'):\n                            canny_low_threshold = gr.Slider(label='Canny Low Threshold', minimum=1, maximum=255,\n                                                            step=1, value=64)\n                            canny_high_threshold = gr.Slider(label='Canny High Threshold', minimum=1, maximum=255,\n                                                             step=1, value=128)\n\n                    with gr.Tab(label='Inpaint'):\n                        debugging_inpaint_preprocessor = gr.Checkbox(label='Debug Inpaint Preprocessing', value=False)\n                        debugging_enhance_masks_checkbox = gr.Checkbox(label='Debug Enhance Masks', value=False,\n                                                                       info='Show enhance masks in preview and final results')\n                        debugging_dino = gr.Checkbox(label='Debug GroundingDINO', value=False,\n                                                     info='Use GroundingDINO boxes instead of more detailed SAM masks')\n                        inpaint_disable_initial_latent = gr.Checkbox(label='Disable initial latent in inpaint', value=False)\n                        inpaint_engine = gr.Dropdown(label='Inpaint Engine',\n                                                     value=modules.config.default_inpaint_engine_version,\n                                                     choices=flags.inpaint_engine_versions,\n                                                     info='Version of Fooocus inpaint model. If set, use performance Quality or Speed (no performance LoRAs) for best results.')\n                        inpaint_strength = gr.Slider(label='Inpaint Denoising Strength',\n                                                     minimum=0.0, maximum=1.0, step=0.001, value=1.0,\n                                                     info='Same as the denoising strength in A1111 inpaint. '\n                                                          'Only used in inpaint, not used in outpaint. '\n                                                          '(Outpaint always use 1.0)')\n                        inpaint_respective_field = gr.Slider(label='Inpaint Respective Field',\n                                                             minimum=0.0, maximum=1.0, step=0.001, value=0.618,\n                                                             info='The area to inpaint. '\n                                                                  'Value 0 is same as \"Only Masked\" in A1111. '\n                                                                  'Value 1 is same as \"Whole Image\" in A1111. '\n                                                                  'Only used in inpaint, not used in outpaint. '\n                                                                  '(Outpaint always use 1.0)')\n                        inpaint_erode_or_dilate = gr.Slider(label='Mask Erode or Dilate',\n                                                            minimum=-64, maximum=64, step=1, value=0,\n                                                            info='Positive value will make white area in the mask larger, '\n                                                                 'negative value will make white area smaller. '\n                                                                 '(default is 0, always processed before any mask invert)')\n                        dino_erode_or_dilate = gr.Slider(label='GroundingDINO Box Erode or Dilate',\n                                                         minimum=-64, maximum=64, step=1, value=0,\n                                                         info='Positive value will make white area in the mask larger, '\n                                                              'negative value will make white area smaller. '\n                                                              '(default is 0, processed before SAM)')\n\n                        inpaint_mask_color = gr.ColorPicker(label='Inpaint brush color', value='#FFFFFF', elem_id='inpaint_brush_color')\n\n                        inpaint_ctrls = [debugging_inpaint_preprocessor, inpaint_disable_initial_latent, inpaint_engine,\n                                         inpaint_strength, inpaint_respective_field,\n                                         inpaint_advanced_masking_checkbox, invert_mask_checkbox, inpaint_erode_or_dilate]\n\n                        inpaint_advanced_masking_checkbox.change(lambda x: [gr.update(visible=x)] * 2,\n                                                                 inputs=inpaint_advanced_masking_checkbox,\n                                                                 outputs=[inpaint_mask_image, inpaint_mask_generation_col],\n                                                                 queue=False, show_progress=False)\n\n                        inpaint_mask_color.change(lambda x: gr.update(brush_color=x), inputs=inpaint_mask_color,\n                                                  outputs=inpaint_input_image,\n                                                  queue=False, show_progress=False)\n\n                    with gr.Tab(label='FreeU'):\n                        freeu_enabled = gr.Checkbox(label='Enabled', value=False)\n                        freeu_b1 = gr.Slider(label='B1', minimum=0, maximum=2, step=0.01, value=1.01)\n                        freeu_b2 = gr.Slider(label='B2', minimum=0, maximum=2, step=0.01, value=1.02)\n                        freeu_s1 = gr.Slider(label='S1', minimum=0, maximum=4, step=0.01, value=0.99)\n                        freeu_s2 = gr.Slider(label='S2', minimum=0, maximum=4, step=0.01, value=0.95)\n                        freeu_ctrls = [freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2]\n\n                def dev_mode_checked(r):\n                    return gr.update(visible=r)\n\n                dev_mode.change(dev_mode_checked, inputs=[dev_mode], outputs=[dev_tools],\n                                queue=False, show_progress=False)\n\n                def refresh_files_clicked():\n                    modules.config.update_files()\n                    results = [gr.update(choices=modules.config.model_filenames)]\n                    results += [gr.update(choices=['None'] + modules.config.model_filenames)]\n                    results += [gr.update(choices=[flags.default_vae] + modules.config.vae_filenames)]\n                    if not args_manager.args.disable_preset_selection:\n                        results += [gr.update(choices=modules.config.available_presets)]\n                    for i in range(modules.config.default_max_lora_number):\n                        results += [gr.update(interactive=True),\n                                    gr.update(choices=['None'] + modules.config.lora_filenames), gr.update()]\n                    return results\n\n                refresh_files_output = [base_model, refiner_model, vae_name]\n                if not args_manager.args.disable_preset_selection:\n                    refresh_files_output += [preset_selection]\n                refresh_files.click(refresh_files_clicked, [], refresh_files_output + lora_ctrls,\n                                    queue=False, show_progress=False)\n\n        state_is_generating = gr.State(False)\n\n        load_data_outputs = [advanced_checkbox, image_number, prompt, negative_prompt, style_selections,\n                             performance_selection, overwrite_step, overwrite_switch, aspect_ratios_selection,\n                             overwrite_width, overwrite_height, guidance_scale, sharpness, adm_scaler_positive,\n                             adm_scaler_negative, adm_scaler_end, refiner_swap_method, adaptive_cfg, clip_skip,\n                             base_model, refiner_model, refiner_switch, sampler_name, scheduler_name, vae_name,\n                             seed_random, image_seed, inpaint_engine, inpaint_engine_state,\n                             inpaint_mode] + enhance_inpaint_mode_ctrls + [generate_button,\n                             load_parameter_button] + freeu_ctrls + lora_ctrls\n\n        if not args_manager.args.disable_preset_selection:\n            def preset_selection_change(preset, is_generating, inpaint_mode):\n                preset_content = modules.config.try_get_preset_content(preset) if preset != 'initial' else {}\n                preset_prepared = modules.meta_parser.parse_meta_from_preset(preset_content)\n\n                default_model = preset_prepared.get('base_model')\n                previous_default_models = preset_prepared.get('previous_default_models', [])\n                checkpoint_downloads = preset_prepared.get('checkpoint_downloads', {})\n                embeddings_downloads = preset_prepared.get('embeddings_downloads', {})\n                lora_downloads = preset_prepared.get('lora_downloads', {})\n                vae_downloads = preset_prepared.get('vae_downloads', {})\n\n                preset_prepared['base_model'], preset_prepared['checkpoint_downloads'] = launch.download_models(\n                    default_model, previous_default_models, checkpoint_downloads, embeddings_downloads, lora_downloads,\n                    vae_downloads)\n\n                if 'prompt' in preset_prepared and preset_prepared.get('prompt') == '':\n                    del preset_prepared['prompt']\n\n                return modules.meta_parser.load_parameter_button_click(json.dumps(preset_prepared), is_generating, inpaint_mode)\n\n\n            def inpaint_engine_state_change(inpaint_engine_version, *args):\n                if inpaint_engine_version == 'empty':\n                    inpaint_engine_version = modules.config.default_inpaint_engine_version\n\n                result = []\n                for inpaint_mode in args:\n                    if inpaint_mode != modules.flags.inpaint_option_detail:\n                        result.append(gr.update(value=inpaint_engine_version))\n                    else:\n                        result.append(gr.update())\n\n                return result\n\n            preset_selection.change(preset_selection_change, inputs=[preset_selection, state_is_generating, inpaint_mode], outputs=load_data_outputs, queue=False, show_progress=True) \\\n                .then(fn=style_sorter.sort_styles, inputs=style_selections, outputs=style_selections, queue=False, show_progress=False) \\\n                .then(lambda: None, _js='()=>{refresh_style_localization();}') \\\n                .then(inpaint_engine_state_change, inputs=[inpaint_engine_state] + enhance_inpaint_mode_ctrls, outputs=enhance_inpaint_engine_ctrls, queue=False, show_progress=False)\n\n        performance_selection.change(lambda x: [gr.update(interactive=not flags.Performance.has_restricted_features(x))] * 11 +\n                                               [gr.update(visible=not flags.Performance.has_restricted_features(x))] * 1 +\n                                               [gr.update(value=flags.Performance.has_restricted_features(x))] * 1,\n                                     inputs=performance_selection,\n                                     outputs=[\n                                         guidance_scale, sharpness, adm_scaler_end, adm_scaler_positive,\n                                         adm_scaler_negative, refiner_switch, refiner_model, sampler_name,\n                                         scheduler_name, adaptive_cfg, refiner_swap_method, negative_prompt, disable_intermediate_results\n                                     ], queue=False, show_progress=False)\n\n        output_format.input(lambda x: gr.update(output_format=x), inputs=output_format)\n\n        advanced_checkbox.change(lambda x: gr.update(visible=x), advanced_checkbox, advanced_column,\n                                 queue=False, show_progress=False) \\\n            .then(fn=lambda: None, _js='refresh_grid_delayed', queue=False, show_progress=False)\n\n        inpaint_mode.change(inpaint_mode_change, inputs=[inpaint_mode, inpaint_engine_state], outputs=[\n            inpaint_additional_prompt, outpaint_selections, example_inpaint_prompts,\n            inpaint_disable_initial_latent, inpaint_engine,\n            inpaint_strength, inpaint_respective_field\n        ], show_progress=False, queue=False)\n\n        # load configured default_inpaint_method\n        default_inpaint_ctrls = [inpaint_mode, inpaint_disable_initial_latent, inpaint_engine, inpaint_strength, inpaint_respective_field]\n        for mode, disable_initial_latent, engine, strength, respective_field in [default_inpaint_ctrls] + enhance_inpaint_update_ctrls:\n            shared.gradio_root.load(inpaint_mode_change, inputs=[mode, inpaint_engine_state], outputs=[\n                inpaint_additional_prompt, outpaint_selections, example_inpaint_prompts, disable_initial_latent,\n                engine, strength, respective_field\n            ], show_progress=False, queue=False)\n\n        generate_mask_button.click(fn=generate_mask,\n                                   inputs=[inpaint_input_image, inpaint_mask_model, inpaint_mask_cloth_category,\n                                           inpaint_mask_dino_prompt_text, inpaint_mask_sam_model,\n                                           inpaint_mask_box_threshold, inpaint_mask_text_threshold,\n                                           inpaint_mask_sam_max_detections, dino_erode_or_dilate, debugging_dino],\n                                   outputs=inpaint_mask_image, show_progress=True, queue=True)\n\n        ctrls = [currentTask, generate_image_grid]\n        ctrls += [\n            prompt, negative_prompt, style_selections,\n            performance_selection, aspect_ratios_selection, image_number, output_format, image_seed,\n            read_wildcards_in_order, sharpness, guidance_scale\n        ]\n\n        ctrls += [base_model, refiner_model, refiner_switch] + lora_ctrls\n        ctrls += [input_image_checkbox, current_tab]\n        ctrls += [uov_method, uov_input_image]\n        ctrls += [outpaint_selections, inpaint_input_image, inpaint_additional_prompt, inpaint_mask_image]\n        ctrls += [disable_preview, disable_intermediate_results, disable_seed_increment, black_out_nsfw]\n        ctrls += [adm_scaler_positive, adm_scaler_negative, adm_scaler_end, adaptive_cfg, clip_skip]\n        ctrls += [sampler_name, scheduler_name, vae_name]\n        ctrls += [overwrite_step, overwrite_switch, overwrite_width, overwrite_height, overwrite_vary_strength]\n        ctrls += [overwrite_upscale_strength, mixing_image_prompt_and_vary_upscale, mixing_image_prompt_and_inpaint]\n        ctrls += [debugging_cn_preprocessor, skipping_cn_preprocessor, canny_low_threshold, canny_high_threshold]\n        ctrls += [refiner_swap_method, controlnet_softness]\n        ctrls += freeu_ctrls\n        ctrls += inpaint_ctrls\n\n        if not args_manager.args.disable_image_log:\n            ctrls += [save_final_enhanced_image_only]\n\n        if not args_manager.args.disable_metadata:\n            ctrls += [save_metadata_to_images, metadata_scheme]\n\n        ctrls += ip_ctrls\n        ctrls += [debugging_dino, dino_erode_or_dilate, debugging_enhance_masks_checkbox,\n                  enhance_input_image, enhance_checkbox, enhance_uov_method, enhance_uov_processing_order,\n                  enhance_uov_prompt_type]\n        ctrls += enhance_ctrls\n\n        def parse_meta(raw_prompt_txt, is_generating):\n            loaded_json = None\n            if is_json(raw_prompt_txt):\n                loaded_json = json.loads(raw_prompt_txt)\n\n            if loaded_json is None:\n                if is_generating:\n                    return gr.update(), gr.update(), gr.update()\n                else:\n                    return gr.update(), gr.update(visible=True), gr.update(visible=False)\n\n            return json.dumps(loaded_json), gr.update(visible=False), gr.update(visible=True)\n\n        prompt.input(parse_meta, inputs=[prompt, state_is_generating], outputs=[prompt, generate_button, load_parameter_button], queue=False, show_progress=False)\n\n        load_parameter_button.click(modules.meta_parser.load_parameter_button_click, inputs=[prompt, state_is_generating, inpaint_mode], outputs=load_data_outputs, queue=False, show_progress=False)\n\n        def trigger_metadata_import(file, state_is_generating):\n            parameters, metadata_scheme = modules.meta_parser.read_info_from_image(file)\n            if parameters is None:\n                print('Could not find metadata in the image!')\n                parsed_parameters = {}\n            else:\n                metadata_parser = modules.meta_parser.get_metadata_parser(metadata_scheme)\n                parsed_parameters = metadata_parser.to_json(parameters)\n\n            return modules.meta_parser.load_parameter_button_click(parsed_parameters, state_is_generating, inpaint_mode)\n\n        metadata_import_button.click(trigger_metadata_import, inputs=[metadata_input_image, state_is_generating], outputs=load_data_outputs, queue=False, show_progress=True) \\\n            .then(style_sorter.sort_styles, inputs=style_selections, outputs=style_selections, queue=False, show_progress=False)\n\n        generate_button.click(lambda: (gr.update(visible=True, interactive=True), gr.update(visible=True, interactive=True), gr.update(visible=False, interactive=False), [], True),\n                              outputs=[stop_button, skip_button, generate_button, gallery, state_is_generating]) \\\n            .then(fn=refresh_seed, inputs=[seed_random, image_seed], outputs=image_seed) \\\n            .then(fn=get_task, inputs=ctrls, outputs=currentTask) \\\n            .then(fn=generate_clicked, inputs=currentTask, outputs=[progress_html, progress_window, progress_gallery, gallery]) \\\n            .then(lambda: (gr.update(visible=True, interactive=True), gr.update(visible=False, interactive=False), gr.update(visible=False, interactive=False), False),\n                  outputs=[generate_button, stop_button, skip_button, state_is_generating]) \\\n            .then(fn=update_history_link, outputs=history_link) \\\n            .then(fn=lambda: None, _js='playNotification').then(fn=lambda: None, _js='refresh_grid_delayed')\n\n        reset_button.click(lambda: [worker.AsyncTask(args=[]), False, gr.update(visible=True, interactive=True)] +\n                                   [gr.update(visible=False)] * 6 +\n                                   [gr.update(visible=True, value=[])],\n                           outputs=[currentTask, state_is_generating, generate_button,\n                                    reset_button, stop_button, skip_button,\n                                    progress_html, progress_window, progress_gallery, gallery],\n                           queue=False)\n\n        for notification_file in ['notification.ogg', 'notification.mp3']:\n            if os.path.exists(notification_file):\n                gr.Audio(interactive=False, value=notification_file, elem_id='audio_notification', visible=False)\n                break\n\n        def trigger_describe(modes, img, apply_styles):\n            describe_prompts = []\n            styles = set()\n\n            if flags.describe_type_photo in modes:\n                from extras.interrogate import default_interrogator as default_interrogator_photo\n                describe_prompts.append(default_interrogator_photo(img))\n                styles.update([\"Fooocus V2\", \"Fooocus Enhance\", \"Fooocus Sharp\"])\n\n            if flags.describe_type_anime in modes:\n                from extras.wd14tagger import default_interrogator as default_interrogator_anime\n                describe_prompts.append(default_interrogator_anime(img))\n                styles.update([\"Fooocus V2\", \"Fooocus Masterpiece\"])\n\n            if len(styles) == 0 or not apply_styles:\n                styles = gr.update()\n            else:\n                styles = list(styles)\n\n            if len(describe_prompts) == 0:\n                describe_prompt = gr.update()\n            else:\n                describe_prompt = ', '.join(describe_prompts)\n\n            return describe_prompt, styles\n\n        describe_btn.click(trigger_describe, inputs=[describe_methods, describe_input_image, describe_apply_styles],\n                           outputs=[prompt, style_selections], show_progress=True, queue=True) \\\n            .then(fn=style_sorter.sort_styles, inputs=style_selections, outputs=style_selections, queue=False, show_progress=False) \\\n            .then(lambda: None, _js='()=>{refresh_style_localization();}')\n\n        if args_manager.args.enable_auto_describe_image:\n            def trigger_auto_describe(mode, img, prompt, apply_styles):\n                # keep prompt if not empty\n                if prompt == '':\n                    return trigger_describe(mode, img, apply_styles)\n                return gr.update(), gr.update()\n\n            uov_input_image.upload(trigger_auto_describe, inputs=[describe_methods, uov_input_image, prompt, describe_apply_styles],\n                                   outputs=[prompt, style_selections], show_progress=True, queue=True) \\\n                .then(fn=style_sorter.sort_styles, inputs=style_selections, outputs=style_selections, queue=False, show_progress=False) \\\n                .then(lambda: None, _js='()=>{refresh_style_localization();}')\n\n            enhance_input_image.upload(lambda: gr.update(value=True), outputs=enhance_checkbox, queue=False, show_progress=False) \\\n                .then(trigger_auto_describe, inputs=[describe_methods, enhance_input_image, prompt, describe_apply_styles],\n                      outputs=[prompt, style_selections], show_progress=True, queue=True) \\\n                .then(fn=style_sorter.sort_styles, inputs=style_selections, outputs=style_selections, queue=False, show_progress=False) \\\n                .then(lambda: None, _js='()=>{refresh_style_localization();}')\n\ndef dump_default_english_config():\n    from modules.localization import dump_english_config\n    dump_english_config(grh.all_components)\n\n\n# dump_default_english_config()\n\nshared.gradio_root.launch(\n    inbrowser=args_manager.args.in_browser,\n    server_name=args_manager.args.listen,\n    server_port=args_manager.args.port,\n    share=args_manager.args.share,\n    auth=check_auth if (args_manager.args.share or args_manager.args.listen) and auth_enabled else None,\n    allowed_paths=[modules.config.path_outputs],\n    blocked_paths=[constants.AUTH_FILENAME]\n)\n"
        },
        {
          "name": "wildcards",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}