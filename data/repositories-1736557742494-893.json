{
  "metadata": {
    "timestamp": 1736557742494,
    "page": 893,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "fastai/fastai",
      "stars": 26480,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".devcontainer.json",
          "type": "blob",
          "size": 0.53,
          "content": "{\n    \"name\": \"fastai-codespaces\",\n    \"dockerComposeFile\": \"docker-compose.yml\",\n    \"service\": \"watcher\",\n    \"settings\": {\"terminal.integrated.shell.linux\": \"/bin/bash\"},\n    \"mounts\": [ \"source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind\" ],\n    \"workspaceFolder\": \"/data\",\n    \"forwardPorts\": [4000, 8080],\n    \"appPort\": [4000, 8080],\n    \"extensions\": [\"ms-python.python\",\n                   \"ms-azuretools.vscode-docker\"],\n    \"runServices\": [\"notebook\", \"jekyll\", \"watcher\"],\n    \"postStartCommand\": \"pip install -e .\"\n}\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.34,
          "content": "_proc/\n.gitattributes\nGemfile.lock\ncollect_env.py\ntmp*\nUntitled*.ipynb\n*.bak\ntoken\n.idea/\nconda/\ntmp/\n\ntags\n*~\n~*\n*.swp\n.gitconfig\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n.vscode/\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# Mac stuff\n.DS_Store\n_docs/\n\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 37.81,
          "content": "# Release notes\n\n<!-- do not remove -->\n\n## 2.7.18\n\n### New Features\n\n- PyTorch 2.5 support\n\n\n## 2.7.17\n\n### New Features\n\n- add markdown to doc output ([#4044](https://github.com/fastai/fastai/issues/4044))\n- Support PyTorch 2.4 ([#4040](https://github.com/fastai/fastai/pull/4040)), thanks to [@tonyhoo](https://github.com/tonyhoo)\n- Update Fastcore max version\n\n\n## 2.7.16\n\n### New Features\n\n- Support PyTorch 2.4 ([#4040](https://github.com/fastai/fastai/pull/4040)), thanks to [@tonyhoo](https://github.com/tonyhoo)\n- Support for loss function pickling ([#4034](https://github.com/fastai/fastai/pull/4034)), thanks to [@kevin-vitro](https://github.com/kevin-vitro)\n\n\n## 2.7.15\n\n### New Features\n\n- Support PyTorch 2.3 ([#4026](https://github.com/fastai/fastai/pull/4026)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Add `log` and `show_epochs` to `log_ploss` ([#3964](https://github.com/fastai/fastai/pull/3964)), thanks to [@turbotimon](https://github.com/turbotimon)\n\n\n## 2.7.14\n\n### New Features\n\n- PyTorch 2.2 support, thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n\n## 2.7.13\n\n### New Features\n\n- PyTorch 2.1 compatibility ([#3970](https://github.com/fastai/fastai/pull/3970)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Add `MutableMapping` to `torch_core.apply` to Support Moving Transformers Dicts ([#3969](https://github.com/fastai/fastai/pull/3969)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Added Jaccard coefficient metric for multiclass target in segmentation ([#3951](https://github.com/fastai/fastai/pull/3951)), thanks to [@Hazem-Ahmed-Abdelraouf](https://github.com/Hazem-Ahmed-Abdelraouf)\n- Support TorchVision's Multi-Weight API ([#3944](https://github.com/fastai/fastai/pull/3944)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix the Deploy to GitHub Pages Action ([#3942](https://github.com/fastai/fastai/pull/3942)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n### Bugs Squashed\n\n- Fix Pandas Categorical FutureWarning ([#3973](https://github.com/fastai/fastai/pull/3973)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix torch.jit.script on TimmBody ([#3948](https://github.com/fastai/fastai/pull/3948)), thanks to [@johan12345](https://github.com/johan12345)\n- Resolve CutMix Deprecation Warning ([#3937](https://github.com/fastai/fastai/pull/3937)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fixed format string ([#3934](https://github.com/fastai/fastai/pull/3934)), thanks to [@bkowshik](https://github.com/bkowshik)\n- Fix casting types for mps ([#3912](https://github.com/fastai/fastai/pull/3912)), thanks to [@MSciesiek](https://github.com/MSciesiek)\n- Fix AccumMetric name.setter ([#3621](https://github.com/fastai/fastai/pull/3621)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n\n## 2.7.12\n\n### New Features\n\n- PyTorch 2.0 compatibility ([#3890](https://github.com/fastai/fastai/pull/3890)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Pytorch 2.0 compiler compatibility ([#3899](https://github.com/fastai/fastai/pull/3899)), thanks to [@ggosline](https://github.com/ggosline)\n- Better version support for `TensorBase.new_empty` ([#3887](https://github.com/fastai/fastai/pull/3887)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- TensorBase deepcopy Compatibility ([#3882](https://github.com/fastai/fastai/pull/3882)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n### Bugs Squashed\n\n- Fix `Learn.predict` Errors Out if Passed a PILImage ([#3884](https://github.com/fastai/fastai/pull/3884)), thanks to [@nglillywhite](https://github.com/nglillywhite)\n- Set DataLoaders device if not None and to exists ([#3873](https://github.com/fastai/fastai/pull/3873)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix `default_device` to correctly detect + use mps (Apple Silicon) ([#3858](https://github.com/fastai/fastai/pull/3858)), thanks to [@wolever](https://github.com/wolever)\n\n\n## 2.7.11\n\n### New Features\n\n- ChannelsLast Callback Improvements, Additional Documentation, & Bug Fix ([#3876](https://github.com/fastai/fastai/pull/3876)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Add support for a batch transforms `to` method ([#3875](https://github.com/fastai/fastai/pull/3875)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Allow Pillow Image to be passed to PILBase.create ([#3872](https://github.com/fastai/fastai/pull/3872)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Compat with latest numpy ([#3871](https://github.com/fastai/fastai/pull/3871)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Move training-only step to separate function in `Learner` ([#3857](https://github.com/fastai/fastai/pull/3857)), thanks to [@kunaltyagi](https://github.com/kunaltyagi)\n- TabularPandas data transform reproducibility ([#2826](https://github.com/fastai/fastai/issues/2826))\n\n### Bugs Squashed\n\n- Set DataLoaders device if not None and to exists ([#3873](https://github.com/fastai/fastai/pull/3873)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix `default_device` to correctly detect + use mps (Apple Silicon) ([#3858](https://github.com/fastai/fastai/pull/3858)), thanks to [@wolever](https://github.com/wolever)\n- Fix load hanging in distributed processes ([#3839](https://github.com/fastai/fastai/pull/3839)), thanks to [@muellerzr](https://github.com/muellerzr)\n- `default_device` logic is repeated twice, related to `mps` / OSX support. ([#3785](https://github.com/fastai/fastai/issues/3785))\n- revert auto-enable of mac mps due to pytorch limitations ([#3769](https://github.com/fastai/fastai/issues/3769))\n- Fix Classification Interpretation ([#3563](https://github.com/fastai/fastai/pull/3563)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- vision tutorial failed at `learner.fine_tune(1)` ([#3283](https://github.com/fastai/fastai/issues/3283))\n\n\n## 2.7.10\n\n### New Features\n\n- Add torch save and load kwargs ([#3831](https://github.com/fastai/fastai/pull/3831)), thanks to [@JonathanGrant](https://github.com/JonathanGrant)\n  - This lets us do nice things like set pickle_module to cloudpickle\n- PyTorch 1.13 Compatibility ([#3828](https://github.com/fastai/fastai/pull/3828)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Recursive copying of attribute dictionaries for TensorImage subclass ([#3822](https://github.com/fastai/fastai/pull/3822)), thanks to [@restlessronin](https://github.com/restlessronin)\n- `OptimWrapper` sets same param groups as `Optimizer` ([#3821](https://github.com/fastai/fastai/pull/3821)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n  - This PR harmonizes the default parameter group setting between `OptimWrapper` and `Optimizer` by modifying `OptimWrapper` to match `Optimizer`'s logic.\n- Support normalization of 1-channel images in unet ([#3820](https://github.com/fastai/fastai/pull/3820)), thanks to [@marib00](https://github.com/marib00)\n- Add `img_cls` param to `ImageDataLoaders` ([#3808](https://github.com/fastai/fastai/pull/3808)), thanks to [@tcapelle](https://github.com/tcapelle)\n  - This is particularly useful for passing `PILImageBW` for MNIST.\n- Add support for `kwargs` to `tensor()` when arg is an `ndarray` ([#3797](https://github.com/fastai/fastai/pull/3797)), thanks to [@SaadAhmedGit](https://github.com/SaadAhmedGit)\n- Add latest TorchVision models on fastai ([#3791](https://github.com/fastai/fastai/pull/3791)), thanks to [@datumbox](https://github.com/datumbox)\n- Option to preserve filenames in `download_images` ([#2983](https://github.com/fastai/fastai/pull/2983)), thanks to [@mess-lelouch](https://github.com/mess-lelouch)\n\n### Bugs Squashed\n\n- `get_text_classifier` fails with custom `AWS_LSTM` ([#3817](https://github.com/fastai/fastai/issues/3817))\n- revert auto-enable of mac mps due to pytorch limitations ([#3769](https://github.com/fastai/fastai/issues/3769))\n- Workaround for performance bug in PyTorch with subclassed tensors ([#3683](https://github.com/fastai/fastai/pull/3683)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n\n## 2.7.8\n\n### New Features\n\n- add split value argument to ColSplitter ([#3737](https://github.com/fastai/fastai/pull/3737)), thanks to [@DanteOz](https://github.com/DanteOz)\n- deterministic repr for PIL images ([#3762](https://github.com/fastai/fastai/issues/3762))\n- option to skip default callbacks in `Learner` ([#3739](https://github.com/fastai/fastai/issues/3739))\n- update for nbdev2 ([#3747](https://github.com/fastai/fastai/issues/3747))\n\n### Bugs Squashed\n\n- IntToFloatTensor failing on Mac mps due to missing op ([#3761](https://github.com/fastai/fastai/issues/3761))\n- fix for pretrained in vision.learner ([#3746](https://github.com/fastai/fastai/pull/3746)), thanks to [@peterdudfield](https://github.com/peterdudfield)\n- fix same file error message when resizing image ([#3743](https://github.com/fastai/fastai/pull/3743)), thanks to [@cvergnes](https://github.com/cvergnes)\n\n\n## 2.7.6\n\n### New Features\n\n- Initial Mac GPU (mps) support ([#3719](https://github.com/fastai/fastai/issues/3719))\n\n\n## 2.7.5\n\n### New Features\n\n- auto-normalize timm models ([#3716](https://github.com/fastai/fastai/issues/3716))\n- PyTorch 1.12 support\n\n\n## 2.7.4\n\n### New Features\n\n- Add `DataBlock.weighted_dataloaders` ([#3706](https://github.com/fastai/fastai/issues/3706))\n\n\n## 2.7.2\n\n### Bugs Squashed\n\n- `PIL.Resampling` only added in v9.1 ([#3699](https://github.com/fastai/fastai/issues/3699))\n\n\n## 2.7.1\n\n### Bugs Squashed\n\n- Update fastcore minimum version\n\n\n## 2.7.0\n\n### Breaking changes\n\n- Distributed training now uses Hugging Face Accelerate, rather than fastai's launcher.\n  Distributed training is now supported in a notebook -- see [this tutorial](https://docs.fast.ai/tutorial.distributed) for details\n\n### New Features\n\n- `resize_images` creates folder structure at `dest` when `recurse=True` ([#3692](https://github.com/fastai/fastai/issues/3692))\n- Integrate nested callable and getcallable ([#3691](https://github.com/fastai/fastai/pull/3691)), thanks to [@muellerzr](https://github.com/muellerzr)\n- workaround pytorch subclass performance bug ([#3682](https://github.com/fastai/fastai/issues/3682))\n- Torch 1.12.0 compatibility ([#3659](https://github.com/fastai/fastai/pull/3659)), thanks to [@josiahls](https://github.com/josiahls)\n- Integrate Accelerate into fastai ([#3646](https://github.com/fastai/fastai/pull/3646)), thanks to [@muellerzr](https://github.com/muellerzr)\n- New Callback event, before and after backward ([#3644](https://github.com/fastai/fastai/pull/3644)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Let optimizer use built torch opt ([#3642](https://github.com/fastai/fastai/pull/3642)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Support PyTorch Dataloaders with `DistributedDL` ([#3637](https://github.com/fastai/fastai/pull/3637)), thanks to [@tmabraham](https://github.com/tmabraham)\n- Add `channels_last` cb ([#3634](https://github.com/fastai/fastai/pull/3634)), thanks to [@tcapelle](https://github.com/tcapelle)\n- support all timm kwargs ([#3631](https://github.com/fastai/fastai/issues/3631))\n- send `self.loss_func` to device if it is an insatnce on nn.Module ([#3395](https://github.com/fastai/fastai/pull/3395)), thanks to [@arampacha](https://github.com/arampacha)\n- adds tracking and logging best metrics to wandb cb ([#3372](https://github.com/fastai/fastai/pull/3372)), thanks to [@arampacha](https://github.com/arampacha)\n\n### Bugs Squashed\n\n- Solve hanging `load_model` and let LRFind be ran in a distributed setup ([#3689](https://github.com/fastai/fastai/pull/3689)), thanks to [@muellerzr](https://github.com/muellerzr)\n- pytorch subclass functions fail if no positional args ([#3687](https://github.com/fastai/fastai/issues/3687))\n- Workaround for performance bug in PyTorch with subclassed tensors ([#3683](https://github.com/fastai/fastai/pull/3683)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix `Tokenizer.get_lengths` ([#3667](https://github.com/fastai/fastai/pull/3667)), thanks to [@karotchykau](https://github.com/karotchykau)\n- `load_learner` with `cpu=False` doesn't respect the current cuda device if model exported on another; fixes #3656 ([#3657](https://github.com/fastai/fastai/pull/3657)), thanks to [@ohmeow](https://github.com/ohmeow)\n- [Bugfix] Fix smoothloss on distributed ([#3643](https://github.com/fastai/fastai/pull/3643)), thanks to [@muellerzr](https://github.com/muellerzr)\n- WandbCallback Error: \"Tensors must be CUDA and dense\" on distributed training ([#3291](https://github.com/fastai/fastai/issues/3291))\n- vision tutorial failed at `learner.fine_tune(1)` ([#3283](https://github.com/fastai/fastai/issues/3283))\n\n\n## 2.6.3\n\n### Bugs Squashed\n\n- Fix `Learner` pickling problem introduced in v2.6.2\n\n\n## 2.6.2\n\n### Bugs Squashed\n\n- Race condition: `'Tensor' object has no attribute 'append'` ([#3385](https://github.com/fastai/fastai/issues/3385))\n\n\n## 2.6.0\n\n### New Features\n\n- add support for Ross Wightman's Pytorch Image Models (timm) library ([#3624](https://github.com/fastai/fastai/issues/3624))\n- rename `cnn_learner` to `vision_learner` since we now support models other than CNNs too ([#3625](https://github.com/fastai/fastai/issues/3625))\n\n### Bugs Squashed\n\n- Fix AccumMetric name.setter ([#3621](https://github.com/fastai/fastai/pull/3621)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix Classification Interpretation ([#3563](https://github.com/fastai/fastai/pull/3563)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n\n\n## 2.5.6\n\n### New Features\n\n- support pytorch 1.11 ([#3618](https://github.com/fastai/fastai/issues/3618))\n- Add in exceptions and verbose errors ([#3611](https://github.com/fastai/fastai/pull/3611)), thanks to [@muellerzr](https://github.com/muellerzr)\n\n### Bugs Squashed\n\n- Fix name conflicts in `ColReader` ([#3602](https://github.com/fastai/fastai/pull/3602)), thanks to [@hiromis](https://github.com/hiromis)\n\n\n## 2.5.5\n\n### New Features\n\n- Update fastcore dep\n\n## 2.5.4\n\n### New Features\n\n- Support py3.10 annotations ([#3601](https://github.com/fastai/fastai/issues/3601))\n\n### Bugs Squashed\n\n- Fix pin_memory=True breaking (batch) Transforms ([#3606](https://github.com/fastai/fastai/pull/3606)), thanks to [@johan12345](https://github.com/johan12345)\n- Add Python 3.9 to `setup.py` for PyPI ([#3604](https://github.com/fastai/fastai/pull/3604)), thanks to [@nzw0301](https://github.com/nzw0301)\n- removes add_vert from get_grid calls ([#3593](https://github.com/fastai/fastai/pull/3593)), thanks to [@kevinbird15](https://github.com/kevinbird15)\n- Making `loss_not_reduced` work with DiceLoss ([#3583](https://github.com/fastai/fastai/pull/3583)), thanks to [@hiromis](https://github.com/hiromis)\n- Fix bug in URLs.path() in 04_data.external ([#3582](https://github.com/fastai/fastai/pull/3582)), thanks to [@malligaraj](https://github.com/malligaraj)\n- Custom name for metrics ([#3573](https://github.com/fastai/fastai/pull/3573)), thanks to [@bdsaglam](https://github.com/bdsaglam)\n- Update import for show_install ([#3568](https://github.com/fastai/fastai/pull/3568)), thanks to [@fr1ll](https://github.com/fr1ll)\n- Fix Classification Interpretation ([#3563](https://github.com/fastai/fastai/pull/3563)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Updates Interpretation class to be memory efficient ([#3558](https://github.com/fastai/fastai/pull/3558)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Learner.show_results uses passed dataloader via dl_idx or dl arguments ([#3554](https://github.com/fastai/fastai/pull/3554)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix learn.export pickle error with MixedPrecision Callback ([#3544](https://github.com/fastai/fastai/pull/3544)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix concurrent LRFinder instances overwriting each other by using tempfile ([#3528](https://github.com/fastai/fastai/pull/3528)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix _get_shapes to work with dictionaries ([#3520](https://github.com/fastai/fastai/pull/3520)), thanks to [@ohmeow](https://github.com/ohmeow)\n- Fix torch version checks, remove clip_grad_norm check ([#3518](https://github.com/fastai/fastai/pull/3518)), thanks to [@warner-benjamin](https://github.com/warner-benjamin)\n- Fix nested tensors predictions compatibility with fp16 ([#3516](https://github.com/fastai/fastai/pull/3516)), thanks to [@tcapelle](https://github.com/tcapelle)\n- Learning rate passed via OptimWrapper not updated in Learner ([#3337](https://github.com/fastai/fastai/issues/3337))\n- Different results after running `lr_find()` at different times ([#3295](https://github.com/fastai/fastai/issues/3295))\n- lr_find() may fail if run in parallel from the same directory ([#3240](https://github.com/fastai/fastai/issues/3240))\n\n\n## 2.5.3\n\n### New Features\n\n- add `at_end` feature to `SaveModelCallback` ([#3296](https://github.com/fastai/fastai/pull/3296)), thanks to [@tmabraham](https://github.com/tmabraham)\n\n### Bugs Squashed\n\n- fix fp16 test ([#3284](https://github.com/fastai/fastai/pull/3284)), thanks to [@tmabraham](https://github.com/tmabraham)\n\n\n## 2.5.1\n\n- Import `download_url` from fastdownload\n\n\n## 2.5.0\n\n### Breaking changes\n\n- `config.yml` has been renamed to `config.ini`, and is now in `ConfigParser` format instead of YAML\n- THe `_path` suffixes in `config.ini` have been removed\n\n### Bugs Squashed\n\n- Training with `learn.to_fp16(`) fails with PyTorch 1.9 / Cuda 11.4 ([#3438](https://github.com/fastai/fastai/issues/3438))\n- pandas 1.3.0 breaks `add_elapsed_times` ([#3431](https://github.com/fastai/fastai/issues/3431))\n\n\n## 2.4.1\n\n### New Features\n\n- add DiceLoss ([#3386](https://github.com/fastai/fastai/pull/3386)), thanks to [@tcapelle](https://github.com/tcapelle)\n- TabularPandas data transform reproducibility ([#2826](https://github.com/fastai/fastai/issues/2826))\n\n### Bugs Squashed\n\n- Latest Pillow v8.3.0 breaks conversion Image to Tensor ([#3416](https://github.com/fastai/fastai/issues/3416))\n\n\n## 2.4\n\n### Breaking changes\n\n- QRNN module removed, due to incompatibility with PyTorch 1.9, and lack of utilization of QRNN in the deep learning community. QRNN was our only module that wasn't pure Python, so with this change fastai is now a pure Python package.\n\n### New Features\n\n- Support for PyTorch 1.9\n- Improved LR Suggestions ([#3377](https://github.com/fastai/fastai/pull/3377)), thanks to [@muellerzr](https://github.com/muellerzr)\n- SaveModelCallback every nth epoch ([#3375](https://github.com/fastai/fastai/pull/3375)), thanks to [@KeremTurgutlu](https://github.com/KeremTurgutlu)\n- Send self.loss_func to device if it is an instance of nn.Module ([#3395](https://github.com/fastai/fastai/pull/3395)), thanks to [@arampacha](https://github.com/arampacha)\n- Batch support for more than one image ([#3339](https://github.com/fastai/fastai/issues/3339))\n- Changable tfmdlists for TransformBlock, Datasets, DataBlock ([#3327](https://github.com/fastai/fastai/issues/3327))\n\n### Bugs Squashed\n\n- convert TensorBBox to TensorBase during compare ([#3388](https://github.com/fastai/fastai/pull/3388)), thanks to [@kevinbird15](https://github.com/kevinbird15)\n- Check if normalize exists on `_add_norm` ([#3371](https://github.com/fastai/fastai/pull/3371)), thanks to [@renato145](https://github.com/renato145)\n\n\n## 2.3.1\n\n### New Features\n\n- Add support for pytorch 1.8 ([#3349](https://github.com/fastai/fastai/issues/3349))\n- Add support for spacy3 ([#3348](https://github.com/fastai/fastai/issues/3348))\n- Add support for Windows. Big thanks to Microsoft for many contributions to get this working\n- Timedistributed layer and Image Sequence Tutorial ([#3124](https://github.com/fastai/fastai/pull/3124)), thanks to [@tcapelle](https://github.com/tcapelle)\n- Add interactive run logging to AzureMLCallback ([#3341](https://github.com/fastai/fastai/pull/3341)), thanks to [@yijinlee](https://github.com/yijinlee)\n- Batch support for more than one image ([#3339](https://github.com/fastai/fastai/issues/3339))\n- Have interp use ds_idx, add tests ([#3332](https://github.com/fastai/fastai/pull/3332)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Automatically have fastai determine the right device, even with torch DataLoaders ([#3330](https://github.com/fastai/fastai/pull/3330)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Add `at_end` feature to `SaveModelCallback` ([#3296](https://github.com/fastai/fastai/pull/3296)), thanks to [@tmabraham](https://github.com/tmabraham)\n- Improve inplace params in Tabular's new and allow for new and test_dl to be in place ([#3292](https://github.com/fastai/fastai/pull/3292)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Update VSCode & Codespaces dev container ([#3280](https://github.com/fastai/fastai/pull/3280)), thanks to [@bamurtaugh](https://github.com/bamurtaugh)\n- Add max_scale param to RandomResizedCrop(GPU) ([#3252](https://github.com/fastai/fastai/pull/3252)), thanks to [@kai-tub](https://github.com/kai-tub)\n- Increase testing granularity for speedup ([#3242](https://github.com/fastai/fastai/pull/3242)), thanks to [@ddobrinskiy](https://github.com/ddobrinskiy)\n\n### Bugs Squashed\n\n- Make TTA turn shuffle and drop_last off when using ds_idx ([#3347](https://github.com/fastai/fastai/pull/3347)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Add order to TrackerCallback derived classes ([#3346](https://github.com/fastai/fastai/pull/3346)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Prevent schedule from crashing close to the end of training ([#3335](https://github.com/fastai/fastai/pull/3335)), thanks to [@Lewington-pitsos](https://github.com/Lewington-pitsos)\n- Fix ability to use raw pytorch DataLoaders ([#3328](https://github.com/fastai/fastai/pull/3328)), thanks to [@hamelsmu](https://github.com/hamelsmu)\n- Fix PixelShuffle_icnr weight ([#3322](https://github.com/fastai/fastai/pull/3322)), thanks to [@pratX](https://github.com/pratX)\n- Creation of new DataLoader in Learner.get_preds has wrong keyword ([#3316](https://github.com/fastai/fastai/pull/3316)), thanks to [@tcapelle](https://github.com/tcapelle)\n- Correct layers order in tabular learner ([#3314](https://github.com/fastai/fastai/pull/3314)), thanks to [@gradientsky](https://github.com/gradientsky)\n- Fix vmin parameter default ([#3305](https://github.com/fastai/fastai/pull/3305)), thanks to [@tcapelle](https://github.com/tcapelle)\n- Ensure call to `one_batch` places data on the right device ([#3298](https://github.com/fastai/fastai/pull/3298)), thanks to [@tcapelle](https://github.com/tcapelle)\n- Fix Cutmix Augmentation ([#3259](https://github.com/fastai/fastai/pull/3259)), thanks to [@MrRobot2211](https://github.com/MrRobot2211)\n- Fix custom tokenizers for DataLoaders ([#3256](https://github.com/fastai/fastai/pull/3256)), thanks to [@iskode](https://github.com/iskode)\n- fix error setting  'tok_tfm' parameter in TextDataloaders.from_folder\n- Fix lighting augmentation ([#3255](https://github.com/fastai/fastai/pull/3255)), thanks to [@kai-tub](https://github.com/kai-tub)\n- Fix CUDA variable serialization ([#3253](https://github.com/fastai/fastai/pull/3253)), thanks to [@mszhanyi](https://github.com/mszhanyi)\n- change batch tfms to have the correct dimensionality ([#3251](https://github.com/fastai/fastai/pull/3251)), thanks to [@trdvangraft](https://github.com/trdvangraft)\n- Ensure add_datepart adds elapsed as numeric column ([#3230](https://github.com/fastai/fastai/pull/3230)), thanks to [@aberres](https://github.com/aberres)\n\n\n## 2.3.0\n### Breaking Changes\n\n- fix optimwrapper to work with `param_groups` ([#3241](https://github.com/fastai/fastai/pull/3241)), thanks to [@tmabraham](https://github.com/tmabraham)\n  - OptimWrapper now has a different constructor signature, which makes it easier to wrap PyTorch optimizers\n\n### New Features\n\n- Support discriminative learning with OptimWrapper ([#2829](https://github.com/fastai/fastai/issues/2829))\n\n### Bugs Squashed\n\n- Updated to support adding transforms to multiple dataloaders ([#3268](https://github.com/fastai/fastai/pull/3268)), thanks to [@marii-moe](https://github.com/marii-moe)\n  - This fixes an issue in 2.2.7 which resulted in incorrect validation metrics when using Normalization\n\n\n## 2.2.7\n\n### Bugs Squashed\n\n- Regression fix: Ensure `add_datepart` adds elapsed as numeric column ([#3230](https://github.com/fastai/fastai/pull/3230)), thanks to [@aberres](https://github.com/aberres)\n\n\n## 2.2.6\n\n### Bugs Squashed\n\n- 2.2.5 was not released correctly - it was actually 2.2.3\n\n## 2.2.5\n\n### New Features\n\n- Enhancement: Let TextDataLoaders take in a custom `tok_text_col` ([#3208](https://github.com/fastai/fastai/pull/3208)), thanks to [@muellerzr](https://github.com/muellerzr)\n- Changed dataloaders arguments to have consistent overrides ([#3178](https://github.com/fastai/fastai/pull/3178)), thanks to [@marii-moe](https://github.com/marii-moe)\n- Better support for iterable datasets ([#3173](https://github.com/fastai/fastai/pull/3173)), thanks to [@jcaw](https://github.com/jcaw)\n\n### Bugs Squashed\n\n- BrokenProcessPool in `download_images()` on Windows ([#3196](https://github.com/fastai/fastai/issues/3196))\n- error on predict() or using interp with resnet and MixUp ([#3180](https://github.com/fastai/fastai/issues/3180))\n- Fix 'cat' attribute with pandas dataframe: `AttributeError: Can only use .cat accessor with a 'category' dtype` ([#3165](https://github.com/fastai/fastai/pull/3165)), thanks to [@dreamflasher](https://github.com/dreamflasher)\n- `cont_cat_split` does not support pandas types ([#3156](https://github.com/fastai/fastai/issues/3156))\n- `DataBlock.dataloaders` does not support the advertised \"shuffle\" argument ([#3133](https://github.com/fastai/fastai/issues/3133))\n\n\n## 2.2.3\n\n### New Features\n\n- Calculate correct `nf` in `create_head` based on `concat_pool` ([#3115](https://github.com/fastai/fastai/pull/3115)), thanks to [@muellerzr](https://github.com/muellerzr)\n\n### Bugs Squashed\n\n- wandb integration failing with latest wandb library ([#3066](https://github.com/fastai/fastai/issues/3066))\n- `Learner.load` and `LRFinder` not functioning properly for the optimizer states ([#2892](https://github.com/fastai/fastai/issues/2892))\n\n\n## 2.2.2\n\n### Bugs Squashed\n\n- tensorboard and wandb can not access `smooth_loss` ([#3131](https://github.com/fastai/fastai/issues/3131))\n\n\n## 2.2.0\n### Breaking Changes\n\n- Promote `NativeMixedPrecision` to default `MixedPrecision` (and similar for `Learner.to_fp16`); old `MixedPrecision` is now called `NonNativeMixedPrecision` ([#3127](https://github.com/fastai/fastai/issues/3127))\n  - Use the new `GradientClip` callback instead of the `clip` parameter to use gradient clipping\n- Adding a `Callback` which has the same name as an attribute no longer raises an exception ([#3109](https://github.com/fastai/fastai/issues/3109))\n- RNN training now requires `RNNCallback`, but does not require `RNNRegularizer`; `out` and `raw_out` have moved to `RNNRegularizer` ([#3108](https://github.com/fastai/fastai/issues/3108))\n  - Call `rnn_cbs` to get all callbacks needed for RNN training, optionally with regularization\n- replace callback `run_after` with `order`; do not run `after` cbs on exception ([#3101](https://github.com/fastai/fastai/issues/3101))\n\n### New Features\n\n- Add `GradientClip` callback ([#3107](https://github.com/fastai/fastai/issues/3107))\n- Make `Flatten` cast to `TensorBase` to simplify type compatibility ([#3106](https://github.com/fastai/fastai/issues/3106))\n- make flattened metrics compatible with all tensor subclasses ([#3105](https://github.com/fastai/fastai/issues/3105))\n- New class method `TensorBase.register_func` to register types for `__torch_function__` ([#3097](https://github.com/fastai/fastai/issues/3097))\n- new `dynamic` flag for controlling dynamic loss scaling in `NativeMixedPrecision` ([#3096](https://github.com/fastai/fastai/issues/3096))\n- remove need to call `to_native_fp32` before `predict`; set `skipped` in NativeMixedPrecision after NaN from dynamic loss scaling ([#3095](https://github.com/fastai/fastai/issues/3095))\n- make native fp16 extensible with callbacks ([#3094](https://github.com/fastai/fastai/issues/3094))\n- Calculate correct `nf` in `create_head` based on `concat_pool` ([#3115](https://github.com/fastai/fastai/pull/3115)) thanks to [@muellerzr](https://github.com/muellerzr)\n\n\n## 2.1.10\n\n### New Features\n\n- Small DICOM segmentation dataset ([#3034](https://github.com/fastai/fastai/pull/3034)), thanks to [@moritzschwyzer](https://github.com/moritzschwyzer)\n\n### Bugs Squashed\n\n- `NoneType object has no attribute append` in fastbook chapter 6 BIWI example ([#3091](https://github.com/fastai/fastai/issues/3091))\n\n\n## 2.1.9\n\n### New Features\n\n- Refactor MixUp and CutMix into MixHandler ([#3037](https://github.com/fastai/fastai/pull/3037)), thanks to [@muellerzr](https://github.com/muellerzr)\n  - Refactors into a general MixHandler class, with MixUp and CutMix simply implementing a `before_batch` to perform the data augmentation. See `fastai.callback.mixup`\n\n### Bugs Squashed\n\n- Gradient Accumulation + Mixed Precision shows artificially high training loss ([#3048](https://github.com/fastai/fastai/issues/3048))\n\n\n## 2.1.8\n\n### New Features\n\n### Bugs Squashed\n\n- Update for fastcore `negate_func`->`not_`\n- LR too high for gradient accumulation ([#3040](https://github.com/fastai/fastai/pull/3040)), thanks to [@marii-moe](https://github.com/marii-moe)\n- Torchscript transforms incompatibility with nn.Sequential ([#2920](https://github.com/fastai/fastai/issues/2920))\n\n\n## 2.1.7\n\n### New Features\n\n- Pytorch 1.7 subclassing support ([#2769](https://github.com/fastai/fastai/issues/2769))\n\n### Bugs Squashed\n\n- unsupported operand type(s) for +=: 'TensorCategory' and 'TensorText' when using AWD_LSTM for text classification ([#3027](https://github.com/fastai/fastai/issues/3027))\n- UserWarning when using SaveModelCallback() on after_epoch ([#3025](https://github.com/fastai/fastai/issues/3025))\n- Segmentation error: no implementation found for 'torch.nn.functional.cross_entropy' on types that implement torch_function ([#3022](https://github.com/fastai/fastai/issues/3022))\n- `TextDataLoaders.from_df()` returns `TypeError: 'float' object is not iterable` ([#2978](https://github.com/fastai/fastai/issues/2978))\n- Internal assert error in awd_qrnn ([#2967](https://github.com/fastai/fastai/issues/2967))\n\n\n## 2.1.6\n\n### New Features\n\n- Option to preserve filenames in `download_images` ([#2983](https://github.com/fastai/fastai/pull/2983)), thanks to [@mess-lelouch](https://github.com/mess-lelouch)\n- Deprecate `config` in `create_cnn` and instead pass kwargs directly ([#2966](https://github.com/fastai/fastai/pull/2966)), thanks to [@borisdayma](https://github.com/borisdayma)\n\n### Bugs Squashed\n\n- Progress and Recorder callbacks serialize their data, resulting in large Learner export file sizes ([#2981](https://github.com/fastai/fastai/issues/2981))\n- `TextDataLoaders.from_df()` returns `TypeError: 'float' object is not iterable` ([#2978](https://github.com/fastai/fastai/issues/2978))\n- \"only one element tensors can be converted to Python scalars\" exception in Siamese Tutorial ([#2973](https://github.com/fastai/fastai/issues/2973))\n- Learn.load and LRFinder not functioning properly for the optimizer states ([#2892](https://github.com/fastai/fastai/issues/2892))\n\n\n## 2.1.5\n\n### Breaking Changes\n\n- remove `log_args` ([#2954](https://github.com/fastai/fastai/issues/2954))\n\n### New Features\n\n- Improve performance of `RandomSplitter` (h/t @muellerzr) ([#2957](https://github.com/fastai/fastai/issues/2957))\n\n### Bugs Squashed\n\n- Exporting TabularLearner via learn.export() leads to huge file size ([#2945](https://github.com/fastai/fastai/issues/2945))\n- `TensorPoint` object has no attribute `img_size` ([#2950](https://github.com/fastai/fastai/issues/2950))\n\n\n## 2.1.4\n\n### Breaking Changes\n\n- moved `has_children` from `nn.Module` to free function ([#2931](https://github.com/fastai/fastai/issues/2931))\n\n### New Features\n\n- Support persistent workers ([#2768](https://github.com/fastai/fastai/issues/2768))\n\n### Bugs Squashed\n\n- `unet_learner` segmentation fails ([#2939](https://github.com/fastai/fastai/issues/2939))\n- In \"Transfer learning in text\" tutorial, the \"dls.show_batch()\" show wrong outputs ([#2910](https://github.com/fastai/fastai/issues/2910))\n- `Learn.load` and `LRFinder` not functioning properly for the optimizer states ([#2892](https://github.com/fastai/fastai/issues/2892))\n- Documentation for `Show_Images` broken ([#2876](https://github.com/fastai/fastai/issues/2876))\n- URL link for documentation for `torch_core` library from the `doc()` method gives incorrect url ([#2872](https://github.com/fastai/fastai/issues/2872))\n\n\n## 2.1.3\n\n### Bugs Squashed\n\n- Work around broken PyTorch subclassing of some `new_*` methods ([#2769](https://github.com/fastai/fastai/issues/2769))\n\n\n## 2.1.0\n\n### New Features\n\n- PyTorch 1.7 compatibility ([#2917](https://github.com/fastai/fastai/issues/2917))\n\nPyTorch 1.7 includes support for tensor subclassing, so we have replaced much of our custom subclassing code with PyTorch's. We have seen a few bugs in PyTorch's subclassing feature, however, so please file an issue if you see any code failing now which was working before.\n\nThere is one breaking change in this version of fastai, which is that custom metadata is now stored directly in tensors as standard python attributes, instead of in the special `_meta` attribute. Only advanced customization of fastai OO tensors would have used this functionality, so if you do not know what this all means, then it means you did not use it.\n\n\n## 2.0.19\n\nThis version was released *after* `2.1.0`, and adds fastcore 1.3 compatibility, whilst maintaining PyTorch 1.6 compatibility. It has no new features or bug fixes.\n\n\n## 2.0.18\n\n### Forthcoming breaking changes\n\nThe next version of fastai will be 2.1. It will require PyTorch 1.7, which has significant foundational changes. It should not require any code changes except for people doing sophisticated tensor subclassing work, but nonetheless we recommend testing carefully. Therefore, we recommend pinning your fastai version to `<2.1` if you are not able to fully test your fastai code when the new version comes out.\n\n### Dependencies\n\n- pin pytorch (`<1.7`) and torchvision (`<0.8`) requirements ([#2915](https://github.com/fastai/fastai/issues/2915))\n- Add version pin for fastcore\n- Remove version pin for sentencepiece\n\n\n## 2.0.16\n\n### New Features\n\n- added support for tb projector word embeddings ([#2853](https://github.com/fastai/fastai/pull/2853)), thanks to [@floleuerer](https://github.com/floleuerer)\n- Added ability to have variable length draw ([#2845](https://github.com/fastai/fastai/pull/2845)), thanks to [@marii-moe](https://github.com/marii-moe)\n- add pip upgrade cell to all notebooks, to ensure colab has current fastai version ([#2843](https://github.com/fastai/fastai/issues/2843))\n\n### Bugs Squashed\n\n- fix TabularDataLoaders inference of cont_names to keep y_names separate ([#2859](https://github.com/fastai/fastai/pull/2859)), thanks to [@sutt](https://github.com/sutt)\n\n\n## 2.0.15\n\n### Breaking Changes\n\n- loss functions were moved to `loss.py` ([#2843](https://github.com/fastai/fastai/pull/2810))\n\n\n## 2.0.14\n\n### New Features\n\n- new callback event: `after_create` ([#2842](https://github.com/fastai/fastai/issues/2842))\n  - This event runs after a `Learner` is constructed. It's useful for initial setup which isn't needed for every `fit`, but just once for each `Learner` (such as setting initial defaults).\n\n- Modified XResNet to support Conv1d / Conv3d ([#2744](https://github.com/fastai/fastai/pull/2744)), thanks to [@floleuerer](https://github.com/floleuerer)\n  - Supports different input dimensions, kernel sizes and stride (added parameters ndim, ks, stride). Tested with fastai_audio and fastai time series with promising results.\n\n### Bugs Squashed\n\n- `img_size` attribute for `TensorPoint` is not updated properly ([#2799](https://github.com/fastai/fastai/pull/2799)), thanks to [@IRailean](https://github.com/IRailean)\n\n## 2.0.13\n\n### Bugs Squashed\n\n- Undo breaking num_workers fix ([#2804](https://github.com/fastai/fastai/pull/2804))\n  - Some users found the recent addition of `num_workers` to inference\n    functions was causing problems, particularly on Windows. This PR\n    reverts that change, until we find a more reliable way to handle\n    `num_workers` for inference.\n- learn.tta() fails on a learner imported with load_learner() ([#2764](https://github.com/fastai/fastai/issues/2764))\n- learn.summary() crashes out on 2nd transfer learning ([#2735](https://github.com/fastai/fastai/issues/2735))\n\n## 2.0.12\n\n### Bugs Squashed\n\n- Undo breaking `num_workers` fix ([#2804](https://github.com/fastai/fastai/pull/2804))\n\n## 2.0.11\n\n### Bugs Squashed\n\n- Fix `cont_cat_split` for multi-label classification ([#2759](https://github.com/fastai/fastai/issues/2759))\n- fastbook error: \"index 3 is out of bounds for dimension 0 with size 3\" ([#2792](https://github.com/fastai/fastai/issues/2792))\n\n## 2.0.10\n\n### New Features\n\n- update for fastcore 1.0.5 ([#2775](https://github.com/fastai/fastai/issues/2775))\n\n## 2.0.6\n\n### New Features\n\n- \"Remove pandas min version requirement\" ([#2765](https://github.com/fastai/fastai/issues/2765))\n- Modify XResNet to support Conv1d / Conv3d ([#2744](https://github.com/fastai/fastai/issues/2744))\n  - Also support different input dimensions, kernel sizes and stride (added parameters ndim, ks, stride).\n- Add support for multidimensional arrays for RNNDropout ([#2737](https://github.com/fastai/fastai/issues/2737))\n- MCDropoutCallback to enable Monte Carlo Dropout in fastai. ([#2733](https://github.com/fastai/fastai/issues/2733))\n  - A new callback to enable Monte Carlo Dropout in fastai in the `get_preds` method.\n    Monte Carlo Dropout is simply enabling dropout during inference.\n    Calling get_preds multiple times and stacking them yield of a distribution of predictions that you can use to evaluate your prediction uncertainty.\n- adjustable workers in `get_preds` ([#2721](https://github.com/fastai/fastai/issues/2721))\n\n## Version 2.0.0\n\n- Initial release of v2\n\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.29,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\neducation, socio-economic status, nationality, personal appearance, race,\nreligion, or sexual identity and orientation.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n\nThese examples of unacceptable behaviour are requirements; we will not allow them\nin any fast.ai project, including this one.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nThese examples are shown only to help you participate effectively -- they are not\nrequirements, just requests and guidance.\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing or otherwise unacceptable behavior may be\nreported by contacting the project team at info@fast.ai. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 9.16,
          "content": "# How to contribute to fastai\n\nFirst, thanks a lot for wanting to help! Make sure you have read the [doc on code style](\nhttps://docs.fast.ai/dev/style.html) first. (Note that we don't follow PEP8, but instead follow a coding style designed specifically for numerical and interactive programming.) For help running and building the code, see the [developers guide](https://docs.fast.ai/dev/develop.html).\n\n## Note for new contributors from Jeremy\n\nIt can be tempting to jump into a new project by questioning the stylistic decisions that have been made, such as naming, formatting, and so forth. This can be especially so for python programmers contributing to this project, which is unusual in following a number of conventions that are common in other programming communities, but not in Python. However, please don’t do this, for (amongst others) the following reasons:\n\n- Contributing to [Parkinson’s law of triviality](https://www.wikiwand.com/en/Law_of_triviality) has negative consequences for a project. Let’s focus on deep learning!\n- It’s exhausting to repeat the same discussion over and over again, especially when it’s been well documented already. When you have a question about the project, please check the pages in the docs website linked here.\n- You’re likely to get a warmer welcome from the community if you start out by contributing something that’s been requested on the forum, since you’ll be solving someone’s current problem.\n- If you start out by just telling us your point of view, rather than studying the background behind the decisions that have been made, you’re unlikely to be contributing anything new or useful.\n- I’ve been writing code for nearly 40 years now, across dozens of languages, and other folks involved have quite a bit of experience too - the approaches used are based on significant experience and research. Whilst there’s always room for improvement, it’s much more likely you’ll be making a positive contribution if you spend a few weeks studying and working within the current framework before suggesting wholesale changes.\n\n## How to get started\n\nHere are some ways that you can learn a lot about the library, whilst also contributing to the community:\n\n- Pick a class, function, or method and write tests for it. For instance, here are the tests for [fastai.core](https://github.com/fastai/fastai1/blob/master/tests/test_core.py). Adding tests for anything without good test coverage is a great way to really understand that part of the library deeply, and have in-depth conversations with the dev team about the reasoning behind decisions in the code.\n- Document something that is currently undocumented. You can find them by looking for the “new methods” section in any doc notebook. Here’s a [search](https://github.com/fastai/fastai/search?q=%22new+methods%22&unscoped_q=%22new+methods%22) that lists them\n- Add an example of use to the docs for something that doesn’t currently have an example of use. We’d like everything soon in the docs to include an actual piece of working code demonstrating it. Currently, we’ve largely only provided working examples for stuff higher up the abstraction ladder.\n\n## Did you find a bug?\n\n* Nobody is perfect, especially not us. But first, please double-check the bug doesn't come from something on your side. The [forum](http://forums.fast.ai/) is a tremendous source for help, and we'd advise to use it as a first step. Be sure to include as much code as you can so that other people can easily help you.\n* Then, ensure the bug was not already reported by searching on GitHub under [Issues](https://github.com/fastai/fastai/issues).\n* If you're unable to find an open issue addressing the problem, [open a new one](https://github.com/fastai/fastai/issues/new). Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\n* Be sure to add the complete error messages as well as the result of the line `import fastai.test_utils; fastai.test_utils.show_install(1)`.\n\n#### Did you write a patch that fixes a bug?\n\n* Open a new GitHub pull request with the patch.\n* Ensure that your PR includes tests that fail without your patch, and pass with it.\n* Ensure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n* Before submitting, please be sure you abide by our [coding style](https://docs.fast.ai/dev/style.html) and [the guide on abbreviations](https://docs.fast.ai/dev/abbr.html) and clean-up your code accordingly.\n\n## Do you intend to add a new feature or change an existing one?\n\n* You can suggest your change on the [fastai forum](http://forums.fast.ai/) to see if others are interested or want to help. [This topic](http://forums.fast.ai/t/fastai-v1-adding-features/23041/8) lists the features that will be added to fastai in the foreseeable future. Be sure to read it too!\n* Before implementing a non-trivial new feature, first create a notebook version of your new feature, like those in [dev_nb](https://github.com/fastai/fastai_docs/tree/master/dev_nb). It should show step-by-step what your code is doing, and why, with the result of each step. Try to simplify the code as much as possible. When you're happy with it, let us know on the forum (include a link to gist with your notebook.)\n* Once your approach has been discussed and confirmed on the forum, you are welcome to push a PR, including a complete description of the new feature and an example of how it's used. Be sure to document your code and read the [doc on code style](https://docs.fast.ai/dev/style.html) and [the one on abbreviations](https://docs.fast.ai/dev/abbr.html).\n* Ensure that your PR includes tests that exercise not only your feature, but also any other code that might be impacted. Currently we have poor test coverage of existing features, so often you'll need to add tests of existing code. Your help here is much appreciated!\n\n## How to submit notebook PRs?\n\nPlease run [`nbdev_install_hooks`](https://nbdev.fast.ai/api/clean.html#nbdev_install_hooks) in your terminal after cloning the repository. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.\n\nIf you made a change to the notebooks in one of the exported cells, you can export it to the library with [`nbdev_export`](https://nbdev.fast.ai/api/doclinks.html#nbdev_export).\nIf you made a change to the library, you can export it back to the notebooks with [`nbdev_update`](https://nbdev.fast.ai/api/sync.html#nbdev_update).\n\nFurthermore, you can run tests in parallel by launching [`nbdev_test`](https://nbdev.fast.ai/api/test.html#nbdev_test).\n\nIf you'd like to learn the nbdev commands available and more about the project, please visit [`the docs`](https://nbdev.fast.ai/getting_started.html#how-to-use-nbdev).\n\n\n## PR submission guidelines\n\n* Keep each PR focused. While it's more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\n\n* Do not mix style changes/fixes with \"functional\" changes. It's very difficult to review such PRs and it most likely get rejected.\n\n* Do not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\n\n* Do not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\n\n* If, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won't need to review the whole PR again. In the exception case where you realize it'll take many many commits to complete the requests, then it's probably best to close the PR, do the work and then submit it again. Use common sense where you'd choose one way over another.\n\n\n### Code PRs\n\n* If your PR is a bug fix, please also include a test that demonstrates the problem, or modifies an existing test that wasn't catching that problem already. Of course, it's not a requirement, so proceed anyway if you can't figure out how to write a test, but do try. Without having a test your fix could be lost down the road. By supplying a test, you're ensuring that your projects won't break in the future.\n\n* Same applies for PRs that implement new features - without having a test case validating this new feature, it'd be very easy for that new feature to break in the future. A test case ensures that the feature will not break.\n\n\n## Do you have questions about the source code?\n\n* Please ask it on the [fastai forum](http://forums.fast.ai/) (after searching someone didn't ask the same one before with a quick search). We'd rather have the maximum of discussions there so that the largest number can benefit from it.\n\n## Do you want to contribute to the documentation?\n\n* Docs are automatically created from the notebooks in the `/nbs` directory.\n* To switch the `docs` submodule to ssh, `cd docs && git remote set-url origin git@github.com:fastai/fastai-docs.git`\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.17,
          "content": "include settings.ini\ninclude CONTRIBUTING.md\ninclude LICENSE\ninclude README.md\ninclude fastai/text/models/*.cu\ninclude fastai/text/models/*.cpp\n\nrecursive-exclude * __pycache__\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.7,
          "content": "# Welcome to fastai\n\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\n\n[![CI](https://github.com/fastai/fastai/actions/workflows/main.yml/badge.svg)](https://github.com/fastai/fastai/actions/workflows/main.yml)\n[![PyPI](https://img.shields.io/pypi/v/fastai?color=blue&label=pypi%20version.png)](https://pypi.org/project/fastai/#description)\n[![Conda (channel\nonly)](https://img.shields.io/conda/vn/fastai/fastai?color=seagreen&label=conda%20version.png)](https://anaconda.org/fastai/fastai)\n![docs](https://github.com/fastai/fastai/workflows/docs/badge.svg)\n\n## Installing\n\nYou can use fastai without any installation by using [Google\nColab](https://colab.research.google.com/). In fact, every page of this\ndocumentation is also available as an interactive notebook - click “Open\nin colab” at the top of any page to open it (be sure to change the Colab\nruntime to “GPU” to have it run fast!) See the fast.ai documentation on\n[Using Colab](https://course.fast.ai/start_colab) for more information.\n\nYou can install fastai on your own machines with conda (highly\nrecommended), as long as you’re running Linux or Windows (NB: Mac is not\nsupported). For Windows, please see the “Running on Windows” for\nimportant notes.\n\nWe recommend using\n[miniconda](https://docs.conda.io/en/latest/miniconda.html) (or\nminiforge). First install PyTorch using the conda line shown\n[here](https://pytorch.org/get-started/locally/), and then run:\n\n``` bash\nconda install -c fastai fastai\n```\n\nTo install with pip, use: `pip install fastai`.\n\nIf you plan to develop fastai yourself, or want to be on the cutting\nedge, you can use an editable install (if you do this, you should also\nuse an editable install of\n[fastcore](https://github.com/fastai/fastcore) to go with it.) First\ninstall PyTorch, and then:\n\n    git clone https://github.com/fastai/fastai\n    pip install -e \"fastai[dev]\"\n\n## Learning fastai\n\nThe best way to get started with fastai (and deep learning) is to read\n[the\nbook](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527),\nand complete [the free course](https://course.fast.ai).\n\nTo see what’s possible with fastai, take a look at the [Quick\nStart](https://docs.fast.ai/quick_start.html), which shows how to use\naround 5 lines of code to build an image classifier, an image\nsegmentation model, a text sentiment model, a recommendation system, and\na tabular model. For each of the applications, the code is much the\nsame.\n\nRead through the [Tutorials](https://docs.fast.ai/tutorial.html) to\nlearn how to train your own models on your own datasets. Use the\nnavigation sidebar to look through the fastai documentation. Every\nclass, function, and method is documented here.\n\nTo learn about the design and motivation of the library, read the [peer\nreviewed paper](https://www.mdpi.com/2078-2489/11/2/108/htm).\n\n## About fastai\n\nfastai is a deep learning library which provides practitioners with\nhigh-level components that can quickly and easily provide\nstate-of-the-art results in standard deep learning domains, and provides\nresearchers with low-level components that can be mixed and matched to\nbuild new approaches. It aims to do both things without substantial\ncompromises in ease of use, flexibility, or performance. This is\npossible thanks to a carefully layered architecture, which expresses\ncommon underlying patterns of many deep learning and data processing\ntechniques in terms of decoupled abstractions. These abstractions can be\nexpressed concisely and clearly by leveraging the dynamism of the\nunderlying Python language and the flexibility of the PyTorch library.\nfastai includes:\n\n- A new type dispatch system for Python along with a semantic type\n  hierarchy for tensors\n- A GPU-optimized computer vision library which can be extended in pure\n  Python\n- An optimizer which refactors out the common functionality of modern\n  optimizers into two basic pieces, allowing optimization algorithms to\n  be implemented in 4–5 lines of code\n- A novel 2-way callback system that can access any part of the data,\n  model, or optimizer and change it at any point during training\n- A new data block API\n- And much more…\n\nfastai is organized around two main design goals: to be approachable and\nrapidly productive, while also being deeply hackable and configurable.\nIt is built on top of a hierarchy of lower-level APIs which provide\ncomposable building blocks. This way, a user wanting to rewrite part of\nthe high-level API or add particular behavior to suit their needs does\nnot have to learn how to use the lowest level.\n\n<img alt=\"Layered API\" src=\"images/layered.png\" width=\"345\">\n\n## Migrating from other libraries\n\nIt’s very easy to migrate from plain PyTorch, Ignite, or any other\nPyTorch-based library, or even to use fastai in conjunction with other\nlibraries. Generally, you’ll be able to use all your existing data\nprocessing code, but will be able to reduce the amount of code you\nrequire for training, and more easily take advantage of modern best\npractices. Here are migration guides from some popular libraries to help\nyou on your way:\n\n- [Plain PyTorch](https://docs.fast.ai/examples/migrating_pytorch.html)\n- [Ignite](https://docs.fast.ai/examples/migrating_ignite.html)\n- [Lightning](https://docs.fast.ai/examples/migrating_lightning.html)\n- [Catalyst](https://docs.fast.ai/examples/migrating_catalyst.html)\n\n## Windows Support\n\nDue to python multiprocessing issues on Jupyter and Windows,\n`num_workers` of `Dataloader` is reset to 0 automatically to avoid\nJupyter hanging. This makes tasks such as computer vision in Jupyter on\nWindows many times slower than on Linux. This limitation doesn’t exist\nif you use fastai from a script.\n\nSee [this\nexample](https://github.com/fastai/fastai/blob/master/nbs/examples/dataloader_spawn.py)\nto fully leverage the fastai API on Windows.\n\nWe recommend using Windows Subsystem for Linux (WSL) instead – if you do\nthat, you can use the regular Linux installation approach, and you won’t\nhave any issues with `num_workers`.\n\n## Tests\n\nTo run the tests in parallel, launch:\n\n`nbdev_test`\n\nFor all the tests to pass, you’ll need to install the dependencies\nspecified as part of dev_requirements in settings.ini\n\n`pip install -e .[dev]`\n\nTests are written using `nbdev`, for example see the documentation for\n`test_eq`.\n\n## Contributing\n\nAfter you clone this repository, make sure you have run\n`nbdev_install_hooks` in your terminal. This install Jupyter and git\nhooks to automatically clean, trust, and fix merge conflicts in\nnotebooks.\n\nAfter making changes in the repo, you should run `nbdev_prepare` and\nmake additional and necessary changes in order to pass all the tests.\n\n## Docker Containers\n\nFor those interested in official docker containers for this project,\nthey can be found\n[here](https://github.com/fastai/docker-containers#fastai).\n"
        },
        {
          "name": "dev_nbs",
          "type": "tree",
          "content": null
        },
        {
          "name": "disabled",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 1.25,
          "content": "version: \"3\"\nservices:\n  fastai: &fastai\n    restart: unless-stopped\n    working_dir: /data\n    image: fastai/codespaces\n    logging:\n      driver: json-file\n      options:\n        max-size: 50m\n    stdin_open: true\n    tty: true\n    volumes:\n      - .:/data/\n    environment:\n#      - LIB_INSTALL_TYPE=.[dev] && pip install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu --upgrade #optionally change this locally to .[dev] and install nighty torch\n      - LIB_INSTALL_TYPE=. #optionally change this locally to .[dev] to install dev packages as well\n\n  notebook:\n    <<: *fastai\n    command: bash -c \"pip install -e $$LIB_INSTALL_TYPE && jupyter notebook --allow-root --no-browser --ip=0.0.0.0 --port=8080 --NotebookApp.token='' --NotebookApp.password=''\"\n    ports:\n      - \"8080:8080\"\n\n  watcher:\n    <<: *fastai\n    command: watchmedo shell-command --command nbdev_build_docs --pattern *.ipynb --recursive --drop\n    network_mode: host # for GitHub Codespaces https://github.com/features/codespaces/\n\n  jekyll:\n    <<: *fastai\n    ports:\n     - \"4000:4000\"\n    command: >\n     bash -c \"cp -r docs_src docs\n     && pip install $$LIB_INSTALL_TYPE\n     && nbdev_build_docs && cd docs\n     && bundle i\n     && bundle exec jekyll serve --host 0.0.0.0\"\n"
        },
        {
          "name": "download_checks.py",
          "type": "blob",
          "size": 1.54,
          "content": "{'https://s3.amazonaws.com/fast-ai-imageclas/caltech_101.tgz': (131740031,\n                                                                'd673425306e98ee4619fcdeef8a0e876'),\n 'https://s3.amazonaws.com/fast-ai-imagelocal/biwi_head_pose.tgz': (452316199,\n                                                                    '00f4ccf66e8cba184bc292fdc08fb237'),\n 'https://s3.amazonaws.com/fast-ai-imagelocal/camvid.tgz': (598913237,\n                                                            '648371e4f3a833682afb39b08a3ce2aa'),\n 'https://s3.amazonaws.com/fast-ai-nlp/ag_news_csv.tgz': (11784419,\n                                                          'b86f328f4dbd072486591cb7a5644dcd'),\n 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_full_csv.tgz': (71606272,\n                                                                     '4a1196cf0adaea22f4bc3f592cddde90'),\n 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz': (688339454,\n                                                                         '676f7e5208ec343c8274b4bb085bc938'),\n 'https://s3.amazonaws.com/fast-ai-sample/adult_sample.tgz': (968212,\n                                                              '64eb9d7e23732de0b138f7372d15492f'),\n 'https://s3.amazonaws.com/fast-ai-sample/biwi_sample.tgz': (593774,\n                                                             '9179f4c1435f4b291f0d5b072d60c2c9'),\n 'https://s3.amazonaws.com/fast-ai-sample/camvid_tiny.tgz': (2314212,\n                                                             '2cf6daf91b7a2083ecfa3e9968e9d915')}"
        },
        {
          "name": "environment.yml",
          "type": "blob",
          "size": 0.25,
          "content": "name: fastai\nchannels:\n- fastai\n- pytorch\n- defaults\ndependencies:\n- fastcore>=1.5.29\n- torchvision>=0.11\n- matplotlib\n- pandas>=1.0.0\n- requests\n- pyyaml\n- fastprogress>=0.2.4\n- pillow>=9.0.0\n- scikit-learn\n- scipy\n- spacy\n- pytorch>=1.10.0\n- fastdownload\n"
        },
        {
          "name": "fastai",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "nbs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.08,
          "content": "[build-system]\nrequires = [\"setuptools>=64.0\"]\nbuild-backend = \"setuptools.build_meta\"\n"
        },
        {
          "name": "settings.ini",
          "type": "blob",
          "size": 1.48,
          "content": "[DEFAULT]\nlib_name = fastai\nuser = fastai\nrepo = fastai\nbranch = master\nversion = 2.7.18\ndescription = fastai simplifies training fast and accurate neural nets using modern best practices\nkeywords = fastai, deep learning, machine learning\nauthor = Jeremy Howard, Sylvain Gugger, and contributors\nauthor_email = info@fast.ai\nlicense = apache2\ncopyright = fast.ai\nstatus = 4\nmin_python = 3.9\naudience = Developers\nlanguage = English\nrequirements = fastdownload>=0.0.5,<2 fastcore>=1.5.29,<1.8 torchvision>=0.11 matplotlib pandas requests pyyaml fastprogress>=0.2.4 pillow>=9.0.0 scikit-learn scipy spacy<4 packaging\npip_requirements = torch>=1.10,<2.6\nconda_requirements = pytorch>=1.10,<2.6\nconda_user = fastai\ndev_requirements = ipywidgets lightning pytorch-ignite transformers sentencepiece tensorboard pydicom catalyst flask_compress captum>=0.4.1 flask wandb kornia scikit-image comet_ml albumentations opencv-python pyarrow ninja timm>=0.9 accelerate>=0.21 ipykernel\nconsole_scripts = configure_accelerate=fastai.distributed:configure_accelerate\nnbs_path = nbs\ndoc_path = _docs\ngit_url = https://github.com/fastai/fastai\nlib_path = fastai\ntitle = fastai\ntst_flags = slow cpp cuda multicuda\ncustom_sidebar = True\ndoc_host = https://docs.fast.ai\ndoc_baseurl = /\nhost = github\nrecursive = True\nclean_ids = False\nblack_formatting = False\nreadme_nb = index.ipynb\nallowed_metadata_keys = \nallowed_cell_metadata_keys = \njupyter_hooks = True\nclear_all = False\nput_version_in_init = True\ncell_number = True\nskip_procs = \n\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.77,
          "content": "from pkg_resources import parse_version\nfrom configparser import ConfigParser\nimport setuptools,re,sys\nassert parse_version(setuptools.__version__)>=parse_version('36.2')\n\n# note: all settings are in settings.ini; edit there, not here\nconfig = ConfigParser(delimiters=['='])\nconfig.read('settings.ini')\ncfg = config['DEFAULT']\n\ncfg_keys = 'version description keywords author author_email'.split()\nexpected = cfg_keys + \"lib_name user branch license status min_python audience language\".split()\nfor o in expected: assert o in cfg, \"missing expected setting: {}\".format(o)\nsetup_cfg = {o:cfg[o] for o in cfg_keys}\n\nif len(sys.argv)>1 and sys.argv[1]=='version':\n    print(setup_cfg['version'])\n    exit()\n\nlicenses = {\n    'apache2': ('Apache Software License 2.0','OSI Approved :: Apache Software License'),\n}\nstatuses = [ '1 - Planning', '2 - Pre-Alpha', '3 - Alpha',\n    '4 - Beta', '5 - Production/Stable', '6 - Mature', '7 - Inactive' ]\npy_versions = '2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 3.0 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 3.10 3.11 3.12 3.13'.split()\nmin_python = cfg['min_python']\nlic = licenses[cfg['license']]\n\nrequirements = ['pip', 'packaging']\nif cfg.get('requirements'): requirements += cfg.get('requirements','').split()\nif cfg.get('pip_requirements'): requirements += cfg.get('pip_requirements','').split()\ndev_requirements = (cfg.get('dev_requirements') or '').split()\n\nlong_description = open('README.md', encoding='utf8').read()\n# ![png](docs/images/output_13_0.png)\nfor ext in ['png', 'svg']:\n    long_description = re.sub(r'!\\['+ext+'\\]\\((.*)\\)', '!['+ext+']('+'https://raw.githubusercontent.com/{}/{}'.format(cfg['user'],cfg['lib_name'])+'/'+cfg['branch']+'/\\\\1)', long_description)\n    long_description = re.sub(r'src=\\\"(.*)\\.'+ext+'\\\"', 'src=\\\"https://raw.githubusercontent.com/{}/{}'.format(cfg['user'],cfg['lib_name'])+'/'+cfg['branch']+'/\\\\1.'+ext+'\\\"', long_description)\n\nsetuptools.setup(\n    name = 'fastai',\n    license = lic[0],\n    classifiers = [\n        'Development Status :: ' + statuses[int(cfg['status'])],\n        'Intended Audience :: ' + cfg['audience'].title(),\n        'License :: ' + lic[1],\n        'Natural Language :: ' + cfg['language'].title(),\n    ] + ['Programming Language :: Python :: '+o for o in py_versions[py_versions.index(min_python):]],\n    url = cfg['git_url'],\n    packages = setuptools.find_packages(),\n    include_package_data = True,\n    install_requires = requirements,\n    extras_require={ 'dev': dev_requirements },\n    python_requires  = '>=' + cfg['min_python'],\n    long_description = long_description,\n    long_description_content_type = 'text/markdown',\n    zip_safe = False,\n    entry_points = {\n        'console_scripts': cfg.get('console_scripts','').split(),\n        'nbdev': [f'{cfg.get(\"lib_path\")}={cfg.get(\"lib_path\")}._modidx:d']\n    },\n    **setup_cfg)\n\n"
        },
        {
          "name": "test_settings.ini",
          "type": "blob",
          "size": 0.21,
          "content": "[DEFAULT]\nlib_name = fastai\nuser = fastai\nbranch = master\ngit_url = https://github.com/%(user)s/%(lib_name)s/tree/%(branch)s/\nlib_path = %(lib_name)s\nnbs_path = nbs\ndoc_path = docs\ntst_flags = tst\nversion = 0.0.1\n\n"
        }
      ]
    }
  ]
}