{
  "metadata": {
    "timestamp": 1736710159925,
    "page": 832,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dog-qiuqiu/MobileNet-Yolo",
      "stars": 1728,
      "defaultBranch": "master",
      "files": [
        {
          "name": "3rdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 19.5498046875,
          "content": "cmake_minimum_required(VERSION 3.8)\n\nset(Darknet_MAJOR_VERSION 0)\nset(Darknet_MINOR_VERSION 2)\nset(Darknet_PATCH_VERSION 5)\nset(Darknet_TWEAK_VERSION 1)\nset(Darknet_VERSION ${Darknet_MAJOR_VERSION}.${Darknet_MINOR_VERSION}.${Darknet_PATCH_VERSION}.${Darknet_TWEAK_VERSION})\n\noption(CMAKE_VERBOSE_MAKEFILE \"Create verbose makefile\" OFF)\noption(CUDA_VERBOSE_BUILD \"Create verbose CUDA build\" OFF)\noption(BUILD_SHARED_LIBS \"Create dark as a shared library\" ON)\noption(BUILD_AS_CPP \"Build Darknet using C++ compiler also for C files\" OFF)\noption(BUILD_USELIB_TRACK \"Build uselib_track\" ON)\noption(MANUALLY_EXPORT_TRACK_OPTFLOW \"Manually export the TRACK_OPTFLOW=1 define\" OFF)\noption(ENABLE_OPENCV \"Enable OpenCV integration\" ON)\noption(ENABLE_CUDA \"Enable CUDA support\" ON)\noption(ENABLE_CUDNN \"Enable CUDNN\" ON)\noption(ENABLE_CUDNN_HALF \"Enable CUDNN Half precision\" ON)\noption(ENABLE_ZED_CAMERA \"Enable ZED Camera support\" ON)\noption(ENABLE_VCPKG_INTEGRATION \"Enable VCPKG integration\" ON)\n\nif(ENABLE_VCPKG_INTEGRATION AND DEFINED ENV{VCPKG_ROOT} AND NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(CMAKE_TOOLCHAIN_FILE \"$ENV{VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake\" CACHE STRING \"\")\n  message(STATUS \"VCPKG found: $ENV{VCPKG_ROOT}\")\n  message(STATUS \"Using VCPKG integration\")\nendif()\n\nproject(Darknet VERSION ${Darknet_VERSION})\n\nif(WIN32 AND NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(USE_INTEGRATED_LIBS \"TRUE\" CACHE BOOL \"Use libs distributed with this repo\")\nelse()\n  set(USE_INTEGRATED_LIBS \"FALSE\" CACHE BOOL \"Use libs distributed with this repo\")\nendif()\n\nenable_language(C)\nenable_language(CXX)\n\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_MODULE_PATH \"${CMAKE_CURRENT_LIST_DIR}/cmake/Modules/\" ${CMAKE_MODULE_PATH})\n\nif (CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT)\n  set(CMAKE_INSTALL_PREFIX \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Install prefix\" FORCE)\nendif()\n\nset(INSTALL_BIN_DIR      \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Path where exe and dll will be installed\")\nset(INSTALL_LIB_DIR      \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Path where lib will be installed\")\nset(INSTALL_INCLUDE_DIR  \"include/darknet\"           CACHE PATH \"Path where headers will be installed\")\nset(INSTALL_CMAKE_DIR    \"share/darknet\"             CACHE PATH \"Path where cmake configs will be installed\")\n\nif(${CMAKE_VERSION} VERSION_LESS \"3.9.0\")\n  message(WARNING \"To build with CUDA support you need CMake 3.9.0+\")\n  set(ENABLE_CUDA \"FALSE\" CACHE BOOL \"Enable CUDA support\" FORCE)\nelse()\n  include(CheckLanguage)\n  check_language(CUDA)\n  if(CMAKE_CUDA_COMPILER AND ENABLE_CUDA)\n    set(CUDA_ARCHITECTURES \"Auto\" CACHE STRING \"\\\"Auto\\\" detects local machine GPU compute arch at runtime, \\\"Common\\\" and \\\"All\\\" cover common and entire subsets of architectures, \\\"Names\\\" is a list of architectures to enable by name, \\\"Numbers\\\" is a list of compute capabilities (version number) to enable\")\n    set_property(CACHE CUDA_ARCHITECTURES PROPERTY STRINGS \"Auto\" \"Common\" \"All\" \"Kepler Maxwell Kepler+Tegra Maxwell+Tegra Pascal\" \"3.0 7.5\")\n    enable_language(CUDA)\n    find_package(CUDA REQUIRED)\n    if(CUDA_VERSION VERSION_LESS \"9.0\")\n      message(STATUS \"Unsupported CUDA version, please upgrade to CUDA 9+. Disabling CUDA support\")\n      set(ENABLE_CUDA \"FALSE\" CACHE BOOL \"Enable CUDA support\" FORCE)\n    else()\n      cuda_select_nvcc_arch_flags(CUDA_ARCH_FLAGS ${CUDA_ARCHITECTURES})\n      message(STATUS \"Building with CUDA flags: \" \"${CUDA_ARCH_FLAGS}\")\n      if (NOT \"arch=compute_75,code=sm_75\" IN_LIST CUDA_ARCH_FLAGS)\n        set(ENABLE_CUDNN_HALF \"FALSE\" CACHE BOOL \"Enable CUDNN Half precision\" FORCE)\n        message(STATUS \"Your setup does not supports half precision (it requires CC >= 7.5)\")\n      endif()\n    endif()\n  else()\n    set(ENABLE_CUDA \"FALSE\" CACHE BOOL \"Enable CUDA support\" FORCE)\n  endif()\nendif()\n\nif (WIN32 AND ENABLE_CUDA AND CMAKE_MAKE_PROGRAM MATCHES \"ninja\")\n  option(SELECT_OPENCV_MODULES \"Use only few selected OpenCV modules to circumvent 8192 char limit when using Ninja on Windows\" ON)\nelse()\n  option(SELECT_OPENCV_MODULES \"Use only few selected OpenCV modules to circumvent 8192 char limit when using Ninja on Windows\" OFF)\nendif()\n\nif(USE_INTEGRATED_LIBS)\n  set(PThreads_windows_DIR ${CMAKE_CURRENT_LIST_DIR}/3rdparty/pthreads CACHE PATH \"Path where pthreads for windows can be located\")\nendif()\nset(Stb_DIR ${CMAKE_CURRENT_LIST_DIR}/3rdparty/stb CACHE PATH \"Path where Stb image library can be located\")\n\nset(CMAKE_DEBUG_POSTFIX d)\nset(CMAKE_THREAD_PREFER_PTHREAD ON)\nfind_package(Threads REQUIRED)\nif(MSVC)\n  find_package(PThreads_windows REQUIRED)\nendif()\nif(ENABLE_OPENCV)\n  find_package(OpenCV)\n  if(OpenCV_FOUND)\n    if(SELECT_OPENCV_MODULES)\n      if(TARGET opencv_world)\n        list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_world\")\n      else()\n        if(TARGET opencv_core)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_core\")\n        endif()\n        if(TARGET opencv_highgui)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_highgui\")\n        endif()\n        if(TARGET opencv_imgproc)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_imgproc\")\n        endif()\n        if(TARGET opencv_video)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_video\")\n        endif()\n        if(TARGET opencv_videoio)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_videoio\")\n        endif()\n        if(TARGET opencv_imgcodecs)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_imgcodecs\")\n        endif()\n        if(TARGET opencv_text)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_text\")\n        endif()\n      endif()\n    else()\n      list(APPEND OpenCV_LINKED_COMPONENTS ${OpenCV_LIBS})\n    endif()\n  endif()\nendif()\nfind_package(Stb REQUIRED)\nif(${CMAKE_VERSION} VERSION_LESS \"3.11.0\")\n  message(WARNING \"To build with OpenMP support you need CMake 3.11.0+\")\nelse()\n  find_package(OpenMP)\nendif()\n\nset(ADDITIONAL_CXX_FLAGS \"-Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -Wno-deprecated-declarations -Wno-write-strings\")\nset(ADDITIONAL_C_FLAGS \"-Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -Wno-deprecated-declarations -Wno-write-strings\")\n\nif(MSVC)\n  set(ADDITIONAL_CXX_FLAGS \"/wd4013 /wd4018 /wd4028 /wd4047 /wd4068 /wd4090 /wd4101 /wd4113 /wd4133 /wd4190 /wd4244 /wd4267 /wd4305 /wd4477 /wd4996 /wd4819 /fp:fast\")\n  set(ADDITIONAL_C_FLAGS \"/wd4013 /wd4018 /wd4028 /wd4047 /wd4068 /wd4090 /wd4101 /wd4113 /wd4133 /wd4190 /wd4244 /wd4267 /wd4305 /wd4477 /wd4996 /wd4819 /fp:fast\")\n  set(CMAKE_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} ${CMAKE_CXX_FLAGS}\")\n  set(CMAKE_C_FLAGS \"${ADDITIONAL_C_FLAGS} ${CMAKE_C_FLAGS}\")\n  string(REGEX REPLACE \"/O2\" \"/Ox\" CMAKE_CXX_FLAGS_RELEASE ${CMAKE_CXX_FLAGS_RELEASE})\n  string(REGEX REPLACE \"/O2\" \"/Ox\" CMAKE_C_FLAGS_RELEASE ${CMAKE_C_FLAGS_RELEASE})\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCC OR \"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n  if (\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n    if (UNIX AND NOT APPLE)\n      set(CMAKE_CXX_FLAGS \"-pthread ${CMAKE_CXX_FLAGS}\")  #force pthread to avoid bugs in some cmake setups\n      set(CMAKE_C_FLAGS \"-pthread ${CMAKE_C_FLAGS}\")\n    endif()\n  endif()\n  set(CMAKE_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} ${CMAKE_CXX_FLAGS}\")\n  set(CMAKE_C_FLAGS \"${ADDITIONAL_C_FLAGS} ${CMAKE_C_FLAGS}\")\n  string(REGEX REPLACE \"-O0\" \"-Og\" CMAKE_CXX_FLAGS_DEBUG ${CMAKE_CXX_FLAGS_DEBUG})\n  string(REGEX REPLACE \"-O3\" \"-Ofast\" CMAKE_CXX_FLAGS_RELEASE ${CMAKE_CXX_FLAGS_RELEASE})\n  string(REGEX REPLACE \"-O0\" \"-Og\" CMAKE_C_FLAGS_DEBUG ${CMAKE_C_FLAGS_DEBUG})\n  string(REGEX REPLACE \"-O3\" \"-Ofast\" CMAKE_C_FLAGS_RELEASE ${CMAKE_C_FLAGS_RELEASE})\n  set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\")\n  set(CMAKE_C_FLAGS_RELEASE \"${CMAKE_C_FLAGS_RELEASE} -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\")\nendif()\n\nif(OpenCV_FOUND)\n  if(ENABLE_CUDA AND NOT OpenCV_CUDA_VERSION)\n    set(BUILD_USELIB_TRACK \"FALSE\" CACHE BOOL \"Build uselib_track\" FORCE)\n    message(STATUS \"  ->  darknet is fine for now, but uselib_track has been disabled!\")\n    message(STATUS \"  ->  Please rebuild OpenCV from sources with CUDA support to enable it\")\n  elseif(ENABLE_CUDA AND OpenCV_CUDA_VERSION)\n    if(TARGET opencv_cudaoptflow)\n      list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_cudaoptflow\")\n    endif()\n    if(TARGET opencv_cudaimgproc)\n      list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_cudaimgproc\")\n    endif()\n  endif()\nendif()\n\nif(ENABLE_CUDA)\n  find_package(CUDNN)\n  if(NOT CUDNN_FOUND)\n    set(ENABLE_CUDNN \"FALSE\" CACHE BOOL \"Enable CUDNN\" FORCE)\n  endif()\nendif()\n\nif(ENABLE_CUDA)\n  if (MSVC)\n    set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DGPU\")\n    if(CUDNN_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DCUDNN\")\n    endif()\n    if(OpenCV_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DOPENCV\")\n    endif()\n    string(REPLACE \" \" \",\" ADDITIONAL_CXX_FLAGS_COMMA_SEPARATED \"${ADDITIONAL_CXX_FLAGS}\")\n    set(CUDA_HOST_COMPILER_FLAGS \"-Wno-deprecated-declarations -Xcompiler=\\\"${ADDITIONAL_CXX_FLAGS_COMMA_SEPARATED}\\\"\")\n  else()\n    set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DGPU\")\n    if(CUDNN_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DCUDNN\")\n    endif()\n    if(OpenCV_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DOPENCV\")\n    endif()\n    set(CUDA_HOST_COMPILER_FLAGS \"--compiler-options \\\" ${ADDITIONAL_CXX_FLAGS} -fPIC -fopenmp -Ofast \\\"\")\n  endif()\n\n  string (REPLACE \";\" \" \" CUDA_ARCH_FLAGS_SPACE_SEPARATED \"${CUDA_ARCH_FLAGS}\")\n  set(CMAKE_CUDA_FLAGS \"${CUDA_ARCH_FLAGS_SPACE_SEPARATED} ${CUDA_HOST_COMPILER_FLAGS} ${CMAKE_CUDA_FLAGS}\")\n  message(STATUS \"CMAKE_CUDA_FLAGS: ${CMAKE_CUDA_FLAGS}\")\nendif()\n\nif(ENABLE_CUDA)\n  if(ENABLE_ZED_CAMERA)\n    find_package(ZED 2 QUIET)\n    if(ZED_FOUND)\n      include_directories(${ZED_INCLUDE_DIRS})\n      link_directories(${ZED_LIBRARY_DIR})\n      message(STATUS \"ZED SDK enabled\")\n    else()\n      message(STATUS \"ZED SDK not found\")\n      set(ENABLE_ZED_CAMERA \"FALSE\" CACHE BOOL \"Enable ZED Camera support\" FORCE)\n    endif()\n  endif()\nelse()\n  message(STATUS \"ZED SDK not enabled, since it requires CUDA\")\n  set(ENABLE_ZED_CAMERA \"FALSE\" CACHE BOOL \"Enable ZED Camera support\" FORCE)\nendif()\n\nset(DARKNET_INSTALL_INCLUDE_DIR ${INSTALL_INCLUDE_DIR})\n# Make relative paths absolute (needed later on)\nforeach(p LIB BIN INCLUDE CMAKE)\n  set(var INSTALL_${p}_DIR)\n  if(NOT IS_ABSOLUTE \"${${var}}\")\n    set(${var} \"${CMAKE_INSTALL_PREFIX}/${${var}}\")\n  endif()\nendforeach()\n\nconfigure_file(\n  \"${CMAKE_CURRENT_LIST_DIR}/src/version.h.in\"\n  \"${CMAKE_CURRENT_LIST_DIR}/src/version.h\"\n)\n\n#look for all *.h files in src folder\nfile(GLOB headers \"${CMAKE_CURRENT_LIST_DIR}/src/*.h\")\n#add also files in the include folder\nlist(APPEND headers\n  ${CMAKE_CURRENT_LIST_DIR}/include/darknet.h\n)\n#remove windows only files\nif(NOT WIN32)\n  list(REMOVE_ITEM headers\n    ${CMAKE_CURRENT_LIST_DIR}/src/gettimeofday.h\n    ${CMAKE_CURRENT_LIST_DIR}/src/getopt.h\n  )\nendif()\n#set(exported_headers ${headers})\n\n#look for all *.c files in src folder\nfile(GLOB sources \"${CMAKE_CURRENT_LIST_DIR}/src/*.c\")\n#add also .cpp files\nlist(APPEND sources\n  ${CMAKE_CURRENT_LIST_DIR}/src/http_stream.cpp\n  ${CMAKE_CURRENT_LIST_DIR}/src/image_opencv.cpp\n)\n#remove darknet.c file which is necessary only for the executable, not for the lib\nlist(REMOVE_ITEM sources\n  ${CMAKE_CURRENT_LIST_DIR}/src/darknet.c\n)\n#remove windows only files\nif(NOT WIN32)\n  list(REMOVE_ITEM sources\n    ${CMAKE_CURRENT_LIST_DIR}/src/gettimeofday.c\n    ${CMAKE_CURRENT_LIST_DIR}/src/getopt.c\n  )\nendif()\n\nif(ENABLE_CUDA)\n  file(GLOB cuda_sources \"${CMAKE_CURRENT_LIST_DIR}/src/*.cu\")\nendif()\n\nif(BUILD_AS_CPP)\n  set_source_files_properties(${sources} PROPERTIES LANGUAGE CXX)\nendif()\n\nadd_library(dark ${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp ${CMAKE_CURRENT_LIST_DIR}/src/yolo_v2_class.cpp ${sources} ${headers} ${cuda_sources})\nset_target_properties(dark PROPERTIES POSITION_INDEPENDENT_CODE ON)\nif(ENABLE_CUDA)\n  set_target_properties(dark PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\nendif()\nif(BUILD_SHARED_LIBS)\n  target_compile_definitions(dark PRIVATE LIB_EXPORTS=1)\nendif()\nif(BUILD_AS_CPP)\n  set_target_properties(dark PROPERTIES LINKER_LANGUAGE CXX)\nendif()\n\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  add_executable(uselib_track ${CMAKE_CURRENT_LIST_DIR}/src/yolo_console_dll.cpp)\nendif()\n\nadd_executable(uselib ${CMAKE_CURRENT_LIST_DIR}/src/yolo_console_dll.cpp)\nif(BUILD_AS_CPP)\n  set_target_properties(uselib PROPERTIES LINKER_LANGUAGE CXX)\nendif()\n\nadd_executable(darknet ${CMAKE_CURRENT_LIST_DIR}/src/darknet.c ${sources} ${headers} ${cuda_sources})\nif(BUILD_AS_CPP)\n  set_source_files_properties(${CMAKE_CURRENT_LIST_DIR}/src/darknet.c PROPERTIES LANGUAGE CXX)\n  set_target_properties(darknet PROPERTIES LINKER_LANGUAGE CXX)\nendif()\n\ntarget_include_directories(darknet PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${DARKNET_INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\ntarget_include_directories(dark PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${DARKNET_INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\ntarget_include_directories(uselib PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${DARKNET_INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\n\ntarget_compile_definitions(darknet PRIVATE -DUSE_CMAKE_LIBS)\ntarget_compile_definitions(dark PRIVATE -DUSE_CMAKE_LIBS)\ntarget_compile_definitions(uselib PRIVATE -DUSE_CMAKE_LIBS)\n\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK AND NOT MANUALLY_EXPORT_TRACK_OPTFLOW)\n  target_compile_definitions(dark PUBLIC TRACK_OPTFLOW=1)\nendif()\n\nif(CUDNN_FOUND)\n  target_link_libraries(darknet PRIVATE CuDNN::CuDNN)\n  target_link_libraries(dark PRIVATE CuDNN::CuDNN)\n  target_compile_definitions(darknet PRIVATE -DCUDNN)\n  target_compile_definitions(dark PUBLIC -DCUDNN)\n  if(ENABLE_CUDNN_HALF)\n    target_compile_definitions(darknet PRIVATE -DCUDNN_HALF)\n    target_compile_definitions(dark PUBLIC -DCUDNN_HALF)\n  endif()\nendif()\n\nif(OpenCV_FOUND)\n  target_link_libraries(darknet PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  target_link_libraries(uselib PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  target_link_libraries(dark PUBLIC ${OpenCV_LINKED_COMPONENTS})\n  target_include_directories(dark PUBLIC ${OpenCV_INCLUDE_DIRS})\n  target_compile_definitions(darknet PRIVATE -DOPENCV)\n  target_compile_definitions(dark PUBLIC -DOPENCV)\nendif()\n\nif(OPENMP_FOUND)\n  target_link_libraries(darknet PRIVATE OpenMP::OpenMP_CXX)\n  target_link_libraries(darknet PRIVATE OpenMP::OpenMP_C)\n  target_link_libraries(dark PUBLIC OpenMP::OpenMP_CXX)\n  target_link_libraries(dark PUBLIC OpenMP::OpenMP_C)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCC)\n  target_link_libraries(darknet PRIVATE m)\n  target_link_libraries(dark PUBLIC m)\nendif()\n\nif(MSVC)\n  target_link_libraries(darknet PRIVATE PThreads_windows::PThreads_windows)\n  target_link_libraries(darknet PRIVATE wsock32 ws2_32)\n  target_link_libraries(dark PUBLIC PThreads_windows::PThreads_windows)\n  target_link_libraries(dark PUBLIC wsock32 ws2_32)\n  target_link_libraries(uselib PRIVATE PThreads_windows::PThreads_windows)\n  target_compile_definitions(darknet PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  target_compile_definitions(dark PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  target_compile_definitions(dark PUBLIC -D_CRT_SECURE_NO_WARNINGS)\n  target_compile_definitions(uselib PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\nendif()\n\ntarget_link_libraries(darknet PRIVATE Threads::Threads)\ntarget_link_libraries(dark PUBLIC Threads::Threads)\ntarget_link_libraries(uselib PRIVATE Threads::Threads)\n\nif(ENABLE_ZED_CAMERA)\n  target_link_libraries(darknet PRIVATE ${ZED_LIBRARIES})\n  target_link_libraries(dark PUBLIC ${ZED_LIBRARIES})\n  target_link_libraries(uselib PRIVATE ${ZED_LIBRARIES})\n  target_compile_definitions(darknet PRIVATE -DZED_STEREO)\n  target_compile_definitions(uselib PRIVATE -DZED_STEREO)\n  target_compile_definitions(dark PUBLIC -DZED_STEREO)\nendif()\n\nif(ENABLE_CUDA)\n  target_include_directories(darknet PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n  target_include_directories(dark PUBLIC ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n  target_link_libraries(darknet PRIVATE curand cublas cuda)\n  target_link_libraries(dark PRIVATE curand cublas cuda)\n  set_target_properties(dark PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)\n  target_compile_definitions(darknet PRIVATE -DGPU)\n  target_compile_definitions(dark PUBLIC -DGPU)\nendif()\n\nif(USE_INTEGRATED_LIBS)\n  target_compile_definitions(darknet PRIVATE -D_TIMESPEC_DEFINED)\n  target_compile_definitions(dark PRIVATE -D_TIMESPEC_DEFINED)\nendif()\n\ntarget_link_libraries(uselib PRIVATE dark)\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  target_link_libraries(uselib_track PRIVATE dark)\n  target_compile_definitions(uselib_track PRIVATE TRACK_OPTFLOW=1)\n  target_compile_definitions(uselib_track PRIVATE -DUSE_CMAKE_LIBS)\n  if(BUILD_AS_CPP)\n    set_target_properties(uselib_track PROPERTIES LINKER_LANGUAGE CXX)\n  endif()\n  target_include_directories(uselib_track PRIVATE ${CMAKE_CURRENT_LIST_DIR}/include)\n  target_link_libraries(uselib_track PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  if(ENABLE_ZED_CAMERA)\n    target_link_libraries(uselib_track PRIVATE ${ZED_LIBRARIES})\n    target_compile_definitions(uselib_track PRIVATE -DZED_STEREO)\n  endif()\n  if(MSVC)\n    target_link_libraries(uselib_track PRIVATE PThreads_windows::PThreads_windows)\n    target_compile_definitions(uselib_track PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  endif()\n  target_link_libraries(uselib_track PRIVATE Threads::Threads)\nendif()\n\n#set_target_properties(dark PROPERTIES PUBLIC_HEADER \"${exported_headers};${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp\")\nset_target_properties(dark PROPERTIES PUBLIC_HEADER \"${CMAKE_CURRENT_LIST_DIR}/include/darknet.h;${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp\")\n\nset_target_properties(dark PROPERTIES CXX_VISIBILITY_PRESET hidden)\n\ninstall(TARGETS dark EXPORT DarknetTargets\n  RUNTIME DESTINATION \"${INSTALL_BIN_DIR}\"\n  LIBRARY DESTINATION \"${INSTALL_LIB_DIR}\"\n  ARCHIVE DESTINATION \"${INSTALL_LIB_DIR}\"\n  PUBLIC_HEADER DESTINATION \"${INSTALL_INCLUDE_DIR}\"\n  COMPONENT dev\n)\ninstall(TARGETS uselib darknet\n  DESTINATION \"${INSTALL_BIN_DIR}\"\n)\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  install(TARGETS uselib_track\n    DESTINATION \"${INSTALL_BIN_DIR}\"\n  )\nendif()\n\ninstall(EXPORT DarknetTargets\n  FILE DarknetTargets.cmake\n  NAMESPACE Darknet::\n  DESTINATION \"${INSTALL_CMAKE_DIR}\"\n)\n\n# Export the package for use from the build-tree (this registers the build-tree with a global CMake-registry)\nexport(PACKAGE Darknet)\n\n# Create the DarknetConfig.cmake\n# First of all we compute the relative path between the cmake config file and the include path\nfile(RELATIVE_PATH REL_INCLUDE_DIR \"${INSTALL_CMAKE_DIR}\" \"${INSTALL_INCLUDE_DIR}\")\nset(CONF_INCLUDE_DIRS \"${PROJECT_SOURCE_DIR}\" \"${PROJECT_BINARY_DIR}\")\nconfigure_file(DarknetConfig.cmake.in \"${PROJECT_BINARY_DIR}/DarknetConfig.cmake\" @ONLY)\nset(CONF_INCLUDE_DIRS \"\\${Darknet_CMAKE_DIR}/${REL_INCLUDE_DIR}\")\nconfigure_file(DarknetConfig.cmake.in \"${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DarknetConfig.cmake\" @ONLY)\n\n# Create the DarknetConfigVersion.cmake\ninclude(CMakePackageConfigHelpers)\nwrite_basic_package_version_file(\"${PROJECT_BINARY_DIR}/DarknetConfigVersion.cmake\"\n  COMPATIBILITY SameMajorVersion\n)\n\ninstall(FILES\n  \"${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DarknetConfig.cmake\"\n  \"${PROJECT_BINARY_DIR}/DarknetConfigVersion.cmake\"\n  DESTINATION \"${INSTALL_CMAKE_DIR}\"\n)\n"
        },
        {
          "name": "DarknetConfig.cmake.in",
          "type": "blob",
          "size": 1.3310546875,
          "content": "# Config file for the Darknet package\n\nget_filename_component(Darknet_CMAKE_DIR \"${CMAKE_CURRENT_LIST_FILE}\" PATH)\nlist(APPEND CMAKE_MODULE_PATH \"${Darknet_CMAKE_DIR}\")\n\ninclude(CMakeFindDependencyMacro)\n\nif(@OpenCV_FOUND@)\n  find_dependency(OpenCV)\nendif()\n\nif(@ENABLE_CUDA@)\n  include(CheckLanguage)\n  check_language(CUDA)\n  if(NOT CMAKE_CUDA_COMPILER)\n    message(STATUS \" --> WARNING: Unable to find native CUDA integration!\")\n  endif()\n  find_dependency(CUDA)\n  cuda_select_nvcc_arch_flags(CUDA_ARCH_FLAGS ${CUDA_ARCHITECTURES})\n  if(@CUDNN_FOUND@)\n    find_dependency(CUDNN)\n  endif()\nendif()\n\nset(CMAKE_THREAD_PREFER_PTHREAD ON)\nfind_dependency(Threads)\n\nif(MSVC)\n  find_dependency(PThreads_windows)\n  set(CMAKE_CXX_FLAGS \"/wd4018 /wd4244 /wd4267 /wd4305 ${CMAKE_CXX_FLAGS}\")\nendif()\n\nif(@OPENMP_FOUND@)\n  find_dependency(OpenMP)\nendif()\n\n# Our library dependencies (contains definitions for IMPORTED targets)\ninclude(\"${Darknet_CMAKE_DIR}/DarknetTargets.cmake\")\ninclude(\"${Darknet_CMAKE_DIR}/DarknetConfigVersion.cmake\")\n\nget_target_property(FULL_DARKNET_INCLUDE_DIRS Darknet::dark INTERFACE_INCLUDE_DIRECTORIES)\nlist(GET FULL_DARKNET_INCLUDE_DIRS 0 Darknet_INCLUDE_DIR)\nget_filename_component(Darknet_INCLUDE_DIR \"${Darknet_INCLUDE_DIR}\" REALPATH)\n\nfind_package_handle_standard_args(Darknet REQUIRED_VARS Darknet_INCLUDE_DIR VERSION_VAR PACKAGE_VERSION)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.5029296875,
          "content": "                                  YOLO LICENSE\n                             Version 2, July 29 2016\n\nTHIS SOFTWARE LICENSE IS PROVIDED \"ALL CAPS\" SO THAT YOU KNOW IT IS SUPER\nSERIOUS AND YOU DON'T MESS AROUND WITH COPYRIGHT LAW BECAUSE YOU WILL GET IN\nTROUBLE HERE ARE SOME OTHER BUZZWORDS COMMONLY IN THESE THINGS WARRANTIES\nLIABILITY CONTRACT TORT LIABLE CLAIMS RESTRICTION MERCHANTABILITY. NOW HERE'S\nTHE REAL LICENSE:\n\n0. Darknet is public domain.\n1. Do whatever you want with it.\n2. Stop emailing me about it!\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 5.296875,
          "content": "GPU=1\nCUDNN=1\nCUDNN_HALF=1\nOPENCV=1\nAVX=1\nOPENMP=1\nLIBSO=0\nZED_CAMERA=0 # ZED SDK 3.0 and above\nZED_CAMERA_v2_8=0 # ZED SDK 2.X\n\n# set GPU=1 and CUDNN=1 to speedup on GPU\n# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n\nUSE_CPP=0\nDEBUG=0\n\nARCH= -gencode arch=compute_30,code=sm_30 \\\n      -gencode arch=compute_35,code=sm_35 \\\n      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n\t  -gencode arch=compute_61,code=[sm_61,compute_61]\n\nOS := $(shell uname)\n\n# Tesla V100\n# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n\n# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n\n# Jetson XAVIER\n# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n\n# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61\n\n# GP100/Tesla P100 - DGX-1\n# ARCH= -gencode arch=compute_60,code=sm_60\n\n# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n\n# For Jetson Tx2 or Drive-PX2 uncomment:\n# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n\n\nVPATH=./src/\nEXEC=darknet\nOBJDIR=./obj/\n\nifeq ($(LIBSO), 1)\nLIBNAMESO=libdarknet.so\nAPPNAMESO=uselib\nendif\n\nifeq ($(USE_CPP), 1)\nCC=g++\nelse\nCC=gcc\nendif\n\nCPP=g++ -std=c++11\nNVCC=nvcc\nOPTS=-Ofast\nLDFLAGS= -lm -pthread\nCOMMON= -Iinclude/ -I3rdparty/stb/include\nCFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n\nifeq ($(DEBUG), 1)\n#OPTS= -O0 -g\n#OPTS= -Og -g\nCOMMON+= -DDEBUG\nCFLAGS+= -DDEBUG\nelse\nifeq ($(AVX), 1)\nCFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\nendif\nendif\n\nCFLAGS+=$(OPTS)\n\nifneq (,$(findstring MSYS_NT,$(OS)))\nLDFLAGS+=-lws2_32\nendif\n\nifeq ($(OPENCV), 1)\nCOMMON+= -DOPENCV\nCFLAGS+= -DOPENCV\nLDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\nCOMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\nendif\n\nifeq ($(OPENMP), 1)\nCFLAGS+= -fopenmp\nLDFLAGS+= -lgomp\nendif\n\nifeq ($(GPU), 1)\nCOMMON+= -DGPU -I/usr/local/cuda/include/\nCFLAGS+= -DGPU\nifeq ($(OS),Darwin) #MAC\nLDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\nelse\nLDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\nendif\nendif\n\nifeq ($(CUDNN), 1)\nCOMMON+= -DCUDNN\nifeq ($(OS),Darwin) #MAC\nCFLAGS+= -DCUDNN -I/usr/local/cuda/include\nLDFLAGS+= -L/usr/local/cuda/lib -lcudnn\nelse\nCFLAGS+= -DCUDNN -I/usr/local/cudnn/include\nLDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\nendif\nendif\n\nifeq ($(CUDNN_HALF), 1)\nCOMMON+= -DCUDNN_HALF\nCFLAGS+= -DCUDNN_HALF\nARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\nendif\n\nifeq ($(ZED_CAMERA), 1)\nCFLAGS+= -DZED_STEREO -I/usr/local/zed/include\nifeq ($(ZED_CAMERA_v2_8), 1)\nLDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0 \nelse\nLDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0 \nendif\nendif\n\nOBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\nifeq ($(GPU), 1) \nLDFLAGS+= -lstdc++ \nOBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\nendif\n\nOBJS = $(addprefix $(OBJDIR), $(OBJ))\nDEPS = $(wildcard src/*.h) Makefile include/darknet.h\n\nall: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n\nifeq ($(LIBSO), 1)\nCFLAGS+= -fPIC\n\n$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n\n$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\nendif\n\n$(EXEC): $(OBJS)\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n\n$(OBJDIR)%.o: %.c $(DEPS)\n\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n\n$(OBJDIR)%.o: %.cpp $(DEPS)\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n\n$(OBJDIR)%.o: %.cu $(DEPS)\n\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n\n$(OBJDIR):\n\tmkdir -p $(OBJDIR)\nbackup:\n\tmkdir -p backup\nresults:\n\tmkdir -p results\nsetchmod:\n\tchmod +x *.sh\n\n.PHONY: clean\n\nclean:\n\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n"
        },
        {
          "name": "MobileNetV2-YOLO-Fastest",
          "type": "tree",
          "content": null
        },
        {
          "name": "MobileNetV2-YOLOv3-Lite",
          "type": "tree",
          "content": null
        },
        {
          "name": "MobileNetV2-YOLOv3-Nano",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.64453125,
          "content": "## 2021.2.6 此项目不再更新，新项目地址: Yolo-Fastest： Faster and stronger https://github.com/dog-qiuqiu/Yolo-Fastest\n\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/7a96026f319ad31e28bc55458ee97e97.gif)\n\n* ***Yolo-Fastest： Faster and stronger https://github.com/dog-qiuqiu/Yolo-Fastest***\n* ***此表中NCNN基准未更新最新ARM82数据，最新版本NCNN理论上ARM82会有一倍速度提升，待更新...***\n* 添加基于ncnn的106关键点 C sample:https://github.com/dog-qiuqiu/MobileNet-Yolo/tree/master/sample/ncnn\n## ***Darknet Group convolution is not well supported on some GPUs such as NVIDIA PASCAL!!! \n* https://github.com/AlexeyAB/darknet/issues/6091#issuecomment-651667469\n## 针对某些Pascal显卡例如1080ti在darknet上 训练失败/训练异常缓慢/推理速度异常 的可以采用Pytorch版yolo3框架 训练/推理\n* https://github.com/dog-qiuqiu/yolov3\n\n## MobileNetV2-YOLOv3-Lite&Nano Darknet\n#### Mobile inference frameworks benchmark (4*ARM_CPU)\nNetwork|VOC mAP(0.5)|COCO mAP(0.5)|Resolution|Inference time (NCNN/Kirin 990)|Inference time (MNN arm82/Kirin 990)|FLOPS|Weight size\n:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:\n[MobileNetV2-YOLOv3-Lite](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/MobileNetV2-YOLOv3-Lite)(our)|73.26|37.44|320|28.42 ms|18 ms|1.8BFlops|8.0MB\n[MobileNetV2-YOLOv3-Nano](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/MobileNetV2-YOLOv3-Nano)(our)|65.27|30.13|320|10.16 ms|5 ms|0.5BFlops|3.0MB\n[MobileNetV2-YOLOv3](https://github.com/eric612/MobileNet-YOLO)|70.7|&|352|32.15 ms|& ms|2.44BFlops|14.4MB\n[MobileNet-SSD](https://github.com/chuanqi305/MobileNet-SSD)|72.7|&|300|26.37 ms|& ms|& BFlops|23.1MB\n[YOLOv5s](https://github.com/ultralytics/yolov5)|&|56.2|416|150.5 ms|& ms|13.2BFlops|28.1MB\n[YOLOv3-Tiny-Prn](https://github.com/AlexeyAB/darknet#pre-trained-models)|&|33.1|416|36.6 ms|& ms|3.5BFlops|18.8MB\n[YOLOv4-Tiny](https://github.com/AlexeyAB/darknet#pre-trained-models)|&|40.2|416|44.6 ms|& ms|6.9BFlops|23.1MB\n[YOLO-Nano](https://github.com/liux0614/yolo_nano)|69.1|&|416|& ms|& ms|4.57BFlops|4.0MB\n* Support mobile inference frameworks such as NCNN&MNN\n* The mnn benchmark only includes the forward inference time\n* The ncnn benchmark is the forward inference time + post-processing time(NMS...) of the convolution feature map. \n* Darknet Train Configuration: CUDA-version: 10010 (10020), cuDNN: 7.6.4,OpenCV version: 4 GPU:RTX2080ti\n## MobileNetV2-YOLOv3-Lite-COCO Test results\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/predictions.jpg)\n\n# Application\n## Ultralight-SimplePose \n* A ultra-lightweight human body posture key point prediction model designed for mobile devices, which can cooperate with MobileNetV2-YOLOv3-Nano to complete the human body posture estimation task\n* https://github.com/dog-qiuqiu/Ultralight-SimplePose\n\n![image](https://github.com/dog-qiuqiu/Ultralight-SimplePose/blob/master/data/Figure_1-1.jpg)\n## YoloFace-500k: 500kb yolo-Face-Detection\nNetwork|Resolution|Inference time (NCNN/Kirin 990)|Inference time (MNN arm82/Kirin 990)|FLOPS|Weight size\n:---:|:---:|:---:|:---:|:---:|:---:\nUltraFace-version-RFB|320x240|&ms|3.36ms|0.1BFlops|1.3MB\nUltraFace-version-Slim|320x240|&ms|3.06ms|0.1BFlops|1.2MB\n[yoloface-500k](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface-500k/v1)|320x256|5.5ms|2.4ms|0.1BFlops|0.52MB\n[yoloface-500k-v2](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface-500k/v2)|352x288|4.7ms|&ms|0.1BFlops|0.42MB\n* 都500k了，要啥mAP:sunglasses:\n* Inference time (DarkNet/i7-6700):13ms\n* The mnn benchmark only includes the forward inference time\n* The ncnn benchmark is the forward inference time + post-processing time(NMS...) of the convolution feature map. \n## Wider Face Val\nModel|Easy Set|Medium Set|Hard Set\n------|--------|----------|--------\nlibfacedetection v1（caffe）|0.65 |0.5       |0.233\nlibfacedetection v2（caffe）|0.714 |0.585       |0.306\nRetinaface-Mobilenet-0.25 (Mxnet)   |0.745|0.553|0.232\nversion-slim-320|0.77     |0.671       |0.395\nversion-RFB-320|0.787     |0.698       |0.438\n[yoloface-500k-320](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface-500k/v1)|**0.728**|**0.682**|**0.431**|\n[yoloface-500k-352-v2](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface-500k/v2)|**0.768**|**0.729**|**0.490**|\n* yoloface-500k-v2：The SE&CSP module is added\n* V2 does not support MNN temporarily\n* wider_face_val(ap05): yoloface-500k: 53.75 yoloface-500k-v2: 56.69\n## YoloFace-500k Test results(thresh 0.7)\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/p1.jpg)\n## YoloFace-500k-v2 Test results(thresh 0.7)\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/f2.jpg)\n## YoloFace-50k: Sub-millisecond face detection model\nNetwork|Resolution|Inference time (NCNN/Kirin 990)|Inference time (MNN arm82/Kirin 990)|Inference time (DarkNet/R3-3100)|FLOPS|Weight size\n:---:|:---:|:---:|:---:|:---:|:---:|:---:\n[yoloface-50k](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface-50k)|56x56|0.27ms|0.31ms|0.5 ms|0.001BFlops|46kb\n* ***For the close-range face detection model in a specific scene, the recommended detection distance is 1.5m***\n## YoloFace-50k Test results(thresh 0.7)\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/yoloface-50k-1.jpg)\n## YoloFace50k-landmark106(Ultra lightweight 106 point face-landmark model)\nNetwork|Resolution|Inference time (NCNN/Kirin 990)|Inference time (MNN arm82/Kirin 990)|Weight size\n:---:|:---:|:---:|:---:|:---:\n[landmark106](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/yoloface50k-landmark106)|112x112|0.6ms|0.5ms|1.4MB\n* Face detection: yoloface-50k Landmark: landmark106\n## YoloFace50k-landmark106 Test results\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/yoloface50k-landmark106/yoloface-50k-landmark106.jpg)\n## Reference&Framework instructions&How to Train\n* https://github.com/AlexeyAB/darknet\n* You must use a pre-trained model to train your own data set. You can make a pre-trained model based on the weights of COCO training in this project to initialize the network parameters\n* 交流qq群:1062122604\n## About model selection\n* MobileNetV2-YOLOv3-SPP:  Nvidia Jeston, Intel Movidius, TensorRT，NPU，OPENVINO...High-performance embedded side\n* MobileNetV2-YOLOv3-Lite: High Performance ARM-CPU，Qualcomm Adreno GPU， ARM82...High-performance mobile\n* MobileNetV2-YOLOv3-NANO： ARM-CPU...Computing resources are limited\n* MobileNetV2-YOLOv3-Fastest： ....... Can you do personal face detection???It’s better than nothing\n## NCNN conversion tutorial\n* Benchmark:https://github.com/Tencent/ncnn/tree/master/benchmark\n* NCNN supports direct conversion of darknet models\n* darknet2ncnn: https://github.com/Tencent/ncnn/tree/master/tools/darknet\n## NCNN C++ Sample\n* https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/tree/master/sample/ncnn\n## NCNN Android Sample\n![image](https://github.com/dog-qiuqiu/MobileNetv2-YOLOV3/blob/master/data/MobileNetV2-YOLOV3-Nano.gif)\n* https://github.com/dog-qiuqiu/Android_MobileNetV2-YOLOV3-Nano-NCNN\n* APK:https://github.com/dog-qiuqiu/Android_MobileNetV2-YOLOV3-Nano-NCNN/blob/master/app/release/MobileNetv2-yolov3-nano.apk\n## DarkNet2Caffe tutorial\n### Environmental requirements\n\n* Python2.7\n* python-opencv\n* Caffe(add upsample layer https://github.com/dog-qiuqiu/caffe)\n* You have to compile cpu version of caffe！！！\n  ```\n\tcd darknet2caffe/\n\tpython darknet2caffe.py MobileNetV2-YOLOv3-Nano-voc.cfg MobileNetV2-YOLOv3-Nano-voc.weights MobileNetV2-YOLOv3-Nano-voc.prototxt MobileNetV2-YOLOv3-Nano-voc.caffemodel\n\tcp MobileNetV2-YOLOv3-Nano-voc.prototxt sample\n\tcp MobileNetV2-YOLOv3-Nano-voc.caffemodel sample\n\tcd sample\n\tpython detector.py\n  ```\n### MNN conversion tutorial\n* Benchmark:https://www.yuque.com/mnn/cn/tool_benchmark\n* Convert darknet model to caffemodel through darknet2caffe\n* Manually replace the upsample layer in prototxt with the interp layer\n* Take the modification of MobileNetV2-YOLOv3-Nano-voc.prototxt as an example\n```\n\t#layer {\n\t#    bottom: \"layer71-route\"\n\t#    top: \"layer72-upsample\"\n\t#    name: \"layer72-upsample\"\n\t#    type: \"Upsample\"\n\t#    upsample_param {\n\t#        scale: 2\n\t#    }\n\t#}\n\tlayer {\n\t    bottom: \"layer71-route\"\n\t    top: \"layer72-upsample\"\n\t    name: \"layer72-upsample\"\n\t    type: \"Interp\"\n\t    interp_param {\n\t\theight:20  #upsample h size\n\t\twidth:20   #upsample w size\n\t    }\n\t}\n\n```\n* MNN conversion: https://www.yuque.com/mnn/cn/model_convert\n## Thanks\n* https://github.com/shicai/MobileNet-Caffe\n* https://github.com/WZTENG/YOLOv5_NCNN \n* https://github.com/AlexeyAB/darknet\n* https://github.com/Tencent/ncnn\n* https://gluon-cv.mxnet.io/\n"
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.025390625,
          "content": "theme: jekyll-theme-cayman"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 5.8779296875,
          "content": "image: Visual Studio 2017\nclone_folder: c:\\projects\\darknet\ncache: C:\\Tools\\vcpkg\\installed\\\n\nenvironment:\n    WORKSPACE: C:\\projects\n    matrix:\n    - platform: Cygwin64\n      COMPILER: cygwin\n      CYGWIN_NOWINPATH: yes\n      CYGSH: C:\\cygwin64\\bin\\bash -c\n    - platform: Win64\n      USE_CUDA: yes\n      COMPILER: vs\n      configuration: Release\n      VCPKG_ROOT: C:\\Tools\\vcpkg\n      VCPKG_DEFAULT_TRIPLET: x64-windows\n    - platform: Win64\n      USE_CUDA: no\n      COMPILER: vs\n      configuration: Release\n      VCPKG_ROOT: C:\\Tools\\vcpkg\n      VCPKG_DEFAULT_TRIPLET: x64-windows\n    - platform: Win64\n      COMPILER: vs\n      configuration: Release\n      USE_INTEGRATED_LIBS: yes\n    - platform: Win64\n      COMPILER: vs\n      configuration: Release\n      USE_INTEGRATED_LIBS: yes\n      FORCE_CPP: yes\n\ninstall:\n  - if [%COMPILER%]==[vs] cinst cmake ninja\n  - if [%COMPILER%]==[vs] SET \"PATH=C:\\Program Files\\CMake\\bin;%PATH%\"\n  - if [%COMPILER%]==[vs] call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64\n  - if [%COMPILER%]==[cygwin] SET \"PATH=C:\\cygwin64\\usr\\local\\bin;C:\\cygwin64\\bin;C:\\cygwin64\\usr\\bin;%PATH%\"\n  - if [%COMPILER%]==[cygwin] SET PATH=%PATH:C:\\Program Files\\Git\\usr\\bin;=%\n  - git submodule -q update --init --recursive\n  - cd %WORKSPACE%\\\n  - if [%USE_CUDA%]==[yes] curl -L https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.96_win10.exe -o setup.exe\n  - if [%USE_CUDA%]==[yes] .\\setup.exe -s nvcc_10.1 cuobjdump_10.1 nvprune_10.1 cupti_10.1 gpu_library_advisor_10.1 memcheck_10.1 nvdisasm_10.1 nvprof_10.1 visual_profiler_10.1 visual_studio_integration_10.1 cublas_10.1 cublas_dev_10.1 cudart_10.1 cufft_10.1 cufft_dev_10.1 curand_10.1 curand_dev_10.1 cusolver_10.1 cusolver_dev_10.1 cusparse_10.1 cusparse_dev_10.1 nvgraph_10.1 nvgraph_dev_10.1 npp_10.1 npp_dev_10.1 nvrtc_10.1 nvrtc_dev_10.1 nvml_dev_10.1 occupancy_calculator_10.1 fortran_examples_10.1\n  - if [%USE_CUDA%]==[yes] set CUDA_PATH=%ProgramFiles%\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\n  - if [%USE_CUDA%]==[yes] set CUDA_PATH_V10_1=%CUDA_PATH%\n  - if [%USE_CUDA%]==[yes] set CUDA_TOOLKIT_ROOT_DIR=%CUDA_PATH%\n  - if [%USE_CUDA%]==[yes] set PATH=%CUDA_PATH%\\bin;%PATH%\n  - cd %WORKSPACE%\\\n  - mkdir cygwin-downloads\n  - ps: if($env:COMPILER -eq \"cygwin\") { Invoke-WebRequest https://cygwin.com/setup-x86_64.exe -OutFile $env:WORKSPACE\\cygwin-setup.exe }\n  - if [%COMPILER%]==[cygwin] %WORKSPACE%\\cygwin-setup.exe --quiet-mode --no-shortcuts --no-startmenu --no-desktop --upgrade-also --root C:\\cygwin64 --local-package-dir %WORKSPACE%\\cygwin-downloads --packages gcc-g++,cmake,libopencv-devel,libncurses-devel\n  - ps: if($env:COMPILER -eq \"cygwin\") { Invoke-WebRequest https://github.com/Kitware/CMake/releases/download/v3.14.0/cmake-3.14.0.tar.gz -OutFile $env:WORKSPACE\\cmake-3.14.0.tar.gz }\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'tar zxvf cmake-3.14.0.tar.gz'\n  - if [%COMPILER%]==[cygwin] cd %WORKSPACE%\\cmake-3.14.0\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'cmake .'\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'make -j8'\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'make install'\n  - if [%COMPILER%]==[cygwin] cd %WORKSPACE%\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] cd %VCPKG_ROOT%\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] git checkout .\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] git pull\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] .\\bootstrap-vcpkg.bat\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] echo set(VCPKG_BUILD_TYPE release) >> triplets\\%VCPKG_DEFAULT_TRIPLET%.cmake\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] if [%USE_CUDA%]==[yes] vcpkg install cuda --recurse\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] vcpkg install stb pthreads --recurse\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] vcpkg install ffmpeg --recurse\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] vcpkg install opencv[ffmpeg] --recurse ## opencv[ffmpeg,cuda] is too big to build, timing out (>1h). We use plain openCV also for CUDA builds (toolchain can manage this strange situation anyway)\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] rmdir \"buildtrees\" /S /Q\n  - cd %WORKSPACE%\\darknet\\\n  - if [%COMPILER%]==[cygwin] mkdir build_debug && cd build_debug\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'cmake .. -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=\"Debug\"'\n  - if [%COMPILER%]==[cygwin] cd ..\n  - mkdir build_release && cd build_release\n  - if [%COMPILER%]==[cygwin] %CYGSH% 'cmake .. -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=\"Release\"'\n  - if [%COMPILER%]==[vs] if NOT [%USE_INTEGRATED_LIBS%]==[yes] if [%configuration%]==[Release] cmake -G \"Visual Studio 15 2017\" -T \"host=x64\" -A \"x64\" \"-DCMAKE_TOOLCHAIN_FILE=%VCPKG_ROOT%\\scripts\\buildsystems\\vcpkg.cmake\" \"-DVCPKG_TARGET_TRIPLET=%VCPKG_DEFAULT_TRIPLET%\" -DCMAKE_BUILD_TYPE=\"Release\" ..\n  - if [%COMPILER%]==[vs] if     [%USE_INTEGRATED_LIBS%]==[yes] if [%FORCE_CPP%]==[yes]         cmake -G \"Visual Studio 15 2017\" -T \"host=x64\" -A \"x64\" -DCMAKE_BUILD_TYPE=\"Release\" \"-DBUILD_AS_CPP:BOOL=TRUE\" ..\n  - if [%COMPILER%]==[vs] if     [%USE_INTEGRATED_LIBS%]==[yes]                                 cmake -G \"Visual Studio 15 2017\" -T \"host=x64\" -A \"x64\" -DCMAKE_BUILD_TYPE=\"Release\" ..\n  - cd ..\n\nbuild_script:\n  - if [%COMPILER%]==[cygwin]                                                                   cd build_debug   && %CYGSH% 'cmake --build . --target install -- -j8'              && cd ..\n  - if [%COMPILER%]==[cygwin]                                                                   cd build_release && %CYGSH% 'cmake --build . --target install -- -j8'              && cd ..\n  - if [%COMPILER%]==[vs]                                       if [%configuration%]==[Release] cd build_release && cmake --build . --config Release --parallel 8 --target install && cd ..\n\nartifacts:\n  - path: lib\n  - path: '*.exe'\n"
        },
        {
          "name": "build.ps1",
          "type": "blob",
          "size": 8.0712890625,
          "content": "#!/usr/bin/env pwsh\n\n$number_of_build_workers=8\n$use_vcpkg=$true\n$use_ninja=$false\n$force_cpp_build=$false\n\nfunction getProgramFiles32bit() {\n  $out = ${env:PROGRAMFILES(X86)}\n  if ($null -eq $out) {\n    $out = ${env:PROGRAMFILES}\n  }\n\n  if ($null -eq $out) {\n    throw \"Could not find [Program Files 32-bit]\"\n  }\n\n  return $out\n}\n\nfunction getLatestVisualStudioWithDesktopWorkloadPath() {\n  $programFiles = getProgramFiles32bit\n  $vswhereExe = \"$programFiles\\Microsoft Visual Studio\\Installer\\vswhere.exe\"\n  if (Test-Path $vswhereExe) {\n    $output = & $vswhereExe -products * -latest -requires Microsoft.VisualStudio.Workload.NativeDesktop -format xml\n    [xml]$asXml = $output\n    foreach ($instance in $asXml.instances.instance) {\n      $installationPath = $instance.InstallationPath -replace \"\\\\$\" # Remove potential trailing backslash\n    }\n    if (!$installationPath) {\n      Write-Host \"Warning: no full Visual Studio setup has been found, extending search to include also partial installations\" -ForegroundColor Yellow\n      $output = & $vswhereExe -products * -latest -format xml\n      [xml]$asXml = $output\n      foreach ($instance in $asXml.instances.instance) {\n        $installationPath = $instance.InstallationPath -replace \"\\\\$\" # Remove potential trailing backslash\n      }\n    }\n    if (!$installationPath) {\n      Throw \"Could not locate any installation of Visual Studio\"\n    }\n  }\n  else {\n    Throw \"Could not locate vswhere at $vswhereExe\"\n  }\n  return $installationPath\n}\n\n\nfunction getLatestVisualStudioWithDesktopWorkloadVersion() {\n  $programFiles = getProgramFiles32bit\n  $vswhereExe = \"$programFiles\\Microsoft Visual Studio\\Installer\\vswhere.exe\"\n  if (Test-Path $vswhereExe) {\n    $output = & $vswhereExe -products * -latest -requires Microsoft.VisualStudio.Workload.NativeDesktop -format xml\n    [xml]$asXml = $output\n    foreach ($instance in $asXml.instances.instance) {\n      $installationVersion = $instance.InstallationVersion\n    }\n    if (!$installationVersion) {\n      Write-Host \"Warning: no full Visual Studio setup has been found, extending search to include also partial installations\" -ForegroundColor Yellow\n      $output = & $vswhereExe -products * -latest -format xml\n      [xml]$asXml = $output\n      foreach ($instance in $asXml.instances.instance) {\n        $installationVersion = $instance.installationVersion\n      }\n    }\n    if (!$installationVersion) {\n      Throw \"Could not locate any installation of Visual Studio\"\n    }\n  }\n  else {\n    Throw \"Could not locate vswhere at $vswhereExe\"\n  }\n  return $installationVersion\n}\n\n\nif ((Test-Path env:VCPKG_ROOT) -and $use_vcpkg) {\n  $vcpkg_path = \"$env:VCPKG_ROOT\"\n  Write-Host \"Found vcpkg in VCPKG_ROOT: $vcpkg_path\"\n}\nelseif ((Test-Path \"${env:WORKSPACE}\\vcpkg\") -and $use_vcpkg) {\n  $vcpkg_path = \"${env:WORKSPACE}\\vcpkg\"\n  Write-Host \"Found vcpkg in WORKSPACE\\vcpkg: $vcpkg_path\"\n}\nelse {\n  Write-Host \"Skipping vcpkg-enabled builds because the VCPKG_ROOT environment variable is not defined or you requested to avoid VCPKG, using self-distributed libs`n\" -ForegroundColor Yellow\n}\n\nif ($null -eq $env:VCPKG_DEFAULT_TRIPLET -and $use_vcpkg) {\n  Write-Host \"No default triplet has been set-up for vcpkg. Defaulting to x64-windows\" -ForegroundColor Yellow\n  $vcpkg_triplet = \"x64-windows\"\n}\nelseif ($use_vcpkg) {\n  $vcpkg_triplet = $env:VCPKG_DEFAULT_TRIPLET\n}\n\nif ($vcpkg_triplet -Match \"x86\" -and $use_vcpkg) {\n  Throw \"darknet is supported only in x64 builds!\"\n}\n\nif ($null -eq (Get-Command \"cl.exe\" -ErrorAction SilentlyContinue)) {\n  $vsfound = getLatestVisualStudioWithDesktopWorkloadPath\n  Write-Host \"Found VS in ${vsfound}\"\n  Push-Location \"${vsfound}\\Common7\\Tools\"\n  cmd.exe /c \"VsDevCmd.bat -arch=x64 & set\" |\n  ForEach-Object {\n    if ($_ -match \"=\") {\n      $v = $_.split(\"=\"); Set-Item -force -path \"ENV:\\$($v[0])\"  -value \"$($v[1])\"\n    }\n  }\n  Pop-Location\n  Write-Host \"Visual Studio Command Prompt variables set\" -ForegroundColor Yellow\n}\n\n$tokens = getLatestVisualStudioWithDesktopWorkloadVersion\n$tokens = $tokens.split('.')\nif($use_ninja) {\n  $generator = \"Ninja\"\n}\nelse {\n  if ($tokens[0] -eq \"14\") {\n    $generator = \"Visual Studio 14 2015\"\n  }\n  elseif ($tokens[0] -eq \"15\") {\n    $generator = \"Visual Studio 15 2017\"\n  }\n  elseif ($tokens[0] -eq \"16\") {\n    $generator = \"Visual Studio 16 2019\"\n  }\n  else {\n    throw \"Unknown Visual Studio version, unsupported configuration\"\n  }\n}\nWrite-Host \"Setting up environment to use CMake generator: $generator\" -ForegroundColor Yellow\n\nif ($null -eq (Get-Command \"nvcc.exe\" -ErrorAction SilentlyContinue)) {\n  if (Test-Path env:CUDA_PATH) {\n    $env:PATH += \";${env:CUDA_PATH}\\bin\"\n    Write-Host \"Found cuda in ${env:CUDA_PATH}\" -ForegroundColor Yellow\n  }\n  else {\n    Write-Host \"Unable to find CUDA, if necessary please install it or define a CUDA_PATH env variable pointing to the install folder\" -ForegroundColor Yellow\n  }\n}\n\nif (Test-Path env:CUDA_PATH) {\n  if (-Not(Test-Path env:CUDA_TOOLKIT_ROOT_DIR)) {\n    $env:CUDA_TOOLKIT_ROOT_DIR = \"${env:CUDA_PATH}\"\n    Write-Host \"Added missing env variable CUDA_TOOLKIT_ROOT_DIR\" -ForegroundColor Yellow\n  }\n}\n\nif($force_cpp_build) {\n  $additional_build_setup=\"-DBUILD_AS_CPP:BOOL=TRUE\"\n}\n\nif ($use_vcpkg) {\n  ## DEBUG\n  #New-Item -Path .\\build_win_debug -ItemType directory -Force\n  #Set-Location build_win_debug\n  #if ($use_ninja) {\n    #cmake -G \"$generator\" \"-DCMAKE_TOOLCHAIN_FILE=$vcpkg_path\\scripts\\buildsystems\\vcpkg.cmake\" \"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\" #\"-DCMAKE_BUILD_TYPE=Debug\" $additional_build_setup ..\n    #$dllfolder = \".\"\n  #}\n  #else {\n    #cmake -G \"$generator\" -T \"host=x64\" -A \"x64\" \"-DCMAKE_TOOLCHAIN_FILE=$vcpkg_path\\scripts\\buildsystems\\vcpkg.cmake\" \"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\" \"-DCMAKE_BUILD_TYPE=Debug\" $additional_build_setup ..\n    #$dllfolder = \"Debug\"\n  #}\n  #cmake --build . --config Debug --target install\n  ##cmake --build . --config Debug --parallel ${number_of_build_workers} --target install  #valid only for CMake 3.12+\n  #Remove-Item DarknetConfig.cmake\n  #Remove-Item DarknetConfigVersion.cmake\n  #$dllfiles = Get-ChildItem ${dllfolder}\\*.dll\n  #if ($dllfiles) {\n  #  Copy-Item $dllfiles ..\n  #}\n  #Set-Location ..\n  #Copy-Item cmake\\Modules\\*.cmake share\\darknet\\\n\n  # RELEASE\n  New-Item -Path .\\build_win_release -ItemType directory -Force\n  Set-Location build_win_release\n  if($use_ninja) {\n    cmake -G \"$generator\" \"-DCMAKE_TOOLCHAIN_FILE=$vcpkg_path\\scripts\\buildsystems\\vcpkg.cmake\" \"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\" \"-DCMAKE_BUILD_TYPE=Release\" $additional_build_setup ..\n    $dllfolder = \".\"\n  }\n  else {\n    cmake -G \"$generator\" -T \"host=x64\" -A \"x64\" \"-DCMAKE_TOOLCHAIN_FILE=$vcpkg_path\\scripts\\buildsystems\\vcpkg.cmake\" \"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\" \"-DCMAKE_BUILD_TYPE=Release\" $additional_build_setup ..\n    $dllfolder = \"Release\"\n  }\n  cmake --build . --config Release --target install\n  #cmake --build . --config Release --parallel ${number_of_build_workers} --target install  #valid only for CMake 3.12+\n  Remove-Item DarknetConfig.cmake\n  Remove-Item DarknetConfigVersion.cmake\n  $dllfiles = Get-ChildItem ${dllfolder}\\*.dll\n  if ($dllfiles) {\n    Copy-Item $dllfiles ..\n  }\n  Set-Location ..\n  Copy-Item cmake\\Modules\\*.cmake share\\darknet\\\n}\nelse {\n  # USE LOCAL PTHREAD LIB AND LOCAL STB HEADER, NO VCPKG, ONLY RELEASE MODE SUPPORTED\n  # if you want to manually force this case, remove VCPKG_ROOT env variable and remember to use \"vcpkg integrate remove\" in case you had enabled user-wide vcpkg integration\n  New-Item -Path .\\build_win_release_novcpkg -ItemType directory -Force\n  Set-Location build_win_release_novcpkg\n  if($use_ninja) {\n    cmake -G \"$generator\" $additional_build_setup ..\n  }\n  else {\n    cmake -G \"$generator\" -T \"host=x64\" -A \"x64\" $additional_build_setup ..\n  }\n  cmake --build . --config Release --target install\n  #cmake --build . --config Release --parallel ${number_of_build_workers} --target install  #valid only for CMake 3.12+\n  Remove-Item DarknetConfig.cmake\n  Remove-Item DarknetConfigVersion.cmake\n  $dllfolder = \"..\\3rdparty\\pthreads\\bin\"\n  $dllfiles = Get-ChildItem ${dllfolder}\\*.dll\n  if ($dllfiles) {\n    Copy-Item $dllfiles ..\n  }\n  Set-Location ..\n  Copy-Item cmake\\Modules\\*.cmake share\\darknet\\\n}\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 1.99609375,
          "content": "#!/usr/bin/env bash\n\nnumber_of_build_workers=8\nbypass_vcpkg=true\nforce_cpp_build=false\n\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n  vcpkg_triplet=\"x64-osx\"\nelse\n  vcpkg_triplet=\"x64-linux\"\nfi\n\nif [[ ! -z \"${VCPKG_ROOT}\" ]] && [ -d ${VCPKG_ROOT} ] && [ ! \"$bypass_vcpkg\" = true ]\nthen\n  vcpkg_path=\"${VCPKG_ROOT}\"\n  vcpkg_define=\"-DCMAKE_TOOLCHAIN_FILE=${vcpkg_path}/scripts/buildsystems/vcpkg.cmake\"\n  vcpkg_triplet_define=\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\"\n  echo \"Found vcpkg in VCPKG_ROOT: ${vcpkg_path}\"\n  additional_defines=\"-DBUILD_SHARED_LIBS=OFF\"\nelif [[ ! -z \"${WORKSPACE}\" ]] && [ -d ${WORKSPACE}/vcpkg ] && [ ! \"$bypass_vcpkg\" = true ]\nthen\n  vcpkg_path=\"${WORKSPACE}/vcpkg\"\n  vcpkg_define=\"-DCMAKE_TOOLCHAIN_FILE=${vcpkg_path}/scripts/buildsystems/vcpkg.cmake\"\n  vcpkg_triplet_define=\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\"\n  echo \"Found vcpkg in WORKSPACE/vcpkg: ${vcpkg_path}\"\n  additional_defines=\"-DBUILD_SHARED_LIBS=OFF\"\nelif [ ! \"$bypass_vcpkg\" = true ]\nthen\n  (>&2 echo \"darknet is unsupported without vcpkg, use at your own risk!\")\nfi\n\nif [ \"$force_cpp_build\" = true ]\nthen\n  additional_build_setup=\"-DBUILD_AS_CPP:BOOL=TRUE\"\nfi\n\n## DEBUG\n#mkdir -p build_debug\n#cd build_debug\n#cmake .. -DCMAKE_BUILD_TYPE=Debug ${vcpkg_define} ${vcpkg_triplet_define} ${additional_defines} ${additional_build_setup}\n#cmake --build . --target install -- -j${number_of_build_workers}\n##cmake --build . --target install --parallel ${number_of_build_workers}  #valid only for CMake 3.12+\n#rm -f DarknetConfig.cmake\n#rm -f DarknetConfigVersion.cmake\n#cd ..\n#cp cmake/Modules/*.cmake share/darknet/\n\n# RELEASE\nmkdir -p build_release\ncd build_release\ncmake .. -DCMAKE_BUILD_TYPE=Release ${vcpkg_define} ${vcpkg_triplet_define} ${additional_defines} ${additional_build_setup}\ncmake --build . --target install -- -j${number_of_build_workers}\n#cmake --build . --target install --parallel ${number_of_build_workers}  #valid only for CMake 3.12+\nrm -f DarknetConfig.cmake\nrm -f DarknetConfigVersion.cmake\ncd ..\ncp cmake/Modules/*.cmake share/darknet/\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "cfg",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknet.py",
          "type": "blob",
          "size": 19.5859375,
          "content": "#!python3\n\"\"\"\nPython 3 wrapper for identifying objects in images\n\nRequires DLL compilation\n\nBoth the GPU and no-GPU version should be compiled; the no-GPU version should be renamed \"yolo_cpp_dll_nogpu.dll\".\n\nOn a GPU system, you can force CPU evaluation by any of:\n\n- Set global variable DARKNET_FORCE_CPU to True\n- Set environment variable CUDA_VISIBLE_DEVICES to -1\n- Set environment variable \"FORCE_CPU\" to \"true\"\n\n\nTo use, either run performDetect() after import, or modify the end of this file.\n\nSee the docstring of performDetect() for parameters.\n\nDirectly viewing or returning bounding-boxed images requires scikit-image to be installed (`pip install scikit-image`)\n\n\nOriginal *nix 2.7: https://github.com/pjreddie/darknet/blob/0f110834f4e18b30d5f101bf8f1724c34b7b83db/python/darknet.py\nWindows Python 2.7 version: https://github.com/AlexeyAB/darknet/blob/fc496d52bf22a0bb257300d3c79be9cd80e722cb/build/darknet/x64/darknet.py\n\n@author: Philip Kahn\n@date: 20180503\n\"\"\"\n#pylint: disable=R, W0401, W0614, W0703\nfrom ctypes import *\nimport math\nimport random\nimport os\n\ndef sample(probs):\n    s = sum(probs)\n    probs = [a/s for a in probs]\n    r = random.uniform(0, 1)\n    for i in range(len(probs)):\n        r = r - probs[i]\n        if r <= 0:\n            return i\n    return len(probs)-1\n\ndef c_array(ctype, values):\n    arr = (ctype*len(values))()\n    arr[:] = values\n    return arr\n\nclass BOX(Structure):\n    _fields_ = [(\"x\", c_float),\n                (\"y\", c_float),\n                (\"w\", c_float),\n                (\"h\", c_float)]\n\nclass DETECTION(Structure):\n    _fields_ = [(\"bbox\", BOX),\n                (\"classes\", c_int),\n                (\"prob\", POINTER(c_float)),\n                (\"mask\", POINTER(c_float)),\n                (\"objectness\", c_float),\n                (\"sort_class\", c_int),\n                (\"uc\", POINTER(c_float)),\n                (\"points\", c_int)]\n\nclass DETNUMPAIR(Structure):\n    _fields_ = [(\"num\", c_int),\n                (\"dets\", POINTER(DETECTION))]\n\nclass IMAGE(Structure):\n    _fields_ = [(\"w\", c_int),\n                (\"h\", c_int),\n                (\"c\", c_int),\n                (\"data\", POINTER(c_float))]\n\nclass METADATA(Structure):\n    _fields_ = [(\"classes\", c_int),\n                (\"names\", POINTER(c_char_p))]\n\n\n\n#lib = CDLL(\"/home/pjreddie/documents/darknet/libdarknet.so\", RTLD_GLOBAL)\n#lib = CDLL(\"libdarknet.so\", RTLD_GLOBAL)\nhasGPU = True\nif os.name == \"nt\":\n    cwd = os.path.dirname(__file__)\n    os.environ['PATH'] = cwd + ';' + os.environ['PATH']\n    winGPUdll = os.path.join(cwd, \"yolo_cpp_dll.dll\")\n    winNoGPUdll = os.path.join(cwd, \"yolo_cpp_dll_nogpu.dll\")\n    envKeys = list()\n    for k, v in os.environ.items():\n        envKeys.append(k)\n    try:\n        try:\n            tmp = os.environ[\"FORCE_CPU\"].lower()\n            if tmp in [\"1\", \"true\", \"yes\", \"on\"]:\n                raise ValueError(\"ForceCPU\")\n            else:\n                print(\"Flag value '\"+tmp+\"' not forcing CPU mode\")\n        except KeyError:\n            # We never set the flag\n            if 'CUDA_VISIBLE_DEVICES' in envKeys:\n                if int(os.environ['CUDA_VISIBLE_DEVICES']) < 0:\n                    raise ValueError(\"ForceCPU\")\n            try:\n                global DARKNET_FORCE_CPU\n                if DARKNET_FORCE_CPU:\n                    raise ValueError(\"ForceCPU\")\n            except NameError:\n                pass\n            # print(os.environ.keys())\n            # print(\"FORCE_CPU flag undefined, proceeding with GPU\")\n        if not os.path.exists(winGPUdll):\n            raise ValueError(\"NoDLL\")\n        lib = CDLL(winGPUdll, RTLD_GLOBAL)\n    except (KeyError, ValueError):\n        hasGPU = False\n        if os.path.exists(winNoGPUdll):\n            lib = CDLL(winNoGPUdll, RTLD_GLOBAL)\n            print(\"Notice: CPU-only mode\")\n        else:\n            # Try the other way, in case no_gpu was\n            # compile but not renamed\n            lib = CDLL(winGPUdll, RTLD_GLOBAL)\n            print(\"Environment variables indicated a CPU run, but we didn't find `\"+winNoGPUdll+\"`. Trying a GPU run anyway.\")\nelse:\n    lib = CDLL(\"./libdarknet.so\", RTLD_GLOBAL)\nlib.network_width.argtypes = [c_void_p]\nlib.network_width.restype = c_int\nlib.network_height.argtypes = [c_void_p]\nlib.network_height.restype = c_int\n\ncopy_image_from_bytes = lib.copy_image_from_bytes\ncopy_image_from_bytes.argtypes = [IMAGE,c_char_p]\n\ndef network_width(net):\n    return lib.network_width(net)\n\ndef network_height(net):\n    return lib.network_height(net)\n\npredict = lib.network_predict_ptr\npredict.argtypes = [c_void_p, POINTER(c_float)]\npredict.restype = POINTER(c_float)\n\nif hasGPU:\n    set_gpu = lib.cuda_set_device\n    set_gpu.argtypes = [c_int]\n\ninit_cpu = lib.init_cpu\n\nmake_image = lib.make_image\nmake_image.argtypes = [c_int, c_int, c_int]\nmake_image.restype = IMAGE\n\nget_network_boxes = lib.get_network_boxes\nget_network_boxes.argtypes = [c_void_p, c_int, c_int, c_float, c_float, POINTER(c_int), c_int, POINTER(c_int), c_int]\nget_network_boxes.restype = POINTER(DETECTION)\n\nmake_network_boxes = lib.make_network_boxes\nmake_network_boxes.argtypes = [c_void_p]\nmake_network_boxes.restype = POINTER(DETECTION)\n\nfree_detections = lib.free_detections\nfree_detections.argtypes = [POINTER(DETECTION), c_int]\n\nfree_batch_detections = lib.free_batch_detections\nfree_batch_detections.argtypes = [POINTER(DETNUMPAIR), c_int]\n\nfree_ptrs = lib.free_ptrs\nfree_ptrs.argtypes = [POINTER(c_void_p), c_int]\n\nnetwork_predict = lib.network_predict_ptr\nnetwork_predict.argtypes = [c_void_p, POINTER(c_float)]\n\nreset_rnn = lib.reset_rnn\nreset_rnn.argtypes = [c_void_p]\n\nload_net = lib.load_network\nload_net.argtypes = [c_char_p, c_char_p, c_int]\nload_net.restype = c_void_p\n\nload_net_custom = lib.load_network_custom\nload_net_custom.argtypes = [c_char_p, c_char_p, c_int, c_int]\nload_net_custom.restype = c_void_p\n\ndo_nms_obj = lib.do_nms_obj\ndo_nms_obj.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\ndo_nms_sort = lib.do_nms_sort\ndo_nms_sort.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\nfree_image = lib.free_image\nfree_image.argtypes = [IMAGE]\n\nletterbox_image = lib.letterbox_image\nletterbox_image.argtypes = [IMAGE, c_int, c_int]\nletterbox_image.restype = IMAGE\n\nload_meta = lib.get_metadata\nlib.get_metadata.argtypes = [c_char_p]\nlib.get_metadata.restype = METADATA\n\nload_image = lib.load_image_color\nload_image.argtypes = [c_char_p, c_int, c_int]\nload_image.restype = IMAGE\n\nrgbgr_image = lib.rgbgr_image\nrgbgr_image.argtypes = [IMAGE]\n\npredict_image = lib.network_predict_image\npredict_image.argtypes = [c_void_p, IMAGE]\npredict_image.restype = POINTER(c_float)\n\npredict_image_letterbox = lib.network_predict_image_letterbox\npredict_image_letterbox.argtypes = [c_void_p, IMAGE]\npredict_image_letterbox.restype = POINTER(c_float)\n\nnetwork_predict_batch = lib.network_predict_batch\nnetwork_predict_batch.argtypes = [c_void_p, IMAGE, c_int, c_int, c_int,\n                                   c_float, c_float, POINTER(c_int), c_int, c_int]\nnetwork_predict_batch.restype = POINTER(DETNUMPAIR)\n\ndef array_to_image(arr):\n    import numpy as np\n    # need to return old values to avoid python freeing memory\n    arr = arr.transpose(2,0,1)\n    c = arr.shape[0]\n    h = arr.shape[1]\n    w = arr.shape[2]\n    arr = np.ascontiguousarray(arr.flat, dtype=np.float32) / 255.0\n    data = arr.ctypes.data_as(POINTER(c_float))\n    im = IMAGE(w,h,c,data)\n    return im, arr\n\ndef classify(net, meta, im):\n    out = predict_image(net, im)\n    res = []\n    for i in range(meta.classes):\n        if altNames is None:\n            nameTag = meta.names[i]\n        else:\n            nameTag = altNames[i]\n        res.append((nameTag, out[i]))\n    res = sorted(res, key=lambda x: -x[1])\n    return res\n\ndef detect(net, meta, image, thresh=.5, hier_thresh=.5, nms=.45, debug= False):\n    \"\"\"\n    Performs the meat of the detection\n    \"\"\"\n    #pylint: disable= C0321\n    im = load_image(image, 0, 0)\n    if debug: print(\"Loaded image\")\n    ret = detect_image(net, meta, im, thresh, hier_thresh, nms, debug)\n    free_image(im)\n    if debug: print(\"freed image\")\n    return ret\n\ndef detect_image(net, meta, im, thresh=.5, hier_thresh=.5, nms=.45, debug= False):\n    #import cv2\n    #custom_image_bgr = cv2.imread(image) # use: detect(,,imagePath,)\n    #custom_image = cv2.cvtColor(custom_image_bgr, cv2.COLOR_BGR2RGB)\n    #custom_image = cv2.resize(custom_image,(lib.network_width(net), lib.network_height(net)), interpolation = cv2.INTER_LINEAR)\n    #import scipy.misc\n    #custom_image = scipy.misc.imread(image)\n    #im, arr = array_to_image(custom_image)\t\t# you should comment line below: free_image(im)\n    num = c_int(0)\n    if debug: print(\"Assigned num\")\n    pnum = pointer(num)\n    if debug: print(\"Assigned pnum\")\n    predict_image(net, im)\n    letter_box = 0\n    #predict_image_letterbox(net, im)\n    #letter_box = 1\n    if debug: print(\"did prediction\")\n    #dets = get_network_boxes(net, custom_image_bgr.shape[1], custom_image_bgr.shape[0], thresh, hier_thresh, None, 0, pnum, letter_box) # OpenCV\n    dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, None, 0, pnum, letter_box)\n    if debug: print(\"Got dets\")\n    num = pnum[0]\n    if debug: print(\"got zeroth index of pnum\")\n    if nms:\n        do_nms_sort(dets, num, meta.classes, nms)\n    if debug: print(\"did sort\")\n    res = []\n    if debug: print(\"about to range\")\n    for j in range(num):\n        if debug: print(\"Ranging on \"+str(j)+\" of \"+str(num))\n        if debug: print(\"Classes: \"+str(meta), meta.classes, meta.names)\n        for i in range(meta.classes):\n            if debug: print(\"Class-ranging on \"+str(i)+\" of \"+str(meta.classes)+\"= \"+str(dets[j].prob[i]))\n            if dets[j].prob[i] > 0:\n                b = dets[j].bbox\n                if altNames is None:\n                    nameTag = meta.names[i]\n                else:\n                    nameTag = altNames[i]\n                if debug:\n                    print(\"Got bbox\", b)\n                    print(nameTag)\n                    print(dets[j].prob[i])\n                    print((b.x, b.y, b.w, b.h))\n                res.append((nameTag, dets[j].prob[i], (b.x, b.y, b.w, b.h)))\n    if debug: print(\"did range\")\n    res = sorted(res, key=lambda x: -x[1])\n    if debug: print(\"did sort\")\n    free_detections(dets, num)\n    if debug: print(\"freed detections\")\n    return res\n\n\nnetMain = None\nmetaMain = None\naltNames = None\n\ndef performDetect(imagePath=\"data/dog.jpg\", thresh= 0.25, configPath = \"./cfg/yolov3.cfg\", weightPath = \"yolov3.weights\", metaPath= \"./cfg/coco.data\", showImage= True, makeImageOnly = False, initOnly= False):\n    \"\"\"\n    Convenience function to handle the detection and returns of objects.\n\n    Displaying bounding boxes requires libraries scikit-image and numpy\n\n    Parameters\n    ----------------\n    imagePath: str\n        Path to the image to evaluate. Raises ValueError if not found\n\n    thresh: float (default= 0.25)\n        The detection threshold\n\n    configPath: str\n        Path to the configuration file. Raises ValueError if not found\n\n    weightPath: str\n        Path to the weights file. Raises ValueError if not found\n\n    metaPath: str\n        Path to the data file. Raises ValueError if not found\n\n    showImage: bool (default= True)\n        Compute (and show) bounding boxes. Changes return.\n\n    makeImageOnly: bool (default= False)\n        If showImage is True, this won't actually *show* the image, but will create the array and return it.\n\n    initOnly: bool (default= False)\n        Only initialize globals. Don't actually run a prediction.\n\n    Returns\n    ----------------------\n\n\n    When showImage is False, list of tuples like\n        ('obj_label', confidence, (bounding_box_x_px, bounding_box_y_px, bounding_box_width_px, bounding_box_height_px))\n        The X and Y coordinates are from the center of the bounding box. Subtract half the width or height to get the lower corner.\n\n    Otherwise, a dict with\n        {\n            \"detections\": as above\n            \"image\": a numpy array representing an image, compatible with scikit-image\n            \"caption\": an image caption\n        }\n    \"\"\"\n    # Import the global variables. This lets us instance Darknet once, then just call performDetect() again without instancing again\n    global metaMain, netMain, altNames #pylint: disable=W0603\n    assert 0 < thresh < 1, \"Threshold should be a float between zero and one (non-inclusive)\"\n    if not os.path.exists(configPath):\n        raise ValueError(\"Invalid config path `\"+os.path.abspath(configPath)+\"`\")\n    if not os.path.exists(weightPath):\n        raise ValueError(\"Invalid weight path `\"+os.path.abspath(weightPath)+\"`\")\n    if not os.path.exists(metaPath):\n        raise ValueError(\"Invalid data file path `\"+os.path.abspath(metaPath)+\"`\")\n    if netMain is None:\n        netMain = load_net_custom(configPath.encode(\"ascii\"), weightPath.encode(\"ascii\"), 0, 1)  # batch size = 1\n    if metaMain is None:\n        metaMain = load_meta(metaPath.encode(\"ascii\"))\n    if altNames is None:\n        # In Python 3, the metafile default access craps out on Windows (but not Linux)\n        # Read the names file and create a list to feed to detect\n        try:\n            with open(metaPath) as metaFH:\n                metaContents = metaFH.read()\n                import re\n                match = re.search(\"names *= *(.*)$\", metaContents, re.IGNORECASE | re.MULTILINE)\n                if match:\n                    result = match.group(1)\n                else:\n                    result = None\n                try:\n                    if os.path.exists(result):\n                        with open(result) as namesFH:\n                            namesList = namesFH.read().strip().split(\"\\n\")\n                            altNames = [x.strip() for x in namesList]\n                except TypeError:\n                    pass\n        except Exception:\n            pass\n    if initOnly:\n        print(\"Initialized detector\")\n        return None\n    if not os.path.exists(imagePath):\n        raise ValueError(\"Invalid image path `\"+os.path.abspath(imagePath)+\"`\")\n    # Do the detection\n    #detections = detect(netMain, metaMain, imagePath, thresh)\t# if is used cv2.imread(image)\n    detections = detect(netMain, metaMain, imagePath.encode(\"ascii\"), thresh)\n    if showImage:\n        try:\n            from skimage import io, draw\n            import numpy as np\n            image = io.imread(imagePath)\n            print(\"*** \"+str(len(detections))+\" Results, color coded by confidence ***\")\n            imcaption = []\n            for detection in detections:\n                label = detection[0]\n                confidence = detection[1]\n                pstring = label+\": \"+str(np.rint(100 * confidence))+\"%\"\n                imcaption.append(pstring)\n                print(pstring)\n                bounds = detection[2]\n                shape = image.shape\n                # x = shape[1]\n                # xExtent = int(x * bounds[2] / 100)\n                # y = shape[0]\n                # yExtent = int(y * bounds[3] / 100)\n                yExtent = int(bounds[3])\n                xEntent = int(bounds[2])\n                # Coordinates are around the center\n                xCoord = int(bounds[0] - bounds[2]/2)\n                yCoord = int(bounds[1] - bounds[3]/2)\n                boundingBox = [\n                    [xCoord, yCoord],\n                    [xCoord, yCoord + yExtent],\n                    [xCoord + xEntent, yCoord + yExtent],\n                    [xCoord + xEntent, yCoord]\n                ]\n                # Wiggle it around to make a 3px border\n                rr, cc = draw.polygon_perimeter([x[1] for x in boundingBox], [x[0] for x in boundingBox], shape= shape)\n                rr2, cc2 = draw.polygon_perimeter([x[1] + 1 for x in boundingBox], [x[0] for x in boundingBox], shape= shape)\n                rr3, cc3 = draw.polygon_perimeter([x[1] - 1 for x in boundingBox], [x[0] for x in boundingBox], shape= shape)\n                rr4, cc4 = draw.polygon_perimeter([x[1] for x in boundingBox], [x[0] + 1 for x in boundingBox], shape= shape)\n                rr5, cc5 = draw.polygon_perimeter([x[1] for x in boundingBox], [x[0] - 1 for x in boundingBox], shape= shape)\n                boxColor = (int(255 * (1 - (confidence ** 2))), int(255 * (confidence ** 2)), 0)\n                draw.set_color(image, (rr, cc), boxColor, alpha= 0.8)\n                draw.set_color(image, (rr2, cc2), boxColor, alpha= 0.8)\n                draw.set_color(image, (rr3, cc3), boxColor, alpha= 0.8)\n                draw.set_color(image, (rr4, cc4), boxColor, alpha= 0.8)\n                draw.set_color(image, (rr5, cc5), boxColor, alpha= 0.8)\n            if not makeImageOnly:\n                io.imshow(image)\n                io.show()\n            detections = {\n                \"detections\": detections,\n                \"image\": image,\n                \"caption\": \"\\n<br/>\".join(imcaption)\n            }\n        except Exception as e:\n            print(\"Unable to show image: \"+str(e))\n    return detections\n\ndef performBatchDetect(thresh= 0.25, configPath = \"./cfg/yolov3.cfg\", weightPath = \"yolov3.weights\", metaPath= \"./cfg/coco.data\", hier_thresh=.5, nms=.45, batch_size=3):\n    import cv2\n    import numpy as np\n    # NB! Image sizes should be the same\n    # You can change the images, yet, be sure that they have the same width and height\n    img_samples = ['data/person.jpg', 'data/person.jpg', 'data/person.jpg']\n    image_list = [cv2.imread(k) for k in img_samples]\n\n    net = load_net_custom(configPath.encode('utf-8'), weightPath.encode('utf-8'), 0, batch_size)\n    meta = load_meta(metaPath.encode('utf-8'))\n    pred_height, pred_width, c = image_list[0].shape\n    net_width, net_height = (network_width(net), network_height(net))\n    img_list = []\n    for custom_image_bgr in image_list:\n        custom_image = cv2.cvtColor(custom_image_bgr, cv2.COLOR_BGR2RGB)\n        custom_image = cv2.resize(\n            custom_image, (net_width, net_height), interpolation=cv2.INTER_NEAREST)\n        custom_image = custom_image.transpose(2, 0, 1)\n        img_list.append(custom_image)\n\n    arr = np.concatenate(img_list, axis=0)\n    arr = np.ascontiguousarray(arr.flat, dtype=np.float32) / 255.0\n    data = arr.ctypes.data_as(POINTER(c_float))\n    im = IMAGE(net_width, net_height, c, data)\n\n    batch_dets = network_predict_batch(net, im, batch_size, pred_width,\n                                                pred_height, thresh, hier_thresh, None, 0, 0)\n    batch_boxes = []\n    batch_scores = []\n    batch_classes = []\n    for b in range(batch_size):\n        num = batch_dets[b].num\n        dets = batch_dets[b].dets\n        if nms:\n            do_nms_obj(dets, num, meta.classes, nms)\n        boxes = []\n        scores = []\n        classes = []\n        for i in range(num):\n            det = dets[i]\n            score = -1\n            label = None\n            for c in range(det.classes):\n                p = det.prob[c]\n                if p > score:\n                    score = p\n                    label = c\n            if score > thresh:\n                box = det.bbox\n                left, top, right, bottom = map(int,(box.x - box.w / 2, box.y - box.h / 2,\n                                            box.x + box.w / 2, box.y + box.h / 2))\n                boxes.append((top, left, bottom, right))\n                scores.append(score)\n                classes.append(label)\n                boxColor = (int(255 * (1 - (score ** 2))), int(255 * (score ** 2)), 0)\n                cv2.rectangle(image_list[b], (left, top),\n                          (right, bottom), boxColor, 2)\n        cv2.imwrite(os.path.basename(img_samples[b]),image_list[b])\n\n        batch_boxes.append(boxes)\n        batch_scores.append(scores)\n        batch_classes.append(classes)\n    free_batch_detections(batch_dets, batch_size)\n    return batch_boxes, batch_scores, batch_classes    \n\nif __name__ == \"__main__\":\n    print(performDetect())\n    #Uncomment the following line to see batch inference working \n    #print(performBatchDetect())"
        },
        {
          "name": "darknet2caffe",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknet_video.py",
          "type": "blob",
          "size": 3.916015625,
          "content": "from ctypes import *\nimport math\nimport random\nimport os\nimport cv2\nimport numpy as np\nimport time\nimport darknet\n\ndef convertBack(x, y, w, h):\n    xmin = int(round(x - (w / 2)))\n    xmax = int(round(x + (w / 2)))\n    ymin = int(round(y - (h / 2)))\n    ymax = int(round(y + (h / 2)))\n    return xmin, ymin, xmax, ymax\n\n\ndef cvDrawBoxes(detections, img):\n    for detection in detections:\n        x, y, w, h = detection[2][0],\\\n            detection[2][1],\\\n            detection[2][2],\\\n            detection[2][3]\n        xmin, ymin, xmax, ymax = convertBack(\n            float(x), float(y), float(w), float(h))\n        pt1 = (xmin, ymin)\n        pt2 = (xmax, ymax)\n        cv2.rectangle(img, pt1, pt2, (0, 255, 0), 1)\n        cv2.putText(img,\n                    detection[0].decode() +\n                    \" [\" + str(round(detection[1] * 100, 2)) + \"]\",\n                    (pt1[0], pt1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n                    [0, 255, 0], 2)\n    return img\n\n\nnetMain = None\nmetaMain = None\naltNames = None\n\n\ndef YOLO():\n\n    global metaMain, netMain, altNames\n    configPath = \"./cfg/yolov3.cfg\"\n    weightPath = \"./yolov3.weights\"\n    metaPath = \"./cfg/coco.data\"\n    if not os.path.exists(configPath):\n        raise ValueError(\"Invalid config path `\" +\n                         os.path.abspath(configPath)+\"`\")\n    if not os.path.exists(weightPath):\n        raise ValueError(\"Invalid weight path `\" +\n                         os.path.abspath(weightPath)+\"`\")\n    if not os.path.exists(metaPath):\n        raise ValueError(\"Invalid data file path `\" +\n                         os.path.abspath(metaPath)+\"`\")\n    if netMain is None:\n        netMain = darknet.load_net_custom(configPath.encode(\n            \"ascii\"), weightPath.encode(\"ascii\"), 0, 1)  # batch size = 1\n    if metaMain is None:\n        metaMain = darknet.load_meta(metaPath.encode(\"ascii\"))\n    if altNames is None:\n        try:\n            with open(metaPath) as metaFH:\n                metaContents = metaFH.read()\n                import re\n                match = re.search(\"names *= *(.*)$\", metaContents,\n                                  re.IGNORECASE | re.MULTILINE)\n                if match:\n                    result = match.group(1)\n                else:\n                    result = None\n                try:\n                    if os.path.exists(result):\n                        with open(result) as namesFH:\n                            namesList = namesFH.read().strip().split(\"\\n\")\n                            altNames = [x.strip() for x in namesList]\n                except TypeError:\n                    pass\n        except Exception:\n            pass\n    #cap = cv2.VideoCapture(0)\n    cap = cv2.VideoCapture(\"test.mp4\")\n    cap.set(3, 1280)\n    cap.set(4, 720)\n    out = cv2.VideoWriter(\n        \"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 10.0,\n        (darknet.network_width(netMain), darknet.network_height(netMain)))\n    print(\"Starting the YOLO loop...\")\n\n    # Create an image we reuse for each detect\n    darknet_image = darknet.make_image(darknet.network_width(netMain),\n                                    darknet.network_height(netMain),3)\n    while True:\n        prev_time = time.time()\n        ret, frame_read = cap.read()\n        frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)\n        frame_resized = cv2.resize(frame_rgb,\n                                   (darknet.network_width(netMain),\n                                    darknet.network_height(netMain)),\n                                   interpolation=cv2.INTER_LINEAR)\n\n        darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())\n\n        detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.25)\n        image = cvDrawBoxes(detections, frame_resized)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        print(1/(time.time()-prev_time))\n        cv2.imshow('Demo', image)\n        cv2.waitKey(3)\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    YOLO()\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "image_yolov2.sh",
          "type": "blob",
          "size": 0.10546875,
          "content": "\n\n./darknet detector test ./cfg/voc.data ./cfg/yolov2.cfg ./yolov2.weights data/dog.jpg -i 0 -thresh 0.2\n\n\n\n"
        },
        {
          "name": "image_yolov3.sh",
          "type": "blob",
          "size": 0.107421875,
          "content": "\n\n./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights data/dog.jpg -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "json_mjpeg_streams.sh",
          "type": "blob",
          "size": 0.3369140625,
          "content": "# Run this file and then open URL in Chrome/Firefox in 2 tabs: http://localhost:8070 and http://localhost:8090\n# Or open: http://ip-address:8070 and http://ip-address:8090\n# to get <ip-address> run: sudo ifconfig\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output\n\n"
        },
        {
          "name": "net_cam_v3.sh",
          "type": "blob",
          "size": 0.1552734375,
          "content": "#rm test_dnn_out.avi\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights rtsp://admin:admin12345@192.168.0.228:554 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "results",
          "type": "tree",
          "content": null
        },
        {
          "name": "sample",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "video_v2.sh",
          "type": "blob",
          "size": 0.10546875,
          "content": "\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov2.cfg ./yolov2.weights test50.mp4 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "video_yolov3.sh",
          "type": "blob",
          "size": 0.10546875,
          "content": "\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "yoloface-500k",
          "type": "tree",
          "content": null
        },
        {
          "name": "yoloface-50k",
          "type": "tree",
          "content": null
        },
        {
          "name": "yoloface50k-landmark106",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}