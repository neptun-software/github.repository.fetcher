{
  "metadata": {
    "timestamp": 1736710009532,
    "page": 602,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "arnaud-lb/php-rdkafka",
      "stars": 2103,
      "defaultBranch": "7.x",
      "files": [
        {
          "name": ".appveyor.yml",
          "type": "blob",
          "size": 1.193359375,
          "content": "# general configuration\nversion: '{branch}.{build}'\n\n# environment configuration\nimage: Visual Studio 2017\nclone_folder: C:\\projects\\rdkafka\nenvironment:\n  BIN_SDK_VER: 2.2.0\n  DEP: librdkafka-1.5.3\n  matrix:\n    - PHP_VER: 8.1\n      TS: 0\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 0\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n    - PHP_VER: 8.1\n      TS: 1\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 1\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n    - PHP_VER: 8.2\n      TS: 0\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 0\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n    - PHP_VER: 8.2\n      TS: 1\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 1\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n    - PHP_VER: 8.3\n      TS: 0\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 0\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n    - PHP_VER: 8.3\n      TS: 1\n      VC: vs16\n      ARCH: x64\n      OPCACHE: 1\n      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n\ncache:\n  - C:\\build-cache -> .appveyor.yml, .appveyor\\install.ps1\ninstall:\n  - ps: .appveyor\\install.ps1\n\n# build configuration\nbuild_script:\n  - ps: .appveyor\\build.ps1\n\nafter_build:\n  - ps: .appveyor\\package.ps1\n"
        },
        {
          "name": ".appveyor",
          "type": "tree",
          "content": null
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.3095703125,
          "content": "root = true\n\n[*]\ninsert_final_newline = true\n\n[*.{c,h}]\nindent_style = space\nindent_size = 4\n\n[.travis.yml]\nindent_style = space\nindent_size = 4\n\n[*.md]\ntrim_trailing_whitespace = false\n\n[*.phpt]\ntrim_trailing_whitespace = true\nindent_style = space\nindent_size = 4\n\n[package.xml]\nindent_style = space\nindent_size = 1\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.494140625,
          "content": "*.dep\n*.la\n*.lo\n*.swp\n*_legacy_arginfo.h\n.deps\n.libs\nMakefile\nMakefile.fragments\nMakefile.global\nMakefile.objects\nacinclude.m4\naclocal.m4\nautom4te.cache\nbuild\nconfig.guess\nconfig.h\nconfig.h.in\nconfig.h.in~\nconfig.log\nconfig.nice\nconfig.status\nconfig.sub\nconfigure\nconfigure.ac\nconfigure.in\ninclude\ninstall-sh\nlibtool\nltmain.sh\nmissing\nmkinstalldirs\nmodules\npackage.xml\nrdkafka-*.tgz\nrun-tests.php\ngen_stub.php\ntests/*/*.diff\ntests/*/*.exp\ntests/*/*.log\ntests/*/*.out\ntests/*/*.php\ntests/*/*.sh\ntmp-php.ini\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.7021484375,
          "content": "# How to contribute\n\nIf you would like to contribute, thank you :)\n\nHere are a few informations you need to know before starting:\n\n## Branches\n\nPull requests should be made against the 5.x branch, which supports both PHP 7 and PHP 8.\n\n## How to make good contributions\n\n- Before starting to work, maybe open an issue to find whether your change would be accepted.\n- Create relatively small PRs. This is easier to review, and will be merged faster. Do not send huge PRs with multiple unrelated changes.\n- Make sure that you followed the design/style (see bellow).\n- Make sure that your changes do not introduce new compiler warnings or errors.\n- Do not make changes that would break existing code.\n\n## Testing\n\nTests are in phpt file format in the tests directory.\n\n### Using your own machine for building and testing. \n\nTests can be run by following compilation and installation procedure \nand executing `make test`.\n\nTo run integration tests, make sure you have Kafka instance running.\nThen, rename `test_env.php.sample` to `test_env.php` and adjust it\nwith values proper for your kafka instance.\n\n## Design / naming things\n\nphp-rdkafka's goal is to expose the librdkafka APIs to PHP scripts, without\nabstracting it. Rationale:\n\n- Abstractions would be inherently opinionated, which would make the extension\n  less than ideal or unusable in some cases.\n- Abstractions are easily implemented in pure PHP on top of the extension.\n- Remaining close to librdkafka in terms of naming/design makes it possible to\n  refer to librdkafka's documentation and other resources when needed.\n\nAs a result, php-rdkafka will:\n\n - Follow librdkafka's naming for everything\n - Avoid introducing functions, helpers, classes that do not exist in\n   librdkafka (these are easy to implement in pure PHP, on top of the\n   extension).\n\nHowever, in order to make the API PHP-ish, some transformations have to be done.\n\nHere is the full design/style guide:\n\n - For librdkafka functions that return an error type, or signal errors via\n   errno, php-rdkafka throws a Rdkafka\\Exception\n - librdkafka structs are exposed as PHP objects. The object name is derived\n   from the struct name like this:\n   - Remove the `rd_kafka_` prefix\n   - Convert from snake case to camel case\n   - Add `Rdkafka\\` namespace\n - `rd_kafka_*_new` functions are implemented as PHP object constructors / object\n   instantiation\n - `rd_kafka_*_destroy` functions are implemented as PHP object free handlers\n - librdkaka functions that take a struct as first argument are implemented as\n   a method of the struct's related PHP object\n - The user should not be required to manage memory (e.g. free somthing)\n - Do not change librdkafka's default behavior\n - Be safe: No user error should cause a crash or a memory leak.\n\n"
        },
        {
          "name": "CREDITS",
          "type": "blob",
          "size": 0.0234375,
          "content": "rdkafka\nArnaud Le Blanc\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.056640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2015 Arnaud Le Blanc\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.7939453125,
          "content": "# PHP Kafka client - php-rdkafka\n\n[![Join the chat at https://gitter.im/arnaud-lb/php-rdkafka](https://badges.gitter.im/arnaud-lb/php-rdkafka.svg)](https://gitter.im/arnaud-lb/php-rdkafka?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n[![Supported librdkafka versions: >= 0.11](https://img.shields.io/badge/librdkafka-%3E%3D%200.11-blue.svg)](https://github.com/edenhill/librdkafka/releases) [![Supported Kafka versions: >= 0.8](https://img.shields.io/badge/kafka-%3E%3D%200.8-blue.svg)](https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#broker-version-compatibility) ![Supported PHP versions: 7.x .. 8.x](https://img.shields.io/badge/php-7.x%20..%208.x-blue.svg)\n\nPHP-rdkafka is a **stable**, **production-ready**, and **fast** Kafka client for PHP based on [librdkafka](https://github.com/edenhill/librdkafka).\n\nCurrent version supports PHP >= 8.1.0, librdkafka >= 1.5.3, Kafka >= 0.8. Version [6.x](https://github.com/arnaud-lb/php-rdkafka/tree/6.x) supports PHP 7.x..8.x, librdkafka 0.11..2.x. Older versions support PHP 5.\n\nThe goal of the extension is to be a low-level un-opinionated librdkafka binding focused on production and long term support.\n\nThe high level and low level *consumers*, *producer*, and *metadata* APIs are supported.\n\nDocumentation is available [here](https://arnaud-lb.github.io/php-rdkafka/phpdoc/book.rdkafka.html).\n\n## Table of Contents\n\n1. [Installation](#installation)\n2. [Examples](#examples)\n3. [Usage](#usage)\n   * [Producing](#producing)\n   * [High-level consuming](#high-level-consuming)\n   * [Low-level consuming (legacy)](#low-level-consuming-legacy)\n   * [Low-level consuming from multiple topics / partitions (legacy)](#low-level-consuming-from-multiple-topics--partitions-legacy)\n   * [Using stored offsets](#using-stored-offsets)\n   * [Interesting configuration parameters](#interesting-configuration-parameters)\n     * [queued.max.messages.kbytes](#queuedmaxmessageskbytes)\n     * [topic.metadata.refresh.sparse and topic.metadata.refresh.interval.ms](#topicmetadatarefreshsparse-and-topicmetadatarefreshintervalms)\n     * [internal.termination.signal](#internalterminationsignal)\n4. [Documentation](#documentation)\n5. [Credits](#credits)\n6. [License](#license)\n\n## Installation\n\nhttps://arnaud-lb.github.io/php-rdkafka-doc/phpdoc/rdkafka.setup.html\n\n## Examples\n\nhttps://arnaud-lb.github.io/php-rdkafka-doc/phpdoc/rdkafka.examples.html\n\n## Usage\n\nConfiguration parameters used below can be found in [Librdkafka Configuration reference](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)\n\n### Producing\n\n#### Creating a producer\nFor producing, we first need to create a producer, and to add brokers (Kafka\nservers) to it:\n\n``` php\n<?php\n$conf = new RdKafka\\Conf();\n$conf->set('log_level', (string) LOG_DEBUG);\n$conf->set('debug', 'all');\n$rk = new RdKafka\\Producer($conf);\n$rk->addBrokers(\"10.0.0.1:9092,10.0.0.2:9092\");\n```\n\n#### Producing messages\n\n> **Warning** Make sure that your producer follows proper shutdown (see below) to not lose messages.  \n\nNext, we create a topic instance from the producer:\n``` php\n<?php\n\n$topic = $rk->newTopic(\"test\");\n```\n\nFrom there, we can produce as much messages as we want, using the produce\nmethod:\n``` php\n<?php\n\n$topic->produce(RD_KAFKA_PARTITION_UA, 0, \"Message payload\");\n```\nThe first argument is the partition. RD_KAFKA_PARTITION_UA stands for\n*unassigned*, and lets librdkafka choose the partition.  \nThe second argument are message flags and should be either 0  \nor `RD_KAFKA_MSG_F_BLOCK` to block produce on full queue.\nThe message payload can be anything.\n\n#### Proper shutdown\n\nThis should be done prior to destroying a producer instance  \nto make sure all queued and in-flight produce requests are completed  \nbefore terminating. Use a reasonable value for `$timeout_ms`.  \n\n> **Warning** Not calling flush can lead to message loss!\n\n```php\n$rk->flush($timeout_ms);\n```\n\nIn case you don't care about sending messages that haven't been sent yet,\nyou can use `purge()` before calling `flush()`:\n\n```php\n// Forget messages that are not fully sent yet\n$rk->purge(RD_KAFKA_PURGE_F_QUEUE);\n\n$rk->flush($timeout_ms);\n```\n\n### High-level consuming\n\nThe RdKafka\\KafkaConsumer class supports automatic partition assignment/revocation. See the example [here](https://arnaud-lb.github.io/php-rdkafka-doc/phpdoc/rdkafka.examples.html#example-1).\n\n### Low-level consuming (legacy)\n\n> **Note** The low-level consumer is a legacy API, please prefer using the high-level consumer\n\nWe first need to create a low level consumer, and to add brokers (Kafka\nservers) to it:\n\n``` php\n<?php\n$conf = new RdKafka\\Conf();\n$conf->set('log_level', (string) LOG_DEBUG);\n$conf->set('debug', 'all');\n$rk = new RdKafka\\Consumer($conf);\n$rk->addBrokers(\"10.0.0.1,10.0.0.2\");\n```\n\nNext, create a topic instance by calling the `newTopic()` method, and start\nconsuming on partition 0:\n\n``` php\n<?php\n\n$topic = $rk->newTopic(\"test\");\n\n// The first argument is the partition to consume from.\n// The second argument is the offset at which to start consumption. Valid values\n// are: RD_KAFKA_OFFSET_BEGINNING, RD_KAFKA_OFFSET_END, RD_KAFKA_OFFSET_STORED.\n$topic->consumeStart(0, RD_KAFKA_OFFSET_BEGINNING);\n```\n\nNext, retrieve the consumed messages:\n\n``` php\n<?php\n\nwhile (true) {\n    // The first argument is the partition (again).\n    // The second argument is the timeout.\n    $msg = $topic->consume(0, 1000);\n    if (null === $msg || $msg->err === RD_KAFKA_RESP_ERR__PARTITION_EOF) {\n        // Constant check required by librdkafka 0.11.6. Newer librdkafka versions will return NULL instead.\n        continue;\n    } elseif ($msg->err) {\n        echo $msg->errstr(), \"\\n\";\n        break;\n    } else {\n        echo $msg->payload, \"\\n\";\n    }\n}\n```\n\n### Low-level consuming from multiple topics / partitions (legacy)\n\n> **Note** The low-level consumer is a legacy API, please prefer using the high-level consumer\n\nConsuming from multiple topics and/or partitions can be done by telling\nlibrdkafka to forward all messages from these topics/partitions to an internal\nqueue, and then consuming from this queue:\n\nCreating the queue:\n\n``` php\n<?php\n$queue = $rk->newQueue();\n```\n\nAdding topic partitions to the queue:\n\n``` php\n<?php\n\n$topic1 = $rk->newTopic(\"topic1\");\n$topic1->consumeQueueStart(0, RD_KAFKA_OFFSET_BEGINNING, $queue);\n$topic1->consumeQueueStart(1, RD_KAFKA_OFFSET_BEGINNING, $queue);\n\n$topic2 = $rk->newTopic(\"topic2\");\n$topic2->consumeQueueStart(0, RD_KAFKA_OFFSET_BEGINNING, $queue);\n```\n\nNext, retrieve the consumed messages from the queue:\n\n``` php\n<?php\n\nwhile (true) {\n    // The only argument is the timeout.\n    $msg = $queue->consume(1000);\n    if (null === $msg || $msg->err === RD_KAFKA_RESP_ERR__PARTITION_EOF) {\n        // Constant check required by librdkafka 0.11.6. Newer librdkafka versions will return NULL instead.\n        continue;\n    } elseif ($msg->err) {\n        echo $msg->errstr(), \"\\n\";\n        break;\n    } else {\n        echo $msg->payload, \"\\n\";\n    }\n}\n```\n\n### Using stored offsets\n\n#### Broker (default)\nlibrdkafka per default stores offsets on the broker.\n\n#### File offsets (deprecated)\nIf you're using local file for offset storage, then by default the file is created in the current directory, with a\nname based on the topic and the partition. The directory can be changed by setting the ``offset.store.path``\n[configuration property](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md).\n\n### Consumer settings\n\n#### Low-level consumer: auto commit settings\nTo manually control the offset, set `enable.auto.offset.store` to `false`.  \nThe settings `auto.commit.interval.ms` and `auto.commit.enable` will control  \nif the stored offsets will be auto committed to the broker and in which interval.\n\n#### High-level consumer: auto commit settings\nTo manually control the offset, set `enable.auto.commit` to `false`.\n\n#### High level consumer: max.poll.interval.ms\nMaximum allowed time between calls to consume messages for high-level consumers.  \nIf this interval is exceeded the consumer is considered failed and the group will  \nrebalance in order to reassign the partitions to another consumer group member.\n\n#### Consumer group id (general)\n`group.id` is responsible for setting your consumer group ID and it should be unique (and should\nnot change). Kafka uses it to recognize applications and store offsets for them.\n\n``` php\n<?php\n\n$topicConf = new RdKafka\\TopicConf();\n$topicConf->set(\"auto.commit.interval.ms\", 1e3);\n\n$topic = $rk->newTopic(\"test\", $topicConf);\n\n$topic->consumeStart(0, RD_KAFKA_OFFSET_STORED);\n```\n\n### Interesting configuration parameters\n\n[Librdkafka Configuration reference](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)\n\n#### queued.max.messages.kbytes\n\nlibrdkafka will buffer up to 1GB of messages for each consumed partition by default. You can lower memory usage by reducing the value of the ``queued.max.messages.kbytes`` parameter on your consumers.\n\n### topic.metadata.refresh.sparse and topic.metadata.refresh.interval.ms\n\nEach consumer and producer instance will fetch topics metadata at an interval defined by the ``topic.metadata.refresh.interval.ms`` parameter. Depending on your librdkafka version, the parameter defaults to 10 seconds, or 600 seconds.\n\nlibrdkafka fetches the metadata for all topics of the cluster by default. Setting ``topic.metadata.refresh.sparse`` to the string ``\"true\"`` makes sure that librdkafka fetches only the topics he uses.\n\nSetting ``topic.metadata.refresh.sparse`` to ``\"true\"``, and ``topic.metadata.refresh.interval.ms`` to 600 seconds (plus some jitter) can reduce the bandwidth a lot, depending on the number of consumers and topics.\n\n### internal.termination.signal\n\nThis setting allows librdkafka threads to terminate as soon as librdkafka is done with them. This effectively allows your PHP processes / requests to terminate quickly.\n\nWhen enabling this, you have to mask the signal like this:\n\n``` php\n<?php\n// once\npcntl_sigprocmask(SIG_BLOCK, array(SIGIO));\n// any time\n$conf->set('internal.termination.signal', SIGIO);\n```\n\n### socket.blocking.max.ms (librdkafka < 1.0.0)\n\n> Maximum time a broker socket operation may block. A lower value improves responsiveness at the expense of slightly higher CPU usage.\n\nReducing the value of this setting improves shutdown speed. The value defines the maximum time librdkafka will block in one iteration of a read loop. This also defines how often the main librdkafka thread will check for termination.\n\n### queue.buffering.max.ms\n\nThis defines the maximum and default time librdkafka will wait before sending a batch of messages. Reducing this setting to e.g. 1ms ensures that messages are sent ASAP, instead of being batched.\n\nThis has been seen to reduce the shutdown time of the rdkafka instance, and of the PHP process / request.\n\n## Performance / Low-latency settings\n\nHere is a configuration optimized for low latency. This allows a PHP process / request to send messages ASAP and to terminate quickly.\n\n``` php\n<?php\n\n$conf = new \\RdKafka\\Conf();\n$conf->set('socket.timeout.ms', 50); // or socket.blocking.max.ms, depending on librdkafka version\nif (function_exists('pcntl_sigprocmask')) {\n    pcntl_sigprocmask(SIG_BLOCK, array(SIGIO));\n    $conf->set('internal.termination.signal', SIGIO);\n} else {\n    $conf->set('queue.buffering.max.ms', 1);\n}\n\n$producer = new \\RdKafka\\Producer($conf);\n$consumer = new \\RdKafka\\Consumer($conf);\n```\n\nIt is advised to call poll at regular intervals to serve callbacks. In `php-rdkafka:3.x`  \npoll was also called during shutdown, so not calling it in regular intervals might  \nlead to a slightly longer shutdown. The example below polls until there are no more events in the queue:\n\n```\n$producer->produce(...);\nwhile ($producer->getOutQLen() > 0) {\n    $producer->poll(1);\n}\n```\n\n## Documentation\n\nhttps://arnaud-lb.github.io/php-rdkafka-doc/phpdoc/book.rdkafka.html  \nThe source of the documentation can be found [here](https://github.com/arnaud-lb/php-rdkafka-doc)\n\n## Asking for Help\n\nIf the documentation is not enough, feel free to ask a questions on the php-rdkafka channels on [Gitter](https://gitter.im/arnaud-lb/php-rdkafka) or [Google Groups](https://groups.google.com/forum/#!forum/php-rdkafka).\n\n## Stubs\n\nBecause your IDE is not able to auto discover php-rdkadka api you can consider usage of external package providing a set of stubs for php-rdkafka classes, functions and constants: [kwn/php-rdkafka-stubs](https://github.com/kwn/php-rdkafka-stubs)\n\n## Contributing\n\nIf you would like to contribute, thank you :)\n\nBefore you start, please take a look at the [CONTRIBUTING document](https://github.com/arnaud-lb/php-rdkafka/blob/master/CONTRIBUTING.md) to see how to get your changes merged in.\n\n## Credits\n\nDocumentation copied from [librdkafka](https://github.com/edenhill/librdkafka).\n\nAuthors: see [contributors](https://github.com/arnaud-lb/php-rdkafka/graphs/contributors).\n\n## License\n\nphp-rdkafka is released under the [MIT](https://github.com/arnaud-lb/php-rdkafka/blob/master/LICENSE) license.\n"
        },
        {
          "name": "composer.json",
          "type": "blob",
          "size": 0.4287109375,
          "content": "{\n    \"name\": \"rdkafka/rdkafka\",\n    \"type\": \"php-ext\",\n    \"license\": \"MIT\",\n    \"description\": \"A PHP extension for Kafka\",\n    \"require\": {\n        \"php\": \">= 8.1.0\"\n    },\n    \"php-ext\": {\n        \"extension-name\": \"rdkafka\",\n        \"configure-options\": [\n            {\n                \"name\": \"with-rdkafka\",\n                \"description\": \"Use system librdkafka\",\n                \"needs-value\": true\n            }\n        ]\n    }\n}\n"
        },
        {
          "name": "conf.c",
          "type": "blob",
          "size": 22.490234375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_ini.h\"\n#include \"ext/standard/info.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n#include \"conf.h\"\n#include \"topic_partition.h\"\n#include \"message.h\"\n#include \"conf_arginfo.h\"\n\nzend_class_entry * ce_kafka_conf;\nzend_class_entry * ce_kafka_topic_conf;\n\nstatic zend_object_handlers handlers;\n\nstatic void kafka_conf_callback_dtor(kafka_conf_callback *cb) /* {{{ */\n{\n    if (cb) {\n        zval_ptr_dtor(&cb->fci.function_name);\n        efree(cb);\n    }\n} /* }}} */\n\nvoid kafka_conf_callbacks_dtor(kafka_conf_callbacks *cbs) /* {{{ */\n{\n    kafka_conf_callback_dtor(cbs->error);\n    cbs->error = NULL;\n    kafka_conf_callback_dtor(cbs->rebalance);\n    cbs->rebalance = NULL;\n    kafka_conf_callback_dtor(cbs->dr_msg);\n    cbs->dr_msg = NULL;\n    kafka_conf_callback_dtor(cbs->stats);\n    cbs->stats = NULL;\n    kafka_conf_callback_dtor(cbs->consume);\n    cbs->consume = NULL;\n    kafka_conf_callback_dtor(cbs->offset_commit);\n    cbs->offset_commit = NULL;\n    kafka_conf_callback_dtor(cbs->log);\n    cbs->log = NULL;\n    kafka_conf_callback_dtor(cbs->oauthbearer_token_refresh);\n    cbs->oauthbearer_token_refresh = NULL;\n} /* }}} */\n\nstatic void kafka_conf_callback_copy(kafka_conf_callback **to, kafka_conf_callback *from) /* {{{ */\n{\n    if (from) {\n        *to = emalloc(sizeof(**to));\n        **to = *from;\n        zval_copy_ctor(&(*to)->fci.function_name);\n    }\n} /* }}} */\n\nvoid kafka_conf_callbacks_copy(kafka_conf_callbacks *to, kafka_conf_callbacks *from) /* {{{ */\n{\n    kafka_conf_callback_copy(&to->oauthbearer_token_refresh, from->oauthbearer_token_refresh);\n    kafka_conf_callback_copy(&to->error, from->error);\n    kafka_conf_callback_copy(&to->rebalance, from->rebalance);\n    kafka_conf_callback_copy(&to->dr_msg, from->dr_msg);\n    kafka_conf_callback_copy(&to->stats, from->stats);\n    kafka_conf_callback_copy(&to->consume, from->consume);\n    kafka_conf_callback_copy(&to->offset_commit, from->offset_commit);\n    kafka_conf_callback_copy(&to->log, from->log);\n} /* }}} */\n\nstatic void kafka_conf_free(zend_object *object) /* {{{ */\n{\n    kafka_conf_object *intern = php_kafka_from_obj(kafka_conf_object, object);\n\n    switch (intern->type) {\n        case KAFKA_CONF:\n            if (intern->u.conf) {\n                rd_kafka_conf_destroy(intern->u.conf);\n            }\n            kafka_conf_callbacks_dtor(&intern->cbs);\n            break;\n        case KAFKA_TOPIC_CONF:\n            if (intern->u.topic_conf) {\n                rd_kafka_topic_conf_destroy(intern->u.topic_conf);\n            }\n            break;\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *kafka_conf_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    kafka_conf_object *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nkafka_conf_object * get_kafka_conf_object(zval *zconf)\n{\n    kafka_conf_object *oconf = Z_RDKAFKA_P(kafka_conf_object, zconf);\n\n    if (!oconf->type) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Conf::__construct() has not been called\");\n        return NULL;\n    }\n\n    return oconf;\n}\n\nstatic void kafka_conf_error_cb(rd_kafka_t *rk, int err, const char *reason, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[3];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cbs->error) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n    ZVAL_NULL(&args[2]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n    ZVAL_LONG(&args[1], err);\n    ZVAL_STRING(&args[2], reason);\n\n    rdkafka_call_function(&cbs->error->fci, &cbs->error->fcc, NULL, 3, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n    zval_ptr_dtor(&args[2]);\n}\n\nvoid kafka_conf_dr_msg_cb(rd_kafka_t *rk, const rd_kafka_message_t *msg, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zend_string *msg_opaque = msg->_private;\n    zval args[2];\n\n    if (cbs != NULL && cbs->dr_msg) {\n        ZVAL_NULL(&args[0]);\n        ZVAL_NULL(&args[1]);\n\n        ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n        kafka_message_new(&args[1], msg, msg_opaque);\n\n        rdkafka_call_function(&cbs->dr_msg->fci, &cbs->dr_msg->fcc, NULL, 2, args);\n\n        zval_ptr_dtor(&args[0]);\n        zval_ptr_dtor(&args[1]);\n    }\n\n    if (msg_opaque != NULL) {\n        zend_string_release(msg_opaque);\n    }\n}\n\nstatic int kafka_conf_stats_cb(rd_kafka_t *rk, char *json, size_t json_len, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[3];\n\n    if (!opaque) {\n        return 0;\n    }\n\n    if (!cbs->stats) {\n        return 0;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n    ZVAL_NULL(&args[2]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n    ZVAL_STRING(&args[1], json);\n    ZVAL_LONG(&args[2], json_len);\n\n    rdkafka_call_function(&cbs->stats->fci, &cbs->stats->fcc, NULL, 3, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n    zval_ptr_dtor(&args[2]);\n\n    return 0;\n}\n\nstatic void kafka_conf_rebalance_cb(rd_kafka_t *rk, rd_kafka_resp_err_t err, rd_kafka_topic_partition_list_t *partitions, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[3];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cbs->rebalance) {\n        err = rd_kafka_assign(rk, NULL);\n\n        if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n            zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n            return;\n        }\n\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n    ZVAL_NULL(&args[2]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n    ZVAL_LONG(&args[1], err);\n    kafka_topic_partition_list_to_array(&args[2], partitions);\n\n    rdkafka_call_function(&cbs->rebalance->fci, &cbs->rebalance->fcc, NULL, 3, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n    zval_ptr_dtor(&args[2]);\n}\n\nstatic void kafka_conf_consume_cb(rd_kafka_message_t *msg, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[2];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cbs->consume) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n\n    kafka_message_new(&args[0], msg, NULL);\n    ZVAL_ZVAL(&args[1], &cbs->zrk, 1, 0);\n\n\n    rdkafka_call_function(&cbs->consume->fci, &cbs->consume->fcc, NULL, 2, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n}\n\nstatic void kafka_conf_offset_commit_cb(rd_kafka_t *rk, rd_kafka_resp_err_t err, rd_kafka_topic_partition_list_t *partitions, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[3];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cbs->offset_commit) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n    ZVAL_NULL(&args[2]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n    ZVAL_LONG(&args[1], err);\n    kafka_topic_partition_list_to_array(&args[2], partitions);\n\n    rdkafka_call_function(&cbs->offset_commit->fci, &cbs->offset_commit->fcc, NULL, 3, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n    zval_ptr_dtor(&args[2]);\n}\n\nstatic void kafka_conf_log_cb(const rd_kafka_t *rk, int level, const char *facility, const char *message)\n{\n    zval args[4];\n\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) rd_kafka_opaque(rk);\n\n    if (!cbs->log) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n    ZVAL_NULL(&args[2]);\n    ZVAL_NULL(&args[3]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n    ZVAL_LONG(&args[1], level);\n    ZVAL_STRING(&args[2], facility);\n    ZVAL_STRING(&args[3], message);\n\n    rdkafka_call_function(&cbs->log->fci, &cbs->log->fcc, NULL, 4, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n    zval_ptr_dtor(&args[2]);\n    zval_ptr_dtor(&args[3]);\n}\n\n/* \nvoid rd_kafka_conf_set_oauthbearer_token_refresh_cb(\n    rd_kafka_conf_t *conf,\n    void (*oauthbearer_token_refresh_cb)(rd_kafka_t *rk,\n                                         const char *oauthbearer_config,\n                                         void *opaque)) {\n}*/\nstatic void kafka_conf_set_oauthbearer_token_refresh_cb(rd_kafka_t *rk, const char *oauthbearer_config, void *opaque)\n{\n    kafka_conf_callbacks *cbs = (kafka_conf_callbacks*) opaque;\n    zval args[2];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cbs->oauthbearer_token_refresh) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n    ZVAL_NULL(&args[1]);\n\n    ZVAL_ZVAL(&args[0], &cbs->zrk, 1, 0);\n\n    if (oauthbearer_config) {\n        ZVAL_STRING(&args[1], oauthbearer_config);\n    }\n\n    rdkafka_call_function(&cbs->oauthbearer_token_refresh->fci, &cbs->oauthbearer_token_refresh->fcc, NULL, 2, args);\n\n    zval_ptr_dtor(&args[0]);\n    zval_ptr_dtor(&args[1]);\n}\n\n/* {{{ proto RdKafka\\Conf::__construct() */\nPHP_METHOD(RdKafka_Conf, __construct)\n{\n    kafka_conf_object *intern;\n    zend_error_handling error_handling;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(kafka_conf_object, getThis());\n    intern->type = KAFKA_CONF;\n    intern->u.conf = rd_kafka_conf_new();\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto array RfKafka\\Conf::dump()\n   Dump the configuration properties and values of `conf` to an array */\nPHP_METHOD(RdKafka_Conf, dump)\n{\n    size_t cntp;\n    const char **dump;\n    kafka_conf_object *intern;\n    size_t i;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    switch (intern->type) {\n        case KAFKA_CONF:\n            dump = rd_kafka_conf_dump(intern->u.conf, &cntp);\n            break;\n        case KAFKA_TOPIC_CONF:\n            dump = rd_kafka_topic_conf_dump(intern->u.topic_conf, &cntp);\n            break;\n        default:\n            return;\n    }\n\n    array_init(return_value);\n\n    for (i = 0; i < cntp; i+=2) {\n        const char *key = dump[i];\n        const char *value = dump[i+1];\n        add_assoc_string(return_value, (char*)key, (char*)value);\n    }\n\n    rd_kafka_conf_dump_free(dump, cntp);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::set(string $name, string $value)\n   Sets a configuration property. */\nPHP_METHOD(RdKafka_Conf, set)\n{\n    char *name;\n    size_t name_len;\n    char *value;\n    size_t value_len;\n    kafka_conf_object *intern;\n    rd_kafka_conf_res_t ret = 0;\n    char errstr[512];\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"ss\", &name, &name_len, &value, &value_len) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    errstr[0] = '\\0';\n\n    switch (intern->type) {\n        case KAFKA_CONF:\n            ret = rd_kafka_conf_set(intern->u.conf, name, value, errstr, sizeof(errstr));\n            break;\n        case KAFKA_TOPIC_CONF:\n            ret = rd_kafka_topic_conf_set(intern->u.topic_conf, name, value, errstr, sizeof(errstr));\n            break;\n    }\n\n    switch (ret) {\n        case RD_KAFKA_CONF_UNKNOWN:\n            zend_throw_exception(ce_kafka_exception, errstr, RD_KAFKA_CONF_UNKNOWN);\n            return;\n        case RD_KAFKA_CONF_INVALID:\n            zend_throw_exception(ce_kafka_exception, errstr, RD_KAFKA_CONF_INVALID);\n            return;\n        case RD_KAFKA_CONF_OK:\n            break;\n    }\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Conf::setDefaultTopicConf(RdKafka\\TopicConf $topicConf) */\nPHP_METHOD(RdKafka_Conf, setDefaultTopicConf)\n{\n    zval *ztopic_conf;\n    kafka_conf_object *intern;\n    kafka_conf_object *topic_conf_intern;\n    rd_kafka_topic_conf_t *topic_conf;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"O\", &ztopic_conf, ce_kafka_topic_conf) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topic_conf_intern = get_kafka_conf_object(ztopic_conf);\n    if (!topic_conf_intern) {\n        return;\n    }\n\n    topic_conf = rd_kafka_topic_conf_dup(topic_conf_intern->u.topic_conf);\n\n    rd_kafka_conf_set_default_topic_conf(intern->u.conf, topic_conf);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setErrorCb(callable $callback)\n   Sets the error callback */\nPHP_METHOD(RdKafka_Conf, setErrorCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.error) {\n        zval_ptr_dtor(&intern->cbs.error->fci.function_name);\n    } else {\n        intern->cbs.error = ecalloc(1, sizeof(*intern->cbs.error));\n    }\n\n    intern->cbs.error->fci = fci;\n    intern->cbs.error->fcc = fcc;\n\n    rd_kafka_conf_set_error_cb(intern->u.conf, kafka_conf_error_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setDrMsgCb(callable $callback)\n   Sets the delivery report callback */\nPHP_METHOD(RdKafka_Conf, setDrMsgCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.dr_msg) {\n        zval_ptr_dtor(&intern->cbs.dr_msg->fci.function_name);\n    } else {\n        intern->cbs.dr_msg = ecalloc(1, sizeof(*intern->cbs.dr_msg));\n    }\n\n    intern->cbs.dr_msg->fci = fci;\n    intern->cbs.dr_msg->fcc = fcc;\n\n    rd_kafka_conf_set_dr_msg_cb(intern->u.conf, kafka_conf_dr_msg_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setStatsCb(callable $callback)\n   Sets the statistics report callback */\nPHP_METHOD(RdKafka_Conf, setStatsCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.stats) {\n        zval_ptr_dtor(&intern->cbs.stats->fci.function_name);\n    } else {\n        intern->cbs.stats = ecalloc(1, sizeof(*intern->cbs.stats));\n    }\n\n    intern->cbs.stats->fci = fci;\n    intern->cbs.stats->fcc = fcc;\n\n    rd_kafka_conf_set_stats_cb(intern->u.conf, kafka_conf_stats_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setRebalanceCb(mixed $callback)\n   Set rebalance callback for use with coordinated consumer group balancing */\nPHP_METHOD(RdKafka_Conf, setRebalanceCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.rebalance) {\n        zval_ptr_dtor(&intern->cbs.rebalance->fci.function_name);\n    } else {\n        intern->cbs.rebalance = ecalloc(1, sizeof(*intern->cbs.rebalance));\n    }\n\n    intern->cbs.rebalance->fci = fci;\n    intern->cbs.rebalance->fcc = fcc;\n\n    rd_kafka_conf_set_rebalance_cb(intern->u.conf, kafka_conf_rebalance_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setConsumeCb(callable $callback)\n   Set consume callback to use with poll */\nPHP_METHOD(RdKafka_Conf, setConsumeCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.consume) {\n        zval_ptr_dtor(&intern->cbs.consume->fci.function_name);\n    } else {\n        intern->cbs.consume = ecalloc(1, sizeof(*intern->cbs.consume));\n    }\n\n    intern->cbs.consume->fci = fci;\n    intern->cbs.consume->fcc = fcc;\n\n    rd_kafka_conf_set_consume_cb(intern->u.conf, kafka_conf_consume_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setOffsetCommitCb(mixed $callback)\n   Set offset commit callback for use with consumer groups */\nPHP_METHOD(RdKafka_Conf, setOffsetCommitCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (intern->cbs.offset_commit) {\n        zval_ptr_dtor(&intern->cbs.offset_commit->fci.function_name);\n    } else {\n        intern->cbs.offset_commit = ecalloc(1, sizeof(*intern->cbs.offset_commit));\n    }\n\n    intern->cbs.offset_commit->fci = fci;\n    intern->cbs.offset_commit->fcc = fcc;\n\n    rd_kafka_conf_set_offset_commit_cb(intern->u.conf, kafka_conf_offset_commit_cb);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setLogCb(mixed $callback)\n   Set offset commit callback for use with consumer groups */\nPHP_METHOD(RdKafka_Conf, setLogCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *conf;\n    char errstr[512];\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    conf = get_kafka_conf_object(getThis());\n    if (!conf) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (conf->cbs.log) {\n        zval_ptr_dtor(&conf->cbs.log->fci.function_name);\n    } else {\n        conf->cbs.log = ecalloc(1, sizeof(*conf->cbs.log));\n    }\n\n    conf->cbs.log->fci = fci;\n    conf->cbs.log->fcc = fcc;\n\n    rd_kafka_conf_set_log_cb(conf->u.conf, kafka_conf_log_cb);\n    rd_kafka_conf_set(conf->u.conf, \"log.queue\", \"true\", errstr, sizeof(errstr));\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Conf::setOauthbearerTokenRefreshCb(mixed $callback)\n   Set token refresh callback for OAUTHBEARER sasl */\nPHP_METHOD(RdKafka_Conf, setOauthbearerTokenRefreshCb)\n{\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n    kafka_conf_object *conf;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"f\", &fci, &fcc) == FAILURE) {\n        return;\n    }\n\n    conf = get_kafka_conf_object(getThis());\n    if (!conf) {\n        return;\n    }\n\n    Z_ADDREF_P(&fci.function_name);\n\n    if (conf->cbs.oauthbearer_token_refresh) {\n        zval_ptr_dtor(&conf->cbs.oauthbearer_token_refresh->fci.function_name);\n    } else {\n        conf->cbs.oauthbearer_token_refresh = ecalloc(1, sizeof(*conf->cbs.oauthbearer_token_refresh));\n    }\n\n    conf->cbs.oauthbearer_token_refresh->fci = fci;\n    conf->cbs.oauthbearer_token_refresh->fcc = fcc;\n\n    rd_kafka_conf_set_oauthbearer_token_refresh_cb(conf->u.conf, kafka_conf_set_oauthbearer_token_refresh_cb);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicConf::__construct() */\nPHP_METHOD(RdKafka_TopicConf, __construct)\n{\n    kafka_conf_object *intern;\n    zend_error_handling error_handling;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(kafka_conf_object, getThis());\n    intern->type = KAFKA_TOPIC_CONF;\n    intern->u.topic_conf = rd_kafka_topic_conf_new();\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicConf::setPartitioner(int $partitioner) */\nPHP_METHOD(RdKafka_TopicConf, setPartitioner)\n{\n    kafka_conf_object *intern;\n    zend_long id;\n    int32_t (*partitioner) (const rd_kafka_topic_t * rkt, const void * keydata, size_t keylen, int32_t partition_cnt, void * rkt_opaque, void * msg_opaque);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &id) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_conf_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    switch (id) {\n        case MSG_PARTITIONER_RANDOM:\n            partitioner = rd_kafka_msg_partitioner_random;\n            break;\n        case MSG_PARTITIONER_CONSISTENT:\n            partitioner = rd_kafka_msg_partitioner_consistent;\n            break;\n        case MSG_PARTITIONER_CONSISTENT_RANDOM:\n            partitioner = rd_kafka_msg_partitioner_consistent_random;\n            break;\n        case MSG_PARTITIONER_MURMUR2:\n            partitioner = rd_kafka_msg_partitioner_murmur2;\n            break;\n        case MSG_PARTITIONER_MURMUR2_RANDOM:\n            partitioner = rd_kafka_msg_partitioner_murmur2_random;\n            break;\n        default:\n            zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Invalid partitioner given\");\n            return;\n    }\n\n    rd_kafka_topic_conf_set_partitioner_cb(intern->u.topic_conf, partitioner);\n}\n/* }}} */\n\nvoid kafka_conf_minit(INIT_FUNC_ARGS)\n{\n    handlers = kafka_default_object_handlers;\n    handlers.free_obj = kafka_conf_free;\n    handlers.offset = XtOffsetOf(kafka_conf_object, std);\n\n    ce_kafka_conf = register_class_RdKafka_Conf();\n    ce_kafka_conf->create_object = kafka_conf_new;\n\n    ce_kafka_topic_conf = register_class_RdKafka_TopicConf();\n    ce_kafka_topic_conf->create_object = kafka_conf_new;\n}\n"
        },
        {
          "name": "conf.h",
          "type": "blob",
          "size": 2.58984375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifndef KAFKA_CONF_H\n#define KAFKA_CONF_H\n\nenum {\n        MSG_PARTITIONER_RANDOM = 2,\n        MSG_PARTITIONER_CONSISTENT = 3,\n        MSG_PARTITIONER_CONSISTENT_RANDOM = 4,\n        MSG_PARTITIONER_MURMUR2 = 5,\n        MSG_PARTITIONER_MURMUR2_RANDOM = 6\n};\n\ntypedef enum {\n    KAFKA_CONF = 1,\n    KAFKA_TOPIC_CONF\n} kafka_conf_type;\n\ntypedef struct _kafka_conf_callback {\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n} kafka_conf_callback;\n\ntypedef struct _kafka_conf_callbacks {\n    zval zrk;\n    kafka_conf_callback *error;\n    kafka_conf_callback *rebalance;\n    kafka_conf_callback *dr_msg;\n    kafka_conf_callback *stats;\n    kafka_conf_callback *consume;\n    kafka_conf_callback *offset_commit;\n    kafka_conf_callback *log;\n    kafka_conf_callback *oauthbearer_token_refresh;\n} kafka_conf_callbacks;\n\ntypedef struct _kafka_conf_object {\n    kafka_conf_type type;\n    union {\n        rd_kafka_conf_t         *conf;\n        rd_kafka_topic_conf_t   *topic_conf;\n    } u;\n    kafka_conf_callbacks cbs;\n    zend_object                 std;\n} kafka_conf_object;\n\nkafka_conf_object * get_kafka_conf_object(zval *zconf);\nvoid kafka_conf_minit(INIT_FUNC_ARGS);\n\nvoid kafka_conf_callbacks_dtor(kafka_conf_callbacks *cbs);\nvoid kafka_conf_callbacks_copy(kafka_conf_callbacks *to, kafka_conf_callbacks *from);\n\nvoid kafka_conf_dr_msg_cb(rd_kafka_t *rk, const rd_kafka_message_t *msg, void *opaque);\n\nextern zend_class_entry * ce_kafka_conf;\nextern zend_class_entry * ce_kafka_topic_conf;\n\n#endif /* KAFKA_CONF_H */\n"
        },
        {
          "name": "conf.stub.php",
          "type": "blob",
          "size": 1.671875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass Conf\n{\n    public function __construct() {}\n\n    /** @tentative-return-type */\n    public function dump(): array {}\n\n    /** @tentative-return-type */\n    public function set(string $name, string $value): void {}\n\n    /**\n     * @tentative-return-type\n     * @deprecated\n     */\n    public function setDefaultTopicConf(TopicConf $topic_conf): void {}\n\n    /** @tentative-return-type */\n    public function setErrorCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setDrMsgCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setStatsCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setRebalanceCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setConsumeCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setOffsetCommitCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setLogCb(callable $callback): void {}\n\n    /** @tentative-return-type */\n    public function setOauthbearerTokenRefreshCb(callable $callback): void {}\n}\n\nclass TopicConf\n{\n    public function __construct() {}\n\n    /**\n     * @tentative-return-type\n     * @implementation-alias RdKafka\\Conf::dump\n     */\n    public function dump(): array {}\n\n    /**\n     * @tentative-return-type\n     * @implementation-alias RdKafka\\Conf::set\n     */\n    public function set(string $name, string $value): void {}\n\n    /** @tentative-return-type */\n    public function setPartitioner(int $partitioner): void {}\n}\n"
        },
        {
          "name": "conf_arginfo.h",
          "type": "blob",
          "size": 5.2666015625,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 4bdaeef0f9a2a0194b1f800100ff14793cf6980a */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Conf___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Conf_dump, 0, 0, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Conf_dump, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Conf_set, 0, 2, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Conf_set, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, name, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, value, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Conf_setDefaultTopicConf, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Conf_setDefaultTopicConf, 0, 0, 1)\n#endif\n\tZEND_ARG_OBJ_INFO(0, topic_conf, RdKafka\\\\TopicConf, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Conf_setErrorCb, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Conf_setErrorCb, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, callback, IS_CALLABLE, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Conf_setDrMsgCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setStatsCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setRebalanceCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setConsumeCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setOffsetCommitCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setLogCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_Conf_setOauthbearerTokenRefreshCb arginfo_class_RdKafka_Conf_setErrorCb\n\n#define arginfo_class_RdKafka_TopicConf___construct arginfo_class_RdKafka_Conf___construct\n\n#define arginfo_class_RdKafka_TopicConf_dump arginfo_class_RdKafka_Conf_dump\n\n#define arginfo_class_RdKafka_TopicConf_set arginfo_class_RdKafka_Conf_set\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_TopicConf_setPartitioner, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_TopicConf_setPartitioner, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partitioner, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka_Conf, __construct);\nZEND_METHOD(RdKafka_Conf, dump);\nZEND_METHOD(RdKafka_Conf, set);\nZEND_METHOD(RdKafka_Conf, setDefaultTopicConf);\nZEND_METHOD(RdKafka_Conf, setErrorCb);\nZEND_METHOD(RdKafka_Conf, setDrMsgCb);\nZEND_METHOD(RdKafka_Conf, setStatsCb);\nZEND_METHOD(RdKafka_Conf, setRebalanceCb);\nZEND_METHOD(RdKafka_Conf, setConsumeCb);\nZEND_METHOD(RdKafka_Conf, setOffsetCommitCb);\nZEND_METHOD(RdKafka_Conf, setLogCb);\nZEND_METHOD(RdKafka_Conf, setOauthbearerTokenRefreshCb);\nZEND_METHOD(RdKafka_TopicConf, __construct);\nZEND_METHOD(RdKafka_TopicConf, setPartitioner);\n\n\nstatic const zend_function_entry class_RdKafka_Conf_methods[] = {\n\tZEND_ME(RdKafka_Conf, __construct, arginfo_class_RdKafka_Conf___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, dump, arginfo_class_RdKafka_Conf_dump, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, set, arginfo_class_RdKafka_Conf_set, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setDefaultTopicConf, arginfo_class_RdKafka_Conf_setDefaultTopicConf, ZEND_ACC_PUBLIC|ZEND_ACC_DEPRECATED)\n\tZEND_ME(RdKafka_Conf, setErrorCb, arginfo_class_RdKafka_Conf_setErrorCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setDrMsgCb, arginfo_class_RdKafka_Conf_setDrMsgCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setStatsCb, arginfo_class_RdKafka_Conf_setStatsCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setRebalanceCb, arginfo_class_RdKafka_Conf_setRebalanceCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setConsumeCb, arginfo_class_RdKafka_Conf_setConsumeCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setOffsetCommitCb, arginfo_class_RdKafka_Conf_setOffsetCommitCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setLogCb, arginfo_class_RdKafka_Conf_setLogCb, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Conf, setOauthbearerTokenRefreshCb, arginfo_class_RdKafka_Conf_setOauthbearerTokenRefreshCb, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_TopicConf_methods[] = {\n\tZEND_ME(RdKafka_TopicConf, __construct, arginfo_class_RdKafka_TopicConf___construct, ZEND_ACC_PUBLIC)\n\tZEND_MALIAS(RdKafka_Conf, dump, dump, arginfo_class_RdKafka_TopicConf_dump, ZEND_ACC_PUBLIC)\n\tZEND_MALIAS(RdKafka_Conf, set, set, arginfo_class_RdKafka_TopicConf_set, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicConf, setPartitioner, arginfo_class_RdKafka_TopicConf_setPartitioner, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Conf(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Conf\", class_RdKafka_Conf_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_TopicConf(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"TopicConf\", class_RdKafka_TopicConf_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "config.m4",
          "type": "blob",
          "size": 2.146484375,
          "content": "dnl $Id$\ndnl config.m4 for extension rdkafka\n\nPHP_ARG_WITH(rdkafka, for rdkafka support,\n[  --with-rdkafka             Include rdkafka support])\n\nif test \"$PHP_RDKAFKA\" != \"no\"; then\n\n  SEARCH_PATH=\"/usr/local /usr\"     # you might want to change this\n  SEARCH_FOR=\"/include/librdkafka/rdkafka.h\"  # you most likely want to change this\n  if test -r $PHP_RDKAFKA/$SEARCH_FOR; then # path given as parameter\n    RDKAFKA_DIR=$PHP_RDKAFKA\n  else # search default path list\n    AC_MSG_CHECKING([for librdkafka/rdkafka.h\" in default path])\n    for i in $SEARCH_PATH ; do\n      if test -r $i/$SEARCH_FOR; then\n        RDKAFKA_DIR=$i\n        AC_MSG_RESULT(found in $i)\n      fi\n    done\n  fi\n\n  if test -z \"$RDKAFKA_DIR\"; then\n    AC_MSG_RESULT([not found])\n    AC_MSG_ERROR([Please reinstall the rdkafka distribution])\n  fi\n\n  PHP_ADD_INCLUDE($RDKAFKA_DIR/include)\n\n  SOURCES=\"rdkafka.c metadata.c metadata_broker.c metadata_topic.c metadata_partition.c metadata_collection.c conf.c topic.c queue.c message.c fun.c kafka_consumer.c topic_partition.c kafka_error_exception.c\"\n\n  LIBNAME=rdkafka\n  LIBSYMBOL=rd_kafka_new\n\n  PHP_CHECK_LIBRARY($LIBNAME,$LIBSYMBOL,\n  [\n    PHP_ADD_LIBRARY_WITH_PATH($LIBNAME, $RDKAFKA_DIR/$PHP_LIBDIR, RDKAFKA_SHARED_LIBADD)\n    AC_DEFINE(HAVE_RDKAFKALIB,1,[ ])\n  ],[\n    AC_MSG_ERROR([wrong rdkafka lib version or lib not found])\n  ],[\n    -L$RDKAFKA_DIR/$PHP_LIBDIR -lm\n  ])\n\n  ORIG_LDFLAGS=\"$LDFLAGS\"\n  ORIG_CPPFLAGS=\"$CPPFLAGS\"\n  LDFLAGS=\"-L$RDKAFKA_DIR/$PHP_LIBDIR -lm\"\n  CPPFLAGS=\"-I$RDKAFKA_DIR/include\"\n\n  AC_MSG_CHECKING([for librdkafka version])\n  AC_EGREP_CPP(yes,[\n#include <librdkafka/rdkafka.h>\n#if RD_KAFKA_VERSION >= 0x010503ff\n  yes\n#endif\n  ],[\n    AC_MSG_RESULT([>= 1.5.3])\n  ],[\n    AC_MSG_ERROR([librdkafka version 1.5.3 or greater required.])\n  ])\n\n  AC_CHECK_LIB($LIBNAME,[rd_kafka_incremental_assign, rd_kafka_incremental_unassign],[\n    AC_DEFINE(HAS_RD_KAFKA_INCREMENTAL_ASSIGN,1,[ ])\n  ],[\n    AC_MSG_WARN([no rd_kafka_incremental_(un)assign, incremental rebalance support will not be available])\n  ])\n\n  LDFLAGS=\"$ORIG_LDFLAGS\"\n  CPPFLAGS=\"$ORIG_CPPFLAGS\"\n\n  PHP_SUBST(RDKAFKA_SHARED_LIBADD)\n\n  PHP_NEW_EXTENSION(rdkafka, $SOURCES, $ext_shared)\nfi\n"
        },
        {
          "name": "config.w32",
          "type": "blob",
          "size": 0.5830078125,
          "content": "// $Id$\n// vim:ft=javascript\n\nARG_WITH(\"rdkafka\", \"for rdkafka support\", \"no\");\n\nif (PHP_RDKAFKA != \"no\") {\n\tif (CHECK_LIB(\"librdkafka.lib\", \"rdkafka\", PHP_RDKAFKA) &&\n\t\tCHECK_HEADER_ADD_INCLUDE(\"librdkafka/rdkafka.h\", \"CFLAGS_RDKAFKA\")) {\n\n\t\tEXTENSION(\"rdkafka\", \"rdkafka.c metadata.c metadata_broker.c metadata_topic.c \\\n\t\t\t\tmetadata_partition.c metadata_collection.c conf.c \\\n\t\t\t\ttopic.c queue.c message.c fun.c kafka_consumer.c topic_partition.c kafka_error_exception.c\");\n\n\t\tAC_DEFINE('HAVE_RDKAFKA', 1, '');\n\t} else {\n\t\tWARNING(\"rdkafka not enabled; libraries and headers not found\");\n\t}\n}\n\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "fun.c",
          "type": "blob",
          "size": 4.244140625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n\n/* {{{ proto array rd_kafka_get_err_descs()\n * Returns the full list of error codes.\n */\nPHP_FUNCTION(rd_kafka_get_err_descs)\n{\n    const struct rd_kafka_err_desc *errdescs;\n    size_t cnt;\n    size_t i;\n    int seen_zero = 0;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    rd_kafka_get_err_descs(&errdescs, &cnt);\n\n    array_init_size(return_value, cnt);\n\n    for (i = 0; i < cnt; i++) {\n        const struct rd_kafka_err_desc *desc = &errdescs[i];\n        zval el;\n\n        if (desc->code == 0) {\n            if (seen_zero) {\n                continue;\n            }\n            seen_zero = 1;\n        }\n\n        ZVAL_NULL(&el);\n        array_init(&el);\n        add_assoc_long(&el, \"code\", desc->code);\n        if (desc->name) {\n            add_assoc_string(&el, \"name\", (char*) desc->name);\n        } else {\n            add_assoc_null(&el, \"name\");\n        }\n        if (desc->desc) {\n            add_assoc_string(&el, \"desc\", (char*) desc->desc);\n        }else {\n            add_assoc_null(&el, \"desc\");\n        }\n        add_next_index_zval(return_value, &el);\n    }\n}\n/* }}} */\n\n/* {{{ proto string rd_kafka_err2name(int $err)\n * Returns the name of an error code\n */\nPHP_FUNCTION(rd_kafka_err2name)\n{\n    zend_long err;\n    const char *name;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &err) == FAILURE) {\n        return;\n    }\n\n    name = rd_kafka_err2name(err);\n\n    if (name) {\n        RETURN_STRING(name);\n    }\n}\n\n/* }}} */\n/* {{{ proto string rd_kafka_err2str(int $err)\n * Returns a human readable representation of a kafka error.\n */\nPHP_FUNCTION(rd_kafka_err2str)\n{\n    zend_long err;\n    const char *errstr;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &err) == FAILURE) {\n        return;\n    }\n\n    errstr = rd_kafka_err2str(err);\n\n    if (errstr) {\n        RETURN_STRING(errstr);\n    }\n}\n/* }}} */\n\n/* {{{ proto int rd_kafka_errno()\n * Returns `errno` */\nPHP_FUNCTION(rd_kafka_errno)\n{\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    RETURN_LONG(errno);\n}\n/* }}} */\n\n/* {{{ proto int rd_kafka_errno2err(int $errnox)\n * Converts `errno` to a rdkafka error code */\nPHP_FUNCTION(rd_kafka_errno2err)\n{\n    zend_long errnox;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &errnox) == FAILURE) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_errno2err(errnox));\n}\n/* }}} */\n\n/* {{{ proto int rd_kafka_thread_cnt()\n * Retrieve the current number of threads in use by librdkafka.\n */\nPHP_FUNCTION(rd_kafka_thread_cnt)\n{\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_thread_cnt());\n}\n/* }}} */\n\n/* {{{ proto int rd_kafka_offset_tail(int $cnt)\n * Start consuming `$cnt` messages from topic's current `.._END` offset.\n */\nPHP_FUNCTION(rd_kafka_offset_tail)\n{\n    zend_long cnt;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &cnt) == FAILURE) {\n        return;\n    }\n\n    RETURN_LONG(RD_KAFKA_OFFSET_TAIL(cnt));\n}\n/* }}} */\n"
        },
        {
          "name": "fun.stub.php",
          "type": "blob",
          "size": 0.4189453125,
          "content": "<?php\n\n/**\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nfunction rd_kafka_get_err_descs(): array {}\n\nfunction rd_kafka_err2name(int $err): ?string {}\n\nfunction rd_kafka_err2str(int $err): ?string {}\n\n/** @deprecated */\nfunction rd_kafka_errno2err(int $errnox): int {}\n\n/** @deprecated */\nfunction rd_kafka_errno(): int {}\n\nfunction rd_kafka_offset_tail(int $cnt): int {}\n\nfunction rd_kafka_thread_cnt(): int {}\n"
        },
        {
          "name": "fun_arginfo.h",
          "type": "blob",
          "size": 1.5888671875,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 0e1e56d853a47168a1f7f0950b674c2de6a91976 */\n\nZEND_BEGIN_ARG_WITH_RETURN_TYPE_INFO_EX(arginfo_rd_kafka_get_err_descs, 0, 0, IS_ARRAY, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_RETURN_TYPE_INFO_EX(arginfo_rd_kafka_err2name, 0, 1, IS_STRING, 1)\n\tZEND_ARG_TYPE_INFO(0, err, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_rd_kafka_err2str arginfo_rd_kafka_err2name\n\nZEND_BEGIN_ARG_WITH_RETURN_TYPE_INFO_EX(arginfo_rd_kafka_errno2err, 0, 1, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, errnox, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_RETURN_TYPE_INFO_EX(arginfo_rd_kafka_errno, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_RETURN_TYPE_INFO_EX(arginfo_rd_kafka_offset_tail, 0, 1, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, cnt, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_rd_kafka_thread_cnt arginfo_rd_kafka_errno\n\n\nZEND_FUNCTION(rd_kafka_get_err_descs);\nZEND_FUNCTION(rd_kafka_err2name);\nZEND_FUNCTION(rd_kafka_err2str);\nZEND_FUNCTION(rd_kafka_errno2err);\nZEND_FUNCTION(rd_kafka_errno);\nZEND_FUNCTION(rd_kafka_offset_tail);\nZEND_FUNCTION(rd_kafka_thread_cnt);\n\n\nstatic const zend_function_entry ext_functions[] = {\n\tZEND_FE(rd_kafka_get_err_descs, arginfo_rd_kafka_get_err_descs)\n\tZEND_FE(rd_kafka_err2name, arginfo_rd_kafka_err2name)\n\tZEND_FE(rd_kafka_err2str, arginfo_rd_kafka_err2str)\n\tZEND_DEP_FE(rd_kafka_errno2err, arginfo_rd_kafka_errno2err)\n\tZEND_DEP_FE(rd_kafka_errno, arginfo_rd_kafka_errno)\n\tZEND_FE(rd_kafka_offset_tail, arginfo_rd_kafka_offset_tail)\n\tZEND_FE(rd_kafka_thread_cnt, arginfo_rd_kafka_thread_cnt)\n\tZEND_FE_END\n};\n"
        },
        {
          "name": "kafka_consumer.c",
          "type": "blob",
          "size": 24.4716796875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n#include \"conf.h\"\n#include \"topic_partition.h\"\n#include \"topic.h\"\n#include \"message.h\"\n#include \"metadata.h\"\n#include \"kafka_consumer_arginfo.h\"\n\ntypedef struct _object_intern {\n    rd_kafka_t              *rk;\n    kafka_conf_callbacks    cbs;\n    zend_object             std;\n} object_intern;\n\nstatic zend_class_entry * ce;\nstatic zend_object_handlers handlers;\n\nstatic void kafka_consumer_free(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n    rd_kafka_resp_err_t err;\n    kafka_conf_callbacks_dtor(&intern->cbs);\n\n    if (intern->rk) {\n        err = rd_kafka_consumer_close(intern->rk);\n\n        if (err) {\n            php_error(E_WARNING, \"rd_kafka_consumer_close failed: %s\", rd_kafka_err2str(err));\n        }\n\n        rd_kafka_destroy(intern->rk);\n        intern->rk = NULL;\n    }\n\n    kafka_conf_callbacks_dtor(&intern->cbs);\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *kafka_consumer_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zconsumer) /* {{{ */\n{\n    object_intern *oconsumer = Z_RDKAFKA_P(object_intern, zconsumer);\n\n    if (!oconsumer->rk) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\KafkaConsumer::__construct() has not been called, or RdKafka\\\\KafkaConsumer::close() was already called\");\n        return NULL;\n    }\n\n    return oconsumer;\n} /* }}} */\n\nstatic int has_group_id(rd_kafka_conf_t *conf) { /* {{{ */\n\n    size_t len;\n\n    if (conf == NULL) {\n        return 0;\n    }\n\n    if (rd_kafka_conf_get(conf, \"group.id\", NULL, &len) != RD_KAFKA_CONF_OK) {\n        return 0;\n    }\n\n    if (len <= 1) {\n        return 0;\n    }\n\n    return 1;\n} /* }}} */\n\n/* {{{ proto RdKafka\\KafkaConsumer::__construct(RdKafka\\Conf $conf) */\nPHP_METHOD(RdKafka_KafkaConsumer, __construct)\n{\n    zval *zconf;\n    zend_error_handling error_handling;\n    char errstr[512];\n    rd_kafka_t *rk;\n    object_intern *intern;\n    kafka_conf_object *conf_intern;\n    rd_kafka_conf_t *conf = NULL;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"O\", &zconf, ce_kafka_conf) == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, getThis());\n\n    conf_intern = get_kafka_conf_object(zconf);\n    if (conf_intern) {\n        conf = rd_kafka_conf_dup(conf_intern->u.conf);\n        kafka_conf_callbacks_copy(&intern->cbs, &conf_intern->cbs);\n        intern->cbs.zrk = *getThis();\n        rd_kafka_conf_set_opaque(conf, &intern->cbs);\n    }\n\n    if (!has_group_id(conf)) {\n        if (conf) {\n            rd_kafka_conf_destroy(conf);\n        }\n        zend_throw_exception(ce_kafka_exception, \"\\\"group.id\\\" must be configured\", 0);\n        return;\n    }\n\n    rk = rd_kafka_new(RD_KAFKA_CONSUMER, conf, errstr, sizeof(errstr));\n\n    if (rk == NULL) {\n        zend_restore_error_handling(&error_handling);\n        zend_throw_exception(ce_kafka_exception, errstr, 0);\n        return;\n    }\n\n    if (intern->cbs.log) {\n        rd_kafka_set_log_queue(rk, NULL);\n    }\n\n    intern->rk = rk;\n\n    rd_kafka_poll_set_consumer(rk);\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::assign([array $topics])\n    Atomic assignment of partitions to consume */\nPHP_METHOD(RdKafka_KafkaConsumer, assign)\n{\n    HashTable *htopars = NULL;\n    rd_kafka_topic_partition_list_t *topics;\n    rd_kafka_resp_err_t err;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"|h!\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (htopars) {\n        topics = array_arg_to_kafka_topic_partition_list(1, htopars);\n        if (!topics) {\n            return;\n        }\n    } else {\n        topics = NULL;\n    }\n\n    err = rd_kafka_assign(intern->rk, topics);\n\n    if (topics) {\n        rd_kafka_topic_partition_list_destroy(topics);\n    }\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n#ifdef HAS_RD_KAFKA_INCREMENTAL_ASSIGN\nstatic void consumer_incremental_op(int assign, INTERNAL_FUNCTION_PARAMETERS) /* {{{ */\n{\n    HashTable *htopars = NULL;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE || !htopars) {\n        return;\n    }\n\n    object_intern *intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rd_kafka_topic_partition_list_t *topics = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topics) {\n        return;\n    }\n\n    rd_kafka_error_t *err;\n\n    if (assign) {\n        err = rd_kafka_incremental_assign(intern->rk, topics);\n    } else {\n        err = rd_kafka_incremental_unassign(intern->rk, topics);\n    }\n\n    rd_kafka_topic_partition_list_destroy(topics);\n\n    if (err) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_error_string(err), 0);\n        rd_kafka_error_destroy(err);\n    }\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::incrementalAssign(array $topics)\n    Incremental assignment of partitions to consume */\nPHP_METHOD(RdKafka_KafkaConsumer, incrementalAssign)\n{\n    consumer_incremental_op(1, INTERNAL_FUNCTION_PARAM_PASSTHRU);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::incrementalUnassign(array $topics)\n    Incremental unassign of partitions to consume */\nPHP_METHOD(RdKafka_KafkaConsumer, incrementalUnassign)\n{\n    consumer_incremental_op(0, INTERNAL_FUNCTION_PARAM_PASSTHRU);\n}\n/* }}} */\n#endif // !HAS_RD_KAFKA_INCREMENTAL_ASSIGN\n\n/* {{{ proto array RdKafka\\KafkaConsumer::getAssignment()\n    Returns the current partition getAssignment */\nPHP_METHOD(RdKafka_KafkaConsumer, getAssignment)\n{\n    rd_kafka_resp_err_t err;\n    rd_kafka_topic_partition_list_t *topics;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_assignment(intern->rk, &topics);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_topic_partition_list_to_array(return_value, topics);\n    rd_kafka_topic_partition_list_destroy(topics);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::subscribe(array $topics)\n    Update the subscription set to $topics */\nPHP_METHOD(RdKafka_KafkaConsumer, subscribe)\n{\n    HashTable *htopics;\n    HashPosition pos;\n    object_intern *intern;\n    rd_kafka_topic_partition_list_t *topics;\n    rd_kafka_resp_err_t err;\n    zval *zv;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopics) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topics = rd_kafka_topic_partition_list_new(zend_hash_num_elements(htopics));\n\n    for (zend_hash_internal_pointer_reset_ex(htopics, &pos);\n            (zv = zend_hash_get_current_data_ex(htopics, &pos)) != NULL;\n            zend_hash_move_forward_ex(htopics, &pos)) {\n        convert_to_string_ex(zv);\n        rd_kafka_topic_partition_list_add(topics, Z_STRVAL_P(zv), RD_KAFKA_PARTITION_UA);\n    }\n\n    err = rd_kafka_subscribe(intern->rk, topics);\n\n    rd_kafka_topic_partition_list_destroy(topics);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto array RdKafka\\KafkaConsumer::getSubscription()\n   Returns the current subscription as set by subscribe() */\nPHP_METHOD(RdKafka_KafkaConsumer, getSubscription)\n{\n    rd_kafka_resp_err_t err;\n    rd_kafka_topic_partition_list_t *topics;\n    object_intern *intern;\n    int i;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_subscription(intern->rk, &topics);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    array_init_size(return_value, topics->cnt);\n\n    for (i = 0; i < topics->cnt; i++) {\n        add_next_index_string(return_value, topics->elems[i].topic);\n    }\n\n    rd_kafka_topic_partition_list_destroy(topics);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::unsubsribe()\n    Unsubscribe from the current subscription set */\nPHP_METHOD(RdKafka_KafkaConsumer, unsubscribe)\n{\n    object_intern *intern;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_unsubscribe(intern->rk);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto Message RdKafka\\KafkaConsumer::consume()\n   Consume message or get error event, triggers callbacks */\nPHP_METHOD(RdKafka_KafkaConsumer, consume)\n{\n    object_intern *intern;\n    zend_long timeout_ms;\n    rd_kafka_message_t *rkmessage, rkmessage_tmp = {0};\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rkmessage = rd_kafka_consumer_poll(intern->rk, timeout_ms);\n\n    if (!rkmessage) {\n        rkmessage_tmp.err = RD_KAFKA_RESP_ERR__TIMED_OUT;\n        rkmessage = &rkmessage_tmp;\n    }\n\n    kafka_message_new(return_value, rkmessage, NULL);\n\n    if (rkmessage != &rkmessage_tmp) {\n        rd_kafka_message_destroy(rkmessage);\n    }\n}\n/* }}} */\n\nstatic void consumer_commit(int async, INTERNAL_FUNCTION_PARAMETERS) /* {{{ */\n{\n    zval *zarg = NULL;\n    object_intern *intern;\n    rd_kafka_topic_partition_list_t *offsets = NULL;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"|z!\", &zarg) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (zarg) {\n        if (Z_TYPE_P(zarg) == IS_OBJECT && instanceof_function(Z_OBJCE_P(zarg), ce_kafka_message)) {\n            zval *zerr;\n            zval *ztopic;\n            zval *zpartition;\n            zval *zoffset;\n            rd_kafka_topic_partition_t *rktpar;\n\n            zerr = rdkafka_read_property(NULL, Z_OBJ_P(zarg), ZEND_STRL(\"err\"), 0);\n            if (zerr && Z_TYPE_P(zerr) != IS_NULL && (Z_TYPE_P(zerr) != IS_LONG || Z_LVAL_P(zerr) != RD_KAFKA_RESP_ERR_NO_ERROR)) {\n                zend_throw_exception(ce_kafka_exception, \"Invalid argument: Specified Message has an error\", RD_KAFKA_RESP_ERR__INVALID_ARG);\n                return;\n            }\n\n            ztopic = rdkafka_read_property(NULL, Z_OBJ_P(zarg), ZEND_STRL(\"topic_name\"), 0);\n            if (!ztopic || Z_TYPE_P(ztopic) != IS_STRING) {\n                zend_throw_exception(ce_kafka_exception, \"Invalid argument: Specified Message's topic_name is not a string\", RD_KAFKA_RESP_ERR__INVALID_ARG);\n                return;\n            }\n\n            zpartition = rdkafka_read_property(NULL, Z_OBJ_P(zarg), ZEND_STRL(\"partition\"), 0);\n            if (!zpartition || Z_TYPE_P(zpartition) != IS_LONG) {\n                zend_throw_exception(ce_kafka_exception, \"Invalid argument: Specified Message's partition is not an int\", RD_KAFKA_RESP_ERR__INVALID_ARG);\n                return;\n            }\n\n            zoffset = rdkafka_read_property(NULL, Z_OBJ_P(zarg), ZEND_STRL(\"offset\"), 0);\n            if (!zoffset || Z_TYPE_P(zoffset) != IS_LONG) {\n                zend_throw_exception(ce_kafka_exception, \"Invalid argument: Specified Message's offset is not an int\", RD_KAFKA_RESP_ERR__INVALID_ARG);\n                return;\n            }\n\n            offsets = rd_kafka_topic_partition_list_new(1);\n            rktpar = rd_kafka_topic_partition_list_add(\n                    offsets, Z_STRVAL_P(ztopic),\n                    Z_LVAL_P(zpartition));\n            rktpar->offset = Z_LVAL_P(zoffset)+1;\n\n        } else if (Z_TYPE_P(zarg) == IS_ARRAY) {\n            HashTable *ary = Z_ARRVAL_P(zarg);\n            offsets = array_arg_to_kafka_topic_partition_list(1, ary);\n            if (!offsets) {\n                return;\n            }\n        } else if (Z_TYPE_P(zarg) != IS_NULL) {\n            php_error(E_ERROR,\n                    \"RdKafka\\\\KafkaConsumer::%s() expects parameter %d to be %s, %s given\",\n                    get_active_function_name(),\n                    1,\n                    \"an instance of RdKafka\\\\Message or an array of RdKafka\\\\TopicPartition\",\n                    zend_zval_type_name(zarg));\n            return;\n        }\n    }\n\n    err = rd_kafka_commit(intern->rk, offsets, async);\n\n    if (offsets) {\n        rd_kafka_topic_partition_list_destroy(offsets);\n    }\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::commit([mixed $message_or_offsets])\n   Commit offsets */\nPHP_METHOD(RdKafka_KafkaConsumer, commit)\n{\n    consumer_commit(0, INTERNAL_FUNCTION_PARAM_PASSTHRU);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::commitAsync([mixed $message_or_offsets])\n   Commit offsets */\nPHP_METHOD(RdKafka_KafkaConsumer, commitAsync)\n{\n    consumer_commit(1, INTERNAL_FUNCTION_PARAM_PASSTHRU);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::close()\n   Close connection */\nPHP_METHOD(RdKafka_KafkaConsumer, close)\n{\n    object_intern *intern;\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rd_kafka_consumer_close(intern->rk);\n    intern->rk = NULL;\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Metadata RdKafka\\KafkaConsumer::getMetadata(bool $all_topics, RdKafka\\Topic $only_topic, int $timeout_ms)\n   Request Metadata from broker */\nPHP_METHOD(RdKafka_KafkaConsumer, getMetadata)\n{\n    zend_bool all_topics;\n    zval *only_zrkt;\n    zend_long timeout_ms;\n    rd_kafka_resp_err_t err;\n    object_intern *intern;\n    const rd_kafka_metadata_t *metadata;\n    kafka_topic_object *only_orkt = NULL;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"bO!l\", &all_topics, &only_zrkt, ce_kafka_topic, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (only_zrkt) {\n        only_orkt = get_kafka_topic_object(only_zrkt);\n        if (!only_orkt) {\n            return;\n        }\n    }\n\n    err = rd_kafka_metadata(intern->rk, all_topics, only_orkt ? only_orkt->rkt : NULL, &metadata, timeout_ms);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_metadata_init(return_value, metadata);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\KafkaConsumer::getControllerId(int $timeout_ms)\n   Returns the current ControllerId (controller broker id) as reported in broker metadata */\nPHP_METHOD(RdKafka_KafkaConsumer, getControllerId)\n{\n    object_intern *intern;\n    zend_long timeout;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_controllerid(intern->rk, timeout));\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\KafkaConsumerTopic RdKafka\\KafkaConsumer::newTopic(string $topic)\n   Returns a RdKafka\\KafkaConsumerTopic object */\nPHP_METHOD(RdKafka_KafkaConsumer, newTopic)\n{\n    char *topic;\n    size_t topic_len;\n    rd_kafka_topic_t *rkt;\n    object_intern *intern;\n    kafka_topic_object *topic_intern;\n    zval *zconf = NULL;\n    rd_kafka_topic_conf_t *conf = NULL;\n    kafka_conf_object *conf_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|O!\", &topic, &topic_len, &zconf, ce_kafka_topic_conf) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (zconf) {\n        conf_intern = get_kafka_conf_object(zconf);\n        if (conf_intern) {\n            conf = rd_kafka_topic_conf_dup(conf_intern->u.topic_conf);\n        }\n    }\n\n    rkt = rd_kafka_topic_new(intern->rk, topic, conf);\n\n    if (!rkt) {\n        return;\n    }\n\n    if (object_init_ex(return_value, ce_kafka_kafka_consumer_topic) != SUCCESS) {\n        return;\n    }\n\n    topic_intern = Z_RDKAFKA_P(kafka_topic_object, return_value);\n    if (!topic_intern) {\n        return;\n    }\n\n    topic_intern->rkt = rkt;\n}\n/* }}} */\n\n/* {{{ proto array RdKafka\\KafkaConsumer::getCommittedOffsets(array $topics, int timeout_ms)\n   Retrieve committed offsets for topics+partitions */\nPHP_METHOD(RdKafka_KafkaConsumer, getCommittedOffsets)\n{\n    HashTable *htopars = NULL;\n    zend_long timeout_ms;\n    object_intern *intern;\n    rd_kafka_resp_err_t err;\n    rd_kafka_topic_partition_list_t *topics;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"hl\", &htopars, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topics = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topics) {\n        return;\n    }\n\n    err = rd_kafka_committed(intern->rk, topics, timeout_ms);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topics);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n    kafka_topic_partition_list_to_array(return_value, topics);\n    rd_kafka_topic_partition_list_destroy(topics);\n}\n/* }}} */\n\n/* }}} */\n\n/* {{{ proto array RdKafka\\KafkaConsumer::getOffsetPositions(array $topics)\n   Retrieve current offsets for topics+partitions */\nPHP_METHOD(RdKafka_KafkaConsumer, getOffsetPositions)\n{\n    HashTable *htopars = NULL;\n    object_intern *intern;\n    rd_kafka_resp_err_t err;\n    rd_kafka_topic_partition_list_t *topics;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topics = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topics) {\n        return;\n    }\n\n    err = rd_kafka_position(intern->rk, topics);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topics);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n    kafka_topic_partition_list_to_array(return_value, topics);\n    rd_kafka_topic_partition_list_destroy(topics);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::offsetsForTimes(array $topicPartitions, int $timeout_ms)\n   Look up the offsets for the given partitions by timestamp. */\nPHP_METHOD(RdKafka_KafkaConsumer, offsetsForTimes)\n{\n    HashTable *htopars = NULL;\n    object_intern *intern;\n    rd_kafka_topic_partition_list_t *topicPartitions;\n    zend_long timeout_ms;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"hl\", &htopars, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topicPartitions = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topicPartitions) {\n        return;\n    }\n\n    err = rd_kafka_offsets_for_times(intern->rk, topicPartitions, timeout_ms);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topicPartitions);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n    kafka_topic_partition_list_to_array(return_value, topicPartitions);\n    rd_kafka_topic_partition_list_destroy(topicPartitions);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaConsumer::queryWatermarkOffsets(string $topic, int $partition, int &$low, int &$high, int $timeout_ms)\n   Query broker for low (oldest/beginning) or high (newest/end) offsets for partition */\nPHP_METHOD(RdKafka_KafkaConsumer, queryWatermarkOffsets)\n{\n    object_intern *intern;\n    char *topic;\n    size_t topic_length;\n    int64_t low, high;\n    zend_long partition, timeout;\n    zval *lowResult, *highResult;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"slzzl\", &topic, &topic_length, &partition, &lowResult, &highResult, &timeout) == FAILURE) {\n        return;\n    }\n\n    ZVAL_DEREF(lowResult);\n    ZVAL_DEREF(highResult);\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_query_watermark_offsets(intern->rk, topic, partition, &low, &high, timeout);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    ZVAL_LONG(lowResult, (zend_long) low);\n    ZVAL_LONG(highResult, (zend_long) high);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicPartition[] RdKafka\\KafkaConsumer::pausePatitions(RdKafka\\TopicPartition[] $topicPartitions)\n   Pause consumption for the provided list of partitions. */\nPHP_METHOD(RdKafka_KafkaConsumer, pausePartitions)\n{\n    HashTable *htopars;\n    rd_kafka_topic_partition_list_t *topars;\n    rd_kafka_resp_err_t err;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topars = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topars) {\n        return;\n    }\n\n    err = rd_kafka_pause_partitions(intern->rk, topars);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topars);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_topic_partition_list_to_array(return_value, topars);\n    rd_kafka_topic_partition_list_destroy(topars);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicPartition[] RdKafka\\KafkaConsumer::resumePatitions(RdKafka\\TopicPartition[] $topicPartitions)\n   Resume consumption for the provided list of partitions. */\nPHP_METHOD(RdKafka_KafkaConsumer, resumePartitions)\n{\n    HashTable *htopars;\n    rd_kafka_topic_partition_list_t *topars;\n    rd_kafka_resp_err_t err;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topars = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topars) {\n        return;\n    }\n\n    err = rd_kafka_resume_partitions(intern->rk, topars);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topars);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_topic_partition_list_to_array(return_value, topars);\n    rd_kafka_topic_partition_list_destroy(topars);\n}\n/* }}} */\n\nvoid kafka_kafka_consumer_minit(INIT_FUNC_ARGS) /* {{{ */\n{\n    ce = register_class_RdKafka_KafkaConsumer();\n    ce->create_object = kafka_consumer_new;\n\n    handlers = kafka_default_object_handlers;\n    handlers.free_obj = kafka_consumer_free;\n    handlers.offset = XtOffsetOf(object_intern, std);\n} /* }}} */\n"
        },
        {
          "name": "kafka_consumer.h",
          "type": "blob",
          "size": 1.1533203125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_kafka_consumer_minit(INIT_FUNC_ARGS);\n"
        },
        {
          "name": "kafka_consumer.stub.php",
          "type": "blob",
          "size": 2.4404296875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass KafkaConsumer\n{\n    private ?callable $error_cb;\n\n    private ?callable $rebalance_cb;\n\n    private ?callable $dr_msg_cb;\n\n    public function __construct(Conf $conf) {}\n\n    /** @tentative-return-type */\n    public function assign(?array $topic_partitions = null): void {}\n\n#ifdef HAS_RD_KAFKA_INCREMENTAL_ASSIGN\n    /** @tentative-return-type */\n    public function incrementalAssign(array $topic_partitions): void {}\n\n    /** @tentative-return-type */\n    public function incrementalUnassign(array $topic_partitions): void {}\n#endif\n\n    /** @tentative-return-type */\n    public function getAssignment(): array {}\n\n    /** @tentative-return-type */\n    public function commit(Message|array|null $message_or_offsets = null): void {}\n\n    /** @tentative-return-type */\n    public function close(): void {}\n\n    /** @tentative-return-type */\n    public function commitAsync(Message|array|null $message_or_offsets = null): void {}\n\n    /** @tentative-return-type */\n    public function consume(int $timeout_ms): Message {}\n\n    /** @tentative-return-type */\n    public function subscribe(array $topics): void {}\n\n    /** @tentative-return-type */\n    public function getSubscription(): array {}\n\n    /** @tentative-return-type */\n    public function unsubscribe(): void {}\n\n    /** @tentative-return-type */\n    public function getMetadata(bool $all_topics, ?Topic $only_topic, int $timeout_ms): Metadata {}\n\n    /** @tentative-return-type */\n    public function getControllerId(int $timeout_ms): int {}\n\n    /** @tentative-return-type */\n    public function newTopic(string $topic_name, ?TopicConf $topic_conf = null): KafkaConsumerTopic {}\n\n    /** @tentative-return-type */\n    public function getCommittedOffsets(array $topic_partitions, int $timeout_ms): array {}\n\n    /** @tentative-return-type */\n    public function getOffsetPositions(array $topic_partitions): array {}\n\n    /** @tentative-return-type */\n    public function queryWatermarkOffsets(string $topic, int $partition, int &$low, int &$high, int $timeout_ms): void {}\n\n    /** @tentative-return-type */\n    public function offsetsForTimes(array $topic_partitions, int $timeout_ms): array {}\n\n    /** @tentative-return-type */\n    public function pausePartitions(array $topic_partitions): array {}\n\n    /** @tentative-return-type */\n    public function resumePartitions(array $topic_partitions): array {}\n}\n"
        },
        {
          "name": "kafka_consumer_arginfo.h",
          "type": "blob",
          "size": 10.732421875,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 5396249050f6bf118e5f830140cc016efee80def */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer___construct, 0, 0, 1)\n\tZEND_ARG_OBJ_INFO(0, conf, RdKafka\\\\Conf, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_assign, 0, 0, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_assign, 0, 0, 0)\n#endif\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, topic_partitions, IS_ARRAY, 1, \"null\")\nZEND_END_ARG_INFO()\n\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_incrementalAssign, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_incrementalAssign, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_partitions, IS_ARRAY, 0)\nZEND_END_ARG_INFO()\n#endif\n\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\n#define arginfo_class_RdKafka_KafkaConsumer_incrementalUnassign arginfo_class_RdKafka_KafkaConsumer_incrementalAssign\n#endif\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getAssignment, 0, 0, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getAssignment, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_commit, 0, 0, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_commit, 0, 0, 0)\n#endif\n\tZEND_ARG_OBJ_TYPE_MASK(0, message_or_offsets, RdKafka\\\\Message, MAY_BE_ARRAY|MAY_BE_NULL, \"null\")\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_close, 0, 0, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_close, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_KafkaConsumer_commitAsync arginfo_class_RdKafka_KafkaConsumer_commit\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_consume, 0, 1, RdKafka\\\\Message, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_consume, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_subscribe, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_subscribe, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topics, IS_ARRAY, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_KafkaConsumer_getSubscription arginfo_class_RdKafka_KafkaConsumer_getAssignment\n\n#define arginfo_class_RdKafka_KafkaConsumer_unsubscribe arginfo_class_RdKafka_KafkaConsumer_close\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getMetadata, 0, 3, RdKafka\\\\Metadata, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getMetadata, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, all_topics, _IS_BOOL, 0)\n\tZEND_ARG_OBJ_INFO(0, only_topic, RdKafka\\\\Topic, 1)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getControllerId, 0, 1, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getControllerId, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_newTopic, 0, 1, RdKafka\\\\KafkaConsumerTopic, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_newTopic, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_name, IS_STRING, 0)\n\tZEND_ARG_OBJ_INFO_WITH_DEFAULT_VALUE(0, topic_conf, RdKafka\\\\TopicConf, 1, \"null\")\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getCommittedOffsets, 0, 2, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getCommittedOffsets, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_partitions, IS_ARRAY, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getOffsetPositions, 0, 1, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_getOffsetPositions, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_partitions, IS_ARRAY, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_queryWatermarkOffsets, 0, 5, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaConsumer_queryWatermarkOffsets, 0, 0, 5)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(1, low, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(1, high, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_KafkaConsumer_offsetsForTimes arginfo_class_RdKafka_KafkaConsumer_getCommittedOffsets\n\n#define arginfo_class_RdKafka_KafkaConsumer_pausePartitions arginfo_class_RdKafka_KafkaConsumer_getOffsetPositions\n\n#define arginfo_class_RdKafka_KafkaConsumer_resumePartitions arginfo_class_RdKafka_KafkaConsumer_getOffsetPositions\n\n\nZEND_METHOD(RdKafka_KafkaConsumer, __construct);\nZEND_METHOD(RdKafka_KafkaConsumer, assign);\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\nZEND_METHOD(RdKafka_KafkaConsumer, incrementalAssign);\n#endif\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\nZEND_METHOD(RdKafka_KafkaConsumer, incrementalUnassign);\n#endif\nZEND_METHOD(RdKafka_KafkaConsumer, getAssignment);\nZEND_METHOD(RdKafka_KafkaConsumer, commit);\nZEND_METHOD(RdKafka_KafkaConsumer, close);\nZEND_METHOD(RdKafka_KafkaConsumer, commitAsync);\nZEND_METHOD(RdKafka_KafkaConsumer, consume);\nZEND_METHOD(RdKafka_KafkaConsumer, subscribe);\nZEND_METHOD(RdKafka_KafkaConsumer, getSubscription);\nZEND_METHOD(RdKafka_KafkaConsumer, unsubscribe);\nZEND_METHOD(RdKafka_KafkaConsumer, getMetadata);\nZEND_METHOD(RdKafka_KafkaConsumer, getControllerId);\nZEND_METHOD(RdKafka_KafkaConsumer, newTopic);\nZEND_METHOD(RdKafka_KafkaConsumer, getCommittedOffsets);\nZEND_METHOD(RdKafka_KafkaConsumer, getOffsetPositions);\nZEND_METHOD(RdKafka_KafkaConsumer, queryWatermarkOffsets);\nZEND_METHOD(RdKafka_KafkaConsumer, offsetsForTimes);\nZEND_METHOD(RdKafka_KafkaConsumer, pausePartitions);\nZEND_METHOD(RdKafka_KafkaConsumer, resumePartitions);\n\n\nstatic const zend_function_entry class_RdKafka_KafkaConsumer_methods[] = {\n\tZEND_ME(RdKafka_KafkaConsumer, __construct, arginfo_class_RdKafka_KafkaConsumer___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, assign, arginfo_class_RdKafka_KafkaConsumer_assign, ZEND_ACC_PUBLIC)\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\n\tZEND_ME(RdKafka_KafkaConsumer, incrementalAssign, arginfo_class_RdKafka_KafkaConsumer_incrementalAssign, ZEND_ACC_PUBLIC)\n#endif\n#if defined(HAS_RD_KAFKA_INCREMENTAL_ASSIGN)\n\tZEND_ME(RdKafka_KafkaConsumer, incrementalUnassign, arginfo_class_RdKafka_KafkaConsumer_incrementalUnassign, ZEND_ACC_PUBLIC)\n#endif\n\tZEND_ME(RdKafka_KafkaConsumer, getAssignment, arginfo_class_RdKafka_KafkaConsumer_getAssignment, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, commit, arginfo_class_RdKafka_KafkaConsumer_commit, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, close, arginfo_class_RdKafka_KafkaConsumer_close, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, commitAsync, arginfo_class_RdKafka_KafkaConsumer_commitAsync, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, consume, arginfo_class_RdKafka_KafkaConsumer_consume, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, subscribe, arginfo_class_RdKafka_KafkaConsumer_subscribe, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, getSubscription, arginfo_class_RdKafka_KafkaConsumer_getSubscription, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, unsubscribe, arginfo_class_RdKafka_KafkaConsumer_unsubscribe, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, getMetadata, arginfo_class_RdKafka_KafkaConsumer_getMetadata, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, getControllerId, arginfo_class_RdKafka_KafkaConsumer_getControllerId, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, newTopic, arginfo_class_RdKafka_KafkaConsumer_newTopic, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, getCommittedOffsets, arginfo_class_RdKafka_KafkaConsumer_getCommittedOffsets, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, getOffsetPositions, arginfo_class_RdKafka_KafkaConsumer_getOffsetPositions, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, queryWatermarkOffsets, arginfo_class_RdKafka_KafkaConsumer_queryWatermarkOffsets, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, offsetsForTimes, arginfo_class_RdKafka_KafkaConsumer_offsetsForTimes, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, pausePartitions, arginfo_class_RdKafka_KafkaConsumer_pausePartitions, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaConsumer, resumePartitions, arginfo_class_RdKafka_KafkaConsumer_resumePartitions, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_KafkaConsumer(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"KafkaConsumer\", class_RdKafka_KafkaConsumer_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\tzval property_error_cb_default_value;\n\tZVAL_UNDEF(&property_error_cb_default_value);\n\tzend_string *property_error_cb_name = zend_string_init(\"error_cb\", sizeof(\"error_cb\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_error_cb_name, &property_error_cb_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_CALLABLE|MAY_BE_NULL));\n\tzend_string_release(property_error_cb_name);\n\n\tzval property_rebalance_cb_default_value;\n\tZVAL_UNDEF(&property_rebalance_cb_default_value);\n\tzend_string *property_rebalance_cb_name = zend_string_init(\"rebalance_cb\", sizeof(\"rebalance_cb\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_rebalance_cb_name, &property_rebalance_cb_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_CALLABLE|MAY_BE_NULL));\n\tzend_string_release(property_rebalance_cb_name);\n\n\tzval property_dr_msg_cb_default_value;\n\tZVAL_UNDEF(&property_dr_msg_cb_default_value);\n\tzend_string *property_dr_msg_cb_name = zend_string_init(\"dr_msg_cb\", sizeof(\"dr_msg_cb\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_dr_msg_cb_name, &property_dr_msg_cb_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_CALLABLE|MAY_BE_NULL));\n\tzend_string_release(property_dr_msg_cb_name);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "kafka_error_exception.c",
          "type": "blob",
          "size": 5.892578125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"kafka_error_exception.h\"\n#include \"kafka_error_exception_arginfo.h\"\n\nzend_class_entry * ce_kafka_error;\n\nvoid create_kafka_error(zval *return_value, const rd_kafka_error_t *error) /* {{{ */\n{\n    object_init_ex(return_value, ce_kafka_error);\n\n    char message[1024];\n    snprintf(message, sizeof(message), \"%s (RD_KAFKA_RESP_ERR_%s)\", rd_kafka_error_string(error), rd_kafka_error_name(error));\n    zend_update_property_string(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"message\"), message);\n\n    zend_update_property_long(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"code\"), rd_kafka_error_code(error));\n    zend_update_property_string(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"error_string\"), rd_kafka_error_string(error));\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"isFatal\"), rd_kafka_error_is_fatal(error));\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"isRetriable\"), rd_kafka_error_is_retriable(error));\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(return_value), ZEND_STRL(\"transactionRequiresAbort\"), rd_kafka_error_txn_requires_abort(error));\n\n    Z_ADDREF_P(return_value);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\KafkaErrorException::__construct(string $message, int $code[, string $error_string, bool $isFatal, bool $isRetriable, bool $transactionRequiresAbort]) */\nPHP_METHOD(RdKafka_KafkaErrorException, __construct)\n{\n    char *message, *error_string = \"\";\n    size_t message_length = 0, error_string_length = 0;\n    zend_bool isFatal = 0, isRetriable = 0, transactionRequiresAbort = 0;\n    zend_long code = 0;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"sl|sbbb\", &message, &message_length, &code, &error_string, &error_string_length, &isFatal, &isRetriable, &transactionRequiresAbort) == FAILURE) {\n        return;\n    }\n\n    zend_update_property_string(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"message\"), message);\n    zend_update_property_long(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"code\"), code);\n    zend_update_property_string(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"error_string\"), error_string);\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"isFatal\"), isFatal);\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"isRetriable\"), isRetriable);\n    zend_update_property_bool(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"transactionRequiresAbort\"), transactionRequiresAbort);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaErrorException::getErrorString()\n    Get name of error */\nPHP_METHOD(RdKafka_KafkaErrorException, getErrorString)\n{\n    zval *res;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    res = rdkafka_read_property(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"error_string\"), 0);\n\n    if (!res || Z_TYPE_P(res) != IS_STRING) {\n        return;\n    }\n\n    ZVAL_DEREF(res);\n    ZVAL_COPY(return_value, res);\n}\n/* }}} */\n\n\n/* {{{ proto void RdKafka\\KafkaErrorException::isFatal()\n    Return true if error is fatal */\nPHP_METHOD(RdKafka_KafkaErrorException, isFatal)\n{\n    zval *res;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    res = rdkafka_read_property(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"isFatal\"), 0);\n\n    if (!res || (Z_TYPE_P(res) != IS_TRUE && Z_TYPE_P(res) != IS_FALSE)) {\n        return;\n    }\n\n    ZVAL_DEREF(res);\n    ZVAL_COPY(return_value, res);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaErrorException::isRetriable()\n    Return true if error is fatal */\nPHP_METHOD(RdKafka_KafkaErrorException, isRetriable)\n{\n    zval *res;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    res = rdkafka_read_property(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"isRetriable\"), 0);\n\n    if (!res || (Z_TYPE_P(res) != IS_TRUE && Z_TYPE_P(res) != IS_FALSE)) {\n        return;\n    }\n\n    ZVAL_DEREF(res);\n    ZVAL_COPY(return_value, res);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\KafkaErrorException::transactionRequiresAbort()\n    Return true if error is fatal */\nPHP_METHOD(RdKafka_KafkaErrorException, transactionRequiresAbort)\n{\n    zval *res;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    res = rdkafka_read_property(ce_kafka_error, Z_OBJ_P(getThis()), ZEND_STRL(\"transactionRequiresAbort\"), 0);\n\n    if (!res || (Z_TYPE_P(res) != IS_TRUE && Z_TYPE_P(res) != IS_FALSE)) {\n        return;\n    }\n\n    ZVAL_DEREF(res);\n    ZVAL_COPY(return_value, res);\n}\n/* }}} */\n\nvoid kafka_error_minit() /* {{{ */\n{\n    ce_kafka_error = register_class_RdKafka_KafkaErrorException(ce_kafka_exception);\n} /* }}} */\n"
        },
        {
          "name": "kafka_error_exception.h",
          "type": "blob",
          "size": 1.3115234375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_interfaces.h\"\n\nextern zend_class_entry * ce_kafka_error;\nvoid kafka_error_minit();\nvoid create_kafka_error(zval *return_value, const rd_kafka_error_t *error);\n"
        },
        {
          "name": "kafka_error_exception.stub.php",
          "type": "blob",
          "size": 0.767578125,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass KafkaErrorException extends Exception\n{\n    private string $error_string;\n\n    private bool $isFatal;\n\n    private bool $isRetriable;\n\n    private bool $transactionRequiresAbort;\n\n    public function __construct(string $message, int $code, string $error_string, bool $isFatal, bool $isRetriable, bool $transactionRequiresAbort) {}\n\n    /** @tentative-return-type */\n    public function getErrorString(): string {}\n\n    /** @tentative-return-type */\n    public function isFatal(): bool {}\n\n    /** @tentative-return-type */\n    public function isRetriable(): bool {}\n\n    /** @tentative-return-type */\n    public function transactionRequiresAbort(): bool {}\n}\n"
        },
        {
          "name": "kafka_error_exception_arginfo.h",
          "type": "blob",
          "size": 4.125,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 1a50cd552973f23b01a2d6b4e5464ba14320c393 */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_KafkaErrorException___construct, 0, 0, 6)\n\tZEND_ARG_TYPE_INFO(0, message, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, code, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, error_string, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, isFatal, _IS_BOOL, 0)\n\tZEND_ARG_TYPE_INFO(0, isRetriable, _IS_BOOL, 0)\n\tZEND_ARG_TYPE_INFO(0, transactionRequiresAbort, _IS_BOOL, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaErrorException_getErrorString, 0, 0, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_KafkaErrorException_isFatal, 0, 0, _IS_BOOL, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_KafkaErrorException_isRetriable arginfo_class_RdKafka_KafkaErrorException_isFatal\n\n#define arginfo_class_RdKafka_KafkaErrorException_transactionRequiresAbort arginfo_class_RdKafka_KafkaErrorException_isFatal\n\n\nZEND_METHOD(RdKafka_KafkaErrorException, __construct);\nZEND_METHOD(RdKafka_KafkaErrorException, getErrorString);\nZEND_METHOD(RdKafka_KafkaErrorException, isFatal);\nZEND_METHOD(RdKafka_KafkaErrorException, isRetriable);\nZEND_METHOD(RdKafka_KafkaErrorException, transactionRequiresAbort);\n\n\nstatic const zend_function_entry class_RdKafka_KafkaErrorException_methods[] = {\n\tZEND_ME(RdKafka_KafkaErrorException, __construct, arginfo_class_RdKafka_KafkaErrorException___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaErrorException, getErrorString, arginfo_class_RdKafka_KafkaErrorException_getErrorString, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaErrorException, isFatal, arginfo_class_RdKafka_KafkaErrorException_isFatal, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaErrorException, isRetriable, arginfo_class_RdKafka_KafkaErrorException_isRetriable, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_KafkaErrorException, transactionRequiresAbort, arginfo_class_RdKafka_KafkaErrorException_transactionRequiresAbort, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_KafkaErrorException(zend_class_entry *class_entry_RdKafka_Exception)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"KafkaErrorException\", class_RdKafka_KafkaErrorException_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka_Exception);\n\n\tzval property_error_string_default_value;\n\tZVAL_UNDEF(&property_error_string_default_value);\n\tzend_string *property_error_string_name = zend_string_init(\"error_string\", sizeof(\"error_string\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_error_string_name, &property_error_string_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_STRING));\n\tzend_string_release(property_error_string_name);\n\n\tzval property_isFatal_default_value;\n\tZVAL_UNDEF(&property_isFatal_default_value);\n\tzend_string *property_isFatal_name = zend_string_init(\"isFatal\", sizeof(\"isFatal\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_isFatal_name, &property_isFatal_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_BOOL));\n\tzend_string_release(property_isFatal_name);\n\n\tzval property_isRetriable_default_value;\n\tZVAL_UNDEF(&property_isRetriable_default_value);\n\tzend_string *property_isRetriable_name = zend_string_init(\"isRetriable\", sizeof(\"isRetriable\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_isRetriable_name, &property_isRetriable_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_BOOL));\n\tzend_string_release(property_isRetriable_name);\n\n\tzval property_transactionRequiresAbort_default_value;\n\tZVAL_UNDEF(&property_transactionRequiresAbort_default_value);\n\tzend_string *property_transactionRequiresAbort_name = zend_string_init(\"transactionRequiresAbort\", sizeof(\"transactionRequiresAbort\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_transactionRequiresAbort_name, &property_transactionRequiresAbort_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_BOOL));\n\tzend_string_release(property_transactionRequiresAbort_name);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "message.c",
          "type": "blob",
          "size": 5.0400390625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"topic.h\"\n#include \"message.h\"\n#include \"message_arginfo.h\"\n\nzend_class_entry * ce_kafka_message;\n\nvoid kafka_message_new(zval *return_value, const rd_kafka_message_t *message, zend_string *msg_opaque)\n{\n    object_init_ex(return_value, ce_kafka_message);\n\n    rd_kafka_timestamp_type_t tstype;\n    int64_t timestamp;\n\n    timestamp = rd_kafka_message_timestamp(message, &tstype);\n\n    zval headers_array;\n    rd_kafka_headers_t *message_headers = NULL;\n    rd_kafka_resp_err_t header_response;\n    const char *header_name = NULL;\n    const void *header_value = NULL;\n    size_t header_size = 0;\n    size_t i;\n\n    zend_update_property_long(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"err\"), message->err);\n\n    if (message->rkt) {\n        zend_update_property_string(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"topic_name\"), rd_kafka_topic_name(message->rkt));\n    }\n    zend_update_property_long(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"partition\"), message->partition);\n    if (message->payload) {\n        zend_update_property_long(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"timestamp\"), timestamp);\n        zend_update_property_stringl(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"payload\"), message->payload, message->len);\n        zend_update_property_long(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"len\"), message->len);\n    }\n    if (message->key) {\n        zend_update_property_stringl(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"key\"), message->key, message->key_len);\n    }\n    zend_update_property_long(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"offset\"), message->offset);\n\n    array_init(&headers_array);\n    if (message->err == RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_message_headers(message, &message_headers);\n        if (message_headers != NULL) {\n            for (i = 0; i < rd_kafka_header_cnt(message_headers); i++) {\n                header_response = rd_kafka_header_get_all(message_headers, i, &header_name, &header_value, &header_size);\n                if (header_response != RD_KAFKA_RESP_ERR_NO_ERROR) {\n                    break;\n                }\n                add_assoc_stringl(&headers_array, header_name, (const char*)header_value, header_size);\n            }\n        }\n    }\n    zend_update_property(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"headers\"), &headers_array);\n    zval_ptr_dtor(&headers_array);\n\n    if (msg_opaque != NULL) {\n        zend_update_property_str(NULL, Z_OBJ_P(return_value), ZEND_STRL(\"opaque\"), msg_opaque);\n    }\n}\n\nvoid kafka_message_list_to_array(zval *return_value, rd_kafka_message_t **messages, long size) /* {{{ */\n{\n    rd_kafka_message_t *msg;\n    zval zmsg;\n    int i;\n\n    array_init_size(return_value, size);\n\n    for (i = 0; i < size; i++) {\n        msg = messages[i];\n        ZVAL_NULL(&zmsg);\n        kafka_message_new(&zmsg, msg, NULL);\n        add_next_index_zval(return_value, &zmsg);\n    }\n} /* }}} */\n\n/* {{{ proto string RdKafka\\Message::errstr()\n *  Returns the error string for an errored KrKafka\\Message or NULL if there was no error.\n */\nPHP_METHOD(RdKafka_Message, errstr)\n{\n    zval *zerr;\n    zval *zpayload;\n    const char *errstr;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    zerr = rdkafka_read_property(NULL, Z_OBJ_P(getThis()), ZEND_STRL(\"err\"), 0);\n\n    if (!zerr || Z_TYPE_P(zerr) != IS_LONG) {\n        return;\n    }\n\n    errstr = rd_kafka_err2str(Z_LVAL_P(zerr));\n\n    if (errstr) {\n        RETURN_STRING(errstr);\n    }\n\n    zpayload = rdkafka_read_property(NULL, Z_OBJ_P(getThis()), ZEND_STRL(\"payload\"), 0);\n\n    if (zpayload && Z_TYPE_P(zpayload) == IS_STRING) {\n        RETURN_ZVAL(zpayload, 1, 0);\n    }\n}\n/* }}} */\n\nvoid kafka_message_minit(INIT_FUNC_ARGS) { /* {{{ */\n    ce_kafka_message = register_class_RdKafka_Message();\n} /* }}} */\n"
        },
        {
          "name": "message.h",
          "type": "blob",
          "size": 1.3857421875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_message_minit(INIT_FUNC_ARGS);\nvoid kafka_message_new(zval *return_value, const rd_kafka_message_t *message, zend_string *msg_opaque);\nvoid kafka_message_list_to_array(zval *return_value, rd_kafka_message_t **messages, long size);\n\nextern zend_class_entry * ce_kafka_message;\n"
        },
        {
          "name": "message.stub.php",
          "type": "blob",
          "size": 0.5166015625,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass Message\n{\n    public int $err;\n\n    public ?string $topic_name = null;\n\n    public ?int $timestamp = null;\n\n    public int $partition;\n\n    public ?string $payload = null;\n\n    public ?int $len = null;\n\n    public ?string $key = null;\n\n    public int $offset;\n\n    public array $headers;\n\n    public ?string $opaque = null;\n\n    /** @tentative-return-type */\n    public function errstr(): ?string {}\n}\n"
        },
        {
          "name": "message_arginfo.h",
          "type": "blob",
          "size": 4.548828125,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: f642f90b8a3c35c353320c0574902898a3645ee1 */\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Message_errstr, 0, 0, IS_STRING, 1)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka_Message, errstr);\n\n\nstatic const zend_function_entry class_RdKafka_Message_methods[] = {\n\tZEND_ME(RdKafka_Message, errstr, arginfo_class_RdKafka_Message_errstr, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Message(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Message\", class_RdKafka_Message_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\tzval property_err_default_value;\n\tZVAL_UNDEF(&property_err_default_value);\n\tzend_string *property_err_name = zend_string_init(\"err\", sizeof(\"err\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_err_name, &property_err_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_LONG));\n\tzend_string_release(property_err_name);\n\n\tzval property_topic_name_default_value;\n\tZVAL_NULL(&property_topic_name_default_value);\n\tzend_string *property_topic_name_name = zend_string_init(\"topic_name\", sizeof(\"topic_name\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_topic_name_name, &property_topic_name_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_STRING|MAY_BE_NULL));\n\tzend_string_release(property_topic_name_name);\n\n\tzval property_timestamp_default_value;\n\tZVAL_NULL(&property_timestamp_default_value);\n\tzend_string *property_timestamp_name = zend_string_init(\"timestamp\", sizeof(\"timestamp\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_timestamp_name, &property_timestamp_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_LONG|MAY_BE_NULL));\n\tzend_string_release(property_timestamp_name);\n\n\tzval property_partition_default_value;\n\tZVAL_UNDEF(&property_partition_default_value);\n\tzend_string *property_partition_name = zend_string_init(\"partition\", sizeof(\"partition\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_partition_name, &property_partition_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_LONG));\n\tzend_string_release(property_partition_name);\n\n\tzval property_payload_default_value;\n\tZVAL_NULL(&property_payload_default_value);\n\tzend_string *property_payload_name = zend_string_init(\"payload\", sizeof(\"payload\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_payload_name, &property_payload_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_STRING|MAY_BE_NULL));\n\tzend_string_release(property_payload_name);\n\n\tzval property_len_default_value;\n\tZVAL_NULL(&property_len_default_value);\n\tzend_string *property_len_name = zend_string_init(\"len\", sizeof(\"len\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_len_name, &property_len_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_LONG|MAY_BE_NULL));\n\tzend_string_release(property_len_name);\n\n\tzval property_key_default_value;\n\tZVAL_NULL(&property_key_default_value);\n\tzend_string *property_key_name = zend_string_init(\"key\", sizeof(\"key\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_key_name, &property_key_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_STRING|MAY_BE_NULL));\n\tzend_string_release(property_key_name);\n\n\tzval property_offset_default_value;\n\tZVAL_UNDEF(&property_offset_default_value);\n\tzend_string *property_offset_name = zend_string_init(\"offset\", sizeof(\"offset\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_offset_name, &property_offset_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_LONG));\n\tzend_string_release(property_offset_name);\n\n\tzval property_headers_default_value;\n\tZVAL_UNDEF(&property_headers_default_value);\n\tzend_string *property_headers_name = zend_string_init(\"headers\", sizeof(\"headers\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_headers_name, &property_headers_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_ARRAY));\n\tzend_string_release(property_headers_name);\n\n\tzval property_opaque_default_value;\n\tZVAL_NULL(&property_opaque_default_value);\n\tzend_string *property_opaque_name = zend_string_init(\"opaque\", sizeof(\"opaque\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_opaque_name, &property_opaque_default_value, ZEND_ACC_PUBLIC, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_STRING|MAY_BE_NULL));\n\tzend_string_release(property_opaque_name);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "metadata.c",
          "type": "blob",
          "size": 6.3662109375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"metadata_collection.h\"\n#include \"metadata_topic.h\"\n#include \"metadata_broker.h\"\n#include \"metadata_partition.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"metadata_arginfo.h\"\n\ntypedef struct _object_intern {\n    const rd_kafka_metadata_t *metadata;\n    zend_object               std;\n} object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nstatic zend_class_entry * ce;\nstatic zend_object_handlers handlers;\n\nstatic void brokers_collection(zval *return_value, zend_object *parent, object_intern *intern) { /* {{{ */\n    kafka_metadata_collection_init(return_value, parent, intern->metadata->brokers, intern->metadata->broker_cnt, sizeof(*intern->metadata->brokers), kafka_metadata_broker_ctor);\n}\n/* }}} */\n\nstatic void topics_collection(zval *return_value, zend_object *parent, object_intern *intern) { /* {{{ */\n    kafka_metadata_collection_init(return_value, parent, intern->metadata->topics, intern->metadata->topic_cnt, sizeof(*intern->metadata->topics), kafka_metadata_topic_ctor);\n}\n/* }}} */\n\nstatic void kafka_metadata_free(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->metadata) {\n        rd_kafka_metadata_destroy(intern->metadata);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *kafka_metadata_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zmetadata)\n{\n    object_intern *ometadata = Z_RDKAFKA_P(object_intern, zmetadata);\n\n    if (!ometadata->metadata) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Metadata::__construct() has not been called\");\n        return NULL;\n    }\n\n    return ometadata;\n}\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n    zval brokers;\n    zval topics;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n    if (!intern || !intern->metadata) {\n        return Z_ARRVAL(ary);\n    }\n\n    ZVAL_NULL(&brokers);\n    brokers_collection(&brokers, object, intern);\n    add_assoc_zval(&ary, \"brokers\", &brokers);\n\n    ZVAL_NULL(&topics);\n    topics_collection(&topics, object, intern);\n    add_assoc_zval(&ary, \"topics\", &topics);\n\n    add_assoc_long(&ary, \"orig_broker_id\", intern->metadata->orig_broker_id);\n    add_assoc_string(&ary, \"orig_broker_name\", intern->metadata->orig_broker_name);\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\n/* {{{ proto long RdKafka\\Metadata::getOrigBrokerId()\n   Broker originating this metadata */\nPHP_METHOD(RdKafka_Metadata, getOrigBrokerId)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata->orig_broker_id);\n}\n/* }}} */\n\n/* {{{ proto string RdKafka\\Metadata::getOrigBrokerName()\n   Name of originating broker */\nPHP_METHOD(RdKafka_Metadata, getOrigBrokerName)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_STRING(intern->metadata->orig_broker_name);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Metadata\\Collection RdKafka\\Metadata::getBrokers()\n   Topics */\nPHP_METHOD(RdKafka_Metadata, getBrokers)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    brokers_collection(return_value, Z_OBJ_P(getThis()), intern);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Metadata\\Collection RdKafka\\Metadata::getTopics()\n   Topics */\nPHP_METHOD(RdKafka_Metadata, getTopics)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topics_collection(return_value, Z_OBJ_P(getThis()), intern);\n}\n/* }}} */\n\nvoid kafka_metadata_minit(INIT_FUNC_ARGS)\n{\n    ce = register_class_RdKafka_Metadata();\n    ce->create_object = kafka_metadata_new;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = kafka_metadata_free;\n    handlers.offset = XtOffsetOf(object_intern, std);\n\n    kafka_metadata_topic_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_metadata_broker_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_metadata_partition_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_metadata_collection_minit(INIT_FUNC_ARGS_PASSTHRU);\n}\n\nvoid kafka_metadata_init(zval *return_value, const rd_kafka_metadata_t *metadata)\n{\n    object_intern *intern;\n\n    if (object_init_ex(return_value, ce) != SUCCESS) {\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, return_value);\n    if (!intern) {\n        return;\n    }\n\n    intern->metadata = metadata;\n}\n"
        },
        {
          "name": "metadata.h",
          "type": "blob",
          "size": 1.228515625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_metadata_minit(INIT_FUNC_ARGS);\nvoid kafka_metadata_init(zval *return_value, const rd_kafka_metadata_t *metadata);\n"
        },
        {
          "name": "metadata.stub.php",
          "type": "blob",
          "size": 0.568359375,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass Metadata\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function getOrigBrokerId(): int {}\n\n    /** @tentative-return-type */\n    public function getOrigBrokerName(): string {}\n\n    /** @tentative-return-type */\n    public function getBrokers(): Metadata\\Collection {}\n\n    /** @tentative-return-type */\n    public function getTopics(): Metadata\\Collection {}\n}\n"
        },
        {
          "name": "metadata_arginfo.h",
          "type": "blob",
          "size": 1.7998046875,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 6c980079f802be29ef2c30e235a6071f5c0d628c */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Metadata___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_getOrigBrokerId, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_getOrigBrokerName, 0, 0, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_Metadata_getBrokers, 0, 0, RdKafka\\\\Metadata\\\\Collection, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_getTopics arginfo_class_RdKafka_Metadata_getBrokers\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Metadata, getOrigBrokerId);\nZEND_METHOD(RdKafka_Metadata, getOrigBrokerName);\nZEND_METHOD(RdKafka_Metadata, getBrokers);\nZEND_METHOD(RdKafka_Metadata, getTopics);\n\n\nstatic const zend_function_entry class_RdKafka_Metadata_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Metadata___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Metadata, getOrigBrokerId, arginfo_class_RdKafka_Metadata_getOrigBrokerId, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata, getOrigBrokerName, arginfo_class_RdKafka_Metadata_getOrigBrokerName, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata, getBrokers, arginfo_class_RdKafka_Metadata_getBrokers, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata, getTopics, arginfo_class_RdKafka_Metadata_getTopics, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Metadata(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Metadata\", class_RdKafka_Metadata_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "metadata_broker.c",
          "type": "blob",
          "size": 5.001953125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"metadata_broker_arginfo.h\"\n\ntypedef struct _object_intern {\n    zval                            zmetadata;\n    const rd_kafka_metadata_broker_t *metadata_broker;\n    zend_object                     std;\n} object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nstatic zend_class_entry * ce;\nstatic zend_object_handlers handlers;\n\nstatic void free_object(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->metadata_broker) {\n        zval_dtor(&intern->zmetadata);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *create_object(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zmt)\n{\n    object_intern *omt = Z_RDKAFKA_P(object_intern, zmt);\n\n    if (!omt->metadata_broker) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Metadata\\\\Broker::__construct() has not been called\");\n        return NULL;\n    }\n\n    return omt;\n}\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n    if (!intern || !intern->metadata_broker) {\n        return Z_ARRVAL(ary);\n    }\n\n    add_assoc_long(&ary, \"id\", intern->metadata_broker->id);\n    add_assoc_string(&ary, \"host\", intern->metadata_broker->host);\n    add_assoc_long(&ary, \"port\", intern->metadata_broker->port);\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Broker::getId()\n   Broker id */\nPHP_METHOD(RdKafka_Metadata_Broker, getId)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_broker->id);\n}\n/* }}} */\n\n/* {{{ proto string RdKafka\\Metadata\\Broker::getHost()\n   Broker hostname */\nPHP_METHOD(RdKafka_Metadata_Broker, getHost)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_STRING(intern->metadata_broker->host);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Broker::getPort()\n   Broker port */\nPHP_METHOD(RdKafka_Metadata_Broker, getPort)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_broker->port);\n}\n/* }}} */\n\nvoid kafka_metadata_broker_minit(INIT_FUNC_ARGS)\n{\n    ce = register_class_RdKafka_Metadata_Broker();\n    ce->create_object = create_object;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = free_object;\n    handlers.offset = XtOffsetOf(object_intern, std);\n}\n\nvoid kafka_metadata_broker_ctor(zval *return_value, zval *zmetadata, const void *data)\n{\n    rd_kafka_metadata_broker_t *metadata_broker = (rd_kafka_metadata_broker_t*)data;\n    object_intern *intern;\n\n    if (object_init_ex(return_value, ce) != SUCCESS) {\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, return_value);\n    if (!intern) {\n        return;\n    }\n\n    ZVAL_ZVAL(&intern->zmetadata, zmetadata, 1, 0);\n    intern->metadata_broker = metadata_broker;\n}\n"
        },
        {
          "name": "metadata_broker.h",
          "type": "blob",
          "size": 1.2509765625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_metadata_broker_minit(INIT_FUNC_ARGS);\nvoid kafka_metadata_broker_ctor(zval *return_value, zval *zmetadata, const void *metadata_broker);\n"
        },
        {
          "name": "metadata_broker.stub.php",
          "type": "blob",
          "size": 0.4482421875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka\\Metadata;\n\nclass Broker\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function getId(): int {}\n\n    /** @tentative-return-type */\n    public function getHost(): string {}\n\n    /** @tentative-return-type */\n    public function getPort(): int {}\n}\n"
        },
        {
          "name": "metadata_broker_arginfo.h",
          "type": "blob",
          "size": 1.5517578125,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 74c6ee55c31bb86f5bcf71a46607f31688ce71dd */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Metadata_Broker___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Broker_getId, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Broker_getHost, 0, 0, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_Broker_getPort arginfo_class_RdKafka_Metadata_Broker_getId\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Metadata_Broker, getId);\nZEND_METHOD(RdKafka_Metadata_Broker, getHost);\nZEND_METHOD(RdKafka_Metadata_Broker, getPort);\n\n\nstatic const zend_function_entry class_RdKafka_Metadata_Broker_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Metadata_Broker___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Metadata_Broker, getId, arginfo_class_RdKafka_Metadata_Broker_getId, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Broker, getHost, arginfo_class_RdKafka_Metadata_Broker_getHost, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Broker, getPort, arginfo_class_RdKafka_Metadata_Broker_getPort, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Metadata_Broker(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\\\\Metadata\", \"Broker\", class_RdKafka_Metadata_Broker_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "metadata_collection.c",
          "type": "blob",
          "size": 6.681640625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"metadata_collection.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"metadata_collection_arginfo.h\"\n\ntypedef struct _object_intern {\n    zval                             zmetadata;\n    const void                       *items;\n    size_t                           item_cnt;\n    size_t                           item_size;\n    size_t                           position;\n    kafka_metadata_collection_ctor_t ctor;\n    zend_object                      std;\n} object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nstatic zend_class_entry *ce;\nstatic zend_object_handlers handlers;\n\nstatic void free_object(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->items) {\n        zval_dtor(&intern->zmetadata);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *create_object(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zmti)\n{\n    object_intern *omti = Z_RDKAFKA_P(object_intern, zmti);\n\n    if (!omti->items) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Metadata\\\\Collection::__construct() has not been called\");\n        return NULL;\n    }\n\n    return omti;\n}\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n    size_t i;\n    zval item;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n    if (!intern || !intern->items) {\n        return Z_ARRVAL(ary);\n    }\n    \n    for (i = 0; i < intern->item_cnt; i++) {\n        ZVAL_NULL(&item);\n        intern->ctor(&item, &intern->zmetadata, (char *)intern->items + i * intern->item_size);\n        add_next_index_zval(&ary, &item);\n    }\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Collection::count()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, count)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->item_cnt);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Metadata\\Collection::rewind()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, rewind)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    intern->position = 0;\n}\n/* }}} */\n\n/* {{{ proto mixed RdKafka\\Metadata\\Collection::current()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, current)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (intern->position >= intern->item_cnt) {\n        zend_throw_exception(ce_kafka_exception, \"Called current() on invalid iterator\", 0);\n        return;\n    }\n\n    intern->ctor(return_value, &intern->zmetadata, (char *)intern->items + intern->position * intern->item_size);\n}\n/* }}} */\n\n/* {{{ proto mixed RdKafka\\Metadata\\Collection::key()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, key)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (intern->position >= intern->item_cnt) {\n        zend_throw_exception(ce_kafka_exception, \"Called key() on invalid iterator\", 0);\n        return;\n    }\n\n    RETURN_LONG(intern->position);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\Metadata\\Collection::next()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, next)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    intern->position ++;\n}\n/* }}} */\n\n/* {{{ proto bool RdKafka\\Metadata\\Collection::valid()\n   */\nPHP_METHOD(RdKafka_Metadata_Collection, valid)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_BOOL(intern->position < intern->item_cnt);\n}\n/* }}} */\n\nvoid kafka_metadata_collection_minit(INIT_FUNC_ARGS)\n{\n    ce = register_class_RdKafka_Metadata_Collection(zend_ce_countable, zend_ce_iterator);\n    ce->create_object = create_object;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = free_object;\n    handlers.offset = XtOffsetOf(object_intern, std);\n}\n\nvoid kafka_metadata_collection_init(zval *return_value, zend_object *zmetadata, const void * items, size_t item_cnt, size_t item_size, kafka_metadata_collection_ctor_t ctor)\n{\n    object_intern *intern;\n\n    if (object_init_ex(return_value, ce) != SUCCESS) {\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, return_value);\n    if (!intern) {\n        return;\n    }\n\n    ZVAL_OBJ_COPY(&intern->zmetadata, zmetadata);\n    intern->items = items;\n    intern->item_cnt = item_cnt;\n    intern->item_size = item_size;\n    intern->ctor = ctor;\n}\n"
        },
        {
          "name": "metadata_collection.h",
          "type": "blob",
          "size": 1.4345703125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\ntypedef void (*kafka_metadata_collection_ctor_t)(zval *renurn_value, zval *zmetadata, const void *object);\n\nvoid kafka_metadata_collection_minit(INIT_FUNC_ARGS);\nvoid kafka_metadata_collection_init(zval *return_value, zend_object *zmetadata, const void * items, size_t item_cnt, size_t item_size, kafka_metadata_collection_ctor_t ctor);\n"
        },
        {
          "name": "metadata_collection.stub.php",
          "type": "blob",
          "size": 0.6904296875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka\\Metadata;\n\nclass Collection implements \\Countable, \\Iterator\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function count(): int {}\n\n    /** @tentative-return-type */\n    public function current(): mixed {}\n\n    /** @tentative-return-type */\n    public function key(): int {}\n\n    /** @tentative-return-type */\n    public function next(): void {}\n\n    /** @tentative-return-type */\n    public function rewind(): void {}\n\n    /** @tentative-return-type */\n    public function valid(): bool {}\n}\n"
        },
        {
          "name": "metadata_collection_arginfo.h",
          "type": "blob",
          "size": 2.6064453125,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 43c071a00a4c0beb6b5c1f8f685e29b746c2d3fb */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Metadata_Collection___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Collection_count, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Collection_current, 0, 0, IS_MIXED, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_Collection_key arginfo_class_RdKafka_Metadata_Collection_count\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Collection_next, 0, 0, IS_VOID, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_Collection_rewind arginfo_class_RdKafka_Metadata_Collection_next\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Collection_valid, 0, 0, _IS_BOOL, 0)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Metadata_Collection, count);\nZEND_METHOD(RdKafka_Metadata_Collection, current);\nZEND_METHOD(RdKafka_Metadata_Collection, key);\nZEND_METHOD(RdKafka_Metadata_Collection, next);\nZEND_METHOD(RdKafka_Metadata_Collection, rewind);\nZEND_METHOD(RdKafka_Metadata_Collection, valid);\n\n\nstatic const zend_function_entry class_RdKafka_Metadata_Collection_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Metadata_Collection___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Metadata_Collection, count, arginfo_class_RdKafka_Metadata_Collection_count, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Collection, current, arginfo_class_RdKafka_Metadata_Collection_current, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Collection, key, arginfo_class_RdKafka_Metadata_Collection_key, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Collection, next, arginfo_class_RdKafka_Metadata_Collection_next, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Collection, rewind, arginfo_class_RdKafka_Metadata_Collection_rewind, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Collection, valid, arginfo_class_RdKafka_Metadata_Collection_valid, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Metadata_Collection(zend_class_entry *class_entry_Countable, zend_class_entry *class_entry_Iterator)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\\\\Metadata\", \"Collection\", class_RdKafka_Metadata_Collection_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\tzend_class_implements(class_entry, 2, class_entry_Countable, class_entry_Iterator);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "metadata_partition.c",
          "type": "blob",
          "size": 6.451171875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"metadata_collection.h\"\n#include \"metadata_partition_arginfo.h\"\n\ntypedef struct _object_intern {\n    zval                            zmetadata;\n    const rd_kafka_metadata_partition_t *metadata_partition;\n    zend_object                     std;\n} object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nstatic zend_class_entry * ce;\nstatic zend_object_handlers handlers;\n\nstatic void free_object(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->metadata_partition) {\n        zval_dtor(&intern->zmetadata);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *create_object(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zmt)\n{\n    object_intern *omt = Z_RDKAFKA_P(object_intern, zmt);\n\n    if (!omt->metadata_partition) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Metadata\\\\Partition::__construct() has not been called\");\n        return NULL;\n    }\n\n    return omt;\n}\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n    if (!intern || !intern->metadata_partition) {\n        return Z_ARRVAL(ary);\n    }\n\n    add_assoc_long(&ary, \"id\", intern->metadata_partition->id);\n    add_assoc_long(&ary, \"err\", intern->metadata_partition->err);\n    add_assoc_long(&ary, \"leader\", intern->metadata_partition->leader);\n    add_assoc_long(&ary, \"replica_cnt\", intern->metadata_partition->replica_cnt);\n    add_assoc_long(&ary, \"isr_cnt\", intern->metadata_partition->isr_cnt);\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Partition::getId()\n   Partition id */\nPHP_METHOD(RdKafka_Metadata_Partition, getId)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_partition->id);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Partition::getErr()\n   Partition error reported by broker */\nPHP_METHOD(RdKafka_Metadata_Partition, getErr)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_partition->err);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Metadata\\Partition::getLeader()\n   Leader broker */\nPHP_METHOD(RdKafka_Metadata_Partition, getLeader)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_partition->leader);\n}\n/* }}} */\n\nvoid int32_ctor(zval *return_value, zval *zmetadata, const void *data) {\n    ZVAL_LONG(return_value, *(int32_t*)data);\n}\n\n/* {{{ proto array RdKafka\\Metadata\\Partition::getReplicas()\n   Replica broker ids */\nPHP_METHOD(RdKafka_Metadata_Partition, getReplicas)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    kafka_metadata_collection_init(return_value, Z_OBJ_P(getThis()), intern->metadata_partition->replicas, intern->metadata_partition->replica_cnt, sizeof(*intern->metadata_partition->replicas), int32_ctor);\n}\n/* }}} */\n\n/* {{{ proto array RdKafka\\Metadata\\Partition::getIsrs()\n   In-Sync-Replica broker ids */\nPHP_METHOD(RdKafka_Metadata_Partition, getIsrs)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    kafka_metadata_collection_init(return_value, Z_OBJ_P(getThis()), intern->metadata_partition->isrs, intern->metadata_partition->isr_cnt, sizeof(*intern->metadata_partition->isrs), int32_ctor);\n}\n/* }}} */\n\nvoid kafka_metadata_partition_minit(INIT_FUNC_ARGS)\n{\n    ce = register_class_RdKafka_Metadata_Partition();\n    ce->create_object = create_object;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = free_object;\n    handlers.offset = XtOffsetOf(object_intern, std);\n}\n\nvoid kafka_metadata_partition_ctor(zval *return_value, zval *zmetadata, const void *data)\n{\n    rd_kafka_metadata_partition_t *metadata_partition = (rd_kafka_metadata_partition_t*)data;\n    object_intern *intern;\n\n    if (object_init_ex(return_value, ce) != SUCCESS) {\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, return_value);\n    if (!intern) {\n        return;\n    }\n\n    ZVAL_ZVAL(&intern->zmetadata, zmetadata, 1, 0);\n    intern->metadata_partition = metadata_partition;\n}\n"
        },
        {
          "name": "metadata_partition.h",
          "type": "blob",
          "size": 1.259765625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_metadata_partition_minit(INIT_FUNC_ARGS);\nvoid kafka_metadata_partition_ctor(zval *return_value, zval *zmetadata, const void *metadata_partition);\n"
        },
        {
          "name": "metadata_partition.stub.php",
          "type": "blob",
          "size": 0.64453125,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka\\Metadata;\n\nclass Partition\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function getId(): int {}\n\n    /** @tentative-return-type */\n    public function getErr(): int {}\n\n    /** @tentative-return-type */\n    public function getLeader(): int {}\n\n    /** @tentative-return-type */\n    public function getReplicas(): \\RdKafka\\Metadata\\Collection {}\n\n    /** @tentative-return-type */\n    public function getIsrs(): \\RdKafka\\Metadata\\Collection {}\n}\n"
        },
        {
          "name": "metadata_partition_arginfo.h",
          "type": "blob",
          "size": 2.1748046875,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: ce824cf273ec8fec1fe3b6eaac015a51f3e9dc6b */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Metadata_Partition___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Partition_getId, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_Partition_getErr arginfo_class_RdKafka_Metadata_Partition_getId\n\n#define arginfo_class_RdKafka_Metadata_Partition_getLeader arginfo_class_RdKafka_Metadata_Partition_getId\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_Metadata_Partition_getReplicas, 0, 0, RdKafka\\\\Metadata\\\\Collection, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Metadata_Partition_getIsrs arginfo_class_RdKafka_Metadata_Partition_getReplicas\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Metadata_Partition, getId);\nZEND_METHOD(RdKafka_Metadata_Partition, getErr);\nZEND_METHOD(RdKafka_Metadata_Partition, getLeader);\nZEND_METHOD(RdKafka_Metadata_Partition, getReplicas);\nZEND_METHOD(RdKafka_Metadata_Partition, getIsrs);\n\n\nstatic const zend_function_entry class_RdKafka_Metadata_Partition_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Metadata_Partition___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Metadata_Partition, getId, arginfo_class_RdKafka_Metadata_Partition_getId, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Partition, getErr, arginfo_class_RdKafka_Metadata_Partition_getErr, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Partition, getLeader, arginfo_class_RdKafka_Metadata_Partition_getLeader, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Partition, getReplicas, arginfo_class_RdKafka_Metadata_Partition_getReplicas, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Partition, getIsrs, arginfo_class_RdKafka_Metadata_Partition_getIsrs, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Metadata_Partition(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\\\\Metadata\", \"Partition\", class_RdKafka_Metadata_Partition_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "metadata_topic.c",
          "type": "blob",
          "size": 5.5126953125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"metadata_partition.h\"\n#include \"metadata_collection.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"metadata_topic_arginfo.h\"\n\ntypedef struct _object_intern {\n    zval                            zmetadata;\n    const rd_kafka_metadata_topic_t *metadata_topic;\n    zend_object                     std;\n} object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nstatic zend_class_entry * ce;\nstatic zend_object_handlers handlers;\n\nstatic void partitions_collection(zval *return_value, zend_object *parent, object_intern *intern) { /* {{{ */\n    kafka_metadata_collection_init(return_value, parent, intern->metadata_topic->partitions, intern->metadata_topic->partition_cnt, sizeof(*intern->metadata_topic->partitions), kafka_metadata_partition_ctor);\n}\n/* }}} */\n\nstatic void free_object(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->metadata_topic) {\n        zval_dtor(&intern->zmetadata);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *create_object(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *zmt)\n{\n    object_intern *omt = Z_RDKAFKA_P(object_intern, zmt);\n\n    if (!omt->metadata_topic) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Metadata\\\\Topic::__construct() has not been called\");\n        return NULL;\n    }\n\n    return omt;\n}\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n    zval partitions;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n    if (!intern || !intern->metadata_topic) {\n        return Z_ARRVAL(ary);\n    }\n\n    add_assoc_string(&ary, \"topic\", intern->metadata_topic->topic);\n\n    ZVAL_NULL(&partitions);\n    partitions_collection(&partitions, object, intern);\n    add_assoc_zval(&ary, \"partitions\", &partitions);\n\n    add_assoc_long(&ary, \"err\", intern->metadata_topic->err);\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\n/* {{{ proto string RdKafka\\MetadataTopic::getTopic()\n   Topic name */\nPHP_METHOD(RdKafka_Metadata_Topic, getTopic)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_STRING(intern->metadata_topic->topic);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\MetadataTopic::getErr()\n   Error */\nPHP_METHOD(RdKafka_Metadata_Topic, getErr)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->metadata_topic->err);\n}\n/* }}} */\n\n\n/* {{{ proto RdKafka\\Metadata\\Collection RdKafka\\Metadata\\Topic::getPartitions()\n   Partitions */\nPHP_METHOD(RdKafka_Metadata_Topic, getPartitions)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    partitions_collection(return_value, Z_OBJ_P(getThis()), intern);\n}\n/* }}} */\n\nvoid kafka_metadata_topic_minit(INIT_FUNC_ARGS)\n{\n    ce = register_class_RdKafka_Metadata_Topic();\n    ce->create_object = create_object;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = free_object;\n    handlers.offset = XtOffsetOf(object_intern, std);\n}\n\nvoid kafka_metadata_topic_ctor(zval *return_value, zval *zmetadata, const void *data)\n{\n    rd_kafka_metadata_topic_t *metadata_topic = (rd_kafka_metadata_topic_t*)data;\n    object_intern *intern;\n\n    if (object_init_ex(return_value, ce) != SUCCESS) {\n        return;\n    }\n\n    intern = Z_RDKAFKA_P(object_intern, return_value);\n    if (!intern) {\n        return;\n    }\n\n    ZVAL_ZVAL(&intern->zmetadata, zmetadata, 1, 0);\n    intern->metadata_topic = metadata_topic;\n}\n"
        },
        {
          "name": "metadata_topic.h",
          "type": "blob",
          "size": 1.248046875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\nvoid kafka_metadata_topic_minit(INIT_FUNC_ARGS);\nvoid kafka_metadata_topic_ctor(zval *return_value, zval *zmetadata, const void *metadata_topic);\n"
        },
        {
          "name": "metadata_topic.stub.php",
          "type": "blob",
          "size": 0.4794921875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka\\Metadata;\n\nclass Topic\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function getTopic(): string {}\n\n    /** @tentative-return-type */\n    public function getErr(): int {}\n\n    /** @tentative-return-type */\n    public function getPartitions(): \\RdKafka\\Metadata\\Collection {}\n}\n"
        },
        {
          "name": "metadata_topic_arginfo.h",
          "type": "blob",
          "size": 1.6220703125,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 04fd71ae954bd0a09730d401c8160574e1045369 */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Metadata_Topic___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Topic_getTopic, 0, 0, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Metadata_Topic_getErr, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_Metadata_Topic_getPartitions, 0, 0, RdKafka\\\\Metadata\\\\Collection, 0)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Metadata_Topic, getTopic);\nZEND_METHOD(RdKafka_Metadata_Topic, getErr);\nZEND_METHOD(RdKafka_Metadata_Topic, getPartitions);\n\n\nstatic const zend_function_entry class_RdKafka_Metadata_Topic_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Metadata_Topic___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Metadata_Topic, getTopic, arginfo_class_RdKafka_Metadata_Topic_getTopic, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Topic, getErr, arginfo_class_RdKafka_Metadata_Topic_getErr, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Metadata_Topic, getPartitions, arginfo_class_RdKafka_Metadata_Topic_getPartitions, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Metadata_Topic(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\\\\Metadata\", \"Topic\", class_RdKafka_Metadata_Topic_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "package.xml",
          "type": "blob",
          "size": 25.5322265625,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<package xmlns=\"http://pear.php.net/dtd/package-2.1\" xmlns:tasks=\"http://pear.php.net/dtd/tasks-1.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"2.1\" xsi:schemaLocation=\"http://pear.php.net/dtd/tasks-1.0     http://pear.php.net/dtd/tasks-1.0.xsd     http://pear.php.net/dtd/package-2.1     http://pear.php.net/dtd/package-2.1.xsd\">\n <name>rdkafka</name>\n <channel>pecl.php.net</channel>\n <summary>Kafka client based on librdkafka</summary>\n <description>PHP-rdkafka is a stable Kafka client for PHP based on librdkafka</description>\n <lead>\n  <name>Arnaud Le Blanc</name>\n  <user>lbarnaud</user>\n  <email>arnaud.lb@gmail.com</email>\n  <active>yes</active>\n </lead>\n <date>2024-11-04</date>\n <time>11:24:15</time>\n <version>\n  <release>6.0.5</release>\n  <api>6.0.0</api>\n </version>\n <stability>\n  <release>stable</release>\n  <api>stable</api>\n </stability>\n <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n <notes>\n  ## Bug fixes\n  - Fix php 7.0 build (#563, @arnaud-lb)\n  - Fix x32 build (#565, @arnaud-lb)\n  - Fix segmentation fault in setOauthbearerTokenRefreshCb when sasl.oauthbearer.config is unset (#568, @scorgn)\n </notes>\n <contents>\n  <dir name=\"/\">\n   <file role=\"doc\" name=\"CREDITS\"/>\n   <file role=\"doc\" name=\"LICENSE\"/>\n   <file role=\"doc\" name=\"README.md\"/>\n   <file role=\"src\" name=\"conf.c\"/>\n   <file role=\"src\" name=\"conf.h\"/>\n   <file role=\"src\" name=\"conf.stub.php\"/>\n   <file role=\"src\" name=\"conf_arginfo.h\"/>\n   <file role=\"src\" name=\"config.m4\"/>\n   <file role=\"src\" name=\"config.w32\"/>\n   <file role=\"src\" name=\"fun.c\"/>\n   <file role=\"src\" name=\"fun.stub.php\"/>\n   <file role=\"src\" name=\"fun_arginfo.h\"/>\n   <file role=\"src\" name=\"kafka_consumer.c\"/>\n   <file role=\"src\" name=\"kafka_consumer.h\"/>\n   <file role=\"src\" name=\"kafka_consumer.stub.php\"/>\n   <file role=\"src\" name=\"kafka_consumer_arginfo.h\"/>\n   <file role=\"src\" name=\"kafka_error_exception.c\"/>\n   <file role=\"src\" name=\"kafka_error_exception.h\"/>\n   <file role=\"src\" name=\"kafka_error_exception.stub.php\"/>\n   <file role=\"src\" name=\"kafka_error_exception_arginfo.h\"/>\n   <file role=\"src\" name=\"message.c\"/>\n   <file role=\"src\" name=\"message.h\"/>\n   <file role=\"src\" name=\"message.stub.php\"/>\n   <file role=\"src\" name=\"message_arginfo.h\"/>\n   <file role=\"src\" name=\"metadata.c\"/>\n   <file role=\"src\" name=\"metadata.h\"/>\n   <file role=\"src\" name=\"metadata.stub.php\"/>\n   <file role=\"src\" name=\"metadata_arginfo.h\"/>\n   <file role=\"src\" name=\"metadata_broker.c\"/>\n   <file role=\"src\" name=\"metadata_broker.h\"/>\n   <file role=\"src\" name=\"metadata_broker.stub.php\"/>\n   <file role=\"src\" name=\"metadata_broker_arginfo.h\"/>\n   <file role=\"src\" name=\"metadata_collection.c\"/>\n   <file role=\"src\" name=\"metadata_collection.h\"/>\n   <file role=\"src\" name=\"metadata_collection.stub.php\"/>\n   <file role=\"src\" name=\"metadata_collection_arginfo.h\"/>\n   <file role=\"src\" name=\"metadata_partition.c\"/>\n   <file role=\"src\" name=\"metadata_partition.h\"/>\n   <file role=\"src\" name=\"metadata_partition.stub.php\"/>\n   <file role=\"src\" name=\"metadata_partition_arginfo.h\"/>\n   <file role=\"src\" name=\"metadata_topic.c\"/>\n   <file role=\"src\" name=\"metadata_topic.h\"/>\n   <file role=\"src\" name=\"metadata_topic.stub.php\"/>\n   <file role=\"src\" name=\"metadata_topic_arginfo.h\"/>\n   <file role=\"src\" name=\"php_rdkafka.h\"/>\n   <file role=\"src\" name=\"php_rdkafka_priv.h\"/>\n   <file role=\"src\" name=\"queue.c\"/>\n   <file role=\"src\" name=\"queue.h\"/>\n   <file role=\"src\" name=\"queue.stub.php\"/>\n   <file role=\"src\" name=\"queue_arginfo.h\"/>\n   <file role=\"src\" name=\"rdkafka.c\"/>\n   <file role=\"src\" name=\"rdkafka.stub.php\"/>\n   <file role=\"src\" name=\"rdkafka_arginfo.h\"/>\n   <file role=\"src\" name=\"topic.c\"/>\n   <file role=\"src\" name=\"topic.h\"/>\n   <file role=\"src\" name=\"topic.stub.php\"/>\n   <file role=\"src\" name=\"topic_arginfo.h\"/>\n   <file role=\"src\" name=\"topic_partition.c\"/>\n   <file role=\"src\" name=\"topic_partition.h\"/>\n   <file role=\"src\" name=\"topic_partition.stub.php\"/>\n   <file role=\"src\" name=\"topic_partition_arginfo.h\"/>\n   <dir name=\"tests\">\n    <file role=\"test\" name=\"allow_null_payload_and_key.phpt\"/>\n    <file role=\"test\" name=\"allow_null_payload.phpt\"/>\n    <file role=\"test\" name=\"bug115.phpt\"/>\n    <file role=\"test\" name=\"bug330.phpt\"/>\n    <file role=\"test\" name=\"bug465.phpt\"/>\n    <file role=\"test\" name=\"bug508.phpt\"/>\n    <file role=\"test\" name=\"bug521.phpt\"/>\n    <file role=\"test\" name=\"bug567.phpt\"/>\n    <file role=\"test\" name=\"bug74.phpt\"/>\n    <file role=\"test\" name=\"bug88.phpt\"/>\n    <file role=\"test\" name=\"bugConfSetArgument.phpt\"/>\n    <file role=\"test\" name=\"conf_callbacks_integration.phpt\"/>\n    <file role=\"test\" name=\"conf_callbacks_rdkafka11.phpt\"/>\n    <file role=\"test\" name=\"conf_callbacks.phpt\"/>\n    <file role=\"test\" name=\"conf.phpt\"/>\n    <file role=\"test\" name=\"conf_setDefaultTopicConf8.phpt\"/>\n    <file role=\"test\" name=\"conf_setDefaultTopicConf.phpt\"/>\n    <file role=\"test\" name=\"constants.phpt\"/>\n    <file role=\"test\" name=\"controller_id.phpt\"/>\n    <file role=\"test\" name=\"err2name.phpt\"/>\n    <file role=\"test\" name=\"init_transaction_not_configured.phpt\"/>\n    <file role=\"test\" name=\"integration-tests-check.php\"/>\n    <file role=\"test\" name=\"kafka_error_exception.phpt\"/>\n    <file role=\"test\" name=\"message_headers.phpt\"/>\n    <file role=\"test\" name=\"metadata_001.phpt\"/>\n    <file role=\"test\" name=\"metadata_broker_001.phpt\"/>\n    <file role=\"test\" name=\"metadata_collection_001.phpt\"/>\n    <file role=\"test\" name=\"metadata_partition_001.phpt\"/>\n    <file role=\"test\" name=\"metadata_topic_001.phpt\"/>\n    <file role=\"test\" name=\"new_topic_with_conf.phpt\"/>\n    <file role=\"test\" name=\"oauthbearer_integration.phpt\"/>\n    <file role=\"test\" name=\"pause_resume.phpt\"/>\n    <file role=\"test\" name=\"produce_consume.phpt\"/>\n    <file role=\"test\" name=\"produce_consume_queue.phpt\"/>\n    <file role=\"test\" name=\"produce_consume_transactional.phpt\"/>\n    <file role=\"test\" name=\"produce_opaque_noflush_dr_callback.phpt\"/>\n    <file role=\"test\" name=\"produce_opaque_noflush.phpt\"/>\n    <file role=\"test\" name=\"produce_opaque.phpt\"/>\n    <file role=\"test\" name=\"produce_opaque_purge_dr_callback.phpt\"/>\n    <file role=\"test\" name=\"produce_opaque_purge.phpt\"/>\n    <file role=\"test\" name=\"producev_opaque.phpt\"/>\n    <file role=\"test\" name=\"rd_kafka_get_err_descs.phpt\"/>\n    <file role=\"test\" name=\"test0.phpt\"/>\n    <file role=\"test\" name=\"test_env.php.sample\"/>\n    <file role=\"test\" name=\"topic_conf.phpt\"/>\n    <file role=\"test\" name=\"topic_partition_001.phpt\"/>\n    <file role=\"test\" name=\"topic_partition_002.phpt\"/>\n   </dir>\n  </dir>\n </contents>\n <dependencies>\n  <required>\n   <php>\n    <min>8.1.0</min>\n    <max>8.99.99</max>\n   </php>\n   <pearinstaller>\n    <min>1.4.8</min>\n   </pearinstaller>\n  </required>\n </dependencies>\n <providesextension>rdkafka</providesextension>\n <extsrcrelease>\n   <configureoption name=\"with-rdkafka\" default=\"autodetect\" prompt=\"librdkafka installation path?\"/>\n </extsrcrelease>\n <changelog>\n  <release>\n   <date>2024-10-24</date>\n   <time>14:56:47</time>\n   <version>\n    <release>6.0.4</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Improvements\n    - Added OAUTHBEARER support. New methods: RdKafka\\Conf::setOauthbearerTokenRefreshCb(), RdKafka::oauthbearerSetToken(), RdKafka::oauthbearerSetTokenFailure() (#546, #547, @cb-freddysart, @scorgn)\n    - Added incremental rebalance support. New methods: RdKafka\\KafkaConsumer::incrementalAssign(), RdKafka\\KafkaConsumer::incrementalUnassign() (#541, @ikeberlein)\n    - Added RdKafka::getControllerId() (#554, @qkdreyer)\n  \n    ## Bugfixes\n    - Add private constructor on Metadata classes (#531, @arnaud-lb)\n  \n    ## Other Changes\n    - Improve KafkaErrorException message (#555, @arnaud-lb)\n   </notes>\n  </release>\n  <release>\n   <date>2022-07-02</date>\n   <time>12:26:56</time>\n   <version>\n    <release>6.0.3</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Improvements\n    - Ability to provide custom `librdkafka` path during pecl install (#526, @Wirone)\n   </notes>\n  </release>\n  <release>\n   <date>2022-06-12</date>\n   <time>12:00:00</time>\n   <version>\n    <release>6.0.2</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Bugfixes\n    - Fixed signature of RdKafka\\KafkaConsumer::getMetadata() (#521, @arnaud-lb)\n   </notes>\n  </release>\n  <release>\n   <date>2022-02-15</date>\n   <time>12:00:00</time>\n   <version>\n    <release>6.0.1</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Bugfixes\n    - Always initialize Message::$headers (#508, @arnaud-lb)\n   </notes>\n  </release>\n  <release>\n   <date>2022-01-07</date>\n   <time>12:00:00</time>\n   <version>\n    <release>6.0.0</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    # Changes since 5.x\n\n    ## Improvements\n    - PHP 8.1 support (@remicollet, @ruudk, @nick-zh)\n    - Added parameter types (when built with PHP&gt;=8.0) (@arnaud-lb)\n    - Added tentative return types (when built with PHP&gt;=8.1) (@arnaud-lb)\n\n    ## Deprecations\n    - PHP 8.1: Overloading php-rdkafka methods without specifying a return type\n      will trigger a deprecation message unless annotated with\n      #[\\ReturnTypeWillChange]\n\n    # Changes since 6.0.0RC2\n\n    ## Bugfixes\n    - Fix newTopic() arginfo (#502, @arnaud-lb)\n   </notes>\n  </release>\n  <release>\n   <date>2021-11-27</date>\n   <time>15:00:00</time>\n   <version>\n    <release>6.0.0RC2</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>beta</release>\n    <api>beta</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Bugfixes\n    -  Fix crash in RdKafka\\TopicPartition::__construct() (#491, @remicollet)\n   </notes>\n  </release>\n  <release>\n   <date>2021-11-19</date>\n   <time>15:00:00</time>\n   <version>\n    <release>6.0.0RC1</release>\n    <api>6.0.0</api>\n   </version>\n   <stability>\n    <release>beta</release>\n    <api>beta</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Enhancements\n    - PHP 8.1 support (@ruudk, @remicollet, @nick-zh, @arnaud-lb)\n\n    ## Breaking changes\n    - Added tentative return types in PHP 8.1 builds\n   </notes>\n  </release>\n  <release>\n   <date>2021-11-19</date>\n   <time>14:00:00</time>\n   <version>\n    <release>5.0.1</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Enhancements\n    - Add pausePartitions(), resumePartitions() on RdKfaka, RdKafka\\KafkaConsumer (#438, @arnaud-lb)\n    - Clarify error when KafkaConsumer is closed (@zoonru)\n\n    ## Bugfixes\n    - Fix windows build (#440, @nick-zh)\n    - Fix crash in RdKafka\\Metadata\\Topic::getTopic() (#465, @arnaud-lb)\n   </notes>\n  </release>\n  <release>\n   <date>2021-01-14</date>\n   <time>12:00:00</time>\n   <version>\n    <release>5.0.0</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    ## Enhancements\n    - PHP 8 support (@nick-zh, @arnaud-lb)\n    - Suport passing an opaque value in produce(), producev() (@arnaud-lb)\n\n    ## Breaking changes\n    - Dropped PHP 5 support\n   </notes>\n  </release>\n  <release>\n   <date>2020-12-06</date>\n   <time>12:00:00</time>\n   <version>\n    <release>4.1.0</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client no longer polls for network\n    events at shutdown (during object destructor). This behaviour didn't give\n    enough control to the user in case of server issue, and could cause the script\n    to hang while terminating.\n\n    Starting from 4.0, programs MUST call flush() before shutting down, otherwise\n    some messages and callbacks may be lost.\n\n    ## Features\n    - Add transactional producer support (#359, @nick-zh)\n   </notes>\n  </release>\n  <release>\n   <version>\n    <release>4.0.4</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client no longer polls for network\n    events at shutdown (during object destructor). This behaviour didn't give\n    enough control to the user in case of server issue, and could cause the script\n    to hang while terminating.\n\n    Starting from 4.0, programs MUST call flush() before shutting down, otherwise\n    some messages and callbacks may be lost.\n\n    ## Bugfixes\n    - Fix crash during shurtdown (#367, @nick-zh, @sofire)\n\n    ## Enhancements\n    - Improved CI (@Steveb-p, @arnaud-lb)\n\n    ## Documentation\n    - Improved doc (@nick-zh, @Steveb-p)\n   </notes>\n  </release>\n  <release>\n   <date>2020-02-07</date>\n   <time>12:00:00</time>\n   <version>\n    <release>4.0.3</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client no longer polls for network\n    events at shutdown (during object destructor). This behaviour didn't give\n    enough control to the user in case of server issue, and could cause the script\n    to hang while terminating.\n\n    Starting from 4.0, programs MUST call flush() before shutting down, otherwise\n    some messages and callbacks may be lost.\n\n    ## Improvements\n    - Add partition check for offsetStore (#331, @nick-zh)\n    - Naming consistency for setting in tests (#339, @romainneutron)\n\n    ## Bugfixes\n    - Fix headers containing null bytes (#338,  @arnaud-lb, @dirx @nick-zh)\n    - Fix topic deconstruct for high level consumer (#333, @nick-zh)\n\n    ## Documentation\n    - Fix doc example (#340, @Steveb-p)\n    - Remove outdated and duplicate examples (#341, @nick-zh)\n   </notes>\n  </release>\n  <release>\n   <date>2019-12-15</date>\n   <time>12:00:00</time>\n   <version>\n    <release>4.0.2</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client no longer polls for network\n    events at shutdown (during object destructor). This behaviour didn't give\n    enough control to the user in case of server issue, and could cause the script\n    to hang while terminating.\n\n    Starting from 4.0, programs MUST call flush() before shutting down, otherwise\n    some messages and callbacks may be lost.\n\n    ## Bugfixes\n\n    * Fix partition 0 exposed as NULL in Message (#327 reverts #321, @arnaud-lb @nick-zh)\n    * Fix memory leak in consume() when messages have headers (#323, @nick-zh)\n   </notes>\n  </release>\n  <release>\n   <date>2019-12-08</date>\n   <time>12:00:00</time>\n   <version>\n    <release>4.0.1</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client no longer polls for network\n    events at shutdown (during object destructor). This behaviour didn't give\n    enough control to the user in case of server issue, and could cause the script\n    to hang while terminating.\n\n    Starting from 4.0, programs MUST call flush() before shutting down, otherwise\n    some messages and callbacks may be lost.\n\n    ## Features\n\n    * Added RdKafka\\ConsumerTopic::consumeCallback() (#310, @nick-zh)\n\n    ## Enhancements\n\n    * Run integration tests in CI (#223, @Steveb-p)\n    * Improved README (#295 #297 #298, #307 @Steveb-p @sndsgd @nick-zh)\n    * Fix windows test cases (#296, @cmb69)\n    * Add testsuite in pecl archive (#291, @remicollet)\n    * Add editor config (#308, @Steveb-p)\n\n    ## Bugfixes\n\n    * Fix build (#290, @nick-zh)\n    * Fix segfault during module shutdown (#293, @arnaud-lb @nick-zh)\n    * Fix RdKafka\\Topic visibility in PHP 7.4 (#316, @nick-zh)\n    * Fix headers memory management in producev (#318 , @nick-zh)\n    * Fix partition number in error (#321, @nick-zh)\n   </notes>\n  </release>\n  <release>\n   <date>2019-10-04</date>\n   <time>12:00:00</time>\n   <version>\n    <release>4.0.0</release>\n    <api>4.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    BREAKING CHANGE: Since version 4.0, the client longer polls for network events\n    at shutdown (during object destructor). This behaviour didn't give enought\n    control to the user in case of server issue, and could cause the script to\n    hang while terminating.\n\n    Starting from this version, programs MUST now call flush() before shutting\n    down, otherwise some messages and callbacks may be lost.\n\n    ## Features\n\n    * Added RdKafka\\Kafka::offsetsForTimes(), RdKafka\\KafkaConsumer::offsetsForTimes() (#238, #270, @nick-zh)\n    * Added RdKafka\\KafkaConsumer::getOffsetPositions() (#244, @nick-zh)\n    * Added RdKafka\\Kafka::purge() (#255, @nick-zh)\n    * Added RdKafka\\Kafka::flush() (#264, @nick-zh)\n    * Added RdKafka\\ConsumerTopic::consumeBatch() (#256, @nick-zh)\n    * Added RdKafka\\Conf::setLogCb() (#253, @nick-zh)\n    * Added RdKafka\\KafkaConsumer::queryWatermarkOffsets() (#271, @nick-zh)\n    * Added RdKafka\\KafkaConsumer::close() (#144, @TiMESPLiNTER)\n\n    ## Enhancements\n\n    * Support block on full producer queue (RD_KAFKA_MSG_F_BLOCK) (#245, @nick-zh)\n    * Add additional partitioners (#267, @nick-zh)\n    * Fix phpinfo output (#172, @TiMESPLiNTER)\n    * Don't poll in destruct anymore (#264, #278, @nick-zh)\n\n    ## Bugfixes\n\n    * Fix segfault, remove Producer::newQueue (#273, @nick-zh)\n\n    ## General\n\n    * Dropping support for librdkafka below 0.11 (#247, @arnaud-lb)\n    * Update build matrix PHP 7.3 + nightly, librdkafka 1.x + master (#249, @arnaud-lb)\n    * Deprecating deprecated librdkafka functions (#266, #254, #251, @nick-zh)\n   </notes>\n\n  </release>\n  <release>\n   <date>2019-07-08</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.1.2</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    * Fix build\n   </notes>\n  </release>\n  <release>\n   <date>2019-07-03</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.1.1</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    * Expose query watermark offsets (#219, @gytislakavicius)\n    * Support sending timestamp (epoch ms) in producev (#228, @lkm)\n    * Fix KafkaTopic::producev causing segfault on librdkafka 1.0.0 (#222, @Steveb-p)\n    * Fix version parsing (#224, @dariuskasiulevicius)\n   </notes>\n  </release>\n  <release>\n   <date>2019-04-18</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.1.0</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    * Added timestamp support (@mariam-japaridze)\n    * Added headers support (@martynaszaliaduonis, @dariuskasiulevicius)\n    * Added Rdkafka\\Conf::setConsumeCb(), RdKafka\\Conf::setOffsetCommitCb() (@tPl0ch)\n    * Added RdKafka\\KafkaConsumer::getCommittedOffsets() (@dariuskasiulevicius)\n    * Fixed RdKafka\\Message::errstr() (@JustBlackBird)\n    * Fixed reflection (@carusogabriel)\n    * Allow null key and null message (@awons)\n    * Dropped official PHP 5.4 / 5.5 support (@tPl0ch)\n    * Improved examples (@dbakiu, @Steveb-p)\n   </notes>\n  </release>\n  <release>\n   <date>2017-11-20</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.5</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Fixed destruction order, fixes hangs during RdKafka\\Consumer destruction\n   </notes>\n  </release>\n  <release>\n   <date>2017-08-16</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.4</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Fixed destruction order, fixes hangs during RdKafka\\Consumer destruction\n   * Added RdKafka\\Conf::setStatsCb\n   </notes>\n  </release>\n  <release>\n   <date>2017-05-29</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.3</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Reduced termination times\n   </notes>\n  </release>\n  <release>\n   <date>2017-05-23</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.2</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Fixed ConsumerTopic::consumeStop() hanging on PHP 5\n   </notes>\n  </release>\n  <release>\n   <date>2017-01-28</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.1</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Fixed build on old gcc\n   </notes>\n  </release>\n  <release>\n   <date>2016-12-18</date>\n   <time>12:00:00</time>\n   <version>\n    <release>3.0.0</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>stable</release>\n    <api>stable</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n   * Unified code for PHP versions 5 and 7. This package builds and works on\n     PHP 5.3 through PHP 7.x.\n   </notes>\n  </release>\n  <release>\n   <date>2016-09-09</date>\n   <time>12:00:00</time>\n   <version>\n    <release>1.0.0</release>\n    <api>1.0.0</api>\n   </version>\n   <stability>\n    <release>beta</release>\n    <api>beta</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    This version of rdkafka is indented for php version 5. To compile rdkafka for\n    newer versions of php, use the pecl package version 2.\n\n     * Added high level consumer: Rdkafka\\KafkaConsumer (librdkafka 0.9)\n     * RD_KAFKA_VERSION now reports the runtime librdkafka version\n     * Added RD_KAFKA_BUILD_VERSION\n     * Export runtime-provided constants from librdkafka (librdkafka 0.9)\n     * Added rd_kafka_get_err_descs() (librdkafka 0.9)\n     * Improve reflection/arginfo\n     * Rdkafka::metadata() is now a deprecated alias to Rdkafka::getMetadata()\n     * Rdkafka::outqLen() is now a deprecated alias to Rdkafka::getOutQLen()\n     * Rdkafka now throws Rdkafka\\Exception instances\n     * Added Rdkafka\\Conf::setDefaultTopicConf() (librdkafka 0.9)\n     * Added Rdkafka\\Conf::setDrMsgCb() (librdkafka 0.9)\n   </notes>\n  </release>\n  <release>\n   <date>2016-01-11</date>\n   <time>10:30:00</time>\n   <version>\n    <release>0.9.1</release>\n    <api>0.9.0</api>\n   </version>\n   <stability>\n    <release>beta</release>\n    <api>beta</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    * Allow to build against librdkafka master/0.9.x\n   </notes>\n  </release>\n  <release>\n   <date>2016-01-09</date>\n   <time>14:00:00</time>\n   <version>\n    <release>0.9.0</release>\n    <api>0.9.0</api>\n   </version>\n   <stability>\n    <release>beta</release>\n    <api>beta</api>\n   </stability>\n   <license uri=\"http://opensource.org/licenses/mit-license.php\">MIT License</license>\n   <notes>\n    * Metadata API\n    * Consistent partitioner\n    * Fix ZTS build\n   </notes>\n  </release>\n  <release>\n   <date>2015-05-13</date>\n   <time>16:26:12</time>\n   <version>\n    <release>0.0.2</release>\n    <api>0.1.0</api>\n   </version>\n   <stability>\n    <release>alpha</release>\n    <api>alpha</api>\n   </stability>\n   <notes>Fixed package</notes>\n  </release>\n </changelog>\n</package>\n"
        },
        {
          "name": "php_rdkafka.h",
          "type": "blob",
          "size": 2.04296875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n/* $Id$ */\n\n#ifndef PHP_RDKAFKA_H\n#define PHP_RDKAFKA_H\n\n#include \"librdkafka/rdkafka.h\"\n#include \"conf.h\"\n\n#ifndef PHP_FE_END\n#define PHP_FE_END { NULL, NULL, NULL, 0, 0 }\n#endif\n\ntypedef struct _kafka_object {\n    rd_kafka_type_t         type;\n    rd_kafka_t              *rk;\n    kafka_conf_callbacks    cbs;\n    HashTable               consuming;\n\tHashTable\t\t\t\ttopics;\n\tHashTable\t\t\t\tqueues;\n    zend_object             std;\n} kafka_object;\n\nPHP_METHOD(RdKafka, __construct);\n\nextern zend_module_entry rdkafka_module_entry;\n#define phpext_rdkafka_ptr &rdkafka_module_entry\n\n#define PHP_RDKAFKA_VERSION \"7.0.0-dev\"\n\nextern zend_object_handlers kafka_default_object_handlers;\nextern zend_class_entry * ce_kafka_exception;\n\n#ifdef PHP_WIN32\n#\tdefine PHP_RDKAFKA_API __declspec(dllexport)\n#elif defined(__GNUC__) && __GNUC__ >= 4\n#\tdefine PHP_RDKAFKA_API __attribute__ ((visibility(\"default\")))\n#else\n#\tdefine PHP_RDKAFKA_API\n#endif\n\n#endif\t/* PHP_RDKAFKA_H */\n"
        },
        {
          "name": "php_rdkafka_priv.h",
          "type": "blob",
          "size": 2.7333984375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifndef PHP_RDKAFKA_PRIV_H\n#define PHP_RDKAFKA_PRIV_H\n\n#define Z_RDKAFKA_P(php_kafka_type, zobject) php_kafka_from_obj(php_kafka_type, Z_OBJ_P(zobject))\n\n#define php_kafka_from_obj(php_kafka_type, object) \\\n    ((php_kafka_type*)((char *)(object) - XtOffsetOf(php_kafka_type, std)))\n\nstatic inline void rdkafka_call_function(zend_fcall_info *fci, zend_fcall_info_cache *fci_cache, zval *retval, uint32_t param_count, zval params[])\n{\n    int local_retval;\n    zval local_retval_zv;\n\n    if (retval) {\n        local_retval = 0;\n    } else {\n        local_retval = 1;\n        retval = &local_retval_zv;\n    }\n\n    fci->retval = retval;\n    fci->params = params;\n    fci->param_count = param_count;\n\n    zend_call_function(fci, fci_cache);\n\n    if (local_retval) {\n        zval_ptr_dtor(retval);\n    }\n}\n\nstatic inline zval *rdkafka_read_property(zend_class_entry *scope, zend_object *object, const char *name, size_t name_length, zend_bool silent)\n{\n    zval rv;\n    return zend_read_property(scope, object, name, name_length, silent, &rv);\n}\n\n\nstatic inline char *rdkafka_hash_get_current_key_ex(HashTable *ht, HashPosition *pos)\n{\n    zend_string* key;\n    zend_ulong index;\n\n    if (zend_hash_get_current_key_ex(ht, &key, &index, pos) == HASH_KEY_IS_STRING) {\n        return key->val;\n    }\n\n    return NULL;\n}\n\nkafka_object * get_kafka_object(zval *zrk);\nvoid add_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition);\nvoid del_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition);\nint is_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition);\n\n#endif /* PHP_RDKAFKA_PRIV_H */\n"
        },
        {
          "name": "queue.c",
          "type": "blob",
          "size": 3.7451171875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"topic.h\"\n#include \"queue.h\"\n#include \"message.h\"\n#include \"queue_arginfo.h\"\n\nzend_class_entry * ce_kafka_queue;\n\nstatic zend_object_handlers handlers;\n\nstatic void kafka_queue_free(zend_object *object) /* {{{ */\n{\n    kafka_queue_object *intern = php_kafka_from_obj(kafka_queue_object, object);\n\n    if (intern->rkqu) {\n        kafka_object *kafka_intern = get_kafka_object(&intern->zrk);\n        if (kafka_intern) {\n            zend_hash_index_del(&kafka_intern->queues, (zend_ulong)intern);\n        }\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *kafka_queue_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    kafka_queue_object *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nkafka_queue_object * get_kafka_queue_object(zval *zrkqu)\n{\n    kafka_queue_object *orkqu = Z_RDKAFKA_P(kafka_queue_object, zrkqu);\n\n    if (!orkqu->rkqu) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Queue::__construct() has not been called\");\n        return NULL;\n    }\n\n    return orkqu;\n}\n\n/* {{{ proto RdKafka\\Message RdKafka\\Queue::consume(int timeout_ms)\n   Consume a single message */\nPHP_METHOD(RdKafka_Queue, consume)\n{\n    kafka_queue_object *intern;\n    zend_long timeout_ms;\n    rd_kafka_message_t *message;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_queue_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    message = rd_kafka_consume_queue(intern->rkqu, timeout_ms);\n\n    if (!message) {\n        err = rd_kafka_last_error();\n        if (err == RD_KAFKA_RESP_ERR__TIMED_OUT) {\n            return;\n        }\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_message_new(return_value, message, NULL);\n\n    rd_kafka_message_destroy(message);\n}\n/* }}} */\n\nvoid kafka_queue_minit(INIT_FUNC_ARGS) { /* {{{ */\n\n    handlers = kafka_default_object_handlers;\n    handlers.free_obj = kafka_queue_free;\n    handlers.offset = XtOffsetOf(kafka_queue_object, std);\n\n    ce_kafka_queue = register_class_RdKafka_Queue();\n    ce_kafka_queue->create_object = kafka_queue_new;\n} /* }}} */\n"
        },
        {
          "name": "queue.h",
          "type": "blob",
          "size": 1.3876953125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\ntypedef struct _kafka_queue_object {\n    rd_kafka_queue_t    *rkqu;\n    zval               zrk;\n    zend_object         std;\n} kafka_queue_object;\n\nvoid kafka_queue_minit(INIT_FUNC_ARGS);\nkafka_queue_object * get_kafka_queue_object(zval *zrkqu);\n\nextern zend_class_entry * ce_kafka_queue;\n"
        },
        {
          "name": "queue.stub.php",
          "type": "blob",
          "size": 0.3154296875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass Queue\n{\n    /** @implementation-alias RdKafka::__construct */\n    private  function __construct() {}\n\n    /** @tentative-return-type */\n    public function consume(int $timeout_ms): ?Message {}\n}\n"
        },
        {
          "name": "queue_arginfo.h",
          "type": "blob",
          "size": 0.982421875,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 9e80d48bb60ede4003fffcfe0da09ac0e5c2f4d1 */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Queue___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_Queue_consume, 0, 1, RdKafka\\\\Message, 1)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_Queue, consume);\n\n\nstatic const zend_function_entry class_RdKafka_Queue_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_Queue___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_Queue, consume, arginfo_class_RdKafka_Queue_consume, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Queue(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Queue\", class_RdKafka_Queue_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "rdkafka.c",
          "type": "blob",
          "size": 32.408203125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n/* $Id$ */\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_ini.h\"\n#include \"ext/standard/info.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n#include \"metadata.h\"\n#include \"conf.h\"\n#include \"topic.h\"\n#include \"queue.h\"\n#include \"message.h\"\n#include \"kafka_consumer.h\"\n#include \"topic_partition.h\"\n#include \"rdkafka_arginfo.h\"\n#include \"fun_arginfo.h\"\n#include \"kafka_error_exception.h\"\n\n#if PHP_VERSION_ID < 80100\n#   error \"PHP version 8.1.0 or greater required\"\n#endif\n\n#if RD_KAFKA_VERSION < 0x010503ff\n#\terror librdkafka version 1.5.3 or greater required\n#endif\n\nenum {\n   RD_KAFKA_LOG_PRINT = 100\n   , RD_KAFKA_LOG_SYSLOG = 101\n   , RD_KAFKA_LOG_SYSLOG_PRINT = 102\n};\n\ntypedef struct _toppar {\n    rd_kafka_topic_t    *rkt;\n    int32_t             partition;\n} toppar;\n\nstatic zend_object_handlers kafka_object_handlers;\nzend_object_handlers kafka_default_object_handlers;\n\nstatic zend_class_entry * ce_kafka;\nstatic zend_class_entry * ce_kafka_consumer;\nzend_class_entry * ce_kafka_exception;\nstatic zend_class_entry * ce_kafka_producer;\n\nstatic void stop_consuming_toppar_pp(toppar ** tp) {\n    rd_kafka_consume_stop((*tp)->rkt, (*tp)->partition);\n}\n\nstatic void stop_consuming(kafka_object * intern) {\n    zend_hash_apply(&intern->consuming, (apply_func_t)stop_consuming_toppar_pp);\n}\n\nstatic void kafka_free(zend_object *object) /* {{{ */\n{\n    kafka_object *intern = php_kafka_from_obj(kafka_object, object);\n\n    kafka_conf_callbacks_dtor(&intern->cbs);\n\n    if (intern->rk) {\n        if (intern->type == RD_KAFKA_CONSUMER) {\n            stop_consuming(intern);\n            zend_hash_destroy(&intern->consuming);\n            zend_hash_destroy(&intern->queues);\n        } else if (intern->type == RD_KAFKA_PRODUCER) {\n            // Force internal delivery callbacks for queued messages, as we rely\n            // on these to free msg_opaques\n            rd_kafka_purge(intern->rk, RD_KAFKA_PURGE_F_QUEUE | RD_KAFKA_PURGE_F_INFLIGHT);\n            rd_kafka_flush(intern->rk, 0);\n        }\n        zend_hash_destroy(&intern->topics);\n\n        rd_kafka_destroy(intern->rk);\n        intern->rk = NULL;\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic void toppar_pp_dtor(toppar ** tp) {\n    efree(*tp);\n}\n\nstatic void kafka_queue_object_pre_free(kafka_queue_object ** pp) {\n    kafka_queue_object *intern = *pp;\n    rd_kafka_queue_destroy(intern->rkqu);\n    intern->rkqu = NULL;\n    zval_ptr_dtor(&intern->zrk);\n}\n\nstatic void kafka_topic_object_pre_free(kafka_topic_object ** pp) {\n    kafka_topic_object *intern = *pp;\n    rd_kafka_topic_destroy(intern->rkt);\n    intern->rkt = NULL;\n    zval_ptr_dtor(&intern->zrk);\n}\n\nstatic void kafka_init(zval *this_ptr, rd_kafka_type_t type, zval *zconf) /* {{{ */\n{\n    char errstr[512];\n    rd_kafka_t *rk;\n    kafka_object *intern;\n    kafka_conf_object *conf_intern;\n    rd_kafka_conf_t *conf = NULL;\n\n    intern = Z_RDKAFKA_P(kafka_object, this_ptr);\n    intern->type = type;\n\n    if (zconf) {\n        conf_intern = get_kafka_conf_object(zconf);\n        if (conf_intern) {\n            conf = rd_kafka_conf_dup(conf_intern->u.conf);\n            kafka_conf_callbacks_copy(&intern->cbs, &conf_intern->cbs);\n        }\n    }\n\n    if (conf == NULL) {\n        conf = rd_kafka_conf_new();\n    }\n\n    intern->cbs.zrk = *this_ptr;\n    rd_kafka_conf_set_opaque(conf, &intern->cbs);\n    if (type == RD_KAFKA_PRODUCER) {\n        rd_kafka_conf_set_dr_msg_cb(conf, kafka_conf_dr_msg_cb);\n    }\n\n    rk = rd_kafka_new(type, conf, errstr, sizeof(errstr));\n\n    if (rk == NULL) {\n        zend_throw_exception(ce_kafka_exception, errstr, 0);\n        return;\n    }\n\n    if (intern->cbs.log) {\n        rd_kafka_set_log_queue(rk, NULL);\n    }\n\n    intern->rk = rk;\n\n    if (type == RD_KAFKA_CONSUMER) {\n        zend_hash_init(&intern->consuming, 0, NULL, (dtor_func_t)toppar_pp_dtor, 0);\n        zend_hash_init(&intern->queues, 0, NULL, (dtor_func_t)kafka_queue_object_pre_free, 0);\n    }\n\n    zend_hash_init(&intern->topics, 0, NULL, (dtor_func_t)kafka_topic_object_pre_free, 0);\n}\n/* }}} */\n\nstatic zend_object *kafka_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    kafka_object *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &kafka_object_handlers;\n\n    return retval;\n}\n/* }}} */\n\nkafka_object * get_kafka_object(zval *zrk)\n{\n    kafka_object *ork = Z_RDKAFKA_P(kafka_object, zrk);\n\n    if (!ork->rk) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Kafka::__construct() has not been called\");\n        return NULL;\n    }\n\n    return ork;\n}\n\nstatic void kafka_log_syslog_print(const rd_kafka_t *rk, int level, const char *fac, const char *buf) {\n    rd_kafka_log_print(rk, level, fac, buf);\n#ifndef _MSC_VER\n    rd_kafka_log_syslog(rk, level, fac, buf);\n#endif\n}\n\nvoid add_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition) {\n    char *key = NULL;\n    int key_len;\n    const char *topic_name = rd_kafka_topic_name(rkt);\n    toppar *tp;\n\n    tp = emalloc(sizeof(*tp));\n    tp->rkt = rkt;\n    tp->partition = partition;\n\n    key_len = spprintf(&key, 0, \"%s:%d\", topic_name, partition);\n\n    zend_hash_str_add_ptr(&intern->consuming, key, key_len+1, tp);\n\n    efree(key);\n}\n\nvoid del_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition) {\n    char *key = NULL;\n    int key_len;\n    const char *topic_name = rd_kafka_topic_name(rkt);\n\n    key_len = spprintf(&key, 0, \"%s:%d\", topic_name, partition);\n\n    zend_hash_str_del(&intern->consuming, key, key_len+1);\n\n    efree(key);\n}\n\nint is_consuming_toppar(kafka_object * intern, rd_kafka_topic_t * rkt, int32_t partition) {\n    char *key = NULL;\n    int key_len;\n    const char *topic_name = rd_kafka_topic_name(rkt);\n    int ret;\n\n    key_len = spprintf(&key, 0, \"%s:%d\", topic_name, partition);\n\n    ret = zend_hash_str_exists(&intern->consuming, key, key_len+1);\n\n    efree(key);\n\n    return ret;\n}\n\n/* {{{ private constructor */\nPHP_METHOD(RdKafka, __construct)\n{\n    zend_throw_exception(NULL, \"Private constructor\", 0);\n    return;\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Consumer::__construct([RdKafka\\Conf $conf]) */\nPHP_METHOD(RdKafka_Consumer, __construct)\n{\n    zval *zconf = NULL;\n    zend_error_handling error_handling;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"|O!\", &zconf, ce_kafka_conf) == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    kafka_init(getThis(), RD_KAFKA_CONSUMER, zconf);\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Queue RdKafka\\Consumer::newQueue()\n   Returns a RdKafka\\Queue object */\nPHP_METHOD(RdKafka_Consumer, newQueue)\n{\n    rd_kafka_queue_t *rkqu;\n    kafka_object *intern;\n    kafka_queue_object *queue_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rkqu = rd_kafka_queue_new(intern->rk);\n\n    if (!rkqu) {\n        return;\n    }\n\n    if (object_init_ex(return_value, ce_kafka_queue) != SUCCESS) {\n        return;\n    }\n\n    queue_intern = Z_RDKAFKA_P(kafka_queue_object, return_value);\n    if (!queue_intern) {\n        return;\n    }\n\n    queue_intern->rkqu = rkqu;\n\n    // Keep a reference to the parent Kafka object, attempts to ensure that\n    // the Queue object is destroyed before the Kafka object.\n    // This avoids rd_kafka_destroy() hanging.\n    queue_intern->zrk = *getThis();\n\n    Z_ADDREF_P(&queue_intern->zrk);\n\n    zend_hash_index_add_ptr(&intern->queues, (zend_ulong)queue_intern, queue_intern);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::addBrokers(string $brokerList)\n   Returns the number of brokers successfully added */\nPHP_METHOD(RdKafka, addBrokers)\n{\n    char *broker_list;\n    size_t broker_list_len;\n    kafka_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"s\", &broker_list, &broker_list_len) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_brokers_add(intern->rk, broker_list));\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Metadata RdKafka::getMetadata(bool $all_topics, RdKafka\\Topic $only_topic, int $timeout_ms)\n   Request Metadata from broker */\nPHP_METHOD(RdKafka, getMetadata)\n{\n    zend_bool all_topics;\n    zval *only_zrkt;\n    zend_long timeout_ms;\n    rd_kafka_resp_err_t err;\n    kafka_object *intern;\n    const rd_kafka_metadata_t *metadata;\n    kafka_topic_object *only_orkt = NULL;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"bO!l\", &all_topics, &only_zrkt, ce_kafka_topic, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (only_zrkt) {\n        only_orkt = get_kafka_topic_object(only_zrkt);\n        if (!only_orkt) {\n            return;\n        }\n    }\n\n    err = rd_kafka_metadata(intern->rk, all_topics, only_orkt ? only_orkt->rkt : NULL, &metadata, timeout_ms);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_metadata_init(return_value, metadata);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::getControllerId(int $timeout_ms)\n   Returns the current ControllerId (controller broker id) as reported in broker metadata */\nPHP_METHOD(RdKafka, getControllerId)\n{\n    kafka_object *intern;\n    zend_long timeout;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_controllerid(intern->rk, timeout));\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::setLogLevel(int $level)\n   Specifies the maximum logging level produced by internal kafka logging and debugging */\nPHP_METHOD(RdKafka, setLogLevel)\n{\n    kafka_object *intern;\n    zend_long level;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &level) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rd_kafka_set_log_level(intern->rk, level);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::oauthbearerSetToken(string $token_value, int|float|string $lifetime_ms, string $principal_name, array $extensions = [])\n * Set SASL/OAUTHBEARER token and metadata\n *\n * The SASL/OAUTHBEARER token refresh callback or event handler should cause\n * this method to be invoked upon success, via\n * $kafka->oauthbearerSetToken(). The extension keys must not include the\n * reserved key \"`auth`\", and all extension keys and values must conform to the\n * required format as per https://tools.ietf.org/html/rfc7628#section-3.1:\n *\n * key            = 1*(ALPHA)\n * value          = *(VCHAR / SP / HTAB / CR / LF )\n*/\nPHP_METHOD(RdKafka, oauthbearerSetToken)\n{\n    kafka_object *intern;\n    char *token_value;\n    size_t token_value_len;\n    zval *zlifetime_ms;\n    int64_t lifetime_ms;\n    char *principal_name;\n    size_t principal_len;\n    HashTable *extensions_hash = NULL;\n    \n    char errstr[512];\n    rd_kafka_resp_err_t ret = 0;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"szs|h\", &token_value, &token_value_len, &zlifetime_ms, &principal_name, &principal_len, &extensions_hash) == FAILURE) {\n        return;\n    }\n\n    /* On 32-bits, it might be required to pass $lifetime_ms as a float or a\n     * string */\n    switch (Z_TYPE_P(zlifetime_ms)) {\n        case IS_LONG:\n            lifetime_ms = (int64_t) Z_LVAL_P(zlifetime_ms);\n            break;\n        case IS_DOUBLE:\n            lifetime_ms = (int64_t) Z_DVAL_P(zlifetime_ms);\n            break;\n        case IS_STRING:;\n            char *str = Z_STRVAL_P(zlifetime_ms);\n            char *end;\n            lifetime_ms = (int64_t) strtoll(str, &end, 10);\n            if (end != str + Z_STRLEN_P(zlifetime_ms)) {\n                zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Argument #2 ($lifetime_ms) must be a valid integer\");\n                return;\n            }\n            break;\n        EMPTY_SWITCH_DEFAULT_CASE();\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }    \n\n    errstr[0] = '\\0';\n\n    int extensions_size = 0;\n    char **extensions = NULL;\n\n    if (extensions_hash != NULL) {\n        extensions_size = zend_hash_num_elements(extensions_hash) * 2;\n        extensions = safe_emalloc((extensions_size * 2), sizeof(char *), 0);\n\n        int pos = 0;\n        zend_ulong num_key;\n        zend_string *extension_key_str;\n        zval *extension_zval;\n        ZEND_HASH_FOREACH_KEY_VAL(extensions_hash, num_key, extension_key_str, extension_zval) {\n            if (!extension_key_str) {\n                extension_key_str = zend_long_to_str(num_key);\n                extensions[pos++] = estrdup(ZSTR_VAL(extension_key_str));\n                zend_string_release(extension_key_str);\n            } else {\n                extensions[pos++] = estrdup(ZSTR_VAL(extension_key_str));\n            }\n\n            zend_string *tmp_extension_val_str;\n            zend_string *extension_val_str = zval_get_tmp_string(extension_zval, &tmp_extension_val_str);\n            extensions[pos++] = estrdup(ZSTR_VAL(extension_val_str));\n            zend_tmp_string_release(tmp_extension_val_str);\n        } ZEND_HASH_FOREACH_END();\n    }    \n\n    ret = rd_kafka_oauthbearer_set_token(\n        intern->rk,\n        token_value,\n        lifetime_ms,\n        principal_name,\n        (const char **)extensions,\n        extensions_size,\n        errstr,\n        sizeof(errstr));\n\n    if (extensions != NULL) {\n        for (int i = 0; i < extensions_size; i++) {\n            efree(extensions[i]);\n        }\n        efree(extensions);\n    }\n    \n    switch (ret) {\n        case RD_KAFKA_RESP_ERR__INVALID_ARG:\n            zend_throw_exception(ce_kafka_exception, errstr, RD_KAFKA_RESP_ERR__INVALID_ARG);\n            return;\n        case RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED:\n            zend_throw_exception(ce_kafka_exception, errstr, RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED);\n            return;\n        case RD_KAFKA_RESP_ERR__STATE:\n            zend_throw_exception(ce_kafka_exception, errstr, RD_KAFKA_RESP_ERR__STATE);\n            return;\n        case RD_KAFKA_RESP_ERR_NO_ERROR:\n            break;\n        default:\n            return;\n    }\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::oauthbearerSetTokenFailure(string $error)\n The SASL/OAUTHBEARER token refresh callback or event handler should cause\n this method to be invoked upon failure, via\n rd_kafka_oauthbearer_set_token_failure().\n*/\nPHP_METHOD(RdKafka, oauthbearerSetTokenFailure)\n{\n    kafka_object *intern;\n    const char *errstr;\n    size_t errstr_len;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"s\", &errstr, &errstr_len) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }    \n\n    rd_kafka_resp_err_t ret = rd_kafka_oauthbearer_set_token_failure(intern->rk, errstr);\n\n    switch (ret) {\n        case RD_KAFKA_RESP_ERR__INVALID_ARG:\n            zend_throw_exception(ce_kafka_exception, NULL, RD_KAFKA_RESP_ERR__INVALID_ARG);\n            return;\n        case RD_KAFKA_RESP_ERR__STATE:\n            zend_throw_exception(ce_kafka_exception, NULL, RD_KAFKA_RESP_ERR__STATE);\n            return;\n        case RD_KAFKA_RESP_ERR_NO_ERROR:\n            break;\n        default:\n            return;\n    }\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Topic RdKafka::newTopic(string $topic)\n   Returns an RdKafka\\Topic object */\nPHP_METHOD(RdKafka, newTopic)\n{\n    char *topic;\n    size_t topic_len;\n    rd_kafka_topic_t *rkt;\n    kafka_object *intern;\n    kafka_topic_object *topic_intern;\n    zend_class_entry *topic_type;\n    zval *zconf = NULL;\n    rd_kafka_topic_conf_t *conf = NULL;\n    kafka_conf_object *conf_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|O!\", &topic, &topic_len, &zconf, ce_kafka_topic_conf) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (zconf) {\n        conf_intern = get_kafka_conf_object(zconf);\n        if (conf_intern) {\n            conf = rd_kafka_topic_conf_dup(conf_intern->u.topic_conf);\n        }\n    }\n\n    rkt = rd_kafka_topic_new(intern->rk, topic, conf);\n\n    if (!rkt) {\n        return;\n    }\n\n    switch (intern->type) {\n        case RD_KAFKA_CONSUMER:\n            topic_type = ce_kafka_consumer_topic;\n            break;\n        case RD_KAFKA_PRODUCER:\n            topic_type = ce_kafka_producer_topic;\n            break;\n        default:\n            return;\n    }\n\n    if (object_init_ex(return_value, topic_type) != SUCCESS) {\n        return;\n    }\n\n    topic_intern = Z_RDKAFKA_P(kafka_topic_object, return_value);\n    if (!topic_intern) {\n        return;\n    }\n\n    topic_intern->rkt = rkt;\n    topic_intern->zrk = *getThis();\n\n    Z_ADDREF_P(&topic_intern->zrk);\n\n    zend_hash_index_add_ptr(&intern->topics, (zend_ulong)topic_intern, topic_intern);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::getOutQLen()\n   Returns the current out queue length */\nPHP_METHOD(RdKafka, getOutQLen)\n{\n    kafka_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"\") == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_outq_len(intern->rk));\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::poll(int $timeout_ms)\n   Polls the provided kafka handle for events */\nPHP_METHOD(RdKafka, poll)\n{\n    kafka_object *intern;\n    zend_long timeout;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_poll(intern->rk, timeout));\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::flush(int $timeout_ms)\n   Wait until all outstanding produce requests, et.al, are completed. */\nPHP_METHOD(RdKafka, flush)\n{\n    kafka_object *intern;\n    zend_long timeout;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_flush(intern->rk, timeout));\n}\n/* }}} */\n\n/* {{{ proto int RdKafka::purge(int $purge_flags)\n   Purge messages that are in queue or in flight */\nPHP_METHOD(RdKafka, purge)\n{\n    kafka_object *intern;\n    zend_long purge_flags;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &purge_flags) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(rd_kafka_purge(intern->rk, purge_flags));\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::queryWatermarkOffsets(string $topic, int $partition, int &$low, int &$high, int $timeout_ms)\n   Query broker for low (oldest/beginning) or high (newest/end) offsets for partition */\nPHP_METHOD(RdKafka, queryWatermarkOffsets)\n{\n    kafka_object *intern;\n    char *topic;\n    size_t topic_length;\n    int64_t low, high;\n    zend_long partition, timeout;\n    zval *lowResult, *highResult;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"slzzl\", &topic, &topic_length, &partition, &lowResult, &highResult, &timeout) == FAILURE) {\n        return;\n    }\n\n    ZVAL_DEREF(lowResult);\n    ZVAL_DEREF(highResult);\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_query_watermark_offsets(intern->rk, topic, partition, &low, &high, timeout);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    ZVAL_LONG(lowResult, (zend_long) low);\n    ZVAL_LONG(highResult, (zend_long) high);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::offsetsForTimes(array $topicPartitions, int $timeout_ms)\n   Look up the offsets for the given partitions by timestamp. */\nPHP_METHOD(RdKafka, offsetsForTimes)\n{\n    HashTable *htopars = NULL;\n    kafka_object *intern;\n    rd_kafka_topic_partition_list_t *topicPartitions;\n    zend_long timeout_ms;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"hl\", &htopars, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topicPartitions = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topicPartitions) {\n        return;\n    }\n\n    err = rd_kafka_offsets_for_times(intern->rk, topicPartitions, timeout_ms);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topicPartitions);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n    kafka_topic_partition_list_to_array(return_value, topicPartitions);\n    rd_kafka_topic_partition_list_destroy(topicPartitions);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka::setLogger(mixed $logger)\n   Sets the log callback */\nPHP_METHOD(RdKafka, setLogger)\n{\n    kafka_object *intern;\n    zend_long id;\n    void (*logger) (const rd_kafka_t * rk, int level, const char *fac, const char *buf);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &id) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    switch (id) {\n        case RD_KAFKA_LOG_PRINT:\n            logger = rd_kafka_log_print;\n            break;\n#ifndef _MSC_VER\n        case RD_KAFKA_LOG_SYSLOG:\n            logger = rd_kafka_log_syslog;\n            break;\n#endif\n        case RD_KAFKA_LOG_SYSLOG_PRINT:\n            logger = kafka_log_syslog_print;\n            break;\n        default:\n            zend_throw_exception_ex(NULL, 0, \"Invalid logger\");\n            return;\n    }\n\n    rd_kafka_set_logger(intern->rk, logger);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicPartition[] RdKafka::pausePatitions(RdKafka\\TopicPartition[] $topicPartitions)\n   Pause producing or consumption for the provided list of partitions. */\nPHP_METHOD(RdKafka, pausePartitions)\n{\n    HashTable *htopars;\n    rd_kafka_topic_partition_list_t *topars;\n    rd_kafka_resp_err_t err;\n    kafka_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topars = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topars) {\n        return;\n    }\n\n    err = rd_kafka_pause_partitions(intern->rk, topars);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topars);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_topic_partition_list_to_array(return_value, topars);\n    rd_kafka_topic_partition_list_destroy(topars);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\TopicPartition[] RdKafka::resumePatitions(RdKafka\\TopicPartition[] $topicPartitions)\n   Resume producing consumption for the provided list of partitions. */\nPHP_METHOD(RdKafka, resumePartitions)\n{\n    HashTable *htopars;\n    rd_kafka_topic_partition_list_t *topars;\n    rd_kafka_resp_err_t err;\n    kafka_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"h\", &htopars) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    topars = array_arg_to_kafka_topic_partition_list(1, htopars);\n    if (!topars) {\n        return;\n    }\n\n    err = rd_kafka_pause_partitions(intern->rk, topars);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_topic_partition_list_destroy(topars);\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_topic_partition_list_to_array(return_value, topars);\n    rd_kafka_topic_partition_list_destroy(topars);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Producer::__construct([RdKafka\\Conf $conf]) */\nPHP_METHOD(RdKafka_Producer, __construct)\n{\n    zval *zconf = NULL;\n    zend_error_handling error_handling;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"|O!\", &zconf, ce_kafka_conf) == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    kafka_init(getThis(), RD_KAFKA_PRODUCER, zconf);\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Producer::initTransactions(int timeout_ms)\n   Initializes transactions, needs to be done before producing and starting a transaction */\nPHP_METHOD(RdKafka_Producer, initTransactions)\n{\n    kafka_object *intern;\n    zend_long timeout_ms;\n    const rd_kafka_error_t *error;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    error = rd_kafka_init_transactions(intern->rk, timeout_ms);\n\n    if (NULL == error) {\n        return;\n    }\n\n    create_kafka_error(return_value, error);\n    zend_throw_exception_object(return_value);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Producer::beginTransaction()\n   Start a transaction */\nPHP_METHOD(RdKafka_Producer, beginTransaction)\n{\n    kafka_object *intern;\n    const rd_kafka_error_t *error;\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    error = rd_kafka_begin_transaction(intern->rk);\n\n    if (NULL == error) {\n        return;\n    }\n\n    create_kafka_error(return_value, error);\n    zend_throw_exception_object(return_value);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Producer::commitTransaction(int timeout_ms)\n   Commit a transaction */\nPHP_METHOD(RdKafka_Producer, commitTransaction)\n{\n    kafka_object *intern;\n    zend_long timeout_ms;\n    const rd_kafka_error_t *error;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    error = rd_kafka_commit_transaction(intern->rk, timeout_ms);\n\n    if (NULL == error) {\n        return;\n    }\n\n    create_kafka_error(return_value, error);\n    zend_throw_exception_object(return_value);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\Producer::abortTransaction(int timeout_ms)\n   Commit a transaction */\nPHP_METHOD(RdKafka_Producer, abortTransaction)\n{\n    kafka_object *intern;\n    zend_long timeout_ms;\n    const rd_kafka_error_t *error;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    error = rd_kafka_abort_transaction(intern->rk, timeout_ms);\n\n    if (NULL == error) {\n        return;\n    }\n\n    create_kafka_error(return_value, error);\n    zend_throw_exception_object(return_value);\n}\n/* }}} */\n\n#define COPY_CONSTANT(name) \\\n    REGISTER_LONG_CONSTANT(#name, name, CONST_CS | CONST_PERSISTENT)\n\nvoid register_err_constants(INIT_FUNC_ARGS) /* {{{ */\n{\n    const struct rd_kafka_err_desc *errdescs;\n    size_t cnt;\n    size_t i;\n    char buf[128];\n\n    rd_kafka_get_err_descs(&errdescs, &cnt);\n\n    for (i = 0; i < cnt; i++) {\n        const struct rd_kafka_err_desc *desc = &errdescs[i];\n        int len;\n\n        if (!desc->name) {\n            continue;\n        }\n\n        len = snprintf(buf, sizeof(buf), \"RD_KAFKA_RESP_ERR_%s\", desc->name);\n        if ((size_t)len >= sizeof(buf)) {\n            len = sizeof(buf)-1;\n        }\n\n        zend_register_long_constant(buf, len, desc->code, CONST_CS | CONST_PERSISTENT, module_number);\n    }\n} /* }}} */\n\n/* {{{ PHP_MINIT_FUNCTION\n */\nPHP_MINIT_FUNCTION(rdkafka)\n{\n    COPY_CONSTANT(RD_KAFKA_CONSUMER);\n    COPY_CONSTANT(RD_KAFKA_OFFSET_BEGINNING);\n    COPY_CONSTANT(RD_KAFKA_OFFSET_END);\n    COPY_CONSTANT(RD_KAFKA_OFFSET_STORED);\n    COPY_CONSTANT(RD_KAFKA_PARTITION_UA);\n    COPY_CONSTANT(RD_KAFKA_PRODUCER);\n    COPY_CONSTANT(RD_KAFKA_MSG_F_BLOCK);\n    COPY_CONSTANT(RD_KAFKA_PURGE_F_QUEUE);\n    COPY_CONSTANT(RD_KAFKA_PURGE_F_INFLIGHT);\n    COPY_CONSTANT(RD_KAFKA_PURGE_F_NON_BLOCKING);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_VERSION\", rd_kafka_version(), CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_BUILD_VERSION\", RD_KAFKA_VERSION, CONST_CS | CONST_PERSISTENT);\n\n    register_err_constants(INIT_FUNC_ARGS_PASSTHRU);\n\n    COPY_CONSTANT(RD_KAFKA_CONF_UNKNOWN);\n    COPY_CONSTANT(RD_KAFKA_CONF_INVALID);\n    COPY_CONSTANT(RD_KAFKA_CONF_OK);\n\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_MSG_PARTITIONER_RANDOM\", MSG_PARTITIONER_RANDOM, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_MSG_PARTITIONER_CONSISTENT\", MSG_PARTITIONER_CONSISTENT, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_MSG_PARTITIONER_CONSISTENT_RANDOM\", MSG_PARTITIONER_CONSISTENT_RANDOM, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_MSG_PARTITIONER_MURMUR2\", MSG_PARTITIONER_MURMUR2, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_MSG_PARTITIONER_MURMUR2_RANDOM\", MSG_PARTITIONER_MURMUR2_RANDOM, CONST_CS | CONST_PERSISTENT);\n\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_LOG_PRINT\", RD_KAFKA_LOG_PRINT, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_LOG_SYSLOG\", RD_KAFKA_LOG_SYSLOG, CONST_CS | CONST_PERSISTENT);\n    REGISTER_LONG_CONSTANT(\"RD_KAFKA_LOG_SYSLOG_PRINT\", RD_KAFKA_LOG_SYSLOG_PRINT, CONST_CS | CONST_PERSISTENT);\n\n    memcpy(&kafka_default_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n    kafka_default_object_handlers.clone_obj = NULL;\n\n\tkafka_object_handlers = kafka_default_object_handlers;\n    kafka_object_handlers.free_obj = kafka_free;\n    kafka_object_handlers.offset = XtOffsetOf(kafka_object, std);\n\n    ce_kafka = register_class_RdKafka();\n    ce_kafka->create_object = kafka_new;\n\n    ce_kafka_consumer = register_class_RdKafka_Consumer(ce_kafka);\n\n    ce_kafka_producer = register_class_RdKafka_Producer(ce_kafka);\n\n    ce_kafka_exception = register_class_RdKafka_Exception(zend_ce_exception);\n\n    kafka_conf_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_error_minit();\n    kafka_kafka_consumer_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_message_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_metadata_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_metadata_topic_partition_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_queue_minit(INIT_FUNC_ARGS_PASSTHRU);\n    kafka_topic_minit(INIT_FUNC_ARGS_PASSTHRU);\n\n    return SUCCESS;\n}\n/* }}} */\n\n/* {{{ PHP_MINFO_FUNCTION\n */\nPHP_MINFO_FUNCTION(rdkafka)\n{\n    char *rd_kafka_version;\n\n    php_info_print_table_start();\n    php_info_print_table_row(2, \"rdkafka support\", \"enabled\");\n\n    php_info_print_table_row(2, \"version\", PHP_RDKAFKA_VERSION);\n    php_info_print_table_row(2, \"build date\", __DATE__ \" \" __TIME__);\n\n    spprintf(\n        &rd_kafka_version,\n        0,\n        \"%u.%u.%u.%u\",\n        (RD_KAFKA_VERSION & 0xFF000000) >> 24,\n        (RD_KAFKA_VERSION & 0x00FF0000) >> 16,\n        (RD_KAFKA_VERSION & 0x0000FF00) >> 8,\n        (RD_KAFKA_VERSION & 0x000000FF)\n    );\n\n    php_info_print_table_row(2, \"librdkafka version (runtime)\", rd_kafka_version_str());\n    php_info_print_table_row(2, \"librdkafka version (build)\", rd_kafka_version);\n\n\n    efree(rd_kafka_version);\n\n    php_info_print_table_end();\n}\n/* }}} */\n\n/* {{{ rdkafka_module_entry\n */\nzend_module_entry rdkafka_module_entry = {\n    STANDARD_MODULE_HEADER,\n    \"rdkafka\",\n    ext_functions,\n    PHP_MINIT(rdkafka),\n    NULL,\n    NULL,\n    NULL,\n    PHP_MINFO(rdkafka),\n    PHP_RDKAFKA_VERSION,\n    STANDARD_MODULE_PROPERTIES\n};\n/* }}} */\n\n#ifdef COMPILE_DL_RDKAFKA\nZEND_GET_MODULE(rdkafka)\n#endif\n"
        },
        {
          "name": "rdkafka.stub.php",
          "type": "blob",
          "size": 3.361328125,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace {\n    abstract class RdKafka {\n        private ?callable $error_cb;\n\n        private ?callable $dr_cb;\n\n        private function __construct() {}\n\n        /** @tentative-return-type */\n        public function addBrokers(string $broker_list): int {}\n\n        /** @tentative-return-type */\n        public function getMetadata(bool $all_topics, ?RdKafka\\Topic $only_topic, int $timeout_ms): RdKafka\\Metadata {}\n\n        /** @tentative-return-type */\n        public function getControllerId(int $timeout_ms): int {}\n\n        /** @tentative-return-type */\n        public function getOutQLen(): int {}\n\n        /**\n         * @alias RdKafka::getMetadata\n         * @deprecated\n         * @tentative-return-type\n         */\n        public function metadata(bool $all_topics, ?RdKafka\\Topic $only_topic, int $timeout_ms): RdKafka\\Metadata {}\n\n        /**\n         * @deprecated\n         * @tentative-return-type\n         */\n        public function setLogLevel(int $level): void {}\n\n        /** @tentative-return-type */\n        public function newTopic(string $topic_name, ?RdKafka\\TopicConf $topic_conf = null): RdKafka\\Topic {}\n\n        /**\n         * @alias RdKafka::getOutQLen\n         * @deprecated\n         * @tentative-return-type\n         */\n        public function outqLen(): int {}\n\n        /** @tentative-return-type */\n        public function poll(int $timeout_ms): int {}\n\n        /** @tentative-return-type */\n        public function flush(int $timeout_ms): int {}\n\n        /** @tentative-return-type */\n        public function purge(int $purge_flags): int {}\n\n        /**\n         * @deprecated\n         * @tentative-return-type\n         */\n        public function setLogger(int $logger): void {}\n\n        /** @tentative-return-type */\n        public function queryWatermarkOffsets(string $topic, int $partition, int &$low, int &$high, int $timeout_ms): void {}\n\n        /** @tentative-return-type */\n        public function offsetsForTimes(array $topic_partitions, int $timeout_ms): array {}\n\n        /** @tentative-return-type */\n        public function pausePartitions(array $topic_partitions): array {}\n\n        /** @tentative-return-type */\n        public function resumePartitions(array $topic_partitions): array {}\n        \n        /** @tentative-return-type */\n        public function oauthbearerSetToken(string $token_value, int|float|string $lifetime_ms, string $principal_name, array $extensions = []): void {}\n        \n        /** @tentative-return-type */\n        public function oauthbearerSetTokenFailure(string $error): void {}\n    }\n}\n\nnamespace RdKafka {\n    class Exception extends \\Exception {\n    }\n\n    class Consumer extends \\RdKafka {\n        public function __construct(?Conf $conf = null) {}\n\n        /** @tentative-return-type */\n        public function newQueue(): Queue {}\n    }\n\n    class Producer extends \\RdKafka {\n        public function __construct(?Conf $conf = null) {}\n\n        /** @tentative-return-type */\n        public function initTransactions(int $timeout_ms): void {}\n\n        /** @tentative-return-type */\n        public function beginTransaction(): void {}\n\n        /** @tentative-return-type */\n        public function commitTransaction(int $timeout_ms): void {}\n\n        /** @tentative-return-type */\n        public function abortTransaction(int $timeout_ms): void {}\n    }\n}\n"
        },
        {
          "name": "rdkafka_arginfo.h",
          "type": "blob",
          "size": 11.71484375,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: a7de61984c96ac34a70cd48ea1785a4ed5ed00d5 */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_addBrokers, 0, 1, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_addBrokers, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, broker_list, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_getMetadata, 0, 3, RdKafka\\\\Metadata, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_getMetadata, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, all_topics, _IS_BOOL, 0)\n\tZEND_ARG_OBJ_INFO(0, only_topic, RdKafka\\\\Topic, 1)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_getControllerId, 0, 1, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_getControllerId, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_getOutQLen, 0, 0, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_getOutQLen, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_metadata arginfo_class_RdKafka_getMetadata\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_setLogLevel, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_setLogLevel, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, level, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_newTopic, 0, 1, RdKafka\\\\Topic, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_newTopic, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_name, IS_STRING, 0)\n\tZEND_ARG_OBJ_INFO_WITH_DEFAULT_VALUE(0, topic_conf, RdKafka\\\\TopicConf, 1, \"null\")\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_outqLen arginfo_class_RdKafka_getOutQLen\n\n#define arginfo_class_RdKafka_poll arginfo_class_RdKafka_getControllerId\n\n#define arginfo_class_RdKafka_flush arginfo_class_RdKafka_getControllerId\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_purge, 0, 1, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_purge, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, purge_flags, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_setLogger, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_setLogger, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, logger, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_queryWatermarkOffsets, 0, 5, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_queryWatermarkOffsets, 0, 0, 5)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(1, low, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(1, high, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_offsetsForTimes, 0, 2, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_offsetsForTimes, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_partitions, IS_ARRAY, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_pausePartitions, 0, 1, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_pausePartitions, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, topic_partitions, IS_ARRAY, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_resumePartitions arginfo_class_RdKafka_pausePartitions\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_oauthbearerSetToken, 0, 3, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_oauthbearerSetToken, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, token_value, IS_STRING, 0)\n\tZEND_ARG_TYPE_MASK(0, lifetime_ms, MAY_BE_LONG|MAY_BE_DOUBLE|MAY_BE_STRING, NULL)\n\tZEND_ARG_TYPE_INFO(0, principal_name, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, extensions, IS_ARRAY, 0, \"[]\")\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_oauthbearerSetTokenFailure, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_oauthbearerSetTokenFailure, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, error, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Consumer___construct, 0, 0, 0)\n\tZEND_ARG_OBJ_INFO_WITH_DEFAULT_VALUE(0, conf, RdKafka\\\\Conf, 1, \"null\")\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_Consumer_newQueue, 0, 0, RdKafka\\\\Queue, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Consumer_newQueue, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Producer___construct arginfo_class_RdKafka_Consumer___construct\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Producer_initTransactions, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Producer_initTransactions, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Producer_beginTransaction, 0, 0, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Producer_beginTransaction, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_Producer_commitTransaction arginfo_class_RdKafka_Producer_initTransactions\n\n#define arginfo_class_RdKafka_Producer_abortTransaction arginfo_class_RdKafka_Producer_initTransactions\n\n\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka, addBrokers);\nZEND_METHOD(RdKafka, getMetadata);\nZEND_METHOD(RdKafka, getControllerId);\nZEND_METHOD(RdKafka, getOutQLen);\nZEND_METHOD(RdKafka, setLogLevel);\nZEND_METHOD(RdKafka, newTopic);\nZEND_METHOD(RdKafka, poll);\nZEND_METHOD(RdKafka, flush);\nZEND_METHOD(RdKafka, purge);\nZEND_METHOD(RdKafka, setLogger);\nZEND_METHOD(RdKafka, queryWatermarkOffsets);\nZEND_METHOD(RdKafka, offsetsForTimes);\nZEND_METHOD(RdKafka, pausePartitions);\nZEND_METHOD(RdKafka, resumePartitions);\nZEND_METHOD(RdKafka, oauthbearerSetToken);\nZEND_METHOD(RdKafka, oauthbearerSetTokenFailure);\nZEND_METHOD(RdKafka_Consumer, __construct);\nZEND_METHOD(RdKafka_Consumer, newQueue);\nZEND_METHOD(RdKafka_Producer, __construct);\nZEND_METHOD(RdKafka_Producer, initTransactions);\nZEND_METHOD(RdKafka_Producer, beginTransaction);\nZEND_METHOD(RdKafka_Producer, commitTransaction);\nZEND_METHOD(RdKafka_Producer, abortTransaction);\n\n\nstatic const zend_function_entry class_RdKafka_methods[] = {\n\tZEND_ME(RdKafka, __construct, arginfo_class_RdKafka___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka, addBrokers, arginfo_class_RdKafka_addBrokers, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, getMetadata, arginfo_class_RdKafka_getMetadata, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, getControllerId, arginfo_class_RdKafka_getControllerId, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, getOutQLen, arginfo_class_RdKafka_getOutQLen, ZEND_ACC_PUBLIC)\n\tZEND_MALIAS(RdKafka, metadata, getMetadata, arginfo_class_RdKafka_metadata, ZEND_ACC_PUBLIC|ZEND_ACC_DEPRECATED)\n\tZEND_ME(RdKafka, setLogLevel, arginfo_class_RdKafka_setLogLevel, ZEND_ACC_PUBLIC|ZEND_ACC_DEPRECATED)\n\tZEND_ME(RdKafka, newTopic, arginfo_class_RdKafka_newTopic, ZEND_ACC_PUBLIC)\n\tZEND_MALIAS(RdKafka, outqLen, getOutQLen, arginfo_class_RdKafka_outqLen, ZEND_ACC_PUBLIC|ZEND_ACC_DEPRECATED)\n\tZEND_ME(RdKafka, poll, arginfo_class_RdKafka_poll, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, flush, arginfo_class_RdKafka_flush, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, purge, arginfo_class_RdKafka_purge, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, setLogger, arginfo_class_RdKafka_setLogger, ZEND_ACC_PUBLIC|ZEND_ACC_DEPRECATED)\n\tZEND_ME(RdKafka, queryWatermarkOffsets, arginfo_class_RdKafka_queryWatermarkOffsets, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, offsetsForTimes, arginfo_class_RdKafka_offsetsForTimes, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, pausePartitions, arginfo_class_RdKafka_pausePartitions, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, resumePartitions, arginfo_class_RdKafka_resumePartitions, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, oauthbearerSetToken, arginfo_class_RdKafka_oauthbearerSetToken, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka, oauthbearerSetTokenFailure, arginfo_class_RdKafka_oauthbearerSetTokenFailure, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_Exception_methods[] = {\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_Consumer_methods[] = {\n\tZEND_ME(RdKafka_Consumer, __construct, arginfo_class_RdKafka_Consumer___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Consumer, newQueue, arginfo_class_RdKafka_Consumer_newQueue, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_Producer_methods[] = {\n\tZEND_ME(RdKafka_Producer, __construct, arginfo_class_RdKafka_Producer___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Producer, initTransactions, arginfo_class_RdKafka_Producer_initTransactions, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Producer, beginTransaction, arginfo_class_RdKafka_Producer_beginTransaction, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Producer, commitTransaction, arginfo_class_RdKafka_Producer_commitTransaction, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_Producer, abortTransaction, arginfo_class_RdKafka_Producer_abortTransaction, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_CLASS_ENTRY(ce, \"RdKafka\", class_RdKafka_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\tclass_entry->ce_flags |= ZEND_ACC_ABSTRACT;\n\n\tzval property_error_cb_default_value;\n\tZVAL_UNDEF(&property_error_cb_default_value);\n\tzend_string *property_error_cb_name = zend_string_init(\"error_cb\", sizeof(\"error_cb\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_error_cb_name, &property_error_cb_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_CALLABLE|MAY_BE_NULL));\n\tzend_string_release(property_error_cb_name);\n\n\tzval property_dr_cb_default_value;\n\tZVAL_UNDEF(&property_dr_cb_default_value);\n\tzend_string *property_dr_cb_name = zend_string_init(\"dr_cb\", sizeof(\"dr_cb\") - 1, 1);\n\tzend_declare_typed_property(class_entry, property_dr_cb_name, &property_dr_cb_default_value, ZEND_ACC_PRIVATE, NULL, (zend_type) ZEND_TYPE_INIT_MASK(MAY_BE_CALLABLE|MAY_BE_NULL));\n\tzend_string_release(property_dr_cb_name);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_Exception(zend_class_entry *class_entry_Exception)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Exception\", class_RdKafka_Exception_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_Exception);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_Consumer(zend_class_entry *class_entry_RdKafka)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Consumer\", class_RdKafka_Consumer_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_Producer(zend_class_entry *class_entry_RdKafka)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Producer\", class_RdKafka_Producer_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "topic.c",
          "type": "blob",
          "size": 18.3642578125,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"ext/spl/spl_iterators.h\"\n#include \"Zend/zend_interfaces.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n#include \"topic.h\"\n#include \"queue.h\"\n#include \"message.h\"\n#include \"topic_arginfo.h\"\n\nstatic zend_object_handlers object_handlers;\nzend_class_entry * ce_kafka_consumer_topic;\nzend_class_entry * ce_kafka_kafka_consumer_topic;\nzend_class_entry * ce_kafka_producer_topic;\nzend_class_entry * ce_kafka_topic;\n\ntypedef struct _php_callback {\n    zend_fcall_info fci;\n    zend_fcall_info_cache fcc;\n} php_callback;\n\nstatic void kafka_topic_free(zend_object *object) /* {{{ */\n{\n    kafka_topic_object *intern = php_kafka_from_obj(kafka_topic_object, object);\n\n    if (Z_TYPE(intern->zrk) != IS_UNDEF && intern->rkt) {\n        kafka_object *kafka_intern = get_kafka_object(&intern->zrk);\n        if (kafka_intern) {\n            zend_hash_index_del(&kafka_intern->topics, (zend_ulong)intern);\n        }\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *kafka_topic_new(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    kafka_topic_object *intern;\n\n    intern = zend_object_alloc(sizeof(*intern), class_type);\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &object_handlers;\n\n    return retval;\n}\n/* }}} */\n\n\nstatic void consume_callback(rd_kafka_message_t *msg, void *opaque)\n{\n    php_callback *cb = (php_callback*) opaque;\n    zval args[1];\n\n    if (!opaque) {\n        return;\n    }\n\n    if (!cb) {\n        return;\n    }\n\n    ZVAL_NULL(&args[0]);\n\n    kafka_message_new(&args[0], msg, NULL);\n\n    rdkafka_call_function(&cb->fci, &cb->fcc, NULL, 1, args);\n\n    zval_ptr_dtor(&args[0]);\n}\n\nkafka_topic_object * get_kafka_topic_object(zval *zrkt)\n{\n    kafka_topic_object *orkt = Z_RDKAFKA_P(kafka_topic_object, zrkt);\n\n    if (!orkt->rkt) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\Topic::__construct() has not been called\");\n        return NULL;\n    }\n\n    return orkt;\n}\n\n/* {{{ proto RdKafka\\ConsumerTopic::consumeCallback([int $partition, int timeout_ms, mixed $callback]) */\nPHP_METHOD(RdKafka_ConsumerTopic, consumeCallback)\n{\n    php_callback cb;\n    zend_long partition;\n    zend_long timeout_ms;\n    long result;\n    kafka_topic_object *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"llf\", &partition, &timeout_ms, &cb.fci, &cb.fcc) == FAILURE) {\n        return;\n    }\n\n    if (partition < 0 || partition > 0x7FFFFFFF) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    Z_ADDREF_P(&cb.fci.function_name);\n\n    result = rd_kafka_consume_callback(intern->rkt, partition, timeout_ms, consume_callback, &cb);\n\n    zval_ptr_dtor(&cb.fci.function_name);\n\n    RETURN_LONG(result);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ConsumerTopic::consumeQueueStart(int $partition, int $offset, RdKafka\\Queue $queue)\n * Same as consumeStart(), but re-routes incoming messages to the provided queue */\nPHP_METHOD(RdKafka_ConsumerTopic, consumeQueueStart)\n{\n    zval *zrkqu;\n    kafka_topic_object *intern;\n    kafka_queue_object *queue_intern;\n    zend_long partition;\n    zend_long offset;\n    int ret;\n    rd_kafka_resp_err_t err;\n    kafka_object *kafka_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"llO\", &partition, &offset, &zrkqu, ce_kafka_queue) == FAILURE) {\n        return;\n    }\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    queue_intern = get_kafka_queue_object(zrkqu);\n    if (!queue_intern) {\n        return;\n    }\n\n    kafka_intern = get_kafka_object(&intern->zrk);\n    if (!kafka_intern) {\n        return;\n    }\n\n    if (is_consuming_toppar(kafka_intern, intern->rkt, partition)) {\n        zend_throw_exception_ex(\n            ce_kafka_exception,\n            0,\n            \"%s:\" ZEND_LONG_FMT \" is already being consumed by the same Consumer instance\",\n            rd_kafka_topic_name(intern->rkt),\n            partition\n        );\n        return;\n    }\n\n    ret = rd_kafka_consume_start_queue(intern->rkt, partition, offset, queue_intern->rkqu);\n\n    if (ret == -1) {\n        err = rd_kafka_last_error();\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    add_consuming_toppar(kafka_intern, intern->rkt, partition);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ConsumerTopic::consumeStart(int partition, int offset)\n   Start consuming messages */\nPHP_METHOD(RdKafka_ConsumerTopic, consumeStart)\n{\n    kafka_topic_object *intern;\n    zend_long partition;\n    zend_long offset;\n    int ret;\n    rd_kafka_resp_err_t err;\n    kafka_object *kafka_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"ll\", &partition, &offset) == FAILURE) {\n        return;\n    }\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    kafka_intern = get_kafka_object(&intern->zrk);\n    if (!kafka_intern) {\n        return;\n    }\n\n    if (is_consuming_toppar(kafka_intern, intern->rkt, partition)) {\n        zend_throw_exception_ex(\n            ce_kafka_exception,\n            0,\n            \"%s:\" ZEND_LONG_FMT \" is already being consumed by the same Consumer instance\",\n            rd_kafka_topic_name(intern->rkt),\n            partition\n        );\n        return;\n    }\n\n    ret = rd_kafka_consume_start(intern->rkt, partition, offset);\n\n    if (ret == -1) {\n        err = rd_kafka_last_error();\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    add_consuming_toppar(kafka_intern, intern->rkt, partition);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ConsumerTopic::consumeStop(int partition)\n   Stop consuming messages */\nPHP_METHOD(RdKafka_ConsumerTopic, consumeStop)\n{\n    kafka_topic_object *intern;\n    zend_long partition;\n    int ret;\n    rd_kafka_resp_err_t err;\n    kafka_object *kafka_intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &partition) == FAILURE) {\n        return;\n    }\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    kafka_intern = get_kafka_object(&intern->zrk);\n    if (!kafka_intern) {\n        return;\n    }\n\n    ret = rd_kafka_consume_stop(intern->rkt, partition);\n\n    if (ret == -1) {\n        err = rd_kafka_last_error();\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    del_consuming_toppar(kafka_intern, intern->rkt, partition);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Message RdKafka\\ConsumerTopic::consume(int $partition, int timeout_ms)\n   Consume a single message from partition */\nPHP_METHOD(RdKafka_ConsumerTopic, consume)\n{\n    kafka_topic_object *intern;\n    zend_long partition;\n    zend_long timeout_ms;\n    rd_kafka_message_t *message;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"ll\", &partition, &timeout_ms) == FAILURE) {\n        return;\n    }\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    message = rd_kafka_consume(intern->rkt, partition, timeout_ms);\n\n    if (!message) {\n        err = rd_kafka_last_error();\n        if (err == RD_KAFKA_RESP_ERR__TIMED_OUT) {\n            return;\n        }\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    kafka_message_new(return_value, message, NULL);\n\n    rd_kafka_message_destroy(message);\n}\n/* }}} */\n\n/* {{{ proto RdKafka\\Message RdKafka\\ConsumerTopic::consumeBatch(int $partition, int $timeout_ms, int $batch_size)\n   Consume a batch of messages from a partition */\nPHP_METHOD(RdKafka_ConsumerTopic, consumeBatch)\n{\n    kafka_topic_object *intern;\n    zend_long partition, timeout_ms, batch_size;\n    long result, i;\n    rd_kafka_message_t **rkmessages;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"lll\", &partition, &timeout_ms, &batch_size) == FAILURE) {\n        return;\n    }\n\n    if (0 >= batch_size) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for batch_size\", batch_size);\n        return;\n    }\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    rkmessages = malloc(sizeof(*rkmessages) * batch_size);\n\n    result = rd_kafka_consume_batch(intern->rkt, partition, timeout_ms, rkmessages, batch_size);\n\n    if (result == -1) {\n        free(rkmessages);\n        err = rd_kafka_last_error();\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n\n    if (result >= 0) {\n        kafka_message_list_to_array(return_value, rkmessages, result);\n        for (i = 0; i < result; ++i) {\n            rd_kafka_message_destroy(rkmessages[i]);\n        }\n    }\n\n    free(rkmessages);\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ConsumerTopic::offsetStore(int partition, int offset) */\nPHP_METHOD(RdKafka_ConsumerTopic, offsetStore)\n{\n    kafka_topic_object *intern;\n    zend_long partition;\n    zend_long offset;\n    rd_kafka_resp_err_t err;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"ll\", &partition, &offset) == FAILURE) {\n        return;\n    }\n\n    if (partition < 0 || partition > 0x7FFFFFFF) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    err = rd_kafka_offset_store(intern->rkt, partition, offset);\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ProducerTopic::produce(int $partition, int $msgflags[, string $payload[, string $key[, string $msg_opaque]]])\n   Produce and send a single message to broker. */\nPHP_METHOD(RdKafka_ProducerTopic, produce)\n{\n    zend_long partition;\n    zend_long msgflags;\n    char *payload = NULL;\n    size_t payload_len = 0;\n    char *key = NULL;\n    size_t key_len = 0;\n    zend_string *opaque = NULL;\n    int ret;\n    rd_kafka_resp_err_t err;\n    kafka_topic_object *intern;\n\n    ZEND_PARSE_PARAMETERS_START(2, 5)\n        Z_PARAM_LONG(partition)\n        Z_PARAM_LONG(msgflags)\n        Z_PARAM_OPTIONAL\n        Z_PARAM_STRING_OR_NULL(payload, payload_len)\n        Z_PARAM_STRING_OR_NULL(key, key_len)\n        Z_PARAM_STR_OR_NULL(opaque)\n    ZEND_PARSE_PARAMETERS_END();\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    if (msgflags != 0 && msgflags != RD_KAFKA_MSG_F_BLOCK) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Invalid value '\" ZEND_LONG_FMT \"' for $msgflags\", msgflags);\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n\n    if (opaque != NULL) {\n        zend_string_addref(opaque);\n    }\n\n    ret = rd_kafka_produce(intern->rkt, partition, msgflags | RD_KAFKA_MSG_F_COPY, payload, payload_len, key, key_len, opaque);\n\n    if (ret == -1) {\n        if (opaque != NULL) {\n            zend_string_release(opaque);\n        }\n        err = rd_kafka_last_error();\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto void RdKafka\\ProducerTopic::producev(int $partition, int $msgflags[, string $payload[, string $key[, array $headers[, int $timestamp_ms[, string msg_opaque]]]]])\n   Produce and send a single message to broker (with headers possibility and timestamp). */\nPHP_METHOD(RdKafka_ProducerTopic, producev)\n{\n    zend_long partition;\n    zend_long msgflags;\n    char *payload = NULL;\n    size_t payload_len = 0;\n    char *key = NULL;\n    size_t key_len = 0;\n    rd_kafka_resp_err_t err;\n    kafka_topic_object *intern;\n    kafka_object *kafka_intern;\n    HashTable *headersParam = NULL;\n    HashPosition headersParamPos;\n    char *header_key;\n    zval *header_value;\n    rd_kafka_headers_t *headers;\n    zend_long timestamp_ms = 0;\n    zend_bool timestamp_ms_is_null = 0;\n    zend_string *opaque = NULL;\n\n    ZEND_PARSE_PARAMETERS_START(2, 7)\n        Z_PARAM_LONG(partition)\n        Z_PARAM_LONG(msgflags)\n        Z_PARAM_OPTIONAL\n        Z_PARAM_STRING_OR_NULL(payload, payload_len)\n        Z_PARAM_STRING_OR_NULL(key, key_len)\n        Z_PARAM_ARRAY_HT_OR_NULL(headersParam)\n        Z_PARAM_LONG_OR_NULL(timestamp_ms, timestamp_ms_is_null)\n        Z_PARAM_STR_OR_NULL(opaque)\n    ZEND_PARSE_PARAMETERS_END();\n\n    if (partition != RD_KAFKA_PARTITION_UA && (partition < 0 || partition > 0x7FFFFFFF)) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Out of range value '\" ZEND_LONG_FMT \"' for $partition\", partition);\n        return;\n    }\n\n    if (msgflags != 0 && msgflags != RD_KAFKA_MSG_F_BLOCK) {\n        zend_throw_exception_ex(spl_ce_InvalidArgumentException, 0, \"Invalid value '\" ZEND_LONG_FMT \"' for $msgflags\", msgflags);\n        return;\n    }\n\n    if (timestamp_ms_is_null == 1) {\n        timestamp_ms = 0;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n\n    if (opaque != NULL) {\n        zend_string_addref(opaque);\n    }\n\n    if (headersParam != NULL && zend_hash_num_elements(headersParam) > 0) {\n        headers = rd_kafka_headers_new(zend_hash_num_elements(headersParam));\n        for (zend_hash_internal_pointer_reset_ex(headersParam, &headersParamPos);\n                (header_value = zend_hash_get_current_data_ex(headersParam, &headersParamPos)) != NULL &&\n                (header_key = rdkafka_hash_get_current_key_ex(headersParam, &headersParamPos)) != NULL;\n                zend_hash_move_forward_ex(headersParam, &headersParamPos)) {\n            convert_to_string_ex(header_value);\n            rd_kafka_header_add(\n                headers,\n                header_key,\n                -1, // Auto detect header title length\n                Z_STRVAL_P(header_value),\n                Z_STRLEN_P(header_value)\n            );\n        }\n    } else {\n        headers = rd_kafka_headers_new(0);\n    }\n\n    kafka_intern = get_kafka_object(&intern->zrk);\n    if (!kafka_intern) {\n        return;\n    }\n\n    err = rd_kafka_producev(\n            kafka_intern->rk,\n            RD_KAFKA_V_RKT(intern->rkt),\n            RD_KAFKA_V_PARTITION(partition),\n            RD_KAFKA_V_MSGFLAGS(msgflags | RD_KAFKA_MSG_F_COPY),\n            RD_KAFKA_V_VALUE(payload, payload_len),\n            RD_KAFKA_V_KEY(key, key_len),\n            RD_KAFKA_V_TIMESTAMP(timestamp_ms),\n            RD_KAFKA_V_HEADERS(headers),\n            RD_KAFKA_V_OPAQUE(opaque),\n            RD_KAFKA_V_END\n    );\n\n    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {\n        rd_kafka_headers_destroy(headers);\n        if (opaque != NULL) {\n            zend_string_release(opaque);\n        }\n        zend_throw_exception(ce_kafka_exception, rd_kafka_err2str(err), err);\n        return;\n    }\n}\n/* }}} */\n\n/* {{{ proto string RdKafka\\Topic::getName() */\nPHP_METHOD(RdKafka_Topic, getName)\n{\n    kafka_topic_object *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_kafka_topic_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_STRING(rd_kafka_topic_name(intern->rkt));\n}\n/* }}} */\n\nvoid kafka_topic_minit(INIT_FUNC_ARGS) { /* {{{ */\n\n    memcpy(&object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n    object_handlers.clone_obj = NULL;\n    object_handlers.free_obj = kafka_topic_free;\n    object_handlers.offset = XtOffsetOf(kafka_topic_object, std);\n\n    ce_kafka_topic = register_class_RdKafka_Topic();\n    ce_kafka_topic->create_object = kafka_topic_new;\n\n    ce_kafka_consumer_topic = register_class_RdKafka_ConsumerTopic(ce_kafka_topic);\n\n    ce_kafka_kafka_consumer_topic = register_class_RdKafka_KafkaConsumerTopic(ce_kafka_topic);\n\n    ce_kafka_producer_topic = register_class_RdKafka_ProducerTopic(ce_kafka_topic);\n} /* }}} */\n"
        },
        {
          "name": "topic.h",
          "type": "blob",
          "size": 1.541015625,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\ntypedef struct _kafka_topic_object {\n    rd_kafka_topic_t    *rkt;\n    zval               zrk;\n    zend_object         std;\n} kafka_topic_object;\n\nvoid kafka_topic_minit(INIT_FUNC_ARGS);\nkafka_topic_object * get_kafka_topic_object(zval *zrkt);\n\nextern zend_class_entry * ce_kafka_consumer_topic;\nextern zend_class_entry * ce_kafka_kafka_consumer_topic;\nextern zend_class_entry * ce_kafka_producer_topic;\nextern zend_class_entry * ce_kafka_topic;\n"
        },
        {
          "name": "topic.stub.php",
          "type": "blob",
          "size": 1.9560546875,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nabstract class Topic\n{\n    /** @tentative-return-type */\n    public function getName(): string {}\n}\n\nclass ConsumerTopic extends Topic\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function consumeQueueStart(int $partition, int $offset, Queue $queue): void {}\n\n    /** @tentative-return-type */\n    public function consumeCallback(int $partition, int $timeout_ms, callable $callback): int {}\n\n    /** @tentative-return-type */\n    public function consumeStart(int $partition, int $offset): void {}\n\n    /** @tentative-return-type */\n    public function consumeStop(int $partition): void {}\n\n    /** @tentative-return-type */\n    public function consume(int $partition, int $timeout_ms): ?Message {}\n\n    /** @tentative-return-type */\n    public function consumeBatch(int $partition, int $timeout_ms, int $batch_size): array {}\n\n    /** @tentative-return-type */\n    public function offsetStore(int $partition, int $offset): void {}\n}\n\nclass KafkaConsumerTopic extends Topic\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /**\n     * @implementation-alias RdKafka\\ConsumerTopic::offsetStore\n     * @tentative-return-type\n     */\n    public function offsetStore(int $partition, int $offset): void {}\n}\n\nclass ProducerTopic extends Topic\n{\n    /** @implementation-alias RdKafka::__construct */\n    private function __construct() {}\n\n    /** @tentative-return-type */\n    public function produce(int $partition, int $msgflags, ?string $payload = null, ?string $key = null, ?string $msg_opaque = null): void {}\n\n    /** @tentative-return-type */\n    public function producev(int $partition, int $msgflags, ?string $payload = null, ?string $key = null, ?array $headers = null, ?int $timestamp_ms = null, ?string $msg_opaque = null): void {}\n}\n"
        },
        {
          "name": "topic_arginfo.h",
          "type": "blob",
          "size": 8.021484375,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 552619ee1c20d5c1bf1286578c2825ed3d1164d1 */\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_Topic_getName, 0, 0, IS_STRING, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_Topic_getName, 0, 0, 0)\n#endif\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic___construct, 0, 0, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeQueueStart, 0, 3, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeQueueStart, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, offset, IS_LONG, 0)\n\tZEND_ARG_OBJ_INFO(0, queue, RdKafka\\\\Queue, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeCallback, 0, 3, IS_LONG, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeCallback, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, callback, IS_CALLABLE, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeStart, 0, 2, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeStart, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, offset, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeStop, 0, 1, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeStop, 0, 0, 1)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consume, 0, 2, RdKafka\\\\Message, 1)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consume, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeBatch, 0, 3, IS_ARRAY, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ConsumerTopic_consumeBatch, 0, 0, 3)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, timeout_ms, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, batch_size, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_ConsumerTopic_offsetStore arginfo_class_RdKafka_ConsumerTopic_consumeStart\n\n#define arginfo_class_RdKafka_KafkaConsumerTopic___construct arginfo_class_RdKafka_ConsumerTopic___construct\n\n#define arginfo_class_RdKafka_KafkaConsumerTopic_offsetStore arginfo_class_RdKafka_ConsumerTopic_consumeStart\n\n#define arginfo_class_RdKafka_ProducerTopic___construct arginfo_class_RdKafka_ConsumerTopic___construct\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ProducerTopic_produce, 0, 2, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ProducerTopic_produce, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, msgflags, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, payload, IS_STRING, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, key, IS_STRING, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, msg_opaque, IS_STRING, 1, \"null\")\nZEND_END_ARG_INFO()\n\n#if (PHP_VERSION_ID >= 80100)\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_ProducerTopic_producev, 0, 2, IS_VOID, 0)\n#else\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_ProducerTopic_producev, 0, 0, 2)\n#endif\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO(0, msgflags, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, payload, IS_STRING, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, key, IS_STRING, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, headers, IS_ARRAY, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, timestamp_ms, IS_LONG, 1, \"null\")\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, msg_opaque, IS_STRING, 1, \"null\")\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka_Topic, getName);\nZEND_METHOD(RdKafka, __construct);\nZEND_METHOD(RdKafka_ConsumerTopic, consumeQueueStart);\nZEND_METHOD(RdKafka_ConsumerTopic, consumeCallback);\nZEND_METHOD(RdKafka_ConsumerTopic, consumeStart);\nZEND_METHOD(RdKafka_ConsumerTopic, consumeStop);\nZEND_METHOD(RdKafka_ConsumerTopic, consume);\nZEND_METHOD(RdKafka_ConsumerTopic, consumeBatch);\nZEND_METHOD(RdKafka_ConsumerTopic, offsetStore);\nZEND_METHOD(RdKafka_ProducerTopic, produce);\nZEND_METHOD(RdKafka_ProducerTopic, producev);\n\n\nstatic const zend_function_entry class_RdKafka_Topic_methods[] = {\n\tZEND_ME(RdKafka_Topic, getName, arginfo_class_RdKafka_Topic_getName, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_ConsumerTopic_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_ConsumerTopic___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_ConsumerTopic, consumeQueueStart, arginfo_class_RdKafka_ConsumerTopic_consumeQueueStart, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, consumeCallback, arginfo_class_RdKafka_ConsumerTopic_consumeCallback, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, consumeStart, arginfo_class_RdKafka_ConsumerTopic_consumeStart, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, consumeStop, arginfo_class_RdKafka_ConsumerTopic_consumeStop, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, consume, arginfo_class_RdKafka_ConsumerTopic_consume, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, consumeBatch, arginfo_class_RdKafka_ConsumerTopic_consumeBatch, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ConsumerTopic, offsetStore, arginfo_class_RdKafka_ConsumerTopic_offsetStore, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_KafkaConsumerTopic_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_KafkaConsumerTopic___construct, ZEND_ACC_PRIVATE)\n\tZEND_MALIAS(RdKafka_ConsumerTopic, offsetStore, offsetStore, arginfo_class_RdKafka_KafkaConsumerTopic_offsetStore, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\n\nstatic const zend_function_entry class_RdKafka_ProducerTopic_methods[] = {\n\tZEND_MALIAS(RdKafka, __construct, __construct, arginfo_class_RdKafka_ProducerTopic___construct, ZEND_ACC_PRIVATE)\n\tZEND_ME(RdKafka_ProducerTopic, produce, arginfo_class_RdKafka_ProducerTopic_produce, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_ProducerTopic, producev, arginfo_class_RdKafka_ProducerTopic_producev, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_Topic(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"Topic\", class_RdKafka_Topic_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\tclass_entry->ce_flags |= ZEND_ACC_ABSTRACT;\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_ConsumerTopic(zend_class_entry *class_entry_RdKafka_Topic)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"ConsumerTopic\", class_RdKafka_ConsumerTopic_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka_Topic);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_KafkaConsumerTopic(zend_class_entry *class_entry_RdKafka_Topic)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"KafkaConsumerTopic\", class_RdKafka_KafkaConsumerTopic_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka_Topic);\n\n\treturn class_entry;\n}\n\nstatic zend_class_entry *register_class_RdKafka_ProducerTopic(zend_class_entry *class_entry_RdKafka_Topic)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"ProducerTopic\", class_RdKafka_ProducerTopic_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, class_entry_RdKafka_Topic);\n\n\treturn class_entry;\n}\n"
        },
        {
          "name": "topic_partition.c",
          "type": "blob",
          "size": 9.7333984375,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\n#ifdef HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"php.h\"\n#include \"php_ini.h\"\n#include \"ext/standard/info.h\"\n#include \"php_rdkafka.h\"\n#include \"php_rdkafka_priv.h\"\n#include \"librdkafka/rdkafka.h\"\n#include \"Zend/zend_exceptions.h\"\n#include \"ext/spl/spl_exceptions.h\"\n#include \"topic_partition.h\"\n#include \"topic_partition_arginfo.h\"\n\ntypedef kafka_topic_partition_intern object_intern;\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp);\n\nzend_class_entry * ce_kafka_topic_partition;\n\nstatic zend_object_handlers handlers;\n\nstatic void free_object(zend_object *object) /* {{{ */\n{\n    object_intern *intern = php_kafka_from_obj(object_intern, object);\n\n    if (intern->topic) {\n        efree(intern->topic);\n    }\n\n    zend_object_std_dtor(&intern->std);\n}\n/* }}} */\n\nstatic zend_object *create_object(zend_class_entry *class_type) /* {{{ */\n{\n    zend_object* retval;\n    object_intern *intern;\n\n    intern = ecalloc(1, sizeof(*intern));\n    zend_object_std_init(&intern->std, class_type);\n    object_properties_init(&intern->std, class_type);\n\n    retval = &intern->std;\n    retval->handlers = &handlers;\n\n    return retval;\n}\n/* }}} */\n\nstatic object_intern * get_object(zval *z) /* {{{ */\n{\n    object_intern *intern = Z_RDKAFKA_P(object_intern, z);\n\n    if (!intern->topic) {\n        zend_throw_exception_ex(NULL, 0, \"RdKafka\\\\TopicPartition::__construct() has not been called\");\n        return NULL;\n    }\n\n    return intern;\n} /* }}} */\n\nkafka_topic_partition_intern * get_topic_partition_object(zval *z) /* {{{ */\n{\n    return get_object(z);\n} /* }}} */\n\nstatic HashTable *get_debug_info(zend_object *object, int *is_temp) /* {{{ */\n{\n    zval ary;\n    object_intern *intern;\n\n    *is_temp = 1;\n\n    array_init(&ary);\n\n    intern = php_kafka_from_obj(object_intern, object);\n\n    if (!intern || !intern->topic) {\n        return Z_ARRVAL(ary);\n    }\n\n    if (intern->topic) {\n        add_assoc_string(&ary, \"topic\", intern->topic);\n    } else {\n        add_assoc_null(&ary, \"topic\");\n    }\n\n    add_assoc_long(&ary, \"partition\", intern->partition);\n    add_assoc_long(&ary, \"offset\", intern->offset);\n    add_assoc_long(&ary, \"err\", (zend_long) intern->err);\n\n    return Z_ARRVAL(ary);\n}\n/* }}} */\n\nvoid kafka_topic_partition_init(zval *zobj, char * topic, int32_t partition, int64_t offset, rd_kafka_resp_err_t err) /* {{{ */\n{\n    object_intern *intern;\n\n    intern = Z_RDKAFKA_P(object_intern, zobj);\n    if (!intern) {\n        return;\n    }\n\n    if (intern->topic) {\n        efree(intern->topic);\n    }\n    intern->topic = estrdup(topic);\n\n    intern->partition = partition;\n    intern->offset = offset;\n    intern->err = err;\n} /* }}} */\n\nvoid kafka_topic_partition_list_to_array(zval *return_value, rd_kafka_topic_partition_list_t *list) /* {{{ */\n{\n    rd_kafka_topic_partition_t *topar;\n    zval ztopar;\n    int i;\n\n    array_init_size(return_value, list->cnt);\n\n    for (i = 0; i < list->cnt; i++) {\n        topar = &list->elems[i];\n        ZVAL_NULL(&ztopar);\n        object_init_ex(&ztopar, ce_kafka_topic_partition);\n        kafka_topic_partition_init(&ztopar, topar->topic, topar->partition, topar->offset, topar->err);\n        add_next_index_zval(return_value, &ztopar);\n    }\n} /* }}} */\n\nrd_kafka_topic_partition_list_t * array_arg_to_kafka_topic_partition_list(int argnum, HashTable *ary) { /* {{{ */\n\n    HashPosition pos;\n    rd_kafka_topic_partition_list_t *list;\n    zval *zv;\n\n    list = rd_kafka_topic_partition_list_new(zend_hash_num_elements(ary));\n\n    for (zend_hash_internal_pointer_reset_ex(ary, &pos);\n            (zv = zend_hash_get_current_data_ex(ary, &pos)) != NULL;\n            zend_hash_move_forward_ex(ary, &pos)) {\n        kafka_topic_partition_intern *topar_intern;\n        rd_kafka_topic_partition_t *topar;\n\n        if (Z_TYPE_P(zv) != IS_OBJECT || !instanceof_function(Z_OBJCE_P(zv), ce_kafka_topic_partition)) {\n            const char *space;\n            const char *class_name = get_active_class_name(&space);\n            rd_kafka_topic_partition_list_destroy(list);\n            php_error(E_ERROR,\n                    \"Argument %d passed to %s%s%s() must be an array of RdKafka\\\\TopicPartition, at least one element is a(n) %s\",\n                    argnum,\n                    class_name, space,\n                    get_active_function_name(),\n                    zend_zval_type_name(zv));\n            return NULL;\n        }\n\n        topar_intern = get_topic_partition_object(zv);\n        if (!topar_intern) {\n            rd_kafka_topic_partition_list_destroy(list);\n            return NULL;\n        }\n\n        topar = rd_kafka_topic_partition_list_add(list, topar_intern->topic, topar_intern->partition);\n        topar->offset = topar_intern->offset;\n    }\n\n    return list;\n} /* }}} */\n\n\n/* {{{ proto void RdKafka\\TopicPartition::__construct(string $topic, int $partition[, int $offset])\n   Constructor */\nPHP_METHOD(RdKafka_TopicPartition, __construct)\n{\n    char *topic;\n    size_t topic_len;\n    zend_long partition;\n    zend_long offset = 0;\n    zend_error_handling error_handling;\n\n    zend_replace_error_handling(EH_THROW, spl_ce_InvalidArgumentException, &error_handling);\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"sl|l\", &topic, &topic_len, &partition, &offset) == FAILURE) {\n        zend_restore_error_handling(&error_handling);\n        return;\n    }\n\n    kafka_topic_partition_init(getThis(), topic, partition, offset, RD_KAFKA_RESP_ERR_NO_ERROR);\n\n    zend_restore_error_handling(&error_handling);\n}\n/* }}} */\n\n/* {{{ proto string RdKafka\\TopicPartition::getTopic()\n   Returns topic name */\nPHP_METHOD(RdKafka_TopicPartition, getTopic)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (intern->topic) {\n        RETURN_STRING(intern->topic);\n    } else {\n        RETURN_NULL();\n    }\n}\n/* }}} */\n\n/* {{{ proto TopicPartition RdKafka\\TopicPartition::setTopic($topicName)\n   Sets topic name */\nPHP_METHOD(RdKafka_TopicPartition, setTopic)\n{\n    char * topic;\n    size_t topic_len;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"s\", &topic, &topic_len) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    if (intern->topic) {\n        efree(intern->topic);\n    }\n\n    intern->topic = estrdup(topic);\n\n    RETURN_ZVAL(getThis(), 1, 0);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\TopicPartition::getPartition()\n   Returns partition */\nPHP_METHOD(RdKafka_TopicPartition, getPartition)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->partition);\n}\n/* }}} */\n\n/* {{{ proto TopicPartition RdKafka\\TopicPartition::setPartition($partition)\n   Sets partition */\nPHP_METHOD(RdKafka_TopicPartition, setPartition)\n{\n    zend_long partition;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &partition) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    intern->partition = partition;\n\n    RETURN_ZVAL(getThis(), 1, 0);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\TopicPartition::getOffset()\n   Returns offset */\nPHP_METHOD(RdKafka_TopicPartition, getOffset)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG(intern->offset);\n}\n/* }}} */\n\n/* {{{ proto TopicPartition RdKafka\\TopicPartition::setOffset($offset)\n   Sets offset */\nPHP_METHOD(RdKafka_TopicPartition, setOffset)\n{\n    zend_long offset;\n    object_intern *intern;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS(), \"l\", &offset) == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    intern->offset = offset;\n\n    RETURN_ZVAL(getThis(), 1, 0);\n}\n/* }}} */\n\n/* {{{ proto int RdKafka\\TopicPartition::getErr()\n   Returns err */\nPHP_METHOD(RdKafka_TopicPartition, getErr)\n{\n    object_intern *intern;\n\n    if (zend_parse_parameters_none() == FAILURE) {\n        return;\n    }\n\n    intern = get_object(getThis());\n    if (!intern) {\n        return;\n    }\n\n    RETURN_LONG((zend_long) intern->err);\n}\n/* }}} */\n\nvoid kafka_metadata_topic_partition_minit(INIT_FUNC_ARGS) /* {{{ */\n{\n    ce_kafka_topic_partition = register_class_RdKafka_TopicPartition();\n    ce_kafka_topic_partition->create_object = create_object;\n\n    handlers = kafka_default_object_handlers;\n    handlers.get_debug_info = get_debug_info;\n    handlers.free_obj = free_object;\n    handlers.offset = XtOffsetOf(object_intern, std);\n} /* }}} */\n"
        },
        {
          "name": "topic_partition.h",
          "type": "blob",
          "size": 1.794921875,
          "content": "/*\n  +----------------------------------------------------------------------+\n  | php-rdkafka                                                          |\n  +----------------------------------------------------------------------+\n  | Copyright (c) 2016 Arnaud Le Blanc                                   |\n  +----------------------------------------------------------------------+\n  | This source file is subject to version 3.01 of the PHP license,      |\n  | that is bundled with this package in the file LICENSE, and is        |\n  | available through the world-wide-web at the following url:           |\n  | http://www.php.net/license/3_01.txt                                  |\n  | If you did not receive a copy of the PHP license and are unable to   |\n  | obtain it through the world-wide-web, please send a note to          |\n  | license@php.net so we can mail you a copy immediately.               |\n  +----------------------------------------------------------------------+\n  | Author: Arnaud Le Blanc <arnaud.lb@gmail.com>                        |\n  +----------------------------------------------------------------------+\n*/\n\ntypedef struct _kafka_topic_partition_intern {\n    char        *topic;\n    int32_t     partition;\n    int64_t     offset;\n    rd_kafka_resp_err_t err;\n    zend_object std;\n} kafka_topic_partition_intern;\n\nvoid kafka_metadata_topic_partition_minit(INIT_FUNC_ARGS);\n\nkafka_topic_partition_intern * get_topic_partition_object(zval *z);\nvoid kafka_topic_partition_init(zval *z, char *topic, int32_t partition, int64_t offset, rd_kafka_resp_err_t err);\n\nvoid kafka_topic_partition_list_to_array(zval *return_value, rd_kafka_topic_partition_list_t *list);\nrd_kafka_topic_partition_list_t * array_arg_to_kafka_topic_partition_list(int argnum, HashTable *ary);\n\nextern zend_class_entry * ce_kafka_topic_partition;\n"
        },
        {
          "name": "topic_partition.stub.php",
          "type": "blob",
          "size": 0.81640625,
          "content": "<?php\n\n/**\n * @generate-class-entries\n * @generate-function-entries\n * @generate-legacy-arginfo\n */\n\nnamespace RdKafka;\n\nclass TopicPartition\n{\n    public function __construct(string $topic, int $partition, int $offset = 0) {}\n\n    /** @tentative-return-type */\n    public function getTopic(): ?string {}\n\n    /** @tentative-return-type */\n    public function setTopic(string $topic_name): TopicPartition {}\n\n    /** @tentative-return-type */\n    public function getPartition(): int {}\n\n    /** @tentative-return-type */\n    public function setPartition(int $partition): TopicPartition {}\n\n    /** @tentative-return-type */\n    public function getOffset(): int {}\n\n    /** @tentative-return-type */\n    public function setOffset(int $offset): TopicPartition {}\n\n    /** @tentative-return-type */\n    public function getErr(): ?int {}\n}\n"
        },
        {
          "name": "topic_partition_arginfo.h",
          "type": "blob",
          "size": 3.06640625,
          "content": "/* This is a generated file, edit the .stub.php file instead.\n * Stub hash: 7c722b9eb9357157d89a14431ebcfd79cc6f1116 */\n\nZEND_BEGIN_ARG_INFO_EX(arginfo_class_RdKafka_TopicPartition___construct, 0, 0, 2)\n\tZEND_ARG_TYPE_INFO(0, topic, IS_STRING, 0)\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\n\tZEND_ARG_TYPE_INFO_WITH_DEFAULT_VALUE(0, offset, IS_LONG, 0, \"0\")\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_TopicPartition_getTopic, 0, 0, IS_STRING, 1)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_TopicPartition_setTopic, 0, 1, RdKafka\\\\TopicPartition, 0)\n\tZEND_ARG_TYPE_INFO(0, topic_name, IS_STRING, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_TopicPartition_getPartition, 0, 0, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_TopicPartition_setPartition, 0, 1, RdKafka\\\\TopicPartition, 0)\n\tZEND_ARG_TYPE_INFO(0, partition, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\n#define arginfo_class_RdKafka_TopicPartition_getOffset arginfo_class_RdKafka_TopicPartition_getPartition\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_OBJ_INFO_EX(arginfo_class_RdKafka_TopicPartition_setOffset, 0, 1, RdKafka\\\\TopicPartition, 0)\n\tZEND_ARG_TYPE_INFO(0, offset, IS_LONG, 0)\nZEND_END_ARG_INFO()\n\nZEND_BEGIN_ARG_WITH_TENTATIVE_RETURN_TYPE_INFO_EX(arginfo_class_RdKafka_TopicPartition_getErr, 0, 0, IS_LONG, 1)\nZEND_END_ARG_INFO()\n\n\nZEND_METHOD(RdKafka_TopicPartition, __construct);\nZEND_METHOD(RdKafka_TopicPartition, getTopic);\nZEND_METHOD(RdKafka_TopicPartition, setTopic);\nZEND_METHOD(RdKafka_TopicPartition, getPartition);\nZEND_METHOD(RdKafka_TopicPartition, setPartition);\nZEND_METHOD(RdKafka_TopicPartition, getOffset);\nZEND_METHOD(RdKafka_TopicPartition, setOffset);\nZEND_METHOD(RdKafka_TopicPartition, getErr);\n\n\nstatic const zend_function_entry class_RdKafka_TopicPartition_methods[] = {\n\tZEND_ME(RdKafka_TopicPartition, __construct, arginfo_class_RdKafka_TopicPartition___construct, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, getTopic, arginfo_class_RdKafka_TopicPartition_getTopic, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, setTopic, arginfo_class_RdKafka_TopicPartition_setTopic, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, getPartition, arginfo_class_RdKafka_TopicPartition_getPartition, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, setPartition, arginfo_class_RdKafka_TopicPartition_setPartition, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, getOffset, arginfo_class_RdKafka_TopicPartition_getOffset, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, setOffset, arginfo_class_RdKafka_TopicPartition_setOffset, ZEND_ACC_PUBLIC)\n\tZEND_ME(RdKafka_TopicPartition, getErr, arginfo_class_RdKafka_TopicPartition_getErr, ZEND_ACC_PUBLIC)\n\tZEND_FE_END\n};\n\nstatic zend_class_entry *register_class_RdKafka_TopicPartition(void)\n{\n\tzend_class_entry ce, *class_entry;\n\n\tINIT_NS_CLASS_ENTRY(ce, \"RdKafka\", \"TopicPartition\", class_RdKafka_TopicPartition_methods);\n\tclass_entry = zend_register_internal_class_ex(&ce, NULL);\n\n\treturn class_entry;\n}\n"
        }
      ]
    }
  ]
}