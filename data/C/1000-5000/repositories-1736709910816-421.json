{
  "metadata": {
    "timestamp": 1736709910816,
    "page": 421,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "open-telemetry/opentelemetry-ebpf-profiler",
      "stars": 2577,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".codespellignore",
          "type": "blob",
          "size": 0.01953125,
          "content": "ba\nfo\nopne\noptimyze\n"
        },
        {
          "name": ".codespellrc",
          "type": "blob",
          "size": 0.251953125,
          "content": "# https://github.com/codespell-project/codespell\n[codespell]\nbuiltin = clear,rare,informal\ncheck-filenames =\ncheck-hidden =\nignore-words = .codespellignore\ninteractive = 1\nskip = .git,AUTHORS.md,go.mod,go.sum,LICENSES,zydis\nuri-ignore-words-list = *\nwrite =\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.009765625,
          "content": ".cache\ngo\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0537109375,
          "content": "*.o\n*.pb.go\n.cache\n/.idea\n/go\nebpf-profiler\nci-kernels\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 3.017578125,
          "content": "run:\n  timeout: 10m\n  build-tags:\n    - integration\n    - linux\n\nissues:\n  exclude-dirs:\n    - artifacts\n    - build-targets\n    - design\n    - docker-images\n    - docs\n    - etc\n    - experiments\n    - infrastructure\n    - legal\n    - libpf-rs\n    - mocks\n    - pf-code-indexing-service/cibackend/gomock_*\n    - pf-debug-metadata-service/dmsbackend/gomock_*\n    - pf-host-agent/support/ci-kernels\n    - pf-storage-backend/storagebackend/gomock_*\n    - scratch\n    - systemtests/benchmarks/_outdata\n    - target\n    - virt-tests\n    - vm-images\n\nlinters:\n  enable-all: true\n  disable:\n    # Disabled because of\n    #   - too many non-sensical warnings\n    #   - not relevant for us\n    #   - false positives\n    #\n    # \"might be worth fixing\" means we should investigate/fix in the mid term\n    - containedctx # might be worth fixing\n    - contextcheck # might be worth fixing\n    - cyclop\n    - depguard\n    - dupword\n    - durationcheck # might be worth fixing\n    - err113\n    - errorlint # might be worth fixing\n    - exhaustive\n    - exhaustruct\n    - forbidigo\n    - forcetypeassert # might be worth fixing\n    - funlen\n    - gci # might be worth fixing\n    - gochecknoglobals\n    - gochecknoinits\n    - gocognit\n    - goconst\n    - gocyclo\n    - godot\n    - godox # complains about TODO etc\n    - gofumpt\n    - gomnd\n    - gomoddirectives\n    - inamedparam\n    - interfacebloat\n    - ireturn\n    - maintidx\n    - makezero\n    - mnd\n    - nestif\n    - nilerr # might be worth fixing\n    - nilnil\n    - nlreturn\n    - noctx # might be worth fixing\n    - nonamedreturns\n    - paralleltest\n    - protogetter\n    - sqlclosecheck # might be worth fixing\n    - tagalign\n    - tagliatelle\n    - testableexamples # might be worth fixing\n    - testpackage\n    - tparallel # might be worth fixing\n    - thelper\n    - varnamelen\n    - wastedassign\n    - wsl\n    - wrapcheck\n    # the following linters are deprecated\n    - execinquery\n    # we don't want to change code to Go 1.22+ yet\n    - intrange\n    - copyloopvar\n\nlinters-settings:\n  goconst:\n    min-len: 2\n    min-occurrences: 2\n  gocritic:\n    enabled-tags:\n      - diagnostic\n      - experimental\n      - opinionated\n      - performance\n      - style\n    disabled-checks:\n      - dupImport # https://github.com/go-critic/go-critic/issues/845\n      - ifElseChain\n      - whyNoLint\n      - sloppyReassign\n      - uncheckedInlineErr # Experimental rule with high false positive rate.\n  gocyclo:\n    min-complexity: 15\n  govet:\n    enable-all: true\n    disable:\n      - fieldalignment\n    settings:\n      printf: # analyzer name, run `go tool vet help` to see all analyzers\n        funcs: # run `go tool vet help printf` to see available settings for `printf` analyzer\n          - debug,debugf,debugln\n          - error,errorf,errorln\n          - fatal,fatalf,fataln\n          - info,infof,infoln\n          - log,logf,logln\n          - warn,warnf,warnln\n          - print,printf,println,sprint,sprintf,sprintln,fprint,fprintf,fprintln\n  lll:\n    line-length: 100\n    tab-width: 4\n  misspell:\n    locale: US\n    ignore-words:\n      - rela\n"
        },
        {
          "name": "AUTHORS.md",
          "type": "blob",
          "size": 1.1904296875,
          "content": "## Open-Source contributors\n\nFor contributors statistics that occurred after the profiling agent was open sourced, please refer to [the GitHub statistics](https://github.com/open-telemetry/opentelemetry-ebpf-profiler/graphs/contributors).\n\n## Pre-OSS Optimyze/Elastic contributors\n\n- [@amannocci](https://github.com/amannocci)\n- [@athre0z](https://github.com/athre0z)\n- [@cauemarcondes](https://github.com/cauemarcondes)\n- [@christos68k](https://github.com/christos68k)\n- [@danielmitterdorfer](https://github.com/danielmitterdorfer)\n- [@dmathieu](https://github.com/dmathieu)\n- [@fabled](https://github.com/fabled)\n- [@florianl](https://github.com/florianl)\n- [@inge4pres](https://github.com/inge4pres)\n- [@iogbole](https://github.com/iogbole)\n- [@jbcrail](https://github.com/jbcrail)\n- [@joerowell](https://github.com/joerowell)\n- [@kruskall](https://github.com/kruskall)\n- [@mejofi](https://github.com/mejofi)\n- [@reakaleek](https://github.com/reakaleek)\n- [@rockdaboot](https://github.com/rockdaboot)\n- [@sboomsma](https://github.com/sboomsma)\n- [@SeanHeelan](https://github.com/SeanHeelan)\n- [@thomasdullien](https://github.com/thomasdullien)\n- [@v1v](https://github.com/v1v)\n- [@vikmik](https://github.com/vikmik)\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.0576171875,
          "content": "# Contributing to opentelemetry-ebpf-profiler\n\nThe Profiling special interest group (SIG) meets regularly. See the\nOpenTelemetry\n[community](https://github.com/open-telemetry/community)\nrepo for information on this and other SIGs.\n\n## Community\n\nSee the [public meeting\nnotes](https://docs.google.com/document/d/19UqPPPlGE83N37MhS93uRlxsP1_wGxQ33Qv6CDHaEp0/edit#heading=h.4rdgawyis2hd)\nfor a summary description of past meetings.\n\nSee the [calendar\ngroup](https://groups.google.com/a/opentelemetry.io/g/calendar-profiling) to\nget invited to meetings.\n\nSee the [#otel-profiles](https://cloud-native.slack.com/archives/C03J794L0BV)\nslack channel for discussions and questions.\n\n## Development\n\nYou can view and edit the source code by cloning this repository:\n\n```sh\ngit clone https://github.com/open-telemetry/opentelemetry-ebpf-profiler\n```\n\nRun `make test` to run the tests instead of `go test`.\n\n\n## Pull Requests\n\n### How to Send Pull Requests\n\nEveryone is welcome to contribute code to `opentelemetry-ebpf-profiler` via\nGitHub pull requests (PRs).\n\nTo create a new PR, fork the project in GitHub and clone the upstream\nrepo:\n\n```sh\ngit clone https://github.com/open-telemetry/opentelemetry-ebpf-profiler\n```\n\nThis will put the project in `opentelemetry-ebpf-profiler` in\ncurrent working directory.\n\nEnter the newly created directory and add your fork as a new remote:\n\n```sh\ngit remote add <YOUR_FORK> git@github.com:<YOUR_GITHUB_USERNAME>/opentelemetry-ebpf-profiler\n```\n\nCheck out a new branch, make modifications, run linters and tests, and push the\nbranch to your fork:\n\n```sh\ngit checkout -b <YOUR_BRANCH_NAME>\n# edit files\n# update changelog\ngit add -p\ngit commit\ngit push <YOUR_FORK> <YOUR_BRANCH_NAME>\n```\n\nOpen a pull request against the main `opentelemetry-ebpf-profiler` repo.\n\nAvoid rebasing and force-pushing to your branch to facilitate reviewing the\npull request.\nRewriting Git history makes it difficult to keep track of iterations during\ncode review.\nAll pull requests are squashed to a single commit upon merge to `main`.\n\n### How to Receive Comments\n\n* If the PR is not ready for review, please put `[WIP]` in the title,\n\ttag it as `work-in-progress`, or mark it as\n\t[`draft`](https://github.blog/2019-02-14-introducing-draft-pull-requests/).\n* Make sure CLA is signed and CI is clear.\n\n### How to Get PRs Merged\n\nA PR is considered **ready to merge** when:\n\n* It has received two qualified approvals[^1].\n\n\tThis is not enforced through automation, but needs to be validated by the\n\tmaintainer merging.\n\t* PRs introducing changes that have already been discussed and consensus\n\t\treached only need one qualified approval. The discussion and resolution\n\t\tneeds to be linked to the PR.\n\n* All feedback has been addressed.\n\t* All PR comments and suggestions are resolved.\n\t* All GitHub Pull Request reviews with a status of \"Request changes\" have\n\t\tbeen addressed. Another review by the objecting reviewer with a different\n\t\tstatus can be submitted to clear the original review, or the review can be\n\t\tdismissed by a [Maintainer] when the issues from the original review have\n\t\tbeen addressed.\n\t* Any comments or reviews that cannot be resolved between the PR author and\n\t\treviewers can be submitted to the community [Approver]s and [Maintainer]s\n\t\tduring the weekly SIG meeting. If consensus is reached among the\n\t\t[Approver]s and [Maintainer]s during the SIG meeting the objections to the\n\t\tPR may be dismissed or resolved or the PR closed by a [Maintainer].\n\t* Any substantive changes to the PR require existing Approval reviews be\n\t\tcleared unless the approver explicitly states that their approval persists\n\t\tacross changes. This includes changes resulting from other feedback.\n\t\t[Approver]s and [Maintainer]s can help in clearing reviews and they should\n\t\tbe consulted if there are any questions.\n\n* The PR branch is up to date with the base branch it is merging into.\n\t* To ensure this does not block the PR, it should be configured to allow\n\t\tmaintainers to update it.\n\n* It has been open for review for at least one working day. This gives people\n\treasonable time to review.\n\n* All required GitHub workflows have succeeded.\n* Urgent fix can take exception as long as it has been actively communicated\n\tamong [Maintainer]s.\n\nAny [Maintainer] can merge the PR once the above criteria have been met.\n\n[^1]: A qualified approval is a GitHub Pull Request review with \"Approve\"\n\tstatus from an OpenTelemetry Profiler [Approver] or [Maintainer].\n\n## Approvers and Maintainers\n\n### Approvers\n\n- [Florian Lehner](https://github.com/florianl), Elastic\n- [Joel Höner](https://github.com/athre0z)\n- [Tim Rühsen](https://github.com/rockdaboot), Elastic\n\n### Maintainers\n\n- [Christos Kalkanis](https://github.com/christos68k), Elastic\n- [Dmitry Filimonov](https://github.com/petethepig), Pyroscope/Grafana\n- [Felix Geisendörfer](https://github.com/felixge), Datadog\n- [Timo Teräs](https://github.com/fabled)\n\n### Become an Approver or a Maintainer\n\nSee the [community membership document in OpenTelemetry community\nrepo](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md).\n\n[Approver]: #approvers\n[Maintainer]: #maintainers\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.1728515625,
          "content": "FROM debian:testing-20241223-slim\n\nWORKDIR /agent\n\n# cross_debian_arch: amd64 or arm64\n# cross_pkg_arch: x86-64 or aarch64\nRUN cross_debian_arch=$(uname -m | sed -e 's/aarch64/amd64/'  -e 's/x86_64/arm64/'); \\\n    cross_pkg_arch=$(uname -m | sed -e 's/aarch64/x86-64/' -e 's/x86_64/aarch64/'); \\\n    apt-get update -y && \\\n    apt-get dist-upgrade -y && \\\n    apt-get install -y wget make git clang-17 unzip libc6-dev g++ gcc pkgconf \\\n        gcc-${cross_pkg_arch}-linux-gnu libc6-${cross_debian_arch}-cross && \\\n    apt-get clean autoclean && \\\n    apt-get autoremove --yes\n\nCOPY go.mod /tmp/go.mod\n# Extract Go version from go.mod\nRUN GO_VERSION=$(grep -oPm1 '^go \\K([[:digit:].]+)' /tmp/go.mod) && \\\n    GOARCH=$(uname -m) && if [ \"$GOARCH\" = \"x86_64\" ]; then GOARCH=amd64; elif [ \"$GOARCH\" = \"aarch64\" ]; then GOARCH=arm64; fi && \\\n    wget -qO- https://golang.org/dl/go${GO_VERSION}.linux-${GOARCH}.tar.gz | tar -C /usr/local -xz\n\n# Set Go environment variables\nENV GOPATH=\"/agent/go\"\nENV GOCACHE=\"/agent/.cache\"\nENV PATH=\"/usr/local/go/bin:$PATH\"\n\n# gRPC dependencies\nRUN go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.31.0\nRUN go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.3.0\n\nRUN                                                                                \\\n  PB_URL=\"https://github.com/protocolbuffers/protobuf/releases/download/v24.4/\";   \\\n  PB_FILE=\"protoc-24.4-linux-x86_64.zip\";                                      \\\n  INSTALL_DIR=\"/usr/local\";                                                        \\\n                                                                                   \\\n  wget -q \"$PB_URL/$PB_FILE\"                                                       \\\n    && unzip \"$PB_FILE\" -d \"$INSTALL_DIR\" 'bin/*' 'include/*'                      \\\n    && chmod +xr \"$INSTALL_DIR/bin/protoc\"                                         \\\n    && find \"$INSTALL_DIR/include\" -type d -exec chmod +x {} \\;                    \\\n    && find \"$INSTALL_DIR/include\" -type f -exec chmod +r {} \\;                    \\\n    && rm \"$PB_FILE\"\n\n# Append to /etc/profile for login shells\nRUN echo 'export PATH=\"/usr/local/go/bin:$PATH\"' >> /etc/profile\n\nENTRYPOINT [\"/bin/bash\", \"-l\", \"-c\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "LICENSES",
          "type": "tree",
          "content": null
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.9453125,
          "content": ".PHONY: all all-common clean ebpf generate test test-deps protobuf docker-image agent legal \\\n\tintegration-test-binaries codespell lint linter-version debug debug-agent ebpf-profiler\n\nSHELL := /usr/bin/env bash\n\n# Detect native architecture and translate to GOARCH.\nNATIVE_ARCH := $(shell uname -m)\nifeq ($(NATIVE_ARCH),x86_64)\nNATIVE_ARCH := amd64\nelse ifneq (,$(filter $(NATIVE_ARCH),aarch64 arm64))\nNATIVE_ARCH := arm64\nelse\n$(error Unsupported architecture: $(NATIVE_ARCH))\nendif\n\n# Valid values are: amd64, arm64.\nTARGET_ARCH ?= $(NATIVE_ARCH)\n\nifeq ($(NATIVE_ARCH),$(TARGET_ARCH))\nARCH_PREFIX :=\nelse ifeq ($(TARGET_ARCH),arm64)\nARCH_PREFIX := aarch64-linux-gnu-\nelse ifeq ($(TARGET_ARCH),amd64)\nARCH_PREFIX := x86_64-linux-gnu-\nelse\n$(error Unsupported architecture: $(TARGET_ARCH))\nendif\n\nexport TARGET_ARCH\nexport CGO_ENABLED = 1\nexport GOARCH = $(TARGET_ARCH)\nexport CC = $(ARCH_PREFIX)gcc\nexport OBJCOPY = $(ARCH_PREFIX)objcopy\n\nBRANCH = $(shell git rev-parse --abbrev-ref HEAD | tr -d '-' | tr '[:upper:]' '[:lower:]')\nCOMMIT_SHORT_SHA = $(shell git rev-parse --short=8 HEAD)\n\nVERSION ?= v0.0.0\nBUILD_TIMESTAMP ?= $(shell date +%s)\nREVISION ?= $(BRANCH)-$(COMMIT_SHORT_SHA)\n\nLDFLAGS := -X go.opentelemetry.io/ebpf-profiler/vc.version=$(VERSION) \\\n\t-X go.opentelemetry.io/ebpf-profiler/vc.revision=$(REVISION) \\\n\t-X go.opentelemetry.io/ebpf-profiler/vc.buildTimestamp=$(BUILD_TIMESTAMP) \\\n\t-extldflags=-static\n\nGO_TAGS := osusergo,netgo\nEBPF_FLAGS := \n\nGO_FLAGS := -buildvcs=false -ldflags=\"$(LDFLAGS)\"\n\nMAKEFLAGS += -j$(shell nproc)\n\nall: ebpf-profiler\n\ndebug: GO_TAGS := $(GO_TAGS),debugtracer\ndebug: EBPF_FLAGS += debug\ndebug: all\n\n# Removes the go build cache and binaries in the current project\nclean:\n\t@go clean -cache -i\n\t@$(MAKE) -s -C support/ebpf clean\n\t@rm -f support/*.test\n\t@chmod -Rf u+w go/ || true\n\t@rm -rf go .cache\n\ngenerate:\n\tGOARCH=$(NATIVE_ARCH) go generate ./...\n\nebpf:\n\t$(MAKE) $(EBPF_FLAGS) -C support/ebpf\n\nebpf-profiler: generate ebpf\n\tgo build $(GO_FLAGS) -tags $(GO_TAGS)\n\nGOLANGCI_LINT_VERSION = \"v1.60.1\"\nlint: generate vanity-import-check\n\tgo run github.com/golangci/golangci-lint/cmd/golangci-lint@$(GOLANGCI_LINT_VERSION) version\n\tgo run github.com/golangci/golangci-lint/cmd/golangci-lint@$(GOLANGCI_LINT_VERSION) run\n\nlinter-version:\n\t@echo $(GOLANGCI_LINT_VERSION)\n\n.PHONY: vanity-import-check\nvanity-import-check:\n\t@go install github.com/jcchavezs/porto/cmd/porto@latest\n\t@porto --include-internal -l . || ( echo \"(run: make vanity-import-fix)\"; exit 1 )\n\n.PHONY: vanity-import-fix\nvanity-import-fix: $(PORTO)\n\t@go install github.com/jcchavezs/porto/cmd/porto@latest\n\t@porto --include-internal -w .\n\ntest: generate ebpf test-deps\n\tgo test $(GO_FLAGS) -tags $(GO_TAGS) ./...\n\nTESTDATA_DIRS:= \\\n\tnativeunwind/elfunwindinfo/testdata \\\n\tlibpf/pfelf/testdata \\\n\treporter/testdata\n\ntest-deps:\n\t$(foreach testdata_dir, $(TESTDATA_DIRS), \\\n\t\t($(MAKE) -C \"$(testdata_dir)\") || exit ; \\\n\t)\n\nTEST_INTEGRATION_BINARY_DIRS := tracer processmanager/ebpf support\n\nintegration-test-binaries: generate ebpf\n\t$(foreach test_name, $(TEST_INTEGRATION_BINARY_DIRS), \\\n\t\t(go test -ldflags='-extldflags=-static' -trimpath -c \\\n\t\t\t-tags $(GO_TAGS),static_build,integration \\\n\t\t\t-o ./support/$(subst /,_,$(test_name)).test \\\n\t\t\t./$(test_name)) || exit ; \\\n\t)\n\ndocker-image:\n\tdocker build -t profiling-agent -f Dockerfile .\n\nagent:\n\tdocker run -v \"$$PWD\":/agent -it --rm --user $(shell id -u):$(shell id -g) otel/opentelemetry-ebpf-profiler-dev:latest \\\n\t   \"make TARGET_ARCH=$(TARGET_ARCH) VERSION=$(VERSION) REVISION=$(REVISION) BUILD_TIMESTAMP=$(BUILD_TIMESTAMP)\"\n\ndebug-agent:\n\tdocker run -v \"$$PWD\":/agent -it --rm --user $(shell id -u):$(shell id -g) otel/opentelemetry-ebpf-profiler-dev:latest \\\n\t   \"make TARGET_ARCH=$(TARGET_ARCH) VERSION=$(VERSION) REVISION=$(REVISION) BUILD_TIMESTAMP=$(BUILD_TIMESTAMP) debug\"\n\nlegal:\n\t@go install github.com/google/go-licenses@latest\n\t@go-licenses save --force . --save_path=LICENSES\n\t@./legal/add-non-go.sh legal/non-go-dependencies.json LICENSES\n\ncodespell:\n\t@codespell\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.4609375,
          "content": "# Introduction\n\nThis repository implements a whole-system, cross-language profiler for Linux via\neBPF.\n\n## Core features and strengths\n\n- Implements the [experimental OTel profiling\n  signal](https://github.com/open-telemetry/opentelemetry-proto/pull/534)\n- Very low CPU and memory overhead (1% CPU and 250MB memory are our upper limits\n  in testing and the agent typically manages to stay way below that)\n- Support for native C/C++ executables without the need for DWARF debug\n  information (by leveraging `.eh_frame` data as described in\n  [US11604718B1](https://patents.google.com/patent/US11604718B1/en?inventor=thomas+dullien&oq=thomas+dullien))\n- Support profiling of system libraries **without frame pointers** and **without\n  debug symbols on the host**.\n- Support for mixed stacktraces between runtimes - stacktraces go from Kernel\n  space through unmodified system libraries all the way into high-level\n  languages.\n- Support for native code (C/C++, Rust, Zig, Go, etc. without debug symbols on\n  host)\n- Support for a broad set of HLLs (Hotspot JVM, Python, Ruby, PHP, Node.JS, V8,\n  Perl), .NET is in preparation.\n- 100% non-intrusive: there's no need to load agents or libraries into the\n  processes that are being profiled.\n- No need for any reconfiguration, instrumentation or restarts of HLL\n  interpreters and VMs: the agent supports unwinding each of the supported\n  languages in the default configuration.\n- ARM64 support for all unwinders except NodeJS.\n- Support for native `inline frames`, which provide insights into compiler\n  optimizations and offer a higher precision of function call chains.\n\n## Building\n## Quick Start\nIf you'd like to quickly test the agent, you can skip to the [\"Visualizing data locally\"](https://github.com/open-telemetry/opentelemetry-ebpf-profiler?tab=readme-ov-file#visualizing-data-locally) section and launch devfiler. From there, follow the download links for prebuilt agent binaries.\n\n## Platform Requirements\nThe agent can be built with the provided make targets. Docker is required for containerized builds, and both amd64 and arm64 architectures are supported.\n\n For **Linux**, the following steps apply:\n  1. Build the Docker image containing the build environment:\n     ```sh\n     make docker-image\n     ```\n  2. Build the agent for your current machine's architecture:\n     ```sh\n     make agent\n     ```\n     Or `make debug-agent` for debug build.\n  3. To cross-complie for a different architecture (e.g. arm64):\n     ```sh\n     make agent TARGET_ARCH=arm64\n     ```\nThe resulting binary will be named <ebpf-profiler> in the current directory.\n\n## Other OSes\nSince the profiler is Linux-only, macOS and Windows users need to set up a Linux VM to build and run the agent. Ensure the appropriate architecture is specified if using cross-compilation. Use the same make targets as above after the Linux environment is configured in the VM.\n\n## Alternative Build (Without Docker)\nYou can build the agent without Docker by directly installing the dependencies listed in the Dockerfile. Once dependencies are set up, simply run:\n```sh\nmake\n```\nor\n```sh\nmake debug\n```\nThis will build the profiler natively on your machine.\n\n## Running\n\nYou can start the agent with the following command:\n\n```sh\nsudo ./ebpf-profiler -collection-agent=127.0.0.1:11000 -disable-tls\n```\n\nThe agent comes with a functional but work-in-progress / evolving implementation\nof the recently released OTel profiling [signal](https://github.com/open-telemetry/opentelemetry-proto/pull/534).\n\nThe agent loads the eBPF program and its maps, starts unwinding and reports\ncaptured traces to the backend.\n\n## Visualizing data locally\n\nWe created a desktop application called \"devfiler\" that allows visualizing the\nprofiling agent's output locally, making it very convenient for development use.\ndevfiler spins up a local server that listens on `0.0.0.0:11000`.\n\n![Screenshot of devfiler UI](./doc/devfiler.png)\n\nTo run it, simply download and unpack the archive from the following URL:\n\nhttps://upload.elastic.co/d/08ee5a08cdd4587d8db617e5b0a468667d3eda4698d30f78012077fbe5dc7a45\n\nAuthentication token: `68af26a155e25501`\n\n\nThe archive contains a build for each of the following platforms:\n\n- macOS (Intel)\n- macOS (Apple Silicon)\n- Linux AppImage (x86_64)\n- Linux AppImage (aarch64)\n\n> [!IMPORTANT]\n> \n> The macOS application isn't properly signed with an Apple developer certificate: macOS will\n> complain about the application being corrupted on start. To work around that, simply run the following\n> command after downloading the archive:\n>\n> ```\n> xattr -d com.apple.quarantine ~/Downloads/devfiler.app.zip\n> ```\n>\n> If you did this correctly, the application should run just fine after unpacking the ZIP.\n\n> [!NOTE]\n> devfiler is currently in an experimental preview stage.\n\n### macOS\n\nThis build of devfiler is currently not signed with a globally trusted Apple\ndeveloper ID, but with a developer certificate. If you simply double-click the\napplication, you'll run into an error. Instead of opening it with a double\nclick, simply do a **right-click** on `devfiler.app`, then choose \"Open\". If you\ngo this route, you'll instead be presented with the option to run it anyway.\n\n### Linux\n\nThe AppImages in the archive should run on any Linux distribution with a\nreasonably modern glibc and libgl installation. To run the application, simply\nextract the archive and then do:\n\n```console\n./devfiler-appimage-$(uname -m).AppImage\n```\n\n## Agent internals\n\nThe host agent is a Go application that is deployed to all machines customers\nwish to profile. It collects, processes and pushes observed stack traces and\nrelated meta-information to a backend collector.\n\n### Concepts\n\n#### File IDs\n\nA file ID uniquely identifies an executable, kernel or script language source\nfile.\n\nFile IDs for native applications are created by taking the SHA256 checksum of a\nfile's head, tail, and size, then truncating the hash digest to 16 bytes (128\nbits):\n\n```\nInput  ← Concat(File[:4096], File[-4096:], BigEndianUInt64(Len(File)))\nDigest ← SHA256(Input)\nFileID ← Digest[:16]\n```\n\nFile IDs for script and JIT languages are created in an interpreter-specific\nfashion.\n\nFile IDs for Linux kernels are calculated by taking the FNV128 hash of their GNU\nbuild ID.\n\n#### Stack unwinding\n\nStack unwinding is the process of recovering the list of function calls that\nlead execution to the point in the program at which the profiler interrupted it.\n\nHow stacks are unwound varies depending on whether a thread is running native,\nJITed or interpreted code, but the basic idea is always the same: every language\nthat supports arbitrarily nested function calls needs a way to keep track of\nwhich function it needs to return to after the current function completes. Our\nunwinder uses that same information to repeatedly determine the caller until we\nreach the thread's entry point.\n\nIn simplified pseudo-code:\n\n```\npc ← interrupted_process.cpu.pc\nsp ← interrupted_process.cpu.sp\n\nwhile !is_entry_point(pc):\n    file_id, start_addr, interp_type ← file_id_at_pc(pc)\n    push_frame(interp_type, file_id, pc - start_addr)\n    unwinder ← unwinder_for_interp(interp_type)\n    pc, sp ← unwinder.next_frame(pc, sp)\n```\n\n#### Symbolization\n\nSymbolization is the process of assigning source line information to the raw\naddresses extracted during stack unwinding.\n\nFor script and JIT languages that always have symbol information available on\nthe customer machines, the host agent is responsible for symbolizing frames.\n\nFor native code the symbolization occurs in the backend. Stack frames are sent\nas file IDs and the offset within the file and the symbolization service is then\nresponsible for assigning the correct function name, source file and lines in\nthe background. Symbols for open-source software installed from OS package repos\nare pulled in from our global symbolization infrastructure and symbols for\nprivate executables can be manually uploaded by the customer.\n\nThe primary reason for doing native symbolization in the backend is that native\nexecutables in production will often be stripped. Asking the customer to deploy\nsymbols to production would be both wasteful in terms of disk usage and also a\nmajor friction point in initial adoption.\n\n#### Stack trace representation\n\nWe have two major representations for our stack traces.\n\nThe raw trace format produced by our BPF unwinders:\n\nhttps://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/host/host.go#L60-L66\n\nThe final format produced after additional processing in user-land:\n\nhttps://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/libpf/libpf.go#L458-L463\n\nThe two might look rather similar at first glance, but there are some important differences:\n\n- the BPF variant uses truncated 64-bit file IDs to save precious kernel memory\n- for interpreter frames the BPF variant uses the file ID and line number fields to store\n  more or less arbitrary interpreter-specific data that is needed by the user-mode code to\n  conduct symbolization\n\nA third trace representation exists within our network protocol, but it essentially\njust a deduplicated, compressed representation of the user-land trace format.\n\n#### Trace hashing\n\nIn profiling it is common to see the same trace many times. Traces can be up to\n128 entries long, and repeatedly symbolizing and sending the same traces over the\nnetwork would be very wasteful. We use trace hashing to avoid this. Different\nhashing schemes are used for the BPF and user-mode trace representations. Multiple\n64 bit hashes can end up being mapped to the same 128 bit hash, but *not* vice-versa.\n\n**BPF trace hash (64 bit):**\n\n```\nH(kernel_stack_id, frames_user, PID)\n```\n\n**User-land trace hash (128 bit)**\n\n```\nH(frames_user_kernel)\n```\n\n### User-land sub-components\n\n#### Tracer\n\nThe tracer is a central user-land component that loads and attaches our BPF\nprograms to their corresponding BPF probes during startup and then continues to\nserve as the primary event pump for BPF <-> user-land communication. It further\ninstantiates and owns other important subcomponents like the process manager.\n\n#### Trace handler\n\nThe trace handler is responsible for converting traces from the BPF format to\nthe user-space format. It receives raw traces [tracer](#tracer), converts them\nto the user-space format and then sends them on to the [reporter](#reporter).\nThe majority of the conversion logic happens via a call into the process\nmanager's [`ConvertTrace`] function.\n\nSince converting and enriching BPF-format traces is not a cheap operation, the\ntrace handler is also responsible for keeping a cache (mapping) of trace hashes:\nfrom 64bit BPF hash to the user-space 128bit hash.\n\n[`ConvertTrace`]: https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/processmanager/manager.go#L208\n\n#### Reporter\n\nThe reporter receives traces and trace counts in the user-mode format from the\n[trace handler](#trace-handler), converts them to the gRPC representation and\nthen sends them out to a backend collector.\n\nIt also receives additional meta-information (such as [metrics](metrics/metrics.json) and [host metadata](hostmetadata/hostmetadata.json))\nwhich it also converts and sends out to a backend collector over gRPC.\n\nThe reporter does not offer strong guarantees regarding reliability of\nnetwork operations and may drop data at any point, an \"eventual consistency\"\nmodel.\n\n#### Process manager\n\nThe process manager receives process creation/termination events from\n[tracer](#tracer) and is responsible for making available any information to the\nBPF code that it needs to conduct unwinding. It maintains a map of the\nexecutables mapped into each process, loads stack unwinding deltas for native\nmodules and creates interpreter handlers for each memory mapping that belongs to\na supported language interpreter.\n\nDuring trace conversion the process manager is further responsible for routing\nsymbolization requests to the correct interpreter handlers.\n\n#### Interpreter handlers\n\nEach interpreted or JITed language that we support has a corresponding type that\nimplements the interpreter handler interface. It is responsible for:\n\n- detecting the interpreter's version and structure layouts\n- placing information that the corresponding BPF interpreter unwinder needs into BPF maps\n- translating interpreter frames from the BPF format to the user-land format by symbolizing them\n\n#### Stack delta provider\n\nUnwinding the stack of native executables compiled without frame pointers\nrequires stack deltas. These deltas are essentially a mapping from each PC in an\nexecutable to instructions describing how to find the caller and how to adjust\nthe unwinder machine state in preparation of locating the next frame. Typically\nthese instructions consist of a register that is used as a base address and an\noffset (delta) that needs to be added to it -- hence the name. The stack delta\nprovider is responsible for analyzing executables and creating stack deltas for\nthem.\n\nFor most native executables, we rely on the information present in `.eh_frame`.\n`.eh_frame` was originally meant only for C++ exception unwinding, but it has\nsince been repurposed for stack unwinding in general. Even applications written\nin many other native languages like C, Zig or Rust will typically come with\n`.eh_frame`.\n\nOne important exception to this general pattern is Go. As of writing, Go\nexecutables do not come with `.eh_frame` sections unless they are built with CGo\nenabled. Even with CGo the `.eh_frame` section will only contain information for\na small subset of functions that are either written in C/C++ or part of the CGo\nruntime. For Go executables we extract the stack delta information from the\nGo-specific section called `.gopclntab`. In-depth documentation on the format is\navailable in [a separate document](doc/gopclntab.md)).\n\n### BPF components\n\nThe BPF portion of the host agent implements the actual stack unwinding. It uses\nthe eBPF virtual machine to execute our code directly in the Linux kernel. The\ncomponents are implemented in BPF C and live in the\n[`opentelemetry-ebpf-profiler/support/ebpf`](./support/ebpf) directory.\n\n#### Limitations\n\nBPF programs must adhere to various restrictions imposed by the verifier. Many\nof these limitations are significantly relaxed in newer kernel versions, but we\nstill have to stick to the old limits because we wish to continue supporting\nolder kernels.\n\nThe minimum supported Linux kernel versions are\n- 4.19 for amd64/x86_64\n- 5.5 for arm64/aarch64\n\nThe most notable limitations are the following two:\n\n- **4096 instructions per program**\\\n  A single BPF program can consist of a maximum of 4096 instructions, otherwise\n  older kernels will refuse to load it. Since BPF does not allow for loops, they\n  instead need to be unrolled.\n- **32 tail-calls**\\\n  Linux allows BPF programs to do a tail-call to another BPF program. A tail\n  call is essentially a `jmp` into another BPF program, ending execution of the\n  current handler and starting a new one. This allows us to circumvent the 4096\n  instruction limit a bit by doing a tail-call before we run into the limit.\n  There's a maximum of 32 tail calls that a BPF program can do.\n\nThese limitations mean that we generally try to prepare as much work as possible\nin user-land and then only do the minimal work necessary within BPF. We can only\nuse $O(\\log{n})$ algorithms at worst and try to stick with $O(1)$ for most things.\nAll processing that cannot be implemented like this must be delegated to\nuser-land. As a general rule of thumb, anything that needs more than 32\niterations in a loop is out of the question for BPF.\n\n#### Unwinders\n\nUnwinding always begins in [`native_tracer_entry`]. This entry point for our\ntracer starts by reading the register state of the thread that we just\ninterrupted and initializes the [`PerCPURecord`] structure. The per-CPU record\npersists data between tail-calls of the same unwinder invocation. The unwinder's\ncurrent `PC`, `SP` etc. values are initialized from register values.\n\nAfter the initial setup the entry point consults a BPF map that is maintained\nby the user-land portion of the agent to determine which interpreter unwinder\nis responsible for unwinding the code at `PC`. If a record for the memory\nregion is found, we then tail-call to the corresponding interpreter unwinder.\n\nEach interpreter unwinder has their own BPF program. The interpreter unwinders\ntypically have an unrolled main loop where they try to unwind as many frames for\nthat interpreter as they can without going over the instruction limit. After\neach iteration the unwinders will typically check whether the current PC value\nstill belongs to the current unwinder and tail-call to the right unwinder\notherwise.\n\nWhen an unwinder detects that we've reached the last frame in the trace,\nunwinding is terminated with a tail call to [`unwind_stop`]. For most traces\nthis call will happen in the native unwinder, since even JITed languages\nusually call through a few layers of native C/C++ code before entering the VM.\nWe detect the end of a trace by heuristically marking certain functions with\n`PROG_UNWIND_STOP` in the BPF maps prepared by user-land. `unwind_stop` then\nsends the completed BPF trace to user-land.\n\nIf any frame in the trace requires symbolization in user-mode, we additionally\nsend a BPF event to request an expedited read from user-land. For all other\ntraces user-land will simply read and then clear this map on a timer.\n\n[`native_tracer_entry`]: https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/native_stack_trace.ebpf.c#L875\n[`PerCPURecord`]: https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/types.h#L576\n[`unwind_stop`]: https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/interpreter_dispatcher.ebpf.c#L125\n\n#### PID events\n\nThe BPF components are responsible for notifying user-land about new and exiting\nprocesses. An event about a new process is produced when we first interrupt it\nwith the unwinders. Events about exiting processes are created with a\n`sched_process_exit` probe. In both cases the BPF code sends a perf event to\nnotify user-land. We also re-report a PID if we detect execution in previously\nunknown memory region to prompt re-scan of the mappings.\n\n### Network protocol\n\nAll collected information is reported to a backend collector via a push-based,\nstateless, one-way gRPC [protocol](https://github.com/open-telemetry/opentelemetry-proto/pull/534).\n\nAll data to be transmitted is stored in bounded FIFO queues (ring buffers). Old\ndata is overwritten when the queues fill up (e.g. due to a lagging or offline\nbackend collector). There is no explicit reliability or redundancy (besides\nretries internal to gRPC) and the assumption is that data will be resent\n(eventually consistent).\n\n### Trace processing pipeline\n\nThe host agent contains an internal pipeline that incrementally processes the\nraw traces that are produced by the BPF unwinders, enriches them with additional\ninformation (e.g. symbols for interpreter frames and container info), deduplicates\nknown traces and combines trace counts that occurred in the same update period.\n\nThe traces produced in BPF start out with the information shown in the following\ndiagram.\n\n<details>\n<summary>Note: please read this if you wish to update the diagrams</summary>\n\nThe diagrams in this section were created via draw.io. The SVGs can be loaded\ninto draw.io for editing. When you're done, make sure to export via\n<kbd>File</kbd> -> <kbd>Export As</kbd> -> <kbd>SVG</kbd> and then select\na zoom level of 200%. If you simply save the diagram via <kbd>CTRL+S</kbd>,\nit won't fill the whole width of the documentation page. Also make sure that\n\"Include a copy of my diagram\" remains ticked to keep the diagram editable.\n\n</details>\n\n![bpf-trace-diagram](doc/bpf-trace.drawio.svg)\n\nOur backend collector expects to receive trace information in a normalized and\nenriched format. This diagram below is relatively close to the data-structures\nthat are actually sent over the network, minus the batching and domain-specific\ndeduplication that we apply prior to sending it out.\n\n![net-trace-diagram](doc/network-trace.drawio.svg)\n\nThe diagram below provides a detailed overview on how the various components of\nthe host agent interact to transform raw traces into the network format. It\nis focused around our data structures and how data flows through them. Dotted\nlines represent indirect interaction with data structures, solid ones correspond\nto code flow. \"UM\" is short for \"user mode\".\n\n![trace-pipe-diagram](doc/trace-pipe.drawio.svg)\n\n### Testing strategy\n\nThe host agent code is tested with three test suites:\n\n- **Go unit tests**\\\n  Functionality of individual functions and types is tested with regular Go unit\n  tests. This works great for the user-land portion of the agent, but is unable\n  to test any of the unwinding logic and BPF interaction.\n- **coredump test suite**\\\n  The coredump test suite (`utils/coredump`) we compile the whole BPF unwinder\n  code into a user-mode executable, then use the information from a coredump to\n  simulate a realistic environment to test the unwinder code in. The coredump\n  suite essentially implements all required BPF helper functions in user-space,\n  reading memory and thread contexts from the coredump. The resulting traces are\n  then compared to a frame list in a JSON file, serving as regression tests.\n- **BPF integration tests**\\\n  A special build of the host agent with the `integration` tag is created that\n  enables specialized test cases that actually load BPF tracers into the kernel.\n  These test cases require root privileges and thus cannot be part of the\n  regular unit test suite. The test cases focus on covering the interaction and\n  communication of BPF with user-mode code, as well as testing that our BPF code\n  passes the BPF verifier. Our CI builds the integration test executable once and\n  then executes it on a wide range of different Linux kernel versions via qemu.\n\n### Probabilistic profiling\n\nProbabilistic profiling allows you to reduce storage costs by collecting a representative\nsample of profiling data. This method decreases storage costs with a visibility trade-off,\nas not all Profiling Host Agents will have profile collection enabled at all times.\n\nProfiling Events linearly correlate with the probabilistic profiling value. The lower the value,\nthe fewer events are collected.\n\n#### Configure probabilistic profiling\n\nTo configure probabilistic profiling, set the `-probabilistic-threshold` and `-probabilistic-interval` options.\n\nSet the `-probabilistic-threshold` option to a unsigned integer between 1 and 99 to enable\n probabilistic profiling. At every probabilistic interval, a random number between 0 and 99 is chosen.\n If the probabilistic threshold that you've set is greater than this random number, the agent collects\n profiles from this system for the duration of the interval. The default value is 100.\n\nSet the `-probabilistic-interval` option to a time duration to define the time interval for which\nprobabilistic profiling is either enabled or disabled. The default value is 1 minute.\n\n#### Example\n\nThe following example shows how to configure the profiling agent with a threshold of 50 and an interval of 2 minutes and 30 seconds:\n```bash\nsudo ./ebpf-profiler -probabilistic-threshold=50 -probabilistic-interval=2m30s\n```\n\n# Legal\n\n## Licensing Information\n\nThis project is licensed under the Apache License 2.0 (Apache-2.0).\n[Apache License 2.0](LICENSE)\n\nThe eBPF source code is licensed under the GPL 2.0 license.\n[GPL 2.0](support/ebpf/LICENSE)\n\n## Licenses of dependencies\n\nTo display a summary of the dependencies' licenses:\n```sh\nmake legal\n```\n"
        },
        {
          "name": "armhelpers",
          "type": "tree",
          "content": null
        },
        {
          "name": "cli_flags.go",
          "type": "blob",
          "size": 5.2373046875,
          "content": "// Copyright The OpenTelemetry Authors\n// SPDX-License-Identifier: Apache-2.0\n\npackage main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/peterbourgon/ff/v3\"\n\n\t\"go.opentelemetry.io/ebpf-profiler/internal/controller\"\n\t\"go.opentelemetry.io/ebpf-profiler/tracer\"\n)\n\nconst (\n\t// Default values for CLI flags\n\tdefaultArgSamplesPerSecond    = 20\n\tdefaultArgReporterInterval    = 5.0 * time.Second\n\tdefaultArgMonitorInterval     = 5.0 * time.Second\n\tdefaultClockSyncInterval      = 3 * time.Minute\n\tdefaultProbabilisticThreshold = tracer.ProbabilisticThresholdMax\n\tdefaultProbabilisticInterval  = 1 * time.Minute\n\tdefaultArgSendErrorFrames     = false\n\n\t// This is the X in 2^(n + x) where n is the default hardcoded map size value\n\tdefaultArgMapScaleFactor = 0\n)\n\n// Help strings for command line arguments\nvar (\n\tnoKernelVersionCheckHelp = \"Disable checking kernel version for eBPF support. \" +\n\t\t\"Use at your own risk, to run the agent on older kernels with backported eBPF features.\"\n\tcopyrightHelp      = \"Show copyright and short license text.\"\n\tcollAgentAddrHelp  = \"The collection agent address in the format of host:port.\"\n\tverboseModeHelp    = \"Enable verbose logging and debugging capabilities.\"\n\ttracersHelp        = \"Comma-separated list of interpreter tracers to include.\"\n\tmapScaleFactorHelp = fmt.Sprintf(\"Scaling factor for eBPF map sizes. \"+\n\t\t\"Every increase by 1 doubles the map size. Increase if you see eBPF map size errors. \"+\n\t\t\"Default is %d corresponding to 4GB of executable address space, max is %d.\",\n\t\tdefaultArgMapScaleFactor, controller.MaxArgMapScaleFactor)\n\tdisableTLSHelp             = \"Disable encryption for data in transit.\"\n\tbpfVerifierLogLevelHelp    = \"Log level of the eBPF verifier output (0,1,2). Default is 0.\"\n\tversionHelp                = \"Show version.\"\n\tprobabilisticThresholdHelp = fmt.Sprintf(\"If set to a value between 1 and %d will enable \"+\n\t\t\"probabilistic profiling: \"+\n\t\t\"every probabilistic-interval a random number between 0 and %d is \"+\n\t\t\"chosen. If the given probabilistic-threshold is greater than this \"+\n\t\t\"random number, the agent will collect profiles from this system for \"+\n\t\t\"the duration of the interval.\",\n\t\ttracer.ProbabilisticThresholdMax-1, tracer.ProbabilisticThresholdMax-1)\n\tprobabilisticIntervalHelp = \"Time interval for which probabilistic profiling will be \" +\n\t\t\"enabled or disabled.\"\n\tpprofHelp             = \"Listening address (e.g. localhost:6060) to serve pprof information.\"\n\tsamplesPerSecondHelp  = \"Set the frequency (in Hz) of stack trace sampling.\"\n\treporterIntervalHelp  = \"Set the reporter's interval in seconds.\"\n\tmonitorIntervalHelp   = \"Set the monitor interval in seconds.\"\n\tclockSyncIntervalHelp = \"Set the sync interval with the realtime clock. \" +\n\t\t\"If zero, monotonic-realtime clock sync will be performed once, \" +\n\t\t\"on agent startup, but not periodically.\"\n\tsendErrorFramesHelp = \"Send error frames (devfiler only, breaks Kibana)\"\n)\n\n// Package-scope variable, so that conditionally compiled other components can refer\n// to the same flagset.\n\nfunc parseArgs() (*controller.Config, error) {\n\tvar args controller.Config\n\n\tfs := flag.NewFlagSet(\"ebpf-profiler\", flag.ExitOnError)\n\n\t// Please keep the parameters ordered alphabetically in the source-code.\n\tfs.UintVar(&args.BpfVerifierLogLevel, \"bpf-log-level\", 0, bpfVerifierLogLevelHelp)\n\n\tfs.StringVar(&args.CollAgentAddr, \"collection-agent\", \"\", collAgentAddrHelp)\n\tfs.BoolVar(&args.Copyright, \"copyright\", false, copyrightHelp)\n\n\tfs.BoolVar(&args.DisableTLS, \"disable-tls\", false, disableTLSHelp)\n\n\tfs.UintVar(&args.MapScaleFactor, \"map-scale-factor\",\n\t\tdefaultArgMapScaleFactor, mapScaleFactorHelp)\n\n\tfs.DurationVar(&args.MonitorInterval, \"monitor-interval\", defaultArgMonitorInterval,\n\t\tmonitorIntervalHelp)\n\n\tfs.DurationVar(&args.ClockSyncInterval, \"clock-sync-interval\", defaultClockSyncInterval,\n\t\tclockSyncIntervalHelp)\n\n\tfs.BoolVar(&args.NoKernelVersionCheck, \"no-kernel-version-check\", false,\n\t\tnoKernelVersionCheckHelp)\n\n\tfs.StringVar(&args.PprofAddr, \"pprof\", \"\", pprofHelp)\n\n\tfs.DurationVar(&args.ProbabilisticInterval, \"probabilistic-interval\",\n\t\tdefaultProbabilisticInterval, probabilisticIntervalHelp)\n\tfs.UintVar(&args.ProbabilisticThreshold, \"probabilistic-threshold\",\n\t\tdefaultProbabilisticThreshold, probabilisticThresholdHelp)\n\n\tfs.DurationVar(&args.ReporterInterval, \"reporter-interval\", defaultArgReporterInterval,\n\t\treporterIntervalHelp)\n\n\tfs.IntVar(&args.SamplesPerSecond, \"samples-per-second\", defaultArgSamplesPerSecond,\n\t\tsamplesPerSecondHelp)\n\n\tfs.BoolVar(&args.SendErrorFrames, \"send-error-frames\", defaultArgSendErrorFrames,\n\t\tsendErrorFramesHelp)\n\n\tfs.StringVar(&args.Tracers, \"t\", \"all\", \"Shorthand for -tracers.\")\n\tfs.StringVar(&args.Tracers, \"tracers\", \"all\", tracersHelp)\n\n\tfs.BoolVar(&args.VerboseMode, \"v\", false, \"Shorthand for -verbose.\")\n\tfs.BoolVar(&args.VerboseMode, \"verbose\", false, verboseModeHelp)\n\tfs.BoolVar(&args.Version, \"version\", false, versionHelp)\n\n\tfs.Usage = func() {\n\t\tfs.PrintDefaults()\n\t}\n\n\targs.Fs = fs\n\n\treturn &args, ff.Parse(fs, os.Args[1:],\n\t\tff.WithEnvVarPrefix(\"OTEL_PROFILING_AGENT\"),\n\t\tff.WithConfigFileFlag(\"config\"),\n\t\tff.WithConfigFileParser(ff.PlainParser),\n\t\t// This will ignore configuration file (only) options that the current HA\n\t\t// does not recognize.\n\t\tff.WithIgnoreUndefined(true),\n\t\tff.WithAllowMissingConfigFile(true),\n\t)\n}\n"
        },
        {
          "name": "collector",
          "type": "tree",
          "content": null
        },
        {
          "name": "design-docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 3.9716796875,
          "content": "module go.opentelemetry.io/ebpf-profiler\n\ngo 1.22.2\n\nrequire (\n\tgithub.com/aws/aws-sdk-go-v2 v1.30.5\n\tgithub.com/aws/aws-sdk-go-v2/config v1.27.35\n\tgithub.com/aws/aws-sdk-go-v2/service/s3 v1.62.0\n\tgithub.com/cespare/xxhash/v2 v2.3.0\n\tgithub.com/cilium/ebpf v0.16.0\n\tgithub.com/elastic/go-freelru v0.16.0\n\tgithub.com/elastic/go-perf v0.0.0-20241016160959-1342461adb4a\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/jsimonetti/rtnetlink v1.4.2\n\tgithub.com/klauspost/compress v1.17.9\n\tgithub.com/minio/sha256-simd v1.0.1\n\tgithub.com/peterbourgon/ff/v3 v3.4.0\n\tgithub.com/sirupsen/logrus v1.9.3\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/tklauser/numcpus v0.8.0\n\tgithub.com/zeebo/xxh3 v1.0.2\n\tgo.opentelemetry.io/collector/component v0.116.0\n\tgo.opentelemetry.io/collector/consumer/consumerprofiles v0.116.0\n\tgo.opentelemetry.io/collector/consumer/consumertest v0.116.0\n\tgo.opentelemetry.io/collector/pdata v1.22.0\n\tgo.opentelemetry.io/collector/pdata/pprofile v0.116.0\n\tgo.opentelemetry.io/collector/receiver v0.116.0\n\tgo.opentelemetry.io/collector/receiver/receiverprofiles v0.116.0\n\tgo.opentelemetry.io/collector/receiver/receivertest v0.116.0\n\tgo.opentelemetry.io/otel v1.32.0\n\tgolang.org/x/arch v0.10.0\n\tgolang.org/x/exp v0.0.0-20240909161429-701f63a606c0\n\tgolang.org/x/sync v0.10.0\n\tgolang.org/x/sys v0.29.0\n\tgoogle.golang.org/grpc v1.69.2\n)\n\nrequire (\n\tgithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.6.4 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/credentials v1.17.33 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.13 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/configsources v1.3.17 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.17 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/ini v1.8.1 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/v4a v1.3.17 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.4 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/checksum v1.3.19 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.19 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.17.17 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/sso v1.22.8 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/ssooidc v1.26.8 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/sts v1.30.8 // indirect\n\tgithub.com/aws/smithy-go v1.20.4 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/go-logr/logr v1.4.2 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/google/go-cmp v0.6.0 // indirect\n\tgithub.com/josharian/native v1.1.0 // indirect\n\tgithub.com/json-iterator/go v1.1.12 // indirect\n\tgithub.com/klauspost/cpuid/v2 v2.2.8 // indirect\n\tgithub.com/mdlayher/netlink v1.7.2 // indirect\n\tgithub.com/mdlayher/socket v0.4.1 // indirect\n\tgithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect\n\tgithub.com/modern-go/reflect2 v1.0.2 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgo.opentelemetry.io/collector/component/componenttest v0.116.0 // indirect\n\tgo.opentelemetry.io/collector/config/configtelemetry v0.116.0 // indirect\n\tgo.opentelemetry.io/collector/consumer v1.22.0 // indirect\n\tgo.opentelemetry.io/collector/consumer/consumererror v0.116.0 // indirect\n\tgo.opentelemetry.io/collector/consumer/xconsumer v0.116.0 // indirect\n\tgo.opentelemetry.io/collector/pipeline v0.116.0 // indirect\n\tgo.opentelemetry.io/collector/receiver/xreceiver v0.116.0 // indirect\n\tgo.opentelemetry.io/otel/metric v1.32.0 // indirect\n\tgo.opentelemetry.io/otel/sdk v1.32.0 // indirect\n\tgo.opentelemetry.io/otel/sdk/metric v1.32.0 // indirect\n\tgo.opentelemetry.io/otel/trace v1.32.0 // indirect\n\tgo.uber.org/multierr v1.11.0 // indirect\n\tgo.uber.org/zap v1.27.0 // indirect\n\tgolang.org/x/net v0.33.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20250102185135-69823020774d // indirect\n\tgoogle.golang.org/protobuf v1.36.1 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 19.849609375,
          "content": "github.com/aws/aws-sdk-go-v2 v1.30.5 h1:mWSRTwQAb0aLE17dSzztCVJWI9+cRMgqebndjwDyK0g=\ngithub.com/aws/aws-sdk-go-v2 v1.30.5/go.mod h1:CT+ZPWXbYrci8chcARI3OmI/qgd+f6WtuLOoaIA8PR0=\ngithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.6.4 h1:70PVAiL15/aBMh5LThwgXdSQorVr91L127ttckI9QQU=\ngithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.6.4/go.mod h1:/MQxMqci8tlqDH+pjmoLu1i0tbWCUP1hhyMRuFxpQCw=\ngithub.com/aws/aws-sdk-go-v2/config v1.27.35 h1:jeFgiWYNV0vrgdZqB4kZBjYNdy0IKkwrAjr2fwpHIig=\ngithub.com/aws/aws-sdk-go-v2/config v1.27.35/go.mod h1:qnpEvTq8ZfjrCqmJGRfWZuF+lGZ/vG8LK2K0L/TY1gQ=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.17.33 h1:lBHAQQznENv0gLHAZ73ONiTSkCtr8q3pSqWrpbBBZz0=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.17.33/go.mod h1:MBuqCUOT3ChfLuxNDGyra67eskx7ge9e3YKYBce7wpI=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.13 h1:pfQ2sqNpMVK6xz2RbqLEL0GH87JOwSxPV2rzm8Zsb74=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.13/go.mod h1:NG7RXPUlqfsCLLFfi0+IpKN4sCB9D9fw/qTaSB+xRoU=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.3.17 h1:pI7Bzt0BJtYA0N/JEC6B8fJ4RBrEMi1LBrkMdFYNSnQ=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.3.17/go.mod h1:Dh5zzJYMtxfIjYW+/evjQ8uj2OyR/ve2KROHGHlSFqE=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.17 h1:Mqr/V5gvrhA2gvgnF42Zh5iMiQNcOYthFYwCyrnuWlc=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.17/go.mod h1:aLJpZlCmjE+V+KtN1q1uyZkfnUWpQGpbsn89XPKyzfU=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.8.1 h1:VaRN3TlFdd6KxX1x3ILT5ynH6HvKgqdiXoTxAF4HQcQ=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.8.1/go.mod h1:FbtygfRFze9usAadmnGJNc8KsP346kEe+y2/oyhGAGc=\ngithub.com/aws/aws-sdk-go-v2/internal/v4a v1.3.17 h1:Roo69qTpfu8OlJ2Tb7pAYVuF0CpuUMB0IYWwYP/4DZM=\ngithub.com/aws/aws-sdk-go-v2/internal/v4a v1.3.17/go.mod h1:NcWPxQzGM1USQggaTVwz6VpqMZPX1CvDJLDh6jnOCa4=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.4 h1:KypMCbLPPHEmf9DgMGw51jMj77VfGPAN2Kv4cfhlfgI=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.4/go.mod h1:Vz1JQXliGcQktFTN/LN6uGppAIRoLBR2bMvIMP0gOjc=\ngithub.com/aws/aws-sdk-go-v2/service/internal/checksum v1.3.19 h1:FLMkfEiRjhgeDTCjjLoc3URo/TBkgeQbocA78lfkzSI=\ngithub.com/aws/aws-sdk-go-v2/service/internal/checksum v1.3.19/go.mod h1:Vx+GucNSsdhaxs3aZIKfSUjKVGsxN25nX2SRcdhuw08=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.19 h1:rfprUlsdzgl7ZL2KlXiUAoJnI/VxfHCvDFr2QDFj6u4=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.19/go.mod h1:SCWkEdRq8/7EK60NcvvQ6NXKuTcchAD4ROAsC37VEZE=\ngithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.17.17 h1:u+EfGmksnJc/x5tq3A+OD7LrMbSSR/5TrKLvkdy/fhY=\ngithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.17.17/go.mod h1:VaMx6302JHax2vHJWgRo+5n9zvbacs3bLU/23DNQrTY=\ngithub.com/aws/aws-sdk-go-v2/service/s3 v1.62.0 h1:rd/aA3iDq1q7YsL5sc4dEwChutH7OZF9Ihfst6pXQzI=\ngithub.com/aws/aws-sdk-go-v2/service/s3 v1.62.0/go.mod h1:5FmD/Dqq57gP+XwaUnd5WFPipAuzrf0HmupX27Gvjvc=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.22.8 h1:JRwuL+S1Qe1owZQoxblV7ORgRf2o0SrtzDVIbaVCdQ0=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.22.8/go.mod h1:eEygMHnTKH/3kNp9Jr1n3PdejuSNcgwLe1dWgQtO0VQ=\ngithub.com/aws/aws-sdk-go-v2/service/ssooidc v1.26.8 h1:+HpGETD9463PFSj7lX5+eq7aLDs85QUIA+NBkeAsscA=\ngithub.com/aws/aws-sdk-go-v2/service/ssooidc v1.26.8/go.mod h1:bCbAxKDqNvkHxRaIMnyVPXPo+OaPRwvmgzMxbz1VKSA=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.30.8 h1:bAi+4p5EKnni+jrfcAhb7iHFQ24bthOAV9t0taf3DCE=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.30.8/go.mod h1:NXi1dIAGteSaRLqYgarlhP/Ij0cFT+qmCwiJqWh/U5o=\ngithub.com/aws/smithy-go v1.20.4 h1:2HK1zBdPgRbjFOHlfeQZfpC4r72MOb9bZkiFwggKO+4=\ngithub.com/aws/smithy-go v1.20.4/go.mod h1:irrKGvNn1InZwb2d7fkIRNucdfwR8R+Ts3wxYa/cJHg=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cilium/ebpf v0.16.0 h1:+BiEnHL6Z7lXnlGUsXQPPAE7+kenAd4ES8MQ5min0Ok=\ngithub.com/cilium/ebpf v0.16.0/go.mod h1:L7u2Blt2jMM/vLAVgjxluxtBKlz3/GWjB0dMOEngfwE=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/elastic/go-freelru v0.16.0 h1:gG2HJ1WXN2tNl5/p40JS/l59HjvjRhjyAa+oFTRArYs=\ngithub.com/elastic/go-freelru v0.16.0/go.mod h1:bSdWT4M0lW79K8QbX6XY2heQYSCqD7THoYf82pT/H3I=\ngithub.com/elastic/go-perf v0.0.0-20241016160959-1342461adb4a h1:ymmtaN4bVCmKKeu4XEf6JEWNZKRXPMng1zjpKd+8rCU=\ngithub.com/elastic/go-perf v0.0.0-20241016160959-1342461adb4a/go.mod h1:Nt+pnRYvf0POC+7pXsrv8ubsEOSsaipJP0zlz1Ms1RM=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.4.2 h1:6pFjapn8bFcIbiKo3XT4j/BhANplGihG6tvd+8rYgrY=\ngithub.com/go-logr/logr v1.4.2/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-quicktest/qt v1.101.0 h1:O1K29Txy5P2OK0dGo59b7b0LR6wKfIhttaAhHUyn7eI=\ngithub.com/go-quicktest/qt v1.101.0/go.mod h1:14Bz/f7NwaXPtdYEgzsx46kqSxVwTbzVZsDC26tQJow=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/josharian/native v1.1.0 h1:uuaP0hAbW7Y4l0ZRQ6C9zfb7Mg1mbFKry/xzDAfmtLA=\ngithub.com/josharian/native v1.1.0/go.mod h1:7X/raswPFr05uY3HiLlYeyQntB6OO7E/d2Cu7qoaN2w=\ngithub.com/jsimonetti/rtnetlink v1.4.2 h1:Df9w9TZ3npHTyDn0Ev9e1uzmN2odmXd0QX+J5GTEn90=\ngithub.com/jsimonetti/rtnetlink v1.4.2/go.mod h1:92s6LJdE+1iOrw+F2/RO7LYI2Qd8pPpFNNUYW06gcoM=\ngithub.com/jsimonetti/rtnetlink/v2 v2.0.1 h1:xda7qaHDSVOsADNouv7ukSuicKZO7GgVUCXxpaIEIlM=\ngithub.com/jsimonetti/rtnetlink/v2 v2.0.1/go.mod h1:7MoNYNbb3UaDHtF8udiJo/RH6VsTKP1pqKLUTVCvToE=\ngithub.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=\ngithub.com/klauspost/compress v1.17.9/go.mod h1:Di0epgTjJY877eYKx5yC51cX2A2Vl2ibi7bDH9ttBbw=\ngithub.com/klauspost/cpuid/v2 v2.2.8 h1:+StwCXwm9PdpiEkPyzBXIy+M9KUb4ODm0Zarf1kS5BM=\ngithub.com/klauspost/cpuid/v2 v2.2.8/go.mod h1:Lcz8mBdAVJIBVzewtcLocK12l3Y+JytZYpaMropDUws=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/mdlayher/netlink v1.7.2 h1:/UtM3ofJap7Vl4QWCPDGXY8d3GIY2UGSDbK+QWmY8/g=\ngithub.com/mdlayher/netlink v1.7.2/go.mod h1:xraEF7uJbxLhc5fpHL4cPe221LI2bdttWlU+ZGLfQSw=\ngithub.com/mdlayher/socket v0.4.1 h1:eM9y2/jlbs1M615oshPQOHZzj6R6wMT7bX5NPiQvn2U=\ngithub.com/mdlayher/socket v0.4.1/go.mod h1:cAqeGjoufqdxWkD7DkpyS+wcefOtmu5OQ8KuoJGIReA=\ngithub.com/minio/sha256-simd v1.0.1 h1:6kaan5IFmwTNynnKKpDHe6FWHohJOHhCPchzK49dzMM=\ngithub.com/minio/sha256-simd v1.0.1/go.mod h1:Pz6AKMiUdngCLpeTL/RJY1M9rUuPMYujV5xJjtbRSN8=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/peterbourgon/ff/v3 v3.4.0 h1:QBvM/rizZM1cB0p0lGMdmR7HxZeI/ZrBWB4DqLkMUBc=\ngithub.com/peterbourgon/ff/v3 v3.4.0/go.mod h1:zjJVUhx+twciwfDl0zBcFzl4dW8axCRyXE/eKY9RztQ=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/rogpeppe/go-internal v1.11.0 h1:cWPaGQEPrBb5/AsnsZesgZZ9yb1OQ+GOISoDNXVBh4M=\ngithub.com/rogpeppe/go-internal v1.11.0/go.mod h1:ddIwULY96R17DhadqLgMfk9H9tvdUzkipdSkR5nkCZA=\ngithub.com/sirupsen/logrus v1.9.3 h1:dueUQJ1C2q9oE3F7wvmSGAaVtTmUizReu6fjN8uqzbQ=\ngithub.com/sirupsen/logrus v1.9.3/go.mod h1:naHLuLoDiP4jHNo9R0sCBMtWGeIprob74mVsIT4qYEQ=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/tklauser/numcpus v0.8.0 h1:Mx4Wwe/FjZLeQsK/6kt2EOepwwSl7SmJrK5bV/dXYgY=\ngithub.com/tklauser/numcpus v0.8.0/go.mod h1:ZJZlAY+dmR4eut8epnzf0u/VwodKmryxR8txiloSqBE=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/zeebo/assert v1.3.0 h1:g7C04CbJuIDKNPFHmsk4hwZDO5O+kntRxzaUoNXj+IQ=\ngithub.com/zeebo/assert v1.3.0/go.mod h1:Pq9JiuJQpG8JLJdtkwrJESF0Foym2/D9XMU5ciN/wJ0=\ngithub.com/zeebo/xxh3 v1.0.2 h1:xZmwmqxHZA8AI603jOQ0tMqmBr9lPeFwGg6d+xy9DC0=\ngithub.com/zeebo/xxh3 v1.0.2/go.mod h1:5NWz9Sef7zIDm2JHfFlcQvNekmcEl9ekUZQQKCYaDcA=\ngo.opentelemetry.io/collector/component v0.116.0 h1:SQE1YeVfYCN7bw1n4hknUwJE5U/1qJL552sDhAdSlaA=\ngo.opentelemetry.io/collector/component v0.116.0/go.mod h1:MYgXFZWDTq0uPgF1mkLSFibtpNqksRVAOrmihckOQEs=\ngo.opentelemetry.io/collector/component/componenttest v0.116.0 h1:UIcnx4Rrs/oDRYSAZNHRMUiYs2FBlwgV5Nc0oMYfR6A=\ngo.opentelemetry.io/collector/component/componenttest v0.116.0/go.mod h1:W40HaKPHdBFMVI7zzHE7dhdWC+CgAnAC9SmWetFBATY=\ngo.opentelemetry.io/collector/config/configtelemetry v0.116.0 h1:Vl49VCHQwBOeMswDpFwcl2HD8e9y94xlrfII3SR2VeQ=\ngo.opentelemetry.io/collector/config/configtelemetry v0.116.0/go.mod h1:SlBEwQg0qly75rXZ6W1Ig8jN25KBVBkFIIAUI1GiAAE=\ngo.opentelemetry.io/collector/consumer v1.22.0 h1:QmfnNizyNZFt0uK3GG/EoT5h6PvZJ0dgVTc5hFEc1l0=\ngo.opentelemetry.io/collector/consumer v1.22.0/go.mod h1:tiz2khNceFAPokxxfzAuFfIpShBasMT2AL2Sbc7+m0I=\ngo.opentelemetry.io/collector/consumer/consumererror v0.116.0 h1:GRPnuvwxUeHKVTRzy35di8OFlxypY4YWrK+1nWMsExM=\ngo.opentelemetry.io/collector/consumer/consumererror v0.116.0/go.mod h1:OvQvQ2V7sHT4Vz+1/4mwdEajWZNoFUsY1NhOM8rGvXo=\ngo.opentelemetry.io/collector/consumer/consumerprofiles v0.116.0 h1:3UR2wcmFd19ip7aW9r3KljCyRBWhFOpdWCYSL5xQXeE=\ngo.opentelemetry.io/collector/consumer/consumerprofiles v0.116.0/go.mod h1:g34L7TyznLMrZqiCYsv9Q/c462rgcoYGt7JNxubZfN8=\ngo.opentelemetry.io/collector/consumer/consumertest v0.116.0 h1:pIVR7FtQMNAzfxBUSMEIC2dX5Lfo3O9ZBfx+sAwrrrM=\ngo.opentelemetry.io/collector/consumer/consumertest v0.116.0/go.mod h1:cV3cNDiPnls5JdhnOJJFVlclrClg9kPs04cXgYP9Gmk=\ngo.opentelemetry.io/collector/consumer/xconsumer v0.116.0 h1:ZrWvq7HumB0jRYmS2ztZ3hhXRNpUVBWPKMbPhsVGmZM=\ngo.opentelemetry.io/collector/consumer/xconsumer v0.116.0/go.mod h1:C+VFMk8vLzPun6XK8aMts6h4RaDjmzXHCPaiOxzRQzQ=\ngo.opentelemetry.io/collector/pdata v1.22.0 h1:3yhjL46NLdTMoP8rkkcE9B0pzjf2973crn0KKhX5UrI=\ngo.opentelemetry.io/collector/pdata v1.22.0/go.mod h1:nLLf6uDg8Kn5g3WNZwGyu8+kf77SwOqQvMTb5AXEbEY=\ngo.opentelemetry.io/collector/pdata/pprofile v0.116.0 h1:iE6lqkO7Hi6lTIIml1RI7yQ55CKqW12R2qHinwF5Zuk=\ngo.opentelemetry.io/collector/pdata/pprofile v0.116.0/go.mod h1:xQiPpjzIiXRFb+1fPxUy/3ygEZgo0Bu/xmLKOWu8vMQ=\ngo.opentelemetry.io/collector/pdata/testdata v0.116.0 h1:zmn1zpeX2BvzL6vt2dBF4OuAyFF2ml/OXcqflNgFiP0=\ngo.opentelemetry.io/collector/pdata/testdata v0.116.0/go.mod h1:ytWzICFN4XTDP6o65B4+Ed52JGdqgk9B8CpLHCeCpMo=\ngo.opentelemetry.io/collector/pipeline v0.116.0 h1:o8eKEuWEszmRpfShy7ElBoQ3Jo6kCi9ucm3yRgdNb9s=\ngo.opentelemetry.io/collector/pipeline v0.116.0/go.mod h1:qE3DmoB05AW0C3lmPvdxZqd/H4po84NPzd5MrqgtL74=\ngo.opentelemetry.io/collector/receiver v0.116.0 h1:voiBluWLwe4lbyLVwxloK6CudqqszWF+bgYKHuxnETU=\ngo.opentelemetry.io/collector/receiver v0.116.0/go.mod h1:zb6m8l+knUuN62ASCDqQPIm9punK8PEX1mFrF/yzMI8=\ngo.opentelemetry.io/collector/receiver/receiverprofiles v0.116.0 h1:lmNBHahbwZ4u0d0gUAsJE2c1N+yh6gXPS7zyBBZQNAM=\ngo.opentelemetry.io/collector/receiver/receiverprofiles v0.116.0/go.mod h1:q6brB4ZEpsB4Nm6SAtZfmuTaKIEAuO5DBFq6S2nNeaw=\ngo.opentelemetry.io/collector/receiver/receivertest v0.116.0 h1:ZF4QVcots0OUiutblkyPR02pc+g7v1QaJSFW8tOzHoQ=\ngo.opentelemetry.io/collector/receiver/receivertest v0.116.0/go.mod h1:7GGvtHhW3o6457/wGtSWXJtCtlW6VGFUZSlf6wboNTw=\ngo.opentelemetry.io/collector/receiver/xreceiver v0.116.0 h1:Kc+ixqgMjU2sHhzNrFn5TttVNiJlJwTLL3sQrM9uH6s=\ngo.opentelemetry.io/collector/receiver/xreceiver v0.116.0/go.mod h1:H2YGSNFoMbWMIDvB8tzkReHSVqvogihjtet+ppHfYv8=\ngo.opentelemetry.io/otel v1.32.0 h1:WnBN+Xjcteh0zdk01SVqV55d/m62NJLJdIyb4y/WO5U=\ngo.opentelemetry.io/otel v1.32.0/go.mod h1:00DCVSB0RQcnzlwyTfqtxSm+DRr9hpYrHjNGiBHVQIg=\ngo.opentelemetry.io/otel/metric v1.32.0 h1:xV2umtmNcThh2/a/aCP+h64Xx5wsj8qqnkYZktzNa0M=\ngo.opentelemetry.io/otel/metric v1.32.0/go.mod h1:jH7CIbbK6SH2V2wE16W05BHCtIDzauciCRLoc/SyMv8=\ngo.opentelemetry.io/otel/sdk v1.32.0 h1:RNxepc9vK59A8XsgZQouW8ue8Gkb4jpWtJm9ge5lEG4=\ngo.opentelemetry.io/otel/sdk v1.32.0/go.mod h1:LqgegDBjKMmb2GC6/PrTnteJG39I8/vJCAP9LlJXEjU=\ngo.opentelemetry.io/otel/sdk/metric v1.32.0 h1:rZvFnvmvawYb0alrYkjraqJq0Z4ZUJAiyYCU9snn1CU=\ngo.opentelemetry.io/otel/sdk/metric v1.32.0/go.mod h1:PWeZlq0zt9YkYAp3gjKZ0eicRYvOh1Gd+X99x6GHpCQ=\ngo.opentelemetry.io/otel/trace v1.32.0 h1:WIC9mYrXf8TmY/EXuULKc8hR17vE+Hjv2cssQDe03fM=\ngo.opentelemetry.io/otel/trace v1.32.0/go.mod h1:+i4rkvCraA+tG6AzwloGaCtkx53Fa+L+V8e9a7YvhT8=\ngo.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=\ngo.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=\ngo.uber.org/multierr v1.11.0 h1:blXXJkSxSSfBVBlC76pxqeO+LN3aDfLQo+309xJstO0=\ngo.uber.org/multierr v1.11.0/go.mod h1:20+QtiLqy0Nd6FdQB9TLXag12DsQkrbs3htMFfDN80Y=\ngo.uber.org/zap v1.27.0 h1:aJMhYGrd5QSmlpLMr2MftRKl7t8J8PTZPA732ud/XR8=\ngo.uber.org/zap v1.27.0/go.mod h1:GB2qFLM7cTU87MWRP2mPIjqfIDnGu+VIO4V/SdhGo2E=\ngolang.org/x/arch v0.10.0 h1:S3huipmSclq3PJMNe76NGwkBR504WFkQ5dhzWzP8ZW8=\ngolang.org/x/arch v0.10.0/go.mod h1:FEVrYAQjsQXMVJ1nsMoVVXPZg6p2JE2mx8psSWTDQys=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/exp v0.0.0-20240909161429-701f63a606c0 h1:e66Fs6Z+fZTbFBAxKfP3PALWBtpfqks2bwGcexMxgtk=\ngolang.org/x/exp v0.0.0-20240909161429-701f63a606c0/go.mod h1:2TbTHSBQa924w8M6Xs1QcRcFwyucIwBGpK1p2f1YFFY=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.33.0 h1:74SYHlV8BIgHIFC/LrYkOGIwL19eTYXQ5wc6TBuO36I=\ngolang.org/x/net v0.33.0/go.mod h1:HXLR5J+9DxmrqMwG9qjGCxZ+zKXxBru04zlTvWlWuN4=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.29.0 h1:TPYlXGxvx1MGTn2GiZDhnjPA9wZzZeGKHHmKhHYvgaU=\ngolang.org/x/sys v0.29.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20250102185135-69823020774d h1:xJJRGY7TJcvIlpSrN3K6LAWgNFUILlO+OMAqtg9aqnw=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20250102185135-69823020774d/go.mod h1:3ENsm/5D1mzDyhpzeRi1NR784I0BcofWBoSc5QqqMK4=\ngoogle.golang.org/grpc v1.69.2 h1:U3S9QEtbXC0bYNvRtcoklF3xGtLViumSYxWykJS+7AU=\ngoogle.golang.org/grpc v1.69.2/go.mod h1:vyjdE6jLBI76dgpDojsFGNaHlxdjXN9ghpnd2o7JGZ4=\ngoogle.golang.org/protobuf v1.36.1 h1:yBPeRvTftaleIgM3PZ/WBIZ7XM/eEYAaEyCwvyjq/gk=\ngoogle.golang.org/protobuf v1.36.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "host",
          "type": "tree",
          "content": null
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "interpreter",
          "type": "tree",
          "content": null
        },
        {
          "name": "legal",
          "type": "tree",
          "content": null
        },
        {
          "name": "libpf",
          "type": "tree",
          "content": null
        },
        {
          "name": "lpm",
          "type": "tree",
          "content": null
        },
        {
          "name": "maccess",
          "type": "tree",
          "content": null
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 4.197265625,
          "content": "// Copyright The OpenTelemetry Authors\n// SPDX-License-Identifier: Apache-2.0\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t//nolint:gosec\n\t_ \"net/http/pprof\"\n\t\"os\"\n\t\"os/signal\"\n\n\t\"golang.org/x/sys/unix\"\n\n\t\"go.opentelemetry.io/ebpf-profiler/internal/controller\"\n\t\"go.opentelemetry.io/ebpf-profiler/internal/helpers\"\n\t\"go.opentelemetry.io/ebpf-profiler/reporter\"\n\t\"go.opentelemetry.io/ebpf-profiler/times\"\n\t\"go.opentelemetry.io/ebpf-profiler/vc\"\n\n\tlog \"github.com/sirupsen/logrus\"\n)\n\n// Short copyright / license text for eBPF code\nvar copyright = `Copyright The OpenTelemetry Authors.\n\nFor the eBPF code loaded by Universal Profiling Agent into the kernel,\nthe following license applies (GPLv2 only). You can obtain a copy of the GPLv2 code at:\nhttps://go.opentelemetry.io/ebpf-profiler/tree/main/support/ebpf\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License version 2 only,\nas published by the Free Software Foundation;\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details:\n\nhttps://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html\n`\n\ntype exitCode int\n\nconst (\n\texitSuccess exitCode = 0\n\texitFailure exitCode = 1\n\n\t// Go 'flag' package calls os.Exit(2) on flag parse errors, if ExitOnError is set\n\texitParseError exitCode = 2\n)\n\nfunc main() {\n\tos.Exit(int(mainWithExitCode()))\n}\n\nfunc mainWithExitCode() exitCode {\n\tcfg, err := parseArgs()\n\tif err != nil {\n\t\tlog.Errorf(\"Failure to parse arguments: %v\", err)\n\t\treturn exitParseError\n\t}\n\n\tif cfg.Copyright {\n\t\tfmt.Print(copyright)\n\t\treturn exitSuccess\n\t}\n\n\tif cfg.Version {\n\t\tfmt.Printf(\"%s\\n\", vc.Version())\n\t\treturn exitSuccess\n\t}\n\n\tif cfg.VerboseMode {\n\t\tlog.SetLevel(log.DebugLevel)\n\t\t// Dump the arguments in debug mode.\n\t\tcfg.Dump()\n\t}\n\n\tif err = cfg.Validate(); err != nil {\n\t\tlog.Error(err)\n\t\treturn exitFailure\n\t}\n\n\t// Context to drive main goroutine and the Tracer monitors.\n\tctx, mainCancel := signal.NotifyContext(context.Background(),\n\t\tunix.SIGINT, unix.SIGTERM, unix.SIGABRT)\n\tdefer mainCancel()\n\n\tif cfg.PprofAddr != \"\" {\n\t\tgo func() {\n\t\t\t//nolint:gosec\n\t\t\tif err = http.ListenAndServe(cfg.PprofAddr, nil); err != nil {\n\t\t\t\tlog.Errorf(\"Serving pprof on %s failed: %s\", cfg.PprofAddr, err)\n\t\t\t}\n\t\t}()\n\t}\n\n\tintervals := times.New(cfg.MonitorInterval,\n\t\tcfg.ReporterInterval, cfg.ProbabilisticInterval)\n\n\tkernelVersion, err := helpers.GetKernelVersion()\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn exitFailure\n\t}\n\n\t// hostname and sourceIP will be populated from the root namespace.\n\thostname, sourceIP, err := helpers.GetHostnameAndSourceIP(cfg.CollAgentAddr)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn exitFailure\n\t}\n\tcfg.HostName, cfg.IPAddress = hostname, sourceIP\n\n\trep, err := reporter.NewOTLP(&reporter.Config{\n\t\tCollAgentAddr:            cfg.CollAgentAddr,\n\t\tDisableTLS:               cfg.DisableTLS,\n\t\tMaxRPCMsgSize:            32 << 20, // 32 MiB\n\t\tMaxGRPCRetries:           5,\n\t\tGRPCOperationTimeout:     intervals.GRPCOperationTimeout(),\n\t\tGRPCStartupBackoffTime:   intervals.GRPCStartupBackoffTime(),\n\t\tGRPCConnectionTimeout:    intervals.GRPCConnectionTimeout(),\n\t\tReportInterval:           intervals.ReportInterval(),\n\t\tExecutablesCacheElements: 16384,\n\t\t// Next step: Calculate FramesCacheElements from numCores and samplingRate.\n\t\tFramesCacheElements: 65536,\n\t\tCGroupCacheElements: 1024,\n\t\tSamplesPerSecond:    cfg.SamplesPerSecond,\n\t\tKernelVersion:       kernelVersion,\n\t\tHostName:            hostname,\n\t\tIPAddress:           sourceIP,\n\t})\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn exitFailure\n\t}\n\tcfg.Reporter = rep\n\n\tlog.Infof(\"Starting OTEL profiling agent %s (revision %s, build timestamp %s)\",\n\t\tvc.Version(), vc.Revision(), vc.BuildTimestamp())\n\n\tctlr := controller.New(cfg)\n\terr = ctlr.Start(ctx)\n\tif err != nil {\n\t\treturn failure(\"Failed to start agent controller: %v\", err)\n\t}\n\tdefer ctlr.Shutdown()\n\n\t// Block waiting for a signal to indicate the program should terminate\n\t<-ctx.Done()\n\n\tlog.Info(\"Exiting ...\")\n\treturn exitSuccess\n}\n\nfunc failure(msg string, args ...interface{}) exitCode {\n\tlog.Errorf(msg, args...)\n\treturn exitFailure\n}\n"
        },
        {
          "name": "metrics",
          "type": "tree",
          "content": null
        },
        {
          "name": "nativeunwind",
          "type": "tree",
          "content": null
        },
        {
          "name": "nopanicslicereader",
          "type": "tree",
          "content": null
        },
        {
          "name": "pacmask",
          "type": "tree",
          "content": null
        },
        {
          "name": "periodiccaller",
          "type": "tree",
          "content": null
        },
        {
          "name": "proc",
          "type": "tree",
          "content": null
        },
        {
          "name": "process",
          "type": "tree",
          "content": null
        },
        {
          "name": "processmanager",
          "type": "tree",
          "content": null
        },
        {
          "name": "remotememory",
          "type": "tree",
          "content": null
        },
        {
          "name": "reporter",
          "type": "tree",
          "content": null
        },
        {
          "name": "rlimit",
          "type": "tree",
          "content": null
        },
        {
          "name": "stringutil",
          "type": "tree",
          "content": null
        },
        {
          "name": "successfailurecounter",
          "type": "tree",
          "content": null
        },
        {
          "name": "support",
          "type": "tree",
          "content": null
        },
        {
          "name": "testsupport",
          "type": "tree",
          "content": null
        },
        {
          "name": "times",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "tpbase",
          "type": "tree",
          "content": null
        },
        {
          "name": "tracehandler",
          "type": "tree",
          "content": null
        },
        {
          "name": "tracer",
          "type": "tree",
          "content": null
        },
        {
          "name": "traceutil",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "vc",
          "type": "tree",
          "content": null
        },
        {
          "name": "zydis",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}