{
  "metadata": {
    "timestamp": 1736709824435,
    "page": 287,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ivmai/bdwgc",
      "stars": 3048,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".appveyor.yml",
          "type": "blob",
          "size": 12.2451171875,
          "content": "version: 8.3.0-{build}\n\nimage:\n- Visual Studio 2022\n\nenvironment:\n  STUDIO_VERSION_EDITION: Studio\\2022\\Community\n  MINGW_FOLDER: mingw-w64\\i686-8.1.0-posix-dwarf-rt_v6-rev0\\mingw32\n  DJGPP_VER: 3.4\n  DJGPP_GCC_VER: 1220\n  DMC_VER: 857\n  WATCOM_VER: 2024-12-02\n  CMAKE_CONFIG: Debug\n  TEST_TARGET: check\n  matrix:\n  - TARGET: cmake\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=Debug -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON -Werror=deprecated -Dwithout_libatomic_ops=ON\n  - TARGET: cmake\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_throw_bad_alloc_library=OFF -Denable_gc_assertions=ON -Denable_gc_debug=ON -Denable_threads=OFF\n  - TARGET: cmake\n    CFLAGS_EXTRA: -DNO_MSGBOX_ON_ERROR -DNO_MPROTECT_VDB -DGC_READ_ENV_FILE\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=Release -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_large_config=ON -Ddisable_gc_debug=ON -Denable_dynamic_pointer_mask=ON -Denable_rwlock=ON\n  - TARGET: cmake\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=MinSizeRel -Denable_parallel_mark=OFF\n  - TARGET: cmake\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_gc_assertions=ON -Denable_thread_local_alloc=OFF -Ddisable_single_obj_compilation=ON\n  - TARGET: cmake\n    CFLAGS_EXTRA: -DGC_DISABLE_INCREMENTAL\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_gc_assertions=ON -Denable_gcj_support=OFF -Denable_parallel_mark=OFF -Denable_thread_local_alloc=OFF -Denable_valgrind_tracking=ON\n  - TARGET: cmake\n    CMAKE_OPTIONS: -A Win32 -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON -Denable_large_config=ON\n  - TARGET: cmake\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -A ARM64 -DCMAKE_BUILD_TYPE=Release -Denable_cplusplus=ON\n  - TARGET: cmake-bcc\n    CFLAGS_EXTRA: -DCONSOLE_LOG\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON\n  - TARGET: cmake-bcc\n    CFLAGS_EXTRA: -DCONSOLE_LOG -DNO_GWW_VDB\n    CMAKE_OPTIONS: -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON -Denable_gc_debug=ON -Denable_large_config=ON -Denable_threads=OFF\n  - TARGET: cmake-bcc\n    CFLAGS_EXTRA: -DCONSOLE_LOG\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON\n  - TARGET: cmake-mingw\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_cplusplus=ON\n  - TARGET: cmake-msys\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=Debug -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON -Dinstall_headers=OFF -Denable_rwlock=ON\n  - TARGET: cmake-msys\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_docs=OFF\n  - TARGET: cmake-msys\n    CMAKE_OPTIONS: -Dbuild_cord=OFF -Dbuild_tests=ON -Denable_atomic_uncollectable=OFF -Denable_disclaim=OFF -Denable_threads=OFF\n  - TARGET: cmake-wcc-nt\n    CFLAGS_EXTRA: -DCONSOLE_LOG\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_threads=OFF\n  - TARGET: cmake-wcc-nt\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=MinSizeRel -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_checksums=ON -Denable_dynamic_loading=OFF -Denable_large_config=ON -Denable_munmap=OFF -Denable_threads=OFF\n  - TARGET: cmake-wcc-nt\n    CFLAGS_EXTRA: -DCONSOLE_LOG -DNO_MSGBOX_ON_ERROR\n    CMAKE_CONFIG: Release\n    CMAKE_OPTIONS: -DBUILD_SHARED_LIBS=OFF -Dbuild_tests=ON -Denable_cplusplus=ON\n  - TARGET: cmake-wcc-nt\n    CFLAGS_EXTRA: -DCONSOLE_LOG -DNO_MSGBOX_ON_ERROR\n    CMAKE_OPTIONS: -DCMAKE_BUILD_TYPE=Debug -Dbuild_tests=ON -Denable_cplusplus=ON -Denable_gc_assertions=ON\n  - TARGET: nmake\n    ARCH: x86\n    NMAKE_OPTIONS: enable_static=1\n  - TARGET: nmake\n    ARCH: x64\n    CFLAGS_EXTRA: /J /wd4391\n  - TARGET: nmake\n    ARCH: x86\n    CFLAGS_EXTRA: -DUSE_GLOBAL_ALLOC\n    NMAKE_OPTIONS: nodebug=1\n  - TARGET: nmake\n    ARCH: x64\n    NMAKE_OPTIONS: disable_threads=1\n  - TARGET: djgpp-no-make\n    CFLAGS_EXTRA: -O3 -DALL_INTERIOR_POINTERS -DNO_EXECUTE_PERMISSION -DENABLE_DISCLAIM -DGC_ATOMIC_UNCOLLECTABLE -DGC_GCJ_SUPPORT\n  - TARGET: dmc\n    CFLAGS_EXTRA: -s -DNO_MSGBOX_ON_ERROR\n  - TARGET: mingw-shared-no-make\n    CFLAGS_EXTRA: -D GC_THREADS -D GC_ASSERTIONS -D ENABLE_DISCLAIM -D GC_GCJ_SUPPORT -D GC_PREFER_MPROTECT_VDB -D GC_CALL=__stdcall -D GC_CALLBACK=__fastcall -D CONSOLE_LOG -D NO_MSGBOX_ON_ERROR -D USE_RWLOCK -D _WIN32_WINNT=0x0600\n  - TARGET: msys64-mingw64\n  - TARGET: msys64-mingw64\n    CFLAGS_EXTRA: -D GC_THREADS -D THREAD_LOCAL_ALLOC -D PARALLEL_MARK -D GC_ASSERTIONS -D EMPTY_GETENV_RESULTS -D GC_GCJ_SUPPORT -D USE_MUNMAP -D LARGE_CONFIG -D NO_MSGBOX_ON_ERROR\n    TEST_TARGET: check cord/de\n  - TARGET: msys64-mingw64\n    CFLAGS_EXTRA: -O3 -march=native -D GC_THREADS -D GC_GCJ_SUPPORT -D GC_TIME_LIMIT=10 -D WINXP_USE_PERF_COUNTER -D NO_MSGBOX_ON_ERROR -D NO_TEST_ENDTHREADEX\n  - TARGET: msys64-mingw64\n    CFLAGS_EXTRA: -D NO_MSGBOX_ON_ERROR\n  - TARGET: msys64-mingw64\n    CFLAGS_EXTRA: -D GC_THREADS -D THREAD_LOCAL_ALLOC -D PARALLEL_MARK -D GC_ASSERTIONS -D GC_GCJ_SUPPORT -D NO_RETRY_GET_THREAD_CONTEXT\n  - TARGET: wcc\n    WCC_SYSTEM: DOS4GW\n    CFLAGS_EXTRA: -DSMALL_CONFIG\n    ENABLE_STATIC_OPT: \"ENABLE_STATIC=1\"\n    TEST_TARGET: check-deps\n  - TARGET: wcc\n    WCC_SYSTEM: OS2\n    CFLAGS_EXTRA: -DGC_ASSERTIONS\n    ENABLE_STATIC_OPT: \"ENABLE_STATIC=1\"\n    TEST_TARGET: check-deps\n    WCC_INC_SUBDIR: os2\n  - TARGET: wcc\n    WCC_SYSTEM: MSWIN32\n    CFLAGS_EXTRA: -DCONSOLE_LOG -DUSE_MMAP -DUSE_MUNMAP -zp1 -DFORCE_ALIGNMENT_ONE\n    WCC_INC_SUBDIR: nt\n  - TARGET: cygwin64\n    CFLAGS_EXTRA: -std=c11 -D USE_WINALLOC -Wno-array-bounds\n    CONF_OPTIONS: --disable-threads\n  - TARGET: cygwin64\n    CFLAGS_EXTRA: -D GCTEST_PRINT_VERBOSE -D DONT_PROTECT_PTRFREE -Wno-array-bounds\n    CONF_OPTIONS: --enable-cplusplus\n  - TARGET: cygwin64\n    CFLAGS_EXTRA: -Wno-array-bounds\n    CONF_OPTIONS: --enable-cplusplus --disable-munmap --enable-gc-assertions --enable-redirect-malloc\n  - TARGET: cygwin64\n    CFLAGS_EXTRA: -D GC_ALWAYS_MULTITHREADED -D LINT2 -D TEST_MANUAL_VDB -Wno-array-bounds\n    CONF_OPTIONS: --enable-cplusplus --enable-gc-assertions --enable-rwlock --disable-shared\n  - TARGET: cygwin64\n    CFLAGS_EXTRA: -Wno-array-bounds\n    CONF_OPTIONS: --enable-cplusplus --enable-gc-debug\n\nclone_depth: 50\n\ninstall:\n- cmd: git clone --depth=50 https://github.com/ivmai/libatomic_ops.git\n\nbuild_script:\n- cmd: if %TARGET%==cmake (\n    mkdir out && cd out\n    && cmake %CMAKE_OPTIONS% -Denable_werror=ON -DCFLAGS_EXTRA=\"%CFLAGS_EXTRA%\" ..\n    && cmake --build . --config %CMAKE_CONFIG% --verbose --parallel )\n- cmd: if %TARGET%==cmake-mingw (\n    set \"path=C:\\Program Files\\CMake\\bin;C:\\%MINGW_FOLDER%\\bin\"\n    && mkdir out && cd out\n    && cmake -G \"MinGW Makefiles\" %CMAKE_OPTIONS% -Denable_werror=ON -DCFLAGS_EXTRA=\"%CFLAGS_EXTRA%\" ..\n    && cmake --build . --config %CMAKE_CONFIG% --verbose --parallel )\n- cmd: if %TARGET%==cmake-msys (\n    set \"path=C:\\msys64\\usr\\bin;%path%\"\n    && mkdir out && cd out\n    && cmake -G \"MSYS Makefiles\" %CMAKE_OPTIONS% -Denable_werror=ON -DCFLAGS_EXTRA=\"%CFLAGS_EXTRA%\" ..\n    && cmake --build . --config %CMAKE_CONFIG% --verbose --parallel )\n- cmd: if %TARGET%==nmake (\n    \"C:\\Program Files\\Microsoft Visual %STUDIO_VERSION_EDITION%\\VC\\Auxiliary\\Build\\vcvarsall.bat\" %ARCH%\n    && nmake /f NT_MAKEFILE %NMAKE_OPTIONS% CFLAGS_EXTRA=\"/WX %CFLAGS_EXTRA%\" )\n- cmd: if %TARGET%==cygwin64 (\n    C:\\cygwin64\\bin\\bash -e -l -c\n      \"cd /cygdrive/c/projects/bdwgc && ./autogen.sh\n       && ./configure %CONF_OPTIONS% --enable-werror && cat include/config.h\n       && make -j CFLAGS_EXTRA='%CFLAGS_EXTRA%'\" )\n- cmd: if %TARGET%==djgpp-no-make (\n    appveyor DownloadFile \"https://github.com/andrewwutw/build-djgpp/releases/download/v%DJGPP_VER%/djgpp-mingw-gcc%DJGPP_GCC_VER%-standalone.zip\"\n    && 7z x -o.. djgpp-mingw-gcc%DJGPP_GCC_VER%-standalone.zip > nul\n    && ..\\djgpp\\setenv.bat\n    && gcc -I include -Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA% -c extra/gc.c )\n- cmd: if %TARGET%==dmc (\n    appveyor DownloadFile \"http://ftp.digitalmars.com/Digital_Mars_C++/Patch/dm%DMC_VER%c.zip\"\n    && 7z x -o.. dm%DMC_VER%c.zip > nul && set \"path=%cd%\\..\\dm\\bin;%path%\"\n    && make -f digimars.mak CFLAGS_EXTRA=\"-wx %CFLAGS_EXTRA%\" )\n- cmd: if %TARGET%==mingw-shared-no-make (\n    set \"path=C:\\%MINGW_FOLDER%\\bin;%path%\"\n    && gcc -I include -D GC_BUILTIN_ATOMIC -D GC_DLL -Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA% -shared -o gc.dll extra/gc.c )\n- cmd: if %TARGET%==msys64-mingw64 (\n    C:\\msys64\\usr\\bin\\bash -e -l -c\n      \"cd /c/projects/bdwgc\n       && PATH=/c/msys64/mingw64/bin:$PATH make -j -f Makefile.direct CC=gcc CFLAGS_EXTRA='-Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA%'\" )\n- cmd: if %TARGET%==wcc (\n    appveyor DownloadFile \"https://github.com/open-watcom/open-watcom-v2/releases/download/%WATCOM_VER%-Build/ow-snapshot.tar.xz\"\n    && 7z x ow-snapshot.tar.xz > nul && 7z x -o..\\watcom ow-snapshot.tar > nul\n    && set \"watcom=%cd%\\..\\watcom\"\n    && set \"path=%cd%\\..\\watcom\\binnt64;%cd%\\..\\watcom\\binnt\"\n    && set \"include=%cd%\\..\\watcom\\h\\%WCC_INC_SUBDIR%;%cd%\\..\\watcom\\h\"\n    && wmake -f WCC_MAKEFILE SYSTEM=%WCC_SYSTEM% %ENABLE_STATIC_OPT% CFLAGS_EXTRA=\"-we %CFLAGS_EXTRA%\" )\n- cmd: if %TARGET%==cmake-wcc-nt (\n    appveyor DownloadFile \"https://github.com/open-watcom/open-watcom-v2/releases/download/%WATCOM_VER%-Build/ow-snapshot.tar.xz\"\n    && 7z x ow-snapshot.tar.xz > nul && 7z x -o..\\watcom ow-snapshot.tar > nul\n    && set \"watcom=%cd%\\..\\watcom\"\n    && set \"path=C:\\Program Files\\CMake\\bin;%cd%\\..\\watcom\\binnt\"\n    && set \"include=%cd%\\..\\watcom\\h\\nt;%cd%\\..\\watcom\\h\"\n    && mkdir out && cd out\n    && cmake -G \"Watcom WMake\" %CMAKE_OPTIONS% -Denable_werror=ON -DCFLAGS_EXTRA=\"%CFLAGS_EXTRA%\" ..\n    && cmake --build . --config %CMAKE_CONFIG% --verbose )\n- cmd: if %TARGET%==cmake-bcc (\n    appveyor DownloadFile \"https://www.ivmaisoft.com/_bin/misc/freecommandLinetools.exe\"\n    && 7z x -o..\\Bcc55 freecommandLinetools.exe > nul\n    && set \"path=C:\\Program Files\\CMake\\bin;%cd%\\..\\Bcc55\\Bin\"\n    && echo -I\"%cd%\\..\\Bcc55\\Include\" > %cd%\\..\\Bcc55\\Bin\\bcc32.cfg\n    && echo -L\"%cd%\\..\\Bcc55\\Lib;%cd%\\..\\Bcc55\\Lib\\PSDK\" > %cd%\\..\\Bcc55\\Bin\\ilink32.cfg\n    && mkdir out && cd out\n    && cmake -G \"Borland Makefiles\" %CMAKE_OPTIONS% -Denable_werror=ON -DCFLAGS_EXTRA=\"%CFLAGS_EXTRA%\" ..\n    && cmake --build . --config %CMAKE_CONFIG% --verbose --parallel )\n\ntest_script:\n- cmd: if %TARGET%==cmake (\n    ctest --build-config %CMAKE_CONFIG% --verbose --parallel 4 )\n- cmd: if %TARGET%==cmake-bcc (\n    ctest --build-config %CMAKE_CONFIG% --verbose --parallel 4 )\n- cmd: if %TARGET%==cmake-mingw (\n    ctest --build-config %CMAKE_CONFIG% --verbose --parallel 4 )\n- cmd: if %TARGET%==cmake-msys (\n    ctest --build-config %CMAKE_CONFIG% --verbose --parallel 4 )\n- cmd: if %TARGET%==cmake-wcc-nt (\n    ctest --build-config %CMAKE_CONFIG% --verbose --parallel 4 )\n- cmd: if %TARGET%==nmake (\n    \"C:\\Program Files\\Microsoft Visual %STUDIO_VERSION_EDITION%\\VC\\Auxiliary\\Build\\vcvarsall.bat\" %ARCH%\n    && nmake /f NT_MAKEFILE %TEST_TARGET% %NMAKE_OPTIONS% CFLAGS_EXTRA=\"/WX %CFLAGS_EXTRA%\"\n    && nmake /f NT_MAKEFILE clean )\n- cmd: if %TARGET%==cygwin64 (\n    C:\\cygwin64\\bin\\bash -e -l -c\n      \"cd /cygdrive/c/projects/bdwgc\n       && make -j check-without-test-driver CFLAGS_EXTRA='%CFLAGS_EXTRA%'\" )\n- cmd: if %TARGET%==djgpp-no-make (\n    ..\\djgpp\\setenv.bat\n    && gcc -I include -Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA% -o cordtest.exe cord/tests/cordtest.c cord/*.c gc.o\n    && gcc -I include -Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA% -v -o gctest.exe tests/gctest.c gc.o )\n- cmd: if %TARGET%==dmc (\n    make -f digimars.mak %TEST_TARGET% CFLAGS_EXTRA=\"-wx %CFLAGS_EXTRA%\"\n    && type gctest.gc.log cpptest.gc.log\n    && make -f digimars.mak clean )\n- cmd: if %TARGET%==mingw-shared-no-make (\n    gcc -I include -D GC_BUILTIN_ATOMIC -D GC_DLL -Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA% -o gctest.exe tests/gctest.c gc.dll\n    && gctest.exe )\n- cmd: if %TARGET%==msys64-mingw64 (\n    C:\\msys64\\usr\\bin\\bash -e -l -c\n      \"cd /c/projects/bdwgc\n       && PATH=/c/msys64/mingw64/bin:$PATH make -j -f Makefile.direct %TEST_TARGET% CC=gcc CURSES=-lgdi32 CFLAGS_EXTRA='-Werror -Wall -Wextra -Wpedantic %CFLAGS_EXTRA%'\" )\n- cmd: if %TARGET%==wcc (\n    set \"beginlibpath=%cd%\\..\\watcom\\binp\\dll\"\n    && wmake -f WCC_MAKEFILE %TEST_TARGET% SYSTEM=%WCC_SYSTEM% %ENABLE_STATIC_OPT% CFLAGS_EXTRA=\"-we %CFLAGS_EXTRA%\"\n    && wmake -f WCC_MAKEFILE clean )\n"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.21484375,
          "content": "# Clang-format configuration for bdwgc source.\nBasedOnStyle: GNU\n\nAlignEscapedNewlines: Left\nBreakBeforeBraces: Linux\nIndentCaseBlocks: true\nIndentPPDirectives: AfterHash\nSpaceBeforeParens: ControlStatements\nTabWidth: 2\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.447265625,
          "content": "# Git repo attributes.\n\n# Ensure shell and configure-related files have LF enforced.\n*.ac text eol=lf\n*.am text eol=lf\n*.m4 text eol=lf\n*.sh text eol=lf\n\n# Ensure all text files have normalized line endings in the repository.\n* text=auto\n\n# These files should use CR/LF line ending:\n/digimars.mak -text\n\n# Note: \"core.eol\" configuration variable controls which line endings to use\n# for the normalized files in the working directory (the default is native).\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.3330078125,
          "content": "# Ignored files in bdwgc Git repo.\n\n# Binary files (in root dir, cord, tests):\n*.a\n*.dbg\n*.dll\n*.dylib\n*.elf\n*.exe\n*.gcda\n*.gch\n*.gcno\n*.la\n*.lib\n*.lo\n*.o\n*.obj\nlib*.so\n\n*.gc.log\n.dirstamp\n/*_bench.log\n/*_bench.trs\n/*_test\n/*test.log\n/*test.trs\n/.libs/\n/Makefile\n/add_gc_prefix\n/atomicopstest\n/base_lib\n/bdw-gc.pc\n/c++\n/config.cache\n/config.log\n/config.status\n/cord/cordtest\n/cord/de\n/cord/de_win.rbj\n/cord/de_win.res\n/cord/tests/de_win.rbj\n/cord/tests/de_win.res\n/cords\n/cordtest\n/core\n/cpptest\n/de\n/de.dir/\n/disclaim_bench\n/disclaimtest\n/dont_ar_1\n/dont_ar_3\n/dont_ar_4\n/gc-*\n/gc.log\n/gcname\n/gctest\n/gctest_dyn_link\n/gctest_irix_dyn_link\n/hugetest\n/if_mach\n/if_not_there\n/initfromthreadtest\n/leaktest\n/libtool\n/middletest\n/realloctest\n/smashtest\n/staticrootstest\n/subthreadcreatetest\n/sunos5gc.so\n/test-suite.log\n/test_atomic_ops\n/test_atomic_ops.log\n/test_atomic_ops.trs\n/test_cpp\n/test_cpp.cpp\n/test_cpp.log\n/test_cpp.trs\n/test_tree.cpp\n/threadkeytest\n/threadleaktest\n/threadlibs\n/tracetest\n/treetest\n/weakmaptest\n\n/build/\n/out/\n\n# Config, dependency and stamp files generated by configure:\n.deps/\n/include/config.h\nconfig.h.in~\nstamp-h1\n\n# External library (without trailing slash to allow symlinks):\n/libatomic_ops*\n/pthreads-w32*\n\n# These files are generated by autoreconf:\n/Makefile.in\n/aclocal.m4\n/autom4te.cache/\n/compile\n/config.guess\n/config.sub\n/configure\n/configure~\n/depcomp\n/include/config.h.in\n/install-sh\n/ltmain.sh\n/m4/libtool.m4\n/m4/ltoptions.m4\n/m4/ltsugar.m4\n/m4/ltversion.m4\n/m4/lt~obsolete.m4\n/missing\n/mkinstalldirs\n/test-driver\n\n# These files are generated by CMake:\n*.tlog\n/*.vcxproj\n/*.vcxproj.filters\n/CMakeCache.txt\n/CMakeFiles/\n/DartConfiguration.tcl\n/Testing/Temporary/\n/cord/CMakeFiles/\n/cord/Makefile\n/gc.sln\n/tests/*.vcxproj\n/tests/*.vcxproj.filters\n/tests/*test\n/tests/CMakeFiles/\n/tests/Makefile\n/tests/test_cpp\nCTestTestfile.cmake\ncmake_install.cmake\n\n# These ones are generated by Zig:\n/.zig-cache/\n/zig-cache/\n/zig-out/\n\n# Rarely generated files (mostly by some Win/DOS compilers):\n/*.copied.c\n/*.csm\n/*.err\n/*.i\n/*.lb1\n/*.lnk\n/*.map\n/*.out\n/*.rbj\n/*.res\n/*.stackdump\n/*.sym\n/*.tmp\n*.bsc\n*.dll.manifest\n*.exp\n*.idb\n*.ilk\n*.pdb\n*.sbr\n*.tds\ngc.def\n\n# Stuff from VS build system and IDE\n*.vcproj.*.user\n.vs/\n\n# Code analysis tools:\n*.c.gcov\n*.cc.gcov\n*.h.gcov\n*.sancov\n/.sv*-dir\n/cov-int\n/coverage.info\n/pvs-project.log\n/pvs-project.tasks\n/strace_out\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 29.955078125,
          "content": "language: cpp\nos: linux\ndist: jammy\n\njobs:\n  include:\n  - compiler: clang\n    env:\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - os: osx\n    env:\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - env:\n    - COVERITY_SCAN_BRANCH=1\n    addons:\n      coverity_scan:\n        project:\n          name: ivmai/bdwgc\n          version: 8.3.0\n        notification_email: ivmai@mail.ru\n        branch_pattern: master\n        build_command_prepend: \"./configure --enable-cplusplus --disable-shared --enable-single-obj-compilation\"\n        build_command: make -j check CFLAGS_EXTRA=-DLINT2\n  - addons:\n      apt:\n        packages:\n        - lcov\n    compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-gcov --enable-single-obj-compilation --enable-cplusplus --disable-shared --enable-gc-assertions --enable-valgrind-tracking\"\n    - CFLAGS_EXTRA=\"-D USE_CUSTOM_SPECIFIC\"\n    - CC_FOR_CHECK=g++\n    - MAKEFILE_TARGETS=\"all\"\n    - MAKEFILE_TARGETS_CHECK=\"check\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n    - REPORT_COVERAGE=true\n    - TESTS_CUSTOM_RUN=true\n  - env:\n    - MAKEFILE_TARGETS=\"dist\"\n  - os: osx\n    env:\n    - CSA_CHECK=true\n    - CFLAGS_EXTRA=\"-m32\"\n  - compiler: clang\n    language: c\n    env:\n    - CSA_CHECK=true\n    - CFLAGS_EXTRA=\"-D ALL_INTERIOR_POINTERS -D CHECKSUMS -D DBG_HDRS_ALL -D DEBUG_THREADS -D ENABLE_TRACE -D GC_ALWAYS_MULTITHREADED -D GC_ASSERTIONS -D GC_ATOMIC_UNCOLLECTABLE -D GC_ENABLE_SUSPEND_THREAD -D GC_GCJ_SUPPORT -D GC_PRINT_BACK_HEIGHT -D GC_THREADS -D HANDLE_FORK -D JAVA_FINALIZATION -D KEEP_BACK_PTRS -D MAKE_BACK_GRAPH -D PARALLEL_MARK -D PRINT_BLACK_LIST -D THREAD_LOCAL_ALLOC -D USE_MMAP -D USE_MUNMAP\"\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"--enable=unusedFunction -I libatomic_ops/src extra/gc.c tests/*.c\"\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"--enable=unusedFunction --force -D GC_BUILTIN_ATOMIC *.cc cord/*.c cord/tests/*.c tests/*.c\"\n    - CPPCHECK_OUT_FILTER=\"Z\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"-j4 --enable=all --disable=missingInclude,unusedFunction --force -U GC_PRIVATE_H -I libatomic_ops/src a*.c b*.c c*.c d*.c f*.c\"\n    - CPPCHECK_OUT_FILTER=\"Z\"\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"-j4 --enable=all --disable=missingInclude,unusedFunction --force -U GC_PRIVATE_H -I libatomic_ops/src g*.c h*.c m*.c\"\n    - CPPCHECK_OUT_FILTER=\"Z\"\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"-j4 --enable=all --disable=missingInclude,unusedFunction --force -U GC_PRIVATE_H -I libatomic_ops/src n*.c o*.c p*.c r*.c s*.c t*.c w*.c cord/*.c\"\n  - compiler: clang\n    env:\n    - CPPCHECK_ENABLE=\"-j4 --enable=all --disable=missingInclude,unusedFunction --force -I libatomic_ops/src *.cc cord/tests/*.c extra/m*.c extra/*.cpp tests/*.c tests/*.cc tools/*.c\"\n    - CPPCHECK_OUT_FILTER=\"Z\"\n  - arch: arm64\n    compiler: clang\n    dist: focal\n  - arch: arm64\n    compiler: gcc\n    dist: focal\n  - arch: arm64\n    compiler: clang\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-O3\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --disable-shared\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: arm64\n    compiler: gcc\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-O3 -D SIMULATE_LOST_SIGNALS -D TRACE_BUF\"\n    - CONF_OPTIONS=\"--enable-cplusplus --disable-gcj-support\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - musl-tools\n    arch: arm64\n    compiler: musl-gcc\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-O3 -D SOFT_VDB\"\n    - CONF_OPTIONS=\"--enable-gc-assertions\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: arm64\n    compiler: gcc\n    dist: focal\n    env:\n    - CONF_OPTIONS=\"--disable-threads\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - libatomic-ops-dev\n    arch: arm64\n    compiler: gcc\n    dist: focal\n    env:\n    - CONF_OPTIONS=\"--with-libatomic-ops=yes --enable-gc-assertions --enable-cplusplus --disable-munmap\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: arm64\n    compiler: clang\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=memory,undefined -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--enable-static\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n    - TESTS_CUSTOM_RUN=true\n  - arch: arm64\n    compiler: clang\n    dist: focal\n    env:\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=MinSizeRel -DBUILD_SHARED_LIBS=OFF -Denable_cplusplus=ON -Denable_gc_assertions=ON\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: arm64\n    compiler: gcc\n    dist: focal\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    env:\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - arch: ppc64le\n    compiler: gcc\n    dist: focal\n    env:\n    - CONF_OPTIONS=\"--disable-shared --disable-threads\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-O3 -D _FORTIFY_SOURCE=2 -D DONT_PROTECT_PTRFREE -D FORCE_MPROTECT_BEFORE_MADVISE -D GC_UNMAPPED_REGIONS_SOFT_LIMIT=120\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: ppc64le\n    compiler: gcc\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-O3 -D NO_MPROTECT_VDB\"\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-D CHECK_SOFT_VDB\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-static --disable-thread-local-alloc\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=memory,undefined -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--disable-shared\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n    - TESTS_CUSTOM_RUN=true\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    env:\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Release -Denable_cplusplus=ON -Denable_gc_assertions=ON\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: ppc64le\n    compiler: clang\n    dist: focal\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - arch: s390x\n    compiler: clang\n    dist: focal\n    env:\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - arch: s390x\n    compiler: gcc\n    dist: focal\n    env:\n    - CONF_OPTIONS=\"--disable-disclaim\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - addons:\n      apt:\n        packages:\n        - clang-12\n    arch: s390x\n    compiler: clang-12\n    dist: focal\n    env:\n    - CC=clang-12\n    - CXX=clang++-12\n    - CFLAGS_EXTRA=\"-O3 -flto -D _FORTIFY_SOURCE=2 -D NO_RETRY_SIGNALS\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --enable-dynamic-pointer-mask\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - addons:\n      apt:\n        packages:\n        - g++-10\n    arch: s390x\n    compiler: g++-10\n    dist: focal\n    env:\n    - CC=gcc-10\n    - CXX=g++-10\n    - CFLAGS_EXTRA=\"-O3 -flto=auto -D _FORTIFY_SOURCE=2 -D PREFER_MMAP_PROT_NONE\"\n    - CONF_OPTIONS=\"--enable-cplusplus --disable-shared\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - arch: s390x\n    compiler: gcc\n    dist: focal\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - os: freebsd\n    compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-O3 -D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-gc-assertions --enable-redirect-malloc --enable-rwlock\"\n    - MAKE_NPROC=8\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: freebsd\n    env:\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - MAKE_NPROC=8\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: freebsd\n    env:\n    - CONF_OPTIONS=\"--enable-gc-assertions --disable-shared\"\n    - MAKE_NPROC=8\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: freebsd\n    env:\n    - CMAKE_BUILD_OPTIONS=\"--verbose\"\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Release -Denable_cplusplus=ON\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: freebsd\n    compiler: clang\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n    - MAKE_NPROC=8\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-O3 -march=native -fanalyzer\"\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --disable-disclaim --enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-m32 -funsigned-char -D _FORTIFY_SOURCE=2 -D GC_GCJ_MARK_DESCR_OFFSET=32 -D NO_LONGLONG64\"\n    - CONF_OPTIONS=\"--enable-gc-assertions\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-m32 -D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-mmap --enable-rwlock\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - os: osx\n    env:\n    - CFLAGS_EXTRA=\"-m32 -D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--disable-threads --enable-checksums --disable-munmap --enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CONF_OPTIONS=\"--disable-threads --enable-checksums --disable-handle-fork --disable-munmap --enable-gc-assertions --enable-large-config --enable-static\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2 -D DBG_HDRS_ALL -D SHORT_DBG_HDRS\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --disable-dynamic-loading\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CFLAGS_EXTRA=\"-D DBG_HDRS_ALL -D SHORT_DBG_HDRS -D LINT2 -D PRINT_AND_CHECK_INT_LIST -D USE_GETSECTBYNAME\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --enable-handle-fork=manual --disable-throw-bad-alloc-library\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D DEBUG_ADD_DEL_ROOTS -D DEBUG_THREADS -D GC_DEBUG -D GC_LOG_TO_FILE_ALWAYS\"\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D BSD_TIME -D DEFAULT_STACK_MAYBE_SMALL -D ENABLE_TRACE -D EMPTY_GETENV_RESULTS -D GC_ALWAYS_MULTITHREADED -D GC_NETBSD_THREADS_WORKAROUND -D CPPCHECK\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-gc-assertions\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-march=native -D _FORTIFY_SOURCE=2 -D DEFAULT_VDB -D TEST_WITH_SYSTEM_MALLOC\"\n    - CONF_OPTIONS=\"--without-libatomic-ops --enable-cplusplus --disable-handle-fork\"\n  - addons:\n      apt:\n        packages:\n        - libatomic-ops-dev\n    compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2 -D TEST_PAGES_EXECUTABLE\"\n    - CONF_OPTIONS=\"--with-libatomic-ops=yes --enable-gc-assertions --enable-cplusplus --disable-throw-bad-alloc-library\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CFLAGS_EXTRA=\"-march=native -D _FORTIFY_SOURCE=2 -D AO_DISABLE_GCC_ATOMICS\"\n    - CONF_OPTIONS=\"--without-libatomic-ops --enable-munmap --enable-cplusplus --enable-static\"\n  - compiler: gcc\n    env:\n    - CONF_CFLAGS=\"-O3 -D _FORTIFY_SOURCE=2 -D AO_USE_PTHREAD_DEFS -D RANDOM_ONE_CPU_CORE\"\n    - CONF_OPTIONS=\"--without-libatomic-ops --enable-gc-assertions --enable-cplusplus --enable-static\"\n  - compiler: clang\n    env:\n    - CONF_CFLAGS=\"-D AO_USE_PTHREAD_DEFS\"\n    - CONF_OPTIONS=\"--without-libatomic-ops\"\n  - addons:\n      apt:\n        packages:\n        - libatomic-ops-dev\n    compiler: gcc\n    env:\n    - CONF_CFLAGS=\"-O3 -D AO_USE_PTHREAD_DEFS -D RANDOM_ONE_CPU_CORE\"\n    - CONF_OPTIONS=\"--with-libatomic-ops=yes --enable-cplusplus\"\n    - CFLAGS_EXTRA=\"-D GC_NO_FINALIZATION\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - libatomic-ops-dev\n    compiler: clang\n    env:\n    - CONF_CFLAGS=\"-O3 -D AO_USE_PTHREAD_DEFS -D RANDOM_ONE_CPU_CORE\"\n    - CONF_OPTIONS=\"--with-libatomic-ops=yes --enable-gc-assertions --enable-cplusplus --disable-shared --enable-static\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-funsigned-char -D _FORTIFY_SOURCE=2 -D DONT_ADD_BYTE_AT_END -D GC_TIME_LIMIT=3\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-m32 -D _FORTIFY_SOURCE=2 -D MARK_BIT_PER_OBJ -D USE_CUSTOM_SPECIFIC\"\n    - CONF_OPTIONS=\"--enable-gc-assertions\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-D MARK_BIT_PER_OBJ\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-rwlock --disable-shared\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2 -D NO_CLOCK -D POINTER_MASK=~0xf\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --enable-handle-fork=manual\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D PROC_VDB -D GC_NO_SYS_FAULT_H -D NO_INCREMENTAL -D DEBUG_DIRTY_BITS\"\n    - CONF_OPTIONS=\"--enable-cplusplus --disable-docs\"\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2 -D TEST_MANUAL_VDB\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --disable-parallel-mark\"\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D TEST_MANUAL_VDB\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --disable-munmap\"\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2 -D FIND_LEAK -D SKIP_LEAKED_OBJECTS_PRINTING\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus\"\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D SMALL_CONFIG -D NO_GETENV\"\n    - CONF_OPTIONS=\"--enable-cplusplus\"\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-std=c11 -D _FORTIFY_SOURCE=2 -D GC_NO_SIGSETJMP\"\n    - CONF_OPTIONS=\"--disable-threads --enable-gc-assertions\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CONF_OPTIONS=\"--disable-thread-local-alloc --enable-cplusplus --enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-O3 -flto -D _FORTIFY_SOURCE=2 -D NO_MANUAL_VDB\"\n    - CONF_OPTIONS=\"--disable-parallel-mark --disable-thread-local-alloc --enable-gc-assertions --enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-gc-debug --enable-cplusplus\"\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--disable-gc-debug --enable-cplusplus\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: clang\n    env:\n    - CONF_OPTIONS=\"--enable-large-config --enable-cplusplus --disable-shared --enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CFLAGS_EXTRA=\"-D TEST_HANDLE_FORK\"\n    - CONF_OPTIONS=\"--disable-atomic-uncollectible --enable-cplusplus --enable-rwlock --disable-shared --enable-static\"\n  - os: osx\n    env:\n    - CONF_OPTIONS=\"--enable-large-config --enable-cplusplus --disable-gc-debug --disable-handle-fork\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-large-config --disable-munmap\"\n    - CFLAGS_EXTRA=\"-m32\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-large-config --enable-cplusplus --enable-gc-assertions --enable-static\"\n    - CFLAGS_EXTRA=\"-D LINT2 -D NO_VDB_FOR_STATIC_ROOTS -D TEST_REUSE_SIG_SUSPEND\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-large-config --enable-redirect-malloc --disable-threads\"\n    - CFLAGS_EXTRA=\"-O3 -fanalyzer\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: clang\n    env:\n    - CONF_OPTIONS=\"--enable-redirect-malloc --enable-static --disable-threads\"\n    - CFLAGS_EXTRA=\"-m32\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CONF_OPTIONS=\"--enable-redirect-malloc --enable-cplusplus --enable-static --disable-threads\"\n    - CFLAGS_EXTRA=\"-m32\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-redirect-malloc --enable-gc-debug --enable-cplusplus --enable-gc-assertions\"\n  - compiler: clang\n    env:\n    - CONF_OPTIONS=\"--disable-threads --enable-cplusplus\"\n    - CFLAGS_EXTRA=\"-O3 -march=native\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--disable-static --disable-threads --enable-cplusplus\"\n    - CFLAGS_EXTRA=\"-O3 -march=native -fanalyzer -D DONT_PROTECT_PTRFREE -D GC_PREFER_MPROTECT_VDB\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CONF_OPTIONS=\"--disable-threads --enable-cplusplus\"\n    - CFLAGS_EXTRA=\"-O3 -march=native\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CMAKE_OPTIONS=\"-Denable_cplusplus=ON -Denable_gc_assertions=ON\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - libatomic-ops-dev\n    compiler: clang\n    env:\n    - CMAKE_OPTIONS=\"-Denable_atomic_uncollectable=OFF -Denable_cplusplus=ON -Denable_munmap=OFF -Dwith_libatomic_ops=ON\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Release -Denable_cplusplus=ON -Denable_large_config=ON\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Debug -DBUILD_SHARED_LIBS=OFF -Denable_gc_debug=ON -Dwithout_libatomic_ops=ON\"\n  - compiler: gcc\n    env:\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -Denable_threads=OFF\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CMAKE_BUILD_OPTIONS=\"--verbose\"\n    - CMAKE_OPTIONS=\"-Denable_cplusplus=ON\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CMAKE_BUILD_OPTIONS=\"--verbose\"\n    - CMAKE_OPTIONS=\"-Denable_cplusplus=ON -Denable_gc_assertions=ON -Denable_large_config=ON -Denable_redirect_malloc=ON -Denable_rwlock=ON -DCFLAGS_EXTRA=-DIGNORE_FREE\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - os: osx\n    env:\n    - CMAKE_BUILD_OPTIONS=\"--verbose\"\n    - CMAKE_OPTIONS=\"-DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -Denable_cplusplus=ON -Denable_gc_assertions=ON -Denable_large_config=ON\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: gcc\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - os: osx\n    env:\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"check cord/de\"\n  - addons:\n      apt:\n        packages:\n        - musl-tools\n    compiler: musl-gcc\n    language: c\n    env:\n    - CONF_OPTIONS=\"--disable-parallel-mark --enable-gc-assertions\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n  - compiler: clang\n    dist: xenial\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=address -fno-common -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-static\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n    - TESTS_CUSTOM_RUN=true\n  - addons:\n      apt:\n        packages:\n        - gcc-5\n        sources:\n        - ubuntu-toolchain-r-test\n    compiler: gcc-5\n    dist: xenial\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=address -O0\"\n    - CONF_OPTIONS=\"--enable-gc-assertions\"\n    - LDFLAGS=\"-fuse-ld=gold\"\n  - os: osx\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=address -m32 -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--disable-shared --enable-cplusplus\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - clang-12\n    compiler: clang-12\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=memory -fno-omit-frame-pointer -std=gnu11\"\n    - CONF_OPTIONS=\"--enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - TESTS_CUSTOM_RUN=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=undefined -fno-common -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-static\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - TESTS_CUSTOM_RUN=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - clang-12\n    compiler: clang-12\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-O3 -fsanitize=thread -fno-omit-frame-pointer\"\n    - CONF_OPTIONS=\"--enable-static\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    dist: focal\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=thread -D NO_INCREMENTAL -fno-omit-frame-pointer -D TEST_FORK_WITHOUT_ATFORK\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-gc-debug --enable-handle-fork=manual --enable-large-config --without-libatomic-ops\"\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-fsanitize=thread -D NO_INCREMENTAL -fno-omit-frame-pointer -D NTHREADS=0\"\n    - CONF_OPTIONS=\"--disable-parallel-mark --disable-thread-local-alloc --disable-shared --enable-gc-assertions --without-libatomic-ops\"\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-O3 -march=native -D NTHREADS=10\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-static --enable-single-obj-compilation\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-m32 -D _FORTIFY_SOURCE=2 -D GC_DISABLE_INCREMENTAL -std=gnu11\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-gc-debug\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-gc-assertions --enable-static\"\n    - CFLAGS_EXTRA=\"-D VERY_SMALL_CONFIG\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-multilib\n    compiler: gcc\n    env:\n    - CFLAGS_EXTRA=\"-m32 -O3 -std=gnu11\"\n    - CONF_OPTIONS=\"--disable-shared --enable-static --enable-single-obj-compilation\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - addons:\n      apt:\n        packages:\n        - gcc-8\n        - gcc-8-multilib\n        - gcc-multilib\n    compiler: gcc-8\n    dist: focal\n    language: c\n    env:\n    - CFLAGS_EXTRA=\"-mx32 -march=native -D _FORTIFY_SOURCE=2\"\n    - CONF_OPTIONS=\"--enable-large-config --enable-gc-assertions\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-x c++\"\n    - CONF_OPTIONS=\"--enable-gc-assertions --enable-cplusplus --enable-gc-debug --disable-shared\"\n    - MAKEFILE_TARGETS=\"all\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CC_FOR_CHECK=g++\n    - CONF_OPTIONS=\"--enable-gc-assertions\"\n    - MAKEFILE_TARGETS=\"all\"\n    - MAKEFILE_TARGETS_CHECK=\"check\"\n    - GCTEST_WITH_MPROTECT_VDB=true\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: gcc\n    env:\n    - CC_FOR_CHECK=g++\n    - CFLAGS_EXTRA=\"-std=c++20\"\n    - CONF_OPTIONS=\"--enable-cplusplus --enable-gc-assertions --enable-gc-debug\"\n    - MAKEFILE_TARGETS=\"clean\"\n    - MAKEFILE_TARGETS_CHECK=\"check\"\n    - NO_CLONE_LIBATOMIC_OPS=true\n  - compiler: clang\n    env:\n    - CFLAGS_EXTRA=\"-O3 -Wall -Wextra -Werror -x c++\"\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"cords\"\n  - compiler: gcc\n    env:\n    - CC_FOR_CHECK=g++\n    - CFLAGS_EXTRA=\"-O3 -Wall -Wextra -Werror -D TEST_MANUAL_VDB\"\n    - MAKEFILE_NAME=Makefile.direct\n    - MAKEFILE_TARGETS=\"cords\"\n    - MAKEFILE_TARGETS_CHECK=\"cord/de check\"\n  - addons:\n      apt:\n        packages:\n        - g++-mingw-w64\n        - gcc-mingw-w64\n    compiler: x86_64-w64-mingw32-gcc\n    language: c\n    env:\n    - CXX=x86_64-w64-mingw32-g++\n    - CONF_OPTIONS=\"--host=x86_64-w64-mingw32 --enable-cplusplus --disable-shared\"\n    - MAKEFILE_TARGETS=\"all\"\n  - addons:\n      apt:\n        packages:\n        - gcc-mingw-w64\n    compiler: x86_64-w64-mingw32-gcc\n    language: c\n    env:\n    - CONF_OPTIONS=\"--host=x86_64-w64-mingw32 --enable-gc-assertions --enable-gc-debug --enable-threads=pthreads\"\n    - MAKEFILE_TARGETS=\"all\"\n  - addons:\n      apt:\n        packages:\n        - gcc-mingw-w64\n    compiler: i686-w64-mingw32-gcc\n    language: c\n    env:\n    - CONF_OPTIONS=\"--host=i686-w64-mingw32\"\n    - MAKEFILE_TARGETS=\"all\"\n    - CFLAGS_EXTRA=\"-fno-omit-frame-pointer\"\n  - dist: focal\n    env:\n    - MAKEFILE_TARGETS=\"distcheck\"\n    - AUTOCONF_VER=2.72\n    - AUTOMAKE_VER=1.17\n    - LIBTOOL_VER=2.5.4\n    - M4_VER=1.4.19\n    - NO_CLONE_LIBATOMIC_OPS=true\n\nbefore_install:\n- if [[ \"$CPPCHECK_ENABLE\" != \"\" ]]; then\n    CPPCHECK_VER=2.14.2;\n    git clone --depth=3 https://github.com/danmar/cppcheck.git\n            ~/cppcheck -b $CPPCHECK_VER;\n    make --directory ~/cppcheck -j8 CXXFLAGS=\"-O3 -march=native -D NDEBUG\";\n  fi\n- if [[ \"$AUTOCONF_VER\" != \"\" || \"$AUTOMAKE_VER\" != \"\"\n        || \"$LIBTOOL_VER\" != \"\" || \"$M4_VER\" != \"\" ]]; then\n    GNUTOOLS_ROOT=`pwd`/../gnu-tools;\n    export PATH=$GNUTOOLS_ROOT/bin:$PATH;\n    GNU_DOWNLOAD_SITE=https://ftp.gnu.org/gnu;\n  fi\n- if [[ \"$M4_VER\" != \"\" ]]; then\n    M4_XZ_URL=$GNU_DOWNLOAD_SITE/m4/m4-$M4_VER.tar.xz;\n    wget -O - $M4_XZ_URL | tar xf - --xz --directory ~;\n    (cd ~/m4-$M4_VER && ./configure --prefix=$GNUTOOLS_ROOT && make -j && make install);\n  fi\n- if [[ \"$LIBTOOL_VER\" != \"\" ]]; then\n    LIBTOOL_XZ_URL=$GNU_DOWNLOAD_SITE/libtool/libtool-$LIBTOOL_VER.tar.xz;\n    wget -O - $LIBTOOL_XZ_URL | tar xf - --xz --directory ~;\n    (cd ~/libtool-$LIBTOOL_VER && ./configure --prefix=$GNUTOOLS_ROOT && make -j && make install);\n  fi\n- if [[ \"$AUTOCONF_VER\" != \"\" ]]; then\n    AUTOCONF_XZ_URL=$GNU_DOWNLOAD_SITE/autoconf/autoconf-$AUTOCONF_VER.tar.xz;\n    wget -O - $AUTOCONF_XZ_URL | tar xf - --xz --directory ~;\n    (cd ~/autoconf-$AUTOCONF_VER && ./configure --prefix=$GNUTOOLS_ROOT && make -j && make install);\n  fi\n- if [[ \"$AUTOMAKE_VER\" != \"\" ]]; then\n    AUTOMAKE_XZ_URL=$GNU_DOWNLOAD_SITE/automake/automake-$AUTOMAKE_VER.tar.xz;\n    wget -O - $AUTOMAKE_XZ_URL | tar xf - --xz --directory ~;\n    (cd ~/automake-$AUTOMAKE_VER && ./configure --prefix=$GNUTOOLS_ROOT && make -j && make install);\n  fi\n- if [[ \"$MAKEFILE_TARGETS\" == *\"dist\"* ]]; then\n    autoconf --version;\n    automake --version;\n    m4 --version;\n    libtool --version || true;\n  fi\n- if [[ \"$CMAKE_OPTIONS\" != \"\" ]]; then\n    cmake --version;\n  fi\n- if [[ \"$CONF_CFLAGS\" == \"\" ]]; then CONF_CFLAGS=\"-g -O2\"; fi\n- if [[ \"$MAKEFILE_NAME\" == \"\" ]]; then MAKEFILE_NAME=Makefile; fi\n- if [[ \"$MAKEFILE_TARGETS\" == \"\" ]]; then MAKEFILE_TARGETS=\"check\"; fi\n\ninstall:\n- if [[ \"$NO_CLONE_LIBATOMIC_OPS\" != true ]]; then\n    git clone --depth=50 https://github.com/ivmai/libatomic_ops.git;\n  fi\n- if [[ \"$CMAKE_OPTIONS\" == \"\" ]]; then\n    ./autogen.sh;\n  fi\n- if [[ \"$GNUTOOLS_ROOT\" != \"\" ]]; then mv $GNUTOOLS_ROOT $GNUTOOLS_ROOT-x; fi\n- if [[ \"$REPORT_COVERAGE\" == true ]]; then gem install coveralls-lcov; fi\n\nscript:\n- if [[ \"$CSA_CHECK\" != true && \"$CMAKE_OPTIONS\" == \"\"\n        && \"$CPPCHECK_ENABLE\" == \"\" && \"$MAKEFILE_NAME\" != \"Makefile.direct\"\n        && \"$COVERITY_SCAN_BRANCH\" != 1 ]]; then\n    CFLAGS=\"$CONF_CFLAGS\" ./configure $CONF_OPTIONS --enable-werror &&\n    cat include/config.h;\n  fi\n- if [[ \"$CSA_CHECK\" != true && \"$CMAKE_OPTIONS\" == \"\"\n        && \"$CPPCHECK_ENABLE\" == \"\" && \"$COVERITY_SCAN_BRANCH\" != 1 ]]; then\n    make -j$MAKE_NPROC -f $MAKEFILE_NAME $MAKEFILE_TARGETS\n         CFLAGS_EXTRA=\"$CFLAGS_EXTRA\" LDFLAGS=\"$LDFLAGS\";\n  fi\n- if [[ \"$CMAKE_OPTIONS\" != \"\" ]]; then\n    cmake $CMAKE_OPTIONS -Dbuild_tests=ON -Denable_werror=ON -Werror=dev .\n    && cmake --build . $CMAKE_BUILD_OPTIONS --parallel;\n  fi\n- if [[ \"$CMAKE_OPTIONS\" != \"\" ]]; then\n    ctest --verbose --parallel 4;\n  fi\n- if [[ \"$CC_FOR_CHECK\" != \"\" ]]; then\n    make -f $MAKEFILE_NAME $MAKEFILE_TARGETS_CHECK CC=$CC_FOR_CHECK\n            CFLAGS_EXTRA=\"$CFLAGS_EXTRA\";\n  fi\n- if [ -f cordtest.log ]; then cat cordtest.log; fi\n- if [ -f disclaim_bench.log ]; then cat disclaim_bench.log; fi\n- if [ -f disclaimtest.log ]; then cat disclaimtest.log; fi\n- if [ -f gctest.log ]; then cat gctest.log; fi\n- if [ -f threadkeytest.log ]; then cat threadkeytest.log; fi\n- if [ -f threadleaktest.log ]; then cat threadleaktest.log; fi\n- if [ -f weakmaptest.log ]; then cat weakmaptest.log; fi\n- if [[ \"$CSA_CHECK\" == true ]]; then\n    set -o pipefail; ${CC} --analyze -Xanalyzer -analyzer-output=text -Werror\n        -I include -I libatomic_ops/src $CFLAGS_EXTRA\n        *.c *.cc cord/*.c cord/tests/cordtest.c cord/tests/de.c extra/*.c\n        tests/*.c tests/*.cc tools/*.c 2>&1 | tee clang-analyzer-output.log;\n    if [ -s clang-analyzer-output.log ]; then exit 1; fi;\n  fi\n- if [[ \"$CPPCHECK_ENABLE\" != \"\" ]]; then\n    if [[ \"$CPPCHECK_OUT_FILTER\" == \"\" ]]; then CPPCHECK_OUT_FILTER=\"c \"; fi;\n    set -o pipefail; ~/cppcheck/cppcheck --error-exitcode=2 -D CPPCHECK\n        -I include --check-level=exhaustive $CPPCHECK_ENABLE |\n        grep --line-buffered \"$CPPCHECK_OUT_FILTER\";\n  fi\n- if [[ \"$TESTS_CUSTOM_RUN\" == true ]]; then\n    ASAN_OPTIONS=\"detect_leaks=1\" UBSAN_OPTIONS=\"halt_on_error=1\"\n        make check-without-test-driver;\n  fi\n- if [[ \"$GCTEST_WITH_MPROTECT_VDB\" == true ]]; then\n    GC_USE_GETWRITEWATCH=0 ./gctest;\n  fi\n\nafter_success:\n- if [[ \"$REPORT_COVERAGE\" == true ]]; then\n    lcov --capture --base-directory . --directory . --output-file coverage.info;\n    lcov --remove coverage.info '/usr/*' 'cord/tests/*' 'libatomic_ops/*' 'tests/*' --output-file coverage.info;\n    lcov --list coverage.info;\n    coveralls-lcov --repo-token ${COVERALLS_TOKEN} coverage.info;\n    bash <(curl -s https://codecov.io/bash);\n  fi\n\nbefore_deploy:\n- yes | gem update --system --force\n- gem install bundler\n- gem install uri\n- gem install logger\n\ndeploy:\n  provider: releases\n  edge: true\n  file: gc-*.tar.gz\n  file_glob: true\n  on:\n    condition: $MAKEFILE_TARGETS = distcheck\n    repo: ivmai/bdwgc\n    tags: true\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 17.9482421875,
          "content": "This is an attempt to acknowledge contributions to the garbage collector.\nEarly contributions also mentioned (duplicated) in ChangeLog file; details of\nlater ones should be in \"git log\".\n\nCurrently maintained by Ivan Maidanski.\n\nHISTORY -\n\n  Early versions of this collector were developed as a part of research\nprojects supported in part by the National Science Foundation\nand the Defense Advance Research Projects Agency.\n\nThe garbage collector originated as part of the run-time system for\nthe Russell programming language implementation. The first version of the\ngarbage collector was written primarily by Alan Demers.  It was then refined\nand mostly rewritten, primarily by Hans-J. Boehm, at Cornell U.,\nthe University of Washington, Rice University (where it was first used for\nC and assembly code), Xerox PARC, SGI, and HP Labs.  However, significant\ncontributions have also been made by many others.\n\nOther contributors (my apologies for any omissions):\n\nAdam Megacz <adam@megac.com>\nAdnan Ali\nAdrian Bunk <bunk@fs.tum.de>\nAdrian Pop <adrian.pop@liu.se>\nAkira Tagoh <tagoh@redhat.com>\nAlain Novak <alain.novak@hermes.si>\nAlan Dosser <dosser@src.dec.com>\nAlan J. Demers <ademers@cs.cornell.edu>\nAlaskan Emily <emily@alaskanemily.net>\nAleksey Demakov <ademakov@gmail.com>\nAlessandro Bruni <alessandro.bruni@gmail.com>\nAlex Ronne Petersen <alexrp@xamarin.com>\nAlexander Belchenko <bialix@ukr.net>\nAlexander Ederer <alexander.ederer@unity3d.com>\nAlexander Gavrilov <angavrilov@gmail.com>\nAlexander Herz <alexander.herz@mytum.de>\nAlexander Medvednikov <alexander@vlang.io>\nAlexandr Petrosian <paf@design.ru>\nAlexandr Shadchin <ShadchinAV@mail.ru>\nAlexandre Oliva <aoliva@redhat.com>\nAlexis Laferriere <alexis.laf@xymus.net>\nAli Mohammad Pur <ali.mpfard@gmail.com>\nAlistair G. Crooks <agc@uts.amdahl.com>\nAllan Hsu <allan@counterpop.net>\nAmaury Sechet <deadalnix@gmail.com>\nAndre Leiradella <andre@leiradella.com>\nAndreas Jaeger <aj@suse.de>\nAndreas Tobler <andreastt@gmail.com>\nAndrei Polushin <polushin@gmail.com>\nAndrej Cedilnik <acedil1@csee.umbc.edu>\nAndrew Begel <abegel@eecs.berkeley.edu>\nAndrew Buss <abuss@ucsd.edu>\nAndrew Gray <andrew.gray@anu.edu.au>\nAndrew Haley <aph@redhat.com>\nAndrew Horton <andrew.j.horton@gmail.com>\nAndrew McKinlay <mckinlay@axonsoft.com>\nAndrew Pinski <pinskia@physics.uc.edu>\nAndrew Stitcher <astitcher@redhat.com>\nAndrew Stone <andrew@stone.com>\nAndrew Whatson <whatson@gmail.com>\nAndy Li <andy@onthewings.net>\nAndy Wingo <wingo@pobox.com>\nAnselm Baird-Smith <Anselm.BairdSmith@inria.fr>\nAnthony Green <green@redhat.com>\nAntoine de Maricourt\nAnuraag Agrawal <anuraaga@gmail.com>\nAri Huttunen <Ari.Huttunen@hut.fi>\nArrigo Triulzi <arrigo@ic.ac.uk>\nAshley Bone <ashley.bone@nvl.army.mil>\nAssar Westerlund <assar@sics.se>\nAugustin Cavalier <waddlesplash@gmail.com>\nAurelien Larcher <aurelien.larcher@gmail.com>\nBarry DeFreese <bdefreese@debian.org>\nBaruch Siach <baruch@tkos.co.il>\nBen A. Mesander <ben@piglet.cr.usgs.gov>\nBen Cottrell <tamino@wolfhut.org>\nBen Hutchings <ben@decadentplace.org.uk>\nBen Maurer <benm@mono-cvs.ximian.com>\nBenjamin Lerman <Benjamin.Lerman@ambre.net>\nBernd Edlinger <bernd.edlinger@hotmail.de>\nBernd Kuhls <bernd.kuhls@t-online.de>\nBernie Solomon <bernard@mono-cvs.ximian.com>\nBill Holmes <bill.holmes@unity3d.com>\nBill Janssen <janssen@parc.xerox.com>\nBo Thorsen <bo@berlioz.suse.de>\nBradley D. LaRonde <brad@ltc.com>\nBradley Smith <brad@brad-smith.co.uk>\nBrent Benson <brent@jade.ssd.csd.harris.com>\nBrian Alliet <brian@brianweb.net>\nBrian Beuning <bbeuning@corecard.com>\nBrian Burton <bburton@users.sourceforge.net>\nBrian D. Carlstrom <bdc@clark.lcs.mit.edu>\nBrian F. Dennis <xjam@cork.cs.berkeley.edu>\nBrian J. Cardiff <bcardiff@gmail.com>\nBrian Lewis <btlewis@eng.sun.com>\nBruce A Henderson <woollybah@gmail.com>\nBruce Hoult <bruce@hoult.org>\nBruce Mitchener <bruce.mitchener@gmail.com>\nBruno Haible <bruno@clisp.org>\nBryce McKinlay <mckinlay@redhat.com>\nBurkhard Linke <blinke@cebitec.uni-bielefeld.de>\nCalvin Buckley <calvin@openmailbox.org>\nCameron Youell <cameronyouell@gmail.com>\nCarlos J. Puga Medina <cpm@fbsd.es>\nCesar Eduardo Barros <cesarb@nitnet.com.br>\nCharles Fiterman <cef@geode.geodesic.com>\nCharles Mills <boson@cyberspace.org>\nChris Dodd <chrisd@reservoir.com>\nChris Lingard <chris@highludworth.freeserve.co.uk>\nChris Metcalf <cmetcalf@mellanox.com>\nChristian Joensson <christian.joensson@gmail.com>\nChristian Limpach <chris@pin.lu>\nChristian Thalinger <twisti@complang.tuwien.ac.at>\nChristian Weisgerber <naddy@openbsd.org>\nChristoffe Raffali <christophe.raffalli@univ-savoie.fr>\nClay Spence <cds@peanut.sarnoff.com>\nClement Chigot <clement.chigot@atos.net>\nColin LeMahieu <clemahieu@gmail.com>\nCraig McDaniel <kreg7@bellsouth.net>\nDai Sato <satodai@dog.intcul.tohoku.ac.jp>\nDan Bonachea <bonachea@cs.berkeley.edu>\nDan Fandrich <dan@coneharvesters.com>\nDan Sullivan <sullivan@epa.gov>\nDaniel R. Grayson <dan@math.uiuc.edu>\nDanny Smith <danny_r_smith_2001@yahoo.co.nz>\nDarrell Schiebel <drs@nrao.edu>\nDave Barrett <barrett@asgard.cs.colorado.edu>\nDave Barton <dbarton@mathscribe.com>\nDave Detlefs <detlefs@src.dec.com>\nDave Korn <dave.korn.cygwin@googlemail.com>\nDave Love <d.love@dl.ac.uk>\nDavid A. Holland <dholland@netbsd.org>\nDavid Ayers <d.ayers@inode.at>\nDavid Brownlee <abs@absd.org>\nDavid Butenhof <david.butenhof@hp.com>\nDavid Chase <dr2chase@mac.com>\nDavid Daney <ddaney@avtrex.com>\nDavid Grove <groved@us.ibm.com>\nDavid Leonard <leonard@users.sourceforge.net>\nDavid Miller <davem@davemloft.net>\nDavid Mosberger <davidm@hpl.hp.com>\nDavid Peroutka <djp@volny.cz>\nDavid Pickens <dsp@rci.rutgers.edu>\nDavid Rubin <daviru007@icloud.com>\nDavid Stes <stes@d5e02b1d.kabel.telenet.be>\nDavid Terei <d@davidterei.com>\nDavid Van Horn <dvanhorn@ccs.neu.edu>\nDavide Angelocola <davide.angelocola@tiscali.it>\nDavide Beatrici <git@davidebeatrici.dev>\nDejice Jacob <dejice.jacob@glasgow.ac.uk>\nDemyan Kimitsa <demyan.kimitsa@gmail.com>\nDick Porter <dick@acm.org>\nDietmar Planitzer <dave.pl@ping.at>\nDima Pasechnik <dimpase@gmail.com>\nDimitris Apostolou <dimitris.apostolou@icloud.com>\nDimitris Vyzovitis <vyzo@media.mit.edu>\nDimitry Andric <dim@freebsd.org>\nDjamel Magri <djamel.magri@googlemail.com>\nDoug Kaufman <dkaufman@rahul.net>\nDoug Moen <doug@moens.org>\nDouglas Steel <doug@wg.icl.co.uk>\nEli Barzilay <eli@racket-lang.org>\nElijah Taylor <elijahtaylor@google.com>\nElvenlord Elrond <elrond@samba-tng.org>\nEmmanual Stumpf\nEric Benson <eb@kaleida.com>\nEric Holk <eric.holk@gmail.com>\nErik M. Bray <erik.bray@lri.fr>\nFabian Ruffy <contact@ruffy.eu>\nFabian Thylman\nFabrice Fontaine <fontaine.fabrice@gmail.com>\nFergus Henderson <fjh@cs.mu.oz.au>\nFranklin Chen <chen@adi.com>\nFred Gilham <gilham@csl.sri.com>\nFred Stearns\nFriedrich Dominicus <friedrichdominicus@googlemail.com>\nFunda Wang <fundawang@yeah.net>\nGabor Drescher <gabor.drescher@cs.fau.de>\nGary Leavens <leavens@eecs.ucf.edu>\nGautham Venkatasubramanian <ahgamut@gmail.com>\nGeoff Norton <grompf@sublimeintervention.com>\nGeorge Koehler <kernigh@gmail.com>\nGeorge Talbot <Gtalbot@ansarisbio.com>\nGerard A Allan\nGlauco Masotti <glauco.masotti@libero.it>\nGreg Steuck <greg@nest.cx>\nGrzegorz Jakacki <jakacki@acm.org>\nGustavo Giraldez <ggiraldez@manas.com.ar>\nGustavo Rodriguez-Rivera <grr@cs.purdue.edu>\nH.J. Lu <hjl.tools@gmail.com>\nHamayama <hamay1010@gmail.com>\nHannes Mehnert <hannes@mehnert.org>\nHanno Boeck <hanno@gentoo.org>\nHans Boehm <boehm@acm.org>\nHans-Peter Nilsson <hp@axis.com>\nHenning Makholm <Henning@octoshape.com>\nHenrik Theiling <theiling@absint.com>\nHironori Sakamoto <hsaka@mth.biglobe.ne.jp>\nHiroshi Kawashima <kei@arch.sony.co.jp>\nHiroshi Yokota <yokota@netlab.cs.tsukuba.ac.jp>\nHubert Garavel <Hubert.Garavel@imag.fr>\nIain Sandoe <developer@sandoe-acoustics.co.uk>\nIan Piumarta <piumarta@prof.inria.fr>\nIan Searle <ians@eskimo.com>\nIgor Khavkine <i_khavki@alcor.concordia.ca>\nIlya Kurdyukov <ilyakurdyukov@altlinux.org>\nIvan Demakov <ivan@tgrad.nsk.su>\nIvan Maidanski <ivmai@mail.ru>\nIvan R <iarspider@gmail.com>\nJaap Boender <jaapb@netbsd.org>\nJack Andrews <effbiae@gmail.com>\nJacob Navia <jacob.navia@jacob.remcomp.fr>\nJake Hughes <jh@jakehughes.uk>\nJakub Jelinek <jakub@redhat.com>\nJakub Wojciech <jakub-w@riseup.net>\nJames Clark <jjc@jclark.com>\nJames Dominy\nJames Moran <jamesmo@unity3d.com>\nJan Alexander Steffens <jan.steffens@gmail.com>\nJan Wielemaker <J.Wielemaker@cs.vu.nl>\nJani Kajala <jani@sumea.com>\nJared McNeill <jmcneill@NetBSD.org>\nJasper Lievisse Adriaanse <jasper@openbsd.org>\nJay Krell <jaykrell@microsoft.com>\nJean-Baptiste Nivois\nJean-Claude Beaudoin <jean.claude.beaudoin@gmail.com>\nJean-Daniel Fekete <fekete@cs.umd.edu>\nJeaye Wilkerson <contact@jeaye.com>\nJeff Sturm <jsturm@one-point.com>\nJeffrey Hsu <hsu@soda.berkeley.edu>\nJeffrey Mark Siskind\nJeremy Fitzhardinge <jeremy@goop.org>\nJesper Peterson <jep@mtiame.mtia.oz.au>\nJesse Hull <jhull@parc.xerox.com>\nJesse Jones <jesjones@mindspring.com>\nJesse Rosenstock <jmr@ugcs.caltech.edu>\nJi-Yong Chung\nJie Liu <lj8175@gmail.com>\nJim Marshall <jim.marshall@wbemsolutions.com>\nJim Meyering <jim@meyering.net>\nJoao Abecasis <joao@abecasis.name>\nJoe Jones <joejo@unity3d.com>\nJoerg Sonnenberger <joerg@britannica.bec.de>\nJohannes Schmidt <jschmidt@avtrex.com>\nJohannes Totz <jtotz@ic.ac.uk>\nJohn Bowman <bowman@ualberta.ca>\nJohn Clements <clements@brinkerhoff.org>\nJohn David Anglin <dave.anglin@bell.net>\nJohn Ellis <ellis@parc.xerox.com>\nJohn Ericson <git@JohnEricson.me>\nJohn Merryweather Cooper <jmerry@mono-cvs.ximian.com>\nJon Moore <jonm@apache.org>\nJonas Echterhoff <jonas@unity3d.com>\nJonas Hahnfeld <hahnjo@hahnjo.de>\nJonathan Bachrach <jonathan@harlequin.com>\nJonathan Chambers <jonathan@unity3d.com>\nJonathan Clark\nJonathan Pryor <jpryor@novell.com>\nJosh Peterson <petersonjm1@gmail.com>\nJoshua Richardson <jric@chegg.com>\nJuan Jose Garcia-Ripoll <juanjose.garciaripoll@googlemail.com>\nJukka Jylanki <jujjyl@gmail.com>\nKai Tietz <ktietz70@googlemail.com>\nKaz Kojima <kkojima@rr.iij4u.or.jp>\nKazu Hirata <kazu@codesourcery.com>\nKazuhiro Inaoka <inaoka.kazuhiro@renesas.com>\nKeith Seitz <keiths@redhat.com>\nKenjiro Taura <tau@eidos.ic.i.u-tokyo.ac.jp>\nKenneth Schalk <schalk@cadtls.hlo.dec.com>\nKevin Kenny <kenny@m.cs.uiuc.edu>\nKevin Tew <tewk@racket-lang.org>\nKevin Warne <kevinw@direct.ca>\nKim Shrier <gitkim@westryn.net>\nKimura Wataru <kimuraw@i.nifty.jp>\nKirill A. Korinsky <kirill@korins.ky>\nKjetil Matheussen <k.s.matheussen@notam02.no>\nKlaus Treichel <ktreichel@web.de>\nKlemens Zwischenbrugger <ka7@la-evento.com>\nKnut Tvedten <knuttv@ifi.uio.no>\nKrister Walfridsson <cato@df.lth.se>\nKristian Kristensen <kk@cs.aau.dk>\nKristian Larsson <kristian@spritelink.net>\nKumar Srikantan\nKurt Miller <kurt@intricatesoftware.com>\nLars Farm <lars.farm@ite.mh.se>\nLaurent Morichetti <l_m@pacbell.net>\nLeonardo Taccari <iamleot@gmail.com>\nLinas Vepstas <linasvepstas@gmail.com>\nLinus Groh <mail@linusgroh.de>\nLoren J. Rittle <rittle@latour.labs.mot.com>\nLouis Zhuang <louis.zhuang@acm.org>\nLucas Holt <luke@foolishgames.com>\nLucas Meijer <lucas@unity3d.com>\nLudovic Courtes <ludo@gnu.org>\nMaarten Thibaut <mthibaut@cisco.com>\nMahder Gebremedhin <mahder.gebremedhin@liu.se>\nManuel A. Fernandez Montecelo <manuel.montezelo@gmail.com>\nManuel Serrano <serrano@cornas.inria.fr>\nMarc Recht <recht@netbsd.org>\nMarco Maggi <marco.maggi-ipsu@poste.it>\nMarcos Dione <Marcos_David.Dione@sophia.inria.fr>\nMarcus Herbert\nMarek Vasut <marex@denx.de>\nMargaret Fleck <mfleck@illinois.edu>\nMario Hoepfner <mario.hopfner@unity3d.com>\nMario Topf <mario.topf@unity3d.com>\nMarius Gerbershagen <marius.gerbershagen@gmail.com>\nMark Boulter <mboulter@vnet.ibm.com>\nMark Mitchell <mark@codesourcery.com>\nMark Reichert <markr@sirs.com>\nMark Sibly\nMark Weiser <weiser@ubiq.com>\nMartin Hirzel <hirzel@cs.colorado.edu>\nMartin Koeppe <mkoeppe@gmx.de>\nMartin Tauchmann <martintauchmann@bigfoot.com>\nMassimiliano Gubinelli <m.gubinelli@gmail.com>\nMatheus C. Franca <matheus-catarino@hotmail.com>\nMatheus Rambo <mrambo@grupodimed.com.br>\nMatt Austern <austern@google.com>\nMatthew Flatt <mflatt@plt-scheme.org>\nMatthias Andree <matthias.andree@gmx.de>\nMatthias Drochner <M.Drochner@fz-juelich.de>\nMatthieu Herrb <matthieu@openbsd.org>\nMaurizio Vairani <maurizio.vairani@cloverinformatica.it>\nMax Mouratov <mmouratov@gmail.com>\nMaximilian Downey Twiss <creatorsmithmdt@gmail.com>\nMaya Rashish <coypu@sdf.org>\nMelissa O'Neill <oneill@cs.sfu.ca>\nMichael Arnoldus <chime@proinf.dk>\nMichael DeRoy <deroymichael@gmail.com>\nMichael Fox <mfox@cavium.com>\nMichael Herring <khakionion@gmail.com>\nMichael Smith <msmith@spinnakernet.com>\nMichael Spertus <mps@geodesic.com>\nMichel Schinz <schinz@alphanet.ch>\nMiguel de Icaza <miguel@gnome.org>\nMikael Djurfeldt <mikael@djurfeldt.com>\nMike Frysinger <vapier@gentoo.org>\nMike Gran <spk121@yahoo.com>\nMike McGaughey <mmcg@cs.monash.edu.au>\nMike Stump <mrs@windriver.com>\nMitch Harris <maharri@uiuc.edu>\nMohan Embar <gnustuff@thisiscool.com>\nNaoyuki Sawa <sawa_naoyuki-1@yahoo.co.jp>\nNathanael Nerode <neroden@twcny.rr.com>\nNeale Ferguson <neale@mono-cvs.ximian.com>\nNeil Matthew <neil@tilde.co.uk>\nNeil Sharman <neil@cs.mu.oz.au>\nNguyen Thai Ngoc Duy <pclouds@gmail.com>\nNicolas Cannasse <ncannasse@motion-twin.com>\nNiibe Yutaka <gniibe@fsij.org>\nNikita Ermakov <coffe92@gmail.com>\nNiklas Therning <niklas@therning.org>\nNoah Lavine <noah.b.lavine@gmail.com>\nNobuyuki Hikichi <hikichi@sra.co.jp>\nOliver Kurth <oliver.kurth@innominate.com>\nOndrej Bilka <neleai@seznam.cz>\nPaolo Molaro <lupus@ximian.com>\nParag Patel <parag@netcom.com>\nPatrick Bridges <bridges@cs.arizona.edu>\nPatrick C. Beard <beard@netscape.com>\nPatrick Doyle <doylep@eecg.toronto.edu>\nPaul Bone <paul@bone.id.au>\nPaul Brook <paul@codesourcery.com>\nPaul Graham\nPaul Nash <paulnash@wildseed.com>\nPer Bothner <per@bothner.com>\nPeter Bigot <bigotp@acm.org>\nPeter Budai <peterbudai@hotmail.com>\nPeter Chubb <peterc@sour.sw.oz.au>\nPeter Colson <pcolson@connexus.net.au>\nPeter Elliott <pelliott@ualberta.ca>\nPeter Housel <housel@acm.org>\nPeter Monks <pmonks@iname.com>\nPeter Ross <pro@missioncriticalit.com>\nPeter Seebach <seebs@taniemarie.solon.com>\nPeter Wang <novalazy@gmail.com>\nPetr Krajca <krajcap@inf.upol.cz>\nPetr Salinger <Petr.Salinger@seznam.cz>\nPetter Urkedal <paurkedal@gmail.com>\nPhilip Brown <phil@opencsw.org>\nPhilipp Tomsich <phil@complang.tuwien.ac.at>\nPhilippe Queinnec <queinnec@enseeiht.fr>\nPhillip Musumeci <p.musumeci@ieee.org>\nPhong Vo <kpv@research.att.com>\nPierre de Rop\nPontus Rydin <P.Rydin@astea.se>\nQing Guo <delguoqing@hotmail.com>\nRadek Polak <psonek2@seznam.cz>\nRainer Orth <ro@cebitec.uni-bielefeld.de>\nRanjit Mathew <rmathew@gcc.gnu.org>\nRauli Ruohonen <rruohone@cc.hut.fi>\nRegis Cridlig <Regis.Cridlig@cl.cam.ac.uk>\nReimer Behrends <behrends@gmail.com>\nRenaud Blanch <renaud.blanch@lri.fr>\nRene Girard\nRex Dieter <rdieter@math.unl.edu>\nReza Shahidi\nRichard Earnshaw <rearnsha@arm.com>\nRichard Henderson <rth@redhat.com>\nRichard Sandiford <rsandifo@nildram.co.uk>\nRichard Zidlicky <Richard.Zidlicky@stud.informatik.uni-erlangen.de>\nRob Haack <rhaack@polaris.unm.edu>\nRobert Brazile <brazile@diamond.bbn.com>\nRobert Hensing <robert@roberthensing.nl>\nRodrigo Kumpera <kumpera@gmail.com>\nRoger Pack <rogerpack2005@gmail.com>\nRoger Sayle <roger@eyesopen.com>\nRoland McGrath <roland@redhat.com>\nRoman Hodek <Roman.Hodek@informatik.uni-erlangen.de>\nRomain Naour <romain.naour@gmail.com>\nRomano Paolo Tenca <rotenca@telvia.it>\nRutger Ovidius <ovidr@users.sourceforge.net>\nRyan Gonzalez <rymg19@gmail.com>\nRyan Murray <rmurray@debian.org>\nSalvador Eduardo Tropea <salvador@inti.gov.ar>\nSam James <sam@gentoo.org>\nSamuel Martin <s.martin49@gmail.com>\nSamuel Thibault <samuel.thibault@gnu.org>\nScott Ananian <cananian@lesser-magoo.lcs.mit.edu>\nScott Ferguson <scott.ferguson@unity3d.com>\nScott Schwartz <schwartz@groucho.cse.psu.edu>\nSebastian Schoner <sebastian.schoner@unity3d.com>\nSeonghyun Kim <sh8281.kim@samsung.com>\nShawn Wagner <shawnw@speakeasy.org>\nShea Levy <shea@shealevy.com>\nShiro Kawai <shiro@lava.net>\nSimon Gornall <simon@gornall.net>\nSimon Kainz <simon@familiekainz.at>\nSimon Posnjak <simon.posnjak@siol.net>\nSlava Sysoltsev <Viatcheslav.Sysoltsev@h-d-gmbh.de>\nSorawee Porncharoenwase <sorawee.pwase@gmail.com>\nssrlive <ssrlivebox@gmail.com>\nStefan Ring <stefanrin@gmail.com>\nStefano Rivera <stefano@rivera.za.net>\nSteve Youngs <steve@sxemacs.org>\nSugioka Toshinobu <sugioka@itonet.co.jp>\nSuzuki Toshiya <mpsuzuki@hiroshima-u.ac.jp>\nSven Hartrumpf <Sven.Hartrumpf@fernuni-hagen.de>\nSven Verdoolaege <skimo@kotnet.org>\nTakis Psarogiannakopoulos <takis@xfree86.org>\nTatsuya Bizenn <bizenn@visha.org>\nTautvydas Zilys <tautvydas.zilys@gmail.com>\nTerrell Russell <terrellrussell@gmail.com>\nThiemo Seufer <ths@networkno.de>\nThomas Funke <thf@zelator.in-berlin.de>\nThomas Klausner <tk@giga.or.at>\nThomas Linder Puls <thomas_linder_puls@hotmail.com>\nThomas Maier <Thomas.Maier@uni-kassel.de>\nThomas Schwinge <thomas@codesourcery.com>\nThomas Thiriez <thomas@twistedwave.com>\nThorsten Glaser <tg@debian.org>\nTilman Vogel <Tilman.Vogel@web.de>\nTim Bingham <tjb@zko.dec.com>\nTim Cannell <timcannell@unity3d.com>\nTim Gates <tim.gates@iress.com>\nTimothy N. Newsham <newsham@wiliki.eng.hawaii.edu>\nTom Tromey <tromey@cygnus.com>\nTommaso Tagliapietra <tommaso.tagliapietra@enel.it>\nToralf Foerster <toralf.foerster@gmx.de>\nToshio Endo <endo@is.titech.ac.jp>\nTsugutomo Enami <tsugutomo.enami@jp.sony.com>\nTum Nguyen <tum@veridicus.com>\nTyson Dowd <trd@cs.mu.oz.au>\nUchiyama Yasushi <uch@netbsd.org>\nUlrich Drepper <drepper@redhat.com>\nUlrich Weigand <Ulrich.Weigand@de.ibm.com>\nUros Bizjak <ubizjak@gmail.com>\nVernon Lee <scorpion@rice.edu>\nVictor Ivrii <ivrii@math.toronto.edu>\nVictor Romero <romerosanchezv@gmail.com>\nVineet Gupta <vgupta@synopsys.com>\nVitaly Magerya <vmagerya@gmail.com>\nVladimir Tsichevski <wowa@jet.msk.su>\nWalter Bright <walter@walterbright.com>\nWalter Underwood <wunder@hp-ses.sde.hp.com>\nWilson Ho <how@ivy.ucdavis.edu>\nWink Saville <wink@saville.com>\nWookey <wookey@wookware.org>\nwzx <wuzx1226@qq.com>\nXi Wang <xi.wang@gmail.com>\nXiaokun Zhu <xiaokun@aero.gla.ac.uk>\nYann Dirson <dirson@debian.org>\nYannis Bres <Yannis@bres.name>\nYao Zi <ziyao@disroot.org>\nYasuhiro Kimura <yasu@utahime.org>\nYuki Okumura <mjt@cltn.org>\nYusuke Suzuki <utatane.tea@gmail.com>\nYvan Roux <yvan.roux@linaro.org>\nZach Saw <zach.saw@gmail.com>\nZhang Na <zhangna@loongson.cn>\nZhiying Chen\nZhong Shao <zhong.shao@yale.edu>\nZoltan Varga <vargaz@gmail.com>\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 37.5634765625,
          "content": "#\n# Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n# Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n# Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n# Copyright (c) 2000-2010 by Hewlett-Packard Company.  All rights reserved.\n# Copyright (c) 2010-2022 Ivan Maidanski\n##\n# THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n# OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n##\n# Permission is hereby granted to use or copy this program\n# for any purpose, provided the above notices are retained on all copies.\n# Permission to modify the code and to distribute modified code is granted,\n# provided the above notices are retained, and a notice that the code was\n# modified is included with the above copyright notice.\n##\n\n#\n#  get cmake and run:\n#    cmake -G \"Visual Studio 8 2005\"\n#  in the same dir as this file\n#  this will generate gc.sln\n#\n\ncmake_minimum_required(VERSION 3.10)\n\nset(PACKAGE_VERSION 8.3.0)\n# Version must match that in AC_INIT of configure.ac and that in README.\n# Version must conform to: [0-9]+[.][0-9]+[.][0-9]+\n\n# Info (current:revision:age) for the Libtool versioning system.\n# These values should match those in cord/cord.am and Makefile.am.\nset(LIBCORD_VER_INFO    6:1:5)\nset(LIBGC_VER_INFO      6:3:5)\nset(LIBGCCPP_VER_INFO   6:0:5)\n\noption(enable_cplusplus \"C++ support\" OFF)\nif (enable_cplusplus)\n  project(gc)\nelse()\n  project(gc C)\nendif()\n\nif (POLICY CMP0057)\n  # Required for CheckLinkerFlag, at least.\n  cmake_policy(SET CMP0057 NEW)\nendif()\n\ninclude(CheckCCompilerFlag)\ninclude(CheckCSourceCompiles)\ninclude(CheckFunctionExists)\ninclude(CheckIncludeFile)\ninclude(CheckSymbolExists)\ninclude(CMakePackageConfigHelpers)\ninclude(CTest)\ninclude(GNUInstallDirs)\n\nif (NOT (${CMAKE_VERSION} VERSION_LESS \"3.18.0\"))\n  include(CheckLinkerFlag)\nendif()\n\nset(default_enable_threads ON)\nfind_package(Threads QUIET)\nif (NOT (CMAKE_USE_PTHREADS_INIT OR CMAKE_USE_WIN32_THREADS_INIT) OR EMSCRIPTEN OR WASI)\n  set(default_enable_threads OFF)\nendif()\n\n# Customize the build by passing \"-D<option_name>=ON|OFF\" in the command line.\noption(BUILD_SHARED_LIBS \"Build shared libraries\" ON)\noption(build_cord \"Build cord library\" ON)\noption(build_tests \"Build tests\" OFF)\noption(enable_docs \"Build and install documentation\" ON)\noption(enable_threads \"Support threads\" ${default_enable_threads})\noption(enable_parallel_mark \"Parallelize marking and free list construction\" ON)\noption(enable_thread_local_alloc \"Turn on thread-local allocation optimization\" ON)\noption(enable_threads_discovery \"Enable threads discovery in GC\" ON)\noption(enable_rwlock \"Enable reader mode of the allocator lock\" OFF)\noption(enable_throw_bad_alloc_library \"Turn on C++ gctba library build\" ON)\noption(enable_gcj_support \"Support for gcj\" ON)\noption(enable_sigrt_signals \"Use SIGRTMIN-based signals for thread suspend/resume\" OFF)\noption(enable_valgrind_tracking \"Support tracking GC_malloc and friends for heap profiling tools\" OFF)\noption(enable_gc_debug \"Support for pointer back-tracing\" OFF)\noption(disable_gc_debug \"Disable debugging like GC_dump and its callees\" OFF)\noption(enable_java_finalization \"Support for java finalization\" ON)\noption(enable_atomic_uncollectable \"Support for atomic uncollectible allocation\" ON)\noption(enable_redirect_malloc \"Redirect malloc and friends to GC routines\" OFF)\noption(enable_disclaim \"Support alternative finalization interface\" ON)\noption(enable_dynamic_pointer_mask \"Support pointer mask/shift set at runtime\" OFF)\noption(enable_large_config \"Optimize for large heap or root set\" OFF)\noption(enable_gc_assertions \"Enable collector-internal assertion checking\" OFF)\noption(enable_mmap \"Use mmap instead of sbrk to expand the heap\" OFF)\noption(enable_munmap \"Return page to the OS if empty for N collections\" ON)\noption(enable_dynamic_loading \"Enable tracing of dynamic library data roots\" ON)\noption(enable_register_main_static_data \"Perform the initial guess of data root sets\" ON)\noption(enable_checksums \"Report erroneously cleared dirty bits\" OFF)\noption(enable_werror \"Pass -Werror to the C compiler (treat warnings as errors)\" OFF)\noption(enable_single_obj_compilation \"Compile all libgc source files into single .o\" OFF)\noption(disable_single_obj_compilation \"Compile each libgc source file independently\" OFF)\noption(enable_handle_fork \"Attempt to ensure a usable collector after fork()\" ON)\noption(disable_handle_fork \"Prohibit installation of pthread_atfork() handlers\" OFF)\noption(enable_emscripten_asyncify \"Use Emscripten asyncify feature\" OFF)\noption(install_headers \"Install header and pkg-config metadata files\" ON)\noption(with_libatomic_ops \"Use an external libatomic_ops\" OFF)\noption(without_libatomic_ops \"Use atomic_ops.h in libatomic_ops/src\" OFF)\n\n# Override the default build type to RelWithDebInfo (this instructs cmake to\n# pass -O2 -g -DNDEBUG options to the compiler by default).\nif (NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)\n  set(CMAKE_BUILD_TYPE \"RelWithDebInfo\" CACHE\n      STRING \"Choose the type of build.\" FORCE)\n  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY\n               STRINGS \"Debug\" \"Release\" \"RelWithDebInfo\" \"MinSizeRel\")\nendif()\n\n# Convert VER_INFO values to [SO]VERSION ones.\nif (BUILD_SHARED_LIBS)\n  # cord:\n  string(REGEX REPLACE \"(.+):.+:.+\"  \"\\\\1\" cord_cur ${LIBCORD_VER_INFO})\n  string(REGEX REPLACE \".+:(.+):.+\"  \"\\\\1\" cord_rev ${LIBCORD_VER_INFO})\n  string(REGEX REPLACE \".+:.+:(.+)$\" \"\\\\1\" cord_age ${LIBCORD_VER_INFO})\n  math(EXPR CORD_SOVERSION \"${cord_cur} - ${cord_age}\")\n  set(CORD_VERSION_PROP \"${CORD_SOVERSION}.${cord_age}.${cord_rev}\")\n  message(STATUS \"CORD_VERSION_PROP = ${CORD_VERSION_PROP}\")\n  # gc:\n  string(REGEX REPLACE \"(.+):.+:.+\"  \"\\\\1\" gc_cur ${LIBGC_VER_INFO})\n  string(REGEX REPLACE \".+:(.+):.+\"  \"\\\\1\" gc_rev ${LIBGC_VER_INFO})\n  string(REGEX REPLACE \".+:.+:(.+)$\" \"\\\\1\" gc_age ${LIBGC_VER_INFO})\n  math(EXPR GC_SOVERSION \"${gc_cur} - ${gc_age}\")\n  set(GC_VERSION_PROP \"${GC_SOVERSION}.${gc_age}.${gc_rev}\")\n  message(STATUS \"GC_VERSION_PROP = ${GC_VERSION_PROP}\")\n  # gccpp and gctba:\n  string(REGEX REPLACE \"(.+):.+:.+\"  \"\\\\1\" gccpp_cur ${LIBGCCPP_VER_INFO})\n  string(REGEX REPLACE \".+:(.+):.+\"  \"\\\\1\" gccpp_rev ${LIBGCCPP_VER_INFO})\n  string(REGEX REPLACE \".+:.+:(.+)$\" \"\\\\1\" gccpp_age ${LIBGCCPP_VER_INFO})\n  math(EXPR GCCPP_SOVERSION \"${gccpp_cur} - ${gccpp_age}\")\n  set(GCCPP_VERSION_PROP \"${GCCPP_SOVERSION}.${gccpp_age}.${gccpp_rev}\")\n  message(STATUS \"GCCPP_VERSION_PROP = ${GCCPP_VERSION_PROP}\")\nendif(BUILD_SHARED_LIBS)\n\nadd_definitions(\"-DALL_INTERIOR_POINTERS\")\nadd_definitions(\"-DNO_EXECUTE_PERMISSION\")\n\n# Set struct packing alignment to word (instead of 1-byte).\nif (BORLAND)\n  add_compile_options(/a4)\nelseif (WATCOM)\n  add_compile_options(/zp4)\nendif()\n\n# Output all warnings.\nif (BORLAND)\n  # All warnings except for particular ones.\n  add_compile_options(/w /w-aus /w-ccc /w-inl /w-pro /w-rch /w-use)\nelseif (MSVC)\n  # All warnings but ignoring \"conditional expression is constant\" one.\n  add_compile_options(/W4 /wd4127)\nelseif (WATCOM)\n  add_compile_options(/wx)\n  if (enable_gc_assertions)\n    # Suppress \"unreachable code\" warning in GC_ASSERT() if some constant\n    # non-zero expression is given as the argument.\n    add_compile_options(/wcd=201)\n  endif()\n  if (enable_threads)\n    # Suppress \"missing return value\" wcc warning for AO_test_and_set_full()\n    # and AO_char_fetch_and_add_full() in AO msftc/x86.h file.\n    add_compile_options($<$<COMPILE_LANGUAGE:C>:/wcd=107>)\n  endif(enable_threads)\nelse()\n  add_compile_options(-Wall)\n  add_compile_options(-Wextra)\n  # TODO: add -[W]pedantic -Wno-long-long\nendif()\n\nif (WIN32)\n  # Disable MS crt security warnings reported e.g. for getenv, strcpy.\n  add_definitions(\"-D_CRT_SECURE_NO_DEPRECATE\")\nendif()\n\ninclude_directories(include)\n\nset(SRC allchblk.c alloc.c blacklst.c dbg_mlc.c dyn_load.c finalize.c\n        headers.c mach_dep.c malloc.c mallocx.c mark.c mark_rts.c misc.c\n        new_hblk.c obj_map.c os_dep.c ptr_chck.c reclaim.c typd_mlc.c)\n\nset(NODIST_SRC)\nset(ATOMIC_OPS_LIBS)\nset(ATOMIC_OPS_LIBS_CMAKE)\nset(THREADDLLIBS_LIST)\nset(NEED_LIB_RT)\n\nset(_HOST ${CMAKE_SYSTEM_PROCESSOR}-unknown-${CMAKE_SYSTEM})\nstring(TOLOWER ${_HOST} HOST)\nmessage(STATUS \"TARGET = ${HOST}\")\n\nif (enable_threads)\n  find_package(Threads REQUIRED)\n  message(STATUS \"Thread library: ${CMAKE_THREAD_LIBS_INIT}\")\n  include_directories(${Threads_INCLUDE_DIR})\n  if (with_libatomic_ops)\n    if (without_libatomic_ops)\n      message(FATAL_ERROR\n        \"with_libatomic_ops and without_libatomic_ops are mutually exclusive\")\n    endif()\n    set(ATOMIC_OPS_LIBS \"-latomic_ops\")\n    find_package(Atomic_ops CONFIG)\n    if (Atomic_ops_FOUND)\n      get_target_property(AO_INCLUDE_DIRS Atomic_ops::atomic_ops\n                          INTERFACE_INCLUDE_DIRECTORIES)\n      include_directories(${AO_INCLUDE_DIRS})\n      message(STATUS \"AO_INCLUDE_DIRS = ${AO_INCLUDE_DIRS}\")\n      set(ATOMIC_OPS_LIBS_CMAKE Atomic_ops::atomic_ops)\n    else()\n      set(ATOMIC_OPS_LIBS_CMAKE ${ATOMIC_OPS_LIBS})\n    endif()\n  elseif (without_libatomic_ops)\n    include_directories(libatomic_ops/src)\n    # In the tests we use the source files directly from libatomic_ops subtree.\n    set(NODIST_SRC libatomic_ops/src/atomic_ops.c)\n    if (CMAKE_C_COMPILER_ID STREQUAL \"SunPro\")\n      # SunCC compiler on SunOS (Solaris).\n      set(NODIST_SRC ${NODIST_SRC} libatomic_ops/src/atomic_ops_sysdeps.S)\n    endif()\n  elseif (BORLAND OR MSVC OR WATCOM)\n    include_directories(libatomic_ops/src)\n    # Note: alternatively, use CFLAGS_EXTRA to pass -I<...>/libatomic_ops/src.\n  else()\n    # Assume the compiler supports GCC atomic intrinsics.\n    add_definitions(\"-DGC_BUILTIN_ATOMIC\")\n  endif()\n  set(THREADDLLIBS_LIST ${CMAKE_THREAD_LIBS_INIT})\n  if (${CMAKE_DL_LIBS} MATCHES ^[^-].*)\n    # Some cmake versions have a broken non-empty CMAKE_DL_LIBS omitting \"-l\".\n    # Assume CMAKE_DL_LIBS contains just one library.\n    set(THREADDLLIBS_LIST ${THREADDLLIBS_LIST} -l${CMAKE_DL_LIBS})\n  else()\n    set(THREADDLLIBS_LIST ${THREADDLLIBS_LIST} ${CMAKE_DL_LIBS})\n  endif()\n  # Thread support detection.\n  if (CMAKE_USE_PTHREADS_INIT)\n    set(SRC ${SRC} gc_dlopen.c pthread_start.c pthread_support.c)\n    if (CYGWIN OR WIN32)\n      set(SRC ${SRC} win32_threads.c)\n    else()\n      if (APPLE)\n        set(SRC ${SRC} darwin_stop_world.c)\n      else()\n        set(SRC ${SRC} pthread_stop_world.c)\n      endif()\n    endif()\n    if (HOST MATCHES .*-.*-hpux10.*)\n      message(FATAL_ERROR \"HP/UX 10 POSIX threads are not supported.\")\n    endif()\n    # Common defines for POSIX platforms.\n    add_definitions(\"-DGC_THREADS\")\n    add_definitions(\"-D_REENTRANT\")\n    if (enable_parallel_mark)\n      add_definitions(\"-DPARALLEL_MARK\")\n    endif()\n    if (enable_thread_local_alloc)\n      add_definitions(\"-DTHREAD_LOCAL_ALLOC\")\n      set(SRC ${SRC} specific.c thread_local_alloc.c)\n    endif()\n    message(\"Explicit GC_INIT() calls may be required.\")\n    if (HOST MATCHES .*-.*-hpux11.*)\n      message(\"Only HP/UX 11 POSIX threads are supported.\")\n      add_definitions(\"-D_POSIX_C_SOURCE=199506L\")\n      set(NEED_LIB_RT ON)\n    elseif (HOST MATCHES .*-.*-netbsd.*)\n      add_definitions(\"-D_PTHREADS\")\n      set(NEED_LIB_RT ON)\n    elseif (CMAKE_C_COMPILER_ID STREQUAL \"SunPro\")\n      set(NEED_LIB_RT ON)\n    endif()\n    if (WIN32) # AND NOT CYGWIN\n      # Does not provide process fork functionality.\n    elseif (enable_handle_fork AND NOT disable_handle_fork)\n      add_definitions(\"-DHANDLE_FORK\")\n    endif()\n    if (enable_sigrt_signals)\n      add_definitions(\"-DGC_USESIGRT_SIGNALS\")\n    endif()\n  elseif (CMAKE_USE_WIN32_THREADS_INIT)\n    add_definitions(\"-DGC_THREADS\")\n    if (enable_parallel_mark)\n      add_definitions(\"-DPARALLEL_MARK\")\n    endif()\n    if (enable_thread_local_alloc AND (enable_parallel_mark OR NOT BUILD_SHARED_LIBS))\n      # Imply THREAD_LOCAL_ALLOC unless GC_DLL.\n      add_definitions(\"-DTHREAD_LOCAL_ALLOC\")\n      set(SRC ${SRC} thread_local_alloc.c)\n    endif()\n    add_definitions(\"-DEMPTY_GETENV_RESULTS\")\n    set(SRC ${SRC} pthread_start.c) # in case client defines GC_WIN32_PTHREADS\n    set(SRC ${SRC} pthread_support.c win32_threads.c)\n  elseif (CMAKE_HP_PTHREADS_INIT OR CMAKE_USE_SPROC_INIT)\n    message(FATAL_ERROR \"Unsupported thread package\")\n  endif()\n  if (BORLAND)\n    # Workaround \"cannot locate assembly file\" and \"out of hash space\"\n    # compilation errors, \"restarting compile using assembly\" warning.\n    add_definitions(\"-DAO_NO_ASM_XADD\")\n    add_definitions(\"-DAO_NO_ASM_XCHG\")\n  endif()\nendif(enable_threads)\n\n# Check whether -lrt linker option is needed to use clock_gettime.\nif (NOT NEED_LIB_RT)\n  check_function_exists(clock_gettime HAVE_CLOCK_GETTIME_DIRECTLY)\n  if (NOT HAVE_CLOCK_GETTIME_DIRECTLY)\n    # Use of clock_gettime() probably requires linking with \"rt\" library.\n    set(NEED_LIB_RT ON)\n  endif()\nendif()\n\n# Locate and use \"rt\" library if needed (and the library is available).\nif (NEED_LIB_RT)\n  find_library(LIBRT rt)\n  if (LIBRT)\n    set(THREADDLLIBS_LIST ${THREADDLLIBS_LIST} ${LIBRT})\n  endif()\nendif(NEED_LIB_RT)\n\nif (disable_handle_fork)\n  add_definitions(\"-DNO_HANDLE_FORK\")\nendif()\n\nif (enable_gcj_support)\n  add_definitions(\"-DGC_GCJ_SUPPORT\")\n  if (enable_threads AND NOT (enable_thread_local_alloc AND HOST MATCHES .*-.*-kfreebsd.*-gnu))\n    # FIXME: For a reason, gctest hangs up on kFreeBSD if both of\n    # THREAD_LOCAL_ALLOC and GC_ENABLE_SUSPEND_THREAD are defined.\n    add_definitions(\"-DGC_ENABLE_SUSPEND_THREAD\")\n  endif()\n  set(SRC ${SRC} gcj_mlc.c)\nendif(enable_gcj_support)\n\nif (enable_disclaim)\n  add_definitions(\"-DENABLE_DISCLAIM\")\n  set(SRC ${SRC} fnlz_mlc.c)\nendif()\n\nif (enable_dynamic_pointer_mask)\n  add_definitions(\"-DDYNAMIC_POINTER_MASK\")\nendif()\n\nif (enable_java_finalization)\n  add_definitions(\"-DJAVA_FINALIZATION\")\nendif()\n\nif (enable_atomic_uncollectable)\n  add_definitions(\"-DGC_ATOMIC_UNCOLLECTABLE\")\nendif()\n\nif (enable_valgrind_tracking)\n  add_definitions(\"-DVALGRIND_TRACKING\")\nendif()\n\nif (enable_gc_debug)\n  add_definitions(\"-DDBG_HDRS_ALL\")\n  add_definitions(\"-DKEEP_BACK_PTRS\")\n  if (HOST MATCHES i.86-.*-dgux.*|.*-.*-.*linux.*)\n    add_definitions(\"-DMAKE_BACK_GRAPH\")\n    if (HOST MATCHES .*-.*-.*linux.* AND NOT (HOST MATCHES e2k-.*-linux.*))\n      add_definitions(\"-DSAVE_CALL_COUNT=8\")\n    endif()\n    set(SRC ${SRC} backgraph.c)\n  endif()\nendif(enable_gc_debug)\n\nif (disable_gc_debug)\n  add_definitions(\"-DNO_DEBUGGING\")\nelseif (WINCE)\n  # Read environment variables from \"<program>.gc.env\" file.\n  add_definitions(\"-DGC_READ_ENV_FILE\")\nendif()\n\nif (enable_redirect_malloc)\n  if (enable_gc_debug)\n    add_definitions(\"-DREDIRECT_MALLOC=GC_debug_malloc_replacement\")\n    add_definitions(\"-DREDIRECT_REALLOC=GC_debug_realloc_replacement\")\n    add_definitions(\"-DREDIRECT_FREE=GC_debug_free\")\n  else()\n    add_definitions(\"-DREDIRECT_MALLOC=GC_malloc\")\n  endif()\n  if (WIN32)\n    add_definitions(\"-DREDIRECT_MALLOC_IN_HEADER\")\n  else()\n    add_definitions(\"-DGC_USE_DLOPEN_WRAP\")\n  endif()\nendif(enable_redirect_malloc)\n\nif (enable_mmap OR enable_munmap)\n  add_definitions(\"-DUSE_MMAP\")\n  if (enable_munmap)\n    add_definitions(\"-DUSE_MUNMAP\")\n  endif(enable_munmap)\nendif()\n\nif (NOT enable_dynamic_loading)\n  add_definitions(\"-DIGNORE_DYNAMIC_LOADING\")\nendif()\n\nif (NOT enable_register_main_static_data)\n  add_definitions(\"-DGC_DONT_REGISTER_MAIN_STATIC_DATA\")\nendif()\n\nif (enable_large_config)\n  add_definitions(\"-DLARGE_CONFIG\")\nendif()\n\nif (enable_gc_assertions)\n  add_definitions(\"-DGC_ASSERTIONS\")\n  # TODO: pass -Wno-missing-prototypes (if supported) to turn off the clang\n  # warning for STATIC functions.\nendif()\n\nif (NOT enable_threads_discovery)\n  add_definitions(\"-DGC_NO_THREADS_DISCOVERY\")\nendif()\n\nif (enable_rwlock)\n  # Use rwlock for the allocator lock instead of mutex.\n  add_definitions(\"-DUSE_RWLOCK\")\nendif()\n\nif (enable_checksums)\n  if (enable_munmap OR enable_threads)\n    message(FATAL_ERROR \"CHECKSUMS not compatible with USE_MUNMAP or threads\")\n  endif()\n  add_definitions(\"-DCHECKSUMS\")\n  set(SRC ${SRC} checksums.c)\nendif(enable_checksums)\n\nif (enable_werror)\n  if (BORLAND)\n    add_compile_options(/w!)\n  elseif (MSVC)\n    add_compile_options(/WX)\n    # Workaround \"typedef ignored on left of ...\" warning reported in\n    # imagehlp.h of e.g. Windows Kit 8.1.\n    add_compile_options(/wd4091)\n  elseif (WATCOM)\n    add_compile_options(/we)\n  else()\n    add_compile_options(-Werror)\n  endif()\nendif(enable_werror)\n\nif (enable_single_obj_compilation OR (BUILD_SHARED_LIBS AND NOT disable_single_obj_compilation))\n  set(SRC extra/gc.c) # override SRC\n  if (enable_threads AND CMAKE_USE_PTHREADS_INIT AND NOT (APPLE OR CYGWIN OR WIN32))\n    add_definitions(\"-DGC_PTHREAD_START_STANDALONE\")\n    set(SRC ${SRC} pthread_start.c)\n  endif()\nendif()\n\n# Add implementation of backtrace() and backtrace_symbols().\nif (MSVC)\n  set(SRC ${SRC} extra/msvc_dbg.c)\nendif()\n\n# Declare that the libraries do not refer to external symbols.\nif (BUILD_SHARED_LIBS AND NOT (APPLE OR ${CMAKE_SYSTEM_NAME} MATCHES \"BSD\"))\n  # Note: performed before CMAKE_REQUIRED_FLAGS is updated with \"-c\".\n  if (${CMAKE_VERSION} VERSION_LESS \"3.18.0\")\n    set(WL_NO_UNDEFINED_OPT \"-Wl,--no-undefined\")\n    check_c_compiler_flag(${WL_NO_UNDEFINED_OPT} HAVE_FLAG_WL_NO_UNDEFINED)\n  else()\n    set(WL_NO_UNDEFINED_OPT \"LINKER:--no-undefined\")\n    check_linker_flag(C \"${WL_NO_UNDEFINED_OPT}\" HAVE_FLAG_WL_NO_UNDEFINED)\n  endif()\nendif()\n\n# Instruct check_c_source_compiles to skip linking.\n# Alternatively, we could set CMAKE_REQUIRED_LIBRARIES properly.\nSET(CMAKE_REQUIRED_FLAGS \"-c\")\n\nif (NOT (BORLAND OR MSVC OR WATCOM))\n  # Instruct check_c_source_compiles and similar CMake checks not to ignore\n  # compiler warnings (like \"implicit declaration of function\").\n  check_c_compiler_flag(-Werror HAVE_FLAG_WERROR)\n  if (HAVE_FLAG_WERROR)\n    check_c_compiler_flag(-Wno-unused-command-line-argument\n                          HAVE_FLAG_WNO_UNUSED_CMDLINE_ARG)\n    SET(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} -Werror\")\n    # Prevent \"linker input unused\" error in further check_c_compiler_flag.\n    if (HAVE_FLAG_WNO_UNUSED_CMDLINE_ARG)\n      SET(CMAKE_REQUIRED_FLAGS\n          \"${CMAKE_REQUIRED_FLAGS} -Wno-unused-command-line-argument\")\n    endif()\n  endif(HAVE_FLAG_WERROR)\n  # Prevent \"__builtin_return_address with nonzero argument is unsafe\" warning.\n  check_c_compiler_flag(-Wno-frame-address HAVE_FLAG_WNO_FRAME_ADDRESS)\n  if (HAVE_FLAG_WNO_FRAME_ADDRESS)\n    add_compile_options(-Wno-frame-address)\n  endif(HAVE_FLAG_WNO_FRAME_ADDRESS)\nendif()\n\nif (BUILD_SHARED_LIBS)\n  add_definitions(\"-DGC_DLL\")\n  # Pass -fvisibility=hidden option if supported.\n  check_c_compiler_flag(-fvisibility=hidden HAVE_FLAG_F_VISIBILITY_HIDDEN)\n  if (HAVE_FLAG_F_VISIBILITY_HIDDEN)\n    add_definitions(\"-DGC_VISIBILITY_HIDDEN_SET\")\n    add_compile_options(-fvisibility=hidden)\n  else()\n    add_definitions(\"-DGC_NO_VISIBILITY\")\n  endif()\nelse()\n  add_definitions(\"-DGC_NOT_DLL\")\n  if (WIN32)\n    # Do not require the clients to link with \"user32\" system library.\n    add_definitions(\"-DDONT_USE_USER32_DLL\")\n  endif(WIN32)\nendif()\n\n# Extra user-defined flags to pass both to C and C++ compilers.\nif (DEFINED CFLAGS_EXTRA)\n  separate_arguments(CFLAGS_EXTRA_LIST UNIX_COMMAND \"${CFLAGS_EXTRA}\")\n  add_compile_options(${CFLAGS_EXTRA_LIST})\nendif()\n\n# Check whether execinfo.h header file is present.\ncheck_include_file(execinfo.h HAVE_EXECINFO_H)\nif (NOT HAVE_EXECINFO_H)\n  add_definitions(\"-DGC_MISSING_EXECINFO_H\")\nendif()\n\ncheck_include_file(sys/types.h HAVE_SYS_TYPES_H)\nif (HAVE_SYS_TYPES_H)\n  add_definitions(\"-DHAVE_SYS_TYPES_H\")\nendif()\n\nif (NOT WIN32)\n  check_include_file(unistd.h HAVE_UNISTD_H)\n  if (HAVE_UNISTD_H)\n    add_definitions(\"-DHAVE_UNISTD_H\")\n  endif()\nendif()\n\n# Check for getcontext (uClibc can be configured without it, for example).\nif (NOT (BORLAND OR MSVC))\n  check_function_exists(getcontext HAVE_GETCONTEXT)\n  if (HAVE_GETCONTEXT AND NOT APPLE)\n    # Double check getcontext() is available (needed at least on OpenBSD 7.3).\n    # Note: OS X is excluded here because the header filename differs.\n    check_c_source_compiles(\"\n#include <ucontext.h>\\n\nint main(void) { ucontext_t ctxt; (void)getcontext(&ctxt); return 0; }\"\n      HAVE_GETCONTEXT_FUNC)\n    if (NOT HAVE_GETCONTEXT_FUNC)\n      set(HAVE_GETCONTEXT OFF)\n    endif()\n  endif()\n  if (NOT HAVE_GETCONTEXT)\n    add_definitions(\"-DNO_GETCONTEXT\")\n  endif()\nendif()\n\n# Check whether dl_iterate_phdr exists (as a strong symbol).\nif (NOT (APPLE OR CYGWIN OR WIN32))\n  check_function_exists(dl_iterate_phdr HAVE_DL_ITERATE_PHDR)\n  if (HAVE_DL_ITERATE_PHDR)\n    add_definitions(\"-DHAVE_DL_ITERATE_PHDR\")\n  endif(HAVE_DL_ITERATE_PHDR)\nendif()\n\n# Check for pthread_sigmask and sigset_t.\nif (enable_threads AND CMAKE_USE_PTHREADS_INIT)\n  if (NOT (APPLE OR CYGWIN OR WIN32))\n    check_c_source_compiles(\"\n#define _GNU_SOURCE 1\\n\n#include <pthread.h>\\n\n#include <signal.h>\\n\nint main(void) { sigset_t t; (void)pthread_sigmask(SIG_BLOCK, 0, &t); return 0; }\"\n      HAVE_PTHREAD_SIGMASK)\n    if (HAVE_PTHREAD_SIGMASK)\n      # Define to use 'pthread_sigmask' function if needed.\n      add_definitions(\"-DGC_HAVE_PTHREAD_SIGMASK\")\n    endif(HAVE_PTHREAD_SIGMASK)\n  endif()\nendif()\n\ncheck_symbol_exists(sigsetjmp setjmp.h HAVE_SIGSETJMP)\nif (NOT HAVE_SIGSETJMP)\n  add_definitions(\"-DGC_NO_SIGSETJMP\")\nendif()\n\n# Build with GC_wcsdup() support if possible.\ncheck_symbol_exists(wcslen wchar.h HAVE_WCSLEN)\nif (HAVE_WCSLEN)\n  add_definitions(\"-DGC_REQUIRE_WCSDUP\")\nendif()\n\n# pthread_setname_np, if available, may have 1, 2 or 3 arguments.\nif (enable_threads AND CMAKE_USE_PTHREADS_INIT)\n  check_c_source_compiles(\"\n#define _GNU_SOURCE 1\\n\n#include <pthread.h>\\n\nint main(void) { (void)pthread_setname_np(\\\"thread-name\\\"); return 0; }\"\n    HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID)\n  if (HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID)\n    # Define to use 'pthread_setname_np(const char*)' function.\n    add_definitions(\"-DHAVE_PTHREAD_SETNAME_NP_WITHOUT_TID\")\n  else()\n    check_c_source_compiles(\"\n#define _GNU_SOURCE 1\\n\n#include <pthread.h>\\n\nint main(void) {\\n\n  (void)pthread_setname_np(pthread_self(), \\\"thread-name-%u\\\", 0); return 0; }\"\n      HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG)\n    if (HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG)\n      # Define to use 'pthread_setname_np(pthread_t, const char*, void *)'.\n      add_definitions(\"-DHAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG\")\n    else()\n      check_c_source_compiles(\"\n#define _GNU_SOURCE 1\\n\n#include <pthread.h>\\n\nint main(void) {\\n\n  (void)pthread_setname_np(pthread_self(), \\\"thread-name\\\"); return 0; }\"\n        HAVE_PTHREAD_SETNAME_NP_WITH_TID)\n      if (HAVE_PTHREAD_SETNAME_NP_WITH_TID)\n        # Define to use 'pthread_setname_np(pthread_t, const char*)' function.\n        add_definitions(\"-DHAVE_PTHREAD_SETNAME_NP_WITH_TID\")\n      else()\n        check_c_source_compiles(\"\n#include <pthread.h>\\n\n#include <pthread_np.h>\\n\nint main(void) {\\n\n  pthread_set_name_np(pthread_self(), \\\"thread-name\\\"); return 0; }\"\n          HAVE_PTHREAD_SET_NAME_NP)\n        if (HAVE_PTHREAD_SET_NAME_NP)\n          # Define to use 'pthread_set_name_np(pthread_t, const char*)'.\n          add_definitions(\"-DHAVE_PTHREAD_SET_NAME_NP\")\n        endif()\n      endif(HAVE_PTHREAD_SETNAME_NP_WITH_TID)\n    endif(HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG)\n  endif(HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID)\nendif()\n\n# Check for dladdr (used for debugging).\ncheck_c_source_compiles(\"\n#define _GNU_SOURCE 1\\n\n#include <dlfcn.h>\\n\nint main(void) { Dl_info info; (void)dladdr(\\\"\\\", &info); return 0; }\"\n  HAVE_DLADDR)\nif (HAVE_DLADDR)\n  # Define to use 'dladdr' function.\n  add_definitions(\"-DHAVE_DLADDR\")\nendif()\n\n# Check for emscripten; use asyncify feature if requested.\ncheck_c_source_compiles(\"\n#ifndef __EMSCRIPTEN__\\n\n# error This is not Emscripten\\n\n#endif\\n\nint main(void) { return 0; }\"\n  EMSCRIPTEN)\nif (EMSCRIPTEN AND enable_emscripten_asyncify)\n  # Use this option if your program is targeting -sASYNCIFY.  The latter is\n  # required to scan the stack, ASYNCIFY_STACK_SIZE is probably needed for\n  # gctest only.\n  add_definitions(\"-DEMSCRIPTEN_ASYNCIFY\")\n  set(CMAKE_EXE_LINKER_FLAGS\n        \"${CMAKE_EXE_LINKER_FLAGS} -sASYNCIFY -sASYNCIFY_STACK_SIZE=128000\")\nendif()\n\nadd_library(gc ${SRC})\nadd_library(bdwgc::gc ALIAS gc)\ntarget_link_libraries(gc\n                PRIVATE ${ATOMIC_OPS_LIBS_CMAKE} ${THREADDLLIBS_LIST})\ntarget_include_directories(gc INTERFACE\n        \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\"\n        \"$<INSTALL_INTERFACE:include>\")\n\nif (enable_cplusplus)\n  if (BORLAND OR MSVC OR WATCOM)\n    add_library(gccpp gc_badalc.cpp gc_cpp.cpp)\n  else()\n    add_library(gccpp gc_badalc.cc gc_cpp.cc)\n  endif()\n  add_library(bdwgc::gccpp ALIAS gccpp)\n  target_link_libraries(gccpp PRIVATE gc)\n  target_include_directories(gccpp INTERFACE\n        \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\"\n        \"$<INSTALL_INTERFACE:include>\")\n  if (enable_throw_bad_alloc_library)\n    # The same as gccpp but contains only gc_badalc.\n    if (BORLAND OR MSVC OR WATCOM)\n      add_library(gctba gc_badalc.cpp)\n    else()\n      add_library(gctba gc_badalc.cc)\n    endif()\n    add_library(bdwgc::gctba ALIAS gctba)\n    target_link_libraries(gctba PRIVATE gc)\n    target_include_directories(gctba INTERFACE\n        \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\"\n        \"$<INSTALL_INTERFACE:include>\")\n  endif(enable_throw_bad_alloc_library)\nendif()\n\nif (build_cord)\n  set(CORD_SRC cord/cordbscs.c cord/cordprnt.c cord/cordxtra.c)\n  add_library(cord ${CORD_SRC})\n  add_library(bdwgc::cord ALIAS cord)\n  target_link_libraries(cord PRIVATE gc)\n  target_include_directories(cord INTERFACE\n        \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\"\n        \"$<INSTALL_INTERFACE:include>\")\n  if (BUILD_SHARED_LIBS)\n    set_property(TARGET cord PROPERTY VERSION ${CORD_VERSION_PROP})\n    set_property(TARGET cord PROPERTY SOVERSION ${CORD_SOVERSION})\n  endif()\n  install(TARGETS cord EXPORT BDWgcTargets\n          LIBRARY DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n          ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n          RUNTIME DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n          INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\nendif(build_cord)\n\nif (BUILD_SHARED_LIBS AND HAVE_FLAG_WL_NO_UNDEFINED)\n  # Declare that the libraries do not refer to external symbols.\n  if (${CMAKE_VERSION} VERSION_LESS \"3.13.0\")\n    target_link_libraries(gc PRIVATE ${WL_NO_UNDEFINED_OPT})\n    if (enable_cplusplus)\n      target_link_libraries(gccpp PRIVATE ${WL_NO_UNDEFINED_OPT})\n      if (enable_throw_bad_alloc_library)\n        target_link_libraries(gctba PRIVATE ${WL_NO_UNDEFINED_OPT})\n      endif(enable_throw_bad_alloc_library)\n    endif(enable_cplusplus)\n    if (build_cord)\n      target_link_libraries(cord PRIVATE ${WL_NO_UNDEFINED_OPT})\n    endif(build_cord)\n  else()\n    target_link_options(gc PRIVATE ${WL_NO_UNDEFINED_OPT})\n    if (enable_cplusplus)\n      target_link_options(gccpp PRIVATE ${WL_NO_UNDEFINED_OPT})\n      if (enable_throw_bad_alloc_library)\n        target_link_options(gctba PRIVATE ${WL_NO_UNDEFINED_OPT})\n      endif(enable_throw_bad_alloc_library)\n    endif(enable_cplusplus)\n    if (build_cord)\n      target_link_options(cord PRIVATE ${WL_NO_UNDEFINED_OPT})\n    endif(build_cord)\n  endif()\nendif()\n\nif (BUILD_SHARED_LIBS)\n  set_property(TARGET gc PROPERTY VERSION ${GC_VERSION_PROP})\n  set_property(TARGET gc PROPERTY SOVERSION ${GC_SOVERSION})\nendif()\ninstall(TARGETS gc EXPORT BDWgcTargets\n        LIBRARY DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n        ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n        RUNTIME DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n        INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n\nif (enable_cplusplus)\n  if (BUILD_SHARED_LIBS)\n    set_property(TARGET gccpp PROPERTY VERSION ${GCCPP_VERSION_PROP})\n    set_property(TARGET gccpp PROPERTY SOVERSION ${GCCPP_SOVERSION})\n  endif()\n  install(TARGETS gccpp EXPORT BDWgcTargets\n          LIBRARY DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n          ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n          RUNTIME DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n          INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n  if (enable_throw_bad_alloc_library)\n    if (BUILD_SHARED_LIBS)\n      set_property(TARGET gctba PROPERTY VERSION ${GCCPP_VERSION_PROP})\n      set_property(TARGET gctba PROPERTY SOVERSION ${GCCPP_SOVERSION})\n    endif()\n    install(TARGETS gctba EXPORT BDWgcTargets\n            LIBRARY DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n            ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n            RUNTIME DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n            INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n  endif(enable_throw_bad_alloc_library)\nendif(enable_cplusplus)\n\nif (install_headers)\n  install(FILES include/gc/gc.h\n                include/gc/gc_backptr.h\n                include/gc/gc_config_macros.h\n                include/gc/gc_inline.h\n                include/gc/gc_mark.h\n                include/gc/gc_tiny_fl.h\n                include/gc/gc_typed.h\n                include/gc/gc_version.h\n                include/gc/javaxfc.h\n                include/gc/leak_detector.h\n          DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  install(FILES include/gc.h DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n  if (enable_cplusplus)\n    install(FILES include/gc_cpp.h DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n    install(FILES include/gc/gc_allocator.h\n                  include/gc/gc_cpp.h\n            DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  endif()\n  if (enable_disclaim)\n    install(FILES include/gc/gc_disclaim.h\n            DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  endif()\n  if (enable_gcj_support)\n    install(FILES include/gc/gc_gcj.h\n            DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  endif()\n  if (enable_threads)\n    install(FILES include/gc/gc_pthread_redirects.h\n            DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  endif()\n  if (build_cord)\n    install(FILES include/gc/cord.h\n                  include/gc/cord_pos.h\n                  include/gc/ec.h\n            DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/gc\")\n  endif()\n\n  # Provide pkg-config metadata.\n  set(prefix \"${CMAKE_INSTALL_PREFIX}\")\n  set(exec_prefix \\${prefix})\n  set(includedir \"${CMAKE_INSTALL_FULL_INCLUDEDIR}\")\n  set(libdir \"${CMAKE_INSTALL_FULL_LIBDIR}\")\n  string(REPLACE \";\" \" \" THREADDLLIBS \"${THREADDLLIBS_LIST}\")\n  # ATOMIC_OPS_LIBS, PACKAGE_VERSION are defined above.\n  configure_file(bdw-gc.pc.in bdw-gc.pc @ONLY)\n  install(FILES \"${CMAKE_CURRENT_BINARY_DIR}/bdw-gc.pc\"\n          DESTINATION \"${CMAKE_INSTALL_LIBDIR}/pkgconfig\")\nendif(install_headers)\n\nif (build_tests)\n  if (build_cord)\n    add_executable(cordtest cord/tests/cordtest.c ${NODIST_SRC})\n    target_link_libraries(cordtest PRIVATE cord gc)\n    add_test(NAME cordtest COMMAND cordtest)\n\n    if (WIN32) # AND NOT CYGWIN\n      if (NOT (CMAKE_C_COMPILER_ID STREQUAL \"Clang\"))\n        # Workaround MS Clang failure to compile a resource file.\n        set(DE_WIN_RC cord/tests/de_win.rc)\n      endif()\n      add_executable(de cord/tests/de.c cord/tests/de_win.c\n                     ${DE_WIN_RC} ${NODIST_SRC})\n      set_target_properties(de PROPERTIES WIN32_EXECUTABLE TRUE)\n      target_link_libraries(de PRIVATE cord gc gdi32)\n    endif()\n  endif(build_cord)\n\n  # Compile some tests as C++ to test extern \"C\" in header files.\n  if (enable_cplusplus)\n    set_source_files_properties(tests/leak.c PROPERTIES LANGUAGE CXX)\n    if (BORLAND OR MSVC OR WATCOM)\n      # WinMain-based test hangs at startup if compiled by VC as C++ code.\n    else()\n      set_source_files_properties(tests/gctest.c PROPERTIES LANGUAGE CXX)\n      # To avoid \"treating 'c' input as 'c++' when in C++ mode\" Clang warning.\n      add_compile_options(-x c++)\n    endif()\n  endif(enable_cplusplus)\n\n  add_executable(gctest WIN32 tests/gctest.c ${NODIST_SRC})\n  target_link_libraries(gctest\n                PRIVATE gc ${ATOMIC_OPS_LIBS_CMAKE} ${THREADDLLIBS_LIST})\n  add_test(NAME gctest COMMAND gctest)\n  if (WATCOM AND NOT enable_gc_assertions)\n    # Suppress \"unreachable code\" warning in GC_MALLOC_[ATOMIC_]WORDS().\n    target_compile_options(gctest PRIVATE /wcd=201)\n  endif()\n\n  add_executable(hugetest tests/huge.c ${NODIST_SRC})\n  target_link_libraries(hugetest PRIVATE gc)\n  add_test(NAME hugetest COMMAND hugetest)\n\n  add_executable(leaktest tests/leak.c ${NODIST_SRC})\n  target_link_libraries(leaktest PRIVATE gc)\n  add_test(NAME leaktest COMMAND leaktest)\n\n  add_executable(middletest tests/middle.c ${NODIST_SRC})\n  target_link_libraries(middletest PRIVATE gc)\n  add_test(NAME middletest COMMAND middletest)\n\n  add_executable(realloctest tests/realloc.c ${NODIST_SRC})\n  target_link_libraries(realloctest PRIVATE gc)\n  add_test(NAME realloctest COMMAND realloctest)\n\n  add_executable(smashtest tests/smash.c ${NODIST_SRC})\n  target_link_libraries(smashtest PRIVATE gc)\n  add_test(NAME smashtest COMMAND smashtest)\n\n  if (NOT (BUILD_SHARED_LIBS AND WIN32))\n    add_library(staticroots_lib_test tests/staticroots_lib.c)\n    target_link_libraries(staticroots_lib_test PRIVATE gc)\n    add_library(staticroots_lib2_test tests/staticroots_lib.c)\n    target_compile_options(staticroots_lib2_test PRIVATE \"-DSTATICROOTSLIB2\")\n    target_link_libraries(staticroots_lib2_test PRIVATE gc)\n    add_executable(staticrootstest tests/staticroots.c ${NODIST_SRC})\n    target_compile_options(staticrootstest PRIVATE \"-DSTATICROOTSLIB2\")\n    target_link_libraries(staticrootstest PRIVATE\n                          gc staticroots_lib_test staticroots_lib2_test)\n    add_test(NAME staticrootstest COMMAND staticrootstest)\n  endif()\n\n  if (enable_gc_debug)\n    add_executable(tracetest tests/trace.c ${NODIST_SRC})\n    target_link_libraries(tracetest PRIVATE gc)\n    add_test(NAME tracetest COMMAND tracetest)\n  endif()\n\n  if (enable_threads)\n    add_executable(atomicopstest tests/atomicops.c ${NODIST_SRC})\n    target_link_libraries(atomicopstest\n                PRIVATE ${ATOMIC_OPS_LIBS_CMAKE} ${THREADDLLIBS_LIST})\n    add_test(NAME atomicopstest COMMAND atomicopstest)\n\n    add_executable(initfromthreadtest tests/initfromthread.c ${NODIST_SRC})\n    target_link_libraries(initfromthreadtest PRIVATE gc ${THREADDLLIBS_LIST})\n    add_test(NAME initfromthreadtest COMMAND initfromthreadtest)\n\n    add_executable(subthreadcreatetest tests/subthreadcreate.c ${NODIST_SRC})\n    target_link_libraries(subthreadcreatetest\n                PRIVATE gc ${ATOMIC_OPS_LIBS_CMAKE} ${THREADDLLIBS_LIST})\n    add_test(NAME subthreadcreatetest COMMAND subthreadcreatetest)\n\n    add_executable(threadleaktest tests/threadleak.c ${NODIST_SRC})\n    target_link_libraries(threadleaktest PRIVATE gc ${THREADDLLIBS_LIST})\n    add_test(NAME threadleaktest COMMAND threadleaktest)\n\n    if (NOT WIN32)\n      add_executable(threadkeytest tests/threadkey.c ${NODIST_SRC})\n      target_link_libraries(threadkeytest PRIVATE gc ${THREADDLLIBS_LIST})\n      add_test(NAME threadkeytest COMMAND threadkeytest)\n    endif()\n  endif(enable_threads)\n\n  if (enable_cplusplus)\n    add_executable(cpptest WIN32 tests/cpp.cc ${NODIST_SRC})\n    target_link_libraries(cpptest PRIVATE gc gccpp)\n    add_test(NAME cpptest COMMAND cpptest)\n    if (enable_throw_bad_alloc_library)\n      add_executable(treetest tests/tree.cc ${NODIST_SRC})\n      target_link_libraries(treetest PRIVATE gc gctba)\n      add_test(NAME treetest COMMAND treetest)\n    endif(enable_throw_bad_alloc_library)\n  endif()\n\n  if (enable_disclaim)\n    add_executable(disclaim_bench tests/disclaim_bench.c ${NODIST_SRC})\n    target_link_libraries(disclaim_bench PRIVATE gc)\n    add_test(NAME disclaim_bench COMMAND disclaim_bench)\n\n    add_executable(disclaimtest tests/disclaim.c ${NODIST_SRC})\n    target_link_libraries(disclaimtest PRIVATE gc ${THREADDLLIBS_LIST})\n    add_test(NAME disclaimtest COMMAND disclaimtest)\n\n    add_executable(weakmaptest tests/weakmap.c ${NODIST_SRC})\n    target_link_libraries(weakmaptest\n                PRIVATE gc ${ATOMIC_OPS_LIBS_CMAKE} ${THREADDLLIBS_LIST})\n    add_test(NAME weakmaptest COMMAND weakmaptest)\n  endif()\nendif(build_tests)\n\nif (enable_docs)\n  install(FILES AUTHORS ChangeLog LICENSE README.md\n          DESTINATION \"${CMAKE_INSTALL_DOCDIR}\")\n  install(FILES\n            docs/README.autoconf\n            docs/README.cmake\n            docs/README.environment\n            docs/README.macros\n            docs/cords.md\n            docs/debugging.md\n            docs/faq.md\n            docs/finalization.md\n            docs/gcdescr.md\n            docs/gcinterface.md\n            docs/leak.md\n            docs/overview.md\n            docs/porting.md\n            docs/scale.md\n            docs/simple_example.md\n            docs/tree.md\n          DESTINATION \"${CMAKE_INSTALL_DOCDIR}/docs\")\n  install(FILES\n            docs/platforms/README.aix\n            docs/platforms/README.arm_cross\n            docs/platforms/README.darwin\n            docs/platforms/README.dgux386\n            docs/platforms/README.emscripten\n            docs/platforms/README.ews4800\n            docs/platforms/README.hp\n            docs/platforms/README.linux\n            docs/platforms/README.os2\n            docs/platforms/README.sgi\n            docs/platforms/README.solaris2\n            docs/platforms/README.symbian\n            docs/platforms/README.uts\n            docs/platforms/README.win32\n            docs/platforms/README.win64\n          DESTINATION \"${CMAKE_INSTALL_DOCDIR}/docs/platforms\")\n\n  install(FILES gc.man DESTINATION \"${CMAKE_INSTALL_MANDIR}/man3\" RENAME gc.3)\nendif(enable_docs)\n\n# CMake config/targets files.\ninstall(EXPORT BDWgcTargets FILE BDWgcTargets.cmake\n        NAMESPACE BDWgc:: DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/bdwgc\")\n\nconfigure_package_config_file(\"${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in\"\n        \"${CMAKE_CURRENT_BINARY_DIR}/BDWgcConfig.cmake\"\n        INSTALL_DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/bdwgc\"\n        NO_SET_AND_CHECK_MACRO)\n\nwrite_basic_package_version_file(\n        \"${CMAKE_CURRENT_BINARY_DIR}/BDWgcConfigVersion.cmake\"\n        VERSION \"${PACKAGE_VERSION}\" COMPATIBILITY AnyNewerVersion)\n\ninstall(FILES \"${CMAKE_CURRENT_BINARY_DIR}/BDWgcConfig.cmake\"\n              \"${CMAKE_CURRENT_BINARY_DIR}/BDWgcConfigVersion.cmake\"\n        DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/bdwgc\")\n\nexport(EXPORT BDWgcTargets\n       FILE \"${CMAKE_CURRENT_BINARY_DIR}/BDWgcTargets.cmake\")\n"
        },
        {
          "name": "ChangeLog",
          "type": "blob",
          "size": 562.0224609375,
          "content": "\n== [8.3.0] (development) ==\n\n* Acquire allocator lock in GC_is_tmp_root and GC_register_disclaim_proc\n* Add 'lib' prefix to build artifact names in Makefile.direct\n* Add API to get total stopped-world marking time\n* Add I_HOLD_LOCK assertion to callers of GC_get_maps (refactoring)\n* Add Linux example to README.cmake\n* Add assertion about kind argument range in GC_register_describe_type_fn\n* Add assertion about minimal value of GC_GCJ_MARK_DESCR_OFFSET\n* Add assertion in GC_set_fl_marks that there is no loop in freelist\n* Add assertion on GC_envfile_length value in GC_envfile_getenv()\n* Add assertion that GC_high_water is initialized in GC_clear_stack\n* Add assertion that custom setspecific is not called to overwrite value\n* Add assertion that result is not forwarding address in GC_install_header\n* Add assertion that value stored to GC_obj_map[] fits element type\n* Add assertion to GC_maybe_gc that GC is not in progress\n* Add assertion to ensure GC_unmapped_bytes cannot underflow\n* Add assertion to verify GC_threads hash table entries are chained properly\n* Add assertions about GC_mark_state to alloc.c and mark.c\n* Add assertions about hidden ptr lowest bit in toggle-refs implementation\n* Add callback API to support ephemeron marking\n* Add check that gc_hdrs.h and gc_locks.h are included only from gc_priv.h\n* Add check-deps goal to Makefiles to build the tests but not execute them\n* Add debug logging to GC_clear_exclusion_table and GC_exclude_static_roots\n* Add minimal testing of GC_allow_register_threads\n* Add missing cast in GC_is_init_called (refactoring)\n* Add missing undef GC_NO_THREAD_REDIRECTS in threaded tests\n* Add support of wasm32-wasi target\n* Add testing of remaining API functions (gctest and leaktest)\n* Add verbose logging of events of getting memory from OS\n* Add visionOS simulator support\n* Adjust comments in block_unmap_inner\n* Adjust comments referring glibc version (documentation)\n* Adjust header includes in cord .c files (refactoring)\n* Adjust indent inside case statements in configure.ac (reformatting)\n* Adjust indentation in C preprocessor directives (reformatting)\n* Adjust naming of Win32/64 and x86/64 words in comments and documentation\n* Adjust pointer-to-int cast in GC_register_dynamic_libraries for WinCE\n* Adjust printing on amount of unmapped memory after GC\n* Allow GC_push_roots to work even when no exclusions registered\n* Allow custom AO_SRC_DIR, CURSES, EXEEXT, HOSTCC/CFLAGS for Makefile.direct\n* Allow disable USE_PROC_FOR_LIBRARIES even if malloc is redirected on Linux\n* Allow gc_allocator<T> and friends to be defined in namespace boehmgc\n* Allow incremental GC on OpenBSD\n* Allow mprotect-based incremental GC on AIX and for all Linux targets\n* Allow passing custom CC and CXX to Makefile.direct\n* Allow passing custom CFLAGS[_EXTRA] to Makefile.direct\n* Allow single signal usage for both world suspend and resume in gctest\n* Allow testing of retry-signals functionality\n* Allow to build with forced WRAP_MARK_SOME\n* Allow to compile tests with custom NTHREADS set to zero\n* Allow to cross-compile for MacOS X with missing mach-o/getsect.h\n* Allow to omit operator new/delete definitions in gc_cpp\n* Allow to randomly choose a CPU core if AO ops are emulated with locks\n* Allow to skip heap expansion in GC_init\n* Allow to unmap memory block right in GC cycle where block is freed\n* Allow to use print/check_marks_int_list() in gctest\n* Allow to use same signal for thread suspend and restart (default on E2K)\n* Always declare GC_set_and_save_fault_handler before its definition\n* Always invoke pending finalizers in GC_generic_malloc_uncollectable\n* Always print error details message when gctest fails\n* Always set only one bit past end in GC_set_hdr_marks\n* Always specify relative path for private headers mentioned in .md docs\n* Assert SET_HDR does not write to GC_all_nils\n* Assert allocator lock held in GC_add_roots_inner and its callers\n* Assert allocator lock held in GC_reset_finalizer_nested\n* Assert allocator lock held in add_leaked/smashed, check_heap_proc\n* Assert allocator lock held in scratch_alloc/recycle and their callers\n* Assert allocator lock held in start/continue_reclaim and reclaim_all\n* Assert allocator lock held to ensure no race on reveal hidden pointers\n* Assert allocator lock held while GC_our_memory is updated\n* Assert in typed_mark_proc that allocator lock held by some collecting thread\n* Assert that bm_table is already initialized when GC_double_descr used\n* Assert that disappearing links are accessible during registration and GC\n* Assert that size of element of a typed object is non-zero (refactoring)\n* Assume argument of GC_set_fl_marks is non-null (refactoring)\n* Avoid code duplication between pthread_support.c and win32_threads.c\n* Avoid code duplication in GC_core_gcj_malloc (refactoring)\n* Avoid code duplication in GC_dyld_image_add/remove on Darwin (refactoring)\n* Avoid code duplication in GC_incremental_protection_needs (refactoring)\n* Avoid code duplication in GC_make_array_descriptor (refactoring)\n* Avoid code duplication in HAVE_FLAG_WNO_FRAME_ADDRESS of CMake script\n* Avoid code duplication in IGNORE_OFF_PAGE-specific malloc functions\n* Avoid code duplication regarding GC_push_roots in GC_mark_some_inner\n* Avoid duplication of magic numbers in disclaim.c, weakmap.c (refactoring)\n* Avoid fn call inlining in GC_call_with_stack_base/gc_active\n* Avoid static variable name duplication in GC_is_static/tmp_root\n* Avoid unmap of memory allocated during GC init regardless of threshold\n* Better document GC_generate_random_heap/valid_address API functions\n* Better document GC_no_dls and NO_DEBUGGING macro\n* Better document GC_print_free_list regarding allocator lock\n* Better document and simplify define CAN_SAVE_CALL_ARGS in gcconfig.h\n* Better document link argument of GC_general_register_disappearing_link\n* Better document missing debugging version for aligned allocation routines\n* Better document preprocessor-related pointer checking routines in gc.h\n* Better document why REVEAL_POINTER should be used with allocator lock held\n* Better separate libgc build- and use-time macro descriptions in README\n* Build cord/de test by WCC_MAKEFILE on Win32\n* Build extra/gc.c in digimars.mak\n* Build with GC_wcsdup support if wcslen exists\n* Call GC_init_parallel only from GC_init (refactoring)\n* Call syscall() to get E2K procedure stack directly in caller function\n* Change GC_Thread_Rep in pthread_support.h to match that of win32_threads.c\n* Change GC_build_fl prototype to accept size in granules (refactoring)\n* Change GC_gcj_malloc and friends to accept const pointer to descriptor\n* Change GC_warn_proc API to accept const C string\n* Change NOT_MARKED value to non-zero (refactoring)\n* Change default GC_time_limit value from 50 to 15 ms\n* Change default value of max_prior_attempts to 3\n* Change enable_threads default to off if threads are unsupported (CMake)\n* Change file extension of README.* to lower case in doc/platforms\n* Change minimum heap growth to one block if requested explicitly\n* Change p local variable to current_p in push_all/conditional_eager\n* Change return type of GC_get_memory_use() from size_t to word\n* Change type of GC_collecting variable to match atomic operations over it\n* Change type of GC_find_header() argument to a const typeless pointer\n* Change type of client_data of GC_iterate_free_hblks from word to a pointer\n* Change type of collect_a_little_inner argument from int to size_t\n* Change type of hb_sz field (of hblkhdr) from word back to size_t\n* Change type of internal variables from word to size_t where applicable\n* Check highest bit of word using SIGNB instead of cast to signed_word\n* Check out-of-memory and set in_thread_creation inside GC_new_thread\n* Check pointer tag in all mark procedures (E2K)\n* Clear GC_thread_key thread-local value on unregistering the thread\n* Clear stack in GC_core_gcj_malloc only after releasing allocator lock\n* Code refactoring to support pointers larger than word (CHERI)\n* Collapse arch macro defines where possible (refactoring)\n* Comment out argument names of functions in cord public headers\n* Compile gc_dlopen.c and specific.c conditionally in Makefile.am\n* Compute local variables in GC_reclaim_small_nonempty_block only if needed\n* Consistent naming of GC_thread local variables (refactoring)\n* Consistent naming of variables of obj_kind type (refactoring)\n* Consistent use of CHECK_OUT_OF_MEMORY() in tests (refactoring)\n* Consistently use GC_word (instead of word) type in tests (refactoring)\n* Declare GC_noop1 as public function unconditionally\n* Declare GC_register_stackbottom symbol as internal on IA64 (refactoring)\n* Declare variables and arguments as pointer to const where applicable\n* Define ALIGNMENT macro based on CPP_PTRSZ value by default (refactoring)\n* Define AO_t to size_t instead of word (refactoring)\n* Define GC_GCJ_MARK_DESCR_OFFSET public macro\n* Define GC_GLIBC_PREREQ internal macro (refactoring)\n* Define GC_GRANULE_BYTES macro based on GC_GRANULE_PTRS value (refactoring)\n* Define GC_VERSION_VAL_T public macro (refactoring)\n* Define GC_get_parallel and GC_set_markers_count in single-threaded GC\n* Define GC_print_stats as GC_INNER (refactoring)\n* Define GC_save_regs_ret_val variable only if used on IA64 (refactoring)\n* Define GC_self_thread_inner to lookup GC_thread of current thread\n* Define GC_thread type in a single place both for pthreads and Win32\n* Define HBLK_PAGE_ALIGNED() macro for internal use (refactoring)\n* Define LAZY_THRESHOLD const value as long in cord (refactoring)\n* Define and use GC_find_starting_hblk inline function (refactoring)\n* Define and use SIGNAL_BASED_STOP_WORLD macro internally (refactoring)\n* Define clear/set_all_fl_marks internal functions (refactoring)\n* Define counter variables as static in gctest (refactoring)\n* Define internal macro NO_SEH_AVAILABLE where SEH is absent (refactoring)\n* Define internal macro for pointers rounding up by a mask (refactoring)\n* Define macros in gcconfig.h to use sigaction for SIGSEGV and SIGBUS\n* Define marker_[b]sp only if needed (refactoring)\n* Define op and nwords/lpw local variables consistently across typd_mlc.c\n* Define public GC_GRANULE_PTRS macro\n* Define public GC_MALLOC_EXPLICITLY_TYPED_IGNORE_OFF_PAGE()\n* Define public GC_[p]valloc() and redirect to them in leak_detector.h\n* Define sized delete operator in 'gc' class\n* Define tunable values in cordtest as macro (refactoring)\n* Describe strategies to scan data roots on stack (Emscripten)\n* Detect overflow of size_t value addition before the operation in cordbscs\n* Detect presence of pthread_sigmask() in configure and cmake scripts\n* Disable H/W tag checking in mark procedures by default (E2K)\n* Disable memory unmapping explicitly in gcconfig.h for Emscripten\n* Disallow explicit unregister of non-main thread if registered by DllMain\n* Discard sections with pseudo-paths except heap in register_map_entries\n* Do incremental mark some in GC_collect_a_little even if GC is disabled\n* Do not add extra byte to large ignore-off-page and uncollectible objects\n* Do not check INV_SZ_COMPUTATION_CHECK macro (refactoring)\n* Do not check dl_iterate_phdr presence by build scripts on OS X and Win32\n* Do not check presence of getcontext and dl_iterate_phdr by cmake on Win32\n* Do not compile pthread_start.c on Cygwin even if build shared libs (CMake)\n* Do not compile pthread_stop_world.c on Darwin (CMake)\n* Do not count time spent processing toggle-refs in stopped_mark\n* Do not define GC_pthread_start/exit for Orbis and Sony PSP (refactoring)\n* Do not define GETPAGESIZE on Win32 (refactoring)\n* Do not define SIG_HNDLR_PTR on Darwin unless really used\n* Do not define THREAD_SANITIZER if GC is built w/o threads support\n* Do not do unnecessary GC_read_dirty() from GC_enable_incremental\n* Do not expose GC_nacl_gc_thread_self variable outside pthread_stop_world.c\n* Do not flush registers before reading procedure stack on E2K\n* Do not free entry in GC_delete_gc_thread to match that on Win32\n* Do not hard-code page size for wasm32-wasi (refactoring)\n* Do not include gcconfig.h from extra/symbian source files (refactoring)\n* Do not include sched.h from pthread_start.c (refactoring)\n* Do not invoke GC_approx_sp() repeatedly in GC_stopped_mark (refactoring)\n* Do not invoke finalizers during thread creation or destruction\n* Do not iterate over heap blocks in GC_get_memory_use\n* Do not prohibit threaded builds with malloc redirection on non-Linux\n* Do not put atomic_ops[_sysdeps].o to libgc.a in Makefile.direct\n* Do not reference internal files in comments of public header files\n* Do not set SIGBUS handler to catch write faults on Linux\n* Do not store E2K procedure stack to GC heap (refactoring)\n* Do not treat warnings as errors by default in digimars.mak\n* Do not use GC lock in GC_print_callers (refactoring)\n* Do not use _CrtDbgReport() if NO_CRTDBGREPORT macro defined (MSVC/debug)\n* Do not use atomic intrinsic in assertion of GC_reclaim_generic\n* Do not use deprecated _dyld_bind_fully_image_containing_address (Darwin)\n* Do not use deprecated get_etext and get_end on Darwin\n* Do not use deprecated getsectbynamefromheader_64 (Darwin)\n* Do not use integer division in GC_soft_read_dirty\n* Do not wrap mark_some to catch faults if libraries registration is off\n* Document GC_ENABLE_SUSPEND_THREAD better in configure\n* Document GC_print_free_list shortly in gc_inline.h\n* Document GC_with_callee_saves_pushed better\n* Document argument of GC_is_marked in gc_mark.h\n* Document assumption about allocator lock for GC_clear_exclusion_table\n* Document macros in config.h not referring to README (configure)\n* Document that GC_is_X API functions may return only zero or one\n* Document that GC_unregister_my_thread result value is dummy\n* Eliminate 'array subscript has type char' compiler warnings in os_dep\n* Eliminate 'atomic_thread_fence is unsupported with tsan' gcc-11 warning\n* Eliminate 'boolean result used in bitwise op' cppcheck FP in GC_thr_init\n* Eliminate 'cast discards const from target ptr type' clang warning in cord\n* Eliminate 'cast discards const/volatile from target type' warnings in libgc\n* Eliminate 'cast discards volatile from type' warnings in cordxtra, gctest\n* Eliminate 'checking if 1U<<12 is less than zero' cppcheck FP warning\n* Eliminate 'compound assignment with volatile left operand' g++ warning\n* Eliminate 'conversion may change sign' clang warnings in cord and tests\n* Eliminate 'increment for volatile-qualified type deprecated' g++ warning\n* Eliminate 'n obtained from untrusted source' code defect FP in test_cpp\n* Eliminate 'no previous prototype' clang warnings\n* Eliminate 'obj_displ scope can be reduced' cppcheck warning in gc_pmark.h\n* Eliminate 'parameter can be declared as const pointer' cppcheck warnings\n* Eliminate 'scope of p variable could be reduced' cppcheck warning in de.c\n* Eliminate 'skipping config since static_assert is unknown' cppcheck FP\n* Eliminate 'struct treenode member is never used' cppcheck warning\n* Eliminate 'volatile-qualified arg parameter' g++ warning in mach_dep.c\n* Eliminate code duplication in GC_PREFETCH_FOR_WRITE generic definition\n* Eliminate data race FP reported in need_unreachable_finalization by TSan\n* Eliminate duplicate use of GC_obj_kinds[k] in GC_generic_malloc_many\n* Enable HBLKSIZE values up to 64K\n* Enable prefetch for MSVC (Windows/x86 and Windows/x64)\n* Enable prefetch loop in GC_mark_from on E2K\n* Enable without_libatomic_ops for targets requiring atomic_ops.c (CMake)\n* Ensure GC is initialized when GC_push_all_stacks() is called (refactoring)\n* Ensure GC_enable_incremental variable is accessed holding the lock\n* Ensure GC_n_set_marks() does not count extra bits in hb_marks\n* Ensure a collection occurs between adjacent heap expansions\n* Ensure all macros defined in public cord_pos.h have 'CORD_' prefix\n* Ensure const value has proper type before negation operation in msvc_dbg\n* Ensure every test prints a message on success\n* Ensure that GC_init does not allocate any object itself (refactoring)\n* Explicitly check that word has at least 32 bits in shifts by 20+ bits\n* Export CORD_ec_append_cord(), CORD_ec_flush_buf() from cord shared library\n* Export CORD_oom_fn public variable from cord shared library\n* Export GC_apply_to_all_blocks() and GC_is_black_listed() as public API\n* Export get/set_abort_func even in case of SMALL_CONFIG\n* Export get/set_manual_vdb_allowed even in case of SMALL_CONFIG\n* Export setter and getter for pointer checking print procedures\n* Expose functions to enable pushing of custom proc and ranges\n* Fail threadkeytest on pthread_create error in main loop\n* Fix 'destructor is not marked with override specifier' cppcheck warning\n* Fix 'possibly undefined macro AC_ENABLE_SHARED' autoreconf error\n* Fix 'unexpected heap growth' fail in gctest if GC_INITIAL_HEAP_SIZE is set\n* Fix digimars.mak to build 'all' by default\n* Fix double call of unregister_my_thread if thread registered by DllMain\n* Fix gctest failure for non-default MARK_DESCR_OFFSET\n* Fix missing hyphenation in documentation\n* Fix thread_id variable definition placement in main of subthreadcreatetest\n* Fix undefined behavior caused by potential overflow in MAKE_COOLER\n* Force pthread_mutex_lock usage for allocator lock if ThreadSanitizer\n* Get libpthread.so '.text' mapping only for glibc prior to v2.34 (Linux)\n* Group NEED_FIND_LIMIT definitions in gcconfig.h (refactoring)\n* Group all thread id fields together in GC_thread (refactoring)\n* Group char-width fields together in GC_arrays (refactoring)\n* Group functional pointers in struct finalizable_object (refactoring)\n* Group functions related to GC_calloc_explicitly_typed (refactoring)\n* Implement LONG_MULT in portable way using multiplication of 32-bit words\n* Implement shared locks and provide enable_rwlock build script option\n* Improve ABORT message in GC_darwin_sigbus\n* Improve GC_memalign and friends to always return object base pointer\n* Include gc/gc[_cpp].h directly except for cord and tests (refactoring)\n* Include gc_inline.h from gc_priv.h (refactoring)\n* Include signal.h conditionally\n* Include stdio.h and stdlib.h only from gc_priv.h (refactoring)\n* Include sys/types.h and unistd.h from a single place (refactoring)\n* Increase number of iterations in leak and middle tests\n* Increase object kinds limit (to 24 items)\n* Increment allocated objects count after GC_memalign in gctest\n* Initial support of KOS/arm64\n* Initialize GC_retry_signals to true in GC_stop_init (refactoring)\n* Install ChangeLog among doc files\n* Introduce READER_LOCK/UNLOCK macros (refactoring)\n* Make abort message unique in write_fault_handler\n* Make all functions static in msvc_dbg.c except for backtrace[_symbols]\n* Make comparisons to the lowest heap boundary strict\n* Make links to mentioned platforms/README files in doc .md files\n* Make shift size smaller in GC_CLANG/GNUC/GLIBC_PREREQ (refactoring)\n* Mark GC_add_roots_inner() as GC_INNER (refactoring)\n* Mention CMake-based build in README.md and README.QUICK\n* Mention all doc files in overview document\n* Mention gc_allocator.h in README.win32 (documentation)\n* Mention proper CURSES value in Makefile.direct to build cord/de test\n* Minimize THREADS-specific code in GC_invoke_finalizers (refactoring)\n* Minimize code difference between GC_push_marked/unconditionally\n* More clear message about total duration of full collections in gctest\n* Move GC_NO_THREADS_DISCOVERY definition to gcconfig.h (refactoring)\n* Move GC_unblock_gc_signals to pthread_stop_world.c (refactoring)\n* Move HAVE_CLOCK_GETTIME definition from gc_priv.h to gcconfig.h\n* Move fields common between Concatenation and Function to Generic structure\n* Move increment of GC_bytes_allocd to GC_alloc_large (refactoring)\n* Move internals of GC_[signed_]word definition to gc_config_macros.h\n* Move non-cord [pkg]include_HEADERS assignments to include.am (refactoring)\n* Move non-license info from LICENSE file to README and vice versa\n* Move platform-dependent getspecific() call to a dedicated function\n* Move platform-specific README files to doc/platforms\n* Move pthread_atfork() call to a separate function (refactoring)\n* Move public header files to include/gc in source tree\n* Move stack-related fields out of GC_thread to GC_stack_context_t\n* Move thread-only functions to pthread_support.c (refactoring)\n* Move used blocks total size checking from check_dirty to print_block_list\n* Name all tests consistently (refactoring)\n* Never use mmap() for storing procedure stack on E2K (refactoring)\n* New API for disappearing links registration accepting interior pointers\n* New API for more optimal usage of GC_calloc_explicitly_typed\n* New API function (GC_get_hblk_size) to get HBLKSIZE value\n* New API function (GC_set_interrupt_finalizers) to break finalizer loop\n* New API function to check if collector is built with DONT_ADD_BYTE_AT_END\n* New CMake option to link with external libatomic_ops (system library)\n* New GC_count_set_marks_in_hblk and GC_iterate_free_hblks API functions\n* New macro (DONT_PROTECT_PTRFREE) to never protect pointer-free pages\n* New macro (NO_MANUAL_VDB) to disallow manual VDB mode\n* New public function (get_supported_vdbs) to list available VDB techniques\n* New public function GC_get_actual_vdb\n* Order libgc .c files lexicographically in build scripts\n* Output finalization information by GC_dump\n* Pass ATOMIC_OPS_LIBS to tests using AO primitives directly (Automake)\n* Perform overflow/underflow checks before operation on a pointer\n* Prefix size_t and ptrdiff_t with namespace 'std' in C++ files\n* Preserve doc folders structure on package install\n* Preserve provenance of capability to heap block (CHERI)\n* Prevent requesting blocks past max_heapsize in GC_collect_or_expand\n* Prevent result of MAKE_COOLER to be NULL\n* Print heap size in bytes (not MB) in out-of-memory warning if small heap\n* Print in-use heap statistic on heap growth\n* Print iteration number on thread creation or join failure in tests\n* Print objs_in_block as zero for large objects in GC_print_block_list\n* Print thread number on marker thread creation failure\n* Print value of links in GC_dump_finalization_links\n* Provide GC_HIDE/REVEAL_NZ_POINTER public macros\n* Provide GC_init_gcj_malloc_mp with argument of GC_mark_proc type\n* Provide a macro to check dirty bits consistency between MPROTECT/SOFT_VDB\n* Provide debugging variant of GC_toggleref_add\n* Provide global non-throwing operator new/delete in gccpp library\n* Provide mechanism to track allocations with heap profiling tools\n* Provide one flag in each add_compile_options/definitions of CMake script\n* Put faq.html to codebase, update it and convert it to Markdown format\n* Put gc_badalc/cpp.cpp instead of .cc ones in CMake script (MSVC/BCC/WCC)\n* Really ignore bad GC_INITIAL/MAXIMUM_HEAP_SIZE values\n* Redirect GC_gcj_malloc_ignore_off_page to GC_gcj_malloc for small objects\n* Redirect GC_malloc_explicitly_typed_ignore_off_page for small objects\n* Redirect _aligned_malloc/free() in leak_detector.h\n* Redirect aligned_alloc() and reallocarray() in leak_detector.h\n* Redirect malloc_size() and _msize() in leak_detector.h\n* Reduce number of iterations in disclaim and cpp tests\n* Reduce scope of local variables used for assertion checking in add_to_fl\n* Reduce size of heap block per-granule maps twice for 4KB heap blocks\n* Reduce some of big constants in tests to fit into 16-bit int type\n* Refactoring of GC_n_set_marks and GC_print_block_descr\n* Refactoring of GC_protect_heap\n* Refactoring of rt_hash()\n* Refine WARN message in GC_proc_read_dirty regarding buffer size\n* Refine column names output by GC_print_block_list\n* Refine comment about call stack saving and gcc option for i686 in os_dep.c\n* Refine comment of LOG_PHT_ENTRIES for the case of impossible collisions\n* Refine comments in code regarding DllMain-based threads registration\n* Refine comparisons to GC_greatest_plausible_heap_addr\n* Refine debug message in GC_suspend_handler_inner\n* Refine documentation of GC_MALLOC_WORDS_KIND\n* Refine documentation of GC_init_gcj_malloc and GC_get_back_ptr_info\n* Refine documentation of GC_register_disclaim_proc and GC_finalized_malloc\n* Refine gcinterface.md that the allocator belongs to SGI STL\n* Refine main README about the ways available to build the library\n* Refine that GC_save_regs_in_stack is used by save_callers only on SPARC\n* Reformat code of GC_save_callers()\n* Relax required dependencies for atomicopstest (CMake)\n* Remove -o option where not needed in Makefile.direct (refactoring)\n* Remove CORD_max_len debugging symbol\n* Remove EXPORTED_FUNCTIONS linker flag for gctest (Emscripten)\n* Remove GC_copyright symbol\n* Remove GC_mark_threads variable (refactoring)\n* Remove GC_min/max() and simplify heap bounds update in expand_hp_inner\n* Remove GC_save/print_callers duplicate declaration (refactoring)\n* Remove GC_world_is_stopped variable (refactoring)\n* Remove IF_IA64 macro in pthread_stop_world (refactoring)\n* Remove LOGWL, BYTES_PER_WORD, MAXOBJWORDS and various unused CPP_x macros\n* Remove MAIN_THREAD flag in GC_thread (refactoring)\n* Remove MARK_BIT_PER_GRANULE macro (refactoring)\n* Remove OpenBSD uthreads (GC_OPENBSD_UTHREADS) support\n* Remove STACK_GROWS_DOWN explicit definitions in gcconfig.h (refactoring)\n* Remove STACK_GROWS_DOWN macro usage (refactoring)\n* Remove Symbian makefile\n* Remove USED_HEAP_SIZE macro (refactoring)\n* Remove ancient OS2_MAKEFILE\n* Remove code duplication in GC_free[_inner] (refactoring)\n* Remove code duplication in gcconfig.h for Hurd (refactoring)\n* Remove comment from gc_cpp.h about bugs in ancient compilers\n* Remove commented out code in de_win\n* Remove de_win.h dependency on cord.h (refactoring)\n* Remove doc.am, and move gc.man to base folder (refactoring)\n* Remove duplicate 'called once' check in GC_init_lib_bounds (refactoring)\n* Remove duplicate documentation of GC_UNDERSCORE_STDCALL in configure\n* Remove duplication of random numbers generator formula (refactoring)\n* Remove empty default cases in configure (refactoring)\n* Remove extra parentheses in return statement (refactoring)\n* Remove extra space after sizeof (reformatting)\n* Remove extra variable and rename argument of GC_new_hblk (refactoring)\n* Remove main_altstack group of static variables (refactoring)\n* Remove main_pthread_id variable (refactoring)\n* Remove msvc_dbg.h file (refactoring)\n* Remove obsolete AC_PROG_LIBTOOL in configure.ac (refactoring)\n* Remove oom_fn internal type from cord source (refactoring)\n* Remove outdated info from README about Linux/m68k bug\n* Remove private pthread_stop_world.h and darwin_stop_world.h (refactoring)\n* Remove redundant 'private' prefix in include directives in include/private\n* Remove redundant GC_ATTR_UNUSED for GC_mark_and_push\n* Remove redundant HOST_TIZEN macro check for SEARCH_FOR_DATA_START\n* Remove redundant Linux/SPARC checks (refactoring)\n* Remove redundant check a predefined macro of BCC (refactoring)\n* Remove redundant includes from tools and disclaim tests (refactoring)\n* Remove redundant pointer casts to void pointer (refactoring)\n* Remove specific DATASTART definition for ancient OpenBSD/m68k\n* Remove thread_blocked field in GC_thread (refactoring)\n* Remove trailing dot in WARN messages\n* Remove unneeded cast to word in GC_PUSH_ONE_HEAP/STACK (refactoring)\n* Remove unneeded casts in GC_PUSH_ALL_SYM (refactoring)\n* Remove unneeded n_blocks local variable in malloc.c and reclaim.c\n* Remove unneeded pointer casts of HDR() argument (refactoring)\n* Remove unprefixed GRANULE_BYTES, TINY_FREELISTS, WORDSZ macros\n* Remove unreachable code in GC_lookup_pthread (refactoring)\n* Remove unused DCL_LOCK_STATE (refactoring)\n* Remove use of emscripten_scan_stack (refactoring)\n* Remove volatile qualifier for GC_dirty_pages except for MPROTECT_VDB\n* Remove volatile qualifier for GC_threads (pthreads)\n* Remove warning at GC_init about USE_PROC_FOR_LIBRARIES and Linux threads\n* Rename GC_[inner_]start_routine to match that for Win32 (refactoring)\n* Rename GC_enclosing_mapping to GC_enclosing_writable_mapping (refactoring)\n* Rename MAP_LEN internal macro to OBJ_MAP_LEN (refactoring)\n* Rename MARK_BITS_SZ internal macro to HB_MARKS_SZ (refactoring)\n* Rename README.QUICK to LICENSE and install it by default\n* Rename README.rs6000 to README.aix\n* Rename ROUNDED_UP_GRANULES macro to ALLOC_REQUEST_GRANS (refactoring)\n* Rename doc folder to docs\n* Rename mark_stack_ptr argument to mark_stack_top globally (refactoring)\n* Rename p argument to base in dbg_mlc.c/h (refactoring)\n* Rename size argument in GC_build_fl (refactoring)\n* Rename stack[_size] in GC_Thread_Rep and GC_register_altstack (refactoring)\n* Rename thread_args and GC_main_thread in win32_threads.c (refactoring)\n* Reorder macro definitions for rare architectures in gcconfig.h\n* Replace C style comments to C++ ones in gc_allocator.h\n* Replace C-style casts in C++ headers and cpptest (refactoring)\n* Replace GC_MARK_FO macro with inline functions (refactoring)\n* Replace comments about GC is held or not with relevant assertions\n* Replace hard-coded 0x80000000 to SIGNB for pointer-sized values\n* Replace init_netbsd_elf with init_linux_data_start on NetBSD (refactoring)\n* Replace obsolete AC_TRY_COMPILE/LINK/RUN in configure.ac (refactoring)\n* Replace target names with '$@' in Makefile.direct (refactoring)\n* Report 'none' if no machine-dependent code-to-use detected in configure\n* Require to specify CPP_WORDSZ in gcconfig.h for each supported arch\n* Return free memory to OS explicitly before getting new memory from OS\n* Roundup size passed to GC_expand_hp\n* Set name of GC marker threads on OpenBSD\n* Simplify code of GC_allochblk_nth (refactoring)\n* Simplify code to define USE_x_SPECIFIC macros in thread_local_alloc.h\n* Simplify expression to clear extra bits in add_ext_descriptor (refactoring)\n* Simplify gcconfig code to define IRIX5 and ULTRIX on mips (refactoring)\n* Simplify test_basics() and test_extras() in cordtest (refactoring)\n* Specify GC_CALLBACK calling conventions for GC_mark_proc\n* Specify all public headers without path prefix in documentation\n* Specify that error conditions are unlikely to be true in threads code\n* Specify that internal allocations failure is unlikely (refactoring)\n* Specify that out-of-memory is unlikely in typed alloc and make descriptor\n* State explicitly that license is MIT-style\n* Support 32-bit mode on E2K\n* Support CFLAGS_EXTRA in rare build scripts (NT/WCC_MAKEFILE, digimars.mak)\n* Support Embox/x86 (single-threaded)\n* Support GC_memalign with alignments greater than HBLKSIZE\n* Support Linux/sw_64 (sunway-linux)\n* Support QNX on arm[64] and x86[_64]\n* Support ThreadSanitizer (GCC)\n* Support building with Zig (experimental)\n* Support client stop function properly in maybe_gc and collect_a_little\n* Support disable_single_obj_compilation option in cmake script\n* Support malloc redirection on E2K\n* Support pointer mask/shift set at runtime\n* Support saving procedure stack at an offset on E2K (multi-threaded only)\n* Suppress a data race report in debug-related GC_n_set_marks\n* Test garbage collection from a deep recursion in gctest\n* Test manual self-suspend in gctest\n* Test realloc() in leaktest\n* Test that CORD_oom_fn variable could be set from cordtest\n* Test world stop while other thread in deep recursion in gctest (pthreads)\n* Treat GC_arrays as a part of internal memory when printing its size\n* Treat warnings as errors in C++ code if configure --enable-werror\n* Treat zero requested size in GC_malloc_many same as that in GC_malloc\n* Try find libatomic_ops installed by cmake if with_libatomic_ops (CMake)\n* Turn on MAKE_BACK_GRAPH for all Linux architectures in cmake and configure\n* Undefine PUSHn macros after use in win32_threads.c (refactoring)\n* Uniform usage of IS_FORWARDING_ADDR_OR_NIL() and FORWARDED_ADDR()\n* Uniform use of GC_lookup_by_pthread in GC_pthread_join/detach (refactoring)\n* Uniformly name Linux/i686 and Linux/x86_64 in documentation\n* Unify GC_Thread_Rep and thread id type in win32_threads.c (refactoring)\n* Unify GC_[mark_]lock_holder variable definition (refactoring)\n* Unify comments about the allocator lock (documentation)\n* Update information and better describe call stack saving support\n* Update next_random_no state using AO primitive\n* Update time statistics about stopped marking even if abandoned\n* Use AO primitive in GC_noop1 instead of no_sanitize attribute\n* Use AO primitives in GC_RAND_NEXT instead of no_sanitize attribute\n* Use AO_t type for hb_marks, hb_sz, hb_descr fields (refactoring)\n* Use AS_HELP_STRING consistently for AC_ARG_WITH in configure (refactoring)\n* Use BZERO in GC_save_callers (refactoring)\n* Use BZERO() to clear jmp_buf variable in GC_with_callee_saves_pushed\n* Use EXPECT in GC_add_to_heap, GC_lookup_thread and GC_lookup_by_pthread\n* Use EXPECT in checks of MAIN_THREAD bit (refactoring)\n* Use GC_HIDE_NZ_POINTER() for hiding ci_arg value in GC_save_callers\n* Use GC_debug_generic_or_special_malloc in GC_debug_realloc (refactoring)\n* Use GC_delete_thread instead of GC_delete_gc_thread_no_free (refactoring)\n* Use GC_printf in cpptest consistently (refactoring)\n* Use IS_PTRFREE() consistently (refactoring)\n* Use __typeof__ in GC_PTR_ADD and similar if MS Clang\n* Use a dedicated integer type to hold function pointers (refactoring)\n* Use a macro internally to designate Cygwin and MSWin/WinCE (refactoring)\n* Use a macro internally to designate Free/Net/OpenBSD (refactoring)\n* Use cast to void instead of the attribute to indicate unused arguments\n* Use consistent variables naming in typd_mlc.c (refactoring)\n* Use distinct MACH_TYPE for WebAssembly (refactoring)\n* Use hdr identifier only for the type (refactoring)\n* Use hexadecimal format for logging of traced pointer descriptor\n* Use inline keyword in GC_INLINE (bcc)\n* Use lb, lg and k argument names uniformly (refactoring)\n* Use modHBLKSZ where possible (refactoring)\n* Use ptr_t instead of word internally where appropriate (refactoring)\n* Use register_my_thread_inner to add initial thread in pthread_support.c\n* Use signed_word instead of ptrdiff_t for pointers delta (refactoring)\n* Use single-argument suspend_handler for E2K, HP_PA, IA64, M68K\n* Use size_t in GC_repeat_read, GC_get_file_len and generic GC_write\n* Use size_t instead of int where applicable in allchblk.c (refactoring)\n* Use unsigned32 type for all internal 32-bit variables and literals\n* Warn if heap has grown while GC was disabled\n* Workaround 'C-style casting' cppcheck warning in cpptest\n* Workaround 'GC_arrays._static_roots[] accessed out of bounds' cppcheck FP\n* Workaround 'GC_parallel_mark_disabled is always false' cppcheck FP\n* Workaround 'TEXT is unknown macro' cppcheck FP warning\n* Workaround 'address of a symbol cannot be null' cppcheck FP\n* Workaround 'condition !setup_header() is always false' cppcheck FP\n* Workaround 'condition 0!=back_ptr is always true' cppcheck FP\n* Workaround 'condition weakmap_trylock()!=0' is always false' cppcheck FP\n* Workaround 'data access w/o lock' code defect FP in GC_incr_bytes_freed\n* Workaround 'if condition is same as previous if condition' cppcheck FP\n* Workaround 'integer overflow occurs in GC_make_descriptor' code defect FP\n* Workaround 'null ptr dereference' cppcheck FP in remove_all_threads_but_me\n* Workaround 'out-of-bounds access' code defect FP in GC_allochblk_nth\n* Workaround 'parameter can be declared as pointer to const' cppcheck FP\n* Workaround 'returning pointer to local variable base' cppcheck FP in misc\n* Workaround 'scope of sz can be reduced' cppcheck warning in GC_n_set_marks\n* Workaround 'struct member link_map::l_name is never used' cppcheck warning\n* Workaround 'total_time<0 is always false' cppcheck FP warning\n* Workaround 'uninitialized variable bs_lo' cppcheck FP (E2K)\n* Workaround 'uninitialized variable pos.cur_pos' cppcheck FP in cord files\n* Workaround 'uninitialized variable sp' cppcheck FP in setjmp_t.c\n* Workaround 'unsigned int underflow' code defect FP in GC_clear_fl_marks\n* Workaround an integer overflow code defect in GC_make_descriptor\n* Workaround integer overflow code defect FP in GC_write, GC_repeat_read\n* Workaround unsupported 'X' asm constraint in tcc\n\n\n== [8.2.8] 2024-09-08 ==\n\n* Allow GC_size() argument to be null\n* Disable backtrace saving at garbage collections if DONT_SAVE_TO_LAST_STACK\n* Eliminate 'cast signed to bigger unsigned' CSA warnings in GC_find_limit\n* Eliminate 'x might be clobbered by longjmp' gcc warning in setjmp_t.c\n* Fix 'un-mprotect vdb failed' abort with out-of-memory reason on Linux\n* Fix ADD_CALL_CHAIN() placement to follow GC_store_debug_info_inner call\n* Fix GC_debug_realloc to support custom kind\n* Fix GC_is_visible for case of arg pointing exactly to object upper bound\n* Fix GC_print_trace_inner to print the last element of the circular buffer\n* Fix cordtst2.tmp file deletion in cordtest on Windows\n* Fix double lock in GC_malloc called from backtrace()\n* Fix handling of page-unaligned boundaries in soft_set_grungy_pages\n* Fix heap blocks size computation by GC_get_memory_use\n* Fix indent of a closing curly braces in GC_apply_to_all_blocks\n* Fix infinite resend lost signals if a thread is restarted by SIGQUIT\n* Fix null pointer dereference in GC_is_visible if type_descr is null\n* Fix per_object_helper() after changing hb_sz units\n* Fix pointer relational comparison in GC_do_enumerate_reachable_objects\n* Fix poor thread-local allocation performance because of double EXTRA_BYTES\n* Fix potential GC_add_roots_inner call with an overflowed pointer (Win32)\n* Fix potential address overflow in GC_add_to_heap\n* Fix potential buffer overrun during read in GC_text_mapping\n* Fix various typos in comments\n* Prevent GC_noop_sink from scanning by the collector\n* Prevent redirected malloc call from a garbage collection routine\n* Redirect malloc_usable_size() in leak_detector.h\n* Remove redundant dirty/reachable_here calls in GC_malloc_explicitly_typed\n* Update and fix diagrams describing the tree structure for pointer lookups\n* Use atomic store to set GC_first_nonempty in GC_do_parallel_mark\n* Use atomic store to set entry id and update cache_ptr in slow_getspecific\n* Workaround '.obj file not found' error reported by watcom wlib\n\n\n== [8.2.6] 2024-02-04 ==\n\n* Avoid unexpected heap growth in gctest for the case of VERY_SMALL_CONFIG\n* Change gc.man to include gc/gc.h\n* Check for out-of-memory on every memory allocation in tests\n* Do not compile pthread_start.c on Cygwin even if build shared libs (CMake)\n* Eliminate 'alloc_small declared but unused' gcc warning in gctest\n* Eliminate 'make_key is defined but unused' gcc warning in threadkeytest\n* Eliminate 'old_segv_handler is defined but unused' gcc warning on OpenBSD\n* Eliminate 'rand() may return deterministic values' warning\n* Eliminate 'unused parameter' compiler warnings reported by MS clang\n* Eliminate 'unused parameter' gcc warning in free() if IGNORE_FREE\n* Eliminate 'unused value' gcc warnings in init_global_static_roots (Symbian)\n* Eliminate GCC warning of unsafe __builtin_return_address(1) in Cmake script\n* Eliminate compiler warning of missing cast in LONG_MULT after shift\n* Eliminate warning of unused expression result in GC_FreeBSDGetDataStart\n* Ensure _GNU_SOURCE is defined if HAVE_DLADDR is defined by configure\n* Fix 'g++ not found' error on OpenBSD (Makefile.direct)\n* Fix 'implicit declaration of function pthread_atfork' gcc error on MinGW\n* Fix 'implicit declaration of function sbrk' gcc error on Symbian\n* Fix 'implicit declaration of iscntrl()' warning in cord/de_win (MinGW)\n* Fix 'info' buffer potential overrun in GC_save_callers\n* Fix 'l-value specifies const object' MSVC error in GC_push_many_regs\n* Fix 'linker input unused' error inside check_c_compiler_flag (CMake)\n* Fix 'missing binary operator before token' gcc error in gcconfig.h\n* Fix 'missing sysconf() prototype' gcc error in setjmp_t tool (OpenBSD)\n* Fix 'sigset_t undeclared' MS VC error if pthreads-w32 is used\n* Fix 'undefined reference' linker errors if shared build on OpenBSD (CMake)\n* Fix 'unused GC_set_and_save_fault_handler' warning on OS X\n* Fix GC_push_stack_for() to push also Xmm registers on Windows/x64\n* Fix GC_set_handle_fork(1) on Darwin when MPROTECT_VDB but no threads\n* Fix MACH_TYPE macro redefinition on Symbian/arm\n* Fix SVR4 macro definition order\n* Fix asm constraint in LONG_MULT for gcc/x86\n* Fix assertion violation in GC_get_maps on Linux if malloc redirection\n* Fix back graph and checksums support in WCC_MAKEFILE\n* Fix bitwise negation and rounding direction in setjmp_t tool\n* Fix checksums GC_record_fault invocation on Darwin\n* Fix closing bracket placement for case statement in configure\n* Fix deprecation warning about support of CMake older than v3.5\n* Fix extra 'extern C' for include signal.h in gcconfig.h\n* Fix getcontext() detection by CMake on OpenBSD\n* Fix handling of GC_gc_no counter wrap in GC_clear_stack\n* Fix handling of GC_gc_no counter wrap in GC_notify_or_invoke_finalizers\n* Fix indent of a closing curly brace in GC_forward_exception\n* Fix lock assertion violation in GC_try_to_collect_inner on OS X\n* Fix missing GC_pthread_sigmask on FreeBSD and NetBSD\n* Fix missing _setjmp() on djgpp\n* Fix missing atomic barriers in CORD_from_file_lazy\n* Fix missing outermost parentheses in CORD_pos_cur_char_addr and hugetest\n* Fix missing redirect and implementation of pthread_sigmask() on OpenBSD\n* Fix missing type widening before left shift in GC_MAKE_PROC\n* Fix misspelled GC_HEADERS_H macro in gc_priv.h\n* Fix null dereference in check_finalizer_nested if redirect malloc on Linux\n* Fix posix_memalign() to overwrite pointer storage only on success\n* Fix race in init_lib_bounds on Linux with glibc v2.34+ if redirect malloc\n* Fix skipped removal of page protection in case of address hash collision\n* Fix typos in comments\n* Fix undefined GC_real_pthread_sigmask if redirect malloc on OS X\n* Fix update of last_back_trace_gc_no if KEEP_BACK_PTRS is not defined\n* Handle GC_gc_no counter overflow properly in GC_print_trace\n* Include Darwin CoreFoundation.h only if 32-bit ARM\n* Make gc_allocator<void> members public\n* Re-enable incremental mode on OS X (arm64)\n* Remove .log and cordtest .tmp files by 'make clean' (Makefile.direct)\n* Remove a redundant check of HOST_ANDROID in gcconfig.h\n* Remove duplication of random numbers generator formula\n* Specify constexpr in GC allocators if C++20 or later\n* Support NetBSD/riscv64\n* Support non-msys MinGW build by CMake\n* Turn on handle fork by default on Darwin (multi-threaded only)\n* Use AO primitives in GC_RAND_NEXT instead of no_sanitize attribute\n* Workaround 'malloc inconsistent dll linkage' MS VC error in CMake script\n* Workaround MS Clang failure to compile de_win.rc\n* Workaround mark stack overflow in GC_push_finalizer_structures on MinGW\n\n\n== [8.2.4] 2023-05-26 ==\n\n* Abort with appropriate message if first call of mmap fails with EPERM\n* Adjust CORD_ec comment placement in ec.h\n* Adjust WoW64 workaround to work on UWP/WinRT\n* Adjust naming of Win32/64 and x86/64 words in comments and documentation\n* Avoid potential race between realloc and GC_block_was_dirty\n* Do not double-clear first two words of object in GC_generic_malloc\n* Do not mention FASTLOCK in comment\n* Do not mix debug and non-debug allocations in disclaim tests\n* Do not prohibit threaded builds with malloc redirection on non-Linux\n* Do not prohibit zero proc argument in GC_register_disclaim_proc\n* Eliminate '&array may not produce intended result' wcc warnings\n* Eliminate 'GC_unmap_end declared but unused' bcc warning in disclaim_bench\n* Eliminate 'ISO C++17 does not allow register specifier' gcc warning\n* Eliminate 'cast signed to bigger unsigned' CSA warning in WARNs, new_thread\n* Eliminate 'n obtained from untrusted source' code defect FP in test_cpp\n* Eliminate 'skipping config since MAXSIG/_NSIG is unknown' cppcheck FP\n* Eliminate data race FP between remove_protection and write_fault_handler\n* Eliminate data race FP reported in need_unreachable_finalization by TSan\n* Ensure 'new' system header is included by gc_cpp.h if GC_INCLUDE_NEW\n* Ensure GC_NO_PTHREAD_SIGMASK defined if no GC_pthread_sigmask prototype\n* Fix 'EMSCRIPTEN macro redefined' compile error\n* Fix 'ISO C90 forbids mixed decl and code' warning in SOFT_VDB dirty_init\n* Fix 'call to undeclared pthread_setname_np' errors in configure and cmake\n* Fix 'failed to create new win32 semaphore' Cygwin fatal error at fork\n* Fix 'operator new is missing throw(bad_alloc)' clang warning in gc_cpp.h\n* Fix 'overflow in conversion from word' g++ warning in GC_init\n* Fix 'unknown option --no-undefined' linker error in cmake script (OS X)\n* Fix 'unresolved _end' linker error when targeting Android bitcode\n* Fix CORD_next() indent inside loop in test_basics() of cordtest\n* Fix DCL_LOCK_STATE placement in GC_set_oom_fn\n* Fix GC_excl_table overrun on overflow in GC_exclude_static_roots\n* Fix GC_thread_is_registered for finished threads\n* Fix GC_unreachable_finalize_mark_proc to ensure its unique address\n* Fix GC_unregister_my_thread call before GC functions usage in gctest\n* Fix IRIX5 defined wrongly on FreeBSD/mips, WinCE/mips, Tandem S-Series\n* Fix allocated objects count increment in alloc8bytes of gctest\n* Fix alt-stack handling in GC_push_all_stacks if stack grows up\n* Fix comparisons to heap boundary in GC_get_back_ptr_info and GC_mark_from\n* Fix data race in GC_heapsize_at_forced_unmap variable\n* Fix description of client promise for IGNORE_OFF_PAGE allocated objects\n* Fix disabling of automatic dynamic libraries registration\n* Fix double initialization of main thread local free lists on Win32\n* Fix gccpp and gctba library names in gcinterface.md\n* Fix infinite loop in disable_gc_for_dlopen and GC_wait_for_gc_completion\n* Fix infinite wait in pthread_join/detach if thread already finished (Win32)\n* Fix joinable threads shutdown on NaCl\n* Fix loop condition over dll_thread_table in GC_lookup_pthread (Win32)\n* Fix missing GC_CALLBACK for GC_waitForSingleObjectInfinite\n* Fix missing extern C for __asan_default_options\n* Fix missing libalphagc.so dependency in Makefile.direct\n* Fix missing lock while updating GC_in_thread_creation in GC_exit_check\n* Fix missing recovery from faults in GC_mark_some on Win64 if MinGW\n* Fix missing result check of pthread_attr_getdetachstate in pthread_create\n* Fix mistyped function name in documentation of REDIRECT_REALLOC\n* Fix negative heap size values reported in WARN\n* Fix null pointer dereference in TRACE_TARGET\n* Fix of GC_bytes_allocd increment in GC_generic_malloc_inner\n* Fix overlapping region assertion in mark_some if malloc redirect on Linux\n* Fix potential SIGSEGV on out-of-memory in gctest\n* Fix signals delivery fail in find-leak mode if init from non-main thread\n* Fix stack top/bottom print order in GC_push_all_stacks if stack grows up\n* Fix store-and-dirty call in GC_CONS\n* Fix unregistering of thread created by intercepted pthread_create on NaCl\n* Fix unused GC_parse_version if no SOFT_VDB and no parallel mark on Linux\n* Fix use of unset errno after pthread_create/sigmask calls\n* Fix various typos in comments and documentation\n* Increment allocated objects count after GC_GCJ_MALLOC() in gctest\n* Invoke GC_oom_fn if GC_make_array_descriptor failed because of no memory\n* Make Emscripten Asyncify feature optional\n* Mention gctba library in README.cmake\n* Prevent 'function should return a value' BCC error in CMake script\n* Provide meaningful error message in case of Emscripten threaded build\n* Reduce local variable scope in resend_lost_signals_retry for cppcheck\n* Remove disable-warning options from WCC_MAKEFILE unrecognized by wcc v2.0\n* Remove false warning of missing libpthread.so on Linux\n* Remove redundant 'ifdef THREADS' around LOCK/UNLOCK in call_with_alloc_lock\n* Remove redundant GC_ATTR_UNUSED for GC_mark_and_push\n* Remove unused GC_old_sig_mask from gc_locks.h\n* Replace WARN in GC_mark_some wrapper back to GC_COND_LOG_PRINTF\n* Specify throw and noexcept for operator new/delete in gc_cpp.h for MS VC\n* Support Hurd/x86_64\n* Support client-defined stack pointer adjustment before thread stack push\n* Suppress 'unreachable code' wcc warning in I_HOLD_LOCK assertion (CMake)\n* Update autotools for release preparation (ac-2.71, am-1.16.5, m4-1.14.19)\n* Update dump function name in GC_DUMP_REGULARLY variable documentation\n* Use emscripten_stack_get_base instead of emscripten_scan_stack\n* Use sbrk() to get OS memory on Emscripten\n* Workaround 'writing into region of size 0' gcc warning in suspend_handler\n* Workaround CSA null pointer dereference FP in invalidate_map of cord/de\n* Workaround a malfunction of soft-dirty bits clearing on Power9\n\n\n== [8.2.2] 2022-08-26 ==\n\n* Abort if no progress with thread suspend/resume signals resending\n* Add CMake option to force libatomic_ops headers usage\n* Add _PROP suffix to CORD/GC[CPP]_VERSION variables in CMake script\n* Allow not to bypass pthread_cancel hardening in pthread_start\n* Allow to start marker threads in child of single-threaded client\n* Avoid potential race in GC_init_real_syms after GC_allow_register_threads\n* Avoid potential signal loss before sigsuspend in suspend_handler if TSan\n* Define SUNOS5SIGS macro for kFreeBSD\n* Distribute gc_gcj.h and some other headers in single-obj-compilation\n* Do not assert that GC is initialized at DLL_THREAD_DETACH (Win32)\n* Do not call SET_HDR() to remove forwarding counts if none exists in hblk\n* Do not call mprotect/mmap to GC_unmap/remap (Linux)\n* Do not count unmapped regions if GC_unmap is madvise-based (Linux)\n* Do not define NEED_FIND_LIMIT in case of OpenBSD user threads\n* Do not fail tests if pthread_create returns resource unavailable error\n* Do not name GCC intrinsics as C11 ones\n* Do not probe to find main data root start if dl_iterate_phdr exists\n* Do not send signal to thread which is suspended manually\n* Do not use usleep between signals resend if ThreadSanitizer\n* Eliminate '-pedantic is not option that controls warnings' GCC-6.3 message\n* Eliminate '/GS cannot protect parameters' MS VC warning in msvc_dbg\n* Eliminate 'R_AARCH64_ABS64 used with TLS symbol' linker warning (clang)\n* Eliminate 'buffer overflow detected' FP error in realloc_test\n* Eliminate 'extension used' clang warning in sparc_mach_dep.S (configure)\n* Eliminate 'function/data pointer conversion in expression' MSVC warning\n* Eliminate 'implicit decl of _setjmp' gcc warning if -std=c11 on Cygwin\n* Eliminate 'layout of aggregates has changed in GCC 5' warning in test_cpp\n* Eliminate 'new_l may be used uninitialized' gcc warning in os_dep (Cygwin)\n* Eliminate 'old_gc_no is initialized but not referenced' MS VC false warning\n* Eliminate 'possible loss of data' compiler warning in GC_envfile_getenv\n* Eliminate 'potentially uninitialized local variable tc' warning (MSVC)\n* Eliminate 'skipping config since MAX_HEAP_SECTS is unknown' cppcheck FP\n* Eliminate 'unused but set variable' gcc warnings in cpptest\n* Eliminate 'value exceeds maximum size' warnings in debug_malloc, huge_test\n* Eliminate 'writing into region of size 0' gcc FP warning in realloc\n* Eliminate ASan stack-buffer-underflow FP in GC_mark_and_push_stack (E2K)\n* Eliminate code defect about incorrect size of allocated object (leaktest)\n* Eliminate data race reported by TSan in GC_have_errors\n* Eliminate division-by-zero FP warning in GC_ASSERT in reclaim_block\n* Eliminate stringop-overflow gcc-12 warning in CORD__next\n* Ensure typed objects descriptor is never located in the first word\n* Fix 'GC_greatest_stack_base_below is defined but not used' warning (IA64)\n* Fix 'GC_text_mapping not used' GCC warning if redirect malloc w/o threads\n* Fix 'ISO C forbids conversion of function pointer to object' warning\n* Fix 'undeclared getpagesize' compiler warning on AIX and OSF1\n* Fix 'undefined reference to __data_start' linker error on Linux/aarch64\n* Fix 'unresolved __imp__wsprintfA' linker error in msvc_dbg.c (MSVC)\n* Fix 'unresolved symbol GetModuleHandle' error in win32_threads.c (UWP)\n* Fix (workaround) stack overflow in gctest on Alpine Linux/s390x\n* Fix GC_ATTR_NO_SANITIZE_THREAD definition for GCC\n* Fix GC_allocate_ml incorrect cleanup in GC_deinit if pthreads (MinGW)\n* Fix GC_dirty() argument in GC_malloc_explicitly_typed_ignore_off_page\n* Fix GC_make_descriptor for zero length argument\n* Fix GC_suspend_thread if called before thread destructor\n* Fix GC_unmapped_bytes update in GC_unmap for Sony PS/3\n* Fix SIGSEGV caused by dropped stack access from child process in gctest\n* Fix SUNOS5SIGS documentation to match macro definition in gcconfig.h\n* Fix abort in Win32 DllMain if PARALLEL_MARK\n* Fix abort when GC_repeat_read returns zero\n* Fix assertion about built-in AO_test_and_set_acquire on sparc64 (gcc-12)\n* Fix assertion violation in GC_allow_register_threads on Windows\n* Fix assertion violation of GC_thread_key alignment if pthread-based TLS\n* Fix comment in GC_init regarding GC_init_parallel call\n* Fix context saving when GC_suspend_thread(self)\n* Fix data race in fail_proc1 of gctest\n* Fix hang in GC_free if GC_PREFER_MPROTECT_VDB (Mingw64)\n* Fix hang in select() called from suspend signal handler if TSan\n* Fix hang on sem_wait in GC_suspend_thread if thread was resumed recently\n* Fix hb_obj_kind type in documentation (ASCII diagram) describing hblkhdr\n* Fix incremental mode enabling in gctest if TEST_MANUAL_VDB\n* Fix linking of tests in case of finalization is off\n* Fix lock assertion violation in GC_find_limit if always multi-threaded\n* Fix memory return to OS in GC_unmap\n* Fix missing lock when GC_generate_random_valid_address is called\n* Fix missing write() declaration if CONSOLE_LOG (Watcom)\n* Fix nodist_libgc_la_SOURCES value in Makefile.am for Solaris/sparc\n* Fix oldProc initialization in gc_cleanup and eliminate related warnings\n* Fix parallel_initialized assertion violation in initsecondarythread (Win32)\n* Fix potential race if start_mark_threads called from threads in child\n* Fix propagation of out-of-memory occurred in GC_make_sequence_descriptor\n* Fix pthread_setname_np and dladdr detection by CMake\n* Fix race between calloc_explicitly_typed and push_complex_descriptor\n* Fix typos in comments and debugging.md\n* Fix undefined __stack_base__ on UWP/arm64 (llvm-mingw)\n* Force GC_with_callee_saves_pushed in suspend_handler if NO_SA_SIGACTION\n* Link with rt library to get clock_gettime where necessary\n* Make finalizer_closure pointer read/write atomic in malloc and callback\n* Move platform-specific sleep call to GC_usleep (refactoring)\n* Pass -lrt linker option in CMake script on HP/UX, NetBSD\n* Prevent (fix) parallel custom mark procs run in single-threaded clients\n* Prevent changing of GC_markers_m1 value while collection in progress\n* Refer to Makefile.direct instead of deleted Makefile file in README\n* Relax assertion of hb_n_marks in reclaim_block if more than two markers\n* Remove IF_IA64 macro in pthread_stop_world (refactoring)\n* Remove checking of RS6000 completely\n* Remove duplicate check of MSWIN_XBOX1 in os_dep.c\n* Remove duplicate include gc_tiny_fl.h in gc_priv.h\n* Remove non-working check of M68K in gctest\n* Remove useless TSan W/A about read of mark_lock_holder for Windows\n* Replace RAISE_SIGNAL macro with a static function (refactoring)\n* Replace SSH cloning with HTTPS one in README\n* Retry pthread_kill if EAGAIN (Linux)\n* Revert \"Check real-symbols are already initialized in pthread_join/detach\"\n* Revert \"Remove nested always-false ifdef for HPUX and FREEBSD\"\n* Revert addition of msvc_dbg.h in include.am\n* Set default build type to RelWithDebInfo (CMake)\n* Start configure help messages with a lower case letter\n* Support 'z' format modifier by CORD_vsprintf\n* Support Elbrus 2000 (Linux/e2k)\n* Support GCC MCF thread model (mcfgthreads) in configure (MinGW)\n* Support GC_remove_roots on Win32\n* Support OpenBSD/riscv64\n* Support build using Makefile.direct on Linux/sparc\n* Support space-separated flags in CFLAGS_EXTRA passed to CMake\n* Update README.win32 about default build configuration (configure, cmake)\n* Update documentation of GC_RATE and MAX_PRIOR_ATTEMPTS\n* Use SIGRTMIN+6 as suspend signal if sigrt-signals on OpenBSD\n* Use SIGUSR1/2 on FreeBSD/arm64\n* Use compiler TLS on NetBSD only if at least gcc-4.4 or clang-3.9\n* Workaround 'info is not assigned' cppcheck FP if assertions on (OS X)\n* Workaround SIG_SUSPEND delivery to thread inside mutex_lock fail if TSan\n* Workaround TSan FP about race between generic_malloc and array_mark_proc\n* Workaround TSan FP in acquire_mark_lock called from fork_prepare_proc\n* Workaround TSan FP warning in finalized_malloc, push_unconditionally\n* Workaround TSan FP warning in fork_prepare_proc\n* Workaround TSan FP warning in push_marked1/2/4, ptr_store_and_dirty\n* Workaround Thread Sanitizer (TSan) FP warning in is_valid_displacement\n* Workaround call stack size exceeded in gctest (Wasm)\n* Workaround crash in FreeBSD rand() by avoiding its concurrent usage\n* Workaround gctest hang if test compiled as C++ code by MSVC (CMake)\n* Workaround msvc_dbg.c build failure on arm[64] (MSVC)\n\n\n== [8.2.0] 2021-09-29 ==\n\n* Add API for accessing incremental GC time limit with nanosecond precision\n* Add API function to force start of incremental collection\n* Add GC_ prefix to scan_ptr and some other static variables (refactoring)\n* Add GC_get/set_disable_automatic_collection API\n* Add I_HOLD_LOCK assertion to expand_hp_inner and related functions\n* Add assertion on free-list argument and result of GC_new_kind\n* Add assertion that GC is initialized to base incremental_protection_needs\n* Add assertions that GC_page_size is initialized\n* Add cordtest, staticrootstest, test_cpp, tracetest, disclaim tests (CMake)\n* Add debug messages on thread suspend/resume (Win32)\n* Add dummy testing of GC_incr_bytes_allocd/freed\n* Add table of contents in gcdescr.md\n* Add testing of GC_CALLOC/MALLOC_EXPLICITLY_TYPED (gctest)\n* Adjust formatting of numbered lists in README.md to match other .md files\n* Adjust highlighting of API prototypes in gcinterface.md\n* Adjust macro def/usage for AVR32, CRIS, NETBSD, OPENBSD, SH4 in gcconfig.h\n* Adjust printf calls in gctest check_heap_stats so that each has new-line\n* Allow incremental GC on Cygwin\n* Allow memory unmapping in case of MPROTECT_VDB\n* Allow to disable GWW or mprotect-based VDB at build\n* Allow to disable Glibc FPU exception mask and TSX workarounds (Linux)\n* Allow to disable __builtin_return_address(1) usage (x86 and x64)\n* Allow to specify custom value of LOG_PHT_ENTRIES\n* Always abort on failure to access /proc/self/maps (Linux)\n* Always define default_push_other_roots (code refactoring)\n* Avoid gcc stringop-overflow warning for intended overflow in smashtest\n* Avoid initial 3ms pause on world stop/start with GC_retry_signals (Linux)\n* Build cord.lib by Makefile.direct, NT_MAKEFILE, OS2_MAKEFILE, WCC_MAKEFILE\n* Build gc as a shared multi-threaded library by default (CMake)\n* Build gccpp library by Makefile.direct, NT_MAKEFILE and WCC_MAKEFILE\n* Build gctba library\n* Build shared libraries by default (WCC_MAKEFILE)\n* Change CLOCK_TYPE to timespec for Nintendo Switch (code refactoring)\n* Change EMSCRIPTEN macro for internal use to no-underscore format\n* Change log_size fields of finalizer to unsigned type (code refactoring)\n* Change type of toggleref_array_size/capacity to size_t (code refactoring)\n* Check leak of objects allocated by CRT malloc in gctest (MS VC)\n* Check real-symbols are already initialized in pthread_join/detach\n* Collapse multiple includes of windows.h (code refactoring)\n* Comments reformatting in mark.c to properly delimit sentences\n* Compile de test GUI app with resources (CMake)\n* Compile gc.c unless building static libraries (NT_MAKEFILE, WCC_MAKEFILE)\n* Compile msvc_dbg.c by CMake script (MS VC)\n* Declare API function and print amount of memory obtained from OS\n* Define GC_win32_free_heap API function for all Windows targets\n* Define STATIC macro to static by default\n* Depend number of fork_a_thread calls on NTHREADS (gctest)\n* Detect dladdr() presence in CMake script\n* Detect presence of execinfo.h system header in CMake script\n* Detect presence of getcontext and dl_iterate_phdr in CMake script\n* Detect sigsetjmp() availability in CMake script\n* Disable Clang/GCC aliasing optimization in CMake script by default\n* Do not build tests by default (Makefile.direct and other Makefiles)\n* Do not build the tests by default (CMake)\n* Do not call GC_push_conditional unless PROC_VDB\n* Do not call add_to_our_memory with null pointer (refactoring)\n* Do not compile pthread_*.c files in Cygwin or MSYS (CMake)\n* Do not define GC_write_cs for Xbox One target\n* Do not define HAVE_NO_FORK for all Unix-like systems\n* Do not hard-code CMAKE_DL_LIBS value and install paths (CMake)\n* Do not hard-code finalizable objects limit which triggers GC\n* Do not update scratch_last_end_ptr unless used by reg dynamic libraries\n* Document GC_incr_bytes_allocd/freed API function\n* Eliminate '(long)size<=0 is always false' cppcheck FP\n* Eliminate 'Consecutive return is unnecessary' cppcheck style warning\n* Eliminate 'accessing GC_dont_gc without lock' in GC_init code defect FP\n* Eliminate 'bytes_freed access w/o lock in incr_bytes_free' code defect FP\n* Eliminate 'checking if unsigned i < 0' cppcheck FP in is_heap_base\n* Eliminate 'hash_val value is never used' cppcheck false positive\n* Eliminate 'passing tainted var maps_buf to tainted sink' code defect FP\n* Eliminate 'retry_cnt is assigned value but never used' cppcheck FP\n* Eliminate 'stop variable is always 0' compiler warning in print_callers\n* Eliminate 'struct member os_callback is never used' cppcheck warning\n* Eliminate 't->flags not atomically updated' code defect FP\n* Eliminate 'tmpl might be accessed at non-zero index' cppcheck error\n* Eliminate GCC warning of unsafe __builtin_return_address(1)\n* Eliminate code duplication in reclaim_clear and disclaim_and_reclaim\n* Eliminate double lock code defect false positive in generic_lock\n* Eliminate memory leak reported in add_current_malloc_heap at exit (Win32)\n* Emscripten single-threaded support (detect stack base, push registers)\n* Enable CMake-based build for Borland and Watcom compilers\n* Enable compilation without C runtime (Win32)\n* Enable fork testing in single-thread builds (Unix-like)\n* Enable mprotect-based incremental GC for Linux/arm and Linux/aarch64\n* Enable true incremental collection even if parallel marker is on\n* Enable use of __builtin_unwind_init() if clang-8 or later\n* Ensure ELFSIZE is defined in dyn_load.c for OpenBSD (code refactoring)\n* Ensure add_to_heap_inner arguments are valid (refactoring)\n* Ensure all getters and setters are run at least once by gctest (pthreads)\n* Export CMake targets with namespace BDWgc\n* Fix 'const obj must be initialized if not extern' error in gc_alloc_ptrs.h\n* Fix ./libgc.la dependency on FreeBSD (Automake)\n* Fix HOST determination in CMake script\n* Fix copyright message in de_win.rc, gc_cpp.cc, ec.h and specific.h\n* Fix missing OS_TYPE definition for some targets\n* Fix mmap(PROT_NONE) failure if RLIMIT_AS value is low (Linux)\n* Generate cordtest and de executable files in GC base folder\n* Generate pkg-config metadata file (CMake)\n* Get rid of some non-ELF ifdefs (code refactoring)\n* Handle potential incomplete buffer read in GC_linux_main_stack_base\n* Implement GET_TIME for Nintendo Switch\n* Increase NTHREADS value in tests if code coverage analysis\n* Install docs and man page if enable_docs (CMake)\n* Install gc_gcj.h and gc_pthread_redirects.h only if appropriate\n* Log abort message details even if not print_stats (unless SMALL_CONFIG)\n* Mark buffer returned by get_maps as const (code refactoring)\n* Move C++ GC_ATTR_EXPLICIT and GC_NOEXCEPT definition to gc_config_macros.h\n* Move GC state non-pointer variables into GC_arrays (code refactoring)\n* Move GC state pointer variables into GC_arrays\n* Move GC_scratch_recycle_inner() to alloc.c (refactoring)\n* Move GC_throw_bad_alloc definition to new C++ file\n* Move QNX and Emscripten macro definitions to proper place in gcconfig.h\n* Move definition of GC_n_mark_procs and GC_n_kinds from mark.c to misc.c\n* New API (GC_set_markers_count) to control number of parallel markers\n* New API function to clear GC exclusion table\n* New API function to get size of object debug header\n* New API standalone functions to acquire and release the allocator lock\n* New CMake option (disable_gc_debug) to remove debugging code\n* New CMake option (disable_handle_fork) to disable fork handling completely\n* New macro (CONSOLE_LOG) to enable logging to console on Win32\n* New macro (GCTEST_PRINT_VERBOSE) to enable verbose logging in test.c only\n* New macro (NO_MSGBOX_ON_ERROR) to avoid message box on GC abort (Win32)\n* OpenBSD does not use ELF_CLASS (code refactoring)\n* Pass -D GC_DLL -fvisibility=hidden if default configure build is requested\n* Pass -no-undefined linker flag if building shared libraries (CMake)\n* Print pid of child processes if verbose logging (gctest)\n* Read environment variables from a file on WinCE (CMake script)\n* Reduce stack-allocated buffer in get_nprocs from 4KB to 1.7KB\n* Refine flags field comment in pthread_support.h\n* Reflect result of VDB selection at runtime in incremental_protection_needs\n* Reformat code of GC_push_roots\n* Reformat gc.man (wrap long lines)\n* Reformatting and code refactoring of CMake script\n* Remove 'current users' section from overview.md\n* Remove 'distributed ports', 'scalable versions' sections from overview.md\n* Remove AC_MSG_RESULT for THREADDLLIBS (dgux386)\n* Remove Borland-specific Makefile and gc.mak script\n* Remove GC_eobjfreelist variable in typd_mlc.c (code refactoring)\n* Remove GC_gcj_malloc_initialized variable (code refactoring)\n* Remove Linux-specific commands for building cord/de from Makefile.direct\n* Remove Win32 main_thread static variable if threads discovery is disabled\n* Remove code duplication between GC_unmap and GC_unmap_gap (refactoring)\n* Remove code duplication between PROTECT and UNPROTECT macros (refactoring)\n* Remove commented out assignment of gc_use_mmap in configure (refactoring)\n* Remove dash characters comprising prefix of some verbose logs (gctest)\n* Remove dependency on user32.dll import library from static libgc (Win32)\n* Remove documentation specific to particular old BDWGC releases\n* Remove duplicate Linux-related macro definitions in gcconfig.h\n* Remove duplicate macro definitions in gcconfig.h except for Linux\n* Remove gcmt-dll generation, rename libgc-lib.a to libgc.a (CMake)\n* Remove goto statement in print_callers (code refactoring)\n* Remove limit on number of heap sections\n* Remove new_gc_alloc.h file\n* Remove redundant GC_with_callee_saves_pushed call in multi-threaded builds\n* Remove redundant check of GC_free argument in register_finalizer\n* Remove redundant type casts in backgraph HEIGHT_UNKNOWN/IN_PROGRESS\n* Remove unused GC_prev_heap_addr (refactoring)\n* Remove unused STACK_GRAN macro definitions (code refactoring)\n* Remove unused sparc_sunos4_mach_dep.s file\n* Remove useless empty statements after block ones (refactoring)\n* Remove weakobj_free_list variable in disclaim_weakmap_test (refactoring)\n* Rename READ to PROC_READ in os_dep.c (code refactoring)\n* Rename cord/cord test executable to de (CMake)\n* Rename ext_descr to typed_ext_descr_t (code refactoring)\n* Rename gc64.dll to gc.dll and gc[64]_dll.lib to gc.lib in NT_MAKEFILE\n* Rename gc68060.lib to gc.lib, cord/cord68060.lib to cord.lib in SMakefile\n* Rename make_as_lib option to enable_static in NT_MAKEFILE and WCC_MAKEFILE\n* Rename nothreads option to disable_threads in NT_MAKEFILE\n* Repeat run_one_test NTHREADS times by gctest if single-threaded\n* Replace \"msecs\" with \"ms\" in all comments and messages\n* Replace 'stack base' with 'stack bottom' in the documentation\n* Replace SN_TARGET_ORBIS to PLATFORM_* and GC_NO_* macros\n* Replace _M_AMD64 macro with _M_X64 (code refactoring)\n* Replace find_limit_openbsd to find_limit_with_bound (OpenBSD 5.2+)\n* Replace obsolete AC_HELP_STRING with AS_HELP_STRING (refactoring)\n* Replace push_one calls with push_many_regs one for Win32 thread context\n* Report memory region bounds and errno on GC_unmap/remap failure\n* Report presence of process fork testing (gctest)\n* Report time with a nanosecond precision where available\n* Retry suspend/resume signals on all platforms by default\n* Run tree and typed tests in child process (gctest)\n* Set GC_collecting hint for GC_collect_a_little_inner calls (pthreads)\n* Set name of GC marker threads\n* Set so-version for installed shared libraries (CMake)\n* Simplify logged message in scratch_recycle\n* Simplify loops of collect_a_little/stopped_mark invoking mark_some\n* Support -fvisibility=hidden option in CMake script\n* Support CFLAGS_EXTRA to pass extra user-defined compiler flags (CMake)\n* Support FreeBSD/RISC-V, Linux/arc, LoongArch, OpenBSD/powerpc64\n* Support header files installation (CMake)\n* Support most configure options in CMake script\n* Suppress warnings in test_tinyfl() of gctest reported by Watcom C complier\n* Take nanoseconds into account when updating full_gc_total_time\n* Turn off C++ API by default, export it in gccpp library (CMake)\n* Turn on automatic fork() handling by default on Android\n* Update README.cmake regarding Unix, C++ and tests\n* Update libgc.so version info to differentiate against v8.0.x\n* Update the ASCII diagrams describing the tree structure for pointer lookups\n* Update the documentation to match the current GC implementation\n* Upgrade cmake_minimum_required(version) to 3.1\n* Use CreateThread without GC_ prefix in gctest (code refactoring)\n* Use KB/MB/GB abbreviations uniformly across entire documentation\n* Use USE_MMAP_ANON when USE_MMAP is configured on OpenBSD\n* Use a specific Emscripten allocator for Tiny\n* Use atomic primitives for Sony PlayStation Portable 2 and PS4\n* Use better precision Windows timers\n* Use clock_gettime() instead of clock() on Cygwin and Linux\n* Use compiler TLS on FreeBSD and NetBSD\n* Use mprotect-based VDB on PowerPC and S390 (Linux)\n* Use soft dirty bits on Linux (x86, powerpc, s390, x64)\n* Workaround 'condition result<=0 is always false' cppcheck FP in get_maps\n* Workaround 'push_regs configured incorrectly' error (GCC-11)\n* Workaround 'same value in both branches of ternary operator' cppcheck FP\n* Workaround various cppcheck false positives\n\n\n== [8.0.14] 2024-09-07 ==\n\n* Disable backtrace saving at garbage collections if DONT_SAVE_TO_LAST_STACK\n* Fix infinite resend lost signals if a thread is restarted by SIGQUIT\n\nAlso, includes 7.6.22 changes\n\n\n== [8.0.12] 2024-02-04 ==\n\n* Eliminate 'make_key is defined but unused' gcc warning in threadkeytest\n* Ensure _GNU_SOURCE is defined if HAVE_DLADDR is defined by configure\n* Fix 'implicit declaration of function pthread_atfork' gcc error on MinGW\n* Fix 'missing binary operator before token' gcc error in gcconfig.h\n* Fix GC_set_handle_fork(1) on Darwin when MPROTECT_VDB but no threads\n* Fix checksums GC_record_fault invocation on Darwin\n* Fix extra 'extern C' for include signal.h in gcconfig.h\n\nAlso, includes 7.6.20 changes\n\n\n== [8.0.10] 2023-05-26 ==\n\n* Abort with appropriate message if first call of mmap fails with EPERM\n* Avoid potential race between realloc and GC_block_was_dirty\n* Do not prohibit zero proc argument in GC_register_disclaim_proc\n* Eliminate '&array may not produce intended result' wcc warnings\n* Eliminate 'cast signed to bigger unsigned' CSA warning in GC_new_thread\n* Ensure 'new' system header is included by gc_cpp.h if GC_INCLUDE_NEW\n* Fix 'overflow in conversion from word' g++ warning in GC_init\n* Fix description of client promise for IGNORE_OFF_PAGE allocated objects\n* Fix infinite loop in disable_gc_for_dlopen and GC_wait_for_gc_completion\n* Fix missing extern C for __asan_default_options\n* Fix store-and-dirty call in GC_CONS\n* Fix typo in comment of GC_Thread_Rep.dummy\n* Fix use of unset errno after pthread_sigmask calls\n* Increment allocated objects count after GC_GCJ_MALLOC() in gctest\n* Remove redundant GC_ATTR_UNUSED for GC_mark_and_push\n* Workaround CSA null pointer dereference FP in invalidate_map of cord/de\n\nAlso, includes 7.6.18 changes\n\n\n== [8.0.8] 2022-08-26 ==\n\n* Avoid potential race in GC_init_real_syms after GC_allow_register_threads\n* Define SUNOS5SIGS macro for kFreeBSD\n* Distribute gc_disclaim.h in single-obj-compilation\n* Do not assert that GC is initialized at DLL_THREAD_DETACH (Win32)\n* Do not name GCC intrinsics as C11 ones\n* Do not send signal to thread which is suspended manually\n* Eliminate 'buffer overflow detected' FP error in realloc_test\n* Eliminate 'extension used' clang warning in sparc_mach_dep.S (configure)\n* Eliminate 'function/data pointer conversion in expression' MSVC warning\n* Eliminate 'implicit decl of _setjmp' gcc warning if -std=c11 on Cygwin\n* Eliminate 'new_l may be used uninitialized' gcc warning in os_dep (Cygwin)\n* Eliminate 'old_gc_no is initialized but not referenced' MS VC false warning\n* Eliminate 'possible loss of data' compiler warning in GC_envfile_getenv\n* Eliminate 'value exceeds maximum size' warnings in debug_malloc, huge_test\n* Eliminate 'writing into region of size 0' gcc FP warning in realloc\n* Eliminate division-by-zero FP warning in GC_ASSERT in reclaim_block\n* Eliminate stringop-overflow gcc-12 warning in CORD__next\n* Ensure typed objects descriptor is never located in the first word\n* Fix 'GC_greatest_stack_base_below is defined but not used' warning (IA64)\n* Fix 'GC_text_mapping not used' GCC warning if redirect malloc w/o threads\n* Fix 'ISO C forbids conversion of function pointer to object' warning\n* Fix 'undeclared getpagesize' compiler warning on AIX and OSF1\n* Fix 'undefined reference to __data_start' linker error on Linux/aarch64\n* Fix GC_allocate_ml incorrect cleanup in GC_deinit if pthreads (MinGW)\n* Fix GC_dirty() argument in GC_malloc_explicitly_typed_ignore_off_page\n* Fix GC_make_descriptor for zero length argument\n* Fix GC_suspend_thread if called before thread destructor\n* Fix GC_unmapped_bytes update in GC_unmap for Sony PS/3\n* Fix SIGSEGV caused by dropped stack access from child process in gctest\n* Fix SUNOS5SIGS documentation to match macro definition in gcconfig.h\n* Fix abort in Win32 DllMain if PARALLEL_MARK\n* Fix assertion about built-in AO_test_and_set_acquire on sparc64 (gcc-12)\n* Fix assertion violation in GC_allow_register_threads on Windows\n* Fix assertion violation of GC_thread_key alignment if pthread-based TLS\n* Fix context saving when GC_suspend_thread(self)\n* Fix data race in fail_proc1 of gctest\n* Fix get_maps failure when GC_repeat_read returns zero\n* Fix hang in GC_free if GC_PREFER_MPROTECT_VDB (Mingw64)\n* Fix hang in select() called from suspend signal handler if TSan\n* Fix hang on sem_wait in GC_suspend_thread if thread was resumed recently\n* Fix hb_obj_kind type in documentation (ASCII diagram) describing hblkhdr\n* Fix incremental mode enabling in gctest if TEST_MANUAL_VDB\n* Fix lock assertion violation in GC_find_limit if always multi-threaded\n* Fix missing lock when GC_generate_random_valid_address is called\n* Fix nodist_libgc_la_SOURCES value in Makefile.am for Solaris/sparc\n* Fix oldProc initialization in gc_cleanup and eliminate related warnings\n* Fix parallel_initialized assertion violation in initsecondarythread (Win32)\n* Fix potential race if start_mark_threads called from threads in child\n* Fix propagation of out-of-memory occurred in GC_make_sequence_descriptor\n* Fix race between calloc_explicitly_typed and push_complex_descriptor\n* Fix stack overflow in gctest on Alpine Linux/s390x\n* Fix typo in debugging.html\n* Fix typos in comments of .c files and gc.h\n* Fix undefined __stack_base__ on UWP/arm64 (llvm-mingw)\n* Make finalizer_closure pointer read/write atomic in malloc and callback\n* Prevent (fix) parallel custom mark procs run in single-threaded clients\n* Prevent changing of GC_markers_m1 value while collection in progress\n* Refer to Makefile.direct instead of deleted Makefile file in README\n* Relax assertion of hb_n_marks in reclaim_block if more than two markers\n* Remove checking of RS6000 completely\n* Remove duplicate check of MSWIN_XBOX1 in os_dep.c\n* Remove non-working check of M68K in gctest\n* Remove useless TSan W/A about read of mark_lock_holder for Windows\n* Replace SSH cloning with HTTPS one in README\n* Revert \"Remove nested always-false ifdef for HPUX and FREEBSD\"\n* Revert addition of msvc_dbg.h in include.am\n* Support 'z' format modifier by CORD_vsprintf\n* Update documentation of GC_RATE and MAX_PRIOR_ATTEMPTS\n* Use SIGRTMIN+6 as suspend signal if sigrt-signals on OpenBSD\n* Workaround TSan FP about race between generic_malloc and array_mark_proc\n* Workaround TSan FP warning in finalized_malloc, push_unconditionally\n* Workaround TSan FP warning in push_marked1/2/4, ptr_store_and_dirty\n* Workaround Thread Sanitizer (TSan) FP warning in is_valid_displacement\n* Workaround crash in FreeBSD rand() by avoiding its concurrent usage (tests)\n\n\n== [8.0.6] 2021-09-28 ==\n\n* Add loop to handle abort error like in suspend logic on Darwin\n* Add support of OpenBSD/aarch64\n* Add threading libraries to bdw-gc.pc\n* Allocate start_info struct on the stack in GC_pthread_create\n* Allow GC_PAUSE_TIME_TARGET environment variable values smaller than 5 ms\n* Avoid compiler warning about unused d in GC_CALLOC/MALLOC_EXPLICITLY_TYPED\n* Avoid gcc stringop-overflow warning for intended overflow in smashtest\n* Check _MSVC_LANG macro in addition to __cplusplus (MS VC)\n* Compile C++ code with exception handling enabled in NT_MAKEFILE\n* Define OS_TYPE and DATAEND for UWP targets\n* Disable mprotect-based incremental GC if /proc roots are used (Linux)\n* Do not report 'Incremental GC incompatible' warning more than once\n* Do not use Manual VDB mode if C malloc is redirected\n* Do not use iOS private symbols\n* Eliminate 'GC_non_gc_bytes is deprecated' warning in new_gc_alloc.h\n* Eliminate 'GC_old_bus_handler defined but not used' compiler warning\n* Eliminate 'cast between incompatible func types' warnings for FARPROC vars\n* Eliminate 'comparing signed and unsigned values' BCC warning in cordtest\n* Eliminate 'gc_pthread_redirects.h should contain header guard' code defect\n* Eliminate 'implicit declaration of sbrk' gcc warning if -std=c11 on Cygwin\n* Eliminate 'possible loss of data' BCC and MS VC warnings\n* Eliminate 'static GC_sysinfo definition has incomplete type' Clang warning\n* Eliminate 'unused function' compiler warnings (GC_add_map_entry, GC_lock)\n* Eliminate 'while clause does not guard' GCC warning in GC_parse_map_entry\n* Enable sbrk-to-mmap fallback on major supported Unix-like platforms\n* Ensure process is running on one CPU core if AO ops are emulated with locks\n* Explicitly zero-initialize trace_buf (fix trace_buf initialization)\n* Fix 'ACCESS_VIOLATION in marker' GC warning on Win32 async thread start\n* Fix 'GC_generic_malloc must be available' GCC error in new_gc_alloc.h\n* Fix 'ISO C++17 does not allow dynamic exception spec' clang-8 error\n* Fix 'Wrong __data_start/_end pair' if -Bsymbolic-functions used (Linux)\n* Fix 'condition pred!=NULL is always true' compiler warning\n* Fix 'external linkage required for var because of dllimport' error on MinGW\n* Fix 'ulong undefined' compilation error on AIX\n* Fix 'undefined reference to __data_start' linker error on RISC-V\n* Fix 'use of undeclared BUS_PAGE_FAULT' compilation error on FreeBSD 12\n* Fix 'write to GC log failed' error (Cygwin)\n* Fix 'wrong finalization data' gctest failure on Windows\n* Fix CMake build on macOS Catalina\n* Fix GC_OPENBSD_THREADS definition (OpenBSD/hppa)\n* Fix GC_proc_fd value in child process at fork (Solaris)\n* Fix GC_with_callee_saves_pushed for Android NDK r23 (clang-12)\n* Fix MPROTECT_VDB definition for single-threaded GC builds\n* Fix OS_TYPE and USE_MMAP_ANON definitions for Cygwin/x64\n* Fix STACKBOTTOM on 32-bit HP/UX 11.11\n* Fix abort in GC_printf when gctest is built as WinMain executable (Cygwin)\n* Fix assertion violation in register_dynlib_callback on Android\n* Fix build for OS X (CMake)\n* Fix building of shared library with C++ support on MinGW\n* Fix compiling by Makefile.direct on OpenBSD/UltraSparc\n* Fix configure message about 'AIX gcc optimization fix'\n* Fix cordtest build in SMakefile.amiga\n* Fix data race regarding *rlh value in generic_malloc_many\n* Fix first_thread stack_base initialization if custom GC_stackbottom (Win32)\n* Fix gc_allocator.h compilation by Clang\n* Fix gc_cflags variable name in configure (HP/UX)\n* Fix handling of areas smaller than page size in GC_scratch_recycle\n* Fix incorrect markup formatting in documentation\n* Fix misaligned tlfs passed to AO_load on m68k\n* Fix missing GC_quiet declaration in pcr_interface.c\n* Fix missing gc_dlopen.c and specific.c in CMake script\n* Fix missing scratch_last_end_ptr update (Irix)\n* Fix mmap() failures on AIX, HP/UX and Haiku\n* Fix overflow of scratch_free_ptr value\n* Fix page_was_[ever_]dirty() for static roots (Solaris)\n* Fix printf format specifier in simple_example.md\n* Fix save_callers for multi-threaded case if built-in backtrace unavailable\n* Fix subexpression widening in memhash() of disclaim_weakmap_test\n* Fix test_cpp failure caused by arbitrary link order (Win32)\n* Fix test_cpp failure when gc_cpp resides in a dll (Borland, Watcom)\n* Fix various typos mostly in documentation files\n* Fix word size, data start and alignment for OpenBSD/mips64(el)\n* Include <alloca.h> when using alloca on AIX\n* Limit number of unmapped regions (Linux and DragonFly)\n* New macro to avoid system-wide new/delete inlining in gc_cpp.h (Win32)\n* Prevent GetThreadContext failure (Windows)\n* Prevent WARN of incompatible incremental GC if default or manual VDB\n* Reduce a time period between GetExitCodeThread and SuspendThread (Win32)\n* Refactoring of WoW64 workaround (Win32)\n* Refine GC_INIT documentation about its multiple invocation\n* Refine GC_parallel documentation in gc.h\n* Refine do_blocking() documentation in gc.h\n* Remove a misleading comment about Solaris in gc.h\n* Remove cord .h files from list of non-installed headers (Automake)\n* Remove dead part of condition to define NEED_FIND_LIMIT in gc_priv.h\n* Remove gcmt-lib generation by CMake\n* Support MSYS builds by CMake and configure\n* Update documentation about the incremental collector support\n* Use HEURISTIC2 on OpenBSD when single-threaded\n* Use pstat_getprocvm to determine main stack bottom on HP-UX\n* Workaround 'expression is only useful for its side effects' WCC warning\n* Workaround clang-3.8/s390x bug when processing __builtin_frame_address\n* Workaround fread fail after enable_incremental if malloc redirected (Linux)\n\n\n== [8.0.4] 2019-03-02 ==\n\n* Avoid a full GC when growing finalizer tables if in incremental mode\n* Avoid potential race in hb_sz access between realloc and reclaim_block\n* Avoid test.o rebuild on tests folder timestamp change (Makefile.direct)\n* Avoid unexpected heap growth in gctest caused by GC_disable\n* Ensure result of every variant of MS_TIME_DIFF has unsigned long type\n* Fix 'duplicate symbol' error for tests using multiple static libs (OS X)\n* Fix 'undefined reference to __data_start' linker error (Android/aarch64)\n* Fix 'unexpected mark stack overflow' abort in push_all_stack\n* Fix 'wrong __data_start/_end pair' error on Android\n* Fix BSD_TIME variant of MS_TIME_DIFF for the case of a.tv_usec < b.tv_usec\n* Fix GetThreadContext stale register values use if WoW64 (Win32)\n* Fix invalid initializer of CLOCK_TYPE variables if BSD_TIME\n* Fix thread_info() count argument value (OS X)\n* Support de_win.c compilation by Makefile.direct (cord/de)\n\n\n== [8.0.2] 2018-12-23 ==\n\n* Abort with appropriate message if executable pages cannot be allocated\n* Add initial testing of GC_enable/disable, MALLOC[_ATOMIC]_IGNORE_OFF_PAGE\n* Add paths to filenames mentioned in the copyright section in README\n* Add test using disclaim notifiers to implement a weak map\n* Adjust #error messages format\n* Allow to force executable pages allocation in gctest\n* Avoid potential 'macro redefinition' errors for config.h macros\n* Call real pthread_sigmask instead of its wrapper in start_mark_threads\n* Check result of pthread_mutex_unlock in specific.c\n* Default to a single-threaded build for Nintendo, Orbis, Sony PSP targets\n* Default to non-executable memory allocation across all make scripts\n* Define GC_ATOMIC_UNCOLLECTABLE and JAVA_FINALIZATION in all make scripts\n* Do not prevent GC from looking at environment variables (BCC_MAKEFILE)\n* Do not use 'ifndef AO_CLEAR' in mark, pthread_support and gctest\n* Do not use spin locks if AO test-and-set is emulated (pthreads)\n* Document HANDLE_FORK macro optional usage in Makefile.direct\n* Document assertion in the setters that used to return old value\n* Eliminate 'assigned value never used' compiler warning in test_cpp WinMain\n* Eliminate 'casting signed to bigger unsigned int' CSA warning\n* Eliminate 'different const qualifiers' MS VC warnings in cordbscs\n* Eliminate 'function is never used' cppcheck warning for calloc/realloc\n* Eliminate 'non-virtual destructor for class with inheritors' CSA warning\n* Eliminate 'pointer targets differ in signedness' compiler warning (Win32)\n* Eliminate 'struct member is never used' cppcheck warnings in os_dep\n* Eliminate 'uninitialized var' cppcheck false positive in mach_dep, os_dep\n* Eliminate 'unreferenced formal parameter' compiler warning in msvc_dbg\n* Eliminate redundant check in backwards_height\n* Fix 'USE_MUNMAP macro redefinition' error for NaCl\n* Fix 'collecting from unknown thread' abort in leak-finding mode for Win32\n* Fix 'mprotect remapping failed' abort on NetBSD with PaX enabled\n* Fix 'too wide non-owner permissions are set for resource' code defect\n* Fix GC_VSNPRINTF in cordprnt for DJGPP and MS VC for WinCE\n* Fix GC_register_disclaim_proc for leak-finding mode\n* Fix a deadlock in write_fault_handler if AO_or is emulated\n* Fix comment typo in CMakeLists.txt\n* Fix concurrent bitmap update in GC_dirty\n* Fix deadlocks in write and suspend handlers if AO test-and-set is emulated\n* Fix executable memory allocation in GC_unix_get_mem\n* Fix hbp overflow in GC_install_counts\n* Fix linkage with a system libatomic_ops shared library\n* Fix lock assertion violation in get_index if GC_ALWAYS_MULTITHREADED\n* Fix marking of finalizer closure object\n* Fix marks and hb_n_marks consistency when disclaim returns true\n* Fix memory allocation on GCF (Linux/x64)\n* Fix missing curses.h in cord/de when compiling manually (MS VC, MinGW)\n* Fix test_cpp assertion violation in find-leak mode\n* Fix tests linkage with internal atomic_ops.o\n* Fix unneeded end_stubborn_change/ptr_store_and_dirty in disclaim_test\n* Guard against potential buffer overflow in CORD_next and CORD_pos_fetch\n* New macro to suppress printing of leaked objects\n* Pass -Wall -Wextra -Wpedantic to g++ if supported (configure)\n* Prefix internal durango_get_mem symbol with 'GC_'\n* Prevent double inclusion of javaxfc.h and private/specific.h\n* Print relevant message in tests not appropriate for leak detection mode\n* Reduce scope of local variables in GC_remove_all_threads_but_me\n* Refine HIDE_POINTER documentation for the case of the leak-finding mode\n* Refine documentation in gc_disclaim.h\n* Remove extra USE_MMAP definition for Interix\n* Remove redundant header double-inclusion checks in the private headers\n* Remove strlen calls with a constant string argument in msvc_dbg\n* Specify register_disclaim_proc and finalized_malloc argument as non-null\n* Support UWP/arm64 target\n* Test marking of finalizer closure object in disclaim_test\n* Turn off leak detection mode explicitly in cord/de\n* Turn off parallel marker, thread-local allocation if used AO ops emulated\n* Turn on gcj functionality in BCC, DMC, NT, OS/2, WCC makefiles\n* Turn on memory unmapping in BCC/DMC/NT/WCC makefiles and Makefile.direct\n* Update NO_EXECUTE_PERMISSION documentation\n* Update documentation about arm64 ABI in gcconfig.h\n* Use AO_or in async_set_pht_entry_from_index if available\n* Use GC_WORD_MAX macro across all C source files\n* Use macro to operate on a flag residing in GC_stop_count\n* Use standalone private macro to guard against ptr_t redefinition\n* Workaround '#error' cppcheck messages in backgraph and private headers\n* Workaround 'AST broken' syntax error reported by cppcheck in GC_mark_some\n* Workaround 'GC_dump function is never used' cppcheck warning\n* Workaround 'local address assignment to a global variable' CSA warning\n* Workaround 'local variable end shadows outer symbol' cppcheck warnings\n* Workaround 'local variable obj_displ shadows outer symbol' cppcheck warning\n* Workaround 'nonlocal var will use ptr to local var' cppcheck false positive\n* Workaround 'pointer addition with NULL pointer' cppcheck error in msvc_dbg\n* Workaround 'potential non-terminated string' false positive in cordbscs\n* Workaround 'value of _MAX_PATH is unknown' cppcheck warning\n* Workaround cppcheck warnings regarding CLOCKS_PER_SEC, REDIRECT_REALLOC\n\n\n== [8.0.0] 2018-09-05 ==\n\n* Accept Android platform by both CMake and configure\n* Access finalize_now atomically to avoid TSan warning without no-sanitize\n* Acknowledge thread restart from suspend_handler (NetBSD)\n* Add a sanity check that load_acquire and store_release are available\n* Add AO primitives implementation to GC based on GCC atomic intrinsic\n* Add assertion for suspend_ack_sem in start_world\n* Add assertion to allocobj that live unmarked object cannot be reclaimed\n* Add assertions about held lock when accessing all_bottom_indices\n* Add assertions to ensure ADD_CALL_CHAIN is called holding the lock\n* Add assertions to finalize and threads support for MANUAL_VDB needs\n* Add basic calculation of the total full-collection time\n* Add check that gc_cpp operator delete is called (test_cpp)\n* Add debug logging to new_thread about GC_threads hash table collisions\n* Add GC prefix to _MSVC_DBG_H macro\n* Add initial RISC-V support\n* Add Makefile target to run all tests without test-driver\n* Add test_atomic_ops to perform minimal testing of used atomic primitives\n* Add two-argument alloc_size attribute to calloc_explicitly_typed (GCC)\n* Align IRIX/OSF1_THREADS definition in gc_config_macros.h with gcconfig.h\n* Allocate non-executable memory by default (CMake)\n* Allow compilation of PROC_VDB code on Linux host (GC_NO_SYS_FAULT_H)\n* Allow configure --with-libatomic-ops=none to use GCC atomic intrinsics\n* Allow custom N_LOCAL_ITERS and ENTRIES_TO_GET values\n* Allow disabling of dynamic loading in CMake script and configure\n* Allow disabling of main static data registration in CMake and configure\n* Allow disabling of threads discovery in CMake script and configure\n* Allow gc_assertions enabling in CMake script\n* Allow gc_debug, redirect_malloc, large_config options in CMake script\n* Allow GC_NETBSD_THREADS_WORKAROUND macro manual definition\n* Allow mmap enabling in CMake script and configure\n* Allow passing -D DEFAULT_VDB to CFLAGS\n* Allow subthreadcreate_test to be compiled with zero NTHREADS\n* Allow to turn on spin locking even if thread-local allocations are used\n* Always include gc_atomic_ops.h unless threads are disabled\n* Avoid 'Unexpected heap growth' in 64-bit multi-threaded gctest if n_tests=1\n* Avoid duplication of code handling pthreads case in configure\n* Avoid potential data race during apply_to_each_object(reset_back_edge)\n* Avoid potential data race during GC_dump execution\n* Avoid potential race between malloc_kind and mark_thread_local_fls_for\n* Avoid potential race between realloc and clear_hdr_marks/reclaim_generic\n* Avoid potential race in print_static_roots called by dyld_image_add/remove\n* Avoid potential race in SET_MARK_BIT_EXIT_IF_SET if parallel marking\n* Avoid potential race when accessing size_map table\n* Avoid potential race when storing oh_back_ptr during parallel marking\n* Avoid SIGSEGV during GC_INIT on some Android devices\n* Build only shared libraries by default (configure)\n* Change pointer arguments of push_all[_eager]/conditional API to void* type\n* Change type of hb_sz field (of hblkhdr) from size_t to word\n* Check consistency of descr, adjust, clear arguments of GC_new_kind\n* Check that GC_WIN32_PTHREADS is not specified for Cygwin\n* Check thread_local is initialized before accessing thread_key\n* Collapse multiple BCOPY_EXISTS macro definitions\n* Collapse multiple NT_*_MAKEFILE scripts into a single NT_MAKEFILE\n* Collapse multiple page_was_dirty, remove_protection, read_dirty definitions\n* Compile checksums.c only if --enable-checksums is given (configure)\n* Consistently define WIN32_LEAN_AND_MEAN/NOSERVICE before include windows.h\n* Convert .html files to Markdown format\n* Convert code of .c files to valid C++ code\n* Decide between memory unmapping and mprotect-based dirty bits at runtime\n* Declare t local variable in the block where the variable is used\n* Define ABORT() using _CrtDbgBreak (if available) on Windows host\n* Define CLANG/GNUC_PREREQ macros to check gcc/clang minimum version\n* Define DYNAMIC_LOADING for Darwin unless IGNORE_DYNAMIC_LOADING\n* Define GC_ASSERT(x) as C assert(x) for external clients of gc_inline.h\n* Define GC_PREFETCH_FOR_WRITE to __builtin_prefetch in gc_inline.h (GCC)\n* Define GC_THREADS instead of GC_x_THREADS in Makefiles\n* Define macro to specify the environment file name extension (Win32/WinCE)\n* Define static resend_lost_signals(), restart_all() in pthread_stop_world\n* Detect sigsetjmp() availability by configure\n* Determine whether to use compiler TLS for kFreeBSD at compile time\n* Do not call BCOPY and BZERO if size is zero\n* Do not call sem_getvalue in stop_world if one thread exists\n* Do not call set_handle_fork(1) in gctest if pthread_atfork not supported\n* Do not compile pcr_interface.c and real_malloc.c except by PCR-Makefile\n* Do not declare dl_iterate_phdr as weak for kFreeBSD\n* Do not include windows.h when compiling gc_cpp.cc\n* Do not install gc_allocator.h, gc_disclaim.h unless the features enabled\n* Do not merge dynamic root with the existing static one in add_roots_inner\n* Do not print n_rescuing_pages value if incremental collections disabled\n* Do not push cpsr and frame pointer on Darwin/arm and Darwin/arm64\n* Do not rebuild_root_index unless remove_root_at_pos is called\n* Do not specify version info for test libraries (Automake)\n* Do not use alternate thread library on Solaris\n* Do not use asm in GC_pause\n* Do not use PKG_CHECK_MODULES in configure\n* Do not use system clock consistently if NO_CLOCK\n* Do not use x86 asm in PUSH_CONTENTS_HDR for NaCl\n* Document GC_BUILTIN_ATOMIC macro (and gc_atomic_ops private header file)\n* Document STACK_NOT_SCANNED macro in gcconfig.h (Emscripten)\n* Eliminate 'comparison is always false' code defect in get_maps\n* Eliminate 'GC_DEBUG redefined' compiler warning in smashtest\n* Eliminate 'potential unsafe sign check of a bitwise operation' code defect\n* Enable alternative finalization interface (DISCLAIM) in all makefiles\n* Enable compilation for Cygwin with MPROTECT_VDB\n* Enable handle-fork and memory unmapping by default\n* Enable mprotect-based incremental GC for Win64 (GCC)\n* Expose API to control rate and max prior attempts of collect_a_little\n* Expose API to control the minimum bytes allocated before a GC occurs\n* Fix 'comparison of 255 with expr of type bool' error in gc_atomic_ops.h\n* Fix 'doc' files installation folder\n* Fix build of cord tests as C++ files (Makefile.direct)\n* Fix comment typos in backgraph.c, de.c, gcconfig.h\n* Fix delete operator redirection if gc_cpp is built as .dll (Cygwin, MinGW)\n* Fix start_world not resuming all threads on Darwin\n* Fix test_cpp failure in case GC_DEBUG is defined\n* Group common defines for POSIX platforms in configure and CMake scripts\n* Guard against USE_PTHREAD_LOCKS and USE_SPIN_LOCK are both defined\n* Handle pthread restart signals loss if retry_signals\n* Hide value stored to thread-specific entries for a test purpose\n* Implement FindTopOfStack(0) for ARM and AArch64 (Darwin)\n* Implement memory unmapping for Sony PS/3\n* Imply configure --single-obj-compilation if --disable-static\n* Include malloc.c in extra/gc.c after include gc_inline.h\n* Increase MAX_HEAP_SECTS (10 times) for large-config\n* Initial single-threaded support of Interix subsystem\n* Initial support of Nintendo, Orbis, Sony PSP2, WinRT, Xbox One\n* Initial support of TIZEN platform\n* Install gc.3 man page instead of copying gc.man to doc folder (configure)\n* Make extend_size_map() static (code refactoring)\n* Make subthreadcreate test compilable even without libatomic_ops\n* Match GC_FAST_MALLOC_GRANS formal and actual arguments where possible\n* Move de_win compiled resource files to cord/tests\n* Move pcr_interface.c, real_malloc.c to 'extra' folder\n* New API function (GC_dump_named) to produce named dumps\n* New API function (GC_is_incremental_mode)\n* New API function (get_expl_freed_bytes_since_gc)\n* New API function (get_size_map_at) to get content of size_map table\n* New API to stop and start the GC world externally\n* New API to turn on manual VDB at runtime\n* New field (expl_freed_bytes_since_gc) in public prof_stats_s\n* New macro ALWAYS_SMALL_CLEAR_STACK to avoid clearing large stack sections\n* New public API (PTR_STORE_AND_DIRTY) to simplify store-and-dirty operation\n* Pass CFLAGS_FOR_PIC value to CFLAGS in Makefile.direct\n* Print time passed since GC initialization in GC_dump\n* Public API (GC_deinit) to allow Win32 critical sections deletion\n* Reduce probability of collision in threads hashtable for 64-bit targets\n* Reduce the default MUNMAP_THRESHOLD value to 2 for Sony PS/3\n* Refactoring of USE_MMAP/USE_MMAP_ANON pairs definition in gcconfig.h\n* Reformat code and comments in gc_allocator.h\n* Remove 'dist' target from Makefile.direct\n* Remove a redundant check of __cplusplus in Symbian-specific .cpp files\n* Remove Android-specific code in gcconfig.h for M68K\n* Remove C++ WeakPointer and CleanUp API which lacks implementation\n* Remove DGUX_THREADS macro which duplicates GC_DGUX386_THREADS (configure)\n* Remove done_init static variable from fnlz_mlc.c\n* Remove duplicate definition of ALIGNMENT macro for OpenBSD/arm\n* Remove duplicated sample code in leak.md\n* Remove EMX_MAKEFILE (add EMX support to Makefile.direct)\n* Remove GC code fragment (which already merged) from README.Mac\n* Remove GC_GNU_THREADS macro (HURD)\n* Remove GENERAL_MALLOC internal macro\n* Remove HIGH_BIT macro duplicating SIGNB\n* Remove lint-specific code\n* Remove Makefile KandRtest target (that supported K&R C compiler)\n* Remove MIN_WORDS macro from gc_priv.h\n* Remove multi-line macros (FOR_EACH_PRED, ITERATE_DL_HASHTBL_*, PUSH_OBJ)\n* Remove name of optional arguments of operator new and new[] in gc_cpp.h\n* Remove notes that K&R C compiler is unsupported\n* Remove PUSH_CONTENTS_HDR multi-line macro\n* Remove redundant check that clear_fl_marks argument is non-null\n* Remove redundant THREADS macro checks in alloc.c and gc_priv.h\n* Remove stubborn objects allocation code completely, remove stubborn.c\n* Remove unnecessary argument casts in add_roots_inner calls\n* Remove unnecessary type casts in n_set_marks\n* Remove unused USE_GENERIC macro definition and description\n* Remove version info in 'de' cord test application\n* Replace GC_MALLOC(sizeof T) with GC_NEW(T) in tests\n* Replace GC_NO_RETRY_SIGNALS environment variable with GC_RETRY_SIGNALS=0\n* Replace some FIXME items with TODO ones\n* Run command passed to if_not_there directly from Makefile.direct\n* Same type casts for GC_PTR_STORE arguments regardless of GC_DEBUG\n* Skip grungy_pages update when mark state invalid to speedup read_dirty\n* Skip typed_test in gctest if NO_TYPED_TEST macro is defined\n* Support configure --disable-thread-local-alloc option (similar for CMake)\n* Support enable_checksums option in CMake script\n* Support Haiku multi-threaded build by CMake\n* Support threads for DragonFly in configure\n* Turn on 'atomic uncollectable' functionality by default (CMake)\n* Turn on GC assertions in NT_MAKEFILE for debug builds\n* Turn on gcj, disclaim and java finalization by default (CMake)\n* Turn on incremental collection in gctest also if DEFAULT_VDB or MANUAL_VDB\n* Turn on incremental mode in cordtest and cord/de\n* Turn on incremental mode in disclaim_test, test_cpp and staticroots test\n* Turn on parallel marker by default for all multi-threaded builds\n* Update GC compilation and usage notes for Win32\n* Update shared libraries version info to differentiate against v7.6\n* Update top_index entry pointer only when the entry is constructed fully\n* Use __builtin_expect in SIZET_SAT_ADD macro\n* Use __declspec(allocator) for malloc-like prototypes (MS VS 2015+)\n* Use __int64 instead of 'long long' in LONG_MULT if appropriate\n* Use __thread keyword for Android NDK r12b+ Clang (arm)\n* Use atomic allocation for leafs in reverse_test (gctest)\n* Use atomic load/store for the concurrently accessed variables in GC_lock\n* Use C11 static_assert if available\n* Use compiler atomic intrinsics by default if available (configure)\n* Use EXPECT FALSE for mark_from code documented as executed rarely\n* Use heap-allocated memory for local mark stack of non-marker thread\n* Use HOST_ANDROID define instead of PLATFORM_ANDROID\n* Use include gc.h with the angle brackets in the man page synopsis\n* Use longjmp in fault_handler_openbsd if siglongjmp unavailable (OpenBSD)\n* Use MARK_BIT_PER_GRANULE instead of MARK_BIT_PER_OBJ where appropriate\n* Use noexcept specifier in gc_allocator and gc_cpp if C++11\n* Use same macro (NTHREADS) across all tests to specify number of threads\n* Use sigsetjmp() in setjmp_t tool if available\n* Use thread-local allocations for all multi-threaded builds\n* Use THREAD_EQUAL consistently to compare pthread_t values\n* Workaround 'bad pointer arithmetic' false waring in check_annotated_obj\n* Workaround Clang optimizer bug crashing clear_stack_inner on OS X 10.8\n* Workaround Thread Sanitizer (TSan) false positive warnings\n\n\n== [7.6.22] 2024-09-07 ==\n\n* Eliminate 'cast signed to bigger unsigned' CSA warnings in GC_find_limit\n* Fix GC_debug_realloc to support custom kind\n* Fix heap blocks size computation by GC_get_memory_use\n* Fix pointer relational comparison in GC_do_enumerate_reachable_objects\n* Prevent GC_noop_sink from scanning by the collector\n\nAlso, includes 7.4.28 changes\n\n\n== [7.6.20] 2024-02-03 ==\n\n* Eliminate compiler warning of missing cast in LONG_MULT after shift\n* Fix 'sigset_t undeclared' MS VC error if pthreads-w32 is used\n* Fix lock assertion violation in GC_try_to_collect_inner on OS X\n* Fix missing outermost parentheses in macro definitions in huge test\n* Fix undefined GC_real_pthread_sigmask if redirect malloc on OS X\n\nAlso, includes 7.4.26 changes\n\n\n== [7.6.18] 2023-05-26 ==\n\n* Fix IRIX5 defined wrongly on FreeBSD/mips\n* Fix alt-stack handling in GC_push_all_stacks if stack grows up\n* Fix data race in GC_heapsize_at_forced_unmap variable\n\nAlso, includes 7.4.24 changes\n\n\n== [7.6.16] 2022-08-26 ==\n\n* Do not send signal to thread which is suspended manually\n* Eliminate 'old_gc_no is initialized but not referenced' MS VC false warning\n* Fix 'GC_greatest_stack_base_below is defined but not used' warning (IA64)\n* Fix context saving when GC_suspend_thread(self)\n* Fix data race in fail_proc1 of gctest\n* Fix GC_suspend_thread if called before thread destructor\n* Fix hang on sem_wait in GC_suspend_thread if thread was resumed recently\n* Fix lock assertion violation in GC_find_limit if always multi-threaded\n* Fix potential race if start_mark_threads called from threads in child\n* Make finalizer_closure pointer read/write atomic in malloc and callback\n* Prevent changing of GC_markers_m1 value while collection in progress\n* Replace SSH cloning with HTTPS one in README\n* Workaround Thread Sanitizer (TSan) FP warning in is_valid_displacement\n\nAlso, includes 7.4.22 changes\n\n\n== [7.6.14] 2021-09-28 ==\n\n* Add loop to handle abort error like in suspend logic on Darwin\n* Add support of OpenBSD/aarch64\n* Add threading libraries to bdw-gc.pc\n* Disable mprotect-based incremental GC if /proc roots are used (Linux)\n* Do not use iOS private symbols\n* Eliminate 'GC_old_bus_handler defined but not used' compiler warning\n* Eliminate 'comparing signed and unsigned values' BCC warning in cordtest\n* Eliminate 'possible loss of data' BCC and MS VC warnings\n* Eliminate 'static GC_sysinfo definition has incomplete type' Clang warning\n* Eliminate 'unused function GC_add_map_entry' compiler warning\n* Eliminate 'while clause does not guard' GCC warning in GC_parse_map_entry\n* Explicitly zero-initialize trace_buf (fix trace_buf initialization)\n* Fix 'ACCESS_VIOLATION in marker' GC warning on Win32 async thread start\n* Fix 'GC_generic_malloc must be available' GCC error in new_gc_alloc.h\n* Fix 'ulong undefined' compilation error on AIX\n* Fix 'undefined reference to __data_start' linker error on RISC-V\n* Fix 'write to GC log failed' error\n* Fix GC_proc_fd value in child process at fork (Solaris)\n* Fix MPROTECT_VDB definition for single-threaded GC builds\n* Fix OS_TYPE and USE_MMAP_ANON definitions for Cygwin/x64\n* Fix STACKBOTTOM on 32-bit HP/UX 11.11\n* Fix abort in GC_printf when gctest is built as WinMain executable (Cygwin)\n* Fix assertion violation in register_dynlib_callback on Android\n* Fix compiling by Makefile.direct on OpenBSD/UltraSparc\n* Fix configure message about 'AIX gcc optimization fix'\n* Fix cordtest build in SMakefile.amiga\n* Fix data race regarding *rlh value in generic_malloc_many\n* Fix first_thread stack_base initialization if custom GC_stackbottom (Win32)\n* Fix gc_allocator.h compilation by Clang\n* Fix gc_cflags variable name in configure (HP/UX)\n* Fix handling of areas smaller than page size in GC_scratch_recycle\n* Fix incorrect define GC_OPENBSD_THREADS on sparc64\n* Fix misaligned tlfs passed to AO_load on m68k\n* Fix missing GC_quiet declaration in pcr_interface.c\n* Fix missing gc_dlopen.c in CMake script\n* Fix missing scratch_last_end_ptr update (Irix)\n* Fix overflow of scratch_free_ptr value\n* Fix page_was_[ever_]dirty() for static roots (Solaris)\n* Fix printf format specifier in simple_example.html\n* Fix save_callers for multi-threaded case if built-in backtrace unavailable\n* Fix test_cpp failure caused by arbitrary link order (Win32)\n* Fix test_cpp failure when gc_cpp resides in a dll (Borland, Watcom)\n* Fix various typos mostly in documentation files\n* Fix word size, data start and alignment for OpenBSD/mips64(el)\n* Prevent GetThreadContext failure (Windows)\n* Prevent WARN of incompatible incremental GC if default or manual VDB\n* Reduce a time period between GetExitCodeThread and SuspendThread (Win32)\n* Refactoring of WoW64 workaround (Win32)\n* Remove a misleading comment about Solaris in gc.h\n* Workaround 'expression is only useful for its side effects' WCC warning\n* Workaround fread fail after enable_incremental if malloc redirected (Linux)\n\n\n== [7.6.12] 2019-03-01 ==\n\n* Eliminate 'assigned value never used' compiler warning in test_cpp WinMain\n* Fix 'mprotect remapping failed' abort on NetBSD with PaX enabled\n* Fix 'undefined reference to __data_start' linker error (Android/aarch64)\n* Fix 'unexpected mark stack overflow' abort in push_all_stack\n* Fix 'wrong __data_start/_end pair' error on Android\n* Fix BSD_TIME variant of MS_TIME_DIFF for the case of a.tv_usec < b.tv_usec\n* Fix GetThreadContext stale register values use if WoW64 (Win32)\n* Fix executable memory allocation in GC_unix_get_mem\n* Fix invalid initializer of CLOCK_TYPE variables if BSD_TIME\n* Fix thread_info() count argument value (OS X)\n* Update NO_EXECUTE_PERMISSION documentation\n\n\n== [7.6.10] 2018-12-13 ==\n\n* Add paths to filenames mentioned in the copyright section in README\n* Call real pthread_sigmask instead of its wrapper in start_mark_threads\n* Eliminate 'casting signed to bigger unsigned int' CSA warning\n* Eliminate 'non-virtual destructor for class with inheritors' CSA warning\n* Fix 'collecting from unknown thread' abort in leak-finding mode for Win32\n* Fix 'too wide non-owner permissions are set for resource' code defect\n* Fix 'undefined reference to GC_incremental' linker error in pthread_start\n* Fix GC_VSNPRINTF in cordprnt for DJGPP and MS VC for WinCE\n* Fix GC_register_disclaim_proc for leak-finding mode\n* Fix a deadlock in write_fault_handler if AO_or is emulated\n* Fix comment typos in CMakeLists.txt, backgraph.c, de.c, gcconfig.h\n* Fix concurrent bitmap update in GC_dirty\n* Fix delete operator redirection if gc_cpp is built as .dll (Cygwin, MinGW)\n* Fix hbp overflow in GC_install_counts\n* Fix linkage with a system libatomic_ops shared library\n* Fix lock assertion violation in get_index if GC_ALWAYS_MULTITHREADED\n* Fix marking of finalizer closure object\n* Fix marks and hb_n_marks consistency when disclaim returns true\n* Fix memory allocation on GCF (Linux/x64)\n* Fix missing curses.h in cord/de when compiling manually (MS VC, MinGW)\n* Fix start_world not resuming all threads on Darwin\n* Fix test_cpp assertion violation in find-leak mode\n* Fix tests linkage with internal atomic_ops.o\n* Fix unneeded end_stubborn_change in disclaim_test\n* Guard against potential buffer overflow in CORD_next and CORD_pos_fetch\n* New macro to suppress printing of leaked objects\n* Prevent double inclusion of javaxfc.h and private/specific.h\n* Reduce scope of local variables in GC_remove_all_threads_but_me\n* Refine HIDE_POINTER documentation for the case of the leak-finding mode\n* Refine documentation in gc_disclaim.h\n* Test marking of finalizer closure object in disclaim_test\n* Update documentation about arm64 ABI in gcconfig.h\n* Use AO_or in async_set_pht_entry_from_index if available\n* Use include gc.h with the angle brackets in the man page synopsis\n\n\n== [7.6.8] 2018-08-12 ==\n\n* Add cpu, make_as_lib, nothreads options to NT_MAKEFILE\n* Add NetBSD/aarch64 and initial RISC-V support\n* Adjust formatting of configure help messages and config.h comments\n* Avoid multiple 'getcontext failed' warnings if getcontext is broken\n* Cleanup BCC Makefile (remove absolute GC paths, fix del cmd, update clean)\n* Collapse multiple NT_*_MAKEFILE scripts into a single NT_MAKEFILE\n* Do not call GC_dirty_inner unless GC_incremental\n* Do not use NULL in gc_inline.h\n* Eliminate 'cast between incompatible function types' compiler warning\n* Eliminate 'comparing signed and unsigned values' compiler warnings (bcc)\n* Eliminate 'condition is always true' cppcheck warning in init_gcj_malloc\n* Eliminate 'declaration of var hides global declaration' compiler warning\n* Eliminate 'language extension used' Clang warning in gc.h\n* Eliminate 'possibly incorrect assignment in CORD_vsprintf' compiler warning\n* Eliminate 'ptr arithmetic with NULL' cppcheck warning in alloc_mark_stack\n* Eliminate 'scope of var can be reduced' cppcheck warning in pthread_join\n* Eliminate 'switch statement contains no case label' compiler warning\n* Eliminate 'variable might be uninitialized' warning in win32_start_inner\n* Eliminate duplicate clear_mark_bit call when removing disappearing link\n* Fast fail on invalid CPU parameter passed to NT_MAKEFILE\n* Fix 'collecting from unknown thread' abort in leak-finding mode\n* Fix 'pointer arithmetic with NULL' code defect in print_callers\n* Fix Borland version in documentation to match that in BCC_MAKEFILE\n* Fix comment about inv_sz computation in setup_header\n* Fix comments style in configure.ac and Makefile.am\n* Fix compilation by digimars.mak (DMC)\n* Fix compilation by WCC makefile\n* Fix compilation of darwin_stop_world for iOS 8+\n* Fix cords for MANUAL_VDB\n* Fix dependency on gc_cpp source in BCC_MAKEFILE and NT_MAKEFILE\n* Fix GC_is_valid_displacement and GC_is_visible for non-small objects\n* Fix gctest in leak-finding mode\n* Fix infinite restarting of mark_some when a static root disappeared (Linux)\n* Fix large object base computation in PUSH_CONTENTS() if MARK_BIT_PER_OBJ\n* Fix mark stack overflow checking in push_selected\n* Fix missing GC_dirty calls for GC-allocated objects used internally\n* Fix missing GC_dirty invocation from debug_end_stubborn_change\n* Fix MSWIN32 macro redefinition (WCC)\n* Fix multi-threaded gctest for the case of NTHREADS is set to zero\n* Fix new and delete operators definition for DigitalMars compiler\n* Fix NT_MAKEFILE for VS 2017\n* Fix potential null dereference in GC_CONS\n* Fix register_dynamic_libraries on Windows 10\n* Fix result computation in n_set_marks\n* Fix return type in GC_set_warn_proc API documentation\n* Fix tests for GC compiled with MANUAL_VDB\n* Fix the build for Emscripten\n* Fix typo in comment for CORD_ec_flush_buf prototype\n* Fix typos in ChangeLog and generic_malloc\n* Fix UNTESTED for multi-threaded API functions in gctest\n* Fix VirtualQuery call in case of malloc failure (Win32)\n* Install gc.3 man page instead of copying gc.man to doc folder (configure)\n* Keep pointer to the start of previous entry in remove_specific_after_fork\n* Move de_win compiled resource files to cord/tests\n* Never return null by C++ GC allocators and gc_cpp operator new\n* Perform thread_suspend in loop as it may be interrupted (Darwin)\n* Really abort if failed to read /proc for library registration (Linux)\n* Remove code duplication in gcj_malloc and malloc_explicitly_typed\n* Remove duplicate local variable in reclaim_block\n* Remove information how to send bugs from README.cords file\n* Remove libatomic_ops license information\n* Remove unused USE_GENERIC macro definition and description\n* Suppress 'functions containing switch are not expanded inline' bcc warning\n* Suppress 'non-member operator new/delete may not be inline' VC++ warning\n* Turn on incremental collection in gctest also if MANUAL_VDB\n* Update copyright information in alloc.c, gc.c/h and the documentation\n* Update EXTRA_DIST in Makefile, Win32/64 docs after NT_*_MAKEFILE removal\n* Update NT_MAKEFILE usage information in README files for Win32 and Win64\n* Workaround 'class C does not have a copy constructor' cppcheck warning\n* Workaround 'function nested_sp is never used' cppcheck style warning\n* Workaround 'opposite expression on both sides of &' cppcheck style warning\n* Workaround 'template-id not supported in this context' compiler error (WCC)\n\n\n== [7.6.6] 2018-04-20 ==\n\n* Define GC_FREEBSD_THREADS and GC_ADD_CALLER macros for kFreeBSD\n* Eliminate 'boolean result used in bitwise operation' cppcheck warning\n* Eliminate 'there is pointer arithmetic with NULL' cppcheck warning\n* Explicitly unblock GC signals on GC initialization\n* Fix 'scope of var can be reduced' cppcheck err in enqueue_all_finalizers\n* Fix 'undefined reference to __builtin_unwind_init' linker error (ArmCC)\n* Fix arguments delimiter in pcr_interface.c (PCR)\n* Fix assertion violation in DllMain of win32_threads\n* Fix comment for debug_generic_malloc_inner[_ignore_off_page]\n* Fix data race during apply_to_each_object(reset_back_edge)\n* Fix dbg_mlc.c/o file name in documentation\n* Fix gctest with musl libc on s390x\n* Fix include gc_gcj.h in thread_local_alloc.c\n* Fix man section number (3)\n* Fix missing GC_generic_malloc_words_small implementation in new_gc_alloc.h\n* Fix missing new-line in ABORT_ARG<n> definition\n* Fix missing SIGBUS handler setup for kFreeBSD\n* Fix null dereference in print_callers on backtrace_symbols failure\n* Fix null pointer dereference in get_private_path_and_zero_file (Symbian)\n* Fix the collector hang when it is configured with --enable-gc-debug\n* Fix thread_suspend fail for threads registered from key destructor (OS X)\n* Fix type of local variables receiving result of PHT_HASH\n* Fix typo in AIX macro name\n* Fix typo in comment in specific.h\n* Fix unbounded heap growth in case of intensive disappearing links usage\n* Remove API symbols renaming in WCC_MAKEFILE\n* Support Haiku/x64 and Haiku/x86 hosts\n* Support threads for DragonFly in configure\n* Workaround 'address of auto-variable returned' cppcheck error\n* Workaround gctest hang on kFreeBSD (if thread-local allocations are on)\n\n\n== [7.6.4] 2018-01-26 ==\n\n* Add note of set_free_space_divisor, set_warn_proc ABI change after gc-7.1\n* Change compiler invocation example in gc.man to use dynamic libgc\n* Delete dont_ar_* build intermediate files on make clean (Makefile.direct)\n* Do not declare dl_iterate_phdr as weak for DragonFly\n* Fix 'cords' parallel build in Makefile.direct\n* Fix 'undeclared identifier USRSTACK' compiler error on OpenBSD-6.2\n* Fix error code in abort message if sem_wait failed in start_world (NetBSD)\n* Fix GC allocation mutex in child after a fork\n* Fix global operator delete definition for C++14 in gc_cpp\n* Fix last_reclaimed..gc_no interval comparison to threshold in unmap_old\n* Fix libgc version which was changed in linkage breaking way\n* Fix missing EOLn output in threadlibs tool\n* Fix threadlibs tool to output '-lpthread' for DragonFly\n* Prevent DATASTART redefinition for NaCl\n* Remove obsolete advice about linking with _DYNAMIC=0 (Linux)\n\n\n== [7.6.2] 2017-12-23 ==\n\n* Add assertion that no hb_n_marks underflow occurs\n* Add minimal testing of GC_MALLOC_[ATOMIC_]WORDS and GC_CONS (gctest)\n* Add minimal testing of GC_set_bit (gctest)\n* Add more cases to huge_test to cover sizes close to word-type maximum\n* Add testing of new[]/delete[] (test_cpp)\n* Adjust AO_HAVE_x check to match AO_fetch_and_add primitive variant used\n* Adjust code indentation of calloc_explicitly_typed\n* Align local_mark_stack in help_marker explicitly\n* Allow custom TRACE_ENTRIES value\n* Allow gctest and thread_leak_test with zero NTHREADS\n* Avoid data race in finalized_count (gctest)\n* Code refactoring of divide-by-HBLKSIZE occurrences\n* Code refactoring of huge_test\n* Code refactoring of tests/subthread_create regarding AO add primitive\n* Compile thread_local_alloc only if multi-threaded build (Makefile.am)\n* Delete preprocessor output on make clean (Makefile.direct)\n* Disable implicit multi-threaded mode for Win32 to avoid LOCK crash\n* Do not disable parallel mark for WRAP_MARK_SOME\n* Do not enable mprotect-based incremental mode if unmapping is on (gctest)\n* Do not install documentation if configure --disable-docs (new option)\n* Do not use tkill (Android)\n* Document base and size of objects allocated by finalized_malloc\n* Document configure 'syntax error' issue in README\n* Eliminate 'address of local variable returned' static analyzer warning\n* Eliminate 'array vs singleton' code defect in typed_test (gctest)\n* Eliminate 'assigned value never used' CSA warning in min_bytes_allocd\n* Eliminate 'boolean result used in bitwise op' cppcheck false warning\n* Eliminate 'C-style pointer casting' cppcheck style warnings in test\n* Eliminate 'checking if unsigned variable is <0' cppcheck style warning\n* Eliminate 'class member var with name also defined in parent' warning\n* Eliminate 'comparison is always false' static analyzer warning in finalize\n* Eliminate 'Condition 0==datastart always false' cppcheck warning (dyn_load)\n* Eliminate 'condition is always true' cppcheck style warning\n* Eliminate 'constructor with 1 argument is not explicit' cppcheck warning\n* Eliminate 'CORD_*printf is never used' cppcheck style warnings (cordtest)\n* Eliminate 'dereference of null' CSA false warning in array_mark_proc\n* Eliminate 'function result not used' code defect in GC_mark_local\n* Eliminate 'GC_collecting is set but never used' code defect (Win32)\n* Eliminate 'GC_record_fault is never used' cppcheck style warning\n* Eliminate 'integer shift by a negative amount' code defect in finalize\n* Eliminate 'label not used' cppcheck false warnings in GC_mark_X\n* Eliminate 'memory leak' code defect for scratch-allocated memory\n* Eliminate 'memory leak' code defect in remove_specific\n* Eliminate 'non-null arg compared to null' warning in toggleref_add (GCC)\n* Eliminate 'non-reentrant function strtok called' cppcheck warning (POSIX)\n* Eliminate 'possible integer underflow' code defect (cord-de)\n* Eliminate 'potential overflow' static analyzer warning in test\n* Eliminate 'printf format specifies type void*' GCC pedantic warnings\n* Eliminate 'scope of variable can be reduced' cppcheck warnings\n* Eliminate 'suspicious pointer subtraction' cppcheck warning (gc_cpp)\n* Eliminate 'this statement may fall through' GCC warnings\n* Eliminate 'unnecessary comparison of static strings' cppcheck warning\n* Eliminate 'unsafe vsprintf is deprecated' compiler warning\n* Eliminate 'unused formal parameter' compiler warnings in C++ code (MS VC)\n* Eliminate 'unused variable' compiler warning in remove_all_threads_but_me\n* Eliminate 'use of vulnerable sprintf' code defect in de_win test (cord)\n* Eliminate 'value exceeds maximum object size' GCC warning in huge_test\n* Eliminate 'value of CLOCK_TYPE unknown' cppcheck info message\n* Eliminate 'value of DATASTART2 unknown' cppcheck info messages\n* Eliminate 'value of GC_PTHREAD_EXIT_ATTRIBUTE unknown' cppcheck messages\n* Eliminate 'value of GC_RETURN_ADDR_PARENT unknown' cppcheck info messages\n* Eliminate 'value of NEED_FIXUP_POINTER unknown' cppcheck info messages\n* Eliminate 'write to memory that was const-qualified' code analyzer warning\n* Eliminate all 'scope of variable can be reduced' cppcheck style warnings\n* Eliminate CSA warning about incorrect cast applied to HBLK_OBJS\n* Eliminate CSA warning about narrowing cast in CleanUp of test_cpp\n* Eliminate CSA warning of non-virtual destructor in test_cpp base class\n* Eliminate CSA warning of staticroot that can be a local variable (tests)\n* Eliminate CSA warning of unmodified non-const static var (disclaim_test)\n* Eliminate redundant local variable in register_finalizer\n* Eliminate TSan (Thread Sanitizer) warnings in gctest\n* Eliminate UBSan warning of overflow during descr subtraction in mark_from\n* Eliminate unreachable PROC/DEFAULT_VDB GC_printf calls in gctest main()\n* Eliminate unsigned fl_builder_count underflow in mark_thread\n* Enable GC_is_tmp_root for all platforms\n* Execute more single-threaded GC tests by CMake\n* Expand tabs to spaces in de_win.rc (tests)\n* Export GC_dump_finalization/regions()\n* Export GC_is_tmp_root() and GC_print_trace[_inner]()\n* Export GC_print_free_list()\n* Fix '32-bit value shift followed by expansion to 64-bit' code defect\n* Fix 'GC_written_pages never read' code defect (GWW_VDB)\n* Fix 'label cannot be reached' static analyzer warning in disclaim_test\n* Fix 'size of tv is unknown' error in brief_async_signal_safe_sleep (musl)\n* Fix 'syntax error' reported by cppcheck for mach_dep\n* Fix 'unknown type name GC_INNER' compilation error (FreeBSD)\n* Fix 'variable assigned a value that is never used' cppcheck style warnings\n* Fix 'void pointers in calculations: behavior undefined' cppcheck warning\n* Fix assertion violation about disabled cancel in try_to_collect_inner\n* Fix atomic_ops build in Makefile.direct for Solaris\n* Fix Clang static analyzer warning about not found gc_priv.h in extra files\n* Fix compilation error in get_main_stack_base (Emscripten)\n* Fix compilation for winpthreads if HANDLE_FORK\n* Fix compilation if configured with --enable-werror on OS X\n* Fix cord/de build in Makefile.direct (Linux)\n* Fix data race in a list referenced by A.aa (gctest)\n* Fix data race in collectable_count (gctest)\n* Fix data race in do_local_mark when comparing active_count to helper_count\n* Fix data race in GC_suspend/resume_thread\n* Fix data race in last_stop_count access (suspend_handler_inner)\n* Fix data race in make_descriptor when setting explicit_typing_initialized\n* Fix data race in mark_thread when updating mark_no\n* Fix data race when getting object size in explicitly-typed allocators\n* Fix deadlock in GC_suspend_thread\n* Fix gctest failure for Darwin if CPPCHECK is defined\n* Fix lack of barriers to synchronize memory for suspend_handler\n* Fix marking of disclaim-reachable objects in the incremental mode\n* Fix message of VDB implementation used if MPROTECT_VDB+GWW_VDB (gctest)\n* Fix missing started_thread_while_stopped call from mark_some if GCC/Clang\n* Fix null dereference in GC_stack_range_for if not DARWIN_DONT_PARSE_STACK\n* Fix page calculation in checksums\n* Fix parallel build in Makefile.direct\n* Fix test_cpp and c++ parallel build in Makefile.direct\n* Fix typo in comment of GC_mark_some\n* Fix typos in cdescr.html and README.sgi\n* Make GC_INIT optional for clients even if thread-local allocations enabled\n* Match uclinux pattern in configure\n* Move conditional GC_need_to_lock setting to gc_locks.h (refactoring)\n* Move README.QUICK from DOC_FILES to OTHER_FILES in Makefile.direct\n* New API function (GC_is_init_called) to check if BDWGC is initialized\n* New target (check-cpp) in Makefile.direct\n* Prevent abort in register_data_segments for Symbian and Emscripten\n* Prevent multiple 'Caught ACCESS_VIOLATION in marker' per collection\n* Print realloc_count value in gctest\n* Put invariant name in quotes to make mark_state comments clearer\n* Refine configure messages when checking for compiler option support\n* Remove extraneous semicolons after AC_MSG_WARN (configure)\n* Remove page_was_dirty and remove_protection duplicate definitions\n* Remove unnecessary type casts of printf arguments to unsigned long\n* Remove unused ALIGN_DOUBLE, USE_GENERIC_PUSH_REGS macros (TILE-Gx/Pro)\n* Rename 'test' to 'check' target in Makefile.direct\n* Replace deprecated rewind to fseek in cordxtra\n* Report gcc/clang pedantic warnings (configure)\n* Skip thread suspend/resume API testing for Tru64 (OSF1)\n* Support AddressSanitizer (Clang/GCC) and MemorySanitizer (Clang)\n* Support GC_init (and get_stack_base) from non-main thread on FreeBSD/NetBSD\n* Suppress 'tainted string passed to vulnerable operation' false defects\n* Suppress 'taking address of label non-standard' GCC/Clang pedantic warning\n* Test GC initialization from non-main thread on FreeBSD and NetBSD\n* Test GCJ object creation with length-based descriptor (gctest)\n* Update comment in finalized_disclaim to match FINALIZER_CLOSURE_FLAG\n* Update README regarding make cords with Makefile.direct\n* Update README to use autogen.sh on build from the source repository\n* Update shared libraries version info to differentiate against v7.4\n* Use mprotect instead of mmap in GC_unmap() on Cygwin\n* Use same style of include gc.h in documentation\n* Workaround '!GC_page_size is always false' cppcheck style warning\n* Workaround '#error' cppcheck error messages\n* Workaround '32-bit value shift by >31 bits is undefined' cppcheck warnings\n* Workaround 'array compared to 0', 'untrusted loop bound' false defects\n* Workaround 'bad address arithmetic' static analysis tool false positive\n* Workaround 'checking if unsigned value is negative' cppcheck warning\n* Workaround 'checking unsigned value is negative' code defect in mark_from\n* Workaround 'comparison of identical expressions' false code defects\n* Workaround 'Condition 0!=GETENV() is always false' cppcheck style warnings\n* Workaround 'condition is always false' cppcheck warning in get_next_stack\n* Workaround 'condition is always true' cppcheck style warnings in GC_init\n* Workaround 'function is never used' cppcheck style warnings\n* Workaround 'insecure libc pseudo-random number generator used' code defect\n* Workaround 'int shift by negative amount' false code defect in finalize\n* Workaround 'local variable size too big' static analyzer warning\n* Workaround 'memory leak: result' cppcheck false error (POSIX)\n* Workaround 'null pointer dereference' false positive in push_next_marked\n* Workaround 'obsolescent bcopy, bzero called' cppcheck warnings (POSIX)\n* Workaround 'obsolescent usleep called' cppcheck warning (POSIX)\n* Workaround 'obsolete function alloca() called' cppcheck warnings\n* Workaround 'passing untyped NULL to variadic function' cppcheck warning\n* Workaround 'pointer used before comparison to null' code defect (pthread)\n* Workaround 'possible null pointer dereference' cppcheck warnings\n* Workaround 'potential multiplication overflow' code defect in de_win (cord)\n* Workaround 'redundant assignment of *result to itself' cppcheck warning\n* Workaround 'resource leak' false positives in alloc_MS, bl/envfile_init\n* Workaround 'same expression on both sides of ==' cppcheck style warning\n* Workaround 'same expression on both sides of OR' cppcheck style warning\n* Workaround 'struct member is never used' cppcheck style warnings\n* Workaround 'tainted int used as loop bound' static analysis tool warning\n* Workaround 'Uninitialized variable' cppcheck errors\n* Workaround 'unused variable' cppcheck style warnings\n* Workaround 'va_list used before va_start' cppcheck error in cord\n* Workaround 'value of macro unknown' cppcheck info messages\n* Workaround 'value of REDIRECT_MALLOC/FREE unknown' cppcheck info messages\n* Workaround 'value of SIGBUS unknown' cppcheck info messages\n* Workaround 'value of WINAPI unknown' cppcheck info messages\n* Workaround 'variable hides enumerator with same name' cppcheck warnings\n* Workaround 'variable reassigned before old value used' cppcheck warnings\n* Workaround 'waiting while holding lock' code defect in stop_world (Unix)\n* Workaround false 'uninitialized var use' code defect (initsecondarythread)\n\nAlso, includes 7.4.6 changes\n\n\n== [7.6.0] 2016-08-02 ==\n\n* ABORT_ARGn log details at INFO level (Android)\n* Add 'pragma message' to gc.h to detect inconsistent WIN64/_WIN64 (MS VC)\n* Add API function to calculate total memory in use by all GC blocks\n* Add API function to set/modify GC log file descriptor (Unix)\n* Add alloc_size attribute to GC_generic_malloc\n* Add alt-stack registration support\n* Add assertion for GC_new_kind boolean arguments\n* Add assertion on lock status to GC_alloc_large and its callers\n* Add build scripts for VC 9 (Win32/64)\n* Add build system plumbing for building with -Werror\n* Add incremental GC support for Darwin/arm64\n* Add profiling callback events to indicate start/end of reclaim phase\n* Add support for enumerating the reachable objects in the heap\n* Add toggle-ref support (following Mono GC API)\n* Added instructions to README.md for building from git\n* Adjust code indentation of malloc/calloc/str[n]dup\n* Allow fork() automatic handling on Android with API level 21+\n* Allow specific TLS attributes for GC_thread_key\n* Allow thread local allocations from within pthread TLS destructors\n* Allow to force GC_dump_regularly set on at compilation\n* Altera NIOS2 support\n* Change 'cord' no-argument functions declaration style to ANSI C\n* Check DATASTART is less than DATAEND even assertions off\n* Check for execinfo.h by configure\n* Code refactoring of GC_push_finalizer/thread/typed_structures\n* Code refactoring regarding 'data start' definition for FreeBSD\n* Consistently set type of DATASTART/END to ptr_t (code refactoring)\n* Consistently use int[] type for '_end' symbol (code refactoring)\n* Consistently use outermost parentheses for DATASTART/END, STACKBOTTOM\n* Define GC_LINUX_THREADS, NO_EXECUTE_PERMISSION in configure for NaCl\n* Define ROUNDUP_PAGESIZE, ROUNDUP_GRANULE_SIZE macros (code refactoring)\n* Define public GC_GENERIC_OR_SPECIAL_MALLOC and GC_get_kind_and_size\n* Do no declare kernel_id field of GC_Thread_Rep for 64-bit Android\n* Do not allow SHORT_DBG_HDRS if KEEP_BACK_PTRS or MAKE_BACK_GRAPH\n* Do not warn of missing PT_GNU_RELRO segment when custom DSO filter used\n* Document GC_register_my_thread returned value\n* Dump the block information in CSV format\n* Eliminate redundant *flh check for null in GC_allocobj\n* Enable atomic-uncollectable in operator new in gc_cpp.h\n* Enable build with musl libc\n* Enable gc.h inclusion by client without implicit include windows.h (Win32)\n* Enable huge_test for Win64 (and LLP64 target)\n* Enable thread-local storage for Android Clang\n* Enable thread-local storage usage for GC_malloc/calloc_explicitly_typed\n* Export GC_push_all_eager, GC_push_finalizer_structures\n* Fix 'arg parameter might be clobbered by setjmp' compiler warning\n* Fix assertion in GC_mark_from for non-heap regions\n* Fix compilation for Android clang/arm with bfd linker\n* Fix integer shift undefined behavior in GC_init_explicit_typing\n* Fix missing new-line and redundant trailing dot in WARN messages\n* Fix STACKBOTTOM for Solaris 11/x86\n* Fix tag collision between ENABLE_DISCLAIM and KEEP_BACK_PTRS\n* Fix unchecked fork() result in gctest (Unix, Cygwin)\n* Fix user-defined signals drop by marker threads\n* Fix various typos in comments and documentation\n* FreeBSD/arm support improvement\n* GC_make_descriptor code refactoring (eliminate two local variables)\n* GC_malloc[_atomic] global and thread-local generalization with kind\n* GC_malloc_[atomic_]uncollectable generalization\n* GC_scratch_alloc code refactoring (and WARN message improvement)\n* Group all compact fields of GC_arrays to fit in single page\n* Handle load_segs overflow in register_dynlib_callback gracefully\n* Harmonize OSX/iOS configuration; enable compiling for iPhone simulator\n* Implement event callbacks for profiling (following Mono GC API)\n* Implement the finalization extension API\n* Implement thread suspend/resume API (Linux threads only)\n* Improve documentation for disappearing links in gc.h\n* Make heap growth more conservative after GC_gcollect_and_unmap call\n* Mark fo_head, finalize_now with a single GC_push_all call (refactoring)\n* Move MessageBox invocation code from GC_abort to a separate routine (Win32)\n* NaCl/arm initial support; NaCl runtime fixes for other CPUs\n* New macro (GC_ALWAYS_MULTITHREADED) to set multi-threaded mode implicitly\n* New macro (NO_WINMAIN_ENTRY) to prefer main() instead of WinMain in test\n* New macro (REDIRECT_MALLOC_IN_HEADER) to enable source-level redirection\n* Process all PT_LOAD segments before PT_GNU_RELRO segments (Glibc)\n* Re-implement GC_finalized_malloc using GC_malloc_kind\n* Refactoring of android_thread_kill/pthread_kill calls\n* Refactoring of GC_Xobjfreelist (use single array to keep free lists)\n* Refactoring of thread-local *_freelists (use single array of free lists)\n* Refine description in README how to build from source repository\n* Refine GC_free_space_divisor comment regarding its initial value\n* Reformat code of gc_cpp.cc/h\n* Remove 'opp' local variable in GC_malloc_X\n* Remove 'sig' argument of GC_suspend_handler_inner (code refactoring)\n* Remove code commented out by 'ifdef UNDEFINED'\n* Remove hb_large_block field (use 1 extra bit of hb_flags instead)\n* Remove obsolete BACKING_STORE_ALIGNMENT/DISPLACEMENT macros for Linux/IA64\n* Remove redundant casts in GC_generic_or_special_malloc and similar\n* Remove unsupported FreeBSD/ia64 case from gcconfig.h file\n* Remove unused GC_gcjdebugobjfreelist\n* Rename ATOMIC_UNCOLLECTABLE to GC_ATOMIC_UNCOLLECTABLE\n* Replace non-API occurrences of GC_word to word (code refactoring)\n* Return GC_UNIMPLEMENTED instead of abort in GC_get_stack_base (OS/2)\n* Show WoW64 warning message if running 32-bit on Win64 (enabled by macro)\n* Standalone profiling callback for threads suspend/resume\n* Support (add machine description for) TILE-Gx and TILEPro targets\n* Support build for Android 64-bit (arm64, mips64, x64)\n* Support FreeBSD/aarch64, FreeBSD/mips\n* Support iOS7 64-bit (AArch64) and iOS8+ 32/64-bit (Darwin)\n* Support MinGW build in scripts\n* Turn off sigsetjmp workaround for Android/x86 starting from NDK r8e\n* Use magic header on objects to improve disclaim_test\n* Workaround 'sa_sigaction member missing' compiler error (Android/x32)\n* Workaround 'unresolved __tls_get_addr' error for Android NDK Clang\n* Workaround a bug in winpthreads causing parallel marks deadlock (MinGW)\n\nAlso, includes 7.4.4 changes\n\n\n== [7.4.28] 2024-09-07 ==\n\n* Avoid gcc stringop-overflow warning for intended overflow in smashtest\n* Fix ADD_CALL_CHAIN() placement to follow GC_store_debug_info_inner call\n* Fix GC_is_visible for case of arg pointing exactly to object upper bound\n* Fix GC_print_trace_inner to print the last element of the circular buffer\n* Fix cordtst2.tmp file deletion in cordtest on Windows\n* Fix double lock in GC_malloc called from backtrace()\n* Fix indent of a closing curly braces in GC_apply_to_all_blocks\n* Fix null pointer dereference in GC_is_visible if type_descr is null\n* Fix per_object_helper() after changing hb_sz units\n* Fix poor thread-local allocation performance because of double EXTRA_BYTES\n* Fix potential GC_add_roots_inner call with an overflowed pointer (Win32)\n* Fix potential address overflow in GC_add_to_heap\n* Fix potential buffer overrun during read in GC_text_mapping\n* Fix typos in comments\n* Prevent redirected malloc call from a garbage collection routine\n* Remove redundant dirty/reachable_here calls in GC_malloc_explicitly_typed\n* Update and fix diagrams describing the tree structure for pointer lookups\n\n\n== [7.4.26] 2024-02-03 ==\n\n* Eliminate 'unused parameter' gcc warning in free() if IGNORE_FREE\n* Eliminate 'unused value' gcc warnings in init_global_static_roots (Symbian)\n* Fix 'implicit declaration of function sbrk' gcc error on Symbian\n* Fix 'unused GC_set_and_save_fault_handler' warning on OS X\n* Fix GC_push_stack_for() to push also Xmm registers on Windows/x64\n* Fix MACH_TYPE macro redefinition on Symbian/arm\n* Fix missing GC_pthread_sigmask on FreeBSD and NetBSD\n* Fix missing redirect and implementation of pthread_sigmask() on OpenBSD\n\nAlso, includes 7.2r changes.\n\n\n== [7.4.24] 2023-05-25 ==\n\n* Adjust CORD_ec comment placement in ec.h\n* Do not mix debug and non-debug allocations in disclaim tests\n* Eliminate 'cast signed to bigger unsigned' CSA warning in WARN calls\n* Ensure GC_NO_PTHREAD_SIGMASK defined if no GC_pthread_sigmask prototype\n* Fix GC_thread_is_registered for finished threads\n* Fix GC_unregister_my_thread call before GC functions usage in gctest\n* Fix missing lock while updating GC_in_thread_creation in GC_exit_check\n* Fix null pointer dereference in TRACE_TARGET\n* Fix of GC_bytes_allocd increment in GC_generic_malloc_inner\n* Remove redundant 'ifdef THREADS' around LOCK/UNLOCK in call_with_alloc_lock\n\nAlso, includes 7.2q changes.\n\n\n== [7.4.22] 2022-08-26 ==\n\n* Eliminate 'new_l may be used uninitialized' gcc warning in os_dep (Cygwin)\n* Eliminate 'possible loss of data' compiler warning in GC_envfile_getenv\n* Fix 'undeclared getpagesize' compiler warning on AIX and OSF1\n* Fix GC_dirty() argument in GC_malloc_explicitly_typed_ignore_off_page\n* Fix SIGSEGV caused by dropped stack access from child process in gctest\n* Fix abort in Win32 DllMain if PARALLEL_MARK\n* Fix assertion violation of GC_thread_key alignment if pthread-based TLS\n* Fix comment in GC_init regarding GC_init_parallel call\n* Fix stack overflow in gctest on Alpine Linux/s390x\n* Revert \"Remove nested always-false ifdef for HPUX and FREEBSD\"\n* Use SIGRTMIN+6 as suspend signal if sigrt-signals on OpenBSD\n* Workaround crash in FreeBSD rand() by avoiding its concurrent usage\n\nAlso, includes 7.2p changes.\n\n\n== [7.4.20] 2021-09-28 ==\n\n* Do not hold GC_fault_handler_lock when in Sleep (Windows)\n* Eliminate 'static GC_sysinfo definition has incomplete type' Clang warning\n* Eliminate 'unused function GC_add_map_entry' compiler warning\n* Eliminate 'while clause does not guard' GCC warning in GC_parse_map_entry\n* Fix OS_TYPE and USE_MMAP_ANON definitions for Cygwin/x64\n* Fix abort in GC_printf when gctest is built as WinMain executable (Cygwin)\n* Fix configure message about 'AIX gcc optimization fix'\n* Fix cordtest build in SMakefile.amiga\n* Prevent GetThreadContext failure (Windows)\n* Refactoring of WoW64 workaround (Win32)\n\nAlso, includes 7.2o changes\n\n\n== [7.4.18] 2019-03-01 ==\n\n* Fix 'wrong __data_start/_end pair' error on Android\n* Fix thread_info() count argument value (OS X)\n\nAlso, includes 7.2n changes\n\n\n== [7.4.16] 2018-12-13 ==\n\n* Fix 'collecting from unknown thread' abort in leak-finding mode for Win32\n* Fix 'undefined reference to GC_incremental' linker error in pthread_start\n* Fix GC_register_disclaim_proc for leak-finding mode\n* Fix concurrent bitmap update in GC_dirty\n* Fix marking of finalizer closure object\n* Fix marks and hb_n_marks consistency when disclaim returns true\n* Fix missing curses.h in cord/de when compiling manually (MS VC, MinGW)\n* Refine documentation in gc_disclaim.h\n\nAlso, includes 7.2m changes\n\n\n== [7.4.14] 2018-08-11 ==\n\n* Cleanup BCC Makefile (remove absolute GC paths, fix del cmd, update clean)\n* Do not call GC_dirty_inner unless GC_incremental\n* Eliminate 'cast between incompatible function types' compiler warning\n* Eliminate 'comparing signed and unsigned values' compiler warnings (bcc)\n* Eliminate 'language extension used' Clang warning in gc.h\n* Eliminate 'possibly incorrect assignment in CORD_vsprintf' compiler warning\n* Eliminate 'switch statement contains no case label' compiler warning\n* Eliminate 'variable might be uninitialized' warning in win32_start_inner\n* Eliminate duplicate clear_mark_bit call when removing disappearing link\n* Fix 'collecting from unknown thread' abort in leak-finding mode\n* Fix compilation by digimars.mak (DMC) and by WCC makefile\n* Fix cords for MANUAL_VDB\n* Fix dependency on gc_cpp source in BCC_MAKEFILE and NT_MAKEFILE\n* Fix gctest in leak-finding mode\n* Fix missing GC_dirty calls for GC-allocated objects used internally\n* Fix missing GC_dirty invocation from debug_end_stubborn_change\n* Fix multi-threaded gctest for the case of NTHREADS is set to zero\n* Fix typos in ChangeLog and generic_malloc\n* Keep pointer to the start of previous entry in remove_specific_after_fork\n* New API function (GC_is_init_called) to check if BDWGC is initialized\n* Remove code duplication in gcj_malloc and malloc_explicitly_typed\n* Remove duplicate local variable in reclaim_block\n* Remove libatomic_ops license information from README\n* Workaround 'dynamic exception specifications deprecated in C++11' warning\n\nAlso, includes 7.2l changes\n\n\n== [7.4.12] 2018-04-19 ==\n\n* Define GC_FREEBSD_THREADS and GC_ADD_CALLER macros for kFreeBSD\n* Fix comment for debug_generic_malloc_inner[_ignore_off_page]\n* Fix gctest with musl libc on s390x\n* Fix missing new-line in ABORT_ARG<n> definition\n* Fix null pointer dereference in get_private_path_and_zero_file (Symbian)\n* Fix type of local variables receiving result of PHT_HASH\n* Remove API symbols renaming in WCC_MAKEFILE\n\nAlso, includes 7.2k changes\n\n\n== [7.4.10] 2018-01-22 ==\n\n* Fix error code in abort message if sem_wait failed in start_world (NetBSD)\nAlso, includes 7.2j changes\n\n\n== [7.4.8] 2017-12-22 ==\n\n* Eliminate 'this statement may fall through' GCC warnings\n* Eliminate 'value exceeds maximum object size' GCC warning in huge_test\n* Fix data race in make_descriptor when setting explicit_typing_initialized\n* Fix marking of disclaim-reachable objects in the incremental mode\n* Update comment in finalized_disclaim to match FINALIZER_CLOSURE_FLAG\nAlso, includes 7.2i changes\n\n\n== [7.4.6] 2017-10-26 ==\n\n* Add configure --enable-gcov option (enable code coverage analysis)\n* Add configure check whether to define NO_GETCONTEXT\n* Adjust GC_memalign comment\n* Allow HAVE_DL_ITERATE_PHDR to be defined by client (musl)\n* Allow PKG_CHECK_MODULES in configure.ac to be commented out easily\n* Avoid busy waiting in mark_thread while GC_parallel is false\n* Better document minimum value of size argument for typed allocations\n* Change type of THREAD_TABLE_INDEX result to int in win32_threads.c\n* Consistently use 'msec' instead of 'ms' in comments in pthread_support\n* Do not define amiga_get_mem, MacTemporaryNewPtr unless really used (extra)\n* Do not produce .tar.bz2 distribution file (configure)\n* Do not require libatomic_ops for single-threaded builds (configure)\n* Do not warn of missing PT_GNU_RELRO segment when custom DSO filter used\n* Document GWW_VDB in gcdescr.html\n* Eliminate 'cast to void* from int' compiler warnings (Darwin/x64)\n* Eliminate 'conditional expression is always true' code defect in GC_init\n* Eliminate 'FP divide-by-zero' static analyzer warning\n* Eliminate 'incompatible function pointer' warning in mark_some (MinGW/x86)\n* Eliminate 'ISO C forbids an empty translation unit' GCC pedantic warning\n* Eliminate 'ISO C forbids object to function pointer conversion' warning\n* Eliminate 'locally defined symbol imported' MS linker warnings (cord)\n* Eliminate 'null dereference' code defect warning in register_finalizer\n* Eliminate 'possible loss of data' compiler warnings (MS VC)\n* Eliminate 'printf format specifier mismatch' compiler warning (tools)\n* Eliminate 'type defaults to int in declaration' warning (REDIRECT_MALLOC)\n* Eliminate 'value stored is never read' warning of Clang static analyzer\n* Eliminate duplicate log messages in GC_mark_from\n* Eliminate most of collisions in GC_threads on Linux/x64\n* Ensure GC initialized when atfork_prepare is called by client\n* Fix 'arg parameter might be clobbered by setjmp' compiler warning\n* Fix 'bogus LR' detection in FindTopOfStack (Darwin)\n* Fix 'execvp argument incompatible pointer type' compiler warning (tools)\n* Fix 'GetVersion deprecated' compiler warning in os_dep (MS VC)\n* Fix 'incompatible pointer' compiler warning in GC_init_dyld (OS X 64-bit)\n* Fix 'incompatible ptr-to-int conversion' compiler warning in push_all_stack\n* Fix 'ISO C90 does not support %lf, %lg gnu_printf formats' GCC warnings\n* Fix 'ISO C90 forbids mixed declarations and code' compiler warning\n* Fix 'missing libc-version.h' build error (uClibc/x86[_64])\n* Fix 'replacement operator delete cannot be inline' GCC warning (Cygwin)\n* Fix 'variable unused' compiler warning in FirstDLOpenedLinkMap\n* Fix 'zero-size array is extension' Clang warning in os_dep (Linux/x86)\n* Fix (adjust) GC_scratch_alloc actual argument type\n* Fix deadlock in GC_help_marker caused by use of mark_cv of parent process\n* Fix finalize.c compilation in 'strict ANSI' mode\n* Fix GC shared library tests failure related to dl_iterate_phdr (musl)\n* Fix gc.h compliance to strict ANSI (pthreads)\n* Fix GC_bytes_allocd incrementation in case of allocation failure\n* Fix GC_jmp_buf multiple definition\n* Fix GC_noop6 definition to avoid its calls to be optimized away\n* Fix gctest failure if PARALLEL_MARK (musl)\n* Fix gctest thread stack overflow (musl-gcc)\n* Fix initsecondarythread_test runtime failure if GC compiled w/o threads\n* Fix lack of 2 trailing zeros in _MSC_VER numbers\n* Fix local variable declarations in disclaim_bench\n* Fix missing #error pragma\n* Fix missing .exe for disclaim test filenames in Makefile (MinGW)\n* Fix missing atomic/[un]collectable/realloc_count increments in gctest\n* Fix missing new-line and redundant trailing dot in WARN messages\n* Fix missing new-line at format strings end in subthread_create test\n* Fix mixed include of GC public header and gc_priv.h in disclaim bench/test\n* Fix potential overflow in decrement when computing GC_markers_m1\n* Fix printf format specifiers in extra files (cppcheck warnings)\n* Fix pthread_start compilation if single-obj-compilation (Linux)\n* Fix register_finalizer call in disclaim_bench for GC_DEBUG\n* Fix static assertion violation in LONG_MULT for 64-bit targets\n* Fix tag collision between ENABLE_DISCLAIM and KEEP_BACK_PTRS\n* Fix thread id leaks in subthread_create and threadkey_test\n* Fix threaded tests runtime crash if GC_NO_THREAD_REDIRECTS supplied\n* Fix tools/setjmp_t to prevent nested_sp inlining\n* Fix typo in CHECK_GCLIB_VERSION name (test)\n* Fix typos in comments/documentation (ews4800, extend_size_map, push_roots)\n* Fix unchecked fork() result in gctest (Unix, Cygwin)\n* Improve detection of internal libatomic_ops (configure)\n* Move libraries version info to the beginning of Makefile.am\n* Prevent abort in register_data_segments for Symbian\n* Process all PT_LOAD segments before PT_GNU_RELRO segments (Glibc)\n* Refine Makefile.direct comment about multi-threaded GC build\n* Refine README about library source downloading\n* Refine should_invoke_finalizers documentation\n* Remove all generated files by NT_X64_THREADS_MAKEFILE 'clean' target\n* Remove non-existent configure option in simple_example.html\n* Replace C++ style comments to C ones, remove commented out code (extra)\n* Support CFLAGS_EXTRA to pass extra user-defined compiler flags (configure)\n* Support CFLAGS_EXTRA when checking for inline and dladdr (configure)\n* Suppress 'tainted string passed to vulnerable operation' false defects\n* Suppress MS VC warnings about unused param, const condition (NT_MAKEFILE)\n* Update bdwgc mailing list online archive link in documentation\n* Update shared libraries version info to differentiate against v7.2\n* Use AC_DEFINE for defining NO_GETCONTEXT in configure\n* Workaround 'index out of bounds' UBSan false warning in push_marked\n* Workaround 'mmap() resource handle leak' static analyzer warning\n* Workaround 'redundant assignment of *result to itself' cppcheck warning\n* Workaround 'resource leak' error reported by cppcheck (tools, test)\nAlso, includes 7.2h changes\n\n\n== [7.4.4] 2016-05-25 ==\n\n* Allow GC_FAST_MALLOC_GRANS() multiple use in a function\n* Also enable the TSX workaround for Linux/x86\n* Avoid unstructured procfs on Solaris\n* Change cord/de main() declaration style from K-R to ANSI C\n* Change no-argument functions declaration style to ANSI C (cord)\n* Do not include sigcontext.h and asm/sigcontext.h\n* Eliminate 'divide by zero' compiler warning in cordtest\n* Eliminate warning about 64-bit pointer-to-int cast (Win64/pthreads-w32)\n* Eliminate warnings detected by Cppcheck in cord de[_win]\n* Fix 'comparison of non-null parameter is always false' warning (Clang)\n* Fix 'CORD_iter5 unused result' code defect in cordxtra\n* Fix 'GC_generic_malloc_inner_ignore_off_page not used' compiler warning\n* Fix 'implicit declaration of vsnprintf' GCC warning (if strict ANSI mode)\n* Fix 'signed-to-bigger-unsigned value assignment' in GC_init_size_map\n* Fix 'signed-to-bigger-unsigned value assignment' warning for hb_map\n* Fix 'signed-to-bigger-unsigned value assignment' warning in GC_setpagesize\n* Fix 'statement unreachable' compiler warning in GC_mark_from\n* Fix 'statement unreachable' compiler warning in memalign\n* Fix 'unused label' compiler warning in cord/de\n* Fix 'value truncated' compiler warning in CORD_cat (MS VC)\n* Fix 'variable unused' warning in GC_save_callers\n* Fix 'visibility attribute not supported' GCC warning (IBM AIX)\n* Fix CMake warning about CMP0054 by unquoting instances of HOST\n* Fix Cygwin64 build\n* Fix GC_REALLOC to call GC_FREE if new size is zero and pointer is non-NULL\n* Fix Makefile.direct for Cygwin\n* Fix __alloc_size__ availability detection (Clang)\n* Fix abort message in GC_move_long_link\n* Fix and code refactoring of lock elision workaround (Linux/x64)\n* Fix assertion on mark_lock_holder for non-unique NUMERIC_THREAD_ID\n* Fix data race in GC_init_explicit_typing\n* Fix gc.mak regarding msvc_dbg and test (MSVC)\n* Fix missing error handling of pthread_attr_init/getstacksize\n* Fix missing error handling of pthreads_mutex_init and cond_wait\n* Fix missing numeric casts in cord\n* Fix potential left shift overflows in finalize.c (64-bit targets)\n* Fix pthreads-win32 name in comments and documentation\n* Fix setup_mark_lock missing prototype\n* Fix unchecked fcntl() result\n* Fix unchecked pointer dereference in check_ints (gctest)\n* Fix unchecked pthread_join() result in threadkey_test\n* Fix unchecked sigdelset() result in pthread_support\n* Fix undefined PTRFREE/NORMAL in gc_inline.h\n* Prefix PREFETCH_FOR_WRITE with GC_ as used in gc_inline.h public header\n* Relax mark_mutex attribute needed to disable elision (Linux/x64)\n* Remove (deprecate) TODO file\n* Remove code duplication in GC_realloc\n* Remove duplicate new-line in OUT_OF_MEMORY message (cord)\n* Remove references to missing linux_threads.c from documentation\n* Revert \"Move asm machine-dependent files to 'src' folder\" (partly)\n* Support Android API level 21\n* Update compiler options in gc.mak (Win32)\n* Use mmap instead of sbrk (Hurd)\n* Workaround 'comparison is always false' GCC warning in GC_FAST_MALLOC_GRANS\n* Workaround 'identical expr on both sides of bitwise op' warning\n* Workaround Linux NTPL lock elision bug\n* Workaround false warning about unreachable code path\n* Workaround invalid '_end' symbol on Android clang 3.5+\nAlso, includes 7.2g changes\n\n\n== [7.4.2] 2014-06-03 ==\n\n* Add config option to use STGRTMIN-based signals for thread suspend/resume\n* Allow parallel mark to be enabled on powerpc-linux systems\n* Check for Fujitsu compiler in builtin_unwind logic (enable FX10/K-Computer)\n* Fix 'Array subscript is above array bounds' GCC warning in GC_new_kind/proc\n* Fix 'attribute declaration must precede definition' warning (clang-3.1)\n* Fix (enable) Cygwin-64 build\n* Fix GC_finalized_malloc failure on disclaim_test\n* Fix GC_sig_suspend initialization when non-constant SIGRTMIN used\n* Fix MS VC redefinition warning for functions declared with GC_ATTR_MALLOC\n* Fix TEXT() usage for concatenated strings in GC_CreateLogFile (Win32)\n* Fix data roots registration for Android/x86 and NDK ARM 'gold' linker\n* Fix find stackbottom on BlueGene P/Q systems\n* Fix machdep .lo files path in configure (SPARC, IA-64)\n* Fix ok_init assignment (missing cast) in GC_new_kind_inner\n* Fix typos in names in AUTHORS and ChangeLog files\n* Remove barrett_diagram file duplicated by tree.html\n* Remove non-existing DISCARD_WORDS from GC data structure ASCII diagram\n* Restore contribution information for ancient releases in ChangeLog\nAlso, includes 7.2f changes\n\n\n== [7.4.0] 2013-11-17 ==\n\n* Add 'bytes reclaimed' counters to public GC_prof_stats_s\n* Add AArch64 (64-bit ARM) target support\n* Add GC_LONG_REFS_NOT_NEEDED ifdefs to exclude long link functionality\n* Add GC_get_prof_stats[_unsafe]() to GC public API\n* Add GC_push_all/conditional() to GC public API\n* Add assertion on number_of_objs to GC_extend_size_map\n* Add assertion to GC_enable() ensuring no counter underflow\n* Add assertion to LOCK definition that lock is not already held\n* Add assertion to LONG_MULT and remove useless assert in PUSH_CONTENTS_HDR\n* Add double-lock assertion to GC_acquire_mark_lock\n* Add manual POSIX fork handling support (Android)\n* Add note about 'pkg-config' solving problem with autoconf 2.68 or older\n* Add public GC_set/get_abort_func to replace default GC_on_abort\n* Add public GC_start_mark_threads() to allow parallel marker in fork child\n* Add public setter and getter for GC_push_other_roots\n* Add support of Android logger\n* Add tests for GC_register/move/unregister_long_link\n* Add thread suspend/resume signals public setters (POSIX threads)\n* Added long weakref support\n* Adjust GC_dont_expand/gc/precollect and GC_print_stats type to match gc.h\n* Adjust README.md title and references to doc .html files in it\n* Adjust build scripts to enable additional test library in staticrootstest\n* Adjust logged messages in start_mark_threads and GC_thr_init\n* Adjust printf format specifiers in GC_print_trace\n* Allow not to rely on __data_start value (Linux)\n* Allow pthread_kill error code logging in GC_suspend/resume (debugging)\n* Allow to compile GC_inner_start_routine aside from extra/gc.c\n* Allow to omit libc atexit() call\n* Avoid LOCK/UNLOCK hard-coding in gc_locks.h for PS3 target\n* Better document GC_warn_proc in gc.h\n* Call GC_on_abort (with NULL argument) on exit(1)\n* Call GC_stats/verbose_log_printf instead of GC_log_printf if print_stats\n* Change policy regarding version numbers (\"micro\" part instead of \"alpha\")\n* Changed C99-style designated init of GC_dl_hashtbl struct to use C89-style\n* Check GC_base result in GC_print_all_smashed_proc\n* Check that SIG_SUSPEND and SIG_THR_RESTART are different (Pthreads)\n* Check traceable_allocator.allocate result before dereference in test_cpp\n* Code refactoring of GC_x_printf (move shared code to macro)\n* Convert readme to markdown\n* Default to use libc_stack_end in single-threaded GC on glibc targets\n* Define GC_VSNPRINTF internal macro in misc.c (code refactoring)\n* Define functions in darwin_semaphore.h as inline instead of static\n* Define old_bus_handler static variable only if used (Unix)\n* Detect dladdr() presence by configure\n* Disable find-leak GC_gcollect on GC abnormal EXIT\n* Do not define _setjmp/_longjmp macros in mach_dep.c\n* Do not duplicate android_log_write output to GC log file (Android)\n* Do not include sigcontext.h if NO_SIGCONTEXT_H (Linux)\n* Do not set GC_lock_holder by call_with_alloc_lock if assertions disabled\n* Do not use pthread_getattr_np if NO_PTHREAD_GETATTR_NP specified\n* Elaborate comment on dependencies in autogen.sh\n* Eliminate 'cast from int to pointer' warning in GC_exclude_static_roots\n* Eliminate 'missing exception specification' warning in gc_cpp.cc (Clang)\n* Eliminate 'uninitialized variable use' warning in test_printf (cord)\n* Eliminate 'unused result' compiler warning in main() of test_cpp\n* Eliminate 'unused value' compiler warning in GC_stop_world (Pthreads)\n* Eliminate 'unused variable' compiler warning in start_mark_threads (HP/UX)\n* Eliminate Clang warning for GC_pthread_exit attribute\n* Eliminate GCC warning about uninitialized 'hhdr' in GC_allochblk_nth\n* Eliminate GCC warning in GC_get_main_stack_base (OpenBSD)\n* Eliminate GCC warnings in setjmp_t.c, test_cpp and cord 'de' app\n* Eliminate GC_first_nonempty atomic value reload in GC_mark_local assertion\n* Eliminate SIGBUS-related dead code in GC_write_fault_handler (Linux)\n* Eliminate warning and simplify expression in GC_init_explicit_typing\n* Enable 'force GC at every GC_malloc' debug-related functionality\n* Enable on-demand debug logging in GC_FindTopOfStack (Darwin)\n* Enable prefetch operations by default (GCC 3.0+)\n* Enable staticrootstest for the case of GC shared library build\n* Enable thread-local allocation support for Clang on Cygwin\n* Explicitly specify that Darwin, Linux and Solaris platforms have dladdr\n* Fix ABORT definition for mingw32ce (WinCE)\n* Fix AM_CONFIG_HEADER in configure for autoconf-2.69-1\n* Fix GC_CreateThread and GC_beginthreadex definition for Cygwin\n* Fix GC_INIT_CONF_ROOTS in gc.h for Android\n* Fix GC_INLINE definition to comply with ISO C90 standard (GCC)\n* Fix GC_remove_all_threads_but_me for Android (fork support)\n* Fix debug_register_displacement calls from GC_debug_generic_malloc_inner\n* Fix dyn_load.c compilation for Android 4.3\n* Fix make disclaim_test to link with new GNU ld linking rules\n* Improve GC error printing atomicity in GC_debug_X and GC_print_obj\n* Improve GC output atomicity in GC_print_obj, GC_print_all_errors\n* Improve debug-only messages of add/remove_roots and init_linux_data_start\n* Improve fork test logging in gctest\n* Improve logged messages about heap size and usage\n* Improve logging for Android differentiating messages by log level\n* Improve staticrootstest (add global data to library, add lib w/o GC_INIT)\n* Improve staticrootstest checks (tests)\n* Include \"config.h\" instead of \"private/config.h\" on HAVE_CONFIG_H\n* Include proper header file in 'tools' for configuration macros\n* Include pthread_np.h from pthread_stop_world.c on OpenBSD\n* Log error messages to stderr instead of stdout in tests\n* Make GC_generic_malloc_ignore_off_page() public\n* Make GC_mark_lock_holder variable static\n* Make GC_print_trace always thread-safe and remove 'lock' argument\n* Mark GC_started_thread_while_stopped() as GC_INNER\n* Minimize code duplication in GC_mark_and_push\n* Move 'include setjmp.h' from mach_dep.c to gc_priv.h\n* Move GC_OPENBSD_UTHREADS definition to private/gcconfig.h (OpenBSD)\n* Move GC_get_suspend/thr_restart_signal to misc.c for NaCl and OpenBSD\n* Move LOCK/UNLOCK from GC_unregister_disappearing_link_inner outer\n* Port BDWGC to Android/x86\n* Postpone the suspend signal in GC_dirty_init only if used to stop world\n* Prepend '#' symbol to GC number in logged messages\n* Prevent POSIX fork if mprotect_thread is started (Darwin)\n* Prevent abort on GC_err/warn_printf write failure\n* Prevent misleading AC_MSG_ERROR/AS_IF errors reported in configure.ac\n* Put gc_cpp symbols into 'boehmgc' namespace if GC_NAMESPACE defined\n* Recognize GC_DONT_GC macro in gc.h (causes GC_INIT to turn off GC)\n* Recognize GC_SIG_SUSPEND and GC_SIG_THR_RESTART tuning macros in gc.h\n* Redirect WRITE to __android_log_write if GC_ANDROID_LOG (Android)\n* Refine comment of GC_is_heap_ptr and GC_thread_is_registered in gc.h\n* Register dynamic libraries via dl_iterate_phdr on Android and OpenBSD\n* Remove DebugBreak on WriteFile failure (Win32)\n* Remove GC_BUILD definition from build scripts\n* Remove abort on open log failure from GC_write (Win32)\n* Remove configure.ac outdated revision number\n* Remove nested EXPECT in GC_core_finalized_malloc\n* Remove nested always-false ifdef for HPUX and FREEBSD\n* Remove redundant GC_err_printf before abort\n* Remove unused UTHREAD_SP_OFFSET macro (OpenBSD)\n* Rename subthread_create to subthreadcreate_test (Makefile)\n* Replace GC_COND_LOG_PRINTF calls with WARN for allocation failure messages\n* Replace GC_log/err_printf() followed by ABORT with ABORT_ARGn()\n* Replace GC_stats_log_printf with GC_DBG/INFOLOG_PRINTF\n* Replace SIG_SUSPEND/THR_RESTART macros to variables in pthread_stop_world\n* Replace Win32 GC_delete_gc_thread with GC_delete_gc_thread_no_free\n* Replace conditional GC_log_printf calls with GC_COND/VERBOSE_LOG_PRINTF\n* Replace sprintf with defensive snprintf\n* Replace var-args GC_noop with GC_noop6 (to eliminate Clang warning)\n* Simplify LOCK/UNLOCK macro definition for static code analysis tools\n* Specify GC_malloc result is unused in some tests\n* Specify GC_pthread_join result is unused in threadkey_test\n* Specify LT_INIT in configure.ac\n* Start of port to QNX\n* Support rthreads introduced in OpenBSD 5.2+\n* Suppress 'GC_dont_gc deprecated' warning in gc.h if GC_DONT_GC\n* Tag GC malloc routines with alloc_size attribute for Clang 3.2+\n* Test NO_WRAP_MARK_SOME macro to suppress WRAP_MARK_SOME-specific code\n* Turn off GC_LOOP_ON_ABORT functionality if GC compiled with NO_DEBUGGING\n* Turn on world-stop delay logging at debug level by default for Android\n* Use EXPECT in GC_COND/VERBOSE_LOG_PRINTF\n* Use GC_log_printf for logging instead of GC_[err_]printf\n* Use compiler TLS for Android NDK gcc/arm\n* Use memcpy (BCOPY) instead of strcpy (to suppress GCC warning)\n* Use pthread API to operate thread-local data on Linux if no compiler TLS\n* Workaround 'ELF_DATA/EM_ALPHA redefined' warning in Android linker.h\n* Workaround 'unresolved __tls_get_addr' error for Android NDK Clang\nAlso, includes 7.2e, 7.2d, 7.2c, 7.2b changes\n\n\n== [7.3alpha2] 2012-05-11 ==\n\n* Add 'const' qualifier to pointer argument of some API functions\n* Add GC_UNDERSCORE_STDCALL, UNICODE macro templates to configure (Win32)\n* Add GC_get_thr_restart_signal, GC_thread_is_registered to GC API\n* Add GC_is_heap_ptr, GC_move_disappearing_link to GC API\n* Add SHORT_DBG_HDRS macro template to configure\n* Add Symbian port to mainline (porting done by Djamel Magri)\n* Add TODO file\n* Add assertion ensuring proper alignment of 'pushed' GC symbols\n* Add assertion in GC_getspecific on qtid\n* Add assertion to GC_incremental_protection_needs, refine documentation\n* Add assertion to check GC_large_free_bytes by GC_finish_collection\n* Add configure option to compile all library .c files into single gc.o\n* Add cordtest to make check\n* Add disclaim callbacks for efficient finalization (ENABLE_DISCLAIM)\n* Add finalization.html to 'doc' folder\n* Add javaxfc.h to the installation set of GC header files (configure)\n* Add on-heap-resize event notification to API\n* Adjust GC_log_printf format specifiers (regarding signed/unsigned long)\n* Adjust GC_requested_heapsize on GC_init if GC_INITIAL_HEAP_SIZE given\n* Allow GC_exclude_static_roots() region start to be unaligned\n* Allow Win32 DllMain chaining on the client side\n* Allow to exclude finalization support by GC_NO_FINALIZATION macro\n* Allow to get memory via Win32 VirtualAlloc (USE_WINALLOC) on Cygwin\n* Avoid unnecessary GC_find_limit invocation if GC_no_dls\n* Avoid use of deprecated GC_dont_gc and GC_stackbottom in gctest\n* Cast pointers to word (instead of unsigned long) in specific.h\n* Changed the order in autogen.sh so ltmain exists in time for automake\n* Declare privately and use handy GC_base_C() for constant object pointers\n* Define GC_DLL if DLL_EXPORT at GC build (for Cygwin/MinGW)\n* Define GC_READ_ENV_FILE in configure for WinCE unless gc-debug is off\n* Do not compile backgraph.c unless configure '--enable-gc-debug'\n* Do not compile pthread_stop_world.c for Cygwin/Darwin (configure)\n* Do not install ancient new_gc_alloc.h broken for modern STL (configure)\n* Enable GC_MIN_MARKERS to set minimal number of pthread-based markers\n* Enable PARALLEL_MARK and THREAD_LOCAL_ALLOC for FreeBSD in configure\n* Enable parallel mark by default in configure (Darwin/Linux/Solaris/Win32)\n* Export GC_is_marked, GC_clear/set_mark_bit (for mark-bit manipulation)\n* Extend thread-related debug messages\n* Fix 'configure --enable-cplusplus' for Cygwin/MinGW\n* Fix DATASTART (and other minor improvements) for NaCl target\n* Fix GC_setspecific to prevent garbage collection inside\n* Fix compiler warning in cordtest\n* Fix minor warnings reported by GCC with '-pedantic' option\n* Fix static data roots registration on Android (if GC is shared)\n* Implement GC_get_stack_base for Darwin for single-threaded mode\n* Improve GC_allochblk algorithm of block splitting when unmapping enabled\n* Improve GC_collect_or_expand algorithm for many finalizers registered case\n* In tests, print a message in case a test is a no-op\n* Instruct configure to hide internal libgc.so symbols if supported by GCC\n* Log amount of unmapped memory (if enabled) on marking-for-collection\n* Make __data_start a weak symbol to allow loading modules on mips\n* Move \"cord\" library tests to \"cord/tests\" folder\n* Move asm machine-dependent files to \"src\" folder\n* Move build tools sources to \"tools\" folder\n* Move cord_pos.h to public headers folder\n* Open log file in APPEND mode on Win32 (similar that on Unix/Cygwin)\n* Optimize some functions by moving pthread_self calls out of LOCK section\n* Place only major per-release changes description to ChangeLog (this file)\n* Prevent compiler warnings in GC_FindTopOfStack and GC_ports (Darwin)\n* Recognize GC_LOG_TO_FILE_ALWAYS macro to log to 'gc.log' by default\n* Remove all auto-generated files from the repo\n* Remove binary icon file for de_win\n* Remove cordtest from \"cord\" library\n* Remove duplicate MacOS_Test_config.h file\n* Remove gc_amiga_redirects.h (included internally) from public headers\n* Remove obsolete Makefile.DLL (superseded by Cygwin/MinGW configure)\n* Remove obsolete unused asm files for ALPHA, HPUX, SGI, RS6000, ULTRIX\n* Remove unsupported MMAP_STACKS (specific to Solaris threads)\n* Remove unused ancient SILENT, __STDC__, NO_SIGNALS macros\n* Replace ARGSUSED comment-based annotation with GCC 'unused' attribute\n* Replace GC_ms_entry declaration with opaque definition for public API\n* Replace long GC_markers global variable with int GC_markers_m1\n* Replace pointer relational comparisons with non-pointer ones\n* Replace printf PRIxMAX specifier with '%p' for thread id debug output\n* Require autoconf 2.61 instead of v2.64\n* Simplify autogen.sh (use autoreconf)\n* Split GC_abort with GC_on_abort and abort() invoked from ABORT\n* Support GC_ATTR_MALLOC for MS VisualStudio\n* Tag auxiliary malloc-like API functions with 'malloc' attribute\n* Tag deprecated variables in GC API\n* Tag must-be-non-null arguments of GC API functions\n* Turn on \"extra\" GCC warnings\n* Turn on unused-parameter checking for GCC\n* Update AUTHORS file\n* Use EXPECT for checking various 'initialized' boolean variables\n* Use USE_COMPILER_TLS on Cygwin\n* Use pthread_key for thread-local storage on FreeBSD\n* Use union of AO_t and word to favor strict-aliasing compiler optimization\nAlso, includes 7.2 changes\n\n\n== [7.2s] 2024-09-06 ==\n\n* Avoid gcc stringop-overflow warning for intended overflow in smashtest\n* Eliminate 'type defaults to int in declaration' warning (REDIRECT_MALLOC)\n* Eliminate 'value exceeds maximum object size' GCC warning in huge_test\n* Eliminate warning and simplify expression in GC_init_explicit_typing\n* Fix 'GetVersion deprecated' compiler warning in os_dep (MS VC)\n* Fix 'value truncated' compiler warning in CORD_cat (MS VC)\n* Fix ADD_CALL_CHAIN() placement to follow GC_store_debug_info_inner call\n* Fix GC_is_visible for case of arg pointing exactly to object upper bound\n* Fix GC_jmp_buf multiple definition\n* Fix GC_print_trace_inner to print the last element of the circular buffer\n* Fix double lock in GC_malloc called from backtrace()\n* Fix indent of a closing curly braces in GC_apply_to_all_blocks\n* Fix null pointer dereference in GC_is_visible if type_descr is null\n* Fix per_object_helper() after changing hb_sz units\n* Fix poor thread-local allocation performance because of double EXTRA_BYTES\n* Fix potential GC_add_roots_inner call with an overflowed pointer (Win32)\n* Fix potential address overflow in GC_add_to_heap\n* Fix potential buffer overrun during read in GC_text_mapping\n* Fix typos in comments\n* Prevent compiler warnings regarding unused argument and printf in extra\n* Prevent redirected malloc call from a garbage collection routine\n* Remove barrett_diagram file duplicated by tree.html\n* Remove non-existing DISCARD_WORDS from GC data structure ASCII diagram\n* Resolve GCC warning in setjmp_t.c\n* Update and fix diagrams describing the tree structure for pointer lookups\n\n\n== [7.2r] 2024-02-03 ==\n\n* Fix 'g++ not found' error on OpenBSD (Makefile.direct)\n* Fix 'implicit declaration of iscntrl()' warning in cord/de_win (MinGW)\n* Fix 'info' buffer potential overrun in GC_save_callers\n* Fix 'missing sysconf() prototype' gcc error in setjmp_t tool (OpenBSD)\n* Fix SVR4 macro definition order\n* Fix asm constraint in LONG_MULT for gcc/x86\n* Fix assertion violation in GC_get_maps on Linux if malloc redirection\n* Fix bitwise negation and rounding direction in setjmp_t tool\n* Fix closing bracket placement for case statement in configure\n* Fix indent of a closing curly brace in GC_forward_exception\n* Fix missing outermost parentheses in CORD_pos_cur_char_addr\n* Fix missing type widening before left shift in GC_MAKE_PROC\n* Fix misspelled GC_HEADERS_H macro in gc_priv.h\n* Fix null dereference in check_finalizer_nested if redirect malloc on Linux\n* Fix posix_memalign() to overwrite pointer storage only on success\n* Fix skipped removal of page protection in case of address hash collision\n* Fix typos in comments\n* Fix update of last_back_trace_gc_no if KEEP_BACK_PTRS is not defined\n\n\n== [7.2q] 2023-05-25 ==\n\n* Fix CORD_next() indent inside loop in test_basics() of cordtest\n* Fix DCL_LOCK_STATE placement in GC_set_oom_fn\n* Fix GC_excl_table overrun on overflow in GC_exclude_static_roots\n* Fix IRIX5 defined wrongly on Tandem S-Series and WinCE/mips\n* Fix comparisons to heap boundary in GC_get_back_ptr_info and GC_mark_from\n* Fix disabling of automatic dynamic libraries registration\n* Fix double initialization of main thread local free lists on Win32\n* Fix joinable threads shutdown on NaCl\n* Fix loop condition over dll_thread_table in GC_lookup_pthread (Win32)\n* Fix missing GC_CALLBACK for GC_waitForSingleObjectInfinite\n* Fix missing libalphagc.so dependency in Makefile.direct\n* Fix missing result check of pthread_attr_getdetachstate in pthread_create\n* Fix overlapping region assertion in mark_some if malloc redirect on Linux\n* Fix potential SIGSEGV on out-of-memory in gctest\n* Fix typos in comments and documentation\n* Fix unregistering of thread created by intercepted pthread_create on NaCl\n* Fix use of unset errno after pthread_create call\n* Invoke GC_oom_fn if GC_make_array_descriptor failed because of no memory\n\n\n== [7.2p] 2022-08-25 ==\n\n* Avoid potential race in GC_init_real_syms after GC_allow_register_threads\n* Define SUNOS5SIGS macro for kFreeBSD\n* Do not assert that GC is initialized at DLL_THREAD_DETACH (Win32)\n* Ensure typed objects descriptor is never located in the first word\n* Fix GC_make_descriptor for zero length argument\n* Fix SUNOS5SIGS documentation to match macro definition in gcconfig.h\n* Fix assertion violation in GC_allow_register_threads on Windows\n* Fix get_maps failure when GC_repeat_read returns zero\n* Fix hb_obj_kind type in documentation (ASCII diagram) describing hblkhdr\n* Fix missing lock when GC_generate_random_valid_address is called\n* Fix nodist_libgc_la_SOURCES value in Makefile.am for Solaris/sparc\n* Fix oldProc initialization in gc_cleanup and eliminate related warnings\n* Fix parallel_initialized assertion violation in initsecondarythread (Win32)\n* Fix propagation of out-of-memory occurred in GC_make_sequence_descriptor\n* Fix race between calloc_explicitly_typed and push_complex_descriptor\n* Fix typos in comments of .c files, gc.h and a typo in debugging.html\n* Refer to Makefile.direct instead of deleted Makefile file in README\n* Remove checking of RS6000 completely\n* Remove non-working check of M68K in gctest\n* Revert addition of msvc_dbg.h in include.am\n\n\n== [7.2o] 2021-09-28 ==\n\n* Add loop to handle abort error like in suspend logic on Darwin\n* Disable mprotect-based incremental GC if /proc roots are used (Linux)\n* Explicitly zero-initialize trace_buf (fix trace_buf initialization)\n* Fix 'ACCESS_VIOLATION in marker' GC warning on Win32 async thread start\n* Fix 'GC_generic_malloc must be available' GCC error in new_gc_alloc.h\n* Fix 'expected function body after declarator' clang error in gc_cpp.cc\n* Fix 'write to GC log failed' error\n* Fix GC_proc_fd value in child process at fork (Solaris)\n* Fix assertion violation in register_dynlib_callback on Android\n* Fix configure message about 'AIX gcc optimization fix'\n* Fix data race regarding *rlh value in generic_malloc_many\n* Fix first_thread stack_base initialization if custom GC_stackbottom (Win32)\n* Fix fread failure after enable_incremental if malloc is redirected (Linux)\n* Fix gc_cflags variable name in configure (HP/UX)\n* Fix handling of areas smaller than page size on recycle scratch area\n* Fix incorrect define GC_OPENBSD_THREADS on sparc64\n* Fix misaligned tlfs passed to AO_load on m68k\n* Fix missing GC_quiet declaration in pcr_interface.c\n* Fix missing gc_dlopen.c in CMake script\n* Fix missing scratch_last_end_ptr update (Irix)\n* Fix overflow of scratch_free_ptr value\n* Fix page_was_[ever_]dirty() for static roots (Solaris)\n* Fix printf format specifier in simple_example.html\n* Fix save_callers for multi-threaded case if built-in backtrace unavailable\n* Fix various typos in comments and documentation files\n* Fix word size, data start and alignment for OpenBSD/mips64(el)\n* Prevent WARN of incompatible incremental GC if default or manual VDB\n* Reduce a time period between GetExitCodeThread and SuspendThread (Win32)\n* Remove a misleading comment about Solaris in gc.h\n\n\n== [7.2n] 2019-03-01 ==\n\n* Fix 'mprotect remapping failed' abort on NetBSD with PaX enabled\n* Fix 'unexpected mark stack overflow' abort in push_all_stack\n* Fix BSD_TIME variant of MS_TIME_DIFF for the case of a.tv_usec < b.tv_usec\n* Fix GetThreadContext stale register values use if WoW64 (Win32)\n* Fix executable memory allocation in GC_unix_get_mem\n* Fix invalid initializer of CLOCK_TYPE variables if BSD_TIME\n\n\n== [7.2m] 2018-12-11 ==\n\n* Fix comment typos in CMakeLists.txt, backgraph.c, de.c, gcconfig.h\n* Fix hbp overflow in GC_install_counts\n* Fix start_world not resuming all threads on Darwin\n* Guard against potential buffer overflow in CORD_next and CORD_pos_fetch\n\n\n== [7.2l] 2018-08-10 ==\n\n* Fix 'pointer arithmetic with NULL' code defect in print_callers\n* Fix Borland version in documentation to match that in BCC_MAKEFILE\n* Fix comment about inv_sz computation in setup_header\n* Fix comments style in configure.ac and Makefile.am\n* Fix GC_is_valid_displacement and GC_is_visible for non-small objects\n* Fix global operator delete definition for C++14 in gc_cpp\n* Fix infinite restarting of mark_some when a static root disappeared (Linux)\n* Fix large object base computation in PUSH_CONTENTS() if MARK_BIT_PER_OBJ\n* Fix mark stack overflow checking in push_selected\n* Fix MSWIN32 macro redefinition (WCC)\n* Fix potential null dereference in GC_CONS\n* Fix register_dynamic_libraries on Windows 10\n* Fix result computation in n_set_marks\n* Fix return type in GC_set_warn_proc API documentation\n* Fix typo in comment for CORD_ec_flush_buf prototype\n* Fix typos in ChangeLog\n* Fix VirtualQuery call in case of malloc failure (Win32)\n* Install gc.3 man page instead of copying gc.man to doc folder (configure)\n* Perform thread_suspend in loop as it may be interrupted (Darwin)\n* Workaround 'template-id not supported in this context' compiler error (WCC)\n\n\n== [7.2k] 2018-04-19 ==\n\n* Fix arguments delimiter in pcr_interface.c (PCR)\n* Fix assertion violation in DllMain of win32_threads\n* Fix data race during apply_to_each_object(reset_back_edge)\n* Fix dbg_mlc.c/o file name in documentation\n* Fix include gc_gcj.h in thread_local_alloc.c\n* Fix man section number (3)\n* Fix missing GC_generic_malloc_words_small implementation in new_gc_alloc.h\n* Fix missing SIGBUS handler setup for kFreeBSD\n* Fix null dereference in print_callers on backtrace_symbols failure\n* Fix the collector hang when it is configured with --enable-gc-debug\n* Fix thread_suspend fail for threads registered from key destructor (OS X)\n* Fix typo in AIX macro name\n* Fix typo in comment in specific.h\n\n\n== [7.2j] 2018-01-21 ==\n\n* Fix GC allocation mutex in child after a fork\n* Fix last_reclaimed..gc_no interval comparison to threshold in unmap_old\n* Fix libgc version which was changed in linkage breaking way\n* Fix missing EOLn output in threadlibs tool\n\n\n== [7.2i] 2017-12-21 ==\n\n* Avoid data race in finalized_count (gctest)\n* Fix assertion violation about disabled cancel in try_to_collect_inner\n* Fix data race in a list referenced by A.aa (gctest)\n* Fix data race in do_local_mark when comparing active_count to helper_count\n* Fix data race in GC_init_explicit_typing\n* Fix data race in last_stop_count access (suspend_handler_inner)\n* Fix data race in mark_thread when updating mark_no\n* Fix data race when getting object size in explicitly-typed allocators\n* Fix lack of barriers to synchronize memory for suspend_handler\n* Fix typos in cdescr.html, extend_size_map and ews4800 doc, README.sgi\n* Prevent 'Unexpected heap growth' in single-threaded gctest (Linux/x64)\n\n\n== [7.2h] 2017-10-12 ==\n\n* Add gctest as a test (CMake)\n* Change no-argument functions declaration style to ANSI C (extra files)\n* Do not allow SHORT_DBG_HDRS if KEEP_BACK_PTRS or MAKE_BACK_GRAPH\n* Ensure oom_fn callback executed on out-of-memory in calloc\n* Fix '~' operator application to unsigned values shorter than word\n* Fix 'context local variable might be clobbered by setjmp' compiler warning\n* Fix 'doc' files installation folder\n* Fix 'shift count >= width of type' compiler warning in GC_SQRT_SIZE_MAX\n* Fix ALL_INTERIOR_POINTERS name in comments and documentation\n* Fix AO_SRC_DIR target name in NT_*_MAKEFILE\n* Fix assertion in GC_mark_from for non-heap regions\n* Fix assertion in GC_steal_mark_stack for non-heap regions\n* Fix assertion violation in GC_repeat_read if --enable-redirect-malloc\n* Fix assertion violation in GC_wait_builder called from start_mark_threads\n* Fix assertion violation in mark_local checking GC_mark_stack_top\n* Fix assertion violation in return_single_freelist in child process\n* Fix bm_huge initialization for 64-bit targets (gctest)\n* Fix broken external links in documentation\n* Fix bytes count passed to add_to_our_memory in backgraph new_back_edges\n* Fix calloc_explicitly_typed in case of lb*n overflow\n* Fix CMake warning about CMP0054 by unquoting instances of HOST\n* Fix conditional expression in pos_fetch, next non-macro definitions (cord)\n* Fix configure --disable-munmap handling\n* Fix CORD_substr_closure for the case when CORD_from_fn returns C string\n* Fix crash in FirstDLOpenedLinkMap if app linked statically (Alpine Linux)\n* Fix double lock in pthread_detach (Cygwin, winpthreads)\n* Fix double multiplication of lb by n in calloc_explicitly_typed\n* Fix enable_parallel_mark condition in CMake script\n* Fix external libatomic_ops pkg-config-based detection\n* Fix gc_allocator.h file name in new_gc_alloc.h comment\n* Fix gc_backptr.h, gc_mark.h, GC_DS_TAGS names in documentation\n* Fix gc_cleanup destructor for non-heap objects (gc_cpp)\n* Fix GC_collect_or_expand to prevent allocation size value wrap-around\n* Fix GC_incremental declaration/definition type mismatch\n* Fix GC_mark_stack_top assertion violation properly in mark_local\n* Fix GC_remove_specific invocation from remove_all_threads_but_me\n* Fix GC_requested_heapsize increment in GC_init\n* Fix GC_setspecific to prevent garbage collection inside\n* Fix GC_SIZE_MAX definition (Linux/musl-gcc)\n* Fix GCJ support in CMake build script\n* Fix gctest crash if configure --enable-handle-fork on Darwin\n* Fix get_maps on proc maps file asynchronous growth\n* Fix hb_n_marks underflow in clear_fl_marks if MARK_BIT_PER_OBJ\n* Fix header filename in gcconfig.h comment\n* Fix infinite mark_some calls after memory mapping disappeared (Glibc)\n* Fix integer shift undefined behavior in GC_init_explicit_typing\n* Fix leak_test crash in print_callers if free() is redirected\n* Fix Makefile.direct recursive invocation\n* Fix malloc routines to prevent size value wrap-around (fix CVE-2016-9427)\n* Fix missing win32_threads.c compilation for Cygwin (CMake)\n* Fix MS VC warning about compiling unused checksums and thread_local_alloc\n* Fix name typos in GC_FAST_MALLOC_GRANS comment\n* Fix null dereference in reclaim_block if DONT_ADD_BYTE_AT_END\n* Fix OSF1 host pattern in CMakeLists.txt\n* Fix PCR-Makefile by removing compilation of a missing file\n* Fix potential data race in GC_SysVGetDataStart (SPARC)\n* Fix potential integer overflow in GC_find_limit_* functions\n* Fix printf arguments type in print_callers\n* Fix pthread_detach for threads not yet registered (Cygwin, winpthreads)\n* Fix pthread_join to avoid thread removal on failure (Cygwin, winpthreads)\n* Fix pthread_join when thread is registered in thread key destructor\n* Fix push_complex_descriptor to avoid unlimited global mark stack growth\n* Fix removal of dead threads in a child process\n* Fix SIGSEGV in GC_is_marked when gc_cleanup is used in leak-finding mode\n* Fix SIGSEGV in mark_from called from do_local_mark if WRAP_MARK_SOME\n* Fix Solaris/sparc detection in case of strict C compliance is enforced\n* Fix STACKBOTTOM for Solaris 11/x86\n* Fix storage class of local variable in register_dynamic_libraries (Irix)\n* Fix tools/setjmp_t hang (OS X)\n* Fix typed_test to prevent fails in malloc_explicitly_typed (64-bit)\n* Fix undefined HEAP_START in register_dynamic_libraries\n* Fix USE_CUSTOM_SPECIFIC mode (if manually enabled) for Win32\n* Fix USE_GET_STACKBASE_FOR_MAIN definition in gcconfig.h\n* Fix various typos in comments, documentation and printed messages\n* Handle load_segs overflow in register_dynlib_callback gracefully\n* Prevent misleading AC_MSG_ERROR/AS_IF errors reported in configure.ac\n* Replace (fix) 'objs' acronym in comments with 'objects' word\n* Revert \"Skip GC_DS_PER_OBJECT objs with negative descriptor in GC_mark_from\"\n* Update documentation about bugs reporting and new releases notification\n* Update Download information in GC overview document\n* Update shared libraries version info (v7.2)\n* Workaround a bug in winpthreads causing parallel marks deadlock (MinGW)\n* Workaround missing getcontext() in Docker osrf/ubuntu_32bit\n\n\n== [7.2g] 2016-05-23 ==\n\n* Fix 'illegal option -xassembler-with-cpp' error (Oracle SunCC)\n* Fix 'implicit declaration of function' compiler warnings in cord/de\n* Fix CFLAGS in configure regarding -O flag passing to SunCC compiler\n* Fix FirstDLOpenedLinkMap for case libgc not 1st dynamically linked (NetBSD)\n* Fix GC initialization in cord de_win for Cygwin\n* Fix GC_get_stack_base if called before GC_init (Win32)\n* Fix OSX issue with pthread_attr_setstacksize failure\n* Fix Unicode Win32 API calls in cord de_win\n* Fix USE_COMPILER_TLS macro duplicate description in README\n* Fix cord de_win WndProc prototype parameters for 64-bit (Win64)\n* Fix file descriptor resource leak in GC_register_data_segments (OS/2)\n* Fix filename printing in cordtest\n* Fix missing cord_pos.h, ec.h among installed headers (Automake)\n* Fix missing GC_get_stack_base for Amiga\n* Fix missing msvc_dbg.h in dist_noinst_HEADERS (Automake)\n* Fix mistyped ARM_THREAD_STATE macro (Darwin/arm)\n* Fix null-pointer dereferences on out-of-memory in cord and tests\n* Fix potential multiplication overflow in check_heap_stats (gctest)\n* Fix race (and potential deadlock) at marker threads initialization\n* Fix signedness of char values passed to isspace, iscntrl, isxdigit\n* Fix typo (items numbering) in GC_finalize_all documentation\n* Fix typos in ERROR_FL, GC_malloc_uncollectable comments\n* Fix typos in gc_priv.h, in README for ews4800\n* Fix unresolved vsnprintf in misc.c and snprintf in cordtest (DJGPP, VC)\n* Fix various spelling errors\n* Fix vsprintf_args initialization/cleanup in CORD_vsprintf for EMX\n* Regenerate configure files using official libtool release (v2.4.2)\n* Remove documentation about obsolete GC_REDIRECT_TO_LOCAL\n* Skip GC_DS_PER_OBJECT objects with negative descriptor in GC_mark_from\n* windows-untested: Fix paths to msvc_dbg.c/h\n\n\n== [7.2f] 2014-06-03 ==\n\n* Fix 'Bad signal in suspend_handler' abort on FreeBSD-9.2\n* Fix 'source file in a subdirectory' Automake warnings\n* Fix ABORT message in GC_restart_handler\n* Fix ADD_DEFINITION in CMakeLists.txt for kFreeBSD\n* Fix CMakeLists.txt: do not override CMAKE_OSX_ARCHITECTURES\n* Fix GC_alloc_large by bumping GC_collect_at_heapsize in GC_add_to_heap\n* Fix GC_scratch_last_end_ptr update on GC_scratch_alloc failure\n* Fix GET_MEM argument rounding in GC_scratch_alloc and similar\n* Fix PARALLEL_MARK for Windows 7+\n* Fix build (broken by fenv.h inclusion) on Linux/x64 under uClibc\n* Fix crash when using GC_malloc_many() as first allocation call\n* Fix mark stack excessive growth during parallel mark\n* Fix or remove broken URLs in documentation\n* Fix out-of-memory case in new_back_edges, push_in_progress (backgraph)\n* Fix typo in GC_collect_or_expand comment\n* Fix typos in GC overview file, gc_config_macros.h, gc_cpp.h, README.changes\n* Regenerate configure files by automake 1.14.1, libtool 2.4.2.418\n* Update emails/links due to project site and ML transition\n\n\n== [7.2e] 2013-11-10 ==\n\n* Add weak attribute to avoid __data_start undefined messages (s390x)\n* Add weak stubs for pthread_cancel API\n* Adjust 'pthread_[un]register_cancel undefined ref' workaround (Pthreads)\n* Append _test suffix to 'initsecondarythread' binary file names\n* Enable PARALLEL_MARK and THREAD_LOCAL_ALLOC for FreeBSD in configure\n* Fix 'stack section' pointer passed to push_all_stack_sections (Pthreads)\n* Fix GC_CreateThread 'dwStackSize' argument type for Win64\n* Fix GC_PTHREAD_PTRVAL definition for GC_PTHREADS_PARAMARK (Win32)\n* Fix GC_clear_stack by declaring 'dummy' local array as volatile\n* Fix GC_get_stack_base assembly code (Cygwin/Clang)\n* Fix GC_malloc_explicitly_typed_ignore_off_page for large allocations\n* Fix GC_marker_Id elements initialization (WinCE)\n* Fix GC_print_trace missing unlock\n* Fix GC_unix_mmap_get_mem for open of /dev/zero failure\n* Fix GC_win32_free_heap compilation error for Cygwin\n* Fix GC_win32_free_heap to prevent memory leak if USE_GLOBAL_ALLOC\n* Fix Win32 GC_write preventing potential infinite recursion at abort\n* Fix assertion violation in GC_mark_from prefetch loop\n* Fix collection of objects referenced only from GC_mark_stack_X variables\n* Fix dwSize argument of VirtualFree call in detect_GetWriteWatch (Win32)\n* Fix heap sections overflow for Win32/Cygwin with enabled parallel marker\n* Fix min_bytes_allocd preventing potential infinite loop in GC_allocobj\n* Fix missing tabs in SMakefile.amiga file\n* Fix null-pointer dereference in CORD_substr_closure\n* Fix old_segv/bus_act variables initialization for FreeBSD\n* Fix potential double fclose in test_extras (cordtest)\n* Fix pthread_attr_t resource leak in pthread_create\n* Fix race in GC_print_all_errors regarding GC_leaked\n* Fix sizeof in GC_push_thread_structures\n* Fix stackbottom/stack_end assignment in GC_call_with_gc_active\n* Fix tests makefile to link with new GNU ld linking rules\n* Fix typos in comments and documentation\n* Fix unportable '==' test operators in configure\n* Fix vsprintf_args cleanup in CORD_vsprintf\n* Merge FreeBSD New ports collection for boehm-gc v7.2d\n* Replace GC_DBG_RA with GC_DBG_EXTRAS macro\n* Replace deprecated [CXX]INCLUDES to AM_C[PP]FLAGS in configure.ac file\n* Use __builtin_extract_return_addr in GC_RETURN_ADDR_PARENT (gcc/x86)\n\n\n== [7.2d] 2012-08-09 ==\n\n* Fix GC_call_with_stack_base to prevent its tail-call optimization\n* Fix all address-of-dummy operations by using GC_approx_sp() instead\n* Fix stop_info.stack_ptr assignment in GC_suspend_all for OpenBSD\n* Fix test_cpp (ensure the collector recognizes pointers to interiors)\n* Fix thread-related tests for pthreads-w32\n* test_cpp: Fix WinMain to prevent SEGV if zero arguments passed (MinGW)\n\n\n== [7.2c] 2012-06-11 ==\n\n* Fix CORD_cat_char_star to prevent SEGV in case of out-of-memory\n* Fix GC_FirstDLOpenedLinkMap() for NetBSD 6 release\n* Fix GC_scratch_alloc and GC_get_maps invocations to prevent SEGV\n* Fix visibility of GC_clear/set_mark_bit (unhide symbols)\n* Fix visibility of GC_push_all/conditional, GC_push_other_roots symbols\n\n\n== [7.2b] 2012-05-23 ==\n\n* Fix assertion in GC_malloc_[atomic_]uncollectable (THREADS case only)\n\n\n== [7.2] 2012-05-11 ==\n\n* Abort in GC_thr_init on pthread_atfork failure (POSIX threads)\n* Add GC_WIN32_PTHREADS target in configure\n* Add GC_is_disabled new function to GC API\n* Add info that getcontext() resets FPE mask no longer on Linux/x64\n* Add public GC_set_handle_fork to control forked child handling support\n* Add realloc_test.c test\n* Add support for Hexagon target\n* Add thread-safe GC_get_heap_usage_safe to GC API\n* Change GC_check_fl_marks prototype and implementation\n* Check pthread_create/join result in test\n* Define GC_DLL (in configure) if building only dynamic libraries\n* Define NO_DEBUGGING (in configure) if \"--disable-gc-debug\" is set\n* Disable incremental mode on Darwin if fork handling requested\n* Enable parallel marker in configure for Solaris\n* Fix \"comparison of signed and unsigned values\" compiler warnings\n* Fix 'volatile' keyword placement in GC_SysVGetDataStart\n* Fix ALIGNMENT, CPP_WORDSZ, GC_GRANULE_BYTES/WORDS for x32 target\n* Fix GC_READ_ENV_FILE code for Cygwin\n* Fix GC_add_roots_inner for Mac OS X (align segment start)\n* Fix GC_check_fl_marks regarding concurrent access\n* Fix GC_finalizer_nested size to workaround alignment problem in Watcom\n* Fix GC_find_limit_with_bound to always reset fault handler on return\n* Fix GC_init static assertion for clang/x64 (Darwin)\n* Fix GC_init[_lib_bounds] and GC_get_main_stack_base for malloc redirection\n* Fix GC_push_all/selected boundaries check\n* Fix GC_register_my_thread marking thread as detached (Cygwin/pthreads-w32)\n* Fix GC_remove_all_threads_but_me to cleanup thread-specific data storage\n* Fix GC_restart_handler to preserve errno if needed\n* Fix GC_root_size update in GC_add_roots_inner (Win32)\n* Fix GC_unregister_my_thread to ensure no ongoing incremental GC (Win32)\n* Fix GC_with_callee_saves_pushed for clang (disable __builtin_unwind_init)\n* Fix calloc, GC_generic_malloc to check for allocation size overflows\n* Fix compiler warning in GC_dyld_image_add/remove (Darwin)\n* Fix configure --enable-cplusplus make install\n* Fix configure to disable GCC aliasing optimization unless forced to\n* Fix duplicate definitions in gcconfig.h for NetBSD\n* Fix fork() support on Cygwin and Darwin targets\n* Fix gc.h compatibility regression regarding GC_PTR, GC_I_HIDE_POINTERS\n* Fix gc_cpp.cc for Cygwin (remove duplicate function definition)\n* Fix gcconfig.h to define USE_GET_STACKBASE_FOR_MAIN for Android\n* Fix gcconfig.h to handle mips64-linux target\n* Fix gctest (for Win32) to avoid GC_print_stats internal variable usage\n* Fix mach_dep.c to include sys/ucontext.h on Mac OS X 10.6\n* Fix tests to check GC_malloc result for NULL (out-of-memory)\n* Fix thread model in configure for MinGW (\"win32\" instead of \"posix\")\n* Fix various warnings reported by LINT-like tools\n* Fix visibility of some GC internal symbols used by GNU GCJ currently\n* Port some thread tests to Win32\n* Refine API GC setters and getter comments regarding locking\n* Refine GC_stackbottom description in gc.h\n* Remove duplicate calls in GC_register_dynamic_libraries\n* Remove locking in API GC_get_bytes_since_gc and friends\n* Remove newly-added GC_get_heap_size/free_bytes_inner from API\n* Remove some local variables that are unused\n* Support multi-threading for RTEMS target\n* Use global GC_noop_sink variable in GC_noop1 to suppress compiler warning\n* Use pkg-config to pick up libatomic_ops, etc\n* Workaround some Linux/arm kernels bug to get correct GC_nprocs value\n\n\n== [7.2alpha6] 2011-06-14 ==\n\n* configure_atomic_ops.sh: Remove.\n* Makefile.direct (dist gc.tar): Remove configure_atomic_ops.sh.\n* Makefile.am (EXTRA_DIST): Add autogen.sh.\n\n* NT_STATIC_THREADS_MAKEFILE (.cpp.obj): Remove duplicate .cpp\nfilename passed.\n* NT_X64_THREADS_MAKEFILE (.cpp.obj): Use lowercase file\nextension.\n* NT_X64_STATIC_THREADS_MAKEFILE (.cpp.obj): Likewise.\n* NT_MAKEFILE (.cpp.obj): Likewise.\n\n* alloc.c (GC_add_current_malloc_heap, GC_build_back_graph,\nGC_traverse_back_graph): Move prototype to gc_priv.h.\n* checksums.c (GC_page_was_ever_dirty): Likewise.\n* dbg_mlc.c (GC_default_print_heap_obj_proc): Likewise.\n* dyn_load.c (GC_parse_map_entry, GC_get_maps,\nGC_segment_is_thread_stack, GC_roots_present, GC_is_heap_base,\nGC_get_next_stack): Likewise.\n* finalize.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested): Likewise.\n* gcj_mlc.c (GC_start_debugging, GC_store_debug_info): Likewise.\n* malloc.c (GC_extend_size_map, GC_text_mapping): Likewise.\n* mark_rts.c (GC_mark_thread_local_free_lists): Likewise.\n* misc.c (GC_register_main_static_data, GC_init_win32,\nGC_setpagesize, GC_init_linux_data_start,\nGC_set_and_save_fault_handler, GC_init_dyld, GC_init_netbsd_elf,\nGC_initialize_offsets, GC_bl_init, GC_do_blocking_inner,\nGC_bl_init_no_interiors): Likewise.\n* os_dep.c (GC_greatest_stack_base_below, GC_push_all_stacks):\nLikewise.\n* reclaim.c (GC_check_leaked): Likewise.\n* win32_threads.c (GC_gww_dirty_init): Likewise.\n* darwin_stop_world.c (GC_is_mach_marker, GC_mprotect_stop,\nGC_mprotect_resume): Move prototype to darwin_stop_world.h.\n* pthread_support.c (GC_FindTopOfStack): Likewise.\n* dyn_load.c (GC_cond_add_roots): Merge adjacent definitions.\n* mark.c (GC_page_was_ever_dirty): Remove (as already declared).\n* mark_rts.c (GC_roots_present): Change return type to void\npointer (to match the prototype); return NULL instead of FALSE.\n* mark_rts.c (GC_add_roots_inner): Cast GC_roots_present() result.\n* os_dep.c (NEED_PROC_MAPS): Move definition to gcconfig.h.\n* os_dep.c (GC_write_fault_handler): Make STATIC.\n* os_dep.c (GC_set_write_fault_handler): New function (only if\nGC_WIN32_THREADS).\n* pthread_start.c (GC_start_rtn_prepare_thread,\nGC_thread_exit_proc): Move prototype to pthread_support.h.\n* pthread_support.c (GC_nacl_initialize_gc_thread,\nGC_nacl_shutdown_gc_thread, GC_unblock_gc_signals):\nLikewise.\n* pthread_support.c (GC_stop_init): Move prototype to\npthread_stop_world.h.\n* win32_threads.c (GC_write_fault_handler): Remove prototype.\n* win32_threads.c (GC_register_my_thread_inner): Call\nGC_set_write_fault_handler instead of SetUnhandledExceptionFilter\n(only if MPROTECT_VDB).\n* doc/README.win32: Add information about DMC.\n* include/private/gc_priv.h (GC_set_write_fault_handler): New\nprototype (only if GC_WIN32_THREADS and MPROTECT_VDB).\n\n* misc.c (vsnprintf): Redirect to vsprintf() if NO_VSNPRINTF.\n\n* win32_threads.c (GC_unregister_my_thread): Use KNOWN_FINISHED()\ninstead of FINISHED macro.\n* tests/test.c (check_heap_stats): Round up max_heap_sz value for\nWin32 (same as for USE_MMAP).\n\n* tests/test.c (check_heap_stats): Adjust printf format specifier\nfor max_heap_sz; cast max_heap_sz accordingly.\n\n* doc/README.solaris2: Add note.\n\n* configure.ac (SOLARIS25_PROC_VDB_BUG_FIXED): Don't define for\nSolaris/x86 2.10+.\n\n* tests/threadkey_test.c (SKIP_THREADKEY_TEST): Skip the test if\ndefined; explicitly define for some targets.\n\n* mark.c (GC_dirty): Add prototype (only if MANUAL_VDB).\n* stubborn.c (GC_dirty): Likewise.\n* include/private/gcconfig.h (GWW_VDB, MPROTECT_VDB, PCR_VDB,\nPROC_VDB): Undefine if MANUAL_VDB.\n* include/private/gcconfig.h (DEFAULT_VDB): Don't define if\nMANUAL_VDB.\n* os_dep.c (async_set_pht_entry_from_index): Define for\nMANUAL_VDB.\n* os_dep.c (GC_read_dirty): Set GC_dirty_maintained only if\nsuccess; if ioctl() failed then just print warning instead of\naborting.\n\n* include/private/gc_priv.h (GC_ASSERT): Use \"%d\" (instead of %ld)\nfor line number printing.\n\n* os_dep.c (GC_read_dirty): Add debug logging if DEBUG_DIRTY_BITS\n(for PROC_VDB only); print errors via GC_err_printf; rename \"ps\"\nand \"np\" local variables to npages and pagesize, respectively;\nremove \"current_addr\" local variable.\n\n* os_dep.c (GC_get_main_stack_base): Convert to GC_get_stack_base\nfor BeOS and OS/2; define HAVE_GET_STACK_BASE.\n* os_dep.c (GET_MAIN_STACKBASE_SPECIAL): Define when a specific\nGC_get_main_stack_base implementation is defined.\n* os_dep.c (GC_get_main_stack_base): Define that based on\nGC_get_stack_base() in a single place (only if\nGET_MAIN_STACKBASE_SPECIAL is unset); check GC_get_stack_base()\nresult.\n\n* mark.c (GC_push_selected): Remove \"push_fn\" argument (use\nGC_push_all directly); update the documentation.\n* mark.c (GC_push_conditional): Simplify the code (for better\nreadability).\n\n* mark.c (alloc_mark_stack): Use FALSE/TRUE (instead of 0/1) for\nboolean local variables.\n* doc/README.macros (GC_PREFER_MPROTECT_VDB): Update.\n* os_dep.c (GC_page_was_dirty, GC_page_was_ever_dirty,\nGC_remove_protection): Define for GWW_VDB and PROC_VDB in a single\nplace.\n* os_dep.c (GC_page_was_dirty, GC_page_was_ever_dirty): Compute\nPHT_HASH(h) only once (store result to a local variable).\n\n* doc/README.solaris2: Update.\n\n* include/private/gcconfig.h (end, InitStackBottom): Declare\nextern variable for RTEMS.\n* include/private/gcconfig.h (DATASTART, DATAEND, STACKBOTTOM):\nUpdate (for RTEMS).\n* include/private/gcconfig.h (DATAEND): Fix a typo in the macro\nname (for RTEMS).\n* tests/test.c (CONFIGURE_APPLICATION_DOES_NOT_NEED_CLOCK_DRIVER):\nReplace with CONFIGURE_APPLICATION_NEEDS_CLOCK_DRIVER (for RTEMS).\n\n* include/private/gcconfig.h (MPROTECT_VDB): Enable for Solaris in\nsingle-threaded environment.\n\n* include/private/gcconfig.h (MPROTECT_VDB): Undefine if PROC_VDB.\n* tests/test.c (NUMBER_ROUND_UP): New macro.\n* tests/test.c (check_heap_stats): Round up total expected heap\nsize to the nearest 4 MiB bound.\n* tests/test.c (check_heap_stats): Print the current and expected\nheap sizes in case of failure.\n\n* checksums.c (GC_check_blocks, GC_check_dirty): Do log printing\nonly if GC_print_stats; print errors using GC_err_printf.\n* checksums.c (GC_check_blocks): Join adjacent printf() calls into\na single one.\n\n* pthread_support.c (pthread_join): Add assertion (check thread is\nfinished).\n* pthread_support.c (GC_register_my_thread): Don't detach the\nthread if invoked from the thread destructor.\n* win32_threads.c (GC_register_my_thread): Likewise.\n* win32_threads.c (GC_unregister_my_thread): Don't delete the\nthread (just set FINISHED) if the thread is not detached (only if\nGC_PTHREADS); add assertion (check the thread is not finished).\n* tests/threadkey_test.c (main): Join some created threads.\n\n* pthread_support.c (GC_delete_gc_thread): Rename \"gc_id\" local\nvariable to \"t\".\n* win32_threads.c (GC_delete_gc_thread): Likewise.\n* pthread_support.c (pthread_join, pthread_detach,\npthread_cancel): Rename \"thread_gc_id\" local variable to \"t\".\n* win32_threads.c (GC_pthread_detach): Likewise.\n* win32_threads.c (GC_delete_gc_thread): Remove \"gc_nvid\" local\nvariable.\n* win32_threads.c (GC_pthread_join): Rename \"joinee\" local\nvariable to \"t\".\n\n* pthread_stop_world.c (pthread_sigmask): Undefine even if not\nDEBUG_THREADS.\n* pthread_stop_world.c (GC_unblock_gc_signals): New function (only\nif GC_EXPLICIT_SIGNALS_UNBLOCK).\n* pthread_support.c (GC_unblock_gc_signals): New prototype.\n* pthread_support.c (GC_register_my_thread_inner,\nGC_register_my_thread): Call GC_unblock_gc_signals (only if\nGC_EXPLICIT_SIGNALS_UNBLOCK); add comment.\n* include/private/gcconfig.h (GC_EXPLICIT_SIGNALS_UNBLOCK): New\nmacro.\n\n* pthread_stop_world.c (GC_suspend_handler_inner): Remove \"dummy\",\n\"sig\" local variables; rename my_thread local variable to \"self\".\n\n* tests/threadkey_test.c (LIMIT): Use smaller value (don't create\nmore than 30 in parallel by default).\n\n* tests/threadkey_test.c (key_once, main): Work around for Solaris\nPTHREAD_ONCE_INIT.\n* tests/threadkey_test.c (LIMIT): Use smaller value for Solaris.\n\n* dyn_load.c (GC_FirstDLOpenedLinkMap): Remove unused \"r\" local\nvariable.\n* pthread_support.c (GC_unregister_my_thread_inner): Revert back\nGC_remove_specific invocation; add a comment.\n* include/private/thread_local_alloc.h (GC_remove_specific):\nRevert back.\n* specific.c (slow_getspecific): Cast qtid to AO_t.\n* include/private/specific.h (key_create, setspecific,\nremove_specific): Remove \"extern\" keyword.\n* include/private/specific.h (getspecific): Change type of \"qtid\"\nlocal variable to unsigned long.\n\n* pthread_support.c (GC_check_tls): Fix \"#endif\" comment.\n* include/gc.h (GC_REDIRECT_TO_LOCAL): Remove deprecated comment.\n* include/private/thread_local_alloc.h (THREAD_LOCAL_ALLOC):\nRemove redundant test of the macro.\n\n* backgraph.c (add_edge): Recognize DEBUG_PRINT_BIG_N_EDGES macro.\n* os_dep.c (GC_set_and_save_fault_handler): Recognize\nSIGACTION_FLAGS_NODEFER_HACK macro.\n* pthread_support.c (mark_mutex): Recognize GLIBC_2_1_MUTEX_HACK\nmacro.\n* pthread_support.c (GC_acquire_mark_lock): Remove commented out\ncode.\n* include/private/gc_priv.h (SUNOS5SIGS): Don't include\nsys/siginfo.h on Linux.\n* include/private/gcconfig.h (FORCE_WRITE_PREFETCH): New macro\nrecognized, force PREFETCH_FOR_WRITE to be defined on x86.\n* include/private/gcconfig.h (USE_HPUX_FIXED_STACKBOTTOM): New\nmacro recognized (for HP/UX).\n\n* os_dep.c (GC_gww_page_was_ever_dirty): Fix comment (for\nGWW_VDB).\n* os_dep.c (GC_dirty_init): Use memset() for GC_written_pages\nresetting (for PROC_VDB).\n\n* tests/threadkey_test.c: New file.\n* tests/tests.am (TESTS, check_PROGRAMS): Add 'threadkey_test'.\n* tests/tests.am (threadkey_test_SOURCES, threadkey_test_LDADD):\nNew variable.\n\n* pthread_support.c (GC_unregister_my_thread_inner): Don't call\nGC_remove_specific.\n* include/private/thread_local_alloc.h (GC_remove_specific):\nRemove (since it is empty for all targets).\n* pthread_support.c (GC_record_stack_base): New inline function.\n* win32_threads.c (GC_record_stack_base): Likewise.\n* pthread_support.c (GC_register_my_thread_inner): Invoke\nGC_record_stack_base.\n* win32_threads.c (GC_register_my_thread_inner): Likewise.\n* pthread_support.c (GC_register_my_thread): If thread is FINISHED\nthen call GC_record_stack_base, clear FINISHED, initialize\nthread-local list and return success.\n* win32_threads.c (GC_register_my_thread): Likewise.\n* include/gc.h (GC_register_my_thread): Update documentation.\n* include/private/thread_local_alloc.h (GC_thread_key): Likewise.\n\n* thread_local_alloc.c (GC_malloc, GC_malloc_atomic): Join\nadjacent \"#ifdef\".\n* thread_local_alloc.c (GC_malloc_atomic): Call\nGC_core_malloc_atomic (instead of GC_core_malloc).\n\n* pthread_start.c (GC_start_rtn_prepare_thread): Change return\ntype to GC_thread.\n* pthread_start.c (GC_inner_start_routine): Pass the current\nthread descriptor to pthread_cleanup_push (same as in\nwin32_threads.c).\n* pthread_stop_world.c (GC_push_all_stacks): Rename \"me\" local\nvariable to \"self\".\n* win32_threads.c (GC_push_all_stacks): Likewise.\n* pthread_stop_world.c (GC_suspend_all, GC_start_world): Rename\n\"my_thread\" local variable to \"self\".\n* pthread_support.c (GC_unregister_my_thread_inner): New static\nfunction.\n* pthread_support.c (GC_unregister_my_thread,\nGC_thread_exit_proc): Use GC_unregister_my_thread_inner.\n* win32_threads.c (GC_register_my_thread, GC_unregister_my_thread,\nGC_do_blocking_inner): Rename \"t\" local variable to \"thread_id\".\n* win32_threads.c (GC_wait_marker, GC_notify_all_marker): Rename\n\"id\" local variable to \"thread_id\".\n\n* pthread_support.c (GC_unregister_my_thread): Call pthread_self\nonly once.\n* win32_threads.c (GC_pthread_start_inner): Likewise.\n* pthread_support.c (GC_unregister_my_thread): Add debug output.\n* win32_threads.c (GC_unregister_my_thread): Likewise.\n* pthread_support.c (GC_register_my_thread,\nGC_start_rtn_prepare_thread): Rename \"my_pthread\" local variable\nto \"self\".\n\n* include/gc.h (GC_HIDE_POINTER, GC_REVEAL_POINTER): Define\nunconditionally (do not test GC_I_HIDE_POINTERS); update the\ncomment.\n* include/gc.h (HIDE_POINTER, REVEAL_POINTER): Define as alias to\nGC_HIDE/REVEAL_POINTER, respectively.\n* include/private/gc_pmark.h (GC_I_HIDE_POINTERS): Do not define.\n* include/private/gc_priv.h (GC_I_HIDE_POINTERS): Likewise.\n\n* include/gc.h (GC_register_my_thread): Refine the comment.\n\n* include/gc_inline.h (GC_MALLOC_WORDS, GC_CONS): Add missing\nparentheses.\n* include/gc_typed.h (GC_get_bit, GC_set_bit,\nGC_CALLOC_EXPLICITLY_TYPED): Likewise.\n\n* include/private/gcconfig.h (NO_GETCONTEXT): Add missing ')'.\n\n* include/private/gcconfig.h (NO_GETCONTEXT): Do not use\ngetcontext(2) on m68k because it is not implemented there.\n\n* alloc.c (GC_clear_a_few_frames): Use BZERO().\n* mark_rts.c (GC_clear_roots, GC_rebuild_root_index): Likewise.\n* reclaim.c (GC_start_reclaim): Likewise.\n* blacklst.c (total_stack_black_listed): Remove \"len\" local\nvariable.\n* dbg_mlc.c (GC_generate_random_valid_address): Replace \"for\"\nstatement with \"do-while\" one.\n* dyn_load.c (GC_register_dynamic_libraries,\nGC_register_dynlib_callback): Remove redundant parentheses.\n\n* cord/cordxtra.c (CORD_from_file_lazy_inner): Suppress\n\"unused result\" compiler warning for fread().\n\n* os_dep.c (GC_write_fault_handler): Break when in_allocd_block\nis set to true.\n\n* dbg_mlc.c (GC_has_other_debug_info): Change return type to int;\nreturn -1 if the object has (or had) debugging info but was\nmarked deallocated.\n* include/private/dbg_mlc.h (GC_has_other_debug_info): Likewise.\n* dbg_mlc.c (GC_has_other_debug_info): Update documentation;\nremove \"ohdr\" local variable.\n* dbg_mlc.c (GC_debug_free): Don't call GC_free if the object has\nprobably been deallocated.\n* dbg_mlc.c (GC_debug_free): Don't actually free the object even\nin the leak-finding mode if GC_findleak_delay_free.\n* dbg_mlc.c (GC_check_leaked): New function (only unless\nSHORT_DBG_HDRS).\n* doc/README.environment (GC_FINDLEAK_DELAY_FREE): Document.\n* doc/README.macros (GC_FINDLEAK_DELAY_FREE): Likewise.\n* include/private/dbg_mlc.h (START_FLAG, END_FLAG): Use GC_WORD_C\non 64-bit architectures.\n* include/private/dbg_mlc.h (NOT_MARKED): Remove redundant\nparentheses.\n* include/private/dbg_mlc.h (GC_HAS_DEBUG_INFO): Update (due to\nGC_has_other_debug_info change).\n* include/private/gc_priv.h (GC_findleak_delay_free): New global\nvariable declaration (unless SHORT_DBG_HDRS).\n* misc.c (GC_findleak_delay_free): New global variable; recognize\nGC_FINDLEAK_DELAY_FREE.\n* misc.c (GC_init): Recognize GC_FINDLEAK_DELAY_FREE environment\nvariable (unless SHORT_DBG_HDRS).\n* reclaim.c (GC_check_leaked): Declare (unless SHORT_DBG_HDRS).\n* reclaim.c (GC_add_leaked): Don't add the object to leaked list\nif marked as deallocated.\n\n* dbg_mlc.c (GC_has_other_debug_info): Fix punctuation in the\ncomment.\n* dbg_mlc.c (GC_FREED_MEM_MARKER): New macro.\n* dbg_mlc.c (GC_debug_free): Use GC_FREED_MEM_MARKER.\n* dbg_mlc.c (GC_smashed): Refine documentation.\n* mark.c (GC_push_selected): Change dirty_fn return type to\nGC_bool.\n* os_dep.c (GC_page_was_ever_dirty): Make GC_INNER.\n* reclaim.c (GC_reclaim_small_nonempty_block): Remove \"kind\"\nlocal  variable.\n* reclaim.c (GC_reclaim_block): Pass true constant to\nGC_reclaim_small_nonempty_block (instead of report_if_found).\n* doc/README.autoconf: Update; fix a typo.\n* include/private/gcconfig.h (GC_WORD_C): New macro.\n\n* dbg_mlc.c (GC_store_debug_info_inner): Cast \"linenum\".\n* dbg_mlc.c (GC_check_annotated_obj): Fix punctuation in the\ncomment.\n* dbg_mlc.c (GC_print_smashed_obj): Add (and print) \"msg\"\nargument.\n* dbg_mlc.c (GC_debug_free, GC_print_all_smashed_proc): Pass\nmessage to GC_print_smashed_obj.\n* dbg_mlc.c (GC_debug_free): Call GC_size once.\n* dbg_mlc.c (GC_debug_realloc): Calculate old_sz only if\nallocation succeeded; remove unnecessary check for object is\nsmashed (since this is done in GC_debug_free); remove \"clobbered\"\nlocal variable.\n\n* dbg_mlc.c (GC_store_debug_info_inner, GC_store_debug_info):\nRename \"integer\" argument to \"linenum\"; change the type of the\nargument to int.\n* gcj_mlc.c (GC_store_debug_info): Likewise.\n* dbg_mlc.c (GET_OH_LINENUM): New macro.\n* dbg_mlc.c (GC_print_obj, GC_print_smashed_obj): Use\nGET_OH_LINENUM; adjust print format specifier.\n* dbg_mlc.c (GC_debug_malloc, GC_debug_malloc_ignore_off_page,\nGC_debug_malloc_atomic_ignore_off_page,\nGC_debug_generic_malloc_inner,\nGC_debug_generic_malloc_inner_ignore_off_page,\nGC_debug_malloc_stubborn, GC_debug_malloc_atomic,\nGC_debug_malloc_uncollectable,\nGC_debug_malloc_atomic_uncollectable): Remove unnecessary cast of\n\"i\".\n* gcj_mlc.c (GC_debug_gcj_malloc): Likewise.\n\n* os_dep.c (GC_linux_stack_base): Rename to\nGC_linux_main_stack_base.\n* os_dep.c (GC_freebsd_stack_base): Rename to\nGC_freebsd_main_stack_base; adjust error message.\n* pthread_stop_world.c (GC_stop_init): Use GC_SEM_INIT_PSHARED\nas an argument for sem_init().\n* pthread_support.c (pthread_create): Likewise.\n* pthread_support.c (pthread_create): Abort in case sem_init()\nfails.\n* include/private/gc_priv.h (GC_SEM_INIT_PSHARED): Define.\n* tests/initsecondarythread.c: Include gcconfig.h; call GC_INIT\nfrom main() if it should be done from the primordial thread only.\n\n* alloc.c: Don't include sys/types.h for ArmCC.\n* dyn_load.c: Likewise.\n* os_dep.c: Likewise.\n* mach_dep.c (_setjmp, _longjmp): Redirect to setjmp/longjmp for\nArmCC.\n* mark.c (GC_noop): Define specially for ArmCC.\n* include/private/gc_priv.h (GC_noop): Likewise.\n* misc.c (GC_init): Don't test pointers comparison for ArmCC.\n* misc.c: Don't include unistd.h for ArmCC.\n* os_dep.c (pages_executable): Rename to GC_pages_executable;\nmake STATIC.\n* os_dep.c (GC_unix_mmap_get_mem): Don't define for ArmCC.\n* ptr_chck.c (GC_is_visible): Explicitly cast\n(GC_DS_PER_OBJECT-GC_INDIR_PER_OBJ_BIAS) to word (to suppress\na compiler warning).\n* include/private/gcconfig.h: Recognize __arm.\n* include/private/gcconfig.h (HBLKPTR): Define for ArmCC.\n* include/private/gcconfig.h (HBLKPTR): Add parentheses for\n\"bytes\" argument.\n\n* pthread_support.c (GC_get_nprocs): Don't define for Android.\n* pthread_support.c (GC_dummy_thread_local): Don't test\nGC_LINUX_THREADS.\n* include/gc_config_macros.h (GC_ADD_CALLER, GC_RETURN_ADDR):\nDefine for Android.\n\n* mach_dep.c (NO_GETCONTEXT): Move to gcconfig.h.\n* os_dep.c (GC_write_fault_handler): Don't include ucontext.h if\nNO_GETCONTEXT.\n* include/private/gcconfig.h (GETPAGESIZE): Define as a sysconf\ncall for Android.\n\n* include/private/gc_locks.h (WIN32_LEAN_AND_MEAN, NOSERVICE):\nDefine before including windows.h.\n* include/private/gc_priv.h (WIN32_LEAN_AND_MEAN, NOSERVICE):\nLikewise.\n* include/private/thread_local_alloc.h (WIN32_LEAN_AND_MEAN,\nNOSERVICE): Likewise.\n* include/private/gc_priv.h (MS_TIME_DIFF): Avoid floating-point\narithmetics; add a comment.\n\n* mark.c (GC_clear_hdr_marks): Don't test USE_MARK_BYTES.\n* extra/setjmp_t.c (main): Don't test USE_MARK_BITS.\n* include/private/gc_pmark.h (SET_MARK_BIT_EXIT_IF_SET): Likewise.\n* include/private/gc_pmark.h (SET_MARK_BIT_EXIT_IF_SET): Remove\n\"mark_byte\" local variable.\n* include/private/gc_pmark.h (OR_WORD_EXIT_IF_SET): Add a comment\nabout that AO_or() is not used by GC unless USE_MARK_BITS\nexplicitly set.\n* include/private/gc_priv.h (OR_WORD): Likewise.\n* include/private/gc_pmark.h (INCR_MARKS): Remove trailing ';',\nadd parentheses.\n* include/private/gc_priv.h (ONES): Define before use by\nMAKE_COOLER.\n* include/private/gc_priv.h (MARK_BITS_SZ): Define where used.\n* include/private/gc_priv.h (OR_WORD): Don't define if\nUSE_MARK_BYTES.\n* include/private/gcconfig.h (USE_MARK_BYTES); Remove duplicate\ndefinition; simplify expression.\n\n* os_dep.c (GC_get_maps): Always close the file.\n* pthread_support.c (GC_get_nprocs): Likewise.\n* os_dep.c (READ): Define similarly across the file (without\nparameters).\n* pthread_support.c (GC_get_nprocs): Use signed int type for \"i\"\nand \"len\" local variables (since read() may return -1).\n* include/private/gc_pmark.h (LONG_MULT): Add prefix/suffix\ndouble underscore; add \"volatile\" for asm.\n* include/private/gc_pmark.h (LONG_MULT): Add missing\nparentheses.\n* include/private/gc_priv.h (OR_WORD): Likewise.\n* include/private/gc_priv.h (OR_WORD): Remove unnecessary brackets\nand ';' symbol.\n\n* os_dep.c (GC_get_stack_base): Implement for Android (same as\nfor Linux).\n* pthread_support.c (GC_get_nprocs): Return 1 (instead of -1) if\nfailed to open \"stat\" file (not to issue a warning twice); update\nthe comment.\n* pthread_support.c (GC_thr_init): Call sysconf() on Android to\nget the number of CPUs.\n\n* include/private/gc_priv.h (_GNU_SOURCE): Revert one of the\nrecent patches regarding this macro as the macro should be set\n(to 1) before including any other system header.\n\n* doc/README.environment (GC_INITIAL_HEAP_SIZE,\nGC_MAXIMUM_HEAP_SIZE): Update.\n\n* misc.c (GC_parse_mem_size_arg): Allow 'k', 'M', 'G' suffixes in\nheap size specifier; return 0 if not a valid one.\n* include/gc_cpp.h: Explicitly define inline one-argument delete\noperator for Cygwin (as a workaround).\n* tests/test_cpp.cc (main): Suppress compiler warnings about\n\"assigned value is unused\".\n\n* misc.c (GC_parse_mem_size_arg): New function.\n* misc.c (GC_init): Use GC_parse_mem_size_arg().\n* pthread_stop_world.c (tkill): Declare for Android.\n\n* include/private/gc_priv.h (_GNU_SOURCE): Include features.h\nfirst (except for NaCl) and then define the macro to 1 if not yet.\n\n* tests/tests.am (TESTS, check_PROGRAMS): Add\n'initsecondarythread'.\n* tests/tests.am (initsecondarythread_SOURCES,\ninitsecondarythread_LDADD): New variable.\n\n* dbg_mlc.c (GC_store_debug_info_inner): Always define; add\n\"const\" to its string argument.\n* dbg_mlc.c (GC_store_debug_info): Call GC_store_debug_info_inner.\n* dbg_mlc.c (GC_debug_free): Set GC_have_errors in case of\nsmashed or previously deallocated found.\n* dbg_mlc.c (GC_check_heap_block): Replace while loop with a for\none.\n* reclaim.c (GC_reclaim_check): Likewise.\n* dbg_mlc.c (GC_check_heap_proc): Remove redundant cast to word.\n* os_dep.c (GC_get_stack_base): Don't initialize\nstackbase_main_self/ss_sp on Solaris if thr_main() is zero (thus\ncalling GC_INIT() from a non-primordial thread is possible now).\n* reclaim.c (GC_add_leaked): Turn into an inline one.\n* reclaim.c (GC_reclaim_small_nonempty_block):\nChange report_if_found type from int/word to boolean.\n* include/private/gc_priv.h (GC_start_reclaim): Likewise.\n* include/private/gc_priv.h (set_mark_bit_from_hdr,\nclear_mark_bit_from_hdr): Place closing parenthesis properly.\n\n* os_dep.c (GC_get_main_stack_base): Try to use\npthread_attr_getstack first for Linux if THREADS.\n* doc/README.macros (USE_GET_STACKBASE_FOR_MAIN): Adjust text\nalignment.\n\n* dbg_mlc.c (GC_generate_random_backtrace_no_gc): Fix a message\ntypo.\n* dbg_mlc.c (GC_debug_malloc): Add a comment (about zero size).\n* dbg_mlc.c (GC_strdup): Call GC_err_printf instead of WARN (in\ncase of NULL argument).\n* dbg_mlc.c (GC_free): In case of NULL argument, just return\n(without any warning printed); eliminate \"uncollectable\" local\nvariable.\n\n* configure.ac (THREADDLLIBS): Use alternate thread library on\nSolaris 8.\n* configure.ac (need_atomic_ops_asm): Set to true only for SPARC\nSolaris.\n* configure.ac: Don't use libdl on mips-sgi-irix6.\n\n* mach_dep.c (NO_GETCONTEXT); Define for RTEMS.\n* mach_dep.c (GC_with_callee_saves_pushed): Don't call\n__builtin_unwind_init() for RTEMS; use setjmp() without the\nleading underscore (for RTEMS).\n* tests/test.c (BIG): Use smaller value for RTEMS.\n* tests/test.c (main): Customize for RTEMS.\n\n* configure.host: Remove doubled words in comments.\n* os_dep.c: Likewise.\n* doc/README: Likewise.\n* extra/setjmp_t.c: Likewise.\n* tests/huge_test.c: Likewise.\n* extra/setjmp_t.c (getpagesize, nested_sp, main, g): Replace the\nK&R-style function definition with the ANSI C one.\n* extra/setjmp_t.c (nested_sp): Implement in the same way as\nGC_approx_sp.\n\n* dyn_load.c (GC_dyld_sections): Add more sections.\n* dyn_load.c (GC_dyld_add_sect_fmts): New static variable.\n* dyn_load.c (L2_MAX_OFILE_ALIGNMENT): New macro.\n* dyn_load.c (GC_dyld_image_add, GC_dyld_image_remove): Improve\nlogging; add support for on-demand sections.\n\n* gcj_mlc.c (GC_gcj_malloc_initialized): Use STATIC unless\nGC_ASSERTIONS.\n* include/private/gc_priv.h (GC_gcj_malloc_initialized): Don't\ndeclare (as external) unless GC_ASSERTIONS.\n* os_dep.c (GC_win32_free_heap): Clear GC_heap_bases[] also for\nCygwin; add FIXME.\n* include/private/gcconfig.h: Include <sys/unistd.h> for RTEMS.\n* include/private/gcconfig.h: Add \"#error\" for every \"-->\" mark.\n* include/private/gcconfig.h (CLEAR_DOUBLE): Turn the code into\nan expression.\n* include/private/pthread_support.h (SUSPENDED_EXT): Add new flag\n(which existed previously as SUSPENDED and still exists in GCJ).\n* include/private/pthread_support.h (DISABLED_GC): Change the\nvalue (as it is already used by SUSPENDED_EXT).\n\n* tests/test.c (reverse_test):  Modify count (BIG) for\nppc64-darwin.\n\n* reclaim.c (GC_print_all_errors): Recognize new GC_ABORT_ON_LEAK\nmacro and environment variable; abort if any error has been\nprinted provided the environment variable (or macro) is set.\n* doc/README.environment (GC_ABORT_ON_LEAK): Document.\n* doc/README.macros (GC_ABORT_ON_LEAK): Likewise.\n\n* os_dep.c (GC_unix_sbrk_get_mem, GC_unix_get_mem): Don't define\nfor RTEMS.\n* include/private/gcconfig.h (RTEMS): Add support for.\n* include/private/gcconfig.h (GET_MEM): Use calloc() for RTEMS.\n\n* mallocx.c (GC_malloc_uncollectable): Move to malloc.c (since\nit is used internally in some places).\n\n* dbg_mlc.c (GC_register_finalizer_no_order): Remove redundant\ndeclaration.\n* dbg_mlc.c (GC_debug_malloc_replacement,\nGC_debug_realloc_replacement): Rename RA to GC_DBG_RA.\n* malloc.c (GC_debug_malloc_replacement): Likewise.\n* mallocx.c (GC_debug_realloc_replacement): Likewise.\n* dbg_mlc.c (GC_store_debug_info): Move proto from dbg_mlc.h.\n* malloc.c (GC_strdup, GC_strndup, GC_wcsdup): Move to mallocx.c.\n* malloc.c: Include errno.h only REDIRECT_MALLOC; remove redundant\nincludes of string.h.\n* mallocx.c: Include string.h (for GC_strdup).\n* include/private/dbg_mlc.h (GC_store_debug_info): Move declaration\nto dbg_mlc.c.\n* include/private/gc_locks.h (UNCOND_LOCK, UNCOND_UNLOCK): Remove\nredundant trailing ';'.\n* include/private/gc_priv.h (START_WORLD, COND_DUMP): Likewise.\n* include/private/gc_locks.h (LOCK, UNLOCK): Place opening '{'\nproperly.\n* include/private/gc_priv.h (GC_DBG_RA): Move from dbg_mlc.c,\nmalloc.c, mallocx.c.\n\n* alloc.c (GC_check_heap, GC_print_all_smashed): Move the\ndefinition from misc.c.\n* dbg_mlc.c (GC_debug_malloc_atomic_uncollectable): Define as\npublic.\n* include/gc.h (GC_debug_malloc_atomic_uncollectable): Declare.\n* include/gc.h (GC_MALLOC_ATOMIC_UNCOLLECTABLE): Define new public\nmacro.\n* dbg_mlc.c (MAX_SMASHED): Don't define if already set.\n* reclaim.c (MAX_LEAKED): Likewise.\n* dbg_mlc.c (GC_add_smashed): Add FIXME about the concurrent\naccess to the global array.\n* reclaim.c (GC_add_leaked): Likewise.\n* misc.c (GC_print_back_height): Set on if GC_PRINT_BACK_HEIGHT\n(new macro) is defined.\n* doc/README.macros (GC_PRINT_BACK_HEIGHT): Document.\n* misc.c (GC_dump_regularly, GC_init): Replace 0/1 for\nGC_dump_regularly and GC_print_back_height variables with\nFALSE/TRUE.\n* reclaim.c (GC_print_all_errors): Refine the comment.\n\n* tests/test.c (reverse_test_inner): Undo one of the previous\npatches which shifts \"c\" and \"d\" pointers only if\nALL_INTERIOR_POINTERS (since interior pointers are always\nrecognized in stacks).\n\n* misc.c (GC_stdout, GC_stderr): Move the definition to the place\nwhere GC_log is defined (Unix only).\n* misc.c (GC_init): Recognize \"GC_ONLY_LOG_TO_FILE\" environment\nvariable and the similar macro; redirect GC_stdout and GC_stderr\nto GC_log if \"GC_LOG_FILE\" environment variable is set unless\nprohibited by GC_ONLY_LOG_TO_FILE (Unix only).\n* doc/README.environment (GC_ONLY_LOG_TO_FILE): Document.\n* doc/README.macros (GC_ONLY_LOG_TO_FILE): Likewise.\n\n* misc.c (GC_stdout, GC_write): Rename GC_stdout to GC_log (Win32\nonly).\n* misc.c (GC_write): Add for MacOS (and OS/2); change WRITE()\naccordingly.\n* misc.c (GC_printf): Check GC_quiet before va_start().\n\n* allchblk.c (GC_freehblk): Use GC_log_printf instead of GC_printf\ninside \"if (GC_print_stats)\" branch.\n* alloc.c (GC_collect_or_expand): Likewise.\n* dyn_load.c (GC_register_dynamic_libraries): Likewise.\n* headers.c (GC_scratch_alloc): Likewise.\n* os_dep.c (GC_get_maps, GC_remap, PROTECT,\nGC_write_fault_handler, GC_dirty_init, GC_mprotect_thread): Likewise.\n* alloc.c (min_bytes_allocd): Use GC_log_printf instead of\nGC_printf for DEBUG_THREADS output.\n* darwin_stop_world.c (GC_stack_range_for, GC_suspend_thread_list,\nGC_stop_world, GC_thread_resume, GC_start_world): Likewise.\n* pthread_start.c (GC_inner_start_routine): Likewise.\n* pthread_stop_world.c (GC_suspend_handler, GC_restart_handler,\nGC_push_all_stacks, GC_suspend_all, GC_stop_world,\nGC_start_world): Likewise.\n* pthread_support.c (GC_mark_thread, GC_get_nprocs,\nGC_start_rtn_prepare_thread, pthread_create): Likewise.\n* checksums.c (GC_update_check_page): Use GC_printf() instead of\nGC_err_printf() for error printing.\n* checksums.c (GC_check_blocks, GC_check_dirty): Use GC_log_printf\ninstead of GC_printf for logging purposes.\n* dyn_load.c (sys_errlist, sys_nerr, errno): Move declaration of\nexternal variable outside from GC_register_dynamic_libraries.\n* dyn_load.c (GC_register_dynamic_libraries): Don't use\nsys_errlist value if errno equals to sys_nerr.\n* dyn_load.c (GC_register_dynamic_libraries): Use GC_log_printf\ninstead of GC_printf for DL_VERBOSE output.\n* dyn_load.c (GC_dyld_image_add, GC_dyld_image_remove,\nGC_init_dyld): Use GC_log_printf instead of GC_printf for\nDARWIN_DEBUG output.\n* os_dep.c (catch_exception_raise): Use GC_log_printf\ninstead of GC_printf for DEBUG_EXCEPTION_HANDLING output.\n* reclaim.c (GC_print_free_list): Move \"n\" increment out of\nGC_printf() call.\n\n* win32_threads.c (DEBUG_CYGWIN_THREADS, DEBUG_WIN32_PTHREADS,\nDEBUG_WIN32_THREADS): Remove.\n* win32_threads.c (GC_register_my_thread_inner,\nGC_win32_start_inner): Use GC_log_printf instead of GC_printf\ninside \"if (GC_print_stats)\" branch.\n* win32_threads.c (GC_PTHREAD_PTRVAL): New macro (defined only if\nGC_PTHREADS).\n* win32_threads.c (GC_delete_gc_thread, NUMERIC_THREAD_ID,\nGC_pthread_join, GC_pthread_create): Use GC_PTHREAD_PTRVAL\nmacro.\n* win32_threads.c (GC_push_stack_for, GC_mark_thread,\nGC_CreateThread, GC_beginthreadex, GC_pthread_join,\nGC_pthread_create, GC_pthread_start_inner, GC_thread_exit_proc,\nGC_mark_thread_local_free_lists): Use GC_log_printf instead of\nGC_printf for DEBUG_THREADS output.\n* win32_threads.c (GC_win32_start_inner, GC_CreateThread,\nGC_beginthreadex, GC_pthread_join, GC_pthread_create,\nGC_pthread_start_inner, GC_thread_exit_proc): Cast\nGetCurrentThreadId result to long; don't cast value of pthread_t\ntype to int; adjust printf format specifiers.\n* doc/README.win32 (DEBUG_WIN32_PTHREADS): Remove obsolete\ninformation.\n\n* tests/test.c (cons, small_cons, gcj_cons, check_ints,\ncheck_uncollectable_ints, print_int_list, check_marks_int_list,\nfork_a_thread, finalizer, mktree, chktree, alloc8bytes,\nalloc_small, tree_test, typed_test, check_heap_stats, WinMain,\ntest, main): Remove unnecessary casts of GC_printf calls to void.\n\n* allchblk.c (GC_print_hblkfreelist): Adjust (make uniform across\nBDWGC) printed message (adjust letters case, terminating dot and\nnew line symbols).\n* alloc.c (GC_check_fl_marks): Likewise.\n* backgraph.c (new_back_edges): Likewise.\n* checksums.c (GC_check_dirty): Likewise.\n* darwin_stop_world.c (GC_push_all_stacks,\nGC_suspend_thread_list): Likewise.\n* dbg_mlc.c (GC_print_type, GC_debug_free, GC_debug_realloc,\nstore_old): Likewise.\n* dyn_load.c (GC_register_dynamic_libraries): Likewise.\n* mark.c (GC_initiate_gc, GC_mark_some, GC_mark_from, GC_push_all,\nGC_push_selected, GC_push_next_marked_dirty): Likewise.\n* mark_rts.c (GC_exclude_static_roots_inner): Likewise.\n* os_dep.c (GC_remap, GC_default_push_other_roots,\nGC_push_thread_structures, GC_dirty_init, GC_read_dirty,\ncatch_exception_raise_state, catch_exception_raise_state_identity,\nGC_mprotect_thread_notify, GC_mprotect_thread,\ncatch_exception_raise): Likewise.\n* pthread_stop_world.c (GC_print_sig_mask, GC_push_all_stacks,\nGC_stop_world, GC_stop_init): Likewise.\n* pthread_support.c (GC_thr_init, GC_register_my_thread_inner,\nGC_start_routine): Likewise.\n* win32_threads.c (GC_register_my_thread_inner,\nGC_push_all_stacks, GC_win32_start_inner, GC_pthread_join,\nGC_pthread_start_inner): Likewise.\n* alloc.c (GC_expand_hp_inner): Realign the code.\n* mark.c (GC_mark_from, GC_mark_local, GC_do_parallel_mark):\nLikewise.\n* misc.c (GC_init): Likewise.\n* os_dep.c (GC_dirty_init, GC_read_dirty): Likewise.\n* include/private/gc_pmark.h (PUSH_CONTENTS_HDR): Likewise.\n* tests/test.c (run_one_test): Likewise.\n* misc.c (GC_err_puts): Document.\n* misc.c (GC_err_write): Remove.\n* os_dep.c (dump_maps): Likewise.\n* include/private/gc_priv.h (GC_err_write): Likewise.\n* os_dep.c (GC_print_address_map): Call GC_err_puts() instead of\ndump_maps() and GC_err_write().\n* os_dep.c (GC_read_dirty): Remove redundant brackets.\n\n* tests/test.c (reverse_test_inner): Test interior pointer\nrecognition only if ALL_INTERIOR_POINTERS.\n* tests/test.c (run_one_test): Replace GC_all_interior_pointers\nwith GC_get_all_interior_pointers(); simplify the expression.\n* tests/test.c (check_heap_stats): Replace GC_bytes_allocd and\nGC_bytes_allocd_before_gc with GC_get_total_bytes().\n* tests/test.c (main): Replace GC_gc_no with GC_get_gc_no().\n\n* dbg_mlc.c (GC_debug_strdup, GC_debug_free): Output a portability\nwarning if the argument is NULL and GC is in leaks detection mode.\n* dbg_mlc.c (GC_debug_strndup, GC_debug_wcsdup): New public\nfunction definition.\n* malloc.c (GC_strndup, GC_wcsdup, strndup): Likewise.\n* mallocx.c (GC_posix_memalign): Likewise.\n* malloc.c (strdup): Fix string size value; rename \"len\" to \"lb\".\n* mallocx.c: Include errno.h unless WinCE (otherwise include\nwindows.h for Win32 error constants).\n* win32_threads.c: Define WIN32_LEAN_AND_MEAN and NOSERVICE before\nwindows.h inclusion.\n* misc.c (GC_init): Register at-exit callback if GC_find_leak\n(even if GC_FIND_LEAK macro is unset).\n* pthread_stop_world.c (NACL_STORE_REGS,\n__nacl_suspend_thread_if_needed, GC_nacl_initialize_gc_thread):\nUse BCOPY() instead of memcpy().\n* pthread_support.c (GC_init_real_syms): Likewise.\n* doc/README.macros (GC_DEBUG_REPLACEMENT, GC_REQUIRE_WCSDUP):\nDocument new macro.\n* doc/README.macros (REDIRECT_MALLOC): Update documentation.\n* include/gc.h (GC_strndup, GC_posix_memalign, GC_debug_strndup):\nNew API function prototype.\n* include/gc.h (GC_MALLOC, GC_REALLOC): Redirect to\nGC_debug_malloc/realloc_replacement() if GC_DEBUG_REPLACEMENT.\n* include/gc.h (GC_STRDUP): Remove redundant parentheses.\n* include/leak_detector.h (realloc, strdup): Likewise.\n* include/gc.h (GC_STRNDUP): New API macro.\n* include/gc.h (GC_NEW, GC_NEW_ATOMIC, GC_NEW_STUBBORN,\nGC_NEW_UNCOLLECTABLE): Add missing parentheses.\n* include/gc.h (GC_wcsdup, GC_debug_wcsdup): New API function\nprototype (only if GC_REQUIRE_WCSDUP).\n* include/gc.h (GC_WCSDUP): New API macro (only if\nGC_REQUIRE_WCSDUP).\n* include/leak_detector.h: Include stdlib.h and string.h after gc.h (unless\nGC_DONT_INCLUDE_STDLIB).\n* include/leak_detector.h (malloc, calloc, free, realloc):\nUndefine symbol before its redefinition.\n* include/leak_detector.h (strndup, memalign, posix_memalign):\nRedefine to the corresponding GC function.\n* include/leak_detector.h (wcsdup): Redefine to GC_WCSDUP (only\nif GC_REQUIRE_WCSDUP).\n* include/leak_detector.h (CHECK_LEAKS): Add comment; don't define\nthe macro if already defined.\n\n* misc.c (GC_abort): Use _exit() (instead of DebugBreak) on Win32\nwhen doing code static analysis (to inform the tool that the\nfunction is a no-return one).\n* os_dep.c (GC_linux_stack_base): Remove a duplicate validation\nof the length of \"stat\" file; use signed int type for \"i\",\n\"buf_offset\" and \"len\" local variables (since read() may\nreturn -1).\n\n* blacklst.c (GC_bl_init_no_interiors): New function (the code\nmoved from GC_bl_init).\n* blacklst.c (GC_bl_init): Invoke GC_bl_init_no_interiors unless\nGC_all_interior_pointers mode; remove unnecessarily parameter cast\nfor GC_scratch_alloc call.\n* include/private/gc_priv.h (GC_bl_init): Move the function\ndeclaration to misc.c file.\n* misc.c (GC_bl_init_no_interiors): Add a prototype.\n* misc.c (GC_set_all_interior_pointers): Allow values other than 0\nand 1; allow altering GC_set_all_interior_pointers value even\nafter GC initialization.\n* obj_map.c (GC_initialize_offsets): Clear GC_valid_offsets and\nGC_modws_valid_offsets if GC_all_interior_pointers is off.\n* misc.c (GC_init): Don't call GC_initialize_offsets() unless\nGC_all_interior_pointers mode.\n\n* alloc.c (GC_finish_collection): Remove redundant brackets;\nadjust code indentation.\n* blacklst.c (GC_add_to_black_list_normal): Simplify expression\n(to improve code readability).\n* blacklst.c (GC_is_black_listed): Join nested \"if\" (into a single\nconditional expression); initialize \"nblocks\" just before the loop\nbeginning.\n* misc.c (GC_init): Don't compute initial_heap_sz if GC is already\ninitialized.\n* include/private/gc_priv.h (GC_initialize_offsets): Move the\nfunction declaration to misc.c file.\n* obj_map.c (GC_initialize_offsets): Remove offsets_initialized\nstatic variable since the function is called only once.\n* tests/middle.c (main): Use setter for GC_all_interior_pointers;\nadjust printf format specifier (and cast the value passed to).\n\n* doc/README.macros (SMALL_CONFIG, LARGE_CONFIG): Refine the\ndocumentation.\n* include/private/gc_hdrs.h (LOG_BOTTOM_SZ): Ignore SMALL_CONFIG\nif LARGE_CONFIG is defined.\n* include/private/gc_priv.h (CPP_LOG_HBLKSIZE): Likewise.\n\n* alloc.c (GC_finish_collection): Replace \"#else #ifdef\" with\n\"#elif\".\n* include/private/gc_priv.h (CPP_LOG_HBLKSIZE, LOG_PHT_ENTRIES,\nMAX_ROOT_SETS, MAX_HEAP_SECTS): Likewise.\n* alloc.c (GC_expand_hp_inner): Check for GC_collect_at_heapsize\noverflow even if not LARGE_CONFIG.\n* dbg_mlc.c (GC_check_heap_proc): Check \"oh\" size even if\nSMALL_CONFIG.\n* finalize.c (GC_print_finalization_stats): Fix \"#endif\" comment.\n* doc/README.environment (GC_LOG_FILE, GC_PRINT_VERBOSE_STATS,\nGC_FULL_FREQUENCY): Refine the documentation.\n\n* extra/msvc_dbg.c: Test _MSC_VER macro; include \"gc.h\" (for\nGC_word).\n* extra/msvc_dbg.c (ULONG_PTR): Replace with GC_ULONG_PTR; define\nas word.\n\n* dbg_mlc.c (GC_get_back_ptr_info, GC_print_obj,\nGC_print_smashed_obj, GC_debug_free_inner): Add a code for a\nLINT-like tool to instruct it that the function is invoked only\nwith valid parameters (otherwise a SEGV is ok); recognize LINT2\nnew macro.\n* misc.c (GC_abort): Instruct a LINT-like tool that the function\nnever returns in fact.\n* os_dep.c (GC_linux_stack_base): Check for read buffer overflow;\nclose the file immediately after read; use STRTOULL() instead of\ndecoding the address number manually.\n* include/private/gc_priv.h (EXPECT): Don't specify outcome for a\nLINT-like tool.\n* include/private/gc_priv.h (GC_all_interior_pointers): Instruct a\nLINT-like tool that the value is restricted to zero and one only\n(required since the variable is global and its value is used as a\npart of array index expression is some places).\n\n* dbg_mlc.c (GC_make_closure): Fix SEGV in case GC_malloc returns\nNULL.\n* dbg_mlc.c (GC_debug_register_finalizer,\nGC_debug_register_finalizer_no_order,\nGC_debug_register_finalizer_unreachable,\nGC_debug_register_finalizer_ignore_self): Handle out of memory\ncase properly (similar to GC_register_finalizer_inner).\n* headers.c (GC_install_header): Handle the case when alloc_hdr()\nreturns NULL.\n* os_dep.c (GC_get_maps_len): Defend against missing \"maps\" file.\n* pthread_support.c (GC_mark_thread): Place a dummy return\nstatement (which uses \"id\" argument) before the actual use of \"id\"\nas an array index (to suppress a warning produced by some static\ncode analysis tools).\n* win32_threads.c (GC_mark_thread): Likewise.\n* pthread_support.c (GC_thr_init): Abort (with the appropriate\nmessage) if out of memory.\n\n* finalize.c (GC_register_finalizer_inner): Fix a typo in a\ncomment.\n*include/private/gcconfig.h (STACKBOTTOM): Likewise.\n* gcj_mlc.c (GC_core_gcj_malloc): Replace 0/1 with TRUE/FALSE in\nEXPECT (the 2nd argument).\n* malloc.c (GC_core_malloc_atomic, GC_core_malloc, GC_free):\nLikewise.\n* mark.c (GC_mark_and_push, GC_mark_and_push_stack): Likewise.\n* thread_local_alloc.c (GC_malloc, GC_malloc_atomic): Likewise.\n* include/private/gc_hdrs.h (HC_GET_HDR): Likewise.\n* include/private/gc_priv.h (SMALL_OBJ): Likewise.\n* include/private/specific.h (getspecific): Likewise.\n* pthread_support.c (LOCK_STATS): Add a comment.\n\n* include/gc_pthread_redirects.h (GC_NO_DLOPEN,\nGC_NO_PTHREAD_SIGMASK, GC_PTHREAD_CREATE_CONST,\nGC_PTHREAD_EXIT_ATTRIBUTE, GC_NO_PTHREAD_CANCEL): Move the\ndefinition to gc_config_macros.\n\n* pthread_support.c (pthread_cancel, GC_pthread_cancel_t,\nGC_pthread_cancel): Test GC_NO_PTHREAD_CANCEL (instead of NACL and\nGC_PTHREAD_EXIT_ATTRIBUTE).\n* include/gc_pthread_redirects.h (GC_pthread_cancel,\npthread_cancel): Likewise.\n* pthread_support.c (GC_pthread_create, GC_pthread_sigmask,\nGC_pthread_join, GC_pthread_detach, GC_pthread_cancel): Realign\ncode.\n* include/gc_pthread_redirects.h (GC_PTHREAD_EXIT_ATTRIBUTE):\nDefine as empty for NaCl.\n* include/gc_pthread_redirects.h (GC_NO_PTHREAD_CANCEL): New macro\ndefined.\n\n* dyn_load.c (GC_init_dyld): Do not invoke\n_dyld_bind_fully_image_containing_address() if GC_no_dls (as it is\nnot required to register the main data segment in that case).\n* include/gc.h (GC_no_dls): Adjust the comment.\n\n* dyn_load.c (GC_MUST_RESTORE_REDEFINED_DLOPEN): Test\nGC_NO_DLOPEN.\n* gc_dlopen.c: Likewise.\n* include/gc_pthread_redirects.h (GC_dlopen, dlopen): Likewise.\n* gc_dlopen.c: Don't include dlfcn.h (as it is included in\ngc_pthread_redirects.h).\n* pthread_support.c (pthread_sigmask, GC_pthread_sigmask_t,\nGC_pthread_sigmask): Test GC_NO_PTHREAD_SIGMASK (instead of\nGC_DARWIN_THREADS, GC_OPENBSD_THREADS and NACL).\n* include/gc_pthread_redirects.h (GC_pthread_sigmask,\npthread_sigmask): Likewise.\n* win32_threads.c (pthread_sigmask, GC_pthread_sigmask): Test\nGC_NO_PTHREAD_SIGMASK (instead of GC_WIN32_PTHREADS).\n* pthread_support.c (pthread_create, GC_pthread_create_t,\nGC_pthread_create): Rename GC_PTHREAD_CONST to\nGC_PTHREAD_CREATE_CONST.\n* win32_threads.c (GC_pthread_create): Likewise.\n* include/gc_pthread_redirects.h: Likewise.\n* include/gc_pthread_redirects.h (GC_NO_DLOPEN,\nGC_NO_PTHREAD_SIGMASK): New macro defined.\n* include/gc_pthread_redirects.h (GC_PTHREAD_CREATE_CONST): Set to\nempty for NaCl.\n* include/gc_pthread_redirects.h (GC_PTHREAD_EXIT_ATTRIBUTE): Do\nnot define for Android (as CANCEL_SAFE is not defined).\n\n* include/gc.h (GC_ADD_CALLER, GC_RETURN_ADDR,\nGC_HAVE_BUILTIN_BACKTRACE, GC_CAN_SAVE_CALL_STACKS): Move\ndefinition to gc_config_macros.h file.\n* include/gc_config_macros.h: Check the file is included from gc.h\nfile.\n* include/gc_version.h: Likewise.\n\n* gc_dlopen.c: Empty unit for NaCl.\n* os_dep.c: Include fcntl.h for NaCl.\n* os_dep.c (GC_get_main_stack_base): Ignore\nUSE_GET_STACKBASE_FOR_MAIN macro for NaCl.\n* os_dep.c (GC_get_stack_base): Return GC_UNIMPLEMENTED for NaCl.\n* os_dep.c (GC_remap): Use mmap (instead of mprotect) for NaCl.\n* pthread_start.c (GC_inner_start_routine): Don't invoke\npthread_cleanup_push/pop for NaCl.\n* pthread_stop_world.c (GC_nacl_num_gc_threads,\nGC_nacl_thread_idx, GC_nacl_park_threads_now,\nGC_nacl_thread_parker, GC_nacl_gc_thread_self,\nGC_nacl_thread_parked, GC_nacl_thread_used,\nGC_nacl_thread_parking_inited, GC_nacl_thread_alloc_lock): New\nvariable (fo NaCl only).\n* pthread_stop_world.c (GC_remove_allowed_signals,\nsuspend_handler_mask, GC_stop_count, GC_world_is_stopped,\nGC_retry_signals, SIG_THR_RESTART, GC_suspend_ack_sem,\nGC_restart_ack_sem, GC_suspend_handler_inner, GC_suspend_handler,\nGC_restart_handler): Don't define for NaCl.\n* pthread_support.c (GC_get_nprocs): Likewise.\n* include/private/gc_priv.h (SIG_SUSPEND): Likewise.\n* include/private/gcconfig.h (LINUX): Likewise.\n* pthread_stop_world.c (GC_push_all_stacks): Push register storage\nfor NaCl.\n* pthread_stop_world.c (GC_suspend_all, GC_stop_world,\nGC_start_world): Implement for NaCl.\n* pthread_stop_world.c (GC_stop_world): Don't define unused \"i\"\nlocal variable for OpenBSD (and NaCl).\n* pthread_stop_world.c (NACL_STORE_REGS): New macro definition for\nNaCl.\n* pthread_stop_world.c (nacl_pre_syscall_hook,\n__nacl_suspend_thread_if_needed, nacl_post_syscall_hook,\nGC_nacl_initialize_gc_thread, GC_nacl_shutdown_gc_thread): New\nfunction (for NaCl only).\n* pthread_stop_world.c (GC_stop_init): Empty for NaCl.\n* pthread_support.c (pthread_cancel, pthread_sigmask): Don't\nredirect for NaCl.\n* include/gc_pthread_redirects.h (pthread_cancel,\npthread_sigmask): Likewise.\n* pthread_support.c (GC_nacl_initialize_gc_thread,\nGC_nacl_shutdown_gc_thread): New internal prototype (NaCl only).\n* pthread_support.c (GC_new_thread, GC_delete_thread): Initialize\nand shutdown thread for NaCl.\n* pthread_support.c (GC_thr_init): Call sysconf for NaCl.\n* pthread_support.c (GC_pthread_exit): Call GC_thread_exit_proc\nfor NaCl.\n* include/gc.h: Don't include features.h for NaCl.\n* include/gc_pthread_redirects.h (GC_PTHREAD_CONST): New macro.\n* include/gc_pthread_redirects.h (GC_pthread_create): Use\nGC_PTHREAD_CONST instead of const.\n* win32_threads.c (GC_pthread_create): Likewise.\n* pthread_support.c (GC_pthread_create_t, GC_pthread_create,\npthread_create): Likewise.\n* include/private/gcconfig.h (NACL): Recognize NaCl.\n* include/private/gcconfig.h (GC_LINUX_THREADS): Valid for NaCl.\n* include/private/pthread_stop_world.h (thread_stop_info): Add\nreg_storage member; define NACL_GC_REG_STORAGE_SIZE macro (for\nNaCl only).\n* include/private/pthread_support.h (GC_nacl_gc_thread_self):\nDeclare internal variable (for NaCl only).\n\n* mach_dep.c (GC_with_callee_saves_pushed): Fix FE_ALL_EXCEPT\nmacro.\n\n* mark.c (GC_mark_some): Prefix and suffix \"asm\" and \"volatile\"\nkeywords with double underscore.\n* os_dep.c (catch_exception_raise, catch_exception_raise_state,\ncatch_exception_raise_state_identity): Add GC_API_OSCALL to\nfunction definition.\n* os_dep.c (catch_exception_raise_state,\ncatch_exception_raise_state_identity): Move definition to be\nbefore GC_ports.\n* os_dep.c (catch_exception_raise): Declare to have the symbol\ndefined before GC_ports.\n* os_dep.c (GC_ports): Store references to catch_exception_raise,\ncatch_exception_raise_state, catch_exception_raise_state_identity\n(to prevent stripping these symbols as dead).\n* os_dep.c (catch_exception_raise, catch_exception_raise_state,\ncatch_exception_raise_state_identity): Mark these symbols as\n\"referenced dynamically\" via an assembler directive (unless\nNO_DESC_CATCH_EXCEPTION_RAISE).\n* include/private/gc_priv.h (GC_API_OSCALL): New macro (defined\nsimilar to GC_API but as if GC_DLL is always defined).\n\n* os_dep.c: Don't include signal.h for GC_write_fault_handler on\nWin32.\n* os_dep.c (SIG_OK): Don't return true unless SIGSEGV or SIGBUS on\nFreeBSD.\n* os_dep.c (CODE_OK): Use SEGV_ACCERR on FreeBSD (define\nSEGV_ACCERR for older FreeBSD releases).\n\n* dyn_load.c (GC_register_map_entries,\nGC_register_dynamic_libraries_dl_iterate_phdr): Calculate\nDATASTART only once if DATASTART_IS_FUNC.\n* dyn_load.c (GC_register_dynamic_libraries_dl_iterate_phdr):\nCalculate DATAEND only once if DATAEND_IS_FUNC.\n* dyn_load.c: Add comment to some endif; realign some code.\n* dyn_load.c (GC_init_dyld): Don't use\n_dyld_bind_fully_image_containing_address if\nNO_DYLD_BIND_FULLY_IMAGE defined; add FIXME.\n* include/private/gcconfig.h (GC_data_start, GC_find_limit):\nDeclare if used by DATASTART/DATAEND, respectively.\n* include/private/gcconfig.h (DATASTART_IS_FUNC, DATAEND_IS_FUNC):\nDefine if DATASTART/DATAEND is a function, respectively.\n* include/private/gcconfig.h (GETPAGESIZE, NO_PTHREAD_TRYLOCK,\nNO_DYLD_BIND_FULLY_IMAGE): Define for Darwin/arm as well; include\nunistd.h.\n\n* os_dep.c (GC_setpagesize, GC_task_self, PROTECT, UNPROTECT):\nReorder to remove redundant ifdef for Win32.\n* os_dep.c: Add comment to some endif.\n* os_dep.c: Include pthread.h (for Linux even if single-threaded)\nif USE_GET_STACKBASE_FOR_MAIN; also include it for Darwin.\n* os_dep.c (STACKBOTTOM): Redefine for Darwin (unless prohibited\nfor some reason).\n* os_dep.c (GC_get_main_stack_base): Allow\nUSE_GET_STACKBASE_FOR_MAIN for Linux even if single-threaded; add\nassertion for the returned result.\n* os_dep.c (GC_get_stack_base): Define for Darwin if\nmulti-threaded.\n* os_dep.c (SIG_OK, CODE_OK): Add comment (for FreeBSD).\n* os_dep.c (ID_STOP, ID_RESUME): Define only if threads.\n* os_dep.c (catch_exception_raise): Remove redundant parentheses;\nrefine the documentation.\n\n* NT_MAKEFILE: Define _CRT_SECURE_NO_DEPRECATE for C++ files as\nwell.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* doc/README.macros (USE_GET_STACKBASE_FOR_MAIN): Refine.\n* include/gc.h (GC_INIT): Document.\n* include/private/gc_priv.h (GC_MACH_HEADER, GC_MACH_SECTION,\nGC_GETSECTBYNAME): Define depending only on the word size (i.e.,\ndefine these macros also for ARM).\n* tests/test.c (check_heap_stats): Print main thread stack bottom\nas well (only if verbose mode is on).\n\n* mach_dep.c (GC_with_callee_saves_pushed): Fix and improve code\nintroduced by the previous patch (if GETCONTEXT_FPU_EXCMASK_BUG\nand X86_64).\n\n* darwin_stop_world.c (GC_FindTopOfStack): Prefix and suffix\n\"volatile\" keyword with double underscore.\n* mach_dep.c (GETCONTEXT_FPU_EXCMASK_BUG): Recognize new macro and\ninclude fenv.h if defined (unless NO_GETCONTEXT or HAVE_PUSH_REGS).\n* mach_dep.c (GC_with_callee_saves_pushed): Restore FPU exception\nmask corrupted by getcontext if GETCONTEXT_FPU_EXCMASK_BUG.\n* include/private/gcconfig.h (GETCONTEXT_FPU_EXCMASK_BUG): Define\nfor Linux/x64 (since its GLibc getcontext currently has the bug).\n\n* allchblk.c (GC_use_entire_heap): Change type to int (as declared\nin gc.h); set the default value depending on new GC_USE_ENTIRE_HEAP\nmacro.\n* misc.c (GC_init): Test GC_USE_ENTIRE_HEAP environment variable to\nalter the default value of GC_use_entire_heap.\n* doc/README.environment (GC_USE_ENTIRE_HEAP): Document.\n* doc/README.macros (GC_USE_ENTIRE_HEAP): Likewise.\n\n* include/private/gcconfig.h (PARALLEL_MARK): Do not make it cause\nMPROTECT_VDB undefining.\n\n* include/private/gcconfig.h (DYNAMIC_LOADING): Fix filename in\nthe comment.\n\n* include/private/gc_priv.h (_GC_arrays): Move the conditional\nmacro definitions (shortcuts for GC_arrays members) into the\nstructure body.\n\n* darwin_stop_world.c (GC_mach_handler_thread,\nGC_use_mach_handler_thread,\nGC_darwin_register_mach_handler_thread): Define only if\nMPROTECT_VDB.\n* darwin_stop_world.c (GC_suspend_thread_list): Use\nGC_mach_handler_thread and GC_use_mach_handler_thread only if\nMPROTECT_VDB.\n* darwin_stop_world.c (GC_stop_world): Reset GC_mach_threads_count\nonly if defined (i.e. unless GC_NO_THREADS_DISCOVERY).\n* misc.c (GC_init): Fix comment for GWW_VDB.\n* os_dep.c (DARWIN_EXC_STATE, DARWIN_EXC_STATE_COUNT,\nDARWIN_EXC_STATE_T, DARWIN_EXC_STATE_DAR): New macros.\n* os_dep.c (catch_exception_raise): Use DARWIN_EXC_STATE,\nDARWIN_EXC_STATE_COUNT, DARWIN_EXC_STATE_T, DARWIN_EXC_STATE_DAR.\n* pthread_support.c (GC_thr_init): Define \"dummy\" local variable\nonly unless GC_DARWIN_THREADS.\n* include/private/gcconfig.h (MPROTECT_VDB): Define for Darwin\neven in the single-threaded mode; define for iPhone/iPad.\n* include/private/gcconfig.h (IA64): Remove unnecessary \"ifdef\"\naround \"undef\".\n* include/private/gcconfig.h (HEURISTIC1): Remove unused for\nCygwin.\n* include/private/gcconfig.h (STACKBOTTOM): Use fixed address for\nDarwin/arm (instead of HEURISTIC1).\n\n* misc.c (GC_write): Replace multiple \"ifdef/endif\" with \"elif\"\n(for ECOS and NOSYS).\n* os_dep.c (GC_get_main_stack_base): Likewise.\n* os_dep.c (GC_get_main_stack_base): Check\nUSE_GET_STACKBASE_FOR_MAIN macro before checking STACKBOTTOM one;\nremove \"dummy\" variable (use result one instead).\n* doc/README.macros (SN_TARGET_PS3): Document.\n* extra/threadlibs.c (main): Don't output \"-lpthread\" (and \"-ldl\")\nfor Android.\n* include/private/pthread_support.h: Fix comment for \"endif\".\n\n* misc.c (GC_allocate_ml): Define global variable if SN_TARGET_PS3.\n* misc.c (GC_init): Initialize GC_allocate_ml if SN_TARGET_PS3.\n* os_dep.c (SIGSEGV): Define to dummy zero if SN_TARGET_PS3.\n* os_dep.c (GC_unix_mmap_get_mem): Don't define if SN_TARGET_PS3.\n* os_dep.c (GC_default_push_other_roots,\nGC_push_thread_structures): Define for SN_TARGET_PS3.\n* include/private/gc_locks.h (GC_allocate_ml, LOCK, UNLOCK): Define\nfor SN_TARGET_PS3.\n* include/private/gcconfig.h (SN_TARGET_PS3): Recognize new macro\n(Sony PS/3 target).\n* include/private/gcconfig.h (THREADS): Define unconditionally if\nSN_TARGET_PS3.\n* include/private/gcconfig.h (GET_MEM): Define for SN_TARGET_PS3.\n\n* alloc.c (GC_collect_or_expand): Replace NIL with NULL in message.\n* dbg_mlc.c (GC_debug_malloc, GC_debug_malloc_ignore_off_page,\nGC_debug_malloc_atomic_ignore_off_page,\nGC_debug_generic_malloc_inner,\nGC_generic_malloc_inner_ignore_off_page, GC_debug_malloc_stubborn,\nGC_debug_malloc_atomic, GC_debug_malloc_uncollectable,\nGC_debug_malloc_atomic_uncollectable): Likewise.\n* gcj_mlc.c (GC_debug_gcj_malloc): Likewise.\n* dbg_mlc.c (GC_check_annotated_obj): Replace NIL with NULL in a\ncomment.\n* dyn_load.c (GC_FirstDLOpenedLinkMap): Likewise.\n* mark_rts.c (GC_roots_present): Likewise.\n* doc/README: Likewise.\n* include/private/gc_hdrs.h (IS_FORWARDING_ADDR_OR_NIL): Likewise.\n* include/private/gc_priv.h (_GC_arrays): Likewise.\n\n* configure.ac: Use AC_CHECK_LIB() to check for pthread instead of\njust blindly linking to -lpthread, as Android includes pthread\nsupport within libc and does not provide a separate libpthread.\n* dyn_load.c (GC_register_dynamic_libraries): Skip current link map\nentry if l_addr is NULL (Android/bionic only).\n* pthread_stop_world.c (android_thread_kill): New internal function\n(Android only).\n* pthread_stop_world.c (GC_suspend_all, GC_start_world): Call\nandroid_thread_kill (based on tkill) instead of pthread_kill on\nAndroid (since pthread_kill cannot be used safely on the platform).\n* pthread_support.c (GC_new_thread): Store thread Id (obtained from\ngettid) for use by android_thread_kill (Android only).\n* include/private/pthread_support.h (GC_Thread_Rep): Add kernel_id\nstructure member (Android only).\n* include/private/gcconfig.h: Recognize __x86_64 macro as a synonym\nof __x86_64__ (Darwin); define __environ macro (Android on M68K).\n\n* allchblk.c (GC_freehblk): Print extended error message (done via\nGC_printf() before aborting with a short message) only if\nGC_print_stats.\n* dyn_load.c (GC_register_dynamic_libraries): Likewise.\n* os_dep.c (GC_get_maps, GC_register_data_segments, GC_remap,\nPROTECT, GC_write_fault_handler, GC_mprotect_thread): Likewise.\n* pthread_stop_world.c (GC_start_world): Likewise.\n* win32_threads.c (GC_register_my_thread_inner): Likewise.\n* os_dep.c (GC_get_main_stack_base, GC_register_data_segments,\nGC_dirty_init): Remove redundant print of an error message before\naborting with the same message.\n* os_dep.c (GC_register_data_segments): Remove format specifier\nfrom the string passed to GC_err_puts(); use ABORT instead of EXIT\n(if invalid executable type).\n* os_dep.c (GC_remap): Adjust printf format specifier (for long\ntype).\n* os_dep.c (GC_dirty_init): Print a message about SIG_IGN detected\n(for SIGSEGV/BUS) only if GC_print_stats.\n* os_dep.c (catch_exception_raise): Join 2 adjacent GC_err_printf\ncalls.\n\n* tests/test.c (main): Print the relevant message if GWW_VDB.\n* include/private/gcconfig.h: Don't define MPROTECT_VDB for Win32\non x64 if compiled by GCC.\n\n* tests/staticrootstest.c: Include string.h for memset() prototype.\n* tests/thread_leak_test.c (main): Fix printf() format specifiers.\n\n* CMakeLists.txt: Check enable_parallel_mark on Darwin.\n* configure.ac: Likewise.\n* darwin_stop_world.c (DARWIN_SUSPEND_GC_THREADS,\nDARWIN_QUERY_TASK_THREADS): Rename to GC_NO_THREADS_DISCOVERY and\nGC_DISCOVER_TASK_THREADS, respectively.\n* os_dep.c (DARWIN_SUSPEND_GC_THREADS): Likewise.\n* pthread_support.c (DARWIN_SUSPEND_GC_THREADS): Likewise.\n* darwin_stop_world.c (DARWIN_QUERY_TASK_THREADS): Don't define\n(and remove FIXME).\n* darwin_stop_world.c (GC_use_threads_discovery): Add GC_API;\ncomment; remove FIXME.\n* win32_threads.c (GC_NO_DLLMAIN): Rename to\nGC_NO_THREADS_DISCOVERY.\n* tests/test.c (GC_NO_DLLMAIN): Likewise.\n* doc/README.macros (GC_NO_DLLMAIN): Likewise.\n* doc/README.win32 (GC_NO_DLLMAIN): Likewise.\n* doc/README.macros (GC_NO_THREADS_DISCOVERY): Update the comment.\n* win32_threads.c (GC_win32_dll_threads): Define as macro to true\nif GC_DISCOVER_TASK_THREADS (and not GC_NO_THREADS_DISCOVERY);\nupdate the comment.\n* win32_threads.c (GC_use_DllMain): Rename to\nGC_use_threads_discovery; do not set GC_win32_dll_threads if\nGC_DISCOVER_TASK_THREADS.\n* win32_threads.c (GC_started_thread_while_stopped,\nGC_lookup_thread_inner, UNPROTECT_THREAD, GC_lookup_pthread,\nGC_thr_init, GC_pthread_create, DllMain): Rewrite some expressions\nwhich use GC_win32_dll_threads to minimize the possibility of\nan \"unreachable code\" compiler warning when GC_win32_dll_threads\nis defined as a macro.\n* win32_threads.c (GC_unregister_my_thread): Don't call\nGC_delete_thread() if GC_win32_dll_threads and THREAD_LOCAL_ALLOC\n(since can't happen); use \"t\" local variable only if not\nGC_win32_dll_threads.\n* doc/README.macros (GC_DISCOVER_TASK_THREADS): Document.\n* include/gc.h (GC_use_DllMain): Rename to\nGC_use_threads_discovery but keep old name as a macro definition.\n* include/gc.h (GC_use_threads_discovery): Declare also for\nDarwin; update the comment.\n* tests/test.c (main): Call GC_use_threads_discovery for Darwin\n(to test the mode if possible).\n\n* darwin_stop_world.c (DARWIN_SUSPEND_GC_THREADS,\nDARWIN_QUERY_TASK_THREADS): New macro recognized.\n* darwin_stop_world.c (GC_query_task_threads): add STATIC;\ninitialize to false; define as macro if DARWIN_SUSPEND_GC_THREADS\nor DARWIN_QUERY_TASK_THREADS; remove FIXME.\n* darwin_stop_world.c (GC_use_threads_discovery): New function\n(for setting GC_query_task_threads value).\n* darwin_stop_world.c (GC_mach_handler_thread,\nGC_use_mach_handler_thread, GC_mach_thread, GC_MAX_MACH_THREADS,\nGC_mach_threads, GC_mach_threads_count, GC_suspend_thread_list,\nGC_darwin_register_mach_handler_thread): Define only if not\nDARWIN_SUSPEND_GC_THREADS.\n* darwin_stop_world.c (GC_stop_world, GC_start_world): Exclude\nthe code for GC_query_task_threads case from compilation unless\nDARWIN_SUSPEND_GC_THREADS.\n* os_dep.c (GC_darwin_register_mach_handler_thread): Declared only\nif Darwin threads and not DARWIN_SUSPEND_GC_THREADS.\n* os_dep.c (GC_mprotect_thread): Call\nGC_darwin_register_mach_handler_thread only if THREADS and not\nDARWIN_SUSPEND_GC_THREADS.\n* pthread_support.c (marker_mach_threads): Don't define if\nDARWIN_SUSPEND_GC_THREADS.\n* pthread_support.c (GC_mark_thread): Don't fill in\nmarker_mach_threads if DARWIN_SUSPEND_GC_THREADS.\n* include/private/gc_locks.h (GC_need_to_lock): Always declare for\nTHREADS case.\n\n* darwin_stop_world.c (GC_query_task_threads): Don't define to\nfalse for DARWIN_DONT_PARSE_STACK case; unconditionally initialize\nthe variable to false (for now).\n* darwin_stop_world.c (GC_push_all_stacks): Call task_threads()\nonly if not DARWIN_DONT_PARSE_STACK.\n* darwin_stop_world.c (GC_stop_world, GC_start_world): Use the\napproach based on task_threads() only if GC_query_task_threads\nelse use GC_threads table.\n\n* darwin_stop_world.c (GC_mach_threads): Remove static qualifier.\n* darwin_stop_world.c (GC_stop_init): Remove (as we do not need to\nreally clear GC_mach_threads[]).\n* darwin_stop_world.c (GC_stop_world): Reset GC_mach_threads_count\n(instead of calling GC_stop_init).\n* include/private/pthread_support.h (GC_stop_init): Remove proto.\n* pthread_support.c (GC_stop_init): Add proto (unless Darwin).\n* pthread_support.c (GC_thr_init): Don't call GC_stop_init() if\nGC_DARWIN_THREADS.\n\n* darwin_stop_world.c (GC_stack_range_for): New static function\n(move the code from GC_push_all_stacks).\n* darwin_stop_world.c (GC_push_all_stacks): Call\nGC_stack_range_for(); rename kern_return local variable to\nkern_result.\n* darwin_stop_world.c (GC_is_mach_marker): Change argument type\nfrom mach_port_t to thread_act_t.\n* pthread_support.c (GC_is_mach_marker): Likewise.\n\n* darwin_stop_world.c (GC_push_all_stacks): Fix \"my_task\" local\nvariable initialization (always call current_task()).\n* pthread_support.c (GC_thr_init, GC_register_my_thread_inner):\nDon't set thread's stop_info.stack_ptr value for Darwin.\n* include/private/darwin_stop_world.h (thread_stop_info): Update\nthe comment for stack_ptr.\n\n* darwin_stop_world.c (GC_push_all_stacks): Rename \"r\", \"me\" local\nvariables to \"kern_return\" and \"my_thread\" ones, respectively;\ncall mach_port_deallocate() unconditionally.\n* darwin_stop_world.c (GC_stop_world): Don't call mach_thread_self\nif DEBUG_THREADS.\n\n* darwin_stop_world.c (GC_mach_thread): Move from\ndarwin_stop_world.h.\n* include/private/darwin_stop_world.h (GC_mach_thread): Remove.\n* win32_threads.c (GC_start_world): Define \"thread_id\" local\nvariable only if GC_ASSERTIONS; decide whether to resume a thread\nbased on its \"suspended\" field value; assert that suspended thread\nstack_base is non-zero and the thread is not our one.\n\n* darwin_stop_world.c (GC_thread_resume): New inline function\n(move code from GC_thread_resume).\n* darwin_stop_world.c (GC_start_world): Check result of\ntask_threads(); call GC_thread_resume().\n* os_dep.c (GC_malloc_heap_l, GC_is_malloc_heap_base): Define\nonly if not CYGWIN32.\n* os_dep.c (GC_is_heap_base): Call GC_is_malloc_heap_base() only\nif not CYGWIN32.\n\n* darwin_stop_world.c (FindTopOfStack): Change return type to\nptr_t (from long); make GC_INNER; add GC_ prefix.\n* darwin_stop_world.c (GC_push_all_stacks): Add thread_blocked\nlocal variable (initialized from the corresponding GC_thread\nfield unless GC_query_task_threads); add assertion that our\nthread is not blocked; prefix FindTopOfStack with GC_ and remove\nno longer needed cast to ptr_t of the result; handle thread\nblocked case (and remove FIXME); use GC_push_all_stack_sections\nunless GC_query_task_threads (and remove FIXME).\n* pthread_support.c (GC_FindTopOfStack): Declare (if needed).\n* pthread_support.c (GC_do_blocking_inner): Call\nGC_save_regs_in_stack (if needed) before acquiring the lock.\n* win32_threads.c (GC_do_blocking_inner): Likewise.\n* pthread_support.c (GC_do_blocking_inner): Set/clear topOfStack\nfield of GC_thread (Darwin only).\n* include/private/pthread_support.h (GC_thread): Add topOfStack\nfield for Darwin (unless DARWIN_DONT_PARSE_STACK).\n\n* finalize.c (GC_check_finalizer_nested): Change return type to\nchar pointer (instead of int pointer); use explicit cast for\nGC_finalizer_nested assignment.\n* pthread_support.c (GC_check_finalizer_nested): Likewise.\n* win32_threads.c (GC_check_finalizer_nested): Likewise.\n* finalize.c (GC_finalizer_nested): Change type to unsigned char.\n* finalize.c (GC_notify_or_invoke_finalizers): Change type of\n\"pnested\" local variable to char pointer.\n* pthread_support.c (GC_do_blocking_inner,\nGC_call_with_gc_active): Use explicit cast for \"thread_blocked\"\nfield assignment.\n* win32_threads.c (GC_lookup_pthread): Use explicit cast for\n\"suspended\" field assignment.\n* win32_threads.c (GC_Thread_Rep): Use short type for\nfinalizer_skipped; use char type for finalizer_nested and flags\nfields and reorder some fields (to minimize GC_Thread_Rep\nstructure size).\n* include/private/pthread_support.h (GC_Thread_Rep): Likewise.\n* win32_threads.c (GC_Thread_Rep): Use char type for suspended\nfield (instead of GC_bool).\n* include/private/pthread_support.h (GC_Thread_Rep): Use char type\nfor thread_blocked field (instead of short).\n\n* darwin_stop_world.c (GC_query_task_threads): New variable (or\nmacro).\n* darwin_stop_world.c (GC_push_all_stacks): Use\nGC_query_task_threads (to choose between algorithms based on\nkernel task_threads and based on GC_threads table); update FIXME;\nremove commented out GC_push_one statements.\n* pthread_support.c (GC_thr_init, GC_do_blocking_inner,\nGC_call_with_gc_active, GC_register_my_thread_inner): Initialize\nstack_ptr field for all platforms.\n* pthread_support.c (GC_call_with_gc_active): Initialize\nsaved_stack_ptr field for all platforms.\n* include/private/darwin_stop_world.h (thread_stop_info): Add\nstack_ptr field; change type of already_suspended from int to\nGC_bool.\n\n* darwin_stop_world.c (GC_MAX_MACH_THREADS): New macro.\n* darwin_stop_world.c (GC_mach_threads, GC_stop_init): Use\nGC_MAX_MACH_THREADS instead of THREAD_TABLE_SZ.\n* darwin_stop_world.c (GC_mach_threads): Add FIXME.\n* darwin_stop_world.c (GC_stop_init, GC_suspend_thread_list,\nGC_stop_world): Use FALSE and TRUE for already_suspended field and\n\"changed\", \"found\" variables.\n* darwin_stop_world.c (GC_is_mach_marker): New prototype (only if\nPARALLEL_MARK).\n* darwin_stop_world.c (GC_suspend_thread_list): Change return type\nto GC_bool; change type of \"changed\", \"found\" to GC_bool; make\n\"my_thread\" as an argument (instead of acquiring/deallocating it\nlocally); do not add my_thread, GC_mach_handler_thread and marker\nthreads to GC_mach_threads table; check for overflow of\nGC_mach_threads table; increase GC_mach_threads_count if \"found\"\nis true and info.suspend_count is non-zero.\n* darwin_stop_world.c (GC_suspend_thread_list, GC_start_world):\nAdjust \"thread\" format specifiers for GC_printf(); search thread\nin \"old_list\" starting from the previous found one.\n* darwin_stop_world.c (GC_stop_world): Rename \"changes\" to\n\"changed\" local variable; remove \"result\" variable; adjust\nGC_printf debugging message.\n* darwin_stop_world.c (GC_start_world): Do not check for\nmy_thread and GC_use_mach_handler_thread (since they are not added\nto GC_mach_threads table); call thread_info() only if\nDEBUG_THREADS or GC_ASSERTIONS.\n* pthread_support.c (marker_mach_threads): New static variable (if\nDarwin).\n* pthread_support.c (GC_is_mach_marker): New function (if Darwin).\n* pthread_support.c (GC_mark_thread): Fill in marker_mach_threads\ntable (if Darwin).\n\n* alloc.c (GC_parallel): Define only if THREADS.\n* misc.c (GC_get_parallel): Likewise.\n* include/gc.h (GC_parallel, GC_get_parallel,\nGC_get_suspend_signal, GC_allow_register_threads,\nGC_register_my_thread, GC_unregister_my_thread): Define only if\nGC_THREADS.\n* include/gc.h (GC_get_heap_size): Fix a typo in a comment.\n\n* configure.ac: Use `AC_C_INLINE'.\n* include/private/gc_priv.h (GC_INLINE): Use \"inline\" keyword\n(determined by configure AC_C_INLINE) if HAVE_CONFIG_H is defined.\n\n* dyn_load.c (DL_ITERATE_PHDR_STRONG): New macro (define for\nFreeBSD).\n* dyn_load.c (GC_register_main_static_data): Move the definition\nabove GC_register_dynamic_libraries_dl_iterate_phdr one (FreeBSD\ncase); unconditionally return FALSE if DL_ITERATE_PHDR_STRONG.\n* dyn_load.c (GC_register_dynamic_libraries_dl_iterate_phdr): Test\nGC_register_main_static_data() result (instead of direct testing\nof dl_iterate_phdr (to prevent a compiler warning).\n* os_dep.c (CODE_OK): Test si_code also for the value of 2\n(FreeBSD case; required for FreeBSD v7+).\n* os_dep.c (CODE_OK): Properly use parentheses (HPUX case).\n* include/private/gcconfig.h (DATASTART): Cast etext argument in\nGC_FreeBSDGetDataStart() call; remove unnecessary \"&\" (FreeBSD\ncase).\n\n* include/private/specific.h (quick_thread_id): Define thru\nGC_approx_sp(); define as a macro.\n* include/private/specific.h (getspecific): Use GC_INLINE instead\nof __inline__ (to work around Sun CC which does not recognize\ninline keyword surrounded with underscores).\n\n* darwin_stop_world.c (FindTopOfStack): Simplify condition\nexpressions.\n* darwin_stop_world.c (GC_push_all_stacks): Merge two variants\nof this function (DARWIN_DONT_PARSE_STACK).\n* darwin_stop_world.c (GC_push_all_stacks): Add a check for our\nthread is found (same as in pthread_stop_world.c).\n* darwin_stop_world.c (GC_push_all_stacks): Print the number of\nscanned threads if verbose (same as in pthread_stop_world.c).\n\n* darwin_stop_world.c (GC_push_all_stacks): Reset\nthread_state_count value before every thread_get_state call;\nrefine the comment for thread_state_count.\n* darwin_stop_world.c (GC_push_all_stacks): Ignore rsp, rip/eip,\nrflags, cs, fs, gs, ss, ds, es, __pc registers; uncomment ebp\nregister pushing.\n* darwin_stop_world.c (GC_push_all_stacks): Set outCount to\nGC_MACH_THREAD_STATE_COUNT (instead of THREAD_STATE_MAX).\n* darwin_stop_world.c (GC_push_all_stacks): Remove FIXME and WARN\nfor x86.\n\n* doc/README.macros (DARWIN_DONT_PARSE_STACK): Fix a typo.\n* darwin_stop_world.c (GC_use_mach_handler_thread): Change type\nto GC_bool.\n* darwin_stop_world.c (GC_suspend_thread_list, GC_start_world):\nSimplify the expressions involving GC_use_mach_handler_thread.\n* darwin_stop_world.c (GC_darwin_register_mach_handler_thread):\nInitialize GC_use_mach_handler_thread to TRUE (instead of 1).\n\n* include/gc_pthread_redirects.h (GC_pthread_sigmask, GC_dlopen,\npthread_sigmask, dlopen): Don't define for pthreads-win32 (and\ndon't include signal.h and dlfcn.h).\n\n* dyn_load.c (GC_register_dynlib_callback): Add FIXME.\n\n* include/private/gcconfig.h: Add support for FreeBSD on ppc64.\n\n* os_dep.c (PROTECT, UNPROTECT): Correct VM_PROT_EXEC to\nVM_PROT_EXECUTE.\n\n* os_dep.c (os2_alloc): Don't set PAG_EXECUTE unless\npages_executable is on.\n* os_dep.c (os2_alloc): Add FIXME (for recursion).\n* os_dep.c (UNPROTECT): Abort with a more informative message if\npages_executable is on (\"mprotect\" case).\n* os_dep.c (PROTECT, UNPROTECT): Set VM_PROT_EXEC if\npages_executable is on (Darwin case).\n* pthread_support.c (GC_init_real_syms): Abort with an informative\nmessage if libgc is linked after libpthread.\n\n* dyn_load.c (GC_register_dynlib_callback): Adjust \"start\" pointer\nfor 64-bit targets.\n* pthread_support.c (start_mark_threads): Expand PTHREAD_CREATE\nmacro.\n* pthread_support.c (start_mark_threads): Call INIT_REAL_SYMS()\nsince REAL(pthread_create) is used.\n* pthread_support.c (PTHREAD_CREATE): Remove unused.\n\n* extra/threadlibs.c (main): Remove --wrap for \"read\" (since not\nwrapped anymore).\n* doc/README.linux (GC_USE_LD_WRAP): Likewise.\n* os_dep.c (__wrap_read): Likewise.\n\n* include/gc_pthread_redirects.h: Test GC_PTHREADS and GC_H at the\nbeginning of the file.\n* include/gc_pthread_redirects.h (GC_PTHREAD_EXIT_ATTRIBUTE): New\nmacro (defined only for Linux and Solaris).\n* include/gc_pthread_redirects.h (GC_pthread_cancel,\nGC_pthread_exit): Declare new API function (only if\nGC_PTHREAD_EXIT_ATTRIBUTE).\n* include/gc_pthread_redirects.h (pthread_cancel, pthread_exit):\nRedirect (if GC_PTHREAD_EXIT_ATTRIBUTE).\n* include/private/pthread_support.h (DISABLED_GC): New macro.\n* pthread_support.c (pthread_cancel, pthread_exit): Restore\noriginal definition or declare \"real\" function (if needed and\nGC_PTHREAD_EXIT_ATTRIBUTE).\n* pthread_support.c (GC_pthread_cancel_t, GC_pthread_exit_t):\nDeclare new types if needed.\n* pthread_support.c (GC_pthread_cancel, GC_pthread_exit): New\nfunction definition (only if GC_PTHREAD_EXIT_ATTRIBUTE).\n* pthread_support.c (GC_init_real_syms): Initialize pointers to\nthe \"real\" pthread_cancel and pthread_exit (only if\nGC_PTHREAD_EXIT_ATTRIBUTE).\n* pthread_support.c (GC_unregister_my_thread): Enable collections\nif DISABLED_GC was set (only if GC_PTHREAD_EXIT_ATTRIBUTE).\n* pthread_support.c (pthread_cancel, pthread_exit): New wrapped\nfunction definition (only if GC_PTHREAD_EXIT_ATTRIBUTE defined).\n* pthread_support.c (GC_start_routine): Refine the comment.\n* extra/threadlibs.c (main): Adjust --wrap (add \"read\",\n\"pthread_exit\", \"pthread_cancel\" but remove \"sleep\").\n* doc/README.linux (GC_USE_LD_WRAP): Likewise.\n\n* include/gc.h (GC_MALLOC_STUBBORN): Remove trailing ';' in the\nmacro definition.\n* include/gc.h (GC_reachable_here): Likewise.\n* include/gc.h (GC_reachable_here): Prefix and postfix \"volatile\"\nwith double '_'.\n\n* pthread_start.c: New file.\n* CMakeLists.txt (SRC): Add pthread_start.c.\n* Makefile.am (libgc_la_SOURCES): Likewise.\n* Makefile.direct (CSRCS): Likewise.\n* Makefile.direct (OBJS): Add pthread_start.obj.\n* extra/gc.c: Add a comment; include pthread_start.c.\n* pthread_support.c (start_info): Move the struct definition down\ncloser to its usage.\n* pthread_support.c (GC_thread_exit_proc): Replace STATIC with\nGC_INNER.\n* pthread_support.c (GC_inner_start_routine): Move to the\ndefinition to pthread_start.c; leave only the prototype; remove\nSTATIC.\n* pthread_support.c (GC_start_rtn_prepare_thread): New function\n(contains parts of the original GC_inner_start_routine).\n\n* configure.ac (NO_EXECUTE_PERMISSION): Add comment.\n* doc/README.macros (NO_EXECUTE_PERMISSION): Update the\ndocumentation.\n* include/gc.h (GC_set_pages_executable, GC_get_pages_executable):\nNew API function declaration.\n* os_dep.c (OPT_PROT_EXEC): Remove (superseded by\npages_executable).\n* os_dep.c (pages_executable): New static variable.\n* os_dep.c (IGNORE_PAGES_EXECUTABLE): New macro (used by\nGC_get_pages_executable only).\n* os_dep.c (GC_unix_mmap_get_mem, GC_remap, PROTECT, UNPROTECT):\nReplace OPT_PROT_EXEC with pages_executable.\n* os_dep.c (GC_unix_mmap_get_mem, GC_remap, GC_win32_get_mem,\nGC_wince_get_mem, UNPROTECT): Undefine IGNORE_PAGES_EXECUTABLE.\n* os_dep.c (GC_win32_get_mem, GC_wince_get_mem, GC_remap, PROTECT,\nUNPROTECT): Use PAGE_EXECUTE_... only if pages_executable is on.\n* os_dep.c (GC_set_pages_executable, GC_get_pages_executable): New\nAPI function definition.\n\n* tests/test.c (check_heap_stats): Increase max_heap_sz by 20% for\n64-bit CPUs (to prevent \"Unexpected heap growth\" failure on Win64,\nat least).\n\n* tests/test.c (check_heap_stats): Increase max_heap_sz by 25% for\n32-bit CPUs (to prevent \"Unexpected heap growth\" failure).\n\n* gc_dlopen.c (dlopen): Prototype REAL_DLFUNC if GC_USE_LD_WRAP.\n* pthread_support.c (pthread_create, pthread_join, pthread_detach,\npthread_sigmask): Likewise.\n* gc_dlopen.c (dlopen): Remove cast (redundant since the prototype\nis added).\n* gc_dlopen.c (GC_dlopen): Fix return type.\n* pthread_support.c (GC_init_real_syms): Don't define\nLIBPTHREAD_NAME, LIBPTHREAD_NAME_LEN, len, namebuf and\nlibpthread_name if RTLD_NEXT.\n\n* gc_dlopen.c (disable_gc_for_dlopen): Update the comment.\n* gc_dlopen.c (dlopen): Likewise.\n* include/gc.h (GC_enable_incremental): Refine the comment.\n* include/gc.h (DECLSPEC_NORETURN): Define macro as empty if\nmissing (only for Win32).\n* include/gc.h (GC_ExitThread): Use DECLSPEC_NORETURN.\n* win32_threads.c (GC_ExitThread): Likewise.\n* include/gc.h (GC_endthreadex): Add a comment.\n\n* include/cord.h: Fix typos.\n\n* Makefile.am (EXTRA_DIST): Add \"CMakeLists.txt\" and\n\"tests/CMakeLists.txt\".\n* doc/doc.am (dist_pkgdata_DATA): Add \"doc/README.cmake\".\n\n* mach_dep.c (NO_GETCONTEXT): Also define if AVR32.\n* include/private/gcconfig.h (AVR32): New macro (also define the\nsupplementary macros for the target).\n* include/private/thread_local_alloc (USE_COMPILER_TLS): Don't\ndefine for AVR32.\n\n* tests/leak_test.c (main): Explicitly define as returning int\n(to prevent a spurious test failure on some Linux/alpha targets).\n* tests/thread_leak_test.c (main): Likewise.\n* tests/thread_leak_test.c: Initialize GC_find_leak in the main\nthread (before GC_INIT) only.\n* tests/leak_test.c (main): Use GC_set_find_leak() instead of\naccessing GC_find_leak directly.\n* tests/thread_leak_test.c (main): Likewise.\n\n* include/gc.h (GC_find_leak, GC_finalize_on_demand,\nGC_java_finalization, GC_dont_expand, GC_no_dls,\nGC_dont_precollect): Simplify the comment (remove the information\nabout data races since the value is boolean).\n\n* os_dep.c (GC_get_stack_base, GC_get_main_stack_base): New\nSolaris-specific implementation (based on thr_stksegment).\n* os_dep.c (stackbase_main_self, stackbase_main_ss_sp): New static\nvariable used by the Solaris-specific GC_get_stack_base().\n\n* pthread_support.c (GC_mark_thread_local_free_lists,\nGC_check_tls): Mark (and check) only for live threads (in case of\nGC_destroy_thread_local() is called already but GC_delete_thread()\nis not yet).\n* win32_threads.c (GC_mark_thread_local_free_lists, GC_check_tls):\nLikewise.\n\n* NT_MAKEFILE: Remove the comment about DLL and win32s.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_MAKEFILE: Add \".SUFFIXES\" directive (to handle gc_cpp.cc\nproperly on VS 2005+).\n* NT_MAKEFILE: Update GC log file name in comments.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* doc/README.win32: Likewise.\n* NT_MAKEFILE: Remove \":full\" for \"-debug\" option (since no\nlonger supported by VS).\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_MAKEFILE: Commented out copying of gc_cpp.cc to gc_cpp.cpp.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* NT_STATIC_THREADS_MAKEFILE: Add -D PARALLEL_MARK option.\n* NT_STATIC_THREADS_MAKEFILE: Increase stack size for gctest.exe.\n* NT_X64_STATIC_THREADS_MAKEFILE: Remove \"-stack\" option (use the\ndefault stack size limit).\n* NT_X64_THREADS_MAKEFILE: Rename \"gc64_dll.dll\" to \"gc64.dll\".\n* win32_threads.c (GC_get_next_stack): Always define (since it is\nalso used for Cygwin now).\n\n* alloc.c (GC_maybe_gc): Move GC_notify_full_gc() call upper to\nbe just before GC_clear_marks() call.\n* include/gc_mark.h (GC_start_callback_proc): Refine the comment.\n\n* Makefile.am (check_LTLIBRARIES): Initialize to empty.\n* tests/tests.am (TESTS, check_PROGRAMS): Add staticrootstest.\n* tests/tests.am (staticrootstest_SOURCES, staticrootstest_LDADD,\nlibstaticrootslib_la_SOURCES, libstaticrootslib_la_LIBADD,\nlibstaticrootslib_la_LDFLAGS, libstaticrootslib_la_DEPENDENCIES):\nDefine.\n* tests/tests.am (check_LTLIBRARIES): Add libstaticrootslib.la.\n\n* tests/staticrootstest.c: New file.\n* tests/staticrootslib.c: Likewise.\n\n* dyn_load.c (GC_get_next_stack, GC_cond_add_roots): Define for\nCygwin as well as other win32 targets.\n* dyn_load.c (GC_wnt): Define to constant true.\n* dyn_load.c (GC_register_dynamic_libraries): Define for Cygwin as\nwell as other win32 targets.\n* mark_rts.c (rt_hash, GC_roots_present, add_roots_to_index):\nDon't define for Cygwin, as on other win32.\n* mark_rts.c (GC_add_roots_inner, GC_clear_roots): Handle on\nCygwin as for other win32 targets.\n* mark_rts.c (GC_rebuild_root_index): Don't declare on Cygwin, as\nother win32.\n* mark_rts.c (GC_remove_tmp_roots): Do declare on Cygwin as on\nother win32.\n* mark_rts.c (GC_remove_roots, GC_remove_roots_inner): Don't\ndeclare on Cygwin as on other win32.\n* mark_rts.c (GC_is_tmp_root): Do declare on Cygwin when\n!NO_DEBUGGING, as on other win32 targets.\n* mark_rts.c (GC_cond_register_dynamic_libraries): Handle on\nCygwin as for other win32 targets.\n* os_dep.c (GC_setpagesize): Handle on Cygwin as on other win32.\n* os_dep.c (GC_get_main_stack_base): Don't declare on Cygwin, as\nother win32.\n* os_dep.c (GC_sysinfo): Declare on Cygwin, as other win32.\n* os_dep.c (GC_win32_get_mem): Declare on Cygwin, as on other\nWin32, but call GC_unix_get_mem instead of GlobalAlloc.\n* os_dep.c (GC_win32_free_heap): Declare on Cygwin (as empty).\n* ptr_chck.c (GC_is_visible): Register dynamic libraries on Cygwin\nas on other win32 platforms.\n* win32_threads.c (GC_get_next_stack): Define on Cygwin as well as\nfor dynamic loading targets.\n* include/private/gc_priv.h (GC_INNER): Don't try to use\nvisibility on Cygwin which does not support it.\n* include/private/gc_priv.h (struct roots): Don't declare r_next\nmember on Cygwin as on other windows hosts.\n* include/private/gc_priv.h (LOG_RT_SIZE, RT_SIZE): Don't define\nlikewise.\n* include/private/gc_priv.h (struct _GC_arrays): Do declare\n_heap_bases[] member and don't declare _root_index likewise.\n* include/private/gc_priv.h (GC_heap_bases): Do define likewise.\n* include/private/gc_priv.h (_SYSTEM_INFO): Do forward-declare\nlikewise.\n* include/private/gc_priv.h (GC_sysinfo): Do declare extern\nlikewise.\n* include/private/gcconfig.h (GC_win32_get_mem, GET_MEM): Do\nprototype on Cygwin as other win32 platforms.\n\n* os_dep.c (GC_get_main_stack_base): Use pthread_getattr_np() and\npthread_attr_getstack() instead of GC_get_stack_base() (and check\nreturned stackaddr for NULL); output a warning on failure.\n\n* alloc.c (GC_start_call_back): Replace the definition type to\nGC_start_callback_proc.\n* alloc.c (GC_set_start_callback, GC_get_start_callback): New\nsetter/getter function.\n* alloc.c (GC_try_to_collect_inner): Call GC_notify_full_gc()\nunconditionally (because GC_try_to_collect_inner always does full\nGC).\n* include/gc_mark.h (GC_start_callback_proc): New type.\n* include/gc_mark.h (GC_set_start_callback,\nGC_get_start_callback): New API function declaration.\n\n* doc/README.macros (USE_GET_STACKBASE_FOR_MAIN): Document.\n* os_dep.c (GC_get_main_stack_base): Recognize\nUSE_GET_STACKBASE_FOR_MAIN (only if THREADS and LINUX_STACKBOTTOM)\nand use GC_get_stack_base() in this case.\n\n* os_dep.c (GC_get_stack_base): Add LOCK/UNLOCK() (since\nGC_find_limit_with_bound() should be called with the lock held).\n* backgraph.c (FOR_EACH_PRED): Fix a typo.\n\n* alloc.c (GC_set_stop_func, GC_get_stop_func): Add\nDCL_LOCK_STATE.\n* finalize.c (GC_notify_or_invoke_finalizers): Likewise.\n* gc_dlopen.c (disable_gc_for_dlopen): Likewise.\n* gcj_mlc.c (maybe_finalize, GC_debug_gcj_malloc): Likewise.\n* mark.c (GC_print_trace): Likewise.\n* misc.c (GC_set_warn_proc, GC_get_warn_proc, GC_enable,\nGC_disable, GC_new_free_list, GC_new_kind, GC_new_proc,\nGC_set_oom_fn, GC_get_oom_fn, GC_set_finalizer_notifier,\nGC_get_finalizer_notifier): Likewise.\n* os_dep.c (GC_get_stack_base, GC_print_callers): Likewise.\n* pthread_support.c (GC_is_thread_tsd_valid,\nGC_wait_for_gc_completion, GC_init_parallel, GC_do_blocking_inner,\nGC_call_with_gc_active, GC_unregister_my_thread, pthread_join,\npthread_detach, GC_register_my_thread, GC_inner_start_routine,\npthread_create): Likewise.\n* reclaim.c (GC_print_all_errors): Likewise.\n* win32_threads.c (GC_is_thread_tsd_valid, GC_register_my_thread,\nGC_unregister_my_thread, GC_do_blocking_inner,\nGC_call_with_gc_active, GC_lookup_pthread, GC_pthread_join,\nGC_pthread_start_inner, GC_thread_exit_proc, GC_pthread_detach,\nGC_init_parallel): Likewise.\n\n* doc/README.darwin: Update.\n\n* CMakeLists.txt: Adjust INCLUDE_DIRECTORIES and SRC (to make it\nusable on Mac OS X).\n* doc/README.cmake: Update.\n\n* CMakeLists.txt: New file (adding CMake support).\n* tests/CMakeLists.txt: Likewise.\n* doc/README.cmake: Likewise.\n\n* configure.ac (darwin): Don't define HAS_PPC_THREAD_STATE...\nmacros.\n* include/private/gc_priv.h (THREAD_FLD): Recognize\n__DARWIN_UNIX03 instead of HAS_PPC_THREAD_STATE... macros.\n\n* pthread_support.c: Include <sys/param.h> and <sys/sysctl.h> for\nOpenBSD.\n* pthread_support.c (get_ncpu): Define also for Darwin, NetBSD and\nOpenBSD.\n* pthread_support.c (GC_thr_init): Use get_ncpu() for Darwin,\nNetBSD and OpenBSD.\n\n* mallocx.c (GC_generic_malloc_many, GC_malloc_many): Define even\nif THREADS is undefined.\n* include/gc.h (GC_malloc_many): Update the comment.\n\n* include/gc_cpp.h (GC_PLACEMENT_DELETE): Define for Embarcadero\n(formerly known as Borland) C++ compiler v6.21+.\n* include/gc_cpp.h (GC_NO_OPERATOR_NEW_ARRAY): Define for ancient\nVC++ compilers.\n\n* win32_threads.c (GC_register_my_thread_inner,\nGC_pthread_start_inner): Undo the previous commit changes for\nthe thread flags and DETACHED state (since the state is only\ntested in GC_thread_exit_proc).\n\n* include/gc.h (GC_unregister_my_thread): Fix a typo; update the\ncomment.\n* pthread_support.c (GC_delete_thread): Allow to delete the main\nthread (don't call GC_INTERNAL_FREE for it); update the comment.\n* win32_threads.c (GC_delete_thread): Likewise.\n* pthread_support.c (GC_unregister_my_thread): Add an assertion\nfor FINISHED flag is unset.\n* tests/test.c (check_heap_stats): Test the main thread\nunregistering (only if THREADS).\n* win32_threads.c (GC_register_my_thread_inner): Set flags to\nDETACHED (only if GC_PTHREADS).\n* win32_threads.c (GC_unregister_my_thread): Add FIXME (for\nGC_wait_for_gc_completion).\n* win32_threads.c (GC_pthread_start_inner): Clear flags detached\nstate if needed; set pthread_id and flags while holding the lock.\n\n* include/private/gc_priv.h (SIG_SUSPEND): Don't define for\nOpenBSD and Darwin.\n\n* include/gc.h: Recognize _M_X64 (as an alias for _AMD64_).\n\n* test.c (main, WinMain): Consistently don't invoke\nGC_enable_incremental() if MAKE_BACKGRAPH is defined, but\ndo invoke it even if parallel marking is enabled.\n\n* tests/test.c (reverse_test): Comment out a check for MSWIN32\n(when determining BIG value) assuming outdated win32s.\n* tests/test.c (reverse_test): Rename to reverse_test_inner;\nchange the declaration (to be of GC_fn_type); call itself thru\nGC_call_with_gc_active() if the argument is zero.\n* tests/test.c (reverse_test): New function added calling\nreverse_test_inner thru GC_do_blocking (to test GC_do_blocking and\nGC_call_with_gc_active).\n\n* doc/README.macros (IGNORE_DYNAMIC_LOADING, PLATFORM_ANDROID):\nDocument.\n* dyn_load.c: Don't include <elf.h> if PLATFORM_ANDROID.\n* dyn_load.c: Include bionic <linker.h> (instead of <link.h>) if\nPLATFORM_ANDROID.\n* include/private/gcconfig.h (LINUX): Define also if\nPLATFORM_ANDROID (for the windows-based toolkit).\n* include/private/gcconfig.h (SEARCH_FOR_DATA_START): Explicitly\ndefine for Android/x86 platform.\n* include/private/gcconfig.h (IGNORE_DYNAMIC_LOADING): Recognize\nnew macro (undefine DYNAMIC_LOADING in this case).\n* include/private/gcconfig.h (CANCEL_SAFE): Don't define if\nPLATFORM_ANDROID.\n* include/private/gcconfig.h (IF_CANCEL): Fix definition for the\nexplicitly defined CANCEL_SAFE.\n\n* allchblk.c (GC_allochblk_nth): Don't call GC_remove_protection()\nif GC_DISABLE_INCREMENTAL.\n* reclaim.c (GC_reclaim_generic): Likewise.\n* checksums.c (GC_page_was_ever_dirty): Add prototype.\n* include/private/gc_locks.h (GC_mark_lock_holder): Don't declare\nunless PARALLEL_MARK.\n* include/private/gc_priv.h (GC_dirty_maintained,\nGC_page_was_dirty, GC_remove_protection, GC_dirty_init): Don't\ndeclare if GC_DISABLE_INCREMENTAL.\n* include/private/gc_priv.h (GC_print_finalization_stats): Don't\ndeclare if SMALL_CONFIG.\n* include/private/gcconfig.h (CHECKSUMS): Explicitly undefine if\nGC_DISABLE_INCREMENTAL (since nothing to check).\n* include/private/gcconfig.h (DEFAULT_VDB): Don't define if\nGC_DISABLE_INCREMENTAL.\n* os_dep.c (GC_dirty_maintained): Likewise.\n* mark.c (GC_initiate_gc): Don't call GC_read_dirty() if\nGC_DISABLE_INCREMENTAL.\n* os_dep.c (GC_gww_page_was_ever_dirty, GC_page_was_ever_dirty):\nUncomment; define only if CHECKSUMS.\n\n* darwin_stop_world.c (GC_push_all_stacks): Fix a bug (call\nGC_push_all_stack() instead of GC_push_all_stack_frames()).\n* include/private/gc_priv.h (GC_push_all_stack_frames,\nGC_push_all_register_frames): Rename to\nGC_push_all_stack_sections and GC_push_all_register_sections,\nrespectively.\n* mark_rts.c (GC_push_all_stack_frames,\nGC_push_all_register_frames, GC_push_all_stack_part_eager_frames,\nGC_push_current_stack): Likewise.\n* pthread_stop_world.c (GC_push_all_stacks): Likewise.\n* win32_threads.c (GC_push_stack_for): Likewise.\n* misc.c (GC_call_with_gc_active): Rename \"frame\" local variable\nto \"stacksect\".\n* pthread_support.c (GC_call_with_gc_active): Likewise.\n* win32_threads.c (GC_call_with_gc_active): Likewise.\n* pthread_support.c (GC_call_with_gc_active): Update FIXME for\nDarwin.\n* win32_threads.c (GC_Thread_Rep): Update the comment for\ntraced_stack_sect.\n\n* darwin_stop_world.c (GC_push_all_stacks): Rename\nactivation_frame to traced_stack_sect.\n* include/private/gc_priv.h (GC_push_all_stack_frames,\nGC_push_all_register_frames): Likewise.\n* include/private/pthread_support.h (GC_Thread_Rep): Likewise.\n* mark_rts.c (GC_push_all_register_frames,\nGC_push_all_stack_frames, GC_push_all_stack_part_eager_frames,\nGC_push_current_stack): Likewise.\n* pthread_stop_world.c (GC_push_all_stacks): Likewise.\n* pthread_support.c (GC_call_with_gc_active): Likewise.\n* win32_threads.c (GC_Thread_Rep, GC_call_with_gc_active,\nGC_push_stack_for): Likewise.\n* include/private/gc_priv.h (GC_activation_frame_s): Rename to\nGC_traced_stack_sect_s.\n* include/private/gc_priv.h (GC_activation_frame): Rename to\nGC_traced_stack_sect.\n* misc.c (GC_activation_frame, GC_call_with_gc_active): Likewise.\n* doc/README.macros (UNICODE): Document.\n\n* doc/README.macros (GC_READ_ENV_FILE): Document (new macro).\n* include/private/gc_priv.h (GETENV): Recognize GC_READ_ENV_FILE;\ndeclare and use GC_envfile_getenv().\n* misc.c (GC_envfile_content, GC_envfile_length): New static\nvariable (only if GC_READ_ENV_FILE).\n* misc.c (GC_ENVFILE_MAXLEN): New macro (used in GC_envfile_init).\n* misc.c (GC_envfile_init, GC_envfile_getenv): New function (only\nif GC_READ_ENV_FILE).\n* misc.c (GC_init): Call GC_envfile_init() (before using GETENV)\nif GC_READ_ENV_FILE.\n* misc.c (GC_init): Move GC_setpagesize() and GC_init_win32()\ncalls to be just before GC_envfile_init() one (since the latter\nuses GET_MEM).\n* misc.c (GC_abort): use ExitProcess() (instead of DebugBreak) for\nWinCE if NO_DEBUGGING; add a comment for DebugBreak() (for WinCE).\n* mark_rts.c (GC_add_roots_inner): Remove redundant trailing '\\n'\nfrom the ABORT message.\n* misc.c (GC_init): Likewise.\n* os_dep.c (GC_get_main_stack_base, GC_register_data_segments):\nLikewise.\n* pthread_stop_world.c (GC_push_all_stacks): Likewise.\n* pthread_support.c (GC_init_real_syms, start_mark_threads):\nLikewise.\n\n* win32_threads.c (GC_get_next_stack): Don't define for Cygwin\n(since unused for now).\n\n* dyn_load.c (HAVE_REGISTER_MAIN_STATIC_DATA): Don't define unless\nGC_register_main_static_data() is defined.\n* dyn_load.c (GC_register_dynamic_libraries): Define only if used\n(if DYNAMIC_LOADING or PCR or Win32/CE).\n* dyn_load.c (GC_register_main_static_data): Define the default\none only if DYNAMIC_LOADING.\n* include/private/gc_priv.h (GC_register_dynamic_libraries):\nDeclare only if used (to prevent compiler warning).\n\n* mark_rts.c (GC_approx_sp): Add a comment (for GCC).\n\n\n== [7.2alpha4] 2009-12-01 ==\n\n* configure.ac (AC_CONFIG_COMMANDS): Quote srcdir value.\n\n* include/gc.h (GC_get_suspend_signal): New function declaration.\n* misc.c (GC_get_suspend_signal): New API function (only if\nTHREADS).\n\n* alloc.c (min_bytes_allocd): Multiply GC_free_space_divisor by\ntwo if GC_incremental (instead of TRUE_INCREMENTAL).\n\n* sparc_mach_dep.S (GC_push_regs): Remove the reference.\n\n* os_dep.c (SIZE_T, PULONG_PTR): Remove.\n* os_dep.c (ULONG_PTR): Replace with GC_ULONG_PTR (defined as GC\n\"word\"); add the comment.\n* os_dep.c (GetWriteWatch_type, detect_GetWriteWatch,\nGC_gww_read_dirty): Prefix ULONG_PTR with \"GC_\".\n\n* win32_threads.c (THREAD_TABLE_SZ): Change back to a power-of-two\nconst value (for speed).\n* win32_threads.c (THREAD_TABLE_INDEX): New macro.\n* win32_threads.c (GC_new_thread, GC_lookup_thread_inner,\nGC_delete_gc_thread, GC_delete_thread, GC_lookup_pthread): Use\nTHREAD_TABLE_INDEX instead of THREAD_TABLE_SZ.\n* win32_threads.c (PTHREAD_MAP_HASH): Rename to PTHREAD_MAP_INDEX.\n\n* win32_threads.c (THREAD_TABLE_SZ): Make the const value prime.\n\n* backgraph.c: Remove apostrophe char from \"#error\".\n\n* doc/README.macros (GC_DISABLE_INCREMENTAL): Document.\n* include/private/gcconfig.h (GC_DISABLE_INCREMENTAL): Recognize\nnew macro; implicitly define it if SMALL_CONFIG.\n* alloc.c (GC_incremental, GC_timeout_stop_func): Check for\nGC_DISABLE_INCREMENTAL instead of SMALL_CONFIG.\n* include/private/gc_priv.h (GC_incremental, TRUE_INCREMENTAL,\nGC_push_conditional): Likewise.\n* mark.c (GC_push_next_marked_dirty, GC_push_selected,\nGC_push_conditional, GC_block_was_dirty): Likewise.\n* misc.c (GC_enable_incremental): Likewise.\n* misc.c (GC_init): Likewise.\n\n* dyn_load.c (WIN32_LEAN_AND_MEAN): Guard with ifndef.\n* misc.c (WIN32_LEAN_AND_MEAN): Likewise.\n* os_dep.c (WIN32_LEAN_AND_MEAN): Likewise.\n* allchblk.c (GC_allochblk_nth): Fix a minor typo (don't/doesn't)\nin a comment.\n* backgraph.c: Likewise.\n* dyn_load.c (GC_register_dynamic_libraries): Likewise.\n* extra/threadlibs.c (main): Likewise.\n* pthread_support.c (pthread_join): Likewise.\n* tests/test.c (main): Likewise.\n\n* mach_dep.c (GC_push_regs): Remove STATIC (just to catch\na duplicate symbol definition linker error).\n* misc.c (GC_clear_stack_inner): Likewise.\n* sparc_mach_dep.S (GC_push_regs): Comment out the reference.\n\n* include/private/gc_priv.h (GC_write_disabled): New variable\ndeclaration (only if GC_ASSERTIONS and Win32 threads).\n* misc.c (GC_write): Add assertion for GC_write_disabled value is\nnot on (only if THREADS).\n* win32_threads.c (GC_write_disabled): New variable (only if\nGC_ASSERTIONS and not Cygwin).\n* win32_threads.c (GC_stop_world): Set and clear GC_write_disabled\n(while holding GC_write_cs).\n\n* win32_threads.c (GC_please_stop): If DllMain-based thread\nregistration is not compiled in then define GC_please_stop as\na non-volatile variable for assertion only.\n* win32_threads.c (GC_stop_world): Set and clear only if defined.\n* win32_threads.c (GC_stop_world): Add the comment for GC_printf()\nusage (while holding GC_write_cs).\n* win32_threads.c (GC_delete_gc_thread): Likewise.\n* os_dep.c (GC_remove_protection): Likewise.\n\n* pthread_support.c (GC_inner_start_routine): Join 3 sequential\nGC_printf() calls into a single one (for DEBUG_THREADS).\n\n* include/private/gc_priv.h (GC_total_stacksize): New variable\ndeclaration (only if THREADS).\n* alloc.c (GC_total_stacksize): New variable (only if THREADS).\n* alloc.c (min_bytes_allocd): Calculate stack_size using\nGC_stackbottom only in the single-threaded case; otherwise use\nGC_total_stacksize; print GC_total_stacksize value if\nDEBUG_THREADS.\n* darwin_stop_world.c (GC_push_all_stacks): Use \"%p\" printf type\nspecifier for lo/hi values (instead of \"%lx\").\n* darwin_stop_world.c (GC_push_all_stacks): Use\nGC_push_all_stack_frames() instead of GC_push_all_stack().\n* darwin_stop_world.c (GC_push_all_stacks): Recalculate\nGC_total_stacksize value.\n* pthread_stop_world.c (GC_push_all_stacks): Likewise.\n* win32_threads.c (GC_push_all_stacks): Likewise.\n* win32_threads.c (GC_push_stack_for): Pass \"me\" argument; return\nstack size; don't check for non-zero value of thread->stack_base.\n* win32_threads.c (GC_push_all_stacks): Don't call\nGC_push_stack_for() and don't check for \"t->id == me\" if\nthread->stack_base is zero.\n\n* dyn_load.c (GC_dump_meminfo): Prefix \"%lx\" printf type specifier\nwith \"0x\".\n* os_dep.c (PROTECT): Likewise.\n* win32_threads.c (GC_mark_thread_local_free_lists): Cast p->id to\nint (to match printf type specifier).\n\n* tests/test.c (check_heap_stats): Take into account the unmapped\nmemory size when checking for \"Unexpected heap growth\"; remove\nFIXME.\n\n* alloc.c: Revert last change.\n\n* include/private/gcconfig.h (STACKBOTTOM): Add a presence check\nfor eCos/NOSYS.\n* misc.c (GC_write): Comment out _Jv_diag_write() call (since no\nlonger defined in GCJ).\n\n* os_dep.c (brk): Rename to ecos_gc_brk.\n\n* alloc.c (min_bytes_allocd): Use GC_stackbottom value to compute\nstack_size even if THREADS.\n* doc/README.macros (DEBUG_THREADS): Document.\n* pthread_support.c (DEBUG_THREADS): Remove the commented out\ndefinition.\n* win32_threads.c (DEBUG_WIN32_THREADS): Remove duplicate\ndefinition.\n* win32_threads.c: Include errno.h (except for WinCE).\n* win32_threads.c (GC_win32_start_inner): Copy \"start\" and \"param\"\nto local variables, and free \"arg\" parameter before \"start\"\ninvocation.\n* win32_threads.c (GC_beginthreadex): Set errno to EAGAIN on error\n(instead of calling SetLastError(ERROR_NOT_ENOUGH_MEMORY)).\n* win32_threads.c (GC_beginthreadex): Return 0 on error (instead\nof -1).\n\n* darwin_stop_world.c (GC_darwin_register_mach_handler_thread):\nUse GC_INNER for the function definition.\n* include/private/darwin_stop_world.h\n(GC_darwin_register_mach_handler_thread): Remove the prototype.\n* os_dep.c (GC_darwin_register_mach_handler_thread): Use GC_INNER\nfor the function prototype.\n* include/private/gc_priv.h (NDEBUG): Explicitly define if\nNO_DEBUGGING and not GC_ASSERTIONS (before the standard headers\ninclusion).\n\n* include/private/gcconfig.h: Move DebugBreak() workaround (for\nx86mingw32ce toolchain) to gc_priv.h (after windows.h inclusion).\n\n* allchblk.c (GC_unmap_old, GC_merge_unmapped, GC_allochblk,\nGC_freehblk): Use GC_INNER for the function definition.\n* alloc.c (GC_never_stop_func, GC_should_collect,\nGC_try_to_collect_inner, GC_collect_a_little_inner,\nGC_set_fl_marks, GC_add_to_our_memory, GC_add_to_heap,\nGC_expand_hp_inner, GC_collect_or_expand, GC_allocobj): Likewise.\n* backgraph.c (GC_build_back_graph, GC_traverse_back_graph):\nLikewise.\n* blacklst.c (GC_default_print_heap_obj_proc, GC_bl_init,\nGC_promote_black_lists, GC_unpromote_black_lists,\nGC_add_to_black_list_normal, GC_add_to_black_list_stack,\nGC_is_black_listed): Likewise.\n* darwin_stop_world.c (GC_push_all_stacks, GC_push_all_stacks,\nGC_stop_init, GC_stop_world, GC_start_world): Likewise.\n* dbg_mlc.c (GC_has_other_debug_info, GC_store_back_pointer,\nGC_marked_for_finalization, GC_generate_random_backtrace_no_gc,\nGC_store_debug_info, GC_start_debugging,\nGC_debug_generic_malloc_inner,\nGC_debug_generic_malloc_inner_ignore_off_page,\nGC_debug_malloc_uncollectable, GC_debug_free_inner): Likewise.\n* dyn_load.c (GC_register_dynamic_libraries,\nGC_register_main_static_data, GC_init_dyld): Likewise.\n* finalize.c (GC_push_finalizer_structures, GC_finalize,\nGC_notify_or_invoke_finalizers, GC_print_finalization_stats):\nLikewise.\n* gcj_mlc.c (GC_core_gcj_malloc): Likewise.\n* headers.c (GC_find_header, GC_header_cache_miss,\nGC_scratch_alloc, GC_init_headers, GC_install_header,\nGC_install_counts, GC_remove_header, GC_remove_counts,\nGC_next_used_block, GC_prev_block): Likewise.\n* mach_dep.c (GC_with_callee_saves_pushed): Likewise.\n* malloc.c (GC_collect_or_expand, GC_alloc_large,\nGC_generic_malloc_inner, GC_generic_malloc_inner_ignore_off_page,\nGC_core_malloc_atomic, GC_core_malloc, GC_free_inner): Likewise.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Likewise.\n* mark.c (GC_collection_in_progress, GC_clear_hdr_marks,\nGC_set_hdr_marks, GC_set_mark_bit, GC_clear_mark_bit,\nGC_clear_marks, GC_initiate_gc, GC_mark_some,\nGC_mark_stack_empty, GC_invalidate_mark_state,\nGC_signal_mark_stack_overflow, GC_mark_from, GC_help_marker,\nGC_mark_init, GC_push_all, GC_push_conditional,\nGC_mark_and_push_stack, GC_push_all_eager, GC_push_all_stack):\nLikewise.\n* mark_rts.c (GC_is_static_root, GC_roots_present, GC_approx_sp,\nGC_exclude_static_roots_inner, GC_push_all_register_frames,\nGC_push_all_stack_frames, GC_cond_register_dynamic_libraries,\nGC_push_roots): Likewise.\n* misc.c (GC_extend_size_map, GC_clear_stack, GC_err_write):\nLikewise.\n* new_hblk.c (GC_build_fl, GC_new_hblk): Likewise.\n* obj_map.c (GC_register_displacement_inner, GC_add_map_entry,\nGC_initialize_offsets): Likewise.\n* os_dep.c (GC_get_maps, GC_parse_map_entry, GC_text_mapping,\nGC_init_linux_data_start, GC_init_netbsd_elf, GC_setpagesize,\nGC_set_and_save_fault_handler, GC_setup_temporary_fault_handler,\nGC_reset_fault_handler, GC_get_register_stack_base, GC_init_win32,\nGC_add_current_malloc_heap, GC_is_heap_base, GC_unmap, GC_remap,\nGC_unmap_gap, GC_push_all_stacks, GC_gww_dirty_init,\nGC_dirty_init, GC_read_dirty, GC_page_was_dirty,\nGC_page_was_ever_dirty, GC_remove_protection,\nGC_write_fault_handler, GC_mprotect_stop, GC_mprotect_resume,\nGC_save_callers, GC_print_callers): Likewise.\n* pthread_stop_world.c (GC_push_all_stacks, GC_stop_world,\nGC_start_world, GC_stop_init): Likewise.\n* pthread_support.c (GC_mark_thread_local_free_lists,\nGC_lookup_thread, GC_reset_finalizer_nested,\nGC_check_finalizer_nested, GC_segment_is_thread_stack,\nGC_greatest_stack_base_below, GC_thr_init, GC_init_parallel,\nGC_do_blocking_inner, GC_lock, GC_acquire_mark_lock,\nGC_release_mark_lock, GC_wait_for_reclaim, GC_notify_all_builder,\nGC_wait_marker, GC_notify_all_marker): Likewise.\n* reclaim.c (GC_print_all_errors, GC_block_empty,\nGC_reclaim_generic, GC_start_reclaim, GC_continue_reclaim,\nGC_reclaim_all): Likewise.\n* thread_local_alloc.c (GC_init_thread_local,\nGC_destroy_thread_local, GC_mark_thread_local_fls_for): Likewise.\n* win32_threads.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested, GC_do_blocking_inner, GC_stop_world,\nGC_start_world, GC_push_all_stacks, GC_get_next_stack,\nGC_acquire_mark_lock, GC_release_mark_lock, GC_wait_for_reclaim,\nGC_notify_all_builder, GC_wait_marker, GC_notify_all_marker,\nGC_thr_init, GC_init_parallel, GC_lock,\nGC_mark_thread_local_free_lists): Likewise.\n* alloc.c (GC_add_current_malloc_heap, GC_build_back_graph,\nGC_traverse_back_graph): Use GC_INNER for the function prototype.\n* darwin_stop_world.c (GC_mprotect_stop, GC_mprotect_resume):\nLikewise.\n* dbg_mlc.c (GC_default_print_heap_obj_proc): Likewise.\n* dyn_load.c (GC_parse_map_entry, GC_get_maps,\nGC_segment_is_thread_stack, GC_roots_present, GC_is_heap_base,\nGC_get_next_stack): Likewise.\n* finalize.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested): Likewise.\n* gcj_mlc.c (GC_start_debugging): Likewise.\n* include/private/dbg_mlc.h (GC_save_callers, GC_print_callers,\nGC_has_other_debug_info, GC_store_debug_info): Likewise.\n* include/private/gc_hdrs.h (GC_header_cache_miss): Likewise.\n* include/private/gc_locks.h (GC_lock): Likewise.\n* include/private/gc_pmark.h (GC_signal_mark_stack_overflow,\nGC_mark_from): Likewise.\n* include/private/pthread_support.h (GC_lookup_thread,\nGC_stop_init): Likewise.\n* include/private/thread_local_alloc.h (GC_init_thread_local,\nGC_destroy_thread_local, GC_mark_thread_local_fls_for): Likewise.\n* malloc.c (GC_extend_size_map, GC_text_mapping): Likewise.\n* mark.c (GC_page_was_ever_dirty): Likewise.\n* mark_rts.c (GC_mark_thread_local_free_lists): Likewise.\n* misc.c (GC_register_main_static_data, GC_init_win32,\nGC_setpagesize, GC_init_linux_data_start,\nGC_set_and_save_fault_handler, GC_init_dyld, GC_init_netbsd_elf,\nGC_do_blocking_inner): Likewise.\n* os_dep.c (GC_greatest_stack_base_below): Likewise.\n* win32_threads.c (GC_write_fault_handler, GC_gww_dirty_init):\nLikewise.\n* include/private/gc_priv.h: Likewise.\n* include/private/gc_priv.h (GC_INNER): Update the comment.\n* doc/README.macros (GC_DLL): Update.\n\n* alloc.c (GC_collection_in_progress): Move the prototype to\ngc_priv.h.\n* gc_dlopen.c (GC_collection_in_progress): Likewise.\n* pthread_support.c (GC_collection_in_progress): Likewise.\n* misc.c (GC_init_parallel): Likewise.\n* pthread_support.c (GC_init_parallel): Likewise.\n* win32_threads.c (GC_init_parallel): Likewise.\n* darwin_stop_world.c (GC_thr_init): Likewise.\n* misc.c (GC_thr_init): Likewise.\n* pthread_stop_world.c (GC_thr_init): Likewise.\n* pthread_support.c (GC_thr_init): Likewise.\n* blacklst.c (GC_clear_bl, GC_copy_bl,\nGC_number_stack_black_listed): Make STATIC.\n* dbg_mlc.c (GC_print_obj, GC_make_closure,\nGC_debug_invoke_finalizer): Likewise.\n* malloc.c (GC_alloc_large_and_clear): Likewise.\n* mark.c (GC_push_selected, GC_push_marked1, GC_push_marked2,\nGC_push_marked4, GC_push_marked, GC_push_next_marked,\nGC_push_next_marked_dirty, GC_push_next_marked_uncollectable):\nLikewise.\n* misc.c (GC_clear_stack_inner): Likewise.\n* os_dep.c (GC_repeat_read, GC_default_push_other_roots): Likewise.\n* darwin_stop_world.c (FindTopOfStack): Make static; define only\nif not DARWIN_DONT_PARSE_STACK.\n* dbg_mlc.c (GC_debug_free_inner): Define only if DBG_HDRS_ALL.\n* dyn_load.c (GC_repeat_read): Remove unused prototype.\n* include/private/gc_pmark.h (GC_find_start): Likewise.\n* misc.c (GC_read, GC_register_finalizer_no_order): Likewise.\n* dyn_load.c (GC_segment_is_thread_stack): Add prototype (only if\nTHREADS).\n* dyn_load.c (GC_register_main_static_data): Define only if\nDYNAMIC_LOADING.\n* finalize.c (GC_enqueue_all_finalizers): Remove unnecessary tail\n\"return\" statement.\n* gc_dlopen.c (GC_SOLARIS_THREADS): Don't recognize (since implies\nGC_PTHREADS).\n* include/gc.h: Fix a typo.\n* include/gc_inline.h (GC_ASSERT): Define (if not defined) since\nthe header is public.\n* include/gc_inline.h (GC_generic_malloc_many): New public\nfunction declaration.\n* mallocx.c (GC_generic_malloc_many): Make public.\n* include/private/gc_priv.h (GC_INNER): Use visibility attribute\n(if available).\n* include/private/gc_priv.h (GC_EXTERN): Define using GC_INNER.\n* include/private/gc_priv.h: Include atomic_ops.h if THREADS and\nMPROTECT_VDB.\n* os_dep.c: Don't include atomic_ops.h\n* win32_threads.c: Likewise.\n* include/private/gc_priv.h (GC_push_selected, GC_push_regs,\nGC_push_marked, GC_number_stack_black_listed,\nGC_alloc_large_and_clear, GC_reclaim_or_delete_all,\nGC_generic_malloc_many, GC_make_closure,\nGC_debug_invoke_finalizer, GC_print_obj, GC_page_was_ever_dirty):\nRemove the prototype.\n* mark.c (GC_page_was_ever_dirty): Add prototype (only if\nPROC_VDB).\n* include/private/gc_priv.h (GC_push_next_marked_dirty,\nGC_push_next_marked, GC_push_next_marked_uncollectable): Move\nthe prototype to mark.c.\n* include/private/gc_priv.h (GC_is_static_root): Declare only if\nnot THREADS.\n* include/private/gc_priv.h (GC_free_inner): Declare only if\nTHREADS.\n* include/private/gc_priv.h (GC_debug_free_inner): Declare only if\nTHREADS and DBG_HDRS_ALL.\n* include/private/gc_priv.h (GC_markers): Declare GC_markers only\nif PARALLEL_MARK.\n* include/private/gc_priv.h (GC_register_main_static_data): Move\nthe prototype to misc.c.\n* mach_dep.c (GC_push_regs): Make STATIC; define only along with\nHAVE_PUSH_REGS definition.\n* mach_dep.c (GC_clear_stack_inner): Replace K&R-style function\ndefinition with the ANSI C one.\n* mark.c (GC_started_thread_while_stopped): Declared only if not\nGNU C.\n* win32_threads.c (GC_started_thread_while_stopped): Don't define\nif GNU C.\n* mark.c (GC_mark_from): Avoid unbalanced brackets in\n#if-#else-#endif blocks.\n* mark_rts.c (GC_is_static_root): Define only if not THREADS.\n* os_dep.c (GC_get_stack_base): Make public (for OpenBSD).\n* os_dep.c (GC_page_was_ever_dirty): Comment out the function\nexcept for PROC_VDB.\n* tests/test.c (main): Don't reference GC_print_obj,\nGC_make_closure, GC_debug_invoke_finalizer,\nGC_page_was_ever_dirty, GC_is_fresh (in GC_noop).\n* thread_local_alloc.c: Don't include \"gc_inline.h\".\n* win32_threads.c (GC_write_fault_handler): Declare only if\nMPROTECT_VDB.\n\n* allchblk.c (DEBUG): Remove macro (since unused).\n* allchblk.c: Include private/gc_priv.h before other includes and\ndefinitions.\n* alloc.c: Likewise.\n* gc_dlopen.c: Likewise.\n* headers.c: Likewise.\n* mallocx.c: Likewise.\n* mark_rts.c: Likewise.\n* new_hblk.c: Likewise.\n* reclaim.c: Likewise.\n* mark.c: Include private/gc_pmark.h before other includes.\n* misc.c: Likewise.\n* dyn_load.c (_GNU_SOURCE): Move the definition to gc_priv.h.\n* pthread_support.c (_USING_POSIX4A_DRAFT10): Likewise.\n* pthread_support.c (_POSIX4A_DRAFT10_SOURCE): Remove (since\nalready defined in gc_config_macros.h).\n* dyn_load.c (GC_init_dyld): Remove parameter cast for\n_dyld_register_func_for_add_image() and\n_dyld_register_func_for_remove_image(); add the comment about\npossible warnings; add FIXME for the deprecated\n_dyld_bind_fully_image_containing_address().\n* include/private/gc_priv.h: Include gc.h before the standard\nheaders inclusion.\n* tests/test.c: Likewise.\n* include/private/gcconfig.h (DebugBreak): Update the comment.\n* typd_mlc.c (ED_INITIAL_SIZE): Remove ';'.\n\n* configure.ac (openbsd): Define GC_OPENBSD_THREADS.\n* configure.ac: Add AM_CONDITIONAL(OPENBSD_THREADS).\n* configure.ac: Add sparc-openbsd case.\n* doc/README.macros (GC_NETBSD_THREADS, GC_OPENBSD_THREADS):\nDocument.\n* tests/test.c (main): Handle OpenBSD case.\n* include/private/pthread_stop_world.h: Likewise.\n* extra/threadlibs.c (main): Replace K&R-style function definition\nwith the ANSI C one.\n* extra/threadlibs.c (main): Handle GC_OPENBSD_THREADS case.\n* dyn_load.c (OPENBSD): Recognize (similar to NETBSD).\n* include/gc_config_macros.h (GC_SOLARIS_THREADS): Recognize;\ndefine it for OpenBSD.\n* include/gc_pthread_redirects.h (GC_pthread_sigmask,\npthread_sigmask): Don't declare and redefine for OpenBSD.\n* include/private/gcconfig.h: Handle OpenBSD (on arm, sh, x86,\nx64, powerpc).\n* mach_dep.c (NO_GETCONTEXT): Likewise.\n* include/private/pthread_stop_world.h (thread_stop_info): Don't\ndefine last_stop_count field if OpenBSD.\n* misc.c (GC_init_dyld): Add declaration (if NetBSD).\n* misc.c (GC_init): Don't call GC_init_netbsd_elf() for OpenBSD.\n* os_dep.c (GC_init_netbsd_elf): Don't define for OpenBSD.\n* os_dep.c (old_segv_act, GC_jmp_buf_openbsd): New static variable\n(only if OpenBSD).\n* os_dep.c (GC_fault_handler_openbsd, GC_find_limit_openbsd,\nGC_skip_hole_openbsd): New static function (only if OpenBSD).\n* os_dep.c (GC_get_stack_base, GC_get_main_stack_base,\nGC_register_data_segments): Define specially for OpenBSD case.\n* os_dep.c (GC_fault_handler_lock): Initialize to\nAO_TS_INITIALIZER (instead of 0).\n* pthread_support.c (GC_allocate_lock): Likewise.\n* pthread_stop_world.c (NSIG, GC_print_sig_mask,\nGC_remove_allowed_signals, suspend_handler_mask, GC_stop_count,\nGC_world_is_stopped, GC_retry_signals, SIG_THR_RESTART,\nGC_suspend_ack_sem, GC_suspend_handler_inner, GC_suspend_handler,\nGC_restart_handler): Don't define and use if OpenBSD.\n* pthread_stop_world.c (GC_suspend_all, GC_stop_world,\nGC_start_world): Handle OpenBSD case.\n* pthread_stop_world.c (GC_stop_init): Define as empty if OpenBSD.\n* pthread_support.c (pthread_sigmask): Don't undefine the macro and\ndon't define the wrapper function if OpenBSD.\n* pthread_support.c (GC_thr_init): Handle OpenBSD case.\n\n* dyn_load.c: Move the inclusion of private/gc_priv.h below\ndefinition of a feature macro (_GNU_SOURCE).\n\n* include/gc.h (REVEAL_POINTER): Remove redundant parentheses.\n* include/gc.h (GC_HIDE_POINTER, GC_REVEAL_POINTER): New macros\n(only if GC_I_HIDE_POINTERS).\n* backgraph.c (GET_OH_BG_PTR): Prefix REVEAL_POINTER() with \"GC_\".\n* dbg_mlc.c (GC_get_back_ptr_info): Likewise.\n* finalize.c (GC_grow_table, GC_dump_finalization, GC_finalize,\nGC_enqueue_all_finalizers): Likewise.\n* backgraph.c (SET_OH_BG_PTR): Prefix HIDE_POINTER() with \"GC_\".\n* finalize.c (GC_general_register_disappearing_link,\nGC_unregister_disappearing_link, GC_register_finalizer_inner,\nGC_finalize): Likewise.\n* include/private/dbg_mlc.h (HIDE_BACK_PTR): Likewise.\n* include/private/dbg_mlc.h (GC_I_HIDE_POINTERS): Define instead\nof I_HIDE_POINTERS.\n* include/private/gc_priv.h (GC_I_HIDE_POINTERS): Likewise.\n* include/gc.h (_GC_H): Strip leading underscore.\n* include/gc_backptr.h (_GC_H): Likewise.\n* include/gc_gcj.h (_GC_H): Likewise.\n* include/gc_mark.h (_GC_H): Likewise.\n* include/gc_typed.h (_GC_TYPED_H, _GC_H): Likewise.\n* include/javaxfc.h (_GC_H): Likewise.\n* include/new_gc_alloc.h (__GC_SPECIALIZE): Likewise.\n* include/private/dbg_mlc.h (_GC_H): Likewise.\n* include/private/gc_priv.h (_GC_H): Likewise.\n\n* gc_cpp.cc: Include \"gc_cpp.h\" instead of <gc_cpp.h>.\n\n* include/private/gc_priv.h (GC_INNER): New macro (for GC-scope\nvariable definitions).\n* include/private/gc_priv.h (GC_EXTERN): Update the comment.\n* allchblk.c (GC_unmap_threshold): Define as GC_INNER.\n* alloc.c (GC_incremental, GC_world_stopped, GC_n_heap_sects,\nGC_n_memory, GC_fail_count): Likewise.\n* blacklst.c (GC_black_list_spacing, GC_print_heap_obj): Likewise.\n* gcj_mlc.c (GC_gcj_malloc_initialized, GC_gcjobjfreelist): Likewise.\n* mach_dep.c (GC_save_regs_ret_val): Likewise.\n* mark.c (GC_n_mark_procs, GC_obj_kinds, GC_n_kinds,\nGC_mark_stack, GC_mark_stack_limit, GC_mark_stack_size,\nGC_mark_stack_top, GC_mark_state, GC_mark_stack_too_small,\nGC_mark_no, GC_markers): Likewise.\n* mark_rts.c (GC_root_size, GC_push_typed_structures): Likewise.\n* misc.c (GC_allocate_ml, GC_debugging_started, GC_check_heap,\nGC_print_all_smashed, GC_print_back_height, GC_dump_regularly,\nGC_backtraces, GC_force_unmap_on_gcollect,\nGC_large_alloc_warn_interval, GC_is_initialized, GC_write_cs,\nGC_current_warn_proc, GC_blocked_sp, GC_activation_frame): Likewise.\n* os_dep.c (GC_page_size, GC_dont_query_stack_min,\nGC_no_win32_dlls, GC_wnt, GC_sysinfo, GC_push_other_roots,\nGC_dirty_maintained, GC_fault_handler_lock): Likewise.\n* pthread_support.c (GC_allocate_ml, GC_lock_holder,\nGC_need_to_lock, GC_thr_initialized, GC_threads,\nGC_in_thread_creation, GC_collecting, GC_allocate_lock,\nGC_mark_lock_holder): Likewise.\n* reclaim.c (GC_bytes_found, GC_fl_builder_count, GC_have_errors):\nLikewise.\n* win32_threads.c (GC_allocate_ml, GC_lock_holder,\nGC_need_to_lock, GC_mark_lock_holder, GC_collecting): Likewise.\n* extra/gc.c (GC_INNER, GC_EXTERN): Define as STATIC.\n* mach_dep.c (GC_with_callee_saves_pushed): Remove redundant {}.\n\n* include/private/gc_priv.h (GC_bytes_allocd, GC_objfreelist,\nGC_aobjfreelist): Replace GC_EXTERN to extern for SEPARATE_GLOBALS\ncase (since they are not defined inside GC at present).\n* include/private/gc_priv.h (GC_objects_are_marked): Remove the\ndeclaration (since made static).\n* mark.c (GC_objects_are_marked): Define as STATIC.\n* win32_threads.c (GC_thr_initialized, GC_in_thread_creation):\nLikewise.\n* mark.c (GC_N_KINDS_INITIAL_VALUE): New macro (defined and used\nto initialize GC_n_kinds).\n* win32_threads.c (start_mark_threads): Adjust the comment.\n\n* alloc.c (GC_notify_full_gc): Use GC_INLINE for a tiny static\nfunction.\n* backgraph.c (pop_in_progress, GC_apply_to_each_object): Likewise.\n* mark_rts.c (add_roots_to_index): Likewise.\n\n* extra/gc.c: New file.\n* Makefile.am (EXTRA_DIST): Add \"extra/gc.c\".\n\n* misc.c (GC_log): Remove the declaration; move the definition (to\nthe place where it is used); make STATIC.\n* misc.c (GC_init): Use GC_err_printf() instead of GC_log_printf()\nto print open log failure.\n* misc.c (GC_write): Don't abort on open log failure if the GC is\ncompiled with GC_PRINT_VERBOSE_STATS (useful for WinCE).\n\n* include/private/gcconfig.h (USE_MMAP): Guard with ifndef.\n\n* allchblk.c (GC_fail_count, GC_large_alloc_warn_interval): Move\nthe variable declaration to gc_priv.h.\n* alloc.c (GC_bytes_found, GC_unmap_threshold,\nGC_force_unmap_on_gcollect): Likewise.\n* dyn_load.c (GC_no_win32_dlls, GC_wnt): Likewise.\n* finalize.c (GC_fail_count): Likewise.\n* include/private/gc_locks.h (GC_allocate_ml, GC_lock_holder,\nGC_collecting, GC_mark_lock_holder, GC_need_to_lock): Likewise.\n* include/private/gc_pmark.h (GC_n_mark_procs, GC_mark_stack_size,\nGC_mark_stack_limit, GC_mark_stack_top, GC_mark_stack,\nGC_mark_stack_too_small, GC_mark_state): Likewise.\n* include/private/pthread_support.h (GC_threads,\nGC_thr_initialized, GC_in_thread_creation): Likewise.\n* mallocx.c (GC_bytes_found): Likewise.\n* mark_rts.c (GC_save_regs_ret_val, GC_world_stopped): Likewise.\n* misc.c (GC_unmap_threshold): Likewise.\n* os_dep.c (GC_unmap_threshold): Likewise.\n* pthread_support.c (GC_markers): Likewise.\n* thread_local_alloc.c (GC_gcjobjfreelist,\nGC_gcj_malloc_initialized, GC_gcj_kind): Likewise.\n* win32_threads.c (GC_fault_handler_lock, GC_write_cs,\nGC_dont_query_stack_min, GC_markers, GC_wnt): Likewise.\n* include/private/gc_priv.h (GC_EXTERN): New macro (used mostly as\na tag for now); defined after \"gcconfig.h\" inclusion.\n* include/private/gc_priv.h: Use GC_EXTERN instead of \"extern\"\nkeyword for most global variables.\n* alloc.c (GC_copyright): Add the comment about the symbol\nvisibility.\n* finalize.c (GC_fo_entries): Likewise.\n* include/private/gc_priv.h (GC_print_stats): Likewise.\n* misc.c (GC_quiet): Likewise.\n* mallocx.c (GC_bytes_allocd_tmp): Make the volatile variable\nSTATIC.\n* pthread_support.c (GC_threads): Add explicit zero initializer\n(to make the variable definition differ from the declaration).\n\n* backgraph.c (GC_quiet): Remove the declaration (not needed\nanymore since gc_priv.h is always included).\n* checksums.c (GC_quiet): Likewise.\n* gcj_mlc.c (GC_quiet): Likewise.\n* headers.c (GC_hdr_cache_hits, GC_hdr_cache_misses): Add the\ncomment.\n* include/private/gc_hdrs.h (GC_hdr_cache_hits,\nGC_hdr_cache_misses): Likewise.\n* mark.c (GC_first_nonempty): Make the volatile variable STATIC.\n* pthread_stop_world.c (GC_stop_count, GC_world_is_stopped):\nLikewise.\n* win32_threads.c (GC_please_stop, GC_max_thread_index,\nGC_mark_mutex_waitcnt): Likewise.\n\n* pthread_support.c (GC_USE_LD_WRAP): Fix a typo (swapped 'L' and\n'D') in the name.\n\n* gc_dlopen.c (GC_MUST_RESTORE_REDEFINED_DLOPEN): Define if dlopen\nredirection is turned off; turn it on later when dlopen real\nsymbol is no longer needed (according to the comment and the same\nas in dyn_load.c).\n* gc_dlopen.c (WRAP_FUNC, REAL_FUNC): Rename to WRAP_DLFUNC and\nREAL_DLFUNC, respectively (to have unique names since the\ndefinitions may differ from that of the similar ones in\npthread_support.c).\n* mark.c (source): Undefine the macro when no longer needed.\n* os_dep.c (handler): Rename the type to GC_fault_handler_t (to\nhave the unique name across the project).\n* os_dep.c (STAT_BUF_SIZE, STAT_READ); Guard with ifndef; add the\ncomment.\n* pthread_support.c (STAT_BUF_SIZE, STAT_READ): Likewise.\n* os_dep.c (sbrk): Undo sbrk() redirection (for ECOS) when no\nlonger needed.\n\n* pthread_stop_world.c (pthread_sigmask): Undefine before using\nin GC_print_sig_mask() (only if DEBUG_THREADS); add the comment.\n* win32_threads.c (dlopen, _beginthread): Don't undefine (since\nneither redirected nor used here).\n* win32_threads.c (GC_Thread_Rep): Rename \"table_management\" to\n\"tm\" for short; remove \"tm_\" prefix.\n* win32_threads.c (in_use, next): Don't define the macros; use\ntm.in_use and tm.next fields, respectively (to ease debugging).\n* win32_threads.c (HASH): Rename to PTHREAD_MAP_HASH (to have\nunique name across the project).\n\n* include/private/gc_priv.h (I_HIDE_POINTERS): Define before gc.h\ninclusion.\n* include/private/gc_pmark.h (I_HIDE_POINTERS): Define if gc.h is\nnot included yet.\n* finalize.c (I_HIDE_POINTERS): Don't define.\n* include/private/dbg_mlc.h (I_HIDE_POINTERS): Likewise.\n* misc.c (I_HIDE_POINTERS): Likewise.\n* include/private/dbg_mlc.h (HIDE_POINTER, REVEAL_POINTER,\nGC_hidden_pointer): Don't define if HIDE_POINTER is undefined.\n* include/private/gc_pmark.h: Remove the comment about gc_priv.h\ninclusion order.\n\n* dyn_load.c: Include gc_priv.h before using configuration\ninformation (MACOS).\n* dyn_load.c (GC_must_restore_redefined_dlopen): Rename to\nGC_MUST_RESTORE_REDEFINED_DLOPEN.\n\n* backgraph.c (SET_OH_BG_PTR): Place outermost parenthesis\nproperly.\n* darwin_stop_world.c: Replace \"if DEBUG_THREADS\" with\n\"ifdef DEBUG_THREADS\".\n* pthread_stop_world.c: Likewise.\n* pthread_support.c: Likewise.\n* include/gc_inline.h: Guard with GC_INLINE_H.\n\n* alloc.c (GC_copyright): Define as const.\n* alloc.c (GC_collect_at_heapsize): Replace \"static\" with \"STATIC\"\n(since the name starts with \"GC_\" prefix).\n* dbg_mlc.c (GC_describe_type_fns): Likewise.\n* dyn_load.c (GC_FirstDLOpenedLinkMap,\nGC_register_dynlib_callback, GC_dyld_sections,\nGC_dyld_name_for_hdr, GC_dyld_image_add, GC_dyld_image_remove):\nLikewise.\n* malloc.c (GC_libpthread_start, GC_libpthread_end,\nGC_libld_start, GC_libld_end): Likewise.\n* mark_rts.c (GC_remove_root_at_pos, GC_rebuild_root_index):\nLikewise.\n* os_dep.c (GC_gww_read_dirty, GC_gww_page_was_dirty,\nGC_gww_page_was_ever_dirty, GC_mprotect_thread_notify,\nGC_mprotect_thread_reply, GC_mprotect_thread, GC_darwin_sigbus,\nGC_forward_exception): Likewise.\n* pthread_support.c (GC_syms_initialized): Likewise.\n* typd_mlc.c (GC_push_typed_structures_proc): Likewise.\n* win32_threads.c (GC_win32_dll_threads,\nGC_register_my_thread_inner, GC_lookup_pthread, GC_get_stack_min,\nGC_waitForSingleObjectInfinite): Likewise.\n* darwin_stop_world.c (GC_use_mach_handler_thread,\nGC_use_mach_handler_thread, GC_mach_threads_count): Replace\n\"static\" with \"STATIC\" and add zero initializer.\n* os_dep.c (GC_task_self, GC_ports, GC_mprotect_state,\nGC_sigbus_count): Likewise.\n* headers.c (free_hdr): Replace \"static\" with GC_INLINE.\n* misc.c (GC_tmp): Rename static variable to fwrite_gc_res.\n* os_dep.c (memory): Rename static variable to ecos_gc_memory.\n* os_dep.c (async_set_pht_entry_from_index): Make static (for\nMPROTECT_VDB case).\n* pthread_support.c (GC_real_pthread_create,\nGC_real_pthread_sigmask, GC_real_pthread_join,\nGC_real_pthread_detach, GC_init_real_syms): Use REAL_FUNC() macro\nfor static GC_real_XXX symbols.\n* win32_threads.c (GC_may_be_in_stack): Remove \"GC_\" prefix.\n\n* alloc.c (GC_finish_collection): Replace getenv() with GETENV().\n* dyn_load.c (GC_init_dyld): Likewise.\n* os_dep.c (GC_print_callers): Likewise.\n* dyn_load.c (GC_dyld_name_for_hdr): Cast _dyld_get_image_name()\nresult (since it's always of \"struct mach_header\" type).\n* dyn_load.c (GC_init_dyld): Cast GC_dyld_image_add and\nGC_dyld_image_remove (to always have the first argument of\n\"struct mach_header\" pointer type).\n\n* configure.ac: Add threads support for OpenBSD case (threads may\nnot work correctly for it).\n\n* acinclude.m4: Rename to m4/gc_set_version.m4.\n* m4/libtool.m4: Delete the file.\n* m4/lt~obsolete.m4: Likewise.\n* m4/ltoptions.m4: Likewise.\n* m4/ltsugar.m4: Likewise.\n* m4/ltversion.m4: Likewise.\n\n* include/private/gcconfig.h: Define DebugBreak() as _exit(-1) for\nx86mingw32ce toolchain to workaround the incorrect DebugBreak()\ndeclaration in winbase.h (the workaround would turn into a no-op\nwhen DebugBreak() will be defined as a macro in the toolchain).\n\n* include/private/gcconfig.h: Recognize __i386__ if WinCE (for\nx86mingw32ce toolchain).\n* include/private/gcconfig.h (NO_GETENV): Don't define for CeGCC\ntoolchain (or if already defined).\n* include/private/gcconfig.h (NO_GETENV_WIN32): New macro (always\ndefined for WinCE or if NO_GETENV is defined).\n* misc.c (GC_CreateLogFile): Use NO_GETENV_WIN32 macro instead of\nNO_GETENV one.\n\n* configure.ac: Add AC_CONFIG_MACRO_DIR([m4]).\n* Makefile.am: Add \"ACLOCAL_AMFLAGS = -I m4\".\n* libtool.m4: Remove.\n* m4/libtool.m4: New file (generated).\n* m4/lt~obsolete.m4: Likewise.\n* m4/ltoptions.m4: Likewise.\n* m4/ltsugar.m4: Likewise.\n* m4/ltversion.m4: Likewise.\n\n* include/gc.h (GC_UNDERSCORE_STDCALL): Recognize new macro;\nprefix GC_CreateThread and GC_ExitThread with '_' if defined.\n* doc/README.macros (GC_UNDERSCORE_STDCALL): Document.\n\n* alloc.c (GC_collect_or_expand): Add \"retry\" argument; add the\ncomments; don't use \"default\" stop_func on a retry if\nGC_dont_expand.\n* alloc.c (GC_allocobj): Pass \"retry\" argument to\nGC_collect_or_expand().\n* malloc.c (GC_alloc_large): Likewise.\n* include/private/gc_priv.h (GC_collect_or_expand): Move the\ndeclaration to malloc.c; add \"retry\" argument.\n\n* alloc.c (GC_start_call_back): Move the variable definition from\nmisc.c.\n* include/private/gc_priv.h (GC_start_call_back): Remove the\ndeclaration.\n* alloc.c (GC_notify_full_gc): Remove unnecessary cast of 0.\n* alloc.c (GC_try_to_collect_inner): Also call stop_func at the\nbeginning of the function.\n* include/gc.h (GC_try_to_collect): Refine the comment about\nstop_func.\n\n* alloc.c (GC_default_stop_func, GC_try_to_collect_general,\nGC_gcollect): Add the comment.\n* alloc.c (GC_try_to_collect_general): Move the assertion on\nstop_func != 0 to GC_try_to_collect().\n* alloc.c (GC_try_to_collect_general): If stop_func == 0 then use\nGC_default_stop_func instead (holding the lock).\n* alloc.c (GC_gcollect): Pass 0 as stop_func instead of\nGC_default_stop_func (to prevent data races).\n\n* Makefile.direct: Move \"define arguments\" documentation to\ndoc/README.macros; add reference to doc/README.macros.\n* Makefile.dj: Change the documentation reference to\ndoc/README.macros.\n* README.QUICK: Likewise.\n* configure.ac: Likewise.\n* allchblk.c: Remove unnecessary \"-D\" from the comment.\n* doc/README.macros: Likewise.\n* README.environment: Likewise.\n* include/gc.h: Likewise.\n* include/gc_inline.h: Likewise.\n* include/private/gcconfig.h: Likewise.\n* README.QUICK: Fix a typo.\n\n* misc.c (GC_CreateLogFile): Use FILE_ATTRIBUTE_NORMAL for\nCreateFile(); don't immediately flush every write if very verbose.\n\n* doc/README.win32: Replace \".exe.log\" to \".gc.log\".\n* doc/README.win64: Likewise.\n* doc/README.win64: Fix a typo.\n* misc.c (GC_CreateLogFile): Strip executable file extension for\nthe log file; use \".gc.log\" extension (instead of \".log\").\n\n* include/gc_config_macros.h: Avoid the redefinition of\nGC_xxx_THREADS macros.\n\n* alloc.c (GC_try_to_collect_general): Change the type of \"result\"\nlocal variable to GC_bool.\n\n* include/gc_config_macros.h: Use old behavior for FreeBSD and\nNetBSD platform detection code (check that other GC_xxx_THREADS\nare undefined); add FIXME.\n\n* include/gc_config_macros.h: Rearrange the platform detection\ncode (GC_WIN32_PTHREADS implies GC_WIN32_THREADS; define\nGC_THREADS first if GC_XXX_THREADS already set; define proper\nGC_XXX_THREADS if GC_THREADS; define GC_PTHREADS in a single\nplace; define _REENTRANT if posix threads except for Win32).\n\n* alloc.c (GC_try_to_collect_general): New function (move the code\nfrom GC_try_to_collect, pass force_unmap argument).\n* alloc.c (GC_try_to_collect, GC_gcollect): Call\nGC_try_to_collect_general().\n* alloc.c (GC_gcollect_and_unmap): New public function.\n* include/gc.h (GC_gcollect_and_unmap): New function declaration.\n* tests/test.c (window_proc): Call GC_gcollect_and_unmap() on\nWM_HIBERNATE event (instead of GC_set_force_unmap_on_gcollect()\nand GC_gcollect()).\n\n* include/gc.h (GC_allow_register_threads, GC_register_my_thread,\nGC_unregister_my_thread, GC_malloc_many): Refine the comment.\n* include/gc.h (GC_malloc_many, GC_NEXT): Declare unconditionally\n(that is, don't depend on GC_THREADS macro).\n* include/gc.h: Don't check for __CYGWIN32__ and __CYGWIN__ along\nwith a check for GC_PTHREADS (since the former implies the\nlatter).\n\n* include/gc.h (GC_SOLARIS_THREADS): Don't check for.\n* include/gc.h (GC_MIN, GC_MAX): Don't define.\n* mallocx.c (GC_malloc_many): Add comment to #endif.\n\n* configure.ac: Drop the subdir-objects Automake option, since\nit's incompatible with picking source files from libatomic_ops.\n\n* allchblk.c (GC_fail_count, GC_large_alloc_warn_interval): Add\n\"extern\" keyword to a global variable declaration (some compilers\nrequire it).\n* alloc.c (GC_bytes_found, GC_unmap_threshold,\nGC_force_unmap_on_gcollect): Likewise.\n* dyn_load.c (GC_no_win32_dlls, GC_wnt): Likewise.\n* finalize.c (GC_fail_count): Likewise.\n* include/private/gc_hdrs.h (GC_hdr_cache_hits,\nGC_hdr_cache_misses): Likewise.\n* mallocx.c (GC_bytes_found): Likewise.\n* mark_rts.c (GC_save_regs_ret_val, GC_world_stopped): Likewise.\n* misc.c (GC_unmap_threshold): Likewise.\n* os_dep.c (GC_unmap_threshold, GC_old_allocator): Likewise.\n* pthread_support.c (GC_markers): Likewise.\n* thread_local_alloc.c (GC_gcjobjfreelist,\nGC_gcj_malloc_initialized, GC_gcj_kind): Likewise.\n* win32_threads.c (GC_fault_handler_lock, GC_write_cs,\nGC_dont_query_stack_min, GC_markers, GC_wnt): Likewise.\n\n* tests/huge_test.c: Define GC_IGNORE_WARN (if not defined) to\nsuppress misleading GC \"Out of Memory!\" warning printed on every\nGC_MALLOC(LONG_MAX) call.\n* tests/huge_test.c: Include \"gc.h\" instead of <gc.h>.\n* tests/huge_test.c (main): Replace K&R-style function definition\nwith the ANSI C one.\n\n* dyn_load.c (GC_register_dynamic_libraries): Always use\nlpMaximumApplicationAddress value for WinCE (even for old\nversions).\n* os_dep.c (VER_PLATFORM_WIN32_CE): Define if not in winbase.h.\n* os_dep.c (GC_dont_query_stack_min): New global variable (only if\nWinCE and THREADS).\n* os_dep.c (GC_setpagesize): Adjust lpMaximumApplicationAddress\nfor WinCE (prior to version 6) if not _WIN32_WCE_EMULATION; set\nGC_dont_query_stack_min for older WinCE (prior to version 5).\n* win32_threads.c (GC_dont_query_stack_min): Declare.\n* win32_threads.c (GC_get_stack_min): Rename the macro to\nGC_wince_evaluate_stack_min for WinCE; update the comment.\n* win32_threads.c (GC_push_stack_for, GC_get_next_stack): Use\nGC_wince_evaluate_stack_min() instead of GC_get_stack_min() for\nWinCE and don't update thread's last_stack_min value (only if\nGC_dont_query_stack_min).\n* win32_threads.c (GC_push_stack_for): Skip assertion for WinCE if\nGC_dont_query_stack_min (since the evaluated stack_min value may\nbe incorrect if the stack is bigger than 64 KiB).\n\n* gc_dlopen.c (GC_dlopen): Add function redirector (only if\nGC_USE_LD_WRAP).\n* include/gc.h: Include \"gc_pthread_redirects.h\" even if\nGC_USE_LD_WRAP or GC_NO_THREAD_REDIRECTS.\n* include/gc_pthread_redirects.h (GC_PTHREAD_REDIRECTS_H): Don't\ndefine and check for (since included only from gc.h).\n* include/gc_pthread_redirects.h: Declare \"GC_\" symbols even if\nGC_USE_LD_WRAP or GC_NO_THREAD_REDIRECTS.\n* include/gc_pthread_redirects.h: Include signal.h only to get\nsigset_t definition.\n\n* Makefile.direct: Document GC_REGISTER_MEM_PRIVATE.\n* mark_rts.c (GC_is_tmp_root): Define also for WinCE unless\nNO_DEBUGGING (that is, replace _WIN32_WCE_EMULATION with MSWINCE).\n* os_dep.c (GC_sysinfo): Remove explicit global variable\ninitialization to \"{0}\" (revert back the previous change) since it\nmight produce a warning.\n\n* allchblk.c (GC_large_alloc_warn_interval): Move declaration from\ngc_priv.h.\n* allchblk.c (GC_large_alloc_warn_suppressed): Move definition\nfrom misc.c; define as STATIC.\n* include/private/gc_priv.h (GC_large_alloc_warn_interval,\nGC_large_alloc_warn_suppressed): Remove declaration.\n* alloc.c (GC_bytes_found): Add \"defined in\" comment.\n* mallocx.c (GC_bytes_found): Likewise.\n* misc.c (GC_unmap_threshold): Likewise.\n* os_dep.c (GC_old_allocator): Likewise.\n* pthread_support.c (GC_markers): Likewise.\n* thread_local_alloc.c (GC_gcjobjfreelist,\nGC_gcj_malloc_initialized, GC_gcj_kind): Likewise.\n* win32_threads.c (GC_markers): Likewise.\n* alloc.c (GC_start_time): Explicitly initialize to 0 or NULL (to\nbe distinctive from a variable declaration).\n* backgraph.c (GC_max_height, GC_deepest_obj): Likewise.\n* blacklst.c (GC_old_normal_bl, GC_incomplete_normal_bl,\nGC_old_stack_bl, GC_incomplete_stack_bl): Likewise.\n* checksums.c (GC_faulted, GC_n_dirty_errors,\nGC_n_faulted_dirty_errors, GC_n_changed_errors, GC_n_clean,\nGC_n_dirty, GC_bytes_in_used_blocks): Likewise.\n* dbg_mlc.c (GC_smashed): Likewise.\n* finalize.c (GC_old_dl_entries): Likewise.\n* gcj_mlc.c (GC_gcj_kind, GC_gcj_debug_kind, GC_gcjobjfreelist,\nGC_gcjdebugobjfreelist): Likewise.\n* mach_dep.c (GC_save_regs_ret_val): Likewise.\n* mark.c (GC_n_rescuing_pages, GC_mark_stack, GC_mark_stack_limit,\nGC_mark_stack_top): Likewise.\n* misc.c (GC_min_sp, GC_high_water, GC_bytes_allocd_at_reset):\nLikewise.\n* os_dep.c (GC_data_start, GC_page_size, GC_sysinfo,\nGC_old_segv_handler, GC_old_bus_handler,\nGC_old_bus_handler_used_si, GC_old_segv_handler_used_si,\nGC_proc_buf, GC_proc_fd, GC_vd_base): Likewise.\n* pthread_stop_world.c (GC_stop_count, GC_stopping_pid): Likewise.\n* reclaim.c (GC_leaked): Likewise.\n* typd_mlc.c (GC_explicit_kind, GC_array_kind, GC_ext_descriptors,\nGC_typed_mark_proc_index, GC_array_mark_proc_index,\nGC_eobjfreelist, GC_arobjfreelist): Likewise.\n* win32_threads.c (GC_pthread_map_cache, GC_marker_cv,\nGC_marker_Id): Likewise.\n* dbg_mlc.c (GC_smashed, GC_n_smashed): Define as STATIC.\n* gcj_mlc.c (GC_gcjdebugobjfreelist): Likewise.\n* os_dep.c (GC_vd_base): Likewise.\n* pthread_support.c (GC_mark_threads): Likewise.\n* reclaim.c (GC_leaked): Likewise.\n* typd_mlc.c (GC_bm_table): Likewise.\n* mark_rts.c (GC_save_regs_ret_val): Change declaration type to\nthat of definition; add \"defined in\" comment.\n* mark_rts.c (GC_push_current_stack): Remove unnecessary cast for\nGC_save_regs_ret_val.\n* misc.c (GC_check_heap, GC_print_all_smashed,\nGC_start_call_back): Remove unnecessary cast (of 0).\n* misc.c (GC_LARGE_ALLOC_WARN_INTERVAL): New tuning macro.\n* misc.c (GC_large_alloc_warn_interval): Initialize to\nGC_LARGE_ALLOC_WARN_INTERVAL value.\n* misc.c (GC_tmp): Change to \"static\".\n* os_dep.c (GC_mprotect_state): Define as static.\n* pthread_support.c (dummy_thread_local): Prefix with \"GC_\".\n* win32_threads.c (WinMain): Remove FIXME for WinCE.\n\n* os_dep.c (PROTECT, UNPROTECT): Use distinct ABORT messages.\n\n* configure.ac: Rewrite the tests for external or internal\nlibatomic_ops.\n* configure.ac: In particular, drop the symbolic links. Add option\n--with-libatomic-ops for forced selection.\n* Makefile.am: Adjust the path of source files from libatomic_ops\nto not use the links.\n* Makefile.am (libgc_la_LIBADD): Add $(ATOMIC_OPS_LIBS). This will\nbe empty if we use the bundled AO sources.\n\n* Makefile.am: Strip version suffix for libatomic_ops directory.\n* build_atomic_ops.sh: Likewise.\n* build_atomic_ops.sh.cygwin: Likewise.\n* configure_atomic_ops.sh: Likewise.\n* Makefile.direct: Remove AO_VERSION definition; strip version\nsuffix for libatomic_ops directory.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* gc.mak: Likewise.\n\n* libatomic_ops: Rename from \"libatomic_ops-1.2\".\n\n* alloc.c (GC_version): Add \"const\" keyword.\n* alloc.c (GC_get_version): New public function.\n* include/gc.h (GC_get_version): New function declaration; update\nthe comment for the GC version.\n\n* include/private/gc_locks.h (GC_allocate_ml, GC_lock_holder,\nGC_collecting, GC_mark_lock_holder, GC_need_to_lock): Use \"extern\"\n(for the global variable declaration) again.\n* include/private/gc_pmark.h (GC_n_mark_procs, GC_mark_stack_size,\nGC_mark_stack_limit, GC_mark_stack_top, GC_mark_stack,\nGC_mark_stack_too_small, GC_mark_state): Likewise.\n* include/private/gcconfig.h (GC_register_stackbottom): Likewise.\n* include/private/pthread_support.h (GC_threads,\nGC_thr_initialized, GC_in_thread_creation): Likewise.\n* include/private/gc_priv.h: Likewise.\n\n* real_malloc.c: Include private/config.h if HAVE_CONFIG_H.\n\n* allchblk.c (GC_hblkfreelist): Define as STATIC.\n* blacklst.c (GC_total_stack_black_listed): Likewise.\n* include/private/gc_priv.h (GC_hblkfreelist, GC_stopped_mark,\nGC_total_stack_black_listed, GC_push_stubborn_structures): Remove\ndeclaration.\n* mark_rts.c (GC_stopped_mark): Add declaration (only if\nTHREAD_LOCAL_ALLOC).\n* allchblk.c (GC_fail_count): Move the declaration out of\nGC_allochblk_nth(); remove \"extern\".\n* alloc.c (IF_THREADS): Remove unused macro.\n* alloc.c (GC_world_stopped): Define only if THREAD_LOCAL_ALLOC.\n* alloc.c (GC_stopped_mark): Set GC_world_stopped value only if\nTHREAD_LOCAL_ALLOC.\n* alloc.c (GC_bytes_found, GC_collection_in_progress,\nGC_check_tls, GC_unmap_threshold, GC_force_unmap_on_gcollect):\nRemove K&R-style \"extern\" for the declaration.\n* dbg_mlc.c (GC_free_inner): Likewise.\n* dyn_load.c (GC_repeat_read, GC_roots_present, GC_is_heap_base,\nGC_get_next_stack, GC_no_win32_dlls, GC_wnt): Likewise.\n* finalize.c (GC_fail_count): Likewise.\n* include/private/gc_hdrs.h (GC_hdr_cache_hits,\nGC_hdr_cache_misses): Likewise.\n* include/private/gc_locks.h (GC_allocate_ml, GC_lock_holder,\nGC_lock, GC_collecting, GC_mark_lock_holder, GC_need_to_lock):\nLikewise.\n* include/private/gc_pmark.h (GC_mark_procs, GC_n_mark_procs,\nGC_mark_stack_size, GC_mark_stack_limit, GC_mark_stack_top,\nGC_mark_stack, GC_mark_stack_too_small, GC_mark_state): Likewise.\n* include/private/gc_priv.h (GC_current_warn_proc, GC_obj_kinds,\nGC_n_kinds, GC_fo_entries, GC_n_heap_sects, GC_n_memory,\nGC_page_size, GC_sysinfo, GC_black_list_spacing,\nGC_objects_are_marked, GC_incremental, GC_dirty_maintained,\nGC_root_size, GC_debugging_started, GC_large_alloc_warn_interval,\nGC_large_alloc_warn_suppressed, GC_blocked_sp,\nGC_activation_frame, GC_push_other_roots,\nGC_push_finalizer_structures, GC_push_thread_structures,\nGC_push_typed_structures, GC_start_call_back, GC_is_initialized,\nGC_check_heap, GC_print_all_smashed, GC_print_all_errors,\nGC_print_heap_obj, GC_have_errors, GC_print_stats,\nGC_dump_regularly, GC_backtraces, GC_print_back_height,\nGC_debug_generic_malloc_inner,\nGC_debug_generic_malloc_inner_ignore_off_page,\nGC_fl_builder_count, GC_mark_no, GC_help_marker,\nGC_setup_temporary_fault_handler, GC_reset_fault_handler): Likewise.\n* include/private/gcconfig.h (GC_SysVGetDataStart,\nGC_FreeBSDGetDataStart, GC_register_stackbottom,\nGC_MacTemporaryNewPtr, GC_amiga_get_mem): Likewise.\n* include/private/pthread_support.h (GC_threads,\nGC_thr_initialized, GC_in_thread_creation): Likewise.\n* malloc.c (GC_text_mapping): Likewise.\n* mallocx.c (GC_bytes_found): Likewise.\n* mark.c (GC_check_dirty, GC_started_thread_while_stopped): Likewise.\n* mark_rts.c (GC_save_regs_ret_val): Likewise.\n* misc.c (GC_clear_stack_inner, GC_init_parallel, GC_init_win32,\nGC_setpagesize, GC_init_linux_data_start,\nGC_set_and_save_fault_handler, GC_unmap_threshold): Likewise.\n* os_dep.c (GC_unmap_threshold, GC_push_all_stacks,\nGC_darwin_register_mach_handler_thread): Likewise.\n* pthread_support.c (GC_markers, GC_collection_in_progress):\nLikewise.\n* tests/test.c (GC_amiga_free_all_mem): Likewise.\n* thread_local_alloc.c (GC_gcjobjfreelist,\nGC_gcj_malloc_initialized, GC_gcj_kind): Likewise.\n* win32_threads.c (GC_write_fault_handler, GC_gww_dirty_init,\nGC_fault_handler_lock, GC_write_cs, GC_markers): Likewise.\n* misc.c (GC_read, GC_register_finalizer_no_order, GC_init_dyld):\nMove the declaration out of GC_init(); remove \"extern\".\n* os_dep.c (GC_abort): Add the comment; add workaround to suppress\ncompiler \"unreachable code\" warnings for ABORT callers (where\nABORT is followed by a dummy return statement).\n* os_dep.c (GC_old_allocator): Move the declaration out of\nGC_default_push_other_roots(); remove \"extern\".\n* darwin_stop_world.c (GC_mprotect_stop, GC_mprotect_resume):\nMove the declaration out of GC_stop_world() and GC_start_world()\n(only if MPROTECT_VDB); remove \"extern\".\n\n* win32_threads.c (GC_get_stack_min, GC_push_stack_for,\nGC_get_next_stack): Recognize _WIN32_WCE_EMULATION macro (used for\nWinCE emulation and for custom WinCE 6 devices); add the comment.\n* win32_threads.c (GC_get_stack_min): Cast pointer to word instead\nof DWORD.\n* win32_threads.c (GC_get_next_stack): Don't use and maintain the\nlatest known stack_min value for WinCE (if GC_get_stack_min is\ndefined as a macro); update the comments.\n* win32_threads.c (GC_wnt): Don't declare for WinCE.\n\n* Makefile.direct: Document EMPTY_GETENV_RESULTS.\n* gcj_mlc.c (GC_clear_stack): Remove declaration.\n* malloc.c (GC_clear_stack): Likewise.\n* mallocx.c (GC_clear_stack): Likewise.\n* typd_mlc.c (GC_clear_stack): Likewise.\n* gcj_mlc.c (GENERAL_MALLOC, GENERAL_MALLOC_IOP): Rename to\nGENERAL_MALLOC_INNER and GENERAL_MALLOC_INNER_IOP, respectively;\nremove \"lb\" unnecessary cast to word.\n* include/private/gc_priv.h (GC_clear_stack): Add declaration.\n* include/private/gc_priv.h (GENERAL_MALLOC, GENERAL_MALLOC_IOP):\nMove common declaration from typd_mlc.c and malloc.c; remove\nunnecessary result and \"lb\" parameter casts.\n* include/private/thread_local_alloc.h: Guard against duplicate\nheader file inclusion.\n* os_dep.c (USE_MUNMAP): Replace \"-->\" with an error directive for\nthe case when USE_MMAP is not defined.\n* pthread_support.c (GC_is_thread_tsd_valid): New internal\nfunction (only if GC_ASSERTIONS and THREAD_LOCAL_ALLOC); move the\ncode from thread-local GC_malloc(); add FIXME for the condition.\n* win32_threads.c (GC_is_thread_tsd_valid): Likewise.\n* thread_local_alloc.c (GC_gcjobjfreelist): Change the type (to\nmatch that of its definition).\n* thread_local_alloc.c (GC_destroy_thread_local): Add a cast for\nGC_gcjobjfreelist.\n* thread_local_alloc.c (GC_lookup_thread, GC_lookup_thread_inner):\nRemove unused declaration; don't include pthread.h.\n* thread_local_alloc.c (GC_is_thread_tsd_valid): New declaration\n(only if GC_ASSERTIONS).\n* thread_local_alloc.c (GC_malloc): Use GC_is_thread_tsd_valid()\ninstead of GC_lookup_thread().\n* win32_threads.c (GC_lookup_thread_inner): Define as STATIC.\n* win32_threads.c (UNPROTECT): Rename to UNPROTECT_THREAD (to have\nid different from that in os_dep.c).\n\n* allchblk.c (GC_enough_large_bytes_left): Replace \"inline static\"\nwith GC_INLINE.\n* include/private/gc_priv.h (fixed_getenv): Likewise.\n* alloc.c (GC_max, GC_min): Replace \"static INLINE\" with\nGC_INLINE.\n* mark_rts.c (rt_hash): Likewise.\n* win32_threads.c (GC_get_max_thread_index): Likewise.\n* include/private/gc_priv.h (INLINE): Prefix with \"GC_\"; include\n\"static\"; define for Sun CC; define for VC++ (and other\ncompilers).\n* pthread_support.c: Don't define __inline__ for non-GNU compilers\n(not needed anymore).\n\n* NT_THREADS_MAKEFILE: Remove file (since it duplicates gc.mak).\n* Makefile.in: Remove reference to NT_THREADS_MAKEFILE.\n* Makefile.am: Likewise.\n* Makefile.dj: Likewise.\n* Makefile.direct: Likewise.\n* doc/README.win32: Add reference to gc.mak.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n\n* Makefile.direct: Remove references to acinclude.m4, libtool.m4.\n\n* autogen.sh: Update.\n\n* Makefile.am: Don't add libtool.m4 to EXTRA_DIST.\n* acinclude.m4: Fix underquoting of GC_SET_VERSION.\n* README.QUICK: Update information for Makefile.\n* Makefile.am: Do not distribute the substituted bdw-gc.pc.\n* configure.ac: Add AM conditional analog to KEEP_BACK_PTRS.\n* tests/tests.am: Use it here to conditionally enable tracetest\nwhen possible.\n\n* dyn_load.c (GC_wnt): Update the comment.\n* dyn_load.c (GC_register_dynamic_libraries): Add the comment for\n_WIN32_WCE_EMULATION; recognize GC_REGISTER_MEM_PRIVATE (new\nmacro); call GC_is_heap_base() only if check for Type succeeded.\n\n* mark_rts.c (GC_is_tmp_root): Don't define unless NO_DEBUGGING;\nupdate the comment.\n* include/private/gc_priv.h (GC_is_tmp_root): Remove declaration.\n\n* include/private/gcconfig.h (CANCEL_SAFE, IF_CANCEL): new macros.\n* include/private/gc_priv.h (DISABLE_CANCEL, RESTORE_CANCEL,\nASSERT_CANCEL_DISABLED): New macros.\n* alloc.c (GC_maybe_gc): Assert cancellation disabled.\n(GC_collect_a_little_inner,GC_try_to_collect, GC_collect_or_expand):\nDisable cancellation.\n(GC_add_to_our_memory): Check for overflow.\n* misc.c (GC_cancel_disable_count): declare.\n(GC_init, GC_write): Disable cancellation.\n(GC_init): Remove redundant GC_is_initialized test.\n* os_dep.c (GC_repeat_read): Assert cancellation disabled.\n(GC_get_stack_base): Disable cancellation.\n* pthread_stop_world.c (GC_suspend_handler_inner): Disable\ncancellation.\n* pthread_support.c (GC_mark_thread): Permanently disable\ncancellation.\n(GC_wait_for_gc_completion, GC_wait_builder, GC_wait_marker):\nAssert cancellation disabled.\n(fork handling): Disable cancellation, fix comment.\n(GC_pthread_create): Disable cancellation.\n(GC_unregister_my_thread): Disable cancellation.\n* Makefile.direct: Document NO_CANCEL_SAFE.\n\n* Makefile: Remove outdated file (Makefile.direct should be used\ninstead).\n\n* include/gc.h (GC_use_DllMain): Refine the comment.\n\n* configure.ac: Add documentation to AC_DEFINE for GC_THREADS and\nEMPTY_GETENV_RESULTS.\n* configure.ac: Fix a typo.\n* Makefile.am: Likewise.\n\n* checksums.c (GC_checksum, GC_update_check_page): Remove\n\"register\" keyword in local variable declarations (for the code\nused only for debugging or which is not time-critical).\n* dbg_mlc.c (GC_has_other_debug_info, GC_store_debug_info,\nGC_store_debug_info_inner, GC_check_annotated_obj, GC_print_obj,\nGC_print_smashed_obj, GC_debug_end_stubborn_change,\nGC_debug_invoke_finalizer): Likewise.\n* dyn_load.c (GC_register_dynamic_libraries): Likewise.\n* mallocx.c (GC_realloc): Likewise.\n* mark_rts.c (GC_print_static_roots, GC_is_static_root,\nGC_clear_roots): Likewise.\n* misc.c (GC_write): Likewise.\n* os_dep.c (GC_print_callers): Likewise.\n* dyn_load.c (GC_register_dynamic_libraries): Rename \"i\" local\nvariable to \"j\" for the nested loop (just not to hide the similar\nvariable in the outer one).\n* mark_rts.c (GC_print_static_roots): Output an error message\nusing GC_err_printf() (instead of GC_printf()).\n\n* configure.ac: Move include flag from ${INCLUDE} ...\n* Makefile.am: ... to AM_CPPFLAGS and also add the build directory.\n* configure.ac: Call AM_CONFIG_HEADER([include/private/config.h]).\n* configure.ac: Add documentation to all AC_DEFINE either directly\nor using AH_TEMPLATE.\n\n* win32_threads.c (GC_waitForSingleObjectInfinite): New static\nfunction (only if GC_WINMAIN_REDIRECT).\n* win32_threads.c (WinMain): Call GC_waitForSingleObjectInfinite()\nthru GC_do_blocking() instead of calling WaitForSingleObject()\ndirectly.\n\n* pthread_support.c (start_mark_threads): Refine printed message.\n* win32_threads.c (GC_thr_init): Likewise.\n\n* Makefile.direct (GC_WINMAIN_REDIRECT): Add the comment for.\n* Makefile.direct (NO_GETENV): Update the comment.\n* include/gc.h (GC_WINMAIN_WINCE_LPTSTR): Remove macro.\n* include/gc.h (GC_WinMain): Remove declaration.\n* include/gc.h (WinMain): Define (as GC_WinMain) if and only if\nGC_WINMAIN_REDIRECT.\n* tests/test.c (GC_COND_INIT): Define as GC_INIT() also in case of\nWinCE target unless GC_WINMAIN_REDIRECT is defined.\n* tests/test.c (WINMAIN_LPTSTR): New macro.\n* tests/test.c (WinMain): Use WINMAIN_LPTSTR instead of LP[W]STR\nand GC_WINMAIN_WINCE_LPTSTR.\n* win32_threads.c (start_mark_threads): Add the comment for\nMARK_THREAD_STACK_SIZE.\n* win32_threads.c: Recognize new GC_WINMAIN_REDIRECT macro.\n* win32_threads.c (WINMAIN_LPTSTR, WINMAIN_THREAD_STACK_SIZE): New\nmacro (only if GC_WINMAIN_REDIRECT).\n* win32_threads.c: Undefine WinMain macro if GC_WINMAIN_REDIRECT.\n* win32_threads.c (GC_WinMain): Add prototype (only if\nGC_WINMAIN_REDIRECT).\n* win32_threads.c (main_thread_args, WinMain): Rename\nGC_WINMAIN_WINCE_LPTSTR to WINMAIN_LPTSTR.\n* win32_threads.c (WinMain): Call GC_INIT() instead of GC_init();\nuse WINMAIN_THREAD_STACK_SIZE.\n* win32_threads.c (WinMain): Call GC_deinit() and\nDeleteCriticalSection() only if WinCE; add FIXME.\n\n* os_dep.c (GC_get_main_stack_base): add assertion for mem_base\nvalue returned by GC_get_stack_base().\n\n* Makefile.direct (MUNMAP_THRESHOLD, GC_FORCE_UNMAP_ON_GCOLLECT):\nAdd the comment for.\n* alloc.c (GC_unmap_threshold, GC_force_unmap_on_gcollect):\nDeclare external variable (only if USE_MUNMAP).\n* alloc.c (GC_try_to_collect): Temporarily set GC_unmap_threshold\nvalue to 1 if GC_force_unmap_on_gcollect and restore it before\nunlocking (only if USE_MUNMAP).\n* doc/README.environment (GC_FORCE_UNMAP_ON_GCOLLECT): Add\ninformation for.\n* include/gc.h (GC_set_force_unmap_on_gcollect,\nGC_get_force_unmap_on_gcollect): New public function prototype.\n* include/gc.h (GC_FORCE_UNMAP_ON_GCOLLECT): New macro is\nrecognized.\n* misc.c (GC_FORCE_UNMAP_ON_GCOLLECT): Likewise.\n* include/gc.h (GC_INIT_CONF_FORCE_UNMAP_ON_GCOLLECT): New\ninternal macro (used by GC_INIT only).\n* misc.c (GC_force_unmap_on_gcollect): New global variable.\n* misc.c (GC_init): Recognize new \"GC_FORCE_UNMAP_ON_GCOLLECT\"\nenvironment variable (and set GC_force_unmap_on_gcollect).\n* misc.c (GC_set_force_unmap_on_gcollect,\nGC_get_force_unmap_on_gcollect): New public function.\n* tests/test.c (window_proc): Call GC_set_force_unmap_on_gcollect\nto force the mode on if WM_HIBERNATE; restore the mode after\nGC_gcollect().\n\n* Makefile.direct (LARGE_CONFIG): Update information.\n* include/gc.h (GC_stop_func): Refine the comment.\n\n* configure.ac: Use EMPTY_GETENV_RESULTS instead of NO_GETENV for\nWin32 (workaround for Wine bug).\n\n* allchblk.c (GC_freehblk): Adjust local variables indentation.\n* mallocx.c (GC_generic_malloc_many): Likewise.\n* typd_mlc.c (GC_malloc_explicitly_typed_ignore_off_page,\nGC_calloc_explicitly_typed): Likewise.\n* typd_mlc.c (GC_make_array_descriptor): Remove unnecessary\nbrackets.\n\n* configure.ac: Replace GC_WIN32_THREADS with GC_THREADS.\n* configure.ac: Process enable_parallel_mark option for Cygwin and\nWin32; define THREAD_LOCAL_ALLOC for Win32.\n\n* include/private/gc_priv.h: Define AO_ASSUME_WINDOWS98 if\nPARALLEL_MARK (required for VC++ x86).\n\n* dbg_mlc.c (GC_generate_random_backtrace): Call\nGC_try_to_collect(GC_never_stop_func) instead of GC_gcollect();\nif GC is disabled then print error message and return.\n* include/gc.h (GC_try_to_collect): Refine the comment.\n* include/private/gc_priv.h (GC_never_stop_func): Fix return type;\nrefine the comment.\n\n* add_gc_prefix.c: Move the file to the new \"extra\" directory.\n* AmigaOS.c: Likewise.\n* gcname.c: Likewise.\n* if_mach.c: Likewise.\n* if_not_there.c: Likewise.\n* MacOS.c: Likewise.\n* msvc_dbg.c: Likewise.\n* setjmp_t.c: Likewise.\n* threadlibs.c: Likewise.\n* EMX_MAKEFILE: Prepend setjmp_t.c with \"extra\" directory.\n* Makefile: Prepend AmigaOS.c, MacOS.c, add_gc_prefix.c, gcname.c,\nif_mach.c, if_not_there.c, msvc_dbg.c, setjmp_t.c, threadlibs.c\nwith \"extra\" directory.\n* Makefile.am: Likewise.\n* Makefile.direct: Likewise.\n* Makefile.dj: Likewise.\n* Makefile.in: Likewise.\n* NT_MAKEFILE: Prepend msvc_dbg.obj with \"extra\" directory.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* NT_THREADS_MAKEFILE: Prepend msvc_dbg.c with \"extra\" directory.\n* gc.mak: Likewise.\n* PCR-Makefile: Prepend if_mach.c, if_not_there.c with \"extra\"\ndirectory.\n* SMakefile.amiga: Prepend AmigaOS.c, setjmp_t.c with \"extra\"\ndirectory.\n* doc/simple_example.html: Update for threadlibs.c.\n* os_dep.c: Prepend included AmigaOS.c with \"extra\" directory.\n\n* include/gc.h (GC_do_blocking, GC_call_with_gc_active): New\nfunction prototype.\n* include/private/gc_priv.h (STOP_WORLD): Replace a no-op (for the\nsingle-threaded case) with an assertion check for the state to be\nnot a \"do-blocking\" one.\n* include/private/gc_priv.h (blocking_data): Move the structure\ndefinition from pthread_support.c; change \"fn\" return type to void\npointer.\n* include/private/gc_priv.h (GC_activation_frame_s): New structure\ntype.\n* include/private/gc_priv.h (GC_push_all_stack_frames): New\nfunction declaration (only if THREADS).\n* include/private/gc_priv.h (GC_world_stopped): Don't declare\nunless THREADS.\n* include/private/gc_priv.h (GC_blocked_sp,\nGC_activation_frame_s): New declaration (only if not THREADS).\n* include/private/gc_priv.h (GC_push_all_register_frames): New\nfunction declaration (only for IA-64).\n* include/private/gc_priv.h (NURSERY, GC_push_proc): Remove\nobsolete (unused) symbols.\n* include/private/gc_priv.h (GC_push_all_stack_partially_eager):\nRemove declaration (since it is static now).\n* mark_rts.c (GC_push_all_stack_partially_eager): Move from mark.c\n(for code locality) and make STATIC.\n* mark_rts.c (GC_push_all_register_frames): New function (only for\nIA-64).\n* mark_rts.c (GC_push_all_stack_frames): New function (only if\nTHREADS).\n* mark_rts.c (GC_add_trace_entry): New function prototype (used by\nGC_push_all_stack_partially_eager(), only if TRACE_BUF).\n* mark_rts.c (GC_push_all_stack_part_eager_frames): New function.\n* mar_rts.c (GC_save_regs_ret_val): Move the declaration out of a\nfunction body (only for IA-64).\n* mark_rts.c (GC_push_current_stack): Call\nGC_push_all_stack_part_eager_frames() instead of\nGC_push_all_stack_partially_eager().\n* mark_rts.c (GC_push_current_stack): Call\nGC_push_all_register_frames() instead of GC_push_all_eager() for\nIA-64 backing store.\n* misc.c (GC_do_blocking_inner): Declare function (if THREADS\nonly).\n* misc.c (GC_blocked_sp, GC_blocked_register_sp,\nGC_activation_frame): New global variables (only if not THREADS).\n* misc.c (GC_call_with_gc_active, GC_do_blocking_inner): New API\nfunction (only if not THREADS).\n* misc.c (GC_do_blocking): Move the function from\npthread_support.c.\n* include/private/pthread_support.h (GC_Thread_Rep): Add\n\"activation_frame\" field.\n* pthread_stop_world.c (GC_push_all_stacks): Call\nGC_push_all_stack_frames() and GC_push_all_register_frames instead\nof GC_push_all_stack() and/or GC_push_all_eager(); don't check for\nSTACK_GROWS_UP here.\n* pthread_support.c (GC_do_blocking_inner): Remove \"static\"; store\n\"fn\" result back to \"client_data\" field.\n* pthread_support.c (GC_call_with_gc_active): New API function.\n* win32_threads.c (GC_call_with_gc_active): Likewise.\n* win32_threads.c (GC_Thread_Rep): Add \"thread_blocked_sp\" and\n\"activation_frame\" fields.\n* win32_threads.c (GC_new_thread): Add assertion checking for\nthread_blocked_sp is NULL.\n* win32_threads.c (GC_do_blocking_inner): New function.\n* win32_threads.c (GC_stop_world): Don't suspend a thread if its\nthread_blocked_sp is non-NULL.\n* win32_threads.c (GC_push_stack_for): Use thread\n\"activation_frame\" (if non-NULL); use \"thread_blocked_sp\" if\nnon-NULL (instead of calling GetThreadContext()); \"UNPROTECT\" the\nthread before modifying its last_stack_min; call\nGC_push_all_stack_frames() instead of GC_push_all_stack(); update\nthe comments.\n\n* alloc.c (GC_default_stop_func): New static variable (initialized\nto GC_never_stop_func).\n* alloc.c (GC_set_stop_func, GC_get_stop_func): New function.\n* alloc.c (GC_timeout_stop_func): Define as GC_default_stop_func\n(instead of GC_never_stop_func) if SMALL_CONFIG (or NO_CLOCK),\nelse call GC_default_stop_func() before getting \"current_time\".\n* alloc.c (GC_maybe_gc): Expand GC_gcollect_inner() macro (for\nFIXME comment).\n* alloc.c (GC_maybe_gc, GC_collect_a_little_inner): add FIXME for\nreplacing GC_never_stop_func with GC_default_stop_func (if\npossible).\n* alloc.c (GC_gcollect): Use GC_default_stop_func.\n* alloc.c (GC_collect_or_expand): Use GC_default_stop_func\n(instead of GC_never_stop_func) unless it is triggered due to out of\nmemory; don't increment GC_fail_count and don't output warning\n(before trying to collect again) in case the collection has been\ninterrupted (by GC_default_stop_func) and the heap expansion has\nfailed too.\n* include/gc.h (GC_set_stop_func, GC_get_stop_func): New function\nprototypes.\n\n* os_dep.c (GC_get_stack_base): Add FIXME; add assertion for\nGC_get_writable_length() result.\n\n* configure.ac: Don't use -lpthread -ldl for Cygwin.\n\n* NT_THREADS_MAKEFILE: Make it back equal to gc.mak.\n\n* include/private/gcconfig.h (GWW_VDB): Undefine if\nUSE_GLOBAL_ALLOC (since incompatible).\n* os_dep.c (GetWriteWatch_alloc_flag): Define as 0 unless GWW_VDB\nis defined.\n* os_dep.c (GC_unmap_threshold): Declare (for use in\nGC_init_win32) if USE_MUNMAP.\n* os_dep.c (GC_init_win32): Turn off memory unmapping if\nGlobalAlloc() is used.\n* os_dep.c (GC_win32_get_mem): Define and use new\nVIRTUAL_ALLOC_PAD macro; don't waste an extra memory page unless\nMPROTECT_VDB is in use.\n\n* Makefile: Replace \"version.h\" with \"include/gc_version.h\".\n* include/gc_version.h: Likewise.\n\n* alloc.c (GC_collect_or_expand): Output heap size in WARN()\n(before returning FALSE) for convenience.\n\n* allchblk.c (GC_allochblk_nth): Use GC_PRIdPTR in WARN() format\nstring.\n* pthread_support.c (start_mark_threads, GC_thr_init): Likewise.\n* win32_threads.c (GC_delete_thread): Likewise.\n* include/private/gc_priv.h (GC_PRIdPTR): New macro.\n* pthread_stop_world.c (GC_suspend_handler_inner): Remove\nunnecessary cast for WARN argument.\n* pthread_support.c (start_mark_threads): if pthread_create()\nfailed then don't try to create other marker threads and (after\nprinting a warning) adjust GC_markers and GC_parallel values; log\nGC_markers value (possibly adjusted) after that.\n\n* win32_threads.c (start_mark_threads): if pthread_create() is\nfailed then don't try to create other marker threads and (after\nprinting a warning) adjust GC_markers and GC_parallel values.\n* win32_threads.c (mark_mutex_event, builder_cv, mark_cv): Move\nthe definition upper (to be visible in start_mark_threads()).\n* win32_threads.c (start_mark_threads): if CreateThread() or\n_beginthreadex() is failed then don't try to create other marker\nthreads and (after printing a warning) adjust GC_markers,\nGC_parallel values, and destroy the event objects (either only\nsome for the uncreated threads if DONT_USE_SIGNALANDWAIT or all if\nnot a single thread is created).\n* win32_threads.c (GC_thr_init): Log GC_markers value (possibly\nadjusted) after start_mark_threads() call.\n\n* Makefile.am: Back remove \"GC_\" prefix for PTHREADS,\nDARWIN_THREADS, WIN32_THREADS (for configure.ac).\n\n* include/private/gc_priv.h: Change include of config.h to\nprivate/config.h.\n* include/private/gc_pmark.h: Likewise.\n* gc_cpp.cc: Likewise.\n* tests/test.c: Likewise.\n* tests/test_cpp.cc: Include private/config.h (if HAVE_CONFIG_H);\nundefine GC_BUILD.\n\n* finalize.c (GC_general_register_disappearing_link): Return\nGC_SUCCESS, GC_DUPLICATE, GC_NO_MEMORY (instead of 0, 1 and 2,\nrespectively).\n* include/gc.h (GC_NO_MEMORY): New macro (defined as 2).\n* include/gc.h (GC_register_disappearing_link,\nGC_general_register_disappearing_link): Update the comment.\n* typd_mlc.c (GC_calloc_explicitly_typed): Use GC_NO_MEMORY macro.\n* finalize.c (GC_general_register_disappearing_link,\nGC_register_finalizer_inner): Recalculate the hash table index\nafter GC_oom_fn succeeded (since the table may grow while not\nholding the lock) and check again that the entry is still not in\nthe table (free the unused entry otherwise unless DBG_HDRS_ALL).\n* finalize.c (GC_register_finalizer_inner): Initialize \"hhdr\"\nlocal variable (to prevent a compiler warning).\n* finalize.c (GC_register_finalizer_inner): Don't modify the data\npointed by \"ocd\" and \"ofn\" in GC_register_finalizer_inner() failed\n(due to out of memory).\n\n* alloc.c (GC_set_fl_marks, GC_clear_fl_marks): Transform loop to\nsuppress compiler \"variable might be uninitialized\" warnings.\n\n* Makefile.direct (DONT_USE_SIGNALANDWAIT): Add the comment for.\n* win32_threads.c (DONT_USE_SIGNALANDWAIT): Always define for\nWinCE.\n* win32_threads.c (THREAD_HANDLE): Cast Id (of DWORD type) to\nHANDLE thru word type (to avoid a compiler warning) for WinCE.\n* win32_threads.c (GC_marker_cv, GC_marker_Id): New static array\n(only if DONT_USE_SIGNALANDWAIT).\n* win32_threads.c (start_mark_threads): Initialize GC_marker_Id\nand GC_marker_cv for each helper thread (only if\nDONT_USE_SIGNALANDWAIT).\n* win32_threads.c (GC_mark_mutex_state): New static variable (only\nif DONT_USE_SIGNALANDWAIT).\n* win32_threads.c (GC_mark_mutex_waitcnt,\nsignalObjectAndWait_func): Don't define if DONT_USE_SIGNALANDWAIT.\n* win32_threads.c (GC_acquire_mark_lock, GC_release_mark_lock):\nUse InterlockedExchange() over GC_mark_mutex_state (instead of\nAO_fetch_and_add()) if DONT_USE_SIGNALANDWAIT.\n* win32_threads.c (GC_wait_marker, GC_notify_all_marker):\nImplement wait/broadcast primitives using Win32 multiple events\n(one for each marker thread) if DONT_USE_SIGNALANDWAIT (instead of\nusing Win32 SignalObjectAndWait).\n* win32_threads.c (GC_thr_init): Don't declare hK32 local\nvariable, don't check for GC_wnt, and don't initialize\nsignalObjectAndWait_func if DONT_USE_SIGNALANDWAIT.\n\n* alloc.c (GC_finish_collection): Call GC_print_finalization_stats\nif GC_print_stats (after getting \"done_time\").\n* finalize.c (GC_old_dl_entries): New static variable (only if not\nSMALL_CONFIG).\n* finalize.c (GC_finalize): Save current GC_dl_entries value (only\nif not SMALL_CONFIG).\n* finalize.c (GC_print_finalization_stats): Define if and only if\nnot SMALL_CONFIG; use GC_old_dl_entries value; use GC_log_printf()\ninstead of GC_printf(); use \"%lu\" (instead of \"%u\") print format\nspecifier; use unsigned long type for \"ready\" counter (for LP64\ntargets).\n* misc.c (GC_dump): No longer call GC_print_finalization_stats()\nhere (since it is called from GC_finish_collection()).\n* misc.c (STACKBASE): Remove unused macro undef (for NOSYS and\nECOS).\n\n* alloc.c (GC_expand_hp): Replace GC_init_inner() call with\nGC_init() one.\n* malloc.c (GC_alloc_large, GC_generic_malloc_inner): Likewise.\n* mallocx.c (GC_generic_malloc_many): Likewise.\n* misc.c (GC_enable_incremental): Likewise.\n* alloc.c (GC_expand_hp): Update the comment.\n* mark.c (GC_obj_kinds): Likewise.\n* win32_threads.c (GC_allow_register_threads): Likewise.\n* private/gc_priv.h (GC_init_inner): Remove function declaration.\n* misc.c (GC_init_inner): Replace with public GC_init().\n\n* gcj_mlc.c (GC_gcj_fake_mark_proc): New static function.\n* gcj_mlc.c (GC_init_gcj_malloc): If mp is 0 then supply\nGC_gcj_fake_mark_proc (aborting with the appropriate message)\ninstead.\n\n* os_dep.c (GC_wince_get_mem): If VirtualAlloc() returns NULL (due\nto out of memory) then don't increment GC_n_heap_bases and don't\ncall VirtualAlloc() again (with MEM_COMMIT).\n* os_dep.c (GC_remap): Abort with a more informatory message if\nVirtualAlloc() fails due to out of memory; update FIXME.\n\n* Makefile: Fix typo for msvc_dbg.c.\n* Makefile.direct: Likewise.\n* Makefile.am: Prefix PTHREADS, DARWIN_THREADS, WIN32_THREADS with\n\"GC_\".\n* Makefile.dj: Don't reference remove files (nursery.c,\ngc_nursery.h, gc_copy_descr.h).\n* NT_MAKEFILE: Don't define __STDC__ macro (no longer used).\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* gc.mak: Likewise.\n* NT_MAKEFILE: Remove unnecessary -DGC_BUILD (since it is always\ndefined in the source files).\n* NT_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* gc.mak: Likewise.\n* NT_X64_THREADS_MAKEFILE: Fix typo for -DGC_NOT_DLL.\n* NT_STATIC_THREADS_MAKEFILE: Replace GC_WIN32_THREADS with\nGC_THREADS.\n* NT_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_THREADS_MAKEFILE: Likewise.\n* gc.mak: Likewise.\n* NT_MAKEFILE: Define _CRT_SECURE_NO_DEPRECATE to suppress the\ncompiler warnings.\n* NT_STATIC_THREADS_MAKEFILE: Likewise.\n* NT_X64_STATIC_THREADS_MAKEFILE: Place -D_CRT_SECURE_NO_DEPRECATE\nbefore \"$*.C\" (and \"$*.CPP\").\n* NT_X64_THREADS_MAKEFILE: Likewise.\n\n* doc/README.solaris2: Replace GC_SOLARIS_THREADS with GC_THREADS.\n* doc/README.win32: Replace GC_WIN32_THREADS with GC_THREADS.\n* doc/README.win64: Add info about mingw-w64; add note for VC++\nwarnings suppression.\n\n* os_dep.c (GC_forward_exception): Fix logic in several places.\n(OSX-specific)\n\n* include/private/gc_priv.h (MAX_HEAP_SECTS): Guard with ifndef.\n\n* Makefile.direct: Copy missing information for -DSHORT_DBG_HDRS\nfrom Makefile.\n* Makefile: Remove the information about \"define arguments\" (which\nis incomplete and outdated compared to that in Makefile.direct);\nadd help reference to Makefile.direct.\n* Makefile.dj: Likewise.\n\n* alloc.c (world_stopped_total_time, world_stopped_total_divisor):\nReplace \"STATIC\" with \"static\" in the definition (since the\nsymbols aren't prefixed with \"GC_\").\n* win32_threads.c (marker_sp, marker_bsp, marker_last_stack_min,\nstart_mark_threads, mark_mutex, builder_cv, mark_cv,\nmark_mutex_event, signalObjectAndWait_func, main_thread_start):\nLikewise.\n* pthread_support.c (GC_wait_builder): Define as STATIC.\n* win32_threads.c (GC_wait_builder): Likewise.\n\n* misc.c (GC_get_heap_size_inner, GC_get_free_bytes_inner): New\nAPI function.\n* include/gc_pmark.h (GC_get_heap_size_inner,\nGC_get_free_bytes_inner): New function declaration.\n\n* include/gc.h: Recognize __CEGCC__ (as a synonym for _WIN32_WCE).\n* include/gc_config_macros.h: Likewise.\n* include/gc.h (GC_MAXIMUM_HEAP_SIZE): Recognize new macro.\n* include/gc.h (GC_INIT_CONF_MAXIMUM_HEAP_SIZE): New macro (for\ninternal use).\n* include/gc_config_macros.h: Always include stddef.h if GCC.\n* include/gc_config_macros.h (GC_API): Define for CeGCC in the\nsame way as for MinGW.\n* include/gc_config_macros.h (GC_API): Group the definition for\nall cases together (check for GC_DLL only once).\n* include/gc_pthread_redirects.h: Group non-Darwin code together.\n* tests/test.c: Recognize GC_PRINT_VERBOSE_STATS (only if GC_DLL).\n\n* Makefile.direct (GC_PTHREADS_PARAMARK, GC_IGNORE_GCJ_INFO,\nGC_PRINT_VERBOSE_STATS, GC_DONT_EXPAND, GC_INITIAL_HEAP_SIZE,\nGC_FREE_SPACE_DIVISOR, GC_TIME_LIMIT, GC_FULL_FREQ): Add the\ncomment for.\n* misc.c (GC_init_inner): Recognize GC_PRINT_VERBOSE_STATS (new\nmacro).\n* dyn_load.c (GC_wnt): Change definition to TRUE for WinCE; add\nFIXME and the comment for WinCE.\n* gcj_mlc.c (GC_init_gcj_malloc): Recognize GC_IGNORE_GCJ_INFO\n(new macro).\n* include/gc.h (GC_HAVE_BUILTIN_BACKTRACE): Don't define for VC++\nWinCE (since backtrace() is unimplemented).\n* include/private/gc_priv.h (GC_n_heap_bases): Remove declaration\n(since static).\n* os_dep.c (GC_n_heap_bases): Define as STATIC; move the\ndefinition to be above GC_is_heap_base().\n* include/private/gcconfig.h: Don't define NOSYS for WinCE on ARM\n(both for MinGW and CeGCC toolchains).\n* include/private/gcconfig.h: Recognize __CEGCC__ and\n__MINGW32CE__ (as synonyms for __WIN32_WCE).\n* include/private/gcconfig.h: If SH4 then don't set config\nparameters for SH.\n* include/private/thread_local_alloc.h (GC_key_create): Don't\nabort on failures, just return -1 in these cases (this also\nprevents compilation error for targets where ABORT is defined\nindirectly as an inline assembler sequence).\n* mark.c (WRAP_MARK_SOME): Also define for WinCE; add FIXME for\nthe GCC-based cross-compiler.\n* mark.c (ext_ex_regn, mark_ex_handler): Don't define unless\nWRAP_MARK_SOME is defined; define also for WinCE case; don't\ncheck for _WIN64 (since WRAP_MARK_SOME is undefined for it).\n* mark.c (GC_mark_some): Use __try/__except also for WinCE; update\nthe comment.\n* misc.c: Include signal.h after gc_pmark.h included; check for\nMSWINCE instead of _WIN32_WCE.\n* misc.c (GC_init_inner): Remove duplicate GC_setpagesize() call.\n* misc.c: Don't include <crtdbg.h> for WinCE targets.\n* misc.c (GC_write): Define _MAX_PATH if undefined (workaround for\nCeGCC toolchain).\n* misc.c (GC_write): Use OutputDebugStringW() instead of\n_CrtDbgReport() for WinCE targets.\n* os_dep.c (GC_least_described_address): Define as STATIC.\n* os_dep.c (GC_register_data_segments): Fix code indentation.\n* os_dep.c (GC_wince_get_mem): Initialize \"result\" local variable\n(to prevent a compiler warning).\n* os_dep.c (GC_dirty_init): Add comment for WinCE target.\n* tests/test.c: Don't include winbase.h directly if GCC for WinCE,\ninclude assert.h instead.\n* tests/test.c (tiny_reverse_test): Define and use\nTINY_REVERSE_UPPER_VALUE macro (4 if VERY_SMALL_CONFIG else 10);\nuseful for WinCE.\n* win32_threads.c (GC_Thread_Rep): Don't declare \"handle\" field\nfor WinCE (since thread Id is used as a \"real\" thread handle).\n* win32_threads.c (THREAD_HANDLE): New macro.\n* win32_threads.c (GC_register_my_thread_inner): Don't recognize\nDONT_IMPORT_GETCURTHREAD anymore; don't record thread handle on\nWinCE.\n* Makefile.direct (DONT_IMPORT_GETCURTHREAD): Remove comment for.\n* win32_threads.c (UNPROTECT, GC_fault_handler_lock): Don't check\nfor MSWINCE.\n* win32_threads.c (GC_delete_gc_thread, GC_delete_thread): Don't\nclose thread handle on WinCE (since it's a thread Id).\n* win32_threads.c (GC_suspend): Don't check for MSWINCE in the\nMPROTECT-related code (for the case if MPROTECT_VDB would be\nimplemented for WinCE).\n* win32_threads.c (GC_suspend, GC_start_world, GC_push_stack_for):\nUse THREAD_HANDLE(t) to obtain thread handle.\n* win32_threads.c (GC_PTHREADS_PARAMARK): New macro recognized;\nimplicitly define GC_PTHREADS_PARAMARK if GC_PTHREADS; include\npthread.h; define NUMERIC_THREAD_ID(id) if undefined yet; replace\nGC_PTHREADS with GC_PTHREADS_PARAMARK where appropriate (for the\nparallel mark support).\n* win32_threads.c (start_mark_threads): Use int type for \"i\" local\nvariable (instead of \"unsigned\") to prevent a compiler warning.\n* win32_threads.c (start_mark_threads): Don't check CreateThread()\nresult for -1; call CloseHandle() for the handle created by\nCreateThread() (on WinCE); don't use errno (since errno.h is\nmissing on some targets like WinCE) when printing warning on a\nmarker thread creation failure.\n* win32_threads.c (signalObjectAndWait_func): Define for WinCE.\n* win32_threads.c (GC_wait_marker): Remove unnecessary assertion\nfor non-zero signalObjectAndWait_func (to make the code compilable\nfor WinCE).\n* win32_threads.c (GC_thr_init): Allow PARALLEL_MARK for WinCE;\nuse GC_sysinfo to get processors count if WinCE; don't check for\nSignalObjectAndWait() if WinCE; replace GC_PTHREADS with\nGC_PTHREADS_PARAMARK.\n* win32_threads.c (GC_thr_init): Recognize GC_MIN_MARKERS new\nmacro (useful for testing parallel marking on WinCE).\n* win32_threads.c (GC_win32_start, main_thread_start): Define as\nSTATIC.\n* win32_threads.c: Don't define main_thread_args,\nmain_thread_start(), WinMain() for WinCE if GC_DLL.\n* win32_threads.c (WINCE_MAIN_STACK_SIZE): Remove useless macro\n(since the stack size parameter is ignored on WinCE).\n* win32_threads.c (main_thread_start): Remove forward declaration;\nplace its definition before WinMain() one.\n* win32_threads.c (WinMain): Abort if GC_CreateThread() or\nWaitForSingleObject() failed (for the main thread).\n\n* allchblk.c (MUNMAP_THRESHOLD): Move macro definition out of\na function.\n* allchblk.c (GC_unmap_threshold): New global variable definition\n(initialized to MUNMAP_THRESHOLD).\n* allchblk.c (GC_unmap_old): Use GC_unmap_threshold instead of\nMUNMAP_THRESHOLD; skip unmapping if GC_unmap_threshold is 0.\n* doc/README.environment (GC_UNMAP_THRESHOLD): Add information.\n* misc.c (GC_unmap_threshold): New variable declaration.\n* misc.c (GC_init_inner): Recognize \"GC_UNMAP_THRESHOLD\"\nenvironment variable to set GC_unmap_threshold value (only if\nUSE_MUNMAP).\n\n* dbg_mlc.c (OFN_UNSET): New macro (to detect\nGC_register_finalizer() failures).\n* dbg_mlc.c (store_old): Add a check for register_finalizer()\nfailure caused by an out-of-memory event (leave *ofn and *ocd\nunmodified in that case).\n* dbg_mlc.c (GC_debug_register_finalizer,\nGC_debug_register_finalizer_no_order,\nGC_debug_register_finalizer_unreachable,\nGC_debug_register_finalizer_ignore_self): Initialize my_old_fn\nto OFN_UNSET; clear *ocd and *ofn for non-heap objects (the same\nas in GC_register_finalizer_inner()).\n\n* Makefile.direct (GC_DLL): Add the comment for.\n* doc/README.macros: Fix a typo.\n* doc/README.macros (_DLL, GC_DLL, GC_NOT_DLL): Update info.\n* doc/README.macros (__STDC__): Remove info.\n* dbg_mlc.c (GC_get_back_ptr_info, GC_generate_random_heap_address,\nGC_generate_random_valid_address, GC_print_backtrace,\nGC_generate_random_backtrace, GC_register_describe_type_fn): Add\nGC_API and GC_CALL to function definition.\n* malloc.c (GC_generic_malloc): Likewise.\n* mallocx.c (GC_incr_bytes_allocd, GC_incr_bytes_freed): Likewise.\n* mark.c (GC_mark_and_push): Likewise.\n* misc.c (GC_new_free_list_inner, GC_new_free_list,\nGC_new_kind_inner, GC_new_kind, GC_new_proc_inner, GC_new_proc):\nLikewise.\n* include/gc_backptr.h (GC_get_back_ptr_info,\nGC_generate_random_heap_address, GC_generate_random_valid_address,\nGC_generate_random_backtrace, GC_print_backtrace): Add GC_API and\nGC_CALL to function prototype.\n* include/gc_mark.h (GC_mark_and_push, GC_new_free_list,\nGC_new_free_list_inner, GC_new_kind, GC_new_kind_inner,\nGC_new_proc, GC_new_proc_inner, GC_generic_malloc,\nGC_register_describe_type_fn): Likewise.\n* include/new_gc_alloc.h (GC_incr_bytes_allocd, GC_incr_mem_freed,\nGC_generic_malloc_words_small): Likewise.\n* gc_cpp.cc: Include \"config.h\" (if HAVE_CONFIG_H defined).\n* include/private/gc_pmark.h: Likewise.\n* include/private/gc_priv.h: Likewise.\n* tests/test.c: Likewise.\n* gc_cpp.cc: Define GC_BUILD.\n* include/private/gc_pmark.h: Likewise.\n* include/private/gc_priv.h: Likewise.\n* gc_dlopen.c (WRAP_FUNC, REAL_FUNC): New macro.\n* gc_dlopen.c (dlopen): Add GC_API to the wrapper function\ndefinition.\n* pthread_support.c (GC_pthread_create, GC_pthread_sigmask,\nGC_pthread_join, GC_pthread_detach, pthread_sigmask, pthread_join,\npthread_detach, pthread_create): Likewise.\n* win32_threads.c (GC_pthread_join, GC_pthread_create,\nGC_pthread_sigmask, GC_pthread_detach): Likewise.\n* gc_dlopen.c (dlopen): Use WRAP_FUNC and REAL_FUNC macros.\n* include/gc_backptr.h: Include \"gc.h\".\n* include/gc_backptr.h: Use extern \"C\" for the exported functions.\n* include/gc_mark.h: Likewise.\n* include/gc_config_macros.h (GC_THREADS): Define the macro if any\nGC_XXX_THREADS is defined.\n* include/gc_config_macros.h (_PTHREADS, _POSIX4A_DRAFT10_SOURCE):\nMove the definitions below the place where GC_NETBSD_THREADS and\nGC_DGUX386_THREADS are defined.\n* include/gc_config_macros.h (GC_DLL): Don't define (even if _DLL\nis defined) for GCC.\n* include/gc_config_macros.h (GC_API): Define for Cygwin (in the\nsame way as for VC++); define for GCC v4+ (other than already\nrecognized MinGW/Cygwin) as a \"default\" visibility attribute if\nGC_DLL is defined.\n* include/gc_config_macros.h (GC_ATTR_MALLOC, GC_ATTR_ALLOC_SIZE):\nNew macro.\n* include/gc.h (GC_malloc, GC_malloc_atomic, GC_strdup,\nGC_malloc_uncollectable, GC_malloc_stubborn, GC_memalign,\nGC_malloc_atomic_uncollectable, GC_malloc_ignore_off_page,\nGC_malloc_atomic_ignore_off_page, GC_debug_malloc,\nGC_debug_malloc_atomic, GC_debug_strdup,\nGC_debug_malloc_uncollectable, GC_debug_malloc_stubborn,\nGC_debug_malloc_ignore_off_page,\nGC_debug_malloc_atomic_ignore_off_page,\nGC_debug_malloc_replacement): Add GC_ATTR_MALLOC attribute.\n* include/gc_gcj.h (GC_gcj_malloc, GC_debug_gcj_malloc,\nGC_gcj_malloc_ignore_off_page): Likewise.\n* include/gc.h (GC_malloc, GC_malloc_atomic,\nGC_malloc_uncollectable, GC_malloc_stubborn,\nGC_malloc_atomic_uncollectable, GC_malloc_ignore_off_page,\nGC_malloc_atomic_ignore_off_page, GC_debug_malloc,\nGC_debug_malloc_atomic, GC_debug_malloc_uncollectable,\nGC_debug_malloc_stubborn, GC_debug_malloc_ignore_off_page,\nGC_debug_malloc_atomic_ignore_off_page,\nGC_debug_malloc_replacement: Add GC_ATTR_ALLOC_SIZE attribute\n(for the first argument).\n* include/gc_gcj.h (GC_gcj_malloc, GC_debug_gcj_malloc,\nGC_gcj_malloc_ignore_off_page): Likewise.\n* include/gc.h (GC_memalign, GC_realloc, GC_debug_realloc,\nGC_debug_realloc_replacement): Add GC_ATTR_ALLOC_SIZE attribute\n(for the second argument).\n* include/gc.h (GC_malloc, GC_malloc_atomic, GC_strdup,\nGC_malloc_uncollectable, GC_malloc_stubborn, GC_memalign,\nGC_malloc_atomic_uncollectable, GC_free, GC_base, GC_size,\nGC_realloc, GC_expand_hp, GC_set_max_heap_size,\nGC_exclude_static_roots, GC_add_roots, GC_remove_roots,\nGC_register_displacement, GC_debug_register_displacement,\nGC_try_to_collect, GC_malloc_ignore_off_page,\nGC_malloc_atomic_ignore_off_page, GC_debug_malloc,\nGC_debug_malloc_atomic, GC_debug_strdup,\nGC_debug_malloc_uncollectable, GC_debug_malloc_stubborn,\nGC_debug_malloc_ignore_off_page,\nGC_debug_malloc_atomic_ignore_off_page, GC_debug_free,\nGC_debug_realloc, GC_debug_malloc_replacement,\nGC_debug_realloc_replacement, GC_finalization_proc,\nGC_register_finalizer, GC_debug_register_finalizer,\nGC_register_finalizer_ignore_self,\nGC_debug_register_finalizer_ignore_self,\nGC_register_finalizer_no_order,\nGC_debug_register_finalizer_no_order,\nGC_register_finalizer_unreachable,\nGC_debug_register_finalizer_unreachable,\nGC_register_disappearing_link,\nGC_general_register_disappearing_link,\nGC_unregister_disappearing_link, GC_noop1, GC_warn_proc,\nGC_set_warn_proc, GC_ignore_warn_proc, GC_fn_type,\nGC_call_with_alloc_lock, GC_stack_base_func,\nGC_call_with_stack_base, GC_same_obj, GC_pre_incr, GC_post_incr,\nGC_is_visible, GC_is_valid_displacement, GC_same_obj_print_proc,\nGC_is_valid_displacement_print_proc, GC_is_visible_print_proc,\nGC_malloc_many, GC_CreateThread, GC_beginthreadex,\nGC_endthreadex): Comment out (or remove if single and meaningless)\nfunction argument names (to avoid identifiers out of the name\nspace).\n* include/gc_gcj.h (GC_init_gcj_malloc, GC_gcj_malloc,\nGC_debug_gcj_malloc, GC_gcj_malloc_ignore_off_page): Likewise.\n* include/gc.h (GC_try_to_collect): Update the comment.\n* include/gc.h (GC_size, GC_register_my_thread): Add const\nqualifier for the argument referent.\n* misc.c (GC_size): Likewise.\n* pthread_support.c (GC_register_my_thread_inner,\nGC_register_my_thread): Likewise.\n* win32_threads.c (GC_register_my_thread_inner,\nGC_register_my_thread): Likewise.\n* include/gc.h (GC_INIT_CONF_ROOTS): New macro for internal use\n(define instead of GC_INIT() for Cygwin and AIX).\n* include/gc.h (GC_DONT_EXPAND, GC_MAX_RETRIES,\nGC_FREE_SPACE_DIVISOR, GC_FULL_FREQ, GC_TIME_LIMIT, GC_IGNORE_WARN,\nGC_INITIAL_HEAP_SIZE): Recognize new macro.\n* include/gc.h (GC_INIT_CONF_DONT_EXPAND, GC_INIT_CONF_MAX_RETRIES,\nGC_INIT_CONF_FREE_SPACE_DIVISOR, GC_INIT_CONF_FULL_FREQ,\nGC_INIT_CONF_TIME_LIMIT, GC_INIT_CONF_IGNORE_WARN,\nGC_INIT_CONF_INITIAL_HEAP_SIZE): New macro for internal use.\n* include/gc.h (GC_INIT): Use GC_INIT_CONF_XXX macros.\n* include/gc_mark.h: Prefix GC_H with '_'.\n* include/gc_mark.h (GC_least_plausible_heap_addr,\nGC_greatest_plausible_heap_addr, GC_debug_header_size): Use GC_API\nfor the public variable declaration.\n* include/new_gc_alloc.h (GC_objfreelist_ptr, GC_aobjfreelist_ptr,\nGC_uobjfreelist_ptr, GC_auobjfreelist_ptr): Likewise.\n* include/gc_pthread_redirects.h (GC_pthread_create,\nGC_pthread_sigmask, GC_dlopen, GC_pthread_join, GC_pthread_detach):\nUse GC_API for the wrapper prototype.\n* include/gc_pthread_redirects.h (pthread_create, pthread_join,\npthread_detach, pthread_sigmask, dlopen): Undefine unconditionally\nbefore redirecting.\n* include/new_gc_alloc.h: Replace GC_incr_mem_freed() with\nGC_incr_bytes_freed(); remove FIXME.\n* include/private/gc_priv.h (GC_make_closure,\nGC_debug_invoke_finalizer, GC_noop): Remove GC_API for the private\nfunction.\n* tests/test.c (GC_print_stats): Handle GC_DLL case regardless of\nthe target.\n\n* finalize.c (GC_general_register_disappearing_link,\nGC_register_finalizer_inner): Remove unnecessary \"ifdef THREADS\"\nguard for LOCK/UNLOCK().\n* finalize.c (GC_general_register_disappearing_link,\nGC_register_finalizer_inner): Get GC_oom_fn value before releasing\nthe lock (to prevent data races).\n* gcj_mlc.c (GC_gcj_malloc, GC_debug_gcj_malloc,\nGC_gcj_malloc_ignore_off_page): Likewise.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Likewise.\n* include/gc_inline.h (GC_FAST_MALLOC_GRANS): Use GC_get_oom_fn()\ninstead of GC_oom_fn (to prevent data races).\n* malloc.c (GC_generic_malloc): Likewise.\n* mallocx.c (GC_memalign): Likewise.\n* pthread_support.c (pthread_create): Likewise.\n* gcj_mlc.c (maybe_finalize): Acquire the lock before setting\nlast_finalized_no value to prevent data races.\n* include/gc.h (GC_gc_no, GC_get_gc_no, GC_oom_fn, GC_set_oom_fn,\nGC_set_find_leak, GC_set_finalize_on_demand,\nGC_set_java_finalization, GC_set_finalizer_notifier,\nGC_set_dont_expand, GC_set_full_freq, GC_set_non_gc_bytes,\nGC_set_no_dls, GC_set_free_space_divisor, GC_set_max_retries,\nGC_set_dont_precollect, GC_set_time_limit, GC_warn_proc): Refine\nthe comment.\n* misc.c (GC_set_oom_fn): Likewise.\n* include/gc.h (GC_general_register_disappearing_link): Refine the\ncomment (replace \"soft\" word with \"weak\").\n* misc.c (GC_oom_fn, GC_get_gc_no, GC_get_parallel,\nGC_set_finalizer_notifier, GC_set_find_leak): Add the comment.\n* misc.c (GC_set_oom_fn, GC_get_oom_fn, GC_set_finalizer_notifier,\nGC_get_finalizer_notifier): Use LOCK/UNLOCK to prevent data races.\n\n* dbg_mlc.c: Guard include <errno.h> with ifndef MSWINCE; include\n\"private/dbg_mlc.h\" before it.\n* malloc.c: Likewise.\n* dbg_mlc.c (GC_debug_strdup): Use memcpy() instead of strcpy()\nfor WinCE (since deprecated); evaluate strlen() only once; don't\nset errno for WinCE.\n* malloc.c (GC_strdup): Likewise.\n* dyn_load.c (GC_wnt): Define as macro (FALSE) for WinCE.\n* include/gc.h (GC_unregister_my_thread): Refine the comment.\n* include/gc.h (GC_uintptr_t, GC_beginthreadex, GC_endthreadex):\nDon't declare for WinCE.\n* include/gc.h (GC_WINMAIN_WINCE_LPTSTR): New macro (WinCE only).\n* include/gc.h (GC_WinMain): Remove GC_API.\n* include/gc.h (GC_WinMain): Use GC_WINMAIN_WINCE_LPTSTR for\nlpCmdLine.\n* tests/test.c (GC_WinMain): Likewise.\n* win32_threads.c (main_thread_args, GC_WinMain): Likewise.\n* include/gc_config_macros.h (ptrdiff_t): Guard with\nifndef _PTRDIFF_T_DEFINED; define _PTRDIFF_T_DEFINED macro.\n* include/private/gc_locks.h: Guard include \"atomic_ops.h\" with\nifdef GC_PTHREADS (and not GC_WIN32_THREADS).\n* mark.c: Include \"atomic_ops.h\" if PARALLEL_MARK.\n* thread_local_alloc.c: Include \"atomic_ops.h\" if GC_GCJ_SUPPORT.\n* win32_threads.c: Include \"atomic_ops.h\" if MPROTECT_VDB.\n* include/private/gc_locks.h: Use include \"atomic_ops.h\" instead\nof include <atomic_ops.h>.\n* include/private/gc_priv.h: Likewise.\n* include/private/gc_locks.h (GC_allocate_ml, GC_need_to_lock):\nDon't export (replace GC_API to \"extern\").\n* win32_threads.c (GC_allocate_ml): Don't export.\n* include/private/gc_priv.h (DebugBreak): Define as macro for\nWinCE (if not UNDER_CE and DebugBreak is not defined yet).\n* include/private/gc_priv.h (UNALIGNED): Rename to UNALIGNED_PTRS\n(since \"UNALIGNED\" is defined in winnt.h of WinCE).\n* mark.c (UNALIGNED): Likewise.\n* include/private/gcconfig.h (ARM32): Recognize _M_ARM and _ARM_.\n* include/private/gcconfig.h (ALIGNMENT): Check always defined.\n* include/private/gcconfig.h: Allow GC_WIN32_THREADS for WinCE.\n* include/private/thread_local_alloc.h: Define USE_WIN32_SPECIFIC\nfor WinCE (since __declspec(thread) is unsupported).\n* include/private/thread_local_alloc.h (TLS_OUT_OF_INDEXES):\nDefine for WinCE (if undefined).\n* malloc.c (GC_malloc): Remove outdated comment about disabling\nsignals.\n* misc.c: Don't include <tchar.h> (since not used anymore and may\nbreak TEXT() macro defined in winnt.h).\n* misc.c (GC_init_inner): Don't use GetModuleHandle() and\nInitializeCriticalSectionAndSpinCount() for WinCE.\n* misc.c (GC_init_inner): Replace GetModuleHandleA() with\nGetModuleHandle() (and use TEXT() macro controlled by UNICODE).\n* misc.c (LOG_FILE): Remove unused macro; don't use _T() macro.\n* misc.c (GC_CreateLogFile): New static function (Win32/WinCE\nonly); move the code from GC_write(); replace GETENV() with\nGetEnvironmentVariable(); replace CreateFileA() with\nCreateFile(); use TEXT() macro (for Unicode support); replace\nstrcat() with memcpy() (since deprecated in WinCE).\n* misc.c (GC_write): Define as STATIC.\n* win32_threads.c (GC_attached_thread): Likewise.\n* misc.c (GC_write): Use GC_CreateLogFile().\n* misc.c: Define vsnprintf macro as StringCchVPrintfA for WinCE.\n* misc.c (GC_abort): Try to invoke MessageBoxA() dynamically\n(Win32 only) if DONT_USE_USER32_DLL is defined.\n* misc.c (GC_abort): Duplicate msg to GC log file (for Win32 and\nWinCE).\n* misc.c (GC_abort): Use a more user-friendly abort if\nNO_DEBUGGING (Win32 only).\n* os_dep.c: Include \"atomic_ops.h\" only if MPROTECT_VDB (and\nTHREADS).\n* os_dep.c (detect_GetWriteWatch): Use TEXT() for GetModuleHandle\n(for Unicode support); check GetModuleHandle() result.\n* tests/test.c: Don't define assert for WinCE (since may be\nredefined by \"assert.h\" included from libatomic_ops).\n* tests/test.c (FAIL): Define as ABORT for all targets (except\nfor PCR).\n* tests/test.c (n_tests): Don't use AO_t.\n* tests/test.c (check_heap_stats): Don't cast n_tests.\n* tests/test.c (inc_int_counter): New function (for n_tests atomic\nincrementation).\n* tests/test.c (run_one_test): Test GC_memalign() for all targets.\n* tests/test.c (run_one_test): Avoid unbalanced brackets in\n#if-#else-#endif blocks.\n* tests/test.c (run_one_test): Replace AO_fetch_and_add1() and\nprivate LOCK/UNLOCK with GC_call_with_alloc_lock(inc_int_counter).\n* tests/test.c (check_heap_stats): Replace\n\"if (sizeof(char *) > 4)\" with \"#if CPP_WORDSZ == 64\" to suppress\n\"unreachable code\" compiler warning.\n* tests/test.c (WinMain): Set cmd type to LPWSTR (for WinCE\n\"UNDER_CE\" mode); else use LPSTR type (for Win32 and WinCE).\n* tests/test.c (thr_window): Replace \"L\" string prefix with\nTEXT().\n* thread_local_alloc.c: Check THREADS is defined (to prevent other\ncompiler errors and warnings otherwise).\n* tests/test.c (WinMain): Recognize GC_NO_DLLMAIN macro (for\nGC_use_DllMain()).\n* Makefile.direct (GC_NO_DLLMAIN, DONT_IMPORT_GETCURTHREAD): Add\nthe comments for.\n* win32_threads.c (GC_register_my_thread_inner): Recognize\nDONT_IMPORT_GETCURTHREAD macro.\n* win32_threads.c: Recognize GC_NO_DLLMAIN macro (to exclude\nDllMain support if needed).\n* win32_threads.c (GC_NO_DLLMAIN): Define implicitly if DllMain\nthread registration is unsupported for a given configuration.\n* win32_threads.c (GC_use_DllMain): Update the comment; refine\nABORT message.\n* win32_threads.c (GC_use_DllMain,\nGC_started_thread_while_stopped, GC_register_my_thread_inner,\nGC_lookup_thread_inner, GC_delete_gc_thread,\nGC_allow_register_threads, GC_lookup_pthread,\nGC_push_thread_structures, GC_stop_world, GC_push_all_stacks):\nCheck for GC_NO_DLLMAIN.\n* win32_threads.c (GC_Thread_Rep.tm_in_use, GC_attached_thread,\nDllMain): Don't define if GC_NO_DLLMAIN.\n* win32_threads.c (GC_stop_world): Declare \"i\" and \"max\" local\nvariables only if not GC_NO_DLLMAIN (to suppress compiler\nwarning).\n* win32_threads.c (GC_mark_thread, start_mark_threads): Use\nCreateThread() instead of _beginthreadex() for WinCE.\n* win32_threads.c (MARK_THREAD_STACK_SIZE, WINCE_MAIN_STACK_SIZE):\nNew macros defined (used by start_mark_threads(), WinMain()).\n* win32_threads.c (GC_thr_init): Exclude parallel-specific code on\nWinCE for now (since getenv(), GetProcessAffinityMask() and\nSignalObjectAndWait() are missing on WinCE).\n* win32_threads.c (GC_thr_init): replace GetModuleHandleA() with\nGetModuleHandle(); replace CreateEventA() with CreateEvent(); use\nTEXT() macro (for Unicode support).\n\n* include/gc.h (GC_has_static_roots_func): New typedef (user filter\ncallback).\n* include/gc.h (GC_register_has_static_roots_callback): Use\nGC_has_static_roots_func type.\n* dyn_load.c (GC_has_static_roots,\nGC_register_has_static_roots_callback): Likewise.\n* dyn_load.c (GC_has_static_roots,\nGC_register_has_static_roots_callback): Define on all platforms.\n* dyn_load.c (GC_register_dynlib_callback,\nGC_register_dynamic_libraries, GC_init_dyld): Replace K&R-style\nfunctions definition with the ANSI C one.\n* dyn_load.c (GC_register_dynlib_callback): Use new local variable\n\"callback\" (initialized from GC_has_static_roots) to minimize data\nraces.\n* dyn_load.c (GC_register_dynamic_libraries_dl_iterate_phdr,\nGC_cond_add_roots): Define as STATIC.\n* mark_rts.c (GC_remove_roots_inner): Likewise.\n* dyn_load.c (GC_dyld_image_add): Don't call GC_add_roots() for\nsections smaller than pointer size (just to avoid acquiring the\nlock unnecessarily).\n* dyn_load.c (GC_dyld_name_for_hdr): Define unconditionally (not\nonly for DARWIN_DEBUG).\n* dyn_load.c (GC_dyld_image_add): Replace GC_add_roots() call with\nLOCK + GC_add_roots_inner() + UNLOCK.\n* dyn_load.c (GC_dyld_image_add): Call GC_has_static_roots() user\ncallback (if set) holding the lock; if it returns 0 then don't call\nGC_add_roots_inner() for that region.\n* dyn_load.c (GC_register_has_static_roots_callback): Put\n\"callback\" value to GC_has_static_roots on all platforms.\n* dyn_load.c (GC_has_static_roots): Update the comments.\n* include/gc.h (GC_exclude_static_roots, GC_add_roots,\nGC_remove_roots, GC_register_has_static_roots_callback): Likewise.\n* include/private/gc_priv.h (struct roots): Likewise.\n* include/private/gc_priv.h (GC_remove_roots_inner): Move prototype\nto mark_rts.c and declare it as STATIC.\n* include/private/gc_priv.h (GC_exclude_static_roots_inner): New\nprototype.\n* dyn_load.c (GC_register_dynamic_libraries_dl_iterate_phdr): Use\nGC_exclude_static_roots_inner() instead of GC_exclude_static_roots.\n* misc.c (GC_init_inner): Likewise.\n* mark_rts.c (GC_exclude_static_roots_inner): New function (move\nall the code from GC_exclude_static_roots(); add the comment.\n* mark_rts.c (GC_add_roots_inner, GC_exclude_static_roots_inner):\nadd alignment assertion for the lower bound; add assertion for the\nlower bound to be less than the upper one.\n* mark_rts.c (GC_add_roots_inner, GC_exclude_static_roots): Adjust\nthe upper bound (round down to be of a pointer-aligned value);\nreturn in case of an empty range.\n* mark_rts.c (GC_exclude_static_roots): Acquire the lock and call\nGC_exclude_static_roots_inner().\n* mark_rts.c (GC_remove_roots): Quickly check the bounds and return\nin case of a do-nothing case (before acquiring the lock).\n\n* finalize.c (GC_fail_count): New external variable declaration.\n* finalize.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested): New function declarations (if THREADS\nonly).\n* finalize.c (GC_finalizer_nested, GC_finalizer_skipped): New\nstatic global variables (used internally by GC_finalize() and\nGC_check_finalizer_nested()).\n* finalize.c (GC_check_finalizer_nested): New static function\ndefinition (only if not THREADS, used internally by\nGC_notify_or_invoke_finalizers() to minimize the probability of\na deep recursion when a client finalizer tries to allocate GC\nmemory).\n* finalize.c (GC_finalize): Reset GC_finalizer_nested value (or\ncall GC_reset_finalizer_nested()) if last heap expansion failed.\n* finalize.c (GC_notify_or_invoke_finalizers): Access GC_gc_no,\nGC_finalizer_now, GC_finalize_on_demand, GC_finalizer_notifier,\nlast_finalizer_notification variables holding the lock (to avoid\ndata races).\n* finalize.c (GC_finalizer_notifier): Add comment.\n* finalize.c (GC_notify_or_invoke_finalizers): Add \"quick\" check\nfor an empty finalization queue (only if THREADS and not\nKEEP_BACK_PTRS/MAKE_BACK_GRAPH).\n* finalize.c (GC_notify_or_invoke_finalizers): Call\nGC_check_finalizer_nested() and skip GC_invoke_finalizers() call\nif appropriate.\n* include/private/pthread_support.h (GC_Thread_Rep): Add unsigned\nfinalizer_nested and finalizer_skipped fields (for internal use\nby the multi-threaded GC_check_finalizer_nested()).\n* win32_threads.c (GC_Thread_Rep): Likewise.\n* pthread_support.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested): New function definitions (the\nmulti-threaded variants of that in finalize.c).\n* win32_threads.c (GC_reset_finalizer_nested,\nGC_check_finalizer_nested): Likewise.\n\n* alloc.c (GC_stopped_mark): Remove GC_log_printf(\"\") (not needed\nanymore and GCC produces a warning for it).\n* alloc.c (GC_stopped_mark): Adjust printf argument type\nspecifier.\n* backgraph.c: Include dbg_mlc.h before ifdef MAKE_BACK_GRAPH (for\nthe case when the configuration information comes from a config.h\nfile).\n* checksums.c: Likewise.\n* include/gc_allocator.h (GC_ATTR_UNUSED): Use \"__unused__\"\nkeyword instead of \"unused\".\n* include/gc_allocator.h: Fix typos in comments.\n* thread_local_alloc.c: Likewise.\n* include/javaxfc.h (GC_finalize_all): Update comment.\n* include/private/gc_priv.h (GC_API_PRIV): New macro (defined as\nGC_API and serves only as a marker for the private but exported\nsymbols used by test.c only).\n* include/private/gc_priv.h (GC_abort, GC_arrays, GC_is_marked,\nGC_printf, GC_err_printf, GC_log_printf): Replace GC_API decl with\nGC_API_PRIV one.\n* include/private/gc_priv.h (GC_fo_entries): Don't export it\noutside a DLL.\n* include/private/gc_priv.h (GC_ATTR_FORMAT_PRINTF): New macro\ndesignated to check the arguments correctness of printf-like\nfunctions (currently works only for GCC v3+).\n* include/private/gc_priv.h (GC_printf, GC_err_printf,\nGC_log_printf): Use GC_ATTR_FORMAT_PRINTF attribute.\n\n* dyn_load.c (HAVE_DL_ITERATE_PHDR): Break definition from use.\nDefine for FreeBSD 7.0+.\n\n* mach_dep.c: Don't include ucontext.h with NO_GETCONTEXT.\n\n* include/gc_gcj.h (GC_init_gcj_malloc): Improve descriptive\ncomment.\n\n* allchblk.c (GC_merge_unmapped): Don't assume that adjacent\nfree blocks have different mapping status.  Correctly handle gap\nbetween blocks.\n(GC_split_block): Remove dead code setting hb_flags.  Add comment.\n(GC_allochblk): Split blocks also in generational-only mode.\n* os_dep.c (GC_unmap_gap): Don't really use munmap.\n\n* include/private/gc_priv.h (GC_unmapped_bytes): Define as 0 for\nnot USE_MUNMAP case.\n\n* Makefile.direct (MARK_BIT_PER_OBJ, PRINT_BLACK_LIST,\nUSE_PROC_FOR_LIBRARIES): Fix typo in the comments.\n* Makefile.direct (USE_MMAP, USE_MUNMAP, THREAD_LOCAL_ALLOC,\nPARALLEL_MARK, STATIC): Update the comments.\n* include/private/gcconfig.h (GC_PREFER_MPROTECT_VDB): New macro\nrecognized (only if MPROTECT_VDB).\n* Makefile.direct (DONT_USE_USER32_DLL, GC_PREFER_MPROTECT_VDB):\nAdd the comments for.\n* os_dep.c (detect_GetWriteWatch): Recognize \"GC_USE_GETWRITEWATCH\"\nenvironment variable (only if MPROTECT_VDB, if the variable is\nunset when GC_PREFER_MPROTECT_VDB macro controls the strategy).\n* doc/README.environment (GC_USE_GETWRITEWATCH): New variable.\n* include/private/gcconfig.h (MPROTECT_VDB): Add FIXME for\nUSE_MUNMAP and PARALLEL_MARK cases (to relax the conditions in\nthe future).\n* misc.c (GC_get_heap_size, GC_get_free_bytes): Ignore the memory\nspace returned to OS (GC_unmapped_bytes).\n* include/gc.h (GC_get_heap_size, GC_get_free_bytes): Update the\ncomments.\n* misc.c (GC_get_unmapped_bytes): New API function.\n* include/gc.h (GC_get_unmapped_bytes): New API prototype.\n* os_dep.c (GC_dirty_init): Move \"ifdef GWW_VDB\" block out of\n\"ifdef MSWIN32\" one (for Cygwin).\n\n* pthread_support.c (GC_allow_register_threads): New API function.\n* win32_threads.c (GC_allow_register_threads): Likewise.\n* include/gc.h (GC_allow_register_threads): New API prototype.\n* include/gc.h (GC_register_my_thread, GC_unregister_my_thread):\nUpdate the comments.\n* pthread_support.c (GC_register_my_thread): Check the collector\nis in the multi-threaded mode.\n* win32_threads.c (GC_register_my_thread): Likewise.\n\n* finalize.c (GC_finalize_all): Always call GC_invoke_finalizers\ninstead, following Ivan's original patch.\n\n* allchblk.c (GC_allochblk_nth): Add assertion.\n* checksums.c: Add GC_record_fault, GC_was_faulted,\nCC_n_faulted_dirty_errors.\n(GC_check_dirty): Remove register declarations, print\ndirty bit errors on faulted pages.\n* os_dep.c (GC_write_fault_handler): Call GC_record_fault().\n* os_dep.c (GC_remove_protection): Compute index correctly.\n\n\n== [7.2alpha2] 2009-06-12 ==\n\n* dbg_mlc.c (GC_print_smashed_obj): Convert a group of printf()\ncalls into a single one (for output atomicity).\n* typd_mlc.c (GC_calloc_explicitly_typed): Don't declare and use\nGC_finalization_failures variable; check the result of\nGC_general_register_disappearing_link() (for lack of memory)\ninstead.\n* finalize.c (GC_finalization_failures): Remove unused global\nvariable.\n* finalize.c (GC_general_register_disappearing_link,\nGC_general_register_disappearing_link): Don't update the value of\nGC_finalization_failures (since unused).\n* include/private/gc_pmark.h (PUSH_ONE_CHECKED_STACK,\nGC_PUSH_ONE_STACK, GC_PUSH_ONE_HEAP): The first parameter is of\nword type now (as FIXUP_POINTER requires numeric argument).\n* finalize.c (GC_ignore_self_finalize_mark_proc): GC_PUSH_ONE_HEAP\nrequires the first parameter of word type.\n* mark.c (PUSH_GRANULE): Likewise.\n* mark.c (GC_push_one, GC_push_all_eager): Likewise.\n* finalize.c (GC_finalize_all): Call GC_invoke_finalizers() or\nGC_finalizer_notifier directly, instead\nof GC_INVOKE_FINALIZERS() to prevent infinite looping.\n* include/javaxfc.h: Clarify GC_finalize_all comment.\n* gcj_mlc.c: Include gc_pmark.h before \"ifdef GC_GCJ_SUPPORT\" (not\nafter) for configuration information.\n* gcj_mlc.c (GC_gcj_malloc_ignore_off_page): Add comment.\n* gcj_mlc.c (GC_gcj_malloc_ignore_off_page): Check \"op\" local\nvariable for NULL before dereferencing it, return GC_oom_fn() in\nthis case.\n* typd_mlc.c (GC_malloc_explicitly_typed,\nGC_malloc_explicitly_typed_ignore_off_page): Transform the code to\nsuppress compiler warning (for uninitialized \"lg\" variable).\n\n* win32_threads.c (GC_unregister_my_thread): add false assertion\nin unreachable code.\n\n* pthread_support.c (GC_inner_start_routine): Don't release the\nGC lock between GC_register_my_thread_inner() and\nGC_init_thread_local() calls (post the \"registered\" even after\ncalling GC_init_thread_local()).\n* win32_threads.c (GC_register_my_thread, GC_unregister_my_thread):\nUse GC_lookup_thread_inner() instead of GC_lookup_thread() and\nacquire the GC lock only once.\n* win32_threads.c (GC_thr_init): Call GC_register_my_thread_inner()\ndirectly instead of GC_register_my_thread() since I_HOLD_LOCK\nand our (main) thread is not registered yet (add assertion for it).\n* win32_threads.c (GC_init_parallel): Call GC_lookup_thread_inner()\ndirectly instead of GC_lookup_thread() (since I_HOLD_LOCK).\n* win32_threads.c (GC_lookup_thread): Remove unused function.\n* win32_threads.c: Remove \"#error GC_DLL untested with Cygwin\".\n* win32_threads.c (GC_win32_dll_threads): Define as FALSE macro\nalso if THREAD_LOCAL_ALLOC or GC_PTHREADS.\n* win32_threads.c (GC_use_DllMain): Call ABORT also if GC_PTHREADS\n(for Cygwin).\n* win32_threads.c (GC_push_stack_for): Add parentheses around \"&&\"\n(inside GC_ASSERT) to prevent compiler warning.\n* win32_threads.c (GC_push_all_stacks): Remove FIXME for\nPARALLEL_MARK.\n* win32_threads.c (MAX_MARKERS, GC_markers): Move the definitions\nto a place before GC_get_next_stack().\n* win32_threads.c (marker_sp, marker_bsp): New static arrays (same\nas in pthread_support.c).\n* win32_threads.c (marker_last_stack_min): New static arrays (the\nsame semantics as for last_stack_min of GC_Thread_Rep).\n* win32_threads.c (GC_get_next_stack): Handle marker threads.\n* win32_threads.c (GC_mark_thread): Save the current stack pointer\nto marker_[b]sp.\n* win32_threads.c (start_mark_threads): Initialize\nmarker_last_stack_min elements (to \"unset\" value).\n\n* misc.c (GC_set_oom_fn, GC_set_all_interior_pointers,\nGC_set_finalize_on_demand, GC_set_java_finalization,\nGC_set_finalizer_notifier, GC_set_dont_expand, GC_set_full_freq,\nGC_set_no_dls, GC_set_free_space_divisor, GC_set_max_retries,\nGC_set_dont_precollect, GC_set_time_limit, GC_set_warn_proc):\nChange return type to void (these API functions no longer return\nthe old value).\n* include/gc.h: Likewise.\n* tests/test.c (main, WinMain, test): Remove explicit cast to void\nfor GC_set_warn_proc().\n* misc.c (GC_get_oom_fn, GC_get_all_interior_pointers,\nGC_get_finalize_on_demand, GC_get_java_finalization,\nGC_get_finalizer_notifier, GC_get_dont_expand, GC_get_full_freq,\nGC_get_no_dls, GC_get_free_space_divisor, GC_get_max_retries,\nGC_get_dont_precollect, GC_get_time_limit, GC_get_warn_proc): New\nAPI functions (to get the current value of the corresponding R/W\npublic variables).\n* include/gc.h: Likewise.\n* include/gc.h (GC_set_warn_proc, GC_set_free_space_divisor):\nUpdate the comment.\n* misc.c (GC_ignore_warn_proc): New API call-back function.\n* include/gc.h (GC_ignore_warn_proc): Likewise.\n* misc.c (GC_set_find_leak, GC_get_find_leak, GC_set_non_gc_bytes,\nGC_get_non_gc_bytes): New API setter and getter functions (for the\npublic GC_find_leak and GC_non_gc_bytes variables, respectively).\n* include/gc.h: Likewise.\n* include/gc.h (GC_memalign): Add proto to GC API.\n* mallocx.c (GC_memalign): Use GC_API, GC_CALL for the definition.\n* tests/test.c (run_one_test): Test GC_memalign() on Win32 too,\nremove GC_memalign() proto.\n* misc.c (GC_write): Use multi-byte (A) variants of Win32\nGetModuleFileName() and CreateFile().\n* tests/test.c (main): Replace K&R-style function definition with the\nANSI C one.\n\n* include/private/gcconfig.h (PLATFORM_ANDROID): New macro\nrecognized (for Linux on ARM32 without glibc).\n* include/private/gcconfig.h (STRTOULL): Define for all targets\n(define as \"strtoul\" for most targets except for LLP64/Win64).\n* misc.c (GC_init_inner): Use STRTOULL instead of atoi/atol()\n(cast the result to word type) to decode values of \"GC_TRACE\",\n\"GC_INITIAL_HEAP_SIZE\", \"GC_MAXIMUM_HEAP_SIZE\" environment\nvariables.\n\n* include/gc_allocator.h: Add gc_allocator_ignore_off_page.\n* tests/test_cpp.cc: Add call to gc_allocator_ignore_off_page.\n\n* win32_threads.c (GC_release_mark_lock): Correct misspelling of\nAO_load in assertion.\n\n* win32_threads.c (MAX_THREADS): Define as 1 if GC_win32_dll_threads\nis defined as FALSE (otherwise the size of dll_thread_table is near\n200 KiB for 32-bit).\n* win32_threads.c (GC_use_DllMain): Optimize for THREAD_LOCAL_ALLOC.\n* win32_threads.c (GC_Thread_Rep): Add backing_store_end and\nbacking_store_ptr fields for IA64 support.\n* win32_threads.c (GC_register_my_thread_inner): Set\nbacking_store_end field to reg_base value for IA64 (same as in\npthread_support.c).\n* win32_threads.c (SET_PTHREAD_MAP_CACHE): Put parentheses in the\n\"right\" places, remove ';'.\n* win32_threads.c (GC_fault_handler_lock): Declare only\nif MPROTECT_VDB (and not WinCE).\n* win32_threads.c (GC_suspend): Acquire and release\nGC_fault_handler_lock only if MPROTECT_VDB (and not WinCE).\n* win32_threads.c (GC_suspend): Define as STATIC.\n* win32_threads.c (GC_push_stack_for): Fix WARN() format specifier\n(should be word-compliant, \"%p\" is used w/o \"0x\"), don't cast sp.\n* win32_threads.c (GC_push_all_stacks): Convert a group of printf()\ncalls into a single one (for output atomicity).\n* win32_threads.c (GC_get_next_stack): Unprotect thread descriptor\nbefore altering its last_stack_min (\"thread\" variable is added).\n* win32_threads.c (GC_get_next_stack): Remove unnecessary checks for\n\"s\" is non-NULL.\n* win32_threads.c (GC_get_next_stack): Don't call GC_may_be_in_stack\nif WinCE.\n* win32_threads.c (GC_get_next_stack): Pass current_min value to\nGC_get_stack_min as-is (without -1).\n* win32_threads.c (GC_wait_marker): Remove FIXME and use \"release\"\nversion of AO_fetch_and_sub1().\n* win32_threads.c (GC_win32_start_inner, GC_win32_start): convert int\nto pointer (and vice versa) thru word type to suppress warnings.\n* win32_threads.c (GC_mark_mutex_waitcnt): Fix comment, always\naccess atomically.\n* misc.c: Change GC_THREADS tests back to THREADS.\n\n* allchblk.c (GC_print_hblkfreelist, GC_dump_regions): Convert\na group of printf() calls into a single one (for output atomicity).\n* include/gc.h (GC_set_all_interior_pointers, GC_set_full_freq,\nGC_set_time_limit): New prototypes.\n* misc.c (GC_set_all_interior_pointers, GC_set_full_freq,\nGC_set_time_limit): New public setter/getter functions.\n* include/gc.h: Fix (and remove outdated) comments for thread-local\nallocation.\n* include/gc.h: Fix typos in comments.\n* misc.c (GC_init_inner, GC_printf): Likewise.\n* include/gc.h (GC_unregister_disappearing_link): Refine comment.\n* include/gc.h (GC_stack_base): Recognize _M_IA64 macro.\n* misc.c (GC_stack_last_cleared, GC_min_sp, GC_high_water,\nGC_bytes_allocd_at_reset, DEGRADE_RATE): Define only if THREADS.\n* misc.c (GC_stack_last_cleared, GC_min_sp, GC_high_water,\nGC_bytes_allocd_at_reset): Define as STATIC.\n* misc.c (GC_get_heap_size, GC_get_free_bytes,\nGC_get_bytes_since_gc, GC_get_total_bytes): Acquire the GC lock to\navoid data races.\n* misc.c (GC_write_cs): Define only if THREADS (Win32/WinCE only).\n* misc.c (GC_init_inner): Initialize GC_write_cs only if THREADS.\n* misc.c (GC_init_inner): Use GC_INITIAL_HEAP_SIZE (if available) to\nset the default initial value of initial_heap_sz.\n* misc.c (GC_deinit): Destroy GC_write_cs only if THREADS.\n* misc.c (GC_init_inner): Fix WARN() format specifier (should be\nword-compliant, \"%p\" is used w/o \"0x\").\n* misc.c (GC_init_inner): Don't recognize \"GC_PAUSE_TIME_TARGET\"\nenvironment variable if SMALL_CONFIG.\n* misc.c (GC_init_inner): Recognize \"GC_FULL_FREQUENCY\" environment\nvariable to set initial GC_full_freq value (if not SMALL_CONFIG).\n* doc/README.environment (GC_FULL_FREQUENCY): Add information.\n* doc/README.environment (GC_MARKERS): Refine information.\n* misc.c (GC_init_inner): Change GC_ASSERT to GC_STATIC_ASSERT where\npossible.\n* misc.c (IF_NEED_TO_LOCK): New macro (instead of GC_need_to_lock).\n* misc.c (GC_write): Use IF_NEED_TO_LOCK for handling GC_write_cs.\n* misc.c (GC_abort): Don't define if SMALL_CONFIG.\n* misc.c (GC_abort): Directly use WRITE() instead of GC_err_printf()\n(to prevent possible infinite recursion).\n\n* finalize.c (finalization_mark_proc): Replace K&R-style declaration\nwith ANSI C one.\n* finalize.c (GC_grow_table, GC_register_finalizer_inner,\nGC_enqueue_all_finalizers): Remove outdated comments about disabling\nsignals.\n* finalize.c (GC_general_register_disappearing_link): Fix assertion\nto catch NULL \"obj\" value.\n* finalize.c (GC_unregister_disappearing_link): Check \"link\"\nalignment before gaining the lock.\n* finalize.c (GC_finalize): Refine comment.\n* finalize.c (GC_finalize): Fix WARN() format specifier (should be\nword-compliant, \"%p\" is used w/o \"0x\").\n* finalize.c (GC_invoke_finalizers): Initialize \"bytes_freed_before\"\nvariable (to 0) to suppress compiler warning.\n* include/gc_gcj.h (MARK_DESCR_OFFSET): Move to private/gc_pmark.h.\n* include/gc_gcj.h: add \"extern C\" header and tail.\n* include/private/gc_pmark.h: Remove GC_do_parallel_mark(),\nGC_help_wanted, GC_helper_count, GC_active_count declarations (move\nthe comments to the place where these symbols are defined in mark.c).\n* mark.c: Add STATIC GC_do_parallel_mark() declaration (for use by\nGC_mark_some_inner, if PARALLEL_MARK only).\n* mark.c (GC_mark_some_inner, GC_help_wanted, GC_helper_count,\nGC_active_count, GC_do_parallel_mark): Define as STATIC.\n* pthread_support.c (GC_mark_thread): Likewise.\n* typd_mlc.c (GC_explicit_typing_initialized, GC_explicit_kind,\nGC_array_kind, GC_ext_descriptors, GC_ed_size, GC_avail_descr,\nGC_typed_mark_proc_index, GC_array_mark_proc_index, GC_eobjfreelist,\nGC_arobjfreelist): Likewise.\n* include/private/gc_pmark.h (PUSH_CONTENTS_HDR): Change GC_ASSERT\nfor HBLKSIZE to GC_STATIC_ASSERT.\n* mark.c (GC_noop): Define for Borland C the same as for Watcom.\n* mark.c (GC_noop, GC_mark_and_push): Add ARGSUSED tag.\n* pthread_support.c (GC_do_blocking_inner): Likewise.\n* mark.c (GC_mark_from): Initialize \"limit\" (to 0) in the default\nswitch branch to suppress compiler warning.\n* mark.c (GC_return_mark_stack): Append new-line to printf message.\n* mark.c: Remove unused GC_true_func(), GC_PUSH_ALL().\n* pthread_support.c (GC_mark_thread): Add dummy \"return 0\" to\nsuppress compiler warning.\n* pthread_support.c (start_mark_threads): Move the code limiting\n\"GC_markers\" value (and printing a warning) to GC_thr_init().\n* pthread_support.c (GC_thr_init): Silently limit \"GC_markers\" value\nif based on the number of CPUs.\n* pthread_support.c (GC_thr_init): Treat incorrect \"GC_markers\"\nvalues as one.\n* pthread_support.c (GC_register_my_thread_inner): Add a check for\n\"stack_end\" is non-NULL (the same as in win32_threads.c).\n* pthread_support.c (pthread_create): Call GC_oom_fn before giving up\nwith ENOMEM.\n* thread_local_alloc.c (return_single_freelist): Convert \"for\" loop\nto \"while\" one to suppress \"possible extraneous ';'\" warning.\n\n* darwin_stop_world.c (GC_push_all_stacks): Recognize ARM32.\n* include/private/gc_priv.h (GC_THREAD_STATE_T): Define for ARM32\n(Darwin only).\n* include/private/gcconfig.h: Add machine-specific part for DARWIN.\n* include/private/gcconfig.h (ARM32): Define config parameters for\nDARWIN (iPhone).\n\n* alloc.c (GC_FULL_FREQ, GC_DONT_EXPAND, GC_FREE_SPACE_DIVISOR,\nGC_TIME_LIMIT): New macros (used to control the default initial\nvalues of GC_full_freq variable, GC_dont_expand,\nGC_free_space_divisor, GC_time_limit respectively).\n* include/private/gc_priv.h (TIME_LIMIT): Remove macro (replaced\nwith GC_TIME_LIMIT in alloc.c).\n* alloc.c (GC_need_full_gc, GC_stopped_mark, GC_finish_collection):\nDefine as STATIC.\n* mark_rts.c (GC_push_current_stack, GC_push_gc_structures): Likewise.\n* include/private/gc_priv.h (GC_stopped_mark, GC_finish_collection):\nMove the prototypes to alloc.c, make STATIC.\n* include/private/gc_priv.h (GC_push_current_stack,\nGC_push_gc_structures, GC_push_regs_and_stack): Remove prototypes\n(move the comments to the places where these functions are defined).\n* mach_dep.c (GC_push_regs_and_stack): Move to mark_rts.c and define\nas STATIC.\n* alloc.c (GC_timeout_stop_func, GC_stopped_mark,\nGC_print_heap_sects): Convert a group of printf() calls into\na single one (for output atomicity).\n* mark_rts.c (GC_print_static_roots): Likewise.\n* alloc.c (GC_stopped_mark): Output blank line (when logging) for\nconvenience to delimit collections.\n* alloc.c (GC_clear_a_few_frames): Rename NWORDS to CLEAR_NWORDS;\nmake \"frames\" local variable volatile (to prevent optimization).\n* alloc.c (GC_try_to_collect_inner, GC_stopped_mark,\nGC_finish_collection, GC_allocobj): Remove outdated comments about\ndisabling signals.\n* include/private/gc_priv.h (GC_register_displacement_inner,\nGC_gcollect_inner): Likewise.\n* alloc.c (GC_try_to_collect_inner, GC_stopped_mark,\nGC_finish_collection): Initialize \"start_time\" local variable (to 0)\nto suppress compiler warning.\n* mark_rts.c (GC_add_roots_inner): Likewise.\n* alloc.c (GC_RATE, MAX_PRIOR_ATTEMPTS): Guard with \"ifndef\".\n* include/private/gc_priv.h (clock, GC_stop_world, GC_start_world,\nGC_acquire_mark_lock, GC_release_mark_lock, GC_notify_all_builder,\nGC_wait_for_reclaim, GC_notify_all_marker, GC_wait_marker): Replace\nK&R-style function prototypes with ANSI C one.\n* include/private/gc_priv.h (ABORT): Define as DebugBreak() for\nWin32/WinCE if SMALL_CONFIG (the same as in GC_abort()).\n* include/private/gc_priv.h (ROUNDED_UP_WORDS, abs): Remove unused\nmacros.\n* include/private/gc_priv.h (GC_noop): Declare for Borland C the\nsame as for Watcom.\n* mark_rts.c (GC_push_conditional_with_exclusions): Add ARGSUSED tag.\n\n* dbg_mlc.c (GC_store_debug_info, GC_store_debug_info_inner): Remove\noutdated comment about disabling signals.\n* mallocx.c (GC_malloc_uncollectable,\nGC_malloc_atomic_uncollectable): Likewise.\n* os_dep.c: Likewise.\n* dbg_mlc.c (GC_debug_change_stubborn, GC_debug_end_stubborn_change):\nAdd ARGSUSED tag.\n* pthread_stop_world.c (GC_suspend_handler,\nGC_suspend_handler_inner): Likewise.\n* dbg_mlc.c (GC_debug_free, GC_debug_realloc): Fix printf message.\n* dbg_mlc.c (GC_debug_realloc): Set \"result\" to NULL in the default\nswitch branch to suppress compiler warning.\n* dyn_load.c (GC_init_dyld): Use ABORT() instead of GC_abort().\n* include/private/darwin_semaphore.h (sem_init): Likewise.\n* include/javaxfc.h: Replace \"GC_H\" with \"_GC_H\".\n* include/private/dbg_mlc.h (GC_has_other_debug_info,\nGC_store_debug_info): Replace K&R-style function prototypes with ANSI\nC one.\n* include/private/gcconfig.h (GC_FreeBSDGetDataStart, real_malloc,\nGC_win32_get_mem, GC_wince_get_mem, GC_unix_get_mem): Likewise.\n* include/private/pthread_support.h (GC_stop_init): Likewise.\n* include/private/gcconfig.h: Refine comment about setting\nGC_stackbottom.\n* include/private/gcconfig.h (FIXUP_POINTER): Put parentheses in the\n\"right\" places.\n* include/private/pthread_support.h (GC_Thread_Rep): Refine comment\nfor \"stack_end\" field.\n* mallocx.c (GC_malloc_uncollectable,\nGC_malloc_atomic_uncollectable): Remove cast to undefined \"hbklk\".\n* os_dep.c (GC_USE_MEM_TOP_DOWN): New macro (for setting\nGC_mem_top_down to MEM_TOP_DOWN for debug purposes).\n* os_dep.c (GC_gww_read_dirty, catch_exception_raise): Fix WARN()\nformat specifier (should be word-compliant, \"%p\" is used w/o \"0x\").\n* pthread_stop_world.c (GC_suspend_handler_inner): Likewise.\n* os_dep.c (GC_dirty_init): Append new-line to printf messages.\n* os_dep.c (GC_mprotect_thread): Fix GC_err_printf message.\n* os_dep.c (GC_save_callers): Change GC_ASSERT to GC_STATIC_ASSERT.\n* pthread_stop_world.c (GC_retry_signals, GC_suspend_ack_sem): Define\nas STATIC.\n* pthread_stop_world.c (GC_push_all_stacks): Add assertion for that\n\"thread_blocked\" is not set for the current thread.\n* real_malloc.c: Add \"extern GC_quiet\" to suppress compiler warning.\n* reclaim.c (GC_reclaim_all): Initialize \"start_time\" (to 0) to\nsuppress compiler warning.\n\n* tests/test.c (check_heap_stats): Avoid unbalanced brackets in ifdef.\n\n* win32_threads.c: restructure parallel marking mutex initialization.\n* win32_threads.c, alloc.c, darwin_stop_world.c, mallocx.c, mark.c,\npthread_stop_world.c, pthread_support.c: Add runtime conditions\non GC_parallel were appropriate.\n* pthread_support.c: Condition marker_bsp on ia64.\n(GC_segment_is_thread_stack): Fix loop upper bound.\n* reclaim.c: Limit some assertions to PARALLEL_MARK.\n* pthread_support.c: Don't acquire mark lock for thread-local\nallocation.\n* include/private/gc_priv.h: Don't define parallel mark sync\nsupport just for THREAD_LOCAL_ALLOC.\n\n* include/private/gcconfig.h: refine MINGW32 test.\n* mark.c: Add win64/gcc tests.\n\n* test.c (fork_a_thread, reverse_test, alloc8bytes, tree_test,\ntyped_test, run_one_test, check_heap_stats, main, test): Replace\nall K&R-style function definitions with ANSI C ones.\n* trace_test.c (main): Likewise.\n* test.c (GC_COND_INIT): Define as GC_INIT() also in case of\nTHREAD_LOCAL_ALLOC.\n* test.c (reverse_test): Call fork_a_thread() only if GC_PTHREADS\nor GC_WIN32_THREADS; remove fork_a_thread() macros definition.\n* test.c (reverse_test): Use \"volatile\" when clearing \"b\" and \"c\"\nlocal variables (to suppress \"assigned value is never used\"\ncompiler warning).\n* test.c (tree_test): Use public GC_noop1() instead of private\nGC_noop().\n* test.c (typed_test): Likewise.\n* test.c (check_heap_stats): Define and assign value to\n\"late_finalize_count\" local variable only if its value is used\n(if FINALIZE_ON_DEMAND defined).\n* test.c (main): Remove DJGPP-specific initialization of\nGC_stackbottom (not needed anymore, handled in gcconfig.h).\n* trace_test.c: Guard #define GC_DEBUG with #ifndef.\n* trace_test.c: Include \"gc_backptr.h\".\n* trace_test.c (main): Call GC_INIT().\n* trace_test.c (main): Add \"return 0\" statement.\n\n* dyn_load.c (GC_register_dynlib_callback): Use new index j\ninstead of i in the inner loop.\n\n* tests/test.c: Increment n_tests with fetch_and_add when possible,\navoiding need to export lock.\n\n* include/gc_pthread_redirects.h:\n- dlfcn.h is included for dlopen() proto before undefining\n\"dlopen\" (so, it's possible now to include dlfcn.h after\ngc.h from user code);\n- GC_dlopen() proto is added (except for Darwin as\nit's missing there);\n- \"dlopen\" is explicitly undefined (before its redefinition).\n* include/gc.h:\n- \"process.h\" is included besides \"windows.h\"\n(for _beginthreadex/_endthreadex); win32 only.\n- GC_NO_THREAD_DECLS is moved to the right place\n(before closing \"extern C\").\n* pthread_support.c: Fix out of memory handling for Thread_Reps.\n* win32_threads.c: Don't include process.h on winCE,\nimprove out of memory handling for thread structures, don't\ndefine GC_beginthreadex and GC_endthreadex for winCE.\n\n* tests/test.c: Change gcj vtable decriptor type from size_t to\nGC_word.\n\n* gcj_mlc.c: Add comment.\n* tests/test.c: Change NTEST to NTHREADS.  Fork 5 threads by default.\nRun reverse_test a second time in each thread.Add comments.\nDon't rely on AO_fetch_and_add.\n\n* dyn_load.c (GC_register_dynlib_callback,\nGC_register_dynamic_libraries_dl_iterate_phdr): Add support\nfor GNU_PT_RELRO relocations.\n\n* Makefile, Makefile.direct: GC_SOLARIS_PTHREADS was replaced\nby GC_SOLARIS_THREADS.\n* include/gc.h: Improve finalizer documentation.\n* mips_sgi_mach_dep.s: Replace _MIPS_SIM_ABI32 with _ABIO32.\n* pthread_stop_world.c, Makefile.dj: Fix typos.\n\n* win32_threads.c (GC_new_thread): Make first_thread\nvisible to the whole file.\n(UNPROTECT): New macro.\n(GC_push_stack_for, GC_suspend, GC_start_world): unprotect\nthread structures before writing.\n(GC_suspend): Acquire GC_fault_handler_lock before suspending\nthread.\n* os_dep.c: export GC_fault_handler_lock.\n(GC_remove_protection): Check if already unprotected.\n\n* doc/README.win32: Add OpenWatcom warning.\n* include/private/gcconfig.h: Really check it in.\n\n* os_dep.c (GC_get_stack_base, windows): Replace with Dave Korn's\ncode from gcc version.\n* os_dep.c: make gc compilable (optionally) for Cygwin with\nGetWriteWatch-based virtual dirty bit implementation (\"os_dep.c\" file).\n* os_dep.c: Make non-win32 GC_write_fault_handler STATIC.\n* mark.c (GC_noop): fix declaration definition mismatch for DMC.\n* include/private/gcconfig.h: Enable MPROTECT_VDB and GWW_VDB for\nWatcom (Win32 only).  It works.\n\n* mach_dep.c: Don't use __builtin_unwind_init for register\nstate on PowerPC/Darwin.\n\n* doc/gcdescr.html: Improve description of object freelist\nstructure.\n* include/private/gc_priv.h: Fix comment for _size_map.\n\n* os_dep.c (GC_linux_stack_base): Relax sanity test.\n\n* include/private/gc_pmark.h (PUSH_CONTENTS_HDR for\nMARK_BIT_PER_OBJ): Add missing backslash before eoln.\n\n* misc.c (GC_set_warn_proc): Implicitly initialize GC on\nnon-Cygwin win32.\n\n* configure.ac: Enable thread-local allocation for sparc-linux.\n\n* alloc.c (GC_try_to_collect): Remove duplicate initialization\ncheck.\n* malloc.c (GC_generic_malloc): Remove lw to eliminate single-\nthreaded warnings.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Likewise.\n\n* allchblk.c, backgraph.c, dbg_mlc.c, dyn_load.c,\nfinalize.c, include/private/gc_pmark.h, malloc.c, mark.c,\nos_dep.c, pthread_stop_world.c, pthread_support.c, reclaim.c,\nthread_local_alloc.c.\n* misc.c: Refine comment.\n\n* os_dep.c: Define GC_GWW_BUF_LEN more intelligently.  Add FIXME\ncomment.\n\n* win32_threads.c (GC_push_stack_for): Yet another attempt\nat the stack_min finding logic.  Try to clean up the existing code\nwhile minimizing VirtualQuery calls.\n(GC_win32_start_inner): Register thread before GC_printf.\nProduce more output with DEBUG_THREADS.\n*include/gc.h: Update obsolete comments.\n\n* tests/test.c:\n(gcj_class_struct2): Use cast instead of l suffix.\nCast GetLastError to int in various places.\nAvoid unused result warning from incr/decr macros.\nAdd cast for fake_gcj_mark_proc.\nCast GC_gc_no to unsigned in printf.\n\n* include/gc.h: Fix two typos in comments.\n\n* finalize.c: Fix typo in comment.\n\n* blacklst.c (GC_print_source_pointer): Don't call GC_print_heap_obj\nwith lock.\n\n* reclaim.c: (GC_reclaim_block): Scan even nearly full blocks\nif we are checking for leaks.\n\n* win32_threads.c: Remove mark lock spinning.\n* win32_threads.c, pthread_support.c: Update GC_unlocked_count,\nGC_spin_count, and GC_block_count using atomic operations.\n* tests/test.c: Declare n_tests as AO_t only if we have threads.\n\n* win32_threads.c: Support PARALLEL_MARK.  Make printf arg\ntypes agree with format specifiers.\nAdd STATIC for GC_threads.\n* include/private/gcconfig.h: Add FIXME comment.\n* tests/test.c (run_ine_test): Replace LOCK/UNLOCK use with\nAO_fetch_and_add1_full.  Declare n_tests as AO_t.\n(WinMain): Don't call GC_use_DllMain.\nwith PARALLEL_MARK or THREAD_LOCAL_ALLOC.\n\n* alloc.c (GC_try_to_collect_inner): Don't print redundant\nGC_bytes_allocd and GC_gc_no.\n(GC_stopped_mark): Print average world stop time.\n* include/private/gc_priv.h (MS_TIME_DIFF): Add cast.\n\n* misc.c, doc/README.environment: Add support  for\nGC_FREE_SPACE_DIVISOR and GC-disable-incremental.\n* include/gc.h: Make GC_set_free_space_divisor correspond to\n(somewhat unfortunate) reality.\n\n(Mostly improves LLP64 support.)\n* backgraph.c, checksums.c, dbg_mlc.c, finalize.c, mark.c,\nmisc.c, reclaim.c: Changed some int and long type to word or size_t\n(and vice versa where appropriate)\n* gcj_mlc.c, include/private/dbg_mlc.h, include/private/gcconfig.h,\ninclude/private/thread_local_alloc.h, mark.c,\nmisc.c, thread_local_alloc.c, win32_threads.c: Added intermediate\ncasts to word type when casting from int to pointer (or pointer\nto int, or data pointer to code pointer) - just to remove the\ncorresponding compiler warning.\n* ptr_chck.c (GC_is_visible): cast int const to word type to\nprevent left shift overflow.\n* os_dep.c: change the type of GC_mem_top_down global variable\n(containing a flag) to DWORD.\n* include/gc_config_macros.h: define GC_SOLARIS_THREADS if GC_THREADS\nis defined on SunOS/x64.\n* misc.c (GC_init_size_map): Ifdef out GC_ASSERT as a workaround\nfor VC++ 2008 x64 (v15.00.21022.08 for x64) compiler bug\n(the compiler gets hung if invoked with -Ox -D\nALL_INTERIOR_POINTERS -D GC_ASSERTIONS)\n* backgraph.c: cast GC_gc_no value to unsigned short when\nassigned/compared to height_gc_no field of back_edges.\n* os_dep.c (GC_remove_protection): Add ARGSUSED.\n* win32_threads.c (GC_thread_exit_proc): Remove unused local\nvariable.\n* mark.c (GC_check_dirty): Move declaration out of func body.\n\n* doc/gcinterface.html: Improve REDIRECT_MALLOC documentation.\n* include/gc.h (GC_register_my_thread): Improve comment.\n\n* Makefile.direct: Add comment for -DCHECKSUMS.\n\n* thread_local_alloc.c, include/private/thread_local_alloc.h:\nFix typos in comments.\n* finalize.c: Declare mark_procs and GC_register_finalizer_inner\nSTATIC.\n* malloc.c (GC_free): Move size calculation below assertion.\n\n* win32_threads.c (GC_get_stack_min, GC_may_be_in_stack):\nAdd one entry VirtualQuery cache, I_HOLD_LOCK assertions.\n(GC_push_stack_for, GC_get_next_stack) : Hopefully fix WINCE support.\n\n* finalize.c (GC_general_register_disappearing_link): Add\nassertion.\n* malloc.c (GC_generic_malloc): Round lb to granules, not words.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Round lb to\ngranules, not words.\n\n* mach_dep.c (NO_GETCONTEXT): Define for sparc linux.\n* configure.ac: Define mach_dep for sparc-linux.\n\n* mark_rts.c (GC_approx_sp): Use volatile to avoid common\nwarning.\n\n* dyn_load.c (GC_cond_add_roots): Fix GC_get_next_stack argument\norder.\n\n* alloc.c, dbg_mlc.c, dyn_load.c, finalize.c, gcj_mlc.c,\ninclude/gc.h, include/gc_config_macros.h, include/gc_cpp.h,\ninclude/gc_gcj.h, include/gc_mark.h, include/gc_typed.h,\ninclude/javaxfc.h, include/private/gc_locks.h,\ninclude/private/gc_priv.h, malloc.c, mallocx.c, mark.c, mark_rts.c,\nmisc.c, obj_map.c, os_dep.c, pthread_support.c, ptr_chck.c,\nstubborn.c, tests/test.c, thread_local_alloc.c, typd_mlc.c\nwin32_threads.c: Add GC_CALL and GC_CALLBACK macro invocations.\n* test.c: Remove some old K&R code.\n\n* win32_threads.c (GC_may_be_in_stack): New.  (GC_Thread_Rep):\nAdd last_stack_min.  (GC_push_stack_for): Use last_stack_min.\n(GC_get_next_stack): Add limit argument, use_last_stack_min.\n(GC_suspend): make stack_base assignment conditional.\n* dyn_load.c (win32 GC_cod_add_roots): Pass limit to\nGC_get_next_stack.\n* configure_atomic_ops.sh: Remove.\n* build_atomic_ops.sh, build_atomic_ops.sh.cygwin, doc/README.win32,\nMakefile.direct: Partially support build directories whose path\nname contains blanks.\n* Makefile.am: Support new files (build_atomic_ops.sh,\nbuild_atomic_ops.sh.cygwin)\n\n* include/private/gc_locks.h, include/private/gc_pmark.h,\ninclude/private/gc_priv.h, include/private/gcconfig.h,\nmach_dep.c, mark_rts.c, misc.c, os_dep.c, pthread_stop_world.c,\npthread_support.c, thread_local_alloc.c, typd_mlc.c, win32_threads.c:\nFix comments.\n\n* pthread_support.c: Comment out LOCK_STATS.\n* include/gc.h: Fix comments.\n\n* misc.c (GC_init_inner): Enable GC_LOG_FILE on Cygwin.\n* include/private/gcconfig.h: Consider USE_MMAP for Cygwin.\n* os_dep.c (GC_get_main_stack_base): Use alternate definition\nwith USE_MMAP.\n* include/private/gc_priv.h: Sometimes define SETJMP on Cygwin.\n\n* doc/README: Make it clearer when Makefile.direct is assumed.\n* cord/cord.am: install include/cord.h.\n\n* win32_threads.c (GC_pthread_join, GC_pthread_start_inner):\nRemove unused variables.\n* darwin_stop_world.c: Always declare GC_thr_init().\n* dbg_mlc.c (GC_debug_free_inner): Don't touch oh_sz if\nSHORT_DBG_HDRS is defined.\n* include/private/gc_pmark.h (OR_WORD_EXIT_IF_SET, parallel\nmark, USE_MARK_BITS version): Refer to correct parameter name.\n\n* finalize.c (GC_general_register_disappearing_link): Remove\nredundant code.\n* gcj_mlc.c (GC_init_gcj_malloc): Add cast to signed.\n* os_dep.c: (GC_write_fault_handler): Remove remaining\nreferences to deleted variable \"code\".  Remove redundant\nFREEBSD definitions.\n* include/private/gcconfig.h (GWW_VDB): Define for X86_64 when\ndefined for x86. (STATIC): Define as \"static\" with NO_DEBUGGING.\n\n* include/private/gc_priv.h: Update MAX_HEAP_SECTS.\n\n* dbg_mlc.c (GC_print_smashed_obj): Increase robustness with\nsmashed string, (GC_debug_free_inner): Mark as free.\n* mallocx.c (GC_malloc_many): Always clear new block if\nGC_debugging_started.\n* reclaim.c: Move GC_debugging_started from\nGC_reclaim_small_nonempty_block() to GC_reclaim_generic(),\nwhich is also called directly.\n* doc/README: Fix spelling error.  Update license summary.\n* include/gc.h (GC_PRE_INCR3, GC_POST_INCR3): add (void **) casts.\n* tests/test.c: Don't define GC_DEBUG if already defined.\n\n* doc/simple_example.html: update --enable-full-debug reference,\nMake HTML formatting standards compliant.\n* doc/debugging.html, doc/leak.html: Fix HTML formatting bugs.\n* doc/gcinterface.html: specify encoding.\n\n* doc/simple_example.html: Update thread-local allocation\ndescription.\n\n* configure.ac: Check for gc-debug earlier; replace remaining\nfull-debug tests.\n* include/gc.h, ptr_chck.c (GC_pre_incr, GC_post_incr):\nUse signed offset type.  Use ptr_t internally.\n* doc/gcinterface.html: Update LOCAL_MALLOC description.\n* doc/README.autoconf, doc/leak.html, doc/README.DGUX386:\nFix full-debug reference.\n* include/gc.h: Rewrite GC_..._INCR and friends.\n* tests/test.c: Minimally test GC_..._INCR and friends.\n\n* mark.c: (GC_push_next_marked, GC_push_next_marked_dirty,\nGC_push_next_marked_uncollectable): Never invoke GC_push_marked\non free hblk.\n* headers.c: Test COUNT_HDR_CACHE_HITS not USE_HDR_CACHE.\n(GC_header_cache_miss): Always blacklist pointers for free\nhblks.  Add assertion and comment.\n* pthread_support.c (GC_register_my_thread): Fix #if indentation.\n* include/private/gc_hdrs.h: USE_HDR_CACHE is no longer tested.\nDelete it.\n* include/private/gc_pmark.h: (PUSH_OBJ): Add assertion.\n\n* alloc.c, include/gc_mark.h, Makefile.direct: Improve comments.\n\n* configure.ac: Set win32_threads on MinGW.\n\nIvan's description of the patch follows. Note that a few pieces like\nthe GC_malloc(0) patch, were not applied since an alternate had been\npreviously applied.  A few differed stylistically from the rest of\nthe code (mostly casts to void * instead of target type),\nor were classified as too minor to bother.  Note that\nall of Ivan's static declarations which did not correct outright\nnaming bugs (as a few did), where replaced by STATIC, which is\nignored by default.\n\n- minor bug fixing (for FreeBSD, for THREAD_LOCAL_ALLOC and for\nGC_malloc(0));\n- addition of missing getter/setter functions for public variables\n(may be useful if compiled as Win32 DLL);\n- addition of missing GC_API for some exported functions;\n- addition of missing \"static\" declarator for internal functions\nand variables (where possible);\n- replacement of all remaining K&R-style definitions with ANSI\nC ones (__STDC__ macro is not used anymore);\n- addition of some Win32 macro definitions (that may be missing in\nthe standard headers supplied with a compiler) for GWW_VDB mode;\n- elimination of most compiler warnings (except for\n\"uninitialized data\" warning);\n- several typos correction;\n- missing parenthesis addition in macros in some header files of\n\"libatomic_ops\" module.\n\nMy highlights based on reading the patch:\n\n* allchblk.c: Remove GC_freehblk_ptr decl.\nMake free_list_index_of() static.\n* include/gc.h: Use __int64 on Win64, define GC_oom_func,\nGC_finalizer_notifier_proc, GC_finalizer_notifier_proc,\nadd getter and setters: GC_get_gc_no, GC_get_parallel,\nGC_set_oom_fn, GC_set_finalize_on_demand,\nGC_set_java_finalization, GC_set_dont_expand,\nGC_set_no_dls, GC_set_max_retries, GC_set_dont_precollect,\nGC_set_finalizer_notifier.  Always define GC_win32_free_heap.\ngc_config_macros.h: Define _REENTRANT after processing\nGC_THREADS.\n* include/gc_cpp.h: Improve GC_PLACEMENT_DELETE test,\nhandling of operator new[] for old Windows compilers.\n* include/gc_inline.h (GC_MALLOC_FAST_GRANS): Add parentheses\naround arguments.\n* dbg_mlc.c, malloc.c, misc.c: Add many GC_API specs.\n* mark.c (GC_mark_and_push_stack): Fix source argument for\nblacklist printing.\n* misc.c: Fix log file naming based on environment variable\nfor Windows.  Make GC_set_warn_proc and GC_set_free_space_divisor\njust return current value with 0 argument.  Add DONT_USE_USER32_DLL.\nAdd various getters and setters as in gc.h.\n* os_dep.c: Remove no longer used GC_disable/enable_signals\nimplementations.  (GC_get_stack_base): Add pthread_attr_destroy\ncall.  No longer set GC_old_bus_handler in DARWIN workaround.\n* pthread_support.c: GC_register_my_thread must also\ncall GC_init_thread_local.\n\n* Makefile.direct, mach_dep.c: Add support for NO_GETCONTEXT.\n* mach_dep.c: Include signal.h.\n* gc_priv.h: Factor out INLINE declaration.\n\n* include/private/gcconfig.h: Update MIPS/LINUX config.\n* doc/gcdescr.html: Fix typo.\n* mach_dep.c (GC_with_callee_saves_pushed): Don't rely on getcontext\nfor MIPS/LINUX.\n\n* configure.ac: SPARC fixes.\n* thread_local_alloc.c(GC_mark_thread_local_fls_for): Include\nsize 0, except for gcj.\n* doc/gc.man: Expand C++ cautions.\n* include/gc_inline.h: Fix comments.\n\n\n== [7.1] 2008-05-03 ==\n\n* doc/gcinterface.html: Improve C++ interface documentation.\n\n* allchblk.c (GC_allochblk): Check for overflow during size\nrounding.\n* tests/huge_test.c: New.\n* Makefile.direct, tests/tests.am: Add huge_test.c\n\n* pthread_support.c: Fix typo in comment.\n* os_dep.c (GC_win32_get_mem): Add heap section only if\nallocation succeeded.\n\n* malloc.c: (free replacement) Fix caller address space check.\n\n* finalize.c (GC_grow_table): Dereference table in null-check.\n\n* win32_threads.c (GC_delete_gc_thread, GC_delete_thread):\nConsistently call CloseHandle. (GC_suspend): Call\nGC_delete_gc_thread.\n* tests/test.c: Don't reference GC_print_stats if not exported.\n\n* tests/test.c (run_one_test): Don't mention pthread_self().\n* misc.c: Declare GC_thr_init().\n\n* allchblk.c (add_to_fl): disable assertions with USE_MUNMAP,\nand refine assertions to handle huge unmergeable blocks.\n(GC_allochblk_nth): Add comment.\n\n* include/private/gcconfig.h: Add missing FREEBSD macro\nconsistency test.\n\n* allchblk.c (GC_enough_large_bytes_left): No longer take\nparameters; return free list index bound.\n(GC_merge_unmapped): Don't access nexthdr until after null test.\n(Fixes bug in 1/29/08 check-in.)  (GC_allochblk): Calculate\nwhen splitting is allowable only once here, not when considering each\nblock. (GC_allochblk_nth): Accept new may_split parameter.\nAvoid some redundant tests for exact size matches.\n* alloc.c (GC_should_collect): Cache min_bytes_allocd.\n(GC_maybe_gc): Make locking assertion testable.\n* mark_rts.c: Fix indentation.\n* pthread_stop_world.c: Replace old GC_err_printf1 reference.\n* tests/test.c: Remove (void) casts.  Optionally print some\ntiming information.\n\n* windows-untested/gc.def: Remove CreateThread line.\n* windows-untested/README: New file.\n* win32_threads.c (GC_use_DllMain): Force collector initialization.\n* include/gc.h (GC_use_DllMain): Clarify usage rules in comment.\n* mark.c (GC_mark_from): Slightly simplify GC_DS_PER_OBJECT code.\n* include/gc_cpp.h: Add matching placement delete overloads\neverywhere.\n* include/private/gc_locks.h (NO_THREAD): Add cast.\n* include/private/gcconfig.h: Add test for __HP_aCC.\n* configure.ac, tests/tests.am:  Avoid libgccpp on HP/UX.\n\n* doc/README.win32: Fix typo.\n* configure.ac: Fix printing of enable-shared result.\n\n* misc.c (GC_init_inner): Assert !GC_need_to_lock only when\ndefined.  (GC_call_with_stack_base): Add GC_API.\n* os_dep.c (GC_get_stack_base): Add GC_API.\n* win32_threads.c: (GC_register_my_thread, GC_unregister_my_thread):\nAdd GC_API.\n* include/gc.h: Add GC_API annotations.\n* include/private/gc_locks.h: Define UNCOND_LOCK etc. also for\nPCR.\n* include/private/gc_pmark.h: Fix comments.\n\n* include/private/gc_priv.h, mark_rts.c, typd_mlc.c:\nAdd GC_push_typed_structures() to push GC_ext_descriptors.\n\n* tests/test.c: Call GC_INIT for DARWIN; test system type using\ngcconfig.h-defined macros.\n\n* allchblk.c (GC_merge_unmapped, GC_freehblk): Refuse to create\nblocks large enough that their size, when interpreted as a signed\nvalue, would be negative.\n* include/private/gc_priv.h: Comment hb_sz range limit.\n\n* mark.c (GC_push_next_marked): correct comment.\n* Makefile.direct: document NO_PROC_STAT.\n* include/private/gcconfig.h: Accommodate NO_PROC_STAT.\n\n\n== [7.1alpha2] 2008-01-10 ==\n\n* Makefile.am: Mention atomic_ops.c and atomic_ops_sysdeps.S\nagain.  Refer to build directory as \".\".\n\n* configure.ac: Ignore --enable-parallel-mark on Darwin for now.\n* darwin_stop_world.c: Add FIXME comment for parallel marker.\n\n* include/private/gc_priv.h: Update MAX_ROOT_SETS\nand LOG_PHT_ENTRIES to handle larger heaps.\n\n* include/gc.h (GC_INIT,GC_init): Update comments.\n\n* allchblk.c, alloc.c, include/private/gc_priv.h:\nTrack GC_bytes_dropped and use in GC triggering decisions.\n* alloc.c (min_bytes_allocd): Weight atomic blocks less.\n\n* alloc.c (GC_add_to_heap): Call GC_install_header(p) AFTER\nadjusting p.\n\n* Makefile.am: Add NT_X64_THREADS_MAKEFILE.\n\n* NT_X64_STATIC_THREADS_MAKEFILE: Clean up obsolete comment.\n* alloc.c: Add declaration for GC_add_current_malloc_heap.\n* win32_threads.c (GC_beginthreadex): Clean up error\nreturn code.\n* doc/README.win64, NT_X64_THREADS_MAKEFILE, Makefile.direct:\nAdd NT_X64_THREADS_MAKEFILE.\n\n* alloc.c: Define GC_version instead of in version.h.\n* version.h: Remove.\n* include/gc_version.h: Move most of version.h here.\n* include/gc.h: Include gc_version.h.\n* gcname.c, add_gc_prefix.c: include gc.h instead of version.h.\n* Makefile.direct, Makefile.dj, Makefile.am, include/include.am:\nAdjust for version.h rename.\n\n* configure.ac: Put libatomic_ops links in build directory.\n* Makefile.am: Don't mention atomic_ops.c and atomic_ops_sysdeps.S\nas nodist sources.\n\n* include/gc.h, doc/README.macros: Add GC_NO_THREAD_REDIRECTS,\nGC_NO_THREAD_DECLS, don't test explicitly for GC_SOLARIS_THREADS.\n\n* alloc.c: Deal correctly with address wrapping for\nGC_greatest_plausible_heap_addr and GC_least_plausible_heap_addr.\n* finalize.c, include/gc.h (GC_register_disappearing_link,\nGC_register_finalizer_inner): Improve out-of-memory handling.\n* include/private/gc_pmark.h: Fix comment spelling.\n\n* include/gc_inline.h, include/gc_tiny_fl.h: cleanups to make usable\nin other contexts.\n\n* include/gc.h: Don't define GC_HAVE_BUILTIN_BACKTRACE for uclibc.\n\n* gc_cpp.cc: Don't include gc_cpp.h from local directory.\n\n* allchblk.c, configure.ac (add --enable-munmap)\n\n* dyn_load.c (GC_dyld_image_add): Remove ifdef clause and use the macro\nGC_GETSECTBYNAME instead.\n* include/private/gc_priv.h: Define GC_GETSECTBYNAME according to the\narchitecture (Darwin).\n\n* reclaim.c (GC_bytes_found): Expand comment.\n* thread_local_alloc.c (GC_malloc_atomic, GC_gcj_malloc): Pass\ngranules, not bytes, to GC_FAST_MALLOC_GRANS.\n* include/gc.h: Never include gc_local_alloc.h.\n* tests/test.c: Add size zero allocation tests.\n\n* malloc.c: Update GC_large_allocd_bytes on explicit deallocation.\n* allchblk.c: Sanity check GC_max_large_allocd_bytes.\n\n* Makefile.direct: Invoke $(MAKE) instead of make.\n\n* doc/scale.html: Reflect gc7 thread local allocation behavior.\n\n* include/extra/gc.h, include/extra/gc_cpp.h: New.\n* include/include.am: Install gc.h and gc_cpp.h in $(prefix)/include\nagain.\n\n* pthread_support.c (GC_thr_init): Use sysconf(_SC_NPROCESSORS_ONLN)\nfor HURD.\n\n* include/private/gcconfig.h: Add Linux/mips-64 support.\n\n* dbg_mlc.c: Use random() on all glibc systems.\n* mach_dep.c (GC_with_callee_saves_pushed): Don't use getcontext() on\nHURD.  Add comment.\n* pthread_stop_world.c (GC_suspend_handler, GC_stop_init): Accommodate\nsystems without SA_SIGINFO.\n\n* include/gc.h (GC_PTR_STORE): Fix non-DEBUG parentheses.\n* tests/test.c (run_one_test): Add GC_PTR_STORE test.\nNo longer test for RS6000.\n\n* alloc.c, backgraph.c, headers.c, include/private/gc_priv.h:\nMaintain GC_our_memory and GC_n_memory.\n* dbg_mlc.c (GC_print_smashed_obj): Improve message.\n(GC_print_all_smashed_proc): Pass client object address instead of\nbase.\n* dyn_load.c (sort_heap_sects): New.  (GC_register_map_entries):\nRegister sections that are contiguous and merged with our heap.\n* malloc.c, os_dep.c (GC_text_mapping): Check for just base name\nof libraries.\n* malloc.c (calloc): Check for special callers even with\nUSE_PROC_FOR_LIBRARIES. Move assertion.  Add rudimentary\nmalloc/free tracing.\n* misc.c: No longer call GC_init_lib_bounds explicitly.\n* thread_local_alloc.c (GC_malloc, GC_malloc_atomic): Always\ninitialize on demand.\n* tests/test.c: Call GC_INIT only when required.\n\n* Makefile.direct: Remove comment fragment.\n* tests/tests.am: Add smashtest.\n* configure.ac: Define GC_USE_DLOPEN_WRAP with redirect-malloc.\n* pthread_support.c: Fix comment spelling.\n* include/private/gcconfig.h: Define USE_PROC_FOR_LIBRARIES with\nGC_LINUX_THREADS and REDIRECT_MALLOC.\n* tests/smash_test.c: Initial check-in.\n* obj_map.c: Print log entry to correct file.\n* include/private/thread_local_alloc.h: Add TlsAlloc error check.\n\n* alloc.c (GC_stopped_mark): Call GC_add_current_malloc_heap()\nwhile world is still running.\n* os_dep.c (GC_is_heap_base): Don't call GC_add_current_malloc_heap()\nwith world stopped.\n* include/gc.h (GC_INIT for cygwin): Always call GC_add_roots.\n* misc.c (GC_init/GC_init_inner): Perform all work in\nGC_init_inner.\n* Makefile.direct: Expand -DUSE_MUNMAP comment.\n\n* include/gc.h: Define uintptr_t explicitly for VC++6.\n* msvc_dbg.c (GetModuleBase): Revert to strcat if strcat_s doesn't\nexist.\n\n\n== [7.0] 2007-07-02 ==\n\n* include/gc_config_macros.h: Also check for IA64 when setting\nGC_HPUX_THREADS.\n* mallocx.c: Change my_bytes_allocd to signed_word.\n* include/gc_pthread_redirects.h: Remove obsolete Solaris threads\n(as opposed to pthreads) support.\n\n* mach_dep.c (GC_with_callee_saves_pushed): Don't use getcontext()\non ARM/Linux.  Check getcontext() return value.\n\n* backgraph.c (per_object_func): Make argument types consistent.\n(GC_traverse_back_graph): Mark GC_deepest_obj.\n\n* finalize.c (GC_finalize): Change dl_size and fo_size to size_t.\n* os_dep.c (GC_win32_get_mem): Add GC_mem_top_down option.\n\n* doc/README.win32, doc/README, README.QUICK: Fix some of the worst\nanachronisms.\n* dyn_load.c: Partially support cygwin, but don't enable it yet.\n\n* Makefile.am: Use -no-undefined for libgc.\n* Makefile.direct: Document USE_PROC_FOR_LIBRARIES.\n* dyn_load.c (GC_register_map_entries): Rename prot_buf to prot\nconsistently.\n* misc.c: Fix some WARN calls.  Move GC_is_initialized setting and\nGC_thr_init() call.\n* os_dep.c: Consistently use WARN where appropriate.\n* thread_local_alloc.c: Revert change to GC_WIN32_THREADS test.  Instead\nremove inappropriate pthread.h include.\n* doc/README.linux: Remove some anachronisms.\n\n* alloc.c: Also use GC_check_tls on non-Linux systems.\n* mallocx.c (GC_reclaim_generic): Remove bogus declaration.\n* include/private/gc_priv.h (GC_reclaim_generic): Declare correctly\nwith prototype.\n\n* alloc.c (GC_adj_bytes_allocd): Avoid (long) casts, fix comment.\n(GC_print_heap_sects): Use size_t instead of unsigned long.\n* thread_local_alloc.c (GC_lookup_thread): Define in the correct\ncontext.\n* win32_threads.c, include/gc_config_macros.h: The last of Romano\nPaolo Tenca's patch.  Move stdint.h include to gc_config_macros.h.\n* include/gc_inline.h: Avoid gc_priv.h dependencies.\n* tests/test.c (check_heap_stats): Replace unsigned long with size_t.\n\n* NT_X64_STATIC_THREADS_MAKEFILE: Replace obsolete -debugtype:cv.\n* mark_rts.c (GC_push_roots): Fix kind type.\n\n* doc/README.win64: New file.\n* doc/doc.am, Makefile.direct: Add README.win64.\n\n* Makefile.am, Makefile.direct: Add NT_X64_STATIC_THREADS_MAKEFILE.\n* NT_X64_STATIC_THREADS_MAKEFILE: Fix warning flags.\n* allochblk.c, alloc.c, blacklst.c, dbg_mlc.c, dyn_load.c,\nfinalize.c, headers.c, mach_dep.c, malloc.c, mark.c, misc.c,\nobj_map.c, os_dep.c, ptr_chck.c, reclaim.c, typd_mlc.c,\nwin32_threads.c, cord/de_win.c, include/gc_mark.h,\ninclude/private/gc_hdrs.h, include/private/gc_pmark.h,\ninclude/private/gc_priv.h, tests/test_cpp.cc:\nReplace old style function declarations.  Clean up integral types.\nRemove register declarations.  The change in malloc.c and the\n\"int descr\" declaration in mark.c are the most likely to have\nbeen real bugs outside of Win64.\n* msvc_dbg.c: Disable on Win64.\n* win32_threads.c: Add x64 support.\n* include/gc.h: no backtrace on x64 for now.\n\n* msvc_dbg.c(GetModuleBase): Replace strcat with strcat_s.\n\n* include/gc.h: (GC_word, GC_signed_word): Fix Win64 definitions.\nDon't include windows.h in an extern \"C\" context.\n* include/private/gcconfig.h: Fix Win64 configuration.\n* tests/test.c: Eliminate more old style function definitions.\nCleanup pointer and integer casts for Win64.\n* tests/test_cpp.cc: Don't include gc_priv.h.\n* NT_STATIC_THREADS_MAKEFILE: Restrict suffixes for VC++ 2005.\n* NT_X64_STATIC_THREADS_MAKEFILE: New.\n\n* win32_threads.c: Separate out DEBUG_WIN32_PTHREADS_STACK.  Ignore\nFINISHED threads for suspension.  (GC_pthread_join): Add\npthread_self() cast.  (GC_pthread_start_inner): Execute cleanup\nhandler when popping it.\n* include/private/gc_locks.h: Inline THREAD_EQUAL for\nGC_WIN32_PTHREADS.  Define USE_PTHREAD_LOCKS only if we have\npthreads.\n\n* gc_dlopen.c, thread_local_alloc.c, threadlibs.c, win32_threads.c,\ntests/test.c: Accommodate GC_WIN32_PTHREADS.\n* include/gc.h: Don't include windows.h for GC_WIN32_PTHREADS.\n* include/gc_config_macros.h: Define both PTHREADS and\nGC_WIN32_THREADS.\n* include/private/gc_locks.h: Nonstandard definitions of\nNUMERIC_THREAD_ID for GC_WIN32_PTHREADS.\n* doc/README.win32, Makefile.direct: Include documentation\nfor GC_WIN32_PTHREADS.\n* Makefile.direct: Remove some anachronisms in the documentation.\n\n* Makefile.am: Move includes to bottom.  Add better library\ndependencies.  Increment library version.  Remove \"SUBDIRS += .\".\n* cord/cord.am, tests/tests.am: Add better library dependencies.\nRemove now unnecessary dependencies.\n* include/gc.h (GC_beginthreadex, GC_endthreadex, GC_ExitThread):\nMove to define on all Windows platforms.  (_beginthread): define\nto generate error if used.\n\n* include/private/gc_locks.h: Format to 80 columns.\n\n* malloc.c(GC_free): Ignore bad frees on MSWIN32 with REDIRECT_MALLOC.\n* NT_MAKEFILE: msvc_dbg.h is in include/private.  Don't use cvars\nrc.\n* misc.c (WIN32 GC_write): Define GC_need_to_lock in single-threaded\ncase.\n* win32_threads.c: Test for __MINGW32__ in addition to _MINGW_VER.\n(GC_CreateThread, GC_beginthreadex): Deallocate args even if we fail.\n* include/gc.h: Add GC_reachable_here().  (GC_WinMain): Add GC_API.\n(GC_beginthreadex, GC_endthreadex, GC_ExitThread): Declare.\n* tests/test.c: Add GC_reachable_here() call.\n\n* alloc.c (GC_try_to_collect): Call GC_init if necessary.\n* tests/thread_leak_test.c: Don't unconditionally define\nGC_LINUX_THREADS.\n\n* Makefile.am: Remove extra_ldflags_libgc definition.\n\n* include/private/gc_priv.h: Define AO_REQUIRE_CAS.\n\n* finalize.c (GC_unreachable_finalize_mark_proc): Don't return void\nvalue.\n\n\n== [7.0alpha9] 2007-05-15 ==\n\n* Some gc6.9 changes.\n* Change FindTopOfStack decl in darwin_stop_world.c.\n* Move some static tests from misc.c to gcconfig.h.  Use #error.\n* Add GC_print_free_list() function (thanks to Bruce Hoult).\n* Add GC_GNU_THREADS support on HURD (thanks to Aleksey Demakov,\nBarry DeFreese, and possibly other Debian maintainers).\n* __GNUC__ was misspelled as __GNUC in thread_local_alloc.h (thanks to\nPeter Wang).\n* Integrated various MacOSX patches and tried to reconcile them (thanks to\nAllan Hsu, several contributors at Apple, and probably others).\n* Added some casts to powerpc.h in libatomic_ops to silence warnings.\n\n* Makefile.am: Include NT_STATIC_THREADS_MAKEFILE in dist.\n* include/private/gc_locks.h: GC_compare_and_exchange, GC_atomic_add:\nremove. NUMERIC_THREAD_ID, THREAD_EQUAL: New.  GC_lock_holder: now\nunsigned long.  I_DONT_HOLD_LOCK, I_HOLD_LOCK: Update.\n* pthread_stop_world.c, pthread_support.c, win32_threads.c: Use\nNUMERIC_THREAD_ID, THREAD_EQUAL.\n* include/private/gcconfig.h: GENERIC_COMPARE_AND_SWAP: Remove.\n* include/private/thread_local_alloc.h: Don't USE_COMPILER_TLS on\nARM.\n\n* dbg_mlc.c, include/gc.h, finalize.c: Merge Alexandre Oliva's\nGC_debug_register_finalizer_unreachable() patch from gcc tree.\n* thread_local_alloc.c (GC_malloc, GC_malloc_atomic): Add assertions\nto check GC has been initialized.\n\n* include/gc_cpp.h: Documentation updates.\n* include/gc_config_macros.h: Don't check for __ppc__ to set\nDARWIN_THREADS.\n* Makefile.am: Include configure_atomic_ops.sh in dist.\n\n* Makefile.am: Don't distribute copied atomic_ops files.  Include\nlibatomic_ops with \"make dist\".\n* configure.ac: Enable THREAD_LOCAL_ALLOC for Cygwin with threads.\n* win32_threads.c: Report error for Cygwin + GC_DLL.\n\n* Makefile.direct: Update THREAD_LOCAL_ALLOC documentation.\n* cord/de_win.c: Rename and move AboutBox.  Call GC_INIT.  Remove\nMakeProcInstance anachronism.\n* doc/README.macros: Officially remove elif prohibition.\nRemove documentation for defunct SRC_M3 support.\n* include/gc.h: Remove more SRC_M3 references.\n* include/private/gcconfig.h: Remove still more SRC_M3 references.\nGC_SOLARIS_THREADS no longer needs to be checked separately.\n\n* thread_local_alloc.c, include/private/thread_local_alloc.h:\nSpell __declspec correctly.\n* NT_STATIC_THREADS_MAKEFILE: Enable thread-local allocation.\n\n* doc/README.win32: Adjust GC_win32_dll_threads rules again.\n\n* mark.c (GC_mark_some wrapper): Restructure for readability, handle\nGC_started_thread_while_stopped.\n* misc.c (Win32 GC_write): Lock GC_write_cs only if needed.\n* win32_threads.c: (client_has_run): remove,\nGC_started_thread_while_stopped, GC_attached_thread: add.\n(GC_push_all_stacks): Add verbose output.\n(DllMain): Avoid initializing collector or the like.\nNever update both thread tables.\n* doc/README.win32: Adjust GC_win32_dll_threads rules.\n\n* pthread_stop_world.c (GC_push_all_stacks): Print thread count with\nGC_PRINT_VERBOSE_STATS.\n\n* configure.ac: Comment out redundant\nAC_DEFINE(NO_EXECUTE_PERMISSION).\n* sparc_mach_dep.S: Remove single quote in comment.\n* include/private/gcconfig.h: Fix DATAEND for NONSTOP.\n* win32_threads.c: Include stdint.h for Mingw.  Add GC_API for DllMain.\n(GC_use_DllMain): Fix assertion.\n\n* configure.ac: Introduce extra_ldflags_libgc. Use it for Darwin.\n* Makefile.am (libgc_la_LDFLAGS): Use extra_ldflags_libgc.\n* include/private/gcconfig.h: Enable MPROTECT_VDB for all Darwin\ntargets. Remove comments.\nPrepare ppc64 support for Darwin.\n\n* darwin_stop_world.c (GC_push_all_stacks): Fix compiler warnings.\nMake i unsigned.\n(GC_stop_world): Likewise. Remove unused GC_thread p.\n(GC_start_world): Likewise.\n\n* os_dep.c: Define GC_darwin_register_mach_handler_thread extern.\nRemove double SIG_HNDLR_PTR definition.\n(GC_forward_exception): Fix compiler warnings, make i unsigned.\nInitialize thread_state to NULL.\n(catch_exception_raise): Fix compiler warnings, make i unsigned.\n\n* include/private/gc_priv.h (NEED_FIND_LIMIT, FREEBSD variant):\nalso define for X86_64.\n* configure.ac: Move generic gnu (Hurd) case to below kfreebsd case.\n* README.changes: Point to ChangeLog.\n\n* darwin_stop_world.c: Move THREAD_FLD defines to ...\n* include/private/gc_priv.h: ... here.\nFix THREAD_STATE definitions for ppc64.\n* os_dep.c (catch_exception_raise): Use THREAD_FLD for exc_state member\naccess.\n\n* configure.ac (i586-darwin): Replaced HAS_I386_THREAD_STATE_* with\nHAS_X86_THREAD_STATE32_*.\n(x86_64-*-darwin*): Extended the above check for x86_64-*-darwin* with\nHAS_X86_THREAD_STATE64_*.\nAdded value 1 in the above AC_DEFINE's. Important for the upcoming\nLeopard.\n* include/private/gcconfig.h: Modified X86_64 define for Darwin.\nRemoved __x86_64__ check in POWERPC section. Added base definitions\nfor the X86_64 Darwin port.\n* include/private/gc_priv.h: Added GC_MACH_HEADER and GC_MACH_SECTION\nto distinguish between 32 and 64-bit applications. Added definitions\nfor X86_64 Darwin.\n* darwin_stop_world.c: Added HAS_X86_THREAD_STATE64___RAX. And\nreplaced HAS_I386_THREAD_STATE___EAX with HAS_X86_THREAD_STATE32___EAX.\n(GC_push_all_stacks): Added code for X86_64 Darwin. Even for the\n!DARWIN_DONT_PARSE_STACK. Maybe obsolete.\n* dyn_load.c (GC_dyld_name_for_hdr): Use GC_MACH_HEADER.\n(GC_dyld_image_add): Use GC_MACH_HEADER and GC_MACH_SECTION.\nDistinguish between getsectbynamefromheader_64 and\ngetsectbynamefromheader.\n* os_dep.c (catch_exception_raise): Introduce exception definition for\nX86_64 Darwin. Replaced old i386_EXCEPTION_STATE_* definition with\nx86_EXCEPTION_STATE32_*. Add X86_64 for exc_state.faultvaddr.\n\n\n== [7.0alpha7] 2006-09-19 ==\n\n* More 6.7 changes.\n* Declare GC_dump() in gc.h.\n* Add --enable-large-config, which just defines the LARGE_CONFIG macro.\n* Make GlobalAlloc address alignment a bit more intuitive (thanks to\nCharles Mills).\n* Use #elif in the definitions of GET_MEM.\n* Overhaul porting.html.  Remove corresponding text from README.\n* Fix typo in DARWIN section of gcconfig.h.\n* Fix Darwin thread memory leak (thanks to Bruce Mitchener).\n* Update x86 AO_test_and_set implementation to use \"=q\".\n* Add $(EXEEXT) to many tests in tests/tests.am.  (Corresponds to a\n6.7 fix, which no longer applied.)\n* Fix Darwin/PPC port.\n* Fix Cygwin/threads port.\n* Fix gcj malloc support.\n* For GNU-style make, don't build libatomic_ops unless threads are requested.\nThis should allow single-threaded builds on platforms which do not\ncurrently support libatomic_ops.\n* Clean up and hopefully fix the CFLAGS calculation for GNU build.\n(Substantially improves things on HP/UX.)\n* Integrated Andrei Polushin's Visual C++ patches.  These provide for\nstack traces, better C++ debug support, and better log file handling.\nNote that these change the location of the log file to a the path of the\nexecutable with a .log extension.  To get the old behavior back, define\nOLD_WIN32_LOG_FILE.  For the time being, I'm checking his project\nfiles and the like into a windows-untested subdirectory.  They\nare almost certainly already out of date, but better than what we had\nbefore.\n* Fixed some win32 threads bugs, and added support for _beginthreadex.\n* Fix zero size thread local allocation so that explicit deallocation\nworks correctly.\n* Removed serious bug in GC_malloc_uncollectable(large size).\n* Do not try to do thread-local gcj allocation in incremental mode.  There\nare races in setting up the descriptor.\n* Add GC_INIT() to middle.c, fix some more GC_printfn calls.\n* Some assertions erroneously used I_HOLD_LOCK() negatively, even though\nit can now spuriously return TRUE.\n* Rename SUNOS5 macro and OS name to SOLARIS and SUNOS5DL to SOLARISDL.\n* On Linux and some Un*x variants, allocate memory by first trying sbrk,\nand then switching to mmap if that fails.\n* Fixed /proc/x/maps reading to deal with asynchronous deletions.\n* Fix REDIRECT_MALLOC with threads on Linux.  It now usually seems to work\nwith ugly hacks that include having calloc behave differently when it is\ncalled from ld.so or the pthreads library.  A reasonable amount of\ninfrastructure was added to support some of this.  (Thanks to Roland McGrath\nfor ideas and information.)\n* Import various updated build scripts.\n* Add GC_register_has_static_roots_callback (thanks to Andrew Haley).\n* Fix serious bugs in GC_malloc_atomic_uncollectable().\n* Return GC_SUCCESS form GC_get_stack_base().\n* Fix several atomic_ops problems on IA64 with HP Compiler.\n* Update to atomic_ops-1.2.\n* Fix hb_n_marks description and reclaim.c assertion.\n* Various additional win32 threads fixes.\n* Enable GC_ASSERTIONS for Debug build with NT_THREADS_MAKEFILE.\n\n\n== [7.0alpha5] 2005-09-29 ==\n\n* More 6.6, 6.7 changes.\n* Some Solaris fixes, including some more general changes in how\nthe assembly pieces of mach_dep.c are handled.\n* Removed a lot of SOLARIS_THREADS-specific code that was only\nneeded with the old implementation.  This included many (mostly no-op)\nversions of GC_is_fresh.\n* Don't use atomic_ops in gc_locks.h unless we need threads.\n* Fixed USE_MARK_BITS, which is once again the default without PARALLEL_MARK.\n* Removed Solaris GC_INIT hack.  It's a workaround for a long dead bug,\nand it seemed to be wrong anyway.\n* Changed win32_threads.c to require preprocessor-based interception\nof thread routines by default.  A client call to GC_use_DllMain is\nnow required to get the old behavior in which DllMain is used to implicitly\nregister threads.  This was done for uniformity with other platforms, and\nbecause the DllMain solution seemed to require very tricky code which,\nat least in the past, imposed hard bounds on the number of threads.\n* Many small changes to make thread support work again on Cygwin.\n* Moved definition of allocator lock etc. to pthread_support.c and\nwin32_threads.c for those two cases.\n* Got rid of the FASTLOCK() machinery.  It doesn't seem useful on modern\nplatforms.\n* Cleaned up the uncollectible allocation routines, speeding up the\nslower paths.  The code did enough unnecessary work off the critical path\nthat the underlying logic was getting hard to extract.\n* No longer turn off THREAD_LOCAL_ALLOC with DBG_HDRS_ALL.  Indications\nare it just works, and I think the reasons for it not working disappeared\na while ago.\n* Fixed bugs in hb_n_marks calculation and assertion.\n* Don't use __builtin_expect for pre-3.0 gcc.\n* Define GWW_VDB only for recent Microsoft tool chains.\n* Add overview.html to doc directory.\n* Fix NT_STATIC_THREADS_MAKEFILE, various compiler warnings.\n* Made thread local allocation sort of work with Cygwin.  The code should\nbe there to deal with other Windows variants, But non-Cygwin Windows\nthreads need more bug fixes.\n\n\n== [7.0alpha4] 2005-08-02 ==\n\n* Various 6.5, 6.6 changes.\n* Removed GC_brief_async_signal_safe_sleep and used atomic_ops instead\n(thanks to Ben Maurer).\n* Integrated build patches from Davide Angelocola and Petter Urkedal.\n* Fix dynamic-linker-based pthread call redirection.\n* Renamed RS6000 to POWERPC/AIX.\n* Allow recovery from SIGSEGV in marker on Linux.  This works around\na race in thread stack marking if /proc is used to find roots.  We do\nthat by default with malloc redirection and threads.  This involved\nmoving some GC_find_limit and SETJMP related declarations to gc_priv.h.\n* Added doc/porting.html file.\n* Added ADD_HEAP_GUARD_PAGES for sbrk/*nix platforms to debug extreme\nmemory overwrite errors.\n* Added trivial NO_INCREMENTAL flag to facilitate debugging.\n* Added GC_getattr_np-based GC_get_stack_base (untested).\n* Separated thread local allocation into a separate file and added the\nbeginning of win32 support for that.\n\n\n== [7.0alpha3] 2005-04-28 ==\n\n* Added support for dlopen-based interception of pthread functions.\nThis is only half done.  The gc.h redefinitions currently interfere.\n* Integrated major automake overhaul from Petter Urkedal.\n\n\n== [7.0alpha2] 2005-04-07 ==\n\n* GC_bytes_allocd was incremented by a possibly uninitialized variable\nin GC_generic_malloc_inner.  (Bug introduced in gc7.0alpha1.  Thanks\nto Ben Hutchings for tracking it down.)\n* Win32 fixes (thanks to Ben Hutchings and Maurizio Vairani).\n* Integrated Ben Hutchings' GetWriteWatch-based virtual dirty bit\nimplementation for win32.\n* Removed pc_gc.tar and floppy targets in Makefile.direct.  Removed\npc_excludes file.\n* No longer include GC_bytes_wasted when evaluating allocation progress.\nSince we are now counting live memory, it no longer makes sense.\n* Applied Davide Angelocola's configure patch.  There are now separate\nMakefile.am's in the cord and tests subdirectory, more tests, etc.\n* Renamed configure.in to configure.ac.\n* Merged a very small number of Nathanael Nerode's configure.ac\ncleanups from the gcc tree.  Unfortunately, that file is a bit\ndifferent from ours.\n* Changed EINTR handling in sem_wait slightly.\n* Restructure the root marking code.  Remove all traces of\nUSE_GENERIC_PUSH_REGS, and effectively make it the default.\nMake it easier to pass a context pointer to the mark routine, in\ncase we ever want to do precise stack marking.\n* Replace GC_start_blocking() and GC_end_blocking() with GC_do_blocking().\nThis remains undocumented, and only implemented for pthreads.  But it\nremoves an otherwise unavoidable race with stores of callee-save\nregisters.\n* Fix GC_n_mark_bits for the default MARK_BIT_PER_GRANULE case.  This\nresulted in bogus complaints in heap dumps.\n* Upgrade to libatomic_ops-1.0, and update build structure to match.\n* Remove SRC_M3 support. Clean up lock initialization code in misc.c.\n* Removed gc_local_alloc.h.  If THREAD_LOCAL_ALLOC is defined, the\nthread local allocation routines are now called automatically.\n* Renamed gc_inl.h back to gc_inline.h.  Changed the interface appreciably\nsince locking has turned into a dominant issue, and in-line allocation\nonly makes sense if it's no worse than thread-local allocation.\nGc_inline.h is now also used to implement thread-local allocation.\n* Finished replacing stubborn allocation with manual write barrier.\nUntested.\n* Use thread-local allocation code by default.\n* Added GC_register_my_thread and friends for Posix and win32.\n* Patch for GWW_VDB from Ben Hutchings.\n* Removed explicit THREAD_LOCAL_ALLOC tests, since that now always\nredefines GC_malloc.\n* Removed now unused AIX memory allocation code.\n* Various minor fixes for bugs introduced in 7.0alpha1.\n\n\n== [7.0alpha1] 2004-11-09 ==\n\n* Remove GC_PROTO, VOLATILE, GC_PTR, and GC_CONST.  Assume ANSI C compiler\nand use ANSI constructs unconditionally.\n* Introduce #elif and #error in some of the appropriate places.\n* Remove GC_printf cruft. Use stdargs.\n* Remove separate Solaris threads support.  Use the more generic Posix\nimplementation.\n* Use atomic_ops for atomic operations and memory barriers.\n* Clean up MPROTECT_VDB implementation.  Use SA_SIGINFO wherever\npossible.\n* Remove broken SIGNALS stuff.\n* Use size_t instead of word, where appropriate.\n* Add .S.o rule to Makefile.am.\n* Officially discontinue SunOS4, several old flavors of M68K (SunOS4,\nA/UX, HP), IBM PC/RTs and RISCOS/Irix4.  (I doubt the old code worked.\nIf anyone cares, these should be easy to resurrect.)\n* Add EXPECT() in some critical places.\n* Redefined hb_sz and hb_body to deal with bytes rather than words.\nThis affected a great deal of code.  I would like to consistently use\nbyte offsets and sizes where there's not a convincing reason to do\notherwise.\n* Redefined several other variables (GC_mem_found, GC_words_allocd)\netc. to use units of bytes.  Most of these were also renamed to\nreflect that fact.\n* Killed as many \"register\" declarations as possible.\n* Partially replaced stubborn allocation with manual write barrier.\nIt's currently broken.\n* Restructured mark code, to allow mark bits to be kept either on\na per allocation granule or per object basis.  The emphasis is\nnow on the -DUSE_MARK_BYTES option, since individual bits perform\nquite badly on hyper-threaded P4s, and are probably suboptimal on\nother architectures.  -DUSE_MARK_BITS is currently broken, and may\nbe resurrected only for the single-threaded case.  This significantly\nreduced the cache footprint required by auxiliary GC data structures.\nIt also reduces space overhead for small heaps.  It probably slows\nthings down slightly if interior pointers are very common.\n* As part of the above, we now maintain an approximate count of set\nmark bits in each heap block.\n* As part of the above, the semantics of hb_map changed drastically.\nFor MARK_BIT_PER_OBJ, it doesn't exist.  For MARK_BIT_PER_GRANULE,\nit is purely a way to replace a mod instruction with a table lookup.\n(Somewhat to my surprise, this still wins on modern hardware.)\n* Removed PRINTSTATS, GATHERSTATS, and SILENT macros.  Everything is\nnow controlled by GC_print_stats variable and GC_PRINT_STATS\nand new GC_PRINT_VERBOSE_STATS environment variables.\n* Add GC_log_printf and use it consistently for logging output.\n* Unconditionally count the objects we reclaim in the sweep phase.\nFor thread local allocation, we need that anyway, and we expect\nthat's increasingly the only case that matters.  And it simplifies\nthe code.  In general expect minor performance hacks that benefit\nonly the single-threaded case to disappear.\n* Remove GC_quiet from gc.h and elsewhere.\n* Changed the heap expansion heuristic, and the definition of\nGC_free_space_divisor, to refer to live data size, instead of total\nheap size.  I believe this is much more robust.  It wasn't previously\npossible, because we didn't have access to live data size.\n* Thread local allocation added the extra byte in twice: Once in\nthread_local_alloc, and once in malloc_many.\n* Removed GC_malloc_words_small and GC_gcj_fast_malloc.  A new\nmechanism based on the thread local allocation data structures\nis expected to be added instead.  This should allow inlined code\nthat is both fast and doesn't rely on collector internals.\n* Changed both free lists and reclaim lists to be indexed by granules\ninstead of words, norming halving their size.\n* MERGE_SIZE is now the only option, and the macro was removed.\n(Without it, we need a memory reference to GC_all_interior_pointers\nanyway.  Thus it costs us nothing.)\n* Change GC_size_map to map to granules instead of words.  Make sure\nthat every possible size up to TINY_FREELISTS is present.\n* Split of macros need for fast inline allocation into gc_tiny_fl.h\nin anticipation of a new inline allocator that doesn't rely on GC\ninternals.\n* Changed thread local allocation to use GRANULE_BYTES and TINY_FREELISTS\nin anticipation of a merge with the inline allocation code.\n* Removed ALIGN_DOUBLE.  This is mostly handled by GRANULE_BYTES.\n* Make locking on most platforms conditional on GC_need_to_lock.\n\n\n== [6.9] ==\n\n* Fix typo in PREFETCH implementation for X86_64 (thanks to Peter Wang).\n* Fix M68K LINUX port (thanks to Debian packagers).\n* __GNUC__ was misspelled as __GNUC in new_gc_alloc.h (thanks to Peter Wang).\n* Integrated Allan Hsu's patch for OS X VM deallocation problems.\n* Applied FreeBSD/X86_64 patch.\n\n\n== [6.8] 2006-07-08 ==\n\n* Added some support for Dragonfly BSD (thanks to Joerg Sonnenberger and\nThomas Klausner).\n* Improvements to the HP/UX section of configure.in/configure.ac (thanks\nto Andreas Tobler).\n* GC_unix_get_mem could neglect to release the malloc lock on Irix, under\nextremely unlikely circumstances.  (Thanks to Jean-Baptiste Nivois for\nsome careful code inspection.)\n* Added support for kFreeBSD + glibc (thanks to Petr Salinger).\n* Fix more MacOS threads memory leaks (thanks to Allan Hsu).\n* Added initial Solaris/x64 support (thanks to Rainer Orth).\n\n\n== [6.7] 2006-03-03 ==\n\n* Add \"int\" to Solaris \"end\" and \"etext\" declaration in gc.h.  Declared\nthe symbols with underscores and as arrays, since that's what's actually\nused.  Perhaps this could all just be removed.  (Thanks to John Bowman.)\n* Fixed ARM GC_test_and_set code (thanks to Kazu Hirata and Paul Brook).\n* Added casts for assignments to hb_last_reclaimed, which truncate the\nvalue.  Added a cast to GC_adj_words_allocd.  Use GetModuleHandleA\nwhen retrieving a handle to kernel32.dll under win32.\n* Added Tandem S-Series support.  (Thanks to Craig McDaniel.  A modified\nversion of his patch was applied, and hence breakage is probably not\nhis fault.)\n* Remove spurious gc:: qualifier for operator delete[] in gc_cpp.h (thanks\nto Hanno Boeck).\n* Changed a test for LINUX in config_macros.h to one for __linux__.\n* Add prototypes for GC_finalizer_notifier and GC_thr_init (thanks to\nDavid Ayers).\n* Use ld instead of nonexistent ldz instruction in Darwin FindTopOfStack\n(thanks to Andreas Tobler).\n* Add support for Darwin/x86 (thanks to Geoff Norton and the Mono\ndevelopers).\n* Merge in some recent gcc fixes.  Add ppc64 asm code.  (Thanks to\nBryce McKinlay and other GCJ developers.)\n* Scan MEM_PRIVATE sections under Windows ME and predecessors.\n* Interior pointers with some largish offsets into large objects could\nbe ignored, if GC_all_interior_pointers was set.  (Oddly this worked\ncorrectly for stack references if it was not set.  Otherwise it failed\nfor both stack and heap references.  Thanks to Andrew McKinlay for the\ncritical test case.)\n* Integrated Tatsuya Bizenn's NETBSD threads support, with some\nuntested changes.\n* Added GC_strdup and friends to make leak detection work correctly\nfor strdup clients (thanks to Jon Moore).  Fixed the existing strdup\nwith malloc redirection to handle a null malloc return correctly.\n\n\n== [6.6] 2005-09-09 ==\n\n* Fix CPU count detection for Irix and FreeBSD (thanks to Dan Bonachea).\n* Integrate Dan Bonachea's patch for the IBM XLC compiler on Darwin.\n* Integrated Andreas Tobler's FreeBSD/PowerPC patch.\n* Don't access the GC thread structure from the restart handler.  It's\nunsafe, since the handler may run too late.  (Thanks to Ben Maurer for\ntracking this down.)\n* Applied Christian Thalinger's patch to change comment syntax in\nalpha_mach_dep.S.\n* Added test for GC_no_dls in GC_dyld_image_add for DARWIN (thanks to\nJuan Jose Garcia-Ripoll).\n* Use LINUX_STACKBOTTOM for Linux/SH and LINUX/ARM (thanks to\nSugioka Toshinobu and Christian Thalinger).\n* Rewrote GC_parse_map_entry.  This assumed a fixed column layout of\n/proc/self/maps on Linux.  This ceased to be true about 2 years ago.\nThe old code is probably quite problematic with -DREDIRECT_MALLOC.  It\nis also used by default for IA64, though I haven't seen actual failures\nthere.\n* More consistently define HBLKSIZE to 4096 on 64 bit architectures with\n4K pages (thanks to Andrew Haley).\n* With win32 threads, GC_stop_world needs to acquire GC_write_cs (thanks\nto Ben Hutchings for the observation and patch).\n* Move up struct callinfo declaration to make gcc 4.0.2 happy.\n\n\n== [6.5] 2005-05-22 ==\n\n* Integrated Paolo Molaro's patch to deal with EINTR in sem_wait.\n* Make GC_approx_sp() write to dummy location to ensure that stack\nis grown here, when sp looks reasonable, rather than later, when\nit might look like a bad memory reference.  (Problem was never\nobserved that I know of.  But on rereading the code it seemed\ndubious.)\n* Separate out GC_with_callee_saves_pushed and sometimes call\nit from GC_suspend_handler in pthread_stop_world.c.  Callee-save\nregister values sometimes failed to get traced under HP/UX on\nPA-RISC.  Linux/IA64 had the same problem, though non-stacked\ncallee-save registers seem to be so rarely used there that nobody\never noticed.\n* Integrated an ancient Darwin powerpc_darwin_machine_dep.s patch\nfrom Andreas Tobler, which I had lost.\n* Fix compare_and_exchange implementation for gcc/IA64 to deal with\npickier compiler versions.\n* Fixed Itanium 32-bit ABI support (HP/UX).  In particular, the\ncompare_and_exchange implementation didn't consider that possibility.\n* Undefine GC_pthread_detach in win32_threads.c (thanks to\nTommaso Tagliapietra).\n* Fixed inclusion of frame.h for NETBSD in os_dep.c.\n* Applied Dan Bonachea's patch to use mmap on AIX.\n* Several fixes to resurrect the Irix port on recent OS versions.\n* Change ALPHA to use LINUX_STACKBOTTOM.\n* Change SPARC64/LINUX to also use LINUX_STACKBOTTOM.  Deal with potential\nbad values of __libc_stack_end on that platform (thanks to David Miller).\n* Relax gctest to allow larger heap if ALIGN_DOUBLE isn't set.\n(Unnecessary in 7.0)\n* Force a define of __STDC__=0 for the IBM compiler on AIX, so that\nwe get prototypes.  (Unnecessary in 7.0)\n* GC_INIT definition for AIX and CYGWIN referred to DATASTART and DATAEND\nwhich are only defined in private include files.\n* Integrated some small gcconfig.h patches from Dan Bonachea.  Also\nrelaxed assertion about FreeBSD stack size in pthread_support.c.\n* Integrated Andrew Begel's darwin_stop_world.c patch for 64-bit\nsupport.  This may need additional work.\n* Avoided potentially infinite recursion in GC_save_callers if\nthe system backtrace calls malloc.  The workaround currently requires\n__thread support if this code is used with threads.\n* Avoided another similar infinite recursion by conditionally\ninvoking GC_save_callers in alloc.c (thanks to Matthias Andree\nfor helping to track down both of these).\n* Removed all traces of aix_irix_threads.c.  AIX and Irix now use\npthread_support.c and pthread_stop_world.c.  The old code appeared\nto be unreliable for AIX, and was not regularly maintained.\n* On Irix, ignore segments with MA_FETCHOP or MA_NOTCACHED attributed;\nthey're not always safe to read.\n* Fixed a previously vacuous assertion (diagnosed by the SGI compiler)\nin GC_remove_from_fl.\n* Fix stack_size assertion in GC_pthread_create.\n* Fix assertion in GC_steal_mark_stack.\n\n\n== [6.4] 2004-12-21 ==\n\n* Merge gcconfig.h changes from gcc tree.\n* Unconditionally include gc_priv.h in solaris_pthreads.c, win32_threads.h,\naix_irix_threads.c, and solaris_threads.c to get thread definitions.\n* Start marker threads in GC_thr_init, so that they get started even\nif no other threads are ever started.  (Oddly enough, the parallel\ncollector worked correctly, though not well, with no helper threads.)\n* Go ahead and split large blocks in GC_allochblk_nth if GC_dont_gc\nis set (thanks to Alexander Petrossian).\n* GC_PRINT_BACK_HEIGHT would deadlock with thread support.\n* Let in_progress_space in backgraph.s grow dynamically.\n* Fix README.solaris2.  The GC_thr_init() hack doesn't work anymore.\n* Convert GC_finalizer_mem_freed to bytes in allchblk.c.\n* Add missing declaration for GC_generic_malloc_words_small_inner.\nWithout it, s390x breaks.  (Thanks to Ulrich Weigand.)\n* Applied several MacOSX patches to support older tool chains (thanks\nto Stefan Ring).\n* Bug fix for NetBSD/x64 (thanks to Marc Recht).\n* Add NetBSD/sh3 support (thanks to Uchiyama Yasushi).\n* Fixed an uninitialized variable in cordprnt.c.\n* Eliminated some, but not all, gcc -Wall warnings.\n* Changed some old style casts to reinterpret_cast in new_gc_alloc.h\n(thanks to Dan Grayson).\n* GC_extend_size_map shouldn't adjust for GC_all_interior_pointers if\nGC_DONT_ADD_BYTE_AT_END is set.\n* Changed some (long) casts to (word) in preparation for Win64 (thanks\nto Peter Colson).\n* Changed \"int stack_size\" declaration in pthread_support.c to use\nsize_t.  (Only mattered with GC_ASSERTIONS enabled.)\n* Added CRIS (etrax) support (thanks to Simon Posnjak and Hans-Peter Nilsson).\n* Removed GC_IGNORE_FB frame buffer recognition, and replaced\nit with a check that the mapping type is MEM_IMAGE.\nIn theory, this should work much better, but it is a high\nrisk change for win32.  (Thanks to Ashley Bone for the crucial\nexperimental data behind this, and to Rutger Ovidius for\nsome further experiments.)\n* GC_allochblk_nth incremented GC_words_wasted by bytes rather than\nwords.\n* Consider GC_words_wasted in GC_adj_words_allocd only if it is within\nreason.  (A hack to avoid some extremely unlikely scenarios in which\nwe manage to allocate only \"wasted\" space.  7.0 has a better fix.)\n* Changed PowerPC GC_clear implementation to use lwsync instead of\neieio, since the documentation recommends against eieio, and\nit seems to be incorrect if the preceding memory op is a load.\n* Fixed print_block_list to print the correct kind number for\nSTUBBORN (thanks to Rutger Ovidius).\n* Have configure.in generate an error if it is asked to support\npthreads, but doesn't know how to.\n* Added Kazuhiro Inaoka's patch for Renesas M32R support.\n* Have the GNU build mechanism link with -ldl.  Rename THREADLIBS\nto THREADDLLIBS to reflect this.  (Thanks to Sven Verdoolaege.)\n* Added Hannes Mehnert's patch for FreeBSD/SPARC support.\n* Merged some FreeBSD specific patches to threadlibs.c and dyn_load.c.\n(Thanks to John Merryweather Cooper.)\n* Define MPROTECT_VDB on MACOSX only if threads are being used, since the\ndirty page tracking mechanism uses threads.  (This avoids an undefined\nreference to _GC_darwin_register_mach_handler_thread.)\n* By popular demand, use __libc symbols only if we are built with\nUSE_LIBC_PRIVATES, which is off by default, and not otherwise documented.\n* Ignore GC_enable_incremental() requests when KEEP_BACK_PTRS is set.\nThe GC itself will dirty lots of pages in this cases, probably making\nit counterproductive on all platforms.  And the DARWIN port crashes.\n\n\n== [6.3] 2004-07-08 ==\n\n* Compile test_cpp.cc with CXXCOMPILE instead of COMPILE.\n* Very large allocations could cause a collector hang.  Correct\ncalculation of GC_collect_at_heapsize.\n* GC_print_hblkfreelist printed some bogus results if USE_MUNMAP\nwas defined.\n* Include gc_config_macros.h in threadlibs.c.\n* Correct MacOSX thread stop code (thanks to Dick Porter).\n* SMALL_OBJ definition was off by one.  This could cause crashes\nat startup.  (Thanks to Zoltan Varga for narrowing this down to\na trivial test case.)\n* Integrate Paolo Molaro's patch to deal with a race in the Darwin\nthread stopping code.\n* Changed X86_64 implementation to use SA_SIGINFO in the MPROTECT_VDB\nimplementation.  The old approach appears to have been broken by\nrecent kernels.\n* Added GC_ATTR_UNUSED to eliminate a warning in gc_allocator.h (thanks\nto Andrew Begel).\n* Fix GC_task_self declaration in os_dep.c (thanks to Andrew Pinski).\n* Increase INITIAL_BUF_SZ in os_dep.c for Solaris /proc reads.\n\n\n== [6.3alpha6] 2004-05-06 ==\n\n* Define USE_GENERIC_PUSH_REGS for NetBSD/M68K.\n* Fixed the x64 PREFETCH macros to correctly handle ia32e (which uses\ndifferent prefetch instructions on x64).  (Thanks to H.J. Lu.)\n* GC_config_macros.h did not correctly define GC_WIN32_THREADS from\nGC_THREADS.\n* Added simple_example.html.\n* Merged Andrew Gray's patch to correctly restore signal handlers on\nFreeBSD.\n* Merged a patch from Andreas Jaeger to deal with prefetch-related warnings\non x86-64.  Added some other casts so that the PREFETCH macros\nalways get a ptr_t argument.  Removed some casts in the PREFETCH\nimplementations.\n* Added a header guard for gc_allocator.h and changed GC_debug_free to\nclobber contents of deallocated object (suggested by Jesse Jones).\n* The signal masking code in pthread_stop_world.c contained some errors.\nIn particular SIGSEGV was masked in the handler, in spite of the fact that\nit wrote to the heap.  This could lead to an uncaught SIGSEGV, which\napparently became much more likely in Linux 2.6.  Also fixed some\ntypos, and reduced code duplication in the same area.\n* Remove ltconfig, clean up configure messages for DG/UX (thanks to\nAdrian Bunk for the patches).\n* Integrated NetBSD/OpenBSD patches from Marc Recht and Matthias Drochner.\n\n\n== [6.3alpha5] 2004-03-30 ==\n\n* Fix & vs && typo in GC_generic_malloc and\nGC_generic_malloc_ignore_off_page.  (Propagated from the gcc tree.)\n* Removed SA_NODEFER hack from NetBSD and Solaris write-protect handler.\n(According to Christian Limpach, the NetBSD problem is fixed.\nPresumably so is the Solaris 2.3 problem.)\n* Removed placement delete from gc_cpp.h for the SGI compiler (thanks\nto Simon Gornall for the patch).\n* Changed semantics of the GC_IGNORE_FB environment variable, based\non experimentation by Nicolas Cannasse pointing out that the old\ninterpretation was useless.  We still need help in identifying win32\ngraphics memory mappings.  The current \"solution\" is a hack.\n* Removed \"MAKEOVERRIDES =\" from Makefile.am and thus Makefile.in.\nIt probably made more sense in the gcc context.\n* Explicitly ensure that NEED_FIND_LIMIT is defined for {Open,Net}BSD/ELF.\n* Replaced USE_HPUX_TLS macro by USE_COMPILER_TLS, since gcc often\nsupports the same extension on various platforms.\n* Added some basic (completely untested) defines for Win64, in support\nof future work.\n* Declared GC_jmp_buf in os_dep.s as JMP_BUF instead of jmp_buf, fixing\na memory overwrite bug on Solaris and perhaps other platforms.\n* Added 0 != __libc_stack_end test to GC_linux_stack_base (thanks to\nJakub Jelinek for the patch and explaining the problem).\nOtherwise pre-linking could cause the collector to fail.\n* Changed default thread local storage implementation to USE_PTHREAD_SPECIFIC\nfor HP/UX with gcc.  The compiler-based implementation appears to work\nonly with the vendor compiler.\n* Export GC_debug_header_size and GC_USR_PTR_FROM_BASE from gc_mark.h,\nmaking client mark code cleaner and less dependent on GC version.\n* Export several new procedures and GC_generic_malloc from gc_mark.h\nto support user-defined kinds.  Use the new procedures to replace existing\ncode in gcj_mlc.c and typd_mlc.c.\n* Added support for GC_BACKTRACES.\n* Fixed a remaining problem in CORD_str with signed characters (thanks\nto Alexandr Petrosian for the patch).\n* Removed supposedly redundant, but very buggy, definitions of finalizer\nmacros from javaxfc.h.  Fortunately this file probably has no users.\nThe correct declarations were already in gc.h.\n* Also need to set GC_in_thread_creation while waiting for GC during\nthread termination, since it is also possible to collect from an\nunregistered thread in that case.\n* Define NO_GETENV for Windows CE, since getenv doesn't appear to exist.\nPlus some other minor WinCE fixes (thanks to Alain Novak).\n* Added GC_register_describe_type_fn.\n* Arrange for debugging finalizer registration to ignore non-heap\nregistrations, since the regular version of the routine also behaves\nthat way.\n* GC_gcj_malloc and friends need to check for finalizers waiting to be run.\nOne of the more obscure allocation routines with missing a LOCK() call.\n* Fixed cvtres invocations in NT_MAKEFILE and NT_STATIC_THREADS_MAKEFILE\nto work with VS.NET.\n* Cleaned up GC_INIT calls in test.  Updated gc.man to encourage GC_INIT\nuse in portable code.\n* Taught the GC to use libunwind if --enable-full-debug is specified on\nIA64 and libunwind is present.\n* The USE_MUNMAP code could get confused about the age of a block and\nprematurely unmap it.  GC_unmap_old had a bug related to wrapping of\nGC_gc_no.  GC_freehblk and GC_merge_unmapped didn't maintain\nhb_last_reclaimed reasonably when blocks were merged.  The code was\nfixed to reflect original intent, but that may not always be an\nimprovement.\n\n\n== [6.3alpha4] 2004-01-01 ==\n\n* USE_MMAP was broken by confusion in the code dealing with USE_MMAP_ANON.\n* Darwin support was broken in alpha3 as a result of my mis-integration of\nAndrew Begel's patches.  Fixed with another patch from Andrew Begel.\n* A new sanity check in pthread_stop_world.c:GC_push_all_stacks() was\noverly aggressive.  We may collect from an unregistered thread during\nthread creation.  Fixed by explicitly checking for that case.  (Added\nGC_in_thread_creation.)\n\n\n== [6.3alpha3] 2003-12-20 ==\n\n* Removed -DSMALL_CONFIG from BCC_MAKEFILE.\n* Changed macros to test for an ARM processor (Patch from Richard Earnshaw.)\n* Mostly applied a DJGPP patch from Doug Kaufman.  Especially Makefile.dj\nhad suffered from serious bit rot.\n* Rewrote GC_apply_to_maps, eliminating an off-by-one subscript error,\nand a call to alloca (for lcc compatibility).\n* Changed USE_MUNMAP behavior on POSIX platforms to immediately remap\nthe memory with PROT_NONE instead of unmapping it.  The latter risks\nan intervening mmap grabbing the address space out from underneath us.\nUpdated this code to reflect a cleaner patch from Ulrich Drepper.\n* Replaced _T with _Tp in new_gc_alloc.h to avoid a MACOS X conflict.\n(Patch from Andrew Begel.)\n* Dynamically choose whether or not lock should spin on win32 (thanks\nto Maurizio Vairani for the patch).  This may be a significant performance\nimprovement for win32.\n* Fix Makefile.direct to actually include NT_STATIC_THREADS_MAKEFILE\nin the distribution (thanks to Maurizio Vairani).\n* Maybe_install_looping_handler() was accidentally exported, violating\nour name space convention.\n* Made os_dep.c use sigsetjmp and SA_NODEFER for NetBSD.  (Thanks to\nChristian Limpach.  I generalized the patch to use sigsetjmp on all\nUNIX_LIKE platforms, admittedly a slightly risky move.  But it may avoid\nsimilar problems on some other platforms.  I also cleaned up the definition\nof UNIX_LIKE a bit.)\n* Integrated Andrew Begel's Darwin threads patch, adjusted according to\nsome of Fergus Hendersons's comments.  (Patch didn't apply cleanly,\nerrors are possible.)\n* Added another test or two for the Intel 8.0 compiler to avoid\nconfusing it with gcc.  The single-threaded collector should now build\nwith icc, at least on ia64.\n\n\n== [6.3alpha2] 2003-11-04 ==\n\n* Re-enabled I_HOLD_LOCK assertion in aix_irix_threads.h.\n* Put back the WINABI qualifier for GC_CreateThread.  (Thanks to\nDanny Smith for the patch.  6.3alpha1 had the qualifier in one place\nbut not elsewhere, which was clearly wrong.)\n* Sometimes explicitly define __private_extern__ before DARWIN dyld.h\ninclude.  (Thanks to Andreas Tobler for posting the patch.)\n* Included signal.h from pthread_support.c.  Removed GC_looping_handler,\nwhich was dead code.\n* GC_find_start was misdeclared by gc_pmark.h if PRINT_BLACK_LIST was\ndefined (thanks to Glauco Masotti for testing and reporting this).\nChanged GC_find_start to never just return 0.  According to its\ncomment it doesn't, and it's unclear that's correct.\n* GC_alloc_large had several largely compensating bugs in the\ncomputation of GC_words_wasted.  (It was confused about bytes vs.\nwords in two places.)\n* Integrated Slava Sysoltsev's patch to support more recent versions of\nthe Intel compiler on IA64/Linux.\n* Changed win32 spinlock initialization to conditionally set a spin count.\n(Emmanual Stumpf pointed out that enabling this makes a large performance\ndifference on win32 multiprocessors.)  Also cleaned up the win32 spinlock\ninitialization code a bit.\n* Fixed thread support for HP/UX/IA64.  The register backing store base for\nthe main thread was sometimes not set correctly.  (Thanks to\nLaurent Morichetti.)\n* Added -DEMPTY_GETENV_RESULTS flag to work around Wine problem.\n* Declare GC_stack_alloc and GC_stack_free in solaris_threads.h to\navoid 64-bit size mismatches (thanks to Bernie Solomon).\n* Fixed GC_generic_push_regs to avoid a potential and very unfortunate\ntail call optimization.  This could lead to prematurely reclaimed\nobjects on configurations that used the generic routine and the new\nbuild infrastructure (which potentially optimizes mach_dep.c).\nThis was a serious bug, but it's unclear whether it has resulted in\nany real failures.\n* Fixed CORD_str to deal with signed characters (thanks to Alexandr Petrosian\nfor noticing the problem and supplying the patch).\n* Merged a couple of NOSYS/ECOS tests into os_dep.c from gcj (thanks\nto Anthony Green).\n* Partially merged a win32 patch from Ben Hutchings, and substantially\nrevised other parts of win32_threads.c.  It had several problems.\nUnder MinGW with a statically linked library, the main thread was\nnot registered.  Cygwin detached threads leaked thread descriptors.\nThere were several race conditions.  For now, unfortunately the\nstatic threads limit remains, though we increased it, and made table\ntraversal cost depend on the actual thread count.\nThere is also still some code duplication with pthread_support.c.\n(Thread descriptors did become much smaller, since Ben Hutchings\nremoved the thread context from them.)\n* Integrated a Solaris configure.in patch from Rainer Orth.\n* Added GC_IGNORE_FB and associated warning to very partially address\nthe issue of the collector treating a mapped frame buffer as part\nof the root set.  (Thanks to David Peroutka for providing some\ninsight.  More would be helpful.  Is there anything that can be used\nto at least partially identify such memory segments?)\n\n\n== [6.3alpha1] 2003-07-26 ==\n\n* Integrated some NetBSD patches by Marc Recht.  These\nwere already in the NetBSD package.\n* GC_pthread_create waited for the semaphore even if pthread_create failed.\n(Thanks to Dick Porter for the pthread_support.c patch.)  Applied the\nanalogous fix for aix_irix_threads.c.\n* Added Rainer Orth's Tru64 fixes.\n* The check for exceeding the thread table size in win32 threadDetach\nwas incorrect (thanks to Alexandr Petrosian for the patch).\n* Applied Andrew Begel's patch to correct some reentrancy issues\nwith dynamic loading on Darwin.\n* GC_CreateThread() was neglecting to duplicate the thread handle in\nthe table (thanks to Tum Nguyen for the patch).\n* Pass +ESdbgasm only on PA-RISC machines with vendor compiler (thanks to\nRoger Sayle for the patch).\n* Applied more AIX threads patches from Scott Ananian.\n\n\n== [6.2] 2003-06-21 ==\n\n* Integrated a second round of Irix/AIX patches from Dan Bonachea.\nRenamed mips_sgi_mach_dep.S back to mips_sgi_mach_dep.s, since it requires\nthe Irix assembler to do the C preprocessing; gcc -E doesn't work.\n* Fixed Makefile.direct for DARWIN (thanks to Manuel Serrano).\n* There was a race between GC_pthread_detach and thread exit that could\nresult in a thread structure being deallocated by GC_pthread_detach\neven though it was still needed by the thread exit code (thanks to\nDick Porter for the small test case that allowed this to be debugged).\n* Fixed version parsing for non-alpha versions in acinclude.m4 and\nversion checking in version.h.\n* Issues identified (not yet fixed):\n- A dynamic libgc.so references dlopen unconditionally, but doesn't link\nagainst libdl.\n- GC_proc_fd for Solaris is not correctly updated in response to a\nfork() call.  Thus incremental collection in the child won't work\ncorrectly.  (Thanks to Ben Cottrell for pointing this out.)\n- --enable-redirect-malloc is mostly untested and known not to work\non some platforms.\n- There seem to be outstanding issues on Solaris/x86, possibly with\nfinding the data segment starting address.\n- Very large root set sizes (> 16 MB or so) could cause the collector\nto abort with an unexpected mark stack overflow.  (Thanks to\nPeter Chubb.)  NOT YET FIXED.  Workaround is to increase the initial\nsize.\n- The SGI version of the collector marks from mmapped pages, even\nif they are not part of dynamic library static data areas.  This\ncauses performance problems with some SGI libraries that use mmap\nas a bitmap allocator.  NOT YET FIXED.  It may be possible to turn\noff DYNAMIC_LOADING in the collector as a workaround.  It may also\nbe possible to conditionally intercept mmap and use GC_exclude_static_roots.\nThe real fix is to walk rld data structures, which looks possible.\n- Incremental collector should handle large objects better.  Currently,\nit looks like the whole object is treated as dirty if any part of it is.\n\n\n== [6.2alpha6] 2003-06-05 ==\n\n* There was an extra underscore in the name of GC_save_registers_in_stack\nfor NetBSD/SPARC (thanks to Jaap Boender for the patch).\n* Integrated Brian Alliet's patch for Darwin.  This restructured the\nlinuxthreads/pthreads support to separate generic pthreads support\nfrom more the system-dependent thread-stopping code.  I believe this\nshould make it easier to eliminate the code duplication between\npthreads platforms in the future.  The patch included some other\ncode cleanups.\n* Integrated Dan Bonachea's patch to support AIX threads.  This required\nsubstantial manual integration, mostly due to conflicts with other\nrecent threads changes.  It may take another iteration to\nget it to work.\n* Removed HPUX/PA-RISC support from aix_irix_threads.c.  It wasn't used\nanyway and it cluttered up the code.  And anything we can do to migrate\ntowards generic pthreads support is a good thing.\n* Added a more explicit test for tracing of function arguments to test.c.\n* Added Akira Tagoh's PowerPC64 patch.\n* Fixed some bit rot in the Cygwin port (thanks to Dan Bonachea for\npointing it out).  gc.h now includes just windows.h, not winbase.h.\n* Declared GC_save_regs_in_stack() in gc_priv.h.  Remove other declarations.\n* Changed --enable-cplusplus to use automake consistently.  The old way\nconfused libtool.  \"Make install\" didn't work correctly for the old version.\nPreviously --enable-cplusplus was broken on cygwin.\n* Changed the C version of GC_push_regs to fail at compile time if it is\ngenerated with an empty body.  This seems to have been the cause of one\nor two subtle failures on unusual platforms.  Those failures should\nnow occur at build time and be easily fixable.\n\n\n== [6.2alpha5] 2003-05-14 ==\n\n* GC_invoke_finalizers could, under rare conditions, set\nGC_finalizer_mem_freed to an essentially random value.  This could\npossibly cause unbounded heap growth for long-running applications\nunder some conditions.  (The bug was introduced in 6.1alpha5, and\nis not in gcc3.3.)\n* Attempted to sanitize the various DLL macros.  GC_USE_DLL disappeared.\nGC_DLL is used instead.  All internal tests are now on GC_DLL.\nREADME.macros is now more precise about the intended meaning.\n* Include DllMain in the multi-threaded win32 version only if the\ncollector is actually built as a dll (thanks to Mohan Embar for\na version of the patch).\n* Hide the cygwin threadAttach/Detach functions.  They were violating our\nnamespace rules.\n* Fixed an assertion in GC_check_heap_proc.  Added GC_STATIC_ASSERT\n(thanks again to Ben Hutchings).\n* Removed some obsolete definitions for Linux/PowerPC in gcconfig.h.\n* CORD_cat was not rebalancing unbalanced trees in some cases, violating\na CORD invariant.  Also tweaked the re-balancing rule for\nCORD_cat_char_star.  (Thanks to Alexandr Petrosian for the bug report\nand patch.)\n* Added hand-coded structured exception handling support to mark.c.\nThis should enable support of dynamic libraries under win32 with\ngcc-compiled code.  (Thanks to Ranjit Mathew for the patch.)\nTurned on dynamic library scanning for gcc on Win32.\n* Removed some remnants of read wrapping (thanks to Kenneth Schalk).\nGC_USE_LD_WRAP was probably broken in recent versions.\n* The build could fail on some platforms since gcconfig.h could include\ndeclarations mentioning ptr_t, which was not defined, e.g. when if_mach\nwas built (thanks to Yann Dirson for pointing this out).  Also\ncleaned up tests for GC_PRIVATE_H in gcconfig.h a bit.\n* The GC_LOOP_ON_ABORT environment variable interfered with incremental\ncollection, since the write fault handler was erroneously overridden.\nHandlers are now set up in the correct order.\n* It used to be possible to call GC_mark_thread_local_free_lists() while\nthe world was not stopped during an incremental GC.  This was not safe.\nFortunately, it was also unnecessary.  Added GC_world_stopped flag\nto avoid it.  (This caused occasional crashes in GC_set_fl_marks\nwith thread local allocation and incremental GC.  This probably happened\nprimarily on old, slow multiprocessors.)\n* Allowed overriding of MAX_THREADS in win32_threads.c from the build\ncommand line (thanks to Yannis Bres for the patch).\n* Taught the IA64/linux code to determine the register backing store base from\n/proc/self/maps after checking the __libc symbol, but before guessing.\n(__libc symbols are on the endangered list, and the guess is likely to not\nalways be right for 2.6 kernels.)  Restructured the code to read and parse\n/proc/self/maps so it only exists in one place (all platforms).\n* The -DUSE_PROC_FOR_LIBRARIES code was broken on Linux.  It claimed that it\nalso registered the main data segment, but didn't actually do so.  (I don't\nthink anyone actually uses this configuration, but ...)\n* Made another attempt to get --enablecplusplus to do the right thing.\nSince there are unavoidable problems with C programs linking against a\ndynamic library that includes C++ code, I separated out the c++ code into\nlibgccpp.\n\n\n== [6.2alpha4] 2003-03-10 ==\n\n* Use LINUX_STACKBOTTOM for >= glibc2.2 on Linux/MIPS.  (See Debian bug\n# 177204)\n* Integrated Jeff Sturm and Jesse Rosenstock's MACOSX threads patches.\n* Integrated Grzegorz Jakacki's substantial GNU build patch.  \"Make dist\"\nshould now work for the GNU build process.  Documentation files\nare installed under share/gc.\n* Tweaked gc_cpp.h to again support the Borland compiler (thanks to\nRene Girard for pointing out the problems).\n* Updated BCC_MAKEFILE (thanks to Rene Girard).\n* Added GC_ASSERT check for minimum thread stack size.\n* Added --enable-gc-assertions.\n* Added some web documentation to the distribution.  Updated it in the\nprocess.\n* Separate gc_conf_macros.h from gc.h.\n* Added generic GC_THREADS client-defined macro to set the appropriate\nGC_XXX_THREADS internal macro.  (gc_config_macros.h.)\n* Add debugging versions of _ignore_off_page allocation primitives.\n* Moved declarations of GC_make_closure and GC_debug_invoke_finalizer\nfrom gc.h to gc_priv.h.\n* Reset GC_fail_count even if only a small allocation succeeds.\n* Integrated Brian Alliet's patch for dynamic library support on Darwin.\n* gc_cpp.h's gc_cleanup destructor called GC_REGISTER_FINALIZER_IGNORE_SELF\nwhen it should have called the lower case version, since it was\nexplicitly computing a base pointer.\n\n\n== [6.2alpha3] 2003-01-30 ==\n\n* Don't include execinfo.h in os_dep.c when it's not needed, and may not\nexist.\n\n\n== [6.2alpha2] ==\n\n* Fixed the completely broken FreeBSD code in 6.2alpha1 (thanks to\nHironori Sakamoto for the patch).\n* Changed IRIX reference in dbg_mlc.c to IRIX5 (thanks to Marcus Herbert).\n* Attempted to work around the problems with .S filenames and the SGI\ncompiler.  (Untested.)\n* Worked around an HP/UX make issue with the GNU-style build process.\n* Fixed the --enable-cplusplus build machinery to allow builds without\na C++ compiler.  (That was always the intent ...)\n* Changed the debugging allocation macros to explicitly pass the return\naddress for Linux and XXXBSD on hardware for which we can't get stack\ntraces.  Use __builtin_return_address(0) to generate it when possible.\nSome of the configuration work was cleaned up (good) and moved to gc.h\n(bad, but necessary).  This should make leak detection more useful\non a number of platforms.  (Thanks to Fabian Thylman for the suggestion.)\n* Fixed compilation problems in dbg_mlc.c with GC_ADD_CALLER.\n* Bumped revision number for dynamic library.\n\n\n== [6.2alpha1] 2003-01-23 ==\n\n* Guard the test for GC_DUMP_REGULARLY in misc.c with\n\"#ifndef NO_DEBUGGING\".  Otherwise it fails to build with NO_DEBUGGING\ndefined.  (Thanks to Manuel Serrano.)\n* Message about retrying suspend signals was incorrectly generated even when\nflag was not set.\n* Cleaned up MACOSX/NEXT root registration code.  There was apparently a\nseparate ifdef case in GC_register_data_segments() for no reason.\n* Removed MPROTECT_VDB for MACOSX port, based on one negative report.\n* Arrange for gc.h and friends to be correctly installed with GNU-style\n\"make install\".\n* Enable the GNU-style build facility include C++ support in the library\nwith --enable-cplusplus (thanks to Thomas Maier for some of the patch).\n* Mark from GC_thread_key in linux_threads.c, in case that's allocated\nfrom the garbage collected heap, as it is with our own thread-specific\nstorage implementation (thanks to Jeff Sturm).\n* Mark all free list header blocks if they are heap allocated.  This avoids\nsome unnecessary tracing.  And it remains correct if we clear the\nroot set.  (Thanks to Jeff Sturm for identifying the bug.)\n* Improved S390/Linux support.  Add S390/Linux 64-bit support (thanks to\nUlrich Weigand).\n* Corrected the spelling of GC_{M,C}ALLOC_EXPLICTLY_TYPED to\nGC_{M,C}ALLOC_EXPLICITLY_TYPED in gc_typed.h.  This is technically\nan interface change.  Based on the fact that nobody reported this,\nI suspect/hope there were no clients.\n* Cleaned up gc_typed.h so that (1) it adds an extern \"C\" declaration\nwhen appropriate, (2) doesn't generate references to undefined internal\nmacros, and (3) allows easier manual construction of descriptors.\n* Close the file descriptor used by GC_print_address_map().\n* Set the \"close-on-exec\" bit for various file descriptors maintained\nfor the collector's internal use.\n* Added a hack to find memory segments owned by the system allocator\nunder win32.  Based on my tests, this tends to eventually find all\nsegments, though it may take a while.  There appear to be cleaner,\nbut slower solutions under NT/XP.  But they rely on an API that's\nunsupported under 9X.\n* Changed Linux PowerPC stack finding to LINUX_STACKBOTTOM.  (Thanks\nto Akira Tagoh for pointing out that HEURISTIC1 does not work on\n64-bit kernels.)\n* Added GC_set_free_space_divisor to avoid some Windows dll issues.\n* Added FIXUP_POINTER, POINTER_SHIFT, POINTER_MASK to allow preprocessing\nof candidate pointers for tagging, etc.\n* Always lock around GC_notify_full_gc().  Simplified code for\ninvoking GC_notify_full_gc().\n* Changed the way DATASTART is defined on FreeBSD to be robust against\nan unmapped page after etext.  (Thanks to Hironori Sakamoto for\ntracking down the intermittent failure.)\n* Made GC_enable() and GC_disable() official.  Deprecated direct update\nof GC_dont_gc.  Changed GC_gcollect to be a noop when garbage collection\nis disabled.\n* Call GC_register_dynamic_libraries before stopping the world on Linux,\nin order to avoid a potential deadlock due to the dl_iterate_phdr lock.\n* Introduced a more general mechanism for platform-dependent code to\ndecide whether the main data segment should be handled separately\nfrom dynamic libraries, or registered by GC_register_dynamic_libraries.\nThe latter is more reliable and easier on Linux with dl_iterate_phdr.\n\n\n== [6.1] ==\n\n* Added GC_MAXIMUM_HEAP_SIZE environment variable.\n* Fix configure.in for MIPS/LINUX (thanks to H.J. Lu).\n* Double page hash table size for -DLARGE_CONFIG.\n* Integrated Bo Thorsen's x64 support.\n* STACKBOTTOM definition for LINUX/MIPS was partially changed back\n(thanks to H.J. Lu and Hiroshi Kawashima for resolving this).\n* Replaced all occurrences of LINUX_DATA_START in gcconfig.h with\nSEARCH_FOR_DATA_START.  It doesn't hurt to fall back to a search.\nAnd __data_start doesn't seem to get defined correctly of the GC\nlibrary is loaded with LD_PRELOAD, e.g. for leak detection.\n* If the GC_find_leak environment variable is set, do a\natexit(GC_gcollect) to give us at least one chance to detect leaks.\nThis may report some very benign leaks, but ...\n* Addeded REDIRECT_FREE.  It's necessary if we want leak detection with\nLD_PRELOAD.\n* Defer printing of leaked objects, as for smashed objects.\n* Fixed process and descriptor leak in GC_print_callers.  Try for\nline number even if we got function name.)\n* Ported parallel GC support and thread local allocation to Alpha.\nNot yet well-tested.\n* Added GC_DUMP_REGULARLY and added finalization statistics to GC_dump().\n* Fixed Makefile.am to mention alpha_mach_dep.S instead of the defunct\nalpha_mach_dep.s.\n* Incorporated a change to new_gc_alloc.h,\nwhich should make it work with gcc3.1.\n* Use alpha_mach_dep.S only on Linux.  (It's not clear that this is\noptimal, but it otherwise didn't build on Tru64.  Thanks to Fergus Henderson.)\n* Added ifdef to guard free() in os_dep.c.  Otherwise we get a\ncompilation error on Irix (thanks to Dai Sato).\n* Added an experimental version of GC_memalign to mallocx.c.  This can't\nalways work, since we don't handle alignment requests in the hblk-level\nallocator, and we can't handle arbitrary pointer displacements unless\nGC_all_interior_pointers is enabled.  But it should work for alignment\nrequests up to HBLKSIZE.  This is not yet documented in the standard\nplaces.\n* Finally debugged the OSF1/Tru64 thread support.  This needs more testing,\nsince I needed to add a somewhat unconvincing workaround for signal\ndelivery issues that I don't yet completely understand.  But it does\npass my tests, even in parallel GC mode.  Incremental GC support is\ndisabled if thread support is enabled, due to the signal issues.\n* Eliminated name-space-incorrect definition of _cdecl from gc_cpp.h.\n* Added GC_debug_malloc_replacement and GC_debug_realloc_replacement\ndeclarations to gc.h.  On IA64, this is required for REDIRECT_MALLOC\nto work correctly with these.\n* Fixed Linux USE_PROC_FOR_LIBRARIES to work with a 64-bit /proc format.\n\n\n== [6.1alpha5] 2002-06-19 ==\n\n* Added GC_finalizer_mem_freed, and changed some of the code that\ndecided on heap expansion to look at it.  Memory explicitly\ndeallocated by finalizers essentially needs to be counted as reclaimed\nby the GC.  Otherwise there are cases in which the heap can grow\ninfinitely.  (Thanks to Mark Reichert for the test case.)\n* Integrated Adam Megacz patches to not scan dynamic libraries if\nwe are compiling with gcc on win32.  Otherwise we need structured\nexception handling to deal with asynchronously unmapped root\nsegments, and gcc doesn't directly support that.\n* Integrated Anthony Green's patch to support Wine.\n* GC_OPERATOR_NEW_ARRAY was misspelled OPERATOR_NEW_ARRAY in several\nplaces, including gc_cpp.cc (thanks to Wink Saville for pointing this out).\n* Integrated Loren J. Rittle's Alpha FreeBSD patches.  These also\nchanged the declarations of symbols like _end on many platforms to\nthat they wouldn't mistakenly be declared as short data symbols (suggested by\nRichard Henderson).\n* Integrated changes from the Debian distribution (thanks to Ryan Murray\nfor pointing these out).\nFix C++ comments in POWERPC port.  Add ARM32\nincremental GC support.  Get rid of USE_GENERIC_PUSH_REGS for alpha/Linux,\nthis time for real.  Use va_copy to get rid of cord printf problems\n(finally).\n* Close file descriptor used to count CPUs (thanks to Jeff Sturm for\npointing out the omission).\n* Don't just drop gcj free lists in GC_start_reclaim, since that can\neventually cause the marker to see a bogus mark descriptor in the\ndropped objects.  The usual symptom was a very intermittent segmentation\nfault in the marker.  This mattered only if one of the GC_gcj_malloc\nvariants was used (thanks to Michael Smith, Jeff Sturm, Bryce McKinlay and\nTom Tromey for helping to track this down).\n* Fixed Linux and Solaris/64 SPARC configuration (thanks to David Miller,\nJeff Sturm, Tom Tromey, and Christian Joensson).\n* Fixed a typo in strdup definition (thanks to Gerard A Allan).\n* Changed Makefile.direct to invoke $(CC) to assemble alpha_mach_dep.S.\nThis is needed on Linux.  I'm not sure whether it's better or worse\non Tru64.\n* Changed gc_cpp.h once more to declare operator new and friends only in\na Microsoft environment.  This may need further fine tuning (thanks to\nJohannes Schmidt for pointing out that the older code breaks on gcc3.0.4).\n* Don't ever override strdup if it's already macro defined (thanks to\nAdnan Ali for pointing out the problem).\n* Changed gc_cpp.h yet again to also overload placement new.  Due to the\nC++ overloading rules, the other overloaded new operations otherwise hide\nplacement new, which causes many STL uses to break (thanks to Reza Shahidi\nfor reporting this, and to Matt Austern for proposing a fix).\n* Integrated cygwin pthreads support from Dan Bonachea.\n* Turn on DYNAMIC_LOADING for NetBSD (thanks to Krister Walfridsson).\n* Changed printing code to print more complete GC times.\n* Applied Mark Mitchell's Irix patch to correct some bit rot.\n* Clarified which object-printing routines in dbg_mlc.c should hold\nthe allocation lock.  Restructured the code to allow reasonable object\nprinting with -DREDIRECT_MALLOC.\n* Fix the Linux mmap code to always start with 0x1000 as the initial hint.\nMinor patches for 64-bit AIX, particularly to STACKBOTTOM (thanks to\nJeffrey Mark Siskind).\n* Renamed \"SUSPENDED\" flag for Solaris threads support to avoid a conflict\nwith a system header (thanks to Philip Brown).\n* Cause win32_threads.c to handle an out of range stack pointer correctly,\nthough currently with a warning.  (Thanks to Jonathan Clark for\nobserving that Windows applications may temporarily use the stack\npointer for other purposes, and suggesting a fix.  Unfortunately, it's\nnot clear that there is a complete solution to this problem.)\n\n\n== [6.1alpha4] 2002-06-16 ==\n\n* Fixed typo in sparc_mach_dep.S, preventing the 64-bit version from\nbuilding.  Increased 64-bit heap size limit in test.c slightly, since\na functional SPARC collector seems to slightly exceed the old limits.\n* Use NPRGREG in solaris_threads.c, thus printing all registers if things\ngo wrong.\n* Added GC_MARKERS environment variable to allow use of a single marker\nthread on an MP without confusing the lock implementation.\n* Collect much less aggressively in incremental mode with GC_TIME_UNLIMITED.\nThis is really a purely generational mode, and we can afford to\npostpone the collection until the heap is (nearly) full.\n* Remove read() wrapper for MPROTECT_VDB.  It was causing more harm than\ngood.  It is often no longer needed if system calls avoid writing to\npointerful heap objects.\n* Fix MACOSX test in gcconfig.h (thanks to John Clements).\n* Change GC_test_and_set so that it consistently has one argument.\nAdd spaces to ::: in powerpc assembly code in gc_locks.h (thanks to\nRyan Murray).\n* Fixed a formatting error in dbg_mlc.c.  Added prototype to GC_abort()\ndeclaration (thanks to Michael Smith).\n* Removed \"source\" argument to GC_find_start().  Eliminate GC_FIND_START().\n* Added win32 recognition code in configure.in.  Changed some of the\ndllimport/export defines in gc.h (thanks to Adam Megacz).\n* GC_malloc_many didn't set hb_last_reclaimed when it called\nGC_reclaim_generic.  (I'm not sure this matters much, but ...)\n* Allocating uncollectible objects with debug information sometimes\nallocated objects that were one byte too small, since uncollectible\nobjects don't have the extra byte added at the end (thanks to\nWink Saville for pointing this out).\n* Added a bit more assertion checking to make sure that gcj objects\non free lists never have a nonzero second word.\n* Replaced BCC_MAKEFILE with an up-to-date one (thanks to Andre Leiradella).\n* Upgraded libtool, configure.in and some related files to hopefully\nsupport NetBSD/SPARC (thanks to Adrian Bunk).  Unfortunately,\nlibtool 1.4.2 seemed to be buggy due to missing quotes in several\n\"test\" invocations.  Fixed those in the ltmain.sh script.\n* Some win32-specific patches, including the introduction of\nGC_CreateThread (thanks to Adam Megacz).\n* Merged in gcj changes from Anthony Green to support embedded systems.\n* Tried to consistently rename preprocessed assembly files with a capital\n.S extension.\n* Use alpha_mach_dep.S on ALPHA again.  It doesn't really matter, but this\nmakes our distribution consistent with the gcc one, avoiding future merge\nproblems.\n* Move GET_MEM definition into gcconfig.h.  Include gcconfig.h slightly\nlater in gc_priv.h to avoid forward references to ptr_t.\n* Add some testing of local allocation to test.c.\n* Change definition of INVALID_QTID in specific.h.  The -1 value was used\ninconsistently, and too likely to collide with a valid stack address.\nSome general clean-up of specific.[ch].  Added assertions.  (Thanks\nto Michael Smith for tracking down an intermittent bug to this\ngeneral area.  I'm not sure it has been squashed yet, however.)\n* On Pthread systems it was not safe to call GC_malloc() between fork()\nand exec().  According to the applicable standards, it doesn't appear\nto be safe to call malloc() or many other libc functions either, thus\nit's not clear this is fixable.  Added experimental support for\n-DHANDLE_FORK in linux_threads.c which tries to support it.  It may\nsucceed if libc does the right thing.  I'm not sure whether it does.\n(Thanks to Kenneth Schalk for pointing out this issue.)\n* Documented thread local allocation primitives to require an\nexplicit GC_init call.  GC_init_parallel is no longer declared to\nbe a constructor function, since that isn't portable and often\nseems to lead to initialization order problems.\n* Changed gc_cpp.cc and gc_cpp.h in one more attempt to make them\ncompatible with Visual C++ 6 (thanks to Wink Saville for the patch).\n* Some more patches for Linux on HP PA-RISC.\n* Added include/gc_allocator.h.  It implements (hopefully) standard\nconforming (as opposed to SGI-style) allocators that allocate\ncollectible (gc_allocator) or GC-traceable, but not collectible\n(traceable_allocator) objects.  This borrows heavily from libstc++,\nwhich borrows heavily from the SGI implementation, this part of\nwhich was written by Matt Austern.  Changed test_cpp.cc to very\nminimally test this.\n* On Linux/x86, retry mmap with a different start argument.  That should\nallow the collector to use more (closer to 3GB) of the address space.\n* Force 64 bit alignment with GCJ support (reflects Bryce McKinlay's\npatch to the gcc tree).\n* Refined the choice of sa_handler vs. sa_sigaction in GC_dirty_init\nto accommodate some glibc5 systems (thanks to Dan Fandrich for the patch).\n* Compensated for the fact that current versions of glibc set\n__libc_stack_end incorrectly on Linux/IA64 while initialization code\nis running.  This could cause the collector to miss 16 bytes of\nthe memory stack if GC_malloc or friends where called before main().\n* Mostly integrated Takis Psarogiannakopoulos' port to DG/UX Inix 86.\nThis will probably take another iteration to work, since his\npatch conflicted with the libtool upgrade.\n* Added README.arm.cross containing some information about cross-\ncompiling to an ARM processor from Margaret Fleck (original code provided by\nBradley D. LaRonde; edited by Andrej Cedilnik using some of solutions by\nTilman Vogel; also ported for iPAQ by Oliver Kurth).\n\n\n== [6.1alpha3] 2002-02-07 ==\n\n* Minor cleanup on the gcconfig.h section for SPARC.\n* Minor fix to support Intel compiler for Linux/x86 (thanks to\nSven Hartrumpf).\n* Added SPARC V9 (64-bit) support (thanks to Jeff Sturm).\n* Restructured the way in which we determine whether or not to keep\ncall stacks for debug allocation.  By default SAVE_CALL_COUNT is\nnow zero on all platforms.  Added SAVE_CALL_NARGS parameters.\nIf possible, use execinfo.h to capture call stack.  (This should\nadd support for a number of new platforms, though often at\nconsiderable runtime expense.)\n* Try to print symbolic information for call stacks.  On Linux, we\ndo this with a combination of execinfo.h and running addr2line in\na separate process.  This is both much more expensive and much more\nuseful.  Amazingly, it seems to be fast enough for most purposes.\n* Redefined strdup if -DREDIRECT_MALLOC is given.\n* Changed incremental collector and MPROTECT_VDB implementation so that,\nunder favorable conditions, pointer-free objects are not protected.\nAdded GC_incremental_protection_needs() to determine ahead of time whether\npointer-free objects may be protected.  Replaced GC_write_hint() with\nGC_remove_protection().\n* Added test for GC_ENABLE_INCREMENTAL environment variable.\n* Made GC_time_limit runtime configurable.  Added GC_PAUSE_TIME_TARGET\nenvironment variable.\n* Eliminated GC_page_sz, a duplicate of GC_page_size.\n* Caused the Solaris and Irix thread creation primitives to call\nGC_init_inner().\n\n\n== [6.1alpha2] 2001-12-20 ==\n\n* No longer wrap read by default in multi-threaded applications.  It was\npointed out on the libgcj list that this holds the allocation lock for\nway too long if the read blocks.  For now, reads into the heap are\nbroken with incremental collection.  It's possible to turn this back on\nif you make sure that read calls don't block (e.g. by calling select\nfirst).\n* Fix ifdef in Solaris_threads.h to refer to GC_SOLARIS_THREADS.\n* Added check for environment variable GC_IGNORE_GCJ_INFO.\n* Added printing of stop-the-world GC times if GC_PRINT_STATS environment\nvariable is set.\n* The calloc definition in leak_detector.h was missing parentheses, and\nrealloc was missing a second argument to GC_REALLOC (thanks to\nElvenlord Elrond).\n* Added GC_PRINT_BACK_HEIGHT environment variable and associated\ncode, mostly in the new file backgraph.c.  See doc/README.environment.\n* Added -DUSE_GLOBAL_ALLOC to work around a Windows NT issue (thanks to\nJonathan Clark).\n* Integrated port to NEC EWS4800 (MIPS-based workstation, with somewhat\ndifferent address-space layout).  This may help for other machines with\nholes in the data segment.  (Thanks to Hironori Sakamoto.)\n* Changed the order in which GC_push_roots and friends push things onto\nthe mark stack.  GC_push_all calls need to come first, since we can't\nnecessarily recover if those overflow the mark stack.  (Thanks to\nMatthew Flatt for tracking down the problem.)\n* Some minor cleanups to mostly support the Intel compiler on Linux/IA64.\n\n\n== [6.1alpha1] 2001-09-22 ==\n\n* Non-debug, atomic allocations could result in bogus smashed object\nreports with debugging on (thanks to Patrick Doyle for the small test case).\n* Fixed GC_get_register_stack_base (Itanium only) to work around a glibc\n2.2.4 bug.\n* Initial port to HP/UX on Itanium.  Thread support and both 32 and 64\nbit ABIs appear to work.  Parallel mark support doesn't yet, due to\nsome inline assembly code issues.  Thread local allocation does appear\nto work.\n* ifdef'ed out glibc2.1/Itanium workaround.  I suspect nobody is using\nthat combination anymore.\n* Added a patch to make new_gc_alloc.h usable with gcc3.0 (thanks to\nDimitris Vyzovitis for the patch).\n* Debugged 64-bit support on HP/UX PA-RISC.\n* Turned on dynamic loading support for FreeBSD/ELF (thanks to Peter Housel).\n* Unregistering of finalizers with debugging allocation was broken (thanks\nto Jani Kajala for the test case).\n* Old finalizers were not returned correctly from GC_debug_register_finalizer.\n* Disabled MPROTECT_VDB for Linux/M68K based on a report that it doesn't work.\n* Cleaned up some statistics gathering code in reclaim.c (thanks to\nWalter Bright).\n* Added some support for OpenBSD/ELF/Linux (thanks to Suzuki Toshiya).\n* Added Jakub Jelinek's patch to use dl_iterate_phdr for dynamic library\ntraversal to dyn_load.c.  Changed it to weakly reference dl_iterate_phdr,\nso that the old code is still used with old versions of glibc.\n* Cleaned up feature test macros for various threads packages and\nintegrated (partially functional) FreeBSD threads code from Loren J. Rittle.\nIt's likely that the cleanup broke something, since it touched lots of\ncode.  It's also likely that it fixed some unreported bugs in the\nless common thread implementations, since some of the original code\ndidn't stand up to close scrutiny.  Support for the next pthreads\nimplementation should be easier to add.\n\n\n== [6.0] 2001-07-26 ==\n\n* Two more bug fixes for KEEP_BACK_PTRS and DBG_HDRS_ALL.\n* Fixed a stack clearing problem that resulted in SIGILL with a\nmisaligned stack pointer for multi-threaded SPARC builds.\n* Integrated another HURD patch (thanks to Igor Khavkine).\n\n\n== [6.0alpha9] ==\n\n* added README.macros.\n* Made gc.mak a symbolic link to work around winzip's tendency to ignore\nhard links.\n* Simplified the setting of NEED_FIND_LIMIT in os_dep.c, possibly breaking\nit on untested platforms.\n* Integrated initial GNU HURD port (thanks to Chris Lingard and\nIgor Khavkine).\n* A few more fixes for Digital Mars compiler (by Walter Bright).\n* Fixed gcc version recognition.  Renamed OPERATOR_NEW_ARRAY to\nGC_OPERATOR_NEW_ARRAY.  Changed GC_OPERATOR_NEW_ARRAY to be the default.\nIt can be overridden with -DGC_NO_OPERATOR_NEW_ARRAY (thanks to\nCesar Eduardo Barros).\n* Changed the byte size to free-list mapping in thread local allocation\nso that size 0 allocations are handled correctly.\n* Fixed Linux/MIPS stackbottom for new toolchain (thanks to Ryan Murray).\n* Changed finalization registration to invoke GC_oom_fn when it runs out\nof memory.\n* Removed lvalue cast in finalize.c.  This caused some debug configurations\nnot to build with some non-gcc compilers.\n\n\n== [6.0alpha8] 2001-06-15 ==\n\n* Changed GC_debug_malloc_replacement and GC_debug_realloc_replacement\nso that they compile under Irix (thanks to Dave Love).\n* Updated powerpc_macosx_mach_dep.s so that it works if the collector\nis in a dynamic library (thanks to Andrew Begel).\n* Transformed README.debugging into debugging.html, updating and\nexpanding it in the process.  Added gcdescr.html and tree.html\nfrom the web site to the GC distribution.\n* Fixed several problems related to PRINT_BLACK_LIST.  This involved\nrestructuring some of the marker macros.\n* Fixed some problems with the sizing of objects with debug information.\nFinalization was broken KEEP_BACK_PTRS or PRINT_BLACK_LIST.  Reduced the\nobject size with SHORT_DEBUG_HDRS by another word.\n* The \"Needed to allocate blacklisted ...\" warning had inadvertently\nbeen turned off by default, due to a buggy test in allchblk.c.  Turned\nit back on.\n* Removed the marker macros to deal with 2 pointers in interleaved fashion.\nThey were messy and the performance improvement seemed minimal.  We'll\nleave such scheduling issues to the compiler.\n* Changed Linux/PowerPC test to also check for __powerpc__ in response\nto a discussion on the gcc mailing list.\n* Removed the \"static\" from the jmp_buf declaration in GC_generic_push_regs\n(suggested by Matthew Flatt).  This was causing problems in\nsystems that register all of their own roots.  It looks far more correct\nto me without the \"static\" anyway.\n* Fixed several problems with thread local allocation of pointer-free or\ntyped objects.  The collector was reclaiming thread-local free lists, since\nit wasn't following the link fields.\n* There was apparently a long-standing race condition related to\nmulti-threaded incremental collection.  A collection could be started and\na thread stopped between the memory unprotect system call and the setting of\nthe corresponding dirt bit.  I believe this did not affect Solaris or PCR,\nwhich use a different dirty-bit implementation.  Fixed this by installing\nsignal handlers with sigaction instead of signal, and disabling the thread\nsuspend signal while in the write-protect handler.  (It is unclear\nwhether this scenario ever actually occurred.)\n* Incremental collection did not cooperate correctly with the PARALLEL_MARK\nimplementation of GC_malloc_many or the local_malloc primitives.  It still\ndoesn't work well, but it shouldn't lose memory anymore.\n* Integrated some changes from the gcc source tree that I had previously\nmissed (thanks to Bryce McKinlay for the reminder and patch).\n* Added Makefile.direct as a copy of the default Makefile, which would\nnormally be overwritten if configure is run.\n* Changed the gc.tar target in Makefile.direct to embed the version number\nin the gc directory name.  This will affect future tar file distributions.\n* Changed the Irix dynamic library finding code to no longer try to\neliminate writable text segments under Irix6.x, since that is probably no\nlonger necessary, and can apparently be unsafe on occasion (thanks to\nShiro Kawai for pointing this out).\n* GC_cleanup with GC_DEBUG enabled passed a real object base address to\nGC_debug_register_finalizer_ignore_self, which expected a pointer past the\ndebug header.  Call GC_register_finalizer_ignore_self instead, even with\ndebugging enabled (thanks to Jean-Daniel Fekete for catching this).\n* The collector didn't build with call chain saving enabled but NARGS=0.\n* Fixed up the GNU-style build files enough so that they work in some\nobvious cases (thanks to Maarten Thibaut).\n* Added initial port to Digital Mars compiler for win32 (thanks to Walter\nBright).\n\n\n== [6.0alpha7] 2001-04-19 ==\n\n* Added GC_finalizer_notifier.  Fixed GC_finalize_on_demand.  (The variable\nactually wasn't being tested at the right points.  The build-time flag\nwas.)\n* Added Tom Tromey's S390 Linux patch.\n* Added code to push GC_finalize_now in GC_push_finalizer_structures\n(thanks to Matthew Flatt).\n* Added GC_push_gc_structures() to push all GC internal roots.\n* Integrated some FreeBSD changes from Matthew Flatt.\n* It looks like USRSTACK is not always correctly defined under Solaris.\nHacked gcconfig.h to attempt to work around the problem.  The result\nis not well tested.  (Thanks again to Matthew Flatt for pointing this out.)\n* Added Ji-Yong Chung's win32 threads and C++ fixes.\n* Arranged for hpux_test_and_clear.s to no longer be needed or built.\nIt was causing build problems with gas, and it's not clear this is\nbetter than the pthreads alternative on this platform.\n* Some MINGW32 fixes from Hubert Garavel.\n* Added initial Hitachi SH4 port from Kaz Kojima.\n* Ported thread-local allocation and parallel mark code to HP/UX on PA_RISC.\n* Made include/gc_mark.h more public and separated out the really private\npieces.  This is probably still not quite sufficient for clients that\nwant to supply their own kind of type information.  But it's a start.\nThis involved lots of identifier renaming to make it namespace clean.\n* Added GC_dont_precollect for clients that need complete control over\nthe root set.\n* GC_is_visible didn't do the right thing with gcj objects.  (Not that\nmany people are likely to care, but ...)\n* Don't redefine read with GC_USE_LD_WRAP.\n* Initial port to LINUX/HP_PA.  Incremental collection and threads are not\nyet supported.  (Incremental collection should work if you have the\nright kernel.  Threads may work with a sufficiently patched pthread\nlibrary.)\n* Changed gcconfig.h to recognize __i386__ as an alternative to x86 in\nmany places (thanks to Benjamin Lerman).\n* Made win32_threads.c more tolerant of detaching a thread that it didn't\nknow about (thanks to Paul Nash).\n* Added Makefile.am and configure.in from gcc to the distribution, with\nminimal changes.  For the moment, those are just placeholders.  In the\nfuture, we're planning to switch to a GNU-style build environment for\nUn*x-like systems, though the old Makefile will remain as a backup.\n* Turned off STUBBORN_ALLOC by default, and added it back as a Makefile\noption.\n* Redistributed some functions between malloc.c and mallocx.c, so that\nsimple statically linked apps no longer pull in mallocx.o.\n* Changed large object allocation to clear the first and last few words\nof each block before releasing the lock.  Otherwise the marker could see\nobjects with nonsensical type descriptors.\n* Fixed a couple of subtle problems that could result in not recognizing\ninterior pointers from the stack.  (I believe these were introduced\nin 6.0alpha6.)\n* GC_debug_free_inner called GC_free, which tried to reacquire the\nallocator lock, and hence deadlocked.  (DBG_HDRS_ALL probably never worked\nwith threads.)\n* Fixed several problems with back traces.  Accidental references to a free\nlist could cause the free list pointer to be overwritten by a back pointer.\nThere seemed to be some problems with the encoding of root and finalizer\nreferences.\n\n\n== [6.0alpha6] "
        },
        {
          "name": "Config.cmake.in",
          "type": "blob",
          "size": 0.13671875,
          "content": "# The BDWgc CMake configuration file.\n\n@PACKAGE_INIT@\ninclude(\"${CMAKE_CURRENT_LIST_DIR}/BDWgcTargets.cmake\")\ncheck_required_components(gc)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.521484375,
          "content": "MIT-style License\n\nCopyright (c) 1988-1989 Hans-J. Boehm, Alan J. Demers\nCopyright (c) 1991-1996 by Xerox Corporation.  All rights reserved.\nCopyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\nCopyright (c) 1998 by Fergus Henderson.  All rights reserved.\nCopyright (c) 1999-2001 by Red Hat, Inc.  All rights reserved.\nCopyright (c) 1999-2011 Hewlett-Packard Development Company, L.P.\nCopyright (c) 2004-2005 Andrei Polushin\nCopyright (c) 2007 Free Software Foundation, Inc.\nCopyright (c) 2008-2022 Ivan Maidanski\nCopyright (c) 2011 Ludovic Courtes\nCopyright (c) 2018 Petter A. Urkedal\n\n\nTHIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\nOR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n\nPermission is hereby granted to use or copy this program\nfor any purpose, provided the above notices are retained on all copies.\nPermission to modify the code and to distribute modified code is granted,\nprovided the above notices are retained, and a notice that the code was\nmodified is included with the above copyright notice.\n\n\nSeveral files (gc/gc_allocator.h, extra/msvc_dbg.c) come with slightly\ndifferent licenses, though they are all similar in spirit (the exact\nlicensing terms are given at the beginning of the corresponding source file).\n\nA few of the files needed to use the GNU-style build procedure come with\na modified GPL license that appears not to significantly restrict use of\nthe collector, though use of those files for a purpose other than building\nthe collector may require the resulting code to be covered by the GPL.\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 6.6298828125,
          "content": "# Copyright (c) 1999-2001 by Red Hat, Inc. All rights reserved.\n#\n# THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n# OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n#\n# Permission is hereby granted to use or copy this program\n# for any purpose, provided the above notices are retained on all copies.\n# Permission to modify the code and to distribute modified code is granted,\n# provided the above notices are retained, and a notice that the code was\n# modified is included with the above copyright notice.\n\n## Process this file with automake to produce Makefile.in.\n\n# Info (current:revision:age) for the Libtool versioning system.\n# These numbers should be updated at most once just before the release,\n# and, optionally, at most once during the development (after the release).\nLIBGC_VER_INFO = 6:3:5\nLIBGCCPP_VER_INFO = 6:0:5\n\n## FIXME: `make distcheck' in this directory will not currently work.\n##     This is most likely to the explicit flags passed to submakes.\n\n# We currently use the source files directly from libatomic_ops, if we\n# use the internal version.\n# Thus there seems to be no real reason to recursively build in the\n# libatomic_ops directory.\nSUBDIRS =\n\nACLOCAL_AMFLAGS = -I m4\nAM_CPPFLAGS = \\\n    -I$(top_builddir)/include -I$(top_srcdir)/include \\\n    $(ATOMIC_OPS_CFLAGS)\n\n## Initialize variables so that we can declare files locally.\nEXTRA_DIST =\nlib_LTLIBRARIES =\ninclude_HEADERS =\npkginclude_HEADERS =\ndist_noinst_HEADERS =\ncheck_PROGRAMS =\ncheck_LTLIBRARIES =\nTESTS =\n\npkgconfigdir = $(libdir)/pkgconfig\npkgconfig_DATA = bdw-gc.pc\n\n# C Library\n# ---------\n\nlib_LTLIBRARIES += libgc.la\n\nif SINGLE_GC_OBJ\n\nlibgc_la_SOURCES = extra/gc.c\n\nif PTHREAD_START_STANDALONE\nAM_CPPFLAGS += -DGC_PTHREAD_START_STANDALONE\nlibgc_la_SOURCES += pthread_start.c\nendif\n\nelse\n\nEXTRA_DIST += extra/gc.c\nlibgc_la_SOURCES = \\\n    allchblk.c alloc.c blacklst.c dbg_mlc.c dyn_load.c finalize.c \\\n    headers.c mach_dep.c malloc.c mallocx.c mark.c mark_rts.c misc.c \\\n    new_hblk.c obj_map.c os_dep.c ptr_chck.c reclaim.c typd_mlc.c\n\nif MAKE_BACK_GRAPH\nlibgc_la_SOURCES += backgraph.c\nendif\n\nif CHECKSUMS\nlibgc_la_SOURCES += checksums.c\nendif\n\nif ENABLE_DISCLAIM\nlibgc_la_SOURCES += fnlz_mlc.c\nendif\n\nif ENABLE_GCJ_SUPPORT\nlibgc_la_SOURCES += gcj_mlc.c\nendif\n\n# C library: architecture dependent\n# ---------------------------------\n\nif THREADS\n\nlibgc_la_SOURCES += gc_dlopen.c pthread_start.c pthread_support.c\n\nif THREAD_LOCAL_ALLOC\nlibgc_la_SOURCES += specific.c thread_local_alloc.c\nendif\n\nif WIN32_THREADS\nlibgc_la_SOURCES += win32_threads.c\nelse\nif DARWIN_THREADS\nlibgc_la_SOURCES += darwin_stop_world.c\nelse\nlibgc_la_SOURCES += pthread_stop_world.c\nendif\nendif\n\nendif\n\n## End of !SINGLE_GC_OBJ\nendif\n\nif USE_INTERNAL_LIBATOMIC_OPS\nnodist_libgc_la_SOURCES = libatomic_ops/src/atomic_ops.c\nif NEED_ATOMIC_OPS_ASM\nnodist_libgc_la_SOURCES += libatomic_ops/src/atomic_ops_sysdeps.S\nendif\nendif\n\n# Include THREADDLLIBS here to ensure that the correct versions of\n# LinuxThreads semaphore (and clock_gettime) functions get linked:\nlibgc_la_LIBADD = @addobjs@ $(THREADDLLIBS) $(UNWINDLIBS) $(ATOMIC_OPS_LIBS)\nlibgc_la_DEPENDENCIES = @addobjs@\nlibgc_la_LDFLAGS = $(extra_ldflags_libgc) -version-info $(LIBGC_VER_INFO) \\\n    -no-undefined\n\nEXTRA_libgc_la_SOURCES = ia64_save_regs_in_stack.s sparc_mach_dep.S \\\n    sparc_netbsd_mach_dep.s\n\nif CPLUSPLUS\n# C++ Interface\n# -------------\nlib_LTLIBRARIES += libgccpp.la\nlibgccpp_la_SOURCES = gc_badalc.cc gc_cpp.cc\nlibgccpp_la_LIBADD = libgc.la\nlibgccpp_la_LDFLAGS = -version-info $(LIBGCCPP_VER_INFO) -no-undefined\nif GC_TBA_LIBRARY\n# The same as libgccpp but contains only gc_badalc.o.\nlib_LTLIBRARIES += libgctba.la\nlibgctba_la_SOURCES = gc_badalc.cc\nlibgctba_la_LIBADD = libgc.la\n# Set the same version as for libgccpp.\nlibgctba_la_LDFLAGS = -version-info $(LIBGCCPP_VER_INFO) -no-undefined\nendif\nendif\n\nEXTRA_DIST += gc_badalc.cpp gc_cpp.cpp\n\n\n# Misc\n# ----\n\nAM_CXXFLAGS = $(WERROR_CFLAGS) @GC_CFLAGS@\nAM_CFLAGS = $(WERROR_CFLAGS) @GC_CFLAGS@\n\nCFLAGS += $(CFLAGS_EXTRA)\nCXXFLAGS += $(CFLAGS_EXTRA)\n\n## FIXME: relies on internal code generated by automake.\n## FIXME: ./configure --enable-dependency-tracking should be used\n\n## FIXME: we shouldn't have to do this, but automake forces us to.\n## We use -Wp,-P to strip #line directives.  Irix `as' chokes on\n## these.\nif ASM_WITH_CPP_UNSUPPORTED\n  ASM_CPP_OPTIONS =\nelse\n  ASM_CPP_OPTIONS = -Wp,-P -x assembler-with-cpp\nendif\n\n.s.lo:\n\t$(LTCOMPILE) $(ASM_CPP_OPTIONS) -c $<\n\n.S.lo:\n\t$(LTCOMPILE) $(ASM_CPP_OPTIONS) -c $<\n\n## We need to add DEFS to assembler flags\n## :FIXME: what if assembler does not accept -D... ?\n## (use Autoconf to prepare ASDEFS?)\n\nCCASFLAGS += $(DEFS)\n\n# headers which are not installed\n# (see include/include.am for more)\n#\n\n# other makefiles\nEXTRA_DIST += Makefile.direct NT_MAKEFILE WCC_MAKEFILE digimars.mak \\\n    autogen.sh build.zig CMakeLists.txt Config.cmake.in\n\n# files used by makefiles other than Makefile.am\n#\nEXTRA_DIST += tools/if_mach.c tools/if_not_there.c tools/setjmp_t.c \\\n    tools/threadlibs.c tools/callprocs.sh extra/msvc_dbg.c \\\n    extra/symbian/global_end.cpp extra/symbian/global_start.cpp \\\n    extra/symbian/init_global_static_roots.cpp extra/symbian.cpp\n\n#\n# :GOTCHA: GNU make rule for making .s out of .S is flawed,\n# it will not remove dest if building fails\n.S.s:\n\tif $(CPP) $< >$@ ; then :; else rm -f $@; fi\n\ninclude include/include.am\ninclude cord/cord.am\ninclude tests/tests.am\n\n## Putting these at the top causes cord to be built first, and not find\n## libgc.a on HP/UX.  There may be a better fix.\n\n# Installed documentation.\nif ENABLE_DOCS\ndist_doc_DATA = \\\n    AUTHORS \\\n    ChangeLog \\\n    LICENSE \\\n    README.md\n\ndocdocsdir = $(docdir)/docs\ndist_docdocs_DATA = \\\n    docs/README.autoconf \\\n    docs/README.cmake \\\n    docs/README.environment \\\n    docs/README.macros \\\n    docs/cords.md \\\n    docs/debugging.md \\\n    docs/faq.md \\\n    docs/finalization.md \\\n    docs/gcdescr.md \\\n    docs/gcinterface.md \\\n    docs/leak.md \\\n    docs/overview.md \\\n    docs/porting.md \\\n    docs/scale.md \\\n    docs/simple_example.md \\\n    docs/tree.md\n\ndocdocsplatformsdir = $(docdocsdir)/platforms\ndist_docdocsplatforms_DATA = \\\n    docs/platforms/README.aix \\\n    docs/platforms/README.arm_cross \\\n    docs/platforms/README.darwin \\\n    docs/platforms/README.dgux386 \\\n    docs/platforms/README.emscripten \\\n    docs/platforms/README.ews4800 \\\n    docs/platforms/README.hp \\\n    docs/platforms/README.linux \\\n    docs/platforms/README.os2 \\\n    docs/platforms/README.sgi \\\n    docs/platforms/README.solaris2 \\\n    docs/platforms/README.symbian \\\n    docs/platforms/README.uts \\\n    docs/platforms/README.win32 \\\n    docs/platforms/README.win64\n\ndist_man3_MANS = gc.man\nendif\n\n# A dummy target for mono build.\ntest-bundle:\n"
        },
        {
          "name": "Makefile.direct",
          "type": "blob",
          "size": 16.6513671875,
          "content": "# This is the original manually generated Makefile.  It may still be used\n# to build the collector.\n#\n# Primary targets:\n# all - builds libgc.a, libgccpp.a, libgctba.a and libcord.a\n# base_lib - builds libgc.a only (basic library)\n# c++ - builds libgccpp.a and libgctba.a only (C++ interface to library)\n# cords - builds libcord.a only (heavyweight strings library)\n# check - same as \"all\" but also prints porting information, and runs some\n#         tests of collector and cords\n# check-deps - same as check but do not run the tests\n# check-cpp - builds libgc.a, libgccpp.a and libgctba.a, runs C++ only test\n# check-cpp-deps - same as check-cpp but do not run the test\n# cord/de - builds dumb editor based on cords.\n\nABI_FLAG?=\n# ABI_FLAG should be the cc flag that specifies the ABI.  On most\n# platforms this will be the empty string.  Possible values:\n# +DD64 for 64-bit executable on HP/UX.\n# -n32, -n64, -o32 for SGI/MIPS ABIs.\n\nAS_ABI_FLAG?= $(ABI_FLAG)\n# ABI flag for assembler.  On HP/UX this is +A64 for 64 bit\n# executables.\n\nCC?= cc $(ABI_FLAG)\n# Compiler executable name.  For EMX, replace to \"gcc\".\n\nCXX?= c++ $(ABI_FLAG)\n# Needed only for \"make c++\", which builds the C++ interface.\n\nAS= as $(AS_ABI_FLAG)\n# The above doesn't work with gas, which doesn't run cpp.\n# Define AS as `gcc -c -x assembler-with-cpp' instead.\n# Under Irix 6, you have to specify the ABI (-o32, -n32, or -64)\n# if you use something other than the default ABI on your machine.\n\nLD= ld\n\n# Redefining srcdir allows object code of the collector\n# to be generated in different directories.\nsrcdir= .\nVPATH= $(srcdir)\n\n# Path to atomic_ops source.\nAO_SRC_DIR?=\nAO_SRC_DIR+= $(srcdir)/libatomic_ops\n\nCFLAGS_EXTRA?=\n\n# We need CFLAGS_FOR_PIC because we might be building a shared library.\nCFLAGS_FOR_PIC?=\n\n# The default libgc configuration, OK to customize it by client.\nCFLAGS_DEFAULT_MACROS?= \\\n  -DALL_INTERIOR_POINTERS -DENABLE_DISCLAIM -DGC_ATOMIC_UNCOLLECTABLE \\\n  -DGC_GCJ_SUPPORT -DJAVA_FINALIZATION -DNO_EXECUTE_PERMISSION \\\n  -DUSE_MMAP -DUSE_MUNMAP\n\n# The client or host might provide the default optimizations flags (e.g. -O2).\nCFLAGS?= -O\n\n# Add the required options to CFLAGS like -I option.\nCFLAGS+= -I$(srcdir)/include -I$(AO_SRC_DIR)/src \\\n  $(CFLAGS_DEFAULT_MACROS) $(CFLAGS_FOR_PIC) $(CFLAGS_EXTRA)\n\n# To build the collector with threads support, add to CFLAGS_EXTRA:\n# -DGC_THREADS -DPARALLEL_MARK -DTHREAD_LOCAL_ALLOC\n#\n# To build the preload library that intercepts malloc, add:\n# -DGC_USE_DLOPEN_WRAP -DREDIRECT_MALLOC=GC_malloc -fpic\n\n# To build the collector with fork() support by default, add to the above:\n# -DHANDLE_FORK\n\n# To build the collector with GC_wcsdup support, provided libc has wcslen(),\n# add to the above:\n# -DGC_REQUIRE_WCSDUP\n\n# HOSTCC and HOSTCFLAGS are used to build executables that will be run as\n# part of the build process, i.e. on the build machine.  These will usually\n# be the same as CC and CFLAGS, except in a cross-compilation environment.\n# Note that HOSTCFLAGS should include any -D flags that affect thread support.\nHOSTCC= $(CC)\nHOSTCFLAGS= $(CFLAGS)\n\n# For dynamic library builds, it may be necessary to add flags to generate\n# PIC code, e.g. -fPIC on Linux.\n\n# setjmp_test may yield overly optimistic results when compiled\n# without optimization.\n\n# Look into docs/README.macros for the description of the \"define arguments\"\n# influencing the collector configuration.\n\n# Flags for the C++ files.\n# Note: non-GNU make might not recognize \"?=\" properly, so just duplicate\n# the flags of CFLAGS as a workaround.\nCXXFLAGS?=\nCXXFLAGS+= -I$(srcdir)/include -I$(AO_SRC_DIR)/src \\\n  $(CFLAGS_DEFAULT_MACROS) $(CFLAGS_FOR_PIC) $(CFLAGS_EXTRA)\n\nAR?= ar\n\n# Note: for Cosmo and EMX, specify \"$(AR) s\" instead of \"ranlib\".\nRANLIB?= ranlib\n\n# All .o files of libgc.a except for dyn_load.o.\nOBJS= allchblk.o alloc.o backgraph.o blacklst.o checksums.o \\\n  darwin_stop_world.o dbg_mlc.o finalize.o fnlz_mlc.o gc_dlopen.o \\\n  gcj_mlc.o headers.o mach_dep.o malloc.o mallocx.o mark.o mark_rts.o misc.o \\\n  new_hblk.o obj_map.o os_dep.o pthread_start.o pthread_stop_world.o \\\n  pthread_support.o ptr_chck.o reclaim.o specific.o thread_local_alloc.o \\\n  typd_mlc.o win32_threads.o\n\nNODIST_OBJS= atomic_ops.o\n\n# Note: comment out the following line if compiler does not support .S files.\nNODIST_OBJS+= atomic_ops_sysdeps.o\n\n# Almost matches OBJS but also includes dyn_load.c.\nCSRCS= allchblk.c alloc.c backgraph.c blacklst.c checksums.c \\\n  darwin_stop_world.c dbg_mlc.c dyn_load.c finalize.c fnlz_mlc.c gc_dlopen.c \\\n  gcj_mlc.c headers.c mach_dep.c malloc.c mallocx.c mark.c mark_rts.c misc.c \\\n  new_hblk.c obj_map.c os_dep.c pthread_start.c pthread_stop_world.c \\\n  pthread_support.c ptr_chck.c reclaim.c specific.c thread_local_alloc.c \\\n  typd_mlc.c win32_threads.c\n\nCORD_SRCS= cord/cordbscs.c cord/cordprnt.c cord/cordxtra.c cord/tests/de.c \\\n  cord/tests/cordtest.c include/gc/cord.h include/gc/ec.h \\\n  include/gc/cord_pos.h cord/tests/de_win.c cord/tests/de_win.h \\\n  cord/tests/de_cmds.h cord/tests/de_win.rc\n\n# Not all compilers understand \"-o\" option.  Thus, no \"cord/\" prefix here.\nCORD_OBJS= cordbscs.o cordprnt.o cordxtra.o\n\nSRCS= $(CSRCS) \\\n  include/gc/gc_typed.h include/gc/gc_tiny_fl.h include/gc/gc_version.h \\\n  include/gc.h include/private/gc_hdrs.h include/private/gc_priv.h \\\n  include/gc/gc.h include/private/gcconfig.h include/private/gc_pmark.h \\\n  include/gc/gc_inline.h include/gc/gc_mark.h include/gc/gc_disclaim.h \\\n  tools/threadlibs.c tools/if_mach.c tools/if_not_there.c gc_badalc.cc \\\n  gc_cpp.cc include/gc_cpp.h include/gc/gc_cpp.h \\\n  include/private/gc_alloc_ptrs.h include/gc/gc_allocator.h \\\n  include/gc/javaxfc.h include/gc/gc_backptr.h include/gc/gc_gcj.h \\\n  include/private/gc_locks.h include/private/dbg_mlc.h \\\n  include/private/specific.h include/gc/leak_detector.h \\\n  include/gc/gc_pthread_redirects.h include/private/gc_atomic_ops.h \\\n  include/gc/gc_config_macros.h include/private/pthread_support.h \\\n  include/private/darwin_semaphore.h include/private/thread_local_alloc.h \\\n  ia64_save_regs_in_stack.s sparc_mach_dep.S \\\n  sparc_netbsd_mach_dep.s $(CORD_SRCS)\n\nCORD_INCLUDE_FILES= $(srcdir)/include/gc/gc.h $(srcdir)/include/gc/cord.h \\\n  $(srcdir)/include/gc/ec.h $(srcdir)/include/gc/cord_pos.h\n\n# Executable file name extension.  For EMX, specify \".exe\".\nEXEEXT?=\n\nUTILS= if_mach$(EXEEXT) if_not_there$(EXEEXT) threadlibs$(EXEEXT)\n\n# Libraries needed for curses applications.  Only needed for de.\n# It might also require -ltermlib on some targets.\n# For Win32, it should be set to: -lgdi32\nCURSES?= -lcurses\n\n# The following is irrelevant on most systems.  But a few\n# versions of make otherwise fork the shell specified in\n# the SHELL environment variable.\nSHELL= /bin/sh\n\nSPECIALCFLAGS= -I$(srcdir)/include -I$(AO_SRC_DIR)/src $(CFLAGS_FOR_PIC)\n# Alternative flags to the C compiler for mach_dep.c.\n# mach_dep.c often doesn't like optimization, and it's\n# not time-critical anyway.\n# Set SPECIALCFLAGS to -q nodirect_code on Encore.\n\nall: base_lib cords c++\n\natomic_ops.o: $(AO_SRC_DIR)/src/atomic_ops.c\n\t$(CC) $(CFLAGS) -c $(AO_SRC_DIR)/src/atomic_ops.c\n# For some reason, Solaris make does not handle \"$<\" properly.\n\natomic_ops_sysdeps.o: $(AO_SRC_DIR)/src/atomic_ops_sysdeps.S\n\t$(CC) $(CFLAGS) -c $(AO_SRC_DIR)/src/atomic_ops_sysdeps.S\n\nLEAK_CFLAGS= $(CFLAGS) -DFIND_LEAK\n\n$(OBJS) gctest.o dyn_load.o dyn_load_sunos53.o: \\\n  $(srcdir)/include/private/gc_priv.h \\\n  $(srcdir)/include/private/gc_hdrs.h $(srcdir)/include/private/gc_locks.h \\\n  $(srcdir)/include/gc/gc.h $(srcdir)/include/gc/gc_pthread_redirects.h \\\n  $(srcdir)/include/private/gcconfig.h $(srcdir)/include/gc/gc_typed.h \\\n  $(srcdir)/include/gc/gc_config_macros.h\n\nmark.o typd_mlc.o finalize.o ptr_chck.o: $(srcdir)/include/gc/gc_mark.h \\\n\t\t\t\t\t $(srcdir)/include/private/gc_pmark.h\n\nspecific.o pthread_support.o thread_local_alloc.o win32_threads.o: \\\n  $(srcdir)/include/private/specific.h $(srcdir)/include/gc/gc_inline.h \\\n  $(srcdir)/include/private/thread_local_alloc.h\n\ndbg_mlc.o gcj_mlc.o: $(srcdir)/include/private/dbg_mlc.h\n\ngctest.o: $(srcdir)/tests/gctest.c\n\tmkdir tests || cat /dev/null\n\t$(CC) $(CFLAGS) -c $(srcdir)/tests/gctest.c\n\nbase_lib libgc.a: $(OBJS) dyn_load.o $(UTILS)\n\trm -f dont_ar_1\n\t./if_mach SPARC SOLARIS touch dont_ar_1\n\t./if_mach SPARC SOLARIS $(AR) rus libgc.a $(OBJS) dyn_load.o\n\t./if_not_there dont_ar_1 || $(AR) ru libgc.a $(OBJS) dyn_load.o\n\t./if_not_there dont_ar_1 || $(RANLIB) libgc.a || cat /dev/null\n\techo > base_lib\n#    Ignore ranlib failure; that usually means it doesn't exist, and\n#    isn't needed.\n\ncords libcord.a: $(CORD_OBJS) $(UTILS)\n\trm -f dont_ar_3\n\t./if_mach SPARC SOLARIS touch dont_ar_3\n\t./if_mach SPARC SOLARIS $(AR) rus libcord.a $(CORD_OBJS)\n\t./if_not_there dont_ar_3 || $(AR) ru libcord.a $(CORD_OBJS)\n\t./if_not_there dont_ar_3 || $(RANLIB) libcord.a || cat /dev/null\n\techo > cords\n\ngc_badalc.o: $(srcdir)/gc_badalc.cc $(srcdir)/include/gc/gc_cpp.h \\\n  $(srcdir)/include/gc/gc.h\n\t$(CXX) $(CXXFLAGS) -c $(srcdir)/gc_badalc.cc\n\ngc_cpp.o: $(srcdir)/gc_cpp.cc $(srcdir)/include/gc/gc_cpp.h \\\n  $(srcdir)/include/gc/gc.h\n\t$(CXX) $(CXXFLAGS) -c $(srcdir)/gc_cpp.cc\n\ncpptest$(EXEEXT): $(srcdir)/tests/cpp.cc $(srcdir)/include/gc/gc_cpp.h \\\n  $(srcdir)/include/gc/gc_allocator.h $(srcdir)/include/gc/gc.h c++ \\\n  base_lib $(NODIST_OBJS) $(UTILS)\n\trm -f $@\n\t./if_mach HP_PA HPUX $(CXX) $(CXXFLAGS) -o $@ $(srcdir)/tests/cpp.cc $(NODIST_OBJS) libgc.a libgccpp.a -ldld `./threadlibs`\n\t./if_not_there $@ || $(CXX) $(CXXFLAGS) -DGC_NOT_DLL -o $@ $(srcdir)/tests/cpp.cc $(NODIST_OBJS) libgc.a libgccpp.a `./threadlibs`\n\ntreetest$(EXEEXT): $(srcdir)/tests/tree.cc $(srcdir)/include/gc/gc.h \\\n  $(srcdir)/include/gc/gc_cpp.h libgctba.a base_lib $(NODIST_OBJS)\n\t$(CXX) $(CXXFLAGS) -DGC_NOT_DLL -o $@ $(srcdir)/tests/tree.cc $(NODIST_OBJS) libgc.a libgctba.a `./threadlibs`\n\ncheck-cpp-deps: cpptest$(EXEEXT) treetest$(EXEEXT)\n\ncheck-cpp: check-cpp-deps\n\t./cpptest\n\t./treetest\n\nc++-t: c++ cpptest$(EXEEXT)\n\t./cpptest 1\n\nc++-nt: c++\n\t@echo \"Use ./cpptest 1 to test the leak library\"\n\nc++ libgccpp.a libgctba.a: gc_badalc.o gc_cpp.o $(UTILS)\n\trm -f dont_ar_4\n\t./if_mach SPARC SOLARIS touch dont_ar_4\n\t./if_mach SPARC SOLARIS $(AR) rus libgccpp.a gc_badalc.o gc_cpp.o\n\t./if_mach SPARC SOLARIS $(AR) rus libgctba.a gc_badalc.o\n\t./if_not_there dont_ar_4 || $(AR) ru libgccpp.a gc_badalc.o gc_cpp.o\n\t./if_not_there dont_ar_4 || $(RANLIB) libgccpp.a || cat /dev/null\n\t./if_not_there dont_ar_4 || $(AR) ru libgctba.a gc_badalc.o\n\t./if_not_there dont_ar_4 || $(RANLIB) libgctba.a || cat /dev/null\n\techo > c++\n\ndyn_load_sunos53.o: dyn_load.c\n\t$(CC) $(CFLAGS) -DSUNOS53_SHARED_LIB -c -o $@ $(srcdir)/dyn_load.c\n\n# SunOS5 shared library version of the collector\nsunos5gc.so: $(OBJS) $(NODIST_OBJS) dyn_load_sunos53.o\n\t$(CC) -G -o $@ $(OBJS) $(NODIST_OBJS) dyn_load_sunos53.o -ldl\n\tln $@ libgc.so\n\n# Alpha/OSF shared library version of the collector\nlibalphagc.so: $(OBJS) $(NODIST_OBJS) dyn_load.o\n\t$(LD) -shared -o $@ $(OBJS) $(NODIST_OBJS) dyn_load.o -lc\n\tln $@ libgc.so\n\n# IRIX shared library version of the collector\nlibirixgc.so: $(OBJS) $(NODIST_OBJS) dyn_load.o\n\t$(LD) -shared $(ABI_FLAG) -o $@ $(OBJS) $(NODIST_OBJS) dyn_load.o -lc\n\tln $@ libgc.so\n\n# Linux shared library version of the collector\nliblinuxgc.so: $(OBJS) $(NODIST_OBJS) dyn_load.o\n\tgcc -shared -o $@ $(OBJS) $(NODIST_OBJS) dyn_load.o\n\tln $@ libgc.so\n\n# Build gctest with dynamic library\ndyn_test:\n\t$(CC) $(CFLAGS) -o gctest$(EXEEXT) tests/gctest.c libgc.so `./threadlibs`\n\t./gctest\n\nmach_dep.o: $(srcdir)/mach_dep.c $(srcdir)/sparc_mach_dep.S \\\n  $(srcdir)/ia64_save_regs_in_stack.s \\\n  $(srcdir)/sparc_netbsd_mach_dep.s $(UTILS)\n\trm -f $@\n\t./if_mach SPARC LINUX $(CC) -c -o mach_dep2.o $(srcdir)/sparc_mach_dep.S\n\t./if_mach SPARC SOLARIS $(CC) -c -o mach_dep2.o $(srcdir)/sparc_mach_dep.S\n\t./if_mach SPARC OPENBSD $(CC) -c -o mach_dep2.o $(srcdir)/sparc_mach_dep.S\n\t./if_mach SPARC NETBSD $(AS) -o mach_dep2.o $(srcdir)/sparc_netbsd_mach_dep.s\n\t./if_mach SPARC \"\" $(CC) $(SPECIALCFLAGS) -c -o mach_dep1.o $(srcdir)/mach_dep.c\n\t./if_mach SPARC \"\" $(LD) -r -o $@ mach_dep1.o mach_dep2.o\n\t./if_mach IA64 \"\" $(AS) -o ia64_save_regs_in_stack.o $(srcdir)/ia64_save_regs_in_stack.s\n\t./if_mach IA64 \"\" $(CC) $(SPECIALCFLAGS) -c -o mach_dep1.o $(srcdir)/mach_dep.c\n\t./if_mach IA64 \"\" $(LD) -r -o $@ mach_dep1.o ia64_save_regs_in_stack.o\n\t-./if_not_there $@ || $(CC) $(SPECIALCFLAGS) -c $(srcdir)/mach_dep.c\n\t-./if_not_there $@ || `cygpath -w /bin/sh` $(CC) $(SPECIALCFLAGS) -c $(srcdir)/mach_dep.c\n\t-./if_not_there $@ || /bin/sh $(CC) $(SPECIALCFLAGS) -c $(srcdir)/mach_dep.c\n\nmark_rts.o: $(srcdir)/mark_rts.c $(UTILS)\n\trm -f $@\n\t-./if_mach ALPHA OSF1 $(CC) $(CFLAGS) -Wo,-notail -c $(srcdir)/mark_rts.c\n\t-./if_not_there $@ || $(CC) $(CFLAGS) -c $(srcdir)/mark_rts.c\n\t-./if_not_there $@ || `cygpath -w /bin/sh` $(CC) $(CFLAGS) -c $(srcdir)/mark_rts.c\n\t-./if_not_there $@ || /bin/sh $(CC) $(CFLAGS) -c $(srcdir)/mark_rts.c\n#   Work-around for DEC optimizer tail recursion elimination bug.\n#   The ALPHA-specific line should be removed if gcc is used.\n\nalloc.o: include/gc/gc_version.h\n\ncordbscs.o: $(srcdir)/cord/cordbscs.c $(CORD_INCLUDE_FILES)\n\t$(CC) $(CFLAGS) -I$(srcdir) -c $(srcdir)/cord/cordbscs.c\n\ncordxtra.o: $(srcdir)/cord/cordxtra.c $(CORD_INCLUDE_FILES)\n\t$(CC) $(CFLAGS) -I$(srcdir) -c $(srcdir)/cord/cordxtra.c\n\ncordprnt.o: $(srcdir)/cord/cordprnt.c $(CORD_INCLUDE_FILES)\n\t$(CC) $(CFLAGS) -I$(srcdir) -c $(srcdir)/cord/cordprnt.c\n\ncordtest$(EXEEXT): $(srcdir)/cord/tests/cordtest.c cords base_lib $(NODIST_OBJS) $(UTILS)\n\trm -f $@\n\t./if_mach SPARC DRSNX $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/cordtest.c $(NODIST_OBJS) libgc.a libcord.a -lucb\n\t./if_mach HP_PA HPUX $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/cordtest.c $(NODIST_OBJS) libgc.a libcord.a -ldld `./threadlibs`\n\t./if_not_there $@ || $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/cordtest.c $(NODIST_OBJS) libgc.a libcord.a `./threadlibs`\n\ncord/de: de$(EXEEXT)\n\nde$(EXEEXT): $(srcdir)/cord/tests/de.c $(srcdir)/cord/tests/de_win.c \\\n  $(srcdir)/cord/tests/de_win.h cords base_lib $(NODIST_OBJS) $(UTILS)\n\trm -f $@\n\t./if_mach SPARC DRSNX $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/de.c $(NODIST_OBJS) libgc.a libcord.a -lcurses -ltermlib -lucb `./threadlibs`\n\t./if_mach HP_PA HPUX $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/de.c $(NODIST_OBJS) libgc.a libcord.a -lcurses -ltermlib -ldld `./threadlibs`\n\t./if_mach POWERPC AIX $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/de.c $(NODIST_OBJS) libgc.a libcord.a -lcurses\n\t./if_mach POWERPC DARWIN $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/de.c $(NODIST_OBJS) libgc.a libcord.a\n\t./if_not_there $@ || $(CC) $(CFLAGS) -o $@ $(srcdir)/cord/tests/de.c $(srcdir)/cord/tests/de_win.c $(NODIST_OBJS) libgc.a libcord.a $(CURSES) `./threadlibs`\n\nif_mach$(EXEEXT): $(srcdir)/tools/if_mach.c \\\n  $(srcdir)/include/private/gcconfig.h\n\t$(HOSTCC) $(HOSTCFLAGS) -o $@ $(srcdir)/tools/if_mach.c\n\nthreadlibs$(EXEEXT): $(srcdir)/tools/threadlibs.c \\\n  $(srcdir)/include/private/gcconfig.h\n\t$(HOSTCC) $(HOSTCFLAGS) -o $@ $(srcdir)/tools/threadlibs.c\n\nif_not_there$(EXEEXT): $(srcdir)/tools/if_not_there.c\n\t$(HOSTCC) $(HOSTCFLAGS) -o $@ $(srcdir)/tools/if_not_there.c\n\nclean:\n\trm -f *.a *.i *.o *.com.dbg *.elf *.exe \\\n\t      cpptest treetest gctest gctest_dyn_link setjmp_test \\\n\t      a.out core if_not_there if_mach base_lib c++ gmon.out mon.out \\\n\t      cordtest de cords dont_ar_* threadlibs *.log cordtst*.tmp\n\t-rm -f *~\n\ngctest$(EXEEXT): gctest.o base_lib $(NODIST_OBJS) $(UTILS)\n\trm -f $@\n\t./if_mach SPARC DRSNX $(CC) $(CFLAGS) -o $@ gctest.o $(NODIST_OBJS) libgc.a -lucb\n\t./if_mach HP_PA HPUX $(CC) $(CFLAGS) -o $@ gctest.o $(NODIST_OBJS) libgc.a -ldld `./threadlibs`\n\t./if_not_there $@ || $(CC) $(CFLAGS) -o $@ gctest.o $(NODIST_OBJS) libgc.a `./threadlibs`\n\n# If an optimized setjmp_test generates a segmentation fault,\n# odds are your compiler is broken.  gctest may still work.\n# Try compiling setjmp_t.c unoptimized.\nsetjmp_test$(EXEEXT): $(srcdir)/tools/setjmp_t.c $(srcdir)/include/gc/gc.h \\\n  $(UTILS)\n\t$(CC) $(CFLAGS) -o $@ $(srcdir)/tools/setjmp_t.c\n\ncheck-deps: cordtest$(EXEEXT) gctest$(EXEEXT) setjmp_test$(EXEEXT) \\\n  cpptest$(EXEEXT) treetest$(EXEEXT)\n\ncheck: check-deps\n\t./setjmp_test\n\t./gctest\n\t./cordtest\n\t./cpptest\n\t./treetest\n\n# A synonym to \"check\" (for compatibility with older GC versions).\ntest: check\n\n# BTL: added to test shared library version of collector.\n# Currently works only under SunOS5.  Requires GC_INIT call from statically\n# loaded client code.\nABSDIR= `pwd`\ngctest_dyn_link: gctest.o libgc.so\n\t$(CC) -L$(ABSDIR) -R$(ABSDIR) -o $@ gctest.o -lgc -ldl -lthread\n\ngctest_irix_dyn_link: gctest.o libirixgc.so\n\t$(CC) -L$(ABSDIR) -o $@ gctest.o -lirixgc\n\nSYM_PREFIX-libgc= GC\n\nreserved_namespace: $(SRCS)\n\tfor file in $(SRCS) tests/gctest.c tests/cpp.cc; do \\\n\t\tsed s/GC_/_GC_/g < $$file > tmp; \\\n\t\tcp tmp $$file; \\\n\t\tdone\n\nuser_namespace: $(SRCS)\n\tfor file in $(SRCS) tests/gctest.c tests/cpp.cc; do \\\n\t\tsed s/_GC_/GC_/g < $$file > tmp; \\\n\t\tcp tmp $$file; \\\n\t\tdone\n"
        },
        {
          "name": "NT_MAKEFILE",
          "type": "blob",
          "size": 7.400390625,
          "content": "# Makefile for Windows (Win32/64).  Assumes Microsoft compiler.\n# Should be invoked as \"nmake -f NT_MAKEFILE [<args>]\"; the optional arguments\n# are: \"cpu=AMD64\" - to target x64, \"cpu=i386\" - to target x86,\n# \"enable_static=1\" - to build it as a static library, \"nodebug=1\" - to produce\n# the release variant of the library, \"disable_threads=1\" - to build the\n# library and the tests without threads support.\n\ncc = cl\nlink = link\nrc = rc\n\n!IF !DEFINED(CPU) || \"$(CPU)\" == \"\"\nCPU = $(PROCESSOR_ARCHITECTURE)\n!ENDIF\n!IF \"$(CPU)\" == \"I386\" || \"$(CPU)\" == \"X86\" || \"$(CPU)\" == \"x86\"\nCPU = i386\n!ELSEIF \"$(CPU)\" == \"X64\" || \"$(CPU)\" == \"x64\" || \"$(CPU)\" == \"amd64\"\nCPU = AMD64\n!ENDIF\n\n!IF !DEFINED(NMAKE_WINVER)\nNMAKE_WINVER = 0x0600\n!ENDIF\n\ncflags = $(cflags) -c -DCRTAPI1=_cdecl -DCRTAPI2=_cdecl -GS -D_WINNT -W4\n!IF \"$(CPU)\" == \"i386\"\ncflags = $(cflags) -D_X86_=1  -DWIN32 -D_WIN32\n!ELSEIF \"$(CPU)\" == \"AMD64\"\ncflags = $(cflags) -D_AMD64_=1 -DWIN64 -D_WIN64  -DWIN32 -D_WIN32\n!ENDIF\ncflags = $(cflags) -D_WIN32_WINNT=$(NMAKE_WINVER) -DWINVER=$(NMAKE_WINVER)\n\n!IFDEF NODEBUG\ncvarsmt = -D_MT -MT\ncdebug = -Ox -DNDEBUG\nrcvars = -DWIN32 -D_WIN32 -DWINVER=$(NMAKE_WINVER)\nldebug = /RELEASE\n!ELSE\ncvarsmt = -D_MT -MTd\ncdebug = -Zi -Od -DDEBUG\nrcvars = -DWIN32 -D_WIN32 -DWINVER=$(NMAKE_WINVER) -DDEBUG -D_DEBUG\nldebug = /DEBUG /DEBUGTYPE:cv\n!ENDIF\n\n!IF \"$(CPU)\" == \"i386\"\nCVTRES_CPU=X86\n!ELSEIF \"$(CPU)\" == \"AMD64\"\nCVTRES_CPU=X64\n!ENDIF\n\n!IFNDEF NODEBUG\nCFLAGS_DEBUG=-DGC_ASSERTIONS\n!ENDIF\n\n!IFDEF ENABLE_STATIC\nCFLAGS_GCDLL=-DGC_NOT_DLL\nCORDFLAG=\n!ELSE\nCFLAGS_GCDLL=-DGC_DLL\n# cord.dll and its clients should not link C library statically otherwise\n# FILE-related functions might not work (because own set of opened FILEs\n# is maintained by each copy of the C library thus making impossible to pass\n# FILE pointer from .exe code to .dll code).\ncvarsmt=\n!IFDEF NODEBUG\nCORDFLAG=-MD\n!ELSE\nCORDFLAG=-MDd\n!ENDIF\n!ENDIF\n\n!IFNDEF DISABLE_THREADS\nCFLAGS_MT=$(cvarsmt) -DGC_THREADS -DTHREAD_LOCAL_ALLOC -DPARALLEL_MARK\n!ENDIF\n\n# Extra user-defined flags to pass both to C and C++ compilers.\nCFLAGS_EXTRA=\n\nCFLAGS_SPECIFIC=$(CFLAGS_DEBUG) $(CFLAGS_GCDLL) $(CFLAGS_MT)\n\nCFLAGS_DEFAULT=-DALL_INTERIOR_POINTERS -DENABLE_DISCLAIM -DGC_ATOMIC_UNCOLLECTABLE -DGC_GCJ_SUPPORT -DJAVA_FINALIZATION -DNO_EXECUTE_PERMISSION -DGC_REQUIRE_WCSDUP -DUSE_MUNMAP\n\nCXXFLAGS_SPECIFIC=/EHsc\n\n# Make sure that .cc is not viewed as a suffix.  It is for VC++2005, but\n# not earlier versions.  We can deal with either, but not inconsistency.\n.SUFFIXES:\n.SUFFIXES: .obj .cpp .c\n\n# Atomic_ops installation directory.  For Win32, the source directory\n# should do, since we only need the headers.\n# We assume this was manually unpacked.\nAO_SRC_DIR=libatomic_ops/src\nAO_INCLUDE_DIR=$(AO_SRC_DIR)\n\n!IFDEF ENABLE_STATIC\n# pthread_start.obj is needed just in case client defines GC_WIN32_PTHREADS.\nOBJS= allchblk.obj alloc.obj blacklst.obj dbg_mlc.obj dyn_load.obj finalize.obj fnlz_mlc.obj gcj_mlc.obj headers.obj mach_dep.obj malloc.obj mallocx.obj mark.obj mark_rts.obj misc.obj new_hblk.obj obj_map.obj os_dep.obj pthread_start.obj pthread_support.obj ptr_chck.obj reclaim.obj thread_local_alloc.obj typd_mlc.obj win32_threads.obj extra\\msvc_dbg.obj\n!ELSE\nOBJS= extra\\gc.obj extra\\msvc_dbg.obj\n!ENDIF\n\nCOBJS= cord\\cordbscs.obj cord\\cordprnt.obj cord\\cordxtra.obj\n\nall: gc.lib cord.lib gccpp.lib gctba.lib\n\ncheck-deps: gctest.exe cpptest.exe treetest.exe cordtest.exe de.exe\n\ncheck: check-deps\n\tgctest.exe\n\tcordtest.exe\n\tcpptest.exe\n\ttreetest.exe\n\n.c.obj:\n\t$(cc) $(cdebug) $(cflags) $(CFLAGS_SPECIFIC) $(CORDFLAG) -Iinclude -I$(AO_INCLUDE_DIR) $(CFLAGS_DEFAULT) -D_CRT_SECURE_NO_DEPRECATE $(CFLAGS_EXTRA) $*.c /Fo$*.obj /wd4127 /wd4701\n# Disable crt security warnings, since unfortunately they warn about all sorts\n# of safe uses of strncpy.  It would be nice to leave the rest enabled.\n\n.cpp.obj:\n\t$(cc) $(cdebug) $(cflags) $(CFLAGS_SPECIFIC) -Iinclude $(CFLAGS_DEFAULT) $(CXXFLAGS_SPECIFIC) -D_CRT_SECURE_NO_DEPRECATE $(CFLAGS_EXTRA) $*.cpp /Fo$*.obj\n\n$(OBJS) tests\\gctest.obj: include\\private\\gc_priv.h include\\private\\gc_hdrs.h include\\gc\\gc.h include\\private\\gcconfig.h include\\private\\gc_locks.h include\\private\\gc_pmark.h include\\gc\\gc_mark.h include\\gc\\gc_disclaim.h\n\n!IFDEF ENABLE_STATIC\n\ngc.lib: $(OBJS)\n\tlib /out:gc.lib /MACHINE:$(CPU) $(OBJS)\n\ncord.lib: $(COBJS)\n\tlib /out:cord.lib /MACHINE:$(CPU) $(COBJS)\n\ngccpp.lib: gc_badalc.obj gc_cpp.obj\n\tlib /out:gccpp.lib /MACHINE:$(CPU) gc_badalc.obj gc_cpp.obj\n\n# The same as gccpp.lib but contains only gc_badalc.obj.\ngctba.lib: gc_badalc.obj\n\tlib /out:gctba.lib /MACHINE:$(CPU) gc_badalc.obj\n\n!ELSE\n\ngc.lib: $(OBJS)\n\t$(link) $(ldebug) kernel32.lib user32.lib /subsystem:windows /dll /INCREMENTAL:NO /pdb:\"gc.pdb\" /out:gc.dll /implib:gc.lib /MACHINE:$(CPU) $(OBJS)\n\ncord.lib: $(COBJS) gc.lib\n\t$(link) $(ldebug) gc.lib /subsystem:windows /dll /INCREMENTAL:NO /pdb:\"cord.pdb\" /out:cord.dll /implib:cord.lib /MACHINE:$(CPU) $(COBJS)\n\ngccpp.lib: gc_badalc.obj gc_cpp.obj gc.lib\n\t$(link) $(ldebug) gc.lib /subsystem:windows /dll /INCREMENTAL:NO /pdb:\"gccpp.pdb\" /out:gccpp.dll /implib:gccpp.lib /MACHINE:$(CPU) gc_badalc.obj gc_cpp.obj\n\ngctba.lib: gc_badalc.obj gc.lib\n\t$(link) $(ldebug) gc.lib /subsystem:windows /dll /INCREMENTAL:NO /pdb:\"gctba.pdb\" /out:gctba.dll /implib:gctba.lib /MACHINE:$(CPU) gc_badalc.obj\n\n!ENDIF\n\ngctest.exe: gc.lib tests\\gctest.obj\n\t$(link) /MACHINE:$(CPU) /INCREMENTAL:NO $(ldebug) $(lflags) user32.lib -out:$*.exe tests\\gctest.obj gc.lib\n#\tmapsympe -n -o gctest.sym gctest.exe\n# This produces a GUI app that opens no window and writes to gctest.gc.log.\n\ncord\\tests\\de_win.rbj: cord\\tests\\de_win.res\n\tcvtres /MACHINE:$(CVTRES_CPU) /OUT:cord\\tests\\de_win.rbj cord\\tests\\de_win.res\n\ncord\\tests\\de.obj cord\\tests\\de_win.obj: include\\gc\\cord.h include\\gc\\cord_pos.h cord\\tests\\de_win.h cord\\tests\\de_cmds.h\n\ncord\\tests\\de_win.res: cord\\tests\\de_win.rc cord\\tests\\de_win.h cord\\tests\\de_cmds.h\n\t$(rc) $(rcvars) -r -fo cord\\tests\\de_win.res cord\\tests\\de_win.rc\n\n# Cord/de is a real Windows GUI app.\nde.exe: cord\\tests\\de.obj cord\\tests\\de_win.obj cord\\tests\\de_win.rbj gc.lib cord.lib\n\t$(link) /MACHINE:$(CPU) /INCREMENTAL:NO $(ldebug) $(lflags) -out:de.exe cord\\tests\\de.obj cord\\tests\\de_win.obj cord\\tests\\de_win.rbj gc.lib cord.lib gdi32.lib user32.lib\n\ncordtest.exe: cord\\tests\\cordtest.obj gc.lib cord.lib\n\t$(link) /subsystem:console /MACHINE:$(CPU) /INCREMENTAL:NO $(ldebug) $(lflags) -out:cordtest.exe cord\\tests\\cordtest.obj gc.lib cord.lib user32.lib\n\ngc_badalc.obj: gc_badalc.cc include\\gc\\gc_cpp.h include\\gc\\gc.h\n\ngc_cpp.obj: gc_cpp.cc include\\gc\\gc_cpp.h include\\gc\\gc.h\n\ntest_cpp.cpp: tests\\cpp.cc\n\tcopy tests\\cpp.cc test_cpp.cpp\n\n# This generates the C++ test executable.  The executable expects\n# a single numeric argument, which is the number of iterations.\n# The output appears in cpptest.gc.log file.\ncpptest.exe: test_cpp.obj include\\gc\\gc_cpp.h include\\gc\\gc_allocator.h include\\gc\\gc.h gc.lib gccpp.lib\n\t$(link) /MACHINE:$(CPU) /INCREMENTAL:NO $(ldebug) $(lflags) user32.lib -out:cpptest.exe test_cpp.obj gc.lib gccpp.lib\n\ntest_tree.cpp: tests\\tree.cc\n\tcopy tests\\tree.cc test_tree.cpp\n\ntreetest.exe: test_tree.obj include\\gc\\gc_cpp.h include\\gc\\gc.h gc.lib gctba.lib\n\t$(link) /MACHINE:$(CPU) /INCREMENTAL:NO $(ldebug) $(lflags) user32.lib -out:treetest.exe test_tree.obj gc.lib gctba.lib\n\n$(AO_SRC_DIR):\n\ttar xvfz $(AO_SRC_DIR).tar.gz\n\nclean:\n\tdel *.dll *.exe *.exp *.lib *.log *.obj *.pdb cordtst*.tmp cord\\*.obj cord\\tests\\*.rbj cord\\tests\\*.res cord\\tests\\*.obj extra\\*.obj test_cpp.cpp test_tree.cpp tests\\*.obj 2> nul\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 30.8095703125,
          "content": "# Boehm-Demers-Weiser Garbage Collector\n\n[![Travis-CI build status](https://app.travis-ci.com/ivmai/bdwgc.svg?branch=master)](https://app.travis-ci.com/github/ivmai/bdwgc)\n[![AppVeyor CI build status](https://ci.appveyor.com/api/projects/status/github/ivmai/bdwgc?branch=master&svg=true)](https://ci.appveyor.com/project/ivmai/bdwgc)\n[![GitHub Actions build status (cmake)](https://github.com/ivmai/bdwgc/actions/workflows/cmake-build.yml/badge.svg?event=push)](https://github.com/ivmai/bdwgc/actions/workflows/cmake-build.yml?query=branch%3Amaster)\n[![GitHub Actions build status (cmake cosmo)](https://github.com/ivmai/bdwgc/actions/workflows/cmake-cosmo.yml/badge.svg?event=push)](https://github.com/ivmai/bdwgc/actions/workflows/cmake-cosmo.yml?query=branch%3Amaster)\n[![GitHub Actions build status (zig build/test)](https://github.com/ivmai/bdwgc/actions/workflows/zig-build.yml/badge.svg?event=push)](https://github.com/ivmai/bdwgc/actions/workflows/zig-build.yml?query=branch%3Amaster)\n[![GitHub Actions build status (zig cross-compile)](https://github.com/ivmai/bdwgc/actions/workflows/zig-cross-compile.yml/badge.svg?event=push)](https://github.com/ivmai/bdwgc/actions/workflows/zig-cross-compile.yml?query=branch%3Amaster)\n[![GitHub Actions status (clang-format)](https://github.com/ivmai/bdwgc/actions/workflows/clang-format-check.yml/badge.svg?event=push)](https://github.com/ivmai/bdwgc/actions/workflows/clang-format-check.yml?query=branch%3Amaster)\n[![CodeQL](https://github.com/ivmai/bdwgc/workflows/CodeQL/badge.svg)](https://github.com/ivmai/bdwgc/actions/workflows/CodeQL.yml?query=branch%3Amaster)\n[![Codecov.io](https://codecov.io/github/ivmai/bdwgc/coverage.svg?branch=master)](https://codecov.io/github/ivmai/bdwgc?branch=master)\n[![Coveralls test coverage status](https://coveralls.io/repos/github/ivmai/bdwgc/badge.png?branch=master)](https://coveralls.io/github/ivmai/bdwgc)\n[![Coverity Scan build status](https://scan.coverity.com/projects/10813/badge.svg)](https://scan.coverity.com/projects/ivmai-bdwgc)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fivmai%2Fbdwgc.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fivmai%2Fbdwgc?ref=badge_shield)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6332/badge)](https://bestpractices.coreinfrastructure.org/projects/6332)\n[![Hits-of-Code](https://hitsofcode.com/github/ivmai/bdwgc?branch=master)](https://hitsofcode.com/github/ivmai/bdwgc/view)\n[![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/ivmai/bdwgc)](https://shields.io/category/size)\n[![Github All Releases](https://img.shields.io/github/downloads/ivmai/bdwgc/total.svg)](https://shields.io/category/downloads)\n[![Packaging status](https://repology.org/badge/tiny-repos/boehm-gc.svg)](https://repology.org/project/boehm-gc/versions)\n\nThis is version 8.3.0 (next release development) of a conservative garbage\ncollector for C and C++.\n\nLicense: [MIT-style](LICENSE)\n\n\n## Download\n\nYou might find a more recent/stable version on the\n[Download](https://github.com/ivmai/bdwgc/wiki/Download) page, or\n[BDWGC site](http://www.hboehm.info/gc/).\n\nAlso, the latest bug fixes and new features are available in the\n[development repository](https://github.com/ivmai/bdwgc).\n\n\n## Overview\n\nThis is intended to be a general purpose, garbage collecting storage\nallocator.  The algorithms used are described in:\n\n * Boehm, H., and M. Weiser, \"Garbage Collection in an Uncooperative\n   Environment\", Software Practice & Experience, September 1988, pp. 807-820.\n\n * Boehm, H., A. Demers, and S. Shenker, \"Mostly Parallel Garbage Collection\",\n   Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design\n   and Implementation, SIGPLAN Notices 26, 6 (June 1991), pp. 157-164.\n\n * Boehm, H., \"Space Efficient Conservative Garbage Collection\", Proceedings\n   of the ACM SIGPLAN '91 Conference on Programming Language Design and\n   Implementation, SIGPLAN Notices 28, 6 (June 1993), pp. 197-206.\n\n * Boehm H., \"Reducing Garbage Collector Cache Misses\", Proceedings of the\n   2000 International Symposium on Memory Management.\n\nPossible interactions between the collector and optimizing compilers are\ndiscussed in\n\n * Boehm, H., and D. Chase, \"A Proposal for GC-safe C Compilation\",\n   The Journal of C Language Translation 4, 2 (December 1992).\n\n * Boehm H., \"Simple GC-safe Compilation\", Proceedings of the ACM SIGPLAN '96\n   Conference on Programming Language Design and Implementation.\n\nUnlike the collector described in the second reference, this collector\noperates either with the mutator stopped during the entire collection\n(default) or incrementally during allocations.  (The latter is supported\non fewer machines.)  On the most common platforms, it can be built\nwith or without thread support.  On some platforms, it can take advantage\nof a multiprocessor to speed up garbage collection.\n\nMany of the ideas underlying the collector have previously been explored\nby others.  Notably, some of the run-time systems developed at Xerox PARC\nin the early 1980s conservatively scanned thread stacks to locate possible\npointers (cf. Paul Rovner, \"On Adding Garbage Collection and Runtime Types\nto a Strongly-Typed Statically Checked, Concurrent Language\" Xerox PARC\nCSL 84-7).  Doug McIlroy wrote a simpler fully conservative collector that\nwas part of version 8 UNIX (tm), but appears to not have received\nwidespread use.\n\nRudimentary tools for use of the collector as a [leak detector](docs/leak.md)\nare included, as is a fairly sophisticated string package \"cord\" that\nmakes use of the collector.  (See [cords.md](docs/cords.md) and\nH.-J. Boehm, R. Atkinson, and M. Plass, \"Ropes: An Alternative to Strings\",\nSoftware Practice and Experience 25, 12 (December 1995), pp. 1315-1330.\nThis is very similar to the \"rope\" package in Xerox Cedar, or the \"rope\"\npackage in the SGI STL or the g++ distribution.)\n\nFurther collector documentation can be found in the\n[overview](docs/overview.md).\n\nSome of the known uses of the collector are listed on the GitHub\n[Known-clients](https://github.com/ivmai/bdwgc/wiki/Known-clients) page.\n\n\n## General Description\n\nThis is a garbage collecting storage allocator that is intended to be\nused as a plug-in replacement for C's malloc.\n\nSince the collector does not require pointers to be tagged, it does not\nattempt to ensure that all inaccessible storage is reclaimed.  However,\nin our experience, it is typically more successful at reclaiming unused\nmemory than most C programs using explicit deallocation.  Unlike manually\nintroduced leaks, the amount of unreclaimed memory typically stays\nbounded.\n\nIn the following, an \"object\" is defined to be a region of memory allocated\nby the routines described below.\n\nAny objects not intended to be collected must be pointed to either\nfrom other such accessible objects, or from the registers,\nstack, data, or statically allocated bss segments.  Pointers from\nthe stack or registers may point to anywhere inside an object.\nThe same is true for heap pointers if the collector is compiled with\n`ALL_INTERIOR_POINTERS` defined, or `GC_all_interior_pointers` is otherwise\nset, as is now the default.\n\nCompiling without `ALL_INTERIOR_POINTERS` may reduce accidental retention\nof garbage objects, by requiring pointers from the heap to the beginning\nof an object.  But this no longer appears to be a significant\nissue for most programs occupying a small fraction of the possible\naddress space.\n\nThere are a number of routines which modify the pointer recognition\nalgorithm.  `GC_register_displacement` allows certain interior pointers\nto be recognized even if `ALL_INTERIOR_POINTERS` is not defined.\n`GC_malloc_ignore_off_page` allows some pointers into the middle of\nlarge objects to be disregarded, greatly reducing the probability of\naccidental retention of large objects.  For most purposes it seems\nbest to compile with `ALL_INTERIOR_POINTERS` and to use\n`GC_malloc_ignore_off_page` if you get collector warnings from\nallocations of very large objects.  See [here](docs/debugging.md) for details.\n\n_WARNING_: pointers inside memory allocated by the standard (system) `malloc`\nare not seen by the garbage collector.  Thus objects pointed to only from such\na region may be prematurely deallocated.  It is thus suggested that the\nstandard `malloc` be used only for memory regions, such as I/O buffers, that\nare guaranteed not to contain pointers to garbage collectible memory.\nPointers in C language automatic, static, or register variables,\nare correctly recognized.  (Note that `GC_malloc_uncollectable` has\nsemantics similar to standard malloc, but allocates objects that are\ntraced by the collector.)\n\n_WARNING_: the collector does not always know how to find pointers in data\nareas that are associated with dynamic libraries.  This is easy to remedy\nif you know how to find those data areas on your operating system (see\n`GC_add_roots`).  Code for doing this under SunOS, IRIX 5.X and 6.X, HP/UX,\nAlpha OSF/1, Linux, and Win32 is included and used by default.\n(See [README.win32](docs/platforms/README.win32) and\n[README.win64](docs/platforms/README.win64) for Windows details.)  On other\nsystems, pointers from dynamic library data areas may not be considered by the\ncollector.  If you're writing a program that depends on the collector scanning\ndynamic library data areas, it may be a good idea to include at least one call\nto `GC_is_visible` to ensure that those areas are visible to the collector.\n\nNote that the garbage collector does not need to be informed of shared\nread-only data.  However, if the shared library mechanism can introduce\ndiscontiguous data areas that may contain pointers then the collector does\nneed to be informed.\n\nSignal processing for most signals may be deferred during collection,\nand during uninterruptible parts of the allocation process.\nLike standard ANSI C mallocs, by default it is unsafe to invoke\nmalloc (and other GC routines) from a signal handler while another\nmalloc call may be in progress.\n\nThe allocator/collector can also be configured for thread-safe operation.\n(Full signal safety can also be achieved, but only at the cost of two system\ncalls per malloc, which is usually unacceptable.)\n\n_WARNING_: the collector does not guarantee to scan thread-local storage\n(e.g. of the kind accessed with `pthread_getspecific`).  The collector\ndoes scan thread stacks, though, so generally the best solution is to\nensure that any pointers stored in thread-local storage are also\nstored on the thread's stack for the duration of their lifetime.\n(This is arguably a longstanding bug, but it hasn't been fixed yet.)\n\n\n## Building and Installing\n\nThere are multiple ways to build the collector:\n\n  * CMake (it is the recommended way)\n  * GNU autoconf/automake\n  * Zig (experimental)\n  * MS nmake (directly)\n  * Makefile.direct\n  * Manual C compilation\n\n### CMake\n\nThe simplest way to build libgc (as well as libcord) and run the tests using\ncmake:\n\n```sh\nmkdir out\ncd out\ncmake -Dbuild_tests=ON ..\ncmake --build .\nctest\n```\n\nThis is the most cross-platform way of building the library.\nSee [README.cmake](docs/README.cmake) for details.\n\n### GNU Autoconf/Automake\n\nPlease note that the collector source repository does not contain `configure`\nand similar auto-generated files, thus the full procedure of autoconf-based\nbuild of the collector from the source repository could look like:\n\n```sh\n./autogen.sh\n./configure\nmake check\n```\n\nThe GNU style build process understands the usual targets and options.\n`make install` installs libgc and libcord.  Try `./configure --help` to see\nall the configuration options.  It is currently not possible to exercise all\ncombinations of build options this way.\n\nSee [README.autoconf](docs/README.autoconf) for details.\n\n### Zig\n\nBuilding and testing the collector using zig is straight forward in its\nsimplest form:\n\n```sh\nzig build test\n```\n\nIt is possible to configure the build through the use of variables, e.g.\n`zig build -Denable_redirect_malloc -Denable_threads=false`. Zig offers\nexcellent cross-compilation functionality, it is configurable like this:\n\n```sh\nzig build -Dtarget=riscv64-linux-musl\n```\n\nThe appropriate Zig binary package file could be downloaded from the official\n[Zig releases](https://ziglang.org/download/) page.\n\n### MS nmake\n\nOn Windows, assuming the Microsoft build tools are installed and suitably\nconfigured, it is possible to build the library and run the tests using\n`nmake` directly, e.g. by by typing `nmake -f NT_MAKEFILE check`.  However,\nthe recommended way is to use cmake as described above.\n\nSee [README.win32](docs/platforms/README.win32) for details.\n\n### Makefile.direct\n\nFor the old-style (classic) makefile-based build process, typing\n`make -f Makefile.direct check` will automatically build libgc, libcord and\nthen run a number of tests such as `gctest`.  The test is a somewhat\nsuperficial test of collector functionality.  Failure is indicated by a core\ndump or a message to the effect that the collector is broken.  `gctest` may\ntake a dozen of seconds to run on reasonable 2023 vintage 64-bit desktops.\nIt may use up to about 30 MB of memory.\n\nMakefile.direct will generate a library libgc.a which you should link against.\n\n### Manual C Compilation\n\nFinally, on most targets, the collector could be built and tested directly\nwith a single compiler invocation, like this (the sample lacks multi-threading\nsupport):\n\n```sh\ncc -I include -o gctest tests/gctest.c extra/gc.c && ./gctest\n```\n\nE.g., this could be convenient for a debugging purpose.\n\n### Configurable Macros\n\nThe library can be configured more precisely during the build by defining\nthe macros listed in [README.macros](docs/README.macros) file.\n\nThe library is built with threads support enabled (i.e. for thread-safe\noperation) by default, unless explicitly disabled by:\n\n  * `-Denable_threads=false` option passed to `cmake` or `zig build`\n  * `--disable-threads` option passed to `./configure`\n\nThe collector operates silently in the default configuration.\nIn the event of issues, this can usually be changed by defining the\n`GC_PRINT_STATS` or `GC_PRINT_VERBOSE_STATS` environment variables.  This\nwill result in a few lines of descriptive output for each collection.\n(The given statistics exhibit a few peculiarities.\nThings don't appear to add up for a variety of reasons, most notably\nfragmentation losses.  These are probably much more significant for the\ncontrived program `gctest` than for your application.)\n\n### Atomic_ops\n\nUse (cloning) of `libatomic_ops` is now optional provided the compiler\nsupports atomic intrinsics.  Most modern compilers do.  The notable exception\nis the MS compiler (as of Visual Studio 2022).\n\nIf needed, most OS distributes have `libatomic_ops` package; alternatively,\nyou can download or clone it from\n[libatomic_ops](https://github.com/ivmai/libatomic_ops) repository on GitHub.\n\n\n## Portability\n\nThe collector currently is designed to run essentially unmodified on\nmachines that use a flat 32-bit or 64-bit address space.\nThat includes the vast majority of Workstations and x86 (i386 or later) PCs.\n\nIn a few cases (e.g., OS/2, Win32) a separate makefile is supplied; these have\na separate host-specific docs/platforms/README.* file.\n\nDynamic libraries are completely supported only under SunOS/Solaris,\n(and even that support is not functional on the last Sun 3 release),\nLinux, FreeBSD, NetBSD, IRIX, HP/UX, Win32 (not win32s) and OSF/1\non DEC AXP machines plus perhaps a few others listed near the top\nof dyn_load.c.  On other machines we recommend that you do one of\nthe following:\n\n  1. Add dynamic library support (and send us the code).\n  2. Use static versions of the libraries.\n  3. Arrange for dynamic libraries to use the standard malloc. This is still\n  dangerous if the library stores a pointer to a garbage collected object.\n  But nearly all standard interfaces prohibit this, because they deal\n  correctly with pointers to stack allocated objects.  (`strtok` is an\n  exception.  Don't use it.)\n\nIn all cases we assume that pointer alignment is consistent with that\nenforced by the standard C compilers.  If you use a nonstandard compiler\nyou may have to adjust the alignment parameters defined in\n`include/private/gc_priv.h`.  Note that this may also be an issue with packed\nrecords/structs, if those enforce less alignment for pointers.\n\nA port to a machine that is not byte addressed, or does not use 32 bit\nor 64 bit addresses will require a major effort.  A port to plain MSDOS\nor win16 is hard.\n\nFor machines not already mentioned, or for nonstandard compilers,\nsome porting suggestions are provided [here](docs/porting.md).\n\n\n## The C Interface to the Allocator\n\nThe following routines are intended to be directly called by the user.\nNote that usually only `GC_malloc` is necessary.  `GC_clear_roots` and\n`GC_add_roots` calls may be required if the collector has to trace\nfrom nonstandard places (e.g. from dynamic library data areas on a\nmachine on which the collector doesn't already understand them.)  On\nsome machines, it may be desirable to set `GC_stackbottom` to a good\napproximation of the stack base (bottom).\n\nClient code may include `gc.h`, which defines all of the following, plus many\nothers.\n\n  1. `GC_malloc(bytes)` - Allocate an object of a given size.  Unlike malloc,\n  the object is cleared before being returned to the user.  `GC_malloc` will\n  invoke the garbage collector when it determines this to be appropriate.\n  GC_malloc may return 0 if it is unable to acquire sufficient space from the\n  operating system.  This is the most probable consequence of running out\n  of space.  Other possible consequences are that a function call will fail\n  due to lack of stack space, or that the collector will fail in other ways\n  because it cannot maintain its internal data structures, or that a crucial\n  system process will fail and take down the machine.  Most of these\n  possibilities are independent of the malloc implementation.\n\n  2. `GC_malloc_atomic(bytes)` - Allocate an object of a given size that\n  is guaranteed not to contain any pointers.  The returned object is not\n  guaranteed to be cleared. (Can always be replaced by `GC_malloc`, but\n  results in faster collection times.  The collector will probably run faster\n  if large character arrays, etc. are allocated with `GC_malloc_atomic` than\n  if they are statically allocated.)\n\n  3. `GC_realloc(object, new_bytes)` - Change the size of object to be of\n  a given size.  Returns a pointer to the new object, which may, or may not,\n  be the same as the pointer to the old object.  The new object is taken to\n  be atomic if and only if the old one was.  If the new object is composite\n  and larger than the original object then the newly added bytes are cleared.\n  This is very likely to allocate a new object.\n\n  4. `GC_free(object)` - Explicitly deallocate an object returned by\n  `GC_malloc` or `GC_malloc_atomic`, or friends.  Not necessary, but can be\n  used to minimize collections if performance is critical.  Probably\n  a performance loss for very small objects (<= 8 bytes).\n\n  5. `GC_expand_hp(bytes)` - Explicitly increase the heap size.  (This is\n  normally done automatically if a garbage collection failed to reclaim\n  enough memory.  Explicit calls to `GC_expand_hp` may prevent unnecessarily\n  frequent collections at program startup.)\n\n  6. `GC_malloc_ignore_off_page(bytes)` - Identical to `GC_malloc`, but the\n  client promises to keep a pointer to the somewhere within the first GC\n  heap block (512 .. 4096 bytes or even more, depending on the configuration)\n  of the object while it is live.  (This pointer should normally be\n  declared volatile to prevent interference from compiler optimizations.)\n  This is the recommended way to allocate anything that is likely to be\n  larger than 100 KB or so.  (`GC_malloc` may result in a failure to reclaim\n  such objects.)\n\n  7. `GC_set_warn_proc(proc)` - Can be used to redirect warnings from the\n  collector.  Such warnings should be rare, and should not be ignored during\n  code development.\n\n  8. `GC_enable_incremental()` - Enables generational and incremental\n  collection.  Useful for large heaps on machines that provide access to page\n  dirty information.  Some dirty bit implementations may interfere with\n  debugging (by catching address faults) and place restrictions on heap\n  arguments to system calls (since write faults inside a system call may not\n  be handled well).\n\n  9. `GC_register_finalizer(object, proc, data, 0, 0)` and friends - Allow for\n  registration of finalization code.  User supplied finalization code\n  (`(*proc)(object, data)`) is invoked after object becomes unreachable.\n  For more sophisticated uses, and for finalization ordering issues, see\n  `gc.h`.\n\nThe global variable `GC_free_space_divisor` may be adjusted up from it\ndefault value of 3 to use less space and more collection time, or down for\nthe opposite effect.  Setting it to 1 will almost disable collections\nand cause all allocations to simply grow the heap.\n\nThe variable `GC_non_gc_bytes`, which is normally 0, may be changed to reflect\nthe amount of memory allocated by the above routines that should not be\nconsidered as a candidate for collection.  Careless use may, of course, result\nin excessive memory consumption.\n\nSome additional tuning is possible through the parameters defined\nnear the top of `include/private/gc_priv.h`.\n\nIf only `GC_malloc` is intended to be used, it might be appropriate to define:\n\n    #define malloc(n) GC_malloc(n)\n    #define calloc(m,n) GC_malloc((m)*(n))\n\nFor small pieces of VERY allocation intensive code, `gc_inline.h` includes\nsome allocation macros that may be used in place of `GC_malloc` and\nfriends.\n\nAll externally visible names in the garbage collector start with `GC_`.\nTo avoid name conflicts, client code should avoid this prefix, except when\naccessing garbage collector routines.\n\nThere are provisions for allocation with explicit type information.\nThis is rarely necessary.  Details can be found in `gc_typed.h`.\n\n\n## The C++ Interface to the Allocator\n\nThe Ellis-Hull C++ interface to the collector is included in the collector\ndistribution.  If you intend to use this, type\n`./configure --enable-cplusplus && make` (or\n`cmake -Denable_cplusplus=ON . && cmake --build .`, or\n`make -f Makefile.direct c++` depending on the build system you use).\nThis creates libgccpp.a and libgctba.a files, or their shared library\nequivalents (libgccpp.so and libgctba.so).  You should link with either the\nfirst (gccpp) or the second one (gctba), but not both.  See `gc_cpp.h` and\n[here](docs/gcinterface.md) for the definition of the interface.\nThis interface tries to approximate the Ellis-Detlefs C++ garbage collection\nproposal without compiler changes.\n\nVery often it will also be necessary to use `gc_allocator.h` and the\nallocator declared there to construct STL data structures.  Otherwise\nsubobjects of STL data structures will be allocated using a system\nallocator, and objects they refer to may be prematurely collected.\n\n\n## Use as Leak Detector\n\nThe collector may be used to track down leaks in C programs that are\nintended to run with malloc/free (e.g. code with extreme real-time or\nportability constraints).  To do so define `FIND_LEAK` in Makefile.\nThis will cause the collector to print a human-readable object description\nwhenever an inaccessible object is found that has not been explicitly freed.\nSuch objects will also be automatically reclaimed.\n\nIf all objects are allocated with `GC_DEBUG_MALLOC` (see the next section)\nthen, by default, the human-readable object description will at least contain\nthe source file and the line number at which the leaked object was allocated.\nThis may sometimes be sufficient.  (On a few machines, it will also report\na cryptic stack trace.  If this is not symbolic, it can sometimes be called\ninto a symbolic stack trace by invoking program \"foo\" with\n`tools/callprocs.sh foo`.  It is a short shell script that invokes adb to\nexpand program counter values to symbolic addresses.  It was largely supplied\nby Scott Schwartz.)\n\nNote that the debugging facilities described in the next section can\nsometimes be slightly LESS effective in leak finding mode, since in the latter\n`GC_debug_free` actually results in reuse of the object.  (Otherwise the\nobject is simply marked invalid.)  Also, note that most GC tests are not\ndesigned to run meaningfully in `FIND_LEAK` mode.\n\n\n## Debugging Facilities\n\nThe routines `GC_debug_malloc`, `GC_debug_malloc_atomic`, `GC_debug_realloc`,\nand `GC_debug_free` provide an alternate interface to the collector, which\nprovides some help with memory overwrite errors, and the like.\nObjects allocated in this way are annotated with additional\ninformation.  Some of this information is checked during garbage\ncollections, and detected inconsistencies are reported to stderr.\n\nSimple cases of writing past the end of an allocated object should\nbe caught if the object is explicitly deallocated, or if the\ncollector is invoked while the object is live.  The first deallocation\nof an object will clear the debugging info associated with an\nobject, so accidentally repeated calls to `GC_debug_free` will report the\ndeallocation of an object without debugging information.  Out of\nmemory errors will be reported to stderr, in addition to returning `NULL`.\n\n`GC_debug_malloc` checking during garbage collection is enabled\nwith the first call to this function.  This will result in some\nslowdown during collections.  If frequent heap checks are desired,\nthis can be achieved by explicitly invoking `GC_gcollect`, e.g. from\nthe debugger.\n\n`GC_debug_malloc` allocated objects should not be passed to `GC_realloc`\nor `GC_free`, and conversely.  It is however acceptable to allocate only\nsome objects with `GC_debug_malloc`, and to use `GC_malloc` for other objects,\nprovided the two pools are kept distinct.  In this case, there is a very\nlow probability that `GC_malloc` allocated objects may be misidentified as\nhaving been overwritten.  This should happen with probability at most\none in 2**32.  This probability is zero if `GC_debug_malloc` is never called.\n\n`GC_debug_malloc`, `GC_debug_malloc_atomic`, and `GC_debug_realloc` take two\nadditional trailing arguments, a string and an integer.  These are not\ninterpreted by the allocator.  They are stored in the object (the string is\nnot copied).  If an error involving the object is detected, they are printed.\n\nThe macros `GC_MALLOC`, `GC_MALLOC_ATOMIC`, `GC_REALLOC`, `GC_FREE`,\n`GC_REGISTER_FINALIZER` and friends are also provided.  These require the same\narguments as the corresponding (nondebugging) routines.  If `gc.h` is included\nwith `GC_DEBUG` defined, they call the debugging versions of these\nfunctions, passing the current file name and line number as the two\nextra arguments, where appropriate.  If `gc.h` is included without `GC_DEBUG`\ndefined then all these macros will instead be defined to their nondebugging\nequivalents.  (`GC_REGISTER_FINALIZER` is necessary, since pointers to\nobjects with debugging information are really pointers to a displacement\nof 16 bytes from the object beginning, and some translation is necessary\nwhen finalization routines are invoked.  For details, about what's stored\nin the header, see the definition of the type oh in dbg_mlc.c file.)\n\n\n## Incremental/Generational Collection\n\nThe collector normally interrupts client code for the duration of\na garbage collection mark phase.  This may be unacceptable if interactive\nresponse is needed for programs with large heaps.  The collector\ncan also run in a \"generational\" mode, in which it usually attempts to\ncollect only objects allocated since the last garbage collection.\nFurthermore, in this mode, garbage collections run mostly incrementally,\nwith a small amount of work performed in response to each of a large number of\n`GC_malloc` requests.\n\nThis mode is enabled by a call to `GC_enable_incremental`.\n\nIncremental and generational collection is effective in reducing\npause times only if the collector has some way to tell which objects\nor pages have been recently modified.  The collector uses two sources\nof information:\n\n  1. Information provided by the VM system.  This may be provided in one of\n  several forms.  Under Solaris 2.X (and potentially under other similar\n  systems) information on dirty pages can be read from the /proc file system.\n  Under other systems (e.g. SunOS4.X) it is possible to write-protect\n  the heap, and catch the resulting faults. On these systems we require that\n  system calls writing to the heap (other than read) be handled specially by\n  client code. See `os_dep.c` for details.\n\n  2. Information supplied by the programmer.  The object is considered dirty\n  after a call to `GC_end_stubborn_change` provided the library has been\n  compiled suitably. It is typically not worth using for short-lived objects.\n  Note that bugs caused by a missing `GC_end_stubborn_change` or\n  `GC_reachable_here` call are likely to be observed very infrequently and\n  hard to trace.\n\n\n## Bugs\n\nAny memory that does not have a recognizable pointer to it will be\nreclaimed.  Exclusive-or'ing forward and backward links in a list\ndoesn't cut it.\n\nSome C optimizers may lose the last undisguised pointer to a memory\nobject as a consequence of clever optimizations.  This has almost\nnever been observed in practice.\n\nThis is not a real-time collector.  In the standard configuration,\npercentage of time required for collection should be constant across\nheap sizes.  But collection pauses will increase for larger heaps.\nThey will decrease with the number of processors if parallel marking\nis enabled.\n\n(On 2007 vintage machines, GC times may be on the order of 5 ms\nper MB of accessible memory that needs to be scanned and processed.\nYour mileage may vary.)  The incremental/generational collection facility\nmay help in some cases.\n\n\n## Feedback, Contribution, Questions and Notifications\n\nPlease address bug reports and new feature ideas to\n[GitHub issues](https://github.com/ivmai/bdwgc/issues).  Before the\nsubmission please check that it has not been done yet by someone else.\n\nIf you want to contribute, submit\na [pull request](https://github.com/ivmai/bdwgc/pulls) to GitHub.\nPlease process the modified files with clang-format before the submission.\n\nIf you need help, use\n[Stack Overflow](https://stackoverflow.com/questions/tagged/boehm-gc).\nOlder technical discussions are available in `bdwgc` mailing list archive - it\ncan be downloaded as a\n[compressed file](https://github.com/ivmai/bdwgc/files/1038163/bdwgc-mailing-list-archive-2017_04.tar.gz)\nor browsed at [Narkive](http://bdwgc.opendylan.narkive.com).\n\nTo get new release announcements, subscribe to\n[RSS feed](https://github.com/ivmai/bdwgc/releases.atom).\n(To receive the notifications by email, a 3rd-party free service like\n[IFTTT RSS Feed](https://ifttt.com/feed) can be setup.)\nTo be notified on all issues, please\n[watch](https://github.com/ivmai/bdwgc/watchers) the project on\nGitHub.\n\n\n## Copyright & Warranty, Contributors\n\nOur intent is to make it easy to use bdwgc (libgc), in both free and\nproprietary software.  Hence, the Boehm-Demers-Weiser conservative garbage\ncollector code that we expect to be linked dynamically or statically into\na client application is covered by own license, which is similar in\nspirit to an MIT-style one.\n\nThe exact licensing information is provided in [LICENSE](LICENSE) file.\n\nAll the contributors are listed in [AUTHORS](AUTHORS) file.\n"
        },
        {
          "name": "WCC_MAKEFILE",
          "type": "blob",
          "size": 9.341796875,
          "content": "# Makefile for Watcom C/C++ 10.5, 10.6, 11.0 on NT, OS/2 and DOS4GW.\n# May work with Watcom 10.0.\n\n# Uncomment one of the lines below for cross compilation.\nSYSTEM=MSWIN32\n#SYSTEM=DOS4GW\n#SYSTEM=OS2\n\n# The collector can be built either as dynamic (the default) or as static\n# library. The latter is selected by setting ENABLE_STATIC variable.\n#ENABLE_STATIC=1\n\n# Select calling conventions.\n# Possible choices are r and s.\nCALLING=s\n\n# Select target CPU.\n# Possible choices are 3, 4, 5, and 6.\n# The last choice available only since version 11.0.\nCPU=5\n\n# Set optimization options.\n# Watcom before 11.0 does not support option \"-oh\".\nOPTIM=-oneatx -s\n#OPTIM=-ohneatx -s\n\n# Extra user-defined flags to pass both to C and C++ compilers.\nCFLAGS_EXTRA=\n\nDEFS=-DALL_INTERIOR_POINTERS -DENABLE_DISCLAIM -DGC_ATOMIC_UNCOLLECTABLE -DGC_GCJ_SUPPORT -DJAVA_FINALIZATION -DNO_EXECUTE_PERMISSION -DGC_REQUIRE_WCSDUP #-DSMALL_CONFIG\n\n#####\n\n!ifndef SYSTEM\n!ifdef __MSDOS__\nSYSTEM=DOS4GW\n!else ifdef __NT__\nSYSTEM=MSWIN32\n!else ifdef __OS2__\nSYSTEM=OS2\n!else\nSYSTEM=Unknown\n!endif\n!endif\n\n!define $(SYSTEM)\n\n!ifdef DOS4GW\nSYSFLAG=-DDOS4GW -bt=dos\n!else ifdef MSWIN32\nSYSFLAG=-DMSWIN32 -bt=nt\nDEFS=$(DEFS) -DUSE_MUNMAP\n!else ifdef OS2\nSYSFLAG=-DOS2 -bt=os2\n!else\n!error undefined or unsupported target platform: $(SYSTEM)\n!endif\n\n!ifdef ENABLE_STATIC\nDLLFLAG=\nTEST_DLLFLAG=-DGC_NOT_DLL\nCORDFLAG=\n!else\nDLLFLAG=-bd -DGC_DLL\nTEST_DLLFLAG=-DGC_DLL\n# cord.dll and its clients should not link C library statically otherwise\n# FILE-related functions might not work (because own set of opened FILEs\n# is maintained by each copy of the C library thus making impossible to pass\n# FILE pointer from, e.g., .exe code to .dll one).\nCORDFLAG=-br\n!endif\n\nCC=wcc386\nCXX=wpp386\n\nCFLAGS=-$(CPU)$(CALLING) $(OPTIM) -iinclude -zp4 -zc $(SYSFLAG) $(DLLFLAG) $(DEFS) $(CFLAGS_EXTRA)\nCXXFLAGS= $(CFLAGS) -xs\nTEST_CFLAGS=-$(CPU)$(CALLING) $(OPTIM) -iinclude -zp4 -zc $(SYSFLAG) $(TEST_DLLFLAG) $(DEFS) $(CFLAGS_EXTRA)\nTEST_CXXFLAGS= $(TEST_CFLAGS) -xs\n\nCOBJS= cordbscs.obj cordprnt.obj cordxtra.obj\n\nall: gc.lib gccpp.lib gctba.lib cord.lib\n\n!ifdef MSWIN32\ncheck-deps-mswin: de.exe .SYMBOLIC\n!else\ncheck-deps-mswin: .SYMBOLIC\n!endif\n\ncheck-deps: gctest.exe cpptest.exe treetest.exe cordtest.exe check-deps-mswin .SYMBOLIC\n\ncheck: check-deps .SYMBOLIC\n        *gctest.exe\n        *cpptest.exe\n        *treetest.exe\n        *cordtest.exe\n\n!ifdef ENABLE_STATIC\n\nOBJS= allchblk.obj alloc.obj backgraph.obj blacklst.obj checksums.obj &\n      dbg_mlc.obj dyn_load.obj finalize.obj fnlz_mlc.obj gcj_mlc.obj &\n      headers.obj mach_dep.obj malloc.obj mallocx.obj mark.obj mark_rts.obj &\n      misc.obj new_hblk.obj obj_map.obj os_dep.obj ptr_chck.obj reclaim.obj &\n      typd_mlc.obj\n\ngc.lib: $(OBJS)\n        @%create $*.lb1\n        @for %i in ($(OBJS)) do @%append $*.lb1 +%i\n        *wlib -b -c -n -p=512 $@ @$*.lb1\n\ncord.lib: $(COBJS)\n        @%create $*.lb1\n        @for %i in ($(COBJS)) do @%append $*.lb1 +%i\n        *wlib -b -c -n -p=512 $@ @$*.lb1\n\ngccpp.lib: gc_badalc.obj gc_cpp.obj\n        @%create $*.lb1\n        @%append $*.lb1 +gc_badalc.obj\n        @%append $*.lb1 +gc_cpp.obj\n        *wlib -b -c -n -p=512 $@ @$*.lb1\n\n# The same as gccpp.lib but contains only gc_badalc.obj.\ngctba.lib: gc_badalc.obj\n        @%create $*.lb1\n        @%append $*.lb1 +gc_badalc.obj\n        *wlib -b -c -n -p=512 $@ @$*.lb1\n\n!else\n\ngc.obj: extra\\gc.c .AUTODEPEND\n        $(CC) $(CFLAGS) extra\\gc.c\n\ngc.lib: gc.dll\n        *wlib -b -c -n -p=512 $@ +gc.dll\n\ngc.dll: gc.obj .AUTODEPEND\n        @%create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys os2v2_dll\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt_dll\n!else ifdef OS2\n        @%append $*.lnk sys os2v2_dll\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk name $*\n        @%append $*.lnk file gc.obj\n        *wlink @$*.lnk\n\ncord.lib: cord.dll\n        *wlib -b -c -n -p=512 $@ +cord.dll\n\ncord.dll: $(COBJS) gc.lib .AUTODEPEND\n        @%create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys os2v2_dll\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt_dll\n!else ifdef OS2\n        @%append $*.lnk sys os2v2_dll\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk name $*\n        @for %i in ($(COBJS)) do @%append $*.lnk file %i\n        @%append $*.lnk library gc.lib\n        *wlink @$*.lnk\n\ngccpp.lib: gccpp.dll\n        *wlib -b -c -n -p=512 $@ +gccpp.dll\n\ngccpp.dll: gc_badalc.obj gc_cpp.obj gc.lib .AUTODEPEND\n        @%create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys os2v2_dll\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt_dll\n!else ifdef OS2\n        @%append $*.lnk sys os2v2_dll\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk name $*\n        @%append $*.lnk file gc_badalc.obj\n        @%append $*.lnk file gc_cpp.obj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library wr7$(CALLING)dll.lib\n        *wlink @$*.lnk\n\ngctba.lib: gctba.dll\n        *wlib -b -c -n -p=512 $@ +gctba.dll\n\ngctba.dll: gc_badalc.obj gc.lib .AUTODEPEND\n        @%create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys os2v2_dll\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt_dll\n!else ifdef OS2\n        @%append $*.lnk sys os2v2_dll\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk name $*\n        @%append $*.lnk file gc_badalc.obj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library wr7$(CALLING)dll.lib\n        *wlink @$*.lnk\n\n!endif\n\ngctest.exe: gctest.obj gc.lib\n        %create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys dos4g\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt\n!else ifdef OS2\n        @%append $*.lnk sys os2v2\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk op stack=256K\n        @%append $*.lnk name $*\n        @%append $*.lnk file gctest.obj\n        @%append $*.lnk library gc.lib\n        *wlink @$*.lnk\n\ncordtest.exe: cordtest.obj gc.lib cord.lib\n        %create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys dos4g\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt\n!else ifdef OS2\n        @%append $*.lnk sys os2v2\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk op stack=256K\n        @%append $*.lnk name $*\n        @%append $*.lnk file cordtest.obj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library cord.lib\n        *wlink @$*.lnk\n\n!ifdef MSWIN32\nde.exe: de.obj de_win.obj de_win.rbj gc.lib cord.lib\n        %create $*.lnk\n        @%append $*.lnk sys nt\n        @%append $*.lnk op case\n        @%append $*.lnk op stack=256K\n        @%append $*.lnk name $*\n        @%append $*.lnk file de.obj\n        @%append $*.lnk file de_win.obj\n        @%append $*.lnk resource de_win.rbj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library cord.lib\n        @%append $*.lnk library gdi32.lib\n        *wlink @$*.lnk\n\nde.obj: cord\\tests\\de.c .AUTODEPEND\n        $(CC) $(TEST_CFLAGS) $(CORDFLAG) cord\\tests\\de.c\nde_win.obj: cord\\tests\\de_win.c .AUTODEPEND\n        $(CC) $(TEST_CFLAGS) $(CORDFLAG) cord\\tests\\de_win.c\n\nde_win.res: cord\\tests\\de_win.rc cord\\tests\\de_win.h cord\\tests\\de_cmds.h\n        rc -fo $@ cord\\tests\\de_win.rc\nde_win.rbj: de_win.res\n        cvtres -out:$@ de_win.res\n!endif\n\ncpptest.exe: cpptest.obj gc.lib gccpp.lib\n        %create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys dos4g\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt\n!else ifdef OS2\n        @%append $*.lnk sys os2v2\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk op stack=256K\n        @%append $*.lnk name $*\n        @%append $*.lnk file cpptest.obj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library gccpp.lib\n        *wlink @$*.lnk\n\ntreetest.exe: treetest.obj gc.lib gctba.lib\n        %create $*.lnk\n!ifdef DOS4GW\n        @%append $*.lnk sys dos4g\n!else ifdef MSWIN32\n        @%append $*.lnk sys nt\n!else ifdef OS2\n        @%append $*.lnk sys os2v2\n!endif\n        @%append $*.lnk op case\n        @%append $*.lnk op stack=256K\n        @%append $*.lnk name $*\n        @%append $*.lnk file treetest.obj\n        @%append $*.lnk library gc.lib\n        @%append $*.lnk library gctba.lib\n        *wlink @$*.lnk\n\ncordbscs.obj: cord\\cordbscs.c .AUTODEPEND\n        $(CC) $(CFLAGS) $(CORDFLAG) cord\\cordbscs.c\ncordxtra.obj: cord\\cordxtra.c .AUTODEPEND\n        $(CC) $(CFLAGS) $(CORDFLAG) cord\\cordxtra.c\ncordprnt.obj: cord\\cordprnt.c .AUTODEPEND\n        $(CC) $(CFLAGS) $(CORDFLAG) cord\\cordprnt.c\n\ngc_badalc.obj: gc_badalc.cc .AUTODEPEND\n        $(CXX) $(TEST_CXXFLAGS) $*.cc\ngc_cpp.obj: gc_cpp.cc .AUTODEPEND\n        $(CXX) $(TEST_CXXFLAGS) $*.cc\n\ngctest.obj: tests\\gctest.c .AUTODEPEND\n        $(CC) $(TEST_CFLAGS) /wcd=201 tests\\gctest.c\ncordtest.obj: cord\\tests\\cordtest.c .AUTODEPEND\n        $(CC) $(TEST_CFLAGS) $(CORDFLAG) cord\\tests\\cordtest.c\ncpptest.obj: tests\\cpp.cc .AUTODEPEND\n        $(CXX) $(TEST_CXXFLAGS) -fo=cpptest.obj tests\\cpp.cc\ntreetest.obj: tests\\tree.cc .AUTODEPEND\n        $(CXX) $(TEST_CXXFLAGS) -fo=treetest.obj tests\\tree.cc\n\n.c.obj: .AUTODEPEND\n        $(CC) $(CFLAGS) $*.c\n\n.cc.obj: .AUTODEPEND\n        $(CXX) $(CXXFLAGS) $*.cc\n\nclean: .SYMBOLIC\n        @if exist *.dll del *.dll\n        @if exist *.err del *.err\n        @if exist *.exe del *.exe\n        @if exist *.lb1 del *.lb1\n        @if exist *.lib del *.lib\n        @if exist *.lnk del *.lnk\n        @if exist *.log del *.log\n        @if exist *.lst del *.lst\n        @if exist *.map del *.map\n        @if exist *.obj del *.obj\n        @if exist *.rbj del *.rbj\n        @if exist *.res del *.res\n        @if exist *.sym del *.sym\n        @if exist *.tmp del *.tmp\n"
        },
        {
          "name": "allchblk.c",
          "type": "blob",
          "size": 37.1015625,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1998-1999 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1999 by Hewlett-Packard Company. All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#ifdef GC_USE_ENTIRE_HEAP\nint GC_use_entire_heap = TRUE;\n#else\nint GC_use_entire_heap = FALSE;\n#endif\n\n/* Free heap blocks are kept on one of several free lists, depending on */\n/* the size of the block.  Each free list is doubly linked.  Adjacent   */\n/* free blocks are coalesced.                                           */\n\n/* Largest block we will allocate starting on a black listed block.     */\n/* Must be >= HBLKSIZE.                                                 */\n#define MAX_BLACK_LIST_ALLOC (2 * HBLKSIZE)\n\n/* Sizes up to this many HBLKs each have their own free list.           */\n#define UNIQUE_THRESHOLD 32\n\n/* Sizes of at least this many heap blocks are mapped to a single free  */\n/* list.                                                                */\n#define HUGE_THRESHOLD 256\n\n/* In between sizes map this many distinct sizes to a single bin.       */\n#define FL_COMPRESSION 8\n\n#define N_HBLK_FLS \\\n  ((HUGE_THRESHOLD - UNIQUE_THRESHOLD) / FL_COMPRESSION + UNIQUE_THRESHOLD)\n\n/* List of completely empty heap blocks.  Linked through hb_next field  */\n/* of header structure associated with block.  Remains externally       */\n/* visible as used by GNU GCJ currently.                                */\n#ifndef GC_GCJ_SUPPORT\nSTATIC\n#endif\nstruct hblk *GC_hblkfreelist[N_HBLK_FLS + 1] = { 0 };\n\nGC_API void GC_CALL\nGC_iterate_free_hblks(GC_walk_free_blk_fn fn, void *client_data)\n{\n  int i;\n\n  for (i = 0; i <= N_HBLK_FLS; ++i) {\n    struct hblk *h;\n\n    for (h = GC_hblkfreelist[i]; h != NULL; h = HDR(h)->hb_next) {\n      fn(h, i, client_data);\n    }\n  }\n}\n\n/* Number of free bytes on each list.  Remains visible to GCJ.          */\n#ifndef GC_GCJ_SUPPORT\nSTATIC\n#endif\nword GC_free_bytes[N_HBLK_FLS + 1] = { 0 };\n\n/* Return the largest n such that the number of free bytes on lists     */\n/* n .. N_HBLK_FLS is greater or equal to GC_max_large_allocd_bytes     */\n/* minus GC_large_allocd_bytes.  If there is no such n, return 0.       */\nGC_INLINE size_t\nGC_enough_large_bytes_left(void)\n{\n  size_t n;\n  word bytes = GC_large_allocd_bytes;\n\n  GC_ASSERT(GC_max_large_allocd_bytes <= GC_heapsize);\n  for (n = N_HBLK_FLS + 1; n > 0;) {\n    n--;\n    bytes += GC_free_bytes[n];\n    if (bytes >= GC_max_large_allocd_bytes)\n      break;\n  }\n  return n;\n}\n\n/* Map a number of blocks to the appropriate large block free-list index. */\nSTATIC size_t\nGC_hblk_fl_from_blocks(size_t blocks_needed)\n{\n  if (blocks_needed <= UNIQUE_THRESHOLD)\n    return blocks_needed;\n  if (blocks_needed >= HUGE_THRESHOLD)\n    return N_HBLK_FLS;\n  return (blocks_needed - UNIQUE_THRESHOLD) / FL_COMPRESSION\n         + UNIQUE_THRESHOLD;\n}\n\n#define PHDR(hhdr) HDR((hhdr)->hb_prev)\n#define NHDR(hhdr) HDR((hhdr)->hb_next)\n\n#ifdef USE_MUNMAP\n#  define IS_MAPPED(hhdr) (((hhdr)->hb_flags & WAS_UNMAPPED) == 0)\n#else\n#  define IS_MAPPED(hhdr) TRUE\n#endif /* !USE_MUNMAP */\n\n#if !defined(NO_DEBUGGING) || defined(GC_ASSERTIONS)\nstatic void GC_CALLBACK\nadd_hb_sz(struct hblk *h, int i, void *total_free_ptr)\n{\n  UNUSED_ARG(i);\n  *(word *)total_free_ptr += HDR(h)->hb_sz;\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(h);\n#  endif\n}\n\n/* Should return the same value as GC_large_free_bytes.       */\nGC_INNER word\nGC_compute_large_free_bytes(void)\n{\n  word total_free = 0;\n\n  GC_iterate_free_hblks(add_hb_sz, &total_free);\n  return total_free;\n}\n#endif /* !NO_DEBUGGING || GC_ASSERTIONS */\n\n#if !defined(NO_DEBUGGING)\nstatic void GC_CALLBACK\nprint_hblkfreelist_item(struct hblk *h, int i, void *prev_index_ptr)\n{\n  hdr *hhdr = HDR(h);\n\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(h);\n#  endif\n  if (i != *(int *)prev_index_ptr) {\n    GC_printf(\"Free list %d (total size %lu):\\n\", i,\n              (unsigned long)GC_free_bytes[i]);\n    *(int *)prev_index_ptr = i;\n  }\n\n  GC_printf(\"\\t%p size %lu %s black listed\\n\", (void *)h,\n            (unsigned long)hhdr->hb_sz,\n            GC_is_black_listed(h, HBLKSIZE) != NULL      ? \"start\"\n            : GC_is_black_listed(h, hhdr->hb_sz) != NULL ? \"partially\"\n                                                         : \"not\");\n}\n\nvoid\nGC_print_hblkfreelist(void)\n{\n  word total;\n  int prev_index = -1;\n\n  GC_iterate_free_hblks(print_hblkfreelist_item, &prev_index);\n  GC_printf(\"GC_large_free_bytes: %lu\\n\", (unsigned long)GC_large_free_bytes);\n  total = GC_compute_large_free_bytes();\n  if (total != GC_large_free_bytes)\n    GC_err_printf(\"GC_large_free_bytes INCONSISTENT!! Should be: %lu\\n\",\n                  (unsigned long)total);\n}\n\n/* Return the free-list index on which the block described by the header */\n/* appears, or -1 if it appears nowhere.                                 */\nstatic int\nfree_list_index_of(const hdr *wanted)\n{\n  int i;\n\n  for (i = 0; i <= N_HBLK_FLS; ++i) {\n    const struct hblk *h;\n    const hdr *hhdr;\n\n    for (h = GC_hblkfreelist[i]; h != NULL; h = hhdr->hb_next) {\n      hhdr = HDR(h);\n      if (hhdr == wanted)\n        return i;\n    }\n  }\n  return -1;\n}\n\nGC_API void GC_CALL\nGC_dump_regions(void)\n{\n  size_t i;\n\n  for (i = 0; i < GC_n_heap_sects; ++i) {\n    ptr_t start = GC_heap_sects[i].hs_start;\n    size_t bytes = GC_heap_sects[i].hs_bytes;\n    ptr_t finish = start + bytes;\n    ptr_t p;\n\n    /* Merge in contiguous sections.        */\n    while (i + 1 < GC_n_heap_sects\n           && GC_heap_sects[i + 1].hs_start == finish) {\n      ++i;\n      finish = GC_heap_sects[i].hs_start + GC_heap_sects[i].hs_bytes;\n    }\n    GC_printf(\"***Section from %p to %p\\n\", (void *)start, (void *)finish);\n    for (p = start; ADDR_LT(p, finish);) {\n      hdr *hhdr = HDR(p);\n\n      if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n        GC_printf(\"\\t%p Missing header!!(%p)\\n\", (void *)p, (void *)hhdr);\n        p += HBLKSIZE;\n        continue;\n      }\n      if (HBLK_IS_FREE(hhdr)) {\n        int correct_index\n            = (int)GC_hblk_fl_from_blocks(divHBLKSZ(hhdr->hb_sz));\n        int actual_index;\n\n        GC_printf(\"\\t%p\\tfree block of size 0x%lx bytes%s\\n\", (void *)p,\n                  (unsigned long)hhdr->hb_sz,\n                  IS_MAPPED(hhdr) ? \"\" : \" (unmapped)\");\n        actual_index = free_list_index_of(hhdr);\n        if (-1 == actual_index) {\n          GC_printf(\"\\t\\tBlock not on free list %d!!\\n\", correct_index);\n        } else if (correct_index != actual_index) {\n          GC_printf(\"\\t\\tBlock on list %d, should be on %d!!\\n\", actual_index,\n                    correct_index);\n        }\n        p += hhdr->hb_sz;\n      } else {\n        GC_printf(\"\\t%p\\tused for blocks of size 0x%lx bytes\\n\", (void *)p,\n                  (unsigned long)hhdr->hb_sz);\n        p += HBLKSIZE * OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n      }\n    }\n  }\n}\n#endif /* NO_DEBUGGING */\n\n/* Initialize hdr for a block containing the indicated size and         */\n/* kind of objects.  Return FALSE on failure.                           */\nstatic GC_bool\nsetup_header(hdr *hhdr, struct hblk *block, size_t lb_adjusted, int k,\n             unsigned flags)\n{\n  const struct obj_kind *ok;\n  word descr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(lb_adjusted >= ALIGNMENT);\n#ifndef MARK_BIT_PER_OBJ\n  if (lb_adjusted > MAXOBJBYTES)\n    flags |= LARGE_BLOCK;\n#endif\n  ok = &GC_obj_kinds[k];\n#ifdef ENABLE_DISCLAIM\n  if (ok->ok_disclaim_proc)\n    flags |= HAS_DISCLAIM;\n  if (ok->ok_mark_unconditionally)\n    flags |= MARK_UNCONDITIONALLY;\n#endif\n\n  /* Set size, kind and mark proc fields.     */\n  hhdr->hb_sz = lb_adjusted;\n  hhdr->hb_obj_kind = (unsigned char)k;\n  hhdr->hb_flags = (unsigned char)flags;\n  hhdr->hb_block = block;\n  descr = ok->ok_descriptor;\n#if ALIGNMENT > GC_DS_TAGS\n  /* An extra byte is not added in case of ignore-off-page  */\n  /* allocated objects not smaller than HBLKSIZE.           */\n  if (EXTRA_BYTES != 0 && (flags & IGNORE_OFF_PAGE) != 0 && k == NORMAL\n      && lb_adjusted >= HBLKSIZE)\n    descr += ALIGNMENT; /* or set to 0 */\n#endif\n  if (ok->ok_relocate_descr)\n    descr += lb_adjusted;\n  hhdr->hb_descr = descr;\n\n#ifdef MARK_BIT_PER_OBJ\n  /* Set hb_inv_sz as portably as possible.  We set it to the       */\n  /* smallest value such that lb_adjusted * inv_sz >= 2**32.        */\n  /* This may be more precision than necessary.                     */\n  if (lb_adjusted > MAXOBJBYTES) {\n    hhdr->hb_inv_sz = LARGE_INV_SZ;\n  } else {\n    unsigned32 inv_sz;\n\n    GC_ASSERT(lb_adjusted > 1);\n#  if CPP_WORDSZ > 32\n    inv_sz = (unsigned32)(((word)1 << 32) / lb_adjusted);\n    if (((inv_sz * (word)lb_adjusted) >> 32) == 0)\n      ++inv_sz;\n#  else\n    inv_sz = (((unsigned32)1 << 31) / lb_adjusted) << 1;\n    while ((inv_sz * lb_adjusted) > lb_adjusted)\n      inv_sz++;\n#  endif\n#  if (CPP_WORDSZ == 32) && defined(__GNUC__)\n    GC_ASSERT(((1ULL << 32) + lb_adjusted - 1) / lb_adjusted == inv_sz);\n#  endif\n    hhdr->hb_inv_sz = inv_sz;\n  }\n#else\n  {\n    size_t lg = BYTES_TO_GRANULES(lb_adjusted);\n\n    if (EXPECT(!GC_add_map_entry(lg), FALSE)) {\n      /* Make it look like a valid block.   */\n      hhdr->hb_sz = HBLKSIZE;\n      hhdr->hb_descr = 0;\n      hhdr->hb_flags |= LARGE_BLOCK;\n      hhdr->hb_map = NULL;\n      return FALSE;\n    }\n    hhdr->hb_map = GC_obj_map[(hhdr->hb_flags & LARGE_BLOCK) != 0 ? 0 : lg];\n  }\n#endif\n\n  /* Clear mark bits. */\n  GC_clear_hdr_marks(hhdr);\n\n  hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n  return TRUE;\n}\n\n/* Remove hhdr from the free list (it is assumed to specified by index). */\nSTATIC void\nGC_remove_from_fl_at(hdr *hhdr, size_t index)\n{\n  GC_ASSERT(modHBLKSZ(hhdr->hb_sz) == 0);\n  if (hhdr->hb_prev == 0) {\n    GC_ASSERT(HDR(GC_hblkfreelist[index]) == hhdr);\n    GC_hblkfreelist[index] = hhdr->hb_next;\n  } else {\n    hdr *phdr;\n    GET_HDR(hhdr->hb_prev, phdr);\n    phdr->hb_next = hhdr->hb_next;\n  }\n  /* We always need index to maintain free counts.    */\n  GC_ASSERT(GC_free_bytes[index] >= hhdr->hb_sz);\n  GC_free_bytes[index] -= hhdr->hb_sz;\n  if (hhdr->hb_next != NULL) {\n    hdr *nhdr;\n\n    GC_ASSERT(!IS_FORWARDING_ADDR_OR_NIL(NHDR(hhdr)));\n    GET_HDR(hhdr->hb_next, nhdr);\n    nhdr->hb_prev = hhdr->hb_prev;\n  }\n}\n\n/* Remove hhdr from the appropriate free list (we assume it is on the   */\n/* size-appropriate free list).                                         */\nGC_INLINE void\nGC_remove_from_fl(hdr *hhdr)\n{\n  GC_remove_from_fl_at(hhdr, GC_hblk_fl_from_blocks(divHBLKSZ(hhdr->hb_sz)));\n}\n\n/* Return a pointer to the block ending just before h, if any.  */\nstatic struct hblk *\nget_block_ending_at(struct hblk *h)\n{\n  struct hblk *p = h - 1;\n  hdr *hhdr;\n\n  GET_HDR(p, hhdr);\n  if (hhdr != NULL) {\n    return GC_find_starting_hblk(p, &hhdr);\n  }\n  p = GC_prev_block(p);\n  if (p != NULL) {\n    hhdr = HDR(p);\n    if ((ptr_t)p + hhdr->hb_sz == (ptr_t)h) {\n      return p;\n    }\n  }\n  return NULL;\n}\n\n/* Return a pointer to the free block ending just before h, if any.     */\nSTATIC struct hblk *\nGC_free_block_ending_at(struct hblk *h)\n{\n  struct hblk *p = get_block_ending_at(h);\n\n  if (p /* != NULL */) { /* CPPCHECK */\n    const hdr *hhdr = HDR(p);\n\n    if (HBLK_IS_FREE(hhdr)) {\n      return p;\n    }\n  }\n  return 0;\n}\n\n/* Add hhdr to the appropriate free list.               */\n/* We maintain individual free lists sorted by address. */\nSTATIC void\nGC_add_to_fl(struct hblk *h, hdr *hhdr)\n{\n  size_t index = GC_hblk_fl_from_blocks(divHBLKSZ(hhdr->hb_sz));\n  struct hblk *second = GC_hblkfreelist[index];\n\n#if defined(GC_ASSERTIONS) && !defined(USE_MUNMAP)\n  {\n    struct hblk *next = (struct hblk *)((ptr_t)h + hhdr->hb_sz);\n    const hdr *nexthdr = HDR(next);\n    struct hblk *prev = GC_free_block_ending_at(h);\n    const hdr *prevhdr = HDR(prev);\n\n    GC_ASSERT(NULL == nexthdr || !HBLK_IS_FREE(nexthdr)\n              || (GC_heapsize & SIGNB) != 0);\n    /* In the last case, blocks may be too large to be merged.    */\n    GC_ASSERT(NULL == prev || !HBLK_IS_FREE(prevhdr)\n              || (GC_heapsize & SIGNB) != 0);\n  }\n#endif\n  GC_ASSERT(modHBLKSZ(hhdr->hb_sz) == 0);\n  GC_hblkfreelist[index] = h;\n  GC_free_bytes[index] += hhdr->hb_sz;\n  GC_ASSERT(GC_free_bytes[index] <= GC_large_free_bytes);\n  hhdr->hb_next = second;\n  hhdr->hb_prev = NULL;\n  if (second /* != NULL */) { /* CPPCHECK */\n    hdr *second_hdr;\n\n    GET_HDR(second, second_hdr);\n    second_hdr->hb_prev = h;\n  }\n  hhdr->hb_flags |= FREE_BLK;\n}\n\n#define BLOCKS_MERGE_OVERFLOW(hhdr, nexthdr) \\\n  ((((hhdr)->hb_sz + (nexthdr)->hb_sz) & SIZET_SIGNB) != 0)\n\n#ifdef USE_MUNMAP\n\n#  ifdef COUNT_UNMAPPED_REGIONS\n/* GC_unmap_old will avoid creating more than this many unmapped regions, */\n/* but an unmapped region may be split again so exceeding the limit.      */\n\n/* Return the change in number of unmapped regions if the block h swaps   */\n/* from its current state of mapped/unmapped to the opposite state.       */\nstatic int\ncalc_num_unmapped_regions_delta(struct hblk *h, hdr *hhdr)\n{\n  struct hblk *prev = get_block_ending_at(h);\n  struct hblk *next;\n  GC_bool prev_unmapped = FALSE;\n  GC_bool next_unmapped = FALSE;\n\n  next = GC_next_block((struct hblk *)((ptr_t)h + hhdr->hb_sz), TRUE);\n  /* Ensure next is contiguous with h.        */\n  if (next != HBLK_PAGE_ALIGNED((ptr_t)h + hhdr->hb_sz)) {\n    next = NULL;\n  }\n  if (prev != NULL) {\n    const hdr *prevhdr = HDR(prev);\n    prev_unmapped = !IS_MAPPED(prevhdr);\n  }\n  if (next != NULL) {\n    const hdr *nexthdr = HDR(next);\n    next_unmapped = !IS_MAPPED(nexthdr);\n  }\n\n  if (prev_unmapped && next_unmapped) {\n    /* If h unmapped, merge two unmapped regions into one.    */\n    /* If h remapped, split one unmapped region into two.     */\n    return IS_MAPPED(hhdr) ? -1 : 1;\n  }\n  if (!prev_unmapped && !next_unmapped) {\n    /* If h unmapped, create an isolated unmapped region.     */\n    /* If h remapped, remove it.                              */\n    return IS_MAPPED(hhdr) ? 1 : -1;\n  }\n  /* If h unmapped, merge it with previous or next unmapped region.   */\n  /* If h remapped, reduce either previous or next unmapped region.   */\n  /* In either way, no change to the number of unmapped regions.      */\n  return 0;\n}\n#  endif /* COUNT_UNMAPPED_REGIONS */\n\n/* Update GC_num_unmapped_regions assuming the block h changes      */\n/* from its current state of mapped/unmapped to the opposite state. */\nGC_INLINE void\nGC_adjust_num_unmapped(struct hblk *h, hdr *hhdr)\n{\n#  ifdef COUNT_UNMAPPED_REGIONS\n  GC_num_unmapped_regions += calc_num_unmapped_regions_delta(h, hhdr);\n#  else\n  UNUSED_ARG(h);\n  UNUSED_ARG(hhdr);\n#  endif\n}\n\n/* Unmap blocks that haven't been recently touched.  This is the only   */\n/* way blocks are ever unmapped.                                        */\nGC_INNER void\nGC_unmap_old(unsigned threshold)\n{\n  size_t i;\n\n#  ifdef COUNT_UNMAPPED_REGIONS\n  /* Skip unmapping if we have already exceeded the soft limit.       */\n  /* This forgoes any opportunities to merge unmapped regions though. */\n  if (GC_num_unmapped_regions >= GC_UNMAPPED_REGIONS_SOFT_LIMIT)\n    return;\n#  endif\n\n  for (i = 0; i <= N_HBLK_FLS; ++i) {\n    struct hblk *h;\n    hdr *hhdr;\n\n    for (h = GC_hblkfreelist[i]; h != NULL; h = hhdr->hb_next) {\n      hhdr = HDR(h);\n      if (!IS_MAPPED(hhdr))\n        continue;\n\n      /* Check that the interval is not smaller than the threshold.   */\n      /* The truncated counter value wrapping is handled correctly.   */\n      if ((unsigned short)(GC_gc_no - hhdr->hb_last_reclaimed)\n          >= (unsigned short)threshold) {\n#  ifdef COUNT_UNMAPPED_REGIONS\n        /* Continue with unmapping the block only if it will not    */\n        /* create too many unmapped regions, or if unmapping        */\n        /* reduces the number of regions.                           */\n        int delta = calc_num_unmapped_regions_delta(h, hhdr);\n        GC_signed_word regions = GC_num_unmapped_regions + delta;\n\n        if (delta >= 0 && regions >= GC_UNMAPPED_REGIONS_SOFT_LIMIT) {\n          GC_COND_LOG_PRINTF(\"Unmapped regions limit reached!\\n\");\n          return;\n        }\n        GC_num_unmapped_regions = regions;\n#  endif\n        GC_unmap((ptr_t)h, hhdr->hb_sz);\n        hhdr->hb_flags |= WAS_UNMAPPED;\n      }\n    }\n  }\n}\n\n/* Merge all unmapped blocks that are adjacent to other free            */\n/* blocks.  This may involve remapping, since all blocks are either     */\n/* fully mapped or fully unmapped.                                      */\nGC_INNER void\nGC_merge_unmapped(void)\n{\n  size_t i;\n\n  for (i = 0; i <= N_HBLK_FLS; ++i) {\n    struct hblk *h = GC_hblkfreelist[i];\n\n    while (h != NULL) {\n      struct hblk *next;\n      hdr *hhdr, *nexthdr;\n      size_t size, next_size;\n\n      GET_HDR(h, hhdr);\n      size = hhdr->hb_sz;\n      next = (struct hblk *)((ptr_t)h + size);\n      GET_HDR(next, nexthdr);\n      /* Coalesce with successor, if possible. */\n      if (NULL == nexthdr || !HBLK_IS_FREE(nexthdr)\n          || BLOCKS_MERGE_OVERFLOW(hhdr, nexthdr)) {\n        /* Not mergeable with the successor. */\n        h = hhdr->hb_next;\n        continue;\n      }\n\n      next_size = nexthdr->hb_sz;\n#  ifdef CHERI_PURECAP\n      /* FIXME: Coalesce with super-capability. */\n      if (!CAPABILITY_COVERS_RANGE(h, ADDR(next), ADDR(next) + nextsize)) {\n        h = hhdr->hb_next;\n        continue;\n      }\n#  endif\n\n      /* Note that we usually try to avoid adjacent free blocks     */\n      /* that are either both mapped or both unmapped.  But that    */\n      /* isn't guaranteed to hold since we remap blocks when we     */\n      /* split them, and don't merge at that point.  It may also    */\n      /* not hold if the merged block would be too big.             */\n      if (IS_MAPPED(hhdr) && !IS_MAPPED(nexthdr)) {\n        /* Make both consistent, so that we can merge. */\n        if (size > next_size) {\n          GC_adjust_num_unmapped(next, nexthdr);\n          GC_remap((ptr_t)next, next_size);\n        } else {\n          GC_adjust_num_unmapped(h, hhdr);\n          GC_unmap((ptr_t)h, size);\n          GC_unmap_gap((ptr_t)h, size, (ptr_t)next, next_size);\n          hhdr->hb_flags |= WAS_UNMAPPED;\n        }\n      } else if (IS_MAPPED(nexthdr) && !IS_MAPPED(hhdr)) {\n        if (size > next_size) {\n          GC_adjust_num_unmapped(next, nexthdr);\n          GC_unmap((ptr_t)next, next_size);\n          GC_unmap_gap((ptr_t)h, size, (ptr_t)next, next_size);\n        } else {\n          GC_adjust_num_unmapped(h, hhdr);\n          GC_remap((ptr_t)h, size);\n          hhdr->hb_flags &= (unsigned char)~WAS_UNMAPPED;\n          hhdr->hb_last_reclaimed = nexthdr->hb_last_reclaimed;\n        }\n      } else if (!IS_MAPPED(hhdr) && !IS_MAPPED(nexthdr)) {\n        /* Unmap any gap in the middle.   */\n        GC_unmap_gap((ptr_t)h, size, (ptr_t)next, next_size);\n      }\n      /* If they are both unmapped, we merge, but leave unmapped. */\n      GC_remove_from_fl_at(hhdr, i);\n      GC_remove_from_fl(nexthdr);\n      hhdr->hb_sz += nexthdr->hb_sz;\n      GC_remove_header(next);\n      GC_add_to_fl(h, hhdr);\n      /* Start over at the beginning of list. */\n      h = GC_hblkfreelist[i];\n    }\n  }\n}\n\n#endif /* USE_MUNMAP */\n\n/* Return a pointer to a block starting at h of length bytes.  Memory   */\n/* for the block is mapped.  Remove the block from its free list, and   */\n/* return the remainder (if any) to its appropriate free list.          */\n/* May fail by returning 0.  The header for the returned block must     */\n/* be set up by the caller.  If the return value is not 0, then hhdr is */\n/* the header for it.                                                   */\nSTATIC struct hblk *\nGC_get_first_part(struct hblk *h, hdr *hhdr, size_t size_needed, size_t index)\n{\n  size_t total_size;\n  struct hblk *rest;\n  hdr *rest_hdr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(modHBLKSZ(size_needed) == 0);\n  total_size = hhdr->hb_sz;\n  GC_ASSERT(modHBLKSZ(total_size) == 0);\n  GC_remove_from_fl_at(hhdr, index);\n  if (total_size == size_needed)\n    return h;\n\n  rest = (struct hblk *)((ptr_t)h + size_needed);\n  rest_hdr = GC_install_header(rest);\n  if (EXPECT(NULL == rest_hdr, FALSE)) {\n    /* FIXME: This is likely to be very bad news ... */\n    WARN(\"Header allocation failed: dropping block\\n\", 0);\n    return NULL;\n  }\n  rest_hdr->hb_block = rest;\n  rest_hdr->hb_sz = total_size - size_needed;\n  rest_hdr->hb_flags = 0;\n#ifdef GC_ASSERTIONS\n  /* Mark h not free, to avoid assertion about adjacent free blocks. */\n  hhdr->hb_flags &= (unsigned char)~FREE_BLK;\n#endif\n  GC_add_to_fl(rest, rest_hdr);\n  return h;\n}\n\n/* Split the block.  hbp is a free block; last_hbp points at an address */\n/* inside it; a new header for last_hbp is assumed to be already set    */\n/* up.  Fix up the header of hbp to reflect the fact that it is being   */\n/* split, move it to the appropriate free list.  last_hbp replaces hbp  */\n/* in the original free list.  last_hdr is not completely filled in,    */\n/* since it is about to be allocated.  It may in fact end up on the     */\n/* wrong free list for its size.  That is not a disaster, since         */\n/* last_hbp is to be allocated by our caller.  (Hence adding it to      */\n/* a free list is silly.  But this path is hopefully rare enough that   */\n/* it does not matter.  The code is cleaner this way.)                  */\nSTATIC void\nGC_split_block(struct hblk *hbp, hdr *hhdr, struct hblk *last_hbp,\n               hdr *last_hdr, size_t index /* of free list */)\n{\n  size_t h_size = (size_t)((ptr_t)last_hbp - (ptr_t)hbp);\n  struct hblk *prev = hhdr->hb_prev;\n  struct hblk *next = hhdr->hb_next;\n\n  /* Replace hbp with last_hbp on its free list.  */\n  last_hdr->hb_prev = prev;\n  last_hdr->hb_next = next;\n  last_hdr->hb_sz = hhdr->hb_sz - h_size;\n  last_hdr->hb_flags = 0;\n  if (prev /* != NULL */) { /* CPPCHECK */\n    HDR(prev)->hb_next = last_hbp;\n  } else {\n    GC_hblkfreelist[index] = last_hbp;\n  }\n  if (next /* != NULL */) {\n    HDR(next)->hb_prev = last_hbp;\n  }\n  GC_ASSERT(GC_free_bytes[index] > h_size);\n  GC_free_bytes[index] -= h_size;\n#ifdef USE_MUNMAP\n  hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n#endif\n  hhdr->hb_sz = h_size;\n  GC_add_to_fl(hbp, hhdr);\n  last_hdr->hb_flags |= FREE_BLK;\n}\n\nSTATIC struct hblk *GC_allochblk_nth(size_t lb_adjusted, int k, unsigned flags,\n                                     size_t index, int may_split,\n                                     size_t align_m1);\n\n#ifdef USE_MUNMAP\n#  define AVOID_SPLIT_REMAPPED 2\n#endif\n\nGC_INNER struct hblk *\nGC_allochblk(size_t lb_adjusted, int k,\n             unsigned flags /* IGNORE_OFF_PAGE or 0 */, size_t align_m1)\n{\n  size_t blocks, start_list;\n  struct hblk *result;\n  int may_split;\n  size_t split_limit; /* highest index of free list whose blocks we split */\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT((lb_adjusted & (GC_GRANULE_BYTES - 1)) == 0);\n  blocks = OBJ_SZ_TO_BLOCKS_CHECKED(lb_adjusted);\n  if (EXPECT(SIZET_SAT_ADD(blocks * HBLKSIZE, align_m1) >= (GC_SIZE_MAX >> 1),\n             FALSE))\n    return NULL; /* overflow */\n\n  start_list = GC_hblk_fl_from_blocks(blocks);\n  /* Try for an exact match first.    */\n  result\n      = GC_allochblk_nth(lb_adjusted, k, flags, start_list, FALSE, align_m1);\n  if (result != NULL)\n    return result;\n\n  may_split = TRUE;\n  if (GC_use_entire_heap || GC_dont_gc\n      || GC_heapsize - GC_large_free_bytes < GC_requested_heapsize\n      || GC_incremental || !GC_should_collect()) {\n    /* Should use more of the heap, even if it requires splitting. */\n    split_limit = N_HBLK_FLS;\n  } else if (GC_finalizer_bytes_freed > (GC_heapsize >> 4)) {\n    /* If we are deallocating lots of memory from finalizers,     */\n    /* fail and collect sooner rather than later.                 */\n    split_limit = 0;\n  } else {\n    /* If we have enough large blocks left to cover any   */\n    /* previous request for large blocks, we go ahead     */\n    /* and split.  Assuming a steady state, that should   */\n    /* be safe.  It means that we can use the full        */\n    /* heap if we allocate only small objects.            */\n    split_limit = GC_enough_large_bytes_left();\n#ifdef USE_MUNMAP\n    if (split_limit > 0)\n      may_split = AVOID_SPLIT_REMAPPED;\n#endif\n  }\n  if (start_list < UNIQUE_THRESHOLD && 0 == align_m1) {\n    /* No reason to try start_list again, since all blocks are exact  */\n    /* matches.                                                       */\n    ++start_list;\n  }\n  for (; start_list <= split_limit; ++start_list) {\n    result = GC_allochblk_nth(lb_adjusted, k, flags, start_list, may_split,\n                              align_m1);\n    if (result != NULL)\n      break;\n  }\n  return result;\n}\n\n/* Number of warnings suppressed so far.        */\nSTATIC long GC_large_alloc_warn_suppressed = 0;\n\n/* Counter of the cases when found block by GC_allochblk_nth is     */\n/* blacklisted completely.                                          */\nSTATIC unsigned GC_drop_blacklisted_count = 0;\n\n#define ALIGN_PAD_SZ(p, align_m1) \\\n  (((align_m1) + 1 - (size_t)ADDR(p)) & (align_m1))\n\nstatic GC_bool\nnext_hblk_fits_better(const hdr *hhdr, size_t size_avail, size_t size_needed,\n                      size_t align_m1)\n{\n  const hdr *nexthdr;\n  size_t next_size;\n  size_t next_ofs;\n  struct hblk *next_hbp = hhdr->hb_next;\n\n  if (NULL == next_hbp)\n    return FALSE; /* no next block */\n  GET_HDR(next_hbp, nexthdr);\n  next_size = nexthdr->hb_sz;\n  if (size_avail <= next_size)\n    return FALSE; /* not enough size */\n\n  next_ofs = ALIGN_PAD_SZ(next_hbp, align_m1);\n  return next_size >= size_needed + next_ofs\n         && !GC_is_black_listed(next_hbp + divHBLKSZ(next_ofs), size_needed);\n}\n\nstatic struct hblk *\nfind_nonbl_hblk(struct hblk *last_hbp, size_t size_remain,\n                size_t eff_size_needed, size_t align_m1)\n{\n  ptr_t search_end\n      = PTR_ALIGN_DOWN((ptr_t)last_hbp + size_remain, align_m1 + 1);\n\n  do {\n    struct hblk *next_hbp;\n\n    last_hbp += divHBLKSZ(ALIGN_PAD_SZ(last_hbp, align_m1));\n    next_hbp = GC_is_black_listed(last_hbp, eff_size_needed);\n    if (NULL == next_hbp)\n      return last_hbp; /* not black-listed */\n    last_hbp = next_hbp;\n  } while (ADDR_GE(search_end, (ptr_t)last_hbp));\n  return NULL;\n}\n\n/* Allocate and drop the block in small chunks, to maximize the chance  */\n/* that we will recover some later.  hhdr should correspond to hbp.     */\nstatic void\ndrop_hblk_in_chunks(size_t n, struct hblk *hbp, hdr *hhdr)\n{\n  size_t total_size = hhdr->hb_sz;\n  const struct hblk *limit = hbp + divHBLKSZ(total_size);\n\n  GC_ASSERT(HDR(hbp) == hhdr);\n  GC_ASSERT(modHBLKSZ(total_size) == 0 && total_size > 0);\n  GC_large_free_bytes -= total_size;\n  GC_bytes_dropped += total_size;\n  GC_remove_from_fl_at(hhdr, n);\n  do {\n    (void)setup_header(hhdr, hbp, HBLKSIZE, PTRFREE, 0); /* cannot fail */\n    if (GC_debugging_started)\n      BZERO(hbp, HBLKSIZE);\n    hbp++;\n    if (ADDR_GE(hbp, limit))\n      break;\n\n    hhdr = GC_install_header(hbp);\n  } while (EXPECT(hhdr != NULL, TRUE)); /* no header allocation failure? */\n}\n\n#if defined(MPROTECT_VDB) && defined(DONT_PROTECT_PTRFREE)\nstatic GC_bool\nis_hblks_mix_in_page(struct hblk *hbp, GC_bool is_ptrfree)\n{\n  struct hblk *h = HBLK_PAGE_ALIGNED(hbp);\n  size_t i, cnt = divHBLKSZ(GC_page_size);\n\n  /* Iterate over blocks in the page to check if all the    */\n  /* occupied blocks are pointer-free if we are going to    */\n  /* allocate a pointer-free one, and vice versa.           */\n  for (i = 0; i < cnt; i++) {\n    hdr *hhdr;\n\n    GET_HDR(&h[i], hhdr);\n    if (NULL == hhdr)\n      continue;\n    (void)GC_find_starting_hblk(&h[i], &hhdr);\n    if (!HBLK_IS_FREE(hhdr)) {\n      /* It is OK to check only the first found occupied block.   */\n      return IS_PTRFREE(hhdr) != is_ptrfree;\n    }\n  }\n  return FALSE; /* all blocks are free */\n}\n#endif /* MPROTECT_VDB && DONT_PROTECT_PTRFREE */\n\n/* The same as GC_allochblk, but with search restricted to the index-th */\n/* free list.  flags should be IGNORE_OFF_PAGE or zero; may_split       */\n/* indicates whether it is OK to split larger blocks; size is in bytes. */\n/* If may_split is set to AVOID_SPLIT_REMAPPED, then memory remapping   */\n/* followed by splitting should be generally avoided.  Rounded-up       */\n/* lb_adjusted plus align_m1 value should be less than GC_SIZE_MAX / 2. */\nSTATIC struct hblk *\nGC_allochblk_nth(size_t lb_adjusted, int k, unsigned flags, size_t index,\n                 int may_split, size_t align_m1)\n{\n  struct hblk *hbp, *last_hbp;\n  /* The header corresponding to hbp. */\n  hdr *hhdr;\n  /* Number of bytes in requested objects.    */\n  size_t size_needed = (lb_adjusted + HBLKSIZE - 1) & ~(HBLKSIZE - 1);\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(((align_m1 + 1) & align_m1) == 0 && lb_adjusted > 0);\n  GC_ASSERT(0 == align_m1 || modHBLKSZ(align_m1 + 1) == 0);\nretry:\n  /* Search for a big enough block in free list.      */\n  for (hbp = GC_hblkfreelist[index];; hbp = hhdr->hb_next) {\n    size_t size_avail; /* bytes available in this block */\n    size_t align_ofs;\n\n    if (hbp /* != NULL */) {\n      /* CPPCHECK */\n    } else {\n      return NULL;\n    }\n    GET_HDR(hbp, hhdr); /* set hhdr value */\n    size_avail = hhdr->hb_sz;\n    if (!may_split && size_avail != size_needed)\n      continue;\n\n    align_ofs = ALIGN_PAD_SZ(hbp, align_m1);\n    if (size_avail < size_needed + align_ofs)\n      continue; /* the block is too small */\n\n    if (size_avail != size_needed) {\n      /* If the next heap block is obviously better, go on.   */\n      /* This prevents us from disassembling a single large   */\n      /* block to get tiny blocks.                            */\n      if (next_hblk_fits_better(hhdr, size_avail, size_needed, align_m1))\n        continue;\n    }\n\n#if defined(MPROTECT_VDB) && defined(DONT_PROTECT_PTRFREE)\n    /* Avoid write-protecting pointer-free blocks (only the */\n    /* case if page size is larger than the block size).    */\n    GC_ASSERT(GC_page_size != 0);\n    if (GC_page_size != HBLKSIZE\n        && (!GC_incremental /* not enabled yet */\n            || GC_incremental_protection_needs() != GC_PROTECTS_NONE)\n        && is_hblks_mix_in_page(hbp, k == PTRFREE))\n      continue;\n#endif\n\n    if (IS_UNCOLLECTABLE(k)\n        || (k == PTRFREE && size_needed <= MAX_BLACK_LIST_ALLOC)) {\n      last_hbp = hbp + divHBLKSZ(align_ofs);\n      break;\n    }\n\n    last_hbp = find_nonbl_hblk(\n        hbp, size_avail - size_needed,\n        (flags & IGNORE_OFF_PAGE) != 0 ? HBLKSIZE : size_needed, align_m1);\n    /* Is non-blacklisted part of enough size?        */\n    if (last_hbp != NULL) {\n#ifdef USE_MUNMAP\n      /* Avoid remapping followed by splitting.     */\n      if (may_split == AVOID_SPLIT_REMAPPED && last_hbp != hbp\n          && !IS_MAPPED(hhdr))\n        continue;\n#endif\n      break;\n    }\n\n    /* The block is completely blacklisted.  If so, we need to        */\n    /* drop some such blocks, since otherwise we spend all our        */\n    /* time traversing them if pointer-free blocks are unpopular.     */\n    /* A dropped block will be reconsidered at next GC.               */\n    if (size_needed == HBLKSIZE && 0 == align_m1 && !GC_find_leak\n        && IS_MAPPED(hhdr) && (++GC_drop_blacklisted_count & 3) == 0) {\n      const struct hblk *prev = hhdr->hb_prev;\n\n      drop_hblk_in_chunks(index, hbp, hhdr);\n      if (NULL == prev)\n        goto retry;\n      /* Restore hhdr to point at free block. */\n      hhdr = HDR(prev);\n      continue;\n    }\n\n    if (size_needed > BL_LIMIT && size_avail - size_needed > BL_LIMIT) {\n      /* Punt, since anything else risks unreasonable heap growth.    */\n      if (++GC_large_alloc_warn_suppressed >= GC_large_alloc_warn_interval) {\n        WARN(\"Repeated allocation of very large block\"\n             \" (appr. size %\" WARN_PRIuPTR \" KiB):\\n\"\n             \"\\tMay lead to memory leak and poor performance\\n\",\n             size_needed >> 10);\n        GC_large_alloc_warn_suppressed = 0;\n      }\n      last_hbp = hbp + divHBLKSZ(align_ofs);\n      break;\n    }\n  }\n\n  GC_ASSERT((ADDR(last_hbp) & align_m1) == 0);\n  if (last_hbp != hbp) {\n    hdr *last_hdr = GC_install_header(last_hbp);\n\n    if (EXPECT(NULL == last_hdr, FALSE))\n      return NULL;\n      /* Make sure it's mapped before we mangle it.     */\n#ifdef USE_MUNMAP\n    if (!IS_MAPPED(hhdr)) {\n      GC_adjust_num_unmapped(hbp, hhdr);\n      GC_remap((ptr_t)hbp, hhdr->hb_sz);\n      hhdr->hb_flags &= (unsigned char)~WAS_UNMAPPED;\n    }\n#endif\n    /* Split the block at last_hbp. */\n    GC_split_block(hbp, hhdr, last_hbp, last_hdr, index);\n    /* We must now allocate last_hbp, since it may be on the  */\n    /* wrong free list.                                       */\n    hbp = last_hbp;\n    hhdr = last_hdr;\n  }\n  GC_ASSERT(hhdr->hb_sz >= size_needed);\n\n#ifdef USE_MUNMAP\n  if (!IS_MAPPED(hhdr)) {\n    GC_adjust_num_unmapped(hbp, hhdr);\n    GC_remap((ptr_t)hbp, hhdr->hb_sz);\n    hhdr->hb_flags &= (unsigned char)~WAS_UNMAPPED;\n    /* Note: This may leave adjacent, mapped free blocks. */\n  }\n#endif\n  /* hbp may be on the wrong free list; the parameter index is important. */\n  hbp = GC_get_first_part(hbp, hhdr, size_needed, index);\n  if (EXPECT(NULL == hbp, FALSE))\n    return NULL;\n\n  /* Add it to map of valid blocks.   */\n  if (EXPECT(!GC_install_counts(hbp, size_needed), FALSE))\n    return NULL; /* This leaks memory under very rare conditions. */\n\n  /* Set up the header.       */\n  GC_ASSERT(HDR(hbp) == hhdr);\n#ifdef MARK_BIT_PER_OBJ\n  (void)setup_header(hhdr, hbp, lb_adjusted, k, flags);\n  /* Result is always true, not checked to avoid a cppcheck warning. */\n#else\n  if (EXPECT(!setup_header(hhdr, hbp, lb_adjusted, k, flags), FALSE)) {\n    GC_remove_counts(hbp, size_needed);\n    return NULL; /* ditto */\n  }\n#endif\n\n#ifndef GC_DISABLE_INCREMENTAL\n  /* Notify virtual dirty bit implementation that we are about to   */\n  /* write.  Ensure that pointer-free objects are not protected     */\n  /* if it is avoidable.  This also ensures that newly allocated    */\n  /* blocks are treated as dirty - it is necessary since we do not  */\n  /* protect free blocks.                                           */\n  GC_ASSERT(modHBLKSZ(size_needed) == 0);\n  GC_remove_protection(hbp, divHBLKSZ(size_needed), IS_PTRFREE(hhdr));\n#endif\n  /* We just successfully allocated a block.  Restart count of        */\n  /* consecutive failures.                                            */\n  GC_fail_count = 0;\n\n  GC_large_free_bytes -= size_needed;\n  GC_ASSERT(IS_MAPPED(hhdr));\n  return hbp;\n}\n\n#ifdef VALGRIND_TRACKING\n/* Note: this is intentionally defined in a file other than malloc.c  */\n/* and reclaim.c ones.                                                */\nGC_ATTR_NOINLINE\nGC_API void GC_CALLBACK\nGC_free_profiler_hook(void *p)\n{\n#  ifndef PARALLEL_MARK\n  GC_ASSERT(I_HOLD_LOCK());\n#  endif\n  /* Prevent treating this function by the compiler as a no-op one.   */\n  GC_noop1_ptr(p);\n}\n#endif /* VALGRIND_TRACKING */\n\n/* Free a heap block.  Coalesce it with its neighbors if possible.      */\n/* All mark words are assumed to be cleared.                            */\nGC_INNER void\nGC_freehblk(struct hblk *hbp)\n{\n  struct hblk *next, *prev;\n  hdr *hhdr, *prevhdr, *nexthdr;\n  size_t size;\n\n  GET_HDR(hbp, hhdr);\n  size = HBLKSIZE * OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n  if ((size & SIZET_SIGNB) != 0) {\n    /* Probably possible if we try to allocate more than half the     */\n    /* address space at once.  If we don't catch it here, strange     */\n    /* things happen later.                                           */\n    ABORT(\"Deallocating excessively large block.  Too large an allocation?\");\n  }\n  GC_remove_counts(hbp, size);\n  hhdr->hb_sz = size;\n#ifdef USE_MUNMAP\n  hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n#endif\n\n  /* Check for duplicate deallocation in the easy case. */\n  if (HBLK_IS_FREE(hhdr)) {\n    ABORT_ARG1(\"Duplicate large block deallocation\", \" of %p\", (void *)hbp);\n  }\n\n  GC_ASSERT(IS_MAPPED(hhdr));\n  hhdr->hb_flags |= FREE_BLK;\n  next = (struct hblk *)((ptr_t)hbp + size);\n  GET_HDR(next, nexthdr);\n  prev = GC_free_block_ending_at(hbp);\n  /* Coalesce with successor, if possible.    */\n  if (nexthdr != NULL && HBLK_IS_FREE(nexthdr)\n      && IS_MAPPED(nexthdr)\n#ifdef CHERI_PURECAP\n      /* FIXME: Coalesce with super-capability. */\n      /* Bounds of capability should span the entire coalesced memory;   */\n      /* bounds being larger than the block size is OK; bounded by the   */\n      /* imprecision of original capability obtained from system memory. */\n      && CAPABILITY_COVERS_RANGE(hbp, ADDR(next), ADDR(next) + nexthdr->hb_sz)\n#endif\n      && !BLOCKS_MERGE_OVERFLOW(hhdr, nexthdr)) {\n    GC_remove_from_fl(nexthdr);\n    hhdr->hb_sz += nexthdr->hb_sz;\n    GC_remove_header(next);\n  }\n\n  /* Coalesce with predecessor, if possible. */\n  if (prev /* != NULL */) { /* CPPCHECK */\n    prevhdr = HDR(prev);\n    if (IS_MAPPED(prevhdr)\n#ifdef CHERI_PURECAP\n        /* FIXME: Coalesce with super-capability. */\n        && cheri_base_get(hbp) <= ADDR(prev)\n#endif\n        && !BLOCKS_MERGE_OVERFLOW(prevhdr, hhdr)) {\n      GC_remove_from_fl(prevhdr);\n      prevhdr->hb_sz += hhdr->hb_sz;\n#ifdef USE_MUNMAP\n      prevhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n#endif\n      GC_remove_header(hbp);\n      hbp = prev;\n      hhdr = prevhdr;\n    }\n  }\n  /* FIXME: It is not clear we really always want to do these merges  */\n  /* with USE_MUNMAP, since it updates ages and hence prevents        */\n  /* unmapping.                                                       */\n\n  GC_large_free_bytes += size;\n  GC_add_to_fl(hbp, hhdr);\n}\n"
        },
        {
          "name": "alloc.c",
          "type": "blob",
          "size": 58.5458984375,
          "content": "/*\n * Copyright (c) 1988-1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1996 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1999-2011 Hewlett-Packard Development Company, L.P.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/*\n * Separate free lists are maintained for different sized objects\n * up to MAXOBJBYTES.\n * The call GC_allocobj(lg, k) ensures that the free list for\n * kind k objects of size lg granules to a non-empty\n * free list. It returns a pointer to the first entry on the free list.\n * In a single-threaded world, GC_allocobj may be called to allocate\n * an object of small size lb (and NORMAL kind) as follows\n * (GC_generic_malloc_inner is a wrapper over GC_allocobj which also\n * fills in GC_size_map if needed):\n *\n *   lg = GC_size_map[lb];\n *   op = GC_objfreelist[lg];\n *   if (NULL == op) {\n *     op = GC_generic_malloc_inner(lb, NORMAL, 0);\n *   } else {\n *     GC_objfreelist[lg] = obj_link(op);\n *     GC_bytes_allocd += GRANULES_TO_BYTES((word)lg);\n *   }\n *\n * Note that this is very fast if the free list is non-empty; it should\n * only involve the execution of 4 or 5 simple instructions.\n * All composite objects on freelists are cleared, except for\n * their first \"pointer-sized\" word.\n */\n\n/* The allocator uses GC_allochblk to allocate large chunks of objects. */\n/* These chunks all start on addresses which are multiples of HBLKSZ.   */\n/* Each allocated chunk has an associated header, which can be located  */\n/* quickly based on the address of the chunk.  This makes it possible   */\n/* to check quickly whether an arbitrary address corresponds to an      */\n/* object administered by the allocator.  (See headers.c for details.)  */\n\n/* Number of bytes not intended to be collected.        */\nword GC_non_gc_bytes = 0;\n\nword GC_gc_no = 0;\n\n#ifndef NO_CLOCK\n\nstatic unsigned long full_gc_total_time = 0; /* in ms, may wrap */\nstatic unsigned long stopped_mark_total_time = 0;\nstatic unsigned32 full_gc_total_ns_frac = 0; /* fraction of 1 ms */\nstatic unsigned32 stopped_mark_total_ns_frac = 0;\n\n/* Do performance measurements if set to true (e.g., accumulation of  */\n/* the total time of full collections).                               */\nstatic GC_bool measure_performance = FALSE;\n\nGC_API void GC_CALL\nGC_start_performance_measurement(void)\n{\n  measure_performance = TRUE;\n}\n\nGC_API unsigned long GC_CALL\nGC_get_full_gc_total_time(void)\n{\n  return full_gc_total_time;\n}\n\nGC_API unsigned long GC_CALL\nGC_get_stopped_mark_total_time(void)\n{\n  return stopped_mark_total_time;\n}\n\n/* Variables for world-stop average delay time statistic computation. */\n/* \"divisor\" is incremented every world stop and halved when reached  */\n/* its maximum (or upon \"total_time\" overflow).  In milliseconds.     */\n/* TODO: Store the nanosecond part. */\nstatic unsigned world_stopped_total_time = 0;\nstatic unsigned world_stopped_total_divisor = 0;\n\n#  ifndef MAX_TOTAL_TIME_DIVISOR\n/* We shall not use big values here (so \"outdated\" delay time       */\n/* values would have less impact on \"average\" delay time value than */\n/* newer ones).                                                     */\n#    define MAX_TOTAL_TIME_DIVISOR 1000\n#  endif\n\nGC_API unsigned long GC_CALL\nGC_get_avg_stopped_mark_time_ns(void)\n{\n  unsigned long total_time;\n  unsigned divisor;\n\n  READER_LOCK();\n  total_time = (unsigned long)world_stopped_total_time;\n  divisor = world_stopped_total_divisor;\n  READER_UNLOCK();\n  if (0 == divisor) {\n    GC_ASSERT(0 == total_time);\n    /* No world-stopped collection has occurred since the start of  */\n    /* performance measurements.                                    */\n    return 0;\n  }\n\n  /* Halve values to prevent overflow during the multiplication.    */\n  for (; total_time > ~0UL / (1000UL * 1000); total_time >>= 1) {\n    divisor >>= 1;\n    if (EXPECT(0 == divisor, FALSE)) {\n      /* The actual result is larger than representable value.  */\n      return ~0UL;\n    }\n  }\n\n  return total_time * (1000UL * 1000) / divisor;\n}\n\n#endif /* !NO_CLOCK */\n\n#ifndef GC_DISABLE_INCREMENTAL\nGC_INNER GC_bool GC_incremental = FALSE; /* By default, stop the world. */\nSTATIC GC_bool GC_should_start_incremental_collection = FALSE;\n#endif\n\nGC_API int GC_CALL\nGC_is_incremental_mode(void)\n{\n  return (int)GC_incremental;\n}\n\n#ifdef THREADS\nint GC_parallel = FALSE; /* By default, parallel GC is off.      */\n#endif\n\n#if defined(GC_FULL_FREQ) && !defined(CPPCHECK)\nint GC_full_freq = GC_FULL_FREQ;\n#else\n/* Every 20th collection is a full collection, whether we need it     */\n/* or not.                                                            */\nint GC_full_freq = 19;\n#endif\n\n/* Need full GC due to heap growth.     */\nSTATIC GC_bool GC_need_full_gc = FALSE;\n\n#ifdef THREAD_LOCAL_ALLOC\nGC_INNER GC_bool GC_world_stopped = FALSE;\n#endif\n\nSTATIC GC_bool GC_disable_automatic_collection = FALSE;\n\nGC_API void GC_CALL\nGC_set_disable_automatic_collection(int value)\n{\n  LOCK();\n  GC_disable_automatic_collection = (GC_bool)value;\n  UNLOCK();\n}\n\nGC_API int GC_CALL\nGC_get_disable_automatic_collection(void)\n{\n  int value;\n\n  READER_LOCK();\n  value = (int)GC_disable_automatic_collection;\n  READER_UNLOCK();\n  return value;\n}\n\nSTATIC word GC_used_heap_size_after_full = 0;\n\n/* Version macros are now defined in gc_version.h, which is included by */\n/* gc.h, which is included by gc_priv.h.                                */\n#ifndef GC_NO_VERSION_VAR\nEXTERN_C_BEGIN\nextern const GC_VERSION_VAL_T GC_version;\nEXTERN_C_END\n\nconst GC_VERSION_VAL_T GC_version = ((GC_VERSION_VAL_T)GC_VERSION_MAJOR << 16)\n                                    | (GC_VERSION_MINOR << 8)\n                                    | GC_VERSION_MICRO;\n#endif\n\nGC_API GC_VERSION_VAL_T GC_CALL\nGC_get_version(void)\n{\n  return ((GC_VERSION_VAL_T)GC_VERSION_MAJOR << 16) | (GC_VERSION_MINOR << 8)\n         | GC_VERSION_MICRO;\n}\n\nGC_API int GC_CALL\nGC_get_dont_add_byte_at_end(void)\n{\n#ifdef DONT_ADD_BYTE_AT_END\n  return 1;\n#else\n  return 0; /* meaningful only if GC_all_interior_pointers */\n#endif\n}\n\n/* Some more variables. */\n\n#ifdef GC_DONT_EXPAND\nint GC_dont_expand = TRUE;\n#else\nint GC_dont_expand = FALSE;\n#endif\n\n#if defined(GC_FREE_SPACE_DIVISOR) && !defined(CPPCHECK)\nword GC_free_space_divisor = GC_FREE_SPACE_DIVISOR; /* must be > 0 */\n#else\nword GC_free_space_divisor = 3;\n#endif\n\nGC_INNER int GC_CALLBACK\nGC_never_stop_func(void)\n{\n  return FALSE;\n}\n\n#if defined(GC_TIME_LIMIT) && !defined(CPPCHECK)\n/* We try to keep pause times from exceeding this by much.            */\n/* In milliseconds.                                                   */\nunsigned long GC_time_limit = GC_TIME_LIMIT;\n#elif defined(PARALLEL_MARK)\n/* The parallel marker cannot be interrupted for now, so the time     */\n/* limit is absent by default.                                        */\nunsigned long GC_time_limit = GC_TIME_UNLIMITED;\n#else\nunsigned long GC_time_limit = 15;\n#endif\n\n#ifndef NO_CLOCK\n/* The nanoseconds add-on to GC_time_limit value.  Not updated by     */\n/* GC_set_time_limit().  Ignored if the value of GC_time_limit is     */\n/* GC_TIME_UNLIMITED.                                                 */\nSTATIC unsigned long GC_time_lim_nsec = 0;\n\n#  define TV_NSEC_LIMIT (1000UL * 1000) /* amount of nanoseconds in 1 ms */\n\nGC_API void GC_CALL\nGC_set_time_limit_tv(struct GC_timeval_s tv)\n{\n  GC_ASSERT(tv.tv_ms <= GC_TIME_UNLIMITED);\n  GC_ASSERT(tv.tv_nsec < TV_NSEC_LIMIT);\n  GC_time_limit = tv.tv_ms;\n  GC_time_lim_nsec = tv.tv_nsec;\n}\n\nGC_API struct GC_timeval_s GC_CALL\nGC_get_time_limit_tv(void)\n{\n  struct GC_timeval_s tv;\n\n  tv.tv_ms = GC_time_limit;\n  tv.tv_nsec = GC_time_lim_nsec;\n  return tv;\n}\n\nSTATIC CLOCK_TYPE GC_start_time = CLOCK_TYPE_INITIALIZER;\n/* Time at which we stopped world.      */\n/* used only in GC_timeout_stop_func.   */\n#endif /* !NO_CLOCK */\n\n/* Number of attempts at finishing collection within GC_time_limit.     */\nSTATIC int GC_n_attempts = 0;\n\n/* Note: accessed holding the allocator lock.   */\nSTATIC GC_stop_func GC_default_stop_func = GC_never_stop_func;\n\nGC_API void GC_CALL\nGC_set_stop_func(GC_stop_func stop_func)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(stop_func));\n  LOCK();\n  GC_default_stop_func = stop_func;\n  UNLOCK();\n}\n\nGC_API GC_stop_func GC_CALL\nGC_get_stop_func(void)\n{\n  GC_stop_func stop_func;\n\n  READER_LOCK();\n  stop_func = GC_default_stop_func;\n  READER_UNLOCK();\n  return stop_func;\n}\n\n#if defined(GC_DISABLE_INCREMENTAL) || defined(NO_CLOCK)\n#  define GC_timeout_stop_func GC_default_stop_func\n#else\nSTATIC int GC_CALLBACK\nGC_timeout_stop_func(void)\n{\n  CLOCK_TYPE current_time;\n  static unsigned count = 0;\n  unsigned long time_diff, nsec_diff;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_default_stop_func())\n    return TRUE;\n\n  if (GC_time_limit == GC_TIME_UNLIMITED || (count++ & 3) != 0)\n    return FALSE;\n\n  GET_TIME(current_time);\n  time_diff = MS_TIME_DIFF(current_time, GC_start_time);\n  nsec_diff = NS_FRAC_TIME_DIFF(current_time, GC_start_time);\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(&nsec_diff);\n#  endif\n  if (time_diff >= GC_time_limit\n      && (time_diff > GC_time_limit || nsec_diff >= GC_time_lim_nsec)) {\n    GC_COND_LOG_PRINTF(\"Abandoning stopped marking after %lu ms %lu ns\"\n                       \" (attempt %d)\\n\",\n                       time_diff, nsec_diff, GC_n_attempts);\n    return TRUE;\n  }\n\n  return FALSE;\n}\n#endif /* !GC_DISABLE_INCREMENTAL */\n\n#ifdef THREADS\nGC_INNER word GC_total_stacksize = 0; /* updated on every push_all_stacks */\n#endif\n\n/* The lowest value returned by min_bytes_allocd().     */\nstatic size_t min_bytes_allocd_minimum = 1;\n\nGC_API void GC_CALL\nGC_set_min_bytes_allocd(size_t value)\n{\n  GC_ASSERT(value > 0);\n  min_bytes_allocd_minimum = value;\n}\n\nGC_API size_t GC_CALL\nGC_get_min_bytes_allocd(void)\n{\n  return min_bytes_allocd_minimum;\n}\n\n/* Return the minimum number of bytes that must be allocated between    */\n/* collections to amortize the collection cost.  Should be non-zero.    */\nstatic word\nmin_bytes_allocd(void)\n{\n  word result;\n  word stack_size;\n  /* Total size of roots, it includes double stack size, since the    */\n  /* stack is expensive to scan.                                      */\n  word total_root_size;\n  /* Estimate of memory to be scanned during normal GC.               */\n  word scan_size;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#ifdef THREADS\n  if (GC_need_to_lock) {\n    /* We are multi-threaded... */\n    stack_size = GC_total_stacksize;\n    /* For now, we just use the value computed during the latest GC. */\n#  ifdef DEBUG_THREADS\n    GC_log_printf(\"Total stacks size: %lu\\n\", (unsigned long)stack_size);\n#  endif\n  } else\n#endif\n  /* else*/ {\n#ifdef STACK_NOT_SCANNED\n    stack_size = 0;\n#elif defined(STACK_GROWS_UP)\n    stack_size = (word)(GC_approx_sp() - GC_stackbottom);\n#else\n    stack_size = (word)(GC_stackbottom - GC_approx_sp());\n#endif\n  }\n\n  total_root_size = 2 * stack_size + GC_root_size;\n  scan_size = 2 * GC_composite_in_use + GC_atomic_in_use / 4 + total_root_size;\n  result = scan_size / GC_free_space_divisor;\n  if (GC_incremental) {\n    result /= 2;\n  }\n  return result > min_bytes_allocd_minimum ? result : min_bytes_allocd_minimum;\n}\n\n/* Number of explicitly managed bytes of storage at last collection.    */\nSTATIC word GC_non_gc_bytes_at_gc = 0;\n\n/* Return the number of bytes allocated, adjusted for explicit storage  */\n/* management, etc.  This number is used in deciding when to trigger    */\n/* collections.                                                         */\nSTATIC word\nGC_adj_bytes_allocd(void)\n{\n  GC_signed_word result;\n  GC_signed_word expl_managed = (GC_signed_word)GC_non_gc_bytes\n                                - (GC_signed_word)GC_non_gc_bytes_at_gc;\n\n  /* Don't count what was explicitly freed, or newly allocated for    */\n  /* explicit management.  Note that deallocating an explicitly       */\n  /* managed object should not alter result, assuming the client      */\n  /* is playing by the rules.                                         */\n  result = (GC_signed_word)GC_bytes_allocd + (GC_signed_word)GC_bytes_dropped\n           - (GC_signed_word)GC_bytes_freed\n           + (GC_signed_word)GC_finalizer_bytes_freed - expl_managed;\n  if (result > (GC_signed_word)GC_bytes_allocd) {\n    /* Probably a client bug or unfortunate scheduling.     */\n    result = (GC_signed_word)GC_bytes_allocd;\n  }\n  /* We count objects enqueued for finalization as though they had    */\n  /* been reallocated this round. Finalization is user visible        */\n  /* progress.  And if we do not count this, we have stability        */\n  /* problems for programs that finalize all objects.                 */\n  result += (GC_signed_word)GC_bytes_finalized;\n  if (result < (GC_signed_word)(GC_bytes_allocd >> 3)) {\n    /* Always count at least 1/8 of the allocations.  We don't want */\n    /* to collect too infrequently, since that would inhibit        */\n    /* coalescing of free storage blocks.                           */\n    /* This also makes us partially robust against client bugs.     */\n    result = (GC_signed_word)(GC_bytes_allocd >> 3);\n  }\n  return (word)result;\n}\n\n/* Clear up a few frames worth of garbage left at the top of the stack. */\n/* This is used to prevent us from accidentally treating garbage left   */\n/* on the stack by other parts of the collector as roots.  This         */\n/* differs from the code in misc.c, which actually tries to keep the    */\n/* stack clear of long-lived, client-generated garbage.                 */\nSTATIC void\nGC_clear_a_few_frames(void)\n{\n#ifndef CLEAR_STACK_NPTRS\n#  define CLEAR_STACK_NPTRS 64 /* pointers */\n#endif\n  volatile ptr_t frames[CLEAR_STACK_NPTRS];\n\n  BZERO(CAST_AWAY_VOLATILE_PVOID(frames), sizeof(frames));\n}\n\nGC_API void GC_CALL\nGC_start_incremental_collection(void)\n{\n#ifndef GC_DISABLE_INCREMENTAL\n  LOCK();\n  if (GC_incremental) {\n    GC_should_start_incremental_collection = TRUE;\n    if (!GC_dont_gc) {\n      ENTER_GC();\n      GC_collect_a_little_inner(1);\n      EXIT_GC();\n    }\n  }\n  UNLOCK();\n#endif\n}\n\n/* Have we allocated enough to amortize a collection? */\nGC_INNER GC_bool\nGC_should_collect(void)\n{\n  static word last_min_bytes_allocd;\n  static word last_gc_no;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (last_gc_no != GC_gc_no) {\n    last_min_bytes_allocd = min_bytes_allocd();\n    last_gc_no = GC_gc_no;\n  }\n#ifndef GC_DISABLE_INCREMENTAL\n  if (GC_should_start_incremental_collection) {\n    GC_should_start_incremental_collection = FALSE;\n    return TRUE;\n  }\n#endif\n  if (GC_disable_automatic_collection)\n    return FALSE;\n\n  if (GC_last_heap_growth_gc_no == GC_gc_no)\n    return TRUE; /* avoid expanding past limits used by blacklisting  */\n\n  return GC_adj_bytes_allocd() >= last_min_bytes_allocd;\n}\n\n/* Called at start of full collections.  Not called if 0.  Called with  */\n/* the allocator lock held.  Not used by GC itself.                     */\n/* STATIC */ GC_start_callback_proc GC_start_call_back = 0;\n\nGC_API void GC_CALL\nGC_set_start_callback(GC_start_callback_proc fn)\n{\n  LOCK();\n  GC_start_call_back = fn;\n  UNLOCK();\n}\n\nGC_API GC_start_callback_proc GC_CALL\nGC_get_start_callback(void)\n{\n  GC_start_callback_proc fn;\n\n  READER_LOCK();\n  fn = GC_start_call_back;\n  READER_UNLOCK();\n  return fn;\n}\n\nGC_INLINE void\nGC_notify_full_gc(void)\n{\n  if (GC_start_call_back != 0) {\n    (*GC_start_call_back)();\n  }\n}\n\nSTATIC GC_bool GC_is_full_gc = FALSE;\n\nSTATIC GC_bool GC_stopped_mark(GC_stop_func stop_func);\nSTATIC void GC_finish_collection(void);\n\n/* Initiate a garbage collection if appropriate.  Choose judiciously    */\n/* between partial, full, and stop-world collections.                   */\nSTATIC void\nGC_maybe_gc(void)\n{\n  static int n_partial_gcs = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  ASSERT_CANCEL_DISABLED();\n  if (!GC_should_collect())\n    return;\n\n  if (!GC_incremental) {\n    GC_gcollect_inner();\n    return;\n  }\n\n  GC_ASSERT(!GC_collection_in_progress());\n#ifdef PARALLEL_MARK\n  if (GC_parallel)\n    GC_wait_for_reclaim();\n#endif\n  if (GC_need_full_gc || n_partial_gcs >= GC_full_freq) {\n    GC_COND_LOG_PRINTF(\n        \"***>Full mark for collection #%lu after %lu allocd bytes\\n\",\n        (unsigned long)GC_gc_no + 1, (unsigned long)GC_bytes_allocd);\n    GC_promote_black_lists();\n    (void)GC_reclaim_all((GC_stop_func)0, TRUE);\n    GC_notify_full_gc();\n    GC_clear_marks();\n    n_partial_gcs = 0;\n    GC_is_full_gc = TRUE;\n  } else {\n    n_partial_gcs++;\n  }\n\n  /* Try to mark with the world stopped.  If we run out of      */\n  /* time, this turns into an incremental marking.              */\n#ifndef NO_CLOCK\n  if (GC_time_limit != GC_TIME_UNLIMITED)\n    GET_TIME(GC_start_time);\n#endif\n  if (GC_stopped_mark(GC_timeout_stop_func)) {\n    SAVE_CALLERS_TO_LAST_STACK();\n    GC_finish_collection();\n  } else if (!GC_is_full_gc) {\n    /* Count this as the first attempt. */\n    GC_n_attempts++;\n  }\n}\n\nSTATIC GC_on_collection_event_proc GC_on_collection_event = 0;\n\nGC_API void GC_CALL\nGC_set_on_collection_event(GC_on_collection_event_proc fn)\n{\n  /* fn may be 0 (means no event notifier). */\n  LOCK();\n  GC_on_collection_event = fn;\n  UNLOCK();\n}\n\nGC_API GC_on_collection_event_proc GC_CALL\nGC_get_on_collection_event(void)\n{\n  GC_on_collection_event_proc fn;\n\n  READER_LOCK();\n  fn = GC_on_collection_event;\n  READER_UNLOCK();\n  return fn;\n}\n\n/* Stop the world garbage collection.  If stop_func is not      */\n/* GC_never_stop_func then abort if stop_func returns TRUE.     */\n/* Return TRUE if we successfully completed the collection.     */\nGC_INNER GC_bool\nGC_try_to_collect_inner(GC_stop_func stop_func)\n{\n#ifndef NO_CLOCK\n  CLOCK_TYPE start_time = CLOCK_TYPE_INITIALIZER;\n  GC_bool start_time_valid;\n#endif\n\n  ASSERT_CANCEL_DISABLED();\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n  if (GC_dont_gc || (*stop_func)())\n    return FALSE;\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_START);\n  if (GC_incremental && GC_collection_in_progress()) {\n    GC_COND_LOG_PRINTF(\n        \"GC_try_to_collect_inner: finishing collection in progress\\n\");\n    /* Just finish collection already in progress.    */\n    do {\n      if ((*stop_func)()) {\n        /* TODO: Notify GC_EVENT_ABANDON */\n        return FALSE;\n      }\n      ENTER_GC();\n      GC_collect_a_little_inner(1);\n      EXIT_GC();\n    } while (GC_collection_in_progress());\n  }\n  GC_notify_full_gc();\n#ifndef NO_CLOCK\n  start_time_valid = FALSE;\n  if ((GC_print_stats | (int)measure_performance) != 0) {\n    if (GC_print_stats)\n      GC_log_printf(\"Initiating full world-stop collection!\\n\");\n    start_time_valid = TRUE;\n    GET_TIME(start_time);\n  }\n#endif\n  GC_promote_black_lists();\n  /* Make sure all blocks have been reclaimed, so sweep routines      */\n  /* don't see cleared mark bits.                                     */\n  /* If we're guaranteed to finish, then this is unnecessary.         */\n  /* In the find_leak case, we have to finish to guarantee that       */\n  /* previously unmarked objects are not reported as leaks.           */\n#ifdef PARALLEL_MARK\n  if (GC_parallel)\n    GC_wait_for_reclaim();\n#endif\n  if ((GC_find_leak || stop_func != GC_never_stop_func)\n      && !GC_reclaim_all(stop_func, FALSE)) {\n    /* Aborted.  So far everything is still consistent. */\n    /* TODO: Notify GC_EVENT_ABANDON */\n    return FALSE;\n  }\n  GC_invalidate_mark_state(); /* Flush mark stack.   */\n  GC_clear_marks();\n  SAVE_CALLERS_TO_LAST_STACK();\n  GC_is_full_gc = TRUE;\n  if (!GC_stopped_mark(stop_func)) {\n    if (!GC_incremental) {\n      /* We're partially done and have no way to complete or use      */\n      /* current work.  Reestablish invariants as cheaply as          */\n      /* possible.                                                    */\n      GC_invalidate_mark_state();\n      GC_unpromote_black_lists();\n    } else {\n      /* We claim the world is already still consistent.  We will     */\n      /* finish incrementally.                                        */\n    }\n    /* TODO: Notify GC_EVENT_ABANDON */\n    return FALSE;\n  }\n  GC_finish_collection();\n#ifndef NO_CLOCK\n  if (start_time_valid) {\n    CLOCK_TYPE current_time;\n    unsigned long time_diff, ns_frac_diff;\n\n    GET_TIME(current_time);\n    time_diff = MS_TIME_DIFF(current_time, start_time);\n    ns_frac_diff = NS_FRAC_TIME_DIFF(current_time, start_time);\n    if (measure_performance) {\n      full_gc_total_time += time_diff; /* may wrap */\n      full_gc_total_ns_frac += (unsigned32)ns_frac_diff;\n      if (full_gc_total_ns_frac >= (unsigned32)1000000UL) {\n        /* Overflow of the nanoseconds part. */\n        full_gc_total_ns_frac -= (unsigned32)1000000UL;\n        full_gc_total_time++;\n      }\n    }\n    if (GC_print_stats)\n      GC_log_printf(\"Complete collection took %lu ms %lu ns\\n\", time_diff,\n                    ns_frac_diff);\n  }\n#endif\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_END);\n  return TRUE;\n}\n\n/* The number of extra calls to GC_mark_some that we have made. */\nSTATIC size_t GC_deficit = 0;\n\n/* The default value of GC_rate.        */\n#ifndef GC_RATE\n#  define GC_RATE 10\n#endif\n\n/* When GC_collect_a_little_inner() performs n_blocks units of garbage  */\n/* collection work, a unit is intended to touch roughly GC_rate pages.  */\n/* (But, every once in a while, we do more than that.)  This needs to   */\n/* be a fairly large number with our current incremental GC strategy,   */\n/* since otherwise we allocate too much during GC, and the cleanup gets */\n/* expensive.                                                           */\nSTATIC unsigned GC_rate = GC_RATE;\n\nGC_API void GC_CALL\nGC_set_rate(int value)\n{\n  GC_ASSERT(value > 0);\n  GC_rate = (unsigned)value;\n}\n\nGC_API int GC_CALL\nGC_get_rate(void)\n{\n  return (int)GC_rate;\n}\n\n/* The default maximum number of prior attempts at world stop marking.  */\n#ifndef MAX_PRIOR_ATTEMPTS\n#  define MAX_PRIOR_ATTEMPTS 3\n#endif\n\n/* The maximum number of prior attempts at world stop marking.          */\n/* A value of 1 means that we finish the second time, no matter how     */\n/* long it takes.  Does not count the initial root scan for a full GC.  */\nstatic int max_prior_attempts = MAX_PRIOR_ATTEMPTS;\n\nGC_API void GC_CALL\nGC_set_max_prior_attempts(int value)\n{\n  GC_ASSERT(value >= 0);\n  max_prior_attempts = value;\n}\n\nGC_API int GC_CALL\nGC_get_max_prior_attempts(void)\n{\n  return max_prior_attempts;\n}\n\nGC_INNER void\nGC_collect_a_little_inner(size_t n_blocks)\n{\n  IF_CANCEL(int cancel_state;)\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n  DISABLE_CANCEL(cancel_state);\n  if (GC_incremental && GC_collection_in_progress()) {\n    size_t i;\n    size_t max_deficit = GC_rate * n_blocks;\n\n#ifdef PARALLEL_MARK\n    if (GC_time_limit != GC_TIME_UNLIMITED)\n      GC_parallel_mark_disabled = TRUE;\n#endif\n    for (i = GC_deficit; i < max_deficit; i++) {\n      if (GC_mark_some(NULL))\n        break;\n    }\n#ifdef PARALLEL_MARK\n    GC_parallel_mark_disabled = FALSE;\n#endif\n\n    if (i < max_deficit && !GC_dont_gc) {\n      GC_ASSERT(!GC_collection_in_progress());\n      /* Need to follow up with a full collection.        */\n      SAVE_CALLERS_TO_LAST_STACK();\n#ifdef PARALLEL_MARK\n      if (GC_parallel)\n        GC_wait_for_reclaim();\n#endif\n#ifndef NO_CLOCK\n      if (GC_time_limit != GC_TIME_UNLIMITED\n          && GC_n_attempts < max_prior_attempts)\n        GET_TIME(GC_start_time);\n#endif\n      if (GC_stopped_mark(GC_n_attempts < max_prior_attempts\n                              ? GC_timeout_stop_func\n                              : GC_never_stop_func)) {\n        GC_finish_collection();\n      } else {\n        GC_n_attempts++;\n      }\n    }\n    if (GC_deficit > 0) {\n      GC_deficit = GC_deficit > max_deficit ? GC_deficit - max_deficit : 0;\n    }\n  } else if (!GC_dont_gc) {\n    GC_maybe_gc();\n  }\n  RESTORE_CANCEL(cancel_state);\n}\n\nGC_INNER void (*GC_check_heap)(void) = 0;\nGC_INNER void (*GC_print_all_smashed)(void) = 0;\n\nGC_API int GC_CALL\nGC_collect_a_little(void)\n{\n  int result;\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  LOCK();\n  ENTER_GC();\n  /* Note: if the collection is in progress, this may do marking (not */\n  /* stopping the world) even in case of disabled GC.                 */\n  GC_collect_a_little_inner(1);\n  EXIT_GC();\n  result = (int)GC_collection_in_progress();\n  UNLOCK();\n  if (!result && GC_debugging_started)\n    GC_print_all_smashed();\n  return result;\n}\n\n#ifdef THREADS\nGC_API void GC_CALL\nGC_stop_world_external(void)\n{\n  GC_ASSERT(GC_is_initialized);\n  LOCK();\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_ASSERT(!GC_world_stopped);\n#  endif\n  STOP_WORLD();\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_world_stopped = TRUE;\n#  endif\n}\n\nGC_API void GC_CALL\nGC_start_world_external(void)\n{\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_ASSERT(GC_world_stopped);\n  GC_world_stopped = FALSE;\n#  else\n  GC_ASSERT(GC_is_initialized);\n#  endif\n  START_WORLD();\n  UNLOCK();\n}\n#endif /* THREADS */\n\n#ifdef USE_MUNMAP\n#  ifndef MUNMAP_THRESHOLD\n#    define MUNMAP_THRESHOLD 7\n#  endif\nGC_INNER unsigned GC_unmap_threshold = MUNMAP_THRESHOLD;\n\n#  define IF_USE_MUNMAP(x) x\n#  define COMMA_IF_USE_MUNMAP(x) /* comma */ , x\n#else\n#  define IF_USE_MUNMAP(x)\n#  define COMMA_IF_USE_MUNMAP(x)\n#endif /* !USE_MUNMAP */\n\n/* We stop the world and mark from all roots.  If stop_func() ever      */\n/* returns TRUE, we may fail and return FALSE.  Increment GC_gc_no if   */\n/* we succeed.                                                          */\nSTATIC GC_bool\nGC_stopped_mark(GC_stop_func stop_func)\n{\n  ptr_t cold_gc_frame = GC_approx_sp();\n  unsigned abandoned_at;\n#ifndef NO_CLOCK\n  CLOCK_TYPE start_time = CLOCK_TYPE_INITIALIZER;\n  GC_bool start_time_valid = FALSE;\n#endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n#if !defined(REDIRECT_MALLOC) && defined(USE_WINALLOC)\n  GC_add_current_malloc_heap();\n#endif\n#if defined(REGISTER_LIBRARIES_EARLY)\n  GC_cond_register_dynamic_libraries();\n#endif\n\n#if !defined(GC_NO_FINALIZATION) && !defined(GC_TOGGLE_REFS_NOT_NEEDED)\n  GC_process_togglerefs();\n#endif\n\n  /* Output blank line for convenience here.  */\n  GC_COND_LOG_PRINTF(\n      \"\\n--> Marking for collection #%lu after %lu allocated bytes\\n\",\n      (unsigned long)GC_gc_no + 1, (unsigned long)GC_bytes_allocd);\n#ifndef NO_CLOCK\n  if (GC_PRINT_STATS_FLAG || measure_performance) {\n    GET_TIME(start_time);\n    start_time_valid = TRUE;\n  }\n#endif\n#ifdef THREADS\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_PRE_STOP_WORLD);\n#endif\n  STOP_WORLD();\n#ifdef THREADS\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_POST_STOP_WORLD);\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_world_stopped = TRUE;\n#  elif defined(CPPCHECK)\n  (void)0; /* workaround a warning about adjacent same \"if\" condition */\n#  endif\n#endif\n\n#ifdef MAKE_BACK_GRAPH\n  if (GC_print_back_height) {\n    GC_build_back_graph();\n  }\n#endif\n\n  /* Notify about marking from all roots.     */\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_MARK_START);\n\n  /* Minimize junk left in my registers and on the stack.     */\n  GC_clear_a_few_frames();\n  GC_noop6(0, 0, 0, 0, 0, 0);\n\n  GC_initiate_gc();\n#ifdef PARALLEL_MARK\n  if (stop_func != GC_never_stop_func)\n    GC_parallel_mark_disabled = TRUE;\n#endif\n  for (abandoned_at = 1; !(*stop_func)(); abandoned_at++) {\n    if (GC_mark_some(cold_gc_frame)) {\n#ifdef PARALLEL_MARK\n      if (GC_parallel && GC_parallel_mark_disabled) {\n        GC_COND_LOG_PRINTF(\"Stopped marking done after %u iterations\"\n                           \" with disabled parallel marker\\n\",\n                           abandoned_at - 1);\n      }\n#endif\n      abandoned_at = 0;\n      break;\n    }\n  }\n#ifdef PARALLEL_MARK\n  GC_parallel_mark_disabled = FALSE;\n#endif\n\n  if (abandoned_at > 0) {\n    GC_deficit = abandoned_at - 1; /* give the mutator a chance */\n    /* TODO: Notify GC_EVENT_MARK_ABANDON */\n  } else {\n    GC_gc_no++;\n    /* Check all debugged objects for consistency.    */\n    if (GC_debugging_started) {\n      (*GC_check_heap)();\n    }\n    if (GC_on_collection_event)\n      GC_on_collection_event(GC_EVENT_MARK_END);\n  }\n\n#ifdef THREADS\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_PRE_START_WORLD);\n#endif\n#ifdef THREAD_LOCAL_ALLOC\n  GC_world_stopped = FALSE;\n#endif\n  START_WORLD();\n#ifdef THREADS\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_POST_START_WORLD);\n#endif\n\n#ifndef NO_CLOCK\n  if (start_time_valid) {\n    CLOCK_TYPE current_time;\n    unsigned long time_diff, ns_frac_diff;\n\n    /* TODO: Avoid code duplication from GC_try_to_collect_inner */\n    GET_TIME(current_time);\n    time_diff = MS_TIME_DIFF(current_time, start_time);\n    ns_frac_diff = NS_FRAC_TIME_DIFF(current_time, start_time);\n    if (measure_performance) {\n      stopped_mark_total_time += time_diff; /* may wrap */\n      stopped_mark_total_ns_frac += (unsigned32)ns_frac_diff;\n      if (stopped_mark_total_ns_frac >= (unsigned32)1000000UL) {\n        stopped_mark_total_ns_frac -= (unsigned32)1000000UL;\n        stopped_mark_total_time++;\n      }\n    }\n\n    if (GC_PRINT_STATS_FLAG || measure_performance) {\n      unsigned total_time = world_stopped_total_time;\n      unsigned divisor = world_stopped_total_divisor;\n\n      /* Compute new world-stop delay total time.   */\n      if (total_time > (((unsigned)-1) >> 1)\n          || divisor >= MAX_TOTAL_TIME_DIVISOR) {\n        /* Halve values if overflow occurs. */\n        total_time >>= 1;\n        divisor >>= 1;\n      }\n      total_time += time_diff < (((unsigned)-1) >> 1) ? (unsigned)time_diff\n                                                      : ((unsigned)-1) >> 1;\n      /* Update old world_stopped_total_time and its divisor.   */\n      world_stopped_total_time = total_time;\n      world_stopped_total_divisor = ++divisor;\n      if (GC_PRINT_STATS_FLAG && 0 == abandoned_at) {\n        GC_ASSERT(divisor != 0);\n        GC_log_printf(\"World-stopped marking took %lu ms %lu ns\"\n                      \" (%u ms in average)\\n\",\n                      time_diff, ns_frac_diff, total_time / divisor);\n      }\n    }\n  }\n#endif\n\n  if (0 == abandoned_at)\n    return TRUE;\n  GC_COND_LOG_PRINTF(\"Abandoned stopped marking after %u iterations\\n\",\n                     abandoned_at - 1);\n  return FALSE;\n}\n\nGC_INNER void\nGC_set_fl_marks(ptr_t q)\n{\n#ifdef GC_ASSERTIONS\n  ptr_t q2;\n#endif\n  struct hblk *h = HBLKPTR(q);\n  const struct hblk *last_h = h;\n  hdr *hhdr;\n#ifdef MARK_BIT_PER_OBJ\n  size_t sz;\n#endif\n\n  GC_ASSERT(q != NULL);\n  hhdr = HDR(h);\n#ifdef MARK_BIT_PER_OBJ\n  sz = hhdr->hb_sz;\n#endif\n#ifdef GC_ASSERTIONS\n  q2 = (ptr_t)obj_link(q);\n#endif\n  for (;;) {\n    size_t bit_no = MARK_BIT_NO((size_t)((ptr_t)q - (ptr_t)h), sz);\n\n    if (!mark_bit_from_hdr(hhdr, bit_no)) {\n      set_mark_bit_from_hdr(hhdr, bit_no);\n      INCR_MARKS(hhdr);\n    }\n    q = (ptr_t)obj_link(q);\n    if (NULL == q)\n      break;\n#ifdef GC_ASSERTIONS\n    /* Detect a cycle in the free list.  The algorithm is to  */\n    /* have a second \"twice faster\" iterator over the list -  */\n    /* the second iterator meets the first one in case of     */\n    /* a cycle existing in the list.                          */\n    if (q2 != NULL) {\n      q2 = (ptr_t)obj_link(q2);\n      GC_ASSERT(q2 != q);\n      if (q2 != NULL) {\n        q2 = (ptr_t)obj_link(q2);\n        GC_ASSERT(q2 != q);\n      }\n    }\n#endif\n\n    h = HBLKPTR(q);\n    if (EXPECT(h != last_h, FALSE)) {\n      last_h = h;\n      /* Update hhdr and sz. */\n      hhdr = HDR(h);\n#ifdef MARK_BIT_PER_OBJ\n      sz = hhdr->hb_sz;\n#endif\n    }\n  }\n}\n\n#if defined(GC_ASSERTIONS) && defined(THREAD_LOCAL_ALLOC)\n/* Check that all mark bits for the free list whose first entry is    */\n/* (*pfreelist) are set.  Check skipped if points to a special value. */\nvoid\nGC_check_fl_marks(void **pfreelist)\n{\n  /* TODO: There is a data race with GC_FAST_MALLOC_GRANS (which does */\n  /* not do atomic updates to the free-list).  The race seems to be   */\n  /* harmless, and for now we just skip this check in case of TSan.   */\n#  if defined(AO_HAVE_load_acquire_read) && !defined(THREAD_SANITIZER)\n  ptr_t list = GC_cptr_load_acquire_read((volatile ptr_t *)pfreelist);\n  /* Atomic operations are used because the world is running. */\n  ptr_t p, prev, next;\n\n  if (ADDR(list) <= HBLKSIZE)\n    return;\n\n  prev = (ptr_t)pfreelist;\n  for (p = list; p != NULL; p = next) {\n    if (!GC_is_marked(p)) {\n      ABORT_ARG2(\"Unmarked local free-list entry\", \": object %p on list %p\",\n                 (void *)p, (void *)list);\n    }\n\n    /* While traversing the free-list, it re-reads the pointer to   */\n    /* the current node before accepting its next pointer and       */\n    /* bails out if the latter has changed.  That way, it won't     */\n    /* try to follow the pointer which might be been modified       */\n    /* after the object was returned to the client.  It might       */\n    /* perform the mark-check on the just allocated object but      */\n    /* that should be harmless.                                     */\n    next = GC_cptr_load_acquire_read((volatile ptr_t *)p);\n    if (GC_cptr_load((volatile ptr_t *)prev) != p)\n      break;\n    prev = p;\n  }\n#  else\n  /* FIXME: Not implemented (just skipped). */\n  (void)pfreelist;\n#  endif\n}\n#endif /* GC_ASSERTIONS && THREAD_LOCAL_ALLOC */\n\n/* Clear all mark bits for the free list (specified by the first        */\n/* entry).  Decrement GC_bytes_found by number of bytes on free list.   */\nSTATIC void\nGC_clear_fl_marks(ptr_t q)\n{\n  struct hblk *h = HBLKPTR(q);\n  const struct hblk *last_h = h;\n  hdr *hhdr = HDR(h);\n  size_t sz = hhdr->hb_sz; /* normally set only once */\n\n  for (;;) {\n    size_t bit_no = MARK_BIT_NO((size_t)((ptr_t)q - (ptr_t)h), sz);\n\n    if (mark_bit_from_hdr(hhdr, bit_no)) {\n      size_t n_marks = hhdr->hb_n_marks;\n\n#ifdef LINT2\n      if (0 == n_marks)\n        ABORT(\"hhdr->hb_n_marks cannot be zero\");\n#else\n      GC_ASSERT(n_marks != 0);\n#endif\n      clear_mark_bit_from_hdr(hhdr, bit_no);\n      n_marks--;\n#ifdef PARALLEL_MARK\n      /* Appr. count, don't decrement to zero!    */\n      if (n_marks != 0 || !GC_parallel) {\n        hhdr->hb_n_marks = n_marks;\n      }\n#else\n      hhdr->hb_n_marks = n_marks;\n#endif\n    }\n    GC_bytes_found -= (GC_signed_word)sz;\n\n    q = (ptr_t)obj_link(q);\n    if (NULL == q)\n      break;\n\n    h = HBLKPTR(q);\n    if (EXPECT(h != last_h, FALSE)) {\n      last_h = h;\n      /* Update hhdr and sz.    */\n      hhdr = HDR(h);\n      sz = hhdr->hb_sz;\n    }\n  }\n}\n\n/* Mark all objects on the free lists for every object kind.    */\nstatic void\nset_all_fl_marks(void)\n{\n  unsigned kind;\n\n  for (kind = 0; kind < GC_n_kinds; kind++) {\n    word size; /* current object size */\n\n    for (size = 1; size <= MAXOBJGRANULES; size++) {\n      ptr_t q = (ptr_t)GC_obj_kinds[kind].ok_freelist[size];\n\n      if (q != NULL)\n        GC_set_fl_marks(q);\n    }\n  }\n}\n\n/* Clear free-list mark bits.  Also subtract memory remaining from  */\n/* GC_bytes_found count.                                            */\nstatic void\nclear_all_fl_marks(void)\n{\n  unsigned kind;\n\n  for (kind = 0; kind < GC_n_kinds; kind++) {\n    word size; /* current object size */\n\n    for (size = 1; size <= MAXOBJGRANULES; size++) {\n      ptr_t q = (ptr_t)GC_obj_kinds[kind].ok_freelist[size];\n\n      if (q != NULL)\n        GC_clear_fl_marks(q);\n    }\n  }\n}\n\n#if defined(GC_ASSERTIONS) && defined(THREAD_LOCAL_ALLOC)\nvoid GC_check_tls(void);\n#endif\n\nGC_on_heap_resize_proc GC_on_heap_resize = 0;\n\n/* Used for logging only. */\nGC_INLINE int\nGC_compute_heap_usage_percent(void)\n{\n  word used = GC_composite_in_use + GC_atomic_in_use + GC_bytes_allocd;\n  word heap_sz = GC_heapsize - GC_unmapped_bytes;\n#if defined(CPPCHECK)\n  word limit = (GC_WORD_MAX >> 1) / 50; /* to avoid a false positive */\n#else\n  const word limit = GC_WORD_MAX / 100;\n#endif\n\n  return used >= heap_sz ? 0\n         : used < limit  ? (int)((used * 100) / heap_sz)\n                         : (int)(used / (heap_sz / 100));\n}\n\n#define GC_DBGLOG_PRINT_HEAP_IN_USE()                                        \\\n  GC_DBGLOG_PRINTF(\"In-use heap: %d%% (%lu KiB pointers + %lu KiB other)\\n\", \\\n                   GC_compute_heap_usage_percent(),                          \\\n                   TO_KiB_UL(GC_composite_in_use),                           \\\n                   TO_KiB_UL(GC_atomic_in_use + GC_bytes_allocd))\n\n/* Finish up a collection.  Assumes mark bits are consistent, but the   */\n/* world is otherwise running.                                          */\nSTATIC void\nGC_finish_collection(void)\n{\n#ifndef NO_CLOCK\n  CLOCK_TYPE start_time = CLOCK_TYPE_INITIALIZER;\n  CLOCK_TYPE finalize_time = CLOCK_TYPE_INITIALIZER;\n#endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n#if defined(GC_ASSERTIONS) && defined(THREAD_LOCAL_ALLOC) \\\n    && !defined(DBG_HDRS_ALL)\n  /* Check that we marked some of our own data.           */\n  GC_check_tls();\n  /* TODO: Add more checks. */\n#endif\n\n#ifndef NO_CLOCK\n  if (GC_print_stats)\n    GET_TIME(start_time);\n#endif\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_RECLAIM_START);\n\n#ifndef GC_GET_HEAP_USAGE_NOT_NEEDED\n  if (GC_bytes_found > 0)\n    GC_reclaimed_bytes_before_gc += (word)GC_bytes_found;\n#endif\n  GC_bytes_found = 0;\n#if defined(LINUX) && defined(__ELF__) && !defined(SMALL_CONFIG)\n  if (GETENV(\"GC_PRINT_ADDRESS_MAP\") != NULL) {\n    GC_print_address_map();\n  }\n#endif\n  COND_DUMP;\n  if (GC_find_leak) {\n    set_all_fl_marks();\n    /* This just checks; it doesn't really reclaim anything.      */\n    GC_start_reclaim(TRUE);\n  }\n\n#ifndef GC_NO_FINALIZATION\n  GC_finalize();\n#endif\n#ifndef NO_CLOCK\n  if (GC_print_stats)\n    GET_TIME(finalize_time);\n#endif\n\n  if (GC_print_back_height) {\n#ifdef MAKE_BACK_GRAPH\n    GC_traverse_back_graph();\n#elif !defined(SMALL_CONFIG)\n    GC_err_printf(\"Back height not available: \"\n                  \"Rebuild collector with -DMAKE_BACK_GRAPH\\n\");\n#endif\n  }\n\n  /* Clear free-list mark bits, in case they got accidentally marked  */\n  /* (or GC_find_leak is set and they were intentionally marked).     */\n  /* Note that composite objects on free list are cleared, thus       */\n  /* accidentally marking a free list is not a problem; but some      */\n  /* objects on the list itself might be marked, and the given        */\n  /* function call fixes it.                                          */\n  clear_all_fl_marks();\n\n  GC_VERBOSE_LOG_PRINTF(\"Bytes recovered before sweep - f.l. count = %ld\\n\",\n                        (long)GC_bytes_found);\n\n  /* Reconstruct free lists to contain everything not marked. */\n  GC_start_reclaim(FALSE);\n\n#ifdef USE_MUNMAP\n  if (GC_unmap_threshold > 0          /* unmapping enabled? */\n      && EXPECT(GC_gc_no != 1, TRUE)) /* do not unmap during GC init */\n    GC_unmap_old(GC_unmap_threshold);\n\n  GC_ASSERT(GC_heapsize >= GC_unmapped_bytes);\n#endif\n  GC_ASSERT(GC_our_mem_bytes >= GC_heapsize);\n  GC_DBGLOG_PRINTF(\n      \"GC #%lu freed %ld bytes, heap %lu KiB (\" IF_USE_MUNMAP(\n          \"+ %lu KiB unmapped \") \"+ %lu KiB internal)\\n\",\n      (unsigned long)GC_gc_no, (long)GC_bytes_found,\n      TO_KiB_UL(GC_heapsize - GC_unmapped_bytes) /*, */\n      COMMA_IF_USE_MUNMAP(TO_KiB_UL(GC_unmapped_bytes)),\n      TO_KiB_UL(GC_our_mem_bytes - GC_heapsize + sizeof(GC_arrays)));\n  GC_DBGLOG_PRINT_HEAP_IN_USE();\n  if (GC_is_full_gc) {\n    GC_used_heap_size_after_full = GC_heapsize - GC_large_free_bytes;\n    GC_need_full_gc = FALSE;\n  } else {\n    GC_need_full_gc = GC_heapsize - GC_used_heap_size_after_full\n                      > min_bytes_allocd() + GC_large_free_bytes;\n  }\n\n  /* Reset or increment counters for next cycle.      */\n  GC_n_attempts = 0;\n  GC_is_full_gc = FALSE;\n  GC_bytes_allocd_before_gc += GC_bytes_allocd;\n  GC_non_gc_bytes_at_gc = GC_non_gc_bytes;\n  GC_bytes_allocd = 0;\n  GC_bytes_dropped = 0;\n  GC_bytes_freed = 0;\n  GC_finalizer_bytes_freed = 0;\n\n  if (GC_on_collection_event)\n    GC_on_collection_event(GC_EVENT_RECLAIM_END);\n#ifndef NO_CLOCK\n  if (GC_print_stats) {\n    CLOCK_TYPE done_time;\n\n    GET_TIME(done_time);\n#  if !defined(SMALL_CONFIG) && !defined(GC_NO_FINALIZATION)\n    /* A convenient place to output finalization statistics.      */\n    GC_print_finalization_stats();\n#  endif\n    GC_log_printf(\"Finalize and initiate sweep took %lu ms %lu ns\"\n                  \" + %lu ms %lu ns\\n\",\n                  MS_TIME_DIFF(finalize_time, start_time),\n                  NS_FRAC_TIME_DIFF(finalize_time, start_time),\n                  MS_TIME_DIFF(done_time, finalize_time),\n                  NS_FRAC_TIME_DIFF(done_time, finalize_time));\n  }\n#elif !defined(SMALL_CONFIG) && !defined(GC_NO_FINALIZATION)\n  if (GC_print_stats)\n    GC_print_finalization_stats();\n#endif\n}\n\n/* Note: accessed with the allocator lock held. */\nSTATIC word GC_heapsize_at_forced_unmap = 0;\n\n/* Note: if stop_func is 0 then GC_default_stop_func is used instead. */\nSTATIC GC_bool\nGC_try_to_collect_general(GC_stop_func stop_func, GC_bool force_unmap)\n{\n  GC_bool result;\n#ifdef USE_MUNMAP\n  unsigned old_unmap_threshold;\n#endif\n  IF_CANCEL(int cancel_state;)\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  if (GC_debugging_started)\n    GC_print_all_smashed();\n  GC_INVOKE_FINALIZERS();\n  LOCK();\n  if (force_unmap) {\n    /* Record current heap size to make heap growth more conservative */\n    /* afterwards (as if the heap is growing from zero size again).   */\n    GC_heapsize_at_forced_unmap = GC_heapsize;\n  }\n  DISABLE_CANCEL(cancel_state);\n#ifdef USE_MUNMAP\n  old_unmap_threshold = GC_unmap_threshold;\n  if (force_unmap || (GC_force_unmap_on_gcollect && old_unmap_threshold > 0))\n    GC_unmap_threshold = 1; /* unmap as much as possible */\n#endif\n  ENTER_GC();\n  /* Minimize junk left in my registers.      */\n  GC_noop6(0, 0, 0, 0, 0, 0);\n  result = GC_try_to_collect_inner(stop_func != 0 ? stop_func\n                                                  : GC_default_stop_func);\n  EXIT_GC();\n#ifdef USE_MUNMAP\n  /* Restore it.  */\n  GC_unmap_threshold = old_unmap_threshold;\n#endif\n  RESTORE_CANCEL(cancel_state);\n  UNLOCK();\n  if (result) {\n    if (GC_debugging_started)\n      GC_print_all_smashed();\n    GC_INVOKE_FINALIZERS();\n  }\n  return result;\n}\n\n/* Externally callable routines to invoke full, stop-the-world collection. */\n\nGC_API int GC_CALL\nGC_try_to_collect(GC_stop_func stop_func)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(stop_func));\n  return (int)GC_try_to_collect_general(stop_func, FALSE);\n}\n\nGC_API void GC_CALL\nGC_gcollect(void)\n{\n  /* Zero is passed as stop_func to get GC_default_stop_func value    */\n  /* while holding the allocator lock (to prevent data race).         */\n  (void)GC_try_to_collect_general(0, FALSE);\n  if (get_have_errors())\n    GC_print_all_errors();\n}\n\nGC_API void GC_CALL\nGC_gcollect_and_unmap(void)\n{\n  /* Collect and force memory unmapping to OS. */\n  (void)GC_try_to_collect_general(GC_never_stop_func, TRUE);\n}\n\nGC_INNER ptr_t\nGC_os_get_mem(size_t bytes)\n{\n  ptr_t space;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  space = (ptr_t)GET_MEM(bytes); /* HBLKSIZE-aligned */\n  if (EXPECT(NULL == space, FALSE))\n    return NULL;\n#ifdef USE_PROC_FOR_LIBRARIES\n  /* Add HBLKSIZE aligned, GET_MEM-generated block to GC_our_memory. */\n  if (GC_n_memory >= MAX_HEAP_SECTS)\n    ABORT(\"Too many GC-allocated memory sections: Increase MAX_HEAP_SECTS\");\n  GC_our_memory[GC_n_memory].hs_start = space;\n  GC_our_memory[GC_n_memory].hs_bytes = bytes;\n  GC_n_memory++;\n#endif\n  GC_our_mem_bytes += bytes;\n  GC_VERBOSE_LOG_PRINTF(\"Got %lu bytes from OS\\n\", (unsigned long)bytes);\n  return space;\n}\n\n/* Use the chunk of memory starting at h of size sz as part of the      */\n/* heap.  Assumes h is HBLKSIZE aligned, sz is a multiple of HBLKSIZE.  */\nSTATIC void\nGC_add_to_heap(struct hblk *h, size_t sz)\n{\n  hdr *hhdr;\n  ptr_t endp;\n  size_t old_capacity = 0;\n  void *old_heap_sects = NULL;\n#ifdef GC_ASSERTIONS\n  size_t i;\n#endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(ADDR(h) % HBLKSIZE == 0);\n  GC_ASSERT(sz % HBLKSIZE == 0);\n  GC_ASSERT(sz > 0);\n  GC_ASSERT(GC_all_nils != NULL);\n\n  if (EXPECT(GC_n_heap_sects == GC_capacity_heap_sects, FALSE)) {\n    /* Allocate new GC_heap_sects with sufficient capacity.   */\n#ifndef INITIAL_HEAP_SECTS\n#  define INITIAL_HEAP_SECTS 32\n#endif\n    size_t new_capacity\n        = GC_n_heap_sects > 0 ? GC_n_heap_sects * 2 : INITIAL_HEAP_SECTS;\n    void *new_heap_sects\n        = GC_scratch_alloc(new_capacity * sizeof(struct HeapSect));\n\n    if (NULL == new_heap_sects) {\n      /* Retry with smaller yet sufficient capacity.  */\n      new_capacity = GC_n_heap_sects + INITIAL_HEAP_SECTS;\n      new_heap_sects\n          = GC_scratch_alloc(new_capacity * sizeof(struct HeapSect));\n      if (NULL == new_heap_sects)\n        ABORT(\"Insufficient memory for heap sections\");\n    }\n    old_capacity = GC_capacity_heap_sects;\n    old_heap_sects = GC_heap_sects;\n    /* Transfer GC_heap_sects contents to the newly allocated array.  */\n    if (GC_n_heap_sects > 0)\n      BCOPY(old_heap_sects, new_heap_sects,\n            GC_n_heap_sects * sizeof(struct HeapSect));\n    GC_capacity_heap_sects = new_capacity;\n    GC_heap_sects = (struct HeapSect *)new_heap_sects;\n    GC_COND_LOG_PRINTF(\"Grew heap sections array to %lu elements\\n\",\n                       (unsigned long)new_capacity);\n  }\n\n  while (EXPECT(ADDR(h) <= HBLKSIZE, FALSE)) {\n    /* Can't handle memory near address zero. */\n    ++h;\n    sz -= HBLKSIZE;\n    if (0 == sz)\n      return;\n  }\n  while (EXPECT(ADDR(h) >= GC_WORD_MAX - sz, FALSE)) {\n    /* Prevent overflow when calculating endp.  */\n    sz -= HBLKSIZE;\n    if (0 == sz)\n      return;\n  }\n  endp = (ptr_t)h + sz;\n\n  hhdr = GC_install_header(h);\n  if (EXPECT(NULL == hhdr, FALSE)) {\n    /* This is extremely unlikely. Can't add it.  This will         */\n    /* almost certainly result in a 0 return from the allocator,    */\n    /* which is entirely appropriate.                               */\n    return;\n  }\n#ifdef GC_ASSERTIONS\n  /* Ensure no intersection between sections.       */\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    ptr_t hs_start = GC_heap_sects[i].hs_start;\n    ptr_t hs_end = hs_start + GC_heap_sects[i].hs_bytes;\n\n    GC_ASSERT(!(ADDR_INSIDE((ptr_t)h, hs_start, hs_end)\n                || (ADDR_LT(hs_start, endp) && ADDR_GE(hs_end, endp))\n                || (ADDR_LT((ptr_t)h, hs_start) && ADDR_LT(hs_end, endp))));\n  }\n#endif\n  GC_heap_sects[GC_n_heap_sects].hs_start = (ptr_t)h;\n  GC_heap_sects[GC_n_heap_sects].hs_bytes = sz;\n  GC_n_heap_sects++;\n  hhdr->hb_sz = sz;\n  hhdr->hb_flags = 0;\n  GC_freehblk(h);\n  GC_heapsize += sz;\n\n  if (ADDR_GE((ptr_t)GC_least_plausible_heap_addr, (ptr_t)h)\n      || EXPECT(NULL == GC_least_plausible_heap_addr, FALSE)) {\n    /* Making it a little smaller than necessary prevents us from   */\n    /* getting a false hit from the variable itself.  There is some */\n    /* unintentional reflection here.                               */\n    GC_least_plausible_heap_addr = (ptr_t)h - sizeof(ptr_t);\n  }\n  if (ADDR_LT((ptr_t)GC_greatest_plausible_heap_addr, endp)) {\n    GC_greatest_plausible_heap_addr = endp;\n  }\n#ifdef SET_REAL_HEAP_BOUNDS\n  if (ADDR(h) < GC_least_real_heap_addr\n      || EXPECT(0 == GC_least_real_heap_addr, FALSE))\n    GC_least_real_heap_addr = ADDR(h) - sizeof(ptr_t);\n  if (GC_greatest_real_heap_addr < ADDR(endp)) {\n#  ifdef INCLUDE_LINUX_THREAD_DESCR\n    /* Avoid heap intersection with the static data roots. */\n    GC_exclude_static_roots_inner((ptr_t)h, endp);\n#  endif\n    GC_greatest_real_heap_addr = ADDR(endp);\n  }\n#endif\n  GC_handle_protected_regions_limit();\n  if (EXPECT(old_capacity > 0, FALSE)) {\n#ifndef GWW_VDB\n    /* Recycling may call GC_add_to_heap() again but should not     */\n    /* cause resizing of GC_heap_sects.                             */\n    GC_scratch_recycle_no_gww(old_heap_sects,\n                              old_capacity * sizeof(struct HeapSect));\n#else\n    /* TODO: implement GWW-aware recycling as in alloc_mark_stack */\n    GC_noop1_ptr(old_heap_sects);\n#endif\n  }\n}\n\n#if !defined(NO_DEBUGGING)\nvoid\nGC_print_heap_sects(void)\n{\n  size_t i;\n\n  GC_printf(\"Total heap size: %lu\" IF_USE_MUNMAP(\" (%lu unmapped)\") \"\\n\",\n            (unsigned long)GC_heapsize /*, */\n                COMMA_IF_USE_MUNMAP((unsigned long)GC_unmapped_bytes));\n\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    ptr_t start = GC_heap_sects[i].hs_start;\n    size_t len = GC_heap_sects[i].hs_bytes;\n    struct hblk *h;\n    unsigned nbl = 0;\n\n    for (h = (struct hblk *)start; ADDR_LT((ptr_t)h, start + len); h++) {\n      if (GC_is_black_listed(h, HBLKSIZE))\n        nbl++;\n    }\n    GC_printf(\"Section %u from %p to %p %u/%lu blacklisted\\n\", (unsigned)i,\n              (void *)start, (void *)&start[len], nbl,\n              (unsigned long)divHBLKSZ(len));\n  }\n}\n#endif\n\nvoid *GC_least_plausible_heap_addr = MAKE_CPTR(GC_WORD_MAX);\nvoid *GC_greatest_plausible_heap_addr = NULL;\n\nSTATIC word GC_max_heapsize = 0;\n\nGC_API void GC_CALL\nGC_set_max_heap_size(GC_word n)\n{\n  GC_max_heapsize = n;\n}\n\nword GC_max_retries = 0;\n\nGC_INNER void\nGC_scratch_recycle_inner(void *ptr, size_t sz)\n{\n  size_t page_offset;\n  size_t displ = 0;\n  size_t recycled_bytes;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == ptr)\n    return;\n\n  GC_ASSERT(sz != 0);\n  GC_ASSERT(GC_page_size != 0);\n  /* TODO: Assert correct memory flags if GWW_VDB */\n  page_offset = ADDR(ptr) & (GC_page_size - 1);\n  if (page_offset != 0)\n    displ = GC_page_size - page_offset;\n  recycled_bytes = sz > displ ? (sz - displ) & ~(GC_page_size - 1) : 0;\n  GC_COND_LOG_PRINTF(\"Recycle %lu/%lu scratch-allocated bytes at %p\\n\",\n                     (unsigned long)recycled_bytes, (unsigned long)sz, ptr);\n  if (recycled_bytes > 0)\n    GC_add_to_heap((struct hblk *)((ptr_t)ptr + displ), recycled_bytes);\n}\n\n/* This explicitly increases the size of the heap.  It is used          */\n/* internally, but may also be invoked from GC_expand_hp by the user.   */\n/* The argument is in units of HBLKSIZE (zero is treated as 1).         */\n/* Returns FALSE on failure.                                            */\nGC_INNER GC_bool\nGC_expand_hp_inner(word n)\n{\n  size_t sz;\n  struct hblk *space;\n  /* Number of bytes by which we expect the heap to expand soon.  */\n  word expansion_slop;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_page_size != 0);\n  if (0 == n)\n    n = 1;\n  sz = ROUNDUP_PAGESIZE((size_t)n * HBLKSIZE);\n  GC_DBGLOG_PRINT_HEAP_IN_USE();\n  if (GC_max_heapsize != 0\n      && (GC_max_heapsize < (word)sz\n          || GC_heapsize > GC_max_heapsize - (word)sz)) {\n    /* Exceeded the self-imposed limit.     */\n    return FALSE;\n  }\n  space = (struct hblk *)GC_os_get_mem(sz);\n  if (EXPECT(NULL == space, FALSE)) {\n    WARN(\"Failed to expand heap by %\" WARN_PRIuPTR \" KiB\\n\", sz >> 10);\n    return FALSE;\n  }\n  GC_last_heap_growth_gc_no = GC_gc_no;\n  GC_INFOLOG_PRINTF(\"Grow heap to %lu KiB after %lu bytes allocated\\n\",\n                    TO_KiB_UL(GC_heapsize + sz),\n                    (unsigned long)GC_bytes_allocd);\n\n  /* Adjust heap limits generously for blacklisting to work better.   */\n  /* GC_add_to_heap performs minimal adjustment needed for            */\n  /* correctness.                                                     */\n  expansion_slop = min_bytes_allocd() + 4 * MAXHINCR * HBLKSIZE;\n  if ((0 == GC_last_heap_addr && (ADDR(space) & SIGNB) == 0)\n      || (GC_last_heap_addr != 0 && GC_last_heap_addr < ADDR(space))) {\n    /* Assume the heap is growing up. */\n    if (EXPECT(ADDR(space) < GC_WORD_MAX - (sz + expansion_slop), TRUE)) {\n      ptr_t new_limit = (ptr_t)space + sz + expansion_slop;\n\n      if (ADDR_LT((ptr_t)GC_greatest_plausible_heap_addr, new_limit))\n        GC_greatest_plausible_heap_addr = new_limit;\n    }\n  } else {\n    /* Heap is growing down.  */\n    if (EXPECT(ADDR(space) > expansion_slop + sizeof(ptr_t), TRUE)) {\n      ptr_t new_limit = (ptr_t)space - expansion_slop - sizeof(ptr_t);\n\n      if (ADDR_LT(new_limit, (ptr_t)GC_least_plausible_heap_addr))\n        GC_least_plausible_heap_addr = new_limit;\n    }\n  }\n  GC_last_heap_addr = ADDR(space);\n\n  GC_add_to_heap(space, sz);\n  if (GC_on_heap_resize)\n    (*GC_on_heap_resize)(GC_heapsize);\n\n  return TRUE;\n}\n\n/* Really returns a bool, but it's externally visible, so that's clumsy. */\nGC_API int GC_CALL\nGC_expand_hp(size_t bytes)\n{\n  size_t n_blocks = OBJ_SZ_TO_BLOCKS_CHECKED(bytes);\n  word old_heapsize;\n  GC_bool result;\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  LOCK();\n  old_heapsize = GC_heapsize;\n  result = GC_expand_hp_inner(n_blocks);\n  if (result) {\n    GC_requested_heapsize += bytes;\n    if (GC_dont_gc) {\n      /* Do not call WARN if the heap growth is intentional.  */\n      GC_ASSERT(GC_heapsize >= old_heapsize);\n      GC_heapsize_on_gc_disable += GC_heapsize - old_heapsize;\n    }\n  }\n  UNLOCK();\n  return (int)result;\n}\n\n/* How many consecutive GC/expansion failures?  Reset by GC_allochblk.  */\nGC_INNER unsigned GC_fail_count = 0;\n\n/* The minimum value of the ratio of allocated bytes since the latest   */\n/* GC to the amount of finalizers created since that GC which triggers  */\n/* the collection instead heap expansion.  Has no effect in the         */\n/* incremental mode.                                                    */\n#if defined(GC_ALLOCD_BYTES_PER_FINALIZER) && !defined(CPPCHECK)\nSTATIC word GC_allocd_bytes_per_finalizer = GC_ALLOCD_BYTES_PER_FINALIZER;\n#else\nSTATIC word GC_allocd_bytes_per_finalizer = 10000;\n#endif\n\nGC_API void GC_CALL\nGC_set_allocd_bytes_per_finalizer(GC_word value)\n{\n  GC_allocd_bytes_per_finalizer = value;\n}\n\nGC_API GC_word GC_CALL\nGC_get_allocd_bytes_per_finalizer(void)\n{\n  return GC_allocd_bytes_per_finalizer;\n}\n\nstatic word last_fo_entries = 0;\nstatic word last_bytes_finalized = 0;\n\n/* Collect or expand heap in an attempt make the indicated number of    */\n/* free blocks available.  Should be called until the blocks are        */\n/* available (setting retry value to TRUE unless this is the first call */\n/* in a loop) or until it fails by returning FALSE.  The flags argument */\n/* should be IGNORE_OFF_PAGE or 0.                                      */\nGC_INNER GC_bool\nGC_collect_or_expand(word needed_blocks, unsigned flags, GC_bool retry)\n{\n  GC_bool gc_not_stopped = TRUE;\n  word blocks_to_get;\n  IF_CANCEL(int cancel_state;)\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n  DISABLE_CANCEL(cancel_state);\n  if (!GC_incremental && !GC_dont_gc\n      && ((GC_dont_expand && GC_bytes_allocd > 0)\n          || (GC_fo_entries > last_fo_entries\n              && (last_bytes_finalized | GC_bytes_finalized) != 0\n              && (GC_fo_entries - last_fo_entries)\n                         * GC_allocd_bytes_per_finalizer\n                     > GC_bytes_allocd)\n          || GC_should_collect())) {\n    /* Try to do a full collection using 'default' stop_func (unless  */\n    /* nothing has been allocated since the latest collection or heap */\n    /* expansion is disabled).                                        */\n    gc_not_stopped = GC_try_to_collect_inner(\n        GC_bytes_allocd > 0 && (!GC_dont_expand || !retry)\n            ? GC_default_stop_func\n            : GC_never_stop_func);\n    if (gc_not_stopped || !retry) {\n      /* Either the collection hasn't been aborted or this is the     */\n      /* first attempt (in a loop).                                   */\n      last_fo_entries = GC_fo_entries;\n      last_bytes_finalized = GC_bytes_finalized;\n      RESTORE_CANCEL(cancel_state);\n      return TRUE;\n    }\n  }\n\n  blocks_to_get = (GC_heapsize - GC_heapsize_at_forced_unmap)\n                      / (HBLKSIZE * GC_free_space_divisor)\n                  + needed_blocks;\n  if (blocks_to_get > MAXHINCR) {\n    word slop;\n\n    /* Get the minimum required to make it likely that we can satisfy */\n    /* the current request in the presence of black-listing.          */\n    /* This will probably be more than MAXHINCR.                      */\n    if ((flags & IGNORE_OFF_PAGE) != 0) {\n      slop = 4;\n    } else {\n      slop = 2 * divHBLKSZ(BL_LIMIT);\n      if (slop > needed_blocks)\n        slop = needed_blocks;\n    }\n    if (needed_blocks + slop > MAXHINCR) {\n      blocks_to_get = needed_blocks + slop;\n    } else {\n      blocks_to_get = MAXHINCR;\n    }\n    if (blocks_to_get > divHBLKSZ(GC_WORD_MAX))\n      blocks_to_get = divHBLKSZ(GC_WORD_MAX);\n  } else if (blocks_to_get < MINHINCR) {\n    blocks_to_get = MINHINCR;\n  }\n\n  if (GC_max_heapsize > GC_heapsize) {\n    word max_get_blocks = divHBLKSZ(GC_max_heapsize - GC_heapsize);\n    if (blocks_to_get > max_get_blocks)\n      blocks_to_get\n          = max_get_blocks > needed_blocks ? max_get_blocks : needed_blocks;\n  }\n\n#ifdef USE_MUNMAP\n  if (GC_unmap_threshold > 1) {\n    /* Return as much memory to the OS as possible before   */\n    /* trying to get memory from it.                        */\n    GC_unmap_old(0);\n  }\n#endif\n  if (!GC_expand_hp_inner(blocks_to_get)\n      && (blocks_to_get == needed_blocks\n          || !GC_expand_hp_inner(needed_blocks))) {\n    if (!gc_not_stopped) {\n      /* Don't increment GC_fail_count here (and no warning).     */\n      GC_gcollect_inner();\n      GC_ASSERT(0 == GC_bytes_allocd);\n    } else if (GC_fail_count++ < GC_max_retries) {\n      WARN(\"Out of Memory!  Trying to continue...\\n\", 0);\n      GC_gcollect_inner();\n    } else {\n#ifdef USE_MUNMAP\n      GC_ASSERT(GC_heapsize >= GC_unmapped_bytes);\n#endif\n#if !defined(SMALL_CONFIG) && (CPP_WORDSZ >= 32)\n#  define MAX_HEAPSIZE_WARNED_IN_BYTES (5 << 20) /* 5 MB */\n\n      if (GC_heapsize > (word)MAX_HEAPSIZE_WARNED_IN_BYTES) {\n        WARN(\"Out of Memory! Heap size: %\" WARN_PRIuPTR \" MiB.\"\n             \" Returning NULL!\\n\",\n             (GC_heapsize - GC_unmapped_bytes) >> 20);\n      } else\n#endif\n      /* else */ {\n        WARN(\"Out of Memory! Heap size: %\" WARN_PRIuPTR \" bytes.\"\n             \" Returning NULL!\\n\",\n             GC_heapsize - GC_unmapped_bytes);\n      }\n      RESTORE_CANCEL(cancel_state);\n      return FALSE;\n    }\n  } else if (GC_fail_count) {\n    GC_COND_LOG_PRINTF(\"Memory available again...\\n\");\n  }\n  RESTORE_CANCEL(cancel_state);\n  return TRUE;\n}\n\nGC_INNER ptr_t\nGC_allocobj(size_t lg, int k)\n{\n  void **flh = &GC_obj_kinds[k].ok_freelist[lg];\n  GC_bool tried_minor = FALSE;\n  GC_bool retry = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n  if (EXPECT(0 == lg, FALSE))\n    return NULL;\n\n  while (NULL == *flh) {\n    ENTER_GC();\n#ifndef GC_DISABLE_INCREMENTAL\n    if (GC_incremental && GC_time_limit != GC_TIME_UNLIMITED && !GC_dont_gc) {\n      /* True incremental mode, not just generational.      */\n      /* Do our share of marking work.                      */\n      GC_collect_a_little_inner(1);\n    }\n#endif\n    /* Sweep blocks for objects of this size. */\n    GC_ASSERT(!GC_is_full_gc || NULL == GC_obj_kinds[k].ok_reclaim_list\n              || NULL == GC_obj_kinds[k].ok_reclaim_list[lg]);\n    GC_continue_reclaim(lg, k);\n    EXIT_GC();\n#if defined(CPPCHECK)\n    GC_noop1_ptr(&flh);\n#endif\n    if (NULL == *flh) {\n      GC_new_hblk(lg, k);\n#if defined(CPPCHECK)\n      GC_noop1_ptr(&flh);\n#endif\n      if (NULL == *flh) {\n        ENTER_GC();\n        if (GC_incremental && GC_time_limit == GC_TIME_UNLIMITED\n            && !tried_minor && !GC_dont_gc) {\n          GC_collect_a_little_inner(1);\n          tried_minor = TRUE;\n        } else {\n          if (!GC_collect_or_expand(1, 0 /* flags */, retry)) {\n            EXIT_GC();\n            return NULL;\n          }\n          retry = TRUE;\n        }\n        EXIT_GC();\n      }\n    }\n  }\n  /* Successful allocation; reset failure count.      */\n  GC_fail_count = 0;\n  return (ptr_t)(*flh);\n}\n"
        },
        {
          "name": "autogen.sh",
          "type": "blob",
          "size": 1.0078125,
          "content": "#!/bin/sh\nset -e\n\n# This script creates (or regenerates) configure (as well as aclocal.m4,\n# config.h.in, Makefile.in, etc.) missing in the source repository.\n#\n# If you compile from a distribution tarball, you can skip this.  Otherwise,\n# make sure that you have Autoconf, Automake and Libtool installed\n# on your system, and that the corresponding *.m4 files are visible\n# to the aclocal.  The latter can be achieved by using packages shipped by\n# your OS, or by installing custom versions of all four packages to the same\n# prefix.  Otherwise, you may need to invoke autoreconf with the appropriate\n# -I options to locate the required *.m4 files.\n\n# Install libtool.m4 and ltmain.sh in the build tree.  This command is needed\n# if autoreconf and libtoolize are available from the different directories.\n# Note: libtoolize might be missing on some platforms.\nif (type libtoolize) > /dev/null 2>&1; then\n  libtoolize -i -c\nelse\n  echo \"libtoolize is not found, ignoring!\"\nfi\n\nautoreconf -i\n\necho\necho \"Ready to run './configure'.\"\n"
        },
        {
          "name": "backgraph.c",
          "type": "blob",
          "size": 18.330078125,
          "content": "/*\n * Copyright (c) 2001 by Hewlett-Packard Company. All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/dbg_mlc.h\"\n\n/*\n * This implements a full, though not well-tuned, representation of the\n * backwards points-to graph.  This is used to test for non-GC-robust\n * data structures; the code is not used during normal garbage collection.\n *\n * One restriction is that we drop all back-edges from nodes with very\n * high in-degree, and simply add them add them to a list of such\n * nodes.  They are then treated as permanent roots.  If this by itself\n * doesn't introduce a space leak, then such nodes can't contribute to\n * a growing space leak.\n */\n\n#ifdef MAKE_BACK_GRAPH\n\n/* The maximum in-degree we handle directly.    */\n#  define MAX_IN 10\n\n#  if (!defined(DBG_HDRS_ALL)                                        \\\n       || (ALIGNMENT != CPP_PTRSZ / 8) /* || !defined(UNIX_LIKE) */) \\\n      && !defined(CPPCHECK)\n#    error The configuration does not support MAKE_BACK_GRAPH\n#  endif\n\n/* We store single back pointers directly in the object's oh_bg_ptr field. */\n/* If there is more than one ptr to an object, we store q or'ed with       */\n/* FLAG_MANY, where q is a pointer to a back_edges object.                 */\n/* Every once in a while we use a back_edges object even for a single      */\n/* pointer, since we need the other fields in the back_edges structure to  */\n/* be present in some fraction of the objects.  Otherwise we get serious   */\n/* performance issues.                                                     */\n#  define FLAG_MANY 2\n\ntypedef struct back_edges_struct {\n  /* Number of edges, including those in continuation structures.       */\n  word n_edges;\n\n  unsigned short flags;\n\n  /* Directly points to a reachable object; retain for the next GC.     */\n#  define RETAIN 1\n\n  /* If height > 0, then the GC_gc_no value when it was computed.       */\n  /* If it was computed this cycle, then it is current.  If it was      */\n  /* computed during the last cycle, then it represents the old height, */\n  /* which is only saved for live objects referenced by dead ones.      */\n  /* This may grow due to refs from newly dead objects.                 */\n  unsigned short height_gc_no;\n\n  /* Longest path through unreachable nodes to this node that we found  */\n  /* using depth first search.                                          */\n  GC_signed_word height;\n#  define HEIGHT_UNKNOWN (-2)\n#  define HEIGHT_IN_PROGRESS (-1)\n\n  ptr_t edges[MAX_IN];\n\n  /* Pointer to continuation structure; we use only the edges field in  */\n  /* the continuation.  Also used as a free-list link.                  */\n  struct back_edges_struct *cont;\n} back_edges;\n\n#  define MAX_BACK_EDGE_STRUCTS 100000\nstatic back_edges *back_edge_space = 0;\n\n/* Points to never-used back_edges space.       */\nSTATIC int GC_n_back_edge_structs = 0;\n\n/* Pointer to free list of deallocated back_edges structures.   */\nstatic back_edges *avail_back_edges = 0;\n\n/* Allocate a new back edge structure.  Should be more sophisticated    */\n/* if this were production code.                                        */\nstatic back_edges *\nnew_back_edges(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (0 == back_edge_space) {\n    size_t bytes_to_get\n        = ROUNDUP_PAGESIZE_IF_MMAP(MAX_BACK_EDGE_STRUCTS * sizeof(back_edges));\n\n    GC_ASSERT(GC_page_size != 0);\n    back_edge_space = (back_edges *)GC_os_get_mem(bytes_to_get);\n    if (NULL == back_edge_space)\n      ABORT(\"Insufficient memory for back edges\");\n  }\n  if (avail_back_edges != 0) {\n    back_edges *result = avail_back_edges;\n    avail_back_edges = result->cont;\n    result->cont = 0;\n    return result;\n  }\n  if (GC_n_back_edge_structs >= MAX_BACK_EDGE_STRUCTS - 1) {\n    ABORT(\"Needed too much space for back edges: adjust \"\n          \"MAX_BACK_EDGE_STRUCTS\");\n  }\n  return back_edge_space + (GC_n_back_edge_structs++);\n}\n\n/* Deallocate p and its associated continuation structures.     */\nstatic void\ndeallocate_back_edges(back_edges *p)\n{\n  back_edges *last;\n\n  for (last = p; last->cont != NULL;)\n    last = last->cont;\n\n  last->cont = avail_back_edges;\n  avail_back_edges = p;\n}\n\n/* Table of objects that are currently on the depth-first search        */\n/* stack.  Only objects with in-degree one are in this table.           */\n/* Other objects are identified using HEIGHT_IN_PROGRESS.               */\n/* FIXME: This data structure NEEDS IMPROVEMENT.                        */\nstatic ptr_t *in_progress_space = 0;\n#  define INITIAL_IN_PROGRESS 10000\nstatic size_t in_progress_size = 0;\nstatic size_t n_in_progress = 0;\n\nstatic void\npush_in_progress(ptr_t p)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (n_in_progress >= in_progress_size) {\n    ptr_t *new_in_progress_space;\n\n    GC_ASSERT(GC_page_size != 0);\n    if (NULL == in_progress_space) {\n      in_progress_size\n          = ROUNDUP_PAGESIZE_IF_MMAP(INITIAL_IN_PROGRESS * sizeof(ptr_t))\n            / sizeof(ptr_t);\n      new_in_progress_space\n          = (ptr_t *)GC_os_get_mem(in_progress_size * sizeof(ptr_t));\n    } else {\n      in_progress_size *= 2;\n      new_in_progress_space\n          = (ptr_t *)GC_os_get_mem(in_progress_size * sizeof(ptr_t));\n      if (new_in_progress_space != NULL)\n        BCOPY(in_progress_space, new_in_progress_space,\n              n_in_progress * sizeof(ptr_t));\n    }\n#  ifndef GWW_VDB\n    GC_scratch_recycle_no_gww(in_progress_space,\n                              n_in_progress * sizeof(ptr_t));\n#  elif defined(LINT2)\n    /* TODO: implement GWW-aware recycling as in alloc_mark_stack */\n    GC_noop1_ptr(in_progress_space);\n#  endif\n    in_progress_space = new_in_progress_space;\n  }\n  if (in_progress_space == 0)\n    ABORT(\"MAKE_BACK_GRAPH: Out of in-progress space: \"\n          \"Huge linear data structure?\");\n  in_progress_space[n_in_progress++] = p;\n}\n\nstatic GC_bool\nis_in_progress(const char *p)\n{\n  size_t i;\n  for (i = 0; i < n_in_progress; ++i) {\n    if (in_progress_space[i] == p)\n      return TRUE;\n  }\n  return FALSE;\n}\n\nGC_INLINE void\npop_in_progress(ptr_t p)\n{\n#  ifndef GC_ASSERTIONS\n  UNUSED_ARG(p);\n#  endif\n  --n_in_progress;\n  GC_ASSERT(in_progress_space[n_in_progress] == p);\n}\n\n#  define GET_OH_BG_PTR(p) (ptr_t) GC_REVEAL_POINTER(((oh *)(p))->oh_bg_ptr)\n#  define SET_OH_BG_PTR(p, q) (((oh *)(p))->oh_bg_ptr = GC_HIDE_POINTER(q))\n\n/* Ensure that p has a back_edges structure associated with it. */\nstatic void\nensure_struct(ptr_t p)\n{\n  ptr_t old_back_ptr = GET_OH_BG_PTR(p);\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if ((ADDR(old_back_ptr) & FLAG_MANY) == 0) {\n    back_edges *be = new_back_edges();\n\n    be->flags = 0;\n#  if defined(CPPCHECK)\n    GC_noop1_ptr(&old_back_ptr);\n    /* Workaround a false positive that old_back_ptr cannot be null.  */\n#  endif\n    if (NULL == old_back_ptr) {\n      be->n_edges = 0;\n    } else {\n      be->n_edges = 1;\n      be->edges[0] = old_back_ptr;\n    }\n    be->height = HEIGHT_UNKNOWN;\n    be->height_gc_no = (unsigned short)(GC_gc_no - 1);\n    GC_ASSERT(ADDR_GE((ptr_t)be, (ptr_t)back_edge_space));\n    SET_OH_BG_PTR(p, CPTR_SET_FLAGS(be, FLAG_MANY));\n  }\n}\n\n/* Add the (forward) edge from p to q to the backward graph.  Both p    */\n/* q are pointers to the object base, i.e. pointers to an oh.           */\nstatic void\nadd_edge(ptr_t p, ptr_t q)\n{\n  ptr_t pred = GET_OH_BG_PTR(q);\n  back_edges *be, *be_cont;\n  word i;\n\n  GC_ASSERT(p == GC_base(p) && q == GC_base(q));\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_HAS_DEBUG_INFO(q) || !GC_HAS_DEBUG_INFO(p)) {\n    /* This is really a misinterpreted free-list link, since we saw   */\n    /* a pointer to a free list.  Don't overwrite it!                 */\n    return;\n  }\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(&pred);\n#  endif\n  if (NULL == pred) {\n    /* A not very random number we use to occasionally allocate a     */\n    /* back_edges structure even for a single backward edge.  This    */\n    /* prevents us from repeatedly tracing back through very long     */\n    /* chains, since we will have some place to store height and      */\n    /* in_progress flags along the way.                               */\n#  define GOT_LUCKY_NUMBER (((++random_number) & 0x7f) == 0)\n    static unsigned random_number = 13;\n\n    SET_OH_BG_PTR(q, p);\n    if (GOT_LUCKY_NUMBER)\n      ensure_struct(q);\n    return;\n  }\n\n  /* Check whether it was already in the list of predecessors. */\n  {\n    back_edges *e = (back_edges *)CPTR_CLEAR_FLAGS(pred, FLAG_MANY);\n    word n_edges;\n    word total;\n    int local = 0;\n\n    if ((ADDR(pred) & FLAG_MANY) != 0) {\n      n_edges = e->n_edges;\n    } else if ((COVERT_DATAFLOW(ADDR(pred)) & 1) == 0) {\n      /* A misinterpreted free-list link.     */\n      n_edges = 1;\n      local = -1;\n    } else {\n      n_edges = 0;\n    }\n    for (total = 0; total < n_edges; ++total) {\n      if (local == MAX_IN) {\n        e = e->cont;\n        local = 0;\n      }\n      if (local >= 0)\n        pred = e->edges[local++];\n      if (pred == p)\n        return;\n    }\n  }\n\n  ensure_struct(q);\n  be = (back_edges *)CPTR_CLEAR_FLAGS(GET_OH_BG_PTR(q), FLAG_MANY);\n  for (i = be->n_edges, be_cont = be; i > MAX_IN; i -= MAX_IN)\n    be_cont = be_cont->cont;\n  if (i == MAX_IN) {\n    be_cont->cont = new_back_edges();\n    be_cont = be_cont->cont;\n    i = 0;\n  }\n  be_cont->edges[i] = p;\n  be->n_edges++;\n#  ifdef DEBUG_PRINT_BIG_N_EDGES\n  if (GC_print_stats == VERBOSE && be->n_edges == 100) {\n    GC_err_printf(\"The following object has big in-degree:\\n\");\n    GC_print_heap_obj(q);\n  }\n#  endif\n}\n\ntypedef void (*per_object_func)(ptr_t p, size_t sz, word descr);\n\nstatic GC_CALLBACK void\nper_object_helper(struct hblk *h, void *fn_ptr)\n{\n  const hdr *hhdr = HDR(h);\n  word descr = hhdr->hb_descr;\n  per_object_func fn = *(per_object_func *)fn_ptr;\n  size_t sz = hhdr->hb_sz;\n  size_t i = 0;\n\n  do {\n    fn((ptr_t)(h->hb_body + i), sz, descr);\n    i += sz;\n  } while (i + sz <= HBLKSIZE);\n}\n\nGC_INLINE void\nGC_apply_to_each_object(per_object_func fn)\n{\n  GC_apply_to_all_blocks(per_object_helper, &fn);\n}\n\nstatic void\nreset_back_edge(ptr_t p, size_t sz, word descr)\n{\n  UNUSED_ARG(sz);\n  UNUSED_ARG(descr);\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Skip any free-list links, or dropped blocks.   */\n  if (GC_HAS_DEBUG_INFO(p)) {\n    ptr_t old_back_ptr = GET_OH_BG_PTR(p);\n\n    if ((ADDR(old_back_ptr) & FLAG_MANY) != 0) {\n      back_edges *be = (back_edges *)CPTR_CLEAR_FLAGS(old_back_ptr, FLAG_MANY);\n\n      if (!(be->flags & RETAIN)) {\n        deallocate_back_edges(be);\n        SET_OH_BG_PTR(p, NULL);\n      } else {\n        GC_ASSERT(GC_is_marked(p));\n\n        /* Back edges may point to objects that will not be retained.   */\n        /* Delete them for now, but remember the height.                */\n        /* Some will be added back at next GC.                          */\n        be->n_edges = 0;\n        if (be->cont != NULL) {\n          deallocate_back_edges(be->cont);\n          be->cont = NULL;\n        }\n\n        GC_ASSERT(GC_is_marked(p));\n        /* We only retain things for one GC cycle at a time.            */\n        be->flags &= (unsigned short)~RETAIN;\n      }\n    } else /* simple back pointer */ {\n      /* Clear to avoid dangling pointer. */\n      SET_OH_BG_PTR(p, NULL);\n    }\n  }\n}\n\nstatic void\nadd_back_edges(ptr_t p, size_t sz, word descr)\n{\n  ptr_t current_p = p + sizeof(oh);\n\n  /* For now, fix up non-length descriptors conservatively.     */\n  if ((descr & GC_DS_TAGS) != GC_DS_LENGTH) {\n    descr = sz;\n  }\n\n  for (; ADDR_LT(current_p, p + descr); current_p += sizeof(ptr_t)) {\n    ptr_t q;\n\n    LOAD_PTR_OR_CONTINUE(q, current_p);\n    FIXUP_POINTER(q);\n    if (GC_least_real_heap_addr < ADDR(q)\n        && ADDR(q) < GC_greatest_real_heap_addr) {\n      ptr_t target = (ptr_t)GC_base(q);\n\n      if (target != NULL)\n        add_edge(p, target);\n    }\n  }\n}\n\n/* Rebuild the representation of the backward reachability graph.       */\n/* Does not examine mark bits.  Can be called before GC.                */\nGC_INNER void\nGC_build_back_graph(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_apply_to_each_object(add_back_edges);\n}\n\n/* Return an approximation to the length of the longest simple path     */\n/* through unreachable objects to p.  We refer to this as the height    */\n/* of p.                                                                */\nstatic word\nbackwards_height(ptr_t p)\n{\n  word result;\n  ptr_t pred = GET_OH_BG_PTR(p);\n  back_edges *be;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(&pred);\n#  endif\n  if (NULL == pred)\n    return 1;\n  if ((ADDR(pred) & FLAG_MANY) == 0) {\n    if (is_in_progress(p)) {\n      /* DFS back edge, i.e. we followed an edge to an object already   */\n      /* on our stack: ignore.                                          */\n      return 0;\n    }\n    push_in_progress(p);\n    result = backwards_height(pred) + 1;\n    pop_in_progress(p);\n    return result;\n  }\n  be = (back_edges *)CPTR_CLEAR_FLAGS(pred, FLAG_MANY);\n  if (be->height >= 0 && be->height_gc_no == (unsigned short)GC_gc_no)\n    return (word)be->height;\n  /* Ignore back edges in DFS.  */\n  if (be->height == HEIGHT_IN_PROGRESS)\n    return 0;\n\n  result = be->height > 0 ? (word)be->height : 1U;\n  be->height = HEIGHT_IN_PROGRESS;\n\n  {\n    back_edges *e = be;\n    word n_edges;\n    word total;\n    int local = 0;\n\n    if ((ADDR(pred) & FLAG_MANY) != 0) {\n      n_edges = e->n_edges;\n    } else if ((ADDR(pred) & 1) == 0) {\n      /* A misinterpreted free-list link.     */\n      n_edges = 1;\n      local = -1;\n    } else {\n      n_edges = 0;\n    }\n    for (total = 0; total < n_edges; ++total) {\n      word this_height;\n      if (local == MAX_IN) {\n        e = e->cont;\n        local = 0;\n      }\n      if (local >= 0)\n        pred = e->edges[local++];\n\n      /* Execute the following once for each predecessor pred of p    */\n      /* in the points-to graph.                                      */\n      if (GC_is_marked(pred) && (ADDR(GET_OH_BG_PTR(p)) & FLAG_MANY) == 0) {\n        GC_COND_LOG_PRINTF(\"Found bogus pointer from %p to %p\\n\", (void *)pred,\n                           (void *)p);\n        /* Reachable object \"points to\" unreachable one.              */\n        /* Could be caused by our lax treatment of GC descriptors.    */\n        this_height = 1;\n      } else {\n        this_height = backwards_height(pred);\n      }\n      if (this_height >= result)\n        result = this_height + 1;\n    }\n  }\n\n  be->height = (GC_signed_word)result;\n  be->height_gc_no = (unsigned short)GC_gc_no;\n  return result;\n}\n\nSTATIC word GC_max_height = 0;\nSTATIC ptr_t GC_deepest_obj = NULL;\n\n/* Compute the maximum height of every unreachable predecessor p of a   */\n/* reachable object.  Arrange to save the heights of all such objects p */\n/* so that they can be used in calculating the height of objects in the */\n/* next GC.                                                             */\n/* Set GC_max_height to be the maximum height we encounter, and         */\n/* GC_deepest_obj to be the corresponding object.                       */\nstatic void\nupdate_max_height(ptr_t p, size_t sz, word descr)\n{\n  UNUSED_ARG(sz);\n  UNUSED_ARG(descr);\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_is_marked(p) && GC_HAS_DEBUG_INFO(p)) {\n    word p_height = 0;\n    ptr_t p_deepest_obj = 0;\n    ptr_t back_ptr;\n    back_edges *be = 0;\n\n    /* If we remembered a height last time, use it as a minimum.        */\n    /* It may have increased due to newly unreachable chains pointing   */\n    /* to p, but it can't have decreased.                               */\n    back_ptr = GET_OH_BG_PTR(p);\n#  if defined(CPPCHECK)\n    GC_noop1_ptr(&back_ptr);\n#  endif\n    if (back_ptr != NULL && (ADDR(back_ptr) & FLAG_MANY) != 0) {\n      be = (back_edges *)CPTR_CLEAR_FLAGS(back_ptr, FLAG_MANY);\n      if (be->height != HEIGHT_UNKNOWN)\n        p_height = (word)be->height;\n    }\n\n    {\n      ptr_t pred = back_ptr;\n      back_edges *e = (back_edges *)CPTR_CLEAR_FLAGS(pred, FLAG_MANY);\n      word n_edges;\n      word total;\n      int local = 0;\n\n      if ((ADDR(pred) & FLAG_MANY) != 0) {\n        n_edges = e->n_edges;\n      } else if (pred != NULL && (ADDR(pred) & 1) == 0) {\n        /* A misinterpreted free-list link.     */\n        n_edges = 1;\n        local = -1;\n      } else {\n        n_edges = 0;\n      }\n      for (total = 0; total < n_edges; ++total) {\n        if (local == MAX_IN) {\n          e = e->cont;\n          local = 0;\n        }\n        if (local >= 0)\n          pred = e->edges[local++];\n\n        /* Execute the following once for each predecessor pred of p    */\n        /* in the points-to graph.                                      */\n        if (!GC_is_marked(pred) && GC_HAS_DEBUG_INFO(pred)) {\n          word this_height = backwards_height(pred);\n\n          if (this_height > p_height) {\n            p_height = this_height;\n            p_deepest_obj = pred;\n          }\n        }\n      }\n    }\n\n    if (p_height > 0) {\n      /* Remember the height for next time. */\n      if (NULL == be) {\n        ensure_struct(p);\n        back_ptr = GET_OH_BG_PTR(p);\n        be = (back_edges *)CPTR_CLEAR_FLAGS(back_ptr, FLAG_MANY);\n      }\n      be->flags |= RETAIN;\n      be->height = (GC_signed_word)p_height;\n      be->height_gc_no = (unsigned short)GC_gc_no;\n    }\n    if (p_height > GC_max_height) {\n      GC_max_height = p_height;\n      GC_deepest_obj = p_deepest_obj;\n    }\n  }\n}\n\nSTATIC word GC_max_max_height = 0;\n\nGC_INNER void\nGC_traverse_back_graph(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_max_height = 0;\n  GC_apply_to_each_object(update_max_height);\n  if (GC_deepest_obj != NULL) {\n    /* Keep the pointer until we can print it.  */\n    GC_set_mark_bit(GC_deepest_obj);\n  }\n}\n\nvoid\nGC_print_back_graph_stats(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_printf(\"Maximum backwards height of reachable objects\"\n            \" at GC #%lu is %lu\\n\",\n            (unsigned long)GC_gc_no, (unsigned long)GC_max_height);\n  if (GC_max_height > GC_max_max_height) {\n    ptr_t obj = GC_deepest_obj;\n\n    GC_max_max_height = GC_max_height;\n    UNLOCK();\n    GC_err_printf(\n        \"The following unreachable object is last in a longest chain \"\n        \"of unreachable objects:\\n\");\n    GC_print_heap_obj(obj);\n    LOCK();\n  }\n  GC_COND_LOG_PRINTF(\"Needed max total of %d back-edge structs\\n\",\n                     GC_n_back_edge_structs);\n  GC_apply_to_each_object(reset_back_edge);\n  GC_deepest_obj = NULL;\n}\n\n#endif /* MAKE_BACK_GRAPH */\n"
        },
        {
          "name": "bdw-gc.pc.in",
          "type": "blob",
          "size": 0.30078125,
          "content": "prefix=@prefix@\nexec_prefix=@exec_prefix@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: Boehm-Demers-Weiser Conservative Garbage Collector\nDescription: A garbage collector for C and C++\nVersion: @PACKAGE_VERSION@\nLibs: -L${libdir} -lgc @THREADDLLIBS@\nLibs.private: @ATOMIC_OPS_LIBS@\nCflags: -I${includedir}\n"
        },
        {
          "name": "blacklst.c",
          "type": "blob",
          "size": 10.294921875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/*\n * We maintain several hash tables of hblks that have had false hits.\n * Each contains one bit per hash bucket;  If any page in the bucket\n * has had a false hit, we assume that all of them have.\n * See the definition of page_hash_table in gc_priv.h.\n * False hits from the stack(s) are much more dangerous than false hits\n * from elsewhere, since the former can pin a large object that spans the\n * block, even though it does not start on the dangerous block.\n */\n\n/* Externally callable routines are:    */\n/* - GC_add_to_black_list_normal,       */\n/* - GC_add_to_black_list_stack,        */\n/* - GC_promote_black_lists.            */\n\n/* Pointers to individual tables.  We replace one table by another by   */\n/* switching these pointers.                                            */\n\n/* Nonstack false references seen at last full collection.      */\nSTATIC word *GC_old_normal_bl = NULL;\n\n/* Nonstack false references seen since last full collection.   */\nSTATIC word *GC_incomplete_normal_bl = NULL;\n\nSTATIC word *GC_old_stack_bl = NULL;\nSTATIC word *GC_incomplete_stack_bl = NULL;\n\n/* Number of bytes on stack blacklist.  */\nSTATIC word GC_total_stack_black_listed = 0;\n\nGC_INNER word GC_black_list_spacing = MINHINCR * HBLKSIZE; /* initial guess */\n\nSTATIC void GC_clear_bl(word *);\n\nGC_INNER void\nGC_default_print_heap_obj_proc(ptr_t p)\n{\n  ptr_t base = (ptr_t)GC_base(p);\n  int kind = HDR(base)->hb_obj_kind;\n\n  GC_err_printf(\"object at %p of appr. %lu bytes (%s)\\n\", (void *)base,\n                (unsigned long)GC_size(base),\n                kind == PTRFREE          ? \"atomic\"\n                : IS_UNCOLLECTABLE(kind) ? \"uncollectable\"\n                                         : \"composite\");\n}\n\nGC_INNER void (*GC_print_heap_obj)(ptr_t p) = GC_default_print_heap_obj_proc;\n\n#ifdef PRINT_BLACK_LIST\nSTATIC void\nGC_print_blacklisted_ptr(ptr_t p, ptr_t source, const char *kind_str)\n{\n  ptr_t base = (ptr_t)GC_base(source);\n\n  if (0 == base) {\n    GC_err_printf(\"Black listing (%s) %p referenced from %p in %s\\n\", kind_str,\n                  (void *)p, (void *)source,\n                  NULL != source ? \"root set\" : \"register\");\n  } else {\n    /* FIXME: We can't call the debug version of GC_print_heap_obj  */\n    /* (with PRINT_CALL_CHAIN) here because the allocator lock is   */\n    /* held and the world is stopped.                               */\n    GC_err_printf(\"Black listing (%s) %p referenced from %p in\"\n                  \" object at %p of appr. %lu bytes\\n\",\n                  kind_str, (void *)p, (void *)source, (void *)base,\n                  (unsigned long)GC_size(base));\n  }\n}\n#endif /* PRINT_BLACK_LIST */\n\nGC_INNER void\nGC_bl_init_no_interiors(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == GC_incomplete_normal_bl) {\n    GC_old_normal_bl = (word *)GC_scratch_alloc(sizeof(page_hash_table));\n    GC_incomplete_normal_bl\n        = (word *)GC_scratch_alloc(sizeof(page_hash_table));\n    if (NULL == GC_old_normal_bl || NULL == GC_incomplete_normal_bl) {\n      GC_err_printf(\"Insufficient memory for black list\\n\");\n      EXIT();\n    }\n    GC_clear_bl(GC_old_normal_bl);\n    GC_clear_bl(GC_incomplete_normal_bl);\n  }\n}\n\nGC_INNER void\nGC_bl_init(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_all_interior_pointers) {\n    GC_bl_init_no_interiors();\n  }\n  GC_ASSERT(NULL == GC_old_stack_bl && NULL == GC_incomplete_stack_bl);\n  GC_old_stack_bl = (word *)GC_scratch_alloc(sizeof(page_hash_table));\n  GC_incomplete_stack_bl = (word *)GC_scratch_alloc(sizeof(page_hash_table));\n  if (NULL == GC_old_stack_bl || NULL == GC_incomplete_stack_bl) {\n    GC_err_printf(\"Insufficient memory for black list\\n\");\n    EXIT();\n  }\n  GC_clear_bl(GC_old_stack_bl);\n  GC_clear_bl(GC_incomplete_stack_bl);\n}\n\nSTATIC void\nGC_clear_bl(word *bl)\n{\n  BZERO(bl, sizeof(page_hash_table));\n}\n\nSTATIC void\nGC_copy_bl(const word *old, word *dest)\n{\n  BCOPY(old, dest, sizeof(page_hash_table));\n}\n\nstatic word total_stack_black_listed(void);\n\n/* Signal the completion of a collection.  Turn the incomplete black    */\n/* lists into new black lists, etc.                                     */\nGC_INNER void\nGC_promote_black_lists(void)\n{\n  word *very_old_normal_bl = GC_old_normal_bl;\n  word *very_old_stack_bl = GC_old_stack_bl;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_old_normal_bl = GC_incomplete_normal_bl;\n  GC_old_stack_bl = GC_incomplete_stack_bl;\n  if (!GC_all_interior_pointers) {\n    GC_clear_bl(very_old_normal_bl);\n  }\n  GC_clear_bl(very_old_stack_bl);\n  GC_incomplete_normal_bl = very_old_normal_bl;\n  GC_incomplete_stack_bl = very_old_stack_bl;\n  GC_total_stack_black_listed = total_stack_black_listed();\n  GC_VERBOSE_LOG_PRINTF(\n      \"%lu bytes in heap blacklisted for interior pointers\\n\",\n      (unsigned long)GC_total_stack_black_listed);\n  if (GC_total_stack_black_listed != 0) {\n    GC_black_list_spacing\n        = HBLKSIZE * (GC_heapsize / GC_total_stack_black_listed);\n  }\n  if (GC_black_list_spacing < 3 * HBLKSIZE) {\n    GC_black_list_spacing = 3 * HBLKSIZE;\n  }\n  if (GC_black_list_spacing > MAXHINCR * HBLKSIZE) {\n    /* Make it easier to allocate really huge blocks, which         */\n    /* otherwise may have problems with nonuniform blacklist        */\n    /* distributions.  This way we should always succeed            */\n    /* immediately after growing the heap.                          */\n    GC_black_list_spacing = MAXHINCR * HBLKSIZE;\n  }\n}\n\nGC_INNER void\nGC_unpromote_black_lists(void)\n{\n  if (!GC_all_interior_pointers) {\n    GC_copy_bl(GC_old_normal_bl, GC_incomplete_normal_bl);\n  }\n  GC_copy_bl(GC_old_stack_bl, GC_incomplete_stack_bl);\n}\n\n#if defined(PARALLEL_MARK) && defined(THREAD_SANITIZER)\n#  define backlist_set_pht_entry_from_index(db, index) \\\n    set_pht_entry_from_index_concurrent(db, index)\n#else\n/* It is safe to set a bit in a blacklist even without        */\n/* synchronization, the only drawback is that we might have   */\n/* to redo blacklisting sometimes.                            */\n#  define backlist_set_pht_entry_from_index(bl, index) \\\n    set_pht_entry_from_index(bl, index)\n#endif\n\n/* The argument p is not a valid pointer reference, but it falls inside */\n/* the plausible heap bounds.  Add it to the normal incomplete black    */\n/* list if appropriate.                                                 */\n#ifdef PRINT_BLACK_LIST\nGC_INNER void\nGC_add_to_black_list_normal(ptr_t p, ptr_t source)\n#else\nGC_INNER void\nGC_add_to_black_list_normal(ptr_t p)\n#endif\n{\n#ifndef PARALLEL_MARK\n  GC_ASSERT(I_HOLD_LOCK());\n#endif\n  if (GC_modws_valid_offsets[ADDR(p) & (sizeof(ptr_t) - 1)]) {\n    size_t index = PHT_HASH(p);\n\n    if (NULL == HDR(p) || get_pht_entry_from_index(GC_old_normal_bl, index)) {\n#ifdef PRINT_BLACK_LIST\n      if (!get_pht_entry_from_index(GC_incomplete_normal_bl, index)) {\n        GC_print_blacklisted_ptr(p, source, \"normal\");\n      }\n#endif\n      backlist_set_pht_entry_from_index(GC_incomplete_normal_bl, index);\n    } else {\n      /* This is probably just an interior pointer to an allocated      */\n      /* object, and is not worth black listing.                        */\n    }\n  }\n}\n\n/* And the same for false pointers from the stack. */\n#ifdef PRINT_BLACK_LIST\nGC_INNER void\nGC_add_to_black_list_stack(ptr_t p, ptr_t source)\n#else\nGC_INNER void\nGC_add_to_black_list_stack(ptr_t p)\n#endif\n{\n  size_t index = PHT_HASH(p);\n\n#ifndef PARALLEL_MARK\n  GC_ASSERT(I_HOLD_LOCK());\n#endif\n  if (NULL == HDR(p) || get_pht_entry_from_index(GC_old_stack_bl, index)) {\n#ifdef PRINT_BLACK_LIST\n    if (!get_pht_entry_from_index(GC_incomplete_stack_bl, index)) {\n      GC_print_blacklisted_ptr(p, source, \"stack\");\n    }\n#endif\n    backlist_set_pht_entry_from_index(GC_incomplete_stack_bl, index);\n  }\n}\n\n/* Is the block starting at h of size len bytes black-listed?  If so,   */\n/* return the address of the next plausible r such that (r,len) might   */\n/* not be black-listed.  (Pointer r may not actually be in the heap.    */\n/* We guarantee only that every smaller value of r after h is also      */\n/* black-listed.)  If (h,len) is not, then return NULL.  Knows about    */\n/* the structure of the black list hash tables.  Assumes the allocator  */\n/* lock is held but no assertion about it by design.                    */\nGC_API struct GC_hblk_s *GC_CALL\nGC_is_black_listed(struct GC_hblk_s *h, size_t len)\n{\n  size_t index = PHT_HASH(h);\n  size_t i, nblocks;\n\n  if (!GC_all_interior_pointers\n      && (get_pht_entry_from_index(GC_old_normal_bl, index)\n          || get_pht_entry_from_index(GC_incomplete_normal_bl, index))) {\n    return h + 1;\n  }\n\n  nblocks = divHBLKSZ(len);\n  for (i = 0;;) {\n    if (GC_old_stack_bl[divWORDSZ(index)] == 0\n        && GC_incomplete_stack_bl[divWORDSZ(index)] == 0) {\n      /* An easy case. */\n      i += CPP_WORDSZ - modWORDSZ(index);\n    } else {\n      if (get_pht_entry_from_index(GC_old_stack_bl, index)\n          || get_pht_entry_from_index(GC_incomplete_stack_bl, index)) {\n        return &h[i + 1];\n      }\n      i++;\n    }\n    if (i >= nblocks)\n      break;\n    index = PHT_HASH(h + i);\n  }\n  return NULL;\n}\n\n/* Return the number of blacklisted blocks in a given range.  Used only */\n/* for statistical purposes.  Looks only at the GC_incomplete_stack_bl. */\nSTATIC word\nGC_number_stack_black_listed(struct hblk *start, struct hblk *endp1)\n{\n  struct hblk *h;\n  word result = 0;\n\n  for (h = start; ADDR_LT((ptr_t)h, (ptr_t)endp1); h++) {\n    size_t index = PHT_HASH(h);\n\n    if (get_pht_entry_from_index(GC_old_stack_bl, index))\n      result++;\n  }\n  return result;\n}\n\n/* Return the total number of (stack) black-listed bytes. */\nstatic word\ntotal_stack_black_listed(void)\n{\n  size_t i;\n  word total = 0;\n\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    struct hblk *start = (struct hblk *)GC_heap_sects[i].hs_start;\n    struct hblk *endp1 = start + divHBLKSZ(GC_heap_sects[i].hs_bytes);\n\n    total += GC_number_stack_black_listed(start, endp1);\n  }\n  return total * HBLKSIZE;\n}\n"
        },
        {
          "name": "build.zig",
          "type": "blob",
          "size": 27.421875,
          "content": "// THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n// OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n//\n// Permission is hereby granted to use or copy this program\n// for any purpose, provided the above notices are retained on all copies.\n// Permission to modify the code and to distribute modified code is granted,\n// provided the above notices are retained, and a notice that the code was\n// modified is included with the above copyright notice.\n\n// A script to build and test the collector using Zig build system.\n// The script matches CMakeLists.txt as much as possible.\n\nconst builtin = @import(\"builtin\");\nconst std = @import(\"std\");\n\nconst zig_min_required_version = \"0.12.0\";\n\n// TODO: specify PACKAGE_VERSION and LIB*_VER_INFO.\n\n// Compared to the CMake script, some definitions and compiler options\n// are hard-coded here, which is natural because build.zig is only built with\n// the Zig build system and Zig ships with an embedded clang (as of zig 0.12).\n// As a consequence, we do not have to support lots of different compilers\n// (a notable exception is msvc target which implies use of the corresponding\n// native compiler).\n// And, on the contrary, we know exactly what we get and thus we can align on\n// clang's capabilities rather than having to discover compiler capabilities.\n// Similarly, since Zig ships libc headers for many platforms, we can, with\n// the knowledge of the platform, determine what capabilities should be\n// enabled or not.\n\ncomptime {\n    const required_ver = std.SemanticVersion.parse(zig_min_required_version)\n                            catch unreachable;\n    if (builtin.zig_version.order(required_ver) == .lt) {\n        @compileError(std.fmt.comptimePrint(\n            \"Zig version {} does not meet the build requirement of {}\",\n            .{ builtin.zig_version, required_ver },\n        ));\n    }\n}\n\npub fn build(b: *std.Build) void {\n    const optimize = b.standardOptimizeOption(.{});\n    const target = b.standardTargetOptions(.{});\n    const t = target.result;\n\n    const default_enable_threads = !t.isWasm(); // both emscripten and wasi\n\n    // Customize build by passing \"-D<option_name>[=false]\" in command line.\n    const enable_cplusplus = b.option(bool, \"enable_cplusplus\",\n                                      \"C++ support\") orelse false;\n    const build_shared_libs = b.option(bool, \"BUILD_SHARED_LIBS\",\n                \"Build shared libraries (otherwise static ones)\") orelse true;\n    const build_cord = b.option(bool, \"build_cord\",\n                                \"Build cord library\") orelse true;\n    const cflags_extra = b.option([]const u8, \"CFLAGS_EXTRA\",\n                                  \"Extra user-defined cflags\") orelse \"\";\n    // TODO: support enable_docs\n    const enable_threads = b.option(bool, \"enable_threads\",\n                \"Support threads\") orelse default_enable_threads;\n    const enable_parallel_mark = b.option(bool, \"enable_parallel_mark\",\n        \"Parallelize marking and free list construction\") orelse true;\n    const enable_thread_local_alloc = b.option(bool,\n        \"enable_thread_local_alloc\",\n        \"Turn on thread-local allocation optimization\") orelse true;\n    const enable_threads_discovery = b.option(bool,\n        \"enable_threads_discovery\",\n        \"Enable threads discovery in GC\") orelse true;\n    const enable_rwlock = b.option(bool, \"enable_rwlock\",\n        \"Enable reader mode of the allocator lock\") orelse false;\n    const enable_throw_bad_alloc_library = b.option(bool,\n        \"enable_throw_bad_alloc_library\",\n        \"Turn on C++ gctba library build\") orelse true;\n    const enable_gcj_support = b.option(bool, \"enable_gcj_support\",\n                                        \"Support for gcj\") orelse true;\n    const enable_sigrt_signals = b.option(bool, \"enable_sigrt_signals\",\n        \"Use SIGRTMIN-based signals for thread suspend/resume\") orelse false;\n    const enable_valgrind_tracking = b.option(bool,\n        \"enable_valgrind_tracking\",\n        \"Support tracking GC_malloc and friends for heap profiling tools\")\n        orelse false;\n    const enable_gc_debug = b.option(bool, \"enable_gc_debug\",\n        \"Support for pointer back-tracing\") orelse false;\n    const disable_gc_debug = b.option(bool, \"disable_gc_debug\",\n        \"Disable debugging like GC_dump and its callees\") orelse false;\n    const enable_java_finalization = b.option(bool,\n        \"enable_java_finalization\",\n        \"Support for java finalization\") orelse true;\n    const enable_atomic_uncollectable = b.option(bool,\n        \"enable_atomic_uncollectable\",\n        \"Support for atomic uncollectible allocation\") orelse true;\n    const enable_redirect_malloc = b.option(bool, \"enable_redirect_malloc\",\n        \"Redirect malloc and friend to GC routines\") orelse false;\n    const enable_disclaim = b.option(bool, \"enable_disclaim\",\n        \"Support alternative finalization interface\") orelse true;\n    const enable_dynamic_pointer_mask = b.option(bool,\n        \"enable_dynamic_pointer_mask\",\n        \"Support pointer mask/shift set at runtime\") orelse false;\n    const enable_large_config = b.option(bool, \"enable_large_config\",\n        \"Optimize for large heap or root set\") orelse false;\n    const enable_gc_assertions = b.option(bool, \"enable_gc_assertions\",\n        \"Enable collector-internal assertion checking\") orelse false;\n    const enable_mmap = b.option(bool, \"enable_mmap\",\n        \"Use mmap instead of sbrk to expand the heap\") orelse false;\n    const enable_munmap = b.option(bool, \"enable_munmap\",\n        \"Return page to the OS if empty for N collections\") orelse true;\n    const enable_dynamic_loading = b.option(bool, \"enable_dynamic_loading\",\n        \"Enable tracing of dynamic library data roots\") orelse true;\n    const enable_register_main_static_data = b.option(bool,\n        \"enable_register_main_static_data\",\n        \"Perform the initial guess of data root sets\") orelse true;\n    const enable_checksums = b.option(bool, \"enable_checksums\",\n        \"Report erroneously cleared dirty bits\") orelse false;\n    const enable_werror = b.option(bool, \"enable_werror\",\n        \"Pass -Werror to the C compiler (treat warnings as errors)\")\n        orelse false;\n    const enable_single_obj_compilation = b.option(bool,\n        \"enable_single_obj_compilation\",\n        \"Compile all libgc source files into single .o\") orelse false;\n    const disable_single_obj_compilation = b.option(bool,\n        \"disable_single_obj_compilation\",\n        \"Compile each libgc source file independently\") orelse false;\n    const enable_handle_fork = b.option(bool, \"enable_handle_fork\",\n        \"Attempt to ensure a usable collector after fork()\") orelse true;\n    const disable_handle_fork = b.option(bool, \"disable_handle_fork\",\n        \"Prohibit installation of pthread_atfork() handlers\") orelse false;\n    // TODO: support enable_emscripten_asyncify\n    const install_headers = b.option(bool, \"install_headers\",\n        \"Install header and pkg-config metadata files\") orelse true;\n    // TODO: support with_libatomic_ops, without_libatomic_ops\n\n    const gc = if (build_shared_libs) blk: {\n        // TODO: convert VER_INFO values to [SO]VERSION ones\n        break :blk b.addSharedLibrary(.{\n            .name = \"gc\",\n            .target = target,\n            .optimize = optimize,\n        });\n    } else blk: {\n        break :blk b.addStaticLibrary(.{\n            .name = \"gc\",\n            .target = target,\n            .optimize = optimize,\n        });\n    };\n\n    var source_files = std.ArrayList([]const u8).init(b.allocator);\n    defer source_files.deinit();\n    var flags = std.ArrayList([]const u8).init(b.allocator);\n    defer flags.deinit();\n\n    // Always enabled.\n    flags.append(\"-D ALL_INTERIOR_POINTERS\") catch unreachable;\n    flags.append(\"-D NO_EXECUTE_PERMISSION\") catch unreachable;\n\n    // Output all warnings.\n    flags.appendSlice(&.{\n        \"-Wall\",\n        \"-Wextra\",\n        \"-Wpedantic\",\n    }) catch unreachable;\n\n    // Disable MS crt security warnings reported e.g. for getenv, strcpy.\n    if (t.abi == .msvc) {\n        flags.append(\"-D _CRT_SECURE_NO_DEPRECATE\") catch unreachable;\n    }\n\n    source_files.appendSlice(&.{\n        \"allchblk.c\",\n        \"alloc.c\",\n        \"blacklst.c\",\n        \"dbg_mlc.c\",\n        \"dyn_load.c\",\n        \"finalize.c\",\n        \"headers.c\",\n        \"mach_dep.c\",\n        \"malloc.c\",\n        \"mallocx.c\",\n        \"mark.c\",\n        \"mark_rts.c\",\n        \"misc.c\",\n        \"new_hblk.c\",\n        \"obj_map.c\",\n        \"os_dep.c\",\n        \"ptr_chck.c\",\n        \"reclaim.c\",\n        \"typd_mlc.c\",\n    }) catch unreachable;\n\n    if (enable_threads) {\n        flags.append(\"-D GC_THREADS\") catch unreachable;\n        if (enable_parallel_mark) {\n            flags.append(\"-D PARALLEL_MARK\") catch unreachable;\n        }\n        if (t.os.tag != .windows) { // assume pthreads\n            // TODO: support cygwin when supported by zig\n            // Zig comes with clang which supports GCC atomic intrinsics.\n            flags.append(\"-D GC_BUILTIN_ATOMIC\") catch unreachable;\n            // TODO: define and use THREADDLLIBS_LIST\n            source_files.appendSlice(&.{\n                \"gc_dlopen.c\",\n                \"pthread_start.c\",\n                \"pthread_support.c\",\n            }) catch unreachable;\n            if (t.isDarwin()) {\n                source_files.append(\"darwin_stop_world.c\") catch unreachable;\n            } else {\n                source_files.append(\"pthread_stop_world.c\") catch unreachable;\n            }\n            // Common defines for POSIX platforms.\n            flags.append(\"-D _REENTRANT\") catch unreachable;\n            // TODO: some targets might need _PTHREADS defined too.\n            if (enable_thread_local_alloc) {\n                flags.append(\"-D THREAD_LOCAL_ALLOC\") catch unreachable;\n                source_files.appendSlice(&.{\n                    \"specific.c\",\n                    \"thread_local_alloc.c\",\n                }) catch unreachable;\n            }\n            // Message for clients: Explicit GC_INIT() calls may be required.\n            if (enable_handle_fork and !disable_handle_fork) {\n                flags.append(\"-D HANDLE_FORK\") catch unreachable;\n            }\n            if (enable_sigrt_signals) {\n                flags.append(\"-D GC_USESIGRT_SIGNALS\") catch unreachable;\n            }\n        } else {\n            // Assume the GCC atomic intrinsics are supported.\n            flags.append(\"-D GC_BUILTIN_ATOMIC\") catch unreachable;\n            if (enable_thread_local_alloc\n                    and (enable_parallel_mark or !build_shared_libs)) {\n                // Imply THREAD_LOCAL_ALLOC unless GC_DLL.\n                flags.append(\"-D THREAD_LOCAL_ALLOC\") catch unreachable;\n                source_files.append(\"thread_local_alloc.c\") catch unreachable;\n            }\n            flags.append(\"-D EMPTY_GETENV_RESULTS\") catch unreachable;\n            source_files.appendSlice(&.{\n                \"pthread_start.c\", // just if client defines GC_WIN32_PTHREADS\n                \"pthread_support.c\",\n                \"win32_threads.c\",\n            }) catch unreachable;\n        }\n    }\n\n    // TODO: define/use NEED_LIB_RT\n\n    if (disable_handle_fork) {\n        flags.append(\"-D NO_HANDLE_FORK\") catch unreachable;\n    }\n\n    if (enable_gcj_support) {\n        flags.append(\"-D GC_GCJ_SUPPORT\") catch unreachable;\n        // TODO: do not define GC_ENABLE_SUSPEND_THREAD on kFreeBSD\n        // if enable_thread_local_alloc (a workaround for some bug).\n        flags.append(\"-D GC_ENABLE_SUSPEND_THREAD\") catch unreachable;\n        source_files.append(\"gcj_mlc.c\") catch unreachable;\n    }\n\n    if (enable_disclaim) {\n        flags.append(\"-D ENABLE_DISCLAIM\") catch unreachable;\n        source_files.append(\"fnlz_mlc.c\") catch unreachable;\n    }\n\n    if (enable_dynamic_pointer_mask) {\n        flags.append(\"-D DYNAMIC_POINTER_MASK\") catch unreachable;\n    }\n\n    if (enable_java_finalization) {\n        flags.append(\"-D JAVA_FINALIZATION\") catch unreachable;\n    }\n\n    if (enable_atomic_uncollectable) {\n        flags.append(\"-D GC_ATOMIC_UNCOLLECTABLE\") catch unreachable;\n    }\n\n    if (enable_valgrind_tracking) {\n        flags.append(\"-D VALGRIND_TRACKING\") catch unreachable;\n    }\n\n    if (enable_gc_debug) {\n        flags.append(\"-D DBG_HDRS_ALL\") catch unreachable;\n        flags.append(\"-D KEEP_BACK_PTRS\") catch unreachable;\n        if (t.os.tag == .linux) {\n            flags.append(\"-D MAKE_BACK_GRAPH\") catch unreachable;\n            // TODO: do not define SAVE_CALL_COUNT for e2k\n            flags.append(\"-D SAVE_CALL_COUNT=8\") catch unreachable;\n            source_files.append(\"backgraph.c\") catch unreachable;\n        }\n    }\n\n    if (disable_gc_debug) {\n        flags.append(\"-D NO_DEBUGGING\") catch unreachable;\n    }\n    if (optimize != .Debug) {\n        flags.append(\"-D NDEBUG\") catch unreachable;\n    }\n\n    if (enable_redirect_malloc) {\n        if (enable_gc_debug) {\n            flags.append(\"-D REDIRECT_MALLOC=GC_debug_malloc_replacement\")\n                catch unreachable;\n            flags.append(\"-D REDIRECT_REALLOC=GC_debug_realloc_replacement\")\n                catch unreachable;\n            flags.append(\"-D REDIRECT_FREE=GC_debug_free\") catch unreachable;\n        } else {\n            flags.append(\"-D REDIRECT_MALLOC=GC_malloc\") catch unreachable;\n        }\n        if (t.os.tag == .windows) {\n            flags.append(\"-D REDIRECT_MALLOC_IN_HEADER\") catch unreachable;\n        } else {\n            flags.append(\"-D GC_USE_DLOPEN_WRAP\") catch unreachable;\n        }\n    }\n\n    if (enable_mmap or enable_munmap) {\n        flags.append(\"-D USE_MMAP\") catch unreachable;\n    }\n\n    if (enable_munmap) {\n        flags.append(\"-D USE_MUNMAP\") catch unreachable;\n    }\n\n    if (!enable_dynamic_loading) {\n        flags.append(\"-D IGNORE_DDYNAMIC_LOADING\") catch unreachable;\n    }\n\n    if (!enable_register_main_static_data) {\n        flags.append(\"-D GC_DONT_REGISTER_MAIN_STATIC_DATA\") catch unreachable;\n    }\n\n    if (enable_large_config) {\n        flags.append(\"-D LARGE_CONFIG\") catch unreachable;\n    }\n\n    if (enable_gc_assertions) {\n        flags.append(\"-D GC_ASSERTIONS\") catch unreachable;\n    }\n\n    if (!enable_threads_discovery) {\n        flags.append(\"-D GC_NO_THREADS_DISCOVERY\") catch unreachable;\n    }\n\n    if (enable_rwlock) {\n        flags.append(\"-D USE_RWLOCK\") catch unreachable;\n    }\n\n    if (enable_checksums) {\n        if (enable_munmap or enable_threads) {\n            @panic(\"CHECKSUMS not compatible with USE_MUNMAP or threads\");\n        }\n        flags.append(\"-D CHECKSUMS\") catch unreachable;\n        source_files.append(\"checksums.c\") catch unreachable;\n    }\n\n    if (enable_werror) {\n        flags.append(\"-Werror\") catch unreachable;\n    }\n\n    if (enable_single_obj_compilation\n            or (build_shared_libs and !disable_single_obj_compilation)) {\n        source_files.clearAndFree();\n        source_files.append(\"extra/gc.c\") catch unreachable;\n        if (enable_threads and !t.isDarwin() and t.os.tag != .windows) {\n            flags.append(\"-D GC_PTHREAD_START_STANDALONE\") catch unreachable;\n            source_files.append(\"pthread_start.c\") catch unreachable;\n        }\n    }\n\n    // Add implementation of backtrace() and backtrace_symbols().\n    if (t.abi == .msvc) {\n        source_files.append(\"extra/msvc_dbg.c\") catch unreachable;\n    }\n\n    // TODO: declare that the libraries do not refer to external symbols\n    // of build_shared_libs.\n\n    // zig cc supports this flag.\n    flags.appendSlice(&.{\n        // TODO: -Wno-unused-command-line-argument\n        // Prevent \"__builtin_return_address with nonzero argument is unsafe\".\n        \"-Wno-frame-address\",\n    }) catch unreachable;\n\n    if (build_shared_libs) {\n        flags.append(\"-D GC_DLL\") catch unreachable;\n        if (t.abi == .msvc) {\n            // TODO: depend on user32.lib instead\n            flags.append(\"-D DONT_USE_USER32_DLL\") catch unreachable;\n        } else {\n            // zig cc supports these flags.\n            flags.append(\"-D GC_VISIBILITY_HIDDEN_SET\") catch unreachable;\n            flags.append(\"-fvisibility=hidden\") catch unreachable;\n        }\n    } else {\n        flags.append(\"-D GC_NOT_DLL\") catch unreachable;\n        if (t.os.tag == .windows) {\n            // Do not require the clients to link with \"user32\" system library.\n            flags.append(\"-D DONT_USE_USER32_DLL\") catch unreachable;\n        }\n    }\n\n    // Note: Zig uses clang which ships with these so, unless another\n    // sysroot/libc, etc. headers location is pointed out, it is fine to\n    // hard-code enable this.\n    // -U GC_MISSING_EXECINFO_H\n    // -U GC_NO_SIGSETJMP\n    flags.append(\"-D HAVE_SYS_TYPES_H\") catch unreachable;\n\n    if (t.abi == .msvc) {\n        // To workaround \"extension used\" error reported for __try/finally.\n        flags.append(\"-D NO_SEH_AVAILABLE\") catch unreachable;\n    } else {\n        flags.append(\"-D HAVE_UNISTD_H\") catch unreachable;\n    }\n\n    const have_getcontext = !t.abi.isMusl() and t.os.tag != .windows;\n    if (!have_getcontext) {\n        flags.append(\"-D NO_GETCONTEXT\") catch unreachable;\n    }\n\n    if (!t.isDarwin() and t.os.tag != .windows) {\n        // dl_iterate_phdr exists (as a strong symbol).\n        flags.append(\"-D HAVE_DL_ITERATE_PHDR\") catch unreachable;\n        if (enable_threads) {\n            // pthread_sigmask() and sigset_t are available and needed.\n            flags.append(\"-D HAVE_PTHREAD_SIGMASK\") catch unreachable;\n        }\n    }\n\n    // Build with GC_wcsdup() support (wcslen is available).\n    flags.append(\"-D GC_REQUIRE_WCSDUP\") catch unreachable;\n\n    // pthread_setname_np, if available, may have 1, 2 or 3 arguments.\n    if (t.isDarwin()) {\n        flags.append(\"-D HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID\")\n                catch unreachable;\n    } else if (t.os.tag == .linux) {\n        flags.append(\"-D HAVE_PTHREAD_SETNAME_NP_WITH_TID\") catch unreachable;\n    } else {\n        // TODO: support HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG\n        // and HAVE_PTHREAD_SET_NAME_NP targets.\n    }\n\n    if (t.os.tag != .windows) {\n        // Define to use 'dladdr' function (used for debugging).\n        flags.append(\"-D HAVE_DLADDR\") catch unreachable;\n    }\n\n    // TODO: as of zig 0.12, exception.h and getsect.h are not provided\n    // by zig itself for Darwin target.\n    if (t.isDarwin() and !target.query.isNative()) {\n        flags.append(\"-D MISSING_MACH_O_GETSECT_H\") catch unreachable;\n        flags.append(\"-D NO_MPROTECT_VDB\") catch unreachable;\n    }\n\n    if (enable_cplusplus and enable_werror) {\n        if (build_shared_libs and t.os.tag == .windows or t.abi == .msvc) {\n            // Avoid \"replacement operator new[] cannot be declared inline\"\n            // warnings.\n            flags.append(\"-Wno-inline-new-delete\") catch unreachable;\n        }\n        if (t.abi == .msvc) {\n            // TODO: as of zig 0.12,\n            // \"argument unused during compilation: -nostdinc++\" warning is\n            // reported if using MS compiler.\n            flags.append(\"-Wno-unused-command-line-argument\")\n                catch unreachable;\n        }\n    }\n\n    if (build_cord and enable_werror and !enable_threads\n        and (t.abi == .gnueabi or t.abi == .gnueabihf or t.abi == .musleabi\n             or t.abi == .musleabihf)) {\n        // TODO: as of zig 0.12, if GCC built-in atomic intrinsic is used,\n        // \"large atomic operation may incur significant performance penalty\"\n        // warning is reported for 32-bit arm targets.\n        flags.append(\"-D AO_DISABLE_GCC_ATOMICS\") catch unreachable;\n    }\n\n    // Extra user-defined flags (if any) to pass to the compiler.\n    if (cflags_extra.len > 0) {\n        // Split it up on a space and append each part to flags separately.\n        var tokenizer = std.mem.tokenizeScalar(u8, cflags_extra, ' ');\n        while (tokenizer.next()) |token| {\n            flags.append(token) catch unreachable;\n        }\n    }\n\n    gc.addCSourceFiles(.{\n        .files = source_files.items,\n        .flags = flags.items,\n    });\n    gc.addIncludePath(b.path(\"include\"));\n    gc.linkLibC();\n\n    var gccpp: *std.Build.Step.Compile = undefined;\n    var gctba: *std.Build.Step.Compile = undefined;\n    if (enable_cplusplus) {\n        gccpp = if (build_shared_libs) blk: {\n            break :blk b.addSharedLibrary(.{\n                .name = \"gccpp\",\n                .target = target,\n                .optimize = optimize,\n            });\n        } else blk: {\n            break :blk b.addStaticLibrary(.{\n                .name = \"gccpp\",\n                .target = target,\n                .optimize = optimize,\n            });\n        };\n        gccpp.addCSourceFiles(.{\n            .files = &.{\n                \"gc_badalc.cc\",\n                \"gc_cpp.cc\",\n            },\n            .flags = flags.items,\n        });\n        gccpp.addIncludePath(b.path(\"include\"));\n        gccpp.linkLibrary(gc);\n        linkLibCpp(gccpp);\n        if (enable_throw_bad_alloc_library) {\n            // The same as gccpp but contains only gc_badalc.\n            gctba = if (build_shared_libs) blk: {\n                break :blk b.addSharedLibrary(.{\n                    .name = \"gctba\",\n                    .target = target,\n                    .optimize = optimize,\n                });\n            } else blk: {\n                break :blk b.addStaticLibrary(.{\n                    .name = \"gctba\",\n                    .target = target,\n                    .optimize = optimize,\n                });\n            };\n            gctba.addCSourceFiles(.{\n                .files = &.{\n                    \"gc_badalc.cc\",\n                },\n                .flags = flags.items,\n            });\n            gctba.addIncludePath(b.path(\"include\"));\n            gctba.linkLibrary(gc);\n            linkLibCpp(gctba);\n        }\n    }\n\n    var cord: *std.Build.Step.Compile = undefined;\n    if (build_cord) {\n        cord = if (build_shared_libs) blk: {\n            break :blk b.addSharedLibrary(.{\n                .name = \"cord\",\n                .target = target,\n                .optimize = optimize,\n            });\n        } else blk: {\n            break :blk b.addStaticLibrary(.{\n                .name = \"cord\",\n                .target = target,\n                .optimize = optimize,\n            });\n        };\n        cord.addCSourceFiles(.{\n            .files = &.{\n                \"cord/cordbscs.c\",\n                \"cord/cordprnt.c\",\n                \"cord/cordxtra.c\",\n            },\n            .flags = flags.items,\n        });\n        cord.addIncludePath(b.path(\"include\"));\n        cord.linkLibrary(gc);\n        cord.linkLibC();\n    }\n\n    if (install_headers) {\n        installHeader(b, gc, \"gc.h\");\n        installHeader(b, gc, \"gc/gc.h\");\n        installHeader(b, gc, \"gc/gc_backptr.h\");\n        installHeader(b, gc, \"gc/gc_config_macros.h\");\n        installHeader(b, gc, \"gc/gc_inline.h\");\n        installHeader(b, gc, \"gc/gc_mark.h\");\n        installHeader(b, gc, \"gc/gc_tiny_fl.h\");\n        installHeader(b, gc, \"gc/gc_typed.h\");\n        installHeader(b, gc, \"gc/gc_version.h\");\n        installHeader(b, gc, \"gc/javaxfc.h\");\n        installHeader(b, gc, \"gc/leak_detector.h\");\n        if (enable_cplusplus) {\n            installHeader(b, gccpp, \"gc_cpp.h\");\n            installHeader(b, gccpp, \"gc/gc_allocator.h\");\n            installHeader(b, gccpp, \"gc/gc_cpp.h\");\n            if (enable_throw_bad_alloc_library) {\n                // The same headers as gccpp library has.\n                installHeader(b, gctba, \"gc_cpp.h\");\n                installHeader(b, gctba, \"gc/gc_allocator.h\");\n                installHeader(b, gctba, \"gc/gc_cpp.h\");\n            }\n        }\n        if (enable_disclaim) {\n            installHeader(b, gc, \"gc/gc_disclaim.h\");\n        }\n        if (enable_gcj_support) {\n            installHeader(b, gc, \"gc/gc_gcj.h\");\n        }\n        if (enable_threads) {\n            installHeader(b, gc, \"gc/gc_pthread_redirects.h\");\n        }\n        if (build_cord) {\n            installHeader(b, cord, \"gc/cord.h\");\n            installHeader(b, cord, \"gc/cord_pos.h\");\n            installHeader(b, cord, \"gc/ec.h\");\n        }\n        // TODO: compose and install bdw-gc.pc and pkgconfig.\n    }\n\n    b.installArtifact(gc);\n    if (enable_cplusplus) {\n        b.installArtifact(gccpp);\n        if (enable_throw_bad_alloc_library) {\n            b.installArtifact(gctba);\n        }\n    }\n    if (build_cord) {\n        b.installArtifact(cord);\n    }\n\n    // Note: there is no \"build_tests\" option, as the tests are built\n    // only if \"test\" step is requested.\n    const test_step = b.step(\"test\", \"Run tests\");\n    addTest(b, gc, test_step, flags, \"gctest\", \"tests/gctest.c\");\n    if (build_cord) {\n        addTestExt(b, gc, cord, test_step, flags,\n                   \"cordtest\", \"cord/tests/cordtest.c\");\n        // TODO: add de test (Windows only)\n    }\n    addTest(b, gc, test_step, flags, \"hugetest\", \"tests/huge.c\");\n    addTest(b, gc, test_step, flags, \"leaktest\", \"tests/leak.c\");\n    addTest(b, gc, test_step, flags, \"middletest\", \"tests/middle.c\");\n    addTest(b, gc, test_step, flags, \"realloctest\", \"tests/realloc.c\");\n    addTest(b, gc, test_step, flags, \"smashtest\", \"tests/smash.c\");\n    // TODO: add staticroots test\n    if (enable_gc_debug) {\n        addTest(b, gc, test_step, flags, \"tracetest\", \"tests/trace.c\");\n    }\n    if (enable_threads) {\n        addTest(b, gc, test_step, flags, \"atomicopstest\", \"tests/atomicops.c\");\n        addTest(b, gc, test_step, flags,\n                \"initfromthreadtest\", \"tests/initfromthread.c\");\n        addTest(b, gc, test_step, flags,\n                \"subthreadcreatetest\", \"tests/subthreadcreate.c\");\n        addTest(b, gc, test_step, flags,\n                \"threadleaktest\", \"tests/threadleak.c\");\n        if (t.os.tag != .windows) {\n            addTest(b, gc, test_step, flags,\n                    \"threadkeytest\", \"tests/threadkey.c\");\n        }\n    }\n    if (enable_cplusplus) {\n        addTestExt(b, gc, gccpp, test_step, flags, \"cpptest\", \"tests/cpp.cc\");\n        if (enable_throw_bad_alloc_library) {\n            addTestExt(b, gc, gctba, test_step, flags,\n                       \"treetest\", \"tests/tree.cc\");\n        }\n    }\n    if (enable_disclaim) {\n        addTest(b, gc, test_step, flags,\n                \"disclaim_bench\", \"tests/disclaim_bench.c\");\n        addTest(b, gc, test_step, flags, \"disclaimtest\", \"tests/disclaim.c\");\n        addTest(b, gc, test_step, flags, \"weakmaptest\", \"tests/weakmap.c\");\n    }\n}\n\nfn linkLibCpp(lib: *std.Build.Step.Compile) void {\n    const t = lib.rootModuleTarget();\n    if (t.abi == .msvc) {\n        // TODO: as of zig 0.12, \"unable to build libcxxabi\" warning is\n        // reported if linking C++ code using MS compiler.\n        lib.linkLibC();\n    } else {\n        lib.linkLibCpp();\n    }\n}\n\nfn addTest(b: *std.Build, gc: *std.Build.Step.Compile,\n           test_step: *std.Build.Step, flags: std.ArrayList([]const u8),\n           testname: []const u8, filename: []const u8) void {\n    addTestExt(b, gc, null, test_step, flags, testname, filename);\n}\n\nfn addTestExt(b: *std.Build, gc: *std.Build.Step.Compile,\n              lib2: ?*std.Build.Step.Compile, test_step: *std.Build.Step,\n              flags: std.ArrayList([]const u8), testname: []const u8,\n              filename: []const u8) void {\n    const test_exe = b.addExecutable(.{\n        .name = testname,\n        .optimize = gc.root_module.optimize.?,\n        .target = gc.root_module.resolved_target.?\n    });\n    test_exe.addCSourceFile(.{\n        .file = b.path(filename),\n        .flags = flags.items\n    });\n    test_exe.addIncludePath(b.path(\"include\"));\n    test_exe.linkLibrary(gc);\n    if (lib2 != null) {\n        test_exe.linkLibrary(lib2.?);\n    }\n    test_exe.linkLibC();\n    const run_test_exe = b.addRunArtifact(test_exe);\n    test_step.dependOn(&run_test_exe.step);\n}\n\nfn installHeader(b: *std.Build, lib: *std.Build.Step.Compile,\n                 hfile: []const u8) void {\n   const src_path = b.pathJoin(&.{ \"include\", hfile });\n   lib.installHeader(b.path(src_path), hfile);\n}\n"
        },
        {
          "name": "checksums.c",
          "type": "blob",
          "size": 3.994140625,
          "content": "/*\n * Copyright (c) 1992-1994 by Xerox Corporation.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#ifdef CHECKSUMS\n\n/* This is debugging code intended to verify the results of dirty bit   */\n/* computations.  Works only in a single threaded environment.          */\n#  define NSUMS 10000\n#  define OFFSET 0x10000\n\ntypedef struct {\n  GC_bool new_valid;\n  word old_sum;\n  word new_sum;\n\n  /* Block to which this refers plus OFFSET to hide it from the   */\n  /* garbage collector.                                           */\n  struct hblk *block;\n} page_entry;\n\npage_entry GC_sums[NSUMS];\n\n/* Record of pages on which we saw a write fault.       */\nSTATIC word GC_faulted[NSUMS] = { 0 };\n\nSTATIC size_t GC_n_faulted = 0;\n\n#  ifdef MPROTECT_VDB\nvoid\nGC_record_fault(struct hblk *h)\n{\n  GC_ASSERT(GC_page_size != 0);\n  if (GC_n_faulted >= NSUMS)\n    ABORT(\"write fault log overflowed\");\n  GC_faulted[GC_n_faulted++] = ADDR(HBLK_PAGE_ALIGNED(h));\n}\n#  endif\n\nSTATIC GC_bool\nGC_was_faulted(struct hblk *h)\n{\n  size_t i;\n  word page = ADDR(HBLK_PAGE_ALIGNED(h));\n\n  for (i = 0; i < GC_n_faulted; ++i) {\n    if (GC_faulted[i] == page)\n      return TRUE;\n  }\n  return FALSE;\n}\n\nSTATIC word\nGC_checksum(struct hblk *h)\n{\n  word *p;\n  word *lim = (word *)(h + 1);\n  word result = 0;\n\n  for (p = (word *)h; ADDR_LT((ptr_t)p, (ptr_t)lim); p++) {\n    result += *p;\n  }\n  return result | SIGNB; /* does not look like pointer */\n}\n\nint GC_n_dirty_errors = 0;\nint GC_n_faulted_dirty_errors = 0;\nunsigned long GC_n_clean = 0;\nunsigned long GC_n_dirty = 0;\n\nSTATIC void\nGC_update_check_page(struct hblk *h, int index)\n{\n  page_entry *pe = GC_sums + index;\n  hdr *hhdr = HDR(h);\n\n  if (pe->block != 0 && pe->block != h + OFFSET)\n    ABORT(\"goofed\");\n  pe->old_sum = pe->new_sum;\n  pe->new_sum = GC_checksum(h);\n#  if !defined(MSWIN32) && !defined(MSWINCE)\n  if (pe->new_sum != SIGNB && !GC_page_was_ever_dirty(h)) {\n    GC_err_printf(\"GC_page_was_ever_dirty(%p) is wrong\\n\", (void *)h);\n  }\n#  endif\n  if (GC_page_was_dirty(h)) {\n    GC_n_dirty++;\n  } else {\n    GC_n_clean++;\n  }\n  if (hhdr != NULL) {\n    (void)GC_find_starting_hblk(h, &hhdr);\n    if (pe->new_valid\n#  ifdef SOFT_VDB\n        && !HBLK_IS_FREE(hhdr)\n#  endif\n        && !IS_PTRFREE(hhdr) && pe->old_sum != pe->new_sum) {\n      if (!GC_page_was_dirty(h) || !GC_page_was_ever_dirty(h)) {\n        GC_bool was_faulted = GC_was_faulted(h);\n        /* Set breakpoint here */ GC_n_dirty_errors++;\n        if (was_faulted)\n          GC_n_faulted_dirty_errors++;\n      }\n    }\n  }\n  pe->new_valid = TRUE;\n  pe->block = h + OFFSET;\n}\n\n/* Should be called immediately after GC_read_dirty.    */\nvoid\nGC_check_dirty(void)\n{\n  int index;\n  size_t i;\n\n  GC_n_dirty_errors = 0;\n  GC_n_faulted_dirty_errors = 0;\n  GC_n_clean = 0;\n  GC_n_dirty = 0;\n\n  index = 0;\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    ptr_t start = GC_heap_sects[i].hs_start;\n    struct hblk *h;\n\n    for (h = (struct hblk *)start;\n         ADDR_LT((ptr_t)h, start + GC_heap_sects[i].hs_bytes); h++) {\n      GC_update_check_page(h, index);\n      index++;\n      if (index >= NSUMS) {\n        i = GC_n_heap_sects;\n        break;\n      }\n    }\n  }\n\n  GC_COND_LOG_PRINTF(\"Checked %lu clean and %lu dirty pages\\n\", GC_n_clean,\n                     GC_n_dirty);\n  if (GC_n_dirty_errors > 0) {\n    GC_err_printf(\"Found %d dirty bit errors (%d were faulted)\\n\",\n                  GC_n_dirty_errors, GC_n_faulted_dirty_errors);\n  }\n  for (i = 0; i < GC_n_faulted; ++i) {\n    /* Do not expose block addresses to the garbage collector.      */\n    GC_faulted[i] = 0;\n  }\n  GC_n_faulted = 0;\n}\n\n#endif /* CHECKSUMS */\n"
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 43.974609375,
          "content": "# Copyright (c) 1999-2001 by Red Hat, Inc. All rights reserved.\n# Copyright (c) 2005-2009 Hewlett-Packard Development Company, L.P.\n# Copyright (c) 2009-2022 Ivan Maidanski\n#\n# THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n# OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n#\n# Permission is hereby granted to use or copy this program\n# for any purpose, provided the above notices are retained on all copies.\n# Permission to modify the code and to distribute modified code is granted,\n# provided the above notices are retained, and a notice that the code was\n# modified is included with the above copyright notice.\n\ndnl Process this file with autoconf to produce configure.\n\ndnl Initialization.\nAC_INIT(gc,8.3.0,https://github.com/ivmai/bdwgc/issues)\ndnl Version must conform to: [0-9]+[.][0-9]+[.][0-9]+\n\nAC_CONFIG_SRCDIR(gcj_mlc.c)\nAC_CONFIG_MACRO_DIR([m4])\nAC_CANONICAL_TARGET\nAC_PREREQ(2.61)\nGC_SET_VERSION\nAM_INIT_AUTOMAKE([foreign nostdinc subdir-objects])\nAC_CONFIG_HEADERS([include/config.h])\nAM_MAINTAINER_MODE\n\nAC_SUBST(PACKAGE)\nAC_SUBST(GC_VERSION)\n\nAM_PROG_CC_C_O\nAC_PROG_CXX\nAM_PROG_AS\nAC_PROG_INSTALL\nLT_INIT([disable-static])\n# Only the shared libraries are produced by default, use \"--enable-static\"\n# option to override it.\ndnl Note: If Autoconf reports that LIBTOOL (or AC_ENABLE_SHARED) is\ndnl undefined, Libtool installation should be checked.\n\n# Special CFLAGS to use when building\ngc_cflags=\"\"\n\n# Set to \"yes\" on platforms where mmap should be used instead of sbrk.\n# This will define USE_MMAP.\ngc_use_mmap=\"\"\n\n# We should set -fexceptions if we are using gcc and might be used\n# inside something like gcj.  This is the zeroth approximation:\nif test :\"$GCC\": = :yes: ; then\n    gc_cflags=\"${gc_cflags} -fexceptions\"\nelse\n    case \"$host\" in\n      hppa*-*-hpux*)\n        if test :$GCC: != :\"yes\": ; then\n            gc_cflags=\"${gc_cflags} +ESdbgasm\"\n        fi\n        # :TODO: actually we should check using Autoconf if\n        #     the compiler supports this option.\n        ;;\n    esac\nfi\n\n#   target_optspace     --enable-target-optspace (\"yes\", \"no\", \"\")\ncase \"${target_optspace}:${host}\" in\n  yes:*)\n    gc_cflags=\"${gc_cflags} -Os\"\n    ;;\n  :m32r-* | :d10v-* | :d30v-*)\n    gc_cflags=\"${gc_cflags} -Os\"\n    ;;\n  no:* | :*)\n    # Nothing.\n    ;;\nesac\n\n# Set any host dependent compiler flags.\ncase \"${host}\" in\n  mips-tx39-* | mipstx39-unknown-*)\n    gc_cflags=\"${gc_cflags} -G 0\"\n    ;;\nesac\n\nAC_MSG_CHECKING([for emscripten])\nAC_COMPILE_IFELSE([AC_LANG_SOURCE([[\n#   ifndef __EMSCRIPTEN__\n#     error This is not Emscripten\n#   endif\n  ]])], [emscripten=yes], [emscripten=no])\nAM_CONDITIONAL(EMSCRIPTEN, test x$emscripten = xyes)\nAC_MSG_RESULT([$emscripten])\n\nAC_ARG_ENABLE(emscripten-asyncify,\n    [AS_HELP_STRING([--enable-emscripten-asyncify],\n                    [use Emscripten asyncify feature])])\n# Use this option if your program is targeting -sASYNCIFY.  The latter is\n# required to scan the stack, ASYNCIFY_STACK_SIZE is probably needed for\n# gctest only.\nAS_IF([test \"${emscripten}\" = yes -a \"${enable_emscripten_asyncify}\" = yes],\n      [gc_cflags=\"${gc_cflags} -DEMSCRIPTEN_ASYNCIFY\"\n       gc_cflags=\"${gc_cflags} -sASYNCIFY -sASYNCIFY_STACK_SIZE=128000\"])\n\nGC_CFLAGS=${gc_cflags}\nAC_SUBST(GC_CFLAGS)\n\ndnl Extra user-defined flags to pass both to C and C++ compilers.\nAC_SUBST([CFLAGS_EXTRA])\n\nAC_ARG_ENABLE(threads,\n  [AS_HELP_STRING([--enable-threads=TYPE], [choose threading package])],\n  THREADS=$enableval,\n   [AC_MSG_CHECKING([for thread model used by GCC])\n    THREADS=`$CC -v 2>&1 | sed -n 's/^Thread model: //p'`\n    if test -z \"$THREADS\" -o \"x$emscripten\" = \"xyes\"; then\n      THREADS=no\n    fi\n    if test \"$THREADS\" = \"posix\"; then\n      case \"$host\" in\n        *-*-mingw*)\n          # Adjust thread model if cross-compiling for MinGW.\n          THREADS=win32\n          ;;\n      esac\n    fi\n    AC_MSG_RESULT([$THREADS])])\n\nAC_ARG_ENABLE(parallel-mark,\n    [AS_HELP_STRING([--disable-parallel-mark],\n        [do not parallelize marking and free list construction])],\n    [case \"$THREADS\" in\n      no | none | single)\n        if test \"${enable_parallel_mark}\" != no; then\n          AC_MSG_ERROR([Parallel mark requires --enable-threads=x spec])\n        fi\n        ;;\n     esac])\n\nAC_ARG_ENABLE(thread-local-alloc,\n    [AS_HELP_STRING([--disable-thread-local-alloc],\n        [turn off thread-local allocation optimization])],\n    [case \"$THREADS\" in\n      no | none | single)\n        if test \"${enable_thread_local_alloc}\" = yes; then\n          AC_MSG_ERROR(\n                [Thread-local allocation requires --enable-threads=x spec])\n        fi\n        ;;\n     esac])\n\nAC_ARG_ENABLE(threads-discovery,\n    [AS_HELP_STRING([--disable-threads-discovery],\n                    [disable threads discovery in GC])])\nif test \"${enable_threads_discovery}\" = no; then\n    AC_DEFINE([GC_NO_THREADS_DISCOVERY], 1,\n              [Disable threads discovery in GC.])\nfi\n\nAC_ARG_ENABLE(rwlock,\n    [AS_HELP_STRING([--enable-rwlock],\n                    [enable reader mode of the allocator lock])])\nif test \"${enable_rwlock}\" = yes; then\n    AC_DEFINE([USE_RWLOCK], 1,\n              [Use rwlock for the allocator lock instead of mutex.])\nfi\n\nAC_ARG_ENABLE(cplusplus,\n    [AS_HELP_STRING([--enable-cplusplus], [install C++ support])])\n\ndnl Features which may be selected in the following thread-detection switch.\nAH_TEMPLATE([PARALLEL_MARK], [Define to enable parallel marking.])\nAH_TEMPLATE([THREAD_LOCAL_ALLOC],\n            [Define to enable thread-local allocation optimization.])\nAH_TEMPLATE([USE_COMPILER_TLS],\n            [Define to use of compiler-support for thread-local variables.])\n\ndnl Thread selection macros.\nAH_TEMPLATE([GC_THREADS], [Define to support platform-specific threads.])\nAH_TEMPLATE([GC_WIN32_PTHREADS],\n                [Define to support pthreads-win32 or winpthreads.])\n\ndnl System header feature requests.\nAH_TEMPLATE([_POSIX_C_SOURCE], [The POSIX feature macro.])\nAH_TEMPLATE([_PTHREADS], [Indicates the use of pthreads (NetBSD).])\n\ndnl Win32-specific API usage controls.\nAH_TEMPLATE([UNICODE],\n        [Use Unicode (W) variant of Win32 API instead of ASCII (A) one.])\n\ndnl GC API symbols export control.\nAH_TEMPLATE([GC_DLL],\n        [Define to build dynamic libraries with only API symbols exposed.])\n\ndnl Check for a flavor of supported inline keyword.\nold_CFLAGS=\"$CFLAGS\"\nCFLAGS=\"$CFLAGS $CFLAGS_EXTRA\"\nAC_C_INLINE\nCFLAGS=\"$old_CFLAGS\"\n\nTHREADDLLIBS=\nneed_atomic_ops_asm=false\nneed_lib_rt=false\ncompile_asm=false\nuse_parallel_mark=no\nuse_thread_local_alloc=no\n# Libraries needed to support dynamic loading and/or threads.\ncase \"$THREADS\" in\n  no | none | single)\n    THREADS=none\n    ;;\n  posix | pthreads)\n    THREADS=posix\n    default_threadlibs=false\n    # Common defines for most POSIX platforms.\n    case \"$host\" in\n      *-*-aix* | *-*-android* | *-*-cygwin* | *-*-darwin* | *-*-dragonfly* | \\\n      *-*-freebsd* | *-*-haiku* | *-*-hpux11* | *-*-irix* | \\\n      *-*-kfreebsd*-gnu | *-*-gnu* | *-*-*linux* | *-*-msys* | *-*-nacl* | \\\n      *-*-netbsd* | *-*-openbsd* | *-*-osf* | *-*-serenity* | *-*-solaris*)\n        AC_DEFINE(GC_THREADS)\n        AC_DEFINE([_REENTRANT], [1],\n                  [Required define if using POSIX threads.])\n        use_parallel_mark=$enable_parallel_mark\n        use_thread_local_alloc=$enable_thread_local_alloc\n        default_threadlibs=true\n        AC_MSG_WARN(\"Explicit GC_INIT() calls may be required.\")\n        ;;\n    esac\n    AC_CHECK_LIB(pthread, pthread_self, THREADDLLIBS=\"-lpthread\",,)\n    case \"$host\" in\n      *-*-hpux11*)\n        AC_MSG_WARN(\"Only HP/UX 11 POSIX threads are supported.\")\n        AC_DEFINE(_POSIX_C_SOURCE,199506L)\n        THREADDLLIBS=\"-lpthread\"\n        # HPUX needs REENTRANT for the _r calls.\n        need_lib_rt=true\n        ;;\n      *-*-openbsd*)\n        AM_CFLAGS=\"$AM_CFLAGS -pthread\"\n        THREADDLLIBS=-pthread\n        ;;\n      *-*-freebsd*)\n        AM_CFLAGS=\"$AM_CFLAGS -pthread\"\n        ;;\n      *-*-kfreebsd*-gnu)\n        AM_CFLAGS=\"$AM_CFLAGS -pthread\"\n        THREADDLLIBS=-pthread\n        ;;\n      *-*-gnu*) # E.g. linux but excluding kfreebsd.\n        # The default THREADDLLIBS.\n        ;;\n      *-*-netbsd*)\n        AC_DEFINE(_PTHREADS)\n        THREADDLLIBS=\"-lpthread\"\n        need_lib_rt=true\n        ;;\n      *-*-solaris*)\n        THREADDLLIBS=\"-lpthread\"\n        need_lib_rt=true\n        ;;\n      *-*-cygwin* | *-*-msys*)\n        # Cygwin doesn't have a real libpthread, so Libtool can't link\n        # against it.\n        THREADDLLIBS=\"\"\n        win32_threads=true\n        ;;\n      *-*-mingw*)\n        AC_DEFINE(GC_WIN32_PTHREADS)\n        # Using pthreads-win32 (or other non-Cygwin pthreads) library.\n        THREADDLLIBS=\"-lpthread\"\n        use_parallel_mark=$enable_parallel_mark\n        use_thread_local_alloc=$enable_thread_local_alloc\n        win32_threads=true\n        ;;\n      *-*-darwin*)\n        darwin_threads=true\n        ;;\n      *-*-osf*)\n        AM_CFLAGS=\"$AM_CFLAGS -pthread\"\n        THREADDLLIBS=\"-lpthread\"\n        need_lib_rt=true\n        ;;\n      *)\n        AS_IF([test x$default_threadlibs != xtrue],\n              [AC_MSG_ERROR(\n                    [Pthreads not supported by the GC on this platform])])\n        # The default THREADDLLIBS.\n        ;;\n    esac\n    case \"$host\" in\n      sparc*-*-solaris*)\n        if test \"$GCC\" != yes; then\n          need_atomic_ops_asm=true\n        fi\n        ;;\n    esac\n    ;;\n  mcf | win32)\n    AC_DEFINE(GC_THREADS)\n    use_parallel_mark=$enable_parallel_mark\n    if test \"${enable_parallel_mark}\" != no \\\n            -o \"${enable_shared}\" != yes -o \"${enable_static}\" != no; then\n      # Imply THREAD_LOCAL_ALLOC unless GC_DLL.\n      use_thread_local_alloc=$enable_thread_local_alloc\n    fi\n    if test \"${enable_win32_dllmain}\" = yes; then\n      AC_DEFINE(GC_INSIDE_DLL, 1,\n                [Enable Win32 DllMain-based approach of threads registering.])\n    fi\n    win32_threads=true\n    AC_DEFINE([EMPTY_GETENV_RESULTS], [1],\n              [Wine getenv may not return NULL for missing entry.])\n    ;;\n  dgux386)\n    AC_DEFINE(GC_THREADS)\n    # Use pthread GCC switch\n    THREADDLLIBS=-pthread\n    use_parallel_mark=$enable_parallel_mark\n    use_thread_local_alloc=$enable_thread_local_alloc\n    AC_MSG_WARN(\"Explicit GC_INIT() calls may be required.\")\n    AM_CFLAGS=\"-pthread $AM_CFLAGS\"\n    ;;\n  aix)\n    THREADS=posix\n    THREADDLLIBS=-lpthread\n    AC_DEFINE(GC_THREADS)\n    AC_DEFINE(_REENTRANT)\n    use_parallel_mark=$enable_parallel_mark\n    use_thread_local_alloc=$enable_thread_local_alloc\n    ;;\n  rtems)\n    THREADS=posix\n    AC_DEFINE(GC_THREADS)\n    use_parallel_mark=$enable_parallel_mark\n    use_thread_local_alloc=$enable_thread_local_alloc\n    ;;\n  decosf1 | irix | mach | os2 | solaris | dce | vxworks)\n    AC_MSG_ERROR(thread package $THREADS not yet supported)\n    ;;\n  *)\n    AC_MSG_ERROR($THREADS is an unknown thread package)\n    ;;\nesac\n\n# Check whether -lrt linker option is needed to use clock_gettime.\nif test \"x$need_lib_rt\" != xtrue; then\n  AC_MSG_CHECKING(for clock_gettime without additional libraries)\n  AC_LINK_IFELSE([AC_LANG_PROGRAM([#include <time.h>],\n                    [struct timespec t; clock_gettime(CLOCK_REALTIME, &t)])],\n    [AC_MSG_RESULT(yes)],\n    [AC_MSG_RESULT(no)\n     AC_CHECK_LIB(rt, clock_gettime, [need_lib_rt=true])])\nfi\n\nif test \"x$need_lib_rt\" = xtrue; then\n  THREADDLLIBS=\"$THREADDLLIBS -lrt\"\nfi\nAC_SUBST(THREADDLLIBS)\n\nAM_CONDITIONAL(THREADS, test x$THREADS != xnone)\nAM_CONDITIONAL(PTHREADS, test x$THREADS = xposix)\nAM_CONDITIONAL(DARWIN_THREADS, test x$darwin_threads = xtrue)\nAM_CONDITIONAL(WIN32_THREADS, test x$win32_threads = xtrue)\n\ncompiler_suncc=no\npthread_start_standalone=no\ncase \"$host\" in\n  *-*-*linux*)\n    # Turn on the workaround described in pthread_start.c.\n    AS_IF([test \"$THREADS\" = posix], [pthread_start_standalone=yes])\n    ;;\n  powerpc-*-darwin*)\n    powerpc_darwin=true\n    ;;\n  *-*-solaris*)\n    if test \"$GCC\" != yes; then\n      # Solaris SunCC\n      compiler_suncc=yes\n      CFLAGS=\"-O $CFLAGS\"\n    fi\n    ;;\n  *-*-wince*)\n    if test \"$enable_gc_debug\" != \"no\"; then\n      AC_DEFINE([GC_READ_ENV_FILE], 1,\n                [Read environment variables from the GC 'env' file.])\n    fi\n    ;;\nesac\nAM_CONDITIONAL(PTHREAD_START_STANDALONE,\n               test x$pthread_start_standalone = xyes)\n\nif test \"$GCC\" = yes; then\n  # Output all warnings.\n  AC_MSG_CHECKING([whether compiler supports -Wextra])\n  old_CFLAGS=\"$CFLAGS\"\n  CFLAGS=\"-Wextra $CFLAGS\"\n  AC_COMPILE_IFELSE([AC_LANG_SOURCE([])],\n                    [ac_cv_cc_wextra=yes], [ac_cv_cc_wextra=no])\n  CFLAGS=\"$old_CFLAGS\"\n  AC_MSG_RESULT($ac_cv_cc_wextra)\n  AS_IF([test \"$ac_cv_cc_wextra\" = yes], [WEXTRA=\"-Wextra\"], [WEXTRA=\"-W\"])\n  AC_MSG_CHECKING([whether compiler supports -Wpedantic])\n  CFLAGS=\"-Wpedantic -Wno-long-long $CFLAGS\"\n  AC_COMPILE_IFELSE([AC_LANG_SOURCE([[extern int quiet;]])],\n                    [ac_cv_cc_pedantic=yes], [ac_cv_cc_pedantic=no])\n  CFLAGS=\"$old_CFLAGS\"\n  AC_MSG_RESULT($ac_cv_cc_pedantic)\n  WPEDANTIC=\n  AS_IF([test \"$ac_cv_cc_pedantic\" = yes],\n        [WPEDANTIC=\"-Wpedantic -Wno-long-long\"])\n  CFLAGS=\"-Wall $WEXTRA $WPEDANTIC $CFLAGS\"\n  CXXFLAGS=\"-Wall $WEXTRA $WPEDANTIC $CXXFLAGS\"\nfi\n\nAC_MSG_CHECKING(for xlc)\nAC_COMPILE_IFELSE([AC_LANG_SOURCE([[\n#   ifndef __xlC__\n#     error\n#   endif\n  ]])], [compiler_xlc=yes], [compiler_xlc=no])\nAC_MSG_RESULT($compiler_xlc)\nif test $compiler_xlc = yes -a \"$powerpc_darwin\" = true; then\n  # The darwin stack-frame-walking code is completely broken on xlc.\n  AC_DEFINE([DARWIN_DONT_PARSE_STACK], 1,\n            [Define to discover thread stack bounds on Darwin without trying\n             to walk the frames on the stack.])\nfi\n\n# XLC neither requires nor tolerates the unnecessary assembler goop.\n# Similar for the Sun C compiler.\nAM_CONDITIONAL([ASM_WITH_CPP_UNSUPPORTED],\n    [test $compiler_xlc = yes -o $compiler_suncc = yes])\n\n# Check for getcontext (uClibc can be configured without it, for example)\nAC_CHECK_FUNC([getcontext], [],\n    [AC_DEFINE([NO_GETCONTEXT], [1], [Missing getcontext function.])])\n\n# Check whether dl_iterate_phdr exists (as a strong symbol).\ncase \"$host\" in\n  *-*-cygwin* | *-*-darwin* | *-*-msys*)\n    ;;\n  *)\n    AC_CHECK_FUNCS([dl_iterate_phdr])\n    ;;\nesac\n\ncase \"$host\" in\n# While IRIX 6 has libdl for the O32 and N32 ABIs, it's missing for N64\n# and unnecessary everywhere.\n  mips-sgi-irix6*)\n    ;;\n# We never want libdl on darwin. It is a fake libdl that just ends up making\n# dyld calls anyway.  The same applies to Cygwin.\n  *-*-cygwin* | *-*-darwin* | *-*-msys*)\n    ;;\n  *)\n    AC_CHECK_LIB(dl, dlopen, THREADDLLIBS=\"$THREADDLLIBS -ldl\")\n    ;;\nesac\n\navoid_cpp_lib=no\ncase \"$host\" in\n  *-*-hpux*)\n    avoid_cpp_lib=yes\n    ;;\nesac\nAM_CONDITIONAL(AVOID_CPP_LIB,test $avoid_cpp_lib = yes)\n\n# Check for various headers.\nAC_CHECK_HEADER([execinfo.h], [],\n    [AC_DEFINE([GC_MISSING_EXECINFO_H], [1], [Missing execinfo.h header.])])\n\n# extra LD Flags which are required for targets\ncase \"${host}\" in\n  *-*-darwin*)\n    extra_ldflags_libgc=-Wl,-single_module\n    ;;\nesac\nAC_SUBST(extra_ldflags_libgc)\n\nAC_SUBST(EXTRA_TEST_LIBS)\n\ntarget_all=libgc.la\nAC_SUBST(target_all)\n\ndnl If the target is an eCos system, use the appropriate eCos\ndnl I/O routines.\ndnl FIXME: this should not be a local option but a global target\ndnl system; at present there is no eCos target.\nTARGET_ECOS=\"no\"\nAC_ARG_WITH([ecos],\n    [AS_HELP_STRING([--with-ecos], [enable runtime eCos target support])],\n    [TARGET_ECOS=\"$with_ecos\"])\n\naddobjs=\naddlibs=\nCXXLIBS=\n\ncase \"$TARGET_ECOS\" in\n  no)\n    ;;\n  *)\n    AC_DEFINE([ECOS], 1, [Define to enable eCos target support.])\n    AM_CPPFLAGS=\"-I${TARGET_ECOS}/include $AM_CPPFLAGS\"\n    addobjs=\"$addobjs ecos.lo\"\n    ;;\nesac\n\nAM_CONDITIONAL(CPLUSPLUS, test \"${enable_cplusplus}\" = yes)\n\nAC_ARG_ENABLE(throw-bad-alloc-library,\n    [AS_HELP_STRING([--disable-throw-bad-alloc-library],\n                    [do not build C++ gctba library])])\nAM_CONDITIONAL(GC_TBA_LIBRARY,\n               test \"${enable_cplusplus}\" = yes \\\n                    -a \"${enable_throw_bad_alloc_library}\" != no)\n\nif test \"$GCC\" = yes; then\n  if test \"${enable_cplusplus}\" = yes; then\n    case \"$host\" in\n      *-*-cygwin* | *-*-mingw* | *-*-msys*)\n        AC_MSG_CHECKING([whether libsupc++ required])\n        SUPC=\"`$CXX -print-file-name=libsupc++.a 2>/dev/null`\"\n        if test -n \"$SUPC\" -a \"$SUPC\" != \"libsupc++.a\"; then\n          AC_MSG_RESULT(yes)\n          CXXLIBS=\"-lsupc++\"\n        else\n          AC_MSG_RESULT(no)\n        fi\n        ;;\n    esac\n  fi\nfi\n\nAC_SUBST(CXX)\nAC_SUBST(AM_CFLAGS)\nAC_SUBST(AM_CPPFLAGS)\nAC_SUBST(CXXLIBS)\n\n# Configuration of shared libraries\n#\nAC_MSG_CHECKING(whether to build shared libraries)\nAC_ENABLE_SHARED\n\ncase \"$host\" in\n  alpha-*-openbsd*)\n    enable_shared=no\n    ;;\nesac\n\nAC_MSG_RESULT($enable_shared)\n\n# Compile with GC_DLL defined unless building static libraries.\nif test \"${enable_shared}\" != no -a \"${enable_static}\" != yes; then\n    AC_DEFINE(GC_DLL)\n    if test \"$GCC\" = yes; then\n      # Pass -fvisibility=hidden option if supported\n      AC_MSG_CHECKING([whether compiler supports -fvisibility])\n      old_CFLAGS=\"$CFLAGS\"\n      CFLAGS=\"-Werror -fvisibility=hidden $CFLAGS\"\n      AC_COMPILE_IFELSE([AC_LANG_PROGRAM([], [])],\n                [ac_cv_fvisibility_hidden=yes], [ac_cv_fvisibility_hidden=no])\n      CFLAGS=\"$old_CFLAGS\"\n      AS_IF([test \"$ac_cv_fvisibility_hidden\" = yes],\n            [CFLAGS=\"-DGC_VISIBILITY_HIDDEN_SET -fvisibility=hidden $CFLAGS\"],\n            [CFLAGS=\"-DGC_NO_VISIBILITY $CFLAGS\"])\n      AC_MSG_RESULT($ac_cv_fvisibility_hidden)\n    fi\nelse\n\n  case \"$host\" in\n    *-*-cygwin* | *-*-mingw* | *-*-msys*)\n      # Do not require the clients to link with \"user32\" system library.\n      AC_DEFINE([DONT_USE_USER32_DLL], 1,\n                [Do not use user32.dll import library (Win32).])\n      # Use inline version of GC new and delete operators in cpptest\n      # otherwise the system ones might be used instead because of arbitrary\n      # ordering of object files when linking.\n      CXXFLAGS=\"$CXXFLAGS -DGC_NOT_DLL\"\n      ;;\n  esac\nfi\n\n# Configuration of machine-dependent code\n#\nAC_MSG_CHECKING(which machine-dependent code should be used)\nmachdep=\ncase \"$host\" in\n  alpha-*-openbsd*)\n    if test x\"${ac_cv_lib_dl_dlopen}\" != xyes ; then\n      AC_MSG_WARN(\n         \"OpenBSD/Alpha without dlopen(). Shared library support is disabled.\")\n    fi\n    ;;\n  i?86-*-solaris2.[[89]])\n    # PROC_VDB appears to work in 2.8 and 2.9 but not in 2.10+ (for now).\n    AC_DEFINE([SOLARIS25_PROC_VDB_BUG_FIXED], 1,\n              [See the comment in gcconfig.h.])\n    ;;\n  sparc-*-netbsd*)\n    machdep=\"sparc_netbsd_mach_dep.lo\"\n    compile_asm=true\n    ;;\n  sparc*-*-linux* | sparc*-*-openbsd* | sparc64-*-freebsd* | sparc64-*-netbsd*)\n    machdep=\"sparc_mach_dep.lo\"\n    compile_asm=true\n    ;;\n  sparc-sun-solaris2.3)\n    machdep=\"sparc_mach_dep.lo\"\n    compile_asm=true\n    AC_DEFINE(SUNOS53_SHARED_LIB, 1,\n              [Define to work around a Solaris 5.3 bug (see dyn_load.c).])\n    ;;\n  sparc*-sun-solaris2*)\n    machdep=\"sparc_mach_dep.lo\"\n    compile_asm=true\n    ;;\n  ia64-*-*)\n    machdep=\"ia64_save_regs_in_stack.lo\"\n    ;;\nesac\nif test \"x$machdep\" = x; then\n  AC_MSG_RESULT(none)\nelse\n  AC_MSG_RESULT($machdep)\n  addobjs=\"$addobjs $machdep\"\nfi\nAC_SUBST(addobjs)\nAC_SUBST(addlibs)\n\n# Suppress \"extension used\" clang warning (when compiling .S files).\nif test x$compile_asm = xtrue -a \"$GCC\" = yes; then\n  AC_MSG_CHECKING([whether compiler supports -Wno-language-extension-token])\n  old_CFLAGS=\"$CFLAGS\"\n  CFLAGS=\"$CFLAGS -Werror -Wno-language-extension-token\"\n  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([], [])],\n                    [ac_cv_lang_ext_token=yes], [ac_cv_lang_ext_token=no])\n  CFLAGS=\"$old_CFLAGS\"\n  AS_IF([test \"$ac_cv_lang_ext_token\" = yes],\n        [CFLAGS=\"$CFLAGS -Wno-language-extension-token\"])\n  AC_MSG_RESULT($ac_cv_lang_ext_token)\nfi\n\ndnl We use these options to decide which functions to include.\nAC_ARG_WITH([target-subdir],\n    [AS_HELP_STRING([--with-target-subdir=SUBDIR],\n                    [configuring target with a cross compiler])])\nAC_ARG_WITH([cross-host],\n    [AS_HELP_STRING([--with-cross-host=HOST],\n                    [configuring host with a cross compiler])])\n\ndnl automake wants to see AC_EXEEXT.  But we don't need it.  And having\ndnl it is actually a problem, because the compiler we're passed can't\ndnl necessarily do a full link.  So we fool automake here.\nif false; then\n  dnl autoconf 2.50 runs AC_EXEEXT by default, and the macro expands\n  dnl to nothing, so nothing would remain between `then' and `fi' if it\n  dnl were not for the `:' below.\n  :\n  AC_EXEEXT\nfi\n\ndnl The collector might not properly work on IBM AIX when\ndnl built with gcc and -O.  So we remove -O in the appropriate case.\nAC_MSG_CHECKING(whether AIX gcc optimization fix is necessary)\ncase \"$host\" in\n  *aix*)\n    if test \"$GCC\" = yes; then\n      AC_MSG_RESULT(yes)\n      new_CFLAGS=\n      for i in $CFLAGS; do\n        case \"$i\" in\n          -O*)\n            ;;\n          *)\n            new_CFLAGS=\"$new_CFLAGS $i\"\n            ;;\n        esac\n      done\n      CFLAGS=\"$new_CFLAGS\"\n    else\n      AC_MSG_RESULT(no)\n    fi\n    ;;\n  *)\n    AC_MSG_RESULT(no)\n    ;;\nesac\n\ndnl Include defines that have become de facto standard.\ndnl ALL_INTERIOR_POINTERS and NO_EXECUTE_PERMISSION can be overridden\ndnl in the startup code.\nAC_DEFINE([NO_EXECUTE_PERMISSION], [1],\n          [Define to make the collector not allocate executable memory\n           by default.])\nAC_DEFINE([ALL_INTERIOR_POINTERS], [1],\n          [Define to recognise all pointers to the interior of objects.])\n\n\ndnl Interface Selection\ndnl -------------------\ndnl\ndnl By default, make the library as general as possible.\nAC_ARG_ENABLE(gcj-support,\n    [AS_HELP_STRING([--disable-gcj-support], [disable support for gcj])])\nif test x\"$enable_gcj_support\" != xno; then\n    AC_DEFINE(GC_GCJ_SUPPORT, 1, [Define to include support for gcj.])\n    case \"$host\" in\n      *-*-kfreebsd*-gnu)\n        # FIXME: For a reason, gctest hangs up on kFreeBSD if both of\n        # THREAD_LOCAL_ALLOC and GC_ENABLE_SUSPEND_THREAD are defined.\n        if test \"${enable_thread_local_alloc}\" = no; then\n          AC_DEFINE(GC_ENABLE_SUSPEND_THREAD)\n        fi\n        ;;\n      *)\n        AC_DEFINE([GC_ENABLE_SUSPEND_THREAD], 1,\n              [Define to turn on GC_suspend_thread support (Linux only).])\n        ;;\n    esac\nfi\nAM_CONDITIONAL(ENABLE_GCJ_SUPPORT, [test x\"enable_gcj_support\" != xno])\n\ndnl Interaction with other programs that might use signals.\nAC_ARG_ENABLE(sigrt-signals,\n    [AS_HELP_STRING([--enable-sigrt-signals],\n        [force GC to use SIGRTMIN-based signals for thread suspend/resume])])\nif test x\"${enable_sigrt_signals}\" = xyes; then\n    AC_DEFINE([GC_USESIGRT_SIGNALS], 1,\n              [Force the GC to use signals based on SIGRTMIN+k.])\nfi\n\n\ndnl Debugging\ndnl ---------\n\nAH_TEMPLATE([GC_HAVE_BUILTIN_BACKTRACE],\n            [Define if backtrace information is supported.])\nAH_TEMPLATE([MAKE_BACK_GRAPH],\n            [Define to build the collector with the support of the\n             functionality to print max length of chain through unreachable\n             objects ending in a reachable one.])\nAH_TEMPLATE([SAVE_CALL_COUNT],\n            [The number of caller frames saved when allocating with the\n             debugging API.])\n\nAC_ARG_ENABLE(valgrind-tracking,\n    [AS_HELP_STRING([--enable-valgrind-tracking],\n                    [heap profiler allocation tracking])],\n    [if test \"${enable_valgrind_tracking}\" = yes; then\n      AC_DEFINE([VALGRIND_TRACKING], 1,\n                [Define to support tracking GC_malloc and friends for heap\n                 profiling tools.])\n     fi])\n\nUNWINDLIBS=\nAC_ARG_ENABLE(gc-debug,\n              [AS_HELP_STRING([--enable-gc-debug],\n                    [include full support for pointer backtracing etc.])],\n [if test \"$enable_gc_debug\" = \"yes\"; then\n    AC_MSG_WARN(\"Should define GC_DEBUG and use debug alloc in clients.\")\n    AC_DEFINE([KEEP_BACK_PTRS], 1,\n              [Define to save back-pointers in debugging headers.])\n    keep_back_ptrs=true\n    AC_DEFINE([DBG_HDRS_ALL], 1,\n              [Define to force debug headers on all objects.])\n    AH_TEMPLATE([SHORT_DBG_HDRS],\n                [Shorten the headers to minimize object size at the expense\n                 of checking for writes past the end.])\n    case $host in\n      ia64-*-linux*)\n        AC_CHECK_LIB(unwind, backtrace,\n           [AC_DEFINE(GC_HAVE_BUILTIN_BACKTRACE)\n            UNWINDLIBS=-lunwind\n            AC_MSG_WARN(\"Client code may need to link against libunwind.\")])\n        ;;\n    esac\n    case $host in\n      i[3456]86-*-dgux* | *-*-*linux*)\n        AC_DEFINE(MAKE_BACK_GRAPH)\n        ;;\n    esac\n    case $host in\n      e2k-*-linux*)\n        # Some bug exists in backtrace().\n        ;;\n      *-*-*linux*)\n        AC_MSG_WARN(\"Client must not use -fomit-frame-pointer.\")\n        AC_DEFINE(SAVE_CALL_COUNT, 8)\n        ;;\n    esac\n  fi])\nAM_CONDITIONAL([MAKE_BACK_GRAPH], [test x\"$enable_gc_debug\" = xyes])\nAM_CONDITIONAL([KEEP_BACK_PTRS], [test x\"$keep_back_ptrs\" = xtrue])\n\n# Check whether a compiler warning of unsafe __builtin_return_address(1)\n# could be suppressed by -Wno-frame-address option.\n# __builtin_return_address(1) is used by libgc for debugging purposes only.\nAC_MSG_CHECKING([whether -Wno-frame-address works])\nuse_wno_error_frame_address=no\nold_CFLAGS=\"$CFLAGS\"\nCFLAGS=\"$CFLAGS -Werror -Wno-frame-address $CFLAGS_EXTRA\"\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([],\n    [if (!__builtin_return_address(1)) return 1;])],\n  [use_wno_error_frame_address=yes])\nCFLAGS=\"$old_CFLAGS\"\nAC_MSG_RESULT($use_wno_error_frame_address)\nif test x\"$use_wno_error_frame_address\" = xyes; then\n  CFLAGS=\"$CFLAGS -Wno-frame-address\"\nfi\n\n# Check for dladdr (used for debugging).\nAC_MSG_CHECKING(for dladdr)\nhave_dladdr=no\nold_CFLAGS=\"$CFLAGS\"\nCFLAGS=\"$CFLAGS $CFLAGS_EXTRA\"\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#   define _GNU_SOURCE 1\n#   include <dlfcn.h>\n  ], [\n    Dl_info info;\n    (void)dladdr(\"\", &info);\n  ])], [have_dladdr=yes])\nCFLAGS=\"$old_CFLAGS\"\nAC_MSG_RESULT($have_dladdr)\nif test x\"$have_dladdr\" = xyes; then\n  AC_DEFINE([HAVE_DLADDR], 1, [Define to use 'dladdr' function.])\nfi\n\n# Check for pthread_sigmask and sigset_t.\nAS_IF([test \"$THREADS\" = posix],\n  [AS_IF([test x$darwin_threads != xtrue -a x$win32_threads != xtrue],\n    [AC_MSG_CHECKING(for pthread_sigmask)\n     old_CFLAGS=\"$CFLAGS\"\n     CFLAGS=\"$CFLAGS $CFLAGS_EXTRA\"\n     AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#           define _GNU_SOURCE 1\n#           include <pthread.h>\n#           include <signal.h>\n         ], [sigset_t t; (void)pthread_sigmask(SIG_BLOCK, 0, &t)])],\n       [AC_MSG_RESULT(yes)\n        AC_DEFINE([GC_HAVE_PTHREAD_SIGMASK], [1],\n                  [Define to use 'pthread_sigmask' function if needed.])],\n       [AC_MSG_RESULT(no)])\n     CFLAGS=\"$old_CFLAGS\"])])\n\n# sigsetjmp could be a macro (thus AC_CHECK_FUNCS cannot be used).\nAC_MSG_CHECKING(for sigsetjmp)\nold_CFLAGS=\"$CFLAGS\"\nCFLAGS=\"$CFLAGS $CFLAGS_EXTRA\"\nAC_LINK_IFELSE([AC_LANG_PROGRAM([#include <setjmp.h>],\n                                [sigjmp_buf t; sigsetjmp(t, 0)])],\n  [AC_MSG_RESULT(yes)],\n  [AC_MSG_RESULT(no)\n   AC_DEFINE([GC_NO_SIGSETJMP], [1], [Missing sigsetjmp function.])])\nCFLAGS=\"$old_CFLAGS\"\n\n# Build with GC_wcsdup() support if possible.\nAC_MSG_CHECKING(for wcslen)\nold_CFLAGS=\"$CFLAGS\"\nCFLAGS=\"$CFLAGS $CFLAGS_EXTRA\"\nAC_LINK_IFELSE([AC_LANG_PROGRAM([#include <wchar.h>],\n                                [wchar_t ws[] = {0}; (void)wcslen(&ws)])],\n  [AC_MSG_RESULT(yes)\n   AC_DEFINE([GC_REQUIRE_WCSDUP], [1],\n             [Define and export GC_wcsdup function.])],\n  [AC_MSG_RESULT(no)])\nCFLAGS=\"$old_CFLAGS\"\n\n# pthread_setname_np, if available, may have 1, 2 or 3 arguments.\nAS_IF([test \"$THREADS\" = posix],\n  [AC_MSG_CHECKING(for pthread_setname_np)\n   old_CFLAGS=\"$CFLAGS\"\n   CFLAGS=\"$CFLAGS $CFLAGS_EXTRA -Werror\"\n   AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#         define _GNU_SOURCE 1\n#         include <pthread.h>\n        ], [pthread_setname_np(\"thread-name\")])],\n     [AC_MSG_RESULT([yes (w/o tid)])\n      AC_DEFINE([HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID], [1],\n                [Define to use 'pthread_setname_np(const char*)' function.])],\n     [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#         define _GNU_SOURCE 1\n#         include <pthread.h>\n        ], [pthread_setname_np(pthread_self(), \"thread-name-%u\", 0)])],\n       [AC_MSG_RESULT([yes (with tid and arg)])\n        AC_DEFINE([HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG], [1],\n         [Define to use 'pthread_setname_np(pthread_t, const char*, void *)'\n          function.])],\n       [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#             define _GNU_SOURCE 1\n#             include <pthread.h>\n            ], [pthread_setname_np(pthread_self(), \"thread-name\")])],\n         [AC_MSG_RESULT([yes (with tid)])\n          AC_DEFINE([HAVE_PTHREAD_SETNAME_NP_WITH_TID], [1],\n                    [Define to use 'pthread_setname_np(pthread_t, const char*)'\n                     function.])],\n         [AC_MSG_RESULT(no)\n          AC_MSG_CHECKING(for pthread_set_name_np)\n          AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#               include <pthread.h>\n#               include <pthread_np.h>\n              ], [pthread_set_name_np(pthread_self(), \"thread-name\")])],\n           [AC_MSG_RESULT(yes)\n            AC_DEFINE([HAVE_PTHREAD_SET_NAME_NP], [1],\n                [Define to use 'pthread_set_name_np(pthread_t, const char*)'\n                 function.])],\n           [AC_MSG_RESULT(no)])])])])\n   CFLAGS=\"$old_CFLAGS\"])\n\n# Check for AViiON Machines running DGUX\nac_is_dgux=no\nAC_CHECK_HEADER(sys/dg_sys_info.h,\n[ac_is_dgux=yes;])\n\ndnl :GOTCHA: we do not check anything but sys/dg_sys_info.h\nif test $ac_is_dgux = yes; then\n    dgux_spec_opts=\"-DDGUX -D_DGUX_SOURCE -Di386 -mno-legend -O2\"\n    CFLAGS=\"$dgux_spec_opts $CFLAGS\"\n    CXXFLAGS=\"$dgux_spec_opts $CXXFLAGS\"\n    if test \"$enable_gc_debug\" = \"yes\"; then\n      CFLAGS=\"-g -mstandard $CFLAGS\"\n      CXXFLAGS=\"-g -mstandard $CXXFLAGS\"\n    fi\n    AC_SUBST(CFLAGS)\n    AC_SUBST(CXXFLAGS)\nfi\n\nAC_ARG_ENABLE(java-finalization,\n    [AS_HELP_STRING([--disable-java-finalization],\n                    [disable support for java finalization])])\nif test x\"$enable_java_finalization\" != xno; then\n    AC_DEFINE([JAVA_FINALIZATION], 1,\n              [Define to make it somewhat safer by default to finalize objects\n               out of order by specifying a nonstandard finalization mark\n               procedure.])\nfi\n\nAC_ARG_ENABLE(atomic-uncollectable,\n    [AS_HELP_STRING([--disable-atomic-uncollectible],\n                    [disable support for atomic uncollectible allocation])])\nif test x\"$enable_atomic_uncollectible\" != x\"no\"; then\n    AC_DEFINE([GC_ATOMIC_UNCOLLECTABLE], 1,\n        [Define to enable atomic uncollectible allocation.])\nfi\n\nAC_ARG_ENABLE(redirect-malloc,\n    [AS_HELP_STRING([--enable-redirect-malloc],\n                    [redirect malloc and friends to GC routines])])\n\nif test \"${enable_redirect_malloc}\" = yes; then\n    if test \"${enable_gc_debug}\" = yes; then\n        AC_DEFINE([REDIRECT_MALLOC], GC_debug_malloc_replacement,\n                  [If defined, redirect malloc to this function.])\n        AC_DEFINE([REDIRECT_REALLOC], GC_debug_realloc_replacement,\n                  [If defined, redirect GC_realloc to this function.])\n        AC_DEFINE([REDIRECT_FREE], GC_debug_free,\n                  [If defined, redirect free to this function.])\n    else\n        AC_DEFINE(REDIRECT_MALLOC, GC_malloc)\n    fi\n    AC_DEFINE([GC_USE_DLOPEN_WRAP], 1,\n              [Define to cause the collector to redefine malloc and\n               intercepted pthread routines with their real names while using\n               dlsym to refer to the original routines.])\nfi\n\nAC_ARG_ENABLE(disclaim,\n    [AS_HELP_STRING([--disable-disclaim],\n        [disable alternative (more efficient) finalization interface])])\nif test x\"$enable_disclaim\" != xno; then\n    AC_DEFINE(ENABLE_DISCLAIM, 1,\n        [Define to enable alternative finalization interface.])\nfi\nAM_CONDITIONAL(ENABLE_DISCLAIM,\n    [test x\"$enable_disclaim\" != xno])\n\nAC_ARG_ENABLE(dynamic-pointer-mask,\n    [AS_HELP_STRING([--enable-dynamic-pointer-mask],\n        [support pointer mask/shift set at runtime])])\nif test \"${enable_dynamic_pointer_mask}\" = yes; then\n    AC_DEFINE(DYNAMIC_POINTER_MASK, 1,\n              [Define to support pointer mask/shift set at runtime.])\nfi\n\nAC_ARG_ENABLE(large-config,\n    [AS_HELP_STRING([--enable-large-config],\n        [optimize for large (> 100 MB) heap or root set])])\nif test \"${enable_large_config}\" = yes; then\n    AC_DEFINE(LARGE_CONFIG, 1,\n              [Define to optimize for large heaps or root sets.])\nfi\n\ndnl This is something of a hack.  When cross-compiling we turn off\ndnl some functionality.  We also enable the \"small\" configuration.\ndnl These is only correct when targeting an embedded system.  FIXME.\nif test -n \"${with_cross_host}\"; then\n   AC_DEFINE([NO_CLOCK], 1,\n             [Define to not use system clock (cross compiling).])\n   AC_DEFINE([SMALL_CONFIG], 1,\n             [Define to tune the collector for small heap sizes.])\nfi\n\nif test \"$enable_gc_debug\" = \"no\"; then\n   AC_DEFINE([NO_DEBUGGING], 1,\n             [Disable debugging, like GC_dump and its callees.])\nfi\n\nAC_SUBST(UNWINDLIBS)\n\nAC_ARG_ENABLE(gc-assertions,\n    [AS_HELP_STRING([--enable-gc-assertions],\n        [collector-internal assertion checking])])\nif test \"${enable_gc_assertions}\" = yes; then\n    AC_DEFINE([GC_ASSERTIONS], 1,\n              [Define to enable internal debug assertions.])\nfi\n\nAC_ARG_ENABLE(mmap,\n    [AS_HELP_STRING([--enable-mmap],\n                    [use mmap instead of sbrk to expand the heap])],\n    gc_use_mmap=$enableval)\n\nAC_ARG_ENABLE(munmap,\n    [AS_HELP_STRING([--enable-munmap=N],\n                    [return page to the OS if page is marked as\n                     empty during N collections (default: 7)])],\n    MUNMAP_THRESHOLD=$enableval)\nif test x$enable_munmap != xno; then\n    AC_DEFINE([USE_MMAP], 1,\n              [Define to use mmap instead of sbrk to expand the heap.])\n    AH_TEMPLATE([USE_WINALLOC],\n                  [Define to use Win32 VirtualAlloc (instead of sbrk or\n                   mmap) to expand the heap.])\n    AC_DEFINE([USE_MUNMAP], 1,\n              [Define to return memory to OS with munmap calls.])\n    if test x$MUNMAP_THRESHOLD = x -o x$MUNMAP_THRESHOLD = xyes; then\n      MUNMAP_THRESHOLD=7\n    fi\n    AC_DEFINE_UNQUOTED([MUNMAP_THRESHOLD], [${MUNMAP_THRESHOLD}],\n        [Number of sequential garbage collections during those a candidate\n         block for unmapping should be marked as free.])\nelse\n    if test \"${gc_use_mmap}\" = \"yes\"; then\n      AC_DEFINE([USE_MMAP], 1,\n                [Define to use mmap instead of sbrk to expand the heap.])\n    fi\nfi\n\nAC_ARG_ENABLE(dynamic-loading,\n    [AS_HELP_STRING([--disable-dynamic-loading],\n                    [build the collector with disabled tracing\n                     of dynamic library data roots])])\nif test \"${enable_dynamic_loading}\" = \"no\"; then\n  AC_DEFINE([IGNORE_DYNAMIC_LOADING], 1,\n            [Do not define DYNAMIC_LOADING even if supported (i.e., build the\n             collector with disabled tracing of dynamic library data roots).])\nfi\n\nAC_ARG_ENABLE(register-main-static-data,\n    [AS_HELP_STRING([--disable-register-main-static-data],\n                    [skip the initial guess of data root sets])])\nif test \"${enable_register_main_static_data}\" = \"no\"; then\n    AC_DEFINE([GC_DONT_REGISTER_MAIN_STATIC_DATA], 1,\n              [Skip the initial guess of data root sets.])\nfi\n\nAC_ARG_ENABLE(checksums,\n    [AS_HELP_STRING([--enable-checksums],\n                    [report on erroneously cleared dirty bits at\n                     substantial performance cost; use only for\n                     debugging of the incremental collector])])\nif test x$enable_checksums = xyes; then\n    if test x$enable_munmap != xno -o x$THREADS != xnone; then\n        AC_MSG_ERROR([CHECKSUMS not compatible with USE_MUNMAP or threads])\n    fi\n    AC_DEFINE([CHECKSUMS], 1,\n              [Erroneously cleared dirty bits checking.  Use only for\n               debugging of the incremental collector.])\nfi\nAM_CONDITIONAL([CHECKSUMS], test x$enable_checksums = xyes)\n\nAM_CONDITIONAL(USE_LIBDIR, test -z \"$with_cross_host\")\n\nAC_ARG_ENABLE(werror,\n    [AS_HELP_STRING([--enable-werror], [pass -Werror to the C compiler])],\n    werror_flag=$enableval, werror_flag=no)\nif test x$werror_flag = xyes; then\n    WERROR_CFLAGS=\"-Werror\"\nfi\nAC_SUBST([WERROR_CFLAGS])\n\nAC_ARG_ENABLE(single-obj-compilation,\n    [AS_HELP_STRING([--enable-single-obj-compilation],\n                    [compile all libgc source files into single .o\n                     (default: yes if static libraries are disabled)])],\n    [], [AS_IF([test x\"$enable_static\" = xno],\n               [enable_single_obj_compilation=yes])])\nAM_CONDITIONAL([SINGLE_GC_OBJ],\n               [test x\"$enable_single_obj_compilation\" = xyes])\n\nAC_ARG_ENABLE(gcov,\n    [AS_HELP_STRING([--enable-gcov], [turn on code coverage analysis])])\nif test \"$enable_gcov\" = \"yes\"; then\n  CFLAGS=\"-D NTHREADS=20 $CFLAGS --coverage\"\n  if test \"${enable_shared}\" = no; then\n    # FIXME: As of g++-4.8.4/x64, in case of shared library build, cpptest\n    # linkage fails with \"hidden symbol atexit is referenced by DSO\" message.\n    CXXFLAGS=\"$CXXFLAGS --coverage\"\n  fi\n  # Turn off optimization to get accurate line numbers.\n  CFLAGS=`echo \"$CFLAGS\" | sed -e 's/-O\\(1\\|2\\|3\\|4\\|s\\|fast\\)\\?//g'`\n  CXXFLAGS=`echo \"$CXXFLAGS\" | sed -e 's/-O\\(1\\|2\\|3\\|4\\|s\\|fast\\)\\?//g'`\nfi\n\nAC_ARG_ENABLE(docs,\n        [AS_HELP_STRING([--disable-docs],\n                        [do not build and install documentation])])\nAM_CONDITIONAL(ENABLE_DOCS, test x$enable_docs != xno)\n\nAM_CONDITIONAL(ENABLE_SHARED, test x$enable_shared = xyes)\n\n# Atomic_ops\n# ----------\n\n# Do we want to use an external libatomic_ops?  By default use it if it's\n# found.\nAC_ARG_WITH([libatomic-ops],\n    [AS_HELP_STRING([--with-libatomic-ops[=yes|no|check|none]],\n                    [use an external libatomic_ops? (default: check;\n                     none: use compiler intrinsics or no thread support)])],\n    [], [AS_IF([test x\"$THREADS\" != xnone],\n               [with_libatomic_ops=check], [with_libatomic_ops=none])])\n\n# Check whether compiler atomic intrinsics can be used.\nif test x\"$with_libatomic_ops\" = xcheck; then\n  AC_MSG_CHECKING(for compiler intrinsics support)\n  old_CFLAGS=\"$CFLAGS\"\n  CFLAGS=\"$CFLAGS $CFLAGS_EXTRA -DGC_BUILTIN_ATOMIC\"\n  CFLAGS=\"$CFLAGS -I${srcdir}/include -I${srcdir}\"\n  AC_RUN_IFELSE([AC_LANG_SOURCE([[#include \"tests/atomicops.c\"]])],\n    [AC_MSG_RESULT(yes)\n     with_libatomic_ops=none],\n    [AC_MSG_RESULT(no)], [AC_MSG_RESULT(skipped because cross-compiling)])\n  CFLAGS=\"$old_CFLAGS\"\nfi\n\n# Check for an external libatomic_ops if the above answer is \"yes\" or \"check\".\n# If not found, fail on \"yes\", and convert \"check\" to \"no\".\n# First, check that libatomic_ops usage is not disabled explicitly.\nmissing_libatomic_ops=false\nAS_IF([test x\"$with_libatomic_ops\" != xno -a x\"$with_libatomic_ops\" != xnone],\n  [missing_libatomic_ops=true])\n\ndnl To avoid \"syntax error near unexpected token ATOMIC_OPS\" configure error\ndnl observed by some clients, the following 3 code lines are commented out:\ndnl\ndnl AS_IF([test x$missing_libatomic_ops = xtrue],\ndnl  [PKG_CHECK_MODULES([ATOMIC_OPS], [atomic_ops],\ndnl    [missing_libatomic_ops=false], [[]])])\n\ndnl Retry with AC_CHECK_HEADER if PKG_CHECK_MODULES failed.\nAS_IF([test x$missing_libatomic_ops = xtrue],\n      [AC_CHECK_HEADER([atomic_ops.h], [missing_libatomic_ops=false])])\nAS_IF([test x$missing_libatomic_ops = xtrue],\n      [AS_IF([test x\"$with_libatomic_ops\" != xcheck],\n             [AC_MSG_ERROR([An external libatomic_ops was not found])])\n        with_libatomic_ops=no])\n\n# If we have neither an external or an internal version, offer a useful hint\n# and exit.\nAS_IF([test x\"$with_libatomic_ops\" = xno \\\n            -a ! -e \"$srcdir/libatomic_ops/src/atomic_ops.h\"],\n  [AC_MSG_ERROR([libatomic_ops is required.  You can either install it on\n                 your system, or fetch and unpack a recent version into the\n                 source directory and link or rename it to libatomic_ops.])])\n\n# Finally, emit the definitions for bundled or external AO.\nAC_MSG_CHECKING([which libatomic_ops to use])\nAS_IF([test x\"$with_libatomic_ops\" != xno],\n  [AS_IF([test x\"$with_libatomic_ops\" != xnone -a x\"$THREADS\" != xnone],\n         [AC_MSG_RESULT([external])\n          ATOMIC_OPS_LIBS=\"-latomic_ops\"\n          AC_SUBST([ATOMIC_OPS_LIBS])],\n         [AC_MSG_RESULT([none])\n          AS_IF([test x\"$THREADS\" != xnone],\n                [AC_DEFINE([GC_BUILTIN_ATOMIC], [1],\n                           [Use GCC atomic intrinsics instead of\n                            libatomic_ops primitives.])])])\n    AO_TRYLINK_CFLAGS=\"\"],\n  [AC_MSG_RESULT([internal])\n   AO_TRYLINK_CFLAGS=\"-I${srcdir}/libatomic_ops/src\"\n   ATOMIC_OPS_CFLAGS='-I$(top_builddir)/libatomic_ops/src -I$(top_srcdir)/libatomic_ops/src'\n   ATOMIC_OPS_LIBS=\"\"\n   AC_SUBST([ATOMIC_OPS_CFLAGS])\n   AC_CONFIG_SUBDIRS([libatomic_ops])\n  ])\nAM_CONDITIONAL([USE_INTERNAL_LIBATOMIC_OPS],\n    [test x$with_libatomic_ops = xno -a x\"$THREADS\" != xnone])\nAM_CONDITIONAL([NEED_ATOMIC_OPS_ASM],\n    [test x$with_libatomic_ops = xno -a x$need_atomic_ops_asm = xtrue])\n\n# Check whether particular AO primitives are emulated with locks.\n# The check below is based on the fact that linking with the libatomic_ops\n# binary file is not needed in case of absence of the emulation (except for\n# Solaris SPARC).\nAS_IF([test x$with_libatomic_ops != xnone -a x$need_atomic_ops_asm != xtrue],\n    [old_CFLAGS=\"$CFLAGS\"\n     CFLAGS=\"$CFLAGS $AO_TRYLINK_CFLAGS $CFLAGS_EXTRA\"\n     AC_MSG_CHECKING([for lock-free AO_or primitive])\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([#include \"atomic_ops.h\"],\n                                     [AO_t x=0; AO_or(&x,1)])],\n       [AC_MSG_RESULT(yes)\n        AC_DEFINE([HAVE_LOCKFREE_AO_OR], [1],\n          [libatomic_ops AO_or primitive implementation is lock-free.])],\n       [AC_MSG_RESULT(no)])\n     AC_MSG_CHECKING([for lock-free AO load/store, test-and-set primitives])\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([#include \"atomic_ops.h\"],\n [AO_t x=0;unsigned char c=0;AO_TS_t z=AO_TS_INITIALIZER;\n  (void)AO_test_and_set_acquire(&z);AO_CLEAR(&z);AO_compiler_barrier();\n  AO_store(&x,AO_load(&x)+1);AO_char_store(&c,AO_char_load(&c)+1);\n  AO_store_release(&x,AO_load_acquire(&x)+1)])],\n        [AC_MSG_RESULT(yes)],\n        [AC_MSG_RESULT(no)\n         use_thread_local_alloc=no\n         AC_DEFINE([BASE_ATOMIC_OPS_EMULATED], [1],\n                   [AO load, store and/or test-and-set primitives are\n                    implemented in libatomic_ops using locks.])])\n      AS_IF([test x$use_parallel_mark != xno],\n        [AC_MSG_CHECKING(\n            [for lock-free compare-and-swap and fetch-and-add primitives])\n         AC_LINK_IFELSE([AC_LANG_PROGRAM([\n#             define AO_REQUIRE_CAS\n#             include \"atomic_ops.h\"\n            ],\n [AO_t x=0;(void)AO_fetch_and_add(&x,1);(void)AO_compare_and_swap(&x,1,2)])],\n                    [AC_MSG_RESULT(yes)],\n                    [AC_MSG_RESULT(no)\n                     use_parallel_mark=no ])])\n      CFLAGS=\"$old_CFLAGS\"])\n\nAS_IF([test x$use_parallel_mark != xno],\n      [AC_DEFINE(PARALLEL_MARK)])\nAS_IF([test x$use_thread_local_alloc != xno],\n      [AC_DEFINE(THREAD_LOCAL_ALLOC)])\nAM_CONDITIONAL(THREAD_LOCAL_ALLOC, test x$use_thread_local_alloc != xno)\n\nAC_ARG_ENABLE(handle-fork,\n    [AS_HELP_STRING([--enable-handle-fork[=yes|no|auto|manual]],\n                    [attempt to ensure a usable collector after fork()\n                     in multi-threaded programs (default: auto;\n                     manual: GC_atfork_prepare/parent/child should be\n                     called by the client)])])\nif test \"${enable_handle_fork}\" = yes; then\n    AC_DEFINE(HANDLE_FORK, 1,\n              [Define to install pthread_atfork() handlers by default.])\nelif test \"${enable_handle_fork}\" = no; then\n    AC_DEFINE(NO_HANDLE_FORK, 1,\n              [Prohibit installation of pthread_atfork() handlers.])\nelif test \"${enable_handle_fork}\" != manual -a x$THREADS = xposix; then\n    # If the option is omitted, pthread_atfork handlers are installed\n    # by default for the targets where pthread_atfork is known to work.\n    case \"$host\" in\n      *-*-aix* | *-*-android* | *-*-cygwin* | *-*-darwin* | *-*-freebsd* | \\\n      *-*-haiku* | *-*-hpux11* | *-*-irix* | *-*-kfreebsd*-gnu | \\\n      *-*-*linux* | *-*-netbsd* | *-*-openbsd* | *-*-osf* | *-*-solaris*)\n        AC_DEFINE(HANDLE_FORK)\n        ;;\n    esac\nfi\n\ndnl Produce the Files\ndnl -----------------\n\nAC_CONFIG_FILES([Makefile bdw-gc.pc])\n\nAC_CONFIG_COMMANDS([default],,\n   [srcdir=\"${srcdir}\"\n    host=${host}\n    CONFIG_SHELL=${CONFIG_SHELL-/bin/sh}\n    CC=\"${CC}\"\n    DEFS=\"$DEFS\"])\n\nAC_OUTPUT\n"
        },
        {
          "name": "cord",
          "type": "tree",
          "content": null
        },
        {
          "name": "darwin_stop_world.c",
          "type": "blob",
          "size": 25.310546875,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n * Copyright (c) 2000-2010 by Hewlett-Packard Development Company.\n * All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/pthread_support.h\"\n\n/* This probably needs more porting work to ppc64. */\n\n#if defined(DARWIN) && defined(THREADS)\n\n#  include <mach/machine.h>\n#  include <sys/sysctl.h>\n\n#  if defined(ARM32) && defined(ARM_THREAD_STATE32)\n#    include <CoreFoundation/CoreFoundation.h>\n#  endif\n\n/* From \"Inside Mac OS X - Mach-O Runtime Architecture\" published by Apple\n   Page 49:\n   \"The space beneath the stack pointer, where a new stack frame would normally\n   be allocated, is called the red zone. This area as shown in Figure 3-2 may\n   be used for any purpose as long as a new stack frame does not need to be\n   added to the stack.\"\n\n   Page 50: \"If a leaf procedure's red zone usage would exceed 224 bytes, then\n   it must set up a stack frame just like routines that call other routines.\"\n*/\n#  ifdef POWERPC\n#    if CPP_WORDSZ == 32\n#      define PPC_RED_ZONE_SIZE 224\n#    elif CPP_WORDSZ == 64\n#      define PPC_RED_ZONE_SIZE 320\n#    endif\n#  endif\n\n#  ifndef DARWIN_DONT_PARSE_STACK\n\ntypedef struct StackFrame {\n  unsigned long savedSP;\n  unsigned long savedCR;\n  unsigned long savedLR;\n  /* unsigned long reserved[2]; */\n  /* unsigned long savedRTOC; */\n} StackFrame;\n\nGC_INNER ptr_t\nGC_FindTopOfStack(unsigned long stack_start)\n{\n  StackFrame *frame = (StackFrame *)MAKE_CPTR(stack_start);\n\n  if (NULL == frame) {\n#    ifdef POWERPC\n#      if CPP_WORDSZ == 32\n    __asm__ __volatile__(\"lwz %0,0(r1)\" : \"=r\"(frame));\n#      else\n    __asm__ __volatile__(\"ld %0,0(r1)\" : \"=r\"(frame));\n#      endif\n#    elif defined(ARM32)\n    volatile ptr_t sp_reg;\n\n    __asm__ __volatile__(\"mov %0, r7\\n\" : \"=r\"(sp_reg));\n    frame = (/* no volatile */ StackFrame *)sp_reg;\n#    elif defined(AARCH64)\n    volatile ptr_t sp_reg;\n\n    __asm__ __volatile__(\"mov %0, x29\\n\" : \"=r\"(sp_reg));\n    frame = (/* no volatile */ StackFrame *)sp_reg;\n#    else\n#      if defined(CPPCHECK)\n    GC_noop1_ptr(&frame);\n#      endif\n    ABORT(\"GC_FindTopOfStack(0) is not implemented\");\n#    endif\n  }\n\n#    ifdef DEBUG_THREADS_EXTRA\n  GC_log_printf(\"FindTopOfStack start at sp= %p\\n\", (void *)frame);\n#    endif\n  while (frame->savedSP != 0) { /* stop if no more stack frames */\n    unsigned long maskedLR;\n\n#    ifdef CPPCHECK\n    GC_noop1(frame->savedCR);\n#    endif\n    frame = (StackFrame *)MAKE_CPTR(frame->savedSP);\n\n    /* We do these next two checks after going to the next frame        */\n    /* because the LR for the first stack frame in the loop is not set  */\n    /* up on purpose, so we should not check it.                        */\n    maskedLR = frame->savedLR & ~0x3UL;\n    if (0 == maskedLR || ~0x3UL == maskedLR)\n      break; /* if the next LR is bogus, stop */\n  }\n#    ifdef DEBUG_THREADS_EXTRA\n  GC_log_printf(\"FindTopOfStack finish at sp= %p\\n\", (void *)frame);\n#    endif\n  return (ptr_t)frame;\n}\n\n#  endif /* !DARWIN_DONT_PARSE_STACK */\n\n/* GC_query_task_threads controls whether to obtain the list of */\n/* the threads from the kernel or to use GC_threads table.      */\n#  ifdef GC_NO_THREADS_DISCOVERY\n#    define GC_query_task_threads FALSE\n#  elif defined(GC_DISCOVER_TASK_THREADS)\n#    define GC_query_task_threads TRUE\n#  else\nSTATIC GC_bool GC_query_task_threads = FALSE;\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\n/* Use implicit threads registration (all task threads excluding the GC */\n/* special ones are stopped and scanned).  Should be called before      */\n/* GC_INIT() (or, at least, before going multi-threaded).  Deprecated.  */\nGC_API void GC_CALL\nGC_use_threads_discovery(void)\n{\n#  ifdef GC_NO_THREADS_DISCOVERY\n  ABORT(\"Darwin task-threads-based stop and push unsupported\");\n#  else\n#    ifndef GC_ALWAYS_MULTITHREADED\n  GC_ASSERT(!GC_need_to_lock);\n#    endif\n#    ifndef GC_DISCOVER_TASK_THREADS\n  GC_query_task_threads = TRUE;\n#    endif\n  GC_init();\n#  endif\n}\n\n#  ifndef kCFCoreFoundationVersionNumber_iOS_8_0\n#    define kCFCoreFoundationVersionNumber_iOS_8_0 1140.1\n#  endif\n\n#  define THREAD_ACT_TO_VPTR(t) THREAD_ID_TO_VPTR(t)\n#  define MACH_PORT_TO_VPTR(t) THREAD_ID_TO_VPTR(t)\n\n/* Evaluates the stack range for a given thread.  Returns the lower     */\n/* bound and sets *phi to the upper one.  Sets *pfound_me to TRUE if    */\n/* this is current thread, otherwise the value is not changed.          */\nSTATIC ptr_t\nGC_stack_range_for(ptr_t *phi, thread_act_t thread, GC_thread p,\n                   mach_port_t my_thread, ptr_t *paltstack_lo,\n                   ptr_t *paltstack_hi, GC_bool *pfound_me)\n{\n#  ifdef DARWIN_DONT_PARSE_STACK\n  GC_stack_context_t crtn;\n#  endif\n  ptr_t lo;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (thread == my_thread) {\n    GC_ASSERT(NULL == p || (p->flags & DO_BLOCKING) == 0);\n    lo = GC_approx_sp();\n#  ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(0);\n#  endif\n    *pfound_me = TRUE;\n  } else if (p != NULL && (p->flags & DO_BLOCKING) != 0) {\n    lo = p->crtn->stack_ptr;\n#  ifndef DARWIN_DONT_PARSE_STACK\n    *phi = p->crtn->topOfStack;\n#  endif\n\n  } else {\n    /* MACHINE_THREAD_STATE_COUNT does not seem to be defined       */\n    /* everywhere.  Hence we use our own version.  Alternatively,   */\n    /* we could use THREAD_STATE_MAX (but seems to be not optimal). */\n    kern_return_t kern_result;\n    GC_THREAD_STATE_T state;\n\n#  if defined(ARM32) && defined(ARM_THREAD_STATE32)\n    /* Use ARM_UNIFIED_THREAD_STATE on iOS8+ 32-bit targets and on    */\n    /* 64-bit H/W (iOS7+ 32-bit mode).                                */\n    size_t size;\n    static cpu_type_t cputype = 0;\n\n    if (cputype == 0) {\n      sysctlbyname(\"hw.cputype\", &cputype, &size, NULL, 0);\n    }\n    if (cputype == CPU_TYPE_ARM64\n        || kCFCoreFoundationVersionNumber\n               >= kCFCoreFoundationVersionNumber_iOS_8_0) {\n      arm_unified_thread_state_t unified_state;\n      mach_msg_type_number_t unified_thread_state_count\n          = ARM_UNIFIED_THREAD_STATE_COUNT;\n#    if defined(CPPCHECK)\n#      define GC_ARM_UNIFIED_THREAD_STATE 1\n#    else\n#      define GC_ARM_UNIFIED_THREAD_STATE ARM_UNIFIED_THREAD_STATE\n#    endif\n      kern_result = thread_get_state(thread, GC_ARM_UNIFIED_THREAD_STATE,\n                                     (natural_t *)&unified_state,\n                                     &unified_thread_state_count);\n#    if !defined(CPPCHECK)\n      if (unified_state.ash.flavor != ARM_THREAD_STATE32) {\n        ABORT(\"unified_state flavor should be ARM_THREAD_STATE32\");\n      }\n#    endif\n      state = unified_state;\n    } else\n#  endif\n    /* else */ {\n      mach_msg_type_number_t thread_state_count = GC_MACH_THREAD_STATE_COUNT;\n\n      /* Get the thread state (registers, etc.) */\n      do {\n        kern_result\n            = thread_get_state(thread, GC_MACH_THREAD_STATE,\n                               (natural_t *)&state, &thread_state_count);\n      } while (kern_result == KERN_ABORTED);\n    }\n#  ifdef DEBUG_THREADS\n    GC_log_printf(\"thread_get_state returns %d\\n\", kern_result);\n#  endif\n    if (kern_result != KERN_SUCCESS)\n      ABORT(\"thread_get_state failed\");\n\n#  if defined(I386)\n    lo = (ptr_t)state.THREAD_FLD(esp);\n#    ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(state.THREAD_FLD(esp));\n#    endif\n    GC_push_one(state.THREAD_FLD(eax));\n    GC_push_one(state.THREAD_FLD(ebx));\n    GC_push_one(state.THREAD_FLD(ecx));\n    GC_push_one(state.THREAD_FLD(edx));\n    GC_push_one(state.THREAD_FLD(edi));\n    GC_push_one(state.THREAD_FLD(esi));\n    GC_push_one(state.THREAD_FLD(ebp));\n\n#  elif defined(X86_64)\n    lo = (ptr_t)state.THREAD_FLD(rsp);\n#    ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(state.THREAD_FLD(rsp));\n#    endif\n    GC_push_one(state.THREAD_FLD(rax));\n    GC_push_one(state.THREAD_FLD(rbx));\n    GC_push_one(state.THREAD_FLD(rcx));\n    GC_push_one(state.THREAD_FLD(rdx));\n    GC_push_one(state.THREAD_FLD(rdi));\n    GC_push_one(state.THREAD_FLD(rsi));\n    GC_push_one(state.THREAD_FLD(rbp));\n    /* rsp is skipped.        */\n    GC_push_one(state.THREAD_FLD(r8));\n    GC_push_one(state.THREAD_FLD(r9));\n    GC_push_one(state.THREAD_FLD(r10));\n    GC_push_one(state.THREAD_FLD(r11));\n    GC_push_one(state.THREAD_FLD(r12));\n    GC_push_one(state.THREAD_FLD(r13));\n    GC_push_one(state.THREAD_FLD(r14));\n    GC_push_one(state.THREAD_FLD(r15));\n\n#  elif defined(POWERPC)\n    lo = (ptr_t)(state.THREAD_FLD(r1) - PPC_RED_ZONE_SIZE);\n#    ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(state.THREAD_FLD(r1));\n#    endif\n    GC_push_one(state.THREAD_FLD(r0));\n    /* r1 is skipped. */\n    GC_push_one(state.THREAD_FLD(r2));\n    GC_push_one(state.THREAD_FLD(r3));\n    GC_push_one(state.THREAD_FLD(r4));\n    GC_push_one(state.THREAD_FLD(r5));\n    GC_push_one(state.THREAD_FLD(r6));\n    GC_push_one(state.THREAD_FLD(r7));\n    GC_push_one(state.THREAD_FLD(r8));\n    GC_push_one(state.THREAD_FLD(r9));\n    GC_push_one(state.THREAD_FLD(r10));\n    GC_push_one(state.THREAD_FLD(r11));\n    GC_push_one(state.THREAD_FLD(r12));\n    GC_push_one(state.THREAD_FLD(r13));\n    GC_push_one(state.THREAD_FLD(r14));\n    GC_push_one(state.THREAD_FLD(r15));\n    GC_push_one(state.THREAD_FLD(r16));\n    GC_push_one(state.THREAD_FLD(r17));\n    GC_push_one(state.THREAD_FLD(r18));\n    GC_push_one(state.THREAD_FLD(r19));\n    GC_push_one(state.THREAD_FLD(r20));\n    GC_push_one(state.THREAD_FLD(r21));\n    GC_push_one(state.THREAD_FLD(r22));\n    GC_push_one(state.THREAD_FLD(r23));\n    GC_push_one(state.THREAD_FLD(r24));\n    GC_push_one(state.THREAD_FLD(r25));\n    GC_push_one(state.THREAD_FLD(r26));\n    GC_push_one(state.THREAD_FLD(r27));\n    GC_push_one(state.THREAD_FLD(r28));\n    GC_push_one(state.THREAD_FLD(r29));\n    GC_push_one(state.THREAD_FLD(r30));\n    GC_push_one(state.THREAD_FLD(r31));\n\n#  elif defined(ARM32)\n    lo = (ptr_t)state.THREAD_FLD(sp);\n#    ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(state.THREAD_FLD(r[7])); /* fp */\n#    endif\n    {\n      int j;\n      for (j = 0; j < 7; j++)\n        GC_push_one(state.THREAD_FLD(r[j]));\n      j++; /* \"r7\" is skipped (iOS uses it as a frame pointer) */\n      for (; j <= 12; j++)\n        GC_push_one(state.THREAD_FLD(r[j]));\n    }\n    /* \"cpsr\", \"pc\" and \"sp\" are skipped */\n    GC_push_one(state.THREAD_FLD(lr));\n\n#  elif defined(AARCH64)\n    lo = (ptr_t)state.THREAD_FLD(sp);\n#    ifndef DARWIN_DONT_PARSE_STACK\n    *phi = GC_FindTopOfStack(state.THREAD_FLD(fp));\n#    endif\n    {\n      int j;\n      for (j = 0; j <= 28; j++) {\n        GC_push_one(state.THREAD_FLD(x[j]));\n      }\n    }\n    /* \"cpsr\", \"fp\", \"pc\" and \"sp\" are skipped */\n    GC_push_one(state.THREAD_FLD(lr));\n\n#  elif defined(CPPCHECK)\n    lo = NULL;\n#  else\n#    error FIXME for non-arm/ppc/x86 architectures\n#  endif\n  } /* thread != my_thread */\n\n#  ifndef DARWIN_DONT_PARSE_STACK\n  /* TODO: Determine p and handle altstack if !DARWIN_DONT_PARSE_STACK */\n  UNUSED_ARG(paltstack_hi);\n#  else\n  /* p is guaranteed to be non-NULL regardless of GC_query_task_threads. */\n#    ifdef CPPCHECK\n  if (NULL == p)\n    ABORT(\"Bad GC_stack_range_for call\");\n#    endif\n  crtn = p->crtn;\n  *phi = crtn->stack_end;\n  if (crtn->altstack != NULL && ADDR_GE(lo, crtn->altstack)\n      && ADDR_GE(crtn->altstack + crtn->altstack_size, lo)) {\n    *paltstack_lo = lo;\n    *paltstack_hi = crtn->altstack + crtn->altstack_size;\n    lo = crtn->normstack;\n    *phi = lo + crtn->normstack_size;\n  } else\n#  endif\n  /* else */ {\n    *paltstack_lo = NULL;\n  }\n#  if defined(STACKPTR_CORRECTOR_AVAILABLE) && defined(DARWIN_DONT_PARSE_STACK)\n  if (GC_sp_corrector != 0)\n    GC_sp_corrector((void **)&lo, THREAD_ID_TO_VPTR(p->id));\n#  endif\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Darwin: Stack for thread %p is [%p,%p)\\n\",\n                THREAD_ACT_TO_VPTR(thread), (void *)lo, (void *)*phi);\n#  endif\n  return lo;\n}\n\nGC_INNER void\nGC_push_all_stacks(void)\n{\n  ptr_t hi, altstack_lo, altstack_hi;\n  task_t my_task = current_task();\n  mach_port_t my_thread = mach_thread_self();\n  GC_bool found_me = FALSE;\n  int nthreads = 0;\n  word total_size = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_thr_initialized);\n\n#  ifndef DARWIN_DONT_PARSE_STACK\n  if (GC_query_task_threads) {\n    int i;\n    kern_return_t kern_result;\n    thread_act_array_t act_list;\n    mach_msg_type_number_t listcount;\n\n    /* Obtain the list of the threads from the kernel.  */\n    kern_result = task_threads(my_task, &act_list, &listcount);\n    if (kern_result != KERN_SUCCESS)\n      ABORT(\"task_threads failed\");\n\n    for (i = 0; i < (int)listcount; i++) {\n      thread_act_t thread = act_list[i];\n      ptr_t lo = GC_stack_range_for(&hi, thread, NULL, my_thread, &altstack_lo,\n                                    &altstack_hi, &found_me);\n\n      if (lo) {\n        GC_ASSERT(ADDR_GE(hi, lo));\n        total_size += hi - lo;\n        GC_push_all_stack(lo, hi);\n      }\n      /* TODO: Handle altstack */\n      nthreads++;\n      mach_port_deallocate(my_task, thread);\n    } /* for (i=0; ...) */\n\n    vm_deallocate(my_task, (vm_address_t)act_list,\n                  sizeof(thread_t) * listcount);\n  } else\n#  endif /* !DARWIN_DONT_PARSE_STACK */\n  /* else */ {\n    int i;\n\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      GC_thread p;\n\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        GC_ASSERT(THREAD_TABLE_INDEX(p->id) == i);\n        if (!KNOWN_FINISHED(p)) {\n          thread_act_t thread = (thread_act_t)(p->mach_thread);\n          ptr_t lo = GC_stack_range_for(&hi, thread, p, my_thread,\n                                        &altstack_lo, &altstack_hi, &found_me);\n\n          if (lo) {\n            GC_ASSERT(ADDR_GE(hi, lo));\n            total_size += hi - lo;\n            GC_push_all_stack_sections(lo, hi, p->crtn->traced_stack_sect);\n          }\n          if (altstack_lo) {\n            total_size += altstack_hi - altstack_lo;\n            GC_push_all_stack(altstack_lo, altstack_hi);\n          }\n          nthreads++;\n        }\n      }\n    } /* for (i=0; ...) */\n  }\n\n  mach_port_deallocate(my_task, my_thread);\n  GC_VERBOSE_LOG_PRINTF(\"Pushed %d thread stacks\\n\", nthreads);\n  if (!found_me && !GC_in_thread_creation)\n    ABORT(\"Collecting from unknown thread\");\n  GC_total_stacksize = total_size;\n}\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n\n#    ifdef MPROTECT_VDB\nSTATIC mach_port_t GC_mach_handler_thread = 0;\nSTATIC GC_bool GC_use_mach_handler_thread = FALSE;\n\nGC_INNER void\nGC_darwin_register_self_mach_handler(void)\n{\n  GC_mach_handler_thread = mach_thread_self();\n  GC_use_mach_handler_thread = TRUE;\n}\n#    endif /* MPROTECT_VDB */\n\n#    ifndef GC_MAX_MACH_THREADS\n#      define GC_MAX_MACH_THREADS THREAD_TABLE_SZ\n#    endif\n\nstruct GC_mach_thread {\n  thread_act_t thread;\n  GC_bool suspended;\n};\n\nstruct GC_mach_thread GC_mach_threads[GC_MAX_MACH_THREADS];\nSTATIC int GC_mach_threads_count = 0;\n/* FIXME: it is better to implement GC_mach_threads as a hash set.  */\n\n/* Return true if there is a thread in act_list that was not in old_list. */\nSTATIC GC_bool\nGC_suspend_thread_list(thread_act_array_t act_list, int count,\n                       thread_act_array_t old_list, int old_count,\n                       task_t my_task, mach_port_t my_thread)\n{\n  int i;\n  int j = -1;\n  GC_bool changed = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < count; i++) {\n    thread_act_t thread = act_list[i];\n    GC_bool found;\n    kern_return_t kern_result;\n\n    if (thread == my_thread\n#    ifdef MPROTECT_VDB\n        || (GC_mach_handler_thread == thread && GC_use_mach_handler_thread)\n#    endif\n#    ifdef PARALLEL_MARK\n        || GC_is_mach_marker(thread) /* ignore the parallel markers */\n#    endif\n    ) {\n      /* Do not add our one, parallel marker and the handler threads;   */\n      /* consider it as found (e.g., it was processed earlier).         */\n      mach_port_deallocate(my_task, thread);\n      continue;\n    }\n\n    /* find the current thread in the old list */\n    found = FALSE;\n    {\n      int last_found = j; /* remember the previous found thread index */\n\n      /* Search for the thread starting from the last found one first.  */\n      while (++j < old_count)\n        if (old_list[j] == thread) {\n          found = TRUE;\n          break;\n        }\n      if (!found) {\n        /* If not found, search in the rest (beginning) of the list.    */\n        for (j = 0; j < last_found; j++)\n          if (old_list[j] == thread) {\n            found = TRUE;\n            break;\n          }\n      }\n    }\n\n    if (found) {\n      /* It is already in the list, skip processing, release mach port. */\n      mach_port_deallocate(my_task, thread);\n      continue;\n    }\n\n    /* Add it to the GC_mach_threads list.      */\n    if (GC_mach_threads_count == GC_MAX_MACH_THREADS)\n      ABORT(\"Too many threads\");\n    GC_mach_threads[GC_mach_threads_count].thread = thread;\n    /* default is not suspended */\n    GC_mach_threads[GC_mach_threads_count].suspended = FALSE;\n    changed = TRUE;\n\n#    ifdef DEBUG_THREADS\n    GC_log_printf(\"Suspending %p\\n\", THREAD_ACT_TO_VPTR(thread));\n#    endif\n    /* Unconditionally suspend the thread.  It will do no     */\n    /* harm if it is already suspended by the client logic.   */\n    GC_acquire_dirty_lock();\n    do {\n      kern_result = thread_suspend(thread);\n    } while (kern_result == KERN_ABORTED);\n    GC_release_dirty_lock();\n    if (kern_result != KERN_SUCCESS) {\n      /* The thread may have quit since the thread_threads() call we  */\n      /* mark already suspended so it's not dealt with anymore later. */\n      GC_mach_threads[GC_mach_threads_count].suspended = FALSE;\n    } else {\n      /* Mark the thread as suspended and require resume.     */\n      GC_mach_threads[GC_mach_threads_count].suspended = TRUE;\n      if (GC_on_thread_event)\n        GC_on_thread_event(GC_EVENT_THREAD_SUSPENDED,\n                           THREAD_ACT_TO_VPTR(thread));\n    }\n    GC_mach_threads_count++;\n  }\n  return changed;\n}\n\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\nGC_INNER void\nGC_stop_world(void)\n{\n  task_t my_task = current_task();\n  mach_port_t my_thread = mach_thread_self();\n  kern_return_t kern_result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_thr_initialized);\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Stopping the world from thread %p\\n\",\n                MACH_PORT_TO_VPTR(my_thread));\n#  endif\n#  ifdef PARALLEL_MARK\n  if (GC_parallel) {\n    GC_acquire_mark_lock();\n    /* We should have previously waited for it to become zero. */\n    GC_ASSERT(GC_fl_builder_count == 0);\n  }\n#  endif /* PARALLEL_MARK */\n\n  if (GC_query_task_threads) {\n#  ifndef GC_NO_THREADS_DISCOVERY\n    GC_bool changed;\n    thread_act_array_t act_list, prev_list;\n    mach_msg_type_number_t listcount, prevcount;\n\n    /* Clear out the mach threads list table.  We do not need to      */\n    /* really clear GC_mach_threads[] as it is used only in the range */\n    /* from 0 to GC_mach_threads_count-1, inclusive.                  */\n    GC_mach_threads_count = 0;\n\n    /* Loop stopping threads until you have gone over the whole list  */\n    /* twice without a new one appearing.  thread_create() won't      */\n    /* return (and thus the thread stop) until the new thread exists, */\n    /* so there is no window whereby you could stop a thread,         */\n    /* recognize it is stopped, but then have a new thread it created */\n    /* before stopping show up later.                                 */\n    changed = TRUE;\n    prev_list = NULL;\n    prevcount = 0;\n    do {\n      kern_result = task_threads(my_task, &act_list, &listcount);\n\n      if (kern_result == KERN_SUCCESS) {\n        changed = GC_suspend_thread_list(act_list, listcount, prev_list,\n                                         prevcount, my_task, my_thread);\n\n        if (prev_list != NULL) {\n          /* Thread ports are not deallocated by list, unused ports   */\n          /* deallocated in GC_suspend_thread_list, used - kept in    */\n          /* GC_mach_threads till GC_start_world as otherwise thread  */\n          /* object change can occur and GC_start_world will not      */\n          /* find the thread to resume which will cause app to hang.  */\n          vm_deallocate(my_task, (vm_address_t)prev_list,\n                        sizeof(thread_t) * prevcount);\n        }\n\n        /* Repeat while having changes. */\n        prev_list = act_list;\n        prevcount = listcount;\n      }\n    } while (changed);\n\n    GC_ASSERT(prev_list != 0);\n    /* The thread ports are not deallocated by list, see above.       */\n    vm_deallocate(my_task, (vm_address_t)act_list,\n                  sizeof(thread_t) * listcount);\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\n  } else {\n    unsigned i;\n\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      GC_thread p;\n\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        if ((p->flags & (FINISHED | DO_BLOCKING)) == 0\n            && p->mach_thread != my_thread) {\n          GC_acquire_dirty_lock();\n          do {\n            kern_result = thread_suspend(p->mach_thread);\n          } while (kern_result == KERN_ABORTED);\n          GC_release_dirty_lock();\n          if (kern_result != KERN_SUCCESS)\n            ABORT(\"thread_suspend failed\");\n          if (GC_on_thread_event)\n            GC_on_thread_event(GC_EVENT_THREAD_SUSPENDED,\n                               MACH_PORT_TO_VPTR(p->mach_thread));\n        }\n      }\n    }\n  }\n\n#  ifdef MPROTECT_VDB\n  if (GC_auto_incremental) {\n    GC_mprotect_stop();\n  }\n#  endif\n#  ifdef PARALLEL_MARK\n  if (GC_parallel)\n    GC_release_mark_lock();\n#  endif\n\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"World stopped from %p\\n\", MACH_PORT_TO_VPTR(my_thread));\n#  endif\n  mach_port_deallocate(my_task, my_thread);\n}\n\nGC_INLINE void\nGC_thread_resume(thread_act_t thread)\n{\n  kern_return_t kern_result;\n#  if defined(DEBUG_THREADS) || defined(GC_ASSERTIONS)\n  struct thread_basic_info info;\n  mach_msg_type_number_t outCount = THREAD_BASIC_INFO_COUNT;\n\n#    ifdef CPPCHECK\n  info.run_state = 0;\n#    endif\n  kern_result = thread_info(thread, THREAD_BASIC_INFO, (thread_info_t)&info,\n                            &outCount);\n  if (kern_result != KERN_SUCCESS)\n    ABORT(\"thread_info failed\");\n#  endif\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Resuming thread %p with state %d\\n\",\n                THREAD_ACT_TO_VPTR(thread), info.run_state);\n#  endif\n  /* Resume the thread. */\n  kern_result = thread_resume(thread);\n  if (kern_result != KERN_SUCCESS) {\n    WARN(\"thread_resume(%p) failed: mach port invalid\\n\", thread);\n  } else if (GC_on_thread_event) {\n    GC_on_thread_event(GC_EVENT_THREAD_UNSUSPENDED,\n                       THREAD_ACT_TO_VPTR(thread));\n  }\n}\n\nGC_INNER void\nGC_start_world(void)\n{\n  task_t my_task = current_task();\n\n  /* The allocator lock is held continuously since the world stopped.   */\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"World starting\\n\");\n#  endif\n#  ifdef MPROTECT_VDB\n  if (GC_auto_incremental) {\n    GC_mprotect_resume();\n  }\n#  endif\n\n  if (GC_query_task_threads) {\n#  ifndef GC_NO_THREADS_DISCOVERY\n    int i, j;\n    kern_return_t kern_result;\n    thread_act_array_t act_list;\n    mach_msg_type_number_t listcount;\n\n    kern_result = task_threads(my_task, &act_list, &listcount);\n    if (kern_result != KERN_SUCCESS)\n      ABORT(\"task_threads failed\");\n\n    j = (int)listcount;\n    for (i = 0; i < GC_mach_threads_count; i++) {\n      thread_act_t thread = GC_mach_threads[i].thread;\n\n      if (GC_mach_threads[i].suspended) {\n        /* The thread index found during the previous iteration       */\n        /* (count value means no thread found yet).                   */\n        int last_found = j;\n\n        /* Search for the thread starting from the last found one first. */\n        while (++j < (int)listcount) {\n          if (act_list[j] == thread)\n            break;\n        }\n        if (j >= (int)listcount) {\n          /* If not found, search in the rest (beginning) of the list. */\n          for (j = 0; j < last_found; j++) {\n            if (act_list[j] == thread)\n              break;\n          }\n        }\n        if (j != last_found) {\n          /* The thread is alive, resume it.  */\n          GC_thread_resume(thread);\n        }\n      } else {\n        /* This thread failed to be suspended by GC_stop_world, no    */\n        /* action is needed.                                          */\n#    ifdef DEBUG_THREADS\n        GC_log_printf(\"Not resuming thread %p as it is not suspended\\n\",\n                      THREAD_ACT_TO_VPTR(thread));\n#    endif\n      }\n      mach_port_deallocate(my_task, thread);\n    }\n\n    for (i = 0; i < (int)listcount; i++)\n      mach_port_deallocate(my_task, act_list[i]);\n    vm_deallocate(my_task, (vm_address_t)act_list,\n                  sizeof(thread_t) * listcount);\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\n  } else {\n    int i;\n    mach_port_t my_thread = mach_thread_self();\n\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      GC_thread p;\n\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        if ((p->flags & (FINISHED | DO_BLOCKING)) == 0\n            && p->mach_thread != my_thread)\n          GC_thread_resume(p->mach_thread);\n      }\n    }\n\n    mach_port_deallocate(my_task, my_thread);\n  }\n\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"World started\\n\");\n#  endif\n}\n\n#endif /* DARWIN && THREADS */\n"
        },
        {
          "name": "dbg_mlc.c",
          "type": "blob",
          "size": 35.7216796875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1997 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1999-2004 Hewlett-Packard Development Company, L.P.\n * Copyright (c) 2007 Free Software Foundation, Inc.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/dbg_mlc.h\"\n\n#ifndef MSWINCE\n#  include <errno.h>\n#endif\n#include <string.h>\n\n#ifndef SHORT_DBG_HDRS\n/* Check whether object given by its base pointer has debugging   */\n/* info.  base is assumed to point to a legitimate object in our  */\n/* heap.  This excludes the check as to whether the back pointer  */\n/* is odd, which is added by the GC_HAS_DEBUG_INFO macro.         */\n/* Note that if DBG_HDRS_ALL is set, uncollectible objects on     */\n/* free lists may not have debug information set.  Thus, it is    */\n/* not always safe to return TRUE (1), even if the client does    */\n/* its part.  Return -1 if the object with debug info has been    */\n/* marked as deallocated.                                         */\nGC_INNER int\nGC_has_other_debug_info(ptr_t base)\n{\n  ptr_t body = (ptr_t)((oh *)base + 1);\n  size_t sz = GC_size(base);\n\n  if (HBLKPTR(base) != HBLKPTR(body) || sz < DEBUG_BYTES + EXTRA_BYTES) {\n    return 0;\n  }\n  if (((oh *)base)->oh_sf != (START_FLAG ^ (GC_uintptr_t)body)\n      && ((GC_uintptr_t *)base)[BYTES_TO_PTRS(sz) - 1]\n             != (END_FLAG ^ (GC_uintptr_t)body)) {\n    return 0;\n  }\n  if (((oh *)base)->oh_sz == (GC_uintptr_t)sz) {\n    /* Object may have had debug info, but has been deallocated.  */\n    return -1;\n  }\n  return 1;\n}\n#endif /* !SHORT_DBG_HDRS */\n\n#ifdef KEEP_BACK_PTRS\n\n/* Use a custom trivial random() implementation as the standard   */\n/* one might lead to crashes (if used from a multi-threaded code) */\n/* or to a compiler warning about the deterministic result.       */\nstatic int\nGC_rand(void)\n{\n  static GC_RAND_STATE_T seed;\n\n  return GC_RAND_NEXT(&seed);\n}\n\n#  define RANDOM() (long)GC_rand()\n\n/* Store back pointer to source in dest, if that appears to be possible. */\n/* This is not completely safe, since we may mistakenly conclude that    */\n/* dest has a debugging wrapper.  But the error probability is very      */\n/* small, and this shouldn't be used in production code.                 */\n/* We assume that dest is the real base pointer.  Source will usually    */\n/* be a pointer to the interior of an object.                            */\nGC_INNER void\nGC_store_back_pointer(ptr_t source, ptr_t dest)\n{\n  if (GC_HAS_DEBUG_INFO(dest)) {\n#  ifdef PARALLEL_MARK\n    GC_cptr_store((volatile ptr_t *)&((oh *)dest)->oh_back_ptr,\n                  (ptr_t)HIDE_BACK_PTR(source));\n#  else\n    ((oh *)dest)->oh_back_ptr = HIDE_BACK_PTR(source);\n#  endif\n  }\n}\n\nGC_INNER void\nGC_marked_for_finalization(ptr_t dest)\n{\n  GC_store_back_pointer(MARKED_FOR_FINALIZATION, dest);\n}\n\nGC_API GC_ref_kind GC_CALL\nGC_get_back_ptr_info(void *dest, void **base_p, size_t *offset_p)\n{\n  oh *ohdr = (oh *)GC_base(dest);\n  ptr_t bp, bp_base;\n\n#  ifdef LINT2\n  /* Explicitly instruct the code analysis tool that                */\n  /* GC_get_back_ptr_info is not expected to be called with an      */\n  /* incorrect \"dest\" value.                                        */\n  if (!ohdr)\n    ABORT(\"Invalid GC_get_back_ptr_info argument\");\n#  endif\n  if (!GC_HAS_DEBUG_INFO((ptr_t)ohdr))\n    return GC_NO_SPACE;\n  bp = (ptr_t)GC_REVEAL_POINTER(ohdr->oh_back_ptr);\n  if (MARKED_FOR_FINALIZATION == bp)\n    return GC_FINALIZER_REFD;\n  if (MARKED_FROM_REGISTER == bp)\n    return GC_REFD_FROM_REG;\n  if (NOT_MARKED == bp)\n    return GC_UNREFERENCED;\n#  if ALIGNMENT == 1\n  /* Heuristically try to fix off-by-one errors we introduced by    */\n  /* insisting on even addresses.                                   */\n  {\n    ptr_t alternate_ptr = bp + 1;\n    ptr_t target = *(ptr_t *)bp;\n    ptr_t alternate_target = *(ptr_t *)alternate_ptr;\n\n    if (GC_least_real_heap_addr < ADDR(alternate_target)\n        && ADDR(alternate_target) < GC_greatest_real_heap_addr\n        && (GC_least_real_heap_addr >= ADDR(target)\n            || ADDR(target) >= GC_greatest_real_heap_addr)) {\n      bp = alternate_ptr;\n    }\n  }\n#  endif\n  bp_base = (ptr_t)GC_base(bp);\n  if (NULL == bp_base) {\n    *base_p = bp;\n    *offset_p = 0;\n    return GC_REFD_FROM_ROOT;\n  } else {\n    if (GC_HAS_DEBUG_INFO(bp_base))\n      bp_base += sizeof(oh);\n    *base_p = bp_base;\n    *offset_p = (size_t)(bp - bp_base);\n    return GC_REFD_FROM_HEAP;\n  }\n}\n\n/* Generate a random heap address.  The resulting address is in the   */\n/* heap, but not necessarily inside a valid object.                   */\nGC_API void *GC_CALL\nGC_generate_random_heap_address(void)\n{\n  size_t i;\n  word heap_offset = (word)RANDOM();\n\n  if (GC_heapsize > (word)GC_RAND_MAX) {\n    heap_offset *= GC_RAND_MAX;\n    heap_offset += (word)RANDOM();\n  }\n\n  /* This does not yield a uniform distribution, especially if e.g.   */\n  /* RAND_MAX is 1.5*GC_heapsize.  But for typical cases,  it is not  */\n  /* too bad.                                                         */\n  heap_offset %= GC_heapsize;\n\n  for (i = 0;; ++i) {\n    size_t size;\n\n    if (i >= GC_n_heap_sects)\n      ABORT(\"GC_generate_random_heap_address: size inconsistency\");\n\n    size = GC_heap_sects[i].hs_bytes;\n    if (heap_offset < size)\n      break;\n    heap_offset -= size;\n  }\n  return GC_heap_sects[i].hs_start + heap_offset;\n}\n\n/* Generate a random address inside a valid marked heap object. */\nGC_API void *GC_CALL\nGC_generate_random_valid_address(void)\n{\n  ptr_t result;\n  ptr_t base;\n\n  do {\n    result = (ptr_t)GC_generate_random_heap_address();\n    base = (ptr_t)GC_base(result);\n  } while (NULL == base || !GC_is_marked(base));\n  return result;\n}\n\nGC_API void GC_CALL\nGC_print_backtrace(void *p)\n{\n  void *current = p;\n  int i;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  GC_print_heap_obj((ptr_t)GC_base(current));\n\n  for (i = 0;; ++i) {\n    void *base;\n    size_t offset;\n    GC_ref_kind source = GC_get_back_ptr_info(current, &base, &offset);\n\n    if (GC_UNREFERENCED == source) {\n      GC_err_printf(\"Reference could not be found\\n\");\n      break;\n    }\n    if (GC_NO_SPACE == source) {\n      GC_err_printf(\"No debug info in object: Can't find reference\\n\");\n      break;\n    }\n    GC_err_printf(\"Reachable via %d levels of pointers from \", i);\n    switch (source) {\n    case GC_REFD_FROM_ROOT:\n      GC_err_printf(\"root at %p\\n\\n\", base);\n      return;\n    case GC_REFD_FROM_REG:\n      GC_err_printf(\"root in register\\n\\n\");\n      return;\n    case GC_FINALIZER_REFD:\n      GC_err_printf(\"list of finalizable objects\\n\\n\");\n      return;\n    case GC_REFD_FROM_HEAP:\n      GC_err_printf(\"offset %ld in object:\\n\", (long)offset);\n      /* Take GC_base(base) to get real base, i.e. header.    */\n      GC_print_heap_obj((ptr_t)GC_base(base));\n      break;\n    default:\n      GC_err_printf(\"INTERNAL ERROR: UNEXPECTED SOURCE!!!!\\n\");\n      return;\n    }\n    current = base;\n  }\n}\n\nGC_API void GC_CALL\nGC_generate_random_backtrace(void)\n{\n  void *current;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  if (GC_try_to_collect(GC_never_stop_func) == 0) {\n    GC_err_printf(\"Cannot generate a backtrace: \"\n                  \"garbage collection is disabled!\\n\");\n    return;\n  }\n\n  /* Generate/print a backtrace from a random heap address.   */\n  LOCK();\n  current = GC_generate_random_valid_address();\n  UNLOCK();\n  GC_printf(\"\\n***Chosen address %p in object\\n\", current);\n  GC_print_backtrace(current);\n}\n\n#endif /* KEEP_BACK_PTRS */\n\n#define CROSSES_HBLK(p, sz) \\\n  ((ADDR((p) + (sizeof(oh) - 1) + (sz)) ^ ADDR(p)) >= HBLKSIZE)\n\nGC_INNER void *\nGC_store_debug_info_inner(void *base, size_t sz, const char *string,\n                          int linenum)\n{\n  GC_uintptr_t *result = (GC_uintptr_t *)((oh *)base + 1);\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_size(base) >= sizeof(oh) + sz);\n  GC_ASSERT(!(SMALL_OBJ(sz) && CROSSES_HBLK((ptr_t)base, sz)));\n#ifdef KEEP_BACK_PTRS\n  ((oh *)base)->oh_back_ptr = HIDE_BACK_PTR(NOT_MARKED);\n#endif\n#ifdef MAKE_BACK_GRAPH\n  ((oh *)base)->oh_bg_ptr = HIDE_BACK_PTR((ptr_t)0);\n#endif\n  ((oh *)base)->oh_string = string;\n  ((oh *)base)->oh_int = linenum;\n#ifdef SHORT_DBG_HDRS\n  UNUSED_ARG(sz);\n#else\n  ((oh *)base)->oh_sz = (GC_uintptr_t)sz;\n  ((oh *)base)->oh_sf = START_FLAG ^ (GC_uintptr_t)result;\n  ((GC_uintptr_t *)base)[BYTES_TO_PTRS(GC_size(base)) - 1]\n      = result[BYTES_TO_PTRS_ROUNDUP(sz)] = END_FLAG ^ (GC_uintptr_t)result;\n#endif\n  return result;\n}\n\n/* Check the allocation is successful, store debugging info into base,  */\n/* start the debugging mode (if not yet), and return displaced pointer. */\nstatic void *\nstore_debug_info(void *base, size_t lb, const char *fn, GC_EXTRA_PARAMS)\n{\n  void *result;\n\n  if (NULL == base) {\n    GC_err_printf(\"%s(%lu) returning NULL (%s:%d)\\n\", fn, (unsigned long)lb, s,\n                  i);\n    return NULL;\n  }\n  LOCK();\n  if (!GC_debugging_started)\n    GC_start_debugging_inner();\n  result = GC_store_debug_info_inner(base, lb, s, i);\n  ADD_CALL_CHAIN(base, ra);\n  UNLOCK();\n  return result;\n}\n\n#ifndef SHORT_DBG_HDRS\n/* Check the object with debugging info at ohdr.  Return NULL if it   */\n/* is OK.  Else return clobbered address.                             */\nSTATIC ptr_t\nGC_check_annotated_obj(oh *ohdr)\n{\n  ptr_t body = (ptr_t)(ohdr + 1);\n  size_t gc_sz = GC_size(ohdr);\n  size_t lpw_up;\n\n  if (ohdr->oh_sz + DEBUG_BYTES > (GC_uintptr_t)gc_sz) {\n    return (ptr_t)(&ohdr->oh_sz);\n  }\n  if (ohdr->oh_sf != (START_FLAG ^ (GC_uintptr_t)body)) {\n    return (ptr_t)(&ohdr->oh_sf);\n  }\n\n  {\n    size_t lpw_m1 = BYTES_TO_PTRS(gc_sz) - 1;\n\n    if (((GC_uintptr_t *)ohdr)[lpw_m1] != (END_FLAG ^ (GC_uintptr_t)body)) {\n      return (ptr_t)(&((GC_uintptr_t *)ohdr)[lpw_m1]);\n    }\n  }\n  lpw_up = BYTES_TO_PTRS_ROUNDUP((size_t)ohdr->oh_sz);\n  if (((GC_uintptr_t *)body)[lpw_up] != (END_FLAG ^ (GC_uintptr_t)body)) {\n    return (ptr_t)(&((GC_uintptr_t *)body)[lpw_up]);\n  }\n  return NULL;\n}\n#endif /* !SHORT_DBG_HDRS */\n\nSTATIC GC_describe_type_fn GC_describe_type_fns[MAXOBJKINDS] = { 0 };\n\nGC_API void GC_CALL\nGC_register_describe_type_fn(int k, GC_describe_type_fn fn)\n{\n  GC_ASSERT((unsigned)k < MAXOBJKINDS);\n  GC_describe_type_fns[k] = fn;\n}\n\n#define GET_OH_LINENUM(ohdr) ((int)(ohdr)->oh_int)\n\n#ifndef SHORT_DBG_HDRS\n#  define IF_NOT_SHORTDBG_HDRS(x) x\n#  define COMMA_IFNOT_SHORTDBG_HDRS(x) /* comma */ , x\n#else\n#  define IF_NOT_SHORTDBG_HDRS(x)\n#  define COMMA_IFNOT_SHORTDBG_HDRS(x)\n#endif\n\n/* Print a human-readable description of the object to stderr.  */\n/* The object is assumed to have the debugging info.            */\nSTATIC void\nGC_print_obj(ptr_t base)\n{\n  oh *ohdr = (oh *)base;\n  ptr_t q;\n  hdr *hhdr;\n  int k;\n  const char *kind_str;\n  char buffer[GC_TYPE_DESCR_LEN + 1];\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n#ifdef LINT2\n  if (!ohdr)\n    ABORT(\"Invalid GC_print_obj argument\");\n#endif\n\n  q = (ptr_t)(ohdr + 1);\n  /* Print a type description for the object whose client-visible     */\n  /* address is q.                                                    */\n  hhdr = GC_find_header(q);\n  k = hhdr->hb_obj_kind;\n  if (GC_describe_type_fns[k] != 0 && GC_is_marked(ohdr)) {\n    /* This should preclude free-list objects except with   */\n    /* thread-local allocation.                             */\n    buffer[GC_TYPE_DESCR_LEN] = 0;\n    (GC_describe_type_fns[k])(q, buffer);\n    GC_ASSERT(buffer[GC_TYPE_DESCR_LEN] == 0);\n    kind_str = buffer;\n  } else {\n    switch (k) {\n    case PTRFREE:\n      kind_str = \"PTRFREE\";\n      break;\n    case NORMAL:\n      kind_str = \"NORMAL\";\n      break;\n    case UNCOLLECTABLE:\n      kind_str = \"UNCOLLECTABLE\";\n      break;\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n    case AUNCOLLECTABLE:\n      kind_str = \"ATOMIC_UNCOLLECTABLE\";\n      break;\n#endif\n    default:\n      kind_str = NULL;\n      /* The alternative is to use snprintf(buffer) but the       */\n      /* latter is not quite portable (see vsnprintf in misc.c).  */\n    }\n  }\n\n  if (NULL != kind_str) {\n    GC_err_printf(\"%p (%s:%d,\" IF_NOT_SHORTDBG_HDRS(\" sz= %lu,\") \" %s)\\n\",\n                  (void *)((ptr_t)ohdr + sizeof(oh)), ohdr->oh_string,\n                  GET_OH_LINENUM(ohdr) /*, */\n                  COMMA_IFNOT_SHORTDBG_HDRS((unsigned long)ohdr->oh_sz),\n                  kind_str);\n  } else {\n    GC_err_printf(\"%p (%s:%d,\" IF_NOT_SHORTDBG_HDRS(\n                      \" sz= %lu,\") \" kind= %d, descr= 0x%lx)\\n\",\n                  (void *)((ptr_t)ohdr + sizeof(oh)), ohdr->oh_string,\n                  GET_OH_LINENUM(ohdr) /*, */\n                  COMMA_IFNOT_SHORTDBG_HDRS((unsigned long)ohdr->oh_sz),\n                  k, (unsigned long)hhdr->hb_descr);\n  }\n  PRINT_CALL_CHAIN(ohdr);\n}\n\nSTATIC void\nGC_debug_print_heap_obj_proc(ptr_t base)\n{\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  if (GC_HAS_DEBUG_INFO(base)) {\n    GC_print_obj(base);\n  } else {\n    GC_default_print_heap_obj_proc(base);\n  }\n}\n\n#ifndef SHORT_DBG_HDRS\n/* Use GC_err_printf and friends to print a description of the object */\n/* whose client-visible address is p, and which was smashed at memory */\n/* location pointed by clobbered.                                     */\nSTATIC void\nGC_print_smashed_obj(const char *msg, void *p, ptr_t clobbered)\n{\n  oh *ohdr = (oh *)GC_base(p);\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n#  ifdef LINT2\n  if (!ohdr)\n    ABORT(\"Invalid GC_print_smashed_obj argument\");\n#  endif\n  if (ADDR_GE((ptr_t)(&ohdr->oh_sz), clobbered) || NULL == ohdr->oh_string) {\n    GC_err_printf(\"%s %p in or near object at %p(<smashed>, appr. sz= %lu)\\n\",\n                  msg, (void *)clobbered, p,\n                  (unsigned long)(GC_size(ohdr) - DEBUG_BYTES));\n  } else {\n    GC_err_printf(\"%s %p in or near object at %p (%s:%d, sz= %lu)\\n\", msg,\n                  (void *)clobbered, p,\n                  ADDR(ohdr->oh_string) < HBLKSIZE ? \"(smashed string)\"\n                  : ohdr->oh_string[0] == '\\0'     ? \"EMPTY(smashed?)\"\n                                                   : ohdr->oh_string,\n                  GET_OH_LINENUM(ohdr), (unsigned long)ohdr->oh_sz);\n    PRINT_CALL_CHAIN(ohdr);\n  }\n}\n\nSTATIC void GC_check_heap_proc(void);\nSTATIC void GC_print_all_smashed_proc(void);\n#else\nSTATIC void\nGC_do_nothing(void)\n{\n}\n#endif /* SHORT_DBG_HDRS */\n\nGC_INNER void\nGC_start_debugging_inner(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#ifndef SHORT_DBG_HDRS\n  GC_check_heap = GC_check_heap_proc;\n  GC_print_all_smashed = GC_print_all_smashed_proc;\n#else\n  GC_check_heap = GC_do_nothing;\n  GC_print_all_smashed = GC_do_nothing;\n#endif\n  GC_print_heap_obj = GC_debug_print_heap_obj_proc;\n  GC_debugging_started = TRUE;\n  GC_register_displacement_inner(sizeof(oh));\n#if defined(CPPCHECK)\n  GC_noop1(GC_debug_header_size);\n#endif\n}\n\nconst size_t GC_debug_header_size = sizeof(oh);\n\nGC_API size_t GC_CALL\nGC_get_debug_header_size(void)\n{\n  return sizeof(oh);\n}\n\nGC_API void GC_CALL\nGC_debug_register_displacement(size_t offset)\n{\n  LOCK();\n  GC_register_displacement_inner(offset);\n  GC_register_displacement_inner(sizeof(oh) + offset);\n  UNLOCK();\n}\n\n#ifdef GC_ADD_CALLER\n#  if defined(HAVE_DLADDR) && defined(GC_HAVE_RETURN_ADDR_PARENT) \\\n      && defined(FUNCPTR_IS_DATAPTR)\n#    include <dlfcn.h>\n\nSTATIC void\nGC_caller_func_offset(GC_return_addr_t ra, const char **symp, int *offp)\n{\n  Dl_info caller;\n\n  if (ra != 0 && dladdr((void *)ra, &caller) && caller.dli_sname != NULL) {\n    *symp = caller.dli_sname;\n    *offp = (int)((ptr_t)ra - (ptr_t)caller.dli_saddr);\n  }\n  if (NULL == *symp) {\n    *symp = \"unknown\";\n    /* Note: *offp is unchanged.    */\n  }\n}\n#  else\n#    define GC_caller_func_offset(ra, symp, offp) (void)(*(symp) = \"unknown\")\n#  endif\n#endif /* GC_ADD_CALLER */\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base;\n\n  /* Note that according to malloc() specification, if size is 0 then */\n  /* malloc() returns either NULL, or a unique pointer value that can */\n  /* later be successfully passed to free(). We always do the latter. */\n#if defined(_FORTIFY_SOURCE) && !defined(__clang__)\n  /* Workaround to avoid \"exceeds maximum object size\" gcc warning. */\n  base = GC_malloc(lb < GC_SIZE_MAX - DEBUG_BYTES ? lb + DEBUG_BYTES\n                                                  : GC_SIZE_MAX >> 1);\n#else\n  base = GC_malloc(SIZET_SAT_ADD(lb, DEBUG_BYTES));\n#endif\n#ifdef GC_ADD_CALLER\n  if (NULL == s) {\n    GC_caller_func_offset(ra, &s, &i);\n  }\n#endif\n  return store_debug_info(base, lb, \"GC_debug_malloc\", OPT_RA s, i);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_ignore_off_page(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base = GC_malloc_ignore_off_page(SIZET_SAT_ADD(lb, DEBUG_BYTES));\n\n  return store_debug_info(base, lb, \"GC_debug_malloc_ignore_off_page\",\n                          OPT_RA s, i);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_atomic_ignore_off_page(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base\n      = GC_malloc_atomic_ignore_off_page(SIZET_SAT_ADD(lb, DEBUG_BYTES));\n\n  return store_debug_info(base, lb, \"GC_debug_malloc_atomic_ignore_off_page\",\n                          OPT_RA s, i);\n}\n\nSTATIC void *\nGC_debug_generic_malloc(size_t lb, int k, GC_EXTRA_PARAMS)\n{\n  void *base = GC_generic_malloc_aligned(SIZET_SAT_ADD(lb, DEBUG_BYTES), k,\n                                         0 /* flags */, 0 /* align_m1 */);\n\n  return store_debug_info(base, lb, \"GC_debug_generic_malloc\", OPT_RA s, i);\n}\n\n#ifdef DBG_HDRS_ALL\n/* An allocation function for internal use.  Normally internally      */\n/* allocated objects do not have debug information.  But in this      */\n/* case, we need to make sure that all objects have debug headers.    */\nGC_INNER void *\nGC_debug_generic_malloc_inner(size_t lb, int k, unsigned flags)\n{\n  void *base, *result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  base = GC_generic_malloc_inner(SIZET_SAT_ADD(lb, DEBUG_BYTES), k, flags);\n  if (NULL == base) {\n    GC_err_printf(\"GC internal allocation (%lu bytes) returning NULL\\n\",\n                  (unsigned long)lb);\n    return NULL;\n  }\n  if (!GC_debugging_started)\n    GC_start_debugging_inner();\n  result = GC_store_debug_info_inner(base, lb, \"INTERNAL\", 0);\n  ADD_CALL_CHAIN_INNER(base);\n  return result;\n}\n#endif /* DBG_HDRS_ALL */\n\n#ifndef CPPCHECK\nGC_API void *GC_CALL\nGC_debug_malloc_stubborn(size_t lb, GC_EXTRA_PARAMS)\n{\n  return GC_debug_malloc(lb, OPT_RA s, i);\n}\n\nGC_API void GC_CALL\nGC_debug_change_stubborn(const void *p)\n{\n  UNUSED_ARG(p);\n}\n#endif /* !CPPCHECK */\n\nGC_API void GC_CALL\nGC_debug_end_stubborn_change(const void *p)\n{\n  const void *q = GC_base_C(p);\n\n  if (NULL == q) {\n    ABORT_ARG1(\"GC_debug_end_stubborn_change: bad arg\", \": %p\", p);\n  }\n  GC_end_stubborn_change(q);\n}\n\nGC_API void GC_CALL\nGC_debug_ptr_store_and_dirty(void *p, const void *q)\n{\n  *(void **)GC_is_visible(p)\n      = GC_is_valid_displacement(GC_CAST_AWAY_CONST_PVOID(q));\n  GC_debug_end_stubborn_change(p);\n  REACHABLE_AFTER_DIRTY(q);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_atomic(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base = GC_malloc_atomic(SIZET_SAT_ADD(lb, DEBUG_BYTES));\n\n  return store_debug_info(base, lb, \"GC_debug_malloc_atomic\", OPT_RA s, i);\n}\n\nGC_API GC_ATTR_MALLOC char *GC_CALL\nGC_debug_strdup(const char *str, GC_EXTRA_PARAMS)\n{\n  char *copy;\n  size_t lb;\n  if (str == NULL) {\n    if (GC_find_leak)\n      GC_err_printf(\"strdup(NULL) behavior is undefined\\n\");\n    return NULL;\n  }\n\n  lb = strlen(str) + 1;\n  copy = (char *)GC_debug_malloc_atomic(lb, OPT_RA s, i);\n  if (copy == NULL) {\n#ifndef MSWINCE\n    errno = ENOMEM;\n#endif\n    return NULL;\n  }\n  BCOPY(str, copy, lb);\n  return copy;\n}\n\nGC_API GC_ATTR_MALLOC char *GC_CALL\nGC_debug_strndup(const char *str, size_t size, GC_EXTRA_PARAMS)\n{\n  char *copy;\n  size_t len = strlen(str); /* str is expected to be non-NULL  */\n  if (len > size)\n    len = size;\n  copy = (char *)GC_debug_malloc_atomic(len + 1, OPT_RA s, i);\n  if (copy == NULL) {\n#ifndef MSWINCE\n    errno = ENOMEM;\n#endif\n    return NULL;\n  }\n  if (len > 0)\n    BCOPY(str, copy, len);\n  copy[len] = '\\0';\n  return copy;\n}\n\n#ifdef GC_REQUIRE_WCSDUP\n#  include <wchar.h> /* for wcslen() */\n\nGC_API GC_ATTR_MALLOC wchar_t *GC_CALL\nGC_debug_wcsdup(const wchar_t *str, GC_EXTRA_PARAMS)\n{\n  size_t lb = (wcslen(str) + 1) * sizeof(wchar_t);\n  wchar_t *copy = (wchar_t *)GC_debug_malloc_atomic(lb, OPT_RA s, i);\n  if (copy == NULL) {\n#  ifndef MSWINCE\n    errno = ENOMEM;\n#  endif\n    return NULL;\n  }\n  BCOPY(str, copy, lb);\n  return copy;\n}\n#endif /* GC_REQUIRE_WCSDUP */\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_uncollectable(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base\n      = GC_malloc_uncollectable(SIZET_SAT_ADD(lb, UNCOLLECTABLE_DEBUG_BYTES));\n\n  return store_debug_info(base, lb, \"GC_debug_malloc_uncollectable\", OPT_RA s,\n                          i);\n}\n\n#ifdef GC_ATOMIC_UNCOLLECTABLE\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_atomic_uncollectable(size_t lb, GC_EXTRA_PARAMS)\n{\n  void *base = GC_malloc_atomic_uncollectable(\n      SIZET_SAT_ADD(lb, UNCOLLECTABLE_DEBUG_BYTES));\n\n  return store_debug_info(base, lb, \"GC_debug_malloc_atomic_uncollectable\",\n                          OPT_RA s, i);\n}\n#endif /* GC_ATOMIC_UNCOLLECTABLE */\n\n#ifdef LINT2\n#  include \"private/gc_alloc_ptrs.h\"\n#endif\n\nGC_API void GC_CALL\nGC_debug_free(void *p)\n{\n  ptr_t base;\n  if (0 == p)\n    return;\n\n  base = (ptr_t)GC_base(p);\n  if (NULL == base) {\n#if defined(REDIRECT_MALLOC)                                           \\\n    && ((defined(NEED_CALLINFO) && defined(GC_HAVE_BUILTIN_BACKTRACE)) \\\n        || defined(REDIR_MALLOC_AND_LINUXTHREADS)                      \\\n        || (defined(SOLARIS) && defined(THREADS)) || defined(MSWIN32))\n    /* In some cases, we should ignore objects that do not belong   */\n    /* to the GC heap.  See the comment in GC_free.                 */\n    if (!GC_is_heap_ptr(p))\n      return;\n#endif\n    ABORT_ARG1(\"Invalid pointer passed to free()\", \": %p\", p);\n  }\n  if ((word)((ptr_t)p - base) != sizeof(oh)) {\n#if defined(REDIRECT_FREE) && defined(USE_PROC_FOR_LIBRARIES)\n    /* TODO: Suppress the warning if free() caller is in libpthread */\n    /* or libdl.                                                    */\n#endif\n    /* TODO: Suppress the warning for objects allocated by            */\n    /* GC_memalign and friends (these ones do not have the debugging  */\n    /* counterpart).                                                  */\n    GC_err_printf(\"GC_debug_free called on pointer %p w/o debugging info\\n\",\n                  p);\n  } else {\n#ifndef SHORT_DBG_HDRS\n    ptr_t clobbered = GC_check_annotated_obj((oh *)base);\n    size_t sz = GC_size(base);\n\n    if (clobbered != NULL) {\n      GC_SET_HAVE_ERRORS(); /* no \"release\" barrier is needed */\n      if (((oh *)base)->oh_sz == (GC_uintptr_t)sz) {\n        GC_print_smashed_obj(\n            \"GC_debug_free: found previously deallocated (?) object at\", p,\n            clobbered);\n        return; /* ignore double free */\n      } else {\n        GC_print_smashed_obj(\"GC_debug_free: found smashed location at\", p,\n                             clobbered);\n      }\n    }\n    /* Invalidate size (mark the object as deallocated).    */\n    ((oh *)base)->oh_sz = (GC_uintptr_t)sz;\n#endif /* !SHORT_DBG_HDRS */\n  }\n  if (GC_find_leak\n#ifndef SHORT_DBG_HDRS\n      && ((word)((ptr_t)p - base) != sizeof(oh) || !GC_findleak_delay_free)\n#endif\n  ) {\n    GC_free(base);\n  } else {\n    const hdr *hhdr = HDR(p);\n    if (hhdr->hb_obj_kind == UNCOLLECTABLE\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n        || hhdr->hb_obj_kind == AUNCOLLECTABLE\n#endif\n    ) {\n      GC_free(base);\n    } else {\n      size_t sz = hhdr->hb_sz;\n      size_t i;\n      size_t lpw = BYTES_TO_PTRS(sz - sizeof(oh));\n\n      for (i = 0; i < lpw; ++i)\n        ((GC_uintptr_t *)p)[i] = GC_FREED_MEM_MARKER;\n      GC_ASSERT((GC_uintptr_t *)p + i == (GC_uintptr_t *)(base + sz));\n      /* Update the counter even though the real deallocation */\n      /* is deferred.                                         */\n      LOCK();\n#ifdef LINT2\n      GC_incr_bytes_freed(sz);\n#else\n      GC_bytes_freed += sz;\n#endif\n      UNLOCK();\n    }\n  } /* !GC_find_leak */\n}\n\n#if defined(THREADS) && defined(DBG_HDRS_ALL)\n/* Used internally; we assume it's called correctly.    */\nGC_INNER void\nGC_debug_free_inner(void *p)\n{\n  ptr_t base = (ptr_t)GC_base(p);\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT((word)((ptr_t)p - base) == sizeof(oh));\n#  ifdef LINT2\n  if (!base)\n    ABORT(\"Invalid GC_debug_free_inner argument\");\n#  endif\n#  ifndef SHORT_DBG_HDRS\n  /* Invalidate size.       */\n  ((oh *)base)->oh_sz = (GC_uintptr_t)GC_size(base);\n#  endif\n  GC_free_inner(base);\n}\n#endif\n\nGC_API void *GC_CALL\nGC_debug_realloc(void *p, size_t lb, GC_EXTRA_PARAMS)\n{\n  ptr_t base;\n  void *result;\n  const hdr *hhdr;\n\n  if (NULL == p) {\n    return GC_debug_malloc(lb, OPT_RA s, i);\n  }\n  if (0 == lb) /* and p != NULL */ {\n    GC_debug_free(p);\n    return NULL;\n  }\n\n#ifdef GC_ADD_CALLER\n  if (NULL == s) {\n    GC_caller_func_offset(ra, &s, &i);\n  }\n#endif\n  base = (ptr_t)GC_base(p);\n  if (NULL == base) {\n    ABORT_ARG1(\"Invalid pointer passed to realloc()\", \": %p\", p);\n  }\n  if ((word)((ptr_t)p - base) != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_realloc called on pointer %p w/o debugging info\\n\",\n                  p);\n    return GC_realloc(p, lb);\n  }\n  hhdr = HDR(base);\n  result\n      = GC_debug_generic_or_special_malloc(lb, hhdr->hb_obj_kind, OPT_RA s, i);\n  if (result != NULL) {\n    size_t old_sz;\n#ifdef SHORT_DBG_HDRS\n    old_sz = GC_size(base) - sizeof(oh);\n#else\n    old_sz = (size_t)(((oh *)base)->oh_sz);\n#endif\n    if (old_sz > 0)\n      BCOPY(p, result, old_sz < lb ? old_sz : lb);\n    GC_debug_free(p);\n  }\n  return result;\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_generic_or_special_malloc(size_t lb, int k, GC_EXTRA_PARAMS)\n{\n  switch (k) {\n  case PTRFREE:\n    return GC_debug_malloc_atomic(lb, OPT_RA s, i);\n  case NORMAL:\n    return GC_debug_malloc(lb, OPT_RA s, i);\n  case UNCOLLECTABLE:\n    return GC_debug_malloc_uncollectable(lb, OPT_RA s, i);\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n  case AUNCOLLECTABLE:\n    return GC_debug_malloc_atomic_uncollectable(lb, OPT_RA s, i);\n#endif\n  default:\n    return GC_debug_generic_malloc(lb, k, OPT_RA s, i);\n  }\n}\n\n#ifndef SHORT_DBG_HDRS\n\n#  ifndef MAX_SMASHED\n#    define MAX_SMASHED 20\n#  endif\n\n/* List of smashed (clobbered) locations.  We defer printing these,   */\n/* since we cannot always print them nicely with the allocator lock   */\n/* held.  We put them here instead of in GC_arrays, since it may be   */\n/* useful to be able to look at them with the debugger.               */\nSTATIC ptr_t GC_smashed[MAX_SMASHED] = { 0 };\nSTATIC unsigned GC_n_smashed = 0;\n\nSTATIC void\nGC_add_smashed(ptr_t smashed)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_marked(GC_base(smashed)));\n  /* FIXME: Prevent adding an object while printing smashed list.     */\n  GC_smashed[GC_n_smashed] = smashed;\n  /* In case of overflow, we keep the first MAX_SMASHED-1 entries     */\n  /* plus the last one.                                               */\n  if (GC_n_smashed < MAX_SMASHED - 1)\n    ++GC_n_smashed;\n  GC_SET_HAVE_ERRORS();\n}\n\n/* Print all objects on the list.  Clear the list.    */\nSTATIC void\nGC_print_all_smashed_proc(void)\n{\n  unsigned i;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  if (GC_n_smashed == 0)\n    return;\n  GC_err_printf(\"GC_check_heap_block: found %u smashed heap objects:\\n\",\n                GC_n_smashed);\n  for (i = 0; i < GC_n_smashed; ++i) {\n    ptr_t base = (ptr_t)GC_base(GC_smashed[i]);\n\n#  ifdef LINT2\n    if (!base)\n      ABORT(\"Invalid GC_smashed element\");\n#  endif\n    GC_print_smashed_obj(\"\", base + sizeof(oh), GC_smashed[i]);\n    GC_smashed[i] = 0;\n  }\n  GC_n_smashed = 0;\n}\n\n/* Check all marked objects in the given block for validity   */\n/* Avoid GC_apply_to_each_object for performance reasons.     */\nSTATIC void GC_CALLBACK\nGC_check_heap_block(struct hblk *hbp, void *dummy)\n{\n  const hdr *hhdr = HDR(hbp);\n  ptr_t p = hbp->hb_body;\n  ptr_t plim;\n  size_t sz = hhdr->hb_sz;\n  size_t bit_no;\n\n  UNUSED_ARG(dummy);\n  GC_ASSERT((ptr_t)hhdr->hb_block == p);\n  plim = sz > MAXOBJBYTES ? p : p + HBLKSIZE - sz;\n  /* Go through all objects in block. */\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz), p += sz) {\n    if (mark_bit_from_hdr(hhdr, bit_no) && GC_HAS_DEBUG_INFO(p)) {\n      ptr_t clobbered = GC_check_annotated_obj((oh *)p);\n\n      if (clobbered != NULL)\n        GC_add_smashed(clobbered);\n    }\n  }\n}\n\n/* This assumes that all accessible objects are marked.   */\n/* Normally called by collector.                          */\nSTATIC void\nGC_check_heap_proc(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_STATIC_ASSERT((sizeof(oh) & (GC_GRANULE_BYTES - 1)) == 0);\n  /* FIXME: Should we check for twice that alignment? */\n  GC_apply_to_all_blocks(GC_check_heap_block, NULL);\n}\n\nGC_INNER GC_bool\nGC_check_leaked(ptr_t base)\n{\n  size_t i;\n  size_t lpw;\n  ptr_t *p;\n\n  if (\n#  if defined(KEEP_BACK_PTRS) || defined(MAKE_BACK_GRAPH)\n      (*(GC_uintptr_t *)base & 1) != 0 &&\n#  endif\n      GC_has_other_debug_info(base) >= 0)\n    return TRUE; /* object has leaked */\n\n  /* Validate freed object's content. */\n  p = (ptr_t *)(base + sizeof(oh));\n  lpw = BYTES_TO_PTRS(HDR(base)->hb_sz - sizeof(oh));\n  for (i = 0; i < lpw; ++i)\n    if ((GC_uintptr_t)p[i] != GC_FREED_MEM_MARKER) {\n      GC_set_mark_bit(base);          /* do not reclaim it in this cycle */\n      GC_add_smashed((ptr_t)(&p[i])); /* alter-after-free detected */\n      /* Do not report any other smashed locations in the object.     */\n      break;\n    }\n\n  return FALSE; /* GC_debug_free() has been called */\n}\n\n#endif /* !SHORT_DBG_HDRS */\n\n#ifndef GC_NO_FINALIZATION\n\nstruct closure {\n  GC_finalization_proc cl_fn;\n  void *cl_data;\n};\n\nSTATIC void *\nGC_make_closure(GC_finalization_proc fn, void *data)\n{\n  struct closure *result =\n#  ifdef DBG_HDRS_ALL\n      (struct closure *)GC_debug_malloc(sizeof(struct closure), GC_EXTRAS);\n#  else\n      (struct closure *)GC_malloc(sizeof(struct closure));\n#  endif\n  if (result != NULL) {\n    result->cl_fn = fn;\n    result->cl_data = data;\n  }\n  return result;\n}\n\n/* An auxiliary function to make finalization work correctly with */\n/* displaced pointers introduced by the debugging allocators.     */\nSTATIC void GC_CALLBACK\nGC_debug_invoke_finalizer(void *obj, void *data)\n{\n  struct closure *cl = (struct closure *)data;\n\n  cl->cl_fn((ptr_t)obj + sizeof(oh), cl->cl_data);\n}\n\n/* Special finalizer_proc value to detect GC_register_finalizer failure. */\n#  define OFN_UNSET ((GC_finalization_proc)(~(GC_funcptr_uint)0))\n\n/* Set ofn and ocd to reflect the values we got back. */\nstatic void\nstore_old(void *obj, GC_finalization_proc my_old_fn, struct closure *my_old_cd,\n          GC_finalization_proc *ofn, void **ocd)\n{\n  if (my_old_fn != 0) {\n    if (my_old_fn == OFN_UNSET) {\n      /* GC_register_finalizer() failed; (*ofn) and (*ocd) are unchanged. */\n      return;\n    }\n    if (my_old_fn != GC_debug_invoke_finalizer) {\n      GC_err_printf(\"Debuggable object at %p had a non-debug finalizer\\n\",\n                    obj);\n      /* This should probably be fatal. */\n    } else {\n      if (ofn)\n        *ofn = my_old_cd->cl_fn;\n      if (ocd)\n        *ocd = my_old_cd->cl_data;\n    }\n  } else {\n    if (ofn)\n      *ofn = 0;\n    if (ocd)\n      *ocd = NULL;\n  }\n}\n\nGC_API void GC_CALL\nGC_debug_register_finalizer(void *obj, GC_finalization_proc fn, void *cd,\n                            GC_finalization_proc *ofn, void **ocd)\n{\n  GC_finalization_proc my_old_fn = OFN_UNSET;\n  void *my_old_cd = NULL; /* to avoid \"might be uninitialized\" warning */\n  ptr_t base = (ptr_t)GC_base(obj);\n  if (NULL == base) {\n    /* We will not collect it, hence finalizer wouldn't be run.   */\n    if (ocd)\n      *ocd = NULL;\n    if (ofn)\n      *ofn = 0;\n    return;\n  }\n  if ((ptr_t)obj - base != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_register_finalizer called with\"\n                  \" non-base-pointer %p\\n\",\n                  obj);\n  }\n  if (0 == fn) {\n    GC_register_finalizer(base, 0, NULL, &my_old_fn, &my_old_cd);\n  } else {\n    cd = GC_make_closure(fn, cd);\n    if (NULL == cd)\n      return; /* out of memory; *ofn and *ocd are unchanged */\n    GC_register_finalizer(base, GC_debug_invoke_finalizer, cd, &my_old_fn,\n                          &my_old_cd);\n  }\n  store_old(obj, my_old_fn, (struct closure *)my_old_cd, ofn, ocd);\n}\n\nGC_API void GC_CALL\nGC_debug_register_finalizer_no_order(void *obj, GC_finalization_proc fn,\n                                     void *cd, GC_finalization_proc *ofn,\n                                     void **ocd)\n{\n  GC_finalization_proc my_old_fn = OFN_UNSET;\n  void *my_old_cd = NULL;\n  ptr_t base = (ptr_t)GC_base(obj);\n  if (NULL == base) {\n    if (ocd)\n      *ocd = NULL;\n    if (ofn)\n      *ofn = 0;\n    return;\n  }\n  if ((ptr_t)obj - base != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_register_finalizer_no_order called with\"\n                  \" non-base-pointer %p\\n\",\n                  obj);\n  }\n  if (0 == fn) {\n    GC_register_finalizer_no_order(base, 0, NULL, &my_old_fn, &my_old_cd);\n  } else {\n    cd = GC_make_closure(fn, cd);\n    if (NULL == cd)\n      return; /* out of memory */\n    GC_register_finalizer_no_order(base, GC_debug_invoke_finalizer, cd,\n                                   &my_old_fn, &my_old_cd);\n  }\n  store_old(obj, my_old_fn, (struct closure *)my_old_cd, ofn, ocd);\n}\n\nGC_API void GC_CALL\nGC_debug_register_finalizer_unreachable(void *obj, GC_finalization_proc fn,\n                                        void *cd, GC_finalization_proc *ofn,\n                                        void **ocd)\n{\n  GC_finalization_proc my_old_fn = OFN_UNSET;\n  void *my_old_cd = NULL;\n  ptr_t base = (ptr_t)GC_base(obj);\n  if (NULL == base) {\n    if (ocd)\n      *ocd = NULL;\n    if (ofn)\n      *ofn = 0;\n    return;\n  }\n  if ((ptr_t)obj - base != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_register_finalizer_unreachable called with\"\n                  \" non-base-pointer %p\\n\",\n                  obj);\n  }\n  if (0 == fn) {\n    GC_register_finalizer_unreachable(base, 0, NULL, &my_old_fn, &my_old_cd);\n  } else {\n    cd = GC_make_closure(fn, cd);\n    if (NULL == cd)\n      return; /* out of memory */\n    GC_register_finalizer_unreachable(base, GC_debug_invoke_finalizer, cd,\n                                      &my_old_fn, &my_old_cd);\n  }\n  store_old(obj, my_old_fn, (struct closure *)my_old_cd, ofn, ocd);\n}\n\nGC_API void GC_CALL\nGC_debug_register_finalizer_ignore_self(void *obj, GC_finalization_proc fn,\n                                        void *cd, GC_finalization_proc *ofn,\n                                        void **ocd)\n{\n  GC_finalization_proc my_old_fn = OFN_UNSET;\n  void *my_old_cd = NULL;\n  ptr_t base = (ptr_t)GC_base(obj);\n  if (NULL == base) {\n    if (ocd)\n      *ocd = NULL;\n    if (ofn)\n      *ofn = 0;\n    return;\n  }\n  if ((ptr_t)obj - base != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_register_finalizer_ignore_self called with\"\n                  \" non-base-pointer %p\\n\",\n                  obj);\n  }\n  if (0 == fn) {\n    GC_register_finalizer_ignore_self(base, 0, NULL, &my_old_fn, &my_old_cd);\n  } else {\n    cd = GC_make_closure(fn, cd);\n    if (NULL == cd)\n      return; /* out of memory */\n    GC_register_finalizer_ignore_self(base, GC_debug_invoke_finalizer, cd,\n                                      &my_old_fn, &my_old_cd);\n  }\n  store_old(obj, my_old_fn, (struct closure *)my_old_cd, ofn, ocd);\n}\n\n#  ifndef GC_TOGGLE_REFS_NOT_NEEDED\nGC_API int GC_CALL\nGC_debug_toggleref_add(void *obj, int is_strong_ref)\n{\n  ptr_t base = (ptr_t)GC_base(obj);\n\n  if ((ptr_t)obj - base != sizeof(oh)) {\n    GC_err_printf(\"GC_debug_toggleref_add called with\"\n                  \" non-base-pointer %p\\n\",\n                  obj);\n  }\n  return GC_toggleref_add(base, is_strong_ref);\n}\n#  endif /* !GC_TOGGLE_REFS_NOT_NEEDED */\n\n#endif /* !GC_NO_FINALIZATION */\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_malloc_replacement(size_t lb)\n{\n  return GC_debug_malloc(lb, GC_DBG_EXTRAS);\n}\n\nGC_API void *GC_CALL\nGC_debug_realloc_replacement(void *p, size_t lb)\n{\n  return GC_debug_realloc(p, lb, GC_DBG_EXTRAS);\n}\n"
        },
        {
          "name": "digimars.mak",
          "type": "blob",
          "size": 2.7685546875,
          "content": "# Makefile to build Hans Boehm garbage collector using the Digital Mars\r\n# compiler from www.digitalmars.com\r\n# Written by Walter Bright\r\n\r\nCFLAGS_EXTRA=\r\nDEFINES=-DGC_DLL -DGC_THREADS -DGC_DISCOVER_TASK_THREADS \\\r\n    -DALL_INTERIOR_POINTERS -DENABLE_DISCLAIM -DGC_ATOMIC_UNCOLLECTABLE \\\r\n    -DGC_GCJ_SUPPORT -DJAVA_FINALIZATION -DNO_EXECUTE_PERMISSION \\\r\n    -DGC_REQUIRE_WCSDUP -DUSE_MUNMAP\r\nCORD_DEFINES=-DGC_DLL -DCORD_NOT_DLL\r\nCFLAGS=-Iinclude -Ilibatomic_ops\\src $(DEFINES) -g $(CFLAGS_EXTRA)\r\nCORD_CFLAGS=-Iinclude $(CORD_DEFINES) -g $(CFLAGS_EXTRA)\r\nLFLAGS=/ma/implib/co\r\nCC=sc\r\n\r\n# Must precede other goals.\r\nall: cord.lib gc.lib\r\n\r\ngc.obj: extra\\gc.c\r\n\t$(CC) -c $(CFLAGS) extra\\gc.c -ogc.obj\r\n\r\n.cpp.obj:\r\n\t$(CC) -c $(CFLAGS) -Aa $*\r\n\r\ncheck: gctest.exe cpptest.exe treetest.exe cordtest.exe\r\n\tgctest.exe\r\n\tcpptest.exe\r\n\ttreetest.exe\r\n\tcordtest.exe\r\n\r\ngc.lib: gc.dll\r\n\r\ngc.dll: gc.obj gc_badalc.obj gc_cpp.obj gc.def digimars.mak\r\n\t$(CC) -ogc.dll gc.obj gc_badalc.obj gc_cpp.obj -L$(LFLAGS) gc.def kernel32.lib user32.lib\r\n\r\ngc.def: digimars.mak\r\n\techo LIBRARY GC >gc.def\r\n\techo DESCRIPTION \"Boehm-Demers-Weiser Garbage Collector\" >>gc.def\r\n\techo EXETYPE NT\t>>gc.def\r\n\techo EXPORTS >>gc.def\r\n\techo GC_is_visible_print_proc >>gc.def\r\n\techo GC_is_valid_displacement_print_proc >>gc.def\r\n\r\n# FIXME: building cord as DLL results in cordtest fail.\r\ncord.lib: cord\\cordbscs.obj cord\\cordprnt.obj cord\\cordxtra.obj\r\n\tlib -c cord.lib cord\\cordbscs.obj cord\\cordprnt.obj cord\\cordxtra.obj\r\n\r\ncord\\cordbscs.obj: cord\\cordbscs.c\r\n\t$(CC) -c $(CORD_CFLAGS) cord\\cordbscs.c -ocord\\cordbscs.obj\r\n\r\ncord\\cordprnt.obj: cord\\cordprnt.c\r\n\t$(CC) -c $(CORD_CFLAGS) cord\\cordprnt.c -ocord\\cordprnt.obj\r\n\r\ncord\\cordxtra.obj: cord\\cordxtra.c\r\n\t$(CC) -c $(CORD_CFLAGS) cord\\cordxtra.c -ocord\\cordxtra.obj\r\n\r\nclean:\r\n\tdel *.log *.map *.obj gc.def gc.dll gc.lib\r\n\tdel tests\\*.obj gctest.exe cpptest.exe treetest.exe\r\n\tdel cord\\*.obj cord.lib cord\\tests\\cordtest.obj cordtest.exe\r\n\r\ngctest.exe: gc.lib tests\\gctest.obj\r\n\t$(CC) -ogctest.exe tests\\gctest.obj gc.lib\r\n\r\ntests\\gctest.obj: tests\\gctest.c\r\n\t$(CC) -c $(CFLAGS) tests\\gctest.c -otests\\gctest.obj\r\n\r\ncpptest.exe: gc.lib tests\\cpptest.obj\r\n\t$(CC) -ocpptest.exe tests\\cpptest.obj gc.lib\r\n\r\ntests\\cpptest.obj: tests\\cpp.cc\r\n\t$(CC) -c $(CFLAGS) -cpp tests\\cpp.cc -otests\\cpptest.obj\r\n\r\ntreetest.exe: gc.lib tests\\treetest.obj\r\n\t$(CC) -otreetest.exe tests\\treetest.obj gc.lib\r\n\r\ntests\\treetest.obj: tests\\tree.cc\r\n\t$(CC) -c $(CFLAGS) -cpp tests\\tree.cc -otests\\treetest.obj\r\n\r\ncordtest.exe: cord\\tests\\cordtest.obj cord.lib gc.lib\r\n\t$(CC) -ocordtest.exe cord\\tests\\cordtest.obj cord.lib gc.lib\r\n\r\ncord\\tests\\cordtest.obj: cord\\tests\\cordtest.c\r\n\t$(CC) -c $(CORD_CFLAGS) cord\\tests\\cordtest.c -ocord\\tests\\cordtest.obj\r\n\r\ngc_badalc.obj: gc_badalc.cc gc_badalc.cpp\r\ngc_cpp.obj: gc_cpp.cc gc_cpp.cpp\r\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dyn_load.c",
          "type": "blob",
          "size": 51.978515625,
          "content": "/*\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1997 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 2009-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/*\n * This is incredibly OS specific code for tracking down data sections in\n * dynamic libraries.  There appears to be no way of doing this quickly\n * without groveling through undocumented data structures.  We would argue\n * that this is a bug in the design of the dlopen interface.  THIS CODE\n * MAY BREAK IN FUTURE OS RELEASES.  If this matters to you, don't hesitate\n * to let your vendor know ...\n *\n * None of this is safe with dlclose and incremental collection.\n * But then not much of anything is safe in the presence of dlclose.\n */\n\n/* BTL: avoid circular redefinition of dlopen if SOLARIS+THREADS defined */\n#undef GC_MUST_RESTORE_REDEFINED_DLOPEN\n#if defined(GC_PTHREADS) && !defined(GC_NO_DLOPEN) \\\n    && !defined(GC_NO_THREAD_REDIRECTS) && !defined(GC_USE_LD_WRAP)\n/* To support threads in Solaris, gc.h interposes on dlopen by        */\n/* defining \"dlopen\" to be \"GC_dlopen\", which is implemented below.   */\n/* However, both GC_FirstDLOpenedLinkMap() and GC_dlopen() use the    */\n/* real system dlopen() in their implementation. We first remove      */\n/* gc.h's dlopen definition and restore it later, after GC_dlopen().  */\n#  undef dlopen\n#  define GC_MUST_RESTORE_REDEFINED_DLOPEN\n#endif /* !GC_NO_DLOPEN */\n\n#if defined(SOLARISDL) && defined(THREADS) && !defined(SOLARIS) \\\n    && !defined(CPPCHECK)\n#  error Fix mutual exclusion with dlopen\n#endif\n\n/* A user-supplied routine (custom filter) that might be called to      */\n/* determine whether a DSO really needs to be scanned by the GC.        */\n/* 0 means no filter installed.  May be unused on some platforms.       */\n/* FIXME: Add filter support for more platforms.                        */\nSTATIC GC_has_static_roots_func GC_has_static_roots = 0;\n\n#ifdef ANY_MSWIN\n/* We traverse the entire address space and register all segments     */\n/* that could possibly have been written to.                          */\nSTATIC void\nGC_cond_add_roots(ptr_t base, ptr_t limit)\n{\n#  ifdef THREADS\n  ptr_t curr_base = base;\n  ptr_t next_stack_lo, next_stack_hi;\n#  else\n  ptr_t stack_top;\n#  endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (base == limit)\n    return;\n#  ifdef THREADS\n  for (;;) {\n    GC_get_next_stack(curr_base, limit, &next_stack_lo, &next_stack_hi);\n    if (ADDR_GE(next_stack_lo, limit))\n      break;\n    if (ADDR_LT(curr_base, next_stack_lo))\n      GC_add_roots_inner(curr_base, next_stack_lo, TRUE);\n    curr_base = next_stack_hi;\n  }\n  if (ADDR_LT(curr_base, limit))\n    GC_add_roots_inner(curr_base, limit, TRUE);\n#  else\n  stack_top\n      = PTR_ALIGN_DOWN(GC_approx_sp(), GC_sysinfo.dwAllocationGranularity);\n  if (ADDR_LT(stack_top, limit) && ADDR_LT(base, GC_stackbottom)) {\n    /* Part of the stack; ignore it.      */\n    return;\n  }\n  GC_add_roots_inner(base, limit, TRUE);\n#  endif\n}\n\n#  ifdef DYNAMIC_LOADING\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n#    if defined(MSWINCE) || defined(CYGWIN32)\n  return FALSE;\n#    else\n  return GC_no_win32_dlls;\n#    endif\n}\n#    define HAVE_REGISTER_MAIN_STATIC_DATA\n#  endif /* DYNAMIC_LOADING */\n\n#  ifdef DEBUG_VIRTUALQUERY\nvoid\nGC_dump_meminfo(MEMORY_BASIC_INFORMATION *buf)\n{\n  GC_printf(\"BaseAddress= 0x%lx, AllocationBase= 0x%lx,\"\n            \" RegionSize= 0x%lx(%lu)\\n\",\n            buf->BaseAddress, buf->AllocationBase, buf->RegionSize,\n            buf->RegionSize);\n  GC_printf(\"\\tAllocationProtect= 0x%lx, State= 0x%lx, Protect= 0x%lx, \"\n            \"Type= 0x%lx\\n\",\n            buf->AllocationProtect, buf->State, buf->Protect, buf->Type);\n}\n#  endif /* DEBUG_VIRTUALQUERY */\n\n#  if defined(MSWINCE) || defined(CYGWIN32)\n/* FIXME: Should we really need to scan MEM_PRIVATE sections?       */\n/* For now, we don't add MEM_PRIVATE sections to the data roots for */\n/* WinCE because otherwise SEGV fault sometimes happens to occur in */\n/* GC_mark_from() (and, even if we use WRAP_MARK_SOME, WinCE prints */\n/* a \"Data Abort\" message to the debugging console).                */\n/* To workaround that, use -DGC_REGISTER_MEM_PRIVATE.               */\n#    define GC_wnt TRUE\n#  endif\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  ptr_t p, base, limit;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef MSWIN32\n  if (GC_no_win32_dlls)\n    return;\n#  endif\n  p = (ptr_t)GC_sysinfo.lpMinimumApplicationAddress;\n  base = limit = p;\n  while (ADDR_LT(p, (ptr_t)GC_sysinfo.lpMaximumApplicationAddress)) {\n    MEMORY_BASIC_INFORMATION buf;\n    size_t result = VirtualQuery((LPVOID)p, &buf, sizeof(buf));\n\n#  ifdef MSWINCE\n    if (0 == result) {\n      if (ADDR(p) > GC_WORD_MAX - GC_sysinfo.dwAllocationGranularity)\n        break; /* overflow */\n      /* Page is free; advance to the next possible allocation base. */\n      p = PTR_ALIGN_UP(p + 1, GC_sysinfo.dwAllocationGranularity);\n    } else\n#  endif\n    /* else */ {\n      DWORD protect;\n\n      if (result != sizeof(buf))\n        ABORT(\"Weird VirtualQuery result\");\n      if (ADDR(p) > GC_WORD_MAX - buf.RegionSize)\n        break; /* overflow */\n\n      protect = buf.Protect;\n      if (buf.State == MEM_COMMIT\n          && (protect == PAGE_EXECUTE_READWRITE\n              || protect == PAGE_EXECUTE_WRITECOPY || protect == PAGE_READWRITE\n              || protect == PAGE_WRITECOPY)\n          && (buf.Type == MEM_IMAGE\n#  ifdef GC_REGISTER_MEM_PRIVATE\n              || (protect == PAGE_READWRITE && buf.Type == MEM_PRIVATE)\n#  else\n              /* There is some evidence that we cannot always   */\n              /* ignore MEM_PRIVATE sections under Windows ME   */\n              /* and predecessors.  Hence we now also check for */\n              /* that case.                                     */\n              || (!GC_wnt && buf.Type == MEM_PRIVATE)\n#  endif\n                  )\n          && !GC_is_heap_base(buf.AllocationBase)) {\n#  ifdef DEBUG_VIRTUALQUERY\n        GC_dump_meminfo(&buf);\n#  endif\n        if (p != limit) {\n          GC_cond_add_roots(base, limit);\n          base = p;\n        }\n        limit = p + buf.RegionSize;\n      }\n      p += buf.RegionSize;\n    }\n  }\n  GC_cond_add_roots(base, limit);\n}\n\n#elif defined(DYNAMIC_LOADING) /* && !ANY_MSWIN */\n\n#  if !(defined(CPPCHECK) || defined(AIX) || defined(DARWIN) || defined(DGUX) \\\n        || defined(IRIX5) || defined(HAIKU) || defined(HPUX) || defined(HURD) \\\n        || defined(NACL) || defined(OSF1) || defined(SCO_ELF)                 \\\n        || defined(SERENITY) || defined(SOLARISDL)                            \\\n        || ((defined(ANY_BSD) || defined(LINUX)) && defined(__ELF__))         \\\n        || (defined(OPENBSD) && defined(M68K)))\n#    error Finding data segments of dynamic libraries is unsupported on target\n#  endif\n\n#  if defined(DARWIN) && !defined(USE_DYLD_TO_BIND) \\\n      && !defined(NO_DYLD_BIND_FULLY_IMAGE)\n#    include <dlfcn.h>\n#  endif\n\n#  ifdef SOLARISDL\n#    include <dlfcn.h>\n#    include <link.h>\n#    include <sys/elf.h>\n#  endif\n\n#  if defined(NETBSD)\n#    include <dlfcn.h>\n#    include <machine/elf_machdep.h>\n#    include <sys/param.h>\n#    define ELFSIZE ARCH_ELFSIZE\n#  endif\n\n#  if defined(OPENBSD)\n#    include <sys/param.h>\n#    if (OpenBSD >= 200519) && !defined(HAVE_DL_ITERATE_PHDR)\n#      define HAVE_DL_ITERATE_PHDR\n#    endif\n#  endif /* OPENBSD */\n\n#  if defined(DGUX) || defined(HURD) || defined(NACL) || defined(SCO_ELF) \\\n      || defined(SERENITY)                                                \\\n      || ((defined(ANY_BSD) || defined(LINUX)) && defined(__ELF__))\n#    include <stddef.h>\n#    if !defined(OPENBSD) && !defined(HOST_ANDROID)\n/* OpenBSD does not have elf.h file; link.h below is sufficient.    */\n/* Exclude Android because linker.h below includes its own version. */\n#      include <elf.h>\n#    endif\n#    ifdef HOST_ANDROID\n/* If you don't need the \"dynamic loading\" feature, you may build   */\n/* the collector with -D IGNORE_DYNAMIC_LOADING.                    */\n#      ifdef BIONIC_ELFDATA_REDEF_BUG\n/* Workaround a problem in Bionic (as of Android 4.2) which has   */\n/* mismatching ELF_DATA definitions in sys/exec_elf.h and         */\n/* asm/elf.h included from linker.h file (similar to EM_ALPHA).   */\n#        include <asm/elf.h>\n#        include <linux/elf-em.h>\n#        undef ELF_DATA\n#        undef EM_ALPHA\n#      endif\n#      include <link.h>\n#    endif /* HOST_ANDROID */\n#    if ((defined(HOST_ANDROID) && !defined(GC_DONT_DEFINE_LINK_MAP) \\\n          && !(__ANDROID_API__ >= 21))                               \\\n         || defined(SERENITY))                                       \\\n        && !defined(USE_PROC_FOR_LIBRARIES)\n/* link_map and r_debug are defined in link.h of NDK r10+.        */\n/* bionic/linker/linker.h defines them too but the header         */\n/* itself is a C++ one starting from Android 4.3.                 */\nstruct link_map {\n  uintptr_t l_addr;\n  char *l_name;\n  uintptr_t l_ld;\n  struct link_map *l_next;\n  struct link_map *l_prev;\n};\nstruct r_debug {\n  int32_t r_version;\n  struct link_map *r_map;\n  /* void (*r_brk)(void); */\n  /* int32_t r_state; */\n  /* uintptr_t r_ldbase; */\n};\n#    endif /* __ANDROID_API__ >= 21 || SERENITY */\n#    ifndef HOST_ANDROID\n/* Workaround missing extern \"C\" around _DYNAMIC symbol in link.h   */\n/* of some Linux hosts.                                             */\nEXTERN_C_BEGIN\n#      include <link.h>\nEXTERN_C_END\n#    endif /* !HOST_ANDROID */\n#  endif\n\n/* Newer versions of GNU/Linux define this macro.  We define it         */\n/* similarly for any ELF systems that do not.                           */\n#  ifndef ElfW\n#    if defined(FREEBSD)\n#      if __ELF_WORD_SIZE == 32\n#        define ElfW(type) Elf32_##type\n#      else\n#        define ElfW(type) Elf64_##type\n#      endif\n#    elif defined(NETBSD) || defined(OPENBSD)\n#      if ELFSIZE == 32\n#        define ElfW(type) Elf32_##type\n#      elif ELFSIZE == 64\n#        define ElfW(type) Elf64_##type\n#      else\n#        error Missing ELFSIZE define\n#      endif\n#    else\n#      if !defined(ELF_CLASS) || ELF_CLASS == ELFCLASS32\n#        define ElfW(type) Elf32_##type\n#      else\n#        define ElfW(type) Elf64_##type\n#      endif\n#    endif\n#  endif\n\n#  if defined(SOLARISDL) && !defined(USE_PROC_FOR_LIBRARIES)\n\nEXTERN_C_BEGIN\nextern ElfW(Dyn) _DYNAMIC;\nEXTERN_C_END\n\nSTATIC struct link_map *\nGC_FirstDLOpenedLinkMap(void)\n{\n  ElfW(Dyn) * dp;\n  static struct link_map *cachedResult = 0;\n  static ElfW(Dyn) *dynStructureAddr = 0;\n  /* BTL: added to avoid Solaris 5.3 ld.so _DYNAMIC bug   */\n\n#    ifdef SUNOS53_SHARED_LIB\n  /* BTL: Avoid the Solaris 5.3 bug that _DYNAMIC isn't being set */\n  /* up properly in dynamically linked .so's. This means we have  */\n  /* to use its value in the set of original object files loaded  */\n  /* at program startup.                                          */\n  if (0 == dynStructureAddr) {\n    void *startupSyms = dlopen(0, RTLD_LAZY);\n\n    dynStructureAddr = (ElfW(Dyn) *)dlsym(startupSyms, \"_DYNAMIC\");\n    /* Note: dlclose() is not called intentionally. */\n  }\n#    else\n  dynStructureAddr = &_DYNAMIC;\n#    endif\n\n  if (0 == COVERT_DATAFLOW(ADDR(dynStructureAddr))) {\n    /* _DYNAMIC symbol not resolved. */\n    return NULL;\n  }\n  if (NULL == cachedResult) {\n    int tag;\n\n    for (dp = (ElfW(Dyn) *)&_DYNAMIC; (tag = dp->d_tag) != 0; dp++) {\n      if (tag == DT_DEBUG) {\n        const struct r_debug *rd = (struct r_debug *)MAKE_CPTR(dp->d_un.d_ptr);\n\n        if (rd != NULL) {\n          const struct link_map *lm = rd->r_map;\n\n          if (lm != NULL)\n            cachedResult = lm->l_next; /* might be NULL */\n        }\n        break;\n      }\n    }\n  }\n  return cachedResult;\n}\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  struct link_map *lm;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (lm = GC_FirstDLOpenedLinkMap(); lm != NULL; lm = lm->l_next) {\n    ElfW(Ehdr) * e;\n    ElfW(Phdr) * p;\n    ptr_t start;\n    unsigned long offset;\n    int i;\n\n    e = (ElfW(Ehdr) *)lm->l_addr;\n    p = (ElfW(Phdr) *)((ptr_t)e + e->e_phoff);\n    offset = (unsigned long)ADDR(e);\n    for (i = 0; i < (int)e->e_phnum; i++, p++) {\n      switch (p->p_type) {\n      case PT_LOAD:\n        if ((p->p_flags & PF_W) == 0)\n          break;\n        start = MAKE_CPTR(p->p_vaddr) + offset;\n        GC_add_roots_inner(start, start + p->p_memsz, TRUE);\n        break;\n      default:\n        break;\n      }\n    }\n  }\n}\n\n#  endif /* SOLARISDL && !USE_PROC_FOR_LIBRARIES */\n\n#  if defined(DGUX) || defined(HURD) || defined(NACL) || defined(SCO_ELF) \\\n      || defined(SERENITY)                                                \\\n      || ((defined(ANY_BSD) || defined(LINUX)) && defined(__ELF__))\n\n#    ifdef USE_PROC_FOR_LIBRARIES\n\n#      include <fcntl.h>\n#      include <string.h>\n#      include <sys/stat.h>\n\n#      define MAPS_BUF_SIZE (32 * 1024)\n\n/* Sort an array of HeapSects by start address.                         */\n/* Unfortunately at least some versions of                              */\n/* Linux qsort end up calling malloc by way of sysconf, and hence can't */\n/* be used in the collector.  Hence we roll our own.  Should be         */\n/* reasonably fast if the array is already mostly sorted, as we expect  */\n/* it to be.                                                            */\nstatic void\nsort_heap_sects(struct HeapSect *base, size_t number_of_elements)\n{\n  GC_signed_word n = (GC_signed_word)number_of_elements;\n  GC_signed_word nsorted = 1;\n\n  while (nsorted < n) {\n    GC_signed_word i;\n\n    while (nsorted < n\n           && ADDR_LT(base[nsorted - 1].hs_start, base[nsorted].hs_start)) {\n      ++nsorted;\n    }\n    if (nsorted == n)\n      break;\n    GC_ASSERT(ADDR_LT(base[nsorted].hs_start, base[nsorted - 1].hs_start));\n    for (i = nsorted - 1;\n         i >= 0 && ADDR_LT(base[i + 1].hs_start, base[i].hs_start); --i) {\n      struct HeapSect tmp = base[i];\n\n      base[i] = base[i + 1];\n      base[i + 1] = tmp;\n    }\n    GC_ASSERT(ADDR_LT(base[nsorted - 1].hs_start, base[nsorted].hs_start));\n    ++nsorted;\n  }\n}\n\nSTATIC void\nGC_register_map_entries(const char *maps)\n{\n  const char *prot, *path;\n  ptr_t my_start, my_end;\n  ptr_t least_ha, greatest_ha;\n  unsigned maj_dev;\n  unsigned i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  sort_heap_sects(GC_our_memory, GC_n_memory);\n  least_ha = GC_our_memory[0].hs_start;\n  greatest_ha = GC_our_memory[GC_n_memory - 1].hs_start\n                + GC_our_memory[GC_n_memory - 1].hs_bytes;\n\n  for (;;) {\n    maps\n        = GC_parse_map_entry(maps, &my_start, &my_end, &prot, &maj_dev, &path);\n    if (NULL == maps)\n      break;\n\n    if (prot[1] == 'w') {\n      /* This is a writable mapping.  Add it to           */\n      /* the root set unless it is already otherwise      */\n      /* accounted for.                                   */\n#      ifndef THREADS\n      if (ADDR_GE(GC_stackbottom, my_start)\n          && ADDR_GE(my_end, GC_stackbottom)) {\n        /* Stack mapping; discard it.   */\n        continue;\n      }\n#      endif\n#      if defined(E2K) && defined(__ptr64__)\n      /* TODO: avoid hard-coded addresses */\n      if (ADDR(my_start) == 0xc2fffffff000UL\n          && ADDR(my_end) == 0xc30000000000UL && path[0] == '\\n')\n        continue; /* discard some special mapping */\n#      endif\n      if (path[0] == '[' && strncmp(path + 1, \"heap]\", 5) != 0)\n        continue; /* discard if a pseudo-path unless \"[heap]\" */\n\n#      ifdef THREADS\n      /* This may fail, since a thread may already be           */\n      /* unregistered, but its thread stack may still be there. */\n      /* That can fail because the stack may disappear while    */\n      /* we're marking.  Thus the marker is, and has to be      */\n      /* prepared to recover from segmentation faults.          */\n\n      if (GC_segment_is_thread_stack(my_start, my_end))\n        continue;\n\n        /* FIXME: NPTL squirrels                                  */\n        /* away pointers in pieces of the stack segment that we   */\n        /* don't scan.  We work around this                       */\n        /* by treating anything allocated by libpthread as        */\n        /* uncollectible, as we do in some other cases.           */\n        /* A specifically identified problem is that              */\n        /* thread stacks contain pointers to dynamic thread       */\n        /* vectors, which may be reused due to thread caching.    */\n        /* They may not be marked if the thread is still live.    */\n        /* This specific instance should be addressed by          */\n        /* INCLUDE_LINUX_THREAD_DESCR, but that doesn't quite     */\n        /* seem to suffice.                                       */\n        /* We currently trace entire thread stacks, if they are   */\n        /* are currently cached but unused.  This is              */\n        /* very suboptimal for performance reasons.               */\n#      endif\n      /* We no longer exclude the main data segment.              */\n      if (ADDR_GE(least_ha, my_end) || ADDR_GE(my_start, greatest_ha)) {\n        /* The easy case; just trace the entire segment.  */\n        GC_add_roots_inner(my_start, my_end, TRUE);\n        continue;\n      }\n      /* Add sections that don't belong to us. */\n      i = 0;\n      while (ADDR_LT(GC_our_memory[i].hs_start + GC_our_memory[i].hs_bytes,\n                     my_start)) {\n        ++i;\n      }\n      GC_ASSERT(i < GC_n_memory);\n      if (ADDR_GE(my_start, GC_our_memory[i].hs_start)) {\n        my_start = GC_our_memory[i].hs_start + GC_our_memory[i].hs_bytes;\n        ++i;\n      }\n      for (; i < GC_n_memory && ADDR_LT(my_start, my_end)\n             && ADDR_LT(GC_our_memory[i].hs_start, my_end);\n           ++i) {\n        if (ADDR_LT(my_start, GC_our_memory[i].hs_start))\n          GC_add_roots_inner(my_start, GC_our_memory[i].hs_start, TRUE);\n        my_start = GC_our_memory[i].hs_start + GC_our_memory[i].hs_bytes;\n      }\n      if (ADDR_LT(my_start, my_end))\n        GC_add_roots_inner(my_start, my_end, TRUE);\n    } else if (prot[0] == '-' && prot[1] == '-' && prot[2] == '-') {\n      /* Even roots added statically might disappear partially    */\n      /* (e.g. the roots added by INCLUDE_LINUX_THREAD_DESCR).    */\n      GC_remove_roots_subregion(my_start, my_end);\n    }\n  }\n}\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  GC_register_map_entries(GC_get_maps());\n}\n\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n  /* We now take care of the main data segment ourselves. */\n  return FALSE;\n}\n#      define HAVE_REGISTER_MAIN_STATIC_DATA\n\n#    else /* !USE_PROC_FOR_LIBRARIES */\n\n/* The following is the preferred way to walk dynamic libraries */\n/* for glibc 2.2.4+.  Unfortunately, it doesn't work for older  */\n/* versions.  Thanks to Jakub Jelinek for most of the code.     */\n\n#      if GC_GLIBC_PREREQ(2, 3) || defined(HOST_ANDROID)\n/* Are others OK here, too? */\n#        ifndef HAVE_DL_ITERATE_PHDR\n#          define HAVE_DL_ITERATE_PHDR\n#        endif\n#        ifdef HOST_ANDROID\n/* Android headers might have no such definition for some targets.  */\nEXTERN_C_BEGIN\nextern int dl_iterate_phdr(int (*cb)(struct dl_phdr_info *, size_t, void *),\n                           void *data);\nEXTERN_C_END\n#        endif\n#      endif /* __GLIBC__ >= 2 || HOST_ANDROID */\n\n#      if defined(__DragonFly__) || defined(__FreeBSD_kernel__) \\\n          || (defined(FREEBSD) && __FreeBSD__ >= 7)\n/* On the FreeBSD system, any target system at major version 7 shall   */\n/* have dl_iterate_phdr; therefore, we need not make it weak as below. */\n#        ifndef HAVE_DL_ITERATE_PHDR\n#          define HAVE_DL_ITERATE_PHDR\n#        endif\n#        define DL_ITERATE_PHDR_STRONG\n#      elif defined(HAVE_DL_ITERATE_PHDR)\n/* We have the header files for a glibc that includes dl_iterate_phdr.*/\n/* It may still not be available in the library on the target system. */\n/* Thus we also treat it as a weak symbol.                            */\nEXTERN_C_BEGIN\n#        pragma weak dl_iterate_phdr\nEXTERN_C_END\n#      endif\n\n#      ifdef HAVE_DL_ITERATE_PHDR\n\n#        ifdef PT_GNU_RELRO\n/* Instead of registering PT_LOAD sections directly, we keep them       */\n/* in a temporary list, and filter them by excluding PT_GNU_RELRO       */\n/* segments.  Processing PT_GNU_RELRO sections with                     */\n/* GC_exclude_static_roots instead would be superficially cleaner.  But */\n/* it runs into trouble if a client registers an overlapping segment,   */\n/* which unfortunately seems quite possible.                            */\n\n#          define MAX_LOAD_SEGS MAX_ROOT_SETS\n\nstatic struct load_segment {\n  ptr_t start;\n  ptr_t end;\n  /* Room for a second segment if we remove a RELRO segment */\n  /* from the middle.                                       */\n  ptr_t start2;\n  ptr_t end2;\n} load_segs[MAX_LOAD_SEGS];\n\nstatic int n_load_segs;\nstatic GC_bool load_segs_overflow;\n#        endif /* PT_GNU_RELRO */\n\nSTATIC int\nGC_register_dynlib_callback(struct dl_phdr_info *info, size_t size, void *ptr)\n{\n  const ElfW(Phdr) * p;\n  ptr_t my_start, my_end;\n  int i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Make sure struct dl_phdr_info is at least as big as we need.  */\n  if (size\n      < offsetof(struct dl_phdr_info, dlpi_phnum) + sizeof(info->dlpi_phnum))\n    return 1; /* stop */\n\n  p = info->dlpi_phdr;\n  for (i = 0; i < (int)info->dlpi_phnum; i++, p++) {\n    if (p->p_type == PT_LOAD) {\n      GC_has_static_roots_func callback = GC_has_static_roots;\n      if ((p->p_flags & PF_W) == 0)\n        continue;\n\n      my_start = MAKE_CPTR(p->p_vaddr) + info->dlpi_addr;\n      my_end = my_start + p->p_memsz;\n#        ifdef CHERI_PURECAP\n      my_start = PTR_ALIGN_UP(my_start, ALIGNMENT);\n      my_end = PTR_ALIGN_DOWN(my_end, ALIGNMENT);\n      if (!SPANNING_CAPABILITY(info->dlpi_addr, ADDR(my_start), ADDR(my_end)))\n        continue;\n      my_start = cheri_bounds_set(my_start, (word)(my_end - my_start));\n#        endif\n\n      if (callback != 0 && !callback(info->dlpi_name, my_start, p->p_memsz))\n        continue;\n#        ifdef PT_GNU_RELRO\n#          if CPP_PTRSZ >= 64 && !defined(CHERI_PURECAP)\n      /* TODO: GC_push_all eventually does the correct          */\n      /* rounding to the next multiple of ALIGNMENT, so, most   */\n      /* probably, we should remove the corresponding assertion */\n      /* check in GC_add_roots_inner along with this code line. */\n      /* my_start pointer value may require aligning.           */\n      my_start = PTR_ALIGN_DOWN(my_start, ALIGNMENT);\n#          endif\n      if (n_load_segs >= MAX_LOAD_SEGS) {\n        if (!load_segs_overflow) {\n          WARN(\"Too many PT_LOAD segments;\"\n               \" registering as roots directly...\\n\",\n               0);\n          load_segs_overflow = TRUE;\n        }\n        GC_add_roots_inner(my_start, my_end, TRUE);\n      } else {\n        load_segs[n_load_segs].start = my_start;\n        load_segs[n_load_segs].end = my_end;\n        load_segs[n_load_segs].start2 = NULL;\n        load_segs[n_load_segs].end2 = NULL;\n        ++n_load_segs;\n      }\n#        else\n      GC_add_roots_inner(my_start, my_end, TRUE);\n#        endif /* !PT_GNU_RELRO */\n    }\n  }\n\n#        ifdef PT_GNU_RELRO\n  p = info->dlpi_phdr;\n  for (i = 0; i < (int)info->dlpi_phnum; i++, p++) {\n    if (p->p_type == PT_GNU_RELRO) {\n      /* This entry is known to be constant and will eventually be    */\n      /* remapped as read-only.  However, the address range covered   */\n      /* by this entry is typically a subset of a previously          */\n      /* encountered \"LOAD\" segment, so we need to exclude it.        */\n      int j;\n\n      my_start = MAKE_CPTR(p->p_vaddr) + info->dlpi_addr;\n      my_end = my_start + p->p_memsz;\n      for (j = n_load_segs; --j >= 0;) {\n        if (ADDR_INSIDE(my_start, load_segs[j].start, load_segs[j].end)) {\n          if (load_segs[j].start2 != NULL) {\n            WARN(\"More than one GNU_RELRO segment per load one\\n\", 0);\n          } else {\n            GC_ASSERT(\n                ADDR_GE(PTR_ALIGN_UP(load_segs[j].end, GC_page_size), my_end));\n            /* Remove from the existing load segment. */\n            load_segs[j].end2 = load_segs[j].end;\n            load_segs[j].end = my_start;\n            load_segs[j].start2 = my_end;\n            /* Note that start2 may be greater than end2 because of   */\n            /* p->p_memsz value multiple of page size.                */\n          }\n          break;\n        }\n        if (0 == j && 0 == GC_has_static_roots)\n          WARN(\"Failed to find PT_GNU_RELRO segment\"\n               \" inside PT_LOAD region\\n\",\n               0);\n        /* No warning reported in case of the callback is present   */\n        /* because most likely the segment has been excluded.       */\n      }\n    }\n  }\n#        endif\n\n  /* Signal that we were called.        */\n  *(int *)ptr = 1;\n  return 0;\n}\n\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n#        if defined(DL_ITERATE_PHDR_STRONG) && !defined(CPPCHECK)\n  /* If dl_iterate_phdr is not a weak symbol then don't test against  */\n  /* zero (otherwise a compiler might issue a warning).               */\n  return FALSE;\n#        else\n  return 0 == COVERT_DATAFLOW(ADDR(dl_iterate_phdr));\n#        endif\n}\n#        define HAVE_REGISTER_MAIN_STATIC_DATA\n\n/* Return TRUE if we succeed, FALSE if dl_iterate_phdr wasn't there. */\nSTATIC GC_bool\nGC_register_dynamic_libraries_dl_iterate_phdr(void)\n{\n  int did_something;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_register_main_static_data())\n    return FALSE;\n\n#        ifdef PT_GNU_RELRO\n  {\n    static GC_bool excluded_segs = FALSE;\n    n_load_segs = 0;\n    load_segs_overflow = FALSE;\n    if (!EXPECT(excluded_segs, TRUE)) {\n      GC_exclude_static_roots_inner((ptr_t)load_segs,\n                                    (ptr_t)load_segs + sizeof(load_segs));\n      excluded_segs = TRUE;\n    }\n  }\n#        endif\n\n  did_something = 0;\n  dl_iterate_phdr(GC_register_dynlib_callback, &did_something);\n  if (did_something) {\n#        ifdef PT_GNU_RELRO\n    int i;\n\n    for (i = 0; i < n_load_segs; ++i) {\n      if (ADDR_LT(load_segs[i].start, load_segs[i].end))\n        GC_add_roots_inner(load_segs[i].start, load_segs[i].end, TRUE);\n      if (ADDR_LT(load_segs[i].start2, load_segs[i].end2))\n        GC_add_roots_inner(load_segs[i].start2, load_segs[i].end2, TRUE);\n    }\n#        endif\n  } else {\n    ptr_t datastart, dataend;\n#        ifdef DATASTART_USES_XGETDATASTART\n    static ptr_t datastart_cached = MAKE_CPTR(GC_WORD_MAX);\n\n    /* Evaluate DATASTART only once.  */\n    if (ADDR(datastart_cached) == GC_WORD_MAX) {\n      datastart_cached = DATASTART;\n    }\n    datastart = datastart_cached;\n#        else\n    datastart = DATASTART;\n#        endif\n#        ifdef DATAEND_IS_FUNC\n    {\n      static ptr_t dataend_cached = 0;\n      /* Evaluate DATAEND only once. */\n      if (dataend_cached == 0) {\n        dataend_cached = DATAEND;\n      }\n      dataend = dataend_cached;\n    }\n#        else\n    dataend = DATAEND;\n#        endif\n    if (NULL == *(char *volatile *)&datastart || ADDR_LT(dataend, datastart))\n      ABORT_ARG2(\"Wrong DATASTART/END pair\", \": %p .. %p\", (void *)datastart,\n                 (void *)dataend);\n\n    /* dl_iterate_phdr may forget the static data segment in  */\n    /* statically linked executables.                         */\n    GC_add_roots_inner(datastart, dataend, TRUE);\n#        ifdef GC_HAVE_DATAREGION2\n    /* Subtract one to check also for NULL without a compiler warning. */\n    if (ADDR(DATASTART2) - 1U >= ADDR(DATAEND2)) {\n      ABORT_ARG2(\"Wrong DATASTART/END2 pair\", \": %p .. %p\", (void *)DATASTART2,\n                 (void *)DATAEND2);\n    }\n    GC_add_roots_inner(DATASTART2, DATAEND2, TRUE);\n#        endif\n  }\n  return TRUE;\n}\n\n#      else /* !HAVE_DL_ITERATE_PHDR */\n\n/* Dynamic loading code for Linux running ELF.  Somewhat tested on  */\n/* Linux/i686, untested but hopefully should work on Linux/Alpha.   */\n/* This code was derived from the Solaris/ELF support.  Thanks to   */\n/* whatever kind soul wrote that.  - Patrick Bridges                */\n\n/* This does not necessarily work in all cases, e.g. with preloaded */\n/* dynamic libraries.                                               */\n\n#        if defined(NETBSD) || defined(OPENBSD)\n#          include <sys/exec_elf.h>\n/* For compatibility with 1.4.x. */\n#          ifndef DT_DEBUG\n#            define DT_DEBUG 21\n#          endif\n#          ifndef PT_LOAD\n#            define PT_LOAD 1\n#          endif\n#          ifndef PF_W\n#            define PF_W 2\n#          endif\n#        elif !defined(HOST_ANDROID)\n#          include <elf.h>\n#        endif\n\n#        ifndef HOST_ANDROID\n#          include <link.h>\n#        endif\n\n#      endif /* !HAVE_DL_ITERATE_PHDR */\n\nEXTERN_C_BEGIN\n#      ifdef __GNUC__\n#        pragma weak _DYNAMIC\n#      endif\nextern ElfW(Dyn) _DYNAMIC[];\nEXTERN_C_END\n\nSTATIC struct link_map *\nGC_FirstDLOpenedLinkMap(void)\n{\n  static struct link_map *cachedResult = 0;\n\n  if (0 == COVERT_DATAFLOW(ADDR(_DYNAMIC))) {\n    /* _DYNAMIC symbol not resolved. */\n    return NULL;\n  }\n  if (NULL == cachedResult) {\n#      if defined(NETBSD) && defined(RTLD_DI_LINKMAP)\n#        if defined(CPPCHECK)\n#          define GC_RTLD_DI_LINKMAP 2\n#        else\n#          define GC_RTLD_DI_LINKMAP RTLD_DI_LINKMAP\n#        endif\n    struct link_map *lm = NULL;\n    if (!dlinfo(RTLD_SELF, GC_RTLD_DI_LINKMAP, &lm) && lm != NULL) {\n      /* Now lm points link_map object of libgc.  Since it    */\n      /* might not be the first dynamically linked object,    */\n      /* try to find it (object next to the main object).     */\n      while (lm->l_prev != NULL) {\n        lm = lm->l_prev;\n      }\n      cachedResult = lm->l_next;\n    }\n#      else\n    ElfW(Dyn) * dp;\n    int tag;\n\n    for (dp = _DYNAMIC; (tag = dp->d_tag) != 0; dp++) {\n      if (tag == DT_DEBUG) {\n        const struct r_debug *rd = (struct r_debug *)MAKE_CPTR(dp->d_un.d_ptr);\n\n        /* d_ptr could be 0 if libs are linked statically. */\n        if (rd != NULL) {\n          const struct link_map *lm = rd->r_map;\n\n#        if defined(CPPCHECK)                                               \\\n            && ((defined(HOST_ANDROID) && !defined(GC_DONT_DEFINE_LINK_MAP) \\\n                 && !(__ANDROID_API__ >= 21))                               \\\n                || defined(SERENITY))\n          GC_noop1((word)rd->r_version);\n#        endif\n          if (lm != NULL)\n            cachedResult = lm->l_next; /* might be NULL */\n        }\n        break;\n      }\n    }\n#      endif /* !NETBSD || !RTLD_DI_LINKMAP */\n  }\n  return cachedResult;\n}\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  struct link_map *lm;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#      ifdef HAVE_DL_ITERATE_PHDR\n  if (GC_register_dynamic_libraries_dl_iterate_phdr()) {\n    return;\n  }\n#      endif\n  for (lm = GC_FirstDLOpenedLinkMap(); lm != NULL; lm = lm->l_next) {\n    ElfW(Ehdr) * e;\n    ElfW(Phdr) * p;\n    ptr_t start;\n    unsigned long offset;\n    int i;\n\n    e = (ElfW(Ehdr) *)lm->l_addr;\n#      ifdef HOST_ANDROID\n    if (NULL == e)\n      continue;\n#      endif\n    p = (ElfW(Phdr) *)((ptr_t)e + e->e_phoff);\n    offset = (unsigned long)ADDR(e);\n    for (i = 0; i < (int)e->e_phnum; i++, p++) {\n      switch (p->p_type) {\n      case PT_LOAD:\n        if ((p->p_flags & PF_W) == 0)\n          break;\n        start = MAKE_CPTR(p->p_vaddr) + offset;\n        GC_add_roots_inner(start, start + p->p_memsz, TRUE);\n        break;\n      default:\n        break;\n      }\n    }\n#      if defined(CPPCHECK)                                               \\\n          && ((defined(HOST_ANDROID) && !defined(GC_DONT_DEFINE_LINK_MAP) \\\n               && !(__ANDROID_API__ >= 21))                               \\\n              || defined(SERENITY))\n    GC_noop1_ptr(lm->l_name);\n    GC_noop1((word)lm->l_ld);\n    GC_noop1_ptr(lm->l_prev);\n#      endif\n  }\n}\n\n#    endif /* !USE_PROC_FOR_LIBRARIES */\n\n#  endif /* DGUX || HURD || NACL || (ANY_BSD || LINUX) && __ELF__ */\n\n#  if defined(USE_PROC_FOR_LIBRARIES) && !defined(LINUX) || defined(IRIX5)\n\n#    include <elf.h>\n#    include <errno.h>\n#    include <fcntl.h>\n#    include <sys/procfs.h>\n#    include <sys/stat.h>\n\n/* This is included only for the following test. */\n#    include <signal.h>\n#    ifndef _sigargs\n#      define IRIX6\n#    endif\n\n/* We use /proc to track down all parts of the address space that are   */\n/* mapped by the process, and throw out regions we know we shouldn't    */\n/* worry about.  This may also work under other SVR4 variants.          */\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  static int fd = -1;\n  static prmap_t *addr_map = 0;\n  /* Number of records currently in addr_map. */\n  static int current_sz = 0;\n  char buf[32];\n  /* Required size of addr_map.       */\n  int needed_sz = 0;\n  int i;\n  long flags;\n  ptr_t start;\n  ptr_t limit;\n  word heap_start = ADDR(HEAP_START);\n  word heap_end = heap_start;\n#    ifdef SOLARISDL\n#      define MA_PHYS 0\n#    endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (fd < 0) {\n    (void)snprintf(buf, sizeof(buf), \"/proc/%ld\", (long)getpid());\n    buf[sizeof(buf) - 1] = '\\0';\n    fd = open(buf, O_RDONLY);\n    if (fd < 0) {\n      ABORT(\"/proc open failed\");\n    }\n  }\n  if (ioctl(fd, PIOCNMAP, &needed_sz) < 0) {\n    ABORT_ARG2(\"/proc PIOCNMAP ioctl failed\", \": fd= %d, errno= %d\", fd,\n               errno);\n  }\n  if (needed_sz >= current_sz) {\n    GC_scratch_recycle_no_gww(addr_map, (size_t)current_sz * sizeof(prmap_t));\n    /* Expansion, plus room for record 0.   */\n    current_sz = needed_sz * 2 + 1;\n    addr_map\n        = (prmap_t *)GC_scratch_alloc((size_t)current_sz * sizeof(prmap_t));\n    if (NULL == addr_map)\n      ABORT(\"Insufficient memory for address map\");\n  }\n  if (ioctl(fd, PIOCMAP, addr_map) < 0) {\n    ABORT_ARG3(\"/proc PIOCMAP ioctl failed\",\n               \": errcode= %d, needed_sz= %d, addr_map= %p\", errno, needed_sz,\n               (void *)addr_map);\n  }\n  if (GC_n_heap_sects > 0) {\n    heap_end = ADDR(GC_heap_sects[GC_n_heap_sects - 1].hs_start)\n               + GC_heap_sects[GC_n_heap_sects - 1].hs_bytes;\n    if (heap_end < GC_scratch_last_end_addr)\n      heap_end = GC_scratch_last_end_addr;\n  }\n  for (i = 0; i < needed_sz; i++) {\n    flags = addr_map[i].pr_mflags;\n    if ((flags & (MA_BREAK | MA_STACK | MA_PHYS | MA_FETCHOP | MA_NOTCACHED))\n        != 0)\n      goto irrelevant;\n    if ((flags & (MA_READ | MA_WRITE)) != (MA_READ | MA_WRITE))\n      goto irrelevant;\n    /* The latter test is empirically useless in very old Irix      */\n    /* versions.  Other than the main data and stack segments,      */\n    /* everything appears to be mapped readable, writable,          */\n    /* executable, and shared(!!).  This makes no sense to me. - HB */\n    start = (ptr_t)addr_map[i].pr_vaddr;\n    if (GC_roots_present(start)\n        || (ADDR(start) >= heap_start && ADDR(start) < heap_end))\n      goto irrelevant;\n\n    limit = start + addr_map[i].pr_size;\n    /* The following seemed to be necessary for very old versions   */\n    /* of Irix, but it has been reported to discard relevant        */\n    /* segments under Irix 6.5.                                     */\n#    ifndef IRIX6\n    if (addr_map[i].pr_off == 0 && strncmp(start, ELFMAG, 4) == 0) {\n      /* Discard text segments, i.e. 0-offset mappings against    */\n      /* executable files which appear to have ELF headers.       */\n      caddr_t arg;\n      int obj;\n#      define MAP_IRR_SZ 10\n      /* Known irrelevant map entries.    */\n      static ptr_t map_irr[MAP_IRR_SZ];\n      static int n_irr = 0;\n      struct stat buf;\n      int j;\n\n      for (j = 0; j < n_irr; j++) {\n        if (map_irr[j] == start)\n          goto irrelevant;\n      }\n      arg = (caddr_t)start;\n      obj = ioctl(fd, PIOCOPENM, &arg);\n      if (obj >= 0) {\n        fstat(obj, &buf);\n        close(obj);\n        if ((buf.st_mode & 0111) != 0) {\n          if (n_irr < MAP_IRR_SZ) {\n            map_irr[n_irr++] = start;\n          }\n          goto irrelevant;\n        }\n      }\n    }\n#    endif /* !IRIX6 */\n    GC_add_roots_inner(start, limit, TRUE);\n  irrelevant:;\n  }\n  /* Don't keep cached descriptor, for now.  Some kernels don't like us */\n  /* to keep a /proc file descriptor around during kill -9.             */\n  /* Otherwise, it should also require FD_CLOEXEC and proper handling   */\n  /* at fork (i.e. close because of the pid change).                    */\n  if (close(fd) < 0)\n    ABORT(\"Couldn't close /proc file\");\n  fd = -1;\n}\n\n#  endif /* USE_PROC_FOR_LIBRARIES && !LINUX || IRIX5 */\n\n#  ifdef AIX\n#    include <alloca.h>\n#    include <sys/errno.h>\n#    include <sys/ldr.h>\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  int ldibuflen = 8192;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (;;) {\n    int len;\n    struct ld_info *ldi;\n#    if defined(CPPCHECK)\n    char ldibuf[ldibuflen];\n#    else\n    char *ldibuf = alloca(ldibuflen);\n#    endif\n\n    len = loadquery(L_GETINFO, ldibuf, ldibuflen);\n    if (len < 0) {\n      if (errno != ENOMEM) {\n        ABORT(\"loadquery failed\");\n      }\n      ldibuflen *= 2;\n      continue;\n    }\n\n    ldi = (struct ld_info *)ldibuf;\n    for (;;) {\n      len = ldi->ldinfo_next;\n      GC_add_roots_inner((ptr_t)ldi->ldinfo_dataorg,\n                         (ptr_t)ldi->ldinfo_dataorg + ldi->ldinfo_datasize,\n                         TRUE);\n      if (0 == len)\n        break;\n      ldi = (struct ld_info *)((ptr_t)ldi + len);\n    }\n    break;\n  }\n}\n#  endif /* AIX */\n\n#  ifdef DARWIN\n\n/* __private_extern__ hack required for pre-3.4 gcc versions.   */\n#    ifndef __private_extern__\n#      define __private_extern__ extern\n#      include <mach-o/dyld.h>\n#      undef __private_extern__\n#    else\n#      include <mach-o/dyld.h>\n#    endif\n\n#    if CPP_WORDSZ == 64\n#      define GC_MACH_HEADER mach_header_64\n#    else\n#      define GC_MACH_HEADER mach_header\n#    endif\n\n#    ifdef MISSING_MACH_O_GETSECT_H\nEXTERN_C_BEGIN\nextern uint8_t *getsectiondata(const struct GC_MACH_HEADER *, const char *seg,\n                               const char *sect, unsigned long *psz);\nEXTERN_C_END\n#    else\n#      include <mach-o/getsect.h>\n#    endif\n\n/* Writable sections generally available on Darwin.     */\nSTATIC const struct dyld_sections_s {\n  const char *seg;\n  const char *sect;\n} GC_dyld_sections[]\n    = { { SEG_DATA, SECT_DATA },\n        /* Used by FSF GCC, but not by OS X system tools, so far.   */\n        { SEG_DATA, \"__static_data\" },\n        { SEG_DATA, SECT_BSS },\n        { SEG_DATA, SECT_COMMON },\n        /* FSF GCC - zero-sized object sections for targets         */\n        /* supporting section anchors.                              */\n        { SEG_DATA, \"__zobj_data\" },\n        { SEG_DATA, \"__zobj_bss\" } };\n\n/* Additional writable sections:                                */\n/* GCC on Darwin constructs aligned sections \"on demand\", where */\n/* the alignment size is embedded in the section name.          */\n/* Furthermore, there are distinctions between sections         */\n/* containing private vs. public symbols.  It also constructs   */\n/* sections specifically for zero-sized objects, when the       */\n/* target supports section anchors.                             */\nSTATIC const char *const GC_dyld_bss_prefixes[]\n    = { \"__bss\", \"__pu_bss\", \"__zo_bss\", \"__zo_pu_bss\" };\n\n/* Currently, mach-o will allow up to the max of 2^15 alignment */\n/* in an object file.                                           */\n#    ifndef L2_MAX_OFILE_ALIGNMENT\n#      define L2_MAX_OFILE_ALIGNMENT 15\n#    endif\n\nSTATIC const char *\nGC_dyld_name_for_hdr(const struct GC_MACH_HEADER *phdr)\n{\n  unsigned long i, count = _dyld_image_count();\n\n  for (i = 0; i < count; i++) {\n    if ((const struct GC_MACH_HEADER *)_dyld_get_image_header(i) == phdr)\n      return _dyld_get_image_name(i);\n  }\n  /* TODO: probably ABORT in this case? */\n  return NULL; /* not found */\n}\n\n/* getsectbynamefromheader is deprecated (first time in macOS 13.0),    */\n/* getsectiondata (introduced in macOS 10.7) is used instead if exists. */\n/* Define USE_GETSECTBYNAME to use the deprecated symbol, if needed.    */\n#    if !defined(USE_GETSECTBYNAME) \\\n        && (MAC_OS_X_VERSION_MIN_REQUIRED < 1070 /*MAC_OS_X_VERSION_10_7*/)\n#      define USE_GETSECTBYNAME\n#    endif\n\nstatic void\ndyld_section_add_del(const struct GC_MACH_HEADER *phdr, intptr_t slide,\n                     const char *dlpi_name, GC_has_static_roots_func callback,\n                     const char *seg, const char *secnam, GC_bool is_add)\n{\n  ptr_t start, finish;\n  unsigned long sec_size;\n#    ifdef USE_GETSECTBYNAME\n#      if CPP_WORDSZ == 64\n  const struct section_64 *sec = getsectbynamefromheader_64(phdr, seg, secnam);\n#      else\n  const struct section *sec = getsectbynamefromheader(phdr, seg, secnam);\n#      endif\n\n  if (NULL == sec)\n    return;\n  sec_size = sec->size;\n  start = MAKE_CPTR(slide + sec->addr);\n#    else\n\n  UNUSED_ARG(slide);\n  sec_size = 0;\n  start = (ptr_t)getsectiondata(phdr, seg, secnam, &sec_size);\n  if (NULL == start)\n    return;\n#    endif\n  if (sec_size < sizeof(ptr_t))\n    return;\n  finish = start + sec_size;\n  if (is_add) {\n    LOCK();\n    /* The user callback is invoked holding the allocator lock.   */\n    if (EXPECT(callback != 0, FALSE)\n        && !callback(dlpi_name, start, (size_t)sec_size)) {\n      UNLOCK();\n      return; /* skip section */\n    }\n    GC_add_roots_inner(start, finish, FALSE);\n    UNLOCK();\n  } else {\n    GC_remove_roots(start, finish);\n  }\n#    ifdef DARWIN_DEBUG\n  GC_log_printf(\"%s section __DATA,%s at %p-%p (%lu bytes) from image %s\\n\",\n                is_add ? \"Added\" : \"Removed\", secnam, (void *)start,\n                (void *)finish, sec_size, dlpi_name);\n#    endif\n}\n\nstatic void\ndyld_image_add_del(const struct GC_MACH_HEADER *phdr, intptr_t slide,\n                   GC_has_static_roots_func callback, GC_bool is_add)\n{\n  unsigned i, j;\n  const char *dlpi_name;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n#    ifndef DARWIN_DEBUG\n  if (0 == callback) {\n    dlpi_name = NULL;\n  } else\n#    endif\n  /* else */ {\n    dlpi_name = GC_dyld_name_for_hdr(phdr);\n  }\n  for (i = 0; i < sizeof(GC_dyld_sections) / sizeof(GC_dyld_sections[0]);\n       i++) {\n    dyld_section_add_del(phdr, slide, dlpi_name, callback,\n                         GC_dyld_sections[i].seg, GC_dyld_sections[i].sect,\n                         is_add);\n  }\n\n  /* Sections constructed on demand.    */\n  for (j = 0; j < sizeof(GC_dyld_bss_prefixes) / sizeof(char *); j++) {\n    /* Our manufactured aligned BSS sections.   */\n    for (i = 0; i <= L2_MAX_OFILE_ALIGNMENT; i++) {\n      char secnam[16];\n\n      (void)snprintf(secnam, sizeof(secnam), \"%s%u\", GC_dyld_bss_prefixes[j],\n                     i);\n      secnam[sizeof(secnam) - 1] = '\\0';\n      dyld_section_add_del(phdr, slide, dlpi_name, 0 /* callback */, SEG_DATA,\n                           secnam, is_add);\n    }\n  }\n\n#    if defined(DARWIN_DEBUG) && !defined(NO_DEBUGGING)\n  READER_LOCK();\n  GC_print_static_roots();\n  READER_UNLOCK();\n#    endif\n}\n\nSTATIC void\nGC_dyld_image_add(const struct GC_MACH_HEADER *phdr, intptr_t slide)\n{\n  if (!GC_no_dls)\n    dyld_image_add_del(phdr, slide, GC_has_static_roots, TRUE);\n}\n\nSTATIC void\nGC_dyld_image_remove(const struct GC_MACH_HEADER *phdr, intptr_t slide)\n{\n  dyld_image_add_del(phdr, slide, 0 /* callback */, FALSE);\n}\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  /* Currently does nothing. The callbacks are setup by GC_init_dyld()\n  The dyld library takes it from there. */\n}\n\n/* The _dyld_* functions have an internal lock, so none of them can be  */\n/* called while the world is stopped without the risk of a deadlock.    */\n/* Because of this we MUST setup callbacks BEFORE we ever stop the      */\n/* world.  This should be called BEFORE any thread is created and       */\n/* WITHOUT the allocator lock held.                                     */\n\n/* _dyld_bind_fully_image_containing_address is deprecated, so use      */\n/* dlopen(0,RTLD_NOW) instead; define USE_DYLD_TO_BIND to override this */\n/* if needed.                                                           */\n\nGC_INNER void\nGC_init_dyld(void)\n{\n  static GC_bool initialized = FALSE;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  if (initialized)\n    return;\n\n#    ifdef DARWIN_DEBUG\n  GC_log_printf(\"Registering dyld callbacks...\\n\");\n#    endif\n\n  /* Apple's Documentation:\n     When you call _dyld_register_func_for_add_image, the dynamic linker\n     runtime calls the specified callback (func) once for each of the images\n     that is currently loaded into the program. When a new image is added to\n     the program, your callback is called again with the mach_header for the\n     new image, and the virtual memory slide amount of the new image.\n\n     This WILL properly register already linked libraries and libraries\n     linked in the future.\n  */\n\n  /* Structure mach_header_64 has the same fields as mach_header except */\n  /* for the reserved one at the end, so these casts are OK.            */\n  _dyld_register_func_for_add_image(\n      (void (*)(const struct mach_header *, intptr_t))GC_dyld_image_add);\n  _dyld_register_func_for_remove_image(\n      (void (*)(const struct mach_header *, intptr_t))GC_dyld_image_remove);\n\n  /* Set this early to avoid reentrancy issues. */\n  initialized = TRUE;\n\n#    ifndef NO_DYLD_BIND_FULLY_IMAGE\n  if (GC_no_dls)\n    return; /* skip main data segment registration */\n\n  /* When the environment variable is set, the dynamic linker binds   */\n  /* all undefined symbols the application needs at launch time.      */\n  /* This includes function symbols that are normally bound lazily at */\n  /* the time of their first invocation.                              */\n  if (GETENV(\"DYLD_BIND_AT_LAUNCH\") != NULL)\n    return;\n\n    /* The environment variable is unset, so we should bind manually.   */\n#      ifdef DARWIN_DEBUG\n  GC_log_printf(\"Forcing full bind of GC code...\\n\");\n#      endif\n#      ifndef USE_DYLD_TO_BIND\n  {\n    void *dl_handle = dlopen(NULL, RTLD_NOW);\n\n    if (!dl_handle)\n      ABORT(\"dlopen failed (to bind fully image)\");\n      /* Note that the handle is never closed.        */\n#        if defined(CPPCHECK) || defined(LINT2)\n    GC_noop1_ptr(dl_handle);\n#        endif\n  }\n#      else\n  /* Note: '_dyld_bind_fully_image_containing_address' is deprecated. */\n  if (!_dyld_bind_fully_image_containing_address((unsigned long *)GC_malloc))\n    ABORT(\"_dyld_bind_fully_image_containing_address failed\");\n#      endif\n#    endif\n}\n\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n  /* Already done through dyld callbacks. */\n  return FALSE;\n}\n#    define HAVE_REGISTER_MAIN_STATIC_DATA\n\n#  endif /* DARWIN */\n\n#  if defined(HAIKU)\n#    include <kernel/image.h>\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  image_info info;\n  int32 cookie = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  while (get_next_image_info(B_CURRENT_TEAM, &cookie, &info) == B_OK) {\n    ptr_t data = (ptr_t)info.data;\n\n    GC_add_roots_inner(data, data + info.data_size, TRUE);\n  }\n}\n\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n  /* On Haiku, the main application binary is also a \"shared image\" and */\n  /* will be reported in an image_info same as for dynamically-loaded   */\n  /* libraries.                                                         */\n  return FALSE;\n}\n#    define HAVE_REGISTER_MAIN_STATIC_DATA\n#  endif /* HAIKU */\n\n#  ifdef HPUX\n#    include <dl.h>\n#    include <errno.h>\n\nEXTERN_C_BEGIN\nextern char *sys_errlist[];\nextern int sys_nerr;\nEXTERN_C_END\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  /* Ordinal position in shared library search list.    */\n  int index = 1;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* For each dynamic library loaded. */\n  for (;;) {\n    /* Shared library info, see dl.h.        */\n    struct shl_descriptor *shl_desc;\n    /* Get info about next shared library.    */\n    int status = shl_get(index, &shl_desc);\n\n    /* Check if this is the end of the list or if some error occurred. */\n    if (status != 0) {\n#    ifdef THREADS\n      /* I've seen errno values of 0.  The man page is not clear   */\n      /* as to whether errno should get set on a -1 return.        */\n      break;\n#    else\n      if (errno == EINVAL) {\n        /* Moved past end of shared library list.  Finish.  */\n        break;\n      } else {\n        ABORT_ARG3(\"shl_get failed\", \": status= %d, errcode= %d (%s)\", status,\n                   errno, errno < sys_nerr ? sys_errlist[errno] : \"\");\n      }\n#    endif\n    }\n\n#    ifdef DL_VERBOSE\n    GC_log_printf(\"---Shared library---\\n\");\n    GC_log_printf(\"filename= \\\"%s\\\"\\n\", shl_desc->filename);\n    GC_log_printf(\"index= %d\\n\", index);\n    GC_log_printf(\"handle= %08x\\n\", (unsigned long)shl_desc->handle);\n    GC_log_printf(\"text seg.start= %08x\\n\", shl_desc->tstart);\n    GC_log_printf(\"text seg.end= %08x\\n\", shl_desc->tend);\n    GC_log_printf(\"data seg.start= %08x\\n\", shl_desc->dstart);\n    GC_log_printf(\"data seg.end= %08x\\n\", shl_desc->dend);\n    GC_log_printf(\"ref.count= %lu\\n\", shl_desc->ref_count);\n#    endif\n\n    /* Register shared library's data segment as a garbage collection */\n    /* root.                                                          */\n    GC_add_roots_inner((char *)shl_desc->dstart, (char *)shl_desc->dend, TRUE);\n\n    index++;\n  }\n}\n#  endif /* HPUX */\n\n#  ifdef OSF1\n#    include <loader.h>\n\nEXTERN_C_BEGIN\nextern char *sys_errlist[];\nextern int sys_nerr, errno;\nEXTERN_C_END\n\nGC_INNER void\nGC_register_dynamic_libraries(void)\n{\n  ldr_module_t moduleid = LDR_NULL_MODULE;\n  ldr_process_t mypid;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Obtain id of this process.       */\n  mypid = ldr_my_process();\n\n  /* For each module. */\n  for (;;) {\n    ldr_module_info_t moduleinfo;\n    size_t modulereturnsize;\n    ldr_region_t region;\n    ldr_region_info_t regioninfo;\n    size_t regionreturnsize;\n    /* Get the next (first) module. */\n    int status = ldr_next_module(mypid, &moduleid);\n\n    if (moduleid == LDR_NULL_MODULE) {\n      /* No more modules.     */\n      break;\n    }\n\n    /* Check status AFTER checking moduleid because       */\n    /* of a bug in the non-shared ldr_next_module stub.   */\n    if (status != 0) {\n      ABORT_ARG3(\"ldr_next_module failed\", \": status= %d, errcode= %d (%s)\",\n                 status, errno, errno < sys_nerr ? sys_errlist[errno] : \"\");\n    }\n\n    /* Get the module information.    */\n    status = ldr_inq_module(mypid, moduleid, &moduleinfo, sizeof(moduleinfo),\n                            &modulereturnsize);\n    if (status != 0)\n      ABORT(\"ldr_inq_module failed\");\n\n    /* Is module for the main program (i.e. nonshared portion)?   */\n    if ((moduleinfo.lmi_flags & LDR_MAIN) != 0) {\n      /* Skip the main module.        */\n      continue;\n    }\n\n#    ifdef DL_VERBOSE\n    GC_log_printf(\"---Module---\\n\");\n    GC_log_printf(\"Module ID: %ld\\n\", moduleinfo.lmi_modid);\n    GC_log_printf(\"Count of regions: %d\\n\", moduleinfo.lmi_nregion);\n    GC_log_printf(\"Flags for module: %016lx\\n\", moduleinfo.lmi_flags);\n    GC_log_printf(\"Module pathname: \\\"%s\\\"\\n\", moduleinfo.lmi_name);\n#    endif\n\n    /* For each region in this module. */\n    for (region = 0; region < moduleinfo.lmi_nregion; region++) {\n      /* Get the region information. */\n      status = ldr_inq_region(mypid, moduleid, region, &regioninfo,\n                              sizeof(regioninfo), &regionreturnsize);\n      if (status != 0)\n        ABORT(\"ldr_inq_region failed\");\n\n      /* Only process writable (data) regions.      */\n      if ((regioninfo.lri_prot & LDR_W) == 0)\n        continue;\n\n#    ifdef DL_VERBOSE\n      GC_log_printf(\"--- Region ---\\n\");\n      GC_log_printf(\"Region number: %ld\\n\", regioninfo.lri_region_no);\n      GC_log_printf(\"Protection flags: %016x\\n\", regioninfo.lri_prot);\n      GC_log_printf(\"Virtual address: %p\\n\", regioninfo.lri_vaddr);\n      GC_log_printf(\"Mapped address: %p\\n\", regioninfo.lri_mapaddr);\n      GC_log_printf(\"Region size: %ld\\n\", regioninfo.lri_size);\n      GC_log_printf(\"Region name: \\\"%s\\\"\\n\", regioninfo.lri_name);\n#    endif\n\n      /* Register region as a garbage collection root.      */\n      GC_add_roots_inner((char *)regioninfo.lri_mapaddr,\n                         (char *)regioninfo.lri_mapaddr + regioninfo.lri_size,\n                         TRUE);\n    }\n  }\n}\n#  endif /* OSF1 */\n\n#endif /* DYNAMIC_LOADING */\n\n#ifdef GC_MUST_RESTORE_REDEFINED_DLOPEN\n#  define dlopen GC_dlopen\n#endif\n\n#if !defined(HAVE_REGISTER_MAIN_STATIC_DATA) && defined(DYNAMIC_LOADING)\n/* Do we need to separately register the main static data segment? */\nGC_INNER GC_bool\nGC_register_main_static_data(void)\n{\n  return TRUE;\n}\n#endif /* HAVE_REGISTER_MAIN_STATIC_DATA */\n\n/* Register a routine to filter dynamic library registration.  */\nGC_API void GC_CALL\nGC_register_has_static_roots_callback(GC_has_static_roots_func callback)\n{\n  GC_has_static_roots = callback;\n}\n"
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "finalize.c",
          "type": "blob",
          "size": 46.876953125,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1996 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 2007 Free Software Foundation, Inc.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\"\n\n#ifndef GC_NO_FINALIZATION\n#  include \"gc/javaxfc.h\" /* to get GC_finalize_all() as extern \"C\" */\n\n/* Type of mark procedure used for marking from finalizable object.     */\n/* This procedure normally does not mark the object, only its           */\n/* descendants.                                                         */\ntypedef void (*finalization_mark_proc)(ptr_t /* finalizable_obj_ptr */);\n\n#  define HASH3(addr, size, log_size)                               \\\n    ((size_t)((ADDR(addr) >> 3) ^ (ADDR(addr) >> (3 + (log_size)))) \\\n     & ((size)-1))\n#  define HASH2(addr, log_size) HASH3(addr, (size_t)1 << (log_size), log_size)\n\nstruct hash_chain_entry {\n  GC_hidden_pointer hidden_key;\n  struct hash_chain_entry *next;\n};\n\nstruct disappearing_link {\n  struct hash_chain_entry prolog;\n#  define dl_hidden_link prolog.hidden_key /* field to be cleared */\n#  define dl_next(x) (struct disappearing_link *)((x)->prolog.next)\n#  define dl_set_next(x, y) \\\n    (void)((x)->prolog.next = (struct hash_chain_entry *)(y))\n  GC_hidden_pointer dl_hidden_obj; /* pointer to object base */\n};\n\nstruct finalizable_object {\n  struct hash_chain_entry prolog;\n  /* Pointer to object base.  No longer hidden once object is on      */\n  /* finalize_now queue.                                              */\n#  define fo_hidden_base prolog.hidden_key\n#  define fo_next(x) (struct finalizable_object *)((x)->prolog.next)\n#  define fo_set_next(x, y) ((x)->prolog.next = (struct hash_chain_entry *)(y))\n  GC_finalization_proc fo_fn;          /* finalizer */\n  finalization_mark_proc fo_mark_proc; /* mark-through procedure */\n  ptr_t fo_client_data;\n  size_t fo_object_sz; /* in bytes */\n};\n\n#  ifdef AO_HAVE_store\n/* Update finalize_now atomically as GC_should_invoke_finalizers does */\n/* not acquire the allocator lock.                                    */\n#    define SET_FINALIZE_NOW(fo) \\\n      GC_cptr_store((volatile ptr_t *)&GC_fnlz_roots.finalize_now, (ptr_t)(fo))\n#  else\n#    define SET_FINALIZE_NOW(fo) (void)(GC_fnlz_roots.finalize_now = (fo))\n#  endif /* !THREADS */\n\nGC_API void GC_CALL\nGC_push_finalizer_structures(void)\n{\n  GC_ASSERT(ADDR(&GC_dl_hashtbl.head) % ALIGNMENT == 0);\n  GC_ASSERT(ADDR(&GC_fnlz_roots) % ALIGNMENT == 0);\n#  ifndef GC_LONG_REFS_NOT_NEEDED\n  GC_ASSERT(ADDR(&GC_ll_hashtbl.head) % ALIGNMENT == 0);\n  GC_PUSH_ALL_SYM(GC_ll_hashtbl.head);\n#  endif\n  GC_PUSH_ALL_SYM(GC_dl_hashtbl.head);\n  GC_PUSH_ALL_SYM(GC_fnlz_roots);\n  /* GC_toggleref_arr is pushed specially by GC_mark_togglerefs.        */\n}\n\n/* Threshold of log_size to initiate full collection before growing     */\n/* a hash table.                                                        */\n#  ifndef GC_ON_GROW_LOG_SIZE_MIN\n#    define GC_ON_GROW_LOG_SIZE_MIN LOG_HBLKSIZE\n#  endif\n\n/* Double the size of a hash table.  *log_size_ptr is the log of its    */\n/* current size.  May be a no-op.  *table_ptr is a pointer to an array  */\n/* of hash headers.  We update both *table_ptr and *log_size_ptr on     */\n/* success.                                                             */\nSTATIC void\nGC_grow_table(struct hash_chain_entry ***table_ptr, unsigned *log_size_ptr,\n              const size_t *entries_ptr)\n{\n  size_t i;\n  struct hash_chain_entry *p;\n  unsigned log_old_size = *log_size_ptr;\n  unsigned log_new_size = log_old_size + 1;\n  size_t old_size = NULL == *table_ptr ? 0 : (size_t)1 << log_old_size;\n  size_t new_size = (size_t)1 << log_new_size;\n  /* FIXME: Power of 2 size often gets rounded up to one more page. */\n  struct hash_chain_entry **new_table;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Avoid growing the table in case of at least 25% of entries can   */\n  /* be deleted by enforcing a collection.  Ignored for small tables. */\n  /* In incremental mode we skip this optimization, as we want to     */\n  /* avoid triggering a full GC whenever possible.                    */\n  if (log_old_size >= (unsigned)GC_ON_GROW_LOG_SIZE_MIN && !GC_incremental) {\n    IF_CANCEL(int cancel_state;)\n\n    DISABLE_CANCEL(cancel_state);\n    GC_gcollect_inner();\n    RESTORE_CANCEL(cancel_state);\n    /* GC_finalize might decrease entries value.  */\n    if (*entries_ptr < ((size_t)1 << log_old_size) - (*entries_ptr >> 2))\n      return;\n  }\n\n  new_table = (struct hash_chain_entry **)GC_INTERNAL_MALLOC_IGNORE_OFF_PAGE(\n      new_size * sizeof(struct hash_chain_entry *), NORMAL);\n  if (NULL == new_table) {\n    if (NULL == *table_ptr) {\n      ABORT(\"Insufficient space for initial table allocation\");\n    } else {\n      return;\n    }\n  }\n  for (i = 0; i < old_size; i++) {\n    for (p = (*table_ptr)[i]; p != NULL;) {\n      ptr_t real_key = (ptr_t)GC_REVEAL_POINTER(p->hidden_key);\n      struct hash_chain_entry *next = p->next;\n      size_t new_hash = HASH3(real_key, new_size, log_new_size);\n\n      p->next = new_table[new_hash];\n      GC_dirty(p);\n      new_table[new_hash] = p;\n      p = next;\n    }\n  }\n  *log_size_ptr = log_new_size;\n  *table_ptr = new_table;\n  GC_dirty(new_table); /* entire object */\n}\n\nGC_API int GC_CALL\nGC_register_disappearing_link(void **link)\n{\n  ptr_t base;\n\n  base = (ptr_t)GC_base(link);\n  if (base == 0)\n    ABORT(\"Bad arg to GC_register_disappearing_link\");\n  return GC_general_register_disappearing_link(link, base);\n}\n\nSTATIC int\nGC_register_disappearing_link_inner(struct dl_hashtbl_s *dl_hashtbl,\n                                    void **link, const void *obj,\n                                    const char *tbl_log_name)\n{\n  struct disappearing_link *curr_dl;\n  size_t index;\n  struct disappearing_link *new_dl;\n\n  GC_ASSERT(GC_is_initialized);\n  if (EXPECT(GC_find_leak, FALSE))\n    return GC_UNIMPLEMENTED;\n#  ifdef GC_ASSERTIONS\n  GC_noop1_ptr(*link); /* check accessibility */\n#  endif\n  LOCK();\n  GC_ASSERT(obj != NULL && GC_base_C(obj) == obj);\n  if (EXPECT(NULL == dl_hashtbl->head, FALSE)\n      || EXPECT(dl_hashtbl->entries > ((size_t)1 << dl_hashtbl->log_size),\n                FALSE)) {\n    GC_grow_table((struct hash_chain_entry ***)&dl_hashtbl->head,\n                  &dl_hashtbl->log_size, &dl_hashtbl->entries);\n    GC_COND_LOG_PRINTF(\"Grew %s table to %u entries\\n\", tbl_log_name,\n                       1U << dl_hashtbl->log_size);\n  }\n  index = HASH2(link, dl_hashtbl->log_size);\n  for (curr_dl = dl_hashtbl->head[index]; curr_dl != 0;\n       curr_dl = dl_next(curr_dl)) {\n    if (curr_dl->dl_hidden_link == GC_HIDE_POINTER(link)) {\n      /* Alternatively, GC_HIDE_NZ_POINTER() could be used instead. */\n      curr_dl->dl_hidden_obj = GC_HIDE_POINTER(obj);\n      UNLOCK();\n      return GC_DUPLICATE;\n    }\n  }\n  new_dl = (struct disappearing_link *)GC_INTERNAL_MALLOC(\n      sizeof(struct disappearing_link), NORMAL);\n  if (EXPECT(NULL == new_dl, FALSE)) {\n    GC_oom_func oom_fn = GC_oom_fn;\n    UNLOCK();\n    new_dl = (struct disappearing_link *)(*oom_fn)(\n        sizeof(struct disappearing_link));\n    if (0 == new_dl) {\n      return GC_NO_MEMORY;\n    }\n    /* It's not likely we'll make it here, but ... */\n    LOCK();\n    /* Recalculate index since the table may grow.    */\n    index = HASH2(link, dl_hashtbl->log_size);\n    /* Check again that our disappearing link not in the table. */\n    for (curr_dl = dl_hashtbl->head[index]; curr_dl != 0;\n         curr_dl = dl_next(curr_dl)) {\n      if (curr_dl->dl_hidden_link == GC_HIDE_POINTER(link)) {\n        curr_dl->dl_hidden_obj = GC_HIDE_POINTER(obj);\n        UNLOCK();\n#  ifndef DBG_HDRS_ALL\n        /* Free unused new_dl returned by GC_oom_fn().      */\n        GC_free(new_dl);\n#  endif\n        return GC_DUPLICATE;\n      }\n    }\n  }\n  new_dl->dl_hidden_obj = GC_HIDE_POINTER(obj);\n  new_dl->dl_hidden_link = GC_HIDE_POINTER(link);\n  dl_set_next(new_dl, dl_hashtbl->head[index]);\n  GC_dirty(new_dl);\n  dl_hashtbl->head[index] = new_dl;\n  dl_hashtbl->entries++;\n  GC_dirty(dl_hashtbl->head + index);\n  UNLOCK();\n  return GC_SUCCESS;\n}\n\nGC_API int GC_CALL\nGC_general_register_disappearing_link(void **link, const void *obj)\n{\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0 || !NONNULL_ARG_NOT_NULL(link))\n    ABORT(\"Bad arg to GC_general_register_disappearing_link\");\n  return GC_register_disappearing_link_inner(&GC_dl_hashtbl, link, obj, \"dl\");\n}\n\n#  ifdef DBG_HDRS_ALL\n#    define FREE_DL_ENTRY(curr_dl) dl_set_next(curr_dl, NULL)\n#  else\n#    define FREE_DL_ENTRY(curr_dl) GC_free(curr_dl)\n#  endif\n\n/* Unregisters given link and returns the link entry to free.   */\nGC_INLINE struct disappearing_link *\nGC_unregister_disappearing_link_inner(struct dl_hashtbl_s *dl_hashtbl,\n                                      void **link)\n{\n  struct disappearing_link *curr_dl;\n  struct disappearing_link *prev_dl = NULL;\n  size_t index;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (EXPECT(NULL == dl_hashtbl->head, FALSE))\n    return NULL;\n\n  index = HASH2(link, dl_hashtbl->log_size);\n  for (curr_dl = dl_hashtbl->head[index]; curr_dl;\n       curr_dl = dl_next(curr_dl)) {\n    if (curr_dl->dl_hidden_link == GC_HIDE_POINTER(link)) {\n      /* Remove found entry from the table. */\n      if (NULL == prev_dl) {\n        dl_hashtbl->head[index] = dl_next(curr_dl);\n        GC_dirty(dl_hashtbl->head + index);\n      } else {\n        dl_set_next(prev_dl, dl_next(curr_dl));\n        GC_dirty(prev_dl);\n      }\n      dl_hashtbl->entries--;\n      break;\n    }\n    prev_dl = curr_dl;\n  }\n  return curr_dl;\n}\n\nGC_API int GC_CALL\nGC_unregister_disappearing_link(void **link)\n{\n  struct disappearing_link *curr_dl;\n\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0) {\n    /* Nothing to do. */\n    return 0;\n  }\n\n  LOCK();\n  curr_dl = GC_unregister_disappearing_link_inner(&GC_dl_hashtbl, link);\n  UNLOCK();\n  if (NULL == curr_dl)\n    return 0;\n  FREE_DL_ENTRY(curr_dl);\n  return 1;\n}\n\n/* Mark from one finalizable object using the specified mark proc.      */\n/* May not mark the object pointed to by real_ptr (i.e, it is the job   */\n/* of the caller, if appropriate).  Note that this is called with the   */\n/* mutator running.  This is safe only if the mutator (client) gets     */\n/* the allocator lock to reveal hidden pointers.                        */\nGC_INLINE void\nGC_mark_fo(ptr_t real_ptr, finalization_mark_proc fo_mark_proc)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  fo_mark_proc(real_ptr);\n  /* Process objects pushed by the mark procedure.      */\n  while (!GC_mark_stack_empty())\n    MARK_FROM_MARK_STACK();\n}\n\n/* Complete a collection in progress, if any.   */\nGC_INLINE void\nGC_complete_ongoing_collection(void)\n{\n  if (EXPECT(GC_collection_in_progress(), FALSE)) {\n    while (!GC_mark_some(NULL)) { /* empty */\n    }\n  }\n}\n\n/* Toggle-ref support.  */\n#  ifndef GC_TOGGLE_REFS_NOT_NEEDED\ntypedef union toggle_ref_u GCToggleRef;\n\nSTATIC GC_toggleref_func GC_toggleref_callback = 0;\n\nGC_INNER void\nGC_process_togglerefs(void)\n{\n  size_t i;\n  size_t new_size = 0;\n  GC_bool needs_barrier = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < GC_toggleref_array_size; ++i) {\n    GCToggleRef *r = &GC_toggleref_arr[i];\n    void *obj = r->strong_ref;\n\n    if ((ADDR(obj) & 1) != 0) {\n      obj = GC_REVEAL_POINTER(r->weak_ref);\n      GC_ASSERT((ADDR(obj) & 1) == 0);\n    }\n    if (NULL == obj)\n      continue;\n\n    switch (GC_toggleref_callback(obj)) {\n    case GC_TOGGLE_REF_DROP:\n      break;\n    case GC_TOGGLE_REF_STRONG:\n      GC_toggleref_arr[new_size++].strong_ref = obj;\n      needs_barrier = TRUE;\n      break;\n    case GC_TOGGLE_REF_WEAK:\n      GC_toggleref_arr[new_size++].weak_ref = GC_HIDE_POINTER(obj);\n      break;\n    default:\n      ABORT(\"Bad toggle-ref status returned by callback\");\n    }\n  }\n\n  if (new_size < GC_toggleref_array_size) {\n    BZERO(&GC_toggleref_arr[new_size],\n          (GC_toggleref_array_size - new_size) * sizeof(GCToggleRef));\n    GC_toggleref_array_size = new_size;\n  }\n  if (needs_barrier)\n    GC_dirty(GC_toggleref_arr); /* entire object */\n}\n\nSTATIC void GC_normal_finalize_mark_proc(ptr_t);\n\nSTATIC void\nGC_mark_togglerefs(void)\n{\n  size_t i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == GC_toggleref_arr)\n    return;\n\n  GC_set_mark_bit(GC_toggleref_arr);\n  for (i = 0; i < GC_toggleref_array_size; ++i) {\n    void *obj = GC_toggleref_arr[i].strong_ref;\n    if (obj != NULL && (ADDR(obj) & 1) == 0) {\n      /* Push and mark the object.    */\n      GC_mark_fo((ptr_t)obj, GC_normal_finalize_mark_proc);\n      GC_set_mark_bit(obj);\n      GC_complete_ongoing_collection();\n    }\n  }\n}\n\nSTATIC void\nGC_clear_togglerefs(void)\n{\n  size_t i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < GC_toggleref_array_size; ++i) {\n    GCToggleRef *r = &GC_toggleref_arr[i];\n\n    if ((ADDR(r->strong_ref) & 1) != 0) {\n      if (!GC_is_marked(GC_REVEAL_POINTER(r->weak_ref))) {\n        r->weak_ref = 0;\n      } else {\n        /* No need to copy, BDWGC is a non-moving collector.    */\n      }\n    }\n  }\n}\n\nGC_API void GC_CALL\nGC_set_toggleref_func(GC_toggleref_func fn)\n{\n  LOCK();\n  GC_toggleref_callback = fn;\n  UNLOCK();\n}\n\nGC_API GC_toggleref_func GC_CALL\nGC_get_toggleref_func(void)\n{\n  GC_toggleref_func fn;\n\n  READER_LOCK();\n  fn = GC_toggleref_callback;\n  READER_UNLOCK();\n  return fn;\n}\n\nstatic GC_bool\nensure_toggleref_capacity(size_t capacity_inc)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == GC_toggleref_arr) {\n    GC_toggleref_array_capacity = 32; /* initial capacity */\n    GC_toggleref_arr = (GCToggleRef *)GC_INTERNAL_MALLOC_IGNORE_OFF_PAGE(\n        GC_toggleref_array_capacity * sizeof(GCToggleRef), NORMAL);\n    if (NULL == GC_toggleref_arr)\n      return FALSE;\n  }\n  if (GC_toggleref_array_size + capacity_inc >= GC_toggleref_array_capacity) {\n    GCToggleRef *new_array;\n    while (GC_toggleref_array_capacity\n           < GC_toggleref_array_size + capacity_inc) {\n      GC_toggleref_array_capacity *= 2;\n      if ((GC_toggleref_array_capacity\n           & ((size_t)1 << (sizeof(size_t) * 8 - 1)))\n          != 0)\n        return FALSE; /* overflow */\n    }\n\n    new_array = (GCToggleRef *)GC_INTERNAL_MALLOC_IGNORE_OFF_PAGE(\n        GC_toggleref_array_capacity * sizeof(GCToggleRef), NORMAL);\n    if (NULL == new_array)\n      return FALSE;\n    if (EXPECT(GC_toggleref_array_size > 0, TRUE))\n      BCOPY(GC_toggleref_arr, new_array,\n            GC_toggleref_array_size * sizeof(GCToggleRef));\n    GC_INTERNAL_FREE(GC_toggleref_arr);\n    GC_toggleref_arr = new_array;\n  }\n  return TRUE;\n}\n\nGC_API int GC_CALL\nGC_toggleref_add(void *obj, int is_strong_ref)\n{\n  int res = GC_SUCCESS;\n\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(obj));\n  LOCK();\n  GC_ASSERT((ADDR(obj) & 1) == 0 && obj == GC_base(obj));\n  if (GC_toggleref_callback != 0) {\n    if (!ensure_toggleref_capacity(1)) {\n      res = GC_NO_MEMORY;\n    } else {\n      GCToggleRef *r = &GC_toggleref_arr[GC_toggleref_array_size];\n\n      if (is_strong_ref) {\n        r->strong_ref = obj;\n        GC_dirty(GC_toggleref_arr + GC_toggleref_array_size);\n      } else {\n        r->weak_ref = GC_HIDE_POINTER(obj);\n        GC_ASSERT((r->weak_ref & 1) != 0);\n      }\n      GC_toggleref_array_size++;\n    }\n  }\n  UNLOCK();\n  return res;\n}\n#  endif /* !GC_TOGGLE_REFS_NOT_NEEDED */\n\n/* Finalizer callback support. */\nSTATIC GC_await_finalize_proc GC_object_finalized_proc = 0;\n\nGC_API void GC_CALL\nGC_set_await_finalize_proc(GC_await_finalize_proc fn)\n{\n  LOCK();\n  GC_object_finalized_proc = fn;\n  UNLOCK();\n}\n\nGC_API GC_await_finalize_proc GC_CALL\nGC_get_await_finalize_proc(void)\n{\n  GC_await_finalize_proc fn;\n\n  READER_LOCK();\n  fn = GC_object_finalized_proc;\n  READER_UNLOCK();\n  return fn;\n}\n\n#  ifndef GC_LONG_REFS_NOT_NEEDED\nGC_API int GC_CALL\nGC_register_long_link(void **link, const void *obj)\n{\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0 || !NONNULL_ARG_NOT_NULL(link))\n    ABORT(\"Bad arg to GC_register_long_link\");\n  return GC_register_disappearing_link_inner(&GC_ll_hashtbl, link, obj,\n                                             \"long dl\");\n}\n\nGC_API int GC_CALL\nGC_unregister_long_link(void **link)\n{\n  struct disappearing_link *curr_dl;\n\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0) {\n    /* Nothing to do. */\n    return 0;\n  }\n  LOCK();\n  curr_dl = GC_unregister_disappearing_link_inner(&GC_ll_hashtbl, link);\n  UNLOCK();\n  if (NULL == curr_dl)\n    return 0;\n  FREE_DL_ENTRY(curr_dl);\n  return 1;\n}\n#  endif /* !GC_LONG_REFS_NOT_NEEDED */\n\n#  ifndef GC_MOVE_DISAPPEARING_LINK_NOT_NEEDED\nSTATIC int\nGC_move_disappearing_link_inner(struct dl_hashtbl_s *dl_hashtbl, void **link,\n                                void **new_link)\n{\n  struct disappearing_link *curr_dl, *new_dl;\n  struct disappearing_link *prev_dl = NULL;\n  size_t curr_index, new_index;\n  GC_hidden_pointer curr_hidden_link, new_hidden_link;\n\n#    ifdef GC_ASSERTIONS\n  GC_noop1_ptr(*new_link);\n#    endif\n  GC_ASSERT(I_HOLD_LOCK());\n  if (EXPECT(NULL == dl_hashtbl->head, FALSE))\n    return GC_NOT_FOUND;\n\n  /* Find current link.       */\n  curr_index = HASH2(link, dl_hashtbl->log_size);\n  curr_hidden_link = GC_HIDE_POINTER(link);\n  for (curr_dl = dl_hashtbl->head[curr_index]; curr_dl;\n       curr_dl = dl_next(curr_dl)) {\n    if (curr_dl->dl_hidden_link == curr_hidden_link)\n      break;\n    prev_dl = curr_dl;\n  }\n  if (EXPECT(NULL == curr_dl, FALSE)) {\n    return GC_NOT_FOUND;\n  } else if (link == new_link) {\n    /* Nothing to do. */\n    return GC_SUCCESS;\n  }\n\n  /* link is found; now check new_link not present.   */\n  new_index = HASH2(new_link, dl_hashtbl->log_size);\n  new_hidden_link = GC_HIDE_POINTER(new_link);\n  for (new_dl = dl_hashtbl->head[new_index]; new_dl;\n       new_dl = dl_next(new_dl)) {\n    if (new_dl->dl_hidden_link == new_hidden_link) {\n      /* Target already registered; bail out. */\n      return GC_DUPLICATE;\n    }\n  }\n\n  /* Remove from old, add to new, update link.        */\n  if (NULL == prev_dl) {\n    dl_hashtbl->head[curr_index] = dl_next(curr_dl);\n  } else {\n    dl_set_next(prev_dl, dl_next(curr_dl));\n    GC_dirty(prev_dl);\n  }\n  curr_dl->dl_hidden_link = new_hidden_link;\n  dl_set_next(curr_dl, dl_hashtbl->head[new_index]);\n  dl_hashtbl->head[new_index] = curr_dl;\n  GC_dirty(curr_dl);\n  GC_dirty(dl_hashtbl->head); /* entire object */\n  return GC_SUCCESS;\n}\n\nGC_API int GC_CALL\nGC_move_disappearing_link(void **link, void **new_link)\n{\n  int result;\n\n  if ((ADDR(new_link) & (ALIGNMENT - 1)) != 0\n      || !NONNULL_ARG_NOT_NULL(new_link))\n    ABORT(\"Bad new_link arg to GC_move_disappearing_link\");\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0) {\n    /* Nothing to do. */\n    return GC_NOT_FOUND;\n  }\n  LOCK();\n  result = GC_move_disappearing_link_inner(&GC_dl_hashtbl, link, new_link);\n  UNLOCK();\n  return result;\n}\n\n#    ifndef GC_LONG_REFS_NOT_NEEDED\nGC_API int GC_CALL\nGC_move_long_link(void **link, void **new_link)\n{\n  int result;\n\n  if ((ADDR(new_link) & (ALIGNMENT - 1)) != 0\n      || !NONNULL_ARG_NOT_NULL(new_link))\n    ABORT(\"Bad new_link arg to GC_move_long_link\");\n  if ((ADDR(link) & (ALIGNMENT - 1)) != 0) {\n    /* Nothing to do.       */\n    return GC_NOT_FOUND;\n  }\n  LOCK();\n  result = GC_move_disappearing_link_inner(&GC_ll_hashtbl, link, new_link);\n  UNLOCK();\n  return result;\n}\n#    endif\n#  endif /* !GC_MOVE_DISAPPEARING_LINK_NOT_NEEDED */\n\n/* Possible finalization_marker procedures.  Note that mark stack       */\n/* overflow is handled by the caller, and is not a disaster.            */\n#  if defined(_MSC_VER) && defined(I386)\nGC_ATTR_NOINLINE\n/* Otherwise some optimizer bug is tickled in VC for x86 (v19, at least). */\n#  endif\nSTATIC void\nGC_normal_finalize_mark_proc(ptr_t p)\n{\n  GC_mark_stack_top = GC_push_obj(p, HDR(p), GC_mark_stack_top,\n                                  GC_mark_stack + GC_mark_stack_size);\n}\n\n/* This only pays very partial attention to the mark descriptor.        */\n/* It does the right thing for normal and atomic objects, and treats    */\n/* most others as normal.                                               */\nSTATIC void\nGC_ignore_self_finalize_mark_proc(ptr_t p)\n{\n  const hdr *hhdr = HDR(p);\n  word descr = hhdr->hb_descr;\n  ptr_t current_p;\n  ptr_t scan_limit;\n  ptr_t target_limit = p + hhdr->hb_sz - 1;\n\n  if ((descr & GC_DS_TAGS) == GC_DS_LENGTH) {\n    scan_limit = p + descr - sizeof(ptr_t);\n  } else {\n    scan_limit = target_limit + 1 - sizeof(ptr_t);\n  }\n  for (current_p = p; ADDR_GE(scan_limit, current_p); current_p += ALIGNMENT) {\n    ptr_t q;\n\n    LOAD_PTR_OR_CONTINUE(q, current_p);\n    if (ADDR_LT(q, p) || ADDR_LT(target_limit, q)) {\n      GC_PUSH_ONE_HEAP(q, current_p, GC_mark_stack_top);\n    }\n  }\n}\n\nSTATIC void\nGC_null_finalize_mark_proc(ptr_t p)\n{\n  UNUSED_ARG(p);\n}\n\n/* Possible finalization_marker procedures.  Note that mark stack       */\n/* overflow is handled by the caller, and is not a disaster.            */\n\n/* GC_unreachable_finalize_mark_proc is an alias for normal marking,    */\n/* but it is explicitly tested for, and triggers different              */\n/* behavior.  Objects registered in this way are not finalized          */\n/* if they are reachable by other finalizable objects, even if those    */\n/* other objects specify no ordering.                                   */\nSTATIC void\nGC_unreachable_finalize_mark_proc(ptr_t p)\n{\n  /* A dummy comparison to ensure the compiler not to optimize two    */\n  /* identical functions into a single one (thus, to ensure a unique  */\n  /* address of each).  Alternatively, GC_noop1_ptr(p) could be used. */\n  if (EXPECT(NULL == p, FALSE))\n    return;\n\n  GC_normal_finalize_mark_proc(p);\n}\n\n/* Avoid the work if unreachable finalizable objects are not used.      */\n/* TODO: turn need_unreachable_finalization into a counter */\nstatic GC_bool need_unreachable_finalization = FALSE;\n\n/* Register a finalization function.  See gc.h for details.     */\n/* The last parameter is a procedure that determines            */\n/* marking for finalization ordering.  Any objects marked       */\n/* by that procedure will be guaranteed to not have been        */\n/* finalized when this finalizer is invoked.                    */\nSTATIC void\nGC_register_finalizer_inner(void *obj, GC_finalization_proc fn, void *cd,\n                            GC_finalization_proc *ofn, void **ocd,\n                            finalization_mark_proc mp)\n{\n  struct finalizable_object *curr_fo;\n  size_t index;\n  struct finalizable_object *new_fo = 0;\n  const hdr *hhdr = NULL; /* initialized to prevent warning. */\n\n  GC_ASSERT(GC_is_initialized);\n  if (EXPECT(GC_find_leak, FALSE)) {\n    /* No-op.  *ocd and *ofn remain unchanged.    */\n    return;\n  }\n  LOCK();\n  GC_ASSERT(obj != NULL && GC_base_C(obj) == obj);\n  if (mp == GC_unreachable_finalize_mark_proc)\n    need_unreachable_finalization = TRUE;\n  if (EXPECT(NULL == GC_fnlz_roots.fo_head, FALSE)\n      || EXPECT(GC_fo_entries > ((size_t)1 << GC_log_fo_table_size), FALSE)) {\n    GC_grow_table((struct hash_chain_entry ***)&GC_fnlz_roots.fo_head,\n                  &GC_log_fo_table_size, &GC_fo_entries);\n    GC_COND_LOG_PRINTF(\"Grew fo table to %u entries\\n\",\n                       1U << GC_log_fo_table_size);\n  }\n  for (;;) {\n    struct finalizable_object *prev_fo = NULL;\n    GC_oom_func oom_fn;\n\n    index = HASH2(obj, GC_log_fo_table_size);\n    curr_fo = GC_fnlz_roots.fo_head[index];\n    while (curr_fo != NULL) {\n      GC_ASSERT(GC_size(curr_fo) >= sizeof(struct finalizable_object));\n      if (curr_fo->fo_hidden_base == GC_HIDE_POINTER(obj)) {\n        /* Interruption by a signal in the middle of this     */\n        /* should be safe.  The client may see only *ocd      */\n        /* updated, but we'll declare that to be his problem. */\n        if (ocd)\n          *ocd = curr_fo->fo_client_data;\n        if (ofn)\n          *ofn = curr_fo->fo_fn;\n        /* Delete the structure for obj.      */\n        if (prev_fo == 0) {\n          GC_fnlz_roots.fo_head[index] = fo_next(curr_fo);\n        } else {\n          fo_set_next(prev_fo, fo_next(curr_fo));\n          GC_dirty(prev_fo);\n        }\n        if (fn == 0) {\n          GC_fo_entries--;\n          /* May not happen if we get a signal.  But a high   */\n          /* estimate will only make the table larger than    */\n          /* necessary.                                       */\n#  if !defined(THREADS) && !defined(DBG_HDRS_ALL)\n          GC_free(curr_fo);\n#  endif\n        } else {\n          curr_fo->fo_fn = fn;\n          curr_fo->fo_client_data = (ptr_t)cd;\n          curr_fo->fo_mark_proc = mp;\n          GC_dirty(curr_fo);\n          /* Reinsert it.  We deleted it first to maintain    */\n          /* consistency in the event of a signal.            */\n          if (prev_fo == 0) {\n            GC_fnlz_roots.fo_head[index] = curr_fo;\n          } else {\n            fo_set_next(prev_fo, curr_fo);\n            GC_dirty(prev_fo);\n          }\n        }\n        if (NULL == prev_fo)\n          GC_dirty(GC_fnlz_roots.fo_head + index);\n        UNLOCK();\n#  ifndef DBG_HDRS_ALL\n        /* Free unused new_fo returned by GC_oom_fn() */\n        GC_free(new_fo);\n#  endif\n        return;\n      }\n      prev_fo = curr_fo;\n      curr_fo = fo_next(curr_fo);\n    }\n    if (EXPECT(new_fo != 0, FALSE)) {\n      /* new_fo is returned by GC_oom_fn().   */\n      GC_ASSERT(fn != 0);\n#  ifdef LINT2\n      if (NULL == hhdr)\n        ABORT(\"Bad hhdr in GC_register_finalizer_inner\");\n#  endif\n      break;\n    }\n    if (fn == 0) {\n      if (ocd)\n        *ocd = 0;\n      if (ofn)\n        *ofn = 0;\n      UNLOCK();\n      return;\n    }\n    GET_HDR(obj, hhdr);\n    if (EXPECT(NULL == hhdr, FALSE)) {\n      /* We won't collect it, hence finalizer wouldn't be run. */\n      if (ocd)\n        *ocd = 0;\n      if (ofn)\n        *ofn = 0;\n      UNLOCK();\n      return;\n    }\n    new_fo = (struct finalizable_object *)GC_INTERNAL_MALLOC(\n        sizeof(struct finalizable_object), NORMAL);\n    if (EXPECT(new_fo != 0, TRUE))\n      break;\n    oom_fn = GC_oom_fn;\n    UNLOCK();\n    new_fo = (struct finalizable_object *)(*oom_fn)(\n        sizeof(struct finalizable_object));\n    if (0 == new_fo) {\n      /* No enough memory.  *ocd and *ofn remain unchanged.   */\n      return;\n    }\n    /* It's not likely we'll make it here, but ... */\n    LOCK();\n    /* Recalculate index since the table may grow and         */\n    /* check again that our finalizer is not in the table.    */\n  }\n  GC_ASSERT(GC_size(new_fo) >= sizeof(struct finalizable_object));\n  if (ocd)\n    *ocd = 0;\n  if (ofn)\n    *ofn = 0;\n  new_fo->fo_hidden_base = GC_HIDE_POINTER(obj);\n  new_fo->fo_fn = fn;\n  new_fo->fo_client_data = (ptr_t)cd;\n  new_fo->fo_object_sz = hhdr->hb_sz;\n  new_fo->fo_mark_proc = mp;\n  fo_set_next(new_fo, GC_fnlz_roots.fo_head[index]);\n  GC_dirty(new_fo);\n  GC_fo_entries++;\n  GC_fnlz_roots.fo_head[index] = new_fo;\n  GC_dirty(GC_fnlz_roots.fo_head + index);\n  UNLOCK();\n}\n\nGC_API void GC_CALL\nGC_register_finalizer(void *obj, GC_finalization_proc fn, void *cd,\n                      GC_finalization_proc *ofn, void **ocd)\n{\n  GC_register_finalizer_inner(obj, fn, cd, ofn, ocd,\n                              GC_normal_finalize_mark_proc);\n}\n\nGC_API void GC_CALL\nGC_register_finalizer_ignore_self(void *obj, GC_finalization_proc fn, void *cd,\n                                  GC_finalization_proc *ofn, void **ocd)\n{\n  GC_register_finalizer_inner(obj, fn, cd, ofn, ocd,\n                              GC_ignore_self_finalize_mark_proc);\n}\n\nGC_API void GC_CALL\nGC_register_finalizer_no_order(void *obj, GC_finalization_proc fn, void *cd,\n                               GC_finalization_proc *ofn, void **ocd)\n{\n  GC_register_finalizer_inner(obj, fn, cd, ofn, ocd,\n                              GC_null_finalize_mark_proc);\n}\n\nGC_API void GC_CALL\nGC_register_finalizer_unreachable(void *obj, GC_finalization_proc fn, void *cd,\n                                  GC_finalization_proc *ofn, void **ocd)\n{\n  GC_ASSERT(GC_java_finalization);\n  GC_register_finalizer_inner(obj, fn, cd, ofn, ocd,\n                              GC_unreachable_finalize_mark_proc);\n}\n\n#  ifndef NO_DEBUGGING\nSTATIC void\nGC_dump_finalization_links(const struct dl_hashtbl_s *dl_hashtbl)\n{\n  size_t dl_size = (size_t)1 << dl_hashtbl->log_size;\n  size_t i;\n\n  if (NULL == dl_hashtbl->head) {\n    /* The table is empty.    */\n    return;\n  }\n\n  for (i = 0; i < dl_size; i++) {\n    struct disappearing_link *curr_dl;\n\n    for (curr_dl = dl_hashtbl->head[i]; curr_dl != 0;\n         curr_dl = dl_next(curr_dl)) {\n      ptr_t real_ptr = (ptr_t)GC_REVEAL_POINTER(curr_dl->dl_hidden_obj);\n      ptr_t real_link = (ptr_t)GC_REVEAL_POINTER(curr_dl->dl_hidden_link);\n\n      GC_printf(\"Object: %p, link value: %p, link addr: %p\\n\",\n                (void *)real_ptr, *(void **)real_link, (void *)real_link);\n    }\n  }\n}\n\nGC_API void GC_CALL\nGC_dump_finalization(void)\n{\n  struct finalizable_object *curr_fo;\n  size_t i;\n  size_t fo_size\n      = GC_fnlz_roots.fo_head == NULL ? 0 : (size_t)1 << GC_log_fo_table_size;\n\n  GC_printf(\"\\n***Disappearing (short) links:\\n\");\n  GC_dump_finalization_links(&GC_dl_hashtbl);\n#    ifndef GC_LONG_REFS_NOT_NEEDED\n  GC_printf(\"\\n***Disappearing long links:\\n\");\n  GC_dump_finalization_links(&GC_ll_hashtbl);\n#    endif\n  GC_printf(\"\\n***Finalizers:\\n\");\n  for (i = 0; i < fo_size; i++) {\n    for (curr_fo = GC_fnlz_roots.fo_head[i]; curr_fo != NULL;\n         curr_fo = fo_next(curr_fo)) {\n      ptr_t real_ptr = (ptr_t)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n\n      GC_printf(\"Finalizable object: %p\\n\", (void *)real_ptr);\n    }\n  }\n}\n#  endif /* !NO_DEBUGGING */\n\n#  ifndef SMALL_CONFIG\nSTATIC size_t GC_old_dl_entries = 0; /* for stats printing */\n#    ifndef GC_LONG_REFS_NOT_NEEDED\nSTATIC size_t GC_old_ll_entries = 0;\n#    endif\n#  endif /* !SMALL_CONFIG */\n\n#  ifndef THREADS\n/* Checks and updates the level of finalizers recursion.              */\n/* Returns NULL if GC_invoke_finalizers() should not be called by the */\n/* collector (to minimize the risk of a deep finalizers recursion),   */\n/* otherwise returns a pointer to GC_finalizer_nested.                */\nSTATIC unsigned char *\nGC_check_finalizer_nested(void)\n{\n  unsigned nesting_level = GC_finalizer_nested;\n  if (nesting_level) {\n    /* We are inside another GC_invoke_finalizers().          */\n    /* Skip some implicitly-called GC_invoke_finalizers()     */\n    /* depending on the nesting (recursion) level.            */\n    if ((unsigned)(++GC_finalizer_skipped) < (1U << nesting_level))\n      return NULL;\n    GC_finalizer_skipped = 0;\n  }\n  GC_finalizer_nested = (unsigned char)(nesting_level + 1);\n  return &GC_finalizer_nested;\n}\n#  endif /* !THREADS */\n\nGC_INLINE void\nGC_make_disappearing_links_disappear(struct dl_hashtbl_s *dl_hashtbl,\n                                     GC_bool is_remove_dangling)\n{\n  size_t i;\n  size_t dl_size = (size_t)1 << dl_hashtbl->log_size;\n  GC_bool needs_barrier = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == dl_hashtbl->head) {\n    /* The table is empty.      */\n    return;\n  }\n\n  for (i = 0; i < dl_size; i++) {\n    struct disappearing_link *curr_dl, *next_dl;\n    struct disappearing_link *prev_dl = NULL;\n\n    for (curr_dl = dl_hashtbl->head[i]; curr_dl != NULL; curr_dl = next_dl) {\n      next_dl = dl_next(curr_dl);\n#  if defined(GC_ASSERTIONS) && !defined(THREAD_SANITIZER)\n      /* Check accessibility of the location pointed by link. */\n      GC_noop1_ptr(*(ptr_t *)GC_REVEAL_POINTER(curr_dl->dl_hidden_link));\n#  endif\n      if (is_remove_dangling) {\n        ptr_t real_link\n            = (ptr_t)GC_base(GC_REVEAL_POINTER(curr_dl->dl_hidden_link));\n\n        if (NULL == real_link || EXPECT(GC_is_marked(real_link), TRUE)) {\n          prev_dl = curr_dl;\n          continue;\n        }\n      } else {\n        if (EXPECT(\n                GC_is_marked((ptr_t)GC_REVEAL_POINTER(curr_dl->dl_hidden_obj)),\n                TRUE)) {\n          prev_dl = curr_dl;\n          continue;\n        }\n        *(ptr_t *)GC_REVEAL_POINTER(curr_dl->dl_hidden_link) = NULL;\n      }\n\n      /* Delete curr_dl entry from dl_hashtbl.  */\n      if (NULL == prev_dl) {\n        dl_hashtbl->head[i] = next_dl;\n        needs_barrier = TRUE;\n      } else {\n        dl_set_next(prev_dl, next_dl);\n        GC_dirty(prev_dl);\n      }\n      GC_clear_mark_bit(curr_dl);\n      dl_hashtbl->entries--;\n    }\n  }\n  if (needs_barrier)\n    GC_dirty(dl_hashtbl->head); /* entire object */\n}\n\n/* Cause disappearing links to disappear and unreachable objects to be  */\n/* enqueued for finalization.  Called with the world running.           */\nGC_INNER void\nGC_finalize(void)\n{\n  struct finalizable_object *curr_fo, *prev_fo, *next_fo;\n  ptr_t real_ptr;\n  size_t i;\n  size_t fo_size\n      = GC_fnlz_roots.fo_head == NULL ? 0 : (size_t)1 << GC_log_fo_table_size;\n  GC_bool needs_barrier = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifndef SMALL_CONFIG\n  /* Save current GC_[dl/ll]_entries value for stats printing.      */\n  GC_old_dl_entries = GC_dl_hashtbl.entries;\n#    ifndef GC_LONG_REFS_NOT_NEEDED\n  GC_old_ll_entries = GC_ll_hashtbl.entries;\n#    endif\n#  endif\n\n#  ifndef GC_TOGGLE_REFS_NOT_NEEDED\n  GC_mark_togglerefs();\n#  endif\n  GC_make_disappearing_links_disappear(&GC_dl_hashtbl, FALSE);\n\n  /* Mark all objects reachable via chains of 1 or more pointers        */\n  /* from finalizable objects.                                          */\n  GC_ASSERT(!GC_collection_in_progress());\n  for (i = 0; i < fo_size; i++) {\n    for (curr_fo = GC_fnlz_roots.fo_head[i]; curr_fo != NULL;\n         curr_fo = fo_next(curr_fo)) {\n      GC_ASSERT(GC_size(curr_fo) >= sizeof(struct finalizable_object));\n      real_ptr = (ptr_t)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n      if (!GC_is_marked(real_ptr)) {\n        GC_MARKED_FOR_FINALIZATION(real_ptr);\n        GC_mark_fo(real_ptr, curr_fo->fo_mark_proc);\n        if (GC_is_marked(real_ptr)) {\n          WARN(\"Finalization cycle involving %p\\n\", real_ptr);\n        }\n      }\n    }\n  }\n  /* Enqueue for finalization all objects that are still                */\n  /* unreachable.                                                       */\n  GC_bytes_finalized = 0;\n  for (i = 0; i < fo_size; i++) {\n    curr_fo = GC_fnlz_roots.fo_head[i];\n    prev_fo = NULL;\n    while (curr_fo != NULL) {\n      real_ptr = (ptr_t)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n      if (!GC_is_marked(real_ptr)) {\n        if (!GC_java_finalization) {\n          GC_set_mark_bit(real_ptr);\n        }\n        /* Delete from hash table.  */\n        next_fo = fo_next(curr_fo);\n        if (NULL == prev_fo) {\n          GC_fnlz_roots.fo_head[i] = next_fo;\n          if (GC_object_finalized_proc) {\n            GC_dirty(GC_fnlz_roots.fo_head + i);\n          } else {\n            needs_barrier = TRUE;\n          }\n        } else {\n          fo_set_next(prev_fo, next_fo);\n          GC_dirty(prev_fo);\n        }\n        GC_fo_entries--;\n        if (GC_object_finalized_proc)\n          GC_object_finalized_proc(real_ptr);\n\n        /* Add to list of objects awaiting finalization.    */\n        fo_set_next(curr_fo, GC_fnlz_roots.finalize_now);\n        GC_dirty(curr_fo);\n        SET_FINALIZE_NOW(curr_fo);\n        /* Unhide object pointer so any future collections will   */\n        /* see it.                                                */\n        curr_fo->fo_hidden_base\n            = (GC_hidden_pointer)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n\n        GC_bytes_finalized\n            += (word)curr_fo->fo_object_sz + sizeof(struct finalizable_object);\n        GC_ASSERT(GC_is_marked(GC_base(curr_fo)));\n        curr_fo = next_fo;\n      } else {\n        prev_fo = curr_fo;\n        curr_fo = fo_next(curr_fo);\n      }\n    }\n  }\n\n  if (GC_java_finalization) {\n    /* Make sure we mark everything reachable from objects finalized  */\n    /* using the no-order fo_mark_proc.                               */\n    for (curr_fo = GC_fnlz_roots.finalize_now; curr_fo != NULL;\n         curr_fo = fo_next(curr_fo)) {\n      real_ptr = (ptr_t)curr_fo->fo_hidden_base; /* revealed */\n      if (!GC_is_marked(real_ptr)) {\n        if (curr_fo->fo_mark_proc == GC_null_finalize_mark_proc) {\n          GC_mark_fo(real_ptr, GC_normal_finalize_mark_proc);\n        }\n        if (curr_fo->fo_mark_proc != GC_unreachable_finalize_mark_proc) {\n          GC_set_mark_bit(real_ptr);\n        }\n      }\n    }\n\n    /* Now revive finalize-when-unreachable objects reachable from    */\n    /* other finalizable objects.                                     */\n    if (need_unreachable_finalization) {\n      curr_fo = GC_fnlz_roots.finalize_now;\n      GC_ASSERT(NULL == curr_fo || GC_fnlz_roots.fo_head != NULL);\n      for (prev_fo = NULL; curr_fo != NULL;\n           prev_fo = curr_fo, curr_fo = next_fo) {\n        next_fo = fo_next(curr_fo);\n        if (curr_fo->fo_mark_proc != GC_unreachable_finalize_mark_proc)\n          continue;\n\n        real_ptr = (ptr_t)curr_fo->fo_hidden_base; /* revealed */\n        if (!GC_is_marked(real_ptr)) {\n          GC_set_mark_bit(real_ptr);\n          continue;\n        }\n        if (NULL == prev_fo) {\n          SET_FINALIZE_NOW(next_fo);\n        } else {\n          fo_set_next(prev_fo, next_fo);\n          GC_dirty(prev_fo);\n        }\n        curr_fo->fo_hidden_base = GC_HIDE_POINTER(real_ptr);\n        GC_bytes_finalized\n            -= (word)curr_fo->fo_object_sz + sizeof(struct finalizable_object);\n\n        i = HASH2(real_ptr, GC_log_fo_table_size);\n        fo_set_next(curr_fo, GC_fnlz_roots.fo_head[i]);\n        GC_dirty(curr_fo);\n        GC_fo_entries++;\n        GC_fnlz_roots.fo_head[i] = curr_fo;\n        curr_fo = prev_fo;\n        needs_barrier = TRUE;\n      }\n    }\n  }\n  if (needs_barrier)\n    GC_dirty(GC_fnlz_roots.fo_head); /* entire object */\n\n  /* Remove dangling disappearing links. */\n  GC_make_disappearing_links_disappear(&GC_dl_hashtbl, TRUE);\n\n#  ifndef GC_TOGGLE_REFS_NOT_NEEDED\n  GC_clear_togglerefs();\n#  endif\n#  ifndef GC_LONG_REFS_NOT_NEEDED\n  GC_make_disappearing_links_disappear(&GC_ll_hashtbl, FALSE);\n  GC_make_disappearing_links_disappear(&GC_ll_hashtbl, TRUE);\n#  endif\n\n  if (GC_fail_count) {\n    /* Don't prevent running finalizers if there has been an allocation */\n    /* failure recently.                                                */\n#  ifdef THREADS\n    GC_reset_finalizer_nested();\n#  else\n    GC_finalizer_nested = 0;\n#  endif\n  }\n}\n\n/* Count of finalizers to run, at most, during a single invocation      */\n/* of GC_invoke_finalizers(); zero means no limit.  Accessed with the   */\n/* allocator lock held.                                                 */\nSTATIC unsigned GC_interrupt_finalizers = 0;\n\n#  ifndef JAVA_FINALIZATION_NOT_NEEDED\n\n/* Enqueue all remaining finalizers to be run.  A collection in       */\n/* progress, if any, is completed when the first finalizer is         */\n/* enqueued.                                                          */\nSTATIC void\nGC_enqueue_all_finalizers(void)\n{\n  size_t i;\n  size_t fo_size\n      = GC_fnlz_roots.fo_head == NULL ? 0 : (size_t)1 << GC_log_fo_table_size;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_bytes_finalized = 0;\n  for (i = 0; i < fo_size; i++) {\n    struct finalizable_object *curr_fo = GC_fnlz_roots.fo_head[i];\n\n    GC_fnlz_roots.fo_head[i] = NULL;\n    while (curr_fo != NULL) {\n      struct finalizable_object *next_fo;\n      ptr_t real_ptr = (ptr_t)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n\n      GC_mark_fo(real_ptr, GC_normal_finalize_mark_proc);\n      GC_set_mark_bit(real_ptr);\n      GC_complete_ongoing_collection();\n      next_fo = fo_next(curr_fo);\n\n      /* Add to list of objects awaiting finalization.      */\n      fo_set_next(curr_fo, GC_fnlz_roots.finalize_now);\n      GC_dirty(curr_fo);\n      SET_FINALIZE_NOW(curr_fo);\n\n      /* Unhide object pointer so any future collections will       */\n      /* see it.                                                    */\n      curr_fo->fo_hidden_base\n          = (GC_hidden_pointer)GC_REVEAL_POINTER(curr_fo->fo_hidden_base);\n      GC_bytes_finalized\n          += curr_fo->fo_object_sz + sizeof(struct finalizable_object);\n      curr_fo = next_fo;\n    }\n  }\n  /* All entries are deleted from the hash table.     */\n  GC_fo_entries = 0;\n}\n\n/* Invoke all remaining finalizers that haven't yet been run.\n * This is needed for strict compliance with the Java standard,\n * which can make the runtime guarantee that all finalizers are run.\n * Unfortunately, the Java standard implies we have to keep running\n * finalizers until there are no more left, a potential infinite loop.\n * YUCK.\n * Note that this is even more dangerous than the usual Java\n * finalizers, in that objects reachable from static variables\n * may have been finalized when these finalizers are run.\n * Finalizers run at this point must be prepared to deal with a\n * mostly broken world.\n */\nGC_API void GC_CALL\nGC_finalize_all(void)\n{\n  LOCK();\n  while (GC_fo_entries > 0) {\n    GC_enqueue_all_finalizers();\n    GC_interrupt_finalizers = 0; /* reset */\n    UNLOCK();\n    GC_invoke_finalizers();\n    /* Running the finalizers in this thread is arguably not a good   */\n    /* idea when we should be notifying another thread to run them.   */\n    /* But otherwise we don't have a great way to wait for them to    */\n    /* run.                                                           */\n    LOCK();\n  }\n  UNLOCK();\n}\n\n#  endif /* !JAVA_FINALIZATION_NOT_NEEDED */\n\nGC_API void GC_CALL\nGC_set_interrupt_finalizers(unsigned value)\n{\n  LOCK();\n  GC_interrupt_finalizers = value;\n  UNLOCK();\n}\n\nGC_API unsigned GC_CALL\nGC_get_interrupt_finalizers(void)\n{\n  unsigned value;\n\n  READER_LOCK();\n  value = GC_interrupt_finalizers;\n  READER_UNLOCK();\n  return value;\n}\n\n/* Returns true if it is worth calling GC_invoke_finalizers. (Useful if */\n/* finalizers can only be called from some kind of \"safe state\" and     */\n/* getting into that safe state is expensive.)                          */\nGC_API int GC_CALL\nGC_should_invoke_finalizers(void)\n{\n#  ifdef AO_HAVE_load\n  return GC_cptr_load((volatile ptr_t *)&GC_fnlz_roots.finalize_now) != NULL;\n#  else\n  return GC_fnlz_roots.finalize_now != NULL;\n#  endif /* !THREADS */\n}\n\n/* Invoke finalizers for all objects that are ready to be finalized.    */\nGC_API int GC_CALL\nGC_invoke_finalizers(void)\n{\n  int count = 0;\n  word bytes_freed_before = 0; /* initialized to prevent warning */\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  while (GC_should_invoke_finalizers()) {\n    struct finalizable_object *curr_fo;\n    ptr_t real_ptr;\n\n    LOCK();\n    if (count == 0) {\n      /* Note: we hold the allocator lock here.   */\n      bytes_freed_before = GC_bytes_freed;\n    } else if (EXPECT(GC_interrupt_finalizers != 0, FALSE)\n               && (unsigned)count >= GC_interrupt_finalizers) {\n      UNLOCK();\n      break;\n    }\n    curr_fo = GC_fnlz_roots.finalize_now;\n#  ifdef THREADS\n    if (EXPECT(NULL == curr_fo, FALSE)) {\n      UNLOCK();\n      break;\n    }\n#  endif\n    SET_FINALIZE_NOW(fo_next(curr_fo));\n    UNLOCK();\n    fo_set_next(curr_fo, 0);\n    real_ptr = (ptr_t)curr_fo->fo_hidden_base; /* revealed */\n    curr_fo->fo_fn(real_ptr, curr_fo->fo_client_data);\n    curr_fo->fo_client_data = NULL;\n    ++count;\n    /* Explicit freeing of curr_fo is probably a bad idea.  */\n    /* It throws off accounting if nearly all objects are   */\n    /* finalizable.  Otherwise it should not matter.        */\n  }\n  /* bytes_freed_before is initialized whenever count != 0 */\n  if (count != 0\n#  if defined(THREADS) && !defined(THREAD_SANITIZER)\n      /* A quick check whether some memory was freed.     */\n      /* The race with GC_free() is safe to be ignored    */\n      /* because we only need to know if the current      */\n      /* thread has deallocated something.                */\n      && bytes_freed_before != GC_bytes_freed\n#  endif\n  ) {\n    LOCK();\n    GC_finalizer_bytes_freed += (GC_bytes_freed - bytes_freed_before);\n    UNLOCK();\n  }\n  return count;\n}\n\nstatic word last_finalizer_notification = 0;\n\nGC_INNER void\nGC_notify_or_invoke_finalizers(void)\n{\n  GC_finalizer_notifier_proc notifier_fn = 0;\n#  if defined(KEEP_BACK_PTRS) || defined(MAKE_BACK_GRAPH)\n  static word last_back_trace_gc_no = 1; /* skip first one */\n#  endif\n\n#  if defined(THREADS) && !defined(KEEP_BACK_PTRS) && !defined(MAKE_BACK_GRAPH)\n  /* Quick check (while unlocked) for an empty finalization queue.  */\n  if (!GC_should_invoke_finalizers())\n    return;\n#  endif\n  LOCK();\n\n  /* This is a convenient place to generate backtraces if appropriate, */\n  /* since that code is not callable with the allocator lock.          */\n#  if defined(KEEP_BACK_PTRS) || defined(MAKE_BACK_GRAPH)\n  if (GC_gc_no != last_back_trace_gc_no) {\n#    ifdef KEEP_BACK_PTRS\n    static GC_bool bt_in_progress = FALSE;\n\n    if (!bt_in_progress) {\n      long i;\n\n      /* Prevent a recursion or parallel usage.   */\n      bt_in_progress = TRUE;\n      for (i = 0; i < GC_backtraces; ++i) {\n        /* FIXME: This tolerates concurrent heap mutation, which  */\n        /* may cause occasional mysterious results.  We need to   */\n        /* release the allocator lock, since GC_print_callers()   */\n        /* acquires it.  It probably shouldn't.                   */\n        void *current = GC_generate_random_valid_address();\n\n        UNLOCK();\n        GC_printf(\"\\n***Chosen address %p in object\\n\", current);\n        GC_print_backtrace(current);\n        LOCK();\n      }\n      bt_in_progress = FALSE;\n    }\n#    endif\n    last_back_trace_gc_no = GC_gc_no;\n#    ifdef MAKE_BACK_GRAPH\n    if (GC_print_back_height) {\n      GC_print_back_graph_stats();\n    }\n#    endif\n  }\n#  endif\n  if (NULL == GC_fnlz_roots.finalize_now) {\n    UNLOCK();\n    return;\n  }\n\n  if (!GC_finalize_on_demand) {\n    unsigned char *pnested;\n\n#  ifdef THREADS\n    if (EXPECT(GC_in_thread_creation, FALSE)) {\n      UNLOCK();\n      return;\n    }\n#  endif\n    pnested = GC_check_finalizer_nested();\n    UNLOCK();\n    /* Skip GC_invoke_finalizers() if nested. */\n    if (pnested != NULL) {\n      (void)GC_invoke_finalizers();\n      /* Reset since no more finalizers or interrupted.       */\n      *pnested = 0;\n#  ifndef THREADS\n      GC_ASSERT(NULL == GC_fnlz_roots.finalize_now\n                || GC_interrupt_finalizers > 0);\n#  else\n      /* Note: in the multi-threaded case GC can run concurrently   */\n      /* and add more finalizers to run.                            */\n#  endif\n    }\n    return;\n  }\n\n  /* These variables require synchronization to avoid data race.  */\n  if (last_finalizer_notification != GC_gc_no) {\n    notifier_fn = GC_finalizer_notifier;\n    last_finalizer_notification = GC_gc_no;\n  }\n  UNLOCK();\n  if (notifier_fn != 0) {\n    /* Invoke the notifier. */\n    (*notifier_fn)();\n  }\n}\n\n#  ifndef SMALL_CONFIG\n#    ifndef GC_LONG_REFS_NOT_NEEDED\n#      define IF_LONG_REFS_PRESENT_ELSE(x, y) (x)\n#    else\n#      define IF_LONG_REFS_PRESENT_ELSE(x, y) (y)\n#    endif\n\nGC_INNER void\nGC_print_finalization_stats(void)\n{\n  const struct finalizable_object *fo;\n  unsigned long ready = 0;\n\n  GC_log_printf(\n      \"%lu finalization entries;\"\n      \" %lu/%lu short/long disappearing links alive\\n\",\n      (unsigned long)GC_fo_entries, (unsigned long)GC_dl_hashtbl.entries,\n      (unsigned long)IF_LONG_REFS_PRESENT_ELSE(GC_ll_hashtbl.entries, 0));\n\n  for (fo = GC_fnlz_roots.finalize_now; fo != NULL; fo = fo_next(fo))\n    ++ready;\n  GC_log_printf(\"%lu finalization-ready objects;\"\n                \" %ld/%ld short/long links cleared\\n\",\n                ready, (long)GC_old_dl_entries - (long)GC_dl_hashtbl.entries,\n                (long)IF_LONG_REFS_PRESENT_ELSE(\n                    GC_old_ll_entries - GC_ll_hashtbl.entries, 0));\n}\n#  endif /* !SMALL_CONFIG */\n\n#endif /* !GC_NO_FINALIZATION */\n"
        },
        {
          "name": "fnlz_mlc.c",
          "type": "blob",
          "size": 4.73828125,
          "content": "/*\n * Copyright (c) 2011 by Hewlett-Packard Company.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#ifdef ENABLE_DISCLAIM\n\n#  include \"gc/gc_disclaim.h\"\n#  include \"private/dbg_mlc.h\" /* for oh type */\n\n#  if defined(KEEP_BACK_PTRS) || defined(MAKE_BACK_GRAPH)\n/* The first bit is already used for a debug purpose. */\n#    define FINALIZER_CLOSURE_FLAG 0x2\n#  else\n#    define FINALIZER_CLOSURE_FLAG 0x1\n#  endif\n\nSTATIC int GC_CALLBACK\nGC_finalized_disclaim(void *obj)\n{\n#  ifdef AO_HAVE_load\n  ptr_t fc_p = GC_cptr_load((volatile ptr_t *)obj);\n#  else\n  ptr_t fc_p = *(ptr_t *)obj;\n#  endif\n\n  if ((ADDR(fc_p) & FINALIZER_CLOSURE_FLAG) != 0) {\n    /* The disclaim function may be passed fragments from the       */\n    /* free-list, on which it should not run finalization.          */\n    /* To recognize this case, we use the fact that the value of    */\n    /* the first pointer of such fragments is always, at least,     */\n    /* multiple of a pointer size (a link to the next fragment, or  */\n    /* NULL).  If it is desirable to have a finalizer which does    */\n    /* not use the first pointer for storing the finalization       */\n    /* information, GC_disclaim_and_reclaim() must be extended to   */\n    /* clear fragments so that the assumption holds for the         */\n    /* selected pointer location.                                   */\n    const struct GC_finalizer_closure *fc\n        = (struct GC_finalizer_closure *)CPTR_CLEAR_FLAGS(\n            fc_p, FINALIZER_CLOSURE_FLAG);\n\n    GC_ASSERT(!GC_find_leak);\n    fc->proc((ptr_t *)obj + 1, fc->cd);\n  }\n  return 0;\n}\n\nSTATIC void\nGC_register_disclaim_proc_inner(unsigned kind, GC_disclaim_proc proc,\n                                GC_bool mark_unconditionally)\n{\n  GC_ASSERT(kind < MAXOBJKINDS);\n  if (EXPECT(GC_find_leak, FALSE))\n    return;\n\n  GC_obj_kinds[kind].ok_disclaim_proc = proc;\n  GC_obj_kinds[kind].ok_mark_unconditionally = mark_unconditionally;\n}\n\nGC_API void GC_CALL\nGC_init_finalized_malloc(void)\n{\n  /* Initialize the collector just in case it is not done yet.        */\n  GC_init();\n\n  LOCK();\n  if (GC_finalized_kind != 0) {\n    UNLOCK();\n    return;\n  }\n\n  /* The finalizer closure is placed in the first pointer of the      */\n  /* object in order to use the lower bits to distinguish live        */\n  /* objects from objects on the free list.  The downside of this is  */\n  /* that we need one-pointer offset interior pointers, and that      */\n  /* GC_base() does not return the start of the user region.          */\n  GC_register_displacement_inner(sizeof(ptr_t));\n\n  /* And, the pointer to the finalizer closure object itself is       */\n  /* displaced due to baking in this indicator.                       */\n  GC_register_displacement_inner(FINALIZER_CLOSURE_FLAG);\n  GC_register_displacement_inner(sizeof(oh) | FINALIZER_CLOSURE_FLAG);\n\n  GC_finalized_kind\n      = GC_new_kind_inner(GC_new_free_list_inner(), GC_DS_LENGTH, TRUE, TRUE);\n  GC_ASSERT(GC_finalized_kind != 0);\n  GC_register_disclaim_proc_inner(GC_finalized_kind, GC_finalized_disclaim,\n                                  TRUE);\n  UNLOCK();\n}\n\nGC_API void GC_CALL\nGC_register_disclaim_proc(int kind, GC_disclaim_proc proc,\n                          int mark_unconditionally)\n{\n  LOCK();\n  GC_register_disclaim_proc_inner((unsigned)kind, proc,\n                                  (GC_bool)mark_unconditionally);\n  UNLOCK();\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_finalized_malloc(size_t lb, const struct GC_finalizer_closure *fclos)\n{\n  void *op;\n  ptr_t fc_p;\n\n#  ifndef LINT2\n  /* Actually, there is no data race because the variable is set once. */\n  GC_ASSERT(GC_finalized_kind != 0);\n#  endif\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fclos));\n  GC_ASSERT((ADDR(fclos) & FINALIZER_CLOSURE_FLAG) == 0);\n  op = GC_malloc_kind(SIZET_SAT_ADD(lb, sizeof(ptr_t)),\n                      (int)GC_finalized_kind);\n  if (EXPECT(NULL == op, FALSE))\n    return NULL;\n\n  /* Set the flag (w/o conversion to a numeric type) and store    */\n  /* the finalizer closure.                                       */\n  fc_p = CPTR_SET_FLAGS(GC_CAST_AWAY_CONST_PVOID(fclos),\n                        FINALIZER_CLOSURE_FLAG);\n#  ifdef AO_HAVE_store\n  GC_cptr_store((volatile ptr_t *)op, fc_p);\n#  else\n  *(ptr_t *)op = fc_p;\n#  endif\n  GC_dirty(op);\n  REACHABLE_AFTER_DIRTY(fc_p);\n  return (ptr_t *)op + 1;\n}\n\n#endif /* ENABLE_DISCLAIM */\n"
        },
        {
          "name": "gc.man",
          "type": "blob",
          "size": 5.7255859375,
          "content": ".TH BDWGC 3 \"14 Jun 2024\"\n.SH NAME\nGC_malloc, GC_malloc_atomic, GC_free, GC_realloc, GC_enable_incremental,\nGC_register_finalizer, GC_malloc_ignore_off_page,\nGC_malloc_atomic_ignore_off_page, GC_set_warn_proc \\- Garbage collecting\nmalloc replacement\n.SH SYNOPSIS\n#include <gc/gc.h>\n.br\nvoid * GC_malloc(size_t size);\n.br\nvoid * GC_malloc_atomic(size_t size);\n.br\nvoid GC_free(void *ptr);\n.br\nvoid * GC_realloc(void *ptr, size_t size);\n.br\nvoid GC_enable_incremental(void);\n.br\nvoid * GC_malloc_ignore_off_page(size_t size);\n.br\nvoid * GC_malloc_atomic_ignore_off_page(size_t size);\n.br\nvoid GC_set_warn_proc(void (*proc)(const char *, GC_uintptr_t));\n.br\n.sp\ncc ... -lgc\n.LP\n.SH DESCRIPTION\n.I GC_malloc\nand\n.I GC_free\nare plug-in replacements for standard malloc and free.  However,\n.I\nGC_malloc\nwill attempt to reclaim inaccessible space automatically by invoking\na conservative garbage collector at appropriate points.  The collector\ntraverses all data structures accessible by following pointers from the\nmachines registers, stack(s), data, and bss segments.  Inaccessible structures\nwill be reclaimed.  A machine word is considered to be a valid pointer if\nit is an address inside an object allocated by\n.I\nGC_malloc\nor friends.\n.LP\nIn most cases it is preferable to call the macros GC_MALLOC, GC_FREE, etc.\ninstead of calling GC_malloc and friends directly.  This allows debugging\nversions of the routines to be substituted by defining GC_DEBUG before\nincluding gc.h.\n.LP\nSee the documentation in the include files gc_cpp.h and gc_allocator.h,\nas well as the gcinterface.md file in the distribution,\nfor an alternate, C++ specific interface to the garbage collector.\nNote that C++ programs generally\nneed to be careful to ensure that all allocated memory (whether via new,\nmalloc, or STL allocators) that may point to garbage collected memory\nis either itself garbage collected, or at least traced by the collector.\n.LP\nUnlike the standard implementations of malloc,\n.I\nGC_malloc\nclears the newly allocated storage.\n.I\nGC_malloc_atomic\ndoes not.  Furthermore, it informs the collector that the resulting object\nwill never contain any pointers, and should therefore not be scanned by the\ncollector.\n.LP\n.I\nGC_free\ncan be used to deallocate objects, but its use is optional, and generally\ndiscouraged.\n.I\nGC_realloc\nhas the standard realloc semantics.  It preserves pointer-free-ness.\n.I\nGC_register_finalizer\nallows for registration of functions that are invoked when an object becomes\ninaccessible.\n.LP\nThe garbage collector tries to avoid allocating memory at locations that\nalready appear to be referenced before allocation.  (Such apparent\n``pointers'' are usually large integers and the like that just happen to look\nlike an address.)  This may make it hard to allocate very large objects.\nAn attempt to do so may generate a warning.\n.LP\n.I\nGC_malloc_ignore_off_page\nand\n.I\nGC_malloc_atomic_ignore_off_page\ninform the collector that the client code will always maintain a pointer to\nnear the beginning (i.e. within the first heap block) of the object, and that\npointers beyond that can be ignored by the collector.  This makes it much\neasier for the collector to place large objects.  These are recommended for\nlarge object allocation.  (Objects expected to be > ~100 KB should be\nallocated this way.)\n.LP\nIt is also possible to use the collector to find storage leaks in programs\ndestined to be run with standard malloc/free.  The collector can be compiled\nfor thread-safe operation.  Unlike standard malloc, it is safe to call malloc\nafter a previous malloc call was interrupted by a signal, provided the\noriginal malloc call is not resumed.\n.LP\nThe collector may, on rare occasion, produce warning messages.  On UNIX\nmachines these appear on stderr.  Warning messages can be filtered,\nredirected, or ignored with\n.I\nGC_set_warn_proc\nThis is recommended for production code.  See gc.h for details.\n.LP\nFully portable code should call\n.I\nGC_INIT\nfrom the primordial thread of the main program before making any other\nGC calls.  On most platforms this does nothing and the collector is\ninitialized on first use.  On a few platforms explicit initialization is\nnecessary.  And it can never hurt.\n.LP\nDebugging versions of many of the above routines are provided as macros.\nTheir names are identical to the above, but consist of all capital letters.\nIf GC_DEBUG is defined before gc.h is included, these routines do additional\nchecking, and allow the leak detecting version of the collector to produce\nslightly more useful output.  Without GC_DEBUG defined, they behave exactly\nlike the lower-case versions.\n.LP\nOn some machines, collection will be performed incrementally after a call to\n.I\nGC_enable_incremental.\nThis may temporarily write protect pages in the heap.  See the README file for\nmore information on how this interacts with system calls that write to the\nheap.\n.LP\nOther facilities not discussed here include limited facilities to support\nincremental collection on machines without appropriate VM support, provisions\nfor providing more explicit object layout information to the garbage\ncollector, more direct support for ``weak'' pointers, support for\n``abortable'' garbage collections during idle time, etc.\n.LP\n.SH \"SEE ALSO\"\nThe README and gc.h files in the distribution.  More detailed definitions of\nthe functions exported by the collector are given there.  (The above list is\nnot complete.)\n.LP\nThe web site at http://www.hboehm.info/gc/ (or https://github.com/ivmai/bdwgc/).\n.LP\nBoehm, H., and M. Weiser, \"Garbage Collection in an Uncooperative Environment\",\n\"Software Practice & Experience\", September 1988, pp. 807-820.\n.LP\nThe malloc(3) man page.\n.LP\n.SH AUTHOR\nHans-J. Boehm (boehm@acm.org).\nSome of the code was written by others (see the AUTHORS file for the details),\nmost notably by Alan Demers, and, recently, Ivan Maidanski.\n"
        },
        {
          "name": "gc_badalc.cc",
          "type": "blob",
          "size": 1.126953125,
          "content": "/*\n * Copyright (c) 2018-2020 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n *\n */\n\n// This file provides the implementation of GC_throw_bad_alloc() which\n// is invoked by GC operator \"new\" in case of an out-of-memory event.\n\n#ifdef HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#ifndef GC_BUILD\n#  define GC_BUILD\n#endif\n\n#define GC_DONT_INCL_WINDOWS_H\n#include \"gc/gc.h\"\n\n#include <new> // for bad_alloc, precedes include of gc_cpp.h\n\n#if defined(GC_NEW_ABORTS_ON_OOM) || defined(_LIBCPP_NO_EXCEPTIONS)\n#  define GC_ALLOCATOR_THROW_OR_ABORT() GC_abort_on_oom()\n#else\n#  define GC_ALLOCATOR_THROW_OR_ABORT() throw std::bad_alloc()\n#endif\n\nGC_API void GC_CALL\nGC_throw_bad_alloc()\n{\n  GC_ALLOCATOR_THROW_OR_ABORT();\n}\n"
        },
        {
          "name": "gc_badalc.cpp",
          "type": "blob",
          "size": 0.0810546875,
          "content": "// Visual C++ seems to prefer a .cpp extension to .cc one.\n#include \"gc_badalc.cc\"\n"
        },
        {
          "name": "gc_cpp.cc",
          "type": "blob",
          "size": 3.736328125,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n/*\nThis implementation module for gc_cpp.h provides an implementation of\nthe global operators \"new\" and \"delete\" that calls the Boehm\nallocator.  All objects allocated by this implementation will be\nuncollectible but part of the root set of the collector.\n\nYou should ensure (using implementation-dependent techniques) that the\nlinker finds this module before the library that defines the default\nbuilt-in \"new\" and \"delete\".\n*/\n\n#ifdef HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#ifndef GC_BUILD\n#  define GC_BUILD\n#endif\n\n#define GC_DONT_INCL_WINDOWS_H\n#include \"gc/gc.h\"\n\n#ifndef GC_INCLUDE_NEW\n#  define GC_INCLUDE_NEW\n#endif\n#include \"gc/gc_cpp.h\"\n\n#if (!defined(_MSC_VER) && !defined(__DMC__) \\\n     || defined(GC_NO_INLINE_STD_NEW))       \\\n    && !defined(GC_INLINE_STD_NEW) && !defined(SKIP_GCCPP_DEFINITIONS)\n\n#  if defined(GC_NEW_ABORTS_ON_OOM) || defined(_LIBCPP_NO_EXCEPTIONS)\n#    define GC_ALLOCATOR_THROW_OR_ABORT() GC_abort_on_oom()\n#  else\n// Use bad_alloc() directly instead of GC_throw_bad_alloc() call.\n#    define GC_ALLOCATOR_THROW_OR_ABORT() throw std::bad_alloc()\n#  endif\n\nvoid *\noperator new(GC_SIZE_T size) GC_DECL_NEW_THROW\n{\n  void *obj = GC_MALLOC_UNCOLLECTABLE(size);\n  if (0 == obj)\n    GC_ALLOCATOR_THROW_OR_ABORT();\n  return obj;\n}\n\n#  ifdef _MSC_VER\n// This new operator is used by VC++ in case of Debug builds.\nvoid *\noperator new(GC_SIZE_T size, int /* nBlockUse */, const char *szFileName,\n             int nLine)\n{\n#    ifdef GC_DEBUG\n  void *obj = GC_debug_malloc_uncollectable(size, szFileName, nLine);\n#    else\n  void *obj = GC_MALLOC_UNCOLLECTABLE(size);\n  (void)szFileName;\n  (void)nLine;\n#    endif\n  if (0 == obj)\n    GC_ALLOCATOR_THROW_OR_ABORT();\n  return obj;\n}\n#  endif // _MSC_VER\n\nvoid\noperator delete(void *obj) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n\n#  ifdef GC_OPERATOR_NEW_NOTHROW\nvoid *\noperator new(GC_SIZE_T size, const std::nothrow_t &) GC_NOEXCEPT\n{\n  return GC_MALLOC_UNCOLLECTABLE(size);\n}\n\nvoid\noperator delete(void *obj, const std::nothrow_t &) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n#  endif // GC_OPERATOR_NEW_NOTHROW\n\n#  if defined(GC_OPERATOR_NEW_ARRAY) && !defined(CPPCHECK)\nvoid *\noperator new[](GC_SIZE_T size) GC_DECL_NEW_THROW\n{\n  void *obj = GC_MALLOC_UNCOLLECTABLE(size);\n  if (0 == obj)\n    GC_ALLOCATOR_THROW_OR_ABORT();\n  return obj;\n}\n\n#    ifdef _MSC_VER\n// This new operator is used by VC++ 7+ in Debug builds.\nvoid *\noperator new[](GC_SIZE_T size, int nBlockUse, const char *szFileName,\n               int nLine)\n{\n  return operator new(size, nBlockUse, szFileName, nLine);\n}\n#    endif // _MSC_VER\n\nvoid\noperator delete[](void *obj) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n\n#    ifdef GC_OPERATOR_NEW_NOTHROW\nvoid *\noperator new[](GC_SIZE_T size, const std::nothrow_t &) GC_NOEXCEPT\n{\n  return GC_MALLOC_UNCOLLECTABLE(size);\n}\n\nvoid\noperator delete[](void *obj, const std::nothrow_t &) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n#    endif\n#  endif // GC_OPERATOR_NEW_ARRAY\n\n#  ifdef GC_OPERATOR_SIZED_DELETE\nvoid\noperator delete(void *obj, GC_SIZE_T) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n\n#    if defined(GC_OPERATOR_NEW_ARRAY) && !defined(CPPCHECK)\nvoid\noperator delete[](void *obj, GC_SIZE_T) GC_NOEXCEPT\n{\n  GC_FREE(obj);\n}\n#    endif\n#  endif // GC_OPERATOR_SIZED_DELETE\n\n#endif // !_MSC_VER && !__DMC__ || GC_NO_INLINE_STD_NEW\n"
        },
        {
          "name": "gc_cpp.cpp",
          "type": "blob",
          "size": 0.0732421875,
          "content": "// Visual C++ seems to prefer a .cpp extension to .cc\n#include \"gc_cpp.cc\"\n"
        },
        {
          "name": "gc_dlopen.c",
          "type": "blob",
          "size": 3.8671875,
          "content": "/*\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1997 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 2000 by Hewlett-Packard Company.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/* This used to be in dyn_load.c.  It was extracted into a separate     */\n/* file to avoid having to link against libdl.{a,so} if the client      */\n/* doesn't call dlopen.  Of course this fails if the collector is in    */\n/* a dynamic library. -HB                                               */\n#if defined(GC_PTHREADS) && !defined(GC_NO_DLOPEN)\n\n#  undef GC_MUST_RESTORE_REDEFINED_DLOPEN\n#  if defined(dlopen) && !defined(GC_USE_LD_WRAP)\n/* To support various threads pkgs, gc.h interposes on dlopen by      */\n/* defining \"dlopen\" to be \"GC_dlopen\", which is implemented below.   */\n/* However, both GC_FirstDLOpenedLinkMap() and GC_dlopen() use the    */\n/* real system dlopen() in their implementation. We first remove      */\n/* gc.h's dlopen definition and restore it later, after GC_dlopen().  */\n#    undef dlopen\n#    define GC_MUST_RESTORE_REDEFINED_DLOPEN\n#  endif\n\n/* Make sure we're not in the middle of a collection, and make sure we  */\n/* don't start any.  This is invoked prior to a dlopen call to avoid    */\n/* synchronization issues.  We cannot just acquire the allocator lock,  */\n/* since startup code in dlopen may try to allocate.  This solution     */\n/* risks heap growth (or, even, heap overflow) in the presence of many  */\n/* dlopen calls in either a multi-threaded environment, or if the       */\n/* library initialization code allocates substantial amounts of GC'ed   */\n/* memory.                                                              */\n#  ifndef USE_PROC_FOR_LIBRARIES\nstatic void\ndisable_gc_for_dlopen(void)\n{\n  LOCK();\n  while (GC_incremental && GC_collection_in_progress()) {\n    ENTER_GC();\n    GC_collect_a_little_inner(1000);\n    EXIT_GC();\n  }\n  ++GC_dont_gc;\n  UNLOCK();\n}\n#  endif\n\n/* Redefine dlopen to guarantee mutual exclusion with           */\n/* GC_register_dynamic_libraries.  Should probably happen for   */\n/* other operating systems, too.                                */\n\n/* This is similar to WRAP/REAL_FUNC() in pthread_support.c.    */\n#  ifdef GC_USE_LD_WRAP\n#    define WRAP_DLFUNC(f) __wrap_##f\n#    define REAL_DLFUNC(f) __real_##f\nvoid *REAL_DLFUNC(dlopen)(const char *, int);\n#  else\n#    define WRAP_DLFUNC(f) GC_##f\n#    define REAL_DLFUNC(f) f\n#  endif\n\n#  define GC_wrap_dlopen WRAP_DLFUNC(dlopen)\nGC_API void *\nGC_wrap_dlopen(const char *path, int mode)\n{\n  void *result;\n\n#  ifndef USE_PROC_FOR_LIBRARIES\n  /* Disable collections.  This solution risks heap growth (or,       */\n  /* even, heap overflow) but there seems no better solutions.        */\n  disable_gc_for_dlopen();\n#  endif\n  result = REAL_DLFUNC(dlopen)(path, mode);\n#  ifndef USE_PROC_FOR_LIBRARIES\n  /* This undoes disable_gc_for_dlopen().     */\n  GC_enable();\n#  endif\n  return result;\n}\n#  undef GC_wrap_dlopen\n\n#  ifdef GC_USE_LD_WRAP\n/* Define GC_ function as an alias for the plain one, which will be   */\n/* intercepted.  This allows files which include gc.h, and hence      */\n/* generate references to the GC_ symbol, to see the right symbol.    */\nGC_API void *\nGC_dlopen(const char *path, int mode)\n{\n  return dlopen(path, mode);\n}\n#  endif /* GC_USE_LD_WRAP */\n\n#  ifdef GC_MUST_RESTORE_REDEFINED_DLOPEN\n#    define dlopen GC_dlopen\n#  endif\n\n#endif /* GC_PTHREADS && !GC_NO_DLOPEN */\n"
        },
        {
          "name": "gcj_mlc.c",
          "type": "blob",
          "size": 7.4306640625,
          "content": "/*\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1999-2004 Hewlett-Packard Development Company, L.P.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\" /* includes gc_priv.h */\n\n#ifdef GC_GCJ_SUPPORT\n\n/*\n * This is an allocator interface tuned for gcj (the GNU static\n * java compiler).\n *\n * Each allocated object has a pointer in its beginning to a vtable,\n * which for our purposes is simply a structure describing the type of\n * the object.  This descriptor structure contains a GC marking\n * descriptor at offset GC_GCJ_MARK_DESCR_OFFSET.\n *\n * It is hoped that this interface may also be useful for other systems,\n * possibly with some tuning of the constants.  But the immediate goal\n * is to get better gcj performance.\n *\n * We assume: counting on explicit initialization of this interface is OK.\n */\n\n#  include \"gc/gc_gcj.h\"\n#  include \"private/dbg_mlc.h\"\n\n/* Object kind for objects with descriptors in \"vtable\".                */\nint GC_gcj_kind = 0;\n\n/* The kind of objects that are always marked with a mark proc call.    */\nint GC_gcj_debug_kind = 0;\n\nSTATIC struct GC_ms_entry *GC_CALLBACK\nGC_gcj_fake_mark_proc(word *addr, struct GC_ms_entry *mark_stack_top,\n                      struct GC_ms_entry *mark_stack_limit, word env)\n{\n  UNUSED_ARG(addr);\n  UNUSED_ARG(mark_stack_limit);\n  UNUSED_ARG(env);\n#  if defined(FUNCPTR_IS_DATAPTR) && defined(CPPCHECK)\n  GC_noop1((word)(GC_funcptr_uint)(&GC_init_gcj_malloc));\n#  endif\n  ABORT_RET(\"No client gcj mark proc is specified\");\n  return mark_stack_top;\n}\n\n#  ifdef FUNCPTR_IS_DATAPTR\nGC_API void GC_CALL\nGC_init_gcj_malloc(int mp_index, void *mp)\n{\n  GC_init_gcj_malloc_mp((unsigned)mp_index,\n                        CAST_THRU_UINTPTR(GC_mark_proc, mp),\n                        GC_GCJ_MARK_DESCR_OFFSET);\n}\n#  endif /* FUNCPTR_IS_DATAPTR */\n\nGC_API void GC_CALL\nGC_init_gcj_malloc_mp(unsigned mp_index, GC_mark_proc mp, size_t descr_offset)\n{\n#  ifndef GC_IGNORE_GCJ_INFO\n  GC_bool ignore_gcj_info;\n#  endif\n\n  GC_STATIC_ASSERT(GC_GCJ_MARK_DESCR_OFFSET >= sizeof(ptr_t));\n  if (0 == mp) {\n    /* In case GC_DS_PROC is unused.  */\n    mp = GC_gcj_fake_mark_proc;\n  }\n\n  /* Initialize the collector just in case it is not done yet.        */\n  GC_init();\n  if (descr_offset != GC_GCJ_MARK_DESCR_OFFSET)\n    ABORT(\"GC_init_gcj_malloc_mp: bad offset\");\n\n  LOCK();\n  if (GC_gcjobjfreelist != NULL) {\n    /* Already initialized.   */\n    UNLOCK();\n    return;\n  }\n#  ifdef GC_IGNORE_GCJ_INFO\n  /* This is useful for debugging on platforms with missing getenv(). */\n#    define ignore_gcj_info TRUE\n#  else\n  ignore_gcj_info = GETENV(\"GC_IGNORE_GCJ_INFO\") != NULL;\n#  endif\n  if (ignore_gcj_info) {\n    GC_COND_LOG_PRINTF(\"Gcj-style type information is disabled!\\n\");\n  }\n  GC_ASSERT(GC_mark_procs[mp_index] == (GC_mark_proc)0); /* unused */\n  GC_mark_procs[mp_index] = mp;\n  if (mp_index >= GC_n_mark_procs)\n    ABORT(\"GC_init_gcj_malloc_mp: bad index\");\n  /* Set up object kind gcj-style indirect descriptor. */\n  GC_gcjobjfreelist = (ptr_t *)GC_new_free_list_inner();\n  if (ignore_gcj_info) {\n    /* Use a simple length-based descriptor, thus forcing a fully   */\n    /* conservative scan.                                           */\n    GC_gcj_kind = (int)GC_new_kind_inner((void **)GC_gcjobjfreelist,\n                                         /* 0 | */ GC_DS_LENGTH, TRUE, TRUE);\n    GC_gcj_debug_kind = GC_gcj_kind;\n  } else {\n    GC_gcj_kind = (int)GC_new_kind_inner(\n        (void **)GC_gcjobjfreelist,\n        (((word)(-(GC_signed_word)GC_GCJ_MARK_DESCR_OFFSET\n                 - GC_INDIR_PER_OBJ_BIAS))\n         | GC_DS_PER_OBJECT),\n        FALSE, TRUE);\n    /* Set up object kind for objects that require mark proc call.  */\n    GC_gcj_debug_kind = (int)GC_new_kind_inner(\n        GC_new_free_list_inner(),\n        GC_MAKE_PROC(mp_index, 1 /* allocated with debug info */), FALSE,\n        TRUE);\n  }\n  UNLOCK();\n#  undef ignore_gcj_info\n}\n\n/* A mechanism to release the allocator lock and invoke finalizers.     */\n/* We don't really have an opportunity to do this on a rarely executed  */\n/* path on which the allocator lock is not held.  Thus we check at      */\n/* a rarely executed point at which it is safe to release the allocator */\n/* lock; we do this even where we could just call GC_INVOKE_FINALIZERS, */\n/* since it is probably cheaper and certainly more uniform.             */\n/* TODO: Consider doing the same elsewhere? */\nstatic void\nmaybe_finalize(void)\n{\n  static word last_finalized_no = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_gc_no == last_finalized_no || !EXPECT(GC_is_initialized, TRUE))\n    return;\n  UNLOCK();\n  GC_INVOKE_FINALIZERS();\n  LOCK();\n  last_finalized_no = GC_gc_no;\n}\n\n/* Allocate an object, clear it, and store the pointer to the   */\n/* type structure (vtable in gcj).  This adds a byte at the     */\n/* end of the object if GC_malloc would.                        */\n#  ifdef THREAD_LOCAL_ALLOC\nGC_INNER\n#  else\nSTATIC\n#  endif\nvoid *\nGC_core_gcj_malloc(size_t lb, const void *vtable_ptr, unsigned flags)\n{\n  ptr_t op;\n  size_t lg;\n\n  GC_DBG_COLLECT_AT_MALLOC(lb);\n  LOCK();\n  if (SMALL_OBJ(lb)\n      && (op = GC_gcjobjfreelist[lg = GC_size_map[lb]],\n          EXPECT(op != NULL, TRUE))) {\n    GC_gcjobjfreelist[lg] = (ptr_t)obj_link(op);\n    GC_bytes_allocd += GRANULES_TO_BYTES((word)lg);\n    GC_ASSERT(NULL == ((void **)op)[1]);\n  } else {\n    maybe_finalize();\n    op = (ptr_t)GC_generic_malloc_inner(lb, GC_gcj_kind, flags);\n    if (NULL == op) {\n      GC_oom_func oom_fn = GC_oom_fn;\n      UNLOCK();\n      return (*oom_fn)(lb);\n    }\n  }\n  *(const void **)op = vtable_ptr;\n  UNLOCK();\n  GC_dirty(op);\n  REACHABLE_AFTER_DIRTY(vtable_ptr);\n  return GC_clear_stack(op);\n}\n\n#  ifndef THREAD_LOCAL_ALLOC\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_gcj_malloc(size_t lb, const void *vtable_ptr)\n{\n  return GC_core_gcj_malloc(lb, vtable_ptr, 0 /* flags */);\n}\n#  endif /* !THREAD_LOCAL_ALLOC */\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_gcj_malloc_ignore_off_page(size_t lb, const void *vtable_ptr)\n{\n  return GC_core_gcj_malloc(lb, vtable_ptr, IGNORE_OFF_PAGE);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_debug_gcj_malloc(size_t lb, const void *vtable_ptr, GC_EXTRA_PARAMS)\n{\n  void *base, *result;\n\n  /* We are careful to avoid extra calls those could confuse the      */\n  /* backtrace.                                                       */\n  LOCK();\n  maybe_finalize();\n  base = GC_generic_malloc_inner(SIZET_SAT_ADD(lb, DEBUG_BYTES),\n                                 GC_gcj_debug_kind, 0 /* flags */);\n  if (NULL == base) {\n    GC_oom_func oom_fn = GC_oom_fn;\n    UNLOCK();\n    GC_err_printf(\"GC_debug_gcj_malloc(%lu, %p) returning NULL (%s:%d)\\n\",\n                  (unsigned long)lb, vtable_ptr, s, i);\n    return (*oom_fn)(lb);\n  }\n  *((const void **)((ptr_t)base + sizeof(oh))) = vtable_ptr;\n  if (!GC_debugging_started) {\n    GC_start_debugging_inner();\n  }\n  result = GC_store_debug_info_inner(base, lb, s, i);\n  ADD_CALL_CHAIN(base, ra);\n  UNLOCK();\n  GC_dirty(result);\n  REACHABLE_AFTER_DIRTY(vtable_ptr);\n  return result;\n}\n\n#endif /* GC_GCJ_SUPPORT */\n"
        },
        {
          "name": "headers.c",
          "type": "blob",
          "size": 11.3779296875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#if defined(KEEP_BACK_PTRS) && defined(GC_ASSERTIONS)\n#  include \"private/dbg_mlc.h\" /* for NOT_MARKED */\n#endif\n\n/*\n * This implements:\n * 1. allocation of heap block headers\n * 2. A map from addresses to heap block addresses to heap block headers\n *\n * Access speed is crucial.  We implement an index structure based on a 2\n * level tree.\n */\n\n/* A non-macro version of header location routine.      */\nGC_INNER hdr *\nGC_find_header(const void *h)\n{\n#ifdef HASH_TL\n  hdr *result;\n  GET_HDR(h, result);\n  return result;\n#else\n  return HDR_INNER(h);\n#endif\n}\n\n/* Handle a header cache miss.  Returns a pointer to the        */\n/* header corresponding to p, if p can possibly be a valid      */\n/* object pointer, and 0 otherwise.                             */\n/* GUARANTEED to return 0 for a pointer past the first page     */\n/* of an object unless both GC_all_interior_pointers is set     */\n/* and p is in fact a valid object pointer.                     */\n/* Never returns a pointer to a free hblk.                      */\nGC_INNER hdr *\n#ifdef PRINT_BLACK_LIST\nGC_header_cache_miss(ptr_t p, hdr_cache_entry *hce, ptr_t source)\n#else\nGC_header_cache_miss(ptr_t p, hdr_cache_entry *hce)\n#endif\n{\n  hdr *hhdr;\n\n  HC_MISS();\n  GET_HDR(p, hhdr);\n  if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n    if (GC_all_interior_pointers) {\n      if (hhdr != NULL) {\n        /* Pointer to near the start of the large object.       */\n        ptr_t current = (ptr_t)GC_find_starting_hblk(HBLKPTR(p), &hhdr);\n\n        if (hhdr->hb_flags & IGNORE_OFF_PAGE)\n          return 0;\n        if (HBLK_IS_FREE(hhdr) || p - current >= (GC_signed_word)hhdr->hb_sz) {\n          GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n          /* The pointer is past the end of the block.        */\n          return 0;\n        }\n      } else {\n        GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n        /* And return zero: */\n      }\n      GC_ASSERT(NULL == hhdr || !HBLK_IS_FREE(hhdr));\n      /* Pointers past the first page are probably too rare to add them */\n      /* to the cache.  We do not.  And correctness relies on the fact  */\n      /* that we do not.                                                */\n      return hhdr;\n    } else {\n      if (NULL == hhdr) {\n        GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n      }\n      return 0;\n    }\n  } else {\n    if (HBLK_IS_FREE(hhdr)) {\n      GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n      return 0;\n    } else {\n      hce->block_addr = ADDR(p) >> LOG_HBLKSIZE;\n      hce->hce_hdr = hhdr;\n      return hhdr;\n    }\n  }\n}\n\n/* Routines to dynamically allocate collector data structures that will */\n/* never be freed.                                                      */\n\nGC_INNER ptr_t\nGC_scratch_alloc(size_t bytes)\n{\n  ptr_t result = GC_scratch_free_ptr;\n  size_t bytes_to_get;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  bytes = ROUNDUP_GRANULE_SIZE(bytes);\n  for (;;) {\n    GC_ASSERT(GC_scratch_end_addr >= ADDR(result));\n    if (bytes <= GC_scratch_end_addr - ADDR(result)) {\n      /* Unallocated space of scratch buffer has enough size. */\n      GC_scratch_free_ptr = result + bytes;\n      return result;\n    }\n\n    GC_ASSERT(GC_page_size != 0);\n    if (bytes >= MINHINCR * HBLKSIZE) {\n      bytes_to_get = ROUNDUP_PAGESIZE_IF_MMAP(bytes);\n      result = GC_os_get_mem(bytes_to_get);\n      if (result != NULL) {\n#if defined(KEEP_BACK_PTRS) && (GC_GRANULE_BYTES < 0x10)\n        GC_ASSERT(ADDR(result) > (word)NOT_MARKED);\n#endif\n        /* No update of scratch free area pointer; get memory     */\n        /* directly.                                              */\n#ifdef USE_SCRATCH_LAST_END_PTR\n        /* Update end point of last obtained area (needed only  */\n        /* by GC_register_dynamic_libraries for some targets).  */\n        GC_scratch_last_end_addr = ADDR(result) + bytes;\n#endif\n      }\n      return result;\n    }\n\n    /* This is rounded up for a safety reason.      */\n    bytes_to_get = ROUNDUP_PAGESIZE_IF_MMAP(MINHINCR * HBLKSIZE);\n\n    result = GC_os_get_mem(bytes_to_get);\n    if (EXPECT(NULL == result, FALSE)) {\n      WARN(\"Out of memory - trying to allocate requested amount\"\n           \" (%\" WARN_PRIuPTR \" bytes)...\\n\",\n           bytes);\n      bytes_to_get = ROUNDUP_PAGESIZE_IF_MMAP(bytes);\n      result = GC_os_get_mem(bytes_to_get);\n      if (result != NULL) {\n#ifdef USE_SCRATCH_LAST_END_PTR\n        GC_scratch_last_end_addr = ADDR(result) + bytes;\n#endif\n      }\n      return result;\n    }\n\n    /* TODO: some amount of unallocated space may remain unused forever */\n    /* Update scratch area pointers and retry.      */\n    GC_scratch_free_ptr = result;\n    GC_scratch_end_addr = ADDR(GC_scratch_free_ptr) + bytes_to_get;\n#ifdef USE_SCRATCH_LAST_END_PTR\n    GC_scratch_last_end_addr = GC_scratch_end_addr;\n#endif\n  }\n}\n\n/* Return an uninitialized header.      */\nstatic hdr *\nalloc_hdr(void)\n{\n  hdr *result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == GC_hdr_free_list) {\n    result = (hdr *)GC_scratch_alloc(sizeof(hdr));\n  } else {\n    result = GC_hdr_free_list;\n    GC_hdr_free_list = (hdr *)result->hb_next;\n  }\n  return result;\n}\n\nGC_INLINE void\nfree_hdr(hdr *hhdr)\n{\n  hhdr->hb_next = (struct hblk *)GC_hdr_free_list;\n  GC_hdr_free_list = hhdr;\n}\n\n#ifdef COUNT_HDR_CACHE_HITS\n/* Used for debugging/profiling (the symbols are externally visible). */\nword GC_hdr_cache_hits = 0;\nword GC_hdr_cache_misses = 0;\n#endif\n\nGC_INNER void\nGC_init_headers(void)\n{\n  unsigned i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(NULL == GC_all_nils);\n  GC_all_nils = (bottom_index *)GC_scratch_alloc(sizeof(bottom_index));\n  if (GC_all_nils == NULL) {\n    GC_err_printf(\"Insufficient memory for GC_all_nils\\n\");\n    EXIT();\n  }\n  BZERO(GC_all_nils, sizeof(bottom_index));\n  for (i = 0; i < TOP_SZ; i++) {\n    GC_top_index[i] = GC_all_nils;\n  }\n}\n\n/* Make sure that there is a bottom level index block for address addr. */\n/* Return FALSE on failure.                                             */\nstatic GC_bool\nget_index(word addr)\n{\n  word hi = addr >> (LOG_BOTTOM_SZ + LOG_HBLKSIZE);\n  bottom_index *r;\n  bottom_index *p;\n  bottom_index **prev;\n  bottom_index *pi; /* old_p */\n  word i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#ifdef HASH_TL\n  i = TL_HASH(hi);\n  pi = GC_top_index[i];\n  for (p = pi; p != GC_all_nils; p = p->hash_link) {\n    if (p->key == hi)\n      return TRUE;\n  }\n#else\n  if (GC_top_index[hi] != GC_all_nils)\n    return TRUE;\n  i = hi;\n#endif\n  r = (bottom_index *)GC_scratch_alloc(sizeof(bottom_index));\n  if (EXPECT(NULL == r, FALSE))\n    return FALSE;\n  BZERO(r, sizeof(bottom_index));\n  r->key = hi;\n#ifdef HASH_TL\n  r->hash_link = pi;\n#endif\n\n  /* Add it to the list of bottom indices.    */\n  prev = &GC_all_bottom_indices; /* pointer to p */\n  pi = NULL;                     /* bottom_index preceding p */\n  while ((p = *prev) != 0 && p->key < hi) {\n    pi = p;\n    prev = &p->asc_link;\n  }\n  r->desc_link = pi;\n  if (NULL == p) {\n    GC_all_bottom_indices_end = r;\n  } else {\n    p->desc_link = r;\n  }\n  r->asc_link = p;\n  *prev = r;\n\n  GC_top_index[i] = r;\n  return TRUE;\n}\n\nGC_INNER hdr *\nGC_install_header(struct hblk *h)\n{\n  hdr *result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (EXPECT(!get_index(ADDR(h)), FALSE))\n    return NULL;\n\n  result = alloc_hdr();\n  if (EXPECT(result != NULL, TRUE)) {\n    GC_ASSERT(!IS_FORWARDING_ADDR_OR_NIL(result));\n    SET_HDR(h, result);\n#ifdef USE_MUNMAP\n    result->hb_last_reclaimed = (unsigned short)GC_gc_no;\n#endif\n  }\n  return result;\n}\n\nGC_INNER GC_bool\nGC_install_counts(struct hblk *h, size_t sz /* bytes */)\n{\n  struct hblk *hbp;\n\n  for (hbp = h; ADDR_LT((ptr_t)hbp, (ptr_t)h + sz); hbp += BOTTOM_SZ) {\n    if (!get_index(ADDR(hbp)))\n      return FALSE;\n    /* Is overflow of hbp expected? */\n    if (ADDR(hbp) > GC_WORD_MAX - (word)BOTTOM_SZ * HBLKSIZE)\n      break;\n  }\n  if (!get_index(ADDR(h) + sz - 1))\n    return FALSE;\n\n  GC_ASSERT(!IS_FORWARDING_ADDR_OR_NIL(HDR(h)));\n  for (hbp = h + 1; ADDR_LT((ptr_t)hbp, (ptr_t)h + sz); hbp++) {\n    word i = (word)HBLK_PTR_DIFF(hbp, h);\n\n    SET_HDR(hbp, (hdr *)NUMERIC_TO_VPTR(i > MAX_JUMP ? MAX_JUMP : i));\n  }\n  return TRUE;\n}\n\nGC_INNER void\nGC_remove_header(struct hblk *h)\n{\n  hdr **ha;\n  GET_HDR_ADDR(h, ha);\n  free_hdr(*ha);\n  *ha = 0;\n}\n\nGC_INNER void\nGC_remove_counts(struct hblk *h, size_t sz /* bytes */)\n{\n  struct hblk *hbp;\n\n  if (sz <= HBLKSIZE)\n    return;\n  if (NULL == HDR(h + 1)) {\n#ifdef GC_ASSERTIONS\n    for (hbp = h + 2; ADDR_LT((ptr_t)hbp, (ptr_t)h + sz); hbp++) {\n      GC_ASSERT(NULL == HDR(hbp));\n    }\n#endif\n    return;\n  }\n\n  for (hbp = h + 1; ADDR_LT((ptr_t)hbp, (ptr_t)h + sz); hbp++) {\n    SET_HDR(hbp, NULL);\n  }\n}\n\n#define HBLK_ADDR(bi, j) \\\n  ((((bi)->key << LOG_BOTTOM_SZ) + (word)(j)) << LOG_HBLKSIZE)\n\nGC_API void GC_CALL\nGC_apply_to_all_blocks(GC_walk_hblk_fn fn, void *client_data)\n{\n  bottom_index *bi;\n\n  for (bi = GC_all_bottom_indices; bi != NULL; bi = bi->asc_link) {\n    GC_signed_word j;\n\n    for (j = BOTTOM_SZ - 1; j >= 0;) {\n      hdr *hhdr = bi->index[j];\n\n      if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n        j -= (GC_signed_word)(hhdr != NULL ? ADDR(hhdr) : 1);\n      } else {\n        if (!HBLK_IS_FREE(hhdr)) {\n          GC_ASSERT(HBLK_ADDR(bi, j) == ADDR(hhdr->hb_block));\n          fn(hhdr->hb_block, client_data);\n        }\n        j--;\n      }\n    }\n  }\n}\n\nGC_INNER struct hblk *\nGC_next_block(struct hblk *h, GC_bool allow_free)\n{\n  REGISTER bottom_index *bi;\n  REGISTER size_t j = (size_t)(ADDR(h) >> LOG_HBLKSIZE) & (BOTTOM_SZ - 1);\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  GET_BI(h, bi);\n  if (bi == GC_all_nils) {\n    REGISTER word hi = ADDR(h) >> (LOG_BOTTOM_SZ + LOG_HBLKSIZE);\n\n    bi = GC_all_bottom_indices;\n    while (bi != NULL && bi->key < hi)\n      bi = bi->asc_link;\n    j = 0;\n  }\n\n  for (; bi != NULL; bi = bi->asc_link) {\n    while (j < BOTTOM_SZ) {\n      hdr *hhdr = bi->index[j];\n\n      if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n        j++;\n      } else {\n        if (allow_free || !HBLK_IS_FREE(hhdr)) {\n          GC_ASSERT(HBLK_ADDR(bi, j) == ADDR(hhdr->hb_block));\n          return hhdr->hb_block;\n        }\n        j += divHBLKSZ(hhdr->hb_sz);\n      }\n    }\n    j = 0;\n  }\n  return NULL;\n}\n\nGC_INNER struct hblk *\nGC_prev_block(struct hblk *h)\n{\n  bottom_index *bi;\n  GC_signed_word j = (ADDR(h) >> LOG_HBLKSIZE) & (BOTTOM_SZ - 1);\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  GET_BI(h, bi);\n  if (bi == GC_all_nils) {\n    word hi = ADDR(h) >> (LOG_BOTTOM_SZ + LOG_HBLKSIZE);\n\n    bi = GC_all_bottom_indices_end;\n    while (bi != NULL && bi->key > hi)\n      bi = bi->desc_link;\n    j = BOTTOM_SZ - 1;\n  }\n  for (; bi != NULL; bi = bi->desc_link) {\n    while (j >= 0) {\n      hdr *hhdr = bi->index[j];\n\n      if (NULL == hhdr) {\n        --j;\n      } else if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n        j -= (GC_signed_word)ADDR(hhdr);\n      } else {\n        /* TODO: return hhdr -> hb_block instead */\n        return (struct hblk *)MAKE_CPTR(HBLK_ADDR(bi, j));\n      }\n    }\n    j = BOTTOM_SZ - 1;\n  }\n  return NULL;\n}\n"
        },
        {
          "name": "ia64_save_regs_in_stack.s",
          "type": "blob",
          "size": 0.2490234375,
          "content": "        .text\n        .align 16\n        .global GC_save_regs_in_stack\n        .proc GC_save_regs_in_stack\nGC_save_regs_in_stack:\n        .body\n        flushrs\n        ;;\n        mov r8=ar.bsp\n        br.ret.sptk.few rp\n        .endp GC_save_regs_in_stack\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "m4",
          "type": "tree",
          "content": null
        },
        {
          "name": "mach_dep.c",
          "type": "blob",
          "size": 6.654296875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#if !defined(PLATFORM_MACH_DEP) && !defined(SN_TARGET_PSP2)\n\n#  if defined(IA64) && !defined(THREADS)\nGC_INNER ptr_t GC_save_regs_ret_val = NULL;\n#  endif\n\n/* Routine to mark from registers that are preserved by the C compiler. */\n/* This must be ported to every new architecture.  It is not optional,  */\n/* and should not be used on platforms that are either UNIX-like, or    */\n/* require thread support.                                              */\n\n#  if defined(UNIX_LIKE) && !defined(STACK_NOT_SCANNED)\n#    include <signal.h>\n#    ifndef NO_GETCONTEXT\n#      if defined(DARWIN) \\\n          && (MAC_OS_X_VERSION_MAX_ALLOWED >= 1060 /*MAC_OS_X_VERSION_10_6*/)\n#        include <sys/ucontext.h>\n#      else\n#        include <ucontext.h>\n#      endif /* !DARWIN */\n#      ifdef GETCONTEXT_FPU_EXCMASK_BUG\n#        include <fenv.h>\n#      endif\n#    endif /* !NO_GETCONTEXT */\n#  endif\n\n/* Ensure that either registers are pushed, or callee-save registers    */\n/* are somewhere on the stack, and then call fn(arg, ctxt).             */\n/* ctxt is either a pointer to a ucontext_t we generated, or NULL.      */\n/* Could be called with or w/o the allocator lock held; could be called */\n/* from a signal handler as well.                                       */\nGC_ATTR_NOINLINE GC_ATTR_NO_SANITIZE_ADDR GC_INNER void\nGC_with_callee_saves_pushed(GC_with_callee_saves_func fn, ptr_t arg)\n{\n  volatile int dummy;\n  volatile ptr_t context = 0;\n#  if defined(EMSCRIPTEN) || defined(HAVE_BUILTIN_UNWIND_INIT)               \\\n      || defined(STACK_NOT_SCANNED) || (defined(NO_CRT) && defined(MSWIN32)) \\\n      || !defined(NO_UNDERSCORE_SETJMP)\n#    define volatile_arg arg\n#  else\n  /* Note: volatile to avoid \"arg might be clobbered by setjmp\"       */\n  /* warning produced by some compilers.                              */\n  volatile ptr_t volatile_arg = arg;\n#  endif\n\n#  if defined(EMSCRIPTEN) || defined(STACK_NOT_SCANNED)\n  /* No-op, \"registers\" are pushed in GC_push_other_roots().  */\n#  else\n#    if defined(UNIX_LIKE) && !defined(NO_GETCONTEXT)\n  /* Older versions of Darwin seem to lack getcontext().    */\n  /* ARM and MIPS Linux often doesn't support a real        */\n  /* getcontext().                                          */\n\n  /* The variable is set to -1 (means broken) or 1 (means it works). */\n  static signed char getcontext_works = 0;\n  ucontext_t ctxt;\n#      ifdef GETCONTEXT_FPU_EXCMASK_BUG\n  /* Workaround a bug (clearing the FPU exception mask) in        */\n  /* getcontext on Linux/x86_64.                                  */\n#        ifdef X86_64\n  /* We manipulate FPU control word here just not to force the  */\n  /* client application to use -lm linker option.               */\n  unsigned short old_fcw;\n\n#          if defined(CPPCHECK)\n  GC_noop1_ptr(&old_fcw);\n#          endif\n  __asm__ __volatile__(\"fstcw %0\" : \"=m\"(*&old_fcw));\n#        else\n  int except_mask = fegetexcept();\n#        endif\n#      endif\n\n  if (getcontext_works >= 0) {\n    if (getcontext(&ctxt) < 0) {\n      WARN(\"getcontext failed:\"\n           \" using another register retrieval method...\\n\",\n           0);\n      /* getcontext() is broken, do not try again.          */\n      /* E.g., to workaround a bug in Docker ubuntu_32bit.  */\n    } else {\n      context = (ptr_t)&ctxt;\n    }\n    if (EXPECT(0 == getcontext_works, FALSE))\n      getcontext_works = context != NULL ? 1 : -1;\n  }\n#      ifdef GETCONTEXT_FPU_EXCMASK_BUG\n#        ifdef X86_64\n  __asm__ __volatile__(\"fldcw %0\" : : \"m\"(*&old_fcw));\n  {\n    unsigned mxcsr;\n    /* And now correct the exception mask in SSE MXCSR. */\n    __asm__ __volatile__(\"stmxcsr %0\" : \"=m\"(*&mxcsr));\n    mxcsr = (mxcsr & ~(FE_ALL_EXCEPT << 7)) | ((old_fcw & FE_ALL_EXCEPT) << 7);\n    __asm__ __volatile__(\"ldmxcsr %0\" : : \"m\"(*&mxcsr));\n  }\n#        else /* !X86_64 */\n  if (feenableexcept(except_mask) < 0)\n    ABORT(\"feenableexcept failed\");\n#        endif\n#      endif /* GETCONTEXT_FPU_EXCMASK_BUG */\n#      if defined(IA64) || defined(SPARC)\n  /* On a register window machine, we need to save register       */\n  /* contents on the stack for this to work.  This may already be */\n  /* subsumed by the getcontext() call.                           */\n#        if defined(IA64) && !defined(THREADS)\n  GC_save_regs_ret_val =\n#        endif\n      GC_save_regs_in_stack();\n#      endif\n  if (NULL == context) /* getcontext failed */\n#    endif /* !NO_GETCONTEXT */\n  {\n#    if defined(HAVE_BUILTIN_UNWIND_INIT)\n    /* This was suggested by Richard Henderson as the way to        */\n    /* force callee-save registers and register windows onto        */\n    /* the stack.                                                   */\n    __builtin_unwind_init();\n#    elif defined(NO_CRT) && defined(MSWIN32)\n    CONTEXT ctx;\n\n    RtlCaptureContext(&ctx);\n#    else\n    /* Generic code.                         */\n    /* The idea is due to Parag Patel at HP. */\n    /* We're not sure whether he would like  */\n    /* to be acknowledged for it or not.     */\n    jmp_buf regs;\n\n    /* setjmp doesn't always clear all of the buffer.       */\n    /* That tends to preserve garbage.  Clear it.           */\n    BZERO(regs, sizeof(regs));\n#      ifdef NO_UNDERSCORE_SETJMP\n    (void)setjmp(regs);\n#      else\n    /* We do not want to mess with signals.  According to */\n    /* SUSV3, setjmp() may or may not save signal mask.   */\n    /* _setjmp won't, but is less portable.               */\n    (void)_setjmp(regs);\n#      endif\n#    endif\n  }\n#  endif\n  /* TODO: context here is sometimes just zero.  At the moment, the     */\n  /* callees don't really need it.                                      */\n  /* Cast fn to a volatile type to prevent call inlining.               */\n  (*(GC_with_callee_saves_func volatile *)&fn)(\n      volatile_arg, CAST_AWAY_VOLATILE_PVOID(context));\n  /* Strongly discourage the compiler from treating the above   */\n  /* as a tail-call, since that would pop the register          */\n  /* contents before we get a chance to look at them.           */\n  GC_noop1(COVERT_DATAFLOW(ADDR(&dummy)));\n#  undef volatile_arg\n}\n\n#endif /* !PLATFORM_MACH_DEP && !SN_TARGET_PSP2 */\n"
        },
        {
          "name": "malloc.c",
          "type": "blob",
          "size": 22.41015625,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1999-2004 Hewlett-Packard Development Company, L.P.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#include <string.h>\n\n/* Allocate reclaim list for the kind.  Returns TRUE on success.        */\nSTATIC GC_bool\nGC_alloc_reclaim_list(struct obj_kind *ok)\n{\n  struct hblk **result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  result = (struct hblk **)GC_scratch_alloc((MAXOBJGRANULES + 1)\n                                            * sizeof(struct hblk *));\n  if (EXPECT(NULL == result, FALSE))\n    return FALSE;\n\n  BZERO(result, (MAXOBJGRANULES + 1) * sizeof(struct hblk *));\n  ok->ok_reclaim_list = result;\n  return TRUE;\n}\n\n/* Allocate a large block of size lb_adjusted bytes with the requested  */\n/* alignment (align_m1 plus one).  The block is not cleared.  We assume */\n/* that the size is non-zero and a multiple of GC_GRANULE_BYTES, and    */\n/* that it already includes EXTRA_BYTES value.  The flags argument      */\n/* should be IGNORE_OFF_PAGE or 0.  Calls GC_allochblk() to do the      */\n/* actual allocation, but also triggers collection and/or heap          */\n/* expansion as appropriate.  Updates value of GC_bytes_allocd; does    */\n/* also other accounting.                                               */\nSTATIC ptr_t\nGC_alloc_large(size_t lb_adjusted, int k, unsigned flags, size_t align_m1)\n{\n  struct hblk *h;\n  size_t n_blocks; /* includes alignment */\n  ptr_t result = NULL;\n  GC_bool retry = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(lb_adjusted != 0 && (lb_adjusted & (GC_GRANULE_BYTES - 1)) == 0);\n  n_blocks = OBJ_SZ_TO_BLOCKS_CHECKED(SIZET_SAT_ADD(lb_adjusted, align_m1));\n  if (!EXPECT(GC_is_initialized, TRUE)) {\n    UNLOCK(); /* just to unset GC_lock_holder */\n    GC_init();\n    LOCK();\n  }\n  /* Do our share of marking work.    */\n  if (GC_incremental && !GC_dont_gc) {\n    ENTER_GC();\n    GC_collect_a_little_inner(n_blocks);\n    EXIT_GC();\n  }\n\n  h = GC_allochblk(lb_adjusted, k, flags, align_m1);\n#ifdef USE_MUNMAP\n  if (NULL == h) {\n    GC_merge_unmapped();\n    h = GC_allochblk(lb_adjusted, k, flags, align_m1);\n  }\n#endif\n  while (NULL == h && GC_collect_or_expand(n_blocks, flags, retry)) {\n    h = GC_allochblk(lb_adjusted, k, flags, align_m1);\n    retry = TRUE;\n  }\n  if (EXPECT(h != NULL, TRUE)) {\n    GC_bytes_allocd += lb_adjusted;\n    if (lb_adjusted > HBLKSIZE) {\n      GC_large_allocd_bytes += HBLKSIZE * OBJ_SZ_TO_BLOCKS(lb_adjusted);\n      if (GC_large_allocd_bytes > GC_max_large_allocd_bytes)\n        GC_max_large_allocd_bytes = GC_large_allocd_bytes;\n    }\n    /* FIXME: Do we need some way to reset GC_max_large_allocd_bytes? */\n    result = h->hb_body;\n    GC_ASSERT((ADDR(result) & align_m1) == 0);\n  }\n  return result;\n}\n\n/* Allocate a large block of given size in bytes, clear it if   */\n/* appropriate.  We assume that the size is non-zero and        */\n/* a multiple of GC_GRANULE_BYTES, and that it already includes */\n/* EXTRA_BYTES value.  Update value of GC_bytes_allocd.         */\nSTATIC ptr_t\nGC_alloc_large_and_clear(size_t lb_adjusted, int k, unsigned flags)\n{\n  ptr_t result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  result = GC_alloc_large(lb_adjusted, k, flags, 0 /* align_m1 */);\n  if (EXPECT(result != NULL, TRUE)\n      && (GC_debugging_started || GC_obj_kinds[k].ok_init)) {\n    /* Clear the whole block, in case of GC_realloc call. */\n    BZERO(result, HBLKSIZE * OBJ_SZ_TO_BLOCKS(lb_adjusted));\n  }\n  return result;\n}\n\n/* Fill in additional entries in GC_size_map, including the i-th one.   */\n/* Note that a filled in section of the array ending at n always        */\n/* has the length of at least n/4.                                      */\nSTATIC void\nGC_extend_size_map(size_t i)\n{\n  size_t original_lg = ALLOC_REQUEST_GRANS(i);\n  size_t lg;\n  /* The size we try to preserve.  Close to i, unless this would        */\n  /* introduce too many distinct sizes.                                 */\n  size_t byte_sz = GRANULES_TO_BYTES(original_lg);\n  size_t smaller_than_i = byte_sz - (byte_sz >> 3);\n  /* The lowest indexed entry we initialize.    */\n  size_t low_limit;\n  size_t number_of_objs;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(0 == GC_size_map[i]);\n  if (0 == GC_size_map[smaller_than_i]) {\n    low_limit = byte_sz - (byte_sz >> 2); /* much smaller than i */\n    lg = original_lg;\n    while (GC_size_map[low_limit] != 0)\n      low_limit++;\n  } else {\n    low_limit = smaller_than_i + 1;\n    while (GC_size_map[low_limit] != 0)\n      low_limit++;\n\n    lg = ALLOC_REQUEST_GRANS(low_limit);\n    lg += lg >> 3;\n    if (lg < original_lg)\n      lg = original_lg;\n  }\n\n  /* For these larger sizes, we use an even number of granules.         */\n  /* This makes it easier to, e.g., construct a 16-byte-aligned         */\n  /* allocator even if GC_GRANULE_BYTES is 8.                           */\n  lg = (lg + 1) & ~(size_t)1;\n  if (lg > MAXOBJGRANULES)\n    lg = MAXOBJGRANULES;\n\n  /* If we can fit the same number of larger objects in a block, do so. */\n  GC_ASSERT(lg != 0);\n  number_of_objs = HBLK_GRANULES / lg;\n  GC_ASSERT(number_of_objs != 0);\n  lg = (HBLK_GRANULES / number_of_objs) & ~(size_t)1;\n\n  /* We may need one extra byte; do not always fill in  */\n  /* GC_size_map[byte_sz].                              */\n  byte_sz = GRANULES_TO_BYTES(lg) - EXTRA_BYTES;\n\n  for (; low_limit <= byte_sz; low_limit++)\n    GC_size_map[low_limit] = lg;\n}\n\nSTATIC void *\nGC_generic_malloc_inner_small(size_t lb, int k)\n{\n  struct obj_kind *ok = &GC_obj_kinds[k];\n  size_t lg = GC_size_map[lb];\n  void **opp = &ok->ok_freelist[lg];\n  void *op = *opp;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (EXPECT(NULL == op, FALSE)) {\n    if (0 == lg) {\n      if (!EXPECT(GC_is_initialized, TRUE)) {\n        UNLOCK(); /* just to unset GC_lock_holder */\n        GC_init();\n        LOCK();\n        lg = GC_size_map[lb];\n      }\n      if (0 == lg) {\n        GC_extend_size_map(lb);\n        lg = GC_size_map[lb];\n        GC_ASSERT(lg != 0);\n      }\n      /* Retry. */\n      opp = &ok->ok_freelist[lg];\n      op = *opp;\n    }\n    if (NULL == op) {\n      if (NULL == ok->ok_reclaim_list && !GC_alloc_reclaim_list(ok))\n        return NULL;\n      op = GC_allocobj(lg, k);\n      if (NULL == op)\n        return NULL;\n    }\n  }\n  *opp = obj_link(op);\n  obj_link(op) = NULL;\n  GC_bytes_allocd += GRANULES_TO_BYTES((word)lg);\n  return op;\n}\n\nGC_INNER void *\nGC_generic_malloc_inner(size_t lb, int k, unsigned flags)\n{\n  size_t lb_adjusted;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(k < MAXOBJKINDS);\n  if (SMALL_OBJ(lb)) {\n    return GC_generic_malloc_inner_small(lb, k);\n  }\n\n#if MAX_EXTRA_BYTES > 0\n  if ((flags & IGNORE_OFF_PAGE) != 0 && lb >= HBLKSIZE) {\n    /* No need to add EXTRA_BYTES.  */\n    lb_adjusted = lb;\n  } else\n#endif\n  /* else */ {\n    lb_adjusted = ADD_EXTRA_BYTES(lb);\n  }\n  return GC_alloc_large_and_clear(ROUNDUP_GRANULE_SIZE(lb_adjusted), k, flags);\n}\n\n#ifdef GC_COLLECT_AT_MALLOC\n#  if defined(CPPCHECK)\nsize_t GC_dbg_collect_at_malloc_min_lb = 16 * 1024; /* e.g. */\n#  else\nsize_t GC_dbg_collect_at_malloc_min_lb = (GC_COLLECT_AT_MALLOC);\n#  endif\n#endif\n\nGC_INNER void *\nGC_generic_malloc_aligned(size_t lb, int k, unsigned flags, size_t align_m1)\n{\n  void *result;\n\n  GC_ASSERT(k < MAXOBJKINDS);\n  if (EXPECT(get_have_errors(), FALSE))\n    GC_print_all_errors();\n  GC_INVOKE_FINALIZERS();\n  GC_DBG_COLLECT_AT_MALLOC(lb);\n  if (SMALL_OBJ(lb) && EXPECT(align_m1 < GC_GRANULE_BYTES, TRUE)) {\n    LOCK();\n    result = GC_generic_malloc_inner_small(lb, k);\n    UNLOCK();\n  } else {\n#ifdef THREADS\n    size_t lg;\n#endif\n    size_t lb_adjusted;\n    GC_bool init;\n\n#if MAX_EXTRA_BYTES > 0\n    if ((flags & IGNORE_OFF_PAGE) != 0 && lb >= HBLKSIZE) {\n      /* No need to add EXTRA_BYTES.      */\n      lb_adjusted = ROUNDUP_GRANULE_SIZE(lb);\n#  ifdef THREADS\n      lg = BYTES_TO_GRANULES(lb_adjusted);\n#  endif\n    } else\n#endif\n    /* else */ {\n#ifndef THREADS\n      size_t lg; /* CPPCHECK */\n#endif\n\n      if (EXPECT(0 == lb, FALSE))\n        lb = 1;\n      lg = ALLOC_REQUEST_GRANS(lb);\n      lb_adjusted = GRANULES_TO_BYTES(lg);\n    }\n\n    init = GC_obj_kinds[k].ok_init;\n    if (EXPECT(align_m1 < GC_GRANULE_BYTES, TRUE)) {\n      align_m1 = 0;\n    } else if (align_m1 < HBLKSIZE) {\n      align_m1 = HBLKSIZE - 1;\n    }\n    LOCK();\n    result = GC_alloc_large(lb_adjusted, k, flags, align_m1);\n    if (EXPECT(result != NULL, TRUE)) {\n      if (GC_debugging_started\n#ifndef THREADS\n          || init\n#endif\n      ) {\n        BZERO(result, HBLKSIZE * OBJ_SZ_TO_BLOCKS(lb_adjusted));\n      } else {\n#ifdef THREADS\n        GC_ASSERT(GRANULES_TO_PTRS(lg) >= 2);\n        /* Clear any memory that might be used for GC descriptors */\n        /* before we release the allocator lock.                  */\n        ((ptr_t *)result)[0] = NULL;\n        ((ptr_t *)result)[1] = NULL;\n        ((ptr_t *)result)[GRANULES_TO_PTRS(lg) - 1] = NULL;\n        ((ptr_t *)result)[GRANULES_TO_PTRS(lg) - 2] = NULL;\n#endif\n      }\n    }\n    UNLOCK();\n#ifdef THREADS\n    if (init && !GC_debugging_started && result != NULL) {\n      /* Clear the rest (i.e. excluding the initial 2 words). */\n      BZERO((ptr_t *)result + 2,\n            HBLKSIZE * OBJ_SZ_TO_BLOCKS(lb_adjusted) - 2 * sizeof(ptr_t));\n    }\n#endif\n  }\n  if (EXPECT(NULL == result, FALSE)) {\n    result = (*GC_get_oom_fn())(lb);\n    /* Note: result might be misaligned.      */\n  }\n  return result;\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_generic_malloc(size_t lb, int k)\n{\n  return GC_generic_malloc_aligned(lb, k, 0 /* flags */, 0 /* align_m1 */);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_kind_global(size_t lb, int k)\n{\n  return GC_malloc_kind_aligned_global(lb, k, 0 /* align_m1 */);\n}\n\nGC_INNER void *\nGC_malloc_kind_aligned_global(size_t lb, int k, size_t align_m1)\n{\n  GC_ASSERT(k < MAXOBJKINDS);\n  if (SMALL_OBJ(lb) && EXPECT(align_m1 < HBLKSIZE / 2, TRUE)) {\n    void *op;\n    void **opp;\n    size_t lg;\n\n    GC_DBG_COLLECT_AT_MALLOC(lb);\n    LOCK();\n    lg = GC_size_map[lb];\n    opp = &GC_obj_kinds[k].ok_freelist[lg];\n    op = *opp;\n    if (EXPECT(align_m1 >= GC_GRANULE_BYTES, FALSE)) {\n      /* TODO: Avoid linear search. */\n      for (; (ADDR(op) & align_m1) != 0; op = *opp) {\n        opp = &obj_link(op);\n      }\n    }\n    if (EXPECT(op != NULL, TRUE)) {\n      GC_ASSERT(PTRFREE == k || NULL == obj_link(op)\n                || (ADDR(obj_link(op)) < GC_greatest_real_heap_addr\n                    && GC_least_real_heap_addr < ADDR(obj_link(op))));\n      *opp = obj_link(op);\n      if (k != PTRFREE)\n        obj_link(op) = NULL;\n      GC_bytes_allocd += GRANULES_TO_BYTES((word)lg);\n      UNLOCK();\n      GC_ASSERT((ADDR(op) & align_m1) == 0);\n      return op;\n    }\n    UNLOCK();\n  }\n\n  /* We make the GC_clear_stack() call a tail one, hoping to get more */\n  /* of the stack.                                                    */\n  return GC_clear_stack(\n      GC_generic_malloc_aligned(lb, k, 0 /* flags */, align_m1));\n}\n\n#if defined(THREADS) && !defined(THREAD_LOCAL_ALLOC)\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_kind(size_t lb, int k)\n{\n  return GC_malloc_kind_global(lb, k);\n}\n#endif\n\n/* Allocate lb bytes of atomic (pointer-free) data.     */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_atomic(size_t lb)\n{\n  return GC_malloc_kind(lb, PTRFREE);\n}\n\n/* Allocate lb bytes of composite (pointerful) data.    */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc(size_t lb)\n{\n  return GC_malloc_kind(lb, NORMAL);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_generic_malloc_uncollectable(size_t lb, int k)\n{\n  void *op;\n  size_t lb_orig = lb;\n\n  GC_ASSERT(k < MAXOBJKINDS);\n  if (EXTRA_BYTES != 0 && EXPECT(lb != 0, TRUE)) {\n    /* We do not need the extra byte, since this will not be          */\n    /* collected anyway.                                              */\n    lb--;\n  }\n\n  if (SMALL_OBJ(lb)) {\n    void **opp;\n    size_t lg;\n\n    if (EXPECT(get_have_errors(), FALSE))\n      GC_print_all_errors();\n    GC_INVOKE_FINALIZERS();\n    GC_DBG_COLLECT_AT_MALLOC(lb_orig);\n    LOCK();\n    lg = GC_size_map[lb];\n    opp = &GC_obj_kinds[k].ok_freelist[lg];\n    op = *opp;\n    if (EXPECT(op != NULL, TRUE)) {\n      *opp = obj_link(op);\n      obj_link(op) = 0;\n      GC_bytes_allocd += GRANULES_TO_BYTES((word)lg);\n      /* Mark bit was already set on free list.  It will be       */\n      /* cleared only temporarily during a collection, as a       */\n      /* result of the normal free-list mark bit clearing.        */\n      GC_non_gc_bytes += GRANULES_TO_BYTES((word)lg);\n    } else {\n      op = GC_generic_malloc_inner_small(lb, k);\n      if (NULL == op) {\n        GC_oom_func oom_fn = GC_oom_fn;\n        UNLOCK();\n        return (*oom_fn)(lb_orig);\n      }\n      /* For small objects, the free lists are completely marked. */\n    }\n    GC_ASSERT(GC_is_marked(op));\n    UNLOCK();\n  } else {\n    op = GC_generic_malloc_aligned(lb, k, 0 /* flags */, 0 /* align_m1 */);\n    if (op /* != NULL */) { /* CPPCHECK */\n      hdr *hhdr = HDR(op);\n\n      GC_ASSERT(HBLKDISPL(op) == 0); /* large block */\n\n      /* We do not need to acquire the allocator lock before HDR(op), */\n      /* since we have an undisguised pointer, but we need it while   */\n      /* we adjust the mark bits.                                     */\n      LOCK();\n      set_mark_bit_from_hdr(hhdr, 0); /* Only object. */\n#ifndef THREADS\n      /* This is not guaranteed in the multi-threaded case because  */\n      /* the counter could be updated before locking.               */\n      GC_ASSERT(hhdr->hb_n_marks == 0);\n#endif\n      hhdr->hb_n_marks = 1;\n      UNLOCK();\n    }\n  }\n  return op;\n}\n\n/* Allocate lb bytes of pointerful, traced, but not collectible data.   */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_uncollectable(size_t lb)\n{\n  return GC_generic_malloc_uncollectable(lb, UNCOLLECTABLE);\n}\n\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n/* Allocate lb bytes of pointer-free, untraced, uncollectible data    */\n/* This is normally roughly equivalent to the system malloc.          */\n/* But it may be useful if malloc is redefined.                       */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_atomic_uncollectable(size_t lb)\n{\n  return GC_generic_malloc_uncollectable(lb, AUNCOLLECTABLE);\n}\n#endif /* GC_ATOMIC_UNCOLLECTABLE */\n\n#if defined(REDIRECT_MALLOC) && !defined(REDIRECT_MALLOC_IN_HEADER)\n\n#  ifndef MSWINCE\n#    include <errno.h>\n#  endif\n\n/* Avoid unnecessary nested procedure calls here, by #defining some   */\n/* malloc replacements.  Otherwise we end up saving a meaningless     */\n/* return address in the object.  It also speeds things up, but it is */\n/* admittedly quite ugly.                                             */\n#  define GC_debug_malloc_replacement(lb) GC_debug_malloc(lb, GC_DBG_EXTRAS)\n\n#  if defined(CPPCHECK)\n#    define REDIRECT_MALLOC_F GC_malloc /* e.g. */\n#  else\n#    define REDIRECT_MALLOC_F REDIRECT_MALLOC\n#  endif\n\nvoid *\nmalloc(size_t lb)\n{\n  /* It might help to manually inline the GC_malloc call here.        */\n  /* But any decent compiler should reduce the extra procedure call   */\n  /* to at most a jump instruction in this case.                      */\n#  if defined(SOLARIS) && defined(THREADS) && defined(I386)\n  /* Thread initialization can call malloc before we are ready for. */\n  /* It is not clear that this is enough to help matters.           */\n  /* The thread implementation may well call malloc at other        */\n  /* inopportune times.                                             */\n  if (!EXPECT(GC_is_initialized, TRUE))\n    return sbrk(lb);\n#  endif\n  return (void *)REDIRECT_MALLOC_F(lb);\n}\n\n#  ifdef REDIR_MALLOC_AND_LINUXTHREADS\n#    ifdef HAVE_LIBPTHREAD_SO\nSTATIC ptr_t GC_libpthread_start = NULL;\nSTATIC ptr_t GC_libpthread_end = NULL;\n#    endif\nSTATIC ptr_t GC_libld_start = NULL;\nSTATIC ptr_t GC_libld_end = NULL;\nstatic GC_bool lib_bounds_set = FALSE;\n\nGC_INNER void\nGC_init_lib_bounds(void)\n{\n  IF_CANCEL(int cancel_state;)\n\n  /* This test does not need to ensure memory visibility, since     */\n  /* the bounds will be set when/if we create another thread.       */\n  if (EXPECT(lib_bounds_set, TRUE))\n    return;\n\n  DISABLE_CANCEL(cancel_state);\n  GC_init(); /* if not called yet */\n\n#    if defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED)\n  LOCK(); /* just to set GC_lock_holder */\n#    endif\n#    ifdef HAVE_LIBPTHREAD_SO\n  if (!GC_text_mapping(\"libpthread-\", &GC_libpthread_start,\n                       &GC_libpthread_end)) {\n    WARN(\"Failed to find libpthread.so text mapping: Expect crash\\n\", 0);\n    /* This might still work with some versions of libpthread,    */\n    /* so we do not abort.                                        */\n  }\n#    endif\n  if (!GC_text_mapping(\"ld-\", &GC_libld_start, &GC_libld_end)) {\n    WARN(\"Failed to find ld.so text mapping: Expect crash\\n\", 0);\n  }\n#    if defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED)\n  UNLOCK();\n#    endif\n  RESTORE_CANCEL(cancel_state);\n  lib_bounds_set = TRUE;\n}\n#  endif /* REDIR_MALLOC_AND_LINUXTHREADS */\n\nvoid *\ncalloc(size_t n, size_t lb)\n{\n  if (EXPECT((lb | n) > GC_SQRT_SIZE_MAX, FALSE) /* fast initial test */\n      && lb && n > GC_SIZE_MAX / lb)\n    return (*GC_get_oom_fn())(GC_SIZE_MAX); /* n*lb overflow */\n#  ifdef REDIR_MALLOC_AND_LINUXTHREADS\n  /* The linker may allocate some memory that is only pointed to by */\n  /* mmapped thread stacks.  Make sure it is not collectible.       */\n  {\n    ptr_t caller = (ptr_t)__builtin_return_address(0);\n\n    GC_init_lib_bounds();\n    if (ADDR_INSIDE(caller, GC_libld_start, GC_libld_end)\n#    ifdef HAVE_LIBPTHREAD_SO\n        /* Note: the two ranges are actually usually adjacent, so */\n        /* there may be a way to speed this up.                   */\n        || ADDR_INSIDE(caller, GC_libpthread_start, GC_libpthread_end)\n#    endif\n    ) {\n      return GC_generic_malloc_uncollectable(n * lb, UNCOLLECTABLE);\n    }\n  }\n#  endif\n  return (void *)REDIRECT_MALLOC_F(n * lb);\n}\n\n#  ifndef strdup\nchar *\nstrdup(const char *s)\n{\n  size_t lb = strlen(s) + 1;\n  char *result = (char *)REDIRECT_MALLOC_F(lb);\n\n  if (EXPECT(NULL == result, FALSE)) {\n    errno = ENOMEM;\n    return NULL;\n  }\n  BCOPY(s, result, lb);\n  return result;\n}\n#  else\n/* If strdup is macro defined, we assume that it actually calls     */\n/* malloc, and thus the right thing will happen even without        */\n/* overriding it.  This seems to be true on most Linux systems.     */\n#  endif /* strdup */\n\n#  ifndef strndup\n/* This is similar to strdup().     */\nchar *\nstrndup(const char *str, size_t size)\n{\n  char *copy;\n  size_t len = strlen(str);\n  if (EXPECT(len > size, FALSE))\n    len = size;\n  copy = (char *)REDIRECT_MALLOC_F(len + 1);\n  if (EXPECT(NULL == copy, FALSE)) {\n    errno = ENOMEM;\n    return NULL;\n  }\n  if (EXPECT(len > 0, TRUE))\n    BCOPY(str, copy, len);\n  copy[len] = '\\0';\n  return copy;\n}\n#  endif /* !strndup */\n\n#  undef GC_debug_malloc_replacement\n\n#endif /* REDIRECT_MALLOC */\n\n/* Explicitly deallocate the object.  hhdr should correspond to p.      */\nstatic void\nfree_internal(void *p, const hdr *hhdr)\n{\n  size_t lb = hhdr->hb_sz;           /* size in bytes */\n  size_t lg = BYTES_TO_GRANULES(lb); /* size in granules */\n  int k = hhdr->hb_obj_kind;\n\n  GC_bytes_freed += lb;\n  if (IS_UNCOLLECTABLE(k))\n    GC_non_gc_bytes -= lb;\n  if (EXPECT(lg <= MAXOBJGRANULES, TRUE)) {\n    struct obj_kind *ok = &GC_obj_kinds[k];\n    void **flh;\n\n    /* It is unnecessary to clear the mark bit.  If the object is       */\n    /* reallocated, it does not matter.  Otherwise, the collector will  */\n    /* do it, since it is on a free list.                               */\n    if (ok->ok_init && EXPECT(lb > sizeof(ptr_t), TRUE)) {\n      BZERO((ptr_t *)p + 1, lb - sizeof(ptr_t));\n    }\n\n    flh = &ok->ok_freelist[lg];\n    obj_link(p) = *flh;\n    *flh = (ptr_t)p;\n  } else {\n    if (lb > HBLKSIZE) {\n      GC_large_allocd_bytes -= HBLKSIZE * OBJ_SZ_TO_BLOCKS(lb);\n    }\n    GC_ASSERT(ADDR(HBLKPTR(p)) == ADDR(hhdr->hb_block));\n    GC_freehblk(hhdr->hb_block);\n  }\n}\n\nGC_API void GC_CALL\nGC_free(void *p)\n{\n  const hdr *hhdr;\n\n  if (p /* != NULL */) {\n    /* CPPCHECK */\n  } else {\n    /* Required by ANSI.  It's not my fault ...     */\n    return;\n  }\n\n#ifdef LOG_ALLOCS\n  GC_log_printf(\"GC_free(%p) after GC #%lu\\n\", p, (unsigned long)GC_gc_no);\n#endif\n  hhdr = HDR(p);\n#if defined(REDIRECT_MALLOC)                                           \\\n    && ((defined(NEED_CALLINFO) && defined(GC_HAVE_BUILTIN_BACKTRACE)) \\\n        || defined(REDIR_MALLOC_AND_LINUXTHREADS)                      \\\n        || (defined(SOLARIS) && defined(THREADS)) || defined(MSWIN32))\n  /* This might be called indirectly by GC_print_callers to free  */\n  /* the result of backtrace_symbols.                             */\n  /* For Solaris, we have to redirect malloc calls during         */\n  /* initialization.  For the others, this seems to happen        */\n  /* implicitly.                                                  */\n  /* Don't try to deallocate that memory.                         */\n  if (EXPECT(NULL == hhdr, FALSE))\n    return;\n#endif\n  GC_ASSERT(GC_base(p) == p);\n  LOCK();\n  free_internal(p, hhdr);\n  FREE_PROFILER_HOOK(p);\n  UNLOCK();\n}\n\n#ifdef THREADS\nGC_INNER void\nGC_free_inner(void *p)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  free_internal(p, HDR(p));\n}\n#endif /* THREADS */\n\n#if defined(REDIRECT_MALLOC) && !defined(REDIRECT_FREE)\n#  define REDIRECT_FREE GC_free\n#endif\n\n#if defined(REDIRECT_FREE) && !defined(REDIRECT_MALLOC_IN_HEADER)\n\n#  if defined(CPPCHECK)\n#    define REDIRECT_FREE_F GC_free /* e.g. */\n#  else\n#    define REDIRECT_FREE_F REDIRECT_FREE\n#  endif\n\nvoid\nfree(void *p)\n{\n#  ifdef IGNORE_FREE\n  UNUSED_ARG(p);\n#  else\n#    if defined(REDIR_MALLOC_AND_LINUXTHREADS) \\\n        && !defined(USE_PROC_FOR_LIBRARIES)\n  /* Don't bother with initialization checks.  If nothing         */\n  /* has been initialized, the check fails, and that's safe,      */\n  /* since we have not allocated uncollectible objects neither.   */\n  ptr_t caller = (ptr_t)__builtin_return_address(0);\n  /* This test does not need to ensure memory visibility, since   */\n  /* the bounds will be set when/if we create another thread.     */\n  if (ADDR_INSIDE(caller, GC_libld_start, GC_libld_end)\n#      ifdef HAVE_LIBPTHREAD_SO\n      || ADDR_INSIDE(caller, GC_libpthread_start, GC_libpthread_end)\n#      endif\n  ) {\n    GC_free(p);\n    return;\n  }\n#    endif\n  REDIRECT_FREE_F(p);\n#  endif\n}\n#endif /* REDIRECT_FREE */\n"
        },
        {
          "name": "mallocx.c",
          "type": "blob",
          "size": 18.1435546875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 2000 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2009-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/*\n * These are extra allocation routines which are likely to be less\n * frequently used than those in malloc.c.  They are separate in the\n * hope that the .o file will be excluded from statically linked\n * executables.  We should probably break this up further.\n */\n\n#include <string.h>\n\n#ifndef MSWINCE\n#  include <errno.h>\n#endif\n\n/* Some externally visible but unadvertised variables to allow access to */\n/* free lists from inlined allocators without including gc_priv.h        */\n/* or introducing dependencies on internal data structure layouts.       */\n#include \"private/gc_alloc_ptrs.h\"\nvoid **const GC_objfreelist_ptr = GC_objfreelist;\nvoid **const GC_aobjfreelist_ptr = GC_aobjfreelist;\nvoid **const GC_uobjfreelist_ptr = GC_uobjfreelist;\n#ifdef GC_ATOMIC_UNCOLLECTABLE\nvoid **const GC_auobjfreelist_ptr = GC_auobjfreelist;\n#endif\n\nGC_API int GC_CALL\nGC_get_kind_and_size(const void *p, size_t *psize)\n{\n  const hdr *hhdr = HDR(p);\n\n  if (psize != NULL) {\n    *psize = hhdr->hb_sz;\n  }\n  return hhdr->hb_obj_kind;\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_generic_or_special_malloc(size_t lb, int k)\n{\n  switch (k) {\n  case PTRFREE:\n  case NORMAL:\n    return GC_malloc_kind(lb, k);\n  case UNCOLLECTABLE:\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n  case AUNCOLLECTABLE:\n#endif\n    return GC_generic_malloc_uncollectable(lb, k);\n  default:\n    return GC_generic_malloc_aligned(lb, k, 0 /* flags */, 0);\n  }\n}\n\n/* Change the size of the block pointed to by p to contain at least   */\n/* lb bytes.  The object may be (and quite likely will be) moved.     */\n/* The kind (e.g. atomic) is the same as that of the old.             */\n/* Shrinking of large blocks is not implemented well.                 */\nGC_API void *GC_CALL\nGC_realloc(void *p, size_t lb)\n{\n  hdr *hhdr;\n  void *result;\n#if defined(_FORTIFY_SOURCE) && defined(__GNUC__) && !defined(__clang__)\n  /* Use cleared_p instead of p as a workaround to avoid        */\n  /* passing alloc_size(lb) attribute associated with p to      */\n  /* memset (including a memset call inside GC_free).           */\n  volatile GC_uintptr_t cleared_p = (GC_uintptr_t)p;\n#else\n#  define cleared_p p\n#endif\n  size_t sz;      /* current size in bytes */\n  size_t orig_sz; /* original sz (in bytes) */\n  int obj_kind;\n\n  if (NULL == p) {\n    /* Required by ANSI.      */\n    return GC_malloc(lb);\n  }\n  if (0 == lb) /* and p != NULL */ {\n#ifndef IGNORE_FREE\n    GC_free(p);\n#endif\n    return NULL;\n  }\n  hhdr = HDR(HBLKPTR(p));\n  sz = hhdr->hb_sz;\n  obj_kind = hhdr->hb_obj_kind;\n  orig_sz = sz;\n\n  if (sz > MAXOBJBYTES) {\n    const struct obj_kind *ok = &GC_obj_kinds[obj_kind];\n    word descr = ok->ok_descriptor;\n\n    /* Round it up to the next whole heap block.    */\n    sz = (sz + HBLKSIZE - 1) & ~(HBLKSIZE - 1);\n#if ALIGNMENT > GC_DS_TAGS\n    /* An extra byte is not added in case of ignore-off-page  */\n    /* allocated objects not smaller than HBLKSIZE.           */\n    GC_ASSERT(sz >= HBLKSIZE);\n    if (EXTRA_BYTES != 0 && (hhdr->hb_flags & IGNORE_OFF_PAGE) != 0\n        && obj_kind == NORMAL)\n      descr += ALIGNMENT; /* or set to 0 */\n#endif\n    if (ok->ok_relocate_descr)\n      descr += sz;\n      /* GC_realloc might be changing the block size while            */\n      /* GC_reclaim_block or GC_clear_hdr_marks is examining it.      */\n      /* The change to the size field is benign, in that GC_reclaim   */\n      /* (and GC_clear_hdr_marks) would work correctly with either    */\n      /* value, since we are not changing the number of objects in    */\n      /* the block.  But seeing a half-updated value (though unlikely */\n      /* to occur in practice) could be probably bad.                 */\n      /* Using unordered atomic accesses on the size and hb_descr     */\n      /* fields would solve the issue.  (The alternate solution might */\n      /* be to initially overallocate large objects, so we do not     */\n      /* have to adjust the size in GC_realloc, if they still fit.    */\n      /* But that is probably more expensive, since we may end up     */\n      /* scanning a bunch of zeros during GC.)                        */\n#ifdef AO_HAVE_store\n    AO_store(&hhdr->hb_sz, sz);\n    AO_store((AO_t *)&hhdr->hb_descr, descr);\n#else\n    {\n      LOCK();\n      hhdr->hb_sz = sz;\n      hhdr->hb_descr = descr;\n      UNLOCK();\n    }\n#endif\n\n#ifdef MARK_BIT_PER_OBJ\n    GC_ASSERT(hhdr->hb_inv_sz == LARGE_INV_SZ);\n#else\n    GC_ASSERT((hhdr->hb_flags & LARGE_BLOCK) != 0\n              && hhdr->hb_map[ANY_INDEX] == 1);\n#endif\n    if (IS_UNCOLLECTABLE(obj_kind))\n      GC_non_gc_bytes += (sz - orig_sz);\n    /* Extra area is already cleared by GC_alloc_large_and_clear. */\n  }\n  if (ADD_EXTRA_BYTES(lb) <= sz) {\n    if (lb >= (sz >> 1)) {\n      if (orig_sz > lb) {\n        /* Clear unneeded part of object to avoid bogus pointer */\n        /* tracing.                                             */\n        BZERO((ptr_t)cleared_p + lb, orig_sz - lb);\n      }\n      return p;\n    }\n    /* Shrink it.   */\n    sz = lb;\n  }\n  result = GC_generic_or_special_malloc((word)lb, obj_kind);\n  if (EXPECT(result != NULL, TRUE)) {\n    /* In case of shrink, it could also return original object.       */\n    /* But this gives the client warning of imminent disaster.        */\n    BCOPY(p, result, sz);\n#ifndef IGNORE_FREE\n    GC_free((ptr_t)cleared_p);\n#endif\n  }\n  return result;\n#undef cleared_p\n}\n\n#if defined(REDIRECT_MALLOC) && !defined(REDIRECT_REALLOC)\n#  define REDIRECT_REALLOC GC_realloc\n#endif\n\n#ifdef REDIRECT_REALLOC\n\n/* As with malloc, avoid two levels of extra calls here.        */\n#  define GC_debug_realloc_replacement(p, lb) \\\n    GC_debug_realloc(p, lb, GC_DBG_EXTRAS)\n\n#  if !defined(REDIRECT_MALLOC_IN_HEADER)\nvoid *\nrealloc(void *p, size_t lb)\n{\n  return REDIRECT_REALLOC(p, lb);\n}\n#  endif\n\n#  undef GC_debug_realloc_replacement\n#endif /* REDIRECT_REALLOC */\n\n/* Allocate memory such that only pointers to near the beginning of */\n/* the object are considered.  We avoid holding the allocator lock  */\n/* while we clear the memory.                                       */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_generic_malloc_ignore_off_page(size_t lb, int k)\n{\n  return GC_generic_malloc_aligned(lb, k, IGNORE_OFF_PAGE, 0 /* align_m1 */);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_ignore_off_page(size_t lb)\n{\n  return GC_generic_malloc_aligned(lb, NORMAL, IGNORE_OFF_PAGE, 0);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_atomic_ignore_off_page(size_t lb)\n{\n  return GC_generic_malloc_aligned(lb, PTRFREE, IGNORE_OFF_PAGE, 0);\n}\n\n/* Increment GC_bytes_allocd from code that doesn't have direct access  */\n/* to GC_arrays.                                                        */\nvoid GC_CALL\nGC_incr_bytes_allocd(size_t n)\n{\n  GC_bytes_allocd += n;\n}\n\n/* The same for GC_bytes_freed.                         */\nvoid GC_CALL\nGC_incr_bytes_freed(size_t n)\n{\n  GC_bytes_freed += n;\n}\n\nGC_API size_t GC_CALL\nGC_get_expl_freed_bytes_since_gc(void)\n{\n  return (size_t)GC_bytes_freed;\n}\n\n#ifdef PARALLEL_MARK\n/* Number of bytes of memory allocated since we released the        */\n/* allocator lock.  Instead of reacquiring the allocator lock just  */\n/* to add this in, we add it in the next time we reacquire the      */\n/* allocator lock.  (Atomically adding it does not work, since we   */\n/* would have to atomically update it in GC_malloc, which is too    */\n/* expensive.)                                                      */\nSTATIC volatile AO_t GC_bytes_allocd_tmp = 0;\n#endif /* PARALLEL_MARK */\n\nGC_API void GC_CALL\nGC_generic_malloc_many(size_t lb_adjusted, int k, void **result)\n{\n  void *op;\n  void *p;\n  void **opp;\n  size_t lg; /* lb_adjusted value converted to granules */\n  word my_bytes_allocd = 0;\n  struct obj_kind *ok;\n  struct hblk **rlh;\n\n  GC_ASSERT(lb_adjusted != 0 && (lb_adjusted & (GC_GRANULE_BYTES - 1)) == 0);\n  /* Currently a single object is always allocated if manual VDB. */\n  /* TODO: GC_dirty should be called for each linked object (but  */\n  /* the last one) to support multiple objects allocation.        */\n  if (!EXPECT(lb_adjusted <= MAXOBJBYTES, TRUE) || GC_manual_vdb) {\n    op = GC_generic_malloc_aligned(lb_adjusted - EXTRA_BYTES, k, 0 /* flags */,\n                                   0 /* align_m1 */);\n    if (EXPECT(op != NULL, TRUE))\n      obj_link(op) = NULL;\n    *result = op;\n#ifndef NO_MANUAL_VDB\n    if (GC_manual_vdb && GC_is_heap_ptr(result)) {\n      GC_dirty_inner(result);\n      REACHABLE_AFTER_DIRTY(op);\n    }\n#endif\n    return;\n  }\n  GC_ASSERT(k < MAXOBJKINDS);\n  lg = BYTES_TO_GRANULES(lb_adjusted);\n  if (EXPECT(get_have_errors(), FALSE))\n    GC_print_all_errors();\n  GC_INVOKE_FINALIZERS();\n  GC_DBG_COLLECT_AT_MALLOC(lb_adjusted - EXTRA_BYTES);\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  LOCK();\n  /* Do our share of marking work.    */\n  if (GC_incremental && !GC_dont_gc) {\n    ENTER_GC();\n    GC_collect_a_little_inner(1);\n    EXIT_GC();\n  }\n\n  /* First see if we can reclaim a page of objects waiting to be */\n  /* reclaimed.                                                  */\n  ok = &GC_obj_kinds[k];\n  rlh = ok->ok_reclaim_list;\n  if (rlh != NULL) {\n    struct hblk *hbp;\n    hdr *hhdr;\n\n    while ((hbp = rlh[lg]) != NULL) {\n      hhdr = HDR(hbp);\n      rlh[lg] = hhdr->hb_next;\n      GC_ASSERT(hhdr->hb_sz == lb_adjusted);\n      hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n#ifdef PARALLEL_MARK\n      if (GC_parallel) {\n        GC_signed_word my_bytes_allocd_tmp\n            = (GC_signed_word)AO_load(&GC_bytes_allocd_tmp);\n        GC_ASSERT(my_bytes_allocd_tmp >= 0);\n        /* We only decrement it while holding the allocator   */\n        /* lock.  Thus, we cannot accidentally adjust it down */\n        /* in more than one thread simultaneously.            */\n        if (my_bytes_allocd_tmp != 0) {\n          (void)AO_fetch_and_add(&GC_bytes_allocd_tmp,\n                                 (AO_t)(-my_bytes_allocd_tmp));\n          GC_bytes_allocd += (word)my_bytes_allocd_tmp;\n        }\n        GC_acquire_mark_lock();\n        ++GC_fl_builder_count;\n        UNLOCK();\n        GC_release_mark_lock();\n      }\n#endif\n      op = GC_reclaim_generic(hbp, hhdr, lb_adjusted, ok->ok_init, 0,\n                              &my_bytes_allocd);\n      if (op != 0) {\n#ifdef PARALLEL_MARK\n        if (GC_parallel) {\n          *result = op;\n          (void)AO_fetch_and_add(&GC_bytes_allocd_tmp, (AO_t)my_bytes_allocd);\n          GC_acquire_mark_lock();\n          --GC_fl_builder_count;\n          if (GC_fl_builder_count == 0)\n            GC_notify_all_builder();\n#  ifdef THREAD_SANITIZER\n          GC_release_mark_lock();\n          LOCK();\n          GC_bytes_found += (GC_signed_word)my_bytes_allocd;\n          UNLOCK();\n#  else\n          /* The resulting GC_bytes_found may be inaccurate.  */\n          GC_bytes_found += (GC_signed_word)my_bytes_allocd;\n          GC_release_mark_lock();\n#  endif\n          (void)GC_clear_stack(0);\n          return;\n        }\n#endif\n        /* We also reclaimed memory, so we need to adjust that count. */\n        GC_bytes_found += (GC_signed_word)my_bytes_allocd;\n        GC_bytes_allocd += my_bytes_allocd;\n        goto out;\n      }\n#ifdef PARALLEL_MARK\n      if (GC_parallel) {\n        GC_acquire_mark_lock();\n        --GC_fl_builder_count;\n        if (GC_fl_builder_count == 0)\n          GC_notify_all_builder();\n        GC_release_mark_lock();\n        /* The allocator lock is needed for access to the       */\n        /* reclaim list.  We must decrement fl_builder_count    */\n        /* before reacquiring the allocator lock.  Hopefully    */\n        /* this path is rare.                                   */\n        LOCK();\n\n        /* Reload rlh after locking.    */\n        rlh = ok->ok_reclaim_list;\n        if (NULL == rlh)\n          break;\n      }\n#endif\n    }\n  }\n  /* Next try to use prefix of global free list if there is one.      */\n  /* We don't refill it, but we need to use it up before allocating   */\n  /* a new block ourselves.                                           */\n  opp = &ok->ok_freelist[lg];\n  if ((op = *opp) != NULL) {\n    *opp = NULL;\n    my_bytes_allocd = 0;\n    for (p = op; p != NULL; p = obj_link(p)) {\n      my_bytes_allocd += lb_adjusted;\n      if ((word)my_bytes_allocd >= HBLKSIZE) {\n        *opp = obj_link(p);\n        obj_link(p) = NULL;\n        break;\n      }\n    }\n    GC_bytes_allocd += my_bytes_allocd;\n    goto out;\n  }\n\n  /* Next try to allocate a new block worth of objects of this size.  */\n  {\n    struct hblk *h\n        = GC_allochblk(lb_adjusted, k, 0 /* flags */, 0 /* align_m1 */);\n\n    if (h /* != NULL */) { /* CPPCHECK */\n      if (IS_UNCOLLECTABLE(k))\n        GC_set_hdr_marks(HDR(h));\n      GC_bytes_allocd += HBLKSIZE - (HBLKSIZE % lb_adjusted);\n#ifdef PARALLEL_MARK\n      if (GC_parallel) {\n        GC_acquire_mark_lock();\n        ++GC_fl_builder_count;\n        UNLOCK();\n        GC_release_mark_lock();\n\n        op = GC_build_fl(h, NULL, lg, ok->ok_init || GC_debugging_started);\n        *result = op;\n        GC_acquire_mark_lock();\n        --GC_fl_builder_count;\n        if (GC_fl_builder_count == 0)\n          GC_notify_all_builder();\n        GC_release_mark_lock();\n        (void)GC_clear_stack(0);\n        return;\n      }\n#endif\n      op = GC_build_fl(h, NULL, lg, ok->ok_init || GC_debugging_started);\n      goto out;\n    }\n  }\n\n  /* As a last attempt, try allocating a single object.  Note that    */\n  /* this may trigger a collection or expand the heap.                */\n  op = GC_generic_malloc_inner(lb_adjusted - EXTRA_BYTES, k, 0 /* flags */);\n  if (op != NULL)\n    obj_link(op) = NULL;\n\nout:\n  *result = op;\n  UNLOCK();\n  (void)GC_clear_stack(0);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_many(size_t lb)\n{\n  void *result;\n  size_t lg, lb_adjusted;\n\n  if (EXPECT(0 == lb, FALSE))\n    lb = 1;\n  lg = ALLOC_REQUEST_GRANS(lb);\n  lb_adjusted = GRANULES_TO_BYTES(lg);\n  GC_generic_malloc_many(lb_adjusted, NORMAL, &result);\n  return result;\n}\n\n/* TODO: The debugging version of GC_memalign and friends is tricky     */\n/* and currently missing.  The major difficulty is:                     */\n/* - store_debug_info() should return the pointer of the object with    */\n/* the requested alignment (unlike the object header).                  */\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_memalign(size_t align, size_t lb)\n{\n  size_t align_m1 = align - 1;\n\n  /* Check the alignment argument.    */\n  if (EXPECT(0 == align || (align & align_m1) != 0, FALSE))\n    return NULL;\n\n  /* TODO: use thread-local allocation */\n  if (align <= GC_GRANULE_BYTES)\n    return GC_malloc(lb);\n  return GC_malloc_kind_aligned_global(lb, NORMAL, align_m1);\n}\n\n/* This one exists largely to redirect posix_memalign for leaks finding. */\nGC_API int GC_CALL\nGC_posix_memalign(void **memptr, size_t align, size_t lb)\n{\n  void *p;\n  size_t align_minus_one = align - 1; /* to workaround a cppcheck warning */\n\n  /* Check alignment properly.  */\n  if (EXPECT(align < sizeof(void *) || (align_minus_one & align) != 0,\n             FALSE)) {\n#ifdef MSWINCE\n    return ERROR_INVALID_PARAMETER;\n#else\n    return EINVAL;\n#endif\n  }\n\n  p = GC_memalign(align, lb);\n  if (EXPECT(NULL == p, FALSE)) {\n#ifdef MSWINCE\n    return ERROR_NOT_ENOUGH_MEMORY;\n#else\n    return ENOMEM;\n#endif\n  }\n  *memptr = p;\n  return 0; /* success */\n}\n\n#ifndef GC_NO_VALLOC\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_valloc(size_t lb)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  GC_ASSERT(GC_real_page_size != 0);\n  return GC_memalign(GC_real_page_size, lb);\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_pvalloc(size_t lb)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  GC_ASSERT(GC_real_page_size != 0);\n  lb = SIZET_SAT_ADD(lb, GC_real_page_size - 1) & ~(GC_real_page_size - 1);\n  return GC_memalign(GC_real_page_size, lb);\n}\n#endif /* !GC_NO_VALLOC */\n\n/* Provide a version of strdup() that uses the collector to allocate    */\n/* the copy of the string.                                              */\nGC_API GC_ATTR_MALLOC char *GC_CALL\nGC_strdup(const char *s)\n{\n  char *copy;\n  size_t lb;\n  if (s == NULL)\n    return NULL;\n  lb = strlen(s) + 1;\n  copy = (char *)GC_malloc_atomic(lb);\n  if (EXPECT(NULL == copy, FALSE)) {\n#ifndef MSWINCE\n    errno = ENOMEM;\n#endif\n    return NULL;\n  }\n  BCOPY(s, copy, lb);\n  return copy;\n}\n\nGC_API GC_ATTR_MALLOC char *GC_CALL\nGC_strndup(const char *str, size_t size)\n{\n  char *copy;\n  /* Note: str is expected to be non-NULL.      */\n  size_t len = strlen(str);\n  if (EXPECT(len > size, FALSE))\n    len = size;\n  copy = (char *)GC_malloc_atomic(len + 1);\n  if (EXPECT(NULL == copy, FALSE)) {\n#ifndef MSWINCE\n    errno = ENOMEM;\n#endif\n    return NULL;\n  }\n  if (EXPECT(len > 0, TRUE))\n    BCOPY(str, copy, len);\n  copy[len] = '\\0';\n  return copy;\n}\n\n#ifdef GC_REQUIRE_WCSDUP\n#  include <wchar.h> /* for wcslen() */\n\nGC_API GC_ATTR_MALLOC wchar_t *GC_CALL\nGC_wcsdup(const wchar_t *str)\n{\n  size_t lb = (wcslen(str) + 1) * sizeof(wchar_t);\n  wchar_t *copy = (wchar_t *)GC_malloc_atomic(lb);\n\n  if (EXPECT(NULL == copy, FALSE)) {\n#  ifndef MSWINCE\n    errno = ENOMEM;\n#  endif\n    return NULL;\n  }\n  BCOPY(str, copy, lb);\n  return copy;\n}\n\n#  if !defined(wcsdup) && defined(REDIRECT_MALLOC) \\\n      && !defined(REDIRECT_MALLOC_IN_HEADER)\nwchar_t *\nwcsdup(const wchar_t *str)\n{\n  return GC_wcsdup(str);\n}\n#  endif\n#endif /* GC_REQUIRE_WCSDUP */\n\n#ifndef CPPCHECK\nGC_API void *GC_CALL\nGC_malloc_stubborn(size_t lb)\n{\n  return GC_malloc(lb);\n}\n\nGC_API void GC_CALL\nGC_change_stubborn(const void *p)\n{\n  UNUSED_ARG(p);\n}\n#endif /* !CPPCHECK */\n\nGC_API void GC_CALL\nGC_end_stubborn_change(const void *p)\n{\n  GC_dirty(p); /* entire object */\n}\n\nGC_API void GC_CALL\nGC_ptr_store_and_dirty(void *p, const void *q)\n{\n  *(const void **)p = q;\n  GC_dirty(p);\n  REACHABLE_AFTER_DIRTY(q);\n}\n"
        },
        {
          "name": "mark.c",
          "type": "blob",
          "size": 72.7216796875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 2000 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\"\n\n/* Make arguments appear live to compiler.  Put here to minimize the    */\n/* risk of inlining.  Used to minimize junk left in registers.          */\nGC_ATTR_NOINLINE\nvoid\nGC_noop6(word arg1, word arg2, word arg3, word arg4, word arg5, word arg6)\n{\n  UNUSED_ARG(arg1);\n  UNUSED_ARG(arg2);\n  UNUSED_ARG(arg3);\n  UNUSED_ARG(arg4);\n  UNUSED_ARG(arg5);\n  UNUSED_ARG(arg6);\n  /* Avoid GC_noop6 calls to be optimized away. */\n#if defined(AO_HAVE_compiler_barrier) && !defined(BASE_ATOMIC_OPS_EMULATED)\n  AO_compiler_barrier(); /* to serve as a special side-effect */\n#else\n  GC_noop1(0);\n#endif\n}\n\n/* Make the argument appear live to compiler.  This is similar  */\n/* to GC_noop6(), but with a single argument.  Robust against   */\n/* whole program analysis.                                      */\nGC_API void GC_CALL\nGC_noop1(GC_word x)\n{\n#if defined(AO_HAVE_store) && defined(THREAD_SANITIZER)\n  AO_store(&GC_noop_sink, (AO_t)x);\n#else\n  GC_noop_sink = x;\n#endif\n}\n\nGC_API void GC_CALL\nGC_noop1_ptr(volatile void *p)\n{\n#if CPP_PTRSZ > CPP_WORDSZ\n#  if defined(AO_HAVE_store) && defined(THREAD_SANITIZER)\n  GC_cptr_store(&GC_noop_sink_ptr, (ptr_t)CAST_AWAY_VOLATILE_PVOID(p));\n#  else\n  GC_noop_sink_ptr = (ptr_t)CAST_AWAY_VOLATILE_PVOID(p);\n#  endif\n#else\n  GC_noop1(ADDR(p));\n#endif\n}\n\n/* Initialize GC_obj_kinds properly and standard free lists properly.   */\n/* This must be done statically since they may be accessed before       */\n/* GC_init is called.  It is done here, since we need to deal with mark */\n/* descriptors.  Note: GC_obj_kinds[NORMAL].ok_descriptor is adjusted   */\n/* in GC_init() for EXTRA_BYTES.                                        */\nGC_INNER struct obj_kind GC_obj_kinds[MAXOBJKINDS] = {\n  /* PTRFREE */ { &GC_aobjfreelist[0], 0 /* filled in dynamically */,\n                  /* 0 | */ GC_DS_LENGTH, FALSE,\n                  FALSE\n                      /*, */ OK_DISCLAIM_INITZ },\n  /* NORMAL */\n  { &GC_objfreelist[0], 0,\n    /* 0 | */ GC_DS_LENGTH, TRUE /* add length to descr */,\n    TRUE\n        /*, */ OK_DISCLAIM_INITZ },\n  /* UNCOLLECTABLE */\n  { &GC_uobjfreelist[0], 0,\n    /* 0 | */ GC_DS_LENGTH, TRUE /* add length to descr */,\n    TRUE\n        /*, */ OK_DISCLAIM_INITZ },\n#ifdef GC_ATOMIC_UNCOLLECTABLE\n  { &GC_auobjfreelist[0], 0,\n    /* 0 | */ GC_DS_LENGTH, FALSE,\n    FALSE\n        /*, */ OK_DISCLAIM_INITZ },\n#endif\n};\n\n#ifndef INITIAL_MARK_STACK_SIZE\n/* INITIAL_MARK_STACK_SIZE * sizeof(mse) should be a multiple of      */\n/* HBLKSIZE.  The incremental collector actually likes a larger size, */\n/* since it wants to push all marked dirty objects before marking     */\n/* anything new.  Currently we let it grow dynamically.               */\n#  define INITIAL_MARK_STACK_SIZE (1 * HBLKSIZE)\n#endif /* !INITIAL_MARK_STACK_SIZE */\n\n#if !defined(GC_DISABLE_INCREMENTAL)\n/* Number of dirty pages we marked from, excluding pointer-free       */\n/* pages, etc.  Used for logging only.                                */\nSTATIC word GC_n_rescuing_pages = 0;\n#endif\n\nGC_API void GC_CALL\nGC_set_pointer_mask(GC_word value)\n{\n#ifdef DYNAMIC_POINTER_MASK\n  GC_ASSERT(value >= 0xff); /* a simple sanity check */\n  GC_pointer_mask = value;\n#else\n  if (value\n#  ifdef POINTER_MASK\n      != (word)(POINTER_MASK)\n#  else\n      != GC_WORD_MAX\n#  endif\n  ) {\n    ABORT(\"Dynamic pointer mask/shift is unsupported\");\n  }\n#endif\n}\n\nGC_API GC_word GC_CALL\nGC_get_pointer_mask(void)\n{\n#ifdef DYNAMIC_POINTER_MASK\n  GC_word value = GC_pointer_mask;\n\n  if (0 == value) {\n    GC_ASSERT(!GC_is_initialized);\n    value = GC_WORD_MAX;\n  }\n  return value;\n#elif defined(POINTER_MASK)\n  return POINTER_MASK;\n#else\n  return GC_WORD_MAX;\n#endif\n}\n\nGC_API void GC_CALL\nGC_set_pointer_shift(unsigned value)\n{\n#ifdef DYNAMIC_POINTER_MASK\n  GC_ASSERT(value < CPP_WORDSZ);\n  GC_pointer_shift = (unsigned char)value;\n#else\n  if (value\n#  ifdef POINTER_SHIFT\n      != (unsigned)(POINTER_SHIFT)\n#  endif /* else is not zero */\n  ) {\n    ABORT(\"Dynamic pointer mask/shift is unsupported\");\n  }\n#endif\n}\n\nGC_API unsigned GC_CALL\nGC_get_pointer_shift(void)\n{\n#ifdef DYNAMIC_POINTER_MASK\n  return GC_pointer_shift;\n#elif defined(POINTER_SHIFT)\n  GC_STATIC_ASSERT((unsigned)(POINTER_SHIFT) < CPP_WORDSZ);\n  return POINTER_SHIFT;\n#else\n  return 0;\n#endif\n}\n\n/* Is a collection in progress?  Note that this can return true in the  */\n/* non-incremental case, if a collection has been abandoned and the     */\n/* mark state is now MS_INVALID.                                        */\nGC_INNER GC_bool\nGC_collection_in_progress(void)\n{\n  return GC_mark_state != MS_NONE;\n}\n\n/* Clear all mark bits in the header.   */\nGC_INNER void\nGC_clear_hdr_marks(hdr *hhdr)\n{\n  size_t last_bit;\n\n#ifdef AO_HAVE_load\n  /* Atomic access is used to avoid racing with GC_realloc.   */\n  last_bit = FINAL_MARK_BIT(AO_load(&hhdr->hb_sz));\n#else\n  /* No race as GC_realloc holds the allocator lock while updating hb_sz. */\n  last_bit = FINAL_MARK_BIT(hhdr->hb_sz);\n#endif\n\n  BZERO(CAST_AWAY_VOLATILE_PVOID(hhdr->hb_marks), sizeof(hhdr->hb_marks));\n  set_mark_bit_from_hdr(hhdr, last_bit);\n  hhdr->hb_n_marks = 0;\n}\n\n/* Set all mark bits in the header.  Used for uncollectible blocks. */\nGC_INNER void\nGC_set_hdr_marks(hdr *hhdr)\n{\n  size_t i;\n  size_t sz = hhdr->hb_sz;\n  size_t n_marks = FINAL_MARK_BIT(sz);\n\n#ifdef USE_MARK_BYTES\n  for (i = 0; i <= n_marks; i += MARK_BIT_OFFSET(sz)) {\n    hhdr->hb_marks[i] = 1;\n  }\n#else\n  /* Note that all bits are set even in case of not MARK_BIT_PER_OBJ,   */\n  /* instead of setting every n-th bit where n is MARK_BIT_OFFSET(sz).  */\n  /* This is done for a performance reason.                             */\n  for (i = 0; i < divWORDSZ(n_marks); ++i) {\n    hhdr->hb_marks[i] = GC_WORD_MAX;\n  }\n  /* Set the remaining bits near the end (plus one bit past the end).   */\n  hhdr->hb_marks[i] = ((((word)1 << modWORDSZ(n_marks)) - 1) << 1) | 1;\n#endif\n#ifdef MARK_BIT_PER_OBJ\n  hhdr->hb_n_marks = n_marks;\n#else\n  hhdr->hb_n_marks = HBLK_OBJS(sz);\n#endif\n}\n\n/* Clear all mark bits associated with block h. */\nstatic void GC_CALLBACK\nclear_marks_for_block(struct hblk *h, void *dummy)\n{\n  hdr *hhdr = HDR(h);\n\n  UNUSED_ARG(dummy);\n  if (IS_UNCOLLECTABLE(hhdr->hb_obj_kind)) {\n    /* Mark bit for these is cleared only once the object is          */\n    /* explicitly deallocated.  This either frees the block, or the   */\n    /* bit is cleared once the object is on the free list.            */\n    return;\n  }\n  GC_clear_hdr_marks(hhdr);\n#if defined(CPPCHECK)\n  GC_noop1_ptr(h);\n#endif\n}\n\n/* Slow but general routines for setting/clearing/asking about mark bits. */\nGC_API void GC_CALL\nGC_set_mark_bit(const void *p)\n{\n  struct hblk *h = HBLKPTR(p);\n  hdr *hhdr = HDR(h);\n  size_t bit_no = MARK_BIT_NO((size_t)((ptr_t)p - (ptr_t)h), hhdr->hb_sz);\n\n  if (!mark_bit_from_hdr(hhdr, bit_no)) {\n    set_mark_bit_from_hdr(hhdr, bit_no);\n    INCR_MARKS(hhdr);\n  }\n}\n\nGC_API void GC_CALL\nGC_clear_mark_bit(const void *p)\n{\n  struct hblk *h = HBLKPTR(p);\n  hdr *hhdr = HDR(h);\n  size_t bit_no = MARK_BIT_NO((size_t)((ptr_t)p - (ptr_t)h), hhdr->hb_sz);\n\n  if (mark_bit_from_hdr(hhdr, bit_no)) {\n    size_t n_marks = hhdr->hb_n_marks;\n\n    GC_ASSERT(n_marks != 0);\n    clear_mark_bit_from_hdr(hhdr, bit_no);\n    n_marks--;\n#ifdef PARALLEL_MARK\n    /* Don't decrement to zero.  The counts are approximate due to  */\n    /* concurrency issues, but we need to ensure that a count of    */\n    /* zero implies an empty block.                                 */\n    if (n_marks != 0 || !GC_parallel)\n      hhdr->hb_n_marks = n_marks;\n#else\n    hhdr->hb_n_marks = n_marks;\n#endif\n  }\n}\n\nGC_API int GC_CALL\nGC_is_marked(const void *p)\n{\n  struct hblk *h = HBLKPTR(p);\n  hdr *hhdr = HDR(h);\n  size_t bit_no = MARK_BIT_NO((size_t)((ptr_t)p - (ptr_t)h), hhdr->hb_sz);\n\n  return (int)mark_bit_from_hdr(hhdr, bit_no); /* 0 or 1 */\n}\n\n/* Clear mark bits in all allocated heap blocks.  This invalidates the  */\n/* marker invariant, and sets GC_mark_state to reflect this.  (This     */\n/* implicitly starts marking to reestablish the invariant.)             */\nGC_INNER void\nGC_clear_marks(void)\n{\n  /* The initialization is needed for GC_push_roots().        */\n  GC_ASSERT(GC_is_initialized);\n\n  GC_apply_to_all_blocks(clear_marks_for_block, NULL);\n  GC_objects_are_marked = FALSE;\n  GC_mark_state = MS_INVALID;\n  GC_scan_ptr = NULL;\n}\n\n/* Initiate a garbage collection.  Initiates a full collection if the   */\n/* mark state is invalid.                                               */\nGC_INNER void\nGC_initiate_gc(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_is_initialized);\n#ifndef GC_DISABLE_INCREMENTAL\n  if (GC_incremental) {\n#  ifdef CHECKSUMS\n    GC_read_dirty(FALSE);\n    GC_check_dirty();\n#  else\n    GC_read_dirty(GC_mark_state == MS_INVALID);\n#  endif\n  }\n  GC_n_rescuing_pages = 0;\n#endif\n  if (GC_mark_state == MS_NONE) {\n    GC_mark_state = MS_PUSH_RESCUERS;\n  } else {\n    /* This is really a full collection, and mark bits are invalid. */\n    GC_ASSERT(GC_mark_state == MS_INVALID);\n  }\n  GC_scan_ptr = NULL;\n}\n\n#ifdef PARALLEL_MARK\n/* Initiate parallel marking.       */\nSTATIC void GC_do_parallel_mark(void);\n#endif /* PARALLEL_MARK */\n\n#ifdef GC_DISABLE_INCREMENTAL\n#  define GC_push_next_marked_dirty(h) GC_push_next_marked(h)\n#else\nSTATIC struct hblk *GC_push_next_marked_dirty(struct hblk *h);\n#endif /* !GC_DISABLE_INCREMENTAL */\n\nSTATIC struct hblk *GC_push_next_marked(struct hblk *h);\nSTATIC struct hblk *GC_push_next_marked_uncollectable(struct hblk *h);\n\nstatic void alloc_mark_stack(size_t);\n\nstatic void\npush_roots_and_advance(GC_bool push_all, ptr_t cold_gc_frame)\n{\n  if (GC_scan_ptr != NULL) {\n    /* Not ready to push.       */\n    return;\n  }\n  GC_push_roots(push_all, cold_gc_frame);\n  GC_objects_are_marked = TRUE;\n  if (GC_mark_state != MS_INVALID)\n    GC_mark_state = MS_ROOTS_PUSHED;\n}\n\nSTATIC GC_on_mark_stack_empty_proc GC_on_mark_stack_empty;\n\nGC_API void GC_CALL\nGC_set_on_mark_stack_empty(GC_on_mark_stack_empty_proc fn)\n{\n  LOCK();\n  GC_on_mark_stack_empty = fn;\n  UNLOCK();\n}\n\nGC_API GC_on_mark_stack_empty_proc GC_CALL\nGC_get_on_mark_stack_empty(void)\n{\n  GC_on_mark_stack_empty_proc fn;\n\n  READER_LOCK();\n  fn = GC_on_mark_stack_empty;\n  READER_UNLOCK();\n  return fn;\n}\n\n/* Perform a small amount of marking.                   */\n/* We try to touch roughly a page of memory.            */\n/* Return TRUE if we just finished a mark phase.        */\n/* Cold_gc_frame is an address inside a GC frame that   */\n/* remains valid until all marking is complete.         */\n/* A zero value indicates that it's OK to miss some     */\n/* register values.  In the case of an incremental      */\n/* collection, the world may be running.                */\n#ifdef WRAP_MARK_SOME\n/* For Win32, this is called after we establish a structured  */\n/* exception (or signal) handler, in case Windows unmaps one  */\n/* of our root segments.  Note that this code should never    */\n/* generate an incremental GC write fault.                    */\nSTATIC GC_bool\nGC_mark_some_inner(ptr_t cold_gc_frame)\n#else\nGC_INNER GC_bool\nGC_mark_some(ptr_t cold_gc_frame)\n#endif\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  switch (GC_mark_state) {\n  case MS_NONE:\n    return TRUE;\n\n  case MS_PUSH_RESCUERS:\n    if (ADDR_GE((ptr_t)GC_mark_stack_top,\n                (ptr_t)(GC_mark_stack_limit - INITIAL_MARK_STACK_SIZE / 2))) {\n      /* Go ahead and mark, even though that might cause us to */\n      /* see more marked dirty objects later on.  Avoid this   */\n      /* in the future.                                        */\n      GC_mark_stack_too_small = TRUE;\n      MARK_FROM_MARK_STACK();\n    } else {\n      GC_scan_ptr = GC_push_next_marked_dirty(GC_scan_ptr);\n#ifndef GC_DISABLE_INCREMENTAL\n      if (NULL == GC_scan_ptr) {\n        GC_COND_LOG_PRINTF(\"Marked from %lu dirty pages\\n\",\n                           (unsigned long)GC_n_rescuing_pages);\n      }\n#endif\n      push_roots_and_advance(FALSE, cold_gc_frame);\n    }\n    GC_ASSERT(GC_mark_state == MS_PUSH_RESCUERS\n              || GC_mark_state == MS_ROOTS_PUSHED\n              || GC_mark_state == MS_INVALID);\n    break;\n\n  case MS_PUSH_UNCOLLECTABLE:\n    if (ADDR_GE((ptr_t)GC_mark_stack_top,\n                (ptr_t)(GC_mark_stack + GC_mark_stack_size / 4))) {\n#ifdef PARALLEL_MARK\n      /* Avoid this, since we don't parallelize the marker  */\n      /* here.                                              */\n      if (GC_parallel)\n        GC_mark_stack_too_small = TRUE;\n#endif\n      MARK_FROM_MARK_STACK();\n    } else {\n      GC_scan_ptr = GC_push_next_marked_uncollectable(GC_scan_ptr);\n      push_roots_and_advance(TRUE, cold_gc_frame);\n    }\n    GC_ASSERT(GC_mark_state == MS_PUSH_UNCOLLECTABLE\n              || GC_mark_state == MS_ROOTS_PUSHED\n              || GC_mark_state == MS_INVALID);\n    break;\n\n  case MS_ROOTS_PUSHED:\n#ifdef PARALLEL_MARK\n    /* Eventually, incremental marking should run             */\n    /* asynchronously in multiple threads, without acquiring  */\n    /* the allocator lock.                                    */\n    /* For now, parallel marker is disabled if there is       */\n    /* a chance that marking could be interrupted by          */\n    /* a client-supplied time limit or custom stop function.  */\n    if (GC_parallel && !GC_parallel_mark_disabled) {\n      GC_do_parallel_mark();\n      GC_ASSERT(ADDR_LT((ptr_t)GC_mark_stack_top, GC_first_nonempty));\n      GC_mark_stack_top = GC_mark_stack - 1;\n      if (GC_mark_stack_too_small) {\n        alloc_mark_stack(2 * GC_mark_stack_size);\n      }\n      if (GC_mark_state == MS_ROOTS_PUSHED) {\n        GC_mark_state = MS_NONE;\n        return TRUE;\n      }\n      GC_ASSERT(GC_mark_state == MS_INVALID);\n      break;\n    }\n#endif\n    if (ADDR_GE((ptr_t)GC_mark_stack_top, (ptr_t)GC_mark_stack)) {\n      MARK_FROM_MARK_STACK();\n    } else {\n      GC_on_mark_stack_empty_proc on_ms_empty = GC_on_mark_stack_empty;\n\n      if (on_ms_empty != 0) {\n        GC_mark_stack_top\n            = on_ms_empty(GC_mark_stack_top, GC_mark_stack_limit);\n        /* If we pushed new items, we need to continue  */\n        /* processing.                                  */\n        if (ADDR_GE((ptr_t)GC_mark_stack_top, (ptr_t)GC_mark_stack))\n          break;\n      }\n      if (GC_mark_stack_too_small) {\n        alloc_mark_stack(2 * GC_mark_stack_size);\n      }\n      GC_mark_state = MS_NONE;\n      return TRUE;\n    }\n    GC_ASSERT(GC_mark_state == MS_ROOTS_PUSHED || GC_mark_state == MS_INVALID);\n    break;\n\n  case MS_INVALID:\n  case MS_PARTIALLY_INVALID:\n    if (!GC_objects_are_marked) {\n      GC_mark_state = MS_PUSH_UNCOLLECTABLE;\n      break;\n    }\n    if (ADDR_GE((ptr_t)GC_mark_stack_top, (ptr_t)GC_mark_stack)) {\n      MARK_FROM_MARK_STACK();\n      GC_ASSERT(GC_mark_state == MS_PARTIALLY_INVALID\n                || GC_mark_state == MS_INVALID);\n      break;\n    }\n    if (NULL == GC_scan_ptr && GC_mark_state == MS_INVALID) {\n      /* About to start a heap scan for marked objects. */\n      /* Mark stack is empty.  OK to reallocate.        */\n      if (GC_mark_stack_too_small) {\n        alloc_mark_stack(2 * GC_mark_stack_size);\n      }\n      GC_mark_state = MS_PARTIALLY_INVALID;\n    }\n    GC_scan_ptr = GC_push_next_marked(GC_scan_ptr);\n    if (GC_mark_state == MS_PARTIALLY_INVALID)\n      push_roots_and_advance(TRUE, cold_gc_frame);\n    GC_ASSERT(GC_mark_state == MS_ROOTS_PUSHED\n              || GC_mark_state == MS_PARTIALLY_INVALID\n              || GC_mark_state == MS_INVALID);\n    break;\n\n  default:\n    ABORT(\"GC_mark_some: bad state\");\n  }\n  return FALSE;\n}\n\n#ifdef PARALLEL_MARK\nGC_INNER GC_bool GC_parallel_mark_disabled = FALSE;\n#endif\n\n#ifdef WRAP_MARK_SOME\nGC_INNER GC_bool\nGC_mark_some(ptr_t cold_gc_frame)\n{\n  GC_bool ret_val;\n\n  if (GC_no_dls) {\n    ret_val = GC_mark_some_inner(cold_gc_frame);\n  } else {\n    /* Windows appears to asynchronously create and remove      */\n    /* writable memory mappings, for reasons we haven't yet     */\n    /* understood.  Since we look for writable regions to       */\n    /* determine the root set, we may try to mark from an       */\n    /* address range that disappeared since we started the      */\n    /* collection.  Thus we have to recover from faults here.   */\n    /* This code seems to be necessary for WinCE (at least in   */\n    /* the case we'd decide to add MEM_PRIVATE sections to      */\n    /* data roots in GC_register_dynamic_libraries()).          */\n    /* It's conceivable that this is the same issue as with     */\n    /* terminating threads that we see with Linux and           */\n    /* USE_PROC_FOR_LIBRARIES.                                  */\n#  ifndef NO_SEH_AVAILABLE\n    __try {\n      ret_val = GC_mark_some_inner(cold_gc_frame);\n    } __except (GetExceptionCode() == EXCEPTION_ACCESS_VIOLATION\n                    ? EXCEPTION_EXECUTE_HANDLER\n                    : EXCEPTION_CONTINUE_SEARCH) {\n      goto handle_ex;\n    }\n#  else\n#    if defined(USE_PROC_FOR_LIBRARIES) && !defined(DEFAULT_VDB)\n    if (GC_auto_incremental) {\n      static GC_bool is_warned = FALSE;\n\n      if (!is_warned) {\n        is_warned = TRUE;\n        WARN(\"Incremental GC incompatible with /proc roots\\n\", 0);\n      }\n      /* I'm not sure if this could still work ...  */\n    }\n#    endif\n    /* If USE_PROC_FOR_LIBRARIES, we are handling the case in     */\n    /* which /proc is used for root finding, and we have threads. */\n    /* We may find a stack for a thread that is in the process of */\n    /* exiting, and disappears while we are marking it.           */\n    /* This seems extremely difficult to avoid otherwise.         */\n    GC_setup_temporary_fault_handler();\n    if (SETJMP(GC_jmp_buf) != 0)\n      goto handle_ex;\n    ret_val = GC_mark_some_inner(cold_gc_frame);\n    GC_reset_fault_handler();\n#  endif\n  }\n\n#  if defined(GC_WIN32_THREADS) && !defined(GC_PTHREADS)\n  /* With DllMain-based thread tracking, a thread may have        */\n  /* started while we were marking.  This is logically equivalent */\n  /* to the exception case; our results are invalid and we have   */\n  /* to start over.  This cannot be prevented since we can't      */\n  /* block in DllMain.                                            */\n  if (GC_started_thread_while_stopped())\n    goto handle_thr_start;\n#  endif\n  return ret_val;\n\nhandle_ex:\n  /* Exception handler starts here for all cases.   */\n#  if defined(NO_SEH_AVAILABLE)\n  GC_reset_fault_handler();\n#  endif\n  {\n    static word warned_gc_no;\n\n    /* Report caught ACCESS_VIOLATION, once per collection. */\n    if (warned_gc_no != GC_gc_no) {\n      GC_COND_LOG_PRINTF(\"Memory mapping disappeared at collection #%lu\\n\",\n                         (unsigned long)GC_gc_no + 1);\n      warned_gc_no = GC_gc_no;\n    }\n  }\n#  if defined(GC_WIN32_THREADS) && !defined(GC_PTHREADS)\nhandle_thr_start:\n#  endif\n  /* We have bad roots on the mark stack - discard it.      */\n  /* Rescan from marked objects.  Redetermine roots.        */\n#  ifdef REGISTER_LIBRARIES_EARLY\n  START_WORLD();\n  GC_cond_register_dynamic_libraries();\n  STOP_WORLD();\n#  endif\n  GC_invalidate_mark_state();\n  GC_scan_ptr = NULL;\n  return FALSE;\n}\n#endif /* WRAP_MARK_SOME */\n\nGC_INNER void\nGC_invalidate_mark_state(void)\n{\n  GC_mark_state = MS_INVALID;\n  GC_mark_stack_top = GC_mark_stack - 1;\n}\n\nSTATIC mse *\nGC_signal_mark_stack_overflow(mse *msp)\n{\n  GC_mark_state = MS_INVALID;\n#ifdef PARALLEL_MARK\n  /* We are using a local_mark_stack in parallel mode, so   */\n  /* do not signal the global mark stack to be resized.     */\n  /* That will be done if required in GC_return_mark_stack. */\n  if (!GC_parallel)\n    GC_mark_stack_too_small = TRUE;\n#else\n  GC_mark_stack_too_small = TRUE;\n#endif\n  GC_COND_LOG_PRINTF(\"Mark stack overflow; current size: %lu entries\\n\",\n                     (unsigned long)GC_mark_stack_size);\n#if defined(CPPCHECK)\n  GC_noop1_ptr(msp);\n#endif\n  return msp - GC_MARK_STACK_DISCARDS;\n}\n\n/*\n * Mark objects pointed to by the regions described by\n * mark stack entries between mark_stack and mark_stack_top,\n * inclusive.  Assumes the upper limit of a mark stack entry\n * is never 0.  A mark stack entry never has size 0.\n * We try to traverse on the order of a hblk of memory before we return.\n * Caller is responsible for calling this until the mark stack is empty.\n * Note that this is the most performance critical routine in the\n * collector.  Hence it contains all sorts of ugly hacks to speed\n * things up.  In particular, we avoid procedure calls on the common\n * path, we take advantage of peculiarities of the mark descriptor\n * encoding, we optionally maintain a cache for the block address to\n * header mapping, we prefetch when an object is \"grayed\", etc.\n */\nGC_ATTR_NO_SANITIZE_ADDR_MEM_THREAD\nGC_INNER mse *\nGC_mark_from(mse *mark_stack_top, mse *mark_stack, mse *mark_stack_limit)\n{\n  GC_signed_word credit = HBLKSIZE; /* remaining credit for marking work */\n  word descr;\n  ptr_t current_p; /* pointer to current candidate ptr */\n  ptr_t q;         /* the candidate pointer */\n  ptr_t limit = 0; /* limit (incl.) of current candidate range */\n  ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n  DECLARE_HDR_CACHE;\n\n#define SPLIT_RANGE_PTRS 128 /* must be power of 2 */\n\n  GC_objects_are_marked = TRUE;\n  INIT_HDR_CACHE;\n#if defined(OS2) || CPP_PTRSZ > CPP_WORDSZ\n  /* OS/2: use untweaked version to circumvent a compiler problem.    */\n  while (ADDR_GE((ptr_t)mark_stack_top, (ptr_t)mark_stack) && credit >= 0)\n#else\n  while (((((word)mark_stack_top - (word)mark_stack) | (word)credit) & SIGNB)\n         == 0)\n#endif\n  {\n    current_p = mark_stack_top->mse_start;\n    descr = mark_stack_top->mse_descr;\n  retry:\n    /* current_p and descr describe the current object.                 */\n    /* (*mark_stack_top) is vacant.                                     */\n    /* The following is 0 only for small objects described by a simple  */\n    /* length descriptor.  For many applications this is the common     */\n    /* case, so we try to detect it quickly.                            */\n    if (descr & (~(word)(PTRS_TO_BYTES(SPLIT_RANGE_PTRS) - 1) | GC_DS_TAGS)) {\n      word tag = descr & GC_DS_TAGS;\n\n      GC_STATIC_ASSERT(GC_DS_TAGS == 0x3);\n      switch (tag) {\n      case GC_DS_LENGTH:\n        /* Large length.  Process part of the range to avoid pushing  */\n        /* too much on the stack.                                     */\n\n        /* Either it is a heap object or a region outside the heap.   */\n        GC_ASSERT(descr < GC_greatest_real_heap_addr - GC_least_real_heap_addr\n                  || GC_least_real_heap_addr + sizeof(ptr_t)\n                         >= ADDR(current_p) + descr\n                  || ADDR(current_p) >= GC_greatest_real_heap_addr);\n#ifdef PARALLEL_MARK\n#  define SHARE_BYTES 2048\n        if (descr > SHARE_BYTES && GC_parallel\n            && ADDR_LT((ptr_t)mark_stack_top, (ptr_t)(mark_stack_limit - 1))) {\n          word new_size = (descr >> 1) & ~(word)(sizeof(ptr_t) - 1);\n\n          mark_stack_top->mse_start = current_p;\n          /* This makes sure we handle misaligned pointers. */\n          mark_stack_top->mse_descr\n              = (new_size + sizeof(ptr_t)) | GC_DS_LENGTH;\n          mark_stack_top++;\n#  ifdef ENABLE_TRACE\n          if (ADDR_INSIDE(GC_trace_ptr, current_p, current_p + descr)) {\n            GC_log_printf(\"GC #%lu: large section; start %p, len %lu,\"\n                          \" splitting (parallel) at %p\\n\",\n                          (unsigned long)GC_gc_no, (void *)current_p,\n                          (unsigned long)descr,\n                          (void *)(current_p + new_size));\n          }\n#  endif\n          current_p += new_size;\n          descr -= new_size;\n          goto retry;\n        }\n#endif /* PARALLEL_MARK */\n        limit = current_p + PTRS_TO_BYTES(SPLIT_RANGE_PTRS - 1);\n        mark_stack_top->mse_start = limit;\n        mark_stack_top->mse_descr\n            = descr - PTRS_TO_BYTES(SPLIT_RANGE_PTRS - 1);\n#ifdef ENABLE_TRACE\n        if (ADDR_INSIDE(GC_trace_ptr, current_p, current_p + descr)) {\n          GC_log_printf(\"GC #%lu: large section; start %p, len %lu,\"\n                        \" splitting at %p\\n\",\n                        (unsigned long)GC_gc_no, (void *)current_p,\n                        (unsigned long)descr, (void *)limit);\n        }\n#endif\n        /* Make sure that pointers overlapping the two ranges are     */\n        /* considered.                                                */\n        limit += sizeof(ptr_t) - ALIGNMENT;\n        break;\n      case GC_DS_BITMAP:\n        mark_stack_top--;\n#ifdef ENABLE_TRACE\n        if (ADDR_INSIDE(GC_trace_ptr, current_p,\n                        current_p + PTRS_TO_BYTES(BITMAP_BITS))) {\n          GC_log_printf(\"GC #%lu: tracing from %p bitmap descr 0x%lx\\n\",\n                        (unsigned long)GC_gc_no, (void *)current_p,\n                        (unsigned long)descr);\n        }\n#endif\n        descr &= ~(word)GC_DS_TAGS;\n        credit -= (GC_signed_word)PTRS_TO_BYTES(CPP_PTRSZ / 2); /* guess */\n        for (; descr != 0; descr <<= 1, current_p += sizeof(ptr_t)) {\n          if ((descr & SIGNB) == 0)\n            continue;\n          LOAD_PTR_OR_CONTINUE(q, current_p);\n          FIXUP_POINTER(q);\n          if (ADDR_LT(least_ha, q) && ADDR_LT(q, greatest_ha)) {\n            PREFETCH(q);\n#ifdef ENABLE_TRACE\n            if (GC_trace_ptr == current_p) {\n              GC_log_printf(\"GC #%lu: considering(3) %p -> %p\\n\",\n                            (unsigned long)GC_gc_no, (void *)current_p,\n                            (void *)q);\n            }\n#endif\n            PUSH_CONTENTS(q, mark_stack_top, mark_stack_limit, current_p);\n          }\n        }\n        continue;\n      case GC_DS_PROC:\n        mark_stack_top--;\n#ifdef ENABLE_TRACE\n        if (ADDR_GE(GC_trace_ptr, current_p)) {\n          const void *base = GC_base(current_p);\n\n          if (base != NULL && GC_base(GC_trace_ptr) == base) {\n            GC_log_printf(\"GC #%lu: tracing from %p, proc descr 0x%lx\\n\",\n                          (unsigned long)GC_gc_no, (void *)current_p,\n                          (unsigned long)descr);\n          }\n        }\n#endif\n        credit -= GC_PROC_BYTES;\n        mark_stack_top = (*PROC(descr))((word *)current_p, mark_stack_top,\n                                        mark_stack_limit, ENV(descr));\n        continue;\n      case GC_DS_PER_OBJECT:\n        if (!(descr & SIGNB)) {\n          /* Descriptor is in the object.     */\n          descr = *(word *)(current_p + descr - GC_DS_PER_OBJECT);\n        } else {\n          /* Descriptor is in the type descriptor pointed to by the   */\n          /* first \"pointer-sized\" word of the object.                */\n          ptr_t type_descr = *(ptr_t *)current_p;\n\n          /* type_descr is either a valid pointer to the descriptor   */\n          /* structure, or this object was on a free list.            */\n          /* If it was anything but the last object on the free list, */\n          /* we will misinterpret the next object on the free list as */\n          /* the type descriptor, and get a 0 GC descriptor, which    */\n          /* is ideal.  Unfortunately, we need to check for the last  */\n          /* object case explicitly.                                  */\n          if (EXPECT(NULL == type_descr, FALSE)) {\n            mark_stack_top--;\n            continue;\n          }\n          descr = *(word *)(type_descr\n                            - ((GC_signed_word)descr\n                               + (GC_INDIR_PER_OBJ_BIAS - GC_DS_PER_OBJECT)));\n        }\n        if (0 == descr) {\n          /* Can happen either because we generated a 0 descriptor  */\n          /* or we saw a pointer to a free object.                  */\n          mark_stack_top--;\n          continue;\n        }\n        goto retry;\n      }\n    } else {\n      /* Small object with length descriptor.   */\n      mark_stack_top--;\n#ifndef SMALL_CONFIG\n      if (descr < sizeof(ptr_t))\n        continue;\n#endif\n#ifdef ENABLE_TRACE\n      if (ADDR_INSIDE(GC_trace_ptr, current_p, current_p + descr)) {\n        GC_log_printf(\"GC #%lu: small object; start %p, len %lu\\n\",\n                      (unsigned long)GC_gc_no, (void *)current_p,\n                      (unsigned long)descr);\n      }\n#endif\n      limit = current_p + descr;\n    }\n    /* The simple case in which we're scanning a range. */\n    GC_ASSERT((ADDR(current_p) & (ALIGNMENT - 1)) == 0);\n    credit -= limit - current_p;\n    limit -= sizeof(ptr_t);\n    {\n#define PREF_DIST 4\n\n#if !defined(SMALL_CONFIG) && !(defined(E2K) && defined(USE_PTR_HWTAG))\n      ptr_t deferred;\n\n#  ifdef CHERI_PURECAP\n      /* Check each pointer for validity before dereferencing         */\n      /* to prevent capability exceptions.  Utilize the pointer       */\n      /* meta-data to speed-up the loop.  If the loop is below the    */\n      /* pointer bounds, skip the rest of marking for that chunk.     */\n      /* If the limit capability restricts us to reading fewer than   */\n      /* size of a pointer, then there cannot possibly be a pointer   */\n      /* at limit's pointer, and reading at that location will raise  */\n      /* a capability exception.                                      */\n      {\n        word cap_limit = cheri_base_get(limit) + cheri_length_get(limit);\n\n        if (ADDR(limit) + sizeof(ptr_t) > cap_limit) {\n          /* Decrement limit so that it to be within bounds of current_p. */\n          GC_ASSERT(cap_limit > sizeof(ptr_t));\n          limit = (ptr_t)cheri_address_set(\n              current_p, (cap_limit - sizeof(ptr_t)) & ~(sizeof(ptr_t) - 1));\n          goto check_limit;\n        }\n      }\n#  endif\n      /* Try to prefetch the next pointer to be examined ASAP.        */\n      /* Empirically, this also seems to help slightly without        */\n      /* prefetches, at least on Linux/i686.  Presumably this loop    */\n      /* ends up with less register pressure, and gcc thus ends up    */\n      /* generating slightly better code.  Overall gcc code quality   */\n      /* for this loop is still not great.                            */\n      for (;;) {\n        PREFETCH(limit - PREF_DIST * CACHE_LINE_SIZE);\n        GC_ASSERT(ADDR_GE(limit, current_p));\n#  ifdef CHERI_PURECAP\n        if (ADDR(limit) < cheri_base_get(limit))\n          goto next_object;\n        if (!HAS_TAG_AND_PERM_LOAD(limit)) {\n          limit -= ALIGNMENT;\n          goto check_limit;\n        }\n#  endif\n        deferred = *(ptr_t *)limit;\n        FIXUP_POINTER(deferred);\n        limit -= ALIGNMENT;\n#  ifdef CHERI_PURECAP\n        if (!HAS_TAG_AND_PERM_LOAD(deferred))\n          goto check_limit;\n#  endif\n        if (ADDR_LT(least_ha, deferred) && ADDR_LT(deferred, greatest_ha)) {\n          PREFETCH(deferred);\n          break;\n        }\n#  ifndef CHERI_PURECAP\n        if (ADDR_LT(limit, current_p))\n          goto next_object;\n        /* Unroll once, so we don't do too many of the prefetches     */\n        /* based on limit.                                            */\n        deferred = *(ptr_t *)limit;\n        FIXUP_POINTER(deferred);\n        limit -= ALIGNMENT;\n        if (ADDR_LT(least_ha, deferred) && ADDR_LT(deferred, greatest_ha)) {\n          PREFETCH(deferred);\n          break;\n        }\n#  else\n      check_limit:\n#  endif\n        if (ADDR_LT(limit, current_p))\n          goto next_object;\n      }\n#endif\n\n      for (; ADDR_GE(limit, current_p); current_p += ALIGNMENT) {\n        /* Empirically, unrolling this loop doesn't help a lot. */\n        /* Since PUSH_CONTENTS expands to a lot of code,        */\n        /* we don't.                                            */\n        LOAD_PTR_OR_CONTINUE(q, current_p);\n        FIXUP_POINTER(q);\n        PREFETCH(current_p + PREF_DIST * CACHE_LINE_SIZE);\n        if (ADDR_LT(least_ha, q) && ADDR_LT(q, greatest_ha)) {\n          /* Prefetch the content of the object we just pushed.  It is  */\n          /* likely we will need them soon.                             */\n          PREFETCH(q);\n#ifdef ENABLE_TRACE\n          if (GC_trace_ptr == current_p) {\n            GC_log_printf(\"GC #%lu: considering(1) %p -> %p\\n\",\n                          (unsigned long)GC_gc_no, (void *)current_p,\n                          (void *)q);\n          }\n#endif\n          PUSH_CONTENTS(q, mark_stack_top, mark_stack_limit, current_p);\n        }\n      }\n\n#if !defined(SMALL_CONFIG) && !(defined(E2K) && defined(USE_PTR_HWTAG))\n      /* We still need to mark the entry we previously prefetched.    */\n      /* We already know that it passes the preliminary pointer       */\n      /* validity test.                                               */\n#  ifdef ENABLE_TRACE\n      if (GC_trace_ptr == current_p) {\n        GC_log_printf(\"GC #%lu: considering(2) %p -> %p\\n\",\n                      (unsigned long)GC_gc_no, (void *)current_p,\n                      (void *)deferred);\n      }\n#  endif\n      PUSH_CONTENTS(deferred, mark_stack_top, mark_stack_limit, current_p);\n    next_object:;\n#endif\n    }\n  }\n  return mark_stack_top;\n}\n\n#ifdef PARALLEL_MARK\n\n/* Note: this is protected by the mark lock.  */\nSTATIC GC_bool GC_help_wanted = FALSE;\n\n/* Number of running helpers.  Protected by the mark lock.    */\nSTATIC unsigned GC_helper_count = 0;\n\n/* Number of active helpers.  May increase and decrease within each   */\n/* mark cycle; but once it returns to 0, it stays zero for the cycle. */\n/* Protected by the mark lock.                                        */\nSTATIC unsigned GC_active_count = 0;\n\nGC_INNER word GC_mark_no = 0;\n\n#  ifdef LINT2\n#    define LOCAL_MARK_STACK_SIZE (HBLKSIZE / 8)\n#  else\n/* Under normal circumstances, this is big enough to guarantee we do  */\n/* not overflow half of it in a single call to GC_mark_from.          */\n#    define LOCAL_MARK_STACK_SIZE HBLKSIZE\n#  endif\n\n/* Wait all markers to finish initialization (i.e. store        */\n/* marker_[b]sp, marker_mach_threads, GC_marker_Id).            */\nGC_INNER void\nGC_wait_for_markers_init(void)\n{\n  GC_signed_word count;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_markers_m1 == 0)\n    return;\n\n    /* Allocate the local mark stack for the thread that holds    */\n    /* the allocator lock.                                        */\n#  ifndef CAN_HANDLE_FORK\n  GC_ASSERT(NULL == GC_main_local_mark_stack);\n#  else\n  if (NULL == GC_main_local_mark_stack)\n#  endif\n  {\n    size_t bytes_to_get\n        = ROUNDUP_PAGESIZE_IF_MMAP(LOCAL_MARK_STACK_SIZE * sizeof(mse));\n\n    GC_ASSERT(GC_page_size != 0);\n    GC_main_local_mark_stack = (mse *)GC_os_get_mem(bytes_to_get);\n    if (NULL == GC_main_local_mark_stack)\n      ABORT(\"Insufficient memory for main local_mark_stack\");\n  }\n\n  /* Reuse the mark lock and builders count to synchronize      */\n  /* marker threads startup.                                    */\n  GC_acquire_mark_lock();\n  GC_fl_builder_count += GC_markers_m1;\n  count = GC_fl_builder_count;\n  GC_release_mark_lock();\n  if (count != 0) {\n    GC_ASSERT(count > 0);\n    GC_wait_for_reclaim();\n  }\n}\n\n/* Steal mark stack entries starting at mse low into mark stack local   */\n/* until we either steal mse high, or we have n_to_get entries.         */\n/* Return a pointer to the top of the local mark stack.                 */\n/* (*next) is replaced by a pointer to the next unscanned mark stack    */\n/* entry.                                                               */\nSTATIC mse *\nGC_steal_mark_stack(mse *low, mse *high, mse *local, size_t n_to_get,\n                    mse **next)\n{\n  mse *p;\n  mse *top = local - 1;\n  size_t i = 0;\n\n  GC_ASSERT(ADDR_GE((ptr_t)high, (ptr_t)(low - 1))\n            && (word)(high - low + 1) <= GC_mark_stack_size);\n  for (p = low; ADDR_GE((ptr_t)high, (ptr_t)p) && i <= n_to_get; ++p) {\n    word descr = AO_load(&p->mse_descr);\n\n    if (descr != 0) {\n      /* Must be ordered after read of descr: */\n      AO_store_release_write(&p->mse_descr, 0);\n      /* More than one thread may get this entry, but that's only */\n      /* a minor performance problem.                             */\n      ++top;\n      top->mse_start = p->mse_start;\n      top->mse_descr = descr;\n      GC_ASSERT((descr & GC_DS_TAGS) != GC_DS_LENGTH /* 0 */\n                || descr < GC_greatest_real_heap_addr - GC_least_real_heap_addr\n                || GC_least_real_heap_addr + sizeof(ptr_t)\n                       >= ADDR(p->mse_start) + descr\n                || ADDR(p->mse_start) >= GC_greatest_real_heap_addr);\n      /* If this is a big object, count it as size/256 + 1 objects. */\n      ++i;\n      if ((descr & GC_DS_TAGS) == GC_DS_LENGTH)\n        i += (size_t)(descr >> 8);\n    }\n  }\n  *next = p;\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(local);\n#  endif\n  return top;\n}\n\n/* Copy back a local mark stack.  low and high are inclusive bounds.    */\nSTATIC void\nGC_return_mark_stack(mse *low, mse *high)\n{\n  mse *my_top;\n  mse *my_start;\n  size_t stack_size;\n\n  if (ADDR_LT((ptr_t)high, (ptr_t)low))\n    return;\n  stack_size = high - low + 1;\n  GC_acquire_mark_lock();\n  /* Note: the concurrent modification is impossible. */\n  my_top = GC_mark_stack_top;\n  my_start = my_top + 1;\n  if ((word)(my_start - GC_mark_stack + stack_size)\n      > (word)GC_mark_stack_size) {\n    GC_COND_LOG_PRINTF(\"No room to copy back mark stack\\n\");\n    GC_mark_state = MS_INVALID;\n    GC_mark_stack_too_small = TRUE;\n    /* We drop the local mark stack.  We'll fix things later. */\n  } else {\n    BCOPY(low, my_start, stack_size * sizeof(mse));\n    GC_ASSERT((mse *)GC_cptr_load((volatile ptr_t *)&GC_mark_stack_top)\n              == my_top);\n    /* Ensures visibility of previously written stack contents.   */\n    GC_cptr_store_release_write((volatile ptr_t *)&GC_mark_stack_top,\n                                (ptr_t)(my_top + stack_size));\n  }\n  GC_release_mark_lock();\n  GC_notify_all_marker();\n}\n\n#  ifndef N_LOCAL_ITERS\n#    define N_LOCAL_ITERS 1\n#  endif\n\n/* Note: called only when the local and the main mark stacks are both   */\n/* empty.                                                               */\nstatic GC_bool\nhas_inactive_helpers(void)\n{\n  GC_bool res;\n\n  GC_acquire_mark_lock();\n  res = GC_active_count < GC_helper_count;\n  GC_release_mark_lock();\n  return res;\n}\n\n/* Mark from the local mark stack.              */\n/* On return, the local mark stack is empty.    */\n/* But this may be achieved by copying the      */\n/* local mark stack back into the global one.   */\n/* We do not hold the mark lock.                */\nSTATIC void\nGC_do_local_mark(mse *local_mark_stack, mse *local_top)\n{\n  unsigned n;\n\n  for (;;) {\n    for (n = 0; n < N_LOCAL_ITERS; ++n) {\n      local_top = GC_mark_from(local_top, local_mark_stack,\n                               local_mark_stack + LOCAL_MARK_STACK_SIZE);\n      if (ADDR_LT((ptr_t)local_top, (ptr_t)local_mark_stack))\n        return;\n      if ((word)(local_top - local_mark_stack) >= LOCAL_MARK_STACK_SIZE / 2) {\n        GC_return_mark_stack(local_mark_stack, local_top);\n        return;\n      }\n    }\n    if (ADDR_LT(GC_cptr_load((volatile ptr_t *)&GC_mark_stack_top),\n                GC_cptr_load(&GC_first_nonempty))\n        && ADDR_LT((ptr_t)(local_mark_stack + 1), (ptr_t)local_top)\n        && has_inactive_helpers()) {\n      /* Try to share the load, since the main stack is empty,    */\n      /* and helper threads are waiting for a refill.             */\n      /* The entries near the bottom of the stack are likely      */\n      /* to require more work.  Thus we return those, even though */\n      /* it's harder.                                             */\n      mse *new_bottom = local_mark_stack + (local_top - local_mark_stack) / 2;\n\n      GC_ASSERT(ADDR_LT((ptr_t)local_mark_stack, (ptr_t)new_bottom)\n                && ADDR_LT((ptr_t)new_bottom, (ptr_t)local_top));\n      GC_return_mark_stack(local_mark_stack, new_bottom - 1);\n      memmove(local_mark_stack, new_bottom,\n              (local_top - new_bottom + 1) * sizeof(mse));\n      local_top -= new_bottom - local_mark_stack;\n    }\n  }\n}\n\n#  ifndef ENTRIES_TO_GET\n#    define ENTRIES_TO_GET 5\n#  endif\n\n/* Mark using the local mark stack until the global mark stack is empty */\n/* and there are no active workers. Update GC_first_nonempty to reflect */\n/* progress.  Caller holds the mark lock.                               */\n/* Caller has already incremented GC_helper_count.  We decrement it,    */\n/* and maintain GC_active_count.                                        */\nSTATIC void\nGC_mark_local(mse *local_mark_stack, int id)\n{\n  mse *my_first_nonempty;\n\n  GC_active_count++;\n  my_first_nonempty = (mse *)GC_cptr_load(&GC_first_nonempty);\n  GC_ASSERT(ADDR_GE((ptr_t)my_first_nonempty, (ptr_t)GC_mark_stack));\n  GC_ASSERT(\n      ADDR_GE(GC_cptr_load((volatile ptr_t *)&GC_mark_stack_top) + sizeof(mse),\n              (ptr_t)my_first_nonempty));\n  GC_VERBOSE_LOG_PRINTF(\"Starting mark helper %d\\n\", id);\n  GC_release_mark_lock();\n  for (;;) {\n    size_t n_on_stack, n_to_get;\n    mse *my_top, *local_top;\n    mse *global_first_nonempty = (mse *)GC_cptr_load(&GC_first_nonempty);\n\n    GC_ASSERT(ADDR_GE((ptr_t)my_first_nonempty, (ptr_t)GC_mark_stack)\n              && ADDR_GE(GC_cptr_load((volatile ptr_t *)&GC_mark_stack_top)\n                             + sizeof(mse),\n                         (ptr_t)my_first_nonempty));\n    GC_ASSERT(ADDR_GE((ptr_t)global_first_nonempty, (ptr_t)GC_mark_stack));\n    if (ADDR_LT((ptr_t)my_first_nonempty, (ptr_t)global_first_nonempty)) {\n      my_first_nonempty = global_first_nonempty;\n    } else if (ADDR_LT((ptr_t)global_first_nonempty,\n                       (ptr_t)my_first_nonempty)) {\n      (void)GC_cptr_compare_and_swap(&GC_first_nonempty,\n                                     (ptr_t)global_first_nonempty,\n                                     (ptr_t)my_first_nonempty);\n      /* If this fails, we just go ahead, without updating        */\n      /* GC_first_nonempty.                                       */\n    }\n    /* Perhaps we should also update GC_first_nonempty, if it */\n    /* is less.  But that would require using atomic updates. */\n    my_top = (mse *)GC_cptr_load_acquire((volatile ptr_t *)&GC_mark_stack_top);\n    if (ADDR_LT((ptr_t)my_top, (ptr_t)my_first_nonempty)) {\n      GC_acquire_mark_lock();\n      /* Note: asynchronous modification is impossible here,      */\n      /* since we hold the mark lock.                             */\n      my_top = GC_mark_stack_top;\n      n_on_stack = my_top - my_first_nonempty + 1;\n      if (0 == n_on_stack) {\n        GC_active_count--;\n        GC_ASSERT(GC_active_count <= GC_helper_count);\n        /* Other markers may redeposit objects on the stack.    */\n        if (0 == GC_active_count)\n          GC_notify_all_marker();\n        while (GC_active_count > 0\n               && ADDR_LT((ptr_t)GC_mark_stack_top,\n                          GC_cptr_load(&GC_first_nonempty))) {\n          /* We will be notified if either GC_active_count    */\n          /* reaches zero, or if more objects are pushed on   */\n          /* the global mark stack.                           */\n          GC_wait_marker();\n        }\n        if (0 == GC_active_count\n            && ADDR_LT((ptr_t)GC_mark_stack_top,\n                       GC_cptr_load(&GC_first_nonempty))) {\n          GC_bool need_to_notify = FALSE;\n\n          /* The above conditions can't be falsified while we */\n          /* hold the mark lock, since neither                */\n          /* GC_active_count nor GC_mark_stack_top can        */\n          /* change.  GC_first_nonempty can only be           */\n          /* incremented asynchronously.  Thus we know that   */\n          /* both conditions actually held simultaneously.    */\n          GC_helper_count--;\n          if (0 == GC_helper_count)\n            need_to_notify = TRUE;\n          GC_VERBOSE_LOG_PRINTF(\"Finished mark helper %d\\n\", id);\n          if (need_to_notify)\n            GC_notify_all_marker();\n          return;\n        }\n        /* Else there's something on the stack again, or        */\n        /* another helper may push something.                   */\n        GC_active_count++;\n        GC_ASSERT(GC_active_count > 0);\n        GC_release_mark_lock();\n        continue;\n      } else {\n        GC_release_mark_lock();\n      }\n    } else {\n      n_on_stack = my_top - my_first_nonempty + 1;\n    }\n    n_to_get = ENTRIES_TO_GET;\n    if (n_on_stack < 2 * ENTRIES_TO_GET)\n      n_to_get = 1;\n    local_top\n        = GC_steal_mark_stack(my_first_nonempty, my_top, local_mark_stack,\n                              n_to_get, &my_first_nonempty);\n    GC_ASSERT(ADDR_GE((ptr_t)my_first_nonempty, (ptr_t)GC_mark_stack)\n              && ADDR_GE(GC_cptr_load((volatile ptr_t *)&GC_mark_stack_top)\n                             + sizeof(mse),\n                         (ptr_t)my_first_nonempty));\n    GC_do_local_mark(local_mark_stack, local_top);\n  }\n}\n\n/* Perform parallel mark.  We hold the allocator lock, but not the mark */\n/* lock.  Currently runs until the mark stack is empty.                 */\nSTATIC void\nGC_do_parallel_mark(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_acquire_mark_lock();\n  GC_ASSERT(!GC_help_wanted);\n  GC_ASSERT(0 == GC_active_count && 0 == GC_helper_count);\n  GC_VERBOSE_LOG_PRINTF(\"Starting marking for mark phase number %lu\\n\",\n                        (unsigned long)GC_mark_no);\n\n  GC_cptr_store(&GC_first_nonempty, (ptr_t)GC_mark_stack);\n  GC_active_count = 0;\n  GC_helper_count = 1;\n  GC_help_wanted = TRUE;\n  /* Wake up potential helpers.       */\n  GC_notify_all_marker();\n  GC_mark_local(GC_main_local_mark_stack, 0);\n  GC_help_wanted = FALSE;\n  /* Done; clean up.  */\n  while (GC_helper_count > 0) {\n    GC_wait_marker();\n  }\n  /* GC_helper_count cannot be incremented while not GC_help_wanted.  */\n  GC_VERBOSE_LOG_PRINTF(\"Finished marking for mark phase number %lu\\n\",\n                        (unsigned long)GC_mark_no);\n  GC_mark_no++;\n  GC_release_mark_lock();\n  GC_notify_all_marker();\n}\n\n/* Try to help out the marker, if it's running.  We hold the mark lock  */\n/* only, the initiating thread holds the allocator lock.                */\nGC_INNER void\nGC_help_marker(word my_mark_no)\n{\n#  define my_id my_id_mse.mse_descr\n  mse my_id_mse; /* align local_mark_stack explicitly */\n  mse local_mark_stack[LOCAL_MARK_STACK_SIZE];\n  /* Note: local_mark_stack is quite big (up to 128 KiB).     */\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  GC_ASSERT(GC_parallel);\n  while (GC_mark_no < my_mark_no\n         || (!GC_help_wanted && GC_mark_no == my_mark_no)) {\n    GC_wait_marker();\n  }\n  my_id = GC_helper_count;\n  if (GC_mark_no != my_mark_no || my_id > (unsigned)GC_markers_m1) {\n    /* Second test is useful only if original threads can also        */\n    /* act as helpers.  Under Linux they can't.                       */\n    return;\n  }\n  GC_helper_count = (unsigned)my_id + 1;\n  GC_mark_local(local_mark_stack, (int)my_id);\n  /* GC_mark_local decrements GC_helper_count. */\n#  undef my_id\n}\n\n#endif /* PARALLEL_MARK */\n\n/* Allocate or reallocate space for mark stack of size n entries.  */\n/* May silently fail.                                              */\nstatic void\nalloc_mark_stack(size_t n)\n{\n#ifdef GWW_VDB\n  static GC_bool GC_incremental_at_stack_alloc = FALSE;\n\n  GC_bool recycle_old;\n#endif\n  mse *new_stack;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  new_stack = (mse *)GC_scratch_alloc(n * sizeof(struct GC_ms_entry));\n#ifdef GWW_VDB\n  /* Don't recycle a stack segment obtained with the wrong flags.   */\n  /* Win32 GetWriteWatch requires the right kind of memory.         */\n  recycle_old = !GC_auto_incremental || GC_incremental_at_stack_alloc;\n  GC_incremental_at_stack_alloc = GC_auto_incremental;\n#endif\n\n  GC_mark_stack_too_small = FALSE;\n  if (GC_mark_stack != NULL) {\n    if (new_stack != 0) {\n#ifdef GWW_VDB\n      if (recycle_old)\n#endif\n      {\n        /* Recycle old space.       */\n        GC_scratch_recycle_inner(\n            GC_mark_stack, GC_mark_stack_size * sizeof(struct GC_ms_entry));\n      }\n      GC_mark_stack = new_stack;\n      GC_mark_stack_size = n;\n      /* FIXME: Do we need some way to reset GC_mark_stack_size?    */\n      GC_mark_stack_limit = new_stack + n;\n      GC_COND_LOG_PRINTF(\"Grew mark stack to %lu frames\\n\",\n                         (unsigned long)GC_mark_stack_size);\n    } else {\n      WARN(\"Failed to grow mark stack to %\" WARN_PRIuPTR \" frames\\n\", n);\n    }\n  } else if (NULL == new_stack) {\n    GC_err_printf(\"No space for mark stack\\n\");\n    EXIT();\n  } else {\n    GC_mark_stack = new_stack;\n    GC_mark_stack_size = n;\n    GC_mark_stack_limit = new_stack + n;\n  }\n  GC_mark_stack_top = GC_mark_stack - 1;\n}\n\nGC_INNER void\nGC_mark_init(void)\n{\n  alloc_mark_stack(INITIAL_MARK_STACK_SIZE);\n}\n\n/* Push all locations between bottom and top onto the mark stack.   */\n/* bottom is the first location to be checked; top is one past the  */\n/* last location to be checked.  Should only be used if there is    */\n/* no possibility of mark stack overflow.                           */\nGC_API void GC_CALL\nGC_push_all(void *bottom, void *top)\n{\n  mse *mark_stack_top;\n  word length;\n\n  bottom = PTR_ALIGN_UP((ptr_t)bottom, ALIGNMENT);\n  top = PTR_ALIGN_DOWN((ptr_t)top, ALIGNMENT);\n  if (ADDR_GE((ptr_t)bottom, (ptr_t)top))\n    return;\n\n  mark_stack_top = GC_mark_stack_top + 1;\n  if (ADDR_GE((ptr_t)mark_stack_top, (ptr_t)GC_mark_stack_limit)) {\n    ABORT(\"Unexpected mark stack overflow\");\n  }\n  length = (word)((ptr_t)top - (ptr_t)bottom);\n#if GC_DS_TAGS > ALIGNMENT - 1\n  length = (length + GC_DS_TAGS) & ~(word)GC_DS_TAGS; /* round up */\n#endif\n  mark_stack_top->mse_start = (ptr_t)bottom;\n  mark_stack_top->mse_descr = length | GC_DS_LENGTH;\n  GC_mark_stack_top = mark_stack_top;\n}\n\nGC_API struct GC_ms_entry *GC_CALL\nGC_custom_push_range(void *bottom, void *top,\n                     struct GC_ms_entry *mark_stack_top,\n                     struct GC_ms_entry *mark_stack_limit)\n{\n  word length;\n\n  bottom = PTR_ALIGN_UP((ptr_t)bottom, ALIGNMENT);\n  top = PTR_ALIGN_DOWN((ptr_t)top, ALIGNMENT);\n  if (ADDR_GE((ptr_t)bottom, (ptr_t)top))\n    return mark_stack_top;\n\n  length = (word)((ptr_t)top - (ptr_t)bottom);\n#if GC_DS_TAGS > ALIGNMENT - 1\n  length = (length + GC_DS_TAGS) & ~(word)GC_DS_TAGS; /* round up */\n#endif\n  return GC_custom_push_proc(length | GC_DS_LENGTH, bottom, mark_stack_top,\n                             mark_stack_limit);\n}\n\nGC_API struct GC_ms_entry *GC_CALL\nGC_custom_push_proc(GC_word descr, void *obj,\n                    struct GC_ms_entry *mark_stack_top,\n                    struct GC_ms_entry *mark_stack_limit)\n{\n  mark_stack_top++;\n  if (ADDR_GE((ptr_t)mark_stack_top, (ptr_t)mark_stack_limit)) {\n    mark_stack_top = GC_signal_mark_stack_overflow(mark_stack_top);\n  }\n  mark_stack_top->mse_start = (ptr_t)obj;\n  mark_stack_top->mse_descr = descr;\n  return mark_stack_top;\n}\n\nGC_API void GC_CALL\nGC_push_proc(GC_word descr, void *obj)\n{\n  GC_mark_stack_top = GC_custom_push_proc(descr, obj, GC_mark_stack_top,\n                                          GC_mark_stack_limit);\n}\n\n#ifndef GC_DISABLE_INCREMENTAL\n\n/* Analogous to the above, but push only those pages h with           */\n/* dirty_fn(h) != 0.  We use GC_push_all to actually push the block.  */\n/* Used both to selectively push dirty pages, or to push a block in   */\n/* piecemeal fashion, to allow for more marking concurrency.          */\n/* Will not overflow mark stack if GC_push_all pushes a small fixed   */\n/* number of entries.  (This is invoked only if GC_push_all pushes    */\n/* a single entry, or if it marks each object before pushing it, thus */\n/* ensuring progress in the event of a stack overflow.)               */\nSTATIC void\nGC_push_selected(ptr_t bottom, ptr_t top, GC_bool (*dirty_fn)(struct hblk *))\n{\n  struct hblk *h;\n\n  bottom = PTR_ALIGN_UP(bottom, ALIGNMENT);\n  top = PTR_ALIGN_DOWN(top, ALIGNMENT);\n  if (ADDR_GE(bottom, top))\n    return;\n\n  h = HBLKPTR(bottom + HBLKSIZE);\n  if (ADDR_GE((ptr_t)h, top)) {\n    if ((*dirty_fn)(h - 1)) {\n      GC_push_all(bottom, top);\n    }\n    return;\n  }\n  if ((*dirty_fn)(h - 1)) {\n    if ((word)(GC_mark_stack_top - GC_mark_stack)\n        > 3 * GC_mark_stack_size / 4) {\n      GC_push_all(bottom, top);\n      return;\n    }\n    GC_push_all(bottom, h);\n  }\n\n  while (ADDR_GE(top, (ptr_t)(h + 1))) {\n    if ((*dirty_fn)(h)) {\n      if ((word)(GC_mark_stack_top - GC_mark_stack)\n          > 3 * GC_mark_stack_size / 4) {\n        /* Danger of mark stack overflow.       */\n        GC_push_all(h, top);\n        return;\n      } else {\n        GC_push_all(h, h + 1);\n      }\n    }\n    h++;\n  }\n\n  if ((ptr_t)h != top && (*dirty_fn)(h)) {\n    GC_push_all(h, top);\n  }\n}\n\nGC_API void GC_CALL\nGC_push_conditional(void *bottom, void *top, int all)\n{\n  if (!all) {\n    GC_push_selected((ptr_t)bottom, (ptr_t)top, GC_page_was_dirty);\n  } else {\n#  ifdef PROC_VDB\n    if (GC_auto_incremental) {\n      /* Pages that were never dirtied cannot contain pointers.     */\n      GC_push_selected((ptr_t)bottom, (ptr_t)top, GC_page_was_ever_dirty);\n    } else\n#  endif\n    /* else */ {\n      GC_push_all(bottom, top);\n    }\n  }\n}\n\n#  ifndef NO_VDB_FOR_STATIC_ROOTS\n#    ifndef PROC_VDB\n/* Same as GC_page_was_dirty but h is allowed to point to some    */\n/* page in the registered static roots only.  Not used if         */\n/* manual VDB is on.                                              */\nSTATIC GC_bool\nGC_static_page_was_dirty(struct hblk *h)\n{\n  return get_pht_entry_from_index(GC_grungy_pages, PHT_HASH(h));\n}\n#    endif\n\nGC_INNER void\nGC_push_conditional_static(void *bottom, void *top, GC_bool all)\n{\n#    ifdef PROC_VDB\n  /* Just redirect to the generic routine because PROC_VDB        */\n  /* implementation gets the dirty bits map for the whole         */\n  /* process memory.                                              */\n  GC_push_conditional(bottom, top, all);\n#    else\n  if (all || !GC_is_vdb_for_static_roots()) {\n    GC_push_all(bottom, top);\n  } else {\n    GC_push_selected((ptr_t)bottom, (ptr_t)top, GC_static_page_was_dirty);\n  }\n#    endif\n}\n#  endif /* !NO_VDB_FOR_STATIC_ROOTS */\n\n#else\nGC_API void GC_CALL\nGC_push_conditional(void *bottom, void *top, int all)\n{\n  UNUSED_ARG(all);\n  GC_push_all(bottom, top);\n}\n#endif /* GC_DISABLE_INCREMENTAL */\n\n#if defined(DARWIN) && defined(THREADS)\nvoid\nGC_push_one(word p)\n{\n  GC_PUSH_ONE_STACK((ptr_t)p, MARKED_FROM_REGISTER);\n}\n#endif /* DARWIN && THREADS */\n\n#if defined(GC_WIN32_THREADS)\nGC_INNER void\nGC_push_many_regs(const word *regs, unsigned count)\n{\n  unsigned i;\n\n  for (i = 0; i < count; i++)\n    GC_PUSH_ONE_STACK((ptr_t)regs[i], MARKED_FROM_REGISTER);\n}\n#endif /* GC_WIN32_THREADS */\n\nGC_API struct GC_ms_entry *GC_CALL\nGC_mark_and_push(void *obj, mse *mark_stack_top, mse *mark_stack_limit,\n                 void **src)\n{\n  hdr *hhdr;\n\n  PREFETCH(obj);\n  GET_HDR(obj, hhdr);\n  if ((EXPECT(IS_FORWARDING_ADDR_OR_NIL(hhdr), FALSE)\n       && (!GC_all_interior_pointers\n           || NULL == (hhdr = GC_find_header(GC_base(obj)))))\n      || EXPECT(HBLK_IS_FREE(hhdr), FALSE)) {\n    GC_ADD_TO_BLACK_LIST_NORMAL((ptr_t)obj, (ptr_t)src);\n    return mark_stack_top;\n  }\n  return GC_push_contents_hdr((ptr_t)obj, mark_stack_top, mark_stack_limit,\n                              (ptr_t)src, hhdr, TRUE);\n}\n\nGC_ATTR_NO_SANITIZE_ADDR\nGC_INNER void\n#if defined(PRINT_BLACK_LIST) || defined(KEEP_BACK_PTRS)\nGC_mark_and_push_stack(ptr_t p, ptr_t source)\n#else\nGC_mark_and_push_stack(ptr_t p)\n#  define source ((ptr_t)0)\n#endif\n{\n  hdr *hhdr;\n  ptr_t r = p;\n\n  PREFETCH(p);\n  GET_HDR(p, hhdr);\n  if (EXPECT(IS_FORWARDING_ADDR_OR_NIL(hhdr), FALSE)) {\n    if (NULL == hhdr || (r = (ptr_t)GC_base(p)) == NULL\n        || (hhdr = HDR(r)) == NULL) {\n      GC_ADD_TO_BLACK_LIST_STACK(p, source);\n      return;\n    }\n  }\n  if (EXPECT(HBLK_IS_FREE(hhdr), FALSE)) {\n    GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n    return;\n  }\n#ifdef THREADS\n  /* Pointer is on the stack.  We may have dirtied the object       */\n  /* it points to, but have not called GC_dirty yet.                */\n  GC_dirty(p); /* entire object */\n#endif\n  GC_mark_stack_top = GC_push_contents_hdr(\n      r, GC_mark_stack_top, GC_mark_stack_limit, source, hhdr, FALSE);\n  /* We silently ignore pointers to near the end of a block,  */\n  /* which is very mildly suboptimal.                         */\n  /* FIXME: We should probably add a header word to address   */\n  /* this.                                                    */\n#undef source\n}\n\n#ifdef TRACE_BUF\n#  ifndef TRACE_ENTRIES\n#    define TRACE_ENTRIES 1000\n#  endif\n\nstruct trace_entry {\n  const char *caller_fn_name;\n  word gc_no;\n  word bytes_allocd;\n  GC_hidden_pointer arg1;\n  GC_hidden_pointer arg2;\n} GC_trace_buf[TRACE_ENTRIES] = { { (const char *)NULL, 0, 0, 0, 0 } };\n\nvoid\nGC_add_trace_entry(const char *caller_fn_name, ptr_t arg1, ptr_t arg2)\n{\n  size_t i = GC_trace_buf_pos;\n\n  GC_trace_buf[i].caller_fn_name = caller_fn_name;\n  GC_trace_buf[i].gc_no = GC_gc_no;\n  GC_trace_buf[i].bytes_allocd = GC_bytes_allocd;\n  GC_trace_buf[i].arg1 = GC_HIDE_POINTER(arg1);\n  GC_trace_buf[i].arg2 = GC_HIDE_POINTER(arg2);\n  i++;\n  if (i >= TRACE_ENTRIES)\n    i = 0;\n  GC_trace_buf_pos = i;\n}\n\nGC_API void GC_CALL\nGC_print_trace_inner(GC_word gc_no)\n{\n  size_t i;\n\n  for (i = GC_trace_buf_pos;; i--) {\n    struct trace_entry *p;\n\n    if (0 == i)\n      i = TRACE_ENTRIES;\n    p = &GC_trace_buf[i - 1];\n    /* Compare gc_no values (p->gc_no is less than given gc_no) */\n    /* taking into account that the counter may overflow.       */\n    if (((p->gc_no - gc_no) & SIGNB) != 0 || NULL == p->caller_fn_name) {\n      return;\n    }\n    GC_printf(\"Trace:%s (gc:%lu, bytes:%lu) %p, %p\\n\", p->caller_fn_name,\n              (unsigned long)p->gc_no, (unsigned long)p->bytes_allocd,\n              GC_REVEAL_POINTER(p->arg1), GC_REVEAL_POINTER(p->arg2));\n    if (i == GC_trace_buf_pos + 1)\n      break;\n  }\n  GC_printf(\"Trace incomplete\\n\");\n}\n\nGC_API void GC_CALL\nGC_print_trace(GC_word gc_no)\n{\n  READER_LOCK();\n  GC_print_trace_inner(gc_no);\n  READER_UNLOCK();\n}\n#endif /* TRACE_BUF */\n\n/* A version of GC_push_all that treats all interior pointers as valid  */\n/* and scans the entire region immediately, in case the contents        */\n/* change.                                                              */\nGC_ATTR_NO_SANITIZE_ADDR_MEM_THREAD\nGC_API void GC_CALL\nGC_push_all_eager(void *bottom, void *top)\n{\n  REGISTER ptr_t current_p;\n  REGISTER word lim_addr;\n  REGISTER ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  REGISTER ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n#define GC_greatest_plausible_heap_addr greatest_ha\n#define GC_least_plausible_heap_addr least_ha\n\n  if (NULL == top)\n    return;\n  /* Check all pointers in range and push if they appear to be valid. */\n  current_p = PTR_ALIGN_UP((ptr_t)bottom, ALIGNMENT);\n  lim_addr = ADDR(PTR_ALIGN_DOWN((ptr_t)top, ALIGNMENT)) - sizeof(ptr_t);\n#ifdef CHERI_PURECAP\n  {\n    word cap_limit = cheri_base_get(current_p) + cheri_length_get(current_p);\n\n    if (lim_addr >= cap_limit)\n      lim_addr = cap_limit - sizeof(ptr_t);\n  }\n#endif\n  for (; ADDR(current_p) <= lim_addr; current_p += ALIGNMENT) {\n    REGISTER ptr_t q;\n\n    LOAD_PTR_OR_CONTINUE(q, current_p);\n    GC_PUSH_ONE_STACK(q, current_p);\n  }\n#undef GC_greatest_plausible_heap_addr\n#undef GC_least_plausible_heap_addr\n}\n\nGC_INNER void\nGC_push_all_stack(ptr_t bottom, ptr_t top)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#ifndef NEED_FIXUP_POINTER\n  if (GC_all_interior_pointers\n#  if defined(THREADS) && defined(MPROTECT_VDB)\n      && !GC_auto_incremental\n#  endif\n      && ADDR_LT((ptr_t)GC_mark_stack_top,\n                 (ptr_t)(GC_mark_stack_limit - INITIAL_MARK_STACK_SIZE / 8))) {\n    GC_push_all(bottom, top);\n  } else\n#endif\n  /* else */ {\n    GC_push_all_eager(bottom, top);\n  }\n}\n\n#if defined(WRAP_MARK_SOME) && defined(PARALLEL_MARK)\n/* Similar to GC_push_conditional but scans the whole region immediately. */\nGC_ATTR_NO_SANITIZE_ADDR_MEM_THREAD\nGC_INNER void\nGC_push_conditional_eager(void *bottom, void *top, GC_bool all)\n{\n  REGISTER ptr_t current_p;\n  REGISTER ptr_t lim;\n  REGISTER ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  REGISTER ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n#  define GC_greatest_plausible_heap_addr greatest_ha\n#  define GC_least_plausible_heap_addr least_ha\n\n  if (NULL == top)\n    return;\n\n  /* TODO: If !all then scan only dirty pages. */\n  (void)all;\n\n  current_p = PTR_ALIGN_UP((ptr_t)bottom, ALIGNMENT);\n  lim = PTR_ALIGN_DOWN((ptr_t)top, ALIGNMENT) - sizeof(ptr_t);\n  for (; ADDR_GE(lim, current_p); current_p += ALIGNMENT) {\n    REGISTER ptr_t q;\n\n    LOAD_PTR_OR_CONTINUE(q, current_p);\n    GC_PUSH_ONE_HEAP(q, current_p, GC_mark_stack_top);\n  }\n#  undef GC_greatest_plausible_heap_addr\n#  undef GC_least_plausible_heap_addr\n}\n#endif /* WRAP_MARK_SOME && PARALLEL_MARK */\n\n#if !defined(SMALL_CONFIG) && !defined(USE_MARK_BYTES) \\\n    && !defined(MARK_BIT_PER_OBJ) && GC_GRANULE_PTRS <= 4\n#  define USE_PUSH_MARKED_ACCELERATORS\n#  if GC_GRANULE_PTRS == 1\n#    define PUSH_GRANULE(q)                                \\\n      do {                                                 \\\n        ptr_t qcontents = (q)[0];                          \\\n        GC_PUSH_ONE_HEAP(qcontents, q, GC_mark_stack_top); \\\n      } while (0)\n#  elif GC_GRANULE_PTRS == 2\n#    define PUSH_GRANULE(q)                                      \\\n      do {                                                       \\\n        ptr_t qcontents = (q)[0];                                \\\n        GC_PUSH_ONE_HEAP(qcontents, q, GC_mark_stack_top);       \\\n        qcontents = (q)[1];                                      \\\n        GC_PUSH_ONE_HEAP(qcontents, (q) + 1, GC_mark_stack_top); \\\n      } while (0)\n#  else\n#    define PUSH_GRANULE(q)                                      \\\n      do {                                                       \\\n        ptr_t qcontents = (q)[0];                                \\\n        GC_PUSH_ONE_HEAP(qcontents, q, GC_mark_stack_top);       \\\n        qcontents = (q)[1];                                      \\\n        GC_PUSH_ONE_HEAP(qcontents, (q) + 1, GC_mark_stack_top); \\\n        qcontents = (q)[2];                                      \\\n        GC_PUSH_ONE_HEAP(qcontents, (q) + 2, GC_mark_stack_top); \\\n        qcontents = (q)[3];                                      \\\n        GC_PUSH_ONE_HEAP(qcontents, (q) + 3, GC_mark_stack_top); \\\n      } while (0)\n#  endif\n\n/* Push all objects reachable from marked objects in the given block  */\n/* containing objects of size 1 granule.                              */\nGC_ATTR_NO_SANITIZE_THREAD\nSTATIC void\nGC_push_marked1(struct hblk *h, const hdr *hhdr)\n{\n  const word *mark_word_addr\n      = (word *)CAST_AWAY_VOLATILE_PVOID(hhdr->hb_marks);\n  ptr_t *p;\n  ptr_t plim;\n\n  /* Allow registers to be used for some frequently accessed  */\n  /* global variables.  Otherwise aliasing issues are likely  */\n  /* to prevent that.                                         */\n  ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n  mse *mark_stack_top = GC_mark_stack_top;\n  mse *mark_stack_limit = GC_mark_stack_limit;\n\n#  undef GC_mark_stack_top\n#  undef GC_mark_stack_limit\n#  define GC_mark_stack_top mark_stack_top\n#  define GC_mark_stack_limit mark_stack_limit\n#  define GC_greatest_plausible_heap_addr greatest_ha\n#  define GC_least_plausible_heap_addr least_ha\n\n  p = (ptr_t *)h->hb_body;\n  plim = (ptr_t)h + HBLKSIZE;\n\n  /* Go through all granules in block.    */\n  while (ADDR_LT((ptr_t)p, plim)) {\n    word mark_word = *mark_word_addr++;\n    ptr_t *q;\n\n    for (q = p; mark_word != 0; mark_word >>= 1) {\n      if ((mark_word & 1) != 0)\n        PUSH_GRANULE(q);\n      q += GC_GRANULE_PTRS;\n    }\n    p += CPP_WORDSZ * GC_GRANULE_PTRS;\n  }\n\n#  undef GC_greatest_plausible_heap_addr\n#  undef GC_least_plausible_heap_addr\n#  undef GC_mark_stack_top\n#  undef GC_mark_stack_limit\n#  define GC_mark_stack_limit GC_arrays._mark_stack_limit\n#  define GC_mark_stack_top GC_arrays._mark_stack_top\n  GC_mark_stack_top = mark_stack_top;\n}\n\n#  ifndef UNALIGNED_PTRS\n/* Push all objects reachable from marked objects in the given  */\n/* block of size 2 (granules) objects.                          */\nGC_ATTR_NO_SANITIZE_THREAD\nSTATIC void\nGC_push_marked2(struct hblk *h, const hdr *hhdr)\n{\n  const word *mark_word_addr\n      = (word *)CAST_AWAY_VOLATILE_PVOID(hhdr->hb_marks);\n  ptr_t *p;\n  ptr_t plim;\n  ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n  mse *mark_stack_top = GC_mark_stack_top;\n  mse *mark_stack_limit = GC_mark_stack_limit;\n\n#    undef GC_mark_stack_top\n#    undef GC_mark_stack_limit\n#    define GC_mark_stack_top mark_stack_top\n#    define GC_mark_stack_limit mark_stack_limit\n#    define GC_greatest_plausible_heap_addr greatest_ha\n#    define GC_least_plausible_heap_addr least_ha\n\n  p = (ptr_t *)h->hb_body;\n  plim = (ptr_t)h + HBLKSIZE;\n\n  /* Go through all granules in block.  */\n  while (ADDR_LT((ptr_t)p, plim)) {\n    word mark_word = *mark_word_addr++;\n    ptr_t *q;\n\n    for (q = p; mark_word != 0; mark_word >>= 2) {\n      if (mark_word & 1) {\n        PUSH_GRANULE(q);\n        PUSH_GRANULE(q + GC_GRANULE_PTRS);\n      }\n      q += 2 * GC_GRANULE_PTRS;\n    }\n    p += CPP_WORDSZ * GC_GRANULE_PTRS;\n  }\n\n#    undef GC_greatest_plausible_heap_addr\n#    undef GC_least_plausible_heap_addr\n#    undef GC_mark_stack_top\n#    undef GC_mark_stack_limit\n#    define GC_mark_stack_limit GC_arrays._mark_stack_limit\n#    define GC_mark_stack_top GC_arrays._mark_stack_top\n  GC_mark_stack_top = mark_stack_top;\n}\n\n#    if GC_GRANULE_PTRS < 4\n/* Push all objects reachable from marked objects in the given    */\n/* block of size 4 (granules) objects.  There is a risk of mark   */\n/* stack overflow here.  But we handle that.  And only unmarked   */\n/* objects get pushed, so it's not very likely.                   */\nGC_ATTR_NO_SANITIZE_THREAD\nSTATIC void\nGC_push_marked4(struct hblk *h, const hdr *hhdr)\n{\n  const word *mark_word_addr\n      = (word *)CAST_AWAY_VOLATILE_PVOID(hhdr->hb_marks);\n  ptr_t *p;\n  ptr_t plim;\n  ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n  mse *mark_stack_top = GC_mark_stack_top;\n  mse *mark_stack_limit = GC_mark_stack_limit;\n\n#      undef GC_mark_stack_top\n#      undef GC_mark_stack_limit\n#      define GC_mark_stack_top mark_stack_top\n#      define GC_mark_stack_limit mark_stack_limit\n#      define GC_greatest_plausible_heap_addr greatest_ha\n#      define GC_least_plausible_heap_addr least_ha\n\n  p = (ptr_t *)h->hb_body;\n  plim = (ptr_t)h + HBLKSIZE;\n\n  /* Go through all granules in block.    */\n  while (ADDR_LT((ptr_t)p, plim)) {\n    word mark_word = *mark_word_addr++;\n    ptr_t *q;\n\n    for (q = p; mark_word != 0; mark_word >>= 4) {\n      if (mark_word & 1) {\n        PUSH_GRANULE(q);\n        PUSH_GRANULE(q + GC_GRANULE_PTRS);\n        PUSH_GRANULE(q + 2 * GC_GRANULE_PTRS);\n        PUSH_GRANULE(q + 3 * GC_GRANULE_PTRS);\n      }\n      q += 4 * GC_GRANULE_PTRS;\n    }\n    p += CPP_WORDSZ * GC_GRANULE_PTRS;\n  }\n#      undef GC_greatest_plausible_heap_addr\n#      undef GC_least_plausible_heap_addr\n#      undef GC_mark_stack_top\n#      undef GC_mark_stack_limit\n#      define GC_mark_stack_limit GC_arrays._mark_stack_limit\n#      define GC_mark_stack_top GC_arrays._mark_stack_top\n  GC_mark_stack_top = mark_stack_top;\n}\n#    endif /* GC_GRANULE_PTRS < 4 */\n#  endif\n#endif /* !USE_MARK_BYTES && !MARK_BIT_PER_OBJ && !SMALL_CONFIG */\n\n/* Push all objects reachable from marked objects in the given block.   */\nSTATIC void\nGC_push_marked(struct hblk *h, const hdr *hhdr)\n{\n  size_t sz = hhdr->hb_sz;\n  ptr_t p;\n  size_t bit_no;\n  ptr_t plim;\n  mse *mark_stack_top;\n  mse *mark_stack_limit = GC_mark_stack_limit;\n\n  /* Some quick shortcuts: */\n  if ((/* 0 | */ GC_DS_LENGTH) == hhdr->hb_descr)\n    return;\n  if (GC_block_empty(hhdr) /* nothing marked */)\n    return;\n\n#if !defined(GC_DISABLE_INCREMENTAL)\n  GC_n_rescuing_pages++;\n#endif\n  GC_objects_are_marked = TRUE;\n  switch (BYTES_TO_GRANULES(sz)) {\n#ifdef USE_PUSH_MARKED_ACCELERATORS\n  case 1:\n    GC_push_marked1(h, hhdr);\n    break;\n#  ifndef UNALIGNED_PTRS\n  case 2:\n    GC_push_marked2(h, hhdr);\n    break;\n#    if GC_GRANULE_PTRS < 4\n  case 4:\n    GC_push_marked4(h, hhdr);\n    break;\n#    endif\n#  endif /* !UNALIGNED_PTRS */\n#else\n  case 1: /* to suppress \"switch statement contains no case\" warning */\n#endif\n  default:\n    plim = sz > MAXOBJBYTES ? h->hb_body\n                            : CAST_THRU_UINTPTR(ptr_t, (h + 1)->hb_body) - sz;\n    mark_stack_top = GC_mark_stack_top;\n    for (p = h->hb_body, bit_no = 0; ADDR_GE(plim, p);\n         p += sz, bit_no += MARK_BIT_OFFSET(sz)) {\n      /* Mark from fields inside the object.  */\n      if (mark_bit_from_hdr(hhdr, bit_no)) {\n        mark_stack_top\n            = GC_push_obj(p, hhdr, mark_stack_top, mark_stack_limit);\n      }\n    }\n    GC_mark_stack_top = mark_stack_top;\n  }\n}\n\n#ifdef ENABLE_DISCLAIM\n/* Unconditionally mark from all objects which have not been          */\n/* reclaimed.  This is useful in order to retain pointers reachable   */\n/* from the disclaim notifiers.                                       */\n/* To determine whether an object has been reclaimed, we require that */\n/* any live object has a non-zero as one of the two least significant */\n/* bits of the first \"pointer-sized\" word.  On the other hand, the    */\n/* reclaimed object is a member of free lists, and thus contains      */\n/* a pointer-aligned next-pointer as the first \"pointer-sized\" word.  */\nGC_ATTR_NO_SANITIZE_THREAD\nSTATIC void\nGC_push_unconditionally(struct hblk *h, const hdr *hhdr)\n{\n  size_t sz = hhdr->hb_sz;\n  ptr_t p;\n  ptr_t plim;\n  mse *mark_stack_top;\n  mse *mark_stack_limit = GC_mark_stack_limit;\n\n  if ((/* 0 | */ GC_DS_LENGTH) == hhdr->hb_descr)\n    return;\n\n#  if !defined(GC_DISABLE_INCREMENTAL)\n  GC_n_rescuing_pages++;\n#  endif\n  GC_objects_are_marked = TRUE;\n  plim = sz > MAXOBJBYTES ? h->hb_body\n                          : CAST_THRU_UINTPTR(ptr_t, (h + 1)->hb_body) - sz;\n  mark_stack_top = GC_mark_stack_top;\n  for (p = h->hb_body; ADDR_GE(plim, p); p += sz) {\n    if ((ADDR(*(ptr_t *)p) & 0x3) != 0) {\n      mark_stack_top = GC_push_obj(p, hhdr, mark_stack_top, mark_stack_limit);\n    }\n  }\n  GC_mark_stack_top = mark_stack_top;\n}\n#endif /* ENABLE_DISCLAIM */\n\n#ifndef GC_DISABLE_INCREMENTAL\n/* Test whether any page in the given block is dirty.   */\nSTATIC GC_bool\nGC_block_was_dirty(struct hblk *h, const hdr *hhdr)\n{\n  size_t sz;\n  ptr_t p;\n\n#  ifdef AO_HAVE_load\n  /* Atomic access is used to avoid racing with GC_realloc. */\n  sz = AO_load(&hhdr->hb_sz);\n#  else\n  sz = hhdr->hb_sz;\n#  endif\n  if (sz <= MAXOBJBYTES) {\n    return GC_page_was_dirty(h);\n  }\n\n  for (p = (ptr_t)h; ADDR_LT(p, (ptr_t)h + sz); p += HBLKSIZE) {\n    if (GC_page_was_dirty((struct hblk *)p))\n      return TRUE;\n  }\n  return FALSE;\n}\n#endif /* GC_DISABLE_INCREMENTAL */\n\n/* Similar to GC_push_marked, but skip over unallocated blocks and      */\n/* return address of next plausible block.                              */\nSTATIC struct hblk *\nGC_push_next_marked(struct hblk *h)\n{\n  hdr *hhdr = HDR(h);\n\n  if (EXPECT(IS_FORWARDING_ADDR_OR_NIL(hhdr) || HBLK_IS_FREE(hhdr), FALSE)) {\n    h = GC_next_block(h, FALSE);\n    if (NULL == h)\n      return NULL;\n    hhdr = GC_find_header(h);\n  } else {\n#ifdef LINT2\n    if (NULL == h)\n      ABORT(\"Bad HDR() definition\");\n#endif\n  }\n  GC_push_marked(h, hhdr);\n  return h + OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n}\n\n#ifndef GC_DISABLE_INCREMENTAL\n/* Identical to GC_push_next_marked, but mark only from dirty pages.  */\nSTATIC struct hblk *\nGC_push_next_marked_dirty(struct hblk *h)\n{\n  hdr *hhdr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_incremental)\n    ABORT(\"Dirty bits not set up\");\n  for (;; h += OBJ_SZ_TO_BLOCKS(hhdr->hb_sz)) {\n    hhdr = HDR(h);\n    if (EXPECT(IS_FORWARDING_ADDR_OR_NIL(hhdr) || HBLK_IS_FREE(hhdr), FALSE)) {\n      h = GC_next_block(h, FALSE);\n      if (NULL == h)\n        return NULL;\n      hhdr = GC_find_header(h);\n    } else {\n#  ifdef LINT2\n      if (NULL == h)\n        ABORT(\"Bad HDR() definition\");\n#  endif\n    }\n    if (GC_block_was_dirty(h, hhdr))\n      break;\n  }\n#  ifdef ENABLE_DISCLAIM\n  if ((hhdr->hb_flags & MARK_UNCONDITIONALLY) != 0) {\n    GC_push_unconditionally(h, hhdr);\n\n    /* Then we may ask, why not also add the MARK_UNCONDITIONALLY   */\n    /* case to GC_push_next_marked, which is also applied to        */\n    /* uncollectible blocks?  But it seems to me that the function  */\n    /* does not need to scan uncollectible (and unconditionally     */\n    /* marked) blocks since those are already handled in the        */\n    /* MS_PUSH_UNCOLLECTABLE phase.                                 */\n  } else\n#  endif\n  /* else */ {\n    GC_push_marked(h, hhdr);\n  }\n  return h + OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n}\n#endif /* !GC_DISABLE_INCREMENTAL */\n\n/* Similar to above, but for uncollectible pages.  Needed since we      */\n/* do not clear marks for such pages, even for full collections.        */\nSTATIC struct hblk *\nGC_push_next_marked_uncollectable(struct hblk *h)\n{\n  hdr *hhdr = HDR(h);\n\n  for (;;) {\n    if (EXPECT(IS_FORWARDING_ADDR_OR_NIL(hhdr) || HBLK_IS_FREE(hhdr), FALSE)) {\n      h = GC_next_block(h, FALSE);\n      if (NULL == h)\n        return NULL;\n      hhdr = GC_find_header(h);\n    } else {\n#ifdef LINT2\n      if (NULL == h)\n        ABORT(\"Bad HDR() definition\");\n#endif\n    }\n    if (hhdr->hb_obj_kind == UNCOLLECTABLE) {\n      GC_push_marked(h, hhdr);\n      break;\n    }\n#ifdef ENABLE_DISCLAIM\n    if ((hhdr->hb_flags & MARK_UNCONDITIONALLY) != 0) {\n      GC_push_unconditionally(h, hhdr);\n      break;\n    }\n#endif\n    h += OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n    hhdr = HDR(h);\n  }\n  return h + OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n}\n"
        },
        {
          "name": "mark_rts.c",
          "type": "blob",
          "size": 30.5966796875,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 2009-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#if defined(E2K) && !defined(THREADS)\n#  include <alloca.h>\n#endif\n\n/* Data structure for list of root sets.                                */\n/* We keep a hash table, so that we can filter out duplicate additions. */\n/* Under Win32, we need to do a better job of filtering overlaps, so    */\n/* we resort to sequential search, and pay the price.                   */\n/* This is really declared in gc_priv.h:\nstruct roots {\n        ptr_t r_start;\n        ptr_t r_end;\n#       ifndef ANY_MSWIN\n          struct roots * r_next;\n#       endif\n        GC_bool r_tmp;\n                -- Delete before registering new dynamic libraries\n};\n\nstruct roots GC_static_roots[MAX_ROOT_SETS];\n*/\n\n/* Register dynamic library data segments.      */\nint GC_no_dls = 0;\n\n#if !defined(NO_DEBUGGING) || defined(GC_ASSERTIONS)\n/* Should return the same value as GC_root_size.      */\nGC_INNER word\nGC_compute_root_size(void)\n{\n  size_t i;\n  word size = 0;\n\n  for (i = 0; i < n_root_sets; i++) {\n    size += (word)(GC_static_roots[i].r_end - GC_static_roots[i].r_start);\n  }\n  return size;\n}\n#endif /* !NO_DEBUGGING || GC_ASSERTIONS */\n\n#if !defined(NO_DEBUGGING)\n/* For debugging:     */\nvoid\nGC_print_static_roots(void)\n{\n  size_t i;\n  word size;\n\n  for (i = 0; i < n_root_sets; i++) {\n    GC_printf(\"From %p to %p%s\\n\", (void *)GC_static_roots[i].r_start,\n              (void *)GC_static_roots[i].r_end,\n              GC_static_roots[i].r_tmp ? \" (temporary)\" : \"\");\n  }\n  GC_printf(\"GC_root_size= %lu\\n\", (unsigned long)GC_root_size);\n\n  if ((size = GC_compute_root_size()) != GC_root_size)\n    GC_err_printf(\"GC_root_size incorrect!! Should be: %lu\\n\",\n                  (unsigned long)size);\n}\n#endif /* !NO_DEBUGGING */\n\n#ifndef THREADS\n/* Is the address p in one of the registered static root sections?    */\n/* Primarily for debugging support.                                   */\nGC_INNER GC_bool\nGC_is_static_root(ptr_t p)\n{\n  static size_t last_static_root_set = MAX_ROOT_SETS;\n  size_t i;\n\n#  if defined(CPPCHECK)\n  if (n_root_sets > MAX_ROOT_SETS)\n    ABORT(\"Bad n_root_sets\");\n#  endif\n  if (last_static_root_set < n_root_sets\n      && ADDR_INSIDE(p, GC_static_roots[last_static_root_set].r_start,\n                     GC_static_roots[last_static_root_set].r_end))\n    return TRUE;\n  for (i = 0; i < n_root_sets; i++) {\n    if (ADDR_INSIDE(p, GC_static_roots[i].r_start, GC_static_roots[i].r_end)) {\n      last_static_root_set = i;\n      return TRUE;\n    }\n  }\n  return FALSE;\n}\n#endif /* !THREADS */\n\n#ifndef ANY_MSWIN\nGC_INLINE size_t\nrt_hash(ptr_t addr)\n{\n  word val = ADDR(addr);\n\n#  if CPP_WORDSZ > 4 * LOG_RT_SIZE\n#    if CPP_WORDSZ > 8 * LOG_RT_SIZE\n  val ^= val >> (8 * LOG_RT_SIZE);\n#    endif\n  val ^= val >> (4 * LOG_RT_SIZE);\n#  endif\n  val ^= val >> (2 * LOG_RT_SIZE);\n  return (size_t)((val >> LOG_RT_SIZE) ^ val) & (RT_SIZE - 1);\n}\n\n/* Is a range starting at b already in the table? If so, return a     */\n/* pointer to it, else NULL.                                          */\nGC_INNER void *\nGC_roots_present(ptr_t b)\n{\n  size_t h;\n  struct roots *p;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  h = rt_hash(b);\n  for (p = GC_root_index[h]; p != NULL; p = p->r_next) {\n    if (p->r_start == (ptr_t)b)\n      break;\n  }\n  return p;\n}\n\n/* Add the given root structure to the index. */\nGC_INLINE void\nadd_roots_to_index(struct roots *p)\n{\n  size_t h = rt_hash(p->r_start);\n\n  p->r_next = GC_root_index[h];\n  GC_root_index[h] = p;\n}\n#endif /* !ANY_MSWIN */\n\nGC_INNER word GC_root_size = 0;\n\nGC_API void GC_CALL\nGC_add_roots(void *b, void *e)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  LOCK();\n  GC_add_roots_inner((ptr_t)b, (ptr_t)e, FALSE);\n  UNLOCK();\n}\n\n/* Add [b,e) to the root set.  Adding the same interval a second time   */\n/* is a moderately fast no-op, and hence benign.  We do not handle      */\n/* different but overlapping intervals efficiently.  (We do handle      */\n/* them correctly.)                                                     */\n/* Tmp specifies that the interval may be deleted before                */\n/* re-registering dynamic libraries.                                    */\nGC_INNER void\nGC_add_roots_inner(ptr_t b, ptr_t e, GC_bool tmp)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(ADDR_GE(e, b));\n  b = PTR_ALIGN_UP(b, ALIGNMENT);\n  e = PTR_ALIGN_DOWN(e, ALIGNMENT);\n  if (ADDR_GE(b, e)) {\n    /* Nothing to do. */\n    return;\n  }\n\n#ifdef ANY_MSWIN\n  /* Spend the time to ensure that there are no overlapping */\n  /* or adjacent intervals.                                 */\n  /* This could be done faster with e.g. a                  */\n  /* balanced tree.  But the execution time here is         */\n  /* virtually guaranteed to be dominated by the time it    */\n  /* takes to scan the roots.                               */\n  {\n    size_t i;\n    struct roots *old = NULL; /* initialized to prevent warning */\n\n    for (i = 0; i < n_root_sets; i++) {\n      old = GC_static_roots + i;\n      if (ADDR_GE(old->r_end, b) && ADDR_GE(e, old->r_start)) {\n        if (ADDR_LT(b, old->r_start)) {\n          GC_root_size += (word)(old->r_start - b);\n          old->r_start = b;\n        }\n        if (ADDR_LT(old->r_end, e)) {\n          GC_root_size += (word)(e - old->r_end);\n          old->r_end = e;\n        }\n        old->r_tmp &= tmp;\n        break;\n      }\n    }\n    if (i < n_root_sets) {\n      /* Merge other overlapping intervals.       */\n      struct roots *other;\n\n      for (i++; i < n_root_sets; i++) {\n        other = GC_static_roots + i;\n        b = other->r_start;\n        e = other->r_end;\n        if (ADDR_GE(old->r_end, b) && ADDR_GE(e, old->r_start)) {\n          if (ADDR_LT(b, old->r_start)) {\n            GC_root_size += (word)(old->r_start - b);\n            old->r_start = b;\n          }\n          if (ADDR_LT(old->r_end, e)) {\n            GC_root_size += (word)(e - old->r_end);\n            old->r_end = e;\n          }\n          old->r_tmp &= other->r_tmp;\n          /* Delete this entry. */\n          GC_root_size -= (word)(other->r_end - other->r_start);\n          other->r_start = GC_static_roots[n_root_sets - 1].r_start;\n          other->r_end = GC_static_roots[n_root_sets - 1].r_end;\n          n_root_sets--;\n        }\n      }\n      return;\n    }\n  }\n#else\n  {\n    struct roots *old = (struct roots *)GC_roots_present(b);\n\n    if (old != NULL) {\n      if (ADDR_GE(old->r_end, e)) {\n        old->r_tmp &= tmp;\n        /* Already there.   */\n        return;\n      }\n      if (old->r_tmp == tmp || !tmp) {\n        /* Extend the existing root. */\n        GC_root_size += (word)(e - old->r_end);\n        old->r_end = e;\n        old->r_tmp = tmp;\n        return;\n      }\n      b = old->r_end;\n    }\n  }\n#endif\n  if (n_root_sets == MAX_ROOT_SETS) {\n    ABORT(\"Too many root sets\");\n  }\n\n#ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"Adding data root section %u: %p .. %p%s\\n\",\n                (unsigned)n_root_sets, (void *)b, (void *)e,\n                tmp ? \" (temporary)\" : \"\");\n#endif\n  GC_static_roots[n_root_sets].r_start = (ptr_t)b;\n  GC_static_roots[n_root_sets].r_end = (ptr_t)e;\n  GC_static_roots[n_root_sets].r_tmp = tmp;\n#ifndef ANY_MSWIN\n  GC_static_roots[n_root_sets].r_next = 0;\n  add_roots_to_index(GC_static_roots + n_root_sets);\n#endif\n  GC_root_size += (word)(e - b);\n  n_root_sets++;\n}\n\nGC_API void GC_CALL\nGC_clear_roots(void)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  LOCK();\n#ifdef THREADS\n  GC_roots_were_cleared = TRUE;\n#endif\n  n_root_sets = 0;\n  GC_root_size = 0;\n#ifndef ANY_MSWIN\n  BZERO(GC_root_index, sizeof(GC_root_index));\n#endif\n#ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"Clear all data root sections\\n\");\n#endif\n  UNLOCK();\n}\n\nSTATIC void\nGC_remove_root_at_pos(size_t i)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(i < n_root_sets);\n#ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"Remove data root section at %u: %p .. %p%s\\n\", (unsigned)i,\n                (void *)GC_static_roots[i].r_start,\n                (void *)GC_static_roots[i].r_end,\n                GC_static_roots[i].r_tmp ? \" (temporary)\" : \"\");\n#endif\n  GC_root_size\n      -= (word)(GC_static_roots[i].r_end - GC_static_roots[i].r_start);\n  GC_static_roots[i].r_start = GC_static_roots[n_root_sets - 1].r_start;\n  GC_static_roots[i].r_end = GC_static_roots[n_root_sets - 1].r_end;\n  GC_static_roots[i].r_tmp = GC_static_roots[n_root_sets - 1].r_tmp;\n  n_root_sets--;\n}\n\n#ifndef ANY_MSWIN\nSTATIC void\nGC_rebuild_root_index(void)\n{\n  size_t i;\n\n  BZERO(GC_root_index, sizeof(GC_root_index));\n  for (i = 0; i < n_root_sets; i++)\n    add_roots_to_index(GC_static_roots + i);\n}\n#endif /* !ANY_MSWIN */\n\n#if defined(ANY_MSWIN) || defined(DYNAMIC_LOADING)\nSTATIC void\nGC_remove_tmp_roots(void)\n{\n  size_t i;\n#  ifndef ANY_MSWIN\n  size_t old_n_roots = n_root_sets;\n#  endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < n_root_sets;) {\n    if (GC_static_roots[i].r_tmp) {\n      GC_remove_root_at_pos(i);\n    } else {\n      i++;\n    }\n  }\n#  ifndef ANY_MSWIN\n  if (n_root_sets < old_n_roots)\n    GC_rebuild_root_index();\n#  endif\n}\n#endif /* ANY_MSWIN || DYNAMIC_LOADING */\n\nSTATIC void GC_remove_roots_inner(ptr_t b, ptr_t e);\n\nGC_API void GC_CALL\nGC_remove_roots(void *b, void *e)\n{\n  /* A quick check whether has nothing to do. */\n  if (ADDR_GE(PTR_ALIGN_UP((ptr_t)b, ALIGNMENT),\n              PTR_ALIGN_DOWN((ptr_t)e, ALIGNMENT)))\n    return;\n\n  LOCK();\n  GC_remove_roots_inner((ptr_t)b, (ptr_t)e);\n  UNLOCK();\n}\n\nSTATIC void\nGC_remove_roots_inner(ptr_t b, ptr_t e)\n{\n  size_t i;\n#ifndef ANY_MSWIN\n  size_t old_n_roots = n_root_sets;\n#endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < n_root_sets;) {\n    if (ADDR_GE(GC_static_roots[i].r_start, b)\n        && ADDR_GE(e, GC_static_roots[i].r_end)) {\n      GC_remove_root_at_pos(i);\n    } else {\n      i++;\n    }\n  }\n#ifndef ANY_MSWIN\n  if (n_root_sets < old_n_roots)\n    GC_rebuild_root_index();\n#endif\n}\n\n#ifdef USE_PROC_FOR_LIBRARIES\n/* Exchange the elements of the roots table.  Requires rebuild of     */\n/* the roots index table after the swap.                              */\nGC_INLINE void\nswap_static_roots(size_t i, size_t j)\n{\n  ptr_t r_start = GC_static_roots[i].r_start;\n  ptr_t r_end = GC_static_roots[i].r_end;\n  GC_bool r_tmp = GC_static_roots[i].r_tmp;\n\n  GC_static_roots[i].r_start = GC_static_roots[j].r_start;\n  GC_static_roots[i].r_end = GC_static_roots[j].r_end;\n  GC_static_roots[i].r_tmp = GC_static_roots[j].r_tmp;\n  /* No need to swap r_next values.   */\n  GC_static_roots[j].r_start = r_start;\n  GC_static_roots[j].r_end = r_end;\n  GC_static_roots[j].r_tmp = r_tmp;\n}\n\n/* Remove given range from every static root which intersects with    */\n/* the range.  It is assumed GC_remove_tmp_roots is called before     */\n/* this function is called repeatedly by GC_register_map_entries.     */\nGC_INNER void\nGC_remove_roots_subregion(ptr_t b, ptr_t e)\n{\n  size_t i;\n  GC_bool rebuild = FALSE;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(ADDR(b) % ALIGNMENT == 0 && ADDR(e) % ALIGNMENT == 0);\n  for (i = 0; i < n_root_sets; i++) {\n    ptr_t r_start, r_end;\n\n    if (GC_static_roots[i].r_tmp) {\n      /* The remaining roots are skipped as they are all temporary. */\n#  ifdef GC_ASSERTIONS\n      size_t j;\n\n      for (j = i + 1; j < n_root_sets; j++) {\n        GC_ASSERT(GC_static_roots[j].r_tmp);\n      }\n#  endif\n      break;\n    }\n    r_start = GC_static_roots[i].r_start;\n    r_end = GC_static_roots[i].r_end;\n    if (!EXPECT(ADDR_GE(r_start, e) || ADDR_GE(b, r_end), TRUE)) {\n#  ifdef DEBUG_ADD_DEL_ROOTS\n      GC_log_printf(\"Removing %p .. %p from root section %u (%p .. %p)\\n\",\n                    (void *)b, (void *)e, (unsigned)i, (void *)r_start,\n                    (void *)r_end);\n#  endif\n      if (ADDR_LT(r_start, b)) {\n        GC_root_size -= (word)(r_end - b);\n        GC_static_roots[i].r_end = b;\n        /* No need to rebuild as hash does not use r_end value. */\n        if (ADDR_LT(e, r_end)) {\n          size_t j;\n\n          if (rebuild) {\n            GC_rebuild_root_index();\n            rebuild = FALSE;\n          }\n          /* Note: updates n_root_sets as well.       */\n          GC_add_roots_inner(e, r_end, FALSE);\n          for (j = i + 1; j < n_root_sets; j++)\n            if (GC_static_roots[j].r_tmp)\n              break;\n          if (j < n_root_sets - 1 && !GC_static_roots[n_root_sets - 1].r_tmp) {\n            /* Exchange the roots to have all temporary ones at the end. */\n            swap_static_roots(j, n_root_sets - 1);\n            rebuild = TRUE;\n          }\n        }\n      } else {\n        if (ADDR_LT(e, r_end)) {\n          GC_root_size -= (word)(e - r_start);\n          GC_static_roots[i].r_start = e;\n        } else {\n          GC_remove_root_at_pos(i);\n          if (i + 1 < n_root_sets && GC_static_roots[i].r_tmp\n              && !GC_static_roots[i + 1].r_tmp) {\n            size_t j;\n\n            for (j = i + 2; j < n_root_sets; j++)\n              if (GC_static_roots[j].r_tmp)\n                break;\n            /* Exchange the roots to have all temporary ones at the end. */\n            swap_static_roots(i, j - 1);\n          }\n          i--;\n        }\n        rebuild = TRUE;\n      }\n    }\n  }\n  if (rebuild)\n    GC_rebuild_root_index();\n}\n#endif /* USE_PROC_FOR_LIBRARIES */\n\n#if !defined(NO_DEBUGGING)\n/* For the debugging purpose only.                                    */\n/* Workaround for the OS mapping and unmapping behind our back:       */\n/* Is the address p in one of the temporary static root sections?     */\nGC_API int GC_CALL\nGC_is_tmp_root(void *p)\n{\n#  ifndef HAS_REAL_READER_LOCK\n  static size_t last_root_set; /* initialized to 0; no shared access */\n#  elif defined(AO_HAVE_load) || defined(AO_HAVE_store)\n  static volatile AO_t last_root_set;\n#  else\n  /* Note: a race is acceptable, it's just a cached index.  */\n  static volatile size_t last_root_set;\n#  endif\n  size_t i;\n  int res;\n\n  READER_LOCK();\n  /* First try the cached root. */\n#  if defined(AO_HAVE_load) && defined(HAS_REAL_READER_LOCK)\n  i = AO_load(&last_root_set);\n#  else\n  i = last_root_set;\n#  endif\n  if (i < n_root_sets\n      && ADDR_INSIDE((ptr_t)p, GC_static_roots[i].r_start,\n                     GC_static_roots[i].r_end)) {\n    res = (int)GC_static_roots[i].r_tmp;\n  } else {\n    res = 0;\n    for (i = 0; i < n_root_sets; i++) {\n      if (ADDR_INSIDE((ptr_t)p, GC_static_roots[i].r_start,\n                      GC_static_roots[i].r_end)) {\n        res = (int)GC_static_roots[i].r_tmp;\n#  if defined(AO_HAVE_store) && defined(HAS_REAL_READER_LOCK)\n        AO_store(&last_root_set, i);\n#  else\n        last_root_set = i;\n#  endif\n        break;\n      }\n    }\n  }\n  READER_UNLOCK();\n  return res;\n}\n#endif /* !NO_DEBUGGING */\n\nGC_INNER ptr_t\nGC_approx_sp(void)\n{\n  volatile ptr_t sp;\n\n  /* This also forces stack to grow if necessary.  Otherwise the      */\n  /* later accesses might cause the kernel to think we are doing      */\n  /* something wrong.                                                 */\n  STORE_APPROX_SP_TO(sp);\n  return (/* no volatile */ ptr_t)sp;\n}\n\n/* Clear the number of entries in the exclusion table.  The caller  */\n/* should acquire the allocator lock (to avoid data race) but no    */\n/* assertion about it by design.                                    */\nGC_API void GC_CALL\nGC_clear_exclusion_table(void)\n{\n#ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"Clear static root exclusions (%u elements)\\n\",\n                (unsigned)GC_excl_table_entries);\n#endif\n  GC_excl_table_entries = 0;\n}\n\n/* Return the first exclusion range that includes an address not    */\n/* lower than start_addr.                                           */\nSTATIC struct exclusion *\nGC_next_exclusion(ptr_t start_addr)\n{\n  size_t low = 0;\n  size_t high;\n\n  if (EXPECT(0 == GC_excl_table_entries, FALSE))\n    return NULL;\n  high = GC_excl_table_entries - 1;\n  while (high > low) {\n    size_t mid = (low + high) >> 1;\n\n    /* low <= mid < high    */\n    if (ADDR_GE(start_addr, GC_excl_table[mid].e_end)) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  if (ADDR_GE(start_addr, GC_excl_table[low].e_end))\n    return NULL;\n\n  return GC_excl_table + low;\n}\n\n/* The range boundaries should be properly aligned and valid.   */\nGC_INNER void\nGC_exclude_static_roots_inner(ptr_t start, ptr_t finish)\n{\n  struct exclusion *next;\n  size_t next_index;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(ADDR(start) % ALIGNMENT == 0);\n  GC_ASSERT(ADDR_LT(start, finish));\n\n  next = GC_next_exclusion(start);\n  if (next != NULL) {\n    if (ADDR_LT(next->e_start, finish)) {\n      /* Incomplete error check.      */\n      ABORT(\"Exclusion ranges overlap\");\n    }\n    if (ADDR(next->e_start) == ADDR(finish)) {\n      /* Extend old range backwards.  */\n      next->e_start = start;\n#ifdef DEBUG_ADD_DEL_ROOTS\n      GC_log_printf(\"Updating static root exclusion to %p .. %p\\n\",\n                    (void *)start, (void *)next->e_end);\n#endif\n      return;\n    }\n  }\n\n  next_index = GC_excl_table_entries;\n  if (next_index >= MAX_EXCLUSIONS)\n    ABORT(\"Too many exclusions\");\n  if (next != NULL) {\n    size_t i;\n\n    next_index = (size_t)(next - GC_excl_table);\n    for (i = GC_excl_table_entries; i > next_index; --i) {\n      GC_excl_table[i] = GC_excl_table[i - 1];\n    }\n  }\n#ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"Adding static root exclusion at %u: %p .. %p\\n\",\n                (unsigned)next_index, (void *)start, (void *)finish);\n#endif\n  GC_excl_table[next_index].e_start = start;\n  GC_excl_table[next_index].e_end = finish;\n  ++GC_excl_table_entries;\n}\n\nGC_API void GC_CALL\nGC_exclude_static_roots(void *b, void *e)\n{\n  if (b == e) {\n    /* Nothing to exclude.    */\n    return;\n  }\n\n  /* Round boundaries in direction reverse to that of GC_add_roots. */\n#if ALIGNMENT > 1\n  b = PTR_ALIGN_DOWN((ptr_t)b, ALIGNMENT);\n  e = EXPECT(ADDR(e) > ~(word)(ALIGNMENT - 1), FALSE)\n          ? PTR_ALIGN_DOWN((ptr_t)e, ALIGNMENT) /* overflow */\n          : PTR_ALIGN_UP((ptr_t)e, ALIGNMENT);\n#endif\n\n  LOCK();\n  GC_exclude_static_roots_inner((ptr_t)b, (ptr_t)e);\n  UNLOCK();\n}\n\n#if defined(WRAP_MARK_SOME) && defined(PARALLEL_MARK)\n#  define GC_PUSH_CONDITIONAL(b, t, all)                \\\n    (GC_parallel ? GC_push_conditional_eager(b, t, all) \\\n                 : GC_push_conditional_static(b, t, all))\n#else\n#  define GC_PUSH_CONDITIONAL(b, t, all) GC_push_conditional_static(b, t, all)\n#endif\n\n/* Invoke push_conditional on ranges that are not excluded. */\nSTATIC void\nGC_push_conditional_with_exclusions(ptr_t bottom, ptr_t top, GC_bool all)\n{\n  while (ADDR_LT(bottom, top)) {\n    struct exclusion *next = GC_next_exclusion(bottom);\n    ptr_t excl_start = top;\n\n    if (next != NULL) {\n      if (ADDR_GE(next->e_start, top)) {\n        next = NULL;\n      } else {\n        excl_start = next->e_start;\n      }\n    }\n    if (ADDR_LT(bottom, excl_start))\n      GC_PUSH_CONDITIONAL(bottom, excl_start, all);\n    if (NULL == next)\n      break;\n    bottom = next->e_end;\n  }\n}\n\n#ifdef IA64\n/* Similar to GC_push_all_stack_sections() but for IA-64 registers store. */\nGC_INNER void\nGC_push_all_register_sections(ptr_t bs_lo, ptr_t bs_hi, GC_bool eager,\n                              struct GC_traced_stack_sect_s *traced_stack_sect)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  while (traced_stack_sect != NULL) {\n    ptr_t frame_bs_lo = traced_stack_sect->backing_store_end;\n\n    GC_ASSERT(ADDR_GE(bs_hi, frame_bs_lo));\n    if (eager) {\n      GC_push_all_eager(frame_bs_lo, bs_hi);\n    } else {\n      GC_push_all_stack(frame_bs_lo, bs_hi);\n    }\n    bs_hi = traced_stack_sect->saved_backing_store_ptr;\n    traced_stack_sect = traced_stack_sect->prev;\n  }\n  GC_ASSERT(ADDR_GE(bs_hi, bs_lo));\n  if (eager) {\n    GC_push_all_eager(bs_lo, bs_hi);\n  } else {\n    GC_push_all_stack(bs_lo, bs_hi);\n  }\n}\n#endif /* IA64 */\n\n#ifdef THREADS\n\nGC_INNER void\nGC_push_all_stack_sections(ptr_t lo /* top */, ptr_t hi /* bottom */,\n                           struct GC_traced_stack_sect_s *traced_stack_sect)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  while (traced_stack_sect != NULL) {\n    GC_ASSERT(HOTTER_THAN(lo, (ptr_t)traced_stack_sect));\n#  ifdef STACK_GROWS_UP\n    GC_push_all_stack((ptr_t)traced_stack_sect, lo);\n#  else\n    GC_push_all_stack(lo, (ptr_t)traced_stack_sect);\n#  endif\n    lo = traced_stack_sect->saved_stack_ptr;\n    GC_ASSERT(lo != NULL);\n    traced_stack_sect = traced_stack_sect->prev;\n  }\n  GC_ASSERT(!HOTTER_THAN(hi, lo));\n#  ifdef STACK_GROWS_UP\n  /* We got them backwards! */\n  GC_push_all_stack(hi, lo);\n#  else\n  GC_push_all_stack(lo, hi);\n#  endif\n}\n\n#else /* !THREADS */\n\n/* Similar to GC_push_all_eager, but only the part hotter than    */\n/* cold_gc_frame is scanned immediately.  Needed to ensure that   */\n/* callee-save registers are not missed.  Treats all interior     */\n/* pointers as valid and scans part of the area immediately, to   */\n/* make sure that saved register values are not lost.             */\n/* Cold_gc_frame delimits the stack section that must be scanned  */\n/* eagerly.  A zero value indicates that no eager scanning is     */\n/* needed.  We do not need to worry about the manual VDB case     */\n/* here, since this is only called in the single-threaded case.   */\n/* We assume that we cannot collect between an assignment and the */\n/* corresponding GC_dirty() call.                                 */\nSTATIC void\nGC_push_all_stack_partially_eager(ptr_t bottom, ptr_t top, ptr_t cold_gc_frame)\n{\n#  ifndef NEED_FIXUP_POINTER\n  if (GC_all_interior_pointers) {\n    /* Push the hot end of the stack eagerly, so that register  */\n    /* values saved inside GC frames are marked before they     */\n    /* disappear.  The rest of the marking can be deferred      */\n    /* until later.                                             */\n    if (0 == cold_gc_frame) {\n      GC_push_all_stack(bottom, top);\n      return;\n    }\n    GC_ASSERT(ADDR_GE(cold_gc_frame, bottom) && ADDR_GE(top, cold_gc_frame));\n#    ifdef STACK_GROWS_UP\n    GC_push_all(bottom, cold_gc_frame + sizeof(ptr_t));\n    GC_push_all_eager(cold_gc_frame, top);\n#    else\n    GC_push_all(cold_gc_frame - sizeof(ptr_t), top);\n    GC_push_all_eager(bottom, cold_gc_frame);\n#    endif\n  } else\n#  endif\n  /* else */ {\n    GC_push_all_eager(bottom, top);\n  }\n#  ifdef TRACE_BUF\n  GC_add_trace_entry(\"GC_push_all_stack\", bottom, top);\n#  endif\n}\n\n/* Similar to GC_push_all_stack_sections() but also uses cold_gc_frame. */\nSTATIC void\nGC_push_all_stack_part_eager_sections(\n    ptr_t lo /* top */, ptr_t hi /* bottom */, ptr_t cold_gc_frame,\n    struct GC_traced_stack_sect_s *traced_stack_sect)\n{\n  GC_ASSERT(traced_stack_sect == NULL || cold_gc_frame == NULL\n            || HOTTER_THAN(cold_gc_frame, (ptr_t)traced_stack_sect));\n\n  while (traced_stack_sect != NULL) {\n    GC_ASSERT(HOTTER_THAN(lo, (ptr_t)traced_stack_sect));\n#  ifdef STACK_GROWS_UP\n    GC_push_all_stack_partially_eager((ptr_t)traced_stack_sect, lo,\n                                      cold_gc_frame);\n#  else\n    GC_push_all_stack_partially_eager(lo, (ptr_t)traced_stack_sect,\n                                      cold_gc_frame);\n#  endif\n    lo = traced_stack_sect->saved_stack_ptr;\n    GC_ASSERT(lo != NULL);\n    traced_stack_sect = traced_stack_sect->prev;\n    /* Note: use at most once.      */\n    cold_gc_frame = NULL;\n  }\n\n  GC_ASSERT(!HOTTER_THAN(hi, lo));\n#  ifdef STACK_GROWS_UP\n  /* We got them backwards! */\n  GC_push_all_stack_partially_eager(hi, lo, cold_gc_frame);\n#  else\n  GC_push_all_stack_partially_eager(lo, hi, cold_gc_frame);\n#  endif\n}\n\n#endif /* !THREADS */\n\n/* Push enough of the current stack eagerly to ensure that callee-save  */\n/* registers saved in GC frames are scanned.  In the non-threads case,  */\n/* schedule entire stack for scanning.  The 2nd argument is a pointer   */\n/* to the (possibly null) thread context, for (currently hypothetical)  */\n/* more precise stack scanning.  In the presence of threads, push       */\n/* enough of the current stack to ensure that callee-save registers     */\n/* saved in collector frames have been seen.                            */\n/* TODO: Merge it with per-thread stuff. */\nSTATIC void\nGC_push_current_stack(ptr_t cold_gc_frame, void *context)\n{\n  UNUSED_ARG(context);\n  GC_ASSERT(I_HOLD_LOCK());\n#if defined(THREADS)\n  /* cold_gc_frame is non-NULL.   */\n#  ifdef STACK_GROWS_UP\n  GC_push_all_eager(cold_gc_frame, GC_approx_sp());\n#  else\n  GC_push_all_eager(GC_approx_sp(), cold_gc_frame);\n  /* For IA64, the register stack backing store is handled      */\n  /* in the thread-specific code.                               */\n#  endif\n#else\n  GC_push_all_stack_part_eager_sections(GC_approx_sp(), GC_stackbottom,\n                                        cold_gc_frame, GC_traced_stack_sect);\n#  ifdef IA64\n  /* We also need to push the register stack backing store.   */\n  /* This should really be done in the same way as the        */\n  /* regular stack.  For now we fudge it a bit.               */\n  /* Note that the backing store grows up, so we can't use    */\n  /* GC_push_all_stack_partially_eager.                       */\n  {\n    ptr_t bsp = GC_save_regs_ret_val;\n    ptr_t cold_gc_bs_pointer = bsp - 2048;\n    if (GC_all_interior_pointers\n        && ADDR_LT(GC_register_stackbottom, cold_gc_bs_pointer)) {\n      /* Adjust cold_gc_bs_pointer if below our innermost   */\n      /* \"traced stack section\" in backing store.           */\n      if (GC_traced_stack_sect != NULL\n          && ADDR_LT(cold_gc_bs_pointer,\n                     GC_traced_stack_sect->backing_store_end)) {\n        cold_gc_bs_pointer = GC_traced_stack_sect->backing_store_end;\n      }\n      GC_push_all_register_sections(GC_register_stackbottom,\n                                    cold_gc_bs_pointer, FALSE,\n                                    GC_traced_stack_sect);\n      GC_push_all_eager(cold_gc_bs_pointer, bsp);\n    } else {\n      GC_push_all_register_sections(GC_register_stackbottom, bsp,\n                                    TRUE /* eager */, GC_traced_stack_sect);\n    }\n    /* All values should be sufficiently aligned that we    */\n    /* don't have to worry about the boundary.              */\n  }\n#  elif defined(E2K)\n  /* We also need to push procedure stack store.        */\n  /* Procedure stack grows up.                          */\n  {\n    ptr_t bs_lo;\n    size_t stack_size;\n\n    /* TODO: support ps_ofs here and in GC_do_blocking_inner */\n    GET_PROCEDURE_STACK_LOCAL(0, &bs_lo, &stack_size);\n    GC_push_all_eager(bs_lo, bs_lo + stack_size);\n  }\n#  endif\n#endif /* !THREADS */\n}\n\nGC_INNER void (*GC_push_typed_structures)(void) = 0;\n\nGC_INNER void\nGC_cond_register_dynamic_libraries(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#if defined(DYNAMIC_LOADING) && !defined(MSWIN_XBOX1) || defined(ANY_MSWIN)\n  GC_remove_tmp_roots();\n  if (!GC_no_dls)\n    GC_register_dynamic_libraries();\n#else\n  GC_no_dls = TRUE;\n#endif\n}\n\nSTATIC void\nGC_push_regs_and_stack(ptr_t cold_gc_frame)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#ifdef THREADS\n  if (NULL == cold_gc_frame) {\n    /* GC_push_all_stacks should push registers and stack.          */\n    return;\n  }\n#endif\n  GC_with_callee_saves_pushed(GC_push_current_stack, cold_gc_frame);\n}\n\n/* Call the mark routines (GC_push_one for a single pointer,            */\n/* GC_push_conditional on groups of pointers) on every top level        */\n/* accessible pointer.  If all is false, arrange to push only possibly  */\n/* altered values.  Cold_gc_frame is an address inside a GC frame that  */\n/* remains valid until all marking is complete; a NULL value indicates  */\n/* that it is OK to miss some register values.                          */\nGC_INNER void\nGC_push_roots(GC_bool all, ptr_t cold_gc_frame)\n{\n  size_t i;\n  unsigned kind;\n\n  GC_ASSERT(I_HOLD_LOCK());\n\n  /* The initialization is needed for GC_push_all_stacks().           */\n  GC_ASSERT(GC_is_initialized);\n\n  /* Next push static data.  This must happen early on, since it is   */\n  /* not robust against mark stack overflow.                          */\n  /* Re-register dynamic libraries, in case one got added.            */\n  /* There is some argument for doing this as late as possible,       */\n  /* especially on Win32, where it can change asynchronously.         */\n  /* In those cases, we do it here.  But on other platforms, it's     */\n  /* not safe with the world stopped, so we do it earlier.            */\n#if !defined(REGISTER_LIBRARIES_EARLY)\n  GC_cond_register_dynamic_libraries();\n#endif\n\n  /* Mark everything in static data areas.                            */\n  for (i = 0; i < n_root_sets; i++) {\n    GC_push_conditional_with_exclusions(GC_static_roots[i].r_start,\n                                        GC_static_roots[i].r_end, all);\n  }\n\n  /* Mark all free-list header blocks, if those were allocated from   */\n  /* the garbage collected heap.  This makes sure they don't          */\n  /* disappear if we are not marking from static data.  It also       */\n  /* saves us the trouble of scanning them, and possibly that of      */\n  /* marking the freelists.                                           */\n  for (kind = 0; kind < GC_n_kinds; kind++) {\n    const void *base = GC_base(GC_obj_kinds[kind].ok_freelist);\n\n    if (base != NULL) {\n      GC_set_mark_bit(base);\n    }\n  }\n\n  /* Mark from GC internal roots if those might otherwise have        */\n  /* been excluded.                                                   */\n#ifndef GC_NO_FINALIZATION\n  GC_push_finalizer_structures();\n#endif\n#ifdef THREADS\n  if (GC_no_dls || GC_roots_were_cleared)\n    GC_push_thread_structures();\n#endif\n  if (GC_push_typed_structures)\n    GC_push_typed_structures();\n\n    /* Mark thread-local free lists, even if their mark        */\n    /* descriptor excludes the link field.                     */\n    /* If the world is not stopped, this is unsafe.  It is     */\n    /* also unnecessary, since we will do this again with the  */\n    /* world stopped.                                          */\n#if defined(THREAD_LOCAL_ALLOC)\n  if (GC_world_stopped)\n    GC_mark_thread_local_free_lists();\n#endif\n\n    /* Now traverse stacks, and mark from register contents.    */\n    /* These must be done last, since they can legitimately     */\n    /* overflow the mark stack.  This is usually done by saving */\n    /* the current context on the stack, and then just tracing  */\n    /* from the stack.                                          */\n#ifdef STACK_NOT_SCANNED\n  UNUSED_ARG(cold_gc_frame);\n#else\n  GC_push_regs_and_stack(cold_gc_frame);\n#endif\n\n  if (GC_push_other_roots != 0) {\n    /* In the threads case, this also pushes thread stacks. */\n    /* Note that without interior pointer recognition lots  */\n    /* of stuff may have been pushed already, and this      */\n    /* should be careful about mark stack overflows.        */\n    (*GC_push_other_roots)();\n  }\n}\n"
        },
        {
          "name": "misc.c",
          "type": "blob",
          "size": 76.30078125,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1999-2001 by Hewlett-Packard Company. All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\"\n\n#include <limits.h>\n#include <stdarg.h>\n\n#if defined(SOLARIS) && defined(THREADS)\n#  include <sys/syscall.h>\n#endif\n\n#if defined(UNIX_LIKE) || defined(CYGWIN32) || defined(SYMBIAN) \\\n    || (defined(CONSOLE_LOG) && defined(MSWIN32))\n#  include <fcntl.h>\n#  include <sys/stat.h>\n#endif\n\n#if defined(CONSOLE_LOG) && defined(MSWIN32) && !defined(__GNUC__)\n#  include <io.h>\n#endif\n\n#ifdef NONSTOP\n#  include <floss.h>\n#endif\n\n#ifdef THREADS\n#  if defined(SN_TARGET_PSP2)\nGC_INNER WapiMutex GC_allocate_ml_PSP2 = { 0, NULL };\n#  elif defined(GC_DEFN_ALLOCATE_ML) && !defined(USE_RWLOCK) \\\n      || defined(SN_TARGET_PS3)\n#    include <pthread.h>\nGC_INNER pthread_mutex_t GC_allocate_ml;\n#  else\n/* For other platforms with threads, the allocator lock and possibly  */\n/* GC_lock_holder variables are defined in the thread support code.   */\n#  endif\n#endif /* THREADS */\n\n#ifdef DYNAMIC_LOADING\n/* We need to register the main data segment.  Returns TRUE unless    */\n/* this is done implicitly as part of dynamic library registration.   */\n#  define GC_REGISTER_MAIN_STATIC_DATA() GC_register_main_static_data()\n#elif defined(GC_DONT_REGISTER_MAIN_STATIC_DATA)\n#  define GC_REGISTER_MAIN_STATIC_DATA() FALSE\n#else\n/* Don't unnecessarily call GC_register_main_static_data() in case    */\n/* dyn_load.c isn't linked in.                                        */\n#  define GC_REGISTER_MAIN_STATIC_DATA() TRUE\n#endif\n\n#ifdef NEED_CANCEL_DISABLE_COUNT\n__thread unsigned char GC_cancel_disable_count = 0;\n#endif\n\nstruct _GC_arrays GC_arrays /* = { 0 } */;\n\nGC_INNER unsigned GC_n_mark_procs = GC_RESERVED_MARK_PROCS;\n\nGC_INNER unsigned GC_n_kinds = GC_N_KINDS_INITIAL_VALUE;\n\n/* This variable is defined here so we do not have to link dbg_mlc.o.   */\nGC_INNER GC_bool GC_debugging_started = FALSE;\n\nptr_t GC_stackbottom = 0;\n\n#if defined(E2K) && defined(THREADS) || defined(IA64)\nGC_INNER ptr_t GC_register_stackbottom = NULL;\n#endif\n\nint GC_dont_gc = FALSE;\n\nint GC_dont_precollect = FALSE;\n\nGC_bool GC_quiet = 0; /* used also in msvc_dbg.c */\n\n#if !defined(NO_CLOCK) || !defined(SMALL_CONFIG)\nGC_INNER int GC_print_stats = 0;\n#endif\n\n#ifdef GC_PRINT_BACK_HEIGHT\nGC_INNER GC_bool GC_print_back_height = TRUE;\n#else\nGC_INNER GC_bool GC_print_back_height = FALSE;\n#endif\n\n#ifndef NO_DEBUGGING\n#  ifdef GC_DUMP_REGULARLY\n/* Generate regular debugging dumps if set. */\nGC_INNER GC_bool GC_dump_regularly = TRUE;\n#  else\nGC_INNER GC_bool GC_dump_regularly = FALSE;\n#  endif\n#  ifndef NO_CLOCK\n/* The time that the GC was initialized at. */\nSTATIC CLOCK_TYPE GC_init_time;\n#  endif\n#endif /* !NO_DEBUGGING */\n\n#ifdef KEEP_BACK_PTRS\n/* Number of random backtraces to generate for each GC.       */\nGC_INNER long GC_backtraces = 0;\n#endif\n\n#ifdef FIND_LEAK\nint GC_find_leak = 1;\n#else\nint GC_find_leak = 0;\n#endif\n\n#ifndef SHORT_DBG_HDRS\n#  ifdef GC_FINDLEAK_DELAY_FREE\nGC_INNER GC_bool GC_findleak_delay_free = TRUE;\n#  else\nGC_INNER GC_bool GC_findleak_delay_free = FALSE;\n#  endif\n#endif /* !SHORT_DBG_HDRS */\n\n#ifdef ALL_INTERIOR_POINTERS\nint GC_all_interior_pointers = 1;\n#else\nint GC_all_interior_pointers = 0;\n#endif\n\n#ifdef FINALIZE_ON_DEMAND\nint GC_finalize_on_demand = 1;\n#else\nint GC_finalize_on_demand = 0;\n#endif\n\n#ifdef JAVA_FINALIZATION\nint GC_java_finalization = 1;\n#else\nint GC_java_finalization = 0;\n#endif\n\n/* All accesses to it should be synchronized to avoid data race.    */\nGC_finalizer_notifier_proc GC_finalizer_notifier\n    = (GC_finalizer_notifier_proc)0;\n\n#ifdef GC_FORCE_UNMAP_ON_GCOLLECT\n/* Has no effect unless USE_MUNMAP.                           */\n/* Has no effect on implicitly-initiated garbage collections. */\nGC_INNER GC_bool GC_force_unmap_on_gcollect = TRUE;\n#else\nGC_INNER GC_bool GC_force_unmap_on_gcollect = FALSE;\n#endif\n\n#ifndef GC_LARGE_ALLOC_WARN_INTERVAL\n#  define GC_LARGE_ALLOC_WARN_INTERVAL 5\n#endif\n\n/* The interval between unsuppressed warnings.  */\nGC_INNER long GC_large_alloc_warn_interval = GC_LARGE_ALLOC_WARN_INTERVAL;\n\nSTATIC void *GC_CALLBACK\nGC_default_oom_fn(size_t bytes_requested)\n{\n  UNUSED_ARG(bytes_requested);\n  return NULL;\n}\n\n/* All accesses to it should be synchronized to avoid data race.    */\nGC_oom_func GC_oom_fn = GC_default_oom_fn;\n\n#ifdef CAN_HANDLE_FORK\n#  ifdef HANDLE_FORK\n/* Note: the value is examined by GC_thr_init.      */\nGC_INNER int GC_handle_fork = 1;\n#  else\nGC_INNER int GC_handle_fork = FALSE;\n#  endif\n\n#elif !defined(HAVE_NO_FORK)\nGC_API void GC_CALL\nGC_atfork_prepare(void)\n{\n#  ifdef THREADS\n  ABORT(\"fork() handling unsupported\");\n#  endif\n}\n\nGC_API void GC_CALL\nGC_atfork_parent(void)\n{\n  /* empty */\n}\n\nGC_API void GC_CALL\nGC_atfork_child(void)\n{\n  /* empty */\n}\n#endif /* !CAN_HANDLE_FORK && !HAVE_NO_FORK */\n\n/* Overrides the default automatic handle-fork mode.  Has effect only   */\n/* if called before GC_INIT.                                            */\nGC_API void GC_CALL\nGC_set_handle_fork(int value)\n{\n#ifdef CAN_HANDLE_FORK\n  if (!GC_is_initialized) {\n    /* Map all negative values except for -1 to a positive one.       */\n    GC_handle_fork = value >= -1 ? value : 1;\n  }\n#elif defined(THREADS) || (defined(DARWIN) && defined(MPROTECT_VDB))\n  if (!GC_is_initialized && value) {\n#  ifndef SMALL_CONFIG\n    /* Initialize GC_manual_vdb and GC_stderr.      */\n    GC_init();\n#    ifndef THREADS\n    if (GC_manual_vdb)\n      return;\n#    endif\n#  endif\n    ABORT(\"fork() handling unsupported\");\n  }\n#else\n  /* No at-fork handler is needed in the single-threaded mode.        */\n  UNUSED_ARG(value);\n#endif\n}\n\n/* Set things up so that GC_size_map[i] >= granules(i),                 */\n/* but not too much bigger                                              */\n/* and so that size_map contains relatively few distinct entries        */\n/* This was originally stolen from Russ Atkinson's Cedar                */\n/* quantization algorithm (but we precompute it).                       */\nSTATIC void\nGC_init_size_map(void)\n{\n  size_t i = 1;\n\n  /* Map size 0 to something bigger; this avoids problems at lower levels. */\n  GC_size_map[0] = 1;\n\n  for (; i <= GRANULES_TO_BYTES(GC_TINY_FREELISTS - 1) - EXTRA_BYTES; i++) {\n    GC_size_map[i] = ALLOC_REQUEST_GRANS(i);\n#ifndef _MSC_VER\n    /* Seems to tickle bug in VC++ 2008 for x64.  */\n    GC_ASSERT(GC_size_map[i] < GC_TINY_FREELISTS);\n#endif\n  }\n  /* We leave the rest of the array to be filled in on demand. */\n}\n\n/*\n * The following is a gross hack to deal with a problem that can occur\n * on machines that are sloppy about stack frame sizes, notably SPARC.\n * Bogus pointers may be written to the stack and not cleared for\n * a LONG time, because they always fall into holes in stack frames\n * that are not written.  We partially address this by clearing\n * sections of the stack whenever we get control.\n */\n\n#ifndef SMALL_CLEAR_SIZE\n/* Clear this many words of the stack every time.     */\n#  define SMALL_CLEAR_SIZE 256\n#endif\n\n#if defined(ALWAYS_SMALL_CLEAR_STACK) || defined(STACK_NOT_SCANNED)\nGC_API void *GC_CALL\nGC_clear_stack(void *arg)\n{\n#  ifndef STACK_NOT_SCANNED\n  volatile ptr_t dummy[SMALL_CLEAR_SIZE];\n\n  BZERO(CAST_AWAY_VOLATILE_PVOID(dummy), sizeof(dummy));\n#  endif\n  return arg;\n}\n#else\n\n#  ifdef THREADS\n/* Clear this much sometimes. */\n#    define BIG_CLEAR_SIZE 2048\n#  else\n/* GC_gc_no value when we last did this.    */\nSTATIC word GC_stack_last_cleared = 0;\n\nSTATIC word GC_bytes_allocd_at_reset = 0;\n\n/* Coolest stack pointer value from which we have already cleared   */\n/* the stack.                                                       */\nSTATIC ptr_t GC_min_sp = NULL;\n\n/* The \"hottest\" stack pointer value we have seen recently.         */\n/* Degrades over time.                                              */\nSTATIC ptr_t GC_high_water = NULL;\n\n#    define DEGRADE_RATE 50\n#  endif\n\n#  if defined(__APPLE_CC__) && !GC_CLANG_PREREQ(6, 0)\n#    define CLEARSTACK_LIMIT_MODIFIER volatile /* to workaround some bug */\n#  else\n#    define CLEARSTACK_LIMIT_MODIFIER /* empty */\n#  endif\n\nEXTERN_C_BEGIN\nvoid *GC_clear_stack_inner(void *, CLEARSTACK_LIMIT_MODIFIER ptr_t);\nEXTERN_C_END\n\n#  ifndef ASM_CLEAR_CODE\n/* Clear the stack up to about limit.  Return arg.  This function   */\n/* is not static because it could also be erroneously defined in .S */\n/* file, so this error would be caught by the linker.               */\nvoid *\nGC_clear_stack_inner(void *arg, CLEARSTACK_LIMIT_MODIFIER ptr_t limit)\n{\n#    define CLEAR_SIZE 213 /* granularity */\n  volatile ptr_t dummy[CLEAR_SIZE];\n\n  BZERO(CAST_AWAY_VOLATILE_PVOID(dummy), sizeof(dummy));\n  if (HOTTER_THAN((/* no volatile */ ptr_t)limit, GC_approx_sp())) {\n    (void)GC_clear_stack_inner(arg, limit);\n  }\n  /* Make sure the recursive call is not a tail call, and the bzero */\n  /* call is not recognized as dead code.                           */\n#    if defined(CPPCHECK)\n  GC_noop1(ADDR(dummy[0]));\n#    else\n  GC_noop1(COVERT_DATAFLOW(ADDR(dummy)));\n#    endif\n  return arg;\n}\n#  endif /* !ASM_CLEAR_CODE */\n\n#  ifdef THREADS\n/* Used to occasionally clear a bigger chunk.       */\n/* TODO: Should be more random than it is ...       */\nstatic unsigned\nnext_random_no(void)\n{\n#    ifdef AO_HAVE_fetch_and_add1\n  static volatile AO_t random_no;\n\n  return (unsigned)AO_fetch_and_add1(&random_no) % 13;\n#    else\n  static unsigned random_no = 0;\n\n  return (random_no++) % 13;\n#    endif\n}\n#  endif /* THREADS */\n\n/* Clear some of the inaccessible part of the stack.  Returns its       */\n/* argument, so it can be used in a tail call position, hence clearing  */\n/* another frame.                                                       */\nGC_API void *GC_CALL\nGC_clear_stack(void *arg)\n{\n  /* Note: this is hotter than the actual stack pointer.      */\n  ptr_t sp = GC_approx_sp();\n#  ifdef THREADS\n  volatile ptr_t dummy[SMALL_CLEAR_SIZE];\n#  endif\n\n  /* Extra bytes we clear every time.  This clears our own activation */\n  /* record, and should cause more frequent clearing near the cold    */\n  /* end of the stack, a good thing.                                  */\n#  define SLOP 400\n\n  /* We make GC_high_water this much hotter than we really saw it,    */\n  /* to cover for the GC noise above our current frame.               */\n#  define GC_SLOP 4000\n\n  /* We restart the clearing process after this many bytes of     */\n  /* allocation.  Otherwise very heavily recursive programs       */\n  /* with sparse stacks may result in heaps that grow almost      */\n  /* without bounds.  As the heap gets larger, collection         */\n  /* frequency decreases, thus clearing frequency would decrease, */\n  /* thus more junk remains accessible, thus the heap gets        */\n  /* larger ...                                                   */\n#  define CLEAR_THRESHOLD 100000\n\n#  ifdef THREADS\n  if (next_random_no() == 0) {\n    ptr_t limit = sp;\n\n    MAKE_HOTTER(limit, BIG_CLEAR_SIZE * sizeof(ptr_t));\n    /* Make it sufficiently aligned for assembly implementations    */\n    /* of GC_clear_stack_inner.                                     */\n    limit = PTR_ALIGN_DOWN(limit, 0x10);\n    return GC_clear_stack_inner(arg, limit);\n  }\n  BZERO(CAST_AWAY_VOLATILE_PVOID(dummy), sizeof(dummy));\n#  else\n  if (GC_gc_no != GC_stack_last_cleared) {\n    /* Start things over, so we clear the entire stack again.   */\n    if (EXPECT(NULL == GC_high_water, FALSE))\n      GC_high_water = (ptr_t)GC_stackbottom;\n    GC_min_sp = GC_high_water;\n    GC_stack_last_cleared = GC_gc_no;\n    GC_bytes_allocd_at_reset = GC_bytes_allocd;\n  }\n  /* Adjust GC_high_water.  */\n  GC_ASSERT(GC_high_water != NULL);\n  MAKE_COOLER(GC_high_water, PTRS_TO_BYTES(DEGRADE_RATE) + GC_SLOP);\n  if (HOTTER_THAN(sp, GC_high_water))\n    GC_high_water = sp;\n  MAKE_HOTTER(GC_high_water, GC_SLOP);\n  {\n    ptr_t limit = GC_min_sp;\n\n    MAKE_HOTTER(limit, SLOP);\n    if (HOTTER_THAN(limit, sp)) {\n      limit = PTR_ALIGN_DOWN(limit, 0x10);\n      GC_min_sp = sp;\n      return GC_clear_stack_inner(arg, limit);\n    }\n  }\n  if (GC_bytes_allocd - GC_bytes_allocd_at_reset > CLEAR_THRESHOLD) {\n    /* Restart clearing process, but limit how much clearing we do. */\n    GC_min_sp = sp;\n    MAKE_HOTTER(GC_min_sp, CLEAR_THRESHOLD / 4);\n    if (HOTTER_THAN(GC_min_sp, GC_high_water))\n      GC_min_sp = GC_high_water;\n    GC_bytes_allocd_at_reset = GC_bytes_allocd;\n  }\n#  endif\n  return arg;\n}\n\n#endif /* !ALWAYS_SMALL_CLEAR_STACK && !STACK_NOT_SCANNED */\n\n/* Return a pointer to the base address of p, given a pointer to a      */\n/* an address within an object.  Return 0 otherwise.                    */\nGC_API void *GC_CALL\nGC_base(void *p)\n{\n  ptr_t r = (ptr_t)p;\n  struct hblk *h;\n  bottom_index *bi;\n  hdr *hhdr;\n  ptr_t limit;\n  size_t sz;\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    return NULL;\n  h = HBLKPTR(r);\n  GET_BI(r, bi);\n  hhdr = HDR_FROM_BI(bi, r);\n  if (NULL == hhdr)\n    return NULL;\n\n  /* If it's a pointer to the middle of a large object, move it       */\n  /* to the beginning.                                                */\n  if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n    h = GC_find_starting_hblk(h, &hhdr);\n    r = (ptr_t)h;\n  }\n  if (HBLK_IS_FREE(hhdr))\n    return NULL;\n\n  /* Make sure r points to the beginning of the object.       */\n  r = PTR_ALIGN_DOWN(r, sizeof(ptr_t));\n\n  sz = hhdr->hb_sz;\n  r -= HBLKDISPL(r) % sz;\n  limit = r + sz;\n  if ((ADDR_LT((ptr_t)(h + 1), limit) && sz <= HBLKSIZE)\n      || ADDR_GE((ptr_t)p, limit))\n    return NULL;\n\n  return r;\n}\n\n/* Return TRUE if and only if p points to somewhere in GC heap. */\nGC_API int GC_CALL\nGC_is_heap_ptr(const void *p)\n{\n  bottom_index *bi;\n\n  GC_ASSERT(GC_is_initialized);\n  GET_BI(p, bi);\n  return HDR_FROM_BI(bi, p) != 0;\n}\n\nGC_API size_t GC_CALL\nGC_size(const void *p)\n{\n  const hdr *hhdr;\n\n  /* Accept NULL for compatibility with malloc_usable_size(). */\n  if (EXPECT(NULL == p, FALSE))\n    return 0;\n\n  hhdr = HDR(p);\n  return hhdr->hb_sz;\n}\n\n/* These getters remain unsynchronized for compatibility (since some    */\n/* clients could call some of them from a GC callback holding the       */\n/* allocator lock).                                                     */\n\nGC_API size_t GC_CALL\nGC_get_heap_size(void)\n{\n  /* Ignore the memory space returned to OS (i.e. count only the      */\n  /* space owned by the garbage collector).                           */\n  return (size_t)(GC_heapsize - GC_unmapped_bytes);\n}\n\nGC_API size_t GC_CALL\nGC_get_obtained_from_os_bytes(void)\n{\n  return (size_t)GC_our_mem_bytes;\n}\n\nGC_API size_t GC_CALL\nGC_get_free_bytes(void)\n{\n  /* Ignore the memory space returned to OS.  */\n  return (size_t)(GC_large_free_bytes - GC_unmapped_bytes);\n}\n\nGC_API size_t GC_CALL\nGC_get_unmapped_bytes(void)\n{\n  return (size_t)GC_unmapped_bytes;\n}\n\nGC_API size_t GC_CALL\nGC_get_bytes_since_gc(void)\n{\n  return (size_t)GC_bytes_allocd;\n}\n\nGC_API size_t GC_CALL\nGC_get_total_bytes(void)\n{\n  return (size_t)(GC_bytes_allocd + GC_bytes_allocd_before_gc);\n}\n\n#ifndef GC_GET_HEAP_USAGE_NOT_NEEDED\n\nGC_API size_t GC_CALL\nGC_get_size_map_at(int i)\n{\n  if ((unsigned)i > MAXOBJBYTES)\n    return GC_SIZE_MAX;\n  return GRANULES_TO_BYTES(GC_size_map[i]);\n}\n\n/* Return the heap usage information.  This is a thread-safe (atomic)   */\n/* alternative for the five above getters.  NULL pointer is allowed for */\n/* any argument.  Returned (filled in) values are of word type.         */\nGC_API void GC_CALL\nGC_get_heap_usage_safe(GC_word *pheap_size, GC_word *pfree_bytes,\n                       GC_word *punmapped_bytes, GC_word *pbytes_since_gc,\n                       GC_word *ptotal_bytes)\n{\n  READER_LOCK();\n  if (pheap_size != NULL)\n    *pheap_size = GC_heapsize - GC_unmapped_bytes;\n  if (pfree_bytes != NULL)\n    *pfree_bytes = GC_large_free_bytes - GC_unmapped_bytes;\n  if (punmapped_bytes != NULL)\n    *punmapped_bytes = GC_unmapped_bytes;\n  if (pbytes_since_gc != NULL)\n    *pbytes_since_gc = GC_bytes_allocd;\n  if (ptotal_bytes != NULL)\n    *ptotal_bytes = GC_bytes_allocd + GC_bytes_allocd_before_gc;\n  READER_UNLOCK();\n}\n\nGC_INNER word GC_reclaimed_bytes_before_gc = 0;\n\n/* Fill in GC statistics provided the destination is of enough size.  */\nstatic void\nfill_prof_stats(struct GC_prof_stats_s *pstats)\n{\n  pstats->heapsize_full = GC_heapsize;\n  pstats->free_bytes_full = GC_large_free_bytes;\n  pstats->unmapped_bytes = GC_unmapped_bytes;\n  pstats->bytes_allocd_since_gc = GC_bytes_allocd;\n  pstats->allocd_bytes_before_gc = GC_bytes_allocd_before_gc;\n  pstats->non_gc_bytes = GC_non_gc_bytes;\n  pstats->gc_no = GC_gc_no; /* could be -1 */\n#  ifdef PARALLEL_MARK\n  pstats->markers_m1 = (word)((GC_signed_word)GC_markers_m1);\n#  else\n  /* A single marker.       */\n  pstats->markers_m1 = 0;\n#  endif\n  pstats->bytes_reclaimed_since_gc\n      = GC_bytes_found > 0 ? (word)GC_bytes_found : 0;\n  pstats->reclaimed_bytes_before_gc = GC_reclaimed_bytes_before_gc;\n  pstats->expl_freed_bytes_since_gc = GC_bytes_freed; /* since gc-7.7 */\n  pstats->obtained_from_os_bytes = GC_our_mem_bytes;  /* since gc-8.2 */\n}\n\n#  include <string.h> /* for memset() */\n\nGC_API size_t GC_CALL\nGC_get_prof_stats(struct GC_prof_stats_s *pstats, size_t stats_sz)\n{\n  struct GC_prof_stats_s stats;\n\n  READER_LOCK();\n  fill_prof_stats(stats_sz >= sizeof(stats) ? pstats : &stats);\n  READER_UNLOCK();\n\n  if (stats_sz == sizeof(stats)) {\n    return sizeof(stats);\n  } else if (stats_sz > sizeof(stats)) {\n    /* Fill in the remaining part with -1.    */\n    memset((char *)pstats + sizeof(stats), 0xff, stats_sz - sizeof(stats));\n    return sizeof(stats);\n  } else {\n    if (EXPECT(stats_sz > 0, TRUE))\n      BCOPY(&stats, pstats, stats_sz);\n    return stats_sz;\n  }\n}\n\n#  ifdef THREADS\n/* The _unsafe version assumes the caller holds the allocator lock, */\n/* at least in the reader mode.                                     */\nGC_API size_t GC_CALL\nGC_get_prof_stats_unsafe(struct GC_prof_stats_s *pstats, size_t stats_sz)\n{\n  struct GC_prof_stats_s stats;\n\n  if (stats_sz >= sizeof(stats)) {\n    fill_prof_stats(pstats);\n    if (stats_sz > sizeof(stats))\n      memset((char *)pstats + sizeof(stats), 0xff, stats_sz - sizeof(stats));\n    return sizeof(stats);\n  } else {\n    if (EXPECT(stats_sz > 0, TRUE)) {\n      fill_prof_stats(&stats);\n      BCOPY(&stats, pstats, stats_sz);\n    }\n    return stats_sz;\n  }\n}\n#  endif /* THREADS */\n\n#endif /* !GC_GET_HEAP_USAGE_NOT_NEEDED */\n\n#if defined(THREADS) && !defined(SIGNAL_BASED_STOP_WORLD)\n/* GC does not use signals to suspend and restart threads.    */\nGC_API void GC_CALL\nGC_set_suspend_signal(int sig)\n{\n  UNUSED_ARG(sig);\n}\n\nGC_API void GC_CALL\nGC_set_thr_restart_signal(int sig)\n{\n  UNUSED_ARG(sig);\n}\n\nGC_API int GC_CALL\nGC_get_suspend_signal(void)\n{\n  return -1;\n}\n\nGC_API int GC_CALL\nGC_get_thr_restart_signal(void)\n{\n  return -1;\n}\n#endif /* THREADS && !SIGNAL_BASED_STOP_WORLD */\n\n#if !defined(_MAX_PATH) && defined(ANY_MSWIN)\n#  define _MAX_PATH MAX_PATH\n#endif\n\n#ifdef GC_READ_ENV_FILE\n/* This works for Win32/WinCE for now.  Really useful only for WinCE. */\n\n/* The content of the GC \"env\" file with CR and LF replaced to '\\0'.  */\n/* NULL if the file is missing or empty.  Otherwise, always ends      */\n/* with '\\0'.                                                         */\nSTATIC char *GC_envfile_content = NULL;\n\n/* Length of GC_envfile_content (if non-NULL).  */\nSTATIC unsigned GC_envfile_length = 0;\n\n#  ifndef GC_ENVFILE_MAXLEN\n#    define GC_ENVFILE_MAXLEN 0x4000\n#  endif\n\n#  define GC_ENV_FILE_EXT \".gc.env\"\n\n/* The routine initializes GC_envfile_content from the GC \"env\" file. */\nSTATIC void\nGC_envfile_init(void)\n{\n#  ifdef ANY_MSWIN\n  HANDLE hFile;\n  char *content;\n  unsigned ofs;\n  unsigned len;\n  DWORD nBytesRead;\n  TCHAR path[_MAX_PATH + 0x10]; /* buffer for path + ext */\n  size_t bytes_to_get;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  len = (unsigned)GetModuleFileName(NULL /* hModule */, path, _MAX_PATH + 1);\n  /* If GetModuleFileName() failed then len is 0.   */\n  if (len > 4 && path[len - 4] == (TCHAR)'.') {\n    /* Strip the executable file extension. */\n    len -= 4;\n  }\n  BCOPY(TEXT(GC_ENV_FILE_EXT), &path[len], sizeof(TEXT(GC_ENV_FILE_EXT)));\n  hFile = CreateFile(path, GENERIC_READ, FILE_SHARE_READ | FILE_SHARE_WRITE,\n                     NULL /* lpSecurityAttributes */, OPEN_EXISTING,\n                     FILE_ATTRIBUTE_NORMAL, NULL /* hTemplateFile */);\n  if (hFile == INVALID_HANDLE_VALUE) {\n    /* The file is absent or the operation failed.  */\n    return;\n  }\n  len = (unsigned)GetFileSize(hFile, NULL);\n  if (len <= 1 || len >= GC_ENVFILE_MAXLEN) {\n    CloseHandle(hFile);\n    /* Invalid file length - ignoring the file content.     */\n    return;\n  }\n  /* At this execution point, GC_setpagesize() and GC_init_win32()  */\n  /* must already be called (for GET_MEM() to work correctly).      */\n  GC_ASSERT(GC_page_size != 0);\n  bytes_to_get = ROUNDUP_PAGESIZE_IF_MMAP((size_t)len + 1);\n  content = GC_os_get_mem(bytes_to_get);\n  if (content == NULL) {\n    CloseHandle(hFile);\n    /* An allocation failure.       */\n    return;\n  }\n  ofs = 0;\n  nBytesRead = (DWORD)-1L;\n  /* Last ReadFile() call should clear nBytesRead on success. */\n  while (ReadFile(hFile, content + ofs, len - ofs + 1, &nBytesRead,\n                  NULL /* lpOverlapped */)\n         && nBytesRead != 0) {\n    if ((ofs += nBytesRead) > len)\n      break;\n  }\n  CloseHandle(hFile);\n  if (ofs != len || nBytesRead != 0) {\n    /* TODO: recycle content */\n    /* Read operation has failed - ignoring the file content.   */\n    return;\n  }\n  content[ofs] = '\\0';\n  while (ofs-- > 0) {\n    if (content[ofs] == '\\r' || content[ofs] == '\\n')\n      content[ofs] = '\\0';\n  }\n  GC_ASSERT(NULL == GC_envfile_content);\n  GC_envfile_length = len + 1;\n  GC_envfile_content = content;\n#  endif\n}\n\n/* This routine scans GC_envfile_content for the specified            */\n/* environment variable (and returns its value if found).             */\nGC_INNER char *\nGC_envfile_getenv(const char *name)\n{\n  char *p;\n  const char *end_of_content;\n  size_t namelen;\n\n#  ifndef NO_GETENV\n  /* Try the standard getenv() first.       */\n  p = getenv(name);\n  if (p != NULL)\n    return *p != '\\0' ? p : NULL;\n#  endif\n  p = GC_envfile_content;\n  if (NULL == p) {\n    /* \"env\" file is absent (or empty).       */\n    return NULL;\n  }\n  namelen = strlen(name);\n  if (0 == namelen) {\n    /* A sanity check.        */\n    return NULL;\n  }\n  for (end_of_content = p + GC_envfile_length;\n       ADDR_LT((ptr_t)p, (ptr_t)end_of_content); p += strlen(p) + 1) {\n    if (strncmp(p, name, namelen) == 0 && *(p += namelen) == '=') {\n      /* The match is found; skip '='.        */\n      p++;\n      return *p != '\\0' ? p : NULL;\n    }\n    /* If not matching then skip to the next line. */\n  }\n  GC_ASSERT(p == end_of_content);\n  /* No match is found.       */\n  return NULL;\n}\n#endif /* GC_READ_ENV_FILE */\n\nGC_INNER GC_bool GC_is_initialized = FALSE;\n\nGC_API int GC_CALL\nGC_is_init_called(void)\n{\n  return (int)GC_is_initialized;\n}\n\n#if defined(GC_WIN32_THREADS) \\\n    && ((defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE))\nGC_INNER CRITICAL_SECTION GC_write_cs;\n#endif\n\n#ifndef DONT_USE_ATEXIT\n\n#  if !defined(SMALL_CONFIG)\n/* A dedicated variable to avoid a garbage collection on abort.     */\n/* GC_find_leak cannot be used for this purpose as otherwise        */\n/* TSan finds a data race (between GC_default_on_abort and, e.g.,   */\n/* GC_finish_collection).                                           */\nstatic GC_bool skip_gc_atexit = FALSE;\n#  else\n#    define skip_gc_atexit FALSE\n#  endif\n\nSTATIC void\nGC_exit_check(void)\n{\n  if (GC_find_leak && !skip_gc_atexit) {\n#  ifdef THREADS\n    /* Check that the thread executing at-exit functions is     */\n    /* the same as the one performed the GC initialization,     */\n    /* otherwise the latter thread might already be dead but    */\n    /* still registered and this, as a consequence, might       */\n    /* cause a signal delivery fail when suspending the threads */\n    /* on platforms that do not guarantee ESRCH returned if     */\n    /* the signal is not delivered.                             */\n    /* It should also prevent \"Collecting from unknown thread\"  */\n    /* abort in GC_push_all_stacks().                           */\n    if (!GC_is_main_thread() || !GC_thread_is_registered())\n      return;\n#  endif\n    GC_gcollect();\n  }\n}\n\n#endif /* !DONT_USE_ATEXIT */\n\n#if defined(UNIX_LIKE) && !defined(NO_DEBUGGING)\nstatic void\nlooping_handler(int sig)\n{\n  GC_err_printf(\"Caught signal %d: looping in handler\\n\", sig);\n  for (;;) {\n    /* empty */\n  }\n}\n\nstatic GC_bool installed_looping_handler = FALSE;\n\nstatic void\nmaybe_install_looping_handler(void)\n{\n  /* Install looping handler before the write fault handler, so we    */\n  /* handle write faults correctly.                                   */\n  if (!installed_looping_handler && GETENV(\"GC_LOOP_ON_ABORT\") != NULL) {\n    GC_set_and_save_fault_handler(looping_handler);\n    installed_looping_handler = TRUE;\n  }\n}\n\n#else /* !UNIX_LIKE */\n#  define maybe_install_looping_handler()\n#endif\n\n#define GC_DEFAULT_STDERR_FD 2\n#ifdef KOS\n#  define GC_DEFAULT_STDOUT_FD GC_DEFAULT_STDERR_FD\n#else\n#  define GC_DEFAULT_STDOUT_FD 1\n#endif\n\n#if !defined(OS2) && !defined(GC_ANDROID_LOG) && !defined(NN_PLATFORM_CTR) \\\n    && !defined(NINTENDO_SWITCH)                                           \\\n    && (!defined(MSWIN32) || defined(CONSOLE_LOG)) && !defined(MSWINCE)\nSTATIC int GC_stdout = GC_DEFAULT_STDOUT_FD;\nSTATIC int GC_stderr = GC_DEFAULT_STDERR_FD;\nSTATIC int GC_log = GC_DEFAULT_STDERR_FD;\n\n#  ifndef MSWIN32\nGC_API void GC_CALL\nGC_set_log_fd(int fd)\n{\n  GC_log = fd;\n}\n#  endif\n#endif\n\n#ifdef MSGBOX_ON_ERROR\nSTATIC void\nGC_win32_MessageBoxA(const char *msg, const char *caption, unsigned flags)\n{\n#  ifndef DONT_USE_USER32_DLL\n  /* Use static binding to \"user32.dll\".    */\n  (void)MessageBoxA(NULL, msg, caption, flags);\n#  else\n  /* This simplifies linking - resolve \"MessageBoxA\" at run-time. */\n  HINSTANCE hU32 = LoadLibrary(TEXT(\"user32.dll\"));\n  if (hU32) {\n    FARPROC pfn = GetProcAddress(hU32, \"MessageBoxA\");\n    if (pfn)\n      (void)(*(int(WINAPI *)(HWND, LPCSTR, LPCSTR, UINT))(GC_funcptr_uint)pfn)(\n          NULL /* hWnd */, msg, caption, flags);\n    (void)FreeLibrary(hU32);\n  }\n#  endif\n}\n#endif /* MSGBOX_ON_ERROR */\n\n#if defined(THREADS) && defined(UNIX_LIKE) && !defined(NO_GETCONTEXT)\nstatic void\ncallee_saves_pushed_dummy_fn(ptr_t data, void *context)\n{\n  UNUSED_ARG(data);\n  UNUSED_ARG(context);\n}\n#endif\n\n#ifdef MANUAL_VDB\nstatic GC_bool manual_vdb_allowed = TRUE;\n#else\nstatic GC_bool manual_vdb_allowed = FALSE;\n#endif\n\nGC_API void GC_CALL\nGC_set_manual_vdb_allowed(int value)\n{\n  manual_vdb_allowed = (GC_bool)value;\n}\n\nGC_API int GC_CALL\nGC_get_manual_vdb_allowed(void)\n{\n  return (int)manual_vdb_allowed;\n}\n\nGC_API unsigned GC_CALL\nGC_get_supported_vdbs(void)\n{\n#ifdef GC_DISABLE_INCREMENTAL\n  return GC_VDB_NONE;\n#else\n#  if defined(CPPCHECK)\n  /* Workaround a warning about redundant \"or 0\".   */\n  volatile unsigned zero = 0;\n#  endif\n  return\n#  if defined(CPPCHECK)\n      zero\n#  else\n      0\n#  endif\n#  ifndef NO_MANUAL_VDB\n      | GC_VDB_MANUAL\n#  endif\n#  ifdef DEFAULT_VDB\n      | GC_VDB_DEFAULT\n#  endif\n#  ifdef MPROTECT_VDB\n      | GC_VDB_MPROTECT\n#  endif\n#  ifdef GWW_VDB\n      | GC_VDB_GWW\n#  endif\n#  ifdef PROC_VDB\n      | GC_VDB_PROC\n#  endif\n#  ifdef SOFT_VDB\n      | GC_VDB_SOFT\n#  endif\n      ;\n#endif\n}\n\n#ifndef GC_DISABLE_INCREMENTAL\nstatic void\nset_incremental_mode_on(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifndef NO_MANUAL_VDB\n  if (manual_vdb_allowed) {\n    GC_manual_vdb = TRUE;\n    GC_incremental = TRUE;\n  } else\n#  endif\n  /* else */ {\n    /* For GWW_VDB on Win32, this needs to happen before any  */\n    /* heap memory is allocated.                              */\n    GC_incremental = GC_dirty_init();\n  }\n}\n#endif /* !GC_DISABLE_INCREMENTAL */\n\nSTATIC word\nGC_parse_mem_size_arg(const char *str)\n{\n  word result;\n  char *endptr;\n  char ch;\n\n  if ('\\0' == *str)\n    return GC_WORD_MAX; /* bad value */\n  result = (word)STRTOULL(str, &endptr, 10);\n  ch = *endptr;\n  if (ch != '\\0') {\n    if (*(endptr + 1) != '\\0')\n      return GC_WORD_MAX;\n    /* Allow k, M or G suffix.  */\n    switch (ch) {\n    case 'K':\n    case 'k':\n      result <<= 10;\n      break;\n#if CPP_WORDSZ >= 32\n    case 'M':\n    case 'm':\n      result <<= 20;\n      break;\n    case 'G':\n    case 'g':\n      result <<= 30;\n      break;\n#endif\n    default:\n      result = GC_WORD_MAX;\n    }\n  }\n  return result;\n}\n\n#define GC_LOG_STD_NAME \"gc.log\"\n\nGC_API void GC_CALL\nGC_init(void)\n{\n  /* LOCK(); -- no longer does anything this early. */\n  word initial_heap_sz;\n  IF_CANCEL(int cancel_state;)\n\n  if (EXPECT(GC_is_initialized, TRUE))\n    return;\n#ifdef REDIRECT_MALLOC\n  {\n    static GC_bool init_started = FALSE;\n    if (init_started)\n      ABORT(\"Redirected malloc() called during GC init\");\n    init_started = TRUE;\n  }\n#endif\n\n#if defined(GC_INITIAL_HEAP_SIZE) && !defined(CPPCHECK)\n  initial_heap_sz = GC_INITIAL_HEAP_SIZE;\n#else\n  initial_heap_sz = MINHINCR * HBLKSIZE;\n#endif\n\n  DISABLE_CANCEL(cancel_state);\n  /* Note that although we are nominally called with the allocator    */\n  /* lock held, now it is only really acquired once a second thread   */\n  /* is forked.  And the initialization code needs to run before      */\n  /* then.  Thus we really don't hold any locks, and can in fact      */\n  /* safely initialize them here.                                     */\n#ifdef THREADS\n#  ifndef GC_ALWAYS_MULTITHREADED\n  GC_ASSERT(!GC_need_to_lock);\n#  endif\n#  ifdef USE_SPIN_LOCK\n  GC_allocate_lock = AO_TS_INITIALIZER;\n#  endif\n#  ifdef NEED_FAULT_HANDLER_LOCK\n  GC_fault_handler_lock = AO_TS_INITIALIZER;\n#  endif\n#  ifdef SN_TARGET_PS3\n  {\n    pthread_mutexattr_t mattr;\n\n    if (pthread_mutexattr_init(&mattr) != 0)\n      ABORT(\"pthread_mutexattr_init failed\");\n    if (pthread_mutex_init(&GC_allocate_ml, &mattr) != 0)\n      ABORT(\"pthread_mutex_init failed\");\n    (void)pthread_mutexattr_destroy(&mattr);\n  }\n#  endif\n#endif /* THREADS */\n#if defined(GC_WIN32_THREADS) && !defined(GC_PTHREADS)\n#  ifndef SPIN_COUNT\n#    define SPIN_COUNT 4000\n#  endif\n#  ifdef USE_RWLOCK\n  /* TODO: probably use SRWLOCK_INIT instead */\n  InitializeSRWLock(&GC_allocate_ml);\n#  elif defined(MSWINRT_FLAVOR)\n  InitializeCriticalSectionAndSpinCount(&GC_allocate_ml, SPIN_COUNT);\n#  else\n  {\n#    ifndef MSWINCE\n    FARPROC pfn = 0;\n    HMODULE hK32 = GetModuleHandle(TEXT(\"kernel32.dll\"));\n    if (hK32)\n      pfn = GetProcAddress(hK32, \"InitializeCriticalSectionAndSpinCount\");\n    if (pfn) {\n      (*(BOOL(WINAPI *)(LPCRITICAL_SECTION, DWORD))(GC_funcptr_uint)pfn)(\n          &GC_allocate_ml, SPIN_COUNT);\n    } else\n#    endif /* !MSWINCE */\n      /* else */ InitializeCriticalSection(&GC_allocate_ml);\n  }\n#  endif\n#endif /* GC_WIN32_THREADS && !GC_PTHREADS */\n#if defined(GC_WIN32_THREADS) \\\n    && ((defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE))\n  InitializeCriticalSection(&GC_write_cs);\n#endif\n#if defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED)\n  /* Just to set GC_lock_holder.    */\n  LOCK();\n#endif\n#ifdef DYNAMIC_POINTER_MASK\n  if (0 == GC_pointer_mask)\n    GC_pointer_mask = GC_WORD_MAX;\n#endif\n  GC_setpagesize();\n#ifdef MSWIN32\n  GC_init_win32();\n#endif\n#ifdef GC_READ_ENV_FILE\n  GC_envfile_init();\n#endif\n#if !defined(NO_CLOCK) || !defined(SMALL_CONFIG)\n#  ifdef GC_PRINT_VERBOSE_STATS\n  /* This is useful for debugging and profiling on platforms with */\n  /* missing getenv() (like WinCE).                               */\n  GC_print_stats = VERBOSE;\n#  else\n  if (GETENV(\"GC_PRINT_VERBOSE_STATS\") != NULL) {\n    GC_print_stats = VERBOSE;\n  } else if (GETENV(\"GC_PRINT_STATS\") != NULL) {\n    GC_print_stats = 1;\n  }\n#  endif\n#endif\n#if ((defined(UNIX_LIKE) && !defined(GC_ANDROID_LOG))                   \\\n     || (defined(CONSOLE_LOG) && defined(MSWIN32)) || defined(CYGWIN32) \\\n     || defined(SYMBIAN))                                               \\\n    && !defined(SMALL_CONFIG)\n  {\n    const char *fname = TRUSTED_STRING(GETENV(\"GC_LOG_FILE\"));\n#  ifdef GC_LOG_TO_FILE_ALWAYS\n    if (NULL == fname)\n      fname = GC_LOG_STD_NAME;\n#  else\n    if (fname != NULL)\n#  endif\n    {\n#  if defined(_MSC_VER)\n      int log_d = _open(fname, O_CREAT | O_WRONLY | O_APPEND);\n#  else\n      int log_d = open(fname, O_CREAT | O_WRONLY | O_APPEND, 0644);\n#  endif\n      if (log_d < 0) {\n        GC_err_printf(\"Failed to open %s as log file\\n\", fname);\n      } else {\n        const char *str;\n        GC_log = log_d;\n        str = GETENV(\"GC_ONLY_LOG_TO_FILE\");\n#  ifdef GC_ONLY_LOG_TO_FILE\n        /* The similar environment variable set to \"0\"  */\n        /* overrides the effect of the macro defined.   */\n        if (str != NULL && str[0] == '0' && str[1] == '\\0')\n#  else\n        /* Otherwise setting the environment variable   */\n        /* to anything other than \"0\" will prevent from */\n        /* redirecting stdout/err to the log file.      */\n        if (str == NULL || (str[0] == '0' && str[1] == '\\0'))\n#  endif\n        {\n          GC_stdout = log_d;\n          GC_stderr = log_d;\n        }\n      }\n    }\n  }\n#endif\n#if !defined(NO_DEBUGGING) && !defined(GC_DUMP_REGULARLY)\n  if (GETENV(\"GC_DUMP_REGULARLY\") != NULL) {\n    GC_dump_regularly = TRUE;\n  }\n#endif\n#ifdef KEEP_BACK_PTRS\n  {\n    const char *str = GETENV(\"GC_BACKTRACES\");\n\n    if (str != NULL) {\n      GC_backtraces = atol(str);\n      if (str[0] == '\\0')\n        GC_backtraces = 1;\n    }\n  }\n#endif\n  if (GETENV(\"GC_FIND_LEAK\") != NULL) {\n    GC_find_leak = 1;\n  }\n#ifndef SHORT_DBG_HDRS\n  if (GETENV(\"GC_FINDLEAK_DELAY_FREE\") != NULL) {\n    GC_findleak_delay_free = TRUE;\n  }\n#endif\n  if (GETENV(\"GC_ALL_INTERIOR_POINTERS\") != NULL) {\n    GC_all_interior_pointers = 1;\n  }\n  if (GETENV(\"GC_DONT_GC\") != NULL) {\n#if defined(LINT2) \\\n    && !(defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED))\n    GC_disable();\n#else\n    GC_dont_gc = 1;\n#endif\n  }\n  if (GETENV(\"GC_PRINT_BACK_HEIGHT\") != NULL) {\n    GC_print_back_height = TRUE;\n  }\n  if (GETENV(\"GC_NO_BLACKLIST_WARNING\") != NULL) {\n    GC_large_alloc_warn_interval = LONG_MAX;\n  }\n  {\n    const char *str = GETENV(\"GC_TRACE\");\n\n    if (str != NULL) {\n#ifndef ENABLE_TRACE\n      WARN(\"Tracing not enabled: Ignoring GC_TRACE value\\n\", 0);\n#else\n      ptr_t p = MAKE_CPTR(STRTOULL(str, NULL, 16));\n\n      if (ADDR(p) < 0x1000)\n        WARN(\"Unlikely trace address: %p\\n\", p);\n      GC_trace_ptr = p;\n#endif\n    }\n  }\n#ifdef GC_COLLECT_AT_MALLOC\n  {\n    const char *str = GETENV(\"GC_COLLECT_AT_MALLOC\");\n\n    if (str != NULL) {\n      size_t min_lb = (size_t)STRTOULL(str, NULL, 10);\n\n      if (min_lb > 0)\n        GC_dbg_collect_at_malloc_min_lb = min_lb;\n    }\n  }\n#endif\n#if !defined(GC_DISABLE_INCREMENTAL) && !defined(NO_CLOCK)\n  {\n    const char *str = GETENV(\"GC_PAUSE_TIME_TARGET\");\n\n    if (str != NULL) {\n      long time_limit = atol(str);\n\n      if (time_limit > 0) {\n        GC_time_limit = (unsigned long)time_limit;\n      }\n    }\n  }\n#endif\n#ifndef SMALL_CONFIG\n  {\n    const char *str = GETENV(\"GC_FULL_FREQUENCY\");\n\n    if (str != NULL) {\n      int full_freq = atoi(str);\n\n      if (full_freq > 0)\n        GC_full_freq = full_freq;\n    }\n  }\n#endif\n  {\n    char const *str = GETENV(\"GC_LARGE_ALLOC_WARN_INTERVAL\");\n\n    if (str != NULL) {\n      long interval = atol(str);\n\n      if (interval <= 0) {\n        WARN(\"GC_LARGE_ALLOC_WARN_INTERVAL environment variable has\"\n             \" bad value - ignoring\\n\",\n             0);\n      } else {\n        GC_large_alloc_warn_interval = interval;\n      }\n    }\n  }\n  {\n    const char *str = GETENV(\"GC_FREE_SPACE_DIVISOR\");\n\n    if (str != NULL) {\n      int space_divisor = atoi(str);\n\n      if (space_divisor > 0)\n        GC_free_space_divisor = (unsigned)space_divisor;\n    }\n  }\n#ifdef USE_MUNMAP\n  {\n    const char *str = GETENV(\"GC_UNMAP_THRESHOLD\");\n\n    if (str != NULL) {\n      if (str[0] == '0' && str[1] == '\\0') {\n        /* \"0\" is used to disable unmapping. */\n        GC_unmap_threshold = 0;\n      } else {\n        int unmap_threshold = atoi(str);\n\n        if (unmap_threshold > 0)\n          GC_unmap_threshold = (unsigned)unmap_threshold;\n      }\n    }\n  }\n  {\n    const char *str = GETENV(\"GC_FORCE_UNMAP_ON_GCOLLECT\");\n\n    if (str != NULL) {\n      if (str[0] == '0' && str[1] == '\\0') {\n        /* \"0\" is used to turn off the mode. */\n        GC_force_unmap_on_gcollect = FALSE;\n      } else {\n        GC_force_unmap_on_gcollect = TRUE;\n      }\n    }\n  }\n  {\n    const char *str = GETENV(\"GC_USE_ENTIRE_HEAP\");\n\n    if (str != NULL) {\n      if (str[0] == '0' && str[1] == '\\0') {\n        /* \"0\" is used to turn off the mode. */\n        GC_use_entire_heap = FALSE;\n      } else {\n        GC_use_entire_heap = TRUE;\n      }\n    }\n  }\n#endif\n#if !defined(NO_DEBUGGING) && !defined(NO_CLOCK)\n  GET_TIME(GC_init_time);\n#endif\n  maybe_install_looping_handler();\n#if ALIGNMENT > GC_DS_TAGS\n  /* Adjust normal object descriptor for extra allocation.  */\n  if (EXTRA_BYTES != 0)\n    GC_obj_kinds[NORMAL].ok_descriptor\n        = ((~(word)ALIGNMENT) + 1) | GC_DS_LENGTH;\n#endif\n  GC_exclude_static_roots_inner(beginGC_arrays, endGC_arrays);\n  GC_exclude_static_roots_inner(beginGC_obj_kinds, endGC_obj_kinds);\n#ifdef SEPARATE_GLOBALS\n  GC_exclude_static_roots_inner(beginGC_objfreelist, endGC_objfreelist);\n  GC_exclude_static_roots_inner(beginGC_aobjfreelist, endGC_aobjfreelist);\n#endif\n#if defined(USE_PROC_FOR_LIBRARIES) && defined(LINUX) && defined(THREADS)\n  /* TODO: USE_PROC_FOR_LIBRARIES with LinuxThreads performs poorly!    */\n  /* If thread stacks are cached, they tend to be scanned in entirety   */\n  /* as part of the root set.  This will grow them to maximum size, and */\n  /* is generally not desirable.                                        */\n#endif\n#if !defined(THREADS) || !(defined(SN_TARGET_PS3) || defined(SN_TARGET_PSP2))\n  if (NULL == GC_stackbottom) {\n    GC_stackbottom = GC_get_main_stack_base();\n#  if (defined(LINUX) || defined(HPUX)) && defined(IA64)\n    GC_register_stackbottom = GC_get_register_stack_base();\n#  endif\n  } else {\n#  if (defined(LINUX) || defined(HPUX)) && defined(IA64)\n    if (NULL == GC_register_stackbottom) {\n      WARN(\"GC_register_stackbottom should be set with GC_stackbottom\\n\", 0);\n      /* The following may fail, since we may rely on             */\n      /* alignment properties that may not hold with a user set   */\n      /* GC_stackbottom.                                          */\n      GC_register_stackbottom = GC_get_register_stack_base();\n    }\n#  endif\n  }\n#endif\n#if !defined(CPPCHECK)\n  GC_STATIC_ASSERT(sizeof(size_t) <= sizeof(ptrdiff_t));\n#  ifdef AO_HAVE_store\n  /* As of now, hb/mse_descr and hb_marks[i] might be treated */\n  /* as words but might be accessed atomically.               */\n  GC_STATIC_ASSERT(sizeof(AO_t) == sizeof(word));\n#  endif\n  GC_STATIC_ASSERT(sizeof(ptrdiff_t) == sizeof(word));\n  GC_STATIC_ASSERT(sizeof(GC_signed_word) == sizeof(word));\n  GC_STATIC_ASSERT(sizeof(word) * 8 == CPP_WORDSZ);\n  GC_STATIC_ASSERT(sizeof(ptr_t) * 8 == CPP_PTRSZ);\n  GC_STATIC_ASSERT(sizeof(ptr_t) == sizeof(GC_uintptr_t));\n  GC_STATIC_ASSERT(sizeof(GC_oom_func) == sizeof(GC_funcptr_uint));\n#  ifdef FUNCPTR_IS_DATAPTR\n  GC_STATIC_ASSERT(sizeof(ptr_t) == sizeof(GC_funcptr_uint));\n#  endif\n#  if !defined(_AUX_SOURCE) || defined(__GNUC__)\n  GC_STATIC_ASSERT((word)(-1) > (word)0);\n  /* word should be unsigned */\n#  endif\n  /* We no longer check for ((void*)(-1) > NULL) since all pointers */\n  /* are explicitly cast to word in every less/greater comparison.  */\n  GC_STATIC_ASSERT((GC_signed_word)(-1) < (GC_signed_word)0);\n#endif\n  GC_STATIC_ASSERT(sizeof(struct hblk) == HBLKSIZE);\n#ifndef THREADS\n  GC_ASSERT(!HOTTER_THAN(GC_stackbottom, GC_approx_sp()));\n#endif\n  GC_init_headers();\n#ifdef SEARCH_FOR_DATA_START\n  /* For MPROTECT_VDB, the temporary fault handler should be        */\n  /* installed first, before the write fault one in GC_dirty_init.  */\n  if (GC_REGISTER_MAIN_STATIC_DATA())\n    GC_init_linux_data_start();\n#endif\n#ifndef GC_DISABLE_INCREMENTAL\n  if (GC_incremental || GETENV(\"GC_ENABLE_INCREMENTAL\") != NULL) {\n    set_incremental_mode_on();\n    GC_ASSERT(0 == GC_bytes_allocd);\n  }\n#endif\n\n  /* Add initial guess of root sets.  Do this first, since sbrk(0)    */\n  /* might be used.                                                   */\n  if (GC_REGISTER_MAIN_STATIC_DATA())\n    GC_register_data_segments();\n\n  GC_bl_init();\n  GC_mark_init();\n  {\n    const char *str = GETENV(\"GC_INITIAL_HEAP_SIZE\");\n\n    if (str != NULL) {\n      word value = GC_parse_mem_size_arg(str);\n\n      if (GC_WORD_MAX == value) {\n        WARN(\"Bad initial heap size %s - ignoring\\n\", str);\n      } else {\n        initial_heap_sz = value;\n      }\n    }\n  }\n  {\n    const char *str = GETENV(\"GC_MAXIMUM_HEAP_SIZE\");\n\n    if (str != NULL) {\n      word max_heap_sz = GC_parse_mem_size_arg(str);\n\n      if (max_heap_sz < initial_heap_sz || GC_WORD_MAX == max_heap_sz) {\n        WARN(\"Bad maximum heap size %s - ignoring\\n\", str);\n      } else {\n        if (0 == GC_max_retries)\n          GC_max_retries = 2;\n        GC_set_max_heap_size(max_heap_sz);\n      }\n    }\n  }\n  if (initial_heap_sz != 0) {\n    if (!GC_expand_hp_inner(divHBLKSZ(initial_heap_sz))) {\n      GC_err_printf(\"Can't start up: not enough memory\\n\");\n      EXIT();\n    } else {\n      GC_requested_heapsize += initial_heap_sz;\n    }\n  }\n  if (GC_all_interior_pointers)\n    GC_initialize_offsets();\n  GC_register_displacement_inner(0);\n#ifdef REDIR_MALLOC_AND_LINUXTHREADS\n  if (!GC_all_interior_pointers) {\n    /* TLS ABI uses pointer-sized offsets for dtv. */\n    GC_register_displacement_inner(sizeof(void *));\n  }\n#endif\n  GC_init_size_map();\n  GC_is_initialized = TRUE;\n#ifdef THREADS\n#  if defined(LINT2) \\\n      && !(defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED))\n  LOCK();\n  GC_thr_init();\n  UNLOCK();\n#  else\n  GC_thr_init();\n#  endif\n#endif\n  COND_DUMP;\n  /* Get black list set up and/or the incremental GC started. */\n  if (!GC_dont_precollect || GC_incremental) {\n#if defined(DYNAMIC_LOADING) && defined(DARWIN)\n    GC_ASSERT(0 == GC_bytes_allocd);\n#endif\n    GC_gcollect_inner();\n  }\n#if defined(GC_ASSERTIONS) && defined(GC_ALWAYS_MULTITHREADED)\n  UNLOCK();\n#endif\n#if defined(THREADS) && defined(UNIX_LIKE) && !defined(NO_GETCONTEXT)\n  /* Ensure getcontext_works is set to avoid potential data race.   */\n  if (GC_dont_gc || GC_dont_precollect)\n    GC_with_callee_saves_pushed(callee_saves_pushed_dummy_fn, NULL);\n#endif\n#ifndef DONT_USE_ATEXIT\n  if (GC_find_leak) {\n    /* This is to give us at least one chance to detect leaks.        */\n    /* This may report some very benign leaks, but ...                */\n    atexit(GC_exit_check);\n  }\n#endif\n\n  /* The rest of this again assumes we do not really hold     */\n  /* the allocator lock.                                      */\n\n#ifdef THREADS\n  /* Initialize thread-local allocation.    */\n  GC_init_parallel();\n#endif\n\n#if defined(DYNAMIC_LOADING) && defined(DARWIN)\n  /* This must be called WITHOUT the allocator lock held  */\n  /* and before any threads are created.                  */\n  GC_init_dyld();\n#endif\n  RESTORE_CANCEL(cancel_state);\n  /* It is not safe to allocate any object till completion of GC_init */\n  /* (in particular by GC_thr_init), i.e. before GC_init_dyld() call  */\n  /* and initialization of the incremental mode (if any).             */\n#if defined(GWW_VDB) && !defined(KEEP_BACK_PTRS)\n  GC_ASSERT(GC_bytes_allocd + GC_bytes_allocd_before_gc == 0);\n#endif\n}\n\nGC_API void GC_CALL\nGC_enable_incremental(void)\n{\n#if !defined(GC_DISABLE_INCREMENTAL) && !defined(KEEP_BACK_PTRS)\n  /* If we are keeping back pointers, the GC itself dirties all */\n  /* pages on which objects have been marked, making            */\n  /* incremental GC pointless.                                  */\n  if (!GC_find_leak && NULL == GETENV(\"GC_DISABLE_INCREMENTAL\")) {\n    LOCK();\n    if (!GC_incremental) {\n      GC_setpagesize();\n      /* TODO: Should we skip enabling incremental if win32s? */\n\n      /* Install the looping handler before write fault handler!  */\n      maybe_install_looping_handler();\n      if (!GC_is_initialized) {\n        /* Indicate the intention to turn it on.      */\n        GC_incremental = TRUE;\n        UNLOCK();\n        GC_init();\n        LOCK();\n      } else {\n        set_incremental_mode_on();\n      }\n      /* Can't easily do it if GC_dont_gc.    */\n      if (GC_incremental && !GC_dont_gc) {\n        IF_CANCEL(int cancel_state;)\n\n        DISABLE_CANCEL(cancel_state);\n        if (GC_bytes_allocd > 0) {\n          /* There may be unmarked reachable objects. */\n          GC_gcollect_inner();\n        } else {\n          /* We are OK in assuming everything is      */\n          /* clean since nothing can point to an      */\n          /* unmarked object.                         */\n#  ifdef CHECKSUMS\n          GC_read_dirty(FALSE);\n#  else\n          GC_read_dirty(TRUE);\n#  endif\n        }\n        RESTORE_CANCEL(cancel_state);\n      }\n    }\n    UNLOCK();\n    return;\n  }\n#endif\n  GC_init();\n}\n\nGC_API void GC_CALL\nGC_start_mark_threads(void)\n{\n#ifdef PARALLEL_MARK\n  IF_CANCEL(int cancel_state;)\n\n  DISABLE_CANCEL(cancel_state);\n  LOCK();\n  GC_start_mark_threads_inner();\n  UNLOCK();\n  RESTORE_CANCEL(cancel_state);\n#else\n  /* No action since parallel markers are disabled (or no POSIX fork). */\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n#endif\n}\n\nGC_API void GC_CALL\nGC_deinit(void)\n{\n  if (GC_is_initialized) {\n    /* Prevent duplicate resource close.  */\n    GC_is_initialized = FALSE;\n    GC_bytes_allocd = 0;\n    GC_bytes_allocd_before_gc = 0;\n#if defined(GC_WIN32_THREADS) && (defined(MSWIN32) || defined(MSWINCE))\n#  if !defined(CONSOLE_LOG) || defined(MSWINCE)\n    DeleteCriticalSection(&GC_write_cs);\n#  endif\n#  if !defined(GC_PTHREADS) && !defined(USE_RWLOCK)\n    DeleteCriticalSection(&GC_allocate_ml);\n#  endif\n#endif\n  }\n}\n\n#if (defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE)\n\nSTATIC HANDLE GC_log = 0;\n\n#  ifdef THREADS\n#    if defined(PARALLEL_MARK) && !defined(GC_ALWAYS_MULTITHREADED)\n#      define IF_NEED_TO_LOCK(x)            \\\n        if (GC_parallel || GC_need_to_lock) \\\n        x\n#    else\n#      define IF_NEED_TO_LOCK(x) \\\n        if (GC_need_to_lock)     \\\n        x\n#    endif\n#  else\n#    define IF_NEED_TO_LOCK(x)\n#  endif /* !THREADS */\n\n#  ifdef MSWINRT_FLAVOR\n#    include <windows.storage.h>\n\n/* This API is defined in roapi.h, but we cannot include it here    */\n/* since it does not compile in C.                                  */\nDECLSPEC_IMPORT HRESULT WINAPI\nRoGetActivationFactory(HSTRING activatableClassId, REFIID iid, void **factory);\n\nstatic GC_bool\ngetWinRTLogPath(wchar_t *buf, size_t bufLen)\n{\n  static const GUID kIID_IApplicationDataStatics\n      = { 0x5612147B, 0xE843, 0x45E3, 0x94, 0xD8, 0x06,\n          0x16,       0x9E,   0x3C,   0x8E, 0x17 };\n  static const GUID kIID_IStorageItem\n      = { 0x4207A996, 0xCA2F, 0x42F7, 0xBD, 0xE8, 0x8B,\n          0x10,       0x45,   0x7A,   0x7F, 0x30 };\n  GC_bool result = FALSE;\n  HSTRING_HEADER appDataClassNameHeader;\n  HSTRING appDataClassName;\n  __x_ABI_CWindows_CStorage_CIApplicationDataStatics *appDataStatics = 0;\n\n  GC_ASSERT(bufLen > 0);\n  if (SUCCEEDED(WindowsCreateStringReference(\n          RuntimeClass_Windows_Storage_ApplicationData,\n          (sizeof(RuntimeClass_Windows_Storage_ApplicationData) - 1)\n              / sizeof(wchar_t),\n          &appDataClassNameHeader, &appDataClassName))\n      && SUCCEEDED(RoGetActivationFactory(\n          appDataClassName, &kIID_IApplicationDataStatics, &appDataStatics))) {\n    __x_ABI_CWindows_CStorage_CIApplicationData *appData = NULL;\n    __x_ABI_CWindows_CStorage_CIStorageFolder *tempFolder = NULL;\n    __x_ABI_CWindows_CStorage_CIStorageItem *tempFolderItem = NULL;\n    HSTRING tempPath = NULL;\n\n    if (SUCCEEDED(\n            appDataStatics->lpVtbl->get_Current(appDataStatics, &appData))\n        && SUCCEEDED(\n            appData->lpVtbl->get_TemporaryFolder(appData, &tempFolder))\n        && SUCCEEDED(tempFolder->lpVtbl->QueryInterface(\n            tempFolder, &kIID_IStorageItem, &tempFolderItem))\n        && SUCCEEDED(\n            tempFolderItem->lpVtbl->get_Path(tempFolderItem, &tempPath))) {\n      UINT32 tempPathLen;\n      const wchar_t *tempPathBuf\n          = WindowsGetStringRawBuffer(tempPath, &tempPathLen);\n\n      buf[0] = '\\0';\n      if (wcsncat_s(buf, bufLen, tempPathBuf, tempPathLen) == 0\n          && wcscat_s(buf, bufLen, L\"\\\\\") == 0\n          && wcscat_s(buf, bufLen, TEXT(GC_LOG_STD_NAME)) == 0)\n        result = TRUE;\n      WindowsDeleteString(tempPath);\n    }\n\n    if (tempFolderItem != NULL)\n      tempFolderItem->lpVtbl->Release(tempFolderItem);\n    if (tempFolder != NULL)\n      tempFolder->lpVtbl->Release(tempFolder);\n    if (appData != NULL)\n      appData->lpVtbl->Release(appData);\n    appDataStatics->lpVtbl->Release(appDataStatics);\n  }\n  return result;\n}\n#  endif /* MSWINRT_FLAVOR */\n\nSTATIC HANDLE\nGC_CreateLogFile(void)\n{\n  HANDLE hFile;\n#  ifdef MSWINRT_FLAVOR\n  TCHAR pathBuf[_MAX_PATH + 0x10]; /* buffer for path + ext */\n\n  hFile = INVALID_HANDLE_VALUE;\n  if (getWinRTLogPath(pathBuf, _MAX_PATH + 1)) {\n    CREATEFILE2_EXTENDED_PARAMETERS extParams;\n\n    BZERO(&extParams, sizeof(extParams));\n    extParams.dwSize = sizeof(extParams);\n    extParams.dwFileAttributes = FILE_ATTRIBUTE_NORMAL;\n    extParams.dwFileFlags\n        = GC_print_stats == VERBOSE ? 0 : FILE_FLAG_WRITE_THROUGH;\n    hFile = CreateFile2(pathBuf, GENERIC_WRITE, FILE_SHARE_READ, CREATE_ALWAYS,\n                        &extParams);\n  }\n\n#  else\n  TCHAR *logPath;\n#    if defined(NO_GETENV_WIN32) && defined(CPPCHECK)\n#      define appendToFile FALSE\n#    else\n  BOOL appendToFile = FALSE;\n#    endif\n#    if !defined(NO_GETENV_WIN32) || !defined(OLD_WIN32_LOG_FILE)\n  TCHAR pathBuf[_MAX_PATH + 0x10]; /* buffer for path + ext */\n\n  logPath = pathBuf;\n#    endif\n\n  /* Use GetEnvironmentVariable instead of GETENV() for unicode support. */\n#    ifndef NO_GETENV_WIN32\n  if (GetEnvironmentVariable(TEXT(\"GC_LOG_FILE\"), pathBuf, _MAX_PATH + 1) - 1U\n      < (DWORD)_MAX_PATH) {\n    appendToFile = TRUE;\n  } else\n#    endif\n  /* else */ {\n    /* Env var not found or its value too long.       */\n#    ifdef OLD_WIN32_LOG_FILE\n    logPath = TEXT(GC_LOG_STD_NAME);\n#    else\n    int len\n        = (int)GetModuleFileName(NULL /* hModule */, pathBuf, _MAX_PATH + 1);\n    /* If GetModuleFileName() has failed then len is 0. */\n    if (len > 4 && pathBuf[len - 4] == (TCHAR)'.') {\n      /* Strip the executable file extension.       */\n      len -= 4;\n    }\n    BCOPY(TEXT(\".\") TEXT(GC_LOG_STD_NAME), &pathBuf[len],\n          sizeof(TEXT(\".\") TEXT(GC_LOG_STD_NAME)));\n#    endif\n  }\n\n  hFile = CreateFile(logPath, GENERIC_WRITE, FILE_SHARE_READ,\n                     NULL /* lpSecurityAttributes */,\n                     appendToFile ? OPEN_ALWAYS : CREATE_ALWAYS,\n                     GC_print_stats == VERBOSE\n                         ? FILE_ATTRIBUTE_NORMAL\n                         :\n                         /* immediately flush writes unless very verbose */\n                         FILE_ATTRIBUTE_NORMAL | FILE_FLAG_WRITE_THROUGH,\n                     NULL /* hTemplateFile */);\n\n#    ifndef NO_GETENV_WIN32\n  if (appendToFile && hFile != INVALID_HANDLE_VALUE) {\n    LONG posHigh = 0;\n    /* Seek to the file end (ignoring any error).   */\n    (void)SetFilePointer(hFile, 0, &posHigh, FILE_END);\n  }\n#    endif\n#    undef appendToFile\n#  endif\n  return hFile;\n}\n\nSTATIC int\nGC_write(const char *buf, size_t len)\n{\n  BOOL res;\n  DWORD written;\n#  if defined(THREADS) && defined(GC_ASSERTIONS)\n  /* This is to prevent infinite recursion at abort.      */\n  static GC_bool inside_write = FALSE;\n  if (inside_write)\n    return -1;\n#  endif\n\n  if (0 == len)\n    return 0;\n  IF_NEED_TO_LOCK(EnterCriticalSection(&GC_write_cs));\n#  if defined(THREADS) && defined(GC_ASSERTIONS)\n  if (GC_write_disabled) {\n    inside_write = TRUE;\n    ABORT(\"Assertion failure: GC_write called with write_disabled\");\n  }\n#  endif\n  if (0 == GC_log) {\n    GC_log = GC_CreateLogFile();\n  }\n  if (GC_log == INVALID_HANDLE_VALUE) {\n    IF_NEED_TO_LOCK(LeaveCriticalSection(&GC_write_cs));\n#  ifdef NO_DEBUGGING\n    /* Ignore open log failure (e.g., it might be caused by       */\n    /* read-only folder of the client application).               */\n    return 0;\n#  else\n    return -1;\n#  endif\n  }\n  res = WriteFile(GC_log, buf, (DWORD)len, &written, NULL);\n#  if defined(_MSC_VER) && defined(_DEBUG) && !defined(NO_CRT) \\\n      && !defined(NO_CRTDBGREPORT)\n#    ifdef MSWINCE\n  /* There is no CrtDbgReport() in WinCE */\n  {\n    WCHAR wbuf[1024];\n\n    /* Always use Unicode variant of OutputDebugString() */\n    wbuf[MultiByteToWideChar(CP_ACP, 0 /* dwFlags */, buf, len, wbuf,\n                             sizeof(wbuf) / sizeof(wbuf[0]) - 1)]\n        = 0;\n    OutputDebugStringW(wbuf);\n  }\n#    else\n  _CrtDbgReport(_CRT_WARN, NULL, 0, NULL, \"%.*s\", len, buf);\n#    endif\n#  endif\n  IF_NEED_TO_LOCK(LeaveCriticalSection(&GC_write_cs));\n  return res ? (int)written : -1;\n}\n\n/* TODO: This is pretty ugly ... */\n#  define WRITE(f, buf, len) GC_write(buf, len)\n\n#elif defined(OS2)\nSTATIC FILE *GC_stdout = NULL;\nSTATIC FILE *GC_stderr = NULL;\nSTATIC FILE *GC_log = NULL;\n\n/* Initialize GC_log (and the friends) passed to GC_write().  */\nSTATIC void\nGC_set_files(void)\n{\n  if (GC_stdout == NULL) {\n    GC_stdout = stdout;\n  }\n  if (GC_stderr == NULL) {\n    GC_stderr = stderr;\n  }\n  if (GC_log == NULL) {\n    GC_log = stderr;\n  }\n}\n\nGC_INLINE int\nGC_write(FILE *f, const char *buf, size_t len)\n{\n  int res = fwrite(buf, 1, len, f);\n  fflush(f);\n  return res;\n}\n\n#  define WRITE(f, buf, len) (GC_set_files(), GC_write(f, buf, len))\n\n#elif defined(GC_ANDROID_LOG)\n\n#  include <android/log.h>\n\n#  ifndef GC_ANDROID_LOG_TAG\n#    define GC_ANDROID_LOG_TAG \"BDWGC\"\n#  endif\n\n#  define GC_stdout ANDROID_LOG_DEBUG\n#  define GC_stderr ANDROID_LOG_ERROR\n#  define GC_log GC_stdout\n\n#  define WRITE(level, buf, unused_len) \\\n    __android_log_write(level, GC_ANDROID_LOG_TAG, buf)\n\n#elif defined(NN_PLATFORM_CTR)\nint n3ds_log_write(const char *text, int length);\n#  define WRITE(level, buf, len) n3ds_log_write(buf, len)\n\n#elif defined(NINTENDO_SWITCH)\nint switch_log_write(const char *text, int length);\n#  define WRITE(level, buf, len) switch_log_write(buf, len)\n\n#else\n\n#  if !defined(ECOS) && !defined(NOSYS) && !defined(PLATFORM_WRITE) \\\n      && !defined(SN_TARGET_PSP2)\n#    include <errno.h>\n#  endif\n\nSTATIC int\nGC_write(int fd, const char *buf, size_t len)\n{\n#  if defined(ECOS) || defined(PLATFORM_WRITE) || defined(SN_TARGET_PSP2) \\\n      || defined(NOSYS)\n  UNUSED_ARG(fd);\n#    ifdef ECOS\n  /* FIXME: This seems to be defined nowhere at present.  */\n  /* _Jv_diag_write(buf, len); */\n#    else\n  /* No writing.  */\n#    endif\n  UNUSED_ARG(buf);\n  return (int)len;\n#  else\n  size_t bytes_written = 0;\n  IF_CANCEL(int cancel_state;)\n\n  DISABLE_CANCEL(cancel_state);\n  while (bytes_written < len) {\n    int result;\n\n#    if defined(SOLARIS) && defined(THREADS)\n    result = syscall(SYS_write, fd, buf + bytes_written, len - bytes_written);\n#    elif defined(_MSC_VER)\n    result = _write(fd, buf + bytes_written, (unsigned)(len - bytes_written));\n#    else\n    result = (int)write(fd, buf + bytes_written, len - bytes_written);\n#    endif\n    if (result < 0) {\n      if (EAGAIN == errno) {\n        /* Resource is temporarily unavailable.     */\n        continue;\n      }\n      RESTORE_CANCEL(cancel_state);\n      return -1;\n    }\n#    ifdef LINT2\n    if ((unsigned)result > len - bytes_written)\n      ABORT(\"write() result cannot be bigger than requested length\");\n#    endif\n    bytes_written += (unsigned)result;\n  }\n  RESTORE_CANCEL(cancel_state);\n  return (int)bytes_written;\n#  endif\n}\n\n#  define WRITE(f, buf, len) GC_write(f, buf, len)\n#endif /* !MSWINCE && !OS2 && !GC_ANDROID_LOG */\n\n#define BUFSZ 1024\n\n#if defined(DJGPP) || defined(__STRICT_ANSI__)\n/* vsnprintf is missing in DJGPP (v2.0.3) */\n#  define GC_VSNPRINTF(buf, bufsz, format, args) vsprintf(buf, format, args)\n#elif defined(_MSC_VER)\n#  ifdef MSWINCE\n/* _vsnprintf is deprecated in WinCE */\n#    define GC_VSNPRINTF StringCchVPrintfA\n#  else\n#    define GC_VSNPRINTF _vsnprintf\n#  endif\n#else\n#  define GC_VSNPRINTF vsnprintf\n#endif\n\n/* A version of printf that is unlikely to call malloc, and is thus safer */\n/* to call from the collector in case malloc has been bound to GC_malloc. */\n/* Floating point arguments and formats should be avoided, since FP       */\n/* conversion is more likely to allocate memory.                          */\n/* Assumes that no more than BUFSZ-1 characters are written at once.      */\n#define GC_PRINTF_FILLBUF(buf, format)                      \\\n  do {                                                      \\\n    va_list args;                                           \\\n    va_start(args, format);                                 \\\n    (buf)[sizeof(buf) - 1] = 0x15; /* guard */              \\\n    (void)GC_VSNPRINTF(buf, sizeof(buf) - 1, format, args); \\\n    va_end(args);                                           \\\n    if ((buf)[sizeof(buf) - 1] != 0x15)                     \\\n      ABORT(\"GC_printf clobbered stack\");                   \\\n  } while (0)\n\nvoid\nGC_printf(const char *format, ...)\n{\n  if (!GC_quiet) {\n    char buf[BUFSZ + 1];\n\n    GC_PRINTF_FILLBUF(buf, format);\n#ifdef NACL\n    (void)WRITE(GC_stdout, buf, strlen(buf));\n    /* Ignore errors silently.      */\n#else\n    if (WRITE(GC_stdout, buf, strlen(buf)) < 0\n#  if defined(CYGWIN32) || (defined(CONSOLE_LOG) && defined(MSWIN32))\n        && GC_stdout != GC_DEFAULT_STDOUT_FD\n#  endif\n    ) {\n      ABORT(\"write to stdout failed\");\n    }\n#endif\n  }\n}\n\nvoid\nGC_err_printf(const char *format, ...)\n{\n  char buf[BUFSZ + 1];\n\n  GC_PRINTF_FILLBUF(buf, format);\n  GC_err_puts(buf);\n}\n\nvoid\nGC_log_printf(const char *format, ...)\n{\n  char buf[BUFSZ + 1];\n\n  GC_PRINTF_FILLBUF(buf, format);\n#ifdef NACL\n  (void)WRITE(GC_log, buf, strlen(buf));\n#else\n  if (WRITE(GC_log, buf, strlen(buf)) < 0\n#  if defined(CYGWIN32) || (defined(CONSOLE_LOG) && defined(MSWIN32))\n      && GC_log != GC_DEFAULT_STDERR_FD\n#  endif\n  ) {\n    ABORT(\"write to GC log failed\");\n  }\n#endif\n}\n\n#ifndef GC_ANDROID_LOG\n\n#  define GC_warn_printf GC_err_printf\n\n#else\n\nGC_INNER void\nGC_info_log_printf(const char *format, ...)\n{\n  char buf[BUFSZ + 1];\n\n  GC_PRINTF_FILLBUF(buf, format);\n  (void)WRITE(ANDROID_LOG_INFO, buf, 0 /* unused */);\n}\n\nGC_INNER void\nGC_verbose_log_printf(const char *format, ...)\n{\n  char buf[BUFSZ + 1];\n\n  GC_PRINTF_FILLBUF(buf, format);\n  /* Note: write errors are ignored.  */\n  (void)WRITE(ANDROID_LOG_VERBOSE, buf, 0);\n}\n\nSTATIC void\nGC_warn_printf(const char *format, ...)\n{\n  char buf[BUFSZ + 1];\n\n  GC_PRINTF_FILLBUF(buf, format);\n  (void)WRITE(ANDROID_LOG_WARN, buf, 0);\n}\n\n#endif /* GC_ANDROID_LOG */\n\nvoid\nGC_err_puts(const char *s)\n{\n  /* Note: write errors are ignored.  */\n  (void)WRITE(GC_stderr, s, strlen(s));\n}\n\nSTATIC void GC_CALLBACK\nGC_default_warn_proc(const char *msg, GC_uintptr_t arg)\n{\n  /* TODO: Add assertion on arg comply with msg (format).     */\n  GC_warn_printf(msg, arg);\n}\n\nGC_INNER GC_warn_proc GC_current_warn_proc = GC_default_warn_proc;\n\n/* This is recommended for production code (release). */\nGC_API void GC_CALLBACK\nGC_ignore_warn_proc(const char *msg, GC_uintptr_t arg)\n{\n  if (GC_print_stats) {\n    /* Don't ignore warnings if stats printing is on. */\n    GC_default_warn_proc(msg, arg);\n  }\n}\n\nGC_API void GC_CALL\nGC_set_warn_proc(GC_warn_proc p)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(p));\n  LOCK();\n  GC_current_warn_proc = p;\n  UNLOCK();\n}\n\nGC_API GC_warn_proc GC_CALL\nGC_get_warn_proc(void)\n{\n  GC_warn_proc result;\n\n  READER_LOCK();\n  result = GC_current_warn_proc;\n  READER_UNLOCK();\n  return result;\n}\n\n/* Print (or display) a message before abnormal exit (including     */\n/* abort).  Invoked from ABORT(msg) macro (there msg is non-NULL)   */\n/* and from EXIT() macro (msg is NULL in that case).                */\nSTATIC void GC_CALLBACK\nGC_default_on_abort(const char *msg)\n{\n#if !defined(SMALL_CONFIG)\n#  ifndef DONT_USE_ATEXIT\n  /* Disable at-exit garbage collection.    */\n  skip_gc_atexit = TRUE;\n#  endif\n\n  if (msg != NULL) {\n#  ifdef MSGBOX_ON_ERROR\n    GC_win32_MessageBoxA(msg, \"Fatal error in GC\", MB_ICONERROR | MB_OK);\n    /* Also duplicate msg to GC log file.   */\n#  endif\n\n#  ifndef GC_ANDROID_LOG\n    /* Avoid calling GC_err_printf() here, as GC_on_abort() could be  */\n    /* called from it.  Note 1: this is not an atomic output.         */\n    /* Note 2: possible write errors are ignored.                     */\n#    if defined(GC_WIN32_THREADS) && defined(GC_ASSERTIONS) \\\n        && ((defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE))\n    if (!GC_write_disabled)\n#    endif\n    {\n      if (WRITE(GC_stderr, msg, strlen(msg)) >= 0)\n        (void)WRITE(GC_stderr, \"\\n\", 1);\n    }\n#  else\n    __android_log_assert(\"*\" /* cond */, GC_ANDROID_LOG_TAG, \"%s\\n\", msg);\n#  endif\n#  if defined(HAIKU) && !defined(DONT_CALL_DEBUGGER)\n    /* This will cause the crash reason to appear in any debug reports  */\n    /* generated (by the default system application crash dialog).      */\n    debugger(msg);\n#  endif\n  }\n\n#  if !defined(NO_DEBUGGING) && !defined(GC_ANDROID_LOG)\n  if (GETENV(\"GC_LOOP_ON_ABORT\") != NULL) {\n    /* In many cases it's easier to debug a running process.    */\n    /* It's arguably nicer to sleep, but that makes it harder   */\n    /* to look at the thread if the debugger doesn't know much  */\n    /* about threads.                                           */\n    for (;;) {\n      /* Empty */\n    }\n  }\n#  endif\n#else\n  UNUSED_ARG(msg);\n#endif\n}\n\n#ifndef SMALL_CONFIG\nGC_abort_func GC_on_abort = GC_default_on_abort;\n#endif\n\nGC_API void GC_CALL\nGC_set_abort_func(GC_abort_func fn)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fn));\n  LOCK();\n#ifndef SMALL_CONFIG\n  GC_on_abort = fn;\n#else\n  UNUSED_ARG(fn);\n#endif\n  UNLOCK();\n}\n\nGC_API GC_abort_func GC_CALL\nGC_get_abort_func(void)\n{\n  GC_abort_func fn;\n\n  READER_LOCK();\n#ifndef SMALL_CONFIG\n  fn = GC_on_abort;\n  GC_ASSERT(fn != 0);\n#else\n  fn = GC_default_on_abort;\n#endif\n  READER_UNLOCK();\n  return fn;\n}\n\nGC_API void GC_CALL\nGC_enable(void)\n{\n  LOCK();\n  /* Ensure no counter underflow.     */\n  GC_ASSERT(GC_dont_gc != 0);\n  GC_dont_gc--;\n  if (!GC_dont_gc && GC_heapsize > GC_heapsize_on_gc_disable)\n    WARN(\"Heap grown by %\" WARN_PRIuPTR \" KiB while GC was disabled\\n\",\n         (GC_heapsize - GC_heapsize_on_gc_disable) >> 10);\n  UNLOCK();\n}\n\nGC_API void GC_CALL\nGC_disable(void)\n{\n  LOCK();\n  if (!GC_dont_gc)\n    GC_heapsize_on_gc_disable = GC_heapsize;\n  GC_dont_gc++;\n  UNLOCK();\n}\n\nGC_API int GC_CALL\nGC_is_disabled(void)\n{\n  return GC_dont_gc != 0;\n}\n\n/* Helper procedures for new kind creation.     */\nGC_API void **GC_CALL\nGC_new_free_list_inner(void)\n{\n  void *result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  result = GC_INTERNAL_MALLOC((MAXOBJGRANULES + 1) * sizeof(ptr_t), PTRFREE);\n  if (NULL == result)\n    ABORT(\"Failed to allocate free list for new kind\");\n  BZERO(result, (MAXOBJGRANULES + 1) * sizeof(ptr_t));\n  return (void **)result;\n}\n\nGC_API void **GC_CALL\nGC_new_free_list(void)\n{\n  void **result;\n\n  LOCK();\n  result = GC_new_free_list_inner();\n  UNLOCK();\n  return result;\n}\n\nGC_API unsigned GC_CALL\nGC_new_kind_inner(void **fl, GC_word descr, int adjust, int clear)\n{\n  unsigned result = GC_n_kinds;\n\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fl));\n  GC_ASSERT(!adjust || 1 == adjust);\n  /* If an object is not needed to be cleared (when moved to the      */\n  /* free list) then its descriptor should be zero to denote          */\n  /* a pointer-free object (and, as a consequence, the size of the    */\n  /* object should not be added to the descriptor template).          */\n  GC_ASSERT(1 == clear || (0 == descr && !adjust && !clear));\n  if (result < MAXOBJKINDS) {\n    GC_ASSERT(result > 0);\n    GC_n_kinds++;\n    GC_obj_kinds[result].ok_freelist = fl;\n    GC_obj_kinds[result].ok_reclaim_list = 0;\n    GC_obj_kinds[result].ok_descriptor = descr;\n    GC_obj_kinds[result].ok_relocate_descr = (GC_bool)adjust;\n    GC_obj_kinds[result].ok_init = (GC_bool)clear;\n#ifdef ENABLE_DISCLAIM\n    GC_obj_kinds[result].ok_mark_unconditionally = FALSE;\n    GC_obj_kinds[result].ok_disclaim_proc = 0;\n#endif\n  } else {\n    ABORT(\"Too many kinds\");\n  }\n  return result;\n}\n\nGC_API unsigned GC_CALL\nGC_new_kind(void **fl, GC_word descr, int adjust, int clear)\n{\n  unsigned result;\n\n  LOCK();\n  result = GC_new_kind_inner(fl, descr, adjust, clear);\n  UNLOCK();\n  return result;\n}\n\nGC_API unsigned GC_CALL\nGC_new_proc_inner(GC_mark_proc proc)\n{\n  unsigned result = GC_n_mark_procs;\n\n  if (result < GC_MAX_MARK_PROCS) {\n    GC_n_mark_procs++;\n    GC_mark_procs[result] = proc;\n  } else {\n    ABORT(\"Too many mark procedures\");\n  }\n  return result;\n}\n\nGC_API unsigned GC_CALL\nGC_new_proc(GC_mark_proc proc)\n{\n  unsigned result;\n\n  LOCK();\n  result = GC_new_proc_inner(proc);\n  UNLOCK();\n  return result;\n}\n\nGC_API void *GC_CALL\nGC_call_with_alloc_lock(GC_fn_type fn, void *client_data)\n{\n  void *result;\n\n  LOCK();\n  result = fn(client_data);\n  UNLOCK();\n  return result;\n}\n\n#ifdef THREADS\nGC_API void GC_CALL\nGC_alloc_lock(void)\n{\n  LOCK();\n}\n\nGC_API void GC_CALL\nGC_alloc_unlock(void)\n{\n  UNLOCK();\n}\n\nGC_API void *GC_CALL\nGC_call_with_reader_lock(GC_fn_type fn, void *client_data, int release)\n{\n  void *result;\n\n  READER_LOCK();\n  result = fn(client_data);\n#  ifdef HAS_REAL_READER_LOCK\n  if (release) {\n    READER_UNLOCK_RELEASE();\n#    ifdef LINT2\n    GC_noop1((unsigned)release);\n#    endif\n    return result;\n  }\n#  else\n  UNUSED_ARG(release);\n#  endif\n  READER_UNLOCK();\n  return result;\n}\n#endif /* THREADS */\n\nGC_ATTR_NOINLINE\nGC_API void *GC_CALL\nGC_call_with_stack_base(GC_stack_base_func fn, void *arg)\n{\n  struct GC_stack_base base;\n  void *result;\n\n  STORE_APPROX_SP_TO(*(volatile ptr_t *)&base.mem_base);\n#ifdef IA64\n  base.reg_base = GC_save_regs_in_stack();\n  /* TODO: Unnecessarily flushes register stack,    */\n  /* but that probably doesn't hurt.                */\n#elif defined(E2K)\n  {\n    unsigned long long sz_ull;\n\n    GET_PROCEDURE_STACK_SIZE_INNER(&sz_ull);\n    base.reg_base = NUMERIC_TO_VPTR(sz_ull);\n  }\n#endif\n  result = (*(GC_stack_base_func volatile *)&fn)(&base, arg);\n  /* Strongly discourage the compiler from treating the above */\n  /* as a tail call.                                          */\n  GC_noop1(COVERT_DATAFLOW(ADDR(&base)));\n  return result;\n}\n\n#ifndef THREADS\n\n/* Note: NULL value means we are not inside GC_do_blocking() call.    */\nGC_INNER ptr_t GC_blocked_sp = NULL;\n\n#  ifdef IA64\nSTATIC ptr_t GC_blocked_register_sp = NULL;\n#  endif\n\nGC_INNER struct GC_traced_stack_sect_s *GC_traced_stack_sect = NULL;\n\n/* This is nearly the same as in pthread_support.c.   */\nGC_ATTR_NOINLINE\nGC_API void *GC_CALL\nGC_call_with_gc_active(GC_fn_type fn, void *client_data)\n{\n  struct GC_traced_stack_sect_s stacksect;\n  GC_ASSERT(GC_is_initialized);\n\n  /* Adjust our stack bottom pointer (this could happen if    */\n  /* GC_get_main_stack_base() is unimplemented or broken for  */\n  /* the platform).  Note: stacksect variable is reused here. */\n  STORE_APPROX_SP_TO(*(volatile ptr_t *)&stacksect.saved_stack_ptr);\n  if (HOTTER_THAN(GC_stackbottom, stacksect.saved_stack_ptr))\n    GC_stackbottom = stacksect.saved_stack_ptr;\n\n  if (GC_blocked_sp == NULL) {\n    /* We are not inside GC_do_blocking() - do nothing more.  */\n    client_data = (*(GC_fn_type volatile *)&fn)(client_data);\n    /* Prevent treating the above as a tail call.     */\n    GC_noop1(COVERT_DATAFLOW(ADDR(&stacksect)));\n    return client_data; /* result */\n  }\n\n  /* Setup new \"stack section\".       */\n  stacksect.saved_stack_ptr = GC_blocked_sp;\n#  ifdef IA64\n  /* This is the same as in GC_call_with_stack_base().      */\n  stacksect.backing_store_end = GC_save_regs_in_stack();\n  /* Unnecessarily flushes register stack,          */\n  /* but that probably doesn't hurt.                */\n  stacksect.saved_backing_store_ptr = GC_blocked_register_sp;\n#  endif\n  stacksect.prev = GC_traced_stack_sect;\n  GC_blocked_sp = NULL;\n  GC_traced_stack_sect = &stacksect;\n\n  client_data = (*(GC_fn_type volatile *)&fn)(client_data);\n  GC_ASSERT(GC_blocked_sp == NULL);\n  GC_ASSERT(GC_traced_stack_sect == &stacksect);\n\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(GC_traced_stack_sect);\n  GC_noop1_ptr(GC_blocked_sp);\n#  endif\n  /* Restore original \"stack section\".        */\n  GC_traced_stack_sect = stacksect.prev;\n#  ifdef IA64\n  GC_blocked_register_sp = stacksect.saved_backing_store_ptr;\n#  endif\n  GC_blocked_sp = stacksect.saved_stack_ptr;\n\n  return client_data; /* result */\n}\n\n/* This is nearly the same as in pthread_support.c.   */\nSTATIC void\nGC_do_blocking_inner(ptr_t data, void *context)\n{\n  UNUSED_ARG(context);\n  GC_ASSERT(GC_is_initialized);\n  GC_ASSERT(GC_blocked_sp == NULL);\n#  ifdef SPARC\n  GC_blocked_sp = GC_save_regs_in_stack();\n#  else\n  GC_blocked_sp = GC_approx_sp();\n#    ifdef IA64\n  GC_blocked_register_sp = GC_save_regs_in_stack();\n#    endif\n#  endif\n\n  ((struct blocking_data *)data)->client_data /* result */\n      = ((struct blocking_data *)data)\n            ->fn(((struct blocking_data *)data)->client_data);\n\n  GC_ASSERT(GC_blocked_sp != NULL);\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(GC_blocked_sp);\n#  endif\n  GC_blocked_sp = NULL;\n}\n\nGC_API void GC_CALL\nGC_set_stackbottom(void *gc_thread_handle, const struct GC_stack_base *sb)\n{\n  GC_ASSERT(sb->mem_base != NULL);\n  GC_ASSERT(NULL == gc_thread_handle || &GC_stackbottom == gc_thread_handle);\n  GC_ASSERT(NULL == GC_blocked_sp\n            && NULL == GC_traced_stack_sect); /* for now */\n  UNUSED_ARG(gc_thread_handle);\n\n  GC_stackbottom = (char *)sb->mem_base;\n#  ifdef IA64\n  GC_register_stackbottom = (ptr_t)sb->reg_base;\n#  endif\n}\n\nGC_API void *GC_CALL\nGC_get_my_stackbottom(struct GC_stack_base *sb)\n{\n  GC_ASSERT(GC_is_initialized);\n  sb->mem_base = GC_stackbottom;\n#  ifdef IA64\n  sb->reg_base = GC_register_stackbottom;\n#  elif defined(E2K)\n  sb->reg_base = NULL;\n#  endif\n  return &GC_stackbottom; /* gc_thread_handle */\n}\n\n#endif /* !THREADS */\n\nGC_API void *GC_CALL\nGC_do_blocking(GC_fn_type fn, void *client_data)\n{\n  struct blocking_data my_data;\n\n  my_data.fn = fn;\n  my_data.client_data = client_data;\n  GC_with_callee_saves_pushed(GC_do_blocking_inner, (ptr_t)(&my_data));\n  return my_data.client_data; /* result */\n}\n\n#if !defined(NO_DEBUGGING)\nGC_API void GC_CALL\nGC_dump(void)\n{\n  READER_LOCK();\n  GC_dump_named(NULL);\n  READER_UNLOCK();\n}\n\nGC_API void GC_CALL\nGC_dump_named(const char *name)\n{\n#  ifndef NO_CLOCK\n  CLOCK_TYPE current_time;\n\n  GET_TIME(current_time);\n#  endif\n  if (name != NULL) {\n    GC_printf(\"\\n***GC Dump %s\\n\", name);\n  } else {\n    GC_printf(\"\\n***GC Dump collection #%lu\\n\", (unsigned long)GC_gc_no);\n  }\n#  ifndef NO_CLOCK\n  /* Note that the time is wrapped in ~49 days if sizeof(long)==4.  */\n  GC_printf(\"Time since GC init: %lu ms\\n\",\n            MS_TIME_DIFF(current_time, GC_init_time));\n#  endif\n\n  GC_printf(\"\\n***Static roots:\\n\");\n  GC_print_static_roots();\n  GC_printf(\"\\n***Heap sections:\\n\");\n  GC_print_heap_sects();\n  GC_printf(\"\\n***Free blocks:\\n\");\n  GC_print_hblkfreelist();\n  GC_printf(\"\\n***Blocks in use:\\n\");\n  GC_print_block_list();\n#  ifndef GC_NO_FINALIZATION\n  GC_dump_finalization();\n#  endif\n}\n#endif /* !NO_DEBUGGING */\n\nGC_API GC_word GC_CALL\nGC_get_memory_use(void)\n{\n  word bytes;\n\n  READER_LOCK();\n  GC_ASSERT(GC_heapsize >= GC_large_free_bytes);\n  bytes = GC_heapsize - GC_large_free_bytes;\n  READER_UNLOCK();\n  return bytes;\n}\n\n/* Getter functions for the public Read-only variables.                 */\n\nGC_API GC_word GC_CALL\nGC_get_gc_no(void)\n{\n  return GC_gc_no;\n}\n\n#ifndef PARALLEL_MARK\nGC_API void GC_CALL\nGC_set_markers_count(unsigned markers)\n{\n  UNUSED_ARG(markers);\n}\n#endif\n\nGC_API int GC_CALL\nGC_get_parallel(void)\n{\n#ifdef THREADS\n  return GC_parallel;\n#else\n  return 0;\n#endif\n}\n\n/* Setter and getter functions for the public R/W function variables.   */\n/* These functions are synchronized (like GC_set_warn_proc() and        */\n/* GC_get_warn_proc()).                                                 */\n\nGC_API void GC_CALL\nGC_set_oom_fn(GC_oom_func fn)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fn));\n  LOCK();\n  GC_oom_fn = fn;\n  UNLOCK();\n}\n\nGC_API GC_oom_func GC_CALL\nGC_get_oom_fn(void)\n{\n  GC_oom_func fn;\n\n  READER_LOCK();\n  fn = GC_oom_fn;\n  READER_UNLOCK();\n  return fn;\n}\n\nGC_API void GC_CALL\nGC_set_on_heap_resize(GC_on_heap_resize_proc fn)\n{\n  /* fn may be 0 (means no event notifier). */\n  LOCK();\n  GC_on_heap_resize = fn;\n  UNLOCK();\n}\n\nGC_API GC_on_heap_resize_proc GC_CALL\nGC_get_on_heap_resize(void)\n{\n  GC_on_heap_resize_proc fn;\n\n  READER_LOCK();\n  fn = GC_on_heap_resize;\n  READER_UNLOCK();\n  return fn;\n}\n\nGC_API void GC_CALL\nGC_set_finalizer_notifier(GC_finalizer_notifier_proc fn)\n{\n  /* fn may be 0 (means no finalizer notifier). */\n  LOCK();\n  GC_finalizer_notifier = fn;\n  UNLOCK();\n}\n\nGC_API GC_finalizer_notifier_proc GC_CALL\nGC_get_finalizer_notifier(void)\n{\n  GC_finalizer_notifier_proc fn;\n\n  READER_LOCK();\n  fn = GC_finalizer_notifier;\n  READER_UNLOCK();\n  return fn;\n}\n\n/* Setter and getter functions for the public numeric R/W variables.    */\n/* It is safe to call these functions even before GC_INIT().            */\n/* These functions are unsynchronized and, if called after GC_INIT(),   */\n/* should be typically invoked inside the context of                    */\n/* GC_call_with_alloc_lock() (or GC_call_with_reader_lock() in case of  */\n/* the getters) to prevent data race (unless it is guaranteed the       */\n/* collector is not multi-threaded at that execution point).            */\n\nGC_API void GC_CALL\nGC_set_find_leak(int value)\n{\n  /* value is of boolean type. */\n  GC_find_leak = value;\n}\n\nGC_API int GC_CALL\nGC_get_find_leak(void)\n{\n  return GC_find_leak;\n}\n\nGC_API void GC_CALL\nGC_set_all_interior_pointers(int value)\n{\n  GC_all_interior_pointers = value ? 1 : 0;\n  if (GC_is_initialized) {\n    /* It is not recommended to change GC_all_interior_pointers value */\n    /* after GC is initialized but it seems GC could work correctly   */\n    /* even after switching the mode.                                 */\n    LOCK();\n    /* Note: this resets manual offsets as well.      */\n    GC_initialize_offsets();\n\n    if (!GC_all_interior_pointers)\n      GC_bl_init_no_interiors();\n    UNLOCK();\n  }\n}\n\nGC_API int GC_CALL\nGC_get_all_interior_pointers(void)\n{\n  return GC_all_interior_pointers;\n}\n\nGC_API void GC_CALL\nGC_set_finalize_on_demand(int value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT(value != -1);\n  /* value is of boolean type. */\n  GC_finalize_on_demand = value;\n}\n\nGC_API int GC_CALL\nGC_get_finalize_on_demand(void)\n{\n  return GC_finalize_on_demand;\n}\n\nGC_API void GC_CALL\nGC_set_java_finalization(int value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT(value != -1);\n  /* value is of boolean type. */\n  GC_java_finalization = value;\n}\n\nGC_API int GC_CALL\nGC_get_java_finalization(void)\n{\n  return GC_java_finalization;\n}\n\nGC_API void GC_CALL\nGC_set_dont_expand(int value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT(value != -1);\n  /* value is of boolean type. */\n  GC_dont_expand = value;\n}\n\nGC_API int GC_CALL\nGC_get_dont_expand(void)\n{\n  return GC_dont_expand;\n}\n\nGC_API void GC_CALL\nGC_set_no_dls(int value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT(value != -1);\n  /* value is of boolean type. */\n  GC_no_dls = value;\n}\n\nGC_API int GC_CALL\nGC_get_no_dls(void)\n{\n  return GC_no_dls;\n}\n\nGC_API void GC_CALL\nGC_set_non_gc_bytes(GC_word value)\n{\n  GC_non_gc_bytes = value;\n}\n\nGC_API GC_word GC_CALL\nGC_get_non_gc_bytes(void)\n{\n  return GC_non_gc_bytes;\n}\n\nGC_API void GC_CALL\nGC_set_free_space_divisor(GC_word value)\n{\n  GC_ASSERT(value > 0);\n  GC_free_space_divisor = value;\n}\n\nGC_API GC_word GC_CALL\nGC_get_free_space_divisor(void)\n{\n  return GC_free_space_divisor;\n}\n\nGC_API void GC_CALL\nGC_set_max_retries(GC_word value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT((GC_signed_word)value != -1);\n  GC_max_retries = value;\n}\n\nGC_API GC_word GC_CALL\nGC_get_max_retries(void)\n{\n  return GC_max_retries;\n}\n\nGC_API void GC_CALL\nGC_set_dont_precollect(int value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT(value != -1);\n  /* value is of boolean type. */\n  GC_dont_precollect = value;\n}\n\nGC_API int GC_CALL\nGC_get_dont_precollect(void)\n{\n  return GC_dont_precollect;\n}\n\nGC_API void GC_CALL\nGC_set_full_freq(int value)\n{\n  GC_ASSERT(value >= 0);\n  GC_full_freq = value;\n}\n\nGC_API int GC_CALL\nGC_get_full_freq(void)\n{\n  return GC_full_freq;\n}\n\nGC_API void GC_CALL\nGC_set_time_limit(unsigned long value)\n{\n  /* Note: -1 was used to retrieve old value in gc-7.2.       */\n  GC_ASSERT((long)value != -1L);\n  GC_time_limit = value;\n}\n\nGC_API unsigned long GC_CALL\nGC_get_time_limit(void)\n{\n  return GC_time_limit;\n}\n\nGC_API void GC_CALL\nGC_set_force_unmap_on_gcollect(int value)\n{\n  GC_force_unmap_on_gcollect = (GC_bool)value;\n}\n\nGC_API int GC_CALL\nGC_get_force_unmap_on_gcollect(void)\n{\n  return (int)GC_force_unmap_on_gcollect;\n}\n\nGC_API void GC_CALL\nGC_abort_on_oom(void)\n{\n  GC_err_printf(\"Insufficient memory for the allocation\\n\");\n  EXIT();\n}\n\nGC_API size_t GC_CALL\nGC_get_hblk_size(void)\n{\n  return (size_t)HBLKSIZE;\n}\n"
        },
        {
          "name": "new_hblk.c",
          "type": "blob",
          "size": 5.111328125,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 2000 by Hewlett-Packard Company.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/* This file contains the functions:    */\n/* - ptr_t GC_build_flXXX(h, old_fl);   */\n/* - void GC_new_hblk(size, kind);      */\n\n#ifndef SMALL_CONFIG\n/* Build a free list for two-pointer cleared objects inside the given */\n/* block.  Set the last link to be ofl.  Return a pointer to the      */\n/* first free-list entry.                                             */\nSTATIC ptr_t\nGC_build_fl_clear2(struct hblk *h, ptr_t ofl)\n{\n  ptr_t *p = (ptr_t *)h->hb_body;\n  ptr_t plim = (ptr_t)(h + 1);\n\n  p[0] = ofl;\n  p[1] = NULL;\n  p[2] = (ptr_t)p;\n  p[3] = NULL;\n  for (p += 4; ADDR_LT((ptr_t)p, plim); p += 4) {\n    p[0] = (ptr_t)(p - 2);\n    p[1] = NULL;\n    p[2] = (ptr_t)p;\n    p[3] = NULL;\n  }\n  return (ptr_t)(p - 2);\n}\n\n/* The same as above but uncleared objects.   */\nSTATIC ptr_t\nGC_build_fl2(struct hblk *h, ptr_t ofl)\n{\n  ptr_t *p = (ptr_t *)h->hb_body;\n  ptr_t plim = (ptr_t)(h + 1);\n\n  p[0] = ofl;\n  p[2] = (ptr_t)p;\n  for (p += 4; ADDR_LT((ptr_t)p, plim); p += 4) {\n    p[0] = (ptr_t)(p - 2);\n    p[2] = (ptr_t)p;\n  }\n  return (ptr_t)(p - 2);\n}\n\n/* The same as above but for four-pointer cleared objects.        */\nSTATIC ptr_t\nGC_build_fl_clear4(struct hblk *h, ptr_t ofl)\n{\n  ptr_t *p = (ptr_t *)h->hb_body;\n  ptr_t plim = (ptr_t)(h + 1);\n\n  p[0] = ofl;\n  p[1] = NULL;\n  p[2] = NULL;\n  p[3] = NULL;\n  for (p += 4; ADDR_LT((ptr_t)p, plim); p += 4) {\n    GC_PREFETCH_FOR_WRITE((ptr_t)(p + 64));\n    p[0] = (ptr_t)(p - 4);\n    p[1] = NULL;\n    CLEAR_DOUBLE(p + 2);\n  }\n  return (ptr_t)(p - 4);\n}\n\n/* The same as GC_build_fl_clear4() but uncleared objects.            */\nSTATIC ptr_t\nGC_build_fl4(struct hblk *h, ptr_t ofl)\n{\n  ptr_t *p = (ptr_t *)h->hb_body;\n  ptr_t plim = (ptr_t)(h + 1);\n\n  p[0] = ofl;\n  p[4] = (ptr_t)p;\n  /* Unroll the loop by 2.    */\n  for (p += 8; ADDR_LT((ptr_t)p, plim); p += 8) {\n    GC_PREFETCH_FOR_WRITE((ptr_t)(p + 64));\n    p[0] = (ptr_t)(p - 4);\n    p[4] = (ptr_t)p;\n  }\n  return (ptr_t)(p - 4);\n}\n#endif /* !SMALL_CONFIG */\n\nGC_INNER ptr_t\nGC_build_fl(struct hblk *h, ptr_t list, size_t lg, GC_bool clear)\n{\n  ptr_t *p, *prev;\n  ptr_t plim; /* points to last object in new hblk */\n  size_t lpw = GRANULES_TO_PTRS(lg);\n\n  /* Do a few prefetches here, just because it's cheap.         */\n  /* If we were more serious about it, these should go inside   */\n  /* the loops.  But write prefetches usually don't seem to     */\n  /* matter much.                                               */\n  GC_PREFETCH_FOR_WRITE((ptr_t)h);\n  GC_PREFETCH_FOR_WRITE((ptr_t)h + 128);\n  GC_PREFETCH_FOR_WRITE((ptr_t)h + 256);\n  GC_PREFETCH_FOR_WRITE((ptr_t)h + 378);\n#ifndef SMALL_CONFIG\n  /* Handle small objects sizes more efficiently.  For larger objects */\n  /* the difference is less significant.                              */\n  switch (lpw) {\n  case 2:\n    if (clear) {\n      return GC_build_fl_clear2(h, list);\n    } else {\n      return GC_build_fl2(h, list);\n    }\n  case 4:\n    if (clear) {\n      return GC_build_fl_clear4(h, list);\n    } else {\n      return GC_build_fl4(h, list);\n    }\n  default:\n    break;\n  }\n#endif /* !SMALL_CONFIG */\n\n  /* Clear the page if necessary. */\n  if (clear)\n    BZERO(h, HBLKSIZE);\n\n  /* Add objects to free list. */\n  prev = (ptr_t *)h->hb_body; /* one object behind p */\n\n  /* The last place for the last object to start.       */\n  plim = (ptr_t)h + HBLKSIZE - lpw * sizeof(ptr_t);\n\n  /* Make a list of all objects in *h with head as last object. */\n  for (p = prev + lpw; ADDR_GE(plim, (ptr_t)p); p += lpw) {\n    /* current object's link points to last object */\n    obj_link(p) = (ptr_t)prev;\n    prev = p;\n  }\n  p -= lpw;\n  /* p now points to the last object.   */\n\n  /* Put p (which is now head of list of objects in *h) as first    */\n  /* pointer in the appropriate free list for this size.            */\n  *(ptr_t *)h = list;\n  return (ptr_t)p;\n}\n\nGC_INNER void\nGC_new_hblk(size_t lg, int k)\n{\n  struct hblk *h; /* the new heap block */\n  size_t lb_adjusted = GRANULES_TO_BYTES(lg);\n\n  GC_STATIC_ASSERT(sizeof(struct hblk) == HBLKSIZE);\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Allocate a new heap block. */\n  h = GC_allochblk(lb_adjusted, k, 0 /* flags */, 0 /* align_m1 */);\n  if (EXPECT(NULL == h, FALSE)) {\n    /* Out of memory.   */\n    return;\n  }\n\n  /* Mark all objects if appropriate. */\n  if (IS_UNCOLLECTABLE(k))\n    GC_set_hdr_marks(HDR(h));\n\n  /* Build the free list.       */\n  GC_obj_kinds[k].ok_freelist[lg]\n      = GC_build_fl(h, (ptr_t)GC_obj_kinds[k].ok_freelist[lg], lg,\n                    GC_debugging_started || GC_obj_kinds[k].ok_init);\n}\n"
        },
        {
          "name": "obj_map.c",
          "type": "blob",
          "size": 3.083984375,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991, 1992 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1999-2001 by Hewlett-Packard Company. All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n/* Routines for maintaining maps describing heap block\n * layouts for various object sizes.  Allows fast pointer validity checks\n * and fast location of object start locations on machines (such as SPARC)\n * with slow division.\n */\n\n/* Consider pointers that are offset bytes displaced from the beginning */\n/* of an object to be valid.                                            */\n\nGC_API void GC_CALL\nGC_register_displacement(size_t offset)\n{\n  LOCK();\n  GC_register_displacement_inner(offset);\n  UNLOCK();\n}\n\nGC_INNER void\nGC_register_displacement_inner(size_t offset)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (offset >= VALID_OFFSET_SZ) {\n    ABORT(\"Bad argument to GC_register_displacement\");\n  }\n  if (!GC_valid_offsets[offset]) {\n    GC_valid_offsets[offset] = TRUE;\n    GC_modws_valid_offsets[offset % sizeof(ptr_t)] = TRUE;\n  }\n}\n\n#ifndef MARK_BIT_PER_OBJ\nGC_INNER GC_bool\nGC_add_map_entry(size_t lg)\n{\n  size_t displ;\n  hb_map_entry_t *new_map;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Ensure displ % lg fits into hb_map_entry_t.  Note: the maximum   */\n  /* value is computed in this way to avoid compiler complains about  */\n  /* constant truncation or expression overflow.                      */\n  GC_STATIC_ASSERT(\n      MAXOBJGRANULES - 1\n      <= (~(size_t)0 >> ((sizeof(size_t) - sizeof(hb_map_entry_t)) * 8)));\n\n  if (lg > MAXOBJGRANULES)\n    lg = 0;\n  if (EXPECT(GC_obj_map[lg] != NULL, TRUE))\n    return TRUE;\n\n  new_map = (hb_map_entry_t *)GC_scratch_alloc(OBJ_MAP_LEN\n                                               * sizeof(hb_map_entry_t));\n  if (EXPECT(NULL == new_map, FALSE))\n    return FALSE;\n\n  GC_COND_LOG_PRINTF(\"Adding block map for size of %u granules (%u bytes)\\n\",\n                     (unsigned)lg, (unsigned)GRANULES_TO_BYTES(lg));\n  if (0 == lg) {\n    for (displ = 0; displ < OBJ_MAP_LEN; displ++) {\n      /* Set to a nonzero to get us out of the marker fast path.  */\n      new_map[displ] = 1;\n    }\n  } else {\n    for (displ = 0; displ < OBJ_MAP_LEN; displ++) {\n      new_map[displ] = (hb_map_entry_t)(displ % lg);\n    }\n  }\n  GC_obj_map[lg] = new_map;\n  return TRUE;\n}\n#endif /* !MARK_BIT_PER_OBJ */\n\nGC_INNER void\nGC_initialize_offsets(void)\n{\n  size_t i;\n\n  if (GC_all_interior_pointers) {\n    for (i = 0; i < VALID_OFFSET_SZ; ++i)\n      GC_valid_offsets[i] = TRUE;\n  } else {\n    BZERO(GC_valid_offsets, sizeof(GC_valid_offsets));\n    for (i = 0; i < sizeof(ptr_t); ++i)\n      GC_modws_valid_offsets[i] = FALSE;\n  }\n}\n"
        },
        {
          "name": "os_dep.c",
          "type": "blob",
          "size": 179.599609375,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1999 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#if (defined(MPROTECT_VDB) && !defined(MSWIN32) && !defined(MSWINCE)) \\\n    || (defined(SOLARIS) && defined(THREADS)) || defined(OPENBSD)\n#  include <signal.h>\n#endif\n\n#if defined(UNIX_LIKE) || defined(CYGWIN32) || defined(NACL) \\\n    || defined(SYMBIAN)\n#  include <fcntl.h>\n#endif\n\n#ifdef LINUX\n#  include <ctype.h>\n#endif\n\n/* Blatantly OS dependent routines, except for those that are related   */\n/* to dynamic loading.                                                  */\n\n#ifdef IRIX5\n#  include <malloc.h> /* for locking */\n#  include <sys/uio.h>\n#endif\n\n#if defined(MMAP_SUPPORTED) || defined(ADD_HEAP_GUARD_PAGES)\n#  if defined(USE_MUNMAP) && !defined(USE_MMAP) && !defined(CPPCHECK)\n#    error Invalid config: USE_MUNMAP requires USE_MMAP\n#  endif\n#  include <sys/mman.h>\n#  include <sys/stat.h>\n#endif\n\n#if defined(LINUX) && defined(SPECIFIC_MAIN_STACKBOTTOM)        \\\n    || defined(ADD_HEAP_GUARD_PAGES) || defined(MMAP_SUPPORTED) \\\n    || defined(NEED_PROC_MAPS)\n#  include <errno.h>\n#endif\n\n#if defined(DARWIN) && !defined(DYNAMIC_LOADING) \\\n    && !defined(GC_DONT_REGISTER_MAIN_STATIC_DATA)\n/* for get_etext and friends */\n#  include <mach-o/getsect.h>\n#endif\n\n#ifdef DJGPP\n/* Apparently necessary for djgpp 2.01.  May cause problems with      */\n/* other versions.                                                    */\ntypedef long unsigned int caddr_t;\n#endif\n\n#if !defined(NO_EXECUTE_PERMISSION)\nSTATIC GC_bool GC_pages_executable = TRUE;\n#else\nSTATIC GC_bool GC_pages_executable = FALSE;\n#endif\n\n/* Note: it is undefined later on GC_pages_executable real use. */\n#define IGNORE_PAGES_EXECUTABLE 1\n\n#if ((defined(LINUX) && defined(SPECIFIC_MAIN_STACKBOTTOM)                  \\\n      || defined(NEED_PROC_MAPS) || defined(PROC_VDB) || defined(SOFT_VDB)) \\\n     && !defined(PROC_READ))                                                \\\n    || defined(CPPCHECK)\n/* Note: should probably call the real read, if read is wrapped.  */\n#  define PROC_READ read\n#endif\n\n#if defined(LINUX) && defined(SPECIFIC_MAIN_STACKBOTTOM) \\\n    || defined(NEED_PROC_MAPS)\n/* Repeatedly perform a read call until the buffer is filled  */\n/* up, or we encounter EOF or an error.                       */\nSTATIC ssize_t\nGC_repeat_read(int f, char *buf, size_t count)\n{\n  size_t num_read = 0;\n\n  ASSERT_CANCEL_DISABLED();\n  while (num_read < count) {\n    ssize_t result = PROC_READ(f, buf + num_read, count - num_read);\n\n    if (result < 0)\n      return result;\n    if (0 == result)\n      break;\n#  ifdef LINT2\n    if ((size_t)result > count - num_read)\n      ABORT(\"read() result cannot be bigger than requested length\");\n#  endif\n    num_read += (size_t)result;\n  }\n  return num_read;\n}\n#endif /* LINUX && SPECIFIC_MAIN_STACKBOTTOM || NEED_PROC_MAPS */\n\n#ifdef NEED_PROC_MAPS\n/* We need to parse /proc/self/maps, either to find dynamic libraries,  */\n/* and/or to find the register backing store base (IA64).  Do it once   */\n/* here.                                                                */\n\n#  ifdef THREADS\n/* Determine the length of a file by incrementally reading it into a  */\n/* buffer.  This would be silly to use it on a file supporting lseek, */\n/* but Linux /proc files usually do not.                              */\n/* As of Linux 4.15.0, lseek(SEEK_END) fails for /proc/self/maps.     */\nSTATIC size_t\nGC_get_file_len(int f)\n{\n  size_t total = 0;\n#    define GET_FILE_LEN_BUF_SZ 500\n  char buf[GET_FILE_LEN_BUF_SZ];\n\n  ASSERT_CANCEL_DISABLED();\n  for (;;) {\n    ssize_t result = PROC_READ(f, buf, sizeof(buf));\n\n    if (result < 0) {\n      /* An error has occurred.       */\n      return 0;\n    }\n    if (0 == result)\n      break;\n#    ifdef LINT2\n    if ((size_t)result >= GC_SIZE_MAX - total)\n      ABORT(\"Too big file is passed to GC_get_file_len\");\n#    endif\n    total += (size_t)result;\n  }\n  return total;\n}\n\nSTATIC size_t\nGC_get_maps_len(void)\n{\n  int f = open(\"/proc/self/maps\", O_RDONLY);\n  size_t result;\n\n  if (f < 0) {\n    /* Treat missing file as empty.   */\n    return 0;\n  }\n  result = GC_get_file_len(f);\n  close(f);\n  return result;\n}\n#  endif /* THREADS */\n\n/* Copy the content of /proc/self/maps to a buffer in our address       */\n/* space.  Return the address of the buffer.                            */\nGC_INNER const char *\nGC_get_maps(void)\n{\n  ssize_t result;\n  static char *maps_buf = NULL;\n  static size_t maps_buf_sz = 1;\n  size_t maps_size;\n#  ifdef THREADS\n  size_t old_maps_size = 0;\n#  endif\n\n  /* The buffer is essentially static, so there must be a single client. */\n  GC_ASSERT(I_HOLD_LOCK());\n\n  /* Note that in the presence of threads, the maps file can  */\n  /* essentially shrink asynchronously and unexpectedly as    */\n  /* threads that we already think of as dead release their   */\n  /* stacks.  And there is no easy way to read the entire     */\n  /* file atomically.  This is arguably a misfeature of the   */\n  /* /proc/self/maps interface.                               */\n  /* Since we expect the file can grow asynchronously in rare */\n  /* cases, it should suffice to first determine              */\n  /* the size (using read), and then to reread the file.      */\n  /* If the size is inconsistent we have to retry.            */\n  /* This only matters with threads enabled, and if we use    */\n  /* this to locate roots (not the default).                  */\n\n#  ifdef THREADS\n  /* Determine the initial size of /proc/self/maps.       */\n  maps_size = GC_get_maps_len();\n  if (0 == maps_size)\n    ABORT(\"Cannot determine length of /proc/self/maps\");\n#  else\n  maps_size = 4000; /* Guess */\n#  endif\n\n  /* Read /proc/self/maps, growing maps_buf as necessary.     */\n  /* Note that we may not allocate conventionally, and        */\n  /* thus can't use stdio.                                    */\n  do {\n    int f;\n\n    while (maps_size >= maps_buf_sz) {\n#  ifdef LINT2\n      /* Workaround passing tainted maps_buf to a tainted sink. */\n      GC_noop1_ptr(maps_buf);\n#  else\n      GC_scratch_recycle_no_gww(maps_buf, maps_buf_sz);\n#  endif\n      /* Grow only by powers of 2, since we leak \"too small\" buffers.*/\n      while (maps_size >= maps_buf_sz)\n        maps_buf_sz *= 2;\n      maps_buf = GC_scratch_alloc(maps_buf_sz);\n      if (NULL == maps_buf)\n        ABORT_ARG1(\"Insufficient space for /proc/self/maps buffer\",\n                   \", %lu bytes requested\", (unsigned long)maps_buf_sz);\n#  ifdef THREADS\n      /* Recompute initial length, since we allocated.        */\n      /* This can only happen a few times per program         */\n      /* execution.                                           */\n      maps_size = GC_get_maps_len();\n      if (0 == maps_size)\n        ABORT(\"Cannot determine length of /proc/self/maps\");\n#  endif\n    }\n    GC_ASSERT(maps_buf_sz >= maps_size + 1);\n    f = open(\"/proc/self/maps\", O_RDONLY);\n    if (-1 == f)\n      ABORT_ARG1(\"Cannot open /proc/self/maps\", \": errno= %d\", errno);\n#  ifdef THREADS\n    old_maps_size = maps_size;\n#  endif\n    maps_size = 0;\n    do {\n      result = GC_repeat_read(f, maps_buf, maps_buf_sz - 1);\n      if (result < 0) {\n        ABORT_ARG1(\"Failed to read /proc/self/maps\", \": errno= %d\", errno);\n      }\n      maps_size += (size_t)result;\n    } while ((size_t)result == maps_buf_sz - 1);\n    close(f);\n    if (0 == maps_size)\n      ABORT(\"Empty /proc/self/maps\");\n#  ifdef THREADS\n    if (maps_size > old_maps_size) {\n      /* This might be caused by e.g. thread creation. */\n      WARN(\"Unexpected asynchronous /proc/self/maps growth\"\n           \" (to %\" WARN_PRIuPTR \" bytes)\\n\",\n           maps_size);\n    }\n#  endif\n  } while (maps_size >= maps_buf_sz\n#  ifdef THREADS\n           || maps_size < old_maps_size\n#  endif\n  );\n  maps_buf[maps_size] = '\\0';\n  return maps_buf;\n}\n\n/*\n *  GC_parse_map_entry parses an entry from /proc/self/maps so we can\n *  locate all writable data segments that belong to shared libraries.\n *  The format of one of these entries and the fields we care about\n *  is as follows:\n *  XXXXXXXX-XXXXXXXX r-xp 00000000 30:05 260537     name of mapping...\\n\n *  ^^^^^^^^ ^^^^^^^^ ^^^^          ^^\n *  *p_start *p_end   *p_prot       *p_maj_dev\n *\n *  Note that since about august 2003 kernels, the columns no longer have\n *  fixed offsets on 64-bit kernels.  Hence we no longer rely on fixed offsets\n *  anywhere, which is safer anyway.\n */\n\n/* Assign various fields of the first line in maps_ptr to *p_start,     */\n/* *p_end, *p_prot, *p_maj_dev and *p_mapping_name.  p_mapping_name may */\n/* be NULL. *p_prot and *p_mapping_name are assigned pointers into the  */\n/* original buffer.                                                     */\n#  if defined(DYNAMIC_LOADING) && defined(USE_PROC_FOR_LIBRARIES) \\\n      || defined(IA64) || defined(INCLUDE_LINUX_THREAD_DESCR)     \\\n      || (defined(CHECK_SOFT_VDB) && defined(MPROTECT_VDB))       \\\n      || defined(REDIR_MALLOC_AND_LINUXTHREADS)\nGC_INNER const char *\nGC_parse_map_entry(const char *maps_ptr, ptr_t *p_start, ptr_t *p_end,\n                   const char **p_prot, unsigned *p_maj_dev,\n                   const char **p_mapping_name)\n{\n  const unsigned char *start_start, *end_start, *maj_dev_start;\n  const unsigned char *p; /* unsigned for isspace, isxdigit */\n\n  if (maps_ptr == NULL || *maps_ptr == '\\0') {\n    return NULL;\n  }\n\n  p = (const unsigned char *)maps_ptr;\n  while (isspace(*p))\n    ++p;\n  start_start = p;\n  GC_ASSERT(isxdigit(*start_start));\n  *p_start = (ptr_t)strtoul((const char *)start_start, (char **)&p, 16);\n  GC_ASSERT(*p == '-');\n\n  ++p;\n  end_start = p;\n  GC_ASSERT(isxdigit(*end_start));\n  *p_end = (ptr_t)strtoul((const char *)end_start, (char **)&p, 16);\n  GC_ASSERT(isspace(*p));\n\n  while (isspace(*p))\n    ++p;\n  GC_ASSERT(*p == 'r' || *p == '-');\n  *p_prot = (const char *)p;\n  /* Skip past protection field to offset field.      */\n  while (!isspace(*p))\n    ++p;\n  while (isspace(*p))\n    p++;\n  GC_ASSERT(isxdigit(*p));\n  /* Skip past offset field, which we ignore.         */\n  while (!isspace(*p))\n    ++p;\n  while (isspace(*p))\n    p++;\n  maj_dev_start = p;\n  GC_ASSERT(isxdigit(*maj_dev_start));\n  *p_maj_dev = strtoul((const char *)maj_dev_start, NULL, 16);\n\n  if (p_mapping_name != NULL) {\n    while (*p && *p != '\\n' && *p != '/' && *p != '[')\n      p++;\n    *p_mapping_name = (const char *)p;\n  }\n  while (*p && *p++ != '\\n') {\n    /* Empty. */\n  }\n  return (const char *)p;\n}\n#  endif /* REDIRECT_MALLOC || DYNAMIC_LOADING || IA64 || ... */\n\n#  if defined(IA64) || defined(INCLUDE_LINUX_THREAD_DESCR) \\\n      || (defined(CHECK_SOFT_VDB) && defined(MPROTECT_VDB))\n/* Try to read the backing store base from /proc/self/maps.           */\n/* Return the bounds of the writable mapping with a 0 major device,   */\n/* which includes the address passed as data.                         */\n/* Return FALSE if there is no such mapping.                          */\nGC_INNER GC_bool\nGC_enclosing_writable_mapping(ptr_t addr, ptr_t *startp, ptr_t *endp)\n{\n  const char *prot;\n  ptr_t my_start, my_end;\n  const char *maps_ptr;\n  unsigned maj_dev;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  maps_ptr = GC_get_maps();\n  for (;;) {\n    maps_ptr = GC_parse_map_entry(maps_ptr, &my_start, &my_end, &prot,\n                                  &maj_dev, NULL);\n    if (NULL == maps_ptr)\n      break;\n\n    if (ADDR_INSIDE(addr, my_start, my_end)) {\n      if (prot[1] != 'w' || maj_dev != 0)\n        break;\n      *startp = my_start;\n      *endp = my_end;\n      return TRUE;\n    }\n  }\n  return FALSE;\n}\n#  endif /* IA64 || INCLUDE_LINUX_THREAD_DESCR */\n\n#  ifdef REDIR_MALLOC_AND_LINUXTHREADS\n/* Find the text(code) mapping for the library whose name, after      */\n/* stripping the directory part, starts with nm.                      */\nGC_INNER GC_bool\nGC_text_mapping(const char *nm, ptr_t *startp, ptr_t *endp)\n{\n  size_t nm_len;\n  const char *prot, *map_path;\n  ptr_t my_start, my_end;\n  unsigned int maj_dev;\n  const char *maps_ptr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  maps_ptr = GC_get_maps();\n  nm_len = strlen(nm);\n  for (;;) {\n    maps_ptr = GC_parse_map_entry(maps_ptr, &my_start, &my_end, &prot,\n                                  &maj_dev, &map_path);\n    if (NULL == maps_ptr)\n      break;\n\n    if (prot[0] == 'r' && prot[1] == '-' && prot[2] == 'x') {\n      const char *p = map_path;\n\n      /* Set p to point just past last slash, if any.       */\n      while (*p != '\\0' && *p != '\\n' && *p != ' ' && *p != '\\t') {\n        ++p;\n      }\n      while (ADDR_GE((ptr_t)p, (ptr_t)map_path) && *p != '/') {\n        --p;\n      }\n      ++p;\n\n      if (strncmp(nm, p, nm_len) == 0) {\n        *startp = my_start;\n        *endp = my_end;\n        return TRUE;\n      }\n    }\n  }\n  return FALSE;\n}\n#  endif /* REDIR_MALLOC_AND_LINUXTHREADS */\n\n#  ifdef IA64\nstatic ptr_t\nbacking_store_base_from_proc(void)\n{\n  ptr_t my_start, my_end;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_enclosing_writable_mapping(GC_save_regs_in_stack(), &my_start,\n                                     &my_end)) {\n    GC_COND_LOG_PRINTF(\"Failed to find backing store base from /proc\\n\");\n    return 0;\n  }\n  return my_start;\n}\n#  endif\n\n#endif /* NEED_PROC_MAPS */\n\n#if defined(SEARCH_FOR_DATA_START)\n/* The i686 case can be handled without a search.  The Alpha case     */\n/* used to be handled differently as well, but the rules changed      */\n/* for recent Linux versions.  This seems to be the easiest way to    */\n/* cover all versions.                                                */\n\n#  if defined(LINUX) || defined(HURD)\n/* Some Linux distributions arrange to define __data_start.  Some   */\n/* define data_start as a weak symbol.  The latter is technically   */\n/* broken, since the user program may define data_start, in which   */\n/* case we lose.  Nonetheless, we try both, preferring __data_start.*/\n/* We assume gcc-compatible pragmas.                                */\nEXTERN_C_BEGIN\n#    pragma weak __data_start\n#    pragma weak data_start\nextern int __data_start[], data_start[];\nEXTERN_C_END\n#  elif defined(NETBSD)\nEXTERN_C_BEGIN\nextern char **environ;\nEXTERN_C_END\n#  endif\n\nptr_t GC_data_start = NULL;\n\nGC_INNER void\nGC_init_linux_data_start(void)\n{\n  ptr_t data_end = DATAEND;\n\n#  if (defined(LINUX) || defined(HURD)) && defined(USE_PROG_DATA_START)\n  /* Try the easy approaches first: */\n  /* However, this may lead to wrong data start value if libgc  */\n  /* code is put into a shared library (directly or indirectly) */\n  /* which is linked with -Bsymbolic-functions option.  Thus,   */\n  /* the following is not used by default.                      */\n  if (COVERT_DATAFLOW(ADDR(__data_start)) != 0) {\n    GC_data_start = (ptr_t)(__data_start);\n  } else {\n    GC_data_start = (ptr_t)(data_start);\n  }\n  if (COVERT_DATAFLOW(ADDR(GC_data_start)) != 0) {\n    if (ADDR_LT(data_end, GC_data_start))\n      ABORT_ARG2(\"Wrong __data_start/_end pair\", \": %p .. %p\",\n                 (void *)GC_data_start, (void *)data_end);\n    return;\n  }\n#    ifdef DEBUG_ADD_DEL_ROOTS\n  GC_log_printf(\"__data_start not provided\\n\");\n#    endif\n#  endif /* LINUX */\n\n  if (GC_no_dls) {\n    /* Not needed, avoids the SIGSEGV caused by       */\n    /* GC_find_limit which complicates debugging.     */\n    GC_data_start = data_end; /* set data root size to 0 */\n    return;\n  }\n\n#  ifdef NETBSD\n  /* This may need to be environ, without the underscore, for       */\n  /* some versions.                                                 */\n  GC_data_start = (ptr_t)GC_find_limit(&environ, FALSE);\n#  else\n  GC_data_start = (ptr_t)GC_find_limit(data_end, FALSE);\n#  endif\n}\n#endif /* SEARCH_FOR_DATA_START */\n\n#ifdef ECOS\n\n#  ifndef ECOS_GC_MEMORY_SIZE\n#    define ECOS_GC_MEMORY_SIZE (448 * 1024)\n#  endif /* ECOS_GC_MEMORY_SIZE */\n\n/* TODO: This is a simple way of allocating memory which is           */\n/* compatible with ECOS early releases.  Later releases use a more    */\n/* sophisticated means of allocating memory than this simple static   */\n/* allocator, but this method is at least bound to work.              */\nstatic char ecos_gc_memory[ECOS_GC_MEMORY_SIZE];\nstatic ptr_t ecos_gc_brk = ecos_gc_memory;\n\nstatic void *\ntiny_sbrk(ptrdiff_t increment)\n{\n  void *p = ecos_gc_brk;\n\n  if (ADDR_LT((ptr_t)ecos_gc_memory + sizeof(ecos_gc_memory),\n              (ptr_t)p + increment))\n    return NULL;\n  ecos_gc_brk += increment;\n  return p;\n}\n#  define sbrk tiny_sbrk\n#endif /* ECOS */\n\n#if defined(ADDRESS_SANITIZER)                         \\\n    && (defined(UNIX_LIKE) || defined(NEED_FIND_LIMIT) \\\n        || defined(MPROTECT_VDB))                      \\\n    && !defined(CUSTOM_ASAN_DEF_OPTIONS)\nEXTERN_C_BEGIN\nGC_API const char *__asan_default_options(void);\nEXTERN_C_END\n\n/* To tell ASan to allow GC to use its own SIGBUS/SEGV handlers.      */\n/* The function is exported just to be visible to ASan library.       */\nGC_API const char *\n__asan_default_options(void)\n{\n  return \"allow_user_segv_handler=1\";\n}\n#endif\n\n#ifdef OPENBSD\nstatic struct sigaction old_segv_act;\nSTATIC JMP_BUF GC_jmp_buf_openbsd;\n\nSTATIC void\nGC_fault_handler_openbsd(int sig)\n{\n  UNUSED_ARG(sig);\n  LONGJMP(GC_jmp_buf_openbsd, 1);\n}\n\nstatic volatile int firstpass;\n\n/* Return first addressable location > p or bound.    */\nSTATIC ptr_t\nGC_skip_hole_openbsd(ptr_t p, ptr_t bound)\n{\n  static volatile ptr_t result;\n  struct sigaction act;\n  size_t pgsz;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  pgsz = (size_t)sysconf(_SC_PAGESIZE);\n  GC_ASSERT(ADDR(bound) >= (word)pgsz);\n\n  act.sa_handler = GC_fault_handler_openbsd;\n  sigemptyset(&act.sa_mask);\n  act.sa_flags = SA_NODEFER | SA_RESTART;\n  /* act.sa_restorer is deprecated and should not be initialized. */\n  sigaction(SIGSEGV, &act, &old_segv_act);\n\n  firstpass = 1;\n  result = PTR_ALIGN_DOWN(p, pgsz);\n  if (SETJMP(GC_jmp_buf_openbsd) != 0 || firstpass) {\n    firstpass = 0;\n    if (ADDR_GE(result, bound - pgsz)) {\n      result = bound;\n    } else {\n      /* Notes: no overflow is expected; do not use compound          */\n      /* assignment with volatile-qualified left operand.             */\n      result = result + pgsz;\n      GC_noop1((word)(unsigned char)(*result));\n    }\n  }\n\n  sigaction(SIGSEGV, &old_segv_act, 0);\n  return result;\n}\n#endif /* OPENBSD */\n\n#ifdef OS2\n\n#  include <stddef.h>\n\n#  if !defined(__IBMC__) && !defined(__WATCOMC__) /* e.g. EMX */\n\nstruct exe_hdr {\n  unsigned short magic_number;\n  unsigned short padding[29];\n  long new_exe_offset;\n};\n\n#    define E_MAGIC(x) (x).magic_number\n#    define EMAGIC 0x5A4D\n#    define E_LFANEW(x) (x).new_exe_offset\n\nstruct e32_exe {\n  unsigned char magic_number[2];\n  unsigned char byte_order;\n  unsigned char word_order;\n  unsigned long exe_format_level;\n  unsigned short cpu;\n  unsigned short os;\n  unsigned long padding1[13];\n  unsigned long object_table_offset;\n  unsigned long object_count;\n  unsigned long padding2[31];\n};\n\n#    define E32_MAGIC1(x) (x).magic_number[0]\n#    define E32MAGIC1 'L'\n#    define E32_MAGIC2(x) (x).magic_number[1]\n#    define E32MAGIC2 'X'\n#    define E32_BORDER(x) (x).byte_order\n#    define E32LEBO 0\n#    define E32_WORDER(x) (x).word_order\n#    define E32LEWO 0\n#    define E32_CPU(x) (x).cpu\n#    define E32CPU286 1\n#    define E32_OBJTAB(x) (x).object_table_offset\n#    define E32_OBJCNT(x) (x).object_count\n\nstruct o32_obj {\n  unsigned long size;\n  unsigned long base;\n  unsigned long flags;\n  unsigned long pagemap;\n  unsigned long mapsize;\n  unsigned long reserved;\n};\n\n#    define O32_FLAGS(x) (x).flags\n#    define OBJREAD 0x0001L\n#    define OBJWRITE 0x0002L\n#    define OBJINVALID 0x0080L\n#    define O32_SIZE(x) (x).size\n#    define O32_BASE(x) (x).base\n\n#  else /* IBM's compiler */\n\n/* A kludge to get around what appears to be a header file bug.   */\n#    ifndef WORD\n#      define WORD unsigned short\n#    endif\n#    ifndef DWORD\n#      define DWORD unsigned long\n#    endif\n\n#    define EXE386 1\n#    include <exe386.h>\n#    include <newexe.h>\n\n#  endif /* __IBMC__ */\n\n#  define INCL_DOSERRORS\n#  define INCL_DOSEXCEPTIONS\n#  define INCL_DOSFILEMGR\n#  define INCL_DOSMEMMGR\n#  define INCL_DOSMISC\n#  define INCL_DOSMODULEMGR\n#  define INCL_DOSPROCESS\n#  include <os2.h>\n\n#endif /* OS2 */\n\n/* Find the page size.  */\nGC_INNER size_t GC_page_size = 0;\n#ifdef REAL_PAGESIZE_NEEDED\nGC_INNER size_t GC_real_page_size = 0;\n#endif\n\n#ifdef SOFT_VDB\nSTATIC unsigned GC_log_pagesize = 0;\n#endif\n\n#ifdef ANY_MSWIN\n\n#  ifndef VER_PLATFORM_WIN32_CE\n#    define VER_PLATFORM_WIN32_CE 3\n#  endif\n\n#  if defined(MSWINCE) && defined(THREADS)\nGC_INNER GC_bool GC_dont_query_stack_min = FALSE;\n#  endif\n\nGC_INNER SYSTEM_INFO GC_sysinfo;\n\n#  ifndef CYGWIN32\n#    define is_writable(prot)                               \\\n      ((prot) == PAGE_READWRITE || (prot) == PAGE_WRITECOPY \\\n       || (prot) == PAGE_EXECUTE_READWRITE                  \\\n       || (prot) == PAGE_EXECUTE_WRITECOPY)\n/* Return the number of bytes that are writable starting at p.      */\n/* The pointer p is assumed to be page aligned.                     */\n/* If base is not 0, *base becomes the beginning of the             */\n/* allocation region containing p.                                  */\nSTATIC word\nGC_get_writable_length(ptr_t p, ptr_t *base)\n{\n  MEMORY_BASIC_INFORMATION buf;\n  word result;\n  word protect;\n\n  result = VirtualQuery(p, &buf, sizeof(buf));\n  if (result != sizeof(buf))\n    ABORT(\"Weird VirtualQuery result\");\n  if (base != 0)\n    *base = (ptr_t)(buf.AllocationBase);\n  protect = buf.Protect & ~(word)(PAGE_GUARD | PAGE_NOCACHE);\n  if (!is_writable(protect) || buf.State != MEM_COMMIT)\n    return 0;\n  return buf.RegionSize;\n}\n\n/* Fill in the GC_stack_base structure with the stack bottom for    */\n/* this thread.  Should not acquire the allocator lock as the       */\n/* function is used by GC_DllMain.                                  */\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  ptr_t trunc_sp;\n  word size;\n\n  /* Set page size if it is not ready (so client can use this       */\n  /* function even before GC is initialized).                       */\n  if (!GC_page_size)\n    GC_setpagesize();\n\n  trunc_sp = PTR_ALIGN_DOWN(GC_approx_sp(), GC_page_size);\n  /* FIXME: This won't work if called from a deeply recursive       */\n  /* client code (and the committed stack space has grown).         */\n  size = GC_get_writable_length(trunc_sp, 0);\n  GC_ASSERT(size != 0);\n  sb->mem_base = trunc_sp + size;\n  return GC_SUCCESS;\n}\n#  else /* CYGWIN32 */\n/* An alternate version for Cygwin (adapted from Dave Korn's        */\n/* gcc version of boehm-gc).                                        */\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n#    ifdef X86_64\n  sb->mem_base = ((NT_TIB *)NtCurrentTeb())->StackBase;\n#    else\n  void *_tlsbase;\n\n  __asm__(\"movl %%fs:4, %0\" : \"=r\"(_tlsbase));\n  sb->mem_base = _tlsbase;\n#    endif\n  return GC_SUCCESS;\n}\n#  endif /* CYGWIN32 */\n#  define HAVE_GET_STACK_BASE\n\n#elif defined(OS2)\n\nstatic int\nos2_getpagesize(void)\n{\n  ULONG result[1];\n\n  if (DosQuerySysInfo(QSV_PAGE_SIZE, QSV_PAGE_SIZE, (void *)result,\n                      sizeof(ULONG))\n      != NO_ERROR) {\n    WARN(\"DosQuerySysInfo failed\\n\", 0);\n    result[0] = 4096;\n  }\n  return (int)result[0];\n}\n\n#endif /* !ANY_MSWIN && OS2 */\n\nGC_INNER void\nGC_setpagesize(void)\n{\n#ifdef ANY_MSWIN\n  GetSystemInfo(&GC_sysinfo);\n#  ifdef ALT_PAGESIZE_USED\n  /* Allocations made with mmap() are aligned to the allocation     */\n  /* granularity, which (at least on Win64) is not the same as the  */\n  /* page size.  Probably we could distinguish the allocation       */\n  /* granularity from the actual page size, but in practice there   */\n  /* is no good reason to make allocations smaller than             */\n  /* dwAllocationGranularity, so we just use it instead of the      */\n  /* actual page size here (as Cygwin itself does in many cases).   */\n  GC_page_size = (size_t)GC_sysinfo.dwAllocationGranularity;\n#    ifdef REAL_PAGESIZE_NEEDED\n  GC_real_page_size = (size_t)GC_sysinfo.dwPageSize;\n  GC_ASSERT(GC_page_size >= GC_real_page_size);\n#    endif\n#  else\n  GC_page_size = (size_t)GC_sysinfo.dwPageSize;\n#  endif\n#  if defined(MSWINCE) && !defined(_WIN32_WCE_EMULATION)\n  {\n    OSVERSIONINFO verInfo;\n    /* Check the current WinCE version.     */\n    verInfo.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);\n    if (!GetVersionEx(&verInfo))\n      ABORT(\"GetVersionEx failed\");\n    if (verInfo.dwPlatformId == VER_PLATFORM_WIN32_CE\n        && verInfo.dwMajorVersion < 6) {\n      /* Only the first 32 MB of address space belongs to the       */\n      /* current process (unless WinCE 6.0+ or emulation).          */\n      GC_sysinfo.lpMaximumApplicationAddress = (LPVOID)((word)32 << 20);\n#    ifdef THREADS\n      /* On some old WinCE versions, it's observed that           */\n      /* VirtualQuery calls don't work properly when used to      */\n      /* get thread current stack committed minimum.              */\n      if (verInfo.dwMajorVersion < 5)\n        GC_dont_query_stack_min = TRUE;\n#    endif\n    }\n  }\n#  endif\n#else\n#  ifdef ALT_PAGESIZE_USED\n#    ifdef REAL_PAGESIZE_NEEDED\n  GC_real_page_size = (size_t)GETPAGESIZE();\n#    endif\n  /* It's acceptable to fake it.    */\n  GC_page_size = HBLKSIZE;\n#  else\n  GC_page_size = (size_t)GETPAGESIZE();\n#    if !defined(CPPCHECK)\n  if (0 == GC_page_size)\n    ABORT(\"getpagesize failed\");\n#    endif\n#  endif\n#endif /* !ANY_MSWIN */\n#ifdef SOFT_VDB\n  {\n    size_t pgsize;\n    unsigned log_pgsize = 0;\n\n#  if !defined(CPPCHECK)\n    if (((GC_page_size - 1) & GC_page_size) != 0) {\n      /* Not a power of two.        */\n      ABORT(\"Invalid page size\");\n    }\n#  endif\n    for (pgsize = GC_page_size; pgsize > 1; pgsize >>= 1)\n      log_pgsize++;\n    GC_log_pagesize = log_pgsize;\n  }\n#endif\n}\n\n#ifdef EMBOX\n#  include <kernel/thread/thread_stack.h>\n#  include <pthread.h>\n\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  pthread_t self = pthread_self();\n  void *stack_addr = thread_stack_get(self);\n\n  /* TODO: use pthread_getattr_np, pthread_attr_getstack alternatively */\n#  ifdef STACK_GROWS_UP\n  sb->mem_base = stack_addr;\n#  else\n  sb->mem_base = (ptr_t)stack_addr + thread_stack_get_size(self);\n#  endif\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* EMBOX */\n\n#ifdef OS2\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  PTIB ptib; /* thread information block */\n  PPIB ppib;\n\n  if (DosGetInfoBlocks(&ptib, &ppib) != NO_ERROR) {\n    WARN(\"DosGetInfoBlocks failed\\n\", 0);\n    return GC_UNIMPLEMENTED;\n  }\n  sb->mem_base = ptib->tib_pstacklimit;\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* OS2 */\n\n#ifdef SERENITY\n#  include <serenity.h>\n\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  uintptr_t base;\n  size_t size;\n\n  if (get_stack_bounds(&base, &size) < 0) {\n    WARN(\"get_stack_bounds failed\\n\", 0);\n    return GC_UNIMPLEMENTED;\n  }\n  sb->mem_base = base + size;\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* SERENITY */\n\n#if defined(NEED_FIND_LIMIT)                                 \\\n    || (defined(UNIX_LIKE) && !defined(NO_DEBUGGING))        \\\n    || (defined(USE_PROC_FOR_LIBRARIES) && defined(THREADS)) \\\n    || (defined(WRAP_MARK_SOME) && defined(NO_SEH_AVAILABLE))\n\n#  include <signal.h>\n\n#  ifdef USE_SEGV_SIGACT\n#    ifndef OPENBSD\nstatic struct sigaction old_segv_act;\n#    endif\n#    ifdef USE_BUS_SIGACT\nstatic struct sigaction old_bus_act;\n#    endif\n#  else\nstatic GC_fault_handler_t old_segv_hand;\n#    ifdef HAVE_SIGBUS\nstatic GC_fault_handler_t old_bus_hand;\n#    endif\n#  endif /* !USE_SEGV_SIGACT */\n\nGC_INNER void\nGC_set_and_save_fault_handler(GC_fault_handler_t h)\n{\n#  ifdef USE_SEGV_SIGACT\n  struct sigaction act;\n\n  act.sa_handler = h;\n#    ifdef SIGACTION_FLAGS_NODEFER_HACK\n  /* Was necessary for Solaris 2.3 and very temporary */\n  /* NetBSD bugs.                                     */\n  act.sa_flags = SA_RESTART | SA_NODEFER;\n#    else\n  act.sa_flags = SA_RESTART;\n#    endif\n\n  (void)sigemptyset(&act.sa_mask);\n  /* act.sa_restorer is deprecated and should not be initialized. */\n#    if defined(IRIX5) && defined(THREADS)\n  /* Older versions have a bug related to retrieving and      */\n  /* and setting a handler at the same time.                  */\n  (void)sigaction(SIGSEGV, 0, &old_segv_act);\n  (void)sigaction(SIGSEGV, &act, 0);\n#    else\n  (void)sigaction(SIGSEGV, &act, &old_segv_act);\n#      ifdef USE_BUS_SIGACT\n  /* Pthreads doesn't exist under Irix 5.x, so we   */\n  /* don't have to worry in the threads case.       */\n  (void)sigaction(SIGBUS, &act, &old_bus_act);\n#      endif\n#    endif /* !IRIX5 || !THREADS */\n#  else\n  old_segv_hand = signal(SIGSEGV, h);\n#    ifdef HAVE_SIGBUS\n  old_bus_hand = signal(SIGBUS, h);\n#    endif\n#  endif /* !USE_SEGV_SIGACT */\n#  if defined(CPPCHECK) && defined(ADDRESS_SANITIZER)\n  GC_noop1((word)(GC_funcptr_uint)(&__asan_default_options));\n#  endif\n}\n#endif /* NEED_FIND_LIMIT || UNIX_LIKE || WRAP_MARK_SOME */\n\n#if defined(NEED_FIND_LIMIT)                                 \\\n    || (defined(USE_PROC_FOR_LIBRARIES) && defined(THREADS)) \\\n    || (defined(WRAP_MARK_SOME) && defined(NO_SEH_AVAILABLE))\nGC_INNER JMP_BUF GC_jmp_buf;\n\nSTATIC void\nGC_fault_handler(int sig)\n{\n  UNUSED_ARG(sig);\n  LONGJMP(GC_jmp_buf, 1);\n}\n\nGC_INNER void\nGC_setup_temporary_fault_handler(void)\n{\n  /* Handler is process-wide, so this should only happen in one   */\n  /* thread at a time.                                            */\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_set_and_save_fault_handler(GC_fault_handler);\n}\n\nGC_INNER void\nGC_reset_fault_handler(void)\n{\n#  ifdef USE_SEGV_SIGACT\n  (void)sigaction(SIGSEGV, &old_segv_act, 0);\n#    ifdef USE_BUS_SIGACT\n  (void)sigaction(SIGBUS, &old_bus_act, 0);\n#    endif\n#  else\n  (void)signal(SIGSEGV, old_segv_hand);\n#    ifdef HAVE_SIGBUS\n  (void)signal(SIGBUS, old_bus_hand);\n#    endif\n#  endif\n}\n#endif /* NEED_FIND_LIMIT || USE_PROC_FOR_LIBRARIES || WRAP_MARK_SOME */\n\n#if defined(NEED_FIND_LIMIT) \\\n    || (defined(USE_PROC_FOR_LIBRARIES) && defined(THREADS))\n#  define MIN_PAGE_SIZE 256 /* Smallest conceivable page size, in bytes. */\n\n/* Return the first non-addressable location greater than p (if up) or  */\n/* the smallest location q such that [q,p) is addressable (if not up).  */\n/* We assume that p (if up) or p-1 (if not up) is addressable.          */\nGC_ATTR_NO_SANITIZE_ADDR\nSTATIC ptr_t\nGC_find_limit_with_bound(ptr_t p, GC_bool up, ptr_t bound)\n{\n  /* This is safer if static, since otherwise it may not be       */\n  /* preserved across the longjmp.  Can safely be static since it */\n  /* is only called with the allocator lock held.                 */\n  static volatile ptr_t result;\n\n  GC_ASSERT(up ? ADDR(bound) >= MIN_PAGE_SIZE\n               : ADDR(bound) <= ~(word)MIN_PAGE_SIZE);\n  GC_ASSERT(I_HOLD_LOCK());\n  result = PTR_ALIGN_DOWN(p, MIN_PAGE_SIZE);\n  GC_setup_temporary_fault_handler();\n  if (SETJMP(GC_jmp_buf) == 0) {\n    for (;;) {\n      if (up) {\n        if (ADDR_GE(result, bound - MIN_PAGE_SIZE)) {\n          result = bound;\n          break;\n        }\n        /* Notes: no overflow is expected; do not use       */\n        /* compound assignment with volatile-qualified left */\n        /* operand.                                         */\n        result = result + MIN_PAGE_SIZE;\n      } else {\n        if (ADDR_GE(bound + MIN_PAGE_SIZE, result)) {\n          /* This is to compensate further result increment */\n          /* (we do not modify \"up\" variable since it might */\n          /* be clobbered by setjmp otherwise).             */\n          result = bound - MIN_PAGE_SIZE;\n          break;\n        }\n        /* See the notes for the \"up\" case. */\n        result = result - MIN_PAGE_SIZE;\n      }\n      GC_noop1((word)(unsigned char)(*result));\n    }\n  }\n  GC_reset_fault_handler();\n  return up ? result : result + MIN_PAGE_SIZE;\n}\n\nvoid *\nGC_find_limit(void *p, int up)\n{\n  ptr_t bound;\n\n#  ifdef CHERI_PURECAP\n  bound = (ptr_t)cheri_address_set(p, cheri_base_get(p)\n                                          + (up ? cheri_length_get(p) : 0));\n#  else\n  bound = up ? MAKE_CPTR(GC_WORD_MAX) : NULL;\n#  endif\n  return GC_find_limit_with_bound((ptr_t)p, (GC_bool)up, bound);\n}\n#endif /* NEED_FIND_LIMIT || USE_PROC_FOR_LIBRARIES */\n\n#if defined(HPUX) && defined(IA64)\n#  include <sys/param.h>\n#  include <sys/pstat.h>\n\nGC_INNER ptr_t\nGC_get_register_stack_base(void)\n{\n  struct pst_vm_status vm_status;\n\n  int i = 0;\n  while (pstat_getprocvm(&vm_status, sizeof(vm_status), 0, i++) == 1) {\n    if (vm_status.pst_type == PS_RSESTACK) {\n      return (ptr_t)vm_status.pst_vaddr;\n    }\n  }\n\n  /* Old way to get the register stack bottom.        */\n  GC_ASSERT(GC_stackbottom != NULL);\n  return PTR_ALIGN_DOWN(GC_stackbottom - BACKING_STORE_DISPLACEMENT - 1,\n                        BACKING_STORE_ALIGNMENT);\n}\n#endif /* HPUX && IA64 */\n\n#if defined(LINUX) && defined(IA64)\n#  ifdef USE_LIBC_PRIVATES\nEXTERN_C_BEGIN\n#    pragma weak __libc_ia64_register_backing_store_base\nextern ptr_t __libc_ia64_register_backing_store_base;\nEXTERN_C_END\n#  endif\n\nGC_INNER ptr_t\nGC_get_register_stack_base(void)\n{\n  ptr_t result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef USE_LIBC_PRIVATES\n  {\n    ptr_t *p_libc_ia64_register_backing_store_base\n        = &__libc_ia64_register_backing_store_base;\n\n#    ifdef CPPCHECK\n    /* Workaround a warning that the address of the global  */\n    /* symbol (which is a weak one) cannot be null.         */\n    GC_noop1_ptr(&p_libc_ia64_register_backing_store_base);\n#    endif\n    if (p_libc_ia64_register_backing_store_base != NULL\n        && __libc_ia64_register_backing_store_base != NULL) {\n      /* glibc 2.2.4 has a bug such that for dynamically linked   */\n      /* executables __libc_ia64_register_backing_store_base is   */\n      /* defined but uninitialized during constructor calls.      */\n      /* Hence we check for both nonzero address and value.       */\n      return __libc_ia64_register_backing_store_base;\n    }\n  }\n#  endif\n  result = backing_store_base_from_proc();\n  if (0 == result) {\n    /* This works better than a constant displacement heuristic.  */\n    result = (ptr_t)GC_find_limit(GC_save_regs_in_stack(), FALSE);\n  }\n  return result;\n}\n#endif /* LINUX && IA64 */\n\n#ifdef SPECIFIC_MAIN_STACKBOTTOM\n\n#  ifdef HPUX\n#    include <sys/param.h>\n#    include <sys/pstat.h>\n\nstatic ptr_t\nos_main_stackbottom(void)\n{\n  struct pst_vm_status vm_status;\n  int i = 0;\n\n  while (pstat_getprocvm(&vm_status, sizeof(vm_status), 0, i++) == 1) {\n    if (vm_status.pst_type == PS_STACK)\n      return (ptr_t)vm_status.pst_vaddr;\n  }\n\n  /* Old way to get the stack bottom. */\n#    ifdef STACK_GROWS_UP\n  return (ptr_t)GC_find_limit(GC_approx_sp(), FALSE);\n#    else\n  return (ptr_t)GC_find_limit(GC_approx_sp(), TRUE /* up */);\n#    endif\n}\n\n#  elif defined(LINUX)\n#    include <sys/stat.h>\n\n/* Number of fields preceding startstack one in /proc/self/stat.  */\n#    define STAT_SKIP 27\n\n#    ifdef USE_LIBC_PRIVATES\nEXTERN_C_BEGIN\n#      pragma weak __libc_stack_end\nextern ptr_t __libc_stack_end;\nEXTERN_C_END\n#    endif\n\nstatic ptr_t\nos_main_stackbottom(void)\n{\n  /* We read the stack bottom value from /proc/self/stat.  We do this */\n  /* using direct I/O system calls in order to avoid calling malloc   */\n  /* in case REDIRECT_MALLOC is defined.                              */\n#    define STAT_BUF_SIZE 4096\n  unsigned char stat_buf[STAT_BUF_SIZE];\n  int f;\n  word addr;\n  ssize_t i, buf_offset = 0, len;\n\n  /* First try the easy way.  This should work for glibc 2.2. */\n  /* This fails in a prelinked (\"prelink\" command) executable */\n  /* since the correct value of __libc_stack_end never        */\n  /* becomes visible to us.  The second test works around     */\n  /* this.                                                    */\n#    ifdef USE_LIBC_PRIVATES\n  ptr_t *p_libc_stack_end = &__libc_stack_end;\n\n#      ifdef CPPCHECK\n  GC_noop1_ptr(&p_libc_stack_end);\n#      endif\n  if (p_libc_stack_end != NULL && __libc_stack_end != NULL) {\n#      ifdef IA64\n    /* Some versions of glibc set the address 16 bytes too        */\n    /* low while the initialization code is running.              */\n    if ((ADDR(__libc_stack_end) & 0xfff) + 0x10 < 0x1000) {\n      return __libc_stack_end + 0x10;\n    } /* Otherwise it's not safe to add 16 bytes and we fall      */\n      /* back to using /proc.                                     */\n#      elif defined(SPARC)\n    /* Older versions of glibc for 64-bit SPARC do not set this   */\n    /* variable correctly, it gets set to either zero or one.     */\n    if (ADDR(__libc_stack_end) != 1)\n      return __libc_stack_end;\n#      else\n    return __libc_stack_end;\n#      endif\n  }\n#    endif\n\n  f = open(\"/proc/self/stat\", O_RDONLY);\n  if (-1 == f)\n    ABORT_ARG1(\"Could not open /proc/self/stat\", \": errno= %d\", errno);\n  len = GC_repeat_read(f, (char *)stat_buf, sizeof(stat_buf));\n  if (len < 0)\n    ABORT_ARG1(\"Failed to read /proc/self/stat\", \": errno= %d\", errno);\n  close(f);\n\n  /* Skip the required number of fields.  This number is hopefully    */\n  /* constant across all Linux implementations.                       */\n  for (i = 0; i < STAT_SKIP; ++i) {\n    while (buf_offset < len && isspace(stat_buf[buf_offset++])) {\n      /* empty */\n    }\n    while (buf_offset < len && !isspace(stat_buf[buf_offset++])) {\n      /* empty */\n    }\n  }\n  /* Skip spaces.     */\n  while (buf_offset < len && isspace(stat_buf[buf_offset])) {\n    buf_offset++;\n  }\n  /* Find the end of the number and cut the buffer there.     */\n  for (i = 0; buf_offset + i < len; i++) {\n    if (!isdigit(stat_buf[buf_offset + i]))\n      break;\n  }\n  if (buf_offset + i >= len)\n    ABORT(\"Could not parse /proc/self/stat\");\n  stat_buf[buf_offset + i] = '\\0';\n\n  addr = (word)STRTOULL((char *)stat_buf + buf_offset, NULL, 10);\n  if (addr < 0x100000 || addr % ALIGNMENT != 0)\n    ABORT_ARG1(\"Absurd stack bottom value\", \": 0x%lx\", (unsigned long)addr);\n  return MAKE_CPTR(addr);\n}\n\n#  elif defined(QNX)\nstatic ptr_t\nos_main_stackbottom(void)\n{\n  /* TODO: this approach is not very exact but it works for the       */\n  /* tests, at least, unlike other available heuristics.              */\n  return (ptr_t)__builtin_frame_address(0);\n}\n\n#  elif defined(FREEBSD)\n#    include <sys/sysctl.h>\n\n/* This uses an undocumented sysctl call, but at least one expert     */\n/* believes it will stay.                                             */\nstatic ptr_t\nos_main_stackbottom(void)\n{\n  int nm[2] = { CTL_KERN, KERN_USRSTACK };\n  ptr_t base;\n  size_t len = sizeof(ptr_t);\n  int r = sysctl(nm, 2, &base, &len, NULL, 0);\n\n  if (r != 0)\n    ABORT(\"Error getting main stack base\");\n  return base;\n}\n#  endif\n\n#endif /* SPECIFIC_MAIN_STACKBOTTOM */\n\n#if defined(ECOS) || defined(NOSYS)\nGC_INNER ptr_t\nGC_get_main_stack_base(void)\n{\n  return STACKBOTTOM;\n}\n#  define GET_MAIN_STACKBASE_SPECIAL\n\n#elif defined(SYMBIAN)\nEXTERN_C_BEGIN\nextern int GC_get_main_symbian_stack_base(void);\nEXTERN_C_END\n\nGC_INNER ptr_t\nGC_get_main_stack_base(void)\n{\n  return (ptr_t)GC_get_main_symbian_stack_base();\n}\n#  define GET_MAIN_STACKBASE_SPECIAL\n\n#elif defined(EMSCRIPTEN)\n#  include <emscripten/stack.h>\n\nGC_INNER ptr_t\nGC_get_main_stack_base(void)\n{\n  return (ptr_t)emscripten_stack_get_base();\n}\n#  define GET_MAIN_STACKBASE_SPECIAL\n\n#elif !defined(ANY_MSWIN) && !defined(EMBOX) && !defined(OS2)        \\\n    && !(defined(OPENBSD) && defined(THREADS)) && !defined(SERENITY) \\\n    && (!(defined(SOLARIS) && defined(THREADS)) || defined(_STRICT_STDC))\n\n#  if (defined(HAVE_PTHREAD_ATTR_GET_NP) || defined(HAVE_PTHREAD_GETATTR_NP)) \\\n      && (defined(THREADS) || defined(USE_GET_STACKBASE_FOR_MAIN))\n#    include <pthread.h>\n#    ifdef HAVE_PTHREAD_NP_H\n#      include <pthread_np.h> /* for pthread_attr_get_np() */\n#    endif\n#  elif defined(DARWIN) && !defined(NO_PTHREAD_GET_STACKADDR_NP)\n/* We could use pthread_get_stackaddr_np even in case of a  */\n/* single-threaded gclib (there is no -lpthread on Darwin). */\n#    include <pthread.h>\n#    undef STACKBOTTOM\n#    define STACKBOTTOM (ptr_t) pthread_get_stackaddr_np(pthread_self())\n#  endif\n\nGC_INNER ptr_t\nGC_get_main_stack_base(void)\n{\n  ptr_t result;\n#  if (defined(HAVE_PTHREAD_ATTR_GET_NP) || defined(HAVE_PTHREAD_GETATTR_NP)) \\\n      && (defined(USE_GET_STACKBASE_FOR_MAIN)                                 \\\n          || (defined(THREADS) && !defined(REDIRECT_MALLOC)))\n  pthread_attr_t attr;\n  void *stackaddr;\n  size_t size;\n\n#    ifdef HAVE_PTHREAD_ATTR_GET_NP\n  if (pthread_attr_init(&attr) == 0\n      && (pthread_attr_get_np(pthread_self(), &attr) == 0\n              ? TRUE\n              : (pthread_attr_destroy(&attr), FALSE)))\n#    else /* HAVE_PTHREAD_GETATTR_NP */\n  if (pthread_getattr_np(pthread_self(), &attr) == 0)\n#    endif\n  {\n    if (pthread_attr_getstack(&attr, &stackaddr, &size) == 0\n        && stackaddr != NULL) {\n      (void)pthread_attr_destroy(&attr);\n#    ifndef STACK_GROWS_UP\n      stackaddr = (char *)stackaddr + size;\n#    endif\n      return (ptr_t)stackaddr;\n    }\n    (void)pthread_attr_destroy(&attr);\n  }\n  WARN(\"pthread_getattr_np or pthread_attr_getstack failed\"\n       \" for main thread\\n\",\n       0);\n#  endif\n#  ifdef STACKBOTTOM\n  result = STACKBOTTOM;\n#  else\n#    ifdef HEURISTIC1\n#      define STACKBOTTOM_ALIGNMENT_M1 ((word)STACK_GRAN - 1)\n#      ifdef STACK_GROWS_UP\n  result = PTR_ALIGN_DOWN(GC_approx_sp(), STACKBOTTOM_ALIGNMENT_M1 + 1);\n#      else\n  result = PTR_ALIGN_UP(GC_approx_sp(), STACKBOTTOM_ALIGNMENT_M1 + 1);\n#      endif\n#    elif defined(SPECIFIC_MAIN_STACKBOTTOM)\n  result = os_main_stackbottom();\n#    elif defined(HEURISTIC2)\n  {\n    ptr_t sp = GC_approx_sp();\n\n#      ifdef STACK_GROWS_UP\n    result = (ptr_t)GC_find_limit(sp, FALSE);\n#      else\n    result = (ptr_t)GC_find_limit(sp, TRUE /* up */);\n#      endif\n#      if defined(HEURISTIC2_LIMIT) && !defined(CPPCHECK)\n    if (HOTTER_THAN(HEURISTIC2_LIMIT, result)\n        && HOTTER_THAN(sp, HEURISTIC2_LIMIT))\n      result = HEURISTIC2_LIMIT;\n#      endif\n  }\n#    elif defined(STACK_NOT_SCANNED) || defined(CPPCHECK)\n  result = NULL;\n#    else\n#      error None of HEURISTIC* and *STACKBOTTOM defined!\n#    endif\n#    if !defined(STACK_GROWS_UP) && !defined(CPPCHECK)\n  if (NULL == result)\n    result = MAKE_CPTR((GC_signed_word)(-sizeof(ptr_t)));\n#    endif\n#  endif\n#  if !defined(CPPCHECK)\n  GC_ASSERT(HOTTER_THAN(GC_approx_sp(), result));\n#  endif\n  return result;\n}\n#  define GET_MAIN_STACKBASE_SPECIAL\n#endif /* !ANY_MSWIN && !EMBOX && !OS2 && !SERENITY */\n\n#if (defined(HAVE_PTHREAD_ATTR_GET_NP) || defined(HAVE_PTHREAD_GETATTR_NP)) \\\n    && defined(THREADS) && !defined(HAVE_GET_STACK_BASE)\n#  include <pthread.h>\n#  ifdef HAVE_PTHREAD_NP_H\n#    include <pthread_np.h>\n#  endif\n\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *b)\n{\n  pthread_attr_t attr;\n  size_t size;\n\n#  ifdef HAVE_PTHREAD_ATTR_GET_NP\n  if (pthread_attr_init(&attr) != 0)\n    ABORT(\"pthread_attr_init failed\");\n  if (pthread_attr_get_np(pthread_self(), &attr) != 0) {\n    WARN(\"pthread_attr_get_np failed\\n\", 0);\n    (void)pthread_attr_destroy(&attr);\n    return GC_UNIMPLEMENTED;\n  }\n#  else /* HAVE_PTHREAD_GETATTR_NP */\n  if (pthread_getattr_np(pthread_self(), &attr) != 0) {\n    WARN(\"pthread_getattr_np failed\\n\", 0);\n    return GC_UNIMPLEMENTED;\n  }\n#  endif\n  if (pthread_attr_getstack(&attr, &b->mem_base, &size) != 0) {\n    ABORT(\"pthread_attr_getstack failed\");\n  }\n  (void)pthread_attr_destroy(&attr);\n#  ifndef STACK_GROWS_UP\n  b->mem_base = (char *)b->mem_base + size;\n#  endif\n#  ifdef IA64\n  /* We could try backing_store_base_from_proc, but that's safe     */\n  /* only if no mappings are being asynchronously created.          */\n  /* Subtracting the size from the stack base doesn't work for at   */\n  /* least the main thread.                                         */\n  LOCK();\n  {\n    IF_CANCEL(int cancel_state;)\n    ptr_t bsp;\n    ptr_t next_stack;\n\n    DISABLE_CANCEL(cancel_state);\n    bsp = GC_save_regs_in_stack();\n    next_stack = GC_greatest_stack_base_below(bsp);\n    if (NULL == next_stack) {\n      b->reg_base = GC_find_limit(bsp, FALSE);\n    } else {\n      /* Avoid walking backwards into preceding memory stack and    */\n      /* growing it.                                                */\n      b->reg_base = GC_find_limit_with_bound(bsp, FALSE, next_stack);\n    }\n    RESTORE_CANCEL(cancel_state);\n  }\n  UNLOCK();\n#  elif defined(E2K)\n  b->reg_base = NULL;\n#  endif\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* THREADS && (HAVE_PTHREAD_ATTR_GET_NP || HAVE_PTHREAD_GETATTR_NP) */\n\n#if defined(DARWIN) && defined(THREADS) \\\n    && !defined(NO_PTHREAD_GET_STACKADDR_NP)\n#  include <pthread.h>\n\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *b)\n{\n  /* pthread_get_stackaddr_np() should return stack bottom (highest   */\n  /* stack address plus 1).                                           */\n  b->mem_base = pthread_get_stackaddr_np(pthread_self());\n  GC_ASSERT(HOTTER_THAN(GC_approx_sp(), (ptr_t)b->mem_base));\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* DARWIN && THREADS && !NO_PTHREAD_GET_STACKADDR_NP */\n\n#if defined(OPENBSD) && defined(THREADS)\n#  include <pthread.h>\n#  include <pthread_np.h>\n#  include <sys/signal.h>\n\n/* Find the stack using pthread_stackseg_np(). */\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  stack_t stack;\n  if (pthread_stackseg_np(pthread_self(), &stack))\n    ABORT(\"pthread_stackseg_np(self) failed\");\n  sb->mem_base = stack.ss_sp;\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* OPENBSD && THREADS */\n\n#if defined(SOLARIS) && defined(THREADS) && !defined(_STRICT_STDC)\n\n#  include <pthread.h>\n#  include <thread.h>\n\n/* These variables are used to cache ss_sp value for the primordial   */\n/* thread (it's better not to call thr_stksegment() twice for this    */\n/* thread - see JDK bug #4352906).                                    */\n/* Note: stackbase_main_self set to zero means stackbase_main_ss_sp   */\n/* value is unset.                                                    */\nstatic pthread_t stackbase_main_self = 0;\nstatic void *stackbase_main_ss_sp = NULL;\n\n#  ifdef CAN_HANDLE_FORK\nGC_INNER void\nGC_stackbase_info_update_after_fork(void)\n{\n  if (stackbase_main_self == GC_parent_pthread_self) {\n    /* The primordial thread has forked the process. */\n    stackbase_main_self = pthread_self();\n  } else {\n    stackbase_main_self = 0;\n  }\n}\n#  endif\n\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *b)\n{\n  stack_t s;\n  pthread_t self = pthread_self();\n\n  if (self == stackbase_main_self) {\n    /* If the client calls GC_get_stack_base() from the main thread */\n    /* then just return the cached value.                           */\n    b->mem_base = stackbase_main_ss_sp;\n    GC_ASSERT(b->mem_base != NULL);\n    return GC_SUCCESS;\n  }\n\n  if (thr_stksegment(&s)) {\n    /* According to the manual, the only failure error code returned  */\n    /* is EAGAIN meaning \"the information is not available due to the */\n    /* thread is not yet completely initialized or it is an internal  */\n    /* thread\" - this shouldn't happen here.                          */\n    ABORT(\"thr_stksegment failed\");\n  }\n  /* s.ss_sp holds the pointer to the stack bottom. */\n  GC_ASSERT(HOTTER_THAN(GC_approx_sp(), (ptr_t)s.ss_sp));\n\n  if (!stackbase_main_self && thr_main() != 0) {\n    /* Cache the stack bottom pointer for the primordial thread     */\n    /* (this is done during GC_init, so there is no race).          */\n    stackbase_main_ss_sp = s.ss_sp;\n    stackbase_main_self = self;\n  }\n\n  b->mem_base = s.ss_sp;\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* SOLARIS && THREADS */\n\n#if defined(RTEMS) && defined(THREADS)\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *sb)\n{\n  sb->mem_base = rtems_get_stack_bottom();\n  return GC_SUCCESS;\n}\n#  define HAVE_GET_STACK_BASE\n#endif /* RTEMS && THREADS */\n\n#ifndef HAVE_GET_STACK_BASE\n\n#  ifdef NEED_FIND_LIMIT\n/* Retrieve the stack bottom.                                       */\n/* Using the GC_find_limit version is risky.                        */\n/* On IA64, for example, there is no guard page between the         */\n/* stack of one thread and the register backing store of the        */\n/* next.  Thus this is likely to identify way too large a           */\n/* \"stack\" and thus at least result in disastrous performance.      */\n/* TODO: Implement better strategies here. */\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *b)\n{\n  IF_CANCEL(int cancel_state;)\n\n  LOCK();\n  /* TODO: DISABLE_CANCEL may be unnecessary? */\n  DISABLE_CANCEL(cancel_state);\n#    ifdef STACK_GROWS_UP\n  b->mem_base = GC_find_limit(GC_approx_sp(), FALSE);\n#    else\n  b->mem_base = GC_find_limit(GC_approx_sp(), TRUE /* up */);\n#    endif\n#    ifdef IA64\n  b->reg_base = GC_find_limit(GC_save_regs_in_stack(), FALSE);\n#    elif defined(E2K)\n  b->reg_base = NULL;\n#    endif\n  RESTORE_CANCEL(cancel_state);\n  UNLOCK();\n  return GC_SUCCESS;\n}\n#  else /* !NEED_FIND_LIMIT */\nGC_API int GC_CALL\nGC_get_stack_base(struct GC_stack_base *b)\n{\n#    if defined(GET_MAIN_STACKBASE_SPECIAL) && !defined(THREADS) \\\n        && !defined(IA64)\n  b->mem_base = GC_get_main_stack_base();\n  return GC_SUCCESS;\n#    else\n  UNUSED_ARG(b);\n  return GC_UNIMPLEMENTED;\n#    endif\n}\n#  endif\n\n#endif /* !HAVE_GET_STACK_BASE */\n\n#ifndef GET_MAIN_STACKBASE_SPECIAL\n/* This is always called from the main thread.  Default implementation. */\nGC_INNER ptr_t\nGC_get_main_stack_base(void)\n{\n  struct GC_stack_base sb;\n\n  if (GC_get_stack_base(&sb) != GC_SUCCESS)\n    ABORT(\"GC_get_stack_base failed\");\n  GC_ASSERT(HOTTER_THAN(GC_approx_sp(), (ptr_t)sb.mem_base));\n  return (ptr_t)sb.mem_base;\n}\n#endif /* !GET_MAIN_STACKBASE_SPECIAL */\n\n/* Register static data segment(s) as roots.  If more data segments are */\n/* added later then they need to be registered at that point (as we do  */\n/* with SunOS dynamic loading), or GC_mark_roots needs to check for     */\n/* them.                                                                */\n\n#ifdef ANY_MSWIN\n\n#  if defined(GWW_VDB)\n#    ifndef MEM_WRITE_WATCH\n#      define MEM_WRITE_WATCH 0x200000\n#    endif\n#    ifndef WRITE_WATCH_FLAG_RESET\n#      define WRITE_WATCH_FLAG_RESET 1\n#    endif\n\n/* Since we can't easily check whether ULONG_PTR and SIZE_T are     */\n/* defined in Win32 basetsd.h, we define own ULONG_PTR.             */\n#    define GC_ULONG_PTR word\n\ntypedef UINT(WINAPI *GetWriteWatch_type)(DWORD, PVOID,\n                                         GC_ULONG_PTR /* SIZE_T */, PVOID *,\n                                         GC_ULONG_PTR *, PULONG);\nstatic FARPROC GetWriteWatch_func;\nstatic DWORD GetWriteWatch_alloc_flag;\n\n#    define GC_GWW_AVAILABLE() (GetWriteWatch_func != 0)\n\nstatic void\ndetect_GetWriteWatch(void)\n{\n  static GC_bool done;\n  HMODULE hK32;\n  if (done)\n    return;\n\n#    if defined(MPROTECT_VDB)\n  {\n    char *str = GETENV(\"GC_USE_GETWRITEWATCH\");\n#      if defined(GC_PREFER_MPROTECT_VDB)\n    if (NULL == str || (*str == '0' && *(str + 1) == '\\0')) {\n      /* GC_USE_GETWRITEWATCH is unset or set to \"0\".           */\n      /* Falling back to MPROTECT_VDB strategy.                 */\n      done = TRUE;\n      /* This should work as if GWW_VDB is undefined. */\n      return;\n    }\n#      else\n    if (str != NULL && *str == '0' && *(str + 1) == '\\0') {\n      /* GC_USE_GETWRITEWATCH is set \"0\".                       */\n      /* Falling back to MPROTECT_VDB strategy.                 */\n      done = TRUE;\n      return;\n    }\n#      endif\n  }\n#    endif\n\n#    if defined(MSWINRT_FLAVOR) && defined(FUNCPTR_IS_DATAPTR)\n  {\n    MEMORY_BASIC_INFORMATION memInfo;\n    SIZE_T result = VirtualQuery(CAST_THRU_UINTPTR(void *, GetProcAddress),\n                                 &memInfo, sizeof(memInfo));\n\n    if (result != sizeof(memInfo))\n      ABORT(\"Weird VirtualQuery result\");\n    hK32 = (HMODULE)memInfo.AllocationBase;\n  }\n#    else\n  hK32 = GetModuleHandle(TEXT(\"kernel32.dll\"));\n#    endif\n  if (hK32 != (HMODULE)0\n      && (GetWriteWatch_func = GetProcAddress(hK32, \"GetWriteWatch\")) != 0) {\n    void *page;\n\n    GC_ASSERT(GC_page_size != 0);\n    /* Also check whether VirtualAlloc accepts MEM_WRITE_WATCH, */\n    /* as some versions of kernel32.dll have one but not the    */\n    /* other, making the feature completely broken.             */\n    page = VirtualAlloc(NULL, GC_page_size, MEM_WRITE_WATCH | MEM_RESERVE,\n                        PAGE_READWRITE);\n    if (page != NULL) {\n      PVOID pages[16];\n      GC_ULONG_PTR count = sizeof(pages) / sizeof(PVOID);\n      DWORD page_size;\n      /* Check that it actually works.  In spite of some        */\n      /* documentation it actually seems to exist on Win2K.     */\n      /* This test may be unnecessary, but ...                  */\n      if ((*(GetWriteWatch_type)(GC_funcptr_uint)GetWriteWatch_func)(\n              WRITE_WATCH_FLAG_RESET, page, GC_page_size, pages, &count,\n              &page_size)\n          != 0) {\n        /* GetWriteWatch always fails. */\n        GetWriteWatch_func = 0;\n      } else {\n        GetWriteWatch_alloc_flag = MEM_WRITE_WATCH;\n      }\n      VirtualFree(page, 0 /* dwSize */, MEM_RELEASE);\n    } else {\n      /* GetWriteWatch will be useless. */\n      GetWriteWatch_func = 0;\n    }\n  }\n  done = TRUE;\n}\n\n#  else\n#    define GetWriteWatch_alloc_flag 0\n#  endif /* !GWW_VDB */\n\n#  ifdef MSWIN32\n/* Unfortunately, we have to handle win32s very differently from    */\n/* NT, since VirtualQuery has very different semantics.  In         */\n/* particular, under win32s a VirtualQuery call on an unmapped page */\n/* returns an invalid result.  Under NT, GC_register_data_segments  */\n/* is a no-op and all real work is done by                          */\n/* GC_register_dynamic_libraries().  Under win32s, we cannot find   */\n/* the data segments associated with dll's.  We register the main   */\n/* data segment here.                                               */\n\nGC_INNER GC_bool GC_no_win32_dlls = FALSE;\n\n/* This is a Windows NT derivative, i.e. NT, Win2K, XP or later.    */\nGC_INNER GC_bool GC_wnt = FALSE;\n\nGC_INNER void\nGC_init_win32(void)\n{\n#    if defined(_WIN64) || (defined(_MSC_VER) && _MSC_VER >= 1800)\n  /* MS Visual Studio 2013 deprecates GetVersion, but on the      */\n  /* other hand it cannot be used to target pre-Win2K.            */\n  GC_wnt = TRUE;\n#    else\n  /* Set GC_wnt.  If we're running under win32s, assume that no     */\n  /* DLLs will be loaded.  I doubt anyone still runs win32s, but... */\n  DWORD v = GetVersion();\n\n  GC_wnt = !(v & (DWORD)0x80000000UL);\n  GC_no_win32_dlls |= ((!GC_wnt) && (v & 0xff) <= 3);\n#    endif\n#    ifdef USE_MUNMAP\n  if (GC_no_win32_dlls) {\n    /* Turn off unmapping for safety (since may not work well     */\n    /* with GlobalAlloc).                                         */\n    GC_unmap_threshold = 0;\n  }\n#    endif\n}\n\n/* Return the smallest address p such that VirtualQuery returns     */\n/* correct results for all addresses between p and start.  Assumes  */\n/* VirtualQuery() returns correct information for start.            */\nSTATIC ptr_t\nGC_least_described_address(ptr_t start)\n{\n  ptr_t limit = (ptr_t)GC_sysinfo.lpMinimumApplicationAddress;\n  ptr_t p = PTR_ALIGN_DOWN(start, GC_page_size);\n\n  GC_ASSERT(GC_page_size != 0);\n  for (;;) {\n    MEMORY_BASIC_INFORMATION buf;\n    size_t result;\n    ptr_t q;\n\n    if (EXPECT(ADDR(p) <= (word)GC_page_size, FALSE)) {\n      /* Avoid underflow.   */\n      break;\n    }\n    q = p - GC_page_size;\n    if (ADDR_LT(q, limit))\n      break;\n\n    result = VirtualQuery((LPVOID)q, &buf, sizeof(buf));\n    if (result != sizeof(buf) || 0 == buf.AllocationBase)\n      break;\n    p = (ptr_t)buf.AllocationBase;\n  }\n  return p;\n}\n\nSTATIC void\nGC_register_root_section(ptr_t static_root)\n{\n  ptr_t p, base, limit;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_no_win32_dlls)\n    return;\n\n  p = GC_least_described_address(static_root);\n  base = limit = p;\n  while (ADDR_LT(p, (ptr_t)GC_sysinfo.lpMaximumApplicationAddress)) {\n    MEMORY_BASIC_INFORMATION buf;\n    size_t result = VirtualQuery((LPVOID)p, &buf, sizeof(buf));\n\n    if (result != sizeof(buf) || 0 == buf.AllocationBase\n        || GC_is_heap_base(buf.AllocationBase))\n      break;\n    if (ADDR(p) > GC_WORD_MAX - buf.RegionSize) {\n      /* Avoid overflow.    */\n      break;\n    }\n    if (buf.State == MEM_COMMIT && is_writable(buf.Protect)) {\n      if (p != limit) {\n        if (base != limit)\n          GC_add_roots_inner(base, limit, FALSE);\n        base = p;\n      }\n      limit = p + buf.RegionSize;\n    }\n    p += buf.RegionSize;\n  }\n  if (base != limit)\n    GC_add_roots_inner(base, limit, FALSE);\n}\n#  endif /* MSWIN32 */\n\n#  if defined(USE_WINALLOC) && !defined(REDIRECT_MALLOC)\n/* We maintain a linked list of AllocationBase values that we */\n/* know correspond to malloc heap sections.  Currently this   */\n/* is only called during a GC.  But there is some hope that   */\n/* for long running programs we will eventually see most heap */\n/* sections.                                                  */\n\n/* In the long run, it would be more reliable to occasionally */\n/* walk the malloc heap with HeapWalk on the default heap.    */\n/* But that apparently works only for NT-based Windows.       */\n\n/* Note: initialized to approximate largest root size.        */\nSTATIC size_t GC_max_root_size = 100000;\n\n/* In the long run, a better data structure would also be nice... */\nSTATIC struct GC_malloc_heap_list {\n  void *allocation_base;\n  struct GC_malloc_heap_list *next;\n} *GC_malloc_heap_l = 0;\n\n/* Is p the base of one of the malloc heap sections we already    */\n/* know about?                                                    */\nSTATIC GC_bool\nGC_is_malloc_heap_base(const void *p)\n{\n  struct GC_malloc_heap_list *q;\n\n  for (q = GC_malloc_heap_l; q != NULL; q = q->next) {\n    if (q->allocation_base == p)\n      return TRUE;\n  }\n  return FALSE;\n}\n\nSTATIC void *\nGC_get_allocation_base(void *p)\n{\n  MEMORY_BASIC_INFORMATION buf;\n  size_t result = VirtualQuery(p, &buf, sizeof(buf));\n\n  if (result != sizeof(buf)) {\n    ABORT(\"Weird VirtualQuery result\");\n  }\n  return buf.AllocationBase;\n}\n\nGC_INNER void\nGC_add_current_malloc_heap(void)\n{\n  struct GC_malloc_heap_list *new_l = (struct GC_malloc_heap_list *)malloc(\n      sizeof(struct GC_malloc_heap_list));\n  void *candidate;\n\n  if (NULL == new_l)\n    return;\n  /* Explicitly set to suppress maybe-uninitialized gcc warning.  */\n  new_l->allocation_base = NULL;\n\n  candidate = GC_get_allocation_base(new_l);\n  if (GC_is_malloc_heap_base(candidate)) {\n    /* Try a little harder to find malloc heap.   */\n    size_t req_size = 10000;\n\n    do {\n      void *p = malloc(req_size);\n\n      if (NULL == p) {\n        free(new_l);\n        return;\n      }\n      candidate = GC_get_allocation_base(p);\n      free(p);\n      req_size *= 2;\n    } while (GC_is_malloc_heap_base(candidate)\n             && req_size < GC_max_root_size / 10 && req_size < 500000);\n    if (GC_is_malloc_heap_base(candidate)) {\n      free(new_l);\n      return;\n    }\n  }\n  GC_COND_LOG_PRINTF(\"Found new system malloc AllocationBase at %p\\n\",\n                     candidate);\n  new_l->allocation_base = candidate;\n  new_l->next = GC_malloc_heap_l;\n  GC_malloc_heap_l = new_l;\n}\n\n/* Free all the linked list nodes.  Could be invoked at process   */\n/* exit to avoid memory leak complains of a dynamic code analysis */\n/* tool.                                                          */\nSTATIC void\nGC_free_malloc_heap_list(void)\n{\n  struct GC_malloc_heap_list *q = GC_malloc_heap_l;\n\n  GC_malloc_heap_l = NULL;\n  while (q != NULL) {\n    struct GC_malloc_heap_list *next = q->next;\n\n    free(q);\n    q = next;\n  }\n}\n#  endif /* USE_WINALLOC && !REDIRECT_MALLOC */\n\n/* Is p the start of either the malloc heap, or of one of our   */\n/* heap sections?                                               */\nGC_INNER GC_bool\nGC_is_heap_base(const void *p)\n{\n  size_t i;\n\n#  if defined(USE_WINALLOC) && !defined(REDIRECT_MALLOC)\n  if (GC_root_size > GC_max_root_size)\n    GC_max_root_size = GC_root_size;\n  if (GC_is_malloc_heap_base(p))\n    return TRUE;\n#  endif\n  for (i = 0; i < GC_n_heap_bases; i++) {\n    if (GC_heap_bases[i] == p)\n      return TRUE;\n  }\n  return FALSE;\n}\n\nGC_INNER void\nGC_register_data_segments(void)\n{\n#  ifdef MSWIN32\n  /* Note: any other GC global variable would fit too.    */\n  GC_register_root_section((ptr_t)&GC_pages_executable);\n#  endif\n}\n\n#endif /* ANY_MSWIN */\n\n#ifdef DATASTART_USES_XGETDATASTART\n#  ifdef CHERI_PURECAP\n#    include <link.h>\n\n/* The CheriBSD LLVM compiler declares etext, edata and end as typeless */\n/* variables.  If libgc is statically linked with the executable, these */\n/* capabilities are compiled with the read-only permissions and bounds  */\n/* that span the .data and .bss sections.  If libgc is compiled as      */\n/* a shared library, these symbols are compiled with zero bounds and    */\n/* cannot be dereferenced; instead, the read-only capability returned   */\n/* by the loader is used.                                               */\n\nstruct scan_bounds_s {\n  word start_addr;\n  word end_addr;\n  ptr_t ld_cap;\n};\n\nstatic int\nld_cap_search(struct dl_phdr_info *info, size_t size, void *cd)\n{\n  struct scan_bounds_s *region = (struct scan_bounds_s *)cd;\n  ptr_t load_ptr = (ptr_t)info->dlpi_addr;\n\n  UNUSED_ARG(size);\n  if (!SPANNING_CAPABILITY(load_ptr, region->start_addr, region->end_addr))\n    return 0;\n\n  region->ld_cap = (ptr_t)cheri_bounds_set(\n      cheri_address_set(load_ptr, region->start_addr),\n      region->end_addr - region->start_addr);\n  return 1; /* stop */\n}\n\nstatic ptr_t\nderive_cap_from_ldr(ptr_t range_start, ptr_t range_end)\n{\n  word scan_start = ADDR(range_start);\n  word scan_end = ADDR(range_end);\n  struct scan_bounds_s region;\n\n  /* If symbols already span the required range, return one of them.    */\n  if (SPANNING_CAPABILITY(range_start, scan_start, scan_end))\n    return range_start;\n  if (SPANNING_CAPABILITY(range_end, scan_start, scan_end))\n    return range_end;\n\n  /* Fall-back option: derive .data plus .bss end pointer from the      */\n  /* read-only capability provided by loader.                           */\n  region.start_addr = scan_start;\n  region.end_addr = scan_end;\n  region.ld_cap = NULL; /* prevent compiler warning */\n  if (!dl_iterate_phdr(ld_cap_search, &region))\n    ABORT(\"Cannot find static roots for capability system\");\n  GC_ASSERT(region.ld_cap != NULL);\n  return region.ld_cap;\n}\n#  endif /* CHERI_PURECAP */\n\nGC_INNER ptr_t\nGC_SysVGetDataStart(size_t max_page_size, ptr_t etext_ptr)\n{\n  volatile ptr_t result;\n\n  GC_ASSERT(max_page_size % ALIGNMENT == 0);\n  result = PTR_ALIGN_UP(etext_ptr, ALIGNMENT);\n#  ifdef CHERI_PURECAP\n  result = derive_cap_from_ldr(result, DATAEND);\n#  endif\n\n  GC_setup_temporary_fault_handler();\n  if (SETJMP(GC_jmp_buf) == 0) {\n    /* Note that this is not equivalent to just adding max_page_size to */\n    /* etext_ptr because the latter is not guaranteed to be multiple of */\n    /* the page size.                                                   */\n    ptr_t next_page = PTR_ALIGN_UP(result, max_page_size);\n\n#  ifdef FREEBSD\n    /* It's unclear whether this should be identical to the below, or   */\n    /* whether it should apply to non-x86 architectures.  For now we    */\n    /* do not assume that there is always an empty page after etext.    */\n    /* But in some cases there actually seems to be slightly more.      */\n    /* It also deals with holes between read-only and writable data.    */\n\n    /* Try reading at the address.  This should happen before there is  */\n    /* another thread.                                                  */\n    for (; ADDR_LT(next_page, DATAEND); next_page += max_page_size) {\n      GC_noop1((word)(*(volatile unsigned char *)next_page));\n    }\n#  else\n    result = next_page + (ADDR(result) & ((word)max_page_size - 1));\n    /* Try writing to the address. */\n    {\n#    ifdef AO_HAVE_fetch_and_add\n      volatile AO_t zero = 0;\n\n      (void)AO_fetch_and_add((volatile AO_t *)result, zero);\n#    else\n      /* Fallback to non-atomic fetch-and-store. */\n      char v = *result;\n\n#      ifdef CPPCHECK\n      GC_noop1_ptr(&v);\n#      endif\n      *result = v;\n#    endif\n    }\n#  endif\n    GC_reset_fault_handler();\n  } else {\n    GC_reset_fault_handler();\n    /* We got here via a longjmp.  The address is not readable.   */\n    /* This is known to happen under Solaris 2.4 + gcc, which     */\n    /* places string constants in the text segment, but after     */\n    /* etext.  Use plan B.  Note that we now know there is a gap  */\n    /* between text and data segments, so plan A brought us       */\n    /* something.                                                 */\n#  ifdef CHERI_PURECAP\n    result = (ptr_t)GC_find_limit(cheri_address_set(result, ADDR(DATAEND)),\n                                  FALSE);\n#  else\n    result = (ptr_t)GC_find_limit(DATAEND, FALSE);\n#  endif\n  }\n  return (ptr_t)CAST_AWAY_VOLATILE_PVOID(result);\n}\n#endif /* DATASTART_USES_XGETDATASTART */\n\n#if defined(OS2)\nGC_INNER void\nGC_register_data_segments(void)\n{\n  PTIB ptib;\n  PPIB ppib;\n  HMODULE module_handle;\n#  define PBUFSIZ 512\n  UCHAR path[PBUFSIZ];\n  FILE *myexefile;\n  struct exe_hdr hdrdos; /* MSDOS header */\n  struct e32_exe hdr386; /* real header for my executable */\n  struct o32_obj seg;    /* current segment */\n  int nsegs;\n\n#  if defined(CPPCHECK)\n  hdrdos.padding[0] = 0; /* to prevent \"field unused\" warnings */\n  hdr386.exe_format_level = 0;\n  hdr386.os = 0;\n  hdr386.padding1[0] = 0;\n  hdr386.padding2[0] = 0;\n  seg.pagemap = 0;\n  seg.mapsize = 0;\n  seg.reserved = 0;\n#  endif\n  if (DosGetInfoBlocks(&ptib, &ppib) != NO_ERROR) {\n    ABORT(\"DosGetInfoBlocks failed\");\n  }\n  module_handle = ppib->pib_hmte;\n  if (DosQueryModuleName(module_handle, PBUFSIZ, path) != NO_ERROR) {\n    ABORT(\"DosQueryModuleName failed\");\n  }\n  myexefile = fopen(path, \"rb\");\n  if (myexefile == 0) {\n    ABORT_ARG1(\"Failed to open executable\", \": %s\", path);\n  }\n  if (fread((char *)&hdrdos, 1, sizeof(hdrdos), myexefile) < sizeof(hdrdos)) {\n    ABORT_ARG1(\"Could not read MSDOS header\", \" from: %s\", path);\n  }\n  if (E_MAGIC(hdrdos) != EMAGIC) {\n    ABORT_ARG1(\"Bad DOS magic number\", \" in file: %s\", path);\n  }\n  if (fseek(myexefile, E_LFANEW(hdrdos), SEEK_SET) != 0) {\n    ABORT_ARG1(\"Bad DOS magic number\", \" in file: %s\", path);\n  }\n  if (fread((char *)&hdr386, 1, sizeof(hdr386), myexefile) < sizeof(hdr386)) {\n    ABORT_ARG1(\"Could not read OS/2 header\", \" from: %s\", path);\n  }\n  if (E32_MAGIC1(hdr386) != E32MAGIC1 || E32_MAGIC2(hdr386) != E32MAGIC2) {\n    ABORT_ARG1(\"Bad OS/2 magic number\", \" in file: %s\", path);\n  }\n  if (E32_BORDER(hdr386) != E32LEBO || E32_WORDER(hdr386) != E32LEWO) {\n    ABORT_ARG1(\"Bad byte order in executable\", \" file: %s\", path);\n  }\n  if (E32_CPU(hdr386) == E32CPU286) {\n    ABORT_ARG1(\"GC cannot handle 80286 executables\", \": %s\", path);\n  }\n  if (fseek(myexefile, E_LFANEW(hdrdos) + E32_OBJTAB(hdr386), SEEK_SET) != 0) {\n    ABORT_ARG1(\"Seek to object table failed\", \" in file: %s\", path);\n  }\n  for (nsegs = E32_OBJCNT(hdr386); nsegs > 0; nsegs--) {\n    int flags;\n    if (fread((char *)&seg, 1, sizeof(seg), myexefile) < sizeof(seg)) {\n      ABORT_ARG1(\"Could not read obj table entry\", \" from file: %s\", path);\n    }\n    flags = O32_FLAGS(seg);\n    if (!(flags & OBJWRITE))\n      continue;\n    if (!(flags & OBJREAD))\n      continue;\n    if (flags & OBJINVALID) {\n      GC_err_printf(\"Object with invalid pages?\\n\");\n      continue;\n    }\n    GC_add_roots_inner((ptr_t)O32_BASE(seg),\n                       (ptr_t)(O32_BASE(seg) + O32_SIZE(seg)), FALSE);\n  }\n  (void)fclose(myexefile);\n}\n\n#elif defined(OPENBSD)\n/* Depending on arch alignment, there can be multiple holes       */\n/* between DATASTART and DATAEND.  Scan in DATASTART .. DATAEND   */\n/* and register each region.                                      */\nGC_INNER void\nGC_register_data_segments(void)\n{\n  ptr_t region_start = DATASTART;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (ADDR(region_start) - 1U >= ADDR(DATAEND))\n    ABORT_ARG2(\"Wrong DATASTART/END pair\", \": %p .. %p\", (void *)region_start,\n               (void *)DATAEND);\n  for (;;) {\n    ptr_t region_end = GC_find_limit_with_bound(region_start, TRUE, DATAEND);\n\n    GC_add_roots_inner(region_start, region_end, FALSE);\n    if (ADDR_GE(region_end, DATAEND))\n      break;\n    region_start = GC_skip_hole_openbsd(region_end, DATAEND);\n  }\n}\n\n#elif !defined(ANY_MSWIN)\nGC_INNER void\nGC_register_data_segments(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  if !defined(DYNAMIC_LOADING) && defined(GC_DONT_REGISTER_MAIN_STATIC_DATA)\n  /* Avoid even referencing DATASTART and DATAEND as they are   */\n  /* unnecessary and cause linker errors when bitcode is        */\n  /* enabled.  GC_register_data_segments is not called anyway.  */\n#  elif defined(DYNAMIC_LOADING) && (defined(DARWIN) || defined(HAIKU))\n  /* No-op.  GC_register_main_static_data() always returns false. */\n#  elif defined(REDIRECT_MALLOC) && defined(SOLARIS) && defined(THREADS)\n  /* As of Solaris 2.3, the Solaris threads implementation    */\n  /* allocates the data structure for the initial thread with */\n  /* sbrk at process startup.  It needs to be scanned, so     */\n  /* that we don't lose some malloc allocated data structures */\n  /* hanging from it.  We're on thin ice here...              */\n  GC_ASSERT(DATASTART);\n  {\n    ptr_t p = (ptr_t)sbrk(0);\n\n    if (ADDR_LT(DATASTART, p))\n      GC_add_roots_inner(DATASTART, p, FALSE);\n  }\n#  else\n  /* Note: subtract one to also check for NULL without        */\n  /* a compiler warning.                                      */\n  if (ADDR(DATASTART) - 1U >= ADDR(DATAEND)) {\n    ABORT_ARG2(\"Wrong DATASTART/END pair\", \": %p .. %p\", (void *)DATASTART,\n               (void *)DATAEND);\n  }\n  GC_add_roots_inner(DATASTART, DATAEND, FALSE);\n#    ifdef GC_HAVE_DATAREGION2\n  if (ADDR(DATASTART2) - 1U >= ADDR(DATAEND2))\n    ABORT_ARG2(\"Wrong DATASTART/END2 pair\", \": %p .. %p\", (void *)DATASTART2,\n               (void *)DATAEND2);\n  GC_add_roots_inner(DATASTART2, DATAEND2, FALSE);\n#    endif\n#  endif\n  /* Dynamic libraries are added at every collection, since they  */\n  /* may change.                                                  */\n}\n#endif /* !ANY_MSWIN && !OPENBSD && !OS2 */\n\n/* Auxiliary routines for obtaining memory from OS.     */\n\n#ifdef NEED_UNIX_GET_MEM\n\n#  define SBRK_ARG_T ptrdiff_t\n\n#  if defined(MMAP_SUPPORTED)\n\n#    ifdef USE_MMAP_FIXED\n/* Seems to yield better performance on Solaris 2, but can be       */\n/* unreliable if something is already mapped at the address.        */\n#      define GC_MMAP_FLAGS MAP_FIXED | MAP_PRIVATE\n#    else\n#      define GC_MMAP_FLAGS MAP_PRIVATE\n#    endif\n\n#    ifdef USE_MMAP_ANON\n#      define zero_fd -1\n#      if defined(MAP_ANONYMOUS) && !defined(CPPCHECK)\n#        define OPT_MAP_ANON MAP_ANONYMOUS\n#      else\n#        define OPT_MAP_ANON MAP_ANON\n#      endif\n#    else\nstatic int zero_fd = -1;\n#      define OPT_MAP_ANON 0\n#    endif\n\n#    ifndef MSWIN_XBOX1\n#      if defined(SYMBIAN) && !defined(USE_MMAP_ANON)\nEXTERN_C_BEGIN\nextern char *GC_get_private_path_and_zero_file(void);\nEXTERN_C_END\n#      endif\n\nSTATIC void *\nGC_unix_mmap_get_mem(size_t bytes)\n{\n  void *result;\n  static ptr_t last_addr = HEAP_START;\n\n#      ifndef USE_MMAP_ANON\n  static GC_bool initialized = FALSE;\n\n  if (!EXPECT(initialized, TRUE)) {\n#        ifdef SYMBIAN\n    char *path = GC_get_private_path_and_zero_file();\n    if (path != NULL) {\n      zero_fd = open(path, O_RDWR | O_CREAT, 0644);\n      free(path);\n    }\n#        else\n    zero_fd = open(\"/dev/zero\", O_RDONLY);\n#        endif\n    if (zero_fd == -1)\n      ABORT(\"Could not open /dev/zero\");\n    if (fcntl(zero_fd, F_SETFD, FD_CLOEXEC) == -1)\n      WARN(\"Could not set FD_CLOEXEC for /dev/zero\\n\", 0);\n\n    initialized = TRUE;\n  }\n#      endif\n\n  GC_ASSERT(GC_page_size != 0);\n  if (bytes & (GC_page_size - 1))\n    ABORT(\"Bad GET_MEM arg\");\n  result\n      = mmap(last_addr, bytes,\n             (PROT_READ | PROT_WRITE) | (GC_pages_executable ? PROT_EXEC : 0),\n             GC_MMAP_FLAGS | OPT_MAP_ANON, zero_fd, 0 /* offset */);\n#      undef IGNORE_PAGES_EXECUTABLE\n\n  if (EXPECT(MAP_FAILED == result, FALSE)) {\n    if (HEAP_START == last_addr && GC_pages_executable\n        && (EACCES == errno || EPERM == errno))\n      ABORT(\"Cannot allocate executable pages\");\n    return NULL;\n  }\n#      ifdef LINUX\n  GC_ASSERT(ADDR(result) <= ~(word)(GC_page_size - 1) - bytes);\n  /* The following PTR_ALIGN_UP() cannot overflow.  */\n#      else\n  if (EXPECT(ADDR(result) > ~(word)(GC_page_size - 1) - bytes, FALSE)) {\n    /* Oops.  We got the end of the address space.  This isn't      */\n    /* usable by arbitrary C code, since one-past-end pointers      */\n    /* do not work, so we discard it and try again.                 */\n    /* Leave the last page mapped, so we can't repeat.              */\n    (void)munmap(result, ~(GC_page_size - 1) - (size_t)ADDR(result));\n    return GC_unix_mmap_get_mem(bytes);\n  }\n#      endif\n  last_addr = PTR_ALIGN_UP((ptr_t)result + bytes, GC_page_size);\n\n  if ((ADDR(result) % HBLKSIZE) != 0)\n    ABORT(\"GC_unix_get_mem: Memory returned by mmap is not aligned to \"\n          \"HBLKSIZE.\");\n  return result;\n}\n#    endif /* !MSWIN_XBOX1 */\n\n#  endif /* MMAP_SUPPORTED */\n\n#  if defined(USE_MMAP)\n\nGC_INNER void *\nGC_unix_get_mem(size_t bytes)\n{\n  return GC_unix_mmap_get_mem(bytes);\n}\n\n#  else /* !USE_MMAP */\n\nSTATIC void *\nGC_unix_sbrk_get_mem(size_t bytes)\n{\n  void *result;\n\n#    ifdef IRIX5\n  /* Bare sbrk isn't thread safe.  Play by malloc rules.      */\n  /* The equivalent may be needed on other systems as well.   */\n  __LOCK_MALLOC();\n#    endif\n  {\n    ptr_t cur_brk = (ptr_t)sbrk(0);\n    SBRK_ARG_T lsbs = ADDR(cur_brk) & (GC_page_size - 1);\n\n    GC_ASSERT(GC_page_size != 0);\n    if (EXPECT((SBRK_ARG_T)bytes < 0, FALSE)) {\n      /* Value of bytes is too big.   */\n      result = NULL;\n      goto out;\n    }\n    if (lsbs != 0) {\n      if ((ptr_t)sbrk((SBRK_ARG_T)GC_page_size - lsbs) == (ptr_t)(-1)) {\n        result = NULL;\n        goto out;\n      }\n    }\n#    ifdef ADD_HEAP_GUARD_PAGES\n    /* This is useful for catching severe memory overwrite problems that */\n    /* span heap sections.  It shouldn't otherwise be turned on.         */\n    {\n      ptr_t guard = (ptr_t)sbrk((SBRK_ARG_T)GC_page_size);\n      if (mprotect(guard, GC_page_size, PROT_NONE) != 0)\n        ABORT(\"ADD_HEAP_GUARD_PAGES: mprotect failed\");\n    }\n#    endif\n    result = sbrk((SBRK_ARG_T)bytes);\n    if (EXPECT(ADDR(result) == GC_WORD_MAX, FALSE))\n      result = NULL;\n  }\nout:\n#    ifdef IRIX5\n  __UNLOCK_MALLOC();\n#    endif\n  return result;\n}\n\nGC_INNER void *\nGC_unix_get_mem(size_t bytes)\n{\n#    if defined(MMAP_SUPPORTED)\n  /* By default, we try both sbrk and mmap, in that order.    */\n  static GC_bool sbrk_failed = FALSE;\n  void *result = NULL;\n\n  if (GC_pages_executable) {\n    /* If the allocated memory should have the execute permission   */\n    /* then sbrk() cannot be used.                                  */\n    return GC_unix_mmap_get_mem(bytes);\n  }\n  if (!sbrk_failed)\n    result = GC_unix_sbrk_get_mem(bytes);\n  if (NULL == result) {\n    sbrk_failed = TRUE;\n    result = GC_unix_mmap_get_mem(bytes);\n    if (NULL == result) {\n      /* Try sbrk again, in case sbrk memory became available.    */\n      result = GC_unix_sbrk_get_mem(bytes);\n    }\n  }\n  return result;\n#    else /* !MMAP_SUPPORTED */\n  return GC_unix_sbrk_get_mem(bytes);\n#    endif\n}\n\n#  endif /* !USE_MMAP */\n\n#endif /* NEED_UNIX_GET_MEM */\n\n#if defined(OS2)\nGC_INNER void *\nGC_get_mem(size_t bytes)\n{\n  void *result = NULL;\n  int retry;\n\n  GC_ASSERT(GC_page_size != 0);\n  bytes = SIZET_SAT_ADD(bytes, GC_page_size);\n  for (retry = 0;; retry++) {\n    if (DosAllocMem(&result, bytes,\n                    (PAG_READ | PAG_WRITE | PAG_COMMIT)\n                        | (GC_pages_executable ? PAG_EXECUTE : 0))\n            == NO_ERROR\n        && EXPECT(result != NULL, TRUE))\n      break;\n    /* TODO: Unclear the purpose of the retry.  (Probably, if           */\n    /* DosAllocMem returns memory at 0 address then just retry once.)   */\n    if (retry >= 1)\n      return NULL;\n  }\n  return HBLKPTR((ptr_t)result + GC_page_size - 1);\n}\n\n#elif defined(MSWIN_XBOX1)\nGC_INNER void *\nGC_get_mem(size_t bytes)\n{\n  if (EXPECT(0 == bytes, FALSE))\n    return NULL;\n  return VirtualAlloc(NULL, bytes, MEM_COMMIT | MEM_TOP_DOWN, PAGE_READWRITE);\n}\n\n#elif defined(MSWINCE)\nGC_INNER void *\nGC_get_mem(size_t bytes)\n{\n  void *result = NULL; /* initialized to prevent warning */\n  size_t i;\n\n  GC_ASSERT(GC_page_size != 0);\n  bytes = ROUNDUP_PAGESIZE(bytes);\n\n  /* Try to find reserved, uncommitted pages. */\n  for (i = 0; i < GC_n_heap_bases; i++) {\n    if (((word)(-(GC_signed_word)GC_heap_lengths[i])\n         & (GC_sysinfo.dwAllocationGranularity - 1))\n        >= bytes) {\n      result = GC_heap_bases[i] + GC_heap_lengths[i];\n      break;\n    }\n  }\n\n  if (i == GC_n_heap_bases) {\n    /* Reserve more pages.  */\n    size_t res_bytes\n        = SIZET_SAT_ADD(bytes, (size_t)GC_sysinfo.dwAllocationGranularity - 1)\n          & ~((size_t)GC_sysinfo.dwAllocationGranularity - 1);\n    /* If we ever support MPROTECT_VDB here, we will probably need  */\n    /* to ensure that res_bytes is greater (strictly) than bytes,   */\n    /* so that VirtualProtect never spans regions.  It seems to be  */\n    /* fine for a VirtualFree argument to span regions, so we       */\n    /* should be OK for now.                                        */\n    result = VirtualAlloc(NULL, res_bytes, MEM_RESERVE | MEM_TOP_DOWN,\n                          GC_pages_executable ? PAGE_EXECUTE_READWRITE\n                                              : PAGE_READWRITE);\n    if (HBLKDISPL(result) != 0) {\n      /* If I read the documentation correctly, this can only       */\n      /* happen if HBLKSIZE > 64 KB or not a power of 2.            */\n      ABORT(\"Bad VirtualAlloc result\");\n    }\n    if (GC_n_heap_bases >= MAX_HEAP_SECTS)\n      ABORT(\"Too many heap sections\");\n    if (EXPECT(NULL == result, FALSE))\n      return NULL;\n    GC_heap_bases[GC_n_heap_bases] = (ptr_t)result;\n    GC_heap_lengths[GC_n_heap_bases] = 0;\n    GC_n_heap_bases++;\n  }\n\n  /* Commit pages.    */\n  result = VirtualAlloc(result, bytes, MEM_COMMIT,\n                        GC_pages_executable ? PAGE_EXECUTE_READWRITE\n                                            : PAGE_READWRITE);\n#  undef IGNORE_PAGES_EXECUTABLE\n\n  if (HBLKDISPL(result) != 0)\n    ABORT(\"Bad VirtualAlloc result\");\n  if (EXPECT(result != NULL, TRUE))\n    GC_heap_lengths[i] += bytes;\n  return result;\n}\n\n#elif defined(CYGWIN32) || defined(MSWIN32)\n#  ifdef USE_GLOBAL_ALLOC\n#    define GLOBAL_ALLOC_TEST 1\n#  else\n#    define GLOBAL_ALLOC_TEST GC_no_win32_dlls\n#  endif\n\n#  if (defined(GC_USE_MEM_TOP_DOWN) && defined(USE_WINALLOC)) \\\n      || defined(CPPCHECK)\n/* Use GC_USE_MEM_TOP_DOWN for better 64-bit testing.  Otherwise    */\n/* all addresses tend to end up in the first 4 GB, hiding bugs.     */\nDWORD GC_mem_top_down = MEM_TOP_DOWN;\n#  else\n#    define GC_mem_top_down 0\n#  endif /* !GC_USE_MEM_TOP_DOWN */\n\nGC_INNER void *\nGC_get_mem(size_t bytes)\n{\n  void *result;\n\n#  ifndef USE_WINALLOC\n  result = GC_unix_get_mem(bytes);\n#  else\n#    if defined(MSWIN32) && !defined(MSWINRT_FLAVOR)\n  if (GLOBAL_ALLOC_TEST) {\n    /* VirtualAlloc doesn't like PAGE_EXECUTE_READWRITE.    */\n    /* There are also unconfirmed rumors of other problems, */\n    /* so we dodge the issue.                               */\n    result = GlobalAlloc(0, SIZET_SAT_ADD(bytes, HBLKSIZE));\n    /* Align it at HBLKSIZE boundary (NULL value remains unchanged). */\n    result = PTR_ALIGN_UP((ptr_t)result, HBLKSIZE);\n  } else\n#    endif\n  /* else */ {\n    /* VirtualProtect only works on regions returned by a   */\n    /* single VirtualAlloc call.  Thus we allocate one      */\n    /* extra page, which will prevent merging of blocks     */\n    /* in separate regions, and eliminate any temptation    */\n    /* to call VirtualProtect on a range spanning regions.  */\n    /* This wastes a small amount of memory, and risks      */\n    /* increased fragmentation.  But better alternatives    */\n    /* would require effort.                                */\n#    ifdef MPROTECT_VDB\n    /* We can't check for GC_incremental here (because    */\n    /* GC_enable_incremental() might be called some time  */\n    /* later after the GC initialization).                */\n#      ifdef GWW_VDB\n#        define VIRTUAL_ALLOC_PAD (GC_GWW_AVAILABLE() ? 0 : 1)\n#      else\n#        define VIRTUAL_ALLOC_PAD 1\n#      endif\n#    else\n#      define VIRTUAL_ALLOC_PAD 0\n#    endif\n    /* Pass the MEM_WRITE_WATCH only if GetWriteWatch-based */\n    /* VDBs are enabled and the GetWriteWatch function is   */\n    /* available.  Otherwise we waste resources or possibly */\n    /* cause VirtualAlloc to fail (observed in Windows 2000 */\n    /* SP2).                                                */\n    result = VirtualAlloc(\n        NULL, SIZET_SAT_ADD(bytes, VIRTUAL_ALLOC_PAD),\n        MEM_COMMIT | MEM_RESERVE | GetWriteWatch_alloc_flag | GC_mem_top_down,\n        GC_pages_executable ? PAGE_EXECUTE_READWRITE : PAGE_READWRITE);\n#    undef IGNORE_PAGES_EXECUTABLE\n  }\n#  endif\n  if (HBLKDISPL(result) != 0)\n    ABORT(\"Bad VirtualAlloc result\");\n  if (GC_n_heap_bases >= MAX_HEAP_SECTS)\n    ABORT(\"Too many heap sections\");\n  if (EXPECT(result != NULL, TRUE))\n    GC_heap_bases[GC_n_heap_bases++] = (ptr_t)result;\n  return result;\n}\n#endif /* CYGWIN32 || MSWIN32 */\n\n#if defined(ANY_MSWIN) || defined(MSWIN_XBOX1)\nGC_API void GC_CALL\nGC_win32_free_heap(void)\n{\n#  if defined(USE_WINALLOC) && !defined(REDIRECT_MALLOC)\n  GC_free_malloc_heap_list();\n#  endif\n#  if defined(CYGWIN32) || defined(MSWIN32)\n#    ifndef MSWINRT_FLAVOR\n#      ifdef MSWIN32\n  if (GLOBAL_ALLOC_TEST)\n#      endif\n  {\n    while (GC_n_heap_bases > 0) {\n      GC_n_heap_bases--;\n#      ifdef CYGWIN32\n      /* FIXME: Is it OK to use non-GC free() here? */\n#      else\n      GlobalFree(GC_heap_bases[GC_n_heap_bases]);\n#      endif\n      GC_heap_bases[GC_n_heap_bases] = 0;\n    }\n    return;\n  }\n#    endif /* !MSWINRT_FLAVOR */\n#    ifndef CYGWIN32\n  /* Avoiding VirtualAlloc leak.  */\n  while (GC_n_heap_bases > 0) {\n    VirtualFree(GC_heap_bases[--GC_n_heap_bases], 0, MEM_RELEASE);\n    GC_heap_bases[GC_n_heap_bases] = 0;\n  }\n#    endif\n#  endif\n}\n#endif /* ANY_MSWIN || MSWIN_XBOX1 */\n\n#if (defined(USE_MUNMAP) || defined(MPROTECT_VDB)) && !defined(USE_WINALLOC)\n#  define ABORT_ON_REMAP_FAIL(C_msg_prefix, start_addr, len)             \\\n    ABORT_ARG3(C_msg_prefix \" failed\", \" at %p (length %lu), errno= %d\", \\\n               (void *)(start_addr), (unsigned long)(len), errno)\n#endif\n\n#ifdef USE_MUNMAP\n\n#  if !defined(NN_PLATFORM_CTR) && !defined(MSWIN32) && !defined(MSWINCE) \\\n      && !defined(MSWIN_XBOX1)\n#    ifdef SN_TARGET_PS3\n#      include <sys/memory.h>\n#    else\n#      include <sys/mman.h>\n#    endif\n#    include <sys/stat.h>\n#  endif\n\n/* Compute a page aligned starting address for the unmap        */\n/* operation on a block of size bytes starting at start.        */\n/* Return 0 if the block is too small to make this feasible.    */\nSTATIC ptr_t\nGC_unmap_start(ptr_t start, size_t bytes)\n{\n  ptr_t result;\n\n  GC_ASSERT(GC_page_size != 0);\n  result = PTR_ALIGN_UP(start, GC_page_size);\n  if (ADDR_LT(start + bytes, result + GC_page_size))\n    return NULL;\n\n  return result;\n}\n\n/* We assume that GC_remap is called on exactly the same range  */\n/* as a previous call to GC_unmap.  It is safe to consistently  */\n/* round the endpoints in both places.                          */\n\nstatic void\nblock_unmap_inner(ptr_t start_addr, size_t len)\n{\n  if (0 == start_addr)\n    return;\n\n#  ifdef USE_WINALLOC\n  /* Under Win32/WinCE we commit (map) and decommit (unmap)         */\n  /* memory using VirtualAlloc and VirtualFree.  These functions    */\n  /* work on individual allocations of virtual memory, made         */\n  /* previously using VirtualAlloc with the MEM_RESERVE flag.       */\n  /* The ranges we need to (de)commit may span several of these     */\n  /* allocations; therefore we use VirtualQuery to check            */\n  /* allocation lengths, and split up the range as necessary.       */\n  while (len != 0) {\n    MEMORY_BASIC_INFORMATION mem_info;\n    word free_len;\n\n    if (VirtualQuery(start_addr, &mem_info, sizeof(mem_info))\n        != sizeof(mem_info))\n      ABORT(\"Weird VirtualQuery result\");\n    free_len = (len < mem_info.RegionSize) ? len : mem_info.RegionSize;\n    if (!VirtualFree(start_addr, free_len, MEM_DECOMMIT))\n      ABORT(\"VirtualFree failed\");\n    GC_unmapped_bytes += free_len;\n    start_addr += free_len;\n    len -= free_len;\n  }\n#  else\n  if (len != 0) {\n#    ifdef SN_TARGET_PS3\n    ps3_free_mem(start_addr, len);\n#    elif defined(AIX) || defined(COSMO) || defined(CYGWIN32) \\\n        || defined(HPUX)                                      \\\n        || (defined(LINUX) && !defined(PREFER_MMAP_PROT_NONE))\n    /* On AIX, mmap(PROT_NONE) fails with ENOMEM unless the       */\n    /* environment variable XPG_SUS_ENV is set to ON.             */\n    /* On Cygwin, calling mmap() with the new protection flags on */\n    /* an existing memory map with MAP_FIXED is broken.           */\n    /* However, calling mprotect() on the given address range     */\n    /* with PROT_NONE seems to work fine.                         */\n    /* On Linux, low RLIMIT_AS value may lead to mmap failure.    */\n#      if (defined(COSMO) || defined(LINUX)) \\\n          && !defined(FORCE_MPROTECT_BEFORE_MADVISE)\n    /* On Linux, at least, madvise() should be sufficient.      */\n#      else\n    if (mprotect(start_addr, len, PROT_NONE))\n      ABORT_ON_REMAP_FAIL(\"unmap: mprotect\", start_addr, len);\n#      endif\n#      if !defined(CYGWIN32)\n    /* On Linux (and some other platforms probably),    */\n    /* mprotect(PROT_NONE) is just disabling access to  */\n    /* the pages but not returning them to OS.          */\n    if (madvise(start_addr, len, MADV_DONTNEED) == -1)\n      ABORT_ON_REMAP_FAIL(\"unmap: madvise\", start_addr, len);\n#      endif\n#    else\n    /* We immediately remap it to prevent an intervening mmap()   */\n    /* from accidentally grabbing the same address space.         */\n    void *result = mmap(start_addr, len, PROT_NONE,\n                        MAP_PRIVATE | MAP_FIXED | OPT_MAP_ANON, zero_fd,\n                        0 /* offset */);\n\n    if (EXPECT(MAP_FAILED == result, FALSE))\n      ABORT_ON_REMAP_FAIL(\"unmap: mmap\", start_addr, len);\n    if (result != start_addr)\n      ABORT(\"unmap: mmap() result differs from start_addr\");\n#      if defined(CPPCHECK) || defined(LINT2)\n    /* Explicitly store the resource handle to a global variable. */\n    GC_noop1_ptr(result);\n#      endif\n#    endif\n    GC_unmapped_bytes += len;\n  }\n#  endif\n}\n\n/* Compute end address for an unmap operation on the indicated block.   */\nGC_INLINE ptr_t\nGC_unmap_end(ptr_t start, size_t bytes)\n{\n  return (ptr_t)HBLK_PAGE_ALIGNED(start + bytes);\n}\n\nGC_INNER void\nGC_unmap(ptr_t start, size_t bytes)\n{\n  ptr_t start_addr = GC_unmap_start(start, bytes);\n  ptr_t end_addr = GC_unmap_end(start, bytes);\n\n  block_unmap_inner(start_addr, (size_t)(end_addr - start_addr));\n}\n\nGC_INNER void\nGC_remap(ptr_t start, size_t bytes)\n{\n  ptr_t start_addr = GC_unmap_start(start, bytes);\n  ptr_t end_addr = GC_unmap_end(start, bytes);\n  word len = (word)(end_addr - start_addr);\n  if (0 == start_addr)\n    return;\n\n    /* FIXME: Handle out-of-memory correctly (at least for Win32)       */\n#  ifdef USE_WINALLOC\n  while (len != 0) {\n    MEMORY_BASIC_INFORMATION mem_info;\n    word alloc_len;\n    ptr_t result;\n\n    if (VirtualQuery(start_addr, &mem_info, sizeof(mem_info))\n        != sizeof(mem_info))\n      ABORT(\"Weird VirtualQuery result\");\n    alloc_len = (len < mem_info.RegionSize) ? len : mem_info.RegionSize;\n    result = (ptr_t)VirtualAlloc(start_addr, alloc_len, MEM_COMMIT,\n                                 GC_pages_executable ? PAGE_EXECUTE_READWRITE\n                                                     : PAGE_READWRITE);\n    if (result != start_addr) {\n      if (GetLastError() == ERROR_NOT_ENOUGH_MEMORY\n          || GetLastError() == ERROR_OUTOFMEMORY) {\n        ABORT(\"Not enough memory to process remapping\");\n      } else {\n        ABORT(\"VirtualAlloc remapping failed\");\n      }\n    }\n#    ifdef LINT2\n    GC_noop1_ptr(result);\n#    endif\n    GC_ASSERT(GC_unmapped_bytes >= alloc_len);\n    GC_unmapped_bytes -= alloc_len;\n    start_addr += alloc_len;\n    len -= alloc_len;\n  }\n#    undef IGNORE_PAGES_EXECUTABLE\n#  else\n  /* It was already remapped with PROT_NONE. */\n  {\n#    if !defined(SN_TARGET_PS3) && !defined(FORCE_MPROTECT_BEFORE_MADVISE) \\\n        && (defined(LINUX) && !defined(PREFER_MMAP_PROT_NONE)              \\\n            || defined(COSMO))\n    /* Nothing to unprotect as madvise() is just a hint.  */\n#    elif defined(COSMO) || defined(NACL) || defined(NETBSD)\n    /* NaCl does not expose mprotect, but mmap should work fine.  */\n    /* In case of NetBSD, mprotect fails (unlike mmap) even       */\n    /* without PROT_EXEC if PaX MPROTECT feature is enabled.      */\n    void *result = mmap(\n        start_addr, len,\n        (PROT_READ | PROT_WRITE) | (GC_pages_executable ? PROT_EXEC : 0),\n        MAP_PRIVATE | MAP_FIXED | OPT_MAP_ANON, zero_fd, 0 /* offset */);\n    if (EXPECT(MAP_FAILED == result, FALSE))\n      ABORT_ON_REMAP_FAIL(\"remap: mmap\", start_addr, len);\n    if (result != start_addr)\n      ABORT(\"remap: mmap() result differs from start_addr\");\n#      if defined(CPPCHECK) || defined(LINT2)\n    GC_noop1_ptr(result);\n#      endif\n#      undef IGNORE_PAGES_EXECUTABLE\n#    else\n    if (mprotect(start_addr, len,\n                 (PROT_READ | PROT_WRITE)\n                     | (GC_pages_executable ? PROT_EXEC : 0)))\n      ABORT_ON_REMAP_FAIL(\"remap: mprotect\", start_addr, len);\n#      undef IGNORE_PAGES_EXECUTABLE\n#    endif /* !NACL */\n  }\n  GC_ASSERT(GC_unmapped_bytes >= len);\n  GC_unmapped_bytes -= len;\n#  endif\n}\n\n/* Two adjacent blocks have already been unmapped and are about to      */\n/* be merged.  Unmap the whole block.  This typically requires          */\n/* that we unmap a small section in the middle that was not previously  */\n/* unmapped due to alignment constraints.                               */\nGC_INNER void\nGC_unmap_gap(ptr_t start1, size_t bytes1, ptr_t start2, size_t bytes2)\n{\n  ptr_t start1_addr = GC_unmap_start(start1, bytes1);\n  ptr_t end1_addr = GC_unmap_end(start1, bytes1);\n  ptr_t start2_addr = GC_unmap_start(start2, bytes2);\n  ptr_t start_addr = end1_addr;\n  ptr_t end_addr = start2_addr;\n\n  GC_ASSERT(start1 + bytes1 == start2);\n  if (0 == start1_addr)\n    start_addr = GC_unmap_start(start1, bytes1 + bytes2);\n  if (0 == start2_addr)\n    end_addr = GC_unmap_end(start1, bytes1 + bytes2);\n  block_unmap_inner(start_addr, (size_t)(end_addr - start_addr));\n}\n\n#endif /* USE_MUNMAP */\n\n/* Routine for pushing any additional roots.  In the multi-threaded     */\n/* environment, this is also responsible for marking from thread        */\n/* stacks.                                                              */\n#ifndef THREADS\n\n#  if defined(EMSCRIPTEN) && defined(EMSCRIPTEN_ASYNCIFY)\n#    include <emscripten.h>\n\nstatic void\nscan_regs_cb(void *begin, void *finish)\n{\n  GC_push_all_stack((ptr_t)begin, (ptr_t)finish);\n}\n\nSTATIC void GC_CALLBACK\nGC_default_push_other_roots(void)\n{\n  /* Note: this needs -sASYNCIFY linker flag. */\n  emscripten_scan_registers(scan_regs_cb);\n}\n\n#  else\n#    define GC_default_push_other_roots 0\n#  endif\n\n#else /* THREADS */\n\n#  if defined(SN_TARGET_PS3)\nSTATIC void GC_CALLBACK\nGC_default_push_other_roots(void)\n{\n  ABORT(\"GC_default_push_other_roots is not implemented\");\n}\n\nGC_INNER void\nGC_push_thread_structures(void)\n{\n  ABORT(\"GC_push_thread_structures is not implemented\");\n}\n\n#  else /* GC_PTHREADS, etc. */\nSTATIC void GC_CALLBACK\nGC_default_push_other_roots(void)\n{\n  GC_push_all_stacks();\n}\n#  endif\n\n#endif /* THREADS */\n\nGC_push_other_roots_proc GC_push_other_roots = GC_default_push_other_roots;\n\nGC_API void GC_CALL\nGC_set_push_other_roots(GC_push_other_roots_proc fn)\n{\n  GC_push_other_roots = fn;\n}\n\nGC_API GC_push_other_roots_proc GC_CALL\nGC_get_push_other_roots(void)\n{\n  return GC_push_other_roots;\n}\n\n#if defined(SOFT_VDB) && !defined(NO_SOFT_VDB_LINUX_VER_RUNTIME_CHECK) \\\n    || (defined(GLIBC_2_19_TSX_BUG) && defined(GC_PTHREADS_PARAMARK))\nGC_INNER int\nGC_parse_version(int *pminor, const char *pverstr)\n{\n  char *endp;\n  unsigned long value = strtoul(pverstr, &endp, 10);\n  int major = (int)value;\n\n  if (major < 0 || (char *)pverstr == endp || (unsigned)major != value) {\n    /* Parse error.   */\n    return -1;\n  }\n  if (*endp != '.') {\n    /* No minor part. */\n    *pminor = -1;\n  } else {\n    value = strtoul(endp + 1, &endp, 10);\n    *pminor = (int)value;\n    if (*pminor < 0 || (unsigned)(*pminor) != value) {\n      return -1;\n    }\n  }\n  return major;\n}\n#endif\n\n/*\n * Routines for accessing dirty bits on virtual pages.\n * There are six ways to maintain this information:\n * DEFAULT_VDB: A simple dummy implementation that treats every page\n *              as possibly dirty.  This makes incremental collection\n *              useless, but the implementation is still correct.\n * Manual VDB:  Stacks and static data are always considered dirty.\n *              Heap pages are considered dirty if GC_dirty(p) has been\n *              called on some pointer p pointing to somewhere inside\n *              an object on that page.  A GC_dirty() call on a large\n *              object directly dirties only a single page, but for the\n *              manual VDB we are careful to treat an object with a dirty\n *              page as completely dirty.\n *              In order to avoid races, an object must be marked dirty\n *              after it is written, and a reference to the object\n *              must be kept on a stack or in a register in the interim.\n *              With threads enabled, an object directly reachable from the\n *              stack at the time of a collection is treated as dirty.\n *              In single-threaded mode, it suffices to ensure that no\n *              collection can take place between the pointer assignment\n *              and the GC_dirty() call.\n * PROC_VDB:    Use the /proc facility for reading dirty bits.  Only\n *              works under some SVR4 variants.  Even then, it may be\n *              too slow to be entirely satisfactory.  Requires reading\n *              dirty bits for entire address space.  Implementations tend\n *              to assume that the client is a (slow) debugger.\n * SOFT_VDB:    Use the /proc facility for reading soft-dirty PTEs.\n *              Works on Linux 3.18+ if the kernel is properly configured.\n *              The proposed implementation iterates over GC_heap_sects and\n *              GC_static_roots examining the soft-dirty bit of the words\n *              in /proc/self/pagemap corresponding to the pages of the\n *              sections; finally all soft-dirty bits of the process are\n *              cleared (by writing some special value to\n *              /proc/self/clear_refs file).  In case the soft-dirty bit is\n *              not supported by the kernel, MPROTECT_VDB may be defined as\n *              a fallback strategy.\n * MPROTECT_VDB:Protect pages and then catch the faults to keep track of\n *              dirtied pages.  The implementation (and implementability)\n *              is highly system dependent.  This usually fails when system\n *              calls write to a protected page.  We prevent the read system\n *              call from doing so.  It is the clients responsibility to\n *              make sure that other system calls are similarly protected\n *              or write only to the stack.\n * GWW_VDB:     Use the Win32 GetWriteWatch functions, if available, to\n *              read dirty bits.  In case it is not available (because we\n *              are running on Windows 95, Windows 2000 or earlier),\n *              MPROTECT_VDB may be defined as a fallback strategy.\n */\n\n#if (defined(CHECKSUMS) && defined(GWW_VDB)) || defined(PROC_VDB)\n/* Add all pages in pht2 to pht1.   */\nSTATIC void\nGC_or_pages(page_hash_table pht1, const word *pht2)\n{\n  size_t i;\n\n  for (i = 0; i < PHT_SIZE; i++)\n    pht1[i] |= pht2[i];\n}\n#endif /* CHECKSUMS && GWW_VDB || PROC_VDB */\n\n#ifdef GWW_VDB\n\n#  define GC_GWW_BUF_LEN (MAXHINCR * HBLKSIZE / 4096 /* x86 page size */)\n/* Still susceptible to overflow, if there are very large allocations, */\n/* and everything is dirty.                                            */\nstatic PVOID gww_buf[GC_GWW_BUF_LEN];\n\n#  ifndef MPROTECT_VDB\n#    define GC_gww_dirty_init GC_dirty_init\n#  endif\n\nGC_INNER GC_bool\nGC_gww_dirty_init(void)\n{\n  /* No assumption about the allocator lock. */\n  detect_GetWriteWatch();\n  return GC_GWW_AVAILABLE();\n}\n\nGC_INLINE void\nGC_gww_read_dirty(GC_bool output_unneeded)\n{\n  size_t i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!output_unneeded)\n    BZERO(GC_grungy_pages, sizeof(GC_grungy_pages));\n\n  for (i = 0; i < GC_n_heap_sects; ++i) {\n    GC_ULONG_PTR count;\n\n    do {\n      PVOID *pages = gww_buf;\n      DWORD page_size;\n\n      count = GC_GWW_BUF_LEN;\n      /* GetWriteWatch is documented as returning non-zero when it    */\n      /* fails, but the documentation doesn't explicitly say why it   */\n      /* would fail or what its behavior will be if it fails.  It     */\n      /* does appear to fail, at least on recent Win2K instances, if  */\n      /* the underlying memory was not allocated with the appropriate */\n      /* flag.  This is common if GC_enable_incremental is called     */\n      /* shortly after GC initialization.  To avoid modifying the     */\n      /* interface, we silently work around such a failure, it only   */\n      /* affects the initial (small) heap allocation. If there are    */\n      /* more dirty pages than will fit in the buffer, this is not    */\n      /* treated as a failure; we must check the page count in the    */\n      /* loop condition. Since each partial call will reset the       */\n      /* status of some pages, this should eventually terminate even  */\n      /* in the overflow case.                                        */\n      if ((*(GetWriteWatch_type)(GC_funcptr_uint)GetWriteWatch_func)(\n              WRITE_WATCH_FLAG_RESET, GC_heap_sects[i].hs_start,\n              GC_heap_sects[i].hs_bytes, pages, &count, &page_size)\n          != 0) {\n        static int warn_count = 0;\n        struct hblk *start = (struct hblk *)GC_heap_sects[i].hs_start;\n        static const struct hblk *last_warned = NULL;\n        size_t nblocks = divHBLKSZ(GC_heap_sects[i].hs_bytes);\n\n        if (i != 0 && last_warned != start && warn_count++ < 5) {\n          last_warned = start;\n          WARN(\"GC_gww_read_dirty unexpectedly failed at %p:\"\n               \" Falling back to marking all pages dirty\\n\",\n               start);\n        }\n        if (!output_unneeded) {\n          size_t j;\n\n          for (j = 0; j < nblocks; ++j) {\n            size_t index = PHT_HASH(start + j);\n\n            set_pht_entry_from_index(GC_grungy_pages, index);\n          }\n        }\n        /* Done with this section.    */\n        count = 1;\n      } else if (!output_unneeded) { /* succeeded */\n        const PVOID *pages_end = pages + count;\n\n        while (pages != pages_end) {\n          struct hblk *h = (struct hblk *)(*pages++);\n          ptr_t h_end = (ptr_t)h + page_size;\n\n          do {\n            set_pht_entry_from_index(GC_grungy_pages, PHT_HASH(h));\n            h++;\n          } while (ADDR_LT((ptr_t)h, h_end));\n        }\n      }\n    } while (count == GC_GWW_BUF_LEN);\n    /* FIXME: It's unclear from Microsoft's documentation if this loop */\n    /* is useful.  We suspect the call just fails if the buffer fills  */\n    /* up.  But that should still be handled correctly.                */\n  }\n\n#  ifdef CHECKSUMS\n  GC_ASSERT(!output_unneeded);\n  GC_or_pages(GC_written_pages, GC_grungy_pages);\n#  endif\n}\n\n#elif defined(SOFT_VDB)\nstatic int clear_refs_fd = -1;\n#  define GC_GWW_AVAILABLE() (clear_refs_fd != -1)\n#else\n#  define GC_GWW_AVAILABLE() FALSE\n#endif /* !GWW_VDB && !SOFT_VDB */\n\n#ifdef DEFAULT_VDB\n/* The client asserts that unallocated pages in the heap are never    */\n/* written.                                                           */\n\n/* Initialize virtual dirty bit implementation.       */\nGC_INNER GC_bool\nGC_dirty_init(void)\n{\n  GC_VERBOSE_LOG_PRINTF(\"Initializing DEFAULT_VDB...\\n\");\n  /* GC_dirty_pages and GC_grungy_pages are already cleared.  */\n  return TRUE;\n}\n#endif /* DEFAULT_VDB */\n\n#if !defined(NO_MANUAL_VDB) || defined(MPROTECT_VDB)\n#  if !defined(THREADS) || defined(HAVE_LOCKFREE_AO_OR)\n#    ifdef MPROTECT_VDB\n#      define async_set_pht_entry_from_index(db, index) \\\n        set_pht_entry_from_index_concurrent_volatile(db, index)\n#    else\n#      define async_set_pht_entry_from_index(db, index) \\\n        set_pht_entry_from_index_concurrent(db, index)\n#    endif\n#  elif defined(NEED_FAULT_HANDLER_LOCK)\n/* We need to lock around the bitmap update (in the write fault     */\n/* handler or GC_dirty) in order to avoid the risk of losing a bit. */\n/* We do this with a test-and-set spin lock if possible.            */\nstatic void\nasync_set_pht_entry_from_index(volatile page_hash_table db, size_t index)\n{\n  GC_acquire_dirty_lock();\n  set_pht_entry_from_index(db, index);\n  GC_release_dirty_lock();\n}\n#  else /* THREADS && !NEED_FAULT_HANDLER_LOCK */\n#    error No test_and_set operation: Introduces a race.\n#  endif\n#endif /* !NO_MANUAL_VDB || MPROTECT_VDB */\n\n#ifdef MPROTECT_VDB\n/* This implementation maintains dirty bits itself by catching write  */\n/* faults and keeping track of them.  We assume nobody else catches   */\n/* SIGBUS or SIGSEGV.  We assume no write faults occur in system      */\n/* calls.  This means that clients must ensure that system calls do   */\n/* not write to the write-protected heap.  Probably the best way to   */\n/* do this is to ensure that system calls write at most to            */\n/* pointer-free objects in the heap, and do even that only if we are  */\n/* on a platform on which those are not protected (or the collector   */\n/* is built with DONT_PROTECT_PTRFREE defined).  We assume the page   */\n/* size is a multiple of HBLKSIZE.                                    */\n\n#  ifdef DARWIN\n/* #define BROKEN_EXCEPTION_HANDLING */\n\n/* Using vm_protect (mach syscall) over mprotect (BSD syscall)      */\n/* seems to decrease the likelihood of some of the problems         */\n/* described below.                                                 */\n#    include <mach/vm_map.h>\nSTATIC mach_port_t GC_task_self = 0;\n#    define PROTECT_INNER(addr, len, allow_write, C_msg_prefix)            \\\n      if (vm_protect(GC_task_self, (vm_address_t)(addr), (vm_size_t)(len), \\\n                     FALSE,                                                \\\n                     VM_PROT_READ | ((allow_write) ? VM_PROT_WRITE : 0)    \\\n                         | (GC_pages_executable ? VM_PROT_EXECUTE : 0))    \\\n          == KERN_SUCCESS) {                                               \\\n      } else                                                               \\\n        ABORT(C_msg_prefix \"vm_protect() failed\")\n\n#  elif !defined(USE_WINALLOC)\n#    include <sys/mman.h>\n#    if !defined(AIX) && !defined(CYGWIN32) && !defined(HAIKU)\n#      include <sys/syscall.h>\n#    endif\n\n#    define PROTECT_INNER(addr, len, allow_write, C_msg_prefix)           \\\n      if (mprotect((caddr_t)(addr), (size_t)(len),                        \\\n                   PROT_READ | ((allow_write) ? PROT_WRITE : 0)           \\\n                       | (GC_pages_executable ? PROT_EXEC : 0))           \\\n          >= 0) {                                                         \\\n      } else if (GC_pages_executable) {                                   \\\n        ABORT_ON_REMAP_FAIL(C_msg_prefix \"mprotect vdb executable pages\", \\\n                            addr, len);                                   \\\n      } else                                                              \\\n        ABORT_ON_REMAP_FAIL(C_msg_prefix \"mprotect vdb\", addr, len)\n#    undef IGNORE_PAGES_EXECUTABLE\n\n#  else /* USE_WINALLOC */\nstatic DWORD protect_junk;\n#    define PROTECT_INNER(addr, len, allow_write, C_msg_prefix)             \\\n      if (VirtualProtect(addr, len,                                         \\\n                         GC_pages_executable                                \\\n                             ? ((allow_write) ? PAGE_EXECUTE_READWRITE      \\\n                                              : PAGE_EXECUTE_READ)          \\\n                         : (allow_write) ? PAGE_READWRITE                   \\\n                                         : PAGE_READONLY,                   \\\n                         &protect_junk)) {                                  \\\n      } else                                                                \\\n        ABORT_ARG1(C_msg_prefix \"VirtualProtect failed\", \": errcode= 0x%X\", \\\n                   (unsigned)GetLastError())\n#  endif /* USE_WINALLOC */\n\n#  define PROTECT(addr, len) PROTECT_INNER(addr, len, FALSE, \"\")\n#  define UNPROTECT(addr, len) PROTECT_INNER(addr, len, TRUE, \"un-\")\n\n#  if defined(MSWIN32)\ntypedef LPTOP_LEVEL_EXCEPTION_FILTER SIG_HNDLR_PTR;\n#    undef SIG_DFL\n#    define SIG_DFL ((LPTOP_LEVEL_EXCEPTION_FILTER)(~(GC_funcptr_uint)0))\n#  elif defined(MSWINCE)\ntypedef LONG(WINAPI *SIG_HNDLR_PTR)(struct _EXCEPTION_POINTERS *);\n#    undef SIG_DFL\n#    define SIG_DFL ((SIG_HNDLR_PTR)(~(GC_funcptr_uint)0))\n#  elif defined(DARWIN)\n#    ifdef BROKEN_EXCEPTION_HANDLING\ntypedef void (*SIG_HNDLR_PTR)();\n#    endif\n#  else\ntypedef void (*SIG_HNDLR_PTR)(int, siginfo_t *, void *);\ntypedef void (*PLAIN_HNDLR_PTR)(int);\n#  endif /* !DARWIN && !MSWIN32 && !MSWINCE */\n\n#  ifndef DARWIN\n/* Also old MSWIN32 ACCESS_VIOLATION filter.  */\nSTATIC SIG_HNDLR_PTR GC_old_segv_handler = 0;\n#    ifdef USE_BUS_SIGACT\nSTATIC SIG_HNDLR_PTR GC_old_bus_handler = 0;\nSTATIC GC_bool GC_old_bus_handler_used_si = FALSE;\n#    endif\n#    if !defined(MSWIN32) && !defined(MSWINCE)\nSTATIC GC_bool GC_old_segv_handler_used_si = FALSE;\n#    endif\n#  endif /* !DARWIN */\n\n#  ifdef THREADS\n/* This function is used only by the fault handler.  Potential data   */\n/* race between this function and GC_install_header, GC_remove_header */\n/* should not be harmful because the added or removed header should   */\n/* be already unprotected.                                            */\nGC_ATTR_NO_SANITIZE_THREAD\nstatic GC_bool\nis_header_found_async(const void *p)\n{\n#    ifdef HASH_TL\n  hdr *result;\n\n  GET_HDR(p, result);\n  return result != NULL;\n#    else\n  return HDR_INNER(p) != NULL;\n#    endif\n}\n#  else\n#    define is_header_found_async(p) (HDR(p) != NULL)\n#  endif /* !THREADS */\n\n#  ifndef DARWIN\n\n#    if !defined(MSWIN32) && !defined(MSWINCE)\n#      include <errno.h>\n#      ifdef USE_BUS_SIGACT\n#        define SIG_OK (sig == SIGBUS || sig == SIGSEGV)\n#      else\n/* Catch SIGSEGV but ignore SIGBUS.       */\n#        define SIG_OK (sig == SIGSEGV)\n#      endif\n#      if defined(FREEBSD) || defined(OPENBSD)\n#        ifndef SEGV_ACCERR\n#          define SEGV_ACCERR 2\n#        endif\n#        if defined(AARCH64) || defined(ARM32) || defined(MIPS) \\\n            || (__FreeBSD__ >= 7 || defined(OPENBSD))\n#          define CODE_OK (si->si_code == SEGV_ACCERR)\n#        elif defined(POWERPC)\n/* Pretend that we are AIM.     */\n#          define AIM\n#          include <machine/trap.h>\n#          define CODE_OK \\\n            (si->si_code == EXC_DSI || si->si_code == SEGV_ACCERR)\n#        else\n#          define CODE_OK \\\n            (si->si_code == BUS_PAGE_FAULT || si->si_code == SEGV_ACCERR)\n#        endif\n#      elif defined(OSF1)\n#        define CODE_OK (si->si_code == 2 /* experimentally determined */)\n#      elif defined(IRIX5)\n#        define CODE_OK (si->si_code == EACCES)\n#      elif defined(AIX) || defined(COSMO) || defined(CYGWIN32) \\\n          || defined(HAIKU) || defined(HURD) || defined(LINUX)  \\\n          || defined(NETBSD)\n/* Linux: Empirically c.trapno == 14, on IA32, but is that useful?      */\n/* Should probably consider alignment issues on other architectures.    */\n#        define CODE_OK TRUE\n#      elif defined(HPUX)\n#        define CODE_OK                                                 \\\n          (si->si_code == SEGV_ACCERR || si->si_code == BUS_ADRERR      \\\n           || si->si_code == BUS_UNKNOWN || si->si_code == SEGV_UNKNOWN \\\n           || si->si_code == BUS_OBJERR)\n#      elif defined(SUNOS5SIGS)\n#        define CODE_OK (si->si_code == SEGV_ACCERR)\n#      endif\n#      ifndef NO_GETCONTEXT\n#        include <ucontext.h>\n#      endif\nSTATIC void\nGC_write_fault_handler(int sig, siginfo_t *si, void *raw_sc)\n#    else /* MSWIN32 || MSWINCE */\n#      define SIG_OK \\\n        (exc_info->ExceptionRecord->ExceptionCode == STATUS_ACCESS_VIOLATION)\n#      define CODE_OK                                       \\\n        (exc_info->ExceptionRecord->ExceptionInformation[0] \\\n         == 1) /* write fault */\nSTATIC LONG WINAPI\nGC_write_fault_handler(struct _EXCEPTION_POINTERS *exc_info)\n#    endif\n{\n#    if !defined(MSWIN32) && !defined(MSWINCE)\n  char *addr = (char *)si->si_addr;\n#    else\n  char *addr = (char *)exc_info->ExceptionRecord->ExceptionInformation[1];\n#    endif\n\n  if (SIG_OK && CODE_OK) {\n    struct hblk *h = HBLK_PAGE_ALIGNED(addr);\n    GC_bool in_allocd_block;\n    size_t i;\n\n    GC_ASSERT(GC_page_size != 0);\n#    ifdef CHECKSUMS\n    GC_record_fault(h);\n#    endif\n#    ifdef SUNOS5SIGS\n    /* Address is only within the correct physical page.        */\n    in_allocd_block = FALSE;\n    for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n      if (is_header_found_async(&h[i])) {\n        in_allocd_block = TRUE;\n        break;\n      }\n    }\n#    else\n    in_allocd_block = is_header_found_async(addr);\n#    endif\n    if (!in_allocd_block) {\n      /* FIXME - We should make sure that we invoke the   */\n      /* old handler with the appropriate calling         */\n      /* sequence, which often depends on SA_SIGINFO.     */\n\n      /* Heap blocks now begin and end on page boundaries.    */\n      SIG_HNDLR_PTR old_handler;\n\n#    if defined(MSWIN32) || defined(MSWINCE)\n      old_handler = GC_old_segv_handler;\n#    else\n      GC_bool used_si;\n\n#      ifdef USE_BUS_SIGACT\n      if (sig == SIGBUS) {\n        old_handler = GC_old_bus_handler;\n        used_si = GC_old_bus_handler_used_si;\n      } else\n#      endif\n      /* else */ {\n        old_handler = GC_old_segv_handler;\n        used_si = GC_old_segv_handler_used_si;\n      }\n#    endif\n\n      if ((GC_funcptr_uint)old_handler == (GC_funcptr_uint)SIG_DFL) {\n#    if !defined(MSWIN32) && !defined(MSWINCE)\n        ABORT_ARG1(\"Unexpected segmentation fault outside heap\", \" at %p\",\n                   (void *)addr);\n#    else\n        return EXCEPTION_CONTINUE_SEARCH;\n#    endif\n      } else {\n        /* FIXME: This code should probably check if the old    */\n        /* signal handler used the traditional style and if so, */\n        /* call it using that style.                            */\n#    if defined(MSWIN32) || defined(MSWINCE)\n        return (*old_handler)(exc_info);\n#    else\n        if (used_si)\n          ((SIG_HNDLR_PTR)old_handler)(sig, si, raw_sc);\n        else\n          /* FIXME: should pass nonstandard args as well. */\n          ((PLAIN_HNDLR_PTR)(GC_funcptr_uint)old_handler)(sig);\n        return;\n#    endif\n      }\n    }\n    UNPROTECT(h, GC_page_size);\n    /* We need to make sure that no collection occurs between       */\n    /* the UNPROTECT and the setting of the dirty bit.  Otherwise   */\n    /* a write by a third thread might go unnoticed.  Reversing     */\n    /* the order is just as bad, since we would end up unprotecting */\n    /* a page in a GC cycle during which it's not marked.           */\n    /* Currently we do this by disabling the thread stopping        */\n    /* signals while this handler is running.  An alternative might */\n    /* be to record the fact that we're about to unprotect, or      */\n    /* have just unprotected a page in the GC's thread structure,   */\n    /* and then to have the thread stopping code set the dirty      */\n    /* flag, if necessary.                                          */\n    for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n      size_t index = PHT_HASH(h + i);\n\n      async_set_pht_entry_from_index(GC_dirty_pages, index);\n    }\n    /* The write() may not take place before dirty bits are read.   */\n    /* But then we'll fault again ...                               */\n#    if defined(MSWIN32) || defined(MSWINCE)\n    return EXCEPTION_CONTINUE_EXECUTION;\n#    else\n    return;\n#    endif\n  }\n#    if defined(MSWIN32) || defined(MSWINCE)\n  return EXCEPTION_CONTINUE_SEARCH;\n#    else\n  ABORT_ARG1(\"Unexpected bus error or segmentation fault\", \" at %p\",\n             (void *)addr);\n#    endif\n}\n\n#    if defined(GC_WIN32_THREADS) && !defined(CYGWIN32)\nGC_INNER void\nGC_set_write_fault_handler(void)\n{\n  SetUnhandledExceptionFilter(GC_write_fault_handler);\n}\n#    endif\n\n#    ifdef SOFT_VDB\nstatic GC_bool soft_dirty_init(void);\n#    endif\n\nGC_INNER GC_bool\nGC_dirty_init(void)\n{\n#    if !defined(MSWIN32) && !defined(MSWINCE)\n  struct sigaction act, oldact;\n#    endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n#    ifdef COUNT_PROTECTED_REGIONS\n  GC_ASSERT(GC_page_size != 0);\n  if ((GC_signed_word)(GC_heapsize / (word)GC_page_size)\n      >= ((GC_signed_word)GC_UNMAPPED_REGIONS_SOFT_LIMIT\n          - GC_num_unmapped_regions)\n             * 2) {\n    GC_COND_LOG_PRINTF(\"Cannot turn on GC incremental mode\"\n                       \" as heap contains too many pages\\n\");\n    return FALSE;\n  }\n#    endif\n#    if !defined(MSWIN32) && !defined(MSWINCE)\n  act.sa_flags = SA_RESTART | SA_SIGINFO;\n  act.sa_sigaction = GC_write_fault_handler;\n  (void)sigemptyset(&act.sa_mask);\n#      ifdef SIGNAL_BASED_STOP_WORLD\n  /* Arrange to postpone the signal while we are in a write fault */\n  /* handler.  This effectively makes the handler atomic w.r.t.   */\n  /* stopping the world for GC.                                   */\n  (void)sigaddset(&act.sa_mask, GC_get_suspend_signal());\n#      endif\n#    endif /* !MSWIN32 */\n  GC_VERBOSE_LOG_PRINTF(\n      \"Initializing mprotect virtual dirty bit implementation\\n\");\n  if (GC_page_size % HBLKSIZE != 0) {\n    ABORT(\"Page size not multiple of HBLKSIZE\");\n  }\n#    ifdef GWW_VDB\n  if (GC_gww_dirty_init()) {\n    GC_COND_LOG_PRINTF(\"Using GetWriteWatch()\\n\");\n    return TRUE;\n  }\n#    elif defined(SOFT_VDB)\n#      ifdef CHECK_SOFT_VDB\n  if (!soft_dirty_init())\n    ABORT(\"Soft-dirty bit support is missing\");\n#      else\n  if (soft_dirty_init()) {\n    GC_COND_LOG_PRINTF(\"Using soft-dirty bit feature\\n\");\n    return TRUE;\n  }\n#      endif\n#    endif\n#    ifdef MSWIN32\n  GC_old_segv_handler = SetUnhandledExceptionFilter(GC_write_fault_handler);\n  if (GC_old_segv_handler != NULL) {\n    GC_COND_LOG_PRINTF(\"Replaced other UnhandledExceptionFilter\\n\");\n  } else {\n    GC_old_segv_handler = SIG_DFL;\n  }\n#    elif defined(MSWINCE)\n    /* MPROTECT_VDB is unsupported for WinCE at present.      */\n    /* FIXME: implement it (if possible). */\n#    else\n  /* act.sa_restorer is deprecated and should not be initialized. */\n#      if defined(IRIX5) && defined(THREADS)\n  sigaction(SIGSEGV, 0, &oldact);\n  sigaction(SIGSEGV, &act, 0);\n#      else\n  {\n    int res = sigaction(SIGSEGV, &act, &oldact);\n    if (res != 0)\n      ABORT(\"Sigaction failed\");\n  }\n#      endif\n  if (oldact.sa_flags & SA_SIGINFO) {\n    GC_old_segv_handler = oldact.sa_sigaction;\n    GC_old_segv_handler_used_si = TRUE;\n  } else {\n    GC_old_segv_handler = (SIG_HNDLR_PTR)(GC_funcptr_uint)oldact.sa_handler;\n    GC_old_segv_handler_used_si = FALSE;\n  }\n  if ((GC_funcptr_uint)GC_old_segv_handler == (GC_funcptr_uint)SIG_IGN) {\n    WARN(\"Previously ignored segmentation violation!?\\n\", 0);\n    GC_old_segv_handler = (SIG_HNDLR_PTR)(GC_funcptr_uint)SIG_DFL;\n  }\n  if ((GC_funcptr_uint)GC_old_segv_handler != (GC_funcptr_uint)SIG_DFL) {\n    GC_VERBOSE_LOG_PRINTF(\"Replaced other SIGSEGV handler\\n\");\n  }\n#      ifdef USE_BUS_SIGACT\n  sigaction(SIGBUS, &act, &oldact);\n  if ((oldact.sa_flags & SA_SIGINFO) != 0) {\n    GC_old_bus_handler = oldact.sa_sigaction;\n    GC_old_bus_handler_used_si = TRUE;\n  } else {\n    GC_old_bus_handler = (SIG_HNDLR_PTR)(GC_funcptr_uint)oldact.sa_handler;\n  }\n  if ((GC_funcptr_uint)GC_old_bus_handler == (GC_funcptr_uint)SIG_IGN) {\n    WARN(\"Previously ignored bus error!?\\n\", 0);\n    GC_old_bus_handler = (SIG_HNDLR_PTR)(GC_funcptr_uint)SIG_DFL;\n  } else if ((GC_funcptr_uint)GC_old_bus_handler != (GC_funcptr_uint)SIG_DFL) {\n    GC_VERBOSE_LOG_PRINTF(\"Replaced other SIGBUS handler\\n\");\n  }\n#      endif\n#    endif /* !MSWIN32 && !MSWINCE */\n#    if defined(CPPCHECK) && defined(ADDRESS_SANITIZER)\n  GC_noop1((word)(GC_funcptr_uint)(&__asan_default_options));\n#    endif\n  return TRUE;\n}\n#  endif /* !DARWIN */\n\nSTATIC void\nGC_protect_heap(void)\n{\n  size_t i;\n\n  GC_ASSERT(GC_page_size != 0);\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    ptr_t start = GC_heap_sects[i].hs_start;\n    size_t len = GC_heap_sects[i].hs_bytes;\n    struct hblk *current;\n    struct hblk *current_start; /* start of block to be protected */\n    ptr_t limit;\n\n    GC_ASSERT((ADDR(start) & (GC_page_size - 1)) == 0);\n    GC_ASSERT((len & (GC_page_size - 1)) == 0);\n#  ifndef DONT_PROTECT_PTRFREE\n    /* We avoid protecting pointer-free objects unless the page   */\n    /* size differs from HBLKSIZE.                                */\n    if (GC_page_size != HBLKSIZE) {\n      PROTECT(start, len);\n      continue;\n    }\n#  endif\n\n    current_start = (struct hblk *)start;\n    limit = start + len;\n    for (current = current_start;;) {\n      size_t nblocks = 0;\n      GC_bool is_ptrfree = TRUE;\n\n      if (ADDR_LT((ptr_t)current, limit)) {\n        hdr *hhdr;\n\n        GET_HDR(current, hhdr);\n        if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n          /* This can happen only if we are at the beginning of a heap  */\n          /* segment, and a block spans heap segments.  We will handle  */\n          /* that block as part of the preceding segment.               */\n          GC_ASSERT(current_start == current);\n\n          current_start = ++current;\n          continue;\n        }\n        if (HBLK_IS_FREE(hhdr)) {\n          GC_ASSERT(modHBLKSZ(hhdr->hb_sz) == 0);\n          nblocks = divHBLKSZ(hhdr->hb_sz);\n        } else {\n          nblocks = OBJ_SZ_TO_BLOCKS(hhdr->hb_sz);\n          is_ptrfree = IS_PTRFREE(hhdr);\n        }\n      }\n      if (is_ptrfree) {\n        if (ADDR_LT((ptr_t)current_start, (ptr_t)current)) {\n#  ifdef DONT_PROTECT_PTRFREE\n          ptr_t cur_aligned = PTR_ALIGN_UP((ptr_t)current, GC_page_size);\n\n          current_start = HBLK_PAGE_ALIGNED(current_start);\n          /* Adjacent free blocks might be protected too because  */\n          /* of the alignment by the page size.                   */\n          PROTECT(current_start, cur_aligned - (ptr_t)current_start);\n#  else\n          PROTECT(current_start, (ptr_t)current - (ptr_t)current_start);\n#  endif\n        }\n        if (ADDR_GE((ptr_t)current, limit))\n          break;\n      }\n      current += nblocks;\n      if (is_ptrfree)\n        current_start = current;\n    }\n  }\n}\n\n#  if defined(CAN_HANDLE_FORK) && defined(DARWIN) && defined(THREADS) \\\n      || defined(COUNT_PROTECTED_REGIONS)\n/* Remove protection for the entire heap not updating GC_dirty_pages. */\nSTATIC void\nGC_unprotect_all_heap(void)\n{\n  size_t i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_auto_incremental);\n  for (i = 0; i < GC_n_heap_sects; i++) {\n    UNPROTECT(GC_heap_sects[i].hs_start, GC_heap_sects[i].hs_bytes);\n  }\n}\n#  endif\n\n#  ifdef COUNT_PROTECTED_REGIONS\nGC_INNER void\nGC_handle_protected_regions_limit(void)\n{\n  GC_ASSERT(GC_page_size != 0);\n  /* To prevent exceeding the limit of vm.max_map_count, the most */\n  /* trivial (though highly restrictive) way is to turn off the   */\n  /* incremental collection mode (based on mprotect) once the     */\n  /* number of pages in the heap reaches that limit.              */\n  if (GC_auto_incremental && !GC_GWW_AVAILABLE()\n      && (GC_signed_word)(GC_heapsize / (word)GC_page_size)\n             >= ((GC_signed_word)GC_UNMAPPED_REGIONS_SOFT_LIMIT\n                 - GC_num_unmapped_regions)\n                    * 2) {\n    GC_unprotect_all_heap();\n#    ifdef DARWIN\n    GC_task_self = 0;\n#    endif\n    GC_incremental = FALSE;\n    WARN(\"GC incremental mode is turned off\"\n         \" to prevent hitting VM maps limit\\n\",\n         0);\n  }\n}\n#  endif /* COUNT_PROTECTED_REGIONS */\n\n#endif /* MPROTECT_VDB */\n\n#if !defined(THREADS) && (defined(PROC_VDB) || defined(SOFT_VDB))\nstatic pid_t saved_proc_pid; /* pid used to compose /proc file names */\n#endif\n\n#ifdef PROC_VDB\n/* This implementation assumes a Solaris 2.X like /proc               */\n/* pseudo-file-system from which we can read page modified bits.      */\n/* This facility is far from optimal (e.g. we would like to get the   */\n/* info for only some of the address space), but it avoids            */\n/* intercepting system calls.                                         */\n\n#  include <errno.h>\n#  include <sys/signal.h>\n#  include <sys/stat.h>\n#  include <sys/syscall.h>\n\n#  ifdef GC_NO_SYS_FAULT_H\n/* This exists only to check PROC_VDB code compilation (on Linux).  */\n#    define PG_MODIFIED 1\nstruct prpageheader {\n  int dummy[2]; /* pr_tstamp */\n  unsigned long pr_nmap;\n  unsigned long pr_npage;\n};\nstruct prasmap {\n  char *pr_vaddr;\n  size_t pr_npage;\n  char dummy1[64 + 8]; /* pr_mapname, pr_offset */\n  unsigned pr_mflags;\n  unsigned pr_pagesize;\n  int dummy2[2];\n};\n#  else\n#    include <sys/fault.h>\n#    include <sys/procfs.h>\n#  endif\n\n#  define INITIAL_BUF_SZ 16384\nSTATIC size_t GC_proc_buf_size = INITIAL_BUF_SZ;\nSTATIC char *GC_proc_buf = NULL;\nSTATIC int GC_proc_fd = -1;\n\nstatic GC_bool\nproc_dirty_open_files(void)\n{\n  char buf[40];\n  pid_t pid = getpid();\n\n  (void)snprintf(buf, sizeof(buf), \"/proc/%ld/pagedata\", (long)pid);\n  buf[sizeof(buf) - 1] = '\\0';\n  GC_proc_fd = open(buf, O_RDONLY);\n  if (-1 == GC_proc_fd) {\n    WARN(\"/proc open failed; cannot enable GC incremental mode\\n\", 0);\n    return FALSE;\n  }\n  if (syscall(SYS_fcntl, GC_proc_fd, F_SETFD, FD_CLOEXEC) == -1)\n    WARN(\"Could not set FD_CLOEXEC for /proc\\n\", 0);\n#  ifndef THREADS\n  /* Updated on success only.       */\n  saved_proc_pid = pid;\n#  endif\n  return TRUE;\n}\n\n#  ifdef CAN_HANDLE_FORK\nGC_INNER void\nGC_dirty_update_child(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (-1 == GC_proc_fd) {\n    /* The GC incremental mode is off.      */\n    return;\n  }\n  close(GC_proc_fd);\n  if (!proc_dirty_open_files()) {\n    /* Should be safe to turn it off.       */\n    GC_incremental = FALSE;\n  }\n}\n#  endif /* CAN_HANDLE_FORK */\n\nGC_INNER GC_bool\nGC_dirty_init(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_bytes_allocd != 0 || GC_bytes_allocd_before_gc != 0) {\n    memset(GC_written_pages, 0xff, sizeof(page_hash_table));\n    GC_VERBOSE_LOG_PRINTF(\n        \"Allocated %lu bytes: all pages may have been written\\n\",\n        (unsigned long)(GC_bytes_allocd + GC_bytes_allocd_before_gc));\n  }\n  if (!proc_dirty_open_files())\n    return FALSE;\n  GC_proc_buf = GC_scratch_alloc(GC_proc_buf_size);\n  if (GC_proc_buf == NULL)\n    ABORT(\"Insufficient space for /proc read\");\n  return TRUE;\n}\n\nGC_INLINE void\nGC_proc_read_dirty(GC_bool output_unneeded)\n{\n  size_t i, nmaps;\n  char *bufp = GC_proc_buf;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifndef THREADS\n  /* If the current pid differs from the saved one, then we are in  */\n  /* the forked (child) process, the current /proc file should be   */\n  /* closed, the new one should be opened with the updated path.    */\n  /* Note, this is not needed for multi-threaded case because       */\n  /* fork_child_proc() reopens the file right after fork.           */\n  if (getpid() != saved_proc_pid\n      && (-1 == GC_proc_fd /* no need to retry */\n          || (close(GC_proc_fd), !proc_dirty_open_files()))) {\n    /* Failed to reopen the file.  Punt!    */\n    if (!output_unneeded)\n      memset(GC_grungy_pages, 0xff, sizeof(page_hash_table));\n    memset(GC_written_pages, 0xff, sizeof(page_hash_table));\n    return;\n  }\n#  endif\n\n  BZERO(GC_grungy_pages, sizeof(GC_grungy_pages));\n  if (PROC_READ(GC_proc_fd, bufp, GC_proc_buf_size) <= 0) {\n    /* Retry with larger buffer.    */\n    size_t new_size = 2 * GC_proc_buf_size;\n    char *new_buf;\n\n    WARN(\"/proc read failed (buffer size is %\" WARN_PRIuPTR \" bytes)\\n\",\n         GC_proc_buf_size);\n    new_buf = GC_scratch_alloc(new_size);\n    if (new_buf != 0) {\n      GC_scratch_recycle_no_gww(bufp, GC_proc_buf_size);\n      GC_proc_buf = bufp = new_buf;\n      GC_proc_buf_size = new_size;\n    }\n    if (PROC_READ(GC_proc_fd, bufp, GC_proc_buf_size) <= 0) {\n      WARN(\"Insufficient space for /proc read\\n\", 0);\n      /* Punt:        */\n      if (!output_unneeded)\n        memset(GC_grungy_pages, 0xff, sizeof(page_hash_table));\n      memset(GC_written_pages, 0xff, sizeof(page_hash_table));\n      return;\n    }\n  }\n\n  /* Copy dirty bits into GC_grungy_pages.    */\n  nmaps = (size_t)(((struct prpageheader *)bufp)->pr_nmap);\n#  ifdef DEBUG_DIRTY_BITS\n  GC_log_printf(\"Proc VDB read: pr_nmap= %u, pr_npage= %lu\\n\", (unsigned)nmaps,\n                ((struct prpageheader *)bufp)->pr_npage);\n#  endif\n#  if defined(GC_NO_SYS_FAULT_H) && defined(CPPCHECK)\n  GC_noop1(((struct prpageheader *)bufp)->dummy[0]);\n#  endif\n  bufp += sizeof(struct prpageheader);\n  for (i = 0; i < nmaps; i++) {\n    struct prasmap *map = (struct prasmap *)bufp;\n    ptr_t vaddr = (ptr_t)map->pr_vaddr;\n    unsigned long npages = map->pr_npage;\n    unsigned pagesize = map->pr_pagesize;\n    ptr_t limit;\n\n#  if defined(GC_NO_SYS_FAULT_H) && defined(CPPCHECK)\n    GC_noop1(map->dummy1[0] + map->dummy2[0]);\n#  endif\n#  ifdef DEBUG_DIRTY_BITS\n    GC_log_printf(\"pr_vaddr= %p, npage= %lu, mflags= 0x%x, pagesize= 0x%x\\n\",\n                  (void *)vaddr, npages, map->pr_mflags, pagesize);\n#  endif\n\n    bufp += sizeof(struct prasmap);\n    limit = vaddr + pagesize * npages;\n    for (; ADDR_LT(vaddr, limit); vaddr += pagesize) {\n      if ((*bufp++) & PG_MODIFIED) {\n        struct hblk *h;\n        ptr_t next_vaddr = vaddr + pagesize;\n\n#  ifdef DEBUG_DIRTY_BITS\n        GC_log_printf(\"dirty page at: %p\\n\", (void *)vaddr);\n#  endif\n        for (h = (struct hblk *)vaddr; ADDR_LT((ptr_t)h, next_vaddr); h++) {\n          size_t index = PHT_HASH(h);\n\n          set_pht_entry_from_index(GC_grungy_pages, index);\n        }\n      }\n    }\n    bufp = PTR_ALIGN_UP(bufp, sizeof(long));\n  }\n#  ifdef DEBUG_DIRTY_BITS\n  GC_log_printf(\"Proc VDB read done\\n\");\n#  endif\n\n  /* Update GC_written_pages (even if output_unneeded).       */\n  GC_or_pages(GC_written_pages, GC_grungy_pages);\n}\n\n#endif /* PROC_VDB */\n\n#ifdef SOFT_VDB\n#  ifndef VDB_BUF_SZ\n#    define VDB_BUF_SZ 16384\n#  endif\n\nstatic int\nopen_proc_fd(pid_t pid, const char *proc_filename, int mode)\n{\n  int f;\n  char buf[40];\n\n  (void)snprintf(buf, sizeof(buf), \"/proc/%ld/%s\", (long)pid, proc_filename);\n  buf[sizeof(buf) - 1] = '\\0';\n  f = open(buf, mode);\n  if (-1 == f) {\n    WARN(\"/proc/self/%s open failed; cannot enable GC incremental mode\\n\",\n         proc_filename);\n  } else if (fcntl(f, F_SETFD, FD_CLOEXEC) == -1) {\n    WARN(\"Could not set FD_CLOEXEC for /proc\\n\", 0);\n  }\n  return f;\n}\n\n#  include <stdint.h> /* for uint64_t */\n\ntypedef uint64_t pagemap_elem_t;\n\nstatic pagemap_elem_t *soft_vdb_buf;\nstatic int pagemap_fd;\n\nstatic GC_bool\nsoft_dirty_open_files(void)\n{\n  pid_t pid = getpid();\n\n  clear_refs_fd = open_proc_fd(pid, \"clear_refs\", O_WRONLY);\n  if (-1 == clear_refs_fd)\n    return FALSE;\n  pagemap_fd = open_proc_fd(pid, \"pagemap\", O_RDONLY);\n  if (-1 == pagemap_fd) {\n    close(clear_refs_fd);\n    clear_refs_fd = -1;\n    return FALSE;\n  }\n#  ifndef THREADS\n  /* Updated on success only.       */\n  saved_proc_pid = pid;\n#  endif\n  return TRUE;\n}\n\n#  ifdef CAN_HANDLE_FORK\nGC_INNER void\nGC_dirty_update_child(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (-1 == clear_refs_fd) {\n    /* The GC incremental mode is off.      */\n    return;\n  }\n  close(clear_refs_fd);\n  close(pagemap_fd);\n  if (!soft_dirty_open_files())\n    GC_incremental = FALSE;\n}\n#  endif /* CAN_HANDLE_FORK */\n\n/* Clear soft-dirty bits from the task's PTEs.        */\nstatic void\nclear_soft_dirty_bits(void)\n{\n  ssize_t res = write(clear_refs_fd, \"4\\n\", 2);\n\n  if (res != 2)\n    ABORT_ARG1(\"Failed to write to /proc/self/clear_refs\", \": errno= %d\",\n               res < 0 ? errno : 0);\n}\n\n/* The bit 55 of the 64-bit qword of pagemap file is the soft-dirty one. */\n#  define PM_SOFTDIRTY_MASK ((pagemap_elem_t)1 << 55)\n\nstatic GC_bool\ndetect_soft_dirty_supported(ptr_t vaddr)\n{\n  off_t fpos;\n  pagemap_elem_t buf[1];\n\n  GC_ASSERT(GC_log_pagesize != 0);\n  /* Make it dirty.   */\n  *vaddr = 1;\n  fpos = (off_t)((ADDR(vaddr) >> GC_log_pagesize) * sizeof(pagemap_elem_t));\n\n  for (;;) {\n    /* Read the relevant PTE from the pagemap file.   */\n    if (lseek(pagemap_fd, fpos, SEEK_SET) == (off_t)(-1))\n      return FALSE;\n    if (PROC_READ(pagemap_fd, buf, sizeof(buf)) != (int)sizeof(buf))\n      return FALSE;\n\n    /* Is the soft-dirty bit unset?   */\n    if ((buf[0] & PM_SOFTDIRTY_MASK) == 0)\n      return FALSE;\n\n    if (0 == *vaddr)\n      break;\n    /* Retry to check that writing to clear_refs works as expected.   */\n    /* This malfunction of the soft-dirty bits implementation is      */\n    /* observed on some Linux kernels on Power9 (e.g. in Fedora 36).  */\n    clear_soft_dirty_bits();\n    *vaddr = 0;\n  }\n  return TRUE; /* success */\n}\n\n#  ifndef NO_SOFT_VDB_LINUX_VER_RUNTIME_CHECK\n#    include <string.h> /* for strcmp() */\n#    include <sys/utsname.h>\n\n/* Ensure the linux (kernel) major/minor version is as given or higher. */\nstatic GC_bool\nensure_min_linux_ver(int major, int minor)\n{\n  struct utsname info;\n  int actual_major;\n  int actual_minor = -1;\n\n  if (uname(&info) == -1) {\n    /* uname() failed, should not happen actually.  */\n    return FALSE;\n  }\n  if (strcmp(info.sysname, \"Linux\")) {\n    WARN(\"Cannot ensure Linux version as running on other OS: %s\\n\",\n         info.sysname);\n    return FALSE;\n  }\n  actual_major = GC_parse_version(&actual_minor, info.release);\n  return actual_major > major\n         || (actual_major == major && actual_minor >= minor);\n}\n#  endif\n\n#  ifdef MPROTECT_VDB\nstatic GC_bool\nsoft_dirty_init(void)\n#  else\nGC_INNER GC_bool\nGC_dirty_init(void)\n#  endif\n{\n#  if defined(MPROTECT_VDB) && !defined(CHECK_SOFT_VDB)\n  char *str = GETENV(\"GC_USE_GETWRITEWATCH\");\n#    ifdef GC_PREFER_MPROTECT_VDB\n  if (NULL == str || (*str == '0' && *(str + 1) == '\\0')) {\n    /* The environment variable is unset or set to \"0\".   */\n    return FALSE;\n  }\n#    else\n  if (str != NULL && *str == '0' && *(str + 1) == '\\0') {\n    /* The environment variable is set \"0\".       */\n    return FALSE;\n  }\n#    endif\n#  endif\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(NULL == soft_vdb_buf);\n#  ifndef NO_SOFT_VDB_LINUX_VER_RUNTIME_CHECK\n  if (!ensure_min_linux_ver(3, 18)) {\n    GC_COND_LOG_PRINTF(\n        \"Running on old kernel lacking correct soft-dirty bit support\\n\");\n    return FALSE;\n  }\n#  endif\n  if (!soft_dirty_open_files())\n    return FALSE;\n  soft_vdb_buf = (pagemap_elem_t *)GC_scratch_alloc(VDB_BUF_SZ);\n  if (NULL == soft_vdb_buf)\n    ABORT(\"Insufficient space for /proc pagemap buffer\");\n  if (!detect_soft_dirty_supported((ptr_t)soft_vdb_buf)) {\n    GC_COND_LOG_PRINTF(\"Soft-dirty bit is not supported by kernel\\n\");\n    /* Release the resources. */\n    GC_scratch_recycle_no_gww(soft_vdb_buf, VDB_BUF_SZ);\n    soft_vdb_buf = NULL;\n    close(clear_refs_fd);\n    clear_refs_fd = -1;\n    close(pagemap_fd);\n    return FALSE;\n  }\n  return TRUE;\n}\n\nstatic off_t pagemap_buf_fpos; /* valid only if pagemap_buf_len > 0 */\n\nstatic size_t pagemap_buf_len;\n\n/* Read bytes from /proc/self/pagemap at given file position.         */\n/* len - the maximum number of bytes to read; (*pres) - amount of     */\n/* bytes actually read, always bigger than 0 but never exceeds len;   */\n/* next_fpos_hint - the file position of the next bytes block to read */\n/* ahead if possible (0 means no information provided).               */\nstatic const pagemap_elem_t *\npagemap_buffered_read(size_t *pres, off_t fpos, size_t len,\n                      off_t next_fpos_hint)\n{\n  ssize_t res;\n  size_t ofs;\n\n  GC_ASSERT(GC_page_size != 0);\n  GC_ASSERT(len > 0);\n  if (pagemap_buf_fpos <= fpos\n      && fpos < pagemap_buf_fpos + (off_t)pagemap_buf_len) {\n    /* The requested data is already in the buffer.   */\n    ofs = (size_t)(fpos - pagemap_buf_fpos);\n    res = (ssize_t)(pagemap_buf_fpos + pagemap_buf_len - fpos);\n  } else {\n    off_t aligned_pos = fpos\n                        & ~(off_t)(GC_page_size < VDB_BUF_SZ ? GC_page_size - 1\n                                                             : VDB_BUF_SZ - 1);\n\n    for (;;) {\n      size_t count;\n\n      if ((0 == pagemap_buf_len\n           || pagemap_buf_fpos + (off_t)pagemap_buf_len != aligned_pos)\n          && lseek(pagemap_fd, aligned_pos, SEEK_SET) == (off_t)(-1))\n        ABORT_ARG2(\"Failed to lseek /proc/self/pagemap\",\n                   \": offset= %lu, errno= %d\", (unsigned long)fpos, errno);\n\n      /* How much to read at once?    */\n      ofs = (size_t)(fpos - aligned_pos);\n      GC_ASSERT(ofs < VDB_BUF_SZ);\n      if (next_fpos_hint > aligned_pos\n          && next_fpos_hint - aligned_pos < VDB_BUF_SZ) {\n        count = VDB_BUF_SZ;\n      } else {\n        count = len + ofs;\n        if (count > VDB_BUF_SZ)\n          count = VDB_BUF_SZ;\n      }\n\n      GC_ASSERT(count % sizeof(pagemap_elem_t) == 0);\n      res = PROC_READ(pagemap_fd, soft_vdb_buf, count);\n      if (res > (ssize_t)ofs)\n        break;\n      if (res <= 0)\n        ABORT_ARG1(\"Failed to read /proc/self/pagemap\", \": errno= %d\",\n                   res < 0 ? errno : 0);\n      /* Retry (once) w/o page-alignment.     */\n      aligned_pos = fpos;\n    }\n\n    /* Save the buffer (file window) position and size.       */\n    pagemap_buf_fpos = aligned_pos;\n    pagemap_buf_len = (size_t)res;\n    res -= (ssize_t)ofs;\n  }\n\n  GC_ASSERT(ofs % sizeof(pagemap_elem_t) == 0);\n  *pres = (size_t)res < len ? (size_t)res : len;\n  return &soft_vdb_buf[ofs / sizeof(pagemap_elem_t)];\n}\n\nstatic void\nsoft_set_grungy_pages(ptr_t start, ptr_t limit, ptr_t next_start_hint,\n                      GC_bool is_static_root)\n{\n  ptr_t vaddr = (ptr_t)HBLK_PAGE_ALIGNED(start);\n  off_t next_fpos_hint = (off_t)((ADDR(next_start_hint) >> GC_log_pagesize)\n                                 * sizeof(pagemap_elem_t));\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(modHBLKSZ(ADDR(start)) == 0);\n  GC_ASSERT(GC_log_pagesize != 0);\n  while (ADDR_LT(vaddr, limit)) {\n    size_t res;\n    ptr_t limit_buf;\n    word vlen_p = ADDR(limit) - ADDR(vaddr) + GC_page_size - 1;\n    const pagemap_elem_t *bufp = pagemap_buffered_read(\n        &res,\n        (off_t)((ADDR(vaddr) >> GC_log_pagesize) * sizeof(pagemap_elem_t)),\n        (size_t)((vlen_p >> GC_log_pagesize) * sizeof(pagemap_elem_t)),\n        next_fpos_hint);\n\n    if (res % sizeof(pagemap_elem_t) != 0) {\n      /* Punt: */\n      memset(GC_grungy_pages, 0xff, sizeof(page_hash_table));\n      WARN(\"Incomplete read of pagemap, not multiple of entry size\\n\", 0);\n      break;\n    }\n\n    limit_buf = vaddr + ((res / sizeof(pagemap_elem_t)) << GC_log_pagesize);\n    for (; ADDR_LT(vaddr, limit_buf); vaddr += GC_page_size, bufp++) {\n      if ((*bufp & PM_SOFTDIRTY_MASK) != 0) {\n        struct hblk *h;\n        ptr_t next_vaddr = vaddr + GC_page_size;\n\n        if (EXPECT(ADDR_LT(limit, next_vaddr), FALSE))\n          next_vaddr = limit;\n          /* If the bit is set, the respective PTE was written to       */\n          /* since clearing the soft-dirty bits.                        */\n#  ifdef DEBUG_DIRTY_BITS\n        if (is_static_root)\n          GC_log_printf(\"static root dirty page at: %p\\n\", (void *)vaddr);\n#  endif\n        h = (struct hblk *)vaddr;\n        if (EXPECT(ADDR_LT(vaddr, start), FALSE))\n          h = (struct hblk *)start;\n        for (; ADDR_LT((ptr_t)h, next_vaddr); h++) {\n          size_t index = PHT_HASH(h);\n\n          /* Filter out the blocks without pointers.  It might worth  */\n          /* for the case when the heap is large enough for the hash  */\n          /* collisions to occur frequently.  Thus, off by default.   */\n#  if defined(FILTER_PTRFREE_HBLKS_IN_SOFT_VDB) || defined(CHECKSUMS) \\\n      || defined(DEBUG_DIRTY_BITS)\n          if (!is_static_root) {\n            hdr *hhdr;\n\n#    ifdef CHECKSUMS\n            set_pht_entry_from_index(GC_written_pages, index);\n#    endif\n            GET_HDR(h, hhdr);\n            if (NULL == hhdr)\n              continue;\n\n            (void)GC_find_starting_hblk(h, &hhdr);\n            if (HBLK_IS_FREE(hhdr) || IS_PTRFREE(hhdr))\n              continue;\n#    ifdef DEBUG_DIRTY_BITS\n            GC_log_printf(\"dirty page (hblk) at: %p\\n\", (void *)h);\n#    endif\n          }\n#  else\n          UNUSED_ARG(is_static_root);\n#  endif\n          set_pht_entry_from_index(GC_grungy_pages, index);\n        }\n      } else {\n#  if defined(CHECK_SOFT_VDB) /* && MPROTECT_VDB */\n        /* Ensure that each clean page according to the soft-dirty  */\n        /* VDB is also identified such by the mprotect-based one.   */\n        if (!is_static_root\n            && get_pht_entry_from_index(GC_dirty_pages, PHT_HASH(vaddr))) {\n          ptr_t my_start, my_end; /* the values are not used */\n\n          /* There could be a hash collision, thus we need to       */\n          /* verify the page is clean using slow GC_get_maps().     */\n          if (GC_enclosing_writable_mapping(vaddr, &my_start, &my_end)) {\n            ABORT(\"Inconsistent soft-dirty against mprotect dirty bits\");\n          }\n        }\n#  endif\n      }\n    }\n    /* Read the next portion of pagemap file if incomplete.   */\n  }\n}\n\nGC_INLINE void\nGC_soft_read_dirty(GC_bool output_unneeded)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifndef THREADS\n  /* Similar as for GC_proc_read_dirty.     */\n  if (getpid() != saved_proc_pid\n      && (-1 == clear_refs_fd /* no need to retry */\n          || (close(clear_refs_fd), close(pagemap_fd),\n              !soft_dirty_open_files()))) {\n    /* Failed to reopen the files.  */\n    if (!output_unneeded) {\n      /* Punt: */\n      memset(GC_grungy_pages, 0xff, sizeof(page_hash_table));\n#    ifdef CHECKSUMS\n      memset(GC_written_pages, 0xff, sizeof(page_hash_table));\n#    endif\n    }\n    return;\n  }\n#  endif\n\n  if (!output_unneeded) {\n    size_t i;\n\n    BZERO(GC_grungy_pages, sizeof(GC_grungy_pages));\n    pagemap_buf_len = 0; /* invalidate soft_vdb_buf */\n\n    for (i = 0; i < GC_n_heap_sects; ++i) {\n      ptr_t start = GC_heap_sects[i].hs_start;\n\n      soft_set_grungy_pages(\n          start, start + GC_heap_sects[i].hs_bytes,\n          i + 1 < GC_n_heap_sects ? GC_heap_sects[i + 1].hs_start : NULL,\n          FALSE);\n    }\n\n#  ifndef NO_VDB_FOR_STATIC_ROOTS\n    for (i = 0; i < n_root_sets; ++i) {\n      soft_set_grungy_pages(\n          (ptr_t)HBLKPTR(GC_static_roots[i].r_start), GC_static_roots[i].r_end,\n          i + 1 < n_root_sets ? GC_static_roots[i + 1].r_start : NULL, TRUE);\n    }\n#  endif\n  }\n\n  clear_soft_dirty_bits();\n}\n#endif /* SOFT_VDB */\n\n#ifndef NO_MANUAL_VDB\nGC_INNER GC_bool GC_manual_vdb = FALSE;\n\n/* Manually mark the page containing p as dirty.  Logically, this     */\n/* dirties the entire object.                                         */\nGC_INNER void\nGC_dirty_inner(const void *p)\n{\n  size_t index = PHT_HASH(p);\n\n#  if defined(MPROTECT_VDB)\n  /* Do not update GC_dirty_pages if it should be followed by the   */\n  /* page unprotection.                                             */\n  GC_ASSERT(GC_manual_vdb);\n#  endif\n  async_set_pht_entry_from_index(GC_dirty_pages, index);\n}\n#endif /* !NO_MANUAL_VDB */\n\n#ifndef GC_DISABLE_INCREMENTAL\n/* Retrieve system dirty bits for the heap to a local buffer (unless  */\n/* output_unneeded).  Restore the systems notion of which pages are   */\n/* dirty.  We assume that either the world is stopped or it is OK to  */\n/* lose dirty bits while it is happening (GC_enable_incremental is    */\n/* the caller and output_unneeded is TRUE at least if multi-threading */\n/* support is on).                                                    */\nGC_INNER void\nGC_read_dirty(GC_bool output_unneeded)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef DEBUG_DIRTY_BITS\n  GC_log_printf(\"read dirty begin\\n\");\n#  endif\n  if (GC_manual_vdb\n#  if defined(MPROTECT_VDB)\n      || !GC_GWW_AVAILABLE()\n#  endif\n  ) {\n    if (!output_unneeded)\n      BCOPY(CAST_AWAY_VOLATILE_PVOID(GC_dirty_pages), GC_grungy_pages,\n            sizeof(GC_dirty_pages));\n    BZERO(CAST_AWAY_VOLATILE_PVOID(GC_dirty_pages), sizeof(GC_dirty_pages));\n#  ifdef MPROTECT_VDB\n    if (!GC_manual_vdb)\n      GC_protect_heap();\n#  endif\n    return;\n  }\n\n#  ifdef GWW_VDB\n  GC_gww_read_dirty(output_unneeded);\n#  elif defined(PROC_VDB)\n  GC_proc_read_dirty(output_unneeded);\n#  elif defined(SOFT_VDB)\n  GC_soft_read_dirty(output_unneeded);\n#  endif\n#  if defined(CHECK_SOFT_VDB) /* && MPROTECT_VDB */\n  BZERO(CAST_AWAY_VOLATILE_PVOID(GC_dirty_pages), sizeof(GC_dirty_pages));\n  GC_protect_heap();\n#  endif\n}\n\n#  if !defined(NO_VDB_FOR_STATIC_ROOTS) && !defined(PROC_VDB)\nGC_INNER GC_bool\nGC_is_vdb_for_static_roots(void)\n{\n  if (GC_manual_vdb)\n    return FALSE;\n#    if defined(MPROTECT_VDB)\n  /* Currently used only in conjunction with SOFT_VDB.    */\n  return GC_GWW_AVAILABLE();\n#    else\n#      ifndef LINT2\n  GC_ASSERT(GC_incremental);\n#      endif\n  return TRUE;\n#    endif\n}\n#  endif\n\n/* Is the HBLKSIZE sized page at h marked dirty in the local buffer?  */\n/* If the actual page size is different, this returns TRUE if any     */\n/* of the pages overlapping h are dirty.  This routine may err on the */\n/* side of labeling pages as dirty (and this implementation does).    */\nGC_INNER GC_bool\nGC_page_was_dirty(struct hblk *h)\n{\n  size_t index;\n\n#  ifdef DEFAULT_VDB\n  if (!GC_manual_vdb)\n    return TRUE;\n#  elif defined(PROC_VDB)\n  /* Unless manual VDB is on, the bitmap covers all process memory. */\n  if (GC_manual_vdb)\n#  endif\n  {\n    if (NULL == HDR(h))\n      return TRUE;\n  }\n  index = PHT_HASH(h);\n  return get_pht_entry_from_index(GC_grungy_pages, index);\n}\n\n#  if defined(CHECKSUMS) || defined(PROC_VDB)\n/* Could any valid GC heap pointer ever have been written to this page? */\nGC_INNER GC_bool\nGC_page_was_ever_dirty(struct hblk *h)\n{\n#    if defined(GWW_VDB) || defined(PROC_VDB) || defined(SOFT_VDB)\n  size_t index;\n\n#      ifdef MPROTECT_VDB\n  if (!GC_GWW_AVAILABLE())\n    return TRUE;\n#      endif\n#      if defined(PROC_VDB)\n  if (GC_manual_vdb)\n#      endif\n  {\n    if (NULL == HDR(h))\n      return TRUE;\n  }\n  index = PHT_HASH(h);\n  return get_pht_entry_from_index(GC_written_pages, index);\n#    else\n  /* TODO: implement me for MANUAL_VDB. */\n  UNUSED_ARG(h);\n  return TRUE;\n#    endif\n}\n#  endif /* CHECKSUMS || PROC_VDB */\n\nGC_INNER void\nGC_remove_protection(struct hblk *h, size_t nblocks, GC_bool is_ptrfree)\n{\n#  ifdef MPROTECT_VDB\n  struct hblk *current;\n  struct hblk *h_trunc; /* truncated to page boundary */\n  ptr_t h_end;          /* page boundary following the block end */\n#  endif\n\n#  ifndef PARALLEL_MARK\n  GC_ASSERT(I_HOLD_LOCK());\n#  endif\n#  ifdef MPROTECT_VDB\n  /* Note it is not allowed to call GC_printf (and the friends) */\n  /* in this function, see Win32 GC_stop_world for the details. */\n#    ifdef DONT_PROTECT_PTRFREE\n  if (is_ptrfree)\n    return;\n#    endif\n  if (!GC_auto_incremental || GC_GWW_AVAILABLE())\n    return;\n  GC_ASSERT(GC_page_size != 0);\n  h_trunc = HBLK_PAGE_ALIGNED(h);\n  h_end = PTR_ALIGN_UP((ptr_t)(h + nblocks), GC_page_size);\n  /* Note that we cannot examine GC_dirty_pages to check    */\n  /* whether the page at h_trunc has already been marked    */\n  /* dirty as there could be a hash collision.              */\n  for (current = h_trunc; ADDR_LT((ptr_t)current, h_end); ++current) {\n    size_t index = PHT_HASH(current);\n\n#    ifndef DONT_PROTECT_PTRFREE\n    if (!is_ptrfree\n        || !ADDR_INSIDE((ptr_t)current, (ptr_t)h, (ptr_t)(h + nblocks)))\n#    endif\n    {\n      async_set_pht_entry_from_index(GC_dirty_pages, index);\n    }\n  }\n  UNPROTECT(h_trunc, h_end - (ptr_t)h_trunc);\n#  else\n  /* Ignore write hints.  They don't help us here.  */\n  UNUSED_ARG(h);\n  UNUSED_ARG(nblocks);\n  UNUSED_ARG(is_ptrfree);\n#  endif\n}\n#endif /* !GC_DISABLE_INCREMENTAL */\n\n#if defined(MPROTECT_VDB) && defined(DARWIN)\n/* The following sources were used as a \"reference\" for this exception\n   handling code:\n      1. Apple's mach/xnu documentation\n      2. Timothy J. Wood's \"Mach Exception Handlers 101\" post to the\n         omnigroup's macosx-dev list.\n         www.omnigroup.com/mailman/archive/macosx-dev/2000-June/014178.html\n      3. macosx-nat.c from Apple's GDB source code.\n*/\n\n/* The bug that caused all this trouble should now be fixed.            */\n/* This should eventually be removed if all goes well.                  */\n\n#  include <mach/exception.h>\n#  include <mach/mach.h>\n#  include <mach/mach_error.h>\n#  include <mach/task.h>\n\nEXTERN_C_BEGIN\n\n/* Some of the following prototypes are missing in any header, although */\n/* they are documented.  Some are in mach/exc.h file.                   */\nextern boolean_t exc_server(mach_msg_header_t *, mach_msg_header_t *);\n\nextern kern_return_t exception_raise(mach_port_t, mach_port_t, mach_port_t,\n                                     exception_type_t, exception_data_t,\n                                     mach_msg_type_number_t);\n\nextern kern_return_t exception_raise_state(\n    mach_port_t, mach_port_t, mach_port_t, exception_type_t, exception_data_t,\n    mach_msg_type_number_t, thread_state_flavor_t *, thread_state_t,\n    mach_msg_type_number_t, thread_state_t, mach_msg_type_number_t *);\n\nextern kern_return_t exception_raise_state_identity(\n    mach_port_t, mach_port_t, mach_port_t, exception_type_t, exception_data_t,\n    mach_msg_type_number_t, thread_state_flavor_t *, thread_state_t,\n    mach_msg_type_number_t, thread_state_t, mach_msg_type_number_t *);\n\nGC_API_OSCALL kern_return_t catch_exception_raise(\n    mach_port_t exception_port, mach_port_t thread, mach_port_t task,\n    exception_type_t exception, exception_data_t code,\n    mach_msg_type_number_t code_count);\n\nGC_API_OSCALL kern_return_t catch_exception_raise_state(\n    mach_port_name_t exception_port, int exception, exception_data_t code,\n    mach_msg_type_number_t codeCnt, int flavor, thread_state_t old_state,\n    int old_stateCnt, thread_state_t new_state, int new_stateCnt);\n\nGC_API_OSCALL kern_return_t catch_exception_raise_state_identity(\n    mach_port_name_t exception_port, mach_port_t thread, mach_port_t task,\n    int exception, exception_data_t code, mach_msg_type_number_t codeCnt,\n    int flavor, thread_state_t old_state, int old_stateCnt,\n    thread_state_t new_state, int new_stateCnt);\n\nEXTERN_C_END\n\n/* These should never be called, but just in case...  */\nGC_API_OSCALL kern_return_t\ncatch_exception_raise_state(mach_port_name_t exception_port, int exception,\n                            exception_data_t code,\n                            mach_msg_type_number_t codeCnt, int flavor,\n                            thread_state_t old_state, int old_stateCnt,\n                            thread_state_t new_state, int new_stateCnt)\n{\n  UNUSED_ARG(exception_port);\n  UNUSED_ARG(exception);\n  UNUSED_ARG(code);\n  UNUSED_ARG(codeCnt);\n  UNUSED_ARG(flavor);\n  UNUSED_ARG(old_state);\n  UNUSED_ARG(old_stateCnt);\n  UNUSED_ARG(new_state);\n  UNUSED_ARG(new_stateCnt);\n  ABORT_RET(\"Unexpected catch_exception_raise_state invocation\");\n  return KERN_INVALID_ARGUMENT;\n}\n\nGC_API_OSCALL kern_return_t\ncatch_exception_raise_state_identity(\n    mach_port_name_t exception_port, mach_port_t thread, mach_port_t task,\n    int exception, exception_data_t code, mach_msg_type_number_t codeCnt,\n    int flavor, thread_state_t old_state, int old_stateCnt,\n    thread_state_t new_state, int new_stateCnt)\n{\n  UNUSED_ARG(exception_port);\n  UNUSED_ARG(thread);\n  UNUSED_ARG(task);\n  UNUSED_ARG(exception);\n  UNUSED_ARG(code);\n  UNUSED_ARG(codeCnt);\n  UNUSED_ARG(flavor);\n  UNUSED_ARG(old_state);\n  UNUSED_ARG(old_stateCnt);\n  UNUSED_ARG(new_state);\n  UNUSED_ARG(new_stateCnt);\n  ABORT_RET(\"Unexpected catch_exception_raise_state_identity invocation\");\n  return KERN_INVALID_ARGUMENT;\n}\n\n#  define MAX_EXCEPTION_PORTS 16\n\nstatic struct {\n  mach_msg_type_number_t count;\n  exception_mask_t masks[MAX_EXCEPTION_PORTS];\n  exception_handler_t ports[MAX_EXCEPTION_PORTS];\n  exception_behavior_t behaviors[MAX_EXCEPTION_PORTS];\n  thread_state_flavor_t flavors[MAX_EXCEPTION_PORTS];\n} GC_old_exc_ports;\n\nSTATIC struct ports_s {\n  void (*volatile os_callback[3])(void);\n  mach_port_t exception;\n#  if defined(THREADS)\n  mach_port_t reply;\n#  endif\n} GC_ports = { { /* This is to prevent stripping these routines as dead.     */\n                 (void (*)(void))catch_exception_raise,\n                 (void (*)(void))catch_exception_raise_state,\n                 (void (*)(void))catch_exception_raise_state_identity },\n#  ifdef THREADS\n               0, /* for 'exception' */\n#  endif\n               0 };\n\ntypedef struct {\n  mach_msg_header_t head;\n} GC_msg_t;\n\ntypedef enum {\n  GC_MP_NORMAL,\n  GC_MP_DISCARDING,\n  GC_MP_STOPPED\n} GC_mprotect_state_t;\n\n#  ifdef THREADS\n/* FIXME: 1 and 2 seem to be safe to use in the msgh_id field, but it */\n/* is not documented.  Use the source and see if they should be OK.   */\n#    define ID_STOP 1\n#    define ID_RESUME 2\n\n/* This value is only used on the reply port. */\n#    define ID_ACK 3\n\nSTATIC GC_mprotect_state_t GC_mprotect_state = GC_MP_NORMAL;\n\n/* The following should ONLY be called when the world is stopped.     */\nSTATIC void\nGC_mprotect_thread_notify(mach_msg_id_t id)\n{\n  struct buf_s {\n    GC_msg_t msg;\n    mach_msg_trailer_t trailer;\n  } buf;\n  mach_msg_return_t r;\n\n  /* remote, local */\n  buf.msg.head.msgh_bits = MACH_MSGH_BITS(MACH_MSG_TYPE_MAKE_SEND, 0);\n  buf.msg.head.msgh_size = sizeof(buf.msg);\n  buf.msg.head.msgh_remote_port = GC_ports.exception;\n  buf.msg.head.msgh_local_port = MACH_PORT_NULL;\n  buf.msg.head.msgh_id = id;\n\n  r = mach_msg(&buf.msg.head, MACH_SEND_MSG | MACH_RCV_MSG | MACH_RCV_LARGE,\n               sizeof(buf.msg), sizeof(buf), GC_ports.reply,\n               MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL);\n  if (r != MACH_MSG_SUCCESS)\n    ABORT(\"mach_msg failed in GC_mprotect_thread_notify\");\n  if (buf.msg.head.msgh_id != ID_ACK)\n    ABORT(\"Invalid ack in GC_mprotect_thread_notify\");\n}\n\n/* Should only be called by the mprotect thread.      */\nSTATIC void\nGC_mprotect_thread_reply(void)\n{\n  GC_msg_t msg;\n  mach_msg_return_t r;\n\n  /* remote, local */\n  msg.head.msgh_bits = MACH_MSGH_BITS(MACH_MSG_TYPE_MAKE_SEND, 0);\n  msg.head.msgh_size = sizeof(msg);\n  msg.head.msgh_remote_port = GC_ports.reply;\n  msg.head.msgh_local_port = MACH_PORT_NULL;\n  msg.head.msgh_id = ID_ACK;\n\n  r = mach_msg(&msg.head, MACH_SEND_MSG, sizeof(msg), 0, MACH_PORT_NULL,\n               MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL);\n  if (r != MACH_MSG_SUCCESS)\n    ABORT(\"mach_msg failed in GC_mprotect_thread_reply\");\n}\n\nGC_INNER void\nGC_mprotect_stop(void)\n{\n  GC_mprotect_thread_notify(ID_STOP);\n}\n\nGC_INNER void\nGC_mprotect_resume(void)\n{\n  GC_mprotect_thread_notify(ID_RESUME);\n}\n\n#    ifdef CAN_HANDLE_FORK\nGC_INNER void\nGC_dirty_update_child(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (0 == GC_task_self) {\n    /* The GC incremental mode is off.      */\n    return;\n  }\n\n  GC_ASSERT(GC_mprotect_state == GC_MP_NORMAL);\n  GC_task_self = mach_task_self(); /* needed by UNPROTECT() */\n  GC_unprotect_all_heap();\n\n  /* Restore the old task exception ports.  */\n  /* TODO: Should we do it in fork_prepare/parent_proc? */\n  if (GC_old_exc_ports.count > 0) {\n    /* TODO: Should we check GC_old_exc_ports.count<=1? */\n    if (task_set_exception_ports(\n            GC_task_self, GC_old_exc_ports.masks[0], GC_old_exc_ports.ports[0],\n            GC_old_exc_ports.behaviors[0], GC_old_exc_ports.flavors[0])\n        != KERN_SUCCESS)\n      ABORT(\"task_set_exception_ports failed (in child)\");\n  }\n\n  /* TODO: Re-enable incremental mode in child. */\n  GC_task_self = 0;\n  GC_incremental = FALSE;\n}\n#    endif /* CAN_HANDLE_FORK */\n\n#  else\n/* The compiler should optimize away any GC_mprotect_state computations. */\n#    define GC_mprotect_state GC_MP_NORMAL\n#  endif /* !THREADS */\n\nstruct mp_reply_s {\n  mach_msg_header_t head;\n  char data[256];\n};\n\nstruct mp_msg_s {\n  mach_msg_header_t head;\n  mach_msg_body_t msgh_body;\n  char data[1024];\n};\n\nSTATIC void *\nGC_mprotect_thread(void *arg)\n{\n  mach_msg_return_t r;\n  /* These two structures contain some private kernel data.  We don't   */\n  /* need to access any of it so we don't bother defining a proper      */\n  /* struct.  The correct definitions are in the xnu source code.       */\n  struct mp_reply_s reply;\n  struct mp_msg_s msg;\n  mach_msg_id_t id;\n\n  if (ADDR(arg) == GC_WORD_MAX)\n    return 0; /* to prevent a compiler warning */\n#  if defined(CPPCHECK)\n  reply.data[0] = 0; /* to prevent \"field unused\" warnings */\n  msg.data[0] = 0;\n#  endif\n\n#  if defined(HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID)\n  (void)pthread_setname_np(\"GC-mprotect\");\n#  endif\n#  if defined(THREADS) && !defined(GC_NO_THREADS_DISCOVERY)\n  GC_darwin_register_self_mach_handler();\n#  endif\n\n  for (;;) {\n    r = mach_msg(\n        &msg.head,\n        MACH_RCV_MSG | MACH_RCV_LARGE\n            | (GC_mprotect_state == GC_MP_DISCARDING ? MACH_RCV_TIMEOUT : 0),\n        0, sizeof(msg), GC_ports.exception,\n        GC_mprotect_state == GC_MP_DISCARDING ? 0 : MACH_MSG_TIMEOUT_NONE,\n        MACH_PORT_NULL);\n    id = r == MACH_MSG_SUCCESS ? msg.head.msgh_id : -1;\n\n#  if defined(THREADS)\n    if (GC_mprotect_state == GC_MP_DISCARDING) {\n      if (r == MACH_RCV_TIMED_OUT) {\n        GC_mprotect_state = GC_MP_STOPPED;\n        GC_mprotect_thread_reply();\n        continue;\n      }\n      if (r == MACH_MSG_SUCCESS && (id == ID_STOP || id == ID_RESUME))\n        ABORT(\"Out of order mprotect thread request\");\n    }\n#  endif /* THREADS */\n\n    if (r != MACH_MSG_SUCCESS) {\n      ABORT_ARG2(\"mach_msg failed\", \": errcode= %d (%s)\", (int)r,\n                 mach_error_string(r));\n    }\n\n    switch (id) {\n#  if defined(THREADS)\n    case ID_STOP:\n      if (GC_mprotect_state != GC_MP_NORMAL)\n        ABORT(\"Called mprotect_stop when state wasn't normal\");\n      GC_mprotect_state = GC_MP_DISCARDING;\n      break;\n    case ID_RESUME:\n      if (GC_mprotect_state != GC_MP_STOPPED)\n        ABORT(\"Called mprotect_resume when state wasn't stopped\");\n      GC_mprotect_state = GC_MP_NORMAL;\n      GC_mprotect_thread_reply();\n      break;\n#  endif /* THREADS */\n    default:\n      /* Handle the message (calls catch_exception_raise).  */\n      if (!exc_server(&msg.head, &reply.head))\n        ABORT(\"exc_server failed\");\n      /* Send the reply.    */\n      r = mach_msg(&reply.head, MACH_SEND_MSG, reply.head.msgh_size, 0,\n                   MACH_PORT_NULL, MACH_MSG_TIMEOUT_NONE, MACH_PORT_NULL);\n      if (r != MACH_MSG_SUCCESS) {\n        /* This will fail if the thread dies, but the thread should */\n        /* not die...                                               */\n#  ifdef BROKEN_EXCEPTION_HANDLING\n        GC_err_printf(\"mach_msg failed with %d %s while sending \"\n                      \"exc reply\\n\",\n                      (int)r, mach_error_string(r));\n#  else\n        ABORT(\"mach_msg failed while sending exception reply\");\n#  endif\n      }\n    } /* switch */\n  }   /* for */\n}\n\n/* All this SIGBUS code should not be necessary.  All protection faults */\n/* should be going through the mach exception handler.  However, it     */\n/* seems a SIGBUS is occasionally sent for some unknown reason.  Even   */\n/* more odd, it seems to be meaningless and safe to ignore.             */\n#  ifdef BROKEN_EXCEPTION_HANDLING\n\n/* Updates to this aren't atomic, but the SIGBUS'es seem pretty rare.    */\n/* Even if this doesn't get updated property, it isn't really a problem. */\nSTATIC int GC_sigbus_count = 0;\n\nSTATIC void\nGC_darwin_sigbus(int num, siginfo_t *sip, void *context)\n{\n  if (num != SIGBUS)\n    ABORT(\"Got a non-sigbus signal in the sigbus handler\");\n\n  /* Ugh... some seem safe to ignore, but too many in a row probably  */\n  /* means trouble.  GC_sigbus_count is reset for each mach exception */\n  /* that is handled.                                                 */\n  if (GC_sigbus_count >= 8)\n    ABORT(\"Got many SIGBUS signals in a row!\");\n  GC_sigbus_count++;\n  WARN(\"Ignoring SIGBUS\\n\", 0);\n}\n#  endif /* BROKEN_EXCEPTION_HANDLING */\n\nGC_INNER GC_bool\nGC_dirty_init(void)\n{\n  kern_return_t r;\n  mach_port_t me;\n  pthread_t thread;\n  pthread_attr_t attr;\n  exception_mask_t mask;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  if defined(CAN_HANDLE_FORK) && !defined(THREADS)\n  if (GC_handle_fork) {\n    /* To both support GC incremental mode and GC functions usage in  */\n    /* the forked child, pthread_atfork should be used to install     */\n    /* handlers that switch off GC_incremental in the child           */\n    /* gracefully (unprotecting all pages and clearing                */\n    /* GC_mach_handler_thread).  For now, we just disable incremental */\n    /* mode if fork() handling is requested by the client.            */\n    WARN(\"Can't turn on GC incremental mode as fork()\"\n         \" handling requested\\n\",\n         0);\n    return FALSE;\n  }\n#  endif\n\n  GC_VERBOSE_LOG_PRINTF(\"Initializing mach/darwin mprotect\"\n                        \" virtual dirty bit implementation\\n\");\n#  ifdef BROKEN_EXCEPTION_HANDLING\n  WARN(\"Enabling workarounds for various darwin exception handling bugs\\n\", 0);\n#  endif\n  if (GC_page_size % HBLKSIZE != 0) {\n    ABORT(\"Page size not multiple of HBLKSIZE\");\n  }\n\n  GC_task_self = me = mach_task_self();\n  GC_ASSERT(me != 0);\n\n  r = mach_port_allocate(me, MACH_PORT_RIGHT_RECEIVE, &GC_ports.exception);\n  /* TODO: WARN and return FALSE in case of a failure. */\n  if (r != KERN_SUCCESS)\n    ABORT(\"mach_port_allocate failed (exception port)\");\n\n  r = mach_port_insert_right(me, GC_ports.exception, GC_ports.exception,\n                             MACH_MSG_TYPE_MAKE_SEND);\n  if (r != KERN_SUCCESS)\n    ABORT(\"mach_port_insert_right failed (exception port)\");\n\n#  if defined(THREADS)\n  r = mach_port_allocate(me, MACH_PORT_RIGHT_RECEIVE, &GC_ports.reply);\n  if (r != KERN_SUCCESS)\n    ABORT(\"mach_port_allocate failed (reply port)\");\n#  endif\n\n  /* The exceptions we want to catch. */\n  mask = EXC_MASK_BAD_ACCESS;\n  r = task_get_exception_ports(me, mask, GC_old_exc_ports.masks,\n                               &GC_old_exc_ports.count, GC_old_exc_ports.ports,\n                               GC_old_exc_ports.behaviors,\n                               GC_old_exc_ports.flavors);\n  if (r != KERN_SUCCESS)\n    ABORT(\"task_get_exception_ports failed\");\n\n  r = task_set_exception_ports(me, mask, GC_ports.exception, EXCEPTION_DEFAULT,\n                               GC_MACH_THREAD_STATE);\n  if (r != KERN_SUCCESS)\n    ABORT(\"task_set_exception_ports failed\");\n\n  if (pthread_attr_init(&attr) != 0)\n    ABORT(\"pthread_attr_init failed\");\n  if (pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED) != 0)\n    ABORT(\"pthread_attr_setdetachedstate failed\");\n  /* This will call the real pthread function, not our wrapper. */\n  if (GC_inner_pthread_create(&thread, &attr, GC_mprotect_thread, NULL) != 0)\n    ABORT(\"pthread_create failed\");\n  (void)pthread_attr_destroy(&attr);\n\n  /* Setup the sigbus handler for ignoring the meaningless SIGBUS signals. */\n#  ifdef BROKEN_EXCEPTION_HANDLING\n  {\n    struct sigaction sa, oldsa;\n    sa.sa_handler = (SIG_HNDLR_PTR)GC_darwin_sigbus;\n    sigemptyset(&sa.sa_mask);\n    sa.sa_flags = SA_RESTART | SA_SIGINFO;\n    /* sa.sa_restorer is deprecated and should not be initialized. */\n    if (sigaction(SIGBUS, &sa, &oldsa) < 0)\n      ABORT(\"sigaction failed\");\n    if ((GC_funcptr_uint)oldsa.sa_handler != (GC_funcptr_uint)SIG_DFL) {\n      GC_VERBOSE_LOG_PRINTF(\"Replaced other SIGBUS handler\\n\");\n    }\n  }\n#  endif /* BROKEN_EXCEPTION_HANDLING  */\n#  if defined(CPPCHECK)\n  GC_noop1((word)(GC_funcptr_uint)GC_ports.os_callback[0]);\n#  endif\n  return TRUE;\n}\n\n/* The source code for Apple's GDB was used as a reference for the      */\n/* exception forwarding code.  This code is similar to be GDB code only */\n/* because there is only one way to do it.                              */\nSTATIC kern_return_t\nGC_forward_exception(mach_port_t thread, mach_port_t task,\n                     exception_type_t exception, exception_data_t data,\n                     mach_msg_type_number_t data_count)\n{\n  size_t i;\n  kern_return_t r;\n  mach_port_t port;\n  exception_behavior_t behavior;\n  thread_state_flavor_t flavor;\n\n  thread_state_data_t thread_state;\n  mach_msg_type_number_t thread_state_count = THREAD_STATE_MAX;\n\n  for (i = 0; i < (size_t)GC_old_exc_ports.count; i++) {\n    if ((GC_old_exc_ports.masks[i] & ((exception_mask_t)1 << exception)) != 0)\n      break;\n  }\n  if (i == (size_t)GC_old_exc_ports.count)\n    ABORT(\"No handler for exception!\");\n\n  port = GC_old_exc_ports.ports[i];\n  behavior = GC_old_exc_ports.behaviors[i];\n  flavor = GC_old_exc_ports.flavors[i];\n\n  if (behavior == EXCEPTION_STATE || behavior == EXCEPTION_STATE_IDENTITY) {\n    r = thread_get_state(thread, flavor, thread_state, &thread_state_count);\n    if (r != KERN_SUCCESS)\n      ABORT(\"thread_get_state failed in forward_exception\");\n  }\n\n  switch (behavior) {\n  case EXCEPTION_STATE:\n    r = exception_raise_state(port, thread, task, exception, data, data_count,\n                              &flavor, thread_state, thread_state_count,\n                              thread_state, &thread_state_count);\n    break;\n  case EXCEPTION_STATE_IDENTITY:\n    r = exception_raise_state_identity(\n        port, thread, task, exception, data, data_count, &flavor, thread_state,\n        thread_state_count, thread_state, &thread_state_count);\n    break;\n  /* case EXCEPTION_DEFAULT: */ /* default signal handlers */\n  default:                      /* user-supplied signal handlers */\n    r = exception_raise(port, thread, task, exception, data, data_count);\n  }\n\n  if (behavior == EXCEPTION_STATE || behavior == EXCEPTION_STATE_IDENTITY) {\n    r = thread_set_state(thread, flavor, thread_state, thread_state_count);\n    if (r != KERN_SUCCESS)\n      ABORT(\"thread_set_state failed in forward_exception\");\n  }\n  return r;\n}\n\n#  define FWD() GC_forward_exception(thread, task, exception, code, code_count)\n\n#  ifdef ARM32\n#    define DARWIN_EXC_STATE ARM_EXCEPTION_STATE\n#    define DARWIN_EXC_STATE_COUNT ARM_EXCEPTION_STATE_COUNT\n#    define DARWIN_EXC_STATE_T arm_exception_state_t\n#    define DARWIN_EXC_STATE_DAR THREAD_FLD_NAME(far)\n#  elif defined(AARCH64)\n#    define DARWIN_EXC_STATE ARM_EXCEPTION_STATE64\n#    define DARWIN_EXC_STATE_COUNT ARM_EXCEPTION_STATE64_COUNT\n#    define DARWIN_EXC_STATE_T arm_exception_state64_t\n#    define DARWIN_EXC_STATE_DAR THREAD_FLD_NAME(far)\n#  elif defined(POWERPC)\n#    if CPP_WORDSZ == 32\n#      define DARWIN_EXC_STATE PPC_EXCEPTION_STATE\n#      define DARWIN_EXC_STATE_COUNT PPC_EXCEPTION_STATE_COUNT\n#      define DARWIN_EXC_STATE_T ppc_exception_state_t\n#    else\n#      define DARWIN_EXC_STATE PPC_EXCEPTION_STATE64\n#      define DARWIN_EXC_STATE_COUNT PPC_EXCEPTION_STATE64_COUNT\n#      define DARWIN_EXC_STATE_T ppc_exception_state64_t\n#    endif\n#    define DARWIN_EXC_STATE_DAR THREAD_FLD_NAME(dar)\n#  elif defined(I386) || defined(X86_64)\n#    if CPP_WORDSZ == 32\n#      if defined(i386_EXCEPTION_STATE_COUNT) \\\n          && !defined(x86_EXCEPTION_STATE32_COUNT)\n/* Use old naming convention for i686.    */\n#        define DARWIN_EXC_STATE i386_EXCEPTION_STATE\n#        define DARWIN_EXC_STATE_COUNT i386_EXCEPTION_STATE_COUNT\n#        define DARWIN_EXC_STATE_T i386_exception_state_t\n#      else\n#        define DARWIN_EXC_STATE x86_EXCEPTION_STATE32\n#        define DARWIN_EXC_STATE_COUNT x86_EXCEPTION_STATE32_COUNT\n#        define DARWIN_EXC_STATE_T x86_exception_state32_t\n#      endif\n#    else\n#      define DARWIN_EXC_STATE x86_EXCEPTION_STATE64\n#      define DARWIN_EXC_STATE_COUNT x86_EXCEPTION_STATE64_COUNT\n#      define DARWIN_EXC_STATE_T x86_exception_state64_t\n#    endif\n#    define DARWIN_EXC_STATE_DAR THREAD_FLD_NAME(faultvaddr)\n#  elif !defined(CPPCHECK)\n#    error FIXME for non-arm/ppc/x86 darwin\n#  endif\n\n/* This violates the namespace rules but there isn't anything that can  */\n/* be done about it.  The exception handling stuff is hard coded to     */\n/* call this.  catch_exception_raise, catch_exception_raise_state and   */\n/* and catch_exception_raise_state_identity are called from OS.         */\nGC_API_OSCALL kern_return_t\ncatch_exception_raise(mach_port_t exception_port, mach_port_t thread,\n                      mach_port_t task, exception_type_t exception,\n                      exception_data_t code, mach_msg_type_number_t code_count)\n{\n  kern_return_t r;\n  char *addr;\n  thread_state_flavor_t flavor = DARWIN_EXC_STATE;\n  mach_msg_type_number_t exc_state_count = DARWIN_EXC_STATE_COUNT;\n  DARWIN_EXC_STATE_T exc_state;\n\n  UNUSED_ARG(exception_port);\n  UNUSED_ARG(task);\n  if (exception != EXC_BAD_ACCESS || code[0] != KERN_PROTECTION_FAILURE) {\n#  ifdef DEBUG_EXCEPTION_HANDLING\n    /* We are not interested, pass it on to the old handler.  */\n    GC_log_printf(\"Exception: 0x%x Code: 0x%x 0x%x in catch...\\n\", exception,\n                  code_count > 0 ? code[0] : -1,\n                  code_count > 1 ? code[1] : -1);\n#  else\n    UNUSED_ARG(code_count);\n#  endif\n    return FWD();\n  }\n\n  r = thread_get_state(thread, flavor, (natural_t *)&exc_state,\n                       &exc_state_count);\n  if (r != KERN_SUCCESS) {\n    /* The thread is supposed to be suspended while the exception       */\n    /* handler is called.  This shouldn't fail.                         */\n#  ifdef BROKEN_EXCEPTION_HANDLING\n    GC_err_printf(\"thread_get_state failed in catch_exception_raise\\n\");\n    return KERN_SUCCESS;\n#  else\n    ABORT(\"thread_get_state failed in catch_exception_raise\");\n#  endif\n  }\n\n  /* This is the address that caused the fault. */\n  addr = (char *)exc_state.DARWIN_EXC_STATE_DAR;\n  if (!is_header_found_async(addr)) {\n    /* Ugh... just like the SIGBUS problem above, it seems we get       */\n    /* a bogus KERN_PROTECTION_FAILURE every once and a while.  We wait */\n    /* till we get a bunch in a row before doing anything about it.     */\n    /* If a \"real\" fault ever occurs it'll just keep faulting over and  */\n    /* over and we'll hit the limit pretty quickly.                     */\n#  ifdef BROKEN_EXCEPTION_HANDLING\n    static const char *last_fault;\n    static int last_fault_count;\n\n    if (addr != last_fault) {\n      last_fault = addr;\n      last_fault_count = 0;\n    }\n    if (++last_fault_count < 32) {\n      if (last_fault_count == 1)\n        WARN(\"Ignoring KERN_PROTECTION_FAILURE at %p\\n\", addr);\n      return KERN_SUCCESS;\n    }\n\n    GC_err_printf(\"Unexpected KERN_PROTECTION_FAILURE at %p; aborting...\\n\",\n                  (void *)addr);\n    /* Can't pass it along to the signal handler because that is      */\n    /* ignoring SIGBUS signals.  We also shouldn't call ABORT here as */\n    /* signals don't always work too well from the exception handler. */\n    EXIT();\n#  else\n    /* Pass it along to the next exception handler (which should call */\n    /* SIGBUS/SIGSEGV).                                               */\n    return FWD();\n#  endif /* !BROKEN_EXCEPTION_HANDLING */\n  }\n\n#  ifdef BROKEN_EXCEPTION_HANDLING\n  /* Reset the number of consecutive SIGBUS signals.  */\n  GC_sigbus_count = 0;\n#  endif\n\n  GC_ASSERT(GC_page_size != 0);\n  if (GC_mprotect_state == GC_MP_NORMAL) {\n    /* The common case. */\n    struct hblk *h = HBLK_PAGE_ALIGNED(addr);\n    size_t i;\n\n#  ifdef CHECKSUMS\n    GC_record_fault(h);\n#  endif\n    UNPROTECT(h, GC_page_size);\n    for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n      size_t index = PHT_HASH(h + i);\n\n      async_set_pht_entry_from_index(GC_dirty_pages, index);\n    }\n  } else if (GC_mprotect_state == GC_MP_DISCARDING) {\n    /* Lie to the thread for now.  No sense UNPROTECT()'ing the memory  */\n    /* when we are just going to PROTECT() it again later.  The thread  */\n    /* will just fault again once it resumes.                           */\n  } else {\n    /* Should not happen, I don't think. */\n    GC_err_printf(\"KERN_PROTECTION_FAILURE while world is stopped\\n\");\n    return FWD();\n  }\n  return KERN_SUCCESS;\n}\n#  undef FWD\n\n#  ifndef NO_DESC_CATCH_EXCEPTION_RAISE\n/* These symbols should have REFERENCED_DYNAMICALLY (0x10) bit set to */\n/* let strip know they are not to be stripped.                        */\n__asm__(\".desc _catch_exception_raise, 0x10\");\n__asm__(\".desc _catch_exception_raise_state, 0x10\");\n__asm__(\".desc _catch_exception_raise_state_identity, 0x10\");\n#  endif\n\n#endif /* DARWIN && MPROTECT_VDB */\n\nGC_API int GC_CALL\nGC_incremental_protection_needs(void)\n{\n  GC_ASSERT(GC_is_initialized);\n#ifdef MPROTECT_VDB\n#  if defined(GWW_VDB) || (defined(SOFT_VDB) && !defined(CHECK_SOFT_VDB))\n  /* Only if the incremental mode is already switched on.   */\n  if (GC_GWW_AVAILABLE())\n    return GC_PROTECTS_NONE;\n#  endif\n#  ifndef DONT_PROTECT_PTRFREE\n  if (GC_page_size != HBLKSIZE)\n    return GC_PROTECTS_POINTER_HEAP | GC_PROTECTS_PTRFREE_HEAP;\n#  endif\n  return GC_PROTECTS_POINTER_HEAP;\n#else\n  return GC_PROTECTS_NONE;\n#endif\n}\n\nGC_API unsigned GC_CALL\nGC_get_actual_vdb(void)\n{\n#ifndef GC_DISABLE_INCREMENTAL\n  if (GC_incremental) {\n#  ifndef NO_MANUAL_VDB\n    if (GC_manual_vdb)\n      return GC_VDB_MANUAL;\n#  endif\n#  ifdef MPROTECT_VDB\n#    ifdef GWW_VDB\n    if (GC_GWW_AVAILABLE())\n      return GC_VDB_GWW;\n#    endif\n#    ifdef SOFT_VDB\n    if (GC_GWW_AVAILABLE())\n      return GC_VDB_SOFT;\n#    endif\n    return GC_VDB_MPROTECT;\n#  elif defined(GWW_VDB)\n    return GC_VDB_GWW;\n#  elif defined(SOFT_VDB)\n    return GC_VDB_SOFT;\n#  elif defined(PROC_VDB)\n    return GC_VDB_PROC;\n#  else /* DEFAULT_VDB */\n    return GC_VDB_DEFAULT;\n#  endif\n  }\n#endif\n  return GC_VDB_NONE;\n}\n\n#ifdef ECOS\n/* Undo sbrk() redirection. */\n#  undef sbrk\n#endif\n\n/* If value is non-zero then allocate executable memory.        */\nGC_API void GC_CALL\nGC_set_pages_executable(int value)\n{\n  GC_ASSERT(!GC_is_initialized);\n  /* Even if IGNORE_PAGES_EXECUTABLE is defined, GC_pages_executable is */\n  /* touched here to prevent a compiler warning.                        */\n  GC_pages_executable = (GC_bool)(value != 0);\n}\n\n/* Returns non-zero if the GC-allocated memory is executable.   */\n/* GC_get_pages_executable is defined after all the places      */\n/* where GC_get_pages_executable is undefined.                  */\nGC_API int GC_CALL\nGC_get_pages_executable(void)\n{\n#ifdef IGNORE_PAGES_EXECUTABLE\n  return 1; /* Always allocate executable memory. */\n#else\n  return (int)GC_pages_executable;\n#endif\n}\n\n/* Call stack save code for debugging.  Should probably be in           */\n/* mach_dep.c, but that requires reorganization.                        */\n#ifdef NEED_CALLINFO\n\n/* I suspect the following works for most *nix i686 variants, so long */\n/* as the frame pointer is explicitly stored.  In the case of gcc,    */\n/* the client code should not be compiled with -fomit-frame-pointer.  */\n#  if defined(I386) && defined(LINUX) && defined(SAVE_CALL_CHAIN)\nstruct frame {\n  struct frame *fr_savfp;\n  long fr_savpc;\n#    if NARGS > 0\n  /* All the arguments go here. */\n  long fr_arg[NARGS];\n#    endif\n};\n#  endif\n\n#  if defined(SPARC)\n#    if defined(LINUX)\n#      if defined(SAVE_CALL_CHAIN)\nstruct frame {\n  long fr_local[8];\n  long fr_arg[6];\n  struct frame *fr_savfp;\n  long fr_savpc;\n#        ifndef __arch64__\n  char *fr_stret;\n#        endif\n  long fr_argd[6];\n  long fr_argx[0];\n};\n#      endif\n#    elif defined(DRSNX)\n#      include <sys/sparc/frame.h>\n#    elif defined(OPENBSD)\n#      include <frame.h>\n#    elif defined(FREEBSD) || defined(NETBSD)\n#      include <machine/frame.h>\n#    else\n#      include <sys/frame.h>\n#    endif\n#    if NARGS > 6\n#      error We only know how to get the first 6 arguments\n#    endif\n#  endif /* SPARC */\n\n/* Fill in the pc and argument information for up to NFRAMES of my    */\n/* callers.  Ignore my frame and my callers frame.                    */\n\n#  if defined(GC_HAVE_BUILTIN_BACKTRACE)\n#    ifdef _MSC_VER\nEXTERN_C_BEGIN\nint backtrace(void *addresses[], int count);\nchar **backtrace_symbols(void *const addresses[], int count);\nEXTERN_C_END\n#    else\n#      include <execinfo.h>\n#    endif\n#  endif /* GC_HAVE_BUILTIN_BACKTRACE */\n\n#  ifdef SAVE_CALL_CHAIN\n\n#    if NARGS == 0 && NFRAMES % 2 == 0 /* No padding */ \\\n        && defined(GC_HAVE_BUILTIN_BACKTRACE)\n\n#      ifdef REDIRECT_MALLOC\n/* Deal with possible malloc calls in backtrace by omitting */\n/* the infinitely recursing backtrace.                      */\nSTATIC GC_bool GC_in_save_callers = FALSE;\n\n#        if defined(THREADS) && defined(DBG_HDRS_ALL)\n#          include \"private/dbg_mlc.h\"\n\n/* A dummy version of GC_save_callers() which does not call   */\n/* backtrace().                                               */\nGC_INNER void\nGC_save_callers_no_unlock(struct callinfo info[NFRAMES])\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  info[0].ci_pc\n      = CAST_THRU_UINTPTR(GC_return_addr_t, GC_save_callers_no_unlock);\n  BZERO(&info[1], sizeof(void *) * (NFRAMES - 1));\n}\n#        endif\n#      endif /* REDIRECT_MALLOC */\n\nGC_INNER void\nGC_save_callers(struct callinfo info[NFRAMES])\n{\n  void *tmp_info[NFRAMES + 1];\n  int npcs, i;\n\n  /* backtrace() may call dl_iterate_phdr which is also used by   */\n  /* GC_register_dynamic_libraries(), and dl_iterate_phdr is not  */\n  /* guaranteed to be reentrant.                                  */\n  GC_ASSERT(I_HOLD_LOCK());\n\n  GC_STATIC_ASSERT(sizeof(struct callinfo) == sizeof(void *));\n#      ifdef REDIRECT_MALLOC\n  if (GC_in_save_callers) {\n    info[0].ci_pc = CAST_THRU_UINTPTR(GC_return_addr_t, GC_save_callers);\n    BZERO(&info[1], sizeof(void *) * (NFRAMES - 1));\n    return;\n  }\n  GC_in_save_callers = TRUE;\n  /* backtrace() might call a redirected malloc. */\n  UNLOCK();\n  npcs = backtrace((void **)tmp_info, NFRAMES + 1);\n  LOCK();\n#      else\n  npcs = backtrace((void **)tmp_info, NFRAMES + 1);\n#      endif\n  /* We retrieve NFRAMES+1 pc values, but discard the first one,  */\n  /* since it points to our own frame.                            */\n  i = 0;\n  if (npcs > 1) {\n    i = npcs - 1;\n    BCOPY(&tmp_info[1], info, (unsigned)i * sizeof(void *));\n  }\n  BZERO(&info[i], sizeof(void *) * (unsigned)(NFRAMES - i));\n#      ifdef REDIRECT_MALLOC\n  GC_in_save_callers = FALSE;\n#      endif\n}\n\n#    elif defined(I386) || defined(SPARC)\n\n#      if defined(ANY_BSD) && defined(SPARC)\n#        define FR_SAVFP fr_fp\n#        define FR_SAVPC fr_pc\n#      else\n#        define FR_SAVFP fr_savfp\n#        define FR_SAVPC fr_savpc\n#      endif\n\n#      if defined(SPARC) && (defined(__arch64__) || defined(__sparcv9))\n#        define BIAS 2047\n#      else\n#        define BIAS 0\n#      endif\n\nGC_INNER void\nGC_save_callers(struct callinfo info[NFRAMES])\n{\n  struct frame *frame;\n  struct frame *fp;\n  int nframes = 0;\n#      ifdef I386\n  /* We assume this is turned on only with gcc as the compiler. */\n  asm(\"movl %%ebp,%0\" : \"=r\"(frame));\n  fp = frame;\n#      else /* SPARC */\n  frame = (struct frame *)GC_save_regs_in_stack();\n  fp = (struct frame *)((ptr_t)frame->FR_SAVFP + BIAS);\n#      endif\n\n  for (; !HOTTER_THAN((ptr_t)fp, (ptr_t)frame)\n#      ifndef THREADS\n         && !HOTTER_THAN(GC_stackbottom, (ptr_t)fp)\n#      elif defined(STACK_GROWS_UP)\n         && fp != NULL\n#      endif\n         && nframes < NFRAMES;\n       fp = (struct frame *)((ptr_t)fp->FR_SAVFP + BIAS), nframes++) {\n#      if NARGS > 0\n    int i;\n#      endif\n\n    info[nframes].ci_pc = (GC_return_addr_t)fp->FR_SAVPC;\n#      if NARGS > 0\n    for (i = 0; i < NARGS; i++) {\n      info[nframes].ci_arg[i] = GC_HIDE_NZ_POINTER(MAKE_CPTR(fp->fr_arg[i]));\n    }\n#      endif\n  }\n  if (nframes < NFRAMES)\n    info[nframes].ci_pc = 0;\n}\n\n#    endif /* !GC_HAVE_BUILTIN_BACKTRACE */\n\n#  endif /* SAVE_CALL_CHAIN */\n\n/* Print info to stderr.  We do not hold the allocator lock.  */\nGC_INNER void\nGC_print_callers(struct callinfo info[NFRAMES])\n{\n  int i, reent_cnt;\n#  if defined(AO_HAVE_fetch_and_add1) && defined(AO_HAVE_fetch_and_sub1)\n  static volatile AO_t reentry_count = 0;\n\n  /* Note: alternatively, if available, we may use a thread-local   */\n  /* storage, thus, enabling concurrent usage of GC_print_callers;  */\n  /* but practically this has little sense because printing is done */\n  /* into a single output stream.                                   */\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  reent_cnt = (int)(GC_signed_word)AO_fetch_and_add1(&reentry_count);\n#  else\n  static int reentry_count = 0;\n\n  /* Note: this could use a different lock. */\n  LOCK();\n  reent_cnt = reentry_count++;\n  UNLOCK();\n#  endif\n#  if NFRAMES == 1\n  GC_err_printf(\"\\tCaller at allocation:\\n\");\n#  else\n  GC_err_printf(\"\\tCall chain at allocation:\\n\");\n#  endif\n  for (i = 0; i < NFRAMES; i++) {\n#  if defined(LINUX) && !defined(SMALL_CONFIG)\n    GC_bool stop = FALSE;\n#  endif\n\n    if (0 == info[i].ci_pc)\n      break;\n#  if NARGS > 0\n    {\n      int j;\n\n      GC_err_printf(\"\\t\\targs: \");\n      for (j = 0; j < NARGS; j++) {\n        void *p = GC_REVEAL_NZ_POINTER(info[i].ci_arg[j]);\n\n        if (j != 0)\n          GC_err_printf(\", \");\n        GC_err_printf(\"%ld (%p)\", (long)(GC_signed_word)ADDR(p), p);\n      }\n      GC_err_printf(\"\\n\");\n    }\n#  endif\n    if (reent_cnt > 0) {\n      /* We were called either concurrently or during an allocation */\n      /* by backtrace_symbols() called from GC_print_callers; punt. */\n      GC_err_printf(\"\\t\\t##PC##= 0x%lx\\n\", (unsigned long)ADDR(info[i].ci_pc));\n      continue;\n    }\n\n    {\n      char buf[40];\n      char *name;\n#  if defined(GC_HAVE_BUILTIN_BACKTRACE) \\\n      && !defined(GC_BACKTRACE_SYMBOLS_BROKEN) && defined(FUNCPTR_IS_DATAPTR)\n      char **sym_name = backtrace_symbols((void **)&info[i].ci_pc, 1);\n      if (sym_name != NULL) {\n        name = sym_name[0];\n      } else\n#  endif\n      /* else */ {\n        (void)snprintf(buf, sizeof(buf), \"##PC##= 0x%lx\",\n                       (unsigned long)ADDR(info[i].ci_pc));\n        buf[sizeof(buf) - 1] = '\\0';\n        name = buf;\n      }\n#  if defined(LINUX) && !defined(SMALL_CONFIG)\n      /* Try for a line number. */\n      do {\n        FILE *pipe;\n#    define EXE_SZ 100\n        static char exe_name[EXE_SZ];\n#    define CMD_SZ 200\n        char cmd_buf[CMD_SZ];\n#    define RESULT_SZ 200\n        static char result_buf[RESULT_SZ];\n        size_t result_len;\n        const char *old_preload;\n#    define PRELOAD_SZ 200\n        char preload_buf[PRELOAD_SZ];\n        static GC_bool found_exe_name = FALSE;\n        static GC_bool will_fail = FALSE;\n\n        /* Try to get it via a hairy and expensive scheme.      */\n        /* First we get the name of the executable:             */\n        if (will_fail)\n          break;\n        if (!found_exe_name) {\n          int ret_code = readlink(\"/proc/self/exe\", exe_name, EXE_SZ);\n\n          if (ret_code < 0 || ret_code >= EXE_SZ || exe_name[0] != '/') {\n            will_fail = TRUE; /* Don't try again. */\n            break;\n          }\n          exe_name[ret_code] = '\\0';\n          found_exe_name = TRUE;\n        }\n        /* Then we use popen to start addr2line -e <exe> <addr> */\n        /* There are faster ways to do this, but hopefully this */\n        /* isn't time critical.                                 */\n        (void)snprintf(cmd_buf, sizeof(cmd_buf),\n                       \"/usr/bin/addr2line -f -e %s 0x%lx\", exe_name,\n                       (unsigned long)ADDR(info[i].ci_pc));\n        cmd_buf[sizeof(cmd_buf) - 1] = '\\0';\n        old_preload = GETENV(\"LD_PRELOAD\");\n        if (old_preload != NULL) {\n          size_t old_len = strlen(old_preload);\n          if (old_len >= PRELOAD_SZ) {\n            will_fail = TRUE;\n            break;\n          }\n          BCOPY(old_preload, preload_buf, old_len + 1);\n          unsetenv(\"LD_PRELOAD\");\n        }\n        pipe = popen(cmd_buf, \"r\");\n        if (old_preload != NULL\n            && setenv(\"LD_PRELOAD\", preload_buf, 0 /* overwrite */) == -1) {\n          WARN(\"Failed to reset LD_PRELOAD\\n\", 0);\n        }\n        if (NULL == pipe) {\n          will_fail = TRUE;\n          break;\n        }\n        result_len = fread(result_buf, 1, RESULT_SZ - 1, pipe);\n        (void)pclose(pipe);\n        if (0 == result_len) {\n          will_fail = TRUE;\n          break;\n        }\n        if (result_buf[result_len - 1] == '\\n')\n          --result_len;\n        result_buf[result_len] = 0;\n        if (result_buf[0] == '?'\n            || (result_buf[result_len - 2] == ':'\n                && result_buf[result_len - 1] == '0'))\n          break;\n        /* Get rid of embedded newline, if any.  Test for \"main\". */\n        {\n          char *nl = strchr(result_buf, '\\n');\n          if (nl != NULL && ADDR_LT(nl, result_buf + result_len)) {\n            *nl = ':';\n          }\n          if (strncmp(result_buf, \"main\",\n                      nl != NULL\n                          ? (size_t)(ADDR(nl) /* a cppcheck workaround */\n                                     - COVERT_DATAFLOW(ADDR(result_buf)))\n                          : result_len)\n              == 0) {\n            stop = TRUE;\n          }\n        }\n        if (result_len < RESULT_SZ - 25) {\n          /* Add address in the hex format.     */\n          (void)snprintf(&result_buf[result_len],\n                         sizeof(result_buf) - result_len, \" [0x%lx]\",\n                         (unsigned long)ADDR(info[i].ci_pc));\n          result_buf[sizeof(result_buf) - 1] = '\\0';\n        }\n#    if defined(CPPCHECK)\n        GC_noop1((unsigned char)name[0]);\n        /* The value of name computed previously is discarded. */\n#    endif\n        name = result_buf;\n      } while (0);\n#  endif /* LINUX */\n      GC_err_printf(\"\\t\\t%s\\n\", name);\n#  if defined(GC_HAVE_BUILTIN_BACKTRACE) \\\n      && !defined(GC_BACKTRACE_SYMBOLS_BROKEN) && defined(FUNCPTR_IS_DATAPTR)\n      if (sym_name != NULL) {\n        /* May call GC_[debug_]free; that's OK.   */\n        free(sym_name);\n      }\n#  endif\n    }\n#  if defined(LINUX) && !defined(SMALL_CONFIG)\n    if (stop)\n      break;\n#  endif\n  }\n#  if defined(AO_HAVE_fetch_and_add1) && defined(AO_HAVE_fetch_and_sub1)\n  (void)AO_fetch_and_sub1(&reentry_count);\n#  else\n  LOCK();\n  --reentry_count;\n  UNLOCK();\n#  endif\n}\n\n#endif /* NEED_CALLINFO */\n\n#if defined(LINUX) && defined(__ELF__) && !defined(SMALL_CONFIG)\n/* Dump /proc/self/maps to GC_stderr, to enable looking up names for  */\n/* addresses in FIND_LEAK output.                                     */\nvoid\nGC_print_address_map(void)\n{\n  const char *maps_ptr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  maps_ptr = GC_get_maps();\n  GC_err_printf(\"---------- Begin address map ----------\\n\");\n  GC_err_puts(maps_ptr);\n  GC_err_printf(\"---------- End address map ----------\\n\");\n}\n#endif /* LINUX && ELF */\n"
        },
        {
          "name": "pthread_start.c",
          "type": "blob",
          "size": 3.0205078125,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n * Copyright (c) 2000-2010 by Hewlett-Packard Development Company.\n * All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n/* We want to make sure that GC_thread_exit_proc() is unconditionally   */\n/* invoked, even if the client is not compiled with -fexceptions, but   */\n/* the GC is.  The workaround is to put GC_pthread_start_inner() in its */\n/* own file (pthread_start.c), and undefine __EXCEPTIONS in the GCC     */\n/* case at the top of the file.  FIXME: it's still unclear whether this */\n/* will actually cause the exit handler to be invoked last when         */\n/* thread_exit is called (and if -fexceptions is used).                 */\n#if !defined(DONT_UNDEF_EXCEPTIONS) && defined(__GNUC__) && defined(__linux__)\n/* We undefine __EXCEPTIONS to avoid using GCC __cleanup__ attribute. */\n/* The current NPTL implementation of pthread_cleanup_push uses       */\n/* __cleanup__ attribute when __EXCEPTIONS is defined (-fexceptions). */\n/* The stack unwinding and cleanup with __cleanup__ attributes work   */\n/* correctly when everything is compiled with -fexceptions, but it is */\n/* not the requirement for this library clients to use -fexceptions   */\n/* everywhere.  With __EXCEPTIONS undefined, the cleanup routines are */\n/* registered with __pthread_register_cancel thus should work anyway. */\n#  undef __EXCEPTIONS\n#endif\n\n#include \"private/pthread_support.h\"\n\n#if defined(GC_PTHREADS) && !defined(PLATFORM_THREADS) \\\n    && !defined(SN_TARGET_PSP2)\n\n/* Invoked from GC_pthread_start. */\nGC_INNER_PTHRSTART void *GC_CALLBACK\nGC_pthread_start_inner(struct GC_stack_base *sb, void *arg)\n{\n  void *(*start)(void *);\n  void *start_arg;\n  void *result;\n  volatile GC_thread me\n      = GC_start_rtn_prepare_thread(&start, &start_arg, sb, arg);\n\n#  ifndef NACL\n  pthread_cleanup_push(GC_thread_exit_proc, (/* no volatile */ void *)me);\n#  endif\n  result = (*start)(start_arg);\n#  if defined(DEBUG_THREADS) && !defined(GC_PTHREAD_START_STANDALONE)\n  GC_log_printf(\"Finishing thread %p\\n\", PTHREAD_TO_VPTR(pthread_self()));\n#  endif\n  me->status = result;\n  /* Note: we cannot use GC_dirty() instead.    */\n  GC_end_stubborn_change(me);\n\n  /* Cleanup acquires the allocator lock, ensuring that we cannot exit  */\n  /* while a collection that thinks we are alive is trying to stop us.  */\n#  ifdef NACL\n  GC_thread_exit_proc((/* no volatile */ void *)me);\n#  else\n  pthread_cleanup_pop(1);\n#  endif\n  return result;\n}\n\n#endif /* GC_PTHREADS */\n"
        },
        {
          "name": "pthread_stop_world.c",
          "type": "blob",
          "size": 47.705078125,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n * Copyright (c) 2000-2009 by Hewlett-Packard Development Company.\n * All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/pthread_support.h\"\n\n#ifdef PTHREAD_STOP_WORLD_IMPL\n\n#  ifdef NACL\n#    include <sys/time.h>\n#  else\n#    include <errno.h>\n#    include <semaphore.h>\n#    include <signal.h>\n#    include <time.h>\n#  endif /* !NACL */\n\n#  ifdef E2K\n#    include <alloca.h>\n#  endif\n\nGC_INLINE void\nGC_usleep(unsigned us)\n{\n#  if defined(LINT2) || defined(THREAD_SANITIZER)\n  /* Workaround \"waiting while holding a lock\" static analyzer warning. */\n  /* Workaround a rare hang in usleep() trying to acquire TSan Lock.    */\n  while (us-- > 0) {\n    /* Sleep for a moment, pretending it takes 1us. */\n    sched_yield();\n  }\n#  elif defined(CPPCHECK) /* || _POSIX_C_SOURCE >= 199309L */\n  struct timespec ts;\n\n  ts.tv_sec = 0;\n  ts.tv_nsec = (unsigned32)us * 1000;\n  /* This requires _POSIX_TIMERS feature. */\n  (void)nanosleep(&ts, NULL);\n#  else\n  usleep(us);\n#  endif\n}\n\n#  ifdef NACL\n\nSTATIC int GC_nacl_num_gc_threads = 0;\nSTATIC volatile int GC_nacl_park_threads_now = 0;\nSTATIC volatile pthread_t GC_nacl_thread_parker = -1;\n\nSTATIC __thread int GC_nacl_thread_idx = -1;\n\n/* TODO: Use GC_get_tlfs() instead. */\nSTATIC __thread GC_thread GC_nacl_gc_thread_self = NULL;\n\nvolatile int GC_nacl_thread_parked[MAX_NACL_GC_THREADS];\nint GC_nacl_thread_used[MAX_NACL_GC_THREADS];\n\n#  else /* !NACL */\n\n#    if (!defined(AO_HAVE_load_acquire) || !defined(AO_HAVE_store_release)) \\\n        && !defined(CPPCHECK)\n#      error AO_load_acquire and/or AO_store_release are missing;\n#      error please define AO_REQUIRE_CAS manually\n#    endif\n\n#    ifdef DEBUG_THREADS\n/* It's safe to call original pthread_sigmask() here. */\n#      undef pthread_sigmask\n\n#      ifndef NSIG\n#        ifdef CPPCHECK\n#          define NSIG 32\n#        elif defined(MAXSIG)\n#          define NSIG (MAXSIG + 1)\n#        elif defined(_NSIG)\n#          define NSIG _NSIG\n#        elif defined(__SIGRTMAX)\n#          define NSIG (__SIGRTMAX + 1)\n#        else\n#          error define NSIG\n#        endif\n#      endif\n\nvoid\nGC_print_sig_mask(void)\n{\n  sigset_t blocked;\n  int i;\n\n  if (pthread_sigmask(SIG_BLOCK, NULL, &blocked) != 0)\n    ABORT(\"pthread_sigmask failed\");\n  for (i = 1; i < NSIG; i++) {\n    if (sigismember(&blocked, i))\n      GC_printf(\"Signal blocked: %d\\n\", i);\n  }\n}\n#    endif /* DEBUG_THREADS */\n\n/* Remove the signals that we want to allow in thread stopping  */\n/* handler from a set.                                          */\nSTATIC void\nGC_remove_allowed_signals(sigset_t *set)\n{\n  if (sigdelset(set, SIGINT) != 0 || sigdelset(set, SIGQUIT) != 0\n      || sigdelset(set, SIGABRT) != 0 || sigdelset(set, SIGTERM) != 0) {\n    ABORT(\"sigdelset failed\");\n  }\n\n#    ifdef MPROTECT_VDB\n  /* Handlers write to the thread structure, which is in the heap,  */\n  /* and hence can trigger a protection fault.                      */\n  if (sigdelset(set, SIGSEGV) != 0\n#      ifdef HAVE_SIGBUS\n      || sigdelset(set, SIGBUS) != 0\n#      endif\n  ) {\n    ABORT(\"sigdelset failed\");\n  }\n#    endif\n}\n\nstatic sigset_t suspend_handler_mask;\n\n#    define THREAD_RESTARTED 0x1\n\n/* Incremented (to the nearest even value) at the beginning of          */\n/* GC_stop_world() (or when a thread is requested to be suspended by    */\n/* GC_suspend_thread) and once more (to an odd value) at the beginning  */\n/* of GC_start_world().  The lowest bit is THREAD_RESTARTED one which,  */\n/* if set, means it is safe for threads to restart, i.e. they will see  */\n/* another suspend signal before they are expected to stop (unless they */\n/* have stopped voluntarily).                                           */\nSTATIC volatile AO_t GC_stop_count;\n\nSTATIC GC_bool GC_retry_signals = FALSE;\n\n/*\n * We use signals to stop threads during GC.\n *\n * Suspended threads wait in signal handler for SIG_THR_RESTART.\n * That's more portable than semaphores or condition variables.\n * (We do use sem_post from a signal handler, but that should be portable.)\n *\n * The thread suspension signal SIG_SUSPEND is now defined in gc_priv.h.\n * Note that we can't just stop a thread; we need it to save its stack\n * pointer(s) and acknowledge.\n */\n#    ifndef SIG_THR_RESTART\n#      if defined(SUSPEND_HANDLER_NO_CONTEXT) || defined(GC_REUSE_SIG_SUSPEND)\n/* Reuse the suspend signal. */\n#        define SIG_THR_RESTART SIG_SUSPEND\n#      elif defined(HPUX) || defined(NETBSD) || defined(OSF1) \\\n          || defined(GC_USESIGRT_SIGNALS)\n#        if defined(_SIGRTMIN) && !defined(CPPCHECK)\n#          define SIG_THR_RESTART (_SIGRTMIN + 5)\n#        else\n#          define SIG_THR_RESTART (SIGRTMIN + 5)\n#        endif\n#      elif defined(FREEBSD) && defined(__GLIBC__)\n#        define SIG_THR_RESTART (32 + 5)\n#      elif defined(FREEBSD) || defined(HURD) || defined(RTEMS)\n#        define SIG_THR_RESTART SIGUSR2\n#      else\n#        define SIG_THR_RESTART SIGXCPU\n#      endif\n#    endif /* !SIG_THR_RESTART */\n\n#    define SIGNAL_UNSET (-1)\n\n/* Since SIG_SUSPEND and/or SIG_THR_RESTART could represent             */\n/* a non-constant expression (e.g., in case of SIGRTMIN), actual signal */\n/* numbers are determined by GC_stop_init() unless manually set (before */\n/* GC initialization).  Might be set to the same signal number.         */\nSTATIC int GC_sig_suspend = SIGNAL_UNSET;\nSTATIC int GC_sig_thr_restart = SIGNAL_UNSET;\n\nGC_API void GC_CALL\nGC_set_suspend_signal(int sig)\n{\n  if (GC_is_initialized)\n    return;\n\n  GC_sig_suspend = sig;\n}\n\nGC_API void GC_CALL\nGC_set_thr_restart_signal(int sig)\n{\n  if (GC_is_initialized)\n    return;\n\n  GC_sig_thr_restart = sig;\n}\n\nGC_API int GC_CALL\nGC_get_suspend_signal(void)\n{\n  return GC_sig_suspend != SIGNAL_UNSET ? GC_sig_suspend : SIG_SUSPEND;\n}\n\nGC_API int GC_CALL\nGC_get_thr_restart_signal(void)\n{\n  return GC_sig_thr_restart != SIGNAL_UNSET ? GC_sig_thr_restart\n                                            : SIG_THR_RESTART;\n}\n\n#    ifdef BASE_ATOMIC_OPS_EMULATED\n/* The AO primitives emulated with locks cannot be used inside signal */\n/* handlers as this could cause a deadlock or a double lock.          */\n/* The following \"async\" macro definitions are correct only for       */\n/* an uniprocessor case and are provided for a test purpose.          */\n#      define ao_load_acquire_async(p) (*(p))\n#      define ao_load_async(p) ao_load_acquire_async(p)\n#      define ao_store_release_async(p, v) (void)(*(p) = (v))\n#      define ao_cptr_store_async(p, v) (void)(*(p) = (v))\n#    else\n#      define ao_load_acquire_async(p) AO_load_acquire(p)\n#      define ao_load_async(p) AO_load(p)\n#      define ao_store_release_async(p, v) AO_store_release(p, v)\n#      define ao_cptr_store_async(p, v) GC_cptr_store(p, v)\n#    endif /* !BASE_ATOMIC_OPS_EMULATED */\n\n/* Note: this is also used to acknowledge restart.      */\nSTATIC sem_t GC_suspend_ack_sem;\n\nSTATIC void GC_suspend_handler_inner(ptr_t dummy, void *context);\n\n#    ifdef SUSPEND_HANDLER_NO_CONTEXT\nSTATIC void\nGC_suspend_handler(int sig)\n#    else\nSTATIC void\nGC_suspend_sigaction(int sig, siginfo_t *info, void *context)\n#    endif\n{\n  int old_errno = errno;\n\n  if (sig != GC_sig_suspend) {\n#    ifdef FREEBSD\n    /* Workaround \"deferred signal handling\" bug in FreeBSD 9.2.      */\n    if (0 == sig)\n      return;\n#    endif\n    ABORT(\"Bad signal in suspend_handler\");\n  }\n\n#    ifdef SUSPEND_HANDLER_NO_CONTEXT\n  /* A quick check if the signal is called to restart the world.      */\n  if ((ao_load_async(&GC_stop_count) & THREAD_RESTARTED) != 0)\n    return;\n  GC_with_callee_saves_pushed(GC_suspend_handler_inner, NULL);\n#    else\n  UNUSED_ARG(info);\n  /* We believe that in this case the full context is already         */\n  /* in the signal handler frame.                                     */\n  GC_suspend_handler_inner(NULL, context);\n#    endif\n  errno = old_errno;\n}\n\n/* The lookup here is safe, since this is done on behalf        */\n/* of a thread which holds the allocator lock in order          */\n/* to stop the world.  Thus concurrent modification of the      */\n/* data structure is impossible.  Unfortunately, we have to     */\n/* instruct TSan that the lookup is safe.                       */\n#    ifdef THREAD_SANITIZER\n/* Almost same as GC_self_thread_inner() except for the       */\n/* no-sanitize attribute added and the result is never NULL.  */\nGC_ATTR_NO_SANITIZE_THREAD\nstatic GC_thread\nGC_lookup_self_thread_async(void)\n{\n  thread_id_t self_id = thread_id_self();\n  GC_thread p = GC_threads[THREAD_TABLE_INDEX(self_id)];\n\n  for (;; p = p->tm.next) {\n    if (THREAD_EQUAL(p->id, self_id))\n      break;\n  }\n  return p;\n}\n#    else\n#      define GC_lookup_self_thread_async() GC_self_thread_inner()\n#    endif\n\nGC_INLINE void\nGC_store_stack_ptr(GC_stack_context_t crtn)\n{\n  /* There is no data race between the suspend handler (storing         */\n  /* stack_ptr) and GC_push_all_stacks (fetching stack_ptr) because     */\n  /* GC_push_all_stacks is executed after GC_stop_world exits and the   */\n  /* latter runs sem_wait repeatedly waiting for all the suspended      */\n  /* threads to call sem_post.  Nonetheless, stack_ptr is stored (here) */\n  /* and fetched (by GC_push_all_stacks) using the atomic primitives to */\n  /* avoid the related TSan warning.                                    */\n#    ifdef SPARC\n  ao_cptr_store_async(&crtn->stack_ptr, GC_save_regs_in_stack());\n  /* TODO: regs saving already done by GC_with_callee_saves_pushed */\n#    else\n#      ifdef IA64\n  crtn->backing_store_ptr = GC_save_regs_in_stack();\n#      endif\n  ao_cptr_store_async(&crtn->stack_ptr, GC_approx_sp());\n#    endif\n}\n\nSTATIC void\nGC_suspend_handler_inner(ptr_t dummy, void *context)\n{\n  GC_thread me;\n  GC_stack_context_t crtn;\n#    ifdef E2K\n  ptr_t bs_lo;\n  size_t stack_size;\n#    endif\n  IF_CANCEL(int cancel_state;)\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n  AO_t suspend_cnt;\n#    endif\n  AO_t my_stop_count = ao_load_acquire_async(&GC_stop_count);\n  /* After the barrier, this thread should see the actual content of    */\n  /* GC_threads.                                                        */\n\n  UNUSED_ARG(dummy);\n  UNUSED_ARG(context);\n  if ((my_stop_count & THREAD_RESTARTED) != 0) {\n    /* Restarting the world.    */\n    return;\n  }\n\n  /* pthread_setcancelstate() is not defined to be async-signal-safe.   */\n  /* But the glibc version appears to be in the absence of asynchronous */\n  /* cancellation.  And since this signal handler to block on           */\n  /* sigsuspend, which is both async-signal-safe and a cancellation     */\n  /* point, there seems to be no obvious way out of it.  In fact, it    */\n  /* looks to me like an async-signal-safe cancellation point is        */\n  /* inherently a problem, unless there is some way to disable          */\n  /* cancellation in the handler.                                       */\n  DISABLE_CANCEL(cancel_state);\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"Suspending %p\\n\", PTHREAD_TO_VPTR(pthread_self()));\n#    endif\n  me = GC_lookup_self_thread_async();\n  if ((me->last_stop_count & ~(word)THREAD_RESTARTED) == my_stop_count) {\n    /* Duplicate signal.  OK if we are retrying.      */\n    if (!GC_retry_signals) {\n      WARN(\"Duplicate suspend signal in thread %p\\n\", pthread_self());\n    }\n    RESTORE_CANCEL(cancel_state);\n    return;\n  }\n  crtn = me->crtn;\n  GC_store_stack_ptr(crtn);\n#    ifdef E2K\n  GC_ASSERT(NULL == crtn->backing_store_end);\n  GET_PROCEDURE_STACK_LOCAL(crtn->ps_ofs, &bs_lo, &stack_size);\n  crtn->backing_store_end = bs_lo;\n  crtn->backing_store_ptr = bs_lo + stack_size;\n#    endif\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n  suspend_cnt = ao_load_async(&me->ext_suspend_cnt);\n#    endif\n\n  /* Tell the thread that wants to stop the world that this     */\n  /* thread has been stopped.  Note that sem_post() is          */\n  /* the only async-signal-safe primitive in LinuxThreads.      */\n  sem_post(&GC_suspend_ack_sem);\n  ao_store_release_async(&me->last_stop_count, my_stop_count);\n\n  /* Wait until that thread tells us to restart by sending      */\n  /* this thread a GC_sig_thr_restart signal (should be masked  */\n  /* at this point thus there is no race).                      */\n  /* We do not continue until we receive that signal,           */\n  /* but we do not take that as authoritative.  (We may be      */\n  /* accidentally restarted by one of the user signals we       */\n  /* don't block.)  After we receive the signal, we use a       */\n  /* primitive and expensive mechanism to wait until it's       */\n  /* really safe to proceed.  Under normal circumstances,       */\n  /* this code should not be executed.                          */\n  do {\n    sigsuspend(&suspend_handler_mask);\n    /* Iterate while not restarting the world or thread is suspended. */\n  } while (ao_load_acquire_async(&GC_stop_count) == my_stop_count\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n           || ((suspend_cnt & 1) != 0\n               && ao_load_async(&me->ext_suspend_cnt) == suspend_cnt)\n#    endif\n  );\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"Resuming %p\\n\", PTHREAD_TO_VPTR(pthread_self()));\n#    endif\n#    ifdef E2K\n  GC_ASSERT(crtn->backing_store_end == bs_lo);\n  crtn->backing_store_ptr = NULL;\n  crtn->backing_store_end = NULL;\n#    endif\n\n#    ifndef GC_NETBSD_THREADS_WORKAROUND\n  if (GC_retry_signals || GC_sig_suspend == GC_sig_thr_restart)\n#    endif\n  {\n    /* If the RESTART signal loss is possible (though it should be      */\n    /* less likely than losing the SUSPEND signal as we do not do       */\n    /* much between the first sem_post and sigsuspend calls), more      */\n    /* handshaking is provided to work around it.                       */\n    sem_post(&GC_suspend_ack_sem);\n    /* Set the flag that the thread has been restarted. */\n    if (GC_retry_signals)\n      ao_store_release_async(&me->last_stop_count,\n                             my_stop_count | THREAD_RESTARTED);\n  }\n  RESTORE_CANCEL(cancel_state);\n}\n\nstatic void\nsuspend_restart_barrier(int n_live_threads)\n{\n  int i;\n\n  for (i = 0; i < n_live_threads; i++) {\n    while (sem_wait(&GC_suspend_ack_sem) == -1) {\n      /* On Linux, sem_wait is documented to always return zero.      */\n      /* But the documentation appears to be incorrect.               */\n      /* EINTR seems to happen with some versions of gdb.             */\n      if (errno != EINTR)\n        ABORT(\"sem_wait failed\");\n    }\n  }\n#    ifdef GC_ASSERTIONS\n  sem_getvalue(&GC_suspend_ack_sem, &i);\n  GC_ASSERT(0 == i);\n#    endif\n}\n\n#    define WAIT_UNIT 3000 /* us */\n\nstatic int\nresend_lost_signals(int n_live_threads, int (*suspend_restart_all)(void))\n{\n#    define RESEND_SIGNALS_LIMIT 150\n#    define RETRY_INTERVAL 100000 /* us */\n\n  if (n_live_threads > 0) {\n    unsigned long wait_usecs = 0; /* total wait since retry */\n    int retry = 0;\n    int prev_sent = 0;\n\n    for (;;) {\n      int ack_count;\n\n      sem_getvalue(&GC_suspend_ack_sem, &ack_count);\n      if (ack_count == n_live_threads)\n        break;\n      if (wait_usecs > RETRY_INTERVAL) {\n        int newly_sent = suspend_restart_all();\n\n        if (newly_sent != prev_sent) {\n          /* Restart the counter.     */\n          retry = 0;\n        } else if (++retry >= RESEND_SIGNALS_LIMIT) {\n          /* No progress.     */\n          ABORT_ARG1(\"Signals delivery fails constantly\", \" at GC #%lu\",\n                     (unsigned long)GC_gc_no);\n        }\n\n        GC_COND_LOG_PRINTF(\"Resent %d signals after timeout, retry: %d\\n\",\n                           newly_sent, retry);\n        sem_getvalue(&GC_suspend_ack_sem, &ack_count);\n        if (newly_sent < n_live_threads - ack_count) {\n          WARN(\"Lost some threads while stopping or starting world?!\\n\", 0);\n          n_live_threads = ack_count + newly_sent;\n        }\n        prev_sent = newly_sent;\n        wait_usecs = 0;\n      }\n      GC_usleep(WAIT_UNIT);\n      wait_usecs += WAIT_UNIT;\n    }\n  }\n  return n_live_threads;\n}\n\n#    ifdef HAVE_CLOCK_GETTIME\n#      define TS_NSEC_ADD(ts, ns)                                     \\\n        (ts.tv_nsec += (ns),                                          \\\n         (void)(ts.tv_nsec >= 1000000L * 1000                         \\\n                    ? (ts.tv_nsec -= 1000000L * 1000, ts.tv_sec++, 0) \\\n                    : 0))\n#    endif\n\nstatic void\nresend_lost_signals_retry(int n_live_threads, int (*suspend_restart_all)(void))\n{\n#    if defined(HAVE_CLOCK_GETTIME) && !defined(DONT_TIMEDWAIT_ACK_SEM)\n#      define TIMEOUT_BEFORE_RESEND 10000 /* us */\n  struct timespec ts;\n\n  if (n_live_threads > 0 && clock_gettime(CLOCK_REALTIME, &ts) == 0) {\n    int i;\n\n    TS_NSEC_ADD(ts, TIMEOUT_BEFORE_RESEND * (unsigned32)1000);\n    /* First, try to wait for the semaphore with some timeout.            */\n    /* On failure, fallback to WAIT_UNIT pause and resend of the signal.  */\n    for (i = 0; i < n_live_threads; i++) {\n      if (sem_timedwait(&GC_suspend_ack_sem, &ts) == -1)\n        break; /* Wait timed out or any other error.  */\n    }\n    /* Update the count of threads to wait the ack from.      */\n    n_live_threads -= i;\n  }\n#    endif\n  n_live_threads = resend_lost_signals(n_live_threads, suspend_restart_all);\n  suspend_restart_barrier(n_live_threads);\n}\n\nSTATIC void\nGC_restart_handler(int sig)\n{\n#    ifdef DEBUG_THREADS\n  /* Preserve errno value.    */\n  int old_errno = errno;\n#    endif\n\n  if (sig != GC_sig_thr_restart)\n    ABORT(\"Bad signal in restart handler\");\n\n    /* Note: even if we do not do anything useful here, it would still    */\n    /* be necessary to have a signal handler, rather than ignoring the    */\n    /* signals, otherwise the signals will not be delivered at all,       */\n    /* and will thus not interrupt the sigsuspend() above.                */\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"In GC_restart_handler for %p\\n\",\n                PTHREAD_TO_VPTR(pthread_self()));\n  errno = old_errno;\n#    endif\n}\n\n#    ifdef USE_TKILL_ON_ANDROID\nEXTERN_C_BEGIN\nextern int tkill(pid_t tid, int sig); /* from sys/linux-unistd.h */\nEXTERN_C_END\n#      define THREAD_SYSTEM_ID(t) (t)->kernel_id\n#    else\n#      define THREAD_SYSTEM_ID(t) (t)->id\n#    endif\n\n#    ifndef RETRY_TKILL_EAGAIN_LIMIT\n#      define RETRY_TKILL_EAGAIN_LIMIT 16\n#    endif\n\nstatic int\nraise_signal(GC_thread p, int sig)\n{\n  int res;\n#    ifdef RETRY_TKILL_ON_EAGAIN\n  int retry;\n#    endif\n#    if defined(SIMULATE_LOST_SIGNALS) && !defined(GC_ENABLE_SUSPEND_THREAD)\n#      ifndef LOST_SIGNALS_RATIO\n#        define LOST_SIGNALS_RATIO 25\n#      endif\n  /* Note: race is OK, it is for test purpose only. */\n  static int signal_cnt;\n\n  if (GC_retry_signals && (++signal_cnt) % LOST_SIGNALS_RATIO == 0) {\n    /* Simulate the signal is sent but lost.        */\n    return 0;\n  }\n#    endif\n#    ifdef RETRY_TKILL_ON_EAGAIN\n  for (retry = 0;; retry++)\n#    endif\n  {\n#    ifdef USE_TKILL_ON_ANDROID\n    int old_errno = errno;\n\n    res = tkill(THREAD_SYSTEM_ID(p), sig);\n    if (res < 0) {\n      res = errno;\n      errno = old_errno;\n    }\n#    else\n    res = pthread_kill(THREAD_SYSTEM_ID(p), sig);\n#    endif\n#    ifdef RETRY_TKILL_ON_EAGAIN\n    if (res != EAGAIN || retry >= RETRY_TKILL_EAGAIN_LIMIT)\n      break;\n    /* A temporal overflow of the real-time signal queue.   */\n    GC_usleep(WAIT_UNIT);\n#    endif\n  }\n  return res;\n}\n\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n#      include <sys/time.h>\n\n/* This is to get the prototypes as extern \"C\".     */\n#      include \"gc/javaxfc.h\"\n\nSTATIC void\nGC_brief_async_signal_safe_sleep(void)\n{\n  struct timeval tv;\n  tv.tv_sec = 0;\n#      if defined(GC_TIME_LIMIT) && !defined(CPPCHECK)\n  tv.tv_usec = 1000 * GC_TIME_LIMIT / 2;\n#      else\n  tv.tv_usec = 1000 * 15 / 2;\n#      endif\n  (void)select(0, 0, 0, 0, &tv);\n}\n\nGC_INNER void\nGC_suspend_self_inner(GC_thread me, size_t suspend_cnt)\n{\n  IF_CANCEL(int cancel_state;)\n\n  GC_ASSERT((suspend_cnt & 1) != 0);\n  DISABLE_CANCEL(cancel_state);\n#      ifdef DEBUG_THREADS\n  GC_log_printf(\"Suspend self: %p\\n\", THREAD_ID_TO_VPTR(me->id));\n#      endif\n  while (ao_load_acquire_async(&me->ext_suspend_cnt) == suspend_cnt) {\n    /* TODO: Use sigsuspend() even for self-suspended threads. */\n    GC_brief_async_signal_safe_sleep();\n  }\n#      ifdef DEBUG_THREADS\n  GC_log_printf(\"Resume self: %p\\n\", THREAD_ID_TO_VPTR(me->id));\n#      endif\n  RESTORE_CANCEL(cancel_state);\n}\n\nGC_API void GC_CALL\nGC_suspend_thread(GC_SUSPEND_THREAD_ID thread)\n{\n  GC_thread t;\n  AO_t next_stop_count;\n  AO_t suspend_cnt;\n  IF_CANCEL(int cancel_state;)\n\n  LOCK();\n  t = GC_lookup_by_pthread((pthread_t)thread);\n  if (NULL == t) {\n    UNLOCK();\n    return;\n  }\n  suspend_cnt = t->ext_suspend_cnt;\n  if ((suspend_cnt & 1) != 0) /* already suspended? */ {\n    GC_ASSERT(!THREAD_EQUAL((pthread_t)thread, pthread_self()));\n    UNLOCK();\n    return;\n  }\n  if ((t->flags & (FINISHED | DO_BLOCKING)) != 0) {\n    t->ext_suspend_cnt = suspend_cnt | 1; /* suspend */\n    /* Terminated but not joined yet, or in do-blocking state.  */\n    UNLOCK();\n    return;\n  }\n\n  if (THREAD_EQUAL((pthread_t)thread, pthread_self())) {\n    t->ext_suspend_cnt = suspend_cnt | 1;\n    GC_with_callee_saves_pushed(GC_suspend_self_blocked, (ptr_t)t);\n    UNLOCK();\n    return;\n  }\n\n  /* GC_suspend_thread is not a cancellation point. */\n  DISABLE_CANCEL(cancel_state);\n#      ifdef PARALLEL_MARK\n  /* Ensure we do not suspend a thread while it is rebuilding */\n  /* a free list, otherwise such a deadlock is possible:      */\n  /* thread 1 is blocked in GC_wait_for_reclaim holding       */\n  /* the allocator lock, thread 2 is suspended in             */\n  /* GC_reclaim_generic invoked from GC_generic_malloc_many   */\n  /* (with GC_fl_builder_count > 0), and thread 3 is blocked  */\n  /* acquiring the allocator lock in GC_resume_thread.        */\n  if (GC_parallel)\n    GC_wait_for_reclaim();\n#      endif\n\n  if (GC_manual_vdb) {\n    /* See the relevant comment in GC_stop_world.   */\n    GC_acquire_dirty_lock();\n  }\n  /* Else do not acquire the dirty lock as the write fault handler  */\n  /* might be trying to acquire it too, and the suspend handler     */\n  /* execution is deferred until the write fault handler completes. */\n\n  next_stop_count = GC_stop_count + THREAD_RESTARTED;\n  GC_ASSERT((next_stop_count & THREAD_RESTARTED) == 0);\n  AO_store(&GC_stop_count, next_stop_count);\n\n  /* Set the flag making the change visible to the signal handler.  */\n  AO_store_release(&t->ext_suspend_cnt, suspend_cnt | 1);\n\n  /* TODO: Support GC_retry_signals (not needed for TSan) */\n  switch (raise_signal(t, GC_sig_suspend)) {\n  /* ESRCH cannot happen as terminated threads are handled above.   */\n  case 0:\n    break;\n  default:\n    ABORT(\"pthread_kill failed\");\n  }\n\n  /* Wait for the thread to complete threads table lookup and   */\n  /* stack_ptr assignment.                                      */\n  GC_ASSERT(GC_thr_initialized);\n  suspend_restart_barrier(1);\n  if (GC_manual_vdb)\n    GC_release_dirty_lock();\n  AO_store(&GC_stop_count, next_stop_count | THREAD_RESTARTED);\n\n  RESTORE_CANCEL(cancel_state);\n  UNLOCK();\n}\n\nGC_API void GC_CALL\nGC_resume_thread(GC_SUSPEND_THREAD_ID thread)\n{\n  GC_thread t;\n\n  LOCK();\n  t = GC_lookup_by_pthread((pthread_t)thread);\n  if (t != NULL) {\n    AO_t suspend_cnt = t->ext_suspend_cnt;\n\n    if ((suspend_cnt & 1) != 0) /* is suspended? */ {\n      GC_ASSERT((GC_stop_count & THREAD_RESTARTED) != 0);\n      /* Mark the thread as not suspended - it will be resumed shortly. */\n      AO_store(&t->ext_suspend_cnt, suspend_cnt + 1);\n\n      if ((t->flags & (FINISHED | DO_BLOCKING)) == 0) {\n        int result = raise_signal(t, GC_sig_thr_restart);\n\n        /* TODO: Support signal resending on GC_retry_signals */\n        if (result != 0)\n          ABORT_ARG1(\"pthread_kill failed in GC_resume_thread\",\n                     \": errcode= %d\", result);\n#      ifndef GC_NETBSD_THREADS_WORKAROUND\n        if (GC_retry_signals || GC_sig_suspend == GC_sig_thr_restart)\n#      endif\n        {\n          IF_CANCEL(int cancel_state;)\n\n          DISABLE_CANCEL(cancel_state);\n          suspend_restart_barrier(1);\n          RESTORE_CANCEL(cancel_state);\n        }\n      }\n    }\n  }\n  UNLOCK();\n}\n\nGC_API int GC_CALL\nGC_is_thread_suspended(GC_SUSPEND_THREAD_ID thread)\n{\n  GC_thread t;\n  int is_suspended = 0;\n\n  READER_LOCK();\n  t = GC_lookup_by_pthread((pthread_t)thread);\n  if (t != NULL && (t->ext_suspend_cnt & 1) != 0)\n    is_suspended = (int)TRUE;\n  READER_UNLOCK();\n  return is_suspended;\n}\n#    endif /* GC_ENABLE_SUSPEND_THREAD */\n\n#    undef ao_cptr_store_async\n#    undef ao_load_acquire_async\n#    undef ao_load_async\n#    undef ao_store_release_async\n#  endif /* !NACL */\n\n/* Should do exactly the right thing if the world is stopped; should    */\n/* not fail if it is not.                                               */\nGC_INNER void\nGC_push_all_stacks(void)\n{\n  GC_bool found_me = FALSE;\n  size_t nthreads = 0;\n  int i;\n  GC_thread p;\n  ptr_t lo; /* stack top (sp) */\n  ptr_t hi; /* bottom */\n#  if defined(E2K) || defined(IA64)\n  /* We also need to scan the register backing store.   */\n  ptr_t bs_lo, bs_hi;\n#  endif\n  struct GC_traced_stack_sect_s *traced_stack_sect;\n  pthread_t self = pthread_self();\n  word total_size = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_thr_initialized);\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Pushing stacks from thread %p\\n\", PTHREAD_TO_VPTR(self));\n#  endif\n  for (i = 0; i < THREAD_TABLE_SZ; i++) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n#  if defined(E2K) || defined(IA64)\n      GC_bool is_self = FALSE;\n#  endif\n      GC_stack_context_t crtn = p->crtn;\n\n      GC_ASSERT(THREAD_TABLE_INDEX(p->id) == i);\n      if (KNOWN_FINISHED(p))\n        continue;\n      ++nthreads;\n      traced_stack_sect = crtn->traced_stack_sect;\n      if (THREAD_EQUAL(p->id, self)) {\n        GC_ASSERT((p->flags & DO_BLOCKING) == 0);\n#  ifdef SPARC\n        lo = GC_save_regs_in_stack();\n#  else\n        lo = GC_approx_sp();\n#    ifdef IA64\n        bs_hi = GC_save_regs_in_stack();\n#    elif defined(E2K)\n        {\n          size_t stack_size;\n\n          GC_ASSERT(NULL == crtn->backing_store_end);\n          GET_PROCEDURE_STACK_LOCAL(crtn->ps_ofs, &bs_lo, &stack_size);\n          bs_hi = bs_lo + stack_size;\n        }\n#    endif\n#  endif\n        found_me = TRUE;\n#  if defined(E2K) || defined(IA64)\n        is_self = TRUE;\n#  endif\n      } else {\n        lo = GC_cptr_load(&crtn->stack_ptr);\n#  ifdef IA64\n        bs_hi = crtn->backing_store_ptr;\n#  elif defined(E2K)\n        bs_lo = crtn->backing_store_end;\n        bs_hi = crtn->backing_store_ptr;\n#  endif\n        if (traced_stack_sect != NULL\n            && traced_stack_sect->saved_stack_ptr == lo) {\n          /* If the thread has never been stopped since the recent  */\n          /* GC_call_with_gc_active invocation then skip the top    */\n          /* \"stack section\" as stack_ptr already points to.        */\n          traced_stack_sect = traced_stack_sect->prev;\n        }\n      }\n      hi = crtn->stack_end;\n#  ifdef IA64\n      bs_lo = crtn->backing_store_end;\n#  endif\n#  ifdef DEBUG_THREADS\n#    ifdef STACK_GROWS_UP\n      GC_log_printf(\"Stack for thread %p is (%p,%p]\\n\",\n                    THREAD_ID_TO_VPTR(p->id), (void *)hi, (void *)lo);\n#    else\n      GC_log_printf(\"Stack for thread %p is [%p,%p)\\n\",\n                    THREAD_ID_TO_VPTR(p->id), (void *)lo, (void *)hi);\n#    endif\n#  endif\n      if (NULL == lo)\n        ABORT(\"GC_push_all_stacks: sp not set!\");\n      if (crtn->altstack != NULL && ADDR_GE(lo, crtn->altstack)\n          && ADDR_GE(crtn->altstack + crtn->altstack_size, lo)) {\n#  ifdef STACK_GROWS_UP\n        hi = crtn->altstack;\n#  else\n        hi = crtn->altstack + crtn->altstack_size;\n#  endif\n        /* FIXME: Need to scan the normal stack too, but how ? */\n      }\n#  ifdef STACKPTR_CORRECTOR_AVAILABLE\n      if (GC_sp_corrector != 0)\n        GC_sp_corrector((void **)&lo, THREAD_ID_TO_VPTR(p->id));\n#  endif\n      GC_push_all_stack_sections(lo, hi, traced_stack_sect);\n#  ifdef STACK_GROWS_UP\n      total_size += lo - hi;\n#  else\n      total_size += hi - lo; /* lo <= hi */\n#  endif\n#  ifdef NACL\n      /* Push reg_storage as roots, this will cover the reg context. */\n      GC_push_all_stack((ptr_t)p->reg_storage,\n                        (ptr_t)(p->reg_storage + NACL_GC_REG_STORAGE_SIZE));\n      total_size += NACL_GC_REG_STORAGE_SIZE * sizeof(ptr_t);\n#  endif\n#  ifdef E2K\n      if ((GC_stop_count & THREAD_RESTARTED) != 0\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n          && (p->ext_suspend_cnt & 1) == 0\n#    endif\n          && !is_self && (p->flags & DO_BLOCKING) == 0) {\n        /* Procedure stack buffer has already been freed.   */\n        continue;\n      }\n#  endif\n#  if defined(E2K) || defined(IA64)\n#    ifdef DEBUG_THREADS\n      GC_log_printf(\"Reg stack for thread %p is [%p,%p)\\n\",\n                    THREAD_ID_TO_VPTR(p->id), (void *)bs_lo, (void *)bs_hi);\n#    endif\n      GC_ASSERT(bs_lo != NULL && bs_hi != NULL);\n      /* FIXME: This (if is_self) may add an unbounded number of    */\n      /* entries, and hence overflow the mark stack, which is bad.  */\n#    ifdef IA64\n      GC_push_all_register_sections(bs_lo, bs_hi, is_self, traced_stack_sect);\n#    else\n      if (is_self) {\n        GC_push_all_eager(bs_lo, bs_hi);\n      } else {\n        GC_push_all_stack(bs_lo, bs_hi);\n      }\n#    endif\n      total_size += bs_hi - bs_lo; /* bs_lo <= bs_hi */\n#  endif\n    }\n  }\n  GC_VERBOSE_LOG_PRINTF(\"Pushed %d thread stacks\\n\", (int)nthreads);\n  if (!found_me && !GC_in_thread_creation)\n    ABORT(\"Collecting from unknown thread\");\n  GC_total_stacksize = total_size;\n}\n\n#  ifdef DEBUG_THREADS\n/* There seems to be a very rare thread stopping problem.  To help us */\n/* debug that, we save the ids of the stopping thread.                */\npthread_t GC_stopping_thread;\nint GC_stopping_pid = 0;\n#  endif\n\n/* Suspend all threads that might still be running.  Return the number  */\n/* of suspend signals that were sent.                                   */\nSTATIC int\nGC_suspend_all(void)\n{\n  int n_live_threads = 0;\n  int i;\n#  ifndef NACL\n  GC_thread p;\n  pthread_t self = pthread_self();\n  int result;\n\n  GC_ASSERT((GC_stop_count & THREAD_RESTARTED) == 0);\n  GC_ASSERT(I_HOLD_LOCK());\n  for (i = 0; i < THREAD_TABLE_SZ; i++) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      if (!THREAD_EQUAL(p->id, self)) {\n        if ((p->flags & (FINISHED | DO_BLOCKING)) != 0)\n          continue;\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n        if ((p->ext_suspend_cnt & 1) != 0)\n          continue;\n#    endif\n        if (AO_load(&p->last_stop_count) == GC_stop_count) {\n          /* Matters only if GC_retry_signals.  */\n          continue;\n        }\n        n_live_threads++;\n#    ifdef DEBUG_THREADS\n        GC_log_printf(\"Sending suspend signal to %p\\n\",\n                      THREAD_ID_TO_VPTR(p->id));\n#    endif\n\n        /* The synchronization between GC_dirty (based on       */\n        /* test-and-set) and the signal-based thread suspension */\n        /* is performed in GC_stop_world because                */\n        /* GC_release_dirty_lock cannot be called before        */\n        /* acknowledging the thread is really suspended.        */\n        result = raise_signal(p, GC_sig_suspend);\n        switch (result) {\n        case ESRCH:\n          /* Not really there anymore.  Possible? */\n          n_live_threads--;\n          break;\n        case 0:\n          if (GC_on_thread_event) {\n            /* Note: thread id might be truncated.    */\n            GC_on_thread_event(GC_EVENT_THREAD_SUSPENDED,\n                               THREAD_ID_TO_VPTR(THREAD_SYSTEM_ID(p)));\n          }\n          break;\n        default:\n          ABORT_ARG1(\"pthread_kill failed at suspend\", \": errcode= %d\",\n                     result);\n        }\n      }\n    }\n  }\n\n#  else /* NACL */\n#    ifndef NACL_PARK_WAIT_USEC\n#      define NACL_PARK_WAIT_USEC 100 /* us */\n#    endif\n  unsigned long num_sleeps = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"pthread_stop_world: number of threads: %d\\n\",\n                GC_nacl_num_gc_threads - 1);\n#    endif\n  GC_nacl_thread_parker = pthread_self();\n  GC_nacl_park_threads_now = 1;\n\n  if (GC_manual_vdb)\n    GC_acquire_dirty_lock();\n  for (;;) {\n    int num_threads_parked = 0;\n    int num_used = 0;\n\n    /* Check the 'parked' flag for each thread the GC knows about.    */\n    for (i = 0; i < MAX_NACL_GC_THREADS && num_used < GC_nacl_num_gc_threads;\n         i++) {\n      if (GC_nacl_thread_used[i] == 1) {\n        num_used++;\n        if (GC_nacl_thread_parked[i] == 1) {\n          num_threads_parked++;\n          if (GC_on_thread_event)\n            GC_on_thread_event(GC_EVENT_THREAD_SUSPENDED, NUMERIC_TO_VPTR(i));\n        }\n      }\n    }\n    /* Note: -1 for the current thread.       */\n    if (num_threads_parked >= GC_nacl_num_gc_threads - 1)\n      break;\n#    ifdef DEBUG_THREADS\n    GC_log_printf(\"Sleep waiting for %d threads to park...\\n\",\n                  GC_nacl_num_gc_threads - num_threads_parked - 1);\n#    endif\n    GC_usleep(NACL_PARK_WAIT_USEC);\n    if (++num_sleeps > (1000 * 1000) / NACL_PARK_WAIT_USEC) {\n      WARN(\"GC appears stalled waiting for %\" WARN_PRIdPTR\n           \" threads to park...\\n\",\n           GC_nacl_num_gc_threads - num_threads_parked - 1);\n      num_sleeps = 0;\n    }\n  }\n  if (GC_manual_vdb)\n    GC_release_dirty_lock();\n#  endif /* NACL */\n  return n_live_threads;\n}\n\nGC_INNER void\nGC_stop_world(void)\n{\n#  ifndef NACL\n  int n_live_threads;\n#  endif\n  GC_ASSERT(I_HOLD_LOCK());\n  /* Make sure all free list construction has stopped before we start.  */\n  /* No new construction can start, since it is required to acquire and */\n  /* release the allocator lock before start.                           */\n\n  GC_ASSERT(GC_thr_initialized);\n#  ifdef DEBUG_THREADS\n  GC_stopping_thread = pthread_self();\n  GC_stopping_pid = getpid();\n  GC_log_printf(\"Stopping the world from %p\\n\",\n                PTHREAD_TO_VPTR(GC_stopping_thread));\n#  endif\n#  ifdef PARALLEL_MARK\n  if (GC_parallel) {\n    GC_acquire_mark_lock();\n    GC_ASSERT(GC_fl_builder_count == 0);\n    /* We should have previously waited for it to become zero.        */\n  }\n#  endif /* PARALLEL_MARK */\n\n#  ifdef NACL\n  (void)GC_suspend_all();\n#  else\n  /* Note: only concurrent reads are possible.        */\n  AO_store(&GC_stop_count, GC_stop_count + THREAD_RESTARTED);\n  if (GC_manual_vdb) {\n    GC_acquire_dirty_lock();\n    /* The write fault handler cannot be called if GC_manual_vdb      */\n    /* (thus double-locking should not occur in                       */\n    /* async_set_pht_entry_from_index based on test-and-set).         */\n  }\n  n_live_threads = GC_suspend_all();\n  if (GC_retry_signals) {\n    resend_lost_signals_retry(n_live_threads, GC_suspend_all);\n  } else {\n    suspend_restart_barrier(n_live_threads);\n  }\n  if (GC_manual_vdb) {\n    /* Note: cannot be done in GC_suspend_all.        */\n    GC_release_dirty_lock();\n  }\n#  endif\n\n#  ifdef PARALLEL_MARK\n  if (GC_parallel)\n    GC_release_mark_lock();\n#  endif\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"World stopped from %p\\n\", PTHREAD_TO_VPTR(pthread_self()));\n  GC_stopping_thread = 0;\n#  endif\n}\n\n#  ifdef NACL\n#    if defined(__x86_64__)\n#      define NACL_STORE_REGS()                                 \\\n        do {                                                    \\\n          __asm__ __volatile__(\"push %rbx\");                    \\\n          __asm__ __volatile__(\"push %rbp\");                    \\\n          __asm__ __volatile__(\"push %r12\");                    \\\n          __asm__ __volatile__(\"push %r13\");                    \\\n          __asm__ __volatile__(\"push %r14\");                    \\\n          __asm__ __volatile__(\"push %r15\");                    \\\n          __asm__ __volatile__(                                 \\\n              \"mov %%esp, %0\"                                   \\\n              : \"=m\"(GC_nacl_gc_thread_self->crtn->stack_ptr)); \\\n          BCOPY(GC_nacl_gc_thread_self->crtn->stack_ptr,        \\\n                GC_nacl_gc_thread_self->reg_storage,            \\\n                NACL_GC_REG_STORAGE_SIZE * sizeof(ptr_t));      \\\n          __asm__ __volatile__(\"naclasp $48, %r15\");            \\\n        } while (0)\n#    elif defined(__i386__)\n#      define NACL_STORE_REGS()                                 \\\n        do {                                                    \\\n          __asm__ __volatile__(\"push %ebx\");                    \\\n          __asm__ __volatile__(\"push %ebp\");                    \\\n          __asm__ __volatile__(\"push %esi\");                    \\\n          __asm__ __volatile__(\"push %edi\");                    \\\n          __asm__ __volatile__(                                 \\\n              \"mov %%esp, %0\"                                   \\\n              : \"=m\"(GC_nacl_gc_thread_self->crtn->stack_ptr)); \\\n          BCOPY(GC_nacl_gc_thread_self->crtn->stack_ptr,        \\\n                GC_nacl_gc_thread_self->reg_storage,            \\\n                NACL_GC_REG_STORAGE_SIZE * sizeof(ptr_t));      \\\n          __asm__ __volatile__(\"add $16, %esp\");                \\\n        } while (0)\n#    elif defined(__arm__)\n#      define NACL_STORE_REGS()                                 \\\n        do {                                                    \\\n          __asm__ __volatile__(\"push {r4-r8,r10-r12,lr}\");      \\\n          __asm__ __volatile__(                                 \\\n              \"mov r0, %0\"                                      \\\n              :                                                 \\\n              : \"r\"(&GC_nacl_gc_thread_self->crtn->stack_ptr)); \\\n          __asm__ __volatile__(\"bic r0, r0, #0xc0000000\");      \\\n          __asm__ __volatile__(\"str sp, [r0]\");                 \\\n          BCOPY(GC_nacl_gc_thread_self->crtn->stack_ptr,        \\\n                GC_nacl_gc_thread_self->reg_storage,            \\\n                NACL_GC_REG_STORAGE_SIZE * sizeof(ptr_t));      \\\n          __asm__ __volatile__(\"add sp, sp, #40\");              \\\n          __asm__ __volatile__(\"bic sp, sp, #0xc0000000\");      \\\n        } while (0)\n#    else\n#      error TODO Please port NACL_STORE_REGS\n#    endif\n\nGC_API_OSCALL void\nnacl_pre_syscall_hook(void)\n{\n  if (GC_nacl_thread_idx != -1) {\n    NACL_STORE_REGS();\n    GC_nacl_gc_thread_self->crtn->stack_ptr = GC_approx_sp();\n    GC_nacl_thread_parked[GC_nacl_thread_idx] = 1;\n  }\n}\n\nGC_API_OSCALL void\n__nacl_suspend_thread_if_needed(void)\n{\n  if (!GC_nacl_park_threads_now)\n    return;\n\n  /* Don't try to park the thread parker.   */\n  if (GC_nacl_thread_parker == pthread_self())\n    return;\n\n  /* This can happen when a thread is created outside of the GC     */\n  /* system (wthread mostly).                                       */\n  if (GC_nacl_thread_idx < 0)\n    return;\n\n  /* If it was already 'parked', we're returning from a syscall,    */\n  /* so don't bother storing registers again, the GC has a set.     */\n  if (!GC_nacl_thread_parked[GC_nacl_thread_idx]) {\n    NACL_STORE_REGS();\n    GC_nacl_gc_thread_self->crtn->stack_ptr = GC_approx_sp();\n  }\n  GC_nacl_thread_parked[GC_nacl_thread_idx] = 1;\n  while (GC_nacl_park_threads_now) {\n    /* Just spin.   */\n  }\n  GC_nacl_thread_parked[GC_nacl_thread_idx] = 0;\n\n  /* Clear out the reg storage for next suspend.    */\n  BZERO(GC_nacl_gc_thread_self->reg_storage,\n        NACL_GC_REG_STORAGE_SIZE * sizeof(ptr_t));\n}\n\nGC_API_OSCALL void\nnacl_post_syscall_hook(void)\n{\n  /* Calling __nacl_suspend_thread_if_needed right away should        */\n  /* guarantee we don't mutate the GC set.                            */\n  __nacl_suspend_thread_if_needed();\n  if (GC_nacl_thread_idx != -1) {\n    GC_nacl_thread_parked[GC_nacl_thread_idx] = 0;\n  }\n}\n\nSTATIC GC_bool GC_nacl_thread_parking_inited = FALSE;\nSTATIC pthread_mutex_t GC_nacl_thread_alloc_lock = PTHREAD_MUTEX_INITIALIZER;\n\nstruct nacl_irt_blockhook {\n  int (*register_block_hooks)(void (*pre)(void), void (*post)(void));\n};\n\nEXTERN_C_BEGIN\nextern size_t nacl_interface_query(const char *interface_ident, void *table,\n                                   size_t tablesize);\nEXTERN_C_END\n\nGC_INNER void\nGC_nacl_initialize_gc_thread(GC_thread me)\n{\n  int i;\n  static struct nacl_irt_blockhook gc_hook;\n\n  GC_ASSERT(NULL == GC_nacl_gc_thread_self);\n  GC_nacl_gc_thread_self = me;\n  pthread_mutex_lock(&GC_nacl_thread_alloc_lock);\n  if (!EXPECT(GC_nacl_thread_parking_inited, TRUE)) {\n    BZERO(GC_nacl_thread_parked, sizeof(GC_nacl_thread_parked));\n    BZERO(GC_nacl_thread_used, sizeof(GC_nacl_thread_used));\n    /* TODO: replace with public 'register hook' function when        */\n    /* available from glibc.                                          */\n    nacl_interface_query(\"nacl-irt-blockhook-0.1\", &gc_hook, sizeof(gc_hook));\n    gc_hook.register_block_hooks(nacl_pre_syscall_hook,\n                                 nacl_post_syscall_hook);\n    GC_nacl_thread_parking_inited = TRUE;\n  }\n  GC_ASSERT(GC_nacl_num_gc_threads <= MAX_NACL_GC_THREADS);\n  for (i = 0; i < MAX_NACL_GC_THREADS; i++) {\n    if (GC_nacl_thread_used[i] == 0) {\n      GC_nacl_thread_used[i] = 1;\n      GC_nacl_thread_idx = i;\n      GC_nacl_num_gc_threads++;\n      break;\n    }\n  }\n  pthread_mutex_unlock(&GC_nacl_thread_alloc_lock);\n}\n\nGC_INNER void\nGC_nacl_shutdown_gc_thread(void)\n{\n  GC_ASSERT(GC_nacl_gc_thread_self != NULL);\n  pthread_mutex_lock(&GC_nacl_thread_alloc_lock);\n  GC_ASSERT(GC_nacl_thread_idx >= 0);\n  GC_ASSERT(GC_nacl_thread_idx < MAX_NACL_GC_THREADS);\n  GC_ASSERT(GC_nacl_thread_used[GC_nacl_thread_idx] != 0);\n  GC_nacl_thread_used[GC_nacl_thread_idx] = 0;\n  GC_nacl_thread_idx = -1;\n  GC_nacl_num_gc_threads--;\n  pthread_mutex_unlock(&GC_nacl_thread_alloc_lock);\n  GC_nacl_gc_thread_self = NULL;\n}\n\n#  else /* !NACL */\n\nstatic GC_bool in_resend_restart_signals;\n\n/* Restart all threads that were suspended by the collector.  */\n/* Return the number of restart signals that were sent.       */\nSTATIC int\nGC_restart_all(void)\n{\n  int n_live_threads = 0;\n  int i;\n  pthread_t self = pthread_self();\n  GC_thread p;\n  int result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT((GC_stop_count & THREAD_RESTARTED) != 0);\n  for (i = 0; i < THREAD_TABLE_SZ; i++) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      if (!THREAD_EQUAL(p->id, self)) {\n        if ((p->flags & (FINISHED | DO_BLOCKING)) != 0)\n          continue;\n#    ifdef GC_ENABLE_SUSPEND_THREAD\n        if ((p->ext_suspend_cnt & 1) != 0)\n          continue;\n#    endif\n        if (GC_retry_signals\n            && AO_load(&p->last_stop_count) == GC_stop_count) {\n          /* The thread has been restarted.   */\n          if (!in_resend_restart_signals) {\n            /* Some user signal (which we do not block, e.g. SIGQUIT) */\n            /* has already restarted the thread, but nonetheless we   */\n            /* need to count the thread in n_live_threads, so that    */\n            /* to decrement the semaphore's value proper amount of    */\n            /* times.  (We are also sending the restart signal to the */\n            /* thread, it is not needed actually but does not hurt.)  */\n          } else {\n            continue;\n            /* FIXME: Still, an extremely low chance exists that the  */\n            /* user signal restarts the thread after the restart      */\n            /* signal has been lost (causing sem_timedwait() to fail) */\n            /* while retrying, causing finally a mismatch between     */\n            /* GC_suspend_ack_sem and n_live_threads.                 */\n          }\n        }\n        n_live_threads++;\n#    ifdef DEBUG_THREADS\n        GC_log_printf(\"Sending restart signal to %p\\n\",\n                      THREAD_ID_TO_VPTR(p->id));\n#    endif\n        result = raise_signal(p, GC_sig_thr_restart);\n        switch (result) {\n        case ESRCH:\n          /* Not really there anymore.  Possible?   */\n          n_live_threads--;\n          break;\n        case 0:\n          if (GC_on_thread_event)\n            GC_on_thread_event(GC_EVENT_THREAD_UNSUSPENDED,\n                               THREAD_ID_TO_VPTR(THREAD_SYSTEM_ID(p)));\n          break;\n        default:\n          ABORT_ARG1(\"pthread_kill failed at resume\", \": errcode= %d\", result);\n        }\n      }\n    }\n  }\n  return n_live_threads;\n}\n#  endif /* !NACL */\n\nGC_INNER void\nGC_start_world(void)\n{\n#  ifndef NACL\n  int n_live_threads;\n\n  /* The allocator lock is held continuously since the world stopped. */\n  GC_ASSERT(I_HOLD_LOCK());\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"World starting\\n\");\n#    endif\n  /* Note: the updated value should now be visible to the signal      */\n  /* handler (note that pthread_kill is not on the list of functions  */\n  /* which synchronize memory).                                       */\n  AO_store_release(&GC_stop_count, GC_stop_count + THREAD_RESTARTED);\n\n  GC_ASSERT(!in_resend_restart_signals);\n  n_live_threads = GC_restart_all();\n  if (GC_retry_signals) {\n    in_resend_restart_signals = TRUE;\n    resend_lost_signals_retry(n_live_threads, GC_restart_all);\n    in_resend_restart_signals = FALSE;\n  } else {\n#    ifndef GC_NETBSD_THREADS_WORKAROUND\n    if (GC_sig_suspend == GC_sig_thr_restart)\n#    endif\n    {\n      suspend_restart_barrier(n_live_threads);\n    }\n  }\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"World started\\n\");\n#    endif\n#  else /* NACL */\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"World starting...\\n\");\n#    endif\n  GC_nacl_park_threads_now = 0;\n  if (GC_on_thread_event) {\n    GC_on_thread_event(GC_EVENT_THREAD_UNSUSPENDED, NULL);\n    /* TODO: Send event for every unsuspended thread. */\n  }\n#  endif\n}\n\nGC_INNER void\nGC_stop_init(void)\n{\n#  ifndef NACL\n  struct sigaction act;\n  char *str;\n\n  if (SIGNAL_UNSET == GC_sig_suspend)\n    GC_sig_suspend = SIG_SUSPEND;\n  if (SIGNAL_UNSET == GC_sig_thr_restart)\n    GC_sig_thr_restart = SIG_THR_RESTART;\n\n  if (sem_init(&GC_suspend_ack_sem, GC_SEM_INIT_PSHARED, 0) == -1)\n    ABORT(\"sem_init failed\");\n  GC_stop_count = THREAD_RESTARTED; /* i.e. the world is not stopped */\n\n  if (sigfillset(&act.sa_mask) != 0) {\n    ABORT(\"sigfillset failed\");\n  }\n#    ifdef RTEMS\n  if (sigprocmask(SIG_UNBLOCK, &act.sa_mask, NULL) != 0) {\n    ABORT(\"sigprocmask failed\");\n  }\n#    endif\n  GC_remove_allowed_signals(&act.sa_mask);\n  /* GC_sig_thr_restart is set in the resulting mask. */\n  /* It is unmasked by the handler when necessary.    */\n\n#    ifdef SA_RESTART\n  act.sa_flags = SA_RESTART;\n#    else\n  act.sa_flags = 0;\n#    endif\n#    ifdef SUSPEND_HANDLER_NO_CONTEXT\n  act.sa_handler = GC_suspend_handler;\n#    else\n  act.sa_flags |= SA_SIGINFO;\n  act.sa_sigaction = GC_suspend_sigaction;\n#    endif\n  /* act.sa_restorer is deprecated and should not be initialized. */\n  if (sigaction(GC_sig_suspend, &act, NULL) != 0) {\n    ABORT(\"Cannot set SIG_SUSPEND handler\");\n  }\n\n  if (GC_sig_suspend != GC_sig_thr_restart) {\n#    ifndef SUSPEND_HANDLER_NO_CONTEXT\n    act.sa_flags &= ~SA_SIGINFO;\n#    endif\n    act.sa_handler = GC_restart_handler;\n    if (sigaction(GC_sig_thr_restart, &act, NULL) != 0)\n      ABORT(\"Cannot set SIG_THR_RESTART handler\");\n  } else {\n    GC_COND_LOG_PRINTF(\"Using same signal for suspend and restart\\n\");\n  }\n\n  /* Initialize suspend_handler_mask (excluding GC_sig_thr_restart).  */\n  if (sigfillset(&suspend_handler_mask) != 0)\n    ABORT(\"sigfillset failed\");\n  GC_remove_allowed_signals(&suspend_handler_mask);\n  if (sigdelset(&suspend_handler_mask, GC_sig_thr_restart) != 0)\n    ABORT(\"sigdelset failed\");\n\n#    ifndef NO_RETRY_SIGNALS\n  /* Any platform could lose signals, so let's be conservative and  */\n  /* always enable signals retry logic.                             */\n  GC_retry_signals = TRUE;\n#    endif\n  /* Override the default value of GC_retry_signals.  */\n  str = GETENV(\"GC_RETRY_SIGNALS\");\n  if (str != NULL) {\n    /* Do not retry if the environment variable is set to \"0\".      */\n    GC_retry_signals = *str != '0' || *(str + 1) != '\\0';\n  }\n  if (GC_retry_signals) {\n    GC_COND_LOG_PRINTF(\n        \"Will retry suspend and restart signals if necessary\\n\");\n  }\n#    ifndef NO_SIGNALS_UNBLOCK_IN_MAIN\n  /* Explicitly unblock the signals once before new threads creation. */\n  GC_unblock_gc_signals();\n#    endif\n#  endif /* !NACL */\n}\n\n#endif /* PTHREAD_STOP_WORLD_IMPL */\n"
        },
        {
          "name": "pthread_support.c",
          "type": "blob",
          "size": 100.3486328125,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n * Copyright (c) 2000-2008 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/pthread_support.h\"\n\n/*\n * Support code originally for LinuxThreads, the clone()-based kernel\n * thread package for Linux which is included in libc6.\n *\n * This code no doubt makes some assumptions beyond what is\n * guaranteed by the pthread standard, though it now does\n * very little of that.  It now also supports NPTL, and many\n * other Posix thread implementations.  We are trying to merge\n * all flavors of pthread support code into this file.\n */\n\n#ifdef THREADS\n\n#  ifdef GC_PTHREADS\n#    if defined(DARWIN) \\\n        || (defined(GC_WIN32_THREADS) && defined(EMULATE_PTHREAD_SEMAPHORE))\n#      include \"private/darwin_semaphore.h\"\n#    elif !defined(PLATFORM_THREADS) && !defined(SN_TARGET_PSP2)\n#      include <semaphore.h>\n#    endif\n#    include <errno.h>\n#  endif /* GC_PTHREADS */\n\n#  if !defined(GC_WIN32_THREADS)\n#    include <sched.h>\n#    include <time.h>\n#    if !defined(PLATFORM_THREADS) && !defined(SN_TARGET_PSP2)\n#      ifndef RTEMS\n#        include <sys/mman.h>\n#      endif\n#      include <fcntl.h>\n#      include <sys/stat.h>\n#      include <sys/time.h>\n#    endif\n#    if defined(GC_EXPLICIT_SIGNALS_UNBLOCK) \\\n        || !defined(GC_NO_PTHREAD_SIGMASK)   \\\n        || (defined(GC_PTHREADS_PARAMARK)    \\\n            && !defined(NO_MARKER_SPECIAL_SIGMASK))\n#      include <signal.h>\n#    endif\n#  endif /* !GC_WIN32_THREADS */\n\n#  ifdef E2K\n#    include <alloca.h>\n#  endif\n\n#  if defined(DARWIN) || defined(ANY_BSD)\n#    if defined(NETBSD) || defined(OPENBSD)\n#      include <sys/param.h>\n#    endif\n#    include <sys/sysctl.h>\n#  elif defined(DGUX)\n#    include <sys/_int_psem.h>\n#    include <sys/dg_sys_info.h>\n/* sem_t is an uint in DG/UX */\ntypedef unsigned int sem_t;\n#  endif\n\n#  if defined(GC_PTHREADS) && !defined(PLATFORM_THREADS) \\\n      && !defined(SN_TARGET_PSP2)\n/* Undefine macros used to redirect pthread primitives.       */\n#    undef pthread_create\n#    ifndef GC_NO_PTHREAD_SIGMASK\n#      undef pthread_sigmask\n#    endif\n#    ifndef GC_NO_PTHREAD_CANCEL\n#      undef pthread_cancel\n#    endif\n#    ifdef GC_HAVE_PTHREAD_EXIT\n#      undef pthread_exit\n#    endif\n#    undef pthread_join\n#    undef pthread_detach\n#    if defined(OSF1) && defined(_PTHREAD_USE_MANGLED_NAMES_) \\\n        && !defined(_PTHREAD_USE_PTDNAM_)\n/* Restore the original mangled names on Tru64 UNIX.        */\n#      define pthread_create __pthread_create\n#      define pthread_join __pthread_join\n#      define pthread_detach __pthread_detach\n#      ifndef GC_NO_PTHREAD_CANCEL\n#        define pthread_cancel __pthread_cancel\n#      endif\n#      ifdef GC_HAVE_PTHREAD_EXIT\n#        define pthread_exit __pthread_exit\n#      endif\n#    endif\n#  endif /* GC_PTHREADS */\n\n#  if !defined(GC_WIN32_THREADS) && !defined(PLATFORM_THREADS) \\\n      && !defined(SN_TARGET_PSP2)\n/* TODO: Enable GC_USE_DLOPEN_WRAP for Cygwin? */\n\n#    ifdef GC_USE_LD_WRAP\n#      define WRAP_FUNC(f) __wrap_##f\n#      define REAL_FUNC(f) __real_##f\nint REAL_FUNC(pthread_create)(pthread_t *,\n                              GC_PTHREAD_CREATE_CONST pthread_attr_t *,\n                              void *(*start_routine)(void *), void *);\nint REAL_FUNC(pthread_join)(pthread_t, void **);\nint REAL_FUNC(pthread_detach)(pthread_t);\n#      ifndef GC_NO_PTHREAD_SIGMASK\nint REAL_FUNC(pthread_sigmask)(int, const sigset_t *, sigset_t *);\n#      endif\n#      ifndef GC_NO_PTHREAD_CANCEL\nint REAL_FUNC(pthread_cancel)(pthread_t);\n#      endif\n#      ifdef GC_HAVE_PTHREAD_EXIT\nvoid REAL_FUNC(pthread_exit)(void *) GC_PTHREAD_EXIT_ATTRIBUTE;\n#      endif\n#    elif defined(GC_USE_DLOPEN_WRAP)\n#      include <dlfcn.h>\n#      define WRAP_FUNC(f) f\n#      define REAL_FUNC(f) GC_real_##f\n/* We define both GC_f and plain f to be the wrapped function.  */\n/* In that way plain calls work, as do calls from files that    */\n/* included gc.h, which redefined f to GC_f.                    */\n/* FIXME: Needs work for DARWIN and True64 (OSF1) */\ntypedef int (*GC_pthread_create_t)(pthread_t *,\n                                   GC_PTHREAD_CREATE_CONST pthread_attr_t *,\n                                   void *(*)(void *), void *);\nstatic GC_pthread_create_t REAL_FUNC(pthread_create);\n#      ifndef GC_NO_PTHREAD_SIGMASK\ntypedef int (*GC_pthread_sigmask_t)(int, const sigset_t *, sigset_t *);\nstatic GC_pthread_sigmask_t REAL_FUNC(pthread_sigmask);\n#      endif\ntypedef int (*GC_pthread_join_t)(pthread_t, void **);\nstatic GC_pthread_join_t REAL_FUNC(pthread_join);\ntypedef int (*GC_pthread_detach_t)(pthread_t);\nstatic GC_pthread_detach_t REAL_FUNC(pthread_detach);\n#      ifndef GC_NO_PTHREAD_CANCEL\ntypedef int (*GC_pthread_cancel_t)(pthread_t);\nstatic GC_pthread_cancel_t REAL_FUNC(pthread_cancel);\n#      endif\n#      ifdef GC_HAVE_PTHREAD_EXIT\ntypedef void (*GC_pthread_exit_t)(void *) GC_PTHREAD_EXIT_ATTRIBUTE;\nstatic GC_pthread_exit_t REAL_FUNC(pthread_exit);\n#      endif\n#    else\n#      define WRAP_FUNC(f) GC_##f\n#      ifdef DGUX\n#        define REAL_FUNC(f) __d10_##f\n#      else\n#        define REAL_FUNC(f) f\n#      endif\n#    endif /* !GC_USE_LD_WRAP && !GC_USE_DLOPEN_WRAP */\n\n#    if defined(GC_USE_LD_WRAP) || defined(GC_USE_DLOPEN_WRAP)\n/* Define GC_ functions as aliases for the plain ones, which will   */\n/* be intercepted.  This allows files which include gc.h, and hence */\n/* generate references to the GC_ symbols, to see the right ones.   */\nGC_API int\nGC_pthread_create(pthread_t *t, GC_PTHREAD_CREATE_CONST pthread_attr_t *a,\n                  void *(*fn)(void *), void *arg)\n{\n  return pthread_create(t, a, fn, arg);\n}\n\n#      ifndef GC_NO_PTHREAD_SIGMASK\nGC_API int\nGC_pthread_sigmask(int how, const sigset_t *mask, sigset_t *old)\n{\n  return pthread_sigmask(how, mask, old);\n}\n#      endif /* !GC_NO_PTHREAD_SIGMASK */\n\nGC_API int\nGC_pthread_join(pthread_t t, void **res)\n{\n  return pthread_join(t, res);\n}\n\nGC_API int\nGC_pthread_detach(pthread_t t)\n{\n  return pthread_detach(t);\n}\n\n#      ifndef GC_NO_PTHREAD_CANCEL\nGC_API int\nGC_pthread_cancel(pthread_t t)\n{\n  return pthread_cancel(t);\n}\n#      endif /* !GC_NO_PTHREAD_CANCEL */\n\n#      ifdef GC_HAVE_PTHREAD_EXIT\nGC_API GC_PTHREAD_EXIT_ATTRIBUTE void\nGC_pthread_exit(void *retval)\n{\n  pthread_exit(retval);\n}\n#      endif\n#    endif /* GC_USE_LD_WRAP || GC_USE_DLOPEN_WRAP */\n\n#    ifdef GC_USE_DLOPEN_WRAP\nSTATIC GC_bool GC_syms_initialized = FALSE;\n\n/* Resolve a symbol from the dynamic library (given by a handle)    */\n/* and cast it to the given functional type.                        */\n#      define TYPED_DLSYM(fn, h, name) CAST_THRU_UINTPTR(fn, dlsym(h, name))\n\nSTATIC void\nGC_init_real_syms(void)\n{\n  void *dl_handle;\n\n  GC_ASSERT(!GC_syms_initialized);\n#      ifdef RTLD_NEXT\n  dl_handle = RTLD_NEXT;\n#      else\n  dl_handle = dlopen(\"libpthread.so.0\", RTLD_LAZY);\n  if (NULL == dl_handle) {\n    /* Retry without \".0\" suffix. */\n    dl_handle = dlopen(\"libpthread.so\", RTLD_LAZY);\n    if (NULL == dl_handle)\n      ABORT(\"Couldn't open libpthread\");\n  }\n#      endif\n  REAL_FUNC(pthread_create)\n      = TYPED_DLSYM(GC_pthread_create_t, dl_handle, \"pthread_create\");\n#      ifdef RTLD_NEXT\n  if (REAL_FUNC(pthread_create) == 0)\n    ABORT(\"pthread_create not found\"\n          \" (probably -lgc is specified after -lpthread)\");\n#      endif\n#      ifndef GC_NO_PTHREAD_SIGMASK\n  REAL_FUNC(pthread_sigmask)\n      = TYPED_DLSYM(GC_pthread_sigmask_t, dl_handle, \"pthread_sigmask\");\n#      endif\n  REAL_FUNC(pthread_join)\n      = TYPED_DLSYM(GC_pthread_join_t, dl_handle, \"pthread_join\");\n  REAL_FUNC(pthread_detach)\n      = TYPED_DLSYM(GC_pthread_detach_t, dl_handle, \"pthread_detach\");\n#      ifndef GC_NO_PTHREAD_CANCEL\n  REAL_FUNC(pthread_cancel)\n      = TYPED_DLSYM(GC_pthread_cancel_t, dl_handle, \"pthread_cancel\");\n#      endif\n#      ifdef GC_HAVE_PTHREAD_EXIT\n  REAL_FUNC(pthread_exit)\n      = TYPED_DLSYM(GC_pthread_exit_t, dl_handle, \"pthread_exit\");\n#      endif\n  GC_syms_initialized = TRUE;\n}\n\n#      define INIT_REAL_SYMS()                   \\\n        if (EXPECT(GC_syms_initialized, TRUE)) { \\\n        } else                                   \\\n          GC_init_real_syms()\n#    else\n#      define INIT_REAL_SYMS() (void)0\n#    endif /* !GC_USE_DLOPEN_WRAP */\n\n#  else\n#    define WRAP_FUNC(f) GC_##f\n#    define REAL_FUNC(f) f\n#    define INIT_REAL_SYMS() (void)0\n#  endif /* GC_WIN32_THREADS */\n\n#  if defined(MPROTECT_VDB) && defined(DARWIN)\nGC_INNER int\nGC_inner_pthread_create(pthread_t *t,\n                        GC_PTHREAD_CREATE_CONST pthread_attr_t *a,\n                        void *(*fn)(void *), void *arg)\n{\n  INIT_REAL_SYMS();\n  return REAL_FUNC(pthread_create)(t, a, fn, arg);\n}\n#  endif\n\n#  ifndef GC_ALWAYS_MULTITHREADED\nGC_INNER GC_bool GC_need_to_lock = FALSE;\n#  endif\n\n#  ifdef THREAD_LOCAL_ALLOC\n\n/* We must explicitly mark ptrfree and gcj free lists, since the free */\n/* list links wouldn't otherwise be found.  We also set them in the   */\n/* normal free lists, since that involves touching less memory than   */\n/* if we scanned them normally.                                       */\nGC_INNER void\nGC_mark_thread_local_free_lists(void)\n{\n  int i;\n  GC_thread p;\n\n  for (i = 0; i < THREAD_TABLE_SZ; ++i) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      if (!KNOWN_FINISHED(p))\n        GC_mark_thread_local_fls_for(&p->tlfs);\n    }\n  }\n}\n\n#    if defined(GC_ASSERTIONS)\n/* Check that all thread-local free-lists are completely marked.    */\n/* Also check that thread-specific-data structures are marked.      */\nvoid\nGC_check_tls(void)\n{\n  int i;\n  GC_thread p;\n\n  for (i = 0; i < THREAD_TABLE_SZ; ++i) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      if (!KNOWN_FINISHED(p))\n        GC_check_tls_for(&p->tlfs);\n    }\n  }\n#      if defined(USE_CUSTOM_SPECIFIC)\n  if (GC_thread_key != 0)\n    GC_check_tsd_marks(GC_thread_key);\n#      endif\n}\n#    endif\n\n#  endif /* THREAD_LOCAL_ALLOC */\n\n#  ifdef GC_WIN32_THREADS\n/* A macro for functions and variables which should be accessible     */\n/* from win32_threads.c but otherwise could be static.                */\n#    define GC_INNER_WIN32THREAD GC_INNER\n#  else\n#    define GC_INNER_WIN32THREAD STATIC\n#  endif\n\n#  ifdef PARALLEL_MARK\n\n#    if defined(GC_WIN32_THREADS) || defined(USE_PROC_FOR_LIBRARIES) \\\n        || (defined(IA64)                                            \\\n            && (defined(HAVE_PTHREAD_ATTR_GET_NP)                    \\\n                || defined(HAVE_PTHREAD_GETATTR_NP)))\n/* The cold end of the stack for markers.   */\nGC_INNER_WIN32THREAD ptr_t GC_marker_sp[MAX_MARKERS - 1] = { 0 };\n#    endif /* GC_WIN32_THREADS || USE_PROC_FOR_LIBRARIES */\n\n#    if defined(IA64) && defined(USE_PROC_FOR_LIBRARIES)\nstatic ptr_t marker_bsp[MAX_MARKERS - 1] = { 0 };\n#    endif\n\n#    if defined(DARWIN) && !defined(GC_NO_THREADS_DISCOVERY)\nstatic mach_port_t marker_mach_threads[MAX_MARKERS - 1] = { 0 };\n\n/* Used only by GC_suspend_thread_list().   */\nGC_INNER GC_bool\nGC_is_mach_marker(thread_act_t thread)\n{\n  int i;\n  for (i = 0; i < GC_markers_m1; i++) {\n    if (marker_mach_threads[i] == thread)\n      return TRUE;\n  }\n  return FALSE;\n}\n#    endif /* DARWIN && !GC_NO_THREADS_DISCOVERY */\n\n#    ifdef HAVE_PTHREAD_SETNAME_NP_WITH_TID_AND_ARG\n/* For NetBSD.      */\nstatic void\nset_marker_thread_name(unsigned id)\n{\n  int err = pthread_setname_np(pthread_self(), \"GC-marker-%zu\",\n                               NUMERIC_TO_VPTR(id));\n  if (EXPECT(err != 0, FALSE))\n    WARN(\"pthread_setname_np failed, errno= %\" WARN_PRIdPTR \"\\n\",\n         (GC_signed_word)err);\n}\n\n#    elif defined(HAVE_PTHREAD_SETNAME_NP_WITH_TID)     \\\n        || defined(HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID) \\\n        || defined(HAVE_PTHREAD_SET_NAME_NP)\n#      ifdef HAVE_PTHREAD_SET_NAME_NP\n#        include <pthread_np.h>\n#      endif\nstatic void\nset_marker_thread_name(unsigned id)\n{\n  char name_buf[16]; /* pthread_setname_np may fail for longer names */\n  int len = sizeof(\"GC-marker-\") - 1;\n\n  /* Compose the name manually as snprintf may be unavailable or    */\n  /* \"%u directive output may be truncated\" warning may occur.      */\n  BCOPY(\"GC-marker-\", name_buf, len);\n  if (id >= 10)\n    name_buf[len++] = (char)('0' + (id / 10) % 10);\n  name_buf[len] = (char)('0' + id % 10);\n  name_buf[len + 1] = '\\0';\n\n#      ifdef HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID\n  /* The iOS or OS X case.        */\n  (void)pthread_setname_np(name_buf);\n#      elif defined(HAVE_PTHREAD_SET_NAME_NP)\n  /* The OpenBSD case.            */\n  pthread_set_name_np(pthread_self(), name_buf);\n#      else\n  /* The case of Linux, Solaris, etc.     */\n  if (EXPECT(pthread_setname_np(pthread_self(), name_buf) != 0, FALSE))\n    WARN(\"pthread_setname_np failed\\n\", 0);\n#      endif\n}\n\n#    elif defined(GC_WIN32_THREADS) && !defined(MSWINCE)\n/* A pointer to SetThreadDescription() which is available since     */\n/* Windows 10.  The function prototype is in processthreadsapi.h.   */\nstatic FARPROC setThreadDescription_fn;\n\nGC_INNER void\nGC_init_win32_thread_naming(HMODULE hK32)\n{\n  if (hK32)\n    setThreadDescription_fn = GetProcAddress(hK32, \"SetThreadDescription\");\n}\n\nstatic void\nset_marker_thread_name(unsigned id)\n{\n  WCHAR name_buf[16];\n  int len = sizeof(L\"GC-marker-\") / sizeof(WCHAR) - 1;\n  HRESULT hr;\n\n  if (!setThreadDescription_fn) {\n    /* SetThreadDescription() is missing.   */\n    return;\n  }\n\n  /* Compose the name manually as swprintf may be unavailable.      */\n  BCOPY(L\"GC-marker-\", name_buf, len * sizeof(WCHAR));\n  if (id >= 10)\n    name_buf[len++] = (WCHAR)('0' + (id / 10) % 10);\n  name_buf[len] = (WCHAR)('0' + id % 10);\n  name_buf[len + 1] = 0;\n\n  /* Invoke SetThreadDescription().  Cast the function pointer to word  */\n  /* first to avoid \"incompatible function types\" compiler warning.     */\n  hr = (*(HRESULT(WINAPI *)(HANDLE, const WCHAR *))(\n      GC_funcptr_uint)setThreadDescription_fn)(GetCurrentThread(), name_buf);\n  if (hr < 0)\n    WARN(\"SetThreadDescription failed\\n\", 0);\n}\n#    else\n#      define set_marker_thread_name(id) (void)(id)\n#    endif\n\nGC_INNER_WIN32THREAD\n#    ifdef GC_PTHREADS_PARAMARK\nvoid *\nGC_mark_thread(void *id)\n#    elif defined(MSWINCE)\nDWORD WINAPI\nGC_mark_thread(LPVOID id)\n#    else\nunsigned __stdcall GC_mark_thread(void *id)\n#    endif\n{\n  word my_mark_no = 0;\n  word id_n = (word)(GC_uintptr_t)id;\n  IF_CANCEL(int cancel_state;)\n\n  if (id_n == GC_WORD_MAX)\n    return 0; /* to prevent a compiler warning */\n\n  /* Mark threads are not cancellable; they should be invisible to    */\n  /* client.                                                          */\n  DISABLE_CANCEL(cancel_state);\n\n  set_marker_thread_name((unsigned)id_n);\n#    if defined(GC_WIN32_THREADS) || defined(USE_PROC_FOR_LIBRARIES) \\\n        || (defined(IA64)                                            \\\n            && (defined(HAVE_PTHREAD_ATTR_GET_NP)                    \\\n                || defined(HAVE_PTHREAD_GETATTR_NP)))\n  GC_marker_sp[id_n] = GC_approx_sp();\n#    endif\n#    if defined(IA64) && defined(USE_PROC_FOR_LIBRARIES)\n  marker_bsp[id_n] = GC_save_regs_in_stack();\n#    endif\n#    if defined(DARWIN) && !defined(GC_NO_THREADS_DISCOVERY)\n  marker_mach_threads[id_n] = mach_thread_self();\n#    endif\n#    if !defined(GC_PTHREADS_PARAMARK)\n  GC_marker_Id[id_n] = thread_id_self();\n#    endif\n\n  /* Inform GC_start_mark_threads about completion of marker data init. */\n  GC_acquire_mark_lock();\n  /* Note: the count variable may have a negative value.      */\n  if (0 == --GC_fl_builder_count)\n    GC_notify_all_builder();\n\n  /* GC_mark_no is passed only to allow GC_help_marker to terminate   */\n  /* promptly.  This is important if it were called from the signal   */\n  /* handler or from the allocator lock acquisition code.  Under      */\n  /* Linux, it is not safe to call it from a signal handler, since it */\n  /* uses mutexes and condition variables.  Since it is called only   */\n  /* here, the argument is unnecessary.                               */\n  for (;; ++my_mark_no) {\n    if (my_mark_no - GC_mark_no > (word)2) {\n      /* Resynchronize if we get far off, e.g. because GC_mark_no     */\n      /* wrapped.                                                     */\n      my_mark_no = GC_mark_no;\n    }\n#    ifdef DEBUG_THREADS\n    GC_log_printf(\"Starting helper for mark number %lu (thread %u)\\n\",\n                  (unsigned long)my_mark_no, (unsigned)id_n);\n#    endif\n    GC_help_marker(my_mark_no);\n  }\n}\n\nGC_INNER_WIN32THREAD int GC_available_markers_m1 = 0;\n\n#  endif /* PARALLEL_MARK */\n\n#  ifdef GC_PTHREADS_PARAMARK\n\n#    ifdef GLIBC_2_1_MUTEX_HACK\n/* Ugly workaround for a linux threads bug in the final versions    */\n/* of glibc 2.1.  Pthread_mutex_trylock sets the mutex owner        */\n/* field even when it fails to acquire the mutex.  This causes      */\n/* pthread_cond_wait to die.  Should not be needed for glibc 2.2.   */\n/* According to the man page, we should use                         */\n/* PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP, but that isn't actually */\n/* defined.                                                         */\nstatic pthread_mutex_t mark_mutex\n    = { 0, 0, 0, PTHREAD_MUTEX_ERRORCHECK_NP, { 0, 0 } };\n#    else\nstatic pthread_mutex_t mark_mutex = PTHREAD_MUTEX_INITIALIZER;\n#    endif\n\n#    ifdef CAN_HANDLE_FORK\n/* Note: this is initialized by GC_start_mark_threads_inner().      */\nstatic pthread_cond_t mark_cv;\n#    else\nstatic pthread_cond_t mark_cv = PTHREAD_COND_INITIALIZER;\n#    endif\n\nGC_INNER void\nGC_start_mark_threads_inner(void)\n{\n  int i;\n  pthread_attr_t attr;\n#    ifndef NO_MARKER_SPECIAL_SIGMASK\n  sigset_t set, oldset;\n#    endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  ASSERT_CANCEL_DISABLED();\n  if (GC_available_markers_m1 <= 0 || GC_parallel) {\n    /* Skip if parallel markers disabled or already started.          */\n    return;\n  }\n  GC_wait_for_gc_completion(TRUE);\n\n#    ifdef CAN_HANDLE_FORK\n  /* Initialize mark_cv (for the first time), or cleanup its value  */\n  /* after forking in the child process.  All the marker threads in */\n  /* the parent process were blocked on this variable at fork, so   */\n  /* pthread_cond_wait() malfunction (hang) is possible in the      */\n  /* child process without such a cleanup.                          */\n  /* TODO: This is not portable, it is better to shortly unblock    */\n  /* all marker threads in the parent process at fork.              */\n  {\n    pthread_cond_t mark_cv_local = PTHREAD_COND_INITIALIZER;\n    BCOPY(&mark_cv_local, &mark_cv, sizeof(mark_cv));\n  }\n#    endif\n\n  GC_ASSERT(0 == GC_fl_builder_count);\n  INIT_REAL_SYMS(); /* for pthread_create */\n\n  if (pthread_attr_init(&attr) != 0)\n    ABORT(\"pthread_attr_init failed\");\n  if (pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED) != 0)\n    ABORT(\"pthread_attr_setdetachstate failed\");\n\n#    ifdef DEFAULT_STACK_MAYBE_SMALL\n  /* Default stack size is usually too small: increase it.  */\n  /* Otherwise marker threads or GC may run out of space.   */\n  {\n    size_t old_size;\n\n    if (pthread_attr_getstacksize(&attr, &old_size) != 0)\n      ABORT(\"pthread_attr_getstacksize failed\");\n    if (old_size < MIN_STACK_SIZE && old_size != 0 /* stack size is known */) {\n      if (pthread_attr_setstacksize(&attr, MIN_STACK_SIZE) != 0)\n        ABORT(\"pthread_attr_setstacksize failed\");\n    }\n  }\n#    endif /* DEFAULT_STACK_MAYBE_SMALL */\n\n#    ifndef NO_MARKER_SPECIAL_SIGMASK\n  /* Apply special signal mask to GC marker threads, and don't drop */\n  /* user defined signals by GC marker threads.                     */\n  if (sigfillset(&set) != 0)\n    ABORT(\"sigfillset failed\");\n\n#      ifdef SIGNAL_BASED_STOP_WORLD\n  /* These are used by GC to stop and restart the world.  */\n  if (sigdelset(&set, GC_get_suspend_signal()) != 0\n      || sigdelset(&set, GC_get_thr_restart_signal()) != 0)\n    ABORT(\"sigdelset failed\");\n#      endif\n\n  if (EXPECT(REAL_FUNC(pthread_sigmask)(SIG_BLOCK, &set, &oldset) != 0,\n             FALSE)) {\n    WARN(\"pthread_sigmask set failed, no markers started\\n\", 0);\n    GC_markers_m1 = 0;\n    (void)pthread_attr_destroy(&attr);\n    return;\n  }\n#    endif /* !NO_MARKER_SPECIAL_SIGMASK */\n\n  /* To have proper GC_parallel value in GC_help_marker.      */\n  GC_markers_m1 = GC_available_markers_m1;\n\n  for (i = 0; i < GC_available_markers_m1; ++i) {\n    pthread_t new_thread;\n\n#    ifdef GC_WIN32_THREADS\n    GC_marker_last_stack_min[i] = ADDR_LIMIT;\n#    endif\n    if (EXPECT(REAL_FUNC(pthread_create)(&new_thread, &attr, GC_mark_thread,\n                                         NUMERIC_TO_VPTR(i))\n                   != 0,\n               FALSE)) {\n      WARN(\"Marker thread %\" WARN_PRIdPTR \" creation failed\\n\",\n           (GC_signed_word)i);\n      /* Don't try to create other marker threads.    */\n      GC_markers_m1 = i;\n      break;\n    }\n  }\n\n#    ifndef NO_MARKER_SPECIAL_SIGMASK\n  /* Restore previous signal mask.  */\n  if (EXPECT(REAL_FUNC(pthread_sigmask)(SIG_SETMASK, &oldset, NULL) != 0,\n             FALSE)) {\n    WARN(\"pthread_sigmask restore failed\\n\", 0);\n  }\n#    endif\n\n  (void)pthread_attr_destroy(&attr);\n  GC_wait_for_markers_init();\n  GC_COND_LOG_PRINTF(\"Started %d mark helper threads\\n\", GC_markers_m1);\n}\n\n#  endif /* GC_PTHREADS_PARAMARK */\n\n/* A hash table to keep information about the registered threads.       */\n/* Not used if GC_win32_dll_threads is set.                             */\nGC_INNER GC_thread GC_threads[THREAD_TABLE_SZ] = { 0 };\n\n/* It may not be safe to allocate when we register the first thread.    */\n/* Note that next and status fields are unused, but there might be some */\n/* other fields (crtn) to be pushed.                                    */\nstatic struct GC_StackContext_Rep first_crtn;\nstatic struct GC_Thread_Rep first_thread;\n\n/* A place to retain a pointer to an allocated object while a thread    */\n/* registration is ongoing.  Protected by the allocator lock.           */\nstatic GC_stack_context_t saved_crtn = NULL;\n\n#  ifdef GC_ASSERTIONS\nGC_INNER GC_bool GC_thr_initialized = FALSE;\n#  endif\n\nGC_INNER void\nGC_push_thread_structures(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  if (GC_win32_dll_threads) {\n    /* Unlike the other threads implementations, the thread table     */\n    /* here contains no pointers to the collectible heap (note also   */\n    /* that GC_PTHREADS is incompatible with DllMain-based thread     */\n    /* registration).  Thus we have no private structures we need     */\n    /* to preserve.                                                   */\n  } else\n#  endif\n  /* else */ {\n    GC_push_all(&GC_threads, (ptr_t)(&GC_threads) + sizeof(GC_threads));\n    GC_ASSERT(NULL == first_thread.tm.next);\n#  ifdef GC_PTHREADS\n    GC_ASSERT(NULL == first_thread.status);\n#  endif\n    GC_PUSH_ALL_SYM(first_thread.crtn);\n    GC_PUSH_ALL_SYM(saved_crtn);\n  }\n#  if defined(THREAD_LOCAL_ALLOC) && defined(USE_CUSTOM_SPECIFIC)\n  GC_PUSH_ALL_SYM(GC_thread_key);\n#  endif\n}\n\n#  if defined(MPROTECT_VDB) && defined(GC_WIN32_THREADS)\nGC_INNER void\nGC_win32_unprotect_thread(GC_thread t)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!GC_win32_dll_threads && GC_auto_incremental) {\n    GC_stack_context_t crtn = t->crtn;\n\n    if (crtn != &first_crtn) {\n      GC_ASSERT(SMALL_OBJ(GC_size(crtn)));\n      GC_remove_protection(HBLKPTR(crtn), 1, FALSE);\n    }\n    if (t != &first_thread) {\n      GC_ASSERT(SMALL_OBJ(GC_size(t)));\n      GC_remove_protection(HBLKPTR(t), 1, FALSE);\n    }\n  }\n}\n#  endif /* MPROTECT_VDB && GC_WIN32_THREADS */\n\n#  ifdef DEBUG_THREADS\nSTATIC int\nGC_count_threads(void)\n{\n  int i;\n  int count = 0;\n\n#    if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  if (GC_win32_dll_threads)\n    return -1; /* not implemented */\n#    endif\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  for (i = 0; i < THREAD_TABLE_SZ; ++i) {\n    GC_thread p;\n\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      if (!KNOWN_FINISHED(p))\n        ++count;\n    }\n  }\n  return count;\n}\n#  endif /* DEBUG_THREADS */\n\n/* Add a thread to GC_threads.  We assume it wasn't already there.      */\n/* The id field is set by the caller.                                   */\nGC_INNER_WIN32THREAD GC_thread\nGC_new_thread(thread_id_t self_id)\n{\n  int hv = THREAD_TABLE_INDEX(self_id);\n  GC_thread result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Creating thread %p\\n\", THREAD_ID_TO_VPTR(self_id));\n  for (result = GC_threads[hv]; result != NULL; result = result->tm.next)\n    if (!THREAD_ID_EQUAL(result->id, self_id)) {\n      GC_log_printf(\"Hash collision at GC_threads[%d]\\n\", hv);\n      break;\n    }\n#  endif\n  if (EXPECT(NULL == first_thread.crtn, FALSE)) {\n    result = &first_thread;\n    first_thread.crtn = &first_crtn;\n    GC_ASSERT(NULL == GC_threads[hv]);\n#  if defined(CPPCHECK) && defined(THREAD_SANITIZER) \\\n      && defined(SIGNAL_BASED_STOP_WORLD)\n    GC_noop1((unsigned char)first_crtn.dummy[0]);\n#  endif\n  } else {\n    GC_stack_context_t crtn;\n\n    GC_ASSERT(!GC_win32_dll_threads);\n    GC_ASSERT(!GC_in_thread_creation);\n    GC_in_thread_creation = TRUE; /* OK to collect from unknown thread */\n    crtn = (GC_stack_context_t)GC_INTERNAL_MALLOC(\n        sizeof(struct GC_StackContext_Rep), NORMAL);\n\n    /* The current stack is not scanned until the thread is         */\n    /* registered, thus crtn pointer is to be retained in the       */\n    /* global data roots for a while (and pushed explicitly if      */\n    /* a collection occurs here).                                   */\n    GC_ASSERT(NULL == saved_crtn);\n    saved_crtn = crtn;\n    result\n        = (GC_thread)GC_INTERNAL_MALLOC(sizeof(struct GC_Thread_Rep), NORMAL);\n    /* No more collections till thread is registered.       */\n    saved_crtn = NULL;\n    GC_in_thread_creation = FALSE;\n    if (NULL == crtn || NULL == result)\n      ABORT(\"Failed to allocate memory for thread registering\");\n    result->crtn = crtn;\n  }\n  /* The id field is not set here. */\n#  ifdef USE_TKILL_ON_ANDROID\n  result->kernel_id = gettid();\n#  endif\n  result->tm.next = GC_threads[hv];\n  GC_threads[hv] = result;\n#  ifdef NACL\n  GC_nacl_initialize_gc_thread(result);\n#  endif\n  GC_ASSERT(0 == result->flags);\n  if (EXPECT(result != &first_thread, TRUE))\n    GC_dirty(result);\n  return result;\n}\n\n/* Delete a thread from GC_threads.  We assume it is there.  (The code  */\n/* intentionally traps if it was not.)  It is also safe to delete the   */\n/* main thread.  If GC_win32_dll_threads is set, it should be called    */\n/* only from the thread being deleted.  If a thread has been joined,    */\n/* but we have not yet been notified, then there may be more than one   */\n/* thread in the table with the same thread id - this is OK because we  */\n/* delete a specific one.                                               */\nGC_INNER_WIN32THREAD void\nGC_delete_thread(GC_thread t)\n{\n#  if defined(GC_WIN32_THREADS) && !defined(MSWINCE)\n  CloseHandle(t->handle);\n#  endif\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  if (GC_win32_dll_threads) {\n    /* This is intended to be lock-free.  It is either called         */\n    /* synchronously from the thread being deleted, or by the joining */\n    /* thread.  In this branch asynchronous changes to (*t) are       */\n    /* possible.  Note that it is not allowed to call GC_printf (and  */\n    /* the friends) here, see GC_stop_world() in win32_threads.c for  */\n    /* the information.                                               */\n    t->crtn->stack_end = NULL;\n    t->id = 0;\n    /* The thread is not suspended.   */\n    t->flags = 0;\n#    ifdef RETRY_GET_THREAD_CONTEXT\n    t->context_sp = NULL;\n#    endif\n    AO_store_release(&t->tm.in_use, FALSE);\n  } else\n#  endif\n  /* else */ {\n    thread_id_t id = t->id;\n    int hv = THREAD_TABLE_INDEX(id);\n    GC_thread p;\n    GC_thread prev = NULL;\n\n    GC_ASSERT(I_HOLD_LOCK());\n#  if defined(DEBUG_THREADS) && !defined(MSWINCE) \\\n      && (!defined(MSWIN32) || defined(CONSOLE_LOG))\n    GC_log_printf(\"Deleting thread %p, n_threads= %d\\n\", THREAD_ID_TO_VPTR(id),\n                  GC_count_threads());\n#  endif\n    for (p = GC_threads[hv]; p != t; p = p->tm.next) {\n      prev = p;\n    }\n    if (NULL == prev) {\n      GC_threads[hv] = p->tm.next;\n    } else {\n      GC_ASSERT(prev != &first_thread);\n      prev->tm.next = p->tm.next;\n      GC_dirty(prev);\n    }\n    if (EXPECT(p != &first_thread, TRUE)) {\n#  ifdef DARWIN\n      mach_port_deallocate(mach_task_self(), p->mach_thread);\n#  endif\n      GC_ASSERT(p->crtn != &first_crtn);\n      GC_INTERNAL_FREE(p->crtn);\n      GC_INTERNAL_FREE(p);\n    }\n  }\n}\n\n/* Return a GC_thread corresponding to a given thread id, or    */\n/* NULL if it is not there.  Caller holds the allocator lock    */\n/* at least in the reader mode or otherwise inhibits updates.   */\n/* If there is more than one thread with the given id, we       */\n/* return the most recent one.                                  */\nGC_INNER GC_thread\nGC_lookup_thread(thread_id_t id)\n{\n  GC_thread p;\n\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  if (GC_win32_dll_threads)\n    return GC_win32_dll_lookup_thread(id);\n#  endif\n  for (p = GC_threads[THREAD_TABLE_INDEX(id)]; p != NULL; p = p->tm.next) {\n    if (EXPECT(THREAD_ID_EQUAL(p->id, id), TRUE))\n      break;\n  }\n  return p;\n}\n\n/* Same as GC_self_thread_inner() but acquires the allocator lock (in   */\n/* the reader mode).                                                    */\nSTATIC GC_thread\nGC_self_thread(void)\n{\n  GC_thread p;\n\n  READER_LOCK();\n  p = GC_self_thread_inner();\n  READER_UNLOCK();\n  return p;\n}\n\n#  ifndef GC_NO_FINALIZATION\n/* Called by GC_finalize() (in case of an allocation failure observed). */\nGC_INNER void\nGC_reset_finalizer_nested(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_self_thread_inner()->crtn->finalizer_nested = 0;\n}\n\n/* Checks and updates the thread-local level of finalizers recursion. */\n/* Returns NULL if GC_invoke_finalizers() should not be called by the */\n/* collector (to minimize the risk of a deep finalizers recursion),   */\n/* otherwise returns a pointer to the thread-local finalizer_nested.  */\n/* Called by GC_notify_or_invoke_finalizers() only.                   */\nGC_INNER unsigned char *\nGC_check_finalizer_nested(void)\n{\n  GC_thread me;\n  GC_stack_context_t crtn;\n  unsigned nesting_level;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  me = GC_self_thread_inner();\n#    if defined(INCLUDE_LINUX_THREAD_DESCR) && defined(REDIRECT_MALLOC)\n  /* As noted in GC_pthread_start, an allocation may happen in  */\n  /* GC_get_stack_base, causing GC_notify_or_invoke_finalizers  */\n  /* to be called before the thread gets registered.            */\n  if (EXPECT(NULL == me, FALSE))\n    return NULL;\n#    endif\n  crtn = me->crtn;\n  nesting_level = crtn->finalizer_nested;\n  if (nesting_level) {\n    /* We are inside another GC_invoke_finalizers().          */\n    /* Skip some implicitly-called GC_invoke_finalizers()     */\n    /* depending on the nesting (recursion) level.            */\n    if ((unsigned)(++crtn->finalizer_skipped) < (1U << nesting_level))\n      return NULL;\n    crtn->finalizer_skipped = 0;\n  }\n  crtn->finalizer_nested = (unsigned char)(nesting_level + 1);\n  return &crtn->finalizer_nested;\n}\n#  endif /* !GC_NO_FINALIZATION */\n\n#  define ADDR_INSIDE_OBJ(p, obj) \\\n    ADDR_INSIDE(p, (ptr_t)(&(obj)), (ptr_t)(&(obj)) + sizeof(obj))\n\n#  if defined(GC_ASSERTIONS) && defined(THREAD_LOCAL_ALLOC)\n/* This is called from thread-local GC_malloc(). */\nGC_bool\nGC_is_thread_tsd_valid(void *tsd)\n{\n  GC_thread me = GC_self_thread();\n\n  return ADDR_INSIDE_OBJ((ptr_t)tsd, me->tlfs);\n}\n#  endif /* GC_ASSERTIONS && THREAD_LOCAL_ALLOC */\n\nGC_API int GC_CALL\nGC_thread_is_registered(void)\n{\n  /* TODO: Use GC_get_tlfs() instead. */\n  GC_thread me = GC_self_thread();\n\n  return me != NULL && !KNOWN_FINISHED(me);\n}\n\nGC_API void GC_CALL\nGC_register_altstack(void *normstack, size_t normstack_size, void *altstack,\n                     size_t altstack_size)\n{\n#  ifdef GC_WIN32_THREADS\n  /* TODO: Implement */\n  UNUSED_ARG(normstack);\n  UNUSED_ARG(normstack_size);\n  UNUSED_ARG(altstack);\n  UNUSED_ARG(altstack_size);\n#  else\n  GC_thread me;\n  GC_stack_context_t crtn;\n\n  READER_LOCK();\n  me = GC_self_thread_inner();\n  if (EXPECT(NULL == me, FALSE)) {\n    /* We are called before GC_thr_init. */\n    me = &first_thread;\n  }\n  crtn = me->crtn;\n  crtn->normstack = (ptr_t)normstack;\n  crtn->normstack_size = normstack_size;\n  crtn->altstack = (ptr_t)altstack;\n  crtn->altstack_size = altstack_size;\n  READER_UNLOCK_RELEASE();\n#  endif\n}\n\n#  ifdef USE_PROC_FOR_LIBRARIES\nGC_INNER GC_bool\nGC_segment_is_thread_stack(ptr_t lo, ptr_t hi)\n{\n  int i;\n  GC_thread p;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n#    ifdef PARALLEL_MARK\n  for (i = 0; i < GC_markers_m1; ++i) {\n    if (ADDR_LT(lo, GC_marker_sp[i]) && ADDR_LT(GC_marker_sp[i], hi))\n      return TRUE;\n#      ifdef IA64\n    if (ADDR_LT(lo, marker_bsp[i]) && ADDR_LT(marker_bsp[i], hi))\n      return TRUE;\n#      endif\n  }\n#    endif\n  for (i = 0; i < THREAD_TABLE_SZ; i++) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      ptr_t stack_end = p->crtn->stack_end;\n\n      if (stack_end != NULL) {\n#    ifdef STACK_GROWS_UP\n        if (ADDR_INSIDE(stack_end, lo, hi))\n          return TRUE;\n#    else\n        if (ADDR_LT(lo, stack_end) && ADDR_GE(hi, stack_end))\n          return TRUE;\n#    endif\n      }\n    }\n  }\n  return FALSE;\n}\n#  endif /* USE_PROC_FOR_LIBRARIES */\n\n#  if (defined(HAVE_PTHREAD_ATTR_GET_NP) || defined(HAVE_PTHREAD_GETATTR_NP)) \\\n      && defined(IA64)\n/* Find the largest stack base smaller than bound.  May be used       */\n/* to find the boundary between a register stack and adjacent         */\n/* immediately preceding memory stack.                                */\nGC_INNER ptr_t\nGC_greatest_stack_base_below(ptr_t bound)\n{\n  int i;\n  GC_thread p;\n  ptr_t result = NULL;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n#    ifdef PARALLEL_MARK\n  for (i = 0; i < GC_markers_m1; ++i) {\n    if (ADDR_LT(result, GC_marker_sp[i]) && ADDR_LT(GC_marker_sp[i], bound))\n      result = GC_marker_sp[i];\n  }\n#    endif\n  for (i = 0; i < THREAD_TABLE_SZ; i++) {\n    for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n      ptr_t stack_end = p->crtn->stack_end;\n\n      if (ADDR_LT(result, stack_end) && ADDR_LT(stack_end, bound))\n        result = stack_end;\n    }\n  }\n  return result;\n}\n#  endif /* IA64 */\n\n#  ifndef STAT_READ\n/* Note: if read is wrapped, this may need to be redefined to call    */\n/* the real one.                                                      */\n#    define STAT_READ read\n#  endif\n\n#  ifdef HPUX\n#    define GC_get_nprocs() pthread_num_processors_np()\n\n#  elif defined(AIX) || defined(COSMO) || defined(HAIKU)         \\\n      || defined(HOST_ANDROID) || defined(HURD) || defined(NACL) \\\n      || defined(OSF1) || defined(SOLARIS)\nGC_INLINE int\nGC_get_nprocs(void)\n{\n  int nprocs = (int)sysconf(_SC_NPROCESSORS_ONLN);\n  /* Note: ignore any error silently. */\n  return nprocs > 0 ? nprocs : 1;\n}\n\n#  elif defined(IRIX5)\nGC_INLINE int\nGC_get_nprocs(void)\n{\n  int nprocs = (int)sysconf(_SC_NPROC_ONLN);\n  /* Note: ignore any error silently. */\n  return nprocs > 0 ? nprocs : 1;\n}\n\n#  elif defined(LINUX)\n/* Return the number of processors. */\nSTATIC int\nGC_get_nprocs(void)\n{\n  /* Should be \"return sysconf(_SC_NPROCESSORS_ONLN);\" but that     */\n  /* appears to be buggy in many cases.                             */\n  /* We look for lines \"cpu<n>\" in /proc/stat.                      */\n#    define PROC_STAT_BUF_SZ ((1 + MAX_MARKERS) * 100) /* should be enough */\n  /* No need to read the entire /proc/stat to get maximum cpu<N> as   */\n  /* - the requested lines are located at the beginning of the file;  */\n  /* - the lines with cpu<N> where N > MAX_MARKERS are not needed.    */\n  char stat_buf[PROC_STAT_BUF_SZ + 1];\n  int f;\n  int result, i, len;\n\n  f = open(\"/proc/stat\", O_RDONLY);\n  if (f < 0) {\n    WARN(\"Could not open /proc/stat\\n\", 0);\n    /* Assume an uniprocessor.        */\n    return 1;\n  }\n  len = STAT_READ(f, stat_buf, sizeof(stat_buf) - 1);\n  /* Unlikely that we need to retry because of an incomplete read here. */\n  if (len < 0) {\n    WARN(\"Failed to read /proc/stat, errno= %\" WARN_PRIdPTR \"\\n\",\n         (GC_signed_word)errno);\n    close(f);\n    return 1;\n  }\n  /* Avoid potential buffer overrun by atoi().        */\n  stat_buf[len] = '\\0';\n\n  close(f);\n\n  /* Some old kernels only have a single \"cpu nnnn ...\" entry */\n  /* in /proc/stat.  We identify those as uniprocessors.      */\n  result = 1;\n\n  for (i = 0; i < len - 4; ++i) {\n    if (stat_buf[i] == '\\n' && stat_buf[i + 1] == 'c' && stat_buf[i + 2] == 'p'\n        && stat_buf[i + 3] == 'u') {\n      int cpu_no = atoi(&stat_buf[i + 4]);\n      if (cpu_no >= result)\n        result = cpu_no + 1;\n    }\n  }\n  return result;\n}\n\n#  elif defined(DGUX)\n/* Return the number of processors, or i <= 0 if it can't be determined. */\nSTATIC int\nGC_get_nprocs(void)\n{\n  int numCpus;\n  struct dg_sys_info_pm_info pm_sysinfo;\n  int status = 0;\n\n  status = dg_sys_info((long int *)&pm_sysinfo, DG_SYS_INFO_PM_INFO_TYPE,\n                       DG_SYS_INFO_PM_CURRENT_VERSION);\n  if (status < 0) {\n    /* Set -1 for an error.  */\n    numCpus = -1;\n  } else {\n    /* Active CPUs.   */\n    numCpus = pm_sysinfo.idle_vp_count;\n  }\n  return numCpus;\n}\n\n#  elif defined(ANY_BSD) || defined(DARWIN)\nSTATIC int\nGC_get_nprocs(void)\n{\n  int mib[] = { CTL_HW, HW_NCPU };\n  int res;\n  size_t len = sizeof(res);\n\n  sysctl(mib, sizeof(mib) / sizeof(int), &res, &len, NULL, 0);\n  return res;\n}\n\n#  else\n/* E.g., RTEMS. */\n/* TODO: not implemented */\n#    define GC_get_nprocs() 1\n#  endif\n\n#  if defined(LINUX) && defined(ARM32)\n/* Some buggy Linux/arm kernels show only non-sleeping CPUs in        */\n/* /proc/stat (and /proc/cpuinfo), so another data system source is   */\n/* tried first.  Result <= 0 on error.                                */\nSTATIC int\nGC_get_nprocs_present(void)\n{\n  char stat_buf[16];\n  int f;\n  int len;\n\n  f = open(\"/sys/devices/system/cpu/present\", O_RDONLY);\n  if (f < 0) {\n    /* Cannot open the file.  */\n    return -1;\n  }\n\n  len = STAT_READ(f, stat_buf, sizeof(stat_buf));\n  close(f);\n\n  /* Recognized file format: \"0\\n\" or \"0-<max_cpu_id>\\n\"      */\n  /* The file might probably contain a comma-separated list   */\n  /* but we do not need to handle it (just silently ignore).  */\n  if (len < 2 || stat_buf[0] != '0' || stat_buf[len - 1] != '\\n') {\n    /* A read error or an unrecognized content.       */\n    return 0;\n  } else if (len == 2) {\n    /* An uniprocessor.       */\n    return 1;\n  } else if (stat_buf[1] != '-') {\n    /* An unrecognized content.       */\n    return 0;\n  }\n\n  /* Terminate the string.    */\n  stat_buf[len - 1] = '\\0';\n\n  /* Skip \"0-\" and parse max_cpu_num. */\n  return atoi(&stat_buf[2]) + 1;\n}\n#  endif /* LINUX && ARM32 */\n\n#  if defined(CAN_HANDLE_FORK) && defined(THREAD_SANITIZER)\n#    include \"private/gc_pmark.h\" /* for MS_NONE */\n\n/* Workaround for TSan which does not notice that the allocator lock  */\n/* is acquired in fork_prepare_proc().                                */\nGC_ATTR_NO_SANITIZE_THREAD\nstatic GC_bool\ncollection_in_progress(void)\n{\n  return GC_mark_state != MS_NONE;\n}\n#  else\n#    define collection_in_progress() GC_collection_in_progress()\n#  endif\n\n/* We hold the allocator lock.  Wait until an in-progress GC has        */\n/* finished.  Repeatedly releases the allocator lock in order to wait.  */\n/* If wait_for_all is true, then we exit with the allocator lock held   */\n/* and no collection is in progress; otherwise we just wait for the     */\n/* current collection to finish.                                        */\nGC_INNER void\nGC_wait_for_gc_completion(GC_bool wait_for_all)\n{\n#  if !defined(THREAD_SANITIZER) || !defined(CAN_CALL_ATFORK)\n  /* GC_lock_holder is accessed with the allocator lock held, so      */\n  /* there is no data race actually (unlike what's reported by TSan). */\n  GC_ASSERT(I_HOLD_LOCK());\n#  endif\n  ASSERT_CANCEL_DISABLED();\n#  ifdef GC_DISABLE_INCREMENTAL\n  (void)wait_for_all;\n#  else\n  if (GC_incremental && collection_in_progress()) {\n    word old_gc_no = GC_gc_no;\n\n    /* Make sure that no part of our stack is still on the mark     */\n    /* stack, since it's about to be unmapped.                      */\n#    ifdef LINT2\n    /* Note: do not transform this if-do-while construction into  */\n    /* a single while statement because it might cause some       */\n    /* static code analyzers to report a false positive (FP)      */\n    /* code defect about missing unlock after lock.               */\n#    endif\n    do {\n      ENTER_GC();\n      GC_ASSERT(!GC_in_thread_creation);\n      GC_in_thread_creation = TRUE;\n      GC_collect_a_little_inner(1);\n      GC_in_thread_creation = FALSE;\n      EXIT_GC();\n\n      UNLOCK();\n#    ifdef GC_WIN32_THREADS\n      Sleep(0);\n#    else\n      sched_yield();\n#    endif\n      LOCK();\n    } while (GC_incremental && collection_in_progress()\n             && (wait_for_all || old_gc_no == GC_gc_no));\n  }\n#  endif\n}\n\n#  if defined(GC_ASSERTIONS) && defined(GC_PTHREADS_PARAMARK)\nSTATIC unsigned long GC_mark_lock_holder = NO_THREAD;\n#  endif\n\n#  ifdef CAN_HANDLE_FORK\n\n/* Procedures called before and after a fork.  The goal here is to    */\n/* make it safe to call GC_malloc() in a forked child.  It is unclear */\n/* that is attainable, since the single UNIX spec seems to imply that */\n/* one should only call async-signal-safe functions, and we probably  */\n/* cannot quite guarantee that.  But we give it our best shot.  (That */\n/* same spec also implies that it is not safe to call the system      */\n/* malloc between fork and exec.  Thus we're doing no worse than it.) */\n\nIF_CANCEL(static int fork_cancel_state;)\n/* protected by the allocator lock */\n\n#    ifdef PARALLEL_MARK\n#      ifdef THREAD_SANITIZER\n#        if defined(GC_ASSERTIONS) && defined(CAN_CALL_ATFORK)\nSTATIC void GC_generic_lock(pthread_mutex_t *);\n#        endif\nGC_ATTR_NO_SANITIZE_THREAD\nstatic void wait_for_reclaim_atfork(void);\n#      else\n#        define wait_for_reclaim_atfork() GC_wait_for_reclaim()\n#      endif\n#    endif /* PARALLEL_MARK */\n\n/* Prevent TSan false positive about the race during items removal    */\n/* from GC_threads.  (The race cannot happen since only one thread    */\n/* survives in the child.)                                            */\n#    ifdef CAN_CALL_ATFORK\nGC_ATTR_NO_SANITIZE_THREAD\n#    endif\nstatic void\nstore_to_threads_table(int hv, GC_thread me)\n{\n  GC_threads[hv] = me;\n}\n\n/* Remove all entries from the GC_threads table, except the one for */\n/* the current thread.  Also update thread identifiers stored in    */\n/* the table for the current thread.  We need to do this in the     */\n/* child process after a fork(), since only the current thread      */\n/* survives in the child.                                           */\nSTATIC void\nGC_remove_all_threads_but_me(void)\n{\n  int hv;\n  GC_thread me = NULL;\n#    ifndef GC_WIN32_THREADS\n#      define pthread_id id\n#    endif\n\n  for (hv = 0; hv < THREAD_TABLE_SZ; ++hv) {\n    GC_thread p, next;\n\n    for (p = GC_threads[hv]; p != NULL; p = next) {\n      next = p->tm.next;\n      if (THREAD_EQUAL(p->pthread_id, GC_parent_pthread_self) && me == NULL) {\n        /* Ignore dead threads with the same id.      */\n        me = p;\n        p->tm.next = NULL;\n      } else {\n#    ifdef THREAD_LOCAL_ALLOC\n        if (!KNOWN_FINISHED(p)) {\n          /* Cannot call GC_destroy_thread_local here.  The free    */\n          /* lists may be in an inconsistent state (as thread p may */\n          /* be updating one of the lists by GC_generic_malloc_many */\n          /* or GC_FAST_MALLOC_GRANS when fork is invoked).         */\n          /* This should not be a problem because the lost elements */\n          /* of the free lists will be collected during GC.         */\n          GC_remove_specific_after_fork(GC_thread_key, p->pthread_id);\n        }\n#    endif\n        /* TODO: To avoid TSan hang (when updating GC_bytes_freed),   */\n        /* we just skip explicit freeing of GC_threads entries.       */\n#    if !defined(THREAD_SANITIZER) || !defined(CAN_CALL_ATFORK)\n        if (p != &first_thread) {\n          /* TODO: Should call mach_port_deallocate? */\n          GC_ASSERT(p->crtn != &first_crtn);\n          GC_INTERNAL_FREE(p->crtn);\n          GC_INTERNAL_FREE(p);\n        }\n#    endif\n      }\n    }\n    store_to_threads_table(hv, NULL);\n  }\n\n#    if defined(CPPCHECK) || defined(LINT2)\n  if (NULL == me)\n    ABORT(\"Current thread is not found after fork\");\n#    else\n  GC_ASSERT(me != NULL);\n#    endif\n  /* Update pthread's id as it is not guaranteed to be the same     */\n  /* between this (child) process and the parent one.               */\n  me->pthread_id = pthread_self();\n#    ifdef GC_WIN32_THREADS\n  /* Update Win32 thread id and handle.     */\n  /* They differ from that in the parent.   */\n  me->id = thread_id_self();\n#      ifndef MSWINCE\n  if (!DuplicateHandle(GetCurrentProcess(), GetCurrentThread(),\n                       GetCurrentProcess(), (HANDLE *)&me->handle,\n                       0 /* dwDesiredAccess */, FALSE /* bInheritHandle */,\n                       DUPLICATE_SAME_ACCESS))\n    ABORT(\"DuplicateHandle failed\");\n#      endif\n#    endif\n#    ifdef DARWIN\n  /* Update thread Id after fork (it is OK to call  */\n  /* GC_destroy_thread_local and GC_free_inner      */\n  /* before update).                                */\n  me->mach_thread = mach_thread_self();\n#    endif\n#    ifdef USE_TKILL_ON_ANDROID\n  me->kernel_id = gettid();\n#    endif\n\n  /* Put \"me\" back to GC_threads.     */\n  store_to_threads_table(THREAD_TABLE_INDEX(me->id), me);\n\n#    ifdef THREAD_LOCAL_ALLOC\n#      ifdef USE_CUSTOM_SPECIFIC\n  GC_update_specific_after_fork(GC_thread_key);\n#      else\n  /* Some TLS implementations (e.g., on Cygwin) might be not        */\n  /* fork-friendly, so we re-assign thread-local pointer to 'tlfs'  */\n  /* for safety instead of the assertion check (again, it is OK to  */\n  /* call GC_destroy_thread_local and GC_free_inner before).        */\n  {\n    int res = GC_setspecific(GC_thread_key, &me->tlfs);\n\n    if (COVERT_DATAFLOW(res) != 0)\n      ABORT(\"GC_setspecific failed (in child)\");\n  }\n#      endif\n#    endif\n#    undef pthread_id\n}\n\n/* Called before a fork().    */\n#    if defined(GC_ASSERTIONS) && defined(CAN_CALL_ATFORK)\n/* GC_lock_holder is updated safely (no data race actually).        */\nGC_ATTR_NO_SANITIZE_THREAD\n#    endif\nstatic void\nfork_prepare_proc(void)\n{\n  /* Acquire all relevant locks, so that after releasing the locks  */\n  /* the child will see a consistent state in which monitor         */\n  /* invariants hold.  Unfortunately, we can't acquire libc locks   */\n  /* we might need, and there seems to be no guarantee that libc    */\n  /* must install a suitable fork handler.                          */\n  /* Wait for an ongoing GC to finish, since we can't finish it in  */\n  /* the (one remaining thread in) the child.                       */\n\n  LOCK();\n  DISABLE_CANCEL(fork_cancel_state);\n  GC_parent_pthread_self = pthread_self();\n  /* The following waits may include cancellation points.   */\n#    ifdef PARALLEL_MARK\n  if (GC_parallel)\n    wait_for_reclaim_atfork();\n#    endif\n  GC_wait_for_gc_completion(TRUE);\n#    ifdef PARALLEL_MARK\n  if (GC_parallel) {\n#      if defined(THREAD_SANITIZER) && defined(GC_ASSERTIONS) \\\n          && defined(CAN_CALL_ATFORK)\n    /* Prevent TSan false positive about the data race  */\n    /* when updating GC_mark_lock_holder.               */\n    GC_generic_lock(&mark_mutex);\n#      else\n    GC_acquire_mark_lock();\n#      endif\n  }\n#    endif\n  GC_acquire_dirty_lock();\n}\n\n/* Called in parent after a fork() (even if the latter failed).       */\n#    if defined(GC_ASSERTIONS) && defined(CAN_CALL_ATFORK)\nGC_ATTR_NO_SANITIZE_THREAD\n#    endif\nstatic void\nfork_parent_proc(void)\n{\n  GC_release_dirty_lock();\n#    ifdef PARALLEL_MARK\n  if (GC_parallel) {\n#      if defined(THREAD_SANITIZER) && defined(GC_ASSERTIONS) \\\n          && defined(CAN_CALL_ATFORK)\n    /* To match that in fork_prepare_proc. */\n    (void)pthread_mutex_unlock(&mark_mutex);\n#      else\n    GC_release_mark_lock();\n#      endif\n  }\n#    endif\n  RESTORE_CANCEL(fork_cancel_state);\n#    ifdef GC_ASSERTIONS\n  BZERO(&GC_parent_pthread_self, sizeof(pthread_t));\n#    endif\n  UNLOCK();\n}\n\n/* Called in child after a fork().    */\n#    if defined(GC_ASSERTIONS) && defined(CAN_CALL_ATFORK)\nGC_ATTR_NO_SANITIZE_THREAD\n#    endif\nstatic void\nfork_child_proc(void)\n{\n#    ifdef GC_ASSERTIONS\n  /* Update GC_lock_holder as value of thread_id_self() might       */\n  /* differ from that of the parent process.                        */\n  SET_LOCK_HOLDER();\n#    endif\n  GC_release_dirty_lock();\n#    ifndef GC_DISABLE_INCREMENTAL\n  GC_dirty_update_child();\n#    endif\n#    ifdef PARALLEL_MARK\n  if (GC_parallel) {\n#      ifdef GC_WIN32_THREADS\n    GC_release_mark_lock();\n#      else\n#        if !defined(GC_ASSERTIONS) \\\n            || (defined(THREAD_SANITIZER) && defined(CAN_CALL_ATFORK))\n    /* Do not change GC_mark_lock_holder. */\n#        else\n    GC_mark_lock_holder = NO_THREAD;\n#        endif\n    /* The unlock operation may fail on some targets, just ignore   */\n    /* the error silently.                                          */\n    (void)pthread_mutex_unlock(&mark_mutex);\n    /* Reinitialize the mark lock.  The reason is the same as for   */\n    /* GC_allocate_ml below.                                        */\n    (void)pthread_mutex_destroy(&mark_mutex);\n    /* TODO: GLIBC_2_19_TSX_BUG has no effect. */\n    if (pthread_mutex_init(&mark_mutex, NULL) != 0)\n      ABORT(\"mark_mutex re-init failed in child\");\n#      endif\n    /* Turn off parallel marking in the child, since we are probably  */\n    /* just going to exec, and we would have to restart mark threads. */\n    GC_parallel = FALSE;\n  }\n#      ifdef THREAD_SANITIZER\n  /* TSan does not support threads creation in the child process. */\n  GC_available_markers_m1 = 0;\n#      endif\n#    endif\n  /* Clean up the thread table, so that just our thread is left.      */\n  GC_remove_all_threads_but_me();\n  GC_stackbase_info_update_after_fork();\n  RESTORE_CANCEL(fork_cancel_state);\n#    ifdef GC_ASSERTIONS\n  BZERO(&GC_parent_pthread_self, sizeof(pthread_t));\n#    endif\n  UNLOCK();\n  /* Even though after a fork the child only inherits the single      */\n  /* thread that called the fork(), if another thread in the parent   */\n  /* was attempting to lock the mutex while being held in             */\n  /* fork_child_prepare(), the mutex will be left in an inconsistent  */\n  /* state in the child after the UNLOCK.  This is the case, at       */\n  /* least, in Mac OS X and leads to an unusable GC in the child      */\n  /* which will block when attempting to perform any GC operation     */\n  /* that acquires the allocation mutex.                              */\n#    if defined(USE_PTHREAD_LOCKS) && !defined(GC_WIN32_THREADS)\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  /* Reinitialize the mutex.  It should be safe since we are        */\n  /* running this in the child which only inherits a single thread. */\n  /* pthread_mutex_destroy() and pthread_rwlock_destroy() may       */\n  /* return EBUSY, which makes no sense, but that is the reason for */\n  /* the need of the reinitialization.                              */\n  /* Note: excluded for Cygwin as does not seem to be needed.       */\n#      ifdef USE_RWLOCK\n  (void)pthread_rwlock_destroy(&GC_allocate_ml);\n#        ifdef DARWIN\n  /* A workaround for pthread_rwlock_init() fail with EBUSY.    */\n  {\n    pthread_rwlock_t rwlock_local = PTHREAD_RWLOCK_INITIALIZER;\n    BCOPY(&rwlock_local, &GC_allocate_ml, sizeof(GC_allocate_ml));\n  }\n#        else\n  if (pthread_rwlock_init(&GC_allocate_ml, NULL) != 0)\n    ABORT(\"pthread_rwlock_init failed (in child)\");\n#        endif\n#      else\n  (void)pthread_mutex_destroy(&GC_allocate_ml);\n  /* TODO: Probably some targets (e.g. with GLIBC_2_19_TSX_BUG) might   */\n  /* need the default mutex attribute to be passed instead of NULL.     */\n  if (pthread_mutex_init(&GC_allocate_ml, NULL) != 0)\n    ABORT(\"pthread_mutex_init failed (in child)\");\n#      endif\n#    endif\n}\n\n/* Routines for fork handling by client (no-op if pthread_atfork works). */\nGC_API void GC_CALL\nGC_atfork_prepare(void)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  if (GC_handle_fork <= 0)\n    fork_prepare_proc();\n}\n\nGC_API void GC_CALL\nGC_atfork_parent(void)\n{\n  if (GC_handle_fork <= 0)\n    fork_parent_proc();\n}\n\nGC_API void GC_CALL\nGC_atfork_child(void)\n{\n  if (GC_handle_fork <= 0)\n    fork_child_proc();\n}\n\n/* Prepare for forks if requested.    */\nGC_INNER_WIN32THREAD void\nGC_setup_atfork(void)\n{\n  if (GC_handle_fork) {\n#    ifdef CAN_CALL_ATFORK\n    if (pthread_atfork(fork_prepare_proc, fork_parent_proc, fork_child_proc)\n        == 0) {\n      /* Handlers successfully registered.  */\n      GC_handle_fork = 1;\n    } else\n#    endif\n    /* else */ {\n      if (GC_handle_fork != -1)\n        ABORT(\"pthread_atfork failed\");\n    }\n  }\n}\n\n#  endif /* CAN_HANDLE_FORK */\n\n#  ifdef INCLUDE_LINUX_THREAD_DESCR\n__thread int GC_dummy_thread_local;\n#  endif\n\n#  ifdef PARALLEL_MARK\n#    ifndef GC_WIN32_THREADS\nstatic void setup_mark_lock(void);\n#    endif\n\n/* Note: the default value (0) means the number of markers should be  */\n/* selected automatically.                                            */\nGC_INNER_WIN32THREAD unsigned GC_required_markers_cnt = 0;\n\nGC_API void GC_CALL\nGC_set_markers_count(unsigned markers)\n{\n  GC_required_markers_cnt = markers < MAX_MARKERS ? markers : MAX_MARKERS;\n}\n#  endif /* PARALLEL_MARK */\n\n/* Note: this variable is protected by the allocator lock.      */\nGC_INNER GC_bool GC_in_thread_creation = FALSE;\n\nGC_INNER_WIN32THREAD void\nGC_record_stack_base(GC_stack_context_t crtn, const struct GC_stack_base *sb)\n{\n#  if !defined(DARWIN) && !defined(GC_WIN32_THREADS)\n  crtn->stack_ptr = (ptr_t)sb->mem_base;\n#  endif\n  if ((crtn->stack_end = (ptr_t)sb->mem_base) == NULL)\n    ABORT(\"Bad stack base in GC_register_my_thread\");\n#  ifdef E2K\n  crtn->ps_ofs = (size_t)(GC_uintptr_t)sb->reg_base;\n#  elif defined(IA64)\n  crtn->backing_store_end = (ptr_t)sb->reg_base;\n#  elif defined(I386) && defined(GC_WIN32_THREADS)\n  crtn->initial_stack_base = (ptr_t)sb->mem_base;\n#  endif\n}\n\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS) \\\n      || !defined(DONT_USE_ATEXIT)\nGC_INNER_WIN32THREAD thread_id_t GC_main_thread_id;\n#  endif\n\n#  ifndef DONT_USE_ATEXIT\nGC_INNER GC_bool\nGC_is_main_thread(void)\n{\n  GC_ASSERT(GC_thr_initialized);\n  return THREAD_ID_EQUAL(GC_main_thread_id, thread_id_self());\n}\n#  endif /* !DONT_USE_ATEXIT */\n\n#  ifndef GC_WIN32_THREADS\n\nSTATIC GC_thread\nGC_register_my_thread_inner(const struct GC_stack_base *sb,\n                            thread_id_t self_id)\n{\n  GC_thread me;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  me = GC_new_thread(self_id);\n  me->id = self_id;\n#    ifdef DARWIN\n  me->mach_thread = mach_thread_self();\n#    endif\n  GC_record_stack_base(me->crtn, sb);\n  return me;\n}\n\n/* Number of processors.  We may not have access to all of them, but  */\n/* this is as good a guess as any ...                                 */\nSTATIC int GC_nprocs = 1;\n\nGC_INNER void\nGC_thr_init(void)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(!GC_thr_initialized);\n  GC_ASSERT(ADDR(&GC_threads) % ALIGNMENT == 0);\n#    ifdef GC_ASSERTIONS\n  GC_thr_initialized = TRUE;\n#    endif\n#    ifdef CAN_HANDLE_FORK\n  GC_setup_atfork();\n#    endif\n\n#    ifdef INCLUDE_LINUX_THREAD_DESCR\n  /* Explicitly register the region including the address     */\n  /* of a thread-local variable.  This should include thread  */\n  /* locals for the main thread, except for those allocated   */\n  /* in response to dlopen calls.                             */\n  {\n    ptr_t thread_local_addr = (ptr_t)(&GC_dummy_thread_local);\n    ptr_t main_thread_start, main_thread_end;\n    if (!GC_enclosing_writable_mapping(thread_local_addr, &main_thread_start,\n                                       &main_thread_end)) {\n      ABORT(\"Failed to find TLS mapping for the primordial thread\");\n    } else {\n      /* main_thread_start and main_thread_end are initialized.       */\n      GC_add_roots_inner(main_thread_start, main_thread_end, FALSE);\n    }\n  }\n#    endif\n\n  /* Set GC_nprocs and GC_available_markers_m1. */\n  {\n    const char *nprocs_string = GETENV(\"GC_NPROCS\");\n    GC_nprocs = -1;\n    if (nprocs_string != NULL)\n      GC_nprocs = atoi(nprocs_string);\n  }\n  if (GC_nprocs <= 0\n#    if defined(LINUX) && defined(ARM32)\n      /* Workaround for some Linux/arm kernels.       */\n      && (GC_nprocs = GC_get_nprocs_present()) <= 1\n#    endif\n  ) {\n    GC_nprocs = GC_get_nprocs();\n  }\n  if (GC_nprocs <= 0) {\n    WARN(\"GC_get_nprocs() returned %\" WARN_PRIdPTR \"\\n\",\n         (GC_signed_word)GC_nprocs);\n    /* Assume a dual-core CPU.  */\n    GC_nprocs = 2;\n#    ifdef PARALLEL_MARK\n    /* But use only one marker.       */\n    GC_available_markers_m1 = 0;\n#    endif\n  } else {\n#    ifdef PARALLEL_MARK\n    {\n      const char *markers_string = GETENV(\"GC_MARKERS\");\n      int markers = GC_required_markers_cnt;\n\n      if (markers_string != NULL) {\n        markers = atoi(markers_string);\n        if (markers <= 0 || markers > MAX_MARKERS) {\n          WARN(\"Too big or invalid number of mark threads: %\" WARN_PRIdPTR\n               \"; using maximum threads\\n\",\n               (GC_signed_word)markers);\n          markers = MAX_MARKERS;\n        }\n      } else if (0 == markers) {\n        /* Unless the client sets the desired number of       */\n        /* parallel markers, it is determined based on the    */\n        /* number of CPU cores.                               */\n        markers = GC_nprocs;\n#      if defined(GC_MIN_MARKERS) && !defined(CPPCHECK)\n        /* This is primarily for targets without getenv().  */\n        if (markers < GC_MIN_MARKERS)\n          markers = GC_MIN_MARKERS;\n#      endif\n        if (markers > MAX_MARKERS) {\n          /* Silently limit the amount of markers.    */\n          markers = MAX_MARKERS;\n        }\n      }\n      GC_available_markers_m1 = markers - 1;\n    }\n#    endif\n  }\n  GC_COND_LOG_PRINTF(\"Number of processors: %d\\n\", GC_nprocs);\n\n#    if defined(BASE_ATOMIC_OPS_EMULATED) && defined(SIGNAL_BASED_STOP_WORLD)\n  /* Ensure the process is running on just one CPU core.      */\n  /* This is needed because the AO primitives emulated with   */\n  /* locks cannot be used inside signal handlers.             */\n  {\n    cpu_set_t mask;\n    int cpu_set_cnt = 0;\n    int cpu_lowest_set = 0;\n#      ifdef RANDOM_ONE_CPU_CORE\n    int cpu_highest_set = 0;\n#      endif\n    /* Ensure at least 2 cores.       */\n    int i = GC_nprocs > 1 ? GC_nprocs : 2;\n\n    if (sched_getaffinity(0 /* current process */, sizeof(mask), &mask) == -1)\n      ABORT_ARG1(\"sched_getaffinity failed\", \": errno= %d\", errno);\n    while (i-- > 0)\n      if (CPU_ISSET(i, &mask)) {\n#      ifdef RANDOM_ONE_CPU_CORE\n        if (i + 1 != cpu_lowest_set)\n          cpu_highest_set = i;\n#      endif\n        cpu_lowest_set = i;\n        cpu_set_cnt++;\n      }\n    if (0 == cpu_set_cnt)\n      ABORT(\"sched_getaffinity returned empty mask\");\n    if (cpu_set_cnt > 1) {\n#      ifdef RANDOM_ONE_CPU_CORE\n      if (cpu_lowest_set < cpu_highest_set) {\n        /* Pseudo-randomly adjust the bit to set among valid ones.  */\n        cpu_lowest_set\n            += (unsigned)getpid() % (cpu_highest_set - cpu_lowest_set + 1);\n      }\n#      endif\n      CPU_ZERO(&mask);\n      /* Select just one CPU. */\n      CPU_SET(cpu_lowest_set, &mask);\n      if (sched_setaffinity(0, sizeof(mask), &mask) == -1)\n        ABORT_ARG1(\"sched_setaffinity failed\", \": errno= %d\", errno);\n      WARN(\"CPU affinity mask is set to %p\\n\", (word)1 << cpu_lowest_set);\n    }\n  }\n#    endif /* BASE_ATOMIC_OPS_EMULATED */\n\n#    ifndef DARWIN\n  GC_stop_init();\n#    endif\n\n#    ifdef PARALLEL_MARK\n  if (GC_available_markers_m1 <= 0) {\n    /* Disable parallel marking.      */\n    GC_parallel = FALSE;\n    GC_COND_LOG_PRINTF(\"Single marker thread, turning off parallel marking\\n\");\n  } else {\n    setup_mark_lock();\n  }\n#    endif\n\n  /* Add the initial thread, so we can stop it. */\n  {\n    struct GC_stack_base sb;\n    GC_thread me;\n    thread_id_t self_id = thread_id_self();\n\n    sb.mem_base = GC_stackbottom;\n    GC_ASSERT(sb.mem_base != NULL);\n#    if defined(E2K) || defined(IA64)\n    sb.reg_base = GC_register_stackbottom;\n#    endif\n    GC_ASSERT(NULL == GC_self_thread_inner());\n    me = GC_register_my_thread_inner(&sb, self_id);\n#    ifndef DONT_USE_ATEXIT\n    GC_main_thread_id = self_id;\n#    endif\n    me->flags = DETACHED;\n  }\n}\n\n#  endif /* !GC_WIN32_THREADS */\n\n/* Perform all initializations, including those that may require        */\n/* allocation, e.g. initialize thread-local free lists if used.         */\n/* Must be called before a thread is created.                           */\nGC_INNER void\nGC_init_parallel(void)\n{\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_thread me;\n\n  GC_ASSERT(GC_is_initialized);\n  LOCK();\n  me = GC_self_thread_inner();\n  GC_init_thread_local(&me->tlfs);\n  UNLOCK();\n#  endif\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  if (GC_win32_dll_threads) {\n    /* Cannot intercept thread creation.  Hence we don't know if  */\n    /* other threads exist.  However, client is not allowed to    */\n    /* create other threads before collector initialization.      */\n    /* Thus it's OK not to lock before this.                      */\n    set_need_to_lock();\n  }\n#  endif\n}\n\n#  if !defined(GC_NO_PTHREAD_SIGMASK) && defined(GC_PTHREADS)\n#    define GC_wrap_pthread_sigmask WRAP_FUNC(pthread_sigmask)\nGC_API int\nGC_wrap_pthread_sigmask(int how, const sigset_t *set, sigset_t *oset)\n{\n#    ifdef GC_WIN32_THREADS\n  /* pthreads-win32 does not support sigmask.       */\n  /* So, nothing required here...                   */\n#    else\n  sigset_t fudged_set;\n\n  INIT_REAL_SYMS();\n  if (EXPECT(set != NULL, TRUE) && (how == SIG_BLOCK || how == SIG_SETMASK)) {\n    int sig_suspend = GC_get_suspend_signal();\n\n    fudged_set = *set;\n    GC_ASSERT(sig_suspend >= 0);\n    if (sigdelset(&fudged_set, sig_suspend) != 0)\n      ABORT(\"sigdelset failed\");\n    set = &fudged_set;\n  }\n#    endif\n  return REAL_FUNC(pthread_sigmask)(how, set, oset);\n}\n#    undef GC_wrap_pthread_sigmask\n#  endif /* !GC_NO_PTHREAD_SIGMASK */\n\n/* Wrapper for functions that are likely to block for an appreciable    */\n/* length of time.                                                      */\n\n#  ifdef E2K\n/* Cannot be defined as a function because the stack-allocated buffer */\n/* (pointed to by bs_lo) should be preserved till completion of       */\n/* GC_do_blocking_inner (or GC_suspend_self_blocked).                 */\n#    define do_blocking_enter(pTopOfStackUnset, me)                   \\\n      do {                                                            \\\n        ptr_t bs_lo;                                                  \\\n        size_t stack_size;                                            \\\n        GC_stack_context_t crtn = (me)->crtn;                         \\\n                                                                      \\\n        *(pTopOfStackUnset) = FALSE;                                  \\\n        crtn->stack_ptr = GC_approx_sp();                             \\\n        GC_ASSERT(NULL == crtn->backing_store_end);                   \\\n        GET_PROCEDURE_STACK_LOCAL(crtn->ps_ofs, &bs_lo, &stack_size); \\\n        crtn->backing_store_end = bs_lo;                              \\\n        crtn->backing_store_ptr = bs_lo + stack_size;                 \\\n        (me)->flags |= DO_BLOCKING;                                   \\\n      } while (0)\n\n#  else /* !E2K */\nstatic void\ndo_blocking_enter(GC_bool *pTopOfStackUnset, GC_thread me)\n{\n#    if defined(SPARC) || defined(IA64)\n  ptr_t bs_hi = GC_save_regs_in_stack();\n  /* TODO: regs saving already done by GC_with_callee_saves_pushed */\n#    endif\n  GC_stack_context_t crtn = me->crtn;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  GC_ASSERT((me->flags & DO_BLOCKING) == 0);\n  *pTopOfStackUnset = FALSE;\n#    ifdef SPARC\n  crtn->stack_ptr = bs_hi;\n#    else\n  crtn->stack_ptr = GC_approx_sp();\n#    endif\n#    if defined(DARWIN) && !defined(DARWIN_DONT_PARSE_STACK)\n  if (NULL == crtn->topOfStack) {\n    /* GC_do_blocking_inner is not called recursively,  */\n    /* so topOfStack should be computed now.            */\n    *pTopOfStackUnset = TRUE;\n    crtn->topOfStack = GC_FindTopOfStack(0);\n  }\n#    endif\n#    ifdef IA64\n  crtn->backing_store_ptr = bs_hi;\n#    endif\n  me->flags |= DO_BLOCKING;\n  /* Save context here if we want to support precise stack marking.   */\n}\n#  endif /* !E2K */\n\nstatic void\ndo_blocking_leave(GC_thread me, GC_bool topOfStackUnset)\n{\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  me->flags &= (unsigned char)~DO_BLOCKING;\n#  ifdef E2K\n  {\n    GC_stack_context_t crtn = me->crtn;\n\n    GC_ASSERT(crtn->backing_store_end != NULL);\n    crtn->backing_store_ptr = NULL;\n    crtn->backing_store_end = NULL;\n  }\n#  endif\n#  if defined(DARWIN) && !defined(DARWIN_DONT_PARSE_STACK)\n  if (topOfStackUnset) {\n    /* Make it unset again.       */\n    me->crtn->topOfStack = NULL;\n  }\n#  else\n  (void)topOfStackUnset;\n#  endif\n}\n\nGC_INNER void\nGC_do_blocking_inner(ptr_t data, void *context)\n{\n  GC_thread me;\n  GC_bool topOfStackUnset;\n\n  UNUSED_ARG(context);\n  READER_LOCK();\n  me = GC_self_thread_inner();\n  do_blocking_enter(&topOfStackUnset, me);\n  READER_UNLOCK_RELEASE();\n\n  ((struct blocking_data *)data)->client_data /* result */\n      = ((struct blocking_data *)data)\n            ->fn(((struct blocking_data *)data)->client_data);\n\n  /* This will block if the world is stopped. */\n  READER_LOCK();\n\n#  ifdef LINT2\n  {\n#    ifdef GC_ASSERTIONS\n    GC_thread saved_me = me;\n#    endif\n\n    /* The pointer to the GC thread descriptor should not be   */\n    /* changed while the thread is registered but a static     */\n    /* analysis tool might complain that this pointer value    */\n    /* (obtained in the first locked section) is unreliable in */\n    /* the second locked section.                              */\n    me = GC_self_thread_inner();\n    GC_ASSERT(me == saved_me);\n  }\n#  endif\n#  if defined(GC_ENABLE_SUSPEND_THREAD) && defined(SIGNAL_BASED_STOP_WORLD)\n  /* Note: this code cannot be moved into do_blocking_leave()   */\n  /* otherwise there could be a static analysis tool warning    */\n  /* (false positive) about unlock without a matching lock.     */\n  while (EXPECT((me->ext_suspend_cnt & 1) != 0, FALSE)) {\n    /* Read suspend counter (number) before unlocking.          */\n    size_t suspend_cnt = me->ext_suspend_cnt;\n\n    READER_UNLOCK_RELEASE();\n    GC_suspend_self_inner(me, suspend_cnt);\n    READER_LOCK();\n  }\n#  endif\n  do_blocking_leave(me, topOfStackUnset);\n  READER_UNLOCK_RELEASE();\n}\n\n#  if defined(GC_ENABLE_SUSPEND_THREAD) && defined(SIGNAL_BASED_STOP_WORLD)\n/* Similar to GC_do_blocking_inner() but assuming the allocator lock  */\n/* is held and fn is GC_suspend_self_inner.                           */\nGC_INNER void\nGC_suspend_self_blocked(ptr_t thread_me, void *context)\n{\n  GC_thread me = (GC_thread)thread_me;\n  GC_bool topOfStackUnset;\n\n  UNUSED_ARG(context);\n\n  /* The caller holds the allocator lock in the exclusive mode, thus  */\n  /* we require and restore it to the same mode upon return from the  */\n  /* function.                                                        */\n  GC_ASSERT(I_HOLD_LOCK());\n\n  do_blocking_enter(&topOfStackUnset, me);\n  while ((me->ext_suspend_cnt & 1) != 0) {\n    size_t suspend_cnt = me->ext_suspend_cnt;\n\n    UNLOCK();\n    GC_suspend_self_inner(me, suspend_cnt);\n    LOCK();\n  }\n  do_blocking_leave(me, topOfStackUnset);\n}\n#  endif /* GC_ENABLE_SUSPEND_THREAD */\n\nGC_API void GC_CALL\nGC_set_stackbottom(void *gc_thread_handle, const struct GC_stack_base *sb)\n{\n  GC_thread t = (GC_thread)gc_thread_handle;\n  GC_stack_context_t crtn;\n\n  GC_ASSERT(sb->mem_base != NULL);\n  if (!EXPECT(GC_is_initialized, TRUE)) {\n    GC_ASSERT(NULL == t);\n    /* Alter the stack bottom of the primordial thread.       */\n    GC_stackbottom = (char *)sb->mem_base;\n#  if defined(E2K) || defined(IA64)\n    GC_register_stackbottom = (ptr_t)sb->reg_base;\n#  endif\n    return;\n  }\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  if (NULL == t) {\n    /* The current thread.    */\n    t = GC_self_thread_inner();\n  }\n  GC_ASSERT(!KNOWN_FINISHED(t));\n  crtn = t->crtn;\n  GC_ASSERT((t->flags & DO_BLOCKING) == 0\n            && NULL == crtn->traced_stack_sect); /* for now */\n\n  crtn->stack_end = (ptr_t)sb->mem_base;\n#  ifdef E2K\n  crtn->ps_ofs = (size_t)(GC_uintptr_t)sb->reg_base;\n#  elif defined(IA64)\n  crtn->backing_store_end = (ptr_t)sb->reg_base;\n#  endif\n#  ifdef GC_WIN32_THREADS\n  /* Reset the known minimum (hottest address in the stack). */\n  crtn->last_stack_min = ADDR_LIMIT;\n#  endif\n}\n\nGC_API void *GC_CALL\nGC_get_my_stackbottom(struct GC_stack_base *sb)\n{\n  GC_thread me;\n  GC_stack_context_t crtn;\n\n  READER_LOCK();\n  me = GC_self_thread_inner();\n  /* The thread is assumed to be registered.  */\n  crtn = me->crtn;\n  sb->mem_base = crtn->stack_end;\n#  ifdef E2K\n  /* Store the offset in the procedure stack, not address.  */\n  sb->reg_base = NUMERIC_TO_VPTR(crtn->ps_ofs);\n#  elif defined(IA64)\n  sb->reg_base = crtn->backing_store_end;\n#  endif\n  READER_UNLOCK();\n  return me; /* gc_thread_handle */\n}\n\n/* GC_call_with_gc_active() has the opposite to GC_do_blocking()        */\n/* functionality.  It might be called from a user function invoked by   */\n/* GC_do_blocking() to temporarily back allow calling any GC function   */\n/* and/or manipulating pointers to the garbage collected heap.          */\nGC_ATTR_NOINLINE\nGC_API void *GC_CALL\nGC_call_with_gc_active(GC_fn_type fn, void *client_data)\n{\n  struct GC_traced_stack_sect_s stacksect;\n  GC_thread me;\n  GC_stack_context_t crtn;\n  ptr_t stack_end;\n#  ifdef E2K\n  ptr_t saved_bs_ptr, saved_bs_end;\n  size_t saved_ps_ofs;\n#  endif\n\n  /* This will block if the world is stopped. */\n  READER_LOCK();\n\n  me = GC_self_thread_inner();\n  crtn = me->crtn;\n\n  /* Adjust our stack bottom value (this could happen unless  */\n  /* GC_get_stack_base() was used which returned GC_SUCCESS). */\n  stack_end = crtn->stack_end; /* read of a volatile field */\n  GC_ASSERT(stack_end != NULL);\n  STORE_APPROX_SP_TO(*(volatile ptr_t *)&stacksect.saved_stack_ptr);\n  if (HOTTER_THAN(stack_end, stacksect.saved_stack_ptr)) {\n    crtn->stack_end = stacksect.saved_stack_ptr;\n#  if defined(I386) && defined(GC_WIN32_THREADS)\n    crtn->initial_stack_base = stacksect.saved_stack_ptr;\n#  endif\n  }\n\n  if ((me->flags & DO_BLOCKING) == 0) {\n    /* We are not inside GC_do_blocking() - do nothing more.  */\n    READER_UNLOCK_RELEASE();\n    /* Cast fn to a volatile type to prevent its call inlining.   */\n    client_data = (*(GC_fn_type volatile *)&fn)(client_data);\n    /* Prevent treating the above as a tail call.     */\n    GC_noop1(COVERT_DATAFLOW(ADDR(&stacksect)));\n    return client_data; /* result */\n  }\n\n#  if defined(GC_ENABLE_SUSPEND_THREAD) && defined(SIGNAL_BASED_STOP_WORLD)\n  while (EXPECT((me->ext_suspend_cnt & 1) != 0, FALSE)) {\n    size_t suspend_cnt = me->ext_suspend_cnt;\n\n    READER_UNLOCK_RELEASE();\n    GC_suspend_self_inner(me, suspend_cnt);\n    READER_LOCK();\n    GC_ASSERT(me->crtn == crtn);\n  }\n#  endif\n\n  /* Setup new \"stack section\".       */\n  stacksect.saved_stack_ptr = crtn->stack_ptr;\n#  ifdef E2K\n  GC_ASSERT(crtn->backing_store_end != NULL);\n  {\n    unsigned long long sz_ull;\n\n    GET_PROCEDURE_STACK_SIZE_INNER(&sz_ull);\n    saved_ps_ofs = crtn->ps_ofs;\n    GC_ASSERT(saved_ps_ofs <= (size_t)sz_ull);\n    crtn->ps_ofs = (size_t)sz_ull;\n  }\n  saved_bs_end = crtn->backing_store_end;\n  saved_bs_ptr = crtn->backing_store_ptr;\n  crtn->backing_store_ptr = NULL;\n  crtn->backing_store_end = NULL;\n#  elif defined(IA64)\n  /* This is the same as in GC_call_with_stack_base().      */\n  stacksect.backing_store_end = GC_save_regs_in_stack();\n  /* Unnecessarily flushes register stack,          */\n  /* but that probably doesn't hurt.                */\n  stacksect.saved_backing_store_ptr = crtn->backing_store_ptr;\n#  endif\n  stacksect.prev = crtn->traced_stack_sect;\n  me->flags &= (unsigned char)~DO_BLOCKING;\n  crtn->traced_stack_sect = &stacksect;\n\n  READER_UNLOCK_RELEASE();\n  client_data = (*(GC_fn_type volatile *)&fn)(client_data);\n  GC_ASSERT((me->flags & DO_BLOCKING) == 0);\n\n  /* Restore original \"stack section\".        */\n  READER_LOCK();\n  GC_ASSERT(me->crtn == crtn);\n  GC_ASSERT(crtn->traced_stack_sect == &stacksect);\n#  ifdef CPPCHECK\n  GC_noop1_ptr(crtn->traced_stack_sect);\n#  endif\n  crtn->traced_stack_sect = stacksect.prev;\n#  ifdef E2K\n  GC_ASSERT(NULL == crtn->backing_store_end);\n  crtn->backing_store_end = saved_bs_end;\n  crtn->backing_store_ptr = saved_bs_ptr;\n  crtn->ps_ofs = saved_ps_ofs;\n#  elif defined(IA64)\n  crtn->backing_store_ptr = stacksect.saved_backing_store_ptr;\n#  endif\n  me->flags |= DO_BLOCKING;\n  crtn->stack_ptr = stacksect.saved_stack_ptr;\n  READER_UNLOCK_RELEASE();\n  return client_data; /* result */\n}\n\nSTATIC void\nGC_unregister_my_thread_inner(GC_thread me)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"Unregistering thread %p, gc_thread= %p, n_threads= %d\\n\",\n                THREAD_ID_TO_VPTR(me->id), (void *)me, GC_count_threads());\n#  endif\n  GC_ASSERT(!KNOWN_FINISHED(me));\n#  if defined(THREAD_LOCAL_ALLOC)\n  GC_destroy_thread_local(&me->tlfs);\n#  endif\n#  ifdef NACL\n  GC_nacl_shutdown_gc_thread();\n#  endif\n#  ifdef GC_PTHREADS\n#    if defined(GC_HAVE_PTHREAD_EXIT) || !defined(GC_NO_PTHREAD_CANCEL)\n  /* Handle DISABLED_GC flag which is set by the  */\n  /* intercepted pthread_cancel or pthread_exit.  */\n  if ((me->flags & DISABLED_GC) != 0) {\n    GC_dont_gc--;\n  }\n#    endif\n  if ((me->flags & DETACHED) == 0) {\n    me->flags |= FINISHED;\n  } else\n#  endif\n  /* else */ {\n    GC_delete_thread(me);\n  }\n#  if defined(THREAD_LOCAL_ALLOC)\n  /* It is required to call remove_specific defined in specific.c. */\n  GC_remove_specific(GC_thread_key);\n#  endif\n}\n\nGC_API int GC_CALL\nGC_unregister_my_thread(void)\n{\n  GC_thread me;\n  IF_CANCEL(int cancel_state;)\n\n  /* Client should not unregister the thread explicitly if it */\n  /* is registered by DllMain, except for the main thread.    */\n#  if !defined(GC_NO_THREADS_DISCOVERY) && defined(GC_WIN32_THREADS)\n  GC_ASSERT(!GC_win32_dll_threads\n            || THREAD_ID_EQUAL(GC_main_thread_id, thread_id_self()));\n#  endif\n\n  LOCK();\n  DISABLE_CANCEL(cancel_state);\n  /* Wait for any GC that may be marking from our stack to    */\n  /* complete before we remove this thread.                   */\n  GC_wait_for_gc_completion(FALSE);\n  me = GC_self_thread_inner();\n  GC_ASSERT(THREAD_ID_EQUAL(me->id, thread_id_self()));\n  GC_unregister_my_thread_inner(me);\n  RESTORE_CANCEL(cancel_state);\n  UNLOCK();\n  return GC_SUCCESS;\n}\n\n#  if !defined(GC_NO_PTHREAD_CANCEL) && defined(GC_PTHREADS)\n/* We should deal with the fact that apparently on Solaris and,       */\n/* probably, on some Linux we can't collect while a thread is         */\n/* exiting, since signals aren't handled properly.  This currently    */\n/* gives rise to deadlocks.  The only workaround seen is to intercept */\n/* pthread_cancel() and pthread_exit(), and disable the collections   */\n/* until the thread exit handler is called.  That's ugly, because we  */\n/* risk growing the heap unnecessarily. But it seems that we don't    */\n/* really have an option in that the process is not in a fully        */\n/* functional state while a thread is exiting.                        */\n#    define GC_wrap_pthread_cancel WRAP_FUNC(pthread_cancel)\nGC_API int\nGC_wrap_pthread_cancel(pthread_t thread)\n{\n#    ifdef CANCEL_SAFE\n  GC_thread t;\n#    endif\n\n  INIT_REAL_SYMS();\n#    ifdef CANCEL_SAFE\n  LOCK();\n  t = GC_lookup_by_pthread(thread);\n  /* We test DISABLED_GC because pthread_exit could be called at    */\n  /* the same time.  (If t is NULL then pthread_cancel should       */\n  /* return ESRCH.)                                                 */\n  if (t != NULL && (t->flags & DISABLED_GC) == 0) {\n    t->flags |= DISABLED_GC;\n    GC_dont_gc++;\n  }\n  UNLOCK();\n#    endif\n  return REAL_FUNC(pthread_cancel)(thread);\n}\n#    undef GC_wrap_pthread_cancel\n#  endif /* !GC_NO_PTHREAD_CANCEL */\n\n#  ifdef GC_HAVE_PTHREAD_EXIT\n#    define GC_wrap_pthread_exit WRAP_FUNC(pthread_exit)\nGC_API GC_PTHREAD_EXIT_ATTRIBUTE void\nGC_wrap_pthread_exit(void *retval)\n{\n  GC_thread me;\n\n  INIT_REAL_SYMS();\n  LOCK();\n  me = GC_self_thread_inner();\n  /* We test DISABLED_GC because someone else could call    */\n  /* pthread_cancel at the same time.                       */\n  if (me != NULL && (me->flags & DISABLED_GC) == 0) {\n    me->flags |= DISABLED_GC;\n    GC_dont_gc++;\n  }\n  UNLOCK();\n\n  REAL_FUNC(pthread_exit)(retval);\n}\n#    undef GC_wrap_pthread_exit\n#  endif /* GC_HAVE_PTHREAD_EXIT */\n\nGC_API void GC_CALL\nGC_allow_register_threads(void)\n{\n  /* Check GC is initialized and the current thread is registered.  */\n  GC_ASSERT(GC_self_thread() != NULL);\n\n  /* Initialize symbols while still single-threaded.    */\n  INIT_REAL_SYMS();\n\n  GC_init_lib_bounds();\n  GC_start_mark_threads();\n  set_need_to_lock();\n}\n\n#  if defined(PTHREAD_STOP_WORLD_IMPL)            \\\n          && !defined(NO_SIGNALS_UNBLOCK_IN_MAIN) \\\n      || defined(GC_EXPLICIT_SIGNALS_UNBLOCK)\n/* Some targets (e.g., Solaris) might require this to be called when  */\n/* doing thread registering from the thread destructor.               */\nGC_INNER void\nGC_unblock_gc_signals(void)\n{\n  sigset_t set;\n\n  /* This is for pthread_sigmask.     */\n  INIT_REAL_SYMS();\n\n  sigemptyset(&set);\n  sigaddset(&set, GC_get_suspend_signal());\n  sigaddset(&set, GC_get_thr_restart_signal());\n  if (REAL_FUNC(pthread_sigmask)(SIG_UNBLOCK, &set, NULL) != 0)\n    ABORT(\"pthread_sigmask failed\");\n}\n#  endif /* PTHREAD_STOP_WORLD_IMPL || GC_EXPLICIT_SIGNALS_UNBLOCK */\n\nGC_API int GC_CALL\nGC_register_my_thread(const struct GC_stack_base *sb)\n{\n  GC_thread me;\n\n  if (!GC_need_to_lock)\n    ABORT(\"Threads explicit registering is not previously enabled\");\n\n  /* We lock here, since we want to wait for an ongoing GC.   */\n  LOCK();\n  me = GC_self_thread_inner();\n  if (EXPECT(NULL == me, TRUE)) {\n    me = GC_register_my_thread_inner(sb, thread_id_self());\n#  ifdef GC_PTHREADS\n#    ifdef CPPCHECK\n    GC_noop1(me->flags);\n#    endif\n    /* Treat as detached, since we do not need to worry about       */\n    /* pointer results.                                             */\n    me->flags |= DETACHED;\n#  else\n    (void)me;\n#  endif\n  } else {\n#  ifdef GC_PTHREADS\n    if (KNOWN_FINISHED(me)) {\n      /* This code is executed when a thread is registered from the */\n      /* client thread key destructor.                              */\n#    ifdef NACL\n      GC_nacl_initialize_gc_thread(me);\n#    endif\n#    ifdef DARWIN\n      /* Reinitialize mach_thread to avoid thread_suspend fail    */\n      /* with MACH_SEND_INVALID_DEST error.                       */\n      me->mach_thread = mach_thread_self();\n#    endif\n      GC_record_stack_base(me->crtn, sb);\n      me->flags &= (unsigned char)~FINISHED; /* but not DETACHED */\n    } else\n#  endif\n    /* else */ {\n      UNLOCK();\n      return GC_DUPLICATE;\n    }\n  }\n\n#  ifdef THREAD_LOCAL_ALLOC\n  GC_init_thread_local(&me->tlfs);\n#  endif\n#  ifdef GC_EXPLICIT_SIGNALS_UNBLOCK\n  /* Since this could be executed from a thread destructor, */\n  /* our signals might already be blocked.                  */\n  GC_unblock_gc_signals();\n#  endif\n#  if defined(GC_ENABLE_SUSPEND_THREAD) && defined(SIGNAL_BASED_STOP_WORLD)\n  if (EXPECT((me->ext_suspend_cnt & 1) != 0, FALSE)) {\n    GC_with_callee_saves_pushed(GC_suspend_self_blocked, (ptr_t)me);\n  }\n#  endif\n  UNLOCK();\n  return GC_SUCCESS;\n}\n\n#  if defined(GC_PTHREADS) && !defined(PLATFORM_THREADS) \\\n      && !defined(SN_TARGET_PSP2)\n\n/* Called at thread exit.  Never called for main thread.      */\n/* That is OK, since it results in at most a tiny one-time    */\n/* leak.  And LinuxThreads implementation does not reclaim    */\n/* the primordial (main) thread resources or id anyway.       */\nGC_INNER_PTHRSTART void\nGC_thread_exit_proc(void *arg)\n{\n  GC_thread me = (GC_thread)arg;\n  IF_CANCEL(int cancel_state;)\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"Called GC_thread_exit_proc on %p, gc_thread= %p\\n\",\n                THREAD_ID_TO_VPTR(me->id), (void *)me);\n#    endif\n  LOCK();\n  DISABLE_CANCEL(cancel_state);\n  GC_wait_for_gc_completion(FALSE);\n  GC_unregister_my_thread_inner(me);\n  RESTORE_CANCEL(cancel_state);\n  UNLOCK();\n}\n\n#    define GC_wrap_pthread_join WRAP_FUNC(pthread_join)\nGC_API int\nGC_wrap_pthread_join(pthread_t thread, void **retval)\n{\n  int result;\n  GC_thread t;\n\n  INIT_REAL_SYMS();\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"thread %p is joining thread %p\\n\",\n                PTHREAD_TO_VPTR(pthread_self()), PTHREAD_TO_VPTR(thread));\n#    endif\n\n  /* After the join, thread id may have been recycled.                */\n  READER_LOCK();\n  t = (GC_thread)COVERT_DATAFLOW_P(GC_lookup_by_pthread(thread));\n  /* This is guaranteed to be the intended one, since the thread id */\n  /* cannot have been recycled by pthreads.                         */\n  READER_UNLOCK();\n\n  result = REAL_FUNC(pthread_join)(thread, retval);\n#    ifdef FREEBSD\n  /* On FreeBSD, the wrapped pthread_join() sometimes returns       */\n  /* (what appears to be) a spurious EINTR which caused the test    */\n  /* and real code to fail gratuitously.  Having looked at system   */\n  /* pthread library source code, I see how such return code value  */\n  /* may be generated.  In one path of the code, pthread_join just  */\n  /* returns the errno setting of the thread being joined - this    */\n  /* does not match the POSIX specification or the local man pages. */\n  /* Thus, I have taken the liberty to catch this one spurious      */\n  /* return value.                                                  */\n  if (EXPECT(result == EINTR, FALSE))\n    result = 0;\n#    endif\n\n  if (EXPECT(0 == result, TRUE)) {\n    LOCK();\n    /* Here the pthread id may have been recycled.  Delete the thread */\n    /* from GC_threads (unless it has been registered again from the  */\n    /* client thread key destructor).                                 */\n    if (KNOWN_FINISHED(t)) {\n      GC_delete_thread(t);\n    }\n    UNLOCK();\n  }\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"thread %p join with thread %p %s\\n\",\n                PTHREAD_TO_VPTR(pthread_self()), PTHREAD_TO_VPTR(thread),\n                result != 0 ? \"failed\" : \"succeeded\");\n#    endif\n  return result;\n}\n#    undef GC_wrap_pthread_join\n\n#    define GC_wrap_pthread_detach WRAP_FUNC(pthread_detach)\nGC_API int\nGC_wrap_pthread_detach(pthread_t thread)\n{\n  int result;\n  GC_thread t;\n\n  INIT_REAL_SYMS();\n  READER_LOCK();\n  t = (GC_thread)COVERT_DATAFLOW_P(GC_lookup_by_pthread(thread));\n  READER_UNLOCK();\n  result = REAL_FUNC(pthread_detach)(thread);\n  if (EXPECT(0 == result, TRUE)) {\n    LOCK();\n    /* Here the pthread id may have been recycled.    */\n    if (KNOWN_FINISHED(t)) {\n      GC_delete_thread(t);\n    } else {\n      t->flags |= DETACHED;\n    }\n    UNLOCK();\n  }\n  return result;\n}\n#    undef GC_wrap_pthread_detach\n\nstruct start_info {\n  void *(*start_routine)(void *);\n  void *arg;\n  sem_t registered; /* 1 ==> in our thread table, but       */\n                    /* parent hasn't yet noticed.           */\n  unsigned char flags;\n};\n\n/* Called from GC_pthread_start_inner().  Defined in this file to     */\n/* minimize the number of include files in pthread_start.c (because   */\n/* sem_t and sem_post() are not used in that file directly).          */\nGC_INNER_PTHRSTART GC_thread\nGC_start_rtn_prepare_thread(void *(**pstart)(void *), void **pstart_arg,\n                            struct GC_stack_base *sb, void *arg)\n{\n  struct start_info *psi = (struct start_info *)arg;\n  thread_id_t self_id = thread_id_self();\n  GC_thread me;\n\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"Starting thread %p, sp= %p\\n\",\n                PTHREAD_TO_VPTR(pthread_self()), (void *)GC_approx_sp());\n#    endif\n  /* If a GC occurs before the thread is registered, that GC will     */\n  /* ignore this thread.  That's fine, since it will block trying to  */\n  /* acquire the allocator lock, and won't yet hold interesting       */\n  /* pointers.                                                        */\n  LOCK();\n  /* We register the thread here instead of in the parent, so that    */\n  /* we don't need to hold the allocator lock during pthread_create.  */\n  me = GC_register_my_thread_inner(sb, self_id);\n  GC_ASSERT(me != &first_thread);\n  me->flags = psi->flags;\n#    ifdef GC_WIN32_THREADS\n  GC_win32_cache_self_pthread(self_id);\n#    endif\n#    ifdef THREAD_LOCAL_ALLOC\n  GC_init_thread_local(&me->tlfs);\n#    endif\n  UNLOCK();\n\n  *pstart = psi->start_routine;\n  *pstart_arg = psi->arg;\n#    if defined(DEBUG_THREADS) && defined(FUNCPTR_IS_DATAPTR)\n  GC_log_printf(\"start_routine= %p\\n\", CAST_THRU_UINTPTR(void *, *pstart));\n#    endif\n  sem_post(&psi->registered);\n  /* This was the last action on *psi; OK to deallocate.      */\n  return me;\n}\n\nSTATIC void *\nGC_pthread_start(void *arg)\n{\n#    ifdef INCLUDE_LINUX_THREAD_DESCR\n  struct GC_stack_base sb;\n\n#      ifdef REDIRECT_MALLOC\n  /* GC_get_stack_base may call pthread_getattr_np, which can     */\n  /* unfortunately call realloc, which may allocate from an       */\n  /* unregistered thread.  This is unpleasant, since it might     */\n  /* force heap growth (or, even, heap overflow).                 */\n  GC_disable();\n#      endif\n  if (GC_get_stack_base(&sb) != GC_SUCCESS)\n    ABORT(\"Failed to get thread stack base\");\n#      ifdef REDIRECT_MALLOC\n  GC_enable();\n#      endif\n  return GC_pthread_start_inner(&sb, arg);\n#    else\n  return GC_call_with_stack_base(GC_pthread_start_inner, arg);\n#    endif\n}\n\n#    define GC_wrap_pthread_create WRAP_FUNC(pthread_create)\nGC_API int\nGC_wrap_pthread_create(pthread_t *new_thread,\n                       GC_PTHREAD_CREATE_CONST pthread_attr_t *attr,\n                       void *(*start_routine)(void *), void *arg)\n{\n  int result;\n  struct start_info si;\n\n  GC_ASSERT(I_DONT_HOLD_LOCK());\n  INIT_REAL_SYMS();\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  GC_ASSERT(GC_thr_initialized);\n\n  GC_init_lib_bounds();\n  if (sem_init(&si.registered, GC_SEM_INIT_PSHARED, 0) == -1)\n    ABORT(\"sem_init failed\");\n  si.flags = 0;\n  si.start_routine = start_routine;\n  si.arg = arg;\n\n  /* We resist the temptation to muck with the stack size here,       */\n  /* even if the default is unreasonably small.  That is the client's */\n  /* responsibility.                                                  */\n#    ifdef GC_ASSERTIONS\n  {\n    size_t stack_size = 0;\n    if (NULL != attr) {\n      if (pthread_attr_getstacksize(attr, &stack_size) != 0)\n        ABORT(\"pthread_attr_getstacksize failed\");\n    }\n    if (0 == stack_size) {\n      pthread_attr_t my_attr;\n\n      if (pthread_attr_init(&my_attr) != 0)\n        ABORT(\"pthread_attr_init failed\");\n      if (pthread_attr_getstacksize(&my_attr, &stack_size) != 0)\n        ABORT(\"pthread_attr_getstacksize failed\");\n      (void)pthread_attr_destroy(&my_attr);\n    }\n    /* On Solaris 10 and on Win32 with winpthreads, with the        */\n    /* default attr initialization, stack_size remains 0; fudge it. */\n    if (EXPECT(0 == stack_size, FALSE)) {\n#      if !defined(SOLARIS) && !defined(GC_WIN32_PTHREADS)\n      WARN(\"Failed to get stack size for assertion checking\\n\", 0);\n#      endif\n      stack_size = 1000000;\n    }\n    GC_ASSERT(stack_size >= 65536);\n    /* Our threads may need to do some work for the GC.     */\n    /* Ridiculously small threads won't work, and they      */\n    /* probably wouldn't work anyway.                       */\n  }\n#    endif\n\n  if (attr != NULL) {\n    int detachstate;\n\n    if (pthread_attr_getdetachstate(attr, &detachstate) != 0)\n      ABORT(\"pthread_attr_getdetachstate failed\");\n    if (PTHREAD_CREATE_DETACHED == detachstate)\n      si.flags |= DETACHED;\n  }\n\n#    ifdef PARALLEL_MARK\n  if (EXPECT(!GC_parallel && GC_available_markers_m1 > 0, FALSE))\n    GC_start_mark_threads();\n#    endif\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"About to start new thread from thread %p\\n\",\n                PTHREAD_TO_VPTR(pthread_self()));\n#    endif\n  set_need_to_lock();\n  result = REAL_FUNC(pthread_create)(new_thread, attr, GC_pthread_start, &si);\n\n  /* Wait until child has been added to the thread table.             */\n  /* This also ensures that we hold onto the stack-allocated si       */\n  /* until the child is done with it.                                 */\n  if (EXPECT(0 == result, TRUE)) {\n    IF_CANCEL(int cancel_state;)\n\n    /* pthread_create() is not a cancellation point.        */\n    DISABLE_CANCEL(cancel_state);\n\n    while (sem_wait(&si.registered) == -1) {\n#    ifdef HAIKU\n      /* To workaround some bug in Haiku semaphores.    */\n      if (EACCES == errno)\n        continue;\n#    endif\n      if (errno != EINTR)\n        ABORT(\"sem_wait failed\");\n    }\n    RESTORE_CANCEL(cancel_state);\n  }\n  sem_destroy(&si.registered);\n  return result;\n}\n#    undef GC_wrap_pthread_create\n\n#  endif /* GC_PTHREADS && !PLATFORM_THREADS && !SN_TARGET_PSP2 */\n\n#  if ((defined(GC_PTHREADS_PARAMARK) || defined(USE_PTHREAD_LOCKS)) \\\n       && !defined(NO_PTHREAD_TRYLOCK))                              \\\n      || defined(USE_SPIN_LOCK)\n/* Spend a few cycles in a way that can't introduce contention with   */\n/* other threads.                                                     */\n#    define GC_PAUSE_SPIN_CYCLES 10\nSTATIC void\nGC_pause(void)\n{\n  int i;\n\n  for (i = 0; i < GC_PAUSE_SPIN_CYCLES; ++i) {\n    /* Something that's unlikely to be optimized away. */\n#    if defined(AO_HAVE_compiler_barrier) && !defined(BASE_ATOMIC_OPS_EMULATED)\n    AO_compiler_barrier();\n#    else\n    GC_noop1(i);\n#    endif\n  }\n}\n#  endif /* USE_SPIN_LOCK || !NO_PTHREAD_TRYLOCK */\n\n#  ifndef SPIN_MAX\n/* Maximum number of calls to GC_pause before give up.        */\n#    define SPIN_MAX 128\n#  endif\n\n#  if (!defined(USE_SPIN_LOCK) && !defined(NO_PTHREAD_TRYLOCK) \\\n       && defined(USE_PTHREAD_LOCKS))                          \\\n      || defined(GC_PTHREADS_PARAMARK)\n/* If we do not want to use the below spinlock implementation, either */\n/* because we don't have a GC_test_and_set implementation, or because */\n/* we don't want to risk sleeping, we can still try spinning on       */\n/* pthread_mutex_trylock for a while.  This appears to be very        */\n/* beneficial in many cases.                                          */\n/* I suspect that under high contention this is nearly always better  */\n/* than the spin lock.  But it is a bit slower on a uniprocessor.     */\n/* Hence we still default to the spin lock.                           */\n/* This is also used to acquire the mark lock for the parallel        */\n/* marker.                                                            */\n\n/* Here we use a strict exponential backoff scheme.  I don't know     */\n/* whether that's better or worse than the above.  We eventually      */\n/* yield by calling pthread_mutex_lock(); it never makes sense to     */\n/* explicitly sleep.                                                  */\n\n#    ifdef LOCK_STATS\n/* Note that LOCK_STATS requires AO_HAVE_test_and_set.      */\nvolatile AO_t GC_spin_count = 0;\nvolatile AO_t GC_block_count = 0;\nvolatile AO_t GC_unlocked_count = 0;\n#    endif\n\nSTATIC void\nGC_generic_lock(pthread_mutex_t *lock)\n{\n#    ifndef NO_PTHREAD_TRYLOCK\n  unsigned pause_length = 1;\n  unsigned i;\n\n  if (EXPECT(0 == pthread_mutex_trylock(lock), TRUE)) {\n#      ifdef LOCK_STATS\n    (void)AO_fetch_and_add1(&GC_unlocked_count);\n#      endif\n    return;\n  }\n  for (; pause_length <= (unsigned)SPIN_MAX; pause_length <<= 1) {\n    for (i = 0; i < pause_length; ++i) {\n      GC_pause();\n    }\n    switch (pthread_mutex_trylock(lock)) {\n    case 0:\n#      ifdef LOCK_STATS\n      (void)AO_fetch_and_add1(&GC_spin_count);\n#      endif\n      return;\n    case EBUSY:\n      break;\n    default:\n      ABORT(\"Unexpected error from pthread_mutex_trylock\");\n    }\n  }\n#    endif /* !NO_PTHREAD_TRYLOCK */\n#    ifdef LOCK_STATS\n  (void)AO_fetch_and_add1(&GC_block_count);\n#    endif\n  pthread_mutex_lock(lock);\n}\n#  endif /* !USE_SPIN_LOCK || ... */\n\n#  if defined(GC_PTHREADS) && !defined(GC_WIN32_THREADS)\n/* A hint that we are in the collector and holding the allocator lock */\n/* for an extended period.                                            */\nGC_INNER volatile unsigned char GC_collecting = FALSE;\n\n#    if defined(AO_HAVE_char_load) && !defined(BASE_ATOMIC_OPS_EMULATED)\n#      define is_collecting() ((GC_bool)AO_char_load(&GC_collecting))\n#    else\n/* GC_collecting is a hint, a potential data race between   */\n/* GC_lock() and ENTER/EXIT_GC() is OK to ignore.           */\n#      define is_collecting() ((GC_bool)GC_collecting)\n#    endif\n#  endif /* GC_PTHREADS && !GC_WIN32_THREADS */\n\n#  ifdef GC_ASSERTIONS\nGC_INNER unsigned long GC_lock_holder = NO_THREAD;\n#  endif\n\n#  if defined(USE_SPIN_LOCK)\n/* Reasonably fast spin locks.  Basically the same implementation     */\n/* as STL alloc.h.  This isn't really the right way to do this.       */\n/* but until the POSIX scheduling mess gets straightened out ...      */\n\n/* Spin cycles if we suspect we are running on an uniprocessor.       */\n#    define low_spin_max 30\n\n/* Spin cycles for a multiprocessor.  */\n#    define high_spin_max SPIN_MAX\n\nstatic volatile AO_t spin_max = low_spin_max;\n\n/* A potential data race between threads invoking GC_lock which reads */\n/* and updates spin_max and last_spins could be ignored because these */\n/* variables are hints only.                                          */\nstatic volatile AO_t last_spins = 0;\n\nGC_INNER void\nGC_lock(void)\n{\n  AO_t my_spin_max, my_last_spins_half;\n  size_t i;\n\n  if (EXPECT(AO_test_and_set_acquire(&GC_allocate_lock) == AO_TS_CLEAR,\n             TRUE)) {\n    return;\n  }\n  my_spin_max = AO_load(&spin_max);\n  my_last_spins_half = AO_load(&last_spins) / 2;\n  for (i = 0; i < my_spin_max; i++) {\n    if (is_collecting() || GC_nprocs == 1)\n      goto yield;\n    if (i < my_last_spins_half) {\n      GC_pause();\n      continue;\n    }\n    if (AO_test_and_set_acquire(&GC_allocate_lock) == AO_TS_CLEAR) {\n      /* Got it, spinning worked!  Thus we are probably not being */\n      /* scheduled against the other process with which we were   */\n      /* contending.  Thus it makes sense to spin longer the next */\n      /* time.                                                    */\n      AO_store(&last_spins, i);\n      AO_store(&spin_max, high_spin_max);\n      return;\n    }\n  }\n  /* We are probably being scheduled against the other process.  Sleep. */\n  AO_store(&spin_max, low_spin_max);\nyield:\n  for (i = 0;; ++i) {\n    if (AO_test_and_set_acquire(&GC_allocate_lock) == AO_TS_CLEAR) {\n      return;\n    }\n\n    /* Under Linux very short sleeps tend to wait until the current */\n    /* time quantum expires.  On old Linux kernels nanosleep        */\n    /* (<= 2 ms) just spins.  (Under Linux 2.4, this happens only   */\n    /* for real-time processes.)  We want to minimize both          */\n    /* behaviors here.                                              */\n#    define SLEEP_THRESHOLD 12\n\n    if (i < SLEEP_THRESHOLD) {\n      sched_yield();\n    } else {\n      struct timespec ts;\n\n      /* Do not wait for more than about 15 ms, even under        */\n      /* extreme contention.                                      */\n      if (i > 24)\n        i = 24;\n\n      ts.tv_sec = 0;\n      ts.tv_nsec = (unsigned32)1 << i;\n      nanosleep(&ts, 0);\n    }\n  }\n}\n\n#  elif defined(USE_PTHREAD_LOCKS)\n#    ifdef USE_RWLOCK\nGC_INNER pthread_rwlock_t GC_allocate_ml = PTHREAD_RWLOCK_INITIALIZER;\n#    else\nGC_INNER pthread_mutex_t GC_allocate_ml = PTHREAD_MUTEX_INITIALIZER;\n#    endif\n\n#    ifndef NO_PTHREAD_TRYLOCK\nGC_INNER void\nGC_lock(void)\n{\n  if (1 == GC_nprocs || is_collecting()) {\n    pthread_mutex_lock(&GC_allocate_ml);\n  } else {\n    GC_generic_lock(&GC_allocate_ml);\n  }\n}\n#    elif defined(GC_ASSERTIONS)\nGC_INNER void\nGC_lock(void)\n{\n#      ifdef USE_RWLOCK\n  (void)pthread_rwlock_wrlock(&GC_allocate_ml); /* exclusive */\n#      else\n  pthread_mutex_lock(&GC_allocate_ml);\n#      endif\n}\n#    endif /* NO_PTHREAD_TRYLOCK && GC_ASSERTIONS */\n\n#  endif /* !USE_SPIN_LOCK && USE_PTHREAD_LOCKS */\n\n#  ifdef GC_PTHREADS_PARAMARK\n\n#    if defined(GC_ASSERTIONS) && defined(GC_WIN32_THREADS) \\\n        && !defined(USE_PTHREAD_LOCKS)\n/* Note: result is not guaranteed to be unique. */\n#      define NUMERIC_THREAD_ID(id) ((unsigned long)ADDR(PTHREAD_TO_VPTR(id)))\n#    endif\n\n#    ifdef GC_ASSERTIONS\n#      define SET_MARK_LOCK_HOLDER \\\n        (void)(GC_mark_lock_holder = NUMERIC_THREAD_ID(pthread_self()))\n#      define UNSET_MARK_LOCK_HOLDER                       \\\n        do {                                               \\\n          GC_ASSERT(GC_mark_lock_holder                    \\\n                    == NUMERIC_THREAD_ID(pthread_self())); \\\n          GC_mark_lock_holder = NO_THREAD;                 \\\n        } while (0)\n#    else\n#      define SET_MARK_LOCK_HOLDER (void)0\n#      define UNSET_MARK_LOCK_HOLDER (void)0\n#    endif /* !GC_ASSERTIONS */\n\nstatic pthread_cond_t builder_cv = PTHREAD_COND_INITIALIZER;\n\n#    ifndef GC_WIN32_THREADS\nstatic void\nsetup_mark_lock(void)\n{\n#      ifdef GLIBC_2_19_TSX_BUG\n  pthread_mutexattr_t mattr;\n  int glibc_minor = -1;\n  int glibc_major = GC_parse_version(&glibc_minor, gnu_get_libc_version());\n\n  if (glibc_major > 2 || (glibc_major == 2 && glibc_minor >= 19)) {\n    /* TODO: disable this workaround for glibc with fixed TSX */\n    /* This disables lock elision to workaround a bug in glibc 2.19+ */\n    if (pthread_mutexattr_init(&mattr) != 0)\n      ABORT(\"pthread_mutexattr_init failed\");\n    if (pthread_mutexattr_settype(&mattr, PTHREAD_MUTEX_NORMAL) != 0)\n      ABORT(\"pthread_mutexattr_settype failed\");\n    if (pthread_mutex_init(&mark_mutex, &mattr) != 0)\n      ABORT(\"pthread_mutex_init failed\");\n    (void)pthread_mutexattr_destroy(&mattr);\n  }\n#      endif\n}\n#    endif /* !GC_WIN32_THREADS */\n\nGC_INNER void\nGC_acquire_mark_lock(void)\n{\n#    if defined(NUMERIC_THREAD_ID_UNIQUE) && !defined(THREAD_SANITIZER)\n  GC_ASSERT(GC_mark_lock_holder != NUMERIC_THREAD_ID(pthread_self()));\n#    endif\n  GC_generic_lock(&mark_mutex);\n  SET_MARK_LOCK_HOLDER;\n}\n\nGC_INNER void\nGC_release_mark_lock(void)\n{\n  UNSET_MARK_LOCK_HOLDER;\n  if (pthread_mutex_unlock(&mark_mutex) != 0)\n    ABORT(\"pthread_mutex_unlock failed\");\n}\n\n/* Collector must wait for free-list builders for 2 reasons:          */\n/* 1) Mark bits may still be getting examined without lock.           */\n/* 2) Partial free lists referenced only by locals may not be scanned */\n/*    correctly, e.g. if they contain \"pointer-free\" objects, since   */\n/*    the free-list link may be ignored.                              */\nSTATIC void\nGC_wait_builder(void)\n{\n  ASSERT_CANCEL_DISABLED();\n  UNSET_MARK_LOCK_HOLDER;\n  if (pthread_cond_wait(&builder_cv, &mark_mutex) != 0)\n    ABORT(\"pthread_cond_wait failed\");\n  GC_ASSERT(GC_mark_lock_holder == NO_THREAD);\n  SET_MARK_LOCK_HOLDER;\n}\n\nGC_INNER void\nGC_wait_for_reclaim(void)\n{\n  GC_acquire_mark_lock();\n  while (GC_fl_builder_count > 0) {\n    GC_wait_builder();\n  }\n  GC_release_mark_lock();\n}\n\n#    if defined(CAN_HANDLE_FORK) && defined(THREAD_SANITIZER)\n/* Identical to GC_wait_for_reclaim() but with the no_sanitize      */\n/* attribute as a workaround for TSan which does not notice that    */\n/* the allocator lock is acquired in fork_prepare_proc().           */\nGC_ATTR_NO_SANITIZE_THREAD\nstatic void\nwait_for_reclaim_atfork(void)\n{\n  GC_acquire_mark_lock();\n  while (GC_fl_builder_count > 0)\n    GC_wait_builder();\n  GC_release_mark_lock();\n}\n#    endif /* CAN_HANDLE_FORK && THREAD_SANITIZER */\n\nGC_INNER void\nGC_notify_all_builder(void)\n{\n  GC_ASSERT(GC_mark_lock_holder == NUMERIC_THREAD_ID(pthread_self()));\n  if (pthread_cond_broadcast(&builder_cv) != 0)\n    ABORT(\"pthread_cond_broadcast failed\");\n}\n\nGC_INNER void\nGC_wait_marker(void)\n{\n  ASSERT_CANCEL_DISABLED();\n  GC_ASSERT(GC_parallel);\n  UNSET_MARK_LOCK_HOLDER;\n  if (pthread_cond_wait(&mark_cv, &mark_mutex) != 0)\n    ABORT(\"pthread_cond_wait failed\");\n  GC_ASSERT(GC_mark_lock_holder == NO_THREAD);\n  SET_MARK_LOCK_HOLDER;\n}\n\nGC_INNER void\nGC_notify_all_marker(void)\n{\n  GC_ASSERT(GC_parallel);\n  if (pthread_cond_broadcast(&mark_cv) != 0)\n    ABORT(\"pthread_cond_broadcast failed\");\n}\n\n#  endif /* GC_PTHREADS_PARAMARK */\n\nGC_INNER GC_on_thread_event_proc GC_on_thread_event = 0;\n\nGC_API void GC_CALL\nGC_set_on_thread_event(GC_on_thread_event_proc fn)\n{\n  /* Note: fn may be 0 (means no event notifier).       */\n  LOCK();\n  GC_on_thread_event = fn;\n  UNLOCK();\n}\n\nGC_API GC_on_thread_event_proc GC_CALL\nGC_get_on_thread_event(void)\n{\n  GC_on_thread_event_proc fn;\n\n  READER_LOCK();\n  fn = GC_on_thread_event;\n  READER_UNLOCK();\n  return fn;\n}\n\n#  ifdef STACKPTR_CORRECTOR_AVAILABLE\nGC_INNER GC_sp_corrector_proc GC_sp_corrector = 0;\n#  endif\n\nGC_API void GC_CALL\nGC_set_sp_corrector(GC_sp_corrector_proc fn)\n{\n#  ifdef STACKPTR_CORRECTOR_AVAILABLE\n  LOCK();\n  GC_sp_corrector = fn;\n  UNLOCK();\n#  else\n  UNUSED_ARG(fn);\n#  endif\n}\n\nGC_API GC_sp_corrector_proc GC_CALL\nGC_get_sp_corrector(void)\n{\n#  ifdef STACKPTR_CORRECTOR_AVAILABLE\n  GC_sp_corrector_proc fn;\n\n  READER_LOCK();\n  fn = GC_sp_corrector;\n  READER_UNLOCK();\n  return fn;\n#  else\n  return 0; /* unsupported */\n#  endif\n}\n\n#  ifdef PTHREAD_REGISTER_CANCEL_WEAK_STUBS\n/* Workaround \"undefined reference\" linkage errors on some targets. */\nEXTERN_C_BEGIN\nextern void __pthread_register_cancel(void) __attribute__((__weak__));\nextern void __pthread_unregister_cancel(void) __attribute__((__weak__));\nEXTERN_C_END\n\nvoid\n__pthread_register_cancel(void)\n{\n}\nvoid\n__pthread_unregister_cancel(void)\n{\n}\n#  endif\n\n#  undef do_blocking_enter\n\n#endif /* THREADS */\n"
        },
        {
          "name": "ptr_chck.c",
          "type": "blob",
          "size": 7.7705078125,
          "content": "/*\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\"\n\n/* These are checking routines calls to which could be inserted by      */\n/* a preprocessor to validate C pointer arithmetic.                     */\n\nSTATIC void GC_CALLBACK\nGC_default_same_obj_print_proc(void *p, void *q)\n{\n  ABORT_ARG2(\"GC_same_obj test failed\",\n             \": %p and %p are not in the same object\", p, q);\n}\n\nGC_same_obj_print_proc_t GC_same_obj_print_proc\n    = GC_default_same_obj_print_proc;\n\nGC_API void *GC_CALL\nGC_same_obj(void *p, void *q)\n{\n  hdr *hhdr;\n  ptr_t base, limit;\n  size_t sz;\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  hhdr = HDR(p);\n  if (NULL == hhdr) {\n    if (divHBLKSZ(ADDR(p)) != divHBLKSZ(ADDR(q)) && HDR(q) != NULL) {\n      GC_same_obj_print_proc((ptr_t)p, (ptr_t)q);\n    }\n    return p;\n  }\n  /* If it's a pointer to the middle of a large object, move it       */\n  /* to the beginning.                                                */\n  if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n    struct hblk *h = GC_find_starting_hblk(HBLKPTR(p), &hhdr);\n\n    limit = (ptr_t)h + hhdr->hb_sz;\n    if (ADDR_GE((ptr_t)p, limit) || ADDR_GE((ptr_t)q, limit)\n        || ADDR_LT((ptr_t)q, (ptr_t)h)) {\n      GC_same_obj_print_proc((ptr_t)p, (ptr_t)q);\n    }\n    return p;\n  }\n  sz = hhdr->hb_sz;\n  if (sz > MAXOBJBYTES) {\n    base = (ptr_t)HBLKPTR(p);\n    limit = base + sz;\n    if (ADDR_GE((ptr_t)p, limit)) {\n      GC_same_obj_print_proc((ptr_t)p, (ptr_t)q);\n      return p;\n    }\n  } else {\n    size_t offset;\n\n    if (HBLKPTR(p) != HBLKPTR(q)) {\n      /* Without this check, we might miss an error if q points to    */\n      /* the first object on a page, and points just before the page. */\n      GC_same_obj_print_proc((ptr_t)p, (ptr_t)q);\n      return p;\n    }\n    offset = HBLKDISPL(p) % sz;\n    base = (ptr_t)p - offset;\n    limit = base + sz;\n  }\n  /* [base, limit) delimits the object containing p, if any.  */\n  /* If p is not inside a valid object, then either q is      */\n  /* also outside any valid object, or it is outside          */\n  /* [base, limit).                                           */\n  if (!ADDR_INSIDE((ptr_t)q, base, limit)) {\n    GC_same_obj_print_proc((ptr_t)p, (ptr_t)q);\n  }\n  return p;\n}\n\nSTATIC void GC_CALLBACK\nGC_default_is_valid_displacement_print_proc(void *p)\n{\n  ABORT_ARG1(\"GC_is_valid_displacement test failed\", \": %p not valid\", p);\n}\n\nGC_valid_ptr_print_proc_t GC_is_valid_displacement_print_proc\n    = GC_default_is_valid_displacement_print_proc;\n\nGC_API void *GC_CALL\nGC_is_valid_displacement(void *p)\n{\n  hdr *hhdr;\n  size_t offset;\n  struct hblk *h;\n  size_t sz;\n\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  if (NULL == p)\n    return NULL;\n  hhdr = HDR(p);\n  if (NULL == hhdr)\n    return p;\n  h = HBLKPTR(p);\n  if (GC_all_interior_pointers) {\n    h = GC_find_starting_hblk(h, &hhdr);\n  } else if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n    GC_is_valid_displacement_print_proc((ptr_t)p);\n    return p;\n  }\n  sz = hhdr->hb_sz;\n  offset = HBLKDISPL(p) % sz;\n  if ((sz > MAXOBJBYTES && ADDR_GE((ptr_t)p, (ptr_t)h + sz))\n      || !GC_valid_offsets[offset]\n      || (ADDR_LT((ptr_t)(h + 1), (ptr_t)p + sz - offset)\n          && !IS_FORWARDING_ADDR_OR_NIL(HDR(h + 1)))) {\n    GC_is_valid_displacement_print_proc((ptr_t)p);\n  }\n  return p;\n}\n\nSTATIC void GC_CALLBACK\nGC_default_is_visible_print_proc(void *p)\n{\n  ABORT_ARG1(\"GC_is_visible test failed\", \": %p not GC-visible\", p);\n}\n\nGC_valid_ptr_print_proc_t GC_is_visible_print_proc\n    = GC_default_is_visible_print_proc;\n\n#ifndef THREADS\n/* Could p be a stack address?        */\nSTATIC GC_bool\nGC_on_stack(ptr_t p)\n{\n  return HOTTER_THAN(p, GC_stackbottom) && !HOTTER_THAN(p, GC_approx_sp());\n}\n#endif /* !THREADS */\n\nGC_API void *GC_CALL\nGC_is_visible(void *p)\n{\n  const hdr *hhdr;\n\n  if ((ADDR(p) & (ALIGNMENT - 1)) != 0)\n    goto fail;\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n#ifdef THREADS\n  hhdr = HDR(p);\n  if (hhdr != NULL && NULL == GC_base(p)) {\n    goto fail;\n  } else {\n    /* May be inside thread stack.  We can't do much. */\n    return p;\n  }\n#else\n  /* Check stack first: */\n  if (GC_on_stack((ptr_t)p))\n    return p;\n\n  hhdr = HDR(p);\n  if (NULL == hhdr) {\n    if (GC_is_static_root((ptr_t)p))\n      return p;\n      /* Else do it again correctly:      */\n#  if defined(ANY_MSWIN) || defined(DYNAMIC_LOADING)\n    if (!GC_no_dls) {\n      GC_register_dynamic_libraries();\n      if (GC_is_static_root((ptr_t)p))\n        return p;\n    }\n#  endif\n    goto fail;\n  } else {\n    /* p points to the heap. */\n    word descr;\n    /* TODO: should GC_base be manually inlined? */\n    ptr_t base = (ptr_t)GC_base(p);\n\n    if (NULL == base)\n      goto fail;\n    if (HBLKPTR(base) != HBLKPTR(p))\n      hhdr = HDR(base);\n    descr = hhdr->hb_descr;\n  retry:\n    switch (descr & GC_DS_TAGS) {\n    case GC_DS_LENGTH:\n      if ((word)((ptr_t)p - base) >= descr)\n        goto fail;\n      break;\n    case GC_DS_BITMAP:\n      if ((ptr_t)p - base >= (ptrdiff_t)PTRS_TO_BYTES(BITMAP_BITS))\n        goto fail;\n#  if ALIGNMENT != CPP_PTRSZ / 8\n      if ((ADDR(p) & (sizeof(ptr_t) - 1)) != 0)\n        goto fail;\n#  endif\n      if (!(((word)1 << (CPP_WORDSZ - 1 - (word)((ptr_t)p - base))) & descr))\n        goto fail;\n      break;\n    case GC_DS_PROC:\n      /* We could try to decipher this partially.         */\n      /* For now we just punt.                            */\n      break;\n    case GC_DS_PER_OBJECT:\n      if (!(descr & SIGNB)) {\n        descr = *(word *)((ptr_t)base + (descr & ~(word)GC_DS_TAGS));\n      } else {\n        ptr_t type_descr = *(ptr_t *)base;\n\n        if (EXPECT(NULL == type_descr, FALSE)) {\n          /* See the comment in GC_mark_from.     */\n          goto fail;\n        }\n        descr = *(word *)(type_descr\n                          - ((GC_signed_word)descr\n                             + (GC_INDIR_PER_OBJ_BIAS - GC_DS_PER_OBJECT)));\n      }\n      goto retry;\n    }\n    return p;\n  }\n#endif\nfail:\n  GC_is_visible_print_proc((ptr_t)p);\n  return p;\n}\n\nGC_API void *GC_CALL\nGC_pre_incr(void **p, ptrdiff_t how_much)\n{\n  void *initial = *p;\n  void *result = GC_same_obj((ptr_t)initial + how_much, initial);\n\n  if (!GC_all_interior_pointers) {\n    (void)GC_is_valid_displacement(result);\n  }\n  *p = result;\n  return result; /* updated pointer */\n}\n\nGC_API void *GC_CALL\nGC_post_incr(void **p, ptrdiff_t how_much)\n{\n  void *initial = *p;\n  void *result = GC_same_obj((ptr_t)initial + how_much, initial);\n\n  if (!GC_all_interior_pointers) {\n    (void)GC_is_valid_displacement(result);\n  }\n  *p = result;\n  return initial; /* original *p */\n}\n\nGC_API void GC_CALL\nGC_set_same_obj_print_proc(GC_same_obj_print_proc_t fn)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fn));\n  GC_same_obj_print_proc = fn;\n}\n\nGC_API GC_same_obj_print_proc_t GC_CALL\nGC_get_same_obj_print_proc(void)\n{\n  return GC_same_obj_print_proc;\n}\n\nGC_API void GC_CALL\nGC_set_is_valid_displacement_print_proc(GC_valid_ptr_print_proc_t fn)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fn));\n  GC_is_valid_displacement_print_proc = fn;\n}\n\nGC_API GC_valid_ptr_print_proc_t GC_CALL\nGC_get_is_valid_displacement_print_proc(void)\n{\n  return GC_is_valid_displacement_print_proc;\n}\n\nGC_API void GC_CALL\nGC_set_is_visible_print_proc(GC_valid_ptr_print_proc_t fn)\n{\n  GC_ASSERT(NONNULL_ARG_NOT_NULL(fn));\n  GC_is_visible_print_proc = fn;\n}\n\nGC_API GC_valid_ptr_print_proc_t GC_CALL\nGC_get_is_visible_print_proc(void)\n{\n  return GC_is_visible_print_proc;\n}\n"
        },
        {
          "name": "reclaim.c",
          "type": "blob",
          "size": 25.755859375,
          "content": "/*\n * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n * Copyright (c) 1991-1996 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1999-2004 Hewlett-Packard Development Company, L.P.\n * Copyright (c) 2009-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#ifdef ENABLE_DISCLAIM\n#  include \"gc/gc_disclaim.h\"\n#endif\n\n/* Number of bytes of memory reclaimed minus the number of bytes        */\n/* originally on free lists which we had to drop.                       */\nGC_INNER GC_signed_word GC_bytes_found = 0;\n\n#if defined(PARALLEL_MARK)\n/* Number of threads currently building free lists without holding    */\n/* the allocator lock.  It is not safe to collect if this is nonzero. */\n/* Also, together with the mark lock, it is used as a semaphore       */\n/* during marker threads startup.                                     */\nGC_INNER GC_signed_word GC_fl_builder_count = 0;\n#endif /* PARALLEL_MARK */\n\n/* We defer printing of leaked objects until we're done with the GC     */\n/* cycle, since the routine for printing objects needs to run outside   */\n/* the collector, e.g. without the allocator lock.                      */\n\n#ifndef MAX_LEAKED\n#  define MAX_LEAKED 40\n#endif\nSTATIC ptr_t GC_leaked[MAX_LEAKED] = { NULL };\nSTATIC unsigned GC_n_leaked = 0;\n\n#ifdef AO_HAVE_store\nGC_INNER volatile AO_t GC_have_errors = 0;\n#else\nGC_INNER GC_bool GC_have_errors = FALSE;\n#endif\n\n#if !defined(EAGER_SWEEP) && defined(ENABLE_DISCLAIM)\nSTATIC void GC_reclaim_unconditionally_marked(void);\n#endif\n\nGC_INLINE void\nGC_add_leaked(ptr_t leaked)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n#ifndef SHORT_DBG_HDRS\n  if (GC_findleak_delay_free && !GC_check_leaked(leaked))\n    return;\n#endif\n\n  GC_SET_HAVE_ERRORS();\n  if (GC_n_leaked < MAX_LEAKED) {\n    GC_leaked[GC_n_leaked++] = leaked;\n    /* Make sure it is not reclaimed this cycle.      */\n    GC_set_mark_bit(leaked);\n  }\n}\n\n/* Print all objects on the list after printing any smashed objects.    */\n/* Clear both lists.  Called without the allocator lock held.           */\nGC_INNER void\nGC_print_all_errors(void)\n{\n  static GC_bool printing_errors = FALSE;\n  GC_bool have_errors;\n  unsigned i, n_leaked;\n  ptr_t leaked[MAX_LEAKED];\n\n  LOCK();\n  if (printing_errors) {\n    UNLOCK();\n    return;\n  }\n  have_errors = get_have_errors();\n  printing_errors = TRUE;\n  n_leaked = GC_n_leaked;\n  if (n_leaked > 0) {\n    GC_ASSERT(n_leaked <= MAX_LEAKED);\n    BCOPY(GC_leaked, leaked, n_leaked * sizeof(ptr_t));\n    GC_n_leaked = 0;\n    BZERO(GC_leaked, n_leaked * sizeof(ptr_t));\n  }\n  UNLOCK();\n\n  if (GC_debugging_started) {\n    GC_print_all_smashed();\n  } else {\n    have_errors = FALSE;\n  }\n\n  if (n_leaked > 0) {\n    GC_err_printf(\"Found %u leaked objects:\\n\", n_leaked);\n    have_errors = TRUE;\n  }\n  for (i = 0; i < n_leaked; i++) {\n    ptr_t p = leaked[i];\n#ifndef SKIP_LEAKED_OBJECTS_PRINTING\n    GC_print_heap_obj(p);\n#endif\n    GC_free(p);\n  }\n\n  if (have_errors\n#ifndef GC_ABORT_ON_LEAK\n      && GETENV(\"GC_ABORT_ON_LEAK\") != NULL\n#endif\n  ) {\n    ABORT(\"Leaked or smashed objects encountered\");\n  }\n\n  LOCK();\n  printing_errors = FALSE;\n  UNLOCK();\n}\n\n/* The reclaim phase.   */\n\n/* Test whether a block is completely empty, i.e. contains no marked    */\n/* objects.  This does not require the block to be in physical memory.  */\nGC_INNER GC_bool\nGC_block_empty(const hdr *hhdr)\n{\n  return 0 == hhdr->hb_n_marks;\n}\n\nSTATIC GC_bool\nGC_block_nearly_full(const hdr *hhdr, size_t sz)\n{\n  return hhdr->hb_n_marks > HBLK_OBJS(sz) * 7 / 8;\n}\n\n/* TODO: This should perhaps again be specialized for USE_MARK_BYTES    */\n/* and USE_MARK_BITS cases.                                             */\n\nGC_INLINE ptr_t\nGC_clear_block(ptr_t q, size_t sz, word *pcount)\n{\n  ptr_t *p = (ptr_t *)q;\n  ptr_t plim = q + sz;\n\n  /* Clear object, advance p to next object in the process.     */\n#ifdef USE_MARK_BYTES\n  GC_ASSERT((sz & 1) == 0);\n  GC_ASSERT((ADDR(p) & (2 * sizeof(ptr_t) - 1)) == 0);\n  p[1] = NULL; /* but do not clear link field */\n  for (p += 2; ADDR_LT((ptr_t)p, plim); p += 2) {\n    CLEAR_DOUBLE(p);\n  }\n#else\n  /* Skip link field. */\n  p++;\n\n  while (ADDR_LT((ptr_t)p, plim)) {\n    *p++ = NULL;\n  }\n#endif\n  *pcount += sz;\n  return (ptr_t)p;\n}\n\n/* Restore unmarked small objects in h of size sz (in bytes) to the     */\n/* object free list.  Returns the new list.  Clears unmarked objects.   */\nSTATIC ptr_t\nGC_reclaim_clear(struct hblk *hbp, const hdr *hhdr, size_t sz, ptr_t list,\n                 word *pcount)\n{\n  size_t bit_no;\n  ptr_t p, plim;\n\n  GC_ASSERT(hhdr == GC_find_header(hbp));\n#ifndef THREADS\n  GC_ASSERT(sz == hhdr->hb_sz);\n#else\n  /* Skip the assertion because of a potential race with GC_realloc. */\n#endif\n  GC_ASSERT((sz & (sizeof(ptr_t) - 1)) == 0);\n\n  /* Go through all objects in the block. */\n  p = hbp->hb_body;\n  plim = p + HBLKSIZE - sz;\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz)) {\n    if (mark_bit_from_hdr(hhdr, bit_no)) {\n      p += sz;\n    } else {\n      /* The object is available - put it on list. */\n      obj_link(p) = list;\n      list = p;\n      FREE_PROFILER_HOOK(p);\n      p = GC_clear_block(p, sz, pcount);\n    }\n  }\n  return list;\n}\n\n/* The same thing as GC_reclaim_clear, but do not clear objects.        */\nSTATIC ptr_t\nGC_reclaim_uninit(struct hblk *hbp, const hdr *hhdr, size_t sz, ptr_t list,\n                  word *pcount)\n{\n  size_t bit_no;\n  word n_bytes_found = 0;\n  ptr_t p, plim;\n\n#ifndef THREADS\n  GC_ASSERT(sz == hhdr->hb_sz);\n#endif\n\n  /* Go through all objects in the block. */\n  p = hbp->hb_body;\n  plim = (ptr_t)hbp + HBLKSIZE - sz;\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz), p += sz) {\n    if (!mark_bit_from_hdr(hhdr, bit_no)) {\n      n_bytes_found += sz;\n      /* The object is available - put it on list. */\n      obj_link(p) = list;\n      list = p;\n      FREE_PROFILER_HOOK(p);\n    }\n  }\n  *pcount += n_bytes_found;\n  return list;\n}\n\n#ifdef ENABLE_DISCLAIM\n/* Call reclaim notifier for block's kind on each unmarked object in  */\n/* block, all within a pair of corresponding enter/leave callbacks.   */\nSTATIC ptr_t\nGC_disclaim_and_reclaim(struct hblk *hbp, hdr *hhdr, size_t sz, ptr_t list,\n                        word *pcount)\n{\n  size_t bit_no;\n  ptr_t p, plim;\n  int(GC_CALLBACK * disclaim)(void *)\n      = GC_obj_kinds[hhdr->hb_obj_kind].ok_disclaim_proc;\n\n  GC_ASSERT(disclaim != 0);\n#  ifndef THREADS\n  GC_ASSERT(sz == hhdr->hb_sz);\n#  endif\n  p = hbp->hb_body;\n  plim = p + HBLKSIZE - sz;\n\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz)) {\n    if (mark_bit_from_hdr(hhdr, bit_no)) {\n      p += sz;\n    } else if (disclaim(p)) {\n      set_mark_bit_from_hdr(hhdr, bit_no);\n      INCR_MARKS(hhdr);\n      p += sz;\n    } else {\n      obj_link(p) = list;\n      list = p;\n      FREE_PROFILER_HOOK(p);\n      p = GC_clear_block(p, sz, pcount);\n    }\n  }\n  return list;\n}\n#endif /* ENABLE_DISCLAIM */\n\n/* Do not really reclaim objects, just check for unmarked ones.     */\nSTATIC void\nGC_reclaim_check(struct hblk *hbp, const hdr *hhdr, size_t sz)\n{\n  size_t bit_no;\n  ptr_t p, plim;\n\n#ifndef THREADS\n  GC_ASSERT(sz == hhdr->hb_sz);\n#endif\n  /* Go through all objects in the block. */\n  p = hbp->hb_body;\n  plim = p + HBLKSIZE - sz;\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz), p += sz) {\n    if (!mark_bit_from_hdr(hhdr, bit_no))\n      GC_add_leaked(p);\n  }\n}\n\n/* Is a pointer-free block?  Same as IS_PTRFREE() macro but uses    */\n/* unordered atomic access to avoid racing with GC_realloc.         */\n#ifdef AO_HAVE_load\n#  define IS_PTRFREE_SAFE(hhdr) (AO_load((AO_t *)&(hhdr)->hb_descr) == 0)\n#else\n/* No race as GC_realloc holds the allocator lock when updating hb_descr. */\n#  define IS_PTRFREE_SAFE(hhdr) IS_PTRFREE(hhdr)\n#endif\n\n/* Generic procedure to rebuild a free list in hbp.  Also called    */\n/* directly from GC_malloc_many.  sz is in bytes.                   */\nGC_INNER ptr_t\nGC_reclaim_generic(struct hblk *hbp, hdr *hhdr, size_t sz, GC_bool init,\n                   ptr_t list, word *pcount)\n{\n  ptr_t result;\n\n#ifndef PARALLEL_MARK\n  GC_ASSERT(I_HOLD_LOCK());\n#endif\n  GC_ASSERT(GC_find_header(hbp) == hhdr);\n#ifndef GC_DISABLE_INCREMENTAL\n  GC_remove_protection(hbp, 1, IS_PTRFREE_SAFE(hhdr));\n#endif\n#ifdef ENABLE_DISCLAIM\n  if ((hhdr->hb_flags & HAS_DISCLAIM) != 0) {\n    result = GC_disclaim_and_reclaim(hbp, hhdr, sz, list, pcount);\n  } else\n#endif\n  /* else */ {\n    if (init || GC_debugging_started) {\n      result = GC_reclaim_clear(hbp, hhdr, sz, list, pcount);\n    } else {\n#ifndef AO_HAVE_load\n      GC_ASSERT(IS_PTRFREE(hhdr));\n#endif\n      result = GC_reclaim_uninit(hbp, hhdr, sz, list, pcount);\n    }\n  }\n  if (IS_UNCOLLECTABLE(hhdr->hb_obj_kind))\n    GC_set_hdr_marks(hhdr);\n  return result;\n}\n\n/* Restore unmarked small objects in the block pointed to by hbp to the */\n/* appropriate object free list.  If entirely empty blocks are to be    */\n/* completely deallocated, then caller should perform that check.       */\nSTATIC void\nGC_reclaim_small_nonempty_block(struct hblk *hbp, size_t sz,\n                                GC_bool report_if_found)\n{\n  hdr *hhdr;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  hhdr = HDR(hbp);\n  hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n  if (report_if_found) {\n    GC_reclaim_check(hbp, hhdr, sz);\n  } else {\n    struct obj_kind *ok = &GC_obj_kinds[hhdr->hb_obj_kind];\n    void **flh = &ok->ok_freelist[BYTES_TO_GRANULES(sz)];\n\n    *flh = GC_reclaim_generic(hbp, hhdr, sz, ok->ok_init, (ptr_t)(*flh),\n                              (/* unsigned */ word *)&GC_bytes_found);\n  }\n}\n\n#ifdef ENABLE_DISCLAIM\nSTATIC void\nGC_disclaim_and_reclaim_or_free_small_block(struct hblk *hbp)\n{\n  hdr *hhdr;\n  size_t sz;\n  struct obj_kind *ok;\n  void **flh;\n  void *flh_next;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  hhdr = HDR(hbp);\n  sz = hhdr->hb_sz;\n  ok = &GC_obj_kinds[hhdr->hb_obj_kind];\n  flh = &ok->ok_freelist[BYTES_TO_GRANULES(sz)];\n\n  hhdr->hb_last_reclaimed = (unsigned short)GC_gc_no;\n  flh_next = GC_reclaim_generic(hbp, hhdr, sz, ok->ok_init, (ptr_t)(*flh),\n                                (/* unsigned */ word *)&GC_bytes_found);\n  if (hhdr->hb_n_marks) {\n    *flh = flh_next;\n  } else {\n    GC_ASSERT(hbp == hhdr->hb_block);\n    GC_bytes_found += (GC_signed_word)HBLKSIZE;\n    GC_freehblk(hbp);\n  }\n}\n#endif /* ENABLE_DISCLAIM */\n\n/* Restore an unmarked large object or an entirely empty blocks of      */\n/* small objects to the heap block free list.  Otherwise enqueue the    */\n/* block for later processing by GC_reclaim_small_nonempty_block.       */\n/* If report_if_found is TRUE, then process any block immediately, and  */\n/* simply report free objects; do not actually reclaim them.            */\nSTATIC void GC_CALLBACK\nGC_reclaim_block(struct hblk *hbp, void *report_if_found)\n{\n  hdr *hhdr;\n  size_t sz; /* size of objects in current block */\n  struct obj_kind *ok;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#if defined(CPPCHECK)\n  GC_noop1_ptr(report_if_found);\n#endif\n  hhdr = HDR(hbp);\n  ok = &GC_obj_kinds[hhdr->hb_obj_kind];\n#ifdef AO_HAVE_load\n  /* Atomic access is used to avoid racing with GC_realloc.       */\n  sz = AO_load(&hhdr->hb_sz);\n#else\n  /* No race as GC_realloc holds the allocator lock while */\n  /* updating hb_sz.                                      */\n  sz = hhdr->hb_sz;\n#endif\n  if (sz > MAXOBJBYTES) {\n    /* The case of 1 big object.    */\n    if (!mark_bit_from_hdr(hhdr, 0)) {\n      if (report_if_found) {\n        GC_ASSERT(hbp == hhdr->hb_block);\n        GC_add_leaked((ptr_t)hbp);\n      } else {\n#ifdef ENABLE_DISCLAIM\n        if (EXPECT(hhdr->hb_flags & HAS_DISCLAIM, 0)) {\n          if (ok->ok_disclaim_proc(hbp)) {\n            /* Not disclaimed, thus resurrect the object.   */\n            set_mark_bit_from_hdr(hhdr, 0);\n            goto in_use;\n          }\n        }\n#endif\n        GC_ASSERT(hbp == hhdr->hb_block);\n        if (sz > HBLKSIZE) {\n          GC_large_allocd_bytes -= HBLKSIZE * OBJ_SZ_TO_BLOCKS(sz);\n        }\n        GC_bytes_found += (GC_signed_word)sz;\n        GC_freehblk(hbp);\n        FREE_PROFILER_HOOK(hbp);\n      }\n    } else {\n#ifdef ENABLE_DISCLAIM\n    in_use:\n#endif\n      if (IS_PTRFREE_SAFE(hhdr)) {\n        GC_atomic_in_use += sz;\n      } else {\n        GC_composite_in_use += sz;\n      }\n    }\n  } else {\n    GC_bool empty = GC_block_empty(hhdr);\n\n#ifdef PARALLEL_MARK\n    /* Count can be low or one too high because we sometimes      */\n    /* have to ignore decrements.  Objects can also potentially   */\n    /* be repeatedly marked by each marker.                       */\n    /* Here we assume 3 markers at most, but this is extremely    */\n    /* unlikely to fail spuriously with more.  And if it does, it */\n    /* should be looked at.                                       */\n    GC_ASSERT(sz != 0\n              && (GC_markers_m1 > 1 ? 3 : GC_markers_m1 + 1)\n                             * (HBLKSIZE / sz + 1)\n                         + 16\n                     >= hhdr->hb_n_marks);\n#else\n    GC_ASSERT(sz * hhdr->hb_n_marks <= HBLKSIZE);\n#endif\n#ifdef VALGRIND_TRACKING\n    /* Call GC_free_profiler_hook() on freed objects so that  */\n    /* a profiling tool could track the allocations.          */\n    {\n      ptr_t p = hbp->hb_body;\n      ptr_t plim = p + HBLKSIZE - sz;\n      size_t bit_no;\n\n      for (bit_no = 0; ADDR_GE(plim, p);\n           bit_no += MARK_BIT_OFFSET(sz), p += sz) {\n        if (!mark_bit_from_hdr(hhdr, bit_no))\n          FREE_PROFILER_HOOK(p);\n      }\n    }\n#endif\n    GC_ASSERT(hbp == hhdr->hb_block);\n    if (report_if_found) {\n      GC_reclaim_small_nonempty_block(hbp, sz, TRUE /* report_if_found */);\n    } else if (empty) {\n#ifdef ENABLE_DISCLAIM\n      if ((hhdr->hb_flags & HAS_DISCLAIM) != 0) {\n        GC_disclaim_and_reclaim_or_free_small_block(hbp);\n      } else\n#endif\n      /* else */ {\n        GC_bytes_found += (GC_signed_word)HBLKSIZE;\n        GC_freehblk(hbp);\n        FREE_PROFILER_HOOK(hbp);\n      }\n    } else if (GC_find_leak || !GC_block_nearly_full(hhdr, sz)) {\n      /* Group of smaller objects, enqueue the real work.   */\n      struct hblk **rlh = ok->ok_reclaim_list;\n\n      if (rlh != NULL) {\n        rlh += BYTES_TO_GRANULES(sz);\n        hhdr->hb_next = *rlh;\n        *rlh = hbp;\n      }\n    } else {\n      /* Not worth salvaging.       */\n    }\n    /* We used to do the nearly_full check later, but we    */\n    /* already have the right cache context here.  Also     */\n    /* doing it here avoids some silly lock contention in   */\n    /* GC_malloc_many.                                      */\n    if (IS_PTRFREE_SAFE(hhdr)) {\n      GC_atomic_in_use += (word)sz * hhdr->hb_n_marks;\n    } else {\n      GC_composite_in_use += (word)sz * hhdr->hb_n_marks;\n    }\n  }\n}\n\n#if !defined(NO_DEBUGGING)\n/* Routines to gather and print heap block info intended for      */\n/* debugging.  Otherwise should be called with the allocator lock */\n/* held.                                                          */\n\nstruct Print_stats {\n  size_t number_of_blocks;\n  size_t total_bytes;\n};\n\nEXTERN_C_BEGIN /* to avoid \"no previous prototype\" clang warning */\n    unsigned\n    GC_n_set_marks(const hdr *);\nEXTERN_C_END\n\n#  ifdef USE_MARK_BYTES\n/* Return the number of set mark bits in the given header.      */\n/* Remains externally visible as used by GNU GCJ currently.     */\n/* There could be a race between GC_clear_hdr_marks and this    */\n/* function but the latter is for a debug purpose.              */\nGC_ATTR_NO_SANITIZE_THREAD\nunsigned\nGC_n_set_marks(const hdr *hhdr)\n{\n  unsigned result = 0;\n  size_t i;\n  size_t offset = MARK_BIT_OFFSET(hhdr->hb_sz);\n  size_t limit = FINAL_MARK_BIT(hhdr->hb_sz);\n\n  for (i = 0; i < limit; i += offset) {\n    result += (unsigned)hhdr->hb_marks[i];\n  }\n\n  /* The one should be set past the end.    */\n  GC_ASSERT(hhdr->hb_marks[limit]);\n  return result;\n}\n\n#  else\n/* Number of set bits in a word.  Not performance critical.     */\nstatic unsigned\ncount_ones(word v)\n{\n  unsigned result = 0;\n\n  for (; v > 0; v >>= 1) {\n    if (v & 1)\n      result++;\n  }\n  return result;\n}\n\nunsigned\nGC_n_set_marks(const hdr *hhdr)\n{\n  unsigned result = 0;\n  size_t i;\n#    ifdef MARK_BIT_PER_OBJ\n  size_t n_objs = HBLK_OBJS(hhdr->hb_sz);\n  size_t n_mark_words = divWORDSZ(n_objs > 0 ? n_objs : 1); /* round down */\n\n  for (i = 0; i <= n_mark_words; i++) {\n    result += count_ones(hhdr->hb_marks[i]);\n  }\n#    else\n\n  for (i = 0; i < HB_MARKS_SZ; i++) {\n    result += count_ones(hhdr->hb_marks[i]);\n  }\n#    endif\n  GC_ASSERT(result > 0);\n  /* Exclude the one bit set past the end.  */\n  result--;\n\n#    ifndef MARK_BIT_PER_OBJ\n  if (IS_UNCOLLECTABLE(hhdr->hb_obj_kind)) {\n    size_t lg = BYTES_TO_GRANULES(hhdr->hb_sz);\n\n    /* As mentioned in GC_set_hdr_marks(), all the bits are set   */\n    /* instead of every n-th, thus the result should be adjusted. */\n    GC_ASSERT((unsigned)lg != 0 && result % lg == 0);\n    result /= (unsigned)lg;\n  }\n#    endif\n  return result;\n}\n#  endif /* !USE_MARK_BYTES  */\n\nGC_API unsigned GC_CALL\nGC_count_set_marks_in_hblk(const void *p)\n{\n  return GC_n_set_marks(HDR(p));\n}\n\nSTATIC void GC_CALLBACK\nGC_print_block_descr(struct hblk *h, void *raw_ps)\n{\n  const hdr *hhdr = HDR(h);\n  size_t sz = hhdr->hb_sz;\n  struct Print_stats *ps = (struct Print_stats *)raw_ps;\n  size_t n_marks = (size_t)GC_n_set_marks(hhdr);\n  size_t n_objs = HBLK_OBJS(sz);\n\n#  ifndef PARALLEL_MARK\n  GC_ASSERT(hhdr->hb_n_marks == n_marks);\n#  endif\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(h);\n#  endif\n  GC_ASSERT((n_objs > 0 ? n_objs : 1) >= n_marks);\n  GC_printf(\"%u,%u,%u,%u\\n\", hhdr->hb_obj_kind, (unsigned)sz,\n            (unsigned)n_marks, (unsigned)n_objs);\n  ps->number_of_blocks++;\n  ps->total_bytes += (sz + HBLKSIZE - 1) & ~(HBLKSIZE - 1); /* round up */\n}\n\nvoid\nGC_print_block_list(void)\n{\n  struct Print_stats pstats;\n\n  GC_printf(\"kind(0=ptrfree/1=normal/2=unc.),\"\n            \"obj_sz,#marks_set,#objs_in_block\\n\");\n  BZERO(&pstats, sizeof(pstats));\n  GC_apply_to_all_blocks(GC_print_block_descr, &pstats);\n  GC_printf(\"blocks= %lu, total_bytes= %lu\\n\",\n            (unsigned long)pstats.number_of_blocks,\n            (unsigned long)pstats.total_bytes);\n  if (pstats.total_bytes + GC_large_free_bytes != GC_heapsize)\n    GC_err_printf(\"LOST SOME BLOCKS!! Total bytes should be: %lu\\n\",\n                  (unsigned long)(GC_heapsize - GC_large_free_bytes));\n}\n\nGC_API void GC_CALL\nGC_print_free_list(int k, size_t lg)\n{\n  void *flh_next;\n  int n;\n\n  GC_ASSERT(k < MAXOBJKINDS);\n  GC_ASSERT(lg <= MAXOBJGRANULES);\n  flh_next = GC_obj_kinds[k].ok_freelist[lg];\n  for (n = 0; flh_next != NULL; n++) {\n    GC_printf(\"Free object in heap block %p [%d]: %p\\n\",\n              (void *)HBLKPTR(flh_next), n, flh_next);\n    flh_next = obj_link(flh_next);\n  }\n}\n#endif /* !NO_DEBUGGING */\n\n/* Clear all obj_link pointers in the list of free objects *flp.        */\n/* Clear *flp.  This must be done before dropping a list of free        */\n/* gcj-style objects, since may otherwise end up with dangling          */\n/* \"descriptor\" pointers.  It may help for other pointer-containing     */\n/* objects.                                                             */\nSTATIC void\nGC_clear_fl_links(void **flp)\n{\n  void *next;\n\n  for (next = *flp; next != NULL; next = *flp) {\n    *flp = NULL;\n    flp = &obj_link(next);\n  }\n}\n\n/* Perform GC_reclaim_block on the entire heap, after first clearing    */\n/* small-object free lists (if we are not just looking for leaks).      */\nGC_INNER void\nGC_start_reclaim(GC_bool report_if_found)\n{\n  int k;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#if defined(PARALLEL_MARK)\n  GC_ASSERT(0 == GC_fl_builder_count);\n#endif\n  /* Reset in-use counters.  GC_reclaim_block recomputes them. */\n  GC_composite_in_use = 0;\n  GC_atomic_in_use = 0;\n\n  /* Clear reclaim- and free-lists.   */\n  for (k = 0; k < (int)GC_n_kinds; k++) {\n    struct hblk **rlist = GC_obj_kinds[k].ok_reclaim_list;\n    GC_bool should_clobber = GC_obj_kinds[k].ok_descriptor != 0;\n\n    if (NULL == rlist) {\n      /* Means this object kind is not used.        */\n      continue;\n    }\n\n    if (!report_if_found) {\n      void **fop;\n      void **lim = &GC_obj_kinds[k].ok_freelist[MAXOBJGRANULES + 1];\n\n      for (fop = GC_obj_kinds[k].ok_freelist; ADDR_LT((ptr_t)fop, (ptr_t)lim);\n           fop++) {\n        if (*fop != NULL) {\n          if (should_clobber) {\n            GC_clear_fl_links(fop);\n          } else {\n            *fop = NULL;\n          }\n        }\n      }\n    } else {\n      /* Free-list objects are marked, and it is safe to leave them. */\n    }\n    BZERO(rlist, (MAXOBJGRANULES + 1) * sizeof(void *));\n  }\n\n  /* Go through all heap blocks (in hblklist) and reclaim unmarked    */\n  /* objects or enqueue the block for later processing.               */\n  GC_apply_to_all_blocks(GC_reclaim_block, NUMERIC_TO_VPTR(report_if_found));\n\n#ifdef EAGER_SWEEP\n  /* This is a very stupid thing to do.  We make it possible anyway,  */\n  /* so that you can convince yourself that it really is very stupid. */\n  GC_reclaim_all((GC_stop_func)0, FALSE);\n#elif defined(ENABLE_DISCLAIM)\n  /* However, make sure to clear reclaimable objects of kinds with    */\n  /* unconditional marking enabled before we do any significant       */\n  /* marking work.                                                    */\n  GC_reclaim_unconditionally_marked();\n#endif\n#if defined(PARALLEL_MARK)\n  GC_ASSERT(0 == GC_fl_builder_count);\n#endif\n}\n\nGC_INNER void\nGC_continue_reclaim(size_t lg, int k)\n{\n  struct hblk *hbp;\n  struct obj_kind *ok = &GC_obj_kinds[k];\n  struct hblk **rlh = ok->ok_reclaim_list;\n  void **flh;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (NULL == rlh) {\n    /* No blocks of this kind.  */\n    return;\n  }\n\n  flh = &ok->ok_freelist[lg];\n  for (rlh += lg; (hbp = *rlh) != NULL;) {\n    const hdr *hhdr = HDR(hbp);\n\n    *rlh = hhdr->hb_next;\n    GC_reclaim_small_nonempty_block(hbp, hhdr->hb_sz, FALSE);\n    if (*flh != NULL) {\n      /* The appropriate free list is nonempty.   */\n      break;\n    }\n  }\n}\n\n/* Reclaim all small blocks waiting to be reclaimed.  Abort and return  */\n/* false when/if (*stop_func)() returns true.  If this returns true,    */\n/* then it is safe to restart the world with incorrectly cleared mark   */\n/* bits.  If ignore_old is true, then reclaim only blocks that have     */\n/* been recently reclaimed, and discard the rest.  stop_func may be 0.  */\nGC_INNER GC_bool\nGC_reclaim_all(GC_stop_func stop_func, GC_bool ignore_old)\n{\n  size_t lg;\n  int k;\n  const hdr *hhdr;\n  struct hblk *hbp;\n  struct hblk **rlp;\n  struct hblk **rlh;\n#ifndef NO_CLOCK\n  CLOCK_TYPE start_time = CLOCK_TYPE_INITIALIZER;\n\n  if (GC_print_stats == VERBOSE)\n    GET_TIME(start_time);\n#endif\n  GC_ASSERT(I_HOLD_LOCK());\n\n  for (k = 0; k < (int)GC_n_kinds; k++) {\n    rlp = GC_obj_kinds[k].ok_reclaim_list;\n    if (NULL == rlp)\n      continue;\n\n    for (lg = 1; lg <= MAXOBJGRANULES; lg++) {\n      for (rlh = rlp + lg; (hbp = *rlh) != NULL;) {\n        if (stop_func != (GC_stop_func)0 && (*stop_func)()) {\n          return FALSE;\n        }\n        hhdr = HDR(hbp);\n        *rlh = hhdr->hb_next;\n        if (!ignore_old || (word)hhdr->hb_last_reclaimed == GC_gc_no - 1) {\n          /* It is likely we will need it this time, too.     */\n          /* It has been touched recently, so this should not */\n          /* trigger paging.                                  */\n          GC_reclaim_small_nonempty_block(hbp, hhdr->hb_sz, FALSE);\n        }\n      }\n    }\n  }\n#ifndef NO_CLOCK\n  if (GC_print_stats == VERBOSE) {\n    CLOCK_TYPE done_time;\n\n    GET_TIME(done_time);\n    GC_verbose_log_printf(\"Disposing of reclaim lists took %lu ms %lu ns\\n\",\n                          MS_TIME_DIFF(done_time, start_time),\n                          NS_FRAC_TIME_DIFF(done_time, start_time));\n  }\n#endif\n  return TRUE;\n}\n\n#if !defined(EAGER_SWEEP) && defined(ENABLE_DISCLAIM)\n/* We do an eager sweep on heap blocks where unconditional marking has  */\n/* been enabled, so that any reclaimable objects have been reclaimed    */\n/* before we start marking.  This is a simplified GC_reclaim_all        */\n/* restricted to kinds where ok_mark_unconditionally is true.           */\nSTATIC void\nGC_reclaim_unconditionally_marked(void)\n{\n  int k;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  for (k = 0; k < (int)GC_n_kinds; k++) {\n    size_t lg;\n    struct obj_kind *ok = &GC_obj_kinds[k];\n    struct hblk **rlp = ok->ok_reclaim_list;\n\n    if (NULL == rlp || !ok->ok_mark_unconditionally)\n      continue;\n\n    for (lg = 1; lg <= MAXOBJGRANULES; lg++) {\n      struct hblk **rlh = rlp + lg;\n      struct hblk *hbp;\n\n      while ((hbp = *rlh) != NULL) {\n        const hdr *hhdr = HDR(hbp);\n\n        *rlh = hhdr->hb_next;\n        GC_reclaim_small_nonempty_block(hbp, hhdr->hb_sz, FALSE);\n      }\n    }\n  }\n}\n#endif /* !EAGER_SWEEP && ENABLE_DISCLAIM */\n\nstruct enumerate_reachable_s {\n  GC_reachable_object_proc proc;\n  void *client_data;\n};\n\nSTATIC void GC_CALLBACK\nGC_do_enumerate_reachable_objects(struct hblk *hbp, void *ed_ptr)\n{\n  const hdr *hhdr = HDR(hbp);\n  ptr_t p, plim;\n  const struct enumerate_reachable_s *ped\n      = (struct enumerate_reachable_s *)ed_ptr;\n  size_t sz = hhdr->hb_sz;\n  size_t bit_no;\n\n  if (GC_block_empty(hhdr))\n    return;\n\n  p = hbp->hb_body;\n  if (sz > MAXOBJBYTES) {\n    /* The case of 1 big object.        */\n    plim = p;\n  } else {\n    plim = p + HBLKSIZE - sz;\n  }\n  /* Go through all objects in the block. */\n  for (bit_no = 0; ADDR_GE(plim, p); bit_no += MARK_BIT_OFFSET(sz), p += sz) {\n    if (mark_bit_from_hdr(hhdr, bit_no)) {\n      ped->proc(p, sz, ped->client_data);\n    }\n  }\n}\n\nGC_API void GC_CALL\nGC_enumerate_reachable_objects_inner(GC_reachable_object_proc proc,\n                                     void *client_data)\n{\n  struct enumerate_reachable_s ed;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  ed.proc = proc;\n  ed.client_data = client_data;\n  GC_apply_to_all_blocks(GC_do_enumerate_reachable_objects, &ed);\n}\n"
        },
        {
          "name": "sparc_mach_dep.S",
          "type": "blob",
          "size": 1.876953125,
          "content": "!\tSPARCompiler 3.0 and later apparently no longer handles\n!\tasm outside functions.  So we need a separate .s file\n!\tThis is only set up for SunOS 5, not SunOS 4.\n!\tAssumes this is called before the stack contents are\n!\texamined.\n\n\t.seg \t\"text\"\n\t.globl\tGC_save_regs_in_stack\nGC_save_regs_in_stack:\n#if defined(__arch64__) || defined(__sparcv9)\n\tsave\t%sp,-128,%sp\n\tflushw\n\tret\n\t  restore %sp,2047+128,%o0\n#else /* 32 bit SPARC */\n\tta\t0x3   ! ST_FLUSH_WINDOWS\n\tmov\t%sp,%o0\n\tretl\n\tnop\n#endif /* 32 bit SPARC */\n.GC_save_regs_in_stack_end:\n\t.size GC_save_regs_in_stack,.GC_save_regs_in_stack_end-GC_save_regs_in_stack\n\n! GC_clear_stack_inner(arg, limit) clears stack area up to limit and\n! returns arg.  Stack clearing is crucial on SPARC, so we supply\n! an assembly version that s more careful.  Assumes limit is hotter\n! than sp, and limit is 8 byte aligned.\n\t.globl\tGC_clear_stack_inner\nGC_clear_stack_inner:\n#if defined(__arch64__) || defined(__sparcv9)\n\tmov %sp,%o2\t\t! Save sp\n\tadd %sp,2047-8,%o3\t! p = sp+bias-8\n\tadd %o1,-2047-192,%sp\t! Move sp out of the way,\n  \t\t\t\t! so that traps still work.\n  \t\t\t\t! Includes some extra words\n  \t\t\t\t! so we can be sloppy below.\nloop:\n\tstx %g0,[%o3]\t\t! *(long *)p = 0\n\tcmp %o3,%o1\n\tbgu,pt %xcc, loop\t! if (p > limit) goto loop\n          add %o3,-8,%o3\t! p -= 8 (delay slot)\n\tretl\n    \t  mov %o2,%sp\t\t! Restore sp., delay slot\n#else  /* 32 bit SPARC */\n\tmov\t%sp,%o2\t\t! Save sp\n\tadd\t%sp,-8,%o3\t! p = sp-8\n\tclr\t%g1\t\t! [g0,g1] = 0\n\tadd\t%o1,-0x60,%sp\t! Move sp out of the way,\n\t\t\t\t! so that traps still work.\n\t\t\t\t! Includes some extra words\n\t\t\t\t! so we can be sloppy below.\nloop:\n\tstd\t%g0,[%o3]\t! *(long long *)p = 0\n\tcmp\t%o3,%o1\n\tbgu\tloop\t\t! if (p > limit) goto loop\n\t  add\t%o3,-8,%o3\t! p -= 8 (delay slot)\n\tretl\n\t  mov\t%o2,%sp\t\t! Restore sp., delay slot\n#endif  /* 32 bit SPARC */\n.GC_clear_stack_inner_end:\n      \t.size GC_clear_stack_inner,.GC_clear_stack_inner_end-GC_clear_stack_inner\n"
        },
        {
          "name": "sparc_netbsd_mach_dep.s",
          "type": "blob",
          "size": 0.830078125,
          "content": "!\tSPARCompiler 3.0 and later apparently no longer handles\n!\tasm outside functions.  So we need a separate .s file\n!\tThis is only set up for SunOS 4.\n!\tAssumes this is called before the stack contents are\n!\texamined.\n\n#include \"machine/asm.h\"\n\n\t.seg \t\"text\"\n\t.globl\t_C_LABEL(GC_save_regs_in_stack)\n_C_LABEL(GC_save_regs_in_stack):\n\tta\t0x3   ! ST_FLUSH_WINDOWS\n\tmov\t%sp,%o0\n\tretl\n\tnop\n\n\t.globl\t_C_LABEL(GC_clear_stack_inner)\n_C_LABEL(GC_clear_stack_inner):\n\tmov\t%sp,%o2\t\t! Save sp\n\tadd\t%sp,-8,%o3\t! p = sp-8\n\tclr\t%g1\t\t! [g0,g1] = 0\n\tadd\t%o1,-0x60,%sp\t! Move sp out of the way,\n\t\t\t\t! so that traps still work.\n\t\t\t\t! Includes some extra words\n\t\t\t\t! so we can be sloppy below.\nloop:\n\tstd\t%g0,[%o3]\t! *(long long *)p = 0\n\tcmp\t%o3,%o1\n\tbgu\tloop\t\t! if (p > limit) goto loop\n\tadd\t%o3,-8,%o3\t! p -= 8 (delay slot)\n\tretl\n\tmov\t%o2,%sp\t\t! Restore sp., delay slot\n"
        },
        {
          "name": "specific.c",
          "type": "blob",
          "size": 7.4775390625,
          "content": "/*\n * Copyright (c) 2000 by Hewlett-Packard Company.  All rights reserved.\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n/* To determine type of tsd implementation; includes private/specific.h */\n/* if needed.                                                           */\n#include \"private/thread_local_alloc.h\"\n\n#if defined(USE_CUSTOM_SPECIFIC)\n\n/* A thread-specific data entry which will never appear valid to a      */\n/* reader.  Used to fill in empty cache entries to avoid a check for 0. */\nstatic const tse invalid_tse = { INVALID_QTID, 0, 0, INVALID_THREADID };\n\nGC_INNER int\nGC_key_create_inner(tsd **key_ptr)\n{\n  int i;\n  int ret;\n  tsd *result;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* A quick alignment check, since we need atomic stores.    */\n  GC_ASSERT(ADDR(&invalid_tse.next) % ALIGNMENT == 0);\n  result = (tsd *)MALLOC_CLEAR(sizeof(tsd));\n  if (NULL == result)\n    return ENOMEM;\n  ret = pthread_mutex_init(&result->lock, NULL);\n  if (ret != 0)\n    return ret;\n\n  for (i = 0; i < TS_CACHE_SIZE; ++i) {\n    result->cache[i] = (tse *)GC_CAST_AWAY_CONST_PVOID(&invalid_tse);\n  }\n#  ifdef GC_ASSERTIONS\n  for (i = 0; i < TS_HASH_SIZE; ++i) {\n    GC_ASSERT(NULL == result->hash[i]);\n  }\n#  endif\n  *key_ptr = result;\n  return 0;\n}\n\n/* Set the thread-local value associated with the key.  Should not  */\n/* be used to overwrite a previously set value.                     */\nGC_INNER int\nGC_setspecific(tsd *key, void *value)\n{\n  pthread_t self = pthread_self();\n  unsigned hash_val = TS_HASH(self);\n  volatile tse *entry;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(self != INVALID_THREADID);\n  /* Disable GC during malloc.        */\n  GC_dont_gc++;\n  entry = (volatile tse *)MALLOC_CLEAR(sizeof(tse));\n  GC_dont_gc--;\n  if (EXPECT(NULL == entry, FALSE))\n    return ENOMEM;\n\n  pthread_mutex_lock(&key->lock);\n  entry->next = key->hash[hash_val];\n#  ifdef GC_ASSERTIONS\n  {\n    tse *p;\n\n    /* Ensure no existing entry.    */\n    for (p = entry->next; p != NULL; p = p->next) {\n      GC_ASSERT(!THREAD_EQUAL(p->thread, self));\n    }\n  }\n#  endif\n  entry->thread = self;\n  entry->value = TS_HIDE_VALUE(value);\n  GC_ASSERT(entry->qtid == INVALID_QTID);\n  /* There can only be one writer at a time, but this needs to be     */\n  /* atomic with respect to concurrent readers.                       */\n  GC_cptr_store_release((volatile ptr_t *)&key->hash[hash_val],\n                        (ptr_t)CAST_AWAY_VOLATILE_PVOID(entry));\n  GC_dirty(CAST_AWAY_VOLATILE_PVOID(entry));\n  GC_dirty(key->hash + hash_val);\n  if (pthread_mutex_unlock(&key->lock) != 0)\n    ABORT(\"pthread_mutex_unlock failed (setspecific)\");\n  return 0;\n}\n\n/* Remove thread-specific data for a given thread.  This function is    */\n/* called at fork from the child process for all threads except for the */\n/* survived one.  GC_remove_specific() should be called on thread exit. */\nGC_INNER void\nGC_remove_specific_after_fork(tsd *key, pthread_t t)\n{\n  unsigned hash_val = TS_HASH(t);\n  tse *entry;\n  tse *prev = NULL;\n\n#  ifdef CAN_HANDLE_FORK\n  /* Both GC_setspecific and GC_remove_specific should be called    */\n  /* with the allocator lock held to ensure the consistency of      */\n  /* the hash table in the forked child.                            */\n  GC_ASSERT(I_HOLD_LOCK());\n#  endif\n  pthread_mutex_lock(&key->lock);\n  for (entry = key->hash[hash_val];\n       entry != NULL && !THREAD_EQUAL(entry->thread, t); entry = entry->next) {\n    prev = entry;\n  }\n  /* Invalidate qtid field, since qtids may be reused, and a later    */\n  /* cache lookup could otherwise find this entry.                    */\n  if (entry != NULL) {\n    entry->qtid = INVALID_QTID;\n    if (NULL == prev) {\n      key->hash[hash_val] = entry->next;\n      GC_dirty(key->hash + hash_val);\n    } else {\n      prev->next = entry->next;\n      GC_dirty(prev);\n    }\n    /* Atomic! Concurrent accesses still work.  They must, since      */\n    /* readers do not lock.  We should not need a volatile access     */\n    /* here, since both this and the preceding write should become    */\n    /* visible no later than the pthread_mutex_unlock() call.         */\n  }\n  /* If we wanted to deallocate the entry, we'd first have to clear   */\n  /* any cache entries pointing to it.  That probably requires        */\n  /* additional synchronization, since we can't prevent a concurrent  */\n  /* cache lookup, which should still be examining deallocated memory.*/\n  /* This can only happen if the concurrent access is from another    */\n  /* thread, and hence has missed the cache, but still...             */\n#  ifdef LINT2\n  GC_noop1_ptr(entry);\n#  endif\n\n  /* With GC, we're done, since the pointers from the cache will      */\n  /* be overwritten, all local pointers to the entries will be        */\n  /* dropped, and the entry will then be reclaimed.                   */\n  if (pthread_mutex_unlock(&key->lock) != 0)\n    ABORT(\"pthread_mutex_unlock failed (remove_specific after fork)\");\n}\n\n#  ifdef CAN_HANDLE_FORK\nGC_INNER void\nGC_update_specific_after_fork(tsd *key)\n{\n  unsigned hash_val = TS_HASH(GC_parent_pthread_self);\n  tse *entry;\n\n  GC_ASSERT(I_HOLD_LOCK());\n#    ifdef LINT2\n  pthread_mutex_lock(&key->lock);\n#    endif\n  entry = key->hash[hash_val];\n  if (EXPECT(entry != NULL, TRUE)) {\n    GC_ASSERT(THREAD_EQUAL(entry->thread, GC_parent_pthread_self));\n    GC_ASSERT(NULL == entry->next);\n    /* Remove the entry from the table. */\n    key->hash[hash_val] = NULL;\n    entry->thread = pthread_self();\n    /* Then put the entry back to the table (based on new hash value). */\n    key->hash[TS_HASH(entry->thread)] = entry;\n  }\n#    ifdef LINT2\n  (void)pthread_mutex_unlock(&key->lock);\n#    endif\n}\n#  endif\n\n/* Note that even the slow path doesn't lock.   */\nGC_INNER void *\nGC_slow_getspecific(tsd *key, size_t qtid, tse *volatile *cache_ptr)\n{\n  pthread_t self = pthread_self();\n  tse *entry = key->hash[TS_HASH(self)];\n\n  GC_ASSERT(qtid != INVALID_QTID);\n  while (entry != NULL && !THREAD_EQUAL(entry->thread, self)) {\n    entry = entry->next;\n  }\n  if (entry == NULL)\n    return NULL;\n  /* Set the cache entry.  It is safe to do this asynchronously.      */\n  /* Either value is safe, though may produce spurious misses.        */\n  /* We are replacing one qtid with another one for the same thread.  */\n  AO_store(&entry->qtid, qtid);\n\n  GC_cptr_store((volatile ptr_t *)cache_ptr, (ptr_t)entry);\n  return TS_REVEAL_PTR(entry->value);\n}\n\n#  ifdef GC_ASSERTIONS\n/* Check that that all elements of the data structure associated  */\n/* with key are marked.                                           */\nvoid\nGC_check_tsd_marks(tsd *key)\n{\n  int i;\n  tse *p;\n\n  if (!GC_is_marked(GC_base(key))) {\n    ABORT(\"Unmarked thread-specific-data table\");\n  }\n  for (i = 0; i < TS_HASH_SIZE; ++i) {\n    for (p = key->hash[i]; p != NULL; p = p->next) {\n      if (!GC_is_marked(GC_base(p))) {\n        ABORT_ARG1(\"Unmarked thread-specific-data entry\", \" at %p\", (void *)p);\n      }\n    }\n  }\n  for (i = 0; i < TS_CACHE_SIZE; ++i) {\n    p = key->cache[i];\n    if (p != &invalid_tse && !GC_is_marked(GC_base(p))) {\n      ABORT_ARG1(\"Unmarked cached thread-specific-data entry\", \" at %p\",\n                 (void *)p);\n    }\n  }\n}\n#  endif /* GC_ASSERTIONS */\n\n#endif /* USE_CUSTOM_SPECIFIC */\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "thread_local_alloc.c",
          "type": "blob",
          "size": 10.423828125,
          "content": "/*\n * Copyright (c) 2000-2005 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_priv.h\"\n\n#if defined(THREAD_LOCAL_ALLOC)\n\n#  if !defined(THREADS) && !defined(CPPCHECK)\n#    error Invalid config - THREAD_LOCAL_ALLOC requires GC_THREADS\n#  endif\n\n#  include \"private/thread_local_alloc.h\"\n\n#  if defined(USE_COMPILER_TLS)\n__thread GC_ATTR_TLS_FAST\n#  elif defined(USE_WIN32_COMPILER_TLS)\n__declspec(thread) GC_ATTR_TLS_FAST\n#  endif\n    GC_key_t GC_thread_key;\n\nstatic GC_bool keys_initialized;\n\n/* Return a single nonempty free list fl to the global one pointed to   */\n/* by gfl.                                                              */\nstatic void\nreturn_single_freelist(void *fl, void **gfl)\n{\n  if (NULL == *gfl) {\n    *gfl = fl;\n  } else {\n    void *q = fl;\n    void **qptr;\n\n    GC_ASSERT(GC_size(fl) == GC_size(*gfl));\n    /* Concatenate: */\n    do {\n      qptr = &obj_link(q);\n      q = *qptr;\n    } while (ADDR(q) >= HBLKSIZE);\n    GC_ASSERT(NULL == q);\n    *qptr = *gfl;\n    *gfl = fl;\n  }\n}\n\n/* Recover the contents of the free-list array fl into the global one gfl. */\nstatic void\nreturn_freelists(void **fl, void **gfl)\n{\n  int i;\n\n  for (i = 1; i < GC_TINY_FREELISTS; ++i) {\n    if (ADDR(fl[i]) >= HBLKSIZE) {\n      return_single_freelist(fl[i], &gfl[i]);\n    }\n    /* Clear fl[i], since the thread structure may hang around.     */\n    /* Do it in a way that is likely to trap if we access it.       */\n    fl[i] = (ptr_t)NUMERIC_TO_VPTR(HBLKSIZE);\n  }\n  /* The 0 granule free list really contains 1 granule objects.       */\n  if (ADDR(fl[0]) >= HBLKSIZE\n#  ifdef GC_GCJ_SUPPORT\n      && ADDR(fl[0]) != ERROR_FL\n#  endif\n  ) {\n    return_single_freelist(fl[0], &gfl[1]);\n  }\n}\n\n#  ifdef USE_PTHREAD_SPECIFIC\n/* Re-set the TLS value on thread cleanup to allow thread-local       */\n/* allocations to happen in the TLS destructors.                      */\n/* GC_unregister_my_thread (and similar routines) will finally set    */\n/* the GC_thread_key to NULL preventing this destructor from being    */\n/* called repeatedly.                                                 */\nstatic void\nreset_thread_key(void *v)\n{\n  pthread_setspecific(GC_thread_key, v);\n}\n#  else\n#    define reset_thread_key 0\n#  endif\n\nGC_INNER void\nGC_init_thread_local(GC_tlfs p)\n{\n  int k, j, res;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (!EXPECT(keys_initialized, TRUE)) {\n#  ifdef USE_CUSTOM_SPECIFIC\n    /* Ensure proper alignment of a \"pushed\" GC symbol.   */\n    GC_ASSERT(ADDR(&GC_thread_key) % ALIGNMENT == 0);\n#  endif\n    res = GC_key_create(&GC_thread_key, reset_thread_key);\n    if (COVERT_DATAFLOW(res) != 0) {\n      ABORT(\"Failed to create key for local allocator\");\n    }\n    keys_initialized = TRUE;\n  }\n  res = GC_setspecific(GC_thread_key, p);\n  if (COVERT_DATAFLOW(res) != 0) {\n    ABORT(\"Failed to set thread specific allocation pointers\");\n  }\n  for (j = 0; j < GC_TINY_FREELISTS; ++j) {\n    for (k = 0; k < THREAD_FREELISTS_KINDS; ++k) {\n      p->_freelists[k][j] = NUMERIC_TO_VPTR(1);\n    }\n#  ifdef GC_GCJ_SUPPORT\n    p->gcj_freelists[j] = NUMERIC_TO_VPTR(1);\n#  endif\n  }\n  /* The zero-sized free list is handled like the regular free list,  */\n  /* to ensure that the explicit deallocation works.  However, an     */\n  /* allocation of a size 0 \"gcj\" object is always an error.          */\n#  ifdef GC_GCJ_SUPPORT\n  p->gcj_freelists[0] = MAKE_CPTR(ERROR_FL);\n#  endif\n}\n\nGC_INNER void\nGC_destroy_thread_local(GC_tlfs p)\n{\n  int k;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_getspecific(GC_thread_key) == p);\n  /* We currently only do this from the thread itself.        */\n  GC_STATIC_ASSERT(THREAD_FREELISTS_KINDS <= MAXOBJKINDS);\n  for (k = 0; k < THREAD_FREELISTS_KINDS; ++k) {\n    if (k == (int)GC_n_kinds) {\n      /* The kind is not created. */\n      break;\n    }\n    return_freelists(p->_freelists[k], GC_obj_kinds[k].ok_freelist);\n  }\n#  ifdef GC_GCJ_SUPPORT\n  return_freelists(p->gcj_freelists, (void **)GC_gcjobjfreelist);\n#  endif\n}\n\nSTATIC void *\nGC_get_tlfs(void)\n{\n#  if !defined(USE_PTHREAD_SPECIFIC) && !defined(USE_WIN32_SPECIFIC)\n  GC_key_t k = GC_thread_key;\n\n  if (EXPECT(0 == k, FALSE)) {\n    /* We have not yet run GC_init_parallel.  That means we also  */\n    /* are not locking, so GC_malloc_kind_global is fairly cheap. */\n    return NULL;\n  }\n  return GC_getspecific(k);\n#  else\n  if (EXPECT(!keys_initialized, FALSE))\n    return NULL;\n\n  return GC_getspecific(GC_thread_key);\n#  endif\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_kind(size_t lb, int k)\n{\n  size_t lg;\n  void *tsd;\n  void *result;\n\n#  if MAXOBJKINDS > THREAD_FREELISTS_KINDS\n  if (EXPECT(k >= THREAD_FREELISTS_KINDS, FALSE)) {\n    return GC_malloc_kind_global(lb, k);\n  }\n#  endif\n  tsd = GC_get_tlfs();\n  if (EXPECT(NULL == tsd, FALSE)) {\n    return GC_malloc_kind_global(lb, k);\n  }\n  GC_ASSERT(GC_is_initialized);\n  GC_ASSERT(GC_is_thread_tsd_valid(tsd));\n  lg = ALLOC_REQUEST_GRANS(lb);\n#  if defined(CPPCHECK)\n#    define MALLOC_KIND_PTRFREE_INIT (void *)1\n#  else\n#    define MALLOC_KIND_PTRFREE_INIT NULL\n#  endif\n  GC_FAST_MALLOC_GRANS(result, lg, ((GC_tlfs)tsd)->_freelists[k],\n                       DIRECT_GRANULES, k, GC_malloc_kind_global(lb, k),\n                       (void)(k == PTRFREE ? MALLOC_KIND_PTRFREE_INIT\n                                           : (obj_link(result) = 0)));\n#  ifdef LOG_ALLOCS\n  GC_log_printf(\"GC_malloc_kind(%lu, %d) returned %p, recent GC #%lu\\n\",\n                (unsigned long)lb, k, result, (unsigned long)GC_gc_no);\n#  endif\n  return result;\n}\n\n#  ifdef GC_GCJ_SUPPORT\n\n#    include \"gc/gc_gcj.h\"\n\n/* Gcj-style allocation without locks is extremely tricky.  The         */\n/* fundamental issue is that we may end up marking a free list, which   */\n/* has free-list links instead of \"vtable\" pointers.  That is usually   */\n/* OK, since the next object on the free list will be cleared, and      */\n/* will thus be interpreted as containing a zero descriptor.  That's    */\n/* fine if the object has not yet been initialized.  But there are      */\n/* interesting potential races.                                         */\n/* In the case of incremental collection, this seems hopeless, since    */\n/* the marker may run asynchronously, and may pick up the pointer to    */\n/* the next free-list entry (which it thinks is a vtable pointer), get  */\n/* suspended for a while, and then see an allocated object instead      */\n/* of the vtable.  This may be avoidable with either a handshake with   */\n/* the collector or, probably more easily, by moving the free list      */\n/* links to the second word of each object.  The latter isn't a         */\n/* universal win, since on architecture like Itanium, nonzero offsets   */\n/* are not necessarily free.  And there may be cache fill order issues. */\n/* For now, we punt with incremental GC.  This probably means that      */\n/* incremental GC should be enabled before we fork a second thread.     */\n/* Unlike the other thread-local allocation calls, we assume that the   */\n/* collector has been explicitly initialized.                           */\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_gcj_malloc(size_t lb, const void *vtable_ptr)\n{\n  if (EXPECT(GC_incremental, FALSE)) {\n    return GC_core_gcj_malloc(lb, vtable_ptr, 0 /* flags */);\n  } else {\n    size_t lg = ALLOC_REQUEST_GRANS(lb);\n    void *result;\n    void **tiny_fl;\n\n    GC_ASSERT(GC_gcjobjfreelist != NULL);\n    tiny_fl = ((GC_tlfs)GC_getspecific(GC_thread_key))->gcj_freelists;\n\n    /* This forces the initialization of the \"method ptr\".  This is     */\n    /* necessary to ensure some very subtle properties required if      */\n    /* a garbage collection is run in the middle of such an allocation. */\n    /* Here we implicitly also assume atomicity for the free list and   */\n    /* method pointer assignments.  We must update the free list before */\n    /* we store the pointer.  Otherwise a collection at this point      */\n    /* would see a corrupted free list.  A real memory barrier is not   */\n    /* needed, since the action of stopping this thread will cause      */\n    /* prior writes to complete.  We assert that any concurrent marker  */\n    /* will stop us.  Thus it is impossible for a mark procedure to see */\n    /* the allocation of the next object, but to see this object still  */\n    /* containing a free-list pointer.  Otherwise the marker, by        */\n    /* misinterpreting the free-list link as a vtable pointer, might    */\n    /* find a random \"mark descriptor\" in the next object.              */\n    GC_FAST_MALLOC_GRANS(\n        result, lg, tiny_fl, DIRECT_GRANULES, GC_gcj_kind,\n        GC_core_gcj_malloc(lb, vtable_ptr, 0 /* flags */), do {\n          AO_compiler_barrier();\n          *(const void **)result = vtable_ptr;\n        } while (0));\n    return result;\n  }\n}\n\n#  endif /* GC_GCJ_SUPPORT */\n\n/* The thread support layer must arrange to mark thread-local   */\n/* free lists explicitly, since the link field is often         */\n/* invisible to the marker.  It knows how to find all threads;  */\n/* we take care of an individual thread free-list structure.    */\nGC_INNER void\nGC_mark_thread_local_fls_for(GC_tlfs p)\n{\n  ptr_t q;\n  int k, j;\n\n  for (j = 0; j < GC_TINY_FREELISTS; ++j) {\n    for (k = 0; k < THREAD_FREELISTS_KINDS; ++k) {\n      /* Load the pointer atomically as it might be updated   */\n      /* concurrently by GC_FAST_MALLOC_GRANS.                */\n      q = GC_cptr_load((volatile ptr_t *)&p->_freelists[k][j]);\n      if (ADDR(q) > HBLKSIZE)\n        GC_set_fl_marks(q);\n    }\n#  ifdef GC_GCJ_SUPPORT\n    if (EXPECT(j > 0, TRUE)) {\n      q = GC_cptr_load((volatile ptr_t *)&p->gcj_freelists[j]);\n      if (ADDR(q) > HBLKSIZE)\n        GC_set_fl_marks(q);\n    }\n#  endif\n  }\n}\n\n#  if defined(GC_ASSERTIONS)\n/* Check that all thread-local free-lists in p are completely marked. */\nvoid\nGC_check_tls_for(GC_tlfs p)\n{\n  int k, j;\n\n  for (j = 1; j < GC_TINY_FREELISTS; ++j) {\n    for (k = 0; k < THREAD_FREELISTS_KINDS; ++k) {\n      GC_check_fl_marks(&p->_freelists[k][j]);\n    }\n#    ifdef GC_GCJ_SUPPORT\n    GC_check_fl_marks(&p->gcj_freelists[j]);\n#    endif\n  }\n}\n#  endif\n\n#endif /* THREAD_LOCAL_ALLOC */\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "typd_mlc.c",
          "type": "blob",
          "size": 24.787109375,
          "content": "/*\n * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1999-2000 by Hewlett-Packard Company.  All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/gc_pmark.h\"\n\n/*\n * Some simple primitives for allocation with explicit type information.\n * Simple objects are allocated such that they contain a GC_descr at the\n * end (in the last allocated word).  This descriptor may be a procedure\n * which then examines an extended descriptor passed as its environment.\n *\n * Arrays are treated as simple objects if they have sufficiently simple\n * structure.  Otherwise they are allocated from an array kind that supplies\n * a special mark procedure.  These arrays contain a pointer to a\n * complex_descriptor as their last \"pointer-sized\" word.\n * This is done because the environment field is too small, and the collector\n * must trace the complex_descriptor.\n *\n * Note that descriptors inside objects may appear cleared, if we encounter\n * a false reference to an object on a free list.  In the case of a simple\n * object, this is OK, since a zero descriptor corresponds to examining no\n * fields.  In the complex_descriptor case, we explicitly check for that case.\n *\n * MAJOR PARTS OF THIS CODE HAVE NOT BEEN TESTED AT ALL and are not testable,\n * since they are not accessible through the current interface.\n */\n\n#include \"gc/gc_typed.h\"\n\n/* Object kind for objects with indirect (possibly extended) descriptors. */\nSTATIC int GC_explicit_kind = 0;\n\n/* Object kind for objects with complex descriptors and GC_array_mark_proc. */\nSTATIC int GC_array_kind = 0;\n\n#define ED_INITIAL_SIZE 100\n\n/* Indices of the typed mark procedures.        */\nSTATIC unsigned GC_typed_mark_proc_index = 0;\nSTATIC unsigned GC_array_mark_proc_index = 0;\n\nSTATIC void\nGC_push_typed_structures_proc(void)\n{\n  GC_PUSH_ALL_SYM(GC_ext_descriptors);\n}\n\n/* Add a multi-word bitmap to GC_ext_descriptors arrays.        */\n/* Returns starting index on success, -1 otherwise.             */\nSTATIC GC_signed_word\nGC_add_ext_descriptor(const word *bm, size_t nbits)\n{\n  GC_signed_word result;\n  size_t i;\n  size_t nwords = divWORDSZ(nbits + CPP_WORDSZ - 1);\n\n  LOCK();\n  while (EXPECT(GC_avail_descr + nwords >= GC_ed_size, FALSE)) {\n    typed_ext_descr_t *newExtD;\n    size_t new_size;\n    size_t ed_size = GC_ed_size;\n\n    if (0 == ed_size) {\n      GC_ASSERT(ADDR(&GC_ext_descriptors) % ALIGNMENT == 0);\n      GC_push_typed_structures = GC_push_typed_structures_proc;\n      UNLOCK();\n      new_size = ED_INITIAL_SIZE;\n    } else {\n      UNLOCK();\n      new_size = 2 * ed_size;\n      if (new_size > MAX_ENV)\n        return -1;\n    }\n    newExtD = (typed_ext_descr_t *)GC_malloc_atomic(\n        new_size * sizeof(typed_ext_descr_t));\n    if (NULL == newExtD)\n      return -1;\n    LOCK();\n    if (ed_size == GC_ed_size) {\n      if (GC_avail_descr != 0) {\n        BCOPY(GC_ext_descriptors, newExtD,\n              GC_avail_descr * sizeof(typed_ext_descr_t));\n      }\n      GC_ed_size = new_size;\n      GC_ext_descriptors = newExtD;\n    } else {\n      /* Another thread is already resized it in the meantime.    */\n    }\n  }\n  result = (GC_signed_word)GC_avail_descr;\n  for (i = 0; i < nwords - 1; i++) {\n    GC_ext_descriptors[(size_t)result + i].ed_bitmap = bm[i];\n    GC_ext_descriptors[(size_t)result + i].ed_continued = TRUE;\n  }\n  /* Clear irrelevant (highest) bits for the last element.    */\n  GC_ext_descriptors[(size_t)result + i].ed_bitmap\n      = bm[i] & (GC_WORD_MAX >> (nwords * CPP_WORDSZ - nbits));\n  GC_ext_descriptors[(size_t)result + i].ed_continued = FALSE;\n  GC_avail_descr += nwords;\n  GC_ASSERT(result >= 0);\n  UNLOCK();\n  return result;\n}\n\n/* Table of bitmap descriptors for n pointer-long all-pointer objects.  */\nSTATIC GC_descr GC_bm_table[CPP_WORDSZ / 2];\n\n/* Return a descriptor for the concatenation of 2 objects, each one is  */\n/* lpw pointers long and described by descriptor d.  The result is      */\n/* known to be short enough to fit into a bitmap descriptor.            */\n/* d is a GC_DS_LENGTH or GC_DS_BITMAP descriptor.                      */\nSTATIC GC_descr\nGC_double_descr(GC_descr d, size_t lpw)\n{\n  GC_ASSERT(GC_bm_table[0] == GC_DS_BITMAP); /* bm table is initialized */\n  if ((d & GC_DS_TAGS) == GC_DS_LENGTH) {\n    d = GC_bm_table[BYTES_TO_PTRS(d)];\n  }\n  d |= (d & ~(GC_descr)GC_DS_TAGS) >> lpw;\n  return d;\n}\n\nSTATIC mse *GC_CALLBACK GC_typed_mark_proc(word *addr, mse *mark_stack_top,\n                                           mse *mark_stack_limit, word env);\n\nSTATIC mse *GC_CALLBACK GC_array_mark_proc(word *addr, mse *mark_stack_top,\n                                           mse *mark_stack_limit, word env);\n\nSTATIC void\nGC_init_explicit_typing(void)\n{\n  unsigned i;\n\n  /* Set up object kind with simple indirect descriptor.      */\n  /* Descriptor is in the last word of the object.            */\n  GC_typed_mark_proc_index = GC_new_proc_inner(GC_typed_mark_proc);\n  GC_explicit_kind = (int)GC_new_kind_inner(\n      GC_new_free_list_inner(),\n      (PTRS_TO_BYTES(GC_WORD_MAX) | GC_DS_PER_OBJECT), TRUE, TRUE);\n\n  /* Set up object kind with array descriptor. */\n  GC_array_mark_proc_index = GC_new_proc_inner(GC_array_mark_proc);\n  GC_array_kind = (int)GC_new_kind_inner(\n      GC_new_free_list_inner(), GC_MAKE_PROC(GC_array_mark_proc_index, 0),\n      FALSE, TRUE);\n\n  GC_bm_table[0] = GC_DS_BITMAP;\n  for (i = 1; i < CPP_WORDSZ / 2; i++) {\n    GC_bm_table[i] = (GC_WORD_MAX << (CPP_WORDSZ - i)) | GC_DS_BITMAP;\n  }\n}\n\nSTATIC mse *GC_CALLBACK\nGC_typed_mark_proc(word *addr, mse *mark_stack_top, mse *mark_stack_limit,\n                   word env)\n{\n  word bm;\n  ptr_t current_p = (ptr_t)addr;\n  ptr_t greatest_ha = (ptr_t)GC_greatest_plausible_heap_addr;\n  ptr_t least_ha = (ptr_t)GC_least_plausible_heap_addr;\n  DECLARE_HDR_CACHE;\n\n  /* The allocator lock is held by the collection initiating thread.  */\n  GC_ASSERT(GC_get_parallel() || I_HOLD_LOCK());\n  bm = GC_ext_descriptors[env].ed_bitmap;\n\n  INIT_HDR_CACHE;\n  for (; bm != 0; bm >>= 1, current_p += sizeof(ptr_t)) {\n    if (bm & 1) {\n      ptr_t q;\n\n      LOAD_PTR_OR_CONTINUE(q, current_p);\n      FIXUP_POINTER(q);\n      if (ADDR_LT(least_ha, q) && ADDR_LT(q, greatest_ha)) {\n        PUSH_CONTENTS(q, mark_stack_top, mark_stack_limit, current_p);\n      }\n    }\n  }\n  if (GC_ext_descriptors[env].ed_continued) {\n    /* Push an entry with the rest of the descriptor back onto the  */\n    /* stack.  Thus we never do too much work at once.  Note that   */\n    /* we also can't overflow the mark stack unless we actually     */\n    /* mark something.                                              */\n    mark_stack_top = GC_custom_push_proc(\n        GC_MAKE_PROC(GC_typed_mark_proc_index, env + 1),\n        (ptr_t *)addr + CPP_WORDSZ, mark_stack_top, mark_stack_limit);\n  }\n  return mark_stack_top;\n}\n\nGC_API GC_descr GC_CALL\nGC_make_descriptor(const GC_word *bm, size_t len)\n{\n  GC_signed_word last_set_bit = (GC_signed_word)len - 1;\n  GC_descr d;\n\n#if defined(AO_HAVE_load_acquire) && defined(AO_HAVE_store_release)\n  if (!EXPECT(AO_load_acquire(&GC_explicit_typing_initialized), TRUE)) {\n    LOCK();\n    if (!GC_explicit_typing_initialized) {\n      GC_init_explicit_typing();\n      AO_store_release(&GC_explicit_typing_initialized, TRUE);\n    }\n    UNLOCK();\n  }\n#else\n  LOCK();\n  if (!EXPECT(GC_explicit_typing_initialized, TRUE)) {\n    GC_init_explicit_typing();\n    GC_explicit_typing_initialized = TRUE;\n  }\n  UNLOCK();\n#endif\n\n  while (last_set_bit >= 0 && !GC_get_bit(bm, (word)last_set_bit))\n    last_set_bit--;\n  if (last_set_bit < 0) {\n    /* No pointers.   */\n    return 0;\n  }\n\n#if ALIGNMENT == CPP_PTRSZ / 8\n  {\n    GC_signed_word i;\n\n    for (i = 0; i < last_set_bit; i++) {\n      if (!GC_get_bit(bm, (word)i))\n        break;\n    }\n    if (i == last_set_bit) {\n      /* The initial section contains all pointers; use the     */\n      /* length descriptor.                                     */\n      return PTRS_TO_BYTES((word)last_set_bit + 1) | GC_DS_LENGTH;\n    }\n  }\n#endif\n  if (last_set_bit < BITMAP_BITS) {\n    GC_signed_word i;\n\n    /* Hopefully the common case.  Build the bitmap descriptor  */\n    /* (with the bits reversed).                                */\n    d = SIGNB;\n    for (i = last_set_bit - 1; i >= 0; i--) {\n      d >>= 1;\n      if (GC_get_bit(bm, (word)i))\n        d |= SIGNB;\n    }\n    d |= GC_DS_BITMAP;\n  } else {\n    GC_signed_word index = GC_add_ext_descriptor(bm, (size_t)last_set_bit + 1);\n\n    if (EXPECT(index < 0, FALSE)) {\n      /* Out of memory: use a conservative approximation. */\n      return PTRS_TO_BYTES((word)last_set_bit + 1) | GC_DS_LENGTH;\n    }\n#ifdef LINT2\n    if ((word)index > MAX_ENV)\n      ABORT(\"GC_add_ext_descriptor() result cannot exceed MAX_ENV\");\n#endif\n    d = GC_MAKE_PROC(GC_typed_mark_proc_index, index);\n  }\n  return d;\n}\n\nstatic void\nset_obj_descr(ptr_t op, GC_descr d)\n{\n  size_t sz;\n\n  if (EXPECT(NULL == op, FALSE))\n    return;\n\n  /* It is not safe to use GC_size_map[] here as the table might be */\n  /* updated asynchronously.                                        */\n  sz = GC_size(op);\n\n  GC_ASSERT((sz & (GC_GRANULE_BYTES - 1)) == 0 && sz > sizeof(GC_descr));\n#ifdef AO_HAVE_store_release\n  AO_store_release((volatile AO_t *)&op[sz - sizeof(GC_descr)], d);\n#else\n  *(GC_descr *)&op[sz - sizeof(GC_descr)] = d;\n#endif\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_explicitly_typed(size_t lb, GC_descr d)\n{\n  ptr_t op;\n\n  GC_ASSERT(GC_explicit_typing_initialized);\n  if (EXPECT(lb < sizeof(ptr_t) - sizeof(GC_descr) + 1, FALSE)) {\n    /* Ensure the descriptor does not occupy the first pointer place. */\n    lb = sizeof(ptr_t) - sizeof(GC_descr) + 1;\n  }\n  op = (ptr_t)GC_malloc_kind(SIZET_SAT_ADD(lb, sizeof(GC_descr) - EXTRA_BYTES),\n                             GC_explicit_kind);\n  set_obj_descr(op, d);\n  return op;\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_malloc_explicitly_typed_ignore_off_page(size_t lb, GC_descr d)\n{\n  ptr_t op;\n\n  if (lb < HBLKSIZE - sizeof(GC_descr))\n    return GC_malloc_explicitly_typed(lb, d);\n\n  GC_ASSERT(GC_explicit_typing_initialized);\n  /* Note that ignore-off-page objects with the requested size    */\n  /* of at least HBLKSIZE do not have EXTRA_BYTES added by        */\n  /* GC_generic_malloc_aligned().                                 */\n  op = (ptr_t)GC_clear_stack(\n      GC_generic_malloc_aligned(SIZET_SAT_ADD(lb, sizeof(GC_descr)),\n                                GC_explicit_kind, IGNORE_OFF_PAGE, 0));\n  set_obj_descr(op, d);\n  return op;\n}\n\n/* Array descriptors.  GC_array_mark_proc understands these.    */\n/* We may eventually need to add provisions for headers and     */\n/* trailers.  Hence we provide for tree structured descriptors, */\n/* though we don't really use them currently.                   */\n\n/* This type describes simple array.    */\nstruct LeafDescriptor {\n  word ld_tag;\n#define LEAF_TAG 1\n  /* Bytes per element; non-zero, multiple of ALIGNMENT.        */\n  size_t ld_size;\n  /* Number of elements.        */\n  size_t ld_nelements;\n  /* A simple length, bitmap, or procedure descriptor.          */\n  GC_descr ld_descriptor;\n};\n\nstruct ComplexArrayDescriptor {\n  word ad_tag;\n#define ARRAY_TAG 2\n  size_t ad_nelements;\n  union ComplexDescriptor *ad_element_descr;\n};\n\nstruct SequenceDescriptor {\n  word sd_tag;\n#define SEQUENCE_TAG 3\n  union ComplexDescriptor *sd_first;\n  union ComplexDescriptor *sd_second;\n};\n\ntypedef union ComplexDescriptor {\n  struct LeafDescriptor ld;\n  struct ComplexArrayDescriptor ad;\n  struct SequenceDescriptor sd;\n} complex_descriptor;\n\nSTATIC complex_descriptor *\nGC_make_leaf_descriptor(size_t size, size_t nelements, GC_descr d)\n{\n  complex_descriptor *result\n      = (complex_descriptor *)GC_malloc_atomic(sizeof(struct LeafDescriptor));\n\n  GC_ASSERT(size != 0);\n  if (EXPECT(NULL == result, FALSE))\n    return NULL;\n\n  result->ld.ld_tag = LEAF_TAG;\n  result->ld.ld_size = size;\n  result->ld.ld_nelements = nelements;\n  result->ld.ld_descriptor = d;\n  return result;\n}\n\nSTATIC complex_descriptor *\nGC_make_sequence_descriptor(complex_descriptor *first,\n                            complex_descriptor *second)\n{\n  /* Note: for a reason, the sanitizer runtime complains of             */\n  /* insufficient space for complex_descriptor if the pointer type of   */\n  /* result variable is changed to.                                     */\n  struct SequenceDescriptor *result = (struct SequenceDescriptor *)GC_malloc(\n      sizeof(struct SequenceDescriptor));\n\n  if (EXPECT(NULL == result, FALSE))\n    return NULL;\n\n  /* Can't result in overly conservative marking, since tags are        */\n  /* very small integers. Probably faster than maintaining type info.   */\n  result->sd_tag = SEQUENCE_TAG;\n  result->sd_first = first;\n  result->sd_second = second;\n  GC_dirty(result);\n  REACHABLE_AFTER_DIRTY(first);\n  REACHABLE_AFTER_DIRTY(second);\n  return (complex_descriptor *)result;\n}\n\n#define NO_MEM (-1)\n#define SIMPLE 0\n#define LEAF 1\n#define COMPLEX 2\n\n/* Build a descriptor for an array with nelements elements, each of     */\n/* which can be described by a simple descriptor d.  We try to optimize */\n/* some common cases.  If the result is COMPLEX, a complex_descriptor*  */\n/* value is returned in *pcomplex_d.  If the result is LEAF, then a     */\n/* LeafDescriptor value is built in the structure pointed to by pleaf.  */\n/* The tag in the *pleaf structure is not set.  If the result is        */\n/* SIMPLE, then a GC_descr value is returned in *psimple_d.  If the     */\n/* result is NO_MEM, then we failed to allocate the descriptor.         */\n/* The implementation assumes GC_DS_LENGTH is 0.  *pleaf, *pcomplex_d   */\n/* and *psimple_d may be used as temporaries during the construction.   */\nSTATIC int\nGC_make_array_descriptor(size_t nelements, size_t size, GC_descr d,\n                         GC_descr *psimple_d, complex_descriptor **pcomplex_d,\n                         struct LeafDescriptor *pleaf)\n{\n  /* For larger arrays, we try to combine descriptors of adjacent       */\n  /* descriptors to speed up marking, and to reduce the amount of space */\n  /* needed on the mark stack.                                          */\n#define OPT_THRESHOLD 50\n\n  GC_ASSERT(size != 0);\n  if ((d & GC_DS_TAGS) == GC_DS_LENGTH) {\n    if (d == (GC_descr)size) {\n      /* Note: no overflow is guaranteed by caller.     */\n      *psimple_d = nelements * d;\n      return SIMPLE;\n    } else if (0 == d) {\n      *psimple_d = 0;\n      return SIMPLE;\n    }\n  }\n\n  if (nelements <= OPT_THRESHOLD) {\n    if (nelements <= 1) {\n      *psimple_d = nelements == 1 ? d : 0;\n      return SIMPLE;\n    }\n  } else if (size <= BITMAP_BITS / 2 && (d & GC_DS_TAGS) != GC_DS_PROC\n             && (size & (sizeof(ptr_t) - 1)) == 0) {\n    complex_descriptor *one_element, *beginning;\n    int result = GC_make_array_descriptor(\n        nelements / 2, 2 * size, GC_double_descr(d, BYTES_TO_PTRS(size)),\n        psimple_d, pcomplex_d, pleaf);\n\n    if ((nelements & 1) == 0 || EXPECT(NO_MEM == result, FALSE))\n      return result;\n\n    one_element = GC_make_leaf_descriptor(size, 1, d);\n    if (EXPECT(NULL == one_element, FALSE))\n      return NO_MEM;\n\n    if (COMPLEX == result) {\n      beginning = *pcomplex_d;\n    } else {\n      beginning\n          = SIMPLE == result\n                ? GC_make_leaf_descriptor(size, 1, *psimple_d)\n                : GC_make_leaf_descriptor(pleaf->ld_size, pleaf->ld_nelements,\n                                          pleaf->ld_descriptor);\n      if (EXPECT(NULL == beginning, FALSE))\n        return NO_MEM;\n    }\n    *pcomplex_d = GC_make_sequence_descriptor(beginning, one_element);\n    if (EXPECT(NULL == *pcomplex_d, FALSE))\n      return NO_MEM;\n\n    return COMPLEX;\n  }\n\n  pleaf->ld_size = size;\n  pleaf->ld_nelements = nelements;\n  pleaf->ld_descriptor = d;\n  return LEAF;\n}\n\nstruct GC_calloc_typed_descr_s {\n  complex_descriptor *complex_d; /* the first field, the only pointer */\n  struct LeafDescriptor leaf;\n  GC_descr simple_d;\n  word alloc_lb;             /* size_t actually */\n  GC_signed_word descr_type; /* int actually */\n};\n\nGC_API int GC_CALL\nGC_calloc_prepare_explicitly_typed(struct GC_calloc_typed_descr_s *pctd,\n                                   size_t ctd_sz, size_t n, size_t lb,\n                                   GC_descr d)\n{\n  GC_STATIC_ASSERT(sizeof(struct GC_calloc_typed_descr_opaque_s)\n                   == sizeof(struct GC_calloc_typed_descr_s));\n  GC_ASSERT(GC_explicit_typing_initialized);\n  GC_ASSERT(sizeof(struct GC_calloc_typed_descr_s) == ctd_sz);\n  (void)ctd_sz; /* unused currently */\n  if (EXPECT(0 == lb || 0 == n, FALSE))\n    lb = n = 1;\n  if (EXPECT((lb | n) > GC_SQRT_SIZE_MAX, FALSE) /* fast initial check */\n      && n > GC_SIZE_MAX / lb) {\n    /* n*lb overflows.        */\n    pctd->alloc_lb = GC_SIZE_MAX;\n    pctd->descr_type = NO_MEM;\n    /* The rest of the fields are unset. */\n    return 0; /* failure */\n  }\n\n  pctd->descr_type = GC_make_array_descriptor(n, lb, d, &pctd->simple_d,\n                                              &pctd->complex_d, &pctd->leaf);\n  switch (pctd->descr_type) {\n  case NO_MEM:\n  case SIMPLE:\n    pctd->alloc_lb = (word)lb * n;\n    break;\n  case LEAF:\n    pctd->alloc_lb = SIZET_SAT_ADD(\n        lb * n, (BYTES_TO_PTRS_ROUNDUP(sizeof(struct LeafDescriptor)) + 1)\n                        * sizeof(ptr_t)\n                    - EXTRA_BYTES);\n    break;\n  case COMPLEX:\n    pctd->alloc_lb = SIZET_SAT_ADD(lb * n, sizeof(ptr_t) - EXTRA_BYTES);\n    break;\n  }\n  return 1; /* success */\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_calloc_do_explicitly_typed(const struct GC_calloc_typed_descr_s *pctd,\n                              size_t ctd_sz)\n{\n  void *op;\n  size_t lpw_m1;\n\n  GC_ASSERT(sizeof(struct GC_calloc_typed_descr_s) == ctd_sz);\n  (void)ctd_sz; /* unused currently */\n  switch (pctd->descr_type) {\n  case NO_MEM:\n    return (*GC_get_oom_fn())((size_t)pctd->alloc_lb);\n  case SIMPLE:\n    return GC_malloc_explicitly_typed((size_t)pctd->alloc_lb, pctd->simple_d);\n  case LEAF:\n  case COMPLEX:\n    break;\n  default:\n    ABORT_RET(\"Bad descriptor type\");\n    return NULL;\n  }\n  op = GC_malloc_kind((size_t)pctd->alloc_lb, GC_array_kind);\n  if (EXPECT(NULL == op, FALSE))\n    return NULL;\n\n  lpw_m1 = BYTES_TO_PTRS(GC_size(op)) - 1;\n  if (pctd->descr_type == LEAF) {\n    /* Set up the descriptor inside the object itself.        */\n    struct LeafDescriptor *lp\n        = (struct LeafDescriptor *)((ptr_t *)op + lpw_m1\n                                    - BYTES_TO_PTRS_ROUNDUP(\n                                        sizeof(struct LeafDescriptor)));\n\n    lp->ld_tag = LEAF_TAG;\n    lp->ld_size = pctd->leaf.ld_size;\n    lp->ld_nelements = pctd->leaf.ld_nelements;\n    lp->ld_descriptor = pctd->leaf.ld_descriptor;\n    /* Hold the allocator lock (in the reader mode which should be    */\n    /* enough) while writing the descriptor word to the object to     */\n    /* ensure that the descriptor contents are seen by                */\n    /* GC_array_mark_proc as expected.                                */\n    /* TODO: It should be possible to replace locking with the atomic */\n    /* operations (with the release barrier here) but, in this case,  */\n    /* avoiding the acquire barrier in GC_array_mark_proc seems to    */\n    /* be tricky as GC_mark_some might be invoked with the world      */\n    /* running.                                                       */\n    READER_LOCK();\n    ((struct LeafDescriptor **)op)[lpw_m1] = lp;\n    READER_UNLOCK_RELEASE();\n  } else {\n#ifndef GC_NO_FINALIZATION\n    READER_LOCK();\n    ((complex_descriptor **)op)[lpw_m1] = pctd->complex_d;\n    READER_UNLOCK_RELEASE();\n\n    GC_dirty((ptr_t *)op + lpw_m1);\n    REACHABLE_AFTER_DIRTY(pctd->complex_d);\n\n    /* Make sure the descriptor is cleared once there is any danger */\n    /* it may have been collected.                                  */\n    if (EXPECT(GC_general_register_disappearing_link((void **)op + lpw_m1, op)\n                   == GC_NO_MEMORY,\n               FALSE))\n#endif\n    {\n      /* Couldn't register it due to lack of memory.  Punt.       */\n      return (*GC_get_oom_fn())((size_t)pctd->alloc_lb);\n    }\n  }\n  return op;\n}\n\nGC_API GC_ATTR_MALLOC void *GC_CALL\nGC_calloc_explicitly_typed(size_t n, size_t lb, GC_descr d)\n{\n  struct GC_calloc_typed_descr_s ctd;\n\n  (void)GC_calloc_prepare_explicitly_typed(&ctd, sizeof(ctd), n, lb, d);\n  return GC_calloc_do_explicitly_typed(&ctd, sizeof(ctd));\n}\n\n/* Return the size of the object described by complex_d.  It would be   */\n/* faster to store this directly, or to compute it as part of           */\n/* GC_push_complex_descriptor, but hopefully it does not matter.        */\nSTATIC size_t\nGC_descr_obj_size(complex_descriptor *complex_d)\n{\n  switch (complex_d->ad.ad_tag) {\n  case LEAF_TAG:\n    return complex_d->ld.ld_nelements * complex_d->ld.ld_size;\n  case ARRAY_TAG:\n    return complex_d->ad.ad_nelements\n           * GC_descr_obj_size(complex_d->ad.ad_element_descr);\n  case SEQUENCE_TAG:\n    return GC_descr_obj_size(complex_d->sd.sd_first)\n           + GC_descr_obj_size(complex_d->sd.sd_second);\n  default:\n    ABORT_RET(\"Bad complex descriptor\");\n    return 0;\n  }\n}\n\n/* Push descriptors for the object with complex descriptor onto the */\n/* mark stack.  Return NULL if the mark stack overflowed.           */\nSTATIC mse *\nGC_push_complex_descriptor(ptr_t current, complex_descriptor *complex_d,\n                           mse *msp, mse *msl)\n{\n  size_t i, nelements;\n  size_t sz;\n  GC_descr d;\n  complex_descriptor *element_descr;\n\n  switch (complex_d->ad.ad_tag) {\n  case LEAF_TAG:\n    d = complex_d->ld.ld_descriptor;\n    nelements = complex_d->ld.ld_nelements;\n    sz = complex_d->ld.ld_size;\n\n    if (EXPECT(msl - msp <= (GC_signed_word)nelements, FALSE))\n      return NULL;\n    GC_ASSERT(sz != 0);\n    for (i = 0; i < nelements; i++) {\n      msp++;\n      msp->mse_start = current;\n      msp->mse_descr = d;\n      current += sz;\n    }\n    break;\n  case ARRAY_TAG:\n    element_descr = complex_d->ad.ad_element_descr;\n    nelements = complex_d->ad.ad_nelements;\n    sz = GC_descr_obj_size(element_descr);\n    GC_ASSERT(sz != 0 || 0 == nelements);\n    for (i = 0; i < nelements; i++) {\n      msp = GC_push_complex_descriptor(current, element_descr, msp, msl);\n      if (EXPECT(NULL == msp, FALSE))\n        return NULL;\n      current += sz;\n    }\n    break;\n  case SEQUENCE_TAG:\n    sz = GC_descr_obj_size(complex_d->sd.sd_first);\n    msp = GC_push_complex_descriptor(current, complex_d->sd.sd_first, msp,\n                                     msl);\n    if (EXPECT(NULL == msp, FALSE))\n      return NULL;\n    GC_ASSERT(sz != 0);\n    current += sz;\n    msp = GC_push_complex_descriptor(current, complex_d->sd.sd_second, msp,\n                                     msl);\n    break;\n  default:\n    ABORT(\"Bad complex descriptor\");\n  }\n  return msp;\n}\n\nGC_ATTR_NO_SANITIZE_THREAD\nstatic complex_descriptor *\nget_complex_descr(ptr_t *p, size_t lpw)\n{\n  return (complex_descriptor *)p[lpw - 1];\n}\n\n/* Used by GC_calloc_do_explicitly_typed via GC_array_kind.     */\nSTATIC mse *GC_CALLBACK\nGC_array_mark_proc(word *addr, mse *mark_stack_top, mse *mark_stack_limit,\n                   word env)\n{\n  size_t sz = HDR(addr)->hb_sz;\n  size_t lpw = BYTES_TO_PTRS(sz);\n  complex_descriptor *complex_d = get_complex_descr((ptr_t *)addr, lpw);\n  mse *orig_mark_stack_top = mark_stack_top;\n  mse *new_mark_stack_top;\n\n  UNUSED_ARG(env);\n  if (NULL == complex_d) {\n    /* Found a reference to a free-list entry.  Ignore it.      */\n    return orig_mark_stack_top;\n  }\n  /* In-use counts were already updated when array descriptor was       */\n  /* pushed.  Here we only replace it by subobject descriptors, so      */\n  /* no update is necessary.                                            */\n  new_mark_stack_top = GC_push_complex_descriptor(\n      (ptr_t)addr, complex_d, mark_stack_top, mark_stack_limit - 1);\n  if (NULL == new_mark_stack_top) {\n    /* Explicitly instruct Clang Static Analyzer that ptr is non-null.  */\n    if (NULL == mark_stack_top)\n      ABORT(\"Bad mark_stack_top\");\n\n      /* Does not fit.  Conservatively push the whole array as a unit and */\n      /* request a mark stack expansion.  This cannot cause a mark stack  */\n      /* overflow, since it replaces the original array entry.            */\n#ifdef PARALLEL_MARK\n    /* We might be using a local_mark_stack in parallel mode. */\n    if (GC_mark_stack + GC_mark_stack_size == mark_stack_limit)\n#endif\n    {\n      GC_mark_stack_too_small = TRUE;\n    }\n    new_mark_stack_top = orig_mark_stack_top + 1;\n    new_mark_stack_top->mse_start = (ptr_t)addr;\n    new_mark_stack_top->mse_descr = sz | GC_DS_LENGTH;\n  } else {\n    /* Push descriptor itself.  */\n    new_mark_stack_top++;\n    new_mark_stack_top->mse_start = (ptr_t)((ptr_t *)addr + lpw - 1);\n    new_mark_stack_top->mse_descr = sizeof(ptr_t) | GC_DS_LENGTH;\n  }\n  return new_mark_stack_top;\n}\n"
        },
        {
          "name": "win32_threads.c",
          "type": "blob",
          "size": 64.9921875,
          "content": "/*\n * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n * Copyright (c) 2000-2008 by Hewlett-Packard Development Company.\n * All rights reserved.\n * Copyright (c) 2008-2022 Ivan Maidanski\n *\n * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n *\n * Permission is hereby granted to use or copy this program\n * for any purpose, provided the above notices are retained on all copies.\n * Permission to modify the code and to distribute modified code is granted,\n * provided the above notices are retained, and a notice that the code was\n * modified is included with the above copyright notice.\n */\n\n#include \"private/pthread_support.h\"\n\n#if defined(GC_WIN32_THREADS)\n\n/* The allocator lock definition.       */\n#  ifndef USE_PTHREAD_LOCKS\n#    ifdef USE_RWLOCK\nGC_INNER SRWLOCK GC_allocate_ml;\n#    else\nGC_INNER CRITICAL_SECTION GC_allocate_ml;\n#    endif\n#  endif /* !USE_PTHREAD_LOCKS */\n\n#  undef CreateThread\n#  undef ExitThread\n#  undef _beginthreadex\n#  undef _endthreadex\n\n#  if !defined(GC_PTHREADS) && !defined(MSWINCE)\n#    include <errno.h>\n#    include <process.h> /* for _beginthreadex, _endthreadex */\n#  endif\n\nstatic ptr_t copy_ptr_regs(word *regs, const CONTEXT *pcontext);\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n/* This code operates in two distinct modes, depending on     */\n/* the setting of GC_win32_dll_threads.                       */\n/* If GC_win32_dll_threads is set, all threads in the process */\n/* are implicitly registered with the GC by DllMain.          */\n/* No explicit registration is required, and attempts at      */\n/* explicit registration are ignored.  This mode is           */\n/* very different from the Posix operation of the collector.  */\n/* In this mode access to the thread table is lock-free.      */\n/* Hence there is a static limit on the number of threads.    */\n\n/* GC_DISCOVER_TASK_THREADS should be used if DllMain-based   */\n/* thread registration is required but it is impossible to    */\n/* call GC_use_threads_discovery before other GC routines.    */\n\n#    ifndef GC_DISCOVER_TASK_THREADS\n/* GC_win32_dll_threads must be set (if needed) at the      */\n/* application initialization time, i.e. before any         */\n/* collector or thread calls.  We make it a \"dynamic\"       */\n/* option only to avoid multiple library versions.          */\nGC_INNER GC_bool GC_win32_dll_threads = FALSE;\n#    endif\n#  else\n/* If GC_win32_dll_threads is FALSE (or the collector is      */\n/* built without GC_DLL defined), things operate in a way     */\n/* that is very similar to Posix platforms, and new threads   */\n/* must be registered with the collector, e.g. by using       */\n/* preprocessor-based interception of the thread primitives.  */\n/* In this case, we use a real data structure for the thread  */\n/* table.  Note that there is no equivalent of linker-based   */\n/* call interception, since we don't have ELF-like            */\n/* facilities.  The Windows analog appears to be \"API         */\n/* hooking\", which really seems to be a standard way to       */\n/* do minor binary rewriting (?).  I'd prefer not to have     */\n/* the basic collector rely on such facilities, but an        */\n/* optional package that intercepts thread calls this way     */\n/* would probably be nice.                                    */\n#    undef MAX_THREADS\n/* dll_thread_table[] is always empty.        */\n#    define MAX_THREADS 1\n#  endif /* GC_NO_THREADS_DISCOVERY */\n\n/* We have two versions of the thread table.  Which one */\n/* we use depends on whether GC_win32_dll_threads       */\n/* is set.  Note that before initialization, we don't   */\n/* add any entries to either table, even if DllMain is  */\n/* called.  The main thread will be added on            */\n/* initialization.                                      */\n\n/* GC_use_threads_discovery() is currently incompatible with pthreads   */\n/* and WinCE.  It might be possible to get DllMain-based thread         */\n/* registration to work with Cygwin, but if you try it then you are on  */\n/* your own.                                                            */\nGC_API void GC_CALL\nGC_use_threads_discovery(void)\n{\n#  ifdef GC_NO_THREADS_DISCOVERY\n  ABORT(\"GC DllMain-based thread registration unsupported\");\n#  else\n  /* Turn on GC_win32_dll_threads. */\n  GC_ASSERT(!GC_is_initialized);\n  /* Note that GC_use_threads_discovery is expected to be called by   */\n  /* the client application (not from DllMain) at start-up.           */\n#    ifndef GC_DISCOVER_TASK_THREADS\n  GC_win32_dll_threads = TRUE;\n#    endif\n  GC_init();\n#    ifdef CPPCHECK\n  GC_noop1((word)(GC_funcptr_uint)(&GC_DllMain));\n#    endif\n#  endif\n}\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n/* We track thread attachments while the world is supposed to be      */\n/* stopped.  Unfortunately, we cannot stop them from starting, since  */\n/* blocking in DllMain seems to cause the world to deadlock.  Thus,   */\n/* we have to recover if we notice this in the middle of marking.     */\nSTATIC volatile AO_t GC_attached_thread = FALSE;\n\n/* We assume that volatile implies memory ordering, at least among    */\n/* volatiles.  This code should consistently use atomic_ops.          */\nSTATIC volatile GC_bool GC_please_stop = FALSE;\n#  elif defined(GC_ASSERTIONS)\nSTATIC GC_bool GC_please_stop = FALSE;\n#  endif /* GC_NO_THREADS_DISCOVERY && GC_ASSERTIONS */\n\n#  if defined(WRAP_MARK_SOME) && !defined(GC_PTHREADS)\n/* Return TRUE if an thread was attached since we last asked or */\n/* since GC_attached_thread was explicitly reset.               */\nGC_INNER GC_bool\nGC_started_thread_while_stopped(void)\n{\n#    ifndef GC_NO_THREADS_DISCOVERY\n  if (GC_win32_dll_threads) {\n#      ifdef AO_HAVE_compare_and_swap_release\n    if (AO_compare_and_swap_release(&GC_attached_thread, TRUE,\n                                    FALSE /* stored */))\n      return TRUE;\n#      else\n    /* Prior heap reads need to complete earlier. */\n    AO_nop_full();\n\n    if (AO_load(&GC_attached_thread)) {\n      AO_store(&GC_attached_thread, FALSE);\n      return TRUE;\n    }\n#      endif\n  }\n#    endif\n  return FALSE;\n}\n#  endif /* WRAP_MARK_SOME */\n\n/* Thread table used if GC_win32_dll_threads is set.    */\n/* This is a fixed size array.                          */\n/* Since we use runtime conditionals, both versions     */\n/* are always defined.                                  */\n#  ifndef MAX_THREADS\n#    define MAX_THREADS 512\n#  endif\n\n/* Things may get quite slow for large numbers of threads,      */\n/* since we look them up with sequential search.                */\nstatic volatile struct GC_Thread_Rep dll_thread_table[MAX_THREADS];\n#  ifndef GC_NO_THREADS_DISCOVERY\nstatic struct GC_StackContext_Rep dll_crtn_table[MAX_THREADS];\n#  endif\n\n/* Largest index in dll_thread_table that was ever used.                */\nSTATIC volatile LONG GC_max_thread_index = 0;\n\n/* This may be called from DllMain, and hence operates under unusual    */\n/* constraints.  In particular, it must be lock-free if                 */\n/* GC_win32_dll_threads is set.  Always called from the thread being    */\n/* added.  If GC_win32_dll_threads is not set, we already hold the      */\n/* allocator lock except possibly during single-threaded startup code.  */\n/* Does not initialize thread-local free lists.                         */\nGC_INNER GC_thread\nGC_register_my_thread_inner(const struct GC_stack_base *sb,\n                            thread_id_t self_id)\n{\n  GC_thread me;\n\n#  ifdef GC_NO_THREADS_DISCOVERY\n  GC_ASSERT(I_HOLD_LOCK());\n#  endif\n  /* The following should be a no-op according to the Win32     */\n  /* documentation.  There is empirical evidence that it        */\n  /* isn't. - HB                                                */\n#  if defined(MPROTECT_VDB) && !defined(CYGWIN32)\n  if (GC_auto_incremental\n#    ifdef GWW_VDB\n      && !GC_gww_dirty_init()\n#    endif\n  )\n    GC_set_write_fault_handler();\n#  endif\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n  if (GC_win32_dll_threads) {\n    int i;\n    /* It appears to be unsafe to acquire a lock here, since this     */\n    /* code is apparently not preemptible on some systems.            */\n    /* (This is based on complaints, not on Microsoft's official      */\n    /* documentation, which says this should perform \"only simple     */\n    /* initialization tasks\".)                                        */\n    /* Hence we make do with nonblocking synchronization.             */\n    /* It has been claimed that DllMain is really only executed with  */\n    /* a particular system lock held, and thus careful use of locking */\n    /* around code that doesn't call back into the system libraries   */\n    /* might be OK.  But this has not been tested across all Win32    */\n    /* variants.                                                      */\n    for (i = 0;\n         InterlockedExchange(&dll_thread_table[i].tm.long_in_use, 1) != 0;\n         i++) {\n      /* Compare-and-swap would make this cleaner, but that's not     */\n      /* supported before Windows 98 and NT 4.0.  In Windows 2000,    */\n      /* InterlockedExchange is supposed to be replaced by            */\n      /* InterlockedExchangePointer, but that's not really what I     */\n      /* want here.                                                   */\n      /* FIXME: We should eventually declare Windows 95 dead and use  */\n      /* AO_ primitives here.                                         */\n      if (i == MAX_THREADS - 1)\n        ABORT(\"Too many threads\");\n    }\n    /* Update GC_max_thread_index if necessary.  The following is     */\n    /* safe, and unlike CompareExchange-based solutions seems to work */\n    /* on all Windows 95 and later platforms.  Unfortunately,         */\n    /* GC_max_thread_index may be temporarily out of bounds, so       */\n    /* readers have to compensate.                                    */\n    while (i > GC_max_thread_index) {\n      InterlockedIncrement((LONG *)&GC_max_thread_index);\n      /* Cast away volatile for older versions of Win32 headers. */\n    }\n    if (EXPECT(GC_max_thread_index >= MAX_THREADS, FALSE)) {\n      /* We overshot due to simultaneous increments.  */\n      /* Setting it to MAX_THREADS-1 is always safe.  */\n      GC_max_thread_index = MAX_THREADS - 1;\n    }\n    me = (GC_thread)(dll_thread_table + i);\n    me->crtn = &dll_crtn_table[i];\n  } else\n#  endif\n  /* else */ {\n    /* Not using DllMain.       */\n    me = GC_new_thread(self_id);\n  }\n#  ifdef GC_PTHREADS\n  me->pthread_id = pthread_self();\n#  endif\n#  ifndef MSWINCE\n  /* GetCurrentThread() returns a pseudohandle (a const value).       */\n  if (!DuplicateHandle(GetCurrentProcess(), GetCurrentThread(),\n                       GetCurrentProcess(), (HANDLE *)&me->handle,\n                       0 /* dwDesiredAccess */, FALSE /* bInheritHandle */,\n                       DUPLICATE_SAME_ACCESS)) {\n    ABORT_ARG1(\"DuplicateHandle failed\", \": errcode= 0x%X\",\n               (unsigned)GetLastError());\n  }\n#  endif\n#  if defined(WOW64_THREAD_CONTEXT_WORKAROUND) && defined(MSWINRT_FLAVOR)\n  /* Lookup TIB value via a call to NtCurrentTeb() on thread          */\n  /* registration rather than calling GetThreadSelectorEntry() which  */\n  /* is not available on UWP.                                         */\n  me->tib = (GC_NT_TIB *)NtCurrentTeb();\n#  endif\n  me->crtn->last_stack_min = ADDR_LIMIT;\n  GC_record_stack_base(me->crtn, sb);\n  /* Up until this point, GC_push_all_stacks considers this thread      */\n  /* invalid.  And, up until this point, the entry is viewed by         */\n  /* GC_win32_dll_lookup_thread as reserved but invalid.                */\n  ((volatile struct GC_Thread_Rep *)me)->id = self_id;\n#  ifndef GC_NO_THREADS_DISCOVERY\n  if (GC_win32_dll_threads) {\n    if (GC_please_stop) {\n      AO_store(&GC_attached_thread, TRUE);\n      AO_nop_full(); /* Later updates must become visible after this. */\n    }\n    /* We'd like to wait here, but cannot, since waiting in DllMain   */\n    /* provokes deadlocks.  Thus we force marking to be restarted     */\n    /* instead.                                                       */\n  } else\n#  endif\n  /* else */ {\n    /* GC_please_stop is false, otherwise both we and the               */\n    /* thread-stopping code would be holding the allocator lock.        */\n    GC_ASSERT(!GC_please_stop);\n  }\n  return me;\n}\n\n/* GC_max_thread_index may temporarily be larger than MAX_THREADS.      */\n/* To avoid subscript errors, we check it on access.                    */\nGC_INLINE LONG\nGC_get_max_thread_index(void)\n{\n  LONG my_max = GC_max_thread_index;\n  if (EXPECT(my_max >= MAX_THREADS, FALSE))\n    return MAX_THREADS - 1;\n  return my_max;\n}\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n/* Search in dll_thread_table and return the GC_thread entity         */\n/* corresponding to the given thread id.                              */\n/* May be called without a lock, but should be called in contexts in  */\n/* which the requested thread cannot be asynchronously deleted, e.g.  */\n/* from the thread itself.                                            */\nGC_INNER GC_thread\nGC_win32_dll_lookup_thread(thread_id_t id)\n{\n  int i;\n  LONG my_max = GC_get_max_thread_index();\n\n  GC_ASSERT(GC_win32_dll_threads);\n  for (i = 0; i <= my_max; i++) {\n    if (AO_load_acquire(&dll_thread_table[i].tm.in_use)\n        && dll_thread_table[i].id == id) {\n      /* Must still be in use, since nobody else can store our      */\n      /* thread id.                                                 */\n      break;\n    }\n  }\n  return i <= my_max ? (GC_thread)(dll_thread_table + i) : NULL;\n}\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\n#  ifdef GC_PTHREADS\n/* A quick-and-dirty cache of the mapping between pthread_t   */\n/* and Win32 thread id.                                       */\n#    define PTHREAD_MAP_SIZE 512\nthread_id_t GC_pthread_map_cache[PTHREAD_MAP_SIZE] = { 0 };\n/* It appears pthread_t is really a pointer type ...          */\n#    define PTHREAD_MAP_INDEX(pthread_id) \\\n      ((NUMERIC_THREAD_ID(pthread_id) >> 5) % PTHREAD_MAP_SIZE)\n#    define SET_PTHREAD_MAP_CACHE(pthread_id, win32_id) \\\n      (void)(GC_pthread_map_cache[PTHREAD_MAP_INDEX(pthread_id)] = (win32_id))\n#    define GET_PTHREAD_MAP_CACHE(pthread_id) \\\n      GC_pthread_map_cache[PTHREAD_MAP_INDEX(pthread_id)]\n\nGC_INNER void\nGC_win32_cache_self_pthread(thread_id_t self_id)\n{\n  pthread_t self = pthread_self();\n\n  GC_ASSERT(I_HOLD_LOCK());\n  SET_PTHREAD_MAP_CACHE(self, self_id);\n}\n\n/* Return a GC_thread corresponding to a given pthread_t, or  */\n/* NULL if it is not there.  We assume that this is only      */\n/* called for pthread ids that have not yet terminated or are */\n/* still joinable, and cannot be terminated concurrently.     */\nGC_INNER GC_thread\nGC_lookup_by_pthread(pthread_t thread)\n{\n  /* TODO: search in dll_thread_table instead when DllMain-based    */\n  /* thread registration is made compatible with pthreads (and      */\n  /* turned on).                                                    */\n  thread_id_t id;\n  GC_thread p;\n  int hv;\n\n  GC_ASSERT(I_HOLD_READER_LOCK());\n  id = GET_PTHREAD_MAP_CACHE(thread);\n  /* We first try the cache.        */\n  for (p = GC_threads[THREAD_TABLE_INDEX(id)]; p != NULL; p = p->tm.next) {\n    if (EXPECT(THREAD_EQUAL(p->pthread_id, thread), TRUE))\n      return p;\n  }\n\n  /* If that fails, we use a very slow approach.    */\n  for (hv = 0; hv < THREAD_TABLE_SZ; ++hv) {\n    for (p = GC_threads[hv]; p != NULL; p = p->tm.next) {\n      if (THREAD_EQUAL(p->pthread_id, thread))\n        return p;\n    }\n  }\n  return NULL;\n}\n#  endif /* GC_PTHREADS */\n\n#  ifdef WOW64_THREAD_CONTEXT_WORKAROUND\n#    ifndef CONTEXT_EXCEPTION_ACTIVE\n#      define CONTEXT_EXCEPTION_ACTIVE 0x08000000\n#      define CONTEXT_EXCEPTION_REQUEST 0x40000000\n#      define CONTEXT_EXCEPTION_REPORTING 0x80000000\n#    endif\n/* Is 32-bit code running on Win64?   */\nstatic GC_bool isWow64;\n#    define GET_THREAD_CONTEXT_FLAGS                                \\\n      (isWow64 ? CONTEXT_INTEGER | CONTEXT_CONTROL                  \\\n                     | CONTEXT_EXCEPTION_REQUEST | CONTEXT_SEGMENTS \\\n               : CONTEXT_INTEGER | CONTEXT_CONTROL)\n#  elif defined(I386) || defined(XMM_CANT_STORE_PTRS)\n#    define GET_THREAD_CONTEXT_FLAGS (CONTEXT_INTEGER | CONTEXT_CONTROL)\n#  else\n#    define GET_THREAD_CONTEXT_FLAGS \\\n      (CONTEXT_INTEGER | CONTEXT_CONTROL | CONTEXT_FLOATING_POINT)\n#  endif /* !WOW64_THREAD_CONTEXT_WORKAROUND && !I386 */\n\n/* Suspend the given thread, if it's still active.      */\nSTATIC void\nGC_suspend(GC_thread t)\n{\n#  ifndef MSWINCE\n  DWORD exitCode;\n#    ifdef RETRY_GET_THREAD_CONTEXT\n  int retry_cnt;\n#      define MAX_SUSPEND_THREAD_RETRIES (1000 * 1000)\n#    endif\n#  endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n#  if defined(DEBUG_THREADS) && !defined(MSWINCE) \\\n      && (!defined(MSWIN32) || defined(CONSOLE_LOG))\n  GC_log_printf(\"Suspending 0x%x\\n\", (int)t->id);\n#  endif\n  GC_win32_unprotect_thread(t);\n  GC_acquire_dirty_lock();\n\n#  ifdef MSWINCE\n  /* SuspendThread() will fail if thread is running kernel code.      */\n  while (SuspendThread(THREAD_HANDLE(t)) == (DWORD)-1) {\n    GC_release_dirty_lock();\n    Sleep(10); /* in millis */\n    GC_acquire_dirty_lock();\n  }\n#  elif defined(RETRY_GET_THREAD_CONTEXT)\n  for (retry_cnt = 0;;) {\n    /* Apparently the Windows 95 GetOpenFileName call creates         */\n    /* a thread that does not properly get cleaned up, and            */\n    /* SuspendThread on its descriptor may provoke a crash.           */\n    /* This reduces the probability of that event, though it still    */\n    /* appears there is a race here.                                  */\n    if (GetExitCodeThread(t->handle, &exitCode) && exitCode != STILL_ACTIVE) {\n      GC_release_dirty_lock();\n#    ifdef GC_PTHREADS\n      /* Prevent stack from being pushed.   */\n      t->crtn->stack_end = NULL;\n#    else\n      /* This breaks pthread_join on Cygwin, which is guaranteed to */\n      /* only see user threads.                                     */\n      GC_delete_thread(t);\n#    endif\n      return;\n    }\n\n    if (SuspendThread(t->handle) != (DWORD)-1) {\n      CONTEXT context;\n\n      context.ContextFlags = GET_THREAD_CONTEXT_FLAGS;\n      if (GetThreadContext(t->handle, &context)) {\n        /* TODO: WoW64 extra workaround: if CONTEXT_EXCEPTION_ACTIVE  */\n        /* then Sleep(1) and retry.                                   */\n        t->context_sp = copy_ptr_regs(t->context_regs, &context);\n        /* Success; the context pointer registers are saved.  */\n        break;\n      }\n\n      /* Resume the thread, try to suspend it in a better location.   */\n      if (ResumeThread(t->handle) == (DWORD)-1)\n        ABORT(\"ResumeThread failed in suspend loop\");\n    }\n    if (retry_cnt > 1) {\n      GC_release_dirty_lock();\n      Sleep(0); /* yield */\n      GC_acquire_dirty_lock();\n    }\n    if (++retry_cnt >= MAX_SUSPEND_THREAD_RETRIES) {\n      /* Something must be wrong.     */\n      ABORT(\"SuspendThread loop failed\");\n    }\n  }\n#  else\n  if (GetExitCodeThread(t->handle, &exitCode) && exitCode != STILL_ACTIVE) {\n    GC_release_dirty_lock();\n#    ifdef GC_PTHREADS\n    /* Prevent stack from being pushed.     */\n    t->crtn->stack_end = NULL;\n#    else\n    GC_delete_thread(t);\n#    endif\n    return;\n  }\n  if (SuspendThread(t->handle) == (DWORD)-1)\n    ABORT(\"SuspendThread failed\");\n#  endif\n  t->flags |= IS_SUSPENDED;\n  GC_release_dirty_lock();\n  if (GC_on_thread_event)\n    GC_on_thread_event(GC_EVENT_THREAD_SUSPENDED, THREAD_HANDLE(t));\n}\n\n#  if defined(GC_ASSERTIONS) \\\n      && ((defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE))\n/* Note: set to true only if GC_stop_world() has acquired GC_write_cs. */\nGC_INNER GC_bool GC_write_disabled = FALSE;\n#  endif\n\nGC_INNER void\nGC_stop_world(void)\n{\n  thread_id_t self_id = GetCurrentThreadId();\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_thr_initialized);\n\n  /* This code is the same as in pthread_stop_world.c.  */\n#  ifdef PARALLEL_MARK\n  if (GC_parallel) {\n    GC_acquire_mark_lock();\n    /* We should have previously waited for the count to become zero. */\n    GC_ASSERT(0 == GC_fl_builder_count);\n  }\n#  endif /* PARALLEL_MARK */\n\n#  if !defined(GC_NO_THREADS_DISCOVERY) || defined(GC_ASSERTIONS)\n  GC_please_stop = TRUE;\n#  endif\n#  if (defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE)\n  GC_ASSERT(!GC_write_disabled);\n  EnterCriticalSection(&GC_write_cs);\n  /* It's not allowed to call GC_printf() (and friends) here down to  */\n  /* LeaveCriticalSection (same applies recursively to GC_suspend,    */\n  /* GC_delete_thread, GC_get_max_thread_index, GC_size and           */\n  /* GC_remove_protection).                                           */\n#    ifdef GC_ASSERTIONS\n  GC_write_disabled = TRUE;\n#    endif\n#  endif\n#  ifndef GC_NO_THREADS_DISCOVERY\n  if (GC_win32_dll_threads) {\n    int i;\n    int my_max;\n    /* Any threads being created during this loop will end up setting */\n    /* GC_attached_thread when they start.  This will force marking   */\n    /* to restart.  This is not ideal, but hopefully correct.         */\n    AO_store(&GC_attached_thread, FALSE);\n    my_max = (int)GC_get_max_thread_index();\n    for (i = 0; i <= my_max; i++) {\n      GC_thread p = (GC_thread)(dll_thread_table + i);\n\n      if (p->crtn->stack_end != NULL && (p->flags & DO_BLOCKING) == 0\n          && p->id != self_id) {\n        GC_suspend(p);\n      }\n    }\n  } else\n#  endif\n  /* else */ {\n    GC_thread p;\n    int i;\n\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next)\n        if (p->crtn->stack_end != NULL && p->id != self_id\n            && (p->flags & (FINISHED | DO_BLOCKING)) == 0)\n          GC_suspend(p);\n    }\n  }\n#  if (defined(MSWIN32) && !defined(CONSOLE_LOG)) || defined(MSWINCE)\n#    ifdef GC_ASSERTIONS\n  GC_write_disabled = FALSE;\n#    endif\n  LeaveCriticalSection(&GC_write_cs);\n#  endif\n#  ifdef PARALLEL_MARK\n  if (GC_parallel)\n    GC_release_mark_lock();\n#  endif\n}\n\nGC_INNER void\nGC_start_world(void)\n{\n#  ifdef GC_ASSERTIONS\n  thread_id_t self_id = GetCurrentThreadId();\n#  endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (GC_win32_dll_threads) {\n    LONG my_max = GC_get_max_thread_index();\n    int i;\n\n    for (i = 0; i <= my_max; i++) {\n      GC_thread p = (GC_thread)(dll_thread_table + i);\n\n      if ((p->flags & IS_SUSPENDED) != 0) {\n#  ifdef DEBUG_THREADS\n        GC_log_printf(\"Resuming 0x%x\\n\", (int)p->id);\n#  endif\n        GC_ASSERT(p->id != self_id);\n        GC_ASSERT(*(ptr_t *)CAST_AWAY_VOLATILE_PVOID(&p->crtn->stack_end)\n                  != NULL);\n        if (ResumeThread(THREAD_HANDLE(p)) == (DWORD)-1)\n          ABORT(\"ResumeThread failed\");\n        p->flags &= (unsigned char)~IS_SUSPENDED;\n        if (GC_on_thread_event)\n          GC_on_thread_event(GC_EVENT_THREAD_UNSUSPENDED, THREAD_HANDLE(p));\n      } else {\n        /* The thread is unregistered or not suspended. */\n      }\n    }\n  } else {\n    GC_thread p;\n    int i;\n\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        if ((p->flags & IS_SUSPENDED) != 0) {\n#  ifdef DEBUG_THREADS\n          GC_log_printf(\"Resuming 0x%x\\n\", (int)p->id);\n#  endif\n          GC_ASSERT(p->id != self_id && *(ptr_t *)&p->crtn->stack_end != NULL);\n          if (ResumeThread(THREAD_HANDLE(p)) == (DWORD)-1)\n            ABORT(\"ResumeThread failed\");\n          GC_win32_unprotect_thread(p);\n          p->flags &= (unsigned char)~IS_SUSPENDED;\n          if (GC_on_thread_event)\n            GC_on_thread_event(GC_EVENT_THREAD_UNSUSPENDED, THREAD_HANDLE(p));\n        } else {\n#  ifdef DEBUG_THREADS\n          GC_log_printf(\"Not resuming thread 0x%x as it is not suspended\\n\",\n                        (int)p->id);\n#  endif\n        }\n      }\n    }\n  }\n#  if !defined(GC_NO_THREADS_DISCOVERY) || defined(GC_ASSERTIONS)\n  GC_please_stop = FALSE;\n#  endif\n}\n\n#  ifdef MSWINCE\n/* The VirtualQuery calls below won't work properly on some old WinCE */\n/* versions, but since each stack is restricted to an aligned 64 KiB  */\n/* region of virtual memory we can just take the next lowest multiple */\n/* of 64 KiB.  The result of this macro must not be used as its       */\n/* argument later and must not be used as the lower bound for sp      */\n/* check (since the stack may be bigger than 64 KiB).                 */\n#    define GC_wince_evaluate_stack_min(s) \\\n      (ptr_t)(((word)(s)-1) & ~(word)0xFFFF)\n#  elif defined(GC_ASSERTIONS)\n#    define GC_dont_query_stack_min FALSE\n#  endif\n\n/* A cache holding the results of the recent VirtualQuery call. */\n/* Protected by the allocator lock.                             */\nstatic ptr_t last_address = 0;\nstatic MEMORY_BASIC_INFORMATION last_info;\n\n/* Probe stack memory region (starting at \"s\") to find out its  */\n/* lowest address (i.e. stack top).                             */\n/* S must be a mapped address inside the region, NOT the first  */\n/* unmapped address.                                            */\nSTATIC ptr_t\nGC_get_stack_min(ptr_t s)\n{\n  ptr_t bottom;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (s != last_address) {\n    VirtualQuery(s, &last_info, sizeof(last_info));\n    last_address = s;\n  }\n  do {\n    bottom = (ptr_t)last_info.BaseAddress;\n    VirtualQuery(bottom - 1, &last_info, sizeof(last_info));\n    last_address = bottom - 1;\n  } while ((last_info.Protect & PAGE_READWRITE)\n           && !(last_info.Protect & PAGE_GUARD));\n  return bottom;\n}\n\n/* Return true if the page at s has protections appropriate     */\n/* for a stack page.                                            */\nstatic GC_bool\nmay_be_in_stack(ptr_t s)\n{\n  GC_ASSERT(I_HOLD_LOCK());\n  if (s != last_address) {\n    VirtualQuery(s, &last_info, sizeof(last_info));\n    last_address = s;\n  }\n  return (last_info.Protect & PAGE_READWRITE)\n         && !(last_info.Protect & PAGE_GUARD);\n}\n\n/* Copy all registers that might point into the heap.  Frame    */\n/* pointer registers are included in case client code was       */\n/* compiled with the 'omit frame pointer' optimization.         */\n/* The context register values are stored to regs argument      */\n/* which is expected to be of PUSHED_REGS_COUNT length exactly. */\n/* The functions returns the context stack pointer value.       */\nstatic ptr_t\ncopy_ptr_regs(word *regs, const CONTEXT *pcontext)\n{\n  ptr_t sp;\n  int cnt = 0;\n#  define context (*pcontext)\n#  define PUSH1(reg) (regs[cnt++] = (word)pcontext->reg)\n#  define PUSH2(r1, r2) (PUSH1(r1), PUSH1(r2))\n#  define PUSH4(r1, r2, r3, r4) (PUSH2(r1, r2), PUSH2(r3, r4))\n#  define PUSH8_LH(r1, r2, r3, r4)            \\\n    (PUSH4(r1.Low, r1.High, r2.Low, r2.High), \\\n     PUSH4(r3.Low, r3.High, r4.Low, r4.High))\n#  if defined(I386)\n#    ifdef WOW64_THREAD_CONTEXT_WORKAROUND\n  /* Notes: these should be the first \"pushed\" registers, exactly */\n  /* in this order, see the WoW64 logic in GC_push_stack_for();   */\n  /* these registers do not contain pointers.                     */\n  PUSH2(ContextFlags, SegFs);\n#    endif\n  PUSH4(Edi, Esi, Ebx, Edx), PUSH2(Ecx, Eax), PUSH1(Ebp);\n  sp = (ptr_t)context.Esp;\n#  elif defined(X86_64)\n  PUSH4(Rax, Rcx, Rdx, Rbx);\n  PUSH2(Rbp, Rsi);\n  PUSH1(Rdi);\n  PUSH4(R8, R9, R10, R11);\n  PUSH4(R12, R13, R14, R15);\n#    ifndef XMM_CANT_STORE_PTRS\n  PUSH8_LH(Xmm0, Xmm1, Xmm2, Xmm3);\n  PUSH8_LH(Xmm4, Xmm5, Xmm6, Xmm7);\n  PUSH8_LH(Xmm8, Xmm9, Xmm10, Xmm11);\n  PUSH8_LH(Xmm12, Xmm13, Xmm14, Xmm15);\n#    endif\n  sp = (ptr_t)context.Rsp;\n#  elif defined(ARM32)\n  PUSH4(R0, R1, R2, R3), PUSH4(R4, R5, R6, R7), PUSH4(R8, R9, R10, R11);\n  PUSH1(R12);\n  sp = (ptr_t)context.Sp;\n#  elif defined(AARCH64)\n  PUSH4(X0, X1, X2, X3), PUSH4(X4, X5, X6, X7), PUSH4(X8, X9, X10, X11);\n  PUSH4(X12, X13, X14, X15), PUSH4(X16, X17, X18, X19),\n      PUSH4(X20, X21, X22, X23);\n  PUSH4(X24, X25, X26, X27), PUSH1(X28);\n  PUSH1(Lr);\n  sp = (ptr_t)context.Sp;\n#  elif defined(SHx)\n  PUSH4(R0, R1, R2, R3), PUSH4(R4, R5, R6, R7), PUSH4(R8, R9, R10, R11);\n  PUSH2(R12, R13), PUSH1(R14);\n  sp = (ptr_t)context.R15;\n#  elif defined(MIPS)\n  PUSH4(IntAt, IntV0, IntV1, IntA0), PUSH4(IntA1, IntA2, IntA3, IntT0);\n  PUSH4(IntT1, IntT2, IntT3, IntT4), PUSH4(IntT5, IntT6, IntT7, IntS0);\n  PUSH4(IntS1, IntS2, IntS3, IntS4), PUSH4(IntS5, IntS6, IntS7, IntT8);\n  PUSH4(IntT9, IntK0, IntK1, IntS8);\n  sp = (ptr_t)context.IntSp;\n#  elif defined(PPC)\n  PUSH4(Gpr0, Gpr3, Gpr4, Gpr5), PUSH4(Gpr6, Gpr7, Gpr8, Gpr9);\n  PUSH4(Gpr10, Gpr11, Gpr12, Gpr14), PUSH4(Gpr15, Gpr16, Gpr17, Gpr18);\n  PUSH4(Gpr19, Gpr20, Gpr21, Gpr22), PUSH4(Gpr23, Gpr24, Gpr25, Gpr26);\n  PUSH4(Gpr27, Gpr28, Gpr29, Gpr30), PUSH1(Gpr31);\n  sp = (ptr_t)context.Gpr1;\n#  elif defined(ALPHA)\n  PUSH4(IntV0, IntT0, IntT1, IntT2), PUSH4(IntT3, IntT4, IntT5, IntT6);\n  PUSH4(IntT7, IntS0, IntS1, IntS2), PUSH4(IntS3, IntS4, IntS5, IntFp);\n  PUSH4(IntA0, IntA1, IntA2, IntA3), PUSH4(IntA4, IntA5, IntT8, IntT9);\n  PUSH4(IntT10, IntT11, IntT12, IntAt);\n  sp = (ptr_t)context.IntSp;\n#  elif defined(CPPCHECK)\n  GC_noop1_ptr(regs);\n  sp = (ptr_t)(word)cnt; /* to workaround \"cnt not used\" false positive */\n#  else\n#    error Architecture is not supported\n#  endif\n#  undef context\n#  undef PUSH1\n#  undef PUSH2\n#  undef PUSH4\n#  undef PUSH8_LH\n  GC_ASSERT(cnt == PUSHED_REGS_COUNT);\n  return sp;\n}\n\nSTATIC word\nGC_push_stack_for(GC_thread thread, thread_id_t self_id, GC_bool *pfound_me)\n{\n  GC_bool is_self = FALSE;\n  ptr_t sp, stack_min;\n  GC_stack_context_t crtn = thread->crtn;\n  ptr_t stack_end = crtn->stack_end;\n  struct GC_traced_stack_sect_s *traced_stack_sect = crtn->traced_stack_sect;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  if (EXPECT(NULL == stack_end, FALSE))\n    return 0;\n\n  if (thread->id == self_id) {\n    GC_ASSERT((thread->flags & DO_BLOCKING) == 0);\n    sp = GC_approx_sp();\n    is_self = TRUE;\n    *pfound_me = TRUE;\n  } else if ((thread->flags & DO_BLOCKING) != 0) {\n    /* Use saved sp value for blocked threads.  */\n    sp = crtn->stack_ptr;\n  } else {\n#  ifdef RETRY_GET_THREAD_CONTEXT\n    /* We cache context when suspending the thread since it may       */\n    /* require looping.                                               */\n    word *regs = thread->context_regs;\n\n    if ((thread->flags & IS_SUSPENDED) != 0) {\n      sp = thread->context_sp;\n    } else\n#  else\n    word regs[PUSHED_REGS_COUNT];\n#  endif\n\n    /* else */ {\n      CONTEXT context;\n\n      /* For unblocked threads call GetThreadContext().       */\n      context.ContextFlags = GET_THREAD_CONTEXT_FLAGS;\n      if (GetThreadContext(THREAD_HANDLE(thread), &context)) {\n        sp = copy_ptr_regs(regs, &context);\n      } else {\n#  ifdef RETRY_GET_THREAD_CONTEXT\n        /* At least, try to use the stale context if saved. */\n        sp = thread->context_sp;\n        if (NULL == sp) {\n          /* Skip the current thread, anyway its stack will */\n          /* be pushed when the world is stopped.           */\n          return 0;\n        }\n#  else\n        /* This is to avoid \"might be uninitialized\" compiler warning. */\n        *(volatile ptr_t *)&sp = NULL;\n        ABORT(\"GetThreadContext failed\");\n#  endif\n      }\n    }\n#  ifdef THREAD_LOCAL_ALLOC\n    GC_ASSERT((thread->flags & IS_SUSPENDED) != 0 || !GC_world_stopped);\n#  endif\n\n#  ifndef WOW64_THREAD_CONTEXT_WORKAROUND\n    GC_push_many_regs(regs, PUSHED_REGS_COUNT);\n#  else\n    GC_push_many_regs(regs + 2, PUSHED_REGS_COUNT - 2);\n    /* skip ContextFlags and SegFs */\n\n    /* WoW64 workaround. */\n    if (isWow64) {\n      DWORD ContextFlags = (DWORD)regs[0];\n\n      if ((ContextFlags & CONTEXT_EXCEPTION_REPORTING) != 0\n          && (ContextFlags\n              & (CONTEXT_EXCEPTION_ACTIVE\n                 /* | CONTEXT_SERVICE_ACTIVE */))\n                 != 0) {\n        GC_NT_TIB *tib;\n\n#    ifdef MSWINRT_FLAVOR\n        tib = thread->tib;\n#    else\n        WORD SegFs = (WORD)regs[1];\n        LDT_ENTRY selector;\n\n        if (!GetThreadSelectorEntry(THREAD_HANDLE(thread), SegFs, &selector))\n          ABORT(\"GetThreadSelectorEntry failed\");\n        tib = (GC_NT_TIB *)(selector.BaseLow\n                            | (selector.HighWord.Bits.BaseMid << 16)\n                            | (selector.HighWord.Bits.BaseHi << 24));\n#    endif\n#    ifdef DEBUG_THREADS\n        GC_log_printf(\"TIB stack limit/base: %p .. %p\\n\",\n                      (void *)tib->StackLimit, (void *)tib->StackBase);\n#    endif\n        GC_ASSERT(!HOTTER_THAN((ptr_t)tib->StackBase, stack_end));\n        if (stack_end != crtn->initial_stack_base\n            /* We are in a coroutine (old-style way of the support).  */\n            && (ADDR(stack_end) <= (word)tib->StackLimit\n                || (word)tib->StackBase < ADDR(stack_end))) {\n          /* The coroutine stack is not within TIB stack.   */\n          WARN(\"GetThreadContext might return stale register values\"\n               \" including ESP= %p\\n\",\n               sp);\n          /* TODO: Because of WoW64 bug, there is no guarantee that   */\n          /* sp really points to the stack top but, for now, we do    */\n          /* our best as the TIB stack limit/base cannot be used      */\n          /* while we are inside a coroutine.                         */\n        } else {\n          /* GetThreadContext() might return stale register values,   */\n          /* so we scan the entire stack region (down to the stack    */\n          /* limit).  There is no 100% guarantee that all the         */\n          /* registers are pushed but we do our best (the proper      */\n          /* solution would be to fix it inside Windows).             */\n          sp = (ptr_t)tib->StackLimit;\n        }\n      } /* else */\n#    ifdef DEBUG_THREADS\n      else {\n        static GC_bool logged;\n        if (!logged && (ContextFlags & CONTEXT_EXCEPTION_REPORTING) == 0) {\n          GC_log_printf(\"CONTEXT_EXCEPTION_REQUEST not supported\\n\");\n          logged = TRUE;\n        }\n      }\n#    endif\n    }\n#  endif /* WOW64_THREAD_CONTEXT_WORKAROUND */\n  }\n#  if defined(STACKPTR_CORRECTOR_AVAILABLE) && defined(GC_PTHREADS)\n  if (GC_sp_corrector != 0)\n    GC_sp_corrector((void **)&sp, PTHREAD_TO_VPTR(thread->pthread_id));\n#  endif\n\n  /* Set stack_min to the lowest address in the thread stack,   */\n  /* or to an address in the thread stack no larger than sp,    */\n  /* taking advantage of the old value to avoid slow traversals */\n  /* of large stacks.                                           */\n  if (crtn->last_stack_min == ADDR_LIMIT) {\n#  ifdef MSWINCE\n    if (GC_dont_query_stack_min) {\n      stack_min = GC_wince_evaluate_stack_min(\n          traced_stack_sect != NULL ? (ptr_t)traced_stack_sect : stack_end);\n      /* Keep last_stack_min value unmodified. */\n    } else\n#  endif\n    /* else */ {\n      stack_min = GC_get_stack_min(\n          traced_stack_sect != NULL ? (ptr_t)traced_stack_sect : stack_end);\n      GC_win32_unprotect_thread(thread);\n      crtn->last_stack_min = stack_min;\n    }\n  } else {\n    /* First, adjust the latest known minimum stack address if we       */\n    /* are inside GC_call_with_gc_active().                             */\n    if (traced_stack_sect != NULL\n        && ADDR_LT((ptr_t)traced_stack_sect, crtn->last_stack_min)) {\n      GC_win32_unprotect_thread(thread);\n      crtn->last_stack_min = (ptr_t)traced_stack_sect;\n    }\n\n    if (ADDR_INSIDE(sp, crtn->last_stack_min, stack_end)) {\n      stack_min = sp;\n    } else {\n      /* In the current thread it is always safe to use sp value.       */\n      if (may_be_in_stack(is_self && ADDR_LT(sp, crtn->last_stack_min)\n                              ? sp\n                              : crtn->last_stack_min)) {\n        stack_min = (ptr_t)last_info.BaseAddress;\n        /* Do not probe rest of the stack if sp is correct. */\n        if (!ADDR_INSIDE(sp, stack_min, stack_end))\n          stack_min = GC_get_stack_min(crtn->last_stack_min);\n      } else {\n        /* Stack shrunk?  Is this possible? */\n        stack_min = GC_get_stack_min(stack_end);\n      }\n      GC_win32_unprotect_thread(thread);\n      crtn->last_stack_min = stack_min;\n    }\n  }\n\n  GC_ASSERT(GC_dont_query_stack_min || stack_min == GC_get_stack_min(stack_end)\n            || (ADDR_GE(sp, stack_min) && ADDR_LT(stack_min, stack_end)\n                && ADDR_LT(GC_get_stack_min(stack_end), stack_min)));\n\n  if (ADDR_INSIDE(sp, stack_min, stack_end)) {\n#  ifdef DEBUG_THREADS\n    GC_log_printf(\"Pushing stack for 0x%x from sp %p to %p from 0x%x\\n\",\n                  (int)thread->id, (void *)sp, (void *)stack_end,\n                  (int)self_id);\n#  endif\n    GC_push_all_stack_sections(sp, stack_end, traced_stack_sect);\n  } else {\n    /* If not current thread then it is possible for sp to point to     */\n    /* the guarded (untouched yet) page just below the current          */\n    /* stack_min of the thread.                                         */\n    if (is_self || ADDR_GE(sp, stack_end)\n        || ADDR_LT(sp + GC_page_size, stack_min))\n      WARN(\"Thread stack pointer %p out of range, pushing everything\\n\", sp);\n#  ifdef DEBUG_THREADS\n    GC_log_printf(\"Pushing stack for 0x%x from (min) %p to %p from 0x%x\\n\",\n                  (int)thread->id, (void *)stack_min, (void *)stack_end,\n                  (int)self_id);\n#  endif\n    /* Push everything - ignore \"traced stack section\" data.            */\n    GC_push_all_stack(stack_min, stack_end);\n  }\n  /* Note: stack grows down.    */\n  return stack_end - sp;\n}\n\n/* Should do exactly the right thing if the world is stopped; should    */\n/* not fail if it is not.                                               */\nGC_INNER void\nGC_push_all_stacks(void)\n{\n  thread_id_t self_id = GetCurrentThreadId();\n  GC_bool found_me = FALSE;\n#  ifndef SMALL_CONFIG\n  unsigned nthreads = 0;\n#  endif\n  word total_size = 0;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(GC_thr_initialized);\n#  ifndef GC_NO_THREADS_DISCOVERY\n  if (GC_win32_dll_threads) {\n    int i;\n    LONG my_max = GC_get_max_thread_index();\n\n    for (i = 0; i <= my_max; i++) {\n      GC_thread p = (GC_thread)(dll_thread_table + i);\n\n      if (p->tm.in_use) {\n#    ifndef SMALL_CONFIG\n        ++nthreads;\n#    endif\n        total_size += GC_push_stack_for(p, self_id, &found_me);\n      }\n    }\n  } else\n#  endif\n  /* else */ {\n    int i;\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      GC_thread p;\n\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        GC_ASSERT(THREAD_TABLE_INDEX(p->id) == i);\n        if (!KNOWN_FINISHED(p)) {\n#  ifndef SMALL_CONFIG\n          ++nthreads;\n#  endif\n          total_size += GC_push_stack_for(p, self_id, &found_me);\n        }\n      }\n    }\n  }\n#  ifndef SMALL_CONFIG\n  GC_VERBOSE_LOG_PRINTF(\n      \"Pushed %d thread stacks%s\\n\", nthreads,\n      GC_win32_dll_threads ? \" based on DllMain thread tracking\" : \"\");\n#  endif\n  if (!found_me && !GC_in_thread_creation)\n    ABORT(\"Collecting from unknown thread\");\n  GC_total_stacksize = total_size;\n}\n\n#  ifdef PARALLEL_MARK\n/* Last known minimum (hottest) address in stack (or ADDR_LIMIT if    */\n/* unset) for markers.                                                */\nGC_INNER ptr_t GC_marker_last_stack_min[MAX_MARKERS - 1] = { 0 };\n#  endif /* PARALLEL_MARK */\n\nGC_INNER void\nGC_get_next_stack(ptr_t start, ptr_t limit, ptr_t *plo, ptr_t *phi)\n{\n  int i;\n  /* Least in-range stack base. */\n  ptr_t current_min = ADDR_LIMIT;\n  /* Address of last_stack_min field for thread corresponding   */\n  /* to current_min.                                            */\n  ptr_t *plast_stack_min = NULL;\n  /* Either NULL or points to the thread's hash table entry     */\n  /* containing (*plast_stack_min).                             */\n  GC_thread thread = NULL;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  /* First set current_min, ignoring limit. */\n  if (GC_win32_dll_threads) {\n    LONG my_max = GC_get_max_thread_index();\n\n    for (i = 0; i <= my_max; i++) {\n      ptr_t stack_end = (ptr_t)dll_thread_table[i].crtn->stack_end;\n\n      if (ADDR_LT(start, stack_end) && ADDR_LT(stack_end, current_min)) {\n        /* Update address of last_stack_min. */\n        plast_stack_min = &dll_thread_table[i].crtn->last_stack_min;\n        current_min = stack_end;\n#  ifdef CPPCHECK\n        /* To avoid a warning that thread is always null.     */\n        thread = (GC_thread)&dll_thread_table[i];\n#  endif\n      }\n    }\n  } else {\n    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n      GC_thread p;\n\n      for (p = GC_threads[i]; p != NULL; p = p->tm.next) {\n        GC_stack_context_t crtn = p->crtn;\n        /* Note: the following is read of a volatile field.     */\n        ptr_t stack_end = crtn->stack_end;\n\n        if (ADDR_LT(start, stack_end) && ADDR_LT(stack_end, current_min)) {\n          /* Update address of last_stack_min. */\n          plast_stack_min = &crtn->last_stack_min;\n          /* Remember current thread to unprotect.      */\n          thread = p;\n          current_min = stack_end;\n        }\n      }\n    }\n#  ifdef PARALLEL_MARK\n    for (i = 0; i < GC_markers_m1; ++i) {\n      ptr_t s = GC_marker_sp[i];\n\n#    ifdef IA64\n      /* FIXME: not implemented */\n#    endif\n      if (ADDR_LT(start, s) && ADDR_LT(s, current_min)) {\n        GC_ASSERT(GC_marker_last_stack_min[i] != NULL);\n        plast_stack_min = &GC_marker_last_stack_min[i];\n        current_min = s;\n        /* Not a thread's hash table entry.   */\n        thread = NULL;\n      }\n    }\n#  endif\n  }\n\n  *phi = current_min;\n  if (current_min == ADDR_LIMIT) {\n    *plo = ADDR_LIMIT;\n    return;\n  }\n\n  GC_ASSERT(ADDR_LT(start, current_min) && plast_stack_min != NULL);\n#  ifdef MSWINCE\n  if (GC_dont_query_stack_min) {\n    *plo = GC_wince_evaluate_stack_min(current_min);\n    /* Keep last_stack_min value unmodified.  */\n    return;\n  }\n#  endif\n\n  if (ADDR_LT(limit, current_min) && !may_be_in_stack(limit)) {\n    /* Skip the rest since the memory region at limit address is        */\n    /* not a stack (so the lowest address of the found stack would      */\n    /* be above the limit value anyway).                                */\n    *plo = ADDR_LIMIT;\n    return;\n  }\n\n  /* Get the minimum address of the found stack by probing its memory   */\n  /* region starting from the recent known minimum (if set).            */\n  if (*plast_stack_min == ADDR_LIMIT || !may_be_in_stack(*plast_stack_min)) {\n    /* Unsafe to start from last_stack_min value. */\n    *plo = GC_get_stack_min(current_min);\n  } else {\n    /* Use the recent value to optimize search for min address. */\n    *plo = GC_get_stack_min(*plast_stack_min);\n  }\n\n  /* Remember current stack_min value. */\n  if (thread != NULL)\n    GC_win32_unprotect_thread(thread);\n  *plast_stack_min = *plo;\n}\n\n#  if defined(PARALLEL_MARK) && !defined(GC_PTHREADS_PARAMARK)\n\n#    ifndef MARK_THREAD_STACK_SIZE\n/* The default size of the marker's thread stack. */\n#      define MARK_THREAD_STACK_SIZE 0\n#    endif\n\n/* Events with manual reset (one for each mark helper).     */\nSTATIC HANDLE GC_marker_cv[MAX_MARKERS - 1] = { 0 };\n\n/* This table is used for mapping helper threads id to mark helper  */\n/* index (linear search is used since the mapping contains only     */\n/* a few entries).                                                  */\nGC_INNER thread_id_t GC_marker_Id[MAX_MARKERS - 1] = { 0 };\n\n/* mark_mutex_event, builder_cv, mark_cv are initialized in GC_thr_init. */\n\n/* Note: this event should be with auto-reset.      */\nstatic HANDLE mark_mutex_event = (HANDLE)0;\n\n/* Note: these events are with manual reset.        */\nstatic HANDLE builder_cv = (HANDLE)0;\nstatic HANDLE mark_cv = (HANDLE)0;\n\nGC_INNER void\nGC_start_mark_threads_inner(void)\n{\n  int i;\n\n  GC_ASSERT(I_HOLD_LOCK());\n  ASSERT_CANCEL_DISABLED();\n  if (GC_available_markers_m1 <= 0 || GC_parallel)\n    return;\n  GC_wait_for_gc_completion(TRUE);\n\n  GC_ASSERT(0 == GC_fl_builder_count);\n  /* Initialize GC_marker_cv[] fully before starting the    */\n  /* first helper thread.                                   */\n  GC_markers_m1 = GC_available_markers_m1;\n  for (i = 0; i < GC_markers_m1; ++i) {\n    if ((GC_marker_cv[i]\n         = CreateEvent(NULL /* attrs */, TRUE /* isManualReset */,\n                       FALSE /* initialState */, NULL /* name (A/W) */))\n        == (HANDLE)0)\n      ABORT(\"CreateEvent failed\");\n  }\n\n  for (i = 0; i < GC_markers_m1; ++i) {\n#    if defined(MSWINCE) || defined(MSWIN_XBOX1)\n    HANDLE handle;\n    DWORD thread_id;\n\n    GC_marker_last_stack_min[i] = ADDR_LIMIT;\n    /* There is no _beginthreadex() in WinCE. */\n    handle = CreateThread(NULL /* lpsa */,\n                          MARK_THREAD_STACK_SIZE /* ignored */, GC_mark_thread,\n                          NUMERIC_TO_VPTR(i), 0 /* fdwCreate */, &thread_id);\n    if (EXPECT(NULL == handle, FALSE)) {\n      WARN(\"Marker thread %\" WARN_PRIdPTR \" creation failed\\n\",\n           (GC_signed_word)i);\n      /* The most probable failure reason is \"not enough memory\". */\n      /* Don't try to create other marker threads.                */\n      break;\n    }\n    /* It is safe to detach the thread.   */\n    CloseHandle(handle);\n#    else\n    GC_uintptr_t handle;\n    unsigned thread_id;\n\n    GC_marker_last_stack_min[i] = ADDR_LIMIT;\n    handle = _beginthreadex(NULL /* security_attr */, MARK_THREAD_STACK_SIZE,\n                            GC_mark_thread, NUMERIC_TO_VPTR(i), 0 /* flags */,\n                            &thread_id);\n    if (EXPECT(!handle || handle == (GC_uintptr_t)-1L, FALSE)) {\n      WARN(\"Marker thread %\" WARN_PRIdPTR \" creation failed\\n\",\n           (GC_signed_word)i);\n      /* Don't try to create other marker threads.                */\n      break;\n    } else {\n      /* We may detach the thread (if handle is of HANDLE type).  */\n      /* CloseHandle((HANDLE)handle); */\n    }\n#    endif\n  }\n\n  /* Adjust GC_markers_m1 (and free unused resources) if failed.    */\n  while (GC_markers_m1 > i) {\n    GC_markers_m1--;\n    CloseHandle(GC_marker_cv[GC_markers_m1]);\n  }\n  GC_wait_for_markers_init();\n  GC_COND_LOG_PRINTF(\"Started %d mark helper threads\\n\", GC_markers_m1);\n  if (EXPECT(0 == i, FALSE)) {\n    CloseHandle(mark_cv);\n    CloseHandle(builder_cv);\n    CloseHandle(mark_mutex_event);\n  }\n}\n\n#    ifdef GC_ASSERTIONS\nSTATIC unsigned long GC_mark_lock_holder = NO_THREAD;\n#      define SET_MARK_LOCK_HOLDER \\\n        (void)(GC_mark_lock_holder = GetCurrentThreadId())\n#      define UNSET_MARK_LOCK_HOLDER                              \\\n        do {                                                      \\\n          GC_ASSERT(GC_mark_lock_holder == GetCurrentThreadId()); \\\n          GC_mark_lock_holder = NO_THREAD;                        \\\n        } while (0)\n#    else\n#      define SET_MARK_LOCK_HOLDER (void)0\n#      define UNSET_MARK_LOCK_HOLDER (void)0\n#    endif /* !GC_ASSERTIONS */\n\n/* Mutex state: unlocked (0), locked and no other waiters (1),      */\n/* locked and waiters may exist (-1).  Accessed using               */\n/* InterlockedExchange().                                           */\nSTATIC /* volatile */ LONG GC_mark_mutex_state = 0;\n\n#    ifdef LOCK_STATS\nvolatile AO_t GC_block_count = 0;\nvolatile AO_t GC_unlocked_count = 0;\n#    endif\n\nGC_INNER void\nGC_acquire_mark_lock(void)\n{\n  GC_ASSERT(GC_mark_lock_holder != GetCurrentThreadId());\n  if (EXPECT(InterlockedExchange(&GC_mark_mutex_state, 1 /* locked */) != 0,\n             FALSE)) {\n#    ifdef LOCK_STATS\n    (void)AO_fetch_and_add1(&GC_block_count);\n#    endif\n    /* Repeatedly reset the state and wait until we acquire the */\n    /* mark lock.                                               */\n    while (InterlockedExchange(&GC_mark_mutex_state,\n                               -1 /* locked_and_has_waiters */)\n           != 0) {\n      if (WaitForSingleObject(mark_mutex_event, INFINITE) == WAIT_FAILED)\n        ABORT(\"WaitForSingleObject failed\");\n    }\n  }\n#    ifdef LOCK_STATS\n  else {\n    (void)AO_fetch_and_add1(&GC_unlocked_count);\n  }\n#    endif\n\n  GC_ASSERT(GC_mark_lock_holder == NO_THREAD);\n  SET_MARK_LOCK_HOLDER;\n}\n\nGC_INNER void\nGC_release_mark_lock(void)\n{\n  UNSET_MARK_LOCK_HOLDER;\n  if (EXPECT(InterlockedExchange(&GC_mark_mutex_state, 0 /* unlocked */) < 0,\n             FALSE)) {\n    /* Wake a waiter.       */\n    if (!SetEvent(mark_mutex_event))\n      ABORT(\"SetEvent failed\");\n  }\n}\n\n/* In GC_wait_for_reclaim/GC_notify_all_builder() we emulate POSIX  */\n/* cond_wait/cond_broadcast() primitives with WinAPI Event object   */\n/* (working in \"manual reset\" mode).  This works here because       */\n/* GC_notify_all_builder() is always called holding the mark lock   */\n/* and the checked condition (GC_fl_builder_count == 0) is the only */\n/* one for which broadcasting on builder_cv is performed.           */\n\nGC_INNER void\nGC_wait_for_reclaim(void)\n{\n  GC_ASSERT(builder_cv != 0);\n  for (;;) {\n    GC_acquire_mark_lock();\n    if (0 == GC_fl_builder_count)\n      break;\n    if (!ResetEvent(builder_cv))\n      ABORT(\"ResetEvent failed\");\n    GC_release_mark_lock();\n    if (WaitForSingleObject(builder_cv, INFINITE) == WAIT_FAILED)\n      ABORT(\"WaitForSingleObject failed\");\n  }\n  GC_release_mark_lock();\n}\n\nGC_INNER void\nGC_notify_all_builder(void)\n{\n  GC_ASSERT(GC_mark_lock_holder == GetCurrentThreadId());\n  GC_ASSERT(builder_cv != 0);\n  GC_ASSERT(0 == GC_fl_builder_count);\n  if (!SetEvent(builder_cv))\n    ABORT(\"SetEvent failed\");\n}\n\n/* mark_cv is used (for waiting) by a non-helper thread.    */\n\nGC_INNER void\nGC_wait_marker(void)\n{\n  HANDLE event = mark_cv;\n  thread_id_t self_id = GetCurrentThreadId();\n  int i = GC_markers_m1;\n\n  while (i-- > 0) {\n    if (GC_marker_Id[i] == self_id) {\n      event = GC_marker_cv[i];\n      break;\n    }\n  }\n\n  if (!ResetEvent(event))\n    ABORT(\"ResetEvent failed\");\n  GC_release_mark_lock();\n  if (WaitForSingleObject(event, INFINITE) == WAIT_FAILED)\n    ABORT(\"WaitForSingleObject failed\");\n  GC_acquire_mark_lock();\n}\n\nGC_INNER void\nGC_notify_all_marker(void)\n{\n  thread_id_t self_id = GetCurrentThreadId();\n  int i = GC_markers_m1;\n\n  while (i-- > 0) {\n    /* Notify every marker ignoring self (for efficiency).  */\n    if (!SetEvent(GC_marker_Id[i] != self_id ? GC_marker_cv[i] : mark_cv))\n      ABORT(\"SetEvent failed\");\n  }\n}\n\n#  endif /* PARALLEL_MARK && !GC_PTHREADS_PARAMARK */\n\n/* We have no DllMain to take care of new threads.  Thus, we    */\n/* must properly intercept thread creation.                     */\n\nstruct win32_start_info {\n  LPTHREAD_START_ROUTINE start_routine;\n  LPVOID arg;\n};\n\nSTATIC void *GC_CALLBACK\nGC_win32_start_inner(struct GC_stack_base *sb, void *arg)\n{\n  void *ret;\n  LPTHREAD_START_ROUTINE start_routine\n      = ((struct win32_start_info *)arg)->start_routine;\n  LPVOID start_arg = ((struct win32_start_info *)arg)->arg;\n\n  GC_ASSERT(!GC_win32_dll_threads);\n  /* This waits for an in-progress garbage collection.        */\n  GC_register_my_thread(sb);\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"thread 0x%lx starting...\\n\", (long)GetCurrentThreadId());\n#  endif\n  GC_free(arg);\n\n  /* Clear the thread entry even if we exit with an exception.        */\n  /* This is probably pointless, since an uncaught exception is       */\n  /* supposed to result in the process being killed.                  */\n#  ifndef NO_SEH_AVAILABLE\n  ret = NULL; /* to avoid \"might be uninitialized\" compiler warning */\n  __try\n#  endif\n  {\n    ret = NUMERIC_TO_VPTR(start_routine(start_arg));\n  }\n#  ifndef NO_SEH_AVAILABLE\n  __finally\n#  endif\n  {\n    (void)GC_unregister_my_thread();\n  }\n\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"thread 0x%lx returned from start routine\\n\",\n                (long)GetCurrentThreadId());\n#  endif\n#  if defined(CPPCHECK)\n  GC_noop1_ptr(sb);\n#  endif\n  return ret;\n}\n\nSTATIC DWORD WINAPI\nGC_win32_start(LPVOID arg)\n{\n  return (DWORD)(GC_uintptr_t)GC_call_with_stack_base(GC_win32_start_inner,\n                                                      arg);\n}\n\nGC_API HANDLE WINAPI\nGC_CreateThread(LPSECURITY_ATTRIBUTES lpThreadAttributes,\n                GC_WIN32_SIZE_T dwStackSize,\n                LPTHREAD_START_ROUTINE lpStartAddress, LPVOID lpParameter,\n                DWORD dwCreationFlags, LPDWORD lpThreadId)\n{\n  /* Make sure GC is initialized (i.e. main thread is attached,   */\n  /* tls is initialized).  This is redundant when                 */\n  /* GC_win32_dll_threads is set by GC_use_threads_discovery().   */\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  GC_ASSERT(GC_thr_initialized);\n\n#  ifdef DEBUG_THREADS\n  GC_log_printf(\"About to create a thread from 0x%lx\\n\",\n                (long)GetCurrentThreadId());\n#  endif\n  if (GC_win32_dll_threads) {\n    return CreateThread(lpThreadAttributes, dwStackSize, lpStartAddress,\n                        lpParameter, dwCreationFlags, lpThreadId);\n  } else {\n    /* Note: this is handed off to and deallocated by child thread.   */\n    struct win32_start_info *psi\n        = (struct win32_start_info *)GC_malloc_uncollectable(\n            sizeof(struct win32_start_info));\n    HANDLE thread_h;\n\n    if (EXPECT(NULL == psi, FALSE)) {\n      SetLastError(ERROR_NOT_ENOUGH_MEMORY);\n      return NULL;\n    }\n\n    /* Set up the thread arguments.   */\n    psi->start_routine = lpStartAddress;\n    psi->arg = lpParameter;\n    GC_dirty(psi);\n    REACHABLE_AFTER_DIRTY(lpParameter);\n\n#  ifdef PARALLEL_MARK\n    if (EXPECT(!GC_parallel && GC_available_markers_m1 > 0, FALSE))\n      GC_start_mark_threads();\n#  endif\n    set_need_to_lock();\n    thread_h = CreateThread(lpThreadAttributes, dwStackSize, GC_win32_start,\n                            psi, dwCreationFlags, lpThreadId);\n    if (EXPECT(0 == thread_h, FALSE))\n      GC_free(psi);\n    return thread_h;\n  }\n}\n\nGC_API DECLSPEC_NORETURN void WINAPI\nGC_ExitThread(DWORD dwExitCode)\n{\n  if (!GC_win32_dll_threads)\n    (void)GC_unregister_my_thread();\n  ExitThread(dwExitCode);\n}\n\n#  if defined(MSWIN32) && !defined(NO_CRT)\nGC_API GC_uintptr_t GC_CALL\nGC_beginthreadex(void *security, unsigned stack_size,\n                 unsigned(__stdcall *start_address)(void *), void *arglist,\n                 unsigned initflag, unsigned *thrdaddr)\n{\n  if (!EXPECT(GC_is_initialized, TRUE))\n    GC_init();\n  GC_ASSERT(GC_thr_initialized);\n#    ifdef DEBUG_THREADS\n  GC_log_printf(\"About to create a thread from 0x%lx\\n\",\n                (long)GetCurrentThreadId());\n#    endif\n\n  if (GC_win32_dll_threads) {\n    return _beginthreadex(security, stack_size, start_address, arglist,\n                          initflag, thrdaddr);\n  } else {\n    GC_uintptr_t thread_h;\n    /* Note: this is handed off to and deallocated by child thread.   */\n    struct win32_start_info *psi\n        = (struct win32_start_info *)GC_malloc_uncollectable(\n            sizeof(struct win32_start_info));\n\n    if (EXPECT(NULL == psi, FALSE)) {\n      /* MSDN docs say _beginthreadex() returns 0 on error and sets */\n      /* errno to either EAGAIN (too many threads) or EINVAL (the   */\n      /* argument is invalid or the stack size is incorrect), so we */\n      /* set errno to EAGAIN on \"not enough memory\".                */\n      errno = EAGAIN;\n      return 0;\n    }\n\n    /* Set up the thread arguments. */\n    psi->start_routine = (LPTHREAD_START_ROUTINE)start_address;\n    psi->arg = arglist;\n    GC_dirty(psi);\n    REACHABLE_AFTER_DIRTY(arglist);\n\n#    ifdef PARALLEL_MARK\n    if (EXPECT(!GC_parallel && GC_available_markers_m1 > 0, FALSE))\n      GC_start_mark_threads();\n#    endif\n    set_need_to_lock();\n    thread_h = _beginthreadex(security, stack_size,\n                              (unsigned(__stdcall *)(void *))GC_win32_start,\n                              psi, initflag, thrdaddr);\n    if (EXPECT(0 == thread_h, FALSE))\n      GC_free(psi);\n    return thread_h;\n  }\n}\n\nGC_API void GC_CALL\nGC_endthreadex(unsigned retval)\n{\n  if (!GC_win32_dll_threads)\n    (void)GC_unregister_my_thread();\n  _endthreadex(retval);\n}\n#  endif /* MSWIN32 && !NO_CRT */\n\n#  ifdef GC_WINMAIN_REDIRECT\n/* This might be useful on WinCE.  Shouldn't be used with GC_DLL.     */\n\n#    if defined(MSWINCE) && defined(UNDER_CE)\n#      define WINMAIN_LPTSTR LPWSTR\n#    else\n#      define WINMAIN_LPTSTR LPSTR\n#    endif\n\n/* This is defined in gc.h.   */\n#    undef WinMain\n\n/* Defined outside GC by an application.      */\nint WINAPI GC_WinMain(HINSTANCE, HINSTANCE, WINMAIN_LPTSTR, int);\n\ntypedef struct {\n  HINSTANCE hInstance;\n  HINSTANCE hPrevInstance;\n  WINMAIN_LPTSTR lpCmdLine;\n  int nShowCmd;\n} main_thread_args;\n\nstatic DWORD WINAPI\nmain_thread_start(LPVOID arg)\n{\n  main_thread_args *main_args = (main_thread_args *)arg;\n  return (DWORD)GC_WinMain(main_args->hInstance, main_args->hPrevInstance,\n                           main_args->lpCmdLine, main_args->nShowCmd);\n}\n\nSTATIC void *GC_CALLBACK\nGC_waitForSingleObjectInfinite(void *handle)\n{\n  return NUMERIC_TO_VPTR(WaitForSingleObject((HANDLE)handle, INFINITE));\n}\n\n#    ifndef WINMAIN_THREAD_STACK_SIZE\n/* The default size of the WinMain's thread stack.  */\n#      define WINMAIN_THREAD_STACK_SIZE 0\n#    endif\n\nint WINAPI\nWinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, WINMAIN_LPTSTR lpCmdLine,\n        int nShowCmd)\n{\n  DWORD exit_code = 1;\n\n  main_thread_args args = { hInstance, hPrevInstance, lpCmdLine, nShowCmd };\n  HANDLE thread_h;\n  DWORD thread_id;\n\n  /* Initialize everything.   */\n  GC_INIT();\n\n  /* Start the main thread.   */\n  thread_h = GC_CreateThread(\n      NULL /* lpsa */, WINMAIN_THREAD_STACK_SIZE /* ignored on WinCE */,\n      main_thread_start, &args, 0 /* fdwCreate */, &thread_id);\n  if (NULL == thread_h)\n    ABORT(\"GC_CreateThread(main_thread) failed\");\n\n  if ((DWORD)(GC_uintptr_t)GC_do_blocking(GC_waitForSingleObjectInfinite,\n                                          (void *)thread_h)\n      == WAIT_FAILED)\n    ABORT(\"WaitForSingleObject(main_thread) failed\");\n  GetExitCodeThread(thread_h, &exit_code);\n  CloseHandle(thread_h);\n\n#    ifdef MSWINCE\n  GC_deinit();\n#    endif\n  return (int)exit_code;\n}\n\n#  endif /* GC_WINMAIN_REDIRECT */\n\n#  ifdef WOW64_THREAD_CONTEXT_WORKAROUND\n#    ifdef MSWINRT_FLAVOR\n/* Available on WinRT but we have to declare it manually.   */\n__declspec(dllimport) HMODULE WINAPI GetModuleHandleW(LPCWSTR);\n#    endif\n\nstatic GC_bool\nis_wow64_process(HMODULE hK32)\n{\n  BOOL is_wow64;\n#    ifdef MSWINRT_FLAVOR\n  /* Try to use IsWow64Process2 as it handles different WoW64 cases. */\n  HMODULE hWow64 = GetModuleHandleW(L\"api-ms-win-core-wow64-l1-1-1.dll\");\n\n  UNUSED_ARG(hK32);\n  if (hWow64) {\n    FARPROC pfn2 = GetProcAddress(hWow64, \"IsWow64Process2\");\n    USHORT process_machine, native_machine;\n\n    if (pfn2\n        && (*(BOOL(WINAPI *)(HANDLE, USHORT *, USHORT *))(GC_funcptr_uint)\n                pfn2)(GetCurrentProcess(), &process_machine, &native_machine))\n      return process_machine != native_machine;\n  }\n  if (IsWow64Process(GetCurrentProcess(), &is_wow64))\n    return (GC_bool)is_wow64;\n#    else\n  if (hK32) {\n    FARPROC pfn = GetProcAddress(hK32, \"IsWow64Process\");\n\n    if (pfn\n        && (*(BOOL(WINAPI *)(HANDLE, BOOL *))(GC_funcptr_uint)pfn)(\n            GetCurrentProcess(), &is_wow64))\n      return (GC_bool)is_wow64;\n  }\n#    endif\n  /* IsWow64Process() failed. */\n  return FALSE;\n}\n#  endif /* WOW64_THREAD_CONTEXT_WORKAROUND */\n\nGC_INNER void\nGC_thr_init(void)\n{\n  struct GC_stack_base sb;\n  thread_id_t self_id = GetCurrentThreadId();\n#  if (!defined(HAVE_PTHREAD_SETNAME_NP_WITH_TID) && !defined(MSWINCE) \\\n       && defined(PARALLEL_MARK))                                      \\\n      || defined(WOW64_THREAD_CONTEXT_WORKAROUND)\n  HMODULE hK32;\n#    if defined(MSWINRT_FLAVOR) && defined(FUNCPTR_IS_DATAPTR)\n  MEMORY_BASIC_INFORMATION memInfo;\n\n  if (VirtualQuery(CAST_THRU_UINTPTR(void *, GetProcAddress), &memInfo,\n                   sizeof(memInfo))\n      != sizeof(memInfo))\n    ABORT(\"Weird VirtualQuery result\");\n  hK32 = (HMODULE)memInfo.AllocationBase;\n#    else\n  hK32 = GetModuleHandle(TEXT(\"kernel32.dll\"));\n#    endif\n#  endif\n\n  GC_ASSERT(I_HOLD_LOCK());\n  GC_ASSERT(!GC_thr_initialized);\n  GC_ASSERT(ADDR(&GC_threads) % ALIGNMENT == 0);\n#  ifdef GC_ASSERTIONS\n  GC_thr_initialized = TRUE;\n#  endif\n#  if !defined(DONT_USE_ATEXIT) || !defined(GC_NO_THREADS_DISCOVERY)\n  GC_main_thread_id = self_id;\n#  endif\n#  ifdef CAN_HANDLE_FORK\n  GC_setup_atfork();\n#  endif\n#  ifdef WOW64_THREAD_CONTEXT_WORKAROUND\n  /* Set isWow64 flag. */\n  isWow64 = is_wow64_process(hK32);\n#  endif\n  /* Add the initial thread, so we can stop it. */\n  sb.mem_base = GC_stackbottom;\n  GC_ASSERT(sb.mem_base != NULL);\n#  ifdef IA64\n  sb.reg_base = GC_register_stackbottom;\n#  endif\n\n#  if defined(PARALLEL_MARK)\n  {\n    const char *markers_string = GETENV(\"GC_MARKERS\");\n    int markers = GC_required_markers_cnt;\n\n    if (markers_string != NULL) {\n      markers = atoi(markers_string);\n      if (markers <= 0 || markers > MAX_MARKERS) {\n        WARN(\"Too big or invalid number of mark threads: %\" WARN_PRIdPTR\n             \"; using maximum threads\\n\",\n             (GC_signed_word)markers);\n        markers = MAX_MARKERS;\n      }\n    } else if (0 == markers) {\n      /* Unless the client sets the desired number of         */\n      /* parallel markers, it is determined based on the      */\n      /* number of CPU cores.                                 */\n#    ifdef MSWINCE\n      /* There is no GetProcessAffinityMask() in WinCE.     */\n      /* GC_sysinfo is already initialized.                 */\n      markers = (int)GC_sysinfo.dwNumberOfProcessors;\n#    else\n#      ifdef _WIN64\n      DWORD_PTR procMask = 0;\n      DWORD_PTR sysMask;\n#      else\n      DWORD procMask = 0;\n      DWORD sysMask;\n#      endif\n      int ncpu = 0;\n      if (\n#      ifdef __cplusplus\n          GetProcessAffinityMask(GetCurrentProcess(), &procMask, &sysMask)\n#      else\n          /* Cast args to void* for compatibility with some old SDKs. */\n          GetProcessAffinityMask(GetCurrentProcess(), (void *)&procMask,\n                                 (void *)&sysMask)\n#      endif\n          && procMask) {\n        do {\n          ncpu++;\n        } while ((procMask &= procMask - 1) != 0);\n      }\n      markers = ncpu;\n#    endif\n#    if defined(GC_MIN_MARKERS) && !defined(CPPCHECK)\n      /* This is primarily for testing on systems without getenv(). */\n      if (markers < GC_MIN_MARKERS)\n        markers = GC_MIN_MARKERS;\n#    endif\n      if (markers > MAX_MARKERS) {\n        /* Silently limit the amount of markers.    */\n        markers = MAX_MARKERS;\n      }\n    }\n    GC_available_markers_m1 = markers - 1;\n  }\n\n  /* Check whether parallel mode could be enabled.    */\n  if (GC_win32_dll_threads || GC_available_markers_m1 <= 0) {\n    /* Disable parallel marking. */\n    GC_parallel = FALSE;\n    GC_COND_LOG_PRINTF(\"Single marker thread, turning off parallel marking\\n\");\n  } else {\n#    ifndef GC_PTHREADS_PARAMARK\n    /* Initialize Win32 event objects for parallel marking.       */\n    mark_mutex_event = CreateEvent(NULL /* attrs */, FALSE /* isManualReset */,\n                                   FALSE /* initialState */, NULL /* name */);\n    builder_cv = CreateEvent(NULL /* attrs */, TRUE /* isManualReset */,\n                             FALSE /* initialState */, NULL /* name */);\n    mark_cv = CreateEvent(NULL /* attrs */, TRUE /* isManualReset */,\n                          FALSE /* initialState */, NULL /* name */);\n    if (mark_mutex_event == (HANDLE)0 || builder_cv == (HANDLE)0\n        || mark_cv == (HANDLE)0)\n      ABORT(\"CreateEvent failed\");\n#    endif\n#    if !defined(HAVE_PTHREAD_SETNAME_NP_WITH_TID) && !defined(MSWINCE)\n    GC_init_win32_thread_naming(hK32);\n#    endif\n  }\n#  endif /* PARALLEL_MARK */\n\n  GC_register_my_thread_inner(&sb, self_id);\n}\n\n#  ifndef GC_NO_THREADS_DISCOVERY\n/* We avoid acquiring locks here, since this doesn't seem to be     */\n/* preemptible.  This may run with an uninitialized collector, in   */\n/* which case we don't do much.  This implies that no threads other */\n/* than the main one should be created with an uninitialized        */\n/* collector.  (The alternative of initializing the collector here  */\n/* seems dangerous, since DllMain is limited in what it can do.)    */\n\n#    ifdef GC_INSIDE_DLL\n/* Export only if needed by client. */\nGC_API\n#    else\n#      define GC_DllMain DllMain\n#    endif\nBOOL WINAPI\nGC_DllMain(HINSTANCE inst, ULONG reason, LPVOID reserved)\n{\n  thread_id_t self_id;\n\n  UNUSED_ARG(inst);\n  UNUSED_ARG(reserved);\n  /* Note that GC_use_threads_discovery should be called by the     */\n  /* client application at start-up to activate automatic thread    */\n  /* registration (it is the default GC behavior);                  */\n  /* to always have automatic thread registration turned on, the GC */\n  /* should be compiled with -D GC_DISCOVER_TASK_THREADS.           */\n  if (!GC_win32_dll_threads && GC_is_initialized)\n    return TRUE;\n\n  switch (reason) {\n  case DLL_THREAD_ATTACH:\n    /* This is invoked for threads other than main one.     */\n#    ifdef PARALLEL_MARK\n    /* Don't register marker threads. */\n    if (GC_parallel) {\n      /* We could reach here only if GC is not initialized.       */\n      /* Because GC_thr_init() sets GC_parallel to off.           */\n      break;\n    }\n#    endif\n    /* FALLTHRU */\n  case DLL_PROCESS_ATTACH:\n    /* This may run with the collector uninitialized. */\n    self_id = GetCurrentThreadId();\n    if (GC_is_initialized && GC_main_thread_id != self_id) {\n      struct GC_stack_base sb;\n      /* Don't lock here. */\n#    ifdef GC_ASSERTIONS\n      int sb_result =\n#    endif\n          GC_get_stack_base(&sb);\n      GC_ASSERT(sb_result == GC_SUCCESS);\n      GC_register_my_thread_inner(&sb, self_id);\n    } else {\n      /* We already did it during GC_thr_init, called by GC_init.   */\n    }\n    break;\n\n  case DLL_THREAD_DETACH:\n    /* We are hopefully running in the context of the exiting thread. */\n    if (GC_win32_dll_threads) {\n      GC_thread t = GC_win32_dll_lookup_thread(GetCurrentThreadId());\n\n      if (EXPECT(t != NULL, TRUE))\n        GC_delete_thread(t);\n    }\n    break;\n\n  case DLL_PROCESS_DETACH:\n    if (GC_win32_dll_threads) {\n      int i;\n      int my_max = (int)GC_get_max_thread_index();\n\n      for (i = 0; i <= my_max; ++i) {\n        if (AO_load(&dll_thread_table[i].tm.in_use))\n          GC_delete_thread((GC_thread)&dll_thread_table[i]);\n      }\n      GC_deinit();\n    }\n    break;\n  }\n  return TRUE;\n}\n#  endif /* !GC_NO_THREADS_DISCOVERY */\n\n#  ifndef GC_NO_THREAD_REDIRECTS\n/* Restore thread calls redirection.        */\n#    define CreateThread GC_CreateThread\n#    define ExitThread GC_ExitThread\n#    undef _beginthreadex\n#    define _beginthreadex GC_beginthreadex\n#    undef _endthreadex\n#    define _endthreadex GC_endthreadex\n#  endif /* !GC_NO_THREAD_REDIRECTS */\n\n#endif /* GC_WIN32_THREADS */\n"
        }
      ]
    }
  ]
}