{
  "metadata": {
    "timestamp": 1736710149684,
    "page": 810,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "citusdata/cstore_fdw",
      "stars": 1761,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.59375,
          "content": "# =====\n# = C =\n# =====\n\n# Object files\n*.o\n*.ko\n*.obj\n*.elf\n\n# Libraries\n*.lib\n*.a\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.app\n*.i*86\n*.x86_64\n*.hex\n\n# ========\n# = Gcov =\n# ========\n\n# gcc coverage testing tool files\n\n*.gcno\n*.gcda\n*.gcov\n\n# ====================\n# = Project-Specific =\n# ====================\n\n/data/*.cstore\n/data/*.footer\n\n/sql/block_filtering.sql\n/sql/copyto.sql\n/sql/create.sql\n/sql/data_types.sql\n/sql/load.sql\n\n/expected/block_filtering.out\n/expected/copyto.out\n/expected/create.out\n/expected/data_types.out\n/expected/load.out\n\n*.pb-c.*\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.91796875,
          "content": "sudo: required\ndist: bionic\nlanguage: c\ncache:\n  apt: true\n  directories:\n    - /home/travis/postgresql\nenv:\n  global:\n    - enable_coverage=yes\n    - PG_PRELOAD=cstore_fdw\n  matrix:\n    - PGVERSION=9.3\n    - PGVERSION=9.4\n    - PGVERSION=9.5\n    - PGVERSION=9.6\n    - PGVERSION=10\n    - PGVERSION=11\n    - PGVERSION=12\n    - PGVERSION=13\n\nbefore_install:\n  - git clone -b v0.7.13 --depth 1 https://github.com/citusdata/tools.git\n  - sudo make -C tools install\n  - setup_apt\n  - nuke_pg\ninstall:\n  - sudo apt-get install protobuf-c-compiler\n  - sudo apt-get install libprotobuf-c0-dev\n  - sudo locale-gen da_DK\n  - sudo locale-gen da_DK.utf8\n  - sudo pip install cpp-coveralls\n  - install_pg\n  - install_custom_pg\nbefore_script:\n  - chmod 777 .\n  - chmod 777 data\n  - chmod 666 data/*\n  - config_and_start_cluster\nscript: pg_travis_test\nafter_success:\n  - sudo chmod 666 *.gcda\n  - coveralls --exclude cstore.pb-c.c --exclude cstore.pb-c.h\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0576171875,
          "content": "Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "META.json",
          "type": "blob",
          "size": 1.1220703125,
          "content": "{\n   \"name\": \"cstore_fdw\",\n   \"abstract\": \"Columnar Store for PostgreSQL\",\n   \"description\": \"PostgreSQL extension which implements a Columnar Store.\",\n   \"version\": \"1.7.0\",\n   \"maintainer\": \"Murat Tuncer <murat.tuncer@microsoft.com>\",\n   \"license\": \"apache_2_0\",\n   \"provides\": {\n      \"cstore_fdw\": {\n         \"abstract\": \"Foreign Data Wrapper for Columnar Store Tables\",\n         \"file\": \"cstore_fdw--1.7.sql\",\n         \"docfile\": \"README.md\",\n         \"version\": \"1.7.0\"\n      }\n   },\n   \"prereqs\": {\n      \"runtime\": {\n         \"requires\": {\n            \"PostgreSQL\": \"9.3.0\"\n         }\n      }\n   },\n   \"resources\": {\n      \"bugtracker\": {\n         \"web\": \"http://github.com/citusdata/cstore_fdw/issues/\"\n      },\n      \"repository\": {\n        \"url\":  \"git://github.com/citusdata/cstore_fdw.git\",\n        \"web\":  \"https://github.com/citusdata/cstore_fdw/\",\n        \"type\": \"git\"\n      }\n   },\n   \"generated_by\": \"Murat Tuncer\",\n   \"meta-spec\": {\n      \"version\": \"1.0.0\",\n      \"url\": \"http://pgxn.org/meta/spec.txt\"\n   },\n   \"tags\": [\n      \"orc\",\n      \"fdw\",\n      \"foreign data wrapper\",\n      \"cstore_fdw\",\n      \"columnar store\"\n   ]\n}\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.734375,
          "content": "# cstore_fdw/Makefile\n#\n# Copyright (c) 2016 Citus Data, Inc.\n#\n\nMODULE_big = cstore_fdw\n\nPG_CPPFLAGS = --std=c99\nSHLIB_LINK = -lprotobuf-c\nOBJS = cstore.pb-c.o cstore_fdw.o cstore_writer.o cstore_reader.o \\\n       cstore_metadata_serialization.o cstore_compression.o\n\nEXTENSION = cstore_fdw\nDATA = cstore_fdw--1.7.sql cstore_fdw--1.6--1.7.sql  cstore_fdw--1.5--1.6.sql cstore_fdw--1.4--1.5.sql \\\n\t   cstore_fdw--1.3--1.4.sql cstore_fdw--1.2--1.3.sql cstore_fdw--1.1--1.2.sql \\\n\t   cstore_fdw--1.0--1.1.sql\n\nREGRESS = create load query analyze data_types functions block_filtering drop \\\n\t\t  insert copyto alter truncate\nEXTRA_CLEAN = cstore.pb-c.h cstore.pb-c.c data/*.cstore data/*.cstore.footer \\\n              sql/block_filtering.sql sql/create.sql sql/data_types.sql sql/load.sql \\\n              sql/copyto.sql expected/block_filtering.out expected/create.out \\\n              expected/data_types.out expected/load.out expected/copyto.out\n\nifeq ($(enable_coverage),yes)\n\tPG_CPPFLAGS += --coverage\n\tSHLIB_LINK  += --coverage\n\tEXTRA_CLEAN += *.gcno\nendif\n\nUNAME_S := $(shell uname -s)\nifeq ($(UNAME_S),Darwin)\n\tPG_CPPFLAGS += -I/usr/local/include\nendif\n\n#\n# Users need to specify their Postgres installation path through pg_config. For\n# example: /usr/local/pgsql/bin/pg_config or /usr/lib/postgresql/9.3/bin/pg_config\n#\n\nPG_CONFIG = pg_config\nPGXS := $(shell $(PG_CONFIG) --pgxs)\ninclude $(PGXS)\n\nifndef MAJORVERSION\n    MAJORVERSION := $(basename $(VERSION))\nendif\n\nifeq (,$(findstring $(MAJORVERSION), 9.3 9.4 9.5 9.6 10 11 12 13))\n    $(error PostgreSQL 9.3 to 13 is required to compile this extension)\nendif\n\ncstore.pb-c.c: cstore.proto\n\tprotoc-c --c_out=. cstore.proto\n\ninstallcheck: remove_cstore_files\n\nremove_cstore_files:\n\trm -f data/*.cstore data/*.cstore.footer\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.73046875,
          "content": "## Important notice: Columnar storage is now part of Citus\n\nColumnar storage is now part of the [Citus extension](https://github.com/citusdata/citus), which uses the table access method API to give a much more native experience. It also supports streaming replication, archival, rollback, and simplifies pg_upgrade. You can use Citus just for columnar storage on a single PostgreSQL server, or combine it with distributed tables to parallelize queries locally or across a cluster of PostgreSQL servers.\n\nMigration is simple, and you'll typically see improved compression thanks to [zstd](https://github.com/facebook/zstd):\n\n```sql\n-- After adding adding shared_preload_libraries = 'citus'\n-- to postgresql.conf and restarting:\nCREATE EXTENSION IF NOT EXISTS citus;\n\n-- Create a table using the columnar access method, with the same columns\n-- as an existing cstore_fdw table\nCREATE TABLE customer_reviews_am (\n  LIKE customer_reviews_fdw INCLUDING ALL\n) USING columnar;\n\n-- Copy data from an old cstore_fdw table to an access method table\nINSERT INTO customer_reviews_am SELECT * FROM customer_reviews_fdw;\n\n-- cstore_fdw data size\nSELECT pg_size_pretty(cstore_table_size('customer_reviews_fdw'));\n┌────────────────┐\n│ pg_size_pretty │\n├────────────────┤\n│ 100 MB         │\n└────────────────┘\n\n-- Citus Columnar data size\nSELECT pg_size_pretty(pg_table_size('customer_reviews_am'));\n┌────────────────┐\n│ pg_size_pretty │\n├────────────────┤\n│ 64 MB          │\n└────────────────┘\n```\n\nRead more about it in the [Citus columnar blog post](https://www.citusdata.com/blog/2021/03/06/citus-10-columnar-compression-for-postgres/) by Jeff Davis.\n\ncstore_fdw\n==========\n\n[![Build Status](https://travis-ci.org/citusdata/cstore_fdw.svg?branch=master)][status]\n[![Coverage](http://img.shields.io/coveralls/citusdata/cstore_fdw/master.svg)][coverage]\n\nCstore_fdw is an open source columnar store extension for PostgreSQL. Columnar stores provide notable benefits for analytics use cases where data is loaded in batches. Cstore_fdw’s columnar nature delivers performance by only reading relevant data from disk, and it may compress data 6x-10x to reduce space requirements for data archival.\n\nCstore_fdw is developed by [Citus Data](https://www.citusdata.com) and can be used in combination with [Citus](https://github.com/citusdata/citus), a postgres extension that intelligently distributes your data and queries across many nodes so your database can scale and your queries are fast. If you have any questions about how Citus can help you scale or how to use Citus in combination with cstore_fdw, [please let us know](https://www.citusdata.com/about/contact_us/).\n\nJoin the [Mailing List][mailing-list] to stay on top of the latest developments for Cstore_fdw.\n\n\nIntroduction\n------------\n\nThis extension uses a format for its data layout that is inspired by ORC,\nthe Optimized Row Columnar format. Like ORC, the cstore format improves\nupon RCFile developed at Facebook, and brings the following benefits:\n\n* Compression: Reduces in-memory and on-disk data size by 2-4x. Can be extended\n  to support different codecs.\n* Column projections: Only reads column data relevant to the query. Improves\n  performance for I/O bound queries.\n* Skip indexes: Stores min/max statistics for row groups, and uses them to skip\n  over unrelated rows.\n\nFurther, we used the Postgres foreign data wrapper APIs and type representations\nwith this extension. This brings:\n\n* Support for 40+ Postgres data types. The user can also create new types and\n  use them.\n* Statistics collection. PostgreSQL's query optimizer uses these stats to\n  evaluate different query plans and pick the best one.\n* Simple setup. Create foreign table and copy data. Run SQL.\n\n\nBuilding\n--------\n\ncstore\\_fdw depends on protobuf-c for serializing and deserializing table metadata.\nSo we need to install these packages first:\n\n    # Fedora 17+, CentOS, and Amazon Linux\n    sudo yum install protobuf-c-devel\n\n    # Ubuntu 10.4+\n    sudo apt-get install protobuf-c-compiler\n    sudo apt-get install libprotobuf-c0-dev\n    \n    # Ubuntu 18.4+\n    sudo apt-get install protobuf-c-compiler\n    sudo apt-get install libprotobuf-c-dev\n\n    # Mac OS X\n    brew install protobuf-c\n\n**Note.** In CentOS 5, 6, and 7, you may need to install or update EPEL 5, 6, or 7 repositories.\n See [this page](https://support.rackspace.com/how-to/install-epel-and-additional-repositories-on-centos-and-red-hat/)\nfor instructions.\n\n**Note.** In Amazon Linux, the EPEL repository is installed by default, but not\nenabled. See [these instructions](http://aws.amazon.com/amazon-linux-ami/faqs/#epel)\nfor how to enable it.\n\nOnce you have protobuf-c installed on your machine, you are ready to build\ncstore\\_fdw.  For this, you need to include the pg\\_config directory path in\nyour make command. This path is typically the same as your PostgreSQL\ninstallation's bin/ directory path. For example:\n\n    PATH=/usr/local/pgsql/bin/:$PATH make\n    sudo PATH=/usr/local/pgsql/bin/:$PATH make install\n\n**Note.** cstore_fdw requires PostgreSQL version from 9.3 to 12. It doesn't\nsupport earlier versions of PostgreSQL.\n\n\nUsage\n-----\n\nBefore using cstore\\_fdw, you need to add it to ```shared_preload_libraries```\nin your ```postgresql.conf``` and restart Postgres:\n\n    shared_preload_libraries = 'cstore_fdw'    # (change requires restart)\n\nThe following parameters can be set on a cstore foreign table object.\n\n* filename (optional): The absolute path to the location for storing table data.\n  If you don't specify the filename option, cstore\\_fdw will automatically\n  choose the $PGDATA/cstore\\_fdw directory to store the files. If specified the \n  value of this parameter will be used as a prefix for all files created to\n  store table data. For example, the value ```/cstore_fdw/my_table``` could result in\n  the files ```/cstore_fdw/my_table``` and ```/cstore_fdw/my_table.footer``` being used\n  to manage table data.\n* compression (optional): The compression used for compressing value streams.\n  Valid options are ```none``` and ```pglz```. The default is ```none```.\n* stripe\\_row\\_count (optional): Number of rows per stripe. The default is\n  ```150000```. Reducing this decreases the amount memory used for loading data\n  and querying, but also decreases the performance.\n* block\\_row\\_count (optional): Number of rows per column block. The default is\n ```10000```. cstore\\_fdw compresses, creates skip indexes, and reads from disk\n  at the block granularity. Increasing this value helps with compression and results\n  in fewer reads from disk. However, higher values also reduce the probability of\n  skipping over unrelated row blocks.\n\n\nTo load or append data into a cstore table, you have two options:\n\n* You can use the [```COPY``` command][copy-command] to load or append data from\n  a file, a program, or STDIN.\n* You can use the ```INSERT INTO cstore_table SELECT ...``` syntax to load or\n  append data from another table.\n\nYou can use the [```ANALYZE``` command][analyze-command] to collect statistics\nabout the table. These statistics help the query planner to help determine the\nmost efficient execution plan for each query.\n\n**Note.** We currently don't support updating table using DELETE, and UPDATE\ncommands. We also don't support single row inserts.\n\n\nUpdating from earlier versions to 1.7\n---------------------------------------\n\nTo update an existing cstore_fdw installation from versions earlier than 1.6\nyou can take the following steps:\n\n* Download and install cstore_fdw version 1.6 using instructions from the \"Building\"\n  section,\n* Restart the PostgreSQL server,\n* Run ```ALTER EXTENSION cstore_fdw UPDATE;```\n\n\nExample\n-------\n\nAs an example, we demonstrate loading and querying data to/from a column store\ntable from scratch here. Let's start with downloading and decompressing the data\nfiles.\n\n    wget http://examples.citusdata.com/customer_reviews_1998.csv.gz\n    wget http://examples.citusdata.com/customer_reviews_1999.csv.gz\n\n    gzip -d customer_reviews_1998.csv.gz\n    gzip -d customer_reviews_1999.csv.gz\n\nThen, let's log into Postgres, and run the following commands to create a column\nstore foreign table:\n\n```SQL\n-- load extension first time after install\nCREATE EXTENSION cstore_fdw;\n\n-- create server object\nCREATE SERVER cstore_server FOREIGN DATA WRAPPER cstore_fdw;\n\n-- create foreign table\nCREATE FOREIGN TABLE customer_reviews\n(\n    customer_id TEXT,\n    review_date DATE,\n    review_rating INTEGER,\n    review_votes INTEGER,\n    review_helpful_votes INTEGER,\n    product_id CHAR(10),\n    product_title TEXT,\n    product_sales_rank BIGINT,\n    product_group TEXT,\n    product_category TEXT,\n    product_subcategory TEXT,\n    similar_product_ids CHAR(10)[]\n)\nSERVER cstore_server\nOPTIONS(compression 'pglz');\n```\n\nNext, we load data into the table:\n\n```SQL\n\\COPY customer_reviews FROM 'customer_reviews_1998.csv' WITH CSV;\n\\COPY customer_reviews FROM 'customer_reviews_1999.csv' WITH CSV;\n```\n\n**Note.** If you are getting ```ERROR: cannot copy to foreign table\n\"customer_reviews\"``` when trying to run the COPY commands, double check that you\nhave added cstore\\_fdw to ```shared_preload_libraries``` in ```postgresql.conf```\nand restarted Postgres.\n\nNext, we collect data distribution statistics about the table. This is optional,\nbut usually very helpful:\n\n```SQL\nANALYZE customer_reviews;\n```\n\nFinally, let's run some example SQL queries on the column store table.\n\n```SQL\n-- Find all reviews a particular customer made on the Dune series in 1998.\nSELECT\n    customer_id, review_date, review_rating, product_id, product_title\nFROM\n    customer_reviews\nWHERE\n    customer_id ='A27T7HVDXA3K2A' AND\n    product_title LIKE '%Dune%' AND\n    review_date >= '1998-01-01' AND\n    review_date <= '1998-12-31';\n\n-- Do we have a correlation between a book's title's length and its review ratings?\nSELECT\n    width_bucket(length(product_title), 1, 50, 5) title_length_bucket,\n    round(avg(review_rating), 2) AS review_average,\n    count(*)\nFROM\n   customer_reviews\nWHERE\n    product_group = 'Book'\nGROUP BY\n    title_length_bucket\nORDER BY\n    title_length_bucket;\n```\n\n\nUsage with Citus\n----------------\n\nThe example above illustrated how to load data into a PostgreSQL database running\non a single host. However, sometimes your data is too large to analyze effectively\non a single host. Citus is a product built by Citus Data that allows you to run\na distributed PostgreSQL database to analyze your data using the power of multiple\nhosts.  You can easily install and run other PostgreSQL extensions and foreign data\nwrappers—including cstore_fdw—alongside Citus.\n\nYou can create a cstore_fdw table and distribute it using the\n```create_distributed_table()``` UDF just like any other table. You can load data\nusing the ```copy``` command as you would do in single node PostgreSQL.\n\nUsing Skip Indexes\n------------------\n\ncstore_fdw partitions each column into multiple blocks. Skip indexes store minimum\nand maximum values for each of these blocks. While scanning the table, if min/max\nvalues of the block contradict the WHERE clause, then the block is completely\nskipped. This way, the query processes less data and hence finishes faster.\n\nTo use skip indexes more efficiently, you should load the data after sorting it\non a column that is commonly used in the WHERE clause. This ensures that there is\na minimum overlap between blocks and the chance of them being skipped is higher.\n\nIn practice, the data generally has an inherent dimension (for example a time field)\non which it is naturally sorted. Usually, the queries also have a filter clause on\nthat column (for example you want to query only the last week's data), and hence you\ndon't need to sort the data in such cases.\n\n\nUninstalling cstore_fdw\n-----------------------\n\nBefore uninstalling the extension, first you need to drop all the cstore tables:\n\n    postgres=# DROP FOREIGN TABLE cstore_table_1;\n    ...\n    postgres=# DROP FOREIGN TABLE cstore_table_n;\n\nThen, you should drop the cstore server and extension:\n\n    postgres=# DROP SERVER cstore_server;\n    postgres=# DROP EXTENSION cstore_fdw;\n\ncstore\\_fdw automatically creates some directories inside the PostgreSQL's data\ndirectory to store its files. To remove them, you can run:\n\n    $ rm -rf $PGDATA/cstore_fdw\n\nThen, you should remove cstore\\_fdw from ```shared_preload_libraries``` in\nyour ```postgresql.conf```:\n\n    shared_preload_libraries = ''    # (change requires restart)\n\nFinally, to uninstall the extension you can run the following command in the\nextension's source code directory. This will clean up all the files copied during\nthe installation:\n\n    $ sudo PATH=/usr/local/pgsql/bin/:$PATH make uninstall\n\n\nChangeset\n---------\n### Version 1.7.0\n* (Fix) Add support for PostgreSQL 12\n* (Fix) Support count(t.*) from t type queries\n* (Fix) Build failures for MacOS 10.14+\n* (Fix) Make foreign scan parallel safe\n* (Fix) Add support for PostgreSQL 11 COPY\n### Version 1.6.2\n* (Fix) Add support for PostgreSQL 11\n### Version 1.6.1\n* (Fix) Fix crash during truncate (Cstore crashing server when enabled, not used)\n* (Fix) No such file or directory warning when attempting to drop database\n### Version 1.6\n* (Feature) Added support for PostgreSQL 10.\n* (Fix) Removed table files when a schema, extension or database is dropped.\n* (Fix) Removed unused code fragments.\n* (Fix) Fixed incorrect initialization of stripe buffers.\n* (Fix) Checked user access rights when executing truncate.\n* (Fix) Made copy command cancellable.\n* (Fix) Fixed namespace issue regarding drop table.\n\n### Version 1.5.1\n* (Fix) Verify cstore_fdw server on CREATE FOREIGN TABLE command\n\n### Version 1.5\n* (Feature) Added support for PostgreSQL 9.6.\n* (Fix) Removed table data when cstore_fdw table is indirectly dropped.\n* (Fix) Removed unused code fragments.\n* (Fix) Fixed column selection logic to return columns used in expressions.\n* (Fix) Prevented alter table command from changinf column type to incompatible types.\n\n### Version 1.4.1\n\n* (Fix) Compatibility fix for Citus [copy command][copy-command].\n\n### Version 1.4\n\n* (Feature) Added support for ```TRUNCATE TABLE```\n* (Fix) Added support for PostgreSQL 9.5\n\n### Version 1.3\n\n* (Feature) Added support for ```ALTER TABLE ADD COLUMN``` and ```ALTER TABLE DROP COLUMN```.\n* (Feature) Added column list support in ```COPY FROM```.\n* (Optimization) Improve row count estimation, which results in better plans.\n* (Fix) Fix the deadlock issue during concurrent inserts.\n* (Fix) Return correct result when using whole row references.\n\n### Version 1.2\n\n* (Feature) Added support for ```COPY TO```.\n* (Feature) Added support for ```INSERT INTO cstore_table SELECT ...```.\n* (Optimization) Improved memory usage.\n* (Fix) Dropping multiple cstore tables in a single command cleans-up files\n  of all them.\n\n### Version 1.1\n\n* (Feature) Make filename option optional, and use a default directory inside\n  $PGDATA to manage cstore tables.\n* (Feature) Automatically delete files on DROP FOREIGN TABLE.\n* (Fix) Return empty table if no data has been loaded. Previously, cstore_fdw\n  errored out.\n* (Fix) Fix overestimating relation column counts when planning.\n* (Feature) Added cstore\\_table\\_size(tablename) for getting the size of a cstore\n  table in bytes.\n\n\nCopyright\n---------\n\nCopyright (c) Citus Data, Inc.\n\nThis module is free software; you can redistribute it and/or modify it under the\nApache v2.0 License.\n\nFor all types of questions and comments about the wrapper, please contact us at\nengage @ citusdata.com.\n\n[status]: https://travis-ci.org/citusdata/cstore_fdw\n[mailing-list]: https://groups.google.com/forum/#!forum/cstore-users\n[coverage]: https://coveralls.io/r/citusdata/cstore_fdw\n[copy-command]: http://www.postgresql.org/docs/current/static/sql-copy.html\n[analyze-command]: http://www.postgresql.org/docs/current/static/sql-analyze.html\n"
        },
        {
          "name": "TODO.md",
          "type": "blob",
          "size": 1.5244140625,
          "content": "To see the list of features and bug-fixes planned for next releases, see our\n[development roadmap][roadmap].\n\nRequested Features\n------------------\n\n* Improve write performance\n* Improve read performance\n* Add checksum logic\n* Add new compression methods\n* Enable INSERT/DELETE/UPDATE\n* Enable users other than superuser to safely create columnar tables (permissions)\n* Transactional semantics\n* Add config setting to make pg\\_fsync() optional\n\n\nKnown Issues\n------------\n\n* Copy command ignores NOT NULL constraints.\n* Planning functions don't take into account average column width.\n* Planning functions don't correctly take into account block skipping benefits.\n* On 32-bit platforms, when file size is outside the 32-bit signed range, EXPLAIN\n  command prints incorrect file size.\n* If two different columnar tables are configured to point to the same file,\n  writes to the underlying file aren't protected from each other.\n* When a data load is in progress, concurrent reads on the table overestimate the\n  page count.\n* We have a minor memory leak in CStoreEndWrite. We need to also free the\n  comparisonFunctionArray.\n* block\\_filtering test fails on Ubuntu because the \"da\\_DK\" locale is not enabled\n  by default.\n* We don't yet incorporate the compression method's impact on disk I/O into cost\n  estimates.\n* CitusDB integration errors:\n* Concurrent staging cstore\\_fdw tables doesn't work.\n* Setting a default value for column with ALTER TABLE has limited support for\n  existing rows.\n\n[roadmap]: https://github.com/citusdata/cstore_fdw/wiki/Roadmap\n\n"
        },
        {
          "name": "cstore.proto",
          "type": "blob",
          "size": 1.2001953125,
          "content": "syntax = \"proto2\";\n\npackage protobuf;\n\nenum CompressionType {\n  // Values should match with the corresponding struct in cstore_fdw.h\n  NONE = 0;\n  PG_LZ = 1;\n};\n\nmessage ColumnBlockSkipNode {\n  optional uint64 rowCount = 1;\n  optional bytes minimumValue = 2;\n  optional bytes maximumValue = 3;\n  optional uint64 valueBlockOffset = 4;\n  optional uint64 valueLength = 5;\n  optional CompressionType valueCompressionType = 6;\n  optional uint64 existsBlockOffset = 7;\n  optional uint64 existsLength = 8;\n}\n\nmessage ColumnBlockSkipList {\n  repeated ColumnBlockSkipNode blockSkipNodeArray = 1;\n}\n\nmessage StripeFooter {\n  repeated uint64 skipListSizeArray = 1;\n  repeated uint64 existsSizeArray = 2;\n  repeated uint64 valueSizeArray = 3;\n}\n\nmessage StripeMetadata {\n  optional uint64 fileOffset = 1;\n  optional uint64 skipListLength = 2;\n  optional uint64 dataLength = 3;\n  optional uint64 footerLength = 4;\n}\n\nmessage TableFooter {\n  repeated StripeMetadata stripeMetadataArray = 1;\n  optional uint32 blockRowCount = 2;\n}\n\nmessage PostScript {\n  optional uint64 tableFooterLength = 1;\n  optional uint64 versionMajor = 2;\n  optional uint64 versionMinor = 3;\n  \n  // Leave this last in the record\n  optional string magicNumber = 8000;\n}\n"
        },
        {
          "name": "cstore_compression.c",
          "type": "blob",
          "size": 4.857421875,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_compression.c\n *\n * This file contains compression/decompression functions definitions\n * used in cstore_fdw.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n#include \"postgres.h\"\n#include \"cstore_fdw.h\"\n\n#if PG_VERSION_NUM >= 90500\n#include \"common/pg_lzcompress.h\"\n#else\n#include \"utils/pg_lzcompress.h\"\n#endif\n\n\n\n\n#if PG_VERSION_NUM >= 90500\n/*\n *\tThe information at the start of the compressed data. This decription is taken\n *\tfrom pg_lzcompress in pre-9.5 version of PostgreSQL.\n */\ntypedef struct CStoreCompressHeader\n{\n\tint32\t\tvl_len_;\t\t/* varlena header (do not touch directly!) */\n\tint32\t\trawsize;\n} CStoreCompressHeader;\n\n/*\n * Utilities for manipulation of header information for compressed data\n */\n\n#define CSTORE_COMPRESS_HDRSZ\t\t((int32) sizeof(CStoreCompressHeader))\n#define CSTORE_COMPRESS_RAWSIZE(ptr) (((CStoreCompressHeader *) (ptr))->rawsize)\n#define CSTORE_COMPRESS_RAWDATA(ptr) (((char *) (ptr)) + CSTORE_COMPRESS_HDRSZ)\n#define CSTORE_COMPRESS_SET_RAWSIZE(ptr, len) (((CStoreCompressHeader *) (ptr))->rawsize = (len))\n\n#else\n\n#define CSTORE_COMPRESS_HDRSZ\t\t(0)\n#define CSTORE_COMPRESS_RAWSIZE(ptr) (PGLZ_RAW_SIZE((PGLZ_Header *) buffer->data))\n#define CSTORE_COMPRESS_RAWDATA(ptr) (((PGLZ_Header *) (ptr)))\n#define CSTORE_COMPRESS_SET_RAWSIZE(ptr, len) (((CStoreCompressHeader *) (ptr))->rawsize = (len))\n\n#endif\n\n\n\n/*\n * CompressBuffer compresses the given buffer with the given compression type\n * outputBuffer enlarged to contain compressed data. The function returns true\n * if compression is done, returns false if compression is not done.\n * outputBuffer is valid only if the function returns true.\n */\nbool\nCompressBuffer(StringInfo inputBuffer, StringInfo outputBuffer,\n\t\t\t   CompressionType compressionType)\n{\n\tuint64 maximumLength = PGLZ_MAX_OUTPUT(inputBuffer->len) + CSTORE_COMPRESS_HDRSZ;\n\tbool compressionResult = false;\n#if PG_VERSION_NUM >= 90500\n\tint32 compressedByteCount = 0;\n#endif\n\n\tif (compressionType != COMPRESSION_PG_LZ)\n\t{\n\t\treturn false;\n\t}\n\n\tresetStringInfo(outputBuffer);\n\tenlargeStringInfo(outputBuffer, maximumLength);\n\n#if PG_VERSION_NUM >= 90500\n\tcompressedByteCount = pglz_compress((const char *) inputBuffer->data,\n\t\t\t\t\t\t\t\t\t\tinputBuffer->len,\n\t\t\t\t\t\t\t\t\t\tCSTORE_COMPRESS_RAWDATA(outputBuffer->data),\n\t\t\t\t\t\t\t\t\t\tPGLZ_strategy_always);\n\tif (compressedByteCount >= 0)\n\t{\n\t\tCSTORE_COMPRESS_SET_RAWSIZE(outputBuffer->data, inputBuffer->len);\n\t\tSET_VARSIZE_COMPRESSED(outputBuffer->data,\n\t\t\t\t\t\t\t   compressedByteCount + CSTORE_COMPRESS_HDRSZ);\n\t\tcompressionResult = true;\n\t}\n#else\n\n\tcompressionResult = pglz_compress(inputBuffer->data, inputBuffer->len,\n\t\t\t\t\t\t\t\t\t  CSTORE_COMPRESS_RAWDATA(outputBuffer->data),\n\t\t\t\t\t\t\t\t\t  PGLZ_strategy_always);\n#endif\n\n\tif (compressionResult)\n\t{\n\t\toutputBuffer->len = VARSIZE(outputBuffer->data);\n\t}\n\n\treturn compressionResult;\n}\n\n\n/*\n * DecompressBuffer decompresses the given buffer with the given compression\n * type. This function returns the buffer as-is when no compression is applied.\n */\nStringInfo\nDecompressBuffer(StringInfo buffer, CompressionType compressionType)\n{\n\tStringInfo decompressedBuffer = NULL;\n\n\tAssert(compressionType == COMPRESSION_NONE || compressionType == COMPRESSION_PG_LZ);\n\n\tif (compressionType == COMPRESSION_NONE)\n\t{\n\t\t/* in case of no compression, return buffer */\n\t\tdecompressedBuffer = buffer;\n\t}\n\telse if (compressionType == COMPRESSION_PG_LZ)\n\t{\n\t\tuint32 compressedDataSize = VARSIZE(buffer->data) - CSTORE_COMPRESS_HDRSZ;\n\t\tuint32 decompressedDataSize = CSTORE_COMPRESS_RAWSIZE(buffer->data);\n\t\tchar *decompressedData = NULL;\n#if PG_VERSION_NUM >= 90500\n\t\tint32 decompressedByteCount = 0;\n#endif\n\n\t\tif (compressedDataSize + CSTORE_COMPRESS_HDRSZ != buffer->len)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"cannot decompress the buffer\"),\n\t\t\t\t\t\t\terrdetail(\"Expected %u bytes, but received %u bytes\",\n\t\t\t\t\t\t\t\t\t  compressedDataSize, buffer->len)));\n\t\t}\n\n\t\tdecompressedData = palloc0(decompressedDataSize);\n\n#if PG_VERSION_NUM >= 90500\n\n#if PG_VERSION_NUM >= 120000\n\t\tdecompressedByteCount = pglz_decompress(CSTORE_COMPRESS_RAWDATA(buffer->data),\n\t\t\t\t\t\t\t\t\t\t\t\tcompressedDataSize, decompressedData,\n\t\t\t\t\t\t\t\t\t\t\t\tdecompressedDataSize, true);\n#else\n\t\tdecompressedByteCount = pglz_decompress(CSTORE_COMPRESS_RAWDATA(buffer->data),\n\t\t\t\t\t\t\t\t\t\t\t\tcompressedDataSize, decompressedData,\n\t\t\t\t\t\t\t\t\t\t\t\tdecompressedDataSize);\n#endif\n\n\t\tif (decompressedByteCount < 0)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"cannot decompress the buffer\"),\n\t\t\t\t\t\t\terrdetail(\"compressed data is corrupted\")));\n\t\t}\n#else\n\t\tpglz_decompress((PGLZ_Header *) buffer->data, decompressedData);\n#endif\n\n\t\tdecompressedBuffer = palloc0(sizeof(StringInfoData));\n\t\tdecompressedBuffer->data = decompressedData;\n\t\tdecompressedBuffer->len = decompressedDataSize;\n\t\tdecompressedBuffer->maxlen = decompressedDataSize;\n\t}\n\n\treturn decompressedBuffer;\n}\n"
        },
        {
          "name": "cstore_fdw--1.0--1.1.sql",
          "type": "blob",
          "size": 1.0419921875,
          "content": "/* cstore_fdw/cstore_fdw--1.0--1.1.sql */\n\n-- complain if script is sourced in psql, rather than via ALTER EXTENSION UPDATE\n\\echo Use \"ALTER EXTENSION cstore_fdw UPDATE TO '1.1'\" to load this file. \\quit\n\nCREATE FUNCTION cstore_ddl_event_end_trigger()\nRETURNS event_trigger\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE EVENT TRIGGER cstore_ddl_event_end\nON ddl_command_end\nEXECUTE PROCEDURE cstore_ddl_event_end_trigger();\n\nCREATE FUNCTION cstore_table_size(relation regclass)\nRETURNS bigint\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\n-- cstore_fdw creates directories to store files for tables with automatically\n-- determined filename during the CREATE SERVER statement. Since this feature\n-- was newly added in v1.1, servers created with v1.0 did not create them. So,\n-- we create a server with v1.1 to ensure that the required directories are\n-- created to allow users to create automatically managed tables with old servers.\nCREATE SERVER cstore_server_for_updating_1_0_to_1_1 FOREIGN DATA WRAPPER cstore_fdw;\nDROP SERVER cstore_server_for_updating_1_0_to_1_1;\n"
        },
        {
          "name": "cstore_fdw--1.1--1.2.sql",
          "type": "blob",
          "size": 0.09375,
          "content": "/* cstore_fdw/cstore_fdw--1.1--1.2.sql */\n\n-- No new functions or definitions were added in 1.2\n"
        },
        {
          "name": "cstore_fdw--1.2--1.3.sql",
          "type": "blob",
          "size": 0.09375,
          "content": "/* cstore_fdw/cstore_fdw--1.2--1.3.sql */\n\n-- No new functions or definitions were added in 1.3\n"
        },
        {
          "name": "cstore_fdw--1.3--1.4.sql",
          "type": "blob",
          "size": 0.09375,
          "content": "/* cstore_fdw/cstore_fdw--1.3--1.4.sql */\n\n-- No new functions or definitions were added in 1.4\n"
        },
        {
          "name": "cstore_fdw--1.4--1.5.sql",
          "type": "blob",
          "size": 0.58984375,
          "content": "/* cstore_fdw/cstore_fdw--1.4--1.5.sql */\n\nCREATE FUNCTION cstore_clean_table_resources(oid)\nRETURNS void\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE OR REPLACE FUNCTION cstore_drop_trigger()\n\tRETURNS event_trigger\n\tLANGUAGE plpgsql\n\tAS $csdt$\nDECLARE v_obj record;\nBEGIN\n\tFOR v_obj IN SELECT * FROM pg_event_trigger_dropped_objects() LOOP\n\n\t\tIF v_obj.object_type NOT IN ('table', 'foreign table') THEN\n\t\t\tCONTINUE;\n\t\tEND IF;\n\n\t\tPERFORM cstore_clean_table_resources(v_obj.objid);\n\n\tEND LOOP;\nEND;\n$csdt$;\n\nCREATE EVENT TRIGGER cstore_drop_event\n\tON SQL_DROP\n\tEXECUTE PROCEDURE cstore_drop_trigger();\n"
        },
        {
          "name": "cstore_fdw--1.5--1.6.sql",
          "type": "blob",
          "size": 0.40234375,
          "content": "/* cstore_fdw/cstore_fdw--1.5--1.6.sql */\n\nCREATE OR REPLACE FUNCTION cstore_drop_trigger()\n\tRETURNS event_trigger\n\tLANGUAGE plpgsql\n\tAS $csdt$\nDECLARE v_obj record;\nBEGIN\n\tFOR v_obj IN SELECT * FROM pg_event_trigger_dropped_objects() LOOP\n\n\t\tIF v_obj.object_type NOT IN ('table', 'foreign table') THEN\n\t\t\tCONTINUE;\n\t\tEND IF;\n\n\t\tPERFORM public.cstore_clean_table_resources(v_obj.objid);\n\n\tEND LOOP;\nEND;\n$csdt$;\n"
        },
        {
          "name": "cstore_fdw--1.6--1.7.sql",
          "type": "blob",
          "size": 0.09375,
          "content": "/* cstore_fdw/cstore_fdw--1.6--1.6.sql */\n\n-- No new functions or definitions were added in 1.7\n"
        },
        {
          "name": "cstore_fdw--1.7.sql",
          "type": "blob",
          "size": 1.3642578125,
          "content": "/* cstore_fdw/cstore_fdw--1.7.sql */\n\n-- complain if script is sourced in psql, rather than via CREATE EXTENSION\n\\echo Use \"CREATE EXTENSION cstore_fdw\" to load this file. \\quit\n\nCREATE FUNCTION cstore_fdw_handler()\nRETURNS fdw_handler\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE FUNCTION cstore_fdw_validator(text[], oid)\nRETURNS void\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE FOREIGN DATA WRAPPER cstore_fdw\nHANDLER cstore_fdw_handler\nVALIDATOR cstore_fdw_validator;\n\nCREATE FUNCTION cstore_ddl_event_end_trigger()\nRETURNS event_trigger\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE EVENT TRIGGER cstore_ddl_event_end\nON ddl_command_end\nEXECUTE PROCEDURE cstore_ddl_event_end_trigger();\n\nCREATE FUNCTION cstore_table_size(relation regclass)\nRETURNS bigint\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE OR REPLACE FUNCTION cstore_clean_table_resources(oid)\nRETURNS void\nAS 'MODULE_PATHNAME'\nLANGUAGE C STRICT;\n\nCREATE OR REPLACE FUNCTION cstore_drop_trigger()\n\tRETURNS event_trigger\n\tLANGUAGE plpgsql\n\tAS $csdt$\nDECLARE v_obj record;\nBEGIN\n\tFOR v_obj IN SELECT * FROM pg_event_trigger_dropped_objects() LOOP\n\n\t\tIF v_obj.object_type NOT IN ('table', 'foreign table') THEN\n\t\t\tCONTINUE;\n\t\tEND IF;\n\n\t\tPERFORM public.cstore_clean_table_resources(v_obj.objid);\n\n\tEND LOOP;\nEND;\n$csdt$;\n\nCREATE EVENT TRIGGER cstore_drop_event\n    ON SQL_DROP\n    EXECUTE PROCEDURE cstore_drop_trigger();\n\n"
        },
        {
          "name": "cstore_fdw.c",
          "type": "blob",
          "size": 72.1181640625,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_fdw.c\n *\n * This file contains the function definitions for scanning, analyzing, and\n * copying into cstore_fdw foreign tables. Note that this file uses the API\n * provided by cstore_reader and cstore_writer for reading and writing cstore\n * files.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n#include \"postgres.h\"\n#include \"cstore_fdw.h\"\n#include \"cstore_version_compat.h\"\n\n#include <sys/stat.h>\n#include <unistd.h>\n#include <limits.h>\n#include \"access/htup_details.h\"\n#include \"access/reloptions.h\"\n#include \"access/sysattr.h\"\n#if PG_VERSION_NUM >= 130000\n#include \"access/heaptoast.h\"\n#else\n#include \"access/tuptoaster.h\"\n#endif\n#include \"catalog/namespace.h\"\n#include \"catalog/pg_foreign_table.h\"\n#include \"catalog/pg_namespace.h\"\n#include \"commands/copy.h\"\n#include \"commands/dbcommands.h\"\n#include \"commands/defrem.h\"\n#include \"commands/event_trigger.h\"\n#include \"commands/explain.h\"\n#include \"commands/extension.h\"\n#include \"commands/vacuum.h\"\n#include \"foreign/fdwapi.h\"\n#include \"foreign/foreign.h\"\n#include \"miscadmin.h\"\n#include \"nodes/makefuncs.h\"\n#include \"optimizer/cost.h\"\n#include \"optimizer/pathnode.h\"\n#include \"optimizer/planmain.h\"\n#include \"optimizer/restrictinfo.h\"\n#if PG_VERSION_NUM >= 120000\n#include \"access/heapam.h\"\n#include \"access/tableam.h\"\n#include \"executor/tuptable.h\"\n#include \"optimizer/optimizer.h\"\n#else\n#include \"optimizer/var.h\"\n#endif\n#include \"parser/parser.h\"\n#include \"parser/parsetree.h\"\n#include \"parser/parse_coerce.h\"\n#include \"parser/parse_type.h\"\n#include \"storage/fd.h\"\n#include \"tcop/utility.h\"\n#include \"utils/builtins.h\"\n#include \"utils/fmgroids.h\"\n#include \"utils/memutils.h\"\n#include \"utils/lsyscache.h\"\n#include \"utils/rel.h\"\n#if PG_VERSION_NUM >= 120000\n#include \"utils/snapmgr.h\"\n#else\n#include \"utils/tqual.h\"\n#endif\n\n#include \"cstore_version_compat.h\"\n\n\n/* local functions forward declarations */\n#if PG_VERSION_NUM >= 130000\nstatic void CStoreProcessUtility(PlannedStmt *plannedStatement, const char *queryString,\n\t\t\t\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t\t\t\t QueryEnvironment *queryEnvironment,\n\t\t\t\t\t\t\t\t DestReceiver *destReceiver,\n\t\t\t\t\t\t\t\t QueryCompletion *queryCompletion);\n#elif PG_VERSION_NUM >= 100000\nstatic void CStoreProcessUtility(PlannedStmt *plannedStatement, const char *queryString,\n\t\t\t\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t\t\t\t QueryEnvironment *queryEnvironment,\n\t\t\t\t\t\t\t\t DestReceiver *destReceiver, char *completionTag);\n#else\nstatic void CStoreProcessUtility(Node *parseTree, const char *queryString,\n\t\t\t\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t\t\t\t DestReceiver *destReceiver, char *completionTag);\n#endif\nstatic bool CopyCStoreTableStatement(CopyStmt* copyStatement);\nstatic void CheckSuperuserPrivilegesForCopy(const CopyStmt* copyStatement);\nstatic uint64 CStoreProcessCopyCommand(CopyStmt *copyStatement, const char *queryString);\nstatic uint64 CopyIntoCStoreTable(const CopyStmt *copyStatement,\n\t\t\t\t\t\t\t\t  const char *queryString);\nstatic uint64 CopyOutCStoreTable(CopyStmt* copyStatement, const char* queryString);\nstatic void CStoreProcessAlterTableCommand(AlterTableStmt *alterStatement);\nstatic List * DroppedCStoreFilenameList(DropStmt *dropStatement);\nstatic List * FindCStoreTables(List *tableList);\nstatic List * OpenRelationsForTruncate(List *cstoreTableList);\nstatic void TruncateCStoreTables(List *cstoreRelationList);\nstatic void DeleteCStoreTableFiles(char *filename);\nstatic void InitializeCStoreTableFile(Oid relationId, Relation relation);\nstatic bool CStoreTable(Oid relationId);\nstatic bool CStoreServer(ForeignServer *server);\nstatic bool DistributedTable(Oid relationId);\nstatic bool DistributedWorkerCopy(CopyStmt *copyStatement);\nstatic void CreateCStoreDatabaseDirectory(Oid databaseOid);\nstatic bool DirectoryExists(StringInfo directoryName);\nstatic void CreateDirectory(StringInfo directoryName);\nstatic void RemoveCStoreDatabaseDirectory(Oid databaseOid);\nstatic StringInfo OptionNamesString(Oid currentContextId);\nstatic HeapTuple GetSlotHeapTuple(TupleTableSlot *tts);\nstatic CStoreFdwOptions * CStoreGetOptions(Oid foreignTableId);\nstatic char * CStoreGetOptionValue(Oid foreignTableId, const char *optionName);\nstatic void ValidateForeignTableOptions(char *filename, char *compressionTypeString,\n\t\t\t\t\t\t\t\t\t\tchar *stripeRowCountString,\n\t\t\t\t\t\t\t\t\t\tchar *blockRowCountString);\nstatic char * CStoreDefaultFilePath(Oid foreignTableId);\nstatic CompressionType ParseCompressionType(const char *compressionTypeString);\nstatic void CStoreGetForeignRelSize(PlannerInfo *root, RelOptInfo *baserel,\n\t\t\t\t\t\t\t\t\tOid foreignTableId);\nstatic void CStoreGetForeignPaths(PlannerInfo *root, RelOptInfo *baserel,\n\t\t\t\t\t\t\t\t  Oid foreignTableId);\n#if PG_VERSION_NUM >= 90500\nstatic ForeignScan * CStoreGetForeignPlan(PlannerInfo *root, RelOptInfo *baserel,\n\t\t\t\t\t\t\t\t\t\t  Oid foreignTableId, ForeignPath *bestPath,\n\t\t\t\t\t\t\t\t\t\t  List *targetList, List *scanClauses,\n\t\t\t\t\t\t\t\t\t\t  Plan *outerPlan);\n#else\nstatic ForeignScan * CStoreGetForeignPlan(PlannerInfo *root, RelOptInfo *baserel,\n\t\t\t\t\t\t\t\t\t\t  Oid foreignTableId, ForeignPath *bestPath,\n\t\t\t\t\t\t\t\t\t\t  List *targetList, List *scanClauses);\n#endif\nstatic double TupleCountEstimate(RelOptInfo *baserel, const char *filename);\nstatic BlockNumber PageCount(const char *filename);\nstatic List * ColumnList(RelOptInfo *baserel, Oid foreignTableId);\nstatic void CStoreExplainForeignScan(ForeignScanState *scanState,\n\t\t\t\t\t\t\t\t\t ExplainState *explainState);\nstatic void CStoreBeginForeignScan(ForeignScanState *scanState, int executorFlags);\nstatic TupleTableSlot * CStoreIterateForeignScan(ForeignScanState *scanState);\nstatic void CStoreEndForeignScan(ForeignScanState *scanState);\nstatic void CStoreReScanForeignScan(ForeignScanState *scanState);\nstatic bool CStoreAnalyzeForeignTable(Relation relation,\n\t\t\t\t\t\t\t\t\t  AcquireSampleRowsFunc *acquireSampleRowsFunc,\n\t\t\t\t\t\t\t\t\t  BlockNumber *totalPageCount);\nstatic int CStoreAcquireSampleRows(Relation relation, int logLevel,\n\t\t\t\t\t\t\t\t   HeapTuple *sampleRows, int targetRowCount,\n\t\t\t\t\t\t\t\t   double *totalRowCount, double *totalDeadRowCount);\nstatic List * CStorePlanForeignModify(PlannerInfo *plannerInfo, ModifyTable *plan,\n\t\t\t\t\t\t\t\t\t Index resultRelation, int subplanIndex);\nstatic void CStoreBeginForeignModify(ModifyTableState *modifyTableState,\n\t\t\t\t\t\t\t\t\t ResultRelInfo *relationInfo, List *fdwPrivate,\n\t\t\t\t\t\t\t\t\t int subplanIndex, int executorflags);\nstatic void CStoreBeginForeignInsert(ModifyTableState *modifyTableState,\n\t\t\t\t\t\t\t\t\t ResultRelInfo *relationInfo);\nstatic TupleTableSlot * CStoreExecForeignInsert(EState *executorState,\n\t\t\t\t\t\t\t\t\t\t\t\tResultRelInfo *relationInfo,\n\t\t\t\t\t\t\t\t\t\t\t\tTupleTableSlot *tupleSlot,\n\t\t\t\t\t\t\t\t\t\t\t\tTupleTableSlot *planSlot);\nstatic void CStoreEndForeignModify(EState *executorState, ResultRelInfo *relationInfo);\nstatic void CStoreEndForeignInsert(EState *executorState, ResultRelInfo *relationInfo);\n#if PG_VERSION_NUM >= 90600\nstatic bool CStoreIsForeignScanParallelSafe(PlannerInfo *root, RelOptInfo *rel,\n\t\t\t\t\t\t\t\t\t\t\tRangeTblEntry *rte);\n#endif\n\n/* declarations for dynamic loading */\nPG_MODULE_MAGIC;\n\nPG_FUNCTION_INFO_V1(cstore_ddl_event_end_trigger);\nPG_FUNCTION_INFO_V1(cstore_table_size);\nPG_FUNCTION_INFO_V1(cstore_fdw_handler);\nPG_FUNCTION_INFO_V1(cstore_fdw_validator);\nPG_FUNCTION_INFO_V1(cstore_clean_table_resources);\n\n\n/* saved hook value in case of unload */\nstatic ProcessUtility_hook_type PreviousProcessUtilityHook = NULL;\n\n\n/*\n * _PG_init is called when the module is loaded. In this function we save the\n * previous utility hook, and then install our hook to pre-intercept calls to\n * the copy command.\n */\nvoid _PG_init(void)\n{\n\tPreviousProcessUtilityHook = (ProcessUtility_hook != NULL) ?\n\t\t\t\t\t\t\t\t ProcessUtility_hook : standard_ProcessUtility;\n\tProcessUtility_hook = CStoreProcessUtility;\n}\n\n\n/*\n * _PG_fini is called when the module is unloaded. This function uninstalls the\n * extension's hooks.\n */\nvoid _PG_fini(void)\n{\n\tProcessUtility_hook = PreviousProcessUtilityHook;\n}\n\n\n/*\n * cstore_ddl_event_end_trigger is the event trigger function which is called on\n * ddl_command_end event. This function creates required directories after the\n * CREATE SERVER statement and valid data and footer files after the CREATE FOREIGN\n * TABLE statement.\n */\nDatum\ncstore_ddl_event_end_trigger(PG_FUNCTION_ARGS)\n{\n\tEventTriggerData *triggerData = NULL;\n\tNode *parseTree = NULL;\n\n\t/* error if event trigger manager did not call this function */\n\tif (!CALLED_AS_EVENT_TRIGGER(fcinfo))\n\t{\n\t\tereport(ERROR, (errmsg(\"trigger not fired by event trigger manager\")));\n\t}\n\n\ttriggerData = (EventTriggerData *) fcinfo->context;\n\tparseTree = triggerData->parsetree;\n\n\tif (nodeTag(parseTree) == T_CreateForeignServerStmt)\n\t{\n\t\tCreateForeignServerStmt *serverStatement = (CreateForeignServerStmt *) parseTree;\n\n\t\tchar *foreignWrapperName = serverStatement->fdwname;\n\t\tif (strncmp(foreignWrapperName, CSTORE_FDW_NAME, NAMEDATALEN) == 0)\n\t\t{\n\t\t\tCreateCStoreDatabaseDirectory(MyDatabaseId);\n\t\t}\n\t}\n\telse if (nodeTag(parseTree) == T_CreateForeignTableStmt)\n\t{\n\t\tCreateForeignTableStmt *createStatement = (CreateForeignTableStmt *) parseTree;\n\t\tchar *serverName = createStatement->servername;\n\n\t\tbool missingOK = false;\n\t\tForeignServer *server = GetForeignServerByName(serverName, missingOK);\n\t\tif (CStoreServer(server))\n\t\t{\n\t\t\tOid relationId = RangeVarGetRelid(createStatement->base.relation,\n\t\t\t\t\t\t\t\t\t\t\t  AccessShareLock, false);\n\t\t\tRelation relation = relation_open(relationId, AccessExclusiveLock);\n\n\t\t\t/*\n\t\t\t * Make sure database directory exists before creating a table.\n\t\t\t * This is necessary when a foreign server is created inside\n\t\t\t * a template database and a new database is created out of it.\n\t\t\t * We have no chance to hook into server creation to create data\n\t\t\t * directory for it during database creation time.\n\t\t\t */\n\t\t\tCreateCStoreDatabaseDirectory(MyDatabaseId);\n\n\t\t\tInitializeCStoreTableFile(relationId, relation);\n\t\t\trelation_close(relation, AccessExclusiveLock);\n\t\t}\n\t}\n\n\tPG_RETURN_NULL();\n}\n\n\n/*\n * CStoreProcessUtility is the hook for handling utility commands. This function\n * customizes the behaviour of \"COPY cstore_table\" and \"DROP FOREIGN TABLE\n * cstore_table\" commands. For all other utility statements, the function calls\n * the previous utility hook or the standard utility command via macro\n * CALL_PREVIOUS_UTILITY.\n */\n#if PG_VERSION_NUM >= 130000\nstatic void\nCStoreProcessUtility(PlannedStmt *plannedStatement, const char *queryString,\n\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t QueryEnvironment *queryEnvironment,\n\t\t\t\t\t DestReceiver *destReceiver, QueryCompletion *queryCompletion)\n#elif PG_VERSION_NUM >= 100000\nstatic void\nCStoreProcessUtility(PlannedStmt * plannedStatement, const char * queryString,\n\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t QueryEnvironment * queryEnvironment,\n\t\t\t\t\t DestReceiver * destReceiver, char * completionTag)\n#else\nstatic void\nCStoreProcessUtility(Node * parseTree, const char * queryString,\n\t\t\t\t\t ProcessUtilityContext context,\n\t\t\t\t\t ParamListInfo paramListInfo,\n\t\t\t\t\t DestReceiver * destReceiver, char * completionTag)\n#endif\n{\n#if PG_VERSION_NUM >= 100000\n\tNode *parseTree = plannedStatement->utilityStmt;\n#endif\n\n\tif (nodeTag(parseTree) == T_CopyStmt)\n\t{\n\t\tCopyStmt *copyStatement = (CopyStmt *) parseTree;\n\n\t\tif (CopyCStoreTableStatement(copyStatement))\n\t\t{\n\t\t\tuint64 processed =\n\t\t\t\tCStoreProcessCopyCommand(copyStatement, queryString);\n\n#if PG_VERSION_NUM >= 130000\n\t\t\tif (queryCompletion)\n\t\t\t{\n\t\t\t\tSetQueryCompletion(queryCompletion, CMDTAG_COPY, processed);\n\t\t\t}\n#else\n\t\t\tif (completionTag != NULL)\n\t\t\t{\n\t\t\t\tsnprintf(completionTag, COMPLETION_TAG_BUFSIZE,\n\t\t\t\t\t\t \"COPY \" UINT64_FORMAT, processed);\n\t\t\t}\n#endif\n\t\t}\n\t\telse\n\t\t{\n\t\t\tCALL_PREVIOUS_UTILITY();\n\t\t}\n\t}\n\telse if (nodeTag(parseTree) == T_DropStmt)\n\t{\n\t\tDropStmt *dropStmt = (DropStmt *) parseTree;\n\n\t\tif (dropStmt->removeType == OBJECT_EXTENSION)\n\t\t{\n\t\t\tbool removeCStoreDirectory = false;\n\t\t\tListCell *objectCell = NULL;\n\n\t\t\tforeach(objectCell, dropStmt->objects)\n\t\t\t{\n\t\t\t\tNode *object = (Node *) lfirst(objectCell);\n\t\t\t\tchar *objectName = NULL;\n\n#if PG_VERSION_NUM >= 100000\n\t\t\t\tAssert(IsA(object, String));\n\t\t\t\tobjectName = strVal(object);\n#else\n\t\t\t\tAssert(IsA(object, List));\n\t\t\t\tobjectName = strVal(linitial((List *) object));\n#endif\n\n\t\t\t\tif (strncmp(CSTORE_FDW_NAME, objectName, NAMEDATALEN) == 0)\n\t\t\t\t{\n\t\t\t\t\tremoveCStoreDirectory = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tCALL_PREVIOUS_UTILITY();\n\n\t\t\tif (removeCStoreDirectory)\n\t\t\t{\n\t\t\t\tRemoveCStoreDatabaseDirectory(MyDatabaseId);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tListCell *fileListCell = NULL;\n\t\t\tList *droppedTables = DroppedCStoreFilenameList((DropStmt *) parseTree);\n\n\t\t\tCALL_PREVIOUS_UTILITY();\n\n\t\t\tforeach(fileListCell, droppedTables)\n\t\t\t{\n\t\t\t\tchar *fileName = lfirst(fileListCell);\n\n\t\t\t\tDeleteCStoreTableFiles(fileName);\n\t\t\t}\n\t\t}\n\t}\n\telse if (nodeTag(parseTree) == T_TruncateStmt)\n\t{\n\t\tTruncateStmt *truncateStatement = (TruncateStmt *) parseTree;\n\t\tList *allTablesList = truncateStatement->relations;\n\t\tList *cstoreTablesList = FindCStoreTables(allTablesList);\n\t\tList *otherTablesList = list_difference(allTablesList, cstoreTablesList);\n\t\tList *cstoreRelationList = OpenRelationsForTruncate(cstoreTablesList);\n\t\tListCell *cstoreRelationCell = NULL;\n\n\t\tif (otherTablesList != NIL)\n\t\t{\n\t\t\ttruncateStatement->relations = otherTablesList;\n\n\t\t\tCALL_PREVIOUS_UTILITY();\n                        /* restore the former relation list. Our\n                         * replacement could be freed but still needed\n                         * in a cached plan. A truncate can be cached\n                         * if run from a pl/pgSQL function */\n                        truncateStatement->relations = allTablesList;\n\t\t}\n\n\t\tTruncateCStoreTables(cstoreRelationList);\n\n\t\tforeach(cstoreRelationCell, cstoreRelationList)\n\t\t{\n\t\t\tRelation relation = (Relation) lfirst(cstoreRelationCell);\n\t\t\trelation_close(relation, AccessExclusiveLock);\n\t\t}\n\t}\n\telse if (nodeTag(parseTree) == T_AlterTableStmt)\n\t{\n\t\tAlterTableStmt *alterTable = (AlterTableStmt *) parseTree;\n\t\tCStoreProcessAlterTableCommand(alterTable);\n\t\tCALL_PREVIOUS_UTILITY();\n\t}\n\telse if (nodeTag(parseTree) == T_DropdbStmt)\n\t{\n\t\tDropdbStmt *dropDdStmt = (DropdbStmt *) parseTree;\n\t\tbool missingOk = true;\n\t\tOid databaseOid = get_database_oid(dropDdStmt->dbname, missingOk);\n\n\t\t/* let postgres handle error checking and dropping of the database */\n\t\tCALL_PREVIOUS_UTILITY();\n\n\t\tif (databaseOid != InvalidOid)\n\t\t{\n\t\t\tRemoveCStoreDatabaseDirectory(databaseOid);\n\t\t}\n\t}\n\t/* handle other utility statements */\n\telse\n\t{\n\t\tCALL_PREVIOUS_UTILITY();\n\t}\n}\n\n\n/*\n * CopyCStoreTableStatement check whether the COPY statement is a \"COPY cstore_table FROM\n * ...\" or \"COPY cstore_table TO ....\" statement. If it is then the function returns\n * true. The function returns false otherwise.\n */\nstatic bool\nCopyCStoreTableStatement(CopyStmt* copyStatement)\n{\n\tbool copyCStoreTableStatement = false;\n\n\tif (copyStatement->relation != NULL)\n\t{\n\t\tOid relationId = RangeVarGetRelid(copyStatement->relation,\n\t\t\t\t\t\t\t\t\t\t  AccessShareLock, true);\n\t\tbool cstoreTable = CStoreTable(relationId);\n\t\tif (cstoreTable)\n\t\t{\n\t\t\tbool distributedTable = DistributedTable(relationId);\n\t\t\tbool distributedCopy = DistributedWorkerCopy(copyStatement);\n\n\t\t\tif (distributedTable || distributedCopy)\n\t\t\t{\n\t\t\t\t/* let COPY on distributed tables fall through to Citus */\n\t\t\t\tcopyCStoreTableStatement = false;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tcopyCStoreTableStatement = true;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn copyCStoreTableStatement;\n}\n\n\n/*\n * CheckSuperuserPrivilegesForCopy checks if superuser privilege is required by\n * copy operation and reports error if user does not have superuser rights.\n */\nstatic void\nCheckSuperuserPrivilegesForCopy(const CopyStmt* copyStatement)\n{\n\t/*\n\t * We disallow copy from file or program except to superusers. These checks\n\t * are based on the checks in DoCopy() function of copy.c.\n\t */\n\tif (copyStatement->filename != NULL && !superuser())\n\t{\n\t\tif (copyStatement->is_program)\n\t\t{\n\t\t\tereport(ERROR, (errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),\n\t\t\t\t\t errmsg(\"must be superuser to COPY to or from a program\"),\n\t\t\t\t\t errhint(\"Anyone can COPY to stdout or from stdin. \"\n\t\t\t\t\t\t\t \"psql's \\\\copy command also works for anyone.\")));\n\t\t}\n\t\telse\n\t\t{\n\t\t\tereport(ERROR, (errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),\n\t\t\t\t\t errmsg(\"must be superuser to COPY to or from a file\"),\n\t\t\t\t\t errhint(\"Anyone can COPY to stdout or from stdin. \"\n\t\t\t\t\t\t\t \"psql's \\\\copy command also works for anyone.\")));\n\t\t}\n\t}\n}\n\n\n/*\n * CStoreProcessCopyCommand handles COPY <cstore_table> FROM/TO ... statements.\n * It determines the copy direction and forwards execution to appropriate function.\n * \n * It returns number of rows processed.\n */\nstatic uint64\nCStoreProcessCopyCommand(CopyStmt *copyStatement, const char* queryString)\n{\n\tuint64 processedCount = 0;\n\n\tif (copyStatement->is_from)\n\t{\n\t\tprocessedCount = CopyIntoCStoreTable(copyStatement, queryString);\n\t}\n\telse\n\t{\n\t\tprocessedCount = CopyOutCStoreTable(copyStatement, queryString);\n\t}\n\n\treturn processedCount;\n}\n\n\n/*\n * CopyIntoCStoreTable handles a \"COPY cstore_table FROM\" statement. This\n * function uses the COPY command's functions to read and parse rows from\n * the data source specified in the COPY statement. The function then writes\n * each row to the file specified in the cstore foreign table options. Finally,\n * the function returns the number of copied rows.\n */\nstatic uint64\nCopyIntoCStoreTable(const CopyStmt *copyStatement, const char *queryString)\n{\n\tuint64 processedRowCount = 0;\n\tRelation relation = NULL;\n\tOid relationId = InvalidOid;\n\tTupleDesc tupleDescriptor = NULL;\n\tuint32 columnCount = 0;\n\tCopyState copyState = NULL;\n\tbool nextRowFound = true;\n\tDatum *columnValues = NULL;\n\tbool *columnNulls = NULL;\n\tTableWriteState *writeState = NULL;\n\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\tMemoryContext tupleContext = NULL;\n\n\t/* Only superuser can copy from or to local file */\n\tCheckSuperuserPrivilegesForCopy(copyStatement);\n\n\tAssert(copyStatement->relation != NULL);\n\n\t/*\n\t * Open and lock the relation. We acquire ShareUpdateExclusiveLock to allow\n\t * concurrent reads, but block concurrent writes.\n\t */\n\trelation = relation_openrv(copyStatement->relation, ShareUpdateExclusiveLock);\n\trelationId = RelationGetRelid(relation);\n\n\t/* allocate column values and nulls arrays */\n\ttupleDescriptor = RelationGetDescr(relation);\n\tcolumnCount = tupleDescriptor->natts;\n\tcolumnValues = palloc0(columnCount * sizeof(Datum));\n\tcolumnNulls = palloc0(columnCount * sizeof(bool));\n\n\tcstoreFdwOptions = CStoreGetOptions(relationId);\n\n\t/*\n\t * We create a new memory context called tuple context, and read and write\n\t * each row's values within this memory context. After each read and write,\n\t * we reset the memory context. That way, we immediately release memory\n\t * allocated for each row, and don't bloat memory usage with large input\n\t * files.\n\t */\n\ttupleContext = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t \"CStore COPY Row Memory Context\",\n\t\t\t\t\t\t\t\t\t\t ALLOCSET_DEFAULT_SIZES);\n\n\t/* init state to read from COPY data source */\n#if (PG_VERSION_NUM >= 100000)\n\t{\n\t\tParseState *pstate = make_parsestate(NULL);\n\t\tpstate->p_sourcetext = queryString;\n\n\t\tcopyState = BeginCopyFrom(pstate, relation, copyStatement->filename,\n\t\t\t\t\t\t\t\t  copyStatement->is_program,\n\t\t\t\t\t\t\t\t  NULL,\n\t\t\t\t\t\t\t\t  copyStatement->attlist,\n\t\t\t\t\t\t\t\t  copyStatement->options);\n\t\tfree_parsestate(pstate);\n\t}\n#else\n\tcopyState = BeginCopyFrom(relation, copyStatement->filename,\n\t\t\t\t\t\t\t  copyStatement->is_program,\n\t\t\t\t\t\t\t  copyStatement->attlist,\n\t\t\t\t\t\t\t  copyStatement->options);\n#endif\n\n\t/* init state to write to the cstore file */\n\twriteState = CStoreBeginWrite(cstoreFdwOptions->filename,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->compressionType,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->stripeRowCount,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->blockRowCount,\n\t\t\t\t\t\t\t\t  tupleDescriptor);\n\n\twhile (nextRowFound)\n\t{\n\t\t/* read the next row in tupleContext */\n\t\tMemoryContext oldContext = MemoryContextSwitchTo(tupleContext);\n#if PG_VERSION_NUM >= 120000\n\t\tnextRowFound = NextCopyFrom(copyState, NULL, columnValues, columnNulls);\n#else\n\t\tnextRowFound = NextCopyFrom(copyState, NULL, columnValues, columnNulls, NULL);\n#endif\n\t\tMemoryContextSwitchTo(oldContext);\n\n\t\t/* write the row to the cstore file */\n\t\tif (nextRowFound)\n\t\t{\n\t\t\tCStoreWriteRow(writeState, columnValues, columnNulls);\n\t\t\tprocessedRowCount++;\n\t\t}\n\n\t\tMemoryContextReset(tupleContext);\n\n\t\tCHECK_FOR_INTERRUPTS();\n\t}\n\n\t/* end read/write sessions and close the relation */\n\tEndCopyFrom(copyState);\n\tCStoreEndWrite(writeState);\n\trelation_close(relation, ShareUpdateExclusiveLock);\n\n\treturn processedRowCount;\n}\n\n\n/*\n * CopyFromCStoreTable handles a \"COPY cstore_table TO ...\" statement. Statement\n * is converted to \"COPY (SELECT * FROM cstore_table) TO ...\" and forwarded to\n * postgres native COPY handler. Function returns number of files copied to external\n * stream. Copying selected columns from cstore table is not currently supported.\n */\nstatic uint64\nCopyOutCStoreTable(CopyStmt* copyStatement, const char* queryString)\n{\n\tuint64 processedCount = 0;\n\tRangeVar *relation = NULL;\n\tchar *qualifiedName = NULL;\n\tList *queryList = NIL;\n\tNode *rawQuery = NULL;\n\n\tStringInfo newQuerySubstring = makeStringInfo();\n\n\tif (copyStatement->attlist != NIL)\n\t{\n\t\tereport(ERROR, (errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t\t\terrmsg(\"copy column list is not supported\"),\n\t\t\t\t\t\terrhint(\"use 'copy (select <columns> from <table>) to \"\n\t\t\t\t\t\t\t\t\"...' instead\")));\n\t}\n\n\trelation = copyStatement->relation;\n\tqualifiedName = quote_qualified_identifier(relation->schemaname,\n\t\t\t\t\t\t\t\t\t\t\t   relation->relname);\n\tappendStringInfo(newQuerySubstring, \"select * from %s\", qualifiedName);\n\tqueryList = raw_parser(newQuerySubstring->data);\n\n\t/* take the first parse tree */\n\trawQuery = linitial(queryList);\n\n\t/*\n\t * Set the relation field to NULL so that COPY command works on\n\t * query field instead.\n\t */\n\tcopyStatement->relation = NULL;\n\n#if (PG_VERSION_NUM >= 100000)\n\t/*\n\t * raw_parser returns list of RawStmt* in PG 10+ we need to\n\t * extract actual query from it.\n\t */\n\t{\n\t\tParseState *pstate = make_parsestate(NULL);\n\t\tRawStmt *rawStatement = (RawStmt *) rawQuery;\n\n\t\tpstate->p_sourcetext = newQuerySubstring->data;\n\t\tcopyStatement->query = rawStatement->stmt;\n\n\t\tDoCopy(pstate, copyStatement, -1, -1, &processedCount);\n\t\tfree_parsestate(pstate);\n\t}\n#else\n\tcopyStatement->query = rawQuery;\n\n\tDoCopy(copyStatement, queryString, &processedCount);\n#endif\n\n\treturn processedCount;\n}\n\n\n/*\n * CStoreProcessAlterTableCommand checks if given alter table statement is\n * compatible with underlying data structure. Currently it only checks alter\n * column type. The function errors out if current column type can not be safely\n * converted to requested column type. This check is more restrictive than\n * PostgreSQL's because we can not change existing data.\n */\nstatic void\nCStoreProcessAlterTableCommand(AlterTableStmt *alterStatement)\n{\n\tObjectType objectType = alterStatement->relkind;\n\tRangeVar *relationRangeVar = alterStatement->relation;\n\tOid relationId = InvalidOid;\n\tList *commandList = alterStatement->cmds;\n\tListCell *commandCell = NULL;\n\n\t/* we are only interested in foreign table changes */\n\tif (objectType != OBJECT_TABLE && objectType != OBJECT_FOREIGN_TABLE)\n\t{\n\t\treturn;\n\t}\n\n\trelationId = RangeVarGetRelid(relationRangeVar, AccessShareLock, true);\n\tif (!CStoreTable(relationId))\n\t{\n\t\treturn;\n\t}\n\n\tforeach(commandCell, commandList)\n\t{\n\t\tAlterTableCmd *alterCommand = (AlterTableCmd *) lfirst(commandCell);\n\t\tif(alterCommand->subtype == AT_AlterColumnType)\n\t\t{\n\t\t\tchar *columnName = alterCommand->name;\n\t\t\tColumnDef *columnDef = (ColumnDef *) alterCommand->def;\n\t\t\tOid targetTypeId = typenameTypeId(NULL, columnDef->typeName);\n\t\t\tchar *typeName = TypeNameToString(columnDef->typeName);\n\t\t\tAttrNumber attributeNumber = get_attnum(relationId, columnName);\n\t\t\tOid currentTypeId = InvalidOid;\n\n\t\t\tif (attributeNumber <= 0)\n\t\t\t{\n\t\t\t\t/* let standard utility handle this */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcurrentTypeId = get_atttype(relationId, attributeNumber);\n\n\t\t\t/*\n\t\t\t * We are only interested in implicit coersion type compatibility.\n\t\t\t * Erroring out here to prevent further processing.\n\t\t\t */\n\t\t\tif (!can_coerce_type(1, &currentTypeId, &targetTypeId, COERCION_IMPLICIT))\n\t\t\t{\n\t\t\t\tereport(ERROR, (errmsg(\"Column %s cannot be cast automatically to \"\n\t\t\t\t\t\t\t\t\t   \"type %s\", columnName, typeName)));\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/*\n * DropppedCStoreFilenameList extracts and returns the list of cstore file names\n * from DROP table statement\n */\nstatic List *\nDroppedCStoreFilenameList(DropStmt *dropStatement)\n{\n\tList *droppedCStoreFileList = NIL;\n\n\tif (dropStatement->removeType == OBJECT_FOREIGN_TABLE)\n\t{\n\t\tListCell *dropObjectCell = NULL;\n\t\tforeach(dropObjectCell, dropStatement->objects)\n\t\t{\n\t\t\tList *tableNameList = (List *) lfirst(dropObjectCell);\n\t\t\tRangeVar *rangeVar = makeRangeVarFromNameList(tableNameList);\n\n\t\t\tOid relationId = RangeVarGetRelid(rangeVar, AccessShareLock, true);\n\t\t\tif (CStoreTable(relationId))\n\t\t\t{\n\t\t\t\tCStoreFdwOptions *cstoreFdwOptions = CStoreGetOptions(relationId);\n\t\t\t\tchar *defaultfilename = CStoreDefaultFilePath(relationId);\n\n\t\t\t\t/*\n\t\t\t\t * Skip files that are placed in default location, they are handled\n\t\t\t\t * by sql drop trigger. Both paths are generated by code, use\n\t\t\t\t * of strcmp is safe here.\n\t\t\t\t */\n\t\t\t\tif (strcmp(defaultfilename, cstoreFdwOptions->filename) == 0)\n\t\t\t\t{\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tdroppedCStoreFileList = lappend(droppedCStoreFileList,\n\t\t\t\t\t\t\t\t\t\t\t\tcstoreFdwOptions->filename);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn droppedCStoreFileList;\n}\n\n\n/* FindCStoreTables returns list of CStore tables from given table list */\nstatic List *\nFindCStoreTables(List *tableList)\n{\n\tList *cstoreTableList = NIL;\n\tListCell *relationCell = NULL;\n\tforeach(relationCell, tableList)\n\t{\n\t\tRangeVar *rangeVar = (RangeVar *) lfirst(relationCell);\n\t\tOid relationId = RangeVarGetRelid(rangeVar, AccessShareLock, true);\n\t\tif (CStoreTable(relationId) && !DistributedTable(relationId))\n\t\t{\n\t\t\tcstoreTableList = lappend(cstoreTableList, rangeVar);\n\t\t}\n\t}\n\n\treturn cstoreTableList;\n}\n\n\n/*\n * OpenRelationsForTruncate opens and locks relations for tables to be truncated.\n *\n * It also performs a permission checks to see if the user has truncate privilege\n * on tables.\n */\nstatic List *\nOpenRelationsForTruncate(List *cstoreTableList)\n{\n\tListCell *relationCell = NULL;\n\tList *relationIdList = NIL;\n\tList *relationList = NIL;\n\tforeach(relationCell, cstoreTableList)\n\t{\n\t\tRangeVar *rangeVar = (RangeVar *) lfirst(relationCell);\n\t\tRelation relation = relation_openrv(rangeVar, AccessExclusiveLock);\n\t\tOid relationId = relation->rd_id;\n\t\tAclResult aclresult = pg_class_aclcheck(relationId, GetUserId(),\n\t\t\t\t\t\t\t\t\t\t\t   ACL_TRUNCATE);\n\t\tif (aclresult != ACLCHECK_OK)\n\t\t{\n\t\t\taclcheck_error(aclresult, ACLCHECK_OBJECT_TABLE, get_rel_name(relationId));\n\t\t}\n\n\t\t/* check if this relation is repeated */\n\t\tif (list_member_oid(relationIdList, relationId))\n\t\t{\n\t\t\trelation_close(relation, AccessExclusiveLock);\n\t\t}\n\t\telse\n\t\t{\n\t\t\trelationIdList = lappend_oid(relationIdList, relationId);\n\t\t\trelationList = lappend(relationList, relation);\n\t\t}\n\t}\n\n\treturn relationList;\n}\n\n\n/* TruncateCStoreTable truncates given cstore tables */\nstatic void\nTruncateCStoreTables(List *cstoreRelationList)\n{\n\tListCell *relationCell = NULL;\n\tforeach(relationCell, cstoreRelationList)\n\t{\n\t\tRelation relation = (Relation) lfirst(relationCell);\n\t\tOid relationId = relation->rd_id;\n\t\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\n\t\tAssert(CStoreTable(relationId));\n\n\t\tcstoreFdwOptions = CStoreGetOptions(relationId);\n\t\tDeleteCStoreTableFiles(cstoreFdwOptions->filename);\n\t\tInitializeCStoreTableFile(relationId, relation);\n\t}\n}\n\n\n/*\n * DeleteCStoreTableFiles deletes the data and footer files for a cstore table\n * whose data filename is given.\n */\nstatic void\nDeleteCStoreTableFiles(char *filename)\n{\n\tint dataFileRemoved = 0;\n\tint footerFileRemoved = 0;\n\n\tStringInfo tableFooterFilename = makeStringInfo();\n\tappendStringInfo(tableFooterFilename, \"%s%s\", filename, CSTORE_FOOTER_FILE_SUFFIX);\n\n\t/* delete the footer file */\n\tfooterFileRemoved = unlink(tableFooterFilename->data);\n\tif (footerFileRemoved != 0)\n\t{\n\t\tereport(WARNING, (errcode_for_file_access(),\n\t\t\t\t\t\t  errmsg(\"could not delete file \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t\t tableFooterFilename->data)));\n\t}\n\n\t/* delete the data file */\n\tdataFileRemoved = unlink(filename);\n\tif (dataFileRemoved != 0)\n\t{\n\t\tereport(WARNING, (errcode_for_file_access(),\n\t\t\t\t\t\t  errmsg(\"could not delete file \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t\t filename)));\n\t}\n}\n\n\n/*\n * InitializeCStoreTableFile creates data and footer file for a cstore table.\n * The function assumes data and footer files do not exist, therefore\n * it should be called on empty or non-existing table. Notice that the caller\n * is expected to acquire AccessExclusiveLock on the relation.\n */\nstatic void InitializeCStoreTableFile(Oid relationId, Relation relation)\n{\n\tTableWriteState *writeState = NULL;\n\tTupleDesc tupleDescriptor = RelationGetDescr(relation);\n\tCStoreFdwOptions* cstoreFdwOptions = CStoreGetOptions(relationId);\n\n\t/*\n\t * Initialize state to write to the cstore file. This creates an\n\t * empty data file and a valid footer file for the table.\n\t */\n\twriteState = CStoreBeginWrite(cstoreFdwOptions->filename,\n\t\t\tcstoreFdwOptions->compressionType, cstoreFdwOptions->stripeRowCount,\n\t\t\tcstoreFdwOptions->blockRowCount, tupleDescriptor);\n\tCStoreEndWrite(writeState);\n}\n\n\n\n/*\n * CStoreTable checks if the given table name belongs to a foreign columnar store\n * table. If it does, the function returns true. Otherwise, it returns false.\n */\nstatic bool\nCStoreTable(Oid relationId)\n{\n\tbool cstoreTable = false;\n\tchar relationKind = 0;\n\n\tif (relationId == InvalidOid)\n\t{\n\t\treturn false;\n\t}\n\n\trelationKind = get_rel_relkind(relationId);\n\tif (relationKind == RELKIND_FOREIGN_TABLE)\n\t{\n\t\tForeignTable *foreignTable = GetForeignTable(relationId);\n\t\tForeignServer *server = GetForeignServer(foreignTable->serverid);\n\t\tif (CStoreServer(server))\n\t\t{\n\t\t\tcstoreTable = true;\n\t\t}\n\t}\n\n\treturn cstoreTable;\n}\n\n\n/*\n * CStoreServer checks if the given foreign server belongs to cstore_fdw. If it\n * does, the function returns true. Otherwise, it returns false.\n */\nstatic bool\nCStoreServer(ForeignServer *server)\n{\n\tForeignDataWrapper *foreignDataWrapper = GetForeignDataWrapper(server->fdwid);\n\tbool cstoreServer = false;\n\n\tchar *foreignWrapperName = foreignDataWrapper->fdwname;\n\tif (strncmp(foreignWrapperName, CSTORE_FDW_NAME, NAMEDATALEN) == 0)\n\t{\n\t\tcstoreServer = true;\n\t}\n\n\treturn cstoreServer;\n}\n\n\n/*\n * DistributedTable checks if the given relationId is the OID of a distributed table,\n * which may also be a cstore_fdw table, but in that case COPY should be handled by\n * Citus.\n */\nstatic bool\nDistributedTable(Oid relationId)\n{\n\tbool distributedTable = false;\n\tOid partitionOid = InvalidOid;\n\tRelation heapRelation = NULL;\n\tTableScanDesc scanDesc = NULL;\n\tconst int scanKeyCount = 1;\n\tScanKeyData scanKey[1];\n\tHeapTuple heapTuple = NULL;\n\n\tbool missingOK = true;\n\tOid extensionOid = get_extension_oid(CITUS_EXTENSION_NAME, missingOK);\n\tif (extensionOid == InvalidOid)\n\t{\n\t\t/* if the citus extension isn't created, no tables are distributed */\n\t\treturn false;\n\t}\n\n\tpartitionOid = get_relname_relid(CITUS_PARTITION_TABLE_NAME, PG_CATALOG_NAMESPACE);\n\tif (partitionOid == InvalidOid)\n\t{\n\t\t/* the pg_dist_partition table does not exist */\n\t\treturn false;\n\t}\n\n\theapRelation = relation_open(partitionOid, AccessShareLock);\n\n\tScanKeyInit(&scanKey[0], ATTR_NUM_PARTITION_RELATION_ID, InvalidStrategy,\n\t\t\t\tF_OIDEQ, ObjectIdGetDatum(relationId));\n\n\tscanDesc = table_beginscan(heapRelation, SnapshotSelf, scanKeyCount, scanKey);\n\n\theapTuple = heap_getnext(scanDesc, ForwardScanDirection);\n\n\tdistributedTable = HeapTupleIsValid(heapTuple);\n\n\ttable_endscan(scanDesc);\n\trelation_close(heapRelation, AccessShareLock);\n\n\treturn distributedTable;\n}\n\n\n/*\n * DistributedWorkerCopy returns whether the Citus-specific master_host option is\n * present in the COPY options.\n */\nstatic bool\nDistributedWorkerCopy(CopyStmt *copyStatement)\n{\n    ListCell *optionCell = NULL;\n    foreach(optionCell, copyStatement->options)\n    {\n        DefElem *defel = (DefElem *) lfirst(optionCell);\n        if (strncmp(defel->defname, \"master_host\", NAMEDATALEN) == 0)\n        {\n            return true;\n        }\n    }\n\n    return false;\n}\n\n\n/*\n * CreateCStoreDatabaseDirectory creates the directory (and parent directories,\n * if needed) used to store automatically managed cstore_fdw files. The path to\n * the directory is $PGDATA/cstore_fdw/{databaseOid}.\n */\nstatic void\nCreateCStoreDatabaseDirectory(Oid databaseOid)\n{\n\tbool cstoreDirectoryExists = false;\n\tbool databaseDirectoryExists = false;\n\tStringInfo cstoreDatabaseDirectoryPath = NULL;\n\n\tStringInfo cstoreDirectoryPath = makeStringInfo();\n\tappendStringInfo(cstoreDirectoryPath, \"%s/%s\", DataDir, CSTORE_FDW_NAME);\n\n\tcstoreDirectoryExists = DirectoryExists(cstoreDirectoryPath);\n\tif (!cstoreDirectoryExists)\n\t{\n\t\tCreateDirectory(cstoreDirectoryPath);\n\t}\n\n\tcstoreDatabaseDirectoryPath = makeStringInfo();\n\tappendStringInfo(cstoreDatabaseDirectoryPath, \"%s/%s/%u\", DataDir,\n\t\t\t\t\t CSTORE_FDW_NAME, databaseOid);\n\n\tdatabaseDirectoryExists = DirectoryExists(cstoreDatabaseDirectoryPath);\n\tif (!databaseDirectoryExists)\n\t{\n\t\tCreateDirectory(cstoreDatabaseDirectoryPath);\n\t}\n}\n\n\n/* DirectoryExists checks if a directory exists for the given directory name. */\nstatic bool\nDirectoryExists(StringInfo directoryName)\n{\n\tbool directoryExists = true;\n\tstruct stat directoryStat;\n\n\tint statOK = stat(directoryName->data, &directoryStat);\n\tif (statOK == 0)\n\t{\n\t\t/* file already exists; check that it is a directory */\n\t\tif (!S_ISDIR(directoryStat.st_mode))\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"\\\"%s\\\" is not a directory\", directoryName->data),\n\t\t\t\t\t\t\terrhint(\"You need to remove or rename the file \\\"%s\\\".\",\n\t\t\t\t\t\t\t\t\tdirectoryName->data)));\n\t\t}\n\t}\n\telse\n\t{\n\t\tif (errno == ENOENT)\n\t\t{\n\t\t\tdirectoryExists = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\t\terrmsg(\"could not stat directory \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t\t   directoryName->data)));\n\t\t}\n\t}\n\n\treturn directoryExists;\n}\n\n\n/* CreateDirectory creates a new directory with the given directory name. */\nstatic void\nCreateDirectory(StringInfo directoryName)\n{\n\tint makeOK = mkdir(directoryName->data, S_IRWXU);\n\tif (makeOK != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not create directory \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t   directoryName->data)));\n\t}\n}\n\n\n/*\n * RemoveCStoreDatabaseDirectory removes CStore directory previously\n * created for this database.\n * However it does not remove 'cstore_fdw' directory even if there\n * are no other databases left.\n */\nstatic void\nRemoveCStoreDatabaseDirectory(Oid databaseOid)\n{\n\tStringInfo cstoreDirectoryPath = makeStringInfo();\n\tStringInfo cstoreDatabaseDirectoryPath = makeStringInfo();\n\n\tappendStringInfo(cstoreDirectoryPath, \"%s/%s\", DataDir, CSTORE_FDW_NAME);\n\n\tappendStringInfo(cstoreDatabaseDirectoryPath, \"%s/%s/%u\", DataDir,\n\t\t\t\t\t CSTORE_FDW_NAME, databaseOid);\n\n\tif (DirectoryExists(cstoreDatabaseDirectoryPath))\n\t{\n\t\trmtree(cstoreDatabaseDirectoryPath->data, true);\n\t}\n}\n\n\n/*\n * cstore_table_size returns the total on-disk size of a cstore table in bytes.\n * The result includes the sizes of data file and footer file.\n */\nDatum\ncstore_table_size(PG_FUNCTION_ARGS)\n{\n\tOid relationId = PG_GETARG_OID(0);\n\n\tint64 tableSize = 0;\n\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\tchar *dataFilename = NULL;\n\tStringInfo footerFilename = NULL;\n\tint dataFileStatResult = 0;\n\tint footerFileStatResult = 0;\n\tstruct stat dataFileStatBuffer;\n\tstruct stat footerFileStatBuffer;\n\n\tbool cstoreTable = CStoreTable(relationId);\n\tif (!cstoreTable)\n\t{\n\t\tereport(ERROR, (errmsg(\"relation is not a cstore table\")));\n\t}\n\n\tcstoreFdwOptions = CStoreGetOptions(relationId);\n\tdataFilename = cstoreFdwOptions->filename;\n\n\tdataFileStatResult = stat(dataFilename, &dataFileStatBuffer);\n\tif (dataFileStatResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not stat file \\\"%s\\\": %m\", dataFilename)));\n\t}\n\n\tfooterFilename = makeStringInfo();\n\tappendStringInfo(footerFilename, \"%s%s\", dataFilename,\n\t\t\t\t\t CSTORE_FOOTER_FILE_SUFFIX);\n\n\tfooterFileStatResult = stat(footerFilename->data, &footerFileStatBuffer);\n\tif (footerFileStatResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not stat file \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t\tfooterFilename->data)));\n\t}\n\n\ttableSize += dataFileStatBuffer.st_size;\n\ttableSize += footerFileStatBuffer.st_size;\n\n\tPG_RETURN_INT64(tableSize);\n}\n\n\n/*\n * cstore_fdw_handler creates and returns a struct with pointers to foreign\n * table callback functions.\n */\nDatum\ncstore_fdw_handler(PG_FUNCTION_ARGS)\n{\n\tFdwRoutine *fdwRoutine = makeNode(FdwRoutine);\n\n\tfdwRoutine->GetForeignRelSize = CStoreGetForeignRelSize;\n\tfdwRoutine->GetForeignPaths = CStoreGetForeignPaths;\n\tfdwRoutine->GetForeignPlan = CStoreGetForeignPlan;\n\tfdwRoutine->ExplainForeignScan = CStoreExplainForeignScan;\n\tfdwRoutine->BeginForeignScan = CStoreBeginForeignScan;\n\tfdwRoutine->IterateForeignScan = CStoreIterateForeignScan;\n\tfdwRoutine->ReScanForeignScan = CStoreReScanForeignScan;\n\tfdwRoutine->EndForeignScan = CStoreEndForeignScan;\n\tfdwRoutine->AnalyzeForeignTable = CStoreAnalyzeForeignTable;\n\tfdwRoutine->PlanForeignModify = CStorePlanForeignModify;\n\tfdwRoutine->BeginForeignModify = CStoreBeginForeignModify;\n\tfdwRoutine->ExecForeignInsert = CStoreExecForeignInsert;\n\tfdwRoutine->EndForeignModify = CStoreEndForeignModify;\n\n#if PG_VERSION_NUM >= 110000\n\tfdwRoutine->BeginForeignInsert = CStoreBeginForeignInsert;\n\tfdwRoutine->EndForeignInsert = CStoreEndForeignInsert;\n#endif\n\n#if PG_VERSION_NUM >= 90600\n\tfdwRoutine->IsForeignScanParallelSafe = CStoreIsForeignScanParallelSafe;\n#endif\n\n\tPG_RETURN_POINTER(fdwRoutine);\n}\n\n\n/*\n * cstore_fdw_validator validates options given to one of the following commands:\n * foreign data wrapper, server, user mapping, or foreign table. This function\n * errors out if the given option name or its value is considered invalid.\n */\nDatum\ncstore_fdw_validator(PG_FUNCTION_ARGS)\n{\n\tDatum optionArray = PG_GETARG_DATUM(0);\n\tOid optionContextId = PG_GETARG_OID(1);\n\tList *optionList = untransformRelOptions(optionArray);\n\tListCell *optionCell = NULL;\n\tchar *filename = NULL;\n\tchar *compressionTypeString = NULL;\n\tchar *stripeRowCountString = NULL;\n\tchar *blockRowCountString = NULL;\n\n\tforeach(optionCell, optionList)\n\t{\n\t\tDefElem *optionDef = (DefElem *) lfirst(optionCell);\n\t\tchar *optionName = optionDef->defname;\n\t\tbool optionValid = false;\n\n\t\tint32 optionIndex = 0;\n\t\tfor (optionIndex = 0; optionIndex < ValidOptionCount; optionIndex++)\n\t\t{\n\t\t\tconst CStoreValidOption *validOption = &(ValidOptionArray[optionIndex]);\n\n\t\t\tif ((optionContextId == validOption->optionContextId) &&\n\t\t\t\t(strncmp(optionName, validOption->optionName, NAMEDATALEN) == 0))\n\t\t\t{\n\t\t\t\toptionValid = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* if invalid option, display an informative error message */\n\t\tif (!optionValid)\n\t\t{\n\t\t\tStringInfo optionNamesString = OptionNamesString(optionContextId);\n\n\t\t\tereport(ERROR, (errcode(ERRCODE_FDW_INVALID_OPTION_NAME),\n\t\t\t\t\t\t\terrmsg(\"invalid option \\\"%s\\\"\", optionName),\n\t\t\t\t\t\t\terrhint(\"Valid options in this context are: %s\",\n\t\t\t\t\t\t\t\t\toptionNamesString->data)));\n\t\t}\n\n\t\tif (strncmp(optionName, OPTION_NAME_FILENAME, NAMEDATALEN) == 0)\n\t\t{\n\t\t\tfilename = defGetString(optionDef);\n\t\t}\n\t\telse if (strncmp(optionName, OPTION_NAME_COMPRESSION_TYPE, NAMEDATALEN) == 0)\n\t\t{\n\t\t\tcompressionTypeString = defGetString(optionDef);\n\t\t}\n\t\telse if (strncmp(optionName, OPTION_NAME_STRIPE_ROW_COUNT, NAMEDATALEN) == 0)\n\t\t{\n\t\t\tstripeRowCountString = defGetString(optionDef);\n\t\t}\n\t\telse if (strncmp(optionName, OPTION_NAME_BLOCK_ROW_COUNT, NAMEDATALEN) == 0)\n\t\t{\n\t\t\tblockRowCountString = defGetString(optionDef);\n\t\t}\n\t}\n\n\tif (optionContextId == ForeignTableRelationId)\n\t{\n\t\tValidateForeignTableOptions(filename, compressionTypeString,\n\t\t\t\t\t\t\t\t\tstripeRowCountString, blockRowCountString);\n\t}\n\n\tPG_RETURN_VOID();\n}\n\n\n/*\n * cstore_clean_table_resources cleans up table data and metadata with provided\n * relation id. The function is meant to be called from drop_event_trigger. It\n * has no way of knowing if the provided relation id belongs to a cstore table.\n * Therefore it first checks if data file exists at default location before\n * attempting to remove data and footer files. If the table is created at a\n * custom path than its resources would not be removed.\n */\nDatum\ncstore_clean_table_resources(PG_FUNCTION_ARGS)\n{\n\tOid relationId = PG_GETARG_OID(0);\n\tStringInfo filePath = makeStringInfo();\n\tstruct stat fileStat;\n\tint statResult = -1;\n\n\tappendStringInfo(filePath, \"%s/%s/%d/%d\", DataDir, CSTORE_FDW_NAME,\n\t\t\t\t\t (int) MyDatabaseId, (int) relationId);\n\n\t/*\n\t * Check to see if the file exist first. This is the only way to\n\t * find out if the table being dropped is a cstore table.\n\t */\n\tstatResult = stat(filePath->data, &fileStat);\n\tif (statResult == 0)\n\t{\n\t\tDeleteCStoreTableFiles(filePath->data);\n\t}\n\n\tPG_RETURN_VOID();\n}\n\n\n/*\n * OptionNamesString finds all options that are valid for the current context,\n * and concatenates these option names in a comma separated string. The function\n * is unchanged from mongo_fdw.\n */\nstatic StringInfo\nOptionNamesString(Oid currentContextId)\n{\n\tStringInfo optionNamesString = makeStringInfo();\n\tbool firstOptionAppended = false;\n\n\tint32 optionIndex = 0;\n\tfor (optionIndex = 0; optionIndex < ValidOptionCount; optionIndex++)\n\t{\n\t\tconst CStoreValidOption *validOption = &(ValidOptionArray[optionIndex]);\n\n\t\t/* if option belongs to current context, append option name */\n\t\tif (currentContextId == validOption->optionContextId)\n\t\t{\n\t\t\tif (firstOptionAppended)\n\t\t\t{\n\t\t\t\tappendStringInfoString(optionNamesString, \", \");\n\t\t\t}\n\n\t\t\tappendStringInfoString(optionNamesString, validOption->optionName);\n\t\t\tfirstOptionAppended = true;\n\t\t}\n\t}\n\n\treturn optionNamesString;\n}\n\n\n/*\n * GetSlotHeapTuple abstracts getting HeapTuple from TupleTableSlot between versions\n */\nstatic HeapTuple\nGetSlotHeapTuple(TupleTableSlot *tts)\n{\n#if PG_VERSION_NUM >= 120000\n\treturn tts->tts_ops->copy_heap_tuple(tts);\n#else\n\treturn tts->tts_tuple;\n#endif\n}\n\n\n/*\n * CStoreGetOptions returns the option values to be used when reading and writing\n * the cstore file. To resolve these values, the function checks options for the\n * foreign table, and if not present, falls back to default values. This function\n * errors out if given option values are considered invalid.\n */\nstatic CStoreFdwOptions *\nCStoreGetOptions(Oid foreignTableId)\n{\n\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\tchar *filename = NULL;\n\tCompressionType compressionType = DEFAULT_COMPRESSION_TYPE;\n\tint32 stripeRowCount = DEFAULT_STRIPE_ROW_COUNT;\n\tint32 blockRowCount = DEFAULT_BLOCK_ROW_COUNT;\n\tchar *compressionTypeString = NULL;\n\tchar *stripeRowCountString = NULL;\n\tchar *blockRowCountString = NULL;\n\n\tfilename = CStoreGetOptionValue(foreignTableId, OPTION_NAME_FILENAME);\n\tcompressionTypeString = CStoreGetOptionValue(foreignTableId,\n\t\t\t\t\t\t\t\t\t\t\t\t OPTION_NAME_COMPRESSION_TYPE);\n\tstripeRowCountString = CStoreGetOptionValue(foreignTableId,\n\t\t\t\t\t\t\t\t\t\t\t\tOPTION_NAME_STRIPE_ROW_COUNT);\n\tblockRowCountString = CStoreGetOptionValue(foreignTableId,\n\t\t\t\t\t\t\t\t\t\t\t   OPTION_NAME_BLOCK_ROW_COUNT);\n\n\tValidateForeignTableOptions(filename, compressionTypeString,\n\t\t\t\t\t\t\t\tstripeRowCountString, blockRowCountString);\n\n\t/* parse provided options */\n\tif (compressionTypeString != NULL)\n\t{\n\t\tcompressionType = ParseCompressionType(compressionTypeString);\n\t}\n\tif (stripeRowCountString != NULL)\n\t{\n\t\tstripeRowCount = pg_atoi(stripeRowCountString, sizeof(int32), 0);\n\t}\n\tif (blockRowCountString != NULL)\n\t{\n\t\tblockRowCount = pg_atoi(blockRowCountString, sizeof(int32), 0);\n\t}\n\n\t/* set default filename if it is not provided */\n\tif (filename == NULL)\n\t{\n\t\tfilename = CStoreDefaultFilePath(foreignTableId);\n\t}\n\n\tcstoreFdwOptions = palloc0(sizeof(CStoreFdwOptions));\n\tcstoreFdwOptions->filename = filename;\n\tcstoreFdwOptions->compressionType = compressionType;\n\tcstoreFdwOptions->stripeRowCount = stripeRowCount;\n\tcstoreFdwOptions->blockRowCount = blockRowCount;\n\n\treturn cstoreFdwOptions;\n}\n\n\n/*\n * CStoreGetOptionValue walks over foreign table and foreign server options, and\n * looks for the option with the given name. If found, the function returns the\n * option's value. This function is unchanged from mongo_fdw.\n */\nstatic char *\nCStoreGetOptionValue(Oid foreignTableId, const char *optionName)\n{\n\tForeignTable *foreignTable = NULL;\n\tForeignServer *foreignServer = NULL;\n\tList *optionList = NIL;\n\tListCell *optionCell = NULL;\n\tchar *optionValue = NULL;\n\n\tforeignTable = GetForeignTable(foreignTableId);\n\tforeignServer = GetForeignServer(foreignTable->serverid);\n\n\toptionList = list_concat(optionList, foreignTable->options);\n\toptionList = list_concat(optionList, foreignServer->options);\n\n\tforeach(optionCell, optionList)\n\t{\n\t\tDefElem *optionDef = (DefElem *) lfirst(optionCell);\n\t\tchar *optionDefName = optionDef->defname;\n\n\t\tif (strncmp(optionDefName, optionName, NAMEDATALEN) == 0)\n\t\t{\n\t\t\toptionValue = defGetString(optionDef);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn optionValue;\n}\n\n\n/*\n * ValidateForeignTableOptions verifies if given options are valid cstore_fdw\n * foreign table options. This function errors out if given option value is\n * considered invalid.\n */\nstatic void\nValidateForeignTableOptions(char *filename, char *compressionTypeString,\n\t\t\t\t\t\t\tchar *stripeRowCountString, char *blockRowCountString)\n{\n\t/* we currently do not have any checks for filename */\n\t(void) filename;\n\n\t/* check if the provided compression type is valid */\n\tif (compressionTypeString != NULL)\n\t{\n\t\tCompressionType compressionType = ParseCompressionType(compressionTypeString);\n\t\tif (compressionType == COMPRESSION_TYPE_INVALID)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"invalid compression type\"),\n\t\t\t\t\t\t\terrhint(\"Valid options are: %s\",\n\t\t\t\t\t\t\t\t\tCOMPRESSION_STRING_DELIMITED_LIST)));\n\t\t}\n\t}\n\n\t/* check if the provided stripe row count has correct format and range */\n\tif (stripeRowCountString != NULL)\n\t{\n\t\t/* pg_atoi() errors out if the given string is not a valid 32-bit integer */\n\t\tint32 stripeRowCount = pg_atoi(stripeRowCountString, sizeof(int32), 0);\n\t\tif (stripeRowCount < STRIPE_ROW_COUNT_MINIMUM ||\n\t\t\tstripeRowCount > STRIPE_ROW_COUNT_MAXIMUM)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"invalid stripe row count\"),\n\t\t\t\t\t\t\terrhint(\"Stripe row count must be an integer between \"\n\t\t\t\t\t\t\t\t\t\"%d and %d\", STRIPE_ROW_COUNT_MINIMUM,\n\t\t\t\t\t\t\t\t\tSTRIPE_ROW_COUNT_MAXIMUM)));\n\t\t}\n\t}\n\n\t/* check if the provided block row count has correct format and range */\n\tif (blockRowCountString != NULL)\n\t{\n\t\t/* pg_atoi() errors out if the given string is not a valid 32-bit integer */\n\t\tint32 blockRowCount = pg_atoi(blockRowCountString, sizeof(int32), 0);\n\t\tif (blockRowCount < BLOCK_ROW_COUNT_MINIMUM ||\n\t\t\tblockRowCount > BLOCK_ROW_COUNT_MAXIMUM)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"invalid block row count\"),\n\t\t\t\t\t\t\terrhint(\"Block row count must be an integer between \"\n\t\t\t\t\t\t\t\t\t\"%d and %d\", BLOCK_ROW_COUNT_MINIMUM,\n\t\t\t\t\t\t\t\t\tBLOCK_ROW_COUNT_MAXIMUM)));\n\t\t}\n\t}\n}\n\n\n/*\n * CStoreDefaultFilePath constructs the default file path to use for a cstore_fdw\n * table. The path is of the form $PGDATA/cstore_fdw/{databaseOid}/{relfilenode}.\n */\nstatic char *\nCStoreDefaultFilePath(Oid foreignTableId)\n{\n\tRelation relation = relation_open(foreignTableId, AccessShareLock);\n\tRelFileNode relationFileNode = relation->rd_node;\n\tOid databaseOid = relationFileNode.dbNode;\n\tOid relationFileOid = relationFileNode.relNode;\n\tStringInfo cstoreFilePath = makeStringInfo();\n\n\trelation_close(relation, AccessShareLock);\n\n\t/* PG12 onward does not create relfilenode for foreign tables */\n\tif (databaseOid == InvalidOid)\n\t{\n\t\tdatabaseOid = MyDatabaseId;\n\t\trelationFileOid = foreignTableId;\n\n\t}\n\n\tappendStringInfo(cstoreFilePath, \"%s/%s/%u/%u\", DataDir, CSTORE_FDW_NAME,\n\t\t\t\t\t databaseOid, relationFileOid);\n\n\treturn cstoreFilePath->data;\n}\n\n\n/* ParseCompressionType converts a string to a compression type. */\nstatic CompressionType\nParseCompressionType(const char *compressionTypeString)\n{\n\tCompressionType compressionType = COMPRESSION_TYPE_INVALID;\n\tAssert(compressionTypeString != NULL);\n\n\tif (strncmp(compressionTypeString, COMPRESSION_STRING_NONE, NAMEDATALEN) == 0)\n\t{\n\t\tcompressionType = COMPRESSION_NONE;\n\t}\n\telse if (strncmp(compressionTypeString, COMPRESSION_STRING_PG_LZ, NAMEDATALEN) == 0)\n\t{\n\t\tcompressionType = COMPRESSION_PG_LZ;\n\t}\n\n\treturn compressionType;\n}\n\n\n/*\n * CStoreGetForeignRelSize obtains relation size estimates for a foreign table and\n * puts its estimate for row count into baserel->rows.\n */\nstatic void\nCStoreGetForeignRelSize(PlannerInfo *root, RelOptInfo *baserel, Oid foreignTableId)\n{\n\tCStoreFdwOptions *cstoreFdwOptions = CStoreGetOptions(foreignTableId);\n\tdouble tupleCountEstimate = TupleCountEstimate(baserel, cstoreFdwOptions->filename);\n\tdouble rowSelectivity = clauselist_selectivity(root, baserel->baserestrictinfo,\n\t\t\t\t\t\t\t\t\t\t\t\t   0, JOIN_INNER, NULL);\n\n\tdouble outputRowCount = clamp_row_est(tupleCountEstimate * rowSelectivity);\n\tbaserel->rows = outputRowCount;\n}\n\n\n/*\n * CStoreGetForeignPaths creates possible access paths for a scan on the foreign\n * table. We currently have one possible access path. This path filters out row\n * blocks that are refuted by where clauses, and only returns values for the\n * projected columns.\n */\nstatic void\nCStoreGetForeignPaths(PlannerInfo *root, RelOptInfo *baserel, Oid foreignTableId)\n{\n\tPath *foreignScanPath = NULL;\n\tCStoreFdwOptions *cstoreFdwOptions = CStoreGetOptions(foreignTableId);\n\tRelation relation = relation_open(foreignTableId, AccessShareLock);\n\n\t/*\n\t * We skip reading columns that are not in query. Here we assume that all\n\t * columns in relation have the same width, and estimate the number pages\n\t * that will be read by query.\n\t *\n\t * Ideally, we should also take into account the row blocks that will be\n\t * suppressed. But for that we need to know which columns are used for\n\t * sorting. If we wrongly assume that we are sorted by a specific column\n\t * and underestimate the page count, planner may choose nested loop join\n\t * in a place it shouldn't be used. Choosing merge join or hash join is\n\t * usually safer than nested loop join, so we take the more conservative\n\t * approach and assume all rows in the columnar store file will be read.\n\t * We intend to fix this in later version by improving the row sampling\n\t * algorithm and using the correlation statistics to detect which columns\n\t * are in stored in sorted order.\n\t */\n\tList *queryColumnList = ColumnList(baserel, foreignTableId);\n\tuint32 queryColumnCount = list_length(queryColumnList);\n\tBlockNumber relationPageCount = PageCount(cstoreFdwOptions->filename);\n\tuint32 relationColumnCount = RelationGetNumberOfAttributes(relation);\n\n\tdouble queryColumnRatio = (double) queryColumnCount / relationColumnCount;\n\tdouble queryPageCount = relationPageCount * queryColumnRatio;\n\tdouble totalDiskAccessCost = seq_page_cost * queryPageCount;\n\n\tdouble tupleCountEstimate = TupleCountEstimate(baserel, cstoreFdwOptions->filename);\n\n\t/*\n\t * We estimate costs almost the same way as cost_seqscan(), thus assuming\n\t * that I/O costs are equivalent to a regular table file of the same size.\n\t */\n\tdouble filterCostPerTuple = baserel->baserestrictcost.per_tuple;\n\tdouble cpuCostPerTuple = cpu_tuple_cost + filterCostPerTuple;\n\tdouble totalCpuCost = cpuCostPerTuple * tupleCountEstimate;\n\n\tdouble startupCost = baserel->baserestrictcost.startup;\n\tdouble totalCost  = startupCost + totalCpuCost + totalDiskAccessCost;\n\n\t/* create a foreign path node and add it as the only possible path */\n#if PG_VERSION_NUM >= 90600\n\tforeignScanPath = (Path *) create_foreignscan_path(root, baserel,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* path target */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   baserel->rows,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   startupCost, totalCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL,  /* no known ordering */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* not parameterized */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* no outer path */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL); /* no fdw_private */\n\n#elif PG_VERSION_NUM >= 90500\n\tforeignScanPath = (Path *) create_foreignscan_path(root, baserel, baserel->rows,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   startupCost, totalCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL,  /* no known ordering */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* not parameterized */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* no outer path */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL); /* no fdw_private */\n#else\n\tforeignScanPath = (Path *) create_foreignscan_path(root, baserel, baserel->rows,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   startupCost, totalCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL,  /* no known ordering */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NULL, /* not parameterized */\n\t\t\t\t\t\t\t\t\t\t\t\t\t   NIL); /* no fdw_private */\n#endif\n\n\tadd_path(baserel, foreignScanPath);\n\trelation_close(relation, AccessShareLock);\n}\n\n\n/*\n * CStoreGetForeignPlan creates a ForeignScan plan node for scanning the foreign\n * table. We also add the query column list to scan nodes private list, because\n * we need it later for skipping over unused columns in the query.\n */\n#if PG_VERSION_NUM >= 90500\nstatic ForeignScan *\nCStoreGetForeignPlan(PlannerInfo *root, RelOptInfo *baserel, Oid foreignTableId,\n\t\t\t\t\t ForeignPath *bestPath, List *targetList, List *scanClauses,\n\t\t\t\t\t Plan *outerPlan)\n#else\nstatic ForeignScan *\nCStoreGetForeignPlan(PlannerInfo *root, RelOptInfo *baserel, Oid foreignTableId,\n\t\t\t\t\t ForeignPath *bestPath, List *targetList, List *scanClauses)\n#endif\n{\n\tForeignScan *foreignScan = NULL;\n\tList *columnList = NIL;\n\tList *foreignPrivateList = NIL;\n\n\t/*\n\t * Although we skip row blocks that are refuted by the WHERE clause, but\n\t * we have no native ability to evaluate restriction clauses and make sure\n\t * that all non-related rows are filtered out. So we just put all of the\n\t * scanClauses into the plan node's qual list for the executor to check.\n\t */\n\tscanClauses = extract_actual_clauses(scanClauses,\n\t\t\t\t\t\t\t\t\t\t false); /* extract regular clauses */\n\n\t/*\n\t * As an optimization, we only read columns that are present in the query.\n\t * To find these columns, we need baserel. We don't have access to baserel\n\t * in executor's callback functions, so we get the column list here and put\n\t * it into foreign scan node's private list.\n\t */\n\tcolumnList = ColumnList(baserel, foreignTableId);\n\tforeignPrivateList = list_make1(columnList);\n\n\t/* create the foreign scan node */\n#if PG_VERSION_NUM >= 90500\n\tforeignScan = make_foreignscan(targetList, scanClauses, baserel->relid,\n\t\t\t\t\t\t\t\t   NIL, /* no expressions to evaluate */\n\t\t\t\t\t\t\t\t   foreignPrivateList,\n\t\t\t\t\t\t\t\t   NIL,\n\t\t\t\t\t\t\t\t   NIL,\n\t\t\t\t\t\t\t\t   NULL); /* no outer path */\n#else\n\tforeignScan = make_foreignscan(targetList, scanClauses, baserel->relid,\n\t\t\t\t\t\t\t\t   NIL, /* no expressions to evaluate */\n\t\t\t\t\t\t\t\t   foreignPrivateList);\n#endif\n\n\treturn foreignScan;\n}\n\n\n/*\n * TupleCountEstimate estimates the number of base relation tuples in the given\n * file.\n */\nstatic double\nTupleCountEstimate(RelOptInfo *baserel, const char *filename)\n{\n\tdouble tupleCountEstimate = 0.0;\n\n\t/* check if the user executed Analyze on this foreign table before */\n\tif (baserel->pages > 0)\n\t{\n\t\t/*\n\t\t * We have number of pages and number of tuples from pg_class (from a\n\t\t * previous ANALYZE), so compute a tuples-per-page estimate and scale\n\t\t * that by the current file size.\n\t\t */\n\t\tdouble tupleDensity = baserel->tuples / (double) baserel->pages;\n\t\tBlockNumber pageCount = PageCount(filename);\n\n\t\ttupleCountEstimate = clamp_row_est(tupleDensity * (double) pageCount);\n\t}\n\telse\n\t{\n\t\ttupleCountEstimate = (double) CStoreTableRowCount(filename);\n\t}\n\n\treturn tupleCountEstimate;\n}\n\n\n/* PageCount calculates and returns the number of pages in a file. */\nstatic BlockNumber\nPageCount(const char *filename)\n{\n\tBlockNumber pageCount = 0;\n\tstruct stat statBuffer;\n\n\t/* if file doesn't exist at plan time, use default estimate for its size */\n\tint statResult = stat(filename, &statBuffer);\n\tif (statResult < 0)\n\t{\n\t\tstatBuffer.st_size = 10 * BLCKSZ;\n\t}\n\n\tpageCount = (statBuffer.st_size + (BLCKSZ - 1)) / BLCKSZ;\n\tif (pageCount < 1)\n\t{\n\t\tpageCount = 1;\n\t}\n\n\treturn pageCount;\n}\n\n\n/*\n * ColumnList takes in the planner's information about this foreign table. The\n * function then finds all columns needed for query execution, including those\n * used in projections, joins, and filter clauses, de-duplicates these columns,\n * and returns them in a new list. This function is taken from mongo_fdw with\n * slight modifications.\n */\nstatic List *\nColumnList(RelOptInfo *baserel, Oid foreignTableId)\n{\n\tList *columnList = NIL;\n\tList *neededColumnList = NIL;\n\tAttrNumber columnIndex = 1;\n\tAttrNumber columnCount = baserel->max_attr;\n#if PG_VERSION_NUM >= 90600\n\tList *targetColumnList = baserel->reltarget->exprs;\n#else\n\tList *targetColumnList = baserel->reltargetlist;\n#endif\n\tListCell *targetColumnCell = NULL;\n\tList *restrictInfoList = baserel->baserestrictinfo;\n\tListCell *restrictInfoCell = NULL;\n\tconst AttrNumber wholeRow = 0;\n\tRelation relation = relation_open(foreignTableId, AccessShareLock);\n\tTupleDesc tupleDescriptor = RelationGetDescr(relation);\n\n\t/* first add the columns used in joins and projections */\n\tforeach(targetColumnCell, targetColumnList)\n\t{\n\t\tList *targetVarList = NIL;\n\t\tNode *targetExpr = (Node *) lfirst(targetColumnCell);\n\n#if PG_VERSION_NUM >= 90600\n\t\ttargetVarList = pull_var_clause(targetExpr,\n\t\t\t\t\t\t\t\t\t\tPVC_RECURSE_AGGREGATES |\n\t\t\t\t\t\t\t\t\t\tPVC_RECURSE_PLACEHOLDERS);\n#else\n\t\ttargetVarList = pull_var_clause(targetExpr,\n\t\t\t\t\t\t\t\t\t\tPVC_RECURSE_AGGREGATES,\n\t\t\t\t\t\t\t\t\t\tPVC_RECURSE_PLACEHOLDERS);\n#endif\n\n\t\tneededColumnList = list_union(neededColumnList, targetVarList);\n\t}\n\n\t/* then walk over all restriction clauses, and pull up any used columns */\n\tforeach(restrictInfoCell, restrictInfoList)\n\t{\n\t\tRestrictInfo *restrictInfo = (RestrictInfo *) lfirst(restrictInfoCell);\n\t\tNode *restrictClause = (Node *) restrictInfo->clause;\n\t\tList *clauseColumnList = NIL;\n\n\t\t/* recursively pull up any columns used in the restriction clause */\n#if PG_VERSION_NUM >= 90600\n\t\tclauseColumnList = pull_var_clause(restrictClause,\n\t\t\t\t\t\t\t\t\t\t   PVC_RECURSE_AGGREGATES |\n\t\t\t\t\t\t\t\t\t\t   PVC_RECURSE_PLACEHOLDERS);\n#else\n\t\tclauseColumnList = pull_var_clause(restrictClause,\n\t\t\t\t\t\t\t\t\t\t   PVC_RECURSE_AGGREGATES,\n\t\t\t\t\t\t\t\t\t\t   PVC_RECURSE_PLACEHOLDERS);\n#endif\n\n\t\tneededColumnList = list_union(neededColumnList, clauseColumnList);\n\t}\n\n\t/* walk over all column definitions, and de-duplicate column list */\n\tfor (columnIndex = 1; columnIndex <= columnCount; columnIndex++)\n\t{\n\t\tListCell *neededColumnCell = NULL;\n\t\tVar *column = NULL;\n\t\tForm_pg_attribute attributeForm =  TupleDescAttr(tupleDescriptor, columnIndex - 1);\n\n\t\tif (attributeForm->attisdropped)\n\t\t{\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* look for this column in the needed column list */\n\t\tforeach(neededColumnCell, neededColumnList)\n\t\t{\n\t\t\tVar *neededColumn = (Var *) lfirst(neededColumnCell);\n\t\t\tif (neededColumn->varattno == columnIndex)\n\t\t\t{\n\t\t\t\tcolumn = neededColumn;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (neededColumn->varattno == wholeRow)\n\t\t\t{\n\t\t\t\tIndex tableId = neededColumn->varno;\n\n\t\t\t\tcolumn = makeVar(tableId, columnIndex, attributeForm->atttypid,\n\t\t\t\t\t\t\t\t attributeForm->atttypmod, attributeForm->attcollation,\n\t\t\t\t\t\t\t\t 0);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (column != NULL)\n\t\t{\n\t\t\tcolumnList = lappend(columnList, column);\n\t\t}\n\t}\n\n\trelation_close(relation, AccessShareLock);\n\n\treturn columnList;\n}\n\n\n/* CStoreExplainForeignScan produces extra output for the Explain command. */\nstatic void\nCStoreExplainForeignScan(ForeignScanState *scanState, ExplainState *explainState)\n{\n\tOid foreignTableId = RelationGetRelid(scanState->ss.ss_currentRelation);\n\tCStoreFdwOptions *cstoreFdwOptions = CStoreGetOptions(foreignTableId);\n\n\tExplainPropertyText(\"CStore File\", cstoreFdwOptions->filename, explainState);\n\n\t/* supress file size if we're not showing cost details */\n\tif (explainState->costs)\n\t{\n\t\tstruct stat statBuffer;\n\n\t\tint statResult = stat(cstoreFdwOptions->filename, &statBuffer);\n\t\tif (statResult == 0)\n\t\t{\n\t\t\tExplainPropertyLong(\"CStore File Size\", (long) statBuffer.st_size,\n\t\t\t\t\t\t\t\texplainState);\n\t\t}\n\t}\n}\n\n\n/* CStoreBeginForeignScan starts reading the underlying cstore file. */\nstatic void\nCStoreBeginForeignScan(ForeignScanState *scanState, int executorFlags)\n{\n\tTableReadState *readState = NULL;\n\tOid foreignTableId = InvalidOid;\n\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\tRelation currentRelation = scanState->ss.ss_currentRelation;\n\tTupleDesc tupleDescriptor = RelationGetDescr(currentRelation);\n\tList *columnList = NIL;\n\tForeignScan *foreignScan = NULL;\n\tList *foreignPrivateList = NIL;\n\tList *whereClauseList = NIL;\n\n\t/* if Explain with no Analyze, do nothing */\n\tif (executorFlags & EXEC_FLAG_EXPLAIN_ONLY)\n\t{\n\t\treturn;\n\t}\n\n\tforeignTableId = RelationGetRelid(scanState->ss.ss_currentRelation);\n\tcstoreFdwOptions = CStoreGetOptions(foreignTableId);\n\n\tforeignScan = (ForeignScan *) scanState->ss.ps.plan;\n\tforeignPrivateList = (List *) foreignScan->fdw_private;\n\twhereClauseList = foreignScan->scan.plan.qual;\n\n\tcolumnList = (List *) linitial(foreignPrivateList);\n\treadState = CStoreBeginRead(cstoreFdwOptions->filename, tupleDescriptor,\n\t\t\t\t\t\t\t\tcolumnList, whereClauseList);\n\n\tscanState->fdw_state = (void *) readState;\n}\n\n\n/*\n * CStoreIterateForeignScan reads the next record from the cstore file, converts\n * it to a Postgres tuple, and stores the converted tuple into the ScanTupleSlot\n * as a virtual tuple.\n */\nstatic TupleTableSlot *\nCStoreIterateForeignScan(ForeignScanState *scanState)\n{\n\tTableReadState *readState = (TableReadState *) scanState->fdw_state;\n\tTupleTableSlot *tupleSlot = scanState->ss.ss_ScanTupleSlot;\n\tbool nextRowFound = false;\n\n\tTupleDesc tupleDescriptor = tupleSlot->tts_tupleDescriptor;\n\tDatum *columnValues = tupleSlot->tts_values;\n\tbool *columnNulls = tupleSlot->tts_isnull;\n\tuint32 columnCount = tupleDescriptor->natts;\n\n\t/* initialize all values for this row to null */\n\tmemset(columnValues, 0, columnCount * sizeof(Datum));\n\tmemset(columnNulls, true, columnCount * sizeof(bool));\n\n\tExecClearTuple(tupleSlot);\n\n\tnextRowFound = CStoreReadNextRow(readState, columnValues, columnNulls);\n\tif (nextRowFound)\n\t{\n\t\tExecStoreVirtualTuple(tupleSlot);\n\t}\n\n\treturn tupleSlot;\n}\n\n\n/* CStoreEndForeignScan finishes scanning the foreign table. */\nstatic void\nCStoreEndForeignScan(ForeignScanState *scanState)\n{\n\tTableReadState *readState = (TableReadState *) scanState->fdw_state;\n\tif (readState != NULL)\n\t{\n\t\tCStoreEndRead(readState);\n\t}\n}\n\n\n/* CStoreReScanForeignScan rescans the foreign table. */\nstatic void\nCStoreReScanForeignScan(ForeignScanState *scanState)\n{\n\tCStoreEndForeignScan(scanState);\n\tCStoreBeginForeignScan(scanState, 0);\n}\n\n\n/*\n * CStoreAnalyzeForeignTable sets the total page count and the function pointer\n * used to acquire a random sample of rows from the foreign file.\n */\nstatic bool\nCStoreAnalyzeForeignTable(Relation relation,\n\t\t\t\t\t\t  AcquireSampleRowsFunc *acquireSampleRowsFunc,\n\t\t\t\t\t\t  BlockNumber *totalPageCount)\n{\n\tOid foreignTableId = RelationGetRelid(relation);\n\tCStoreFdwOptions *cstoreFdwOptions = CStoreGetOptions(foreignTableId);\n\tstruct stat statBuffer;\n\n\tint statResult = stat(cstoreFdwOptions->filename, &statBuffer);\n\tif (statResult < 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not stat file \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t   cstoreFdwOptions->filename)));\n\t}\n\n\t(*totalPageCount) = PageCount(cstoreFdwOptions->filename);\n\t(*acquireSampleRowsFunc) = CStoreAcquireSampleRows;\n\n\treturn true;\n}\n\n\n/*\n * CStoreAcquireSampleRows acquires a random sample of rows from the foreign\n * table. Selected rows are returned in the caller allocated sampleRows array,\n * which must have at least target row count entries. The actual number of rows\n * selected is returned as the function result. We also count the number of rows\n * in the collection and return it in total row count. We also always set dead\n * row count to zero.\n *\n * Note that the returned list of rows does not always follow their actual order\n * in the cstore file. Therefore, correlation estimates derived later could be\n * inaccurate, but that's OK. We currently don't use correlation estimates (the\n * planner only pays attention to correlation for index scans).\n */\nstatic int\nCStoreAcquireSampleRows(Relation relation, int logLevel,\n\t\t\t\t\t\tHeapTuple *sampleRows, int targetRowCount,\n\t\t\t\t\t\tdouble *totalRowCount, double *totalDeadRowCount)\n{\n\tint sampleRowCount = 0;\n\tdouble rowCount = 0.0;\n\tdouble rowCountToSkip = -1;\t/* -1 means not set yet */\n\tdouble selectionState = 0;\n\tMemoryContext oldContext = CurrentMemoryContext;\n\tMemoryContext tupleContext = NULL;\n\tDatum *columnValues = NULL;\n\tbool *columnNulls = NULL;\n\tTupleTableSlot *scanTupleSlot = NULL;\n\tList *columnList = NIL;\n\tList *foreignPrivateList = NULL;\n\tForeignScanState *scanState = NULL;\n\tForeignScan *foreignScan = NULL;\n\tchar *relationName = NULL;\n\tint executorFlags = 0;\n\n\tTupleDesc tupleDescriptor = RelationGetDescr(relation);\n\tuint32 columnCount = tupleDescriptor->natts;\n\n\n\t/* create list of columns of the relation */\n\tuint32 columnIndex = 0;\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tForm_pg_attribute attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\t\tconst Index tableId = 1;\n\n\t\tif (!attributeForm->attisdropped)\n\t\t{\n\t\t\tVar *column = makeVar(tableId, columnIndex + 1, attributeForm->atttypid,\n\t\t\t\t\t\t\t\t  attributeForm->atttypmod, attributeForm->attcollation, 0);\n\t\t\tcolumnList = lappend(columnList, column);\n\t\t}\n\t}\n\n\t/* setup foreign scan plan node */\n\tforeignPrivateList = list_make1(columnList);\n\tforeignScan = makeNode(ForeignScan);\n\tforeignScan->fdw_private = foreignPrivateList;\n\n\t/* set up tuple slot */\n\tcolumnValues = palloc0(columnCount * sizeof(Datum));\n\tcolumnNulls = palloc0(columnCount * sizeof(bool));\n#if PG_VERSION_NUM >= 120000\n\tscanTupleSlot = MakeTupleTableSlot(NULL, &TTSOpsVirtual);\n#elif PG_VERSION_NUM >= 110000\n\tscanTupleSlot = MakeTupleTableSlot(NULL);\n#else\n\tscanTupleSlot = MakeTupleTableSlot();\n#endif\n\tscanTupleSlot->tts_tupleDescriptor = tupleDescriptor;\n\tscanTupleSlot->tts_values = columnValues;\n\tscanTupleSlot->tts_isnull = columnNulls;\n\n\t/* setup scan state */\n\tscanState = makeNode(ForeignScanState);\n\tscanState->ss.ss_currentRelation = relation;\n\tscanState->ss.ps.plan = (Plan *) foreignScan;\n\tscanState->ss.ss_ScanTupleSlot = scanTupleSlot;\n\n\t/*\n\t * Use per-tuple memory context to prevent leak of memory used to read and\n\t * parse rows from the file.\n\t */\n\ttupleContext = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t \"cstore_fdw temporary context\",\n\t\t\t\t\t\t\t\t\t\t ALLOCSET_DEFAULT_SIZES);\n\n\tCStoreBeginForeignScan(scanState, executorFlags);\n\n\t/* prepare for sampling rows */\n\tselectionState = anl_init_selection_state(targetRowCount);\n\n\tfor (;;)\n\t{\n\t\t/* check for user-requested abort or sleep */\n\t\tvacuum_delay_point();\n\n\t\tmemset(columnValues, 0, columnCount * sizeof(Datum));\n\t\tmemset(columnNulls, true, columnCount * sizeof(bool));\n\n\t\tMemoryContextReset(tupleContext);\n\t\tMemoryContextSwitchTo(tupleContext);\n\n\t\t/* read the next record */\n\t\tCStoreIterateForeignScan(scanState);\n\n\t\tMemoryContextSwitchTo(oldContext);\n\n\t\t/* if there are no more records to read, break */\n\t\tif (TTS_EMPTY(scanTupleSlot))\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * The first targetRowCount sample rows are simply copied into the\n\t\t * reservoir. Then we start replacing tuples in the sample until we\n\t\t * reach the end of the relation. This algorithm is from Jeff Vitter's\n\t\t * paper (see more info in commands/analyze.c).\n\t\t */\n\t\tif (sampleRowCount < targetRowCount)\n\t\t{\n\t\t\tsampleRows[sampleRowCount] = heap_form_tuple(tupleDescriptor, columnValues,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t columnNulls);\n\t\t\tsampleRowCount++;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t/*\n\t\t\t * t in Vitter's paper is the number of records already processed.\n\t\t\t * If we need to compute a new S value, we must use the \"not yet\n\t\t\t * incremented\" value of rowCount as t.\n\t\t\t */\n\t\t\tif (rowCountToSkip < 0)\n\t\t\t{\n\t\t\t\trowCountToSkip = anl_get_next_S(rowCount, targetRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\t&selectionState);\n\t\t\t}\n\n\t\t\tif (rowCountToSkip <= 0)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Found a suitable tuple, so save it, replacing one old tuple\n\t\t\t\t * at random.\n\t\t\t\t */\n\t\t\t\tint rowIndex = (int) (targetRowCount * anl_random_fract());\n\t\t\t\tAssert(rowIndex >= 0);\n\t\t\t\tAssert(rowIndex < targetRowCount);\n\n\t\t\t\theap_freetuple(sampleRows[rowIndex]);\n\t\t\t\tsampleRows[rowIndex] = heap_form_tuple(tupleDescriptor,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   columnValues, columnNulls);\n\t\t\t}\n\n\t\t\trowCountToSkip--;\n\t\t}\n\n\t\trowCount++;\n\t}\n\n\t/* clean up */\n\tMemoryContextDelete(tupleContext);\n\tpfree(columnValues);\n\tpfree(columnNulls);\n\n\tCStoreEndForeignScan(scanState);\n\n\t/* emit some interesting relation info */\n\trelationName = RelationGetRelationName(relation);\n\tereport(logLevel, (errmsg(\"\\\"%s\\\": file contains %.0f rows; %d rows in sample\",\n\t\t\t\t\t\t\t  relationName, rowCount, sampleRowCount)));\n\n\t(*totalRowCount) = rowCount;\n\t(*totalDeadRowCount) = 0;\n\n\treturn sampleRowCount;\n}\n\n\n/*\n * CStorePlanForeignModify checks if operation is supported. Only insert\n * command with subquery (ie insert into <table> select ...) is supported.\n * Other forms of insert, delete, and update commands are not supported. It\n * throws an error when the command is not supported.\n */\nstatic List *\nCStorePlanForeignModify(PlannerInfo *plannerInfo, ModifyTable *plan,\n\t\t\t\t\t\tIndex resultRelation, int subplanIndex)\n{\n\tbool operationSupported = false;\n\n\tif (plan->operation == CMD_INSERT)\n\t{\n\t\tListCell *tableCell = NULL;\n\t\tQuery *query = NULL;\n\n\t\t/*\n\t\t * Only insert operation with select subquery is supported. Other forms\n\t\t * of insert, update, and delete operations are not supported.\n\t\t */\n\t\tquery = plannerInfo->parse;\n\t\tforeach(tableCell, query->rtable)\n\t\t{\n\t\t\tRangeTblEntry *tableEntry = lfirst(tableCell);\n\n\t\t\tif (tableEntry->rtekind == RTE_SUBQUERY &&\n\t\t\t\ttableEntry->subquery != NULL &&\n\t\t\t\ttableEntry->subquery->commandType == CMD_SELECT)\n\t\t\t{\n\t\t\t\toperationSupported = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!operationSupported)\n\t{\n\t\tereport(ERROR, (errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t\t\terrmsg(\"operation is not supported\")));\n\t}\n\n\treturn NIL;\n}\n\n\n/*\n * CStoreBeginForeignModify prepares cstore table for a modification.\n * Only insert is currently supported.\n */\nstatic void\nCStoreBeginForeignModify(ModifyTableState *modifyTableState,\n\t\t\t\t\t\t ResultRelInfo *relationInfo, List *fdwPrivate,\n\t\t\t\t\t\t int subplanIndex, int executorFlags)\n{\n\t/* if Explain with no Analyze, do nothing */\n\tif (executorFlags & EXEC_FLAG_EXPLAIN_ONLY)\n\t{\n\t\treturn;\n\t}\n\n\tAssert (modifyTableState->operation == CMD_INSERT);\n\n\tCStoreBeginForeignInsert(modifyTableState, relationInfo);\n}\n\n\n/*\n * CStoreBeginForeignInsert prepares a cstore table for an insert or rows\n * coming from a COPY.\n */\nstatic void\nCStoreBeginForeignInsert(ModifyTableState *modifyTableState, ResultRelInfo *relationInfo)\n{\n\tOid  foreignTableOid = InvalidOid;\n\tCStoreFdwOptions *cstoreFdwOptions = NULL;\n\tTupleDesc tupleDescriptor = NULL;\n\tTableWriteState *writeState = NULL;\n\tRelation relation = NULL;\n\n\tforeignTableOid = RelationGetRelid(relationInfo->ri_RelationDesc);\n\trelation = relation_open(foreignTableOid, ShareUpdateExclusiveLock);\n\tcstoreFdwOptions = CStoreGetOptions(foreignTableOid);\n\ttupleDescriptor = RelationGetDescr(relationInfo->ri_RelationDesc);\n\n\twriteState = CStoreBeginWrite(cstoreFdwOptions->filename,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->compressionType,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->stripeRowCount,\n\t\t\t\t\t\t\t\t  cstoreFdwOptions->blockRowCount,\n\t\t\t\t\t\t\t\t  tupleDescriptor);\n\n\twriteState->relation = relation;\n\trelationInfo->ri_FdwState = (void *) writeState;\n}\n\n\n/*\n * CStoreExecForeignInsert inserts a single row to cstore table\n * and returns inserted row's data values.\n */\nstatic TupleTableSlot *\nCStoreExecForeignInsert(EState *executorState, ResultRelInfo *relationInfo,\n\t\t\t\t\t\tTupleTableSlot *tupleSlot, TupleTableSlot *planSlot)\n{\n\tTableWriteState *writeState = (TableWriteState*) relationInfo->ri_FdwState;\n\tHeapTuple heapTuple;\n\n\tAssert(writeState != NULL);\n\n\theapTuple = GetSlotHeapTuple(tupleSlot);\n\n\tif (HeapTupleHasExternal(heapTuple))\n\t{\n\t\t/* detoast any toasted attributes */\n\t\tHeapTuple newTuple = toast_flatten_tuple(heapTuple,\n\t\t\t\t\t\t\t\t\t\t\t\t tupleSlot->tts_tupleDescriptor);\n\n\t\tExecForceStoreHeapTuple(newTuple, tupleSlot, true);\n\t}\n\n\tslot_getallattrs(tupleSlot);\n\n\tCStoreWriteRow(writeState, tupleSlot->tts_values, tupleSlot->tts_isnull);\n\n\treturn tupleSlot;\n}\n\n\n/*\n * CStoreEndForeignModify ends the current modification. Only insert is currently\n * supported.\n */\nstatic void\nCStoreEndForeignModify(EState *executorState, ResultRelInfo *relationInfo)\n{\n\tCStoreEndForeignInsert(executorState, relationInfo);\n}\n\n\n/*\n * CStoreEndForeignInsert ends the current insert or COPY operation.\n */\nstatic void\nCStoreEndForeignInsert(EState *executorState, ResultRelInfo *relationInfo)\n{\n\tTableWriteState *writeState = (TableWriteState*) relationInfo->ri_FdwState;\n\n\t/* writeState is NULL during Explain queries */\n\tif (writeState != NULL)\n\t{\n\t\tRelation relation = writeState->relation;\n\n\t\tCStoreEndWrite(writeState);\n\t\trelation_close(relation, ShareUpdateExclusiveLock);\n\t}\n}\n\n\n#if PG_VERSION_NUM >= 90600\n/*\n * CStoreIsForeignScanParallelSafe always returns true to indicate that\n * reading from a cstore_fdw table in a parallel worker is safe. This\n * does not enable parallelism for queries on individual cstore_fdw\n * tables, but does allow parallel scans of cstore_fdw partitions.\n *\n * cstore_fdw is parallel-safe because all writes are immediately committed\n * to disk and then read from disk. There is no uncommitted state that needs\n * to be shared across processes.\n */\nstatic bool\nCStoreIsForeignScanParallelSafe(PlannerInfo *root, RelOptInfo *rel,\n\t\t\t\t\t\t\t\tRangeTblEntry *rte)\n{\n\treturn true;\n}\n#endif\n"
        },
        {
          "name": "cstore_fdw.control",
          "type": "blob",
          "size": 0.1572265625,
          "content": "# cstore_fdw extension\ncomment = 'foreign-data wrapper for flat cstore access'\ndefault_version = '1.7'\nmodule_pathname = '$libdir/cstore_fdw'\nrelocatable = true\n"
        },
        {
          "name": "cstore_fdw.h",
          "type": "blob",
          "size": 9.9521484375,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_fdw.h\n *\n * Type and function declarations for CStore foreign data wrapper.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n#ifndef CSTORE_FDW_H\n#define CSTORE_FDW_H\n\n#include \"access/tupdesc.h\"\n#include \"fmgr.h\"\n#include \"catalog/pg_am.h\"\n#include \"catalog/pg_foreign_server.h\"\n#include \"catalog/pg_foreign_table.h\"\n#include \"lib/stringinfo.h\"\n#include \"utils/rel.h\"\n\n\n/* Defines for valid option names */\n#define OPTION_NAME_FILENAME \"filename\"\n#define OPTION_NAME_COMPRESSION_TYPE \"compression\"\n#define OPTION_NAME_STRIPE_ROW_COUNT \"stripe_row_count\"\n#define OPTION_NAME_BLOCK_ROW_COUNT \"block_row_count\"\n\n/* Default values for option parameters */\n#define DEFAULT_COMPRESSION_TYPE COMPRESSION_NONE\n#define DEFAULT_STRIPE_ROW_COUNT 150000\n#define DEFAULT_BLOCK_ROW_COUNT 10000\n\n/* Limits for option parameters */\n#define STRIPE_ROW_COUNT_MINIMUM 1000\n#define STRIPE_ROW_COUNT_MAXIMUM 10000000\n#define BLOCK_ROW_COUNT_MINIMUM 1000\n#define BLOCK_ROW_COUNT_MAXIMUM 100000\n\n/* String representations of compression types */\n#define COMPRESSION_STRING_NONE \"none\"\n#define COMPRESSION_STRING_PG_LZ \"pglz\"\n#define COMPRESSION_STRING_DELIMITED_LIST \"none, pglz\"\n\n/* CStore file signature */\n#define CSTORE_MAGIC_NUMBER \"citus_cstore\"\n#define CSTORE_VERSION_MAJOR 1\n#define CSTORE_VERSION_MINOR 7\n\n/* miscellaneous defines */\n#define CSTORE_FDW_NAME \"cstore_fdw\"\n#define CSTORE_FOOTER_FILE_SUFFIX \".footer\"\n#define CSTORE_TEMP_FILE_SUFFIX \".tmp\"\n#define CSTORE_TUPLE_COST_MULTIPLIER 10\n#define CSTORE_POSTSCRIPT_SIZE_LENGTH 1\n#define CSTORE_POSTSCRIPT_SIZE_MAX 256\n\n/* table containing information about how to partition distributed tables */\n#define CITUS_EXTENSION_NAME \"citus\"\n#define CITUS_PARTITION_TABLE_NAME \"pg_dist_partition\"\n\n/* human-readable names for addressing columns of the pg_dist_partition table */\n#define ATTR_NUM_PARTITION_RELATION_ID 1\n#define ATTR_NUM_PARTITION_TYPE 2\n#define ATTR_NUM_PARTITION_KEY 3\n\n\n/*\n * CStoreValidOption keeps an option name and a context. When an option is passed\n * into cstore_fdw objects (server and foreign table), we compare this option's\n * name and context against those of valid options.\n */\ntypedef struct CStoreValidOption\n{\n\tconst char *optionName;\n\tOid optionContextId;\n\n} CStoreValidOption;\n\n\n/* Array of options that are valid for cstore_fdw */\nstatic const uint32 ValidOptionCount = 4;\nstatic const CStoreValidOption ValidOptionArray[] =\n{\n\t/* foreign table options */\n\t{ OPTION_NAME_FILENAME, ForeignTableRelationId },\n\t{ OPTION_NAME_COMPRESSION_TYPE, ForeignTableRelationId },\n\t{ OPTION_NAME_STRIPE_ROW_COUNT, ForeignTableRelationId },\n\t{ OPTION_NAME_BLOCK_ROW_COUNT, ForeignTableRelationId }\n};\n\n\n/* Enumaration for cstore file's compression method */\ntypedef enum\n{\n\tCOMPRESSION_TYPE_INVALID = -1,\n\tCOMPRESSION_NONE = 0,\n\tCOMPRESSION_PG_LZ = 1,\n\n\tCOMPRESSION_COUNT\n\n} CompressionType;\n\n\n/*\n * CStoreFdwOptions holds the option values to be used when reading or writing\n * a cstore file. To resolve these values, we first check foreign table's options,\n * and if not present, we then fall back to the default values specified above.\n */\ntypedef struct CStoreFdwOptions\n{\n\tchar *filename;\n\tCompressionType compressionType;\n\tuint64 stripeRowCount;\n\tuint32 blockRowCount;\n\n} CStoreFdwOptions;\n\n\n/*\n * StripeMetadata represents information about a stripe. This information is\n * stored in the cstore file's footer.\n */\ntypedef struct StripeMetadata\n{\n\tuint64 fileOffset;\n\tuint64 skipListLength;\n\tuint64 dataLength;\n\tuint64 footerLength;\n\n} StripeMetadata;\n\n\n/* TableFooter represents the footer of a cstore file. */\ntypedef struct TableFooter\n{\n\tList *stripeMetadataList;\n\tuint64 blockRowCount;\n\n} TableFooter;\n\n\n/* ColumnBlockSkipNode contains statistics for a ColumnBlockData. */\ntypedef struct ColumnBlockSkipNode\n{\n\t/* statistics about values of a column block */\n\tbool hasMinMax;\n\tDatum minimumValue;\n\tDatum maximumValue;\n\tuint64 rowCount;\n\n\t/*\n\t * Offsets and sizes of value and exists streams in the column data.\n\t * These enable us to skip reading suppressed row blocks, and start reading\n\t * a block without reading previous blocks.\n\t */\n\tuint64 valueBlockOffset;\n\tuint64 valueLength;\n\tuint64 existsBlockOffset;\n\tuint64 existsLength;\n\n\tCompressionType valueCompressionType;\n\n} ColumnBlockSkipNode;\n\n\n/*\n * StripeSkipList can be used for skipping row blocks. It contains a column block\n * skip node for each block of each column. blockSkipNodeArray[column][block]\n * is the entry for the specified column block.\n */\ntypedef struct StripeSkipList\n{\n\tColumnBlockSkipNode **blockSkipNodeArray;\n\tuint32 columnCount;\n\tuint32 blockCount;\n\n} StripeSkipList;\n\n\n/*\n * ColumnBlockData represents a block of data in a column. valueArray stores\n * the values of data, and existsArray stores whether a value is present.\n * valueBuffer is used to store (uncompressed) serialized values\n * referenced by Datum's in valueArray. It is only used for by-reference Datum's.\n * There is a one-to-one correspondence between valueArray and existsArray.\n */\ntypedef struct ColumnBlockData\n{\n\tbool *existsArray;\n\tDatum *valueArray;\n\n\t/* valueBuffer keeps actual data for type-by-reference datums from valueArray. */\n\tStringInfo valueBuffer;\n\n} ColumnBlockData;\n\n\n/*\n * ColumnBlockBuffers represents a block of serialized data in a column.\n * valueBuffer stores the serialized values of data, and existsBuffer stores\n * serialized value of presence information. valueCompressionType contains\n * compression type if valueBuffer is compressed. Finally rowCount has\n * the number of rows in this block.\n */\ntypedef struct ColumnBlockBuffers\n{\n\tStringInfo existsBuffer;\n\tStringInfo valueBuffer;\n\tCompressionType valueCompressionType;\n\n} ColumnBlockBuffers;\n\n\n/*\n * ColumnBuffers represents data buffers for a column in a row stripe. Each\n * column is made of multiple column blocks.\n */\ntypedef struct ColumnBuffers\n{\n\tColumnBlockBuffers **blockBuffersArray;\n\n} ColumnBuffers;\n\n\n/* StripeBuffers represents data for a row stripe in a cstore file. */\ntypedef struct StripeBuffers\n{\n\tuint32 columnCount;\n\tuint32 rowCount;\n\tColumnBuffers **columnBuffersArray;\n\n} StripeBuffers;\n\n\n/*\n * StripeFooter represents a stripe's footer. In this footer, we keep three\n * arrays of sizes. The number of elements in each of the arrays is equal\n * to the number of columns.\n */\ntypedef struct StripeFooter\n{\n\tuint32 columnCount;\n\tuint64 *skipListSizeArray;\n\tuint64 *existsSizeArray;\n\tuint64 *valueSizeArray;\n\n} StripeFooter;\n\n\n/* TableReadState represents state of a cstore file read operation. */\ntypedef struct TableReadState\n{\n\tFILE *tableFile;\n\tTableFooter *tableFooter;\n\tTupleDesc tupleDescriptor;\n\n\t/*\n\t * List of Var pointers for columns in the query. We use this both for\n\t * getting vector of projected columns, and also when we want to build\n\t * base constraint to find selected row blocks.\n\t */\n\tList *projectedColumnList;\n\n\tList *whereClauseList;\n\tMemoryContext stripeReadContext;\n\tStripeBuffers *stripeBuffers;\n\tuint32 readStripeCount;\n\tuint64 stripeReadRowCount;\n\tColumnBlockData **blockDataArray;\n\tint32 deserializedBlockIndex;\n\n} TableReadState;\n\n\n/* TableWriteState represents state of a cstore file write operation. */\ntypedef struct TableWriteState\n{\n\tFILE *tableFile;\n\tTableFooter *tableFooter;\n\tStringInfo tableFooterFilename;\n\tCompressionType compressionType;\n\tTupleDesc tupleDescriptor;\n\tFmgrInfo **comparisonFunctionArray;\n\tuint64 currentFileOffset;\n\tRelation relation;\n\n\tMemoryContext stripeWriteContext;\n\tStripeBuffers *stripeBuffers;\n\tStripeSkipList *stripeSkipList;\n\tuint32 stripeMaxRowCount;\n\tColumnBlockData **blockDataArray;\n\t/*\n\t * compressionBuffer buffer is used as temporary storage during\n\t * data value compression operation. It is kept here to minimize\n\t * memory allocations. It lives in stripeWriteContext and gets\n\t * deallocated when memory context is reset.\n\t */\n\tStringInfo compressionBuffer;\n\n} TableWriteState;\n\n/* Function declarations for extension loading and unloading */\nextern void _PG_init(void);\nextern void _PG_fini(void);\n\n/* event trigger function declarations */\nextern Datum cstore_ddl_event_end_trigger(PG_FUNCTION_ARGS);\n\n/* Function declarations for utility UDFs */\nextern Datum cstore_table_size(PG_FUNCTION_ARGS);\nextern Datum cstore_clean_table_resources(PG_FUNCTION_ARGS);\n\n/* Function declarations for foreign data wrapper */\nextern Datum cstore_fdw_handler(PG_FUNCTION_ARGS);\nextern Datum cstore_fdw_validator(PG_FUNCTION_ARGS);\n\n/* Function declarations for writing to a cstore file */\nextern TableWriteState * CStoreBeginWrite(const char *filename,\n\t\t\t\t\t\t\t\t\t\t  CompressionType compressionType,\n\t\t\t\t\t\t\t\t\t\t  uint64 stripeMaxRowCount,\n\t\t\t\t\t\t\t\t\t\t  uint32 blockRowCount,\n\t\t\t\t\t\t\t\t\t\t  TupleDesc tupleDescriptor);\nextern void CStoreWriteRow(TableWriteState *state, Datum *columnValues,\n\t\t\t\t\t\t   bool *columnNulls);\nextern void CStoreEndWrite(TableWriteState * state);\n\n/* Function declarations for reading from a cstore file */\nextern TableReadState * CStoreBeginRead(const char *filename, TupleDesc tupleDescriptor,\n\t\t\t\t\t\t\t\t\t\tList *projectedColumnList, List *qualConditions);\nextern TableFooter * CStoreReadFooter(StringInfo tableFooterFilename);\nextern bool CStoreReadFinished(TableReadState *state);\nextern bool CStoreReadNextRow(TableReadState *state, Datum *columnValues,\n\t\t\t\t\t\t\t  bool *columnNulls);\nextern void CStoreEndRead(TableReadState *state);\n\n/* Function declarations for common functions */\nextern FmgrInfo * GetFunctionInfoOrNull(Oid typeId, Oid accessMethodId,\n\t\t\t\t\t\t\t\t\t\tint16 procedureId);\nextern ColumnBlockData ** CreateEmptyBlockDataArray(uint32 columnCount, bool *columnMask,\n\t\t\t\t\t\t\t\t\t\t\t\t\tuint32 blockRowCount);\nextern void FreeColumnBlockDataArray(ColumnBlockData **blockDataArray,\n\t\t\t\t\t\t\t\t\t uint32 columnCount);\nextern uint64 CStoreTableRowCount(const char *filename);\nextern bool CompressBuffer(StringInfo inputBuffer, StringInfo outputBuffer,\n\t\t\t\t\t\t   CompressionType compressionType);\nextern StringInfo DecompressBuffer(StringInfo buffer, CompressionType compressionType);\n\n\n#endif   /* CSTORE_FDW_H */ \n"
        },
        {
          "name": "cstore_metadata_serialization.c",
          "type": "blob",
          "size": 19.3642578125,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_metadata_serialization.c\n *\n * This file contains function definitions for serializing/deserializing cstore\n * metadata.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n\n#include \"postgres.h\"\n#include \"cstore_fdw.h\"\n#include \"cstore_metadata_serialization.h\"\n#include \"cstore.pb-c.h\"\n#include \"access/tupmacs.h\"\n\n\n/* local functions forward declarations */\nstatic ProtobufCBinaryData DatumToProtobufBinary(Datum datum, bool typeByValue,\n\t\t\t\t\t\t\t\t\t\t\t\t int typeLength);\nstatic Datum ProtobufBinaryToDatum(ProtobufCBinaryData protobufBinary,\n\t\t\t\t\t\t\t\t   bool typeByValue, int typeLength);\n\n\n/*\n * SerializePostScript serializes the given postscript and returns the result as\n * a StringInfo.\n */\nStringInfo\nSerializePostScript(uint64 tableFooterLength)\n{\n\tStringInfo postscriptBuffer = NULL;\n\tProtobuf__PostScript protobufPostScript = PROTOBUF__POST_SCRIPT__INIT;\n\tuint8 *postscriptData = NULL;\n\tuint32 postscriptSize = 0;\n\n\tprotobufPostScript.has_tablefooterlength = true;\n\tprotobufPostScript.tablefooterlength = tableFooterLength;\n\tprotobufPostScript.has_versionmajor = true;\n\tprotobufPostScript.versionmajor = CSTORE_VERSION_MAJOR;\n\tprotobufPostScript.has_versionminor = true;\n\tprotobufPostScript.versionminor = CSTORE_VERSION_MINOR;\n\tprotobufPostScript.magicnumber = pstrdup(CSTORE_MAGIC_NUMBER);\n\n\tpostscriptSize = protobuf__post_script__get_packed_size(&protobufPostScript);\n\tpostscriptData = palloc0(postscriptSize);\n\tprotobuf__post_script__pack(&protobufPostScript, postscriptData);\n\n\tpostscriptBuffer = palloc0(sizeof(StringInfoData));\n\tpostscriptBuffer->len = postscriptSize;\n\tpostscriptBuffer->maxlen = postscriptSize;\n\tpostscriptBuffer->data = (char *) postscriptData;\n\n\treturn postscriptBuffer;\n}\n\n\n/*\n * SerializeTableFooter serializes the given table footer and returns the result\n * as a StringInfo.\n */\nStringInfo\nSerializeTableFooter(TableFooter *tableFooter)\n{\n\tStringInfo tableFooterBuffer = NULL;\n\tProtobuf__TableFooter protobufTableFooter = PROTOBUF__TABLE_FOOTER__INIT;\n\tProtobuf__StripeMetadata **stripeMetadataArray = NULL;\n\tListCell *stripeMetadataCell = NULL;\n\tuint8 *tableFooterData = NULL;\n\tuint32 tableFooterSize = 0;\n\tuint32 stripeIndex = 0;\n\n\tList *stripeMetadataList = tableFooter->stripeMetadataList;\n\tuint32 stripeCount = list_length(stripeMetadataList);\n\tstripeMetadataArray = palloc0(stripeCount * sizeof(Protobuf__StripeMetadata *));\n\n\tforeach(stripeMetadataCell, stripeMetadataList)\n\t{\n\t\tStripeMetadata *stripeMetadata = lfirst(stripeMetadataCell);\n\n\t\tProtobuf__StripeMetadata *protobufStripeMetadata = NULL;\n\t\tprotobufStripeMetadata = palloc0(sizeof(Protobuf__StripeMetadata));\n\t\tprotobuf__stripe_metadata__init(protobufStripeMetadata);\n\t\tprotobufStripeMetadata->has_fileoffset = true;\n\t\tprotobufStripeMetadata->fileoffset = stripeMetadata->fileOffset;\n\t\tprotobufStripeMetadata->has_skiplistlength = true;\n\t\tprotobufStripeMetadata->skiplistlength = stripeMetadata->skipListLength;\n\t\tprotobufStripeMetadata->has_datalength = true;\n\t\tprotobufStripeMetadata->datalength = stripeMetadata->dataLength;\n\t\tprotobufStripeMetadata->has_footerlength = true;\n\t\tprotobufStripeMetadata->footerlength = stripeMetadata->footerLength;\n\n\t\tstripeMetadataArray[stripeIndex] = protobufStripeMetadata;\n\t\tstripeIndex++;\n\t}\n\n\tprotobufTableFooter.n_stripemetadataarray = stripeCount;\n\tprotobufTableFooter.stripemetadataarray = stripeMetadataArray;\n\tprotobufTableFooter.has_blockrowcount = true;\n\tprotobufTableFooter.blockrowcount = tableFooter->blockRowCount;\n\n\ttableFooterSize = protobuf__table_footer__get_packed_size(&protobufTableFooter);\n\ttableFooterData = palloc0(tableFooterSize);\n\tprotobuf__table_footer__pack(&protobufTableFooter, tableFooterData);\n\n\ttableFooterBuffer = palloc0(sizeof(StringInfoData));\n\ttableFooterBuffer->len = tableFooterSize;\n\ttableFooterBuffer->maxlen = tableFooterSize;\n\ttableFooterBuffer->data = (char *) tableFooterData;\n\n\treturn tableFooterBuffer;\n}\n\n\n/*\n * SerializeStripeFooter serializes given stripe footer and returns the result\n * as a StringInfo.\n */\nStringInfo\nSerializeStripeFooter(StripeFooter *stripeFooter)\n{\n\tStringInfo stripeFooterBuffer = NULL;\n\tProtobuf__StripeFooter protobufStripeFooter = PROTOBUF__STRIPE_FOOTER__INIT;\n\tuint8 *stripeFooterData = NULL;\n\tuint32 stripeFooterSize = 0;\n\n\tprotobufStripeFooter.n_skiplistsizearray = stripeFooter->columnCount;\n\tprotobufStripeFooter.skiplistsizearray = (uint64_t *) stripeFooter->skipListSizeArray;\n\tprotobufStripeFooter.n_existssizearray = stripeFooter->columnCount;\n\tprotobufStripeFooter.existssizearray = (uint64_t *) stripeFooter->existsSizeArray;\n\tprotobufStripeFooter.n_valuesizearray = stripeFooter->columnCount;\n\tprotobufStripeFooter.valuesizearray = (uint64_t *) stripeFooter->valueSizeArray;\n\n\tstripeFooterSize = protobuf__stripe_footer__get_packed_size(&protobufStripeFooter);\n\tstripeFooterData = palloc0(stripeFooterSize);\n\tprotobuf__stripe_footer__pack(&protobufStripeFooter, stripeFooterData);\n\n\tstripeFooterBuffer = palloc0(sizeof(StringInfoData));\n\tstripeFooterBuffer->len = stripeFooterSize;\n\tstripeFooterBuffer->maxlen = stripeFooterSize;\n\tstripeFooterBuffer->data = (char *) stripeFooterData;\n\n\treturn stripeFooterBuffer;\n}\n\n\n/*\n * SerializeColumnSkipList serializes a column skip list, where the colum skip\n * list includes all block skip nodes for that column. The function then returns\n * the result as a string info.\n */\nStringInfo\nSerializeColumnSkipList(ColumnBlockSkipNode *blockSkipNodeArray, uint32 blockCount,\n\t\t\t\t\t\tbool typeByValue, int typeLength)\n{\n\tStringInfo blockSkipListBuffer = NULL;\n\tProtobuf__ColumnBlockSkipList protobufBlockSkipList =\n\t\tPROTOBUF__COLUMN_BLOCK_SKIP_LIST__INIT;\n\tProtobuf__ColumnBlockSkipNode **protobufBlockSkipNodeArray = NULL;\n\tuint32 blockIndex = 0;\n\tuint8 *blockSkipListData = NULL;\n\tuint32 blockSkipListSize = 0;\n\n\tprotobufBlockSkipNodeArray = palloc0(blockCount *\n\t\t\t\t\t\t\t\t\t\t sizeof(Protobuf__ColumnBlockSkipNode *));\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tColumnBlockSkipNode blockSkipNode = blockSkipNodeArray[blockIndex];\n\t\tProtobuf__ColumnBlockSkipNode *protobufBlockSkipNode = NULL;\n\t\tProtobufCBinaryData binaryMinimumValue = {0, 0};\n\t\tProtobufCBinaryData binaryMaximumValue = {0, 0};\n\n\t\tif (blockSkipNode.hasMinMax)\n\t\t{\n\t\t\tbinaryMinimumValue = DatumToProtobufBinary(blockSkipNode.minimumValue,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   typeByValue, typeLength);\n\t\t\tbinaryMaximumValue = DatumToProtobufBinary(blockSkipNode.maximumValue,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   typeByValue, typeLength);\n\t\t}\n\n\t\tprotobufBlockSkipNode = palloc0(sizeof(Protobuf__ColumnBlockSkipNode));\n\t\tprotobuf__column_block_skip_node__init(protobufBlockSkipNode);\n\t\tprotobufBlockSkipNode->has_rowcount = true;\n\t\tprotobufBlockSkipNode->rowcount = blockSkipNode.rowCount;\n\t\tprotobufBlockSkipNode->has_minimumvalue = blockSkipNode.hasMinMax;\n\t\tprotobufBlockSkipNode->minimumvalue = binaryMinimumValue;\n\t\tprotobufBlockSkipNode->has_maximumvalue = blockSkipNode.hasMinMax;\n\t\tprotobufBlockSkipNode->maximumvalue = binaryMaximumValue;\n\t\tprotobufBlockSkipNode->has_valueblockoffset = true;\n\t\tprotobufBlockSkipNode->valueblockoffset = blockSkipNode.valueBlockOffset;\n\t\tprotobufBlockSkipNode->has_valuelength = true;\n\t\tprotobufBlockSkipNode->valuelength = blockSkipNode.valueLength;\n\t\tprotobufBlockSkipNode->has_existsblockoffset = true;\n\t\tprotobufBlockSkipNode->existsblockoffset = blockSkipNode.existsBlockOffset;\n\t\tprotobufBlockSkipNode->has_existslength = true;\n\t\tprotobufBlockSkipNode->existslength = blockSkipNode.existsLength;\n\t\tprotobufBlockSkipNode->has_valuecompressiontype = true;\n\t\tprotobufBlockSkipNode->valuecompressiontype =\n\t\t\t(Protobuf__CompressionType) blockSkipNode.valueCompressionType;\n\n\t\tprotobufBlockSkipNodeArray[blockIndex] = protobufBlockSkipNode;\n\t}\n\n\tprotobufBlockSkipList.n_blockskipnodearray = blockCount;\n\tprotobufBlockSkipList.blockskipnodearray = protobufBlockSkipNodeArray;\n\n\tblockSkipListSize =\n\t\tprotobuf__column_block_skip_list__get_packed_size(&protobufBlockSkipList);\n\tblockSkipListData = palloc0(blockSkipListSize);\n\tprotobuf__column_block_skip_list__pack(&protobufBlockSkipList, blockSkipListData);\n\n\tblockSkipListBuffer = palloc0(sizeof(StringInfoData));\n\tblockSkipListBuffer->len = blockSkipListSize;\n\tblockSkipListBuffer->maxlen = blockSkipListSize;\n\tblockSkipListBuffer->data = (char *) blockSkipListData;\n\n\treturn blockSkipListBuffer;\n}\n\n\n/*\n * DeserializePostScript deserializes the given postscript buffer and returns\n * the size of table footer in tableFooterLength pointer.\n */\nvoid\nDeserializePostScript(StringInfo buffer, uint64 *tableFooterLength)\n{\n\tProtobuf__PostScript *protobufPostScript = NULL;\n\tprotobufPostScript = protobuf__post_script__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   (uint8 *) buffer->data);\n\tif (protobufPostScript == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid postscript buffer\")));\n\t}\n\n\tif (protobufPostScript->versionmajor != CSTORE_VERSION_MAJOR ||\n\t\tprotobufPostScript->versionminor > CSTORE_VERSION_MINOR)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid column store version number\")));\n\t}\n\telse if (strncmp(protobufPostScript->magicnumber, CSTORE_MAGIC_NUMBER,\n\t\t\t\t\t NAMEDATALEN) != 0)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid magic number\")));\n\t}\n\n\t(*tableFooterLength) = protobufPostScript->tablefooterlength;\n\n\tprotobuf__post_script__free_unpacked(protobufPostScript, NULL);\n}\n\n\n/*\n * DeserializeTableFooter deserializes the given buffer and returns the result as\n * a TableFooter struct.\n */\nTableFooter *\nDeserializeTableFooter(StringInfo buffer)\n{\n\tTableFooter *tableFooter = NULL;\n\tProtobuf__TableFooter *protobufTableFooter = NULL;\n\tList *stripeMetadataList = NIL;\n\tuint64 blockRowCount = 0;\n\tuint32 stripeCount = 0;\n\tuint32 stripeIndex = 0;\n\n\tprotobufTableFooter = protobuf__table_footer__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t (uint8 *) buffer->data);\n\tif (protobufTableFooter == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid table footer buffer\")));\n\t}\n\n\tif (!protobufTableFooter->has_blockrowcount)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"missing required table footer metadata fields\")));\n\t}\n\telse if (protobufTableFooter->blockrowcount < BLOCK_ROW_COUNT_MINIMUM ||\n\t\t\t protobufTableFooter->blockrowcount > BLOCK_ROW_COUNT_MAXIMUM)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid block row count\")));\n\t}\n\tblockRowCount = protobufTableFooter->blockrowcount;\n\n\tstripeCount = protobufTableFooter->n_stripemetadataarray;\n\tfor (stripeIndex = 0; stripeIndex < stripeCount; stripeIndex++)\n\t{\n\t\tStripeMetadata *stripeMetadata = NULL;\n\t\tProtobuf__StripeMetadata *protobufStripeMetadata = NULL;\n\n\t\tprotobufStripeMetadata = protobufTableFooter->stripemetadataarray[stripeIndex];\n\t\tif (!protobufStripeMetadata->has_fileoffset ||\n\t\t\t!protobufStripeMetadata->has_skiplistlength ||\n\t\t\t!protobufStripeMetadata->has_datalength ||\n\t\t\t!protobufStripeMetadata->has_footerlength)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\t\terrdetail(\"missing required stripe metadata fields\")));\n\t\t}\n\n\t\tstripeMetadata = palloc0(sizeof(StripeMetadata));\n\t\tstripeMetadata->fileOffset = protobufStripeMetadata->fileoffset;\n\t\tstripeMetadata->skipListLength = protobufStripeMetadata->skiplistlength;\n\t\tstripeMetadata->dataLength = protobufStripeMetadata->datalength;\n\t\tstripeMetadata->footerLength = protobufStripeMetadata->footerlength;\n\n\t\tstripeMetadataList = lappend(stripeMetadataList, stripeMetadata);\n\t}\n\n\tprotobuf__table_footer__free_unpacked(protobufTableFooter, NULL);\n\n\ttableFooter = palloc0(sizeof(TableFooter));\n\ttableFooter->stripeMetadataList = stripeMetadataList;\n\ttableFooter->blockRowCount = blockRowCount;\n\n\treturn tableFooter;\n}\n\n\n/*\n * DeserializeStripeFooter deserializes the given buffer and returns the result\n * as a StripeFooter struct.\n */\nStripeFooter *\nDeserializeStripeFooter(StringInfo buffer)\n{\n\tStripeFooter *stripeFooter = NULL;\n\tProtobuf__StripeFooter *protobufStripeFooter = NULL;\n\tuint64 *skipListSizeArray = NULL;\n\tuint64 *existsSizeArray = NULL;\n\tuint64 *valueSizeArray = NULL;\n\tuint64 sizeArrayLength = 0;\n\tuint32 columnCount = 0;\n\n\tprotobufStripeFooter = protobuf__stripe_footer__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t   (uint8 *) buffer->data);\n\tif (protobufStripeFooter == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid stripe footer buffer\")));\n\t}\n\n\tcolumnCount = protobufStripeFooter->n_skiplistsizearray;\n\tif (protobufStripeFooter->n_existssizearray != columnCount ||\n\t\tprotobufStripeFooter->n_valuesizearray != columnCount)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"stripe size array lengths don't match\")));\n\t}\n\n\tsizeArrayLength = columnCount * sizeof(uint64);\n\n\tskipListSizeArray = palloc0(sizeArrayLength);\n\texistsSizeArray = palloc0(sizeArrayLength);\n\tvalueSizeArray = palloc0(sizeArrayLength);\n\n\tmemcpy(skipListSizeArray, protobufStripeFooter->skiplistsizearray, sizeArrayLength);\n\tmemcpy(existsSizeArray, protobufStripeFooter->existssizearray, sizeArrayLength);\n\tmemcpy(valueSizeArray, protobufStripeFooter->valuesizearray, sizeArrayLength);\n\n\tprotobuf__stripe_footer__free_unpacked(protobufStripeFooter, NULL);\n\n\tstripeFooter = palloc0(sizeof(StripeFooter));\n\tstripeFooter->skipListSizeArray = skipListSizeArray;\n\tstripeFooter->existsSizeArray = existsSizeArray;\n\tstripeFooter->valueSizeArray = valueSizeArray;\n\tstripeFooter->columnCount = columnCount;\n\n\treturn stripeFooter;\n}\n\n\n/*\n * DeserializeBlockCount deserializes the given column skip list buffer and\n * returns the number of blocks in column skip list.\n */\nuint32\nDeserializeBlockCount(StringInfo buffer)\n{\n\tuint32 blockCount = 0;\n\tProtobuf__ColumnBlockSkipList *protobufBlockSkipList = NULL;\n\n\tprotobufBlockSkipList =\n\t\tprotobuf__column_block_skip_list__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t (uint8 *) buffer->data);\n\tif (protobufBlockSkipList == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid skip list buffer\")));\n\t}\n\n\tblockCount = protobufBlockSkipList->n_blockskipnodearray;\n\n\tprotobuf__column_block_skip_list__free_unpacked(protobufBlockSkipList, NULL);\n\n\treturn blockCount;\n}\n\n\n/*\n * DeserializeRowCount deserializes the given column skip list buffer and\n * returns the total number of rows in block skip list.\n */\nuint32\nDeserializeRowCount(StringInfo buffer)\n{\n\tuint32 rowCount = 0;\n\tProtobuf__ColumnBlockSkipList *protobufBlockSkipList = NULL;\n\tuint32 blockIndex = 0;\n\tuint32 blockCount = 0;\n\n\tprotobufBlockSkipList =\n\t\tprotobuf__column_block_skip_list__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t (uint8 *) buffer->data);\n\tif (protobufBlockSkipList == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid skip list buffer\")));\n\t}\n\n\tblockCount = (uint32) protobufBlockSkipList->n_blockskipnodearray;\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tProtobuf__ColumnBlockSkipNode *protobufBlockSkipNode =\n\t\t\t\tprotobufBlockSkipList->blockskipnodearray[blockIndex];\n\t\trowCount += protobufBlockSkipNode->rowcount;\n\t}\n\n\tprotobuf__column_block_skip_list__free_unpacked(protobufBlockSkipList, NULL);\n\n\treturn rowCount;\n}\n\n\n/*\n * DeserializeColumnSkipList deserializes the given buffer and returns the result as\n * a ColumnBlockSkipNode array. If the number of unpacked block skip nodes are not\n * equal to the given block count function errors out.\n */\nColumnBlockSkipNode *\nDeserializeColumnSkipList(StringInfo buffer, bool typeByValue, int typeLength,\n\t\t\t\t\t\t  uint32 blockCount)\n{\n\tColumnBlockSkipNode *blockSkipNodeArray = NULL;\n\tuint32 blockIndex = 0;\n\tProtobuf__ColumnBlockSkipList *protobufBlockSkipList = NULL;\n\n\tprotobufBlockSkipList =\n\t\tprotobuf__column_block_skip_list__unpack(NULL, buffer->len,\n\t\t\t\t\t\t\t\t\t\t\t\t (uint8 *) buffer->data);\n\tif (protobufBlockSkipList == NULL)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"invalid skip list buffer\")));\n\t}\n\n\tif (protobufBlockSkipList->n_blockskipnodearray != blockCount)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\terrdetail(\"block skip node count and block count don't match\")));\n\t}\n\n\tblockSkipNodeArray = palloc0(blockCount * sizeof(ColumnBlockSkipNode));\n\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tProtobuf__ColumnBlockSkipNode *protobufBlockSkipNode = NULL;\n\t\tColumnBlockSkipNode *blockSkipNode = NULL;\n\t\tbool hasMinMax = false;\n\t\tDatum minimumValue = 0;\n\t\tDatum maximumValue = 0;\n\n\t\tprotobufBlockSkipNode = protobufBlockSkipList->blockskipnodearray[blockIndex];\n\t\tif (!protobufBlockSkipNode->has_rowcount ||\n\t\t\t!protobufBlockSkipNode->has_existsblockoffset ||\n\t\t\t!protobufBlockSkipNode->has_valueblockoffset ||\n\t\t\t!protobufBlockSkipNode->has_existslength ||\n\t\t\t!protobufBlockSkipNode->has_valuelength ||\n\t\t\t!protobufBlockSkipNode->has_valuecompressiontype)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\t\terrdetail(\"missing required block skip node metadata\")));\n\t\t}\n\n\t\tif (protobufBlockSkipNode->has_minimumvalue !=\n\t\t\tprotobufBlockSkipNode->has_maximumvalue)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"could not unpack column store\"),\n\t\t\t\t\t\t\terrdetail(\"has minimum and has maximum fields \"\n\t\t\t\t\t\t\t\t\t  \"don't match\")));\n\t\t}\n\n\t\thasMinMax = protobufBlockSkipNode->has_minimumvalue;\n\t\tif (hasMinMax)\n\t\t{\n\t\t\tminimumValue = ProtobufBinaryToDatum(protobufBlockSkipNode->minimumvalue,\n\t\t\t\t\t\t\t\t\t\t\t\t typeByValue, typeLength);\n\t\t\tmaximumValue = ProtobufBinaryToDatum(protobufBlockSkipNode->maximumvalue,\n\t\t\t\t\t\t\t\t\t\t\t\t typeByValue, typeLength);\n\t\t}\n\n\t\tblockSkipNode = &blockSkipNodeArray[blockIndex];\n\t\tblockSkipNode->rowCount = protobufBlockSkipNode->rowcount;\n\t\tblockSkipNode->hasMinMax = hasMinMax;\n\t\tblockSkipNode->minimumValue = minimumValue;\n\t\tblockSkipNode->maximumValue = maximumValue;\n\t\tblockSkipNode->existsBlockOffset = protobufBlockSkipNode->existsblockoffset;\n\t\tblockSkipNode->valueBlockOffset = protobufBlockSkipNode->valueblockoffset;\n\t\tblockSkipNode->existsLength = protobufBlockSkipNode->existslength;\n\t\tblockSkipNode->valueLength = protobufBlockSkipNode->valuelength;\n\t\tblockSkipNode->valueCompressionType =\n\t\t\t(CompressionType) protobufBlockSkipNode->valuecompressiontype;\n\t}\n\n\tprotobuf__column_block_skip_list__free_unpacked(protobufBlockSkipList, NULL);\n\n\treturn blockSkipNodeArray;\n}\n\n\n/* Converts a datum to a ProtobufCBinaryData. */\nstatic ProtobufCBinaryData\nDatumToProtobufBinary(Datum datum, bool datumTypeByValue, int datumTypeLength)\n{\n\tProtobufCBinaryData protobufBinary = {0, 0};\n\n\tint datumLength = att_addlength_datum(0, datumTypeLength, datum);\n\tchar *datumBuffer = palloc0(datumLength);\n\n\tif (datumTypeLength > 0)\n\t{\n\t\tif (datumTypeByValue)\n\t\t{\n\t\t\tstore_att_byval(datumBuffer, datum, datumTypeLength);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmemcpy(datumBuffer, DatumGetPointer(datum), datumTypeLength);\n\t\t}\n\t}\n\telse\n\t{\n\t\tmemcpy(datumBuffer, DatumGetPointer(datum), datumLength);\n\t}\n\n\tprotobufBinary.data = (uint8 *) datumBuffer;\n\tprotobufBinary.len = datumLength;\n\n\treturn protobufBinary;\n}\n\n\n/* Converts the given ProtobufCBinaryData to a Datum. */\nstatic Datum\nProtobufBinaryToDatum(ProtobufCBinaryData protobufBinary, bool datumTypeByValue,\n\t\t\t\t\t  int datumTypeLength)\n{\n\tDatum datum = 0;\n\n\t/*\n\t * We copy the protobuf data so the result of this function lives even\n\t * after the unpacked protobuf struct is freed.\n\t */\n\tchar *binaryDataCopy = palloc0(protobufBinary.len);\n\tmemcpy(binaryDataCopy, protobufBinary.data, protobufBinary.len);\n\n\tdatum = fetch_att(binaryDataCopy, datumTypeByValue, datumTypeLength);\n\n\treturn datum;\n}\n"
        },
        {
          "name": "cstore_metadata_serialization.h",
          "type": "blob",
          "size": 1.4697265625,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_metadata_serialization.h\n *\n * Type and function declarations to serialize/deserialize cstore metadata.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n#ifndef CSTORE_SERIALIZATION_H\n#define CSTORE_SERIALIZATION_H\n\n#include \"catalog/pg_attribute.h\"\n#include \"nodes/pg_list.h\"\n#include \"lib/stringinfo.h\"\n#include \"cstore_fdw.h\"\n\n\n/* Function declarations for metadata serialization */\nextern StringInfo SerializePostScript(uint64 tableFooterLength);\nextern StringInfo SerializeTableFooter(TableFooter *tableFooter);\nextern StringInfo SerializeStripeFooter(StripeFooter *stripeFooter);\nextern StringInfo SerializeColumnSkipList(ColumnBlockSkipNode *blockSkipNodeArray,\n\t\t\t\t\t\t\t\t\t\t  uint32 blockCount, bool typeByValue,\n\t\t\t\t\t\t\t\t\t\t  int typeLength);\n\n/* Function declarations for metadata deserialization */\nextern void DeserializePostScript(StringInfo buffer, uint64 *tableFooterLength);\nextern TableFooter * DeserializeTableFooter(StringInfo buffer);\nextern uint32 DeserializeBlockCount(StringInfo buffer);\nextern uint32 DeserializeRowCount(StringInfo buffer);\nextern StripeFooter * DeserializeStripeFooter(StringInfo buffer);\nextern ColumnBlockSkipNode * DeserializeColumnSkipList(StringInfo buffer,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   bool typeByValue, int typeLength,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   uint32 blockCount);\n\n\n#endif   /* CSTORE_SERIALIZATION_H */ \n"
        },
        {
          "name": "cstore_reader.c",
          "type": "blob",
          "size": 42.5009765625,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_reader.c\n *\n * This file contains function definitions for reading cstore files. This\n * includes the logic for reading file level metadata, reading row stripes,\n * and skipping unrelated row blocks and columns.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n *\n *-------------------------------------------------------------------------\n */\n\n\n#include \"postgres.h\"\n#include \"cstore_fdw.h\"\n#include \"cstore_metadata_serialization.h\"\n#include \"cstore_version_compat.h\"\n\n#include \"access/nbtree.h\"\n#include \"access/skey.h\"\n#include \"commands/defrem.h\"\n#include \"nodes/makefuncs.h\"\n#if PG_VERSION_NUM >= 120000\n#include \"nodes/pathnodes.h\"\n#include \"nodes/nodeFuncs.h\"\n#include \"optimizer/optimizer.h\"\n#else\n#include \"optimizer/clauses.h\"\n#include \"optimizer/predtest.h\"\n#include \"optimizer/var.h\"\n#endif\n#include \"optimizer/restrictinfo.h\"\n#include \"port.h\"\n#include \"storage/fd.h\"\n#include \"utils/memutils.h\"\n#include \"utils/lsyscache.h\"\n#include \"utils/rel.h\"\n\n\n/* static function declarations */\nstatic StripeBuffers * LoadFilteredStripeBuffers(FILE *tableFile,\n\t\t\t\t\t\t\t\t\t\t\t\t StripeMetadata *stripeMetadata,\n\t\t\t\t\t\t\t\t\t\t\t\t TupleDesc tupleDescriptor,\n\t\t\t\t\t\t\t\t\t\t\t\t List *projectedColumnList,\n\t\t\t\t\t\t\t\t\t\t\t\t List *whereClauseList);\nstatic void ReadStripeNextRow(StripeBuffers *stripeBuffers, List *projectedColumnList,\n\t\t\t\t\t\t\t  uint64 blockIndex, uint64 blockRowIndex,\n\t\t\t\t\t\t\t  ColumnBlockData **blockDataArray,\n\t\t\t\t\t\t\t  Datum *columnValues, bool *columnNulls);\nstatic ColumnBuffers * LoadColumnBuffers(FILE *tableFile,\n\t\t\t\t\t\t\t\t\t\t ColumnBlockSkipNode *blockSkipNodeArray,\n\t\t\t\t\t\t\t\t\t\t uint32 blockCount, uint64 existsFileOffset,\n\t\t\t\t\t\t\t\t\t\t uint64 valueFileOffset,\n\t\t\t\t\t\t\t\t\t\t Form_pg_attribute attributeForm);\nstatic StripeFooter * LoadStripeFooter(FILE *tableFile, StripeMetadata *stripeMetadata,\n\t\t\t\t\t\t\t\t\t   uint32 columnCount);\nstatic StripeSkipList * LoadStripeSkipList(FILE *tableFile,\n\t\t\t\t\t\t\t\t\t\t   StripeMetadata *stripeMetadata,\n\t\t\t\t\t\t\t\t\t\t   StripeFooter *stripeFooter,\n\t\t\t\t\t\t\t\t\t\t   uint32 columnCount,\n\t\t\t\t\t\t\t\t\t\t   bool *projectedColumnMask,\n\t\t\t\t\t\t\t\t\t\t   TupleDesc tupleDescriptor);\nstatic bool * SelectedBlockMask(StripeSkipList *stripeSkipList,\n\t\t\t\t\t\t\t\tList *projectedColumnList, List *whereClauseList);\nstatic List * BuildRestrictInfoList(List *whereClauseList);\nstatic Node * BuildBaseConstraint(Var *variable);\nstatic OpExpr * MakeOpExpression(Var *variable, int16 strategyNumber);\nstatic Oid GetOperatorByType(Oid typeId, Oid accessMethodId, int16 strategyNumber);\nstatic void UpdateConstraint(Node *baseConstraint, Datum minValue, Datum maxValue);\nstatic StripeSkipList * SelectedBlockSkipList(StripeSkipList *stripeSkipList,\n\t\t \t \t \t \t \t \t \t \t \t  bool *projectedColumnMask,\n\t\t\t\t\t\t\t\t\t\t\t  bool *selectedBlockMask);\nstatic uint32 StripeSkipListRowCount(StripeSkipList *stripeSkipList);\nstatic bool * ProjectedColumnMask(uint32 columnCount, List *projectedColumnList);\nstatic void DeserializeBoolArray(StringInfo boolArrayBuffer, bool *boolArray,\n\t\t\t\t\t\t\t\t uint32 boolArrayLength);\nstatic void DeserializeDatumArray(StringInfo datumBuffer, bool *existsArray,\n\t\t\t\t\t\t\t\t  uint32 datumCount, bool datumTypeByValue,\n\t\t\t\t\t\t\t\t  int datumTypeLength, char datumTypeAlign,\n\t\t\t\t\t\t\t\t  Datum *datumArray);\nstatic void DeserializeBlockData(StripeBuffers *stripeBuffers, uint64 blockIndex,\n\t\t\t\t\t\t\t\t uint32 rowCount, ColumnBlockData **blockDataArray,\n\t\t\t\t\t\t\t\t TupleDesc tupleDescriptor);\nstatic Datum ColumnDefaultValue(TupleConstr *tupleConstraints,\n\t\t\t\t\t\t\t\tForm_pg_attribute attributeForm);\nstatic int64 FILESize(FILE *file);\nstatic StringInfo ReadFromFile(FILE *file, uint64 offset, uint32 size);\nstatic void ResetUncompressedBlockData(ColumnBlockData **blockDataArray,\n\t\t\t\t\t\t\t\t\t   uint32 columnCount);\nstatic uint64 StripeRowCount(FILE *tableFile, StripeMetadata *stripeMetadata);\n\n\n/*\n * CStoreBeginRead initializes a cstore read operation. This function returns a\n * read handle that's used during reading rows and finishing the read operation.\n */\nTableReadState *\nCStoreBeginRead(const char *filename, TupleDesc tupleDescriptor,\n\t\t\t\tList *projectedColumnList, List *whereClauseList)\n{\n\tTableReadState *readState = NULL;\n\tTableFooter *tableFooter = NULL;\n\tFILE *tableFile = NULL;\n\tMemoryContext stripeReadContext = NULL;\n\tuint32 columnCount = 0;\n\tbool *projectedColumnMask = NULL;\n\tColumnBlockData **blockDataArray  = NULL;\n\n\tStringInfo tableFooterFilename = makeStringInfo();\n\tappendStringInfo(tableFooterFilename, \"%s%s\", filename, CSTORE_FOOTER_FILE_SUFFIX);\n\n\ttableFooter = CStoreReadFooter(tableFooterFilename);\n\n\tpfree(tableFooterFilename->data);\n\tpfree(tableFooterFilename);\n\n\ttableFile = AllocateFile(filename, PG_BINARY_R);\n\tif (tableFile == NULL)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for reading: %m\",\n\t\t\t\t\t\t\t   filename)));\n\t}\n\n\t/*\n\t * We allocate all stripe specific data in the stripeReadContext, and reset\n\t * this memory context before loading a new stripe. This is to avoid memory\n\t * leaks.\n\t */\n\tstripeReadContext = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t\t  \"Stripe Read Memory Context\",\n\t\t\t\t\t\t\t\t\t\t\t  ALLOCSET_DEFAULT_SIZES);\n\n\tcolumnCount = tupleDescriptor->natts;\n\tprojectedColumnMask = ProjectedColumnMask(columnCount, projectedColumnList);\n\tblockDataArray = CreateEmptyBlockDataArray(columnCount, projectedColumnMask,\n\t\t\t\t\t\t\t\t\t\t \t   tableFooter->blockRowCount);\n\n\treadState = palloc0(sizeof(TableReadState));\n\treadState->tableFile = tableFile;\n\treadState->tableFooter = tableFooter;\n\treadState->projectedColumnList = projectedColumnList;\n\treadState->whereClauseList = whereClauseList;\n\treadState->stripeBuffers = NULL;\n\treadState->readStripeCount = 0;\n\treadState->stripeReadRowCount = 0;\n\treadState->tupleDescriptor = tupleDescriptor;\n\treadState->stripeReadContext = stripeReadContext;\n\treadState->blockDataArray = blockDataArray;\n\treadState->deserializedBlockIndex = -1;\n\n\treturn readState;\n}\n\n\n/*\n * CStoreReadFooter reads the cstore file footer from the given file. First, the\n * function reads the last byte of the file as the postscript size. Then, the\n * function reads the postscript. Last, the function reads and deserializes the\n * footer.\n */\nTableFooter *\nCStoreReadFooter(StringInfo tableFooterFilename)\n{\n\tTableFooter *tableFooter = NULL;\n\tFILE *tableFooterFile = NULL;\n\tuint64 footerOffset = 0;\n\tuint64 footerLength = 0;\n\tStringInfo postscriptBuffer = NULL;\n\tStringInfo postscriptSizeBuffer = NULL;\n\tuint64 postscriptSizeOffset = 0;\n\tuint8 postscriptSize = 0;\n\tuint64 footerFileSize = 0;\n\tuint64 postscriptOffset = 0;\n\tStringInfo footerBuffer = NULL;\n\tint freeResult = 0;\n\n\ttableFooterFile = AllocateFile(tableFooterFilename->data, PG_BINARY_R);\n\tif (tableFooterFile == NULL)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for reading: %m\",\n\t\t\t\t\t\t\t   tableFooterFilename->data),\n\t\t\t\t\t\terrhint(\"Try copying in data to the table.\")));\n\t}\n\n\tfooterFileSize = FILESize(tableFooterFile);\n\tif (footerFileSize < CSTORE_POSTSCRIPT_SIZE_LENGTH)\n\t{\n\t\tereport(ERROR, (errmsg(\"invalid cstore file\")));\n\t}\n\n\tpostscriptSizeOffset = footerFileSize - CSTORE_POSTSCRIPT_SIZE_LENGTH;\n\tpostscriptSizeBuffer = ReadFromFile(tableFooterFile, postscriptSizeOffset,\n\t\t\t\t\t\t\t\t\t\tCSTORE_POSTSCRIPT_SIZE_LENGTH);\n\tmemcpy(&postscriptSize, postscriptSizeBuffer->data, CSTORE_POSTSCRIPT_SIZE_LENGTH);\n\tif (postscriptSize + CSTORE_POSTSCRIPT_SIZE_LENGTH > footerFileSize)\n\t{\n\t\tereport(ERROR, (errmsg(\"invalid postscript size\")));\n\t}\n\n\tpostscriptOffset = footerFileSize - (CSTORE_POSTSCRIPT_SIZE_LENGTH + postscriptSize);\n\tpostscriptBuffer = ReadFromFile(tableFooterFile, postscriptOffset, postscriptSize);\n\n\tDeserializePostScript(postscriptBuffer, &footerLength);\n\tif (footerLength + postscriptSize + CSTORE_POSTSCRIPT_SIZE_LENGTH > footerFileSize)\n\t{\n\t\tereport(ERROR, (errmsg(\"invalid footer size\")));\n\t}\n\n\tfooterOffset = postscriptOffset - footerLength;\n\tfooterBuffer = ReadFromFile(tableFooterFile, footerOffset, footerLength);\n\ttableFooter = DeserializeTableFooter(footerBuffer);\n\n\tfreeResult = FreeFile(tableFooterFile);\n\tif (freeResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not close file: %m\")));\n\t}\n\n\treturn tableFooter;\n}\n\n\n/*\n * CStoreReadNextRow tries to read a row from the cstore file. On success, it sets\n * column values and nulls, and returns true. If there are no more rows to read,\n * the function returns false.\n */\nbool\nCStoreReadNextRow(TableReadState *readState, Datum *columnValues, bool *columnNulls)\n{\n\tuint32 blockIndex = 0;\n\tuint32 blockRowIndex = 0;\n\tTableFooter *tableFooter = readState->tableFooter;\n\tMemoryContext oldContext = NULL;\n\n\t/*\n\t * If no stripes are loaded, load the next non-empty stripe. Note that when\n\t * loading stripes, we skip over blocks whose contents can be filtered with\n\t * the query's restriction qualifiers. So, even when a stripe is physically\n\t * not empty, we may end up loading it as an empty stripe.\n\t */\n\twhile (readState->stripeBuffers == NULL)\n\t{\n\t\tStripeBuffers *stripeBuffers = NULL;\n\t\tStripeMetadata *stripeMetadata = NULL;\n\t\tList *stripeMetadataList = tableFooter->stripeMetadataList;\n\t\tuint32 stripeCount = list_length(stripeMetadataList);\n\n\t\t/* if we have read all stripes, return false */\n\t\tif (readState->readStripeCount == stripeCount)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\n\t\toldContext = MemoryContextSwitchTo(readState->stripeReadContext);\n\t\tMemoryContextReset(readState->stripeReadContext);\n\n\t\tstripeMetadata = list_nth(stripeMetadataList, readState->readStripeCount);\n\t\tstripeBuffers = LoadFilteredStripeBuffers(readState->tableFile, stripeMetadata,\n\t\t\t\t\t\t\t\t\t\t\t\t  readState->tupleDescriptor,\n\t\t\t\t\t\t\t\t\t\t\t\t  readState->projectedColumnList,\n\t\t\t\t\t\t\t\t\t\t\t\t  readState->whereClauseList);\n\t\treadState->readStripeCount++;\n\n\t\tMemoryContextSwitchTo(oldContext);\n\n\t\tif (stripeBuffers->rowCount != 0)\n\t\t{\n\t\t\treadState->stripeBuffers = stripeBuffers;\n\t\t\treadState->stripeReadRowCount = 0;\n\t\t\treadState->deserializedBlockIndex = -1;\n\t\t\tResetUncompressedBlockData(readState->blockDataArray,\n\t\t\t\t\t\t\t\t\t   stripeBuffers->columnCount);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tblockIndex = readState->stripeReadRowCount / tableFooter->blockRowCount;\n\tblockRowIndex = readState->stripeReadRowCount % tableFooter->blockRowCount;\n\n\tif (blockIndex != readState->deserializedBlockIndex)\n\t{\n\t\tuint32 lastBlockIndex = 0;\n\t\tuint32 blockRowCount = 0;\n\t\tuint32 stripeRowCount = 0;\n\n\t\tstripeRowCount = readState->stripeBuffers->rowCount;\n\t\tlastBlockIndex = stripeRowCount / tableFooter->blockRowCount;\n\t\tif (blockIndex == lastBlockIndex)\n\t\t{\n\t\t\tblockRowCount = stripeRowCount % tableFooter->blockRowCount;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tblockRowCount = tableFooter->blockRowCount;\n\t\t}\n\n\t\toldContext = MemoryContextSwitchTo(readState->stripeReadContext);\n\n\t\tDeserializeBlockData(readState->stripeBuffers, blockIndex,\n\t\t\t\t\t\t\t blockRowCount, readState->blockDataArray,\n\t\t\t\t\t\t\t readState->tupleDescriptor);\n\n\t\tMemoryContextSwitchTo(oldContext);\n\n\t\treadState->deserializedBlockIndex = blockIndex;\n\t}\n\n\tReadStripeNextRow(readState->stripeBuffers, readState->projectedColumnList,\n\t\t\t\t\t  blockIndex, blockRowIndex, readState->blockDataArray,\n\t\t\t\t\t  columnValues, columnNulls);\n\n\t/*\n\t * If we finished reading the current stripe, set stripe data to NULL. That\n\t * way, we will load a new stripe the next time this function gets called.\n\t */\n\treadState->stripeReadRowCount++;\n\tif (readState->stripeReadRowCount == readState->stripeBuffers->rowCount)\n\t{\n\t\treadState->stripeBuffers = NULL;\n\t}\n\n\treturn true;\n}\n\n\n/* Finishes a cstore read operation. */\nvoid\nCStoreEndRead(TableReadState *readState)\n{\n\tint columnCount = readState->tupleDescriptor->natts;\n\n\tMemoryContextDelete(readState->stripeReadContext);\n\tFreeFile(readState->tableFile);\n\tlist_free_deep(readState->tableFooter->stripeMetadataList);\n\tFreeColumnBlockDataArray(readState->blockDataArray, columnCount);\n\tpfree(readState->tableFooter);\n\tpfree(readState);\n}\n\n\n/*\n * CreateEmptyBlockDataArray creates data buffers to keep deserialized exist and\n * value arrays for requested columns in columnMask.\n */\nColumnBlockData **\nCreateEmptyBlockDataArray(uint32 columnCount, bool *columnMask, uint32 blockRowCount)\n{\n\tuint32 columnIndex = 0;\n\tColumnBlockData **blockDataArray = palloc0(columnCount * sizeof(ColumnBlockData*));\n\n\t/* allocate block memory for deserialized data */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tif (columnMask[columnIndex])\n\t\t{\n\t\t\tColumnBlockData *blockData = palloc0(sizeof(ColumnBlockData));\n\n\t\t\tblockData->existsArray = palloc0(blockRowCount * sizeof(bool));\n\t\t\tblockData->valueArray = palloc0(blockRowCount * sizeof(Datum));\n\t\t\tblockData->valueBuffer = NULL;\n\t\t\tblockDataArray[columnIndex] = blockData;\n\t\t}\n\t}\n\n\treturn blockDataArray;\n}\n\n\n/*\n * FreeColumnBlockDataArray deallocates data buffers to keep deserialized exist and\n * value arrays for requested columns in columnMask.\n * ColumnBlockData->serializedValueBuffer lives in memory read/write context\n * so it is deallocated automatically when the context is deleted.\n */\nvoid\nFreeColumnBlockDataArray(ColumnBlockData **blockDataArray, uint32 columnCount)\n{\n\tuint32 columnIndex = 0;\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\tif (blockData != NULL)\n\t\t{\n\t\t\tpfree(blockData->existsArray);\n\t\t\tpfree(blockData->valueArray);\n\t\t\tpfree(blockData);\n\t\t}\n\t}\n\n\tpfree(blockDataArray);\n}\n\n\n/* CStoreTableRowCount returns the exact row count of a table using skiplists */\nuint64\nCStoreTableRowCount(const char *filename)\n{\n\tTableFooter *tableFooter = NULL;\n\tFILE *tableFile;\n\tListCell *stripeMetadataCell = NULL;\n\tuint64 totalRowCount = 0;\n\n\tStringInfo tableFooterFilename = makeStringInfo();\n\n\tappendStringInfo(tableFooterFilename, \"%s%s\", filename, CSTORE_FOOTER_FILE_SUFFIX);\n\n\ttableFooter = CStoreReadFooter(tableFooterFilename);\n\n\tpfree(tableFooterFilename->data);\n\tpfree(tableFooterFilename);\n\n\ttableFile = AllocateFile(filename, PG_BINARY_R);\n\tif (tableFile == NULL)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for reading: %m\", filename)));\n\t}\n\n\tforeach(stripeMetadataCell, tableFooter->stripeMetadataList)\n\t{\n\t\tStripeMetadata *stripeMetadata = (StripeMetadata *) lfirst(stripeMetadataCell);\n\t\ttotalRowCount += StripeRowCount(tableFile, stripeMetadata);\n\t}\n\n\tFreeFile(tableFile);\n\n\treturn totalRowCount;\n}\n\n\n/*\n * StripeRowCount reads serialized stripe footer, the first column's\n * skip list, and returns number of rows for given stripe.\n */\nstatic uint64\nStripeRowCount(FILE *tableFile, StripeMetadata *stripeMetadata)\n{\n\tuint64 rowCount = 0;\n\tStripeFooter *stripeFooter = NULL;\n\tStringInfo footerBuffer = NULL;\n\tStringInfo firstColumnSkipListBuffer = NULL;\n\tuint64 footerOffset = 0;\n\n\tfooterOffset += stripeMetadata->fileOffset;\n\tfooterOffset += stripeMetadata->skipListLength;\n\tfooterOffset += stripeMetadata->dataLength;\n\n\tfooterBuffer = ReadFromFile(tableFile, footerOffset, stripeMetadata->footerLength);\n\tstripeFooter = DeserializeStripeFooter(footerBuffer);\n\n\tfirstColumnSkipListBuffer = ReadFromFile(tableFile, stripeMetadata->fileOffset,\n\t                                         stripeFooter->skipListSizeArray[0]);\n\trowCount =  DeserializeRowCount(firstColumnSkipListBuffer);\n\n\treturn rowCount;\n}\n\n\n/*\n * LoadFilteredStripeBuffers reads serialized stripe data from the given file.\n * The function skips over blocks whose rows are refuted by restriction qualifiers,\n * and only loads columns that are projected in the query.\n */\nstatic StripeBuffers *\nLoadFilteredStripeBuffers(FILE *tableFile, StripeMetadata *stripeMetadata,\n\t\t\t\t\t\t  TupleDesc tupleDescriptor, List *projectedColumnList,\n\t\t\t\t\t\t  List *whereClauseList)\n{\n\tStripeBuffers *stripeBuffers = NULL;\n\tColumnBuffers **columnBuffersArray = NULL;\n\tuint64 currentColumnFileOffset = 0;\n\tuint32 columnIndex = 0;\n\tuint32 columnCount = tupleDescriptor->natts;\n\n\tStripeFooter *stripeFooter = LoadStripeFooter(tableFile, stripeMetadata,\n\t\t\t\t\t\t\t\t\t\t\t\t  columnCount);\n\tbool *projectedColumnMask = ProjectedColumnMask(columnCount, projectedColumnList);\n\n\tStripeSkipList *stripeSkipList = LoadStripeSkipList(tableFile, stripeMetadata,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tstripeFooter, columnCount,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tprojectedColumnMask,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\ttupleDescriptor);\n\n\tbool *selectedBlockMask = SelectedBlockMask(stripeSkipList, projectedColumnList,\n\t\t\t\t\t\t\t\t\t\t\t\twhereClauseList);\n\n\tStripeSkipList *selectedBlockSkipList =\n\t\tSelectedBlockSkipList(stripeSkipList, projectedColumnMask,\n\t\t\t\t\t\t\t  selectedBlockMask);\n\n\t/* load column data for projected columns */\n\tcolumnBuffersArray = palloc0(columnCount * sizeof(ColumnBuffers *));\n\tcurrentColumnFileOffset = stripeMetadata->fileOffset + stripeMetadata->skipListLength;\n\n\tfor (columnIndex = 0; columnIndex < stripeFooter->columnCount; columnIndex++)\n\t{\n\t\tuint64 existsSize = stripeFooter->existsSizeArray[columnIndex];\n\t\tuint64 valueSize = stripeFooter->valueSizeArray[columnIndex];\n\t\tuint64 existsFileOffset = currentColumnFileOffset;\n\t\tuint64 valueFileOffset = currentColumnFileOffset + existsSize;\n\n\t\tif (projectedColumnMask[columnIndex])\n\t\t{\n\t\t\tColumnBlockSkipNode *blockSkipNode =\n\t\t\t\tselectedBlockSkipList->blockSkipNodeArray[columnIndex];\n\t\t\tForm_pg_attribute attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\t\t\tuint32 blockCount = selectedBlockSkipList->blockCount;\n\n\t\t\tColumnBuffers *columnBuffers = LoadColumnBuffers(tableFile, blockSkipNode,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t blockCount,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t existsFileOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t valueFileOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t attributeForm);\n\n\t\t\tcolumnBuffersArray[columnIndex] = columnBuffers;\n\t\t}\n\n\t\tcurrentColumnFileOffset += existsSize;\n\t\tcurrentColumnFileOffset += valueSize;\n\t}\n\n\tstripeBuffers = palloc0(sizeof(StripeBuffers));\n\tstripeBuffers->columnCount = columnCount;\n\tstripeBuffers->rowCount = StripeSkipListRowCount(selectedBlockSkipList);\n\tstripeBuffers->columnBuffersArray = columnBuffersArray;\n\n\treturn stripeBuffers;\n}\n\n\n/*\n * ReadStripeNextRow reads the next row from the given stripe, finds the projected\n * column values within this row, and accordingly sets the column values and nulls.\n * Note that this function sets the values for all non-projected columns to null.\n */\nstatic void\nReadStripeNextRow(StripeBuffers *stripeBuffers, List *projectedColumnList,\n\t\t\t\t  uint64 blockIndex, uint64 blockRowIndex,\n\t\t\t\t  ColumnBlockData **blockDataArray, Datum *columnValues,\n\t\t\t\t  bool *columnNulls)\n{\n\tListCell *projectedColumnCell = NULL;\n\n\t/* set all columns to null by default */\n\tmemset(columnNulls, 1, stripeBuffers->columnCount * sizeof(bool));\n\n\tforeach(projectedColumnCell, projectedColumnList)\n\t{\n\t\tVar *projectedColumn = lfirst(projectedColumnCell);\n\t\tuint32 projectedColumnIndex = projectedColumn->varattno - 1;\n\t\tColumnBlockData *blockData = blockDataArray[projectedColumnIndex];\n\n\t\tif (blockData->existsArray[blockRowIndex])\n\t\t{\n\t\t\tcolumnValues[projectedColumnIndex] = blockData->valueArray[blockRowIndex];\n\t\t\tcolumnNulls[projectedColumnIndex] = false;\n\t\t}\n\t}\n}\n\n\n/*\n * LoadColumnBuffers reads serialized column data from the given file. These\n * column data are laid out as sequential blocks in the file; and block positions\n * and lengths are retrieved from the column block skip node array.\n */\nstatic ColumnBuffers *\nLoadColumnBuffers(FILE *tableFile, ColumnBlockSkipNode *blockSkipNodeArray,\n\t\t\t\t  uint32 blockCount, uint64 existsFileOffset, uint64 valueFileOffset,\n\t\t\t\t  Form_pg_attribute attributeForm)\n{\n\tColumnBuffers *columnBuffers = NULL;\n\tuint32 blockIndex = 0;\n\tColumnBlockBuffers **blockBuffersArray =\n\t\t\tpalloc0(blockCount * sizeof(ColumnBlockBuffers *));\n\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tblockBuffersArray[blockIndex] = palloc0(sizeof(ColumnBlockBuffers));\n\t}\n\n\t/*\n\t * We first read the \"exists\" blocks. We don't read \"values\" array here,\n\t * because \"exists\" blocks are stored sequentially on disk, and we want to\n\t * minimize disk seeks.\n\t */\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tColumnBlockSkipNode *blockSkipNode = &blockSkipNodeArray[blockIndex];\n\t\tuint64 existsOffset = existsFileOffset + blockSkipNode->existsBlockOffset;\n\t\tStringInfo rawExistsBuffer = ReadFromFile(tableFile, existsOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t  blockSkipNode->existsLength);\n\n\t\tblockBuffersArray[blockIndex]->existsBuffer = rawExistsBuffer;\n\t}\n\n\t/* then read \"values\" blocks, which are also stored sequentially on disk */\n\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t{\n\t\tColumnBlockSkipNode *blockSkipNode = &blockSkipNodeArray[blockIndex];\n\t\tCompressionType compressionType = blockSkipNode->valueCompressionType;\n\t\tuint64 valueOffset = valueFileOffset + blockSkipNode->valueBlockOffset;\n\t\tStringInfo rawValueBuffer = ReadFromFile(tableFile, valueOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t blockSkipNode->valueLength);\n\n\t\tblockBuffersArray[blockIndex]->valueBuffer = rawValueBuffer;\n\t\tblockBuffersArray[blockIndex]->valueCompressionType = compressionType;\n\t}\n\n\tcolumnBuffers = palloc0(sizeof(ColumnBuffers));\n\tcolumnBuffers->blockBuffersArray = blockBuffersArray;\n\n\treturn columnBuffers;\n}\n\n\n/* Reads and returns the given stripe's footer. */\nstatic StripeFooter *\nLoadStripeFooter(FILE *tableFile, StripeMetadata *stripeMetadata,\n\t\t\t\t uint32 columnCount)\n{\n\tStripeFooter *stripeFooter = NULL;\n\tStringInfo footerBuffer = NULL;\n\tuint64 footerOffset = 0;\n\n\tfooterOffset += stripeMetadata->fileOffset;\n\tfooterOffset += stripeMetadata->skipListLength;\n\tfooterOffset += stripeMetadata->dataLength;\n\n\tfooterBuffer = ReadFromFile(tableFile, footerOffset, stripeMetadata->footerLength);\n\tstripeFooter = DeserializeStripeFooter(footerBuffer);\n\tif (stripeFooter->columnCount > columnCount)\n\t{\n\t\tereport(ERROR, (errmsg(\"stripe footer column count and table column count \"\n\t\t\t\t\t\t\t   \"don't match\")));\n\t}\n\n\treturn stripeFooter;\n}\n\n\n/* Reads the skip list for the given stripe. */\nstatic StripeSkipList *\nLoadStripeSkipList(FILE *tableFile, StripeMetadata *stripeMetadata,\n\t\t\t\t   StripeFooter *stripeFooter, uint32 columnCount,\n\t\t\t\t   bool *projectedColumnMask,\n\t\t\t\t   TupleDesc tupleDescriptor)\n{\n\tStripeSkipList *stripeSkipList = NULL;\n\tColumnBlockSkipNode **blockSkipNodeArray = NULL;\n\tStringInfo firstColumnSkipListBuffer = NULL;\n\tuint64 currentColumnSkipListFileOffset = 0;\n\tuint32 columnIndex = 0;\n\tuint32 stripeBlockCount = 0;\n\tuint32 stripeColumnCount = stripeFooter->columnCount;\n\n\t/* deserialize block count */\n\tfirstColumnSkipListBuffer = ReadFromFile(tableFile, stripeMetadata->fileOffset,\n\t\t\t\t\t\t\t\t\t\t\t stripeFooter->skipListSizeArray[0]);\n\tstripeBlockCount = DeserializeBlockCount(firstColumnSkipListBuffer);\n\n\t/* deserialize column skip lists */\n\tblockSkipNodeArray = palloc0(columnCount * sizeof(ColumnBlockSkipNode *));\n\tcurrentColumnSkipListFileOffset = stripeMetadata->fileOffset;\n\n\tfor (columnIndex = 0; columnIndex < stripeColumnCount; columnIndex++)\n\t{\n\t\tuint64 columnSkipListSize = stripeFooter->skipListSizeArray[columnIndex];\n\t\tbool firstColumn = columnIndex == 0;\n\n\t\t/*\n\t\t * Only selected columns' column skip lists are read. However, the first\n\t\t * column's skip list is read regardless of being selected. It is used by\n\t\t * StripeSkipListRowCount later.\n\t\t */\n\t\tif (projectedColumnMask[columnIndex] || firstColumn)\n\t\t{\n\t\t\tForm_pg_attribute attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\n\t\t\tStringInfo columnSkipListBuffer =\n\t\t\t\tReadFromFile(tableFile, currentColumnSkipListFileOffset,\n\t\t\t\t\t\t\t columnSkipListSize);\n\t\t\tColumnBlockSkipNode *columnSkipList =\n\t\t\t\tDeserializeColumnSkipList(columnSkipListBuffer, attributeForm->attbyval,\n\t\t\t\t\t\t\t\t\t\t  attributeForm->attlen, stripeBlockCount);\n\t\t\tblockSkipNodeArray[columnIndex] = columnSkipList;\n\t\t}\n\n\t\tcurrentColumnSkipListFileOffset += columnSkipListSize;\n\t}\n\n\t/* table contains additional columns added after this stripe is created */\n\tfor (columnIndex = stripeColumnCount; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockSkipNode *columnSkipList = NULL;\n\t\tuint32 blockIndex = 0;\n\t\tbool firstColumn = columnIndex == 0;\n\n\t\t/* no need to create ColumnBlockSkipList if the column is not selected */\n\t\tif (!projectedColumnMask[columnIndex] && !firstColumn)\n\t\t{\n\t\t\tblockSkipNodeArray[columnIndex] = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* create empty ColumnBlockSkipNode for missing columns*/\n\t\tcolumnSkipList = palloc0(stripeBlockCount * sizeof(ColumnBlockSkipNode));\n\n\t\tfor (blockIndex = 0; blockIndex < stripeBlockCount; blockIndex++)\n\t\t{\n\t\t\tcolumnSkipList[blockIndex].rowCount = 0;\n\t\t\tcolumnSkipList[blockIndex].hasMinMax = false;\n\t\t\tcolumnSkipList[blockIndex].minimumValue = 0;\n\t\t\tcolumnSkipList[blockIndex].maximumValue = 0;\n\t\t\tcolumnSkipList[blockIndex].existsBlockOffset = 0;\n\t\t\tcolumnSkipList[blockIndex].valueBlockOffset = 0;\n\t\t\tcolumnSkipList[blockIndex].existsLength = 0;\n\t\t\tcolumnSkipList[blockIndex].valueLength = 0;\n\t\t\tcolumnSkipList[blockIndex].valueCompressionType = COMPRESSION_NONE;\n\t\t}\n\t\tblockSkipNodeArray[columnIndex] = columnSkipList;\n\t}\n\n\tstripeSkipList = palloc0(sizeof(StripeSkipList));\n\tstripeSkipList->blockSkipNodeArray = blockSkipNodeArray;\n\tstripeSkipList->columnCount = columnCount;\n\tstripeSkipList->blockCount = stripeBlockCount;\n\n\treturn stripeSkipList;\n}\n\n\n/*\n * SelectedBlockMask walks over each column's blocks and checks if a block can\n * be filtered without reading its data. The filtering happens when all rows in\n * the block can be refuted by the given qualifier conditions.\n */\nstatic bool *\nSelectedBlockMask(StripeSkipList *stripeSkipList, List *projectedColumnList,\n\t\t\t\t  List *whereClauseList)\n{\n\tbool *selectedBlockMask = NULL;\n\tListCell *columnCell = NULL;\n\tuint32 blockIndex = 0;\n\tList *restrictInfoList = BuildRestrictInfoList(whereClauseList);\n\n\tselectedBlockMask = palloc0(stripeSkipList->blockCount * sizeof(bool));\n\tmemset(selectedBlockMask, true, stripeSkipList->blockCount * sizeof(bool));\n\n\tforeach(columnCell, projectedColumnList)\n\t{\n\t\tVar *column = lfirst(columnCell);\n\t\tuint32 columnIndex = column->varattno - 1;\n\t\tFmgrInfo *comparisonFunction = NULL;\n\t\tNode *baseConstraint = NULL;\n\n\t\t/* if this column's data type doesn't have a comparator, skip it */\n\t\tcomparisonFunction = GetFunctionInfoOrNull(column->vartype, BTREE_AM_OID,\n\t\t\t\t\t\t\t\t\t\t\t\t   BTORDER_PROC);\n\t\tif (comparisonFunction == NULL)\n\t\t{\n\t\t\tcontinue;\n\t\t}\n\n\t\tbaseConstraint = BuildBaseConstraint(column);\n\t\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t\t{\n\t\t\tbool predicateRefuted = false;\n\t\t\tList *constraintList = NIL;\n\t\t\tColumnBlockSkipNode *blockSkipNodeArray =\n\t\t\t\tstripeSkipList->blockSkipNodeArray[columnIndex];\n\t\t\tColumnBlockSkipNode *blockSkipNode = &blockSkipNodeArray[blockIndex];\n\n\t\t\t/*\n\t\t\t * A column block with comparable data type can miss min/max values\n\t\t\t * if all values in the block are NULL.\n\t\t\t */\n\t\t\tif (!blockSkipNode->hasMinMax)\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tUpdateConstraint(baseConstraint, blockSkipNode->minimumValue,\n\t\t\t\t\t\t\t blockSkipNode->maximumValue);\n\n\t\t\tconstraintList = list_make1(baseConstraint);\n#if (PG_VERSION_NUM >= 100000)\n\t\t\tpredicateRefuted = predicate_refuted_by(constraintList, restrictInfoList, false);\n#else\n\t\t\tpredicateRefuted = predicate_refuted_by(constraintList, restrictInfoList);\n#endif\n\t\t\tif (predicateRefuted)\n\t\t\t{\n\t\t\t\tselectedBlockMask[blockIndex] = false;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn selectedBlockMask;\n}\n\n\n/*\n * GetFunctionInfoOrNull first resolves the operator for the given data type,\n * access method, and support procedure. The function then uses the resolved\n * operator's identifier to fill in a function manager object, and returns\n * this object. This function is based on a similar function from CitusDB's code.\n */\nFmgrInfo *\nGetFunctionInfoOrNull(Oid typeId, Oid accessMethodId, int16 procedureId)\n{\n\tFmgrInfo *functionInfo = NULL;\n\tOid operatorClassId = InvalidOid;\n\tOid operatorFamilyId = InvalidOid;\n\tOid operatorId = InvalidOid;\n\n\t/* get default operator class from pg_opclass for datum type */\n\toperatorClassId = GetDefaultOpClass(typeId, accessMethodId);\n\tif (operatorClassId == InvalidOid)\n\t{\n\t\treturn NULL;\n\t}\n\n\toperatorFamilyId = get_opclass_family(operatorClassId);\n\tif (operatorFamilyId == InvalidOid)\n\t{\n\t\treturn NULL;\n\t}\n\n\toperatorId = get_opfamily_proc(operatorFamilyId, typeId, typeId, procedureId);\n\tif (operatorId != InvalidOid)\n\t{\n\t\tfunctionInfo = (FmgrInfo *) palloc0(sizeof(FmgrInfo));\n\n\t\t/* fill in the FmgrInfo struct using the operatorId */\n\t\tfmgr_info(operatorId, functionInfo);\n\t}\n\n\treturn functionInfo;\n}\n\n\n/*\n * BuildRestrictInfoList builds restrict info list using the selection criteria,\n * and then return this list. The function is copied from CitusDB's shard pruning\n * logic.\n */\nstatic List *\nBuildRestrictInfoList(List *whereClauseList)\n{\n\tList *restrictInfoList = NIL;\n\n\tListCell *qualCell = NULL;\n\tforeach(qualCell, whereClauseList)\n\t{\n\t\tRestrictInfo *restrictInfo = NULL;\n\t\tNode *qualNode = (Node *) lfirst(qualCell);\n\n\t\trestrictInfo = make_simple_restrictinfo((Expr *) qualNode);\n\t\trestrictInfoList = lappend(restrictInfoList, restrictInfo);\n\t}\n\n\treturn restrictInfoList;\n}\n\n\n/*\n * BuildBaseConstraint builds and returns a base constraint. This constraint\n * implements an expression in the form of (var <= max && var >= min), where\n * min and max values represent a block's min and max values. These block\n * values are filled in after the constraint is built. This function is based\n * on a similar function from CitusDB's shard pruning logic.\n */\nstatic Node *\nBuildBaseConstraint(Var *variable)\n{\n\tNode *baseConstraint = NULL;\n\tOpExpr *lessThanExpr = NULL;\n\tOpExpr *greaterThanExpr = NULL;\n\n\tlessThanExpr = MakeOpExpression(variable, BTLessEqualStrategyNumber);\n\tgreaterThanExpr = MakeOpExpression(variable, BTGreaterEqualStrategyNumber);\n\n\tbaseConstraint = make_and_qual((Node *) lessThanExpr, (Node *) greaterThanExpr);\n\n\treturn baseConstraint;\n}\n\n\n/*\n * MakeOpExpression builds an operator expression node. This operator expression\n * implements the operator clause as defined by the variable and the strategy\n * number. The function is copied from CitusDB's shard pruning logic.\n */\nstatic OpExpr *\nMakeOpExpression(Var *variable, int16 strategyNumber)\n{\n\tOid typeId = variable->vartype;\n\tOid typeModId = variable->vartypmod;\n\tOid collationId = variable->varcollid;\n\n\tOid accessMethodId = BTREE_AM_OID;\n\tOid operatorId = InvalidOid;\n\tConst  *constantValue = NULL;\n\tOpExpr *expression = NULL;\n\n\t/* Load the operator from system catalogs */\n\toperatorId = GetOperatorByType(typeId, accessMethodId, strategyNumber);\n\n\tconstantValue = makeNullConst(typeId, typeModId, collationId);\n\n\t/* Now make the expression with the given variable and a null constant */\n\texpression = (OpExpr *) make_opclause(operatorId,\n\t\t\t\t\t\t\t\t\t\t  InvalidOid, /* no result type yet */\n\t\t\t\t\t\t\t\t\t\t  false,\t  /* no return set */\n\t\t\t\t\t\t\t\t\t\t  (Expr *) variable,\n\t\t\t\t\t\t\t\t\t\t  (Expr *) constantValue,\n\t\t\t\t\t\t\t\t\t\t  InvalidOid, collationId);\n\n\t/* Set implementing function id and result type */\n\texpression->opfuncid = get_opcode(operatorId);\n\texpression->opresulttype = get_func_rettype(expression->opfuncid);\n\n\treturn expression;\n}\n\n\n/*\n * GetOperatorByType returns operator Oid for the given type, access method,\n * and strategy number. Note that this function incorrectly errors out when\n * the given type doesn't have its own operator but can use another compatible\n * type's default operator. The function is copied from CitusDB's shard pruning\n * logic.\n */\nstatic Oid\nGetOperatorByType(Oid typeId, Oid accessMethodId, int16 strategyNumber)\n{\n\t/* Get default operator class from pg_opclass */\n\tOid operatorClassId = GetDefaultOpClass(typeId, accessMethodId);\n\n\tOid operatorFamily = get_opclass_family(operatorClassId);\n\n\tOid operatorId = get_opfamily_member(operatorFamily, typeId, typeId, strategyNumber);\n\n\treturn operatorId;\n}\n\n\n/*\n * UpdateConstraint updates the base constraint with the given min/max values.\n * The function is copied from CitusDB's shard pruning logic.\n */\nstatic void\nUpdateConstraint(Node *baseConstraint, Datum minValue, Datum maxValue)\n{\n\tBoolExpr *andExpr = (BoolExpr *) baseConstraint;\n\tNode *lessThanExpr = (Node *) linitial(andExpr->args);\n\tNode *greaterThanExpr = (Node *) lsecond(andExpr->args);\n\n\tNode *minNode = get_rightop((Expr *) greaterThanExpr);\n\tNode *maxNode = get_rightop((Expr *) lessThanExpr);\n\tConst *minConstant = NULL;\n\tConst *maxConstant = NULL;\n\n\tAssert(IsA(minNode, Const));\n\tAssert(IsA(maxNode, Const));\n\n\tminConstant = (Const *) minNode;\n\tmaxConstant = (Const *) maxNode;\n\n\tminConstant->constvalue = minValue;\n\tmaxConstant->constvalue = maxValue;\n\n\tminConstant->constisnull = false;\n\tmaxConstant->constisnull = false;\n\n\tminConstant->constbyval = true;\n\tmaxConstant->constbyval = true;\n}\n\n\n/*\n * SelectedBlockSkipList constructs a new StripeSkipList in which the\n * non-selected blocks are removed from the given stripeSkipList.\n */\nstatic StripeSkipList *\nSelectedBlockSkipList(StripeSkipList *stripeSkipList, bool *projectedColumnMask,\n\t\t\t\t\t  bool *selectedBlockMask)\n{\n\tStripeSkipList *SelectedBlockSkipList = NULL;\n\tColumnBlockSkipNode **selectedBlockSkipNodeArray = NULL;\n\tuint32 selectedBlockCount = 0;\n\tuint32 blockIndex = 0;\n\tuint32 columnIndex = 0;\n\tuint32 columnCount = stripeSkipList->columnCount;\n\n\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t{\n\t\tif (selectedBlockMask[blockIndex])\n\t\t{\n\t\t\tselectedBlockCount++;\n\t\t}\n\t}\n\n\tselectedBlockSkipNodeArray = palloc0(columnCount * sizeof(ColumnBlockSkipNode *));\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tuint32 selectedBlockIndex = 0;\n\t\tbool firstColumn = columnIndex == 0;\n\n\t\t/* first column's block skip node is always read */\n\t\tif (!projectedColumnMask[columnIndex] && !firstColumn)\n\t\t{\n\t\t\tselectedBlockSkipNodeArray[columnIndex] = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tAssert(stripeSkipList->blockSkipNodeArray[columnIndex] != NULL);\n\n\t\tselectedBlockSkipNodeArray[columnIndex] = palloc0(selectedBlockCount *\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  sizeof(ColumnBlockSkipNode));\n\n\t\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t\t{\n\t\t\tif (selectedBlockMask[blockIndex])\n\t\t\t{\n\t\t\t\tselectedBlockSkipNodeArray[columnIndex][selectedBlockIndex] =\n\t\t\t\t\tstripeSkipList->blockSkipNodeArray[columnIndex][blockIndex];\n\t\t\t\tselectedBlockIndex++;\n\t\t\t}\n\t\t}\n\t}\n\n\tSelectedBlockSkipList = palloc0(sizeof(StripeSkipList));\n\tSelectedBlockSkipList->blockSkipNodeArray = selectedBlockSkipNodeArray;\n\tSelectedBlockSkipList->blockCount = selectedBlockCount;\n\tSelectedBlockSkipList->columnCount = stripeSkipList->columnCount;\n\n\treturn SelectedBlockSkipList;\n}\n\n\n/*\n * StripeSkipListRowCount counts the number of rows in the given stripeSkipList.\n * To do this, the function finds the first column, and sums up row counts across\n * all blocks for that column.\n */\nstatic uint32\nStripeSkipListRowCount(StripeSkipList *stripeSkipList)\n{\n\tuint32 stripeSkipListRowCount = 0;\n\tuint32 blockIndex = 0;\n\tColumnBlockSkipNode *firstColumnSkipNodeArray =\n\t\tstripeSkipList->blockSkipNodeArray[0];\n\n\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t{\n\t\tuint32 blockRowCount = firstColumnSkipNodeArray[blockIndex].rowCount;\n\t\tstripeSkipListRowCount += blockRowCount;\n\t}\n\n\treturn stripeSkipListRowCount;\n}\n\n\n/*\n * ProjectedColumnMask returns a boolean array in which the projected columns\n * from the projected column list are marked as true.\n */\nstatic bool *\nProjectedColumnMask(uint32 columnCount, List *projectedColumnList)\n{\n\tbool *projectedColumnMask = palloc0(columnCount * sizeof(bool));\n\tListCell *columnCell = NULL;\n\n\tforeach(columnCell, projectedColumnList)\n\t{\n\t\tVar *column = (Var *) lfirst(columnCell);\n\t\tuint32 columnIndex = column->varattno - 1;\n\t\tprojectedColumnMask[columnIndex] = true;\n\t}\n\n\treturn projectedColumnMask;\n}\n\n\n/*\n * DeserializeBoolArray reads an array of bits from the given buffer and stores\n * it in provided bool array.\n */\nstatic void\nDeserializeBoolArray(StringInfo boolArrayBuffer, bool *boolArray,\n\t\t\t\t\t uint32 boolArrayLength)\n{\n\tuint32 boolArrayIndex = 0;\n\n\tuint32 maximumBoolCount = boolArrayBuffer->len * 8;\n\tif (boolArrayLength > maximumBoolCount)\n\t{\n\t\tereport(ERROR, (errmsg(\"insufficient data for reading boolean array\")));\n\t}\n\n\tfor (boolArrayIndex = 0; boolArrayIndex < boolArrayLength; boolArrayIndex++)\n\t{\n\t\tuint32 byteIndex = boolArrayIndex / 8;\n\t\tuint32 bitIndex = boolArrayIndex % 8;\n\t\tuint8 bitmask = (1 << bitIndex);\n\n\t\tuint8 shiftedBit = (boolArrayBuffer->data[byteIndex] & bitmask);\n\t\tif (shiftedBit == 0)\n\t\t{\n\t\t\tboolArray[boolArrayIndex] = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tboolArray[boolArrayIndex] = true;\n\t\t}\n\t}\n}\n\n\n/*\n * DeserializeDatumArray reads an array of datums from the given buffer and stores\n * them in provided datumArray. If a value is marked as false in the exists array,\n * the function assumes that the datum isn't in the buffer, and simply skips it.\n */\nstatic void\nDeserializeDatumArray(StringInfo datumBuffer, bool *existsArray, uint32 datumCount,\n\t\t\t\t\t  bool datumTypeByValue, int datumTypeLength,\n\t\t\t\t\t  char datumTypeAlign, Datum *datumArray)\n{\n\tuint32 datumIndex = 0;\n\tuint32 currentDatumDataOffset = 0;\n\n\tfor (datumIndex = 0; datumIndex < datumCount; datumIndex++)\n\t{\n\t\tchar *currentDatumDataPointer = NULL;\n\n\t\tif (!existsArray[datumIndex])\n\t\t{\n\t\t\tcontinue;\n\t\t}\n\n\t\tcurrentDatumDataPointer = datumBuffer->data + currentDatumDataOffset;\n\n\t\tdatumArray[datumIndex] = fetch_att(currentDatumDataPointer, datumTypeByValue,\n\t\t\t\t\t\t\t\t\t\t   datumTypeLength);\n\t\tcurrentDatumDataOffset = att_addlength_datum(currentDatumDataOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t\t datumTypeLength,\n\t\t\t\t\t\t\t\t\t\t\t\t\t currentDatumDataPointer);\n\t\tcurrentDatumDataOffset = att_align_nominal(currentDatumDataOffset,\n\t\t\t\t\t\t\t\t\t\t\t\t   datumTypeAlign);\n\n\t\tif (currentDatumDataOffset > datumBuffer->len)\n\t\t{\n\t\t\tereport(ERROR, (errmsg(\"insufficient data left in datum buffer\")));\n\t\t}\n\t}\n}\n\n\n/*\n * DeserializeBlockData deserializes requested data block for all columns and\n * stores in blockDataArray. It uncompresses serialized data if necessary. The\n * function also deallocates data buffers used for previous block, and compressed\n * data buffers for the current block which will not be needed again. If a column\n * data is not present serialized buffer, then default value (or null) is used\n * to fill value array.\n */\nstatic void\nDeserializeBlockData(StripeBuffers *stripeBuffers, uint64 blockIndex,\n\t\t\t\t\t uint32 rowCount,\n\t\t\t\t\t ColumnBlockData **blockDataArray, TupleDesc tupleDescriptor)\n{\n\tint columnIndex = 0;\n\tfor (columnIndex = 0; columnIndex < stripeBuffers->columnCount; columnIndex++)\n\t{\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\tForm_pg_attribute attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\t\tColumnBuffers *columnBuffers = stripeBuffers->columnBuffersArray[columnIndex];\n\t\tbool columnAdded = false;\n\n\t\tif ((columnBuffers == NULL) && (blockData != NULL))\n\t\t{\n\t\t\tcolumnAdded = true;\n\t\t}\n\n\t\tif (columnBuffers != NULL)\n\t\t{\n\t\t\tColumnBlockBuffers *blockBuffers = columnBuffers->blockBuffersArray[blockIndex];\n\t\t\tStringInfo valueBuffer = NULL;\n\n\t\t\t/* free previous block's data buffers */\n\t\t\tpfree(blockData->valueBuffer->data);\n\t\t\tpfree(blockData->valueBuffer);\n\n\t\t\t/* decompress and deserialize current block's data */\n\t\t\tvalueBuffer = DecompressBuffer(blockBuffers->valueBuffer,\n\t\t\t\t\t\t\t\t\t\t   blockBuffers->valueCompressionType);\n\n\t\t\tif (blockBuffers->valueCompressionType != COMPRESSION_NONE)\n\t\t\t{\n\t\t\t\t/* compressed data is not needed anymore */\n\t\t\t\tpfree(blockBuffers->valueBuffer->data);\n\t\t\t\tpfree(blockBuffers->valueBuffer);\n\t\t\t}\n\n\t\t\tDeserializeBoolArray(blockBuffers->existsBuffer, blockData->existsArray,\n\t\t\t\t\t\t\t\t rowCount);\n\t\t\tDeserializeDatumArray(valueBuffer, blockData->existsArray,\n\t\t\t\t\t\t\t\t  rowCount, attributeForm->attbyval,\n\t\t\t\t\t\t\t\t  attributeForm->attlen, attributeForm->attalign,\n\t\t\t\t\t\t\t\t  blockData->valueArray);\n\n\t\t\t/* store current block's data buffer to be freed at next block read */\n\t\t\tblockData->valueBuffer = valueBuffer;\n\t\t}\n\t\telse if (columnAdded)\n\t\t{\n\t\t\t/*\n\t\t\t * This is a column that was added after creation of this stripe.\n\t\t\t * So we use either the default value or NULL.\n\t\t\t */\n\t\t\tif (attributeForm->atthasdef)\n\t\t\t{\n\t\t\t\tint rowIndex = 0;\n\n\t\t\t\tDatum defaultValue = ColumnDefaultValue(tupleDescriptor->constr,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tattributeForm);\n\n\t\t\t\tfor (rowIndex = 0; rowIndex < rowCount; rowIndex++)\n\t\t\t\t{\n\t\t\t\t\tblockData->existsArray[rowIndex] = true;\n\t\t\t\t\tblockData->valueArray[rowIndex] = defaultValue;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tmemset(blockData->existsArray, false, rowCount);\n\t\t\t}\n\n\t\t}\n\t}\n}\n\n\n/*\n * ColumnDefaultValue returns default value for given column. Only const values\n * are supported. The function errors on any other default value expressions.\n */\nstatic Datum\nColumnDefaultValue(TupleConstr *tupleConstraints, Form_pg_attribute attributeForm)\n{\n\tDatum defaultValue = 0;\n\tNode *defaultValueNode = NULL;\n\tint defValIndex = 0;\n\n\tfor (defValIndex = 0; defValIndex < tupleConstraints->num_defval; defValIndex++)\n\t{\n\t\tAttrDefault defaultValue = tupleConstraints->defval[defValIndex];\n\t\tif (defaultValue.adnum == attributeForm->attnum)\n\t\t{\n\t\t\tdefaultValueNode = stringToNode(defaultValue.adbin);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tAssert(defaultValueNode != NULL);\n\n\t/* try reducing the default value node to a const node */\n\tdefaultValueNode = eval_const_expressions(NULL, defaultValueNode);\n\tif (IsA(defaultValueNode, Const))\n\t{\n\t\tConst *constNode = (Const *) defaultValueNode;\n\t\tdefaultValue = constNode->constvalue;\n\t}\n\telse\n\t{\n\t\tconst char *columnName = NameStr(attributeForm->attname);\n\t\tereport(ERROR, (errmsg(\"unsupported default value for column \\\"%s\\\"\", columnName),\n\t\t\t\t\t\terrhint(\"Expression is either mutable or \"\n\t\t\t\t\t\t\t\t\"does not evaluate to constant value\")));\n\t}\n\n\treturn defaultValue;\n}\n\n\n/* Returns the size of the given file handle. */\nstatic int64\nFILESize(FILE *file)\n{\n\tint64 fileSize = 0;\n\tint fseekResult = 0;\n\n\terrno = 0;\n\tfseekResult = fseeko(file, 0, SEEK_END);\n\tif (fseekResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not seek in file: %m\")));\n\t}\n\n\tfileSize = ftello(file);\n\tif (fileSize == -1)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not get position in file: %m\")));\n\t}\n\n\treturn fileSize;\n}\n\n\n/* Reads the given segment from the given file. */\nstatic StringInfo\nReadFromFile(FILE *file, uint64 offset, uint32 size)\n{\n\tint fseekResult = 0;\n\tint freadResult = 0;\n\tint fileError = 0;\n\n\tStringInfo resultBuffer = makeStringInfo();\n\tenlargeStringInfo(resultBuffer, size);\n\tresultBuffer->len = size;\n\n\tif (size == 0)\n\t{\n\t\treturn resultBuffer;\n\t}\n\n\terrno = 0;\n\tfseekResult = fseeko(file, offset, SEEK_SET);\n\tif (fseekResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not seek in file: %m\")));\n\t}\n\n\tfreadResult = fread(resultBuffer->data, size, 1, file);\n\tif (freadResult != 1)\n\t{\n\t\tereport(ERROR, (errmsg(\"could not read enough data from file\")));\n\t}\n\n\tfileError = ferror(file);\n\tif (fileError != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not read file: %m\")));\n\t}\n\n\treturn resultBuffer;\n}\n\n\n\n\n/*\n * ResetUncompressedBlockData iterates over deserialized column block data\n * and sets valueBuffer field to empty buffer. This field is allocated in stripe\n * memory context and becomes invalid once memory context is reset.\n */\nstatic void\nResetUncompressedBlockData(ColumnBlockData **blockDataArray, uint32 columnCount)\n{\n\tuint32 columnIndex = 0;\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\tif (blockData != NULL)\n\t\t{\n\t\t\tblockData->valueBuffer = makeStringInfo();\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "cstore_version_compat.h",
          "type": "blob",
          "size": 1.8662109375,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_version_compat.h\n *\n *  Compatibility macros for writing code agnostic to PostgreSQL versions\n *\n * Copyright (c) 2018, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n#ifndef CSTORE_COMPAT_H\n#define CSTORE_COMPAT_H\n\n#if PG_VERSION_NUM < 100000\n\n/* Accessor for the i'th attribute of tupdesc. */\n#define TupleDescAttr(tupdesc, i) ((tupdesc)->attrs[(i)])\n\n#endif\n\n#if PG_VERSION_NUM < 110000\n#define ALLOCSET_DEFAULT_SIZES ALLOCSET_DEFAULT_MINSIZE, ALLOCSET_DEFAULT_INITSIZE, \\\n\tALLOCSET_DEFAULT_MAXSIZE\n#define ACLCHECK_OBJECT_TABLE ACL_KIND_CLASS\n#else\n#define ACLCHECK_OBJECT_TABLE OBJECT_TABLE\n\n#define ExplainPropertyLong(qlabel, value, es) \\\n\tExplainPropertyInteger(qlabel, NULL, value, es)\n#endif\n\n#if PG_VERSION_NUM >= 130000\n#define CALL_PREVIOUS_UTILITY() \\\n\tPreviousProcessUtilityHook(plannedStatement, queryString, context, paramListInfo, \\\n\t\t\t\t\t\t\t   queryEnvironment, destReceiver, queryCompletion)\n#elif PG_VERSION_NUM >= 100000\n#define CALL_PREVIOUS_UTILITY() \\\n\tPreviousProcessUtilityHook(plannedStatement, queryString, context, paramListInfo, \\\n\t\t\t\t\t\t\t   queryEnvironment, destReceiver, completionTag)\n#else\n#define CALL_PREVIOUS_UTILITY() \\\n\tPreviousProcessUtilityHook(parseTree, queryString, context, paramListInfo, \\\n\t\t\t\t\t\t\t   destReceiver, completionTag)\n#endif\n\n#if PG_VERSION_NUM < 120000\n#define TTS_EMPTY(slot) ((slot)->tts_isempty)\n#define ExecForceStoreHeapTuple(tuple, slot, shouldFree) \\\n\tExecStoreTuple(newTuple, tupleSlot, InvalidBuffer, shouldFree);\n#define TableScanDesc HeapScanDesc\n#define table_beginscan heap_beginscan\n#define table_endscan heap_endscan\n\n#endif\n\n#if PG_VERSION_NUM >= 130000\n#define heap_open table_open\n#define heap_openrv table_openrv\n#define heap_close table_close\n#endif\n\n#endif /* CSTORE_COMPAT_H */\n"
        },
        {
          "name": "cstore_writer.c",
          "type": "blob",
          "size": 32.505859375,
          "content": "/*-------------------------------------------------------------------------\n *\n * cstore_writer.c\n *\n * This file contains function definitions for writing cstore files. This\n * includes the logic for writing file level metadata, writing row stripes,\n * and calculating block skip nodes.\n *\n * Copyright (c) 2016, Citus Data, Inc.\n *\n * $Id$\n *\n *-------------------------------------------------------------------------\n */\n\n\n#include \"postgres.h\"\n#include \"cstore_fdw.h\"\n#include \"cstore_metadata_serialization.h\"\n#include \"cstore_version_compat.h\"\n\n#include <sys/stat.h>\n#include \"access/nbtree.h\"\n#include \"catalog/pg_collation.h\"\n#include \"commands/defrem.h\"\n#if PG_VERSION_NUM >= 120000\n#include \"optimizer/optimizer.h\"\n#else\n#include \"optimizer/var.h\"\n#endif\n#include \"port.h\"\n#include \"storage/fd.h\"\n#include \"utils/memutils.h\"\n#include \"utils/lsyscache.h\"\n#include \"utils/rel.h\"\n\n\nstatic void CStoreWriteFooter(StringInfo footerFileName, TableFooter *tableFooter);\nstatic StripeBuffers * CreateEmptyStripeBuffers(uint32 stripeMaxRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\tuint32 blockRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\tuint32 columnCount);\nstatic StripeSkipList * CreateEmptyStripeSkipList(uint32 stripeMaxRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\t  uint32 blockRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\t  uint32 columnCount);\nstatic StripeMetadata FlushStripe(TableWriteState *writeState);\nstatic StringInfo * CreateSkipListBufferArray(StripeSkipList *stripeSkipList,\n\t\t\t\t\t\t\t\t\t\t\t  TupleDesc tupleDescriptor);\nstatic StripeFooter * CreateStripeFooter(StripeSkipList *stripeSkipList,\n\t\t\t\t\t\t\t\t\t\t StringInfo *skipListBufferArray);\nstatic StringInfo SerializeBoolArray(bool *boolArray, uint32 boolArrayLength);\nstatic void SerializeSingleDatum(StringInfo datumBuffer, Datum datum,\n\t\t\t\t\t\t\t\t bool datumTypeByValue, int datumTypeLength,\n\t\t\t\t\t\t\t\t char datumTypeAlign);\nstatic void SerializeBlockData(TableWriteState *writeState, uint32 blockIndex,\n\t\t\t\t\t\t\t   uint32 rowCount);\nstatic void UpdateBlockSkipNodeMinMax(ColumnBlockSkipNode *blockSkipNode,\n\t\t\t\t\t\t\t\t\t  Datum columnValue, bool columnTypeByValue,\n\t\t\t\t\t\t\t\t\t  int columnTypeLength, Oid columnCollation,\n\t\t\t\t\t\t\t\t\t  FmgrInfo *comparisonFunction);\nstatic Datum DatumCopy(Datum datum, bool datumTypeByValue, int datumTypeLength);\nstatic void AppendStripeMetadata(TableFooter *tableFooter,\n\t\t\t\t\t\t\t\t StripeMetadata stripeMetadata);\nstatic void WriteToFile(FILE *file, void *data, uint32 dataLength);\nstatic void SyncAndCloseFile(FILE *file);\nstatic StringInfo CopyStringInfo(StringInfo sourceString);\n\n\n/*\n * CStoreBeginWrite initializes a cstore data load operation and returns a table\n * handle. This handle should be used for adding the row values and finishing the\n * data load operation. If the cstore footer file already exists, we read the\n * footer and then seek to right after the last stripe  where the new stripes\n * will be added.\n */\nTableWriteState *\nCStoreBeginWrite(const char *filename, CompressionType compressionType,\n\t\t\t\t uint64 stripeMaxRowCount, uint32 blockRowCount,\n\t\t\t\t TupleDesc tupleDescriptor)\n{\n\tTableWriteState *writeState = NULL;\n\tFILE *tableFile = NULL;\n\tStringInfo tableFooterFilename = NULL;\n\tTableFooter *tableFooter = NULL;\n\tFmgrInfo **comparisonFunctionArray = NULL;\n\tMemoryContext stripeWriteContext = NULL;\n\tuint64 currentFileOffset = 0;\n\tuint32 columnCount = 0;\n\tuint32 columnIndex = 0;\n\tstruct stat statBuffer;\n\tint statResult = 0;\n\tbool *columnMaskArray = NULL;\n\tColumnBlockData **blockData = NULL;\n\n\ttableFooterFilename = makeStringInfo();\n\tappendStringInfo(tableFooterFilename, \"%s%s\", filename, CSTORE_FOOTER_FILE_SUFFIX);\n\n\tstatResult = stat(tableFooterFilename->data, &statBuffer);\n\tif (statResult < 0)\n\t{\n\t\ttableFile = AllocateFile(filename, \"w\");\n\t\tif (tableFile == NULL)\n\t\t{\n\t\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for writing: %m\",\n\t\t\t\t\t\t\t\t   filename)));\n\t\t}\n\n\t\ttableFooter = palloc0(sizeof(TableFooter));\n\t\ttableFooter->blockRowCount = blockRowCount;\n\t\ttableFooter->stripeMetadataList = NIL;\n\t}\n\telse\n\t{\n\t\ttableFile = AllocateFile(filename, \"r+\");\n\t\tif (tableFile == NULL)\n\t\t{\n\t\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for writing: %m\",\n\t\t\t\t\t\t\t\t   filename)));\n\t\t}\n\n\t\ttableFooter = CStoreReadFooter(tableFooterFilename);\n\t}\n\n\t/*\n\t * If stripeMetadataList is not empty, jump to the position right after\n\t * the last position.\n\t */\n\tif (tableFooter->stripeMetadataList != NIL)\n\t{\n\t\tStripeMetadata *lastStripe = NULL;\n\t\tuint64 lastStripeSize = 0;\n\t\tint fseekResult = 0;\n\n\t\tlastStripe = llast(tableFooter->stripeMetadataList);\n\t\tlastStripeSize += lastStripe->skipListLength;\n\t\tlastStripeSize += lastStripe->dataLength;\n\t\tlastStripeSize += lastStripe->footerLength;\n\n\t\tcurrentFileOffset = lastStripe->fileOffset + lastStripeSize;\n\n\t\terrno = 0;\n\t\tfseekResult = fseeko(tableFile, currentFileOffset, SEEK_SET);\n\t\tif (fseekResult != 0)\n\t\t{\n\t\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\t\terrmsg(\"could not seek in file \\\"%s\\\": %m\", filename)));\n\t\t}\n\t}\n\n\t/* get comparison function pointers for each of the columns */\n\tcolumnCount = tupleDescriptor->natts;\n\tcomparisonFunctionArray = palloc0(columnCount * sizeof(FmgrInfo *));\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tFmgrInfo *comparisonFunction = NULL;\n\t\tFormData_pg_attribute *attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\n\t\tif (!attributeForm->attisdropped)\n\t\t{\n\t\t\tOid typeId = attributeForm->atttypid;\n\n\t\t\tcomparisonFunction = GetFunctionInfoOrNull(typeId, BTREE_AM_OID, BTORDER_PROC);\n\t\t}\n\n\t\tcomparisonFunctionArray[columnIndex] = comparisonFunction;\n\t}\n\n\t/*\n\t * We allocate all stripe specific data in the stripeWriteContext, and\n\t * reset this memory context once we have flushed the stripe to the file.\n\t * This is to avoid memory leaks.\n\t */\n\tstripeWriteContext = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t\t   \"Stripe Write Memory Context\",\n\t\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_SIZES);\n\n\tcolumnMaskArray = palloc(columnCount * sizeof(bool));\n\tmemset(columnMaskArray, true, columnCount);\n\n\tblockData = CreateEmptyBlockDataArray(columnCount, columnMaskArray, blockRowCount);\n\n\twriteState = palloc0(sizeof(TableWriteState));\n\twriteState->tableFile = tableFile;\n\twriteState->tableFooterFilename = tableFooterFilename;\n\twriteState->tableFooter = tableFooter;\n\twriteState->compressionType = compressionType;\n\twriteState->stripeMaxRowCount = stripeMaxRowCount;\n\twriteState->tupleDescriptor = tupleDescriptor;\n\twriteState->currentFileOffset = currentFileOffset;\n\twriteState->comparisonFunctionArray = comparisonFunctionArray;\n\twriteState->stripeBuffers = NULL;\n\twriteState->stripeSkipList = NULL;\n\twriteState->stripeWriteContext = stripeWriteContext;\n\twriteState->blockDataArray = blockData;\n\twriteState->compressionBuffer = NULL;\n\n\treturn writeState;\n}\n\n\n/*\n * CStoreWriteRow adds a row to the cstore file. If the stripe is not initialized,\n * we create structures to hold stripe data and skip list. Then, we serialize and\n * append data to serialized value buffer for each of the columns and update\n * corresponding skip nodes. Then, whole block data is compressed at every\n * rowBlockCount insertion. Then, if row count exceeds stripeMaxRowCount, we flush\n * the stripe, and add its metadata to the table footer.\n */\nvoid\nCStoreWriteRow(TableWriteState *writeState, Datum *columnValues, bool *columnNulls)\n{\n\tuint32 columnIndex = 0;\n\tuint32 blockIndex = 0;\n\tuint32 blockRowIndex = 0;\n\tStripeBuffers *stripeBuffers = writeState->stripeBuffers;\n\tStripeSkipList *stripeSkipList = writeState->stripeSkipList;\n\tuint32 columnCount = writeState->tupleDescriptor->natts;\n\tTableFooter *tableFooter = writeState->tableFooter;\n\tconst uint32 blockRowCount = tableFooter->blockRowCount;\n\tColumnBlockData **blockDataArray = writeState->blockDataArray;\n\tMemoryContext oldContext = MemoryContextSwitchTo(writeState->stripeWriteContext);\n\n\tif (stripeBuffers == NULL)\n\t{\n\t\tstripeBuffers = CreateEmptyStripeBuffers(writeState->stripeMaxRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\t blockRowCount, columnCount);\n\t\tstripeSkipList = CreateEmptyStripeSkipList(writeState->stripeMaxRowCount,\n\t\t\t\t\t\t\t\t\t\t\t\t   blockRowCount, columnCount);\n\t\twriteState->stripeBuffers = stripeBuffers;\n\t\twriteState->stripeSkipList = stripeSkipList;\n\t\twriteState->compressionBuffer = makeStringInfo();\n\n\t\t/*\n\t\t * serializedValueBuffer lives in stripe write memory context so it needs to be\n\t\t * initialized when the stripe is created.\n\t\t */\n\t\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t\t{\n\t\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\t\tblockData->valueBuffer = makeStringInfo();\n\t\t}\n\t}\n\n\tblockIndex = stripeBuffers->rowCount / blockRowCount;\n\tblockRowIndex = stripeBuffers->rowCount % blockRowCount;\n\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\tColumnBlockSkipNode **blockSkipNodeArray = stripeSkipList->blockSkipNodeArray;\n\t\tColumnBlockSkipNode *blockSkipNode =\n\t\t\t&blockSkipNodeArray[columnIndex][blockIndex];\n\n\t\tif (columnNulls[columnIndex])\n\t\t{\n\t\t\tblockData->existsArray[blockRowIndex] = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tFmgrInfo *comparisonFunction =\n\t\t\t\twriteState->comparisonFunctionArray[columnIndex];\n\t\t\tForm_pg_attribute attributeForm =\n\t\t\t\tTupleDescAttr(writeState->tupleDescriptor, columnIndex);\n\t\t\tbool columnTypeByValue = attributeForm->attbyval;\n\t\t\tint columnTypeLength = attributeForm->attlen;\n\t\t\tOid columnCollation = attributeForm->attcollation;\n\t\t\tchar columnTypeAlign  = attributeForm->attalign;\n\n\t\t\tblockData->existsArray[blockRowIndex] = true;\n\n\t\t\tSerializeSingleDatum(blockData->valueBuffer, columnValues[columnIndex],\n\t\t\t\t\t\t\t\t columnTypeByValue, columnTypeLength, columnTypeAlign);\n\n\t\t\tUpdateBlockSkipNodeMinMax(blockSkipNode, columnValues[columnIndex],\n\t\t\t\t\t\t\t\t\t  columnTypeByValue, columnTypeLength,\n\t\t\t\t\t\t\t\t\t  columnCollation, comparisonFunction);\n\t\t}\n\n\t\tblockSkipNode->rowCount++;\n\t}\n\n\tstripeSkipList->blockCount = blockIndex + 1;\n\n\t/* last row of the block is inserted serialize the block */\n\tif (blockRowIndex == blockRowCount - 1)\n\t{\n\t\tSerializeBlockData(writeState, blockIndex, blockRowCount);\n\t}\n\n\tstripeBuffers->rowCount++;\n\tif (stripeBuffers->rowCount >= writeState->stripeMaxRowCount)\n\t{\n\t\tStripeMetadata stripeMetadata = FlushStripe(writeState);\n\t\tMemoryContextReset(writeState->stripeWriteContext);\n\n\t\t/* set stripe data and skip list to NULL so they are recreated next time */\n\t\twriteState->stripeBuffers = NULL;\n\t\twriteState->stripeSkipList = NULL;\n\n\t\t/*\n\t\t * Append stripeMetadata in old context so next MemoryContextReset\n\t\t * doesn't free it.\n\t\t */\n\t\tMemoryContextSwitchTo(oldContext);\n\t\tAppendStripeMetadata(tableFooter, stripeMetadata);\n\t}\n\telse\n\t{\n\t\tMemoryContextSwitchTo(oldContext);\n\t}\n}\n\n\n/*\n * CStoreEndWrite finishes a cstore data load operation. If we have an unflushed\n * stripe, we flush it. Then, we sync and close the cstore data file. Last, we\n * flush the footer to a temporary file, and atomically rename this temporary\n * file to the original footer file.\n */\nvoid\nCStoreEndWrite(TableWriteState *writeState)\n{\n\tStringInfo tableFooterFilename = NULL;\n\tStringInfo tempTableFooterFileName = NULL;\n\tint renameResult = 0;\n\tint columnCount = writeState->tupleDescriptor->natts;\n\tStripeBuffers *stripeBuffers = writeState->stripeBuffers;\n\n\tif (stripeBuffers != NULL)\n\t{\n\t\tMemoryContext oldContext = MemoryContextSwitchTo(writeState->stripeWriteContext);\n\n\t\tStripeMetadata stripeMetadata = FlushStripe(writeState);\n\t\tMemoryContextReset(writeState->stripeWriteContext);\n\n\t\tMemoryContextSwitchTo(oldContext);\n\t\tAppendStripeMetadata(writeState->tableFooter, stripeMetadata);\n\t}\n\n\tSyncAndCloseFile(writeState->tableFile);\n\n\ttableFooterFilename = writeState->tableFooterFilename;\n\ttempTableFooterFileName = makeStringInfo();\n\tappendStringInfo(tempTableFooterFileName, \"%s%s\", tableFooterFilename->data,\n\t\t\t\t\t CSTORE_TEMP_FILE_SUFFIX);\n\n\tCStoreWriteFooter(tempTableFooterFileName, writeState->tableFooter);\n\n\trenameResult = rename(tempTableFooterFileName->data, tableFooterFilename->data);\n\tif (renameResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not rename file \\\"%s\\\" to \\\"%s\\\": %m\",\n\t\t\t\t\t\t\t   tempTableFooterFileName->data,\n\t\t\t\t\t\t\t   tableFooterFilename->data)));\n\t}\n\n\tpfree(tempTableFooterFileName->data);\n\tpfree(tempTableFooterFileName);\n\n\tMemoryContextDelete(writeState->stripeWriteContext);\n\tlist_free_deep(writeState->tableFooter->stripeMetadataList);\n\tpfree(writeState->tableFooter);\n\tpfree(writeState->tableFooterFilename->data);\n\tpfree(writeState->tableFooterFilename);\n\tpfree(writeState->comparisonFunctionArray);\n\tFreeColumnBlockDataArray(writeState->blockDataArray, columnCount);\n\tpfree(writeState);\n}\n\n\n/*\n * CStoreWriteFooter writes the given footer to given file. First, the function\n * serializes and writes the footer to the file. Then, the function serializes\n * and writes the postscript. Then, the function writes the postscript size as\n * the last byte of the file. Last, the function syncs and closes the footer file.\n */\nstatic void\nCStoreWriteFooter(StringInfo tableFooterFilename, TableFooter *tableFooter)\n{\n\tFILE *tableFooterFile = NULL;\n\tStringInfo tableFooterBuffer = NULL;\n\tStringInfo postscriptBuffer = NULL;\n\tuint8 postscriptSize = 0;\n\n\ttableFooterFile = AllocateFile(tableFooterFilename->data, PG_BINARY_W);\n\tif (tableFooterFile == NULL)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not open file \\\"%s\\\" for writing: %m\",\n\t\t\t\t\t\t\t   tableFooterFilename->data)));\n\t}\n\n\t/* write the footer */\n\ttableFooterBuffer = SerializeTableFooter(tableFooter);\n\tWriteToFile(tableFooterFile, tableFooterBuffer->data, tableFooterBuffer->len);\n\n\t/* write the postscript */\n\tpostscriptBuffer = SerializePostScript(tableFooterBuffer->len);\n\tWriteToFile(tableFooterFile, postscriptBuffer->data, postscriptBuffer->len);\n\n\t/* write the 1-byte postscript size */\n\tAssert(postscriptBuffer->len < CSTORE_POSTSCRIPT_SIZE_MAX);\n\tpostscriptSize = postscriptBuffer->len;\n\tWriteToFile(tableFooterFile, &postscriptSize, CSTORE_POSTSCRIPT_SIZE_LENGTH);\n\n\tSyncAndCloseFile(tableFooterFile);\n\n\tpfree(tableFooterBuffer->data);\n\tpfree(tableFooterBuffer);\n\tpfree(postscriptBuffer->data);\n\tpfree(postscriptBuffer);\n}\n\n\n/*\n * CreateEmptyStripeBuffers allocates an empty StripeBuffers structure with the given\n * column count.\n */\nstatic StripeBuffers *\nCreateEmptyStripeBuffers(uint32 stripeMaxRowCount, uint32 blockRowCount,\n\t\t\t\t\t\t uint32 columnCount)\n{\n\tStripeBuffers *stripeBuffers = NULL;\n\tuint32 columnIndex = 0;\n\tuint32 maxBlockCount = (stripeMaxRowCount / blockRowCount) + 1;\n\tColumnBuffers **columnBuffersArray = palloc0(columnCount * sizeof(ColumnBuffers *));\n\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tuint32 blockIndex = 0;\n\t\tColumnBlockBuffers **blockBuffersArray =\n\t\t\tpalloc0(maxBlockCount * sizeof(ColumnBlockBuffers *));\n\n\t\tfor (blockIndex = 0; blockIndex < maxBlockCount; blockIndex++)\n\t\t{\n\t\t\tblockBuffersArray[blockIndex] = palloc0(sizeof(ColumnBlockBuffers));\n\t\t\tblockBuffersArray[blockIndex]->existsBuffer = NULL;\n\t\t\tblockBuffersArray[blockIndex]->valueBuffer = NULL;\n\t\t\tblockBuffersArray[blockIndex]->valueCompressionType = COMPRESSION_NONE;\n\t\t}\n\n\t\tcolumnBuffersArray[columnIndex] = palloc0(sizeof(ColumnBuffers));\n\t\tcolumnBuffersArray[columnIndex]->blockBuffersArray = blockBuffersArray;\n\t}\n\n\tstripeBuffers = palloc0(sizeof(StripeBuffers));\n\tstripeBuffers->columnBuffersArray = columnBuffersArray;\n\tstripeBuffers->columnCount = columnCount;\n\tstripeBuffers->rowCount = 0;\n\n\treturn stripeBuffers;\n}\n\n\n/*\n * CreateEmptyStripeSkipList allocates an empty StripeSkipList structure with\n * the given column count. This structure has enough blocks to hold statistics\n * for stripeMaxRowCount rows.\n */\nstatic StripeSkipList *\nCreateEmptyStripeSkipList(uint32 stripeMaxRowCount, uint32 blockRowCount,\n\t\t\t\t\t\t  uint32 columnCount)\n{\n\tStripeSkipList *stripeSkipList = NULL;\n\tuint32 columnIndex = 0;\n\tuint32 maxBlockCount = (stripeMaxRowCount / blockRowCount) + 1;\n\n\tColumnBlockSkipNode **blockSkipNodeArray =\n\t\tpalloc0(columnCount * sizeof(ColumnBlockSkipNode *));\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tblockSkipNodeArray[columnIndex] =\n\t\t\tpalloc0(maxBlockCount * sizeof(ColumnBlockSkipNode));\n\t}\n\n\tstripeSkipList = palloc0(sizeof(StripeSkipList));\n\tstripeSkipList->columnCount = columnCount;\n\tstripeSkipList->blockCount = 0;\n\tstripeSkipList->blockSkipNodeArray = blockSkipNodeArray;\n\n\treturn stripeSkipList;\n}\n\n\n/*\n * FlushStripe flushes current stripe data into the file. The function first ensures\n * the last data block for each column is properly serialized and compressed. Then,\n * the function creates the skip list and footer buffers. Finally, the function\n * flushes the skip list, data, and footer buffers to the file.\n */\nstatic StripeMetadata\nFlushStripe(TableWriteState *writeState)\n{\n\tStripeMetadata stripeMetadata = {0, 0, 0, 0};\n\tuint64 skipListLength = 0;\n\tuint64 dataLength = 0;\n\tStringInfo *skipListBufferArray = NULL;\n\tStripeFooter *stripeFooter = NULL;\n\tStringInfo stripeFooterBuffer = NULL;\n\tuint32 columnIndex = 0;\n\tuint32 blockIndex = 0;\n\tTableFooter *tableFooter = writeState->tableFooter;\n\tFILE *tableFile = writeState->tableFile;\n\tStripeBuffers *stripeBuffers = writeState->stripeBuffers;\n\tStripeSkipList *stripeSkipList = writeState->stripeSkipList;\n\tColumnBlockSkipNode **columnSkipNodeArray = stripeSkipList->blockSkipNodeArray;\n\tTupleDesc tupleDescriptor = writeState->tupleDescriptor;\n\tuint32 columnCount = tupleDescriptor->natts;\n\tuint32 blockCount = stripeSkipList->blockCount;\n\tuint32 blockRowCount = tableFooter->blockRowCount;\n\tuint32 lastBlockIndex = stripeBuffers->rowCount / blockRowCount;\n\tuint32 lastBlockRowCount = stripeBuffers->rowCount % blockRowCount;\n\n\t/*\n\t * check if the last block needs serialization , the last block was not serialized\n\t * if it was not full yet, e.g.  (rowCount > 0)\n\t */\n\tif (lastBlockRowCount > 0)\n\t{\n\t\tSerializeBlockData(writeState, lastBlockIndex, lastBlockRowCount);\n\t}\n\n\t/* update buffer sizes and positions in stripe skip list */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockSkipNode *blockSkipNodeArray = columnSkipNodeArray[columnIndex];\n\t\tuint64 currentExistsBlockOffset = 0;\n\t\tuint64 currentValueBlockOffset = 0;\n\t\tColumnBuffers *columnBuffers = stripeBuffers->columnBuffersArray[columnIndex];\n\n\t\tfor (blockIndex = 0; blockIndex < blockCount; blockIndex++)\n\t\t{\n\t\t\tColumnBlockBuffers *blockBuffers =\n\t\t\t\t\tcolumnBuffers->blockBuffersArray[blockIndex];\n\t\t\tuint64 existsBufferSize = blockBuffers->existsBuffer->len;\n\t\t\tuint64 valueBufferSize = blockBuffers->valueBuffer->len;\n\t\t\tCompressionType valueCompressionType = blockBuffers->valueCompressionType;\n\t\t\tColumnBlockSkipNode *blockSkipNode = &blockSkipNodeArray[blockIndex];\n\n\t\t\tblockSkipNode->existsBlockOffset = currentExistsBlockOffset;\n\t\t\tblockSkipNode->existsLength = existsBufferSize;\n\t\t\tblockSkipNode->valueBlockOffset = currentValueBlockOffset;\n\t\t\tblockSkipNode->valueLength = valueBufferSize;\n\t\t\tblockSkipNode->valueCompressionType = valueCompressionType;\n\n\t\t\tcurrentExistsBlockOffset += existsBufferSize;\n\t\t\tcurrentValueBlockOffset += valueBufferSize;\n\t\t}\n\t}\n\n\t/* create skip list and footer buffers */\n\tskipListBufferArray = CreateSkipListBufferArray(stripeSkipList, tupleDescriptor);\n\tstripeFooter = CreateStripeFooter(stripeSkipList, skipListBufferArray);\n\tstripeFooterBuffer = SerializeStripeFooter(stripeFooter);\n\n\t/*\n\t * Each stripe has three sections:\n\t * (1) Skip list, which contains statistics for each column block, and can\n\t * be used to skip reading row blocks that are refuted by WHERE clause list,\n\t * (2) Data section, in which we store data for each column continuously.\n\t * We store data for each for each column in blocks. For each block, we\n\t * store two buffers: \"exists\" buffer, and \"value\" buffer. \"exists\" buffer\n\t * tells which values are not NULL. \"value\" buffer contains values for\n\t * present values. For each column, we first store all \"exists\" buffers,\n\t * and then all \"value\" buffers.\n\t * (3) Stripe footer, which contains the skip list buffer size, exists buffer\n\t * size, and value buffer size for each of the columns.\n\t *\n\t * We start by flushing the skip list buffers.\n\t */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tStringInfo skipListBuffer = skipListBufferArray[columnIndex];\n\t\tWriteToFile(tableFile, skipListBuffer->data, skipListBuffer->len);\n\t}\n\n\t/* then, we flush the data buffers */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBuffers *columnBuffers = stripeBuffers->columnBuffersArray[columnIndex];\n\t\tuint32 blockIndex = 0;\n\n\t\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t\t{\n\t\t\tColumnBlockBuffers *blockBuffers =\n\t\t\t\t\tcolumnBuffers->blockBuffersArray[blockIndex];\n\t\t\tStringInfo existsBuffer = blockBuffers->existsBuffer;\n\n\t\t\tWriteToFile(tableFile, existsBuffer->data, existsBuffer->len);\n\t\t}\n\n\t\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t\t{\n\t\t\tColumnBlockBuffers *blockBuffers =\n\t\t\t\t\tcolumnBuffers->blockBuffersArray[blockIndex];\n\t\t\tStringInfo valueBuffer = blockBuffers->valueBuffer;\n\n\t\t\tWriteToFile(tableFile, valueBuffer->data, valueBuffer->len);\n\t\t}\n\t}\n\n\t/* finally, we flush the footer buffer */\n\tWriteToFile(tableFile, stripeFooterBuffer->data, stripeFooterBuffer->len);\n\n\t/* set stripe metadata */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tskipListLength += stripeFooter->skipListSizeArray[columnIndex];\n\t\tdataLength += stripeFooter->existsSizeArray[columnIndex];\n\t\tdataLength += stripeFooter->valueSizeArray[columnIndex];\n\t}\n\n\tstripeMetadata.fileOffset = writeState->currentFileOffset;\n\tstripeMetadata.skipListLength = skipListLength;\n\tstripeMetadata.dataLength = dataLength;\n\tstripeMetadata.footerLength = stripeFooterBuffer->len;\n\n\t/* advance current file offset */\n\twriteState->currentFileOffset += skipListLength;\n\twriteState->currentFileOffset += dataLength;\n\twriteState->currentFileOffset += stripeFooterBuffer->len;\n\n\treturn stripeMetadata;\n}\n\n\n/*\n * CreateSkipListBufferArray serializes the skip list for each column of the\n * given stripe and returns the result as an array.\n */\nstatic StringInfo *\nCreateSkipListBufferArray(StripeSkipList *stripeSkipList, TupleDesc tupleDescriptor)\n{\n\tStringInfo *skipListBufferArray = NULL;\n\tuint32 columnIndex = 0;\n\tuint32 columnCount = stripeSkipList->columnCount;\n\n\tskipListBufferArray = palloc0(columnCount * sizeof(StringInfo));\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tStringInfo skipListBuffer = NULL;\n\t\tColumnBlockSkipNode *blockSkipNodeArray =\n\t\t\tstripeSkipList->blockSkipNodeArray[columnIndex];\n\t\tForm_pg_attribute attributeForm = TupleDescAttr(tupleDescriptor, columnIndex);\n\n\t\tskipListBuffer = SerializeColumnSkipList(blockSkipNodeArray,\n\t\t\t\t\t\t\t\t\t\t\t\t stripeSkipList->blockCount,\n\t\t\t\t\t\t\t\t\t\t\t\t attributeForm->attbyval,\n\t\t\t\t\t\t\t\t\t\t\t\t attributeForm->attlen);\n\n\t\tskipListBufferArray[columnIndex] = skipListBuffer;\n\t}\n\n\treturn skipListBufferArray;\n}\n\n\n/* Creates and returns the footer for given stripe. */\nstatic StripeFooter *\nCreateStripeFooter(StripeSkipList *stripeSkipList, StringInfo *skipListBufferArray)\n{\n\tStripeFooter *stripeFooter = NULL;\n\tuint32 columnIndex = 0;\n\tuint32 columnCount = stripeSkipList->columnCount;\n\tuint64 *skipListSizeArray = palloc0(columnCount * sizeof(uint64));\n\tuint64 *existsSizeArray = palloc0(columnCount * sizeof(uint64));\n\tuint64 *valueSizeArray = palloc0(columnCount * sizeof(uint64));\n\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBlockSkipNode *blockSkipNodeArray =\n\t\t\tstripeSkipList->blockSkipNodeArray[columnIndex];\n\t\tuint32 blockIndex = 0;\n\n\t\tfor (blockIndex = 0; blockIndex < stripeSkipList->blockCount; blockIndex++)\n\t\t{\n\t\t\texistsSizeArray[columnIndex] += blockSkipNodeArray[blockIndex].existsLength;\n\t\t\tvalueSizeArray[columnIndex] += blockSkipNodeArray[blockIndex].valueLength;\n\t\t}\n\t\tskipListSizeArray[columnIndex] = skipListBufferArray[columnIndex]->len;\n\t}\n\n\tstripeFooter = palloc0(sizeof(StripeFooter));\n\tstripeFooter->columnCount = columnCount;\n\tstripeFooter->skipListSizeArray = skipListSizeArray;\n\tstripeFooter->existsSizeArray = existsSizeArray;\n\tstripeFooter->valueSizeArray = valueSizeArray;\n\n\treturn stripeFooter;\n}\n\n\n/*\n * SerializeBoolArray serializes the given boolean array and returns the result\n * as a StringInfo. This function packs every 8 boolean values into one byte.\n */\nstatic StringInfo\nSerializeBoolArray(bool *boolArray, uint32 boolArrayLength)\n{\n\tStringInfo boolArrayBuffer = NULL;\n\tuint32 boolArrayIndex = 0;\n\tuint32 byteCount = (boolArrayLength + 7) / 8;\n\n\tboolArrayBuffer = makeStringInfo();\n\tenlargeStringInfo(boolArrayBuffer, byteCount);\n\tboolArrayBuffer->len = byteCount;\n\tmemset(boolArrayBuffer->data, 0, byteCount);\n\n\tfor (boolArrayIndex = 0; boolArrayIndex < boolArrayLength; boolArrayIndex++)\n\t{\n\t\tif (boolArray[boolArrayIndex])\n\t\t{\n\t\t\tuint32 byteIndex = boolArrayIndex / 8;\n\t\t\tuint32 bitIndex = boolArrayIndex % 8;\n\t\t\tboolArrayBuffer->data[byteIndex] |= (1 << bitIndex);\n\t\t}\n\t}\n\n\treturn boolArrayBuffer;\n}\n\n\n/*\n * SerializeSingleDatum serializes the given datum value and appends it to the\n * provided string info buffer.\n */\nstatic void\nSerializeSingleDatum(StringInfo datumBuffer, Datum datum, bool datumTypeByValue,\n\t\t\t\t\t int datumTypeLength, char datumTypeAlign)\n{\n\tuint32 datumLength = att_addlength_datum(0, datumTypeLength, datum);\n\tuint32 datumLengthAligned = att_align_nominal(datumLength, datumTypeAlign);\n\tchar *currentDatumDataPointer = NULL;\n\n\tenlargeStringInfo(datumBuffer, datumLengthAligned);\n\n\tcurrentDatumDataPointer = datumBuffer->data + datumBuffer->len;\n\tmemset(currentDatumDataPointer, 0, datumLengthAligned);\n\n\tif (datumTypeLength > 0)\n\t{\n\t\tif (datumTypeByValue)\n\t\t{\n\t\t\tstore_att_byval(currentDatumDataPointer, datum, datumTypeLength);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmemcpy(currentDatumDataPointer, DatumGetPointer(datum), datumTypeLength);\n\t\t}\n\t}\n\telse\n\t{\n\t\tAssert(!datumTypeByValue);\n\t\tmemcpy(currentDatumDataPointer, DatumGetPointer(datum), datumLength);\n\t}\n\n\tdatumBuffer->len += datumLengthAligned;\n}\n\n\n/*\n * SerializeBlockData serializes and compresses block data at given block index with given\n * compression type for every column.\n */\nstatic void\nSerializeBlockData(TableWriteState *writeState, uint32 blockIndex, uint32 rowCount)\n{\n\tuint32 columnIndex = 0;\n\tStripeBuffers *stripeBuffers = writeState->stripeBuffers;\n\tColumnBlockData **blockDataArray = writeState->blockDataArray;\n\tCompressionType requestedCompressionType = writeState->compressionType;\n\tconst uint32 columnCount = stripeBuffers->columnCount;\n\tStringInfo compressionBuffer = writeState->compressionBuffer;\n\n\t/* serialize exist values, data values are already serialized */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBuffers *columnBuffers = stripeBuffers->columnBuffersArray[columnIndex];\n\t\tColumnBlockBuffers *blockBuffers = columnBuffers->blockBuffersArray[blockIndex];\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\n\t\tblockBuffers->existsBuffer = SerializeBoolArray(blockData->existsArray, rowCount);\n\t}\n\n\t/*\n\t * check and compress value buffers, if a value buffer is not compressable\n\t * then keep it as uncompressed, store compression information.\n\t */\n\tfor (columnIndex = 0; columnIndex < columnCount; columnIndex++)\n\t{\n\t\tColumnBuffers *columnBuffers = stripeBuffers->columnBuffersArray[columnIndex];\n\t\tColumnBlockBuffers *blockBuffers = columnBuffers->blockBuffersArray[blockIndex];\n\t\tColumnBlockData *blockData = blockDataArray[columnIndex];\n\t\tStringInfo serializedValueBuffer = NULL;\n\t\tCompressionType actualCompressionType = COMPRESSION_NONE;\n\t\tbool compressed = false;\n\n\t\tserializedValueBuffer = blockData->valueBuffer;\n\n\t\t/* the only other supported compression type is pg_lz for now */\n\t\tAssert(requestedCompressionType == COMPRESSION_NONE ||\n\t\t\t   requestedCompressionType == COMPRESSION_PG_LZ);\n\n\t\t/*\n\t\t * if serializedValueBuffer is be compressed, update serializedValueBuffer\n\t\t * with compressed data and store compression type.\n\t\t */\n\t\tcompressed = CompressBuffer(serializedValueBuffer, compressionBuffer,\n\t\t\t\t\t\t\t\t\trequestedCompressionType);\n\t\tif (compressed)\n\t\t{\n\t\t\tserializedValueBuffer = compressionBuffer;\n\t\t\tactualCompressionType = COMPRESSION_PG_LZ;\n\t\t}\n\n\t\t/* store (compressed) value buffer */\n\t\tblockBuffers->valueCompressionType = actualCompressionType;\n\t\tblockBuffers->valueBuffer = CopyStringInfo(serializedValueBuffer);\n\n\t\t/* valueBuffer needs to be reset for next block's data */\n\t\tresetStringInfo(blockData->valueBuffer);\n\t}\n}\n\n\n/*\n * UpdateBlockSkipNodeMinMax takes the given column value, and checks if this\n * value falls outside the range of minimum/maximum values of the given column\n * block skip node. If it does, the function updates the column block skip node\n * accordingly.\n */\nstatic void\nUpdateBlockSkipNodeMinMax(ColumnBlockSkipNode *blockSkipNode, Datum columnValue,\n\t\t\t\t\t\t  bool columnTypeByValue, int columnTypeLength,\n\t\t\t\t\t\t  Oid columnCollation, FmgrInfo *comparisonFunction)\n{\n\tbool hasMinMax = blockSkipNode->hasMinMax;\n\tDatum previousMinimum = blockSkipNode->minimumValue;\n\tDatum previousMaximum = blockSkipNode->maximumValue;\n\tDatum currentMinimum = 0;\n\tDatum currentMaximum = 0;\n\n\t/* if type doesn't have a comparison function, skip min/max values */\n\tif (comparisonFunction == NULL)\n\t{\n\t\treturn;\n\t}\n\n\tif (!hasMinMax)\n\t{\n\t\tcurrentMinimum = DatumCopy(columnValue, columnTypeByValue, columnTypeLength);\n\t\tcurrentMaximum = DatumCopy(columnValue, columnTypeByValue, columnTypeLength);\n\t}\n\telse\n\t{\n\t\tDatum minimumComparisonDatum = FunctionCall2Coll(comparisonFunction,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t columnCollation, columnValue,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t previousMinimum);\n\t\tDatum maximumComparisonDatum = FunctionCall2Coll(comparisonFunction,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t columnCollation, columnValue,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t previousMaximum);\n\t\tint minimumComparison = DatumGetInt32(minimumComparisonDatum);\n\t\tint maximumComparison = DatumGetInt32(maximumComparisonDatum);\n\n\t\tif (minimumComparison < 0)\n\t\t{\n\t\t\tcurrentMinimum = DatumCopy(columnValue, columnTypeByValue, columnTypeLength);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tcurrentMinimum = previousMinimum;\n\t\t}\n\n\t\tif (maximumComparison > 0)\n\t\t{\n\t\t\tcurrentMaximum = DatumCopy(columnValue, columnTypeByValue, columnTypeLength);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tcurrentMaximum = previousMaximum;\n\t\t}\n\t}\n\n\tblockSkipNode->hasMinMax = true;\n\tblockSkipNode->minimumValue = currentMinimum;\n\tblockSkipNode->maximumValue = currentMaximum;\n}\n\n\n/* Creates a copy of the given datum. */\nstatic Datum\nDatumCopy(Datum datum, bool datumTypeByValue, int datumTypeLength)\n{\n\tDatum datumCopy = 0;\n\n\tif (datumTypeByValue)\n\t{\n\t\tdatumCopy = datum;\n\t}\n\telse\n\t{\n\t\tuint32 datumLength = att_addlength_datum(0, datumTypeLength, datum);\n\t\tchar *datumData = palloc0(datumLength);\n\t\tmemcpy(datumData, DatumGetPointer(datum), datumLength);\n\n\t\tdatumCopy = PointerGetDatum(datumData);\n\t}\n\n\treturn datumCopy;\n}\n\n\n/*\n * AppendStripeMetadata adds a copy of given stripeMetadata to the given\n * table footer's stripeMetadataList.\n */\nstatic void\nAppendStripeMetadata(TableFooter *tableFooter, StripeMetadata stripeMetadata)\n{\n\tStripeMetadata *stripeMetadataCopy = palloc0(sizeof(StripeMetadata));\n\tmemcpy(stripeMetadataCopy, &stripeMetadata, sizeof(StripeMetadata));\n\n\ttableFooter->stripeMetadataList = lappend(tableFooter->stripeMetadataList,\n\t\t\t\t\t\t\t\t\t\t\t  stripeMetadataCopy);\n}\n\n\n/* Writes the given data to the given file pointer and checks for errors. */\nstatic void\nWriteToFile(FILE *file, void *data, uint32 dataLength)\n{\n\tint writeResult = 0;\n\tint errorResult = 0;\n\n\tif (dataLength == 0)\n\t{\n\t\treturn;\n\t}\n\n\terrno = 0;\n\twriteResult = fwrite(data, dataLength, 1, file);\n\tif (writeResult != 1)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not write file: %m\")));\n\t}\n\n\terrorResult = ferror(file);\n\tif (errorResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"error in file: %m\")));\n\t}\n}\n\n\n/* Flushes, syncs, and closes the given file pointer and checks for errors. */\nstatic void\nSyncAndCloseFile(FILE *file)\n{\n\tint flushResult = 0;\n\tint syncResult = 0;\n\tint errorResult = 0;\n\tint freeResult = 0;\n\n\terrno = 0;\n\tflushResult = fflush(file);\n\tif (flushResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not flush file: %m\")));\n\t}\n\n\tsyncResult = pg_fsync(fileno(file));\n\tif (syncResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not sync file: %m\")));\n\t}\n\n\terrorResult = ferror(file);\n\tif (errorResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"error in file: %m\")));\n\t}\n\n\tfreeResult = FreeFile(file);\n\tif (freeResult != 0)\n\t{\n\t\tereport(ERROR, (errcode_for_file_access(),\n\t\t\t\t\t\terrmsg(\"could not close file: %m\")));\n\t}\n}\n\n\n/*\n * CopyStringInfo creates a deep copy of given source string allocating only needed\n * amount of memory.\n */\nstatic StringInfo\nCopyStringInfo(StringInfo sourceString)\n{\n\tStringInfo targetString = palloc0(sizeof(StringInfoData));\n\n\tif (sourceString->len > 0)\n\t{\n\t\ttargetString->data = palloc0(sourceString->len);\n\t\ttargetString->len = sourceString->len;\n\t\ttargetString->maxlen = sourceString->len;\n\t\tmemcpy(targetString->data, sourceString->data, sourceString->len);\n\t}\n\n\treturn targetString;\n}\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "expected",
          "type": "tree",
          "content": null
        },
        {
          "name": "input",
          "type": "tree",
          "content": null
        },
        {
          "name": "output",
          "type": "tree",
          "content": null
        },
        {
          "name": "sql",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}