{
  "metadata": {
    "timestamp": 1736709977184,
    "page": 539,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "networkupstools/nut",
      "stars": 2254,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 1.6689453125,
          "content": "# EditorConfig is awesome: https://EditorConfig.org\n# https://github.com/editorconfig/editorconfig/wiki/EditorConfig-Properties\n\n# top-most EditorConfig file\nroot = true\n\n[*]\ncharset = utf-8\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\nmax_line_length = 80\n\nindent_style = tab\ntab_width = 4\n#indent_style = space\n#indent_size = 4\n\n# Platform-dependent, except for certain interpreters\n# whose sources must use LF, see .gitattributes\n###end_of_line = lf\n\n#ij_formatter_enabled = false\n\n[.editorconfig]\ntrim_trailing_whitespace = false\n\n[*.{bat,cmd,ps1}]\nend_of_line = crlf\n\n[*.{am,hwdb,service,target,path}{,.in}]\nend_of_line = lf\nline_comment = #\n\n[*.sh{,.in}]\nend_of_line = lf\nline_comment = #\n\n# Borrowed from https://github.com/armbian/build/blob/master/.editorconfig\nshell_variant = bash\nbinary_next_line = false\nswitch_case_indent = true\nspace_redirects = true\nkeep_padding = false\nfunction_next_line = false\n\n[*.{m4,ac}{,.in}]\nend_of_line = lf\nline_comment = dnl \n\n[*.{conf,sample}{,.in}]\nmax_line_length = 76\nline_comment = #\n\n[*.txt{,.in},*.adoc{,.in},AUTHORS,COPYING,INSTALL.nut,MAINTAINERS,NEWS,README,TODO,UPGRADING]\nmax_line_length = 76\nindent_style = space\nindent_size = 4\n\n# Assumes asciidoc comments:\nblock_comment_start = ////////\nblock_comment_end = ////////\n\n[*.{yaml,yml,json}{,.in}]\nindent_style = space\nindent_size = 4\n\n################################################################\n# Primary concern: C/C++ style\n# See also docs/developers.txt => Code Style chapter\n\n[*.{c,h,cpp}{,.in}]\nspaces_around_operators = true\nspaces_around_brackets = none\n\n# Plus one TAB:\ncontinuation_indent_size = 1\n\nindent_brace_style = K&R\n\nblock_comment_start = /*\nblock_comment_end = */\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.8193359375,
          "content": "# Windows script files should be CR+LF always:\n*.bat text eol=crlf\n\n# Unix/Linux script files should be LF always:\n*.sh text eol=lf\n*.m4 text eol=lf\n*.ac text eol=lf\n*.am text eol=lf\n*.hwdb text eol=lf\n\n# Aspell claims issues finding `utf-8\\r` sometimes (from heading line of\n# the dictionary file), with messages like this:\n#   .cset\" could not be opened for reading or does not exist.lib/aspell/utf-8\n# which tends to happen in mixed-OS development environments. Tracer shows it:\n#   read(3, \"personal_ws-1.1 en 3225 utf-8\\r\\nA\"..., 4096) = 4096\n#   access(\"/usr/lib/aspell/utf-8\\r.cset\", F_OK) = -1 ENOENT (No such file or directory)\n/docs/nut.dict text eol=lf\n\n# Some files are binary always:\n*.png bin\n*.ico bin\n\n# The rest are assumed text sources with platform-dependent EOL being okay,\n# or we let Git guess otherwise:\n* text=auto\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.1376953125,
          "content": "# Backup files\n*.bak\n*~\n\n# Build process\n## Global\n*.[oa]\n*.l[oa]\n.deps/\n.libs/\n.inst/\n/tmp/\n/obj/\n/_install_pkgprotodir/\nMakefile\nMakefile.in\n\n## Parent directory only\n/aclocal.m4\n/ar-lib\n/autom4te.cache/\n/ChangeLog\n/ChangeLog.adoc\n/config.guess\n/config.log\n/config.log.inplace-outer\n/config.status\n/config.sub\n/config.h\n/config.cache\n/configure\n/config.nut_report_feature.log*\n/conf??????/\n/conf??*.file\n/dir.??????/\n/dir?.???????/\n/configure-test*/\n/confdefs.h\n/conftest.*\n/cscope.*\n/depcomp\n/INSTALL\n/INSTALL.nut\n/NEWS\n/README\n/TODO\n/UPGRADING\n/VERSION_DEFAULT\n/VERSION_FORCED\n/VERSION_FORCED_SEMVER\n/install-sh\n/libtool\n/ltmain.sh\n/missing\n/test-driver\n*-contentchecked\n*-spellchecked\n*-prepped\n*.usage-report\n*.adoc-parsed\n*.adoc*.tmp\n*.adoc*.tmp.*\n*.txt*.tmp\n*.txt*.tmp.*\n/cppcheck*.xml\n/.ci*.txt*\n/.ci*.log\n/.ci*.log.*\n.dirstamp\n*.exe\n\n# Python precompiled files\n__pycache__/\n*.pyc\n\n# Dist\n/nut-*.*.*/\n/nut-*.tar.gz\n/nut*.rpm\n/NUT*.local.gz\n/NUT*.p5i\n/NUT*.depot\n/*.msi\n/*.MSI\n\n# Official dist\n/nut-*.tar.gz.md5\n/nut-*.tar.gz.sha256\n/nut-*.tar.gz.sig\n\n# Debuggers and IDEs\n.gdb_history\n/nbproject\n/.idea\n/.vscode\n/*.iml\n\n# Coredumps\n*.stackdump\n*.core\ncore\n"
        },
        {
          "name": ".lgtm.yml",
          "type": "blob",
          "size": 0.4560546875,
          "content": "# NUT uses python scripts generated from templates saved mostly into *.py.in\npath_classifiers:\n  template:\n    - exclude: \"**/*.py.in\"\n    - exclude: \"**/NUT-Monitor*.in\"\n\nqueries:\n- exclude: cpp/fixme-comment\n- exclude: python/fixme-comment\n\nextraction:\n  python:\n    python_setup:\n      # Is there a way to LGTM both 2 and 3?..\n      version: 2\n      setup_py: false\n    index:\n      filters:\n        - include: \"**/*.py.in\"\n        - include: \"**/NUT-Monitor*.in\"\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 48.4248046875,
          "content": "# Travis CI script\n################################################################################\n# This file is based on a template used by zproject, but isn't auto-generated. #\n################################################################################\n\nlanguage:\n- c\n\ncache:\n- ccache\n\nos:\n- linux\n\nsudo: false\n\n# Tests for cppunit require C++11 which requires gcc-4.8 or newer.\n# This is available in either \"trusty\" or newer distros (e.g. \"xenial\"\n# which we also reference explicitly for additional repositories below),\n# or in \"docker\" envs.\ndist: xenial\n\nservices:\n- docker\n\n# Common required packages for all common scenarios\n# Note that YAML lists may be named with & and referenced with * characters;\n# but without such links, every list is complete and unique (meaning that\n# matrix special cases define their own settings, not append to common ones).\n# See https://github.com/travis-ci/travis-ci/issues/3505\naddons:\n  apt:\n    packages: &deps_driverlibs\n    - git\n    - ccache\n    - libcppunit-dev\n    - libcppunit-subunit-dev\n    - libneon27\n    - libneon27-dev\n    - libltdl7\n    - libltdl-dev\n    - libi2c-dev\n    - lua5.1\n    - liblua5.1-0-dev\n    - libsnmp-dev\n    - libfreeipmi-dev\n    - libipmimonitoring-dev\n    - libusb-dev\n    - linux-libc-dev\n    - libpowerman0-dev\n    - libavahi-common-dev\n    - libavahi-core-dev\n    - libavahi-client-dev\n    - libgd2-xpm-dev\n    - libpng-dev\n    - libjpeg-dev\n    - libfreetype6-dev\n    - libxpm-dev\n    - libxml2-utils\n    - libmodbus-dev\n    - libnss3-dev\n    - libssl-dev\n# NOTE: Keep the list above in sync with replicas like deps_driverlibs_cross_i386 below\n\n# Common settings for jobs in the matrix built below\nenv:\n  global:\n    - CI_TIME=true\n    - CI_TRACE=false\n    - CI_DEFAULT_HOMEBREW_NO_AUTO_UPDATE=1\n      # By default, avoid updating (including cleaning) osx worker beside what\n      # we require to install, compared to what Travis provides. Technically\n      # we can call master branch builds sometimes to update the workers cache\n      # of packages by manual or timer-driven runs with explicit setting like\n      # HOMEBREW_NO_AUTO_UPDATE=0\n\n# Builds with customized setups\n# Note that doc-related builds take the longest, and Travis CI cloud\n# runs only a few sub-jobs in parallel, so we want the withdoc and\n# perhaps spellcheck jobs to start first, and while they are still in\n# progress, others are spawned and finished - reducing overall job TTL.\n# Note that the nut-driver-enumerator tests should be tried in at least\n# the shell interpreters reasonable for default setups of Solaris/illumos\n# (ksh) and Linux (bash, dash, etc.) common distros.\n\n# First pass is a few default compilations that normally happen\n# early in Travis CI build chain\n_matrix_required_linux_pass1_quick:\n  include: &_matrix_required_linux_pass1_quick\n  - env: BUILD_TYPE=default-nodoc\n    os: linux\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: BUILD_TYPE=default-spellcheck\n    os: linux\n    addons:\n      apt:\n        packages: &deps_aspell\n        - aspell\n        - aspell-en\n\n  - env: BUILD_TYPE=default\n    os: linux\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: BUILD_TYPE=default-tgt:distcheck-light\n    os: linux\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n# Second pass is a number of shell script syntax checks in standard env:\n_matrix_required_linux_pass2_shell:\n  include: &_matrix_required_linux_pass2_shell\n  - env: BUILD_TYPE=default-shellcheck\n    os: linux\n    addons:\n      apt:\n        packages:\n        - coreutils\n        - file\n        #TBD# - shellcheck\n\n  - env: BUILD_TYPE=nut-driver-enumerator-test SHELL_PROGS=bash\n    os: linux\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - bash\n  - env: BUILD_TYPE=nut-driver-enumerator-test SHELL_PROGS=ksh\n    os: linux\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - ksh\n  - env: BUILD_TYPE=nut-driver-enumerator-test SHELL_PROGS=dash\n    os: linux\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - dash\n  - env: BUILD_TYPE=nut-driver-enumerator-test SHELL_PROGS=ash\n    os: linux\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - ash\n\n# Third pass is a number of larger builds that confirm non-core code is clean:\n_matrix_required_linux_pass3_large:\n  include: &_matrix_required_linux_pass3_large\n  - env: BUILD_TYPE=default-tgt:distcheck-valgrind\n    os: linux\n    sudo: false\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n        - valgrind\n\n  - env: BUILD_TYPE=default-withdoc\n    os: linux\n    addons:\n      apt:\n        packages: &deps_gendocs\n        - asciidoc\n        - xsltproc\n        - dblatex\n        - docbook-xsl\n        - docbook-xsl-ns\n        - source-highlight\n        - libxml2-utils\n\n  - env: BUILD_TYPE=default-alldrv\n    os: linux\n    sudo: false\n    services:\n        - docker\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env:\n    - BUILD_TYPE=default-tgt:distcheck-light\n    - NO_PKG_CONFIG=true\n    os: linux\n    sudo: true\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n# Re-run the build of all binaries we can make, with\n# varied compiler and C/C++ standard implementations\n# and different lenience against warnings. Many of\n# these blocks look similar and all should have unique\n# \"env\" field to use some with allowed_failure below.\n# For a list of standards supported, see:\n#   https://gcc.gnu.org/onlinedocs/gcc/Standards.html\n#   https://gcc.gnu.org/projects/cxx-status.html\n#   https://clang.llvm.org/cxx_status.html\n# Note that while there is C++14 there is no C14:\n#   https://en.wikipedia.org/wiki/C_(programming_language)#History\n#\n# The leading NUT_MATRIX_TAG allows humans to understand\n# what a test case is about in Travis CI dashboard table\n# of jobs, but otherwise it is not used by script code.\n#\n# Note that passing multi-token C*FLAGS may be problematic\n# for sub-makes like distcheck; verify thoroughly before\n# trying to enable those if that would make sense anytime.\n#\n# Ordered by variants expected to succeed to run first,\n# although with current Travis CI implementation, the env\n# blocks listed in allowed_failures only run after all\n# those not listed. Jobs which currently fail until code\n# gets fixed are conditional with \"if: branch =~ fightwarn\"\n# so users (and NUT upstream) can define a branch with a\n# name containing this keyword to work on bug fixes, but by\n# default the main development would not bother Travis CI\n# to waste resources in vain.\n#\n\n_matrix_linux_gnustd_nowarn:\n  include: &_matrix_linux_gnustd_nowarn\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-7-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc-7 CXX=g++-7\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-7\n        - gcc-7\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu11-gcc-7-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu11\" CXXFLAGS=\"-std=gnu++11\" CC=gcc-7 CXX=g++-7\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-7\n        - gcc-7\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-9\n        - gcc-9\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang-5.0 CXX=clang++-5.0\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-5.0\n        packages:\n        - clang-5.0\n        - clang-format-5.0\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n\n# Note: some of the warnings that are hidden in this case seem to be serious\n# issues that may impact viability of binaries built by C89 mode compilers!\n  - env: NUT_MATRIX_TAG=\"gnu89-gcc-default-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu89\" CXXFLAGS=\"-std=gnu++89\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n# Make sure we don't assume \"long int\" is a \"int64_t\" and so on\n# Seems we'd have to use tricks like 32-bit docker in 64-bit VM per\n#   https://stackoverflow.com/questions/29361465/request-for-32bit-travis-build-machine\n#   https://github.com/travis-ci/travis-ci/issues/5770#issuecomment-197771661\n#     services: docker\n#     script: \"docker run -i -v \\\"${PWD}:/MyProgram\\\" toopher/centos-i386:centos6 /bin/bash -c \\\"linux32 --32bit i386 /MyProgram/build.sh\\\"\"\n_matrix_linux_gnustd_nowarn_x86_32bit:\n  include: &_matrix_linux_gnustd_nowarn_x86_32bit\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-x86-32bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99 -m32\" CXXFLAGS=\"-std=gnu++99 -m32\" CPPFLAGS=\"-m32\" LDFLAGS=\"-m32\"\n    os: linux\n    arch: i386\n    sudo: true\n        # Perl is packaged poorly for multiarch, across several distro releases:\n        # https://bugs.launchpad.net/ubuntu/+source/pkgbinarymangler/+bug/1574351\n        # NOTE: According to https://docs.travis-ci.com/user/job-lifecycle/ the\n        # before_install phase happens AFTER addons/apt processing! So we install\n        # that big list first (except pkg's that pull perl) and add them later.\n#    before_install:\n#        - sudo dpkg --add-architecture i386 && sudo apt-get update ; yes | sudo apt-get install -y --force-yes libperl5.22:i386 || true ; sudo rm -f /usr/share/doc/libperl5.22/changelog.Debian.gz ; yes | sudo apt-get install -y --force-yes libperl5.22\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        packages: &deps_driverlibs_cross_i386\n        - git\n        - ccache\n        - gcc-multilib\n        - g++-multilib\n        - libcppunit-dev:i386\n        - libcppunit-subunit-dev:i386\n        - libneon27:i386\n        - libneon27-dev:i386\n        - libltdl7:i386\n        - libltdl-dev:i386\n        #MISSING:i386? hdr only?# - libi2c-dev:i386\n        - libi2c-dev\n        - lua5.1:i386\n        - liblua5.1-0-dev:i386\n        #PULLSPERL# - libsnmp-dev:i386\n        - libfreeipmi-dev:i386\n        - libipmimonitoring-dev:i386\n        - libusb-dev:i386\n        - linux-libc-dev:i386\n        - libpowerman0-dev:i386\n        - libavahi-common-dev:i386\n        - libavahi-core-dev:i386\n        - libavahi-client-dev:i386\n        - libgd2-xpm-dev:i386\n        - libpng-dev:i386\n        - libjpeg-dev:i386\n        - libfreetype6-dev:i386\n        - libxpm-dev:i386\n        - libxml2-utils:i386\n        - libmodbus-dev:i386\n        - libnss3-dev:i386\n        - libssl-dev:i386\n    # See comments above about perl\n    before_install: &before_install_x86_32bit\n        - sudo dpkg --add-architecture i386 && sudo apt-get update\n        - yes | sudo apt-get install -y --force-yes libperl5.22 || true\n        - sudo rm -f /usr/share/doc/libperl5.22/changelog.Debian.gz\n        - yes | sudo apt-get install -f\n        - yes | sudo apt-get install -y --force-yes libperl5.22:i386\n        - yes | sudo apt-get install -y --force-yes libsnmp-dev:i386\n        - yes | sudo apt-get remove -y --force-yes libfreetype6:amd64 || true\n        - yes | sudo apt-get remove -y --force-yes libltdl7:amd64 || true\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-x86-32bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17 -m32\" CXXFLAGS=\"-std=gnu++17 -m32\" CPPFLAGS=\"-m32\" LDFLAGS=\"-m32\" CC=clang-8 CXX=clang++-8\n    os: linux\n    arch: x86\n    dist: xenial\n    sudo: true\n    before_install:\n        - *before_install_x86_32bit\n#        - sudo dpkg --add-architecture i386 && sudo apt-get update\n#        - yes | sudo apt-get install -y --force-yes libperl5.22 || true\n#        - sudo rm -f /usr/share/doc/libperl5.22/changelog.Debian.gz\n#        - sudo apt-get install -f\n#        - yes | apt-get install -y --force-yes libperl5.22:i386\n    services:\n        - docker\n    compiler: clang\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs_cross_i386\n\n# Try s390x builds to check for issues with endianness\n# (it is one current Travis offer with BigEndian CPUs)\n_matrix_linux_gnustd_nowarn_s390x_64bit_viable:\n  include: &_matrix_linux_gnustd_nowarn_s390x_64bit_viable\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n    os: linux\n    arch: s390x\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n        - time\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n    os: linux\n    arch: s390x\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-9\n        - gcc-9\n        - *deps_driverlibs\n        - time\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    arch: s390x\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n        - time\n\n_matrix_linux_gnustd_nowarn_s390x_64bit_fatal:\n  include: &_matrix_linux_gnustd_nowarn_s390x_64bit_fatal\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-warn-s390x-64bit\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    arch: s390x\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n        - time\n\n# Try ARM builds to check for issues with non-x86 CPUs\n_matrix_linux_gnustd_nowarn_arm_64bit_viable:\n  include: &_matrix_linux_gnustd_nowarn_arm_64bit_viable\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n    os: linux\n    arch: arm64\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n    os: linux\n    arch: arm64\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-9\n        - gcc-9\n        - *deps_driverlibs\n\n_matrix_linux_gnustd_nowarn_arm_64bit_fatal:\n  include: &_matrix_linux_gnustd_nowarn_arm_64bit_fatal\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    arch: arm64\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n\n# At this time, anything with strict C standard fails on Linux, even \"nowarn\" cases:\n_matrix_linux_cstd_nowarn:\n  include: &_matrix_linux_cstd_nowarn\n  - env: NUT_MATRIX_TAG=\"c99-clang-3.5-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-3.5 CXX=clang++-3.5\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-3.5\n        packages:\n        - clang-3.5\n        - clang-format-3.5\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c99-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-5.0 CXX=clang++-5.0\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-5.0\n        packages:\n        - clang-5.0\n        - clang-format-5.0\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c11-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang-5.0 CXX=clang++-5.0\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-5.0\n        packages:\n        - clang-5.0\n        - clang-format-5.0\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c17-clang-8-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n\n# Stuff with warnings made fatal... and codebase got good enough to survive!\n_matrix_linux_gnustd_warn_viable:\n  include: &_matrix_linux_gnustd_warn_viable\n  - env: NUT_MATRIX_TAG=\"cDefault-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu11-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu11\" CXXFLAGS=\"-std=gnu++11\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-7-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc-7 CXX=g++-7\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-7\n        - gcc-7\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - ubuntu-toolchain-r-test\n        packages:\n        - g++-9\n        - gcc-9\n        - *deps_driverlibs\n\n# Stuff with warnings made fatal... well, is usually fatal so far:\n_matrix_linux_gnustd_warn_fatal:\n  include: &_matrix_linux_gnustd_warn_fatal\n# Note: Fixing these would make NUT viable again on platforms with only ANSI C!\n  - env: NUT_MATRIX_TAG=\"gnu89-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu89\" CXXFLAGS=\"-std=gnu++89\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n# The hardest of two worlds: both strict C standards on Linux and fatal warnings:\n_matrix_linux_cstd_warn:\n  include: &_matrix_linux_cstd_warn\n  - env: NUT_MATRIX_TAG=\"c99-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++98\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c99-clang-5.0-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-5.0 CXX=clang++-5.0\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-5.0\n        packages:\n        - clang-5.0\n        - clang-format-5.0\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c11-clang-5.0-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang-5.0 CXX=clang++-5.0\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-5.0\n        packages:\n        - clang-5.0\n        - clang-format-5.0\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c17-clang-8-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang-8 CXX=clang++-8\n    os: linux\n    dist: xenial\n    sudo: false\n    services:\n        - docker\n    compiler: clang\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        sources:\n        - llvm-toolchain-xenial-8\n        packages:\n        - clang-8\n        - clang-format-8\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c11-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n  - env: NUT_MATRIX_TAG=\"c89-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c89\" CXXFLAGS=\"-std=c++89\"\n    os: linux\n    sudo: false\n    services:\n        - docker\n    compiler: gcc\n    if: branch =~ fightwarn\n    addons:\n      apt:\n        packages:\n        - *deps_driverlibs\n\n_matrix_freebsd_gnustd_nowarn:\n  include: &_matrix_freebsd_gnustd_nowarn\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc CXX=g++\n    os: freebsd\n    sudo: true\n    compiler: gcc\n    cache:\n      directories:\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: freebsd\n    sudo: true\n    compiler: clang\n    cache:\n      directories:\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc CXX=g++\n    os: freebsd\n    sudo: true\n    compiler: gcc\n    cache:\n      directories:\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n    os: freebsd\n    sudo: true\n    compiler: clang\n    cache:\n      directories:\n      - $HOME/.ccache\n\n_matrix_freebsd_gnustd_warn_viable:\n  include: &_matrix_freebsd_gnustd_warn_viable\n  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc CXX=g++\n    os: freebsd\n    sudo: true\n    compiler: gcc\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-gcc-default-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc CXX=g++\n    os: freebsd\n    sudo: true\n    compiler: gcc\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/.ccache\n\n_matrix_freebsd_gnustd_warn_fatal:\n  include: &_matrix_freebsd_gnustd_warn_fatal\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: freebsd\n    sudo: true\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n    os: freebsd\n    sudo: true\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/.ccache\n\n\n# Try also a range of platforms for MacOS X builds\n# Inspired by https://github.com/taocpp/operators/blob/master/.travis.yml\n_matrix_osx_gnustd_nowarn:\n  include: &_matrix_osx_gnustd_nowarn\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode7.3-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode7.3\n    compiler: clang\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n_matrix_osx_gnustd_warn:\n  include: &_matrix_osx_gnustd_warn\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n_matrix_osx_cstd_nowarn:\n  include: &_matrix_osx_cstd_nowarn\n  - env: NUT_MATRIX_TAG=\"c99-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"c17-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n_matrix_osx_cstd_warn:\n  include: &_matrix_osx_cstd_warn\n  - env: NUT_MATRIX_TAG=\"c99-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"c17-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode10.2\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n  - env: NUT_MATRIX_TAG=\"c11-clang-xcode7.3-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang CXX=clang++\n    os: osx\n    osx_image: xcode7.3\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/Library/Caches/Homebrew\n      - $HOME/.ccache\n\n# Try also a build on Windows to see our horizons\n# https://docs.travis-ci.com/user/reference/windows/\n# says we have clang-9 there by default (and there is\n# a complex routine to add gcc if we'd need that)\n# and a Git Bash as default shell, but no ccache.\n# TODO: Eventually try native visualstudio compilers?\n_matrix_windows_gnustd_nowarn:\n  include: &_matrix_windows_gnustd_nowarn\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-win-nowarn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n    os: windows\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/AppData/Local/Temp/chocolatey\n      - $HOME/.ccache\n      - /C/tools\n\n_matrix_windows_gnustd_warn:\n  include: &_matrix_windows_gnustd_warn\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-win-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n    os: windows\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/AppData/Local/Temp/chocolatey\n      - $HOME/.ccache\n      - /C/tools\n\n_matrix_windows_cstd_nowarn:\n  include: &_matrix_windows_cstd_nowarn\n  - env: NUT_MATRIX_TAG=\"c99-clang-win-nowarn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n    os: windows\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/AppData/Local/Temp/chocolatey\n      - $HOME/.ccache\n      - /C/tools\n\n_matrix_windows_cstd_warn:\n  include: &_matrix_windows_cstd_warn\n  - env: NUT_MATRIX_TAG=\"c99-clang-win-warn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n    os: windows\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/AppData/Local/Temp/chocolatey\n      - $HOME/.ccache\n      - /C/tools\n\n# Incidentally, this is one platform we know to have clang-9,\n# the version which has (at least partial) C++20 support\n  - env: NUT_MATRIX_TAG=\"c20-clang-win-warn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c20\" CXXFLAGS=\"-std=c++20\" CC=clang CXX=clang++\n    os: windows\n    compiler: clang\n    if: branch =~ fightwarn\n    cache:\n      directories:\n      - $HOME/AppData/Local/Temp/chocolatey\n      - $HOME/.ccache\n      - /C/tools\n\n###################################################################################\n# Summarize the matrix blocks above to quickly enable/disable subsets\n# of tests in development (e.g. to focus on fixing bugs and not wasting\n# resources on rebuilding green codebase over and over)\n\n# The original set of tests that are required for master branch CI\n# ...and also the set of builds with various compilers and C standards\n# that should survive at least without warnings made fatal...\n_matrix_required_linux:\n  include: &_matrix_required_linux\n  - *_matrix_required_linux_pass1_quick\n  - *_matrix_required_linux_pass2_shell\n  - *_matrix_required_linux_pass3_large\n  - *_matrix_linux_gnustd_warn_viable\n  - *_matrix_linux_gnustd_nowarn\n  - *_matrix_linux_gnustd_nowarn_x86_32bit\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_viable\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_viable\n\n_matrix_linux_gnustd_warn:\n  include: &_matrix_linux_gnustd_warn\n  - *_matrix_linux_gnustd_warn_viable\n  - *_matrix_linux_gnustd_warn_fatal\n\n_matrix_allowfail_linux:\n  include: &_matrix_allowfail_linux\n  - *_matrix_linux_cstd_nowarn\n  - *_matrix_linux_gnustd_warn_fatal\n  - *_matrix_linux_cstd_warn\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_fatal\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_fatal\n\n_matrix_linux_gnustd_nowarn_arm_64bit:\n  include: &_matrix_linux_gnustd_nowarn_arm_64bit\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_viable\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_fatal\n\n_matrix_linux_arm:\n  include: &_matrix_linux_arm\n  - *_matrix_linux_gnustd_nowarn_arm_64bit\n\n_matrix_linux_gnustd_nowarn_s390x_64bit:\n  include: &_matrix_linux_gnustd_nowarn_s390x_64bit\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_viable\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_fatal\n\n_matrix_linux_s390x:\n  include: &_matrix_linux_s390x\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit\n\n_matrix_linux:\n  include: &_matrix_linux\n  - *_matrix_required_linux\n  - *_matrix_allowfail_linux\n\n_matrix_freebsd:\n  include: &_matrix_freebsd\n  - *_matrix_freebsd_gnustd_nowarn\n  - *_matrix_freebsd_gnustd_warn\n\n_matrix_freebsd_gnustd_warn:\n  include: &_matrix_freebsd_gnustd_warn\n  - *_matrix_freebsd_gnustd_warn_viable\n  - *_matrix_freebsd_gnustd_warn_fatal\n\n_matrix_required_freebsd:\n  include: &_matrix_required_freebsd\n  - *_matrix_freebsd_gnustd_nowarn\n  - *_matrix_freebsd_gnustd_warn_viable\n\n_matrix_allowfail_freebsd:\n  include: &_matrix_allowfail_freebsd\n  - *_matrix_freebsd_gnustd_warn_fatal\n\n_matrix_allowfail_osx:\n  include: &_matrix_allowfail_osx\n  - *_matrix_osx_cstd_nowarn\n  - *_matrix_osx_gnustd_warn\n  - *_matrix_osx_cstd_warn\n\n_matrix_required_osx:\n  include: &_matrix_required_osx\n  - *_matrix_osx_gnustd_nowarn\n\n_matrix_osx:\n  include: &_matrix_osx\n  - *_matrix_required_osx\n  - *_matrix_allowfail_osx\n\n# Nothing this good yet\n#_matrix_required_windows:\n#  include: &_matrix_required_windows\n\n_matrix_allowfail_windows:\n  include: &_matrix_allowfail_windows\n  - *_matrix_windows_gnustd_nowarn\n  - *_matrix_windows_gnustd_warn\n  - *_matrix_windows_cstd_nowarn\n  - *_matrix_windows_cstd_warn\n\n_matrix_windows:\n  include: &_matrix_windows\n#  - *_matrix_required_windows\n  - *_matrix_allowfail_windows\n\n# Different dissections of interest to fixers:\n_matrix_cstd_nowarn:\n  include: &_matrix_cstd_nowarn\n  - *_matrix_linux_cstd_nowarn\n  - *_matrix_osx_cstd_nowarn\n  - *_matrix_windows_cstd_nowarn\n\n_matrix_gnustd_nowarn:\n  include: &_matrix_gnustd_nowarn\n  - *_matrix_osx_gnustd_nowarn\n  - *_matrix_linux_gnustd_nowarn\n  - *_matrix_freebsd_gnustd_nowarn\n#  -*_matrix_windows_gnustd_nowarn\n  - *_matrix_linux_gnustd_nowarn_x86_32bit\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_viable\n  - *_matrix_linux_gnustd_nowarn_arm_64bit_fatal\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_viable\n  - *_matrix_linux_gnustd_nowarn_s390x_64bit_fatal\n\n_matrix_warn:\n  include: &_matrix_warn\n  - *_matrix_linux_gnustd_warn\n  - *_matrix_linux_cstd_warn\n  - *_matrix_freebsd_gnustd_warn\n  - *_matrix_osx_gnustd_warn\n  - *_matrix_osx_cstd_warn\n  - *_matrix_windows_gnustd_warn\n  - *_matrix_windows_cstd_warn\n\n# Default \"jobs:\" matrix should reference at least this for master branches\n_matrix_required:\n  include: &_matrix_required\n  - *_matrix_required_linux\n  - *_matrix_required_freebsd\n  - *_matrix_required_osx\n#  - *_matrix_required_windows\n\n_matrix_all:\n  include: &_matrix_all\n  - *_matrix_linux\n  - *_matrix_freebsd\n  - *_matrix_osx\n  - *_matrix_windows\n\n_matrix_master:\n  include: &_matrix_master\n  - *_matrix_required\n### Enabled for branches with names containing \"fightwarn\" to perform\n### builds that intend to actively fix the issues which preclude the\n### following items from becoming green:\n  - *_matrix_allowfail_linux\n  - *_matrix_allowfail_osx\n  - *_matrix_allowfail_freebsd\n  - *_matrix_windows\n\n_matrix_fixbugs:\n  include: &_matrix_fixbugs\n  - *_matrix_cstd_nowarn\n  - *_matrix_warn\n\n###################################################################################\n# Developers can import some of the definitions above (e.g. _matrix-fixbugs\n# instead of _matrix-master) to get more relevant runs of Travis CI against\n# their branches for their iterations trying to fix stuff.\n#\n# DO NOT COMMIT TO MASTER BRANCH TEST-MATRICES THAT ARE NOT _matrix-master!\n#\n# These days, \"jobs\" and \"matrix\" (Travis keywords) are same thing... at least,\n# ours is an explicit list.\n# By \"fast_finish\" we allow to assign a verdict based on completion of required\n# test cases. The \"allow_failures\" will proceed to run for our information\n# but should not block nor delay PR considerations etc.\njobs:\n  fast_finish: true\n  include:\n  - *_matrix_master\n\n###################################################################################\n# Note: \"env\" lines below must exactly describe a matrix option defined above\n  allow_failures:\n\n### Linux on x86_64\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-7-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc-7 CXX=g++-7\n#OK#  - env: NUT_MATRIX_TAG=\"gnu11-gcc-7-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu11\" CXXFLAGS=\"-std=gnu++11\" CC=gcc-7 CXX=g++-7\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang-5.0 CXX=clang++-5.0\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-x86-32bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99 -m32\" CXXFLAGS=\"-std=gnu++99 -m32\" CPPFLAGS=\"-m32\" LDFLAGS=\"-m32\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-x86-32bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17 -m32\" CXXFLAGS=\"-std=gnu++17 -m32\" CPPFLAGS=\"-m32\" LDFLAGS=\"-m32\" CC=clang-8 CXX=clang++-8\n  - env: NUT_MATRIX_TAG=\"c99-clang-3.5-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-3.5 CXX=clang++-3.5\n  - env: NUT_MATRIX_TAG=\"c99-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-5.0 CXX=clang++-5.0\n  - env: NUT_MATRIX_TAG=\"c11-clang-5.0-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang-5.0 CXX=clang++-5.0\n  - env: NUT_MATRIX_TAG=\"c17-clang-8-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang-8 CXX=clang++-8\n  - env: NUT_MATRIX_TAG=\"c17-clang-8-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang-8 CXX=clang++-8\n#OK#  - env: NUT_MATRIX_TAG=\"cDefault-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n  - env: NUT_MATRIX_TAG=\"c99-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++98\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-7-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc-7 CXX=g++-7\n  - env: NUT_MATRIX_TAG=\"c99-clang-5.0-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang-5.0 CXX=clang++-5.0\n  - env: NUT_MATRIX_TAG=\"c11-clang-5.0-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang-5.0 CXX=clang++-5.0\n  - env: NUT_MATRIX_TAG=\"c11-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu11-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu11\" CXXFLAGS=\"-std=gnu++11\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu89-gcc-default-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu89\" CXXFLAGS=\"-std=gnu++89\"\n  - env: NUT_MATRIX_TAG=\"c89-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c89\" CXXFLAGS=\"-std=c++89\"\n  - env: NUT_MATRIX_TAG=\"gnu89-gcc-default-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu89\" CXXFLAGS=\"-std=gnu++89\"\n\n### Linux on s390x (BigEndian)\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-s390x-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-warn-s390x-64bit\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n\n### Linux on ARM\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\"\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-9-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc-9 CXX=g++-9\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-8-nowarn-ARM-64bit\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang-8 CXX=clang++-8\n\n### FreeBSD on x86_64\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc CXX=g++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-clang-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++17\" CC=gcc CXX=g++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-clang-freebsd-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-gcc-default-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++98\" CC=gcc CXX=g++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-gcc-default-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=gcc CXX=g++\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-freebsd-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n\n### macosx\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu17-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n#OK#  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode7.3-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"gnu17-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=gnu17\" CXXFLAGS=\"-std=gnu++17\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c99-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c99-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c17-clang-xcode10.2-nowarn\" BUILD_TYPE=default-all-errors CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c17-clang-xcode10.2-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c17\" CXXFLAGS=\"-std=c++17\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c11-clang-xcode7.3-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c11\" CXXFLAGS=\"-std=c++11\" CC=clang CXX=clang++\n\n### windows on x86_64\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-win-nowarn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" CFLAGS=\"-std=gnu99\" CXXFLAGS=\"-std=gnu++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"gnu99-clang-win-warn\" BUILD_TYPE=default-all-errors BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c99-clang-win-nowarn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c99-clang-win-warn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c99\" CXXFLAGS=\"-std=c++99\" CC=clang CXX=clang++\n  - env: NUT_MATRIX_TAG=\"c20-clang-win-warn\" BUILD_TYPE=default-all-errors CPPFLAGS=\"-fms-extensions\" BUILD_WARNFATAL=yes BUILD_WARNOPT=hard CFLAGS=\"-std=c20\" CXXFLAGS=\"-std=c++20\" CC=clang CXX=clang++\n\nbefore_install:\n- |-\n  if [ $TRAVIS_OS_NAME = \"osx\" ] ; then\n    [ -n \"$HOMEBREW_NO_AUTO_UPDATE\" ] || HOMEBREW_NO_AUTO_UPDATE=\"$CI_DEFAULT_HOMEBREW_NO_AUTO_UPDATE\"\n    if [ \"$HOMEBREW_NO_AUTO_UPDATE\" = 1 ] ; then\n        echo \"NOT CALLING 'brew update' as it takes too long and cleans up preinstalled env\"\n        export HOMEBREW_NO_AUTO_UPDATE\n    else\n        unset HOMEBREW_NO_AUTO_UPDATE\n        brew update\n    fi\n    brew install binutils ccache gd\n    if [ \"$BUILD_TYPE\" = default-withdoc ] ; then\n        brew install asciidoc docbook-xsl\n        XML_CATALOG_FILES=/usr/local/etc/xml/catalog\n        export XML_CATALOG_FILES\n    fi\n  fi\n\n# Please forgive the funny syntax below to dance around\n# both YAML escaping and windows-acceptable shell syntax\n- |-\n    if [[ $TRAVIS_OS_NAME == \"windows\" ]] ; then\n        if [[ ! -s C:/tools/cygwin/bin/autoreconf.exe ]] ; then\n            if [[ ! -s C:/tools/cygwin/bin/autoreconf ]] ; then\n                choco install cygwin\n                C:\\\\tools\\\\cygwin\\\\cygwinsetup.exe -q -P make,unzip,automake,autoconf,zip\n            fi\n        fi\n        if [[ ! -s C:/tools/bin/ccache.exe ]] ; then\n            mkdir -p C:/tools/bin/\n            pushd C:/tools/bin/ || exit\n                wget https://github.com/ccache/ccache/releases/download/v3.7.12/ccache-3.7.12-windows-64.zip || exit\n                7z e -y ccache-3.7.12-windows-64.zip || exit\n                rm -f ccache-3.7.12-windows-64.zip\n            popd\n        fi\n        export PATH=/C/tools/bin:/cygdrive/c/tools/bin:$PATH:/C/tools/cygwin/bin:/cygdrive/c/tools/cygwin/bin\n        CI_TRACE=true\n        CI_TIME=false\n        ( echo \"user::rwx\"\n          echo \"group::r--\"\n          echo \"mask:rwx\"\n          echo \"other:r--\"\n        ) > /tmp/faclx\n        if ! setfacl -f /tmp/faclx /cygdrive/c/tools/cygwin/*bin/* ; then\n            setfacl -f /tmp/faclx /C/tools/cygwin/*bin/*\n        fi\n    fi\n- if [ \"$TRAVIS_OS_NAME\" = \"freebsd\" ] ; then sudo pkg install -y libgd ; fi\n- if [ -n \"${NUT_MATRIX_TAG}\" ] ; then export CFLAGS CXXFLAGS ; [ -z \"$CC\" ] || export CC ; [ -z \"$CXX\" ] || export CXX ; fi\n\n# Hand off to generated script for each BUILD_TYPE\nscript: ./ci_build.sh\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 5.0947265625,
          "content": "# The NUT AUTHORS file.  Don't be shy.  If you have contributed to this\n# project in some way, send me a patch to add yourself to this file.\n#\n# Everyone deserves credit, including those who haven't added any code.\n# Ideas, clues, and helping out on the mailing lists all count too.\n#\n# This is a blatant ripoff of the fields found in the Linux kernel's CREDITS\n# file.  If we need more data, those fields can always be added later.\n#\n# N = name, E = email, W = web address, D = description, P = PGP info,\n# S = snailmail address, etc.\n#\n# This file is supposed to be roughly alpha-sorted by the last name, but\n# if you want to hide at the bottom, that's fine by me.  Just clarify\n# your preference when submitting changes to this file.\n\nN: Axel Gembe\nE: axel@gembe.net\nW: http://axel.gembe.net/\nD: Added APC Modbus support\nP: rsa4096/43109AAC 11E6 515C B8A4 26C6 07C1  36A4 1CB3 AA21 4310 9AAC\n\nN: Stephen Brown\nE: steve@datalimbo.net\nW: http://www.datalimbo.net/\nD: Hacked genericups to add TrippLite Lan2.x support (Internet Office 700)\n\nN: Bill Carlson\nE: wcarlson@wkks.org\nW: http://wkks.org/\nD: Fixed the GD/configure problem\n\nN: Ben Collver\nE: collver@softhome.net\nW: http://superfluous.oddbox.org\nD: Beginning support for HPUX 10.20 and Windows 2000\n\nN: Luca Filipozzi\nE: lfilipoz@debian.org\nD: Original Debian maintainer for nut package. Minor patches to source.\n\nN: Matthew Gabeler-Lee\nE: msg2@po.cwru.edu\nW: http://cheetah.cwru.edu\nD: Added custom formatting to upslog\nD: Helped get apcsmart working with old SmartUPS models\n\nN: David Goncalves\nE: david@lestat.st\nW: http://www.lestat.st\nD: Python client support (PyNUT module and NUT-Monitor application)\n\nN: Bruno Hall\nD: Contributed UPS compatibility information\n\nN: Bo Kersey - VirCIO - Managed Server Solutions\nE: bo@vircio.com\nW: http://www.vircio.com/\nD: Provided a Best Fortress for development of a Best driver (bestups)\n\nN: Russell Kroll\nE: rkroll@exploits.org\nW: https://www.networkupstools.org/\nD: Original NUT author and coordinator\nP: 1024D/9DC0E77E 6A5C 7D2D 7945 C022 6104  D421 D61D C97F 9DC0 E77E\n\nN: Rick Lyons\nE: rick@powerup.com.au\nD: Support for Liebert UPSes using MultiLink cable\n\nN: Jeremy Maccelari\nE: visualn@iafrica.com, jeremy@visuals.co.za\nW: http://www.visuals.co.za\nD: Support for Mustek UPSes\n\nN: Philippe Marzouk\nE: philm@users.sourceforge.net\nD: Support for MGE Pulsar Ellipse UPSes ; co author of mge-shut\n\nN: Theodor A. Milkov\nE: zimage@delbg.com\nW: http://www.delbg.com/~zimage/\nD: Adding support for Repotec's RPT-800A, RPT-162A to genericups driver.\n\nN: Mark Powell\nE: medp@primagraphics.co.uk\nD: Ported to SunOS4\n\nN: Arnaud Quette\nE: aquette.dev@gmail.com\nE: arnaud.quette@mgeups.com\nE: aquette@debian.org\nW: http://arnaud.quette.free.fr/\nD: Primary coordinator ; author of snmp-ups, mge-shut, usbhid-ups ;\nD: co author of mge-utalk, hidups, SNMP UPS Agent ; contributor to blazer,\nD: bestferrups, nut core, and many others ; coordination with MGE UPS\nD: SYSTEMS, linux-usb developers (for hidups), Net SNMP and packagers\nD: (Mandriva, Debian, SuSE, ...)...\nP: 1024D/204DDF1B 1371 07DF 3CF3 9160 7905  144B DB64 14CA 204D DF1B\n\nN: Lars Balker Rasmussen\nE: lbr@mjolner.dk\nD: Solaris and minor patches\n\nN: David Santinoli\nE: david@santinoli.com\nW: http://www.santinoli.com\nD: Support for Online P-series in genericups driver\n\nN: Jacob Schmier\nE: j.schmier@live.com\nD: support for Universal-Mount ON Series UPS family in oneac driver\n\nN: Peter Selinger\nE: selinger@users.sourceforge.net\nW: http://www.mathstat.dal.ca/~selinger/\nD: wrote belkinunv driver, contributions to usbhid-ups\nP: 1024D/CA31696A 12A2 4B3C 3790 B688 E484  7A98 A68B CC37 CA31 696A\n\nN: Kirill Smelkov\nE: kirr@mns.spb.ru\nD: Author of al175\n\nN: John Stone\nE: johns@megapixel.com\nW: http://www.megapixel.com/\nD: Support for Best MicroFerrups UPS\n\nN: Technorama Ltd.\nE: oss-list-ups@technorama.net\nD: common driver core design, redundant code elimination, security fixes\nD: other misc patches and improvements throughout\n\nN: Jason Thomas\nE: jason@topic.com.au\nW: http://www.topic.com.au/\nD: Hacked up the UPSonic Driver.\n\nN: Simon Rozman\nE: simon@rozman.net\nW: http://simon.rozman.net/\nD: Hacked powercom to add Socomec Sycon Egys 420 VA support\n\nN: Len J White\nE: lwhite@darkfires.net\n\nN: Walt Holman\nE: walt_h@lorettotel.net\nD: Hacked up the cpsups driver for CyberPower text protocol UPSes\n\nN: Fabio Di Niro\nE: blaxwan@users.sourceforge.net\nD: Author of metasys driver, support for Meta System UPS\n\nN: Arjen de Korte\nE: arjen@de-korte.org\nD: Author of safenet driver\nP: 1024R/AEF3BA11 664E 032C 9DB5 CB9B 7AFE 7EC1 EE88 BC57\n\nN: Håvard Lygre\nE: hklygre@online.no\nD: First stab at upscode2 driver for NUT 1.4\n\nN: Niels Baggesen\nE: niels@baggesen.net\nD: upgraded the upscode2 driver to NUT-2, and extended it heavily.\n\nN: Niklas Edmundsson\nE: nikke@acc.umu.se\nD: 3-phase work, updates for upscode2\n\nN: Olli Savia\nE: ops@iki.fi\nD: pwmib support for snmp-ups\n\nN: Kjell Claesson\nE: Kjell.claesson@epost.tidanet.se\nD: Author of bcmxcp driver, 3-phase work.\n\nN: Giuseppe Corbelli\nE: giuseppe.corbelli@copanitalia.com\nD: Author of asem driver\n\nN: zakx\nE: zakx@zakx.de\nD: Updating device support docs after unnecessarily writing a redundant\nD: driver first\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 2.6220703125,
          "content": "\n Most files are licensed under the GNU General Public License (GPL) version 2,\n or (at your option) any later version. See \"LICENSE-GPL2\" in the root of this\n distribution.\n\n The scripts/python/module/nut_telnetlib.py file is copied for fall-back\n purposes from Python 3.10, and released under its original license (the\n PSF License Version 2). It was only modified in the comment section to\n describe the copy, purpose and provenance per section 3 of the license.\n According to https://github.com/python/cpython/blob/3.10/LICENSE most of\n the licenses Python was provided under over the years are GPL-compatible.\n\n Other files in the scripts/python/ directory are released under GNU General\n Public License (GPL) version 3, or (at your option) any later version. See\n \"LICENSE-GPL3\" in the root of this distribution.\n\n The Perl client module (scripts/perl/Nut.pm) is released under the same\n license as Perl itself. That is to say either GPL version 1 or (at your option)\n any later version, or the \"Artistic License\".\n\n The scripts/installer contents were donated to the Network UPS Tools project\n by Eaton in 2022, including the license change from the one originally used\n with their software companion to terms of the open-source project (that is,\n GPL version 2 or newer).\n\n Several fallback implementations for methods absent from standard library of\n an end-user's current build platform are derived from source code available\n under the two-clause BSD license (common/strptime.c, common/strnlen.c)\n\n Various methods may be adapted from code or ideas posted on Stack Exchange\n sites (comments in NUT sources refer to original posts in this case), which\n according to https://stackoverflow.com/help/licensing are made available under\n different Creative Commons Attribution-ShareAlike license (CC BY-SA) versions\n depending on contribution timestamp.\n\n Several autoconf methods under m4/ directory are derived from curl codebase\n and were originally available under curl license. Which is not unlike the MIT\n license, see https://daniel.haxx.se/blog/2022/06/17/curl-is-reuse-compliant/\n\n To the best of our knowledge, conditions of the 2/3-clause BSD, MIT, curl and\n CC BY-SA licenses allow redistribution and reuse of the codebase in projects\n made available under GPL license terms, as long as attribution is provided.\n\n NUT contributors are encouraged to \"sign off\" their git commits as a conscious\n act done under Developer's Certificate of Origin. See the copy of \"LICENSE-DCO\"\n in the root of this distribution, but please note that it is not a \"license\" on\n its own - rather a proclamation that work was done and submitted according to\n applicable open-source licenses.\n"
        },
        {
          "name": "INSTALL.nut.adoc",
          "type": "blob",
          "size": 33.05859375,
          "content": "Installation instructions\n=========================\n// NOTE: No blank line here, document-header include processing should kick in!\n//GH_MARKUP_1095//ifdef::top_srcdir[]\n//GH_MARKUP_1095//include::{top_srcdir}docs/asciidoc-vars.conf[]\n//GH_MARKUP_1095//endif::top_srcdir[]\n//GH_MARKUP_1095//ifndef::top_srcdir[]\n//GH_MARKUP_1095//include::docs/asciidoc-vars.conf[]\n//GH_MARKUP_1095//endif::top_srcdir[]\n//GH_MARKUP_1095_INCLUDE_BEGIN//7e01bd198 (2024-10-20) docs/asciidoc-vars.conf: try defining linksrcdoc macro\nifndef::asciidoc-vars-nut-included[]\n:asciidoc-vars-nut-included:\ttrue\n// NOTE: The big block of comments and definitions below comes from\n// NUT::docs/asciidoc-vars.conf and is included into top-level document\n// sources by maintenance recipes directly (`make maintainer-asciidocs`),\n// due to current limitations of the GitHub Web UI asciidoc renderer.\n// Hopefully it can be dropped in favor of compact include definitions\n// (see README.adoc for anticipated example) after this issue is resolved\n// on their side:\n// * https://github.com/github/markup/issues/1095\n//\n// This file should be included into NUT documentation sources to consistently\n// define certain expandable attributes, with contents defined based on the\n// rendition target (e.g. GitHub Web UI, plain text, locally built HTML/PDF...)\n// Note that currently GitHub Web UI references lead to nut-website (as of\n// last built and published revision), not to neighboring documents in the\n// source browser (which would make sense for branch revisions, etc.) due\n// to certain complexity about referencing other-document sections with a\n// partially functional rendering engine there. Exploration and fixes are\n// welcome (actually working links like\n// https://github.com/networkupstools/nut/tree/master#installing or\n// https://github.com/networkupstools/nut/blob/master/UPGRADING.adoc#changes-from-274-to-280\n// do seem promising)!\n//\n// Since the GitHub UI does not allow use of custom asciidoc configuration\n// files, or generally does not process the `include:` requests at this time,\n// clumsy expandable attributes had to be used (usually a set including a\n// prefix with meaningful name, and one or more separators and/or a suffix\n// with shortened names). For our classic documentation renditions, they\n// should resolve to properly defined macros from `docs/asciidoc.conf`\n// (usually named same as the variables defined here, for simplicity):\n// * `linksrcdoc` allows to refer to a source of documentation file\n//   relative to the root of NUT code base.\n// * `linkdoc` allows to refer to a file under `docs/` directory (or\n//   its nut-website rendition).\n// * `xref` substitutes the asciidoc shorthand '<< >>' syntax with\n//   attributes that conditionally expand to:\n//   - links on GitHub (references can point at most to a section of\n//     level docs/common.xsl's <chunk.section.depth>), or\n//   - xref asciidoc macros when generating docs.\n// * `linksingledoc` guarantees that, when chunked HTML is generated,\n//   the link always points to a non-chunked file.\n// * `linkman2` allows to support different names for the manpage and\n//   the command shown. This is also needed to properly display links\n//   to manpages in both GitHub and generated docs without defining an\n//   attribute for each manpage.\n//\n// Optional attributes set by callers:\n// * `website-url` (defaulted below) may be used for \"historic website\"\n//   snapshot builds... hopefully\n// * `website` is used as a boolean toggle in our recipes for nut-website\n//   vs. offline documentation renditions\n// * `env-github` is used as a boolean toggle, set by GitHub Web-UI renderer\n// * `(top_)srcdir` and `(top_)builddir` can be set by `Makefile.am`\n//   calling the `a2x` tool, since some of the files with the asciidoc\n//   mark-up are only generated or post-processed during build and\n//   (due to `make dist` restrictions) being build products, they may\n//   not reside in same directory as static source text files which\n//   reference or include them. Note that the non-`top` paths would\n//   normally differ based on location of the `Makefile` involved\n//   (e.g. workspace root, or the `docs`, or `docs/man` directories).\n//   These variables are expected to be absolute paths, or ones relative\n//   to asciidoc-selected `:base_dir`, and to end with a relevant path\n//   separator, or be empty -- so in all cases letting the resulting\n//   string resolve meaningfully in the filesystem during docs build.\n//\n// Please keep the remaining comments and definitions as one big block\n// so it does not become a series of empty paragraphs in the rendered\n// documents!\n//\nifndef::website-url[]\n:website-url:\thttps://www.networkupstools.org/\nendif::website-url[]\n//\nifndef::srcdir[]\n:srcdir:\nendif::srcdir[]\n//\nifndef::builddir[]\n:builddir:\nendif::builddir[]\n//\nifndef::top_srcdir[]\n:top_srcdir:\nendif::top_srcdir[]\n//\nifndef::top_builddir[]\n:top_builddir:\nendif::top_builddir[]\n//\n//\n// Address links on GitHub vs. docs\n// (note: 'env-github' attribute is set on GitHub)\n//\n// - when generating docs:\nifndef::env-github[]\n//   * xref -> xref\n//     syntax: {xref}<id>{x-s}[<caption>]\n//     -> xref:<id>[<caption>]\n:xref:\t\txref:\n:x-s:\n//   * link to doc -> our macro\n//     syntax: {linksrcdoc}<document>\n//     -> linksrcdoc:<document>[]\n:linksrcdoc:\tlinksrcdoc:\n//   * link to doc -> our macro\n//     syntax: {linkdoc}<document>{ld-s}[<display title>]\n//     -> linkdoc:<document>[<display title>]\n:linkdoc:\tlinkdoc:\n:ld-s:\n//   * link to single doc -> our macro\n//     syntax: {linksingledoc}<document>{lsd-s}[<display title>]\n//     -> linksingledoc:<document>[<display title>]\n:linksingledoc:\tlinksingledoc:\n:lsd-s:\n//   * link to manpage -> our macro\n//     syntax: {linkman2}<command-page>{lm-s}<displayed-command>{lm-c}<manpage-section>{lm-e}\n//     -> linkman2:<command-page>[<displayed-command>,<manpage-section>]\n:linkman2:\tlinkman2:\n:lm-s:\t\t[\n:lm-c:\t\t,\n:lm-e:\t\t]\nendif::env-github[]\n//\n// - on GitHub:\nifdef::env-github[]\n//     In our normal builds, Makefile variables convey the needed paths\n//     (used relatively below as `image:images/ci/...png` etc.)\n:imagesdir:\tdocs\n//   * xref -> link\n//     syntax: {xref}<id>{x-s}[<caption>]\n//     In order for it to work, <id> can reference at most a section of\n//     level docs/common.xsl's <chunk.section.depth>\n//     -> {website-url}docs/user-manual.chunked/<id>.html[<caption>]\n:xref:\t\t{website-url}docs/user-manual.chunked/\n:x-s:\t\t.html\n//   * link to doc -> our macro\n//     syntax: {linksrcdoc}<document>\n//     -> link:<document>[]\n:linksrcdoc:\tlink:{top_srcdir}/\n//   * link to doc -> link\n//     syntax: {linkdoc}<document>{ld-s}[<display title>]\n//     -> {website-url}docs/<document>.chunked/index.html[<display title>]\n:linkdoc:\t{website-url}docs/\n:ld-s:\t\t.chunked/index.html\n//   * link to single doc -> link\n//     syntax: {linksingledoc}<document>{lsd-s}[<display title>]\n//     -> {website-url}docs/<document>.html[<display title>]\n:linksingledoc:\t{website-url}docs/\n:lsd-s:\t\t.html\n//   * link to manpage -> link\n//     syntax: {linkman2}<command-page>{lm-s}<displayed-command>{lm-c}<manpage-section>{lm-e}\n//     All the fields are mandatory.\n//     -> {website-url}docs/man/<command-page>.html[<displayed-command>(<manpage-section>)]\n:linkman2:\t{website-url}docs/man/\n:lm-s:\t\t.html[\n:lm-c:\t\t(\n:lm-e:\t\t)]\nendif::env-github[]\nendif::asciidoc-vars-nut-included[]\n//\n//GH_MARKUP_1095_INCLUDE_END//\n\nThis chapter describes the various methods for installing Network UPS Tools.\n\nWhenever it is possible, prefer <<Installing_packages, installing from packages>>.\nPackagers have done an excellent and hard work at improving NUT integration\ninto their operating system.  On the other hand, distributions and appliances\ntend to package \"official releases\" of projects such as NUT, and so do not\ndeliver latest and greatest fixes, new drivers, bugs and other features.\n\n[[Installing_source]]\nInstalling from source\n----------------------\n\nThese are the essential steps for compiling and installing this software\nfrom distribution archives (usually \"release tarballs\") which include a\npre-built copy of the `configure` script and some other generated source\nfiles.\n\nTo build NUT from a Git checkout you may need some additional tools\n(referenced just a bit below) and run `./autogen.sh` to generate the\nneeded files. For common developer iterations, porting to new platforms,\nor in-place testing, running the `./ci_build.sh` script can be helpful.\nThe \"<<Installing_inplace,Building NUT for in‐place upgrades or non‐disruptive\ntests>>\" section details some more hints about such workflow, including some\n`systemd` integration.\n\nThe NUT linkdoc:packager-guide[Packager Guide], which presents the best\npractices for installing and integrating NUT, is also a good reading.\n\nThe <<Config_Prereqs,Prerequisites for building NUT on different OSes>>\ndocument suggests prerequisite packages with tools and dependencies\navailable and needed to build and test as much as possible of NUT on\nnumerous platforms, written from perspective of CI testing (if you\nare interested in getting updated drivers for a particular device,\nyou might select a sub-set of those suggestions).\n\nNOTE: This \"Config Prereqs\" document for latest NUT iteration can be found at\nhttps://github.com/networkupstools/nut/blob/master/docs/config-prereqs.txt\nor as `docs/config-prereqs.txt` in your build workspace (from Git or tarball).\n\n[NOTE]\n.Keep in mind that...\n================================================================================\n\n- the paths shown below are the default values you get by just calling\n  configure by itself.  If you have used --prefix or similar, things will be\n  different.  Also, if you didn't install this program from source yourself,\n  the paths will probably have a number of differences.\n\n- by default, your system probably won't find the man pages, since they\n  install to /usr/local/ups/man.  You can fix this by editing your MANPATH,\n  or just do this:\n\n\tman -M /usr/local/ups/man <man page>\n\n- if your favorite system offers up to date binary packages, you should\n  always prefer these over a source installation (unless there are known\n  deficiencies in the package or one is too obsolete). Along with the known\n  advantages of such systems for installation, upgrade and removal, there\n  are many integration issues that have been addressed.\n\n================================================================================\n\n\nPrepare your system\n~~~~~~~~~~~~~~~~~~~~\n\nSystem User creation\n^^^^^^^^^^^^^^^^^^^^\n\nCreate at least one system user and a group for running this software.\nYou might call them \"ups\" and \"nut\".  The exact names aren't important as\nlong as you are consistent.\n\nThe process for doing this varies from one system to the next, and\nexplaining how to add users is beyond the scope of this document.\n\nFor the purposes of this document, the user name and group name\nwill be 'ups' and 'nut' respectively.\n\nBe sure the new user is a member of the new group!  If you forget to\ndo this, you will have problems later on when you try to start upsd.\n\n\nBuild and install\n~~~~~~~~~~~~~~~~~\n\nNOTE: See also <<Installing_inplace,Building NUT for in‐place upgrades\nor non‐disruptive tests>>.\n\n[[Configuration]]\nConfiguration\n^^^^^^^^^^^^^\n\nConfigure the source tree for your system.  Add the '--with-user' and\n'--with-group' switch to set the user name and group that you created\nabove.\n\n\t./configure --with-user=ups --with-group=nut\n\nIf you need any other switches for configure, add them here.  For example:\n\n* to build and install USB drivers, add '--with-usb' (note that you\n  need to install libusb development package or files).\n\n* to build and install SNMP drivers, add '--with-snmp' (note that\n  you need to install libsnmp development package or files).\n\n* to build and install CGI scripts, add '--with-cgi'.\n\nSee <<Configure_options,Configure options>> from the User Manual,\ndocs/configure.txt or './configure --help' for all the available\noptions.\n\nIf you alter paths with additional switches, be sure to use those\nnew paths while reading the rest of the steps.\n\nReference: <<Configure_options,Configure options>> from the\nUser Manual.\n\n\nBuild the programs\n^^^^^^^^^^^^^^^^^^\n\n\tmake\n\nThis will build the NUT client and server programs and the\nselected drivers. It will also build any other features that were\nselected during <<Configuration,configuration>> step above.\n\n\nInstallation\n^^^^^^^^^^^^\n\n[NOTE]\n=====================================================================\n\nyou should now gain privileges for installing software if necessary:\n\n\tsu\n\n=====================================================================\n\nInstall the files to a system level directory:\n\n\tmake install\n\nThis will install the compiled programs and man pages, as well as\nsome data files required by NUT. Any optional features selected\nduring configuration will also be installed.\n\nThis will also install sample versions of the NUT configuration\nfiles. Sample files are installed with names like ups.conf.sample\nso they will not overwrite any existing real config files you may\nhave created.\n\nIf you are packaging this software, then you will probably want to\nuse the DESTDIR variable to redirect the build into another place,\ni.e.:\n\n\tmake DESTDIR=/tmp/package install\n\tmake DESTDIR=/tmp/package install-conf\n\n[[StatePath]]\nState path creation\n^^^^^^^^^^^^^^^^^^^\n\nCreate the state path directory for the driver(s) and server to use\nfor storing UPS status data and other auxiliary files, and make it\ngroup-writable by the group of the system user you created.\n\n\tmkdir -p /var/state/ups\n\tchmod 0770 /var/state/ups\n\tchown root:nut /var/state/ups\n\n[[Ownership]]\nOwnership and permissions\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSet ownership data and permissions on your serial or USB ports\nthat go to your UPS hardware.  Be sure to limit access to just\nthe user you created earlier.\n\nThese examples assume the second serial port (ttyS1) on a typical\nSlackware system.  On FreeBSD, that would be cuaa1.  Serial ports\nvary greatly, so yours may be called something else.\n\n\tchmod 0660 /dev/ttyS1\n\tchown root:nut /dev/ttyS1\n\n////////////////////////////////////////////////////////////////////////////////\nFIXME: TBR\n////////////////////////////////////////////////////////////////////////////////\n\nThe setup for USB ports is slightly more complicated. Device files\nfor USB devices, such as /proc/bus/usb/002/001, are usually\ncreated \"on the fly\" when a device is plugged in, and disappear\nwhen the device is disconnected.  Moreover, the names of these\ndevice files can change randomly. To set up the correct\npermissions for the USB device, you may need to set up (operating\nsystem dependent) hotplugging scripts.  Sample scripts and\ninformation are provided in the scripts/hotplug and\nscripts/udev directories. For most users, the hotplugging scripts\nwill be installed automatically by \"make install\".\n\n(If you want to try if a driver works without setting up\nhotplugging, you can add the \"-u root\" option to upsd, upsmon, and\ndrivers; this should allow you to follow the below\ninstructions. However, don't forget to set up the correct\npermissions later!).\n\nNOTE: if you are using something like udev or devd, make sure\nthese permissions stay set across a reboot.  If they revert to the\nold values, your drivers may fail to start.\n\n\nYou are now ready to configure NUT, and start testing and using it.\n\nYou can jump directly to the <<Configuration_notes,NUT configuration>>.\n\n[[Installing_inplace]]\nBuilding NUT for in‐place upgrades or non‐disruptive tests\n----------------------------------------------------------\n\nNOTE: The NUT GitHub Wiki article at\nhttps://github.com/networkupstools/nut/wiki/Building-NUT-for-in%E2%80%90place-upgrades-or-non%E2%80%90disruptive-tests\nmay contain some more hints as contributed by the community.\n\nOverview\n~~~~~~~~\n\nSince late 2022/early 2023 NUT codebase supports \"in-place\" builds\nwhich try their best to discover the configuration of an earlier build\n(configuration and run-time paths and OS accounts involved, maybe an\nexact configuration if stored in deployed binaries).\n\nThis optional mode is primarily intended for several use-cases:\n\n* Test recent GitHub \"master\" branch or a proposed PR to see if it\n  solves a practical problem for a particular user;\n* Replace an existing deployment, e.g. if OS-provided packages deliver\n  obsolete code, to use newer NUT locally in \"production mode\".\n  - In such cases ideally get your distribution, NAS vendor, etc.\n    to provide current NUT -- and benefit from a better integrated\n    and tested product.\n\nNote that \"just testing\" often involves building the codebase and new\ndrivers or tools in question, and running them right from the build\nworkspace (without installing into the system and so risking an\nunpredictable-stability state). In case of testing new driver builds,\nnote that you would need to stop the normally running instances to\nfree up the communications resources (USB/serial ports, etc.), run the\nnew driver program in data-dump mode, and restart the normal systems\noperations.\n\nSuch tests still benefit from matching the build configuration to what\nis already deployed, in order to request same configuration files and\nsystem access permissions (e.g. to own device nodes for physical-media\nports involved, and to read the production configuration files).\n\nPre-requisites\n^^^^^^^^^^^^^^\n\nThe <<Config_Prereqs,Prerequisites for building NUT on different OSes>>\ndocument details tools and dependencies that were added on NUT CI build\nenvironments, which now cover many operating systems. This should\nprovide a decent starting point for the build on yours (PRs to update\nthe document are welcome!)\n\nNote that unlike distribution tarballs, Git sources do not include a\n`configure` script and some other files -- these should be generated by\nrunning `autogen.sh` (or `ci_build.sh` that calls it).\n\nGetting the right sources\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nTo build the current tip of development iterations (usually after PR\nmerges that passed CI, reviews and/or other tests), just clone the NUT\nrepository and \"master\" branch should get checked out by default (also\ncan request that explicitly, per example posted below).\n\nIf you want to quickly test a particular pull request, see the link on\ntop of the PR page that says `... wants to merge ... from : ...` and\ncopy the proposed-source URL of that \"from\" part.\n\nFor example, in some PR this says `jimklimov:issue-1234` and links to\n`https://github.com/jimklimov/nut/tree/issue-1234`.\nFor manual git-cloning, just paste that URL into the shell and replace\nthe `/tree/` with \"`-b`\" CLI option for branch selection, like this:\n\n\t:; cd /tmp\n\t### Checkout https://github.com/jimklimov/nut/tree/issue-1234\n\t:; git clone https://github.com/jimklimov/nut -b issue-1234\n\nTesting with CI helper\n~~~~~~~~~~~~~~~~~~~~~~\n\nNOTE: this uses the `ci_build.sh` script to arrange some rituals and\nsettings, in this case primarily to default the choice of drivers to\nauto-detection of what can be built, and to skip building documentation.\nAlso note that this script supports many other scenarios for CI and\ndevelopers, managed by `BUILD_TYPE` and other environment variables,\nwhich are not explored here.\n\nAn \"in-place\" _testing_ build and run would probably go along these lines:\n\n\t:; cd /tmp\n\t:; git clone -b master https://github.com/networkupstools/nut\n\t:; cd nut\n\t:; ./ci_build.sh inplace\n\t### Temporarily stop your original drivers\n\t:; ./drivers/nutdrv_qx -a DEVNAME_FROM_UPS_CONF -d1 -DDDDDD \\\n\t    # -x override...=... -x subdriver=...\n\t### Can start back your original drivers\n\t### Analyze and/or post back the data-dump\n\n[NOTE]\n======\nTo probe a device for which you do not have an `ups.conf` section\nyet, you must specify `-s name` and all config options (including\n`port`) on command-line with `-x` arguments, e.g.:\n\n\t:; ./drivers/nutdrv_qx -s temp-ups \\\n\t    -d1 -DDDDDD -x port=auto \\\n\t    -x vendorid=... -x productid=... \\\n\t    -x subdriver=...\n======\n\nReplacing a NUT deployment\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWhile `ci_build.sh inplace` can be a viable option for preparation of\nlocal builds, you may want to have precise control over `configure`\noptions (e.g. choice of required drivers, or enabled documentation).\n\nA sound starting point would be to track down packaging recipes used by\nyour distribution (e.g.\nlink:https://src.fedoraproject.org/rpms/nut/blob/rawhide/f/nut.spec[RPM spec]\nor\nlink:https://salsa.debian.org/debian/nut/-/blob/debian/debian/rules[DEB rules]\nfiles, etc.) to detail the same paths if you intend to replace those,\nand copy the parameters for `configure` script from there -- especially\nif your system is not currently running NUT v2.8.1 or newer (which embeds\nthis information to facilitate in-place upgrade rebuilds).\n\nNote that the primary focus of in-place automated configuration mode is\nabout critical run-time options, such as OS user accounts, configuration\nlocation and state/PID paths, so it alone might not replace your driver\nbinaries that the package would put into an obscure location like\n`/lib/nut`. It would however install init-scripts or systemd units that\nwould refer to new locations specified by the current build, so such old\nbinaries would just consume disk space but not run.\n\nReplacing any NUT deployment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nNOTE: For deployments on OSes with `systemd` see the next section.\n\nThis goes similar to usual build and install from Git:\n\n\t:; cd /tmp\n\t:; git clone https://github.com/networkupstools/nut\n\t:; cd nut\n\t:; ./autogen.sh\n\t:; ./configure --enable-inplace-runtime # --maybe-some-other-options\n\t:; make -j 4 all && make -j 4 check && sudo make install\n\nNote that `make install` does not currently handle all the nuances that\npackaging installation scripts would, such as customizing filesystem\nobject ownership, daemon restarts, etc. or even creating locations like\n`/var/state/ups` and `/var/run/nut` as part of the `make` target (but\ne.g. the delivered `systemd-tmpfiles` configuration can handle that for\na large part of the audience). This aspect is tracked as\nlink:https://github.com/networkupstools/nut/issues/1298[issue #1298]\n\nAt this point you should revise the locations for PID files\n(e.g. `/var/run/nut`) and pipe files (e.g. `/var/state/ups`) that they\nexist and permissions remain suitable for NUT run-time user selected by\nyour configuration, and typically stop your original NUT drivers,\ndata-server (upsd) and upsmon, and restart them using the new binaries.\n\nReplacing a systemd-enabled NUT deployment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor modern Linux distributions with `systemd` this replacement procedure\ncould be enhanced like below, to also re-enable services (creating proper\nsymlinks) and to get them started:\n\n\t:; cd /tmp\n\t:; git clone https://github.com/networkupstools/nut\n\t:; cd nut\n\t:; ./autogen.sh\n\t:; ./configure --enable-inplace-runtime # --maybe-some-other-options\n\t:; make -j 4 all && make -j 4 check && \\\n\t    { sudo systemctl stop nut-monitor nut-server || true ; } && \\\n\t    { sudo systemctl stop nut-driver.service || true ; } && \\\n\t    { sudo systemctl stop nut-driver.target || true ; } && \\\n\t    { sudo systemctl stop nut.target || true ; } && \\\n\t    sudo make install && \\\n\t    sudo systemctl daemon-reload && \\\n\t    sudo systemd-tmpfiles --create && \\\n\t    sudo systemctl disable nut.target nut-driver.target \\\n\t        nut-monitor nut-server nut-driver-enumerator.path \\\n\t        nut-driver-enumerator.service && \\\n\t    sudo systemctl enable nut.target nut-driver.target \\\n\t        nut-monitor nut-server nut-driver-enumerator.path \\\n\t        nut-driver-enumerator.service && \\\n\t    { sudo systemctl restart udev || true ; } && \\\n\t    sudo systemctl restart nut-driver-enumerator.service \\\n\t        nut-monitor nut-server\n\nNote the several attempts to stop old service units -- naming did change\nfrom 2.7.4 and older releases, through 2.8.0, and up to current codebase.\nMost of the NUT units are now `WantedBy=nut.target` (which is in turn\n`WantedBy=multi-user.target` and so bound to system startup). You should\nonly `systemctl enable` those units you need on this system -- this allows\nit to not start the daemons you do not need (e.g. not run `upsd` NUT data\nserver on systems which are only `upsmon secondary` clients).\n\nThe `nut-driver-enumerator` units (and corresponding shell script) are\npart of a new feature introduced in NUT 2.8.0, which automatically\ndiscovers `ups.conf` sections and changes to their contents, and manages\ninstances of a `nut-driver@.service` definition.\n\nYou may also have to restart (or reload if supported) some system services\nif your updates impact them, like `udev` for updates USB support (note also\nlink:https://github.com/networkupstools/nut/pull/1342[PR #1342] regarding\nthe change from `udev.rules` to `udev.hwdb` file with NUT v2.8.0 or later --\nyou may have to remove the older file manually).\n\nIterating with a systemd deployment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIf you are regularly building NUT from GitHub \"master\" branch, or iterating\nlocal development branches of your own, you *may* get away with shorter\nconstructs to just restart the services after installing newly built files\n(if you know there were no changes to unit file definitions and dependencies),\ne.g.:\n\n\t:; cd /tmp\n\t:; git clone https://github.com/networkupstools/nut\n\t:; cd nut\n\t:; git checkout -b issue-1234 ### your PR branch name, arbitrary\n\t:; ./autogen.sh\n\t:; ./configure --enable-inplace-runtime # --maybe-some-other-options\n\t### Iterate your code changes (e.g. PR draft), build and install with:\n\t:; make -j 4 all && make -j 4 check && \\\n\t    sudo make install && \\\n\t    sudo systemctl daemon-reload && \\\n\t    sudo systemd-tmpfiles --create && \\\n\t    sudo systemctl restart \\\n\t        nut-driver-enumerator.service nut-monitor nut-server\n\nNext steps after an in-place upgrade\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can jump directly to the <<Configuration_notes,NUT configuration>>\nif you need to revise the settings for your new NUT version, take advantage\nof new configuration options, etc.\n\nCheck the {linksrcdoc}NEWS.adoc[] and {linksrcdoc}UPGRADING.adoc[] files\nin your checked-out Git workspace to review features that should be present\nin your new build.\n\n[[Installing_packages]]\nInstalling from packages\n------------------------\n\nThis chapter describes the specific installation steps when using\nbinary packages that exist on various major systems.\n\n[[Debian]]\nDebian, Ubuntu and other derivatives\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNOTE: NUT is packaged and well maintained in these systems.\nThe official Debian packager is part of the NUT Team.\n\nUsing your preferred method (apt-get, aptitude, Synaptic, ...), install\nthe 'nut' package, and optionally the following:\n\n- 'nut-cgi', if you need the CGI (HTML) option,\n- 'nut-snmp', if you need the snmp-ups driver,\n- 'nut-xml', for the netxml-ups driver,\n- 'nut-powerman-pdu', to control the PowerMan daemon (PDU management)\n- 'nut-dev', if you need the development files.\n\n////////////////////////////////////////////////////////////////////////////////\n- nut-client\n////////////////////////////////////////////////////////////////////////////////\n\nConfiguration files are located in /etc/nut.\nlinkman:nut.conf[5] must be edited to be able to invoke /etc/init.d/nut\n\nNOTE: Ubuntu users can access the APT URL installation by clicking\non link:apt://nut[this link].\n\n\n[[Mandriva]]\nMandriva\n~~~~~~~~\n\nNOTE: NUT is packaged and well maintained in these systems.\nThe official Mandriva packager is part of the NUT Team.\n\nUsing your preferred method (urpmi, RPMdrake, ...), install one of the\ntwo below packages:\n\n- 'nut-server' if you have a 'standalone' or 'netserver' installation,\n- 'nut' if you have a 'netclient' installation.\n\nOptionally, you can also install the following:\n\n- 'nut-cgi', if you need the CGI (HTML) option,\n- 'nut-devel', if you need the development files.\n\n\n[[SUSE]]\nSUSE / openSUSE\n~~~~~~~~~~~~~~~\n\nNOTE: NUT is packaged and well maintained in these systems.\nThe official SUSE packager is part of the NUT Team.\n\nInstall the 'nut-classic' package, and optionally the following:\n\n- 'nut-drivers-net', if you need the snmp-ups or the netxml-ups drivers,\n- 'nut-cgi', if you need the CGI (HTML) option,\n- 'nut-devel', if you need the development files,\n\nNOTE: SUSE and openSUSE users can use the\nlink:http://software.opensuse.org/search?baseproject=ALL&p=1&q=nut[one-click install method]\nto install NUT.\n\n\n[[RedHat]]\nRed Hat, Fedora and CentOS\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNOTE: NUT is packaged and well maintained in these systems.\nThe official Red Hat packager is part of the NUT Team.\n\nUsing your preferred method (yum, Add/Remove Software, ...), install\none of the two below packages:\n\n- 'nut' if you have a 'standalone' or 'netserver' installation,\n- 'nut-client' if you have a 'netclient' installation.\n\nOptionally, you can also install the following:\n\n- 'nut-cgi', if you need the CGI (HTML) option,\n- 'nut-xml', if you need the netxml-ups driver,\n- 'nut-devel', if you need the development files.\n\n\n[[FreeBSD]]\nFreeBSD\n~~~~~~~\n\nYou can either install NUT as a binary package or as a port.\n\nBinary package\n^^^^^^^^^^^^^^\n\nTo install NUT as a package execute:\n\n\t# pkg install nut\n\nPort\n^^^^\n\nThe port is located under +sysutils/nut+.\nUse +make config+ to select configuration options, e.g. to build the\noptional CGI scripts.\nTo install it, use:\n\n\t# make install clean\n\nUSB UPS on FreeBSD\n^^^^^^^^^^^^^^^^^^\n\nFor USB UPS devices the NUT package/port installs devd rules in\n+/usr/local/etc/devd/nut-usb.conf+ to set USB device permissions.\n 'devd' needs to be restarted  for these rules to apply:\n\n\t# service devd restart\n\n(Re-)connect the device after restarting 'devd' and check that the USB\ndevice has the proper permissions. Check the last entries of the system\nmessage buffer. You should find an entry like:\n\n\t# dmesg | tail\n\t[...]\n\tugen0.2: <INNO TECH USB to Serial> at usbus0\n\nThe device file must be owned by group +uucp+ and must be group\nread-/writable. In the example from above this would be\n\n\t# ls -Ll /dev/ugen0.2\n\tcrw-rw----  1 root  uucp  0xa5 Mar 12 10:33 /dev/ugen0.2\n\nIf the permissions are not correct, verify that your device is registered in\n+/usr/local/etc/devd/nut-usb.conf+. The vendor and product id can be found\nusing:\n\n\t# usbconfig -u 0 -a 2 dump_device_desc\n\nwhere +-u+ specifies the USB bus number and +-a+ specifies the USB device\nindex.\n\n\n[[Windows]]\nWindows\n~~~~~~~\n\nWindows binary package\n^^^^^^^^^^^^^^^^^^^^^^\n\n[NOTE]\n======\nNUT binary package built for Windows platform was last issued for\na much older codebase (using NUT v2.6.5 as a baseline). While the current\nstate of the codebase you are looking at aims to refresh the effort of\ndelivering NUT on Windows, the aim at the moment is to help developers\nbuild and modernize it after a decade of blissful slumber, and packages\nare not being regularly produced yet. Functionality of such builds varies\na lot depending on build environment used. This effort is generally\ntracked at https://github.com/orgs/networkupstools/projects/2/views/1\nand help would be welcome!\n\nIt should currently be possible to build the codebase in native Windows\nwith MSYS2/MinGW and cross-building from Linux with mingw (preferably\nin a Debian/Ubuntu container). Refer to\nlink:config-prereqs.txt[Prerequisites for building NUT on different OSes]\nand link:scripts/Windows/README.adoc[scripts/Windows/README.adoc file]\nfor respective build environment preparation instructions.\n\nNote that to use NUT for Windows, non-system dependency DLL files must\nbe located in same directory as each EXE file that uses them. This can be\naccomplished for FOSS libraries (copying them from the build environment)\nby calling `make install-win-bundle DESTDIR=/some/valid/location` easily.\n\nArchives with binaries built by recent iterations of continuous integration\njobs should be available for exploration on the respective CI platforms.\n======\n\n*Information below may be currently obsolete, but the NUT project wishes\nit to become actual and factual again :)*\n\nNUT binary package built for Windows platform comes in a `.msi` file.\n\nIf you are using Windows 95, 98 or Me, you should install\nlink:http://www.microsoft.com/downloads/en/details.aspx?familyid=cebbacd8-c094-4255-b702-de3bb768148f&displaylang=en[Windows Installer 2.0]\nfrom Microsoft site.\n\nIf you are using Windows 2000 or NT 4.0, you can\nlink:http://www.microsoft.com/downloads/en/details.aspx?FamilyID=4b6140f9-2d36-4977-8fa1-6f8a0f5dca8f&DisplayLang=en[download it here].\n\nNewer Windows releases should include the Windows Installer natively.\n\nRun `NUT-Installer.msi` and follow the wizard indications.\n\nIf you plan to use an UPS which is locally connected to an USB port,\nyou have to install\nlink:https://sourceforge.net/projects/libusb-win32/files/[libUSB-win32]\non your system. Then you must install your device via libusb's \"Inf Wizard\".\n\nNOTE: If you intend to build from source, relevant sources may be available at\nhttps://github.com/mcuee/libusb-win32 and keep in mind that it is a variant of\nlibusb-0.1. Current NUT supports libusb-1.0 as well, and that project should\nhave Windows support out of the box (but it was not explored for NUT yet).\n\nIf you have selected default directory, all configuration files are located in\n`C:\\Program Files\\NUT\\ups\\etc`\n\nBuilding for Windows\n^^^^^^^^^^^^^^^^^^^^\n\nFor suggestions about setting up the NUT build environment variants\nfor Windows, please see link:docs/config-prereqs.txt and/or\nlink:scripts/Windows/README.adoc files. Note this is rather experimental\nat this point.\n\n\nRuntime configuration\n~~~~~~~~~~~~~~~~~~~~~\n\nYou are now ready to configure NUT, and start testing and using it.\n\nYou can jump directly to the\n<<Configuration_notes,NUT configuration>>.\n"
        },
        {
          "name": "Jenkinsfile-dynamatrix",
          "type": "blob",
          "size": 76.005859375,
          "content": "#!/usr/bin/env groovy\n// ^^^ For syntax highlighters\n\n/* Typical Keep this build description formula for custom replayed builds (see below):\n\nKept for reference: build of commit https://github.com/networkupstools/nut/commit/86a32237c7df45c5aba640746f7afc4de09505a1\nPR https://github.com/networkupstools/nut/pull/1047\nA milestone of \"fightwarn\" effort attacking actual warnings in codebase Jun 2021\n\ndef buildCommit = '86a32237c7df45c5aba640746f7afc4de09505a1'\n*/\n\n// See https://github.com/networkupstools/jenkins-dynamatrix/ for the lib\n// Agent setup evolves at https://ci.networkupstools.org/computer/\n// NOTE: The \"${BRANCH_NAME}\" below IS NOT A VARIABLE!\n//       Special notation per custom plugin build including changes from\n//       https://github.com/jenkinsci/pipeline-groovy-lib-plugin/pull/19/\n@Library('jenkins-dynamatrix@${BRANCH_NAME}') _\nimport org.nut.dynamatrix.dynamatrixGlobalState;\nimport org.nut.dynamatrix.*;\n\n    // dynacfgBase = Base configuration for Dynamatrix for this pipeline\n    // dynacfgPipeline = Step-dependent setup in sub-maps\n    def dynacfgBase = [:]\n    def dynacfgPipeline = [:]\n\n    // NOTE: These can be further disabled or active in different combo specs\n    // below based on branch names. Also note that the values are somewhat\n    // \"inversed\" -- e.g. that \"disabledSomething = false\" means \"enable it\".\n    dynacfgPipeline.disableSlowBuildAutotools = false\n    dynacfgPipeline.disableSlowBuildCIBuild = false\n    dynacfgPipeline.disableSlowBuildCIBuildExperimental = false\n\n    // NOTE: Disabled by default because with -std=c* the compiler and linker\n    // (at least on environments NUT CI farm has) do not \"see\" many things,\n    // and do not even define WIN32, and this is unrelated to NUT codebase.\n    // This toggle aims to only disable 'c' builds in the scenario; but the\n    //'gnu' ones should still happen if it is enabled overall.\n    dynacfgPipeline.disableStrictCIBuild_CrossWindows = true\n\n    // At this time, GCC succeeds building C89/GNU89 mode for NUT\n    // while CLANG complains about things we can't fix easily.\n    dynacfgPipeline.axisCombos_COMPILER_GCC = [~/COMPILER=GCC/]\n    dynacfgPipeline.axisCombos_COMPILER_NOT_GCC = [~/COMPILER=(?!GCC)/]\n\n    // Avoid requiring success on GCC so old we can't manage warnings by CLI or pragmas:\n    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD = [~/COMPILER=GCC/, ~/GCCVER=([0123]\\.|4\\.[0123])/]\n\n    // Beside the flag here, the pre-defined C89/C90/ANSI scenarios\n    // should only get considered in branches named ~/fightwarn.*89.*/\n    // or PRs to those (for non-GCC builds):\n    dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI = false\n\n    // The NUT CI farm offers a few other architectures in containers backed\n    // by QEMU virtual CPUs. Running builds in these is expensive (takes a\n    // lot of time and can lag the NUT pipeline), so we would run just a few\n    // scenarios there to ensure code compatibility with headers and libs,\n    // but not exhaustive tests that can be done elsewhere. Currently this\n    // workload hits the Linux builder that completes its usual work earlier\n    // than some other builders, so a few minutes more would not hit pipeline\n    // wallclock time frame much. The slowBuild filter rules rely on separate\n    // label patterns with \"qemu-nut-builder\" and/or \"qemu-nut-builder:alldrv\".\n    dynacfgPipeline.disableSlowBuildCIBuild_QEMU = true\n    //if ( env?.BRANCH_NAME ==~ /master|main|stable|.*qemu.*/ ) {\n    if ( env?.BRANCH_NAME ==~ /.*qemu.*/ ) {\n        dynacfgPipeline.disableSlowBuildCIBuild_QEMU = false\n    }\n\n    dynacfgPipeline.traceBuildShell_configureEnvvars = false // true\n    dynacfgPipeline.traceBuildShell = false // true\n\n    //if (false) // <<< (Un-)comment away in select runs/branches\n    //if (true)  // <<< (Un-)comment away in select runs/branches\n    if ( env?.BRANCH_NAME ==~ /.*fightwarn-verbose.*/ )\n    {\n        dynacfgPipeline.traceBuildShell_configureEnvvars = true // false\n        dynacfgPipeline.traceBuildShell = true // false\n    }\n\n    dynacfgPipeline.failFast = //true //\n        false\n\n    // How long can a single \"slow-build stage\" run before we\n    // consider that the build agent is stuck or network dropped?\n    // The dynamatrix should try to re-schedule this scenario then.\n    dynacfgPipeline.dsbcStageTimeoutSettings = [\n        time: 2,\n        unit: 'HOURS'\n        ]\n\n    // Note: this setting causes a lot of noise in build summary page and\n    // parent job definition (PR, branch...) overview page on Jenkins,\n    // by reporting dozens of lines for each analyzer ID ever published.\n    // Do not enable instant (non-delayed, \"false\" here) reports for the\n    // \"master\" and equivalent branch builds.\n    dynacfgPipeline.delayedIssueAnalysis = //false //\n        true\n\n    // In modern builds, use the ci_build.sh recipe which first checks\n    // quietly for things that succeed, and summarizes errors in the end\n    dynacfgPipeline['spellcheck_prepconf'] = false\n    dynacfgPipeline['spellcheck_configure'] = false\n    dynacfgPipeline['spellcheck'] = '(BUILD_TYPE=default-spellcheck ./ci_build.sh)'\n\n/*\n    // For older builds, with only autotools in the tree:\n    dynacfgPipeline['spellcheck'] = //false //true\n        // '( \\${MAKE} VERBOSE=1 SPELLCHECK_ERROR_FATAL=yes spellcheck )'\n*/\n\n    //dynacfgPipeline['shellcheck'] = true\n    // Check shell scripts as well as make implementations registered on\n    // CI farm -- that they do not fundamentally reject our Makefile syntax.\n    // Note that if MAKE=something does not get into envvars, defaultTools\n    // are used (just assigning it among build agent labels is not enough).\n    dynacfgPipeline['shellcheck'] = [\n        //'stageNameFunc': null,\n        //'dynamatrixAxesLabels': [~/^OS_.+/, 'MAKE'],\n        'dynamatrixAxesLabels': ['OS_FAMILY', 'OS_DISTRO', 'MAKE'],\n        'single': '( if [ x\"\\${MAKE-}\" = x ]; then echo \"WARNING: MAKE is somehow unset, defaulting!\" >&2; MAKE=make; fi; \\${MAKE} shellcheck )',\n        'multi': '(cd tests && SERVICE_FRAMEWORK=\"selftest\" SHELL_PROGS=\"$SHELL_PROGS\" ./nut-driver-enumerator-test.sh )',\n        'multiLabel': 'SHELL_PROGS',\n        'skipShells': [ 'zsh', 'tcsh', 'csh' ]\n    ]\n\n/*\n    // Examples for custom checkouts instead of following a branch/PR that triggered the build:\n    //dynacfgPipeline.bodyStashCmd = { git (url: \"https://github.com/networkupstools/nut\", branch: \"fightwarn\") }\n\n    //def buildCommit = '86a32237c7df45c5aba640746f7afc4de09505a1'\n    def buildCommit = 'refs/tags/v2.7.4'\n\n    dynacfgPipeline.bodyStashCmd = { checkout([\n        $class: 'GitSCM', branches: [[name: buildCommit]],\n        doGenerateSubmoduleConfigurations: false,\n        extensions: [[$class: 'SubmoduleOption', disableSubmodules: false, parentCredentials: false, recursiveSubmodules: false, reference: '', trackingSubmodules: false]],\n        submoduleCfg: [],\n        userRemoteConfigs: [[url: \"https://github.com/networkupstools/nut\"]]\n        ])\n    }\n\n    // While building older release (2.7.4) disable recipes that did not exist back then\n    dynacfgPipeline['stylecheck'] = false //true\n    dynacfgPipeline['spellcheck'] = false //true\n    dynacfgPipeline['shellcheck'] = false //true\n\n    dynacfgPipeline.disableSlowBuildCIBuild = true\n    dynacfgPipeline.disableSlowBuildCIBuildExperimental = true\n*/\n\n    dynacfgBase['commonLabelExpr'] = 'nut-builder'\n    dynacfgBase['dynamatrixAxesLabels'] = //[~/^OS_.+/]\n        ['OS_FAMILY', 'OS_DISTRO', '${COMPILER}VER', 'ARCH${ARCH_BITS}']\n    dynacfgBase['dynamatrixAxesCommonEnv'] = [ ['LANG=C', 'LC_ALL=C', 'TZ=UTC'] ]\n\n    dynacfgPipeline.stashnameSrc = 'nut-ci-src'\n\n    // These platforms do not serve a functional cppunit for gcc,\n    // so a diverse C++ build matrix on them is pointless; thus\n    // so far we allow-failure (or avoid C++11 and newer builds)\n    // on OpenIndiana (cppcheck pkg seems flawed, at least in\n    // various versions of GCC builds) and BSD (also just for GCC):\n    dynacfgPipeline.axisCombos_CPPUNIT = [~/OS_DISTRO=(openindiana|freebsd).*/, ~/CSTDVERSION_cxx=[12].+/, ~/COMPILER=GCC/]\n\n    // Avoid mix-up of bitness-related requests and abilities\n    dynacfgPipeline.axisCombos_ARCH32x64 = [~/BITS=32/, ~/ARCH_BITS=64/]\n    dynacfgPipeline.axisCombos_ARCH64x32 = [~/BITS=64/, ~/ARCH_BITS=32/]\n\n    // Some (but not all) builds skip strict-C standard due to\n    // current build failures with its requirements\n    dynacfgPipeline.axisCombos_STRICT_C = [~/CSTDVARIANT=c/]\n    dynacfgPipeline.axisCombos_GNU_C = [~/CSTDVARIANT=gnu/]\n\n    // Here we consider native-platform builds on a Windows box\n    // (possibly with need for \"bat\" instead of \"sh\" steps):\n    dynacfgPipeline.axisCombos_WINDOWS = [~/OS_FAMILY=windows/]\n    dynacfgPipeline.axisCombos_NOT_WINDOWS = [~/OS_FAMILY=(?!windows)/]\n\n    // TODO: some cross-build enviroments like Linux with mingw?\n    // Currently done as an explicit scenario below...\n    dynacfgPipeline.axisCombos_WINDOWS_CROSS = [~/OS_FAMILY=(mingw|mingw32|mingw64|msys2)/]\n    dynacfgPipeline.axisCombos_NOT_WINDOWS_CROSS = [~/OS_FAMILY=(?!(mingw|mingw32|mingw64|msys2))/]\n\n    // At a minimum, we don't want to mess up our arches:\n    dynacfgPipeline.excludeCombos_DEFAULT = [\n        dynacfgPipeline.axisCombos_ARCH32x64,\n        dynacfgPipeline.axisCombos_ARCH64x32\n        ]\n\n    dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT = [\n        dynacfgPipeline.axisCombos_CPPUNIT,\n        dynacfgPipeline.axisCombos_ARCH32x64,\n        dynacfgPipeline.axisCombos_ARCH64x32\n        ]\n\n    dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C = [\n        dynacfgPipeline.axisCombos_STRICT_C,\n        dynacfgPipeline.axisCombos_ARCH32x64,\n        dynacfgPipeline.axisCombos_ARCH64x32\n        ]\n\n    dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C = [\n        dynacfgPipeline.axisCombos_CPPUNIT,\n        dynacfgPipeline.axisCombos_STRICT_C,\n        dynacfgPipeline.axisCombos_ARCH32x64,\n        dynacfgPipeline.axisCombos_ARCH64x32\n        ]\n\n    dynacfgPipeline.branchStableRegex = ~/^(master|main|stable)$/\n    if ( env?.BRANCH_NAME ==~ /^fightwarn.*$/ && (!env?.CHANGE_TARGET) ) {\n        dynamatrixGlobalState.branchDefaultStable = 'fightwarn'\n    }\n\n    if ( env?.BRANCH_NAME ==~ dynacfgPipeline.branchStableRegex ) {\n        // For our main branches we want all builds in full,\n        // to keep reference for warnings-ng up to date, so do\n        // not limit ny appliesToChangedFilesRegex categories\n\n        // Be sure to not make noise in long-lived branches'\n        // overview pages by enabling quick analysis publishing\n        // (by default above, or in a Replay):\n        dynacfgPipeline.delayedIssueAnalysis = true\n    } else {\n        // First list the building blocks as lists of files;\n        // final regexes are arranged below:\n        // TODO: Technically the slash should be the Path.Separator,\n        // but at least modern windows can handle a sh step with that\n        // character, so no big deal for NUT supported platforms\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX = ~/^(\\/*|.*\\/)/\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE = ~/(configure\\.ac|.*\\.m4|C?Make.*|ci_.*\\.sh|autogen\\.sh|\\.git.*|Jenkinsfile.*|.*\\.groovy)/\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_C = ~/^(.*\\.h|.*\\.hpp|.*\\.c|.*\\.cxx|.*\\.cpp)/\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_TXT = ~/^(.*\\.txt|.*\\.dict|asciidoc.*|.*\\.xsl|.*\\.css|AUTHORS.*|CHANGELOG.*|COPYING.*|INSTALL.*|LICENSE.*|MAINT.*|NEWS.*|README.*|TODO.*|UPGRAD.*)/\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_IMG = ~/^(.*\\.svg|.*\\.png|.*\\.jpg|.*\\.jpeg|.*\\.gif)/\n        dynacfgPipeline.appliesToChangedFilesRegex_FILES_PY = ~/^(.*\\.py|scripts\\/python\\/app\\/Nut-Monitor)/\n\n        // Recipe changes and C source changes go here:\n        dynacfgPipeline.appliesToChangedFilesRegex_RECIPE = ~/${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX}${dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE}(|\\.in)$/\n        dynacfgPipeline.appliesToChangedFilesRegex_C = ~/${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX}(${dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE}|${dynacfgPipeline.appliesToChangedFilesRegex_FILES_C})(|\\.in)$/\n        dynacfgPipeline.appliesToChangedFilesRegex_PY = ~/${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX}(${dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE}|${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PY})(|\\.in)$/\n\n        // Recipe changes and docs source changes go here:\n        dynacfgPipeline.appliesToChangedFilesRegex_TXT = ~/${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX}(${dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE}|${dynacfgPipeline.appliesToChangedFilesRegex_FILES_TXT}(|\\.in)$)/\n        dynacfgPipeline.appliesToChangedFilesRegex_DOC = ~/${dynacfgPipeline.appliesToChangedFilesRegex_FILES_PREFIX}(${dynacfgPipeline.appliesToChangedFilesRegex_FILES_RECIPE}|${dynacfgPipeline.appliesToChangedFilesRegex_FILES_TXT}|${dynacfgPipeline.appliesToChangedFilesRegex_FILES_IMG})(|\\.in)$/\n\n        // TODO: Similar for shell files but based on some logic\n        // like in shellcheck to find the script files (not only *.sh)?\n    }\n\n    // Do not override DISTCHECK_CONFIGURE_FLAGS as default implem\n    // does, that breaks custom proto-dir installs and tries to go\n    // into (not writeable) system paths:\n    if (!dynacfgPipeline.containsKey('buildPhases')) {\n        dynacfgPipeline.buildPhases = [:]\n    }\n\n    // Imported from jenkins-dynamatrix JSL vars/autotools.groovy:\n    // a workaround for the cases of curiously missing MAKE envvar...\n    dynacfgPipeline.buildPhases['distcheck'] = \"\"\"( if [ x\"\\${MAKE-}\" = x ]; then echo \"WARNING: MAKE is somehow unset, defaulting!\" >&2; MAKE=make; fi; eval \\${CONFIG_ENVVARS} time \\${MAKE} \\${MAKE_OPTS} distcheck DISTCHECK_FLAGS=\\${CONFIG_OPTS:+\\\\\"\\$CONFIG_OPTS\\\\\"} )\"\"\"\n\n    // Note: shellcheck/spellcheck/... require autotools currently\n    // or need to be redefined with respective BUILD_TYPE\n    //dynacfgPipeline.buildSystem = 'ci_build.sh'\n\n    //dynacfgPipeline.slowBuildDefaultBody = { echo \"Running default custom build\" }\n    dynacfgPipeline.slowBuildDefaultBody_autotools = { def delegate -> setDelegate(delegate)\n        // Be sure to have a fixed resolved String here ASAP:\n        String stageNameClone = \"${stageName}\"\n        def dsbcClone = dsbc.clone()\n\n        stage('Investigate envvars (Autotools DEBUG)') {\n            echo \"Running default custom build for '${stageNameClone}' ==> ${dsbcClone.toString()}\" +\n                (dynacfgPipeline?.configureEnvvars ? \"\" : \" (note: has no dynacfgPipeline.configureEnvvars)\")\n            // Trick about endianness via ELF binary header picked up from https://serverfault.com/a/749469/490516\n            sh label: 'Inspect initial envvars', script: \"\"\" hostname; date -u; uname -a\necho \"LONG_BIT:`getconf LONG_BIT` WORD_BIT:`getconf WORD_BIT`\" || true\nif command -v xxd >/dev/null ; then xxd -c 1 -l 6 | tail -1; else if command -v od >/dev/null; then od -N 1 -j 5 -b | head -1 ; else hexdump -s 5 -n 1 -C | head -1; fi; fi < /bin/ls 2>/dev/null | awk '(\\$2 == 1){print \"Endianness: LE\"}; (\\$2 == 2){print \"Endianness: BE\"}' || true\necho \"\\${MATRIX_TAG}\"\nset | sort -n \"\"\"\n            if (dynacfgPipeline?.configureEnvvars) {\n                sh label: 'Apply CONFIG_ENVVARS', script: \"\"\" set +x\necho \"Applying CONFIG_ENVVARS:\"\n#set -xv\n${dynacfgPipeline.configureEnvvars}\nset | sort -n \"\"\"\n            }\n        }\n\n        withEnvOptional(dynacfgPipeline.defaultTools) {\n            stage('Unstash sources') {\n                unstashCleanSrc(dynacfgPipeline.stashnameSrc)\n            }\n\n            buildMatrixCellCI(dynacfgPipeline, dsbcClone, stageNameClone)\n            //buildMatrixCellCI(dynacfgPipeline, dsbc, stageName)\n        }\n    }\n\n    dynacfgPipeline.slowBuildDefaultBody_ci_build = { def delegate -> setDelegate(delegate)\n        // Be sure to have a fixed resolved String here ASAP:\n        String stageNameClone = \"${stageName}\"\n        def dsbcClone = dsbc.clone()\n\n        stage('Investigate envvars (CI_Build DEBUG)') {\n            echo \"Running default custom build for '${stageNameClone}' ==> ${dsbcClone.toString()}\" +\n                (dynacfgPipeline?.configureEnvvars ? \"\" : \" (note: has no dynacfgPipeline.configureEnvvars)\")\n            // Trick about endianness via ELF binary header picked up from https://serverfault.com/a/749469/490516\n            sh label: 'Inspect initial envvars', script: \"\"\" hostname; date -u; uname -a\necho \"LONG_BIT:`getconf LONG_BIT` WORD_BIT:`getconf WORD_BIT`\" || true\nif command -v xxd >/dev/null ; then xxd -c 1 -l 6 | tail -1; else if command -v od >/dev/null; then od -N 1 -j 5 -b | head -1 ; else hexdump -s 5 -n 1 -C | head -1; fi; fi < /bin/ls 2>/dev/null | awk '(\\$2 == 1){print \"Endianness: LE\"}; (\\$2 == 2){print \"Endianness: BE\"}' || true\necho \"\\${MATRIX_TAG}\"\nset | sort -n \"\"\"\n            if (dynacfgPipeline?.configureEnvvars) {\n                sh label: 'Apply CONFIG_ENVVARS', script: \"\"\" set +x\necho \"Applying CONFIG_ENVVARS:\"\n#set -xv\n${dynacfgPipeline.configureEnvvars}\nset | sort -n \"\"\"\n            }\n        }\n\n        withEnvOptional(dynacfgPipeline.defaultTools) {\n            stage('Unstash sources') {\n                unstashCleanSrc(dynacfgPipeline.stashnameSrc)\n            }\n\n            def dynacfgPipeline_ciBuild = dynacfgPipeline.clone()\n            dynacfgPipeline_ciBuild.buildSystem = 'ci_build.sh'\n            dynacfgPipeline_ciBuild.buildPhases = [:]\n            dynacfgPipeline_ciBuild = ci_build.sanityCheckDynacfgPipeline(dynacfgPipeline_ciBuild)\n\n            buildMatrixCellCI(dynacfgPipeline_ciBuild, dsbcClone, stageNameClone)\n            //buildMatrixCellCI(dynacfgPipeline_ciBuild, dsbc, stageName)\n        }\n    }\n\n    dynacfgPipeline.slowBuildDefaultBody = dynacfgPipeline.slowBuildDefaultBody_autotools\n\n    /* By default, the master/main/stable branch and PRs against it\n     * is built with as few scenarios as possible, allowing for fast\n     * turnaround and avoiding redundant work (e.g. documentation\n     * rendering, distchecks that are more about recipes than code),\n     * and stricter warnings that current codebase would fail so far.\n     * In particular, this saves CI farm resources - allowing more\n     * PRs per day to be checked in practice.\n     * Conversely, a branch with \"fightwarn\" in the name (or PR to it)\n     * would enjoy many more build scenarios, covering both autotools\n     * directly and ci_build.sh with stricter warnings, in particular.\n     */\n    dynacfgPipeline.slowBuild = [\n        [name: 'Default autotools driven build with default warning levels (gnu99/gnu++11)',\n         disabled: dynacfgPipeline.disableSlowBuildAutotools,\n         branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         branchRegexTarget: ~/fightwarn/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: dynacfgBase.commonLabelExpr,\n                //defaultDynamatrixConfig: dynacfgBase.defaultDynamatrixConfig,\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    // 'CSTDVERSION': ['03', '2a'],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'], 'ansi' ],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'] ],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'] ],\n                    'CSTDVARIANT': ['gnu']\n                    ],\n\n                mergeMode: [ 'dynamatrixAxesVirtualLabelsMap': 'replace', 'excludeCombos': 'merge' ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    dynacfgPipeline.axisCombos_STRICT_C\n                    ],\n                runAllowedFailure: true,\n                //dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                //dynamatrixAxesLabels: [~/^OS/, '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        //'bodyParStages': {}\n        ] // one slowBuild filter configuration, autotools-minimal\n\n        ,[name: 'Default autotools driven build with max warnings and varied C/C++ revisions (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildAutotools,\n         branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         branchRegexTarget: ~/fightwarn/,\n         // NOTE: For fightwarn, we want some schenarios that would always build to test\n         //appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: dynacfgBase.commonLabelExpr,\n                //defaultDynamatrixConfig: dynacfgBase.defaultDynamatrixConfig,\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    // 'CSTDVERSION': ['03', '2a'],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'], 'ansi' ],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'] ],\n                    //'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'] ],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu']\n                    ],\n\n                mergeMode: [ 'dynamatrixAxesVirtualLabelsMap': 'replace', 'dynamatrixAxesCommonEnv': 'replace', 'excludeCombos': 'merge' ],\n                dynamatrixAxesCommonEnv: [\n                    //['LANG=C','LC_ALL=C','TZ=UTC', 'CFLAGS=-Wall\\\\ -Wextra\\\\ -Werror', 'CXXFLAGS=-Wall\\\\ -Wextra\\\\ -Werror']\n                    ['LANG=C','LC_ALL=C','TZ=UTC', 'CFLAGS=-Wall', 'CXXFLAGS=-Wall']\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    [~/C.*FLAGS=.+Werror/]\n                    ],\n                runAllowedFailure: true,\n                //dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                //dynamatrixAxesLabels: [~/^OS/, '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        //'bodyParStages': {}\n        ] // one slowBuild filter configuration, autotools-Wall\n\n        ,[name: 'Default autotools driven build with default configuration, bitness and warning levels on each NUT CI farm platform (but with fatal warnings as of gnu99/gnu++11, must pass where enabled)',\n         disabled: dynacfgPipeline.disableSlowBuildAutotools,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         //branchRegexTarget: ~/fightwarn/,\n         //appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: dynacfgBase.commonLabelExpr,\n                //defaultDynamatrixConfig: dynacfgBase.defaultDynamatrixConfig,\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    //'BITS': [32, 64],\n                    // 'CSTDVERSION': ['03', '2a'],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'], 'ansi' ],\n                    //'CSTDVERSION_${KEY}': [ ['c': '03', 'cxx': '03'], ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '2a'] ],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'] ],\n                    'CSTDVARIANT': ['gnu']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    // One set of several simultaneously exported envvars!\n                    // CONFIG_OPTS are picked up by our dynamatrix configuration\n                    // and substituted into shell \"as is\" for normal builds\n                    // (so splitting into many tokens), or quoted as a single\n                    // token DISTCHECK_FLAGS in its stage (split by make later).\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'CONFIG_OPTS=--with-all=auto --with-docs=auto --with-ssl=auto --enable-Werror --enable-warnings --disable-Wcolor --enable-silent-rules'\n                    ]\n                    ],\n\n                mergeMode: [ 'dynamatrixAxesVirtualLabelsMap': 'replace', 'excludeCombos': 'merge' ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    dynacfgPipeline.axisCombos_STRICT_C\n                    ],\n                runAllowedFailure: true,\n                //dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                //dynamatrixAxesLabels: [~/^OS/, '${COMPILER}VER', 'ARCH${ARCH_BITS}'],\n                dynamatrixAxesLabels: [~/^OS_DISTRO/, 'COMPILER'],\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                    + [[~/OS_DISTRO=openbsd-6\\./, ~/COMPILER=GCC/]]\n                    // Here we picked just OSes and compilers (gcc or clang),\n                    // so exclude systems which have e.g. gcc-4.2.1 which claims\n                    // type range comparison warnings despite pragma fencing.\n                    // gcc-4.8.x on CentOS 7 and Ubuntu 14.04 looks already okay.\n                    + [[~/OS_DISTRO=macos/]]\n                    // MacOS (at least agents prepared with HomeBrew packages)\n                    // requires a few pkg-config and CFLAGS pre-sets which are\n                    // done in ci_build.sh and defeat the purpose of this stage.\n                    // So it is easier and more honest to just skip it.\n                ], body)\n            }, // getParStages\n        //'bodyParStages': {}\n        ] // one slowBuild filter configuration, autotools-everywhere\n\n        ,[name: 'Various non-docs distchecked target builds with main and ~newest supported C/C++ revisions (must pass on all platforms)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-nodoc']\n                    // BUILD_TYPE=default-withdoc:man\n                    // BUILD_TYPE=default-tgt:distcheck-light == --with-all=auto --with-ssl=auto --with-doc=auto\n                    // BUILD_TYPE=default-tgt:distcheck-light + NO_PKG_CONFIG=true ?\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC','BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Valgrind+distchecked target builds with main and ~newest supported C/C++ revisions (must pass on all platforms)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=valgrind=yes||NUT_BUILD_CAPS=valgrind)\"],\n                excludedNodelabels: [\"NUT_BUILD_CAPS=valgrind=no\"],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-tgt:distcheck-valgrind']\n                    // BUILD_TYPE=default-withdoc:man\n                    // BUILD_TYPE=default-tgt:distcheck-light == --with-all=auto --with-ssl=auto --with-doc=auto\n                    // BUILD_TYPE=default-tgt:distcheck-light + NO_PKG_CONFIG=true ?\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC','BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'A cppcheck analysis build',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         // NOTE: At the time of this posting, there are a handful of \"high\"\n         // priority issues, and hundreds of lesser problems which may overlap\n         // or not with those reported by other analysers. Having issues to\n         // report does not mark the builds FAILED nor UNSTABLE however, so\n         // this should be safe to enable for all branches now. But it makes\n         // a lot of noise and (bug?) falls into common warnings category,\n         // not a separate analysis group as was intended by dynamatrix.\n         // So for now this applies only to fightwarn-related branches.\n         branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         branchRegexTarget: ~/fightwarn/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                dynamatrixAxesLabels: ['OS_FAMILY'], // + [ 'OS_DISTRO', 'MAKE'],\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=cppcheck||NUT_BUILD_CAPS=cppcheck=yes)\"],\n                excludedNodelabels: [\"NUT_BUILD_CAPS=cppcheck=no\"],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    // For cppcheck we do not iterate BITS,\n                    // doing one (default) hit per system:\n                    //'BITS': [32, 64],\n\n                    // Take systems that CAN build C; do not really\n                    // care about revision here since it is hardcoded\n                    // in the Makefile to create two analysis XMLs now:\n                    'CSTDVERSION_${KEY}': [ ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-tgt:cppcheck']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC', 'DO_CLEAN_CHECK=no', 'BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'A build with all driver types on capable systems with distcheck for main supported C/C++ revision (must pass)',\n         // NOTE: Here we constrain distcheck builds (more CI stress load)\n         // to run as few combos as possible; arguably this filter config\n         // is more about recipes distributing those drivers than about\n         // directly codebase quality.\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: \"nut-builder:alldrv\",\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=drivers:all||nut-builder:alldrv)\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    // TODO: Find a way to constrain these builds to one\n                    // per OS type, whatever bitness(es) supported there,\n                    // so we really primarily only test the dist-ability.\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-alldrv']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC','BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                // On some systems, pkg-config for net-snmp includes CFLAGS values not supported by gcc-4.9 and older\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/GCCVER=[01234].+/, ~/BUILD_TYPE=default-alldrv/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'A build with all driver types on capable systems without distcheck for other C/C++ revisions (must pass)',\n         // NOTE: We reduce the build load here since the Makefile recipes\n         // (for distcheck part) are deemed tested above with the supported\n         // C/C++ standard revision\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: \"nut-builder:alldrv\",\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=drivers:all||nut-builder:alldrv)\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-alldrv:no-distcheck']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC','BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                // On some systems, pkg-config for net-snmp includes CFLAGS values not supported by gcc-4.9 and older\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/GCCVER=[01234].+/, ~/BUILD_TYPE=default-alldr(v|v:no-distcheck)/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'A build with all driver types on capable systems with distcheck and fatal warnings (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*)$/,\n         branchRegexTarget: ~/fightwarn/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: \"nut-builder:alldrv\",\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=drivers:all||nut-builder:alldrv)\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-alldrv']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                // On some systems, pkg-config for net-snmp includes CFLAGS values not supported by gcc-4.9 and older\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/BUILD_WARNOPT=hard/],\n                    [~/GCCVER=[01234].+/, ~/BUILD_TYPE=default-alldrv/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Various build combos with Python versions for helper scripts',\n         // This is a recipe (and target OS) test for ability to use helper\n         // scripts with various Python interpreter versions.\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_PY,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: \"nut-builder:alldrv\",\n                // TOTHINK: Should we also vary compilers here?\n                dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', 'MAKE', 'PYTHON'],\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=drivers:all||nut-builder:alldrv)\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    //'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-alldrv']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=medium'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesLabels': 'replace', 'commonLabelExpr': 'replace', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'An out-of-tree build with all docs types on capable systems, and a distcheck (must pass)',\n         // TODO: This is a recipe (and target OS) test for ability to build\n         // the docs without error; it should not iterate compilers (maybe\n         // iterate docs tools though, if we were to support many backends?)\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_DOC,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: dynacfgBase.commonLabelExpr + \" && doc-builder\",\n                //commonLabelExpr: infra.labelDocumentationWorker(),\n                dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', 'MAKE'],\n                requiredNodelabels: [\"NUT_BUILD_CAPS=docs:all\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    //'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-withdoc']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     // Build in a subdirectory to check that out-of-dir\n                     // builds are healthy too.\n                     // NOTE: It would be useful to also have a recipe to build\n                     // \"completely out-of-tree\", in a different filesystem (to\n                     // make sure we do not rely on hard-links, relative paths,\n                     // etc.)\n                     'CI_BUILDDIR=obj',\n                     'BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=minimal'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesLabels': 'replace', 'commonLabelExpr': 'replace', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'A build with manpage docs on all systems that did not build \"all docs\", and a distcheck (allowed to fail - e.g. no tools even for that)',\n         // TODO: This is a recipe (and target OS) test for ability to build\n         // the docs without error; it should not iterate compilers; see above\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_TXT,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: dynacfgBase.commonLabelExpr + \" && doc-builder\",\n                //commonLabelExpr: infra.labelDocumentationWorker(),\n                dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', 'MAKE'],\n                requiredNodelabels: [\"NUT_BUILD_CAPS=docs:man\"],\n                excludedNodelabels: [\"NUT_BUILD_CAPS=docs:all\"],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    //'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    'BUILD_TYPE': ['default-withdoc:man']\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_WARNFATAL=yes'\n                     //,'BUILD_WARNOPT=minimal'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/BUILD_TYPE=default-withdoc:man/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesLabels': 'replace', 'commonLabelExpr': 'replace', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C standard builds with non-fatal warnings, without distcheck and docs (must pass)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                // NOTE: C89 not included here as its warnings are quite\n                // noisy as in \"not relevant for more modern revisions\".\n                // It has a separate slowBuild filter configuration below.\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=no','BUILD_WARNOPT=auto'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C89 standard builds with non-fatal warnings and GCC toolkits, without distcheck and docs (must pass)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI,\n         //branchRegexSource: ~/^(PR-.+|.*fightwarn.*89.*)$/,\n         //branchRegexTarget: ~/fightwarn.*89.*/,\n         //disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         //branchRegexSource: ~/^(PR-.+|.*fightwarn.*)$/,\n         //branchRegexTarget: ~/fightwarn.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '89', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=no','BUILD_WARNOPT=auto'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_NOT_GCC]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C89 standard builds with non-fatal warnings and non-GCC toolkits, without distcheck and docs (must pass)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*89.*)$/,\n         branchRegexTarget: ~/fightwarn.*89.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '89', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=no','BUILD_WARNOPT=auto'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C standard builds with non-fatal warnings, without distcheck and docs, one compiler with main supported C/C++ revision on slower QEMU builders (may fail due to those workers)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild_QEMU,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*|.*qemu.*)$/,\n         //branchRegexTarget: ~/^(master|main|stable|.*qemu.*)$/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                //commonLabelExpr: \"qemu-\" + dynacfgBase.commonLabelExpr,\n                commonLabelExpr: \"qemu-nut-builder || ssh-qemu-nut-builder\",\n                dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', 'ARCH${ARCH_BITS}', 'COMPILER'],\n                requiredNodelabels: [\"(NUT_BUILD_CAPS=drivers:all||qemu-nut-builder:alldrv)\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=no','BUILD_WARNOPT=auto'\n                    ]\n                    ],\n                allowedFailure: [\n                    //[~/ARCH(32|64)=(?!i386|amd64))/],\n                    //[~/OS_FAMILY=windows/]\n                    [~/OS_FAMILY=.+/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace', 'dynamatrixAxesLabels': 'replace', 'commonLabelExpr': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: [\n                    [~/BITS=32/, ~/ARCH_BITS=64/], [~/BITS=64/, ~/ARCH_BITS=32/],\n                    [~/CSTDVARIANT=c/],\n                    [~/OS_DISTRO=(openindiana|freebsd).*/, ~/CSTDVERSION_cxx=[12].+/, ~/COMPILER=GCC/],\n                    dynacfgPipeline.axisCombos_WINDOWS_CROSS\n                    ]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C standard builds with fatal warnings, without distcheck and docs (allowed to fail with non-GCC compilers)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*)$/,\n         branchRegexTarget: ~/fightwarn/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                // NOTE: C89 not included here as its warnings are quite\n                // noisy as in \"not relevant for more modern revisions\".\n                // It has a separate slowBuild filter configuration below.\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                    //+ [ [~/COMPILER=GCC/, ~/CSTDVERSION_KEY=(?!89)/] ]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C89 standard builds with fatal warnings with non-GCC compilers, without distcheck and docs (allowed to fail)',\n         // NOTE: This build scenario is quite noisy with regard to warnings\n         // analysis and not too beneficial unless someone looking at the\n         // logs is actively fixing the C89 compatibility. So off by default,\n         // and would only run for a PR against a \"fightwarn.*89.*\" named\n         // branch or for a build of such branch.\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*89.*)$/,\n         branchRegexTarget: ~/fightwarn.*89.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '89', 'cxx': '98'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C + [\n                    [~/COMPILER=GCC/, ~/CSTDVERSION_KEY=(?!89)/]\n                    ] +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'GNU C standard out-of-tree builds with fatal warnings with GCC, without distcheck and docs (must pass)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|fightwarn.*)$/,\n         //branchRegexTarget: dynacfgPipeline.branchStableRegex,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=yes',\n                     // Build in a subdirectory to check that out-of-dir\n                     // builds are healthy too\n                     'CI_BUILDDIR=obj',\n                     // NOTE: \"gcc-hard\" warnings are still not as picky\n                     // as \"clang-hard\" and do not differ much from the\n                     // \"gcc-medium\" definition currently:\n                     'BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT_STRICT_C + [\n                    [~/COMPILER=(?!GCC)/]\n                    ] +\n                    [dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD]\n                    + [dynacfgPipeline.axisCombos_WINDOWS_CROSS]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Strict C standard builds on non-Windows platforms, without distcheck and docs (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*)$/,\n         branchRegexTarget: ~/fightwarn/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '11', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['c'],\n                    ],\n                dynamatrixAxesCommonEnv: [],\n                dynamatrixAxesCommonEnvCartesian: [\n                    [ ['LANG=C','LC_ALL=C','TZ=UTC', 'BUILD_TYPE=default-all-errors'] ],\n                    [ ['BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'], ['BUILD_WARNFATAL=no','BUILD_WARNOPT=minimal'] ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT + [\n                    dynacfgPipeline.axisCombos_GNU_C,\n                    dynacfgPipeline.axisCombos_WINDOWS_CROSS,\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Strict ANSI C (C89/C90) standard builds on non-Windows platforms and GCC toolkits, without distcheck and docs (allowed to fail)',\n         //disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI,\n         //branchRegexSource: ~/^(PR-.+|.*fightwarn.*89.*)$/,\n         //branchRegexTarget: ~/fightwarn.*89.*/,\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*)$/,\n         branchRegexTarget: ~/fightwarn.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ 'ansi' ],\n                    'CSTDVARIANT': ['c'],\n                    ],\n                dynamatrixAxesCommonEnv: [],\n                dynamatrixAxesCommonEnvCartesian: [\n                    [ ['LANG=C','LC_ALL=C','TZ=UTC', 'BUILD_TYPE=default-all-errors'] ],\n                    [ ['BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'], ['BUILD_WARNFATAL=no','BUILD_WARNOPT=minimal'] ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT + [\n                    dynacfgPipeline.axisCombos_GNU_C,\n                    dynacfgPipeline.axisCombos_WINDOWS_CROSS,\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ] + [dynacfgPipeline.axisCombos_COMPILER_NOT_GCC]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Strict ANSI C (C89/C90) standard builds on non-Windows platforms and non-GCC toolkits, without distcheck and docs (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimentalANSI,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*89.*)$/,\n         branchRegexTarget: ~/fightwarn.*89.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ 'ansi' ],\n                    'CSTDVARIANT': ['c'],\n                    ],\n                dynamatrixAxesCommonEnv: [],\n                dynamatrixAxesCommonEnvCartesian: [\n                    [ ['LANG=C','LC_ALL=C','TZ=UTC', 'BUILD_TYPE=default-all-errors'] ],\n                    [ ['BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'], ['BUILD_WARNFATAL=no','BUILD_WARNOPT=minimal'] ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: dynacfgPipeline.excludeCombos_DEFAULT_CPPUNIT + [\n                    dynacfgPipeline.axisCombos_GNU_C,\n                    dynacfgPipeline.axisCombos_WINDOWS_CROSS,\n                    dynacfgPipeline.axisCombos_WINDOWS\n                    ] + [dynacfgPipeline.axisCombos_COMPILER_GCC]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: 'Strict C and GNU standard builds on native-Windows platforms, without distcheck and docs (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuildExperimental,\n         branchRegexSource: ~/^(PR-.+|.*fightwarn.*|.*Windows.*)$/,\n         branchRegexTarget: ~/fightwarn|Windows-.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                requiredNodelabels: [],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [32, 64],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '98'], ['c': '99', 'cxx': '11'], ['c': '17', 'cxx': '17'] ],\n                    'CSTDVARIANT': ['c', 'gnu'],\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=default-all-errors',\n                     'BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard',\n                     'CPPFLAGS=-fms-extensions'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    [~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: [\n                    dynacfgPipeline.axisCombos_ARCH32x64,\n                    dynacfgPipeline.axisCombos_ARCH64x32,\n                    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD,\n                    dynacfgPipeline.axisCombos_WINDOWS_CROSS,\n                    dynacfgPipeline.axisCombos_NOT_WINDOWS\n                    ]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n\n        ,[name: (dynacfgPipeline.disableStrictCIBuild_CrossWindows ? '' : 'Strict C and ') + 'GNU standard builds on cross-Windows platforms (Linux+mingw), without distcheck and docs (allowed to fail)',\n         disabled: dynacfgPipeline.disableSlowBuildCIBuild,\n         //branchRegexSource: ~/^(PR-.+|.*fightwarn.*|.*Windows.*)$/,\n         //branchRegexTarget: ~/fightwarn|Windows-.*/,\n         appliesToChangedFilesRegex: dynacfgPipeline.appliesToChangedFilesRegex_C,\n         'getParStages': { def dynamatrix, Closure body ->\n            return dynamatrix.generateBuild([\n                commonLabelExpr: \"cross-windows-nut-builder\",\n                dynamatrixAxesLabels: ['OS_FAMILY', 'OS_DISTRO', 'ARCH${ARCH_BITS}', 'COMPILER'],\n                requiredNodelabels: [\"NUT_BUILD_CAPS=cross-windows-mingw\"],\n                excludedNodelabels: [],\n\n                dynamatrixAxesVirtualLabelsMap: [\n                    'BITS': [64, 32],\n                    'CSTDVERSION_${KEY}': [ ['c': '99', 'cxx': '11'] ],\n                    'CSTDVARIANT': ['gnu'] + (dynacfgPipeline.disableStrictCIBuild_CrossWindows ? [] : ['c']),\n                    ],\n                dynamatrixAxesCommonEnv: [\n                    ['LANG=C','LC_ALL=C','TZ=UTC',\n                     'BUILD_TYPE=cross-windows-mingw',\n                     // Note: warnings options are currently ignored in ci_build.sh\n                     // for this BUILD_TYPE (technically in build-mingw-nut.sh)\n                     'BUILD_WARNFATAL=yes','BUILD_WARNOPT=hard'\n                    ]\n                    ],\n                allowedFailure: [\n                    dynacfgPipeline.axisCombos_STRICT_C,\n                    //dynacfgPipeline.axisCombos_WINDOWS_CROSS,\n                    //[~/BUILD_WARNOPT=hard/]\n                    ],\n                runAllowedFailure: true,\n                mergeMode: [ 'excludeCombos': 'merge', 'dynamatrixAxesCommonEnv': 'replace' ], // NOTE: We might want to replace other fields, but excludeCombos must be merged to filter compiler versions vs. language standards as centrally defined!\n                excludeCombos: [\n                    dynacfgPipeline.axisCombos_ARCH32x64,\n                    dynacfgPipeline.axisCombos_ARCH64x32,\n                    dynacfgPipeline.axisCombos_COMPILER_GCC_TOO_OLD,\n                    dynacfgPipeline.axisCombos_WINDOWS,\n                    dynacfgPipeline.axisCombos_NOT_WINDOWS_CROSS\n                    ]\n                ], body)\n            }, // getParStages\n        'bodyParStages': dynacfgPipeline.slowBuildDefaultBody_ci_build\n        ] // one slowBuild filter configuration\n    ]\n\n    dynacfgPipeline.notifyHandler = {\n        def summary = null\n        try {\n            summary = dynamatrix.toStringStageCountDump()\n        } catch (Throwable t) {}\n\n        if (summary == null || summary == \"\") {\n            ircNotify (notificationStrategy:'FAILURE_AND_FIXED')\n        } else {\n            ircNotify (notificationStrategy:'FAILURE_AND_FIXED', customMessage: summary)\n        }\n    }\n\n@NonCPS\ndef stageNameFunc_ShellcheckCustom(DynamatrixSingleBuildConfig dsbc) {\n    // NOTE: A direct Closure seems to confuse Jenkins/Groovy CPS, so using a func\n    def labelMap = dsbc.getKVMap(false)\n    String sn = \"\"\n    if (labelMap.containsKey(\"OS_FAMILY\"))\n        sn += labelMap.OS_FAMILY + \"-\"\n    if (labelMap.containsKey(\"OS_DISTRO\"))\n        sn += labelMap.OS_DISTRO + \"-\"\n    return \"MATRIX_TAG=\\\"${sn}shellcheckCustom\\\"\"\n}\n//dynacfgPipeline.shellcheck.stageNameFunc = this.&stageNameFunc_ShellcheckCustom\n\n///////////////////////////////////////////////////////////////////////////\n\n// Hacky big switch for a max debug option\n//if (true)  // <<< (Un-)comment away in select runs/branches\n//if (false) // <<< (Un-)comment away in select runs/branches\nif ( env?.BRANCH_NAME ==~ /.*verbose.*/ )\n{\n    dynamatrixGlobalState.enableDebugTrace = true\n    dynamatrixGlobalState.enableDebugErrors = true\n    dynamatrixGlobalState.enableDebugMilestones = true\n    dynamatrixGlobalState.enableDebugMilestonesDetails = true\n    dynamatrixGlobalState.enableDebugTraceGithubStatusHighlights = true\n}\n\n//if (true)  // <<< (Un-)comment away in select runs/branches\n//if (false) // <<< (Un-)comment away in select runs/branches\nif ( env?.BRANCH_NAME ==~ /.*fightwarn.*/ )\n{\n    dynamatrixGlobalState.enableDebugTraceGithubStatusHighlights = true\n}\n\ndynamatrixPipeline(dynacfgBase, dynacfgPipeline)\n"
        },
        {
          "name": "LICENSE-DCO",
          "type": "blob",
          "size": 1.333984375,
          "content": "Developer Certificate of Origin\nVersion 1.1\n\nCopyright (C) 2004, 2006 The Linux Foundation and its contributors.\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nDeveloper's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n(a) The contribution was created in whole or in part by me and I\n    have the right to submit it under the open source license\n    indicated in the file; or\n\n(b) The contribution is based upon previous work that, to the best\n    of my knowledge, is covered under an appropriate open source\n    license and I have the right under that license to submit that\n    work with modifications, whether created in whole or in part\n    by me, under the same open source license (unless I am\n    permitted to submit under a different license), as indicated\n    in the file; or\n\n(c) The contribution was provided directly to me by some other\n    person who certified (a), (b) or (c) and I have not modified\n    it.\n\n(d) I understand and agree that this project and the contribution\n    are public and that a record of the contribution (including all\n    personal information I submit with it, including my sign-off) is\n    maintained indefinitely and may be redistributed consistent with\n    this project or the open source license(s) involved.\n"
        },
        {
          "name": "LICENSE-GPL2",
          "type": "blob",
          "size": 17.5654296875,
          "content": "\t\t    GNU GENERAL PUBLIC LICENSE\n\t\t       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\t\t\t    Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Lesser General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n\t\t    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n\t\t\t    NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n\t\t     END OF TERMS AND CONDITIONS\n\n\t    How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License along\n    with this program; if not, write to the Free Software Foundation, Inc.,\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.\n"
        },
        {
          "name": "LICENSE-GPL3",
          "type": "blob",
          "size": 34.24609375,
          "content": "\n\t\t    GNU GENERAL PUBLIC LICENSE\n\t\t       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\t\t\t    Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n\t\t       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n \n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n  \n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n\t\t     END OF TERMS AND CONDITIONS\n\n\t    How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n\n"
        },
        {
          "name": "MAINTAINERS",
          "type": "blob",
          "size": 1.798828125,
          "content": "In the tradition of stealing ideas for top-level files from the Linux\nkernel tree, here is the NUT MAINTAINERS file.  This file is intended to\nhelp patch contributors route their changes to the right people.\n\nNote: just because something isn't listed in here doesn't mean it's not\nbeing maintained.  It just means that the maintainer hasn't sent me a\npatch to update this file yet.\n\nNote 2: there are always other people who work on a project beyond those\nwho are listed here.  Omission from this list should not be taken as a\nslight.  Those who are listed below are merely volunteering to be the\n\"lightning rods\" for patches to certain parts of the tree.\n\nFields\n======\n\nP: Person\nM: Mail patches to this address\nW: Web address\nS: Status:\n\n   Supported  = someone is paid to do this\n   Maintained = someone keeps it running\n\n   (add others as necessary)\n\nIn the case of drivers, \"maintained\" should only be used if you have\naccess to the hardware in question for testing.\n\nDrivers\n=======\n\nP: Russell Kroll\nM: rkroll@exploits.org\nS: Maintained: apcsmart, belkin, bestups, cyberpower, dummycons,\n               fentonups, driver core (main.c), upsdrvctl\n\nP: Arnaud Quette\nM: aquette.dev@gmail.com\nM: ArnaudQuette@eaton.com\nS: Maintained or Supported: dummy-ups, usbhid-ups, mge-shut\n                            mge-utalk, snmp-ups, ...\n\nP: Fabio Di Niro\nM: blaxwan@users.sourceforge.net\nS: Maintained: metasys\n\nP: Kirill Smelkov\nM: kirr@mns.spb.ru\nS: Maintained: al175\n\nPackaging\n=========\n\nP: Nigel Metheringham\nM: Nigel.Metheringham@dev.InTechnology.co.uk\nS: Maintained: nut.spec.in (for Red Hat RPM builds)\n\nP: Arnaud Quette\nM: aquette@debian.org\nS: Maintained: Official Debian packages\n\nP: Greg Troxel\nM: gdt@lexort.com\nS: Maintained: pkgsrc (sysutils/ups-nut)\n\nEverything else\n===============\n\nNo other categories have been created yet.\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 33.2216796875,
          "content": "# top-level Makefile for NUT\n\n# Export certain values for ccache which NUT ci_build.sh can customize,\n# to facilitate developer iteration re-runs of \"make\" later.\n# At least GNU and BSD make implementations are okay with this syntax.\n@NUT_AM_MAKE_CAN_EXPORT@@NUT_AM_EXPORT_CCACHE_NAMESPACE@export CCACHE_NAMESPACE=@CCACHE_NAMESPACE@\n@NUT_AM_MAKE_CAN_EXPORT@@NUT_AM_EXPORT_CCACHE_BASEDIR@export CCACHE_BASEDIR=@CCACHE_BASEDIR@\n@NUT_AM_MAKE_CAN_EXPORT@@NUT_AM_EXPORT_CCACHE_DIR@export CCACHE_DIR=@CCACHE_DIR@\n@NUT_AM_MAKE_CAN_EXPORT@@NUT_AM_EXPORT_CCACHE_PATH@export CCACHE_PATH=@CCACHE_PATH@\n@NUT_AM_MAKE_CAN_EXPORT@@NUT_AM_EXPORT_CCACHE_PATH@export PATH=@PATH_DURING_CONFIGURE@\n\n# First target often defines default behavior: all\n# We follow up with another pass to `make doc` because our wild recipes\n# sometimes preclude generating all of them on the first pass (FIXME!)\n# missing e.g. PDF and HTML which then pop up in `make check` footprint,\n# or misses a .prep-src-docs stage needed to pattern-make man page files\n# with some \"make\" implementations...\nall all-am-local all-local: all-recursive\n\t+@$(MAKE) $(AM_MAKEFLAGS) doc\n\t+@$(MAKE) $(AM_MAKEFLAGS) doc\n\n# include directory for aclocal\nACLOCAL_AMFLAGS = -I m4\n\n# subdirectories to build and distribute. The order matters, as\n# several subdirectories depend on stuff in \"common\" or tools being built first\nSUBDIRS = include common clients conf data docs drivers tools \\\n  lib scripts server tests\n\nbindir = @bindir@\nsbindir = @sbindir@\ndriverexecdir = @driverexecdir@\ncgiexecdir = @cgiexecdir@\n\n# Automatically update the libtool script if it becomes out-of-date\n# See https://www.gnu.org/software/libtool/manual/html_node/LT_005fINIT.html\nLIBTOOL_DEPS = @LIBTOOL_DEPS@\nlibtool: $(LIBTOOL_DEPS)\n\t$(SHELL) ./config.status libtool\n\n# COPYING and other autotools-standard files are included automatically\n# by automake. Note that the INSTALL file is (re-)imposed by autotools\n# runs and is essentially a manual on configure script general usage, so\n# NUT's actual installation notes have had to use a different filename.\nEXTRA_DIST = LICENSE-GPL2 LICENSE-GPL3 LICENSE-DCO MAINTAINERS\n\n# Since the renaming of documentation to `*.adoc` extension to help IDE\n# and GitHub UIs to render the source files in a pretty fashion, we need\n# to list them:\nEXTRA_DIST += INSTALL.nut.adoc UPGRADING.adoc TODO.adoc NEWS.adoc README.adoc\n\n# Tarballs created by `make dist` include the `configure.ac` and `m4/*` sources\n# but lack NUT magic logic to recreate the `configure` script if someone would\n# want to adapt it to their autotools or locally fix a tarball-based build.\nEXTRA_DIST += autogen.sh\n\nif KEEP_NUT_REPORT\nnodist_data_DATA = config.nut_report_feature.log\nendif\n\n# ----------------------------------------------------------------------\n# flags to pass to ./configure when calling \"make distcheck\" and \"make\n# distcheck-light\". Try to check as many features as possible! Also\n# need to give augeas-lenses-dir, hotplug-dir and udev-dir, and request\n# PyNUT to be installed near the NUT-Monitor app (if feasible) so that\n# staged install does not fail. Note that by default PyNUT tries to go\n# into the system Python site-packages location, and autotools does not\n# tweak paths not using ${prefix} so `make distcheck` fails for it as\n# it does not play with a `DESTDIR` either.\n\nDISTCHECK_FLAGS = --with-all --with-ssl --with-doc=auto --with-pynut=app --with-nut_monitor=force\nDISTCHECK_LIGHT_FLAGS = --with-all=auto --with-ssl=auto --with-doc=auto --with-pynut=app --with-nut_monitor=force\nDISTCHECK_LIGHT_MAN_FLAGS = --with-all=auto --with-ssl=auto --with-doc=man --with-pynut=app --with-nut_monitor=force\nDISTCHECK_VALGRIND_FLAGS = --with-all=auto --with-ssl=auto --with-doc=skip --with-valgrind CXXFLAGS='$(CXXFLAGS) -g' CFLAGS='$(CFLAGS) -g' --with-pynut=app --with-nut_monitor=force\n\n# Note: this rule uses envvar DISTCHECK_FLAGS expanded at run-time\nDISTCHECK_CONFIGURE_FLAGS = ${DISTCHECK_FLAGS}\t\t\\\n --with-systemdsystemunitdir='$${prefix}/lib/systemd/system' \\\n --with-systemdsystempresetdir='$${prefix}/usr/lib/systemd/system-preset' \\\n --with-systemdshutdowndir='$${prefix}/lib/systemd/system-shutdown' \\\n --with-systemdtmpfilesdir='$${prefix}/usr/lib/tmpfiles.d' \\\n --with-augeas-lenses-dir='$${prefix}/usr/share/augeas/lenses'\t\t\\\n --with-hotplug-dir='$${prefix}/etc/hotplug'\t\t\\\n --with-udev-dir='$${prefix}/etc/udev'\t\t\t\\\n --with-devd-dir='$${prefix}/etc/devd'\t\t\t\\\n --with-pynut=app --with-nut_monitor=force\n\n# Note: trickery with prefix below is needed to expand it from\n# DISTCHECK_CONFIGURE_FLAGS defaults defined above in a manner\n# that is meaningful for sub-make program (gets stripped away\n# otherwise and breaks custom distchecks).\ndistcheck-light:\n\t+prefix='$${prefix}'; $(MAKE) $(AM_MAKEFLAGS) DISTCHECK_CONFIGURE_FLAGS=\"$(DISTCHECK_CONFIGURE_FLAGS)\" DISTCHECK_FLAGS=\"$(DISTCHECK_LIGHT_FLAGS)\" distcheck\n\ndistcheck-light-man:\n\t+prefix='$${prefix}'; $(MAKE) $(AM_MAKEFLAGS) DISTCHECK_CONFIGURE_FLAGS=\"$(DISTCHECK_CONFIGURE_FLAGS)\" DISTCHECK_FLAGS=\"$(DISTCHECK_LIGHT_MAN_FLAGS)\" distcheck\n\n# Make a distcheck (and check in particular) with enabled valgrind and debug info\nmemcheck distcheck-valgrind:\n\t@echo \"See also scripts/valgrind in NUT sources for a helper tool\"\n\t+prefix='$${prefix}'; $(MAKE) $(AM_MAKEFLAGS) DISTCHECK_CONFIGURE_FLAGS=\"$(DISTCHECK_CONFIGURE_FLAGS)\" DISTCHECK_FLAGS=\"$(DISTCHECK_VALGRIND_FLAGS)\" distcheck\n\n# workaround the dist generated files that are also part of the distribution\n# Note that distcleancheck is disabled for now, while waiting for a proper\n# solution, that do not break older unix systems\n#distcleancheck_listfiles = \\\n#\tfind . -type f -exec sh -c 'test -f $(srcdir)/{} || echo {}' ';'\ndistcleancheck:\n\t@:\n\n# Quick alias for root dir recipe:\nrealclean: maintainer-clean\n\n# Files made by our targets:\nCLEANFILES = *-spellchecked *.adoc-parsed cppcheck*.xml config.log.inplace-outer\nDISTCLEANFILES = ChangeLog\n\n# Most of the files generated by custom rules in the configure script\n# or by autogen.sh are cleaned by the Makefile.am in their directories.\n# Files below are re-created by running `configure` script and may be\n# wiped by a `make distclean`:\nDISTCLEANFILES += config.log configure~\n#???# configure.ac~\nDISTCLEANFILES += include/config.h.in~\n\n# Files made by autotools and common rituals of the configure script,\n# these are needed to run the configure script itself so are not wiped\n# by a mere `make distclean`; most of these are copied by autotools\n# from their installation, or made by `automake` etc. on the system\n# which generates `configure`; rebuilding NUT after deleting these\n# requires `autogen.sh` script to be re-run (and tools available):\nMAINTAINERCLEANFILES = INSTALL\nMAINTAINERCLEANFILES += aclocal.m4 config.guess config.sub\nMAINTAINERCLEANFILES += configure\nMAINTAINERCLEANFILES += depcomp install-sh ltmain.sh test-driver ar-lib\nMAINTAINERCLEANFILES += m4/libtool.m4 m4/ltoptions.m4 m4/ltsugar.m4 m4/ltversion.m4 m4/lt~obsolete.m4\nMAINTAINERCLEANFILES += Makefile.in .dirstamp include/config.h.in\n\n# Executed after default rules\nmaintainer-clean-local:\n\t$(AM_V_at)rm -f missing || true\n\n# Do not let $SUBDIRS/Makefile rules delete their local .deps because\n# this breaks our ability to clean up (e.g. some common/.../*.Plo files\n# are included by generated Makefiles from other subdirectories, so they\n# should be available during their clean-up). Just in case, we make sure\n# here that their sub-distcleans complete first.\ndistclean-local:\n\t+@for DIR in $(SUBDIRS) ; do \\\n\t\tif test -f \"$${DIR}/Makefile\" ; then \\\n\t\t\techo \"  DISTCLEAN  in $${DIR}\" >&2 ; \\\n\t\t\t( cd \"$${DIR}\" && $(MAKE) $(AM_MAKEFLAGS) -s distclean ) || exit ; \\\n\t\tfi ; \\\n\t done\n\t$(AM_V_at)rm -rf .inst tmp autom4te.cache\n\t$(AM_V_at)find \"$(builddir)\" -type d -name '.deps' | while read DIR ; do rm -rf \"$${DIR}\" ; done\n\n# Hook the documentation building and validating recipes\n# Note: these are optionally available (as determined during configure runs)\n# Maint: grep -l 'SPELLCHECK_' `git grep -lw spellcheck '*.am'`\nspellcheck spellcheck-interactive:\n\t+@RES=0; \\\n\t(cd $(builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) -s $(abs_top_builddir)/docs/.prep-src-docs) || RES=$$? ; \\\n\t(cd $(builddir)/docs/man && $(MAKE) $(AM_MAKEFLAGS) -s $(abs_top_builddir)/docs/man/.prep-src-docs) || RES=$$? ; \\\n\t(cd $(builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/docs/man && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/conf && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/data && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/data/html && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/Solaris && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/Windows && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/devd && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/hotplug && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/installer && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/python && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/systemd && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/udev && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/scripts/upsdrvsvcctl && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\t(cd $(builddir)/tests/NIT && $(MAKE) $(AM_MAKEFLAGS) -s $@) || RES=$$? ; \\\n\texit $$RES\n\n# Note: the \"all-docs\" and \"check-docs\" targets may require tools not\n# found by `configure` script (and so avoided by conventional recipes)\n# such as PDF generators, so it should only be called at developer's\n# discretion, choice and risk. The \"check-man\" targets covers source\n# texts, man pages and HTML rendering of man pages, as enabled by tools.\ndoc spellcheck-sortdict spellcheck-report-dict-usage \\\nall-docs check-docs \\\nman all-man man-man check-man html-man all-html:\n\t+cd $(abs_top_builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) -s $(abs_top_builddir)/docs/.prep-src-docs\n\t+cd $(abs_top_builddir)/docs/man && $(MAKE) $(AM_MAKEFLAGS) -s $(abs_top_builddir)/docs/man/.prep-src-docs\n\t+cd $(abs_top_builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) $@\n\nINSTALL.nut UPGRADING NEWS README:\n\t+cd $(abs_top_builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) ../$(@F).adoc-parsed && cp -f ../$(@F).adoc-parsed ../$(@F)\n\n# Workarounds for https://github.com/github/markup/issues/1095\n# require direct definition of our attributes in each source\n# document, in order for GitHub Web-UI to render them nicely\n# (unfortunately, asciidoc configs and includes are not handled\n# at this time). Hopefully this will go away at some point.\n# The following rule updates definitions in source asciidoc files\n# between GH_MARKUP_1095_INCLUDE_BEGIN/END tags with contents of\n# current docs/asciidoc-vars.conf file. It is intended to be used\n# by maintainers (or brave contributors who would dare edit those\n# definitions), to apply them into the committed document sources.\n# Not bothering about with \"make dist\" constraints etc. - changes\n# the contents of srcdir directly and intentionally.\n# NOTE: There is a problem with `printf '%s' \"${LINE}\"` (double-quoted)\n# that causes backslashes to be treated as escape characters, and\n# shell replacements with `${VAR/pat/sub}` are not really portable.\n# To address this, we use the pure POSIX shell `replace_all()`\n# method suggested at https://stackoverflow.com/a/75037170/4715872\n# WARNING: It may succumb to lines ending with asterisk however!\nMAINTAINER_ASCIIDOCS_RECIPE_DEBUG_STREAM = /dev/null\n#MAINTAINER_ASCIIDOCS_RECIPE_DEBUG_STREAM = &2\n\nmaintainer-asciidocs:\n\t@USEDREV=\"`git log -1 --oneline --pretty=format:'%h (%cs) %s' docs/asciidoc-vars.conf`\" || exit ; \\\n\t USEDREV_NOSUBJ=\"`git log -1 --oneline --pretty=format:'%h (%cs)' docs/asciidoc-vars.conf`\" || exit ; \\\n\t echo \"$@: Updating asciidoc text sources with docs/asciidoc-vars.conf as of commit: $${USEDREV}\"; \\\n\t echo \"//GH_MARKUP_1095_INCLUDE_BEGIN//$${USEDREV}\" > docs/asciidoc-vars.conf.lastrev.tmp || exit ; \\\n\t replace_all() { \\\n\t   case \"$$1\" in *\"$$2\"*) ;; *) echo \"$$1\" ; return ;; esac ; \\\n\t   RIGHT=\"$$1\" ; R=''; \\\n\t   while [ -n \"$$RIGHT\" ]; do \\\n\t    echo \"LEFT='$$LEFT' RIGHT='$$RIGHT' => R='$$R'\" >$(MAINTAINER_ASCIIDOCS_RECIPE_DEBUG_STREAM) ; \\\n\t    LEFT=\"$${RIGHT%%$$2*}\" ; \\\n\t    echo \"=> LEFT='$$LEFT'\" >$(MAINTAINER_ASCIIDOCS_RECIPE_DEBUG_STREAM) ; \\\n\t    if [ x\"$$LEFT\" = x\"$$RIGHT\" ]; then \\\n\t        R=\"$$R$$RIGHT\" ; \\\n\t        return ; \\\n\t    fi ; \\\n\t    R=\"$$R$$LEFT$$3\" ; \\\n\t    RIGHT=\"$${RIGHT#*$$2}\" ; \\\n\t  done ; \\\n\t  echo \"$$R\" ; \\\n\t } ; \\\n\t find . -name '*.adoc' -or -name '*.txt' | ( \\\n\t  FILES=\"\"; \\\n\t  while read F ; do \\\n\t    grep -E '^//+GH_MARKUP_1095_INCLUDE_(BEGIN|END)' \"$$F\" >/dev/null \\\n\t    || { echo \"$@: SKIP: no GH_MARKUP_1095_INCLUDE_* tags: $$F\"; continue ; } ; \\\n\t    rm -f \"$${F}\"*.tmp || exit ; \\\n\t    EXT=\"1.tmp\"; \\\n\t    while IFS='' read LINE ; do \\\n\t        case \"$${LINE}\" in \\\n\t            \"//GH_MARKUP_1095_INCLUDE_BEGIN\"*) EXT=\"2.tmp\" ; continue ;; \\\n\t            \"//GH_MARKUP_1095_INCLUDE_END\"*|\"////GH_MARKUP_1095_INCLUDE_END\"*) EXT=\"3.tmp\" ; continue ;; \\\n\t        esac ; \\\n\t        printf '%s\\n' \"`replace_all \"$${LINE}\" '\\\\' '''\\\\'`\" >> \"$${F}.$${EXT}\" || exit ; \\\n\t    done < \"$$F\" || { echo \"$@: FAILED injection for $${F}\" >&2; exit 1; } ; \\\n\t    if test -s \"$${F}.2.tmp\" && test -z \"`diff \"$${F}.2.tmp\" docs/asciidoc-vars.conf | tr -d '\\n'`\" ; then \\\n\t        rm -f \"$${F}\"*.tmp ; \\\n\t        echo \"$@: SKIP: no changes: $$F\"; continue ; \\\n\t    fi; \\\n\t    cat \"$${F}.1.tmp\" docs/asciidoc-vars.conf.lastrev.tmp docs/asciidoc-vars.conf > \"$${F}.tmp\" \\\n\t    && echo '//GH_MARKUP_1095_INCLUDE_END//' >> \"$${F}.tmp\" \\\n\t    && cat \"$${F}.3.tmp\" >> \"$${F}.tmp\" \\\n\t    && mv -f \"$${F}.tmp\" \"$${F}\" \\\n\t    || { echo \"$@: FAILED injection for $${F}\" >&2; exit 1; } ; \\\n\t    echo \"$@: UPDATED: $$F\"; \\\n\t    FILES=\"$${FILES} $${F}\"; \\\n\t    rm -f \"$${F}\"*.tmp ; \\\n\t  done; \\\n\t  rm -f docs/asciidoc-vars.conf.lastrev.tmp; \\\n\t  if test -z \"$${FILES}\" ; then \\\n\t    echo \"$@: OVERALL-SKIP: No text files found with GH_MARKUP_1095_INCLUDE_ tags, or obsoleted docs/asciidoc-vars.conf contents\";\\\n\t  else \\\n\t    echo \"$@: OVERALL-UPDATED: You may now want to:\"; \\\n\t    echo \"    git add -p $${FILES} && git commit -sm 'Update NUT documentation sources with current docs/asciidoc-vars.conf: $${USEDREV_NOSUBJ}'\"; \\\n\t  fi; \\\n\t )\n\ncheck-NIT check-NIT-devel check-NIT-sandbox check-NIT-sandbox-devel:\n\t+cd $(builddir)/tests/NIT && $(MAKE) $(AM_MAKEFLAGS) $@\n\nVERSION_DEFAULT: dummy-stamp\n\t@abs_top_srcdir='$(abs_top_srcdir)' ; \\\n\t abs_top_builddir='$(abs_top_builddir)' ; \\\n\t export abs_top_srcdir ; export abs_top_builddir ; \\\n\t NUT_VERSION_QUERY=UPDATE_FILE '$(abs_top_srcdir)/tools/gitlog2version.sh'\n\nCLEANFILES += VERSION_DEFAULT.tmp\nEXTRA_DIST += VERSION_DEFAULT\n\n# Best-effort delivery for (overly?) customized distros, e.g. via\n#   echo NUT_VERSION_FORCED_SEMVER=1.1.1 > VERSION_FORCED_SEMVER\ndist-hook:\n\tfor D in \"$(abs_top_srcdir)\" \"$(abs_top_builddir)\" ; do \\\n\t    for F in VERSION_FORCED VERSION_FORCED_SEMVER ; do \\\n\t        if [ -s \"$$D/$$F\" ] ; then \\\n\t            cat \"$$D/$$F\" > \"$(top_distdir)/$$F\" || true ; \\\n\t        fi ; \\\n\t    done ; \\\n\tdone\n\n# This target adds syntax-checking for committed shell script files,\n# to avoid surprises and delays in finding fatal typos after packaging\n###\n### Note: currently, shellcheck target calls check-scripts-syntax\n### so when both are invoked at once, in the end the check is only\n### executed once. Later it is anticipated that shellcheck would\n### be implemented by requiring, configuring and calling the tool\n### named \"shellcheck\" for even more code inspection and details.\n### Still, there remains value in also checking the script syntax\n### by the very version of the shell interpreter that would run\n### these scripts in production usage of the resulting packages.\n###\ncheck-scripts-syntax:\n\t@echo 'NOTE: modern bash complains about scripts using backticks (warning not error), which we ignore in NUT codebase for portability reasons: `...` obsolete, use $$(...)'\n\t@RUNBASH=bash; if [ -x /bin/bash ] && /bin/bash -c 'echo $${BASH_VERSION}' | grep -E '^[456789]\\.' ; then RUNBASH=/bin/bash ; else if [ -x /usr/bin/env ] ; then RUNBASH=\"/usr/bin/env bash\"; fi; fi ; \\\n\t for F in `git ls-files || find . -type f` ; do \\\n\t    case \"`file \"$$F\"`\" in \\\n\t        *\"Bourne-Again shell script\"*) ( set -x ; $$RUNBASH -n \"$$F\" ; ) ;; \\\n\t        *\"POSIX shell script\"*|*\"shell script\"*) ( set -x ; /bin/sh -n \"$$F\" ; ) ;; \\\n\t    esac || { RES=$$? ; echo \"ERROR: Syntax check failed for script file: $$F\" >&2 ; exit $$RES ; } ; \\\n\tdone\n\t@echo 'SUCCESS: Shell scripts syntax is acceptable, no fatal issues were found'\n\nshellcheck-disclaimer:\n\t@echo \"===============================================================================\"\n\t@echo \"NOTICE: 'make shellcheck' is currently an alias for 'make check-scripts-syntax'\"\n\t@echo \"Later it may become a call to the real shellcheck tool (if available on the\"\n\t@echo \"build system during the configure phase)\"\n\t@echo \"===============================================================================\"\n\n# Note: currently not part of shellcheck target, because the script below\n# can test the logic with numerous SHELL_PROGS in a CI setting, and because\n# check-scripts-syntax probably has checked the basic syntax above already.\nshellcheck-nde:\n\tcd $(srcdir)/tests && SERVICE_FRAMEWORK=\"selftest\" ./nut-driver-enumerator-test.sh\n\nshellcheck: shellcheck-disclaimer check-scripts-syntax\n\nCPPCHECK = @CPPCHECK@\nif HAVE_CPPCHECK\ncppcheck: cppcheck-cxx11.xml cppcheck-c99.xml\n\n# Let the analysis get regenerated due to any change in source;\n# but note that with our different make implementations to support,\n# we can not either $(shell find ...) nor blindly say e.g. *.cpp\n# for each FS structure layer because e.g. there are no ./*.cpp\n# in the root dir of the codebase (and so make complains there is\n# `No rule to make target `*.cpp', needed by `cppcheck-cxx11.xml'`)\n#\n# Note that the actual `cppcheck` scan finds all files it likes\n# (so if CPPCHECK_SRC_* misses something, it just won't trigger\n# automagically a rebuild of the XML in developer working cycles).\nCPPCHECK_SRC_H = $(top_srcdir)/*/*.h $(top_srcdir)/*/*/*.h\n# CPPCHECK_SRC_H += $(top_srcdir)/*.h\n\nCPPCHECK_SRC_C = $(top_srcdir)/*/*.c $(top_srcdir)/*/*/*.c\n# CPPCHECK_SRC_C += $(top_srcdir)/*.cpp\n\nCPPCHECK_SRC_CXX = $(top_srcdir)/*/*.cpp\n# CPPCHECK_SRC_CXX += $(top_srcdir)/*.cpp $(top_srcdir)/*/*/*.cpp\n\ncppcheck-cxx11.xml: $(CPPCHECK_SRC_CXX) $(CPPCHECK_SRC_H)\n\t$(CPPCHECK) --std=c++11 --enable=all --inconclusive --xml --xml-version=2 . 2>$@\n\ncppcheck-c99.xml: $(CPPCHECK_SRC_C) $(CPPCHECK_SRC_H)\n\t$(CPPCHECK) --std=c99 --enable=all --inconclusive --xml --xml-version=2 . 2>$@\nelse !HAVE_CPPCHECK\ncppcheck:\n\t@echo \"CPPCHECK analysis not available since 'cppcheck' was not found.\"\nendif !HAVE_CPPCHECK\n\nsockdebug:\n\t+cd $(builddir)/server && $(MAKE) $(AM_MAKEFLAGS) sockdebug$(EXEEXT)\n\n# ----------------------------------------------------------------------\n# Automatically generate the ChangeLog from Git logs:\nMAINTAINERCLEANFILES += ChangeLog\n\n# CI builds can leave a log of selected features:\nMAINTAINERCLEANFILES += config.nut_report_feature.log*\n\n# Older boundary of the ChangeLog commits range\n# It can be a tag ('v2.2.0'), a commit hash, a date, ...\n# See gitrevisions for more information on specifying ranges\nGITLOG_START_POINT=v2.6.0\n\n# Force ChangeLog regeneration upon make dist (due to nonexistant 'dummy-stamp'),\n# in case it has already been generated previously\n# Note that the script is hard-coded to inspect Git workspace which contains\n# the current dir, and defaults to generate a \"ChangeLog\" in the current dir.\n# The script itself is generated from a template, so resides in builddir.\ndummy-stamp:\nChangeLog: dummy-stamp\n\t+@$(MAKE) $(AM_MAKEFLAGS) $(abs_top_builddir)/ChangeLog\n\nif WITH_PDF_NONASCII_TITLES\nWITH_PDF_NONASCII_TITLES_ENVVAR = WITH_PDF_NONASCII_TITLES=yes\nelse\nWITH_PDF_NONASCII_TITLES_ENVVAR = WITH_PDF_NONASCII_TITLES=no\nendif\n\n# Be sure to not confuse with a DIST'ed file (and so try to overwrite it);\n# do however avoid re-generating it if already made on a previous pass and\n# the Git HEAD pointer (branch) or its actual \"index\" or \"object\" database\n# did not change since then - meaning the local developer or CI did not\n# modify the metadata (subsequent generation of the huge PDF/HTML files\n# can cost dearly).\n# Note there's a bit more fuss about Git internals which NUT should not\n# really care about encapsulation-wise (detection of NUT_GITDIR location\n# which may reside elsewhere, e.g. with local repo clones with reference\n# repo configuration, or submodules). But this is a Git-crawling target\n# anyway, and in the worst case (Git's design changes) we would spend a\n# bit of time researching the FS in vain, and go on to re-generate the\n# ChangeLog when maybe we should not have - oh well.\n# WARNING: The CHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR=true mode here is\n# default to allow for prettier documentation, but it can require too much\n# memory for weaker build systems. Set it to false when calling make there.\nCHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR_ENVVAR = true\n$(abs_top_builddir)/ChangeLog: tools/gitlog2changelog.py dummy-stamp\n\t@cd $(abs_top_srcdir) && \\\n\t    if test -e .git ; then \\\n\t        NUT_GITDIR=\".git\" ; if test -r \"$${NUT_GITDIR}\" -a ! -d \"$${NUT_GITDIR}\" ; then GD=\"`grep -E '^gitdir:' \"$${NUT_GITDIR}\" | sed 's/^gitdir: *//'`\" && test -n \"$$GD\" -a -d \"$$GD\" && NUT_GITDIR=\"$$GD\" ; fi ; \\\n\t        if test -s \"$@\" -a -d \"$${NUT_GITDIR}\" && test -z \"`find \"$${NUT_GITDIR}\" -newer \"$@\" 2>/dev/null`\" ; then \\\n\t            echo \"  DOC-CHANGELOG-GENERATE        $@ : SKIP (keep existing)\" ; \\\n\t            echo \"Using still-valid ChangeLog file generated earlier from same revision of Git source metadata in '$${NUT_GITDIR}'\" >&2 ; \\\n\t        else \\\n\t            echo \"  DOC-CHANGELOG-GENERATE        $@\" ; \\\n\t            CHANGELOG_FILE=\"$@\" $(WITH_PDF_NONASCII_TITLES_ENVVAR) \\\n\t            CHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR=\"$(CHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR_ENVVAR)\" \\\n\t              $(abs_top_builddir)/tools/gitlog2changelog.py $(GITLOG_START_POINT) || { \\\n\t                echo \"  DOC-CHANGELOG-GENERATE        $@ : FAILED (non-fatal)\" >&2 ; \\\n\t                printf \"gitlog2changelog.py failed to generate the ChangeLog.\\n\\nNOTE: See https://github.com/networkupstools/nut/commits/master for change history.\\n\\n\" > \"$@\" ; \\\n\t            } ; \\\n\t        fi ; \\\n\t    else \\\n\t        if test x\"$(abs_top_srcdir)\" != x\"$(abs_top_builddir)\" -a -s ./ChangeLog ; then \\\n\t            echo \"  DOC-CHANGELOG-GENERATE        $@ : SKIP (keep existing)\" ; \\\n\t            echo \"Using distributed ChangeLog file from sources\" >&2 ; \\\n\t            rm -f \"$@\" || true ; \\\n\t            cat ./ChangeLog > \"$@\" ; \\\n\t        else \\\n\t            if test -s \"$@\" ; then \\\n\t                echo \"  DOC-CHANGELOG-GENERATE        $@ : SKIP (keep existing)\" ; \\\n\t                echo \"Using distributed ChangeLog file from sources\" >&2 ; \\\n\t            else \\\n\t                echo \"  DOC-CHANGELOG-GENERATE        $@ : FAILED (non-fatal)\" >&2 ; \\\n\t                printf \"Failed to generate the ChangeLog.\\n\\nNOTE: See https://github.com/networkupstools/nut/commits/master for change history.\\n\\n\" > \"$@\" ; \\\n\t            fi ; \\\n\t        fi ; \\\n\t    fi\n\nChangeLog.adoc: ChangeLog\n\t+cd $(abs_top_builddir)/docs && $(MAKE) $(AM_MAKEFLAGS) ../ChangeLog.adoc\n\nnut_version.h include/nut_version.h:\n\t+cd $(abs_top_builddir)/include && $(MAKE) $(AM_MAKEFLAGS) nut_version.h\n\ntools/gitlog2changelog.py: tools/gitlog2changelog.py.in\n\t+cd $(@D) && $(MAKE) $(AM_MAKEFLAGS) -s $(@F)\n\n# ----------------------------------------------------------------------\n# Maintainers targets: distribution signature and hashes\nnut-@PACKAGE_VERSION@.tar.gz: dist\nnut-@PACKAGE_VERSION@.tar.gz.sig: dist-sig\nnut-@PACKAGE_VERSION@.tar.gz.md5 nut-@PACKAGE_VERSION@.tar.gz.sha256: dist-hash\n\ndist-sig: nut-@PACKAGE_VERSION@.tar.gz\n\trm -f nut-@PACKAGE_VERSION@.tar.gz.sig\n\tgpg --detach-sign nut-@PACKAGE_VERSION@.tar.gz\n\ndist-hash: nut-@PACKAGE_VERSION@.tar.gz\n\tmd5sum nut-@PACKAGE_VERSION@.tar.gz > nut-@PACKAGE_VERSION@.tar.gz.md5\n\tsha256sum nut-@PACKAGE_VERSION@.tar.gz > nut-@PACKAGE_VERSION@.tar.gz.sha256\n\n# ----------------------------------------------------------------------\n# targets from old build system (pre-automake).\n# supported for a period of time for backward \"compatibility\".\n\nWARN=\"----------------------------------------------------------------------\"\n\nbuild:\n\t@echo $(WARN)\n\t@echo \"Warning: 'make build' is deprecated. Use 'make all' instead.\"\n\t@echo $(WARN)\n\t+$(MAKE) $(AM_MAKEFLAGS) all\ninstall-bin:\n\t@echo $(WARN)\n\t@echo \"Warning: 'make install-bin' is deprecated.\" \n\t@echo \"Use 'make install-exec' instead for a similar effect.\"\n\t@echo $(WARN)\n\t+cd common;  $(MAKE) $(AM_MAKEFLAGS) install\n\t+cd drivers; $(MAKE) $(AM_MAKEFLAGS) install\n\t+cd server;  $(MAKE) $(AM_MAKEFLAGS) install\n\t+cd clients; $(MAKE) $(AM_MAKEFLAGS) install\ninstall-man: install-data-recursive\n\t@echo $(WARN)\n\t@echo \"Warning: 'make install-man' is deprecated.\"\n\t@echo \"Use 'cd docs/man; make install' instead.\"\n\t@echo $(WARN)\n\t+cd docs/man; $(MAKE) $(AM_MAKEFLAGS) install\ninstall-conf:\n\t@echo $(WARN)\n\t@echo \"Warning: 'make install-conf' is deprecated.\"\n\t@echo \"Use 'cd conf; make install' instead.\"\n\t@echo $(WARN)\n\t+cd conf; $(MAKE) $(AM_MAKEFLAGS) install\n# The target install-data already has a standardized meaning under automake\ninstall-dirs:\n\t@echo $(WARN)\n\t@echo \"Warning: 'make install-dirs' is deprecated.\"\n\t@echo \"Use 'make installdirs' instead.\"\n\t@echo $(WARN)\n\t+$(MAKE) $(AM_MAKEFLAGS) installdirs\ncgi build-cgi install-cgi install-cgi-dir install-cgi-bin \\\ninstall-cgi-man install-cgi-conf install-cgi-html: \n\t@echo \"Error: 'make $@' no longer exists.\"\n\t@echo \"Use './configure --with-cgi' instead.\"\ninstall-lib:\n\t@echo \"Error: 'make $@' no longer exists.\"\n\t@echo \"Use './configure --with-dev' instead.\"\nusb build-usb install-usb:\n\t@echo \"Error: 'make $@' no longer exists.\"\n\t@echo \"Use './configure --with-usb' instead.\"\nsnmp build-snmp install-snmp install-snmp-mgr install-snmp-man: \n\t@echo \"Error: 'make $@' no longer exists.\"\n\t@echo \"Use './configure --with-snmp' instead.\"\nsetver:\n\t@echo \"Error: 'make setver' no longer exists.\"\n\t@echo \"Edit configure.ac to set version number.\"\n\n# Clean the dist tarball and packages\nMAINTAINERCLEANFILES_DISTBALL = nut-*.tar.gz\n# HP-UX:\nMAINTAINERCLEANFILES_PACKAGES = NUT_HPUX_package@PACKAGE_VERSION@.depot NUT_HPUX_package-@PACKAGE_VERSION@.depot\n# AIX as below, and RedHat-compatible (cover binary and source packages):\nMAINTAINERCLEANFILES_PACKAGES += nut*rpm\n# Debian-compatible (cover binary and source packages):\nMAINTAINERCLEANFILES_PACKAGES += nut*deb\n# Solaris SVR4 package archives:\nMAINTAINERCLEANFILES_PACKAGES += NUT_solaris_*_package@PACKAGE_VERSION@.local.gz NUT_solaris_*_package-@PACKAGE_VERSION@.local.gz\n# Newer Solaris IPS (aka \"pkg(5)\" format archives)\nMAINTAINERCLEANFILES_PACKAGES += *.p5p\n\nMAINTAINERCLEANFILES += $(MAINTAINERCLEANFILES_DISTBALL)\nMAINTAINERCLEANFILES += $(MAINTAINERCLEANFILES_PACKAGES)\n\npackage: dist\n\t+DESTDIR=\"$(abs_builddir)/_install_pkgprotodir\" ; export DESTDIR; \\\n\trm -rf \"$$DESTDIR\"; \\\n\tcase \"`uname -s`\" in \\\n\t\"HP-UX\") \\\n\t\t( cd scripts/HP-UX && \\\n\t\t  $(MAKE) $(AM_MAKEFLAGS) DESTDIR=\"$$DESTDIR\" package && \\\n\t\t  mv NUT_HPUX_package.depot $(abs_top_builddir)/NUT_HPUX_package-@PACKAGE_VERSION@.depot ) ;; \\\n\t\"SunOS\") \\\n\t\t$(MAKE) $(AM_MAKEFLAGS) && \\\n\t\t$(MAKE) $(AM_MAKEFLAGS) DESTDIR=\"$$DESTDIR\" install && \\\n\t\t( cd scripts/Solaris && \\\n\t\t  $(MAKE) $(AM_MAKEFLAGS) DESTDIR=\"$$DESTDIR\" package ) && \\\n\t\t$(MAKE) $(AM_MAKEFLAGS) DESTDIR=\"$$DESTDIR\" uninstall && \\\n\t\trm -rf \"$$DESTDIR\" || \\\n\t\t{ echo \"FAILED to produce SunOS packages, inspect '$$DESTDIR' for clues\" >&2 ; exit 1; } ;; \\\n\t\"AIX\") \\\n\t\tif test -d /usr/src/packages/SPECS -a -w /usr/src/packages/SPECS ; then : ; else echo \"Can not write to /usr/src/packages/SPECS\" >&2 ; exit 1; fi ; \\\n\t\tif test -d /usr/src/packages/SOURCES -a -w /usr/src/packages/SOURCES ; then : ; else echo \"Can not write to /usr/src/packages/SOURCES\" >&2 ; exit 1; fi ; \\\n\t\t$(MAKE) $(AM_MAKEFLAGS) dist && \\\n\t\tcp scripts/Aix/nut-aix.spec /usr/src/packages/SPECS && \\\n\t\tcp scripts/Aix/nut.init nut-@PACKAGE_VERSION@.tar.gz /usr/src/packages/SOURCES && \\\n\t\trpm -ba /usr/src/packages/SPECS/nut-aix.spec && \\\n\t\tmv /usr/src/packages/RPMS/nut*rpm $(abs_top_builddir)/ ;; \\\n\t*)\techo \"Unsupported OS for 'make $@' (no recipe bound)\" >&2; exit 1;; \\\n\tesac\n\nif HAVE_WINDOWS\n# Steam-roll over all executables/libs we have placed in DESTDIR and copy over\n# any resolved dependencies from the cross-build (or native MSYS2) environment.\n# Then hardlink libraries for sbin... (alternative: all bins in one dir)\n# TOTHINK: Are there more dirs to consider? So far we cover bindir, sbindir and\n# driverexecdir (e.g. some Linux distros place drivers to /lib/nut while tools\n# and daemons are in /usr/bin and /usr/sbin), and cgiexecdir, and occasional\n# helpers like \"sockdebug.exe\" in libexecdir; anything else?..\n# Note we hold existance of cgiexecdir as optional, but the name is expected to\n# be defined. Other dirs are \"just assumed\" to exist (that we are not packaging\n# some NUT build without drivers/tools/daemons). Subject to change if needed.\n# Currently this is handled by a CHECKING... step that should fail if it hits\n# anything.\ninstall-win-bundle: all\n\t@if test -z \"$(DESTDIR)\" ; then echo \"ERROR: '$@': Bundle may only be installed to some DESTDIR prototype area'\" >&2 ; exit 1; fi\n\t+$(MAKE) $(AM_MAKEFLAGS) DESTDIR='$(DESTDIR)' install\n\t+$(MAKE) $(AM_MAKEFLAGS) DESTDIR='$(DESTDIR)' install-win-bundle-thirdparty\n\ninstall-win-bundle-thirdparty:\n\t@if test -z \"$(DESTDIR)\" ; then echo \"ERROR: '$@': Bundle may only be installed to some DESTDIR prototype area'\" >&2 ; exit 1; fi\n\t@echo \"Searching which DLLs need to be bundled with NUT for Windows...\" >&2\n\t@if test -z \"$$ARCH\" ; then \\\n\t    if test -n \"$(target)\" ; then \\\n\t        ARCH='$(target)' \\\n\t    ; else \\\n\t        if test -n \"$(target_triplet)\" ; then ARCH='$(target_triplet)' ; fi ; \\\n\t    fi ; \\\n\t fi ; \\\n\t if test -n \"$$ARCH\" ; then export ARCH ; fi ; \\\n\t DESTDIR='$(DESTDIR)' ; export DESTDIR ; \\\n\t (  cd '$(DESTDIR)' || exit ; \\\n\t    DESTDIR=\"\" '$(abs_top_srcdir)/scripts/Windows/dllldd.sh' dllldddir . \\\n\t    | while read D ; do \\\n\t        echo \"   DLL->bin       $$D\" 2>&1 ; \\\n\t        cp -pf \"$$D\" './$(bindir)/' ; \\\n\t    done ; \\\n\t ) || exit ; \\\n\t (  if test x\"$(bindir)\" = x\"$(sbindir)\" ; then exit 0 ; fi ; \\\n\t    cd '$(DESTDIR)/$(sbindir)' || exit ; \\\n\t    '$(abs_top_srcdir)/scripts/Windows/dllldd.sh' dllldddir . \\\n\t    | while read D ; do \\\n\t        echo \"   DLL->sbin      $$D\" 2>&1 ; \\\n\t        ln -f '$(DESTDIR)/$(bindir)'/\"`basename \"$$D\"`\" ./ ; \\\n\t    done ; \\\n\t ) || exit ; \\\n\t (  if test x\"$(driverexecdir)\" = x\"$(bindir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(driverexecdir)\" = x\"$(sbindir)\" ; then exit 0 ; fi ; \\\n\t    cd '$(DESTDIR)/$(driverexecdir)' || exit ; \\\n\t    '$(abs_top_srcdir)/scripts/Windows/dllldd.sh' dllldddir . \\\n\t    | while read D ; do \\\n\t        echo \"   DLL->drv       $$D\" 2>&1 ; \\\n\t        ln -f '$(DESTDIR)/$(bindir)'/\"`basename \"$$D\"`\" ./ ; \\\n\t    done ; \\\n\t ) || exit ; \\\n\t (  if test -z \"$(cgiexecdir)\" -o ! -d \"$(DESTDIR)/$(cgiexecdir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(cgiexecdir)\" = x\"$(bindir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(cgiexecdir)\" = x\"$(sbindir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(driverexecdir)\" = x\"$(cgiexecdir)\" ; then exit 0 ; fi ; \\\n\t    cd '$(DESTDIR)/$(cgiexecdir)' || exit ; \\\n\t    '$(abs_top_srcdir)/scripts/Windows/dllldd.sh' dllldddir . \\\n\t    | while read D ; do \\\n\t        echo \"   DLL->cgi       $$D\" 2>&1 ; \\\n\t        ln -f '$(DESTDIR)/$(bindir)'/\"`basename \"$$D\"`\" ./ ; \\\n\t    done ; \\\n\t ) || exit ; \\\n\t (  if test x\"$(libexecdir)\" = x\"$(bindir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(libexecdir)\" = x\"$(sbindir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(libexecdir)\" = x\"$(driverexecdir)\" ; then exit 0 ; fi ; \\\n\t    if test x\"$(libexecdir)\" = x\"$(cgiexecdir)\" ; then exit 0 ; fi ; \\\n\t    cd '$(DESTDIR)/$(libexecdir)' || exit ; \\\n\t    '$(abs_top_srcdir)/scripts/Windows/dllldd.sh' dllldddir . \\\n\t    | while read D ; do \\\n\t        echo \"   DLL->libexec   $$D\" 2>&1 ; \\\n\t        ln -f '$(DESTDIR)/$(bindir)'/\"`basename \"$$D\"`\" ./ ; \\\n\t    done ; \\\n\t ) || exit\n\t@echo \"CHECKING if any executable files were installed to locations other than those covered by this recipe, so might not have needed DLLs bundled near them\" >&2 ; \\\n\t relbindir=\"`echo './$(bindir)/' | sed 's,//*,/,g'`\" ; \\\n\t relsbindir=\"`echo './$(sbindir)/' | sed 's,//*,/,g'`\" ; \\\n\t reldriverexecdir=\"`echo './$(driverexecdir)/' | sed 's,//*,/,g'`\" ; \\\n\t relcgiexecdir=\"`echo './$(cgiexecdir)/' | sed 's,//*,/,g'`\" ; \\\n\t rellibexecdir=\"`echo './$(libexecdir)/' | sed 's,//*,/,g'`\" ; \\\n\t cd '$(DESTDIR)' || exit ; \\\n\t find . -type f | grep -Ei '\\.(exe|dll)$$' \\\n\t | grep -vE \"^($${relbindir}|$${relsbindir}|$${reldriverexecdir}|$${relcgiexecdir}|$${rellibexecdir})\" \\\n\t | ( RES=0 ; while IFS= read LINE ; do echo \"$$LINE\" ; RES=1; done; exit $$RES )\n\nelse\ninstall-win-bundle:\n\t@echo \"SKIP: '$@' not enabled for current build configuration\"\n\ninstall-win-bundle-thirdparty:\n\t@echo \"SKIP: '$@' not enabled for current build configuration\"\nendif\n\nprint-MAINTAINERCLEANFILES print-REALCLEANFILES:\n\t@echo $(MAINTAINERCLEANFILES)\n\nprint-DISTCLEANFILES:\n\t@echo $(DISTCLEANFILES)\n\n# TODO: Recursive mode to consider patterns defined in sub-dir makefiles\ngit-realclean-check:\n\t@if test -e .git && (command -v git); then \\\n\t\tgit status --ignored || while read F ; do \\\n\t\t\tfor P in $(MAINTAINERCLEANFILES) ; do \\\n\t\t\t\tcase \"$$F\" in \\\n\t\t\t\t*/$$P) exit 1 ;; \\\n\t\t\t\tesac ; \\\n\t\t\tdone; \\\n\t\tdone ; \\\n\t fi\n"
        },
        {
          "name": "NEWS.adoc",
          "type": "blob",
          "size": 164.9208984375,
          "content": "ifdef::txt[]\nNUT Release Notes\n=================\nendif::txt[]\n\nIf you're upgrading from an earlier version, see the link:UPGRADING.adoc[] file.\n\nPlease note that web and source document links, product and service names\nlisted in historic entries of past releases may no longer be relevant.\n\nFor a complete and more detailed list of changes, please refer to the\nChangeLog file (generated for release archives), or to the Git version\ncontrol history for \"live\" codebase.\n\n\nPLANNED: Release notes for NUT 2.8.4 - what's new since 2.8.3\n-------------------------------------------------------------\n\nhttps://github.com/networkupstools/nut/milestone/9\n\n - (expected) Dynamic Mapping Files (DMF) feature supported, to allow\n   the driver binaries to be built once and data mappings to be loaded\n   and modernized on the fly (porting from 42ITy project)\n\n - (expected) Porting of reference packaging from 42ITy project\n\n - (expected) Porting of patches suggested by different distribution packages\n\n - (expected) C code clean-up/consistency (string format security, work with\n   Boolean values, string to number conversions, etc. in the same manner)\n\n - (expected) clean-up of libusb API variants support [#300 and follow-ups]\n\n - (expected) CI automation for coding style\n\n - (expected) CI automation for driver flags and variables to be certainly\n   documented, handled in augeas lenses, nutconf classes, etc.\n\n - (expected) CI automation for use of data points in drivers that conform\n   to patterns defined in link:docs/nut-names.txt[]\n\n - (expected) Bug fixes for fallout possible due to \"fightwarn\" effort in 2.8.0+\n\n\nPLANNED: Release notes for NUT 2.8.3 - what's new since 2.8.2\n-------------------------------------------------------------\n\nhttps://github.com/networkupstools/nut/milestone/11\n\n - Fix fallout of development in NUT v2.8.0 and/or v2.8.1 and/or v2.8.2:\n   * Move of `NUT_DEBUG_LEVEL` and \"-D\" CLI option handling to start of\n     driver programs for issue #2259 in NUT v2.8.2 release misfired with\n     regard to data-dump mode (it no longer caused foreground by default).\n     [#2408]\n   * The `nut-driver-enumerator.sh` improvements misfired in v2.8.2 release\n     with an overlooked bit of shell syntax, and caused `nut-driver@upsname`\n     instances to not auto-restart when `ups.conf` is edited. [#682, #2410]\n   * Addition of \"NUT Simulated devices\" support to `nut-scanner` in v2.8.2\n     broke detection of (in-)ability to find and query \"Old NUT\" servers via\n     `libupsclient.so` (internal flag got always enabled). [#2246]\n   * A fix for `upsmon` v2.8.1 setting of `OFFDURATION` [PR #2108, issue #2104,\n     revisiting PR #2055, issue #2044] was overly zealous and impacted also\n     the `OB` state in cases where communications to the data server were\n     severed and `DEADTIME` setting was not honored. [PR #2462, issue #2454]\n   * Using `drivername -c reload` (e.g. facilitated by `nut-driver-enumerator`\n     script and service when editing `ups.conf`) led to disconnected Unix\n     sockets and a tight polling loop that hogged CPU. While the underlying\n     bug is ancient, it took recent development to hit it as a practical\n     regression. [issue #1904, issue #2484]\n   * Fallback `localtime_r()` and `gmtime_r()` for some platform builds where\n     a `*_s()` variant was available was not handled correctly. [PR #2583]\n   * A recently introduced `allow_killpower` did not actually work as an\n     `ups.conf` flag (only as a protocol command). [issue #2605, PR #2606]\n   * The ability of two copies of the driver program to talk to each other\n     with `upsdrvquery.c` code was not complete for the case of indefinite\n     `select()` wait timeout. Now `upsdrvquery_read_timeout()` fixed private\n     use of `struct timeval={-1,-1}` as a trigger to `select(..., NULL)`,\n     as logged in one part of code and not handled in the other, for the\n     indefinite wait [#1922, #2392, #2686, #2670]\n   * The `disable_fix_report_desc` option introduced for `usbhid-ups` driver\n     since NUT v2.8.1 was not applied for early dialog with the device while\n     its report descriptors were being discovered. Now this flag, as well as\n     `interruptsize` and `interruptonly`, are considered before we first try\n     to open the USB device handle. [#1575, #1512]\n   * In `cps_fix_report_desc()` we intended to fix-up input and output voltages\n     in certain cases against high voltage transfer, we only fixed-up one of\n     them. [#1245]\n\n - SEMVER, know thyself!\n   * development iterations of NUT should now identify with not only the\n     semantic version of a preceding release, but with git-derived information\n     about the amount of iterations that followed (if available):\n     the three-number \"semver\" would be seen on release snapshots, while\n     other builds would expose the added components: one with the amount\n     of commits on the main development trunk since the preceding release\n     which are ancestors of the built code base, and in case of feature\n     development branches -- another component with the amount of commits\n     unique to this branch (which are not part of the development trunk yet).\n     This allows to produce more relevant (monotonously growing) version\n     identifiers for packages and similar artifacts, with more meaningful\n     upgrades via development snapshots, eventually. A copy of the current\n     version information would be embedded into \"dist\" archives as a\n     `VERSION_DEFAULT` file, among provisions for packager tuning. [#1949]\n   * SMF manifests and systemd units now refer to man pages and their online\n     variants under `NUT_WEBSITE_BASE` dependent on codebase maturity\n     (development or release snapshot); many programs now display such\n     references in their command-line usage help, method `suggest_doc_links()`\n     was introduced for this purpose. [issue #722, PR #2733]\n\n - the `upsnotify()` common code introduced in recent NUT releases (integrating\n   with service management frameworks, etc.) was a bit cryptic when it reported\n   a *failure to notify* (e.g. when not running as a service currently), fixed\n   now to report human-friendly text instead of internal enum codes. Follow-up\n   to [issue #1590, PR #1777, PR #2136]\n\n - drivers, `upsd`, `upsmon`: reduce \"scary noise\" about failure to `fopen()`\n   the PID file (which most of the time means that no previous instance of\n   the daemon was running to potentially conflict with), especially useless\n   since in recent NUT releases the verdicts from `sendsignal*()` methods\n   are analyzed and lead to layman worded situation reports in these programs.\n   [issue #1782, PR #2384]\n\n - drivers started with the `-FF` command-line option (e.g. wrapped into the\n   systemd units to stay \"foregrounded\" *and* save a PID file anyway) should\n   now also handle an existing PID file to interact with the earlier instance\n   of the driver program, if still running (e.g. started manually). [#2384]\n\n - Drivers executed to force an UPS shutdown (with `-k` CLI option) should\n   now try harder to kill off a daemonized sibling, if it still runs (and\n   did not handle a `driver.killpower` INSTCMD well). [#2666]\n\n - Extended instant commands for driver reloading with a `driver.exit`\n   command for a protocol equivalent of sending a `SIGTERM`, e.g. when\n   a newer instance of the driver program tries to start. [#1903, #2392]\n\n - A new `NUT_QUIET_INIT_BANNER` envvar (presence or \"true\" value) can now\n   prevent the tool name and NUT version banner from being unilaterally\n   printed out when NUT programs start. [issues #1789 vs. #316; #2573]\n\n - The `upsdrvctl` should now warn if executed on systems where NUT was\n   built with support for service management frameworks like systemd or SMF,\n   so nut-driver service units prepared by `nut-driver-enumerator` would\n   conflict with manually-executed driver programs. This warning can be\n   hushed by exporting a `NUT_QUIET_INIT_NDE_WARNING` environment variable\n   with any value.\n\n - Extended `upsdrvctl` with a `list` operation (or `-l` option) to report\n   manageable device configuration names (possible `<ups>` arguments to\n   `start`, `stop` etc. operations), or to confirm a single name that it\n   is known, and a `status` operation for more information. [#2567]\n\n - riello_ser updates:\n   * added `localcalculation` option to compute `battery.runtime` and\n     `battery.charge` if the device provides bogus values [issue #2390,\n     following in the footsteps of #1692, #1685 done for `riello_usb`]\n     (similar to `runtimecal` in some other drivers, may be refactored\n     to that configuration and logic model in later NUT releases)\n\n - apcsmart updates:\n   * Revised code to use `strncpy()` and avoid potential overflows that are\n     possible with `strcpy()` used before. [PR #2564]\n   * Lost communications led to a logging flood, should not anymore.\n     In fact, the driver should try fully reconnecting upon getting into\n     a prolonged data stale condition. [issue #704, PR #2564]\n\n - nutdrv_qx updates:\n   * added Visench C1K (using serial port converter with USB ID `1a86:7523`)\n     as known supported by `nutdrv_qx` (Megatec protocol) since at least\n     NUT v2.7.4 release. [#2395]\n   * introduced `innovart31` protocol support for Innova RT 3/1 UPSes. [#2712]\n\n - bicker_ser: added new driver for Bicker 12/24Vdc UPS via RS-232 serial\n   communication protocol, which supports any UPS shipped with the PSZ-1053\n   extension module. [PR #2448]\n\n - liebert-gxe: added new driver with support for Liebert GXE Series UPS\n   (serial or USB posing as a serial port). [#2629]\n\n - nhs_ser: added new driver for numerous NHS Nobreaks, senoidal line -- UPS\n   models with serial port, made by NHS Sistemas Eletronicos LTDA and popular\n   in Brazil. Currently this driver only builds on Linux. [#2692]\n\n - `usbhid-ups` and `netxml-ups` updated to handle \"No battery installed!\"\n   alarm also to set the `RB` (Replace Battery) value in `ups.status`.\n   This may cause dual triggering of notifications (as an `ALARM` generally\n   and as an important `REPLBATT` status in particular) in `upsmon`, but\n   better safe than sorry. [#415]\n\n - usbhid-ups updates:\n   * Support of the `onlinedischarge_log_throttle_hovercharge` in the NUT\n     v2.8.2 release was found to be incomplete. [#2423, follow-up to #2215]\n   * Added support for `interrupt_pipe_no_events_tolerance=N` setting to\n     optionally prevent UPS lockup, indicated by continuous \"Got 0 HID Objects\"\n     situation as a clue, by reconnecting on stale data.  Note that while some\n     devices just report information upon subsequent poll and just have nothing\n     urgent to declare with an USB interrupt, others (e.g. APC BXnnnnMI) were\n     seen to lock up until a full connection restart. [#2671, #2681]\n   * Added support for `lbrb_log_delay_sec=N` setting to delay propagation of\n     `LB` or `LB+RB` state (buggy with APC BXnnnnMI devices circa 2023-2024).\n     This may work better with flags like `onlinedischarge_calibration` and\n     `lbrb_log_delay_without_calibrating` for some devices. [#2347]\n   * General suggestion from `possibly_supported()` message method for devices\n     with VendorID=`0x06da` (Phoenixtec), seen in some models supported by\n     MGE HID or Liebert HID, updated to suggest trying `nutdrv_qx`. [#334]\n   * MGE HID list of `mge_model_names[]` was extended for Eaton 9E, 5PX and 5SC\n     series (largely guessing, feedback and PRs for adaptation to actual\n     string values reported by devices via USB are welcome), so these devices\n     would now report `battery.voltage` and `battery.voltage.nominal`. [#2380]\n   * Added `ups.beeper.status` support for Masterpower MF-UPS650VA using the\n     MGE HID subdriver. [#2662]\n   * Added support for `0x09D6:0x0001` devices using the MGE HID subdriver\n     assuming devices made by KSTAR (alternately using MGE vendor ID). [#2661]\n   * `powercom-hid` subdriver sent UPS shutdown commands in wrong byte order,\n     at least for devices currently in the field. A toggle was added to set\n     the old behavior (if some devices do need it), while a fix is applied\n     by default: `powercom_sdcmd_byte_order_fallback`. [PR #2480]\n   * `cps-hid` subdriver now supports more variables, as available on e.g.\n     CP1350EPFCLCD model, including temperature. [PRs #2540, #2711]\n   * loudly suggest to set `pollonly` flag and default a shorter `pollfreq`\n     for CPS devices, to try avoiding device-driven timeouts. [#1689]\n     Also adjust default `offdelay` and `ondelay` to reasonable values,\n     and warn the users with CPS devices if their configured values are\n     not multiples of 60. [#432, #1394]\n   * in `cps-hid` subdriver, `cps_fix_report_desc()` method should now handle\n     mismatched `LogMax` ranges for input and output voltages, whose USB Report\n     Descriptors are wrongly encoded by some firmware versions. [#1512]\n   * in `cps-hid` subdriver, try to fix frequency scaling based on the values\n     we see from the device and/or configuration overrides (low, nominal, high)\n     so `499.0 Hz` reading that comes from some firmware versions gets reported\n     properly as `49.9Hz`. [#2717]\n   * USB parameters (per `usb_communication_subdriver_t`) are now set back to\n     their default values during enumeration after probing each subdriver.\n     Having an unrelated device connected with a VID:PID matching the\n     `arduino-hid` subdriver prevented use of an actual `usb-hid` device due to\n     changes made to this struct during probe. [#2611]\n\n - USB-capable drivers generally:\n   * ...could earlier log `(nut_)libusb_get_string: Success` due to either\n     reading an empty string or getting a success code `0` from libusb.\n     This difference should now be better logged, and not into syslog. [#2399]\n   * ...now can benefit from a new `nut_usb_get_string()` method which can do a\n     fallback `en_US` query for devices which report a broken \"langid\" language\n     identifier value. This notably manifested in inability to query the device\n     Manufacturer, Model and Serial Number values with some buggy device firmware\n     or hardware. [PR #2604, issues #1925, #414]\n     * Currently this was tested to fix certain device discovery with the\n       `usbhid-ups` driver; but should also apply out of the box to same\n       discovery logic in `blazer_usb`, `nutdrv_qx`, `riello_usb` and\n       `tripplite_usb` drivers.\n     * Also applied to `nut-scanner` and `libnutscan`. [issue #2615]\n     * More work may be needed for other USB-capable drivers (`richcomm_usb`,\n       `nutdrv_atcl_usb`) and for general code to collect string readings and\n       other data points, and to configure the fallback locale or choose one\n       if several are served by the device. [issues #2613, #2614, #2615]\n   * ...should now be more likely to succeed with iterative detection\n     of an UPS interface on a composite USB device or when looking at devices\n     with non-default interface/endpoint/config numbers. [PR #2611]\n   * ...should now accept a `LIBUSB_DEBUG=INTEGER` setting in `ups.conf`\n     (as well as an environment variable that can be generally set via\n     `nut.conf` or service unit methods or init script), to enable\n     troubleshooting of LibUSB itself. [issue #2616]\n   * ...should now not log \"insufficient permissions on everything\" alone when\n     some devices were accessible but just did not match -- clarify that case\n     in the next line, when applicable. [PR #2699]\n   * ...should now track the fact of `assumed_LogMax` (typically when firmware\n     encoding logic is wrong, and `-1` is resolved by parser). [#1512, #1040]\n\n - Introduced a new driver concept for interaction with OS-reported hardware\n   monitoring readings. Currently instantiated as `hwmon_ina219` specifically\n   made for Texas Instruments INA219 chip as exposed in the Linux \"hwmon\"\n   subsystem of its \"sysfs\" interface (and talking I2C under the hood), this\n   approach seems to have good potential to expand into covering more devices\n   and perhaps platforms. [#2430]\n\n - Introduced `ECO` status concept for \"ECO mode\" (or \"High Efficiency\" mode,\n   or \"Energy Saver System\"...) as named and defined by hardware vendors.\n   One common aspect is that this is a balance of electrical efficiency vs.\n   robust outage protection (which may be overkill for IT equipment whose\n   PSU can survive several milliseconds on capacitors alone) which can be\n   selected at run-time.  Previously such choice was made at the time of\n   purchase, with the UPSes only supporting some one protection strategy.\n   [issue #2495, PR #2637]\n   * Updated documentation, end-user clients (CGI, NUT-Monitor UI);\n   * Updated `upsmon` client with ability to report entering and exiting\n     the ECO mode if reported by the driver;\n   * Initial implementation for Eaton devices with `usbhid-ups` driver.\n\n - Introduced handling for the `ALARM` status, which already existed as a\n   common denominator for devices seen with active `ups.alarm` variables.\n   UPS devices in an `ALARM` status are generally considered volatile and\n   may be considered critical/dead by the `upsmon` client earlier than in\n   other statuses (e.g. in no-communication situations). It has to be noted\n   that there is no common standard for what constitutes an alarm and such\n   alarm states were also previously observed for less severe reasons. This\n   depends on the manufacturer/device-specific implementation in the driver.\n   [issues #415, #2657, PR #2658]\n   * Updated documentation, end-user clients (CGI, NUT-Monitor UI);\n   * Updated `upsmon` client with ability to report entering and exiting\n     the ALARM status if reported by the driver;\n   * Updated `upsmon` client with setting to toggle whether an `ALARM`\n     status can prompt the UPS to become critical in certain situations.\n\n - upsmon:\n   * it was realized that the `POWERDOWNFLAG` must be explicitly set in the\n     configuration file, there is no built-in default in the binary program\n     (the settings facilitated by the `configure` script during build \"only\"\n     impact the `upsmon.conf.sample`, init-scripts and similar files generated\n     from templates). [issue #321, PR #2383]\n   * added an `OBLBDURATION` (seconds) setting to optionally delay raising\n     the alarm for immediate shutdown in critical situation. [#321]\n   * optimized `parse_status()` by not checking further strings if we had\n     a match; report unexpected tokens in debug log. [#415]\n   * revised internal `do_notify()` method to support formatting strings\n     with two `%s` placeholders, to use if certain use-cases pass any extra\n     information (e.g. not just \"we have alarms\" but their values too). [#415]\n   * introduced handling for \"unknown\" `ups.status` tokens, reporting them\n     as \"OTHER\" notification type (whenever the set of such tokens appears\n     or changes) or \"NOTOTHER\" when they disappear. [#415]\n\n - upslog:\n   * Added support for limiting the loop count. Using in NIT (NUT Integration\n     Test) suite for double profit (checking the tool and fallback in NIT).\n   * If you use the legacy CLI options for single-system logging (`-s <system>`\n     and `-l <logfile>`) along with newer tuple(s) for multiple-system logging\n     (repeatable `-m <system,logfile>`), previously the single-system options\n     were overridden by the tuple(s); now they become part of the list.\n   * The `upsname` in the `system=upsname[@hostname[:port]]` parameter may\n     be an asterisk `*` to query for devices currently served by the hostname.\n   * Same log file may safely be used in different logging tuples (it is\n     then recommended to use `%UPSHOST%` in a custom formatting string).\n   * Fixed printing of `%UPSHOST%` when multiple systems are being logged.\n   * A `%t` for a TAB character can now be used in the formatting string.\n   * Added `-D` for debugging (and foregrounding by default), like with\n     other NUT daemons.\n   * Added systemd and SMF service integration. [#1803]\n\n - More systemd integration:\n   * Introduced a `nut-sleep.service` unit which stops `nut.target` when a\n     system sleep was requested, and starts it when the sleep is finished.\n     This helps avoid NUT shutting down a woken-up system just because its\n     power state was critical before the sleep (called as a `SHUTDOWNCMD`\n     implementation by the end-user), and a next-read timestamp was not seen\n     (deemed to be a stale UPS, meaning lost communications during critical\n     state, so must go down ASAP). While not as elegant as native systemd\n     \"inhibitor interface\" support, this approach does work. [#1833, #1070]\n   * Introduced support for the \"inhibitor interface\" as well (should be\n     available on systems with systemd version 183 or newer) for a better\n     handling of the time jump specifically in the `upsmon` client via new\n     `Inhibit()` method in `common.c`. [#1070]\n   * As an extension of the logic introduced above, hopefully now `upsmon`\n     would behave better in face of any significant and unexpected clock\n     jumps (on POSIX builds so far), even if they are not suspend/hibernate\n     events (or they were but we could not have an inhibit lock). Now they\n     should be handled similar (avoid stale UPS data and rash decisions)\n     for summer/winter time change on non-UTC deployments, a debugger\n     suspending the `upsmon` process, etc. [#2597]\n   * Introduced delivery of default systemd presets (lists of enabled/disabled\n     units). [#2721]\n\n - gamatronic driver revised for safer memory operations; this was reported\n   to have fixed a Segmentation Fault seen in earlier NUT releases with\n   some of the devices supported by this driver. [#2427]\n\n - phoenixcontact_modbus driver: Introduced Phoenix Contact QUINT4-UPS/24DC\n   management (only new modbus addresses). [#2689, #2716]\n\n - upsd:\n   * `upsd_cleanup()` is now traced, to more easily see that the daemon is\n     exiting (and/or start-up has aborted due to configuration or run-time\n     issues). Warning about \"world readable\" files clarified. [#2417]\n\n - nut-scanner:\n   * the tool relies on dynamic loading of shared objects (library files)\n     orchestrated at run-time rather than pre-compiled, to avoid excessively\n     huge package footprints. This however relies on knowing (or sufficiently\n     safely guessing) the library file names to use, and short `libname.so`\n     is not ubiquitously available. With the new `m4` macro `AX_REALPATH_LIB`\n     we can store and try to use the file name which was present on the build\n     system, while we search for a suitable library. [#2431]\n+\nNOTE: A different but functionally equivalent trick is done for `libupsclient`\nduring a NUT build.\n   * fixed support for IPv6 addresses (passed in square brackets) for both\n     `-s` start/`-e` end command-line options, and for `-m cidr/mask` option.\n     [issue #2512, PR #2518]\n   * newly added support to scan several IP addresses (single or ranges)\n     with the same call, by repeating command-line options; also `-m auto{,4,6}`\n     can be specified (once) to select IP (all, IPv4, IPv6) address ranges of\n     configured local network interfaces.\n     An `/ADDRLEN` suffix can be added to the option, to filter out discovered\n     subnets with too many bits available for the host address part (avoiding\n     millions of scans in the extreme cases).\n     [issue #2244, issue #2511, PR #2509, PR #2513, PR #2517]\n   * implemented parallel scanning for IPMI bus, otherwise default scan for\n     all supported buses with `-m auto` takes unbearably long. [#2523]\n   * bumped version of `libnutscan` to 2.6.0, it now includes a few more\n     methods and symbols from `libcommon`. [issue #2244, PR #2509]\n   * do not actively suggest `vendor(id)`, `product(id)`, and `serial` options\n     for `bcmxcp_usb`, `richcomm_usb` and `nutdrv_atcl_usb` drivers for now\n     [#1763, #1764, #1768, #2580]\n\n - all drivers should now support the optional `sdcommands` setting with\n   a site-local list of instant commands to handle `upsdrv_shutdown()`,\n   which may be useful in cases when the driver's built-in commands\n   (or their order) do not meet the goals of particular NUT deployment.\n   This can also help with shutdown endgame testing, using a mock command like\n   starting the beeper (where supported) to verify that the UPS communications\n   happen as expected, without compromising the load connected to the UPS.\n+\nAlso defined `EF_EXIT_SUCCESS` and `EF_EXIT_FAILURE` in `include/common.h`\nto avoid magic numbers in code like `set_exit_flag(-2)`, and revised whether\nit is getting set at all in \"killpower\" vs. other cases, based on new\n`handling_upsdrv_shutdown` internal flag.\n+\nNOTE: during this overhaul, many older drivers got their first ever supported\nINSTCMD such as `shutdown.return`, `shutdown.stayoff` or `load.off`. Default\nlogic that was previously the content of `upsdrv_shutdown()` methods was often\nrelocated into new `shutdown.default` INSTCMD definitions. [#2670]\n\n - common code:\n   * `upscli_splitname()` should now recognize `upsname:port` typos (missing\n     the `@hostname` part) and error out gracefully.\n   * introduced a `NUT_DEBUG_SYSLOG` environment variable to tweak activation\n     of syslog message emission (and related detachment of `stderr` when\n     backgrounding), primarily useful for NIT and perhaps systemd. Most\n     methods relied on logging bits being set, so this change aims to be\n     minimally invasive to impact setting of those bits (or not) in the\n     first place. [#2394]\n   * `root`-owned daemons now use not the hard-coded `PIDPATH` value set\n     by the `configure` script during build, but can override it with a\n     `NUT_PIDPATH` environment variable in certain use-cases (such as\n     tests). [#2407]\n   * allow drivers to set `STATEPATH` via `ups.conf` to match `upsd`\n     custom configuration ability; the data server would prefer the value\n     from `ups.conf` over the one in `upsd.conf`, if both are present.\n     Note that `NUT_STATEPATH` environment variable trumps both. [issue #694]\n   * introduced a check for daemons working with PID files to double-check\n     that if they can resolve the program name of a running process with\n     this identifier, that such name matches the current program (avoid\n     failures to start NUT daemons if PID files are on persistent storage,\n     and some unrelated program got that PID after a reboot).  This might\n     introduce regressions for heavily customized NUT builds (e.g. those\n     embedded in NAS or similar devices) where binary file names differ\n     significantly from a `progname` string defined in the respective NUT\n     source file, so a boolean `NUT_IGNORE_CHECKPROCNAME` environment\n     variable support was added to optionally disable this verification.\n     Also the NUT daemons should request to double-check against their\n     run-time process name (if it can be detected). [issue #2463]\n   * introduced `m4` macros to check during `configure` phase for the\n     platform, and a `nut_bool.h` header with `nut_bool_t` type to use\n     during build, to avoid the numerous definitions of Boolean types\n     and values (or macros) in the NUT codebase. [issue #1176, issue #31]\n   * custom `distcheck-something` targets did not inherit `DISTCHECK_FLAGS`\n     properly. [#2541]\n   * added `status_get()` in NUT driver state API, to check if a status\n     token string had been set recently, and to avoid duplicate settings.\n     [PR #2565]\n   * local socket/pipe protocol introduced a `LOGOUT` command for cleaner\n     disconnection handling. [#2572]\n   * codebase adapted to the liking of `clang-18` and newer revisions of\n     `gcc-13`+ whose static analyzers on NUT CI farm complained about some\n     imperfections after adding newer OS revisions to the population of\n     build agents. [#2585, #2588]\n   * New checks in `clang-19` brought new findings about mismatched formatting\n     strings and `int`-ish parameters of respective methods.\n     Overall, had to change formatting strings in some cases, variable types\n     in others (e.g. flags or notification types do not make sense as signed)\n     and added casting in a few places that remained, because:\n     - `%x` style formatting requires an `unsigned int` variable\n     - numeric literals and macros are `int` by default\n     - results of math with unsigned types like `uint16_t`, done in some\n       cases, are up-scaled into `int` by default\n     - `char`'s, `unsigned` or not, seem to be also up-scaled into `int`\n\n - updated `docs/nut-names.txt` with items defined by 42ITy NUT fork. [#2339]\n\n - various recipe, documentation and source files were revised to address\n   respective warnings issued by the new generations of analysis tools.\n   [#823, #2437, link:https://github.com/networkupstools/nut-website/issues/52[nut-website issue #52]]\n\n - fixed `configure` script to use default (target-specific) values of\n   `CFLAGS`, `LIBS` etc. when probing relevant settings for each third-party\n   dependency; as a consequence, on systems that support building for many\n   targets, we check relevant build-ability for that target and not for the\n   building system itself. [issue #2673, PR #2675]\n\n - fixed dynamic linking of Mozilla NSS on systems like Solaris/illumos,\n   where the shared objects are not packaged into the common RPATH.\n   [issue #2674, PR #2675]\n\n - added `scripts/valgrind` with a helper script and suppression file to\n   ignore common third-party problems. [#2511]\n\n - when drivers dump collected data (during troubleshooting), flush `stdout`\n   buffer immediately for sane logging (especially on Windows). [PR #2699]\n\n - revised `nut.exe` (the NUT for Windows wrapper for all-in-one service)\n   to be more helpful with command-line use (report that it failed to start\n   as a service, have a help message, pass debug verbosity to launched NUT\n   programs...) and add a man page for it. [issue #2432, PR #2446]\n\n - the `scripts/Windows/build-mingw-nut.sh` helper script was extended to\n   use `nut_build_${ARCH}` and `nut_install_${ARCH}` directories by default,\n   with the older `nut_build` and `nut_install` short names becoming just a\n   symbolic link to the latest executed build: this should help compare the\n   differences of 32/64-bit builds, without them stepping on each other's toes.\n\n - the `PyNUTClient` module should no longer rely on presence of a `telnetlib`\n   module in the build or execution environment (deprecated in Python 3.11,\n   removed since Python 3.13). [#2183]\n\n - enabled installation of built single-file PDF and HTML (including man page\n   renditions) under the configured `docdir`. It seems previously they were\n   only built (if requested) but not installed via `make`, unlike the common\n   man pages which are delivered automatically. [#2445]\n+\n   NOTE: The `html-chunked` documents are currently still not installed.\n\n - added support to `./configure --with-doc=man=dist-auto` to use distributed\n   manual page files if present; only fall back to build them if we can. [#2473]\n\n - added a `make distcheck-light-man` recipe to require verification that the\n   manual page files can be built using the prepared \"tarball\" archive. [#2473]\n\n - revised the documentation building recipes, with the goal to avoid building\n   the `ChangeLog` products and their intermediate files more than once (but\n   still react to `git` metadata changes during development), and to sanity\n   check the resulting final document (currently only for `html-single` mode).\n   As part of this, the `CHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR` setting was\n   added (for `make` calls and used by `tools/gitlog2changelog.py.in` script),\n   and it defaults to `true` allowing for better ordered documents at the cost\n   of some memory during document generation. [#2510]\n\n - updated man page generation with `configure` script options to specify that\n   manual sections on the target platform differ from (Linux-based) defaults\n   hard-coded into page sources; this should allow to simplify NUT packaging\n   recipe maintenance in distributions (no more updating patches for changed\n   or added documentation sources).\n\n - lines in first section of NUT configuration report (can optionally remain as\n   `config.nut_report_feature.log` and be installed into shared documentation\n   of a NUT package) are now better grouped as miscellaneous features and\n   detection results, then drivers and programs/tools. [#2676]\n\n - added a `common/Makefile.am` build product for a new internal library\n   `libcommonstr.la` which allows a smaller selection of helper methods\n   for tools like `nut-scanner` which do not need the full `libcommon.la`\n   nor `libcommonclient.la`. [#2478, #2491]\n\n - added a `drivers/Makefile.am` build product for a new internal library\n   `libserial-nutscan.la` to simplify `tools/nut-scanner/Makefile.am` recipes.\n   [#2490]\n\n - build of `snmp-ups` and `netxml-ups` drivers now explicitly brings linker\n   dependency on chosen SSL libraries. [#2479]\n\n - introduced `configure --with-modbus+usb` option to require an USB-capable\n   libmodbus, and defaulted a couple of specific situations as if this was\n   required (implicitly): `configure --with-modbus --with-usb` and\n   either `--with-drivers=*apc_modbus*` (actually implies `--with-modbus`)\n   or `--with-modbus-includes=... --with-modbus-libs=...`\n   as a way to avoid surprises with custom NUT builds aiming to have an\n   USB-capable `apc_modbus` driver (currently this requires a custom-built\n   libmodbus). Also fixed (re-)detection of libmodbus RTU USB support with\n   static libmodbus builds. [#2666]\n\n - brought keyword dictionaries of `nutconf` and `augeas` NUT configuration\n   file parsers up to date; restored automated checks for `augeas` lenses.\n   [issue #657, issue #2294]\n+\n   NOTE: Some known issues remain with augeas lens definitions so currently\n   they should be able to parse common simple use-cases but not certain types\n   of more complex configurations (e.g. some line patterns that involve too\n   many double-quote characters) which are valid for NUT proper. [#657]\n\n - Cross-builds using only a host implementation of `pkg-config` program\n   should now ignore host `*.pc` files and avoid confusion.\n\n - NUT CI farm build recipes, documentation and some `m4`/`configure.ac`\n   sources updated to handle a much larger build scope on MacOS. Also\n   migrated the builders to Apple Silicon from x86 (deprecated by CircleCI).\n   Disabled `HOMEBREW_NO_AUTO_UPDATE` to gain 40 min per build at cost of\n   slightly older environment. [#2502, #1579]\n\n - Introduced a simple experiment to expose NUT client readings as filesystem\n   objects via FUSE, in `scripts/fuse/execfuse-nut` now. [#2591]\n\n\nRelease notes for NUT 2.8.2 - what's new since 2.8.1\n----------------------------------------------------\n\nhttps://github.com/networkupstools/nut/milestone/10\n\n - Fix fallout of development in NUT v2.8.0 and/or v2.8.1:\n   * dstate machinery: a segmentation fault (null pointer dereference) was\n     possible with `INSTCMD` processing of commands without parameters nor\n     `TRACKING` identifier. [#2155]\n   * USB bus number detection for libusb-1.0 builds was overly zealous and\n     wrongly considered zero values as an error. [#2198]\n   * `upsmon` recognition of `CAL` state could linger after the calibration\n     activity was completed by the hardware, which led to mis-processing of\n     shutdown triggers. Also, notification was added to report \"finished\n     calibration\". [issue #2168, PR #2169]\n   * `upsmon` recognition of `OFF` state as a trigger for FSD (forced shut\n     down) criticality considered also the input line state, which may be\n     an independently evolving circumstance. [issue #2278, PR #2279]\n   * `upsmon` support for `POLLFAIL_LOG_THROTTLE_MAX` did not neuter the\n     applied setting when live-reloading configuration, so commenting it\n     away in `upsmon.conf` did not have the effect of resetting the logging\n     frequency to default. It also did not reset the counters to certainly\n     follow the new configuration for existing faults. [issue #2207, PR #2209]\n   * `upsmon` support for `POLLFAIL_LOG_THROTTLE_MAX` had an off-by-one error\n     (e.g. reporting \"Data stale\" or \"Driver not connected\" every 30 sec with\n     `POLLFAIL_LOG_THROTTLE_MAX 5` and `POLLFREQ 5` settings). [#2207]\n   * Drivers running with non-default user account (e.g. with `user=root`\n     in their configuration) failed to apply group ownership and permissions\n     to their Unix socket file for interaction with the local data server.\n     [#2185, #2096]\n   * Dispatcher script `scripts/python/app/NUT-Monitor` referenced `py3qt3`\n     instead of the correct `py3qt5`. It also tries to check both `py2gtk2`\n     and `py3qt5` implementations verbosely, even if one is not installed.\n     [#2199, #2201]\n   * Set the `DesktopFileName` in `scripts/python/app/NUT-Monitor-py3qt5`,\n     this binds the application with the desktop file and allow the Open\n     Desktop compatible implementation to display the proper icon and\n     application name. [#2205]\n   * Original recipe for `apc_modbus` strictly required USB support even if\n     building NUT without it. [#2262]\n   * Builds requested with a specific C/C++ language standard revision via\n     `CFLAGS` and `CXXFLAGS` should again be honoured. [PR #2306]\n   * Allow requesting detailed debug builds (with disabled optimizations for\n     binaries to best match the source code) for supported compilers using\n     `configure` script option `--with-debuginfo`. Note that default autoconf\n     behavior usually embeds moderate optimizations and debug information on\n     its own. [PR #2310]\n   * A fix applied among clean-ups between NUT v2.7.4 and v2.8.0 releases\n     backfired for `usbhid-ups` subdriver `belkin-hid` which in practice\n     relied on the broken older behavior; more details in its entry below.\n     [PR #2371]\n\n - nut-usbinfo.pl, nut-scanner and libnutscan:\n   * Library API version for `libnutscan` was bumped from 2.2.0 to 2.5.0\n     during evolution of this NUT release.\n   * USB VendorID:ProductID support list files generated by the script for\n     different OS frameworks now include a comment with other possibly\n     compatible driver names, where the respective file format allows for\n     comments.\n   * Added the concept of `alt_driver_names` in `nutscan_device_t` structure\n     for ability to suggest a comment with other possibly compatible driver\n     names in configuration snippets generated by `nut-scanner`; practical\n     support implemented for USB connected drivers.\n   * Added the concept of commented-away suggested option values `comment_tag`\n     and a method to `nutscan_add_commented_option_to_device()`, instead of\n     hacks in prepared config data which broke some use-cases. [#2221]\n   * Command-line option `-U` for USB scan can now be specified several times\n     to increase the detail level about hardware link to the device (this was\n     previously always suggested, but may be not reliable if USB enumeration\n     gets changed over time). [#2221]\n   * Added generation of FreeBSD/pfSense quirks for USB devices supported\n     by NUT (may get installed to `$datadir` e.g. `/usr/local/share/nut`\n     and need to be pasted into your `/boot/loader.conf.local`). [#2159]\n   * nut-scanner now avoids creating ambiguous `nutdevN` device section names\n     when called separately to scan different media buses (one at a time).\n     Now the \"bus\" name would be embedded (e.g. non-colliding `nutdev-usb1`\n     and `nutdev-snmp1`). [#2247]\n   * nut-scanner can now discover NUT simulated devices (`.dev` and `.seq`\n     files) located in your sysconfig directory, and prepare configuration\n     sections with the simulation driver (currently `dummy-ups`). [#2246]\n   * nut-scanner now reports `dummy-ups` as driver when scanning NUT \"bus\"\n     with Old or Avahi method. [#2236, #2245]\n\n - upsd: Fixed conditions for \"no listening interface available\" diagnosis\n   to check how many listeners we succeeded with, not whether the first one\n   succeeded or not. If not all requested (non-localhost) listeners were\n   available, default to fail the daemon start-up attempt; support for an\n   `ALLOW_NOT_ALL_LISTENERS` setting was added to control this behavior. [#723]\n\n - NUT CI improvements:\n   * Added publishing recipes for PyNUT client bindings for NUT, so it ends\n     up in the link:https://pypi.org/project/PyNUTClient[PyPI repository].\n     [#2158]\n   * Added support for new `ccache` namespace concept, where possible. [#2256]\n   * Fixed an issue for builds configured `--without-usb`. [#2263]\n   * Added a fallback for `libgd` discovery (for CGI etc. builds). [#2287]\n   * Made `aspell` TeX module detection more reliable. [#2206]\n   * Fixed recipes for completely out-of-tree builds to pass with documentation\n     generation and checking on all tested \"make\" implementations. [#2318]\n   * Various other recipe and documentation clean-up efforts. [#2284, #2269,\n     #2261]\n\n - main driver core codebase:\n   * Help users of drivers that can be built to support optionally USB and\n     other media (like `nutdrv_qx` built for serial-only support), and built\n     in fact without USB support but used for USB devices, with some more\n     information to make troubleshooting easier. [issue #2259, PR #2260]\n   * Driver programs with debug tracing support via `-D` CLI option and/or\n     the `NUT_DEBUG_LEVEL` environment variable now check those earlier in\n     their life-time, so that initialization routine can be debugged. [#2259]\n   * Multiple USB-capable drivers got options to customize `usb_config_index`\n     `usb_hid_rep_index`, `usb_hid_desc_index`, `usb_hid_ep_in` and\n     `usb_hid_ep_out` hardware connection settings via `ups.conf` options.\n     This is treated as experimental, not all code paths may be actually\n     using such values from `struct usb_communication_subdriver_t` rather\n     than hard-coded defaults. Discovery of correct values is up to the\n     user at the moment (using `lsusb`, internet search, luck...) [#2149]\n\n - nut-driver-enumerator (NDE) service/script:\n   * The optional daemon mode (primarily useful for systems which monitor\n     a large and dynamic population of power devices) was enhanced with a\n     `--daemon-after` variant which parses the configuration once before\n     daemonization and this has a chance to fail while not forked off, as\n     well as to allow only completing the service unit initialization when\n     everything is actually ready to work (so further dependencies can start\n     at the proper time). [#682]\n   * Also applied other optimizations to the script implementation. [#682]\n\n - powerpanel text driver now handles status responses in any format and should\n   support most devices. [#2156]\n\n - tripplite_usb driver now allows any device to match if a particular Unit ID\n   was not specified in `ups.conf`. [PR #2297, issues #2282 and #2258]\n\n - snmp-ups driver:\n   * added support for Eaton EMP002 sensor for ATS16 NM2 sub-driver. [#2286]\n   * mapping table updates for apc-mib sub-driver. [#2264]\n\n - usbhid-ups driver:\n   * `arduino-hid` subdriver was enhanced from \"initial bare bones\" experimental\n     set of mapped data points to support some 20 more mappings to make it more\n     useful as an UPS driver, not just a controller developer sandbox. [#2188]\n   * `cps-hid` subdriver now supports devices branded as Cyber Energy and built\n     by cooperation with Cyber Power Systems. [#2312]\n   * `belkin-hid` subdriver now supports Liebert PSI5 devices which have a\n     different numeric reading scale than earlier handled models. [issue #2271,\n     PR #2272, PR #2369] Generally the wrong-scale processing was addressed,\n     including a regression in NUT v2.8.0 which led to zero values\n     in voltage data points which NUT v2.7.4 reported well [#2371]\n   * The `onlinedischarge` configuration flag name was too ambiguous and got\n     deprecated (will be supported but no longer promoted by documentation),\n     introducing `onlinedischarge_onbattery` as the meaningful alias. [#2213]\n   * Logged notifications about `OL+DISCHRG` state should now be throttled\n     (see the driver manual page for more details) [#2214, #2215]:\n     - If `battery.charge` is available, make the message when entering the\n       state and then only if the charge differs from that when we posted\n       the earlier message (e.g. really discharging) and is under\n       `onlinedischarge_log_throttle_hovercharge` value (defaults to 100%);\n     - Also can throttle to a time frequency configurable by a new option\n       `onlinedischarge_log_throttle_sec`, by default 30 sec if `battery.charge`\n       is not reported by the device (should be frequent by default, in case\n       the UPS-reported state combination does reflect a bad power condition).\n\n - nutdrv_qx driver:\n   * Fixed handling of `battery_voltage_reports_one_pack` configuration flag\n     introduced in NUT v2.8.1. [originally by PR #1279; fixed by PR #2324,\n     issue #2325]\n\n - Various code and documentation fixes for NSS crypto support. [#2274, #2268]\n\n - Laid foundations for the SmartNUT effort (aiming to integrate drivers with\n   some other backends than the networked NUT data server process).\n\n - Eaton contributed recipes and scripts used to create the IPP for Unix\n   bundle (aka Eaton IPSS Unix or UPP), a freely available value-added\n   packaging of NUT distributed as the UPS software companion for OSes\n   where their more complex UPS monitoring/management tools had not been\n   ported. This allows for delivery of NUT packages with an interactive\n   installer and some system integration scripts (events, notifications,\n   status, shutdown daemon...), and was contributed to the NUT upstream\n   project by Eaton -- provided \"as is\" at the moment, and may later serve\n   as foundation or inspiration for new NUT features. [#2288]\n\n - nutconf (C++ library and tool to read and manage NUT configuration files)\n   was started in the open by Eaton employees and used in the IPP installer,\n   but the code lingered in a side branch. It was now brushed up to our common\n   best practices and added to the main codebase. As of this import, there are\n   known deficiencies in Windows platform support, as well as some un-awareness\n   about configuration key words which appeared in NUT since 2013. [#2290]\n\n - The `tools/gitlog2changelog.py.in` script was revised, in particular to\n   convert section titles (with contributor names coming from Git metadata)\n   into plain ASCII character set, for `dblatex` versions which do not allow\n   diacritics and other kinds of non-trivial characters in sections. This can\n   cause successful builds of `ChangeLog.pdf` file on more platforms, but at\n   expense of a semi-cosmetic difference in those names. [PR #2360, PR #2366]\n\nRelease notes for NUT 2.8.1 - what's new since 2.8.0\n----------------------------------------------------\n\nhttps://github.com/networkupstools/nut/milestone/8\n\n - \"UPS management protocol\", Informational RFC 9271 published\n   by IETF at https://www.rfc-editor.org/info/rfc9271 and the\n   IANA port number registry was updated accordingly at\n   https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=3493\n   (even though this RFC is not formally an Internet Standard)\n\n - NUT documentation files were rearranged, renaming some to `*.adoc` pattern\n   to facilitate automatic rendering in GitHub and IDE GUIs, and adding recipe\n   support for GitHub issue/PR links. This `NEWS` file is now proper asciidoc\n   rendered into `release-notes.pdf` (and HTML versions). [issue #1953, PR #2048]\n   Internally, the documents would use a new way to define cross-linking to\n   other pages and their chapters, to facilitate different renderers (including\n   GitHub UI), and file names created for \"chunked HTML\" documentation format\n   will no longer have the \"chapter number, section number\" format which is\n   not easy to maintain over time with independent builds of documentation\n   in NUT and the actual and historic snapshots for nut-website for example.\n   Chapter/Section names will be adapted to produce \"chunked HTML\" file names\n   instead. Documentation links rendered in GitHub UI should point to the HTML\n   pages served by a current iteration of the NUT website. [PR #226, PR #669]\n\n - A new `configure --enable-spellcheck` toggle should add spelling checks\n   to `make check` (by default, if tools are available) to facilitate quicker\n   acceptance of contributions. [#2067]\n\n - Published a new maintainer GPG key to sign tags and release artifacts,\n   and possibly git commits as well, as part of solution for issue #1410.\n   You can pull it from common OpenPGP servers with the following command:\n+\n----\n:; gpg --recv-key DE0184DA7043DCF7\ngpg: key DE0184DA7043DCF7: public key \"Jim Klimov (Doing FOSS\n         since last millennium) <jimklimov@gmail.com>\" imported\ngpg: Total number processed: 1\ngpg:               imported: 1\n----\n+\nas part of https://github.com/networkupstools/nut/issues/1410 solution.\n\n - Bug fixes for fallout possible due to \"fightwarn\" effort and other\n   evolution in NUT v2.8.0 release:\n   * The `upsdebugx()` and similar methods were converted to macros in #685\n     to avoid useless data manipulations and requests for logged information,\n     whose results would be ignored instantly because the debug level is\n     too low. As issue #1455 and PR #1495 found, in two cases the called\n     commands did \"meaningfully\" modify data -- so without debug logs the\n     program misbehaved. A known regression for `upscode2` driver; might\n     be or not be a problem with `upsd` server in NUT v2.8.0 release,\n     fixed for NUT v2.8.1.\n   * A table in `cyberpower-mib` (for `snmp-ups` driver) sources was\n     arranged in NUT v2.8.0 release in a way that precluded the driver\n     logic from looking at all of its entries. Also a fix for instant\n     command definitions had in fact broken them due to other development.\n     Regressions fixed for NUT v2.8.1 [#1432, #2029]\n   * A change for file-change detection in `dummy-ups` driver for NUT\n     v2.8.0 release misfired on some platforms. Regression fixed for NUT\n     v2.8.1 [#1420]\n   * Fixed building of NUT man pages when just a few drivers are selected\n     by `configure` script for custom builds [#1467]\n   * Now that `upsdrvctl` can pass debugging level through to the launched\n     driver(s), they would by default stay in the foreground. This can\n     complicate (or simplify, when intentional) the management of service\n     instances. Now there are explicit `upsdrvctl` options for choosing\n     this (`-F`/`-B`), although default behavior is retained. Note that\n     explicit foregrounding mode also keeps `upsdrvctl` tool from exiting\n     and would not wait for one driver to complete initialization before\n     starting another in case of mass-management loop to start all drivers\n     (without specifying the single device) [#1759, #1806, #1875]\n   * The `apcsmart` and `apcsmart-old` handled invalid data too zealously\n     and aborted instead of skipping over it, like they did before [#2015]\n   * A bit maths optimization in `riello_ser` and `riello_usb` misfired [#2137]\n   * Something about compile-time macros or other warnings-related refactoring\n     seems to have confused the MGE SHUT (Serial HID UPS Transfer) driver\n     support [#2022]\n   * Some warnings were not detected by the tools or build scenarios used\n     earlier, and only got addressed now\n\n - An issue was identified which could cause `libupsclient` parser of device\n   and host names to crash upon bad inputs (e.g. poorly resolved environment\n   variables in scripts). Now it should fail more gracefully [#2052]\n\n - New `configure --enable-inplace-runtime` option should set default values\n   for `--sysconfdir`, `--with-user` and `--with-group` options to match an\n   existing NUT deployment -- for users who are trying if a custom build\n   of recent codebase solves their practical issues. For \"quick tests\", a\n   shortcut operation `./ci_build.sh inplace` was added [#1714]\n\n - State tree structure and methods (including \"dstate\" wrapper for common\n   driver internals) was enhanced with time-stamping of last modification\n   (setting, changing, deleting the value or some fields in an entry):\n   this allows to detect stale information in a centralized fashion [#2010]\n\n - We lacked log information about changes of chroot jail (uncommon) and\n   of UID/GID (everywhere), which makes troubleshooting harder (e.g. lack\n   of access to config files or USB device nodes). Now we have it [#1694]\n\n - A `NUT_DEBUG_PID` envvar (presence) support was added to add current\n   process ID to tags with debug-level identifiers. This may be useful\n   when many NUT daemons write to the same console or log file. [#2118]\n\n - huawei-ups2000 is now known to support more devices, noted in docs and\n   for auto-detection [#1448, #1684]\n\n - nutdrv_qx updates:\n   * a `battery_voltage_reports_one_pack` driver option was added for devices\n     which \"natively\" report a `battery.voltage` for a single battery pack or\n     cell, not for the whole assembly [#1279]\n   * the `voltronic_qs_protocol` should now accept both \"V\" (as before)\n     and newly \"H\" dialects, which otherwise seem interchangeable [#1623]\n   * the `armac` subdriver was enhanced to support devices with a different\n     response pattern than previously expected per initial contribution.\n     It was tested to work with Vultech V2000 and Armac PF1 series. [#1978]\n\n - nutdrv_qx and blazer updates:\n   * extended default ranges for max battery voltage when guessing [#1279]\n\n - sms_ser, a driver for SMS Brazil UPS Protocol 1Phase, was introduced.\n   NOTE: it may later become a subdriver under nutdrv_qx. [#2090]\n\n - usbhid-ups updates:\n   * added support for `subdriver` configuration option, to select the\n     USB HID subdriver for the device manually where automatic match\n     does not suffice (e.g. new devices for which no `vendorid`/`productid`\n     pair was built into any driver, or for different-capability devices\n     with same interface chips, notably \"phoenixtec/liebert\" and \"mge\") [#1369]\n   * cps-hid subdriver now applies same report descriptor fixing logic to\n     devices with ProductID 0x0601 as done earlier for 0x0501, to get the\n     correct output voltage data [#1497]\n   * apc-hid subdriver now also supports ProductID 0x0004 [#1429]\n   * ever-hid subdriver reported a `powerfactor` without a namespace (bug\n     in 2.8.0 release), fixed to `outlet.powerfactor`\n   * the `usbhid-ups` driver should now reconnect if `libusb` returned a\n     memory allocation error [#1422] (seen as \"Can't retrieve Report 0a:\n     Resource temporarily unavailable\"), which can cause practical problems\n     in the field -- the driver otherwise interpreted the situation as\n     `ups.status` being `OL OFF` and cut the power supply.\n   * powercom-hid subdriver: fixed `UPS.Battery.ManufacturerDate` to map\n     to `battery.mfr.date` (not `battery.date` which is the maintenance\n     replacement date) [#1644]\n   * added `onlinedischarge_calibration` option for UPSes that report\n     `OL+DISCHRG` when they are in calibration mode [#2104]\n\n - riello_usb updates:\n   * added `localcalculation` option to compute `battery.runtime` and\n     `battery.charge` if the device provides bogus values [#1692, #1685]\n     (similar to `runtimecal` in some other drivers, may be refactored\n     to that configuration and logic model in later NUT releases)\n\n - powercom driver should now try harder to refresh data from device [#356]\n\n - tripplite_usb driver now supports configuration of `upsid` to match the\n   specific device (not all firmware/hardware models support this) [#2075]\n\n - apcupsd-ups:\n   * improvement for `POLL_INTERVAL_MIN` from PR #797 was buggy [#2007]\n   * fix to clean obsoleted readings (if any) AFTER getting new info from an\n     `apcupsd` daemon, to avoid the gap when NUT driver knows nothing [#2007]\n\n - apc_modbus driver was introduced, to cover the feature gap between existing\n   NUT drivers for APC hardware and the actual USB-connected devices (or their\n   firmwares) released since roughly 2010, which deprecated standard USB HID\n   support in favor of Modbus-based protocol which is used across the board\n   (also with their network management cards). The new driver can monitor APC\n   UPS devices over TCP and Serial connections, as well as USB with a patched\n   libmodbus (check https://github.com/EchterAgo/libmodbus/commits/rtu_usb\n   for now, PR pending). [#139, #2063]\n   * For a decade until this driver got introduced, people were advised to\n     use apcupsd project as the actual program which talks to a device, and\n     NUT apcupsd-ups driver to relay information back and forth. This was a\n     limited solution due to lack of command and variable setting support,\n     as well as relaying of just some readings (just whatever apcupsd exposes,\n     further constrained by what our driver knows to re-translate), with\n     little leverage for NUT to tap into everything the device has to offer.\n     There were also issues on some systems due to packaging (e.g. marking\n     NUT and apcupsd as competing implementations of the same features) which\n     required clumsy workarounds to get both installed and running. Finally,\n     there is a small matter of long-term viability of that approach: last\n     commits to apcupsd sources were in 2017 (with last release 3.14.14 in\n     May 2016): https://sourceforge.net/p/apcupsd/svn/HEAD/tree/\n\n - dummy-ups:\n    * Added an `repeater_disable_strict_start` option to disable the driver\n      exiting upon encountering any kind of error at startup (as repeater).\n      This option should allow for collective `upsdrvctl` startup despite\n      individual target UPS to be repeated or `upsd` not having come up yet.\n      [#2132]\n    * Revised detection of file path (for \"dummy\" mode) which misfired under\n      some conditions, and unified several implementations. [#2118]\n\n - NUT for Windows:\n   * Ability to build NUT for Windows, last tackled with a branch based on\n     NUT v2.6.5 a decade ago, has been revived with the 2.8.x era codebase [#5].\n     It is known that at this time some features are not complete, for more\n     details see https://github.com/orgs/networkupstools/projects/2/views/1\n   * Cross-builds of NUT for Windows using Linux and MinGW (and many custom\n     built dependency packages, as documented in the\n     link:scripts/Windows/README.adoc[scripts/Windows/README.adoc file])\n     are now regularly tested on NUT CI farm with moderate integration via\n     custom build script `scripts/Windows/build-mingw-nut.sh` [#1489]\n   * Semi-native NUT for Windows builds with MSYS2/MinGW x64 environment are\n     now regularly tested on AppVeyor, with the same `ci_build.sh` script and\n     `Makefile` checks as used across the board for local developer builds,\n     Linux/illumos/FreeBSD/OpenBSD/... on dedicated NUT CI farm on Fosshost,\n     and MacOS on CircleCI [#1552]\n\n - snmp-ups updates:\n   * Fixed detection for device agents which wrongly return the sysOID value\n     as a string instead of an OID [#1710]\n   * Clearer messages about skipping MIBs during driver initialization [#2037]\n   * IETF MIB mapping updated for data points where negative readings\n     are invalid [#1558]\n   * Added SNMP subdriver \"apc-epdu-mib\" for APC easy PDU support [#1674]\n   * Added SNMP subdriver \"eaton-pdu-nlogic-mib\" for nLogic (rebranded Eaton)\n     support [#1698]\n   * Added SNMP subdriver \"hpe-pdu3-cis-mib\" for HPE G2 Metered & Switched PDU\n     initial \"unitary\" support (no daisychain support yet); also note that due\n     to SNMP v1 implementation limitations on this device, you should prefer\n     SNMP v3 to get both read and write rights [#1713]\n   * Fixed processing loop for large SNMPv2/SNMPv3 responses where one item\n     in the middle has a type error [#1682]\n   * Better manage the slight nuances (especially in `ups.status`) between\n     Eaton UPSs, and rename mibs from `pw` to `eaton_pw_nm2`, and from\n     `pxgx_ups` to `eaton_pxg_ups` [#1715]\n   * Fixed the long standing \"Warning: excessive poll failures\" issue, that\n     was tied to non-existent OIDs, not well handled in some parts of the\n     driver [#1716]\n   * `baytech-mib.c` subdriver: fixed `baytech_outlet_status_info[]` set\n     of valid outlet status values [#1871]\n   * `cyberpower-mib.c` subdriver: support devices which report the shorter\n     Vendor OID as their sysOID, e.g. \"CyberPower PowerPanel Personal\" [#1997]\n     and support more data points including hardware status alarms [#1982]\n\n - The `bestfortress` driver shutdown handling was fixed to use a non-trivial\n   default timeout [#1820]\n\n - The `optiups` driver only gave accurate voltage information with 120VAC\n   models and assumed a 12V battery when calculating capacity. There is\n   a protocol command that gives a (fixed) voltage which correlates with\n   the voltage selection DIP switches on the back of the UPS, taking into\n   account whether it is a 120 or 240VAC model. Likewise, now the battery\n   capacity fix is applied globally, based on whether or not the battery\n   voltage is greater than 20V. [#2089]\n\n - GPIO drivers [#1855]:\n   * Added a new category of drivers, using GPIO interface to locally connected\n     devices (currently limited to 2018+ Linux libgpiod, but its architecture\n     was designed to support more OSes with their equivalents - PRs welcome)\n   * `generic_gpio_libgpiod` driver using `libgpiod` backend was added\n     (defaults to be required on Linux, optional on other platforms)\n\n - Added support for `make install` of PyNUT module and NUT-Monitor desktop\n   application [#1462, #1504]\n\n - Regular CI coverage for NUT codebase enhanced with CircleCI running some\n   scenarios on MacOS, might add Windows in the future. Fixed some build\n   issues for MacOS that had crept into NUT v2.8.0 release [#1415, #1421]\n\n - NUT software-only drivers (dummy-ups, clone, clone-outlet) separated from\n   serial drivers in respective Makefile and configure script options [#1446]\n\n - Fixed support for common USB matching options (\"vendor\", \"device\", \"bus\",\n   etc.) for `riello_usb` and `richcomm_usb` [#1763] and updated man pages\n   of all USB drivers using these options to include the same description\n   [#1766]\n\n - Added a \"busport\" USB matching option (if supported by the hardware, OS and\n   libusb on the particular deployment, it should allow to specify physical\n   port numbers on an USB hub, rather than logical \"device\" enumeration values,\n   and in turn -- this should be less volatile across reboots etc.) [#2043]\n\n - Added an `allow_duplicates` flag for common USB matching options which\n   may help monitor several related no-name devices (although without knowing\n   reliably which one is which... better than nothing) [#1756]\n\n - The `nut-scanner` program should now suggest same configuration fields as\n   those used by common USB matching options in (most of the) drivers, e.g.\n   adding \"device\" to the generated configuration section [#1790]\n\n - Stuck drivers that do not react to `SIGTERM` quickly are now retried with\n   `SIGKILL` [#1424]\n\n - Each driver should now report its `driver.state` to help readers determine\n   whether it is initializing, reconnecting, or running regular loops [#1767]\n\n - Code which resolves full paths to libraries should now consider the common\n   environment variable `LD_LIBRARY_PATH` as a preferred possible override\n   to built-in paths (note that most operating systems advise against setting\n   this variable unless troubleshooting, although other systems rely on it)\n   [#805]\n\n - Debug information tracing methods like `upsdebugx()` should now be less\n   limited in the sizes of messages that they can print, such as path names\n   that may be quite long. Note that the OS methods manipulating the strings,\n   and receivers such as logging systems, may still impose limits of their own.\n\n - The `nut-scanner` usage and debug printouts now include the loadable library\n   search paths, to help troubleshooting especially in multi-platform builds;\n   pre-filtering of the built-in paths was introduced (to walk only existing\n   and unique directory names) [#317]\n\n - The nut-scanner program was updated to fall back to loading unresolved\n   library filenames, hoping that `lt_dlopen()` implementation on the current\n   platform would find library files better [#805]\n\n - Detection of `libltdl` in `configure` script updated with fallback code to\n   find it on systems that deliver the library to `/usr/local/lib` (e.g. on\n   FreeBSD) [#1577]\n\n - An explicit `configure --with-nut-scanner` toggle was added, specifically\n   so that build environments requesting `--with-all` but lack `libltdl` would\n   abort and require either to install the dependency or explicitly forfeit\n   the tool (some distro packages missed it quietly in the past) [#1560]\n\n - The `nut-scanner` program should now by default warn about serial numbers\n   which do not make much sense (are duplicate, empty, all same character, etc)\n   [#1810]\n\n - Existing openssl-1.1.0 support added for NUT v2.8.0 release was tested to\n   be sufficient without deprecation warnings for builds against openssl-3.0.x\n   (but no real-time testing was done yet) [#1547]\n\n - upslog: Added support for logging multiple devices with one call to the\n   program [#1604]\n\n - Documentation to integrate NUT USB driver startup with `usb_resetter` script\n   has been contributed to `scripts/usb_resetter` (the script itself is tracked\n   externally on GitHub), along with a configuration example for Linux+systemd\n   [#1887]\n\n - Some fixes applied to Solaris/illumos packaging and SMF service support\n   [#1554, #1564]\n\n - Some fixes for builds on older OSes with less functional default system\n   shell interpreters - now `autogen.sh` supports a `CONFIG_SHELL` envvar\n   to inject its value into generated `configure` script [#1736]\n   * Note that you may have to install additional tools (possibly from\n     third-party FOSS packaging efforts) to prepare and build the NUT\n     codebase, and/or prefer non-default system provided implementations\n     (e.g. to use the XPG4 `grep` with `-E` support on Solaris as detailed\n     in https://github.com/networkupstools/nut/issues/1736 comments)\n   * Build environment configuration notes in link:docs/config-prereqs.txt[]\n     file refreshed to cover building of current NUT codebase in CentOS 6\n     [#1804] and Solaris 8 [#1736, #1738]\n\n - `configure` script, reference init-script and packaging templates updated\n   to eradicate `@PIDPATH@/nut` ambiguity in favor of `@ALTPIDPATH@` for the\n   unprivileged processes vs. `@PIDPATH@` for those running as root [#1719]\n\n - `configure` script enhanced: `--with-unmapped-data-points` option allows\n   to build SNMP and USB-HID subdrivers with entries discovered by the scripts\n   which generated them from data walks, but developers did not rename yet\n   to NUT mappings conforming to link:docs/nut-names.txt[] standards [#1699]\n\n - PyNUT.py version bumped to 1.5.0 with some improvements:\n   * `ListClients()` method fixed (was broken in many ways), and is now\n     CI-tested [#549]\n   * `DeviceLogin()` method added (mostly as aid to CI-test `ListClients()`\n     in a practically relevant manner, so far)\n\n - nutclient C++ library:\n   * added `listDeviceClients()` and `deviceGetClients(dev)` to `Client`\n     classes, and `Device::getClients()` to match PyNUT capabilities [#549]\n   * published artifacts may include a `libnutclientstub` which is an\n     implementation of a NUT TCP client in C++ with in-memory data store.\n\n - upsclient C library:\n   * added support for `NUT_QUIET_INIT_SSL` environment variable to hide\n     the infamous \"Init SSL without certificate database\" warning [#1662]\n\n - The `upsd.conf` listing of `LISTEN` addresses was previously inverted\n   (the last listed address was applied first), which was counter-intuitive\n   and fixed for this release [#2012]\n\n - The `upsd` configured to listen on IPv6 addresses should handle only\n   IPv6 (and not IPv4-mappings) to avoid surprises and insecurity; it\n   will now warn if a host name resolves to several addresses (and will only\n   listen on the first hit, as before in such cases) [#2012]\n\n - A definitive behavior for `LISTEN *` directives became specified, to try\n   handling both IPv4 and IPv6 \"any\" address (subject to `upsd` CLI options\n   to only choose one, and to OS abilities). When both address families are\n   enabled, the `upsd` data server will first try to open an IPv6 socket\n   asking for disabled IPv4-mapped IPv6 address support (if the OS honors\n   that), and then an IPv4 socket (which may fail if the IPv6 socket already\n   covers it anyway); in other words, you can end up with one or two separate\n   listening sockets. [#2012]\n\n - sstate (server state, e.g. upsd) should now \"PING\" drivers also if they\n   last reported themselves as \"stale\" (and might later crash) so their\n   connections would be terminated if really no longer active [#1626]\n\n - Clarified documentation in codebase according to end-user feedback [#1721,\n   #1750 and others over time]\n\n - upsmon client changes include:\n   * Several fixes for `upsmon` behavior [#1761, #1680...], including new\n     ability to configure default POWERDOWNFLAG location -- packagers are\n     encouraged to pick optimal location for their distributions (which\n     remains mounted at least read-only late in shutdown) and a new optional\n     POLLFAIL_LOG_THROTTLE_MAX setting [#529, #506]\n   * Also `upsmon` should now recognize `OFF` and `BYPASS` flags in `ups.status`\n     and report that these states begin or end. The `OFF` state usually means\n     than an administrative action happened to power off the load, but the UPS\n     device is still alive and communicating (USB, SNMP, etc.); corresponding\n     `MONITOR`'ed amount of power sources are considered not being \"fed\" for\n     the power value calculation purposes. The `BYPASS` state is now treated\n     similarly to `ONBATT`: currently this UPS \"feeds\" its load, but if later\n     communications fail, it is considered dead. This may have unintended\n     consequences for devices (or NUT drivers) that do not report these modes\n     correctly (e.g. an APC calibration routine seems to start with a few\n     seconds of \"OFF\" state), so the reported status is only considered as a\n     loss of feed if it persists for more than `OFFDURATION` seconds. [#2044,\n     #2104]\n   * Introduced `SHUTDOWNEXIT no` configuration toggle for systems which\n     require a long time to stop their workload such as virtual machines.\n     Since the disconnection of a \"secondary\" client is treated by the\n     \"primary\" system as permission to proceed with its own shutdown and\n     power-off for the UPS, the original (now merely default) behavior to\n     call `SHUTDOWNCMD` and immediately exit could be counter-productive.\n     An optional delay can also be introduced. [#2133]\n   * Note there were other changes detailed below which impacted several NUT\n     programs, including `upsmon`.\n\n - Extended Linux systemd support with optional notifications about daemon\n   state (READY, RELOADING, STOPPING) and watchdog keep-alive messages [#1590]\n   * Normally *inability* to send such notifications (e.g. lack of systemd\n     or similar framework on the particular platform) would be reported once\n     per daemon uptime on its console log, to help troubleshooting situations\n     where such lack of notifications can cause automated service restarts.\n     These messages can be hidden by setting `NUT_QUIET_INIT_UPSNOTIFY=true`\n     environment variable in init-scripts on platforms where such frameworks\n     are not expected. [#2136]\n\n - Extended Linux systemd units with aliases named after the daemons:\n   `nut-server.service` as `upsd.service`, and `nut-monitor.service` as\n   `upsmon.service` (so simple `systemctl reload upsd` can work) [#1777]\n\n - Extended driver-server socket protocol with `BROADCAST (num)` keyword,\n   and a `NOBROADCAST` as a shortcut for `BROADCAST 0`. This allows clients\n   to toggle whether they want to receive `send_to_all()` updates from a\n   driver, or only answers to requests they send [#1914]\n\n - Added support for `make sockdebug` for easier developer access to the tool;\n   also if `configure --with-dev` is in effect, it would now be installed to\n   the configured `libexec` location. A man page was also added. [#1936]\n\n - Numerous daemons (`upsd`, `upsmon`, drivers, `upsdrvctl`, `upssched`)\n   which accepted `-D` option for debug setting previously, now can also\n   honour a `NUT_DEBUG_LEVEL=NUM` environment variable if no `-D` arguments\n   were provided. Unlike those arguments, the environment variable does\n   not enforce that daemons run in foreground mode by default [#1915]\n   * Note that unlike some other NUT daemons, `upssched` with enabled\n     debug does not stop reporting on `stderr`! [#1965]\n\n - A bug in `upssched` was discovered and fixed, where it ran a tight loop\n   stressing the CPU; it was presumably introduced between NUT v2.7.4 and\n   v2.8.0 releases [#1964, #1965]\n\n - Implemented generic support for INSTCMD and SETVAR use-cases shared by\n   all drivers, and in particular to see and change active debug verbosity\n   using the driver-server and server-client protocol (at higher priority\n   than CLI or config file choices) per [#1285], e.g.\n------\n# Set verbosity level 6:\n:; upsrw -s driver.debug=6 UPS\n\n# Set verbosity level 0 to disable the noise (even if debug_min is set):\n:; upsrw -s driver.debug=0 UPS1@localhost\n\n# Un-set the protocol override, honour CLI or config-file settings again:\n:; upsrw -s driver.debug=-1 remoteUPS@1.2.3.4\n------\n+\nand a `driver.killpower` instant command (for safety, must be unlocked by\n   `driver.flag.allow_killpower` protocol setting or `allow_killpower`\n   configuration flag), which is now the first choice for `driver -k`\n   operations [#1917, #1923]\n\n - Implemented basic support for `ups.conf` reloading in NUT drivers,\n   with a `driver.reload-with-error` instant command (more commands and\n   signal handling may be available depending on platform), with a goal\n   of changing inconsequential settings like `debug_min` for a running\n   driver. This can also benefit the drivers on systems managed by real-time\n   `nut-driver-enumerator` and for simpler changes the drivers get only\n   reloaded and not redefined and restarted. Reload signals should also\n   be reasonably supported with `upsdrvctl` tool. Relevant CLI options\n   for `-c CMD` handing were added to drivers and `upsdrvctl`, although\n   their availability may vary between operating systems [#1903, #1914, #1924]\n\n - Drivers should now accept `SIGURG` (or `SIGWINCH` on systems that lack\n   the former) on POSIX platforms to dump their current state information\n   and move on. Such report goes to `stdout` of the driver process (may\n   be disconnected when background mode is used) -- this can help with\n   troubleshooting [#1907]\n\n - Recipes and `main.c` code were enhanced to produce a `libdummy_mockdrv.la`\n   helper library during build (not intended to be installed nor distributed),\n   in order to facilitate creation of test programs which behave like a driver\n   [#1855]\n\n - Further revision of public headers delivered by NUT was done, particularly\n   to address lack of common data types (`size_t`, `ssize_t`, `uint16_t`,\n   `time_t` etc.) in third-party client code that earlier sufficed to only\n   include NUT headers. Sort of regression by NUT 2.8.0 (note those consumers\n   still have to re-declare some numeric variable types used) [#1638, #1615]\n\n - The `COPYING` file was updated with licenses and attribution for certain\n   source code files and blocks coming from the Internet originally [#1758]\n\n - The `tools/gitlog2changelog.py.in` script was revised, in particular to\n   generate the `ChangeLog` file more consistently with different versions\n   of Python interpreter, and without breaking the long file paths in the\n   resulting mark-up text [#1945, #1955]\n\n - The \"NUT client for VMware ESXi\" project (by René Garcia) got its build\n   recipes published on GitHub at https://github.com/rgc2000/NutClient-ESXi\n   [#1961]\n\n\nRelease notes for NUT 2.8.0 - what's new since 2.7.4\n----------------------------------------------------\n\nNOTE: Earlier discussions (mailing list threads, GitHub issues, etc.) could\nrefer to this change set (too long in the making) as NUT 2.7.5.\n\n - New (optional) keywords for configuration files were added,\n   so existing NUT 2.7.x builds would not accept them if some\n   deployments switch versions back and forth -- due to this,\n   semantically the version was bumped to NUT 2.8.x.\n\n - Add support for openssl-1.1.0 (Arjen de Korte)\n\n - libusb-1.0 API support in addition to libusb-0.1 API [#300]\n\n - Add support for `DISABLE_WEAK_SSL=true` in upsd.conf to disable older/weaker\n   SSL/TLS protocols and ciphers: when NUT is built against relatively recent\n   versions of OpenSSL or NSS it will be restricted to TLSv1.2 or better.\n   For least-surprise, currently defaults to `false` and complains in log\n   [PR #1043]\n\n - Add support for `ALLOW_NO_DEVICE=true` (as an upsd.conf flag or environment\n   variable passed from caller of the program), to allow starting the data\n   server initially without any device configurations and reloading it later\n   to apply config changes on the fly [PR #766]\n\n - Add support for `debug_min=NUM` setting (ups.conf, upsd.conf, upsmon.conf)\n   to specify the minimum debug verbosity for daemons. This allows \"in-vivo\"\n   troubleshooting of service daemons without editing init scripts or service\n   unit definitions.\n\n - Improve support for upsdrvctl for managing of numerous device configs,\n   including default \"maxretry=3\" and a \"nowait\" option to complete the\n   \"start of everything\" mode after triggering the drivers and not waiting\n   for them to complete initializing. This matters on systems that monitor\n   from dozens to hundreds of devices.\n\n - Drivers support a new value for `synchronous` setting, which is the\n   new default now: `auto`.  Initially after driver start-up this mode\n   acts as the older default `off`, but would fall back to `on` in case\n   the driver fails to send reports to `upsd` by overflowing the socket\n   buffer in async mode -- so the next connections of this driver uptime\n   would be synchronized (potentially slower, but safer -- blocking on\n   writes to the data server).  This adaptation would primarily impact\n   and benefit devices with many (hundreds of) data points, such as\n   ePDUs and daisy chains. [issue #1309, PR #1315]\n\n - Daemons such as upsd, upsmon, upslog, and device drivers previously\n   implied that enabled debugging (or upslog to stdout) means foreground\n   running, otherwise the daemon was always sent to the background.\n   Now there are explicit options for this (`-F`/`-B`), although default\n   behavior is retained. This change is used for simplified service unit\n   definitions.\n\n - Improvements for device discovery or driver \"lock-picking\", including\n   general support for:\n   * \"Standalone\" mode (`-s` option), to monitor a device which is not\n     detailed or mentioned in ups.conf\n   * `NUT_ALTPIDPATH` and `NUT_STATEPATH` environment variables to override\n     the paths built into the driver binary [PR #473 and #507]\n   * \"Driver data dump\" mode (`-d` option), to poll a device for one or\n     few ('update_count' ) loops, report discovered values (dump the data\n     tree in upsc-like format), and exit. This complements the `nut-scanner`\n     for finding and identifying devices.\n\n - support for new devices:\n   * IBM 6000 VA LCD 4U Rack UPS; 5396-1Kx (USB)\n   * Phoenix Contact QUINT-UPS model 2320461 (Modbus)\n   * Tripp-Lite SU3000LCD2UHV (USB; protocol 1330)\n   * Emerson Avocent PM3000 PDU (SNMP)\n   * HPE ePDU (SNMP)\n\n - nutdrv_qx: enhanced estimation of remaining battery runtime based\n   on speed of voltage drop, which varies as they age [PR #1027]\n\n - nutdrv_qx: several subdrivers added or improved, including:\n   * \"snr\" subdriver with USB connection, for SNR-UPS-LID-XXXX [PR #1008].\n     Note that end-users should reference explicitly the `snr` subdriver\n     in their `ups.conf` settings because of USB chip using the same\n     values of VendorID/ProductID as fabula_subdriver, fuji_subdriver,\n     and krauler_subdriver.\n   * \"hunnox\" subdriver, as a dialect of earlier \"fabula\" [PR #638]\n     adds support for Hunnox HNX-850 with USB connection and reported to work\n     for Powercool, Iron Guardian, ARES devices and possibly many others from\n     discussions linking to the pull request which introduced the driver.\n   * \"phoenixtec\" subdriver for Masterguard A and E series, device series\n     A700/1000/2000/3000(-19) and E40/60/100(-19). [PR #975]\n   * \"ablerex\" subdriver provided by the OEM vendor, note that it replaces\n     \"krauler_subdriver\" as default handler for VID:PID 0xffff:0x0000\n     [PR #1135]\n   * Legrand HID defined and handled by \"krauler_subdriver\" by default\n     [PR #1075, issue #616]\n   * add new \"armac\" subdriver, tested with Armac R/2000I/PSW, but should\n     support other UPSes that work with \"PowerManagerII\" software from\n     Richcomm Technologies from around 2004-2005 [PR #1239, issue #1238]\n\n - microsol-apc (starting at version 0.68 as derived from solis 0.67):\n   adding support for newer APC Back-UPS BR hardware, such as\n   APC Back-UPS BZ1500, BZ2200BI and BZ2200I [PR #994]\n\n - pijuice: added new i2c bus driver for PiJuice HAT, a battery UPS module\n   for the Raspberry Pi systems [PR #730]\n\n - huawei-ups2000: added new driver for USB (Linux 5.12+ so far) and Serial\n   RS-232 Modbus device support of Huawei UPS2000/2000A (1kVA-3kVA) series,\n   and possibly some related FSP UPS models. [PR #954]\n\n - socomec_jbus: added new driver for modbus-based JBUS protocol over serial\n   RS-232 for Socomec UPS (tested with a DIGYS 3/3 15kVA model, working\n   on Linux x86-64 and Raspberry Pi 3 ARM). [PR #1313]\n\n - adelsystem_cbi: added new driver for ADELSYSTEM CBI2801224A, an all-in-one\n   12/24Vdc DC-UPS, which supports the modbus RTU communication protocol\n   [PR #1282]\n\n - generic_modbus: added new driver for TCP and Serial Modbus device support.\n   The driver has been tested against PULS UPS (model UB40.241) via\n   MOXA ioLogikR1212 (RS485) and ioLogikE1212 (TCP/IP), and configuration\n   allows to map custom registers and addresses to NUT events [PR #1052]\n\n - genericups: added support for FTTx battery backup devices, and new signal\n   type mappings for the contact closure pins interpretation (RB for replace\n   battery, BYPASS for disconnected battery, and \"none\" or NULL for signals\n   to ignore) [PR #1061]\n\n - add devices to HCL/DDL:\n   * APC Back-UPS CS (USB)\n   * CPS CP1500EPFCLCD (USB)\n   * CPS EC350G, EC750G (USB)\n   * CPS PR2200LCDRT2U (SNMP)\n   * Eaton ATS 16 and 30 (SNMP)\n   * Eaton 5E2200VA (USB)\n   * Eaton 9PX Split Phase 6/8/10 kVA (XML/USB/SHUT)\n   * Eaton 9PX (XML/USB/SHUT)\n   * Eaton Ellipse PRO 650 VA (USB)\n   * Ippon Back Comfo Pro II 650/850/1050 (USB)\n   * Numeric Digital 800 (USB)\n   * Opti-UPS PS1500E (USB)\n   * Powercool 350VA to 1600VA (USB)\n\n - C++11 support in nutclient library and cppunit tests\n\n - Added C++ testing mock for TcpClient class (nutclientmem/MemClientStub:\n   data stored in local memory) [PR #1034]\n\n - Dual Python 2 and 3 compatibility in development scripts; ability to\n   run build activities and resulting built NUT programs on systems that\n   do not have a binary named \"python\" [PR #1115 and some before it]\n\n - Added Russian translation for NUT-Monitor GUI client [PR #806]\n\n - Separated NUT-Monitor UI into two applications, NUT-Monitor-py2gtk2 and\n   NUT-Monitor-py3qt5, suitable for two generations of Python ecosystem\n   with their great differences; `NUT-Monitor` name is retained for wrapper\n   script which calls one of these, such that the current system can execute\n   [PRs #1310, #1354]\n\n - Various USB driver families: expanded device-matching with \"device\" in\n   addition to \"bus\" and generic USB fields. This is needed to support\n   multiple attached devices that seem identical by other fields (e.g.\n   same vendor, same model, same USB bus, and no serial number) [PR #974]\n\n - Various USB driver families: Improved HID parsing for byte-stream to\n   number conversions on different CPU architectures [PR #1024]\n\n - Various USB HID driver families: added support for composite devices\n   utilizing interface greater than 0 for the UPS interface [PR #1044]\n\n - usbhid-ups:\n   * added generic framework for fixing Report Descriptors which can be\n     used for different manufacturers by adding code to the appropriate\n     subdriver rather than polluting the main code with UPS specific\n     exceptions, and applied fixes for known mistakes in (some releases\n     of firmware for) CyberPower CPS*EPFCLCD [issue #439, PR #1245]\n   * added `onlinedischarge` option for UPSes that report `OL+DISCHRG`\n     when wall power is lost [PR #811]\n   * changed detection of VendorID 0x06da handling of which is claimed\n     by Liebert/Phoenixtec HID historically, and MGE HID (for AEG PROTECT\n     NAS UPSes) since NUT 2.7.4, so that the higher-priority MGE subdriver\n     would not grab each and all of the devices exposing that ID [PR #1357]\n   * CPS HID: add input.frequency and output.frequency\n   * OpenUPS2: only check OEM Information string once (fewer log messages)\n   * Liebert GXT4 USB VID:PID [10AF:0000]\n   * add battery voltage and input/output transfer voltage and frequency\n     in Liebert/Phoenixtec HID mapping, to support PowerWalker VFI 2000 TGS\n     better [PR #564, issue #560]\n   * add a little delay between multicommands [PR #1228]\n   * fix Eaton/MGE mapping for beeper handling\n   * add IBM USB VID\n   * add deep battery test for CyberPower OL3000RMXL2U\n   * report the libusb version used\n   * fixed CPU architecture dependent bitmask math issues, causing wrong\n     numbers interpreted from wire protocol data in Big-Endian LP64 builds\n     (SPARC64, s390x, etc.) [issue #1023, PRs #1024, #1040, #1055, #1226]\n   * add Delta UPS Amplon R Series, tested on R1K and R3K model [PR #987]\n   * add Delta Minuteman UPS VID/PID [PR #1230, issues #555 and #1227]\n   * add AMETEK Powervar UPM [PR #733]\n   * add Tripplite AVR750U (ProductID 0x3024) [PR #963]\n   * add Arduino HID device support with new arduino-hid subdriver [PR #1044]\n   * add new salicru-hid subdriver, tested with Salicru SPS Home 850 VA\n     [PR #1199, issue #732]\n   * add new ever-hid subdriver to support EVER UPS devices (Sinline RT Series,\n     Sinline RT XL Series, ECO PRO AVR CDS Series) [PR #431]\n   * add ability to set `battery.mfr.date` for APC HID UPS [PR #1318]\n\n - usbhid-ups / mge-shut: compute a realpower output load approximation for\n   Eaton UPS when the needed data is not present\n\n - snmp-ups:\n   * APC ePDU MIB support\n   * add `input.phase.shift` variable\n   * add configurable write-able `ondelay` (`ups.delay.start`) and `offdelay`\n     (`ups.delay.shutdown`) as timeticks support [PR #276]\n   * outlet groups\n   * fix the rounding / truncation of some values\n   * add outlet.N.name for Eaton ePDU\n   * add input.bypass.frequency for Eaton 3ph\n   * fix support for Eaton 2-phase (\"split phase\") UPS\n   * add flag to list currently loaded MIB-to-NUT mappings\n   * fix input.L2.voltage on Eaton G2/G3 PDU\n   * update Eaton Aphel Revelation MIB\n   * support Raritan Dominion PX2 PDU\n   * support Emerson Avocent PM3000 PDU\n   * improve ALARM flag handling\n   * add firmware version for new HPE Network card\n   * add ups.load, battery.charge, input.{voltage,frequency} and output.voltage\n     for CyberPower, as well as shutdown and other instant commands\n   * several rounds of updates for Eaton devices, including new ATS and ePDU\n     hardware families\n   * fixed bit mask values for flags to surely use different numbers behind\n     logical items (inevitably changing some of those macro symbols) [PR #1180]\n\n - snmp-ups and nut-scanner should now support more SNMPv3 Auth and Priv\n   protocols, as available at NUT build time [PRs #1165, #1172]\n\n - nut-scanner: various improvements, including:\n   * detection of libraries at runtime\n   * tracing information\n   * limiting parallelism (thread count) [PRs #1158, #1164]\n\n - nut-ipmipsu: improve FreeIPMI support to build cleanly against older and\n   newer FreeIPMI versions [PR #1179]\n\n - the powerpanel driver now also supports CyberPower OR1500LCDRTXL2U with\n   serial cable [PR #538]\n\n - powercom driver: implement `nobt` config parameter to skip battery check\n   on initialization/startup [PR #1256]\n\n - netxml-ups:\n   * Report calibration status\n   * Fix for erroneous battery info (MGEXML/0.30) [PR #1069]\n\n - solis: various improvements and fixes\n\n - liebert-esp2: Correct battery V scaling, update docs, implement split-phase\n   unit support [PR #412]\n\n - tripplite: the \"Tripp-Lite SmartUPS driver\" as tested with SMART2200NET\n   learned to discover the firmware generation and some device features,\n   and in particular to manage power separately on one or two outlet groups\n   [PR #1048]\n\n - tripplite_usb: updated to recognize the \"3005\" protocol [PR #584]\n\n - libnutclient: introduce getDevicesVariableValues() to improve performances\n   when querying many devices (up to 15 times faster)\n\n - nut-driver-enumerator: introduced a script for Linux systemd and\n   Solaris/illumos SMF to inspect current NUT configuration in ups.conf\n   file and generate service management instances for each currently\n   tracked power device. Also introduced services to monitor the NUT\n   configuration and react to editions of this file, mostly intended\n   for deployments that do massive monitoring of dynamically changing\n   farms of power devices.\n\n - Fix File descriptors leaks by upsmon and upssched (SELinux errors)\n\n - systemd support improvements:\n   * POWEROFF_WAIT\n   * reload support for upsd\n   * Deliver systemd-tmpfiles config to pre-create runtime locations\n     [PR #1037 for Issue #1030]\n   * Update units with SyslogIdentifier=%N for better logging [PR #1054]\n\n - upsrw: display the variable type beside ENUM / RANGE\n\n - Added `PROTVER` as alias to `NETVER` to report the protocol version in use.\n   Note that NUT codebase itself does not use this value and handles commands\n   and reported errors individually [issue #1347]\n\n - Implement status tracking for instant commands (instcmd) and variables\n   settings (setvar): this allows to get the actual execution status from the\n   driver, and is available in libraries and upscmd / upsrw [PR #659]\n\n - Add support for extra parameter for instant commands, both in library and\n   in upscmd\n\n - dummy-ups can now specify `mode` as a driver argument, and separates the\n   notion of `dummy-once` (new default for `*.dev` files that do not change)\n   vs. `dummy-loop` (legacy default for `*.seq` and others) [issue #1385]\n\n - new protocol variables:\n   * `input.phase.shift`\n   * `outlet.N.name`\n   * `outlet.N.type`\n   * `battery.voltage.cell.max`, `battery.voltage.cell.min`\n   * `battery.temperature.cell.max`, `battery.temperature.cell.min`\n   * `battery.status`\n   * `battery.capacity.nominal`\n   * `battery.date.maintenance` (and clarified purpose of `battery.date`)\n   * `battery.packs.external` (and clarified purpose of `battery.packs`)\n   * `experimental.*` namespace introduced [PR #1046] to facilitate\n     introduction of NUT drivers and their data points for which we do\n     not yet have concepts, or which the original driver contributors\n     did not map well per suitable NUT standards: this allows to balance\n     having those drivers available in the project vs. least surprise\n     for when the explicitly experimental names are changed to something\n     stable and standardized.\n   * Proposed to track Date and Time values (still as \"opaque strings\")\n     preferably in representations compatible to ISO-8601/RFC-3339 [PR #1076]\n     (standards update; changes to actual codebase to be applied in the future)\n   ** New routine to convert a US formatted date string \"MM/DD/YYYY\" to an\n      ISO 8601 Calendar date \"YYYY-MM-DD\" was added to snmp-ups.c [PR #1078]\n\n - Master/Slave terminology was deprecated in favor of Primary/Secondary\n   modes of `upsmon` client:\n   * Respective keywords in the configuration files (`upsd.users` and\n     `upsmon.conf`) are supported as backwards-compatible settings,\n     but the obsoleted values are no longer documented.\n   * Protocol keyword support was similarly updated, with `upsmon` now\n     first trying to elevate privileges with `PRIMARY <ups>` request,\n     and falling back to `MASTER <ups>` just in case it talks to an\n     older build of an `upsd` server.\n   * For the principle of least surprise, NUT codebase still exposes the\n     `net_master()` (as handler for `MASTER` net command) in header and\n     C code for the sake of existing linked binaries, and returns the\n     `OK MASTER-GRANTED` line to the older client that invoked it.\n   * Newly introduced `net_primary()` (as handler for `PRIMARY` net command)\n     calls the exact same application logic, but returns `OK PRIMARY-GRANTED`\n     line to the client.\n   * Python binding updated to handle both cases, as the only found in-tree\n     protocol consumer of the full-line text.\n   * For more details see issue #840 and several pull requests referenced\n     from it, and discussions on NUT mailing lists.\n\n - Build fixes:\n   * In general, numerous fixes were applied to ensure portability and avoid\n     warnings (fixing a number of real bugs that caused them); CI was extended\n     to keep the codebase free of those types of warnings which we have got\n     rid of, requiring builds to succeed cleanly in several dozen combinations\n     of compiler versions, C standard revisions (C99 upwards, though on many\n     OSes with GNU99+ extensions), operating systems and CPU architectures.\n   * Public CI introduced to automatically test every contribution (PR) and\n     resulting increment of main NUT codebase, including Travis CI and LGTM.com\n     services, and a Jenkins farm on virtual hardware donated by Fosshost.org;\n     this augments testing earlier provided for some branches by Buildbot.\n   * Added cppunit testing with valgrind for the C++ client library\n   * Make targets added for shell script syntax checks for helper and service\n     scripts\n   * Make targets added for spellcheck and for maintenance of the dictionary,\n     including incremental spellcheck to only parse recently edited text files\n   * The AsciiDoc detection has been reworked to allow NUT to be built from\n     source without requiring asciidoc/a2x (using pre-built man pages from\n     the distribution tarball, for instance)\n   * Makefile contents rearranged for more resilient out-of-tree and in-tree\n     builds beside those made from the root workspace directory\n   * Makefiles are tested with GNU Make and BSD Make to ensure portable recipes\n   * More use of `pkg-config` to detect dependencies at configure time, as\n     well as fail-safe detection of presence of pkg-config (and its macros)\n     to survive and build without it too\n   * \"slibtool\" pedantic nuances now supported, allowing an alternative to\n     GNU libtool\n   * Build scripts updated to remove obsoleted calls to cleanly work with\n     autoconf-2.70 releases in 2020 (also works with 2.69 which was the\n     earlier release since 2012)\n   * Dynamic library loading used in certain programs and use-cases improved,\n     especially for 64-bit vs. 32-bit builds on multiple-bitness OSes\n   * Logging routines like `upsdebugx()` were refactored as macros so there\n     is slightly less overhead when logging is disabled [PRs #685 and #1100]\n   * Numerous classes of compilation warnings eradicated, many of those being\n     potential issues with implicit data type conversions and varied numeric\n     type width, signedness, string buffer size, uninitialized variables or\n     structure fields; some more in progress\n   * Several logical errors found and fixed during this walk over codebase.\n   * Cases where compilers were overly zealous and particular code was written\n     the way wit was intentionally, including some comparisons that help with\n     different-bitness builds but indeed seem superfluous in a certain single\n     bitness, were commented and encased in pragmas to disable the warnings\n   * Basic coding style (indentations, lack of trailing white space) applied\n     per developer guide, but not automatically enforced/checked yet.\n\n - Due to changes needed to resolve build warnings, mostly about mismatching\n   data types for some variables, some structure definitions and API signatures\n   of several routines had to be changed for argument types, return types,\n   or both. Primarily this change concerns internal implementation details\n   (may impact update of NUT forks with custom drivers using those), but a\n   few changes also happened in header files installed for builds configured\n   `--with-dev` and so may impact `upsclient` and `nutclient` (C++) consumers.\n   At the very least, binaries for those consumers should be rebuilt to remain\n   stable with NUT 2.8.0 and not mismatch int-type sizes and other arguments.\n\n - As usual, more bugfixes, cleanup and improvements, on both source code\n   and documentation.\n\n\nRelease notes for NUT 2.7.4 - what's new since 2.7.3\n----------------------------------------------------\n\n - New class of device supported: ATS - Automatic Transfer Switch are now\n   supported in NUT. Eaton ATS are supported, and APC ones should be too. Users\n   are welcomed to test and provide feedback\n\n - NUT command and variable naming scheme:\n   * Document battery.charger.status, which will in time replace the historic\n     CHRG and DISCHRG flags published in ups.status\n   * Many extensions to support outlets groups, thresholds / alarms (ambient,\n     input, output, outlet and outlet.group)\n\n - support for new devices:\n   * AEG PROTECT B / NAS\n   * APC ATS AP7724 (should be supported)\n   * Asium P700\n   * Eaton ATS\n   * Eaton 5E 1100iUSB\n   * Eaton E Series DX UPS 1-20 kVA\n   * Eaton Powerware 9125-5000g\n   * Electrys UPS 2500\n   * Fideltronic INIGO Viper 1200\n   * Legrand Keor Multiplug\n   * LYONN CTB-800V\n   * Micropower LCD 1000\n   * NHS Laser Senoidal 5000VA\n   * Sweex model P220\n   * TS Shara\n   * Various APCUPSD-controlled APC devices\n\n - snmp-ups:\n   * Improve automatic detection algorithm\n   * Provide access to Net-SNMP timeout and retries\n   * Proper handling of integer RW variables\n   * Implement support for alarms, through ups.alarm and outlet.n.alarm\n   * Improve log/debug output trace\n   * Fix loss of precision when setting values, using upsrw\n   * Support for outlets group management\n   * Many improvements and simplification\n   * Add support for Tripplite units using IETF mib\n   * Improve communication staleness detection and recovery\n   * Add devices MAC address publication\n   * Register values enumerations, when available\n   * Many improvements and fixes to the SNMP subdriver creation script\n\n - Eaton:\n   * 3ph SNMP:\n     Many improvements to Powerware / XUPS MIB, for data and commands\n     Add support for Eaton Power Xpert Gateway UPS Card\n     Improve support for temperature and humidity, including low / high values\n     Alarms handling\n   * ePDU (G2 and G3):\n     Improve support for ambient sensor, including thresholds and dry contacts\n     Outlet groups handling, including data, thresholds, settings and commands\n     Alarms handling\n   * XML/PDC (netxml-ups):\n     Fix Eaton XML published data\n     Add some settings (R/W flags) on ambient thresholds\n\n - bcmxcp_usb: improvements for device claiming and multi-packets responses\n\n - dummy-ups: allow any variable to be modified\n\n - libnutclient: Fix for reads when the socket was closed by NUT server\n\n - macosx-ups:\n   * fix for 10.10 (Yosemite), v1.1\n   * gracefully handle disconnection of UPS (return \"data stale\")\n\n - nutdrv_atcl_usb: point to nutdrv_qx (fuji) for 0001:0000\n\n - nutdrv_qx:\n   * Add new 'sgs' USB subdriver to support TS Shara units\n   * various improvements and simplification, to the code and documentation\n\n - nut-ipmipsu: improve FreeIPMI support\n\n - nut-scanner:\n   * Don't depend on development libraries, by looking at some known paths,\n     including the one provided through --libdir, to find the correct libraries\n   * Fix a crash on a 2nd call to libnutscan with SNMP method\n\n - powercom: fix the processing of input and output voltage for KIN units\n\n - solis:\n   * many improvements and cleanup\n   * resync with end-of-packet character\n   * fixes for Microsol Back-Ups BZ1200-BR\n\n - tripplitesu: Fix initialization when tripplite firmware is buggy (for\n   Tripplite SU1000RT2U and possibly more)\n\n - usbhid-ups:\n   * various minor improvements\n   * support for Eaton UPS with dual HID report descriptor in HID Parser\n   * handle missing USB strings in APC code\n\n - SSL support through Mozilla NSS: Rework the NSS tests to ensure that NSS is\n   actually installed and usable for enabling SSL support in NUT\n\n - Augeas support: Augeas lens for ups.conf was updated to add various missing\n   global directives and ups fields\n\n - scripts/systemd/nut-server.service.in: Restore systemd relationship since it\n   was preventing upsd from starting whenever one or more drivers, among several,\n   was failing to start\n\n - Fix UPower device matching for recent kernels, since hiddev* devices now have\n   class \"usbmisc\", rather than \"usb\"\n\n - Network protocol information: default to type NUMBER for variables that are\n   not flagged as STRING . This point is subject to improvements or change in\n   the next release 2.7.5.  Refer to link:docs/net-protocol.txt[] for more\n   information\n\n - As usual, more bugfixes, cleanup and improvements, on both source code\n   and documentation.\n\n\nRelease notes for NUT 2.7.3 - what's new since 2.7.2\n----------------------------------------------------\n\n - reverted POWERDOWNFLAG to /etc/killpower as in 2.6.5 (packagers may want to\n   put this in another filesystem, though)\n\n - configure/make fixes for `systemdsystemunitdir`\n\n - apcsmart: fix command set parsing for protocol version 4 (e.g. Smart-UPS\n   RT 10000 XL)\n\n - upslog: SIGUSR1 forces an immediate log entry\n\n - riello_usb/_ser: USB interface claim fix; improved error handling\n\n - usbhid-ups: add support for OpenUPS2 (PID: D005), Liebert GXT3 (PID: 0008)\n   APC AP9584 Serial->USB kit (PID: 0000), and some Powercom models\n   (PID: 0001). Fixed scaling for Cyberpower 0764:0501.\n\n - USB core: do not call usb_set_altinterface(0) by default\n\n - nutdrv_qx:\n   * added fabula, fuji USB and Voltronic-QS-HEX subdrivers\n   * add bestups subdriver to supersede the old standalone bestups driver\n\n - NUT Monitor: added FreeDesktop AppData file (including screenshots)\n\n - renamed udev rules file to 62-nut-usbups.rules (permissions fix)\n\n - added AIX packaging\n\n - asem: added a driver for the UPS in ASEM PB1300 embedded PCs\n\n - solis: updated to support APC Microsol units sold in Brazil\n\n - tripplite_usb:\n   * updated to use dv/dq charge calculation for all models (also\n     exposes battery_min and battery max as configuration variables)\n   * added binary 3005 protocol support (such as for SMART500RT1U)\n\n - genericups: better debugging while parsing the cable description flags\n\n - all drivers: a new 'synchronous' driver flag is available for very verbose\n   units, such as some ePDUs\n\n - Eaton:\n   * Add support for EnergySaving features for Eaton UPSs (HID USB/SHUT and\n     XCP USB/serial)\n   * Fix and complete Eaton ePDUs G2/G3 support\n   * ABM (Advanced Battery Monitoring) support through battery.charger.status\n     in HID (USB and SHUT), XCP (USB and serial) and SNMP (Powerware XUPS MIB)\n\n - support for new devices:\n   * APC Back-UPS 1200BR and Back-UPS BZ2200BI-BR (Microsol)\n   * ASEM SPA PB1300 UPS\n   * Belkin Regulator PRO-USB\n   * Cyber Power Systems Value 1500ELCD-RU\n   * EUROCASE EA200N 2000VA\n   * Fideltronik LUPUS 500\n   * Flight Technic & International (FTUPS) FT-1000BS and FT-1000BS(T)\n   * Grafenthal PR-3000-HS\n   * JAWAN JW-UPSLC02\n   * Lacerda New Orion 800VA\n   * Mecer ME-1000-WTU\n   * NHS Sistemas de Energia Expert C Online 6000/8000/10000\n   * NHS Sistemas de Energia Expert S Online 6000/8000/10000\n   * Powercom BNT-xxxAP (USB product id: 0001)\n   * Rucelf UPOII-3000-96-EL\n   * Tripp Lite OMNIVSINT800\n   * Voltronic Power Apex 1KVA and Imperial 1KVA\n\n\nRelease notes for NUT 2.7.2 - what's new since 2.7.1\n----------------------------------------------------\n\n - This release is the second interim release of the 2.7 testing series.\n\n - libupsclient had undefined references related to functions of libcommon.\n   This issue was reported on Debian (bug #731156) and is now fixed\n\n - support for new devices:\n   * CABAC UPS-1700DV2\n   * Eaton Powerware 3105\n   * Emerson Network Power Liebert PSI 1440\n   * MicroDowell B.Box LP 500\n   * Numeric Digital 800 plus\n   * OptiUPS vs. 575C\n   * Tripp Lite SU10KRT3/1X\n\n - FreeDesktop Hardware Abstraction Layer (HAL) support was removed.\n\n - nutdrv_atcl_usb: new driver for 'ATCL FOR UPS'\n\n - al175: re-introduced this driver (actually, it was in 2.7.1)\n\n - upsdrvctl now provides retry options for upsdrvctl and driver(s)\n\n - snmp-ups: add support for XPPC-MIB and Tripp Lite SU10KRT3/1X.\n   Also fix erroneous status in HP/Compaq SNMP MIB (with the most recent HP\n   firmware (1.76); improved various MIBs (APC, HP/Compaq, ...)\n\n - nutdrv_qx: add new 'fallback' Q1 subdriver, with minimal 'Q1' support.\n   General improvements on all subdrivers.\n\n - mge-shut: partially revert PnP/RTS change, for initializing the\n   communication with the UPS. Note that nut-scanner similar function was\n   not modified however.\n\n - FreeBSD DEVD support: generate devd.conf files for USB UPSes\n   This adds a --with-devd-dir=PATH option to ./configure\n\n - The NUT website was moved to a standalone website. A separate code\n   repository and source archive are now available.\n\n - As usual, more bugfixes, cleanup and improvements, on both source code\n   and documentation.\n\n\nRelease notes for NUT 2.7.1 - what's new since 2.6.5\n----------------------------------------------------\n\nNOTE: There was no public NUT 2.7.0 release.\n\n - This release is an interim release, part of the testing series, and the\n   first release after the transition from Subversion to Git.\n   The last release (2.6.5) is almost a year old. A lot of work has\n   been done, but a good amount remains to achieve 2.8.0 goals.\n   Please read the link:UPGRADING.adoc[] notes.\n\n - Added support for SSL via the Mozilla NSS library, in addition to the\n   existing OpenSSL support.\n\n - Added a new driver, nutdrv_qx, for Megatec/Qx devices. This driver will\n   eventually replace the blazer_ser and blazer_usb drivers. In particular, it\n   adds support for Voltronic Power devices.\n\n - Increased USB_TIMEOUT to standards-compliant 5.000 seconds in most drivers.\n   This should reduce the number of timeouts on low-speed USB 1.1 devices.\n\n - The jNut Java source has been split into a separate GitHub repository.\n\n - Added many devices to the HCL. Of particular note are many Tripp Lite USB\n   HID PDC models which were tested against NUT by Tripp Lite.\n\n - Reworked some visual elements of the HCL. The output is better tailored for\n   graphical and text-only browsers, but suggestions are welcome for additional\n   accessibility enhancements.\n\n - Also increased timeouts and added redundant commands to improve reliability\n   of mge-utalk driver.\n\n - Added the apcupsd-ups driver to interoperate with apcupsd installations.\n\n - Added documentation on creating subdrivers for snmp-ups and nutdrv_qx.\n\n - Added new drivers for the Riello UPS product line (riello_ser/riello_usb).\n\n - Many improvements to the BCM/XCP drivers have been merged in. This includes\n   an improved data reception loop, and additional mappings.\n\n - Added a few variables to the Powercom HID mappings.\n\n - Updated the apcsmart driver, and renamed the previous driver to apcsmart-old.\n\n - Fixed the battery percentage calculation in the bestfcom driver.\n\n - libnutclient has been added as a C++ alternative to libupsclient.\n\n - Packaging files for Solaris and HP-UX (sponsored by Eaton)\n\n - Fix shutdown of Eaton HID, using usbhid-ups and mge-shut\n\n - usbhid-ups: final fix for APC Back UPS ES.  APC Back UPS ES devices have\n   buggy firmware, and this version does not cause a regression. The max_report\n   variable should be set automatically based on the USB identification values.\n   * UPDATE: known as `maxreport` flag for `usbhid-ups` driver, and as a\n     `max_report_size` setting in code, as of NUT v2.8.2 release.\n\n - nut-scanner: fix crash\n\n - IPMI support can handle more different versions of FreeIPMI\n\n - Support power supplies scan over the network\n   nut-scanner can now scan for power supplies with IPMI over LAN.\n   This is currently limited to IPMI 1.5 only\n\n - Implement a framework to spell check documentation source files,\n   using Aspell. This includes an interactive build target (make\n   spellcheck-interactive), and an automated one (make spellcheck),\n   mainly for QA / Buildbot purpose. Note that a base NUT dictionary\n   is also available (link:docs/nut.dict[]), providing a glossary of\n   terms related to power devices and management\n\n - Improve systemd integration\n\n - snmp-ups: Fixed a crash on outlet management, and added delta_ups MIB\n   support. Also fixed mappings for upsBypassVoltage, upsBypassCurrent, and\n   upsBypassPower in three-phase IETF MIB.\n\n\nRelease notes for NUT 2.6.5 - what's new since 2.6.4\n----------------------------------------------------\n\n - This release fixes an important regression in upssched:\n   any upssched.conf command that takes a second argument resulted in\n   a defective frame sent to the parent process. Thus, the command was\n   not executed (report and patch from Oliver Schonefeld)\n\n - Website hosting: free NUT from Eaton website hosting\n   +\n   +\n   NUT website (https://www.networkupstools.org) is no longer hosted by Eaton.\n   Arnaud Quette (NUT project leader) has taken over NUT hosting on his own,\n   to give NUT back some independence.\n   +\n   +\n   This effort is also part of a logic to stop crediting Eaton for\n   contributions from others (especially Arnaud Quette, as an individual).\n   The new hosting service is located, as for Arnaud's blog\n   (http://arnaud.quette.fr) on Gandi servers, using PaaS.\n   +\n   +\n   This will allow more flexibility and automation of the release process.\n\n - macosx-ups: new OS X Power Sources meta-driver\n   * Mac OS X provides UPS status information in a format similar to\n     what is shown for laptop batteries. This driver will convert that\n     information into a format compatible with NUT (Charles Lepple).\n\n - support for new devices:\n   * Eaton ePDU Switched\n   * Online Zinto A (USB ID 0x06da:0x0601)\n   * REDi Blazer 400VA / 600VA / 800VA\n   * UNITEK Alpha650ipF and Alpha650ipE (USB ID 0x0f03:0x0001)\n\n - mge-shut driver has been replaced by a new implementation (newmge-shut).\n   In case of issue with this new version, users can revert to oldmge-shut.\n   UPDATE: oldmge-shut was dropped between 2.7.4 and 2.8.0 releases.\n\n - First NUT virtualization package: NUT now supports integration with\n   VMware ESXI 5.0, through a native VIB package. This is, for the time\n   being, an external effort from René Garcia (refer to the Download section\n   on NUT website). But work is underway to improve this integration, and\n   include it in the NUT source tree\n\n - IPMI support (nut-ipmipsu driver and nut-scanner): prepare for supporting\n   API changes in upcoming FreeIPMI versions 1.1.x and 1.2.x.\n\n - snmp-ups now supports high precision values for APC, and more variables\n\n - the NUT variables and commands namespace has been fixed and\n   completed, with the known and used variables that were missing.\n\n - more bugfixes, cleanup and improvements, on both source code and\n   documentation.\n\n\nRelease notes for NUT 2.6.4 - what's new since 2.6.3\n----------------------------------------------------\n\n - This release fixes an important vulnerability in upsd\n   (CVE-2012-2944: upsd can be remotely crashed)\n   +\n   +\n   NUT server (upsd), from versions 2.4.0 to 2.6.3, are exposed to\n   crashes when receiving random data from the network.\n   +\n   +\n   This issue is related to the way NUT parses characters,\n   especially from the network. Non printable characters were missed\n   from strings operation (such as strlen), but still copied to the\n   buffer, causing an overflow.\n   +\n   +\n   Thus, fix NUT parser, to only allow the subset of ASCII charset from\n   `Space` to `~`\n   (Reported by Sebastian Pohle, Alioth bug #313636, CVE-2012-2944)\n   +\n   +\n   A separate patch, which applies to any faulty version, is also available:\n   http://trac.networkupstools.org/projects/nut/changeset/3633\n   +\n   +\n   For more information, refer to the Common Vulnerabilities and Exposures:\n   http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-2944\n\n - A static source code analysis has been done by Michal Hlavinka from RedHat,\n   using Coverity (12 issues fixed).\n\n - Add new \"LIST CLIENTS\" and \"NETVER\" commands to NUT network protocol.\n   \"NETVER\" allows to retrieve the Network protocol version, while\n   \"LIST CLIENTS\" provides the list of clients connected to a device.\n   Refer to the developer guide, \"Network protocol information\" section for\n   more information.\n\n - Support of ranges of values for writable variables has been added, to\n   complete the existing enumerated values mechanism. This will start to\n   appear in some drivers soon, beginning with Eaton. Refer to the developer\n   guide, \"Creating a new driver...\" section for more information.\n\n - PyNUT.py has been updated to version 1.2.2, adding support for\n   LIST CLIENTS, FSD, HELP and VER (Rene Martín Rodríguez)\n\n - support for new devices:\n   * AEG Power Solutions PROTECT HOME\n   * more APC SNMP cards\n   * ATEK Defensor range\n   * all Borri models\n   * all COVER ENERGY SA\n   * CyberPower OR700LCDRM1U, PR6000LCDRTXL5U and CP1000PFCLCD\n   * Dell UPS Network Management Card\n   * Dynamix 1000VA USB\n   * Eaton Management Card Contact (ref 66104)\n   * EVER POWERLINE RT / 11 / 31 and DUO II Pro\n   * GE Digital Energy GT Series 1000-3000 VA\n   * Gtec models\n   * all recent HP serial / USB UPS (G2, G3 and R/T models, ) and HP UPS\n     Management Module\n   * Ippon INNOVA RT\n   * KOLFF BLACK NOVA\n   * Lexis X-power Tigra 1kVA\n   * Microline C-Lion Innova\n   * Online Yunto YQ450\n   * PowerShield Defender 1200VA\n   * PowerWalker Online VFI LCD, Line-Interactive VI LCD and Line-Interactive VI\n   * Riello Netman Plus 102 SNMP Card\n   * Tripp-Lite OMNISMART500\n\n - apcsmart has received some fixes to work better on Mac OS X, and in general\n\n - bcmxcp has improved support for battery status, and better supports\n   PW9120 units\n\n - bestfortress has improved Best Fortress LI675VA support\n\n - blazer_ser and blazer_usb now try to automatically estimate high and low\n   voltages, to be able to calculate battery charge; support for online\n   Innova UPS (T, RT and 3/1 T) has been added; Best UPS support has been\n   improved, to prepare for superseding bestups driver\n\n - bestups has also received some care, though users are encouraged to switch\n   to blazer_ser, since bestups will soon be deprecated.\n\n - newmge-shut has been heavily improved.  However, replacement of the\n   current mge-shut has been postponed to the next release, due to the CVE\n   issue.\n\n - oneac 0.80 improves support for all families of Oneac (EG, ON, OZ and OB),\n   including more data and instant commands (Bill Elliot).\n\n - usbhid-ups: for Eaton devices, ups.start.auto is now automatically adjusted\n   for shutdown.{return,stayoff} to behave as expected; Liebert firmwares with\n   incorrect exponents have also been addressed.\n\n - snmp-ups now provides support for UPS shutdown, based on usbhid-ups\n   mechanisms (composite commands and fallback). Composite commands are also\n   supported now. This means, for example, that if 'shutdown.return' is not\n   supported, a combination of 'load.off' + 'load.on' may be used;\n   Actual validity of instant commands is now tested before commands addition;\n   Eaton/MGE MIB has been cleaned and completed; 3-phases support has been\n   added to Socomec Netvision MIB; HP/Compaq MIB has been completed, with\n   thresholds, nominal values and more commands.\n\n - nut-scanner now also has libupsclient has a weak runtime dependency; more\n   docs and bugfixes have also happened.\n\n - Provide an Uncomplicated Firewall (UFW) profile (nut.ufw.profile)\n\n - Riello protocols have been officially published in NUT protocols library:\n   https://www.networkupstools.org/ups-protocols.html#_riello\n\n - Duplicate instances of upsd / upsmon are now detected upon startup\n\n - NUT variables namespace has been completed with missing variables and\n   commands that are already known and standard\n\n - upslog now comes with a companion file, for logrotate configuration\n\n - more devices embed NUT for power protection, now including Thecus NAS range\n\n - more bugfixes, cleanup and improvements, on both source code and\n   documentation, with a good bunch from Greg A. Woods.\n\n\nRelease notes for NUT 2.6.3 - what's new since 2.6.2\n----------------------------------------------------\n\n - nut-scanner is now more portable, and provides more coherent option names.\n   IPMI support has also been added, to discover local power supplies.\n   This version brings weak runtime dependencies in libnutscan, which allows to\n   compile nut-scanner with all options and to run according to the available\n   dependencies (USB, SNMP, IPMI, ...).\n\n - libnutscan now provides pkg-config support and the needed header files are\n   distributed. Some documentation is also available in the developer guide and\n   manual pages have been updated and completed.\n\n - support for new devices:\n   * Cyber Power Systems with SNMP RMCARD (100, 201, 202 and 301)\n   * Dynamix 650VA USB\n   * LDLC UPS-1200D\n   * Tecnoware UPS ERA LCD 0.65\n   * Powercom BNT-xxxAP (USB ID 0d9f:0004)\n   * Various USB devices using UPSilon 2000 software\n\n - apcsmart has received minor correction.\n\n - bcmxcp_usb now handles disconnection issues and reconnection mechanism.\n\n - blazer_usb enables again inclusion of buggy USB Device and Vendor IDs in\n   udev rules file; language ID support has been added for USB units from\n   LDLC, Dynamix and other no names.\n\n - nut-ipmipsu has also received some improvements.\n\n - snmp-ups has fixed outlets reported current in aphel_genesisII MIB;\n   MGE 3 phases handles better low battery condition; support for Cyber Power\n   Systems with SNMP RMCARD has been added; support of the newer Eaton ePDUs\n   has been improved.\n\n - upsd doesn't anymore fail to start if at least one of the listening\n   interface is available. This is needed on systems where either IPv4 or IPv6\n   is disabled, and no explicit LISTEN directive has been specified.\n\n - Avahi support is now automatically enabled, upon detection\n\n - jNut (NUT Java interface) adds device discovery support, through a\n   nut-scanner wrapper; jNutWebAPI, a HTTP/JSON web service interface, has\n   also been added to interact with upsd and nut-scanner.\n\n - Base files for HPUX packaging have been added. This is still a work in\n   progress.\n\n - Compilation on IBM AIX has been fixed (namespace conflict with ctypes).\n\n - more bugfixes, cleanup and improvements, on both source code and\n   documentation.\n\n\nRelease notes for NUT 2.6.2 - what's new since 2.6.1\n----------------------------------------------------\n\n - NUT can now monitor power supply units (PSU) in servers, through IPMI, using\n   the new experimental 'nut-ipmipsu' driver. Users are encouraged to test it,\n   and send feedback and debug output to the development mailing list.\n   This requires GNU FreeIPMI (0.8.5 or higher) development package or files.\n   Thanks goes to Al Chu, FreeIPMI project leader, for his help during this\n   development.\n\n - NUT now provides a tool, called 'nut-scanner', to discover supported devices,\n   both local and remote. nut-scanner will help to ease the configuration step,\n   and power infrastructure discovery.\n   +\n   +\n   This development, sponsored by Eaton, supports the following methods:\n   * USB,\n   * SNMP,\n   * XML/HTTP (from Eaton),\n   * NUT servers, using the classic connect or Avahi / mDNS methods.\n   +\n   +\n   IPMI support will be added in the next release.\n   +\n   +\n   A separate library, called 'libnutscan', is also available to provide these\n   feature. Future NUT releases will provides binding for the supported\n   languages (Perl, Python and Java).\n\n - NUT now provides a Java interface called 'jNut'.\n   This development, sponsored by Eaton, is currently limited to the client\n   interface. But it will be broaden to device discovery and configuration in\n   the future.\n   +\n   +\n   For more info, refer to nut/scripts/java/README, or the developer guide\n   (chapter 'Creating new client'). Javadoc documentation is also provided,\n   along with Java archives (.jar) in the Download section.\n\n - support for new devices:\n   * Eaton 3S\n   * Cyber Power Systems CP1000AVRLCD\n   * various APC models equipped with APC AP9618 management card, including\n     APC Smart-UPS RT XL\n   * Orvaldi 750 / 900SP\n   * POWEREX VI 1000 LED\n   * PowerWalker VI 850 LCD\n   * SVEN Power Pro+ series (USB ID ffff:0000)\n\n - A regression has been fixed in udev rules file. This previously caused\n   permission issues to owners of some USB devices.\n\n - Avahi support has been added, for NUT mDNS publication, through a static\n   service file (nut/scripts/avahi/nut.service).\n\n - usbhid-ups has had Eaton completion: some features have been improved, such\n   as 'output.voltage.nominal'; 3S Eco control support has been added, along\n   with battery.runtime.low and end of battery life (life cycle monitoring)\n   support; new measurements for 5 PX are also supported now (outlet power\n   factor, power, real power and current).\n\n - apcsmart has been updated to support more variables and features; the\n   previous driver is however still available as 'apcsmart-old', in case of\n   issues.\n\n - bcmxcp now supports per outlet startup and shutdown delays setting; shutdown\n   delay is also used, when available, for outlet.n.shutdown.return instead of\n   the default 3 seconds.\n\n - snmp-ups.c has a new initialization method, that uses sysObjectID, which is\n   a pointer to the preferred MIB of the device, to detect supported devices.\n   This speeds up even more init stage and should render void the use of 'mib'\n   option. SNMP v3 session initialization has also been fixed, and Eaton PDU\n   support has been completed.\n\n - Initial support has been added for systemd, the System and Service Manager\n   from RedHat.\n\n - The chapter 'NUT configuration management with Augeas' of the developer guide\n   has received some completion: a complete Python Augeas example code is now\n   provided.\n\n - Finally, after years of dedication to NUT, Arjen de Korte is now retired.\n   Sincere thanks to you Arjen from us all.\n\n\nRelease notes for NUT 2.6.1 - what's new since 2.6.0\n----------------------------------------------------\n\n - the various recent USB regressions have been definitely fixed.\n\n - NUT now propose a variable to expose UPS efficiency (ups.efficiency).\n   Eaton 5 PX already uses it.\n\n - the Perl module from Gabor Kiss (rewritten from Kit Peters') is now\n   distributed with NUT source code.\n\n - support for new devices:\n   * Eaton Ellipse ECO, Powerware 9140, Eaton 5 PX, and ambient sensor\n     on Eaton ePDU managed\n   * GE EP series\n   * Inform Sinus SS 210\n   * IPAR Mini Energy ME 800\n   * Mustek Yukai PowerMust 1000 USB\n   * Numeric 3000 SW\n   * SVEN Power Pro+ series (recent models)\n   * Vivaldi EA200 LED\n\n - liebert-esp2: Improved Liebert ESP II support, including UPS shutdown\n   (poweroff), 1 and 3-phase input and output variables, and most\n   input / output / bypass / nominal variables. There is also a fix for the\n   USB to serial cable (Farkas Levente and Spiros Ioannou).\n\n - powercom has improved PowerCom BNT 1500A and BNT-other support, along with\n   driver documentation and code conformance to the NUT rules (Keven L. Ates).\n\n - apcsmart has more improved UPS poweroff support and options (Michal Soltys).\n\n - blazer has also seen some improvements.\n\n - usbhid-ups has completed a bit supported variables for APC and Eaton / MGE.\n\n - on the quality assurance side, Eaton has worked on fixing a few\n   non-conformance issues, like C++ style comments and warnings, using\n   a newly developed verification tool (Prachi Gandhi).\n\n - fix remaining references to LIBSSL_LDFLAGS, instead of LIBSSL_LIBS,\n   which cause unresolved symbol on libupsclient users (Fabrice Coutadeur).\n\n - the website has now a better support for Internet Explorer 6.\n\n - graphic illustrations, used for the Features page on the website Features\n   and chapter of the user manual, have been refreshed (courtesy of Eaton).\n\n - more bugfixes, cleanup and improvements, on both source code and\n   documentation.\n\n\nRelease notes for NUT 2.6.0 - what's new since 2.4.3\n----------------------------------------------------\n\nNOTE: Per original semantic versioning, there were no public NUT 2.5.x releases.\n\n - the main focus of this release is the complete documentation revamping,\n   using AsciiDoc. This includes a new website, user manual, developer guide,\n   packager guide and manual pages, available in various formats (single and\n   multiple pages HTML, and PDF at the moment).\n   +\n   +\n   Be sure to check the `--with-doc` option help of `configure` script, and\n   link:docs/configure.txt[] for more information.\n\n - Add Augeas support, to provide easy NUT configuration management, through\n   tools and development APIs. For more information, refer to the developer\n   guide, or link:scripts/augeas/README.adoc[] in the source directory.\n\n - support for new devices:\n   * APC 5G\n   * Eaton PowerWare 5119 RM (smart mode using upscode2 driver)\n   * Eaton Best Ferrups (using older ConnectUPS card)\n   * Eaton 9395 (serial interface)\n   * Eaton ConnectUPS X / BD / E Slot\n   * HP T1000 INTL\n   * HP T1500 INTL\n   * HP T750 G2\n   * HP R1500 G2 INTL\n   * iDowell iBox UPS\n   * Tripp Lite SmartOnline SU1000XLA\n   * Tripp Lite Smart1000LCD\n   * and some more USB/HID devices IDs\n   * CyberPower CP1500AVRLCD and CP1350AVRLCD\n   * PowerWalker Line-Interactive VI 1400\n   * Rocketfish RF-1000VA / RF-1025VA\n\n - usbhid-ups has better support for shutting down APC SmartUPS RM series,\n   and finally fix the \"buffer size\" issue, which was breaking some\n   devices data retrieval, or truncating some data on others.\n\n - snmp-ups now support SNMP v3 and its security parameters. IETF MIB support\n   has also been extended.\n\n - fix dummy-ups simulation driver status handling bug, and add the\n   capability to remove exposed variables on the fly.\n\n - the belkin driver now support control commands and status reporting\n   for beeper and battery test.\n\n - the powerpanel driver supports more older CyberPower units.\n\n - mge-utalk, upscode2, blazer and liebert-esp2 have also received some\n   care, and been improved.\n\n - NUT-Monitor and the PyNUT client module have been updated to 1.3,\n   adding more features like automatic connection to the first local device\n   and i18n support.\n\n - improve configure time dependencies checking and processing.\n\n - improve older Unix systems support (HP-UX, AIX, ...) for missing functions.\n\n - refresh and improve USB helper files (udev and UPower).\n\n - more generation automation: the ChangeLog file is now generated\n   automatically at distribution time, along with the files needed for\n   the website hardware compatibility list.\n\n - SSL support has also received some improvements.\n\n - tcp-wrapper now allows hostnames in /etc/hosts.allow too (not only IPv4\n   and/or IPv6 addresses).\n\n - many bugfixes, cleanup and improvements.\n\n\nRelease notes for NUT 2.4.3 - what's new since 2.4.2\n----------------------------------------------------\n\n - this is a bugfix release that only solves the regression on IPv6 activation.\n\n\nRelease notes for NUT 2.4.2 - what's new since 2.4.1\n----------------------------------------------------\n\n - the general USB support has been vastly improved, including many bug\n   fixes, better OS support, new features and devices.\n\n - NUT now talks to Solar Controller Devices with the new ivtscd driver.\n\n - the snmp-ups driver supports more PDU, with a smaller disk footprint.\n\n - apcsmart supports more older SmartUPS and Matrix units.\n\n - the bestfortress driver is resurrected.\n\n - the virtual driver has been renamed to 'clone'.\n\n - the netxml-ups driver has received some care.\n\n - various debugging and development improvements have been done, around\n   driver output; dummy-ups with more interaction and scripting and the\n   device-recorder.sh script.\n\n - the build system has received many bugfixes and improvements.\n\n - the UPower (previously known as DeviceKit-power) rules file is now\n   generated by NUT.\n\n - support for new devices:\n   * Apollo 1000A and 1000F\n   * various Baytech RPC\n   * old Best Power Fortress\n   * Cyber Power Systems PR3000E, CP 1500C and OR2200LCDRM2U\n   * all the new Dell UPS range (serial, USB and network)\n   * Eaton E Series NV and DX UPS, and Powerware 9130\n   * older HP T500 and T750, newer T750 INTL (USB) and R1500 G2 (serial)\n   * Inform Informer Compact 1000VA\n   * many serial and USB devices from Ippon, like Back Comfo Pro,\n     Smart Power Pro and Smart Winner\n   * IVT SCD series\n   * Liebert GXT2-3000RT230 and PowerSure PSA\n   * Mustek PowerMust 424 / 636 / 848 USB\n   * all new PowerCOM USB devices with HID PDC interface\n   * Tripp-Lite INTERNETOFFICE700, SMART700USB and ECO550UPS\n   * UPSonic DS-800 (USB)\n\n\nRelease notes for NUT 2.4.1 - what's new since 2.4.0\n----------------------------------------------------\n\n - the microdowell driver has appeared to support various MicroDowell Enterprise\n   units (see the \"new devices\" list below).\n\n - support for new devices:\n   * MicroDowell Enterprise B8, B10, N8, N11, N15, N20,\n     N22, N30, N40, N50, N60 and HiBox ST.\n\n - NUT-Monitor now better handles the ups.status field, and has switched to\n   version 1.1.\n\n - the situation of the build toolchain has been fixed, with regard to the\n   \"make clean\" target and the wrongly removed generated USB files. This broke\n   further configure call.\n\n\nRelease notes for NUT 2.4.0 - what's new since 2.2.2\n----------------------------------------------------\n\nNOTE: Per original semantic versioning, there were no public NUT 2.3.x releases.\n\n - preliminary support for Power Distribution Units (PDUs): NUT can now support\n   PDUs, either natively (ie using NUT snmp-ups driver), or through a binding to\n   the Powerman daemon. The list of supported PDUs is already quite long,\n   including:\n   * Eaton ePDUs (Managed and Monitored),\n   * some Aphel models,\n   * some Raritan PDUs,\n   * and the whole list of Powerman supported devices:\n     http://powerman.sourceforge.net/supported.html\n\n - support for new devices:\n   * the various PDUs cited above\n   * Chloride Desk Power 650\n   * Cyber Power Systems Value 400E/600E/800E (USB models)\n   * Delta GES602N\n   * Digitus DN-170020\n   * the whole Eaton ranges (mostly composed of MGE Office Protection Systems\n     and Powerware units) including BladeUPS\n   * Forza Power Technologies SL-1001\n   * HP PowerTrust 2997A\n   * HP R/T 2200 G2\n   * Infosec XP 1000 and XP 500\n   * Ippon Back Power Pro (serial and USB)\n   * Kebo 1200D/D Series\n   * Liebert PowerSure Personal XT\n   * MGE Office Protection Systems Protection Station\n   * Neus 400va and 600va\n   * Phasak 400VA and 600VA\n   * Plexus 500VA\n   * Powercom Black Knight PRO / King PRO and Imperial\n   * PowerKinetics BlackOut Buster\n   * Sweex 1000 USB\n   * UNITEK Alpha 500\n   * WinPower CPM-800\n\n - NUT now embeds Python client support through the PyNUTClient module and the\n   NUT-Monitor application. Both are from David Goncalves, and are still\n   available from http://www.lestat.st.\n   For more information, refer to link:scripts/python/README.adoc[].\n\n - the dummy-ups driver now supports a \"repeater\" mode. This allows it to act as\n   a NUT client, and to forward data. This can be useful for supervision and\n   load sharing purposes.\n\n - tcp-wrappers support has been added to the upsd server, to grant users access\n   by source IP for commands that require to be logged into the server. This\n   replaces the previous internal implementation (ACL in upsd.conf).\n\n - the nut.conf file has been introduced to standardize startup configuration\n   across the various systems.\n\n - NUT now ships a bash completion function for 'upsc' command\n   (scripts/misc/nut.bash_completion). Simply copy it to /etc/bash_completion.d\n\n - many internal changes to improve maintainability, while lowering the\n   maintenance cost (thus allowing developers to focus on what matters: the\n   code!). Examples of this are:\n   - the USB information automatic extraction to generate the various USB helper\n     files,\n   - the upsdrv_info_t structure to track more driver information, and remove\n     the need for the upsdrv_banner() function\n   - common USB code refactoring, as it is done for the serial functions.\n\n - tons of bugfixes, cleanup and improvements to make NUT stronger than ever!\n\n\nRelease notes for NUT 2.2.2 - what's new since 2.2.1\n----------------------------------------------------\n\n - support for new devices: APC BACK-UPS XS LCD, Atlantis Land,\n   Mustek Powermust Office 650, Oneac XAU models, Powerware PW5115 and\n   PW9120 (USB), Nitram Elite 2005\n\n - Integrated Power Management (NUT HAL integration) has reached a\n   major milestone: it is now the most advanced UPS integration into\n   Power Management layer known in existing OSs. It has received many\n   corrections and improvements, and allows to PowerOff the UPS at the\n   end of a power cycle (which is the most important feature, not\n   supported on other systems).\n   The various files are now installed into the correct location.\n\n - the usbhid-ups driver has received attention. Most notably, the\n   shutdown handling has been reworked, and support for MGE UPS SYSTEMS\n   3 phases units has been added.\n\n - snmp-ups now supports MGE* Environment Sensor (ref 66 846).\n   The ambient.temperature reporting has also been fixed for units\n   other than APC.\n\n - the netxml-ups driver has appeared to support MGE* network HTTP/XML\n   cards.\n\n - NUT now distributes by default the shared version of libupsclient\n   (version 1.0.0), and use this for the provided clients (upsmon, upsc,\n   upsrw, upscmd). This is part of an effort to reduce NUT's footprint,\n   both on disk and in memory.\n\n - powerpanel has reach a new step toward the replacement of nitram and\n   cpsups drivers. The final step is scheduled for NUT 2.4.\n\n - many changes, cleanup and fixes to the NUT core and various drivers.\n\n\nRelease notes for NUT 2.2.1 - what's new since 2.2.0\n----------------------------------------------------\n\n - support for new devices:\n   * all MGE Office Protection Systems units\n   * Advice TopGuard 2000\n   * Belkin F6H375-USB\n   * Dynamix UPS1700D\n   * Effekta RM2000MH,\n   * Jageson Technology Jasuny USPS\n   * Powercom SMK-1500A and SXL-1500A\n   * PowerWalker Line-Interactive VI 400/800 and 600\n   * Powerware 9110\n   * UNITEK Alpha 2600\n   * UPSonic CXR1000\n   * some vintage serial APC UPSs\n\n - the usbhid-ups driver has been improved, and fixed in many areas, through\n   a backport of the development (trunk) version.\n\n - the udev rules, for Linux hotplug support of the USB UPSs, has been\n   updated to support kernel newer than 2.6.22.\n\n - the megatec and megatec_usb drivers have also been backported from the\n   development (trunk) version.\n\n - the client development files have also received some care:\n   the upsclient pkg-config file has been fixed, and the upsclient.h\n   file allows older NUT clients to continue using the UPSCONN structure.\n\n\nRelease notes for NUT 2.2.0 - what's new since 2.0.5\n----------------------------------------------------\n\nNOTE: Per original semantic versioning, there were no public NUT 2.1.x releases.\n\n - The new build infrastructure, using automake, is now used.\n   This has major impact on the compilation and installation procedures,\n   and thus on the NUT packaging.\n   For more information, refer to link:UPGRADING.adoc[] and packaging/debian/ for\n   an example of migration.\n\n - NUT now provides support for FreeDesktop Hardware Abstraction Layer\n   (HAL) which brings full Plug And Play experience to USB UPS owners.\n   For more information, refer to link:docs/nut-hal.txt[].\n\n - support for new devices:\n   * Ablerex 625L\n   * ActivePower 400VA, 2000VA;\n   * Belkin Home Office F6H350-SER, F6H500-SER, F6H650-SER\n   * Belkin Office Series F6C550-AVR\n   * Belkin Universal UPS F6C100-UNV (USB), F6C1100-UNV (USB),\n     F6C1200-UNV (USB), F6H350deUNV (serial),\n     F6H350ukUNV (serial), F6H650ukUNV (serial)\n   * Compaq R3000h\n   * Cyber Power Systems PR2200\n   * Dynex DX-800U\n   * Geek Squad GS1285U\n   * Krauler UP-M500VA\n   * Mecer ME-2000\n   * MGE UPS SYSTEMS Ellipse MAX\n   * Online Zinto D\n   * PowerTech SMK-800\n   * SVEN Power Pro+ series\n   * Power Smart RM 2000\n   * Tripp-Lite SmartOnline SU1500RTXL2ua, smart2200RMXL2U.\n\n - added IPv6 support,\n\n - the newmge-shut driver has appeared. This one uses the same HID core\n   as usbhid-ups, but communicate over a serial link. It will eventually\n   replace the current mge-shut driver.\n\n - client commands (upsc, upsrw and upscmd): hostname is now optional,\n   and defaults to \"localhost\"\n\n - many drivers have been improved and have received bug fixes:\n   powerpanel, megatec, megatec_usb, safenet, tripplite_usb, gamatronic,\n\n - the hotplug and udev scripts, in charge of setting the right\n   permissions on the USB devices, are now installed automatically\n   when appropriate.\n\n - more generally, the NUT core and documentation, including the manpages,\n   have been improved and updated.\n\n\nRelease notes for NUT 2.0.5 - what's new since 2.0.4\n----------------------------------------------------\n\nThis release is a backport of the development version.  Many changes\nhave already been backported previously.  Thus it is more a\nsynchronization release, though it includes many bugfixes and support\nfor new models.\n\n - support for new devices:\n   * APC Smart-UPS with 6TI firmware\n   * Belkin Small Enterprise F6C1500-TW-RK\n   * Compaq R3000 XR, R5500 XR\n   * Cyber Power 550SL, 725SL, 685AVR, 800AVR, 1200AVR, AE550\n   * Eltek\n   * Inform GUARD\n   * Microsol Rhino\n   * Opti-UPS PowerES 420E\n   * PowerMan RealSmart, BackPro\n   * Powerware PW9315 3-phase\n   * SOLA 305\n   * Tripp-Lite SMART550USB, SMART2200RMXL2U, OMNI1000LCD, OMNI900LCD,\n     OMNI650LCD, 1500 LCD, AVR550U\n   * Viewsonic PowerES 420E\n\n - bcmxcp: added 3-phase support\n\n - megatec: better hardware support, more instant commands\n\n - mge-hid: support more instant commands\n\n - newhidups: fixed APC and Tripp Lite bugs, various memory bugs,\n   improved report buffering, improved Solaris support, added\n   '-x explore' option for easy diagnosis of new devices\n\n - solis: shutdown programming, support new cables, Solaris support\n\n - tripplite_usb: updated SMARTPRO support, fixed OL/OB reporting,\n   better error handling, some memory bugs\n\n - new dummy-ups driver simulator\n\n - added HTML interface for access to CGI scripts\n\n\nRelease notes for NUT 2.0.4 - what's new since 2.0.3\n----------------------------------------------------\n\n - The newhidups critical bug (segmentation fault) has been fixed. It has\n   also received some more care, like bugfixes and new models support and\n   enhancement for Solaris.\n   [Peter Selinger and Arnaud Quette]\n\n - A bug has been fixed in NUT core to support resuming from suspend-to-disk.\n   This should also fix other similar issues, like time synchronization\n   through the NTP - Network Time Protocol.\n   [Arjen de Korte]\n\n - The mge-shut driver now better detects the Low Battery status, support\n   new models and fixes some wrong status and data. It also fixes some\n   issue where the UPS wasn't restarting (refer to mge-shut manpage).\n   [Arnaud Quette]\n\n - The genericups custom configuration through ups.conf is working again\n   [Arjen de Korte]\n\n - The genericups driver type 22 also support CyberPower 725SL\n   (and maybe others SL models)\n   [David Kaufman]\n\n - The new megatec driver, which will replace a bunch of drivers by nut 2.2\n   (refer to link:docs/megatec.txt[] and link:UPGRADING.adoc[]) has been\n   backported from the trunk (Development tree). The powermust driver has\n   also received some attention.\n   [Carlos Rodrigues]\n\n - The new rhino driver was added to support Microsol Rhino UPS hardware\n   The solis has also been improved for Solaris compatibility, and\n   internal / external shutdown programming. solis can now save external\n   shutdown programming to ups, and support new cables for solis 3\n   [Silvino B. MagalhÃ£es]\n\n - Several fixes and improvements have been made to upsrw, upsset,\n   cpsups, tripplite_usb and the FAQ.\n   [Arjen de Korte and Charles Lepple]\n\n\nRelease notes for NUT 2.0.3 - what's new since 2.0.2\n----------------------------------------------------\n\n - The recent and major newhidups changes have been backported from the\n   Development tree. It now:\n   - supports models from MGE UPS SYSTEMS, APC and Belkin. Mustek and Unitek\n     units are also recognized for development purpose,\n   - handles better device reopening, after a disconnection,\n   - handles multiple devices, with several parameters to find the right UPS.\n   [Peter Selinger, Charles Lepple and Arnaud Quette]\n\n - The bcmxcp_usb driver has been added to support Powerware USB units.\n   [Wolfgang Ocker and Kjell Claesson]\n\n - The tripplite_usb driver has been added to support Tripp Lite USB units.\n   [Charles Lepple]\n\n - The sec driver is back as gamatronic\n   [Gamatronic, Nadav Moskovitch]\n\n - The genericups driver has received official care from Gamatronic\n   to add support for the Gamatronic UPS with alarm interface.\n   [Gamatronic, Nadav Moskovitch]\n\n - The powermust driver now supports Soyntec Sekury C 500 and C 800 units.\n   [Hanno Borns]\n\n - The mge-shut driver has received a bit of attention too, and enhance\n   ups.model retrieval for some specific case (release 0.65)\n\n - The drivers don't change to the \"statepath\" directory anymore at\n   initialization time if called using -k. This avoid unneeded\n   failure to poweroff the UPS if /var is already unmounted.\n   [Gaspar Bakos]\n\n - The belkinunv driver now supports Belkin F6C1100-UNV\n   [Dave Breiland]\n\n - The isbmex driver has been upgraded to version 0.05, which fixes\n   various errors in formulas, add shutdown capability and revert\n   back baudrate to B9600 (instead of B2400), as it broke the\n   communication\n   [Ricardo Martinezgarza]\n\n - The support of Sysgration UPGUARDS Pro650 in fentonups has\n   been fixed\n   [Simon J. Rowe]\n\n - The packaging files for Red Hat have received various fixes\n   [Thomas Jarosch]\n\n - The solis driver has been fixed to avoid a naming collision and\n   compile on Solaris\n   [Paweł Kierdelewicz]\n\n - The snmp-ups driver has corrected the problem when exposing\n   certain time data.\n\n\nRelease notes for NUT 2.0.2 - what's new since 2.0.1\n----------------------------------------------------\n\n - the newhidups USB driver has been improved a lot and is no more\n   experimental. It also now has a basic APC support, which will\n   soon replace the legacy hidups driver.\n\n - The mge-utalk driver has improved its support for old units.\n\n - The mge-shut driver has been improved for restart/shutdown\n   sequences which was previously blocking the serial port.\n\n - The general MGE support has been added Pulsar EXtreme C / EX RT,\n   Comet EX RT, Pulsar SV, Pulsar PSX, Ellipse Office and NOVA AVR USB.\n\n - The genericups driver now supports Generic RUPS 2000, AEC MiniGuard\n   UPS 700 (using Megatec M2501 cable), and Powerware 3110.\n   [Nick Barnes, Paul Andreassen]\n\n - The powermust driver now supports SquareOne Power QP1000, Mustek\n   PowerMust 1400VA Plus and 2000VA USB.\n   [Carlos Rodrigues]\n\n - The fentonups driver has been enhanced and now supports Sysgration\n   UPGUARDS Pro650.\n   [Michel Bouissou, Simon J. Rowe]\n\n - The cpsups driver now supports MicroDowell B.Box BP 500/750/1000/1500.\n   [Armin Diehl]\n\n - The snmp-ups driver now supports Socomec SNMP devices (Netvision MIB),\n   and Powerware ConnectUPS SNMP cards.\n   [Thanos Chatziathanassiou, Olli Salvia]\n\n - The bcmxcp driver is back with support for Powerware UPSs.\n   [Tore Ørpetveit, Kjell Claesson]\n\n - The cyberpower driver now supports CyberPower 1000AVR.\n   [Dave Huang]\n\n - The new solis driver supports Microsol units: Solis 1.0, 1.5,\n   2.0 and 3.0.\n   [Silvino B. Magalhaes]\n\n - The apcsmart driver has fixed APC600 support.\n\n - The etapro driver fixes brokenness due to ser_get_line use\n   [Marek Michalkiewicz]\n\n - The new upscode2 driver supports Fiskars, Compaq and Powerware\n   devices.\n   [Niels Baggesen, Havard Lygre]\n\n - The tripplite driver has fixed a battery charge bug\n   [Cedric Tefft]\n\n\nRelease notes for NUT 2.0.1 - what's new since 2.0.0\n----------------------------------------------------\n\n - The bestuferrups driver has been forked into the new bestfcom driver\n   which has better handling of the inverter status alarm messages and\n   more.\n   [Kent Hill]\n\n - Mustek UPS support returns with two drivers which have overlapping\n   coverage: mustek and powermust.\n   [powermust: Carlos Rodrigues, mustek: Martin Hajduch]\n\n - Additional CyberPower Systems hardware is supported with the new\n   cpsups driver.  Three recognized models are the CPS1500AVR,\n   CPS1100VA, and OP500TE.\n   [Walt Holman, Brad Sawatzky]\n\n - The genericups driver can now generate staleness warnings in\n   specific cases where the UPS provides a way to test for its\n   presence.  See the \"CON\" setting in ups.conf for more details.\n   [stan / saticed.me.uk]\n\n - Documentation for monitoring a Back-UPS RS 500 on a system without\n   USB ports has been added to the cables directory.\n   [Martin Edlman]\n\n - The everups driver now supports types 73-76 (NET 700/1000/1400/500-DPC)\n   [hunter]\n\n - The new metasys driver supports Meta System models: Line,\n   HF Millennium, HF Top Line, ECO Network, ECO, Ally HF, Megaline\n   [BlaXwan]\n\n - The ippon driver now allows user-defined settings for the delay\n   before switching off, and the delay before powering on.\n   [Yuri Elizarov]\n\n - The victronups driver is now at version 0.1.9, which adds many\n   instant commands: calibration control, battery and front panel tests,\n   and bypass control.\n   [Gert Lynge]\n\n - The tripplite driver has received a major overhaul to bring it up to\n   working condition for the 2.0 tree, including code cleanups, several\n   new variables, commands, and user-definable parameters.  See\n   ChangeLog for more.\n   [Nicholas J Kain]\n\n - The mge-utalk driver has been upgraded to version 0.81, which fixes\n   the lack of read-write variables and loss of sync on models which\n   don't support restoring settings.\n   [Arnaud Quette]\n\n - The Micro Ferrups model RE is now supported by the bestuferrups\n   driver.  The driver will also now read the ambient temperature and\n   will no longer constantly report the data as stale.\n   [Tim Thompson]\n\n - The fentonups driver's init sequence has been reworked to work better\n   with some hardware, including a fix to the parser code.\n   [MLH]\n\n - A workaround has been added to the hidups driver to avoid variables\n   which are stuck by calling HIDIOCINITREPORT in every poll.\n   [Stuart D. Gathman]\n\n - SOLA 610 UPS hardware and others which do not support the ID command\n   may now be monitored by the bestups driver after forcing ID= in\n   ups.conf.\n   [Jason White]\n\n - \"pollinterval\" is now available via driver.parameter for consistency.\n   [Arnaud Quette]\n\n - The mge-shut and newhidups drivers, along with the supporting\n   hidparser/libhid code have received many updates, including lowering\n   USB bandwidth consumption, driver unbinding (only in Linux), code\n   cleanups, and more which can be seen in the ChangeLog file.\n   [Arnaud Quette]\n\n - The fentonups driver now recognizes several more Megatec protocol\n   units:\n   * SuperPower HP360, Hope-550\t[Denis Zaika]\n   * Unitek Alpha 1000is\t[Antoine Cuvellard]\n\n - Some variables like uc_sigmask were renamed to avoid clashes with\n   symbols on systems like HP/UX.\n\n - All man pages have been reworked to switch literal \"-\" characters to\n   hyphens or \"\\-\" as appropriate.\n   [Shaul Karl]\n\n - upssched's CANCEL events were broken following the change to\n   text-based socket messages in 1.5 and have been fixed.\n   [Steven Schoch]\n\n - Calls to varargs functions with raw strings from the config files\n   without an intervening \"%s\" have been fixed in upsmon, upssched,\n   snmp-ups and upsd.\n   [Ulf Harnhammar]\n\n\nRelease notes for NUT 2.0.0 - what's new since 1.4.x\n----------------------------------------------------\n\n - The new naming scheme for variables and commands (introduced in 1.4)\n   is now mandatory.  The 1.4 tree supported both the old (STATUS) and\n   the new (ups.status) as a transitional release, and now that time is\n   over.\n   +\n   +\n   This means that 2.0 is generally smaller than 1.4 code, since the\n   interim compatibility hacks have been removed.\n\n - New serial handling code has been added, with greatly simplified\n   operations.  The old mess involving repeated calls to sigaction,\n   alarm, and read has been condensed to a select-read loop.\n   +\n   +\n   This change allows drivers which don't do any serial communications\n   at all (hidups, snmp-ups) to drop that baggage, so they are a bit\n   smaller when compiled.\n\n - The drivers now recognize \"chroot=' and 'user=' in the global section\n   of ups.conf.  This means you don't have to use -r and -u when\n   starting upsdrvctl.\n\n - upsmon now supports the -K argument to check for the presence of the\n   POWERDOWNFLAG file.  If it exists and contains the magic string, then\n   upsmon will exit(EXIT_SUCCESS).  Otherwise, it will\n   exit(EXIT_FAILURE).\n   +\n   +\n   This feature can be used to simplify shutdown scripts, since now you\n   don't have to keep the script in sync with the upsmon.conf.\n\n - Many small things like signed value comparisons, int vs. size_t and\n   proper use of const/struct were fixed throughout the source.  These\n   were mostly for correctness, but a few potential bugs involving very\n   big or very small numbers were fixed at the same time.\n\n - The access control system in upsd.conf has been reworked and\n   simplified.  Since access levels have become meaningless in recent\n   releases, the new system is just ACCEPT <acl> or REJECT <acl>.\n   +\n   +\n   If you are upgrading from a previous version of the software, you\n   will have to edit your upsd.conf to use this method.  See\n   the link:UPGRADING.adoc[] file for more details.\n\n - The build process now halts when make fails in one of the\n   subdirectories.\n   [Petter Reinholdtsen, Charles Lepple]\n\n - Helper data for using upsclient via pkgconfig is now created if\n   pkgconfig is detected when configure runs.\n   [Arnaud Quette]\n\n - The polling interval in drivers may now be set with 'pollinterval'\n   in ups.conf.\n   [Gabriel Faber]\n\n - Blazer UPS equipment is now supported with the blazer driver.\n   [Phil Hutton]\n\n - Energizer USB UPS hardware is now supported on Linux with a new\n   experimental driver.\n   [Viktor T. Toth]\n\n - The newhidups driver has been merged as the first step towards\n   portable USB UPS support.  This will eventually replace the old\n   Linux-only hidups driver.  The newhidups driver is tagged\n   experimental since it is under active development.\n   [Arnaud Quette, Charles Lepple]\n\n - The newapc driver has been renamed to apcsmart, replacing the old\n   driver with that name. If you used the newapc driver, be sure to\n   delete the old binary and fix your ups.conf.\n\n - The apcsmart driver now supports asynchronous notification data\n   from the hardware, which means it can wake up as soon as something\n   happens.  This affects the OL/OB/LB/RB data in ups.status, and\n   generally reduces the latency in dispatching status changes by a few\n   seconds.\n\n - The apcsmart driver can now support quirky hardware which does not\n   provide the usual listing of valid command characters.  This feature\n   is necessary to monitor new models like the APC CS 350 and old ones\n   like the Matrix 5000.  It also now has sdtype=4 to handle the strange\n   shutdown behavior on the CS series.\n\n - The belkin driver now works around broken firmware version 001,\n   avoiding a lengthy delay at startup.  It also implements the shutdown\n   sequence differently, and should actually work on more hardware now.\n\n - The bestups driver has been slowed down to play nicer with the\n   hardware, and is much more reliable as a result.  Among other things,\n   it should always detect the UPS on the first try, meaning no more\n   \"dot dot dot\" when it starts.\n\n - The cyberpower driver is no longer tagged experimental, and now\n   supports powering off the load.  It also supports battery tests via\n   instcmds.\n\n - Effekta MT 2000 RM hardware is now supported by the fentonups driver.\n   [Christoph Moar]\n\n - The new safenet driver supports UPS hardware that uses the protocol\n   of the same name.  This includes models from many manufacturers,\n   including Fairstone, Fenton, Gemini, Powerwell, Repotec, Soltec and\n   Sweex.  See the README or driver.list for the full details.\n   [Arjen de Korte]\n\n - The genericups driver now has type 20 to monitor the Powerware 5119\n   RM.  See http://lists.exploits.org/ups/Oct2003/00052.html.\n   [Daniel Thompson]\n\n - The belkinunv driver has been added to allow monitoring Belkin\n   Universal UPS hardware.\n   [Peter Selinger]\n\n - Cyber Power Systems 1100AVR hardware which has a different protocol\n   than the existing binary type (supported by 'cyberpower') is now\n   supported by the experimental cyberpower1100 driver.\n   [Walt Holman]\n\n - upsdrvctl now returns success or failure information in the exit\n   code.  Any failure during a requested operation will result in a\n   nonzero value (specifically EXIT_FAILURE).\n\n\nRelease notes for NUT 1.4.0 - what's new since 1.2.x\n----------------------------------------------------\n\n - The drivers and upsd now communicate over Unix domain sockets instead\n   of state files, shared memory, or state files with mmap.  This change\n   makes many things possible, including the new dynamic variable and\n   command naming scheme described below.\n   +\n   +\n   There is a new development tool called sockdebug in the server\n   directory for debugging driver-server communications on the sockets.\n\n - The old static variable scheme has been replaced by a new dynamic\n   implementation.  Vague names have been turned into meaningful names\n   that fit into an organized system.  UTILITY is now input.voltage.\n   OUTVOLT is now output.voltage.\n   +\n   +\n   This also applies to the names of instant commands.  BTEST1 is\n   test.battery.start, and BTEST0 is test.battery.stop.\n   +\n   +\n   The old names are still supported for compatibility with older\n   clients.  This compatibility mode will be maintained throughout\n   the 1.4 series, and will be gone by the release of 2.0.  Users\n   with older clients are encouraged to upgrade their software\n   during this time.\n\n - The network protocol has been expanded to handle these new names.\n   Older functions which only apply to the old names will continue to\n   be supported through the 1.4 series.\n\n - The drivers and server (upsd) can now change their user ids and\n   chroot themselves with the new -u and -r arguments.  This lets you\n   create a \"chroot jail\" with the bare minimum components.\n   +\n   +\n   This technique is used to provide a higher degree of security.  If\n   someone exploited upsd to get a shell somehow, they would be stuck\n   in the jail.\n\n - upssched now explicitly confirms reception of timer commands before\n   exiting.  This was done to avoid a race where one process would\n   exit right when another one was starting.  The second one would\n   believe its command had been handled when it had been lost.\n\n - upslog has been reworked to use standard getopt parsing to provide\n   the monitoring settings.  The old way of specifying arguments is\n   still supported for backwards compatibility.\n   +\n   +\n   upslog has also been changed to only parse the format string once,\n   rather than doing it every time through the loop.  This should\n   provide a minuscule drop in CPU utilization.\n\n - Usernames are now required in upsmon and upsd.  This means that you\n   must add a username to your MONITOR lines in upsmon.conf and then\n   create a matching user in upsd.users.\n   +\n   +\n   Installations from the 1.2 era probably already used usernames, so\n   this mostly affects those from 1.0 and before.\n\n - Drivers are now pinged regularly by upsd when they aren't posting\n   updates about the UPS status.  This provides another check in the\n   data validation process.  If upsd fails to get a response within\n   a few seconds, the UPS will be marked stale.\n\n - A few minor memory leaks were discovered with valgrind and squashed.\n\n - upsstats now reuses connections to upsd when cycling through multiple\n   entries in the hosts.conf.  This makes things a bit faster and\n   avoids some of the noise in the syslog.\n   +\n   +\n   This only applies to entries that are adjacent.  To take advantage\n   of this feature, you may have to rearrange them per example below.\n   +\n   +\n   Connection reuse for nonadjacent entries may be considered in the\n   future.\n----\n\tMONITOR ups-1@host-1 ...\n\tMONITOR ups-1@host-2 ...\n\tMONITOR ups-2@host-2 ...\n\tMONITOR ups-3@host-3 ...\n----\n\n - upsd now warns about insecure configuration files at startup.\n   These files (upsd.conf, upsd.users, and the certfile) should\n   only be readable by upsd.  Never make them world-readable.\n\n - The programs no longer print \"shutting down\" when they are just\n   exiting.  This was changed to avoid confusion about the term, since\n   \"shutting down\" has a special meaning in UPS software.\n\n - Signal handlers no longer do any significant amount of work.  Some of\n   the programs used to do numerous things in there, raising concerns\n   about reentrancy.  They now set flags and allow the main loop to do\n   the actual work from there.\n\n - A bug in upsmon where NOTIFYFLAG settings could be ignored was fixed.\n\n - Group handling has been changed.  configure no longer accepts\n   --with-group, and the programs no longer setgid() to a hardcoded\n   value.  They now setgid() to the primary group of whatever the\n   user value may be.\n   +\n   +\n   This may be compiled in with --with-user as before, and many programs\n   accept -u to override it at runtime.\n\n - The state path is no longer created during 'make install'.  Users\n   are now expected to create it themselves.  This removes a lot of\n   evil complexity from the build and install sequences.\n\n - upsd no longer implements the DROP access command, as it\n   could confuse the clients by getting them out of sync.  DROP is now\n   implemented as DENY, which sends an error message.  If you use DROP,\n   you should change it to DENY rather than relying on this\n   compatibility measure.\n\n - The belkin driver no longer reports OFF and OL at the same time.\n\n - The bestups driver no longer sleeps during polls, which makes it\n   more responsive to things like instant commands.\n\n - The cyberpower driver now has much better hardware detection code\n   and no longer freezes at startup under some conditions.  It also now\n   supports the shutdown function.  Instant commands for shutdowns and\n   battery tests were also added.\n\n - The dummyups testing driver has been removed.  The dummycons testing\n   driver can do everything that dummyups once did and much more.\n   dummycons is also now built by default for easier testing.\n\n - The newapc driver has been reworked to take advantage of the new\n   internal driver state functions.  Some variables without an obvious\n   purpose were dropped.\n\n - The newapc driver now sends all five bytes when using sdtype 1.\n   Previously it didn't send the entire string, and it didn't work.\n   [Don Lewis]\n\n - The hidups driver has been expanded to allow for setting variables,\n   a shutdown sequence, and more.\n   [Arnaud Quette]\n\n - The mge-utalk driver had trouble establishing communications in\n   some cases due to the RTS line being set.  This has been fixed.\n   +\n   +\n   The mge-shut driver has been added to the tree, and has replaced\n   the older mge-ellipse driver.\n   [Arnaud Quette, Philippe Marzouk]\n\n - Outlet-level control has been defined in the variable tree, and will\n   be added to drivers where the hardware supports it.  This can be\n   used to shut down some components earlier than others to prolong\n   your runtime on battery.\n   +\n   +\n   This is supported in the mge-shut driver now, and may show up in\n   others before long.\n   [Arnaud Quette]\n\n - KIN-2200AP hardware is now recognized by the powercom driver.\n   This change may also support other KIN-xxxxAP equipment.\n   [Preston A. Elder]\n\n - The 1.1kVA UPS is now supported by the bestuferrups driver.  This\n   driver was also changed to allow easy addition of more models\n   in the future.\n   [Bob Apodaca]\n\n - The fentonups driver can now handle devices which implement the\n   \"I\" detection differently, and now supports the Giant/WELI 500\n   as a result.\n   [Joon Guillen]\n\n - The serial number of the UPS being monitored can now be specified\n   with serial= in ups.conf in the genericups driver.\n   [Shaul Karl]\n\n - The newapc driver now sends ESC to break out of menus when the\n   initial detection fails.  Some new APC models have interactive menus\n   on the serial port, and the driver couldn't handle them before.\n\n - The snmp-ups driver now reports ambient temperature and humidity\n   data for APC equipment.  It also now supports the shutdown.reboot and\n   shutdown.reboot.graceful commands.\n   [Dmitry Frolov]\n\n - The list of supported variables and commands in the snmp-ups driver\n   has been expanded.\n   [Arnaud Quette, J.W. Hoogervorst]\n\n - Various drivers now report bypass mode with the BYP status word.\n   [Arnaud Quette]\n\n - Energy Sistem equipment is now supported with the esupssmart driver.\n   [Antonio Trujillo Coronado]\n\n - The Tripp-Lite SU series (SmartOnline) is supported with the new\n   tripplitesu driver.\n   [Allan Hessenflow]\n\n - The HP PowerTrust A2994A is now recognized by the hp driver.\n   [Jan Sporbeck]\n\n - Many drivers were cleaned up to perform basic sanity checks on the\n   status data before using it.\n\n - An explicit cleanup function has been added to the driver core to\n   ensure that all dynamic resources are freed before exiting.  This\n   is part of the larger process to check for memory leaks and other\n   bad things.\n   [Arnaud Quette]\n\n - upsd now provides variable descriptions from an auxiliary file.\n   This file is optional, which allows for a smaller memory footprint.\n   It can also be edited for localization or other customizations.\n\n - upsimage and upsstats can now render BATTVOLT data.\n   [Andrew R. Ghali]\n\n - String handling has been cleaned up throughout the tree.  Calls to\n   functions like strcpy and strcat were either replaced with other\n   (range-checking) functions or were rewritten to avoid it.\n\n - Many compile-time defaults may now be overridden at runtime.  In\n   the environment NUT_CONFPATH and NUT_STATEPATH may be used.\n   upsdrvctl has been changed to execve to pass these along to the\n   drivers.  ups.conf now supports driverpath=, and upsd.conf supports\n   DATAPATH.\n   [Bryan Henderson]\n\n - The configure --with-gd switches now actually do something useful\n   when gd has been installed outside the default search directories.\n   [Patrik Schindler]\n\n - The inline keyword is now handled properly on systems which do not\n   support it or have it specified as another name.  This was breaking\n   compiles on some systems.\n   [Petter Reinholdtsen]\n\n\nRelease notes for NUT 1.2.2 - what's new since 1.2.1\n----------------------------------------------------\n\n - The snmp-ups driver has been upgraded and expanded.  It now supports\n   multiple MIBs, meaning it can handle RFC 1628, APCC, and MGE\n   equipment.  You can pick the right one with \"mibs=\" in ups.conf.\n   +\n   +\n   Support for setting variable and instant commands is also available.\n   [Arnaud Quette and Dmitry Frolov]\n\n - The powernet driver has been upgraded.  It now supports more\n   variables, has cleaner logging, and may now be considered stable.\n   [Dmitry Frolov]\n\n - The hidups driver now supports physical port IDs.  This avoids most\n   of the problems where the hiddev* names can jump around too easily.\n   It will now stay in the same place as long as you keep it plugged\n   into the same physical port.  See the ChangeLog file for more details.\n   [David Brownell]\n\n - The hidups driver now also supports the MFR variable on APC\n   Back-UPS ES equipment.\n   [Jonathan A. Davis]\n\n - The sms driver has been updated to version 0.70.\n   [Marcio Gomes]\n\n - The bestups driver now recognizes Best Power Axxium Rackmount\n   equipment.\n   [Ales Casar]\n\n - The liebert driver now uses O_NONBLOCK, and should now work\n   consistently on OpenBSD as a result.\n   [Alex Cichowski]\n\n - The liebert driver also now uses debouncing logic on the status\n   lines.  It was possible to get false readings that would start a\n   shutdown or just annoy users with excessive onbatt/online notify\n   messages.  The new code forces the status to settle down for 3 polls\n   before accepting the new value.\n   +\n   +\n   This means that very short power events may not be detected.  The\n   alternative is having your machine shut down just because it decided\n   to wiggle over to OB LB for a few seconds.\n\n - upsmon has had the disconnect logic fixed so the \"communications\n   lost\" (COMMBAD) notify will actually go out when the connection\n   fails.\n   [Steve Monett]\n\n - upssched now uses a lock file to prevent a race where two could\n   start at the same time.  The second upssched would \"win\", and the\n   first one would be unreachable.  This had the side-effect of not\n   being able to cancel timers on the first one.\n   +\n   +\n   If you use upssched, you must define the LOCKFN directive when\n   upgrading to this version, or it will not work.\n   [Gaspar Bakos]\n\n - The packaging and scripts for Red Hat systems have been updated.\n   [Antonino Albanese]\n\n - upsd is now a bit more lenient about access levels in the\n   'numlogins' check, which is what caused the problem in upsmon\n   (next item).\n\n - upsmon no longer gets stuck in slavesync() when upsd is configured\n   to drop certain queries.  This usually happened at the worst\n   possible time: in the middle of a shutdown.\n   [John David Garza]\n\n - The upsclient functions now do more sanity checking on data from\n   upsd so a short read won't return garbage to the callers.\n\n - upsset now works properly with ENUM/VARTYPE values for multiple\n   UPSes on a single upsd.\n   [Dmitry Frolov]\n\n - Various portability fixes for building on SGI were applied.\n   [Andrea Suatoni]\n\n - upsd no longer tries to reference a deleted client structure if the\n   client disconnects at the wrong time.  Previously, it tried to use\n   that pointer after the sendback() function had already failed on\n   write and deleted the client.  This could cause upsd to segfault\n   depending on what areas were accessed.\n   [Patrik Schindler]\n\n\nRelease notes for NUT 1.2.1 - what's new since 1.2.0\n----------------------------------------------------\n\n - The sms driver is back, with support for Microlink Manager III\n   hardware. [Marcio Gomes]\n\n - Fideltronik Ares Series hardware is now supported as genericups\n   type 19.  [Tomek Orzechowski and Arkadiusz Mikiewicz]\n\n - The drivers no longer silently drop instant commands or set commands\n   from upsd that happen to get fragmented in transit.\n   [linux@horizon.com]\n\n - The old multilink driver is back with a new name: liebert.  It\n   supports Liebert UPStation GXE hardware with the contact-closure\n   cable.  This is currently an experimental driver as there is no\n   way to power down the load.\n\n - configure now picks up the right flags for gd automatically if gd\n   2.0.8 or higher is installed.  This greatly simplifies the CGI build\n   process for most users.\n\n - Shutdowns on FreeBSD using the genericups driver should work again.\n   [Petri Riihikallio]\n\n\nHistoric releases\n-----------------\n\nMore ancient history is not covered in detail here.\n\nYou can see link:docs/history.txt[] for more details.\n"
        },
        {
          "name": "README.adoc",
          "type": "blob",
          "size": 33.2744140625,
          "content": "Network UPS Tools Overview\n==========================\n// NOTE: No blank line here, document-header include processing should kick in!\n//GH_MARKUP_1095//ifdef::top_srcdir[]\n//GH_MARKUP_1095//include::{top_srcdir}docs/asciidoc-vars.conf[]\n//GH_MARKUP_1095//endif::top_srcdir[]\n//GH_MARKUP_1095//ifndef::top_srcdir[]\n//GH_MARKUP_1095//include::docs/asciidoc-vars.conf[]\n//GH_MARKUP_1095//endif::top_srcdir[]\n//GH_MARKUP_1095_INCLUDE_BEGIN//7e01bd198 (2024-10-20) docs/asciidoc-vars.conf: try defining linksrcdoc macro\nifndef::asciidoc-vars-nut-included[]\n:asciidoc-vars-nut-included:\ttrue\n// NOTE: The big block of comments and definitions below comes from\n// NUT::docs/asciidoc-vars.conf and is included into top-level document\n// sources by maintenance recipes directly (`make maintainer-asciidocs`),\n// due to current limitations of the GitHub Web UI asciidoc renderer.\n// Hopefully it can be dropped in favor of compact include definitions\n// (see README.adoc for anticipated example) after this issue is resolved\n// on their side:\n// * https://github.com/github/markup/issues/1095\n//\n// This file should be included into NUT documentation sources to consistently\n// define certain expandable attributes, with contents defined based on the\n// rendition target (e.g. GitHub Web UI, plain text, locally built HTML/PDF...)\n// Note that currently GitHub Web UI references lead to nut-website (as of\n// last built and published revision), not to neighboring documents in the\n// source browser (which would make sense for branch revisions, etc.) due\n// to certain complexity about referencing other-document sections with a\n// partially functional rendering engine there. Exploration and fixes are\n// welcome (actually working links like\n// https://github.com/networkupstools/nut/tree/master#installing or\n// https://github.com/networkupstools/nut/blob/master/UPGRADING.adoc#changes-from-274-to-280\n// do seem promising)!\n//\n// Since the GitHub UI does not allow use of custom asciidoc configuration\n// files, or generally does not process the `include:` requests at this time,\n// clumsy expandable attributes had to be used (usually a set including a\n// prefix with meaningful name, and one or more separators and/or a suffix\n// with shortened names). For our classic documentation renditions, they\n// should resolve to properly defined macros from `docs/asciidoc.conf`\n// (usually named same as the variables defined here, for simplicity):\n// * `linksrcdoc` allows to refer to a source of documentation file\n//   relative to the root of NUT code base.\n// * `linkdoc` allows to refer to a file under `docs/` directory (or\n//   its nut-website rendition).\n// * `xref` substitutes the asciidoc shorthand '<< >>' syntax with\n//   attributes that conditionally expand to:\n//   - links on GitHub (references can point at most to a section of\n//     level docs/common.xsl's <chunk.section.depth>), or\n//   - xref asciidoc macros when generating docs.\n// * `linksingledoc` guarantees that, when chunked HTML is generated,\n//   the link always points to a non-chunked file.\n// * `linkman2` allows to support different names for the manpage and\n//   the command shown. This is also needed to properly display links\n//   to manpages in both GitHub and generated docs without defining an\n//   attribute for each manpage.\n//\n// Optional attributes set by callers:\n// * `website-url` (defaulted below) may be used for \"historic website\"\n//   snapshot builds... hopefully\n// * `website` is used as a boolean toggle in our recipes for nut-website\n//   vs. offline documentation renditions\n// * `env-github` is used as a boolean toggle, set by GitHub Web-UI renderer\n// * `(top_)srcdir` and `(top_)builddir` can be set by `Makefile.am`\n//   calling the `a2x` tool, since some of the files with the asciidoc\n//   mark-up are only generated or post-processed during build and\n//   (due to `make dist` restrictions) being build products, they may\n//   not reside in same directory as static source text files which\n//   reference or include them. Note that the non-`top` paths would\n//   normally differ based on location of the `Makefile` involved\n//   (e.g. workspace root, or the `docs`, or `docs/man` directories).\n//   These variables are expected to be absolute paths, or ones relative\n//   to asciidoc-selected `:base_dir`, and to end with a relevant path\n//   separator, or be empty -- so in all cases letting the resulting\n//   string resolve meaningfully in the filesystem during docs build.\n//\n// Please keep the remaining comments and definitions as one big block\n// so it does not become a series of empty paragraphs in the rendered\n// documents!\n//\nifndef::website-url[]\n:website-url:\thttps://www.networkupstools.org/\nendif::website-url[]\n//\nifndef::srcdir[]\n:srcdir:\nendif::srcdir[]\n//\nifndef::builddir[]\n:builddir:\nendif::builddir[]\n//\nifndef::top_srcdir[]\n:top_srcdir:\nendif::top_srcdir[]\n//\nifndef::top_builddir[]\n:top_builddir:\nendif::top_builddir[]\n//\n//\n// Address links on GitHub vs. docs\n// (note: 'env-github' attribute is set on GitHub)\n//\n// - when generating docs:\nifndef::env-github[]\n//   * xref -> xref\n//     syntax: {xref}<id>{x-s}[<caption>]\n//     -> xref:<id>[<caption>]\n:xref:\t\txref:\n:x-s:\n//   * link to doc -> our macro\n//     syntax: {linksrcdoc}<document>\n//     -> linksrcdoc:<document>[]\n:linksrcdoc:\tlinksrcdoc:\n//   * link to doc -> our macro\n//     syntax: {linkdoc}<document>{ld-s}[<display title>]\n//     -> linkdoc:<document>[<display title>]\n:linkdoc:\tlinkdoc:\n:ld-s:\n//   * link to single doc -> our macro\n//     syntax: {linksingledoc}<document>{lsd-s}[<display title>]\n//     -> linksingledoc:<document>[<display title>]\n:linksingledoc:\tlinksingledoc:\n:lsd-s:\n//   * link to manpage -> our macro\n//     syntax: {linkman2}<command-page>{lm-s}<displayed-command>{lm-c}<manpage-section>{lm-e}\n//     -> linkman2:<command-page>[<displayed-command>,<manpage-section>]\n:linkman2:\tlinkman2:\n:lm-s:\t\t[\n:lm-c:\t\t,\n:lm-e:\t\t]\nendif::env-github[]\n//\n// - on GitHub:\nifdef::env-github[]\n//     In our normal builds, Makefile variables convey the needed paths\n//     (used relatively below as `image:images/ci/...png` etc.)\n:imagesdir:\tdocs\n//   * xref -> link\n//     syntax: {xref}<id>{x-s}[<caption>]\n//     In order for it to work, <id> can reference at most a section of\n//     level docs/common.xsl's <chunk.section.depth>\n//     -> {website-url}docs/user-manual.chunked/<id>.html[<caption>]\n:xref:\t\t{website-url}docs/user-manual.chunked/\n:x-s:\t\t.html\n//   * link to doc -> our macro\n//     syntax: {linksrcdoc}<document>\n//     -> link:<document>[]\n:linksrcdoc:\tlink:{top_srcdir}/\n//   * link to doc -> link\n//     syntax: {linkdoc}<document>{ld-s}[<display title>]\n//     -> {website-url}docs/<document>.chunked/index.html[<display title>]\n:linkdoc:\t{website-url}docs/\n:ld-s:\t\t.chunked/index.html\n//   * link to single doc -> link\n//     syntax: {linksingledoc}<document>{lsd-s}[<display title>]\n//     -> {website-url}docs/<document>.html[<display title>]\n:linksingledoc:\t{website-url}docs/\n:lsd-s:\t\t.html\n//   * link to manpage -> link\n//     syntax: {linkman2}<command-page>{lm-s}<displayed-command>{lm-c}<manpage-section>{lm-e}\n//     All the fields are mandatory.\n//     -> {website-url}docs/man/<command-page>.html[<displayed-command>(<manpage-section>)]\n:linkman2:\t{website-url}docs/man/\n:lm-s:\t\t.html[\n:lm-c:\t\t(\n:lm-e:\t\t)]\nendif::env-github[]\nendif::asciidoc-vars-nut-included[]\n//\n//GH_MARKUP_1095_INCLUDE_END//\n\n\nDescription\n-----------\n\nNetwork UPS Tools is a collection of programs which provide a common\ninterface for monitoring and administering UPS, PDU and SCD hardware.\nIt uses a layered approach to connect all of the parts.\n\nDrivers are provided for a wide assortment of equipment.  They\nunderstand the specific language of each device and map it back to a\ncompatibility layer.  This means both an expensive high end UPS, a simple\n\"power strip\" PDU, or any other power device can be handled transparently\nwith a uniform management interface.\n\nThis information is cached by the network server `upsd`, which then\nanswers queries from the clients.  upsd contains a number of access\ncontrol features to limit the abilities of the clients.  Only authorized\nhosts may monitor or control your hardware if you wish.  Since the\nnotion of monitoring over the network is built into the software, you\ncan hang many systems off one large UPS, and they will all shut down\ntogether. You can also use NUT to power on, off or cycle your data center\nnodes, individually or globally through PDU outlets.\n\nClients such as `upsmon` check on the status of the hardware and do things\nwhen necessary.  The most important task is shutting down the operating\nsystem cleanly before the UPS runs out of power.  Other programs are\nalso provided to log information regularly, monitor status through your\nweb browser, and more.\n\n\nNUT and the ecosystem\n---------------------\n\nNUT comes pre-packaged for many operating systems and embedded in storage,\nautomation or virtualization appliances, and is also often shipped as the\nsoftware companion by several UPS vendors. Of course, it is quite normal\nand supported to build your own -- whether for an operating system which\nlacks it yet, or for an older distribution which lacks the current NUT\nversion; whether to take advantage of new features or to troubleshoot a\nnew UPS deployment with a debugger in hand.\n\nGiven its core position at the heart of your systems' lifecycle, we make\nit a point to have current NUT building and running anywhere, especially\nwhere older releases did work before (including \"abandonware\" like the\nservers and OSes from the turn of millennium): if those boxes are still\nalive and in need of power protection, they should be able to get it.\n\n[TIP]\n=====\nIf you like how the NUT project helps protect your systems from power\noutages, please consider sponsoring or at least \"starring\" it on GitHub at\nhttps://github.com/networkupstools/nut/ - these stars are among metrics\nwhich the larger potential sponsors consider when choosing how to help\nFOSS projects. Keeping the lights shining in such a large non-regression\nbuild matrix is a big undertaking!\n\nifndef::pdf_format[]\nimage:https://api.star-history.com/svg?repos=networkupstools/nut&type=Date[link=\"https://star-history.com/#networkupstools/nut&Date\" alt=\"NUT GitHub Star History Chart\"]\nendif::pdf_format[]\n\nSee <<acknowledgements-ci-ops,acknowledgements of organizations which help\nwith NUT CI and other daily operations>> for an overview of the shared effort.\n=====\n\nAs a FOSS project, for over a quarter of a century we welcome contributions\nof both core code (drivers and other features), build recipes and other\nintegration elements to make it work on your favourite system, documentation\nrevisions to make it more accessible to newcomers, as well as hardware vendor\ncooperation with first-hand driver and protocol submissions, and just about\nanything else you can think of.\n\n\nInstalling\n----------\n\nIf you are installing these programs for the first time, go read the\n{xref}_installation_instructions{x-s}[installation instructions]\nto find out how to do that.  This document contains more information\non what all of this stuff does.\n\n\nUpgrading\n---------\n\nWhen upgrading from an older version, always check the\n{xref}Upgrading_notes{x-s}[upgrading notes] to see what may have\nchanged.  Compatibility issues and other changes will be listed there\nto ease the process.\n\n\nConfiguring and using\n---------------------\n\nOnce NUT is installed, refer to the\n{xref}Configuration_notes{x-s}[configuration notes] for directions.\n\n\nDocumentation\n-------------\n\nThis is just an overview of the software.  You should read the man pages,\nincluded example configuration files, and auxiliary documentation for the\nparts that you intend to use.\n\n\nNetwork Information\n-------------------\n\nThese programs are designed to share information over the network.  In\nthe examples below, `localhost` is used as the hostname.  This can also\nbe an IP address or a fully qualified domain name.  You can specify a\nport number if your upsd process runs on another port.\n\nIn the case of the program `upsc`, to view the variables on the UPS called\nsparky on the `upsd` server running on the local machine, you'd do this:\n\n\t/usr/local/ups/bin/upsc sparky@localhost\n\nThe default port number is 3493.  You can change this with\n\"configure --with-port\" at compile-time.  To make a client talk to upsd\non a specific port, add it after the hostname with a colon, like this:\n\n\t/usr/local/ups/bin/upsc sparky@localhost:1234\n\nThis is handy when you have a mixed environment and some of the systems\nare on different ports.\n\nThe general form for UPS identifiers is this:\n\n\t<upsname>[@<hostname>[:<port>]]\n\nKeep this in mind when viewing the examples below.\n\n\nManifest\n--------\n\nThis package is broken down into several categories:\n\n- *drivers*\t- These programs talk directly to your UPS hardware.\n- *server*\t- upsd serves data from the drivers to the network.\n- *clients*\t- They talk to upsd and do things with the status data.\n- *cgi-bin*\t- Special class of clients that you can use with your web server.\n- *scripts*\t- Contains various scripts, like the Perl and Python binding,\nintegration bits and applications.\n\nDrivers\n-------\n\nThese programs provide support for specific UPS models.  They understand\nthe protocols and port specifications which define status information\nand convert it to a form that upsd can understand.\n\nTo configure drivers, edit ups.conf.  For this example, we'll have a UPS\ncalled \"sparky\" that uses the apcsmart driver and is connected to\n`/dev/ttyS1`.  That's the second serial port on most Linux-based systems.\nThe entry in `ups.conf` looks like this:\n\n\t[sparky]\n\t\tdriver = apcsmart\n\t\tport = /dev/ttyS1\n\nTo start and stop drivers, use upsdrvctl of upsdrvsvcctl (installed on\noperating systems with a service management framework supported by NUT).\nBy default, it will start or stop every UPS in the config file:\n\n\t/usr/local/ups/sbin/upsdrvctl start\n\t/usr/local/ups/sbin/upsdrvctl stop\n\nHowever, you can also just start or stop one by adding its name:\n\n\t/usr/local/ups/sbin/upsdrvctl start sparky\n\t/usr/local/ups/sbin/upsdrvctl stop sparky\n\nOn operating systems with a supported service management framework,\nyou might wrap your NUT drivers into individual services instances\nwith:\n\n\t/usr/local/ups/sbin/upsdrvsvcctl resync\n\nand then manage those service instances with commands like:\n\n\t/usr/local/ups/sbin/upsdrvsvcctl start sparky\n\t/usr/local/ups/sbin/upsdrvsvcctl stop sparky\n\nTo find the driver name for your device, refer to the section below\ncalled \"HARDWARE SUPPORT TABLE\".\n\nExtra Settings\n~~~~~~~~~~~~~~\n\nSome drivers may require additional settings to properly communicate\nwith your hardware.  If it doesn't detect your UPS by default, check the\ndriver's man page or help (-h) to see which options are available.\n\nFor example, the usbhid-ups driver allows you to use USB serial numbers to\ndistinguish between units via the \"serial\" configuration option.  To use this\nfeature, just add another line to your ups.conf section for that UPS:\n\n\t[sparky]\n\t\tdriver = usbhid-ups\n\t\tport = auto\n\t\tserial = 1234567890\n\nHardware Compatibility List\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe {xref}HCL{x-s}[Hardware Compatibility List] is available in the source directory\n('nut-X.Y.Z/data/driver.list'), and is generally distributed with packages.\nFor example, it is available on Debian systems as:\n\n\t/usr/share/nut/driver.list\n\nThis table is also available link:{website-url}stable-hcl.html[online].\n\n\nIf your driver has vanished, see the {linksingledoc}FAQ{lsd-s}[FAQ] and\n{xref}Upgrading_notes{x-s}[Upgrading notes].\n\nGeneric Device Drivers\n~~~~~~~~~~~~~~~~~~~~~~\n\nNUT provides several generic drivers that support a variety of very similar\nmodels.\n\n- The `genericups` driver supports many serial models that use the same basic\nprinciple to communicate with the computer.  This is known as \"contact\nclosure\", and basically involves raising or lowering signals to indicate\npower status.\n+\nThis type of UPS tends to be cheaper, and only provides the very simplest\ndata about power and battery status.  Advanced features like battery\ncharge readings and such require a \"smart\" UPS and a driver which\nsupports it.\n+\nSee the {linkman2}genericups{lm-s}genericups{lm-c}8{lm-e} man page for more information.\n\n- The `usbhid-ups` driver attempts to communicate with USB HID Power Device\nClass (PDC) UPSes. These units generally implement the same basic protocol,\nwith minor variations in the exact set of supported attributes. This driver\nalso applies several correction factors when the UPS firmware reports values\nwith incorrect scale factors.\n+\nSee the {linkman2}usbhid-ups{lm-s}usbhid-ups{lm-c}8{lm-e} man page for more information.\n\n- The `nutdrv_qx` driver supports the Megatec / Q1 protocol that is used in\nmany brands (Blazer, Energy Sistem, Fenton Technologies, Mustek, Voltronic\nPower and many others).\n+\nSee the {linkman2}nutdrv_qx{lm-s}nutdrv_qx{lm-c}8{lm-e} man page for more information.\n\n- The `snmp-ups` driver handles various SNMP enabled devices, from many\ndifferent manufacturers. In SNMP terms, `snmp-ups` is a manager, that\nmonitors SNMP agents.\n+\nSee the {linkman2}snmp-ups{lm-s}snmp-ups{lm-c}8{lm-e} man page for more information.\n\n- The `powerman-pdu` is a bridge to the PowerMan daemon, thus handling all\nPowerMan supported devices. The PowerMan project supports several serial\nand networked PDU, along with Blade and IPMI enabled servers.\n+\nSee the {linkman2}powerman-pdu{lm-s}powerman-pdu{lm-c}8{lm-e} man page for more\ninformation.\n\n- The `apcupsd-ups` driver is a bridge to the Apcupsd daemon, thus handling\nall Apcupsd supported devices. The Apcupsd project supports many serial,\nUSB and networked APC UPS.\n+\nSee the {linkman2}apcupsd-ups{lm-s}apcupsd-ups{lm-c}8{lm-e} man page for more information.\n\nUPS Shutdowns\n~~~~~~~~~~~~~\n\nupsdrvctl can also shut down (power down) all of your UPS hardware.\n\nWARNING: if you play around with this command, expect your filesystems\nto die.  Don't power off your computers unless they're ready for it:\n\n\t/usr/local/ups/sbin/upsdrvctl shutdown\n\t/usr/local/ups/sbin/upsdrvctl shutdown sparky\n\nYou should read the {xref}UPS_shutdown{x-s}[Configuring automatic UPS shutdowns]\nchapter to learn more about when to use this feature.  If called at the wrong\ntime, you may cause data loss by turning off a system with a filesystem\nmounted read-write.\n\nPower distribution unit management\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNUT also provides an advanced support for power distribution units.\n\nYou should read the\n{xref}outlet_management{x-s}[NUT outlets management and PDU notes]\nchapter to learn more about when to use this feature.\n\nNetwork Server\n--------------\n\n`upsd` is responsible for passing data from the drivers to the client\nprograms via the network.  It should be run immediately after `upsdrvctl`\nin your system's startup scripts.\n\n`upsd` should be kept running whenever possible, as it is the only source\nof status information for the monitoring clients like `upsmon`.\n\n\nMonitoring client\n-----------------\n\n`upsmon` provides the essential feature that you expect to find in UPS\nmonitoring software: safe shutdowns when the power fails.\n\nIn the layered scheme of NUT software, it is a client.  It has this\nseparate section in the documentation since it is so important.\n\nYou configure it by telling it about UPSes that you want to monitor in\nupsmon.conf.  Each UPS can be defined as one of two possible types:\na \"primary\" or \"secondary\".\n\nPrimary\n~~~~~~~\n\nThe monitored UPS possibly supplies power to this system running `upsmon`,\nbut more importantly -- this system can manage the UPS (typically, this\ninstance of `upsmon` runs on the same system as the `upsd` and driver(s)):\nit is capable and responsible for shutting it down when the battery is\ndepleted (or in another approach, lingering to deplete it or to tell the\nUPS to reboot its load after too much time has elapsed and this system\nis still alive -- meaning wall power returned at a  \"wrong\" moment).\n\nThe shutdown of this (primary) system itself, as well as eventually an\nUPS shutdown, occurs after any secondary systems ordered to shut down\nfirst have disconnected, or a critical urgency threshold was passed.\n\nIf your UPS is plugged directly into a system's serial or USB port, the\n`upsmon` process on that system should define its relation to that UPS\nas a primary. It may be more complicated for higher-end UPSes with a\nshared network management capability (typically via SNMP) or several\nserial/USB ports that can be used simultaneously, and depends on what\nvendors and drivers implement. Setups with several competing primaries\n(for redundancy) are technically possible, if each one runs its own\nfull stack of NUT, but results can be random (currently NUT does not\nprovide a way to coordinate several entities managing the same device).\n\nFor a typical home user, there's one computer connected to one UPS.\nThat means you would run on the same computer the whole NUT stack --\na suitable driver, `upsd`, and `upsmon` in primary mode.\n\nSecondary\n~~~~~~~~~\n\nThe monitored UPS may supply power to the system running `upsmon` (or\nalternatively, it may be a monitoring station with zero PSUs fed by\nthat UPS), but more importantly, this system can't manage the UPS --\ne.g. shut it down directly (through a locally running NUT driver).\n\nUse this mode when you run multiple computers on the same UPS.\nObviously, only one can be connected to the serial or USB port\non a typical UPS, and that system is the primary. Everything\nelse is a secondary.\n\nFor a typical home user, there's one computer connected to one UPS.\nThat means you run a driver, `upsd`, and `upsmon` in primary mode.\n\nAdditional Information\n~~~~~~~~~~~~~~~~~~~~~~\n\nMore information on configuring upsmon can be found in these places:\n\n- The {linkman2}upsmon{lm-s}upsmon{lm-c}8{lm-e} man page\n- {xref}BigServers{x-s}[Typical setups for big servers]\n- {xref}UPS_shutdown{x-s}[Configuring automatic UPS shutdowns] chapter\n- The stock `upsmon.conf` that comes with the package\n\n\nClients\n-------\n\nClients talk to upsd over the network and do useful things with the data\nfrom the drivers.  There are tools for command line access, and a few\nspecial clients which can be run through your web server as CGI\nprograms.\n\nFor more details on specific programs, refer to their man pages.\n\nupsc\n~~~~\n\n`upsc` is a simple client that will display the values of variables known\nto `upsd` and your UPS drivers.  It will list every variable by default,\nor just one if you specify an additional argument.  This can be useful\nin shell scripts for monitoring something without writing your own\nnetwork code.\n\n`upsc` is a quick way to find out if your driver(s) and upsd are working\ntogether properly.  Just run `upsc <ups>` to see what's going on, i.e.:\n\n\tmorbo:~$ upsc sparky@localhost\n\tambient.humidity: 035.6\n\tambient.humidity.alarm.maximum: NO,NO\n\tambient.humidity.alarm.minimum: NO,NO\n\tambient.temperature: 25.14\n\t...\n\nIf you are interested in writing a simple client that monitors `upsd`,\nthe source code for `upsc` is a good way to learn about using the\nupsclient functions.\n\nSee the {linkman2}upsc{lm-s}upsc{lm-c}8{lm-e} man page and\n{xref}nut-names{x-s}[NUT command and variable naming scheme] for more information.\n\nupslog\n~~~~~~\n\n`upslog` will write status information from `upsd` to a file at set\nintervals.  You can use this to generate graphs or reports with other\nprograms such as `gnuplot`.\n\nupsrw\n~~~~~\n\n`upsrw` allows you to display and change the read/write variables in your\nUPS hardware.  Not all devices or drivers implement this, so this may\nnot have any effect on your system.\n\nA driver that supports read/write variables will give results like this:\n\n\t$ upsrw sparky@localhost\n\n\t( many skipped )\n\n\t[ups.test.interval]\n\tInterval between self tests\n\tType: ENUM\n\tOption: \"1209600\"\n\tOption: \"604800\" SELECTED\n\tOption: \"0\"\n\n\t( more skipped )\n\nOn the other hand, one that doesn't support them won't print anything:\n\n\t$ upsrw fenton@gearbox\n\n\t( nothing )\n\n`upsrw` requires administrator powers to change settings in the hardware.\nRefer to {linkman2}upsd.users{lm-s}upsd.users{lm-c}5{lm-e} for information on defining\nusers in `upsd`.\n\nupscmd\n~~~~~~\n\nSome UPS hardware and drivers support the notion of an instant command -\na feature such as starting a battery test, or powering off the load.\nYou can use upscmd to list or invoke instant commands if your\nhardware/drivers support them.\n\nUse the -l command to list them, like this:\n\n\t$ upscmd -l sparky@localhost\n\tInstant commands supported on UPS [sparky@localhost]:\n\n\tload.on - Turn on the load immediately\n\ttest.panel.start - Start testing the UPS panel\n\tcalibrate.start - Start run time calibration\n\tcalibrate.stop - Stop run time calibration\n\t...\n\n`upscmd` requires administrator powers to start instant commands.\nTo define users and passwords in `upsd`, see\n{linkman2}upsd.users{lm-s}upsd.users{lm-c}5{lm-e}.\n\n\nCGI Programs\n------------\n\nThe CGI programs are clients that run through your web server.  They\nallow you to see UPS status and perform certain administrative commands\nfrom any web browser.  Javascript and cookies are not required.\n\nThese programs are not installed or compiled by default.  To compile\nand install them, first run `configure --with-cgi`, then do `make` and\n`make install`.  If you receive errors about \"gd\" during configure, go\nget it and install it before continuing.\n\nYou can get the source here:\n\n- http://www.libgd.org/\n\nIn the event that you need libpng or zlib in order to compile gd,\nthey can be found at these URLs:\n\n- http://www.libpng.org/pub/png/pngcode.html\n- http://www.zlib.net/\n\n\nAccess Restrictions\n~~~~~~~~~~~~~~~~~~~\n\nThe CGI programs use hosts.conf to see if they are allowed to talk to a\nhost.  This keeps malicious visitors from creating queries from your web\nserver to random hosts on the Internet.\n\nIf you get error messages that say \"Access to that host is not\nauthorized\", you're probably missing an entry in your hosts.conf.\n\nupsstats\n~~~~~~~~\n\n`upsstats` generates web pages from HTML templates, and plugs in status\ninformation in the right places.  It looks like a distant relative of\nAPC's old Powerchute interface.  You can use it to monitor several\nsystems or just focus on one.\n\nIt also can generate IMG references to `upsimage`.\n\nupsimage\n~~~~~~~~\n\nThis is usually called by upsstats via IMG SRC tags to draw either the\nutility or outgoing voltage, battery charge percent, or load percent.\n\nupsset\n~~~~~~\n\n`upsset` provides several useful administration functions through a web\ninterface.  You can use `upsset` to kick off instant commands on your UPS\nhardware like running a battery test.  You can also use it to change\nvariables in your UPS that accept user-specified values.\n\nEssentially, `upsset` provides the functions of `upsrw` and `upscmd`, but\nwith a happy pointy-clicky interface.\n\n`upsset` will not run until you convince it that you have secured your\nsystem.  You *must* secure your CGI path so that random interlopers\ncan't run this program remotely.  See the `upsset.conf` file.  Once you\nhave secured the directory, you can enable this program in that\nconfiguration file.  It is not active by default.\n\n\nVersion Numbering\n-----------------\n\nThe version numbers work like this: if the middle number is odd, it's a\ndevelopment tree, otherwise it is the stable tree.\n\nThe past stable trees were 1.0, 1.2, 1.4, 2.0, 2.2 and 2.4, with the\nlatest such stable tree designated 2.6.  The development trees were 1.1,\n1.3, 1.5, 2.1 and 2.3.  Since the 2.4 release, there is no real separate\ndevelopment branch anymore since the code is available through a revision\ncontrol system (namely, Git -- or actually Subversion back then) and its\nsnapshots become published releases.\n\nSince 2.7 line of releases, sources are tracked in Git revision control\nsystem, with the project ecosystem being hosted on GitHub, and any code\nimprovements or other contributions merged through common pull request\napproach and custom NUT CI testing on multiple platforms.\n\nMajor release jumps are mostly due to large changes to the features\nlist.  There have also been a number of architectural changes which\nmay not be noticeable to most users, but which can impact developers.\n\nBackwards and Forwards Compatibility\n------------------------------------\n\nThe network protocol for the current version of NUT should be\nbackwards-compatible all the way back to version 1.4. A newer client should\nfail gracefully when querying an older server.\n\nIf you need more details about cross-compatibility of older NUT releases\n(1.x vs. 2.x), please see the {xref}Project_History{x-s}[Project history] chapter.\n\nSupport / Help / etc.\n---------------------\n\nIf you are in need of help, refer to the\n{xref}Support_Request{x-s}[Support instructions] in the user manual.\n\n\nHacking / Development Info\n--------------------------\n\nAdditional documentation can be found in:\n\n- the {linkdoc}developer-guide{ld-s}[Developer Guide],\n- the {linkdoc}packager-guide{ld-s}[Packager Guide].\n\n\nAcknowledgements / Contributions\n--------------------------------\n\nThe many people who have participated in creating and improving NUT are\nlisted in the user manual {xref}Acknowledgements{x-s}[acknowledgements appendix].\n\n[[acknowledgements-ci-ops]]\n\nWe would like to highlight some organizations which provide continuous\nsupport to the NUT project (and many other FOSS projects) on technological\nand organizational sides, such as helping keep the donations transparent,\nNUT CI farm afloat, and public resources visible. Thanks for keeping the\nclocks ticking, day and night:\n\n////////////\nFIXME: Use different (better-resolution) images for PDF rendering?\n\nFIXME: PDF cells seem to align weirdly, like setting the bottom of the first\nline of text to be on the same level as bottom of the image, or similar to that.\n\nNOTE: GitHub renderer (or CSS stack?) ignores style settings and squashes the\nlogo column into a fixed-width monster with either our specified heights, or\nwith teeny-tiny thumbnail magnitude images, so it is prettier to leave it as\na \"single-column table\" by default. Grid/Frame settings are also ignored, but\nwe can try our best anyway.\n\nNOTE: The classic asciidoc/a2x renderer seems to not support link/url options,\nbut at least does not complain about them either.\n////////////\n\nifndef::env-github[]\n[frame=\"none\",grid=\"none\",cols=\"^.<1,<.<2\"]\nendif::env-github[]\nifdef::env-github[]\n[frame=\"none\",grid=\"none\",cols=\"<1*\"]\nendif::env-github[]\n|===\n| image:images/ci/GitHub-Mark-140pxW.png[alt=\"GitHub logo\",width=\"140\",height=\"140\",link=\"https://github.com/\"]\n| The link:https://github.com/networkupstools/[\"NetworkUPSTools\" organization\n  on GitHub] arranges a lot of things, including source code hosting for NUT\n  itself and several related projects, team management, projects, issue and\n  pull request discussions, sponsorship, nut-website rendering and hosting,\n  some automated actions, and more...\n\n| image:images/ci/jenkins-nut-transparent-bg-140pxW.png[alt=\"Jenkins and NUT logo\",width=\"139\",height=\"104\",link=\"https://www.jenkins.io/\"]\n| The link:https://www.jenkins.io/[Jenkins CI] project and its huge plugin\n  ecosystem provides the technological foundation for the largest island of\n  the link:https://ci.networkupstools.org/[self-hosted NUT CI farm].\n  There is a fair amount of cross-pollination between the upstream project\n  and community, and the development done originally for the NUT CI farm.\n\n  See more at link:https://stories.jenkins.io/user-story/jenkins-is-the-way-for-networkupstools/[Jenkins\n  is the way to build multi-platform NUT] article.\n\n| image:images/ci/fosshost_org_Host_Light_38px.png[alt=\"Fosshost logo\",width=\"112\",height=\"38\"]\n| Fosshost provided virtual machines where the multi-platform NUT CI farm with\n  a link:https://github.com/networkupstools/jenkins-dynamatrix/[jenkins-dynamatrix]\n  link:https://github.com/networkupstools/nut/blob/master/Jenkinsfile-dynamatrix[setup]\n  runs to arrange builds in numerous operating environments and a lot of toolkit\n  versions and implementations. Some workers running on NUT community members'\n  machines can also dial in to provide an example of their favourite platforms.\n  Literally hundreds of NUT builds run for each iteration, to make sure NUT can\n  always build and work everywhere.\n\n  This allows us to ensure that NUT remains portable across two decades' worth\n  of operating systems, compilers, script interpreters, tools and third-party\n  dependencies.\n\n| image:images/ci/CircleCI_vertical_black_logo.png[alt=\"CircleCI logo\",width=\"130\",height=\"107\",link=\"https://circleci.com/\"]\n| The\n  link:https://app.circleci.com/pipelines/github/networkupstools/nut/[CircleCI\n  NUT pipeline] allows us to test NUT CI builds on MacOS.\n\n| image:images/ci/AppVeyor_logo-ar21.png[alt=\"AppVeyor logo\",width=\"120\",height=\"60\",link=\"https://www.appveyor.com/\"]\n| The link:https://ci.appveyor.com/project/nut-travis/nut/[AppVeyor\n  NUT pipeline] allows us to test NUT CI builds on Windows (and publish\n  preview tarballs with binaries).\n\n| image:images/ci/DO_Powered_by_Badge_blue_140pxW.png[alt=\"DigitalOcean logo\",width=\"140\",height=\"29\",link=\"https://www.digitalocean.com/?refcode=d2fbf2b9e082&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge\"]\n| The link:https://www.digitalocean.com/?refcode=d2fbf2b9e082&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge[DigitalOcean]\n  droplets allow us to host NUT CI farm Jenkins controller and the build agents\n  for multiple operating systems.\n\n| image:images/ci/gandi-ar21.png[alt=\"Gandi.Net logo\",width=\"120\",height=\"60\",link=\"https://www.gandi.net/\"]\n| link:https://www.gandi.net/[Gandi.Net] took up the costs of NUT DNS hosting.\n\n| image:images/ci/OC_logo_merged_140x26.png[alt=\"Open Collective logo\",width=\"140\",height=\"26\",link=\"https://opencollective.com/\"]\n| https://opencollective.com/networkupstools allows us to arrange monetary\n  donations and spending, with public transparency of everything that happens.\n|===\n"
        },
        {
          "name": "TODO.adoc",
          "type": "blob",
          "size": 4.44140625,
          "content": "NUT roadmap and ideas for future expansion\n------------------------------------------\n\nHere are some ideas that have come up over the years but haven't\nbeen implemented yet.  This may be a good place to start if you're\nlooking for a rainy day hacking project.\n\n\nRoadmap\n~~~~~~~\n\n2.6\n^^^\n\nThis release is focused on the website and documentation rewrite, using\nthe excellent link:https://asciidoc.org/[AsciiDoc].\n\n2.8\n^^^\n\nThis branch will focus on configuration and user interface improvements.\n\n3.0\n^^^\n\nThis major transition will mark the final switch to a complete power\ndevice broker.\n\n\n\nNon-network \"upsmon\"\n~~~~~~~~~~~~~~~~~~~~\n\nSome systems don't want a daemon listening to the network.  This can be\nfor security reasons, or perhaps because the system has been squashed\ndown and doesn't have TCP/IP available.  For these situations you could\nrun a driver and program that sits on top of the driver socket to do\nlocal monitoring.\n\nThis also makes monitoring extremely easy to automate - you don't need\nto worry about usernames, passwords or firewalling.  Just start a driver\nand drop this program on top of it.\n\n- Parse ups.conf and open the state socket for a driver\n- Send DUMPALL and enter a select loop\n- Parse SETINFOs that change ups.status\n- When you get OB LB, shut down\n\nCompletely unprivileged upsmon\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nupsmon currently retains root in a forked process so it can call the\nshutdown command.  The only reason it needs root on most systems is that\nonly privileged users can signal init or send a message on /dev/initctl.\n\nIn the case of systems running sysvinit (Slackware, others?), upsmon\ncould just open /dev/initctl while it has root and then drop it\ncompletely.  When it's time to shut down, fire a control structure at\ninit across the lingering socket and tell it to enter runlevel 0.\n\nThis has been shown to work in local tests, but it's not portable.  It\ncould only be offered as an option for those systems which run that\nflavor of init.  It also needs to be tested to see what happens to\nthe lingering fd over time, such as when init restarts after an upgrade.\n\nFor other systems, there is always the possibility of having a suid\nprogram which does nothing but prod init into starting a shutdown.  Lock\ndown the group access so only upsmon's unprivileged user can access it,\nand make that your SHUTDOWNCMD.  Then it could drop root completely.\n\nChrooted upsmon\n~~~~~~~~~~~~~~~\n\nupsmon could run the network monitoring part in a chroot jail if it had\na pipe to another process running outside for NOTIFY dispatches.  Such a\npipe would have to be constructed extremely carefully so an attacker\ncould not compromise it from the jailed process.\n\nA state machine with a tightly defined sequence could do this safely.\nAll it has to do is dispatch the UPS name and event type.\n\n\t[start] [type] [length] <name> [stop]\n\nMonitor program with interpreted language\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOnce in awhile, I get requests for a way to shut down based on the UPS\ntemperature, or ambient humidity, or at a certain battery charge level,\nor any number of things other than an \"OB LB\" status.  It should be\nobvious that adding a way to monitor all of that in upsmon would bloat\nupsmon for all those people who really don't need anything like that.\n\nA separate program that interprets a list of rules and uses it to\nmonitor the UPS equipment is the way to solve this.  If you have a\ncondition that needs to be tested, add a rule.\n\nSome of the tools that such a language would need include simple\ngreater-than/less-than testing (if battery.charge < 20), equivalence\ntesting (if ups.model = \"SMART-UPS 700\"), and some way to set and clear\ntimers.\n\nDue to the expected size and limited audience for such a program, it\nmight have to be distributed separately.\n\nNOTE: Python may be a good candidate.\n\nSandbox\n~~~~~~~\n\n- check to refresh and integrate the https://alioth.debian.org/pm/?group_id=30602[tasks] list\nand https://alioth.debian.org/tracker/?atid=411545&group_id=30602&func=browse[feature requests] list from Alioth\n- add \"Generic ?Ascii? driver\": I've got to think more about that, but the recent\nsolar panel driver, and the powerman internal approach of a generic engine with\na scripting interface is a cool idea.\nRef http://powerman.svn.sourceforge.net/viewvc/powerman/trunk/etc/apcpdu.dev?revision=969&view=markup\n- integrate the (future) new powerman LUA engine (maybe/must-be used for the driver above?)\nfor native PDU support\n- see how we can help and collaborate with DeviceKit-power\n"
        },
        {
          "name": "UPGRADING.adoc",
          "type": "blob",
          "size": 39.734375,
          "content": "ifdef::txt[]\nUpgrading notes\n===============\nendif::txt[]\n\nThis file lists changes that affect users who installed older versions\nof this software.  When upgrading from an older version, be sure to\ncheck this file to see if you need to make changes to your system.\n\n[NOTE]\n======\nFor packaging (OS distribution or in-house) it is recommended to\nprimarily `./configure --with-all` and then excise `--without-something`\nexplicitly for items not supported on your platform, so you do not miss\nout on new NUT features as they come with new releases. Some may require\nthat you update your build environment with new third-party dependencies,\nso a broken build of a new NUT release would let you know how to act.\n\nThis is a good time to point out that for stricter packaging systems, it may\nbe beneficial to add `--enable-option-checking=fatal` to the `./configure`\ncommand line, in order to quickly pick up any other removed option flags.\n======\n\nChanges from 2.8.2 to 2.8.3\n---------------------------\n\n- PLANNED: Keep track of any further API clean-up?\n\n- NUT development snapshots can now have more version components than the\n  standard semantic versioning triplet, optionally adding the amount of\n  commits on the development trunk since previous release, and the amount\n  of commits on a feature branch that are unique to it.  Release artifacts\n  that have zeroes in both positions would have them stripped and still\n  have the standard \"semver\" exposed, but the development snapshots can\n  now be more reasonably upgraded with automated tooling. A copy of the\n  current version information would be embedded into \"dist\" archives as\n  a `VERSION_DEFAULT` file, so it can be used without git. Certain distros\n  can benefit from a `VERSION_FORCED` file or a `NUT_VERSION_FORCED`\n  environment variable exported from their build system, e.g. via\n  `echo NUT_VERSION_FORCED=1.1.1 > VERSION_FORCED`. Unfortunately, some\n  appliances tag all software the same with their firmware version;\n  if this is required, a (NUT_)VERSION_FORCED_SEMVER envvar or file can\n  help identify the actual NUT release version triplet used on the box.\n  Please use it, it immensely helps with community troubleshooting!\n  [issue #1949]\n\n- When packaging or custom-building for (Linux) distributions with systemd,\n  you can now take advantage of `nut-systemd.preset` file to enable or\n  disable certain NUT units by default; its comments document each choice.\n  [issue #2721]\n\n- Reference packages prepared by `make package` should now separate the\n  `PACKAGE_VERSION` from the platform-dependent prefix by a dash character\n  in the ultimate package file name. Previously they were glued together\n  for some platform targets (HPUX, Solaris). Solaris SVR4 package file names\n  should new differentiate `i386` vs. `amd64` and `sparc` vs. `sparcv9`,\n  depending on `target_cpu` of the build. If you had any scripts relying\n  on the older pattern, they may have to be updated.\n\n- Updated man page generation with `configure` script options to specify that\n  manual sections on the target platform differ from (Linux-based) defaults\n  hard-coded into page sources; this should allow to simplify NUT packaging\n  recipe maintenance in distributions (no more updating patches for changed\n  or added documentation sources)\n\n- `upsmon` should now integrate natively with systemd-driven OS sleep events\n  (built with systemd version 221 or newer \"inhibitor interface\"), so various\n  hacks previously packaged into `/usr/lib/systemd/system-sleep/` scripts or\n  units requiring/conflicting with the `sleep.target` may be obsolete.\n  For fallback with older systemd, a `nut-sleep.service` is provided now.\n  [#1070, #2596, #2597]\n\n- Added systemd and SMF service integration for `upslog` as a `nut-logger`\n  service (disabled by default, needs a `upslog.conf` file to deliver the\n  `UPSLOG_ARGS=...` setting for actual monitoring and logging). [#1803]\n\n- Handling of per-UPS `ALARM` state was introduced to `upsmon`, allowing it\n  to optionally treat it as a factor in deciding that the device is in a\n  \"critical\" state (polled more often, assumed dead if communications are\n  lost). Since it is up to devices and their NUT drivers what they would\n  raise as an alarm (might be something as mundane as ECO mode being active),\n  some alarms can contribute to unwanted/early shutdowns. For this reason\n  a `0|1` setting `ALARMCRITICAL` was introduced into `upsmon.conf` (default\n  is `1`), for such users to be able to prevent their `upsmon` from treating\n  the `ALARM` status as overly severe when it is not in fact. [#2658, #415]\n\n- `usbhid-ups` and `netxml-ups` updated to handle \"No battery installed!\"\n  alarm also to set the `RB` (Replace Battery) value in `ups.status`.\n  This may cause dual triggering of notifications (as an `ALARM` generally\n  and as an important `REPLBATT` status in particular) in `upsmon`, but\n  better safe than sorry. [#415]\n\n- `usbhid-ups` subdriver `PowerCOM HID` seemingly sent UPS `shutdown` and\n  `stayoff` commands in wrong byte order, at least for devices currently\n  in the field. Driver now sends the commands in a way that satisfies new\n  devices; just in case a flag toggle `powercom_sdcmd_byte_order_fallback`\n  was added to set the old behavior (if some devices do need it). [PR #2480]\n\n- `usbhid-ups` subdriver `CyberPower HID` default `pollfreq` sped up to\n  12 seconds (common default is 30 seconds). Feedback is welcome if this\n  improves connection stability or overwhelms the UPS controller instead.\n  [issue #1689, PR #2718]\n\n- `usbhid-ups` subdriver `CyberPower HID` default `offdelay` is set to 60\n  and `ondelay` to 120 seconds, in accordance with man page suggestions;\n  users with custom settings not divisible by 60 will be loudly warned. [#1394]\n\n- Added support for `lbrb_log_delay_sec=N` setting to delay propagation of\n  `LB` or `LB+RB` state (buggy with APC BXnnnnMI devices/firmwares issued\n  circa 2023-2024 which flood the logs with spurious LOWBATT and REPLACEBATT\n  events). This may work better for some devices when combined with flags\n  like `onlinedischarge_calibration` and `lbrb_log_delay_without_calibrating`.\n  [#2347]\n\n- Enabled installation of built PDF and HTML (including man page renditions)\n  files under the configured `docdir`. It seems previously they were only\n  built (if requested) but not installed via `make`, unlike the common man\n  pages which are delivered automatically. Packaging recipes can likely\n  be simplified now. [#2445]\n\n- A `NUT_DEBUG_SYSLOG` environment variable was introduced to tweak activation\n  of syslog message emission (and related detachment of `stderr` when daemons\n  are backgrounding), which can be useful for systemd service units. It can be\n  set via `nut.conf` file for all standard consumers, or patched/dropped-in to\n  systemd unit definitions specifically (less recommended, but may be easier\n  to package). The positive effect would be avoiding duplicate logging as both\n  `syslog` and `stderr` ending up in the same journal. [#2394]\n\n- A `CHANGELOG_REQUIRE_GROUP_BY_DATE_AUTHOR` setting was added (for `make`\n  calls and used by `tools/gitlog2changelog.py.in` script), and it defaults\n  to `true` allowing for better ordered documents at the cost of some memory\n  during document generation. Resource-constrained builders (working from\n  a Git workspace, not tarball archives) may have to set it to `false` when\n  calling `make` for NUT. [#2510]\n\n- Drivers should now be able to set `STATEPATH` via `ups.conf` to match `upsd`\n  custom configuration ability; in fact, the data server would prefer the\n  value from `ups.conf` over the one in `upsd.conf`, if both are present.\n  Note that `NUT_STATEPATH` environment variable trumps both. [issue #694]\n\n- NUT products like `nut-scanner`, which dynamically load shared libraries\n  at run-time without persistent pre-linking, should now know the library\n  file names that were present during build (likely encumbered with version\n  suffixes), and prefer them over plain `libname.so` patterns used previously\n  (which on some platforms are only delivered by development packages as\n  symlinks). Packaging recipes can likely be simplified now: some distros\n  certainly did patch NUT source to similar effect). [#2431]\n\n- Numerous changes to `nut-scanner` and symbols that its `libnutscan.so`\n  delivers have caused a library version bump.  New methods have been added\n  and one structure (`nutscan_ipmi_t`) updated in a (hopefully) backwards\n  compatible manner. [PR #2523, issue #2244 and numerous PRs for it]\n\n- Internal API change for `sendsignalpid()` and `sendsignalfn()` methods,\n  which can impact NUT forks which build using `libcommon.la` and similar\n  libraries.  Added new last argument with `const char *progname` (may be\n  `NULL`) to check that we are signalling an expected program name when we\n  work with a PID.  With the same effort, NUT programs which deal with PID\n  files to send signals (`upsd`, `upsmon`, drivers and `upsdrvctl`) would\n  now default to a safety precaution -- checking that the running process\n  with that PID has the expected program name (on platforms where we can\n  determine one). This might introduce regressions for heavily customized\n  NUT builds (e.g. embedded in NAS or similar devices) whose binary file\n  names differ significantly from a `progname` defined in the respective\n  NUT source file, so a boolean `NUT_IGNORE_CHECKPROCNAME` environment\n  variable support was added to optionally disable this verification.\n  Also the NUT daemons should request to double-check against their\n  run-time process name (if it can be detected). [issue #2463]\n\n- More environment variable support was added to NUT programs, primarily\n  aimed at wrappers such as init scripts and service unit definitions,\n  allowing to tweak what (and whether) they write into debug traces, and\n  so \"make noise\" or \"bring invaluable insights\" to logs or terminal;\n  they can generally be used for services and init scripts via `nut.conf`:\n  * See `NUT_IGNORE_CHECKPROCNAME` and `NUT_DEBUG_SYSLOG` above. [#1915]\n  * A `NUT_QUIET_INIT_BANNER` envvar (presence or \"true\" value) prevents\n    tool name and NUT version banner from being printed out when programs\n    start. [issues #1789 vs. #316]\n\n- A `configure` script option to build `--with-modbus+usb` was added to\n  let the caller insist on the use of USB-capable libmodbus (or fail the\n  NUT build attempt). Certain build arguments can default this option to\n  become enabled (implicitly): `configure --with-modbus --with-usb` and\n  either `--with-drivers=*apc_modbus*` (actually implies `--with-modbus`)\n  or `--with-modbus-includes=... --with-modbus-libs=...`\n  as a way to avoid surprises with custom NUT builds aiming to have an\n  USB-capable `apc_modbus` driver (currently this requires a custom-built\n  libmodbus, can be a static build to avoid conflicts with OS). [#2666]\n\n- A `configure` script option to `--enable-NUT_STRARG-always` was added\n  to enable the `NUT_STRARG` macro (to handle `NULL` string printing)\n  even if system libraries seem to safely support this behavior natively.\n  This should primarily help against overly zealous static analysis tools\n  in recent compiler generations. [#2585]\n\n\nChanges from 2.8.1 to 2.8.2\n---------------------------\n\n- Builds requested with a specific C/C++ language standard revision via\n  `CFLAGS` and `CXXFLAGS` should again be honoured. There was a mishap\n  with the `m4` scripting for `autoconf` which could have caused use of\n  C11/C++11 if compiler supported it, regardless of a request. [PR #2306]\n\n- Added generation of FreeBSD/pfSense quirks for USB devices supported\n  by NUT (may get installed to `$datadir` e.g. `/usr/local/share/nut`\n  and need to be pasted into your `/boot/loader.conf.local`). [#2159]\n\n- nut-scanner now does not propose active `bus`, `busport` and `device`\n  values when generating device configurations by default. They may\n  appear as comments, or enabled by specifying the `-U` command-line\n  option several times. [#2221]\n\n- The `tools/gitlog2changelog.py.in` script was revised, in particular to\n  convert section titles (with contributor names) into plain ASCII character\n  set, for `dblatex` versions which do not allow diacritics and other kinds\n  of non-trivial characters in sections. A number of other projects seem to\n  use the NUT version of the script, and are encouraged to look at related\n  changes in `configure.ac` and `Makefile.am` recipes. [PR #2360, PR #2366]\n\nChanges from 2.8.0 to 2.8.1\n---------------------------\n\n- NUT documentation recipes were revised, so many of the text source files\n  were renamed to `*.adoc` pattern. Newly, a `release-notes.pdf` and HTML\n  equivalents are generated. Packages which deliver documentation may need\n  to update the lists of files to ship. [#1953] Developers may be impacted\n  by new `configure --enable-spellcheck` toggle (should add spelling checks\n  to `make check` by default, if tools are available) to facilitate quicker\n  acceptance of contributions. Packaging systems may now want to explicitly\n  disable it, if it blocks package building (pull requests to update the\n  `docs/nut.dict` are a better and welcome solution). [#2067]\n\n- Several improvements regarding simultaneous support of USB devices that\n  were previously deemed \"identical\" and so NUT driver instances did not\n  start for all of them:\n\n  * Some more drivers should now use the common USB device matching logic\n    and the 7 `ups.conf` options for that [#1763], and man pages were\n    updated to reflect that [#1766];\n\n  * The `nut-scanner` tool should suggest these options in its generated\n    device configuration [#1790]: hopefully these would now suffice for\n    sufficiently unique combinations;\n\n  * The `nut-scanner` tool should also suggest sanity-check violations\n    as comments in its generated device configuration [#1810], e.g. bogus\n    or duplicate serial number values;\n\n  * The common USB matching logic was updated with an `allow_duplicates`\n    flag (caveat emptor!) which may help monitor several related no-name\n    devices on systems that do not discern \"bus\" and \"device\" values\n    (although without knowing reliably which one is which... sometimes it\n    is better than nothing) [#1756].\n\n- Work on NUT for Windows branch led to situation-specific definitions of\n  what in POSIX code was all \"file descriptors\" (an `int` type). Now such\n  entities are named `TYPE_FD`, `TYPE_FD_SER` or `TYPE_FD_SOCK` with some\n  helper macros to name and determine \"invalid\" values (closed file, etc.)\n  Some of these changes happened in NUT header files, and at this time it\n  was not investigated whether the set of files delivered for third-party\n  code integration (e.g. C/C++ projects binding with `libnutclient` or\n  `libupsclient) is consistent or requires additional definitions/files.\n  If something gets broken by this, it is a bug to address in future [#1556]\n\n- Further revision of public headers delivered by NUT was done, particularly\n  to address lack of common data types (`size_t`, `ssize_t`, `uint16_t`,\n  `time_t` etc.) in third-party client code that earlier sufficed to only\n  include NUT headers. Sort of regression by NUT 2.8.0 (note those consumers\n  still have to re-declare some numeric variable types used) [#1638]\n\n  * For practical example of NUT consumer adaptation (to cater to both old and\n    new API types) please see https://github.com/collectd/collectd/pull/4043\n\n- Added support for `make install` of PyNUT module and NUT-Monitor desktop\n  application -- such activity was earlier done by packages directly; now\n  the packaging recipes may use NUT source-code facilities and package just\n  symlinks as relevant for each distro separately [#1462, #1504]\n\n- The `upsd.conf` listing of `LISTEN` addresses was previously inverted\n  (the last listed address was applied first), which was counter-intuitive\n  and fixed for this release. If user configurations somehow relied on this\n  order (e.g. to prioritize IPv6 vs. IPv4 listeners), configuration changes\n  may be needed. [#2012]\n\n- The `upsd` configured to listen on IPv6 addresses should handle only\n  IPv6 (and not IPv4-mappings like it might have done before) to avoid\n  surprises and insecurity -- if user configurations somehow relied on\n  this dual support, configuration changes may be needed to specify both\n  desired IP addresses. Note that the daemon logs will now warn if a\n  host name resolves to several addresses (and will only listen on the\n  first hit, as it did before in such cases). [#2012]\n\n- A definitive behavior for `LISTEN *` directives became specified, to try\n  handling both IPv4 and IPv6 \"any\" address (subject to `upsd` CLI options\n  to only choose one, and to OS abilities). This use-case may be practically\n  implemented as a single IPv6 socket on systems with enabled and required\n  IPv4-mapped IPv6 address support, or as two separate listening sockets -\n  logged messages to this effect (e.g. inability to listen on IPv4 after\n  opening IPv6) are expected on some platforms. End-users may also want to\n  reconfigure their `upsd.conf` files to remove some now-redundant `LISTEN`\n  lines. [#2012]\n\n- Added support for `make sockdebug` for easier developer access to the tool;\n  also if `configure --with-dev` is in effect, it would now be installed to\n  the configured `libexec` location. A man page was also added. [#1936]\n\n- NUT software-only drivers (dummy-ups, clone, clone-outlet) separated from\n  serial drivers in respective Makefile and configure script options - this\n  may impact packaging decisions on some distributions going forward [#1446]\n\n- GPIO category of drivers was added (`--with-gpio` configure script option) -\n  this may impact packaging decisions on some (currently Linux released 2018+)\n  distributions going forward [#1855]\n\n- An explicit `configure --with-nut-scanner` toggle was added, specifically\n  so that build environments requesting `--with-all` but lacking `libltdl`\n  would abort and require the packager either to install the dependency\n  or explicitly forfeit building the tool (some distro packages missed it\n  quietly in the past) [#1560]\n\n- An `upsdebugx_report_search_paths()` method in NUT common code was added,\n  and exposed in `libnutscan.so` builds in particular - API version for the\n  public library was bumped [#317]\n\n- Some environment variable support was added to NUT programs, primarily\n  aimed at wrappers such as init scripts and service unit definitions,\n  allowing to tweak what (and whether) they write into debug traces, and\n  so \"make noise\" or \"bring invaluable insights\" to logs or terminal:\n  * A `NUT_DEBUG_LEVEL=NUM` envvar allows to temporarily boost debugging\n    of many daemons (`upsd`, `upsmon`, drivers, `upsdrvctl`, `upssched`)\n    without changes to configuration files or scripted command lines. [#1915]\n  * A `NUT_DEBUG_PID` envvar (presence) support was added to add current\n    process ID to tags with debug-level identifiers. This may be useful\n    when many NUT daemons write to the same console or log file, such as\n    in containers/plugins for Home Assistant, storage appliances, etc. [#2118]\n  * A `NUT_QUIET_INIT_SSL` envvar (presence or \"true\" value) prevents\n    `libupsclient` consumers (notoriously `upsc`) from reporting whether\n    they have initialized SSL support. [#1662]\n  * A `NUT_QUIET_INIT_UPSNOTIFY` envvar (presence or \"true\" value)\n    prevents daemons which can notify service management frameworks (such\n    as systemd) about passing their lifecycle milestones, to not report\n    loudly if they could not do so (e.g. running on a system without a\n    framework, or misconfigured so they could not report and the OS would\n    restart the false-positively \"unresponsive\" service). [#2136]\n\n- `configure` script, reference init-script and packaging templates updated\n  to eradicate `@PIDPATH@/nut` ambiguity in favor of `@ALTPIDPATH@` for the\n  unprivileged processes vs. `@PIDPATH@` for those running as root [#1719]\n\n- The \"layman report\" of NUT configuration options displayed after the run\n  of `configure` script can now be retained and installed by using the\n  `--enable-keep_nut_report_feature` option; packagers are welcome to make\n  use of this, to better keep track of their deliveries [#1826, #1708]\n\n- Renamed generated nut-common.tmpfiles(.in) => nut-common-tmpfiles.conf(.in)\n  to install a /usr/lib/systemd-tmpfiles/*.conf pattern [#1755]\n\n  * If earlier NUT v2.8.0 package recipes for your Linux distribution dealt\n    with this file, you may have to adjust its name for newer releases.\n\n  * Several other issues have been fixed related to this file and its content,\n    including #1030, #1037, #1117 and #1712\n\n- Extended Linux systemd support with optional notifications about daemon\n  state (READY, RELOADING, STOPPING) and watchdog keep-alive messages.\n  Note that `WatchdogSec=` values are currently NOT pre-set into systemd\n  unit file templates provided by NUT, this is an exercise for end-users\n  based on sizing of their deployments and performance of monitoring station\n  [#1590, #1777]\n\n- snmp-ups: some subdrivers (addressed using the driver parameter `mibs`)\n  were renamed: `pw` is now `eaton_pw_nm2`, and `pxgx_ups` is `eaton_pxg_ups`\n  [#1715]\n\n- The `tools/gitlog2changelog.py.in` script was revised, in particular to\n  generate the `ChangeLog` file more consistently with different versions\n  of Python interpreter, and without breaking the long file paths in the\n  resulting mark-up text. Due to this, a copy of this file distributed with\n  NUT release archives is expected to considerably differ on first glance\n  from its earlier released versions (not just adding lines for the new\n  release, but changing lines in the older releases too) [#1945, #1955]\n\nChanges from 2.7.4 to 2.8.0\n---------------------------\n\n- Note to distribution packagers: this version hopefully learns from many\n  past mistakes, so many custom patches may be no longer needed. If some\n  remain, please consider making pull requests for upstream NUT codebase\n  to share the fixes consistently across the ecosystem. Also note that\n  some new types of drivers (so package groups with unique dependencies)\n  could have appeared since your packaging was written (e.g. with modbus),\n  as well as new features in systemd integration (`nut-driver@instances`\n  and the `nut-driver-enumerator` to manage their population), as well as\n  updated Python 2 and Python 3 support (again, maybe dictating different\n  package groups) as detailed below.\n\n- Due to changes needed to resolve build warnings, mostly about mismatching\n  data types for some variables, some structure definitions and API signatures\n  of several routines had to be changed for argument types, return types,\n  or both. Primarily this change concerns internal implementation details\n  (may impact update of NUT forks with custom drivers using those), but a\n  few changes also happened in header files installed for builds configured\n  `--with-dev` and so may impact `upsclient` and `nutclient` (C++) consumers.\n  At the very least, binaries for those consumers should be rebuilt to remain\n  stable with NUT 2.8.0 and not mismatch int-type sizes and other arguments.\n\n- libusb-1.0: NUT now defaults to building against libusb-1.0 API version\n  if the configure script finds the development headers, falling back to\n  libusb-0.1 if not. Please report any regressions.\n\n- apcupsd-ups: When monitoring a remote apcupsd server, interpret \"SHUTTING\n  DOWN\" as a NUT \"LB\" status. If you were relying on the previous behavior\n  (for instance, in a monitor-only situation), please adjust your upsmon\n  settings. Reference: https://github.com/networkupstools/nut/issues/460\n\n- Packagers: the AsciiDoc detection has been reworked to allow NUT to be built\n  from source without requiring asciidoc/a2x (using pre-built man pages from\n  the distribution tarball, for instance). Please double-check that we did not\n  break anything (see docs/configure.txt for options).\n\n- Driver core: options added for standalone mode (scanning for devices without\n  requiring ups.conf) - see docs/man/nutupsdrv.txt for details.\n\n- oldmge-shut has been removed, and replaced by mge-shut.\n\n- New drivers for devices with \"Qx\" (also known as \"Megatec Q*\") family of\n  protocols should be developed as sub-drivers in the `nutdrv_qx` framework\n  for USB and Serial connected devices, not as updates/clones of older e.g.\n  `blazer` family and `bestups`. Sources, man pages and start-up messages\n  of such older drivers were marked with \"OBSOLETION WARNING\".\n\n- liebert-esp2: some multi-phase variable names have been updated to match the\n  rest of NUT.\n\n- netxml-ups: if you have old firmware, or were relying on values being off by\n  a factor of 10, consider the `do_convert_deci` flag. See\n  docs/man/netxml-ups.txt for details.\n\n- snmp-ups: detection of Net-SNMP has been updated to use `pkg-config` by\n  default (if present), rather than `net-snmp-config(-32|-64)` script(s) as\n  the only option available previously. The scripts tend to specify a lot\n  of options (sometimes platform-specific) in suggested `CFLAGS` and `LIBS`\n  compared to the packaged `pkg-config` information which also works and is\n  more portable. If this change bites your distribution, please bring it up\n  in https://github.com/networkupstools/nut/issues or better yet, post a PR.\n  Also note that `./configure --with-netsnmp-config(=yes)` should set up the\n  preference of the detected script over `pkg-config` information, if both\n  are available, and `--with-netsnmp-config=/path/name` would as well.\n\n- snmp-ups: bit mask values for flags in earlier codebase were defined in a\n  way that caused logically different items to have same numeric values.\n  This was fixed to surely use different definitions (so changing numbers\n  behind some of those macro symbols), and testing with UPS, ePDU and ATS\n  hardware which was available did not expose any practical differences.\n\n- usbhid-ups: numeric data conversion from wire protocol to CPU representation\n  in GetValue() was completely reworked, aiming to be correct on all CPU types.\n  That said, regressions are possible and feedback is welcome.\n\n- nut-scanner: Packagers, take note of the changes to the library\n  search code in common/common.c. Please file an issue if this does not work\n  with your platform.\n\n- dummy-ups can now specify `mode` as a driver argument, and separates the\n  notion of `dummy-once` (new default for `\\*.dev` files that do not change)\n  vs. `dummy-loop` (legacy default for `*.seq` and others) [issue #1385]\n\n  * Note this can break third-party test scripts which expected `*.dev`\n    files to work as a looping sequence with a `TIMER` keywords to change\n    values slowly; now such files should get processed to the end once.\n    Specify `mode=dummy-loop` driver option or rename the data file used\n    in the `port` option for legacy behavior.\n    Use/Test-cases which modified such files content externally should\n    not be impacted.\n\n- Python: scripts have been updated to work with Python 3 as well as 2.\n\n  * PyNUT module (protocol binding) supports both Python generations.\n\n  * NUT-Monitor (desktop UI client) got separated into two projects:\n    one with support for Python2 and GTK2, and another for Python3 and Qt5.\n    On operating systems that serve both environments, either of these\n    implementation should be usable. For distributions that deprecated\n    and removed Python2 support, it is a point to consider in NUT packages\n    and their build-time and installation dependencies.\n    The historic filenames for desktop integration (`NUT-Monitor` script\n    and `nut-monitor.desktop`) are still delivered, but now cover a wrapper\n    script which detects the environment capabilities and launches the best\n    suitable UI implementation (if both are available).\n\n- apcsmart: updates to CS \"hack\" (see docs/man/apcsmart.txt for details)\n\n- upsdebugx(): added `[D#]` prefix to log entries with level > 0\n  so if any scripts or other tools relied on parsing those messages\n  making some assumptions, they should be updated\n\n- upsdebugx() and related methods are now macros, optionally calling similarly\n  named implementations like s_upsdebugx() as a slight optimization; this may\n  show up in linking of binaries for some customized build scenarios\n\n- libraries, tools and protocol now support a `TRACKING` ID to be used with\n  an `INSTCMD` or `SET VAR` requests; for details see docs/net-protocol.txt\n  and docs/sock-protocol.txt\n\n- upsrw: display the variable type beside ENUM / RANGE\n\n- Augeas: new `--with-augeas-lenses-dir` configure option.\n\nChanges from 2.7.3 to 2.7.4\n---------------------------\n\n- scripts/systemd/nut-server.service.in: Restore systemd relationship since it\n  was preventing upsd from starting whenever one or more drivers, among several,\n  was failing to start\n\n- Fix UPower device matching for recent kernels, since hiddev* devices now have\n  class \"usbmisc\", rather than \"usb\"\n\n- macosx-ups: the \"port\" driver option no longer has any effect\n\n- Network protocol information: default to type NUMBER for variables that are\n  not flagged as STRING . This point is subject to improvements or change in\n  the next release 2.7.5.  Refer to docs/net-protocol.txt for more information\n\nChanges from 2.7.2 to 2.7.3\n---------------------------\n\n- The linkman:nutdrv_qx[8] driver will eventually supersede linkman:bestups[8].\n  It has been tested on a U-series Patriot Pro II. Please test the new driver\n  on your hardware during your next maintenance window, and report any bugs.\n\n- If you are upgrading from a new install of 2.7.1 or 2.7.2, double-check the\n  value of POWERDOWNFLAG in $prefix/etc/upsmon.conf - it has been restored to\n  /etc/killpower as in 2.6.5 and earlier.\n\n- If you use upslog with a large sleep value, you may be interested in adding\n  `killall -SIGUSR1 upslog` to any OB/OL script actions. This will force\n  upslog to write a log entry to catch short power transients.\n\n- Be sure that your SSL keys are readable by the NUT system user. The SSL\n  subsystem is now initialized after `upsd` forks, to work around issues in the\n  NSS library.\n\n- The systemd nut-server.service does not Require nut-driver to be started\n  successfully.  This was previously preventing upsd startup, even for just\n  one driver failure among many.  This also matches the behavior of sysV\n  initscripts.\n\nChanges from 2.7.1 to 2.7.2\n---------------------------\n\n- upsdrvctl is now installed to $prefix/sbin rather than $driverexec.\n  This usually means moving from /bin to /sbin, apart from few exceptions.\n  In all cases, please adapt your scripts.\n\n- FreeDesktop Hardware Abstraction Layer (HAL) support was removed.\n  Please adapt your packaging files, if you used to distribute the\n  nut-hal-drivers package.\n\n- This is a good time to point out that for stricter packaging systems, it may\n  be beneficial to add \"--enable-option-checking=fatal\" to the ./configure\n  command line, in order to quickly pick up any other removed option flags.\n\nChanges from 2.6.5 to 2.7.1\n---------------------------\n\n- The linkman:apcsmart[8] driver has been replaced by a new implementation. There is a new\n  parameter, 'ttymode', which may help if you have a non-standard serial port,\n  or Windows.  In case of issues with this new version, users can revert to\n  apcsmart-old.\n\n- The linkman:nutdrv_qx[8] driver will eventually supersede blazer_ser and blazer_usb.\n  Options are not exactly the same, but are documented in the nutdrv_qx man\n  page.\n\n- Mozilla NSS support has been added. The OpenSSL configuration options should\n  be unchanged, but please refer to the linkman:upsd.conf[5] and\n  linkman:upsmon.conf[5] documentation in case we missed something.\n\n- linkman:upsrw[8] now prints out the maximum size of variables. Hopefully you\n  are not parsing the output of upsrw - it would be easier to use one of the\n  NUT libraries, or implement the network protocol yourself.\n\n- The jNut source is now here: https://github.com/networkupstools/jNut\n\nChanges from 2.6.4 to 2.6.5\n---------------------------\n\n- users are encouraged to update to NUT 2.6.5, to fix a regression in\n  upssched.\n\n- mge-shut driver has been replaced by a new implementation (newmge-shut).\n  In case of issue with this new version, users can revert to oldmge-shut.\n  UPDATE: oldmge-shut was dropped between 2.7.4 and 2.8.0 releases.\n\nChanges from 2.6.3 to 2.6.4\n---------------------------\n\n- users are encouraged to update to NUT 2.6.4, to fix upsd vulnerability\n  (CVE-2012-2944: upsd can be remotely crashed).\n\n- users of the bestups driver are encouraged to switch to blazer_ser,\n  since bestups will soon be deprecated.\n\nChanges from 2.6.2 to 2.6.3\n---------------------------\n\n- nothing that affects upgraded systems.\n\nChanges from 2.6.1 to 2.6.2\n---------------------------\n\n- apcsmart driver has been replaced by a new implementation. In case of issue\n  with this new version, users can revert to apcsmart-old.\n\nChanges from 2.6.0 to 2.6.1\n---------------------------\n\n- nothing that affects upgraded systems.\n\nChanges from 2.4.3 to 2.6.0\n---------------------------\n\n- users of the megatec and megatec_usb drivers must respectively switch to\n  blazer_ser and blazer_usb.\n\n- users of the liebertgxt2 driver are advised that the driver name has changed\n  to liebert-esp2.\n\nChanges from 2.4.2 to 2.4.3\n---------------------------\n\n- nothing that affects upgraded systems.\n\nChanges from 2.4.1 to 2.4.2\n---------------------------\n\n- The default subdriver for the blazer_usb driver USB id 06da:0003 has changed.\n  If you use such a device and it is no longer working with this driver,\n  override the 'subdriver' default in 'ups.conf' (see man 8 blazer).\n\n- NUT ACL and the allowfrom mechanism has been replaced in 2.4.0 by the LISTEN\n  directive and tcp-wrappers respectively. This information was missing below,\n  so a double note has been added.\n\nChanges from 2.4.0 to 2.4.1\n---------------------------\n\n- nothing that affects upgraded systems.\n\nChanges from 2.2.2 to 2.4.0\n---------------------------\n\n- The nut.conf file has been introduced to standardize startup configuration\n  across the various systems.\n\n- The cpsups and nitram drivers have been replaced by the powerpanel driver,\n  and removed from the tree. The cyberpower driver may suffer the same in the\n  future.\n\n- The al175 and energizerups drivers have been removed from the tree, since\n  these were tagged broken for a long time.\n\n- Developers of external client application using libupsclient must rename\n  their \"UPSCONN\" client structure to \"UPSCONN_t\".\n\n- The upsd server will now disconnect clients that remain silent for more than\n  60 seconds.\n\n- The files under scripts/python/client are distributed under GPL 3+, whereas\n  the rest of the files are distributed under GPL 2+. Refer to COPYING for more\n  information.\n\n- The generated udev rules file has been renamed with dash only, no underscore\n  anymore (i.e. 52-nut-usbups.rules instead of 52_nut-usbups.rules)\n\nChanges from 2.2.1 to 2.2.2\n---------------------------\n\n- The configure option \"--with-lib\" has been replaced by \"--with-dev\".\n  This enable the additional build and distribution of the static\n  version of libupsclient, along with the pkg-config helper and manual\n  pages. The default configure option is to distribute only the shared\n  version of libupsclient. This can be overridden by using the\n  \"--disable-shared\" configure option (distribute static only binaries).\n\n- The UPS poweroff handling of the usbhid-ups driver has been reworked.\n  Though regression is not expected, users of this driver are\n  encouraged to test this feature by calling \"upsmon -c fsd\" and\n  report any issue on the NUT mailing lists.\n\nChanges from 2.2.0 to 2.2.1\n---------------------------\n\n- nothing that affects upgraded systems.\n  (The below message is repeated due to previous omission)\n\n- Developers of external client application using libupsclient are\n  encouraged to rename their \"UPSCONN\" client structure to \"UPSCONN_t\"\n  since the former will disappear by the release of NUT 2.4.\n\nChanges from 2.0.5 to 2.2.0\n---------------------------\n\n- users of the newhidups driver are advised that the driver name has changed\n  to usbhid-ups.\n\n- users of the hidups driver must switch to usbhid-ups.\n\n- users of the following drivers (powermust, blazer, fentonups, mustek,\n  esupssmart, ippon, sms) must switch to megatec, which replaces\n  all these drivers.  Please refer to doc/megatec.txt for details.\n\n- users of the mge-shut driver are encouraged to test newmge-shut, which\n  is an alternate driver scheduled to replace mge-shut,\n\n- users of the cpsups driver are encouraged to switch to powerpanel which\n  is scheduled to replace cpsups,\n\n- packagers will have to rework the whole nut packaging due to the\n  major changes in the build system (completely modified, and now using\n  automake). Refer to packaging/debian/ for an example of migration.\n\n- specifying '-a <id>' is now mandatory when starting a driver manually,\n  i.e. not using upsdrvctl.\n\n- Developers of external client application using libupsclient are\n  encouraged to rename the \"UPSCONN\" client structure to \"UPSCONN_t\"\n  since the former will disappear by the release of NUT 2.4.\n\nChanges from 2.0.4 to 2.0.5\n---------------------------\n\n- users of the newhidups driver: the driver is now more strict about\n  refusing to connect to unknown devices. If your device was\n  previously supported, but fails to be recognized now, add\n  'productid=XXXX' to ups.conf. Please report the device to the NUT\n  developer's mailing list.\n\nChanges from 2.0.3 to 2.0.4\n---------------------------\n\n- nothing that affects upgraded systems.\n\n- users of the following drivers (powermust, blazer, fentonups, mustek,\n  esupssmart, ippon, sms, masterguard) are encouraged to switch to megatec,\n  which should replace all these drivers by nut 2.2. For more information,\n  please refer to doc/megatec.txt\n\nChanges from 2.0.2 to 2.0.3\n---------------------------\n\n- nothing that affects upgraded systems.\n\n- hidups users are encouraged to switch to newhidups, as hidups will be\n  removed by nut 2.2.\n\nChanges from 2.0.1 to 2.0.2\n---------------------------\n\n- The newhidups driver, which is the long run USB support approach,\n  needs hotplug files installed to setup the right permissions on\n  device file to operate. Check newhidups manual page for more information.\n\nChanges from 2.0.0 to 2.0.1\n---------------------------\n\n- The cyberpower1100 driver is now called cpsups since it supports\n  more than just one model.  If you use this driver, be sure to remove\n  the old binary and update your ups.conf 'driver=' setting with the\n  new name.\n\n- The upsstats.html template page has been changed slightly to reflect\n  better HTML compliance, so you may want to update your installed copy\n  accordingly.  If you've customized your file, don't just copy the new\n  one over it, or your changes will be lost!\n\nChanges from 1.4.0 to 2.0.0\n---------------------------\n\n- The sample config files are no longer installed by default.  If you\n  want to install them, use 'make install-conf' for the main programs,\n  and 'make install-cgi-conf' for the CGI programs.\n\n- ACCESS is no longer supported in upsd.conf.  Use ACCEPT and REJECT.\n\n  * Old way:\n+\n\tACCESS grant all adminbox\n\tACCESS grant all webserver\n\tACCESS deny all all\n\n  * New way:\n+\n\tACCEPT adminbox\n\tACCEPT webserver\n\tREJECT all\n\n  * Note that ACCEPT and REJECT can take multiple arguments, so this\n    will also work:\n+\n\tACCEPT adminbox webserver\n\tREJECT all\n\n- The drivers no longer support sddelay in ups.conf or -d on the\n  command line.  If you need a delay after calling 'upsdrvctl\n  shutdown', add a call to sleep in your shutdown script.\n\n- The templates used by upsstats have changed considerably to reflect\n  the new variable names.  If you use upsstats, you will need to\n  install new copies or edit your existing files to use the new names.\n\n- Nobody needed UDP mode, so it has been removed.  The only users\n  seemed to be a few people like me with ancient asapm-ups binaries.\n  If you really want to run asapm-ups again, bug me for the new patch\n  which makes it work with upsclient.\n\n- 'make install-misc' is now 'make install-lib'.  The misc directory\n  has been gone for a long time, and the target was ambiguous.\n\n- The newapc driver has been renamed to apcsmart.  If you previously\n  used newapc, make sure you delete the old binary and fix your\n  ups.conf.  Otherwise, you may run the old driver from 1.4.\n\nFile trimmed here on changes from 1.2.2 to 1.4.0\n------------------------------------------------\n\nFor information before this point, start with version 2.4.1 and work back.\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 6.9560546875,
          "content": "#\n# Network UPS Tools: AppVeyor CI build recipe: NUT for Windows with MSYS2/MinGW x64\n#\n# https://www.msys2.org/docs/ci/\n# https://www.appveyor.com/docs/appveyor-yml/\n# https://www.appveyor.com/docs/build-configuration/\n# https://www.appveyor.com/docs/windows-images-software/\n\nversion: 2.8.2.{build}-{branch}\n\n# base image\nimage: Visual Studio 2022\n\n# branches to build\nbranches:\n  # whitelist\n  only:\n    - master\n    - /Windows/\n\nplatform: x64\n\n# https://www.appveyor.com/docs/build-cache/\nenvironment:\n  APPVEYOR_SAVE_CACHE_ON_ERROR: true\n  APPVEYOR_CACHE_ENTRY_ZIP_ARGS: -t7z -m0=lzma -mx=9\n  CCACHE_DIR: /home/appveyor/.ccache\n\n# https://github.com/networkupstools/nut/blob/Windows-v2.8.0-1/docs/config-prereqs.txt#L951\n# or look for the chapter in nearby lines in later (current) revisions.\n# Note: not using `time` in scripts currently - they did upset\n# AppVeyor console log scanner with a /^sys.*/ match (apparently)\ninstall:\n  - cmd: |\n        REM Do not give pacman cause for complaints:\n        C:\\msys64\\usr\\bin\\bash -lc \"mkdir -p /var/cache/pacman/pkg; ls -la /\"\n  - cmd: |\n        REM Core update (in case any core packages are outdated):\n        C:\\msys64\\usr\\bin\\bash -lc \"date -u; pacman --noconfirm -Syuu\"\n  - cmd: |\n        REM Normal update (same command again):\n        C:\\msys64\\usr\\bin\\bash -lc \"date -u; pacman --noconfirm -Syuu\"\n  - cmd: |\n        REM Prerequisites for NUT per https://github.com/networkupstools/nut/blob/master/docs/config-prereqs.txt :\n        C:\\msys64\\usr\\bin\\bash -lc \"date -u; pacman --noconfirm -S --needed base-devel mingw-w64-x86_64-toolchain autoconf-wrapper automake-wrapper libtool mingw-w64-x86_64-libltdl gcc ccache mingw-w64-x86_64-ccache git aspell aspell-en python mingw-w64-x86_64-python-pygments mingw-w64-x86_64-winpthreads-git mingw-w64-x86_64-libusb mingw-w64-x86_64-libusb-compat-git mingw-w64-x86_64-neon libneon-devel mingw-w64-x86_64-libmodbus-git mingw-w64-x86_64-libgd mingw-w64-x86_64-cppunit\"\n  - cmd: |\n        REM Assorted stats after package processing:\n        C:\\msys64\\usr\\bin\\bash -lc \"date -u; ls -la / ; du -ksx / ; date -u; du -ks /var/cache/pacman/pkg; date -u\"\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        C:\\msys64\\usr\\bin\\bash -lc 'PATH=\"/mingw64/bin:$PATH\" ; export PATH ; pwd ; ccache -sv || echo \"SKIP: Could not query ccache stats\" ; ccache -o sloppiness=file_macro || true ; ccache -o compression=true || true '\n\n\nbefore_build:\n  - cmd: |\n      REM Ensure we have a net-snmp to build against\n      REM Adapted from scripts/Windows/README.adoc document.\n      REM Here we hope to build it once, then use the\n      REM stashed version across Appveyor rebuilds.\n      REM Preserve the current working directory:\n      set CHERE_INVOKING=yes\n      REM Start a 64 bit Mingw environment:\n      set MSYSTEM=MINGW64\n      C:\\msys64\\usr\\bin\\bash -lc \"date -u; export MSYS2_PATH ; bash ./scripts/Windows/build-mingw-prereqs.sh\"\n\n\nbuild_script:\n  - cmd: |\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; PATH=\"/mingw64/bin:$PATH\" CI_SKIP_CHECK=true ./ci_build.sh'\n\n\nafter_build:\n  - cmd: |\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; PATH=\"/mingw64/bin:$PATH\" ; export PATH ; ccache -sv || ccache -s || echo \"SKIP: Could not query ccache stats\"'\n\n\ntest_script:\n  - cmd: |\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        REM Start Mingw-based integration and unit checks:\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; NUT_STATEPATH=\"C:\\\\Users\\\\appveyor\\\\AppData\\\\Local\\\\Temp\\\\nut-test\"; mkdir -p \"${NUT_STATEPATH}\"; export NUT_STATEPATH; PATH=\"/mingw64/bin:$PATH\" make -s check || bash -lc \"for F in tests/*.log tests/*.trs ; do echo \\\"===---=== $F :\\\"; cat \\\"$F\\\"; done; exit 1;\" '\n        REM Start a Mingw-based documentation spellcheck:\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; PATH=\"/mingw64/bin:$PATH\" make -s -j 4 spellcheck'\n\n\nafter_test:\n  - cmd: |\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        REM Oh the joys of shell scripting with strings passed through CMD:\n        REM Note: currently Python installation path with MSYS is buggy [#1584]\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; if ! rm -rf \".inst\" ; then echo \"WARNING: Failed to clean away .inst\" ; fi ; PATH=\"/mingw64/bin:$PATH\" make -s install-win-bundle DESTDIR=\"`pwd`/.inst/NUT-for-Windows-x86_64-SNAPSHOT-%APPVEYOR_BUILD_VERSION%\" ; ln -fs \"NUT-for-Windows-x86_64-SNAPSHOT-%APPVEYOR_BUILD_VERSION%\" ./.inst/NUT-for-Windows-x86_64-SNAPSHOT ; ( cd .inst/NUT-for-Windows-x86_64-SNAPSHOT ; find . -ls ; )'\n        cd .inst\n        7z a ../NUT-for-Windows-x86_64-SNAPSHOT-%APPVEYOR_BUILD_VERSION%.7z NUT*\n  - cmd: |\n        REM Preserve the current working directory:\n        set CHERE_INVOKING=yes\n        REM Start a 64 bit Mingw environment:\n        set MSYSTEM=MINGW64\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; PATH=\"/mingw64/bin:$PATH\" ; export PATH ; ccache -sv || ccache -s || echo \"SKIP: Could not query ccache stats\"'\n        C:\\msys64\\usr\\bin\\bash -lc 'date -u; PATH=\"/mingw64/bin:$PATH\" ; export PATH ; ccache -x || echo \"SKIP: Could not query ccache compression stats\"'\n\n\nartifacts:\n  - path: 'NUT-for-Windows*.7z'\n    name: Bundle of binary files and FOSS dependencies of NUT for Windows\n\n  - path: config.log\n    name: config.log of recent build of NUT for Windows\n\n  - path: config.nut_report_feature.log\n    name: config.nut_report_feature.log of recent build of NUT for Windows\n\n# Example optional cache (depends on file change):\n# - C:\\msys64 -> appveyor.yml\ncache:\n  - C:\\msys64\\home\\appveyor\\.ccache\n  - C:\\msys64\\home\\appveyor\\ccache # likely missing, no problem - but the name is reported in ccache status\n  - C:\\Users\\appveyor\\AppData\\Local\\ccache # may be default in newer versions\n  - C:\\Users\\appveyor\\AppData\\Local\\.ccache # may be missing, but for completeness like above\n  - C:\\msys64\\var\\cache\\pacman\\pkg\n  - C:\\msys64\\home\\appveyor\\nut-win-deps\n\n# Below we tried to stash binaries of MSYS2 environment\n# so VM deployment is faster on subsequent builds\n# (update/install \"from scratch\" costs about 3 min),\n# but unstashing the archive takes comparable time\n# and often leads to conflicts in pacman book-keeping,\n# while creating/updating the archive costs ~10 min.\n  #- C:\\msys64\\var\\lib\\pacman\n  #- C:\\msys64\\var\\lib\n  #- C:\\msys64\\mingw64\n  #- C:\\msys64\\mingw32\n  #- C:\\msys64\\ucrt64\n  #- C:\\msys64\\clang32\n  #- C:\\msys64\\clang64\n  #- C:\\msys64\\clangarm64\n  #- C:\\msys64\\usr\n  #- C:\\msys64\\bin\n  #- C:\\msys64\\etc\n  #- C:\\msys64\\*.*\n  #- C:\\msys64\\installerResources\n"
        },
        {
          "name": "autogen.sh",
          "type": "blob",
          "size": 9.7919921875,
          "content": "#! /bin/sh\n#\n# Autoreconf wrapper script to ensure that the source tree is\n# in a buildable state\n# NOTE: uses cumbersome dumbest-possible shell syntax for extra portability\n\n# perl tends to complain if locale is not set (or its files are absent)\nif [ -z \"${LANG-}\" ]; then\n\tLANG=\"C\"\n\texport LANG\nfi\n\nif [ -z \"${LC_ALL-}\" ] ; then\n\tLC_ALL=\"C\"\n\texport LC_ALL\nfi\n\nVERBOSE_FLAG=\"\"\nif [ x\"${DEBUG-}\" = xtrue ] || [ x\"${CI_DEBUG-}\" = xtrue ] || [ x\"$1\" = x-v ] ; then\n\tDEBUG=true\n\tVERBOSE_FLAG=\"-v\"\n\techo \"NUT script $0 will call the tools with higher debug verbosity\"\nelse\n\tDEBUG=false\nfi\n\nNUT_VERSION_QUERY=UPDATE_FILE \"`dirname $0`\"/tools/gitlog2version.sh\n\nif [ -n \"${PYTHON-}\" ] ; then\n\t# May be a name/path of binary, or one with args - check both\n\t(command -v \"$PYTHON\") \\\n\t|| $PYTHON -c \"import re,glob,codecs\" \\\n\t|| {\n\t\techo \"----------------------------------------------------------------------\"\n\t\techo \"WARNING: Caller-specified PYTHON='$PYTHON' is not available.\"\n\t\techo \"----------------------------------------------------------------------\"\n\t\t# Do not die just here, we may not need the interpreter\n\t}\nelse\n\t$DEBUG && echo \"=== Picking usable Python version...\"\n\tPYTHON=\"\"\n\t# FIXME: Use something like TAB-completion to find every name on PATH?\n\tfor P in python python3 python2 \\\n\t\tpython-3.14 python3.14 \\\n\t\tpython-3.13 python3.13 \\\n\t\tpython-3.12 python3.12 \\\n\t\tpython-3.11 python3.11 \\\n\t\tpython-3.10 python3.10 \\\n\t\tpython-3.9 python3.9 \\\n\t\tpython-3.7 python3.7 \\\n\t\tpython-3.5 python3.5 \\\n\t\tpython-3.4 python3.4 \\\n\t\tpython-2.7 python2.7 \\\n\t; do\n\t\tif (command -v \"$P\" >/dev/null) && $P $VERBOSE_FLAG -c \"import re,glob,codecs\" ; then\n\t\t\t$DEBUG && echo \"=== Picked usable Python version: $P\"\n\t\t\tPYTHON=\"$P\"\n\t\t\tbreak\n\t\tfi\n\tdone\n\tif $DEBUG && [ -z \"$PYTHON\" ] ; then\n\t\techo \"=== Did not pick any usable Python version\"\n\tfi\nfi\n\nrm -f *.in.AUTOGEN_WITHOUT || true\n\n# re-generate files needed by configure, and created otherwise at 'dist' time\nif [ ! -f scripts/augeas/nutupsconf.aug.in ]\nthen\n\tif [ -n \"${PYTHON-}\" ] && $PYTHON $VERBOSE_FLAG -c \"import re,glob,codecs\"; then\n\t\techo \"Regenerating Augeas ups.conf lens with '$PYTHON'...\"\n\t\t(   # That script is templated; assume @PYTHON@ is the only\n\t\t    # road-bump there\n\t\t    cd scripts/augeas \\\n\t\t    && $PYTHON $VERBOSE_FLAG ./gen-nutupsconf-aug.py.in\n\t\t) || exit 1\n\telse\n\t\techo \"----------------------------------------------------------------------\"\n\t\techo \"Error: Python is not available.\"\n\t\techo \"Unable to regenerate Augeas lens for ups.conf parsing.\"\n\t\techo \"----------------------------------------------------------------------\"\n\t\tif [ \"${WITHOUT_NUT_AUGEAS-}\" = true ]; then\n\t\t\techo \"Proceeding without Augeas integration, be sure to not require it in configure script\" >&2\n\t\t\ttouch scripts/augeas/nutupsconf.aug.in scripts/augeas/nutupsconf.aug.in.AUTOGEN_WITHOUT\n\t\telse\n\t\t\techo \"Aborting $0! To avoid this, please   export WITHOUT_NUT_AUGEAS=true   and re-run\" >&2\n\t\t\techo \"or better yet,    export PYTHON=python-x.y   and re-run\" >&2\n\t\t\texit 1\n\t\tfi\n\tfi\nfi\n\n# Keep in sync with tools/nut-usbinfo.pl outputs:\n# * List actual file opens:\n#    grep -i '\">' tools/nut-usbinfo.pl\n# * List the names involved:\n#    grep -E 'output.*=' tools/nut-usbinfo.pl\n# Also check that the last re-generation is newer than the sources involved\n# (stay on top of CI rebuilds, development, Git branch switching...)\n# Someone please tell me why GNU `find dir -newer X -name Y -o -name Z` does\n# not filter away layer by layer, but rather finds the names Z and beyond\n# (same for the other way around)? Anyway, dumbed down for the most trivial\n# `find` implementations out there...\nif [ ! -f scripts/udev/nut-usbups.rules.in -o \\\n     ! -f scripts/hotplug/libhid.usermap -o \\\n     ! -f scripts/upower/95-upower-hid.hwdb -o \\\n     ! -f scripts/devd/nut-usb.conf.in -o \\\n     ! -f scripts/devd/nut-usb.quirks -o \\\n     ! -f tools/nut-scanner/nutscan-usb.h ] \\\n|| [ -n \"`find drivers -newer scripts/hotplug/libhid.usermap | grep -E '(-hid|nutdrv_qx|usb.*)\\.c'`\" ] \\\n|| [ -n \"`find drivers -not -newer tools/nut-usbinfo.pl | grep -E '(-hid|nutdrv_qx|usb.*)\\.c'`\" ] \\\n; then\n\tif perl -e 1; then\n\t\tVERBOSE_FLAG_PERL=\"\"\n\t\tif $DEBUG ; then\n\t\t\tif perl -d:Devel::Trace -e 1 >/dev/null 2>/dev/null ; then\n\t\t\t\tVERBOSE_FLAG_PERL=\"-d:Devel::Trace\"\n\t\t\telse\n\t\t\t\techo \"=== Can not trace perl, try sudo cpan install 'Devel::Trace'\"\n\t\t\tfi\n\t\tfi\n\t\techo \"Regenerating the USB helper files...\"\n\t\tcd tools && {\n\t\t\tperl $VERBOSE_FLAG_PERL ./nut-usbinfo.pl || exit 1\n\t\t\tcd ..\n\t\t}\n\telse\n\t\techo \"----------------------------------------------------------------------\"\n\t\techo \"Error: Perl is not available.\"\n\t\techo \"Unable to regenerate USB helper files.\"\n\t\techo \"----------------------------------------------------------------------\"\n\t\tif [ \"${WITHOUT_NUT_USBINFO-}\" = true ]; then\n\t\t\techo \"Proceeding without NUT USB Info, be sure to not require it in configure script\" >&2\n\t\t\ttouch scripts/udev/nut-usbups.rules.in scripts/udev/nut-usbups.rules.in.AUTOGEN_WITHOUT\n\t\t\ttouch scripts/devd/nut-usb.conf.in scripts/devd/nut-usb.conf.in.AUTOGEN_WITHOUT\n\t\telse\n\t\t\techo \"Aborting $0! To avoid this, please   export WITHOUT_NUT_USBINFO=true   and re-run\" >&2\n\t\t\texit 1\n\t\tfi\n\tfi\nfi\n\nif [ ! -f scripts/systemd/nut-common-tmpfiles.conf.in ]; then\n\t( echo '# autoconf requires this file exists before generating configure script;'\n\t  echo '# it will be overwritten by running configure during an actual build'\n\t) > scripts/systemd/nut-common-tmpfiles.conf.in\nfi\n\n# now we can safely call autoreconf\nif ( command -v dos2unix ) 2>/dev/null >/dev/null ; then\n\tif ( dos2unix < configure.ac | cmp - configure.ac ) 2>/dev/null >/dev/null ; then\n\t\t:\n\telse\n\t\techo \"WARNING: Did not confirm that configure.ac has Unix EOL markers;\"\n\t\techo \"this may cause issues for m4 parsing with autotools below.\"\n\t\tif [ -f .git ] || [ -d .git ] ; then\n\t\t\techo \"You may want to enforce that Git uses 'lf' line endings and re-checkout:\"\n\t\t\techo \"    :; git config core.autocrlf false && git config core.eol lf && rm .git/index && git checkout -f\"\n\t\tfi\n\t\techo \"\"\n\tfi\nfi >&2\n\n# Required by autoconf for non-\"foreign\" projects;\n# is tracked as a NEWS.adoc for us however.\n[ -f NEWS ] || { echo \"Please see NEWS.adoc for actual contents\" > NEWS; }\n[ -f README ] || { echo \"Please see README.adoc for actual contents\" > README; }\n\n# Try to serve a fresh one at least when we remake from scratch like this\n# Note to not do it forcefully during `configure` or rebuild\nrm -f include/nut_version.h || true\n\necho \"----------------------------------------------------------------------\"\necho \"Please note that on some systems the routine below can complain that \"\necho \"  > configure.ac: warning: AC_INIT: not a literal: m4_esyscmd_s(...)\"\necho \"but still does the right thing about PACKAGE_VERSION and PACKAGE_URL settings.\"\necho \"Check if your distro provides an 'autoconf-archive' package and if it helps.\"\necho \"Please post an issue in NUT bug tracker with platform details if it does not.\"\necho \"----------------------------------------------------------------------\"\n\necho \"Calling autoreconf...\"\nAUTOTOOL_RES=0\nif $DEBUG ; then\n\tautoreconf -iv --warnings=all -d || AUTOTOOL_RES=$?\nelse\n\t# This tool's own verbosity is rather compact (whom it called)\n\t# and not too useful for actual troubleshooting, while not too\n\t# noisy to just disable.\n\tautoreconf -iv || AUTOTOOL_RES=$?\nfi\n\n[ \"$AUTOTOOL_RES\" = 0 ] && [ -s configure ] && [ -x configure ] \\\n|| { cat << EOF\n----------------------------------------------------------------------\nFAILED: did not generate an executable configure script!\n\n# Note: on some systems \"autoreconf\", \"automake\" et al are dispatcher\n# scripts, and need you to explicitly say which version you want, e.g.\n#    export AUTOCONF_VERSION=2.65 AUTOMAKE_VERSION=1.13\n# If you get issues with AC_DISABLE_STATIC make sure you have libtool.\n#\n# If it complains about \"too few\" or \"excess\" \"arguments to builtin ifdef\",\n# check the configure.ac line it refers to and un-comment (or comment away)\n# the third argument for AM_SILENT_RULES check, or comment away the whole\n# \"ifdef\" block if your autotools still would not grok it.\n----------------------------------------------------------------------\nEOF\n\texit 1\n} >&2\n\n# Some autoconf versions may leave \"/bin/sh\" regardless of CONFIG_SHELL\n# which originally was made for \"recheck\" operations\nif [ -n \"${CONFIG_SHELL-}\" ]; then\n\tcase \"${CONFIG_SHELL-}\" in\n\t\t*/*)\t;; # use as is, assume full path\n\t\t*)\n\t\t\tENV_PROG=\"`command -v env`\" 2>/dev/null\n\t\t\tif [ -n \"$ENV_PROG\" -a -x \"$ENV_PROG\" ] ; then\n\t\t\t\techo \"Using '$ENV_PROG' to call unqualified CONFIG_SHELL program name '$CONFIG_SHELL'\" >&2\n\t\t\t\tCONFIG_SHELL=\"$ENV_PROG $CONFIG_SHELL\"\n\t\t\tfi\n\t\t\t;;\n\tesac\n\n\techo \"Injecting caller-provided CONFIG_SHELL='$CONFIG_SHELL' into the script\" >&2\n\techo \"#!${CONFIG_SHELL}\" > configure.tmp\n\tcat configure >> configure.tmp\n\t# keep the original file rights intact\n\tcat configure.tmp > configure\n\trm configure.tmp\nelse\n\tCONFIG_SHELL=\"`head -1 configure | sed 's,^#!,,'`\"\nfi\n\n# NOTE: Unquoted CONFIG_SHELL, may be multi-token\n$CONFIG_SHELL -n configure 2>/dev/null >/dev/null \\\n|| {\n\techo \"----------------------------------------------------------------------\" >&2\n\techo \"FAILED: configure script did not pass shell interpreter syntax checks with $CONFIG_SHELL\" >&2\n\techo \"NOTE: If you are using an older OS release, try executing the script with\" >&2\n\techo \"a more functional shell implementation (dtksh, bash, dash...)\" >&2\n\techo \"You can re-run this script with a CONFIG_SHELL in environment\" >&2\n\techo \"----------------------------------------------------------------------\" >&2\n\texit 1\n}\n\necho \"----------------------------------------------------------------------\"\necho \"SUCCESS: The generated configure script passed shell interpreter syntax checks\"\necho \"Please proceed by running './configure --with-many-desired-options'\"\necho \"For details check './configure --help' or docs/configure.txt in NUT sources\"\necho \"----------------------------------------------------------------------\"\n"
        },
        {
          "name": "builds",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci_build.sh",
          "type": "blob",
          "size": 100.16015625,
          "content": "#!/usr/bin/env bash\n\n################################################################################\n# This file is based on a template used by zproject, but isn't auto-generated. #\n# Its primary use is to automate a number of BUILD_TYPE scenarios for the NUT  #\n# CI farm, but for the same reason it can also be useful to reduce typing for  #\n# reproducible build attempts with NUT development and refactoring workflows.  #\n# Note that it is driven by enviroment variables rather than CLI arguments --  #\n# this approach better suits the practicalities of CI build farm technologies. #\n################################################################################\n\nset -e\nSCRIPTDIR=\"`dirname \"$0\"`\"\nSCRIPTDIR=\"`cd \"$SCRIPTDIR\" && pwd`\"\n\nSCRIPT_PATH=\"${SCRIPTDIR}/`basename $0`\"\nSCRIPT_ARGS=(\"$@\")\n\n# Quick hijack for interactive development like this:\n#   BUILD_TYPE=fightwarn-clang ./ci_build.sh\n# or to quickly hit the first-found errors in a larger matrix\n# (and then easily `make` to iterate fixes), like this:\n#   CI_REQUIRE_GOOD_GITIGNORE=\"false\" CI_FAILFAST=true DO_CLEAN_CHECK=no BUILD_TYPE=fightwarn ./ci_build.sh\n#\n# For out-of-tree builds you can specify a CI_BUILDDIR (absolute or relative\n# to SCRIPTDIR - not current path), or just call .../ci_build.sh while being\n# in a different directory and then it would be used with a warning. This may\n# require that you `make distclean` the original source checkout first:\n#   CI_BUILDDIR=obj BUILD_TYPE=default-all-errors ./ci_build.sh\ncase \"$BUILD_TYPE\" in\n    fightwarn) ;; # for default compiler\n    fightwarn-all)\n        # This recipe allows to test with different (default-named)\n        # compiler suites if available. Primary goal is to see whether\n        # everything is building ok on a given platform, with one shot.\n        TRIED_BUILD=false\n        if (command -v gcc) >/dev/null ; then\n            TRIED_BUILD=true\n            BUILD_TYPE=fightwarn-gcc \"$0\" || exit\n        else\n            echo \"SKIPPING BUILD_TYPE=fightwarn-gcc: compiler not found\" >&2\n        fi\n        if (command -v clang) >/dev/null ; then\n            TRIED_BUILD=true\n            BUILD_TYPE=fightwarn-clang \"$0\" || exit\n        else\n            echo \"SKIPPING BUILD_TYPE=fightwarn-clang: compiler not found\" >&2\n        fi\n        if ! $TRIED_BUILD ; then\n            echo \"FAILED to run: no default-named compilers were found\" >&2\n            exit 1\n        fi\n        exit 0\n        ;;\n    fightwarn-gcc)\n        CC=\"gcc\"\n        CXX=\"g++\"\n        # Avoid \"cpp\" directly as it may be too \"traditional\"\n        #CPP=\"cpp\"\n        CPP=\"gcc -E\"\n        BUILD_TYPE=fightwarn\n        ;;\n    fightwarn-clang)\n        CC=\"clang\"\n        CXX=\"clang++\"\n        if (command -v clang-cpp) >/dev/null 2>/dev/null ; then\n            CPP=\"clang-cpp\"\n        else\n            CPP=\"clang -E\"\n        fi\n        BUILD_TYPE=fightwarn\n        ;;\nesac\n\nif [ \"$BUILD_TYPE\" = fightwarn ]; then\n    # For CFLAGS/CXXFLAGS keep caller or compiler defaults\n    # (including C/C++ revision)\n    BUILD_TYPE=default-all-errors\n    #BUILD_WARNFATAL=yes\n    #   configure => \"yes\" except for antique compilers\n    BUILD_WARNFATAL=auto\n\n    # Current fightwarn goal is to have no warnings at preset level below,\n    # or at the level defaulted with configure.ac (perhaps considering the\n    # compiler version, etc.):\n    #[ -n \"$BUILD_WARNOPT\" ] || BUILD_WARNOPT=hard\n    #[ -n \"$BUILD_WARNOPT\" ] || BUILD_WARNOPT=medium\n    #   configure => default to medium, detect by compiler type\n    [ -n \"$BUILD_WARNOPT\" ] || BUILD_WARNOPT=auto\n\n    # Eventually this constraint would be removed to check all present\n    # SSL implementations since their ifdef-driven codebases differ and\n    # emit varied warnings. But so far would be nice to get the majority\n    # of shared codebase clean first:\n    #[ -n \"$NUT_SSL_VARIANTS\" ] || NUT_SSL_VARIANTS=auto\n\n    # Similarly for libusb implementations with varying support\n    #[ -n \"$NUT_USB_VARIANTS\" ] || NUT_USB_VARIANTS=auto\nfi\n\n# configure default is \"no\"; an \"auto\" value is \"yes unless CFLAGS say something\"\n[ -n \"${BUILD_DEBUGINFO-}\" ] || BUILD_DEBUGINFO=\"\"\n\n# Set this to enable verbose profiling\n[ -n \"${CI_TIME-}\" ] || CI_TIME=\"\"\ncase \"$CI_TIME\" in\n    [Yy][Ee][Ss]|[Oo][Nn]|[Tt][Rr][Uu][Ee])\n        CI_TIME=\"time -p \" ;;\n    [Nn][Oo]|[Oo][Ff][Ff]|[Ff][Aa][Ll][Ss][Ee])\n        CI_TIME=\"\" ;;\nesac\n\n# Set this to enable verbose tracing\n[ -n \"${CI_TRACE-}\" ] || CI_TRACE=\"no\"\ncase \"$CI_TRACE\" in\n    [Nn][Oo]|[Oo][Ff][Ff]|[Ff][Aa][Ll][Ss][Ee])\n        set +x ;;\n    [Yy][Ee][Ss]|[Oo][Nn]|[Tt][Rr][Uu][Ee])\n        set -x ;;\nesac\n\n[ -n \"${CI_REQUIRE_GOOD_GITIGNORE-}\" ] || CI_REQUIRE_GOOD_GITIGNORE=\"true\"\ncase \"$CI_REQUIRE_GOOD_GITIGNORE\" in\n    [Nn][Oo]|[Oo][Ff][Ff]|[Ff][Aa][Ll][Ss][Ee])\n        CI_REQUIRE_GOOD_GITIGNORE=\"false\" ;;\n    [Yy][Ee][Ss]|[Oo][Nn]|[Tt][Rr][Uu][Ee])\n        CI_REQUIRE_GOOD_GITIGNORE=\"true\" ;;\nesac\n\n# Abort loops like BUILD_TYPE=default-all-errors as soon as we have a problem\n# (allowing to rebuild interactively and investigate that set-up)?\n[ -n \"${CI_FAILFAST-}\" ] || CI_FAILFAST=false\n\n# We allow some CI setups to CI_SKIP_CHECK (avoiding it during single-process\n# scripted build), so tests can be done as a visibly separate stage.\n# This does not really apply to some build scenarios whose purpose is to\n# loop and check many build scenarios (e.g. BUILD_TYPE=\"default-all-errors\"\n# and \"fightwarn*\" family), but it is up to caller when and why to set it.\n# It is also a concern of the caller (for now) if actually passing the check\n# relies on something this script does (set envvars, change paths...)\n[ -n \"${CI_SKIP_CHECK-}\" ] || CI_SKIP_CHECK=false\n\n# By default we configure and build in the same directory as source;\n# and a `make distcheck` handles how we build from a tarball.\n# However there are also cases where source is prepared (autogen) once,\n# but is built in various directories with different configurations.\n# This is something to test via CI, that recipes are not broken for\n# such use-case. Note the path should be in .gitignore, e.g. equal to\n# or under ./tmp/ or ./obj/ for the CI_REQUIRE_GOOD_GITIGNORE sanity\n# checks to pass.\ncase \"${CI_BUILDDIR-}\" in\n    \"\") # Not set, likeliest case\n        CI_BUILDDIR=\"`pwd`\"\n        if [ x\"${SCRIPTDIR}\" = x\"${CI_BUILDDIR}\" ] ; then\n            CI_BUILDDIR=\".\"\n        else\n            echo \"=== WARNING: This build will use '${CI_BUILDDIR}'\"\n            echo \"=== for an out-of-tree build of NUT with sources located\"\n            echo \"=== in '${SCRIPTDIR}'\"\n            echo \"=== PRESS CTRL+C NOW if you did not mean this! (Sleeping 5 sec)\"\n\n            sleep 5\n        fi\n        ;;\n    \".\") ;; # Is SCRIPTDIR, in-tree build\n    /*)  ;; # Absolute path located somewhere else\n    *) # Non-trivial, relative to SCRIPTDIR, may not exist yet\n        CI_BUILDDIR=\"${SCRIPTDIR}/${CI_BUILDDIR}\"\n        ;;\nesac\n\n# Just in case we get blanks from CI - consider them as not-set:\nif [ -z \"`echo \"${MAKE-}\" | tr -d ' '`\" ] ; then\n    if [ \"$1\" = spellcheck -o \"$1\" = spellcheck-interactive ] \\\n    && (command -v gmake) >/dev/null 2>/dev/null \\\n    ; then\n        # GNU make processes quiet mode better, which helps with spellcheck use-case\n        MAKE=gmake\n    else\n        # Use system default, there should be one (or fail eventually if not)\n        MAKE=make\n    fi\n    export MAKE\nfi\n\n[ -n \"$GGREP\" ] || GGREP=grep\n\n[ -n \"$MAKE_FLAGS_QUIET\" ] || MAKE_FLAGS_QUIET=\"VERBOSE=0 V=0 -s\"\n[ -n \"$MAKE_FLAGS_VERBOSE\" ] || MAKE_FLAGS_VERBOSE=\"VERBOSE=1 V=1 -s\"\n[ -n \"$MAKE_FLAGS_CLEAN\" ] || MAKE_FLAGS_CLEAN=\"${MAKE_FLAGS_QUIET}\"\n\n# This is where many symlinks like \"gcc -> ../bin/ccache\" reside\n# (note: a \"-\" value requests to NOT use a CI_CCACHE_SYMLINKDIR;\n# ccache may still be used via prefixing if the tool is found in\n# the PATH, unless you export CI_CCACHE_USE=no also):\npropose_CI_CCACHE_SYMLINKDIR() {\n    echo \\\n        \"/usr/lib/ccache\" \\\n        \"/mingw64/lib/ccache/bin\" \\\n        \"/mingw32/lib/ccache/bin\" \\\n        \"/usr/lib64/ccache\" \\\n        \"/usr/libexec/ccache\" \\\n        \"/usr/lib/ccache/bin\" \\\n        \"/usr/local/lib/ccache\"\n\n    if [ -n \"${HOMEBREW_PREFIX-}\" ]; then\n        echo \"${HOMEBREW_PREFIX}/opt/ccache/libexec\"\n    fi\n}\nif [ -z \"${CI_CCACHE_SYMLINKDIR-}\" ] ; then\n    for D in `propose_CI_CCACHE_SYMLINKDIR` ; do\n        if [ -d \"$D\" ] ; then\n            if ( ls -la \"$D\" | grep -e ' -> .*ccache' >/dev/null) \\\n            || ( test -n \"`find \"$D\" -maxdepth 1 -type f -exec grep -li ccache '{}' \\;`\" ) \\\n            ; then\n                CI_CCACHE_SYMLINKDIR=\"$D\" && break\n            else\n                echo \"WARNING: Found potential CI_CCACHE_SYMLINKDIR='$D' but it did not host expected symlink patterns, skipped\" >&2\n            fi\n        fi\n    done\n\n    if [ -n \"${CI_CCACHE_SYMLINKDIR-}\" ] ; then\n        echo \"INFO: Detected CI_CCACHE_SYMLINKDIR='$CI_CCACHE_SYMLINKDIR'; specify another explicitly if desired\" >&2\n    else\n        echo \"WARNING: Did not find any CI_CCACHE_SYMLINKDIR; specify one explicitly if desired\" >&2\n    fi\nelse\n    if [ x\"${CI_CCACHE_SYMLINKDIR-}\" = x- ] ; then\n        echo \"INFO: Empty CI_CCACHE_SYMLINKDIR was explicitly requested\" >&2\n        CI_CCACHE_SYMLINKDIR=\"\"\n    fi\nfi\n\nif [ -z \"$TMPDIR\" ]; then\n    echo \"WARNING: TMPDIR not set, trying to guess\"\n    if [ -d /tmp -a -w /tmp ] ; then\n        TMPDIR=/tmp\n        export TMPDIR\n    fi\nfi\n\nif [ -z \"$TMPDIR\" ]; then\n    echo \"WARNING: TMPDIR still not set, some tools (notably clang) can fail\"\nfi\n\n# For two-phase builds (quick parallel make first, sequential retry if failed)\n# how verbose should that first phase be? Nothing, automake list of ops, CLIs?\n# See build_to_only_catch_errors_target() for a consumer of this setting.\ncase \"${CI_PARMAKE_VERBOSITY-}\" in\n    silent|quiet|verbose|default) ;;\n    *) CI_PARMAKE_VERBOSITY=silent ;;\nesac\n\n# Set up the parallel make with reasonable limits, using several ways to\n# gather and calculate this information. Note that \"psrinfo\" count is not\n# an honest approach (there may be limits of current CPU set etc.) but is\n# a better upper bound than nothing...\n[ -n \"$NCPUS\" ] || { \\\n    NCPUS=\"`/usr/bin/getconf _NPROCESSORS_ONLN`\" || \\\n    NCPUS=\"`/usr/bin/getconf NPROCESSORS_ONLN`\" || \\\n    NCPUS=\"`cat /proc/cpuinfo | grep -wc processor`\" || \\\n    { [ -x /usr/sbin/psrinfo ] && NCPUS=\"`/usr/sbin/psrinfo | wc -l`\"; } \\\n    || NCPUS=1; } 2>/dev/null\n[ x\"$NCPUS\" != x -a \"$NCPUS\" -ge 1 ] || NCPUS=1\n\n[ x\"$NPARMAKES\" = x ] && { NPARMAKES=\"`expr \"$NCPUS\" '*' 2`\" || NPARMAKES=2; }\n[ x\"$NPARMAKES\" != x -a \"$NPARMAKES\" -ge 1 ] || NPARMAKES=2\n[ x\"$MAXPARMAKES\" != x ] && [ \"$MAXPARMAKES\" -ge 1 ] && \\\n    [ \"$NPARMAKES\" -gt \"$MAXPARMAKES\" ] && \\\n    echo \"INFO: Detected or requested NPARMAKES=$NPARMAKES,\" \\\n        \"however a limit of MAXPARMAKES=$MAXPARMAKES was configured\" && \\\n    NPARMAKES=\"$MAXPARMAKES\"\n\n# GNU make allows to limit spawning of jobs by load average of the host,\n# where LA is (roughly) the average amount over the last {timeframe} of\n# queued processes that are ready to compute but must wait for CPU.\n# The rough estimate for VM builders however seems that they always have\n# some non-trivial LA, so we set the default limit per CPU relatively high.\n[ x\"$PARMAKE_LA_LIMIT\" = x ] && PARMAKE_LA_LIMIT=\"`expr $NCPUS '*' 8`\".0\n\n# After all the tunable options above, this is the one which takes effect\n# for actual builds with parallel phases. Specify a whitespace to neuter.\nif [ -z \"$PARMAKE_FLAGS\" ]; then\n    PARMAKE_FLAGS=\"-j $NPARMAKES\"\n    if LANG=C LC_ALL=C \"$MAKE\" --version 2>&1 | grep -E 'GNU Make|Free Software Foundation' > /dev/null ; then\n        PARMAKE_FLAGS=\"$PARMAKE_FLAGS -l $PARMAKE_LA_LIMIT\"\n        echo \"Parallel builds would spawn up to $NPARMAKES jobs (detected $NCPUS CPUs), or peak out at $PARMAKE_LA_LIMIT system load average\" >&2\n    else\n        echo \"Parallel builds would spawn up to $NPARMAKES jobs (detected $NCPUS CPUs)\" >&2\n    fi\nfi\n\n# CI builds on Jenkins\n[ -z \"$NODE_LABELS\" ] || \\\nfor L in $NODE_LABELS ; do\n    case \"$L\" in\n        \"NUT_BUILD_CAPS=cppunit=no\")\n            [ -n \"$CANBUILD_CPPUNIT_TESTS\" ] || CANBUILD_CPPUNIT_TESTS=no ;;\n        \"NUT_BUILD_CAPS=cppunit=no-gcc\")\n            [ -n \"$CANBUILD_CPPUNIT_TESTS\" ] || CANBUILD_CPPUNIT_TESTS=no-gcc ;;\n        \"NUT_BUILD_CAPS=cppunit=no-clang\")\n            [ -n \"$CANBUILD_CPPUNIT_TESTS\" ] || CANBUILD_CPPUNIT_TESTS=no-clang ;;\n        \"NUT_BUILD_CAPS=cppunit\"|\"NUT_BUILD_CAPS=cppunit=yes\")\n            [ -n \"$CANBUILD_CPPUNIT_TESTS\" ] || CANBUILD_CPPUNIT_TESTS=yes ;;\n\n        # This should cover both the --with-nutconf tool setting\n        # and the cppunit tests for it (if active per above).\n        # By default we would nowadays guess (requires C++11).\n        \"NUT_BUILD_CAPS=nutconf=no\")\n            [ -n \"$CANBUILD_NUTCONF\" ] || CANBUILD_NUTCONF=no ;;\n        \"NUT_BUILD_CAPS=nutconf=no-gcc\")\n            [ -n \"$CANBUILD_NUTCONF\" ] || CANBUILD_NUTCONF=no-gcc ;;\n        \"NUT_BUILD_CAPS=nutconf=no-clang\")\n            [ -n \"$CANBUILD_NUTCONF\" ] || CANBUILD_NUTCONF=no-clang ;;\n        \"NUT_BUILD_CAPS=nutconf\"|\"NUT_BUILD_CAPS=nutconf=yes\")\n            [ -n \"$CANBUILD_NUTCONF\" ] || CANBUILD_NUTCONF=yes ;;\n\n        # Some (QEMU) builders have issues running valgrind as a tool\n        \"NUT_BUILD_CAPS=valgrind=no\")\n            [ -n \"$CANBUILD_VALGRIND_TESTS\" ] || CANBUILD_VALGRIND_TESTS=no ;;\n        \"NUT_BUILD_CAPS=valgrind\"|\"NUT_BUILD_CAPS=valgrind=yes\")\n            [ -n \"$CANBUILD_VALGRIND_TESTS\" ] || CANBUILD_VALGRIND_TESTS=yes ;;\n\n        \"NUT_BUILD_CAPS=cppcheck=no\")\n            [ -n \"$CANBUILD_CPPCHECK_TESTS\" ] || CANBUILD_CPPCHECK_TESTS=no ;;\n        \"NUT_BUILD_CAPS=cppcheck\"|\"NUT_BUILD_CAPS=cppcheck=yes\")\n            [ -n \"$CANBUILD_CPPCHECK_TESTS\" ] || CANBUILD_CPPCHECK_TESTS=yes ;;\n\n        # Some workers (presumably where several executors or separate\n        # Jenkins agents) are enabled randomly fail NIT tests, once in\n        # a hundred runs or so. This option allows isolated workers to\n        # proclaim they are safe places to \"make check-NIT\" (and we can\n        # see if that is true, over time).\n        \"NUT_BUILD_CAPS=NIT=no\")\n            [ -n \"$CANBUILD_NIT_TESTS\" ] || CANBUILD_NIT_TESTS=no ;;\n        \"NUT_BUILD_CAPS=NIT\"|\"NUT_BUILD_CAPS=NIT=yes\")\n            [ -n \"$CANBUILD_NIT_TESTS\" ] || CANBUILD_NIT_TESTS=yes ;;\n\n        \"NUT_BUILD_CAPS=docs:man=no\")\n            [ -n \"$CANBUILD_DOCS_MAN\" ] || CANBUILD_DOCS_MAN=no ;;\n        \"NUT_BUILD_CAPS=docs:man\"|\"NUT_BUILD_CAPS=docs:man=yes\")\n            [ -n \"$CANBUILD_DOCS_MAN\" ] || CANBUILD_DOCS_MAN=yes ;;\n\n        \"NUT_BUILD_CAPS=docs:all=no\")\n            [ -n \"$CANBUILD_DOCS_ALL\" ] || CANBUILD_DOCS_ALL=no ;;\n        \"NUT_BUILD_CAPS=docs:all\"|\"NUT_BUILD_CAPS=docs:all=yes\")\n            [ -n \"$CANBUILD_DOCS_ALL\" ] || CANBUILD_DOCS_ALL=yes ;;\n\n        \"NUT_BUILD_CAPS=drivers:all=no\")\n            [ -n \"$CANBUILD_DRIVERS_ALL\" ] || CANBUILD_DRIVERS_ALL=no ;;\n        \"NUT_BUILD_CAPS=drivers:all\"|\"NUT_BUILD_CAPS=drivers:all=yes\")\n            [ -n \"$CANBUILD_DRIVERS_ALL\" ] || CANBUILD_DRIVERS_ALL=yes ;;\n\n        \"NUT_BUILD_CAPS=cgi=no\")\n            [ -n \"$CANBUILD_LIBGD_CGI\" ] || CANBUILD_LIBGD_CGI=no ;;\n        \"NUT_BUILD_CAPS=cgi\"|\"NUT_BUILD_CAPS=cgi=yes\")\n            [ -n \"$CANBUILD_LIBGD_CGI\" ] || CANBUILD_LIBGD_CGI=yes ;;\n\n        # Currently for nut-scanner, might be more later - hence agnostic naming:\n        \"NUT_BUILD_CAPS=libltdl=no\")\n            [ -n \"$CANBUILD_WITH_LIBLTDL\" ] || CANBUILD_WITH_LIBLTDL=no ;;\n        \"NUT_BUILD_CAPS=libltdl\"|\"NUT_BUILD_CAPS=libltdl=yes\")\n            [ -n \"$CANBUILD_WITH_LIBLTDL\" ] || CANBUILD_WITH_LIBLTDL=yes ;;\n    esac\ndone\n\nif [ -z \"$CI_OS_NAME\" ]; then\n    # Check for dynaMatrix node labels support and map into a simple\n    # classification styled after (compatible with) that in Travis CI\n    for CI_OS_HINT in \\\n        \"$OS_FAMILY-$OS_DISTRO\" \\\n        \"`grep = /etc/os-release 2>/dev/null`\" \\\n        \"`cat /etc/release 2>/dev/null`\" \\\n        \"`uname -o 2>/dev/null`\" \\\n        \"`uname -s -r -v 2>/dev/null`\" \\\n        \"`uname -a`\" \\\n        \"`uname`\" \\\n    ; do\n        [ -z \"$CI_OS_HINT\" -o \"$CI_OS_HINT\" = \"-\" ] || break\n    done\n\n    case \"`echo \"$CI_OS_HINT\" | tr 'A-Z' 'a-z'`\" in\n        *freebsd*)\n            CI_OS_NAME=\"freebsd\" ;;\n        *openbsd*)\n            CI_OS_NAME=\"openbsd\" ;;\n        *netbsd*)\n            CI_OS_NAME=\"netbsd\" ;;\n        *debian*|*ubuntu*)\n            CI_OS_NAME=\"debian\" ;;\n        *centos*|*fedora*|*redhat*|*rhel*)\n            CI_OS_NAME=\"centos\" ;;\n        *linux*)\n            CI_OS_NAME=\"linux\" ;;\n        *msys2*)\n            CI_OS_NAME=\"windows-msys2\" ;;\n        *mingw*64*)\n            CI_OS_NAME=\"windows-mingw64\" ;;\n        *mingw*32*)\n            CI_OS_NAME=\"windows-mingw32\" ;;\n        *windows*)\n            CI_OS_NAME=\"windows\" ;;\n        *[Mm]ac*|*arwin*|*[Oo][Ss][Xx]*)\n            CI_OS_NAME=\"osx\" ;;\n        *openindiana*)\n            CI_OS_NAME=\"openindiana\" ;;\n        *omnios*)\n            CI_OS_NAME=\"omnios\" ;;\n        *bsd*)\n            CI_OS_NAME=\"bsd\" ;;\n        *illumos*)\n            CI_OS_NAME=\"illumos\" ;;\n        *solaris*)\n            CI_OS_NAME=\"solaris\" ;;\n        *sunos*)\n            CI_OS_NAME=\"sunos\" ;;\n        \"-\") ;;\n        *)  echo \"WARNING: Could not recognize CI_OS_NAME from CI_OS_HINT='$CI_OS_HINT', update './ci_build.sh' if needed\" >&2\n            if [ \"$OS_FAMILY-$OS_DISTRO\" != \"-\" ]; then\n                echo \"WARNING: I was told that OS_FAMILY='$OS_FAMILY' and OS_DISTRO='$OS_DISTRO'\" >&2\n            fi\n            ;;\n    esac\n    [ -z \"$CI_OS_NAME\" ] || echo \"INFO: Detected CI_OS_NAME='$CI_OS_NAME'\" >&2\nfi\n\n# CI builds on Travis\n[ -n \"$CI_OS_NAME\" ] || CI_OS_NAME=\"$TRAVIS_OS_NAME\"\n\ncase \"${CI_OS_NAME}\" in\n\twindows*)\n\t\t# At the moment WIN32 builds are quite particular in their\n\t\t# desires, for headers to declare what is needed, and yet\n\t\t# there is currently not much real variation in supportable\n\t\t# build environment (mingw variants). Lest we hardcode\n\t\t# stuff in configure script, define some here:\n\t\tcase \"$CFLAGS\" in\n\t\t\t*-D_POSIX=*) ;;\n\t\t\t*) CFLAGS=\"$CFLAGS -D_POSIX=1\" ;;\n\t\tesac\n\t\tcase \"$CFLAGS\" in\n\t\t\t*-D_POSIX_C_SOURCE=*) ;;\n\t\t\t*) CFLAGS=\"$CFLAGS -D_POSIX_C_SOURCE=200112L\" ;;\n\t\tesac\n\t\tcase \"$CFLAGS\" in\n\t\t\t*-D_WIN32_WINNT=*) ;;\n\t\t\t*) CFLAGS=\"$CFLAGS -D_WIN32_WINNT=0xffff\" ;;\n\t\tesac\n\n\t\tcase \"$CXXFLAGS\" in\n\t\t\t*-D_POSIX=*) ;;\n\t\t\t*) CXXFLAGS=\"$CXXFLAGS -D_POSIX=1\" ;;\n\t\tesac\n\t\tcase \"$CXXFLAGS\" in\n\t\t\t*-D_POSIX_C_SOURCE=*) ;;\n\t\t\t*) CXXFLAGS=\"$CXXFLAGS -D_POSIX_C_SOURCE=200112L\" ;;\n\t\tesac\n\t\tcase \"$CXXFLAGS\" in\n\t\t\t*-D_WIN32_WINNT=*) ;;\n\t\t\t*) CXXFLAGS=\"$CXXFLAGS -D_WIN32_WINNT=0xffff\" ;;\n\t\tesac\n\t\t;;\nesac\n\n# Analyze some environmental choices\nif [ -z \"${CANBUILD_LIBGD_CGI-}\" ]; then\n    # No prereq dll and headers on win so far\n    [[ \"$CI_OS_NAME\" = \"windows\" ]] && CANBUILD_LIBGD_CGI=no\n\n    # NUT CI farm with Jenkins can build it; Travis could not\n    [[ \"$CI_OS_NAME\" = \"freebsd\" ]] && CANBUILD_LIBGD_CGI=yes \\\n    || { [[ \"$TRAVIS_OS_NAME\" = \"freebsd\" ]] && CANBUILD_LIBGD_CGI=no ; }\n\n    # See also below for some compiler-dependent decisions\nfi\n\nif [ -z \"${PKG_CONFIG-}\" ]; then\n    # Default to using one from PATH, if any - mostly for config tuning done\n    # below in this script\n    # DO NOT \"export\" it here so configure script can find one for the build\n    PKG_CONFIG=\"pkg-config\"\nfi\n\n# Would hold full path to the CONFIGURE_SCRIPT=\"${SCRIPTDIR}/${CONFIGURE_SCRIPT_FILENAME}\"\nCONFIGURE_SCRIPT=\"\"\nautogen_get_CONFIGURE_SCRIPT() {\n    # Autogen once (delete the file if some scenario ever requires to re-autogen)\n    if [ -n \"${CONFIGURE_SCRIPT}\" -a -s \"${CONFIGURE_SCRIPT}\" ] ; then return 0 ; fi\n\n    pushd \"${SCRIPTDIR}\" || exit\n\n    if [[ \"$CI_OS_NAME\" == \"windows\" ]] ; then\n        # Debug once\n        [ -n \"$CONFIGURE_SCRIPT\" ] || find . -ls\n        CONFIGURE_SCRIPT=\"configure.bat\"\n    else\n        CONFIGURE_SCRIPT=\"configure\"\n    fi\n\n    if [ ! -s \"./$CONFIGURE_SCRIPT\" ]; then\n        # Note: modern auto(re)conf requires pkg-config to generate the configure\n        # script, so to stage the situation of building without one (as if on an\n        # older system) we have to remove it when we already have the script.\n        # This matches the use-case of distro-building from release tarballs that\n        # include all needed pre-generated files to rely less on OS facilities.\n        if [ \"$CI_OS_NAME\" = \"windows\" ] ; then\n            $CI_TIME ./autogen.sh || true\n        else\n            $CI_TIME ./autogen.sh ### 2>/dev/null\n        fi || exit\n    fi\n\n    # Retain the full path to configure script file\n    CONFIGURE_SCRIPT=\"${SCRIPTDIR}/${CONFIGURE_SCRIPT}\"\n\n    popd || exit\n}\n\nconfigure_CI_BUILDDIR() {\n    autogen_get_CONFIGURE_SCRIPT\n\n    if [ \"${CI_BUILDDIR}\" != \".\" ]; then\n        # Per above, we always start this routine in absolute $SCRIPTDIR\n        echo \"=== Running NUT build out-of-tree in ${CI_BUILDDIR}\"\n        mkdir -p \"${CI_BUILDDIR}\" && cd \"${CI_BUILDDIR}\" || exit\n    fi\n}\n\nconfigure_nut() {\n    configure_CI_BUILDDIR\n\n    # Note: maintainer-clean checks remove this, and then some systems'\n    # build toolchains noisily complain about missing LD path candidate\n    if [ -n \"$BUILD_PREFIX\" ]; then\n        # tmp/lib/\n        mkdir -p \"$BUILD_PREFIX\"/lib\n    fi\n    if [ -n \"$INST_PREFIX\" ]; then\n        # .inst/\n        mkdir -p \"$INST_PREFIX\"\n    fi\n\n    # Help copy-pasting build setups from CI logs to terminal:\n    local CONFIG_OPTS_STR=\"`for F in \"${CONFIG_OPTS[@]}\" ; do echo \"'$F' \" ; done`\" ### | tr '\\n' ' '`\"\n    while : ; do # Note the CI_SHELL_IS_FLAKY=true support below\n      echo \"=== CONFIGURING NUT: $CONFIGURE_SCRIPT ${CONFIG_OPTS_STR}\"\n      echo \"=== CC='$CC' CXX='$CXX' CPP='$CPP'\"\n      [ -z \"${CI_SHELL_IS_FLAKY-}\" ] || echo \"=== CI_SHELL_IS_FLAKY='$CI_SHELL_IS_FLAKY'\"\n      $CI_TIME $CONFIGURE_SCRIPT \"${CONFIG_OPTS[@]}\" \\\n      && echo \"$0: configure phase complete (0)\" >&2 \\\n      && return 0 \\\n      || { RES_CFG=$?\n        echo \"$0: configure phase complete ($RES_CFG)\" >&2\n        echo \"FAILED ($RES_CFG) to configure nut, will dump config.log in a second to help troubleshoot CI\" >&2\n        echo \"    (or press Ctrl+C to abort now if running interactively)\" >&2\n        sleep 5\n        echo \"=========== DUMPING config.log :\"\n        $GGREP -B 100 -A 1 'Cache variables' config.log 2>/dev/null \\\n        || cat config.log || true\n        echo \"=========== END OF config.log\"\n\n        if [ \"${CI_SHELL_IS_FLAKY-}\" = true ]; then\n            # Real-life story from the trenches: there are weird systems\n            # which fail ./configure in random spots not due to script's\n            # quality. Then we'd just loop here.\n            echo \"WOULD BE FATAL: FAILED ($RES_CFG) to $CONFIGURE_SCRIPT ${CONFIG_OPTS[*]} -- but asked to loop trying\" >&2\n        else\n            echo \"FATAL: FAILED ($RES_CFG) to $CONFIGURE_SCRIPT ${CONFIG_OPTS[*]}\" >&2\n            echo \"If you are sure this is not a fault of scripting or config option, try\" >&2\n            echo \"    CI_SHELL_IS_FLAKY=true $0\"\n            exit $RES_CFG\n        fi\n       }\n    done\n}\n\nbuild_to_only_catch_errors_target() {\n    if [ $# = 0 ]; then\n        # Re-enter with an arg list\n        build_to_only_catch_errors_target all ; return $?\n    fi\n\n    # Sub-shells to avoid crashing with \"unhandled\" faults in \"set -e\" mode:\n    ( echo \"`date`: Starting the parallel build attempt (quietly to build what we can) for '$@' ...\"; \\\n      if [ -n \"$PARMAKE_FLAGS\" ]; then\n        echo \"For parallel builds, '$PARMAKE_FLAGS' options would be used\"\n      fi\n      if [ -n \"$MAKEFLAGS\" ]; then\n        echo \"Generally, MAKEFLAGS='$MAKEFLAGS' options would be passed\"\n      fi\n      ( case \"${CI_PARMAKE_VERBOSITY}\" in\n        silent)\n          # Note: stderr would still expose errors and warnings (needed for\n          # e.g. CI analysis of coding issues, even if not treated as fatal)\n          $CI_TIME $MAKE $MAKE_FLAGS_QUIET -k $PARMAKE_FLAGS \"$@\" >/dev/null ;;\n        quiet)\n          $CI_TIME $MAKE $MAKE_FLAGS_QUIET -k $PARMAKE_FLAGS \"$@\" ;;\n        silent)\n          $CI_TIME $MAKE $MAKE_FLAGS_VERBOSE -k $PARMAKE_FLAGS \"$@\" ;;\n        default)\n          $CI_TIME $MAKE -k $PARMAKE_FLAGS \"$@\" ;;\n      esac ) && echo \"`date`: SUCCESS\" ; ) || \\\n    ( RET=$?\n      if [ \"$CI_FAILFAST\" = true ]; then\n        echo \"===== Aborting after parallel build attempt failure for '$*' because CI_FAILFAST=$CI_FAILFAST\" >&2\n        exit $RET\n      fi\n      echo \"`date`: Starting the sequential build attempt (to list remaining files with errors considered fatal for this build configuration) for '$@'...\"; \\\n      $CI_TIME $MAKE $MAKE_FLAGS_VERBOSE \"$@\" -k ) || return $?\n    return 0\n}\n\nbuild_to_only_catch_errors_check() {\n    # Specifically run (an optional) \"make check\"\n    if [ \"${CI_SKIP_CHECK}\" = true ] ; then\n        echo \"`date`: SKIP: not starting a '$MAKE check' for quick sanity test of the products built with the current compiler and standards, because caller requested CI_SKIP_CHECK=true; plain build has just succeeded however\"\n        return 0\n    fi\n\n    echo \"`date`: Starting a '$MAKE check' for quick sanity test of the products built with the current compiler and standards\"\n    $CI_TIME $MAKE $MAKE_FLAGS_QUIET check \\\n    && echo \"`date`: SUCCESS\" \\\n    || return $?\n\n    return 0\n}\n\nbuild_to_only_catch_errors() {\n    build_to_only_catch_errors_target all || return $?\n    build_to_only_catch_errors_check || return $?\n    return 0\n}\n\nccache_stats() {\n    local WHEN=\"$1\"\n    [ -n \"$WHEN\" ] || WHEN=\"some time around the\"\n    if [ \"$HAVE_CCACHE\" = yes ]; then\n        if [ -d \"$CCACHE_DIR\" ]; then\n            echo \"CCache stats $WHEN build:\"\n            ccache -s || true\n            # Some ccache versions support compression stats\n            # This may take time on slower systems however\n            # (and/or with larger cache contents) => off by default\n            if [ x\"${CI_CCACHE_STATS_COMPRESSION-}\" = xtrue ]; then\n                ccache -x 2>/dev/null || true\n            fi\n        else\n            echo \"WARNING: CCache stats $WHEN build: tool is enabled, but CCACHE_DIR='$CCACHE_DIR' was not found now\" >&2\n        fi\n    fi\n    return 0\n}\n\ncheck_gitignore() {\n    # Optional envvars from caller: FILE_DESCR FILE_REGEX FILE_GLOB\n    # and GIT_ARGS GIT_DIFF_SHOW\n    local BUILT_TARGETS=\"$@\"\n\n    [ -n \"${FILE_DESCR-}\" ] || FILE_DESCR=\"some\"\n    # Note: regex actually used starts with catching Git markup, so\n    # FILE_REGEX should not include that nor \"^\" line-start marker.\n    # We also rule out files made by CI routines and this script.\n    # NOTEL: In particular, we need build results of `make cppcheck`\n    # later, so its recipe does not clean nor care for gitignore.\n    [ -n \"${FILE_REGEX-}\" ] || FILE_REGEX='.*'\n    # Shell-glob filename pattern for points of interest to git status\n    # and git diff; note that filenames starting with a dot should be\n    # reported by `git status -- '*'` and not hidden.\n    [ -n \"${FILE_GLOB-}\" ] || FILE_GLOB=\"'*'\"\n    # Always filter these names away:\n    FILE_GLOB_EXCLUDE=\"':!.ci*.log*' ':!VERSION_DEFAULT' ':!VERSION_FORCED*'\"\n    [ -n \"${GIT_ARGS-}\" ] || GIT_ARGS='' # e.g. GIT_ARGS=\"--ignored\"\n    # Display contents of the diff?\n    # (Helps copy-paste from CI logs to source to amend quickly)\n    [ -n \"${GIT_DIFF_SHOW-}\" ] || GIT_DIFF_SHOW=true\n    [ -n \"${BUILT_TARGETS-}\" ] || BUILT_TARGETS=\"all? (usual default)\"\n\n    echo \"=== Are GitIgnores good after '$MAKE $BUILT_TARGETS'? (should have no output below)\"\n    if [ ! -e .git ]; then\n        echo \"WARNING: Skipping the GitIgnores check after '$BUILT_TARGETS' because there is no `pwd`/.git anymore\" >&2\n        return 0\n    fi\n\n    # One invocation should report to log if there was any discrepancy\n    # to report in the first place (GITOUT may be empty without error):\n    GITOUT=\"`git status $GIT_ARGS -s -- ${FILE_GLOB} ${FILE_GLOB_EXCLUDE}`\" \\\n    || { echo \"WARNING: Could not query git repo while in `pwd`\" >&2 ; GITOUT=\"\"; }\n\n    if [ -n \"${GITOUT-}\" ] ; then\n        echo \"$GITOUT\" \\\n        | grep -E \"${FILE_REGEX}\"\n    else\n        echo \"Got no output and no errors querying git repo while in `pwd`: seems clean\" >&2\n    fi\n    echo \"===\"\n\n    # Another invocation checks that there was nothing to complain about:\n    if [ -n \"`git status $GIT_ARGS -s ${FILE_GLOB} ${FILE_GLOB_EXCLUDE} | grep -E \"^.. ${FILE_REGEX}\"`\" ] \\\n    && [ \"$CI_REQUIRE_GOOD_GITIGNORE\" != false ] \\\n    ; then\n        echo \"FATAL: There are changes in $FILE_DESCR files listed above - tracked sources should be updated in the PR (even if generated - not all builders can do so), and build products should be added to a .gitignore file, everything made should be cleaned and no tracked files should be removed! You can 'export CI_REQUIRE_GOOD_GITIGNORE=false' if appropriate.\" >&2\n        if [ \"$GIT_DIFF_SHOW\" = true ]; then\n            PAGER=cat git diff -- ${FILE_GLOB} ${FILE_GLOB_EXCLUDE} || true\n        fi\n        echo \"===\"\n        return 1\n    fi\n    return 0\n}\n\nconsider_cleanup_shortcut() {\n    # Note: modern auto(re)conf requires pkg-config to generate the configure\n    # script, so to stage the situation of building without one (as if on an\n    # older system) we have to remove it when we already have the script.\n    # This matches the use-case of distro-building from release tarballs that\n    # include all needed pre-generated files to rely less on OS facilities.\n    DO_REGENERATE=false\n    if [ x\"${CI_REGENERATE}\" = xtrue ] ; then\n        echo \"=== Starting initial clean-up (from old build products): TAKING SHORTCUT because CI_REGENERATE='${CI_REGENERATE}'\"\n        DO_REGENERATE=true\n    fi\n\n    if [ -s Makefile ]; then\n        if [ -n \"`find \"${SCRIPTDIR}\" -name configure.ac -newer \"${CI_BUILDDIR}\"/configure`\" ] \\\n        || [ -n \"`find \"${SCRIPTDIR}\" -name '*.m4' -newer \"${CI_BUILDDIR}\"/configure`\" ] \\\n        || [ -n \"`find \"${SCRIPTDIR}\" -name Makefile.am -newer \"${CI_BUILDDIR}\"/Makefile`\" ] \\\n        || [ -n \"`find \"${SCRIPTDIR}\" -name Makefile.in -newer \"${CI_BUILDDIR}\"/Makefile`\" ] \\\n        || [ -n \"`find \"${SCRIPTDIR}\" -name Makefile.am -newer \"${CI_BUILDDIR}\"/Makefile.in`\" ] \\\n        ; then\n            # Avoid reconfiguring just for the sake of distclean\n            echo \"=== Starting initial clean-up (from old build products): TAKING SHORTCUT because recipes changed\"\n            DO_REGENERATE=true\n        fi\n    fi\n\n    # When itertating configure.ac or m4 sources, we can end up with an\n    # existing but useless scropt file - nuke it and restart from scratch!\n    if [ -s \"${CI_BUILDDIR}\"/configure ] ; then\n        if ! sh -n \"${CI_BUILDDIR}\"/configure 2>/dev/null ; then\n            echo \"=== Starting initial clean-up (from old build products): TAKING SHORTCUT because current configure script syntax is broken\"\n            DO_REGENERATE=true\n        fi\n    fi\n\n    if $DO_REGENERATE ; then\n        rm -f \"${CI_BUILDDIR}\"/Makefile \"${CI_BUILDDIR}\"/configure \"${CI_BUILDDIR}\"/include/config.h \"${CI_BUILDDIR}\"/include/config.h.in \"${CI_BUILDDIR}\"'/include/config.h.in~'\n    fi\n}\n\ncan_clean_check() {\n    if [ \"${DO_CLEAN_CHECK-}\" = \"no\" ] ; then\n        # NOTE: Not handling here particular DO_MAINTAINER_CLEAN_CHECK or DO_DIST_CLEAN_CHECK\n        return 1\n    fi\n    if [ -s Makefile ] && [ -e .git ] ; then\n        return 0\n    fi\n    return 1\n}\n\noptional_maintainer_clean_check() {\n    if [ ! -e .git ]; then\n        echo \"Skipping maintainer-clean check because there is no .git\" >&2\n        return 0\n    fi\n\n    if [ ! -e Makefile ]; then\n        echo \"WARNING: Skipping maintainer-clean check because there is no Makefile (did we clean in a loop earlier?)\" >&2\n        return 0\n    fi\n\n    if [ \"${DO_CLEAN_CHECK-}\" = \"no\" ] || [ \"${DO_MAINTAINER_CLEAN_CHECK-}\" = \"no\" ] ; then\n        echo \"Skipping maintainer-clean check because recipe/developer said so\"\n    else\n        [ -z \"$CI_TIME\" ] || echo \"`date`: Starting maintainer-clean check of currently tested project...\"\n\n        # Note: currently Makefile.am has just a dummy \"distcleancheck\" rule\n        case \"$MAKE_FLAGS $DISTCHECK_FLAGS $PARMAKE_FLAGS $MAKE_FLAGS_CLEAN\" in\n        *V=0*)\n            $CI_TIME $MAKE DISTCHECK_FLAGS=\"$DISTCHECK_FLAGS\" $PARMAKE_FLAGS $MAKE_FLAGS_CLEAN maintainer-clean > /dev/null || return\n            ;;\n        *)\n            $CI_TIME $MAKE DISTCHECK_FLAGS=\"$DISTCHECK_FLAGS\" $PARMAKE_FLAGS $MAKE_FLAGS_CLEAN maintainer-clean || return\n        esac\n\n        GIT_ARGS=\"--ignored\" check_gitignore \"maintainer-clean\" || return\n    fi\n\n    return 0\n}\n\noptional_dist_clean_check() {\n    if [ ! -e .git ]; then\n        echo \"Skipping distclean check because there is no .git\" >&2\n        return 0\n    fi\n\n    if [ ! -e Makefile ]; then\n        echo \"WARNING: Skipping distclean check because there is no Makefile (did we clean in a loop earlier?)\" >&2\n        return 0\n    fi\n\n    if [ \"${DO_CLEAN_CHECK-}\" = \"no\" ] || [ \"${DO_DIST_CLEAN_CHECK-}\" = \"no\" ] ; then\n        echo \"Skipping distclean check because recipe/developer said so\"\n    else\n        [ -z \"$CI_TIME\" ] || echo \"`date`: Starting dist-clean check of currently tested project...\"\n\n        # Note: currently Makefile.am has just a dummy \"distcleancheck\" rule\n        $CI_TIME $MAKE DISTCHECK_FLAGS=\"$DISTCHECK_FLAGS\" $PARMAKE_FLAGS $MAKE_FLAGS_CLEAN distclean || return\n\n        check_gitignore \"distclean\" || return\n    fi\n    return 0\n}\n\nif [ \"$1\" = inplace ] && [ -z \"$BUILD_TYPE\" ] ; then\n    shift\n    BUILD_TYPE=\"inplace\"\nfi\n\nif [ \"$1\" = spellcheck -o \"$1\" = spellcheck-interactive ] && [ -z \"$BUILD_TYPE\" ] ; then\n    # Note: this is a little hack to reduce typing\n    # and scrolling in (docs) developer iterations.\n    case \"$CI_OS_NAME\" in\n        windows-msys2)\n            # https://github.com/msys2/MSYS2-packages/issues/2088\n            echo \"==========================================================================\"\n            echo \"WARNING: some MSYS2 builds of aspell are broken with 'tex' support\"\n            echo \"Are you sure you run this in a functional build environment? Ctrl+C if not\"\n            echo \"==========================================================================\"\n            sleep 5\n            ;;\n        *)  if ! (command -v aspell) 2>/dev/null >/dev/null ; then\n                echo \"==========================================================================\"\n                echo \"WARNING: Seems you do not have 'aspell' in PATH (but maybe NUT configure\"\n                echo \"script would find the spellchecking toolkit elsewhere)\"\n                echo \"Are you sure you run this in a functional build environment? Ctrl+C if not\"\n                echo \"==========================================================================\"\n                sleep 5\n            fi\n            ;;\n    esac >&2\n    if [ -s Makefile ] && [ -s docs/Makefile ]; then\n        echo \"Processing quick and quiet spellcheck with already existing recipe files, will only report errors if any ...\"\n        build_to_only_catch_errors_target $1 ; exit\n    else\n        # TODO: Actually do it (default-spellcheck-interactive)?\n        if [ \"$1\" = spellcheck-interactive ] ; then\n            echo \"Only CI-building 'spellcheck', please do the interactive part manually if needed\" >&2\n        fi\n        BUILD_TYPE=\"default-spellcheck\"\n        shift\n    fi\nfi\n\necho \"Processing BUILD_TYPE='${BUILD_TYPE}' ...\"\n\necho \"Build host settings:\"\nset | grep -E '^(PATH|[^ ]*CCACHE[^ ]*|CI_[^ ]*|OS_[^ ]*|CANBUILD_[^ ]*|NODE_LABELS|MAKE|C[^ ]*FLAGS|LDFLAGS|ARCH[^ ]*|BITS[^ ]*|CC|CXX|CPP|DO_[^ ]*|BUILD_[^ ]*)=' || true\nuname -a\necho \"LONG_BIT:`getconf LONG_BIT` WORD_BIT:`getconf WORD_BIT`\" || true\nif command -v xxd >/dev/null ; then xxd -c 1 -l 6 | tail -1; else if command -v od >/dev/null; then od -N 1 -j 5 -b | head -1 ; else hexdump -s 5 -n 1 -C | head -1; fi; fi < /bin/ls 2>/dev/null | awk '($2 == 1){print \"Endianness: LE\"}; ($2 == 2){print \"Endianness: BE\"}' || true\n\ncase \"$BUILD_TYPE\" in\ndefault|default-alldrv|default-alldrv:no-distcheck|default-all-errors|default-spellcheck|default-shellcheck|default-nodoc|default-withdoc|default-withdoc:man|\"default-tgt:\"*)\n    LANG=C\n    LC_ALL=C\n    export LANG LC_ALL\n\n    if [ -d \"./tmp/\" ]; then\n        rm -rf ./tmp/\n    fi\n    if [ -d \"./.inst/\" ]; then\n        rm -rf ./.inst/\n    fi\n\n    # Pre-create locations; tmp/lib in particular to avoid (on MacOS xcode):\n    #   ld: warning: directory not found for option '-L/Users/distiller/project/tmp/lib'\n    # Note that maintainer-clean checks can remove these directory trees,\n    # so we re-create them just in case in the configure_nut() method too.\n    mkdir -p tmp/lib .inst/\n    BUILD_PREFIX=\"$PWD/tmp\"\n    INST_PREFIX=\"$PWD/.inst\"\n\n    echo \"PATH='$PATH' before possibly applying CCACHE into the mix\"\n    ( echo \"$PATH\" | grep ccache ) >/dev/null && echo \"WARNING: ccache is already in PATH\"\n    if [ -n \"$CC\" ]; then\n        echo \"CC='$CC' before possibly applying CCACHE into the mix\"\n        $CC --version $CFLAGS || \\\n        $CC --version || true\n    fi\n\n    if [ -n \"$CXX\" ]; then\n        echo \"CXX='$CXX' before possibly applying CCACHE into the mix\"\n        $CXX --version $CXXFLAGS || \\\n        $CXX --version || true\n    fi\n\n    if [ x\"${CI_CCACHE_USE-}\" = xno ]; then\n        HAVE_CCACHE=no\n        CI_CCACHE_SYMLINKDIR=\"\"\n        echo \"WARNING: Caller required to not use ccache even if available\" >&2\n    else\n        if [ -n \"${CI_CCACHE_SYMLINKDIR}\" ]; then\n            # Tell ccache the PATH without itself in it, to avoid loops processing\n            PATH=\"`echo \"$PATH\" | sed -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,' -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,'`\"\n        fi\n        CCACHE_PATH=\"$PATH\"\n        CCACHE_DIR=\"${HOME}/.ccache\"\n        export CCACHE_PATH CCACHE_DIR PATH\n        HAVE_CCACHE=no\n        if (command -v ccache || which ccache) \\\n        && ( [ -z \"${CI_CCACHE_SYMLINKDIR}\" ] || ls -la \"${CI_CCACHE_SYMLINKDIR}\" ) \\\n        ; then\n            HAVE_CCACHE=yes\n        fi\n        mkdir -p \"${CCACHE_DIR}\"/ || HAVE_CCACHE=no\n    fi\n\n    ccache_stats \"before\"\n\n    CONFIG_OPTS=()\n    COMMON_CFLAGS=\"\"\n    EXTRA_CFLAGS=\"\"\n    EXTRA_CPPFLAGS=\"\"\n    EXTRA_CXXFLAGS=\"\"\n\n    is_gnucc() {\n        if [ -n \"$1\" ] && LANG=C \"$1\" --version 2>&1 | grep 'Free Software Foundation' > /dev/null ; then true ; else false ; fi\n    }\n\n    is_clang() {\n        if [ -n \"$1\" ] && LANG=C \"$1\" --version 2>&1 | grep 'clang version' > /dev/null ; then true ; else false ; fi\n    }\n\n    filter_version() {\n        # Starting with number like \"6.0.0\" or \"7.5.0-il-0\" is fair game,\n        # but a \"gcc-4.4.4-il-4\" (starting with \"gcc\") is not\n        sed -e 's,^.* \\([0-9][0-9]*\\.[0-9][^ ),]*\\).*$,\\1,' -e 's, .*$,,' | grep -E '^[0-9]' | head -1\n    }\n\n    ver_gnucc() {\n        [ -n \"$1\" ] && LANG=C \"$1\" --version 2>&1 | grep -i gcc | filter_version\n    }\n\n    ver_clang() {\n        [ -n \"$1\" ] && LANG=C \"$1\" --version 2>&1 | grep -i 'clang' | filter_version\n    }\n\n    COMPILER_FAMILY=\"\"\n    if [ -n \"$CC\" -a -n \"$CXX\" ]; then\n        if is_gnucc \"$CC\" && is_gnucc \"$CXX\" ; then\n            COMPILER_FAMILY=\"GCC\"\n            export CC CXX\n        elif is_clang \"$CC\" && is_clang \"$CXX\" ; then\n            COMPILER_FAMILY=\"CLANG\"\n            export CC CXX\n        fi\n    else\n        # Generally we prefer GCC unless it is very old so we can't impact\n        # its warnings and complaints.\n        if is_gnucc \"gcc\" && is_gnucc \"g++\" ; then\n            # Autoconf would pick this by default\n            COMPILER_FAMILY=\"GCC\"\n            [ -n \"$CC\" ] || CC=gcc\n            [ -n \"$CXX\" ] || CXX=g++\n            export CC CXX\n        elif is_gnucc \"cc\" && is_gnucc \"c++\" ; then\n            COMPILER_FAMILY=\"GCC\"\n            [ -n \"$CC\" ] || CC=cc\n            [ -n \"$CXX\" ] || CXX=c++\n            export CC CXX\n        fi\n\n        if ( [ \"$COMPILER_FAMILY\" = \"GCC\" ] && \\\n            case \"`ver_gnucc \"$CC\"`\" in\n                [123].*) true ;;\n                4.[0123][.,-]*) true ;;\n                4.[0123]) true ;;\n                *) false ;;\n            esac && \\\n            case \"`ver_gnucc \"$CXX\"`\" in\n                [123].*) true ;;\n                4.[0123][.,-]*) true ;;\n                4.[0123]) true ;;\n                *) false ;;\n            esac\n        ) ; then\n            echo \"NOTE: default GCC here is very old, do we have a CLANG instead?..\" >&2\n            COMPILER_FAMILY=\"GCC_OLD\"\n        fi\n\n        if [ -z \"$COMPILER_FAMILY\" ] || [ \"$COMPILER_FAMILY\" = \"GCC_OLD\" ]; then\n            if is_clang \"clang\" && is_clang \"clang++\" ; then\n                # Autoconf would pick this by default\n                [ \"$COMPILER_FAMILY\" = \"GCC_OLD\" ] && CC=\"\" && CXX=\"\"\n                COMPILER_FAMILY=\"CLANG\"\n                [ -n \"$CC\" ]  || CC=clang\n                [ -n \"$CXX\" ] || CXX=clang++\n                export CC CXX\n            elif is_clang \"cc\" && is_clang \"c++\" ; then\n                [ \"$COMPILER_FAMILY\" = \"GCC_OLD\" ] && CC=\"\" && CXX=\"\"\n                COMPILER_FAMILY=\"CLANG\"\n                [ -n \"$CC\" ]  || CC=cc\n                [ -n \"$CXX\" ] || CXX=c++\n                export CC CXX\n            fi\n        fi\n\n        if [ \"$COMPILER_FAMILY\" = \"GCC_OLD\" ]; then\n            COMPILER_FAMILY=\"GCC\"\n        fi\n    fi\n\n    if [ -n \"$CPP\" ] ; then\n        # Note: can be a multi-token name like \"clang -E\" or just not a full pathname\n        ( [ -x \"$CPP\" ] || $CPP --help >/dev/null 2>/dev/null ) && export CPP\n    else\n        # Avoid \"cpp\" directly as it may be too \"traditional\"\n        case \"$COMPILER_FAMILY\" in\n            CLANG*|GCC*) CPP=\"$CC -E\" && export CPP ;;\n            *) if is_gnucc \"cpp\" ; then\n                CPP=cpp && export CPP\n               fi ;;\n        esac\n    fi\n\n    if [ -z \"${CANBUILD_LIBGD_CGI-}\" ]; then\n        if [[ \"$CI_OS_NAME\" = \"openindiana\" ]] ; then\n            # For some reason, here gcc-4.x (4.4.4, 4.9) have a problem with\n            # configure-time checks of libgd; newer compilers fare okay.\n            # Feel free to revise this if the distro packages are fixed\n            # (or the way configure script and further build uses them).\n            # UPDATE: Per https://github.com/networkupstools/nut/pull/1089\n            # This is a systems issue (in current OpenIndiana 2021.04 built\n            # with a newer GCC version, the older GCC is not ABI compatible\n            # with the libgd shared object file). Maybe this warrants later\n            # caring about not just the CI_OS_NAME but also CI_OS_RELEASE...\n            if [[ \"$COMPILER_FAMILY\" = \"GCC\" ]]; then\n                case \"`LANG=C $CC --version | head -1`\" in\n                    *[\\ -][01234].*)\n                        echo \"WARNING: Seems we are running with gcc-4.x or older on $CI_OS_NAME, which last had known issues with libgd; disabling CGI for this build\"\n                        CANBUILD_LIBGD_CGI=no\n                        ;;\n                    *)\n                        case \"${ARCH}${BITS}${ARCH_BITS}\" in\n                            *64*|*sparcv9*) ;;\n                            *)\n                                # GCC-7 (maybe other older compilers) could default\n                                # to 32-bit builds, and the 32-bit libfontconfig.so\n                                # and libfreetype.so are absent for some years now\n                                # (while libgd.so still claims to exist).\n                                echo \"WARNING: Seems we are running with gcc on $CI_OS_NAME, which last had known issues with libgd on non-64-bit builds; making CGI optional for this build\"\n                                CANBUILD_LIBGD_CGI=auto\n                                ;;\n                        esac\n                        ;;\n                esac\n            else\n                case \"${ARCH}${BITS}${ARCH_BITS}\" in\n                    *64*|*sparcv9*) ;;\n                    *)\n                        echo \"WARNING: Seems we are running with $COMPILER_FAMILY on $CI_OS_NAME, which last had known issues with libgd on non-64-bit builds; making CGI optional for this build\"\n                        CANBUILD_LIBGD_CGI=auto\n                        ;;\n                esac\n            fi\n        fi\n    fi\n\n    DEFAULT_PKG_CONFIG_PATH=\"${BUILD_PREFIX}/lib/pkgconfig\"\n    SYSPKG_CONFIG_PATH=\"\" # Let the OS guess... usually\n    case \"`echo \"$CI_OS_NAME\" | tr 'A-Z' 'a-z'`\" in\n        *openindiana*|*omnios*|*solaris*|*illumos*|*sunos*)\n            case \"$CC$CXX$CFLAGS$CXXFLAGS$LDFLAGS\" in\n                *-m64*)\n                    SYS_PKG_CONFIG_PATH=\"/usr/lib/64/pkgconfig:/usr/lib/amd64/pkgconfig:/usr/lib/sparcv9/pkgconfig:/usr/lib/pkgconfig\"\n                    ;;\n                *-m32*)\n                    SYS_PKG_CONFIG_PATH=\"/usr/lib/32/pkgconfig:/usr/lib/pkgconfig:/usr/lib/i86pc/pkgconfig:/usr/lib/i386/pkgconfig:/usr/lib/sparcv7/pkgconfig\"\n                    ;;\n                *)\n                    case \"${ARCH}${BITS}${ARCH_BITS}\" in\n                        *64*)\n                            SYS_PKG_CONFIG_PATH=\"/usr/lib/64/pkgconfig:/usr/lib/amd64/pkgconfig:/usr/lib/sparcv9/pkgconfig:/usr/lib/pkgconfig\"\n                            ;;\n                        *32*)\n                            SYS_PKG_CONFIG_PATH=\"/usr/lib/32/pkgconfig:/usr/lib/pkgconfig:/usr/lib/i86pc/pkgconfig:/usr/lib/i386/pkgconfig:/usr/lib/sparcv7/pkgconfig\"\n                            ;;\n                    esac\n                    ;;\n            esac\n            ;;\n        *darwin*|*macos*|*osx*)\n            # Architecture-dependent base dir, e.g.\n            # * /usr/local on macos x86\n            # * /opt/homebrew on macos Apple Silicon\n            if [ -n \"${HOMEBREW_PREFIX-}\" -a -d \"${HOMEBREW_PREFIX-}\" ]; then\n                echo \"Homebrew: export general pkg-config location and C/C++/LD flags for the platform\"\n                SYS_PKG_CONFIG_PATH=\"${HOMEBREW_PREFIX}/lib/pkgconfig\"\n                CFLAGS=\"${CFLAGS-} -Wno-poison-system-directories -Wno-deprecated-declarations -isystem ${HOMEBREW_PREFIX}/include -I${HOMEBREW_PREFIX}/include\"\n                #CPPFLAGS=\"${CPPFLAGS-} -Wno-poison-system-directories -Wno-deprecated-declarations -isystem ${HOMEBREW_PREFIX}/include -I${HOMEBREW_PREFIX}/include\"\n                CXXFLAGS=\"${CXXFLAGS-} -Wno-poison-system-directories -isystem ${HOMEBREW_PREFIX}/include -I${HOMEBREW_PREFIX}/include\"\n                LDFLAGS=\"${LDFLAGS-} -L${HOMEBREW_PREFIX}/lib\"\n\n                # Net-SNMP \"clashes\" with system-provided tools (but no header/lib)\n                # so explicit args are needed\n                checkFSobj=\"${HOMEBREW_PREFIX}/opt/net-snmp/lib/pkgconfig\"\n                if [ -d \"$checkFSobj\" -a ! -e \"${HOMEBREW_PREFIX}/lib/pkgconfig/netsnmp.pc\" ] ; then\n                    echo \"Homebrew: export pkg-config location for Net-SNMP\"\n                    SYS_PKG_CONFIG_PATH=\"$SYS_PKG_CONFIG_PATH:$checkFSobj\"\n                    #echo \"Homebrew: export flags for Net-SNMP\"\n                    #CONFIG_OPTS+=(\"--with-snmp-includes=-isystem ${HOMEBREW_PREFIX}/opt/net-snmp/include -I${HOMEBREW_PREFIX}/opt/net-snmp/include\")\n                    #CONFIG_OPTS+=(\"--with-snmp-libs=-L${HOMEBREW_PREFIX}/opt/net-snmp/lib\")\n                fi\n\n                if [ -d \"${HOMEBREW_PREFIX}/opt/net-snmp/include\" -a -d \"${HOMEBREW_PREFIX}/include/openssl\" ]; then\n                    # TODO? Check netsnmp.pc for Libs.private with\n                    #   -L/opt/homebrew/opt/openssl@1.1/lib\n                    # or\n                    #   -L/usr/local/opt/openssl@3/lib\n                    # among other options to derive the exact version\n                    # it wants, and serve that include path here\n                    echo \"Homebrew: export configure options for Net-SNMP with default OpenSSL headers (too intimate on Homebrew)\"\n                    CONFIG_OPTS+=(\"--with-snmp-includes=-isystem ${HOMEBREW_PREFIX}/opt/net-snmp/include -I${HOMEBREW_PREFIX}/opt/net-snmp/include -isystem ${HOMEBREW_PREFIX}/include -I${HOMEBREW_PREFIX}/include\")\n                    CONFIG_OPTS+=(\"--with-snmp-libs=-L${HOMEBREW_PREFIX}/opt/net-snmp/lib -lnetsnmp\")\n                fi\n\n                # A bit hackish to check this outside `configure`, but...\n                if [ -s \"${HOMEBREW_PREFIX-}/include/ltdl.h\" ] ; then\n                    echo \"Homebrew: export flags for LibLTDL\"\n                    # The m4 script clear default CFLAGS/LIBS so benefit from new ones\n                    CONFIG_OPTS+=(\"--with-libltdl-includes=-isystem ${HOMEBREW_PREFIX}/include -I${HOMEBREW_PREFIX}/include\")\n                    CONFIG_OPTS+=(\"--with-libltdl-libs=-L${HOMEBREW_PREFIX}/lib -lltdl\")\n                fi\n\n                if [ -z \"${XML_CATALOG_FILES-}\" ] ; then\n                    checkFSobj=\"${HOMEBREW_PREFIX}/etc/xml/catalog\"\n                    if [ -e \"$checkFSobj\" ] ; then\n                        echo \"Homebrew: export XML_CATALOG_FILES='$checkFSobj' for asciidoc et al\"\n                        XML_CATALOG_FILES=\"$checkFSobj\"\n                        export XML_CATALOG_FILES\n                    fi\n                fi\n            else\n                echo \"WARNING: It seems you are building on MacOS, but HOMEBREW_PREFIX is not set or valid.\"\n                echo 'If you do use this build system, try running   eval \"$(brew shellenv)\"'\n                echo \"in your terminal or shell profile, it can help with auto-detection of some features!\"\n            fi\n            ;;\n    esac\n    if [ -n \"$SYS_PKG_CONFIG_PATH\" ] ; then\n        if [ -n \"$PKG_CONFIG_PATH\" ] ; then\n            PKG_CONFIG_PATH=\"$SYS_PKG_CONFIG_PATH:$PKG_CONFIG_PATH\"\n        else\n            PKG_CONFIG_PATH=\"$SYS_PKG_CONFIG_PATH\"\n        fi\n    fi\n    if [ -n \"$PKG_CONFIG_PATH\" ] ; then\n        CONFIG_OPTS+=(\"PKG_CONFIG_PATH=${DEFAULT_PKG_CONFIG_PATH}:${PKG_CONFIG_PATH}\")\n    else\n        CONFIG_OPTS+=(\"PKG_CONFIG_PATH=${DEFAULT_PKG_CONFIG_PATH}\")\n    fi\n\n    # Note: Potentially there can be spaces in entries for multiple\n    # *FLAGS here; this should be okay as long as entry expands to\n    # one token when calling shell (may not be the case for distcheck)\n    CONFIG_OPTS+=(\"CFLAGS=-I${BUILD_PREFIX}/include ${CFLAGS}\")\n    CONFIG_OPTS+=(\"CPPFLAGS=-I${BUILD_PREFIX}/include ${CPPFLAGS}\")\n    CONFIG_OPTS+=(\"CXXFLAGS=-I${BUILD_PREFIX}/include ${CXXFLAGS}\")\n    CONFIG_OPTS+=(\"LDFLAGS=-L${BUILD_PREFIX}/lib ${LDFLAGS}\")\n\n    CONFIG_OPTS+=(\"--enable-keep_nut_report_feature\")\n    CONFIG_OPTS+=(\"--prefix=${BUILD_PREFIX}\")\n    CONFIG_OPTS+=(\"--sysconfdir=${BUILD_PREFIX}/etc/nut\")\n    CONFIG_OPTS+=(\"--with-udev-dir=${BUILD_PREFIX}/etc/udev\")\n    CONFIG_OPTS+=(\"--with-devd-dir=${BUILD_PREFIX}/etc/devd\")\n    CONFIG_OPTS+=(\"--with-hotplug-dir=${BUILD_PREFIX}/etc/hotplug\")\n\n    if [ x\"${INPLACE_RUNTIME-}\" = xtrue ]; then\n        CONFIG_OPTS+=(\"--enable-inplace-runtime\")\n    fi\n\n    # TODO: Consider `--enable-maintainer-mode` to add recipes that\n    # would quickly regenerate Makefile(.in) if you edit Makefile.am\n    # TODO: Resolve port-collision reliably (for multi-executor agents)\n    # and enable the test for CI runs. Bonus for making it quieter.\n    if [ \"${CANBUILD_NIT_TESTS-}\" != no ] ; then\n        CONFIG_OPTS+=(\"--enable-check-NIT\")\n    else\n        echo \"WARNING: Build agent does not say it can reliably 'make check-NIT'\" >&2\n        CONFIG_OPTS+=(\"--disable-check-NIT\")\n    fi\n\n    if [ -n \"${PYTHON-}\" ]; then\n        # WARNING: Watch out for whitespaces, not handled here!\n        CONFIG_OPTS+=(\"--with-python=${PYTHON}\")\n    fi\n    # Even in scenarios that request --with-all, we do not want\n    # to choke on absence of desktop-related modules in Python.\n    # Just make sure relevant install recipes are tested:\n    CONFIG_OPTS+=(\"--with-nut_monitor=force\")\n    CONFIG_OPTS+=(\"--with-pynut=auto\")\n\n    # Similarly for nut-scanner which requires libltdl which\n    # is not ubiquitous on CI workers. So unless agent labels\n    # declare it should be capable, err on the safe side:\n    if [ \"${CANBUILD_WITH_LIBLTDL-}\" != yes ] ; then\n        CONFIG_OPTS+=(\"--with-nut-scanner=auto\")\n    fi\n\n    # Some OSes have broken cppunit support, it crashes either build/link\n    # or at run-time. While distros take time to figure out fixes, we can\n    # skip the case...\n    if [ \"${CANBUILD_CPPUNIT_TESTS-}\" = no ] \\\n    || ( [ \"${CANBUILD_CPPUNIT_TESTS-}\" = \"no-gcc\" ] && [ \"$COMPILER_FAMILY\" = \"GCC\" ] ) \\\n    || ( [ \"${CANBUILD_CPPUNIT_TESTS-}\" = \"no-clang\" ] && [ \"$COMPILER_FAMILY\" = \"CLANG\" ] ) \\\n    ; then\n        echo \"WARNING: Build agent says it can't build or run libcppunit tests, adding configure option to skip them\" >&2\n        CONFIG_OPTS+=(\"--enable-cppunit=no\")\n    fi\n\n    if ( [ \"${CANBUILD_NUTCONF-}\" = \"no-gcc\" ] && [ \"$COMPILER_FAMILY\" = \"GCC\" ] ) \\\n    || ( [ \"${CANBUILD_NUTCONF-}\" = \"no-clang\" ] && [ \"$COMPILER_FAMILY\" = \"CLANG\" ] ) \\\n    ; then\n        CANBUILD_NUTCONF=no\n    fi\n\n    case \"${CANBUILD_NUTCONF-}\" in\n        yes)\n            # Depends on C++11 or newer, so let configure script try this tediously\n            # unless we know we would not build for the too-old language revision\n            case \"${CXXFLAGS-}\" in\n                *-std=c++98*|*-std=gnu++98*|*-std=c++03*|*-std=gnu++03*)\n                    echo \"WARNING: Build agent says it can build nutconf, but requires a test with C++ revision too old - so not requiring the experimental feature (auto-try)\" >&2\n                    CONFIG_OPTS+=(\"--with-nutconf=auto\")\n                    ;;\n                *-std=c++0x*|*-std=gnu++0x*|*-std=c++1*|*-std=gnu++1*|*-std=c++2*|*-std=gnu++2*)\n                    echo \"WARNING: Build agent says it can build nutconf, and requires a test with a sufficiently new C++ revision - so requiring the experimental feature\" >&2\n                    CONFIG_OPTS+=(\"--with-nutconf=yes\")\n                    ;;\n                *)\n                    echo \"WARNING: Build agent says it can build nutconf, and does not specify a test with prticular C++ revision - so not requiring the experimental feature (auto-try)\" >&2\n                    CONFIG_OPTS+=(\"--with-nutconf=auto\")\n                    ;;\n            esac\n            ;;\n        no)\n            echo \"WARNING: Build agent says it can not build nutconf, disabling the feature (do not even try)\" >&2\n            CONFIG_OPTS+=(\"--with-nutconf=no\")\n            ;;\n        \"\")\n            CONFIG_OPTS+=(\"--with-nutconf=auto\")\n            ;;\n    esac\n\n    if [ \"${CANBUILD_VALGRIND_TESTS-}\" = no ] ; then\n        echo \"WARNING: Build agent says it has a broken valgrind, adding configure option to skip tests with it\" >&2\n        CONFIG_OPTS+=(\"--with-valgrind=no\")\n    fi\n\n    if [ -n \"${CI_CROSSBUILD_TARGET-}\" ] || [ -n \"${CI_CROSSBUILD_HOST-}\" ] ; then\n        # at least one is e.g. \"arm-linux-gnueabihf\"\n        [ -z \"${CI_CROSSBUILD_TARGET-}\" ] && CI_CROSSBUILD_TARGET=\"${CI_CROSSBUILD_HOST}\"\n        [ -z \"${CI_CROSSBUILD_HOST-}\" ] && CI_CROSSBUILD_HOST=\"${CI_CROSSBUILD_TARGET}\"\n        echo \"NOTE: Cross-build was requested, passing options to configure this for target '${CI_CROSSBUILD_TARGET}' host '${CI_CROSSBUILD_HOST}' (note you may need customized PKG_CONFIG_PATH)\" >&2\n        CONFIG_OPTS+=(\"--host=${CI_CROSSBUILD_HOST}\")\n        CONFIG_OPTS+=(\"--target=${CI_CROSSBUILD_TARGET}\")\n    fi\n\n    # This flag is primarily linked with (lack of) docs generation enabled\n    # (or not) in some BUILD_TYPE scenarios or workers. Initial value may\n    # be set by caller, but codepaths below have the final word.\n    [ \"${DO_DISTCHECK-}\" = no ] || DO_DISTCHECK=yes\n    case \"$BUILD_TYPE\" in\n        \"default-nodoc\")\n            CONFIG_OPTS+=(\"--with-doc=no\")\n            CONFIG_OPTS+=(\"--disable-spellcheck\")\n            DO_DISTCHECK=no\n            ;;\n        \"default-spellcheck\"|\"default-shellcheck\")\n            CONFIG_OPTS+=(\"--with-all=no\")\n            CONFIG_OPTS+=(\"--with-libltdl=no\")\n            CONFIG_OPTS+=(\"--with-doc=man=skip\")\n            CONFIG_OPTS+=(\"--enable-spellcheck\")\n            #TBD# CONFIG_OPTS+=(\"--with-shellcheck=yes\")\n            DO_DISTCHECK=no\n            ;;\n        \"default-withdoc\")\n            # If the build agent says what it can not do, honor that\n            # TOTHINK: Should this build scenario die with error/unstable instead?\n            if [ \"${CANBUILD_DOCS_ALL-}\" = no ]; then\n                if [ \"${CANBUILD_DOCS_MAN-}\" = no ]; then\n                    # TBD: Also html? We'd have man then, and that is needed for distchecks at least\n                    echo \"WARNING: Build agent says it can build neither 'all' nor 'man' doc types; will ask for what we can build\" >&2\n                    #?#CONFIG_OPTS+=(\"--with-doc=no\")\n                    CONFIG_OPTS+=(\"--with-doc=auto\")\n                else\n                    echo \"WARNING: Build agent says it can't build 'all' doc types, but can build 'man' pages; will ask for what we can build\" >&2\n                    CONFIG_OPTS+=(\"--with-doc=auto\")\n                fi\n            else\n                if [ \"${CANBUILD_DOCS_MAN-}\" = no ]; then\n                    # TBD: Also html? We'd have man then, and that is needed for distchecks at least\n                    echo \"WARNING: Build agent says it can't build 'man' pages and says nothing about 'all' doc types; will ask for what we can build\" >&2\n                    CONFIG_OPTS+=(\"--with-doc=auto\")\n                else\n                    # Not a \"no\" in any category (yes or unspecified), request everything\n                    CONFIG_OPTS+=(\"--with-doc=yes\")\n                fi\n            fi\n            if [ -z \"${DO_CLEAN_CHECK-}\" ]; then\n                # This is one of recipes where we want to\n                # keep the build products by default ;)\n                DO_CLEAN_CHECK=no\n            fi\n            ;;\n        \"default-withdoc:man\")\n            # Some systems lack tools for HTML/PDF generation\n            # but may still yield standard man pages\n            if [ \"${CANBUILD_DOCS_MAN-}\" = no ]; then\n                echo \"WARNING: Build agent says it can't build man pages; will ask for what we can build\" >&2\n                CONFIG_OPTS+=(\"--with-doc=auto\")\n            else\n                CONFIG_OPTS+=(\"--with-doc=man\")\n            fi\n            if [ -z \"${DO_CLEAN_CHECK-}\" ]; then\n                # This is one of recipes where we want to\n                # keep the build products by default ;)\n                DO_CLEAN_CHECK=no\n            fi\n            ;;\n        \"default-all-errors\")\n            # This mode aims to build as many codepaths (to collect warnings)\n            # as it can, so help it enable (require) as many options as we can.\n\n            # Do not build the docs as we are interested in binary code\n            CONFIG_OPTS+=(\"--with-doc=skip\")\n            CONFIG_OPTS+=(\"--disable-spellcheck\")\n            # Enable as many binaries to build as current worker setup allows\n            CONFIG_OPTS+=(\"--with-all=auto\")\n\n            if [ \"${CANBUILD_LIBGD_CGI-}\" != \"no\" ] && [ \"${BUILD_LIBGD_CGI-}\" != \"auto\" ]  ; then\n                # Currently --with-all implies this, but better be sure to\n                # really build everything we can to be certain it builds:\n                if [ \"${CANBUILD_LIBGD_CGI-}\" != \"auto\" ] && (\n                   $PKG_CONFIG --exists libgd || $PKG_CONFIG --exists libgd2 || $PKG_CONFIG --exists libgd3 || $PKG_CONFIG --exists gdlib || $PKG_CONFIG --exists gd \n                ) ; then\n                    CONFIG_OPTS+=(\"--with-cgi=yes\")\n                else\n                    # Note: CI-wise, our goal IS to test as much as we can\n                    # with this build, so environments should be set up to\n                    # facilitate that as much as feasible. But reality is...\n                    echo \"WARNING: Seems libgd{,2,3} is not present, CGI build may be skipped!\" >&2\n                    CONFIG_OPTS+=(\"--with-cgi=auto\")\n                fi\n            else\n                if [ \"${CANBUILD_LIBGD_CGI-}\" = \"no\" ] ; then\n                    CONFIG_OPTS+=(\"--without-cgi\")\n                else\n                    CONFIG_OPTS+=(\"--with-cgi=auto\")\n                fi\n            fi\n            ;;\n        \"default-alldrv:no-distcheck\")\n            DO_DISTCHECK=no\n            ;& # fall through\n        \"default-alldrv\")\n            # Do not build the docs and make possible a distcheck below\n            CONFIG_OPTS+=(\"--with-doc=skip\")\n            CONFIG_OPTS+=(\"--disable-spellcheck\")\n            if [ \"${CANBUILD_DRIVERS_ALL-}\" = no ]; then\n                echo \"WARNING: Build agent says it can't build 'all' driver types; will ask for what we can build\" >&2\n                if [ \"$DO_DISTCHECK\" != no ]; then\n                    echo \"WARNING: this is effectively default-tgt:distcheck-light then\" >&2\n                fi\n                CONFIG_OPTS+=(\"--with-all=auto\")\n            else\n                CONFIG_OPTS+=(\"--with-all=yes\")\n            fi\n            ;;\n        \"default-tgt:cppcheck\")\n            if [ \"${CANBUILD_CPPCHECK_TESTS-}\" = no ] ; then\n                echo \"WARNING: Build agent says it has a broken cppcheck, but we requested a BUILD_TYPE='$BUILD_TYPE'\" >&2\n                exit 1\n            fi\n            if [ -z \"${DO_CLEAN_CHECK-}\" ]; then\n                # This is one of recipes where we want to\n                # keep the build products by default ;)\n                DO_CLEAN_CHECK=no\n            fi\n            CONFIG_OPTS+=(\"--enable-cppcheck=yes\")\n            CONFIG_OPTS+=(\"--with-doc=skip\")\n            ;;\n        \"default\"|\"default-tgt:\"*|*)\n            # Do not build the docs and tell distcheck it is okay\n            CONFIG_OPTS+=(\"--with-doc=skip\")\n            CONFIG_OPTS+=(\"--disable-spellcheck\")\n            ;;\n    esac\n    # NOTE: The case \"$BUILD_TYPE\" above was about setting CONFIG_OPTS.\n    # There is another below for running actual scenarios.\n\n    if [ \"$HAVE_CCACHE\" = yes ] && [ \"${COMPILER_FAMILY}\" = GCC -o \"${COMPILER_FAMILY}\" = CLANG ]; then\n        if [ -n \"${CI_CCACHE_SYMLINKDIR}\" ]; then\n            echo \"INFO: Using ccache via PATH preferring tool names in ${CI_CCACHE_SYMLINKDIR}\" >&2\n            PATH=\"${CI_CCACHE_SYMLINKDIR}:$PATH\"\n            export PATH\n        else\n            case \"$CC\" in\n                \"\") ;; # skip\n                *ccache*) ;; # already requested to use ccache\n                *) CC=\"ccache $CC\" ;;\n            esac\n            case \"$CXX\" in\n                \"\") ;; # skip\n                *ccache*) ;; # already requested to use ccache\n                *) CXX=\"ccache $CXX\" ;;\n            esac\n            # No-op for CPP currently\n        fi\n        if [ -n \"$CC\" ] && [ -n \"${CI_CCACHE_SYMLINKDIR}\" ]; then\n          if [ -x \"${CI_CCACHE_SYMLINKDIR}/`basename \"$CC\"`\" ]; then\n            case \"$CC\" in\n                *ccache*) ;;\n                */*) DIR_CC=\"`dirname \"$CC\"`\" && [ -n \"$DIR_CC\" ] && DIR_CC=\"`cd \"$DIR_CC\" && pwd `\" && [ -n \"$DIR_CC\" ] && [ -d \"$DIR_CC\" ] || DIR_CC=\"\"\n                    [ -z \"$CCACHE_PATH\" ] && CCACHE_PATH=\"$DIR_CC\" || \\\n                    if echo \"$CCACHE_PATH\" | grep -E '(^'\"$DIR_CC\"':.*|^'\"$DIR_CC\"'$|:'\"$DIR_CC\"':|:'\"$DIR_CC\"'$)' ; then\n                        CCACHE_PATH=\"$DIR_CC:$CCACHE_PATH\"\n                    fi\n                    ;;\n            esac\n            CC=\"${CI_CCACHE_SYMLINKDIR}/`basename \"$CC\"`\"\n          else\n            CC=\"ccache $CC\"\n          fi\n        fi\n        if [ -n \"$CXX\" ] && [ -n \"${CI_CCACHE_SYMLINKDIR}\" ]; then\n          if [ -x \"${CI_CCACHE_SYMLINKDIR}/`basename \"$CXX\"`\" ]; then\n            case \"$CXX\" in\n                *ccache*) ;;\n                */*) DIR_CXX=\"`dirname \"$CXX\"`\" && [ -n \"$DIR_CXX\" ] && DIR_CXX=\"`cd \"$DIR_CXX\" && pwd `\" && [ -n \"$DIR_CXX\" ] && [ -d \"$DIR_CXX\" ] || DIR_CXX=\"\"\n                    [ -z \"$CCACHE_PATH\" ] && CCACHE_PATH=\"$DIR_CXX\" || \\\n                    if echo \"$CCACHE_PATH\" | grep -E '(^'\"$DIR_CXX\"':.*|^'\"$DIR_CXX\"'$|:'\"$DIR_CXX\"':|:'\"$DIR_CXX\"'$)' ; then\n                        CCACHE_PATH=\"$DIR_CXX:$CCACHE_PATH\"\n                    fi\n                    ;;\n            esac\n            CXX=\"${CI_CCACHE_SYMLINKDIR}/`basename \"$CXX\"`\"\n          else\n            CXX=\"ccache $CXX\"\n          fi\n        fi\n        if [ -n \"$CPP\" ] && [ -n \"${CI_CCACHE_SYMLINKDIR}\" ] \\\n        && [ -x \"${CI_CCACHE_SYMLINKDIR}/`basename \"$CPP\"`\" ]; then\n            case \"$CPP\" in\n                *ccache*) ;;\n                */*) DIR_CPP=\"`dirname \"$CPP\"`\" && [ -n \"$DIR_CPP\" ] && DIR_CPP=\"`cd \"$DIR_CPP\" && pwd `\" && [ -n \"$DIR_CPP\" ] && [ -d \"$DIR_CPP\" ] || DIR_CPP=\"\"\n                    [ -z \"$CCACHE_PATH\" ] && CCACHE_PATH=\"$DIR_CPP\" || \\\n                    if echo \"$CCACHE_PATH\" | grep -E '(^'\"$DIR_CPP\"':.*|^'\"$DIR_CPP\"'$|:'\"$DIR_CPP\"':|:'\"$DIR_CPP\"'$)' ; then\n                        CCACHE_PATH=\"$DIR_CPP:$CCACHE_PATH\"\n                    fi\n                    ;;\n            esac\n            CPP=\"${CI_CCACHE_SYMLINKDIR}/`basename \"$CPP\"`\"\n        else\n            : # CPP=\"ccache $CPP\"\n        fi\n\n        # Note: Potentially there can be spaces in entries for multiword\n        # \"ccache gcc\" here; this should be okay as long as entry expands to\n        # one token when calling shell (may not be the case for distcheck)\n        CONFIG_OPTS+=(\"CC=${CC}\")\n        CONFIG_OPTS+=(\"CXX=${CXX}\")\n        CONFIG_OPTS+=(\"CPP=${CPP}\")\n    fi\n\n    # Build and check this project; note that zprojects always have an autogen.sh\n    [ -z \"$CI_TIME\" ] || echo \"`date`: Starting build of currently tested project...\"\n    CCACHE_BASEDIR=\"${PWD}\"\n    export CCACHE_BASEDIR\n\n    # Numerous per-compiler variants defined in configure.ac, including\n    # aliases \"minimal\", \"medium\", \"hard\", \"all\"\n    if [ -n \"${BUILD_WARNOPT-}\" ]; then\n        CONFIG_OPTS+=(\"--enable-warnings=${BUILD_WARNOPT}\")\n    fi\n\n    # Parse from strings that could be populated by a CI Boolean checkbox:\n    case \"${BUILD_WARNFATAL-}\" in\n        [Tt][Rr][Uu][Ee]) BUILD_WARNFATAL=yes;;\n        [Ff][Aa][Ll][Ss][Ee]) BUILD_WARNFATAL=no;;\n    esac\n    if [ -n \"${BUILD_WARNFATAL-}\" ]; then\n        CONFIG_OPTS+=(\"--enable-Werror=${BUILD_WARNFATAL}\")\n    fi\n\n    # Tell interactive and CI builds to prefer colorized output so warnings\n    # and errors are found more easily in a wall of text:\n    CONFIG_OPTS+=(\"--enable-Wcolor\")\n\n    if [ -n \"${BUILD_DEBUGINFO-}\" ]; then\n        CONFIG_OPTS+=(\"--with-debuginfo=${BUILD_DEBUGINFO}\")\n    fi\n\n    consider_cleanup_shortcut\n\n    if [ -s Makefile ]; then\n        # Let initial clean-up be at default verbosity\n\n        # Handle Ctrl+C with helpful suggestions:\n        trap 'echo \"!!! If clean-up looped remaking the configure script for maintainer-clean, try to:\"; echo \"    rm -f Makefile configure include/config.h* ; $0 $SCRIPT_ARGS\"' 2\n\n        echo \"=== Starting initial clean-up (from old build products)\"\n        case \"$MAKE_FLAGS $MAKE_FLAGS_CLEAN\" in\n        *V=0*)\n            ${MAKE} maintainer-clean $MAKE_FLAGS_CLEAN -k > /dev/null \\\n            || ${MAKE} maintainer-clean $MAKE_FLAGS_CLEAN -k\n            ;;\n        *)\n            ${MAKE} maintainer-clean $MAKE_FLAGS_CLEAN -k\n        esac \\\n        || ${MAKE} distclean $MAKE_FLAGS_CLEAN -k \\\n        || true\n        echo \"=== Finished initial clean-up\"\n\n        trap - 2\n    fi\n\n    # Just prepare `configure` script; we run it at different points\n    # below depending on scenario\n    autogen_get_CONFIGURE_SCRIPT\n\n    if [ \"$NO_PKG_CONFIG\" == \"true\" ] && [ \"$CI_OS_NAME\" = \"linux\" ] && (command -v dpkg) ; then\n        # This should be done in scratch containers...\n        echo \"NO_PKG_CONFIG==true : BUTCHER pkg-config package for this test case\" >&2\n        sudo dpkg -r --force all pkg-config\n    fi\n\n    if [ \"$BUILD_TYPE\" != \"default-all-errors\" ] ; then\n        configure_nut\n    fi\n\n    # NOTE: There is also a case \"$BUILD_TYPE\" above for setting CONFIG_OPTS\n    # This case runs some specially handled BUILD_TYPEs and exists; support\n    # for all other scenarios proceeds.below.\n    case \"$BUILD_TYPE\" in\n        \"default-tgt:\"*) # Hook for matrix of custom distchecks primarily\n            # e.g. distcheck-light, distcheck-valgrind, cppcheck, maybe\n            # others later, as defined in Makefile.am:\n            BUILD_TGT=\"`echo \"$BUILD_TYPE\" | sed 's,^default-tgt:,,'`\"\n            if [ -n \"${PARMAKE_FLAGS}\" ]; then\n                echo \"`date`: Starting the parallel build attempt for singular target $BUILD_TGT...\"\n            else\n                echo \"`date`: Starting the sequential build attempt for singular target $BUILD_TGT...\"\n            fi\n\n            # Note: Makefile.am already sets some default DISTCHECK_CONFIGURE_FLAGS\n            # that include DISTCHECK_FLAGS if provided\n            DISTCHECK_FLAGS=\"`for F in \"${CONFIG_OPTS[@]}\" ; do echo \"'$F' \" ; done | tr '\\n' ' '`\"\n            export DISTCHECK_FLAGS\n\n            # Tell the sub-makes (distcheck) to hush down\n            # NOTE: Parameter pass-through was tested with:\n            #   MAKEFLAGS=\"-j 12\" BUILD_TYPE=default-tgt:distcheck-light ./ci_build.sh\n            MAKEFLAGS=\"${MAKEFLAGS-} $MAKE_FLAGS_QUIET\" \\\n            $CI_TIME $MAKE DISTCHECK_FLAGS=\"$DISTCHECK_FLAGS\" $PARMAKE_FLAGS \"$BUILD_TGT\"\n\n            # Can be noisy if regen is needed (DMF branch)\n            #GIT_DIFF_SHOW=false \\\n            FILE_DESCR=\"DMF\" FILE_REGEX='\\.dmf$' FILE_GLOB='*.dmf' check_gitignore \"$BUILD_TGT\" || exit\n            check_gitignore \"$BUILD_TGT\" || exit\n\n            ccache_stats \"after\"\n\n            optional_maintainer_clean_check || exit\n\n            echo \"=== Exiting after the custom-build target '$MAKE $BUILD_TGT' succeeded OK\"\n            exit 0\n            ;;\n        \"default-spellcheck\")\n            [ -z \"$CI_TIME\" ] || echo \"`date`: Trying to spellcheck documentation of the currently tested project...\"\n            # Note: use the root Makefile's spellcheck recipe which goes into\n            # sub-Makefiles known to check corresponding directory's doc files.\n            # Note: no PARMAKE_FLAGS here - better have this output readably\n            # ordered in case of issues (in sequential replay below).\n            ( echo \"`date`: Starting the quiet build attempt for target $BUILD_TYPE...\" >&2\n              $CI_TIME $MAKE $MAKE_FLAGS_QUIET SPELLCHECK_ERROR_FATAL=yes -k $PARMAKE_FLAGS spellcheck >/dev/null 2>&1 \\\n              && echo \"`date`: SUCCEEDED the spellcheck\" >&2\n            ) || \\\n            ( echo \"`date`: FAILED something in spellcheck above; re-starting a verbose build attempt to give more context first:\" >&2\n              $CI_TIME $MAKE $MAKE_FLAGS_VERBOSE SPELLCHECK_ERROR_FATAL=yes spellcheck\n              # Make end of log useful:\n              echo \"`date`: FAILED something in spellcheck above; re-starting a non-verbose build attempt to just summarize now:\" >&2\n              $CI_TIME $MAKE $MAKE_FLAGS_QUIET SPELLCHECK_ERROR_FATAL=yes spellcheck\n            )\n            exit $?\n            ;;\n        \"default-shellcheck\")\n            [ -z \"$CI_TIME\" ] || echo \"`date`: Trying to check shell script syntax validity of the currently tested project...\"\n            ### Note: currently, shellcheck target calls check-scripts-syntax\n            ### so when both are invoked at once, in the end the check is only\n            ### executed once. Later it is anticipated that shellcheck would\n            ### be implemented by requiring, configuring and calling the tool\n            ### named \"shellcheck\" for even more code inspection and details.\n            ### Still, there remains value in also checking the script syntax\n            ### by the very version of the shell interpreter that would run\n            ### these scripts in production usage of the resulting packages.\n            ### Note: no PARMAKE_FLAGS here - better have this output readably\n            ### ordered in case of issues.\n            ( $CI_TIME $MAKE $MAKE_FLAGS_VERBOSE shellcheck check-scripts-syntax )\n            exit $?\n            ;;\n        \"default-all-errors\")\n            # This mode aims to build as many codepaths (to collect warnings)\n            # as it can, so help it enable (require) as many options as we can.\n\n            # Try to run various build scenarios to collect build errors\n            # (no checks here) as configured further by caller's choice\n            # of BUILD_WARNFATAL and/or BUILD_WARNOPT envvars above.\n            # Note this is one scenario where we did not configure_nut()\n            # in advance.\n            RES_ALLERRORS=0\n            FAILED=\"\"\n            SUCCEEDED=\"\"\n            BUILDSTODO=0\n\n            # Technically, let caller provide this setting explicitly\n            if [ -z \"$NUT_SSL_VARIANTS\" ] ; then\n                NUT_SSL_VARIANTS=\"auto\"\n                if $PKG_CONFIG --exists nss && $PKG_CONFIG --exists openssl && [ \"${BUILD_SSL_ONCE-}\" != \"true\" ] ; then\n                    # Try builds for both cases as they are ifdef-ed\n                    # TODO: Extend if we begin to care about different\n                    # major versions of openssl (with their APIs), etc.\n                    NUT_SSL_VARIANTS=\"openssl nss\"\n                else\n                    if [ \"${BUILD_SSL_ONCE-}\" != \"true\" ]; then\n                        $PKG_CONFIG --exists nss 2>/dev/null && NUT_SSL_VARIANTS=\"nss\"\n                        $PKG_CONFIG --exists openssl 2>/dev/null && NUT_SSL_VARIANTS=\"openssl\"\n                    fi  # else leave at \"auto\", if we skipped building\n                        # two variants while having two possibilities\n                fi\n\n                # Consider also a build --without-ssl to test that codepath?\n                if [ \"$NUT_SSL_VARIANTS\" != auto ] && [ \"${BUILD_SSL_ONCE-}\" != \"true\" ]; then\n                    NUT_SSL_VARIANTS=\"$NUT_SSL_VARIANTS no\"\n                fi\n            fi\n\n            if [ -z \"$NUT_USB_VARIANTS\" ] ; then\n                # Check preferred version first, in case BUILD_USB_ONCE==true\n                if $PKG_CONFIG --exists libusb-1.0 ; then\n                    NUT_USB_VARIANTS=\"1.0\"\n                fi\n\n                # TODO: Is there anywhere a `pkg-config --exists libusb-0.1`?\n                if $PKG_CONFIG --exists libusb || ( command -v libusb-config || which libusb-config ) 2>/dev/null >/dev/null ; then\n                    if [ -z \"$NUT_USB_VARIANTS\" ] ; then\n                        NUT_USB_VARIANTS=\"0.1\"\n                    else\n                        if [ \"${BUILD_USB_ONCE-}\" != \"true\" ] ; then\n                            NUT_USB_VARIANTS=\"$NUT_USB_VARIANTS 0.1\"\n                        fi\n                    fi\n                fi\n\n                if [ -z \"$NUT_USB_VARIANTS\" ] ; then\n                    # Nothing supported detected...\n                    NUT_USB_VARIANTS=\"auto\"\n                fi\n\n                # Consider also a build --without-usb to test that codepath?\n                # (e.g. for nutdrv_qx that has both serial and USB parts)\n                if [ \"$NUT_USB_VARIANTS\" != auto ] && [ \"${BUILD_USB_ONCE-}\" != \"true\" ]; then\n                    NUT_USB_VARIANTS=\"$NUT_USB_VARIANTS no\"\n                fi\n            fi\n\n            # Count our expected build variants, so the last one gets the\n            # \"maintainer-clean\" check and not a mere \"distclean\" check\n            # NOTE: We count different dependency variations separately,\n            # and analyze later, to avoid building same (auto+auto) twice\n            BUILDSTODO_SSL=0\n            for NUT_SSL_VARIANT in $NUT_SSL_VARIANTS ; do\n                BUILDSTODO_SSL=\"`expr $BUILDSTODO_SSL + 1`\"\n            done\n\n            BUILDSTODO_USB=0\n            for NUT_USB_VARIANT in $NUT_USB_VARIANTS ; do\n                BUILDSTODO_USB=\"`expr $BUILDSTODO_USB + 1`\"\n            done\n\n            if [ \"${BUILDSTODO_SSL}\" -gt 1 ] \\\n            && [ \"${BUILDSTODO_USB}\" -gt 1 ] \\\n            ; then\n                BUILDSTODO=\"`expr $BUILDSTODO_SSL + $BUILDSTODO_USB`\"\n            else\n                ###BUILDSTODO=0\n                ###if [ \"${BUILDSTODO_SSL}\" -gt \"${BUILDSTODO}\" ] ; then BUILDSTODO=\"${BUILDSTODO_SSL}\" ; fi\n                ###if [ \"${BUILDSTODO_USB}\" -gt \"${BUILDSTODO}\" ] ; then BUILDSTODO=\"${BUILDSTODO_USB}\" ; fi\n\n                # Use same logic as in actual loops below\n                # It may be imperfect (WRT avoiding extra builds) -- and\n                # that may be addressed separately, but counts should fit\n                BUILDSTODO=\"${BUILDSTODO_SSL}\"\n\n                # Adding up only if we are building several USB variants\n                # or a single non-default variant (maybe a \"no\" option),\n                # so we should be trying both SSL's and that/those USB\n                ###[ \"$NUT_USB_VARIANTS\" = \"auto\" ] || \\\n                ###{ [ \"${BUILDSTODO_USB}\" -le 1 ] && [ \"$NUT_USB_VARIANTS\" != \"no\" ] ; } || \\\n                if [ \"${BUILDSTODO_USB}\" -gt 1 ] \\\n                || [ \"$NUT_USB_VARIANTS\" != \"auto\" ] \\\n                ; then\n                    BUILDSTODO=\"`expr $BUILDSTODO + $BUILDSTODO_USB`\"\n                fi\n\n                if [ \"$NUT_SSL_VARIANTS\" = \"auto\" ] \\\n                && [ \"${BUILDSTODO_USB}\" -gt 0 ] \\\n                ; then\n                    echo \"=== Only build USB scenario(s) picking whatever SSL is found\"\n                    BUILDSTODO=\"${BUILDSTODO_USB}\"\n                fi\n            fi\n\n            BUILDSTODO_INITIAL=\"$BUILDSTODO\"\n            echo \"=== Will loop now with $BUILDSTODO build variants: found ${BUILDSTODO_SSL} SSL ($NUT_SSL_VARIANTS) and ${BUILDSTODO_USB} USB ($NUT_USB_VARIANTS) variations...\"\n            # If we don't care about SSL implem and want to pick USB, go straight there\n            ( [ \"$NUT_SSL_VARIANTS\" = \"auto\" ] && [ \"${BUILDSTODO_USB}\" -gt 0 ] ) || \\\n            for NUT_SSL_VARIANT in $NUT_SSL_VARIANTS ; do\n                # NOTE: Do not repeat a distclean before the loop,\n                # we have cleaned above before autogen, and here it\n                # would just re-evaluate `configure` to update the\n                # Makefile to remove it and other generated data.\n                #echo \"=== Clean the sandbox, $BUILDSTODO build variants remaining...\"\n                #$MAKE distclean $MAKE_FLAGS_CLEAN -k || true\n\n                echo \"=== Starting 'NUT_SSL_VARIANT=$NUT_SSL_VARIANT', $BUILDSTODO build variants remaining...\"\n                case \"$NUT_SSL_VARIANT\" in\n                    \"\"|auto|default)\n                        # Quietly build one scenario, whatever we can (or not)\n                        # configure regarding SSL and other features\n                        NUT_SSL_VARIANT=auto\n                        configure_nut\n                        ;;\n                    no)\n                        echo \"=== Building without SSL support...\"\n                        ( CONFIG_OPTS+=(\"--without-ssl\")\n                          configure_nut\n                        )\n                        ;;\n                    *)\n                        echo \"=== Building with 'NUT_SSL_VARIANT=${NUT_SSL_VARIANT}' ...\"\n                        ( CONFIG_OPTS+=(\"--with-${NUT_SSL_VARIANT}\")\n                          configure_nut\n                        )\n                        ;;\n                esac || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[configure]\"\n                    # TOTHINK: Do we want to try clean-up if we likely have no Makefile?\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                    BUILDSTODO=\"`expr $BUILDSTODO - 1`\" || [ \"$BUILDSTODO\" = \"0\" ] || break\n                    continue\n                }\n\n                echo \"=== Configured 'NUT_SSL_VARIANT=$NUT_SSL_VARIANT', $BUILDSTODO build variants (including this one) remaining to complete; trying to build...\"\n                cd \"${CI_BUILDDIR}\"\n                # Use default target e.g. \"all\":\n                build_to_only_catch_errors_target && {\n                    SUCCEEDED=\"${SUCCEEDED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[build]\"\n                } || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[build]\"\n                    # Help find end of build (before cleanup noise) in logs:\n                    echo \"=== FAILED 'NUT_SSL_VARIANT=${NUT_SSL_VARIANT}' build\"\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                }\n\n                build_to_only_catch_errors_check && {\n                    SUCCEEDED=\"${SUCCEEDED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[check]\"\n                } || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[check]\"\n                    # Help find end of build (before cleanup noise) in logs:\n                    echo \"=== FAILED 'NUT_SSL_VARIANT=${NUT_SSL_VARIANT}' check\"\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                }\n\n                # Note: when `expr` calculates a zero value below, it returns\n                # an \"erroneous\" `1` as exit code. Why oh why?..\n                # (UPDATE: because expr returns boolean, and calculated 0 is false;\n                # so a `set -e` run aborts)\n                BUILDSTODO=\"`expr $BUILDSTODO - 1`\" || [ \"$BUILDSTODO\" = \"0\" ] || break\n\n                if [ \"$BUILDSTODO\" -gt 0 ] && [ \"${DO_CLEAN_CHECK-}\" != no ]; then\n                    # For last iteration with DO_CLEAN_CHECK=no,\n                    # we would leave built products in place\n                    echo \"=== Clean the sandbox, $BUILDSTODO build variants remaining...\"\n                fi\n\n                if can_clean_check ; then\n                    if [ $BUILDSTODO -gt 0 ]; then\n                        ### Avoid having to re-autogen in a loop:\n                        optional_dist_clean_check && {\n                            if [ \"${DO_DIST_CLEAN_CHECK-}\" != \"no\" ] ; then\n                                SUCCEEDED=\"${SUCCEEDED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[dist_clean]\"\n                            fi\n                        } || {\n                            RES_ALLERRORS=$?\n                            FAILED=\"${FAILED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[dist_clean]\"\n                        }\n                    else\n                        optional_maintainer_clean_check && {\n                            if [ \"${DO_MAINTAINER_CLEAN_CHECK-}\" != no ] ; then\n                                SUCCEEDED=\"${SUCCEEDED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[maintainer_clean]\"\n                            fi\n                        } || {\n                            RES_ALLERRORS=$?\n                            FAILED=\"${FAILED} NUT_SSL_VARIANT=${NUT_SSL_VARIANT}[maintainer_clean]\"\n                        }\n                    fi\n                    echo \"=== Completed sandbox cleanup-check after NUT_SSL_VARIANT=${NUT_SSL_VARIANT}, $BUILDSTODO build variants remaining\"\n                else\n                    if [ \"$BUILDSTODO\" -gt 0 ] && [ \"${DO_CLEAN_CHECK-}\" != no ]; then\n                        $MAKE distclean $MAKE_FLAGS_CLEAN -k \\\n                        || echo \"WARNING: 'make distclean' FAILED: $? ... proceeding\" >&2\n                        echo \"=== Completed sandbox cleanup after NUT_SSL_VARIANT=${NUT_SSL_VARIANT}, $BUILDSTODO build variants remaining\"\n                    else\n                        echo \"=== SKIPPED sandbox cleanup because DO_CLEAN_CHECK=$DO_CLEAN_CHECK and $BUILDSTODO build variants remaining\"\n                    fi\n                fi\n            done\n\n            # Effectively, whatever up to one version of LibUSB support\n            # was detected (or not), was tested above among SSL builds.\n            # Here we drill deeper for envs that have more than one LibUSB,\n            # or when caller explicitly requested to only test without it,\n            # and then we only attempt the serial and/or USB options while\n            # disabling other drivers for faster turnaround.\n            ###[ \"$NUT_USB_VARIANTS\" = \"auto\" ] || \\\n            ###( [ \"${BUILDSTODO_USB}\" -le 1 ] && [ \"$NUT_USB_VARIANTS\" != \"no\" ] ) || \\\n            ( ( [ \"$NUT_SSL_VARIANTS\" = \"auto\" ] && [ \"${BUILDSTODO_USB}\" -gt 0 ] ) \\\n             || [ \"${BUILDSTODO_USB}\" -gt 1 ] \\\n             || [ \"$NUT_USB_VARIANTS\" != \"auto\" ] \\\n            ) && \\\n            (   [ \"$CI_FAILFAST\" != \"true\" ] \\\n             || [ \"$CI_FAILFAST\" = \"true\" -a \"$RES_ALLERRORS\" = 0 ] \\\n            ) && \\\n            for NUT_USB_VARIANT in $NUT_USB_VARIANTS ; do\n                echo \"=== Starting 'NUT_USB_VARIANT=$NUT_USB_VARIANT', $BUILDSTODO build variants remaining...\"\n                case \"$NUT_USB_VARIANT\" in\n                    \"\"|auto|default)\n                        # Quietly build one scenario, whatever we can (or not)\n                        # configure regarding USB and other features\n                        NUT_USB_VARIANT=auto\n                        ( if [ \"$NUT_SSL_VARIANTS\" != \"auto\" ] ; then\n                              CONFIG_OPTS+=(\"--without-all\")\n                              CONFIG_OPTS+=(\"--without-ssl\")\n                          fi\n                          CONFIG_OPTS+=(\"--with-serial=auto\")\n                          CONFIG_OPTS+=(\"--with-usb\")\n                          configure_nut\n                        )\n                        ;;\n                    no)\n                        echo \"=== Building without USB support (check mixed drivers coded for Serial/USB support)...\"\n                        ( if [ \"$NUT_SSL_VARIANTS\" != \"auto\" ] ; then\n                              CONFIG_OPTS+=(\"--without-all\")\n                              CONFIG_OPTS+=(\"--without-ssl\")\n                          fi\n                          CONFIG_OPTS+=(\"--with-serial=auto\")\n                          CONFIG_OPTS+=(\"--without-usb\")\n                          configure_nut\n                        )\n                        ;;\n                    libusb-*)\n                        echo \"=== Building with 'NUT_USB_VARIANT=${NUT_USB_VARIANT}' ...\"\n                        ( if [ \"$NUT_SSL_VARIANTS\" != \"auto\" ] ; then\n                              CONFIG_OPTS+=(\"--without-all\")\n                              CONFIG_OPTS+=(\"--without-ssl\")\n                          fi\n                          CONFIG_OPTS+=(\"--with-serial=auto\")\n                          CONFIG_OPTS+=(\"--with-usb=${NUT_USB_VARIANT}\")\n                          configure_nut\n                        )\n                        ;;\n                    *)\n                        echo \"=== Building with 'NUT_USB_VARIANT=${NUT_USB_VARIANT}' ...\"\n                        ( if [ \"$NUT_SSL_VARIANTS\" != \"auto\" ] ; then\n                              CONFIG_OPTS+=(\"--without-all\")\n                              CONFIG_OPTS+=(\"--without-ssl\")\n                          fi\n                          CONFIG_OPTS+=(\"--with-serial=auto\")\n                          CONFIG_OPTS+=(\"--with-usb=libusb-${NUT_USB_VARIANT}\")\n                          configure_nut\n                        )\n                        ;;\n                esac || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[configure]\"\n                    # TOTHINK: Do we want to try clean-up if we likely have no Makefile?\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                    BUILDSTODO=\"`expr $BUILDSTODO - 1`\" || [ \"$BUILDSTODO\" = \"0\" ] || break\n                    continue\n                }\n\n                echo \"=== Configured 'NUT_USB_VARIANT=$NUT_USB_VARIANT', $BUILDSTODO build variants (including this one) remaining to complete; trying to build...\"\n                cd \"${CI_BUILDDIR}\"\n                # Use default target e.g. \"all\":\n                build_to_only_catch_errors_target && {\n                    SUCCEEDED=\"${SUCCEEDED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[build]\"\n                } || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[build]\"\n                    # Help find end of build (before cleanup noise) in logs:\n                    echo \"=== FAILED 'NUT_USB_VARIANT=${NUT_USB_VARIANT}' build\"\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                }\n\n                build_to_only_catch_errors_check && {\n                    SUCCEEDED=\"${SUCCEEDED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[check]\"\n                } || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[check]\"\n                    # Help find end of build (before cleanup noise) in logs:\n                    echo \"=== FAILED 'NUT_USB_VARIANT=${NUT_USB_VARIANT}' check\"\n                    if [ \"$CI_FAILFAST\" = true ]; then\n                        echo \"===== Aborting because CI_FAILFAST=$CI_FAILFAST\" >&2\n                        break\n                    fi\n                }\n\n                # Note: when `expr` calculates a zero value below, it returns\n                # an \"erroneous\" `1` as exit code. Notes above.\n                BUILDSTODO=\"`expr $BUILDSTODO - 1`\" || [ \"$BUILDSTODO\" = \"0\" ] || break\n\n                if [ \"$BUILDSTODO\" -gt 0 ] && [ \"${DO_CLEAN_CHECK-}\" != no ]; then\n                    # For last iteration with DO_CLEAN_CHECK=no,\n                    # we would leave built products in place\n                    echo \"=== Clean the sandbox, $BUILDSTODO build variants remaining...\"\n                fi\n\n                if can_clean_check ; then\n                    if [ $BUILDSTODO -gt 0 ]; then\n                        ### Avoid having to re-autogen in a loop:\n                        optional_dist_clean_check && {\n                            if [ \"${DO_DIST_CLEAN_CHECK-}\" != \"no\" ] ; then\n                                SUCCEEDED=\"${SUCCEEDED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[dist_clean]\"\n                            fi\n                        } || {\n                            RES_ALLERRORS=$?\n                            FAILED=\"${FAILED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[dist_clean]\"\n                        }\n                    else\n                        optional_maintainer_clean_check && {\n                            if [ \"${DO_MAINTAINER_CLEAN_CHECK-}\" != no ] ; then\n                                SUCCEEDED=\"${SUCCEEDED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[maintainer_clean]\"\n                            fi\n                        } || {\n                            RES_ALLERRORS=$?\n                            FAILED=\"${FAILED} NUT_USB_VARIANT=${NUT_USB_VARIANT}[maintainer_clean]\"\n                        }\n                    fi\n                    echo \"=== Completed sandbox cleanup-check after NUT_USB_VARIANT=${NUT_USB_VARIANT}, $BUILDSTODO build variants remaining\"\n                else\n                    if [ \"$BUILDSTODO\" -gt 0 ] && [ \"${DO_CLEAN_CHECK-}\" != no ]; then\n                        $MAKE distclean $MAKE_FLAGS_CLEAN -k \\\n                        || echo \"WARNING: 'make distclean' FAILED: $? ... proceeding\" >&2\n                        echo \"=== Completed sandbox cleanup after NUT_USB_VARIANT=${NUT_USB_VARIANT}, $BUILDSTODO build variants remaining\"\n                    else\n                        echo \"=== SKIPPED sandbox cleanup because DO_CLEAN_CHECK=$DO_CLEAN_CHECK and $BUILDSTODO build variants remaining\"\n                    fi\n                fi\n            done\n\n            # TODO: Similar loops for other variations like TESTING,\n            # MGE SHUT vs. other serial protocols...\n\n            if can_clean_check ; then\n                echo \"=== One final try for optional_maintainer_clean_check:\"\n                optional_maintainer_clean_check && {\n                    if [ \"${DO_MAINTAINER_CLEAN_CHECK-}\" != no ] ; then\n                        SUCCEEDED=\"${SUCCEEDED} [final_maintainer_clean]\"\n                    fi\n                } || {\n                    RES_ALLERRORS=$?\n                    FAILED=\"${FAILED} [final_maintainer_clean]\"\n                }\n                echo \"=== Completed sandbox maintainer-cleanup-check after all builds\"\n            fi\n\n            if [ -n \"$SUCCEEDED\" ]; then\n                echo \"SUCCEEDED build(s) with:${SUCCEEDED}\" >&2\n            fi\n\n            if [ \"$RES_ALLERRORS\" != 0 ]; then\n                # Leading space is included in FAILED\n                echo \"FAILED build(s) with code ${RES_ALLERRORS}:${FAILED}\" >&2\n            else\n                echo \"(and no build scenarios had failed)\" >&2\n            fi\n\n            echo \"Initially estimated ${BUILDSTODO_INITIAL} variations for BUILD_TYPE='$BUILD_TYPE'\" >&2\n            if [ \"$BUILDSTODO\" -gt 0 ]; then\n                echo \"(and missed the mark: ${BUILDSTODO} variations remain - did anything crash early above?)\" >&2\n            fi\n\n            exit $RES_ALLERRORS\n            ;;\n    esac\n\n    # Quiet parallel make, redo loud sequential if that failed\n    build_to_only_catch_errors_target all\n\n    # Can be noisy if regen is needed (DMF branch with this or that BUILD_TGT)\n    # Bail out due to DMF will (optionally) happen in the next check\n    #GIT_DIFF_SHOW=false FILE_DESCR=\"DMF\" FILE_REGEX='\\.dmf$' FILE_GLOB='*.dmf' check_gitignore \"$BUILD_TGT\" || true\n\n    # TODO (when merging DMF branch, not a problem before then):\n    # this one check should not-list the \"*.dmf\" files even if\n    # changed (listed as a special group above) but should still\n    # fail due to them:\n    check_gitignore \"all\" || exit\n\n    if test -s \"${SCRIPTDIR}/install-sh\" \\\n    && grep -w MKDIRPROG \"${SCRIPTDIR}/install-sh\" >/dev/null \\\n    ; then\n         if grep -v '#' \"${SCRIPTDIR}/install-sh\" | grep -E '\\$mkdirprog.*-p' >/dev/null \\\n        ; then\n            true\n        else\n            if [ -z \"${MKDIRPROG-}\" ] ; then\n                echo \"`date`: WARNING: setting MKDIRPROG to work around possible deficiencies of install-sh\"\n                MKDIRPROG=\"mkdir -p\"\n                export MKDIRPROG\n            fi\n        fi\n    fi\n\n    [ -z \"$CI_TIME\" ] || echo \"`date`: Trying to install the currently tested project into the custom DESTDIR...\"\n    $CI_TIME $MAKE $MAKE_FLAGS_VERBOSE DESTDIR=\"$INST_PREFIX\" install\n    [ -n \"$CI_TIME\" ] && echo \"`date`: listing files installed into the custom DESTDIR...\" && \\\n        find \"$INST_PREFIX\" -ls || true\n\n    if [ \"$DO_DISTCHECK\" == \"no\" ] ; then\n        echo \"Skipping distcheck (doc generation is disabled, it would fail)\"\n    else\n        [ -z \"$CI_TIME\" ] || echo \"`date`: Starting distcheck of currently tested project...\"\n        (\n        # Note: Makefile.am already sets some default DISTCHECK_CONFIGURE_FLAGS\n        # that include DISTCHECK_FLAGS if provided\n        DISTCHECK_FLAGS=\"`for F in \"${CONFIG_OPTS[@]}\" ; do echo \"'$F' \" ; done | tr '\\n' ' '`\"\n        export DISTCHECK_FLAGS\n\n        # Tell the sub-makes (distcheck) to hush down\n        MAKEFLAGS=\"${MAKEFLAGS-} $MAKE_FLAGS_QUIET\" \\\n        $CI_TIME $MAKE DISTCHECK_FLAGS=\"$DISTCHECK_FLAGS\" $PARMAKE_FLAGS distcheck\n\n        #FILE_DESCR=\"DMF\" FILE_REGEX='\\.dmf$' FILE_GLOB='*.dmf' check_gitignore \"$BUILD_TGT\" || true\n        check_gitignore \"distcheck\" || exit\n        )\n    fi\n\n    optional_maintainer_clean_check || exit\n\n    ccache_stats \"after\"\n    ;;\nbindings)\n    pushd \"./bindings/${BINDING}\" && ./ci_build.sh\n    ;;\n\"\"|inplace)\n    echo \"WARNING: No BUILD_TYPE was specified, doing a minimal default ritual without any *required* build products and with developer-oriented options\" >&2\n    if [ -n \"${BUILD_WARNOPT}${BUILD_WARNFATAL}\" ]; then\n        echo \"WARNING: BUILD_WARNOPT and BUILD_WARNFATAL settings are ignored in this mode (warnings are always enabled and fatal for these developer-oriented builds)\" >&2\n        sleep 5\n    fi\n    echo \"\"\n\n    if [ -n \"${CI_CCACHE_SYMLINKDIR}\" ] && [ -d \"${CI_CCACHE_SYMLINKDIR}\" ] ; then\n        PATH=\"`echo \"$PATH\" | sed -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,' -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,'`\"\n        CCACHE_PATH=\"$PATH\"\n        CCACHE_DIR=\"${HOME}/.ccache\"\n        if (command -v ccache || which ccache) && ls -la \"${CI_CCACHE_SYMLINKDIR}\" && mkdir -p \"${CCACHE_DIR}\"/ ; then\n            echo \"INFO: Using ccache via PATH preferring tool names in ${CI_CCACHE_SYMLINKDIR}\" >&2\n            PATH=\"${CI_CCACHE_SYMLINKDIR}:$PATH\"\n            export CCACHE_PATH CCACHE_DIR PATH\n        fi\n    fi\n\n    cd \"${SCRIPTDIR}\"\n\n    consider_cleanup_shortcut\n\n    if [ -s Makefile ]; then\n        # Help developers debug:\n        # Let initial clean-up be at default verbosity\n        echo \"=== Starting initial clean-up (from old build products)\"\n        ${MAKE} realclean -k || true\n        echo \"=== Finished initial clean-up\"\n    fi\n\n    configure_CI_BUILDDIR\n\n    # NOTE: Default NUT \"configure\" actually insists on some features,\n    # like serial port support unless told otherwise, or docs if possible.\n    # Below we aim for really fast iterations of C/C++ development so\n    # enable whatever is auto-detectable (except docs), and highlight\n    # any warnings if we can.\n    CONFIG_OPTS=(--enable-Wcolor \\\n        --enable-warnings --enable-Werror \\\n        --enable-keep_nut_report_feature \\\n        --with-all=auto --with-cgi=auto --with-serial=auto \\\n        --with-dev=auto --with-doc=skip \\\n        --with-nut_monitor=auto --with-pynut=auto \\\n        --disable-force-nut-version-header \\\n        --enable-check-NIT --enable-maintainer-mode)\n\n    # Not default for parameter-less build, to prevent \"make check-NIT\"\n    # from somehow interfering with the running daemons.\n    if [ x\"${INPLACE_RUNTIME-}\" = xtrue ] || [ x\"${BUILD_TYPE-}\" = xinplace ] ; then\n        CONFIG_OPTS+=(\"--enable-inplace-runtime\")\n    else\n        # Help developers debug:\n        CONFIG_OPTS+=(\"--disable-silent-rules\")\n    fi\n\n    if [ -n \"${BUILD_DEBUGINFO-}\" ]; then\n        CONFIG_OPTS+=(\"--with-debuginfo=${BUILD_DEBUGINFO}\")\n    else\n        CONFIG_OPTS+=(\"--with-debuginfo=auto\")\n    fi\n\n    if [ -n \"${PYTHON-}\" ]; then\n        # WARNING: Watch out for whitespaces, not handled here!\n        CONFIG_OPTS+=(\"--with-python=${PYTHON}\")\n    fi\n\n    RES_CFG=0\n    ${CONFIGURE_SCRIPT} \"${CONFIG_OPTS[@]}\" \\\n    || RES_CFG=$?\n    echo \"$0: configure phase complete ($RES_CFG)\" >&2\n    [ x\"$RES_CFG\" = x0 ] || exit $RES_CFG\n\n    # NOTE: Currently parallel builds are expected to succeed (as far\n    # as recipes are concerned), and the builds without a BUILD_TYPE\n    # are aimed at developer iterations so not tweaking verbosity.\n    echo \"Configuration finished, starting make\" >&2\n    if [ -n \"$PARMAKE_FLAGS\" ]; then\n        echo \"For parallel builds, '$PARMAKE_FLAGS' options would be used\" >&2\n    fi\n    if [ -n \"$MAKEFLAGS\" ]; then\n        echo \"Generally, MAKEFLAGS='$MAKEFLAGS' options would be passed\" >&2\n    fi\n\n    #$MAKE all || \\\n    $MAKE $PARMAKE_FLAGS all || exit\n    if [ \"${CI_SKIP_CHECK}\" != true ] ; then $MAKE check || exit ; fi\n\n    case \"$CI_OS_NAME\" in\n        windows*)\n            echo \"INFO: Build and tests succeeded. If you plan to install a NUT bundle now\" >&2\n            echo \"for practical usage or testing on a native Windows system, consider calling\" >&2\n            echo \"    make install-win-bundle DESTDIR=`pwd`/.inst/NUT4Win\" >&2\n            echo \"(or some other valid DESTDIR) to co-bundle dependency FOSS DLL files there.\" >&2\n            ;;\n    esac\n\n    if [ -s config.nut_report_feature.log ]; then\n        cat config.nut_report_feature.log\n    fi\n    ;;\n\n# These mingw modes below are currently experimental and not too integrated\n# with this script per se; it is intended to run for NUT CI farm on prepared\n# Linux+mingw worker nodes (see scripts/Windows/README.adoc) in an uniform\n# manner, using mostly default settings (warnings in particular) and some\n# values hardcoded in that script (ARCH, CFLAGS, ...).\n# Note that semi-native builds with e.g. MSYS2 on Windows should \"just work\" as\n# on any other supported platform (more details in docs/config-prereqs.txt).\ncross-windows-mingw*)\n    echo \"INFO: When using build-mingw-nut.sh consider 'export INSTALL_WIN_BUNDLE=true' to use mainstream DLL co-bundling recipe\" >&2\n\n    if [ \"$HAVE_CCACHE\" = yes ] \\\n    && [ -n \"${CI_CCACHE_SYMLINKDIR}\" ] \\\n    && [ -d \"${CI_CCACHE_SYMLINKDIR}\" ] \\\n    ; then\n        PATH=\"`echo \"$PATH\" | sed -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?:,,' -e 's,:'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,' -e 's,^'\"${CI_CCACHE_SYMLINKDIR}\"'/?$,,'`\"\n        CCACHE_PATH=\"$PATH\"\n        CCACHE_DIR=\"${HOME}/.ccache\"\n        if (command -v ccache || which ccache) && ls -la \"${CI_CCACHE_SYMLINKDIR}\" && mkdir -p \"${CCACHE_DIR}\"/ ; then\n            echo \"INFO: Using ccache via PATH preferring tool names in ${CI_CCACHE_SYMLINKDIR}\" >&2\n            PATH=\"${CI_CCACHE_SYMLINKDIR}:$PATH\"\n            export CCACHE_PATH CCACHE_DIR PATH\n        fi\n    fi\n\n    ./autogen.sh || exit\n    cd scripts/Windows || exit\n\n    cmd=\"\" # default soup of the day, as defined in the called script\n    case \"$BUILD_TYPE\" in\n        cross-windows-mingw32|cross-windows-mingw-32) cmd=\"all32\" ;;\n        cross-windows-mingw64|cross-windows-mingw-64) cmd=\"all64\" ;;\n        cross-windows-mingw) # make a difficult guess\n            case \"${BITS-}\" in\n                32|64) cmd=\"all${BITS}\"\n                    ;;\n                *)  # Use other clues\n                    case \"${CFLAGS-}${CXXFLAGS-}${LDFLAGS-}\" in\n                        *-m32*-m64*|*-m64*-m32*)\n                            echo \"FATAL: Mismatched bitness requested in *FLAGS\" >&2\n                            exit 1\n                            ;;\n                        *-m32*) cmd=\"all32\" ;;\n                        *-m64*) cmd=\"all64\" ;;\n                    esac\n                    ;;\n            esac\n            ;;\n    esac\n\n    SOURCEMODE=\"out-of-tree\" \\\n    MAKEFLAGS=\"$PARMAKE_FLAGS\" \\\n    KEEP_NUT_REPORT_FEATURE=\"true\" \\\n    ./build-mingw-nut.sh $cmd\n    ;;\n\n*)\n    pushd \"./builds/${BUILD_TYPE}\" && REPO_DIR=\"$(dirs -l +1)\" ./ci_build.sh\n    ;;\nesac\n"
        },
        {
          "name": "clients",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "compile",
          "type": "blob",
          "size": 3.6806640625,
          "content": "#! /bin/sh\n# Wrapper for compilers which do not understand `-c -o'.\n\nscriptversion=2009-10-06.20; # UTC\n\n# Copyright (C) 1999, 2000, 2003, 2004, 2005, 2009  Free Software\n# Foundation, Inc.\n# Written by Tom Tromey <tromey@cygnus.com>.\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2, or (at your option)\n# any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n# As a special exception to the GNU General Public License, if you\n# distribute this file as part of a program that contains a\n# configuration script generated by Autoconf, you may include it under\n# the same distribution terms that you use for the rest of that program.\n\n# This file is maintained in Automake, please report\n# bugs to <bug-automake@gnu.org> or send patches to\n# <automake-patches@gnu.org>.\n\ncase $1 in\n  '')\n     echo \"$0: No command.  Try \\`$0 --help' for more information.\" 1>&2\n     exit 1;\n     ;;\n  -h | --h*)\n    cat <<\\EOF\nUsage: compile [--help] [--version] PROGRAM [ARGS]\n\nWrapper for compilers which do not understand `-c -o'.\nRemove `-o dest.o' from ARGS, run PROGRAM with the remaining\narguments, and rename the output as expected.\n\nIf you are trying to build a whole package this is not the\nright script to run: please start by reading the file `INSTALL'.\n\nReport bugs to <bug-automake@gnu.org>.\nEOF\n    exit $?\n    ;;\n  -v | --v*)\n    echo \"compile $scriptversion\"\n    exit $?\n    ;;\nesac\n\nofile=\ncfile=\neat=\n\nfor arg\ndo\n  if test -n \"$eat\"; then\n    eat=\n  else\n    case $1 in\n      -o)\n\t# configure might choose to run compile as `compile cc -o foo foo.c'.\n\t# So we strip `-o arg' only if arg is an object.\n\teat=1\n\tcase $2 in\n\t  *.o | *.obj)\n\t    ofile=$2\n\t    ;;\n\t  *)\n\t    set x \"$@\" -o \"$2\"\n\t    shift\n\t    ;;\n\tesac\n\t;;\n      *.c)\n\tcfile=$1\n\tset x \"$@\" \"$1\"\n\tshift\n\t;;\n      *)\n\tset x \"$@\" \"$1\"\n\tshift\n\t;;\n    esac\n  fi\n  shift\ndone\n\nif test -z \"$ofile\" || test -z \"$cfile\"; then\n  # If no `-o' option was seen then we might have been invoked from a\n  # pattern rule where we don't need one.  That is ok -- this is a\n  # normal compilation that the losing compiler can handle.  If no\n  # `.c' file was seen then we are probably linking.  That is also\n  # ok.\n  exec \"$@\"\nfi\n\n# Name of file we expect compiler to create.\ncofile=`echo \"$cfile\" | sed 's|^.*[\\\\/]||; s|^[a-zA-Z]:||; s/\\.c$/.o/'`\n\n# Create the lock directory.\n# Note: use `[/\\\\:.-]' here to ensure that we don't use the same name\n# that we are using for the .o file.  Also, base the name on the expected\n# object file name, since that is what matters with a parallel build.\nlockdir=`echo \"$cofile\" | sed -e 's|[/\\\\:.-]|_|g'`.d\nwhile true; do\n  if mkdir \"$lockdir\" >/dev/null 2>&1; then\n    break\n  fi\n  sleep 1\ndone\n# FIXME: race condition here if user kills between mkdir and trap.\ntrap \"rmdir '$lockdir'; exit 1\" 1 2 15\n\n# Run the compile.\n\"$@\"\nret=$?\n\nif test -f \"$cofile\"; then\n  test \"$cofile\" = \"$ofile\" || mv \"$cofile\" \"$ofile\"\nelif test -f \"${cofile}bj\"; then\n  test \"${cofile}bj\" = \"$ofile\" || mv \"${cofile}bj\" \"$ofile\"\nfi\n\nrmdir \"$lockdir\"\nexit $ret\n\n# Local Variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'write-file-hooks 'time-stamp)\n# time-stamp-start: \"scriptversion=\"\n# time-stamp-format: \"%:y-%02m-%02d.%02H\"\n# time-stamp-time-zone: \"UTC\"\n# time-stamp-end: \"; # UTC\"\n# End:\n"
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 228.0966796875,
          "content": "dnl +------------------------------------------------------------------+\ndnl | Network UPS Tools: configure.ac                                  |\ndnl +------------------------------------------------------------------+\n\ndnl # Support for older autoconf without m4_esyscmd_s\nm4_ifndef([m4_chomp_all], [m4_define([m4_chomp_all], [m4_format([[%.*s]], m4_bregexp(m4_translit([[$1]], [/], [/ ]), [/*$]), [$1])])])\nm4_ifndef([m4_esyscmd_s], [m4_define([m4_esyscmd_s], [m4_chomp_all(m4_esyscmd([$1]))])])\n\ndnl NUT version number is defined here, with a Git suffixed macro like\ndnl    NUT_VERSION_MACRO \"2.7.4-2838-gdfc3ac08\"\ndnl defined separately in include/nut_version.h (generated by make)\ndnl ...or not defined, for quicker rebuilds, depending on settings.\ndnl Old hard-coded approach (mangled a bit):\ndnl AC INIT([nut],[2.8.2.1],[https://github.com/networkupstools/nut/issues])\ndnl Note: srcdir is only set after AC INIT has completed, but $0 points\ndnl to the generated configure script which is part of dist tarball and\ndnl should be at source root too.\ndnl Note: this gets evaluated (script called) a lot of times during autoconf\ndnl but ends up as static strings in the generated configure script. It may\ndnl be beneficial to have a `version.m4` generated by `autogen.sh` and/or\ndnl shipped in a tarball, allowing for a singular include into configure.ac\ndnl See https://github.com/networkupstools/nut/issues/1949 for details.\ndnl Oddly, autoconf-2.69 on CentOS 7 both complains that AC INIT argument\ndnl is not a literal, and does contain expected values in the generated\ndnl script and include/config.h. A \"pure\" m4 solution would be quieter.\nAC_INIT([nut],\n    m4_esyscmd_s([NUT_VERSION_QUERY=VER50 \"`dirname \"$0\"`/tools/gitlog2version.sh\" 2>/dev/null]),\n    [https://github.com/networkupstools/nut/issues],[nut],\n    m4_esyscmd_s([NUT_VERSION_QUERY=URL \"`dirname \"$0\"`/tools/gitlog2version.sh\" 2>/dev/null]))\ndnl See docs/maintainer-guide.txt about releases - updating the version\ndnl above is a small part of the consistent ritual!\n\ndnl PACKAGE_URL=\"https://www.networkupstools.org/\" for development iterations\ndnl or \"https://www.networkupstools.org/historic/v1.2.3/index.html\" for release\ndnl snapshots further set in stone. Either way, there should be a slash and\ndnl either a filename, or nothing. Adding a bogus filename and chopping it\ndnl off by `dirname` should do the trick.\ndnl NOTE: the resulting NUT_WEBSITE_BASE string does not end with a slash!\nNUT_WEBSITE_BASE=\"`dirname \"${PACKAGE_URL}index.html\"`\"\ndnl Fallback, no trailing slash!\ntest -n \"${NUT_WEBSITE_BASE-}\" || NUT_WEBSITE_BASE='https://www.networkupstools.org'\n\ndnl Note: this refers to GITREV at the time of configure script running\ndnl primarily for better messaging in the script itself (also to render\ndnl the PDF documentation revision history via docs/docinfo.xml.in).\ndnl If the NUT codebase in this workspace is being developed and rebuilt\ndnl without reconfiguration, detailed version in the binaries will differ\ndnl (that one comes from the NUT_VERSION_MACRO from nut_version.h file).\ndnl # Example:   NUT_SOURCE_GITREV='2.8.2.695.1-696-g0e00f0777'\nNUT_SOURCE_GITREV=\"`NUT_VERSION_QUERY=DESC50 \"${srcdir}/tools/gitlog2version.sh\" 2>/dev/null`\"\n\ndnl A true/false (literally) response that can be used for prettier messages\ndnl emitted by NUT code.\nNUT_SOURCE_GITREV_IS_RELEASE=\"`NUT_VERSION_QUERY=IS_RELEASE \"${srcdir}/tools/gitlog2version.sh\" 2>/dev/null`\"\nAS_IF([$NUT_SOURCE_GITREV_IS_RELEASE], [NUT_SOURCE_GITREV_DEVREL=\"release\"], [NUT_SOURCE_GITREV_DEVREL=\"development iteration\"])\n\ndnl Semantic version of most-recent NUT release this code is derived from.\ndnl It may equal the NUT_SOURCE_GITREV and NUT_SOURCE_GITREV_NUMERIC, but\ndnl this situation is only expected if NUT_SOURCE_GITREV_IS_RELEASE==true.\nNUT_SOURCE_GITREV_SEMVER=\"`NUT_VERSION_QUERY=SEMVER \"${srcdir}/tools/gitlog2version.sh\" 2>/dev/null`\"\n\ndnl Gitrev-based build identifier which can be used for e.g. PyPI uploads:\ndnl # Example:   NUT_SOURCE_GITREV_NUMERIC='2.8.2.695.1.696'\ndnl #   NUT_SOURCE_GITREV_NUMERIC=\"`echo \"${NUT_SOURCE_GITREV}\" | sed -e 's/^v//' -e 's/-g.*$//' -e 's/-/./g'`\"\ndnl # Without the commit-count since tag (dash-separated part):\ndnl # Example:   NUT_SOURCE_GITREV_NUMERIC='2.8.2.695.1'\nNUT_SOURCE_GITREV_NUMERIC=\"`echo \"${NUT_SOURCE_GITREV}\" | sed -e 's/^v//' -e 's/-g.*$//' -e 's/-@<:@0-9@:>@*$//'`\"\n\ndnl Note: except for experiments, do not pass this into config.h - use\ndnl the NUT_VERSION_MACRO from nut_version.h instead. Developers may\ndnl want to disable their \"force-nut-version-header\" configure option\ndnl to reduce rebuild scope and so speed up the iterations with ccache.\ndnl New \"config.h\" contents for every reconfig would defeat that purpose!\ndnl ### AS_IF([test -n \"${NUT_SOURCE_GITREV-}\"],\ndnl ###     [AC_DEFINE_UNQUOTED([NUT_SOURCE_GITREV], [\"${NUT_SOURCE_GITREV}\"], [NUT source revision when the build was configured])],\ndnl ###     [AC_DEFINE([NUT_SOURCE_GITREV], [NULL], [NUT source revision when the build was configured: not detected])])\n\ndnl Keep track of command-line options passed to this script:\nAC_MSG_CHECKING([for CONFIG_FLAGS])\nCONFIG_FLAGS=\"\"\ndnl Keep each token quoted, in case spaces or other special chars crawl in:\n_flag_enable_inplace_runtime=\"\"\nfor F in \"$@\" ; do\n    case \"$F\" in\n    *=*\" \"*) NF=\"$(echo \"$F\" | sed \"s,=,=',\")\"\"'\" && F=\"$NF\" ;;\n    esac\n\n    case \"$F\" in\n    --disable-inplace-runtime|--enable-inplace-runtime=no) _flag_enable_inplace_runtime=\"no\" ;;\n    --enable-inplace-runtime*) _flag_enable_inplace_runtime=\"$F\" ;;\n    *)\n        test -z \"${CONFIG_FLAGS}\" \\\n        && CONFIG_FLAGS=\"$F\" \\\n        || CONFIG_FLAGS=\"${CONFIG_FLAGS} $F\"\n        ;;\n    esac\ndone\ndnl Keep it \"known\" that we tried to re-use at least some local configuration\ndnl so unspecified options are not necessarily at default values for this script\nAS_IF([test x\"${NUT_VERSION_DEPLOYED-}\" = x\"<reenter>\"], [_flag_enable_inplace_runtime=\"reenter\"])\nF=\"\"\nAS_IF([test x\"${NUT_VERSION_DEPLOYED-}\" != x && test x\"${NUT_VERSION_DEPLOYED-}\" != x\"<reenter>\"], [\n     dnl Even if explicitly disabled... did we re-enter? Save the value to be seen:\n     F=\"--enable-inplace-runtime='${NUT_VERSION_DEPLOYED}'\"\n    ],[\n     AS_CASE([\"${_flag_enable_inplace_runtime}\"],\n        [no|\"\"|reenter], [],\n        [F=\"${_flag_enable_inplace_runtime}\"])\n    ])\nAS_IF([test x\"$F\" != x], [\n    test -z \"${CONFIG_FLAGS}\" \\\n    && CONFIG_FLAGS=\"$F\" \\\n    || CONFIG_FLAGS=\"${CONFIG_FLAGS} $F\"\n    ])\nunset _flag_enable_inplace_runtime\nunset F\nunset NF\nAC_MSG_RESULT([${CONFIG_FLAGS}])\n\nAC_DEFINE_UNQUOTED([CONFIG_FLAGS],[\"${CONFIG_FLAGS}\"],[Flags passed to configure script])\nAC_SUBST(CONFIG_FLAGS)\n\nAC_CONFIG_AUX_DIR([.])\nAC_CONFIG_SRCDIR(server/upsd.c)\nAC_CONFIG_MACRO_DIR([m4])\nAS_IF([test x\"${NUT_SOURCE_GITREV}\" = x],\n    [echo \"Network UPS Tools version ${PACKAGE_VERSION}\"],\n    [AS_IF([test x\"${NUT_SOURCE_GITREV}\" = x\"${PACKAGE_VERSION}\"],\n        [echo \"Network UPS Tools version ${PACKAGE_VERSION} ${NUT_SOURCE_GITREV_DEVREL}\"],\n        [echo \"Network UPS Tools version ${PACKAGE_VERSION} (${NUT_SOURCE_GITREV}) ${NUT_SOURCE_GITREV_DEVREL}\"])\n    ])\nAC_CANONICAL_TARGET\nNUT_CHECK_OS\nNUT_STASH_WARNINGS\nAC_CONFIG_HEADERS([include/config.h])\nAC_PREFIX_DEFAULT(/usr/local/ups)\nAM_INIT_AUTOMAKE([subdir-objects])\n\nAS_CASE([${target_os}],\n\t[*mingw*], [AS_CASE([${CFLAGS-}${CXXFLAGS-}],\n\t\t[*\"-std=c\"*|*-ansi*], [\n\t\t\tAC_MSG_NOTICE(\n[-----------------------------------------------------------------------\nWARNING: It seems you are building with MinGW and requested a strict C/C++\nlanguage mode. Per https://stackoverflow.com/a/76780217/4715872 MinGW may\nnot define WIN32 and other options needed for proper building and linking.\nIf this happens, please retry with GNU C/C++ language mode options instead.\n-----------------------------------------------------------------------])\n\t\t\tsleep 5\n\t\t])]\n)\n\ndnl +-------------------------------------------------------------------\ndnl Help avoid \"polluting\" CFLAGS etc. with auto-settings like \"-g -O2\"\ndnl at least if we intend to tune --with-debuginfo anyway (where we check\ndnl if the caller asked for specific optimizations). Following some\ndnl experimentation, we do not want to actually mangle the flags provided\ndnl by autoconf - for GCC at least, the rightmost mentions of conflicting\ndnl flags on command line win. We just want to know when it is okay to add\ndnl ours. They may be inherited from \"in-place\" build setup though.\ntest -n \"${CONFIG_CFLAGS-}\" || CONFIG_CFLAGS=\"${CFLAGS-}\"\ntest -n \"${CONFIG_CXXFLAGS-}\" || CONFIG_CXXFLAGS=\"${CXXFLAGS-}\"\ndnl +-------------------------------------------------------------------\n\ndnl Default to `configure --enable-silent-rules` or `make V=1` for details?\ndnl This feature seems to require automake-1.13 or newer (1.11+ by other info)\ndnl On very old systems can comment it away with little loss (then automake-1.10\ndnl is known to suffice):\nm4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])],\n\t[AC_MSG_NOTICE([Silent Rules feature not defined in this automake version, skipped])])\n\ndnl +-------------------------------------------------------------------\ndnl we need Autoconf 2.61 or better to enable features of Posix that are extensions to C\ndnl (and actually 2.64 or better for m4/ax_check_compile_flag.m4 when it is sourced)\ndnl UPDATE: As tested on CentOS 6, its \"autoconf-2.63-5.1.el6.noarch\" also suffices.\ndnl But OpenBSD 6.5 requires autoconf-2.65 and automake-1.13 or newer...\ndnl AC_MSG_NOTICE([CFLAGS_BEFORE_ACPROG=\"${CFLAGS-}\"])\ndnl AC_MSG_NOTICE([CXXFLAGS_BEFORE_ACPROG=\"${CXXFLAGS-}\"])\nAC_MSG_CHECKING(for autoconf macro to enable system extensions)\nm4_version_prereq(2.61, [\n\tAC_MSG_RESULT(yes)\n        dnl Causes calls to ac_prog stuff, so dittoed below if \"no\"\n\tAC_USE_SYSTEM_EXTENSIONS\n], [\n\tAC_MSG_RESULT(no)\n\tAC_PROG_CC\n])\n\nAC_PREREQ([2.63])\ndnl #AC_PREREQ([2.64])\n\ndnl Macro AC_PROG_CC_C99 is obsolete; use AC_PROG_CC\ndnl Note that NUT does not support building with C89 anyway\ndnl AC_PROG_CC_C99\ndnl Needed for per-target flags\nAM_PROG_CC_C_O\nAC_PROG_CPP\nAC_PROG_CXX\nAC_PROG_CXX_C_O\n\nCFLAGS_AFTER_ACPROG=\"${CFLAGS-}\"\nCXXFLAGS_AFTER_ACPROG=\"${CXXFLAGS-}\"\n\ndnl AC_MSG_NOTICE([CFLAGS_AFTER_ACPROG=\"${CFLAGS-}\"])\ndnl AC_MSG_NOTICE([CXXFLAGS_AFTER_ACPROG=\"${CXXFLAGS-}\"])\n\ndnl # LEGACY DEFAULT FALLBACK which NUT had since 2005 or before:\ndnl # if autoconf does not set any options, use default/moderate optimizations\nCFLAGS=${CFLAGS-\"-O\"}\ndnl # Not so far a legacy, added for consistency in 2024 :)\nCXXFLAGS=${CXXFLAGS-\"-O\"}\n\ndnl +-------------------------------------------------------------------\n\ndnl Use \"./configure --enable-maintainer-mode\" to keep Makefile.in and Makefile\ndnl in sync after Git updates.\nAM_MAINTAINER_MODE\n\ndnl GNU and BSD make are okay with the syntax, but Sun make/dmake are not:\nAC_MSG_CHECKING([whether this make implementation supports export VAR=VAL syntax])\ndnl # using printf formatting for some funniner shells out there\nnut_am_output=\"`printf 'export VAR=VAL\\ntest:\\n\\t@echo \"VAR=%s%sVAR%s\"\\n' '\\$' '(' ')' | ${MAKE-make} -f - test`\"\nnut_am_result=\"$?\"\nAS_IF([test x\"${nut_am_result}\" = x0 -a x\"${nut_am_output}\" = x\"VAR=VAL\"], [\n\tNUT_AM_MAKE_CAN_EXPORT=\"\"\n\tAC_MSG_RESULT(yes)\n], [\n\tNUT_AM_MAKE_CAN_EXPORT=\"#ThisMakeCanNotExport# \"\n\tAC_MSG_RESULT(no: got '${nut_am_output}')\n])\nAC_SUBST(NUT_AM_MAKE_CAN_EXPORT)\n\ndnl Some systems have older autotools without direct macro support for PKG_CONF*\nNUT_CHECK_PKGCONFIG\n\n\ndnl Various version related processing\ndnl ----------------------------------\n\ndnl # the following is commented out, because the UPS_VERSION macro now\ndnl # resides in include/nut_version.h, which is generated by Makefile.am,\ndnl # rather than in include/config.h, which is generated by configure.  The\ndnl # reason is that the SVN revision should be computed at compile time,\ndnl # not configure time.\ndnl AC_DEFINE_UNQUOTED(UPS_VERSION, \"${PACKAGE_VERSION}\", [NUT version])\n\ndnl However, automatically define the tree version (mostly for AC_SUBST)\ndnl FIXME: This just picks first 3 chars, assuming single-digit components\ndnl  separated by a dot:\nTREE_VERSION=\"`echo ${PACKAGE_VERSION} | awk '{ print substr($0,1,3) }'`\"\nAC_DEFINE_UNQUOTED(TREE_VERSION, \"${TREE_VERSION}\", [NUT tree version])\n\ndnl Should not be necessary, since old servers have well-defined errors for\ndnl unsupported commands:\nNUT_NETVERSION=\"1.3\"\nAC_DEFINE_UNQUOTED(NUT_NETVERSION, \"${NUT_NETVERSION}\", [NUT network protocol version])\n\n\ndnl Fix this early so we can expand with eval later\ntest \"${prefix}\" = \"NONE\" && prefix=\"${ac_default_prefix}\"\ntest \"${exec_prefix}\" = \"NONE\" && exec_prefix='${prefix}'\n\ndnl Note: for practical and platform-independent use, see AX_REALPATH macro\nAC_CHECK_PROGS([REALPATH], [realpath], [])\n\ndnl FIXME: remove after dev-testing\ndnl UNITTEST_AX_REALPATH\ndnl exit\n\ndnl NOTE: for definition of NUT_* autoconf macros, see m4/ directory\ndnl and docs/macros.txt\n\ndnl +------------------------------------------------------------------+\ndnl | default values for things later on (can be overridden)           |\n\nSTATEPATH=\"/var/state/ups\"\n\ndnl Historically this refers to *system location* for PID files,\ndnl and more specifically that for `upsmon` (running as `root`).\ndnl See also ALTPIDPATH (defaulted to STATEPATH) setting below\ndnl for the unprivileged daemons (`upsd`, drivers).\nPIDPATH=\"/var/run\"\ndnl Honour new LFS recommendations if applied on the build system:\nAS_IF([test -d \"/run\"], [PIDPATH=\"/run\"])\n\nAC_CHECK_PROGS([GETENT], [getent], [])\nAC_CHECK_PROGS([ID], [id], [])\n\nPROBE_OS_USER=\"false\"\nPROBE_OS_GROUP=\"false\"\nAS_IF([test x\"${GETENT}\" != x], [\n\tPROBE_OS_USER=\"${GETENT} passwd \"\n\tPROBE_OS_GROUP=\"${GETENT} group \"\n\t],[\n\tAS_IF([test x\"${ID}\" != x], [\n\t\tPROBE_OS_USER=\"${ID} -u \"\n\t\tPROBE_OS_GROUP=\"${ID} -g \"\n\t\t],[\n\t\tAC_MSG_WARN([Can not check existence of user and group accounts on this system])\n\t\t])\n\t]\n)\n\ndnl Defaults for respective configure options below\ndnl Note these defaults may change further below depending on OS and\ndnl certain other configure options (e.g. \"in-place replacement\")\nRUN_AS_USER=\"nobody\"\nRUN_AS_GROUP=\"nobody\"\nAS_IF([test -n \"`${PROBE_OS_GROUP} nogroup`\" && ! test -n \"`${PROBE_OS_GROUP} \"${RUN_AS_GROUP}\"`\"],\n    [RUN_AS_GROUP=\"nogroup\"]\n)\n\ndnl NOTE: NUT legacy default, keep as is for least surprise\ndnl Distributions are however welcome to specify the option to use tmpfs\nAS_CASE([${target_os}],\n\t[*mingw*], [POWERDOWNFLAG=\"C:\\\\\\\\killpower\"], dnl NOTE: Double backslashes (times escaping) are correct!\n\t[POWERDOWNFLAG=\"/etc/killpower\"] dnl POSIX systems default\n)\n\ncgiexecdir='${exec_prefix}/cgi-bin'\ndriverexecdir='${exec_prefix}/bin'\ndnl Note: htmldir per se is originally for nut-cgi resources\nhtmldir='${prefix}/html'\nhtmldocdir='${docdir}/html-doc'\nhtmlmandir='${docdir}/html-man'\npkgconfigdir='${libdir}/pkgconfig'\n\ndnl Detection of augeas lens dirs is a bit troublesome, since\ndnl they (if present) reside in location not controlled by NUT.\ndnl Try detecting based on build parameters, or fall back to\ndnl hard-coded default location (may break e.g. distcheck).\ndnl Note it would not work too well for \"/usr/local/ups\" :)\nauglensdir='${datarootdir}/augeas/lenses/dist'\nconftemp=\"${auglensdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\n\nif test ! -d \"${conftemp}\"; then\n    auglensdir='${datarootdir}/augeas/lenses'\n    conftemp=\"${auglensdir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n\n    if test ! -d \"${conftemp}\"; then\n        auglensdir='/usr/share/augeas/lenses/dist'\n        if test ! -d \"${auglensdir}\"; then\n            auglensdir='/usr/share/augeas/lenses'\n            if test ! -d \"${auglensdir}\"; then\n                auglensdir=''\n            fi\n        fi\n    fi\nfi\n\ndnl ### NUT_CHECK_LIBREGEX ### Detect below as part of libusb etc.\ndnl ### LIBREGEX_LIBS=''\ndnl Disable Hotplug, DevD and udev support on Windows\ndnl (useful when cross-compiling)\ncase \"${target_os}\" in\n    *mingw* )\n        dnl TODO: Actually detect it? See also nut_check_libregex.m4 for same.\n        dnl Here we assumed from practice that it is available...\n        dnl ### if test x\"${LIBREGEX_LIBS}\" = x ; then\n        dnl ###     LIBREGEX_LIBS='-lregex'\n        dnl ### fi\n        hotplugdir=''\n        udevdir=''\n        devddir=''\n        ;;\n    * )\n        hotplugdir='/etc/hotplug'\n        if test ! -d \"${hotplugdir}\"; then\n            hotplugdir=''\n        fi\n\n        udevdir='/lib/udev'\n        if test ! -d \"${udevdir}\"; then\n            udevdir='/etc/udev'\n            if test ! -d \"${udevdir}\"; then\n                udevdir=''\n            fi\n        fi\n\n        devddir='/usr/local/etc/devd'\n        if test ! -d \"${devddir}\"; then\n            devddir='/etc/devd'\n            if test ! -d \"${devddir}\"; then\n               devddir=''\n            fi\n        fi\n        ;;\nesac\n\ndnl Note: this deals with run-time settings so that the newly built\ndnl programs can be \"just executed\" to use same configuration files\ndnl and filesystem object permissions as an older deployment of NUT\ndnl on this system; this specifically does not deal with trying to\ndnl use same prefix and other paths to fully replace an older setup\ndnl (a different option might be crafted to do that, but really the\ndnl arcane distro-dependent packaging recipes are a better way here).\ndnl This feature is intended for users who want to see if a custom\ndnl build of NUT supports their hardware or other use-cases better.\nNUT_ARG_ENABLE([inplace-runtime],\n    [Request configure option defaults for runtime user/group/confpath based on currently installed NUT (to extent these can be detected)],\n    [no])\n\ndnl Check for not re-entering in this run - whether NUT_VERSION_DEPLOYED is set\nAS_IF([test x\"$nut_enable_inplace_runtime\" = xyes -a x\"${NUT_VERSION_DEPLOYED-}\" = x], [\n    AC_MSG_NOTICE([checking for location, CONFIG_FLAGS and version of an already deployed NUT build (if it reports those)])\n\n    dnl If existing NUT installation reports its build options, re-run this\n    dnl script with those flags (overridden by any options passed currently):\n    conftemp=\"${sbindir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    PREFIX_SBINDIR=\"${conftemp}\"\n\n    conftemp=\"${bindir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    PREFIX_BINDIR=\"${conftemp}\"\n\n    DEPLOYED_SBINDIR=\"${PREFIX_SBINDIR}\"\n    DEPLOYED_BINDIR=\"${PREFIX_BINDIR}\"\n    dnl Note use of AC_PATH_PROG for specific pathname (not AC_CHECK_PROGS which picks filename variants)!\n    dnl Note: \"ordinary\" users might not have \"sbin\" in their default PATH, so appending it:\n    dnl Note: in some systems, the file in PATH is a shell\n    dnl       wrapper for /etc/nut/nut.conf MODE support\n    AC_PATH_PROG([DEPLOYED_UPSD], [upsd], [], [${PREFIX_SBINDIR}:${PATH}:/sbin:/usr/sbin:/usr/local/sbin])\n    dnl ...however \"upsc\" is a userland tool so should be there:\n    AC_PATH_PROG([DEPLOYED_UPSC], [upsc], [], [${PREFIX_BINDIR}:${PATH}])\n    AS_IF([test -x \"${DEPLOYED_UPSD}\"], [\n        AX_REALPATH([$DEPLOYED_UPSD], [DEPLOYED_UPSD])\n        DEPLOYED_SBINDIR=\"`dirname \"${DEPLOYED_UPSD}\"`\"\n        ])\n    AS_IF([test -x \"${DEPLOYED_UPSC}\"], [\n        AX_REALPATH([$DEPLOYED_UPSC], [DEPLOYED_UPSC])\n        DEPLOYED_BINDIR=\"`dirname \"${DEPLOYED_UPSC}\"`\"\n        ])\n\n    DEPLOYED_PREFIX=\"\"\n    AS_IF([test -d \"${DEPLOYED_SBINDIR}\"],\n        [DEPLOYED_PREFIX=\"`dirname \"${DEPLOYED_SBINDIR}\"`\"],\n        [AS_IF([test -d \"${DEPLOYED_BINDIR}\"],\n            [DEPLOYED_PREFIX=\"`dirname \"${DEPLOYED_BINDIR}\"`\"])]\n    )\n\n    AC_MSG_CHECKING([for CONFIG_FLAGS of an already deployed NUT build (if it reports those)])\n\n    CONFIG_FLAGS_DEPLOYED=\"\"\n    NUT_VERSION_DEPLOYED=\"\"\n    dnl TODO: Similar query can be done for BINDIR tools\n    dnl and for libupsclient-config if deployed locally\n    for DEPLOYED_TOOL in \\\n        \"${DEPLOYED_UPSD}\" \\\n        \"${DEPLOYED_UPSC}\" \\\n    ; do\n        AS_IF([test x\"${DEPLOYED_TOOL}\" = x], [continue])\n        AS_IF([test -x \"${DEPLOYED_TOOL}\"], [], [continue])\n\n        AC_MSG_CHECKING([for CONFIG_FLAGS from ${DEPLOYED_TOOL}])\n        CONFIG_FLAGS_DEPLOYED=\"`\"${DEPLOYED_TOOL}\" -DV 2>&1 | grep 'configured with flags:' | head -1 | sed 's,^.*configured with flags: *,,'`\" \\\n        && test x\"${CONFIG_FLAGS_DEPLOYED}\" != x \\\n        || CONFIG_FLAGS_DEPLOYED=\"\"\n\n        NUT_VERSION_DEPLOYED=\"`\"${DEPLOYED_TOOL}\" -DV 2>&1 | grep 'configured with flags:' | head -1 | sed 's,^.*Network UPS Tools version \\(.*\\) configured with flags:.*$,\\1,'`\" \\\n        && test x\"${NUT_VERSION_DEPLOYED}\" != x \\\n        || NUT_VERSION_DEPLOYED=\"\"\n\n        AS_IF([test x\"${CONFIG_FLAGS_DEPLOYED}${NUT_VERSION_DEPLOYED}\" = x], [], [break])\n    done\n\n    AS_IF([test x\"${CONFIG_FLAGS_DEPLOYED}\" != x], [\n        AC_MSG_RESULT([CONFIG_FLAGS_DEPLOYED: ${CONFIG_FLAGS_DEPLOYED}])\n    ],[\n        AC_MSG_RESULT([CONFIG_FLAGS_DEPLOYED: not reported])\n    ])\n\n    dnl Account for custom paths if known/found:\n    AS_IF([test x\"${DEPLOYED_PREFIX}\" != x && test x\"${DEPLOYED_PREFIX}\" != x\"${prefix}\"],\n        AC_MSG_WARN([Deployed NUT installation uses a PREFIX different from one specified (wins) or derived (loses) for this build: '${DEPLOYED_PREFIX}' vs. '${prefix}'])\n        [AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n            [*--prefix=*], [],\n            [CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --prefix='${DEPLOYED_PREFIX}'\"])\n    ])\n\n    AS_IF([test x\"${DEPLOYED_SBINDIR}\" != x && test x\"${DEPLOYED_SBINDIR}\" != x\"${PREFIX_SBINDIR}\"],\n        AC_MSG_WARN([Deployed NUT installation uses a SBINDIR different from one specified (wins) or derived (loses) for this build: '${DEPLOYED_SBINDIR}' vs. '${sbindir}'])\n        [AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n            [*--sbindir=*], [],\n            [CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --sbindir='${DEPLOYED_SBINDIR}'\"])\n    ])\n\n    AS_IF([test x\"${DEPLOYED_BINDIR}\" != x && test x\"${DEPLOYED_BINDIR}\" != x\"${PREFIX_BINDIR}\"],\n        AC_MSG_WARN([Deployed NUT installation uses a BINDIR different from one specified (wins) or derived (loses) for this build: '${DEPLOYED_BINDIR}' vs. '${bindir}'])\n        [AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n            [*--bindir=*], [],\n            [CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --bindir='${DEPLOYED_BINDIR}'\"])\n    ])\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--sysconfdir=*], [\n            for F in ${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS} ; do\n                case \"$F\" in\n                    \"--sysconfdir=\"*) sysconfdir=\"`echo \"$F\" | ( IFS='=' read K V ; echo \"$V\" )`\" ;;\n                esac\n            done\n        ],\n        [\n        dnl If there was no custom --sysconfdir=/etc/myNUT passed,\n        dnl try to default it to something from existing deployment.\n        dnl NOTE: Single-quotes are correct for autotools default,\n        dnl expanded at runtime (see conftemp tricks below)\n\n        AC_MSG_CHECKING([for in-place replacement default sysconfdir (better than '${sysconfdir}')])\n        DEPLOYED_SYSCONFDIR=\"\"\n\n        dnl TODO: Any more reasonable defaults? Pile them on here :)\n        for D in \\\n            /etc/nut /etc/ups \\\n            /usr/etc/nut /usr/etc/ups \\\n            /usr/local/etc/nut /usr/local/etc/ups \\\n            /usr/local/nut/etc /usr/local/ups/etc \\\n        ; do\n            if test -e \"$D/ups.conf\" || test -e \"$D/upsmon.conf\" \\\n            || ( test -e \"$D/upsd.conf\" && test -e \"$D/upsd.users\" ) \\\n            ; then\n                DEPLOYED_SYSCONFDIR=\"$D\"\n                break\n            else\n                if test -d \"$D/\" && test ! -r \"$D/\" ; then\n                    dnl Keeping order of preference defined by \"for\" loop:\n                    AC_MSG_WARN([Picking directory '${D}' which exists but current build user may not read])\n                    DEPLOYED_SYSCONFDIR=\"$D\"\n                    break\n                fi\n            fi\n        done\n\n        AS_IF([test -n \"${DEPLOYED_SYSCONFDIR}\"], [\n            AC_MSG_RESULT([${DEPLOYED_SYSCONFDIR}])\n            dnl May be used in searches below:\n            sysconfdir=\"${DEPLOYED_SYSCONFDIR}\"\n            CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --sysconfdir='${DEPLOYED_SYSCONFDIR}'\"\n        ], [\n            AC_MSG_RESULT([not detected])\n        ])\n    ])\n\n    dnl Prepare paths that may be used in user/group searches below:\n    conftemp=\"${sysconfdir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    CONFPATH=\"${conftemp}\"\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--libdir=*], [\n            for F in ${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS} ; do\n                case \"$F\" in\n                    \"--libdir=\"*) libdir=\"`echo \"$F\" | ( IFS='=' read K V ; echo \"$V\" )`\" ;;\n                esac\n            done\n        ]\n    )\n\n    conftemp=\"${libdir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    LIBDIR=\"${conftemp}\"\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--libexecdir=*], [\n            for F in ${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS} ; do\n                case \"$F\" in\n                    \"--libexecdir=\"*) libexecdir=\"`echo \"$F\" | ( IFS='=' read K V ; echo \"$V\" )`\" ;;\n                esac\n            done\n        ]\n    )\n\n    conftemp=\"${libexecdir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    LIBEXECDIR=\"${conftemp}\"\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--with-pkgconfig-dir=*], [\n            for F in ${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS} ; do\n                case \"$F\" in\n                    \"--with-pkgconfig-dir=\"*) pkgconfigdir=\"`echo \"$F\" | ( IFS='=' read K V ; echo \"$V\" )`\" ;;\n                esac\n            done\n        ]\n    )\n\n    dnl pkgconfigdir may have more indirections:\n    conftemp=\"${pkgconfigdir}\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    eval conftemp=\\\"${conftemp}\\\"\n    PKGCONFIGDIR=\"${conftemp}\"\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--with-group=*], [],\n        [\n        AC_MSG_CHECKING([for in-place replacement default group (better than '${RUN_AS_GROUP}')])\n        nut_inplace_group=\"\"\n        AS_IF([test -d \"${udevdir}/rules.d\"],\n            [for F in \"${udevdir}/rules.d\"/*-nut-*.rules ; do\n                if test -s \"$F\" ; then\n                    nut_inplace_group=\"`grep GROUP= \"$F\" | head -1 | sed 's,^.* GROUP=\"*\\(.*\\)\"*.*$,\\1,'`\" \\\n                    && test -n \"`${PROBE_OS_GROUP} \"${nut_inplace_group}\"`\" \\\n                    && AC_MSG_RESULT([Got from ${F}]) \\\n                    && break \\\n                    || nut_inplace_group=\"\"\n                fi\n             done\n            ])\n\n        AS_IF([test -z \"${nut_inplace_group}\"],\n            [AS_IF([test -n \"`${PROBE_OS_GROUP} nut`\"], [nut_inplace_group=\"nut\"],\n                [AS_IF([test -n \"`${PROBE_OS_GROUP} ups`\"], [nut_inplace_group=\"ups\"])])])\n\n        AS_IF([test -n \"${nut_inplace_group}\"], [\n            AC_MSG_RESULT([${nut_inplace_group}])\n            CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --with-group='${nut_inplace_group}'\"\n        ], [\n            AC_MSG_RESULT([not detected])\n        ])\n    ])\n\n    AS_CASE([\"${CONFIG_FLAGS_DEPLOYED} ${CONFIG_FLAGS}\"],\n        [*--with-user=*], [],\n        [\n        AC_MSG_CHECKING([for in-place replacement default user (better than '${RUN_AS_USER}')])\n        nut_inplace_user=\"\"\n\n        dnl Beside currently active setting, check the built-in default sugestion\n        AS_IF([test -s \"${CONFPATH}/upsmon.conf\"],\n            [for nut_inplace_user in \\\n                `grep -E '^ *RUN_AS_USER' \"${CONFPATH}/upsmon.conf\" | awk '{print $2}'`\\\n                `grep -E '^ *##*RUN_AS_USER' \"${CONFPATH}/upsmon.conf\" | awk '{print $2}'`\\\n                `grep -E '^ *##*  *RUN_AS_USER' \"${CONFPATH}/upsmon.conf\" | awk '{print $3}'`\\\n            ; do \\\n                AS_IF([test -z \"${nut_inplace_user}\"], [\n                    test -n \"`${PROBE_OS_USER} \"${nut_inplace_user}\"`\" \\\n                    && AC_MSG_RESULT([Got from ${CONFPATH}/upsmon.conf]) \\\n                    || nut_inplace_user=\"\"])\n             done\n        ])\n\n        AS_IF([test -s \"${CONFPATH}/upsmon.conf.sample\" && test -z \"${nut_inplace_user}\"],\n            [for nut_inplace_user in \\\n                `grep -E '^ *RUN_AS_USER' \"${CONFPATH}/upsmon.conf.sample\" | awk '{print $2}'`\\\n                `grep -E '^ *##*RUN_AS_USER' \"${CONFPATH}/upsmon.conf.sample\" | awk '{print $2}'`\\\n                `grep -E '^ *##*  *RUN_AS_USER' \"${CONFPATH}/upsmon.conf.sample\" | awk '{print $3}'`\\\n            ; do \\\n                AS_IF([test -z \"${nut_inplace_user}\"], [\n                    test -n \"`${PROBE_OS_USER} \"${nut_inplace_user}\"`\" \\\n                    && AC_MSG_RESULT([Got from ${CONFPATH}/upsmon.conf]) \\\n                    || nut_inplace_user=\"\"])\n             done\n        ])\n\n        dnl Note: with default short inplace and no prefix, this would look under\n        dnl /usr/local/ups/lib/pkgconfig which may be irrelevant for packaged setups\n\n        dnl TODO: Any more reasonable defaults? Pile them on here :)\n        for F in \\\n            \"${PKGCONFDIR}/libupsclient.pc\" \\\n            \"${PKGCONFDIR}/libnutclient.pc\" \\\n            \"${LIBDIR}/pkgconfig/libupsclient.pc\" \\\n            \"${LIBDIR}/pkgconfig/libnutclient.pc\" \\\n        ; do\n            AS_IF([test -z \"${nut_inplace_user}\" && test -s \"$F\"],\n                [nut_inplace_user=\"`grep -E '^ *nutuser=' \"$F\" | sed 's,^ *nutuser=,,'`\" \\\n                && test -n \"`${PROBE_OS_USER} \"${nut_inplace_user}\"`\" \\\n                && AC_MSG_RESULT([Got from $F]) \\\n                || nut_inplace_user=\"\"\n            ])\n        done\n\n        AS_IF([test -z \"${nut_inplace_user}\"],\n            [AS_IF([test -n \"`${PROBE_OS_USER} nut`\"], [nut_inplace_user=\"nut\"],\n                [AS_IF([test -n \"`${PROBE_OS_USER} ups`\"], [nut_inplace_user=\"ups\"])])])\n\n        AS_IF([test -n \"${nut_inplace_user}\"], [\n            AC_MSG_RESULT([${nut_inplace_user}])\n            CONFIG_FLAGS_DEPLOYED=\"${CONFIG_FLAGS_DEPLOYED} --with-user='${nut_inplace_user}'\"\n        ], [\n            AC_MSG_RESULT([not detected])\n        ])\n    ])\n\n    AS_IF([test x\"${CONFIG_FLAGS_DEPLOYED}\" != x], [\n        AC_MSG_NOTICE([Detected CONFIG_FLAGS of an already deployed NUT installation, using them for --inplace-runtime configuration (restarting script)])\n        dnl For multiply-specified flags with conflicting values, last mention wins:\n        AC_MSG_NOTICE([exec \"$0\" $CONFIG_FLAGS_DEPLOYED $CONFIG_FLAGS --disable-inplace-runtime])\n        AS_IF([test x\"${NUT_VERSION_DEPLOYED}\" != x], [\n            AC_MSG_NOTICE([NUT_VERSION_DEPLOYED: ${NUT_VERSION_DEPLOYED}])\n        ],[\n            NUT_VERSION_DEPLOYED=\"<reenter>\"\n        ])\n        export NUT_VERSION_DEPLOYED\n        dnl # Avoid replacement after re-entering:\n        test -n \"${CONFIG_CFLAGS-}\" || CONFIG_CFLAGS=\" \"\n        test -n \"${CONFIG_CXXFLAGS-}\" || CONFIG_CXXFLAGS=\" \"\n        export CONFIG_CFLAGS\n        export CONFIG_CXXFLAGS\n\n        AC_MSG_NOTICE([Moving config.log of the original invocation to config.log.inplace-outer just before exec...])\n        mv -f config.log config.log.inplace-outer || true\n\n        eval exec \"$0\" $CONFIG_FLAGS_DEPLOYED $CONFIG_FLAGS --disable-inplace-runtime\n    ],[\n        AC_MSG_NOTICE([No CONFIG_FLAGS were reported or discovered from existing NUT deployment (if any); restarting script for a clean run])\n        NUT_VERSION_DEPLOYED=\"<reenter>\"\n        export NUT_VERSION_DEPLOYED\n        dnl # Avoid replacement after re-entering:\n        test -n \"${CONFIG_CFLAGS-}\" || CONFIG_CFLAGS=\" \"\n        test -n \"${CONFIG_CXXFLAGS-}\" || CONFIG_CXXFLAGS=\" \"\n        export CONFIG_CFLAGS\n        export CONFIG_CXXFLAGS\n\n        AC_MSG_NOTICE([Moving config.log of the original invocation to config.log.inplace-outer just before exec...])\n        mv -f config.log config.log.inplace-outer || true\n\n        AC_MSG_NOTICE([exec \"$0\" $CONFIG_FLAGS --disable-inplace-runtime])\n        eval exec \"$0\" $CONFIG_FLAGS --disable-inplace-runtime\n    ])\n])\n\ndnl Define directory where LIBOBJS replacement functions are\nAC_CONFIG_LIBOBJ_DIR([common])\n\ndnl +-------------------------------------------------------------------\n\nAC_PROG_INSTALL\nAC_PROG_MKDIR_P\nAC_PROG_LN_S\nAC_PROG_EGREP\nAC_PATH_PROG(AR, ar)\nAC_CHECK_TOOL(RANLIB, ranlib, :)\ndnl Postpone call to LT_INIT/AC_CONFIG_FILES to allow disabling static lib\nAC_C_BIGENDIAN\nAC_C_INLINE\nAC_C_FLEXIBLE_ARRAY_MEMBER\nAC_C_VARARRAYS\n\nNUT_ARG_ENABLE([keep_nut_report_feature],\n    [Request that we keep config.nut_report_feature.log (normally deleted by configure script after displaying)],\n    [no])\n\nAS_IF([test x\"${NUT_SOURCE_GITREV}\" = x],\n    [NUT_REPORT([configured version], [${PACKAGE_VERSION}])],\n    [AS_IF([test x\"${NUT_SOURCE_GITREV}\" = x\"${PACKAGE_VERSION}\"],\n        [NUT_REPORT([configured version], [${PACKAGE_VERSION} ${NUT_SOURCE_GITREV_DEVREL}])],\n        [NUT_REPORT([configured version], [${PACKAGE_VERSION} (${NUT_SOURCE_GITREV}) ${NUT_SOURCE_GITREV_DEVREL}])])\n    ])\nNUT_REPORT([Documentation website base URL], [${NUT_WEBSITE_BASE}])\nAC_DEFINE_UNQUOTED([NUT_WEBSITE_BASE], \"${NUT_WEBSITE_BASE}\", [Documentation website base URL, no trailing slash])\n\ndnl Note: the compiler/pragma/attr methods below are custom for NUT codebase:\nNUT_COMPILER_FAMILY\n\ndnl Note: DO NOT AC_DEFINE the \"FULL\" items: they are generally multi-line.\ndnl NUT_REPORT_TARGET([CC_VERSION_FULL],  [\"${CC_VERSION_FULL}\"],  [Version and other details of C compiler])\ndnl NUT_REPORT_TARGET([CXX_VERSION_FULL], [\"${CXX_VERSION_FULL}\"], [Version and other details of C++ compiler])\ndnl NUT_REPORT_TARGET([CPP_VERSION_FULL], [\"${CPP_VERSION_FULL}\"], [Version and other details of C preprocessor])\nNUT_REPORT_TARGET([CC_VERSION],  [\"${CC_VERSION}\"],  [Compact version of C compiler])\nNUT_REPORT_TARGET([CXX_VERSION], [\"${CXX_VERSION}\"], [Compact version of C++ compiler])\nNUT_REPORT_TARGET([CPP_VERSION], [\"${CPP_VERSION}\"], [Compact version of C preprocessor])\n\ndnl Help find warning/error details in a wall of text (must be processed before NUT_COMPILER_FAMILY_FLAGS):\nNUT_ARG_ENABLE([Wcolor],\n    [Request that compiler output is colorized (no = leave it up to compiler defaults)],\n    [no])\nNUT_COMPILER_FAMILY_FLAGS\nAX_C_PRAGMAS\nAX_C___ATTRIBUTE__\nAX_C_PRINTF_STRING_NULL\n\ndnl Check if the system provides a boolean type and how it is spelled\nNUT_CHECK_BOOL\n\ndnl All current systems provide time.h; it need not be checked for.\ndnl Not all systems provide sys/time.h, but those that do, all allow\ndnl you to include it and time.h simultaneously.\ndnl NUT codebase provides the include/timehead.h to wrap these nuances.\nAC_CHECK_HEADERS_ONCE([sys/time.h time.h sys/types.h])\ndnl ###obsolete### AC_HEADER_TIME\nAS_IF([test \"$ac_cv_header_sys_time_h\" = yes],\n    [AC_DEFINE([TIME_WITH_SYS_TIME],[1],[Define to 1 if you can safely include both <sys/time.h>\n         and <time.h>.  This macro is deemed obsolete by autotools.])\n    ], [])\n\nCODE_TIMEINCL=\"\n#ifdef TIME_WITH_SYS_TIME\n# include <sys/time.h>\n# include <time.h>\n#else\n# ifdef HAVE_SYS_TIME_H\n#  include <sys/time.h>\n# else\n#  include <time.h>\n# endif\n#endif\n\"\n\ndnl TEMPORARY to allow certain linux-only buildable drivers\nAC_CHECK_HEADERS_ONCE([linux/serial.h])\nAM_CONDITIONAL(HAVE_LINUX_SERIAL_H, test x\"${ac_cv_header_linux_serial_h}\" = xyes)\n\nAC_CHECK_HEADERS_ONCE([fcntl.h sys/stat.h sys/socket.h netdb.h])\nAC_CHECK_FUNCS(flock lockf fcvt fcvtl dup dup2 abs_val abs)\n\nAC_CHECK_HEADER([float.h],\n    [AC_DEFINE([HAVE_FLOAT_H], [1],\n        [Define to 1 if you have <float.h>.])])\nAC_CHECK_HEADER([math.h],\n    [AC_DEFINE([HAVE_MATH_H], [1],\n        [Define to 1 if you have <math.h>.])])\n\nAC_CHECK_DECLS([fabs, fabsf, fabsl, pow10, round], [], [],\n[#ifdef HAVE_MATH_H\n# include <math.h>\n#endif\n#ifdef HAVE_FLOAT_H\n# include <float.h>\n#endif\n])\n\nAC_CHECK_HEADER([limits.h],\n    [AC_DEFINE([HAVE_LIMITS_H], [1],\n        [Define to 1 if you have <limits.h>.])])\n\nAC_CHECK_HEADER([stdlib.h],\n    [AC_DEFINE([HAVE_STDLIB_H], [1],\n        [Define to 1 if you have <stdlib.h>.])])\n\nAC_CHECK_DECLS(realpath, [], [],\n[#ifdef HAVE_LIMITS_H\n# include <limits.h>\n#endif\n#ifdef HAVE_STDLIB_H\n# include <stdlib.h>\n#endif\n])\n\nAC_CHECK_HEADER([signal.h],\n    [AC_DEFINE([HAVE_SIGNAL_H], [1],\n        [Define to 1 if you have <signal.h>.])])\n\nAC_CHECK_HEADER([sys/signal.h],\n    [AC_DEFINE([HAVE_SYS_SIGNAL_H], [1],\n        [Define to 1 if you have <sys/signal.h>.])])\n\nAC_CHECK_HEADER([sys/resource.h],\n    [AC_MSG_CHECKING([for struct rlimit and getrlimit()])\n     AC_LANG_PUSH([C])\n     AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#include <sys/resource.h>\n],\n[struct rlimit limit;\ngetrlimit(RLIMIT_NOFILE, &limit);\n/* Do not care about actual return value in this test,\n * normally check for non-zero meaning to look in errno */\n]\n        )],\n        [AC_DEFINE([HAVE_SYS_RESOURCE_H], [1],\n            [Define to 1 if you have <sys/resource.h> with usable struct rlimit and getrlimit().])\n         AC_MSG_RESULT([ok])\n        ],\n        [AC_MSG_RESULT([no])]\n     )\n     AC_LANG_POP([C])\n    ]\n)\n\nAC_CHECK_HEADER([poll.h],\n    [AC_DEFINE([HAVE_POLL_H], [1],\n        [Define to 1 if you have <poll.h>.])])\n\nSEMLIBS=\"\"\nAC_CHECK_HEADER([semaphore.h],\n    [AC_DEFINE([HAVE_SEMAPHORE_H], [1],\n        [Define to 1 if you have <sys/semaphore.h>.])\n\n     AC_LANG_PUSH([C])\n     myLIBS=\"${LIBS}\"\n     LIBS=\"\"\n     SEMLIBS_LRT=\"\"\n\n     dnl Solaris 8 builds complain about indirect dependency involved:\n     dnl   sem_init   nut_scanner-nut-scanner.o\n     dnl   (symbol belongs to implicit dependency /usr/lib/librt.so.1)\n     AC_SEARCH_LIBS([sem_init], [pthread], [], [\n\tunset ac_cv_search_sem_init\n\tAC_SEARCH_LIBS([sem_init], [pthread], [SEMLIBS_LRT=\" -lrt\"], [], [-lrt])])\n     AC_SEARCH_LIBS([sem_open], [pthread], [], [\n\tunset ac_cv_search_sem_open\n\tAC_SEARCH_LIBS([sem_open], [pthread], [SEMLIBS_LRT=\" -lrt\"], [], [-lrt])])\n\n     AS_CASE([${ac_cv_search_sem_init}], [no*], [], [SEMLIBS=\"${ac_cv_search_sem_init}\"])\n     AS_CASE([${ac_cv_search_sem_open}], [no*], [], [\"${SEMLIBS}\"], [], [SEMLIBS=\"${ac_cv_search_sem_open}\"])\n     SEMLIBS=\"${SEMLIBS}${SEMLIBS_LRT}\"\n\n     LIBS=\"${SEMLIBS}\"\n\n     AC_MSG_CHECKING([for sem_t, sem_init() and sem_destroy()])\n     AX_RUN_OR_LINK_IFELSE([AC_LANG_PROGRAM([\n#include <semaphore.h>\n],\n[sem_t semaphore;\nsem_init(&semaphore, 0, 4);\nsem_destroy(&semaphore);\n/* Do not care about actual return value in this test,\n * normally check for non-zero meaning to look in errno */\n]\n        )],\n        [AC_DEFINE([HAVE_SEMAPHORE_UNNAMED], [1],\n            [Define to 1 if you have <sys/semaphore.h> with usable sem_t, sem_init() and sem_destroy() for unnamed semaphores.])\n         AC_MSG_RESULT([ok])\n        ],\n        [AC_MSG_RESULT([no])]\n     )\n\n     AC_MSG_CHECKING([for sem_t, sem_open() and sem_close()])\n     AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#include <semaphore.h>\n#ifdef HAVE_FCNTL_H\n# include <fcntl.h>           /* For O_* constants */\n#endif\n#ifdef SYS_STAT_H\n# include <sys/stat.h>        /* For mode constants */\n#endif\n],\n[sem_t *semaphore = sem_open(\"/s\", O_CREAT, 0644, 4);\nif (semaphore != SEM_FAILED)\n    sem_close(semaphore);\n/* Do not care about actual return value in this test,\n * normally check for non-zero meaning to look in errno */\n]\n        )],\n        [AC_DEFINE([HAVE_SEMAPHORE_NAMED], [1],\n            [Define to 1 if you have <sys/semaphore.h> with usable sem_t, sem_open() and sem_close() for named semaphores.])\n         AC_MSG_RESULT([ok])\n        ],\n        [AC_MSG_RESULT([no])]\n     )\n\n     LIBS=\"${myLIBS}\"\n     AC_LANG_POP([C])\n    ]\n)\nAM_CONDITIONAL(HAVE_SEMAPHORE_LIBS, test -n \"${SEMLIBS}\")\n\nAC_CHECK_FUNCS(cfsetispeed tcsendbreak)\nAC_CHECK_FUNCS(seteuid setsid getpassphrase)\nAC_CHECK_FUNCS(on_exit setlogmask)\nAC_CHECK_DECLS(LOG_UPTO, [], [], [#include <syslog.h>])\n\ndnl These common routines are not available in strict C standard library\ndnl compilation modes (not part of ANSI or later standard), only in GNU,\ndnl POSIX or other extension modes. Note that on modern systems they are\ndnl available, just hidden in headers - so AC_CHECK_FUNCS() finds them\ndnl by adding a declaration, while the \"real\" codebase can't use them.\nAC_MSG_NOTICE(\n[-----------------------------------------------------------------------\nThe next few tests look for required C library routines; if something is\nnot found, you may need to enable a different C standard or extension macro\nversion. You may also have to configure without extreme warning levels\nsince autotools tests fail those on their own and assume system lacks\nstuff (although note we try to not involve standard -W* flags here).\n-----------------------------------------------------------------------])\ndnl# AC_CHECK_FUNCS(strcasecmp strncasecmp,\ndnl# \t[], [AC_MSG_WARN([Required C library routine not found; try adding __EXTENSIONS__])])\ndnl These appear with CFLAGS=\"-std=c99 -D_POSIX_C_SOURCE=200112L\":\ndnl# Methods below currently do not cause build errors for C99+ modes so are\ndnl# not tested as thoroughly as those further below:\nAC_CHECK_FUNCS(strtof strtok_r fileno sigemptyset sigaction,\n\t[], [AC_MSG_WARN([Required C library routine not found by linker; try adding -D_POSIX_C_SOURCE=200112L])])\n\ndnl For these we have a fallback implementation via the other,\ndnl if at least one is available, so initial check is quiet.\ndnl This typically pops up in POSIX vs. Windows builds:\ndnl Reminder: the former checks for declarations in headers,\ndnl the latter checks if known libraries suffice for linker.\ndnl Might need AC_CHECK_LIBS as well to populate the list with\ndnl known variants?\nAC_CHECK_DECLS([localtime_r, localtime_s, gmtime_r, gmtime_s, timegm, _mkgmtime], [], [], [$CODE_TIMEINCL])\nAC_CHECK_FUNCS(localtime_r localtime_s gmtime_r gmtime_s timegm _mkgmtime, [], [])\n\nAC_MSG_CHECKING([for at least one gmtime implementation])\nAS_IF([test x\"${ac_cv_func_gmtime_s}-${ac_cv_func_gmtime_r}\" = \"xno-no\" && test x\"${ac_cv_have_decl_gmtime_s}-${ac_cv_have_decl_gmtime_r}\" = \"xno-no\"], [\n\tAC_MSG_RESULT([no])\n\tAC_MSG_WARN([Required C library routine gmtime_s nor gmtime_r was not found by linker nor in headers; try adding -D_POSIX_C_SOURCE=200112L and/or -D_POSIX_THREAD_SAFE_FUNCTIONS=200112L])\n\t],[\n\tAC_MSG_RESULT([yes])\n\t])\n\nAC_MSG_CHECKING([for at least one localtime implementation])\nAS_IF([test x\"${ac_cv_func_localtime_s}-${ac_cv_func_localtime_r}\" = \"xno-no\" && test x\"${ac_cv_have_decl_localtime_s}-${ac_cv_have_decl_localtime_r}\" = \"xno-no\"], [\n\tAC_MSG_RESULT([no])\n\tAC_MSG_WARN([Required C library routine localtime_s nor localtime_r was not found by linker nor in headers; try adding -D_POSIX_C_SOURCE=200112L and/or -D_POSIX_THREAD_SAFE_FUNCTIONS=200112L])\n\t],[\n\tAC_MSG_RESULT([yes])\n\t])\n\nAC_MSG_CHECKING([for at least one timegm implementation])\nAS_IF([test x\"${ac_cv_func_timegm}-${ac_cv_func__mkgmtime}\" = \"xno-no\" && test x\"${ac_cv_have_decl_timegm}-${ac_cv_have_decl__mkgmtime}\" = \"xno-no\"], [\n\tAC_MSG_RESULT([no])\n\tAC_MSG_WARN([Required C library routine timegm nor _mkgmtime was not found by linker nor in headers])\n\tAC_DEFINE_UNQUOTED([WANT_TIMEGM_FALLBACK], [1], [Defined if we want to use timegm_fallback()])\n\tAM_CONDITIONAL([WANT_TIMEGM_FALLBACK], [true])\n\t],[\n\tAC_MSG_RESULT([yes])\n\tAM_CONDITIONAL([WANT_TIMEGM_FALLBACK], [false])\n\t])\n\nAC_LANG_PUSH([C])\n\nAC_CHECK_HEADER([string.h],\n    [AC_DEFINE([HAVE_STRING_H], [1],\n        [Define to 1 if you have <string.h>.])])\n\nAC_CHECK_HEADER([strings.h],\n    [AC_DEFINE([HAVE_STRINGS_H], [1],\n        [Define to 1 if you have <strings.h>.])])\n\nCODE_STRINGINCL='#ifdef HAVE_STRING_H\n#include <string.h>\n#endif\n#ifdef HAVE_STRINGS_H\n#include <strings.h>\n#endif'\n\nAC_CACHE_CHECK([for strcasecmp(s1,s2)],\n    [ac_cv_func_strcasecmp],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [if (strcasecmp(\"STR1\", \"str1\") != 0) return 1])],\n        [ac_cv_func_strcasecmp=yes], [ac_cv_func_strcasecmp=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strcasecmp}\" = xyes],\n    [AC_DEFINE([HAVE_STRCASECMP], 1, [defined if standard library has, and C standard allows, the strcasecmp(s1,s2) method])],\n    [AC_MSG_WARN([Required C library routine strcasecmp not found; try adding __EXTENSIONS__])]\n    )\n\nAC_CACHE_CHECK([for strncasecmp(s1,s2,n)],\n    [ac_cv_func_strncasecmp],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [if (strncasecmp(\"STR1\", \"strX\", 2) != 0) return 1])],\n        [ac_cv_func_strncasecmp=yes], [ac_cv_func_strncasecmp=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strncasecmp}\" = xyes],\n    [AC_DEFINE([HAVE_STRNCASECMP], 1, [defined if standard library has, and C standard allows, the strncasecmp(s1,s2,n) method])],\n    [AC_MSG_WARN([Required C library routine strncasecmp not found; try adding __EXTENSIONS__])]\n    )\n\ndnl Note: this changes the original string in argument!\ndnl Do not pass it constants (strdup them if needed)!\nAC_CACHE_CHECK([for strlwr(s)],\n    [ac_cv_func_strlwr],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [char s@<:@64@:>@ = {\"Some STR1 text\"} ; if (strlwr(s) == NULL) return 1])],\n        [ac_cv_func_strlwr=yes], [ac_cv_func_strlwr=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strlwr}\" = xyes],\n    [AC_DEFINE([HAVE_STRLWR], 1, [defined if standard library has, and C standard allows, the strlwr(s1,s2) method])],\n    [AC_MSG_WARN([Optional C library routine strlwr not found])]\n    )\n\nAC_CACHE_CHECK([for strsep(s1,s2)],\n    [ac_cv_func_strsep],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [char arr@<:@64@:>@ = {\"Some,tuple,text\"} ; char *s = arr; if (strsep(&s, \",\") == NULL) return 1])],\n        [ac_cv_func_strsep=yes], [ac_cv_func_strsep=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strsep}\" = xyes],\n    [AC_DEFINE([HAVE_STRSEP], 1, [defined if standard library has, and C standard allows, the strsep(s1,s2) method])],\n    [AC_MSG_WARN([Optional C library routine strsep not found])]\n    )\nAM_CONDITIONAL([HAVE_STRSEP], [test x\"${ac_cv_func_strsep}\" = \"xyes\"])\n\nAC_CACHE_CHECK([for strstr(s1,s2)],\n    [ac_cv_func_strstr],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [if (strstr(\"Some str1 text\", \"str1\") == NULL) return 1])],\n        [ac_cv_func_strstr=yes], [ac_cv_func_strstr=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strstr}\" = xyes],\n    [AC_DEFINE([HAVE_STRSTR], 1, [defined if standard library has, and C standard allows, the strstr(s1,s2) method])],\n    [AC_MSG_ERROR([Required C library routine strstr not found])]\n    )\n\nAC_CACHE_CHECK([for strcasestr(s1,s2)],\n    [ac_cv_func_strcasestr],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL],\n            [if (strcasestr(\"Some STR1 text\", \"str1\") == NULL) return 1])],\n        [ac_cv_func_strcasestr=yes], [ac_cv_func_strcasestr=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strcasestr}\" = xyes],\n    [AC_DEFINE([HAVE_STRCASESTR], 1, [defined if standard library has, and C standard allows, the strcasestr(s1,s2) method])],\n    [AS_IF([test x\"${ac_cv_func_strlwr}\" = xyes && test x\"${ac_cv_func_strstr}\" = xyes],\n        [AC_MSG_WARN([Optional C library routine strcasestr not found; a simple wrapper will be built in])]\n        [AC_MSG_WARN([Required C library routine strcasestr not found; try adding _GNU_SOURCE])]\n    )])\n\nAC_CACHE_CHECK([for strptime(s1,s2,tm)],\n    [ac_cv_func_strptime],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL\n$CODE_TIMEINCL\n],\n            [struct tm tm;\nchar *date = \"12/30/1999\";\nchar *p = strptime(date, \"%m/%d/%Y\", &tm);\nif (p == NULL || *p != '\\0') return 1])],\n        [ac_cv_func_strptime=yes], [ac_cv_func_strptime=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strptime}\" = xyes],\n    [AC_DEFINE([HAVE_STRPTIME], 1, [defined if standard library has, and C standard allows, the strptime(s1,s2,tm) method])],\n    [AC_MSG_WARN([Optional C library routine strptime not found; try adding _GNU_SOURCE; a fallback implementation will be built in])]\n    )\ndnl Note: per Linux headers, this may need __USE_XOPEN (features.h)\ndnl which is enabled by _XOPEN_SOURCE via _GNU_SOURCE on the platform.\nAM_CONDITIONAL([HAVE_STRPTIME], [test x\"${ac_cv_func_strptime}\" = \"xyes\"])\n\nAC_CACHE_CHECK([for clock_gettime(CLOCK_MONOTONIC,ts)],\n    [ac_cv_func_clock_gettime],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL\n$CODE_TIMEINCL\n],\n            [struct timespec monoclock_ts;\nint got_monoclock = clock_gettime(CLOCK_MONOTONIC, &monoclock_ts);\nif (monoclock_ts.tv_sec < 0 || monoclock_ts.tv_nsec < 0) return 1])],\n        [ac_cv_func_clock_gettime=yes], [ac_cv_func_clock_gettime=no]\n    )])\nAS_IF([test x\"${ac_cv_func_clock_gettime}\" = xyes],\n    [AC_DEFINE([HAVE_CLOCK_GETTIME], 1, [defined if standard library has, and C standard allows, the clock_gettime(clkid,ts) method])\n     AC_DEFINE([HAVE_CLOCK_MONOTONIC], 1, [defined if standard library has, and C standard allows, the CLOCK_MONOTONIC macro or token])],\n    [AC_MSG_WARN([Optional C library routine clock_gettime not found; will not be used in notifications])]\n    )\ndnl Currently these two are the same for us; note also fallback support for\ndnl older autoconf in SYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY_RELOAD way below:\nAM_CONDITIONAL([HAVE_CLOCK_GETTIME], [test x\"${ac_cv_func_clock_gettime}\" = \"xyes\"])\nAM_CONDITIONAL([HAVE_CLOCK_MONOTONIC], [test x\"${ac_cv_func_clock_gettime}\" = \"xyes\"])\n\nAC_CACHE_CHECK([for strnlen(s1,s2,tm)],\n    [ac_cv_func_strnlen],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL\n#include <stdlib.h>\n],\n            [size_t len = strnlen(\"LongString\", 5);\nif (len != 5) return 5;\n\nlen = strnlen(\"LongString\", 50);\nif (len != 10) return 10\n])],\n        [ac_cv_func_strnlen=yes], [ac_cv_func_strnlen=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strnlen}\" = xyes],\n    [AC_DEFINE([HAVE_STRNLEN], 1, [defined if standard library has, and C standard allows, the strnlen(s1,s2) method])],\n    [AC_MSG_WARN([Optional C library routine strnlen not found; a fallback implementation will be built in])]\n    )\nAM_CONDITIONAL([HAVE_STRNLEN], [test x\"${ac_cv_func_strnlen}\" = \"xyes\"])\n\nAC_CACHE_CHECK([for strdup(s)],\n    [ac_cv_func_strdup],\n    [AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([$CODE_STRINGINCL\n#include <stdlib.h>\n],\n            [[int res = 0;\nchar *t = \"Test\";\nchar *s = strdup(t);\nif (!s || !(s[0]=='T'&&s[1]=='e'&&s[2]=='s'&&s[3]=='t'&&s[4]=='\\0') || s == t) res = 1;\nif (s) free (s);\nif (res != 0) return res\n/* autoconf adds \";return 0;\" */\n]])],\n        [ac_cv_func_strdup=yes], [ac_cv_func_strdup=no]\n    )])\nAS_IF([test x\"${ac_cv_func_strdup}\" = xyes],\n    [AC_DEFINE([HAVE_STRDUP], 1, [defined if standard library has, and C standard allows, the strdup(s) method])],\n    [AC_MSG_WARN([Required C library routine strdup not found; try adding -D_POSIX_C_SOURCE=200112L])]\n    )\n\nAC_CHECK_HEADER([sys/select.h],\n    [AC_DEFINE([HAVE_SYS_SELECT_H], [1],\n        [Define to 1 if you have <sys/select.h>.])])\n\nAC_CHECK_HEADER([unistd.h],\n    [AC_DEFINE([HAVE_UNISTD_H], [1],\n        [Define to 1 if you have <unistd.h>.])])\n\nAC_CHECK_FUNCS(readlink)\n\nAC_CACHE_CHECK([for suseconds_t],\n    [ac_cv_type_suseconds_t],\n    [AC_COMPILE_IFELSE(\n        [AC_LANG_PROGRAM([[#include <sys/types.h>\n#if HAVE_SYS_SELECT_H\n# include <sys/select.h>\n#endif\n        ]],\n            [[suseconds_t us = 1000000;\n              signed long int l = 1000000;\n              if (l != (signed long int)us) return 1;\n\n              l = -1; us = -1;\n              if (l != (signed long int)us) return 1\n/* autoconf adds \";return 0;\" */\n/* we hope the code above fails if type is not defined or range is not sufficient */\n]])],\n        [ac_cv_type_suseconds_t=yes], [ac_cv_type_suseconds_t=no]\n    )])\nAS_IF([test x\"${ac_cv_type_suseconds_t}\" = xyes],\n    [AC_DEFINE([HAVE_SUSECONDS_T], 1, [defined if standard library has, and C standard allows, the suseconds_t type])],\n    [AC_MSG_WARN([Required C library type suseconds_t not found; try adding -D_POSIX_C_SOURCE=200112L])]\n    )\n\nAC_CACHE_CHECK([for useconds_t],\n    [ac_cv_type_useconds_t],\n    [AC_COMPILE_IFELSE(\n        [AC_LANG_PROGRAM([[#include <unistd.h>\n        ]],\n            [[useconds_t us = 1000000;\n              unsigned long int l = 1000000;\n              if (l != (unsigned long int)us) return 1\n/* autoconf adds \";return 0;\" */\n/* we hope the code above fails if type is not defined or range is not sufficient */\n]])],\n        [ac_cv_type_useconds_t=yes], [ac_cv_type_useconds_t=no]\n    )])\nAS_IF([test x\"${ac_cv_type_useconds_t}\" = xyes],\n    [AC_DEFINE([HAVE_USECONDS_T], 1, [defined if standard library has, and C standard allows, the useconds_t type])],\n    [AC_MSG_WARN([Required C library type useconds_t not found; try adding -D_POSIX_C_SOURCE=200112L])]\n    )\n\nAC_CACHE_CHECK([for usleep(us)],\n    [ac_cv_func_usleep],\n    [AC_COMPILE_IFELSE(\n        [AC_LANG_PROGRAM([[#include <unistd.h>\n        ]],\n            [[useconds_t us = 1000;\nif (usleep(us) != 0) return 1 /* per doc, no errors are returned actually */\n/* autoconf adds \";return 0;\" */\n]])],\n        [ac_cv_func_usleep=yes], [ac_cv_func_usleep=no]\n    )])\nAS_IF([test x\"${ac_cv_func_usleep}\" = xyes],\n    [AC_DEFINE([HAVE_USLEEP], 1, [defined if standard library has, and C standard allows, the usleep(us) method])],\n    [AC_MSG_WARN([Required C library routine usleep not found; try adding -D_POSIX_C_SOURCE=200112L])]\n    )\n\ndnl OpenBSD (at least) methods to query process info, per\ndnl https://github.com/openbsd/src/blob/master/bin/ps/ps.c\ndnl https://kaashif.co.uk/2015/06/18/how-to-get-a-list-of-processes-on-openbsd-in-c/\nBSDKVMPROCLIBS=\"\"\nmyLIBS=\"$LIBS\"\nLIBS=\"$LIBS -lkvm\"\nAC_CACHE_CHECK([for BSD KVM process info libs],\n    [ac_cv_lib_bsd_kvm_proc],\n    [AC_LINK_IFELSE(\n        [AC_LANG_PROGRAM([[\n#include <stdio.h>\n#include <kvm.h>\n#include <limits.h>\n#include <sys/param.h>\n#include <sys/sysctl.h>\n        ]],\n            [[\n    char errbuf[_POSIX2_LINE_MAX];\n    kvm_t *kernel = kvm_openfiles(NULL, NULL, NULL, KVM_NO_FILES, errbuf);\n    int nentries = 0;\n    struct kinfo_proc *kinfo = kvm_getprocs(kernel, KERN_PROC_ALL, 0, sizeof(struct kinfo_proc), &nentries);\n    int i;\n    for (i = 0; i < nentries; ++i) {\n        printf(\"%s\\n\", kinfo[i].p_comm);\n    }\n/* autoconf adds \";return 0;\" */\n/* we hope the code above fails if type is not defined or range is not sufficient */\n]])],\n        [ac_cv_lib_bsd_kvm_proc=yes\n        BSDKVMPROCLIBS=\"-lkvm\"\n        ], [ac_cv_lib_bsd_kvm_proc=no]\n    )])\nLIBS=\"$myLIBS\"\n\nAS_IF([test x\"${ac_cv_lib_bsd_kvm_proc}\" = xyes],\n    [AC_DEFINE([HAVE_LIB_BSD_KVM_PROC], 1, [defined if we have libs, includes and methods for BSD KVM process info])]\n    )\n\ndnl https://github.com/illumos/illumos-gate/blob/master/usr/src/uts/common/sys/procfs.h#L318\ndnl https://github.com/illumos/illumos-gate/blob/master/usr/src/cmd/ps/ps.c\nAC_CACHE_CHECK([for Solaris/illumos process info libs],\n    [ac_cv_lib_illumos_proc],\n    [AC_LINK_IFELSE(\n        [AC_LANG_PROGRAM([[\n#include <stdio.h>\n#include <procfs.h>\n        ]],\n            [[\n    psinfo_t info;\n    printf(\"%s\", info.pr_fname)\n/* autoconf adds \";return 0;\" */\n/* we hope the code above fails if type is not defined or range is not sufficient */\n]])],\n        [ac_cv_lib_illumos_proc=yes\n        ], [ac_cv_lib_illumos_proc=no]\n    )])\nLIBS=\"$myLIBS\"\n\nAS_IF([test x\"${ac_cv_lib_illumos_proc}\" = xyes],\n    [AC_DEFINE([HAVE_LIB_ILLUMOS_PROC], 1, [defined if we have libs, includes and methods for Solaris/illumos process info])]\n    )\n\nAC_LANG_POP([C])\n\ndnl These routines' arg types differ in strict C standard mode\ndnl from what they use in the modes expected by NUT codebase:\ndnl   bind() :     /usr/include/x86_64-linux-gnu/sys/socket.h:123:12: note: expected '__CONST_SOCKADDR_ARG {aka union <anonymous>}' but argument is of type 'struct sockaddr *'\ndnl   accept() :   /usr/include/x86_64-linux-gnu/sys/socket.h:243:12: note: expected '__SOCKADDR_ARG {aka union <anonymous>}' but argument is of type 'struct sockaddr *'\ndnl   connect() :  /usr/include/x86_64-linux-gnu/sys/socket.h:137:12: note: expected '__CONST_SOCKADDR_ARG {aka union <anonymous>}' but argument is of type 'const struct sockaddr *'\ndnl   sendto() :   /usr/include/x86_64-linux-gnu/sys/socket.h:163:16: note: expected '__CONST_SOCKADDR_ARG {aka union <anonymous>}' but argument is of type 'struct sockaddr *'\ndnl   recvfrom() : /usr/include/x86_64-linux-gnu/bits/socket2.h:64:1: note: expected '__SOCKADDR_ARG {aka union <anonymous>}' but argument is of type 'struct sockaddr *'\n\nAC_MSG_CHECKING([whether ln -sr works])\ndnl We need to relative-symlink some files. Or hardlink. Or copy...\nLN_S_R=\"cp -pR\"\nif test \"$as_ln_s\" = \"ln -s\" ; then\n    _abs_srcdir=\"`cd \"${srcdir}\" && pwd`\" || _abs_srcdir=\"\"\n    _abs_builddir=\"`pwd`\"\n    dnl AC_MSG_NOTICE([srcdir='${srcdir}' _abs_srcdir='${_abs_srcdir}' _abs_builddir='${_abs_builddir}'])\n    if test x\"${_abs_srcdir}\" = x\"${_abs_builddir}\" ; then\n        LN_S_R=\"ln\"\n    else\n        dnl NOTE: Here we check equality of the file systems by the\n        dnl devices they are mounted from (first column in df output):\n        _fs_srcdir=\"`df \"${_abs_srcdir}\" | tail -1 | awk '{print $1}'`\" || fs_srcdir=\"XXXs\"\n        _fs_builddir=\"`df \"${_abs_builddir}\" | tail -1 | awk '{print $1}'`\" || fs_builddir=\"XXXb\"\n        dnl AC_MSG_NOTICE([_fs_srcdir='${_fs_srcdir}' _fs_builddir='${_fs_builddir}'])\n        if test x\"${_fs_srcdir}\" = x\"${_fs_builddir}\" ; then\n            LN_S_R=\"ln\"\n        else\n            dnl Source and build areas are in different filesystems,\n            dnl can not hardlink - keep copying approach in place\n            AC_MSG_NOTICE([Source and build areas are in different filesystems, or we could not detect this for sure - avoiding hardlinks])\n        fi\n        unset _fs_srcdir _fs_builddir\n    fi\n    unset _abs_srcdir _abs_builddir\n\n    dnl Explore GNU ln (or compatible) with relative symlink support\n    DIR1=\"$(mktemp -d \"dir1.XXXXXXX\")\" && \\\n    DIR2=\"$(mktemp -d \"dir2.XXXXXXX\")\" && \\\n    touch \"${DIR1}/a\" && \\\n    $as_ln_s -r \"${DIR1}/a\" \"${DIR2}/b\" && \\\n    ls -la \"${DIR2}/b\" | grep '\\.\\./' > /dev/null && \\\n    LN_S_R=\"$as_ln_s -r\"\n\n    rm -rf \"${DIR1}\" \"${DIR2}\"\nfi\nAC_SUBST([LN_S_R], [${LN_S_R}])\nif test \"$LN_S_R\" = \"ln -s -r\" ; then\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no, using $LN_S_R])\nfi\n\ndnl the following may add stuff to LIBOBJS (is this still needed?)\nAC_CHECK_FUNCS(vsnprintf snprintf, [], [\n\tAC_LIBOBJ(snprintf)\n\tAC_TYPE_LONG_DOUBLE\n\tAC_TYPE_LONG_LONG_INT\n])\n\nAC_REPLACE_FUNCS(setenv strerror atexit)\n\ncase ${target_os} in\n   solaris2* )\n      dnl On Solaris, this allows errno to use thread local storage\n      CFLAGS=\"${CFLAGS} -D_REENTRANT\"\n      ;;\n   aix* )\n      dnl On AIX, this allows errno to use thread local storage\n      CFLAGS=\"${CFLAGS} -D_REENTRANT\"\n      ;;\n   hpux11* )\n      dnl It seems like the thread safe string functions will not be included\n      dnl on 64 bit HP-UX unless we define _REENTRANT\n      CFLAGS=\"${CFLAGS} -D_REENTRANT\"\n      ;;\nesac\n\ndnl optind handling:\ndnl need to check if unistd.h is enough, else try getopt.h, else need decls\nAC_CHECK_DECLS(optind, [], [\n\tAC_CHECK_HEADERS(getopt.h, [\n\t\tAC_DEFINE(NEED_GETOPT_H, 1, [Define if getopt.h is needed])\n\t], [\n\t\tAC_DEFINE(NEED_GETOPT_DECLS, 1, [Define to use explicit getopt declarations])\n\t], [AC_INCLUDES_DEFAULT])\n], [AC_INCLUDES_DEFAULT])\n\ndnl do a 2nd check to ensure inclusion of getopt.h, in case optind is known\nAC_CHECK_HEADERS(getopt.h, [\n\tAC_DEFINE(NEED_GETOPT_H, 1, [Define if getopt.h is needed])\n], [\n\tAC_DEFINE(NEED_GETOPT_DECLS, 1, [Define to use explicit getopt declarations])\n], [AC_INCLUDES_DEFAULT])\n\ndnl also check for getopt_long\nAC_CHECK_FUNCS(getopt_long)\n\ndnl FreeBSD serial locking compatibility - look for uu_lock in libutil.h\nAC_CHECK_DECLS(uu_lock, [\n\tAC_DEFINE(HAVE_UU_LOCK, 1, [Use uu_lock for locking (FreeBSD)])\n\tSERLIBS=\"-lutil\"\n\tdnl put in some better defaults for FreeBSD\n\tRUN_AS_USER=\"uucp\"\n], [\n\tSERLIBS=\"\"\n], [\n#include <sys/types.h>\n#include <libutil.h>\n])\n\nAC_CHECK_DECLS(__func__, [], [\n\tAC_CHECK_DECLS(__FUNCTION__, [\n\t\tAC_DEFINE(__func__, __FUNCTION__, [Replace missing __func__ declaration])\n\t], [\n\t\tAC_DEFINE(__func__, __LINE__, [Replace missing  __func__ declaration])\n\t], [AC_INCLUDES_DEFAULT])\n], [AC_INCLUDES_DEFAULT])\n\ndnl Solaris compatibility - check for -lnsl and -lsocket\nAC_SEARCH_LIBS(gethostbyname, nsl)\nAC_SEARCH_LIBS(connect, socket)\n\nAC_CHECK_HEADERS(sys/modem.h stdarg.h varargs.h, [], [], [AC_INCLUDES_DEFAULT])\n\n\ndnl pthread related checks\ndnl Note: pthread_tryjoin_np() should be available since glibc 2.3.3, according\ndnl to https://man7.org/linux/man-pages/man3/pthread_tryjoin_np.3.html\nAC_SEARCH_LIBS([pthread_create], [pthread],\n       [AC_DEFINE(HAVE_PTHREAD, 1, [Define to enable pthread support code])\n        AC_SEARCH_LIBS([pthread_tryjoin_np], [pthread],\n               [AC_DEFINE(HAVE_PTHREAD_TRYJOIN, 1, [Define to enable pthread_tryjoin support code])],\n               [])\n       ],\n       [])\n\ndnl ----------------------------------------------------------------------\ndnl Check for types and define possible replacements\nNUT_TYPE_SOCKLEN_T\nNUT_CHECK_SOCKETLIB\nNUT_FUNC_GETNAMEINFO_ARGTYPES\n\nAC_CACHE_CHECK([for inet_ntop() with IPv4 and IPv6 support],\n    [ac_cv_func_inet_ntop],\n    [AC_LANG_PUSH([C])\n    dnl e.g. add \"-lws2_32\" for mingw builds\n    dnl the NETLIBS are set by NUT_CHECK_SOCKETLIB above\n    SAVED_LIBS=\"$LIBS\"\n    LIBS=\"$LIBS $NETLIBS\"\n    AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([[\n#if HAVE_WINDOWS_H\n# undef inline\n# ifndef WIN32_LEAN_AND_MEAN\n#  define WIN32_LEAN_AND_MEAN\n# endif\n# include <windows.h>\n# if HAVE_WINSOCK2_H\n#  include <winsock2.h>\n# endif\n# if HAVE_WS2TCPIP_H\n#  include <ws2tcpip.h>\n# endif\n#else\n# include <arpa/inet.h>\n#endif\n#include <stdio.h>\n]],\n            [[/* const char* inet_ntop(int af, const void* src, char* dst, size_t cnt); */\nchar buf[128];\nprintf(\"%s\", inet_ntop(AF_INET, \"1.2.3.4\", buf, 10));\nprintf(\"%s\", inet_ntop(AF_INET6, \"::1\", buf, 10))\n/* autoconf adds \";return 0;\" */\n]])],\n        [ac_cv_func_inet_ntop=yes], [ac_cv_func_inet_ntop=no]\n    )\n    AC_LANG_POP([C])\n    LIBS=\"$SAVED_LIBS\"\n])\nAS_IF([test x\"${ac_cv_func_inet_ntop}\" = xyes],\n    [AC_DEFINE([HAVE_INET_NTOP], 1, [defined if system has the inet_ntop() method])],\n    [AC_MSG_WARN([Required C library routine inet_ntop() not found])\n     AS_CASE([${target_os}],\n         [*mingw*], [AC_MSG_WARN([Windows antivirus might block this test])]\n         )\n    ]\n    )\n\nAC_CACHE_CHECK([for inet_pton() with IPv4 and IPv6 support],\n    [ac_cv_func_inet_pton],\n    [AC_LANG_PUSH([C])\n    dnl e.g. add \"-lws2_32\" for mingw builds\n    dnl the NETLIBS are set by NUT_CHECK_SOCKETLIB above\n    SAVED_LIBS=\"$LIBS\"\n    LIBS=\"$LIBS $NETLIBS\"\n    AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([[\n#if HAVE_WINDOWS_H\n# undef inline\n# ifndef WIN32_LEAN_AND_MEAN\n#  define WIN32_LEAN_AND_MEAN\n# endif\n# include <windows.h>\n# if HAVE_WINSOCK2_H\n#  include <winsock2.h>\n# endif\n# if HAVE_WS2TCPIP_H\n#  include <ws2tcpip.h>\n# endif\n#else\n# include <arpa/inet.h>\n#endif\n#include <stdio.h>\n]],\n            [[/* int inet_pton(int af, const char *src, char *dst); */\nstruct in_addr  ipv4;\nstruct in6_addr ipv6;\nprintf(\"%i \", inet_pton(AF_INET, \"1.2.3.4\", &ipv4));\nprintf(\"%i \", inet_pton(AF_INET6, \"::1\", &ipv6))\n/* autoconf adds \";return 0;\" */\n]])],\n        [ac_cv_func_inet_pton=yes], [ac_cv_func_inet_pton=no]\n    )\n    AC_LANG_POP([C])\n    LIBS=\"$SAVED_LIBS\"\n])\nAS_IF([test x\"${ac_cv_func_inet_pton}\" = xyes],\n    [AC_DEFINE([HAVE_INET_PTON], 1, [defined if system has the inet_pton() method])],\n    [AC_MSG_WARN([Required C library routine inet_pton() not found])\n     AS_CASE([${target_os}],\n         [*mingw*], [AC_MSG_WARN([Windows antivirus might block this test])]\n         )\n    ]\n    )\n\nAC_CACHE_CHECK([for struct pollfd],\n    [ac_cv_struct_pollfd],\n    [AC_LANG_PUSH([C])\n    dnl e.g. add \"-lws2_32\" for mingw builds\n    dnl the NETLIBS are set by NUT_CHECK_SOCKETLIB above\n    SAVED_LIBS=\"$LIBS\"\n    LIBS=\"$LIBS $NETLIBS\"\n    AX_RUN_OR_LINK_IFELSE(\n        [AC_LANG_PROGRAM([[\n#if HAVE_WINDOWS_H\n# undef inline\n# ifndef WIN32_LEAN_AND_MEAN\n#  define WIN32_LEAN_AND_MEAN\n# endif\n# include <windows.h>\n# if HAVE_WINSOCK2_H\n#  include <winsock2.h>\n# endif\n# if HAVE_WS2TCPIP_H\n#  include <ws2tcpip.h>\n# endif\n#else\n# include <poll.h>\n#endif\n#include <stdio.h>\n]],\n            [[\nstruct pollfd  pfd;\npfd.fd = 0;\n/* autoconf adds \";return 0;\" */\n]])],\n        [ac_cv_struct_pollfd=yes], [ac_cv_struct_pollfd=no]\n    )\n    AC_LANG_POP([C])\n    LIBS=\"$SAVED_LIBS\"\n])\nAS_IF([test x\"${ac_cv_struct_pollfd}\" = xyes],\n    [AC_DEFINE([HAVE_STRUCT_POLLFD], 1, [defined if system has the struct pollfd type])],\n    [AC_MSG_WARN([Required C library type struct pollfd not found])\n     AS_CASE([${target_os}],\n         [*mingw*], [AC_MSG_WARN([Windows antivirus might block this test])]\n         )\n    ]\n    )\n\nNETLIBS_GETADDRS=\"\"\ndnl For `nut-scanner -m auto` modes, see also:\ndnl https://stackoverflow.com/a/41151132/4715872\ndnl https://learn.microsoft.com/en-us/windows/win32/api/iphlpapi/nf-iphlpapi-getadaptersaddresses (since ~Windows Vista)\ndnl https://learn.microsoft.com/en-us/windows/win32/api/iphlpapi/nf-iphlpapi-getadaptersinfo (before Windows XP; not recommended later)\ndnl Must check in global context, to have it not-defined where appropriate too\nNUT_CHECK_HEADER_IPHLPAPI\nAC_CHECK_HEADERS_ONCE([ifaddrs.h netinet/in.h net/if.h])\nAC_CHECK_FUNCS([getifaddrs], [], [\n    AS_CASE([${target_os}],\n        [*mingw*], [\n            dnl Check for GetAdaptersAddresses / GetAdaptersInfo\n            AS_IF([test x\"${nut_cv_header_iphlpapi_h}\" = xyes], [\n\n                myIPHLPAPI_TEST_HEADERS='\n#if HAVE_WINDOWS_H\n# undef inline\n# ifndef WIN32_LEAN_AND_MEAN\n#  define WIN32_LEAN_AND_MEAN\n# endif\n# include <windows.h>\n# if HAVE_WINSOCK2_H\n#  include <winsock2.h>\n# endif\n# if HAVE_IPHLPAPI_H\n#  include <iphlpapi.h>\n# endif\n#endif\n#include <stdio.h>\n'\n\n                myIPHLPAPI_TEST_GAA='\n/* ULONG GetAdaptersAddresses(ULONG af, ULONG flags, void* rsvd, PIP_ADAPTER_ADDRESSES addrs, PULONG sizeptr); */\nIP_ADAPTER_ADDRESSES buf@<:@8@:>@;\nULONG bufsz = sizeof(buf);\nprintf(\"%ld \", GetAdaptersAddresses(AF_UNSPEC, GAA_FLAG_SKIP_MULTICAST, NULL, buf, &bufsz));\nprintf(\"%ld \", GetAdaptersAddresses(AF_INET, GAA_FLAG_SKIP_DNS_SERVER, NULL, buf, &bufsz));\nprintf(\"%ld \", GetAdaptersAddresses(AF_INET6, GAA_FLAG_SKIP_ANYCAST, NULL, buf, &bufsz))\n/* autoconf adds \";return 0;\" */\n'\n\n                AC_CACHE_CHECK([for GetAdaptersAddresses() with IPv4 and IPv6 support],\n                    [ac_cv_func_GetAdaptersAddresses],\n                    [AC_LANG_PUSH([C])\n                    dnl e.g. add \"-lws2_32\" for mingw builds, maybe \"-liphlpapi\"\n                    dnl the NETLIBS are set by NUT_CHECK_SOCKETLIB above\n                    SAVED_LIBS=\"$LIBS\"\n                    LIBS=\"$LIBS $NETLIBS\"\n                    AX_RUN_OR_LINK_IFELSE(\n                        [AC_LANG_PROGRAM(\n                            [${myIPHLPAPI_TEST_HEADERS}],\n                            [${myIPHLPAPI_TEST_GAA}])],\n                        [ac_cv_func_GetAdaptersAddresses=yes\n                        ], [\n                            NETLIBS_GETADDRS=\"-liphlpapi\"\n                            LIBS=\"$LIBS $NETLIBS $NETLIBS_GETADDRS\"\n                            AX_RUN_OR_LINK_IFELSE(\n                                [AC_LANG_PROGRAM(\n                                    [${myIPHLPAPI_TEST_HEADERS}],\n                                    [${myIPHLPAPI_TEST_GAA}])],\n                                [\n                                    ac_cv_func_GetAdaptersAddresses=yes\n                                ], [\n                                    ac_cv_func_GetAdaptersAddresses=no\n                                    NETLIBS_GETADDRS=\"\"\n                                ]\n                            )\n                        ]\n                    )\n                    AC_LANG_POP([C])\n                    LIBS=\"$SAVED_LIBS\"\n                ])\n                AS_IF([test x\"${ac_cv_func_GetAdaptersAddresses}\" = xyes],\n                    [AC_DEFINE([HAVE_GETADAPTERSADDRESSES], 1, [defined if system has the GetAdaptersAddresses() method])],\n                    [dnl AC_MSG_WARN([WIN32 library routine GetAdaptersAddresses() not found])\n                     AS_CASE([${target_os}],\n                         [*mingw*], [AC_MSG_WARN([Windows antivirus might block this test])]\n                         )\n                    ]\n                    )\n\n                myIPHLPAPI_TEST_GAI='\n/* ULONG GetAdaptersInfo(PIP_ADAPTER_INFO addrs, PULONG sizeptr); */\nIP_ADAPTER_INFO buf@<:@8@:>@;\nULONG bufsz = sizeof(buf);\nprintf(\"%ld \", GetAdaptersInfo(buf, &bufsz))\n/* autoconf adds \";return 0;\" */\n'\n\n                AC_CACHE_CHECK([for GetAdaptersInfo() with IPv4 only support],\n                    [ac_cv_func_GetAdaptersInfo],\n                    [AC_LANG_PUSH([C])\n                    dnl e.g. add \"-lws2_32\" for mingw builds\n                    dnl the NETLIBS are set by NUT_CHECK_SOCKETLIB above\n                    SAVED_LIBS=\"$LIBS\"\n                    LIBS=\"$LIBS $NETLIBS $NETLIBS_GETADDRS\"\n                    AX_RUN_OR_LINK_IFELSE(\n                        [AC_LANG_PROGRAM(\n                            [${myIPHLPAPI_TEST_HEADERS}],\n                            [${myIPHLPAPI_TEST_GAI}])],\n                        [ac_cv_func_GetAdaptersInfo=yes\n                        ], [\n                            NETLIBS_GETADDRS=\"-liphlpapi\"\n                            LIBS=\"$LIBS $NETLIBS $NETLIBS_GETADDRS\"\n                            AX_RUN_OR_LINK_IFELSE(\n                                [AC_LANG_PROGRAM(\n                                    [${myIPHLPAPI_TEST_HEADERS}],\n                                    [${myIPHLPAPI_TEST_GAI}])],\n                                [\n                                    ac_cv_func_GetAdaptersInfo=yes\n                                ], [\n                                    ac_cv_func_GetAdaptersInfo=no\n                                    NETLIBS_GETADDRS=\"\"\n                                ]\n                            )\n                        ]\n                    )\n                    AC_LANG_POP([C])\n                    LIBS=\"$SAVED_LIBS\"\n                ])\n                AS_IF([test x\"${ac_cv_func_GetAdaptersInfo}\" = xyes],\n                    [AC_DEFINE([HAVE_GETADAPTERSINFO], 1, [defined if system has the GetAdaptersInfo() method])],\n                    [dnl AC_MSG_WARN([WIN32 library routine GetAdaptersInfo() not found])\n                     AS_CASE([${target_os}],\n                         [*mingw*], [AC_MSG_WARN([Windows antivirus might block this test])]\n                         )\n                    ]\n                    )\n\n            ])\n            ]\n    )]\n)\nAC_SUBST([NETLIBS_GETADDRS])\n\n\ndnl ----------------------------------------------------------------------\ndnl Check for Python binary program names per language version\ndnl to embed into scripts and Make rules\nNUT_CHECK_PYTHON_DEFAULT\n\ndnl ----------------------------------------------------------------------\ndnl Check for \"require Modbus with USB support\" situation before we mangle\ndnl caller-provided with_* values below (by --with-drivers and --with-all)\n\nnut_with_modbus_and_usb=auto\nAC_ARG_WITH(modbus+usb,\n\tAS_HELP_STRING([--with-modbus+usb],\n\t[Require Modbus with USB support (auto)]),\n[\n\tcase \"${withval}\" in\n\tno)\n\t\tdnl # AC_MSG_ERROR(invalid option --without-modbus+usb - see docs/configure.txt)\n\t\tAC_MSG_NOTICE([Treating --without-modbus+usb as not-requiring that used libmodbus supports RTU USB])\n\t\tnut_with_modbus_and_usb=\"no\"\n\t\t;;\n\tauto)\n\t\tnut_with_modbus_and_usb=\"auto\"\n\t\t;;\n\tyes|'')\n\t\tif test -z \"${with_usb}\"; then with_usb=\"${withval}\"; fi\n\t\tif test -z \"${with_modbus}\"; then with_modbus=\"${withval}\"; fi\n\t\tnut_with_modbus_and_usb=\"yes\"\n\t\t;;\n\t*)\n\t\tAC_MSG_ERROR(invalid option --with-modbus+usb='${withval}' - see docs/configure.txt)\n\t\t;;\n\tesac\n], [\n\tdnl Explicit request to build apc_modbus with both modbus and usb\n\tdnl support specified on command line implies we want them present\n\tdnl together too by default\n\tdnl FIXME: Extend to --with-drivers=all or that would not be\n\tdnl  a least-surprise breakage for packagers?\n\tcase x\"${with_drivers}\" in\n\t\t*apc_modbus*)\n\t\t\tdnl Note: defaulting of with_modbus=yes will be handled\n\t\t\tdnl below by --with-drivers\n\t\t\tif test x\"${with_usb}\" = xyes ; then\n\t\t\t\tnut_with_modbus_and_usb=\"yes\"\n\t\t\t\tAC_MSG_WARN([Treating explicit requests to build apc_modbus and toe libusb as building --with-modbus+usb=yes])\n\t\t\tfi\n\t\t\t;;\n\t\t*)\n\t\t\tif test x\"${with_usb}\" = xyes -a x\"${with_modbus}\" = xyes \\\n\t\t\t     -a x\"${with_modbus_includes}\" != x -a x\"${with_modbus_libs}\" != x \\\n\t\t\t; then\n\t\t\t\tnut_with_modbus_and_usb=\"yes\"\n\t\t\t\tAC_MSG_WARN([Treating explicit requests to build NUT with both modbus (with custom includes and libs) and usb as building --with-modbus+usb=yes])\n\t\t\tfi\n\t\t\t;;\n\tesac\n])\n\n\ndnl ----------------------------------------------------------------------\ndnl check for --with-drivers=all (or --with-drivers=name[,name...]) flag\ndnl Note: a few drivers are NUT software constructs (NUTSW_DRIVERLIST)\ndnl e.g. dummy-ups, clone and clone-outlet; they do not have a separate\ndnl toggle or dependency at the moment. Earlier NUT releases before 2.8.0\ndnl grouped them with serial drivers, which were enabled by default.\n\ndnl Autoconf versions before 2.62 do not allow consecutive quadrigraphs\ndnl (square brackets), so the help string depends on the version used\nAC_MSG_CHECKING(which drivers to build)\nAC_ARG_WITH(drivers,\n\tAS_HELP_STRING([m4_version_prereq(2.62,\n\t\t[@<:@--with-drivers=driver@<:@,driver@:>@@:>@],\n\t\t[[[[--with-drivers=driver@<:@,driver@:>@]]]])],\n\t[Only build specific drivers (all)]),\n[\n\tcase \"${withval}\" in\n\tyes|no|'')\n\t\tAC_MSG_ERROR(invalid option --with(out)-drivers - see docs/configure.txt)\n\t\t;;\n\tall)\n\t\tdnl Explicit request to build all drivers (unless specified), or fail\n\t\tDRIVER_BUILD_LIST=\"all\"\n\t\tif test -z \"${with_serial}\"; then with_serial=\"yes\"; fi\n\t\tif test -z \"${with_usb}\"; then with_usb=\"yes\"; fi\n\t\tif test -z \"${with_snmp}\"; then with_snmp=\"yes\"; fi\n\t\tif test -z \"${with_neon}\"; then with_neon=\"yes\"; fi\n\t\tif test -z \"${with_powerman}\"; then with_powerman=\"yes\"; fi\n\t\tif test -z \"${with_modbus}\"; then with_modbus=\"yes\"; fi\n\t\tif test -z \"${with_ipmi}\"; then with_ipmi=\"yes\"; fi\n\n\t\tdnl Platform-dependent snowflakes that are required or auto:\n\t\tif test -z \"${with_gpio}\"; then\n\t\t\tdnl NOTE: Currently we only support a Linux libgpiod\n\t\t\tdnl backend for GPIO; eventually there could be more.\n\t\t\tcase ${target_os} in\n\t\t\t\tlinux*) with_gpio=\"auto\";; dnl # TODO: Detect 2018+ distros?\n\t\t\t\t*) with_gpio=\"auto\";;\n\t\t\tesac\n\t\tfi\n\t\tif test -z \"${with_linux_i2c}\"; then\n\t\t\tcase ${target_os} in\n\t\t\t\tlinux*) with_linux_i2c=\"yes\";;\n\t\t\t\t*) with_linux_i2c=\"auto\";;\n\t\t\tesac\n\t\tfi\n\t\tif test -z \"${with_macosx_ups}\"; then\n\t\t\tif test -d /System/Library/Frameworks/IOKit.framework/ ; then\n\t\t\t\twith_macosx_ups=\"yes\"\n\t\t\telse\n\t\t\t\twith_macosx_ups=\"auto\"\n\t\t\tfi\n\t\tfi\n\t\tAC_MSG_RESULT(${DRIVER_BUILD_LIST})\n\t\t;;\n\tauto)\n\t\tdnl Explicit request to build all drivers that we can\n\t\tDRIVER_BUILD_LIST=\"all\"\n\t\tif test -z \"${with_serial}\"; then with_serial=\"${withval}\"; fi\n\t\tif test -z \"${with_usb}\"; then with_usb=\"${withval}\"; fi\n\t\tif test -z \"${with_snmp}\"; then with_snmp=\"${withval}\"; fi\n\t\tif test -z \"${with_neon}\"; then with_neon=\"${withval}\"; fi\n\t\tif test -z \"${with_powerman}\"; then with_powerman=\"${withval}\"; fi\n\t\tif test -z \"${with_modbus}\"; then with_modbus=\"${withval}\"; fi\n\t\tif test -z \"${with_ipmi}\"; then with_ipmi=\"${withval}\"; fi\n\t\tif test -z \"${with_gpio}\"; then with_gpio=\"${withval}\"; fi\n\t\tif test -z \"${with_linux_i2c}\"; then with_linux_i2c=\"${withval}\"; fi\n\t\tif test -z \"${with_macosx_ups}\"; then with_macosx_ups=\"${withval}\"; fi\n\t\tAC_MSG_RESULT(${DRIVER_BUILD_LIST})\n\t\t;;\n\t*)\n\t\tDRIVER_BUILD_LIST=\"`echo ${withval} | sed 's/,/ /g'`\"\n\t\tAC_MSG_RESULT(${DRIVER_BUILD_LIST})\n\n\t\tAS_IF([test -n \"$DRIVER_BUILD_LIST\"],\n\t\t\t[dnl DRVLIST is occasionally synced with drivers/Makefile.am\n\t\t\t dnl NOTE: Currently \"USB_DRIVERLIST\" is not used standalone:\n\t\t\tDRVLIST_NAMES=\"NUTSW_DRIVERLIST\n\t\t\t\tSERIAL_DRIVERLIST USB_LIBUSB_DRIVERLIST SERIAL_USB_DRIVERLIST\n\t\t\t\tSNMP_DRIVERLIST NEONXML_DRIVERLIST\n\t\t\t\tMACOSX_DRIVERLIST MODBUS_DRIVERLIST LINUX_I2C_DRIVERLIST\n\t\t\t\tPOWERMAN_DRIVERLIST IPMI_DRIVERLIST GPIO_DRIVERLIST\"\n\n\t\t\tget_drvlist() (\n\t\t\t\tdnl Note escaped brackets - \"against\" m4 parser\n\t\t\t\tm4_version_prereq(2.62,\n\t\t\t\t\t[LB=\"@<:@\"; RB=\"@:>@\"],\n\t\t\t\t\t[LB=\"[[\"; RB=\"]]\"]\n\t\t\t\t)\n\t\t\t\tSPACE=\"`printf \"$LB\"' \\t'\"$RB\"`\"\n\t\t\t\tSPACES=\"${SPACE}*\"\n\t\t\t\tsed -e \"s/${SPACES}\"\"$LB\"'+'\"$RB\"'*='\"${SPACES}/=/\" \\\n\t\t\t\t    -e \"s/^${SPACES}//\" < \"$srcdir/drivers/Makefile.am\" \\\n\t\t\t\t| {\n\t\t\t\t\tC=false; V=false\n\t\t\t\t\twhile read LINE ; do\n\t\t\t\t\t\tcase \"$LINE\" in\n\t\t\t\t\t\t\t*'\\') C=true; if $V ; then echo \"$LINE\" ; fi ;;\n\t\t\t\t\t\t\t*) C=false; V=false ;;\n\t\t\t\t\t\tesac\n\t\t\t\t\t\tcase \"$LINE\" in\n\t\t\t\t\t\t\t\"$1\"=*)\n\t\t\t\t\t\t\t\techo \"$LINE\" | sed -e 's,^'\"$LB\"'^='\"$RB\"'*=,,' -e 's,\\$,,'\n\t\t\t\t\t\t\t\tV=$C\n\t\t\t\t\t\t\t\t;;\n\t\t\t\t\t\tesac\n\t\t\t\t\tdone\n\t\t\t\t} | tr '\\n' ' ' | sed -e \"s,${SPACE}${SPACES}, ,\" -e \"s,${SPACES}\\$,,\"\n\t\t\t)\n\n\t\t\tfor DRVLIST_NAME in $DRVLIST_NAMES; do\n\t\t\t\tOUT=\"`get_drvlist \"$DRVLIST_NAME\"`\" \\\n\t\t\t\t&& test -n \"$OUT\" || OUT=\"\"\n\t\t\t\teval $DRVLIST_NAME=\"\\$OUT\"\n\t\t\t\tAC_MSG_NOTICE([Will check custom driver selection against $DRVLIST_NAME=\"$OUT\"])\n\t\t\tdone\n\n\t\t\tdnl Note: do not quote the expansion below to keep it multi-token:\n\t\t\tfor DRV in $DRIVER_BUILD_LIST ; do\n\n\t\t\t\tDRV_HITS=\"\"\n\t\t\t\tdnl #DEVEL-DEBUG# AC_MSG_NOTICE([= Checking DRV=\"$DRV\"])\n\t\t\t\tfor DRVLIST_NAME in $DRVLIST_NAMES; do\n\t\t\t\t\tdnl #DEVEL-DEBUG# AC_MSG_NOTICE([== Checking DRVLIST_NAME=\"$DRVLIST_NAME\"])\n\t\t\t\t\teval DRVLIST=\"\\${$DRVLIST_NAME}\"\n\t\t\t\t\tdnl #DEVEL-DEBUG# AC_MSG_NOTICE([== Contents DRVLIST=\"$DRVLIST\"])\n\n\t\t\t\t\tfor DN in $DRVLIST ; do\n\t\t\t\t\t\tdnl #DEVEL-DEBUG# AC_MSG_NOTICE([=== Checking DN=\"$DN\"])\n\t\t\t\t\t\tAS_IF([test x\"$DN\" = x\"$DRV\"], [\n\t\t\t\t\t\t\tDRV_HITS=\"$DRV_HITS $DRVLIST_NAME\"\n\t\t\t\t\t\t\tAS_CASE([\"$DRVLIST_NAME\"],\n\n\t\t\t\t\t\t\t\t[NUTSW_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAC_MSG_NOTICE([Building NUT-Software-only driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t[SERIAL_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_serial}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-serial=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_serial=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[USB_LIBUSB_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_usb}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-usb=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_usb=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[SERIAL_USB_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tdnl e.g. nutdrv_qx that can do both\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_usb}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-usb=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_usb=yes]\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_serial}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-serial=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_serial=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[SNMP_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_snmp}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-snmp=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_snmp=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[NEONXML_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_neon}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-neon=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_neon=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[MACOSX_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tdnl NOTE: This one is a bit special,\n\t\t\t\t\t\t\t\t\tdnl just one certain driver so far\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_macosx_ups}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-macosx-ups=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_macosx_ups=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[MODBUS_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_modbus}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-modbus=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_modbus=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[LINUX_I2C_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_linux_i2c}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-linux-i2c=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_linux_i2c=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[POWERMAN_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_powerman}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-powerman=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_powerman=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[IPMI_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_ipmi}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-ipmi=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_ipmi=yes]\n\t\t\t\t\t\t\t\t\t)],\n\t\t\t\t\t\t\t\t[GPIO_DRIVERLIST], [\n\t\t\t\t\t\t\t\t\tAS_IF([test -z \"${with_gpio}\"],\n\t\t\t\t\t\t\t\t\t\t[AC_MSG_NOTICE([Requiring --with-gpio=yes for driver \"$DRV\"])\n\t\t\t\t\t\t\t\t\t\twith_gpio=yes]\n\t\t\t\t\t\t\t\t\t)],\n\n\t\t\t\t\t\t\t\t[AC_MSG_WARN([Unhandled DRVLIST_NAME=$DRVLIST_NAME])]\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\tdnl Break once, maybe a driver hits several categories\n\t\t\t\t\t\t])\n\t\t\t\t\tdone\n\t\t\t\tdone\n\t\t\t\tAS_IF([test -z \"${DRV_HITS}\"],\n\t\t\t\t\t[AC_MSG_ERROR([Requested driver '$DRV' is not defined in drivers/Makefile.am (or configure.ac has a bug/lag detecting driver lists)])])\n\n\t\t\tdone\n\t\t\t])\n\n\t\t;;\n\tesac\n], [\n\tdnl Implicit request to build whatever is enabled;\n\tdnl do not force --with-all here:\n\tDRIVER_BUILD_LIST=\"all\"\n\tAC_MSG_RESULT(all available)\n])\nAM_CONDITIONAL(SOME_DRIVERS, test \"${DRIVER_BUILD_LIST}\" != \"all\")\n\nif test \"${DRIVER_BUILD_LIST}\" != \"all\"; then\n\tNUT_REPORT([only build specific drivers], [${DRIVER_BUILD_LIST}])\nfi\n\ndnl ----------------------------------------------------------------------\ndnl check for --with-all (or --without-all, or --with-all=auto) flag\n\nAC_MSG_CHECKING(for --with-all)\nAC_ARG_WITH(all,\n\tAS_HELP_STRING([--with-all], [enable serial, usb, snmp, neon, ipmi, powerman, modbus, gpio (currently on Linux released after ~2018), linux_i2c (on Linux), macosx-ups (on MacOS), cgi, dev, avahi, nut-scanner, nutconf, pynut]),\n[\n\tif test -n \"${withval}\"; then\n\t\tdnl Note: we allow \"no\" as a positive value, because\n\t\tdnl this is what the user expects from --without-all\n\t\tdnl Note: these settings do not touch generation of\n\t\tdnl \"--with-docs=...\", that is handled separately\n\t\tif test -z \"${with_serial}\"; then with_serial=\"${withval}\"; fi\n\t\tif test -z \"${with_usb}\"; then with_usb=\"${withval}\"; fi\n\t\tif test -z \"${with_snmp}\"; then with_snmp=\"${withval}\"; fi\n\t\tif test -z \"${with_neon}\"; then with_neon=\"${withval}\"; fi\n\t\tif test -z \"${with_powerman}\"; then with_powerman=\"${withval}\"; fi\n\t\tif test -z \"${with_modbus}\"; then with_modbus=\"${withval}\"; fi\n\t\tif test -z \"${with_ipmi}\"; then with_ipmi=\"${withval}\"; fi\n\n\t\tdnl Platform-dependent snowflakes that are required or auto:\n\t\tif test -z \"${with_gpio}\"; then\n\t\t\tdnl NOTE: Currently we only support a Linux libgpiod\n\t\t\tdnl backend for GPIO; eventually there could be more.\n\t\t\twith_gpio=\"${withval}\"\n\t\t\tcase ${target_os} in\n\t\t\t\tlinux*) ;;\n\t\t\t\t*) test x\"${withval}\" = xno || with_gpio=\"auto\" ;;\n\t\t\tesac\n\t\tfi\n\t\tif test -z \"${with_linux_i2c}\"; then\n\t\t\twith_linux_i2c=\"${withval}\"\n\t\t\tcase ${target_os} in\n\t\t\t\tlinux*) ;;\n\t\t\t\t*) test x\"${withval}\" = xno || with_linux_i2c=\"auto\" ;;\n\t\t\tesac\n\t\tfi\n\t\tif test -z \"${with_macosx_ups}\"; then\n\t\t\twith_macosx_ups=\"${withval}\"\n\t\t\tif ! test -d /System/Library/Frameworks/IOKit.framework/ ; then\n\t\t\t\ttest x\"${withval}\" = xno || with_macosx_ups=\"auto\"\n\t\t\tfi\n\t\tfi\n\n\t\tdnl These are not driver families, but other features:\n\t\tif test -z \"${with_cgi}\"; then with_cgi=\"${withval}\"; fi\n\t\tif test -z \"${with_dev}\"; then with_dev=\"${withval}\"; fi\n\t\tif test -z \"${with_avahi}\"; then with_avahi=\"${withval}\"; fi\n\t\tif test -z \"${with_nut_scanner}\"; then with_nut_scanner=\"${withval}\"; fi\n\t\tif test -z \"${with_nutconf}\"; then with_nutconf=\"${withval}\"; fi\n\n\t\tif test -n \"${PYTHON}${PYTHON2}${PYTHON3}\" -a x\"${withval}\" = xyes \\\n\t\t|| test x\"${withval}\" != xyes \\\n\t\t; then\n\t\t\tdnl We expect Python to be available (augeas etc),\n\t\t\tdnl so if it is present - try to provide the PyNUT\n\t\t\tdnl binding module:\n\t\t\tif test -z \"${with_pynut}\"; then with_pynut=\"${withval}\"; fi\n\n\t\t\tdnl However, do not let \"--with-all\" break builds\n\t\t\tdnl on servers that lack some GUI modules in their\n\t\t\tdnl Python installations; \"auto\" is defaulted below.\n\t\t\tdnl # if test -z \"${with_nut_monitor}\"; then with_nut_monitor=\"${withval}\"; fi\n\t\tfi\n\n\t\tAC_MSG_RESULT([${withval}])\n\telse\n\t\tAC_MSG_RESULT(not given)\n\tfi\n], [\n\tAC_MSG_RESULT(not given)\n])\n\ndnl ----------------------------------------------------------------------\ndnl declare a number of --with-FEATURE options. Do this early, so that\ndnl they are listed near the top by \"./configure --help\"; however,\ndnl note that options with further investigation methods are listed\ndnl a bit below to be grouped with their additional with/enable help.\n\nNUT_ARG_WITH([nutconf], [build and install the nutconf tool (experimental, has compiler/coverage warnings)], [auto])\n\nNUT_ARG_WITH([dev], [build and install the development files], [no])\n\ndnl Activate WITH_UNMAPPED_DATA_POINTS for troubleshooting and evolution?\ndnl Note that production drivers must conform to docs/nut-names.txt\nNUT_ARG_WITH([unmapped-data-points],\n    [represent USB-HID and SNMP data points discovered during subdriver generation but not mapped to nut-names yet],\n    [no])\nAS_IF([test x\"${nut_with_unmapped_data_points}\" = xyes],\n    [AC_DEFINE(WITH_UNMAPPED_DATA_POINTS, 1,\n        [Define to enable data points discovered during subdriver generation but not mapped to nut-names yet])],\n    [AC_DEFINE(WITH_UNMAPPED_DATA_POINTS, 0,\n        [Define to enable data points discovered during subdriver generation but not mapped to nut-names yet])]\n)\n\ndnl The NUT legacy option was --with-doc; however to simplify configuration\ndnl in some common packaging frameworks, we also allow --with-docs as\ndnl a second-class citizen (if both are set, the old option name wins).\ndnl Also note that the legacy default was \"man=yes\" due to requirements\ndnl of the \"make distcheck\", but it was reduced to \"man=auto\" so that\ndnl the usual builds can pass by default on systems without asciidoc.\nNUT_ARG_WITH([docs], [build and install documentation (alias to --with-doc)], [man=auto])\nNUT_ARG_WITH([doc], [build and install documentation (see docs/configure.txt for many variants of the option)], [${nut_with_docs}])\n\ndnl NOTE: Sections may be strings, not pure numbers, on some platforms:\nNUT_ARG_WITH([docs-man-section-api], [man page section for library APIs], [3])\nNUT_ARG_WITH([docs-man-section-cfg], [man page section for configuration files], [5])\nNUT_ARG_WITH([docs-man-section-cmd-sys], [man page section for system management commands], [8])\nNUT_ARG_WITH([docs-man-section-cmd-usr], [man page section for user commands], [1])\n\ndnl NOTE: Until X-Mas 2021, the default was \"legacy\" (now \"medium\")\nNUT_ARG_ENABLE([warnings],\n    [enable warning presets that were picked as useful in maintainership and CI practice (variants include gcc-minimal, gcc-medium, gcc-hard, clang-minimal, clang-medium, clang-hard, all; auto-choosers: hard, medium, minimal, yes=auto='gcc or clang or all at hardcoded default difficulty')],\n    [auto])\nNUT_ARG_ENABLE([Werror],\n    [fail the build if compiler emits any warnings (treat them as errors)],\n    [no])\nNUT_ARG_WITH([debuginfo],\n    [enable compiler options for debug-friendly builds of all NUT binaries (\"no\" by default; \"auto\" means \"yes unless CFLAGS say otherwise\")],\n    [no])\ndnl To help find warning/error details in a wall of text, see --enable-Wcolor handled above\n\ndnl ----------------------------------------------------------------------\ndnl Check for with-ssl, and --with-nss or --with-openssl which can be used\ndnl by NUT as well as its networking-capable dependencies (net-snmp, etc.)\ndnl Only one can be enabled at a time, with a preference for OpenSSL\ndnl if both are available\n\nnut_ssl_lib=\"\"\n\nNUT_ARG_WITH([ssl], [enable SSL support (either NSS or OpenSSL)], [auto])\nNUT_ARG_WITH([nss], [enable SSL support using Mozilla NSS], [auto])\nNUT_ARG_WITH([openssl], [enable SSL support using OpenSSL], [auto])\n\ndnl ${nut_with_ssl}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_ssl}\" != \"no\"; then\n   dnl check if either NSS or OpenSSL was explicitly requested\n   if test \"${nut_with_nss}\" = \"yes\"; then\n      NUT_CHECK_LIBNSS\n      if test \"${nut_have_libnss}\" != \"yes\"; then\n         AC_MSG_ERROR([Mozilla NSS not found (required for SSL support)])\n      fi\n   elif test \"${nut_with_openssl}\" = \"yes\"; then\n      NUT_CHECK_LIBOPENSSL\n      if test \"${nut_have_openssl}\" != \"yes\"; then\n         AC_MSG_ERROR([OpenSSL not found (required for SSL support)])\n      fi\n   else\n      dnl Prefer OpenSSL over NSS otherwise\n      NUT_CHECK_LIBOPENSSL\n      if test \"${nut_have_openssl}\" != \"yes\"; then\n         NUT_CHECK_LIBNSS\n         if test \"${nut_have_libnss}\" != \"yes\"; then\n            dnl Only abort if SSL has been explicitly requested by the user\n            if test \"${nut_with_ssl}\" = \"yes\"; then\n               AC_MSG_ERROR([Neither Mozilla NSS nor OpenSSL was found, but one is needed for the requested SSL support.])\n            else\n               AC_MSG_WARN([Neither Mozilla NSS nor OpenSSL was found (required for SSL support)])\n            fi\n            nut_with_ssl=\"no\"\n         else\n            nut_with_nss=\"${nut_have_libnss}\"\n         fi\n      else\n         nut_with_openssl=\"${nut_have_openssl}\"\n      fi\n   fi\nfi\n\nAM_CONDITIONAL(WITH_NSS, test \"${nut_with_nss}\" = \"yes\")\nAM_CONDITIONAL(WITH_OPENSSL, test \"${nut_with_openssl}\" = \"yes\")\n\nNUT_REPORT_FEATURE([enable SSL support], [${nut_with_ssl}], [${nut_ssl_lib}],\n\t\t\t\t\t[WITH_SSL], [Define to enable SSL])\n\ndnl ----------------------------------------------------------------------\ndnl Check for presence and compiler flags of various libraries\n\nNUT_ARG_WITH([serial], [build and install serial drivers], [yes])\n\ndnl These checks are performed unconditionally, even if the corresponding\ndnl --with-* options are not given. This is because we cannot predict\ndnl what will be in the --with-drivers argument.\n\nNUT_CHECK_LIBREGEX\nNUT_ARG_WITH([usb], [build and install USB drivers, optionally require build with specified version of libusb library and API: (auto|libusb-0.1|libusb-1.0)], [auto])\nnut_usb_lib=\"\"\nNUT_CHECK_LIBUSB\n\nNUT_ARG_WITH([snmp], [build and install SNMP drivers], [auto])\nNUT_CHECK_LIBNETSNMP\n\nNUT_ARG_WITH([neon], [build and install neon based XML/HTTP driver], [auto])\nNUT_CHECK_LIBNEON\n\nNUT_ARG_WITH([powerman], [build and install Powerman PDU client driver], [auto])\nNUT_CHECK_LIBPOWERMAN\n\nNUT_ARG_WITH([modbus], [build and install modbus drivers], [auto])\nNUT_CHECK_LIBMODBUS\n\nNUT_ARG_WITH([gpio], [build and install GPIO driver], [auto])\nNUT_CHECK_LIBGPIO\n\nNUT_ARG_WITH([avahi], [build and install Avahi support], [auto])\nNUT_CHECK_LIBAVAHI\n\nNUT_ARG_WITH([ipmi], [build and install IPMI PSU driver], [auto])\nNUT_ARG_WITH([freeipmi], [enable IPMI support using FreeIPMI], [auto])\ndnl NUT_ARG_WITH([openipmi], [enable IPMI support using OpenIPMI], [auto])\n\ndnl Platform-dependent drivers, currently their detection code is directly\ndnl spelled out in configure.ac\nNUT_ARG_WITH([macosx_ups], [build and install Mac OS X Power Sources meta-driver], [auto])\nNUT_ARG_WITH([linux_i2c], [build and install i2c drivers], [auto])\n\ndnl A Python GUI client application for the sysadmin desktop\ndnl (not necessarily on the NUT server itself):\nNUT_ARG_WITH([nut_monitor], [install the NUT-Monitor GUI files], [auto])\nNUT_ARG_WITH([pynut], [install the PyNUT module files (yes, no, app, auto)], [auto])\ndnl Note: we did NUT_CHECK_PYTHON2 NUT_CHECK_PYTHON3 etc above,\ndnl and if at all possible, we generate the files from .in templates\ndnl anyway by running this configure script. The question is about\ndnl installing these features or not.\ndnl Note: more for tests than other reasons, there is also an option\ndnl value to \"force\" the installation.\n\ndnl The gettext \"msgfmt\" tool (or equivalent) can be used to maintain\ndnl human-language text translations. Currently this is used specifically\ndnl in the Python NUT-Monitor app sources (*.po => *.mo conversions).\nAC_PATH_PROGS([MSGFMT], [msgfmt], [none])\nAM_CONDITIONAL([HAVE_MSGFMT], [test \"x${MSGFMT}\" != \"xnone\"])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-serial\n\ndnl ${nut_with_serial}: any value except \"yes\" or \"no\" is treated as \"auto\".\ndnl Below we try to detect if we can build serial drivers, and if we must?\nAS_IF([test \"${nut_with_serial}\" != \"no\"],\n    [AS_IF([test \"${nut_with_serial}\" != \"yes\"],[nut_with_serial=\"auto\"])\n\n    CFLAGS_SAVED_SERIAL=\"${CFLAGS}\"\n    AS_IF([test \"${GCC}\" = yes],\n        [CFLAGS_SAVED_WERROR=\"${CFLAGS} -Wall -Werror\"\n         CFLAGS_SAVED_WNOERROR=\"${CFLAGS} -Wno-error\"\n        ],\n        [CFLAGS_SAVED_WERROR=\"${CFLAGS}\"\n         CFLAGS_SAVED_WNOERROR=\"${CFLAGS}\"\n        ])\n\n    dnl At least recent *BSD distros have deprecated sys/termios.h and spew\n    dnl warnings that termios.h should be used instead. This is redundantly\n    dnl fatal for pedantic builds where we aim to have no warnings in code.\n    dnl So there AC_CHECK_HEADERS does find the header, but we don't really\n    dnl want to use it unless we have no choice: if there is a warning while\n    dnl trying sys/ version, try the plain header path (without fatal warnings),\n    dnl and only if that is missing - retry with the sys/ version again (and\n    dnl no warnings still).\n\n    CFLAGS=\"${CFLAGS_SAVED_WERROR}\"\n    AC_CHECK_HEADERS(sys/termios.h, [], [\n        CFLAGS=\"${CFLAGS_SAVED_WNOERROR}\"\n        AC_CHECK_HEADERS(termios.h, [], [\n            AC_CHECK_HEADERS(sys/termios.h, [], [], [AC_INCLUDES_DEFAULT])\n            ], [AC_INCLUDES_DEFAULT])\n        ], [AC_INCLUDES_DEFAULT])\n\n    dnl CFLAGS at this point suffice for surviving a compilation with termios.h\n\n    dnl Don't mind the stupid code below, it just probes the tokens and\n    dnl sails around compiler warnings\n    AC_MSG_CHECKING([for struct termios and speed_t])\n    AC_LANG_PUSH([C])\n    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([\n#if defined(HAVE_SYS_TERMIOS_H)\n#  include <sys/termios.h>      /* for speed_t */\n#else\n# if defined(HAVE_TERMIOS_H)\n#  include <termios.h>\n# endif /* HAVE_TERMIOS_H */\n#endif /* HAVE_SYS_TERMIOS_H */\nvoid getspeed(speed_t* b) { *b = B19200; }\n],\n[struct termios tio;\nif (!tcgetattr(0, &tio)) { return 1; }\nspeed_t baudrate;\ngetspeed(&baudrate);\n]\n        )],\n        [AC_MSG_RESULT([ok])\n         nut_have_serial_types=yes\n        ],\n        [AC_MSG_RESULT([no, struct termios and/or speed_t not found in discovered headers])\n         nut_have_serial_types=no\n        ]\n     )\n     AC_LANG_POP([C])\n\n     dnl Restore common set-or-discovered CFLAGS\n     CFLAGS=\"${CFLAGS_SAVED_SERIAL}\"\n\n     AC_MSG_CHECKING([whether we can build serial drivers])\n     AS_CASE([\"${target_os}\"],\n        [*mingw*], [\n             AS_IF([test \"${nut_have_serial_types}\" != yes],\n                [AC_MSG_WARN([not with system includes, but can try with our fallback for the target platform])\n                 nut_have_serial_types=yes]\n             )\n        ])\n     AS_IF([test \"${nut_have_serial_types}\" = yes],\n        [AS_IF([test \"${nut_with_serial}\" = \"auto\"],[nut_with_serial=\"yes\"])],\n        [AS_IF([test \"${nut_with_serial}\" = \"auto\"],[nut_with_serial=\"no\"])\n         AS_IF([test \"${nut_with_serial}\" = \"yes\"],[AC_MSG_ERROR([no, and were required to])])\n        ])\n     AS_IF([test \"${nut_with_serial}\" = \"yes\"],\n        [AC_MSG_RESULT([yes])],\n        [AC_MSG_RESULT([no])])\n])\n\nNUT_REPORT_DRIVER([build serial drivers], [${nut_with_serial}], [],\n\t\t\t\t\t[WITH_SERIAL], [Define to enable serial support])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-usb are in its m4 file and NUT_CHECK_LIBUSB() called above\n\ndnl Note: there is no libusb-config script (and variable) for libusb-1.0\nAM_CONDITIONAL(WITH_LIBUSB_1_0, test \"${nut_usb_lib}\" = \"(libusb-1.0)\")\nAM_CONDITIONAL(WITH_LIBUSB_0_1, test \"${nut_usb_lib}\" = \"(libusb-0.1)\" -o \"${nut_usb_lib}\" = \"(libusb-0.1-config)\")\n\nNUT_REPORT_DRIVER([build USB drivers], [${nut_with_usb}], [${nut_usb_lib}],\n\t\t\t\t\t[WITH_USB], [Define to enable USB support])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-neon\n\ndnl ${nut_with_neon}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_neon}\" = \"yes\" -a \"${nut_have_neon}\" != \"yes\"; then\n   AC_MSG_ERROR([neon libraries not found, required for neon based XML/HTTP driver])\nfi\n\nif test \"${nut_with_neon}\" != \"no\"; then\n   nut_with_neon=\"${nut_have_neon}\"\nfi\n\nNUT_REPORT_DRIVER([build neon based XML driver], [${nut_with_neon}], [],\n\t\t\t\t\t[WITH_NEON], [Define to enable Neon HTTP support])\nAM_CONDITIONAL([HAVE_NEON], [test \"${nut_have_neon}\" = \"yes\"])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-avahi\n\ndnl ${nut_with_avahi}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_avahi}\" = \"yes\" -a \"${nut_have_avahi}\" != \"yes\"; then\n   AC_MSG_ERROR([avahi libraries not found])\nfi\n\nif test \"${nut_with_avahi}\" != \"no\"; then\n   nut_with_avahi=\"${nut_have_avahi}\"\nfi\n\nNUT_REPORT_FEATURE([enable Avahi support], [${nut_with_avahi}], [],\n\t\t\t\t\t[WITH_AVAHI], [Define to enable Avahi support])\n\ndnl ----------------------------------------------------------------------\n\ndnl checks related to --with-powerman\n\ndnl ${nut_with_powerman}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_powerman}\" = \"yes\" -a \"${nut_have_libpowerman}\" != \"yes\"; then\n   AC_MSG_ERROR([Powerman client libraries not found, required for Powerman PDU client driver])\nfi\n\nif test \"${nut_with_powerman}\" != \"no\"; then\n   nut_with_powerman=\"${nut_have_libpowerman}\"\nfi\n\nNUT_REPORT_DRIVER([build Powerman PDU client driver], [${nut_with_powerman}], [],\n\t\t\t\t\t[WITH_LIBPOWERMAN], [Define to enable Powerman PDU support])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-modbus\n\ndnl ${nut_with_modbus}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_modbus}\" = \"yes\" -a \"${nut_have_libmodbus}\" != \"yes\"; then\n   AC_MSG_ERROR([modbus library not found, required for Modbus drivers])\nfi\n\nif test \"${nut_with_modbus_and_usb}\" = \"yes\" -a \"${nut_have_libmodbus_usb}\" != \"yes\"; then\n   AC_MSG_ERROR([modbus library variant with RTU USB support not found, required for USB-capable Modbus drivers])\nfi\n\nif test \"${nut_with_modbus}\" != \"no\"; then\n   nut_with_modbus=\"${nut_have_libmodbus}\"\nfi\n\nNUT_REPORT_DRIVER([build Modbus drivers], [${nut_with_modbus}], [],\n\t\t\t\t\t[WITH_MODBUS], [Define to enable Modbus support])\n\nAS_IF([test \"${nut_with_modbus}\" != \"no\"], [\n\tdnl Only display this detail when building modbus at all\n\tdnl Config definition NUT_MODBUS_HAS_USB is set in the\n\tdnl detection method (if nut_have_libmodbus_usb==\"yes\")\n\tNUT_REPORT_DRV([build Modbus drivers with RTU USB support], [${nut_have_libmodbus_usb}])\n])\n\ndnl ----------------------------------------------------------------------\ndnl Check for with-ipmi, and --with-freeipmi (or --with-openipmi)\ndnl Only one can be enabled at a time, with a preference for FreeIPMI\ndnl if both are available (since it is the only one supported ATM!!)\n\nnut_ipmi_lib=\"\"\n\ndnl ${nut_with_ipmi}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_ipmi}\" != \"no\"; then\n   dnl check if FreeIPMI (and maybe later OpenIPMI) was explicitly requested\n   if test \"${nut_with_freeipmi}\" = \"yes\"; then\n      NUT_CHECK_LIBFREEIPMI\n      if test \"${nut_have_freeipmi}\" != \"yes\"; then\n         AC_MSG_ERROR([FreeIPMI not found, required for IPMI support])\n      fi\n      dnl Implies --with-ipmi\n      nut_with_ipmi=\"yes\"\n   dnl elif test \"${nut_with_openipmi}\" = \"yes\"; then\n      dnl AC_MSG_ERROR([OpenIPMI is not yet supported])\n      dnl NUT_CHECK_LIBOPENIPMI\n      dnl if test \"${nut_have_openipmi}\" != \"yes\"; then\n      dnl    AC_MSG_ERROR([OpenIPMI not found, required for IPMI support])\n      dnl fi\n      dnl    Implies --with-ipmi\n      dnl    nut_with_ipmi=\"yes\"\n      dnl    AC_DEFINE(WITH_OPENIPMI, 1, [Define to enable IPMI support using OpenIPMI])\n   else\n      dnl Prefer FreeIPMI over OpenIPMI otherwise\n      NUT_CHECK_LIBFREEIPMI\n      if test \"${nut_have_freeipmi}\" != \"yes\"; then\n         if test \"${nut_with_ipmi}\" = \"yes\"; then\n            AC_MSG_ERROR([FreeIPMI not found, required for IPMI support])\n         fi\n         nut_with_ipmi=\"no\"\n         dnl NUT_CHECK_OPENIPMI\n         dnl if test \"${nut_have_openipmi}\" != \"yes\"; then\n         dnl    if test \"${nut_with_ipmi}\" = \"yes\"; then\n         dnl       AC_MSG_ERROR([Neither GNU FreeIPMI nor OpenIPMI was found (required for IPMI support)])\n         dnl    fi\n         dnl    nut_with_ipmi=\"no\"\n         dnl else\n         dnl    Implies --with-ipmi\n         dnl    nut_with_ipmi=\"yes\"\n         dnl    nut_with_openipmi=\"yes\"\n         dnl fi\n      else\n         dnl Implies --with-ipmi\n         nut_with_ipmi=\"yes\"\n         nut_with_freeipmi=\"yes\"\n         AC_DEFINE(WITH_FREEIPMI, 1, [Define to enable IPMI support using FreeIPMI])\n      fi\n   fi\nfi\n\n\nNUT_REPORT_DRIVER([build IPMI driver], [${nut_with_ipmi}], [${nut_ipmi_lib}],\n\t\t\t\t\t[WITH_IPMI], [Define to enable IPMI support])\n\ndnl Note: we still have to manually enable complementary AC_DEFINEs (see above)\ndnl and AM_CONDITIONALs (see below)...\nAM_CONDITIONAL(WITH_FREEIPMI, test \"${nut_with_freeipmi}\" = \"yes\")\ndnl AM_CONDITIONAL(WITH_OPENIPMI, test \"${nut_with_openipmi}\" = \"yes\")\n\ndnl ----------------------------------------------------------------------\ndnl Check for with-gpio\n\nif test \"${nut_with_gpio}\" = \"yes\" -a \"${nut_have_gpio}\" != \"yes\"; then\n   AC_MSG_ERROR([No supported GPIO library was found, required for GPIO driver])\nfi\n\ndnl ${nut_with_gpio}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_gpio}\" != \"no\"; then\n   nut_with_gpio=\"${nut_have_gpio}\"\nfi\n\nNUT_REPORT_DRIVER([build GPIO driver], [${nut_with_gpio}], [${nut_gpio_lib}],\n\t\t\t\t\t[WITH_GPIO], [Define to enable GPIO support])\n\ndnl ----------------------------------------------------------------------\ndnl The Mac OS X meta-driver looks at IOKit Power Sources keys managed by\ndnl the internal USB UPS driver.\ndnl\ndnl FIXME: be slightly more clever here:\n\nif test \"${nut_with_macosx_ups}\" != no; then\n   if test -d /System/Library/Frameworks/IOKit.framework/ ; then\n      nut_with_macosx_ups=\"yes\"\n   else\n      if test \"${nut_with_macosx_ups}\" = yes; then\n          AC_MSG_ERROR([macosx-ups was required but can not be fulfilled for this build: not MacOS])\n      fi\n      nut_with_macosx_ups=\"no\"\n   fi\nfi\n\nNUT_REPORT_DRIVER([build Mac OS X meta-driver],\n\t\t\t[${nut_with_macosx_ups}], [${nut_macosx_ups_lib}],\n\t\t\t[WITH_MACOSX], [Define to enable Mac OS X meta-driver])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with_linux_i2c\ndnl Check for i2c header on Linux, used for ASEM UPS driver\nLIBI2C_LIBS=\"\"\nif test \"${nut_with_linux_i2c}\" != no; then\n    case ${target_os} in\n        linux* )\n            AC_CHECK_HEADER(\n                [linux/i2c-dev.h],\n                [AC_DEFINE([HAVE_LINUX_I2C_DEV_H], [1],\n                    [Define to 1 if you have <linux/i2c-dev.h>.])]\n            )\n            AC_CHECK_HEADER(\n                [i2c/smbus.h],\n                [AC_DEFINE([HAVE_LINUX_SMBUS_H], [1],\n                    [Define to 1 if you have <i2c/smbus.h>.])]\n            )\n            nut_have_linux_i2c=\"no\"\n            AC_CHECK_DECLS(\n                [i2c_smbus_access, i2c_smbus_read_byte_data, i2c_smbus_write_byte_data, i2c_smbus_read_word_data, i2c_smbus_write_word_data, i2c_smbus_read_block_data],\n                [nut_have_linux_i2c=\"yes\"],\n                [],\n                [#include <stdio.h>\n                 #ifdef HAVE_LINUX_I2C_DEV_H\n                 #include <linux/i2c-dev.h>\n                 #endif\n                 #ifdef HAVE_LINUX_SMBUS_H\n                 #include <i2c/smbus.h>\n                 #endif\n                ]\n            )\n            dnl Builds for bitness/arch other than system default can be\n            dnl \"compromised\" by lack of respective binary library, so\n            dnl even if we have the right headers, ultimate link fails.\n            dnl Note: here we keep the verdict from above, or make it worse.\n            LIBS_SAVED=\"$LIBS\"\n            LIBS=\"\"\n            AS_IF([test \"${nut_have_linux_i2c}\" = yes], [\n                nut_have_linux_i2c=\"no\"\n                AC_SEARCH_LIBS(i2c_smbus_read_byte, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_access, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_read_byte_data, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_write_byte_data, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_read_word_data, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_write_word_data, i2c, [\n                AC_SEARCH_LIBS(i2c_smbus_read_block_data, i2c, [\n                    [nut_have_linux_i2c=\"yes\"]\n                ])])])])])])])])\n\n            dnl # Note: *with* (desire) is not \"no\" in this big if-clause\n            AS_IF([test \"${nut_have_linux_i2c}\" = yes],\n                [nut_with_linux_i2c=\"yes\"],\n                [AS_IF([test \"${nut_with_linux_i2c}\" = \"yes\"],\n                    [AC_MSG_ERROR(i2c was required but can not be fulfilled for this build)],\n                    [nut_with_linux_i2c=\"no\"])\n                ])\n\n            LIBI2C_LIBS=\"$LIBS\"\n            LIBS=\"$LIBS_SAVED\"\n            ;;\n        * )\n            if test \"${nut_with_linux_i2c}\" = yes; then\n                AC_MSG_ERROR([i2c was required but can not be fulfilled for this build: not linux])\n            fi\n            nut_with_linux_i2c=\"no\"\n            ;;\n    esac\nfi\nNUT_REPORT_DRIVER(\n    [build i2c based drivers],\n    [${nut_with_linux_i2c}],\n    [],\n    [WITH_LINUX_I2C],\n    [Define to enable I2C support]\n)\n\ndnl ----------------------------------------------------------------------\ndnl Check for --with-wrap\n\nNUT_ARG_WITH([wrap], [enable libwrap (tcp-wrappers) support], [auto])\n\ndnl ${nut_with_wrap}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_wrap}\" != \"no\"; then\n   dnl check for libwrap compiler flags\n   NUT_CHECK_LIBWRAP\nfi\n\nif test \"${nut_with_wrap}\" = \"yes\" -a \"${nut_have_libwrap}\" != \"yes\"; then\n   AC_MSG_ERROR([libwrap not found])\nfi\n\nif test \"${nut_with_wrap}\" != \"no\"; then\n   nut_with_wrap=\"${nut_have_libwrap}\"\nfi\n\nNUT_REPORT_FEATURE([enable libwrap (tcp-wrappers) support], [${nut_with_wrap}], [],\n\t\t\t\t\t[WITH_WRAP], [Define to enable libwrap (tcp-wrappers) support])\n\n\ndnl ----------------------------------------------------------------------\ndnl Check for --with-libltdl and --with-nut-scanner\n\ndnl Note: libltdl is primarily used by nut-scanner now; however some\ndnl side projects and forks of NUT have more creative uses for it\ndnl and might eventually land in NUT codebase proper.\nNUT_ARG_WITH([libltdl], [enable libltdl (Libtool dlopen abstraction) support], [auto])\n\ndnl Note: default could be overridden above by --with-all handling.\ndnl While nut-scanner decides at run-time if it would use third-party shared\ndnl library files (bundled along or not, if available for the platform), its\ndnl binary must be configured now and built against their headers at least.\nNUT_ARG_WITH([nut-scanner], [build and install nut-scanner tool (requires libltdl; optionally libusb, libneon, libsnmp)], [auto])\n\ndnl ${nut_with_libltdl}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test x\"${nut_with_libltdl}\" != x\"no\"; then\n    if test x\"${nut_with_nut_scanner}\" = x\"yes\"; then\n        dnl Require libltdl to be present (or fail the configure script)\n        nut_with_libltdl=\"yes\"\n    fi\n\n    dnl check for libltdl compiler flags\n    NUT_CHECK_LIBLTDL\nfi\n\nif test x\"${nut_with_libltdl}\" = x\"yes\" -a x\"${nut_have_libltdl}\" != x\"yes\"; then\n    AC_MSG_ERROR([libltdl not found])\nfi\n\nif test x\"${nut_with_libltdl}\" != x\"no\"; then\n    nut_with_libltdl=\"${nut_have_libltdl}\"\nfi\n\nNUT_REPORT_FEATURE([enable libltdl (Libtool dlopen abstraction) support], [${nut_with_libltdl}], [],\n\t\t\t\t\t[WITH_LIBLTDL], [Define to enable libltdl (Libtool dlopen abstraction) support])\n\ndnl Explicitly report if we are building nut-scanner or not\ndnl since it requires libltdl\nif test x\"${nut_with_libltdl}\" = x\"no\" && test x\"${nut_with_nut_scanner}\" = x\"yes\"; then\n    AC_MSG_ERROR([libltdl support was disabled or not found, but --with-nut-scanner was requested and requires it])\nfi\n\nif test x\"${nut_with_nut_scanner}\" = x\"auto\"; then\n    nut_with_nut_scanner=\"${nut_with_libltdl}\"\nfi\n\nNUT_REPORT_PROGRAM([build nut-scanner], [${nut_with_nut_scanner}], [],\n\t\t\t\t\t[WITH_NUT_SCANNER], [Define to enable nut-scanner tool support])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-cgi\n\nNUT_ARG_WITH([cgi], [build and install the CGI programs], [no])\n\ndnl ${nut_with_cgi}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_cgi}\" != \"no\"; then\n   dnl check for libgd compiler flags\n   NUT_CHECK_LIBGD\nfi\n\nif test \"${nut_with_cgi}\" = \"yes\" -a \"${nut_have_libgd}\" != \"yes\"; then\n   AC_MSG_ERROR([libgd not found, required for CGI build])\nfi\n\nif test \"${nut_with_cgi}\" != \"no\"; then\n   nut_with_cgi=\"${nut_have_libgd}\"\nfi\n\nNUT_REPORT_PROGRAM([build CGI programs], [${nut_with_cgi}], [],\n\t\t\t\t\t[WITH_CGI], [Define to enable CGI (HTTP) support])\n\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-pynut and --with-nut_monitor\n\ndnl The PYTHON*_REPORT vars also serve as flags that we have certain usable\ndnl Python interpreter versions to care about below, so we only test for\ndnl their existence once (in NUT_CHECK*PYTHON* m4 macros).\n\ndnl ${nut_with_nut_monitor}: TODO: arg values to request Python 2 gtk2,\ndnl Python 3 qt5, or both\nAC_MSG_CHECKING([if we want install NUT-Monitor desktop application])\nAC_MSG_RESULT([${nut_with_nut_monitor}])\nnut_with_nut_monitor_py2gtk2=\"\"\nnut_with_nut_monitor_py3qt5=\"\"\nnut_with_nut_monitor_desktop=\"\"\ndnl TODO: Add a way to define this path? will have app/ maybe module/ inside...\nnut_with_nut_monitor_dir=\"${datarootdir}/nut-monitor\"\n\nPYTHON_FAILED_TEST_DETAILS=\"\"\ndnl ### AC_MSG_NOTICE([nut_with_nut_monitor-1: ${nut_with_nut_monitor}])\nif test x\"${nut_with_nut_monitor}\" != xno ; then\n    dnl While we might just install for \"yes\" request, in hopes user would\n    dnl get their Python ecosystem in place later, we need some criteria to\n    dnl avoid installing it always :) Also, need to substitute the shebang.\n    if test -z \"${PYTHON}${PYTHON2}${PYTHON3}\" ; then\n        case \"${nut_with_nut_monitor}\" in\n            \"auto\") nut_with_nut_monitor=\"no\"\n                    PYTHON_FAILED_TEST_DETAILS=\"No Python 2/3 interpreter was found\"\n                ;;\n            \"yes\")  AC_MSG_ERROR([No Python 2/3 interpreter was found, required for NUT-Monitor desktop application])\n                ;;\n        esac\n    fi\nfi\ndnl ### AC_MSG_NOTICE([nut_with_nut_monitor-2: ${nut_with_nut_monitor}])\n\nif test x\"${nut_with_nut_monitor}\" != xno ; then\n    dnl Note: no double-quoting for use, the command string may be multi-token\n    dnl HACK NOTE: Here we redirect outputs to \"&5\" which is autoconf stream\n    dnl for \"config.log\" details since... forever? Still, hardcoded numbers...\n    PYTHON2_TEST_MODULES=\"re,glob,codecs,gtk,gtk.glade,gobject,ConfigParser\"\n    PYTHON3_TEST_MODULES=\"re,glob,codecs,PyQt5.uic,configparser\"\n    if test -n \"${PYTHON2_VERSION_INFO_REPORT}\" ; then\n        AC_MSG_CHECKING([if we have Python2 prerequisites for NUT-Monitor desktop application])\n        if ${PYTHON2} -c \"import ${PYTHON2_TEST_MODULES}\" 1>&5 2>&5 \\\n        ; then\n            nut_with_nut_monitor_py2gtk2=\"yes\"\n            AC_MSG_RESULT([yes])\n        else\n            AC_MSG_RESULT([no])\n            PYTHON_FAILED_TEST_DETAILS=\"Missing some or all of these Python2 modules: '${PYTHON2_TEST_MODULES}'\"\n        fi\n    fi\n\n    if test -n \"${PYTHON3_VERSION_INFO_REPORT}\" ; then\n        AC_MSG_CHECKING([if we have Python3 prerequisites for NUT-Monitor desktop application])\n        if ${PYTHON3} -c \"import ${PYTHON3_TEST_MODULES}\" 1>&5 2>&5 \\\n        ; then\n            nut_with_nut_monitor_py3qt5=\"yes\"\n            AC_MSG_RESULT([yes])\n        else\n            AC_MSG_RESULT([no])\n            if test -n \"${PYTHON_FAILED_TEST_DETAILS}\" ; then\n                PYTHON_FAILED_TEST_DETAILS=\"${PYTHON_FAILED_TEST_DETAILS} and some or all of these Python3 modules: '${PYTHON3_TEST_MODULES}'\"\n            else\n                PYTHON_FAILED_TEST_DETAILS=\"Missing some or all of these Python3 modules: '${PYTHON3_TEST_MODULES}'\"\n            fi\n        fi\n    fi\n\n    dnl Fall back to default interpreter\n    if test -z \"${nut_with_nut_monitor_py2gtk2}${nut_with_nut_monitor_py3qt5}\" \\\n    && test -n \"${PYTHON_VERSION_INFO_REPORT}\" \\\n    && test x\"${PYTHON_VERSION_INFO_REPORT}\" != x\"${PYTHON3_VERSION_INFO_REPORT}\" \\\n    && test x\"${PYTHON_VERSION_INFO_REPORT}\" != x\"${PYTHON2_VERSION_INFO_REPORT}\" \\\n    ; then\n        AC_MSG_CHECKING([if we have Python3 prerequisites for NUT-Monitor desktop application in default Python])\n        if ${PYTHON} -c \"import ${PYTHON3_TEST_MODULES}\" 1>&5 2>&5 \\\n        ; then\n            nut_with_nut_monitor_py3qt5=\"yes\"\n            AC_MSG_RESULT([yes])\n        else\n            AC_MSG_RESULT([no])\n            if test -n \"${PYTHON_FAILED_TEST_DETAILS}\" ; then\n                PYTHON_FAILED_TEST_DETAILS=\"${PYTHON_FAILED_TEST_DETAILS} and some or all of these Python3 modules in default Python: '${PYTHON3_TEST_MODULES}'\"\n            else\n                PYTHON_FAILED_TEST_DETAILS=\"Missing some or all of these Python3 modules in default Python: '${PYTHON3_TEST_MODULES}'\"\n            fi\n        fi\n\n        AC_MSG_CHECKING([if we have Python2 prerequisites for NUT-Monitor desktop application in default Python])\n        if ${PYTHON} -c \"import ${PYTHON2_TEST_MODULES}\" 1>&5 2>&5 \\\n        ; then\n            nut_with_nut_monitor_py2gtk2=\"yes\"\n            PYTHON_FAILED_TEST_DETAILS=\"\"\n            AC_MSG_RESULT([yes])\n        else\n            AC_MSG_RESULT([no])\n            if test -n \"${PYTHON_FAILED_TEST_DETAILS}\" ; then\n                PYTHON_FAILED_TEST_DETAILS=\"${PYTHON_FAILED_TEST_DETAILS} and some or all of these Python2 modules in default Python: '${PYTHON2_TEST_MODULES}'\"\n            else\n                PYTHON_FAILED_TEST_DETAILS=\"Missing some or all of these Python2 modules in default Python: '${PYTHON2_TEST_MODULES}'\"\n            fi\n        fi\n    fi\n\n    dnl ### AC_MSG_NOTICE([nut_with_nut_monitor-3: ${nut_with_nut_monitor}])\n    dnl ### AC_MSG_NOTICE([nut_with_nut_monitor_py2gtk2: ${nut_with_nut_monitor_py2gtk2}])\n    dnl ### AC_MSG_NOTICE([nut_with_nut_monitor_py3qt5: ${nut_with_nut_monitor_py3qt5}])\n    dnl Can we satisfy any NUT-Monitor installation request?\n    if test -n \"${nut_with_nut_monitor_py2gtk2}${nut_with_nut_monitor_py3qt5}\" ; then\n        case \"${nut_with_nut_monitor}\" in\n            \"auto\") nut_with_nut_monitor=\"yes\" ;;\n        esac\n    else\n        case \"${nut_with_nut_monitor}\" in\n            \"auto\") nut_with_nut_monitor=\"no\" ;;\n            \"yes\")\n                AC_MSG_ERROR([No Python 2/3 interpreter with needed modules was found, as required for NUT-Monitor desktop application: ${PYTHON_FAILED_TEST_DETAILS}])\n                ;;\n        esac\n    fi\nfi\n\nAC_MSG_CHECKING([if we can and should install NUT-Monitor desktop application])\ndnl ### AC_MSG_NOTICE([nut_with_nut_monitor-4: ${nut_with_nut_monitor}])\ncase \"${nut_with_nut_monitor}\" in\n    \"no\") if test -n \"${PYTHON_FAILED_TEST_DETAILS}\" ; then\n            AC_MSG_RESULT([${nut_with_nut_monitor}: ${PYTHON_FAILED_TEST_DETAILS}])\n        else\n            AC_MSG_RESULT([${nut_with_nut_monitor}])\n        fi\n        ;;\n    *) AC_MSG_RESULT([${nut_with_nut_monitor}]) ;;\nesac\n\ndnl ### AC_MSG_NOTICE([nut_with_nut_monitor-5: ${nut_with_nut_monitor}])\nif test x\"${nut_with_nut_monitor}\" != xno ; then\n    if (command -v desktop-file-install || which desktop-file-install) >/dev/null 2>/dev/null ; then\n        case \"${nut_with_nut_monitor}\" in\n            \"auto\"|\"yes\") nut_with_nut_monitor_desktop=\"desktop-file-install\" ;;\n        esac\n    else\n        case \"${nut_with_nut_monitor}\" in\n            \"yes\")  AC_MSG_WARN([Current OS does not seem to provide desktop-file-install])\n                nut_with_nut_monitor_desktop=\"install\"\n                ;;\n            \"auto\") nut_with_nut_monitor_desktop=\"install\" ;;\n        esac\n    fi\nfi\ndnl ### AC_MSG_NOTICE([nut_with_nut_monitor-6: ${nut_with_nut_monitor}])\n\ndnl Check if we can use distributed or fallback telnetlib module for PyNUTClient\nnut_have_telnetlib_py=\"\"\nnut_have_telnetlib_py2=\"\"\nnut_have_telnetlib_py3=\"\"\nif test x\"${nut_with_pynut}\" != xno \\\n    -a -n \"${PYTHON}${PYTHON2}${PYTHON3}\" \\\n; then\n    if test -n \"${PYTHON2_VERSION_INFO_REPORT}\" ; then\n        AC_MSG_CHECKING([if we can use stock Python2 telnetlib module provided with interpreter ${PYTHON2}])\n        if ${PYTHON2} -c \"import telnetlib\" \\\n        ; then\n            nut_have_telnetlib_py2=\"yes\"\n        else\n            nut_have_telnetlib_py2=\"no\"\n        fi\n        AC_MSG_RESULT([${nut_have_telnetlib_py2}])\n    fi\n\n    if test -n \"${PYTHON3_VERSION_INFO_REPORT}\" ; then\n        AC_MSG_CHECKING([if we can use stock Python3 telnetlib module for PyNUTClient provided with interpreter ${PYTHON3} (note for warnings from Python 3.11 and beyond: we have a fallback nut_telnetlib module just in case)])\n        if ${PYTHON3} -c \"import telnetlib\" \\\n        ; then\n            nut_have_telnetlib_py3=\"yes\"\n        else\n            nut_have_telnetlib_py3=\"no\"\n        fi\n        AC_MSG_RESULT([${nut_have_telnetlib_py3}])\n\n        if test x\"${nut_have_telnetlib_py3}\" = x\"no\" ; then\n            dnl We have a stashed copy from Python 3.10, so\n            dnl this line essentially checks for presence of\n            dnl a usable interpreter implementation compatible\n            dnl with Python 3.x syntax.\n            AC_MSG_CHECKING([if we can use fallback Python3 nut_telnetlib module for PyNUTClient])\n            if (cd \"${srcdir}\"/scripts/python/module && ${PYTHON3} -c \"import nut_telnetlib as telnetlib\") \\\n            ; then\n                nut_have_telnetlib_py3=\"yes\"\n            fi\n            AC_MSG_RESULT([${nut_have_telnetlib_py3}])\n        fi\n    fi\n\n    dnl Test same-ness of pythons with sys.version also?\n    if test -n \"${PYTHON_VERSION_INFO_REPORT}\" \\\n    && test x\"${PYTHON_VERSION_INFO_REPORT}\" != x\"${PYTHON3_VERSION_INFO_REPORT}\" \\\n    && test x\"${PYTHON_VERSION_INFO_REPORT}\" != x\"${PYTHON2_VERSION_INFO_REPORT}\" \\\n    ; then\n        AC_MSG_CHECKING([if we can use stock Python telnetlib module for PyNUTClient provided with interpreter ${PYTHON} (note for warnings from Python 3.11 and beyond: we have a fallback nut_telnetlib module just in case)])\n        if ${PYTHON} -c \"import telnetlib\" \\\n        ; then\n            nut_have_telnetlib_py=\"yes\"\n        else\n            nut_have_telnetlib_py=\"no\"\n        fi\n        AC_MSG_RESULT([${nut_have_telnetlib_py}])\n\n        if test x\"${nut_have_telnetlib_py}\" = x\"no\" ; then\n            dnl See comments above\n            AC_MSG_CHECKING([if we can use fallback Python nut_telnetlib module for PyNUTClient])\n            if (cd \"${srcdir}\"/scripts/python/module && ${PYTHON} -c \"import nut_telnetlib as telnetlib\") \\\n            ; then\n                nut_have_telnetlib_py=\"yes\"\n            fi\n            AC_MSG_RESULT([${nut_have_telnetlib_py}])\n        fi\n    fi\nfi\n\ndnl ${nut_with_pynut}: TODO: arg values to request Python 2, 3 or both\ndnl Note that per block above, nut_have_telnetlib_py* values are definitive\ndnl if checked, or empty if skipped (no such Python, not nut_with_pynut, etc.)\nAC_MSG_CHECKING([if we can and should install PyNUT module])\nnut_with_pynut_py=\"\"\nnut_with_pynut_py2=\"\"\nnut_with_pynut_py3=\"\"\nif test x\"${nut_with_pynut}\" != xno \\\n    -a -n \"${PYTHON}${PYTHON2}${PYTHON3}\" \\\n; then\n    if test x\"${nut_have_telnetlib_py2}\" = x\"yes\" ; then\n        nut_with_pynut_py2=\"yes\"\n    fi\n\n    if test x\"${nut_have_telnetlib_py3}\" = x\"yes\" ; then\n        nut_with_pynut_py3=\"yes\"\n    fi\n\n    if test x\"${nut_have_telnetlib_py}\" = x\"yes\" ; then\n        nut_with_pynut_py=\"yes\"\n    fi\nfi\n\nif test -z \"${nut_with_pynut_py}${nut_with_pynut_py2}${nut_with_pynut_py3}\" ; then\n    dnl Not all prereqs are available...\n    case \"${nut_with_pynut}\" in\n        \"auto\"|\"app\")\n            if test \"${nut_with_nut_monitor}\" = yes ; then\n                AC_MSG_ERROR([Prerequisites for PyNUT not found, can't install as required for NUT-Monitor desktop application])\n            else\n                nut_with_pynut=\"no\"\n            fi\n            ;;\n        \"yes\")\n            AC_MSG_ERROR([Prerequisites for PyNUT not found, can't install as required])\n            ;;\n    esac\nfi\n\nif test x\"${nut_with_pynut}\" != xno ; then\n    if test -n \"${PYTHON_SITE_PACKAGES}${PYTHON2_SITE_PACKAGES}${PYTHON3_SITE_PACKAGES}\" \\\n    ; then\n        dnl retain \"app\" if requested by caller\n        case \"${nut_with_pynut}\" in\n            \"auto\")\n                nut_with_pynut=\"yes\"\n                ;;\n        esac\n    else\n        case \"${nut_with_pynut}\" in\n            \"auto\")\n                if test \"${nut_with_nut_monitor}\" = yes -o \"${nut_with_nut_monitor}\" = force ; then\n                    nut_with_pynut=\"app\"\n                else\n                    nut_with_pynut=\"no\"\n                fi\n                ;;\n            \"yes\") dnl Note: this would die for --with-nut_monitor=yes but no site location\n                if test \"${nut_with_nut_monitor}\" = yes -o \"${nut_with_nut_monitor}\" = force ; then\n                    nut_with_pynut=\"app\"\n                else\n                    AC_MSG_ERROR([Python interpreter and/or its site-packages location not found, but required for PyNUT])\n                fi\n                ;;\n        esac\n    fi\nfi\nAC_MSG_RESULT([${nut_with_pynut}])\n\ndnl Note: do not move up to before pynut processing\nif test \"${nut_with_nut_monitor}\" = force ; then\n    AC_MSG_NOTICE([overriding nut_with_nut_monitor=yes because caller forced it])\n    nut_with_nut_monitor=yes\n    nut_with_nut_monitor_py2gtk2=yes\n    nut_with_nut_monitor_py3qt5=yes\nfi\n\nif test \"${nut_with_pynut}\" = force ; then\n    AC_MSG_NOTICE([overriding nut_with_pynut=yes because caller forced it])\n    if test \"${nut_with_nut_monitor}\" = yes ; then\n        nut_with_pynut=app\n    else\n        nut_with_pynut=yes\n    fi\nfi\n\nNUT_REPORT_PROGRAM([install NUT-Monitor desktop application], [${nut_with_nut_monitor}], [],\n\t\t\t\t\t[WITH_NUT_MONITOR], [Define to enable NUT-Monitor desktop application installation])\n\nNUT_REPORT_PROGRAM([install PyNUT binding module], [${nut_with_pynut}], [],\n\t\t\t\t\t[WITH_PYNUT], [Define to enable PyNUT module installation])\n\ndnl One or both of these may be installed:\nAM_CONDITIONAL(WITH_NUT_MONITOR, test \"${nut_with_nut_monitor}\" = \"yes\" && test \"${nut_with_nut_monitor_py2gtk2}\" = \"yes\" -o \"${nut_with_nut_monitor_py3qt5}\" = \"yes\")\nAM_CONDITIONAL(WITH_NUT_MONITOR_PY2GTK2, test \"${nut_with_nut_monitor_py2gtk2}\" = \"yes\")\nAM_CONDITIONAL(WITH_NUT_MONITOR_PY3QT5, test \"${nut_with_nut_monitor_py3qt5}\" = \"yes\")\ndnl Install PyNUT as a globally usable module, or just as app internals?\nAM_CONDITIONAL(WITH_PYNUT_PY,  test \"${nut_with_pynut_py}\" = \"yes\"  -a \"${nut_with_pynut}\" = yes)\nAM_CONDITIONAL(WITH_PYNUT_PY2, test \"${nut_with_pynut_py2}\" = \"yes\" -a \"${nut_with_pynut}\" = yes)\nAM_CONDITIONAL(WITH_PYNUT_PY3, test \"${nut_with_pynut_py3}\" = \"yes\" -a \"${nut_with_pynut}\" = yes)\nAM_CONDITIONAL(WITH_PYNUT_APP, test \"${nut_with_pynut}\" = \"app\")\n\nAC_SUBST([nut_with_nut_monitor_dir], [${nut_with_nut_monitor_dir}])\nAC_SUBST([nut_with_nut_monitor_py2gtk2], [${nut_with_nut_monitor_py2gtk2}])\nAC_SUBST([nut_with_nut_monitor_py3qt5], [${nut_with_nut_monitor_py3qt5}])\nAC_SUBST([nut_with_nut_monitor_desktop], [${nut_with_nut_monitor_desktop}])\nAC_SUBST([nut_with_nut_monitor], [${nut_with_nut_monitor}])\nAC_SUBST([nut_with_pynut], [${nut_with_pynut}])\nAC_SUBST([nut_with_pynut_py], [${nut_with_pynut_py}])\nAC_SUBST([nut_with_pynut_py2], [${nut_with_pynut_py2}])\nAC_SUBST([nut_with_pynut_py3], [${nut_with_pynut_py3}])\n\ndnl MacOS Darwin has a problem with script shebangs, and tends to run anything\ndnl with shell. On the upside, it has no limit on length or amount of tokens\ndnl in the shebang line.\ndnl https://github.com/NixOS/nixpkgs/issues/65351/\nAS_CASE([${target_os}],\n\t[*darwin*], [\n\t\tAS_IF([test -n \"${PYTHON}\"  -a x\"${PYTHON}\"  != xno], [ PYTHON=\" /usr/bin/env ${PYTHON}\"])\n\t\tAS_IF([test -n \"${PYTHON2}\" -a x\"${PYTHON2}\" != xno], [PYTHON2=\" /usr/bin/env ${PYTHON2}\"])\n\t\tAS_IF([test -n \"${PYTHON3}\" -a x\"${PYTHON3}\" != xno], [PYTHON3=\" /usr/bin/env ${PYTHON3}\"])\n\t\t]\n)\n\nAS_IF([test \"${nut_with_nut_monitor}\" != no -o \"${nut_with_pynut}\" != no], [\n    NUT_REPORT([use default  Python  interpreter],   [${PYTHON}])\n    NUT_REPORT([use specific Python2 interpreter],   [${PYTHON2}])\n    NUT_REPORT([use specific Python3 interpreter],   [${PYTHON3}])\n\n    NUT_REPORT_PATH_INTEGRATIONS([Default  Python  interpreter site-packages],\n        [${PYTHON_SITE_PACKAGES}])\n\n    NUT_REPORT_PATH_INTEGRATIONS([Specific Python2 interpreter site-packages],\n        [${PYTHON2_SITE_PACKAGES}])\n\n    NUT_REPORT_PATH_INTEGRATIONS([Specific Python3 interpreter site-packages],\n        [${PYTHON3_SITE_PACKAGES}])\n        dnl # Python site-packages installation path for specific Python3 interpreter\n])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --enable-cppcheck\n\ndnl Currently this is experimental; maybe change default to auto in the future\ndnl At that point, see also defaults in ci_build.sh then (to avoid the workload\ndnl unless desired).\nNUT_ARG_ENABLE([cppcheck], [Run a cppcheck on the codebase among checks], [no])\nNUT_CHECK_CPPCHECK\n\nAC_MSG_CHECKING(whether to run cppcheck among default make check target)\ncase \"${nut_enable_cppcheck}\" in\n\tyes) if test \"${nut_have_cppcheck}\" = \"no\" ; then\n\t        AC_MSG_ERROR([Requested to --enable-cppcheck but did not find a good one])\n\t     fi\n\t     WITH_CPPCHECK=yes\n\t     ;;\n\tno)  WITH_CPPCHECK=no ;;\n\tauto) if test \"${nut_have_cppcheck}\" = \"yes\" ; then\n\t        WITH_CPPCHECK=yes\n\t    else\n\t        WITH_CPPCHECK=no\n\t    fi\n\t    ;;\nesac\nAC_MSG_RESULT([${WITH_CPPCHECK}])\n\nAM_CONDITIONAL(WITH_CPPCHECK, test \"${WITH_CPPCHECK}\" = \"yes\")\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --enable-check-NIT\n\nAC_MSG_CHECKING(whether to run NIT among default make check target)\nnut_enable_check_NIT=\"no\"\nAC_ARG_ENABLE([check-NIT],\n\tAS_HELP_STRING([--enable-check-NIT], [Run check-NIT among default checks (no)]),\n[\n\tcase \"${enableval}\" in\n\tno)\n\t\tAC_MSG_RESULT(no)\n\t\t;;\n\t*)\n\t\tAC_MSG_RESULT(yes)\n\t\tnut_enable_check_NIT=\"yes\"\n\t\t;;\n\tesac\n], [\n\tAC_MSG_RESULT(no)\n])\n\nAM_CONDITIONAL(WITH_CHECK_NIT, test \"${nut_enable_check_NIT}\" = \"yes\")\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --enable-spellcheck\n\nNUT_CHECK_ASPELL\nNUT_ARG_ENABLE([spellcheck], [Run spellcheck among default checks], [auto])\n\nAC_MSG_CHECKING(whether to run spellcheck among default make check target)\ncase \"${nut_enable_spellcheck}\" in\n\tyes) if test \"${nut_have_aspell}\" = \"no\" ; then\n\t        AC_MSG_ERROR([Requested to --enable-spellcheck but did not find a good one])\n\t     fi\n\t     WITH_SPELLCHECK=yes\n\t     ;;\n\tno)  WITH_SPELLCHECK=no ;;\n\tauto) if test \"${nut_have_aspell}\" = \"yes\" ; then\n\t        WITH_SPELLCHECK=yes\n\t    else\n\t        WITH_SPELLCHECK=no\n\t    fi\n\t    ;;\nesac\nAC_MSG_RESULT([${WITH_SPELLCHECK}])\n\nAM_CONDITIONAL(WITH_SPELLCHECK, test \"${WITH_SPELLCHECK}\" = \"yes\")\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-doc\n\ndnl Always check for AsciiDoc prerequisites, since even if --with-doc\ndnl is set to 'no', we may still want to build some doc targets manually\ndnl (so enable the Makefile recipes for those targets if tools are available)\nNUT_CHECK_ASCIIDOC\n\nNUT_REPORT_FEATURE([build and install documentation], [${nut_with_doc}], [],\n\t\t\t\t\t[WITH_ASCIIDOC], [Define to enable Asciidoc support])\n\nDOC_INSTALL_DISTED_MANS=no\n\ncase \"${nut_with_doc}\" in\n\tyes|all|all=yes)\n\t\tnut_doc_build_list=\"man html-single html-chunked pdf\"\n\t\t;;\n\tauto|all=auto)\n\t\tnut_doc_build_list=\"man=auto html-single=auto html-chunked=auto pdf=auto\"\n\t\t;;\n\tskip|all=skip)\n\t\tnut_doc_build_list=\"man=skip html-single=skip html-chunked=skip pdf=skip\"\n\t\t;;\n\tdist-auto) # Experimental, currently only for MANs: prefer disted files if present, auto otherwise\n\t\tnut_doc_build_list=\"man=dist-auto html-single=dist-auto html-chunked=dist-auto pdf=dist-auto\"\n\t\t;;\n\tno|all=no)\n\t\tnut_doc_build_list=\"\"\n\t\t;;\ndnl If user passed --with-doc='' they they want nothing, right?\n\t\"\")\n\t\tnut_doc_build_list=\"\"\n\t\tAC_MSG_NOTICE([Got explicit empty list of document formats to build; nothing will be generated])\n\t\t;;\n\t*)\n\t\tnut_doc_build_list=\"`echo ${nut_with_doc} | sed 's/,/ /g'`\"\n\t\tAC_MSG_NOTICE([Got explicit list of document formats to build or not: ${nut_doc_build_list}; formats not listed will be silently skipped])\n\t\t;;\nesac\n\nif test -z \"${abs_srcdir}\" ; then\n\tcase \"${srcdir}\" in\n\t\t/*) abs_srcdir=\"${srcdir}\";;\n\t\t\"\") AC_MSG_ERROR([Can not detect 'srcdir']) ;;\n\t\t*)  abs_srcdir=\"$(cd \"${srcdir}\" && pwd)\" || AC_MSG_ERROR([Can not detect 'srcdir']) ;;\n\tesac\nfi\nDOCTESTDIR=\"$(mktemp -d configure-test.docbuild.$$.XXXXXXX)\" && \\\nDOCTESTDIR=\"$(cd \"$DOCTESTDIR\" && pwd)\"\n\ndnl Note: Do not cover ${nut_doc_build_list} in braces or quotes here,\ndnl to ensure that it is processed as several space-separated tokens\nfor nut_doc_build_target in $nut_doc_build_list; do\n\tcase \"${nut_doc_build_target}\" in\n\t*=*=*)\trm -rf \"${DOCTESTDIR}\"\n\t\tAC_MSG_ERROR([Invalid documentation format option: ${nut_doc_build_target}]) ;;\n\t*=*)\n\t\tnut_doc_build_target_base=\"`echo \"${nut_doc_build_target}\" | sed 's,=.*$,,'`\"\n\t\tnut_doc_build_target_flag=\"`echo \"${nut_doc_build_target}\" | sed 's,^.*=,,'`\"\n\t\t;;\n\t*)\n\t\tnut_doc_build_target_base=\"${nut_doc_build_target}\"\n\t\tnut_doc_build_target_flag=\"yes\"\n\t\t;;\n\tesac\n\tcase \"${nut_doc_build_target_flag}\" in\n\tyes|no|auto|skip|dist-auto) ;;\n\t\"\") nut_doc_build_target_flag=\"yes\" ;;\n\t*)\trm -rf \"${DOCTESTDIR}\"\n\t\tAC_MSG_ERROR([Invalid documentation format option: ${nut_doc_build_target}]) ;;\n\tesac\n\tAC_MSG_CHECKING([desire and ability to build ${nut_doc_build_target_base} documentation])\n\tAC_MSG_RESULT([${nut_doc_build_target_flag}])\n\n\tcase \"${nut_doc_build_target}\" in\n\t*=no|*=skip)\n\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t;;\n\ndnl Notes: Document options below assume either no flag value (which\ndnl by default means \"yes\"), \"yes\" which is a requirement, or \"auto\"\ndnl to detect if we can build the wanted documentation format and yet\ndnl not fail if we have no tools to generate it (so add to SKIP list).\n\n\thtml-single*)\n\t\tAC_MSG_CHECKING([if asciidoc and a2x versions can build ${nut_doc_build_target_base} (minimum required asciidoc-${ASCIIDOC_MIN_VERSION} a2x-${A2X_MIN_VERSION})])\n\t\tcan_build_doc_html_single=no\n\t\tAX_COMPARE_VERSION([${ASCIIDOC_VERSION}], [ge], [${ASCIIDOC_MIN_VERSION}], [\n\t\t\tAX_COMPARE_VERSION([${A2X_VERSION}], [ge], [${A2X_MIN_VERSION}], [\n\t\t\t\t( cd \"$DOCTESTDIR\" && ${A2X} --attribute=xhtml11_format --format=xhtml --xsl-file=\"${abs_srcdir}\"/docs/xhtml.xsl --destination-dir=. \"${abs_srcdir}\"/docs/asciidoc.txt && test -s asciidoc.html ) && can_build_doc_html_single=yes\n\t\t\t\trm -f \"$DOCTESTDIR\"/asciidoc*.htm*\n\t\t\t], [])\n\t\t], [])\n\t\tif test \"${can_build_doc_html_single}\" = yes ; then\n\t\t\tAC_MSG_RESULT(yes)\n\t\t\tDOC_BUILD_LIST=\"${DOC_BUILD_LIST} ${nut_doc_build_target_base}\"\n\t\telse\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tif test \"${nut_doc_build_target_flag}\" = \"yes\" ; then\n\t\t\t\tDOC_CANNOTBUILD_LIST=\"${DOC_CANNOTBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation which you requested])\n\t\t\telse\n\t\t\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\tfi\n\t\tfi\n\t\t;;\n\n\thtml-chunked*)\n\t\tAC_MSG_CHECKING([if asciidoc and a2x versions can build ${nut_doc_build_target_base} (minimum required asciidoc-${ASCIIDOC_MIN_VERSION} a2x-${A2X_MIN_VERSION})])\n\t\tcan_build_doc_html_chunked=no\n\t\tAX_COMPARE_VERSION([${ASCIIDOC_VERSION}], [ge], [${ASCIIDOC_MIN_VERSION}], [\n\t\t\tAX_COMPARE_VERSION([${A2X_VERSION}], [ge], [${A2X_MIN_VERSION}], [\n\t\t\t\t( cd \"$DOCTESTDIR\" && ${A2X} --attribute=chunked_format --format=chunked --xsl-file=\"${abs_srcdir}\"/docs/chunked.xsl --destination-dir=. \"${abs_srcdir}\"/docs/FAQ.txt && test -s FAQ.chunked/index.html ) && can_build_doc_html_chunked=yes\n\t\t\t\trm -rf \"${DOCTESTDIR}\"/FAQ*.chunked*\n\t\t\t], [])\n\t\t], [])\n\t\tif test \"${can_build_doc_html_chunked}\" = yes ; then\n\t\t\tAC_MSG_RESULT(yes)\n\t\t\tDOC_BUILD_LIST=\"${DOC_BUILD_LIST} ${nut_doc_build_target_base}\"\n\t\telse\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tif test \"${nut_doc_build_target_flag}\" = \"yes\" ; then\n\t\t\t\tDOC_CANNOTBUILD_LIST=\"${DOC_CANNOTBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation which you requested])\n\t\t\telse\n\t\t\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\tfi\n\t\tfi\n\t\t;;\n\n\tpdf*)\n\t\tAC_MSG_CHECKING([if dblatex version can build ${nut_doc_build_target_base} (minimum required ${DBLATEX_MIN_VERSION})])\n\t\tcan_build_doc_pdf=no\n\t\tcan_build_doc_pdf_nonascii_titles=no\n\t\tAX_COMPARE_VERSION([${DBLATEX_VERSION}], [ge], [${DBLATEX_MIN_VERSION}], [\n\t\t\t( cd \"$DOCTESTDIR\" && ${A2X} --format=pdf --destination-dir=. \"${abs_srcdir}\"/docs/asciidoc.txt && test -s asciidoc.pdf ) && can_build_doc_pdf=yes\n\t\t\trm -f \"${DOCTESTDIR}\"/asciidoc.pdf\n\t\t], [])\n\t\tif test \"${can_build_doc_pdf}\" = yes ; then\n\t\t\tAC_MSG_RESULT(yes)\n\t\t\tDOC_BUILD_LIST=\"${DOC_BUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\tAC_MSG_CHECKING([if dblatex can process non-ASCII section titles for PDF])\n\t\t\t( cd \"$DOCTESTDIR\" && sed -e 's/^Intro/'\"`printf '\\303\\215'`\"'ntro/' -e 's/Works in Progress/Works '\"`printf '\\303\\255'`\"'n Progress/' < \"${abs_srcdir}\"/docs/asciidoc.txt > asciidoc.tmp.txt && ${A2X} --format=pdf --destination-dir=. asciidoc.tmp.txt && test -s asciidoc.tmp.pdf ) && can_build_doc_pdf_nonascii_titles=yes\n\t\t\trm -f \"${DOCTESTDIR}\"/asciidoc.tmp.pdf\n\t\t\tAC_MSG_RESULT(${can_build_doc_pdf_nonascii_titles})\n\t\telse\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tif test \"${nut_doc_build_target_flag}\" = \"yes\" ; then\n\t\t\t\tDOC_CANNOTBUILD_LIST=\"${DOC_CANNOTBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation which you requested])\n\t\t\telse\n\t\t\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\tfi\n\t\tfi\n\t\t;;\n\n\tman*)\n\t\tdnl Experimental support for --with-doc=man=dist-auto to prefer pre-disted docs if available, below\n\t\tAC_MSG_CHECKING([if we can build ${nut_doc_build_target_base}])\n\t\tcan_build_doc_man=no\n\t\thave_disted_doc_man=no\n\t\twant_disted_doc_man=no\n\t\tif test -s \"${abs_srcdir}\"/docs/man/snmp-ups.8 ; then\n\t\t\tdnl Test that groff files exist (building from distributed tarball, not git repo)\n\t\t\thave_disted_doc_man=yes\n\t\tfi\n\t\tif test x\"${nut_doc_build_target}\" = x\"man=dist-auto\" || test \"${nut_doc_build_target_flag}\" = \"dist-auto\"; then\n\t\t\twant_disted_doc_man=yes\n\t\tfi\n\t\tif test \"${nut_have_asciidoc}\" = yes ; then\n\t\t\t( cd \"$DOCTESTDIR\" && ${A2X} --format manpage --destination-dir=. --xsltproc-opts=\"--nonet\" \"${abs_srcdir}\"/docs/man/snmp-ups.txt && test -s snmp-ups.8 ) && can_build_doc_man=yes\n\t\t\trm -f \"${DOCTESTDIR}\"/snmp-ups.8\n\t\tfi\n\t\tif test \"${want_disted_doc_man}\" = yes && test \"${have_disted_doc_man}\" = yes ; then\n\t\t\tAC_MSG_NOTICE([Requested, and can, install pre-built distributed copies of ${nut_doc_build_target_base} documentation])\n\t\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\tDOC_INSTALL_DISTED_MANS=\"yes\"\n\t\t\tdnl Avoid rebuilding existing build products due to their timestamp dependencies:\n\t\t\ttouch -r \"${abs_srcdir}\"/docs/man/Makefile.am \"${abs_srcdir}\"/docs/man/*.{1,2,3,4,5,6,7,8,9}* \"${abs_srcdir}\"/docs/man/*.{txt,xml,html,pdf} || true\n\t\telse\n\t\t\tif test \"${can_build_doc_man}\" = yes ; then\n\t\t\t\tAC_MSG_RESULT(yes)\n\t\t\t\tDOC_BUILD_LIST=\"${DOC_BUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\telse\n\t\t\t\tAC_MSG_RESULT(no)\n\t\t\t\tif test \"${nut_doc_build_target_flag}\" = \"yes\" ; then\n\t\t\t\t\tDOC_CANNOTBUILD_LIST=\"${DOC_CANNOTBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation which you requested])\n\t\t\t\telse\n\t\t\t\t\tDOC_SKIPBUILD_LIST=\"${DOC_SKIPBUILD_LIST} ${nut_doc_build_target_base}\"\n\t\t\t\t\tif test \"${nut_doc_build_target_flag}\" = \"auto\" || test \"${nut_doc_build_target_flag}\" = \"dist-auto\" ; then\n\t\t\t\t\t\tif test \"${have_disted_doc_man}\" = yes ; then\n\t\t\t\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation, but can install pre-built distributed copies])\n\t\t\t\t\t\t\tDOC_INSTALL_DISTED_MANS=\"yes\"\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tAC_MSG_WARN([Unable to build ${nut_doc_build_target_base} documentation, and unable to install pre-built distributed copies because they are absent])\n\t\t\t\t\t\tfi\n\t\t\t\t\tfi  # Other variants include \"no\", \"skip\"...\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n\t\t;;\n\n\t*)\trm -rf \"${DOCTESTDIR}\"\n\t\tAC_MSG_ERROR([--with-doc option refers to unknown documentation format: $nut_doc_build_target]) ;;\n\n\tesac\ndone\nrm -rf \"${DOCTESTDIR}\"\n\ncase \"${nut_with_doc}\" in\nauto)\n\tif test -n \"${DOC_BUILD_LIST}\"; then\n\t\tnut_with_doc=\"yes\"\n\telse\n\t\tnut_with_doc=\"no\"\n\tfi\n\t;;\nno)\n\t;;\n*)\n\tif test -n \"${DOC_CANNOTBUILD_LIST}\"; then\n\t\tAC_MSG_ERROR([Unable to build${DOC_CANNOTBUILD_LIST} documentation (check for 'no' results above)])\n\tfi\n\n\tif test -n \"${DOC_SKIPBUILD_LIST}\"; then\n\t\tAC_MSG_NOTICE([Skipping build of${DOC_SKIPBUILD_LIST} documentation (check for 'skip' results above)])\n\tfi\n\n\tif test -n \"${DOC_BUILD_LIST}\"; then\n\t\tnut_with_doc=\"yes\"\n\telse\n\t\tnut_with_doc=\"no\"\n\tfi\n\t;;\nesac\n\nAM_CONDITIONAL(WITH_PDF_NONASCII_TITLES, [test x\"$can_build_doc_pdf_nonascii_titles\" = xyes])\n\nNUT_REPORT_FEATURE([build specific documentation format(s)], [${nut_with_doc}], [${DOC_BUILD_LIST}],\n\t\t\t\t\t[WITH_DOCS], [Define to enable overall documentation generation])\n\n# To cater for less portable make's, precalculate the target list\n# for \"make check\" in \"docs/\" here...\nDOC_CHECK_LIST=\"\"\nif test \"${nut_with_doc}\" = yes ; then\n\tfor V in $DOC_BUILD_LIST ; do\n\t\tDOC_CHECK_LIST=\"$DOC_CHECK_LIST check-$V\"\n\tdone\nfi\n\nWITH_MANS=no\nSKIP_MANS=no\nif echo \"${DOC_BUILD_LIST}\" | grep -w \"man\" >/dev/null || test \"${DOC_INSTALL_DISTED_MANS}\" = \"yes\" ; then\n\tWITH_MANS=yes\nfi\nif echo \"${DOC_SKIPBUILD_LIST}\" | grep -w \"man\" >/dev/null ; then\n\tSKIP_MANS=yes\nfi\ndnl Generally WITH_MANS=no is intentionally fatal for \"make distcheck\"\ndnl But some larger distcheck suites check mans once and then focus on\ndnl other aspects of the project, so they can explicitly skip docs (or\ndnl just mans) instead. Note that for WITH_MANS=yes the SKIP_MANS value\ndnl is effectively ignored by docs/man/Makefile.am at this time.\nAM_CONDITIONAL(WITH_MANS, test \"${WITH_MANS}\" = \"yes\")\nAM_CONDITIONAL(SKIP_MANS, test \"${SKIP_MANS}\" = \"yes\")\nAM_CONDITIONAL(DOC_INSTALL_DISTED_MANS, test \"${DOC_INSTALL_DISTED_MANS}\" = \"yes\")\n\nWITH_HTML_SINGLE=no\nSKIP_HTML_SINGLE=no\nif echo \"${DOC_BUILD_LIST}\" | grep -w \"html-single\" >/dev/null ; then\n\tWITH_HTML_SINGLE=yes\nfi\nif echo \"${DOC_SKIPBUILD_LIST}\" | grep -w \"html-single\" >/dev/null ; then\n\tSKIP_HTML_SINGLE=yes\nfi\nAM_CONDITIONAL(WITH_HTML_SINGLE, test \"${WITH_HTML_SINGLE}\" = \"yes\")\nAM_CONDITIONAL(SKIP_HTML_SINGLE, test \"${SKIP_HTML_SINGLE}\" = \"yes\")\n\nWITH_HTML_CHUNKED=no\nSKIP_HTML_CHUNKED=no\nif echo \"${DOC_BUILD_LIST}\" | grep -w \"html-chunked\" >/dev/null ; then\n\tWITH_HTML_CHUNKED=yes\nfi\nif echo \"${DOC_SKIPBUILD_LIST}\" | grep -w \"html-chunked\" >/dev/null ; then\n\tSKIP_HTML_CHUNKED=yes\nfi\nAM_CONDITIONAL(WITH_HTML_CHUNKED, test \"${WITH_HTML_CHUNKED}\" = \"yes\")\nAM_CONDITIONAL(SKIP_HTML_CHUNKED, test \"${SKIP_HTML_CHUNKED}\" = \"yes\")\n\nWITH_PDFS=no\nSKIP_PDFS=no\nif echo \"${DOC_BUILD_LIST}\" | grep -w \"pdf\" >/dev/null ; then\n\tWITH_PDFS=yes\nfi\nif echo \"${DOC_SKIPBUILD_LIST}\" | grep -w \"pdf\" >/dev/null ; then\n\tSKIP_PDFS=yes\nfi\nAM_CONDITIONAL(WITH_PDFS, test \"${WITH_PDFS}\" = \"yes\")\nAM_CONDITIONAL(SKIP_PDFS, test \"${SKIP_PDFS}\" = \"yes\")\n\ndnl NOTE: Sections may be strings, not pure numbers, on some platforms:\nMAN_SECTION_API=\"${nut_with_docs_man_section_api}\"\nMAN_SECTION_CFG=\"${nut_with_docs_man_section_cfg}\"\nMAN_SECTION_CMD_SYS=\"${nut_with_docs_man_section_cmd_sys}\"\nMAN_SECTION_CMD_USR=\"${nut_with_docs_man_section_cmd_usr}\"\n\nMAN_SECTION_API_BASE=\"`echo \"${MAN_SECTION_API}\" | sed 's/^\\(@<:@0-9@:>@*\\)@<:@^0-9@:>@.*$/\\1/'`\"\nMAN_SECTION_CFG_BASE=\"`echo \"${MAN_SECTION_CFG}\" | sed 's/^\\(@<:@0-9@:>@*\\)@<:@^0-9@:>@.*$/\\1/'`\"\nMAN_SECTION_CMD_SYS_BASE=\"`echo \"${MAN_SECTION_CMD_SYS}\" | sed 's/^\\(@<:@0-9@:>@*\\)@<:@^0-9@:>@.*$/\\1/'`\"\nMAN_SECTION_CMD_USR_BASE=\"`echo \"${MAN_SECTION_CMD_USR}\" | sed 's/^\\(@<:@0-9@:>@*\\)@<:@^0-9@:>@.*$/\\1/'`\"\n\nAC_DEFINE_UNQUOTED([MAN_SECTION_API], [\"${MAN_SECTION_API}\"], [man page section for library APIs])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CFG], [\"${MAN_SECTION_CFG}\"], [man page section for configuration files])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CMD_SYS], [\"${MAN_SECTION_CMD_SYS}\"], [man page section for system management commands])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CMD_USR], [\"${MAN_SECTION_CMD_USR}\"], [man page section for user commands])\n\nAC_DEFINE_UNQUOTED([MAN_SECTION_API_BASE], [\"${MAN_SECTION_API_BASE}\"], [base (number only) man page section for library APIs])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CFG_BASE], [\"${MAN_SECTION_CFG_BASE}\"], [base (number only) man page section for configuration files])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CMD_SYS_BASE], [\"${MAN_SECTION_CMD_SYS_BASE}\"], [base (number only) man page section for system management commands])\nAC_DEFINE_UNQUOTED([MAN_SECTION_CMD_USR_BASE], [\"${MAN_SECTION_CMD_USR_BASE}\"], [base (number only) man page section for user commands])\n\nAC_SUBST(MAN_SECTION_API)\nAC_SUBST(MAN_SECTION_CFG)\nAC_SUBST(MAN_SECTION_CMD_SYS)\nAC_SUBST(MAN_SECTION_CMD_USR)\n\nAC_SUBST(MAN_SECTION_API_BASE)\nAC_SUBST(MAN_SECTION_CFG_BASE)\nAC_SUBST(MAN_SECTION_CMD_SYS_BASE)\nAC_SUBST(MAN_SECTION_CMD_USR_BASE)\n\ndnl ----------------------------------------------------------------------\ndnl checks related to --with-dev\n\ndnl We only init libtool there to allow AC_DISABLE_STATIC\nif ( test \"${GCC}\" = \"yes\" )\nthen\n\tdnl # Avoid new compilers' warnings/errors about libtool distro flaws in this test like:\n\tdnl #   error: ISO C forbids conversion of function pointer to object pointer type [-Werror=pedantic]\n\tdnl #   {\"nm_test_func\", (void *) &nm_test_func},\n\tdnl # or ones about LTO (-flto -fno-common) as discussed and suggested\n\tdnl # in https://www.mail-archive.com/libtool@gnu.org/msg14037.html -\n\tdnl # all leading to undefined \"global_symbol_pipe\" in the generated\n\tdnl # libtool script, and resulting in errors like `... | | ...` below :\n\tdnl # libtool: link: /usr/bin/nm -B .libs/upsclient.o \\\n\tdnl #   ../common/.libs/libcommonclient.a |  | /usr/bin/sed 's/.* //' \\\n\tdnl #   | sort | uniq > .libs/libupsclient.exp\n\tdnl # ../libtool: syntax error: `|' unexpected\n\n\tCFLAGS_SAVED_NOPEDANTIC=\"$CFLAGS\"\n\tAS_CASE([\"${CFLAGS}\"],[*\"-pedantic\"*],[CFLAGS=\"${CFLAGS} -Wno-pedantic\"])\n\tAS_CASE([\"${CFLAGS}\"],[*\"-Werror\"*],[CFLAGS=\"${CFLAGS} -Wno-error\"])\n\tAS_CASE([\"${CFLAGS}\"],[*\"-flto\"*],[CFLAGS=\"${CFLAGS} -ffat-lto-objects\"])\nfi\n\ndnl See https://www.gnu.org/software/libtool/manual/html_node/LT_005fINIT.html\ndnl #OBSOLETED:# LT_INIT and AC_PROG_LIBTOOL\n\ndnl # Hack around the libtool script: as of version 58 (current in 2021),\ndnl # they use code like below to detect library paths:\ndnl #   if test yes = \"$GCC\"; then ... lt_search_path_spec=`$CC -print-search-dirs | ...\ndnl # which explodes when non-default architecture is used for the build,\ndnl # where e.g. \"CC=gcc\" and \"CFLAGS=-m32\" on a 64-bit capable system.\ndnl # And similarly for compilation-checks to link third-party libraries.\nSAVED_GCC=\"$GCC\"\nSAVED_CC=\"$CC\"\nif ( test \"${GCC}\" = \"yes\" )\nthen\n    case \"$CFLAGS$LDFLAGS\" in\n        *-m32*) CC=\"$CC -m32\" ;;\n        *-m64*) CC=\"$CC -m64\" ;;\n    esac\nfi\nm4_ifdef([AM_PROG_AR], [AM_PROG_AR])\nLT_INIT\nAC_SUBST([LIBTOOL_DEPS])\nGCC=\"$SAVED_GCC\"\nCC=\"$SAVED_CC\"\n\nif ( test \"${GCC}\" = \"yes\" )\nthen\n\tCFLAGS=\"$CFLAGS_SAVED_NOPEDANTIC\"\nfi\n\ndnl ${nut_with_dev}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_dev}\" != \"no\"; then\n  nut_with_dev=\"yes\"\nelse\n  AC_DISABLE_STATIC\nfi\nAM_CONDITIONAL(WITH_DEV, test \"${nut_with_dev}\" = \"yes\")\nNUT_REPORT_FEATURE([build and install the development files], [${nut_with_dev}], [],\n\t\t\t\t\t[WITH_DEV], [Define to enable development files support])\n\ndnl ----------------------------------------------------------------------\ndnl checks related to MS Windows support (MingW)\n\nAC_CHECK_TOOL([WINDMC], [windmc], [none])\nAC_CHECK_TOOL([WINDRES], [windres], [none])\n\nif test \"x$WINDMC\" != \"xnone\" -a \"x$WINDRES\" != \"xnone\" ; then\n\tnut_have_mingw_resgen=\"yes\"\nfi\n\nAM_CONDITIONAL([HAVE_MINGW_RESGEN], [test \"${nut_have_mingw_resgen}\" = \"yes\"])\n\ndnl Also define a generic automake condition for general Windows compilation:\ndnl do we at least have the header file(s) we require for the platform\ndnl (more files may be optional e.g. for different generations of networking)\ndnl Could just use ..._COND_IF([HAVE_WINDOWS_H],... but it is not present in\ndnl some older versions of autotools. (Note autoconf expands in comments too).\nAS_IF([test \"x$nut_cv_header_windows_h\" = xyes],\n\t[AM_CONDITIONAL([HAVE_WINDOWS], [test \"${nut_have_mingw_resgen}\" = \"yes\"])],\n\t[AM_CONDITIONAL([HAVE_WINDOWS], [false])]\n\t)\n\n\ndnl ----------------------------------------------------------------------\n\nPREFIX=\"${prefix}\"\nNUT_REPORT_SETTING_PATH([Default installation prefix path],\n    PREFIX, \"${prefix}\", [Default installation prefix path])\n\nAC_MSG_CHECKING(if requested state path)\nAC_ARG_WITH(statepath,\n\tAS_HELP_STRING([--with-statepath=PATH], [path for ups state files (${STATEPATH}, typically /var/state/ups)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-statepath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tSTATEPATH=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\nNUT_REPORT_SETTING_PATH([State file path],\n    STATEPATH, \"${STATEPATH}\", [Path for UPS driver state files])\n\ndnl ---------------------------------------------------------------------\ndnl The 'alt pid path' is used by the drivers (via main.c) and upsd, since\ndnl ideally they do not run as root and will not be able to write to the usual\ndnl /var/run path.  This defaults to the STATEPATH since they should be\ndnl able to write there.\ndnl\n\nAC_MSG_CHECKING(if requested alt pid path)\nAC_ARG_WITH(altpidpath,\n\tAS_HELP_STRING([--with-altpidpath=PATH], [path for NUT driver/upsd .pid files not running as root (<statepath>)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-altpidpath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tALTPIDPATH=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [\n\tALTPIDPATH=\"${STATEPATH}\"\n\tAC_MSG_RESULT([default])\n])\nNUT_REPORT_SETTING_PATH([Unprivileged PID file path],\n    ALTPIDPATH, \"${ALTPIDPATH}\", [Path for pid files of processes not running as root, such as drivers and upsd (usually STATEPATH)])\n\nAC_MSG_CHECKING(if requested pidpath)\nAC_ARG_WITH(pidpath,\n\tAS_HELP_STRING([--with-pidpath=PATH], [Path for root-owned .pid files (${PIDPATH}, typically /var/run)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-pidpath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tPIDPATH=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\nNUT_REPORT_SETTING_PATH([Privileged PID file path],\n    PIDPATH, \"${PIDPATH}\", [Path for pid files of processes running as root, such as upsmon])\n\ndnl --------------------------------------------------------------------\ndnl Legacy default was /etc/killpower, but modern distros may prefer some\ndnl temporary filesystem (no I/O storage device impact) as long as it is\ndnl mounted at least read-only late in shutdown routine. The upsmon program\ndnl writes it as root, so this may well be in /var/run or in NUT PID/state\ndnl path (if that location remains mounted in run-time OS distribution).\ndnl Ideally the filesystems with `upsmon` program and libraries it needs\ndnl also remain mounted, so `upsmon -K` may be queried late in shutdown -\ndnl and we can avoid hardcoding such paths into those shutdown hooks.\ndnl Note that upsmon removes this file early in any daemonized start-up.\nAC_MSG_CHECKING(if requested default upsmon POWERDOWNFLAG path)\nAC_ARG_WITH(powerdownflag,\n\tAS_HELP_STRING([--with-powerdownflag=PATH], [default path for upsmon POWERDOWNFLAG file (${POWERDOWNFLAG}, typically /etc/killpower)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-powerdownflag - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tPOWERDOWNFLAG=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\ndnl # This should be internal detail for \"upsmon -K\" implementation,\ndnl # so not necessarily reported (reduce noise):\ndnl NUT_REPORT_SETTING_PATH([Default upsmon POWERDOWNFLAG path],\ndnl    POWERDOWNFLAG, \"${POWERDOWNFLAG}\", [Default path for upsmon POWERDOWNFLAG file])\n\ndnl ---------------------------------------------------------------------\nAC_MSG_CHECKING(if requested driver path)\nAC_ARG_WITH(drvpath,\n\tAS_HELP_STRING([--with-drvpath=PATH], [where to install UPS drivers (EPREFIX/bin)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-drvpath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tdriverexecdir=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\nconftemp=\"${driverexecdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nDRVPATH=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([Driver program path],\n    DRVPATH, \"${conftemp}\", [Default path for UPS drivers])\n\nAC_MSG_CHECKING(if requested cgi path)\nAC_ARG_WITH(cgipath,\n\tAS_HELP_STRING([--with-cgipath=PATH], [where to install CGI programs (EPREFIX/cgi-bin)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-cgipath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tcgiexecdir=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\nconftemp=\"${cgiexecdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nCGIPATH=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([CGI program path],\n    CGIPATH, \"${conftemp}\", [Default path for CGI programs])\n\nAC_MSG_CHECKING(if requested html path)\nAC_ARG_WITH(htmlpath,\n\tAS_HELP_STRING([--with-htmlpath=PATH], [where to install HTML files (PREFIX/html)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-htmlpath - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\thtmldir=\"${withval}\"\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [AC_MSG_RESULT([default])])\nconftemp=\"${htmldir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nHTMLPATH=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([HTML file path],\n    HTMLPATH, \"${conftemp}\", [Default path for HTML files (CGI templates)])\n\nAC_MSG_CHECKING(network port number)\nAC_ARG_WITH(port,\n\tAS_HELP_STRING([--with-port=PORT], [port for network communications (3493)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-port - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tPORT=\"${withval}\"\n\t\t;;\n\tesac\n], [\n\tPORT=\"3493\"\n])\nAC_DEFINE_UNQUOTED(PORT, ${PORT}, [Port for network communications])\nAC_MSG_RESULT(${PORT})\n\nAC_MSG_CHECKING(facility for syslog)\nAC_ARG_WITH(logfacility,\n\tAS_HELP_STRING([--with-logfacility=FACILITY], [facility for log messages (LOG_DAEMON)]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-logfacility - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tLOGFACILITY=\"${withval}\"\n\t\t;;\n\tesac\n], [\n\tLOGFACILITY=\"LOG_DAEMON\"\n])\nAC_DEFINE_UNQUOTED(LOG_FACILITY, ${LOGFACILITY}, [Desired syslog facility - see syslog(3)])\nAC_MSG_RESULT(${LOGFACILITY})\n\nAC_MSG_CHECKING(which driver man pages to install)\nDRIVER_MAN_LIST_PAGES=\"\"\nif test \"${WITH_MANS}\" = \"yes\"; then\n\tif test \"${DRIVER_BUILD_LIST}\" = \"all\"; then\n\t\tDRIVER_MAN_LIST=all\n\t\tAC_MSG_RESULT(all available)\n\telse\n\t\tDRIVER_MAN_LIST=\"\"\n\t\tfor i in ${DRIVER_BUILD_LIST}; do\n\t\t    dnl See if source or pre-generated (tarball) doc file exists:\n\t\t\tif test -f ${srcdir}/docs/man/$i.txt -o -f ${srcdir}/docs/man/$i.8; then\n\t\t\t\tDRIVER_MAN_LIST=\"${DRIVER_MAN_LIST} $i.8\"\n\t\t\t\tDRIVER_MAN_LIST_PAGES=\"${DRIVER_MAN_LIST_PAGES} $i.txt\"\n\t\t\tfi\n\t\tdone\n\t\tAC_MSG_RESULT(${DRIVER_MAN_LIST})\n\tfi\nelse\n\tDRIVER_MAN_LIST=\"\"\n\tAC_MSG_RESULT([none (manpages disabled)])\nfi\n\ndnl By default as we iterate (and git commit) the codebase during development,\ndnl prerequisites for that header file change and cause much of the C code\ndnl to be rebuilt and re-linked. For developers fixing one small part of the\ndnl project after another (*and* committing fixes as they go on), the version\ndnl string reported by their new binaries may be of lesser consequence than\ndnl iterating *quickly* and rebuiding just what \"really\" changed!\ndnl Still, this speed-up is not default to avoid surprises for core team.\nAC_MSG_CHECKING(whether to force nut_version.h generation for every make run)\ndnl Value is \"FORCE\" or empty, substituted into Makefile.am rule:\nFORCE_NUT_VERSION=\"FORCE\"\nAC_ARG_ENABLE(force-nut-version-header,\n\tAS_HELP_STRING([--enable-force-nut-version-header], [Force nut_version.h generation for every make run (yes)]),\n[\n\tcase \"${enableval}\" in\n\tno)\n\t\tAC_MSG_RESULT(no)\n                FORCE_NUT_VERSION=\"\"\n\t\t;;\n\t*)\n\t\tAC_MSG_RESULT(yes)\n\t\t;;\n\tesac\n], [\n\tAC_MSG_RESULT(no)\n])\n\n\nAC_MSG_CHECKING(whether to strip debug symbols)\nAC_ARG_ENABLE(strip,\n\tAS_HELP_STRING([--enable-strip], [Strip debugging symbols from binaries (no)]),\n[\n\tcase \"${enableval}\" in\n\tno)\n\t\tAC_MSG_RESULT(no)\n\t\t;;\n\t*)\n\t\tAC_MSG_RESULT(yes)\n\t\tCFLAGS=\"${CFLAGS} -s\"\n\t\t;;\n\tesac\n], [\n\tAC_MSG_RESULT(no)\n])\n\nAC_MSG_CHECKING(whether to install pkg-config *.pc files)\nAC_ARG_WITH(pkgconfig-dir,\n\tAS_HELP_STRING([--with-pkgconfig-dir=PATH], [where to install pkg-config *.pc files (EPREFIX/lib/pkgconfig)]),\n[\n\tcase \"${withval}\" in\n\tyes|auto)\n\t\t;;\n\tno)\n\t\tpkgconfigdir=\"\"\n\t\t;;\n\t*)\n\t\tpkgconfigdir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\n\ndnl Note: currently pkgconfigdir='${libdir}/pkgconfig' literally\ndnl goes into lib/Makefile.am substitution for pkgconfig_DATA.\ndnl By default we get ${libdir}/pkgconfig and below expand it to\ndnl => ${exec_prefix}/lib/pkgconfig => ${prefix}/lib/pkgconfig => real path\nconftemp=\"${pkgconfigdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nPKGCONFIGDIR=\"${conftemp}\"\n\nif test -n \"${pkgconfigdir}\"; then\n\tAC_MSG_RESULT(using ${pkgconfigdir} => ${conftemp})\n\tNUT_REPORT_PATH_INTEGRATIONS([pkg-config *.pc directory], [${pkgconfigdir} => ${conftemp}])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL(WITH_PKG_CONFIG, test -n \"${pkgconfigdir}\")\n\n\ndnl Options for Solaris/illumos `make install` and `make package`\nAC_MSG_CHECKING(whether to make Solaris SVR4 packages)\nsolarispkg_svr4=\"auto\"\nAC_ARG_WITH([solaris-pkg-svr4],\n\tAS_HELP_STRING([--with-solaris-pkg-svr4=(yes|auto|no)], [Enable construction of Solaris SVR4 packages (auto)]),\n[\n\tcase \"${withval}\" in\n\tauto|\"\")\n\t\tsolarispkg_svr4=\"auto\"\n\t\t;;\n\tyes|no)\n\t\tsolarispkg_svr4=\"${withval}\"\n\t\t;;\n\t*)\n\t\tAC_MSG_ERROR([Unexpected argument for --with-solaris-pkg-svr4=${withval}])\n\t\t;;\n\tesac\n], [])\n\nif test x\"$solarispkg_svr4\" = xauto ; then\n\tif test -x /usr/bin/pkgtrans && test -x /usr/bin/pkgmk && test -x /usr/bin/pkgproto ; then\n\t\tsolarispkg_svr4=\"yes\"\n\telse\n\t\tsolarispkg_svr4=\"no\"\n\tfi\nfi\nAC_MSG_RESULT([${solarispkg_svr4}])\nAM_CONDITIONAL(WITH_SOLARIS_PKG_SVR4, test x\"$solarispkg_svr4\" = x\"yes\")\n\nAC_MSG_CHECKING(whether to make Solaris IPS packages)\nsolarispkg_ips=\"auto\"\nAC_ARG_WITH([solaris-pkg-ips],\n\tAS_HELP_STRING([--with-solaris-pkg-ips=(yes|auto|no)], [Enable construction of Solaris IPS packages (auto)]),\n[\n\tcase \"${withval}\" in\n\tauto|\"\")\n\t\tsolarispkg_ips=\"auto\"\n\t\t;;\n\tyes|no)\n\t\tsolarispkg_ips=\"${withval}\"\n\t\t;;\n\t*)\n\t\tAC_MSG_ERROR([Unexpected argument for --with-solaris-pkg-ips=${withval}])\n\t\t;;\n\tesac\n], [])\n\nif test x\"$solarispkg_ips\" = xauto ; then\n\tif test -x /usr/bin/pkg && test -x /usr/bin/pkgmogrify && test -x /usr/bin/pkgdepend ; then\n\t\tsolarispkg_ips=\"yes\"\n\telse\n\t\tsolarispkg_ips=\"no\"\n\tfi\nfi\nAC_MSG_RESULT([${solarispkg_ips}])\nAM_CONDITIONAL(WITH_SOLARIS_PKG_IPS, test x\"$solarispkg_ips\" = x\"yes\")\n\n\ndnl NOTE: Be sure to customize e.g.  --datarootdir=/usr/share/nut to install\ndnl these scripts not into default location as e.g. /usr/share/solaris-smf\nAC_MSG_CHECKING(whether to install Solaris SMF files)\nsolarissmf=\"auto\"\nAC_ARG_WITH([solaris-smf],\n\tAS_HELP_STRING([--with-solaris-smf=(yes|auto|no)], [Enable installation of NUT scripts and manifests for Solaris Service Management Framework (auto)]),\n[\n\tcase \"${withval}\" in\n\tauto|\"\")\n\t\tsolarissmf=\"auto\"\n\t\t;;\n\tyes|no)\n\t\tsolarissmf=\"${withval}\"\n\t\t;;\n\t*)\n\t\tAC_MSG_ERROR([Unexpected argument for --with-solaris-smf=${withval}])\n\t\t;;\n\tesac\n], [])\n\nif test x\"$solarissmf\" = xauto ; then\n\tif test -x /usr/sbin/svcadm && test -x /usr/sbin/svccfg && test -x /usr/bin/svcs ; then\n\t\tsolarissmf=\"yes\"\n\telse\n\t\tcase \"${solarispkg_ips}${solarispkg_svr4}\" in\n\t\t\t*yes*) solarisinit=\"yes\" ;; dnl Want to install so we can generally package\n\t\t\t*) solarissmf=\"no\" ;; dnl Target not solarish\n\t\tesac\n\tfi\nfi\nAC_MSG_RESULT([${solarissmf}])\nNUT_REPORT_FEATURE([consider basic SMF support], [${solarissmf}], [],\n\t\t\t\t\t[WITH_SOLARIS_SMF], [Define to consider basic SMF support (provide units and configuration files)])\n\n\nAC_MSG_CHECKING(whether to install Solaris SVR4 (legacy) init-script files)\nsolarisinit=\"auto\"\nAC_ARG_WITH([solaris-init],\n\tAS_HELP_STRING([--with-solaris-init=(yes|auto|no)], [Enable installation of NUT legacy init-scripts for Solaris/illumos (auto)]),\n[\n\tcase \"${withval}\" in\n\tauto|\"\")\n\t\tsolarisinit=\"auto\"\n\t\t;;\n\tyes|no)\n\t\tsolarisinit=\"${withval}\"\n\t\t;;\n\t*)\n\t\tAC_MSG_ERROR([Unexpected argument for --with-solaris-init=${withval}])\n\t\t;;\n\tesac\n], [])\n\nif test x\"$solarisinit\" = xauto ; then\n\tdnl Depends on usability of SMF or making for packaging\n\tcase \"${solarispkg_ips}${solarispkg_svr4}\" in\n\t\t*yes*) solarisinit=\"yes\" ;; dnl Want to install so we can generally package\n\t\t*)\n\t\t\tcase ${target_os} in\n\t\t\t\tsolaris*|sunos*|SunOS*|illumos*)\n\t\t\t\t\tif test \"$solarissmf\" = x\"yes\" ; then\n\t\t\t\t\t\tdnl no need on modern OSes\n\t\t\t\t\t\tsolarisinit=\"no\"\n\t\t\t\t\telse\n\t\t\t\t\t\tsolarisinit=\"yes\"\n\t\t\t\t\tfi\n\t\t\t\t\t;;\n\t\t\t\t*) solarisinit=\"no\" ;; dnl Some other OS\n\t\t\tesac\n\t\t\t;;\n\tesac\nfi\nAC_MSG_RESULT([${solarisinit}])\nAM_CONDITIONAL(WITH_SOLARIS_INIT, test x\"$solarisinit\" = x\"yes\")\n\n\ndnl Note: Currently there is no reliable automatic detection -\ndnl users have to ask they want systemd units installed, or\ndnl risk auto-detection like seen below.\nAC_MSG_CHECKING(whether to install systemd unit files)\nAC_ARG_WITH([systemdsystemunitdir],\n\tAS_HELP_STRING([--with-systemdsystemunitdir=DIR], [Directory for systemd service files (auto)]),\n\t[systemdsystemunitdir=\"${withval}\"],\n\t[systemdsystemunitdir=\"auto\"])\ncase \"${systemdsystemunitdir}\" in\n\tyes|auto|\"\")\n\t\tAS_IF([test x\"$have_PKG_CONFIG\" = xyes],\n\t\t\t[def_systemdsystemunitdir=\"`$PKG_CONFIG --variable=systemdsystemunitdir systemd 2>/dev/null`\" && test -n \"$def_systemdsystemunitdir\" || \\\n\t\t\t def_systemdsystemunitdir=\"`$PKG_CONFIG --variable=systemdsystemunitdir libsystemd 2>/dev/null`\" || def_systemdsystemunitdir=\"\"],\n\t\t\t[def_systemdsystemunitdir=\"\"])\n\n\t\tAS_IF([test x\"${def_systemdsystemunitdir}\" = x], [\n\t\t\tAS_IF([test \"${systemdsystemunitdir}\" = yes],\n\t\t\t\t[AC_MSG_ERROR([--with-systemdsystemunitdir=${systemdsystemunitdir} was requested, but PKG_CONFIG could not be queried for the system settings])])\n\t\t\tsystemdsystemunitdir=\"\"\n\t\t\t], [systemdsystemunitdir=\"${def_systemdsystemunitdir}\"])\n\n\t\tunset def_systemdsystemunitdir\n\t\t;;\n\tno)\n\t\tsystemdsystemunitdir=\"\"\n\t\t;;\n\t*)\n\t\tAS_IF([test -d \"${systemdsystemunitdir}\"], [],\n\t\t\t[AC_MSG_WARN([--with-systemdsystemunitdir='${systemdsystemunitdir}' was requested, but that location does not currently exist in build environment - just so you know...])])\n\t\t;;\nesac\nif test \"${systemdsystemunitdir}\" = \"auto\" ; then systemdsystemunitdir=\"\"; fi\nif test -n \"${systemdsystemunitdir}\"; then\n\thave_systemd=\"yes\"\n\tAC_MSG_RESULT(using ${systemdsystemunitdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Service units for systemd], [${systemdsystemunitdir}])\nelse\n\thave_systemd=\"no\"\n\tAC_MSG_RESULT(no)\nfi\ndnl Note: we may want tighter integration, e.g. systemd-notify support\ndnl configured as a further option/flag (see --with-systemd below).\ndnl This one is a very basic yes/no toggle for unit file delivery.\nNUT_REPORT_FEATURE([consider basic systemd support], [${have_systemd}], [],\n\t\t\t\t\t[HAVE_SYSTEMD], [Define to consider basic systemd support (provide units and configuration files)])\ndnl This option is only provided so that make distcheck can override it,\ndnl otherwise we ask pkg-config whenever --with-systemdsystemunitdir is\ndnl given\n\ndnl Similarly for presets (list of svcs enabled/disabled by default)\nAC_MSG_CHECKING(whether to install systemd preset files)\nAC_ARG_WITH([systemdsystempresetdir],\n\t[AS_HELP_STRING([--with-systemdsystempresetdir=DIR], [Directory for systemd preset files (auto)])],\n\t[systemdsystempresetdir=\"${withval}\"],\n\t[systemdsystempresetdir=\"auto\"])\n\ndnl Note: this option is enabled only if systemdsystemunitdir is not trivial\nif test -n \"${systemdsystemunitdir}\"; then\n\tcase \"${systemdsystempresetdir}\" in\n\tyes|auto|\"\")\n\t\tAS_IF([test x\"$have_PKG_CONFIG\" = xyes],\n\t\t\t[def_systemdsystempresetdir=\"`$PKG_CONFIG --variable=systemdsystempresetdir systemd 2>/dev/null`\" && test -n \"$def_systemdsystempresetdir\" || \\\n\t\t\t def_systemdsystempresetdir=\"`$PKG_CONFIG --variable=systemdsystempresetdir libsystemd 2>/dev/null`\" || def_systemdsystempresetdir=\"\"],\n\t\t\t[def_systemdsystempresetdir=\"\"])\n\n\t\tAS_IF([test x\"${def_systemdsystempresetdir}\" = x], [\n\t\t\tAS_IF([test \"${systemdsystempresetdir}\" = yes],\n\t\t\t\t[AC_MSG_ERROR([--with-systemdsystempresetdir=${systemdsystempresetdir} was requested, but PKG_CONFIG could not be queried for the system settings])])\n\t\t\tsystemdsystempresetdir=\"\"\n\t\t\t], [systemdsystempresetdir=\"${def_systemdsystempresetdir}\"])\n\n\t\tunset def_systemdsystempresetdir\n\t\t;;\n\tno)\n\t\tsystemdsystempresetdir=\"\"\n\t\t;;\n\t*)\n\t\tAS_IF([test -d \"${systemdsystempresetdir}\"], [],\n\t\t\t[AC_MSG_WARN([--with-systemdsystempresetdir='${systemdsystempresetdir}' was requested, but that location does not currently exist in build environment - just so you know...])])\n\t\t;;\n\tesac\nfi\nif test \"${systemdsystempresetdir}\" = \"auto\" ; then systemdsystempresetdir=\"\"; fi\nif test -n \"${systemdsystempresetdir}\"; then\n\tAC_MSG_RESULT(using ${systemdsystempresetdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Service unit presets for systemd], [${systemdsystempresetdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\n\ndnl Similarly for shutdown integration hooks\nAC_MSG_CHECKING(whether to install systemd shutdown files)\nAC_ARG_WITH([systemdshutdowndir],\n\tAS_HELP_STRING([--with-systemdshutdowndir=DIR], [Directory for systemd shutdown scripts (auto)]),\n\t[systemdshutdowndir=\"${withval}\"],\n\t[systemdshutdowndir=\"auto\"])\ndnl Note: this option is enabled only if systemdsystemunitdir is not trivial\nif test -n \"${systemdsystemunitdir}\"; then\n\tcase \"${systemdshutdowndir}\" in\n\tyes|auto|\"\")\n\t\tAS_IF([test x\"$have_PKG_CONFIG\" = xyes],\n\t\t\t[def_systemdshutdowndir=\"`$PKG_CONFIG --variable=systemdshutdowndir systemd 2>/dev/null`\" && test -n \"$def_systemdshutdowndir\" || \\\n\t\t\t def_systemdshutdowndir=\"`$PKG_CONFIG --variable=systemdshutdowndir libsystemd 2>/dev/null`\" || def_systemdshutdowndir=\"\"],\n\t\t\t[def_systemdshutdowndir=\"\"])\n\n\t\tAS_IF([test x\"${def_systemdshutdowndir}\" = x], [\n\t\t\tAS_IF([test \"${systemdshutdowndir}\" = yes],\n\t\t\t\t[AC_MSG_ERROR([--with-systemdshutdowndir=${systemdshutdowndir} was requested, but PKG_CONFIG could not be queried for the system settings])])\n\t\t\tsystemdshutdowndir=\"\"\n\t\t\t], [systemdshutdowndir=\"${def_systemdshutdowndir}\"])\n\n\t\tunset def_systemdshutdowndir\n\t\t;;\n\tno)\n\t\tsystemdshutdowndir=\"\"\n\t\t;;\n\t*)\n\t\tAS_IF([test -d \"${systemdshutdowndir}\"], [],\n\t\t\t[AC_MSG_WARN([--with-systemdshutdowndir='${systemdshutdowndir}' was requested, but that location does not currently exist in build environment - just so you know...])])\n\t\t;;\n\tesac\nfi\nif test \"${systemdshutdowndir}\" = \"auto\" ; then systemdshutdowndir=\"\"; fi\nif test -n \"${systemdshutdowndir}\"; then\n\tAC_MSG_RESULT(using ${systemdshutdowndir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Shutdown hooks for systemd], [${systemdshutdowndir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\n\ndnl Note: if (systemd-)tmpfiles tech is present, it can be useful even for\ndnl daemons starting not as systemd units, to pre-create /var/run/nut etc.\nAC_MSG_CHECKING([whether to install systemd tmpfiles files])\nAC_ARG_WITH([systemdtmpfilesdir],\n\tAS_HELP_STRING([--with-systemdtmpfilesdir=DIR], [Directory for systemd tmpfiles scripts (auto)]),\n\t[systemdtmpfilesdir=\"${withval}\"],\n\t[systemdtmpfilesdir=\"auto\"])\ncase \"${systemdtmpfilesdir}\" in\n\tyes|auto|\"\")\n\t\tAS_IF([test x\"$have_PKG_CONFIG\" = xyes],\n\t\t\t[def_systemdtmpfilesdir=\"`$PKG_CONFIG --variable=tmpfilesdir systemd 2>/dev/null`\" && test -n \"$def_systemdtmpfilesdir\" || \\\n\t\t\t def_systemdtmpfilesdir=\"`$PKG_CONFIG --variable=tmpfilesdir libsystemd 2>/dev/null`\" || def_systemdtmpfilesdir=\"\"],\n\t\t\t[def_systemdtmpfilesdir=\"\"])\n\n\t\tAS_IF([test x\"${def_systemdtmpfilesdir}\" = x], [\n\t\t\tAS_IF([test \"${systemdtmpfilesdir}\" = yes],\n\t\t\t\t[AC_MSG_ERROR([--with-systemdtmpfilesdir=${systemdtmpfilesdir} was requested, but PKG_CONFIG could not be queried for the system settings])])\n\t\t\tsystemdtmpfilesdir=\"\"\n\t\t\t], [systemdtmpfilesdir=\"${def_systemdtmpfilesdir}\"])\n\n\t\tunset def_systemdtmpfilesdir\n\t\t;;\n\tno)\n\t\tsystemdtmpfilesdir=\"\"\n\t\t;;\n\t*)\n\t\tAS_IF([test -d \"${systemdtmpfilesdir}\"], [],\n\t\t\t[AC_MSG_WARN([--with-systemdtmpfilesdir='${systemdtmpfilesdir}' was requested, but that location does not currently exist in build environment - just so you know...])])\n\t\t;;\nesac\nif test \"${systemdtmpfilesdir}\" = \"auto\" ; then systemdtmpfilesdir=\"\"; fi\nif test -n \"${systemdtmpfilesdir}\"; then\n\tAC_MSG_RESULT(using ${systemdtmpfilesdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Systemd-tmpfiles configs], [${systemdtmpfilesdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\n\ndnl What pathname would we embed into unit files ExecStartPre?\ndnl TODO? Any need to make it a --with-... argument?\nAC_PATH_PROG([SYSTEMD_TMPFILES_PROGRAM], [systemd-tmpfiles], [/usr/bin/systemd-tmpfiles])\n\n\ndnl Note: we may want binaries with sd_notify and similar features regardless\ndnl of building and delivering unit files (which may be crafted separately).\ndnl TODO: although end-user deployments (for custom builds) may be lacking\ndnl libsystemd development files, they might have a `systemd-notify` program\ndnl intended to help scripted service units. Consider making use of that then.\nNUT_ARG_WITH([libsystemd], [build binaries with tighter systemd integration (notifications etc)], [auto])\nNUT_CHECK_LIBSYSTEMD\n\nAC_MSG_CHECKING(whether requested and can build binaries with tighter systemd integration support)\nAS_IF([test x\"${nut_with_libsystemd}\" = xyes && test x\"${nut_have_libsystemd}\" != xyes],\n\t[AC_MSG_ERROR([--with-libsystemd was requested, but the library was not found or usable])])\nAS_CASE([\"${nut_with_libsystemd}\"],\n\t[yes|no], [have_libsystemd=\"${nut_with_libsystemd}\"],\n\t[AS_IF([test x\"${nut_have_libsystemd}\" = xyes],\n\t\t[with_libsystemd=\"yes\"],\n\t\t[with_libsystemd=\"no\"])\n\t])\nAC_MSG_RESULT(${with_libsystemd})\n\nAC_PATH_PROG([SYSTEMD_ANALYZE_PROGRAM], [systemd-analyze], [/usr/bin/systemd-analyze])\n\ndnl Relevant since 2023: https://github.com/systemd/systemd/pull/25916\nSYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY=no\nAS_IF([test -x \"$SYSTEMD_ANALYZE_PROGRAM\"], [\n\tAC_MSG_CHECKING([if your systemd version supports Type=notify])\n\tmyFILE=\"`mktemp systemd-analyze-XXXXXX.service`\"\n\tcat > \"$myFILE\" << EOF\n@<:@Unit@:>@\nDescription=temp\n@<:@Service@:>@\nExecStart=/bin/true\nType=notify\nEOF\n\tif myOUT=\"`\"$SYSTEMD_ANALYZE_PROGRAM\" verify \"$myFILE\" 2>&1`\" \\\n\t&& ! (echo \"$myOUT\" | grep \"Failed to parse service type, ignoring\") \\\n\t; then\n\t\tSYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY=yes\n\tfi\n\trm -f \"$myFILE\"\n\tAC_MSG_RESULT([${SYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY}])\n\t])\n\nSYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY_RELOAD=no\nAS_IF([test -x \"$SYSTEMD_ANALYZE_PROGRAM\"], [\n\tAC_MSG_CHECKING([if your systemd version supports Type=notify-reload])\n\tmyFILE=\"`mktemp systemd-analyze-XXXXXX.service`\"\n\tcat > \"$myFILE\" << EOF\n@<:@Unit@:>@\nDescription=temp\n@<:@Service@:>@\nExecStart=/bin/true\nType=notify-reload\nEOF\n\tif myOUT=\"`\"$SYSTEMD_ANALYZE_PROGRAM\" verify \"$myFILE\" 2>&1`\" \\\n\t&& ! (echo \"$myOUT\" | grep \"Failed to parse service type, ignoring\") \\\n\t; then\n\t\tSYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY_RELOAD=yes\n\tfi\n\trm -f \"$myFILE\"\n\tAC_MSG_RESULT([${SYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY_RELOAD}])\n\t])\n\nAS_IF([test x\"${with_libsystemd}\" = xyes && test x\"${SYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY}\" = xyes], [\n\tdnl Built with sd_notify support\n\tdnl Note: `upsd -FF` both runs without forking and leaves a PID file, as\n\tdnl needed for `upsd -c reload` in legacy scripts and old habits to work:\n\tSYSTEMD_DAEMON_ARGS_UPSD=\"-FF\"\n\tSYSTEMD_DAEMON_TYPE_UPSD=\"notify\"\n\tSYSTEMD_DAEMON_ARGS_UPSLOG=\"-F\"\n\tSYSTEMD_DAEMON_TYPE_UPSLOG=\"notify\"\n\tSYSTEMD_DAEMON_ARGS_UPSMON=\"-F\"\n\tSYSTEMD_DAEMON_TYPE_UPSMON=\"notify\"\n\tSYSTEMD_DAEMON_ARGS_DRIVER=\"-FF\"\n\tSYSTEMD_DAEMON_TYPE_DRIVER=\"notify\"\n\tAS_IF([test x\"${SYSTEMD_SUPPORTS_DAEMON_TYPE_NOTIFY_RELOAD}\" = xyes], [\n\t\tdnl Macro supported since aclocal-1.11:\n\t\tm4_ifdef([AM_COND_IF],\n\t\t[AM_COND_IF([HAVE_CLOCK_GETTIME], [AM_COND_IF([HAVE_CLOCK_MONOTONIC], [SYSTEMD_DAEMON_TYPE_DRIVER=\"notify-reload\"])])],\n\t\t[AS_IF([test x\"${ac_cv_func_clock_gettime}\" = \"xyes\"], [SYSTEMD_DAEMON_TYPE_DRIVER=\"notify-reload\"])])\n\t\t])\n\tdnl Calling shell, upsdrvctl, driver, and then it forks... ugh!\n\tdnl https://github.com/systemd/systemd/issues/25961\n\tdnl FIXME: if NotifyAccess=cgroup appears, use it (consult SYSTEMD_VERSION)\n\tSYSTEMD_DAEMON_NOTIFYACCESS_DRIVER=\"NotifyAccess=all\"\n\tdnl Similar for UPSMON with its two processes:\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSMON=\"NotifyAccess=all\"\n\tdnl UPSD is started directly by systemd and does not fork:\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSD=\"NotifyAccess=main\"\n\tdnl Similarly for upslog (per settings above):\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSLOG=\"NotifyAccess=main\"\n\tdnl Note: at this time we do not pre-define watchdog settings,\n\tdnl to avoid breaking something by a poorly hardcoded guess.\n\tdnl This is something end-users should do for their deployment,\n\tdnl especially for drivers\n\tSYSTEMD_DAEMON_WATCHDOG_DRIVER=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSD=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSLOG=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSMON=\"#WatchdogSec=240s\"\n\t], [\n\tdnl \"Usual\" daemons that happen to be spawned by systemd\n\tSYSTEMD_DAEMON_ARGS_UPSD=\"-F\"\n\tSYSTEMD_DAEMON_TYPE_UPSD=\"simple\"\n\tSYSTEMD_DAEMON_ARGS_UPSLOG=\"-F\"\n\tSYSTEMD_DAEMON_TYPE_UPSLOG=\"simple\"\n\tSYSTEMD_DAEMON_ARGS_UPSMON=\"-F\"\n\tSYSTEMD_DAEMON_TYPE_UPSMON=\"simple\"\n\tSYSTEMD_DAEMON_ARGS_DRIVER=\"\"\n\tSYSTEMD_DAEMON_TYPE_DRIVER=\"forking\"\n\tSYSTEMD_DAEMON_NOTIFYACCESS_DRIVER=\"\"\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSD=\"\"\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSLOG=\"\"\n\tSYSTEMD_DAEMON_NOTIFYACCESS_UPSMON=\"\"\n\tdnl Watchdog should not be configured for not-notifying units, right?\n\tSYSTEMD_DAEMON_WATCHDOG_DRIVER=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSD=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSLOG=\"#WatchdogSec=240s\"\n\tSYSTEMD_DAEMON_WATCHDOG_UPSMON=\"#WatchdogSec=240s\"\n\t])\n\nNUT_REPORT_FEATURE([build with tighter systemd support], [${with_libsystemd}], [],\n\t[WITH_LIBSYSTEMD], [Define to build with tighter systemd support (sd_notify etc)])\n\nnut_with_libsystemd_inhibitor=0\nAS_IF([test x\"${with_libsystemd}\" = xyes && test x\"${nut_have_libsystemd_inhibitor}\" = xyes], [nut_with_libsystemd_inhibitor=1])\nAC_DEFINE_UNQUOTED(WITH_LIBSYSTEMD_INHIBITOR, [${nut_with_libsystemd_inhibitor}], [Define as 1 if we can use systemd inhibitor interface here])\nAM_CONDITIONAL([WITH_LIBSYSTEMD_INHIBITOR], [test x\"${nut_with_libsystemd_inhibitor}\" = x1])\n\ndnl\ndnl Tests for CppUnit availability and usability (will be built if we can,\ndnl and if valgrind is enabled for this configuration - reported below).\ndnl Using CppUnit implies C++ support!\ndnl Theoretically, libcppunit-dev will pull up to g++, through libstdc++...\ndnl AM_PATH_CPPUNIT(1.9.6)\n\ndnl # Tests with gcc-4.8 require this C++11 option to be provided explicitly\ndnl # gcc-4.6 does not support this yet; newer gcc's should be ok by default.\ndnl # Could use `AX_CXX_COMPILE_STDCXX_11([noext], [optional])` if it were\ndnl # available everywhere. Or AX_CHECK_COMPILE_FLAG if it was ubiquitous:\ndnl ###AX_CHECK_COMPILE_FLAG([-std=c++11],\ndnl ###    [CXXFLAGS=\"$CXXFLAGS -std=c++11\"\ndnl ###     have_cxx11=yes],\ndnl ###    [have_cxx11=no])\n\nAC_MSG_CHECKING(for C++11 support in current compiler)\nhave_cxx11=unknown\nmy_CXXFLAGS=\"$CXXFLAGS\"\nAC_LANG_PUSH([C++])\n\nCPLUSPLUS_DECL='\n#include <stdio.h>\n#if __cplusplus < 201103L\n  #error This library needs at least a C++11 compliant compiler\n#endif\n\n/* Make sure it supports modern syntax */\n#include <string>\n#include <map>\n'\nCPLUSPLUS_MAIN='\nprintf(\"%ld\\n\", __cplusplus);\n/* Make sure it supports modern syntax */\nstd::map<std::string, std::string> map;\nmap.emplace(\"key\", \"value\");\n'\n\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[${CPLUSPLUS_DECL}]], [[${CPLUSPLUS_MAIN}]])],\n    [AC_MSG_RESULT([yes, out of the box])\n     have_cxx11=yes],\n    [AS_CASE([\"${CXXFLAGS}\"],\n        [*\"-std=\"*|*\"-ansi\"*], [\n            AC_MSG_RESULT([no, not with the standard already set in CXXFLAGS='${CXXFLAGS}'])\n            have_cxx11=no\n        ],[\n            CXXFLAGS=\"$CXXFLAGS -std=c++11\"\n            AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[${CPLUSPLUS_DECL}]], [[${CPLUSPLUS_MAIN}]])],\n                [AC_MSG_RESULT([yes, GCC-style (as C++11)])\n                 have_cxx11=yes],\n                [CXXFLAGS=\"$CXXFLAGS -std=c++0x\"\n                 AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[${CPLUSPLUS_DECL}]], [[${CPLUSPLUS_MAIN}]])],\n                    [AC_MSG_RESULT([yes, GCC-style (as C++0X)])\n                     have_cxx11=yes],\n                    [AC_MSG_RESULT([no])\n                     CXXFLAGS=\"$my_CXXFLAGS\"\n                     have_cxx11=no])])])])\nNUT_REPORT_FEATURE([build C++11 codebase (client library, etc.)], [${have_cxx11}], [],\n\t\t\t\t\t[HAVE_CXX11], [Define to enable C++11 support])\nAC_LANG_POP([C++])\nunset CPLUSPLUS_MAIN\nunset CPLUSPLUS_DECL\n\nAC_MSG_CHECKING(for have_cppunit)\nhave_cppunit=\"no\"\ndnl CPPUNIT_NUT_CXXFLAGS are set below if suitable, but can be\ndnl disabled further below if nut_with_debuginfo gets applied\ndnl for all NUT build products:\nCPPUNIT_NUT_CXXFLAGS=\"\"\nAS_IF([test x\"$have_PKG_CONFIG\" = xyes],\n    [AS_IF([test x\"${have_cxx11}\" = xyes],\n        [ifdef([PKG_CHECK_MODULES], [PKG_CHECK_MODULES(CPPUNIT, cppunit, have_cppunit=yes, have_cppunit=no)], [have_cppunit=no])\n         AS_IF([test \"${have_cppunit}\" != \"yes\"],\n            [AC_MSG_WARN([libcppunit not found - those C++ tests will not be built.])\n             have_cppunit=no],\n            [AS_IF([test \"x$GXX\" = xyes],\n             [CPPUNIT_NUT_CXXFLAGS=\"-g -O0\"])\n            ])\n        ])\n    ], [AC_MSG_WARN([pkg-config not found, can not look properly for libcppunit - those C++ tests will not be built.])\n        have_cppunit=no]\n)\nAC_MSG_RESULT(${have_cppunit})\n\ndnl On some systems, CppUnit inexplicably fails with trivial assertions\ndnl so it should not be enabled with those environments, corrupting the\ndnl test results with misleading errors.\ndnl Tracked in https://github.com/networkupstools/nut/issues/1126\ndnl One such situation was e.g. \"clang++ + arm64(QEMU) + -m64\" while\ndnl this was not seen with other compilers or bitness on same system.\nAS_IF([test \"${have_cppunit}\" = \"yes\"],\n    [AC_MSG_CHECKING([if current toolkit can build and run cppunit tests (e.g. no ABI issues, related segfaults, etc.)])\n     dnl Code below is largely a stripped variant of our tests/example.cpp and cpputest.cpp\n     CPLUSPLUS_DECL='\n#include <stdexcept>\n#include <cppunit/extensions/HelperMacros.h>\n#include <cppunit/CompilerOutputter.h>\n#include <cppunit/extensions/TestFactoryRegistry.h>\n#include <cppunit/ui/text/TestRunner.h>\n\nclass ExampleTest : public CppUnit::TestFixture\n{\n  CPPUNIT_TEST_SUITE( ExampleTest );\n    CPPUNIT_TEST( testOne );\n  CPPUNIT_TEST_SUITE_END();\npublic:\n  void setUp() {};\n  void tearDown() {};\n  void testOne();\n};\nCPPUNIT_TEST_SUITE_REGISTRATION( ExampleTest );\nvoid ExampleTest::testOne()\n{\n  int i = 1;\n  float f = 1.0;\n  int cast = static_cast<int>(f);\n  CPPUNIT_ASSERT_EQUAL_MESSAGE(\"Casted float is not the expected int (assert_eq)\", i, cast );\n  CPPUNIT_ASSERT_MESSAGE(\"Casted float is not the expected int (assert)\", (i == cast) );\n}\n'\n\n     CPLUSPLUS_MAIN='\nCppUnit::Test *suite = CppUnit::TestFactoryRegistry::getRegistry().makeTest();\nCppUnit::TextUi::TestRunner runner;\nrunner.addTest( suite );\nrunner.setOutputter( new CppUnit::CompilerOutputter( &runner.result(), std::cerr ) );\nbool res = runner.run();\nreturn res ? 0 : 1;\n'\n\n     my_CXXFLAGS=\"$CXXFLAGS\"\n     my_LDFLAGS=\"$LDFLAGS\"\n     my_LIBS=\"$LIBS\"\n     CXXFLAGS=\"$myCXXFLAGS $pkg_cv_CPPUNIT_CFLAGS $pkg_cv_CPPUNIT_CXXFLAGS\"\n     LDFLAGS=\"$my_LDFLAGS $pkg_cv_CPPUNIT_LDFLAGS\"\n     LIBS=\"$my_LIBS $pkg_cv_CPPUNIT_LIBS\"\n     AC_LANG_PUSH([C++])\n     AX_RUN_OR_LINK_IFELSE([AC_LANG_PROGRAM([[${CPLUSPLUS_DECL}]], [[${CPLUSPLUS_MAIN}]])],\n        [have_cppunit=yes], [have_cppunit=no])\n     CXXFLAGS=\"$my_CXXFLAGS\"\n     LDFLAGS=\"$my_LDFLAGS\"\n     LIBS=\"$my_LIBS\"\n     AC_LANG_POP([C++])\n     unset CPLUSPLUS_MAIN\n     unset CPLUSPLUS_DECL\n     AC_MSG_RESULT(${have_cppunit})\n     ])\n\ndnl # By default keep the originally detected have_cppunit value\nAC_MSG_CHECKING(for impact from --enable-cppunit option - should we build cppunit tests?)\nAC_ARG_ENABLE(cppunit,\n\t[AS_HELP_STRING([--enable-cppunit], [enable CPPUNIT tests for C++ bindings (yes, no, force, auto)])],\n\t[AS_CASE([\"${enableval}\"],\n\t\t[\"force\"], [AS_IF([test x\"${have_cppunit}\" = xyes], [], [\n\t\t\tAC_MSG_WARN([--enable-cppunit=yes can not be satisfied, but developer asked for it])\n\t\t\thave_cppunit=yes\n\t\t\t])],\n\t\t[\"yes\"], [AS_IF([test x\"${have_cppunit}\" = xyes], [], [AC_MSG_ERROR([--enable-cppunit=yes can not be satisfied])])],\n\t\t[\"no\"], [have_cppunit=no]\n\t\tdnl # \"auto\" and other values keep what was detected (or not)\n\t)])\nAC_MSG_RESULT(${have_cppunit})\n\nNUT_REPORT_FEATURE([build C++ tests with CPPUNIT], [${have_cppunit}], [],\n\t\t\t\t\t[HAVE_CPPUNIT], [Define to enable CPPUNIT tests])\n\ndnl ----------------------------------------------------------------------\n\nAC_MSG_CHECKING(whether we can and want to build nutconf configuration-management tool)\n\nAS_CASE([\"${nut_with_nutconf}\"],\n\t\t[\"auto\"], [AS_IF([test x\"${have_cxx11}\" = xyes], [nut_with_nutconf=\"yes\"], [nut_with_nutconf=\"no\"])],\n\t\t[\"yes\"], [AS_IF([test x\"${have_cxx11}\" = xyes], [], [AC_MSG_ERROR([explicit --with-nutconf=yes can not be satisfied: C++11 support not enabled])])],\n\t\t[\"no\"], [nut_with_nutconf=no]\n\t)\nAC_MSG_RESULT(${nut_with_nutconf})\n\nAM_CONDITIONAL(WITH_NUTCONF, test \"${nut_with_nutconf}\" = \"yes\")\nNUT_REPORT_PROGRAM([build and install the nutconf tool (experimental, may lack support for recent NUT options)],\n\t\t\t\t\t[${nut_with_nutconf}], [],\n\t\t\t\t\t[WITH_NUTCONF], [Define to enable nutconf tool support])\n\ndnl ----------------------------------------------------------------------\n\nAC_MSG_CHECKING(whether to install Augeas configuration-management lenses)\nAC_ARG_WITH(augeas-lenses-dir,\n\tAS_HELP_STRING([--with-augeas-lenses-dir=PATH], [where to install Augeas configuration-management lenses (/usr/share/augeas/lenses{/dist,/})]),\n[\n\tcase \"${withval}\" in\n\tyes)\n\t\tif test -z \"${auglensdir}\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([augeas lenses directory requested but not found in default location])\n\t\tfi\n\t\tif ! test -s scripts/augeas/nutupsconf.aug.in ; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([augeas lenses directory requested but a non-trivial scripts/augeas/nutupsconf.aug.in was not provided by autogen.sh or dist archive])\n\t\tfi\n\t\t;;\n\tauto)\n\t\tif ! test -s scripts/augeas/nutupsconf.aug.in ; then\n\t\t\tAC_MSG_WARN([augeas lenses directory skipped because a non-trivial scripts/augeas/nutupsconf.aug.in was not provided by autogen.sh or dist archive])\n\t\t\tauglensdir=\"\"\n\t\tfi\n\t\t;;\n\tno)\n\t\tauglensdir=\"\"\n\t\t;;\n\t*)\n\t\tauglensdir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nif test -n \"${auglensdir}\"; then\n\tAC_MSG_RESULT(using ${auglensdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Augeas lenses directory], [${auglensdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL(WITH_AUGLENS, test -n \"${auglensdir}\")\n\nif test -n \"${auglensdir}\"; then\n\tauglenstestsdir=\"${auglensdir}/tests\"\nelse\n\tauglenstestsdir=''\nfi\n\nAC_PATH_PROGS([AUGPARSE], [augparse], [none])\nAM_CONDITIONAL([HAVE_AUGPARSE], [test \"x${AUGPARSE}\" != \"xnone\"])\nAC_MSG_CHECKING([whether to enable Augeas configuration-management lenses tests])\nif test \"x${AUGPARSE}\" != xnone ; then\n\tAC_MSG_RESULT(yes)\nelse\n\tAC_MSG_RESULT(no)\nfi\n\ndnl ----------------------------------------------------------------------\n\nAC_MSG_CHECKING(whether to install hotplug rules)\nAC_ARG_WITH(hotplug-dir,\n\tAS_HELP_STRING([--with-hotplug-dir=PATH], [where to install hotplug rules (${hotplugdir}); typically /etc/hotplug]),\n[\n\tcase \"${withval}\" in\n\tyes)\n\t\tif test -z \"${hotplugdir}\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([hotplug directory requested but not found])\n\t\tfi\n\t\t;;\n\tauto)\n\t\t;;\n\tno)\n\t\thotplugdir=\"\"\n\t\t;;\n\t*)\n\t\thotplugdir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nif test -n \"${hotplugdir}\"; then\n\tAC_MSG_RESULT(using ${hotplugdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Hotplug rules directory], [${hotplugdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL(WITH_HOTPLUG, test -n \"${hotplugdir}\")\n\nAC_MSG_CHECKING(whether to install udev rules)\nAC_ARG_WITH(udev-dir,\n\tAS_HELP_STRING([--with-udev-dir=PATH], [where to install udev rules (${udevdir}; typically /lib/udev or /etc/udev)]),\n[\n\tcase \"${withval}\" in\n\tyes) dnl Typically /lib/udev or /etc/udev\n\t\tif test -z \"${udevdir}\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([udev directory requested but not found])\n\t\tfi\n\t\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/udev/nut-usbups.rules.in ; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([udev directory and USB driver support requested but a non-trivial scripts/udev/nut-usbups.rules.in was not provided by autogen.sh or dist archive])\n\t\tfi\n\t\t;;\n\tauto)\n\t\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/udev/nut-usbups.rules.in ; then\n\t\t\tAC_MSG_WARN([udev directory skipped because a non-trivial scripts/udev/nut-usbups.rules.in was not provided by autogen.sh or dist archive])\n\t\t\tudevdir=\"\"\n\t\tfi\n\t\t;;\n\tno)\n\t\tudevdir=\"\"\n\t\t;;\n\t*)\n\t\tudevdir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nif test -n \"${udevdir}\"; then\n\tAC_MSG_RESULT(using ${udevdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([Udev rules directory], [${udevdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL(WITH_UDEV, test -n \"${udevdir}\")\n\ndnl FreeBSD devd support:\n\nAC_MSG_CHECKING(whether to install FreeBSD devd.conf file)\nAC_ARG_WITH(devd-dir,\n\tAS_HELP_STRING([--with-devd-dir=PATH], [where to install devd.conf file (${devddir}; typically /usr/local/etc/devd or /etc/devd)]),\n[\n\tcase \"${withval}\" in\n\tyes) dnl Typically /usr/local/etc/devd or /etc/devd\n\t\tif test -z \"${devddir}\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([devd directory requested but not found])\n\t\tfi\n\t\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/devd/nut-usbups.rules.in -a -s scripts/devd/nut-usb.conf.in ; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([devd directory and USB driver support requested but non-trivial scripts/devd/nut-usbups.rules.in and scripts/devd/nut-usb.conf.in were not provided by autogen.sh or dist archive])\n\t\tfi\n\t\t;;\n\tauto)\n\t\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/devd/nut-usbups.rules.in -a -s scripts/devd/nut-usb.conf.in ; then\n\t\t\tAC_MSG_WARN([devd directory skipped because non-trivial scripts/devd/nut-usbups.rules.in and scripts/devd/nut-usb.conf.in were not provided by autogen.sh or dist archive])\n\t\t\tdevddir=\"\"\n\t\tfi\n\t\t;;\n\tno)\n\t\tdevddir=\"\"\n\t\t;;\n\t*)\n\t\tdevddir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nif test -n \"${devddir}\"; then\n\tAC_MSG_RESULT(using ${devddir})\n\tNUT_REPORT_PATH_INTEGRATIONS([FreeBSD devd rules directory], [${devddir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL(WITH_DEVD, test -n \"${devddir}\")\n\ndnl FreeBSD quirks support:\n\nfreebsdquirksdir=\"\"\nAC_MSG_CHECKING(whether to install FreeBSD site-local USB quirks file)\nAC_ARG_WITH(freebsd-quirks-dir,\n\tAS_HELP_STRING([--with-freebsd-quirks-dir=PATH], [where to install nut-usb.quirks file (${datadir}; typically /usr/local/share/nut)]),\n[\n\tcase \"${withval}\" in\n\tyes) dnl Typically /usr/local/share/nut\n\t\tfreebsdquirksdir=\"${datadir}\"\n\t\t;;\n\tauto)\n\t\tdnl Are we building for FreeBSD with such customizations?\n\t\tif test -s /boot/loader.conf.local ; then\n\t\t\tfreebsdquirksdir=\"${datadir}\"\n\t\tfi\n\t\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/devd/nut-usb.quirks ; then\n\t\t\tAC_MSG_WARN([freebsd-quirks-dir directory skipped because a non-trivial scripts/devd/nut-usb.quirks was not provided by autogen.sh or dist archive])\n\t\t\tfreebsdquirksdir=\"\"\n\t\tfi\n\t\t;;\n\tno)\n\t\tfreebsdquirksdir=\"\"\n\t\t;;\n\t*)\n\t\tfreebsdquirksdir=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nif test -n \"${freebsdquirksdir}\"; then\n\tAC_MSG_RESULT(using ${freebsdquirksdir})\n\tNUT_REPORT_PATH_INTEGRATIONS([FreeBSD site-local USB quirks directory (add into /boot/loader.conf.local)], [${freebsdquirksdir}])\nelse\n\tAC_MSG_RESULT(no)\nfi\n\nif test -n \"${freebsdquirksdir}\" ; then\n\tdnl Expand datadir or similar macros in this path\n\tconftemp=\"${freebsdquirksdir}\"\n\teval conftemp=\\\"${conftemp}\\\"\n\teval conftemp=\\\"${conftemp}\\\"\n\tfreebsdquirksdir=\"${conftemp}\"\n\n\tif test -z \"${freebsdquirksdir}\"; then\n\t\tAC_MSG_ERROR([freebsd-quirks-dir requested but not found (resolved as empty)])\n\tfi\n\n\tif test \"${nut_with_usb}\" = yes && ! test -s scripts/devd/nut-usb.quirks ; then\n\t\tAC_MSG_ERROR([freebsd-quirks-dir directory and USB driver support requested, but a non-trivial scripts/devd/nut-usb.quirks was not provided by autogen.sh or dist archive])\n\tfi\nfi\n\nAM_CONDITIONAL(WITH_FREEBSD_QUIRKS_DIR, test -n \"${freebsdquirksdir}\")\n\ndnl\n\ndnl AIX system\nAM_CONDITIONAL([SYSTEM_AIX], [test \"xAIX\" = \"x`uname -s 2>/dev/null`\"])\n\ndnl processor type\nAC_DEFINE_UNQUOTED(CPU_TYPE, [\"$target_cpu\"], [Define processor type])\n\ndnl Can use valgrind for memory-leak testing, if present\nAC_PATH_PROGS([VALGRIND], [valgrind], [none])\ndnl Even if the tool is installed, it may be not usable on build platform.\ndnl QEMU may further complicate things, providing CPUs that formally match\ndnl a supported family but crash in practice, or hopefully rejected early:\ndnl valgrind: fatal error: unsupported CPU.\ndnl    Supported CPUs are:\ndnl    * x86 (practically any; Pentium-I or above), AMD Athlon or above)\ndnl    * AMD Athlon64/Opteron\ndnl    * ARM (armv7)\ndnl    * MIPS (mips32 and above; mips64 and above)\ndnl    * PowerPC (most; ppc405 and above)\ndnl    * System z (64bit only - s390x; z990 and above)\ndnl Even if the tool does basically start, on some QEMU systems it crashes\ndnl later (e.g. claims Signal 11 in tear-down after a successful test), so\ndnl we support an explicit --without-valgrind (aka --with-valgrind=no) too.\nAS_IF([test -n \"${VALGRIND}\"], [\n\tAC_MSG_CHECKING([whether valgrind is usable on current platform])\n\tAS_IF([( ${VALGRIND} --help >/dev/null 2>/dev/null )],\n\t\t[AS_IF([( ${VALGRIND} /bin/sh -c true >/dev/null 2>/dev/null )],\n\t\t\t[AC_MSG_RESULT([yes])],\n\t\t\t[AC_MSG_RESULT([no])\n\t\t\t VALGRIND=\"none\"\n\t\t\t])],\n\t\t[AC_MSG_RESULT([no])\n\t\t VALGRIND=\"none\"\n\t\t])\n])\nAC_MSG_CHECKING(whether to use valgrind for memory-leak testing)\nAC_ARG_WITH(valgrind,\n\tAS_HELP_STRING([--with-valgrind=PATH], [whether to use valgrind for memory-leak testing]),\n[\n\tdnl ### echo \"Caller said: '${withval}'... Discovered tool: '${VALGRIND}'... \"\n\tcase \"${withval}\" in\n\tyes)\n\t\tif test \"x$VALGRIND\" = \"xnone\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([valgrind requested but not found])\n\t\tfi\n\t\twith_valgrind=\"yes\"\n\t\t;;\n\tauto)\n\t\twith_valgrind=\"auto\"\n\t\t;;\n\tno)\n\t\twith_valgrind=\"no\"\n\t\t;;\n\t*)\n\t\tAC_PATH_PROGS([VALGRIND], [\"${withval}\"], [none])\n\t\tif test \"x$VALGRIND\" = \"xnone\"; then\n\t\t\tAC_MSG_RESULT(no)\n\t\t\tAC_MSG_ERROR([valgrind requested but not found])\n\t\tfi\n\t\twith_valgrind=\"yes\"\n\t\t;;\n\tesac\n], [])\n\nif test \"x${with_valgrind}\" = xauto; then\n\tif test \"x$VALGRIND\" = \"xnone\"; then\n\t\twith_valgrind=\"no\"\n\telse\n\t\twith_valgrind=\"yes\"\n\tfi\nfi\n\nif test \"x${with_valgrind}\" = xyes; then\n\tAC_MSG_RESULT(using ${VALGRIND})\n\tAC_MSG_NOTICE([Do not forget to build with debug (e.g. pass '-g' in CFLAGS for GCC) for best results with valgrind tests])\nelse\n\tAC_MSG_RESULT(no)\nfi\nAM_CONDITIONAL([HAVE_VALGRIND], [test \"x${VALGRIND}\" != \"xnone\"])\nAM_CONDITIONAL([WITH_VALGRIND], [test \"x${with_valgrind}\" = \"xyes\"])\n\nAC_MSG_CHECKING([whether to build cppunit tests using valgrind support])\nif test \"x${with_valgrind}\" = xyes && test \"x${have_cppunit}\" = xyes ; then\n\tAC_MSG_RESULT(yes)\nelse\n\tAC_MSG_RESULT(no)\nfi\n\ndnl expand ${sysconfdir} and write it out - note that most packages\ndnl override it to be /etc/nut, /etc/ups or similar, while the\ndnl autotools default would be $prefix/etc\nconftemp=\"${sysconfdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nCONFPATH=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([Config file path],\n    CONFPATH, \"${conftemp}\", [Default path for configuration files])\n\ndnl same for datadir\nconftemp=\"${datadir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nNUT_DATADIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([Data file path],\n    NUT_DATADIR, \"${conftemp}\", [Default path for data files])\n\ndnl same for mandir\nconftemp=\"${mandir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nNUT_MANDIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([Man page path],\n    NUT_MANDIR, \"${conftemp}\", [Default path for man page files])\n\ndnl same for bindir\nconftemp=\"${bindir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nBINDIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([Tool program path],\n    BINDIR, \"${conftemp}\", [Default path for user executables])\n\ndnl same for sbindir\nconftemp=\"${sbindir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nSBINDIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([System program path],\n    SBINDIR, \"${conftemp}\", [Default path for system executables])\n\ndnl same for libdir\nconftemp=\"${libdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nLIBDIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([System library path],\n    LIBDIR, \"${conftemp}\", [Default path for system libraries])\n\ndnl same for libexecdir\nconftemp=\"${libexecdir}\"\neval conftemp=\\\"${conftemp}\\\"\neval conftemp=\\\"${conftemp}\\\"\nLIBEXECDIR=\"${conftemp}\"\nNUT_REPORT_SETTING_PATH([System exec-library path],\n    LIBEXECDIR, \"${conftemp}\", [Default path for system exec-libraries])\n\n\ndnl checks related to --with-snmp enabled on command-line\n\ndnl ${nut_with_snmp}: any value except \"yes\" or \"no\" is treated as \"auto\".\nif test \"${nut_with_snmp}\" = \"yes\" -a \"${nut_have_libnetsnmp}\" != \"yes\"; then\n   AC_MSG_ERROR([Net-SNMP libraries not found, required for SNMP drivers])\nfi\n\nif test \"${nut_with_snmp}\" != \"no\"; then\n   nut_with_snmp=\"${nut_have_libnetsnmp}\"\nelse\n   nut_have_libnetsnmp_static=\"no\"\nfi\n\nNUT_REPORT_DRIVER([build SNMP drivers], [${nut_with_snmp}], [],\n\t\t\t\t\t[WITH_SNMP], [Define to enable SNMP support])\nNUT_REPORT_DRIVER([build SNMP drivers with statically linked lib(net)snmp], [${nut_have_libnetsnmp_static}], [],\n\t\t\t\t\t[WITH_SNMP_STATIC], [Define to use SNMP support with a statically linked libnetsnmp])\n\n\nif test -n \"${host_alias}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_HOST_ALIAS, \"${host_alias}\", [host env spec we run on])\nelse\n\tif test -n \"${host}\" ; then\n\t\tNUT_REPORT_TARGET(AUTOTOOLS_HOST_ALIAS, \"${host}\", [host env spec we run on])\n\tfi\nfi\nif test -n \"${build_alias}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_BUILD_ALIAS, \"${build_alias}\", [host env spec we built on])\nelse\n\tif test -n \"${build}\" ; then\n\t\tNUT_REPORT_TARGET(AUTOTOOLS_BUILD_ALIAS, \"${build}\", [host env spec we built on])\n\tfi\nfi\nif test -n \"${target_alias}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_TARGET_ALIAS, \"${target_alias}\", [host env spec we built for])\nelse\n\tif test -n \"${target}\" ; then\n\t\tNUT_REPORT_TARGET(AUTOTOOLS_TARGET_ALIAS, \"${target}\", [host env spec we built for])\n\tfi\nfi\n\nif test -n \"${host_cpu}\" -a -n \"${host_os}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_HOST_SHORT_ALIAS, \"${host_cpu}-${host_os}\", [host OS short spec we run on])\nfi\nif test -n \"${build_cpu}\" -a -n \"${build_os}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_BUILD_SHORT_ALIAS, \"${build_cpu}-${build_os}\", [host OS short spec we built on])\nfi\nif test -n \"${target_cpu}\" -a -n \"${target_os}\" ; then\n\tNUT_REPORT_TARGET(AUTOTOOLS_TARGET_SHORT_ALIAS, \"${target_cpu}-${target_os}\", [host OS short spec we built for])\nfi\n\nAC_MSG_CHECKING([whether compiler suggests a MULTIARCH value])\ndnl Recent GCC generally supports this call, although it often returns empty\ndnl Some versions of CLANG also have it, others reject the unknown CLI switch\ncompiler_multiarch=\"`${CC} -print-multiarch 2>/dev/null`\" || compiler_multiarch=\"\"\nif test -n \"${compiler_multiarch}\" ; then\n\tNUT_REPORT_TARGET(MULTIARCH_TARGET_ALIAS, \"${compiler_multiarch}\", [host multiarch spec we build for (as suggested by compiler being used)])\nfi\n\ndnl ----------------------------------------------------------------------\ndnl Check the user and group to run as last, so we can use the paths configured\ndnl above as data sources for default values if building an in-place replacement\n\nAC_MSG_CHECKING(if requested user to run as)\nAC_ARG_WITH(user,\n\tAS_HELP_STRING([--with-user=username], [user for programs started as root (${RUN_AS_USER})]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-user - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tRUN_AS_USER=\"${withval}\"\n\t\tnut_user_given=yes\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [\n\tnut_user_given=no\n\tAC_MSG_RESULT([default])\n])\nNUT_REPORT_SETTING([User to run as],\n    RUN_AS_USER, \"${RUN_AS_USER}\", [User to switch to if started as root])\n\nAC_MSG_CHECKING(if requested group membership of user to run as)\nAC_ARG_WITH(group,\n\tAS_HELP_STRING([--with-group=groupname], [group membership of user for programs started as root (${RUN_AS_GROUP})]),\n[\n\tcase \"${withval}\" in\n\tyes|no)\n\t\tAC_MSG_ERROR(invalid option --with(out)-group - see docs/configure.txt)\n\t\t;;\n\t*)\n\t\tRUN_AS_GROUP=\"${withval}\"\n\t\tnut_group_given=yes\n\t\tAC_MSG_RESULT([specified])\n\t\t;;\n\tesac\n], [\n\tnut_group_given=no\n\tAC_MSG_RESULT([default])\n])\nNUT_REPORT_SETTING([Group of user to run as],\n    RUN_AS_GROUP, \"${RUN_AS_GROUP}\", [Group membership of user to switch to if started as root])\n\ndnl check that --with-user is given if --with-group is given.\nif test \"${nut_user_given}\" = \"yes\" -a \"${nut_group_given}\" = \"no\"; then\n\tAC_MSG_ERROR([If you specify --with-user, you also must specify --with-group])\nelif test \"${nut_user_given}\" = \"no\" -a \"${nut_group_given}\" = \"yes\"; then\n\tAC_MSG_ERROR([If you specify --with-group, you also must specify --with-user])\nfi\n\ndnl ----------------------------------------------------------------------\n\ndnl Current date\nnow=`TZ=UTC date +%Y-%m-%d`\n\nAC_SUBST(now)\nAC_SUBST(OS_NAME)\nAC_SUBST(TREE_VERSION)\nAC_SUBST(NUT_NETVERSION)\nAC_SUBST(FORCE_NUT_VERSION)\nAC_SUBST(NUT_SOURCE_GITREV)\nAC_SUBST(NUT_SOURCE_GITREV_IS_RELEASE)\nAC_SUBST(NUT_SOURCE_GITREV_SEMVER)\nAC_SUBST(NUT_SOURCE_GITREV_NUMERIC)\nAC_SUBST(NUT_WEBSITE_BASE)\nAC_SUBST(LIBSSL_CFLAGS)\nAC_SUBST(LIBSSL_LIBS)\nAC_SUBST(LIBSSL_LDFLAGS_RPATH)\nAC_SUBST(LIBSSL_REQUIRES)\nAC_SUBST(LIBGD_CFLAGS)\nAC_SUBST(LIBGD_LDFLAGS)\nAC_SUBST(LIBNETSNMP_CFLAGS)\nAC_SUBST(LIBNETSNMP_LIBS)\nAC_SUBST(LIBREGEX_LIBS)\nAC_SUBST(LIBUSB_CFLAGS)\nAC_SUBST(LIBUSB_LIBS)\nAC_SUBST(LIBNEON_CFLAGS)\nAC_SUBST(LIBNEON_LIBS)\nAC_SUBST(LIBAVAHI_CFLAGS)\nAC_SUBST(LIBAVAHI_LIBS)\nAC_SUBST(LIBPOWERMAN_CFLAGS)\nAC_SUBST(LIBPOWERMAN_LIBS)\nAC_SUBST(LIBMODBUS_CFLAGS)\nAC_SUBST(LIBMODBUS_LIBS)\nAC_SUBST(LIBIPMI_CFLAGS)\nAC_SUBST(LIBIPMI_LIBS)\nAC_SUBST(LIBGPIO_CFLAGS)\nAC_SUBST(LIBGPIO_LIBS)\nAC_SUBST(LIBI2C_LIBS)\nAC_SUBST(DOC_BUILD_LIST)\nAC_SUBST(DOC_CHECK_LIST)\nAC_SUBST(LIBWRAP_CFLAGS)\nAC_SUBST(LIBWRAP_LIBS)\nAC_SUBST(LIBLTDL_CFLAGS)\nAC_SUBST(LIBLTDL_LIBS)\nAC_SUBST(LIBSYSTEMD_CFLAGS)\nAC_SUBST(LIBSYSTEMD_LIBS)\nAC_SUBST(SYSTEMD_DAEMON_ARGS_UPSD)\nAC_SUBST(SYSTEMD_DAEMON_TYPE_UPSD)\nAC_SUBST(SYSTEMD_DAEMON_ARGS_UPSLOG)\nAC_SUBST(SYSTEMD_DAEMON_TYPE_UPSLOG)\nAC_SUBST(SYSTEMD_DAEMON_ARGS_UPSMON)\nAC_SUBST(SYSTEMD_DAEMON_TYPE_UPSMON)\nAC_SUBST(SYSTEMD_DAEMON_ARGS_DRIVER)\nAC_SUBST(SYSTEMD_DAEMON_TYPE_DRIVER)\nAC_SUBST(SYSTEMD_DAEMON_NOTIFYACCESS_DRIVER)\nAC_SUBST(SYSTEMD_DAEMON_NOTIFYACCESS_UPSD)\nAC_SUBST(SYSTEMD_DAEMON_NOTIFYACCESS_UPSLOG)\nAC_SUBST(SYSTEMD_DAEMON_NOTIFYACCESS_UPSMON)\nAC_SUBST(SYSTEMD_DAEMON_WATCHDOG_UPSD)\nAC_SUBST(SYSTEMD_DAEMON_WATCHDOG_UPSLOG)\nAC_SUBST(SYSTEMD_DAEMON_WATCHDOG_UPSMON)\nAC_SUBST(SYSTEMD_DAEMON_WATCHDOG_DRIVER)\nAC_SUBST(SYSTEMD_TMPFILES_PROGRAM)\nAC_SUBST(DRIVER_BUILD_LIST)\nAC_SUBST(DRIVER_MAN_LIST)\nAC_SUBST(DRIVER_MAN_LIST_PAGES)\nAC_SUBST(DRIVER_INSTALL_TARGET)\nAC_SUBST(BSDKVMPROCLIBS)\nAC_SUBST(NETLIBS)\nAC_SUBST(SERLIBS)\nAC_SUBST(SEMLIBS)\nAC_SUBST(PREFIX)\nAC_SUBST(PIDPATH)\nAC_SUBST(STATEPATH)\nAC_SUBST(ALTPIDPATH)\ndnl #Not in main codebase yet# AC_SUBST(ALTSTATEPATH)\nAC_SUBST(CONFPATH)\nAC_SUBST(POWERDOWNFLAG)\nAC_SUBST(BINDIR)\nAC_SUBST(LIBDIR)\nAC_SUBST(PKGCONFIGDIR)\nAC_SUBST(NUT_DATADIR, [`eval echo \"${NUT_DATADIR}\"`])\nAC_SUBST(NUT_MANDIR, [`eval echo \"${NUT_MANDIR}\"`])\nAC_SUBST(NUT_LIBEXECDIR, [`eval echo \"${LIBEXECDIR}\"`])\nAC_SUBST(DRVPATH)\nAC_SUBST(SBINDIR)\nAC_SUBST(PORT)\nAC_SUBST(RUN_AS_USER)\nAC_SUBST(RUN_AS_GROUP)\nAC_SUBST(SUN_LIBUSB)\nAC_SUBST(WORDS_BIGENDIAN)\nAC_SUBST(cgiexecdir)\nAC_SUBST(devddir)\nAC_SUBST(driverexecdir)\nAC_SUBST(freebsdquirksdir)\nAC_SUBST(htmldir)\nAC_SUBST(htmldocdir)\nAC_SUBST(htmlmandir)\nAC_SUBST(pkgconfigdir)\nAC_SUBST(systemdsystemunitdir)\nAC_SUBST(systemdsystempresetdir)\nAC_SUBST(systemdshutdowndir)\nAC_SUBST(systemdtmpfilesdir)\nAC_SUBST(auglensdir)\nAC_SUBST(auglenstestsdir)\nAC_SUBST(hotplugdir)\nAC_SUBST(udevdir)\n\ndnl On a related note to warning setup below, we limit the minimum C and C++\ndnl standard versions to ones we actively strive to support (C99 and C++11,\ndnl GNU dialects tend to work on more systems if supported by compiler there).\ndnl It is assumed that on very old systems whose compilers do not know these\ndnl standards (only support ANSI/C89/C90 or older), as well as for builds\ndnl that explicitly specify a CFLAGS=\"-std=...\" (for GCC/CLANG toolkits),\ndnl nothing should get added to CFLAGS/CXXFLAGS by this method:\nNUT_COMPILER_FAMILY_FLAGS_DEFAULT_STANDARD\n\ndnl Filter through known variants first, so automatic choices can be made.\ndnl Note that clang identifies as gcc-compatible so should be probed first.\ndnl TODO: Flip this default to \"hard\" when we clear existing codebase.\ndnl Note: the \"gcc-legacy\" option is intentionally undocumented, it acts as\ndnl least-surprise default if caller did not specify any --enable-warnings.\ndnl Note: Currently the \"gcc-minimal\" mode below adapts to builds with\ndnl C89/C90/ANSI mode to be less noisy. Keep this in mind if changing the\ndnl default \"nut_warning_difficulty\" and/or the case handling below.\ndnl NOTE: Until X-Mas 2021, the default was \"minimal\" (now \"medium\")\nnut_warning_difficulty=\"medium\"\nAC_MSG_CHECKING([whether to pre-set warnings (from '${nut_enable_warnings}')])\nAS_CASE([\"${nut_enable_warnings}\"],\n    [no|all|gcc-legacy|gcc-minimal|clang-minimal|gcc-medium|clang-medium|gcc-hard|clang-hard], [],\n    [clang], [nut_enable_warnings=\"${nut_enable_warnings}-${nut_warning_difficulty}\"],\n    [gcc], [\n        AS_CASE([\"${CFLAGS}\"],\n            [*89*|*90*|*ansi*], [nut_enable_warnings=\"${nut_enable_warnings}-minimal\"],\n            [nut_enable_warnings=\"${nut_enable_warnings}-${nut_warning_difficulty}\"]\n        )],\n    [yes|auto|\"\"], [\n        AS_IF([test \"${CLANGCC}\" = \"yes\"], [nut_enable_warnings=\"clang-${nut_warning_difficulty}\"],\n            [AS_IF([test \"${GCC}\" = \"yes\"], [\n                AS_CASE([\"${CFLAGS}\"],\n                    [*89*|*90*|*ansi*], [nut_enable_warnings=\"gcc-minimal\"],\n                    [AS_CASE([\"$CC_VERSION\"],\n                        [*\" \"1.*|*\" \"2.*|3.*|*\" \"4.0*|*\" \"4.1*|*\" \"4.2*|*\" \"4.3*], [\n                            AC_MSG_WARN([Very old GCC in use, disabling warnings])\n                            dnl #AS_IF([test x\"${nut_enable_Werror}\" = xauto], [nut_enable_Werror=\"no\"])\n                            nut_enable_Werror=\"no\"\n                            nut_enable_warnings=\"no\"],\n                        [*\" \"4.4*|*\" \"4.5*|*\" \"4.6*|*\" \"4.7*|*\" \"4.8*], [nut_enable_warnings=\"gcc-legacy\"],\n                        [nut_enable_warnings=\"gcc-${nut_warning_difficulty}\"]\n                    )]\n                )], [nut_enable_warnings=\"all\"])\n            ])\n        ],\n    [hard|auto-hard|auto=hard], [\n        AS_IF([test \"${CLANGCC}\" = \"yes\"], [nut_enable_warnings=\"clang-hard\"],\n            [AS_IF([test \"${GCC}\" = \"yes\"], [nut_enable_warnings=\"gcc-hard\"], [nut_enable_warnings=\"all\"])\n            ])\n        ],\n    [medium|auto-medium|auto=medium], [\n        AS_IF([test \"${CLANGCC}\" = \"yes\"], [nut_enable_warnings=\"clang-medium\"],\n            [AS_IF([test \"${GCC}\" = \"yes\"], [nut_enable_warnings=\"gcc-medium\"], [nut_enable_warnings=\"all\"])\n            ])\n        ],\n    [minimal|auto-minimal|auto=minimal], [\n        AS_IF([test \"${CLANGCC}\" = \"yes\"], [nut_enable_warnings=\"clang-minimal\"],\n            [AS_IF([test \"${GCC}\" = \"yes\"], [nut_enable_warnings=\"gcc-minimal\"], [nut_enable_warnings=\"all\"])\n            ])\n        ],\n    [legacy], [AS_IF([test \"${GCC}\" = \"yes\"], [nut_enable_warnings=\"gcc-legacy\"], [nut_enable_warnings=\"no\"])],\n    [AC_MSG_WARN([Unsupported variant for --enable-warnings=${nut_enable_warnings}, ignored])\n     nut_enable_warnings=\"no\"\n    ]\n)\nAC_MSG_RESULT([${nut_enable_warnings}])\n\ndnl # Nothing special for gcc - we tend to survive it with GNU standard >= 99\ndnl # and fail with strict C standard. Suggestions welcome for \"gcc-hard\" to\ndnl # make a difference.\ndnl # Note that \"medium\" and \"hard\" settings tend to trigger warnings also\ndnl # from system headers, so we try to avoid them, using \"-isystem path\"\ndnl # pre-set in our `m4/nut_compiler_family.m4` script:\ndnl #    https://stackoverflow.com/questions/36355232/disable-certain-warnings-for-system-headers\ndnl # and \"-Wno-system-headers\" below.\ndnl # Some of the compiler flags (including those added by pkg-config of some\ndnl # third-party dependency packages) can upset older compiler releases which\ndnl # did not yet support those. Flags like \"-Wno-unknown-warning\" for GCC or\ndnl # \"-Wno-unknown-warning-option\" for CLANG should take care of that at least\ndnl # for toolkit versions that support these - set in NUT_COMPILER_FAMILY_FLAGS\ndnl # Majority of sanity checks are enabled by \"-Wextra\" on both GCC and CLANG\ndnl # and \"-Weverything\" additionally on CLANG. They are impractically picky,\ndnl # especially with fallout from system headers that we can not impact anyway\ndnl # so the \"difficulty level\" pre-sets exclude certain warning classes from\ndnl # that report.\ndnl ### Special exclusion picks for clang-hard:\ndnl # -Wno-unused-macros -- system headers define a lot of stuff we do not use,\ndnl #    gotta be fatal right?\ndnl # -Wno-reserved-id-macro -- configure script tends to define _GNU_SOURCE_,\ndnl #    __EXTENSIONS__ etc. which are underscored and reserved for compilers\ndnl # -Wno-padded -- NSPR and NSS headers get to issue lots of that\ndnl # -Wno-c++98-compat-pedantic -Wno-c++98-compat -- our C++ code uses nullptr\ndnl #    as requested by newer linters, and C++98 does not. We require C++11\ndnl #    or newer anyway, and skip building C++ library and test otherwise.\ndnl # -Wno-exit-time-destructors -- \"(static) const something\" items would be\ndnl #    de-allocated en-masse when the program exits, not GC'ed at run-time.\ndnl #    Oh well...\ndnl # -Wno-fuse-ld-path -- not much in our control what recipes the autotools\ndnl #    on the build host generate... this tries to avoid failures due to:\ndnl #      clang-13: error: '-fuse-ld=' taking a path is deprecated.\ndnl #      Use '--ld-path=' instead [-Werror,-Wfuse-ld-path]\ndnl # -Wno-unsafe-buffer-usage -- clang-16 introduced a check too smart for\ndnl #    its own good. It detects use of pointer aritmetics as arrays are\ndnl #    walked, which is indeed potentially dangerous. And also is nearly\ndnl #    unavoidable in C (at least not without major rewrites of the world).\ndnl # -Wno-documentation-unknown-command -fcomment-block-commands=retval --\ndnl #    some clang versions sanity-check Doxygen style comments, but do not\ndnl #    recognize \"\\retval\" key word. These options try to both ignore the\ndnl #    problematic area, and to add it as recognized (TODO: scripted check\ndnl #    for abilities of the current build's compiler instead)\ndnl ### Special exclusion picks for clang-medium (same as hard, plus...):\ndnl # -Wno-global-constructors -- using \"const something\" out of method context\ndnl #    potentially impacts start-up time and may be prone to race conditions\ndnl #    (for non-trivial interconnected objects), better be re-architected.\ndnl # -Wno-float-conversion -Wno-double-promotion -Wno-implicit-float-conversion\ndnl #    -- reduce noise due to floating-point literals like \"3.14\" being a C\ndnl #    double type (a \"3.14f\" literal is a C float) cast implicitly into\ndnl #    float variables. Also variadic functions like printf() cast their\ndnl #    floating-point arguments into double (and small integer types into\ndnl #    \"int\") which then confuses pedantic checks of printf(\"%f\", floatval).\ndnl # -Wno-conversion -- similarly for error: implicit conversion loses\ndnl #    floating-point precision: 'double' to 'float' [-Werror,-Wconversion]\ndnl #      max_output = atof(sValue);\ndnl # -Wno-cast-qual -- our code calls some library methods in ways which use\ndnl #    a \"const char *\" as a \"char *\" or vice-versa. Sometimes these method\ndnl #    signatures differ between dependency releases; sometimes they just\ndnl #    happened too hard to unravel cleanly and add more warnings.\ndnl #    This exclusion may be removed after common warnings are solved,\ndnl #    to allow progress on rectifying these cases next.\ndnl # -Wno-incompatible-pointer-types-discards-qualifiers -- our code often\ndnl #    defines (char*) as the type for struct fields and method arguments,\ndnl #    but initializes/passes (char[]) variables or fixed strings.\ndnl #    This makes at least clang-3.4 quite upset and noisy (seems newer\ndnl #    versions care less about this situation).\ndnl # -Wno-disabled-macro-expansion -- some system definitions of strncmp()\ndnl #    and other routines are in fact recursive macros. The -Weverything\ndnl #    mode of clang(-3.4) disables their handling, unless told otherwise.\ndnl # -Wno-incompatible-function-pointer-types-strict -- some system definitions\ndnl #    of methods for signals are not compatible with even those systems'\ndnl #    definitions of default signals, e.g. void vs. int arguments:\ndnl #        #define SIG_IGN (void (*)())1\ndnl #        extern void (*signal(int, void (*)(int)))(int);\ndnl #    (NUT signal handler methods do have the int signal number)\ndnl #    This is currently quiesced for clang-17; better solutions are welcome.\ndnl # -Wno-nullable-to-nonnull-conversion -- newer system headers are tagged\ndnl #    with hints about _Nullable vs. _Nonnull pointers. The general idea\ndnl #    is respectable for memory safety and could be addressed for true old\ndnl #    C99 toolkits and current language spec e.g. with macros... later.\ndnl #    Currently it is more like whack-a-mole as distros update headers.\nAS_CASE([\"${nut_enable_warnings}\"],\n    [all], [\n        CFLAGS=\"${CFLAGS} -Wall\"\n        CXXFLAGS=\"${CXXFLAGS} -Wall\"\n        ],\n    [clang-hard], [\n        CFLAGS=\"${CFLAGS} -ferror-limit=0 -Wno-system-headers -Wall -Wextra -Weverything -Wno-disabled-macro-expansion -Wno-unused-macros -Wno-reserved-id-macro -Wno-padded -Wno-documentation -fcomment-block-commands=retval -Wno-documentation-unknown-command -Wno-cast-qual -pedantic -Wno-fuse-ld-path -Wno-unsafe-buffer-usage\"\n        CXXFLAGS=\"${CXXFLAGS} -ferror-limit=0 -Wno-system-headers -Wall -Wextra -Weverything -Wno-disabled-macro-expansion -Wno-unused-macros -Wno-reserved-id-macro -Wno-padded -Wno-documentation -fcomment-block-commands=retval -Wno-documentation-unknown-command -Wno-cast-qual -Wno-c++98-compat-pedantic -Wno-c++98-compat -Wno-exit-time-destructors -Wno-fuse-ld-path -Wno-unsafe-buffer-usage\"\n        ],\n    [clang-medium], [\n        CFLAGS=\"${CFLAGS} -ferror-limit=0 -Wno-system-headers -Wall -Wextra -Weverything -Wno-disabled-macro-expansion -Wno-unused-macros -Wno-reserved-id-macro -Wno-padded -Wno-documentation -fcomment-block-commands=retval -Wno-documentation-unknown-command -Wno-cast-qual -pedantic -Wno-fuse-ld-path -Wno-unsafe-buffer-usage -Wno-float-conversion -Wno-double-promotion -Wno-implicit-float-conversion -Wno-conversion -Wno-incompatible-pointer-types-discards-qualifiers -Wno-incompatible-function-pointer-types-strict -Wno-nullable-to-nonnull-conversion\"\n        CXXFLAGS=\"${CXXFLAGS} -ferror-limit=0 -Wno-system-headers -Wall -Wextra -Weverything -Wno-disabled-macro-expansion -Wno-unused-macros -Wno-reserved-id-macro -Wno-padded -Wno-documentation -fcomment-block-commands=retval -Wno-documentation-unknown-command -Wno-cast-qual -Wno-c++98-compat-pedantic -Wno-c++98-compat -Wno-exit-time-destructors -Wno-global-constructors -Wno-fuse-ld-path -Wno-unsafe-buffer-usage -Wno-nullable-to-nonnull-conversion\"\n        ],\n    [clang-minimal], [\n        CFLAGS=\"${CFLAGS} -ferror-limit=0 -Wall -Wextra -Wno-documentation -Wno-documentation-unknown-command -fcomment-block-commands=retval\"\n        CXXFLAGS=\"${CXXFLAGS} -ferror-limit=0 -Wall -Wextra -Wno-documentation -Wno-documentation-unknown-command -fcomment-block-commands=retval\"\n        ],\n    [gcc-legacy], [CFLAGS=\"${CFLAGS} -Wall -Wsign-compare\"],\n    [gcc-minimal], [\n        dnl Builds with C89 (and aliases) are quite noisy for C99+ syntax used\n        dnl in NUT. The minimal-warnings should not complain in these builds.\n        dnl To make matters worse, many modern OS and third-party library\n        dnl headers can not be used with \"C90 + pedantic\" mode of GCC, either.\n        CFLAGS=\"${CFLAGS} -Wall -Wsign-compare\"\n        CXXFLAGS=\"${CXXFLAGS} -Wall -Wextra\"\n        AS_CASE([\"${CFLAGS}\"],\n            [*89*|*90*|*ansi*], [],\n            [CFLAGS=\"${CFLAGS} -Wextra -pedantic\"]\n        )\n        ],\n    [gcc-medium|gcc-hard], [\n        CFLAGS=\"${CFLAGS} -Wno-system-headers -Wall -Wextra -Wsign-compare\"\n        CXXFLAGS=\"${CXXFLAGS} -Wno-system-headers -Wall -Wextra\"\n        AS_CASE([\"${CFLAGS}\"],\n            [*89*|*90*|*ansi*], [],\n            [CFLAGS=\"${CFLAGS} -pedantic\"]\n        )\n        ]\n)\n\nAS_IF([test x\"${nut_enable_warnings}\" != xno || test x\"${nut_enable_Werror}\" != xno],\n    [AS_IF([test \"x${CLANGCC}\" = \"xyes\" || test \"x${GCC}\" = \"xyes\"],\n        [AS_CASE([\"${target_os}\"],\n            [*mingw*], [\n                AC_MSG_NOTICE(\n[GCC on WIN32 builds warns about '%lld' etc. via PRId64 etc.\neven though modern libraries support long-long printing\nin practice (older ones did not - hence the warning).\nForcing \"-Wno-format\" into warnings options.\n])\n                CFLAGS=\"${CFLAGS} -Wno-format\"\n                CXXFLAGS=\"${CXXFLAGS} -Wno-format\"\n            ]\n        )\n    ])\n])\n\nAC_MSG_CHECKING([whether to make warnings fatal])\nAS_CASE([\"${nut_enable_Werror}\"],\n    [yes|auto], [\n        CFLAGS=\"${CFLAGS} -Werror\"\n        CXXFLAGS=\"${CXXFLAGS} -Werror\"\n        ],\n    [no], [\n        CFLAGS=\"${CFLAGS} -Wno-error\"\n        CXXFLAGS=\"${CXXFLAGS} -Wno-error\"\n        ]\n)\nAC_MSG_RESULT([${nut_enable_Werror}])\n\ndnl Some compilers (e.g. older clang-3.4) have issues with built-in methods\ndnl that are implemented as macros in system headers -- but only for some\ndnl sources like snmp-ups.c, nutscan-serial.c, scan_eaton_serial.c, serial.c,\ndnl scan_avahi.c, scan_xml_http.c, scan_snmp.c... (Seems they all refer to\ndnl -DNETSNMP_USE_INLINE among other options, and tends to happen more with\ndnl OpenSSL-enabled builds). Check if we like them?\nAC_CHECK_HEADER([string.h],\n    [AC_LANG_PUSH([C])\n     CFLAGS_SAVED=\"${CFLAGS}\"\n     CFLAGS_BUILTIN_STR=\"-fno-builtin-strchr -fno-builtin-strcmp -fno-builtin-strncmp\"\n     CFLAGS=\"${CFLAGS} -Werror -Wunreachable-code ${LIBNETSNMP_CFLAGS} ${LIBLTDL_CFLAGS} ${LIBNEON_CFLAGS} ${LIBSSL_CFLAGS}\"\n     AC_MSG_CHECKING([whether we should disable string built-ins])\n     dnl AC_DEFINE([HAVE_STRING_H], [1], [Define to 1 if you have <string.h>.])\n     AC_COMPILE_IFELSE(\n        [AC_LANG_PROGRAM(\n            [[#include <string.h>\n            ]], [char *s = \"v1\", c = '%';\nif (strcmp(s, \"v1\") != 0) return 1;\nif (strchr(s, '1') == NULL) return 1;\nif (strchr(s, c) != NULL) return 1\n/* no \";return 0;\" here - autoconf adds one */\n            ])],\n        [CFLAGS=\"${CFLAGS_SAVED}\"\n         AC_MSG_RESULT([no, they are not a problem])],\n        [CFLAGS=\"${CFLAGS_BUILTIN_STR} ${CFLAGS}\"\n         AC_COMPILE_IFELSE(\n            [AC_LANG_PROGRAM(\n                [[#include <string.h>\n                ]], [char *s = \"v1\", c = '%';\nif (strcmp(s, \"v1\") != 0) return 1;\nif (strchr(s, '1') == NULL) return 1;\nif (strchr(s, c) != NULL) return 1\n/* no \";return 0;\" here - autoconf adds one */\n                ])],\n            [CFLAGS=\"${CFLAGS_BUILTIN_STR} ${CFLAGS_SAVED}\"\n             AC_MSG_RESULT([yes, this solves a problem])],\n            [CFLAGS=\"${CFLAGS_SAVED} -Werror -Wno-unreachable-code ${LIBNETSNMP_CFLAGS} ${LIBLTDL_CFLAGS} ${LIBNEON_CFLAGS} ${LIBSSL_CFLAGS}\"\n             AC_COMPILE_IFELSE(\n                [AC_LANG_PROGRAM(\n                    [[#include <string.h>\n                    ]], [char *s = \"mibs\", c = '%';\n/* Macro version of strcmp() has problems with strings shorter than\n * 3 or 4 bytes, so to avoid nailing \"-Warray-bounds\" as well,\n * here we just test for longer strings - existing NUT sources were\n * fixed for this situation already */\nif (strcmp(s, \"mibs\") != 0) return 1;\nif (strchr(s, 'b') == NULL) return 1;\nif (strchr(s, c) != NULL) return 1\n/* no \";return 0;\" here - autoconf adds one */\n                    ])],\n                [dnl CFLAGS=\"${CFLAGS_SAVED} -Wno-unreachable-code\"\n                 dnl NOTE: Empirically, constrain to just LIBNETSNMP_CFLAGS\n                 CFLAGS=\"${CFLAGS_SAVED}\"\n                 LIBLTDL_CFLAGS=\"${LIBLTDL_CFLAGS} -Wno-unreachable-code\"\n                 LIBNETSNMP_CFLAGS=\"${LIBNETSNMP_CFLAGS} -Wno-unreachable-code\"\n                 AC_MSG_RESULT([no, but -Wno-unreachable-code solves the problem for this compiler])],\n                [CFLAGS=\"${CFLAGS_SAVED}\"\n                 AC_MSG_RESULT([no, this does not solve the problem or is not supported])\n                ])\n            ])\n        ]\n     )\n     AC_LANG_POP([C])]\n)\n\ndnl Similar to above, for s_addr = htonl((ntohl(ip->start.s_addr) + 1));\ndnl which causes \"shadowed local variable\" as (re-)defined in nested macros.\ndnl Technically also needs to `#include <netinet/in.h>` for struct in_addr\ndnl but that should be pulled by inet.h anyway\nAC_CHECK_HEADER([arpa/inet.h],\n    [AC_LANG_PUSH([C])\n     CFLAGS_SAVED=\"${CFLAGS}\"\n     CFLAGS_BUILTIN_NTOHL=\"-fno-builtin-htonl -fno-builtin-ntohl\"\n     CFLAGS=\"${CFLAGS} -Werror -Wunreachable-code -Wshadow ${LIBNETSNMP_CFLAGS} ${LIBLTDL_CFLAGS} ${LIBNEON_CFLAGS} ${LIBSSL_CFLAGS}\"\n     AC_MSG_CHECKING([whether we should disable htonl/ntohl built-ins])\n     dnl AC_DEFINE([HAVE_ARPA_INET_H], [1], [Define to 1 if you have <arpa/inet.h>.])\n     AC_COMPILE_IFELSE(\n        [AC_LANG_PROGRAM(\n            [[#include <arpa/inet.h>\n            ]], [struct in_addr sin = {0};\nsin.s_addr = htonl((ntohl(sin.s_addr) + 1))\n/* no \";return 0;\" here - autoconf adds one */\n            ])],\n        [CFLAGS=\"${CFLAGS_SAVED}\"\n         AC_MSG_RESULT([no, they are not a problem])],\n        [CFLAGS=\"${CFLAGS_BUILTIN_NTOHL} ${CFLAGS}\"\n         AC_COMPILE_IFELSE(\n            [AC_LANG_PROGRAM(\n                [[#include <arpa/inet.h>\n                ]], [struct in_addr sin = {0};\nsin.s_addr = htonl((ntohl(sin.s_addr) + 1))\n/* no \";return 0;\" here - autoconf adds one */\n                ])],\n            [CFLAGS=\"${CFLAGS_BUILTIN_NTOHL} ${CFLAGS_SAVED}\"\n             AC_MSG_RESULT([yes, this solves a problem])],\n            [CFLAGS=\"${CFLAGS_SAVED} -Werror -Wno-shadow ${LIBNETSNMP_CFLAGS} ${LIBLTDL_CFLAGS} ${LIBNEON_CFLAGS} ${LIBSSL_CFLAGS}\"\n             AC_COMPILE_IFELSE(\n                [AC_LANG_PROGRAM(\n                    [[#include <arpa/inet.h>\n                    ]], [struct in_addr sin = {0};\nsin.s_addr = htonl((ntohl(sin.s_addr) + 1))\n                    ])],\n                [CFLAGS=\"${CFLAGS_SAVED}\"\n                 LIBLTDL_CFLAGS=\"${LIBLTDL_CFLAGS} -Wno-shadow\"\n                 LIBNETSNMP_CFLAGS=\"${LIBNETSNMP_CFLAGS} -Wno-shadow\"\n                 AC_MSG_RESULT([no, but -Wno-shadow solves the problem for this compiler])],\n                [CFLAGS=\"${CFLAGS_SAVED}\"\n                 AC_MSG_RESULT([no, this does not solve the problem or is not supported])\n                ])\n            ])\n        ]\n     )\n     AC_LANG_POP([C])]\n)\n\ndnl Finally restore warnings settings that the caller might have provided in CFLAGS etc\nNUT_POP_WARNINGS\n\ndnl Due to possibly repetitive content, generate unique settings\ndnl relative to the top_builddir (distcheck and all):\nAC_MSG_CHECKING([for top build dir for this configure run])\nTOP_BUILDDIR=\"\"\nAS_IF([test -n \"${ac_abs_top_builddir}\" && test -d \"${ac_abs_top_builddir}\"],\n    [TOP_BUILDDIR=\"${ac_abs_top_builddir}\"],\n    [AS_IF([test -n \"${ac_pwd}\" && test -d \"${ac_pwd}\"],\n        [TOP_BUILDDIR=\"${ac_pwd}\"],\n        [TOP_BUILDDIR=\"`dirname \"$0\"`\"\n         TOP_BUILDDIR=\"`cd \"$TOP_BUILDDIR\" && pwd`\" || AC_MSG_ERROR([Can not detect TOP_BUILDDIR])]\n    )]\n)\ndnl Quoted in case someone copy-pastes this path and it has whitespaces:\nAC_MSG_RESULT(['${TOP_BUILDDIR}'])\n\nABS_TOP_BUILDDIR=\"`cd \"${TOP_BUILDDIR}\" && pwd`\" || AC_MSG_ERROR([Can not detect ABS_TOP_BUILDDIR])\nABS_TOP_SRCDIR=\"`cd \"${abs_srcdir}\" && pwd`\" || AC_MSG_ERROR([Can not detect ABS_TOP_SRCDIR])\nAM_CONDITIONAL([BUILDING_IN_TREE], [test \"${ABS_TOP_BUILDDIR}\" = \"${ABS_TOP_SRCDIR}\"])\n\ndnl When building ON Windows (mingw/MSYS2, cygwin, etc.) fudge these\ndnl path strings back to what native OS methods would recognize.\nAS_CASE([${target_os}],\n    [*mingw*], [\n        AC_MSG_NOTICE([Will try to resolve Windows paths to ABS_TOP_SRCDIR and ABS_TOP_BUILDDIR with cygpath or mingw/msys pwd -W tool (would fail if not a native build)])\n\n        dnl Cygwin path resolver\n        AC_CHECK_TOOL([CYGPATH], [cygpath], [none])\n        AS_IF([test \"x${CYGPATH}\" != \"xnone\" && test x\"`${CYGPATH}`\" != x], [\n            tmp=\"`${CYGPATH} -m \"${ABS_TOP_BUILDDIR}\" | sed -e 's,/,\\\\\\\\\\\\\\\\,g'`\" && test -n \"$tmp\" && test -d \"$tmp\" && ABS_TOP_BUILDDIR=\"$tmp\"\n            tmp=\"`${CYGPATH} -m \"${ABS_TOP_SRCDIR}\" | sed 's,/,\\\\\\\\\\\\\\\\,g'`\" && test -n \"$tmp\" && test -d \"$tmp\" && ABS_TOP_SRCDIR=\"$tmp\"\n        ],[\n            dnl MSYS pwd with -W option to resolve\n            AC_CHECK_TOOL([PWDTOOL], [pwd], [none])\n            AS_IF([test \"x${PWDTOOL}\" != \"xnone\" && test x\"`${PWDTOOL} -W`\" != x], [\n                tmp=\"`(cd \"${ABS_TOP_BUILDDIR}\" && ${PWDTOOL} -W) | sed 's,/,\\\\\\\\\\\\\\\\,g'`\" && test -n \"$tmp\" && test -d \"$tmp\" && ABS_TOP_BUILDDIR=\"$tmp\"\n                tmp=\"`(cd \"${ABS_TOP_SRCDIR}\" && ${PWDTOOL} -W) | sed 's,/,\\\\\\\\\\\\\\\\,g'`\" && test -n \"$tmp\" && test -d \"$tmp\" && ABS_TOP_SRCDIR=\"$tmp\"\n            ])\n        ])\n\n        AC_MSG_NOTICE([FWIW, assuming ABS_TOP_SRCDIR=\"$ABS_TOP_SRCDIR\" and ABS_TOP_BUILDDIR=\"$ABS_TOP_BUILDDIR\"])\n])\n\ndnl Use these at best for tests (e.g. nutconf), not production code:\nAC_DEFINE_UNQUOTED([ABS_TOP_SRCDIR], [\"${ABS_TOP_SRCDIR}\"], [NUT source directory when the build was configured])\nAC_DEFINE_UNQUOTED([ABS_TOP_BUILDDIR], [\"${ABS_TOP_BUILDDIR}\"], [NUT build directory when the build was configured])\n\nAC_MSG_CHECKING([whether to customize ${TOP_BUILDDIR}/scripts/systemd/nut-common-tmpfiles.conf.in for this system])\ndnl TOTHINK: Some distributions make the directories below owned\ndnl by \"root:${RUN_AS_GROUP}\" with 77x permissions. Is it safer?..\nAS_IF([test -n \"$systemdtmpfilesdir\"],\n    [mkdir -p \"${TOP_BUILDDIR}\"/scripts/systemd\n     cat > \"${TOP_BUILDDIR}\"/scripts/systemd/nut-common-tmpfiles.conf.in << EOF\n# Network UPS Tools (NUT) systemd integration\n# Distributed under the terms of GPLv2+\n# See https://networkupstools.org/\n# and https://github.com/networkupstools/nut/\n\n# See also: https://github.com/networkupstools/nut/wiki/Technicalities:-Work-with-PID-and-state-file-paths#pidpath-altpidpath-statepath\n# State file (e.g. upsd to driver pipes) and PID file location for NUT:\nd @STATEPATH@ 0770 @RUN_AS_USER@ @RUN_AS_GROUP@ - -\n# Default PIPEFN and LOCKFN locations per upssched.conf:\nd @STATEPATH@/upssched 0770 @RUN_AS_USER@ @RUN_AS_GROUP@ - -\nX @STATEPATH@\nEOF\n    AS_IF([test \"$STATEPATH\" != \"$PIDPATH\"],\n        [AS_CASE([\"${PIDPATH}\"],\n            [*/run|*/tmp|*/shm], [], dnl Do not intrude into system paths; TODO: add more if appropriate for some Linux distro\n            [cat >> \"${TOP_BUILDDIR}\"/scripts/systemd/nut-common-tmpfiles.conf.in << EOF\n# Primarily used by upsmon and upslog, possibly running as root:\nd @PIDPATH@ 0770 @RUN_AS_USER@ @RUN_AS_GROUP@ - -\nX @PIDPATH@\nEOF\n])])\n    AS_IF([test -n \"$ALTPIDPATH\" && test \"$STATEPATH\" != \"$ALTPIDPATH\" && test \"$PIDPATH\" != \"$ALTPIDPATH\"],\n        [cat >> \"${TOP_BUILDDIR}\"/scripts/systemd/nut-common-tmpfiles.conf.in << EOF\n# Should be used as upsd and driver PID file location for NUT\n# (if ALTPIDPATH differs from STATEPATH):\nd @ALTPIDPATH@ 0770 @RUN_AS_USER@ @RUN_AS_GROUP@ - -\nX @ALTPIDPATH@\nEOF])\n    dnl Generally added to support some forks\n    AS_IF([test -n \"$ALTSTATEPATH\" && test \"$STATEPATH\" != \"$ALTSTATEPATH\" && test \"$ALTSTATEPATH\" != \"$ALTPIDPATH\" && test \"$PIDPATH\" != \"$ALTSTATEPATH\"],\n        [cat >> \"${TOP_BUILDDIR}\"/scripts/systemd/nut-common-tmpfiles.conf.in << EOF\n# Some NUT variants also maintain an ALTSTATEPATH:\nd @ALTSTATEPATH@ 0770 @RUN_AS_USER@ @RUN_AS_GROUP@ - -\nX @ALTSTATEPATH@\nEOF])\n])\nAC_MSG_RESULT([done])\n\ndnl # ccache versions 4.5 and newer support namespacing of the objects\ndnl # to facilitate more targeted eviction with --evict-namespace and\ndnl # perhaps --evict-older-than options. Here we bolt a namespace with\ndnl # NUT as the project and CPU architecture for resulting binaries;\ndnl # maybe we might use distro as well but some overlaps may be possible\ndnl # that result in same objects for different-looking build roots.\ndnl # Note this is enabled by default (explicit --without-... disables it).\ndnl # Has practical effect if NUT_AM_MAKE_CAN_EXPORT test is successful.\nAS_IF([test x\"${CCACHE_NAMESPACE}\" = x], [\n\tCCACHE_NAMESPACE=\"nut\"\n\tdnl # Variables in this list are defined earlier in the script\n\tfor T in \"${compiler_multiarch}\" \"${target_alias}\" \"${target}\" \"${target_cpu}-${target_os}\" ; do\n\t\tif test x\"$T\" != x -a x\"$T\" != x- ; then\n\t\t\tCCACHE_NAMESPACE=\"${CCACHE_NAMESPACE}:${T}\"\n\t\t\tbreak\n\t\tfi\n\tdone\n\tunset T\n])\nAC_ARG_WITH(CCACHE_NAMESPACE,\n\tAS_HELP_STRING([--with-CCACHE_NAMESPACE=namespace], [which ccache namespace to use for built binaries; typically nut:${autotools_target})]),\n[\n\tcase \"${withval}\" in\n\tno)\n\t\tCCACHE_NAMESPACE=\"\"\n\t\t;;\n\tyes)\t# Use user envvar or calculation above\n\t\t;;\n\t*)\n\t\tCCACHE_NAMESPACE=\"${withval}\"\n\t\t;;\n\tesac\n], [])\nNUT_REPORT_TARGET(CCACHE_NAMESPACE, \"${CCACHE_NAMESPACE}\", [ccache namespace tag (if ccache is used and new enough)])\nAS_IF([test x\"$CCACHE_NAMESPACE\" != x -a x\"$NUT_AM_MAKE_CAN_EXPORT\" != x], [\n\tAC_MSG_WARN([CCACHE_NAMESPACE setting may have no effect: this make implementation seems to not support \"export VAR=VAL\" syntax])\n])\n\ndnl # Mark it as a \"precious variable\", for more details see\ndnl # https://www.gnu.org/software/autoconf/manual/autoconf-2.69/html_node/Setting-Output-Variables.html\nAC_ARG_VAR(CCACHE_NAMESPACE)\n\ndnl # Also list some other ccache options which ci_build.sh can fiddle with.\ndnl # While that script \"exports\" them so it can call both configuration and\ndnl # the build, their values may be unknown when a developer re-runs \"make\".\ndnl # Normally most of the options would persist under $CCACHE_DIR/ccache.conf\ndnl # and we would not pass them via envvars.\nAC_ARG_VAR(CCACHE_BASEDIR)\nAC_ARG_VAR(CCACHE_DIR)\nAC_ARG_VAR(CCACHE_PATH)\n\ndnl Some versions of ccache take poorly to an exported empty CCACHE_DIR etc.\ndnl Avoid exporting them if not set at the configure time (assuming ci_build.sh\ndnl integration or user's shell profile sets them persistently)\nAS_IF([test x\"${CCACHE_NAMESPACE-}\" = x], [NUT_AM_EXPORT_CCACHE_NAMESPACE=\"#\"], [NUT_AM_EXPORT_CCACHE_NAMESPACE=\"\"])\nAC_SUBST(NUT_AM_EXPORT_CCACHE_NAMESPACE)\nAS_IF([test x\"${CCACHE_BASEDIR-}\" = x], [NUT_AM_EXPORT_CCACHE_BASEDIR=\"#\"], [NUT_AM_EXPORT_CCACHE_BASEDIR=\"\"])\nAC_SUBST(NUT_AM_EXPORT_CCACHE_BASEDIR)\nAS_IF([test x\"${CCACHE_DIR-}\" = x], [NUT_AM_EXPORT_CCACHE_DIR=\"#\"], [NUT_AM_EXPORT_CCACHE_DIR=\"\"])\nAC_SUBST(NUT_AM_EXPORT_CCACHE_DIR)\n\ndnl Application of PATH_DURING_CONFIGURE is also fenced by NUT_AM_EXPORT_CCACHE_PATH:\nAS_IF([test x\"${CCACHE_PATH-}\" = x], [NUT_AM_EXPORT_CCACHE_PATH=\"#\"], [NUT_AM_EXPORT_CCACHE_PATH=\"\"])\nAC_SUBST(NUT_AM_EXPORT_CCACHE_PATH)\nPATH_DURING_CONFIGURE=\"$PATH\"\nAC_SUBST(PATH_DURING_CONFIGURE)\n\ndnl Some binaries, like CPPUNIT tests, have similar flags already added\ndnl We might wipe their specific options below if consistently applying\ndnl debug-friendly options to everything\nAC_MSG_NOTICE([CONFIG_CFLAGS='${CONFIG_CFLAGS}'])\nAC_MSG_NOTICE([CONFIG_CXXFLAGS='${CONFIG_CXXFLAGS}'])\nAC_MSG_CHECKING([whether to enable debug info in all NUT binaries])\nnut_with_debuginfo_C=\"${nut_with_debuginfo}\"\nnut_with_debuginfo_CXX=\"${nut_with_debuginfo}\"\nAS_CASE([\"${CONFIG_CFLAGS}\"],\n    [*-O*|*-g*], [\n        AS_IF([test x\"${nut_with_debuginfo_C}\" = xauto], [\n            nut_with_debuginfo_C=\"Related settings already specified by caller CFLAGS, not changing anything\"\n            ])\n        ],\n    [   dnl No competing options are provided\n        AS_IF([test x\"${nut_with_debuginfo_C}\" = xauto], [nut_with_debuginfo_C=\"yes\"])\n    ])\n\nAS_CASE([\"${CONFIG_CXXFLAGS}\"],\n    [*-O*|*-g*], [\n        AS_IF([test x\"${nut_with_debuginfo_CXX}\" = xauto], [\n            nut_with_debuginfo_CXX=\"Related settings already specified by caller CXXFLAGS, not changing anything\"\n            ])\n        ],\n    [   dnl No competing options are provided\n        AS_IF([test x\"${nut_with_debuginfo_CXX}\" = xauto], [nut_with_debuginfo_CXX=\"yes\"])\n    ])\n\nAS_CASE([\"${nut_with_debuginfo_C}\"],\n    [yes], [\n        AS_IF([test x\"${CLANGCC}\" = x\"yes\" -o x\"${GCC}\" = x\"yes\"], [\n            dnl Where we can enable debug, minimize the optimizations.\n            dnl On some platforms LIBNETSNMP_CFLAGS or some such defines\n            dnl _FORTIFY_SOURCE=N which in turn \"requires compiling with\n            dnl optimization\", so we can not disable it in CFLAGS applied\n            dnl in the end of each and every build command line (highest\n            dnl priority). However, CPPFLAGS are before (making these\n            dnl lines an implementation-dependent hack)...\n            dnl AS_IF([set | grep -E 'FORTIFY_SOURCE'], [], [CFLAGS=\"${CFLAGS} -O0\"])\n            CPPFLAGS=\"${CPPFLAGS} -O0\"\n            CFLAGS=\"${CFLAGS} -g3 -gdwarf-2\"\n            ],[nut_with_debuginfo_C=\"Unknown C compiler, not adding options\"]\n        )],\n    dnl # [no]: By default we do not add debug info\n    [legacy], [\n        dnl # Apply legacy defaults if no flags were specified by caller or detected by autoconf\n        AS_IF([test x\"${CFLAGS_AFTER_ACPROG}\" = x],\t[CFLAGS=\"-O ${CFLAGS}\"])\n        ]\n)\n\nAS_CASE([\"${nut_with_debuginfo_CXX}\"],\n    [yes], [\n        AS_IF([test \"x$CLANGXX\" = xyes -o \"x$GXX\" = xyes], [\n            dnl Where we can enable debug, minimize the optimizations.\n            dnl NOTE: Concerns for -O0 behavior commented above are about C code,\n            dnl not seen (yet) with C++.\n            CXXFLAGS=\"${CXXFLAGS} -O0 -g3 -gdwarf-2\"\n            dnl Use same settings for CPPUNIT tests (they bump their own by default)\n            CPPUNIT_NUT_CXXFLAGS=\"\"\n            ],[nut_with_debuginfo_CXX=\"Unknown C++ compiler, not adding options\"]\n        )],\n    dnl # [no]: By default we do not add debug info\n    [legacy], [\n        dnl # Apply legacy defaults if no flags were specified by caller or detected by autoconf\n        AS_IF([test x\"${CXXFLAGS_AFTER_ACPROG}\" = x],\t[CXXFLAGS=\"-O ${CXXFLAGS}\"])\n        ]\n)\n\nAC_MSG_RESULT([C: ${nut_with_debuginfo_C}; C++: ${nut_with_debuginfo_CXX}])\n\ndnl Only in the end, do you understand...\nAC_SUBST(CPPUNIT_NUT_CXXFLAGS)\n\nAC_MSG_NOTICE([Generating \"data\" files from templates, see below for executable scripts])\nAC_CONFIG_FILES([\n clients/Makefile\n common/Makefile\n conf/Makefile\n conf/upsmon.conf.sample\n conf/upssched.conf.sample\n data/html/header.html\n data/html/Makefile\n data/Makefile\n data/driver.list\n docs/Makefile\n docs/cables/Makefile\n docs/docinfo.xml\n docs/man/Makefile\n drivers/Makefile\n include/Makefile\n lib/libupsclient.pc\n lib/libnutclient.pc\n lib/libnutclientstub.pc\n lib/libnutscan.pc\n lib/Makefile\n scripts/Aix/nut-aix.spec\n scripts/RedHat/ups\n scripts/augeas/Makefile\n scripts/augeas/nutnutconf.aug\n scripts/augeas/nutupsdconf.aug\n scripts/augeas/nutupsdusers.aug\n scripts/augeas/nutupsmonconf.aug\n scripts/augeas/nutupsschedconf.aug\n scripts/augeas/nuthostsconf.aug\n scripts/augeas/nutupssetconf.aug\n scripts/avahi/nut.service\n scripts/devd/Makefile\n scripts/hotplug/Makefile\n scripts/hotplug/libhidups\n scripts/HP-UX/nut.psf\n scripts/installer/Makefile\n scripts/python/Makefile\n scripts/python/module/Makefile\n scripts/python/module/PyNUT.py\n scripts/python/module/setup.py\n scripts/upsdrvsvcctl/Makefile\n scripts/systemd/Makefile\n scripts/systemd/nut.target\n scripts/systemd/nut-common-tmpfiles.conf\n scripts/systemd/nut-driver.target\n scripts/systemd/nut-driver@.service\n scripts/systemd/nut-logger.service\n scripts/systemd/nut-monitor.service\n scripts/systemd/nut-server.service\n scripts/systemd/nut-driver-enumerator.service\n scripts/systemd/nut-driver-enumerator.path\n scripts/systemd/nut-driver-enumerator-daemon.service\n scripts/systemd/nut-driver-enumerator-daemon-activator.service\n scripts/systemd/nut-driver-enumerator-daemon-activator.path\n scripts/Solaris/nut-driver-enumerator.xml\n scripts/Solaris/nut-driver.xml\n scripts/Solaris/nut-logger.xml\n scripts/Solaris/nut-monitor.xml\n scripts/Solaris/nut-server.xml\n scripts/Solaris/nut.xml\n scripts/Solaris/Makefile\n scripts/Solaris/pkginfo\n scripts/udev/Makefile\n scripts/udev/nut-ipmipsu.rules\n scripts/ufw/Makefile\n scripts/ufw/nut.ufw.profile\n scripts/Windows/Makefile\n scripts/Windows/Installer/NUT-Installer.xml\n scripts/Makefile\n server/Makefile\n tools/Makefile\n tools/nut-scanner/Makefile\n tools/nutconf/Makefile\n tests/Makefile\n tests/NIT/Makefile\n Makefile\n])\n\nAC_MSG_NOTICE([Generating templated script files that should be marked executable])\nm4_foreach_w([SCRIPTFILE], [\n lib/libupsclient-config\n scripts/Aix/nut.init\n scripts/HP-UX/postinstall\n scripts/RedHat/upsd\n scripts/RedHat/upsmon\n scripts/python/app/NUT-Monitor-py2gtk2\n scripts/python/app/NUT-Monitor-py3qt5\n scripts/augeas/gen-nutupsconf-aug.py\n scripts/python/module/test_nutclient.py\n scripts/upsdrvsvcctl/nut-driver-enumerator.sh\n scripts/upsdrvsvcctl/upsdrvsvcctl\n scripts/systemd/nutshutdown\n scripts/Solaris/svc-nut-server\n scripts/Solaris/svc-nut-logger\n scripts/Solaris/svc-nut-monitor\n scripts/Solaris/precheck.py\n scripts/Solaris/preinstall\n scripts/Solaris/postinstall\n scripts/Solaris/preremove\n scripts/Solaris/postremove\n scripts/Solaris/preproto.pl\n scripts/Solaris/nut\n tools/gitlog2changelog.py\n tools/nut-snmpinfo.py\n], [\n dnl Autoconf substitutes the token above specified in plain text,\n dnl e.g. the brace below is empty and bracket gives verbatim varname\n dnl AC_MSG_NOTICE([Script: SCRIPTFILE brace:(${SCRIPTFILE}) bracket:([SCRIPTFILE])])\n AC_CONFIG_FILES(SCRIPTFILE, chmod +x \"SCRIPTFILE\")\n])\n\nAC_MSG_NOTICE([Generating templated script files whose templates might have been generated (or not) by autogen.sh calling our helper scripts])\nm4_foreach_w([SCRIPTFILE], [\n scripts/augeas/nutupsconf.aug\n scripts/udev/nut-usbups.rules\n scripts/devd/nut-usb.conf\n], [\n\tAC_MSG_CHECKING([whether to generate SCRIPTFILE])\n\tAS_IF([test -s SCRIPTFILE.in && ! test -f SCRIPTFILE.in.AUTOGEN_WITHOUT],\n\t\t[AC_MSG_RESULT(yes)\n\t\t AC_CONFIG_FILES(SCRIPTFILE)],\n\t\t[AC_MSG_RESULT(no)]\n\t)\n])\n\ndnl Define this before AC_OUTPUT(), so not inside the report routine below:\nAM_CONDITIONAL(KEEP_NUT_REPORT, test x\"${nut_enable_keep_nut_report_feature-}\" = xyes)\n\ndnl Prints a long list of files generated from templates...\nAC_OUTPUT\n\ndnl Normally the latest action, for the summary to be visible:\nNUT_REPORT_COMPILERS\nNUT_PRINT_FEATURE_REPORT\n\ndnl Stopping short of patching the unknown script, we can warn about the issue\ndnl (visibly as it impacts next activities of the caller):\nAS_IF([test -s \"${ABS_TOP_SRCDIR}/install-sh\" && grep -w MKDIRPROG \"${ABS_TOP_SRCDIR}/install-sh\" >/dev/null],\n\t[AS_IF([grep -v '#' \"${ABS_TOP_SRCDIR}/install-sh\" | grep -E '\\$mkdirprog.*-p' >/dev/null],\n\t\t[],\n\t\t[AC_MSG_WARN([=====================================================])\n\t\t AC_MSG_WARN([Your system provided (or NUT tarball included) an])\n\t\t AC_MSG_WARN(['install-sh' implementation which is not safe for])\n\t\t AC_MSG_WARN([parallel installs; export MKDIRPROG='mkdir -p'])\n\t\t AC_MSG_WARN([may help, otherwise run 'make install' sequentially.])\n\t\t AC_MSG_WARN([This should not impact parallel builds.])\n\t\t AC_MSG_WARN([=====================================================])\n\t])\n])\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "drivers",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "indent.sh",
          "type": "blob",
          "size": 1.8125,
          "content": "#!/usr/bin/env bash\n\n# Filter NUT C source file style to conform to recommendations of\n# https://www.networkupstools.org/docs/developer-guide.chunked/ar01s03.html#_coding_style\n# Note that the sed filter \"command does a reasonable job of converting\n# most C++ style comments (but not URLs and DOCTYPE strings)\" so a manual\n# pass may be needed to revise the changes.\n#\n# Since that the result is not always immediately acceptable, so this script\n# is not part of e.g. automated testing - but it helps clean up much of the\n# codebase to be up to a common spec.\n#\n# Script wrapping (C) 2017 by Jim Klimov\n# Rules (C) long ago by NUT project team\n\nset -o pipefail\n\nTMPFILE=\".style-tmp.$$\"\ntrap 'EXITCODE=$? ; rm -f \"$TMPFILE\" ; exit $EXITCODE' 0 1 2 3 15\n\nconvertFile() {\n    SRCFILE=\"$1\"\n\n    # TODO: The indent below does a poor job for C++\n    cat \"$SRCFILE\" \\\n        | indent -kr -i8 -T FILE -l1000 -nhnl \\\n        | sed 's#\\(^\\|[ \\t]\\)//[ \\t]*\\(.*\\)[ \\t]*#/* \\2 */#' \\\n        > \"$TMPFILE\"\n    STEPCODE=$?\n    if [ \"$STEPCODE\" != 0 ]; then\n        TOTALCODE=\"$STEPCODE\"\n        echo \"FAILED to process file: $SRCFILE\" >&2\n        continue\n    fi\n\n    if diff -q \"$SRCFILE\" \"$TMPFILE\" ; then\n        echo \"File was not changed: $SRCFILE\" >&2\n    else\n        echo \"File was changed: $SRCFILE - please revise the differences\" >&2\n        meld \"$SRCFILE\" \"$TMPFILE\"\n    fi\n}\n\nTOTALCODE=0\nif [ $# = 0 ] ; then\n    git ls-files | grep -E '\\.(c|h)$' | while read F ; do\n        convertFile \"$F\"\n    done\nelse\n    case \"$1\" in\n        -h|--help)\n            echo \"Usage: $0 [file.c] [header.h] - process listed file(s)\"\n            echo \"Usage: $0 - process all .c and .h files currently tracked in Git repo\"\n            ;;\n        *)\n            for F in \"$@\" ; do\n                convertFile \"$F\"\n            done\n            ;;\n    esac\nfi\n\nexit $TOTALCODE\n"
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "m4",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}