{
  "metadata": {
    "timestamp": 1736710030374,
    "page": 638,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dog-qiuqiu/Yolo-Fastest",
      "stars": 2026,
      "defaultBranch": "master",
      "files": [
        {
          "name": "3rdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 20.9306640625,
          "content": "cmake_minimum_required(VERSION 3.18)\ninclude(CMakeDependentOption)\n\nset(Darknet_MAJOR_VERSION 0)\nset(Darknet_MINOR_VERSION 2)\nset(Darknet_PATCH_VERSION 5)\nset(Darknet_TWEAK_VERSION 4)\nset(Darknet_VERSION ${Darknet_MAJOR_VERSION}.${Darknet_MINOR_VERSION}.${Darknet_PATCH_VERSION}.${Darknet_TWEAK_VERSION})\n\noption(CMAKE_VERBOSE_MAKEFILE \"Create verbose makefile\" ON)\noption(CUDA_VERBOSE_BUILD \"Create verbose CUDA build\" ON)\noption(BUILD_SHARED_LIBS \"Create dark as a shared library\" ON)\noption(BUILD_AS_CPP \"Build Darknet using C++ compiler also for C files\" OFF)\noption(BUILD_USELIB_TRACK \"Build uselib_track\" ON)\noption(MANUALLY_EXPORT_TRACK_OPTFLOW \"Manually export the TRACK_OPTFLOW=1 define\" OFF)\noption(ENABLE_OPENCV \"Enable OpenCV integration\" ON)\noption(ENABLE_CUDA \"Enable CUDA support\" ON)\noption(ENABLE_CUDNN \"Enable CUDNN\" ON)\noption(ENABLE_CUDNN_HALF \"Enable CUDNN Half precision\" ON)\noption(ENABLE_ZED_CAMERA \"Enable ZED Camera support\" ON)\noption(ENABLE_VCPKG_INTEGRATION \"Enable VCPKG integration\" ON)\n\nif(CMAKE_COMPILER_IS_GNUCC OR \"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n  set(CMAKE_COMPILER_IS_GNUCC_OR_CLANG TRUE)\n  if(\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n    set(CMAKE_COMPILER_IS_CLANG TRUE)\n  else()\n    set(CMAKE_COMPILER_IS_CLANG FALSE)\n  endif()\nelse()\n  set(CMAKE_COMPILER_IS_GNUCC_OR_CLANG FALSE)\n  set(CMAKE_COMPILER_IS_CLANG FALSE)\nendif()\n\nif(NOT CMAKE_HOST_SYSTEM_PROCESSOR AND NOT WIN32)\n  execute_process(COMMAND \"uname\" \"-m\" OUTPUT_VARIABLE CMAKE_HOST_SYSTEM_PROCESSOR OUTPUT_STRIP_TRAILING_WHITESPACE)\nendif()\n\nif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"x86\")\n  set(IS_X86 TRUE)\nelse()\n  set(IS_X86 FALSE)\nendif()\n\ncmake_dependent_option(ENABLE_SSE_AND_AVX_FLAGS \"Enable AVX and SSE optimizations (x86-only)\" ON \"CMAKE_COMPILER_IS_GNUCC_OR_CLANG;IS_X86\" OFF)\n\nif(ENABLE_VCPKG_INTEGRATION AND DEFINED ENV{VCPKG_ROOT} AND NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(CMAKE_TOOLCHAIN_FILE \"$ENV{VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake\" CACHE STRING \"\")\n  set(_VCPKG_INSTALLED_DIR ${CMAKE_CURRENT_LIST_DIR}/vcpkg CACHE STRING \"\")\n  message(STATUS \"VCPKG found: $ENV{VCPKG_ROOT}\")\n  message(STATUS \"Using VCPKG integration\")\n  message(STATUS \"Installing dependencies in ${_VCPKG_INSTALLED_DIR}\")\nendif()\n\nproject(Darknet VERSION ${Darknet_VERSION})\n\nif(WIN32 AND NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(USE_INTEGRATED_LIBS \"TRUE\" CACHE BOOL \"Use libs distributed with this repo\")\nelse()\n  set(USE_INTEGRATED_LIBS \"FALSE\" CACHE BOOL \"Use libs distributed with this repo\")\nendif()\n\nenable_language(C)\nenable_language(CXX)\n\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_MODULE_PATH \"${CMAKE_CURRENT_LIST_DIR}/cmake/Modules/\" ${CMAKE_MODULE_PATH})\n\nset(default_build_type \"Release\")\nif(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)\n  message(STATUS \"Setting build type to '${default_build_type}' as none was specified.\")\n  set(CMAKE_BUILD_TYPE \"${default_build_type}\" CACHE\n      STRING \"Choose the type of build.\" FORCE)\n  # Set the possible values of build type for cmake-gui\n  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS\n    \"Debug\" \"Release\" \"MinSizeRel\" \"RelWithDebInfo\")\nendif()\n\nif(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT)\n  set(CMAKE_INSTALL_PREFIX \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Install prefix\" FORCE)\nendif()\n\nset(INSTALL_BIN_DIR      \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Path where exe and dll will be installed\")\nset(INSTALL_LIB_DIR      \"${CMAKE_CURRENT_LIST_DIR}\" CACHE PATH \"Path where lib will be installed\")\nset(INSTALL_INCLUDE_DIR  \"include/darknet\"           CACHE PATH \"Path where headers will be installed\")\nset(INSTALL_CMAKE_DIR    \"share/darknet\"             CACHE PATH \"Path where cmake configs will be installed\")\n\nif(ENABLE_CUDA)\n  include(CheckLanguage)\n  check_language(CUDA)\n  if(NOT CMAKE_CUDA_COMPILER)\n    message(FATAL_ERROR \"CUDA not found, please build explicitly with -DENABLE_CUDA=OFF if you do not want CUDA\")\n  elseif(ENABLE_CUDA)\n    enable_language(CUDA)\n    if(CMAKE_CUDA_COMPILER_VERSION VERSION_LESS \"9.0\")\n      message(FATAL_ERROR \"Unsupported CUDA version, please upgrade to CUDA 9+ or disable CUDA with explicitly with -DENABLE_CUDA=OFF\")\n    else()\n      message(STATUS \"Selected CMAKE_CUDA_ARCHITECTURES: ${CMAKE_CUDA_ARCHITECTURES}\")\n      if(70 IN_LIST CMAKE_CUDA_ARCHITECTURES OR\n         72 IN_LIST CMAKE_CUDA_ARCHITECTURES OR\n         75 IN_LIST CMAKE_CUDA_ARCHITECTURES OR\n         80 IN_LIST CMAKE_CUDA_ARCHITECTURES OR\n         86 IN_LIST CMAKE_CUDA_ARCHITECTURES)\n        set(ENABLE_CUDNN_HALF \"TRUE\" CACHE BOOL \"Enable CUDNN Half precision\" FORCE)\n        message(STATUS \"Your setup supports half precision (it requires CC >= 7.0)\")\n      else()\n        set(ENABLE_CUDNN_HALF \"FALSE\" CACHE BOOL \"Enable CUDNN Half precision\" FORCE)\n        message(STATUS \"Your setup does not support half precision (it requires CC >= 7.0)\")\n      endif()\n    endif()\n    if(BUILD_SHARED_LIBS)\n      set(CMAKE_CUDA_RUNTIME_LIBRARY \"Shared\")\n    else()\n      set(CMAKE_CUDA_RUNTIME_LIBRARY \"Static\")\n    endif()\n  endif()\nendif()\n\nif(WIN32 AND ENABLE_CUDA AND CMAKE_MAKE_PROGRAM MATCHES \"ninja\")\n  option(SELECT_OPENCV_MODULES \"Use only few selected OpenCV modules to circumvent 8192 char limit when using Ninja on Windows\" ON)\nelse()\n  option(SELECT_OPENCV_MODULES \"Use only few selected OpenCV modules to circumvent 8192 char limit when using Ninja on Windows\" OFF)\nendif()\n\nif(USE_INTEGRATED_LIBS)\n  set(PThreads_windows_DIR ${CMAKE_CURRENT_LIST_DIR}/3rdparty/pthreads CACHE PATH \"Path where pthreads for windows can be located\")\nendif()\nset(Stb_DIR ${CMAKE_CURRENT_LIST_DIR}/3rdparty/stb CACHE PATH \"Path where Stb image library can be located\")\n\nset(CMAKE_DEBUG_POSTFIX d)\nset(CMAKE_THREAD_PREFER_PTHREAD ON)\nfind_package(Threads REQUIRED)\nif(MSVC)\n  find_package(PThreads_windows REQUIRED)\nendif()\nif(ENABLE_OPENCV)\n  find_package(OpenCV)\n  if(OpenCV_FOUND)\n    if(SELECT_OPENCV_MODULES)\n      if(TARGET opencv_world)\n        list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_world\")\n      else()\n        if(TARGET opencv_core)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_core\")\n        endif()\n        if(TARGET opencv_highgui)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_highgui\")\n        endif()\n        if(TARGET opencv_imgproc)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_imgproc\")\n        endif()\n        if(TARGET opencv_video)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_video\")\n        endif()\n        if(TARGET opencv_videoio)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_videoio\")\n        endif()\n        if(TARGET opencv_imgcodecs)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_imgcodecs\")\n        endif()\n        if(TARGET opencv_text)\n          list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_text\")\n        endif()\n      endif()\n    else()\n      list(APPEND OpenCV_LINKED_COMPONENTS ${OpenCV_LIBS})\n    endif()\n  endif()\nendif()\nfind_package(Stb REQUIRED)\nfind_package(OpenMP)\n\nif(APPLE AND NOT OPENMP_FOUND)\n  message(STATUS \"  ->  To enable OpenMP on macOS, please install libomp from Homebrew\")\nendif()\n\nset(ADDITIONAL_CXX_FLAGS \"-Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -Wno-deprecated-declarations -Wno-write-strings\")\nset(ADDITIONAL_C_FLAGS \"-Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -Wno-deprecated-declarations -Wno-write-strings\")\n\nif(MSVC)\n  set(ADDITIONAL_CXX_FLAGS \"/wd4013 /wd4018 /wd4028 /wd4047 /wd4068 /wd4090 /wd4101 /wd4113 /wd4133 /wd4190 /wd4244 /wd4267 /wd4305 /wd4477 /wd4996 /wd4819 /fp:fast\")\n  set(ADDITIONAL_C_FLAGS \"/wd4013 /wd4018 /wd4028 /wd4047 /wd4068 /wd4090 /wd4101 /wd4113 /wd4133 /wd4190 /wd4244 /wd4267 /wd4305 /wd4477 /wd4996 /wd4819 /fp:fast\")\n  set(CMAKE_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} ${CMAKE_CXX_FLAGS}\")\n  set(CMAKE_C_FLAGS \"${ADDITIONAL_C_FLAGS} ${CMAKE_C_FLAGS}\")\n  string(REGEX REPLACE \"/O2\" \"/Ox\" CMAKE_CXX_FLAGS_RELEASE ${CMAKE_CXX_FLAGS_RELEASE})\n  string(REGEX REPLACE \"/O2\" \"/Ox\" CMAKE_C_FLAGS_RELEASE ${CMAKE_C_FLAGS_RELEASE})\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCC_OR_CLANG)\n  if(CMAKE_COMPILER_IS_CLANG)\n    if(UNIX AND NOT APPLE)\n      set(CMAKE_CXX_FLAGS \"-pthread ${CMAKE_CXX_FLAGS}\")  #force pthread to avoid bugs in some cmake setups\n      set(CMAKE_C_FLAGS \"-pthread ${CMAKE_C_FLAGS}\")\n    endif()\n  endif()\n  set(CMAKE_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} ${CMAKE_CXX_FLAGS}\")\n  set(CMAKE_C_FLAGS \"${ADDITIONAL_C_FLAGS} ${CMAKE_C_FLAGS}\")\n  string(REGEX REPLACE \"-O0\" \"-Og\" CMAKE_CXX_FLAGS_DEBUG ${CMAKE_CXX_FLAGS_DEBUG})\n  string(REGEX REPLACE \"-O3\" \"-Ofast\" CMAKE_CXX_FLAGS_RELEASE ${CMAKE_CXX_FLAGS_RELEASE})\n  string(REGEX REPLACE \"-O0\" \"-Og\" CMAKE_C_FLAGS_DEBUG ${CMAKE_C_FLAGS_DEBUG})\n  string(REGEX REPLACE \"-O3\" \"-Ofast\" CMAKE_C_FLAGS_RELEASE ${CMAKE_C_FLAGS_RELEASE})\n  if(ENABLE_SSE_AND_AVX_FLAGS)\n    set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\")\n    set(CMAKE_C_FLAGS_RELEASE \"${CMAKE_C_FLAGS_RELEASE} -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\")\n  endif()\nendif()\n\nif(OpenCV_FOUND)\n  if(ENABLE_CUDA AND NOT OpenCV_CUDA_VERSION)\n    set(BUILD_USELIB_TRACK \"FALSE\" CACHE BOOL \"Build uselib_track\" FORCE)\n    message(STATUS \"  ->  darknet is fine for now, but uselib_track has been disabled!\")\n    message(STATUS \"  ->  Please rebuild OpenCV from sources with CUDA support to enable it\")\n  elseif(ENABLE_CUDA AND OpenCV_CUDA_VERSION)\n    if(TARGET opencv_cudaoptflow)\n      list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_cudaoptflow\")\n    endif()\n    if(TARGET opencv_cudaimgproc)\n      list(APPEND OpenCV_LINKED_COMPONENTS \"opencv_cudaimgproc\")\n    endif()\n  endif()\nendif()\n\nif(ENABLE_CUDA AND ENABLE_CUDNN)\n  find_package(CUDNN)\nendif()\n\nif(ENABLE_CUDA)\n  if(MSVC)\n    set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DGPU\")\n    if(CUDNN_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DCUDNN\")\n    endif()\n    if(OpenCV_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} /DOPENCV\")\n    endif()\n    string(REPLACE \" \" \",\" ADDITIONAL_CXX_FLAGS_COMMA_SEPARATED \"${ADDITIONAL_CXX_FLAGS}\")\n    set(CUDA_HOST_COMPILER_FLAGS \"-Wno-deprecated-declarations -Xcompiler=\\\"${ADDITIONAL_CXX_FLAGS_COMMA_SEPARATED}\\\"\")\n  else()\n    set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DGPU\")\n    if(CUDNN_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DCUDNN\")\n    endif()\n    if(OpenCV_FOUND)\n      set(ADDITIONAL_CXX_FLAGS \"${ADDITIONAL_CXX_FLAGS} -DOPENCV\")\n    endif()\n    if(APPLE)\n        set(CUDA_HOST_COMPILER_FLAGS \"--compiler-options \\\" ${ADDITIONAL_CXX_FLAGS} -fPIC -Xpreprocessor -fopenmp -Ofast \\\"\")\n    else()\n        set(CUDA_HOST_COMPILER_FLAGS \"--compiler-options \\\" ${ADDITIONAL_CXX_FLAGS} -fPIC -fopenmp -Ofast \\\"\")\n    endif()\n  endif()\n\n  string (REPLACE \";\" \" \" CUDA_ARCH_FLAGS_SPACE_SEPARATED \"${CUDA_ARCH_FLAGS}\")\n  set(CMAKE_CUDA_FLAGS \"${CUDA_ARCH_FLAGS_SPACE_SEPARATED} ${CUDA_HOST_COMPILER_FLAGS} ${CMAKE_CUDA_FLAGS}\")\n  message(STATUS \"CMAKE_CUDA_FLAGS: ${CMAKE_CUDA_FLAGS}\")\nendif()\n\nif(ENABLE_CUDA AND ENABLE_ZED_CAMERA)\n  find_package(ZED 2 QUIET)\n  if(ZED_FOUND)\n    include_directories(${ZED_INCLUDE_DIRS})\n    link_directories(${ZED_LIBRARY_DIR})\n    message(STATUS \"ZED SDK enabled\")\n  else()\n    message(STATUS \"ZED SDK not found\")\n    set(ENABLE_ZED_CAMERA \"FALSE\" CACHE BOOL \"Enable ZED Camera support\" FORCE)\n  endif()\nelse()\n  if(ENABLE_ZED_CAMERA)\n    message(STATUS \"ZED SDK not enabled, since it requires CUDA\")\n  endif()\n  set(ENABLE_ZED_CAMERA \"FALSE\" CACHE BOOL \"Enable ZED Camera support\" FORCE)\nendif()\n\n# Make relative paths absolute (needed later on)\nforeach(p LIB BIN INCLUDE CMAKE)\n  set(var INSTALL_${p}_DIR)\n  if(NOT IS_ABSOLUTE \"${${var}}\")\n    set(FULLPATH_${var} \"${CMAKE_INSTALL_PREFIX}/${${var}}\")\n  endif()\nendforeach()\n\nconfigure_file(\n  \"${CMAKE_CURRENT_LIST_DIR}/src/version.h.in\"\n  \"${CMAKE_CURRENT_LIST_DIR}/src/version.h\"\n)\n\n#look for all *.h files in src folder\nfile(GLOB headers \"${CMAKE_CURRENT_LIST_DIR}/src/*.h\")\n#add also files in the include folder\nlist(APPEND headers\n  ${CMAKE_CURRENT_LIST_DIR}/include/darknet.h\n)\n#remove windows only files\nif(NOT MSVC)\n  list(REMOVE_ITEM headers\n    ${CMAKE_CURRENT_LIST_DIR}/src/gettimeofday.h\n    ${CMAKE_CURRENT_LIST_DIR}/src/getopt.h\n  )\nendif()\n#set(exported_headers ${headers})\n\n#look for all *.c files in src folder\nfile(GLOB sources \"${CMAKE_CURRENT_LIST_DIR}/src/*.c\")\n#add also .cpp files\nlist(APPEND sources\n  ${CMAKE_CURRENT_LIST_DIR}/src/http_stream.cpp\n  ${CMAKE_CURRENT_LIST_DIR}/src/image_opencv.cpp\n)\n#remove darknet.c file which is necessary only for the executable, not for the lib\nlist(REMOVE_ITEM sources\n  ${CMAKE_CURRENT_LIST_DIR}/src/darknet.c\n)\n#remove windows only files\nif(NOT MSVC)\n  list(REMOVE_ITEM sources\n    ${CMAKE_CURRENT_LIST_DIR}/src/gettimeofday.c\n    ${CMAKE_CURRENT_LIST_DIR}/src/getopt.c\n  )\nendif()\n\nif(ENABLE_CUDA)\n  file(GLOB cuda_sources \"${CMAKE_CURRENT_LIST_DIR}/src/*.cu\")\nendif()\n\nif(BUILD_AS_CPP)\n  set_source_files_properties(${sources} PROPERTIES LANGUAGE CXX)\nendif()\n\nadd_library(dark ${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp ${CMAKE_CURRENT_LIST_DIR}/src/yolo_v2_class.cpp ${sources} ${headers} ${cuda_sources})\nset_target_properties(dark PROPERTIES POSITION_INDEPENDENT_CODE ON)\nif(ENABLE_CUDA)\n  set_target_properties(dark PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\nendif()\nif(BUILD_SHARED_LIBS)\n  target_compile_definitions(dark PRIVATE LIB_EXPORTS=1)\nendif()\nif(BUILD_AS_CPP)\n  set_target_properties(dark PROPERTIES LINKER_LANGUAGE CXX)\nendif()\nset_target_properties(dark PROPERTIES OUTPUT_NAME \"darknet\")\n\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  add_executable(uselib_track ${CMAKE_CURRENT_LIST_DIR}/src/yolo_console_dll.cpp)\nendif()\n\nadd_executable(uselib ${CMAKE_CURRENT_LIST_DIR}/src/yolo_console_dll.cpp)\nif(BUILD_AS_CPP)\n  set_target_properties(uselib PROPERTIES LINKER_LANGUAGE CXX)\nendif()\n\nadd_executable(darknet ${CMAKE_CURRENT_LIST_DIR}/src/darknet.c ${sources} ${headers} ${cuda_sources})\nif(BUILD_AS_CPP)\n  set_source_files_properties(${CMAKE_CURRENT_LIST_DIR}/src/darknet.c PROPERTIES LANGUAGE CXX)\n  set_target_properties(darknet PROPERTIES LINKER_LANGUAGE CXX)\nendif()\n\ntarget_include_directories(darknet PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\ntarget_include_directories(dark PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\ntarget_include_directories(uselib PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/include> $<BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}/src> $<INSTALL_INTERFACE:${INSTALL_INCLUDE_DIR}> $<BUILD_INTERFACE:${Stb_INCLUDE_DIR}>)\n\ntarget_compile_definitions(darknet PRIVATE -DUSE_CMAKE_LIBS)\ntarget_compile_definitions(dark PRIVATE -DUSE_CMAKE_LIBS)\ntarget_compile_definitions(uselib PRIVATE -DUSE_CMAKE_LIBS)\n\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK AND NOT MANUALLY_EXPORT_TRACK_OPTFLOW)\n  target_compile_definitions(dark PUBLIC TRACK_OPTFLOW=1)\nendif()\n\nif(CUDNN_FOUND)\n  target_link_libraries(darknet PRIVATE CuDNN::CuDNN)\n  target_link_libraries(dark PRIVATE CuDNN::CuDNN)\n  target_compile_definitions(darknet PRIVATE -DCUDNN)\n  target_compile_definitions(dark PUBLIC -DCUDNN)\n  if(ENABLE_CUDNN_HALF)\n    target_compile_definitions(darknet PRIVATE -DCUDNN_HALF)\n    target_compile_definitions(dark PUBLIC -DCUDNN_HALF)\n  endif()\nendif()\n\nif(OpenCV_FOUND)\n  target_link_libraries(darknet PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  target_link_libraries(uselib PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  target_link_libraries(dark PUBLIC ${OpenCV_LINKED_COMPONENTS})\n  target_include_directories(dark PRIVATE ${OpenCV_INCLUDE_DIRS})\n  target_compile_definitions(darknet PRIVATE -DOPENCV)\n  target_compile_definitions(dark PUBLIC -DOPENCV)\nendif()\n\nif(OPENMP_FOUND)\n  target_link_libraries(darknet PRIVATE OpenMP::OpenMP_CXX)\n  target_link_libraries(darknet PRIVATE OpenMP::OpenMP_C)\n  target_link_libraries(dark PUBLIC OpenMP::OpenMP_CXX)\n  target_link_libraries(dark PUBLIC OpenMP::OpenMP_C)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCC)\n  target_link_libraries(darknet PRIVATE m)\n  target_link_libraries(dark PUBLIC m)\nendif()\n\nif(MSVC)\n  target_link_libraries(darknet PRIVATE PThreads_windows::PThreads_windows)\n  target_link_libraries(darknet PRIVATE wsock32)\n  target_link_libraries(dark PUBLIC PThreads_windows::PThreads_windows)\n  target_link_libraries(dark PUBLIC wsock32)\n  target_link_libraries(uselib PRIVATE PThreads_windows::PThreads_windows)\n  target_compile_definitions(darknet PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  target_compile_definitions(dark PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  target_compile_definitions(dark PUBLIC -D_CRT_SECURE_NO_WARNINGS)\n  target_compile_definitions(uselib PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\nendif()\n\nif(MSVC OR MINGW)\n  target_link_libraries(darknet PRIVATE ws2_32)\n  target_link_libraries(dark PUBLIC ws2_32)\nendif()\n\ntarget_link_libraries(darknet PRIVATE Threads::Threads)\ntarget_link_libraries(dark PUBLIC Threads::Threads)\ntarget_link_libraries(uselib PRIVATE Threads::Threads)\n\nif(ENABLE_ZED_CAMERA)\n  target_link_libraries(darknet PRIVATE ${ZED_LIBRARIES})\n  target_link_libraries(dark PUBLIC ${ZED_LIBRARIES})\n  target_link_libraries(uselib PRIVATE ${ZED_LIBRARIES})\n  target_compile_definitions(darknet PRIVATE -DZED_STEREO)\n  target_compile_definitions(uselib PRIVATE -DZED_STEREO)\n  target_compile_definitions(dark PUBLIC -DZED_STEREO)\nendif()\n\nif(ENABLE_CUDA)\n  target_include_directories(darknet PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n  target_include_directories(dark PUBLIC ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n  target_link_libraries(darknet PRIVATE curand cublas cuda)\n  target_link_libraries(dark PRIVATE curand cublas cuda)\n  set_target_properties(dark PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)\n  target_compile_definitions(darknet PRIVATE -DGPU)\n  target_compile_definitions(dark PUBLIC -DGPU)\nendif()\n\nif(USE_INTEGRATED_LIBS)\n  target_compile_definitions(darknet PRIVATE -D_TIMESPEC_DEFINED)\n  target_compile_definitions(dark PRIVATE -D_TIMESPEC_DEFINED)\nendif()\n\ntarget_link_libraries(uselib PRIVATE dark)\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  target_link_libraries(uselib_track PRIVATE dark)\n  target_compile_definitions(uselib_track PRIVATE TRACK_OPTFLOW=1)\n  target_compile_definitions(uselib_track PRIVATE -DUSE_CMAKE_LIBS)\n  if(BUILD_AS_CPP)\n    set_target_properties(uselib_track PROPERTIES LINKER_LANGUAGE CXX)\n  endif()\n  target_include_directories(uselib_track PRIVATE ${CMAKE_CURRENT_LIST_DIR}/include)\n  target_link_libraries(uselib_track PRIVATE ${OpenCV_LINKED_COMPONENTS})\n  if(ENABLE_ZED_CAMERA)\n    target_link_libraries(uselib_track PRIVATE ${ZED_LIBRARIES})\n    target_compile_definitions(uselib_track PRIVATE -DZED_STEREO)\n  endif()\n  if(MSVC)\n    target_link_libraries(uselib_track PRIVATE PThreads_windows::PThreads_windows)\n    target_compile_definitions(uselib_track PRIVATE -D_CRT_RAND_S -DNOMINMAX -D_USE_MATH_DEFINES)\n  endif()\n  target_link_libraries(uselib_track PRIVATE Threads::Threads)\nendif()\n\n#set_target_properties(dark PROPERTIES PUBLIC_HEADER \"${exported_headers};${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp\")\nset_target_properties(dark PROPERTIES PUBLIC_HEADER \"${CMAKE_CURRENT_LIST_DIR}/include/darknet.h;${CMAKE_CURRENT_LIST_DIR}/include/yolo_v2_class.hpp\")\n\nset_target_properties(dark PROPERTIES CXX_VISIBILITY_PRESET hidden)\n\ninstall(TARGETS dark EXPORT DarknetTargets\n  RUNTIME DESTINATION \"${INSTALL_BIN_DIR}\"\n  LIBRARY DESTINATION \"${INSTALL_LIB_DIR}\"\n  ARCHIVE DESTINATION \"${INSTALL_LIB_DIR}\"\n  PUBLIC_HEADER DESTINATION \"${INSTALL_INCLUDE_DIR}\"\n  COMPONENT dev\n)\ninstall(TARGETS uselib darknet\n  DESTINATION \"${INSTALL_BIN_DIR}\"\n)\nif(OpenCV_FOUND AND OpenCV_VERSION VERSION_GREATER \"3.0\" AND BUILD_USELIB_TRACK)\n  install(TARGETS uselib_track\n    DESTINATION \"${INSTALL_BIN_DIR}\"\n  )\nendif()\n\ninstall(EXPORT DarknetTargets\n  FILE DarknetTargets.cmake\n  NAMESPACE Darknet::\n  DESTINATION \"${INSTALL_CMAKE_DIR}\"\n)\n\n# Export the package for use from the build-tree (this registers the build-tree with a global CMake-registry)\nexport(PACKAGE Darknet)\n\n# Create the DarknetConfig.cmake\n# First of all we compute the relative path between the cmake config file and the include path\nfile(RELATIVE_PATH REL_INCLUDE_DIR \"${FULLPATH_INSTALL_CMAKE_DIR}\" \"${FULLPATH_INSTALL_INCLUDE_DIR}\")\nset(CONF_INCLUDE_DIRS \"${PROJECT_SOURCE_DIR}\" \"${PROJECT_BINARY_DIR}\")\nconfigure_file(DarknetConfig.cmake.in \"${PROJECT_BINARY_DIR}/DarknetConfig.cmake\" @ONLY)\nset(CONF_INCLUDE_DIRS \"\\${Darknet_CMAKE_DIR}/${REL_INCLUDE_DIR}\")\nconfigure_file(DarknetConfig.cmake.in \"${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DarknetConfig.cmake\" @ONLY)\n\n# Create the DarknetConfigVersion.cmake\ninclude(CMakePackageConfigHelpers)\nwrite_basic_package_version_file(\"${PROJECT_BINARY_DIR}/DarknetConfigVersion.cmake\"\n  COMPATIBILITY SameMajorVersion\n)\n\ninstall(FILES\n  \"${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DarknetConfig.cmake\"\n  \"${PROJECT_BINARY_DIR}/DarknetConfigVersion.cmake\"\n  DESTINATION \"${INSTALL_CMAKE_DIR}\"\n)\n"
        },
        {
          "name": "DarknetConfig.cmake.in",
          "type": "blob",
          "size": 1.3408203125,
          "content": "# Config file for the Darknet package\n\nget_filename_component(Darknet_CMAKE_DIR \"${CMAKE_CURRENT_LIST_FILE}\" PATH)\nlist(APPEND CMAKE_MODULE_PATH \"${Darknet_CMAKE_DIR}\")\n\ninclude(CMakeFindDependencyMacro)\n\nif(@OpenCV_FOUND@)\n  find_dependency(OpenCV)\nendif()\n\nif(@ENABLE_CUDA@)\n  include(CheckLanguage)\n  check_language(CUDA)\n  if(NOT CMAKE_CUDA_COMPILER)\n    message(STATUS \" --> WARNING: Unable to find native CUDA integration!\")\n  endif()\n  if(@CUDNN_FOUND@)\n    find_dependency(CUDNN)\n  endif()\nendif()\n\nset(CMAKE_THREAD_PREFER_PTHREAD ON)\nfind_dependency(Threads)\n\nif(MSVC)\n  find_dependency(PThreads_windows)\n  set(CMAKE_CXX_FLAGS \"/wd4018 /wd4244 /wd4267 /wd4305 ${CMAKE_CXX_FLAGS}\")\nendif()\n\nif(@OPENMP_FOUND@)\n  find_dependency(OpenMP)\nendif()\n\n# Our library dependencies (contains definitions for IMPORTED targets)\ninclude(\"${Darknet_CMAKE_DIR}/DarknetTargets.cmake\")\ninclude(\"${Darknet_CMAKE_DIR}/DarknetConfigVersion.cmake\")\n\nif(@OpenCV_FOUND@)\n  target_include_directories(Darknet::dark PRIVATE ${OpenCV_INCLUDE_DIRS})\nendif()\n\nget_target_property(FULL_DARKNET_INCLUDE_DIRS Darknet::dark INTERFACE_INCLUDE_DIRECTORIES)\nlist(GET FULL_DARKNET_INCLUDE_DIRS 0 Darknet_INCLUDE_DIR)\nget_filename_component(Darknet_INCLUDE_DIR \"${Darknet_INCLUDE_DIR}\" REALPATH)\n\nfind_package_handle_standard_args(Darknet REQUIRED_VARS Darknet_INCLUDE_DIR VERSION_VAR PACKAGE_VERSION)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.5029296875,
          "content": "                                  YOLO LICENSE\n                             Version 2, July 29 2016\n\nTHIS SOFTWARE LICENSE IS PROVIDED \"ALL CAPS\" SO THAT YOU KNOW IT IS SUPER\nSERIOUS AND YOU DON'T MESS AROUND WITH COPYRIGHT LAW BECAUSE YOU WILL GET IN\nTROUBLE HERE ARE SOME OTHER BUZZWORDS COMMONLY IN THESE THINGS WARRANTIES\nLIABILITY CONTRACT TORT LIABLE CLAIMS RESTRICTION MERCHANTABILITY. NOW HERE'S\nTHE REAL LICENSE:\n\n0. Darknet is public domain.\n1. Do whatever you want with it.\n2. Stop emailing me about it!\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 5.796875,
          "content": "GPU=1\nCUDNN=1\nCUDNN_HALF=0\nOPENCV=1\nAVX=1\nOPENMP=0\nLIBSO=0\nZED_CAMERA=0\nZED_CAMERA_v2_8=0\n\n# set GPU=1 and CUDNN=1 to speedup on GPU\n# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n\nUSE_CPP=0\nDEBUG=0\n\nARCH= -gencode arch=compute_35,code=sm_35 \\\n      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n\t    -gencode arch=compute_61,code=[sm_61,compute_61]\n\nOS := $(shell uname)\n\n# GeForce RTX 3070, 3080, 3090\n# ARCH= -gencode arch=compute_86,code=[sm_86,compute_86]\n\n# Kepler GeForce GTX 770, GTX 760, GT 740\n# ARCH= -gencode arch=compute_30,code=sm_30\n\n# Tesla A100 (GA100), DGX-A100, RTX 3080\n# ARCH= -gencode arch=compute_80,code=[sm_80,compute_80]\n\n# Tesla V100\n# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n\n# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n\n# Jetson XAVIER\n# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n\n# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\nARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61\n\n# GP100/Tesla P100 - DGX-1\n# ARCH= -gencode arch=compute_60,code=sm_60\n\n# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n\n# For Jetson Tx2 or Drive-PX2 uncomment:\n# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n\n# For Tesla GA10x cards, RTX 3090, RTX 3080, RTX 3070, RTX A6000, RTX A40 uncomment:\n# ARCH= -gencode arch=compute_86,code=[sm_86,compute_86]\n\n\nVPATH=./src/\nEXEC=darknet\nOBJDIR=./obj/\n\nifeq ($(LIBSO), 1)\nLIBNAMESO=libdarknet.so\nAPPNAMESO=uselib\nendif\n\nifeq ($(USE_CPP), 1)\nCC=g++\nelse\nCC=gcc\nendif\n\nCPP=g++ -std=c++11\nNVCC=nvcc\nOPTS=-Ofast\nLDFLAGS= -lm -pthread\nCOMMON= -Iinclude/ -I3rdparty/stb/include\nCFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n\nifeq ($(DEBUG), 1)\n#OPTS= -O0 -g\n#OPTS= -Og -g\nCOMMON+= -DDEBUG\nCFLAGS+= -DDEBUG\nelse\nifeq ($(AVX), 1)\nCFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\nendif\nendif\n\nCFLAGS+=$(OPTS)\n\nifneq (,$(findstring MSYS_NT,$(OS)))\nLDFLAGS+=-lws2_32\nendif\n\nifeq ($(OPENCV), 1)\nCOMMON+= -DOPENCV\nCFLAGS+= -DOPENCV\nLDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\nCOMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\nendif\n\nifeq ($(OPENMP), 1)\n    ifeq ($(OS),Darwin) #MAC\n\t    CFLAGS+= -Xpreprocessor -fopenmp\n\telse\n\t\tCFLAGS+= -fopenmp\n\tendif\nLDFLAGS+= -lgomp\nendif\n\nifeq ($(GPU), 1)\nCOMMON+= -DGPU -I/usr/local/cuda/include/\nCFLAGS+= -DGPU\nifeq ($(OS),Darwin) #MAC\nLDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\nelse\nLDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\nendif\nendif\n\nifeq ($(CUDNN), 1)\nCOMMON+= -DCUDNN\nifeq ($(OS),Darwin) #MAC\nCFLAGS+= -DCUDNN -I/usr/local/cuda/include\nLDFLAGS+= -L/usr/local/cuda/lib -lcudnn\nelse\nCFLAGS+= -DCUDNN -I/usr/local/cudnn/include\nLDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\nendif\nendif\n\nifeq ($(CUDNN_HALF), 1)\nCOMMON+= -DCUDNN_HALF\nCFLAGS+= -DCUDNN_HALF\nARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\nendif\n\nifeq ($(ZED_CAMERA), 1)\nCFLAGS+= -DZED_STEREO -I/usr/local/zed/include\nifeq ($(ZED_CAMERA_v2_8), 1)\nLDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\nelse\nLDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\nendif\nendif\n\nOBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\nifeq ($(GPU), 1)\nLDFLAGS+= -lstdc++\nOBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\nendif\n\nOBJS = $(addprefix $(OBJDIR), $(OBJ))\nDEPS = $(wildcard src/*.h) Makefile include/darknet.h\n\nall: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n\nifeq ($(LIBSO), 1)\nCFLAGS+= -fPIC\n\n$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n\n$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\nendif\n\n$(EXEC): $(OBJS)\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n\n$(OBJDIR)%.o: %.c $(DEPS)\n\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n\n$(OBJDIR)%.o: %.cpp $(DEPS)\n\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n\n$(OBJDIR)%.o: %.cu $(DEPS)\n\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n\n$(OBJDIR):\n\tmkdir -p $(OBJDIR)\nbackup:\n\tmkdir -p backup\nresults:\n\tmkdir -p results\nsetchmod:\n\tchmod +x *.sh\n\n.PHONY: clean\n\nclean:\n\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n"
        },
        {
          "name": "ModelZoo",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.31640625,
          "content": "* 2021.8.12: yolo-fastestV2版本已发布:https://github.com/dog-qiuqiu/Yolo-FastestV2\n* 2021.3.21: 对模型结构进行细微调整优化，更新Yolo-Fastest-1.1模型\n* 2021.3.19: NCNN Camera Demo https://github.com/dog-qiuqiu/Yolo-Fastest/tree/master/sample/ncnn\n* 2021.3.16: 修复分组卷积在某些旧架构GPU推理耗时异常的问题\n\n# :zap:Yolo-Fastest:zap:[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5131532.svg)](https://doi.org/10.5281/zenodo.5131532)\n* Simple, fast, compact, easy to transplant\n* A real-time target detection algorithm for all platforms\n* The fastest and smallest known universal target detection algorithm based on yolo\n* ***Optimized design for ARM mobile terminal, optimized to support [NCNN](https://github.com/Tencent/ncnn) reasoning framework***\n* Based on NCNN deployed on RK3399 ,Raspberry Pi 4b... and other embedded devices to achieve full real-time 30fps+\n\n![image](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/data/fast.jpg)\n* ***中文介绍https://zhuanlan.zhihu.com/p/234506503*** \n* ***相比AlexeyAB/darknet，此版本的darknet修复分组卷积在某些旧架构GPU推理耗时异常的问题(例如1050ti:40ms->4ms速度提升10倍)，强烈建议用此仓库框架训练模型***\n* ***Compared with AlexeyAB/darknet, this version of darknet fixes the problem of abnormal time-consuming inference of grouped convolution in some old architecture GPUs (for example, 1050ti:40ms->4ms speed up 10 times), it is strongly recommended to use this warehouse framework for training model***\n* ***Darknet CPU推理效率优化不好，不建议使用Darknet作为CPU端的推理框架，建议使用NCNN***\n* ***Darknet CPU reasoning efficiency optimization is not good, it is not recommended to use Darknet as the CPU side reasoning framework, it is recommended to use ncnn***\n* ***Based on pytorch training framework: https://github.com/dog-qiuqiu/yolov3***\n\n# Evaluating indicator/Benchmark\nNetwork|COCO mAP(0.5)|Resolution|Run Time(Ncnn 4xCore)|Run Time(Ncnn 1xCore)|FLOPS|Params|Weight size\n:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:\n[Yolo-Fastest-1.1](https://github.com/dog-qiuqiu/Yolo-Fastest/tree/master/ModelZoo/yolo-fastest-1.1_coco)|24.40 %|320X320|5.59 ms|7.52 ms|0.252BFlops|0.35M|1.4M\n[Yolo-Fastest-1.1-xl](https://github.com/dog-qiuqiu/Yolo-Fastest/tree/master/ModelZoo/yolo-fastest-1.1_coco)|34.33 %|320X320|9.27ms|15.72ms|0.725BFlops|0.925M|3.7M\n[Yolov3-Tiny-Prn](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-tiny-prn.cfg)|33.1%|416X416|%ms|%ms|3.5BFlops|4.7M|18.8M\n[Yolov4-Tiny](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg)|40.2%|416X416|23.67ms|40.14ms|6.9 BFlops|5.77M|23.1M\n\n* ***Test platform Mi 11 Snapdragon 888 CPU，Based on [NCNN](https://github.com/Tencent/ncnn)***\n* COCO 2017 Val mAP（no group label）\n* Suitable for hardware with extremely tight computing resources\n* This model is recommended to do some simple single object detection suitable for simple application scenarios\n\n# Yolo-Fastest-1.1 Multi-platform benchmark\nEquipment|Computing backend|System|Framework|Run time\n:---:|:---:|:---:|:---:|:---:\nMi 11|Snapdragon 888|Android(arm64)|ncnn|5.59ms\nMate 30|Kirin 990|Android(arm64)|ncnn|6.12ms\nMeizu 16|Snapdragon 845|Android(arm64)|ncnn|7.72ms\nDevelopment board|Snapdragon 835(Monkey version)|Android(arm64)|ncnn|20.52ms\nDevelopment board|RK3399|Linux(arm64)|ncnn|35.04ms\nRaspberrypi 3B|4xCortex-A53|Linux(arm64)|ncnn|62.31ms\nOrangepi Zero Lts|H2+ 4xCortex-A7|Linux(armv7)|ncnn|550ms\nNvidia|Gtx 1050ti|Ubuntu(x64)|darknet|4.73ms\nIntel|i7-8700|Ubuntu(x64)|ncnn|5.78ms\n* The above is a multi-core test benchmark\n* The above speed benchmark is tested by ***big core*** in big.little CPU\n* Raspberrypi 3B enable bf16s optimization，[Raspberrypi 64 Bit OS](http://downloads.raspberrypi.org/raspios_arm64/images/raspios_arm64-2020-08-24/)\n* [Rk3399 needs to lock the cpu to the highest frequency](http://blog.sina.com.cn/s/blog_15d5280590102yarw.html), ncnn and enable bf16s optimization\n\n# Pascal VOC performance index comparison\nNetwork|Model Size|mAP(VOC 2007)|FLOPS\n:---:|:---:|:---:|:---:\nTiny YOLOv2|60.5MB|57.1%|6.97BFlops\nTiny YOLOv3|33.4MB|58.4%|5.52BFlops\nYOLO Nano|4.0MB|69.1%|4.51Bflops\nMobileNetv2-SSD-Lite|13.8MB|68.6%|&Bflops\nMobileNetV2-YOLOv3|11.52MB|70.20%|2.02Bflos\nPelee-SSD|21.68MB|70.09%|2.40Bflos\n***Yolo Fastest***|1.3MB|61.02%|0.23Bflops\n***Yolo Fastest-XL***|3.5MB|69.43%|0.70Bflops\n***MobileNetv2-Yolo-Lite***|8.0MB|73.26%|1.80Bflops\n* Performance indicators reference from the papers and public indicators in the github project\n* MobileNetv2-Yolo-Lite: https://github.com/dog-qiuqiu/MobileNet-Yolo#mobilenetv2-yolov3-litenano-darknet\n\n# Yolo-Fastest-1.1 Pedestrian detection\nEquipment|System|Framework|Run time\n:---:|:---:|:---:|:---:\nRaspberrypi 3B|Linux(arm64)|ncnn|62ms\n* Simple real-time pedestrian detection model based on yolo-fastest-1.1\n* Enable bf16s optimization，[Raspberrypi 64 Bit OS](http://downloads.raspberrypi.org/raspios_arm64/images/raspios_arm64-2020-08-24/)\n\n## Demo\n![image](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/data/p1.jpg)\n![image](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/data/p2.jpg)\n\n# Compile \n## How to compile on Linux\n* This repo is based on Darknet project so the instructions for compiling the project are same\n(https://github.com/MuhammadAsadJaved/darknet#how-to-compile-on-windows-legacy-way)\n\n\nJust do `make` in the Yolo-Fastest-master directory. Before make, you can set such options in the `Makefile`: [link](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/Makefile#L1)\n\n* `GPU=1` to build with CUDA to accelerate by using GPU (CUDA should be in `/usr/local/cuda`)\n* `CUDNN=1` to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in `/usr/local/cudnn`)\n* `CUDNN_HALF=1` to build for Tensor Cores (on Titan V / Tesla V100 / DGX-2 and later) speedup Detection 3x, Training 2x\n* `OPENCV=1` to build with OpenCV 4.x/3.x/2.4.x - allows to detect on video files and video streams from network cameras or web-cams\n* Set the other options in the `Makefile` according to your need.\n\n# Test/Demo\n*Run Yolo-Fastest , Yolo-Fastest-xl  , Yolov3 or Yolov4 on image or video inputs\n## Demo on image input\n*Note: change  .data , .cfg , .weights and input image file in `image_yolov3.sh` for Yolo-Fastest-x1, Yolov3 and Yolov4\n\n```\n  sh image_yolov3.sh\n```\n## Demo on video input\n*Note: Use any input video and place in the `data` folder or use `0` in the `video_yolov3.sh` for webcam\n\n*Note: change  .data , .cfg , .weights and input video file in `video_yolov3.sh` for Yolo-Fastest-x1, Yolov3 and Yolov4\n\n```\n  sh video_yolov3.sh\n```\n## Yolo-Fastest Test\n![image](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/data/predictions_2.png)\n\n## Yolo-Fastest-xl Test\n![image](https://github.com/dog-qiuqiu/Yolo-Fastest/blob/master/data/projections.jpg)\n\n# How to Train\n## Generate a pre-trained model for the initialization of the model backbone\n```\n  ./darknet partial yolo-fastest.cfg yolo-fastest.weights yolo-fastest.conv.109 109\n```\n## Train\n* 交流qq群:1062122604\n* https://github.com/AlexeyAB/darknet\n```\n  ./darknet detector train voc.data yolo-fastest.cfg yolo-fastest.conv.109 \n```\n# Deploy\n## NCNN\n### NCNN Conversion Tutorial\n* Benchmark:https://github.com/Tencent/ncnn/tree/master/benchmark\n* NCNN supports direct conversion of darknet models\n* darknet2ncnn: https://github.com/Tencent/ncnn/tree/master/tools/darknet\n### NCNN Sample\n* CamSample:https://github.com/dog-qiuqiu/Yolo-Fastest/tree/master/sample/ncnn\n* AndroidSample: https://github.com/WZTENG/YOLOv5_NCNN\n## MNN&TNN&MNN\n* https://github.com/dog-qiuqiu/MobileNet-Yolo#darknet2caffe-tutorial\n* ***Based on MNN: https://github.com/geekzhu001/Yolo-Fastest-MNN Run on : raspberry pi 4B 2G Input size : 320*320 Average inference time : 0.035s*** \n## ONNX&TensorRT\n* https://github.com/CaoWGG/TensorRT-YOLOv4\n* It is not efficient to run on Psacal and earlier GPU architectures. It is not recommended to deploy on such devices such as jeston nano(17ms/img), Tx1, Tx2, but there is no such problem in Turing GPU, such as jetson-Xavier-NX Can run efficiently\n## OpenCV DNN\n* https://blog.csdn.net/nihate/article/details/108670542\n# Thanks\n* https://github.com/AlexeyAB/darknet\n* https://github.com/Tencent/ncnn\n\n## Cite as\ndog-qiuqiu. (2021, July 24). dog-qiuqiu/Yolo-Fastest: \nyolo-fastest-v1.1.0 (Version v.1.1.0). Zenodo. \nhttp://doi.org/10.5281/zenodo.5131532\n"
        },
        {
          "name": "build.ps1",
          "type": "blob",
          "size": 7.693359375,
          "content": "#!/usr/bin/env pwsh\n\n$number_of_build_workers = 8\n$enable_cuda = $true\n$use_vcpkg = $true\n$use_ninja = $true\n$force_cpp_build = $false\n\n#$additional_build_setup = \" -DCMAKE_CUDA_ARCHITECTURES=30\"\n\n\n$CMAKE_EXE = Get-Command cmake | Select-Object -ExpandProperty Definition\n$NINJA_EXE = Get-Command ninja | Select-Object -ExpandProperty Definition\n\nif (-Not $CMAKE_EXE) {\n  throw \"Could not find CMake, please install it\"\n}\nelse {\n  Write-Host \"Using CMake from ${CMAKE_EXE}\"\n}\n\nif (-Not $NINJA_EXE -and $use_ninja) {\n  throw \"Could not find Ninja, please install it\"\n}\nelse {\n  Write-Host \"Using Ninja from ${NINJA_EXE}\"\n}\n\nfunction getProgramFiles32bit() {\n  $out = ${env:PROGRAMFILES(X86)}\n  if ($null -eq $out) {\n    $out = ${env:PROGRAMFILES}\n  }\n\n  if ($null -eq $out) {\n    throw \"Could not find [Program Files 32-bit]\"\n  }\n\n  return $out\n}\n\nfunction getLatestVisualStudioWithDesktopWorkloadPath() {\n  $programFiles = getProgramFiles32bit\n  $vswhereExe = \"$programFiles\\Microsoft Visual Studio\\Installer\\vswhere.exe\"\n  if (Test-Path $vswhereExe) {\n    $output = & $vswhereExe -products * -latest -requires Microsoft.VisualStudio.Workload.NativeDesktop -format xml\n    [xml]$asXml = $output\n    foreach ($instance in $asXml.instances.instance) {\n      $installationPath = $instance.InstallationPath -replace \"\\\\$\" # Remove potential trailing backslash\n    }\n    if (!$installationPath) {\n      Write-Host \"Warning: no full Visual Studio setup has been found, extending search to include also partial installations\" -ForegroundColor Yellow\n      $output = & $vswhereExe -products * -latest -format xml\n      [xml]$asXml = $output\n      foreach ($instance in $asXml.instances.instance) {\n        $installationPath = $instance.InstallationPath -replace \"\\\\$\" # Remove potential trailing backslash\n      }\n    }\n    if (!$installationPath) {\n      Throw \"Could not locate any installation of Visual Studio\"\n    }\n  }\n  else {\n    Throw \"Could not locate vswhere at $vswhereExe\"\n  }\n  return $installationPath\n}\n\n\nfunction getLatestVisualStudioWithDesktopWorkloadVersion() {\n  $programFiles = getProgramFiles32bit\n  $vswhereExe = \"$programFiles\\Microsoft Visual Studio\\Installer\\vswhere.exe\"\n  if (Test-Path $vswhereExe) {\n    $output = & $vswhereExe -products * -latest -requires Microsoft.VisualStudio.Workload.NativeDesktop -format xml\n    [xml]$asXml = $output\n    foreach ($instance in $asXml.instances.instance) {\n      $installationVersion = $instance.InstallationVersion\n    }\n    if (!$installationVersion) {\n      Write-Host \"Warning: no full Visual Studio setup has been found, extending search to include also partial installations\" -ForegroundColor Yellow\n      $output = & $vswhereExe -products * -latest -format xml\n      [xml]$asXml = $output\n      foreach ($instance in $asXml.instances.instance) {\n        $installationVersion = $instance.installationVersion\n      }\n    }\n    if (!$installationVersion) {\n      Throw \"Could not locate any installation of Visual Studio\"\n    }\n  }\n  else {\n    Throw \"Could not locate vswhere at $vswhereExe\"\n  }\n  return $installationVersion\n}\n\n\nif ((Test-Path env:VCPKG_ROOT) -and $use_vcpkg) {\n  $vcpkg_path = \"$env:VCPKG_ROOT\"\n  Write-Host \"Found vcpkg in VCPKG_ROOT: $vcpkg_path\"\n}\nelseif ((Test-Path \"${env:WORKSPACE}\\vcpkg\") -and $use_vcpkg) {\n  $vcpkg_path = \"${env:WORKSPACE}\\vcpkg\"\n  $env:VCPKG_ROOT = \"${env:WORKSPACE}\\vcpkg\"\n  Write-Host \"Found vcpkg in WORKSPACE\\vcpkg: $vcpkg_path\"\n}\nelse {\n  $use_vcpkg = $false\n  Write-Host \"Skipping vcpkg-enabled builds because the VCPKG_ROOT environment variable is not defined or you requested to avoid VCPKG, using self-distributed libs`n\" -ForegroundColor Yellow\n  $additional_build_setup = $additional_build_setup + \" -DENABLE_VCPKG_INTEGRATION:BOOL=OFF\"\n}\n\nif ($null -eq $env:VCPKG_DEFAULT_TRIPLET -and $use_vcpkg) {\n  Write-Host \"No default triplet has been set-up for vcpkg. Defaulting to x64-windows\" -ForegroundColor Yellow\n  $vcpkg_triplet = \"x64-windows\"\n}\nelseif ($use_vcpkg) {\n  $vcpkg_triplet = $env:VCPKG_DEFAULT_TRIPLET\n}\n\nif ($vcpkg_triplet -Match \"x86\" -and $use_vcpkg) {\n  Throw \"darknet is supported only in x64 builds!\"\n}\n\nif ($null -eq (Get-Command \"cl.exe\" -ErrorAction SilentlyContinue)) {\n  $vsfound = getLatestVisualStudioWithDesktopWorkloadPath\n  Write-Host \"Found VS in ${vsfound}\"\n  Push-Location \"${vsfound}\\Common7\\Tools\"\n  cmd.exe /c \"VsDevCmd.bat -arch=x64 & set\" |\n  ForEach-Object {\n    if ($_ -match \"=\") {\n      $v = $_.split(\"=\"); Set-Item -force -path \"ENV:\\$($v[0])\"  -value \"$($v[1])\"\n    }\n  }\n  Pop-Location\n  Write-Host \"Visual Studio Command Prompt variables set\" -ForegroundColor Yellow\n}\n\n$tokens = getLatestVisualStudioWithDesktopWorkloadVersion\n$tokens = $tokens.split('.')\nif ($use_ninja) {\n  $generator = \"Ninja\"\n}\nelse {\n  if ($tokens[0] -eq \"14\") {\n    $generator = \"Visual Studio 14 2015\"\n  }\n  elseif ($tokens[0] -eq \"15\") {\n    $generator = \"Visual Studio 15 2017\"\n  }\n  elseif ($tokens[0] -eq \"16\") {\n    $generator = \"Visual Studio 16 2019\"\n  }\n  else {\n    throw \"Unknown Visual Studio version, unsupported configuration\"\n  }\n}\nWrite-Host \"Setting up environment to use CMake generator: $generator\" -ForegroundColor Yellow\n\nif ($null -eq (Get-Command \"nvcc.exe\" -ErrorAction SilentlyContinue)) {\n  if (Test-Path env:CUDA_PATH) {\n    $env:PATH += \";${env:CUDA_PATH}\\bin\"\n    Write-Host \"Found cuda in ${env:CUDA_PATH}\" -ForegroundColor Yellow\n  }\n  else {\n    Write-Host \"Unable to find CUDA, if necessary please install it or define a CUDA_PATH env variable pointing to the install folder\" -ForegroundColor Yellow\n  }\n}\n\nif (Test-Path env:CUDA_PATH) {\n  if (-Not(Test-Path env:CUDA_TOOLKIT_ROOT_DIR)) {\n    $env:CUDA_TOOLKIT_ROOT_DIR = \"${env:CUDA_PATH}\"\n    Write-Host \"Added missing env variable CUDA_TOOLKIT_ROOT_DIR\" -ForegroundColor Yellow\n  }\n  if (-Not(Test-Path env:CUDACXX)) {\n    $env:CUDACXX = \"${env:CUDA_PATH}\\bin\\nvcc.exe\"\n    Write-Host \"Added missing env variable CUDACXX\" -ForegroundColor Yellow\n  }\n}\n\nif ($force_cpp_build) {\n  $additional_build_setup = $additional_build_setup + \" -DBUILD_AS_CPP:BOOL=ON\"\n}\n\nif (-Not($enable_cuda)) {\n  $additional_build_setup = $additional_build_setup + \" -DENABLE_CUDA:BOOL=OFF\"\n}\n\nif ($use_vcpkg) {\n  New-Item -Path .\\build_win_release -ItemType directory -Force\n  Set-Location build_win_release\n  if ($use_ninja) {\n    $cmake_args = \"-G `\"$generator`\" `\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet`\" `\"-DCMAKE_BUILD_TYPE=Release`\" ${additional_build_setup} -S ..\"\n    $dllfolder = \".\"\n  }\n  else {\n    $cmake_args = \"-G `\"$generator`\" -T `\"host=x64`\" -A `\"x64`\" `\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet`\" `\"-DCMAKE_BUILD_TYPE=Release`\" ${additional_build_setup} -S ..\"\n    $dllfolder = \"Release\"\n  }\n}\nelse {\n  # USE LOCAL PTHREAD LIB AND LOCAL STB HEADER, NO VCPKG, ONLY RELEASE MODE SUPPORTED\n  # if you want to manually force this case, remove VCPKG_ROOT env variable and remember to use \"vcpkg integrate remove\" in case you had enabled user-wide vcpkg integration\n  New-Item -Path .\\build_win_release_novcpkg -ItemType directory -Force\n  Set-Location build_win_release_novcpkg\n  if ($use_ninja) {\n    $cmake_args = \"-G `\"$generator`\" ${additional_build_setup} -S ..\"\n    $dllfolder = \"..\\3rdparty\\pthreads\\bin\"\n  }\n  else {\n    $cmake_args = \"-G `\"$generator`\" -T `\"host=x64`\" -A `\"x64`\" ${additional_build_setup} -S ..\"\n    $dllfolder = \"..\\3rdparty\\pthreads\\bin\"\n  }\n}\n\nWrite-Host \"CMake args: $cmake_args\"\nStart-Process -NoNewWindow -Wait -FilePath $CMAKE_EXE -ArgumentList $cmake_args\nStart-Process -NoNewWindow -Wait -FilePath $CMAKE_EXE -ArgumentList \"--build . --config Release --parallel ${number_of_build_workers} --target install\"\nRemove-Item DarknetConfig.cmake\nRemove-Item DarknetConfigVersion.cmake\n$dllfiles = Get-ChildItem ${dllfolder}\\*.dll\nif ($dllfiles) {\n  Copy-Item $dllfiles ..\n}\nSet-Location ..\nCopy-Item cmake\\Modules\\*.cmake share\\darknet\\\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 1.9140625,
          "content": "#!/usr/bin/env bash\n\nnumber_of_build_workers=8\nuse_vcpkg=false\nforce_cpp_build=false\nenable_cuda=false\n\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n  vcpkg_triplet=\"x64-osx\"\nelse\n  vcpkg_triplet=\"x64-linux\"\nfi\n\nif [[ ! -z \"${VCPKG_ROOT}\" ]] && [ -d ${VCPKG_ROOT} ] && [ \"$use_vcpkg\" = true ]\nthen\n  vcpkg_path=\"${VCPKG_ROOT}\"\n  vcpkg_triplet_define=\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\"\n  echo \"Found vcpkg in VCPKG_ROOT: ${vcpkg_path}\"\n  additional_defines=\"-DBUILD_SHARED_LIBS=OFF\"\nelif [[ ! -z \"${WORKSPACE}\" ]] && [ -d ${WORKSPACE}/vcpkg ] && [ \"$use_vcpkg\" = true ]\nthen\n  export VCPKG_ROOT=\"${WORKSPACE}/vcpkg\"\n  vcpkg_path=\"${WORKSPACE}/vcpkg\"\n  vcpkg_triplet_define=\"-DVCPKG_TARGET_TRIPLET=$vcpkg_triplet\"\n  echo \"Found vcpkg in WORKSPACE/vcpkg: ${vcpkg_path}\"\n  additional_defines=\"-DBUILD_SHARED_LIBS=OFF\"\nelif [ \"$use_vcpkg\" = true ]\nthen\n  (>&2 echo \"darknet is unsupported without vcpkg, use at your own risk!\")\nelse\n  additional_build_setup=${additional_build_setup}\" -DENABLE_VCPKG_INTEGRATION:BOOL=FALSE\"\nfi\n\nif [ \"$force_cpp_build\" = true ]\nthen\n  additional_build_setup=${additional_build_setup}\" -DBUILD_AS_CPP:BOOL=TRUE\"\nfi\n\nif [ \"$enable_cuda\" = false ]\nthen\n  additional_build_setup=${additional_build_setup}\" -DENABLE_CUDA:BOOL=FALSE\"\nfi\n\n## DEBUG\n#mkdir -p build_debug\n#cd build_debug\n#cmake .. -DCMAKE_BUILD_TYPE=Debug ${vcpkg_define} ${vcpkg_triplet_define} ${additional_defines} ${additional_build_setup}\n#cmake --build . --target install --parallel ${number_of_build_workers}\n#rm -f DarknetConfig.cmake\n#rm -f DarknetConfigVersion.cmake\n#cd ..\n#cp cmake/Modules/*.cmake share/darknet/\n\n# RELEASE\nmkdir -p build_release\ncd build_release\ncmake .. -DCMAKE_BUILD_TYPE=Release ${vcpkg_define} ${vcpkg_triplet_define} ${additional_defines} ${additional_build_setup}\ncmake --build . --target install --parallel ${number_of_build_workers}\nrm -f DarknetConfig.cmake\nrm -f DarknetConfigVersion.cmake\ncd ..\ncp cmake/Modules/*.cmake share/darknet/\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "cfg",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknet.py",
          "type": "blob",
          "size": 10.091796875,
          "content": "#!python3\n\"\"\"\nPython 3 wrapper for identifying objects in images\n\nRequires DLL compilation\n\nBoth the GPU and no-GPU version should be compiled; the no-GPU version should be renamed \"yolo_cpp_dll_nogpu.dll\".\n\nOn a GPU system, you can force CPU evaluation by any of:\n\n- Set global variable DARKNET_FORCE_CPU to True\n- Set environment variable CUDA_VISIBLE_DEVICES to -1\n- Set environment variable \"FORCE_CPU\" to \"true\"\n- Set environment variable \"DARKNET_PATH\" to path darknet lib .so (for Linux)\n\nDirectly viewing or returning bounding-boxed images requires scikit-image to be installed (`pip install scikit-image`)\n\nOriginal *nix 2.7: https://github.com/pjreddie/darknet/blob/0f110834f4e18b30d5f101bf8f1724c34b7b83db/python/darknet.py\nWindows Python 2.7 version: https://github.com/AlexeyAB/darknet/blob/fc496d52bf22a0bb257300d3c79be9cd80e722cb/build/darknet/x64/darknet.py\n\n@author: Philip Kahn\n@date: 20180503\n\"\"\"\nfrom ctypes import *\nimport math\nimport random\nimport os\n\n\nclass BOX(Structure):\n    _fields_ = [(\"x\", c_float),\n                (\"y\", c_float),\n                (\"w\", c_float),\n                (\"h\", c_float)]\n\n\nclass DETECTION(Structure):\n    _fields_ = [(\"bbox\", BOX),\n                (\"classes\", c_int),\n                (\"prob\", POINTER(c_float)),\n                (\"mask\", POINTER(c_float)),\n                (\"objectness\", c_float),\n                (\"sort_class\", c_int),\n                (\"uc\", POINTER(c_float)),\n                (\"points\", c_int),\n                (\"embeddings\", POINTER(c_float)),\n                (\"embedding_size\", c_int),\n                (\"sim\", c_float),\n                (\"track_id\", c_int)]\n\nclass DETNUMPAIR(Structure):\n    _fields_ = [(\"num\", c_int),\n                (\"dets\", POINTER(DETECTION))]\n\n\nclass IMAGE(Structure):\n    _fields_ = [(\"w\", c_int),\n                (\"h\", c_int),\n                (\"c\", c_int),\n                (\"data\", POINTER(c_float))]\n\n\nclass METADATA(Structure):\n    _fields_ = [(\"classes\", c_int),\n                (\"names\", POINTER(c_char_p))]\n\n\ndef network_width(net):\n    return lib.network_width(net)\n\n\ndef network_height(net):\n    return lib.network_height(net)\n\n\ndef bbox2points(bbox):\n    \"\"\"\n    From bounding box yolo format\n    to corner points cv2 rectangle\n    \"\"\"\n    x, y, w, h = bbox\n    xmin = int(round(x - (w / 2)))\n    xmax = int(round(x + (w / 2)))\n    ymin = int(round(y - (h / 2)))\n    ymax = int(round(y + (h / 2)))\n    return xmin, ymin, xmax, ymax\n\n\ndef class_colors(names):\n    \"\"\"\n    Create a dict with one random BGR color for each\n    class name\n    \"\"\"\n    return {name: (\n        random.randint(0, 255),\n        random.randint(0, 255),\n        random.randint(0, 255)) for name in names}\n\n\ndef load_network(config_file, data_file, weights, batch_size=1):\n    \"\"\"\n    load model description and weights from config files\n    args:\n        config_file (str): path to .cfg model file\n        data_file (str): path to .data model file\n        weights (str): path to weights\n    returns:\n        network: trained model\n        class_names\n        class_colors\n    \"\"\"\n    network = load_net_custom(\n        config_file.encode(\"ascii\"),\n        weights.encode(\"ascii\"), 0, batch_size)\n    metadata = load_meta(data_file.encode(\"ascii\"))\n    class_names = [metadata.names[i].decode(\"ascii\") for i in range(metadata.classes)]\n    colors = class_colors(class_names)\n    return network, class_names, colors\n\n\ndef print_detections(detections, coordinates=False):\n    print(\"\\nObjects:\")\n    for label, confidence, bbox in detections:\n        x, y, w, h = bbox\n        if coordinates:\n            print(\"{}: {}%    (left_x: {:.0f}   top_y:  {:.0f}   width:   {:.0f}   height:  {:.0f})\".format(label, confidence, x, y, w, h))\n        else:\n            print(\"{}: {}%\".format(label, confidence))\n\n\ndef draw_boxes(detections, image, colors):\n    import cv2\n    for label, confidence, bbox in detections:\n        left, top, right, bottom = bbox2points(bbox)\n        cv2.rectangle(image, (left, top), (right, bottom), colors[label], 1)\n        cv2.putText(image, \"{} [{:.2f}]\".format(label, float(confidence)),\n                    (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n                    colors[label], 2)\n    return image\n\n\ndef decode_detection(detections):\n    decoded = []\n    for label, confidence, bbox in detections:\n        confidence = str(round(confidence * 100, 2))\n        decoded.append((str(label), confidence, bbox))\n    return decoded\n\n\ndef remove_negatives(detections, class_names, num):\n    \"\"\"\n    Remove all classes with 0% confidence within the detection\n    \"\"\"\n    predictions = []\n    for j in range(num):\n        for idx, name in enumerate(class_names):\n            if detections[j].prob[idx] > 0:\n                bbox = detections[j].bbox\n                bbox = (bbox.x, bbox.y, bbox.w, bbox.h)\n                predictions.append((name, detections[j].prob[idx], (bbox)))\n    return predictions\n\n\ndef detect_image(network, class_names, image, thresh=.5, hier_thresh=.5, nms=.45):\n    \"\"\"\n        Returns a list with highest confidence class and their bbox\n    \"\"\"\n    pnum = pointer(c_int(0))\n    predict_image(network, image)\n    detections = get_network_boxes(network, image.w, image.h,\n                                   thresh, hier_thresh, None, 0, pnum, 0)\n    num = pnum[0]\n    if nms:\n        do_nms_sort(detections, num, len(class_names), nms)\n    predictions = remove_negatives(detections, class_names, num)\n    predictions = decode_detection(predictions)\n    free_detections(detections, num)\n    return sorted(predictions, key=lambda x: x[1])\n\n\n#  lib = CDLL(\"/home/pjreddie/documents/darknet/libdarknet.so\", RTLD_GLOBAL)\n#  lib = CDLL(\"libdarknet.so\", RTLD_GLOBAL)\nhasGPU = True\nif os.name == \"nt\":\n    cwd = os.path.dirname(__file__)\n    os.environ['PATH'] = cwd + ';' + os.environ['PATH']\n    winGPUdll = os.path.join(cwd, \"yolo_cpp_dll.dll\")\n    winNoGPUdll = os.path.join(cwd, \"yolo_cpp_dll_nogpu.dll\")\n    envKeys = list()\n    for k, v in os.environ.items():\n        envKeys.append(k)\n    try:\n        try:\n            tmp = os.environ[\"FORCE_CPU\"].lower()\n            if tmp in [\"1\", \"true\", \"yes\", \"on\"]:\n                raise ValueError(\"ForceCPU\")\n            else:\n                print(\"Flag value {} not forcing CPU mode\".format(tmp))\n        except KeyError:\n            # We never set the flag\n            if 'CUDA_VISIBLE_DEVICES' in envKeys:\n                if int(os.environ['CUDA_VISIBLE_DEVICES']) < 0:\n                    raise ValueError(\"ForceCPU\")\n            try:\n                global DARKNET_FORCE_CPU\n                if DARKNET_FORCE_CPU:\n                    raise ValueError(\"ForceCPU\")\n            except NameError as cpu_error:\n                print(cpu_error)\n        if not os.path.exists(winGPUdll):\n            raise ValueError(\"NoDLL\")\n        lib = CDLL(winGPUdll, RTLD_GLOBAL)\n    except (KeyError, ValueError):\n        hasGPU = False\n        if os.path.exists(winNoGPUdll):\n            lib = CDLL(winNoGPUdll, RTLD_GLOBAL)\n            print(\"Notice: CPU-only mode\")\n        else:\n            # Try the other way, in case no_gpu was compile but not renamed\n            lib = CDLL(winGPUdll, RTLD_GLOBAL)\n            print(\"Environment variables indicated a CPU run, but we didn't find {}. Trying a GPU run anyway.\".format(winNoGPUdll))\nelse:\n    lib = CDLL(os.path.join(\n        os.environ.get('DARKNET_PATH', './'),\n        \"libdarknet.so\"), RTLD_GLOBAL)\nlib.network_width.argtypes = [c_void_p]\nlib.network_width.restype = c_int\nlib.network_height.argtypes = [c_void_p]\nlib.network_height.restype = c_int\n\ncopy_image_from_bytes = lib.copy_image_from_bytes\ncopy_image_from_bytes.argtypes = [IMAGE,c_char_p]\n\npredict = lib.network_predict_ptr\npredict.argtypes = [c_void_p, POINTER(c_float)]\npredict.restype = POINTER(c_float)\n\nif hasGPU:\n    set_gpu = lib.cuda_set_device\n    set_gpu.argtypes = [c_int]\n\ninit_cpu = lib.init_cpu\n\nmake_image = lib.make_image\nmake_image.argtypes = [c_int, c_int, c_int]\nmake_image.restype = IMAGE\n\nget_network_boxes = lib.get_network_boxes\nget_network_boxes.argtypes = [c_void_p, c_int, c_int, c_float, c_float, POINTER(c_int), c_int, POINTER(c_int), c_int]\nget_network_boxes.restype = POINTER(DETECTION)\n\nmake_network_boxes = lib.make_network_boxes\nmake_network_boxes.argtypes = [c_void_p]\nmake_network_boxes.restype = POINTER(DETECTION)\n\nfree_detections = lib.free_detections\nfree_detections.argtypes = [POINTER(DETECTION), c_int]\n\nfree_batch_detections = lib.free_batch_detections\nfree_batch_detections.argtypes = [POINTER(DETNUMPAIR), c_int]\n\nfree_ptrs = lib.free_ptrs\nfree_ptrs.argtypes = [POINTER(c_void_p), c_int]\n\nnetwork_predict = lib.network_predict_ptr\nnetwork_predict.argtypes = [c_void_p, POINTER(c_float)]\n\nreset_rnn = lib.reset_rnn\nreset_rnn.argtypes = [c_void_p]\n\nload_net = lib.load_network\nload_net.argtypes = [c_char_p, c_char_p, c_int]\nload_net.restype = c_void_p\n\nload_net_custom = lib.load_network_custom\nload_net_custom.argtypes = [c_char_p, c_char_p, c_int, c_int]\nload_net_custom.restype = c_void_p\n\nfree_network_ptr = lib.free_network_ptr\nfree_network_ptr.argtypes = [c_void_p]\nfree_network_ptr.restype = c_void_p\n\ndo_nms_obj = lib.do_nms_obj\ndo_nms_obj.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\ndo_nms_sort = lib.do_nms_sort\ndo_nms_sort.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\nfree_image = lib.free_image\nfree_image.argtypes = [IMAGE]\n\nletterbox_image = lib.letterbox_image\nletterbox_image.argtypes = [IMAGE, c_int, c_int]\nletterbox_image.restype = IMAGE\n\nload_meta = lib.get_metadata\nlib.get_metadata.argtypes = [c_char_p]\nlib.get_metadata.restype = METADATA\n\nload_image = lib.load_image_color\nload_image.argtypes = [c_char_p, c_int, c_int]\nload_image.restype = IMAGE\n\nrgbgr_image = lib.rgbgr_image\nrgbgr_image.argtypes = [IMAGE]\n\npredict_image = lib.network_predict_image\npredict_image.argtypes = [c_void_p, IMAGE]\npredict_image.restype = POINTER(c_float)\n\npredict_image_letterbox = lib.network_predict_image_letterbox\npredict_image_letterbox.argtypes = [c_void_p, IMAGE]\npredict_image_letterbox.restype = POINTER(c_float)\n\nnetwork_predict_batch = lib.network_predict_batch\nnetwork_predict_batch.argtypes = [c_void_p, IMAGE, c_int, c_int, c_int,\n                                   c_float, c_float, POINTER(c_int), c_int, c_int]\nnetwork_predict_batch.restype = POINTER(DETNUMPAIR)\n"
        },
        {
          "name": "darknet_images.py",
          "type": "blob",
          "size": 9.2451171875,
          "content": "import argparse\nimport os\nimport glob\nimport random\nimport darknet\nimport time\nimport cv2\nimport numpy as np\nimport darknet\n\n\ndef parser():\n    parser = argparse.ArgumentParser(description=\"YOLO Object Detection\")\n    parser.add_argument(\"--input\", type=str, default=\"\",\n                        help=\"image source. It can be a single image, a\"\n                        \"txt with paths to them, or a folder. Image valid\"\n                        \" formats are jpg, jpeg or png.\"\n                        \"If no input is given, \")\n    parser.add_argument(\"--batch_size\", default=1, type=int,\n                        help=\"number of images to be processed at the same time\")\n    parser.add_argument(\"--weights\", default=\"yolov4.weights\",\n                        help=\"yolo weights path\")\n    parser.add_argument(\"--dont_show\", action='store_true',\n                        help=\"windown inference display. For headless systems\")\n    parser.add_argument(\"--ext_output\", action='store_true',\n                        help=\"display bbox coordinates of detected objects\")\n    parser.add_argument(\"--save_labels\", action='store_true',\n                        help=\"save detections bbox for each image in yolo format\")\n    parser.add_argument(\"--config_file\", default=\"./cfg/yolov4.cfg\",\n                        help=\"path to config file\")\n    parser.add_argument(\"--data_file\", default=\"./cfg/coco.data\",\n                        help=\"path to data file\")\n    parser.add_argument(\"--thresh\", type=float, default=.25,\n                        help=\"remove detections with lower confidence\")\n    return parser.parse_args()\n\n\ndef check_arguments_errors(args):\n    assert 0 < args.thresh < 1, \"Threshold should be a float between zero and one (non-inclusive)\"\n    if not os.path.exists(args.config_file):\n        raise(ValueError(\"Invalid config path {}\".format(os.path.abspath(args.config_file))))\n    if not os.path.exists(args.weights):\n        raise(ValueError(\"Invalid weight path {}\".format(os.path.abspath(args.weights))))\n    if not os.path.exists(args.data_file):\n        raise(ValueError(\"Invalid data file path {}\".format(os.path.abspath(args.data_file))))\n    if args.input and not os.path.exists(args.input):\n        raise(ValueError(\"Invalid image path {}\".format(os.path.abspath(args.input))))\n\n\ndef check_batch_shape(images, batch_size):\n    \"\"\"\n        Image sizes should be the same width and height\n    \"\"\"\n    shapes = [image.shape for image in images]\n    if len(set(shapes)) > 1:\n        raise ValueError(\"Images don't have same shape\")\n    if len(shapes) > batch_size:\n        raise ValueError(\"Batch size higher than number of images\")\n    return shapes[0]\n\n\ndef load_images(images_path):\n    \"\"\"\n    If image path is given, return it directly\n    For txt file, read it and return each line as image path\n    In other case, it's a folder, return a list with names of each\n    jpg, jpeg and png file\n    \"\"\"\n    input_path_extension = images_path.split('.')[-1]\n    if input_path_extension in ['jpg', 'jpeg', 'png']:\n        return [images_path]\n    elif input_path_extension == \"txt\":\n        with open(images_path, \"r\") as f:\n            return f.read().splitlines()\n    else:\n        return glob.glob(\n            os.path.join(images_path, \"*.jpg\")) + \\\n            glob.glob(os.path.join(images_path, \"*.png\")) + \\\n            glob.glob(os.path.join(images_path, \"*.jpeg\"))\n\n\ndef prepare_batch(images, network, channels=3):\n    width = darknet.network_width(network)\n    height = darknet.network_height(network)\n\n    darknet_images = []\n    for image in images:\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image_resized = cv2.resize(image_rgb, (width, height),\n                                   interpolation=cv2.INTER_LINEAR)\n        custom_image = image_resized.transpose(2, 0, 1)\n        darknet_images.append(custom_image)\n\n    batch_array = np.concatenate(darknet_images, axis=0)\n    batch_array = np.ascontiguousarray(batch_array.flat, dtype=np.float32)/255.0\n    darknet_images = batch_array.ctypes.data_as(darknet.POINTER(darknet.c_float))\n    return darknet.IMAGE(width, height, channels, darknet_images)\n\n\ndef image_detection(image_path, network, class_names, class_colors, thresh):\n    # Darknet doesn't accept numpy images.\n    # Create one with image we reuse for each detect\n    width = darknet.network_width(network)\n    height = darknet.network_height(network)\n    darknet_image = darknet.make_image(width, height, 3)\n\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(image_rgb, (width, height),\n                               interpolation=cv2.INTER_LINEAR)\n\n    darknet.copy_image_from_bytes(darknet_image, image_resized.tobytes())\n    detections = darknet.detect_image(network, class_names, darknet_image, thresh=thresh)\n    darknet.free_image(darknet_image)\n    image = darknet.draw_boxes(detections, image_resized, class_colors)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB), detections\n\n\ndef batch_detection(network, images, class_names, class_colors,\n                    thresh=0.25, hier_thresh=.5, nms=.45, batch_size=4):\n    image_height, image_width, _ = check_batch_shape(images, batch_size)\n    darknet_images = prepare_batch(images, network)\n    batch_detections = darknet.network_predict_batch(network, darknet_images, batch_size, image_width,\n                                                     image_height, thresh, hier_thresh, None, 0, 0)\n    batch_predictions = []\n    for idx in range(batch_size):\n        num = batch_detections[idx].num\n        detections = batch_detections[idx].dets\n        if nms:\n            darknet.do_nms_obj(detections, num, len(class_names), nms)\n        predictions = darknet.remove_negatives(detections, class_names, num)\n        images[idx] = darknet.draw_boxes(predictions, images[idx], class_colors)\n        batch_predictions.append(predictions)\n    darknet.free_batch_detections(batch_detections, batch_size)\n    return images, batch_predictions\n\n\ndef image_classification(image, network, class_names):\n    width = darknet.network_width(network)\n    height = darknet.network_height(network)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(image_rgb, (width, height),\n                                interpolation=cv2.INTER_LINEAR)\n    darknet_image = darknet.make_image(width, height, 3)\n    darknet.copy_image_from_bytes(darknet_image, image_resized.tobytes())\n    detections = darknet.predict_image(network, darknet_image)\n    predictions = [(name, detections[idx]) for idx, name in enumerate(class_names)]\n    darknet.free_image(darknet_image)\n    return sorted(predictions, key=lambda x: -x[1])\n\n\ndef convert2relative(image, bbox):\n    \"\"\"\n    YOLO format use relative coordinates for annotation\n    \"\"\"\n    x, y, w, h = bbox\n    height, width, _ = image.shape\n    return x/width, y/height, w/width, h/height\n\n\ndef save_annotations(name, image, detections, class_names):\n    \"\"\"\n    Files saved with image_name.txt and relative coordinates\n    \"\"\"\n    file_name = name.split(\".\")[:-1][0] + \".txt\"\n    with open(file_name, \"w\") as f:\n        for label, confidence, bbox in detections:\n            x, y, w, h = convert2relative(image, bbox)\n            label = class_names.index(label)\n            f.write(\"{} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}\\n\".format(label, x, y, w, h, float(confidence)))\n\n\ndef batch_detection_example():\n    args = parser()\n    check_arguments_errors(args)\n    batch_size = 3\n    random.seed(3)  # deterministic bbox colors\n    network, class_names, class_colors = darknet.load_network(\n        args.config_file,\n        args.data_file,\n        args.weights,\n        batch_size=batch_size\n    )\n    image_names = ['data/horses.jpg', 'data/horses.jpg', 'data/eagle.jpg']\n    images = [cv2.imread(image) for image in image_names]\n    images, detections,  = batch_detection(network, images, class_names,\n                                           class_colors, batch_size=batch_size)\n    for name, image in zip(image_names, images):\n        cv2.imwrite(name.replace(\"data/\", \"\"), image)\n    print(detections)\n\n\ndef main():\n    args = parser()\n    check_arguments_errors(args)\n\n    random.seed(3)  # deterministic bbox colors\n    network, class_names, class_colors = darknet.load_network(\n        args.config_file,\n        args.data_file,\n        args.weights,\n        batch_size=args.batch_size\n    )\n\n    images = load_images(args.input)\n\n    index = 0\n    while True:\n        # loop asking for new image paths if no list is given\n        if args.input:\n            if index >= len(images):\n                break\n            image_name = images[index]\n        else:\n            image_name = input(\"Enter Image Path: \")\n        prev_time = time.time()\n        image, detections = image_detection(\n            image_name, network, class_names, class_colors, args.thresh\n            )\n        if args.save_labels:\n            save_annotations(image_name, image, detections, class_names)\n        darknet.print_detections(detections, args.ext_output)\n        fps = int(1/(time.time() - prev_time))\n        print(\"FPS: {}\".format(fps))\n        if not args.dont_show:\n            cv2.imshow('Inference', image)\n            if cv2.waitKey() & 0xFF == ord('q'):\n                break\n        index += 1\n\n\nif __name__ == \"__main__\":\n    # unconmment next line for an example of batch processing\n    # batch_detection_example()\n    main()\n"
        },
        {
          "name": "darknet_video.py",
          "type": "blob",
          "size": 5.1044921875,
          "content": "from ctypes import *\nimport random\nimport os\nimport cv2\nimport time\nimport darknet\nimport argparse\nfrom threading import Thread, enumerate\nfrom queue import Queue\n\n\ndef parser():\n    parser = argparse.ArgumentParser(description=\"YOLO Object Detection\")\n    parser.add_argument(\"--input\", type=str, default=0,\n                        help=\"video source. If empty, uses webcam 0 stream\")\n    parser.add_argument(\"--out_filename\", type=str, default=\"\",\n                        help=\"inference video name. Not saved if empty\")\n    parser.add_argument(\"--weights\", default=\"yolov4.weights\",\n                        help=\"yolo weights path\")\n    parser.add_argument(\"--dont_show\", action='store_true',\n                        help=\"windown inference display. For headless systems\")\n    parser.add_argument(\"--ext_output\", action='store_true',\n                        help=\"display bbox coordinates of detected objects\")\n    parser.add_argument(\"--config_file\", default=\"./cfg/yolov4.cfg\",\n                        help=\"path to config file\")\n    parser.add_argument(\"--data_file\", default=\"./cfg/coco.data\",\n                        help=\"path to data file\")\n    parser.add_argument(\"--thresh\", type=float, default=.25,\n                        help=\"remove detections with confidence below this value\")\n    return parser.parse_args()\n\n\ndef str2int(video_path):\n    \"\"\"\n    argparse returns and string althout webcam uses int (0, 1 ...)\n    Cast to int if needed\n    \"\"\"\n    try:\n        return int(video_path)\n    except ValueError:\n        return video_path\n\n\ndef check_arguments_errors(args):\n    assert 0 < args.thresh < 1, \"Threshold should be a float between zero and one (non-inclusive)\"\n    if not os.path.exists(args.config_file):\n        raise(ValueError(\"Invalid config path {}\".format(os.path.abspath(args.config_file))))\n    if not os.path.exists(args.weights):\n        raise(ValueError(\"Invalid weight path {}\".format(os.path.abspath(args.weights))))\n    if not os.path.exists(args.data_file):\n        raise(ValueError(\"Invalid data file path {}\".format(os.path.abspath(args.data_file))))\n    if str2int(args.input) == str and not os.path.exists(args.input):\n        raise(ValueError(\"Invalid video path {}\".format(os.path.abspath(args.input))))\n\n\ndef set_saved_video(input_video, output_video, size):\n    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n    fps = int(input_video.get(cv2.CAP_PROP_FPS))\n    video = cv2.VideoWriter(output_video, fourcc, fps, size)\n    return video\n\n\ndef video_capture(frame_queue, darknet_image_queue):\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame_resized = cv2.resize(frame_rgb, (width, height),\n                                   interpolation=cv2.INTER_LINEAR)\n        frame_queue.put(frame_resized)\n        img_for_detect = darknet.make_image(width, height, 3)\n        darknet.copy_image_from_bytes(img_for_detect, frame_resized.tobytes())\n        darknet_image_queue.put(img_for_detect)\n    cap.release()\n\n\ndef inference(darknet_image_queue, detections_queue, fps_queue):\n    while cap.isOpened():\n        darknet_image = darknet_image_queue.get()\n        prev_time = time.time()\n        detections = darknet.detect_image(network, class_names, darknet_image, thresh=args.thresh)\n        detections_queue.put(detections)\n        fps = int(1/(time.time() - prev_time))\n        fps_queue.put(fps)\n        print(\"FPS: {}\".format(fps))\n        darknet.print_detections(detections, args.ext_output)\n        darknet.free_image(darknet_image)\n    cap.release()\n\n\ndef drawing(frame_queue, detections_queue, fps_queue):\n    random.seed(3)  # deterministic bbox colors\n    video = set_saved_video(cap, args.out_filename, (width, height))\n    while cap.isOpened():\n        frame_resized = frame_queue.get()\n        detections = detections_queue.get()\n        fps = fps_queue.get()\n        if frame_resized is not None:\n            image = darknet.draw_boxes(detections, frame_resized, class_colors)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            if args.out_filename is not None:\n                video.write(image)\n            if not args.dont_show:\n                cv2.imshow('Inference', image)\n            if cv2.waitKey(fps) == 27:\n                break\n    cap.release()\n    video.release()\n    cv2.destroyAllWindows()\n\n\nif __name__ == '__main__':\n    frame_queue = Queue()\n    darknet_image_queue = Queue(maxsize=1)\n    detections_queue = Queue(maxsize=1)\n    fps_queue = Queue(maxsize=1)\n\n    args = parser()\n    check_arguments_errors(args)\n    network, class_names, class_colors = darknet.load_network(\n            args.config_file,\n            args.data_file,\n            args.weights,\n            batch_size=1\n        )\n    width = darknet.network_width(network)\n    height = darknet.network_height(network)\n    input_path = str2int(args.input)\n    cap = cv2.VideoCapture(input_path)\n    Thread(target=video_capture, args=(frame_queue, darknet_image_queue)).start()\n    Thread(target=inference, args=(darknet_image_queue, detections_queue, fps_queue)).start()\n    Thread(target=drawing, args=(frame_queue, detections_queue, fps_queue)).start()\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "image_yolov3.sh",
          "type": "blob",
          "size": 0.107421875,
          "content": "\n\n./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights data/dog.jpg -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "image_yolov4.sh",
          "type": "blob",
          "size": 0.107421875,
          "content": "\n\n./darknet detector test ./cfg/coco.data ./cfg/yolov4.cfg ./yolov4.weights data/dog.jpg -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "json_mjpeg_streams.sh",
          "type": "blob",
          "size": 0.3369140625,
          "content": "# Run this file and then open URL in Chrome/Firefox in 2 tabs: http://localhost:8070 and http://localhost:8090\n# Or open: http://ip-address:8070 and http://ip-address:8090\n# to get <ip-address> run: sudo ifconfig\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output\n\n"
        },
        {
          "name": "net_cam_v3.sh",
          "type": "blob",
          "size": 0.1552734375,
          "content": "#rm test_dnn_out.avi\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights rtsp://admin:admin12345@192.168.0.228:554 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "net_cam_v4.sh",
          "type": "blob",
          "size": 0.1552734375,
          "content": "#rm test_dnn_out.avi\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov4.cfg ./yolov4.weights rtsp://admin:admin12345@192.168.0.228:554 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "results",
          "type": "tree",
          "content": null
        },
        {
          "name": "sample",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "vcpkg.json",
          "type": "blob",
          "size": 0.357421875,
          "content": "{\n  \"name\": \"darknet\",\n  \"version-string\": \"0.2.5.4\",\n  \"port-version\": 1,\n  \"homepage\": \"https://github.com/alexeyab/darknet\",\n  \"description\": \"Neural networks for object detection\",\n  \"dependencies\": [\n    \"stb\",\n    \"pthreads\",\n    {\n      \"name\": \"opencv\",\n      \"features\": [ \"ffmpeg\" ]\n    },\n    {\n      \"name\": \"cudnn\",\n      \"platform\": \"!osx\"\n    }\n  ]\n}\n"
        },
        {
          "name": "video_yolov3.sh",
          "type": "blob",
          "size": 0.10546875,
          "content": "\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -i 0 -thresh 0.25\n\n\n\n"
        },
        {
          "name": "video_yolov4.sh",
          "type": "blob",
          "size": 0.10546875,
          "content": "\n\n./darknet detector demo ./cfg/coco.data ./cfg/yolov4.cfg ./yolov4.weights test50.mp4 -i 0 -thresh 0.25\n\n\n\n"
        }
      ]
    }
  ]
}