{
  "metadata": {
    "timestamp": 1736709673246,
    "page": 33,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "DualCoder/vgpu_unlock",
      "stars": 4669,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.251953125,
          "content": "root = true\n\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\nindent_style = space\nindent_size = 4\ntrim_trailing_whitespace = true\n\n[*.{c,h}]\nindent_style = tab\nindent_size = 8\n\n[*.ld]\nindent_size = 2\n\n[*.md]\ntrim_trailing_whitespace = false\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.01171875,
          "content": "* text=auto\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.7568359375,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "MIT License\n\nCopyright (c) 2021 Jonathan Johansson\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.2080078125,
          "content": "# vgpu\\_unlock\n\nUnlock vGPU functionality for consumer-grade Nvidia GPUs.\n\n\n## Important!\n\nThis tool is not guarenteed to work out of the box in some cases, \nso use it at your own risk.\n\n\n## Description\n\nThis tool enables the use of Geforce and Quadro GPUs with the NVIDIA vGPU\ngraphics virtualization technology. NVIDIA vGPU normally only supports a \nfew datacenter Teslas and professional Quadro GPUs by design, but not \nconsumer graphics cards through a software limitation. This vgpu_unlock tool \naims to remove this limitation on Linux based systems, thus enabling \nmost Maxwell, Pascal, Volta (untested), and Turing based GPUs to \nuse the vGPU technology. Ampere support is currently a work in progress.  \n  \nA community maintained Wiki written by Krutav Shah with a lot more information \nis [available here.](https://docs.google.com/document/d/1pzrWJ9h-zANCtyqRgS7Vzla0Y8Ea2-5z2HEi4X75d2Q/edit?usp=sharing)\n\n\n## Dependencies:\n\n* This tool requires Python3 and Python3-pip; the latest version is recommended.\n* The python package \"frida\" is required. `pip3 install frida`.\n* The tool requires the NVIDIA GRID vGPU driver.\n* \"dkms\" is required as it simplifies the process of rebuilding the\n  driver alot. Install DKMS with the package manager in your OS.\n\n\n## Installation:\n\nIn the following instructions `<path_to_vgpu_unlock>` need to be replaced with\nthe path to this repository on the target system and `<version>` need to be\nreplaced with the version of the NVIDIA GRID vGPU driver.\n\nInstall the NVIDIA GRID vGPU driver, make sure to install it as a dkms module.\n```\n./nvidia-installer --dkms\n```\n\nModify the line begining with `ExecStart=` in `/lib/systemd/system/nvidia-vgpud.service`\nand `/lib/systemd/system/nvidia-vgpu-mgr.service` to use `vgpu_unlock` as\nthe executable and pass the original executable as the first argument. Example:\n```\nExecStart=<path_to_vgpu_unlock>/vgpu_unlock /usr/bin/nvidia-vgpud\n```\n\nReload the systemd daemons:\n```\nsystemctl daemon-reload\n```\n\nModify the file `/usr/src/nvidia-<version>/nvidia/os-interface.c` and add the\nfollowing line after the lines begining with `#include` at the beginning of the\nfile.\n```\n#include \"<path_to_vgpu_unlock>/vgpu_unlock_hooks.c\"\n```\n\nModify the file `/usr/src/nvidia-<version>/nvidia/nvidia.Kbuild` and add the\nfollowing line at the bottom of the file.\n```\nldflags-y += -T <path_to_vgpu_unlock>/kern.ld\n```\n\nRemove the nvidia kernel module using dkms:\n```\ndkms remove -m nvidia -v <version> --all\n```\n\nRebuild and reinstall the nvidia kernel module using dkms:\n```\ndkms install -m nvidia -v <version>\n```\n\nReboot.\n\n---\n**NOTE**\n\nThis script only works with graphics cards in the same generation as their \nprofessional Tesla counterparts. As a result, only Maxwell and newer \ngeneration Nvidia GPUs are supported. It is not designed to be used with\nlow end graphics card models, so not all cards are guarenteed to work \nsmoothly with vGPU. For the best experience, it is recommended to use \ngraphics cards with the same chip model as the Tesla cards. \nThe same applies to the operating system as well, as certain bleeding-edge \nLinux distributions may not work well with vGPU software.\n\n---\n\n## How it works\n\n### vGPU supported?\n\nIn order to determine if a certain GPU supports the vGPU functionality the\ndriver looks at the PCI device ID. This identifier together with the PCI vendor\nID is unique for each type of PCI device. In order to enable vGPU support we\nneed to tell the driver that the PCI device ID of the installed GPU is one of\nthe device IDs used by a vGPU capable GPU.\n\n### Userspace script: vgpu\\_unlock\n\nThe userspace services nvidia-vgpud and nvidia-vgpu-mgr uses the ioctl syscall\nto communicate with the kernel module. Specifically they read the PCI device ID\nand determines if the installed GPU is vGPU capable.\n\nThe python script vgpu\\_unlock intercepts all ioctl syscalls between the\nexecutable specified as the first argument and the kernel. The script then\nmodifies the kernel responses to indicate a PCI device ID with vGPU support\nand a vGPU capable GPU.\n\n### Kernel module hooks: vgpu\\_unlock\\_hooks.c\n\nIn order to exchange data with the GPU the kernel module maps the physical\naddress space of the PCI bus into its own virtual address space. This is done\nusing the ioremap\\* kernel functions. The kernel module then reads and writes\ndata into that mapped address space. This is done using the memcpy kernel\nfunction.\n\nBy including the vgpu\\_unlock\\_hooks.c file into the os-interface.c file we can\nuse C preprocessor macros to replace and intercept calls to the iormeap and\nmemcpy functions. Doing this allows us to maintain a view of what is mapped\nwhere and what data that is being accessed.\n\n### Kernel module linker script: kern.ld\n\nThis is a modified version of the default linker script provided by gcc. The\nscript is modified to place the .rodata section of nv-kernel.o into .data\nsection instead of .rodata, making it writable. The script also provide the\nsymbols `vgpu_unlock_nv_kern_rodata_beg` and `vgpu_unlock_nv_kern_rodata_end`\nto let us know where that section begins and ends.\n\n### How it all comes together\n\nAfter boot the nvidia-vgpud service queries the kernel for all installed GPUs\nand checks for vGPU capability. This call is intercepted by the vgpu\\_unlock\npython script and the GPU is made vGPU capable. If a vGPU capable GPU is found\nthen nvidia-vgpu creates an MDEV device and the /sys/class/mdev\\_bus directory\nis created by the system.\n\nvGPU devices can now be created by echoing UUIDs into the `create` files in the\nmdev bus representation. This will create additional structures representing\nthe new vGPU device on the MDEV bus. These devices can then be assigned to VMs,\nand when the VM starts it will open the MDEV device. This causes nvidia-vgpu-mgr\nto start communicating with the kernel using ioctl. Again these calls are\nintercepted by the vgpu\\_unlock python script and when nvidia-vgpu-mgr asks if\nthe GPU is vGPU capable the answer is changed to yes. After that check it\nattempts to initialize the vGPU device instance.\n\nInitialization of the vGPU device is handled by the kernel module and it\nperforms its own check for vGPU capability, this one is a bit more complicated.\n\nThe kernel module maps the physical PCI address range 0xf0000000-0xf1000000 into\nits virtual address space, it then performs some magical operations which we\ndon't really know what they do. What we do know is that after these operations\nit accesses a 128 bit value at physical address 0xf0029624, which we call the\nmagic value. The kernel module also accessses a 128 bit value at physical \naddress 0xf0029634, which we call the key value.\n\nThe kernel module then has a couple of lookup tables for the magic value, one\nfor vGPU capable GPUs and one for the others. So the kernel module looks for the\nmagic value in both of these lookup tables, and if it is found that table entry\nalso contains a set of AES-128 encrypted data blocks and a HMAC-SHA256\nsignature.\n\nThe signature is then validated by using the key value mentioned earlier to\ncalculate the HMAC-SHA256 signature over the encrypted data blocks. If the\nsignature is correct, then the blocks are decrypted using AES-128 and the same\nkey.\n\nInside of the decrypted data is once again the PCI device ID.\n\nSo in order for the kernel module to accept the GPU as vGPU capable the magic\nvalue will have to be in the table of vGPU capable magic values, the key has\nto generate a valid HMAC-SHA256 signature and the AES-128 decrypted data blocks\nhas to contain a vGPU capable PCI device ID. If any of these checks fail, then\nthe error code 0x56 \"Call not supported\" is returned.\n\nIn order to make these checks pass the hooks in vgpu\\_unlock\\_hooks.c will look\nfor a ioremap call that maps the physical address range that contain the magic\nand key values, recalculate the addresses of those values into the virtual\naddress space of the kernel module, monitor memcpy operations reading at those\naddresses, and if such an operation occurs, keep a copy of the value until both\nare known, locate the lookup tables in the .rodata section of nv-kernel.o, find\nthe signature and data bocks, validate the signature, decrypt the blocks, edit\nthe PCI device ID in the decrypted data, reencrypt the blocks, regenerate the\nsignature and insert the magic, blocks and signature into the table of vGPU\ncapable magic values. And that's what they do.\n\n"
        },
        {
          "name": "kern.ld",
          "type": "blob",
          "size": 5.43359375,
          "content": "/* Script for ld -r: link without relocation */\n/* Copyright (C) 2014-2018 Free Software Foundation, Inc.\n   Copying and distribution of this script, with or without modification,\n   are permitted in any medium without royalty provided the copyright\n   notice and this notice are preserved.  */\nOUTPUT_FORMAT(\"elf64-x86-64\", \"elf64-x86-64\",\n\t      \"elf64-x86-64\")\nOUTPUT_ARCH(i386:x86-64)\n /* For some reason, the Solaris linker makes bad executables\n  if gld -r is used and the intermediate file has sections starting\n  at non-zero addresses.  Could be a Solaris ld bug, could be a GNU ld\n  bug.  But for now assigning the zero vmas works.  */\nSECTIONS\n{\n  /* Read-only sections, merged into text segment: */\n  .interp       0 : { *(.interp) }\n  .note.gnu.build-id : { *(.note.gnu.build-id) }\n  .hash         0 : { *(.hash) }\n  .gnu.hash     0 : { *(.gnu.hash) }\n  .dynsym       0 : { *(.dynsym) }\n  .dynstr       0 : { *(.dynstr) }\n  .gnu.version  0 : { *(.gnu.version) }\n  .gnu.version_d 0: { *(.gnu.version_d) }\n  .gnu.version_r 0: { *(.gnu.version_r) }\n  .rela.init    0 : { *(.rela.init) }\n  .rela.text    0 : { *(.rela.text) }\n  .rela.fini    0 : { *(.rela.fini) }\n  .rela.rodata  0 : { *(.rela.rodata) }\n  .rela.data.rel.ro 0 : { *(.rela.data.rel.ro) }\n  .rela.data    0 : { *(.rela.data) }\n  .rela.tdata\t0 : { *(.rela.tdata) }\n  .rela.tbss\t0 : { *(.rela.tbss) }\n  .rela.ctors   0 : { *(.rela.ctors) }\n  .rela.dtors   0 : { *(.rela.dtors) }\n  .rela.got     0 : { *(.rela.got) }\n  .rela.bss     0 : { *(.rela.bss) }\n  .rela.ldata   0 : { *(.rela.ldata) }\n  .rela.lbss    0 : { *(.rela.lbss) }\n  .rela.lrodata 0 : { *(.rela.lrodata) }\n  .rela.ifunc   0 : { *(.rela.ifunc) }\n  .rela.plt     0 :\n    {\n      *(.rela.plt)\n    }\n  .init         0 :\n  {\n    KEEP (*(SORT_NONE(.init)))\n  }\n  .plt          0 : { *(.plt) *(.iplt) }\n.plt.got      0 : { *(.plt.got) }\n.plt.sec      0 : { *(.plt.sec) }\n  .text         0 :\n  {\n    *(.text .stub)\n    /* .gnu.warning sections are handled specially by elf32.em.  */\n    *(.gnu.warning)\n  }\n  .fini         0 :\n  {\n    KEEP (*(SORT_NONE(.fini)))\n  }\n  .rodata       0 : { *(EXCLUDE_FILE (*nv-kernel.o) .rodata) }\n  .rodata1      0 : { *(.rodata1) }\n  .eh_frame_hdr : { *(.eh_frame_hdr)  }\n  .eh_frame     0 : ONLY_IF_RO { KEEP (*(.eh_frame))  }\n  .gcc_except_table 0 : ONLY_IF_RO { *(.gcc_except_table\n  .gcc_except_table.*) }\n  .gnu_extab 0 : ONLY_IF_RO { *(.gnu_extab*) }\n  /* These sections are generated by the Sun/Oracle C++ compiler.  */\n  .exception_ranges 0 : ONLY_IF_RO { *(.exception_ranges\n  .exception_ranges*) }\n  /* Adjust the address for the data segment.  We want to adjust up to\n     the same address within the page on the next page up.  */\n  /* Exception handling  */\n  .eh_frame     0 : ONLY_IF_RW { KEEP (*(.eh_frame))  }\n  .gnu_extab    0 : ONLY_IF_RW { *(.gnu_extab) }\n  .gcc_except_table 0 : ONLY_IF_RW { *(.gcc_except_table .gcc_except_table.*) }\n  .exception_ranges 0 : ONLY_IF_RW { *(.exception_ranges .exception_ranges*) }\n  /* Thread Local Storage sections  */\n  .tdata\t0 :\n   {\n     *(.tdata)\n   }\n  .tbss\t\t0 : { *(.tbss) }\n  .jcr          0 : { KEEP (*(.jcr)) }\n  .dynamic      0 : { *(.dynamic) }\n  .got          0 : { *(.got) *(.igot) }\n  .got.plt      0 : { *(.got.plt)  *(.igot.plt) }\n  .data         0 :\n  {\n    *(.data)\n    vgpu_unlock_nv_kern_rodata_beg = .;\n    *nv-kernel.o(.rodata*)\n    vgpu_unlock_nv_kern_rodata_end = .;\n  }\n  .data1        0 : { *(.data1) }\n  .bss          0 :\n  {\n   *(.bss)\n   *(COMMON)\n   /* Align here to ensure that the .bss section occupies space up to\n      _end.  Align after .bss to ensure correct alignment even if the\n      .bss section disappears because there are no input sections.\n      FIXME: Why do we need it? When there is no .bss section, we don't\n      pad the .data section.  */\n  }\n  .lbss 0 :\n  {\n    *(.dynlbss)\n    *(.lbss)\n    *(LARGE_COMMON)\n  }\n  .lrodata 0  :\n  {\n    *(.lrodata)\n  }\n  .ldata 0  :\n  {\n    *(.ldata)\n  }\n  /* Stabs debugging sections.  */\n  .stab          0 : { *(.stab) }\n  .stabstr       0 : { *(.stabstr) }\n  .stab.excl     0 : { *(.stab.excl) }\n  .stab.exclstr  0 : { *(.stab.exclstr) }\n  .stab.index    0 : { *(.stab.index) }\n  .stab.indexstr 0 : { *(.stab.indexstr) }\n  .comment       0 : { *(.comment) }\n  /* DWARF debug sections.\n     Symbols in the DWARF debugging sections are relative to the beginning\n     of the section so we begin them at 0.  */\n  /* DWARF 1 */\n  .debug          0 : { *(.debug) }\n  .line           0 : { *(.line) }\n  /* GNU DWARF 1 extensions */\n  .debug_srcinfo  0 : { *(.debug_srcinfo) }\n  .debug_sfnames  0 : { *(.debug_sfnames) }\n  /* DWARF 1.1 and DWARF 2 */\n  .debug_aranges  0 : { *(.debug_aranges) }\n  .debug_pubnames 0 : { *(.debug_pubnames) }\n  /* DWARF 2 */\n  .debug_info     0 : { *(.debug_info) }\n  .debug_abbrev   0 : { *(.debug_abbrev) }\n  .debug_line     0 : { *(.debug_line .debug_line.* .debug_line_end ) }\n  .debug_frame    0 : { *(.debug_frame) }\n  .debug_str      0 : { *(.debug_str) }\n  .debug_loc      0 : { *(.debug_loc) }\n  .debug_macinfo  0 : { *(.debug_macinfo) }\n  /* SGI/MIPS DWARF 2 extensions */\n  .debug_weaknames 0 : { *(.debug_weaknames) }\n  .debug_funcnames 0 : { *(.debug_funcnames) }\n  .debug_typenames 0 : { *(.debug_typenames) }\n  .debug_varnames  0 : { *(.debug_varnames) }\n  /* DWARF 3 */\n  .debug_pubtypes 0 : { *(.debug_pubtypes) }\n  .debug_ranges   0 : { *(.debug_ranges) }\n  /* DWARF Extension.  */\n  .debug_macro    0 : { *(.debug_macro) }\n  .debug_addr     0 : { *(.debug_addr) }\n  .gnu.attributes 0 : { KEEP (*(.gnu.attributes)) }\n}\n\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "vgpu_unlock",
          "type": "blob",
          "size": 8.4248046875,
          "content": "#!/bin/python3\n#\n# vGPU unlock script for consumer GPUs.\n#\n# Copyright 2021 Jonathan Johansson\n# This file is part of the \"vgpu_unlock\" project, and is distributed under the MIT License.\n# See the LICENSE file for more details.\n#\n# Contributions from Krutav Shah and the vGPU Unlocking community included :)\n#\n\nimport errno\nimport frida\nimport os\nimport queue\nimport subprocess\nimport sys\nimport time\n\nscript_source = r\"\"\"\n    var syslog_func = new NativeFunction(Module.getExportByName(null, \"syslog\"),\n                                         \"void\",\n                                         [\"int\", \"pointer\", \"...\", \"pointer\"]);\n\n    var syslog = function(message) {\n        var format_ptr = Memory.allocUtf8String(\"%s\");\n        var message_ptr = Memory.allocUtf8String(message);\n        syslog_func(5, format_ptr, message_ptr);\n    };\n\n\n    // Value of the \"request\" argument used by nvidia-vgpud and nvidia-vgpu-mgr\n    // when calling ioctl to read the PCI device ID and type (and possibly\n    // other things) from the GPU.\n    var REQ_QUERY_GPU = ptr(\"0xC020462A\");\n\n    // When issuing ioctl with REQ_QUERY_GPU then the \"argp\" argument is a\n    // pointer to a structure something like this:\n    //\n    // struct arg {\n    //    uint32_t unknown_1; // Initialized prior to call.\n    //    uint32_t unknown_2; // Initialized prior to call.\n    //    uint32_t op_type;   // Operation type, see comment below.\n    //    uint32_t padding_1; // Always set to 0 prior to call.\n    //    void*    result;    // Pointer initialized prior to call.\n    //                        // Pointee initialized to 0 prior to call.\n    //                        // Pointee is written by ioctl call.\n    //    uint32_t unknown_4; // Set to 0x10 for READ_PCI_ID and set to 4 for\n                              // READ_DEV_TYPE prior to call.\n    //    uint32_t status;    // Written by ioctl call. See comment below.\n    // }\n\n    // These are the observed values for the op_type member.\n    var OP_READ_DEV_TYPE = 0x800289; // *result type is uint64_t.\n    var OP_READ_PCI_ID = 0x20801801; // *result type is uint16_t[4], the second\n                                     // element (index 1) is the device ID, the\n                                     // forth element (index 3) is the subsystem\n                                     // ID.\n\n    // nvidia-vgpu-mgr expects this value for a vGPU capable GPU.\n    var DEV_TYPE_VGPU_CAPABLE = uint64(3);\n\n    // When ioctl returns success (retval >= 0) but sets the status value of\n    // the arg structure to 3 then nvidia-vgpud will sleep for a bit (first\n    // 0.1s then 1s then 10s) then issue the same ioctl call again until the\n    // status differs from 3. It will attempt this for up to 24h before giving\n    // up.\n    var STATUS_OK = 0;\n    var STATUS_TRY_AGAIN = 3;\n\n    Interceptor.attach(Module.getExportByName(null, \"ioctl\"), {\n        onEnter(args) {\n            this.request = args[1];\n            this.argp = args[2];\n        },\n        onLeave(retVal) {\n            if(!this.request.equals(REQ_QUERY_GPU)) {\n                // Not a call we care about.\n                return;\n            }\n\n            if(retVal.toInt32() < 0) {\n                // Call failed.\n                return;\n            }\n\n            // Lookup status value according to struct above.\n            var status = this.argp.add(0x1C).readU32();\n\n            if(status == STATUS_TRY_AGAIN) {\n                // Driver will try again.\n                return;\n            }\n\n            var op_type = this.argp.add(8).readU32();\n\n            if(op_type == OP_READ_PCI_ID) {\n                // Lookup address of the device and subsystem IDs.\n                var devid_ptr = this.argp.add(0x10).readPointer().add(2);\n                var subsysid_ptr = this.argp.add(0x10).readPointer().add(6);\n\n                // Now we replace the device ID with a spoofed value that needs to\n                // be determined such that the spoofed value represents a GPU with\n                // vGPU support that uses the same GPU chip as our actual GPU.\n                var actual_devid = devid_ptr.readU16();\n                var spoofed_devid = actual_devid;\n                var actual_subsysid = subsysid_ptr.readU16();\n                var spoofed_subsysid = actual_subsysid;\n                \n                // Maxwell\n                if(0x1340 <= actual_devid && actual_devid <= 0x13bd ||\n                   0x174d <= actual_devid && actual_devid <= 0x179c) {\n                    spoofed_devid = 0x13bd; // Tesla M10\n                    spoofed_subsysid = 0x1160;\n                }\n\n                // Maxwell 2.0\n                if(0x13c0 <= actual_devid && actual_devid <= 0x1436 ||\n                   0x1617 <= actual_devid && actual_devid <= 0x1667 ||\n                   0x17c2 <= actual_devid && actual_devid <= 0x17fd) {\n                    spoofed_devid = 0x13f2; // Tesla M60\n                }\n\n                // Pascal\n                if(0x15f0 <= actual_devid && actual_devid <= 0x15f1 ||\n                   0x1b00 <= actual_devid && actual_devid <= 0x1d56 ||\n                   0x1725 <= actual_devid && actual_devid <= 0x172f) {\n                    spoofed_devid = 0x1b38; // Tesla P40\n                }\n\n                // GV100 Volta\n                if(actual_devid == 0x1d81 || // TITAN V\n                   actual_devid == 0x1dba) { // Quadro GV100 32GB\n                    spoofed_devid = 0x1db6; // Tesla V100 32GB PCIE\n                }\n\n                // Turing\n                if(0x1e02 <= actual_devid && actual_devid <= 0x1ff9 ||\n                   0x2182 <= actual_devid && actual_devid <= 0x21d1) {\n                    spoofed_devid = 0x1e30; // Quadro RTX 6000\n                    spoofed_subsysid = 0x12ba;\n                }\n\n                // Ampere\n                if(0x2200 <= actual_devid && actual_devid <= 0x2600) {\n                    spoofed_devid = 0x2230; // RTX A6000\n                }\n\n                devid_ptr.writeU16(spoofed_devid);\n                subsysid_ptr.writeU16(spoofed_subsysid);\n            }\n            \n            if(op_type == OP_READ_DEV_TYPE) {\n                // Set device type to vGPU capable.\n                var dev_type_ptr = this.argp.add(0x10).readPointer();\n                dev_type_ptr.writeU64(DEV_TYPE_VGPU_CAPABLE);\n            }\n\n            if(status != STATUS_OK) {\n                // Things seems to work fine even if some operations that fail\n                // result in failed assertions. So here we change the status\n                // value for these cases to cleanup the logs for nvidia-vgpu-mgr.\n                if(op_type == 0xA0820104 ||\n                   op_type == 0x90960103) {\n                    this.argp.add(0x1C).writeU32(STATUS_OK);\n                } else {\n                    syslog(\"op_type: 0x\" + op_type.toString(16) + \" failed.\");\n                }\n            }\n\n            // Workaround for some Maxwell cards not supporting reading inforom.\n            if(op_type == 0x2080014b && status == 0x56) {\n                this.argp.add(0x1C).writeU32(0x57);\n            }\n        }\n    });\n\n    syslog(\"vgpu_unlock loaded.\");\n\"\"\"\n\ndevice = frida.get_local_device()\nchild_processes = queue.Queue()\n\ndef instrument(pid):\n    \"\"\"Instrument and resume process.\n\n    :param pid: Process identifier\n    \"\"\"\n\n    session = device.attach(pid)\n    # We need to also instrument the children since nvidia-vgpud forks itself\n    # when initially launched.\n    session.enable_child_gating()\n    script = session.create_script(script_source)\n    script.load()\n    device.resume(pid)\n\n\ndef on_child_added(child):\n    \"\"\"Callback for when a new child process has been created.\n\n    :param child: The newly created child process.\n    \"\"\"\n\n    child_processes.put(child.pid)\n    instrument(child.pid)\n\n\ndef wait_exit(pid):\n    \"\"\"Wait for a process to terminate.\n\n    :param pid: Process ID of the target process.\n    \"\"\"\n\n    while 1:\n        time.sleep(.1)\n\n        try:\n            os.kill(pid, 0)\n\n        except OSError as e:\n            if e.errno == errno.ESRCH:\n                break\n\n\ndef main():\n    \"\"\"Entrypoint.\"\"\"\n\n    # Behave at least a little bit like a forking service.\n    if sys.argv[1] != \"-f\":\n        subprocess.Popen([sys.argv[0], \"-f\"] + sys.argv[1:])\n        exit()\n\n    device.on(\"child-added\", on_child_added)\n    pid = device.spawn([\"/bin/bash\", \"-c\", ' '.join(sys.argv[2:])])\n    instrument(pid)\n\n    # Wait for everything to terminate before exiting.\n    wait_exit(pid)\n\n    while not child_processes.empty():\n        wait_exit(child_processes.get_nowait())\n\n\nif __name__ == \"__main__\":\n    main()\n\n"
        },
        {
          "name": "vgpu_unlock_hooks.c",
          "type": "blob",
          "size": 37.345703125,
          "content": "/*\n * vGPU unlock hooks.\n *\n * This file is designed to be included into a single translation unit of the\n * vGPU driver's kernel module. It hooks the nv_ioremap_* functions and memcpy\n * for that translation unit and applies the vgpu_unlock patch when the magic\n * and key values has been accessed by the driver.\n *\n * Copyright 2021 Jonathan Johansson\n * This file is part of the \"vgpu_unlock\" project, and is distributed under the\n * MIT License. See the LICENSE file for more details.\n * \n * Contributions from Krutav Shah and the vGPU Unlocking community included :)\n * \n */\n\n/*------------------------------------------------------------------------------\n * Implementation of AES128-ECB.\n *------------------------------------------------------------------------------\n */\n\ntypedef struct \n{\n\tuint8_t round_key[176];\n}\nvgpu_unlock_aes128_ctx;\n\ntypedef uint8_t vgpu_unlock_aes128_state[4][4];\n\n#define Nb 4\n#define Nk 4\n#define Nr 10\n#define getSBoxValue(num) (vgpu_unlock_aes128_sbox[(num)])\n#define getSBoxInvert(num) (vgpu_unlock_aes128_rsbox[(num)])\n#define Multiply(x, y)                                                                                                            \\\n\t(  ((y & 1) * x) ^                                                                                                        \\\n\t((y>>1 & 1) * vgpu_unlock_aes128_xtime(x)) ^                                                                              \\\n\t((y>>2 & 1) * vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(x))) ^                                                    \\\n\t((y>>3 & 1) * vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(x)))) ^                          \\\n\t((y>>4 & 1) * vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(vgpu_unlock_aes128_xtime(x)))))) \\\n\nstatic const uint8_t vgpu_unlock_aes128_sbox[256] = {\n  //0     1    2      3     4    5     6     7      8    9     A      B    C     D     E     F\n  0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,\n  0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,\n  0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,\n  0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,\n  0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,\n  0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,\n  0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,\n  0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,\n  0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,\n  0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,\n  0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,\n  0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,\n  0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,\n  0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,\n  0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,\n  0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16 };\n\nstatic const uint8_t vgpu_unlock_aes128_rsbox[256] = {\n  0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb,\n  0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87, 0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb,\n  0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d, 0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e,\n  0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2, 0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25,\n  0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92,\n  0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda, 0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84,\n  0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a, 0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06,\n  0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02, 0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b,\n  0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea, 0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73,\n  0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85, 0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e,\n  0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89, 0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b,\n  0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20, 0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4,\n  0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31, 0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f,\n  0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d, 0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef,\n  0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0, 0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61,\n  0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26, 0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d };\n\nstatic const uint8_t vgpu_unlock_aes128_rcon[11] = {\n  0x8d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36 };\n\nstatic void vgpu_unlock_aes128_key_expansion(uint8_t *round_key,\n                                             const uint8_t *Key)\n{\n\tunsigned i, j, k;\n\tuint8_t tempa[4];\n  \n\tfor (i = 0; i < Nk; ++i)\n\t{\n\t\tround_key[(i * 4) + 0] = Key[(i * 4) + 0];\n\t\tround_key[(i * 4) + 1] = Key[(i * 4) + 1];\n\t\tround_key[(i * 4) + 2] = Key[(i * 4) + 2];\n\t\tround_key[(i * 4) + 3] = Key[(i * 4) + 3];\n\t}\n\n\tfor (i = Nk; i < Nb * (Nr + 1); ++i)\n\t{\n\t\tk = (i - 1) * 4;\n\t\ttempa[0] = round_key[k + 0];\n\t\ttempa[1] = round_key[k + 1];\n\t\ttempa[2] = round_key[k + 2];\n\t\ttempa[3] = round_key[k + 3];\n\n\t\tif (i % Nk == 0)\n\t\t{\n\t\t\tconst uint8_t u8tmp = tempa[0];\n\t\t\ttempa[0] = tempa[1];\n\t\t\ttempa[1] = tempa[2];\n\t\t\ttempa[2] = tempa[3];\n\t\t\ttempa[3] = u8tmp;\n\t\t\ttempa[0] = getSBoxValue(tempa[0]);\n\t\t\ttempa[1] = getSBoxValue(tempa[1]);\n\t\t\ttempa[2] = getSBoxValue(tempa[2]);\n\t\t\ttempa[3] = getSBoxValue(tempa[3]);\n\t\t\ttempa[0] = tempa[0] ^ vgpu_unlock_aes128_rcon[i/Nk];\n\t\t}\n\n\t\tj = i * 4; k=(i - Nk) * 4;\n\t\tround_key[j + 0] = round_key[k + 0] ^ tempa[0];\n\t\tround_key[j + 1] = round_key[k + 1] ^ tempa[1];\n\t\tround_key[j + 2] = round_key[k + 2] ^ tempa[2];\n\t\tround_key[j + 3] = round_key[k + 3] ^ tempa[3];\n\t}\n}\n\nstatic void vgpu_unlock_aes128_add_round_key(uint8_t round,\n                                             vgpu_unlock_aes128_state *state,\n                                             const uint8_t *round_key)\n{\n\tuint8_t i,j;\n\n\tfor (i = 0; i < 4; ++i)\n\t{\n\t\tfor (j = 0; j < 4; ++j)\n\t\t{\n\t\t\t(*state)[i][j] ^= round_key[(round * Nb * 4) + (i * Nb) + j];\n\t\t}\n\t}\n}\n\nstatic void vgpu_unlock_aes128_sub_bytes(vgpu_unlock_aes128_state *state)\n{\n\tuint8_t i, j;\n\n\tfor (i = 0; i < 4; ++i)\n\t{\n\t\tfor (j = 0; j < 4; ++j)\n\t\t{\n\t\t\t(*state)[j][i] = getSBoxValue((*state)[j][i]);\n\t\t}\n\t}\n}\n\nstatic void vgpu_unlock_aes128_shift_rows(vgpu_unlock_aes128_state *state)\n{\n\tuint8_t temp;\n\n\ttemp           = (*state)[0][1];\n\t(*state)[0][1] = (*state)[1][1];\n\t(*state)[1][1] = (*state)[2][1];\n\t(*state)[2][1] = (*state)[3][1];\n\t(*state)[3][1] = temp;\n\n\ttemp           = (*state)[0][2];\n\t(*state)[0][2] = (*state)[2][2];\n\t(*state)[2][2] = temp;\n\n\ttemp           = (*state)[1][2];\n\t(*state)[1][2] = (*state)[3][2];\n\t(*state)[3][2] = temp;\n\n\ttemp           = (*state)[0][3];\n\t(*state)[0][3] = (*state)[3][3];\n\t(*state)[3][3] = (*state)[2][3];\n\t(*state)[2][3] = (*state)[1][3];\n\t(*state)[1][3] = temp;\n}\n\nstatic uint8_t vgpu_unlock_aes128_xtime(uint8_t x)\n{\n\treturn ((x<<1) ^ (((x>>7) & 1) * 0x1b));\n}\n\nstatic void vgpu_unlock_aes128_mix_columns(vgpu_unlock_aes128_state *state)\n{\n\tuint8_t i;\n\tuint8_t tmp, tm, t;\n\n\tfor (i = 0; i < 4; ++i)\n\t{  \n\t\tt   = (*state)[i][0];\n\t  \ttmp = (*state)[i][0] ^ (*state)[i][1] ^ (*state)[i][2] ^ (*state)[i][3];\n\t  \ttm  = (*state)[i][0] ^ (*state)[i][1];\n\t\ttm = vgpu_unlock_aes128_xtime(tm);  (*state)[i][0] ^= tm ^ tmp;\n\t  \ttm  = (*state)[i][1] ^ (*state)[i][2];\n\t\ttm = vgpu_unlock_aes128_xtime(tm);  (*state)[i][1] ^= tm ^ tmp;\n\t  \ttm  = (*state)[i][2] ^ (*state)[i][3];\n\t\ttm = vgpu_unlock_aes128_xtime(tm);  (*state)[i][2] ^= tm ^ tmp;\n\t  \ttm  = (*state)[i][3] ^ t;\n\t\ttm = vgpu_unlock_aes128_xtime(tm);  (*state)[i][3] ^= tm ^ tmp;\n\t}\n}\n\nstatic void vgpu_unlock_aes128_inv_mix_columns(vgpu_unlock_aes128_state *state)\n{\n\tint i;\n\tuint8_t a, b, c, d;\n\n\tfor (i = 0; i < 4; ++i)\n\t{ \n\t\ta = (*state)[i][0];\n\t\tb = (*state)[i][1];\n\t\tc = (*state)[i][2];\n\t\td = (*state)[i][3];\n\n\t\t(*state)[i][0] = Multiply(a, 0x0e) ^ Multiply(b, 0x0b) ^ Multiply(c, 0x0d) ^ Multiply(d, 0x09);\n\t\t(*state)[i][1] = Multiply(a, 0x09) ^ Multiply(b, 0x0e) ^ Multiply(c, 0x0b) ^ Multiply(d, 0x0d);\n\t\t(*state)[i][2] = Multiply(a, 0x0d) ^ Multiply(b, 0x09) ^ Multiply(c, 0x0e) ^ Multiply(d, 0x0b);\n\t\t(*state)[i][3] = Multiply(a, 0x0b) ^ Multiply(b, 0x0d) ^ Multiply(c, 0x09) ^ Multiply(d, 0x0e);\n\t}\n}\n\nstatic void vgpu_unlock_aes128_inv_sub_bytes(vgpu_unlock_aes128_state *state)\n{\n\tuint8_t i, j;\n\n\tfor (i = 0; i < 4; ++i)\n\t{\n\t\tfor (j = 0; j < 4; ++j)\n\t\t{\n\t\t\t(*state)[j][i] = getSBoxInvert((*state)[j][i]);\n\t\t}\n\t}\n}\n\nstatic void vgpu_unlock_aes128_inv_shift_rows(vgpu_unlock_aes128_state *state)\n{\n\tuint8_t temp;\n\n\ttemp = (*state)[3][1];\n\t(*state)[3][1] = (*state)[2][1];\n\t(*state)[2][1] = (*state)[1][1];\n\t(*state)[1][1] = (*state)[0][1];\n\t(*state)[0][1] = temp;\n\n\ttemp = (*state)[0][2];\n\t(*state)[0][2] = (*state)[2][2];\n\t(*state)[2][2] = temp;\n\n\ttemp = (*state)[1][2];\n\t(*state)[1][2] = (*state)[3][2];\n\t(*state)[3][2] = temp;\n\n\ttemp = (*state)[0][3];\n\t(*state)[0][3] = (*state)[1][3];\n\t(*state)[1][3] = (*state)[2][3];\n\t(*state)[2][3] = (*state)[3][3];\n\t(*state)[3][3] = temp;\n}\n\nstatic void vgpu_unlock_aes128_cipher(vgpu_unlock_aes128_state *state,\n                                      const uint8_t* round_key)\n{\n\tuint8_t round = 0;\n\n\tvgpu_unlock_aes128_add_round_key(0, state, round_key);\n\n\tfor (round = 1; ; ++round)\n\t{\n\t\tvgpu_unlock_aes128_sub_bytes(state);\n\t\tvgpu_unlock_aes128_shift_rows(state);\n\n\t\tif (round == Nr)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\tvgpu_unlock_aes128_mix_columns(state);\n\t\tvgpu_unlock_aes128_add_round_key(round, state, round_key);\n\t}\n\n\tvgpu_unlock_aes128_add_round_key(Nr, state, round_key);\n}\n\nstatic void vgpu_unlock_aes128_inv_cipher(vgpu_unlock_aes128_state *state,\n                                          const uint8_t* round_key)\n{\n\tuint8_t round = 0;\n\n\tvgpu_unlock_aes128_add_round_key(Nr, state, round_key);\n\n\tfor (round = (Nr - 1); ; --round)\n\t{\n\t\tvgpu_unlock_aes128_inv_shift_rows(state);\n\t\tvgpu_unlock_aes128_inv_sub_bytes(state);\n\t\tvgpu_unlock_aes128_add_round_key(round, state, round_key);\n\n\t\tif (round == 0)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\tvgpu_unlock_aes128_inv_mix_columns(state);\n\t}\n}\n\nstatic void vgpu_unlock_aes128_init(vgpu_unlock_aes128_ctx *ctx,\n                                    const uint8_t *key)\n{\n\tvgpu_unlock_aes128_key_expansion(ctx->round_key, key);\n}\n\nstatic void vgpu_unlock_aes128_encrypt(const vgpu_unlock_aes128_ctx *ctx,\n                                       uint8_t *buf)\n{\n\tvgpu_unlock_aes128_cipher((vgpu_unlock_aes128_state*)buf,\n\t                          ctx->round_key);\n}\n\nstatic void vgpu_unlock_aes128_decrypt(const vgpu_unlock_aes128_ctx *ctx,\n                                       uint8_t* buf)\n{\n\tvgpu_unlock_aes128_inv_cipher((vgpu_unlock_aes128_state*)buf,\n\t                              ctx->round_key);\n}\n\n#undef Nb\n#undef Nk\n#undef Nr\n#undef getSBoxValue\n#undef getSBoxInvert\n#undef Multiply\n\n/*------------------------------------------------------------------------------\n * End of AES128-ECB implementation.\n *------------------------------------------------------------------------------\n */\n\n/*------------------------------------------------------------------------------\n * Implementation of SHA256.\n * Original author: Brad Conte (brad AT bradconte.com)\n *------------------------------------------------------------------------------\n */\n\ntypedef struct {\n\tuint8_t data[64];\n\tuint32_t datalen;\n\tuint64_t bitlen;\n\tuint32_t state[8];\n}\nvgpu_unlock_sha256_ctx;\n\n#define ROTLEFT(a,b) (((a) << (b)) | ((a) >> (32-(b))))\n#define ROTRIGHT(a,b) (((a) >> (b)) | ((a) << (32-(b))))\n\n#define CH(x,y,z) (((x) & (y)) ^ (~(x) & (z)))\n#define MAJ(x,y,z) (((x) & (y)) ^ ((x) & (z)) ^ ((y) & (z)))\n#define EP0(x) (ROTRIGHT(x,2) ^ ROTRIGHT(x,13) ^ ROTRIGHT(x,22))\n#define EP1(x) (ROTRIGHT(x,6) ^ ROTRIGHT(x,11) ^ ROTRIGHT(x,25))\n#define SIG0(x) (ROTRIGHT(x,7) ^ ROTRIGHT(x,18) ^ ((x) >> 3))\n#define SIG1(x) (ROTRIGHT(x,17) ^ ROTRIGHT(x,19) ^ ((x) >> 10))\n\nstatic void vgpu_unlock_sha256_transform(vgpu_unlock_sha256_ctx *ctx,\n                                         const uint8_t data[])\n{\n\tstatic const uint32_t k[64] = {\n\t\t0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5,0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5,\n\t\t0xd807aa98,0x12835b01,0x243185be,0x550c7dc3,0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174,\n\t\t0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc,0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da,\n\t\t0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7,0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967,\n\t\t0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13,0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85,\n\t\t0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3,0xd192e819,0xd6990624,0xf40e3585,0x106aa070,\n\t\t0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5,0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3,\n\t\t0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208,0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2\n\t};\n\n\tuint32_t a, b, c, d, e, f, g, h, i, j, t1, t2, m[64];\n\n\tfor (i = 0, j = 0; i < 16; ++i, j += 4)\n\t\tm[i] = (data[j] << 24) | (data[j + 1] << 16) | (data[j + 2] << 8) | (data[j + 3]);\n\tfor ( ; i < 64; ++i)\n\t\tm[i] = SIG1(m[i - 2]) + m[i - 7] + SIG0(m[i - 15]) + m[i - 16];\n\n\ta = ctx->state[0];\n\tb = ctx->state[1];\n\tc = ctx->state[2];\n\td = ctx->state[3];\n\te = ctx->state[4];\n\tf = ctx->state[5];\n\tg = ctx->state[6];\n\th = ctx->state[7];\n\n\tfor (i = 0; i < 64; ++i) {\n\t\tt1 = h + EP1(e) + CH(e,f,g) + k[i] + m[i];\n\t\tt2 = EP0(a) + MAJ(a,b,c);\n\t\th = g;\n\t\tg = f;\n\t\tf = e;\n\t\te = d + t1;\n\t\td = c;\n\t\tc = b;\n\t\tb = a;\n\t\ta = t1 + t2;\n\t}\n\n\tctx->state[0] += a;\n\tctx->state[1] += b;\n\tctx->state[2] += c;\n\tctx->state[3] += d;\n\tctx->state[4] += e;\n\tctx->state[5] += f;\n\tctx->state[6] += g;\n\tctx->state[7] += h;\n}\n\nstatic void vgpu_unlock_sha256_init(vgpu_unlock_sha256_ctx *ctx)\n{\n\tctx->datalen = 0;\n\tctx->bitlen = 0;\n\tctx->state[0] = 0x6a09e667;\n\tctx->state[1] = 0xbb67ae85;\n\tctx->state[2] = 0x3c6ef372;\n\tctx->state[3] = 0xa54ff53a;\n\tctx->state[4] = 0x510e527f;\n\tctx->state[5] = 0x9b05688c;\n\tctx->state[6] = 0x1f83d9ab;\n\tctx->state[7] = 0x5be0cd19;\n}\n\nstatic void vgpu_unlock_sha256_update(vgpu_unlock_sha256_ctx *ctx,\n                                      const uint8_t data[],\n                                      size_t len)\n{\n\tuint32_t i;\n\n\tfor (i = 0; i < len; ++i) {\n\t\tctx->data[ctx->datalen] = data[i];\n\t\tctx->datalen++;\n\t\tif (ctx->datalen == 64) {\n\t\t\tvgpu_unlock_sha256_transform(ctx, ctx->data);\n\t\t\tctx->bitlen += 512;\n\t\t\tctx->datalen = 0;\n\t\t}\n\t}\n}\n\nstatic void vgpu_unlock_sha256_final(vgpu_unlock_sha256_ctx *ctx,\n                                     uint8_t hash[])\n{\n\tuint32_t i;\n\n\ti = ctx->datalen;\n\n\t/* Pad whatever data is left in the buffer. */\n\tif (ctx->datalen < 56) {\n\t\tctx->data[i++] = 0x80;\n\t\twhile (i < 56)\n\t\t\tctx->data[i++] = 0x00;\n\t}\n\telse {\n\t\tctx->data[i++] = 0x80;\n\t\twhile (i < 64)\n\t\t\tctx->data[i++] = 0x00;\n\t\tvgpu_unlock_sha256_transform(ctx, ctx->data);\n\t\tmemset(ctx->data, 0, 56);\n\t}\n\n\t/*\n\t * Append to the padding the total message's length in bits and\n\t * transform.\n\t */\n\tctx->bitlen += ctx->datalen * 8;\n\tctx->data[63] = ctx->bitlen;\n\tctx->data[62] = ctx->bitlen >> 8;\n\tctx->data[61] = ctx->bitlen >> 16;\n\tctx->data[60] = ctx->bitlen >> 24;\n\tctx->data[59] = ctx->bitlen >> 32;\n\tctx->data[58] = ctx->bitlen >> 40;\n\tctx->data[57] = ctx->bitlen >> 48;\n\tctx->data[56] = ctx->bitlen >> 56;\n\tvgpu_unlock_sha256_transform(ctx, ctx->data);\n\n\t/*\n\t * Since this implementation uses little endian byte ordering and SHA\n\t * uses big endian, reverse all the bytes when copying the final state\n\t * to the output hash.\n\t */\n\tfor (i = 0; i < 4; ++i) {\n\t\thash[i]      = (ctx->state[0] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 4]  = (ctx->state[1] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 8]  = (ctx->state[2] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 12] = (ctx->state[3] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 16] = (ctx->state[4] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 20] = (ctx->state[5] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 24] = (ctx->state[6] >> (24 - i * 8)) & 0x000000ff;\n\t\thash[i + 28] = (ctx->state[7] >> (24 - i * 8)) & 0x000000ff;\n\t}\n}\n\n#undef ROTLEFT\n#undef ROTRIGHT\n\n#undef CH\n#undef MAJ\n#undef EP0\n#undef EP1\n#undef SIG0\n#undef SIG1\n\n/*------------------------------------------------------------------------------\n * End of SHA256 implementation.\n *------------------------------------------------------------------------------\n */\n\n\n/*------------------------------------------------------------------------------\n * Implementation of HMAC-SHA256.\n *------------------------------------------------------------------------------\n */\n\nstatic void vgpu_unlock_hmac_sha256(void* dst,\n                                    const void *msg,\n                                    size_t msg_size,\n                                    const void *key,\n                                    size_t key_size)\n{\n\tvgpu_unlock_sha256_ctx ctx;\n\tuint8_t o_key[96];\n\tuint8_t i_key_pad[64];\n\tuint8_t i;\n\n\tfor (i = 0; i < 64; i++)\n\t{\n\t\tif (i < key_size)\n\t\t{\n\t\t\to_key[i] = ((uint8_t*)key)[i] ^ 0x5c;\n\t\t\ti_key_pad[i] = ((uint8_t*)key)[i] ^ 0x36;\n\t\t}\n\t\telse\n\t\t{\n\t\t\to_key[i] = 0x5c;\n\t\t\ti_key_pad[i] = 0x36;\n\t\t}\n\t}\n\n\tvgpu_unlock_sha256_init(&ctx);\n\tvgpu_unlock_sha256_update(&ctx, i_key_pad, sizeof(i_key_pad));\n\tvgpu_unlock_sha256_update(&ctx, msg, msg_size);\n\tvgpu_unlock_sha256_final(&ctx, &o_key[64]);\n\n\tvgpu_unlock_sha256_init(&ctx);\n\tvgpu_unlock_sha256_update(&ctx, o_key, sizeof(o_key));\n\tvgpu_unlock_sha256_final(&ctx, dst);\n}\n\n/*------------------------------------------------------------------------------\n * End of HMAC-SHA256 implementation.\n *------------------------------------------------------------------------------\n */\n\n/*------------------------------------------------------------------------------\n * Implementation of vgpu_unlock hooks.\n *------------------------------------------------------------------------------\n */\n\n/* Debug logs can be enabled here. To enable it, change 0 to 1. */\n#if 0\n\t#define LOG(...) printk(__VA_ARGS__)\n#else\n\t#define LOG(...)\n#endif\n\ntypedef struct {\n\tuint8_t num_blocks; /* Number of 16 byte blocks up to 'sign'. */\n\tuint8_t name1_len; /* Length of first name (unused?) */\n\tuint8_t name2_len; /* Length of second name (used by VM) */\n\tuint16_t dev_id;\n\tuint16_t vend_id; /* Check skipped if zero. */\n\tuint16_t subsys_id;\n\tuint16_t subsys_vend_id; /* Check skipped if zero. */\n\tchar name1_2[38]; /* First and second name, no separation. */\n\tuint8_t sign[0x20];\n}\n__attribute__((packed))\nvgpu_unlock_vgpu_t;\n\n/* Helper macro to initialize the structure above. */\n#define VGPU(dev_id, subsys_id, name) \\\n\t{ (10 + 2 * strlen(name) + 15) / 16, /* num_blocks */     \\\n\t  strlen(name),                      /* name1_len */      \\\n\t  strlen(name),                      /* name2_len */      \\\n\t  (dev_id),                          /* dev_id */         \\\n\t  0,                                 /* vend_id */        \\\n\t  (subsys_id),                       /* subsys_id */      \\\n\t  0,                                 /* subsys_vend_id */ \\\n\t  { name name } }                    /* name1_2 */\n\nstatic vgpu_unlock_vgpu_t vgpu_unlock_vgpu[] =\n{\n\t/* Tesla M10 (Maxwell) */\n\tVGPU(0x13bd, 0x11cc, \"GRID M10-0B\"),\n\tVGPU(0x13bd, 0x11cd, \"GRID M10-1B\"),\n\tVGPU(0x13bd, 0x1339, \"GRID M10-1B4\"),\n\tVGPU(0x13bd, 0x1286, \"GRID M10-2B\"),\n\tVGPU(0x13bd, 0x12ee, \"GRID M10-2B4\"),\n\tVGPU(0x13bd, 0x11ce, \"GRID M10-0Q\"),\n\tVGPU(0x13bd, 0x11cf, \"GRID M10-1Q\"),\n\tVGPU(0x13bd, 0x11d0, \"GRID M10-2Q\"),\n\tVGPU(0x13bd, 0x11d1, \"GRID M10-4Q\"),\n\tVGPU(0x13bd, 0x11d2, \"GRID M10-8Q\"),\n\tVGPU(0x13bd, 0x11d3, \"GRID M10-1A\"),\n\tVGPU(0x13bd, 0x11d4, \"GRID M10-2A\"),\n\tVGPU(0x13bd, 0x11d5, \"GRID M10-4A\"),\n\tVGPU(0x13bd, 0x11d6, \"GRID M10-8A\"),\n\n\t/* Tesla M60 (Maxwell 2.0) */\n\tVGPU(0x13f2, 0x114c, \"GRID M60-0Q\"),\n\tVGPU(0x13f2, 0x114d, \"GRID M60-1Q\"),\n\tVGPU(0x13f2, 0x114e, \"GRID M60-2Q\"),\n\tVGPU(0x13f2, 0x114f, \"GRID M60-4Q\"),\n\tVGPU(0x13f2, 0x1150, \"GRID M60-8Q\"),\n\tVGPU(0x13f2, 0x1176, \"GRID M60-0B\"),\n\tVGPU(0x13f2, 0x1177, \"GRID M60-1B\"),\n\tVGPU(0x13f2, 0x117D, \"GRID M60-2B\"),\n\tVGPU(0x13f2, 0x1337, \"GRID M60-1B4\"),\n\tVGPU(0x13f2, 0x12ec, \"GRID M60-2B4\"),\n\tVGPU(0x13f2, 0x11ae, \"GRID M60-1A\"),\n\tVGPU(0x13f2, 0x11aF, \"GRID M60-2A\"),\n\tVGPU(0x13f2, 0x11b0, \"GRID M60-4A\"),\n\tVGPU(0x13f2, 0x11b1, \"GRID M60-8A\"),\n\n\t/* Tesla P4 (Pascal) */\n\tVGPU(0x1bb3, 0x1203, \"GRID P4-1B\"),\n\tVGPU(0x1bb3, 0x1204, \"GRID P4-1Q\"),\n\tVGPU(0x1bb3, 0x1205, \"GRID P4-2Q\"),\n\tVGPU(0x1bb3, 0x1206, \"GRID P4-4Q\"),\n\tVGPU(0x1bb3, 0x1207, \"GRID P4-8Q\"),\n\tVGPU(0x1bb3, 0x1208, \"GRID P4-1A\"),\n\tVGPU(0x1bb3, 0x1209, \"GRID P4-2A\"),\n\tVGPU(0x1bb3, 0x120a, \"GRID P4-4A\"),\n\tVGPU(0x1bb3, 0x120b, \"GRID P4-8A\"),\n\tVGPU(0x1bb3, 0x1288, \"GRID P4-2B\"),\n\tVGPU(0x1bb3, 0x12f1, \"GRID P4-2B4\"),\n\tVGPU(0x1bb3, 0x133c, \"GRID P4-1B4\"),\n\tVGPU(0x1bb3, 0x1380, \"GRID P4-8C\"),\n\tVGPU(0x1bb3, 0x1385, \"GRID P4-4C\"),\n\n\t/* Tesla P40 (Pascal) */\n\tVGPU(0x1b38, 0x11e7, \"GRID P40-1B\"),\n\tVGPU(0x1b38, 0x11e8, \"GRID P40-1Q\"),\n\tVGPU(0x1b38, 0x11e9, \"GRID P40-2Q\"),\n\tVGPU(0x1b38, 0x11ea, \"GRID P40-3Q\"),\n\tVGPU(0x1b38, 0x11eb, \"GRID P40-4Q\"),\n\tVGPU(0x1b38, 0x11ec, \"GRID P40-6Q\"),\n\tVGPU(0x1b38, 0x11ed, \"GRID P40-8Q\"),\n\tVGPU(0x1b38, 0x11ee, \"GRID P40-12Q\"),\n\tVGPU(0x1b38, 0x11ef, \"GRID P40-24Q\"),\n\tVGPU(0x1b38, 0x11f0, \"GRID P40-1A\"),\n\tVGPU(0x1b38, 0x11f1, \"GRID P40-2A\"),\n\tVGPU(0x1b38, 0x11f2, \"GRID P40-3A\"),\n\tVGPU(0x1b38, 0x11f3, \"GRID P40-4A\"),\n\tVGPU(0x1b38, 0x11f4, \"GRID P40-6A\"),\n\tVGPU(0x1b38, 0x11f5, \"GRID P40-8A\"),\n\tVGPU(0x1b38, 0x11f6, \"GRID P40-12A\"),\n\tVGPU(0x1b38, 0x11f7, \"GRID P40-24A\"),\n\tVGPU(0x1b38, 0x1287, \"GRID P40-2B\"),\n\tVGPU(0x1b38, 0x12ef, \"GRID P40-2B4\"),\n\tVGPU(0x1b38, 0x133a, \"GRID P40-1B4\"),\n\tVGPU(0x1b38, 0x137e, \"GRID P40-24C\"),\n\tVGPU(0x1b38, 0x1381, \"GRID P40-4C\"),\n\tVGPU(0x1b38, 0x1382, \"GRID P40-6C\"),\n\tVGPU(0x1b38, 0x1383, \"GRID P40-8C\"),\n\tVGPU(0x1b38, 0x1384, \"GRID P40-12C\"),\n\t\n\t/* Tesla V100 32GB PCIE (Volta) */\n\tVGPU(0x1db6, 0x12bd, \"GRID V100D-1B\"),\n\tVGPU(0x1db6, 0x12be, \"GRID V100D-2B\"),\n\tVGPU(0x1db6, 0x12f7, \"GRID V100D-2B4\"),\n\tVGPU(0x1db6, 0x1342, \"GRID V100D-1B4\"),\n\tVGPU(0x1db6, 0x12bf, \"GRID V100D-1Q\"),\n\tVGPU(0x1db6, 0x12c0, \"GRID V100D-2Q\"),\n\tVGPU(0x1db6, 0x12c1, \"GRID V100D-4Q\"),\n\tVGPU(0x1db6, 0x12c2, \"GRID V100D-8Q\"),\n\tVGPU(0x1db6, 0x12c3, \"GRID V100D-16Q\"),\n\tVGPU(0x1db6, 0x12c4, \"GRID V100D-32Q\"),\n\tVGPU(0x1db6, 0x12c5, \"GRID V100D-1A\"),\n\tVGPU(0x1db6, 0x12c6, \"GRID V100D-2A\"),\n\tVGPU(0x1db6, 0x12c7, \"GRID V100D-4A\"),\n\tVGPU(0x1db6, 0x12c8, \"GRID V100D-8A\"),\n\tVGPU(0x1db6, 0x12c9, \"GRID V100D-16A\"),\n\tVGPU(0x1db6, 0x12ca, \"GRID V100D-32A\"),\n\tVGPU(0x1db6, 0x1395, \"GRID V100D-4C\"),\n\tVGPU(0x1db6, 0x1396, \"GRID V100D-8C\"),\n\tVGPU(0x1db6, 0x1397, \"GRID V100D-16C\"),\t\n\tVGPU(0x1db6, 0x1377, \"GRID V100D-32C\"),\t\n\n\t/* Tesla T4 (Turing) */\n\tVGPU(0x1eb8, 0x1309, \"GRID T4-1B\"),\n\tVGPU(0x1eb8, 0x130a, \"GRID T4-2B\"),\n\tVGPU(0x1eb8, 0x130b, \"GRID T4-2B4\"),\n\tVGPU(0x1eb8, 0x130c, \"GRID T4-1Q\"),\n\tVGPU(0x1eb8, 0x130d, \"GRID T4-2Q\"),\n\tVGPU(0x1eb8, 0x130e, \"GRID T4-4Q\"),\n\tVGPU(0x1eb8, 0x130f, \"GRID T4-8Q\"),\n\tVGPU(0x1eb8, 0x1310, \"GRID T4-16Q\"),\n\tVGPU(0x1eb8, 0x1311, \"GRID T4-1A\"),\n\tVGPU(0x1eb8, 0x1312, \"GRID T4-2A\"),\n\tVGPU(0x1eb8, 0x1313, \"GRID T4-4A\"),\n\tVGPU(0x1eb8, 0x1314, \"GRID T4-8A\"),\n\tVGPU(0x1eb8, 0x1315, \"GRID T4-16A\"),\n\tVGPU(0x1eb8, 0x1345, \"GRID T4-1B4\"),\n\tVGPU(0x1eb8, 0x1375, \"GRID T4-16C\"),\n\tVGPU(0x1eb8, 0x139a, \"GRID T4-4C\"),\n\tVGPU(0x1eb8, 0x139b, \"GRID T4-8C\"),\n\n\t/* Quadro RTX 6000 (Turing) */\n\tVGPU(0x1e30, 0x1325, \"GRID RTX6000-1Q\"),\n\tVGPU(0x1e30, 0x1326, \"GRID RTX6000-2Q\"),\n\tVGPU(0x1e30, 0x1327, \"GRID RTX6000-3Q\"),\n\tVGPU(0x1e30, 0x1328, \"GRID RTX6000-4Q\"),\n\tVGPU(0x1e30, 0x1329, \"GRID RTX6000-6Q\"),\n\tVGPU(0x1e30, 0x132a, \"GRID RTX6000-8Q\"),\n\tVGPU(0x1e30, 0x132b, \"GRID RTX6000-12Q\"),\n\tVGPU(0x1e30, 0x132c, \"GRID RTX6000-24Q\"),\n\tVGPU(0x1e30, 0x13bf, \"GRID RTX6000-4C\"),\n\tVGPU(0x1e30, 0x13c0, \"GRID RTX6000-6C\"),\n\tVGPU(0x1e30, 0x13c1, \"GRID RTX6000-8C\"),\n\tVGPU(0x1e30, 0x13c2, \"GRID RTX6000-12C\"),\n\tVGPU(0x1e30, 0x13c3, \"GRID RTX6000-24C\"),\n\tVGPU(0x1e30, 0x1437, \"GRID RTX6000-1B\"),\n\tVGPU(0x1e30, 0x1438, \"GRID RTX6000-2B\"),\n\tVGPU(0x1e30, 0x1439, \"GRID RTX6000-1A\"),\n\tVGPU(0x1e30, 0x143a, \"GRID RTX6000-2A\"),\n\tVGPU(0x1e30, 0x143b, \"GRID RTX6000-3A\"),\n\tVGPU(0x1e30, 0x143c, \"GRID RTX6000-4A\"),\n\tVGPU(0x1e30, 0x143d, \"GRID RTX6000-6A\"),\n\tVGPU(0x1e30, 0x143e, \"GRID RTX6000-8A\"),\n\tVGPU(0x1e30, 0x143f, \"GRID RTX6000-12A\"),\n\tVGPU(0x1e30, 0x1440, \"GRID RTX6000-24A\"),\n\n\t/* RTX A6000 (Ampere) */\n\tVGPU(0x2230, 0x14fa, \"NVIDIA RTXA6000-1B\"),\n\tVGPU(0x2230, 0x14fb, \"NVIDIA RTXA6000-2B\"),\n\tVGPU(0x2230, 0x14fc, \"NVIDIA RTXA6000-1Q\"),\n\tVGPU(0x2230, 0x14fd, \"NVIDIA RTXA6000-2Q\"),\n\tVGPU(0x2230, 0x14fe, \"NVIDIA RTXA6000-3Q\"),\n\tVGPU(0x2230, 0x14ff, \"NVIDIA RTXA6000-4Q\"),\n\tVGPU(0x2230, 0x1500, \"NVIDIA RTXA6000-6Q\"),\n\tVGPU(0x2230, 0x1501, \"NVIDIA RTXA6000-8Q\"),\n\tVGPU(0x2230, 0x1502, \"NVIDIA RTXA6000-12Q\"),\n\tVGPU(0x2230, 0x1503, \"NVIDIA RTXA6000-16Q\"),\n\tVGPU(0x2230, 0x1504, \"NVIDIA RTXA6000-24Q\"),\n\tVGPU(0x2230, 0x1505, \"NVIDIA RTXA6000-48Q\"),\n\tVGPU(0x2230, 0x1506, \"NVIDIA RTXA6000-1A\"),\n\tVGPU(0x2230, 0x1507, \"NVIDIA RTXA6000-2A\"),\n\tVGPU(0x2230, 0x1508, \"NVIDIA RTXA6000-3A\"),\n\tVGPU(0x2230, 0x1509, \"NVIDIA RTXA6000-4A\"),\n\tVGPU(0x2230, 0x150a, \"NVIDIA RTXA6000-6A\"),\n\tVGPU(0x2230, 0x150b, \"NVIDIA RTXA6000-8A\"),\n\tVGPU(0x2230, 0x150c, \"NVIDIA RTXA6000-12A\"),\n\tVGPU(0x2230, 0x150d, \"NVIDIA RTXA6000-16A\"),\n\tVGPU(0x2230, 0x150e, \"NVIDIA RTXA6000-24A\"),\n\tVGPU(0x2230, 0x150f, \"NVIDIA RTXA6000-48A\"),\n\tVGPU(0x2230, 0x1514, \"NVIDIA RTXA6000-4C\"),\n\tVGPU(0x2230, 0x1515, \"NVIDIA RTXA6000-6C\"),\n\tVGPU(0x2230, 0x1516, \"NVIDIA RTXA6000-8C\"),\n\tVGPU(0x2230, 0x1517, \"NVIDIA RTXA6000-12C\"),\n\tVGPU(0x2230, 0x1518, \"NVIDIA RTXA6000-16C\"),\n\tVGPU(0x2230, 0x1519, \"NVIDIA RTXA6000-24C\"),\n\tVGPU(0x2230, 0x151a, \"NVIDIA RTXA6000-48C\"),\n\n\t{ 0 } /* Sentinel */\n};\n\n#undef VGPU\n\nstatic const uint8_t vgpu_unlock_magic_start[0x10] = {\n\t0xf3, 0xf5, 0x9e, 0x3d, 0x13, 0x91, 0x75, 0x18,\n\t0x6a, 0x7b, 0x55, 0xed, 0xce, 0x5d, 0x84, 0x67\n};\n\nstatic const uint8_t vgpu_unlock_magic_sacrifice[0x10] = {\n\t0x46, 0x4f, 0x39, 0x49, 0x74, 0x91, 0xd7, 0x0f,\n\t0xbc, 0x65, 0xc2, 0x70, 0xdd, 0xdd, 0x11, 0x54\n};\n\nstatic bool vgpu_unlock_patch_applied = FALSE;\n\nstatic bool vgpu_unlock_bar3_mapped = FALSE;\nstatic uint64_t vgpu_unlock_bar3_beg;\nstatic uint64_t vgpu_unlock_bar3_end;\n\nstatic uint8_t vgpu_unlock_magic[0x10];\nstatic bool vgpu_unlock_magic_found = FALSE;\n\nstatic uint8_t vgpu_unlock_key[0x10];\nstatic bool vgpu_unlock_key_found = FALSE;\n\n/* These need to be added to the linker script. */\nextern uint8_t vgpu_unlock_nv_kern_rodata_beg;\nextern uint8_t vgpu_unlock_nv_kern_rodata_end;\n\nstatic uint16_t vgpu_unlock_pci_devid_to_vgpu_capable(uint16_t pci_devid)\n{\n\tswitch (pci_devid)\n\t{\n\t/* Maxwell */\n\tcase 0x1340 ... 0x13bd:\n\tcase 0x174d ... 0x179c:\n\t\treturn 0x13bd; /* Tesla M10 */\n\n\t/* Maxwell 2.0 */\n\tcase 0x13c0 ... 0x1436:\n\tcase 0x1617 ... 0x1667: /* GM204 */\n\tcase 0x17c2 ... 0x17fd: /* GM200 */\n\t\treturn 0x13f2; /* Tesla M60 */\n\t\t\n\t/* Pascal */\n\tcase 0x15f0 ... 0x15f1: /* GP100GL */\n\tcase 0x1b00 ... 0x1d56:\n\tcase 0x1725 ... 0x172f: /* GP100 */\n\t\treturn 0x1b38; /* Tesla P40 */\n\n\t/* Volta GV100 */\n\tcase 0x1d81: /* Titan V 16GB */\n\tcase 0x1dba: /* Quadro GV100 32GB */\n\t\treturn 0x1db6; /* Tesla V100 32GB PCIE */\n\n\t/* Turing */\n\tcase 0x1e02 ... 0x1ff9:\n\tcase 0x2182 ... 0x21d1: /* TU116 */\n\t\treturn 0x1e30; /* Quadro RTX 6000 */\n\t\n\t/* Ampere */\n\tcase 0x2200 ... 0x2600: \n\t\treturn 0x2230; /* RTX A6000 */\n\t}\n\n\treturn pci_devid;\n}\n\n/* Our own memcmp that will bypass buffer overflow checks. */\nstatic int vgpu_unlock_memcmp(const void *a, const void *b, size_t size)\n{\n\tuint8_t *pa = (uint8_t*)a;\n\tuint8_t *pb = (uint8_t*)b;\n\n\twhile (size--)\n\t{\n\t\tif (*pa != *pb)\n\t\t{\n\t\t\treturn *pa - *pb;\n\t\t}\n\n\t\tpa++;\n\t\tpb++;\n\t}\n\n\treturn 0;\n}\n\n/* Search for a certain pattern in the .rodata section of nv-kern.o_binary. */\nstatic void *vgpu_unlock_find_in_rodata(const void *val, size_t size)\n{\n\tuint8_t *i;\n\n\tfor (i = &vgpu_unlock_nv_kern_rodata_beg;\n\t     i < &vgpu_unlock_nv_kern_rodata_end - size;\n\t     i++)\n\t{\n\t\tif (vgpu_unlock_memcmp(val, i, size) == 0)\n\t\t{\n\t\t\treturn i;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\n/* Check if a value is within a range. */\nstatic bool vgpu_unlock_in_range(uint64_t val, uint64_t beg, uint64_t end)\n{\n\treturn (val >= beg) && (val <= end);\n}\n\n/* Check if range a is completely contained within range b. */\nstatic bool vgpu_unlock_range_contained_in(uint64_t a_beg,\n                                           uint64_t a_end,\n                                           uint64_t b_beg,\n                                           uint64_t b_end)\n{\n\treturn vgpu_unlock_in_range(a_beg, b_beg, b_end) &&\n\t       vgpu_unlock_in_range(a_end, b_beg, b_end);\n}\n\n/* Check if an address points into a specific BAR of an NVIDIA GPU. */\nstatic bool vgpu_unlock_in_bar(uint64_t addr, int bar)\n{\n\tstruct pci_dev *dev = NULL;\n\n\twhile (1)\n\t{\n\t\tdev = pci_get_device(0x10de, PCI_ANY_ID, dev);\n\n\t\tif (dev)\n\t\t{\n\t\t\tif (vgpu_unlock_in_range(addr,\n\t\t\t                         pci_resource_start(dev, bar),\n\t\t\t                         pci_resource_end(dev, bar)))\n\t\t\t{\n\t\t\t\treturn TRUE;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn FALSE;\n\t\t}\n\t}\n}\n\n/* Check if a potential magic value is valid. */\nstatic bool vgpu_unlock_magic_valid(const uint8_t *magic)\n{\n\tvoid **gpu_list_item;\n\n\tstatic void **gpu_list_start = NULL;\n\n\tif (!gpu_list_start)\n\t{\n\t\tvoid *magic_start = vgpu_unlock_find_in_rodata(vgpu_unlock_magic_start,\n\t\t                                               sizeof(vgpu_unlock_magic_start));\n\n\t\tif (!magic_start)\n\t\t{\n\t\t\tLOG(KERN_ERR \"Failed to find start of gpu list in .rodata\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tgpu_list_start = (void**)vgpu_unlock_find_in_rodata(&magic_start,\n\t\t                                                    sizeof(magic_start));\n\n\t\tif (!gpu_list_start)\n\t\t{\n\t\t\tLOG(KERN_ERR \"Failed to find pointer to start of gpu list in .rodata\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tfor (gpu_list_item = gpu_list_start;\n\t     vgpu_unlock_in_range((uint64_t)*gpu_list_item,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_beg,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_end);\n\t     gpu_list_item += 3)\n\t{\n\t\tif (memcmp(magic, *gpu_list_item, 0x10) == 0)\n\t\t{\n\t\t\treturn TRUE;\n\t\t}\n\t}\n\n\treturn FALSE;\n}\n\nstatic void vgpu_unlock_apply_patch(void)\n{\n\tuint8_t i;\n\tvoid *magic;\n\tvoid **magic_ptr;\n\tvoid **blocks_ptr;\n\tvoid **sign_ptr;\n\tuint8_t sign[0x20];\n\tuint8_t num_blocks;\n\tvoid *sac_magic;\n\tvoid **sac_magic_ptr;\n\tvoid **sac_blocks_ptr;\n\tvoid **sac_sign_ptr;\n\tvgpu_unlock_aes128_ctx aes_ctx;\n\tvgpu_unlock_vgpu_t* vgpu;\n\tuint8_t first_block[0x10];\n\tuint16_t device_id;\n\t\n\tmagic = vgpu_unlock_find_in_rodata(vgpu_unlock_magic,\n\t                                   sizeof(vgpu_unlock_magic));\n\tif (!magic)\n\t{\n\t\tLOG(KERN_ERR \"Failed to find magic in .rodata.\\n\");\n\t\tgoto failed;\n\t}\n\n\tLOG(KERN_WARNING \"Magic is at: %px\\n\", magic);\n\n\tmagic_ptr = (void**)vgpu_unlock_find_in_rodata(&magic,\n\t                                               sizeof(magic));\n\n\tif (!magic_ptr)\n\t{\n\t\tLOG(KERN_ERR \"Failed to find pointer to magic in .rodata.\\n\");\n\t\tgoto failed;\n\t}\n\n\tblocks_ptr = magic_ptr + 1;\n\tsign_ptr = magic_ptr + 2;\n\n\tLOG(KERN_WARNING \"Pointers found, magic: %px blocks: %px sign: %px\\n\",\n\t    magic_ptr, blocks_ptr, sign_ptr);\n\n\tif (!vgpu_unlock_in_range((uint64_t)*blocks_ptr,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_beg,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_end) ||\n\t    !vgpu_unlock_in_range((uint64_t)*sign_ptr,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_beg,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_end))\n\t{\n\t\tLOG(KERN_ERR \"Invalid sign or blocks pointer.\\n\");\n\t\tgoto failed;\n\t}\n\n\tnum_blocks = *(uint8_t*)*blocks_ptr;\n\n\tvgpu_unlock_hmac_sha256(sign,\n\t                        *blocks_ptr,\n\t                        1 + num_blocks * 0x10,\n\t                        vgpu_unlock_key,\n\t                        sizeof(vgpu_unlock_key));\n\n\tLOG(KERN_WARNING \"Generate signature is: %32ph\\n\", sign);\n\n\tif (memcmp(sign, *sign_ptr, sizeof(sign)) != 0)\n\t{\n\t\tLOG(KERN_ERR \"Signatures does not match.\\n\");\n\t\tgoto failed;\n\t}\n\n\tsac_magic = vgpu_unlock_find_in_rodata(vgpu_unlock_magic_sacrifice,\n\t                                       sizeof(vgpu_unlock_magic_sacrifice));\n\n\tif (!sac_magic)\n\t{\n\t\tLOG(KERN_ERR \"Failed to find sacrificial magic.\\n\");\n\t\tgoto failed;\n\t}\n\n\tLOG(KERN_WARNING \"Sacrificial magic is at: %px\\n\", sac_magic);\n\n\tsac_magic_ptr = (void**) vgpu_unlock_find_in_rodata(&sac_magic,\n\t                                                    sizeof(sac_magic));\n\n\tif (!sac_magic_ptr)\n\t{\n\t\tLOG(KERN_ERR \"Failed to find pointer to sacrificial magic.\\n\");\n\t\tgoto failed;\n\t}\n\n\tsac_blocks_ptr = sac_magic_ptr + 1;\n\tsac_sign_ptr = sac_magic_ptr + 2;\n\n\tLOG(KERN_WARNING \"Pointers found, sac_magic: %px sac_blocks: %px sac_sign: %px\\n\",\n\t    sac_magic_ptr, sac_blocks_ptr, sac_sign_ptr);\n\n\tif (!vgpu_unlock_in_range((uint64_t)*sac_blocks_ptr,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_beg,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_end) ||\n\t    !vgpu_unlock_in_range((uint64_t)*sac_sign_ptr,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_beg,\n\t                          (uint64_t)&vgpu_unlock_nv_kern_rodata_end))\n\t{\n\t\tLOG(KERN_ERR \"Invalid sacrificial sign or blocks pointer.\\n\");\n\t\tgoto failed;\n\t}\n\n\t/* Decrypt the first block so we can access the PCI device ID. */\n\tmemcpy(first_block, (uint8_t*)*blocks_ptr + 1, sizeof(first_block));\n\tvgpu_unlock_aes128_init(&aes_ctx, vgpu_unlock_key);\n\tvgpu_unlock_aes128_decrypt(&aes_ctx, first_block);\n\tLOG(KERN_WARNING \"Decrypted first block is: %16ph.\\n\",\n\t    first_block);\n\n\tdevice_id = *((uint16_t*)first_block + 1);\n\tdevice_id = vgpu_unlock_pci_devid_to_vgpu_capable(device_id);\n\n\t/* Loop over all vGPUs and add the ones that match our device ID. */\n\tvgpu = vgpu_unlock_vgpu;\n\n\twhile (vgpu->num_blocks != 0)\n\t{\n\t\tif (vgpu->dev_id != device_id)\n\t\t{\n\t\t\tvgpu++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnum_blocks = vgpu->num_blocks;\n\n\t\t*sac_magic_ptr = vgpu_unlock_magic;\n\t\t*sac_blocks_ptr = vgpu;\n\t\t*sac_sign_ptr = &vgpu->sign;\n\n\t\tvgpu_unlock_aes128_init(&aes_ctx, vgpu_unlock_key);\n\n\t\tfor (i = 0; i < num_blocks; i++)\n\t\t{\n\t\t\tvgpu_unlock_aes128_encrypt(&aes_ctx,\n\t\t\t                           (uint8_t*)vgpu + 1 + i * 0x10);\n\t\t}\n\n\t\tvgpu_unlock_hmac_sha256(&vgpu->sign,\n\t\t                        vgpu,\n\t\t                        1 + num_blocks * 0x10,\n\t\t                        vgpu_unlock_key,\n\t\t                        sizeof(vgpu_unlock_key));\n\n\t\tsac_magic_ptr += 3;\n\t\tsac_blocks_ptr = sac_magic_ptr + 1;\n\t\tsac_sign_ptr = sac_magic_ptr + 2;\n\t\tvgpu++;\n\t}\n\n\tvgpu_unlock_patch_applied = TRUE;\n\n\tLOG(KERN_WARNING \"vGPU unlock patch applied.\\n\");\n\n\treturn;\n\nfailed:\n\tvgpu_unlock_magic_found = FALSE;\n\tvgpu_unlock_key_found = FALSE;\n}\n\nstatic void *vgpu_unlock_memcpy_hook(void *dst, const void *src, size_t count)\n{\n\tbool src_in_bar3 = vgpu_unlock_bar3_mapped &&\n\t                   vgpu_unlock_in_range((uint64_t)src,\n\t                                        vgpu_unlock_bar3_beg,\n\t                                        vgpu_unlock_bar3_end);\n\n\tvoid *result = memcpy(dst, src, count);\n\n\tif (src_in_bar3 &&\n\t    count == sizeof(vgpu_unlock_magic) &&\n\t    !vgpu_unlock_magic_found &&\n\t    vgpu_unlock_magic_valid(dst))\n\t{\n\t\tmemcpy(vgpu_unlock_magic, dst, count);\n\t\tvgpu_unlock_magic_found = TRUE;\n\n\t\tLOG(KERN_WARNING \"Magic found: %16ph\\n\",\n\t\t    vgpu_unlock_magic);\n\n\t}\n\telse if (src_in_bar3 &&\n\t         count == sizeof(vgpu_unlock_key) &&\n\t         vgpu_unlock_magic_found &&\n\t         !vgpu_unlock_key_found)\n\t{\n\t\tmemcpy(vgpu_unlock_key, dst, count);\n\t\tvgpu_unlock_key_found = TRUE;\n\n\t\tLOG(KERN_WARNING \"Key found: %16ph\\n\",\n\t\t    vgpu_unlock_key);\n\t}\n\n\tif (!vgpu_unlock_patch_applied &&\n\t    vgpu_unlock_magic_found &&\n\t    vgpu_unlock_key_found)\n\t{\n\t\tvgpu_unlock_apply_patch();\n\t}\n\n\treturn result;\n}\n\n/* Check if the new IO mapping contains the magic or key. */\nstatic void vgpu_unlock_check_map(uint64_t phys_addr,\n                                  size_t size,\n                                  void *virt_addr)\n{\n\tLOG(KERN_WARNING \"Remap called.\\n\");\n\n\tif (virt_addr &&\n\t    !vgpu_unlock_bar3_mapped &&\n\t    vgpu_unlock_in_bar(phys_addr, 3))\n\t{\n\t\tvgpu_unlock_bar3_beg = (uint64_t)virt_addr;\n\t\tvgpu_unlock_bar3_end = (uint64_t)virt_addr + size;\n\t\tvgpu_unlock_bar3_mapped = TRUE;\n\t\tLOG(KERN_WARNING \"BAR3 mapped at: 0x%llX\\n\",\n\t\t    vgpu_unlock_bar3_beg);\n\t}\n}\n\nstatic void *vgpu_unlock_nv_ioremap_hook(uint64_t phys,\n                                         uint64_t size)\n{\n\tvoid *virt_addr = nv_ioremap(phys, size);\n\tvgpu_unlock_check_map(phys, size, virt_addr);\n\treturn virt_addr;\n}\n\nstatic void *vgpu_unlock_nv_ioremap_nocache_hook(uint64_t phys,\n                                                 uint64_t size)\n{\n\tvoid *virt_addr = nv_ioremap_nocache(phys, size);\n\tvgpu_unlock_check_map(phys, size, virt_addr);\n\treturn virt_addr;\n}\n\nstatic void *vgpu_unlock_nv_ioremap_cache_hook(uint64_t phys,\n                                               uint64_t size)\n{\n\tvoid *virt_addr = nv_ioremap_cache(phys, size);\n\tvgpu_unlock_check_map(phys, size, virt_addr);\n\treturn virt_addr;\n}\n\nstatic void *vgpu_unlock_nv_ioremap_wc_hook(uint64_t phys,\n                                               uint64_t size)\n{\n\tvoid *virt_addr = nv_ioremap_wc(phys, size);\n\tvgpu_unlock_check_map(phys, size, virt_addr);\n\treturn virt_addr;\n}\n\n#undef LOG\n\n/* Redirect future callers to our hooks. */\n#define memcpy             vgpu_unlock_memcpy_hook\n#define nv_ioremap         vgpu_unlock_nv_ioremap_hook\n#define nv_ioremap_nocache vgpu_unlock_nv_ioremap_nocache_hook\n#define nv_ioremap_cache   vgpu_unlock_nv_ioremap_cache_hook\n#define nv_ioremap_wc      vgpu_unlock_nv_ioremap_wc_hook\n"
        }
      ]
    }
  ]
}