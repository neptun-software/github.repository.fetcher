{
  "metadata": {
    "timestamp": 1736710118251,
    "page": 751,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "guanshuicheng/invoice",
      "stars": 1849,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0419921875,
          "content": "MIT License\n\nCopyright (c) 2018 chineseocr\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.9384765625,
          "content": "# 说明\n- 该项目基于chineseocr https://github.com/chineseocr/chineseocr\n- 商业版本（多模态）合作请联系微信：w1003617636\n- 支持其他的卡证及票据类的高精度识别\n- 支持行业内的数据相关合作，欢迎联系\n\n# 增值税发票识别 \n  增值税发票OCR识别，使用flask微服务架构，识别type：增值税电子普通发票，增值税普通发票，增值税专用发票；识别字段为：发票代码、发票号码、开票日期、校验码、税后金额等。\n  \n  识别type：增值税电子普通发票，增值税普通发票，增值税专用发票；识别字段为：发票代码、发票号码、开票日期、校验码、税后金额等\n## 环境\n   1. python3.5/3.6\n   2. 依赖项安装：pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple \n   3. 有GPU环境的可修改安装requirements.txt对应版本的tensorflow-gpu，config.py文件中控制GPU的开关\n## 模型架构\n    YOLOv3 + CRNN + CTC\n   \n## 模型\n   1. 模型下载地址：链接：https://pan.baidu.com/s/1bjtd3ueiUj3rt16p2_YQ2w\n   2. 将下载完毕的模型文件夹models放置于项目根目录下\n## 服务启动\n   1. python3 app.py\n   2. 端口可自行修改\n   3. 服务调用地址：http://*.*.*.*: [端口号]/invoice-ocr，例：http://127.0.0.1:11111/invoice-ocr\n## 测试demo\n   1. 测试工具：postman，可自行下载安装\n   2. 增值税电子普票测试结果\n   \n![Image text](https://github.com/guanshuicheng/invoice/blob/master/test-invoice/%E7%94%B5%E5%AD%90%E5%8F%91%E7%A5%A8-test.png)\n   \n   3. 增值税专用普票测试结果\n   \n![Image text](https://github.com/guanshuicheng/invoice/blob/master/test-invoice/%E5%A2%9E%E5%80%BC%E7%A8%8E%E4%B8%93%E7%94%A8%E5%8F%91%E7%A5%A8-test.png)\n\n   4. 增值税普通普票测试结果\n\n![Image text](https://github.com/guanshuicheng/invoice/blob/master/test-invoice/%E5%A2%9E%E5%80%BC%E7%A8%8E%E6%99%AE%E9%80%9A%E5%8F%91%E7%A5%A8-test.jpg)\n   \n"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 4.11328125,
          "content": "from flask import Flask, jsonify, request, redirect, render_template\nfrom flask_cors import CORS\nimport re\nimport time\nfrom glob import glob\nfrom PIL import Image\nimport numpy as np\nimport os\nimport cv2\nimport uuid\nimport json\nfrom PIL import Image\nfrom datetime import datetime\nfrom model_post_type import ocr as OCR\nfrom model_postE_invoice import ocr as ocr_E\nfrom model_postM_invoice import ocr as ocr_M\nfrom apphelper.image import union_rbox\nfrom application.invoice_e import invoice_e\nfrom application.invoice_m import invoice_m\nimport pytz\nport = 11111\nallowed_extension = ['jpg','png','JPG']\n\n# Flask\napp = Flask(__name__)\nCORS(app, resources=r'/*')\n\n# 构建接口返回结果\ndef build_api_result(code, message, data,file_name,ocr_identify_time):\n    result = {\n        \"code\": code,\n        \"message\": message,\n        \"data\": data,\n        \"FileName\": file_name,\n        \"ocrIdentifyTime\": ocr_identify_time\n    }\n    return jsonify(result)\n\n# 检查文件扩展名\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in allowed_extension\n\n\n# 增值税发票OCR识别接口\n@app.route('/invoice-ocr', methods=['POST'])\ndef invoice_ocr():\n    # 校验请求参数\n    if 'file' not in request.files:\n        return build_api_result(101, \"请求参数错误\", {},{},{})\n\n    # 获取请求参数\n    file = request.files['file']\n    invoice_file_name = file.filename\n    \n    # 检查文件扩展名\n    if not allowed_file(invoice_file_name):\n        return build_api_result(102, \"失败，文件格式问题\", {},{},{})\n   \n    upload_path = \"test\"\n    whole_path = os.path.join(upload_path,invoice_file_name)\n    file.save(whole_path)\n    \n    #去章处理方法\n    def remove_stamp(path,invoice_file_name):\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        B_channel,G_channel,R_channel=cv2.split(img)     # 注意cv2.split()返回通道顺序\n        _,RedThresh = cv2.threshold(R_channel,170,355,cv2.THRESH_BINARY)\n        cv2.imwrite('./test/RedThresh_{}.jpg'.format(invoice_file_name),RedThresh)\n    \n    def Recognition_invoice(path):\n        '''\n        识别发票类别\n        :param none:\n        :return: 发票类别\n        '''\n        remove_stamp(path,invoice_file_name)\n        img1 = './test/RedThresh_{}.jpg'.format(invoice_file_name)\n        img1 = cv2.imread(img1)\n        result_type = OCR(img1)\n        result_type = union_rbox(result_type, 0.2)\n        \n        print(result_type)\n        \n        if len(result_type) > 0:\n            N = len(result_type)\n            for i in range(N):\n                txt = result_type[i]['text'].replace(' ', '')\n                txt = txt.replace(' ', '')\n                type_1 = re.findall('电子普通',txt)\n                type_2 = re.findall('普通发票',txt)\n                type_3 = re.findall('专用发票',txt)\n                if type_1 == None:\n                    type_1 = []\n                if type_2 == None:\n                    type_2 = []\n                if type_3 == None:\n                    type_3 = []\n            print(type_1)\n            print(type_2)\n            print(type_3)\n            if len(type_1) > 0:\n                return 1\n            else:\n                return 2\n        elif len(result_type)==0:\n            return 2\n    \n    Recognition_invoice = Recognition_invoice(whole_path)\n    img = cv2.imread(whole_path)\n    h, w = img.shape[:2]\n    if Recognition_invoice == 1:\n        result = ocr_E(img)\n        res = invoice_e(result)\n        res = res.res\n    elif Recognition_invoice == 2:\n        result = ocr_M(img)\n        res = invoice_m(result)\n        res = res.res\n    else:\n        res = []\n    if len(res) > 0:\n        tz = pytz.timezone('Asia/Shanghai') #东八区\n        ocr_identify_time = datetime.fromtimestamp(int(time.time()),pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')\n        return build_api_result(100, \"识别成功\" , res, invoice_file_name,ocr_identify_time)\n    elif len(res) == 0:\n        return build_api_result(104, \"识别为空！\" ,{},{},{})\n        \nif __name__ == \"__main__\":\n    # Run\n    app.config['JSON_AS_ASCII'] = False\n    app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)\n"
        },
        {
          "name": "apphelper",
          "type": "tree",
          "content": null
        },
        {
          "name": "application",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 2.27734375,
          "content": "import os\n########################文字检测########################\n##文字检测引擎 \npwd = os.getcwd()\nopencvFlag = 'keras' ##keras,opencv,darknet，模型性能 keras>darknet>opencv\nIMGSIZE = (608,608)## yolo3 输入图像尺寸\n## keras 版本anchors\nkeras_anchors = '8,11, 8,16, 8,23, 8,33, 8,48, 8,97, 8,139, 8,198, 8,283'\nclass_names = ['none','text',]\nkerasTextModel_type = os.path.join(pwd,\"models\",\"text_type.h5\")##keras版本模型发票类型权重文件\nkerasTextEModel_invoice = os.path.join(pwd,\"models\",\"text_electronic.h5\")##keras版本模型电子普票权重文件\nkerasTextMModel_invoice = os.path.join(pwd,\"models\",\"text_machine.h5\")##keras版本模型机打发票权重文件\nkerasTextModel = os.path.join(pwd,\"models\",\"text_electronic.h5\")\n\n############## darknet yolo  ##############\ndarknetRoot = os.path.join(os.path.curdir,\"darknet\")## yolo 安装目录\nyoloCfg     = os.path.join(pwd,\"models\",\"text.cfg\")\nyoloWeights = os.path.join(pwd,\"models\",\"text.weights\")\nyoloData    = os.path.join(pwd,\"models\",\"text.data\")\n############## darknet yolo  ##############\n\n########################文字检测########################\n\n## GPU选择及启动GPU序号\n#GPU = True##OCR 是否启用GPU\nGPU = False\nGPUID=0##调用GPU序号\n\n## nms选择,支持cython,gpu,python\nnmsFlag='gpu'## cython/gpu/python ##容错性 优先启动GPU，其次是cpython 最后是python\nif not GPU:\n    nmsFlag='cython'\n\n\n##vgg文字方向检测模型\nDETECTANGLE=True##是否进行文字方向检测\nAngleModelPb = os.path.join(pwd,\"models\",\"Angle-model.pb\")\nAngleModelPbtxt = os.path.join(pwd,\"models\",\"Angle-model.pbtxt\")\n\n\n######################OCR模型######################\n##是否启用LSTM crnn模型\n##OCR模型是否调用LSTM层\nLSTMFLAG = True\n##模型选择 True:中英文模型 False:英文模型\nocrFlag = 'torch'##ocr模型 支持 keras  torch版本\nchinsesModel = True\nocrModelKeras = os.path.join(pwd,\"models\",\"ocr-dense-keras.h5\")##keras版本OCR，暂时支持dense\nif chinsesModel:\n    if LSTMFLAG:\n        ocrModel  = os.path.join(pwd,\"models\",\"ocr-lstm.pth\")\n    else:\n        ocrModel = os.path.join(pwd,\"models\",\"ocr-dense.pth\")\nelse:\n        ##纯英文模型\n        LSTMFLAG=True\n        ocrModel = os.path.join(pwd,\"models\",\"ocr-english.pth\")\n######################OCR模型######################\n"
        },
        {
          "name": "crnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknet",
          "type": "tree",
          "content": null
        },
        {
          "name": "model_postE_invoice.py",
          "type": "blob",
          "size": 5.9453125,
          "content": "# -*- coding: utf-8 -*-\nfrom config import opencvFlag, GPU, IMGSIZE, ocrFlag\n\nif not GPU:\n    import os\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''  ##不启用GPU\n\nif ocrFlag == 'torch':\n    from crnn.crnn_torch import crnnOcr as crnnOcr  ##torch版本ocr\nelif ocrFlag == 'keras':\n    from crnn.crnn_keras import crnnOcr as crnnOcr  ##keras版本OCR\n\nimport time\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom glob import glob\n\nfrom text.detector.detectors import TextDetector\nfrom apphelper.image import get_boxes, letterbox_image\n\nfrom text.opencv_dnn_detect import angle_detect  ##文字方向检测,支持dnn/tensorflow\nfrom apphelper.image import estimate_skew_angle, rotate_cut_img, xy_rotate_box, sort_box, box_rotate, solve\n\nif opencvFlag == 'opencv':\n    from text import opencv_dnn_detect as detect  ##opencv dnn model for darknet\nelif opencvFlag == 'darknet':\n    from text import darknet_detect as detect\nelse:\n    ## keras版本文字检测\n    from text import keras_detectE_invoice as detect\n\nprint(\"Text detect engine:{}\".format(opencvFlag))\n\n\ndef text_detect(img,\n                MAX_HORIZONTAL_GAP=50,\n                MIN_V_OVERLAPS=0.6,\n                MIN_SIZE_SIM=0.6,\n                TEXT_PROPOSALS_MIN_SCORE=0.7,\n                TEXT_PROPOSALS_NMS_THRESH=0.3,\n                TEXT_LINE_NMS_THRESH=0.3,\n                ):\n    boxes, scores = detect.text_detect(np.array(img))\n    boxes = np.array(boxes, dtype=np.float32)\n    scores = np.array(scores, dtype=np.float32)\n    textdetector = TextDetector(MAX_HORIZONTAL_GAP, MIN_V_OVERLAPS, MIN_SIZE_SIM)\n    shape = img.shape[:2]\n    boxes = textdetector.detect(boxes,\n                                scores[:, np.newaxis],\n                                shape,\n                                TEXT_PROPOSALS_MIN_SCORE,\n                                TEXT_PROPOSALS_NMS_THRESH,\n                                TEXT_LINE_NMS_THRESH,\n                                )\n\n    text_recs = get_boxes(boxes)\n    newBox = []\n    rx = 1\n    ry = 1\n    for box in text_recs:\n        x1, y1 = (box[0], box[1])\n        x2, y2 = (box[2], box[3])\n        x3, y3 = (box[6], box[7])\n        x4, y4 = (box[4], box[5])\n        newBox.append([x1 * rx, y1 * ry, x2 * rx, y2 * ry, x3 * rx, y3 * ry, x4 * rx, y4 * ry])\n    return newBox\n\n\ndef crnnRec(im, boxes, leftAdjust=False, rightAdjust=False, alph=0.2, f=1.0):\n    \"\"\"\n    crnn模型，ocr识别\n    leftAdjust,rightAdjust 是否左右调整box 边界误差，解决文字漏检\n    \"\"\"\n    results = []\n    im = Image.fromarray(im)\n    for index, box in enumerate(boxes):\n        degree, w, h, cx, cy = solve(box)\n        partImg, newW, newH = rotate_cut_img(im, degree, box, w, h, leftAdjust, rightAdjust, alph)\n        text = crnnOcr(partImg.convert('L'))\n        if text.strip() != u'':\n            results.append({'cx': cx * f, 'cy': cy * f, 'text': text, 'w': newW * f, 'h': newH * f,\n                            'degree': degree * 180.0 / np.pi})\n\n    return results\n\n\ndef eval_angle(im, detectAngle=False):\n    \"\"\"\n    估计图片偏移角度\n    @@param:im\n    @@param:detectAngle 是否检测文字朝向\n    \"\"\"\n    angle = 0\n    img = np.array(im)\n    if detectAngle:\n        angle = angle_detect(img=np.copy(img))  ##文字朝向检测\n        if angle == 90:\n            im = Image.fromarray(im).transpose(Image.ROTATE_90)\n        elif angle == 180:\n            im = Image.fromarray(im).transpose(Image.ROTATE_180)\n        elif angle == 270:\n            im = Image.fromarray(im).transpose(Image.ROTATE_270)\n        img = np.array(im)\n\n    return angle, img\n\n\ndef model(img, detectAngle=False, config={}, leftAdjust=False, rightAdjust=False, alph=0.2):\n    \"\"\"\n    @@param:img,\n    @@param:ifadjustDegree 调整文字识别倾斜角度\n    @@param:detectAngle,是否检测文字朝向\n    \"\"\"\n    angle, img = eval_angle(img, detectAngle=detectAngle)  ##文字方向检测\n    if opencvFlag != 'keras':\n        img, f = letterbox_image(Image.fromarray(img), IMGSIZE)  ## pad\n        img = np.array(img)\n    else:\n        f = 1.0  ##解决box在原图坐标不一致问题\n\n    config['img'] = img\n    text_recs = text_detect(**config)  ##文字检测\n    newBox = sort_box(text_recs)  ##行文本识别\n    result = crnnRec(np.array(img), newBox, leftAdjust, rightAdjust, alph, 1.0 / f)\n    return img, result, angle\n\n####################################################################################################\n\nfrom PIL import Image\nfrom apphelper.image import union_rbox\nimport os\nimport torch\nfrom apphelper.image import xy_rotate_box, box_rotate, solve\nimport cv2\nimport tensorflow as tf\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'   #指定第一块GPU可用\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.3  # 程序最多只能占用指定gpu30%的显存\nsess = tf.Session(config = config)\n\ndef ocr(img):\n    h, w = img.shape[:2]\n    _, result, angle = model(img,\n                                   detectAngle=True,  ##是否进行文字方向检测\n                                   config=dict(MAX_HORIZONTAL_GAP=50,  ##字符之间的最大间隔，用于文本行的合并\n                                               MIN_V_OVERLAPS=0.6,\n                                               MIN_SIZE_SIM=0.6,\n                                               TEXT_PROPOSALS_MIN_SCORE=0.1,\n                                               TEXT_PROPOSALS_NMS_THRESH=0.3,\n                                               TEXT_LINE_NMS_THRESH=0.7,  ##文本行之间测iou值\n\n                                               ),\n                                   leftAdjust=True,  ##对检测的文本行进行向左延伸\n                                   rightAdjust=True,  ##对检测的文本行进行向右延伸\n                                   alph=0.1,  ##对检测的文本行进行向右、左延伸的倍数\n\n                                   )\n\n\n#     res5 = []\n#     for line in result:\n#         res5.append(line['text'])\n#     return {\"text\": {str(k): v for k, v in enumerate(res5)}}\n    return result\n"
        },
        {
          "name": "model_postM_invoice.py",
          "type": "blob",
          "size": 5.9482421875,
          "content": "# -*- coding: utf-8 -*-\nfrom config import opencvFlag, GPU, IMGSIZE, ocrFlag\n\nif not GPU:\n    import os\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''  ##不启用GPU\n\nif ocrFlag == 'torch':\n    from crnn.crnn_torch import crnnOcr as crnnOcr  ##torch版本ocr\nelif ocrFlag == 'keras':\n    from crnn.crnn_keras import crnnOcr as crnnOcr  ##keras版本OCR\n\nimport time\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom glob import glob\n\nfrom text.detector.detectors import TextDetector\nfrom apphelper.image import get_boxes, letterbox_image\n\nfrom text.opencv_dnn_detect import angle_detect  ##文字方向检测,支持dnn/tensorflow\nfrom apphelper.image import estimate_skew_angle, rotate_cut_img, xy_rotate_box, sort_box, box_rotate, solve\n\nif opencvFlag == 'opencv':\n    from text import opencv_dnn_detect as detect  ##opencv dnn model for darknet\nelif opencvFlag == 'darknet':\n    from text import darknet_detect as detect\nelse:\n    ## keras版本文字检测\n    from text import keras_detectM_invoice as detect\n\nprint(\"Text detect engine:{}\".format(opencvFlag))\n\n\ndef text_detect(img,\n                MAX_HORIZONTAL_GAP=30,\n                MIN_V_OVERLAPS=0.6,\n                MIN_SIZE_SIM=0.6,\n                TEXT_PROPOSALS_MIN_SCORE=0.7,\n                TEXT_PROPOSALS_NMS_THRESH=0.3,\n                TEXT_LINE_NMS_THRESH=0.3,\n                ):\n    boxes, scores = detect.text_detect(np.array(img))\n    boxes = np.array(boxes, dtype=np.float32)\n    scores = np.array(scores, dtype=np.float32)\n    textdetector = TextDetector(MAX_HORIZONTAL_GAP, MIN_V_OVERLAPS, MIN_SIZE_SIM)\n    shape = img.shape[:2]\n    boxes = textdetector.detect(boxes,\n                                scores[:, np.newaxis],\n                                shape,\n                                TEXT_PROPOSALS_MIN_SCORE,\n                                TEXT_PROPOSALS_NMS_THRESH,\n                                TEXT_LINE_NMS_THRESH,\n                                )\n\n    text_recs = get_boxes(boxes)\n    newBox = []\n    rx = 1\n    ry = 1\n    for box in text_recs:\n        x1, y1 = (box[0], box[1])\n        x2, y2 = (box[2], box[3])\n        x3, y3 = (box[6], box[7])\n        x4, y4 = (box[4], box[5])\n        newBox.append([x1 * rx, y1 * ry, x2 * rx, y2 * ry, x3 * rx, y3 * ry, x4 * rx, y4 * ry])\n    return newBox\n\n\ndef crnnRec(im, boxes, leftAdjust=False, rightAdjust=False, alph=0.2, f=1.0):\n    \"\"\"\n    crnn模型，ocr识别\n    leftAdjust,rightAdjust 是否左右调整box 边界误差，解决文字漏检\n    \"\"\"\n    results = []\n    im = Image.fromarray(im)\n    for index, box in enumerate(boxes):\n        degree, w, h, cx, cy = solve(box)\n        partImg, newW, newH = rotate_cut_img(im, degree, box, w, h, leftAdjust, rightAdjust, alph)\n        text = crnnOcr(partImg.convert('L'))\n        if text.strip() != u'':\n            results.append({'cx': cx * f, 'cy': cy * f, 'text': text, 'w': newW * f, 'h': newH * f,\n                            'degree': degree * 180.0 / np.pi})\n\n    return results\n\n\ndef eval_angle(im, detectAngle=False):\n    \"\"\"\n    估计图片偏移角度\n    @@param:im\n    @@param:detectAngle 是否检测文字朝向\n    \"\"\"\n    angle = 0\n    img = np.array(im)\n    if detectAngle:\n        angle = angle_detect(img=np.copy(img))  ##文字朝向检测\n        if angle == 90:\n            im = Image.fromarray(im).transpose(Image.ROTATE_90)\n        elif angle == 180:\n            im = Image.fromarray(im).transpose(Image.ROTATE_180)\n        elif angle == 270:\n            im = Image.fromarray(im).transpose(Image.ROTATE_270)\n        img = np.array(im)\n\n    return angle, img\n\n\ndef model(img, detectAngle=False, config={}, leftAdjust=False, rightAdjust=False, alph=0.2):\n    \"\"\"\n    @@param:img,\n    @@param:ifadjustDegree 调整文字识别倾斜角度\n    @@param:detectAngle,是否检测文字朝向\n    \"\"\"\n    angle, img = eval_angle(img, detectAngle=detectAngle)  ##文字方向检测\n    if opencvFlag != 'keras':\n        img, f = letterbox_image(Image.fromarray(img), IMGSIZE)  ## pad\n        img = np.array(img)\n    else:\n        f = 1.0  ##解决box在原图坐标不一致问题\n\n    config['img'] = img\n    text_recs = text_detect(**config)  ##文字检测\n    newBox = sort_box(text_recs)  ##行文本识别\n    result = crnnRec(np.array(img), newBox, leftAdjust, rightAdjust, alph, 1.0 / f)\n    return img, result, angle\n\n####################################################################################################\n\nfrom PIL import Image\nfrom apphelper.image import union_rbox\nimport os\nimport torch\nfrom apphelper.image import xy_rotate_box, box_rotate, solve\nimport cv2\nimport tensorflow as tf\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'   #指定第一块GPU可用\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.3  # 程序最多只能占用指定gpu30%的显存\nsess = tf.Session(config = config)\n\ndef ocr(img):\n    h, w = img.shape[:2]\n    _, result, angle = model(img,\n                                   detectAngle=True,  ##是否进行文字方向检测\n                                   config=dict(MAX_HORIZONTAL_GAP=50,  ##字符之间的最大间隔，用于文本行的合并\n                                               MIN_V_OVERLAPS=0.6,\n                                               MIN_SIZE_SIM=0.6,\n                                               TEXT_PROPOSALS_MIN_SCORE=0.1,\n                                               TEXT_PROPOSALS_NMS_THRESH=0.3,\n                                               TEXT_LINE_NMS_THRESH=0.7,  ##文本行之间测iou值\n\n                                               ),\n                                   leftAdjust=True,  ##对检测的文本行进行向左延伸\n                                   rightAdjust=True,  ##对检测的文本行进行向右延伸\n                                   alph=0.01,  ##对检测的文本行进行向右、左延伸的倍数\n\n                                   )\n\n\n#     res5 = []\n#     for line in result:\n#         res5.append(line['text'])\n#     return {\"text\": {str(k): v for k, v in enumerate(res5)}}\n    return result\n\n\n"
        },
        {
          "name": "model_post_type.py",
          "type": "blob",
          "size": 5.9501953125,
          "content": "# -*- coding: utf-8 -*-\nfrom config import opencvFlag, GPU, IMGSIZE, ocrFlag\n\nif not GPU:\n    import os\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''  ##不启用GPU\n\nif ocrFlag == 'torch':\n    from crnn.crnn_torch import crnnOcr as crnnOcr  ##torch版本ocr\nelif ocrFlag == 'keras':\n    from crnn.crnn_keras import crnnOcr as crnnOcr  ##keras版本OCR\n\nimport time\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom glob import glob\n\nfrom text.detector.detectors import TextDetector\nfrom apphelper.image import get_boxes, letterbox_image\n\nfrom text.opencv_dnn_detect import angle_detect  ##文字方向检测,支持dnn/tensorflow\nfrom apphelper.image import estimate_skew_angle, rotate_cut_img, xy_rotate_box, sort_box, box_rotate, solve\n\nif opencvFlag == 'opencv':\n    from text import opencv_dnn_detect as detect  ##opencv dnn model for darknet\nelif opencvFlag == 'darknet':\n    from text import darknet_detect as detect\nelse:\n    ## keras版本文字检测\n    from text import keras_detect_type as detect\n\nprint(\"Text detect engine:{}\".format(opencvFlag))\n\n\ndef text_detect(img,\n                MAX_HORIZONTAL_GAP=30,\n                MIN_V_OVERLAPS=0.6,\n                MIN_SIZE_SIM=0.6,\n                TEXT_PROPOSALS_MIN_SCORE=0.7,\n                TEXT_PROPOSALS_NMS_THRESH=0.3,\n                TEXT_LINE_NMS_THRESH=0.3,\n                ):\n    boxes, scores = detect.text_detect(np.array(img))\n    boxes = np.array(boxes, dtype=np.float32)\n    scores = np.array(scores, dtype=np.float32)\n    textdetector = TextDetector(MAX_HORIZONTAL_GAP, MIN_V_OVERLAPS, MIN_SIZE_SIM)\n    shape = img.shape[:2]\n    boxes = textdetector.detect(boxes,\n                                scores[:, np.newaxis],\n                                shape,\n                                TEXT_PROPOSALS_MIN_SCORE,\n                                TEXT_PROPOSALS_NMS_THRESH,\n                                TEXT_LINE_NMS_THRESH,\n                                )\n\n    text_recs = get_boxes(boxes)\n    newBox = []\n    rx = 1\n    ry = 1\n    for box in text_recs:\n        x1, y1 = (box[0], box[1])\n        x2, y2 = (box[2], box[3])\n        x3, y3 = (box[6], box[7])\n        x4, y4 = (box[4], box[5])\n        newBox.append([x1 * rx, y1 * ry, x2 * rx, y2 * ry, x3 * rx, y3 * ry, x4 * rx, y4 * ry])\n    return newBox\n\n\ndef crnnRec(im, boxes, leftAdjust=False, rightAdjust=False, alph=0.2, f=1.0):\n    \"\"\"\n    crnn模型，ocr识别\n    leftAdjust,rightAdjust 是否左右调整box 边界误差，解决文字漏检\n    \"\"\"\n    results = []\n    im = Image.fromarray(im)\n    for index, box in enumerate(boxes):\n        degree, w, h, cx, cy = solve(box)\n        partImg, newW, newH = rotate_cut_img(im, degree, box, w, h, leftAdjust, rightAdjust, alph)\n        text = crnnOcr(partImg.convert('L'))\n        if text.strip() != u'':\n            results.append({'cx': cx * f, 'cy': cy * f, 'text': text, 'w': newW * f, 'h': newH * f,\n                            'degree': degree * 180.0 / np.pi})\n\n    return results\n\n\ndef eval_angle(im, detectAngle=False):\n    \"\"\"\n    估计图片偏移角度\n    @@param:im\n    @@param:detectAngle 是否检测文字朝向\n    \"\"\"\n    angle = 0\n    img = np.array(im)\n    if detectAngle:\n        angle = angle_detect(img=np.copy(img))  ##文字朝向检测\n        if angle == 90:\n            im = Image.fromarray(im).transpose(Image.ROTATE_90)\n        elif angle == 180:\n            im = Image.fromarray(im).transpose(Image.ROTATE_180)\n        elif angle == 270:\n            im = Image.fromarray(im).transpose(Image.ROTATE_270)\n        img = np.array(im)\n\n    return angle, img\n\n\ndef model(img, detectAngle=False, config={}, leftAdjust=False, rightAdjust=False, alph=0.2):\n    \"\"\"\n    @@param:img,\n    @@param:ifadjustDegree 调整文字识别倾斜角度\n    @@param:detectAngle,是否检测文字朝向\n    \"\"\"\n    angle, img = eval_angle(img, detectAngle=detectAngle)  ##文字方向检测\n    if opencvFlag != 'keras':\n        img, f = letterbox_image(Image.fromarray(img), IMGSIZE)  ## pad\n        img = np.array(img)\n    else:\n        f = 1.0  ##解决box在原图坐标不一致问题\n\n    config['img'] = img\n    text_recs = text_detect(**config)  ##文字检测\n    newBox = sort_box(text_recs)  ##行文本识别\n    result = crnnRec(np.array(img), newBox, leftAdjust, rightAdjust, alph, 1.0 / f)\n    return img, result, angle\n\n############################################################################################################\nfrom PIL import Image\nfrom apphelper.image import union_rbox\nimport os\nimport torch\nfrom apphelper.image import xy_rotate_box, box_rotate, solve\nimport cv2\nimport tensorflow as tf\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'   #指定第一块GPU可用\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.3  # 程序最多只能占用指定gpu30%的显存\nsess = tf.Session(config = config)\n\ndef ocr(img):\n    h, w = img.shape[:2]\n    _, result, angle = model(img,\n                                   detectAngle=True,  ##是否进行文字方向检测\n                                   config=dict(MAX_HORIZONTAL_GAP=50,  ##字符之间的最大间隔，用于文本行的合并\n                                               MIN_V_OVERLAPS=0.6,\n                                               MIN_SIZE_SIM=0.6,\n                                               TEXT_PROPOSALS_MIN_SCORE=0.1,\n                                               TEXT_PROPOSALS_NMS_THRESH=0.3,\n                                               TEXT_LINE_NMS_THRESH=0.7,  ##文本行之间测iou值\n\n                                               ),\n                                   leftAdjust=True,  ##对检测的文本行进行向左延伸\n                                   rightAdjust=True,  ##对检测的文本行进行向右延伸\n                                   alph=0.01,  ##对检测的文本行进行向右、左延伸的倍数\n\n                                   )\n\n\n\n#     res5 = []\n#     for line in result:\n#         res5.append(line['text'])\n#     return {\"text\": {str(k): v for k, v in enumerate(res5)}}\n    return result\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.392578125,
          "content": "bs4\ncffi\nchardet\nClick\ncryptography\nFlask\nFlask-Compress\nFlask-Cors\nFlask-JSON\ngast\ngoogle-pasta\ngrpcio\nh5py\nidna\nitsdangerous\nJinja2\nKeras-Applications\nKeras-Preprocessing\nkeyring\nMarkdown\nMarkupSafe\nmock\nnumpy\nopencv-contrib-python\nopencv-python\npdf2image\nPillow\nprotobuf\npycparser\npyxdg\nrequests\nscipy\nSecretStorage\nsix\nsoupsieve\ntensorboard\ntensorflow==1.13.1\ntermcolor\ntorch\nurllib3\nWerkzeug\ntqdm\n"
        },
        {
          "name": "test-invoice",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "text",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}