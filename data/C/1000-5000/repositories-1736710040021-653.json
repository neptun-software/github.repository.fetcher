{
  "metadata": {
    "timestamp": 1736710040021,
    "page": 653,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "GPUOpen-Effects/FidelityFX-FSR2",
      "stars": 1999,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0380859375,
          "content": "bin/\n/.vs/fidelityfx-fsr2/v16\n/.vs\nout/"
        },
        {
          "name": ".gitlab-ci.yml",
          "type": "blob",
          "size": 1.70703125,
          "content": "variables:\n  SampleName: FSR2_Sample\n  CMakeConfig: -G \"Visual Studio 16 2019\" -A x64\n  GIT_SUBMODULE_STRATEGY: normal\n  FF_USE_FASTZIP: \"true\"\n  ARTIFACT_COMPRESSION_LEVEL: \"fast\"\n\nstages:\n  - build\n  - deploy\n\nbuild_dx12:\n  tags:\n  - windows\n  - amd64\n  stage: build\n  artifacts:\n    paths:\n    - bin/\n  script:\n  - 'cmake -A x64 -S . -B build/DX12 -DGFX_API=DX12'\n  - 'cmake --build build/DX12 --config Release --parallel 4 -- /p:CL_MPcount=16'\n\nbuild_vk:\n  tags:\n  - windows\n  - amd64\n  stage: build\n  artifacts:\n    paths:\n    - bin/\n  script:\n  - 'cmake -A x64 -S . -B build/VK -DGFX_API=VK'\n  - 'cmake --build build/VK --config Release --parallel 4 -- /p:CL_MPcount=16'\n\npackage_sample:\n  tags:\n  - windows\n  - amd64\n  stage: deploy\n  dependencies:\n    - build_dx12\n    - build_vk\n  script:\n    - echo \"Packaging build\"\n    - echo cd .\\bin\\ > %SampleName%_DX12.bat\n    - echo start %SampleName%_DX12.exe >> %SampleName%_DX12.bat\n    - copy %VULKAN_SDK%\\Bin\\glslc.exe bin\n    - echo cd .\\bin\\ > %SampleName%_VK.bat\n    - echo start %SampleName%_VK.exe >> %SampleName%_VK.bat\n  artifacts:\n      name: \"%SampleName%-%CI_COMMIT_TAG%-%CI_COMMIT_REF_NAME%-%CI_COMMIT_SHORT_SHA%\"\n      paths:\n      - \"bin/\"\n      - \"media/cauldron-media/AbandonedWarehouse/\"\n      - \"media/cauldron-media/Sponza-New/\"\n      - \"media/cauldron-media/envmaps/\"\n      - \"media/cauldron-media/noise/\"\n      - \"media/cauldron-media/color_ramp_bt2020_dcip3/\"\n      - \"media/cauldron-media/readme.md\"\n      - \"media/cauldron-media/screenshot.png\"\n      - \"media/atlas.dds\"\n      - \"media/checkerboard.dds\"\n      - \"media/composition_text.dds\"\n      - \"media/lion.jpg\"\n      - \"README.md\"\n      - \"LICENSE.txt\"\n      - \"%SampleName%_DX12.bat\"\n      - \"%SampleName%_VK.bat\"\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.216796875,
          "content": "[submodule \"media/cauldron-media\"]\n\tpath = media/cauldron-media\n\turl = ../../GPUOpen-LibrariesAndSDKs/Cauldron-Media.git\n[submodule \"libs/cauldron\"]\n\tpath = libs/cauldron\n\turl = ../../GPUOpen-LibrariesAndSDKs/Cauldron.git\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 3.66796875,
          "content": "# This file is part of the FidelityFX SDK.\n# \n# Copyright (c) 2022 Advanced Micro Devices, Inc. All rights reserved.\n# \n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\ncmake_minimum_required(VERSION 3.12.1)\n\noption (GFX_API_DX12 \"Build with DX12\" ON)\noption (GFX_API_VK \"Build with Vulkan\" ON)\n\nif(NOT DEFINED GFX_API)\n    project (FSR2_Sample)\nelse()\n    project (FSR2_Sample_${GFX_API})\n\n    set_property(DIRECTORY ${CMAKE_PROJECT_DIR} PROPERTY VS_STARTUP_PROJECT ${PROJECT_NAME})\n\n    if(GFX_API STREQUAL DX12)\n        set(GFX_API_DX12 ON)\n        set(GFX_API_VK OFF)\n    elseif(GFX_API STREQUAL VK)\n        set(GFX_API_DX12 OFF)\n        set(GFX_API_VK ON)\n    else()\n        message(STATUS \"----------------------------------------------------------------------------------------\")\n        message(STATUS \"\")\n        message(STATUS \"** Almost there!!\")\n        message(STATUS \"\")\n        message(STATUS \" This framework supports DX12 and VULKAN, you need to invoke cmake in one of these ways:\")\n        message(STATUS \"\")\n        message(STATUS \" Examples:\")\n        message(STATUS \"  Generate selected one:\")\n        message(STATUS \"    cmake <project_root_dir> -DGFX_API=DX12\")\n        message(STATUS \"    cmake <project_root_dir> -DGFX_API=VK\")\n        message(STATUS \"  Generate with switches (Default is ON):\")\n        message(STATUS \"    cmake <project_root_dir> [-DGFX_API_DX12=ON|OFF] [-DGFX_API_VK=ON|OFF]\")\n        message(STATUS \"\")\n        message(STATUS \"----------------------------------------------------------------------------------------\")\n        message(FATAL_ERROR \"\")\n    endif()\nendif()\n\n# Check MSVC toolset version, Visual Studio 2019 required\nif(MSVC_TOOLSET_VERSION VERSION_LESS 142)\n    message(FATAL_ERROR \"Cannot find MSVC toolset version 142 or greater. Please make sure Visual Studio 2019 or newer installed\")\nendif()\n\n# ouput exe to bin directory\nSET(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_HOME_DIRECTORY}/bin)\n\nforeach( OUTPUTCONFIG ${CMAKE_CONFIGURATION_TYPES} )\n    string( TOUPPER ${OUTPUTCONFIG} OUTPUTCONFIG )\n    set( CMAKE_RUNTIME_OUTPUT_DIRECTORY_${OUTPUTCONFIG} ${CMAKE_HOME_DIRECTORY}/bin )\nendforeach( OUTPUTCONFIG CMAKE_CONFIGURATION_TYPES )\n\nadd_compile_options(/MP)\nadd_compile_definitions($<$<CONFIG:RelWithDebInfo>:USE_PIX>)\n\n# override build options in ffx-fsr2-api cmake\noption (FFX_FSR2_API_DX12 \"Build FSR 2.0 DX12 backend\" ${GFX_API_DX12})\noption (FFX_FSR2_API_VK \"Build FSR 2.0 Vulkan backend\" ${GFX_API_VK})\n\n# reference libs used by both backends\nadd_subdirectory(libs/cauldron)\nadd_subdirectory(src/Common)\nadd_subdirectory(src/ffx-fsr2-api)\n\nif(GFX_API_VK)\n    find_package(Vulkan REQUIRED)\n    add_subdirectory(src/VK)\nendif()\nif(GFX_API_DX12)\n    add_subdirectory(src/DX12)\nendif()\n\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.1376953125,
          "content": "FidelityFX Super Resolution 2.2\n=================================\nCopyright (c) 2022-2023 Advanced Micro Devices, Inc. All rights reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 108.6298828125,
          "content": "# FidelityFX Super Resolution 2.2 (FSR 2.2.1)\n\nCopyright (c) 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\n![Screenshot](screenshot.png)\n\nAMD FidelityFX Super Resolution 2 (FSR 2) is an open source, high-quality solution for producing high resolution frames from lower resolution inputs.\n\nYou can find the binaries for FidelityFX FSR in the release section on GitHub.\n\n# Super Resolution 2\n\n### Table of contents\n\n- [Introduction](#introduction)\n    - [Shading language requirements](#shading-language-requirements)\n- [Quick start checklist](#quick-start-checklist)\n- [Integration guidelines](#integration-guidelines)\n    - [Quality modes](#quality-modes)\n    - [Performance](#performance)\n    - [Memory requirements](#memory-requirements)\n    - [Input resources](#input-resources)\n    - [Depth buffer configurations](#depth-buffer-configurations)\n    - [Providing motion vectors](#providing-motion-vectors)\n    - [Reactive mask](#reactive-mask)\n    - [Automatically generating reactivity](#automatically-generating-reactivity)\n    - [Transparency and composition mask](#transparency-and-composition-mask)\n    - [Automatically generating transparency and composition mask](#automatically-generating-transparency-and-composition-mask)\n    - [Placement in the frame](#placement-in-the-frame)\n    - [Host API](#host-api)\n\t- [Modular backend](#modular-backend)\n    - [Memory management](#memory-management)\n    - [Temporal antialiasing](#temporal-antialiasing)\n    - [Camera jitter](#camera-jitter)\n\t- [Camera jump cuts](#camera-jump-cuts)\n    - [Mipmap biasing](#mipmap-biasing)\n    - [Frame Time Delta Input](#frame-time-delta-input)\n    - [HDR support](#hdr-support)\n    - [Falling back to 32-bit floating point](#falling-back-to-32-bit-floating-point)\n    - [64-wide wavefronts](#64-wide-wavefronts)\n    - [API Debug Checker](#debug-checker)\n- [The technique](#the-technique)\n    - [Algorithm structure](#algorithm-structure)\n    - [Compute luminance pyramid](#compute-luminance-pyramid)\n    - [Reconstruct & dilate](#reconstruct-and-dilate)\n    - [Depth clip](#depth-clip)\n    - [Create locks](#create-locks)\n    - [Reproject & accumulate](#reproject-accumulate)\n    - [Robust Contrast Adaptive Sharpening (RCAS)](#robust-contrast-adaptive-sharpening-rcas)\n- [Building the sample](#building-the-sample)\n- [Limitations](#limitations)\n- [Version history](#version-history)\n- [References](#references)\n\n# Introduction\n**FidelityFX Super Resolution 2** (or **FSR2** for short) is a cutting-edge upscaling technique developed from the ground up to produce high resolution frames from lower resolution inputs.\n\n![alt text](docs/media/super-resolution-temporal/overview.svg \"A diagram showing the input resources to the super resolution (temporal) algorithm.\")\n\nFSR2 uses temporal feedback to reconstruct high-resolution images while maintaining and even improving image quality compared to native rendering.\n\nFSR2 can enable “practical performance” for costly render operations, such as hardware ray tracing.\n\n## Shading language requirements\n`HLSL` `CS_6_2` `CS_6_6*`\n\n\\* - CS_6_6 is used on some hardware which supports 64-wide wavefronts.\n\n# Quick start checklist\nTo use FSR2 you should follow the steps below:\n\n1. Double click [`GenerateSolutions.bat`](build/GenerateSolutions.bat) in the [`build`](build) directory.\n\n2. Open the solution matching your API, and build the solution.\n\n3. Copy the API library from `bin/ffx_fsr2_api` into the folder containing a folder in your project which contains third-party libraries.\n\n4. Copy the library matching the FSR2 backend you want to use, e.g.: `bin/ffx_fsr2_api/ffx_fsr2_api_dx12_x64.lib` for DirectX12.\n\n5. Copy the following core API header files from src/ffx-fsr2-api into your project: `ffx_fsr2.h`, `ffx_types.h`, `ffx_error.h`, `ffx_fsr2_interface.h`, `ffx_util.h`, `shaders/ffx_fsr2_common.h`, and `shaders/ffx_fsr2_resources.h`. Care should be taken to maintain the relative directory structure at the destination of the file copying.\n\n6. Copy the header files for the API backend of your choice, e.g. for DirectX12 you would copy `dx12/ffx_fsr2_dx12.h` and `dx12/shaders/ffx_fsr2_shaders_dx12.h`. Care should be taken to maintain the relative directory structure at the destination of the file copying.\n\n7. Include the `ffx_fsr2.h` header file in your codebase where you wish to interact with FSR2.\n\n8. Create a backend for your target API. E.g. for DirectX12 you should call [`ffxFsr2GetInterfaceDX12`](src/ffx-fsr2-api/dx12/ffx_fsr2_dx12.h#L55). A scratch buffer should be allocated of the size returned by calling [`ffxFsr2GetScratchMemorySizeDX12`](src/ffx-fsr2-api/dx12/ffx_fsr2_dx12.h#L40) and the pointer to that buffer passed to [`ffxFsr2GetInterfaceDX12`](src/ffx-fsr2-api/dx12/ffx_fsr2_dx12.h#L55).\n\n9. Create a FSR2 context by calling [`ffxFsr2ContextCreate`](src/ffx-fsr2-api/ffx_fsr2.h#L228). The parameters structure should be filled out matching the configuration of your application. See the API reference documentation for more details.\n\n10. Each frame you should call [`ffxFsr2ContextDispatch`](src/ffx-fsr2-api/ffx_fsr2.h#L269) to launch FSR2 workloads. The parameters structure should be filled out matching the configuration of your application. See the API reference documentation for more details, and ensure the [`frameTimeDelta` field is provided in milliseconds](#frame-time-delta-input).\n\n11. When your application is terminating (or you wish to destroy the context for another reason) you should call [`ffxFsr2ContextDestroy`](src/ffx-fsr2-api/ffx_fsr2.h#L292). The GPU should be idle before calling this function.\n\n12. Sub-pixel jittering should be applied to your application's projection matrix. This should be done when performing the main rendering of your application. You should use the [`ffxFsr2GetJitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L437) function to compute the precise jitter offsets. See [Camera jitter](#camera-jitter) section for more details.\n\n13. For the best upscaling quality it is strongly advised that you populate the [Reactive mask](#reactive-mask) and [Transparency & composition mask](#transparency-and-composition-mask) according to our guidelines. You can also use [`ffxFsr2ContextGenerateReactiveMask`](src/ffx-fsr2-api/ffx_fsr2.h#L280) as a starting point.\n\n14. Applications should expose [scaling modes](#scaling-modes), in their user interface in the following order: Quality, Balanced, Performance, and (optionally) Ultra Performance.\n\n15. Applications should also expose a sharpening slider to allow end users to achieve additional quality.\n\n# Integration guidelines\n\n## Scaling modes\nFor the convenience of end users, the FSR2 API provides a number of preset scaling ratios which are named.\n\n| Quality           | Per-dimension scaling factor |    \n|-------------------|------------------------------|\n| Quality           | 1.5x                         |\n| Balanced          | 1.7x                         |\n| Performance       | 2.0x                         |\n| Ultra performance | 3.0x                         |\n\nWe strongly recommend that applications adopt consistent naming and scaling ratios in their user interface. This is to ensure that user experience is consistent for your application's users which may have experience of other applications using FSR2. \n\n## Performance\nDepending on your target hardware and operating configuration FSR2 will operate at different performance levels.\n\nThe table below summarizes the measured performance of FSR2 on a variety of hardware in DX12.\n\n| Target resolution | Quality          | RX 7900 XTX| RX 6950 XT | RX 6900 XT | RX 6800 XT | RX 6800 | RX 6700 XT | RX 6650 XT | RX 5700 XT | RX Vega 56 | RX 590 |\n|-------------------|------------------|------------|------------|------------|------------|---------|------------|------------|------------|------------|--------|\n| 3840x2160         | Quality (1.5x)   | 0.7ms      | 1.1ms      | 1.2ms      | 1.2ms      | 1.4ms   | 2.0ms      | 2.8ms      | 2.4ms      | 4.9ms      | 5.4ms  |\n|                   | Balanced (1.7x)  | 0.6ms      | 1.0ms      | 1.0ms      | 1.1ms      | 1.4ms   | 1.8ms      | 2.6ms      | 2.2ms      | 4.1ms      | 4.9ms  |\n|                   | Performance (2x) | 0.6ms      | 0.9ms      | 1.0ms      | 1.0ms      | 1.3ms   | 1.7ms      | 2.3ms      | 2.0ms      | 3.6ms      | 4.4ms  |\n|                   | Ultra perf. (3x) | 0.5ms      | 0.8ms      | 0.8ms      | 0.9ms      | 1.1ms   | 1.5ms      | 1.8ms      | 1.7ms      | 2.9ms      | 3.7ms  |\n| 2560x1440         | Quality (1.5x)   | 0.3ms      | 0.5ms      | 0.5ms      | 0.5ms      | 0.7ms   | 0.9ms      | 1.2ms      | 1.1ms      | 1.9ms      | 2.3ms  |\n|                   | Balanced (1.7x)  | 0.3ms      | 0.5ms      | 0.5ms      | 0.5ms      | 0.6ms   | 0.8ms      | 1.1ms      | 1.0ms      | 1.7ms      | 2.1ms  |\n|                   | Performance (2x) | 0.3ms      | 0.4ms      | 0.4ms      | 0.4ms      | 0.6ms   | 0.8ms      | 0.9ms      | 0.9ms      | 1.5ms      | 1.9ms  |\n|                   | Ultra perf. (3x) | 0.2ms      | 0.4ms      | 0.4ms      | 0.4ms      | 0.5ms   | 0.7ms      | 0.8ms      | 0.8ms      | 1.2ms      | 1.7ms  |\n| 1920x1080         | Quality (1.5x)   | 0.2ms      | 0.3ms      | 0.3ms      | 0.3ms      | 0.4ms   | 0.5ms      | 0.6ms      | 0.6ms      | 1.0ms      | 1.3ms  |\n|                   | Balanced (1.7x)  | 0.2ms      | 0.3ms      | 0.3ms      | 0.3ms      | 0.4ms   | 0.5ms      | 0.6ms      | 0.6ms      | 0.9ms      | 1.2ms  |\n|                   | Performance (2x) | 0.2ms      | 0.2ms      | 0.2ms      | 0.3ms      | 0.3ms   | 0.5ms      | 0.5ms      | 0.5ms      | 0.8ms      | 1.1ms  |\n|                   | Ultra perf. (3x) | 0.1ms      | 0.2ms      | 0.2ms      | 0.2ms      | 0.3ms   | 0.4ms      | 0.4ms      | 0.4ms      | 0.7ms      | 0.9ms  |\n\nFigures are rounded to the nearest 0.1ms and are without additional [`sharpness`](src/ffx-fsr2-api/ffx_fsr2.h#L132) and are subject to change.\n\n## Memory requirements\nUsing FSR2 requires some additional GPU local memory to be allocated for consumption by the GPU. When using the FSR2 API, this memory is allocated when the FSR2 context is created, and is done so via the series of callbacks which comprise the backend interface. This memory is used to store intermediate surfaces which are computed by the FSR2 algorithm as well as surfaces which are persistent across many frames of the application. The table below includes the amount of memory used by FSR2 under various operating conditions. The \"Working set\" column indicates the total amount of memory used by FSR2 as the algorithm is executing on the GPU; this is the amount of memory FSR2 will require to run. The \"Persistent memory\" column indicates how much of the \"Working set\" column is required to be left intact for subsequent frames of the application; this memory stores the temporal data consumed by FSR2. The \"Aliasable memory\" column indicates how much of the \"Working set\" column may be aliased by surfaces or other resources used by the application outside of the operating boundaries of FSR2.\n\nYou can take control of resource creation in FSR2 by overriding the resource creation and destruction parts of the FSR2 backend interface, and forwarding the aliasing flags. This means that for a perfect integration of FSR2, additional memory which is equal to the \"Persistent memory\" column of the table below is required depending on your operating conditions.\n\n| Resolution | Quality                | Working set (MB) | Persistent memory (MB) | Aliasable memory (MB)   |  \n| -----------|------------------------|------------------|------------------------|-------------------------|\n| 3840x2160  | Quality (1.5x)         | 448MB      |  354MB      |  93MB         |\n|            | Balanced (1.7x)        | 407MB      |  330MB      |  77MB         |\n|            | Performance (2x)       | 376MB      |  312MB      |  63MB         |\n|            | Ultra performance (3x) | 323MB      |  281MB      |  42MB         |\n| 2560x1440  | Quality (1.5x)         | 207MB      |  164MB      |  43MB         |\n|            | Balanced (1.7x)        | 189MB      |  153MB      |  36MB         |\n|            | Performance (2x)       | 172MB      |  143MB      |  29MB         |\n|            | Ultra performance (3x) | 149MB      |  130MB      |  19MB         |\n| 1920x1080  | Quality (1.5x)         | 115MB      |  90MB      |  24MB         |\n|            | Balanced (1.7x)        | 105MB      |  85MB      |  20MB         |\n|            | Performance (2x)       | 101MB      |  83MB      |  18MB         |\n|            | Ultra performance (3x) | 84MB      |  72MB      |  11MB         |\n\nFigures are approximations, rounded up to nearest MB using an RX 6700XT GPU in DX12, and are subject to change.\n\nFor details on how to manage FSR2's memory requirements please refer to the section of this document dealing with [Memory management](#memory-management).\n\n## Input resources\nFSR2 is a temporal algorithm, and therefore requires access to data from both the current and previous frame. The following table enumerates all external inputs required by FSR2.\n\n> The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. All resources are from the current rendered frame, for DirectX(R)12 and Vulkan(R) applications all input resources should be transitioned to [`D3D12_RESOURCE_STATE_NON_PIXEL_SHADER_RESOURCE`](https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_resource_states) and [`VK_ACCESS_SHADER_READ_BIT`](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkAccessFlagBits.html) respectively before calling [`ffxFsr2ContextDispatch`](src/ffx-fsr2-api/ffx_fsr2.h#L269).\n\n| Name            | Resolution                   |  Format                            | Type      | Notes                                          |  \n| ----------------|------------------------------|------------------------------------|-----------|------------------------------------------------|\n| Color buffer    | Render                       | `APPLICATION SPECIFIED`            | Texture   | The render resolution color buffer for the current frame provided by the application. If the contents of the color buffer are in high dynamic range (HDR), then the [`FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE`](src/ffx-fsr2-api/ffx_fsr2.h#L88) flag should be set in  the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. |\n| Depth buffer    | Render                       | `APPLICATION SPECIFIED (1x FLOAT)` | Texture   | The render resolution depth buffer for the current frame provided by the application. The data should be provided as a single floating point value, the precision of which is under the application's control. The configuration of the depth should be communicated to FSR2 via the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179). You should set the [`FFX_FSR2_ENABLE_DEPTH_INVERTED`](src/ffx-fsr2-api/ffx_fsr2.h#L91) flag if your depth buffer is inverted (that is [1..0] range), and you should set the [`FFX_FSR2_ENABLE_DEPTH_INFINITE`](src/ffx-fsr2-api/ffx_fsr2.h#L92) flag if your depth buffer has an infinite far plane. If the application provides the depth buffer in `D32S8` format, then FSR2 will ignore the stencil component of the buffer, and create an `R32_FLOAT` resource to address the depth buffer. On GCN and RDNA hardware, depth buffers are stored separately from stencil buffers. |\n| Motion vectors  | Render or presentation       | `APPLICATION SPECIFIED (2x FLOAT)` | Texture   | The 2D motion vectors for the current frame provided by the application in [**(<-width, -height>**..**<width, height>**] range. If your application renders motion vectors with a different range, you may use the [`motionVectorScale`](src/ffx-fsr2-api/ffx_fsr2.h#L129) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to adjust them to match the expected range for FSR2. Internally, FSR2 uses 16-bit quantities to represent motion vectors in many cases, which means that while motion vectors with greater precision can be provided, FSR2 will not benefit from the increased precision. The resolution of the motion vector buffer should be equal to the render resolution, unless the [`FFX_FSR2_ENABLE_DISPLAY_RESOLUTION_MOTION_VECTORS`](src/ffx-fsr2-api/ffx_fsr2.h#L89) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179), in which case it should be equal to the presentation resolution. |\n| Reactive mask   | Render                       | `R8_UNORM`                         | Texture   | As some areas of a rendered image do not leave a footprint in the depth buffer or include motion vectors, FSR2 provides support for a reactive mask texture which can be used to indicate to FSR2 where such areas are. Good examples of these are particles, or alpha-blended objects which do not write depth or motion vectors. If this resource is not set, then FSR2's shading change detection logic will handle these cases as best it can, but for optimal results, this resource should be set. For more information on the reactive mask please refer to the [Reactive mask](#reactive-mask) section.  |\n| Exposure        | 1x1                          | `R32_FLOAT`                        | Texture   | A 1x1 texture containing the exposure value computed for the current frame. This resource is optional, and may be omitted if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179).  |\n\nAll inputs that are provided at Render Resolution, except for motion vectors, should be rendered with jitter. Motion vectors should not have jitter applied, unless the `FFX_FSR2_ENABLE_MOTION_VECTORS_JITTER_CANCELLATION` flag is present.\n\n## Depth buffer configurations\nIt is strongly recommended that an inverted, infinite depth buffer is used with FSR2. However, alternative depth buffer configurations are supported. An application should inform the FSR2 API of its depth buffer configuration by setting the appropriate flags during the creation of the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179). The table below contains the appropriate flags.\n\n| FSR2 flag                        | Note                                                                                       |\n|----------------------------------|--------------------------------------------------------------------------------------------|\n| [`FFX_FSR2_ENABLE_DEPTH_INVERTED`](src/ffx-fsr2-api/ffx_fsr2.h#L91) | A bit indicating that the input depth buffer data provided is inverted [max..0].           |\n| [`FFX_FSR2_ENABLE_DEPTH_INFINITE`](src/ffx-fsr2-api/ffx_fsr2.h#L92) | A bit indicating that the input depth buffer data provided is using an infinite far plane. |\n\n\n## Providing motion vectors\n\n### Space\nA key part of a temporal algorithm (be it antialiasing or upscaling) is the provision of motion vectors. FSR2 accepts motion vectors in 2D which encode the motion from a pixel in the current frame to the position of that same pixel in the previous frame. FSR2 expects that motion vectors are provided by the application in [**<-width, -height>**..**<width, height>**] range; this matches screenspace. For example, a motion vector for a pixel in the upper-left corner of the screen with a value of <width, height> would represent a motion that traversed the full width and height of the input surfaces, originating from the bottom-right corner.\n\n![alt text](docs/media/super-resolution-temporal/motion-vectors.svg \"A diagram showing a 2D motion vector.\")\n\nIf your application computes motion vectors in another space - for example normalized device coordinate space - then you may use the [`motionVectorScale`](src/ffx-fsr2-api/ffx_fsr2.h#L129) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to instruct FSR2 to adjust them to match the expected range for FSR2. The code examples below illustrate how motion vectors may be scaled to screen space. The example HLSL and C++ code below illustrates how NDC-space motion vectors can be scaled using the FSR2 host API.\n\n```HLSL\n// GPU: Example of application NDC motion vector computation\nfloat2 motionVector = (previousPosition.xy / previousPosition.w) - (currentPosition.xy / currentPosition.w);\n\n// CPU: Matching FSR 2.0 motionVectorScale configuration\ndispatchParameters.motionVectorScale.x = (float)renderWidth;\ndispatchParameters.motionVectorScale.y = (float)renderHeight;\n```\n\n### Precision & resolution\nInternally, FSR2 uses 16bit quantities to represent motion vectors in many cases, which means that while motion vectors with greater precision can be provided, FSR2 will not currently benefit from the increased precision. The resolution of the motion vector buffer should be equal to the render resolution, unless the [`FFX_FSR2_ENABLE_DISPLAY_RESOLUTION_MOTION_VECTORS`](src/ffx-fsr2-api/ffx_fsr2.h#L89) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179), in which case it should be equal to the presentation resolution.\n\n### Coverage\nFSR2 will perform better quality upscaling when more objects provide their motion vectors. It is therefore advised that all opaque, alpha-tested and alpha-blended objects should write their motion vectors for all covered pixels. If vertex shader effects are applied - such as scrolling UVs - these calculations should also be factored into the calculation of motion for the best results. For alpha-blended objects it is also strongly advised that the alpha value of each covered pixel is stored to the corresponding pixel in the [reactive mask](#reactive-mask). This will allow FSR2 to perform better handling of alpha-blended objects during upscaling. The reactive mask is especially important for alpha-blended objects where writing motion vectors might be prohibitive, such as particles.\n\n## Reactive mask\nIn the context of FSR2, the term \"reactivity\" means how much influence the samples rendered for the current frame have over the production of the final upscaled image. Typically, samples rendered for the current frame contribute a relatively modest amount to the result computed by FSR2; however, there are exceptions. To produce the best results for fast moving, alpha-blended objects, FSR2 requires the [Reproject & accumulate](#reproject-accumulate) stage to become more reactive for such pixels. As there is no good way to determine from either color, depth or motion vectors which pixels have been rendered using alpha blending, FSR2 performs best when applications explicitly mark such areas.\n\nTherefore, it is strongly encouraged that applications provide a reactive mask to FSR2. The reactive mask guides FSR2 on where it should reduce its reliance on historical information when compositing the current pixel, and instead allow the current frame's samples to contribute more to the final result. The reactive mask allows the application to provide a value from [0.0..1.0] where 0.0 indicates that the pixel is not at all reactive (and should use the default FSR2 composition strategy), and a value of 1.0 indicates the pixel should be fully reactive. This is a floating point range and can be tailored to different situations.\n\nWhile there are other applications for the reactive mask, the primary application for the reactive mask is producing better results of upscaling images which include alpha-blended objects. A good proxy for reactiveness is actually the alpha value used when compositing an alpha-blended object into the scene, therefore, applications should write `alpha` to the reactive mask. It should be noted that it is unlikely that a reactive value of close to 1 will ever produce good results. Therefore, we recommend clamping the maximum reactive value to around 0.9.\n\nIf a [Reactive mask](#reactive-mask) is not provided to FSR2 (by setting the [`reactive`](src/ffx-fsr2-api/ffx_fsr2.h#L125) field of [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) to `NULL`) then an internally generated 1x1 texture with a cleared reactive value will be used.\n\n## Automatically generating reactivity\nTo help applications generate the [Reactive mask](#reactive-mask) and the [Transparency & composition mask](#transparency-and-composition-mask), FSR2 provides an optional helper API. Under the hood, the API launches a compute shader which computes these values for each pixel using a luminance-based heuristic.\n\nApplications wishing to do this can call the [`ffxFsr2ContextGenerateReactiveMask`](src/ffx-fsr2-api/ffx_fsr2.h#L280) function and should pass two versions of the color buffer, one containing opaque only geometry, and the other containing both opaque and alpha-blended objects.\n\n## Transparency and composition mask\nIn addition to the [Reactive mask](#reactive-mask), FSR2 provides for the application to denote areas of other specialist rendering which should be accounted for during the upscaling process. Examples of such special rendering include areas of raytraced reflections or animated textures.\n\nWhile the [Reactive mask](#reactive-mask) adjusts the accumulation balance, the [Transparency & composition mask](#transparency-and-composition-mask) adjusts the pixel history protection mechanisms. The mask also removes the effect of the luminance instability factor. A pixel with a value of 0 in the [Transparency & composition mask](#ttransparency-and-composition-mask) does not perform any additional modification to the lock for that pixel. Conversely, a value of 1 denotes that the lock for that pixel should be completely removed.\n\nIf a [Transparency & composition mask](#transparency-and-composition-mask) is not provided to FSR2 (by setting the [`transparencyAndComposition`](#src/ffx-fsr2-api/ffx_fsr2.h#L126) field of [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) to `NULL`) then an internally generated 1x1 texture with a cleared transparency and composition value will be used.\n\n## Automatically generating Transparency and composition mask\nFSR2.2 includes an experimental feature to generate [Reactive mask](#reactive-mask) and [Transparency & composition mask](#transparency-and-composition-mask) automatically. To enable this, the [`enableAutoReactive`](#src/ffx-fsr2-api/ffx_fsr2.h#L142) field of [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) needs to be set to 'TRUE' and a copy of the opaque only portions of the backbuffer needs to be provided in ['colorOpaqueOnly'](src/ffx-fsr2-api/ffx_fsr2.h#L143). FSR2 will then automatically generate and use [Reactive mask](#reactive-mask) and [Transparency & composition mask](#transparency-and-composition-mask) internally. The masks are generated in a compute pass by analyzing the difference of the color buffer with and without transparent geometry, as well as compare it to the previous frame. Based on the result of those computations each pixel gets assigned [Reactive mask](#reactive-mask) and [Transparency & composition mask](#transparency-and-composition-mask) values.\nTo use autogeneration of the masks the following 4 values to scale and limit the intensity of the masks are required to be provided as well (Note the mentioned default values are suggested starting values but should be tuned per title):\n\n- ['autoTcThreshold'](#src/ffx-fsr2-api/ffx_fsr2.h#L144): Setting this value too small will cause visual instability. Larger values can cause ghosting. Recommended default value is 0.05f.\n- ['autoTcScale'](#src/ffx-fsr2-api/ffx_fsr2.h#L145): Smaller values will increase stability at hard edges of translucent objects. Recommended default value is 1.0f.\n- ['autoReactiveScale'](#src/ffx-fsr2-api/ffx_fsr2.h#L146): Larger values result in more reactive pixels. Recommended default value is 5.00f\n- ['autoReactiveMax'](#src/ffx-fsr2-api/ffx_fsr2.h#L147): Maximum value reactivity can reach. Recommended default value is 0.90f.\n\nThis feature is intended to help with integrating FSR2.2 into a new engine or title. However, for best quality we still recommend to render the [Reactive mask](#reactive-mask) and [Transparency & composition mask](#transparency-and-composition-mask) yourself, as generating those values based on material is expected to be more reliable than autogenerating them from the final image.\n\nPlease note that this feature is still in experimental stage and may change significantly in the future. \n\n## Exposure\nFSR2 provides two values which control the exposure used when performing upscaling. They are as follows:\n\n1. **Pre-exposure** a value by which we divide the input signal to get back to the original signal produced by the game before any packing into lower precision render targets.\n2. **Exposure** a value which is multiplied against the result of the pre-exposed color value.\n\nThe exposure value should match that which the application uses during any subsequent tonemapping passes performed by the application. This means FSR2 will operate consistently with what is likely to be visible in the final tonemapped image. \n\n> In various stages of the FSR2 algorithm described in this document, FSR2 will compute its own exposure value for internal use. It is worth noting that all outputs from FSR2 will have this internal tonemapping reversed before the final output is written. Meaning that FSR2 returns results in the same domain as the original input signal.\n\nPoorly selected exposure values can have a drastic impact on the final quality of FSR2's upscaling. Therefore, it is recommended that [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) is used by the application, unless there is a particular reason not to. When [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure, the exposure calculation shown in the HLSL code below is used to compute the exposure value, which matches the exposure response of ISO 100 film stock.\n\n```HLSL\nfloat ComputeAutoExposureFromAverageLog(float averageLogLuminance)\n{\n\tconst float averageLuminance = exp(averageLogLuminance);\n\tconst float S = 100.0f; // ISO arithmetic speed\n\tconst float K = 12.5f;\n\tconst float exposureIso100 = log2((averageLuminance * S) / K);\n\tconst float q = 0.65f;\n\tconst float luminanceMax = (78.0f / (q * S)) * pow(2.0f, exposureIso100);\n\treturn 1 / luminanceMax;\n}\n```\n\n## Placement in the frame\nThe primary goal of FSR2 is to improve application rendering performance by using a temporal upscaling algorithm relying on a number of inputs. Therefore, its placement in the pipeline is key to ensuring the right balance between the highest quality visual quality and great performance.\n\n![alt text](docs/media/super-resolution-temporal/pipeline-placement.svg \"A diagram showing the placement of FidelityFX Super Resolution (Temporal) in the wider rendering pipeline.\")\n\nWith any image upscaling approach is it important to understand how to place other image-space algorithms with respect to the upscaling algorithm. Placing these other image-space effects before the upscaling has the advantage that they run at a lower resolution, which of course confers a performance advantage onto the application. However, it may not be appropriate for some classes of image-space techniques. For example, many applications may introduce noise or grain into the final image, perhaps to simulate a physical camera. Doing so before an upscaler might cause the upscaler to amplify the noise, causing undesirable artifacts in the resulting upscaled image. The following table divides common real-time image-space techniques into two columns. 'Post processing A' contains all the techniques which typically would run before FSR2's upscaling, meaning they would all run at render resolution. Conversely, the 'Post processing B' column contains all the techniques which are recommend to run after FSR2, meaning they would run at the larger, presentation resolution.\n\n| Post processing A              | Post processing B    |\n|--------------------------------|----------------------|\n| Screenspace reflections        | Film grain           |\n| Screenspace ambient occlusion  | Chromatic aberration |\n| Denoisers (shadow, reflections)| Vignette             |\n| Exposure (optional)            | Tonemapping          |\n|                                | Bloom                |\n|                                | Depth of field       |\n|                                | Motion blur          |\n\nPlease note that the recommendations here are for guidance purposes only and depend on the precise characteristics of your application's implementation.\n\n## Host API\nWhile it is possible to generate the appropriate intermediate resources, compile the shader code, set the bindings, and submit the dispatches, it is much easier to use the FSR2 host API which is provided.\n\nTo use to the API, you should link the FSR2 libraries (more on which ones shortly) and include the `ffx_fsr2.h` header file, which in turn has the following header dependencies:\n\n```\nffx_assert.h\nffx_error.h\nffx_fsr2_interface.h\nffx_types.h\nffx_util.h\n```\n\nTo use the FSR2 API, you should link `ffx_fsr2_api_x64.lib` which will provide the symbols for the application-facing APIs. However, FSR2's API has a modular backend, which means that different graphics APIs and platforms may be targeted through the use of a matching backend. Therefore, you should further include the backend lib matching your requirements, referencing the table below.\n\n| Target              | Library name            |\n|---------------------|-------------------------|\n| DirectX(R)12        | `ffx_fsr2_dx12_x64.lib` |\n| Vulkan(R)           | `ffx_fsr2_vk_x64.lib`   | \n\n> Please note the modular architecture of the FSR2 API allows for custom backends to be implemented. See the [Modular backend](#modular-backend) section for more details.\n\nTo begin using the API, the application should first create a [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179) structure. This structure should be located somewhere with a lifetime approximately matching that of your backbuffer; somewhere on the application's heap is usually a good choice. By calling [`ffxFsr2ContextCreate`](src/ffx-fsr2-api/ffx_fsr2.h#L228) the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179) structure will be populated with the data it requires. Moreover, a number of calls will be made from [`ffxFsr2ContextCreate`](src/ffx-fsr2-api/ffx_fsr2.h#L228) to the backend which is provided to [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179) as part of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. These calls will perform such tasks as creating intermediate resources required by FSR2 and setting up shaders and their associated pipeline state. The FSR2 API does not perform any dynamic memory allocation.\n\nEach frame of your application where upscaling is required, you should call [`ffxFsr2ContextDispatch`](src/ffx-fsr2-api/ffx_fsr2.h#L269). This function accepts the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179) structure that was created earlier in the application's lifetime as well as a description of precisely how upscaling should be performed and on which data. This description is provided by the application filling out a [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure.\n\nDestroying the context is performed by calling [`ffxFsr2ContextDestroy`](src/ffx-fsr2-api/ffx_fsr2.h#L292). Please note, that the GPU should be idle before attempting to call [`ffxFsr2ContextDestroy`](src/ffx-fsr2-api/ffx_fsr2.h#L292), and the function does not perform implicit synchronization to ensure that resources being accessed by FSR2 are not currently in flight. The reason for this choice is to avoid FSR2 introducing additional GPU flushes for applications who already perform adequate synchronization at the point where they might wish to destroy the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179), this allows an application to perform the most efficient possible creation and teardown of the FSR2 API when required.\n\nThere are additional helper functions which are provided as part of the FSR2 API. These helper functions perform tasks like the computation of sub-pixel jittering offsets, as well as the calculation of rendering resolutions based on dispatch resolutions and the default [scaling modes](#scaling-modes) provided by FSR2.\n\nFor more exhaustive documentation of the FSR2 API, you can refer to the API reference documentation provided.\n\n## Modular backend\nThe design of the FSR2 API means that the core implementation of the FSR2 algorithm is unaware upon which rendering API it sits. Instead, FSR2 calls functions provided to it through an interface, allowing different backends to be used with FSR2. This design also allows for applications integrating FSR2 to provide their own backend implementation, meaning that platforms which FSR2 does not currently support may be targeted by implementing a handful of functions. Moreover, applications which have their own rendering abstractions can also implement their own backend, taking control of all aspects of FSR2's underlying function, including memory management, resource creation, shader compilation, shader resource bindings, and the submission of FSR2 workloads to the graphics device.\n\n![alt text](docs/media/super-resolution-temporal/api-architecture.svg \"A diagram showing the high-level architecture of the FSR2 API.\")\n\nOut of the box, the FSR2 API will compile into multiple libraries following the separation already outlined between the core API and the backends. This means if you wish to use the backends provided with FSR2 you should link both the core FSR2 API lib as well the backend matching your requirements.\n\n> The public release of FSR2 comes with DirectX(R)12 and Vulkan(R) backends, but other backends are available upon request. Talk with your AMD Developer Technology representative for more information.\n\n## Memory management\nIf the FSR2 API is used with one of the supplied backends (e.g: DirectX(R)12 or Vulkan(R)) then all the resources required by FSR2 are created as committed resources directly using the graphics device provided by the host application. However, by overriding the create and destroy family of functions present in the backend interface it is possible for an application to more precisely control the memory management of FSR2.\n\nTo do this, you can either provide a full custom backend to FSR2 via the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure passed to [`ffxFsr2ContextCreate`](src/ffx-fsr2-api/ffx_fsr2.h#L228) function, or you can retrieve the backend for your desired API and override the resource creation and destruction functions to handle them yourself. To do this, simply overwrite the [`fpCreateResource`](src/ffx-fsr2-api/ffx_fsr2_interface.h#L379) and [`fpDestroyResource`](src/ffx-fsr2-api/ffx_fsr2_interface.h#L383) function pointers.\n\n``` CPP\n// Setup DX12 interface.\nconst size_t scratchBufferSize = ffxFsr2GetScratchMemorySizeDX12();\nvoid* scratchBuffer = malloc(scratchBufferSize);\nFfxErrorCode errorCode = ffxFsr2GetInterfaceDX12(&contextDescription.callbacks, m_pDevice->GetDevice(), scratchBuffer, scratchBufferSize);\nFFX_ASSERT(errorCode == FFX_OK);\n\n// Override the resource creation and destruction.\ncontextDescription.callbacks.createResource = myCreateResource;\ncontextDescription.callbacks.destroyResource = myDestroyResource;\n\n// Set up the context description.\ncontextDescription.device = ffxGetDeviceDX12(m_pDevice->GetDevice());\ncontextDescription.maxRenderSize.width = renderWidth;\ncontextDescription.maxRenderSize.height = renderHeight;\ncontextDescription.displaySize.width = displayWidth;\ncontextDescription.displaySize.height = displayHeight;\ncontextDescription.flags = FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE\n                         | FFX_FSR2_ENABLE_DEPTH_INVERTED\n                         | FFX_FSR2_ENABLE_AUTO_EXPOSURE;\n\n// Create the FSR2 context.\nerrorCode = ffxFsr2ContextCreate(&context, &contextDescription);\nFFX_ASSERT(errorCode == FFX_OK);\n```\n\nOne interesting advantage to an application taking control of the memory management required for FSR2 is that resource aliasing maybe performed, which can yield a memory saving. The table present in [Memory requirements](#memory-requirements) demonstrates the savings available through using this technique. In order to realise the savings shown in this table, an appropriate area of memory - the contents of which are not required to survive across a call to the FSR2 dispatches - should be found to share with the aliasable resources required for FSR2. Each [`FfxFsr2CreateResourceFunc`](src/ffx-fsr2-api/ffx_fsr2_interface.h#L379) call made by FSR2's core API through the FSR2 backend interface will contains a set of flags as part of the [`FfxCreateResourceDescription`](src/ffx-fsr2-api/ffx_types.h#L266) structure. If the [`FFX_RESOURCE_FLAGS_ALIASABLE`](src/ffx-fsr2-api/ffx_types.h#L117) is set in the [`flags`](src/ffx-fsr2-api/ffx_types.h#L224) field this indicates that the resource may be safely aliased with other resources in the rendering frame.\n\n## Temporal Antialiasing\nTemporal antialiasing (TAA) is a technique which uses the output of previous frames to construct a higher quality output from the current frame. As FSR2 has a similar goal - albeit with the additional goal of also increasing the resolution of the rendered image - there is no longer any need to include a separate TAA pass in your application.\n\n## Camera jitter\nFSR2 relies on the application to apply sub-pixel jittering while rendering - this is typically included in the projection matrix of the camera. To make the application of camera jitter simple, the FSR2 API provides a small set of utility function which computes the sub-pixel jitter offset for a particular frame within a sequence of separate jitter offsets.\n\n``` CPP\nint32_t ffxFsr2GetJitterPhaseCount(int32_t renderWidth, int32_t displayWidth);\nFfxErrorCode ffxFsr2GetJitterOffset(float* outX, float* outY, int32_t jitterPhase, int32_t sequenceLength);\n```\n\nInternally, these function implement a Halton[2,3] sequence [[Halton](#references)]. The goal of the Halton sequence is to provide spatially separated points, which cover the available space.\n\n![alt text](docs/media/super-resolution-temporal/jitter-space.svg \"A diagram showing how to map sub-pixel jitter offsets to projection offsets.\")\n\nIt is important to understand that the values returned from the [`ffxFsr2GetJitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L437) are in unit pixel space, and in order to composite this correctly into a projection matrix we must convert them into projection offsets. The diagram above shows a single pixel in unit pixel space, and in projection space. The code listing below shows how to correctly composite the sub-pixel jitter offset value into a projection matrix.\n\n``` CPP\nconst int32_t jitterPhaseCount = ffxFsr2GetJitterPhaseCount(renderWidth, displayWidth);\n\nfloat jitterX = 0;\nfloat jitterY = 0;\nffxFsr2GetJitterOffset(&jitterX, &jitterY, index, jitterPhaseCount);\n\n// Calculate the jittered projection matrix.\nconst float jitterX = 2.0f * jitterX / (float)renderWidth;\nconst float jitterY = -2.0f * jitterY / (float)renderHeight;\nconst Matrix4 jitterTranslationMatrix = translateMatrix(Matrix3::identity, Vector3(jitterX, jitterY, 0));\nconst Matrix4 jitteredProjectionMatrix = jitterTranslationMatrix * projectionMatrix;\n```\n\nJitter should be applied to *all* rendering. This includes opaque, alpha transparent, and raytraced objects. For rasterized objects, the sub-pixel jittering values calculated by the [`ffxFsr2GetJitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L437) function can be applied to the camera projection matrix which is ultimately used to perform transformations during vertex shading. For raytraced rendering, the sub-pixel jitter should be applied to the ray's origin - often the camera's position.\n\nWhether you elect to use the recommended [`ffxFsr2GetJitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L437) function or your own sequence generator, you must set the [`jitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L128) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to inform FSR2 of the jitter offset that has been applied in order to render each frame. Moreover, if not using the recommended [`ffxFsr2GetJitterOffset`](src/ffx-fsr2-api/ffx_fsr2.h#L437) function, care should be taken that your jitter sequence never generates a null vector; that is value of 0 in both the X and Y dimensions.\n\nThe table below shows the jitter sequence length for each of the default quality modes.\n\n | Quality mode      | Scaling factor          | Sequence length |\n |-------------------|-------------------------|-----------------|\n | Quality           | 1.5x (per dimension)    | 18              |\n | Balanced          | 1.7x (per dimension)    | 23              |\n | Performance       | 2.0x (per dimension)    | 32              |\n | Ultra performance | 3.0x (per dimension)    | 72              |\n | Custom            | [1..n]x (per dimension) | `ceil(8 * n^2)` |\n\n## Camera jump cuts\nMost applications with real-time rendering have a large degree of temporal consistency between any two consecutive frames. However, there are cases where a change to a camera's transformation might cause an abrupt change in what is rendered. In such cases, FSR2 is unlikely to be able to reuse any data it has accumulated from previous frames, and should clear this data such to exclude it from consideration in the compositing process. In order to indicate to FSR2 that a jump cut has occurred with the camera you should set the [`reset`](src/ffx-fsr2-api/ffx_fsr2.h#L135) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to `true` for the first frame of the discontinuous camera transformation.\n\nRendering performance may be slightly less than typical frame-to-frame operation when using the reset flag, as FSR2 will clear some additional internal resources.\n\n## Mipmap biasing\nApplying a negative mipmap biasing will typically generate an upscaled image with better texture detail. We recommend applying the following formula to your Mipmap bias:  \n\n``` CPP\nmipBias = log2(renderResolution/displayResolution) - 1.0;\n```\n\nIt is suggested that applications adjust the MIP bias for specific high-frequency texture content which is susceptible to showing temporal aliasing issues.\n\nThe following table illustrates the mipmap biasing factor which results from evaluating the above pseudocode for the scaling ratios matching the suggested quality modes that applications should expose to end users.\n \n | Quality mode      | Scaling factor        | Mipmap bias |\n |-------------------|-----------------------|-------------|\n | Quality           | 1.5X (per dimension)  | -1.58       |\n | Balanced          | 1.7X (per dimension)  | -1.76       |\n | Performance       | 2.0X (per dimension)  | -2.0        |\n | Ultra performance | 3.0X (per dimension)  | -2.58       |\n\n## Frame Time Delta Input\nThe FSR2 API requires [`frameTimeDelta`](src/ffx-fsr2-api/ffx_fsr2.h#L133) be provided by the application through the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure. This value is in __milliseconds__: if running at 60fps, the value passed should be around __16.6f__.\n\nThe value is used within the temporal component of the FSR 2 auto-exposure feature. This allows for tuning of the history accumulation for quality purposes.\n\n## HDR support\nHigh dynamic range images are supported in FSR2. To enable this, you should set the [`FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE`](src/ffx-fsr2-api/ffx_fsr2.h#L88) bit in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. Images should be provided to FSR2 in linear color space.\n\n> Support for additional color spaces might be provided in a future revision of FSR2.\n\n## Falling back to 32-bit floating point\nFSR2 was designed to take advantage of half precision (FP16) hardware acceleration to achieve the highest possible performance. However, to provide the maximum level of compatibility and flexibility for applications, FSR2 also includes the ability to compile the shaders using full precision (FP32) operations.\n\nIt is recommended to use the FP16 version of FSR2 on all hardware which supports it. You can query your graphics card's level of support for FP16 by querying the [`D3D12_FEATURE_DATA_SHADER_MIN_PRECISION_SUPPORT`](https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_shader_min_precision_support) capability in DirectX(R)12 - you should check that the `D3D[11/12]_SHADER_MIN_PRECISION_16_BIT` is set, and if it is not, fallback to the FP32 version of FSR2. For Vulkan, if [`VkPhysicalDeviceFloat16Int8FeaturesKHR::shaderFloat16`](https://khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkPhysicalDeviceShaderFloat16Int8FeaturesKHR.html) is not set, then you should fallback to the FP32 version of FSR2. Similarly, if [`VkPhysicalDevice16BitStorageFeatures::storageBuffer16BitAccess`](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkPhysicalDevice16BitStorageFeatures.html) is not set, you should also fallback to the FP32 version of FSR2.\n\nTo enable the FP32 path in the FSR2 shader source code, you should define `FFX_HALF` to be `1`. In order to share the majority of the algorithm's source code between both FP16 and FP32 (ensuring a high level of code sharing to support ongoing maintenance), you will notice that the FSR2 shader source code uses a set of type macros which facilitate easy switching between 16-bit and 32-bit base types in the shader source.\n\n| FidelityFX type | FP32        | FP16            |\n|-----------------|-------------|-----------------|\n| `FFX_MIN16_F`   | `float`     | `min16float`    |\n| `FFX_MIN16_F2`  | `float2`    | `min16float2`   |\n| `FFX_MIN16_F3`  | `float3`    | `min16float3`   |\n| `FFX_MIN16_F4`  | `float4`    | `min16float4`   |\n\nThe table above enumerates the mappings between the abstract FidelityFX SDK types, and the underlaying intrinsic type which will be substituted depending on the configuration of the shader source during compilation.\n\n## 64-wide wavefronts\nModern GPUs execute collections of threads - called wavefronts - together in a SIMT fashion. The precise number of threads which constitute a single wavefront is a hardware-specific quantity. Some hardware, such as AMD's GCN and RDNA-based GPUs support collecting 64 threads together into a single wavefront. Depending on the precise characteristics of an algorithm's execution, it may be more or less advantageous to prefer a specific wavefront width. With the introduction of Shader Model 6.6, Microsoft added the ability to specific the width of a wavefront via HLSL. For hardware, such as RDNA which supports both 32 and 64 wide wavefront widths, this is a very useful tool for optimization purposes, as it provides a clean and portable way to ask the driver software stack to execute a wavefront with a specific width.\n\nFor DirectX(R)12 based applications which are running on RDNA and RDNA2-based GPUs and using the Microsoft Agility SDK, the FSR2 host API will select a 64-wide wavefront width.\n\n## Debug Checker\n\nThe context description structure can be provided with a callback function for passing textual warnings from the FSR 2 runtime to the underlying application. The `fpMessage` member of the description is of type `FfxFsr2Message` which is a function pointer for passing string messages of various types. Assigning this variable to a suitable function, and passing the [`FFX_FSR2_ENABLE_DEBUG_CHECKING`](src/ffx-fsr2-api/ffx_fsr2.h#L96) flag within the flags member of [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) will enable the feature. It is recommended this is enabled only in debug development builds.\n\nAn example of the kind of output that can occur when the checker observes possible issues is below:\n\n```\nFSR2_API_DEBUG_WARNING: FFX_FSR2_ENABLE_DEPTH_INFINITE and FFX_FSR2_ENABLE_DEPTH_INVERTED present, cameraFar value is very low which may result in depth separation artefacting\nFSR2_API_DEBUG_WARNING: frameTimeDelta is less than 1.0f - this value should be milliseconds (~16.6f for 60fps)\n```\n\n# The technique\n\n## Algorithm structure\nThe FSR2 algorithm is implemented in a series of stages, which are as follows:\n\n1. Compute luminance pyramid\n2. Reconstruct & dilate\n3. Depth clip\n4. Create locks\n5. Reproject & accumulate\n6. Robust Contrast Adaptive Sharpening (RCAS)\n\nEach pass stage of the algorithm is laid out in the sections following this one, but the data flow for the complete FSR2 algorithm is shown in the diagram below.\n\n![alt text](docs/media/super-resolution-temporal/algorithm-structure.svg \"A diagram showing all passes in the FSR2 algorithm.\")\n\n## Compute luminance pyramid\n\nThe compute luminance pyramid stage has two responsibilities:\n\n1. To produce a lower resolution version of the input color's luminance. This is used by shading change detection in the accumulation pass.\n2. To produce a 1x1 exposure texture which is optionally used to apply tonemapping, and the [Reproject & Accumulate](#project-and-accumulate) stage for reversing local tonemapping ahead of producing an output from FSR2.\n\n\n### Resource inputs\nThe following table contains all resources consumed by the [Compute luminance pyramid](#compute-luminance-pyramid) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user.\n\n| Name            | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                        |  \n| ----------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| Color buffer    | Current frame   | Render       | `APPLICATION SPECIFIED` | Texture   | The render resolution color buffer for the current frame provided by the application. If the contents of the color buffer are in high dynamic range (HDR), then the [`FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE`](src/ffx-fsr2-api/ffx_fsr2.h#L88) flag should be set in  the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. |\n\n### Resource outputs\nThe following table contains all resources produced or modified by the [Compute luminance pyramid](#compute-luminance-pyramid) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user.\n\n| Name                        | Temporal layer  | Resolution       |  Format                 | Type      | Notes                                        |  \n| ----------------------------|-----------------|------------------|-------------------------|-----------|----------------------------------------------|\n| Exposure                    | Current frame   | 1x1              | `R32_FLOAT`             | Texture   | A 1x1 texture containing the exposure value computed for the current frame. This resource is optional, and may be omitted if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179).  |\n| Current luminance           | Current frame   | `Render * 0.5` + MipChain  | `R16_FLOAT`             | Texture   | A texture at 50% of render resolution texture which contains the luminance of the current frame. A full mip chain is allocated. |\n\n### Description\nThe [Compute luminance pyramid](#compute-luminance-pyramid) stage is implemented using FidelityFX [Single Pass Downsampler](https://github.com/GPUOpen-Effects/FidelityFX-SPD), an optimized technique for producing mipmap chains using a single compute shader dispatch. Instead of the conventional (full) pyramidal approach, SPD provides a mechanism to produce a specific set of mipmap levels for an arbitrary input texture, as well as performing arbitrary calculations on that data as we store it to the target location in memory. In FSR2, we are interested in producing in upto two intermediate resources depending on the configuration of the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L166). The first resource is a low-resolution representation of the current luminance, this is used later in FSR2 to attempt to detect shading changes. The second is the exposure value, and while it is always computed, it is only used by subsequent stages if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure upon context creation. The exposure value - either from the application, or the [Compute luminance pyramid](#compute-luminance-pyramid) stage - is used in the [Adjust input color](#adjust-input-color) stage of FSR2, as well as by the [Reproject & Accumulate](#project-and-accumulate) stage.\n\n![alt text](docs/media/super-resolution-temporal/auto-exposure.svg \"A diagram showing the mipmap levels written by auto-exposure.\")\n\nAs used by FSR2, SPD is configured to write only to the 2nd (half resolution) and last (1x1) mipmap level. Moreover, different calculations are applied at each of these levels to calculate the quantities required by subsequent stages of the FSR2 algorithm. This means the rest of the mipmap chain is not required to be backed by GPU local memory (or indeed any type of memory).\n\nThe 2nd mipmap level contains current luminance, the value of which is computed during the downsampling of the color buffer using the following HLSL:\n\n``` HLSL\nfloat3 rgb = LoadInputColor(tex);\nfloat3 rgb2y = float3(0.2126, 0.7152, 0.0722);\nfloat logLuma = log(max(FSR2_EPSILON, dot(rgb2y, rgb)));\n```\n\nThe last mipmap level is computed using the following HLSL:\n\n``` HLSL\nfloat ComputeAutoExposureFromAverageLog(float averageLogLuminance)\n{\n\tconst float averageLuminance = exp(averageLogLuminance);\n\tconst float S = 100.0f; // ISO arithmetic speed\n\tconst float K = 12.5f;\n\tconst float exposureIso100 = log2((averageLuminance * S) / K);\n\tconst float q = 0.65f;\n\tconst float luminanceMax = (78.0f / (q * S)) * pow(2.0f, exposureIso100);\n\treturn 1 / luminanceMax;\n}\n```\n\n## Reconstruct and dilate\nThe reconstruct & dilate stage consumes the applications depth buffer and motion vectors, and produces a reconstructed and dilated depth buffer for the previous frame, together with a dilated set of motion vectors in UV space. The stage runs at render resolution.\n \n![alt text](docs/media/super-resolution-temporal/vector-dilation.svg \"A diagram showing how a motion vector is dilated based on the depth value.\")\n\n### Resource inputs\nThe following table contains all of the resources which are required by the reconstruct & dilate stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                        |  Temporal layer | Resolution |  Format                            | Type      | Notes                                          |  \n| ----------------------------|-----------------|------------|------------------------------------|-----------|------------------------------------------------|\n| Color buffer                | Current frame   | Render       | `APPLICATION SPECIFIED`   | Texture   | The render resolution color buffer for the current frame provided by the application. If the contents of the color buffer are in high dynamic range (HDR), then the [`FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE`](src/ffx-fsr2-api/ffx_fsr2.h#L88) flag should be set in  the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. |\n| Exposure                    | Current frame   | 1x1          | ``R32_FLOAT``             | Texture   | A 1x1 texture containing the exposure value computed for the current frame. This resource can be supplied by the application, or computed by the [Compute luminance pyramid](#compute-luminance-pyramid) stage of FSR2 if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure.  |\n| Depth buffer                | Current frame   | Render     | `APPLICATION SPECIFIED (1x FLOAT)` | Texture   | The render resolution depth buffer for the current frame provided by the application. The data should be provided as a single floating point value, the precision of which is under the application's control. The configuration of the depth should be communicated to FSR2 via the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179). You should set the [`FFX_FSR2_ENABLE_DEPTH_INVERTED`](src/ffx-fsr2-api/ffx_fsr2.h#L91) flag if your depth buffer is inverted (that is [1..0] range), and you should set the  flag if your depth buffer has as infinite far plane. If the application provides the depth buffer in `D32S8` format, then FSR2 will ignore the stencil component of the buffer, and create an `R32_FLOAT` resource to address the depth buffer. On GCN and RDNA hardware, depth buffers are stored separately from stencil buffers. |\n| Motion vectors              | Current fraame  | Render or presentation       | `APPLICATION SPECIFIED (2x FLOAT)` | Texture   | The 2D motion vectors for the current frame provided by the application in [*(<-width, -height>*..*<width, height>*] range. If your application renders motion vectors with a different range, you may use the [`motionVectorScale`](src/ffx-fsr2-api/ffx_fsr2.h#L129) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to adjust them to match the expected range for FSR2. Internally, FSR2 uses 16bit quantities to represent motion vectors in many cases, which means that while motion vectors with greater precision can be provided, FSR2 will not benefit from the increased precision. The resolution of the motion vector buffer should be equal to the render resolution, unless the [`FFX_FSR2_ENABLE_DISPLAY_RESOLUTION_MOTION_VECTORS`](src/ffx-fsr2-api/ffx_fsr2.h#L89) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179), in which case it should be equal to the presentation resolution. |\n\n### Resource outputs\nThe following table contains all of the resources which are produced by the reconstruct & dilate stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                                | Temporal layer  | Resolution |  Format                | Type      | Notes                                  |  \n| ------------------------------------|-----------------|------------|------------------------|-----------|------------------------------------------------|\n| Est.Previous depth buffer           | Current frame   | Render     | `R32_UNORM`            | Texture   | A texture containing the reconstructed previous frame depth values. This surface should first be cleared, see the [Adjust input color](#adjust-input-color) stage for details. Please note: When viewing this texture in a capture tool (such as [RenderDoc](https://renderdoc.org)) it may not display correctly. This is because the format of this texture is ``R32_UNORM`` and contains IEEE754 floating point values, which have been written after performing a bitcast using the ``asuint`` intrinsic function. See the note in [Reproject & accumulate](#reproject-accumulate) for more details on the specifics of how this works. |\n| Dilated depth                       | Current frame   | Render     | `R16_UINT`             | Texture    | A texture containing dilated depth values computed from the application's depth buffer. |\n| Dilated motion vectors              | Current frame   | Render     | `R16G16_FLOAT`         | Texture    | A texture containing dilated 2D motion vectors computed from the application's 2D motion vector buffer. The red and green channel contains the two-dimensional motion vectors in NDC space. |\n| Previous depth buffer               | Current frame   | Render       | `R32_UNORM`            | Texture   | A texture containing a reconstructed and dilated depth values. This surface is cleared by the [Adjust input color](#adjust-input-color) stage. Please note: When viewing this texture in a capture tool (such as [RenderDoc](https://renderdoc.org)) it may not display correctly. This is because the format of this texture is ``R32_UNORM`` and contains IEEE754 floating point values, which have been written after performing a bitcast using the [`asuint`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-asuint) intrinsic function. See the note in [Adjust input color](#adjust-input-color) for more details on the specifics of how this works. |\n| Lock input luma                     | Current frame   | Render       | `R16_FLOAT`   | Texture   | A texture containing luma data to be consumed by the lock stage. |\n\n### Description\nThe first step of the [Reconstruct & dilate](#reconstruct-and-dilate) stage is to compute the dilated depth values and motion vectors from the application's depth values and motion vectors for the current frame. Dilated depth values and motion vectors emphasise the edges of geometry which has been rendered into the depth buffer. This is because the edges of geometry will often introduce discontinuities into a contiguous series of depth values, meaning that as depth values and motion vectors are dilated, they will naturally follow the contours of the geometric edges present in the depth buffer. In order to compute the dilated depth values and motion vectors, FSR2 looks at the depth values for a 3x3 neighbourhood for each pixel and then selects the depth values and motion vectors in that neighbourhood where the depth value is nearest to the camera. In the diagram below, you can see how the central pixel of the 3x3 kernel is updated with the depth value and motion vectors from the pixel with the largest depth value - the pixel on the central, right hand side.\n\nAs this stage is the first time that motion vectors are consumed by FSR2, this is where motion vector scaling is applied if using the FSR2 host API. Motion vector scaling factors provided via the [`motionVectorScale`](src/ffx-fsr2-api/ffx_fsr2.h#L129) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure and allows you to transform non-screenspace motion vectors into screenspace motion vectors which FSR2 expects.\n\n``` CPP\n// An example of how to manipulate motion vector scaling factors using the FSR2 host API. \nFfxFsr2DispatchParameters dispatchParams = { 0 };\ndispatchParams.motionVectorScale.x = renderWidth;\ndispatchParams.motionVectorScale.y = renderHeight;\n```\n\nWith the dilated motion vectors, we can now move to the second part of the [Reconstruct & dilate](#reconstruct-and-dilate) stage, which is to estimate the position of each pixel in the current frame's depth buffer in the previous frame. This is done by applying the dilated motion vector computed for a pixel, to its depth buffer value. As it is possible for many pixels to reproject into the same pixel in the previous depth buffer, atomic operations are used in order to resolve the value of the nearest depth value for each pixel. This is done using the [`InterlockedMax`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/interlockedmax) or [`InterlockedMin`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/interlockedmin) operation (the choice depending on if the application's depth buffer is inverted or not). The use of cumulative operations to resolve the contents of the previous depth buffer implies that the reconstructed depth buffer resource must always be cleared to a known value, which is performed in the [Reproject & accumulate](#reproject-accumulate) stage. This is performed on frame N for frame N + 1.\n\n![alt text](docs/media/super-resolution-temporal/reconstruct-previous-depth.svg \"A diagram showing a dilated motion vector being applied to a depth value.\")\n\nWhen using the FSR2 API, the application's depth buffer and the application's velocity buffer must be specified as separate resources as per the [Resource inputs](#resource-inputs) table above. However, if you are undertaking a bespoke integration into your application, this constraint may be relaxed. Take care that the performance characteristics of this pass do not change if moving to a format for the motion vector texture which is more sparse, e.g.: as part of a packed g-buffer in a deferred renderer.\n\n## Depth clip \nThe goal of the [Depth clip](#depth-clip) stage is to produce a mask which indicates disoccluded areas of the current frame. \n\nThis stage runs at render resolution.\n\n### Resource inputs\nThe following table contains all the resources which are consumed by the [Depth clip](#depth-clip) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                                | Temporal layer  | Resolution |  Format                | Type      | Notes                                  |  \n| ------------------------------------|-----------------|------------|------------------------|-----------|------------------------------------------------|\n| Est.Previous depth buffer               | Current frame   | Render     | `R32_UNORM`            | Texture   | A texture containing the reconstructed previous frame depth values. This surface should first be cleared, see the [Reproject & accumulate](#reproject-accumulate) stage for details. Please note: When viewing this texture in a capture tool (such as [RenderDoc](https://renderdoc.org)) it may not display correctly. This is because the format of this texture is ``R32_UINT`` and contains IEEE754 floating point values, which have been written after performing a bitcast using the ``asuint`` intrinsic function. See the note in [Reproject & accumulate](#reproject-accumulate) for more details on the specifics of how this works. |\n| Dilated depth                       | Current frame   | Render     | `R32_FLOAT`             | Texture    | A texture containing dilated depth values computed from the application's depth buffer. |\n| Dilated motion vectors              | Current  & Previous frame  | Render     | `R16G16_FLOAT`         | Texture    | A texture containing dilated 2D motion vectors computed from the application's 2D motion vector buffer. The red and green channel contains the two-dimensional motion vectors in NDC space, and the alpha channel contains the depth value used by the [Depth clip](#depth-clip) stage. |\n| Reactive masks                       | Current frame   | Render       | `R8_UNORM`             | Texture   | As some areas of a rendered image do not leave a footprint in the depth buffer or include motion vectors, FSR2 provides support for a reactive mask texture which can be used to indicate to FSR2 where such areas are. Good examples of these are particles, or alpha-blended objects which do not write depth or motion vectors. If this resource is not set, then FSR2's shading change detection logic will handle these cases as best it can, but for optimal results, this resource should be set. For more information on the reactive mask please refer to the [Reactive mask](#reactive-mask) section.  |\n| Color buffer                | Current frame   | Render       | `APPLICATION SPECIFIED`   | Texture   | The render resolution color buffer for the current frame provided by the application. If the contents of the color buffer are in high dynamic range (HDR), then the [`FFX_FSR2_ENABLE_HIGH_DYNAMIC_RANGE`](src/ffx-fsr2-api/ffx_fsr2.h#L88) flag should be set in  the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure. |\n| Exposure                    | Current frame   | 1x1          | ``R32_FLOAT``             | Texture   | A 1x1 texture containing the exposure value computed for the current frame. This resource can be supplied by the application, or computed by the [Compute luminance pyramid](#compute-luminance-pyramid) stage of FSR2 if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L93) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure.  |\n| Depth buffer                | Current frame   | Render     | `APPLICATION SPECIFIED (1x FLOAT)` | Texture   | The render resolution depth buffer for the current frame provided by the application. The data should be provided as a single floating point value, the precision of which is under the application's control. The configuration of the depth should be communicated to FSR2 via the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179). You should set the [`FFX_FSR2_ENABLE_DEPTH_INVERTED`](src/ffx-fsr2-api/ffx_fsr2.h#L91) flag if your depth buffer is inverted (that is [1..0] range), and you should set the  flag if your depth buffer has as infinite far plane. If the application provides the depth buffer in `D32S8` format, then FSR2 will ignore the stencil component of the buffer, and create an `R32_FLOAT` resource to address the depth buffer. On GCN and RDNA hardware, depth buffers are stored separately from stencil buffers. |\n| Motion vectors              | Current fraame  | Render or presentation       | `APPLICATION SPECIFIED (2x FLOAT)` | Texture   | The 2D motion vectors for the current frame provided by the application in [*(<-width, -height>*..*<width, height>*] range. If your application renders motion vectors with a different range, you may use the [`motionVectorScale`](src/ffx-fsr2-api/ffx_fsr2.h#L129) field of the [`FfxFsr2DispatchDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L118) structure to adjust them to match the expected range for FSR2. Internally, FSR2 uses 16-bit quantities to represent motion vectors in many cases, which means that while motion vectors with greater precision can be provided, FSR2 will not benefit from the increased precision. The resolution of the motion vector buffer should be equal to the render resolution, unless the [`FFX_FSR2_ENABLE_DISPLAY_RESOLUTION_MOTION_VECTORS`](src/ffx-fsr2-api/ffx_fsr2.h#L89) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179), in which case it should be equal to the presentation resolution. |\n\n### Resource outputs\nThe following table contains all the resources which are produced by the [Depth clip](#depth-clip) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                                | Temporal layer  | Resolution |  Format                | Type      | Notes                                  |  \n| ------------------------------------|-----------------|------------|------------------------|-----------|----------------------------------------|\n| Adjusted color buffer                | Current frame   | Render       | `R16G16B16A16_FLOAT`    | Texture   | A texture containing the adjusted version of the application's color buffer. The tonemapping operator may not be the same as any tonemapping operator included in the application, and is instead a local, reversible operator used throughout FSR2. This buffer is stored in YCoCg format. Alpha channel contains disocclusion mask.|\n| Dilated reactive mask                       | Current frame   | Render       | `R8G8_UNORM`             | Texture   | Dilated reactive masks.  |\n### Description\nTo generate the disocclusion mask, the depth value must be computed for each pixel from the previous camera's position and the new camera's position.  In the diagram below, you can see a camera moving from an initial position (labelled P0) to a new position (labelled P1). As it does so, the shaded area behind the sphere becomes disoccluded - that is it becomes visible from the camera at P1 and was previously occluded from the point of view of P0.\n\n![alt text](docs/media/super-resolution-temporal/disocclusion.svg \"A diagram showing a disoccluded area as a camera moves from position 0 to position 1.\")\n\nWith both values depth values, we can compare the delta between them against the Akeley separation value [[Akeley-06](#references)]. Intuitively, the Akeley separation constant provides a minimum distance between two objects represented in a floating point depth buffer which allow you to say - with a high degree of certainty - that the objects were originally distinct from one another. In the diagram below you can see that the mid-grey and dark-grey objects have a delta which is larger than the `kSep` value which has been computed for the application's depth buffer configuration. However, the distance from the light-gray object to the mid-grey object does not exceed the computed `kSep` value, and therefore we are unable to conclude if this object is distinct.\n\n![alt text](docs/media/super-resolution-temporal/k-sep.svg \"A diagram showing the concept behind the constant of separation.\")\n\nThe value stored in the disocclusion mask is in the range [0..1], where 1 maps to a value greater than or equal to the Akeley separation value.\n\n## Create locks\nThis stage is responsible for creating new locks on pixels which are consumed in the [Reproject & Accumulate](#reproject-accumulate) stage. This stage runs at render resolution.\n\n### Resource inputs\nThe following table contains all resources consumed by the [Create locks](#create-locks) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user.\n\n| Name                        | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                        |  \n| ----------------------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| Lock input luma                     | Current frame   | Render       | `R16_FLOAT`   | Texture   | A texture containing luminance data to be consumed by the lock stage. |\n\n### Resource outputs\nThe following table contains all resources produced or modified by the [Create locks](#create-locks) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user.\n\n| Name                        | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                        |  \n| ----------------------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| New lock mask               | Current frame   | Presentation | `R8_UNORM`          | Texture   | A mask which indicates whether or not to perform color rectification on a pixel, can be thought of as a lock on the pixel to stop rectification from removing the detail. Please note: This texture is part of an array of two textures along with the Lock status texture which is used as an input to this stage. The selection of which texture in the array is used for input and output is swapped each frame. The red channel contains the time remaining on the pixel lock, and the Y channel contains the luminance of the pixel at the time when the lock was created. The [Create locks](#create-locks) stage updates only a subset of this resource. |\n| Est.Previous depth buffer   | Next frame   | Render     | `R32_UNORM`            | Texture   | This is only written here to clear it. |\n\n### Description\nIntuitively, a pixel lock is a mechanism to stop color rectification from being applied to a pixel. The net effect of this locking is that more of the previous frame's color data is used when computing the final, super resolution pixel color in the [Reproject & accumulate](#reproject-accumulate) stage. The lock status texture contains two values which together compose a pixel lock. The red channel of the lock status texture contains the remaining lifetime of a pixel lock. This value is decremented by the initial lock length divided by the total length of the jitter sequence. When a lock reaches zero, it is considered to be expired. The green channel of the lock status texture contains the luminance of the pixel at the time the lock was created, but it is only populated during the reprojection stage of [Reproject & accumulate](#reproject-accumulate) stage. The luminance value is ultimately used in the [Reproject & Accumulate](#reproject-accumulate) stage as part of the shading change detection, this allows FSR2 to unlock a pixel if there is discontinuous change to the pixel's appearance (e.g.: an abrupt change to the shading of the pixel).\n\nWhen creating locks, the 3x3 neighbourhood of luminance values is compared against a threshold. The result of this comparison determines if a new lock should be created. The use of the neighbourhood allows us to detect thin features in the input image which should be locked in order to preserve details in the final super resolution image; such as wires, or chain linked fences.\n\nAdditionally, this stage also has the responsibility for clearing the reprojected depth buffer to a known value, ready for the [Reconstruct & dilate](#reconstruct-and-dilate) stage on the next frame of the application. The buffer must be cleared, as [Reconstruct & dilate](#reconstruct-and-dilate) will populate it using atomic operations. Depending on the configuration of the depth buffer, an appropriate clearing value is selected.\n\nThe format of the previous depth buffer is `R32_UINT` which allows the use of [`InterlockedMax`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/interlockedmax) and [`InterlockedMin`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/interlockedmin) operations to be performed from the [Reconstruct & dilate](#reconstruct-and-dilate) stage of FSR2. This is done with the resulting integer values returned by converting depth values using the [`asint`](https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-asint) functions. This works because depth values are always greater than 0, meaning that the monotonicity of IEEE754 floating point values when interpreted as integers is guaranteed.\n\n\n## Reproject & accumulate\nThis stage undertakes the following steps:\n\n1. The current frame's color buffer is upsampled using Lanczos filtering.\n2. The previous frame's output color and lock status buffers are reprojected, as if they were viewed from the current camera's perspective. \n3. Various cleanup steps to the historical color data.\n4. Luma instability is computed.\n5. The historical color data, and the upscaled color data from the current frame are accumulated.\n\nThis stage runs at presentation resolution.\n\n### Resource inputs\nThe following table contain all resources required by the [Reproject & accumulate](#reproject-accumulate) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. If display resolution motion vectors are provided, the reprojection step will use the full precision of the vectors, as we read the resource directly.\n\n| Name                                | Temporal layer  | Resolution   |  Format                | Type      | Notes                                  |  \n| ------------------------------------|-----------------|--------------|------------------------|-----------|----------------------------------------|\n| Exposure                    | Current frame   | 1x1              | `R32_FLOAT`             | Texture   | A 1x1 texture containing the exposure value computed for the current frame. This resource is optional, and may be omitted if the [`FFX_FSR2_ENABLE_AUTO_EXPOSURE`](src/ffx-fsr2-api/ffx_fsr2.h#L92) flag is set in the [`flags`](src/ffx-fsr2-api/ffx_fsr2.h#L105) field of the [`FfxFsr2ContextDescription`](src/ffx-fsr2-api/ffx_fsr2.h#L103) structure when creating the [`FfxFsr2Context`](src/ffx-fsr2-api/ffx_fsr2.h#L179).  |\n| Dilated motion vectors              | Current frame   | Render       | `R16G16_FLOAT`         | Texture   | A texture containing dilated motion vectors computed from the application's velocity buffer. The red and green channel contains the two-dimensional motion vectors in UV space. |\n| Dilated reactive mask                       | Current frame   | Render       | `R8G8_UNORM`             | Texture   | Dilated reactive masks.  |\n| Upscaled buffer               | Previous frame  | Presentation | ``R16G16B16A16_FLOAT``  | Texture   | The output buffer produced by the FSR2 algorithm running in the previous frame. Please note: This buffer is used internally by FSR2, and is distinct from the presentation buffer which is derived from the output buffer, and has [RCAS](#robust-contrast-adpative-sharpening-rcas) applied. Please note: This texture is part of an array of two textures along with the Output buffer texture which is produced by the [Reproject & accumulate](#reproject-accumulate) stage. The selection of which texture in the array is used for input and output is swapped each frame. |\n| Current luminance                     | Current frame   | `Render * 0.5`   | `R16_FLOAT`             | Texture   | A texture at 50% of render resolution texture which contains the luminance of the current frame. |\n| Luminance history                     | Many frames     | Render       | `R8G8B8A8_UNORM`        | Texture   | A texture containing three frames of luminance history, as well as a stability factor encoded in the alpha channel. |\n| Adjusted color buffer                 | Current frame   | Render       | `R16G16B16A16_FLOAT`    | Texture   | A texture containing the adjusted version of the application's color buffer. The tonemapping operator may not be the same as any tonemapping operator included in the application, and is instead a local, reversible operator used throughout FSR2. This buffer is stored in YCoCg format. Alpha channel contains disocclusion mask.|\n| Lock status                         | Previous frame  | Presentation | `R16G16_FLOAT`         | Texture   | A mask which indicates not to perform color clipping on a pixel, can be thought of as a lock on the pixel to stop clipping removing the detail.  For a more detailed description of the pixel locking mechanism please refer to the [Create locks](#create-locks) stage. Please note: This texture is part of an array of two textures along with the Lock status texture which is used as an output from this stage. The selection of which texture in the array is used for input and output is swapped each frame. |\n| New lock mask               | Current frame   | Presentation | `R8_UNORM`          | Texture   | A mask which indicates whether or not to perform color rectification on a pixel, can be thought of as a lock on the pixel to stop rectification from removing the detail. Please note: This texture is part of an array of two textures along with the Lock status texture which is used as an input to this stage. The selection of which texture in the array is used for input and output is swapped each frame. The red channel contains the time remaining on the pixel lock, and the Y channel contains the luminance of the pixel at the time when the lock was created. The [Create locks](#create-locks) stage updates only a subset of this resource. |\n\n\n### Resource outputs\nThis table contains the resources produced by the [Reproject & accumulate](#reproject-accumulate) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                        | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                        |  \n| ----------------------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| Upscaled buffer               | Current frame   | Presentation | `R16G16B16A16_FLOAT`    | Texture   | The output buffer produced by the [Reproject & accumulate](#reproject-accumulate) stage for the current frame. Please note: This buffer is used internally by FSR2, and is distinct from the presentation buffer which is produced as an output from this stage after applying RCAS. Please note: This texture is part of an array of two textures along with the Output buffer texture which is consumed by the [Reproject & accumulate](#reproject-accumulate) stage. The selection of which texture in the array is used for input and output is swapped each frame. |\n| Reprojected locks           | Current frame   | Render       | `R16G16_FLOAT`          | Texture   | The reprojected lock status texture. |\n| Luminance history                     | Many frames     | Render       | `R8G8B8A8_UNORM`        | Texture   | A texture containing three frames of luminance history, as well as a stability factor encoded in the alpha channel. |\n| New lock mask               | Next frame   | Presentation | `R8_UNORM`          | Texture   | This is cleared for next frame. |\n\n### Description\nThe reproject & accumulate stage of FSR2 is the most complicated and expensive stage in the algorithm. It brings together the results from many of the previous algorithmic steps and accumulates the reprojected color data from the previous frame together with the upsampled color data from the current frame. Please note the description in this documentation is designed to give you an intuition for the steps involved in this stage and does not necessarily match the implementation precisely.\n\nThe first step of the [Reproject & accumulate](#reproject-accumulate) stage is to assess each pixel for changes in its shading. If we are in a locked area, the luminance at the time the lock was created is compared to FSR2's shading change threshold. In a non-locked area, both the current frame and historical luminance values are used to make this determination. Shading change determination is a key part of FSR2's [Reproject & accumulate](#reproject-accumulate) stage, and feeds into many of the other parts of this stage.\n\n![alt text](docs/media/super-resolution-temporal/upsample-with-lanczos.svg \"A diagram showing upsampling of the current frame's input using Lanczos.\")\n\nNext we must upsample the adjusted color. To perform upsampling, the adjusted color's pixel position serves as the center of a 5x5 Lanczos resampling kernel [[Lanczos]](#references). In the diagram above, you can see that the Lanczos functions are centered around the display resolution sample `S`. The point in each pixel - labelled `P` - denotes the render resolution jittered sample position for which we calculate the Lanczos weights. Looking above and to the right of the 5x5 pixel neighbourhood, you can see the `Lanczos(x, 2)` resampling kernel being applied to the render resolution samples in the 5x5 grid of pixels surrounding the pixel position. It is worth noting that while conceptually the neighbourhood is 5x5, in the implementation only a 4x4 is actually sampled, due to the zero weighted contributions of those pixels on the periphery of the neighbourhood. The implementation of the Lanczos kernel may vary by GPU product. On RDNA2-based products, we use a look-up-table (LUT) to encode the `sinc(x)` function. This helps to produce a more harmonious balance between ALU and memory in the [Reproject & accumulate](#reproject-accumulate) stage. As the upsample step has access to the 5x5 neighbourhood of pixels, it makes sense from an efficiency point of view to also calculate the YCoCg bounding box - which is used during color rectification - at this point. The diagram below shows a 2D YCo bounding box being constructed from a 3x3 neighbourhood around the current pixel, in reality the bounding box also has a third dimension for Cg.\n\n![alt text](docs/media/super-resolution-temporal/calculate-bounding-box.svg \"A diagram showing how a YCoCg bounding box is computed from the current frame's adjust color samples.\")\n\nReprojection is another key part of the [Reproject & accumulate](#reproject-accumulate) stage. To perform reprojection, the dilated motion vectors produced by the [Reconstruct & dilate](#reconstruct-and-dilate) stage are sampled and then applied to the output buffer from the previous frame's execution of FSR2. The left of the diagram below shows two-dimensional motion vector **M** being applied to the current pixel position. On the right, you can see the `Lanczos(x, 2)` resampling kernel being applied to the 5x5 grid of pixels surrounding the translated pixel position. As with the upsampling step, the implementation of the Lanczos kernel may vary by GPU product. The result of the reprojection is a presentation resolution image which contains all the data from the previous frame that could be mapped into the current frame. However, it is not just the previous frame's output color that is reprojected. As FSR2 relies on a mechanism whereby each pixel may be locked to enhance its temporal stability, the locks must also be reprojected from the previous frame into the current frame. This is done in much the same way as the reprojection of the color data, but also combines the results of the shading change detection step we performed on the various luminance values, both current and historical. \n\n![alt text](docs/media/super-resolution-temporal/reproject-mvs.svg \"A diagram showing the 5x5 Lanczos sampling kernel applied to a pixel position determined by translating the current pixel position by the motion vectors.\")\n\nIt is now time to update our locks. The first task for update locks is to look for locks which were created during this frame's [Create locks](#create-locks) stage that are not reprojected, and instead have the luminance value of the current frame written to the green channel of the reprojected locks texture. All that remains then is to discern which locks are trustworthy for the current frame and pass those on to the color rectification step. The truthworthiness determination is done by comparing the luminance values within a neighbourhood of pixels in the current luminance texture. If the luminance separation between these values is large, then we should not trust the lock.\n\nWith our lock updates applied and their trustworthiness determined, we can move on to color rectification which is the next crucial step of FSR2's [Reproject & accumulate](#reproject-accumulate) stage. During this stage, a final color is determined from the pixel's historical data which will then be blended with the current frame's upsampled color in order to form the final accumulated super-resolution color. The determination of the final historical color and its contribution is chiefly controlled by two things:\n\n1. Reducing the influence of the historical samples for areas which are disoccluded. This is undertaken by modulating the color value by the disocclusion mask.\n2. Reducing the influence of the historical samples (marked S<sub>h</sub> in the diagram below) are far from the current frame color's bounding box (computed during the upsampling phase of the [Reproject & accumulate](#reproject-accumulate) stage).\n\n![alt text](docs/media/super-resolution-temporal/clamp-to-box.svg \"A diagram showing a historical color sample being clamped to the YCoCg bounding box for the current frame.\")\n\nThe final step of the [Reproject & accumulate](#reproject-accumulate) stage is to accumulate the current frame's upsampled color with the rectified historical color data. By default, FSR2 will typically blend the current frame with a relatively low linear interpolation factor - that is relatively little of the current frame will be included in the final output. However, this can be altered based on the contents of the application provided reactivity mask. See the [reactive mask](#reactive-mask) section for further details.\n\n\n## Robust Contrast Adaptive Sharpening (RCAS)\nRobust Contrast Adaptive Sharpening (RCAS) was originally introduced in FidelityFX Super Resolution 1.0 as an additional sharpening pass to help generate additional clarity and sharpeness in the final upscaled image. RCAS is a derivative of the popular Contrast Adaptive Sharpening (CAS) algorithm, but with some key differences which make it more suitable for upscaling. Whereas CAS uses a simplified mechanism to convert local contrast into a variable amount of sharpness, conversely RCAS uses a more exact mechanism, solving for the maximum local sharpness possible before clipping. Additionally, RCAS also has a built-in process to limit the sharpening of what it detects as possible noise. Support for some scaling (which was included in CAS) is not included in RCAS, therefore it should run at presentation resolution.\n\n### Resource inputs\nThis table contains the resources consumed by the [Robust Contrast Adaptive Sharpening (RCAS)](#robust-contrast-adaptive-sharpening-rcas) stage.\n\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                        | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                        |  \n| ----------------------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| Upscaled buffer               | Current frame  | Presentation | `R16G16B16A16_FLOAT`    | Texture   | The output buffer produced by the [Reproject & Accumulate](#reproject-accumulate) stage for the current frame. Please note: This buffer is used internally by FSR2, and is distinct from the presentation buffer which is produced as an output from this stage after applying RCAS. Please note: This texture is part of an array of two textures along with the Output buffer texture which is consumed by the [Reproject & Accumulate](#reproject-accumulate) stage. The selection of which texture in the array is used for input and output is swapped each frame. |\n\n### Resource outputs\n> The temporal layer indicates which frame the data should be sourced from. 'Current frame' means that the data should be sourced from resources created for the frame that is to be presented next. 'Previous frame' indicates that the data should be sourced from resources which were created for the frame that has just presented. The resolution column indicates if the data should be at 'rendered' resolution or 'presentation' resolution. 'Rendered' resolution indicates that the resource should match the resolution at which the application is performing its rendering. Conversely, 'presentation' indicates that the resolution of the target should match that which is to be presented to the user. \n\n| Name                         | Temporal layer  | Resolution   |  Format                 | Type      | Notes                                       |  \n| -----------------------------|-----------------|--------------|-------------------------|-----------|----------------------------------------------|\n| Presentation buffer          | Current frame  | Presentation | Application specific    | Texture   | The presentation buffer produced by the completed FSR2 algorithm for the current frame. |\n\n\n### Description\nRCAS operates on data sampled using a 5-tap filter configured in a cross pattern. See the diagram below.\n\n![alt text](docs/media/super-resolution-temporal/rcas-weights.svg \"A diagram showing the weights RCAS applies to neighbourhood pixels.\")\n\nWith the samples retreived, RCAS then chooses the 'w' which results in no clipping, limits 'w', and multiplies by the 'sharp' amount. The solution above has issues with MSAA input as the steps along the gradient cause edge detection issues. To help stabilize the results of RCAS, it uses 4x the maximum and 4x the minimum (depending on equation) in place of the individual taps, as well as switching from 'm' to either the minimum or maximum (depending on side), to help in energy conservation.\n\n# Building the sample\n\n## Prerequisites\n\nTo build the FSR2 sample, please follow the following instructions:\n\n1) Install the following tools:\n\n- [CMake 3.16](https://cmake.org/download/)\n- Install the \"Desktop Development with C++\" workload\n- [Visual Studio 2019](https://visualstudio.microsoft.com/downloads/)\n- [Windows 10 SDK 10.0.18362.0](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk)\n- [Git 2.32.0](https://git-scm.com/downloads)\n\n2) Generate the solutions:\n    ```\n    > cd <installation path>\\build\n    > GenerateSolutions.bat\n    ```\n\n3) Open the solutions in the DX12 or Vulkan directory (depending on your preference), compile and run.\n\n# Limitations\n\nFSR2 requires a GPU with typed UAV load and R16G16B16A16_UNORM support.\n\n# Version history\n\n| Version        | Date              |\n| ---------------|-------------------|\n| **2.2.1**      | 2023-05-12        |\n| **2.2.0**      | 2023-02-16        |\n| **2.1.2**      | 2022-10-19        |\n| **2.1.1**      | 2022-09-15        |\n| **2.1.0**      | 2022-09-08        |\n| **2.0.1**      | 2022-06-22        |\n\nRefer to changelog for more detail on versions.\n\n\n# References\n[**Akeley-06**] Kurt Akeley and Jonathan Su, **\"Minimum Triangle Separation for Correct Z-Buffer Occlusion\"**, \n[http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/akeley06_triseparation.pdf](https://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/akeley06_triseparation.pdf)\n\n[**Lanczos**] Lanczos resampling, **\"Lanczos resampling\"**, [https://en.wikipedia.org/wiki/Lanczos_resampling](https://en.wikipedia.org/wiki/Lanczos_resampling)\n\n[**Halton**] Halton sequence, **\"Halton sequence\"**, [https://en.wikipedia.org/wiki/Halton_sequence](https://en.wikipedia.org/wiki/Halton_sequence)\n\n[**YCoCg**] YCoCg Color Space, [https://en.wikipedia.org/wiki/YCoCg](https://en.wikipedia.org/wiki/YCoCg)\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "changelog.md",
          "type": "blob",
          "size": 2.45703125,
          "content": "2023-05-12 | FidelityFX Super Resolution 2.2.1\n-------\n- Fixed comments in API header for incorrect cameraFar use.\n- Fixed DRS issue where resource was not correctly cleared on first use.\n- Fixed issue where luma instability logic could introduce output artefacts with strobing lights.\n- Fixed incorrect luma resource size.\n\n2023-02-23 | FidelityFX Super Resolution 2.2.0a\n-------\n- Minor updates to the documentation\n- Removal of a handful of files from the prior release that are no longer part of FSR 2.2.\n\n2023-02-16 | FidelityFX Super Resolution 2.2.0\n-------\n- Introduction of API debug checker.\n- Changes to improve \"High Velocity Ghosting\" situations.\n- Changes to Luminance computation with pre-exposure application.\n- Small motion vectors ignored in previous depth estimation.\n- Changes to depth logic to improve disocclusion detection and avoid self-disocclusions.\n- Dilated reactive mask logic updated to use temporal motion vector divergence to kill locks.\n- New lock luminance resource.\n- Accumulation overhauled to use temporal reactivity.\n- Changed how intermediate signals are stored and tonemapped.\n- Luminance instability logic improved.\n- Tonemapping no longer applied during RCAS to retain more dynamic range.\n- Fixes for multiple user reported issues on GitHub and elsewhere. Thank you for your feedback!\n\n2022-10-10 | FidelityFX Super Resolution 2.1.2\n-------\n- Fix resource precision issue.\n- Clamp coordinates in software sampling logic.\n\n2022-09-13 | FidelityFX Super Resolution 2.1.1\n-------\n- Fix issue with reprojection data on a reset.\n\n2022-09-06 | FidelityFX Super Resolution 2.1\n-------\n- Reactivity mask now uses full range of value in the mask (0.0 - 1.0).\n- Reactivity and Composition and Transparency mask dialation is now based on input colors to avoid expanding reactiveness into non-relevant upscaled areas.\n- Disocclusion logic improved in order to detect disocclusions in areas with very small depth separation.\n- RCAS Pass forced to fp32 mode to reduce chance of issues seen with HDR input values.\n- Fix for display-resolution motion vectors interpretation.\n- FP16/FP32 computation review, readjusting balance of fp16/fp32 for maximum quality.\n- Amended motion vector description within the documentation.\n- Various documentation edits for spelling.\n- Clarified the frame delta time input value within the readme documentation.\n- Fixed issue with bad memset within the shader blob selection logic.\n\n\n2022-06-22 | FidelityFX Super Resolution 2.0.1\n-------\n- First release.\n\n"
        },
        {
          "name": "clang-tidy.txt",
          "type": "blob",
          "size": 1.9375,
          "content": "# This file is part of the FidelityFX SDK.\n#\n# Copyright (c) 2021 Advanced Micro Devices, Inc. All rights reserved.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\nChecks:          'clang-diagnostic-*,clang-analyzer-*,cppcoreguidelines-*,modernize-*,-modernize-use-trailing-return-type'\nWarningsAsErrors: false\nHeaderFilterRegex: ''\nAnalyzeTemporaryDtors: false\nFormatStyle:     google\nCheckOptions:\n  - { key: readability-identifier-naming.NamespaceCase,       value: CamelCase  }\n  - { key: readability-identifier-naming.ClassCase,           value: CamelCase  }\n  - { key: readability-identifier-naming.PrivateMemberPrefix, value: m_         }\n  - { key: readability-identifier-naming.StructCase,          value: CamelCase  }\n  - { key: readability-identifier-naming.FunctionCase,        value: camelBase  }\n  - { key: readability-identifier-naming.VariableCase,        value: camelBase  }\n  - { key: readability-identifier-naming.GlobalConstantCase,  value: UPPER_CASE }\n  "
        },
        {
          "name": "common.cmake",
          "type": "blob",
          "size": 0.8505859375,
          "content": "#\n# enables multithreading compilation\n#\n\nadd_compile_options(/MP)\n\n#\n# includes cauldron's helper cmakes\n#\ninclude(${CMAKE_CURRENT_SOURCE_DIR}/../../libs/cauldron/common.cmake)\n\n#\n# Add manifest so the app uses the right DPI settings\n#\nfunction(addManifest PROJECT_NAME)\n    IF (MSVC)\n        IF (CMAKE_MAJOR_VERSION LESS 3)\n            MESSAGE(WARNING \"CMake version 3.0 or newer is required use build variable TARGET_FILE\")\n        ELSE()\n            ADD_CUSTOM_COMMAND(\n                TARGET ${PROJECT_NAME}\n                POST_BUILD\n                COMMAND \"mt.exe\" -manifest \\\"${CMAKE_CURRENT_SOURCE_DIR}\\\\dpiawarescaling.manifest\\\" -inputresource:\\\"$<TARGET_FILE:${PROJECT_NAME}>\\\"\\;\\#1 -outputresource:\\\"$<TARGET_FILE:${PROJECT_NAME}>\\\"\\;\\#1\n                COMMENT \"Adding display aware manifest...\" \n            )\n        ENDIF()\n    ENDIF(MSVC)\nendfunction()"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "libs",
          "type": "tree",
          "content": null
        },
        {
          "name": "media",
          "type": "tree",
          "content": null
        },
        {
          "name": "release_notes.txt",
          "type": "blob",
          "size": 0.7607421875,
          "content": "FidelityFX Super Resolution 2.2.1\n=================================\n\nChanges\n-------\n- Fixed comments in API header for incorrect cameraFar use.\n- Fixed DRS issue where resource was not correctly cleared on first use.\n- Fixed issue where luma instability logic could introduce output artefacts with strobing lights.\n- Fixed incorrect luma resource size.\n\nLimitations\n-----------\n- The precise configuration and contents of the reactivity mask is subject to change in a future version of FSR2.\n\nKnown issues\n------------\n- The Vulkan version of the FSR2 sample application experiences a crash on Intel i9-10900K products.\n- The Vulkan version of the FSR2 sample application experiences a crash when using the function keys to toggle between scaling modes on some NVIDIA hardware.\n"
        },
        {
          "name": "screenshot.png",
          "type": "blob",
          "size": 4029.59375,
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}