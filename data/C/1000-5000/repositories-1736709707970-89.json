{
  "metadata": {
    "timestamp": 1736709707970,
    "page": 89,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "cloudius-systems/osv",
      "stars": 4130,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.0185546875,
          "content": "*~\nbuild/\n.\\#*\n\\#*\\#\nmodules/java-base/*/target\nmodules/java-tests/*/target\n\n.gradle\ntags\nTAGS\n\ncscope.in.out\ncscope.out\ncscope.po.out\n\n*.pyc\n*.swp\n*.patch\n\n*.orig\n*.rej\n\n# file generated by trace tool\ntracefile\n\nbuild.out\n\nmodules/java-base/**/dependency-reduced-pom.xml\nmodules/java-base/**/*.iml\nmodules/java-base/obj/\nmodules/java-tests/**/*.iml\nmodules/java-tests/obj/\nmodules/java-isolated/obj/\nmodules/java-non-isolated/obj/\nmodules/java-mgmt/cloudius/target/\nmodules/java-mgmt/obj/\nmodules/httpserver/usr.manifest\nmodules/httpserver-jolokia-plugin/autogen/\nmodules/httpserver-jolokia-plugin/jolokia*.so\nmodules/httpserver-jolokia-plugin/obj/\nmodules/httpserver-jolokia-plugin/jolokia-agent/target/\nmodules/httpserver-jolokia-plugin/jolokia-agent/dependency-reduced-pom.xml\nmodules/httpserver-jvm-plugin/autogen/\nmodules/httpserver-jvm-plugin/jvm*.so\nmodules/httpserver-jvm-plugin/obj/\nmodules/libtools/*.so\nmodules/libtools/*.o\nmodules/libyaml/usr.manifest\nmodules/dl_tests/usr.manifest\n.idea\ncompile_commands.json\ndownloaded_packages\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.73046875,
          "content": "[submodule \"external/x64/acpica\"]\n\tpath = external/x64/acpica\n\turl = ../../cloudius-systems/acpica\n\tignore = dirty\n[submodule \"apps\"]\n\tpath = apps\n\turl = ../../cloudius-systems/osv-apps\n\tignore = dirty\n[submodule \"modules/httpserver/swagger-ui\"]\n\tpath = modules/httpserver-html5-gui/swagger-ui\n\turl = ../../cloudius-systems/swagger-ui.git\n[submodule \"modules/httpserver/osv-gui\"]\n\tpath = modules/httpserver-html5-gui/osv-gui\n\turl = ../../cloudius-systems/osv-gui.git\n[submodule \"musl_0.9.12\"]\n\tpath = musl_0.9.12\n\turl = https://github.com/cloudius-systems/musl\n[submodule \"musl_1.1.24\"]\n\tpath = musl_1.1.24\n\turl = https://github.com/osvunikernel/musl\n[submodule \"kbuild\"]\n\tpath = kbuild\n\turl = https://github.com/osvunikernel/kbuild-standalone.git\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 3.62109375,
          "content": "sudo: required\ndist: bionic\nlanguage: c\npython: 3.6\nservices:\n  - docker\nbranches:\n  only:\n  - master\n  - ipv6\naddons:\n  apt:\n    packages:\n      - bridge-utils\n      - libpulse0\n      - libvirt-bin\n      - qemu-kvm\n      - virtinst\n      - ubuntu-vm-builder\n      - python3-pip\nbefore_install:\n  # Set up KVM\n  - sudo adduser $USER libvirt\n  - sudo adduser $USER kvm\n  - echo \"$DOCKER_ACCESS_TOKEN\" | docker login --username osvunikernel --password-stdin\n  - pushd docker && docker build -t osv/builder -f ./Dockerfile.builder --build-arg DIST=\"ubuntu-20.10\" . && popd\n  - docker run -it --privileged -d --name build osv/builder\nstages:\n  - build_and_publish\nenv:\n  global:\n    - CIRP_GITHUB_REPO_SLUG=\"osvunikernel/osv-nightly-releases\"\njobs:\n  include:\n    - stage: build_and_publish\n      script:\n        - docker exec build ./scripts/build clean\n        - docker exec build ./scripts/build -j$(nproc) image=tests\n        - docker exec build lscpu\n        - docker exec build ./scripts/test.py -d tracing_smoke_test -d tst-time.so\n        - docker exec build ./scripts/build-capstan-mpm-packages kernel\n        - docker exec build ./scripts/build-capstan-mpm-packages unit_tests\n        - docker exec build ./scripts/build-capstan-mpm-packages monitoring\n        - docker exec build ./scripts/osv-version.sh > /tmp/osv-version\n        - export ARTIFACTS_DIR=\"$(mktemp -d)\"\n        - cp /tmp/osv-version \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/repository/osv-loader/osv-loader.qemu.x86_64 \"$ARTIFACTS_DIR\"/osv-loader-with-zfs.qemu.x86_64\n        - gzip \"$ARTIFACTS_DIR\"/osv-loader-with-zfs.qemu.x86_64\n        - docker cp build:/git-repos/osv/build/release/loader-stripped.elf \"$ARTIFACTS_DIR\"/loader-with-zfs.elf.x86_64\n        - gzip \"$ARTIFACTS_DIR\"/loader-with-zfs.elf.x86_64\n        - docker cp build:/root/.capstan/repository/osv-loader/index.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.zfs.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.zfs.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.bootstrap.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.bootstrap.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.common-tests.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.common-tests.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.zfs-tests.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.zfs-tests.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.rofs-tests.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.rofs-tests.yaml \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.httpserver-monitoring-api.mpm.x86_64 \"$ARTIFACTS_DIR\"\n        - docker cp build:/root/.capstan/packages/osv.httpserver-monitoring-api.yaml \"$ARTIFACTS_DIR\"\n        - docker exec build rm -rf ./build/release.x64\n        - docker exec build ./scripts/build-capstan-mpm-packages kernel conf_hide_symbols=1 fs=rofs loader_image=osv-loader-hidden\n        - docker cp build:/root/.capstan/repository/osv-loader-hidden/osv-loader-hidden.qemu.x86_64 \"$ARTIFACTS_DIR\"/osv-loader-hidden.qemu.x86_64\n        - gzip \"$ARTIFACTS_DIR\"/osv-loader-hidden.qemu.x86_64\n        - docker cp build:/git-repos/osv/build/release/loader-stripped.elf \"$ARTIFACTS_DIR\"/loader-hidden.elf.x86_64\n        - gzip \"$ARTIFACTS_DIR\"/loader-hidden.elf.x86_64\n        - ./.travis/cirp/cleanup4.sh\n        - ./.travis/cirp/publish.sh \"$ARTIFACTS_DIR\" $(cat /tmp/osv-version)\n        - ./.travis/cirp/cleanup5.sh\n"
        },
        {
          "name": ".travis",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODINGSTYLE.md",
          "type": "blob",
          "size": 2.9443359375,
          "content": "# OSv Coding Style\n\nThis is a coding style guide for OSv.  It is meant to be helpful, not a tool\nfor bikeshedding patches on the mailing list.  The use of common sense when\napplying these rules is required.\n\n## 1. Indentation and layout\n1.1 We use 4 spaces for indentation, no tabs.\n\n1.2 switch statements, put the case with same indentation as the switch\n```\n    switch(op) {\n    case 1:\n            i++;\n            break;\n    case 2:\n    case 3:\n           i *= 2;\n           break;\n    default:\n           break;\n```\n\n1.3 Avoid multiple statements on the same line:\n```\n    i++; j++;\n```\n\n1.4 Line length should not exceed 80 characters.\n\n## 2. Spaces\n2.1 Use spaces around binary and ternary operators.\n```\n   a = a + 3;\n   if (a == 1 || b < 2)\n   a += 1;\n   a = 1 + 2 * 3;\n   a = b < 1 ? b : 1;\n```\n\n2.2 Do not use spaces around unary operators.\n```\n   a = -2;\n   s = *p;\n   for (int i = 3; i < 10; ++i)\n```\n\n2.3 Do not use spaces between a function and its parameters, or a\ntemplate and its paramters.\n```\n   sqrt(2.0)\n   std::vector<object*>\n```\n\n2.4 Bind '*' or '&' to the type, not the variable\n...\n   int* a;\n   int& b;\n...\n\nPlease note that the rule obviously does not make sense when multiple variables\nare declared on the same line.  In such cases, it is preferable to do:\n\n...\n   int *a, *b;\n...\n\n## 3. Braces\n3.1 Always use curly braces for if statement, even if it is a one line if.\n\n3.2 When a brace-delimited block is part of a statement (e.g., if, for,\nswitch, WITH_LOCK, etc.), separate the open brace from the statement\nwith a single space - not with a newline.\n```\n    if (a == 3) {\n        ....\n    }\n````\n\n3.2 In inline method, you can use the open braces at the same line of the method.\n```\n    int get_age() {\n        return age;\n    }\n```\n\n3.3 In longer method,  the opening brace should be at the beginning of the line.\n```\n    void clear()\n    {\n       .....\n    }\n```\n\n## 4. Naming Convention\n4.1 Use all lower snake_case names\n\n## 5. Commenting\n5.1 Use the // C++ comment style for normal comment\n\n5.2 When documenting a namespace, class, method or function using Doxygen, use /** */ comments.\n\n## 6. Macros, Enums and RTL\n6.1 Avoid Macros when a method would do. Prefer enum and constant to macro.\n\n6.2 Prefer \"enum class\" to \"enum\".\n\n6.3 Macro names and enum label should be capitalized. For \"enum class\",\nnon-capitalized values are fine.\n\n## 7. Functions\n7.1 When declaring or defining a function taking no arguments in C++ code,\navoid the unnecessary \"void\" as an argument list.\n\nThis \"void\" was only necessary in C to maintain backward-compatibility with\npre-1989 prototype-less declarations, but was never needed in C++ code.\nFor example, write:\n\n```C++\nvoid abort() {\n```\n\nand not:\n\n```C++\nvoid abort(void) {\n```\n\n7.2 Put no space between function name and the argument list. For example:\n\n```C++\ndouble sqrt(double d) {\n```\n\n7.3 Avoid parantheses around return value\n\n\"return\" is not a function - it doesn't need parantheses. For example:\n\n```C++\nreturn 0;\nreturn a + b;\n```\n"
        },
        {
          "name": "CONTRIBUTING",
          "type": "blob",
          "size": 2.1142578125,
          "content": "We welcome code contributions to the OSv open-source project, in the form of\npatches.\n\nThe OSv project does not require copyright assignment - the copyright on your\nown contribution remains yours. However, contributions are independent, so you\nare considered a copyright holder of your piece of the code - not of the entire\nproject.\n\nWhen you send a patch to the OSv project, we want you to certify that you wrote\nthis patch, or otherwise have the right to submit it for inclusion in OSv.\nIn more details, we want you to agree that:\n\n        By making a contribution to this project, I certify that:\n\n        (a) The contribution was created in whole or in part by me and I\n            have the right to submit it under the open source license\n            indicated in the file; or\n\n        (b) The contribution is based upon previous work that, to the best\n            of my knowledge, is covered under an appropriate open source\n            license and I have the right under that license to submit that\n            work with modifications, whether created in whole or in part\n            by me, under the same open source license (unless I am\n            permitted to submit under a different license), as indicated\n            in the file; or\n\n        (c) The contribution was provided directly to me by some other\n            person who certified (a), (b) or (c) and I have not modified\n            it.\n\n        (d) I understand and agree that this project and the contribution\n            are public and that a record of the contribution (including all\n            personal information I submit with it, including my sign-off) is\n            maintained indefinitely and may be redistributed consistent with\n            this project or the open source license(s) involved.\n\nTo state that you agree to these conditions for code contribution, all you need\nto do is to add a line to your patch stating:\n\n\tSigned-off-by: Your Real Name <your@email.address>\n\nYou may notice that the above four conditions are identical to the \"Developer's\nCertificate of Origin 1.1\" used in the Linux kernel's development. The\n\"signed-off-by\" process was copied from Linux as well.\n"
        },
        {
          "name": "Doxyfile",
          "type": "blob",
          "size": 74.0302734375,
          "content": "DOXYFILE_ENCODING      = UTF-8\nPROJECT_NAME           = \"OSv\"\nPROJECT_NUMBER         = 0.1\n\n# Using the PROJECT_BRIEF tag one can provide an optional one line description\n# for a project that appears at the top of each page and should give viewer\n# a quick idea about the purpose of the project. Keep the description short.\n\nPROJECT_BRIEF          = \"Designed for the Cloud\"\n\n# With the PROJECT_LOGO tag one can specify an logo or icon that is\n# included in the documentation. The maximum height of the logo should not\n# exceed 55 pixels and the maximum width should not exceed 200 pixels.\n# Doxygen will copy the logo to the output directory.\n\nPROJECT_LOGO           =\n\n# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute)\n# base path where the generated documentation will be put.\n# If a relative path is entered, it will be relative to the location\n# where doxygen was started. If left blank the current directory will be used.\n\nOUTPUT_DIRECTORY       = doxyout\nOUTPUT_LANGUAGE        = English\n\n# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will\n# include brief member descriptions after the members that are listed in\n# the file and class documentation (similar to JavaDoc).\n# Set to NO to disable this.\n\nBRIEF_MEMBER_DESC      = YES\n\n# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend\n# the brief description of a member or function before the detailed description.\n# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the\n# brief descriptions will be completely suppressed.\n\nREPEAT_BRIEF           = YES\n\n# This tag implements a quasi-intelligent brief description abbreviator\n# that is used to form the text in various listings. Each string\n# in this list, if found as the leading text of the brief description, will be\n# stripped from the text and the result after processing the whole list, is\n# used as the annotated text. Otherwise, the brief description is used as-is.\n# If left blank, the following values are used (\"$name\" is automatically\n# replaced with the name of the entity): \"The $name class\" \"The $name widget\"\n# \"The $name file\" \"is\" \"provides\" \"specifies\" \"contains\"\n# \"represents\" \"a\" \"an\" \"the\"\n\nABBREVIATE_BRIEF       =\n\n# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then\n# Doxygen will generate a detailed section even if there is only a brief\n# description.\n\nALWAYS_DETAILED_SEC    = NO\n\n# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all\n# inherited members of a class in the documentation of that class as if those\n# members were ordinary class members. Constructors, destructors and assignment\n# operators of the base classes will not be shown.\n\nINLINE_INHERITED_MEMB  = NO\n\n# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full\n# path before files name in the file list and in the header files. If set\n# to NO the shortest path that makes the file name unique will be used.\n\nFULL_PATH_NAMES        = YES\n\n# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag\n# can be used to strip a user-defined part of the path. Stripping is\n# only done if one of the specified strings matches the left-hand part of\n# the path. The tag can be used to show relative paths in the file list.\n# If left blank the directory from which doxygen is run is used as the\n# path to strip. Note that you specify absolute paths here, but also\n# relative paths, which will be relative from the directory where doxygen is\n# started.\n\nSTRIP_FROM_PATH        =\n\n# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of\n# the path mentioned in the documentation of a class, which tells\n# the reader which header file to include in order to use a class.\n# If left blank only the name of the header file containing the class\n# definition is used. Otherwise one should specify the include paths that\n# are normally passed to the compiler using the -I flag.\n\nSTRIP_FROM_INC_PATH    = include\n\n# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter\n# (but less readable) file names. This can be useful if your file system\n# doesn't support long names like on DOS, Mac, or CD-ROM.\n\nSHORT_NAMES            = NO\n\n# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen\n# will interpret the first line (until the first dot) of a JavaDoc-style\n# comment as the brief description. If set to NO, the JavaDoc\n# comments will behave just like regular Qt-style comments\n# (thus requiring an explicit @brief command for a brief description.)\n\nJAVADOC_AUTOBRIEF      = YES\n\n# If the QT_AUTOBRIEF tag is set to YES then Doxygen will\n# interpret the first line (until the first dot) of a Qt-style\n# comment as the brief description. If set to NO, the comments\n# will behave just like regular Qt-style comments (thus requiring\n# an explicit \\brief command for a brief description.)\n\nQT_AUTOBRIEF           = NO\n\n# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen\n# treat a multi-line C++ special comment block (i.e. a block of //! or ///\n# comments) as a brief description. This used to be the default behaviour.\n# The new default is to treat a multi-line C++ comment block as a detailed\n# description. Set this tag to YES if you prefer the old behaviour instead.\n\nMULTILINE_CPP_IS_BRIEF = NO\n\n# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented\n# member inherits the documentation from any documented member that it\n# re-implements.\n\nINHERIT_DOCS           = YES\n\n# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce\n# a new page for each member. If set to NO, the documentation of a member will\n# be part of the file/class/namespace that contains it.\n\nSEPARATE_MEMBER_PAGES  = NO\n\n# The TAB_SIZE tag can be used to set the number of spaces in a tab.\n# Doxygen uses this value to replace tabs by spaces in code fragments.\n\nTAB_SIZE               = 4\n\n# This tag can be used to specify a number of aliases that acts\n# as commands in the documentation. An alias has the form \"name=value\".\n# For example adding \"sideeffect=\\par Side Effects:\\n\" will allow you to\n# put the command \\sideeffect (or @sideeffect) in the documentation, which\n# will result in a user-defined paragraph with heading \"Side Effects:\".\n# You can put \\n's in the value part of an alias to insert newlines.\n\nALIASES                =\n\n# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C\n# sources only. Doxygen will then generate output that is more tailored for C.\n# For instance, some of the names that are used will be different. The list\n# of all members will be omitted, etc.\n\nOPTIMIZE_OUTPUT_FOR_C  = NO\n\n# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java\n# sources only. Doxygen will then generate output that is more tailored for\n# Java. For instance, namespaces will be presented as packages, qualified\n# scopes will look different, etc.\n\nOPTIMIZE_OUTPUT_JAVA   = NO\n\n# Doxygen selects the parser to use depending on the extension of the files it\n# parses. With this tag you can assign which parser to use for a given\n# extension. Doxygen has a built-in mapping, but you can override or extend it\n# using this tag. The format is ext=language, where ext is a file extension,\n# and language is one of the parsers supported by doxygen: IDL, Java,\n# Javascript, CSharp, C, C++, D, PHP, Objective-C, Python, Fortran, VHDL, C,\n# C++. For instance to make doxygen treat .inc files as Fortran files (default\n# is PHP), and .f files as C (default is Fortran), use: inc=Fortran f=C. Note\n# that for custom extensions you also need to set FILE_PATTERNS otherwise the\n# files are not read by doxygen.\n\nEXTENSION_MAPPING      =\n\n# If MARKDOWN_SUPPORT is enabled (the default) then doxygen pre-processes all\n# comments according to the Markdown format, which allows for more readable\n# documentation. See http://daringfireball.net/projects/markdown/ for details.\n# The output of markdown processing is further processed by doxygen, so you\n# can mix doxygen, HTML, and XML commands with Markdown formatting.\n# Disable only in case of backward compatibilities issues.\n\nMARKDOWN_SUPPORT       = YES\n\n# When enabled doxygen tries to link words that correspond to documented classes,\n# or namespaces to their corresponding documentation. Such a link can be\n# prevented in individual cases by by putting a % sign in front of the word or\n# globally by setting AUTOLINK_SUPPORT to NO.\n\nAUTOLINK_SUPPORT       = YES\n\n# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want\n# to include (a tag file for) the STL sources as input, then you should\n# set this tag to YES in order to let doxygen match functions declarations and\n# definitions whose arguments contain STL classes (e.g. func(std::string); v.s.\n# func(std::string) {}). This also makes the inheritance and collaboration\n# diagrams that involve STL classes more complete and accurate.\n\nBUILTIN_STL_SUPPORT    = YES\n\n\n# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC\n# tag is set to YES, then doxygen will reuse the documentation of the first\n# member in the group (if any) for the other members of the group. By default\n# all members of a group must be documented explicitly.\n\nDISTRIBUTE_GROUP_DOC   = NO\n\n# Set the SUBGROUPING tag to YES (the default) to allow class member groups of\n# the same type (for instance a group of public functions) to be put as a\n# subgroup of that type (e.g. under the Public Functions section). Set it to\n# NO to prevent subgrouping. Alternatively, this can be done per class using\n# the \\nosubgrouping command.\n\nSUBGROUPING            = YES\n\n# When the INLINE_GROUPED_CLASSES tag is set to YES, classes, structs and\n# unions are shown inside the group in which they are included (e.g. using\n# @ingroup) instead of on a separate page (for HTML and Man pages) or\n# section (for LaTeX and RTF).\n\nINLINE_GROUPED_CLASSES = NO\n\n# When the INLINE_SIMPLE_STRUCTS tag is set to YES, structs, classes, and\n# unions with only public data fields will be shown inline in the documentation\n# of the scope in which they are defined (i.e. file, namespace, or group\n# documentation), provided this scope is documented. If set to NO (the default),\n# structs, classes, and unions are shown on a separate page (for HTML and Man\n# pages) or section (for LaTeX and RTF).\n\nINLINE_SIMPLE_STRUCTS  = NO\n\n# When TYPEDEF_HIDES_STRUCT is enabled, a typedef of a struct, union, or enum\n# is documented as struct, union, or enum with the name of the typedef. So\n# typedef struct TypeS {} TypeT, will appear in the documentation as a struct\n# with name TypeT. When disabled the typedef will appear as a member of a file,\n# namespace, or class. And the struct will be named TypeS. This can typically\n# be useful for C code in case the coding convention dictates that all compound\n# types are typedef'ed and only the typedef is referenced, never the tag name.\n\nTYPEDEF_HIDES_STRUCT   = NO\n\n# The SYMBOL_CACHE_SIZE determines the size of the internal cache use to\n# determine which symbols to keep in memory and which to flush to disk.\n# When the cache is full, less often used symbols will be written to disk.\n# For small to medium size projects (<1000 input files) the default value is\n# probably good enough. For larger projects a too small cache size can cause\n# doxygen to be busy swapping symbols to and from disk most of the time\n# causing a significant performance penalty.\n# If the system has enough physical memory increasing the cache will improve the\n# performance by keeping more symbols in memory. Note that the value works on\n# a logarithmic scale so increasing the size by one will roughly double the\n# memory usage. The cache size is given by this formula:\n# 2^(16+SYMBOL_CACHE_SIZE). The valid range is 0..9, the default is 0,\n# corresponding to a cache size of 2^16 = 65536 symbols.\n\nSYMBOL_CACHE_SIZE      = 0\n\n# Similar to the SYMBOL_CACHE_SIZE the size of the symbol lookup cache can be\n# set using LOOKUP_CACHE_SIZE. This cache is used to resolve symbols given\n# their name and scope. Since this can be an expensive process and often the\n# same symbol appear multiple times in the code, doxygen keeps a cache of\n# pre-resolved symbols. If the cache is too small doxygen will become slower.\n# If the cache is too large, memory is wasted. The cache size is given by this\n# formula: 2^(16+LOOKUP_CACHE_SIZE). The valid range is 0..9, the default is 0,\n# corresponding to a cache size of 2^16 = 65536 symbols.\n\nLOOKUP_CACHE_SIZE      = 0\n\n#---------------------------------------------------------------------------\n# Build related configuration options\n#---------------------------------------------------------------------------\n\n# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in\n# documentation are documented, even if no documentation was available.\n# Private class members and static file members will be hidden unless\n# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES\n\nEXTRACT_ALL            = NO\n\n# If the EXTRACT_PRIVATE tag is set to YES all private members of a class\n# will be included in the documentation.\n\nEXTRACT_PRIVATE        = NO\n\n# If the EXTRACT_PACKAGE tag is set to YES all members with package or internal\n# scope will be included in the documentation.\n\nEXTRACT_PACKAGE        = NO\n\n# If the EXTRACT_STATIC tag is set to YES all static members of a file\n# will be included in the documentation.\n\nEXTRACT_STATIC         = NO\n\n# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs)\n# defined locally in source files will be included in the documentation.\n# If set to NO only classes defined in header files are included.\n\n#EXTRACT_LOCAL_CLASSES  = YES\nEXTRACT_LOCAL_CLASSES  = NO\n\n# If this flag is set to YES, the members of anonymous namespaces will be\n# extracted and appear in the documentation as a namespace called\n# 'anonymous_namespace{file}', where file will be replaced with the base\n# name of the file that contains the anonymous namespace. By default\n# anonymous namespaces are hidden.\n\nEXTRACT_ANON_NSPACES   = NO\n\n# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all\n# undocumented members of documented classes, files or namespaces.\n# If set to NO (the default) these members will be included in the\n# various overviews, but no documentation section is generated.\n# This option has no effect if EXTRACT_ALL is enabled.\n\n#HIDE_UNDOC_MEMBERS     = NO\nHIDE_UNDOC_MEMBERS     = YES\n\n# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all\n# undocumented classes that are normally visible in the class hierarchy.\n# If set to NO (the default) these classes will be included in the various\n# overviews. This option has no effect if EXTRACT_ALL is enabled.\n\n#HIDE_UNDOC_CLASSES     = NO\nHIDE_UNDOC_CLASSES     = YES\n\n# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all\n# friend (class|struct|union) declarations.\n# If set to NO (the default) these declarations will be included in the\n# documentation.\n\nHIDE_FRIEND_COMPOUNDS  = NO\n\n# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any\n# documentation blocks found inside the body of a function.\n# If set to NO (the default) these blocks will be appended to the\n# function's detailed documentation block.\n\nHIDE_IN_BODY_DOCS      = NO\n\n# The INTERNAL_DOCS tag determines if documentation\n# that is typed after a \\internal command is included. If the tag is set\n# to NO (the default) then the documentation will be excluded.\n# Set it to YES to include the internal documentation.\n\nINTERNAL_DOCS          = NO\n\n# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate\n# file names in lower-case letters. If set to YES upper-case letters are also\n# allowed. This is useful if you have classes or files whose names only differ\n# in case and if your file system supports case sensitive file names. Windows\n# and Mac users are advised to set this option to NO.\n\nCASE_SENSE_NAMES       = YES\n\n# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen\n# will show members with their full class and namespace scopes in the\n# documentation. If set to YES the scope will be hidden.\n\nHIDE_SCOPE_NAMES       = NO\n\n# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen\n# will put a list of the files that are included by a file in the documentation\n# of that file.\n\nSHOW_INCLUDE_FILES     = YES\n\n# If the FORCE_LOCAL_INCLUDES tag is set to YES then Doxygen\n# will list include files with double quotes in the documentation\n# rather than with sharp brackets.\n\nFORCE_LOCAL_INCLUDES   = NO\n\n# If the INLINE_INFO tag is set to YES (the default) then a tag [inline]\n# is inserted in the documentation for inline members.\n\nINLINE_INFO            = YES\n\n# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen\n# will sort the (detailed) documentation of file and class members\n# alphabetically by member name. If set to NO the members will appear in\n# declaration order.\n\nSORT_MEMBER_DOCS       = YES\n\n# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the\n# brief documentation of file, namespace and class members alphabetically\n# by member name. If set to NO (the default) the members will appear in\n# declaration order.\n\nSORT_BRIEF_DOCS        = NO\n\n# If the SORT_MEMBERS_CTORS_1ST tag is set to YES then doxygen\n# will sort the (brief and detailed) documentation of class members so that\n# constructors and destructors are listed first. If set to NO (the default)\n# the constructors will appear in the respective orders defined by\n# SORT_MEMBER_DOCS and SORT_BRIEF_DOCS.\n# This tag will be ignored for brief docs if SORT_BRIEF_DOCS is set to NO\n# and ignored for detailed docs if SORT_MEMBER_DOCS is set to NO.\n\nSORT_MEMBERS_CTORS_1ST = NO\n\n# If the SORT_GROUP_NAMES tag is set to YES then doxygen will sort the\n# hierarchy of group names into alphabetical order. If set to NO (the default)\n# the group names will appear in their defined order.\n\nSORT_GROUP_NAMES       = NO\n\n# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be\n# sorted by fully-qualified names, including namespaces. If set to\n# NO (the default), the class list will be sorted only by class name,\n# not including the namespace part.\n# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.\n# Note: This option applies only to the class list, not to the\n# alphabetical list.\n\nSORT_BY_SCOPE_NAME     = NO\n\n# If the STRICT_PROTO_MATCHING option is enabled and doxygen fails to\n# do proper type resolution of all parameters of a function it will reject a\n# match between the prototype and the implementation of a member function even\n# if there is only one candidate or it is obvious which candidate to choose\n# by doing a simple string match. By disabling STRICT_PROTO_MATCHING doxygen\n# will still accept a match between prototype and implementation in such cases.\n\nSTRICT_PROTO_MATCHING  = NO\n\n# The GENERATE_TODOLIST tag can be used to enable (YES) or\n# disable (NO) the todo list. This list is created by putting \\todo\n# commands in the documentation.\n\nGENERATE_TODOLIST      = YES\n\n# The GENERATE_TESTLIST tag can be used to enable (YES) or\n# disable (NO) the test list. This list is created by putting \\test\n# commands in the documentation.\n\nGENERATE_TESTLIST      = YES\n\n# The GENERATE_BUGLIST tag can be used to enable (YES) or\n# disable (NO) the bug list. This list is created by putting \\bug\n# commands in the documentation.\n\nGENERATE_BUGLIST       = YES\n\n# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or\n# disable (NO) the deprecated list. This list is created by putting\n# \\deprecated commands in the documentation.\n\nGENERATE_DEPRECATEDLIST= YES\n\n# The ENABLED_SECTIONS tag can be used to enable conditional\n# documentation sections, marked by \\if section-label ... \\endif\n# and \\cond section-label ... \\endcond blocks.\n\nENABLED_SECTIONS       =\n\n# The MAX_INITIALIZER_LINES tag determines the maximum number of lines\n# the initial value of a variable or macro consists of for it to appear in\n# the documentation. If the initializer consists of more lines than specified\n# here it will be hidden. Use a value of 0 to hide initializers completely.\n# The appearance of the initializer of individual variables and macros in the\n# documentation can be controlled using \\showinitializer or \\hideinitializer\n# command in the documentation regardless of this setting.\n\nMAX_INITIALIZER_LINES  = 30\n\n# Set the SHOW_USED_FILES tag to NO to disable the list of files generated\n# at the bottom of the documentation of classes and structs. If set to YES the\n# list will mention the files that were used to generate the documentation.\n\nSHOW_USED_FILES        = YES\n\n# Set the SHOW_FILES tag to NO to disable the generation of the Files page.\n# This will remove the Files entry from the Quick Index and from the\n# Folder Tree View (if specified). The default is YES.\n\nSHOW_FILES             = YES\n\n# Set the SHOW_NAMESPACES tag to NO to disable the generation of the\n# Namespaces page.\n# This will remove the Namespaces entry from the Quick Index\n# and from the Folder Tree View (if specified). The default is YES.\n\nSHOW_NAMESPACES        = YES\n\n# The FILE_VERSION_FILTER tag can be used to specify a program or script that\n# doxygen should invoke to get the current version for each file (typically from\n# the version control system). Doxygen will invoke the program by executing (via\n# popen()) the command <command> <input-file>, where <command> is the value of\n# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file\n# provided by doxygen. Whatever the program writes to standard output\n# is used as the file version. See the manual for examples.\n\nFILE_VERSION_FILTER    =\n\n# The LAYOUT_FILE tag can be used to specify a layout file which will be parsed\n# by doxygen. The layout file controls the global structure of the generated\n# output files in an output format independent way. To create the layout file\n# that represents doxygen's defaults, run doxygen with the -l option.\n# You can optionally specify a file name after the option, if omitted\n# DoxygenLayout.xml will be used as the name of the layout file.\n\nLAYOUT_FILE            =\n\n# The CITE_BIB_FILES tag can be used to specify one or more bib files\n# containing the references data. This must be a list of .bib files. The\n# .bib extension is automatically appended if omitted. Using this command\n# requires the bibtex tool to be installed. See also\n# http://en.wikipedia.org/wiki/BibTeX for more info. For LaTeX the style\n# of the bibliography can be controlled using LATEX_BIB_STYLE. To use this\n# feature you need bibtex and perl available in the search path. Do not use\n# file names with spaces, bibtex cannot handle them.\n\nCITE_BIB_FILES         =\n\n#---------------------------------------------------------------------------\n# configuration options related to warning and progress messages\n#---------------------------------------------------------------------------\n\n# The QUIET tag can be used to turn on/off the messages that are generated\n# by doxygen. Possible values are YES and NO. If left blank NO is used.\n\nQUIET                  = NO\n\n# The WARNINGS tag can be used to turn on/off the warning messages that are\n# generated by doxygen. Possible values are YES and NO. If left blank\n# NO is used.\n\nWARNINGS               = YES\n\n# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings\n# for undocumented members. If EXTRACT_ALL is set to YES then this flag will\n# automatically be disabled.\n\n#WARN_IF_UNDOCUMENTED   = YES\nWARN_IF_UNDOCUMENTED   = YES\n\n# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for\n# potential errors in the documentation, such as not documenting some\n# parameters in a documented function, or documenting parameters that\n# don't exist or using markup commands wrongly.\n\nWARN_IF_DOC_ERROR      = YES\n\n# The WARN_NO_PARAMDOC option can be enabled to get warnings for\n# functions that are documented, but have no documentation for their parameters\n# or return value. If set to NO (the default) doxygen will only warn about\n# wrong or incomplete parameter documentation, but not about the absence of\n# documentation.\n\nWARN_NO_PARAMDOC       = NO\n\n# The WARN_FORMAT tag determines the format of the warning messages that\n# doxygen can produce. The string should contain the $file, $line, and $text\n# tags, which will be replaced by the file and line number from which the\n# warning originated and the warning text. Optionally the format may contain\n# $version, which will be replaced by the version of the file (if it could\n# be obtained via FILE_VERSION_FILTER)\n\nWARN_FORMAT            = \"$file:$line: $text\"\n\n# The WARN_LOGFILE tag can be used to specify a file to which warning\n# and error messages should be written. If left blank the output is written\n# to stderr.\n\nWARN_LOGFILE           =\n\n#---------------------------------------------------------------------------\n# configuration options related to the input files\n#---------------------------------------------------------------------------\n\n# The INPUT tag can be used to specify the files and/or directories that contain\n# documented source files. You may enter file names like \"myfile.cpp\" or\n# directories like \"/usr/src/myproject\". Separate the files or directories\n# with spaces.\n\nINPUT                  = core include libc arch drivers\n\n# This tag can be used to specify the character encoding of the source files\n# that doxygen parses. Internally doxygen uses the UTF-8 encoding, which is\n# also the default input encoding. Doxygen uses libiconv (or the iconv built\n# into libc) for the transcoding. See http://www.gnu.org/software/libiconv for\n# the list of possible encodings.\n\nINPUT_ENCODING         = UTF-8\n\n# If the value of the INPUT tag contains directories, you can use the\n# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp\n# and *.h) to filter out the source-files in the directories. If left\n# blank the following patterns are tested:\n# *.c *.cc *.cxx *.cpp *.c++ *.d *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh\n# *.hxx *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.dox *.py\n# *.f90 *.f *.for *.vhd *.vhdl\n\nFILE_PATTERNS          = *.cc *.hh *.c *.h\n\n# The RECURSIVE tag can be used to turn specify whether or not subdirectories\n# should be searched for input files as well. Possible values are YES and NO.\n# If left blank NO is used.\n\n#RECURSIVE              = NO\nRECURSIVE              = YES\n\n# The EXCLUDE tag can be used to specify files and/or directories that should be\n# excluded from the INPUT source files. This way you can easily exclude a\n# subdirectory from a directory tree whose root is specified with the INPUT tag.\n# Note that relative paths are relative to the directory from which doxygen is\n# run.\n\nEXCLUDE                = drivers/libtsm\n\n# The EXCLUDE_SYMLINKS tag can be used to select whether or not files or\n# directories that are symbolic links (a Unix file system feature) are excluded\n# from the input.\n\nEXCLUDE_SYMLINKS       = NO\n\n# If the value of the INPUT tag contains directories, you can use the\n# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude\n# certain files from those directories. Note that the wildcards are matched\n# against the file with absolute path, so to exclude all test directories\n# for example use the pattern */test/*\n\nEXCLUDE_PATTERNS       =\n\n# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names\n# (namespaces, classes, functions, etc.) that should be excluded from the\n# output. The symbol name can be a fully qualified name, a word, or if the\n# wildcard * is used, a substring. Examples: ANamespace, AClass,\n# AClass::ANamespace, ANamespace::*Test\n\nEXCLUDE_SYMBOLS        =\n\n# The EXAMPLE_PATH tag can be used to specify one or more files or\n# directories that contain example code fragments that are included (see\n# the \\include command).\n\nEXAMPLE_PATH           =\n\n# If the value of the EXAMPLE_PATH tag contains directories, you can use the\n# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp\n# and *.h) to filter out the source-files in the directories. If left\n# blank all files are included.\n\nEXAMPLE_PATTERNS       =\n\n# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be\n# searched for input files to be used with the \\include or \\dontinclude\n# commands irrespective of the value of the RECURSIVE tag.\n# Possible values are YES and NO. If left blank NO is used.\n\nEXAMPLE_RECURSIVE      = NO\n\n# The IMAGE_PATH tag can be used to specify one or more files or\n# directories that contain image that are included in the documentation (see\n# the \\image command).\n\nIMAGE_PATH             =\n\n# The INPUT_FILTER tag can be used to specify a program that doxygen should\n# invoke to filter for each input file. Doxygen will invoke the filter program\n# by executing (via popen()) the command <filter> <input-file>, where <filter>\n# is the value of the INPUT_FILTER tag, and <input-file> is the name of an\n# input file. Doxygen will then use the output that the filter program writes\n# to standard output.\n# If FILTER_PATTERNS is specified, this tag will be\n# ignored.\n\nINPUT_FILTER           =\n\n# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern\n# basis.\n# Doxygen will compare the file name with each pattern and apply the\n# filter if there is a match.\n# The filters are a list of the form:\n# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further\n# info on how filters are used. If FILTER_PATTERNS is empty or if\n# non of the patterns match the file name, INPUT_FILTER is applied.\n\nFILTER_PATTERNS        =\n\n# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using\n# INPUT_FILTER) will be used to filter the input files when producing source\n# files to browse (i.e. when SOURCE_BROWSER is set to YES).\n\nFILTER_SOURCE_FILES    = NO\n\n# The FILTER_SOURCE_PATTERNS tag can be used to specify source filters per file\n# pattern. A pattern will override the setting for FILTER_PATTERN (if any)\n# and it is also possible to disable source filtering for a specific pattern\n# using *.ext= (so without naming a filter). This option only has effect when\n# FILTER_SOURCE_FILES is enabled.\n\nFILTER_SOURCE_PATTERNS =\n\n# If the USE_MD_FILE_AS_MAINPAGE tag refers to the name of a markdown file that\n# is part of the input, its contents will be placed on the main page (index.html).\n# This can be useful if you have a project on for instance GitHub and want reuse\n# the introduction page also for the doxygen output.\n\nUSE_MDFILE_AS_MAINPAGE =\n\n#---------------------------------------------------------------------------\n# configuration options related to source browsing\n#---------------------------------------------------------------------------\n\n# If the SOURCE_BROWSER tag is set to YES then a list of source files will\n# be generated. Documented entities will be cross-referenced with these sources.\n# Note: To get rid of all source code in the generated output, make sure also\n# VERBATIM_HEADERS is set to NO.\n\nSOURCE_BROWSER         = NO\n\n# Setting the INLINE_SOURCES tag to YES will include the body\n# of functions and classes directly in the documentation.\n\nINLINE_SOURCES         = NO\n\n# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct\n# doxygen to hide any special comment blocks from generated source code\n# fragments. Normal C, C++ and Fortran comments will always remain visible.\n\nSTRIP_CODE_COMMENTS    = YES\n\n# If the REFERENCED_BY_RELATION tag is set to YES\n# then for each documented function all documented\n# functions referencing it will be listed.\n\nREFERENCED_BY_RELATION = NO\n\n# If the REFERENCES_RELATION tag is set to YES\n# then for each documented function all documented entities\n# called/used by that function will be listed.\n\nREFERENCES_RELATION    = NO\n\n# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)\n# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from\n# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will\n# link to the source code.\n# Otherwise they will link to the documentation.\n\nREFERENCES_LINK_SOURCE = YES\n\n# If the USE_HTAGS tag is set to YES then the references to source code\n# will point to the HTML generated by the htags(1) tool instead of doxygen\n# built-in source browser. The htags tool is part of GNU's global source\n# tagging system (see http://www.gnu.org/software/global/global.html). You\n# will need version 4.8.6 or higher.\n\nUSE_HTAGS              = NO\n\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen\n# will generate a verbatim copy of the header file for each class for\n# which an include is specified. Set to NO to disable this.\n\nVERBATIM_HEADERS       = YES\n\n#---------------------------------------------------------------------------\n# configuration options related to the alphabetical class index\n#---------------------------------------------------------------------------\n\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index\n# of all compounds will be generated. Enable this if the project\n# contains a lot of classes, structs, unions or interfaces.\n\nALPHABETICAL_INDEX     = YES\n\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then\n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns\n# in which this list will be split (can be a number in the range [1..20])\n\nCOLS_IN_ALPHA_INDEX    = 5\n\n# In case all classes in a project start with a common prefix, all\n# classes will be put under the same header in the alphabetical index.\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that\n# should be ignored while generating the index headers.\n\nIGNORE_PREFIX          =\n\n#---------------------------------------------------------------------------\n# configuration options related to the HTML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will\n# generate HTML output.\n\nGENERATE_HTML          = YES\n\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put.\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\n# put in front of it. If left blank `html' will be used as the default path.\n\nHTML_OUTPUT            = html\n\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank\n# doxygen will generate files with .html extension.\n\nHTML_FILE_EXTENSION    = .html\n\n# The HTML_HEADER tag can be used to specify a personal HTML header for\n# each generated HTML page. If it is left blank doxygen will generate a\n# standard header. Note that when using a custom header you are responsible\n#  for the proper inclusion of any scripts and style sheets that doxygen\n# needs, which is dependent on the configuration options used.\n# It is advised to generate a default header using \"doxygen -w html\n# header.html footer.html stylesheet.css YourConfigFile\" and then modify\n# that header. Note that the header is subject to change so you typically\n# have to redo this when upgrading to a newer version of doxygen or when\n# changing the value of configuration settings such as GENERATE_TREEVIEW!\n\nHTML_HEADER            =\n\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for\n# each generated HTML page. If it is left blank doxygen will generate a\n# standard footer.\n\nHTML_FOOTER            =\n\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading\n# style sheet that is used by each HTML page. It can be used to\n# fine-tune the look of the HTML output. If left blank doxygen will\n# generate a default style sheet. Note that it is recommended to use\n# HTML_EXTRA_STYLESHEET instead of this one, as it is more robust and this\n# tag will in the future become obsolete.\n\nHTML_STYLESHEET        =\n\n# The HTML_EXTRA_STYLESHEET tag can be used to specify an additional\n# user-defined cascading style sheet that is included after the standard\n# style sheets created by doxygen. Using this option one can overrule\n# certain style aspects. This is preferred over using HTML_STYLESHEET\n# since it does not replace the standard style sheet and is therefor more\n# robust against future updates. Doxygen will copy the style sheet file to\n# the output directory.\n\nHTML_EXTRA_STYLESHEET  =\n\n# The HTML_EXTRA_FILES tag can be used to specify one or more extra images or\n# other source files which should be copied to the HTML output directory. Note\n# that these files will be copied to the base HTML output directory. Use the\n# $relpath$ marker in the HTML_HEADER and/or HTML_FOOTER files to load these\n# files. In the HTML_STYLESHEET file, use the file name only. Also note that\n# the files will be copied as-is; there are no commands or markers available.\n\nHTML_EXTRA_FILES       =\n\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output.\n# Doxygen will adjust the colors in the style sheet and background images\n# according to this color. Hue is specified as an angle on a colorwheel,\n# see http://en.wikipedia.org/wiki/Hue for more information.\n# For instance the value 0 represents red, 60 is yellow, 120 is green,\n# 180 is cyan, 240 is blue, 300 purple, and 360 is red again.\n# The allowed range is 0 to 359.\n\nHTML_COLORSTYLE_HUE    = 220\n\n# The HTML_COLORSTYLE_SAT tag controls the purity (or saturation) of\n# the colors in the HTML output. For a value of 0 the output will use\n# grayscales only. A value of 255 will produce the most vivid colors.\n\nHTML_COLORSTYLE_SAT    = 100\n\n# The HTML_COLORSTYLE_GAMMA tag controls the gamma correction applied to\n# the luminance component of the colors in the HTML output. Values below\n# 100 gradually make the output lighter, whereas values above 100 make\n# the output darker. The value divided by 100 is the actual gamma applied,\n# so 80 represents a gamma of 0.8, The value 220 represents a gamma of 2.2,\n# and 100 does not change the gamma.\n\nHTML_COLORSTYLE_GAMMA  = 80\n\n# If the HTML_TIMESTAMP tag is set to YES then the footer of each generated HTML\n# page will contain the date and time when the page was generated. Setting\n# this to NO can help when comparing the output of multiple runs.\n\nHTML_TIMESTAMP         = NO\n\n# If the HTML_DYNAMIC_SECTIONS tag is set to YES then the generated HTML\n# documentation will contain sections that can be hidden and shown after the\n# page has loaded.\n\nHTML_DYNAMIC_SECTIONS  = NO\n\n# With HTML_INDEX_NUM_ENTRIES one can control the preferred number of\n# entries shown in the various tree structured indices initially; the user\n# can expand and collapse entries dynamically later on. Doxygen will expand\n# the tree to such a level that at most the specified number of entries are\n# visible (unless a fully collapsed tree already exceeds this amount).\n# So setting the number of entries 1 will produce a full collapsed tree by\n# default. 0 is a special value representing an infinite number of entries\n# and will result in a full expanded tree by default.\n\nHTML_INDEX_NUM_ENTRIES = 100\n\n# If the GENERATE_DOCSET tag is set to YES, additional index files\n# will be generated that can be used as input for Apple's Xcode 3\n# integrated development environment, introduced with OSX 10.5 (Leopard).\n# To create a documentation set, doxygen will generate a Makefile in the\n# HTML output directory. Running make will produce the docset in that\n# directory and running \"make install\" will install the docset in\n# ~/Library/Developer/Shared/Documentation/DocSets so that Xcode will find\n# it at startup.\n# See http://developer.apple.com/tools/creatingdocsetswithdoxygen.html\n# for more information.\n\nGENERATE_DOCSET        = NO\n\n# When GENERATE_DOCSET tag is set to YES, this tag determines the name of the\n# feed. A documentation feed provides an umbrella under which multiple\n# documentation sets from a single provider (such as a company or product suite)\n# can be grouped.\n\nDOCSET_FEEDNAME        = \"Doxygen generated docs\"\n\n# When GENERATE_DOCSET tag is set to YES, this tag specifies a string that\n# should uniquely identify the documentation set bundle. This should be a\n# reverse domain-name style string, e.g. com.mycompany.MyDocSet. Doxygen\n# will append .docset to the name.\n\nDOCSET_BUNDLE_ID       = org.doxygen.Project\n\n# When GENERATE_PUBLISHER_ID tag specifies a string that should uniquely\n# identify the documentation publisher. This should be a reverse domain-name\n# style string, e.g. com.mycompany.MyDocSet.documentation.\n\nDOCSET_PUBLISHER_ID    = org.doxygen.Publisher\n\n# The GENERATE_PUBLISHER_NAME tag identifies the documentation publisher.\n\nDOCSET_PUBLISHER_NAME  = Publisher\n\n# If the GENERATE_HTMLHELP tag is set to YES, additional index files\n# will be generated that can be used as input for tools like the\n# Microsoft HTML help workshop to generate a compiled HTML help file (.chm)\n# of the generated HTML documentation.\n\nGENERATE_HTMLHELP      = NO\n\n# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can\n# be used to specify the file name of the resulting .chm file. You\n# can add a path in front of the file if the result should not be\n# written to the html output directory.\n\nCHM_FILE               =\n\n# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can\n# be used to specify the location (absolute path including file name) of\n# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run\n# the HTML help compiler on the generated index.hhp.\n\nHHC_LOCATION           =\n\n# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag\n# controls if a separate .chi index file is generated (YES) or that\n# it should be included in the master .chm file (NO).\n\nGENERATE_CHI           = NO\n\n# If the GENERATE_HTMLHELP tag is set to YES, the CHM_INDEX_ENCODING\n# is used to encode HtmlHelp index (hhk), content (hhc) and project file\n# content.\n\nCHM_INDEX_ENCODING     =\n\n# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag\n# controls whether a binary table of contents is generated (YES) or a\n# normal table of contents (NO) in the .chm file.\n\nBINARY_TOC             = NO\n\n# The TOC_EXPAND flag can be set to YES to add extra items for group members\n# to the contents of the HTML help documentation and to the tree view.\n\nTOC_EXPAND             = NO\n\n# If the GENERATE_QHP tag is set to YES and both QHP_NAMESPACE and\n# QHP_VIRTUAL_FOLDER are set, an additional index file will be generated\n# that can be used as input for Qt's qhelpgenerator to generate a\n# Qt Compressed Help (.qch) of the generated HTML documentation.\n\nGENERATE_QHP           = NO\n\n# If the QHG_LOCATION tag is specified, the QCH_FILE tag can\n# be used to specify the file name of the resulting .qch file.\n# The path specified is relative to the HTML output folder.\n\nQCH_FILE               =\n\n# The QHP_NAMESPACE tag specifies the namespace to use when generating\n# Qt Help Project output. For more information please see\n# http://doc.trolltech.com/qthelpproject.html#namespace\n\nQHP_NAMESPACE          = org.doxygen.Project\n\n# The QHP_VIRTUAL_FOLDER tag specifies the namespace to use when generating\n# Qt Help Project output. For more information please see\n# http://doc.trolltech.com/qthelpproject.html#virtual-folders\n\nQHP_VIRTUAL_FOLDER     = doc\n\n# If QHP_CUST_FILTER_NAME is set, it specifies the name of a custom filter to\n# add. For more information please see\n# http://doc.trolltech.com/qthelpproject.html#custom-filters\n\nQHP_CUST_FILTER_NAME   =\n\n# The QHP_CUST_FILT_ATTRS tag specifies the list of the attributes of the\n# custom filter to add. For more information please see\n# <a href=\"http://doc.trolltech.com/qthelpproject.html#custom-filters\">\n# Qt Help Project / Custom Filters</a>.\n\nQHP_CUST_FILTER_ATTRS  =\n\n# The QHP_SECT_FILTER_ATTRS tag specifies the list of the attributes this\n# project's\n# filter section matches.\n# <a href=\"http://doc.trolltech.com/qthelpproject.html#filter-attributes\">\n# Qt Help Project / Filter Attributes</a>.\n\nQHP_SECT_FILTER_ATTRS  =\n\n# If the GENERATE_QHP tag is set to YES, the QHG_LOCATION tag can\n# be used to specify the location of Qt's qhelpgenerator.\n# If non-empty doxygen will try to run qhelpgenerator on the generated\n# .qhp file.\n\nQHG_LOCATION           =\n\n# If the GENERATE_ECLIPSEHELP tag is set to YES, additional index files\n#  will be generated, which together with the HTML files, form an Eclipse help\n# plugin. To install this plugin and make it available under the help contents\n# menu in Eclipse, the contents of the directory containing the HTML and XML\n# files needs to be copied into the plugins directory of eclipse. The name of\n# the directory within the plugins directory should be the same as\n# the ECLIPSE_DOC_ID value. After copying Eclipse needs to be restarted before\n# the help appears.\n\nGENERATE_ECLIPSEHELP   = NO\n\n# A unique identifier for the eclipse help plugin. When installing the plugin\n# the directory name containing the HTML and XML files should also have\n# this name.\n\nECLIPSE_DOC_ID         = org.doxygen.Project\n\n# The DISABLE_INDEX tag can be used to turn on/off the condensed index (tabs)\n# at top of each HTML page. The value NO (the default) enables the index and\n# the value YES disables it. Since the tabs have the same information as the\n# navigation tree you can set this option to NO if you already set\n# GENERATE_TREEVIEW to YES.\n\nDISABLE_INDEX          = NO\n\n# The GENERATE_TREEVIEW tag is used to specify whether a tree-like index\n# structure should be generated to display hierarchical information.\n# If the tag value is set to YES, a side panel will be generated\n# containing a tree-like index structure (just like the one that\n# is generated for HTML Help). For this to work a browser that supports\n# JavaScript, DHTML, CSS and frames is required (i.e. any modern browser).\n# Windows users are probably better off using the HTML help feature.\n# Since the tree basically has the same information as the tab index you\n# could consider to set DISABLE_INDEX to NO when enabling this option.\n\nGENERATE_TREEVIEW      = NO\n\n# The ENUM_VALUES_PER_LINE tag can be used to set the number of enum values\n# (range [0,1..20]) that doxygen will group on one line in the generated HTML\n# documentation. Note that a value of 0 will completely suppress the enum\n# values from appearing in the overview section.\n\nENUM_VALUES_PER_LINE   = 4\n\n# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be\n# used to set the initial width (in pixels) of the frame in which the tree\n# is shown.\n\nTREEVIEW_WIDTH         = 250\n\n# When the EXT_LINKS_IN_WINDOW option is set to YES doxygen will open\n# links to external symbols imported via tag files in a separate window.\n\nEXT_LINKS_IN_WINDOW    = NO\n\n# Use this tag to change the font size of Latex formulas included\n# as images in the HTML documentation. The default is 10. Note that\n# when you change the font size after a successful doxygen run you need\n# to manually remove any form_*.png images from the HTML output directory\n# to force them to be regenerated.\n\nFORMULA_FONTSIZE       = 10\n\n# Use the FORMULA_TRANPARENT tag to determine whether or not the images\n# generated for formulas are transparent PNGs. Transparent PNGs are\n# not supported properly for IE 6.0, but are supported on all modern browsers.\n# Note that when changing this option you need to delete any form_*.png files\n# in the HTML output before the changes have effect.\n\nFORMULA_TRANSPARENT    = YES\n\n# Enable the USE_MATHJAX option to render LaTeX formulas using MathJax\n# (see http://www.mathjax.org) which uses client side Javascript for the\n# rendering instead of using prerendered bitmaps. Use this if you do not\n# have LaTeX installed or if you want to formulas look prettier in the HTML\n# output. When enabled you may also need to install MathJax separately and\n# configure the path to it using the MATHJAX_RELPATH option.\n\nUSE_MATHJAX            = NO\n\n# When MathJax is enabled you can set the default output format to be used for\n# thA MathJax output. Supported types are HTML-CSS, NativeMML (i.e. MathML) and\n# SVG. The default value is HTML-CSS, which is slower, but has the best\n# compatibility.\n\nMATHJAX_FORMAT         = HTML-CSS\n\n# When MathJax is enabled you need to specify the location relative to the\n# HTML output directory using the MATHJAX_RELPATH option. The destination\n# directory should contain the MathJax.js script. For instance, if the mathjax\n# directory is located at the same level as the HTML output directory, then\n# MATHJAX_RELPATH should be ../mathjax. The default value points to\n# the MathJax Content Delivery Network so you can quickly see the result without\n# installing MathJax.\n# However, it is strongly recommended to install a local\n# copy of MathJax from http://www.mathjax.org before deployment.\n\nMATHJAX_RELPATH        = http://cdn.mathjax.org/mathjax/latest\n\n# The MATHJAX_EXTENSIONS tag can be used to specify one or MathJax extension\n# names that should be enabled during MathJax rendering.\n\nMATHJAX_EXTENSIONS     =\n\n# When the SEARCHENGINE tag is enabled doxygen will generate a search box\n# for the HTML output. The underlying search engine uses javascript\n# and DHTML and should work on any modern browser. Note that when using\n# HTML help (GENERATE_HTMLHELP), Qt help (GENERATE_QHP), or docsets\n# (GENERATE_DOCSET) there is already a search function so this one should\n# typically be disabled. For large projects the javascript based search engine\n# can be slow, then enabling SERVER_BASED_SEARCH may provide a better solution.\n\nSEARCHENGINE           = YES\n\n# When the SERVER_BASED_SEARCH tag is enabled the search engine will be\n# implemented using a web server instead of a web client using Javascript.\n# There are two flavours of web server based search depending on the\n# EXTERNAL_SEARCH setting. When disabled, doxygen will generate a PHP script for\n# searching and an index file used by the script. When EXTERNAL_SEARCH is\n# enabled the indexing and searching needs to be provided by external tools.\n# See the manual for details.\n\nSERVER_BASED_SEARCH    = NO\n\n# When EXTERNAL_SEARCH is enabled doxygen will no longer generate the PHP\n# script for searching. Instead the search results are written to an XML file\n# which needs to be processed by an external indexer. Doxygen will invoke an\n# external search engine pointed to by the SEARCHENGINE_URL option to obtain\n# the search results. Doxygen ships with an example indexer (doxyindexer) and\n# search engine (doxysearch.cgi) which are based on the open source search engine\n# library Xapian. See the manual for configuration details.\n\nEXTERNAL_SEARCH        = NO\n\n# The SEARCHENGINE_URL should point to a search engine hosted by a web server\n# which will returned the search results when EXTERNAL_SEARCH is enabled.\n# Doxygen ships with an example search engine (doxysearch) which is based on\n# the open source search engine library Xapian. See the manual for configuration\n# details.\n\nSEARCHENGINE_URL       =\n\n# When SERVER_BASED_SEARCH and EXTERNAL_SEARCH are both enabled the unindexed\n# search data is written to a file for indexing by an external tool. With the\n# SEARCHDATA_FILE tag the name of this file can be specified.\n\nSEARCHDATA_FILE        = searchdata.xml\n\n# When SERVER_BASED_SEARCH AND EXTERNAL_SEARCH are both enabled the\n# EXTERNAL_SEARCH_ID tag can be used as an identifier for the project. This is\n# useful in combination with EXTRA_SEARCH_MAPPINGS to search through multiple\n# projects and redirect the results back to the right project.\n\nEXTERNAL_SEARCH_ID     =\n\n# The EXTRA_SEARCH_MAPPINGS tag can be used to enable searching through doxygen\n# projects other than the one defined by this configuration file, but that are\n# all added to the same external search index. Each project needs to have a\n# unique id set via EXTERNAL_SEARCH_ID. The search mapping then maps the id\n# of to a relative location where the documentation can be found.\n# The format is: EXTRA_SEARCH_MAPPINGS = id1=loc1 id2=loc2 ...\n\nEXTRA_SEARCH_MAPPINGS  =\n\n#---------------------------------------------------------------------------\n# configuration options related to the LaTeX output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will\n# generate Latex output.\n\nGENERATE_LATEX         = YES\n\n# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put.\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\n# put in front of it. If left blank `latex' will be used as the default path.\n\nLATEX_OUTPUT           = latex\n\n# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be\n# invoked. If left blank `latex' will be used as the default command name.\n# Note that when enabling USE_PDFLATEX this option is only used for\n# generating bitmaps for formulas in the HTML output, but not in the\n# Makefile that is written to the output directory.\n\nLATEX_CMD_NAME         = latex\n\n# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to\n# generate index for LaTeX. If left blank `makeindex' will be used as the\n# default command name.\n\nMAKEINDEX_CMD_NAME     = makeindex\n\n# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact\n# LaTeX documents. This may be useful for small projects and may help to\n# save some trees in general.\n\nCOMPACT_LATEX          = NO\n\n# The PAPER_TYPE tag can be used to set the paper type that is used\n# by the printer. Possible values are: a4, letter, legal and\n# executive. If left blank a4wide will be used.\n\nPAPER_TYPE             = a4\n\n# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX\n# packages that should be included in the LaTeX output.\n\nEXTRA_PACKAGES         =\n\n# The LATEX_HEADER tag can be used to specify a personal LaTeX header for\n# the generated latex document. The header should contain everything until\n# the first chapter. If it is left blank doxygen will generate a\n# standard header. Notice: only use this tag if you know what you are doing!\n\nLATEX_HEADER           =\n\n# The LATEX_FOOTER tag can be used to specify a personal LaTeX footer for\n# the generated latex document. The footer should contain everything after\n# the last chapter. If it is left blank doxygen will generate a\n# standard footer. Notice: only use this tag if you know what you are doing!\n\nLATEX_FOOTER           =\n\n# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated\n# is prepared for conversion to pdf (using ps2pdf). The pdf file will\n# contain links (just like the HTML output) instead of page references\n# This makes the output suitable for online browsing using a pdf viewer.\n\nPDF_HYPERLINKS         = YES\n\n# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of\n# plain latex in the generated Makefile. Set this option to YES to get a\n# higher quality PDF documentation.\n\nUSE_PDFLATEX           = YES\n\n# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\\\batchmode.\n# command to the generated LaTeX files. This will instruct LaTeX to keep\n# running if errors occur, instead of asking the user for help.\n# This option is also used when generating formulas in HTML.\n\nLATEX_BATCHMODE        = NO\n\n# If LATEX_HIDE_INDICES is set to YES then doxygen will not\n# include the index chapters (such as File Index, Compound Index, etc.)\n# in the output.\n\nLATEX_HIDE_INDICES     = NO\n\n# If LATEX_SOURCE_CODE is set to YES then doxygen will include\n# source code with syntax highlighting in the LaTeX output.\n# Note that which sources are shown also depends on other settings\n# such as SOURCE_BROWSER.\n\nLATEX_SOURCE_CODE      = NO\n\n# The LATEX_BIB_STYLE tag can be used to specify the style to use for the\n# bibliography, e.g. plainnat, or ieeetr. The default style is \"plain\". See\n# http://en.wikipedia.org/wiki/BibTeX for more info.\n\nLATEX_BIB_STYLE        = plain\n\n#---------------------------------------------------------------------------\n# configuration options related to the RTF output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output\n# The RTF output is optimized for Word 97 and may not look very pretty with\n# other RTF readers or editors.\n\nGENERATE_RTF           = NO\n\n# The RTF_OUTPUT tag is used to specify where the RTF docs will be put.\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\n# put in front of it. If left blank `rtf' will be used as the default path.\n\nRTF_OUTPUT             = rtf\n\n# If the COMPACT_RTF tag is set to YES Doxygen generates more compact\n# RTF documents. This may be useful for small projects and may help to\n# save some trees in general.\n\nCOMPACT_RTF            = NO\n\n# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated\n# will contain hyperlink fields. The RTF file will\n# contain links (just like the HTML output) instead of page references.\n# This makes the output suitable for online browsing using WORD or other\n# programs which support those fields.\n# Note: wordpad (write) and others do not support links.\n\nRTF_HYPERLINKS         = NO\n\n# Load style sheet definitions from file. Syntax is similar to doxygen's\n# config file, i.e. a series of assignments. You only have to provide\n# replacements, missing definitions are set to their default value.\n\nRTF_STYLESHEET_FILE    =\n\n# Set optional variables used in the generation of an rtf document.\n# Syntax is similar to doxygen's config file.\n\nRTF_EXTENSIONS_FILE    =\n\n#---------------------------------------------------------------------------\n# configuration options related to the man page output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_MAN tag is set to YES (the default) Doxygen will\n# generate man pages\n\nGENERATE_MAN           = NO\n\n# The MAN_OUTPUT tag is used to specify where the man pages will be put.\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\n# put in front of it. If left blank `man' will be used as the default path.\n\nMAN_OUTPUT             = man\n\n# The MAN_EXTENSION tag determines the extension that is added to\n# the generated man pages (default is the subroutine's section .3)\n\nMAN_EXTENSION          = .3\n\n# If the MAN_LINKS tag is set to YES and Doxygen generates man output,\n# then it will generate one additional man file for each entity\n# documented in the real man page(s). These additional files\n# only source the real man page, but without them the man command\n# would be unable to find the correct page. The default is NO.\n\nMAN_LINKS              = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the XML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_XML tag is set to YES Doxygen will\n# generate an XML file that captures the structure of\n# the code including all documentation.\n\nGENERATE_XML           = NO\n\n# The XML_OUTPUT tag is used to specify where the XML pages will be put.\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\n# put in front of it. If left blank `xml' will be used as the default path.\n\nXML_OUTPUT             = xml\n\n# The XML_SCHEMA tag can be used to specify an XML schema,\n# which can be used by a validating XML parser to check the\n# syntax of the XML files.\n\nXML_SCHEMA             =\n\n# The XML_DTD tag can be used to specify an XML DTD,\n# which can be used by a validating XML parser to check the\n# syntax of the XML files.\n\nXML_DTD                =\n\n# If the XML_PROGRAMLISTING tag is set to YES Doxygen will\n# dump the program listings (including syntax highlighting\n# and cross-referencing information) to the XML output. Note that\n# enabling this will significantly increase the size of the XML output.\n\nXML_PROGRAMLISTING     = YES\n\n#---------------------------------------------------------------------------\n# configuration options for the AutoGen Definitions output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will\n# generate an AutoGen Definitions (see autogen.sf.net) file\n# that captures the structure of the code including all\n# documentation. Note that this feature is still experimental\n# and incomplete at the moment.\n\nGENERATE_AUTOGEN_DEF   = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the Perl module output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_PERLMOD tag is set to YES Doxygen will\n# generate a Perl module file that captures the structure of\n# the code including all documentation. Note that this\n# feature is still experimental and incomplete at the\n# moment.\n\nGENERATE_PERLMOD       = NO\n\n# If the PERLMOD_LATEX tag is set to YES Doxygen will generate\n# the necessary Makefile rules, Perl scripts and LaTeX code to be able\n# to generate PDF and DVI output from the Perl module output.\n\nPERLMOD_LATEX          = NO\n\n# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be\n# nicely formatted so it can be parsed by a human reader.\n# This is useful\n# if you want to understand what is going on.\n# On the other hand, if this\n# tag is set to NO the size of the Perl module output will be much smaller\n# and Perl will parse it just the same.\n\nPERLMOD_PRETTY         = YES\n\n# The names of the make variables in the generated doxyrules.make file\n# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX.\n# This is useful so different doxyrules.make files included by the same\n# Makefile don't overwrite each other's variables.\n\nPERLMOD_MAKEVAR_PREFIX =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the preprocessor\n#---------------------------------------------------------------------------\n\n# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will\n# evaluate all C-preprocessor directives found in the sources and include\n# files.\n\nENABLE_PREPROCESSING   = YES\n\n# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro\n# names in the source code. If set to NO (the default) only conditional\n# compilation will be performed. Macro expansion can be done in a controlled\n# way by setting EXPAND_ONLY_PREDEF to YES.\n\nMACRO_EXPANSION        = NO\n\n# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES\n# then the macro expansion is limited to the macros specified with the\n# PREDEFINED and EXPAND_AS_DEFINED tags.\n\nEXPAND_ONLY_PREDEF     = NO\n\n# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files\n# pointed to by INCLUDE_PATH will be searched when a #include is found.\n\nSEARCH_INCLUDES        = YES\n\n# The INCLUDE_PATH tag can be used to specify one or more directories that\n# contain include files that are not input files but should be processed by\n# the preprocessor.\n\nINCLUDE_PATH           =\n\n# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard\n# patterns (like *.h and *.hpp) to filter out the header-files in the\n# directories. If left blank, the patterns specified with FILE_PATTERNS will\n# be used.\n\nINCLUDE_FILE_PATTERNS  =\n\n# The PREDEFINED tag can be used to specify one or more macro names that\n# are defined before the preprocessor is started (similar to the -D option of\n# gcc). The argument of the tag is a list of macros of the form: name\n# or name=definition (no spaces). If the definition and the = are\n# omitted =1 is assumed. To prevent a macro definition from being\n# undefined via #undef or recursively expanded use the := operator\n# instead of the = operator.\n\nPREDEFINED             = __cplusplus\n\n# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then\n# this tag can be used to specify a list of macro names that should be expanded.\n# The macro definition that is found in the sources will be used.\n# Use the PREDEFINED tag if you want to use a different macro definition that\n# overrules the definition found in the source code.\n\nEXPAND_AS_DEFINED      =\n\n# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then\n# doxygen's preprocessor will remove all references to function-like macros\n# that are alone on a line, have an all uppercase name, and do not end with a\n# semicolon, because these will confuse the parser if not removed.\n\nSKIP_FUNCTION_MACROS   = YES\n\n#---------------------------------------------------------------------------\n# Configuration::additions related to external references\n#---------------------------------------------------------------------------\n\n# The TAGFILES option can be used to specify one or more tagfiles. For each\n# tag file the location of the external documentation should be added. The\n# format of a tag file without this location is as follows:\n#\n# TAGFILES = file1 file2 ...\n# Adding location for the tag files is done as follows:\n#\n# TAGFILES = file1=loc1 \"file2 = loc2\" ...\n# where \"loc1\" and \"loc2\" can be relative or absolute paths\n# or URLs. Note that each tag file must have a unique name (where the name does\n# NOT include the path). If a tag file is not located in the directory in which\n# doxygen is run, you must also specify the path to the tagfile here.\n\nTAGFILES               =\n\n# When a file name is specified after GENERATE_TAGFILE, doxygen will create\n# a tag file that is based on the input files it reads.\n\nGENERATE_TAGFILE       =\n\n# If the ALLEXTERNALS tag is set to YES all external classes will be listed\n# in the class index. If set to NO only the inherited external classes\n# will be listed.\n\nALLEXTERNALS           = NO\n\n# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed\n# in the modules index. If set to NO, only the current project's groups will\n# be listed.\n\nEXTERNAL_GROUPS        = YES\n\n# The PERL_PATH should be the absolute path and name of the perl script\n# interpreter (i.e. the result of `which perl').\n\nPERL_PATH              = /usr/bin/perl\n\n#---------------------------------------------------------------------------\n# Configuration options related to the dot tool\n#---------------------------------------------------------------------------\n\n# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will\n# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base\n# or super classes. Setting the tag to NO turns the diagrams off. Note that\n# this option also works with HAVE_DOT disabled, but it is recommended to\n# install and use dot, since it yields more powerful graphs.\n\nCLASS_DIAGRAMS         = YES\n\n# You can define message sequence charts within doxygen comments using the \\msc\n# command. Doxygen will then run the mscgen tool (see\n# http://www.mcternan.me.uk/mscgen/) to produce the chart and insert it in the\n# documentation. The MSCGEN_PATH tag allows you to specify the directory where\n# the mscgen tool resides. If left empty the tool is assumed to be found in the\n# default search path.\n\nMSCGEN_PATH            =\n\n# If set to YES, the inheritance and collaboration graphs will hide\n# inheritance and usage relations if the target is undocumented\n# or is not a class.\n\nHIDE_UNDOC_RELATIONS   = YES\n\n# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is\n# available from the path. This tool is part of Graphviz, a graph visualization\n# toolkit from AT&T and Lucent Bell Labs. The other options in this section\n# have no effect if this option is set to NO (the default)\n\nHAVE_DOT               = NO\n\n# The DOT_NUM_THREADS specifies the number of dot invocations doxygen is\n# allowed to run in parallel. When set to 0 (the default) doxygen will\n# base this on the number of processors available in the system. You can set it\n# explicitly to a value larger than 0 to get control over the balance\n# between CPU load and processing speed.\n\nDOT_NUM_THREADS        = 0\n\n# By default doxygen will use the Helvetica font for all dot files that\n# doxygen generates. When you want a differently looking font you can specify\n# the font name using DOT_FONTNAME. You need to make sure dot is able to find\n# the font, which can be done by putting it in a standard location or by setting\n# the DOTFONTPATH environment variable or by setting DOT_FONTPATH to the\n# directory containing the font.\n\nDOT_FONTNAME           = Helvetica\n\n# The DOT_FONTSIZE tag can be used to set the size of the font of dot graphs.\n# The default size is 10pt.\n\nDOT_FONTSIZE           = 10\n\n# By default doxygen will tell dot to use the Helvetica font.\n# If you specify a different font using DOT_FONTNAME you can use DOT_FONTPATH to\n# set the path where dot can find it.\n\nDOT_FONTPATH           =\n\n# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen\n# will generate a graph for each documented class showing the direct and\n# indirect inheritance relations. Setting this tag to YES will force the\n# CLASS_DIAGRAMS tag to NO.\n\nCLASS_GRAPH            = YES\n\n# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen\n# will generate a graph for each documented class showing the direct and\n# indirect implementation dependencies (inheritance, containment, and\n# class references variables) of the class with other documented classes.\n\nCOLLABORATION_GRAPH    = YES\n\n# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen\n# will generate a graph for groups, showing the direct groups dependencies\n\nGROUP_GRAPHS           = YES\n\n# If the UML_LOOK tag is set to YES doxygen will generate inheritance and\n# collaboration diagrams in a style similar to the OMG's Unified Modeling\n# Language.\n\nUML_LOOK               = NO\n\n# If the UML_LOOK tag is enabled, the fields and methods are shown inside\n# the class node. If there are many fields or methods and many nodes the\n# graph may become too big to be useful. The UML_LIMIT_NUM_FIELDS\n# threshold limits the number of items for each type to make the size more\n# managable. Set this to 0 for no limit. Note that the threshold may be\n# exceeded by 50% before the limit is enforced.\n\nUML_LIMIT_NUM_FIELDS   = 10\n\n# If set to YES, the inheritance and collaboration graphs will show the\n# relations between templates and their instances.\n\nTEMPLATE_RELATIONS     = NO\n\n# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT\n# tags are set to YES then doxygen will generate a graph for each documented\n# file showing the direct and indirect include dependencies of the file with\n# other documented files.\n\nINCLUDE_GRAPH          = YES\n\n# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and\n# HAVE_DOT tags are set to YES then doxygen will generate a graph for each\n# documented header file showing the documented files that directly or\n# indirectly include this file.\n\nINCLUDED_BY_GRAPH      = YES\n\n# If the CALL_GRAPH and HAVE_DOT options are set to YES then\n# doxygen will generate a call dependency graph for every global function\n# or class method. Note that enabling this option will significantly increase\n# the time of a run. So in most cases it will be better to enable call graphs\n# for selected functions only using the \\callgraph command.\n\nCALL_GRAPH             = NO\n\n# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then\n# doxygen will generate a caller dependency graph for every global function\n# or class method. Note that enabling this option will significantly increase\n# the time of a run. So in most cases it will be better to enable caller\n# graphs for selected functions only using the \\callergraph command.\n\nCALLER_GRAPH           = NO\n\n# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen\n# will generate a graphical hierarchy of all classes instead of a textual one.\n\nGRAPHICAL_HIERARCHY    = YES\n\n# If the DIRECTORY_GRAPH and HAVE_DOT tags are set to YES\n# then doxygen will show the dependencies a directory has on other directories\n# in a graphical way. The dependency relations are determined by the #include\n# relations between the files in the directories.\n\nDIRECTORY_GRAPH        = YES\n\n# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images\n# generated by dot. Possible values are svg, png, jpg, or gif.\n# If left blank png will be used. If you choose svg you need to set\n# HTML_FILE_EXTENSION to xhtml in order to make the SVG files\n# visible in IE 9+ (other browsers do not have this requirement).\n\nDOT_IMAGE_FORMAT       = png\n\n# If DOT_IMAGE_FORMAT is set to svg, then this option can be set to YES to\n# enable generation of interactive SVG images that allow zooming and panning.\n# Note that this requires a modern browser other than Internet Explorer.\n# Tested and working are Firefox, Chrome, Safari, and Opera. For IE 9+ you\n# need to set HTML_FILE_EXTENSION to xhtml in order to make the SVG files\n# visible. Older versions of IE do not have SVG support.\n\nINTERACTIVE_SVG        = NO\n\n# The tag DOT_PATH can be used to specify the path where the dot tool can be\n# found. If left blank, it is assumed the dot tool can be found in the path.\n\nDOT_PATH               =\n\n# The DOTFILE_DIRS tag can be used to specify one or more directories that\n# contain dot files that are included in the documentation (see the\n# \\dotfile command).\n\nDOTFILE_DIRS           =\n\n# The MSCFILE_DIRS tag can be used to specify one or more directories that\n# contain msc files that are included in the documentation (see the\n# \\mscfile command).\n\nMSCFILE_DIRS           =\n\n# The DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of\n# nodes that will be shown in the graph. If the number of nodes in a graph\n# becomes larger than this value, doxygen will truncate the graph, which is\n# visualized by representing a node as a red box. Note that doxygen if the\n# number of direct children of the root node in a graph is already larger than\n# DOT_GRAPH_MAX_NODES then the graph will not be shown at all. Also note\n# that the size of a graph can be further restricted by MAX_DOT_GRAPH_DEPTH.\n\nDOT_GRAPH_MAX_NODES    = 50\n\n# The MAX_DOT_GRAPH_DEPTH tag can be used to set the maximum depth of the\n# graphs generated by dot. A depth value of 3 means that only nodes reachable\n# from the root by following a path via at most 3 edges will be shown. Nodes\n# that lay further from the root node will be omitted. Note that setting this\n# option to 1 or 2 may greatly reduce the computation time needed for large\n# code bases. Also note that the size of a graph can be further restricted by\n# DOT_GRAPH_MAX_NODES. Using a depth of 0 means no depth restriction.\n\nMAX_DOT_GRAPH_DEPTH    = 0\n\n# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent\n# background. This is disabled by default, because dot on Windows does not\n# seem to support this out of the box. Warning: Depending on the platform used,\n# enabling this option may lead to badly anti-aliased labels on the edges of\n# a graph (i.e. they become hard to read).\n\nDOT_TRANSPARENT        = NO\n\n# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output\n# files in one run (i.e. multiple -o and -T options on the command line). This\n# makes dot run faster, but since only newer versions of dot (>1.8.10)\n# support this, this feature is disabled by default.\n\nDOT_MULTI_TARGETS      = NO\n\n# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will\n# generate a legend page explaining the meaning of the various boxes and\n# arrows in the dot generated graphs.\n\nGENERATE_LEGEND        = YES\n\n# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will\n# remove the intermediate dot files that are used to generate\n# the various graphs.\n\nDOT_CLEANUP            = YES\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.0595703125,
          "content": "Copyright (C) 2013 Cloudius Systems, Ltd.\n\nParts are copyright by other contributors. Please refer to copyright notices\nin the individual source files, and to the git commit log, for a more accurate\nlist of copyright holders.\n\nOSv is open-source software, distributed under the 3-clause BSD license:\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright notice,\n      this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n\n    * Neither the name of the Cloudius Systems, Ltd. nor the names of its\n      contributors may be used to endorse or promote products derived from this\n      software without specific prior written permission.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n    DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n    FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n    DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n    CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n    OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nThis project also includes source code adopted and adapted from four other\nopen-source projects - FreeBSD, OpenSolaris, Prex and Musl. These projects have\ntheir own licenses. Please refer to the files documentation/LICENSE-*\nfor the licenses and copyright statements of these projects.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 87.9052734375,
          "content": "# OSv makefile\n#\n# Copyright (C) 2015 Cloudius Systems, Ltd.\n# This work is open source software, licensed under the terms of the\n# BSD license as described in the LICENSE file in the top-level directory.\n\n# Delete the builtin make rules, as if \"make -r\" was used.\n.SUFFIXES:\n\n# Ask make to not delete \"intermediate\" results, such as the .o in the chain\n# .cc -> .o -> .so. Otherwise, during the first build, make considers the .o\n# to be intermediate, and deletes it, but the newly-created \".d\" files lists\n# the \".o\" as a target - so it needs to be created again on the second make.\n# See commit fac05c95 for a longer explanation.\n.SECONDARY:\n\n# Deleting partially-build targets on error should be the default, but it\n# isn't, for historical reasons, so we need to turn it on explicitly...\n.DELETE_ON_ERROR:\n###########################################################################\n# Backward-compatibility hack to support the old \"make ... image=...\" image\n# building syntax, and pass it into scripts/build. We should eventually drop\n# this support and turn the deprecated messages into errors.\ncompat_args=$(if $(usrskel), usrskel=$(usrskel),)\ncompat_args+=$(if $(fs), fs=$(fs),)\nifdef image\n#$(error Please use scripts/build to build images)\n$(info \"make image=...\" deprecated. Please use \"scripts/build image=...\".)\ndefault_target:\n\t./scripts/build image=$(image) $(compat_args)\nendif\nifdef modules\n#$(error Please use scripts/build to build images)\n$(info \"make modules=...\" deprecated. Please use \"scripts/build modules=...\".)\ndefault_target:\n\t./scripts/build modules=$(modules) $(compat_args)\nendif\n.PHONY: default_target\n\n###########################################################################\n\ninclude conf/base.mk\n\n# The build mode defaults to \"release\" (optimized build), the other option\n# is \"debug\" (unoptimized build). In the latter the optimizer interferes\n# less with the debugging, but the release build is fully debuggable too.\nmode=release\nifeq (,$(wildcard conf/$(mode).mk))\n    $(error unsupported mode $(mode))\nendif\ninclude conf/$(mode).mk\n\n\n# By default, detect HOST_CXX's architecture - x64 or aarch64.\n# But also allow the user to specify a cross-compiled target architecture\n# by setting either \"ARCH\" or \"arch\" in the make command line, or the \"ARCH\"\n# environment variable.\nHOST_CXX := g++\n\ndetect_arch = $(word 1, $(shell { echo \"x64        __x86_64__\";  \\\n                                  echo \"aarch64    __aarch64__\"; \\\n                       } | $1 -E -xc - | grep ' 1$$'))\n\nhost_arch := $(call detect_arch, $(HOST_CXX))\n\n# As an alternative to setting ARCH or arch, let's allow the user to\n# directly set the CROSS_PREFIX environment variable, and learn its arch:\nifdef CROSS_PREFIX\n    ARCH := $(call detect_arch, $(CROSS_PREFIX)gcc)\nendif\n\nifndef ARCH\n    ARCH := $(host_arch)\nendif\narch := $(ARCH)\n\n# ARCH_STR is like ARCH, but uses the full name x86_64 instead of x64\nARCH_STR := $(arch:x64=x86_64)\n\nifeq (,$(wildcard conf/$(arch).mk))\n    $(error unsupported architecture $(arch))\nendif\ninclude conf/$(arch).mk\n\nCROSS_PREFIX ?= $(if $(filter-out $(arch),$(host_arch)),$(arch)-linux-gnu-)\nCXX=$(CROSS_PREFIX)g++\nCC=$(CROSS_PREFIX)gcc\nLD=$(CROSS_PREFIX)ld.bfd\nexport STRIP=$(CROSS_PREFIX)strip\nOBJCOPY=$(CROSS_PREFIX)objcopy\n\n# Our makefile puts all compilation results in a single directory, $(out),\n# instead of mixing them with the source code. This allows us to compile\n# different variants of the code - for different mode (release or debug)\n# or arch (x86 or aarch64) side by side. It also makes \"make clean\" very\n# simple, as all compilation results are in $(out) and can be removed in\n# one fell swoop.\nout = build/$(mode).$(arch)\noutlink = build/$(mode)\noutlink2 = build/last\n\nifneq ($(MAKECMDGOALS),menuconfig)\ninclude $(out)/gen/config/kernel_conf.mk\nendif\n#\n# This parameter can be passed in to the build command to specify name of\n# a drivers profile. The drivers profile allows to build custom kernel with\n# a specific set of drivers enabled in the corresponding makefile include\n# file - conf/profiles/$(arch)/$(conf_drivers_profile).mk). The default profile is\n# 'all' which incorporates all drivers into kernel.\n# In general the profiles set variables named conf_drivers_*, which then in turn\n# are used in the rules below to decide which object files are linked into\n# kernel.\nconf_drivers_profile?=all\nifeq (,$(wildcard conf/profiles/$(arch)/$(conf_drivers_profile).mk))\n    $(error unsupported drivers profile $(conf_drivers_profile))\nendif\ninclude conf/profiles/$(arch)/$(conf_drivers_profile).mk\n# The base profile disables all drivers unless they are explicitly enabled\n# by the profile file included in the line above. The base profile also enforces\n# certain dependencies between drivers, for example the ide driver needs pci support, etc.\n# For more details please read comments in the profile file.\ninclude conf/profiles/$(arch)/base.mk\n\nifneq ($(MAKECMDGOALS),clean)\n$(info Building into $(out))\nendif\n\n###########################################################################\n\n# We need some external git modules to have been downloaded, because the\n# default \"make\" depends on the following directories:\n#   musl/ -  for some of the header files (symbolic links in include/api) and\n#            some of the source files ($(musl) below).\n#   external/x64/acpica - for the ACPICA library (see $(acpi) below).\n# Additional submodules are need when certain make parameters are used.\nifeq (,$(wildcard musl/include))\n    $(error Missing musl/ directory. Please run \"git submodule update --init --recursive\")\nendif\nifeq (,$(wildcard external/x64/acpica/source))\n    $(error Missing external/x64/acpica/ directory. Please run \"git submodule update --init --recursive\")\nendif\n\n# This makefile wraps all commands with the $(quiet) or $(very-quiet) macros\n# so that instead of half-a-screen-long command lines we short summaries\n# like \"CC file.cc\". These macros also keep the option of viewing the\n# full command lines, if you wish, with \"make V=1\".\nquiet = $(if $V, $1, @echo \" $2\"; $1)\nvery-quiet = $(if $V, $1, @$1)\n\nall: $(out)/loader.img links $(out)/zfs_builder-stripped.elf\nifeq ($(arch),x64)\nall: $(out)/vmlinuz.bin\nendif\nifeq ($(arch),aarch64)\nall: $(out)/zfs_builder.img\nendif\n.PHONY: all\n\nmenuconfig:\n\t$(call quiet, make -s -f conf/Makefile default_config -j1, GEN default $(out)/.config)\n\tmake -s -f conf/Makefile menuconfig -j1\n\nlinks:\n\t$(call very-quiet, ln -nsf $(notdir $(out)) $(outlink))\n\t$(call very-quiet, ln -nsf $(notdir $(out)) $(outlink2))\n.PHONY: links\n\ncheck:\n\t$(call quiet, pkill -e -9 qemu-system || true, Kill lingering QEMU process if any)\n\t./scripts/build check\n.PHONY: check\n\n# Remember that \"make clean\" needs the same parameters that set $(out) in\n# the first place, so to clean the output of \"make mode=debug\" you need to\n# do \"make mode=debug clean\".\nclean:\n\trm -rf $(out)\n\trm -f $(outlink) $(outlink2)\n.PHONY: clean\n\n# Manually listing recompilation dependencies in the Makefile (such as which\n# object needs to be recompiled when a header changed) is antediluvian.\n# Even \"makedepend\" is old school! The best modern technique for automatic\n# dependency generation, which we use here, works like this:\n# We note that before the first compilation, we don't need to know these\n# dependencies at all, as everything will be compiled anyway. But during\n# this compilation, we pass to the compiler a special option (-MD) which\n# causes it to also output a file with suffix \".d\" listing the dependencies\n# discovered during the compilation of that source file. From then on,\n# on every compilation we \"include\" all the \".d\" files generated in the\n# previous compilation, and create new \".d\" when a source file changed\n# (and therefore got recompiled).\nifneq ($(MAKECMDGOALS),clean)\ninclude $(shell test -d $(out) && find $(out) -name '*.d')\nendif\n\n# Before we can try to build anything in $(out), we need to make sure the\n# directory exists. Unfortunately, this is not quite enough, as when we\n# compile somedir/somefile.c to $(out)/somedir/somefile.o, we also need\n# to make sure $(out)/somedir exists. This is why we have $(makedir) below.\n# I wonder if there's a better way of doing this with dependencies, so make\n# will only call mkdir for each directory once.\n$(out)/%: | $(out)\n$(out):\n\tmkdir -p $(out)\n\n# \"tags\" is the default output file of ctags, \"TAGS\" is that of etags\ntags TAGS:\n\trm -f -- \"$@\"\n\tfind . -name \"*.cc\" -o -name \"*.hh\" -o -name \"*.h\" -o -name \"*.c\" |\\\n\t\txargs $(if $(filter $@, tags),ctags,etags) -a\n.PHONY: tags TAGS\n\ncscope:\n\tfind -name '*.[chS]' -o -name \"*.cc\" -o -name \"*.hh\" | cscope -bq -i-\n\t@echo cscope index created\n.PHONY: cscope\n\n###########################################################################\n\nlocal-includes =\nINCLUDES = $(local-includes) -Iarch/$(arch) -I. -Iinclude  -Iarch/common\nINCLUDES += -isystem include/glibc-compat\n#\n# Let us detect presence of standard C++ headers\nCXX_INCLUDES = $(shell $(CXX) -E -xc++ - -v </dev/null 2>&1 | awk '/^End/ {exit} /^ .*c\\+\\+/ {print \"-isystem\" $$0}')\nifeq ($(CXX_INCLUDES),)\n  ifeq ($(CROSS_PREFIX),aarch64-linux-gnu-)\n    # We are on distribution where the aarch64-linux-gnu package does not come with C++ headers\n    # So let use point it to the expected location\n    aarch64_gccbase = build/downloaded_packages/aarch64/gcc/install\n    ifeq (,$(wildcard $(aarch64_gccbase)))\n     $(error Missing $(aarch64_gccbase) directory. Please run \"./scripts/download_aarch64_packages.py\")\n    endif\n\n    gcc-inc-base := $(dir $(shell find $(aarch64_gccbase)/ -name vector | grep -v -e debug/vector$$ -e profile/vector$$ -e experimental/vector$$))\n    ifeq (,$(gcc-inc-base))\n      $(error Could not find C++ headers under $(aarch64_gccbase) directory. Please run \"./scripts/download_aarch64_packages.py\")\n    endif\n\n    gcc-inc-base3 := $(dir $(shell dirname `find $(aarch64_gccbase)/ -name c++config.h | grep -v /32/`))\n    ifeq (,$(gcc-inc-base3))\n      $(error Could not find C++ headers under $(aarch64_gccbase) directory. Please run \"./scripts/download_aarch64_packages.py\")\n    endif\n    CXX_INCLUDES = -isystem $(gcc-inc-base) -isystem $(gcc-inc-base3)\n\n    gcc-inc-base2 := $(dir $(shell find $(aarch64_gccbase)/ -name unwind.h))\n    ifeq (,$(gcc-inc-base2))\n      $(error Could not find standard gcc headers like \"unwind.h\" under $(aarch64_gccbase) directory. Please run \"./scripts/download_aarch64_packages.py\")\n    endif\n    STANDARD_GCC_INCLUDES = -isystem $(gcc-inc-base2)\n\n    gcc-sysroot = --sysroot $(aarch64_gccbase)\n    standard-includes-flag = -nostdinc\n  else\n    $(error Could not find standard C++ headers. Please run \"sudo ./scripts/setup.py\")\n  endif\nelse\n  # If gcc can find C++ headers it also means it can find standard libc headers, so no need to add them specifically\n  STANDARD_GCC_INCLUDES =\n  standard-includes-flag =\nendif\n\nifeq ($(arch),x64)\nINCLUDES += -isystem external/$(arch)/acpica/source/include\nendif\n\nifeq ($(arch),aarch64)\nlibfdt_base = external/$(arch)/libfdt\nINCLUDES += -isystem $(libfdt_base)\nendif\n\nINCLUDES += $(boost-includes)\n# Starting in Gcc 6, the standard C++ header files (which we do not change)\n# must precede in the include path the C header files (which we replace).\n# This is explained in https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70722.\n# So we are forced to list here (before include/api) the system's default\n# C++ include directories, though they are already in the default search path.\nINCLUDES += $(CXX_INCLUDES)\nINCLUDES += $(pre-include-api)\nINCLUDES += -isystem include/api\nINCLUDES += -isystem include/api/$(arch)\n# must be after include/api, since it includes some libc-style headers:\nINCLUDES += $(STANDARD_GCC_INCLUDES)\nINCLUDES += -isystem $(out)/gen/include\nINCLUDES += $(post-includes-bsd)\n\npost-includes-bsd += -isystem bsd/sys\n# For acessing machine/ in cpp xen drivers\npost-includes-bsd += -isystem bsd/\npost-includes-bsd += -isystem bsd/$(arch)\n\n$(out)/musl/%.o: pre-include-api = -isystem include/api/internal_musl_headers -isystem musl/src/include\n\nifneq ($(werror),0)\n\tCFLAGS_WERROR = -Werror\nendif\n# $(call compiler-flag, -ffoo, option, file)\n#     returns option if file builds with -ffoo, empty otherwise\ncompiler-flag = $(shell $(CXX) $(CFLAGS_WERROR) $1 -o /dev/null -c $3  > /dev/null 2>&1 && echo $2)\n\ncompiler-specific := $(call compiler-flag, -std=$(conf_cxx_level), -DHAVE_ATTR_COLD_LABEL, compiler/attr/cold-label.cc)\n\nsource-dialects = -D_GNU_SOURCE\n\n$(out)/bsd/%.o: source-dialects =\n\n# libc has its own source dialect control\n$(out)/libc/%.o: source-dialects =\n$(out)/musl/%.o: source-dialects =\n\n# do not hide symbols in musl/libc because it has it's own hiding mechanism\n$(out)/libc/%.o: cc-hide-flags =\n$(out)/libc/%.o: cxx-hide-flags =\n$(out)/musl/%.o: cc-hide-flags =\n\nkernel-defines = -D_KERNEL $(source-dialects) $(cc-hide-flags) $(gc-flags)\n\n# This play the same role as \"_KERNEL\", but _KERNEL unfortunately is too\n# overloaded. A lot of files will expect it to be set no matter what, specially\n# in headers. \"userspace\" inclusion of such headers is valid, and lacking\n# _KERNEL will make them fail to compile. That is specially true for the BSD\n# imported stuff like ZFS commands.\n#\n# To add something to the kernel build, you can write for your object:\n#\n#   mydir/*.o COMMON += <MY_STUFF>\n#\n# To add something that will *not* be part of the main kernel, you can do:\n#\n#   mydir/*.o EXTRA_FLAGS = <MY_STUFF>\nifeq ($(arch),x64)\nEXTRA_FLAGS = -D__OSV_CORE__ -DOSV_KERNEL_BASE=$(kernel_base) -DOSV_KERNEL_VM_BASE=$(kernel_vm_base) \\\n\t-DOSV_KERNEL_VM_SHIFT=$(kernel_vm_shift) -DOSV_LZKERNEL_BASE=$(lzkernel_base)\nelse\nEXTRA_FLAGS = -D__OSV_CORE__ -DOSV_KERNEL_VM_BASE=$(kernel_vm_base)\nendif\nEXTRA_LIBS =\nCOMMON = $(autodepend) -g -Wall -Wno-pointer-arith $(CFLAGS_WERROR) -Wformat=0 -Wno-format-security \\\n\t-D __BSD_VISIBLE=1 -U _FORTIFY_SOURCE -fno-stack-protector $(INCLUDES) \\\n\t$(kernel-defines) \\\n\t-fno-omit-frame-pointer $(compiler-specific) \\\n\t-include compiler/include/intrinsics.hh \\\n\t$(conf_compiler_cflags) $(conf_compiler_opt) $(acpi-defines) $(tracing-flags) $(gcc-sysroot) \\\n\t-D__OSV__ -D__XEN_INTERFACE_VERSION__=\"0x00030207\" -DARCH_STRING=$(ARCH_STR) $(EXTRA_FLAGS)\nCOMMON += $(standard-includes-flag)\n\ntracing-flags-0 =\ntracing-flags-1 = -finstrument-functions -finstrument-functions-exclude-file-list=c++,trace.cc,trace.hh,align.hh,mmintrin.h\ntracing-flags = $(tracing-flags-$(conf_tracing))\n\ncc-hide-flags-0 =\ncc-hide-flags-1 = -fvisibility=hidden\ncc-hide-flags = $(cc-hide-flags-$(conf_hide_symbols))\n\ncxx-hide-flags-0 =\ncxx-hide-flags-1 = -fvisibility-inlines-hidden\ncxx-hide-flags = $(cxx-hide-flags-$(conf_hide_symbols))\n\ngc-flags-0 =\ngc-flags-1 = -ffunction-sections -fdata-sections\ngc-flags = $(gc-flags-$(conf_hide_symbols))\n\ngcc-opt-Og := $(call compiler-flag, -Og, -Og, compiler/empty.cc)\n\nCXXFLAGS = -std=$(conf_cxx_level) $(COMMON) $(cxx-hide-flags)\nCFLAGS = -std=gnu99 $(COMMON)\n\n# should be limited to files under libc/ eventually\nCFLAGS += -I libc/stdio -I libc/internal -I libc/arch/$(arch) \\\n\t-Wno-missing-braces -Wno-parentheses -Wno-unused-but-set-variable\n\nASFLAGS = -g $(autodepend) -D__ASSEMBLY__\n\n$(out)/fs/vfs/main.o: CXXFLAGS += -Wno-sign-compare -Wno-write-strings\n\n$(out)/bsd/%.o: INCLUDES += -isystem bsd/sys\n$(out)/bsd/%.o: INCLUDES += -isystem bsd/\n# for machine/\n$(out)/bsd/%.o: INCLUDES += -isystem bsd/$(arch)\n\nmakedir = $(call very-quiet, mkdir -p $(dir $@))\nbuild-so = $(CC) $(CFLAGS) -o $@ $^ $(EXTRA_LIBS)\nq-build-so = $(call quiet, $(build-so), LINK $@)\n\n\n$(out)/%.o: %.cc $(out)/gen/include/osv/kernel_config_hide_symbols.h | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -c -o $@ $<, CXX $*.cc)\n\n$(out)/%.o: %.c $(out)/gen/include/osv/kernel_config_hide_symbols.h | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -c -o $@ $<, CC $*.c)\n\n$(out)/%.o: %.S $(out)/gen/include/osv/kernel_config_hide_symbols.h\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) $(ASFLAGS) -c -o $@ $<, AS $*.S)\n\n$(out)/%.o: %.s $(out)/gen/include/osv/kernel_config_hide_symbols.h\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) $(ASFLAGS) -c -o $@ $<, AS $*.s)\n\n%.so: EXTRA_FLAGS = -fPIC -shared -z relro -z lazy\n%.so: %.o\n\t$(makedir)\n\t$(q-build-so)\n\nautodepend = -MD -MT $@ -MP\n\ntools := tools/mkfs/mkfs.so tools/cpiod/cpiod.so\n\n$(out)/tools/%.o: COMMON += -fPIC\n$(out)/tools/cpiod/options.o: core/options.cc\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -fPIC -c -o $@ $<, CXX core/options.cc)\n\ntools += tools/uush/uush.so\ntools += tools/uush/ls.so\ntools += tools/uush/mkdir.so\n\ntools += tools/mount/mount-fs.so\ntools += tools/mount/umount.so\n\nifeq ($(arch),aarch64)\n# note that the bootfs.manifest entry for the uush image\n# has no effect on the loader image, only on the usr image.\n# The only thing that does have an effect is the\n# bootfs.manifest.skel.\n#\n# Therefore, you need to manually add tests/tst-hello.so\n# to the bootfs.manifest.skel atm to get it to work.\n#\ntools += tests/tst-hello.so\ncmdline = --nomount tests/tst-hello.so\nendif\n\n$(out)/loader-stripped.elf: $(out)/loader.elf\n\t$(call quiet, $(STRIP) $(out)/loader.elf -o $(out)/loader-stripped.elf, STRIP loader.elf -> loader-stripped.elf )\n\nifeq ($(arch),x64)\n\n# kernel_base is where the kernel will be loaded after uncompression.\n# lzkernel_base is where the compressed kernel is loaded from disk.\nkernel_base := 0x200000\nlzkernel_base := 0x100000\nkernel_vm_base := 0x40200000\n\n# the default of 64 bytes can be overridden by passing the app_local_exec_tls_size\n# environment variable to the make or scripts/build\napp_local_exec_tls_size := 0x40\n\n$(out)/arch/x64/boot16.o: $(out)/lzloader.elf\n$(out)/boot.bin: arch/x64/boot16.ld $(out)/arch/x64/boot16.o\n\t$(call quiet, $(LD) -o $@ -T $^, LD $@)\n\nimage-size = $(shell stat --printf %s $(out)/lzloader.elf)\n\n$(out)/loader.img: $(out)/boot.bin $(out)/lzloader.elf\n\t$(call quiet, dd if=$(out)/boot.bin of=$@ > /dev/null 2>&1, DD loader.img boot.bin)\n\t$(call quiet, dd if=$(out)/lzloader.elf of=$@ conv=notrunc seek=128 > /dev/null 2>&1, \\\n\t\tDD loader.img lzloader.elf)\n\t$(call quiet, scripts/imgedit.py setsize \"-f raw $@\" $(image-size), IMGEDIT $@)\n\t$(call quiet, scripts/imgedit.py setargs \"-f raw $@\" $(cmdline), IMGEDIT $@)\n\nkernel_size = $(shell stat --printf %s $(out)/loader-stripped.elf)\n\n$(out)/arch/x64/vmlinuz-boot32.o: $(out)/loader-stripped.elf\n$(out)/arch/x64/vmlinuz-boot32.o: ASFLAGS += -I$(out) -DOSV_KERNEL_SIZE=$(kernel_size)\n\n$(out)/vmlinuz-boot.bin: $(out)/arch/x64/vmlinuz-boot32.o arch/x64/vmlinuz-boot.ld\n\t$(call quiet, $(LD) -static -o $@ \\\n\t\t$(filter-out %.bin, $(^:%.ld=-T %.ld)), LD $@)\n\n$(out)/vmlinuz.bin: $(out)/vmlinuz-boot.bin $(out)/loader-stripped.elf\n\t$(call quiet, dd if=$(out)/vmlinuz-boot.bin of=$@ > /dev/null 2>&1, DD vmlinuz.bin vmlinuz-boot.bin)\n\t$(call quiet, dd if=$(out)/loader-stripped.elf of=$@ conv=notrunc seek=4 > /dev/null 2>&1, \\\n\t\tDD vmlinuz.bin loader-stripped.elf)\n\n$(out)/fastlz/fastlz.o:\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -O2 -m32 -fno-instrument-functions -o $@ -c fastlz/fastlz.cc, CXX fastlz/fastlz.cc)\n\n$(out)/fastlz/lz: fastlz/fastlz.cc fastlz/lz.cc | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -O2 -o $@ $(filter %.cc, $^), CXX $@)\n\n$(out)/loader-stripped.elf.lz.o: $(out)/loader-stripped.elf $(out)/fastlz/lz\n\t$(call quiet, $(out)/fastlz/lz $(out)/loader-stripped.elf, LZ loader-stripped.elf)\n\t$(call quiet, cd $(out); objcopy -B i386 -I binary -O elf32-i386 loader-stripped.elf.lz loader-stripped.elf.lz.o, OBJCOPY loader-stripped.elf.lz -> loader-stripped.elf.lz.o)\n\n$(out)/fastlz/lzloader.o: fastlz/lzloader.cc | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -O0 -m32 -fno-instrument-functions -o $@ -c fastlz/lzloader.cc, CXX $<)\n\n$(out)/lzloader.elf: $(out)/loader-stripped.elf.lz.o $(out)/fastlz/lzloader.o arch/x64/lzloader.ld \\\n\t$(out)/fastlz/fastlz.o\n\t$(call very-quiet, scripts/check-image-size.sh $(out)/loader-stripped.elf)\n\t$(call quiet, $(LD) -o $@ --defsym=OSV_LZKERNEL_BASE=$(lzkernel_base) \\\n\t\t-Bdynamic --export-dynamic --eh-frame-hdr --enable-new-dtags -z max-page-size=4096 \\\n\t\t-T arch/x64/lzloader.ld \\\n\t\t$(filter %.o, $^), LINK lzloader.elf)\n\t$(call quiet, truncate -s %32768 $@, ALIGN lzloader.elf)\n\nacpi-defines = -DACPI_MACHINE_WIDTH=64 -DACPI_USE_LOCAL_CACHE\n\nacpi-source := $(shell find external/$(arch)/acpica/source/components -type f -name '*.c')\nacpi = $(patsubst %.c, %.o, $(acpi-source))\n\n$(acpi:%=$(out)/%): CFLAGS += -fno-strict-aliasing -Wno-stringop-truncation\n\nkernel_vm_shift := $(shell printf \"0x%X\" $(shell expr $$(( $(kernel_vm_base) - $(kernel_base) )) ))\n\nendif # x64\n\nifeq ($(arch),aarch64)\n\nkernel_vm_base := 0xfc0080000 #63GB\napp_local_exec_tls_size := 0x40\n\ninclude $(libfdt_base)/Makefile.libfdt\nlibfdt-source := $(patsubst %.c, $(libfdt_base)/%.c, $(LIBFDT_SRCS))\nlibfdt = $(patsubst %.c, %.o, $(libfdt-source))\n\n$(out)/preboot.elf: arch/$(arch)/preboot.ld $(out)/arch/$(arch)/preboot.o\n\t$(call quiet, $(LD) -o $@ -T $^, LD $@)\n\n$(out)/preboot.bin: $(out)/preboot.elf\n\t$(call quiet, $(OBJCOPY) -O binary $^ $@, OBJCOPY $@)\n\nedata = $(shell readelf --syms $(out)/loader.elf | grep \"\\.edata\" | awk '{print \"0x\" $$2}')\nimage_size = $$(( $(edata) - $(kernel_vm_base) ))\n\nbuilder_edata = $(shell readelf --syms $(out)/zfs_builder.elf | grep \"\\.edata\" | awk '{print \"0x\" $$2}')\nbuilder_image_size = $$(( $(builder_edata) - $(kernel_vm_base) ))\n\n$(out)/loader.img: $(out)/preboot.bin $(out)/loader-stripped.elf\n\t$(call quiet, dd if=$(out)/preboot.bin of=$@ > /dev/null 2>&1, DD $@ preboot.bin)\n\t$(call quiet, dd if=$(out)/loader-stripped.elf of=$@ conv=notrunc obs=4096 seek=16 > /dev/null 2>&1, DD $@ loader-stripped.elf)\n\t$(call quiet, scripts/imgedit.py setsize_aarch64 \"-f raw $@\" $(image_size), IMGEDIT $@)\n\t$(call quiet, scripts/imgedit.py setargs \"-f raw $@\" $(cmdline), IMGEDIT $@)\n\n$(out)/zfs_builder.img: $(out)/preboot.bin $(out)/zfs_builder-stripped.elf\n\t$(call quiet, dd if=$(out)/preboot.bin of=$@ > /dev/null 2>&1, DD $@ preboot.bin)\n\t$(call quiet, dd if=$(out)/zfs_builder-stripped.elf of=$@ conv=notrunc obs=4096 seek=16 > /dev/null 2>&1, DD $@ zfs_builder-stripped.elf)\n\t$(call quiet, scripts/imgedit.py setsize_aarch64 \"-f raw $@\" $(builder_image_size), IMGEDIT $@)\n\t$(call quiet, scripts/imgedit.py setargs \"-f raw $@\" $(cmdline), IMGEDIT $@)\n\nendif # aarch64\n\n$(out)/bsd/sys/crypto/rijndael/rijndael-api-fst.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/crypto/sha2/sha2.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/net/route.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/net/rtsock.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/net/in.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/net/if.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/netinet/in_rmx.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/netinet/ip_input.o: COMMON+=-fno-strict-aliasing\n$(out)/bsd/sys/netinet/in.o: COMMON+=-fno-strict-aliasing\n\n$(out)/bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/metaslab.o: COMMON+=-Wno-tautological-compare\n\n# A lot of the BSD code used to be C code, which commonly bzero()ed or\n# memcpy()ed objects. In C++, this should not be done (objects have\n# constructors and assignments), and gcc 8 starts to warn about it.\n# Instead of fixing all these occurances, let's ask gcc to ignore this\n# warning. At least for now.\n$(out)/bsd/%.o: CXXFLAGS += -Wno-class-memaccess\n\nbsd  = bsd/init.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/net.o\nendif\nbsd += bsd/$(arch)/machine/in_cksum.o\nbsd += bsd/sys/crypto/rijndael/rijndael-alg-fst.o\nbsd += bsd/sys/crypto/rijndael/rijndael-api.o\nbsd += bsd/sys/crypto/rijndael/rijndael-api-fst.o\nbsd += bsd/sys/crypto/sha2/sha2.o\nbsd += bsd/sys/libkern/arc4random.o\nbsd += bsd/sys/libkern/random.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/sys/libkern/inet_ntoa.o\nbsd += bsd/sys/libkern/inet_aton.o\nendif\nbsd += bsd/sys/kern/md5c.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/sys/kern/kern_mbuf.o\nbsd += bsd/sys/kern/uipc_mbuf.o\nbsd += bsd/sys/kern/uipc_mbuf2.o\nbsd += bsd/sys/kern/uipc_domain.o\nbsd += bsd/sys/kern/uipc_sockbuf.o\nbsd += bsd/sys/kern/uipc_socket.o\nbsd += bsd/sys/kern/uipc_syscalls.o\nbsd += bsd/sys/kern/uipc_syscalls_wrap.o\nendif\nbsd += bsd/sys/kern/subr_bufring.o\nbsd += bsd/sys/kern/subr_sbuf.o\nbsd += bsd/sys/kern/subr_eventhandler.o\nbsd += bsd/sys/kern/subr_hash.o\nbsd += bsd/sys/kern/subr_taskqueue.o\n$(out)/bsd/sys/kern/subr_taskqueue.o: COMMON += -Wno-dangling-pointer\nifeq ($(conf_networking_stack),1)\nbsd += bsd/sys/kern/sys_socket.o\nendif\nbsd += bsd/sys/kern/subr_disk.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/porting/route.o\nbsd += bsd/porting/networking.o\nendif\nbsd += bsd/porting/netport.o\nbsd += bsd/porting/netport1.o\nbsd += bsd/porting/shrinker.o\nbsd += bsd/porting/cpu.o\nbsd += bsd/porting/uma_stub.o\nbsd += bsd/porting/sync_stub.o\nbsd += bsd/porting/callout.o\nbsd += bsd/porting/synch.o\nbsd += bsd/porting/kthread.o\nbsd += bsd/porting/mmu.o\nbsd += bsd/porting/pcpu.o\nbsd += bsd/porting/bus_dma.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/sys/netinet/if_ether.o\nbsd += bsd/sys/compat/linux/linux_socket.o\nbsd += bsd/sys/compat/linux/linux_ioctl.o\nbsd += bsd/sys/compat/linux/linux_netlink.o\nbsd += bsd/sys/net/if_ethersubr.o\nbsd += bsd/sys/net/if_llatbl.o\nbsd += bsd/sys/net/radix.o\nbsd += bsd/sys/net/route.o\nbsd += bsd/sys/net/raw_cb.o\nbsd += bsd/sys/net/raw_usrreq.o\nbsd += bsd/sys/net/rtsock.o\nbsd += bsd/sys/net/netisr.o\nbsd += bsd/sys/net/netisr1.o\nbsd += bsd/sys/net/if_dead.o\nbsd += bsd/sys/net/if_clone.o\nbsd += bsd/sys/net/if_loop.o\nbsd += bsd/sys/net/if.o\nbsd += bsd/sys/net/pfil.o\nbsd += bsd/sys/net/routecache.o\nbsd += bsd/sys/netinet/in.o\nbsd += bsd/sys/netinet/in_pcb.o\nbsd += bsd/sys/netinet/in_proto.o\nbsd += bsd/sys/netinet/in_mcast.o\n$(out)/bsd/sys/netinet/in_mcast.o: COMMON += -Wno-maybe-uninitialized\nbsd += bsd/sys/netinet/in_rmx.o\nbsd += bsd/sys/netinet/ip_id.o\nbsd += bsd/sys/netinet/ip_icmp.o\nbsd += bsd/sys/netinet/ip_input.o\nbsd += bsd/sys/netinet/ip_output.o\nbsd += bsd/sys/netinet/ip_options.o\nbsd += bsd/sys/netinet/raw_ip.o\nbsd += bsd/sys/netinet/igmp.o\nbsd += bsd/sys/netinet/udp_usrreq.o\nbsd += bsd/sys/netinet/tcp_debug.o\nbsd += bsd/sys/netinet/tcp_hostcache.o\nbsd += bsd/sys/netinet/tcp_input.o\nbsd += bsd/sys/netinet/tcp_lro.o\nbsd += bsd/sys/netinet/tcp_output.o\nbsd += bsd/sys/netinet/tcp_reass.o\nbsd += bsd/sys/netinet/tcp_sack.o\nbsd += bsd/sys/netinet/tcp_subr.o\nbsd += bsd/sys/netinet/tcp_syncache.o\nbsd += bsd/sys/netinet/tcp_timer.o\nbsd += bsd/sys/netinet/tcp_timewait.o\nbsd += bsd/sys/netinet/tcp_usrreq.o\nbsd += bsd/sys/netinet/cc/cc.o\nbsd += bsd/sys/netinet/cc/cc_cubic.o\nbsd += bsd/sys/netinet/cc/cc_htcp.o\nbsd += bsd/sys/netinet/cc/cc_newreno.o\nbsd += bsd/sys/netinet/arpcache.o\nendif\nifeq ($(conf_drivers_xen),1)\nbsd += bsd/sys/xen/evtchn.o\n$(out)/bsd/sys/xen/evtchn.o: COMMON += -Wno-array-bounds -Wno-stringop-overread -Wno-stringop-overflow\nendif\n\nifeq ($(arch),x64)\n$(out)/bsd/%.o: COMMON += -DXEN -DXENHVM\nifeq ($(conf_drivers_xen),1)\nbsd += bsd/sys/xen/gnttab.o\nbsd += bsd/sys/xen/xenstore/xenstore.o\nbsd += bsd/sys/xen/xenbus/xenbus.o\nbsd += bsd/sys/xen/xenbus/xenbusb.o\nbsd += bsd/sys/xen/xenbus/xenbusb_front.o\nifeq ($(conf_networking_stack),1)\nbsd += bsd/sys/dev/xen/netfront/netfront.o\nendif\nbsd += bsd/sys/dev/xen/blkfront/blkfront.o\nendif\nifeq ($(conf_drivers_hyperv),1)\nbsd += bsd/sys/dev/hyperv/vmbus/hyperv.o\nendif\nifeq ($(conf_networking_stack),1)\nifeq ($(conf_drivers_ena),1)\nbsd += bsd/sys/contrib/ena_com/ena_eth_com.o\nbsd += bsd/sys/contrib/ena_com/ena_com.o\nbsd += bsd/sys/dev/ena/ena_datapath.o\nbsd += bsd/sys/dev/ena/ena.o\n$(out)/bsd/sys/dev/ena/%.o: CXXFLAGS += -Ibsd/sys/contrib\nendif\nendif\nendif\n\nbsd += bsd/sys/dev/random/hash.o\nbsd += bsd/sys/dev/random/randomdev_soft.o\nbsd += bsd/sys/dev/random/yarrow.o\nbsd += bsd/sys/dev/random/random_harvestq.o\nbsd += bsd/sys/dev/random/harvest.o\nbsd += bsd/sys/dev/random/live_entropy_sources.o\n\n$(out)/bsd/sys/%.o: COMMON += -Wno-sign-compare -Wno-narrowing -Wno-write-strings -Wno-parentheses -Wno-unused-but-set-variable\n\nxdr :=\nxdr += bsd/sys/xdr/xdr.o\nxdr += bsd/sys/xdr/xdr_array.o\nxdr += bsd/sys/xdr/xdr_mem.o\n\nsolaris :=\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_atomic.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_cmn_err.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_kmem.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_kobj.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_kstat.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_policy.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_sunddi.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_string.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_sysevent.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_taskq.o\nsolaris += bsd/sys/cddl/compat/opensolaris/kern/opensolaris_uio.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/acl/acl_common.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/avl/avl.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/nvpair/fnvpair.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/nvpair/nvpair.o\n$(out)/bsd/sys/cddl/contrib/opensolaris/common/nvpair/nvpair.o: CFLAGS += -Wno-stringop-overread\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/nvpair/nvpair_alloc_fixed.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/common/unicode/u8_textprep.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/os/callb.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/os/fm.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/os/list.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/os/nvpair_alloc_system.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/adler32.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/deflate.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/inffast.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/inflate.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/inftrees.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/opensolaris_crc32.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/trees.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/zmod.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/zmod_subr.o\nsolaris += bsd/sys/cddl/contrib/opensolaris/uts/common/zmod/zutil.o\n\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfeature_common.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_comutil.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_deleg.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_fletcher.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_ioctl_compat.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_namecheck.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_prop.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zpool_prop.o\nzfs += bsd/sys/cddl/contrib/opensolaris/common/zfs/zprop_common.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/arc.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/bplist.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/bpobj.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/bptree.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dbuf.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/ddt.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/ddt_zap.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu.o\n#zfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_diff.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_object.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_objset.o\n#zfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_send.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_traverse.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_tx.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dmu_zfetch.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dnode.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dnode_sync.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_dataset.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_deadlist.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_deleg.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_dir.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_pool.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_prop.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_scan.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/dsl_synctask.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/gzip.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/lzjb.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/metaslab.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/refcount.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/rrwlock.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/sa.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/sha256.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/spa.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/space_map.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/spa_config.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/spa_errlog.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/spa_history.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/spa_misc.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/txg.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/uberblock.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/unique.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_cache.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_disk.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_file.o\n#zfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_geom.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_label.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_mirror.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_missing.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_queue.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_raidz.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/vdev_root.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zap.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zap_leaf.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zap_micro.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfeature.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_acl.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_byteswap.o\n#zfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_ctldir.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_debug.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_dir.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_fm.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_fuid.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_ioctl.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_init.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_log.o\n#zfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_onexit.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_replay.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_rlock.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_sa.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_vfsops.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_vnops.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zfs_znode.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zil.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zio.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zio_checksum.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zio_compress.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zio_inject.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zle.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zrlock.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/zvol.o\nzfs += bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs/lz4.o\n\nsolaris += $(zfs)\n\n$(zfs:%=$(out)/%): CFLAGS+= \\\n\t-DBUILDING_ZFS \\\n\t-Wno-array-bounds \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/common/zfs\n\n$(solaris:%=$(out)/%): CFLAGS+= \\\n\t-fno-strict-aliasing \\\n\t-Wno-unknown-pragmas \\\n\t-Wno-unused-variable \\\n\t-Wno-switch \\\n\t-Wno-maybe-uninitialized \\\n\t-Ibsd/sys/cddl/compat/opensolaris \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/common \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/uts/common \\\n\t-Ibsd/sys\n\n$(solaris:%=$(out)/%): ASFLAGS+= \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/uts/common\n\n\nlibtsm :=\nlibtsm += drivers/libtsm/tsm_render.o\nlibtsm += drivers/libtsm/tsm_screen.o\nlibtsm += drivers/libtsm/tsm_vte.o\nlibtsm += drivers/libtsm/tsm_vte_charsets.o\n\ndrivers := $(bsd)\ndrivers += core/mmu.o\ndrivers += arch/$(arch)/early-console.o\ndrivers += drivers/blk-common.o\ndrivers += drivers/console.o\ndrivers += drivers/console-multiplexer.o\ndrivers += drivers/console-driver.o\ndrivers += drivers/line-discipline.o\ndrivers += drivers/clock.o\ndrivers += drivers/clock-common.o\ndrivers += drivers/clockevent.o\ndrivers += drivers/isa-serial-base.o\ndrivers += core/elf.o\n$(out)/core/elf.o: CXXFLAGS += -DHIDE_SYMBOLS=$(conf_hide_symbols)\ndrivers += drivers/random.o\ndrivers += drivers/zfs.o\ndrivers += drivers/null.o\ndrivers += drivers/device.o\nifeq ($(conf_drivers_pci),1)\ndrivers += drivers/pci-generic.o\ndrivers += drivers/pci-device.o\ndrivers += drivers/pci-function.o\ndrivers += drivers/pci-bridge.o\nendif\ndrivers += drivers/driver.o\n\nifeq ($(arch),x64)\nifeq ($(conf_drivers_vga),1)\ndrivers += $(libtsm)\ndrivers += drivers/vga.o\nendif\ndrivers += drivers/kbd.o drivers/isa-serial.o\ndrivers += arch/$(arch)/pvclock-abi.o\n\nifeq ($(conf_drivers_virtio),1)\ndrivers += drivers/virtio.o\nifeq ($(conf_drivers_pci),1)\ndrivers += drivers/virtio-pci-device.o\nendif\ndrivers += drivers/virtio-vring.o\nifeq ($(conf_drivers_mmio),1)\ndrivers += drivers/virtio-mmio.o\nendif\nifeq ($(conf_drivers_nvme),1)\ndrivers += drivers/nvme.o\ndrivers += drivers/nvme-queue.o\nendif\nifeq ($(conf_networking_stack),1)\ndrivers += drivers/virtio-net.o\nendif\ndrivers += drivers/virtio-blk.o\ndrivers += drivers/virtio-scsi.o\ndrivers += drivers/virtio-rng.o\ndrivers += drivers/virtio-fs.o\nendif\n\nifeq ($(conf_networking_stack),1)\nifeq ($(conf_drivers_vmxnet3),1)\ndrivers += drivers/vmxnet3.o\ndrivers += drivers/vmxnet3-queues.o\nendif\nendif\ndrivers += drivers/kvmclock.o\nifeq ($(conf_drivers_hyperv),1)\ndrivers += drivers/hypervclock.o\nendif\nifeq ($(conf_drivers_acpi),1)\ndrivers += drivers/acpi.o\nendif\nifeq ($(conf_drivers_hpet),1)\ndrivers += drivers/hpet.o\nendif\nifeq ($(conf_drivers_pvpanic),1)\ndrivers += drivers/pvpanic.o\nendif\ndrivers += drivers/rtc.o\nifeq ($(conf_drivers_ahci),1)\ndrivers += drivers/ahci.o\nendif\nifeq ($(conf_drivers_scsi),1)\ndrivers += drivers/scsi-common.o\nendif\nifeq ($(conf_drivers_ide),1)\ndrivers += drivers/ide.o\nendif\nifeq ($(conf_drivers_pvscsi),1)\ndrivers += drivers/vmw-pvscsi.o\nendif\n\nifeq ($(conf_drivers_xen),1)\ndrivers += drivers/xenclock.o\ndrivers += drivers/xenfront.o drivers/xenfront-xenbus.o drivers/xenfront-blk.o\ndrivers += drivers/xenplatform-pci.o\nendif\nifeq ($(conf_networking_stack),1)\nifeq ($(conf_drivers_ena),1)\ndrivers += drivers/ena.o\nendif\nendif\nendif # x64\n\nifeq ($(arch),aarch64)\ndrivers += drivers/mmio-isa-serial.o\ndrivers += drivers/pl011.o\ndrivers += drivers/pl031.o\nifeq ($(conf_drivers_cadence),1)\ndrivers += drivers/cadence-uart.o\nendif\nifeq ($(conf_drivers_xen),1)\ndrivers += drivers/xenconsole.o\nendif\n\nifeq ($(conf_drivers_virtio),1)\ndrivers += drivers/virtio.o\nifeq ($(conf_drivers_pci),1)\ndrivers += drivers/virtio-pci-device.o\nendif\nifeq ($(conf_drivers_mmio),1)\ndrivers += drivers/virtio-mmio.o\nendif\ndrivers += drivers/virtio-vring.o\ndrivers += drivers/virtio-rng.o\ndrivers += drivers/virtio-blk.o\ndrivers += drivers/virtio-net.o\ndrivers += drivers/virtio-fs.o\nendif\nendif # aarch64\n\nifeq ($(conf_tracepoints),1)\nobjects += arch/$(arch)/arch-trace.o\nendif\nobjects += arch/$(arch)/arch-setup.o\nobjects += arch/$(arch)/signal.o\nobjects += arch/$(arch)/arch-cpu.o\nobjects += arch/$(arch)/backtrace.o\nobjects += arch/$(arch)/smp.o\nobjects += arch/$(arch)/elf-dl.o\nobjects += arch/$(arch)/entry.o\nobjects += arch/$(arch)/mmu.o\nobjects += arch/$(arch)/exceptions.o\nobjects += arch/$(arch)/dump.o\nobjects += arch/$(arch)/arch-elf.o\nobjects += arch/$(arch)/cpuid.o\nobjects += arch/$(arch)/firmware.o\nobjects += arch/$(arch)/hypervisor.o\nobjects += arch/$(arch)/interrupt.o\nobjects += arch/$(arch)/clone.o\nifeq ($(conf_drivers_pci),1)\nobjects += arch/$(arch)/pci.o\nobjects += arch/$(arch)/msi.o\nendif\nobjects += arch/$(arch)/power.o\nobjects += arch/$(arch)/feexcept.o\nifeq ($(conf_drivers_xen),1)\nobjects += arch/$(arch)/xen.o\nendif\n\nifeq ($(conf_memory_optimize),1)\n$(out)/arch/x64/string-ssse3.o: CXXFLAGS += -mssse3\nendif\n\nifeq ($(arch),aarch64)\nobjects += arch/$(arch)/psci.o\nobjects += arch/$(arch)/arm-clock.o\nobjects += arch/$(arch)/gic-common.o\nobjects += arch/$(arch)/gic-v2.o\nobjects += arch/$(arch)/gic-v3.o\nobjects += arch/$(arch)/arch-dtb.o\nobjects += arch/$(arch)/hypercall.o\nifeq ($(conf_memory_optimize),1)\nobjects += arch/$(arch)/memset.o\nobjects += arch/$(arch)/memcpy.o\nobjects += arch/$(arch)/memmove.o\nendif\nobjects += arch/$(arch)/tlsdesc.o\nobjects += arch/$(arch)/sched.o\nobjects += $(libfdt)\nendif\n\nifeq ($(arch),x64)\nobjects += arch/x64/dmi.o\nifeq ($(conf_memory_optimize),1)\nobjects += arch/x64/string.o\nobjects += arch/x64/string-ssse3.o\nendif\nobjects += arch/x64/ioapic.o\nobjects += arch/x64/apic.o\nobjects += arch/x64/apic-clock.o\nobjects += arch/x64/entry-xen.o\nobjects += arch/x64/prctl.o\nobjects += arch/x64/vmlinux.o\nobjects += arch/x64/vmlinux-boot64.o\nobjects += arch/x64/pvh-boot.o\nobjects += arch/x64/syscall.o\nifeq ($(conf_drivers_acpi),1)\nobjects += $(acpi)\nendif\nendif # x64\n\nifeq ($(conf_drivers_xen),1)\nobjects += core/xen_intr.o\nendif\nobjects += core/math.o\nobjects += core/spinlock.o\nobjects += core/lfmutex.o\nobjects += core/rwlock.o\nobjects += core/semaphore.o\nobjects += core/condvar.o\nobjects += core/debug.o\nobjects += core/rcu.o\nobjects += core/pagecache.o\nobjects += core/mempool.o\nifeq ($(conf_memory_tracker),1)\nobjects += core/alloctracker.o\nendif\nobjects += core/printf.o\nifeq ($(conf_tracepoints_sampler),1)\nobjects += core/sampler.o\nendif\n\nobjects += linux.o\nobjects += core/commands.o\nobjects += core/sched.o\nobjects += core/mmio.o\nobjects += core/kprintf.o\nifeq ($(conf_tracepoints),1)\nobjects += core/trace.o\nobjects += core/trace-count.o\nifeq ($(conf_tracepoints_strace),1)\nobjects += core/strace.o\nendif\nobjects += core/callstack.o\nendif\nobjects += core/poll.o\nobjects += core/select.o\nifeq ($(conf_core_epoll),1)\nobjects += core/epoll.o\nendif\nifeq ($(conf_core_newpoll),1)\nobjects += core/newpoll.o\nendif\nobjects += core/power.o\nobjects += core/percpu.o\nobjects += core/per-cpu-counter.o\nobjects += core/percpu-worker.o\nifeq ($(conf_networking_dhcp),1)\nobjects += core/dhcp.o\nendif\nobjects += core/run.o\nobjects += core/shutdown.o\nobjects += core/version.o\nobjects += core/waitqueue.o\nobjects += core/chart.o\nifeq ($(conf_networking_stack),1)\nobjects += core/net_channel.o\nendif\nobjects += core/demangle.o\nobjects += core/async.o\nobjects += core/net_trace.o\nobjects += core/app.o\nobjects += core/libaio.o\nifeq ($(conf_core_namespaces),1)\nobjects += core/osv_execve.o\nendif\nifeq ($(conf_core_c_wrappers),1)\nobjects += core/osv_c_wrappers.o\nendif\nobjects += core/options.o\nobjects += core/string_utils.o\n\n#include $(src)/libc/build.mk:\nlibc =\nlibc_to_hide =\nmusl =\nenviron_libc =\nenviron_musl =\n\nifeq ($(arch),x64)\nmusl_arch = x86_64\nelse\nmusl_arch = aarch64\nendif\n\nlibc += internal/_chk_fail.o\nlibc_to_hide += internal/_chk_fail.o\nlibc += internal/floatscan.o\nlibc += internal/intscan.o\nlibc += internal/libc.o\nlibc += internal/shgetc.o\n\nmusl += ctype/__ctype_get_mb_cur_max.o\nmusl += ctype/__ctype_tolower_loc.o\nmusl += ctype/__ctype_toupper_loc.o\nmusl += ctype/isalnum.o\nmusl += ctype/isalpha.o\nmusl += ctype/isascii.o\nmusl += ctype/isblank.o\nmusl += ctype/iscntrl.o\nmusl += ctype/isdigit.o\nmusl += ctype/isgraph.o\nmusl += ctype/islower.o\nmusl += ctype/isprint.o\nmusl += ctype/ispunct.o\nmusl += ctype/isspace.o\nmusl += ctype/isupper.o\nmusl += ctype/iswalnum.o\nmusl += ctype/iswalpha.o\nmusl += ctype/iswblank.o\nmusl += ctype/iswcntrl.o\nmusl += ctype/iswctype.o\nmusl += ctype/iswdigit.o\nmusl += ctype/iswgraph.o\nmusl += ctype/iswlower.o\nmusl += ctype/iswprint.o\nmusl += ctype/iswpunct.o\nmusl += ctype/iswspace.o\nmusl += ctype/iswupper.o\nmusl += ctype/iswxdigit.o\nmusl += ctype/isxdigit.o\nmusl += ctype/toascii.o\nmusl += ctype/tolower.o\nmusl += ctype/toupper.o\nmusl += ctype/towctrans.o\nmusl += ctype/wcswidth.o\nmusl += ctype/wctrans.o\nmusl += ctype/wcwidth.o\n\nmusl += dirent/alphasort.o\nmusl += dirent/scandir.o\n\nlibc += env/__environ.o\nmusl += env/clearenv.o\nmusl += env/getenv.o\nlibc += env/secure_getenv.o\nmusl += env/putenv.o\nmusl += env/setenv.o\nmusl += env/unsetenv.o\n\nenviron_libc += env/__environ.c\nenviron_musl += env/clearenv.c\nenviron_musl += env/getenv.c\nenviron_libc += env/secure_getenv.c\nenviron_musl += env/putenv.c\nenviron_musl += env/setenv.c\nenviron_musl += env/unsetenv.c\nenviron_musl += string/strchrnul.c\n\nmusl += ctype/__ctype_b_loc.o\n\nmusl += errno/strerror.o\nlibc += errno/strerror.o\n\nmusl += locale/catclose.o\nmusl += locale/__mo_lookup.o\n$(out)/musl/src/locale/__mo_lookup.o: CFLAGS += $(cc-hide-flags-$(conf_hide_symbols))\nmusl += locale/pleval.o\nmusl += locale/catgets.o\nlibc += locale/catopen.o\nlibc += locale/duplocale.o\nlibc += locale/freelocale.o\nlibc += locale/intl.o\nlibc += locale/langinfo.o\nmusl += locale/localeconv.o\nlibc += locale/setlocale.o\nmusl += locale/strcoll.o\nmusl += locale/strfmon.o\nlibc += locale/strtod_l.o\nlibc += locale/strtof_l.o\nlibc += locale/strtold_l.o\nmusl += locale/strxfrm.o\nlibc += locale/uselocale.o\nmusl += locale/wcscoll.o\nmusl += locale/wcsxfrm.o\n\nmusl += math/__cos.o\nmusl += math/__cosdf.o\nmusl += math/__cosl.o\nmusl += math/__expo2.o\nmusl += math/__expo2f.o\nmusl += math/__fpclassify.o\nmusl += math/__fpclassifyf.o\nmusl += math/__fpclassifyl.o\nmusl += math/__invtrigl.o\nmusl += math/__polevll.o\nmusl += math/__rem_pio2.o\nmusl += math/__rem_pio2_large.o\n$(out)/musl/src/math/__rem_pio2_large.o: CFLAGS += -Wno-maybe-uninitialized\nmusl += math/__rem_pio2f.o\nmusl += math/__rem_pio2l.o\nmusl += math/__signbit.o\nmusl += math/__signbitf.o\nmusl += math/__signbitl.o\nmusl += math/__sin.o\nmusl += math/__sindf.o\nmusl += math/__sinl.o\nmusl += math/__tan.o\nmusl += math/__tandf.o\nmusl += math/__tanl.o\nmusl += math/__math_oflow.o\nmusl += math/__math_oflowf.o\nmusl += math/__math_xflow.o\nmusl += math/__math_xflowf.o\nmusl += math/__math_uflow.o\nmusl += math/__math_uflowf.o\nmusl += math/__math_divzero.o\nmusl += math/__math_divzerof.o\nmusl += math/__math_invalid.o\nmusl += math/__math_invalidf.o\nmusl += math/acos.o\nmusl += math/acosf.o\nmusl += math/acosh.o\nmusl += math/acoshf.o\nmusl += math/acoshl.o\nmusl += math/acosl.o\nmusl += math/asin.o\nmusl += math/asinf.o\nmusl += math/asinh.o\nmusl += math/asinhf.o\nmusl += math/asinhl.o\nmusl += math/asinl.o\nmusl += math/atan.o\nmusl += math/atan2.o\nmusl += math/atan2f.o\nmusl += math/atan2l.o\nmusl += math/atanf.o\nmusl += math/atanh.o\nmusl += math/atanhf.o\nmusl += math/atanhl.o\nmusl += math/atanl.o\nmusl += math/cbrt.o\nmusl += math/cbrtf.o\nmusl += math/cbrtl.o\nmusl += math/ceil.o\nmusl += math/ceilf.o\nmusl += math/ceill.o\nmusl += math/copysign.o\nmusl += math/copysignf.o\nmusl += math/copysignl.o\nmusl += math/cos.o\nmusl += math/cosf.o\nmusl += math/cosh.o\nmusl += math/coshf.o\nmusl += math/coshl.o\nmusl += math/cosl.o\nmusl += math/erf.o\nmusl += math/erff.o\nmusl += math/erfl.o\nmusl += math/exp.o\nmusl += math/exp_data.o\nmusl += math/exp10.o\nmusl += math/exp10f.o\nmusl += math/exp10l.o\nmusl += math/exp2.o\nmusl += math/exp2f.o\nmusl += math/exp2f_data.o\nmusl += math/exp2l.o\n$(out)/musl/src/math/exp2l.o: CFLAGS += -Wno-unused-variable\nmusl += math/expf.o\nmusl += math/expl.o\nmusl += math/expm1.o\nmusl += math/expm1f.o\nmusl += math/expm1l.o\nmusl += math/fabs.o\nmusl += math/fabsf.o\nmusl += math/fabsl.o\nmusl += math/fdim.o\nmusl += math/fdimf.o\nmusl += math/fdiml.o\nmusl += math/floor.o\nmusl += math/floorf.o\nmusl += math/floorl.o\n#musl += math/fma.o\n#musl += math/fmaf.o\n#musl += math/fmal.o\nmusl += math/fmax.o\nmusl += math/fmaxf.o\nmusl += math/fmaxl.o\nmusl += math/fmin.o\nmusl += math/fminf.o\nmusl += math/fminl.o\nmusl += math/fmod.o\nmusl += math/fmodf.o\nmusl += math/fmodl.o\nmusl += math/finite.o\nmusl += math/finitef.o\nlibc += math/finitel.o\nmusl += math/frexp.o\nmusl += math/frexpf.o\nmusl += math/frexpl.o\nmusl += math/hypot.o\nmusl += math/hypotf.o\nmusl += math/hypotl.o\nmusl += math/ilogb.o\n$(out)/musl/src/math/ilogb.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/ilogbf.o\n$(out)/musl/src/math/ilogbf.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/ilogbl.o\n$(out)/musl/src/math/ilogbl.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/j0.o\nmusl += math/j0f.o\nmusl += math/j1.o\nmusl += math/j1f.o\nmusl += math/jn.o\nmusl += math/jnf.o\nmusl += math/ldexp.o\nmusl += math/ldexpf.o\nmusl += math/ldexpl.o\nmusl += math/lgamma.o\nmusl += math/lgamma_r.o\n$(out)/musl/src/math/lgamma_r.o: CFLAGS += -Wno-maybe-uninitialized\nmusl += math/lgammaf.o\nmusl += math/lgammaf_r.o\n$(out)/musl/src/math/lgammaf_r.o: CFLAGS += -Wno-maybe-uninitialized\nmusl += math/lgammal.o\n$(out)/musl/src/math/lgammal.o: CFLAGS += -Wno-maybe-uninitialized\n#musl += math/llrint.o\n#musl += math/llrintf.o\n#musl += math/llrintl.o\nmusl += math/llround.o\nmusl += math/llroundf.o\nmusl += math/llroundl.o\nmusl += math/log.o\nmusl += math/log_data.o\nmusl += math/log10.o\nmusl += math/log10f.o\nmusl += math/log10l.o\nmusl += math/log1p.o\nmusl += math/log1pf.o\nmusl += math/log1pl.o\nmusl += math/log2.o\nmusl += math/log2_data.o\nmusl += math/log2f.o\nmusl += math/log2f_data.o\nmusl += math/log2l.o\nmusl += math/logb.o\nmusl += math/logbf.o\nmusl += math/logbl.o\nmusl += math/logf.o\nmusl += math/logf_data.o\nmusl += math/logl.o\nmusl += math/lrint.o\n#musl += math/lrintf.o\n#musl += math/lrintl.o\nmusl += math/lround.o\nmusl += math/lroundf.o\nmusl += math/lroundl.o\nmusl += math/modf.o\nmusl += math/modff.o\nmusl += math/modfl.o\nmusl += math/nan.o\nmusl += math/nanf.o\nmusl += math/nanl.o\nmusl += math/nearbyint.o\n$(out)/musl/src/math/nearbyint.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/nearbyintf.o\n$(out)/musl/src/math/nearbyintf.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/nearbyintl.o\n$(out)/musl/src/math/nearbyintl.o: CFLAGS += -Wno-unknown-pragmas\nmusl += math/nextafter.o\nmusl += math/nextafterf.o\nmusl += math/nextafterl.o\nmusl += math/nexttoward.o\nmusl += math/nexttowardf.o\nmusl += math/nexttowardl.o\nmusl += math/pow.o\nmusl += math/pow_data.o\nmusl += math/powf.o\nmusl += math/powf_data.o\nmusl += math/powl.o\nmusl += math/remainder.o\nmusl += math/remainderf.o\nmusl += math/remainderl.o\nmusl += math/remquo.o\nmusl += math/remquof.o\nmusl += math/remquol.o\nmusl += math/rint.o\nmusl += math/rintf.o\nmusl += math/rintl.o\nmusl += math/round.o\nmusl += math/roundf.o\nmusl += math/roundl.o\nmusl += math/scalb.o\nmusl += math/scalbf.o\nmusl += math/scalbln.o\nmusl += math/scalblnf.o\nmusl += math/scalblnl.o\nmusl += math/scalbn.o\nmusl += math/scalbnf.o\nmusl += math/scalbnl.o\nmusl += math/signgam.o\nmusl += math/significand.o\nmusl += math/significandf.o\nmusl += math/sin.o\nmusl += math/sincos.o\nmusl += math/sincosf.o\nmsul += math/sincosl.o\nmusl += math/sinf.o\nmusl += math/sinh.o\nmusl += math/sinhf.o\nmusl += math/sinhl.o\nmusl += math/sinl.o\nmusl += math/sqrt.o\nmusl += math/sqrtf.o\nmusl += math/sqrtl.o\nmusl += math/tan.o\nmusl += math/tanf.o\nmusl += math/tanh.o\nmusl += math/tanhf.o\nmusl += math/tanhl.o\nmusl += math/tanl.o\nmusl += math/tgamma.o\nmusl += math/tgammaf.o\nmusl += math/tgammal.o\nmusl += math/trunc.o\nmusl += math/truncf.o\nmusl += math/truncl.o\n\n# Issue #867: Gcc 4.8.4 has a bug where it optimizes the trivial round-\n# related functions incorrectly - it appears to convert calls to any\n# function called round() to calls to a function called lround() -\n# and similarly for roundf() and roundl().\n# None of the specific \"-fno-*\" options disable this buggy optimization,\n# unfortunately. The simplest workaround is to just disable optimization\n# for the affected files.\n$(out)/musl/src/math/lround.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n$(out)/musl/src/math/lroundf.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n$(out)/musl/src/math/lroundl.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n$(out)/musl/src/math/llround.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n$(out)/musl/src/math/llroundf.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n$(out)/musl/src/math/llroundl.o: conf_compiler_opt := $(conf_compiler_opt) -O0\n\nmusl += misc/a64l.o\nmusl += misc/basename.o\nmusl += misc/dirname.o\nlibc += misc/error.o\nmusl += misc/ffs.o\nmusl += misc/ffsl.o\nmusl += misc/ffsll.o\nmusl += misc/get_current_dir_name.o\nifeq ($(conf_networking_stack),1)\nlibc += misc/gethostid.o\nendif\nlibc += misc/getopt.o\nlibc_to_hide += misc/getopt.o\nlibc += misc/getopt_long.o\nlibc_to_hide += misc/getopt_long.o\nmusl += misc/getsubopt.o\nlibc += misc/realpath.o\nlibc += misc/backtrace.o\nlibc += misc/uname.o\nlibc += misc/lockf.o\nlibc += misc/mntent.o\nlibc_to_hide += misc/mntent.o\nmusl += misc/nftw.o\nlibc += misc/__longjmp_chk.o\n\nmusl += signal/killpg.o\nmusl += signal/siginterrupt.o\nmusl += signal/sigrtmin.o\nmusl += signal/sigrtmax.o\n\nmusl += multibyte/btowc.o\nmusl += multibyte/internal.o\nmusl += multibyte/mblen.o\nmusl += multibyte/mbrlen.o\nmusl += multibyte/mbrtowc.o\nmusl += multibyte/mbsinit.o\nmusl += multibyte/mbsnrtowcs.o\nlibc += multibyte/__mbsnrtowcs_chk.o\nmusl += multibyte/mbsrtowcs.o\nlibc += multibyte/__mbsrtowcs_chk.o\nmusl += multibyte/mbstowcs.o\nlibc += multibyte/__mbstowcs_chk.o\nmusl += multibyte/mbtowc.o\nmusl += multibyte/wcrtomb.o\nmusl += multibyte/wcsnrtombs.o\nmusl += multibyte/wcsrtombs.o\nmusl += multibyte/wcstombs.o\nmusl += multibyte/wctob.o\nmusl += multibyte/wctomb.o\n\n$(out)/libc/multibyte/mbsrtowcs.o: CFLAGS += -Imusl/src/multibyte\n\nmusl += network/htonl.o\nmusl += network/htons.o\nmusl += network/ntohl.o\nmusl += network/ntohs.o\nifeq ($(conf_networking_stack),1)\nlibc += network/gethostbyname_r.o\nmusl += network/gethostbyname2_r.o\nmusl += network/gethostbyaddr_r.o\nmusl += network/gethostbyaddr.o\nmusl += network/resolvconf.o\nmusl += network/res_msend.o\n$(out)/musl/src/network/res_msend.o: CFLAGS += -Wno-maybe-uninitialized --include libc/syscall_to_function.h --include libc/internal/pthread_stubs.h $(cc-hide-flags-$(conf_hide_symbols))\n$(out)/libc/multibyte/mbsrtowcs.o: CFLAGS += -Imusl/src/multibyte\nmusl += network/lookup_ipliteral.o\nlibc += network/getaddrinfo.o\nlibc += network/freeaddrinfo.o\nmusl += network/res_mkquery.o\nmusl += network/dns_parse.o\nmusl += network/in6addr_any.o\nmusl += network/in6addr_loopback.o\nmusl += network/lookup_name.o\nmusl += network/lookup_serv.o\nlibc += network/getnameinfo.o\nlibc += network/__dns.o\nlibc_to_hide += network/__dns.o\nlibc += network/__ipparse.o\nlibc_to_hide += network/__ipparse.o\nmusl += network/inet_addr.o\nmusl += network/inet_aton.o\nmusl += network/inet_pton.o\nmusl += network/inet_ntop.o\nmusl += network/proto.o\nmusl += network/if_indextoname.o\n$(out)/musl/src/network/if_indextoname.o: CFLAGS += --include libc/syscall_to_function.h --include libc/network/__socket.h -Wno-stringop-truncation\nmusl += network/if_nametoindex.o\n$(out)/musl/src/network/if_nametoindex.o: CFLAGS += --include libc/syscall_to_function.h --include libc/network/__socket.h -Wno-stringop-truncation\nmusl += network/gai_strerror.o\nmusl += network/h_errno.o\nmusl += network/getservbyname_r.o\nmusl += network/getservbyname.o\nmusl += network/getservbyport_r.o\nmusl += network/getservbyport.o\nmusl += network/getifaddrs.o\nmusl += network/if_nameindex.o\nmusl += network/if_freenameindex.o\nmusl += network/netlink.o\n$(out)/musl/src/network/netlink.o: CFLAGS += --include libc/syscall_to_function.h --include libc/network/__netlink.h\nendif\nmusl += network/dn_expand.o\nmusl += network/res_init.o\n\nmusl += prng/rand.o\nmusl += prng/rand_r.o\nlibc += prng/random.o\nmusl += prng/__rand48_step.o\nmusl += prng/__seed48.o\nmusl += prng/drand48.o\nmusl += prng/lcong48.o\nmusl += prng/lrand48.o\nmusl += prng/mrand48.o\nmusl += prng/seed48.o\n$(out)/musl/src/prng/seed48.o: CFLAGS += -Wno-array-parameter\nmusl += prng/srand48.o\nlibc += random.o\n\nlibc += process/execve.o\nmusl += process/execle.o\nmusl += process/execv.o\nmusl += process/execl.o\nlibc += process/waitpid.o\nmusl += process/wait.o\n\nmusl += setjmp/$(musl_arch)/setjmp.o\nmusl += setjmp/$(musl_arch)/longjmp.o\nlibc += arch/$(arch)/setjmp/sigsetjmp.o\nlibc += signal/block.o\nlibc += signal/siglongjmp.o\nifeq ($(arch),x64)\nlibc += arch/$(arch)/ucontext/getcontext.o\nlibc += arch/$(arch)/ucontext/setcontext.o\nlibc += arch/$(arch)/ucontext/start_context.o\nlibc_to_hide += arch/$(arch)/ucontext/start_context.o\nlibc += arch/$(arch)/ucontext/ucontext.o\nifeq ($(conf_memory_optimize),1)\nlibc += string/memmove.o\nendif\nendif\n\nmusl += search/tfind.o\nmusl += search/tsearch.o\n\nmusl += stdio/__fclose_ca.o\nlibc += stdio/__fdopen.o\n$(out)/libc/stdio/__fdopen.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/__fmodeflags.o\nlibc += stdio/__fopen_rb_ca.o\nlibc += stdio/__fprintf_chk.o\nlibc += stdio/__lockfile.o\nmusl += stdio/__overflow.o\nmusl += stdio/__stdio_close.o\n$(out)/musl/src/stdio/__stdio_close.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/__stdio_exit.o\nlibc += stdio/__stdio_read.o\nmusl += stdio/__stdio_seek.o\n$(out)/musl/src/stdio/__stdio_seek.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/__stdio_write.o\n$(out)/musl/src/stdio/__stdio_write.o: CFLAGS += --include libc/syscall_to_function.h\nlibc += stdio/__stdout_write.o\nmusl += stdio/__string_read.o\nmusl += stdio/__toread.o\nmusl += stdio/__towrite.o\nmusl += stdio/__uflow.o\nlibc += stdio/__vfprintf_chk.o\nlibc += stdio/ofl.o\nmusl += stdio/ofl_add.o\nmusl += stdio/asprintf.o\nmusl += stdio/clearerr.o\nmusl += stdio/dprintf.o\nmusl += stdio/ext.o\nmusl += stdio/ext2.o\nmusl += stdio/fclose.o\nmusl += stdio/feof.o\nmusl += stdio/ferror.o\nmusl += stdio/fflush.o\nlibc += stdio/fgetc.o\nmusl += stdio/fgetln.o\nmusl += stdio/fgetpos.o\nmusl += stdio/fgets.o\nmusl += stdio/fgetwc.o\nmusl += stdio/fgetws.o\nmusl += stdio/fileno.o\nlibc += stdio/flockfile.o\nlibc += stdio/fmemopen.o\nmusl += stdio/fopen.o\n$(out)/musl/src/stdio/fopen.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/fprintf.o\nlibc += stdio/fputc.o\nmusl += stdio/fputs.o\nmusl += stdio/fputwc.o\nmusl += stdio/fputws.o\nmusl += stdio/fread.o\nlibc += stdio/__fread_chk.o\nmusl += stdio/freopen.o\n$(out)/musl/src/stdio/freopen.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/fscanf.o\nmusl += stdio/fseek.o\nmusl += stdio/fsetpos.o\nmusl += stdio/ftell.o\nlibc += stdio/ftrylockfile.o\nlibc += stdio/funlockfile.o\nmusl += stdio/fwide.o\nmusl += stdio/fwprintf.o\nmusl += stdio/fwrite.o\nmusl += stdio/fwscanf.o\nlibc += stdio/getc.o\nmusl += stdio/getc_unlocked.o\nlibc += stdio/getchar.o\nmusl += stdio/getchar_unlocked.o\nmusl += stdio/getdelim.o\nmusl += stdio/getline.o\nmusl += stdio/gets.o\nmusl += stdio/getw.o\nmusl += stdio/getwc.o\nmusl += stdio/getwchar.o\nlibc += stdio/open_memstream.o\nlibc += stdio/open_wmemstream.o\nmusl += stdio/perror.o\nmusl += stdio/printf.o\nlibc += stdio/putc.o\nmusl += stdio/putc_unlocked.o\nlibc += stdio/putchar.o\nmusl += stdio/putchar_unlocked.o\nmusl += stdio/puts.o\nmusl += stdio/putw.o\nmusl += stdio/putwc.o\nmusl += stdio/putwchar.o\nlibc += stdio/remove.o\nmusl += stdio/rewind.o\nmusl += stdio/scanf.o\nmusl += stdio/setbuf.o\nmusl += stdio/setbuffer.o\nmusl += stdio/setlinebuf.o\nlibc += stdio/setvbuf.o\nmusl += stdio/snprintf.o\nmusl += stdio/sprintf.o\nlibc += stdio/sscanf.o\nlibc += stdio/stderr.o\nlibc += stdio/stdin.o\nlibc += stdio/stdout.o\nmusl += stdio/swprintf.o\nmusl += stdio/swscanf.o\nmusl += stdio/tempnam.o\n$(out)/musl/src/stdio/tempnam.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/tmpfile.o\n$(out)/musl/src/stdio/tmpfile.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/tmpnam.o\n$(out)/musl/src/stdio/tmpnam.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += stdio/ungetc.o\nmusl += stdio/ungetwc.o\nmusl += stdio/vasprintf.o\nlibc += stdio/vdprintf.o\nlibc += stdio/vfprintf.o\n$(out)/libc/stdio/vfprintf.o: COMMON += -Wno-maybe-uninitialized\nmusl += stdio/vfscanf.o\n$(out)/musl/src/stdio/vfscanf.o: COMMON += -Wno-maybe-uninitialized\nmusl += stdio/vfwprintf.o\nmusl += stdio/vfwscanf.o\n$(out)/musl/src/stdio/vfwscanf.o: COMMON += -Wno-maybe-uninitialized\nmusl += stdio/vprintf.o\nmusl += stdio/vscanf.o\nlibc += stdio/vsnprintf.o\nmusl += stdio/vsprintf.o\nlibc += stdio/vsscanf.o\nlibc += stdio/vswprintf.o\nlibc += stdio/vswscanf.o\nmusl += stdio/vwprintf.o\nmusl += stdio/vwscanf.o\nmusl += stdio/wprintf.o\nmusl += stdio/wscanf.o\nlibc += stdio/printf-hooks.o\n\nmusl += stdlib/abs.o\nmusl += stdlib/atof.o\nmusl += stdlib/atoi.o\nmusl += stdlib/atol.o\nmusl += stdlib/atoll.o\nmusl += stdlib/bsearch.o\nmusl += stdlib/div.o\nmusl += stdlib/ecvt.o\nmusl += stdlib/fcvt.o\nmusl += stdlib/gcvt.o\nmusl += stdlib/imaxabs.o\nmusl += stdlib/imaxdiv.o\nmusl += stdlib/labs.o\nmusl += stdlib/ldiv.o\nmusl += stdlib/llabs.o\nmusl += stdlib/lldiv.o\nmusl += stdlib/qsort.o\n$(out)/musl/src/stdlib/qsort.o: COMMON += -Wno-dangling-pointer\nlibc += stdlib/qsort_r.o\n$(out)/libc/stdlib/qsort_r.o: COMMON += -Wno-dangling-pointer\nlibc += stdlib/strtol.o\nlibc += stdlib/strtod.o\nlibc += stdlib/wcstol.o\nifeq ($(arch),x64)\nlibc += stdlib/unimplemented.o\nendif\n\nlibc += string/__memcpy_chk.o\nlibc += string/explicit_bzero.o\nlibc += string/__explicit_bzero_chk.o\nmusl += string/bcmp.o\nmusl += string/bcopy.o\nmusl += string/bzero.o\nmusl += string/index.o\nmusl += string/memccpy.o\nmusl += string/memchr.o\nmusl += string/memcmp.o\nifeq ($(conf_memory_optimize),1)\nlibc += string/memcpy.o\nlibc_to_hide += string/memcpy.o\nelse\nmusl += string/memcpy.o\nmusl += string/memset.o\nmusl += string/memmove.o\nendif\nmusl += string/memmem.o\nmusl += string/mempcpy.o\nmusl += string/memrchr.o\nlibc += string/__memmove_chk.o\nlibc += string/memset.o\nlibc_to_hide += string/memset.o\nlibc += string/__memset_chk.o\nlibc += string/rawmemchr.o\nmusl += string/rindex.o\nmusl += string/stpcpy.o\nlibc += string/__stpcpy_chk.o\nmusl += string/stpncpy.o\nmusl += string/strcasecmp.o\nmusl += string/strcasestr.o\nmusl += string/strcat.o\nlibc += string/__strcat_chk.o\nmusl += string/strchr.o\nmusl += string/strchrnul.o\nmusl += string/strcmp.o\nmusl += string/strcpy.o\nlibc += string/__strcpy_chk.o\nmusl += string/strcspn.o\nmusl += string/strdup.o\nlibc += string/strerror_r.o\nmusl += string/strlcat.o\nmusl += string/strlcpy.o\nmusl += string/strlen.o\nmusl += string/strncasecmp.o\nmusl += string/strncat.o\nlibc += string/__strncat_chk.o\nmusl += string/strncmp.o\nmusl += string/strncpy.o\nlibc += string/__strncpy_chk.o\nmusl += string/strndup.o\nmusl += string/strnlen.o\nmusl += string/strpbrk.o\nmusl += string/strrchr.o\nmusl += string/strsep.o\nlibc += string/stresep.o\nlibc_to_hide += string/stresep.o\nmusl += string/strsignal.o\nmusl += string/strspn.o\nmusl += string/strstr.o\nmusl += string/strtok.o\nmusl += string/strtok_r.o\nmusl += string/strverscmp.o\nmusl += string/swab.o\nmusl += string/wcpcpy.o\nmusl += string/wcpncpy.o\nmusl += string/wcscasecmp.o\nmusl += string/wcscasecmp_l.o\nmusl += string/wcscat.o\nmusl += string/wcschr.o\nmusl += string/wcscmp.o\nmusl += string/wcscpy.o\nlibc += string/__wcscpy_chk.o\nmusl += string/wcscspn.o\nmusl += string/wcsdup.o\nmusl += string/wcslen.o\nmusl += string/wcsncasecmp.o\nmusl += string/wcsncasecmp_l.o\nmusl += string/wcsncat.o\nmusl += string/wcsncmp.o\nmusl += string/wcsncpy.o\nlibc += string/__wcsncpy_chk.o\nmusl += string/wcsnlen.o\nmusl += string/wcspbrk.o\nmusl += string/wcsrchr.o\nmusl += string/wcsspn.o\nmusl += string/wcsstr.o\nmusl += string/wcstok.o\nmusl += string/wcswcs.o\nmusl += string/wmemchr.o\nmusl += string/wmemcmp.o\nmusl += string/wmemcpy.o\nlibc += string/__wmemcpy_chk.o\nmusl += string/wmemmove.o\nlibc += string/__wmemmove_chk.o\nmusl += string/wmemset.o\nlibc += string/__wmemset_chk.o\n\nmusl += temp/__randname.o\nmusl += temp/mkdtemp.o\nmusl += temp/mkstemp.o\nmusl += temp/mktemp.o\nmusl += temp/mkostemp.o\nmusl += temp/mkostemps.o\n\nmusl += time/__map_file.o\n$(out)/musl/src/time/__map_file.o: CFLAGS += --include libc/syscall_to_function.h\nmusl += time/__month_to_secs.o\nmusl += time/__secs_to_tm.o\nmusl += time/__tm_to_secs.o\nlibc += time/__tz.o\n$(out)/libc/time/__tz.o: pre-include-api = -isystem include/api/internal_musl_headers -isystem musl/src/include\nlibc += time/__year_to_secs.o\nmusl += time/asctime.o\nmusl += time/asctime_r.o\nmusl += time/ctime.o\nmusl += time/ctime_r.o\nmusl += time/difftime.o\nmusl += time/getdate.o\nmusl += time/gmtime.o\nmusl += time/gmtime_r.o\nmusl += time/localtime.o\nmusl += time/localtime_r.o\nmusl += time/mktime.o\nmusl += time/strftime.o\nmusl += time/strptime.o\nmusl += time/time.o\nmusl += time/timegm.o\nmusl += time/wcsftime.o\nmusl += time/ftime.o\n$(out)/libc/time/ftime.o: CFLAGS += -Ilibc/include\n\nmusl += termios/tcflow.o\n\nmusl += unistd/sleep.o\nmusl += unistd/gethostname.o\nlibc += unistd/sethostname.o\nlibc += unistd/sync.o\nlibc += unistd/getpgid.o\nlibc += unistd/setpgid.o\nlibc += unistd/getpgrp.o\nlibc += unistd/getppid.o\nlibc += unistd/getsid.o\nlibc += unistd/ttyname_r.o\nmusl += unistd/ttyname.o\nmusl += unistd/tcgetpgrp.o\nmusl += unistd/tcsetpgrp.o\nmusl += unistd/setpgrp.o\n\nmusl += regex/fnmatch.o\nmusl += regex/glob.o\nmusl += regex/regcomp.o\n$(out)/musl/src/regex/regcomp.o: CFLAGS += -UNDEBUG\nmusl += regex/regexec.o\n$(out)/musl/src/regex/regexec.o: CFLAGS += -UNDEBUG\nmusl += regex/regerror.o\nmusl += regex/tre-mem.o\n$(out)/musl/src/regex/tre-mem.o: CFLAGS += -UNDEBUG\n\nlibc += pthread.o\nlibc_to_hide += pthread.o\nlibc += pthread_barrier.o\nlibc += libc.o\nlibc += dlfcn.o\nlibc += time.o\nlibc_to_hide += time.o\nlibc += signal.o\nlibc_to_hide += signal.o\nlibc += mman.o\nlibc_to_hide += mman.o\nlibc += sem.o\nlibc_to_hide += sem.o\nlibc += pipe_buffer.o\nlibc_to_hide += pipe_buffer.o\nlibc += pipe.o\nlibc_to_hide += pipe.o\nlibc += af_local.o\nlibc_to_hide += af_local.o\nlibc += user.o\nlibc += resource.o\nlibc += mount.o\nlibc += eventfd.o\nlibc_to_hide += eventfd.o\nlibc += timerfd.o\nlibc_to_hide += timerfd.o\nlibc += shm.o\nlibc += inotify.o\nlibc += __pread64_chk.o\nlibc += __read_chk.o\nlibc += syslog.o\nlibc += cxa_thread_atexit.o\nlibc += cpu_set.o\nlibc += malloc_hooks.o\nlibc += mallopt.o\n\nlibc += linux/makedev.o\n\nmusl += fenv/fegetexceptflag.o\nmusl += fenv/feholdexcept.o\nmusl += fenv/fesetexceptflag.o\nmusl += fenv/fesetround.o\nmusl += fenv/$(musl_arch)/fenv.o\n\nmusl += crypt/crypt_blowfish.o\nmusl += crypt/crypt.o\nmusl += crypt/crypt_des.o\nmusl += crypt/crypt_md5.o\nmusl += crypt/crypt_r.o\nmusl += crypt/crypt_sha256.o\nmusl += crypt/crypt_sha512.o\nmusl += crypt/encrypt.o\n\n#include $(src)/fs/build.mk:\n\nfs_objs :=\n\nfs_objs += fs.o \\\n\tunsupported.o\n\nfs_objs += vfs/main.o \\\n\tvfs/kern_descrip.o \\\n\tvfs/kern_physio.o \\\n\tvfs/subr_uio.o \\\n\tvfs/vfs_bdev.o \\\n\tvfs/vfs_bio.o \\\n\tvfs/vfs_conf.o \\\n\tvfs/vfs_lookup.o \\\n\tvfs/vfs_mount.o \\\n\tvfs/vfs_vnode.o \\\n\tvfs/vfs_task.o \\\n\tvfs/vfs_syscalls.o \\\n\tvfs/vfs_fops.o \\\n\tvfs/vfs_dentry.o\n\nfs_objs += ramfs/ramfs_vfsops.o \\\n\tramfs/ramfs_vnops.o\n\nfs_objs += devfs/devfs_vnops.o \\\n\tdevfs/device.o\n\nfs_objs += rofs/rofs_vfsops.o \\\n\trofs/rofs_vnops.o \\\n\trofs/rofs_cache.o \\\n\trofs/rofs_common.o\n\nifeq ($(conf_drivers_virtio),1)\nfs_objs += virtiofs/virtiofs_vfsops.o \\\n\tvirtiofs/virtiofs_vnops.o \\\n\tvirtiofs/virtiofs_dax.o\nendif\n\nfs_objs += pseudofs/pseudofs.o\nifeq ($(conf_fs_procfs),1)\nfs_objs += procfs/procfs_vnops.o\nendif\nifeq ($(conf_fs_sysfs),1)\nfs_objs += sysfs/sysfs_vnops.o\nendif\nfs_objs += zfs/zfs_null_vfsops.o\n\nobjects += $(addprefix fs/, $(fs_objs))\nobjects += $(addprefix libc/, $(libc))\nobjects += $(addprefix musl/src/, $(musl))\n\nlibc_objects_to_hide = $(addprefix $(out)/libc/, $(libc_to_hide))\n$(libc_objects_to_hide): cc-hide-flags = $(cc-hide-flags-$(conf_hide_symbols))\n$(libc_objects_to_hide): cxx-hide-flags = $(cxx-hide-flags-$(conf_hide_symbols))\n\nlibstdc++.a := $(shell $(CXX) -print-file-name=libstdc++.a)\nifeq ($(filter /%,$(libstdc++.a)),)\nifeq ($(arch),aarch64)\n    libstdc++.a := $(shell find $(aarch64_gccbase)/ -name libstdc++.a)\n    ifeq ($(libstdc++.a),)\n        $(error Error: libstdc++.a needs to be installed.)\n    endif\nelse\n    $(error Error: libstdc++.a needs to be installed.)\nendif\nendif\n\nlibgcc.a := $(shell $(CC) -print-libgcc-file-name)\nifeq ($(filter /%,$(libgcc.a)),)\nifeq ($(arch),aarch64)\n    libgcc.a := $(shell find $(aarch64_gccbase)/ -name libgcc.a |  grep -v /32/)\n    ifeq ($(libgcc.a),)\n        $(error Error: libgcc.a needs to be installed.)\n    endif\nelse\n    $(error Error: libgcc.a needs to be installed.)\nendif\nendif\n\nlibgcc_eh.a := $(shell $(CC) -print-file-name=libgcc_eh.a)\nifeq ($(filter /%,$(libgcc_eh.a)),)\nifeq ($(arch),aarch64)\n    libgcc_eh.a := $(shell find $(aarch64_gccbase)/ -name libgcc_eh.a |  grep -v /32/)\n    ifeq ($(libgcc_eh.a),)\n        $(error Error: libgcc_eh.a needs to be installed.)\n    endif\nelse\n    $(error Error: libgcc_eh.a needs to be installed.)\nendif\nendif\n\n#Allow user specify non-default location of boost\nifeq ($(boost_base),)\n    # link with -mt if present, else the base version (and hope it is multithreaded)\n    boost-mt := -mt\n    boost-lib-dir := $(dir $(shell $(CC) --print-file-name libboost_system$(boost-mt).a))\n    ifeq ($(filter /%,$(boost-lib-dir)),)\n        boost-mt :=\n        boost-lib-dir := $(dir $(shell $(CC) --print-file-name libboost_system$(boost-mt).a))\n    endif\n    # When boost_env=host, we won't use \"-nostdinc\", so the build machine's\n    # header files will be used normally. So we don't need to add anything\n    # special for Boost.\n    boost-includes =\n    ifeq ($(filter /%,$(boost-lib-dir)),)\n        # If the compiler cannot find the boost library, for aarch64 we look in a\n        # special location before giving up.\n        ifeq ($(arch),aarch64)\n            aarch64_boostbase = build/downloaded_packages/aarch64/boost/install\n            ifeq (,$(wildcard $(aarch64_boostbase)))\n                $(error Missing $(aarch64_boostbase) directory. Please run \"./scripts/download_aarch64_packages.py\")\n            endif\n\n            boost-lib-dir := $(firstword $(dir $(shell find $(aarch64_boostbase)/ -name libboost_system*.a)))\n            boost-mt := $(if $(filter %-mt.a, $(wildcard $(boost-lib-dir)/*.a)),-mt)\n            boost-includes = -isystem $(aarch64_boostbase)/usr/include\n        else\n            $(error Error: libboost_system.a needs to be installed.)\n        endif\n    endif\nelse\n    # Use boost specified by the user\n    boost-lib-dir := $(firstword $(dir $(shell find $(boost_base)/ -name libboost_system*.a)))\n    boost-mt := $(if $(filter %-mt.a, $(wildcard $(boost-lib-dir)/*.a)),-mt)\n    boost-includes = -isystem $(boost_base)/usr/include\nendif\n\nboost-libs := $(boost-lib-dir)/libboost_system$(boost-mt).a\n\nobjects += fs/nfs/nfs_null_vfsops.o\nobjects += fs/ext/ext_null_vfsops.o\n\n$(out)/loader.o: CXXFLAGS += -DHIDE_SYMBOLS=$(conf_hide_symbols)\n$(out)/core/trace.o: CXXFLAGS += -DHIDE_SYMBOLS=$(conf_hide_symbols)\n\n# The OSv kernel is linked into an ordinary, non-PIE, executable, so there is no point in compiling\n# with -fPIC or -fpie and objects that can be linked into a PIE. On the contrary, PIE-compatible objects\n# have overheads and can cause problems (see issue #1112). Recently, on some systems gcc's\n# default was changed to use -fpie, so we need to undo this default by explicitly specifying -fno-pie.\n$(objects:%=$(out)/%) $(drivers:%=$(out)/%) $(out)/arch/$(arch)/boot.o $(out)/loader.o $(out)/runtime.o: COMMON += -fno-pie\n\n# ld has a known bug (https://sourceware.org/bugzilla/show_bug.cgi?id=6468)\n# where if the executable doesn't use shared libraries, its .dynamic section\n# is dropped, even when we use the \"--export-dynamic\" (which is silently\n# ignored). The workaround is to link loader.elf with a do-nothing library.\n$(out)/dummy-shlib.so: $(out)/dummy-shlib.o\n\t$(call quiet, $(CXX) -nodefaultlibs -shared $(gcc-sysroot) -o $@ $^, LINK $@)\n\nstage1_targets = $(out)/arch/$(arch)/boot.o $(out)/loader.o $(out)/runtime.o $(drivers:%=$(out)/%) $(objects:%=$(out)/%) $(out)/dummy-shlib.so\nstage1: $(stage1_targets) links\n.PHONY: stage1\n\nloader_options_dep = $(out)/arch/$(arch)/loader_options.ld\n$(loader_options_dep): stage1\n\t$(makedir)\n\t@if [ '$(shell cat $(loader_options_dep) 2>&1)' != 'APP_LOCAL_EXEC_TLS_SIZE = $(app_local_exec_tls_size);' ]; then \\\n\t\techo -n \"APP_LOCAL_EXEC_TLS_SIZE = $(app_local_exec_tls_size);\" > $(loader_options_dep) ; \\\n\tfi\n\nifeq ($(conf_hide_symbols),1)\nversion_script_file:=$(out)/version_script\n#Detect which version script to be used and copy to $(out)/version_script\n#so that loader.elf/zfs_builder.elf is rebuilt accordingly if version script has changed\nifdef conf_version_script\nifeq (,$(wildcard $(conf_version_script)))\n    $(error Missing version script: $(conf_version_script))\nendif\nifneq ($(shell cmp $(out)/version_script $(conf_version_script)),)\n$(shell cp $(conf_version_script) $(out)/version_script)\nendif\nelse\nifneq ($(shell cmp $(out)/version_script $(out)/default_version_script),)\n$(shell cp $(out)/default_version_script $(out)/version_script)\nendif\nendif\nlinker_archives_options = --no-whole-archive $(libstdc++.a) $(libgcc.a) $(libgcc_eh.a) $(boost-libs) \\\n  --exclude-libs libstdc++.a --gc-sections\nifneq ($(shell grep -c iconv $(out)/version_script),0)\nmusl += locale/iconv.o\nmusl += locale/iconv_close.o\nelse\nlibc += locale/iconv_stubs.o\nendif\nelse\nlinker_archives_options = --whole-archive $(libstdc++.a) $(libgcc_eh.a) $(boost-libs) --no-whole-archive $(libgcc.a)\nmusl += locale/iconv.o\nmusl += locale/iconv_close.o\nendif\n\nifeq ($(arch),aarch64)\ndef_symbols = --defsym=OSV_KERNEL_VM_BASE=$(kernel_vm_base)\nelse\ndef_symbols = --defsym=OSV_KERNEL_BASE=$(kernel_base) \\\n              --defsym=OSV_KERNEL_VM_BASE=$(kernel_vm_base) \\\n              --defsym=OSV_KERNEL_VM_SHIFT=$(kernel_vm_shift)\nendif\n\n$(out)/loader.elf: $(stage1_targets) arch/$(arch)/loader.ld $(out)/bootfs.o $(out)/libvdso-content.o $(loader_options_dep) $(version_script_file)\n\t$(call quiet, $(LD) -o $@ $(def_symbols) \\\n\t\t-Bdynamic --export-dynamic --eh-frame-hdr --enable-new-dtags -L$(out)/arch/$(arch) \\\n            $(patsubst %version_script,--version-script=%version_script,$(patsubst %.ld,-T %.ld,$^)) \\\n\t    $(linker_archives_options) $(conf_linker_extra_options), \\\n\t\tLINK loader.elf)\n\t@# Build libosv.so matching this loader.elf. This is not a separate\n\t@# rule because that caused bug #545.\n\t@readelf --dyn-syms --wide $(out)/loader.elf > $(out)/osv.syms\n\t@scripts/libosv.py $(out)/osv.syms $(out)/libosv.ld `scripts/osv-version.sh` | $(CC) -c -o $(out)/osv.o -x assembler -\n\t@echo '0000000000000000 T _text' > $(out)/osv.kallsyms\n\t@echo '0000000000000000 T _stext' >> $(out)/osv.kallsyms\n\t@grep ': 0000' $(out)/osv.syms | grep -v 'NOTYPE' | awk '{ print $$2 \" T \" $$8 }' | c++filt >> $(out)/osv.kallsyms\n\t$(call quiet, $(CC) $(out)/osv.o -nostdlib -shared -o $(out)/libosv.so -T $(out)/libosv.ld, LIBOSV.SO)\n\n$(out)/zfs_builder.elf: $(stage1_targets) arch/$(arch)/loader.ld $(out)/zfs_builder_bootfs.o $(out)/libvdso-content.o $(loader_options_dep) $(version_script_file)\n\t$(call quiet, $(LD) -o $@ $(def_symbols) \\\n\t\t-Bdynamic --export-dynamic --eh-frame-hdr --enable-new-dtags -L$(out)/arch/$(arch) \\\n            $(patsubst %version_script,--version-script=%version_script,$(patsubst %.ld,-T %.ld,$^)) \\\n\t    $(linker_archives_options) $(conf_linker_extra_options), \\\n\t\tLINK zfs_builder.elf)\n$(out)/zfs_builder-stripped.elf:  $(out)/zfs_builder.elf\n\t$(call quiet, $(STRIP) $(out)/zfs_builder.elf -o $(out)/zfs_builder-stripped.elf, STRIP zfs_builder.elf -> zfs_builder-stripped.elf )\n\n$(out)/bsd/%.o: COMMON += -DSMP -D'__FBSDID(__str__)=extern int __bogus__'\n\nenviron_sources = $(addprefix libc/, $(environ_libc))\nenviron_sources += $(addprefix musl/src/, $(environ_musl))\n\n$(out)/libenviron.so: pre-include-api = -isystem include/api/internal_musl_headers -isystem musl/src/include\n$(out)/libenviron.so: source-dialects =\n\n$(out)/libenviron.so: $(environ_sources)\n\t$(makedir)\n\t $(call quiet, $(CC) $(CFLAGS) -shared -o $(out)/libenviron.so $(environ_sources), CC libenviron.so)\n\n$(out)/libvdso.so: libc/vdso/vdso.cc\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -fno-exceptions -c -fPIC -o $(out)/libvdso.o libc/vdso/vdso.cc, CXX libvdso.o)\n\t$(call quiet, $(LD) -shared -z now -o $(out)/libvdso.so $(out)/libvdso.o -T libc/vdso/vdso.lds --version-script=libc/vdso/$(arch)/vdso.version, LINK libvdso.so)\n\nbootfs_manifest ?= bootfs.manifest.skel\n\n# If parameter \"bootfs_manifest\" has been changed since the last make,\n# bootfs.bin requires rebuilding\nbootfs_manifest_dep = $(out)/bootfs_manifest.last\n.PHONY: phony\n$(bootfs_manifest_dep): phony\n\t@if [ '$(shell cat $(bootfs_manifest_dep) 2>&1)' != '$(bootfs_manifest)' ]; then \\\n\t\techo -n $(bootfs_manifest) > $(bootfs_manifest_dep) ; \\\n\tfi\n\nlibgcc_s_dir := $(dir $(shell $(CC) -print-file-name=libgcc_s.so.1))\nifeq ($(filter /%,$(libgcc_s_dir)),)\nlibgcc_s_dir := ../../$(aarch64_gccbase)/lib64\nendif\n\n$(out)/bootfs.bin: scripts/mkbootfs.py $(bootfs_manifest) $(bootfs_manifest_dep) $(tools:%=$(out)/%) \\\n\t\t$(out)/libenviron.so $(out)/libsolaris.so\n\t$(call quiet, olddir=`pwd`; cd $(out); \"$$olddir\"/scripts/mkbootfs.py -o bootfs.bin -d bootfs.bin.d -m \"$$olddir\"/$(bootfs_manifest), MKBOOTFS $@)\n\n$(out)/bootfs.o: $(out)/bootfs.bin\n$(out)/bootfs.o: ASFLAGS += -I$(out)\n\n$(out)/libvdso-stripped.so: $(out)/libvdso.so\n\t$(call quiet, $(STRIP) $(out)/libvdso.so -o $(out)/libvdso-stripped.so, STRIP libvdso.so -> libvdso-stripped.so)\n\n$(out)/libvdso-content.o: $(out)/libvdso-stripped.so\n$(out)/libvdso-content.o: ASFLAGS += -I$(out)\n\n# Standard C++ library\nlibstd_dir := $(dir $(shell $(CXX) -print-file-name=libstdc++.so))\nifeq ($(filter /%,$(libstd_dir)),)\nifeq ($(arch),aarch64)\n    libstd_dir := $(dir $(shell find $(aarch64_gccbase)/ -name libstdc++.so))\n    ifeq ($(libstd_dir),)\n        $(error Error: libstdc++.so needs to be installed.)\n    endif\n    LDFLAGS := -L$(libstd_dir)\nelse\n    $(error Error: libstdc++.so needs to be installed.)\nendif\nendif\n\n$(shell mkdir -p $(out) && cp zfs_builder_bootfs.manifest.skel $(out)/zfs_builder_bootfs.manifest)\nifeq ($(conf_hide_symbols),1)\n$(shell echo \"/usr/lib/libstdc++.so.6: $$(readlink -f $(libstd_dir))/libstdc++.so\" >> $(out)/zfs_builder_bootfs.manifest)\nendif\n$(out)/zfs_builder_bootfs.bin: scripts/mkbootfs.py $(zfs_builder_bootfs_manifest) $(tools:%=$(out)/%) \\\n\t\t$(out)/zpool.so $(out)/zfs.so $(out)/libenviron.so $(out)/libsolaris.so\n\t$(call quiet, olddir=`pwd`; cd $(out); \"$$olddir\"/scripts/mkbootfs.py -o zfs_builder_bootfs.bin -d zfs_builder_bootfs.bin.d -m zfs_builder_bootfs.manifest \\\n\t\t-D libgcc_s_dir=$(libgcc_s_dir), MKBOOTFS $@)\n\n$(out)/zfs_builder_bootfs.o: $(out)/zfs_builder_bootfs.bin\n$(out)/zfs_builder_bootfs.o: ASFLAGS += -I$(out)\n\n$(out)/tools/mkfs/mkfs.so: $(out)/tools/mkfs/mkfs.o $(out)/libzfs.so\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -o $@ $(out)/tools/mkfs/mkfs.o $(LDFLAGS) -L$(out) -lzfs, LINK mkfs.so)\n\n$(out)/tools/cpiod/cpiod.so: $(out)/tools/cpiod/cpiod.o $(out)/tools/cpiod/cpio.o $(out)/tools/cpiod/options.o $(out)/libzfs.so\n\t$(makedir)\n\t$(call quiet, $(CXX) $(CXXFLAGS) -o $@ $(out)/tools/cpiod/cpiod.o $(out)/tools/cpiod/cpio.o $(out)/tools/cpiod/options.o $(LDFLAGS) -L$(out) -lzfs, LINK cpiod.so)\n\n################################################################################\n# The dependencies on header files are automatically generated only after the\n# first compilation, as explained above. However, header files generated by\n# the Makefile are special, in that they need to be created even *before* the\n# first compilation. Moreover, some (namely version.h) need to perhaps be\n# re-created on every compilation. \"generated-headers\" is used as an order-\n# only dependency on C compilation rules above, so we don't try to compile\n# C code before generating these headers.\ngenerated-headers: $(out)/gen/include/bits/alltypes.h perhaps-modify-version-h perhaps-modify-drivers-config-h perhaps-modify-syscalls-h\n.PHONY: generated-headers\n\n# While other generated headers only need to be generated once, version.h\n# should be recreated on every compilation. To avoid a cascade of\n# recompilation, the rule below makes sure not to modify version.h's timestamp\n# if the version hasn't changed.\nperhaps-modify-version-h:\n\t$(call quiet, sh scripts/gen-version-header $(out)/gen/include/osv/version.h, GEN gen/include/osv/version.h)\n.PHONY: perhaps-modify-version-h\n#\n# This generates 3 files included by linux.cc - syscalls_config.h, syscalls.cc and syscall_tracepoints.cc.\n# By default gen-syscalls copies the syscalls/syscalls.cc.in and syscalls/syscall_tracepoints.cc as is.\n# If conf_syscalls_list_file parameter is specified, it will filter in only parts of these 2 files based on\n# the list of names of the syscalls in the file conf_syscalls_list_file\n# In either case, syscalls_config.h will contain list of '#define CONF_syscall_*' statements for each selected\n# syscall\nperhaps-modify-syscalls-h:\n\t$(call quiet, bash scripts/gen-syscalls $(out)/gen/include/osv/ $(conf_syscalls_list_file), GEN gen/include/osv/syscall_*)\n.PHONY: perhaps-modify-syscalls-h\n\n# Using 'if ($(conf_drivers_*),1)' in the rules below is enough to include whole object\n# files. Sometimes though we need to enable or disable portions of the code specific\n# to given driver (the arch-setup.cc is best example). To that end the rule below\n# generates drivers_config.h header file with the macros CONF_drivers_* which is\n# then included by relevant source files.\n# This allows for fairly rapid rebuilding of the kernel for specified profiles\n# as only few files need to be re-compiled.\nperhaps-modify-drivers-config-h:\n\t$(call quiet, sh scripts/gen-drivers-config-header $(arch) $(out)/gen/include/osv/drivers_config.h, GEN gen/include/osv/drivers_config.h)\n.PHONY: perhaps-modify-drivers-config-h\n\n$(out)/gen/include/bits/alltypes.h: include/api/$(arch)/bits/alltypes.h.sh\n\t$(makedir)\n\t$(call quiet, sh $^ > $@, GEN $@)\n\n# The generated header ctype-data.h is different in that it is only included\n# at one place (runtime.c), so instead of making it a dependency of\n# generated-headers, we can just make it a dependency of runtime.o\n$(out)/runtime.o: $(out)/gen/include/ctype-data.h\n\n$(out)/gen/include/ctype-data.h: $(out)/gen-ctype-data\n\t$(makedir)\n\t$(call quiet, $(out)/gen-ctype-data > $@, GEN $@)\n\n$(out)/gen-ctype-data: gen-ctype-data.cc\n\t$(call quiet, $(HOST_CXX) -o $@ $^, HOST_CXX $@)\n\n################################################################################\n\n\n\n\n#include $(src)/bsd/cddl/contrib/opensolaris/lib/libuutil/common/build.mk:\nlibuutil-file-list = uu_alloc uu_avl uu_dprintf uu_ident uu_list uu_misc uu_open uu_pname uu_string uu_strtoint\nlibuutil-objects = $(foreach file, $(libuutil-file-list), $(out)/bsd/cddl/contrib/opensolaris/lib/libuutil/common/$(file).o)\n\ndefine libuutil-includes\n  bsd/cddl/contrib/opensolaris/lib/libuutil/common\n  bsd/cddl/compat/opensolaris/include\n  bsd/sys/cddl/contrib/opensolaris/uts/common\n  bsd/sys/cddl/compat/opensolaris\n  bsd/cddl/contrib/opensolaris/head\n  bsd/include\nendef\n\ncflags-libuutil-include = $(foreach path, $(strip $(libuutil-includes)), -isystem $(path))\n\n$(libuutil-objects): local-includes += $(cflags-libuutil-include)\n\n# disable the main bsd include search order, we want it before osv but after solaris\n$(libuutil-objects): post-includes-bsd =\n\n$(libuutil-objects): kernel-defines =\n\n$(libuutil-objects): CFLAGS += -Wno-unknown-pragmas\n\n$(out)/libuutil.so: $(libuutil-objects)\n\t$(makedir)\n\t$(q-build-so)\n\n#include $(src)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/build.mk:\n\nlibzfs-file-list = changelist config dataset diff import iter mount pool status util\nlibzfs-objects = $(foreach file, $(libzfs-file-list), $(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/libzfs_$(file).o)\n\nlibzpool-file-list = util kernel\nlibzpool-objects = $(foreach file, $(libzpool-file-list), $(out)/bsd/cddl/contrib/opensolaris/lib/libzpool/common/$(file).o)\n\nlibsolaris-objects = $(foreach file, $(solaris) $(xdr), $(out)/$(file))\nlibsolaris-objects += $(out)/bsd/porting/kobj.o $(out)/fs/zfs/zfs_initialize.o\n\n$(libsolaris-objects): kernel-defines = -D_KERNEL $(source-dialects) -fvisibility=hidden -ffunction-sections -fdata-sections\n\n$(out)/fs/zfs/zfs_initialize.o: CFLAGS+= \\\n\t-DBUILDING_ZFS \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/common/zfs \\\n\t-Ibsd/sys/cddl/compat/opensolaris \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/common \\\n\t-Ibsd/sys/cddl/contrib/opensolaris/uts/common \\\n\t-Ibsd/sys \\\n\t-Wno-array-bounds \\\n\t-fno-strict-aliasing \\\n\t-Wno-unknown-pragmas \\\n\t-Wno-unused-variable \\\n\t-Wno-switch \\\n\t-Wno-maybe-uninitialized\n\n#build libsolaris.so with -z,now so that all symbols get resolved eagerly (BIND_NOW)\n#also make sure libsolaris.so has osv-mlock note (see zfs_initialize.c) so that\n# the file segments get loaded eagerly as well when mmapped\ncomma:=,\n$(out)/libsolaris.so: $(libsolaris-objects)\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -Wl$(comma)-z$(comma)now -Wl$(comma)--gc-sections -o $@ $(libsolaris-objects) -L$(out), LINK libsolaris.so)\n\nlibzfs-objects += $(libzpool-objects)\nlibzfs-objects += $(out)/bsd/cddl/compat/opensolaris/misc/mkdirp.o\nlibzfs-objects += $(out)/bsd/cddl/compat/opensolaris/misc/zmount.o\nlibzfs-objects += $(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/zfs_prop.o\nlibzfs-objects += $(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/zprop_common.o\n\ndefine libzfs-includes\n  bsd/cddl/compat/opensolaris/lib/libumem\n  bsd/cddl/contrib/opensolaris/head\n  bsd/cddl/contrib/opensolaris/lib/libzpool/common\n  bsd/cddl/contrib/opensolaris/lib/libuutil/common\n  bsd/cddl/compat/opensolaris/include\n  bsd/cddl/contrib/opensolaris/lib/libzfs/common\n  bsd/cddl/contrib/opensolaris/lib/libnvpair\n  bsd/lib/libgeom\n  bsd/sys/cddl/compat/opensolaris\n  bsd/sys/cddl/contrib/opensolaris/uts/common\n  bsd/sys/cddl/contrib/opensolaris/uts/common/sys\n  bsd/sys/cddl/contrib/opensolaris/uts/common/fs/zfs\n  bsd/sys/cddl/contrib/opensolaris/common/zfs\n  bsd/sys/cddl/contrib/opensolaris/uts/common/zmod\n  bsd/include\n  bsd\n  bsd/sys\nendef\n\ncflags-libzfs-include = $(foreach path, $(strip $(libzfs-includes)), -isystem $(path))\n\n$(libzfs-objects): local-includes += $(cflags-libzfs-include)\n\n# disable the main bsd include search order, we want it before osv but after solaris\n$(libzfs-objects): post-includes-bsd =\n\n$(libzfs-objects): kernel-defines =\n\n$(libzfs-objects): CFLAGS += -D_GNU_SOURCE\n\n$(libzfs-objects): CFLAGS += -Wno-switch -D__va_list=__builtin_va_list '-DTEXT_DOMAIN=\"\"' \\\n\t\t\t-Wno-maybe-uninitialized -Wno-unused-variable -Wno-unknown-pragmas -Wno-unused-function \\\n\t\t\t-D_OPENSOLARIS_SYS_UIO_H_\n\n$(out)/bsd/cddl/contrib/opensolaris/lib/libzpool/common/kernel.o: CFLAGS += -fvisibility=hidden\n$(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/zfs_prop.o: CFLAGS += -fvisibility=hidden\n\n# Note: zfs_prop.c and zprop_common.c are also used by the kernel, thus the manual targets.\n$(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/zfs_prop.o: bsd/sys/cddl/contrib/opensolaris/common/zfs/zfs_prop.c | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -c -o $@ $<, CC $<)\n\n$(out)/bsd/cddl/contrib/opensolaris/lib/libzfs/common/zprop_common.o: bsd/sys/cddl/contrib/opensolaris/common/zfs/zprop_common.c | generated-headers\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -c -o $@ $<, CC $<)\n\n$(out)/libzfs.so: $(libzfs-objects) $(out)/libuutil.so $(out)/libsolaris.so\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -o $@ $(libzfs-objects) -L$(out) -luutil, LINK libzfs.so)\n\n#include $(src)/bsd/cddl/contrib/opensolaris/cmd/zpool/build.mk:\nzpool-cmd-file-list = zpool_iter  zpool_main  zpool_util  zpool_vdev\n\nzpool-cmd-objects = $(foreach x, $(zpool-cmd-file-list), $(out)/bsd/cddl/contrib/opensolaris/cmd/zpool/$x.o)\nzpool-cmd-objects += $(out)/bsd/porting/mnttab.o\n\ncflags-zpool-cmd-includes = $(cflags-libzfs-include) -Ibsd/cddl/contrib/opensolaris/cmd/stat/common\n\n$(zpool-cmd-objects): kernel-defines =\n\n$(zpool-cmd-objects): CFLAGS += -D_GNU_SOURCE\n\n$(zpool-cmd-objects): local-includes += $(cflags-zpool-cmd-includes)\n\n$(zpool-cmd-objects): CFLAGS += -Wno-switch -D__va_list=__builtin_va_list '-DTEXT_DOMAIN=\"\"' \\\n\t\t\t-Wno-maybe-uninitialized -Wno-unused-variable -Wno-unknown-pragmas -Wno-unused-function\n\n\n$(out)/zpool.so: $(zpool-cmd-objects) $(out)/libzfs.so\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -o $@ $(zpool-cmd-objects) -L$(out) -lzfs, LINK zpool.so)\n\n#include $(src)/bsd/cddl/contrib/opensolaris/cmd/zfs/build.mk:\nzfs-cmd-file-list = zfs_iter zfs_main\n\nzfs-cmd-objects = $(foreach x, $(zfs-cmd-file-list), $(out)/bsd/cddl/contrib/opensolaris/cmd/zfs/$x.o)\nzfs-cmd-objects += $(out)/bsd/porting/mnttab.o\n\ncflags-zfs-cmd-includes = $(cflags-libzfs-include)\n\n$(zfs-cmd-objects): kernel-defines =\n\n$(zfs-cmd-objects): CFLAGS += -D_GNU_SOURCE\n\n$(zfs-cmd-objects): local-includes += $(cflags-zfs-cmd-includes)\n\n$(zfs-cmd-objects): CFLAGS += -Wno-switch -D__va_list=__builtin_va_list '-DTEXT_DOMAIN=\"\"' \\\n\t\t\t-Wno-maybe-uninitialized -Wno-unused-variable -Wno-unknown-pragmas -Wno-unused-function\n\n\n$(out)/zfs.so: $(zfs-cmd-objects) $(out)/libzfs.so\n\t$(makedir)\n\t$(call quiet, $(CC) $(CFLAGS) -o $@ $(zfs-cmd-objects) -L$(out) -lzfs, LINK zfs.so)\n"
        },
        {
          "name": "PORTING",
          "type": "blob",
          "size": 2.8212890625,
          "content": "AArch64 Port\n============\n\nThe AArch64 Port is being started, initially targeting the QEMU Mach-virt\nplatform, and running on the Foundation Model v8.\n\nThese are some brief instructions about how to cross-compile OSv's\nloader.img (very incomplete still) on an X86-64 build host machine.\n\n------------------------------\nEnvironment Variables for make\n------------------------------\n\nIn addition to the general requirements (see README.md),\nnote that the simple build system recognizes the CROSS_PREFIX\nenvironment variable, and looks for build tools prefixed with its contents.\n\nAlternatively, the following variables can be used to control the tools to use:\n\nCXX           The target C++ compiler\nHOST_CXX      The build host C++ compiler\nCC            The target C compiler\nLD            The target linker\nSTRIP         The target strip\nOBJCOPY       The target objcopy\n\nIf for some reason the ARCH-detection code does not work, it is possible to use\n\nARCH=aarch64\n\nto force the target architecture to AArch64.\n\n---------------------------------------\nCrosscompiler Tools & Image from Linaro\n---------------------------------------\n\nYou can find a [ 32bit :-( needs multilib] crosscompiler from Linaro,\nin particular the package\n\ngcc-linaro-aarch64-linux-gnu-4.8-2013.12_linux,\n\nwhich is not distro-specific [ :-) ], and includes all tools needed.\n\nFor debugging purposes, a standalone gdb package for target AAarch64\ncan be also downloaded from the Linaro web site.\n\nFor the root filesystem for AArch64, a good option is the Linaro LEG Image\n\nlinaro-image-leg-java-genericarmv8-20131215-598.rootfs.tar.gz\n\nhttp://www.linaro.org/downloads/\n\n------------------------------\nCrosscompiler Tools for Ubuntu\n------------------------------\n\nFor Ubuntu there are AArch64 crosscompilers available in the official\nrepositories as well e..g packages\n\ng++-4.8-aarch64-linux-gnu\ngcc-4.8-aarch64-linux-gnu\n\n\n--------------------------------------\nARMv8 Foundation Model guest debugging\n--------------------------------------\n\nIn ARMv8 Foundation model it would be possible to debug the guest kernel\nvia the following setup:\n\n1. Start Foundation model with options\n\n--network=nat --network-nat-ports=1234=1234\n\nThe latter option will expose the gdb port used by QEMU on the host side\n(default port 1234) to the same port number in the guest running inside\nthe model.\n\n2. If you are skipping the user space initialization via something like\ninit=/bin/sh for speedup, in Foundation model you will need to run at least:\n\n/sbin/udhcpc eth0\n\n3. In Foundation model start qemu-system-aarch64 with the -s -S options\n\n4. On the host side, open gdb in a new terminal window and attach to the\nguest kernel with the command:\n\ntarget remote :1234\n\nThis is not currently functional due to unimplemented support in\nKVM/QEMU.\n\n---\nJani Kokkonen <jani.kokkonen@huawei.com>\nClaudio Fontana <claudio.fontana@huawei.com>\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 30.3388671875,
          "content": "***OSv was originally designed and implemented by Cloudius Systems (now ScyllaDB) however\n currently, it is being maintained and enhanced by a small community of volunteers.\n If you are into systems programming or want to learn and help us improve OSv, then please\n contact us on [OSv Google Group forum](https://groups.google.com/forum/#!forum/osv-dev)\n or feel free to pick up any [good issues for newcomers](https://github.com/cloudius-systems/osv/labels/good-for-newcomers).\n For details on how to format and send patches, please read\n [this wiki](https://github.com/cloudius-systems/osv/wiki/Formatting-and-sending-patches)\n (__we do accept pull requests as well__).***\n\n# OSv\n\nOSv is an open-source versatile modular **unikernel** designed to run single **unmodified\nLinux application** securely as microVM on top of a hypervisor, when compared to traditional\noperating systems which were designed for a vast range of physical machines. Built from\nthe ground up for effortless deployment and management of microservices\nand serverless apps, with superior performance.\n\nOSv has been designed to run unmodified x86-64 and aarch64 Linux\nbinaries **as is**, which effectively makes it a **Linux binary compatible unikernel**\n(for more details about Linux ABI compatibility please read\n[this doc](https://github.com/cloudius-systems/osv/wiki/OSv-Linux-ABI-Compatibility)).\nIn particular, OSv can run many managed language runtimes including\n[**JVM**](https://github.com/cloudius-systems/osv-apps/tree/master/java-example),\n[**Python**](https://github.com/cloudius-systems/osv-apps/tree/master/python-from-host),\n[**Node.JS**](https://github.com/cloudius-systems/osv-apps/tree/master/node-from-host),\n[**Ruby**](https://github.com/cloudius-systems/osv-apps/tree/master/ruby-example), **Erlang**,\nand applications built on top of those runtimes.\nIt can also run applications written in languages compiling directly to native machine code like\n**C**, **C++**,\n[**Golang**](https://github.com/cloudius-systems/osv-apps/tree/master/golang-httpserver)\nand [**Rust**](https://github.com/cloudius-systems/osv-apps/tree/master/rust-httpserver)\nas well as native images produced\nby [**GraalVM**](https://github.com/cloudius-systems/osv-apps/tree/master/graalvm-example)\nand [WebAssembly/Wasmer](https://github.com/cloudius-systems/osv-apps/tree/master/webassembly).\n\nOSv can boot as fast as **~5 ms** on Firecracker using as low as 11 MB of memory.\nOSv can run on many hypervisors including QEMU/KVM,\n[Firecracker](https://github.com/cloudius-systems/osv/wiki/Running-OSv-on-Firecracker),\n[Cloud Hypervisor](https://github.com/cloudius-systems/osv/wiki/Running-OSv-on-Cloud-Hypervisor),\nXen, [VMWare](https://github.com/cloudius-systems/osv/wiki/Running-OSv-on-VMware-ESXi),\n[VirtualBox](https://github.com/cloudius-systems/osv/wiki/Running-OSv-on-VirtualBox) and\nHyperkit as well as open clouds like AWS EC2, GCE and OpenStack.\n\nFor more information about OSv, see the [main wiki page](https://github.com/cloudius-systems/osv/wiki)\nand http://osv.io/.\n\n## Building and Running Apps on OSv\n\nTo run an application on OSv, one needs to build an image by fusing the OSv kernel, and\nthe application files together. This, at a high level, can be achieved in two ways, either:\n- by using the shell script located at `./scripts/build`\n that builds the kernel from sources and fuses it with application files, or\n- by using the [capstan tool](https://github.com/cloudius-systems/capstan) that uses *pre-built\n kernel* and combines it with application files to produce a final image.\n\nIf you intend to try to run your app on OSv with the least effort possible, you should pursue the *capstan*\nroute. For introduction please read this \n[crash course](https://github.com/cloudius-systems/osv/wiki/Build-and-run-apps-on-OSv-using-Capstan).\nFor more details about *capstan* please read \nthis more detailed [documentation](https://github.com/cloudius-systems/capstan#documentation). Pre-built OSv kernel files\n(`osv-loader.qemu`) can be automatically downloaded by *capstan* from \nthe [OSv regular releases page](https://github.com/cloudius-systems/osv/releases) or manually from \nthe [nightly releases repo](https://github.com/osvunikernel/osv-nightly-releases/releases/tag/ci-master-latest).\n\nIf you are comfortable with make and GCC toolchain and want to try the latest OSv code, then you should\nread this [part of the readme](#setting-up-development-environment) to guide you how to set up your\n development environment and build OSv kernel and application images.\n\n## Releases\n\nWe aim to release OSv 2-3 times a year. You can find the [latest one on github](https://github.com/cloudius-systems/osv/releases)\nalong with several published artifacts including kernel and some modules.\n\nIn addition, we have set up [Travis-based CI/CD pipeline](https://travis-ci.org/github/cloudius-systems/osv) where each\ncommit to the master and ipv6 branches triggers full build of the latest kernel and publishes some artifacts to \nthe [nightly releases repo](https://github.com/osvunikernel/osv-nightly-releases/releases). Each commit also\ntriggers the publishing of new Docker \"build toolchain\" images to the [Docker hub](https://hub.docker.com/u/osvunikernel).\n\n## Design\n\nA good bit of the design of OSv is pretty well explained in \nthe [Components of OSv](https://github.com/cloudius-systems/osv/wiki/Components-of-OSv) wiki page. You \ncan find even more information in the original \n[USENIX paper and its presentation](https://www.usenix.org/conference/atc14/technical-sessions/presentation/kivity).\n\nIn addition, you can find a lot of good information about the design of specific OSv components on\nthe [main wiki page](https://github.com/cloudius-systems/osv/wiki) and http://osv.io/ and http://blog.osv.io/.\nUnfortunately, some of that information may be outdated (especially on http://osv.io/), so it is always\nbest to ask on the [mailing list](https://groups.google.com/forum/#!forum/osv-dev) if in doubt.\n\n## Component Diagram\nIn the diagram below, you can see the major components of OSv across the logical layers. Starting with `libc` at the top, which is greatly based on `musl`, the core layer in the middle comprises ELF dynamic linker, VFS, networking stack, thread scheduler, page cache, RCU, and memory management components. Then finally down, the layer is composed of the clock, block, and networking device drivers that allow OSv to interact with hypervisors like VMware and VirtualBox or the ones based on KVM and XEN.\n![Component Diagram](../master/documentation/OSv_Component_Diagram.png)\n\n## Metrics and Performance\n\nThere are no official **up-to date** performance metrics comparing OSv to other unikernels or Linux.\nIn general, OSv lags behind Linux in disk-I/O-intensive workloads partially due to coarse-grained locking \nin VFS around read/write operations as described in this [issue](https://github.com/cloudius-systems/osv/issues/450).\nIn network-I/O-intensive workloads, OSv should fare better (or at least used to as Linux has advanced a lot since)\nas shown with performance tests of Redis and [Memcached](https://github.com/cloudius-systems/osv/wiki/OSv-Case-Study:-Memcached).\nYou can find some old \"numbers\" on the main wiki, http://osv.io/benchmarks, and some papers listed at the bottom of this readme.\n\nSo OSv is probably not best suited to run MySQL or ElasticSearch, but should deliver pretty solid performance for general\n stateless applications like microservices or serverless (at least as some papers show).\n\n### Kernel Size\n\nAt this moment (as of December 2022) the size of the universal OSv kernel (`loader.elf` artifact) *built with all symbols hidden* is around\n3.6 MB. The size of the kernel linked with the full `libstdc++.so.6` library and ZFS filesystem library included is 6.8 MB. Please read the [Modularization](https://github.com/cloudius-systems/osv/wiki/Modularization) wiki to better understand how kernel can be built and further reduced in size and customized to run on a specific hypervisor or a specific app.\n\nThe size of OSv kernel may be considered quite large compared to other unikernels. However, bear in mind that OSv kernel (being unikernel) provides **subset** of the functionality of the following Linux libraries (see their approximate size on Linux host):\n- `libresolv.so.2` (_100 K_)\n- `libc.so.6` (_2 MB_)\n- `libm.so.6` (_1.4 MB_)\n- `ld-linux-x86-64.so.2` (_184 K_)\n- `libpthread.so.0` (_156 K_)\n- `libdl.so.2` (_20 K_)\n- `librt.so.1` (_40 K_)\n- `libstdc++.so.6` (_2 MB_)\n- `libaio.so.1` (_16 K_)\n- `libxenstore.so.3.0` (_32 K_)\n- `libcrypt.so.1` (_44 K_)\n\n### Boot Time\n\nOSv, with _Read-Only FS and networking off_, can boot as fast as **~5 ms** on Firecracker \nand even faster around **~3 ms** on QEMU with the microvm machine. However, in general, the boot time\nwill depend on many factors like hypervisor including settings of individual para-virtual devices, \nfilesystem (ZFS, ROFS, RAMFS, or Virtio-FS), and some boot parameters. Please note that by default OSv images\nget built with ZFS filesystem.\n\nFor example, the boot time of ZFS image on Firecracker is ~40 ms, and regular QEMU ~200 ms these days. Also,\nnewer versions of QEMU (>=4.0) are typically faster to boot. Booting on QEMU in PVH/HVM mode (aka direct kernel boot, enabled \nby `-k` option of `run.py`) should always be faster as OSv is directly invoked in 64-bit long mode. Please see\n[this Wiki](https://github.com/cloudius-systems/osv/wiki/OSv-boot-methods-overview) for a brief review of the boot\nmethods OSv supports.\n\nFinally, some boot parameters passed to the kernel may affect the boot time:\n- `--console serial` - this disables VGA console that is [slow to initialize](https://github.com/cloudius-systems/osv/issues/987) and can shave off 60-70 ms on QEMU\n- `--nopci` - this disables enumeration of PCI devices especially if we know none are present (QEMU with microvm or Firecracker) and can shave off 10-20 ms \n- `--redirect=/tmp/out` - writing to the console can impact the performance quite severely (30-40%) if application logs \na lot, so redirecting standard output and error to a file might speed up performance quite a lot\n\nYou can always see boot time breakdown by adding `--bootchart` parameter:\n```\n./scripts/run.py -e '--bootchart /hello'\nOSv v0.57.0-6-gb442a218\neth0: 192.168.122.15\n\tdisk read (real mode): 58.62ms, (+58.62ms)\n\tuncompress lzloader.elf: 77.20ms, (+18.58ms)\n\tTLS initialization: 77.96ms, (+0.76ms)\n\t.init functions: 79.75ms, (+1.79ms)\n\tSMP launched: 80.11ms, (+0.36ms)\n\tVFS initialized: 81.62ms, (+1.52ms)\n\tNetwork initialized: 81.78ms, (+0.15ms)\n\tpvpanic done: 81.91ms, (+0.14ms)\n\tpci enumerated: 93.89ms, (+11.98ms)\n\tdrivers probe: 93.89ms, (+0.00ms)\n\tdrivers loaded: 174.80ms, (+80.91ms)\n\tROFS mounted: 176.88ms, (+2.08ms)\n\tTotal time: 178.01ms, (+1.13ms)\nCmdline: /hello\nHello from C code\n```\n\n### Memory Utilization\n\nOSv needs at least 11 M of memory to run a _hello world_ app. Even though it is a third of what it was 4 years ago, it is still quite a lot compared to other unikernels. The applications spawning many threads may take advantage of building the kernel with the option `conf_lazy_stack=1` to further reduce memory utilization (please see the comments of this [patch](https://github.com/cloudius-systems/osv/commit/f5684d9c3f4f8d20a64605cfe66fd51771754256) to understand this feature better). \n\nWe are planning to further lower this number by adding [self-tuning logic to L1/L2 memory pools](https://github.com/cloudius-systems/osv/issues/1013).\n\n## Testing\n\nOSv comes with around 140 unit tests that get executed upon every commit and run on ScyllaDB servers. There are also a number of extra\ntests located under `tests/` sub-tree that are not automated at this point.\n\nYou can run unit tests in a number of ways:\n```\n./scripts/build check                  # Create ZFS test image and run all tests on QEMU\n\n./scripts/build check fs=rofs          # Create ROFS test image and run all tests on QEMU\n\n./scripts/build image=tests && \\       # Create ZFS test image and run all tests on Firecracker\n./scripts/test.py -p firecracker\n\n./scripts/build image=tests && \\       # Create ZFS test image and run all tests on QEMU\n./scripts/test.py -p qemu_microvm      # with microvm machine\n```\n\nIn addition, there is an [Automated Testing Framework](https://github.com/cloudius-systems/osv/wiki/Automated-Testing-Framework)\nthat can be used to run around 30 real apps, some of them\nunder stress using `ab` or `wrk` tools. The intention is to catch any regressions that may be missed\nby unit tests.\n\nFinally, one can use [Docker files](https://github.com/cloudius-systems/osv/tree/master/docker#docker-osv-builder) to\ntest OSv on different Linux distributions.\n\n## Setting up Development Environment\n\nOSv can only be built on a 64-bit x86 and ARM Linux distribution. Please note that\nthis means the \"x86_64\" or \"amd64\" version for 64-bit x86 and \"aarch64\" or \"arm64\" version for ARM respectively.\n\nTo build the OSv kernel you need a physical or virtual machine with Linux distribution on it and GCC toolchain and\nall necessary packages and libraries OSv build process depends on. The fastest way to set it up is to use the\n[Docker files](https://github.com/cloudius-systems/osv/tree/master/docker#docker-osv-builder) that OSv comes with.\nYou can use them to build your own Docker image and then start it in order to build OSv kernel or run an app on OSv inside of it.\nPlease note that the main docker file depends on pre-built base **Docker images** for \n[Ubuntu](https://hub.docker.com/repository/docker/osvunikernel/osv-ubuntu-20.10-builder-base) \nor [Fedora](https://hub.docker.com/repository/docker/osvunikernel/osv-fedora-31-builder-base) \nthat get published to DockerHub upon every commit. This should speed up building the final images\nas all necessary packages are installed as part of the base images.\n\nAlternatively, you can manually clone the OSv repo and use [setup.py](https://github.com/cloudius-systems/osv/blob/master/scripts/setup.py)\nto install all required packages and libraries, as long as it supports your Linux distribution, and you have both git \nand python 3 installed on your machine:\n```bash\ngit clone https://github.com/cloudius-systems/osv.git\ncd osv && git submodule update --init --recursive\n./scripts/setup.py\n```\n\nThe `setup.py` recognizes and installs packages for a number of Linux distributions including Fedora, Ubuntu,\n[Debian](https://github.com/cloudius-systems/osv/wiki/Building-OSv-on-Debian-stable), LinuxMint and RedHat ones \n(Scientific Linux, NauLinux, CentOS Linux, Red Hat Enterprise Linux, Oracle Linux). Please note that we actively\nmaintain and test only Ubuntu and Fedora, so your mileage with other distributions may vary. The support of CentOS 7\nhas also been recently added and tested so it should work as well. The `setup.py`\nis used by Docker files internally to achieve the same result. \n\n### IDEs\n\nIf you like working in IDEs, we recommend either [Eclipse CDT](https://www.eclipse.org/cdt/) which can be setup\nas described in this [wiki page](https://github.com/cloudius-systems/osv/wiki/Working-With-Eclipse-CDT) or \n[CLion from JetBrains](https://www.jetbrains.com/clion/) which can be set to work with OSv makefile using\nso-called compilation DB as described in this [guide](https://www.jetbrains.com/help/clion/managing-makefile-projects.html).\n\n## Building OSv Kernel and Creating Images\n\nBuilding OSv is as easy as using the shell script `./scripts/build`\nthat orchestrates the build process by delegating to the main [makefile](https://github.com/cloudius-systems/osv/blob/master/Makefile)\nto build the kernel and by using a number of Python scripts like `./scripts/module.py` \nto build application and *fuse* it together with the kernel\ninto a final image placed at `./build/release/usr.img` (or `./build/$(arch)/usr.img` in general).\nPlease note that *building an application* does not necessarily mean building from sources as in many \ncases the application binaries would be located on and copied from the Linux build machine\nusing the shell script `./scripts/manifest_from_host.sh`\n(see [this Wiki page](https://github.com/cloudius-systems/osv/wiki/Running-unmodified-Linux-executables-on-OSv) for details).\n\nThe shell script `build` can be used as the examples below illustrate:\n```bash\n# Create a default image that comes with a command line and REST API server\n./scripts/build\n\n# Create an image with native-example app\n./scripts/build -j4 fs=rofs image=native-example\n\n# Create an image with spring boot app with Java 10 JRE\n./scripts/build JAVA_VERSION=10 image=openjdk-zulu-9-and-above,spring-boot-example\n\n # Create an image with 'ls' executable taken from the host\n./scripts/manifest_from_host.sh -w ls && ./scripts/build --append-manifest\n\n# Create a test image and run all tests in it\n./scripts/build check\n\n# Clean the build tree\n./scripts/build clean\n```\n\nCommand nproc will calculate the number of jobs/threads for make and `./scripts/build` automatically.\nAlternatively, the environment variable MAKEFLAGS can be exported as follows:\n\n```\nexport MAKEFLAGS=-j$(nproc)\n```\n\nIn that case, make and scripts/build do not need the parameter -j.\n\nFor details on how to use the build script, please run `./scripts/build --help`.\n\nThe `./scripts/build` creates the image `build/last/usr.img` in qcow2 format.\nTo convert this image to other formats, use the `./scripts/convert`\ntool, which can convert an image to the vmdk, vdi or raw formats.\nFor example:\n\n```\n./scripts/convert raw\n```\n\n### Aarch64\n\nBy default, the OSv kernel gets built for the native host architecture (x86_64 or aarch64), but it is also possible\n to cross-compile kernel and modules on Intel machine for ARM by adding **arch** parameter like so:\n```bash\n./scripts/build arch=aarch64\n```\nAt this point cross-compiling the **aarch64** version of OSv is only supported\non Fedora, Ubuntu, and CentOS 7, and relevant aarch64 gcc and libraries' binaries can be downloaded using\nthe `./scripts/download_aarch64_packages.py` script. OSv can also be built natively on Ubuntu on ARM hardware\nlike Raspberry PI 4, Odroid N2+, or RockPro64. \n\nPlease note that as of the latest [0.57.0 release](https://github.com/cloudius-systems/osv/releases/tag/v0.57.0), the ARM part of OSv has been greatly improved and tested and is pretty much on par with the x86_64 port in terms of the functionality.\nIn addition, all unit tests and many  advanced apps like Java, golang, nginx, python, iperf3, etc can successfully run\non QEMU and Firecraker on Raspberry PI 4 and Odroid N2+ with KVM acceleration enabled.\n\nFor more information about the aarch64 port please read [this Wiki page](https://github.com/cloudius-systems/osv/wiki/AArch64).\n\n### Filesystems\n\nAt the end of the boot process, the OSv dynamic linker loads an application ELF and any related libraries\nfrom the filesystem on a disk that is part of the image. By default, the images built by `./scripts/build`\ncontain a disk formatted with the ZFS filesystem, which you can read more about [here](https://github.com/cloudius-systems/osv/wiki/ZFS).\nZFS is a great read-write file system and may be a perfect fit if you want to run MySQL on OSv. However, it may be an overkill\nif you want to run stateless apps in which case you may consider \n[Read-Only FS](https://github.com/cloudius-systems/osv/commit/cd449667b7f86721095ddf4f9f3f8b87c1c414c9). Finally,\nyou can also have OSv read the application binary from RAMFS, in which case the filesystem gets embedded as part of\nthe kernel ELF. You can specify which filesystem to build the image disk with\nby setting the parameter `fs` of `./scripts/build` to one of the three values -`zfs`, `rofs`, or `ramfs`.\n\nIn addition, one can mount NFS filesystem, which had been recently transformed to be a shared library pluggable as a [module](https://github.com/cloudius-systems/osv/tree/master/modules/nfs), and newly implemented and improved [Virtio-FS filesystem](https://stefanha.github.io/virtio/virtio-fs.html#x1-41500011). The Virtio-FS mounts can be set up by adding proper entry `/etc/fstab` or by passing a boot parameter as explained in this [Wiki](https://github.com/cloudius-systems/osv/wiki/virtio-fs). In addition, very recently OSv has been enhanced to be able to boot from Virtio-FS filesystem directly.\n\nMoreover, we have added support for the ext2/3/4 filesystem, in the form of a shared pluggable module [`libext`](https://github.com/cloudius-systems/osv/tree/master/modules/libext). One can add the `libext` module to an image and have OSv mount the ext filesystem from a separate disk like so (for more detailed examples please read [here](https://github.com/cloudius-systems/osv/tree/master/modules/libext#building-image-with-ext4-support)):\n```bash\n./scripts/build fs=rofs image=libext,native-example\n\n./scripts/run.py --execute='--mount-fs=ext,/dev/vblk1,/data /hello' --second-disk-image ./ext4.img\n```\n\nFinally, the ZFS support has been also greatly improved as of the 0.57 release and there are many methods and setups to build and run ZFS images with OSv. For details please read the ZFS section of the [Filesystems wiki](https://github.com/cloudius-systems/osv/wiki/Filesystems#zfs).\n\n## Running OSv\n\nRunning an OSv image, built by `scripts/build`, is as easy as:\n```bash\n./scripts/run.py\n```\n\nBy default, the `run.py` runs OSv under KVM, with 4 vCPUs and 2 GB of memory. \nYou can control these and tens of others ones by passing relevant parameters to \nthe `run.py`. For details, on how to use the script, please run `./scripts/run.py --help`.\n\nThe `run.py` can run an OSv image on QEMU/KVM, Xen, and VMware. If running under KVM you can terminate by hitting Ctrl+A X.\n\nAlternatively, you can use `./scripts/firecracker.py` to run OSv on [Firecracker](https://firecracker-microvm.github.io/). \nThis script automatically downloads firecracker binary if missing, and accepts several parameters like the number of vCPUs, and memory\nnamed exactly like `run.py` does. You can learn more about running OSv on Firecracker \nfrom this [wiki](https://github.com/cloudius-systems/osv/wiki/Running-OSv-on-Firecracker). \n\nPlease note that to run OSv with the best performance on Linux under QEMU or Firecracker you need KVM enabled \n(this is only possible on *physical* Linux machines, EC2 \"bare metal\" (i3) instances, or VMs that support nested virtualization with KVM on). \nThe easiest way to verify if KVM is enabled is to check if `/dev/kvm` is present, and your user account can read from and write to it. \nAdding your user to the kvm group may be necessary like so:\n```bash\nusermod -aG kvm <user name>\n```\n\nFor more information about building and running JVM, Node.JS, Python, and other managed runtimes as well as Rust, Golang, or C/C++ apps\non OSv, please read this [wiki page](https://github.com/cloudius-systems/osv/wiki#running-your-application-on-osv). \nFor more information about various example apps you can build and run on OSv, please read \n[the osv-apps repo README](https://github.com/cloudius-systems/osv-apps#osv-applications).\n\n### Application Types and Launch Modes\nRegarding how applications are launched on OSv, they all fall into two categories - **dynamically linked** and **statically linked** executables. The dynamically linked executables can be launched by the OSv built-into-kernel dynamic linker or the Linux dynamic linker `ld*.so`. The statically linked executables are bootstrapped but OSv dynamic linker but then interact via system calls with OSv kernel. For more details please watch the 1st half of [this presentation](https://fosdem.org/2024/schedule/event/fosdem-2024-3483-support-dynamically-linked-executables-via-linux-ld-so-and-implement-ena-driver-to-expand-application-of-osv/) or read [slides 2-7](https://fosdem.org/2024/events/attachments/fosdem-2024-3483-support-dynamically-linked-executables-via-linux-ld-so-and-implement-ena-driver-to-expand-application-of-osv/slides/22482/OSv_FOSDEM_24_5NmcHjr.pdf).\n#### Dynamically Linked Executables\nThe dynamically linked executables require the dynamic linker (built-in or Linux one) to bootstrap the main application ELF file, load the libraries it depends on, resolve symbols and eventually call the `main` function.\n##### Via Built-in Dynamic Linker and `libc`\nThe built-in dynamic linker plays the role of the program interpreter that performs similar steps as on Linux, but instead of loading the libraries it depends on from filesystem, it resolves the undefined symbols by pointing them to the implementations of those in OSv built-in `libc`. The OSv linker supports both Shared Libraries and Dynamically Linked Executables that are either position dependent or non-position dependent.\n\n```bash\n./scripts/build image=native-example\n./scripts/run.py -e '/hello'\n```\nThe benefit is that programs interact with the OSv kernel using the **fast local function calls** without the overhead of SYSCALL/SVC instruction. On the negative side, the Linux-compatibility is a moving target because GLIBc keeps adding new functions, and OSv needs to keep implementing them.\n##### Via Linux Dynamic Linker `ld*.so` and `glibc`\nSimilarly to the built-in dynamic linker, OSv can also launch dynamically linked executables via the Linux dynamic linker `ld*.so`. The Linux dynamic linker `ld*.so` is bootstrapped the exact same way as a statically linked executable (see below) and then it orchestrates loading and execution of the specified dynamically linked executables. Just like with statically linked executable, the application interacts with OSv kernel via system calls.\n```bash\ndl=linux ./scripts/manifest_from_host.sh /bin/ls && ./scripts/build image=empty --append-manifest\n./scripts/run.py -e '/lib64/ld-linux-x86-64.so.2 /hello'\n```\n#### Statically Linked Executables\nThe statically linked executables interact with OSv kernel by directly making system calls and reading from pseudo filesystems like procfs and sysfs like in Linux. \n\nIn this mode, the Linux-compatibility is should be improved. But compared to the dynamically linked executables that call *local functions*, the statically linked ones suffer from the ~110 ns system call overhead mainly paid to save and restore the state of regular registers and FPU. Having said that, most Linux applications have been written with the understanding that system calls are expensive and avoid them if possible so neither statically linked executables are affected negatively nor the dynamically linked ones launched via built-in dynamic linker benefit in any significant way.\n\nFor more information about OSv implementet syscalls please read this [wiki](https://github.com/cloudius-systems/osv/wiki/Syscalls).\n\n### Networking\n\nBy default, the `run.py`  starts OSv with\n [user networking/SLIRP](https://wiki.qemu.org/Documentation/Networking#User_Networking_.28SLIRP.29) on. \nTo start OSv with more performant external networking, you need to enable `-n` and `-v` options like so:\n\n```\nsudo ./scripts/run.py -nv\n```\n\nThe -v is for KVM's vhost that provides better performance\nand its setup requires tap device thus we use sudo.\n\nAlternatively, one can run OSv as a non-privileged used with a tap device like so:\n```\n./scripts/create_tap_device.sh natted qemu_tap0 172.18.0.1 #You can pick a different address but then update all IPs below\n\n./scripts/run.py -n -t qemu_tap0 \\\n  --execute='--ip=eth0,172.18.0.2,255.255.255.252 --defaultgw=172.18.0.1 --nameserver=172.18.0.1 /hello'\n```\n\nBy default, OSv spawns a `dhcpd`-like thread that automatically configures virtual NICs.\nA static configuration can be done within OSv by configuring networking like so:\n\n```\nifconfig virtio-net0 192.168.122.100 netmask 255.255.255.0 up\nroute add default gw 192.168.122.1\n```\n\nTo enable networking on Firecracker, you have to explicitly enable `-n` option\nto `firecracker.py`.\n\nFinally, please note that the master branch of OSv only implements IPV4 subset of the networking stack.\nIf you need IPV6, please build from [ipv6 branch](https://github.com/cloudius-systems/osv/tree/ipv6)\n or use IPV6 kernel published to [nightly releases repo](https://github.com/osvunikernel/osv-nightly-releases/releases/tag/ci-ipv6-latest). \n\n## Debugging, Monitoring, Profiling OSv\n\n- OSv can be debugged with gdb; for more details please read this\n [wiki](https://github.com/cloudius-systems/osv/wiki/Debugging-OSv)\n- OSv kernel and application can be traced and profiled; for more details please read \nthis [wiki](https://github.com/cloudius-systems/osv/wiki/Trace-analysis-using-trace.py)\n- OSv comes with the admin/monitoring REST API server; for more details please read \n[this](https://github.com/cloudius-systems/osv/wiki/Command-Line-Interface-(CLI)) and\n [that wiki page](https://github.com/cloudius-systems/osv/wiki/Using-OSv-REST-API). There is also\n lighter [monitoring REST API module](https://github.com/cloudius-systems/osv/commit/aa32614221254ce300f401bb99c506b528b85682) \n that is effectively a read-only subset of the former one. \n \n## FAQ and Contact\n\nIf you want to learn more about OSv or ask questions, \nplease contact us on [OSv Google Group forum](https://groups.google.com/forum/#!forum/osv-dev).\nYou can also follow us on [Twitter](https://twitter.com/osv_unikernel).\n\n## Papers and Articles about OSv\n\nList of somewhat newer articles about OSv found on the Web:\n* [P99 Presentation: OSv Unikernel — Optimizing Guest OS to Run Stateless and Serverless Apps in the Cloud](https://www.p99conf.io/session/osv-unikernel-optimizing-guest-os-to-run-stateless-and-serverless-apps-in-the-cloud/)\n* [Unikernels vs Containers: An In-Depth Benchmarking Study in the context of Microservice Applications](https://biblio.ugent.be/publication/8582433/file/8582438)\n* [Towards a Practical Ecosystem of Specialized OS Kernels](http://cs.iit.edu/~khale/docs/diver-ross19.pdf)\n* [A Performance Evaluation of Unikernels](https://pdfs.semanticscholar.org/d956/f72dbc65301578dc95e0f751f4ae7c09d831.pdf)\n* [Security Perspective on Unikernels](https://arxiv.org/pdf/1911.06260.pdf)\n* [Performance Evaluation of OSv for Server Applications](http://www.cs.utah.edu/~peterm/prelim-osv-performance.pdf)\n* [Time provisioning Evaluation of KVM, Docker and Unikernels in a Cloud Platform](https://tiagoferreto.github.io/pubs/2016ccgrid_xavier.pdf)\n* [Unikernels - Beyond Containers to the Next Generation of the Cloud](https://theswissbay.ch/pdf/_to_sort/O'Reilly/unikernels.pdf)\n\n### FOSDEM Presentations\n* [2024 - Support Dynamically Linked Executables via Linux ld.so and Implement ENA Driver to Expand Application of OSv](https://fosdem.org/2024/schedule/event/fosdem-2024-3483-support-dynamically-linked-executables-via-linux-ld-so-and-implement-ena-driver-to-expand-application-of-osv/)\n* [2023 - Evolution of OSv: Towards Greater Modularity and Composability](https://archive.fosdem.org/2023/schedule/event/osvevolution/)\n* [2014 - OSv, a New Operating System Designed for the Cloud](https://archive.fosdem.org/2014/schedule/event/virtiaas99/)\n\nYou can find some older articles and presentations at http://osv.io/resources and http://blog.osv.io/.\n"
        },
        {
          "name": "apps",
          "type": "commit",
          "content": null
        },
        {
          "name": "arch",
          "type": "tree",
          "content": null
        },
        {
          "name": "bootfs.S",
          "type": "blob",
          "size": 0.10546875,
          "content": ".pushsection .data\n.global bootfs_start\n.hidden bootfs_start\nbootfs_start:\n.incbin \"bootfs.bin\"\n.popsection\n"
        },
        {
          "name": "bootfs.manifest.skel",
          "type": "blob",
          "size": 0.05078125,
          "content": "[manifest]\n/usr/lib/fs/libsolaris.so: libsolaris.so\n"
        },
        {
          "name": "bootfs_empty.manifest.skel",
          "type": "blob",
          "size": 0.0107421875,
          "content": "[manifest]\n"
        },
        {
          "name": "bsd",
          "type": "tree",
          "content": null
        },
        {
          "name": "compiler",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.json",
          "type": "blob",
          "size": 0.2705078125,
          "content": "{\n   \"modules\": {\n        \"osvinit\": {\n            \"type\": \"direct-dir\",\n            \"path\": \"${OSV_BASE}/modules/cloud-init/\"\n        },\n    \"repositories\": [\n        \"${OSV_BASE}/apps\",\n        \"${OSV_BASE}/modules\"\n    ]\n   },\n   \"default\": [ \"cloud-init\", \"httpserver\" ]\n}\n"
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "documentation",
          "type": "tree",
          "content": null
        },
        {
          "name": "drivers",
          "type": "tree",
          "content": null
        },
        {
          "name": "dummy-shlib.cc",
          "type": "blob",
          "size": 0.0439453125,
          "content": "char force_creation_of_a_dynamic_executable;\n"
        },
        {
          "name": "exported_symbols",
          "type": "tree",
          "content": null
        },
        {
          "name": "external",
          "type": "tree",
          "content": null
        },
        {
          "name": "fastlz",
          "type": "tree",
          "content": null
        },
        {
          "name": "fs",
          "type": "tree",
          "content": null
        },
        {
          "name": "gen-ctype-data.cc",
          "type": "blob",
          "size": 1.12890625,
          "content": "/*\n * Copyright (C) 2013 Cloudius Systems, Ltd.\n *\n * This work is open source software, licensed under the terms of the\n * BSD license as described in the LICENSE file in the top-level directory.\n */\n\n#include <iostream>\n#include <ctype.h>\n\nnamespace {\n\n    void do_ctype(std::ostream& os, int i, int (*f)(int), std::string name)\n    {\n\tif (f(i)) {\n\t    os << \" | \" << name;\n\t}\n    }\n}\n\n#define DO(x) do_ctype(std::cout, i, is##x, \"_IS\" #x)\n\nint main(int ac, char **av)\n{\n    std::cout << \"static unsigned short c_locale_array[384] = {\\n\";\n    for (int i = -128; i < 256; ++i) {\n\tstd::cout << \"0\";\n\tDO(alnum);\n\tDO(alpha);\n\t/* DO(ascii); */\n\tDO(blank);\n\tDO(cntrl);\n\tDO(digit);\n\tDO(graph);\n\tDO(lower);\n\tDO(print);\n\tDO(punct);\n\tDO(space);\n\tDO(upper);\n\tDO(xdigit);\n\tstd::cout << \",\\n\";\n    }\n    std::cout << \"};\\n\";\n    std::cout << \"static int c_toupper_array[384] = {\\n\";\n    for (int i = -128; i < 256; ++i) {\n        std::cout << toupper(i) << \",\\n\";\n    }\n    std::cout << \"};\\n\";\n    std::cout << \"static int c_tolower_array[384] = {\\n\";\n    for (int i = -128; i < 256; ++i) {\n        std::cout << tolower(i) << \",\\n\";\n    }\n    std::cout << \"};\\n\";\n}\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "kbuild",
          "type": "commit",
          "content": null
        },
        {
          "name": "libc",
          "type": "tree",
          "content": null
        },
        {
          "name": "libvdso-content.S",
          "type": "blob",
          "size": 0.1884765625,
          "content": ".pushsection .data\n#ifdef __x86_64__\n.align 4096\n#endif\n#ifdef __aarch64__\n.align 16\n#endif\n.global libvdso_start\n.hidden libvdso_start\nlibvdso_start:\n.incbin \"libvdso-stripped.so\"\n.popsection\n"
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "linux.cc",
          "type": "blob",
          "size": 25.8291015625,
          "content": "/*\n * Copyright (C) 2013-2014 Cloudius Systems, Ltd.\n * Copyright (C) 2018-2024 Waldemar Kozaczuk\n *\n * This work is open source software, licensed under the terms of the\n * BSD license as described in the LICENSE file in the top-level directory.\n */\n\n// linux syscalls\n\n#include <osv/debug.hh>\n#include <osv/sched.hh>\n#include <osv/mutex.h>\n#include <osv/waitqueue.hh>\n#include <osv/stubbing.hh>\n#include <osv/export.h>\n#include <osv/trace.hh>\n#include <memory>\n\n#include <syscall.h>\n#include <stdarg.h>\n#include <errno.h>\n#include <signal.h>\n#include <time.h>\n#include <sys/epoll.h>\n#include <sys/eventfd.h>\n#include <sys/socket.h>\n#include <sys/utsname.h>\n#include <sys/mman.h>\n#include <stdlib.h>\n#include <signal.h>\n#include <sys/select.h>\n#include <sys/mman.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <sys/stat.h>\n#include <sys/statx.h>\n#include <fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/file.h>\n#include <sys/unistd.h>\n#include <sys/random.h>\n#include <sys/vfs.h>\n#include <sys/uio.h>\n#include <sys/epoll.h>\n#include <sys/sysinfo.h>\n#include <sys/sendfile.h>\n#include <sys/prctl.h>\n#include <sys/timerfd.h>\n#include <sys/resource.h>\n#include <sys/shm.h>\n#include <termios.h>\n#include <poll.h>\n#ifdef __x86_64__\n#include \"tls-switch.hh\"\n#endif\n\n#include <unordered_map>\n\n#include <musl/src/internal/ksigaction.h>\n\n#include <osv/kernel_config_core_epoll.h>\n#include <osv/kernel_config_networking_stack.h>\n#include <osv/kernel_config_core_syscall.h>\n\n#include <osv/syscalls_config.h>\n\nextern \"C\" int eventfd2(unsigned int, int);\n\nextern \"C\" OSV_LIBC_API long gettid()\n{\n    return sched::thread::current()->id();\n}\n\n// We don't expect applications to use the Linux futex() system call (it is\n// normally only used to implement higher-level synchronization mechanisms),\n// but unfortunately gcc's C++ runtime uses a subset of futex in the\n// __cxa__guard_* functions, which safeguard the concurrent initialization\n// of function-scope static objects. We only implement here this subset.\n// The __cxa_guard_* functions only call futex in the rare case of contention,\n// in fact so rarely that OSv existed for a year before anyone noticed futex\n// was missing. So the performance of this implementation is not critical.\nstatic std::unordered_map<void*, waitqueue> queues;\nstatic mutex queues_mutex;\n\n#define FUTEX_BITSET_MATCH_ANY  0xffffffff\n\nint futex(int *uaddr, int op, int val, const struct timespec *timeout,\n        int *uaddr2, uint32_t val3)\n{\n    switch (op & FUTEX_CMD_MASK) {\n    case FUTEX_WAIT_BITSET:\n        if (val3 != FUTEX_BITSET_MATCH_ANY) {\n            abort(\"Unimplemented futex() operation %d\\n\", op);\n        }\n\n    case FUTEX_WAIT:\n        WITH_LOCK(queues_mutex) {\n            if (*uaddr == val) {\n                waitqueue &q = queues[uaddr];\n                if (timeout) {\n                    sched::timer tmr(*sched::thread::current());\n                    if ((op & FUTEX_CMD_MASK) == FUTEX_WAIT_BITSET) {\n                        // If FUTEX_WAIT_BITSET we need to interpret timeout as an absolute\n                        // time point. If futex operation FUTEX_CLOCK_REALTIME is set we will use\n                        // real-time clock otherwise we will use monotonic clock\n                        if (op & FUTEX_CLOCK_REALTIME) {\n                            tmr.set(osv::clock::wall::time_point(std::chrono::seconds(timeout->tv_sec) +\n                                                                 std::chrono::nanoseconds(timeout->tv_nsec)));\n                        } else {\n                            tmr.set(osv::clock::uptime::time_point(std::chrono::seconds(timeout->tv_sec) +\n                                                                   std::chrono::nanoseconds(timeout->tv_nsec)));\n                        }\n                    } else {\n                        tmr.set(std::chrono::seconds(timeout->tv_sec) +\n                                std::chrono::nanoseconds(timeout->tv_nsec));\n                    }\n                    sched::thread::wait_for(queues_mutex, tmr, q);\n                    // FIXME: testing if tmr was expired isn't quite right -\n                    // we could have had both a wakeup and timer expiration\n                    // racing. It would be more correct to check if we were\n                    // waken by a FUTEX_WAKE. But how?\n                    if (tmr.expired()) {\n                        errno = ETIMEDOUT;\n                        return -1;\n                    }\n                } else {\n                    q.wait(queues_mutex);\n                }\n                return 0;\n            } else {\n                errno = EWOULDBLOCK;\n                return -1;\n            }\n        }\n    case FUTEX_WAKE:\n        if(val < 0) {\n            errno = EINVAL;\n            return -1;\n        }\n\n        WITH_LOCK(queues_mutex) {\n            auto i = queues.find(uaddr);\n            if (i != queues.end()) {\n                int waken = 0;\n                while( (val > waken) && !(i->second.empty()) ) {\n                    i->second.wake_one(queues_mutex);\n                    waken++;\n                }\n                if(i->second.empty()) {\n                    queues.erase(i);\n                }\n                return waken;\n            }\n        }\n        return 0;\n    default:\n        abort(\"Unimplemented futex() operation %d\\n\", op);\n    }\n}\n\n#if CONF_core_syscall\n// We're not supposed to export the get_mempolicy() function, as this\n// function is not part of glibc (which OSv emulates), but part of a\n// separate library libnuma, which the user can simply load. libnuma's\n// implementation of get_mempolicy() calls syscall(__NR_get_mempolicy,...),\n// so this is what we need to expose, below.\n\n#define MPOL_DEFAULT 0\n#define MPOL_F_NODE         (1<<0)\n#define MPOL_F_ADDR         (1<<1)\n#define MPOL_F_MEMS_ALLOWED (1<<2)\n\n#if CONF_syscall_get_mempolicy\nstatic long get_mempolicy(int *policy, unsigned long *nmask,\n        unsigned long maxnode, void *addr, int flags)\n{\n    // As OSv has no support for NUMA nodes, we do here the minimum possible,\n    // which is basically to return the same policy (MPOL_DEFAULT) and list\n    // of nodes (just node 0) no matter if the caller asked for the default\n    // policy, the allowed policy, or the policy for a specific address.\n    if ((flags & MPOL_F_NODE)) {\n        *policy = 0; // in this case, store a node id, not a policy\n        return 0;\n    }\n    if (policy) {\n        *policy = MPOL_DEFAULT;\n    }\n    if (nmask) {\n        if (maxnode < 1) {\n            errno = EINVAL;\n            return -1;\n        }\n        nmask[0] |= 1;\n    }\n    return 0;\n}\n#endif\n\n#if CONF_syscall_set_mempolicy\nstatic long set_mempolicy(int policy, unsigned long *nmask,\n        unsigned long maxnode)\n{\n    // OSv has very minimal support for NUMA - merely exposes\n    // all cpus as a single node0 and cannot really apply any meaningful policy\n    // Therefore we implement this as noop, ignore all arguments and return success\n    return 0;\n}\n#endif\n\n#if CONF_syscall_sys_sched_getaffinity\n// As explained in the sched_getaffinity(2) manual page, the interface of the\n// sched_getaffinity() function is slightly different than that of the actual\n// system call we need to implement here.\n#define __NR_sys_sched_getaffinity __NR_sched_getaffinity\nstatic int sys_sched_getaffinity(\n        pid_t pid, unsigned len, unsigned long *mask)\n{\n        int ret = sched_getaffinity(\n                pid, len, reinterpret_cast<cpu_set_t *>(mask));\n        if (ret == 0) {\n            // The Linux system call doesn't zero the entire len bytes of the\n            // given mask - it only sets up to the configured maximum number of\n            // CPUs (e.g., 64) and returns the amount of bytes it set at mask.\n            // We don't have this limitation (our sched_getaffinity() does zero\n            // the whole len), but some user code (e.g., libnuma's\n            // set_numa_max_cpu()) expect a reasonably low number to be\n            // returned, even when len is unrealistically high, so let's\n            // return a lower length too.\n            ret = std::min(len, sched::max_cpus / 8);\n        }\n        return ret;\n}\n#endif\n\n#if CONF_syscall_sys_sched_setaffinity\n#define __NR_sys_sched_setaffinity __NR_sched_setaffinity\nstatic int sys_sched_setaffinity(\n        pid_t pid, unsigned len, unsigned long *mask)\n{\n    return sched_setaffinity(\n            pid, len, reinterpret_cast<cpu_set_t *>(mask));\n}\n#endif\n\n#define __NR_long_mmap __NR_mmap\n\n#define __NR_long_shmat __NR_shmat\n// Only void* return value of mmap is type casted, as syscall returns long.\nlong long_mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset) {\n    return (long) mmap(addr, length, prot, flags, fd, offset);\n}\n\nlong long_shmat(int shmid, const void *shmaddr, int shmflg) {\n    return (long) shmat(shmid, shmaddr, shmflg);\n}\n#endif\n\n#define SYSCALL0(fn) case (__NR_##fn): do { long ret = fn(); trace_syscall_##fn(ret); return ret; } while (0)\n\n#define SYSCALL1(fn, __t1)             \\\n        case (__NR_##fn): do {         \\\n        va_list args;                  \\\n        __t1 arg1;                     \\\n        va_start(args, number);        \\\n        arg1 = va_arg(args, __t1);     \\\n        va_end(args);                  \\\n        auto ret = fn(arg1);           \\\n        trace_syscall_##fn(ret, arg1); \\\n        return ret;                    \\\n        } while (0)\n\n#define SYSCALL2(fn, __t1, __t2)            \\\n        case (__NR_##fn): do {              \\\n        va_list args;                       \\\n        __t1 arg1;                          \\\n        __t2 arg2;                          \\\n        va_start(args, number);             \\\n        arg1 = va_arg(args, __t1);          \\\n        arg2 = va_arg(args, __t2);          \\\n        va_end(args);                       \\\n        auto ret = fn(arg1, arg2);          \\\n        trace_syscall_##fn(ret, arg1, arg2);\\\n        return ret;                         \\\n        } while (0)\n\n#define SYSCALL3(fn, __t1, __t2, __t3)             \\\n        case (__NR_##fn): do {                     \\\n        va_list args;                              \\\n        __t1 arg1;                                 \\\n        __t2 arg2;                                 \\\n        __t3 arg3;                                 \\\n        va_start(args, number);                    \\\n        arg1 = va_arg(args, __t1);                 \\\n        arg2 = va_arg(args, __t2);                 \\\n        arg3 = va_arg(args, __t3);                 \\\n        va_end(args);                              \\\n        auto ret = fn(arg1, arg2, arg3);           \\\n        trace_syscall_##fn(ret, arg1, arg2, arg3); \\\n        return ret;                                \\\n        } while (0)\n\n#define SYSCALL4(fn, __t1, __t2, __t3, __t4)             \\\n        case (__NR_##fn): do {                           \\\n        va_list args;                                    \\\n        __t1 arg1;                                       \\\n        __t2 arg2;                                       \\\n        __t3 arg3;                                       \\\n        __t4 arg4;                                       \\\n        va_start(args, number);                          \\\n        arg1 = va_arg(args, __t1);                       \\\n        arg2 = va_arg(args, __t2);                       \\\n        arg3 = va_arg(args, __t3);                       \\\n        arg4 = va_arg(args, __t4);                       \\\n        va_end(args);                                    \\\n        auto ret = fn(arg1, arg2, arg3, arg4);           \\\n        trace_syscall_##fn(ret, arg1, arg2, arg3, arg4); \\\n        return ret;                                      \\\n        } while (0)\n\n#define SYSCALL5(fn, __t1, __t2, __t3, __t4, __t5)             \\\n        case (__NR_##fn): do {                                 \\\n        va_list args;                                          \\\n        __t1 arg1;                                             \\\n        __t2 arg2;                                             \\\n        __t3 arg3;                                             \\\n        __t4 arg4;                                             \\\n        __t5 arg5;                                             \\\n        va_start(args, number);                                \\\n        arg1 = va_arg(args, __t1);                             \\\n        arg2 = va_arg(args, __t2);                             \\\n        arg3 = va_arg(args, __t3);                             \\\n        arg4 = va_arg(args, __t4);                             \\\n        arg5 = va_arg(args, __t5);                             \\\n        va_end(args);                                          \\\n        auto ret = fn(arg1, arg2, arg3, arg4, arg5);           \\\n        trace_syscall_##fn(ret, arg1, arg2, arg3, arg4, arg5); \\\n        return ret;                                            \\\n        } while (0)\n\n#define SYSCALL6(fn, __t1, __t2, __t3, __t4, __t5, __t6)             \\\n        case (__NR_##fn): do {                                       \\\n        va_list args;                                                \\\n        __t1 arg1;                                                   \\\n        __t2 arg2;                                                   \\\n        __t3 arg3;                                                   \\\n        __t4 arg4;                                                   \\\n        __t5 arg5;                                                   \\\n        __t6 arg6;                                                   \\\n        va_start(args, number);                                      \\\n        arg1 = va_arg(args, __t1);                                   \\\n        arg2 = va_arg(args, __t2);                                   \\\n        arg3 = va_arg(args, __t3);                                   \\\n        arg4 = va_arg(args, __t4);                                   \\\n        arg5 = va_arg(args, __t5);                                   \\\n        arg6 = va_arg(args, __t6);                                   \\\n        va_end(args);                                                \\\n        auto ret = fn(arg1, arg2, arg3, arg4, arg5, arg6);           \\\n        trace_syscall_##fn(ret, arg1, arg2, arg3, arg4, arg5, arg6); \\\n        return ret;                                                  \\\n        } while (0)\n\n#if CONF_core_syscall\nint rt_sigaction(int sig, const struct k_sigaction * act, struct k_sigaction * oact, size_t sigsetsize)\n{\n    struct sigaction libc_act, libc_oact, *libc_act_p = nullptr;\n    memset(&libc_act, 0, sizeof(libc_act));\n    memset(&libc_oact, 0, sizeof(libc_act));\n\n    if (act) {\n        libc_act.sa_handler = act->handler;\n        libc_act.sa_flags = act->flags & ~SA_RESTORER;\n        libc_act.sa_restorer = nullptr;\n        memcpy(&libc_act.sa_mask, &act->mask, sizeof(libc_act.sa_mask));\n        libc_act_p = &libc_act;\n    }\n\n    int ret = sigaction(sig, libc_act_p, &libc_oact);\n\n    if (oact) {\n        oact->handler = libc_oact.sa_handler;\n        oact->flags = libc_oact.sa_flags;\n        oact->restorer = nullptr;\n        memcpy(oact->mask, &libc_oact.sa_mask, sizeof(oact->mask));\n    }\n\n    return ret;\n}\n\nint rt_sigprocmask(int how, sigset_t * nset, sigset_t * oset, size_t sigsetsize)\n{\n    return sigprocmask(how, nset, oset);\n}\n\nint rt_sigtimedwait(const sigset_t *set, siginfo_t *info, const struct timespec *timeout, size_t sigsetsize)\n{\n    if (!timeout || (!timeout->tv_sec && !timeout->tv_nsec)) {\n        return sigwaitinfo(set, info);\n    } else {\n        errno = ENOSYS;\n        return -1;\n    }\n}\n\n#if CONF_syscall_sys_exit\n#define __NR_sys_exit __NR_exit\nstatic int sys_exit(int ret)\n{\n    sched::thread::current()->exit();\n    return 0;\n}\n#endif\n\n#if CONF_syscall_sys_exit_group\n#define __NR_sys_exit_group __NR_exit_group\nstatic int sys_exit_group(int ret)\n{\n    exit(ret);\n    return 0;\n}\n#endif\n\n#if CONF_syscall_sys_getcwd\n#define __NR_sys_getcwd __NR_getcwd\nstatic long sys_getcwd(char *buf, unsigned long size)\n{\n    if (!buf) {\n        errno = EINVAL;\n        return -1;\n    }\n    auto ret = getcwd(buf, size);\n    if (!ret) {\n        return -1;\n    }\n    return strlen(ret) + 1;\n}\n#endif\n\n#if CONF_syscall_sys_getcpu\n#define __NR_sys_getcpu __NR_getcpu\nstatic long sys_getcpu(unsigned int *cpu, unsigned int *node, void *tcache)\n{\n    if (cpu) {\n        *cpu = sched::cpu::current()->id;\n    }\n\n    if (node) {\n       *node = 0;\n    }\n\n    return 0;\n}\n#endif\n\n#if CONF_syscall_sys_set_robust_list\n#define __NR_sys_set_robust_list __NR_set_robust_list\nstatic long sys_set_robust_list(struct robust_list_head *head, size_t len)\n{\n    sched::thread::current()->set_robust_list(head);\n    return 0;\n}\n#endif\n\n#if CONF_syscall_sys_set_tid_address\n#define __NR_sys_set_tid_address __NR_set_tid_address\nstatic long sys_set_tid_address(int *tidptr)\n{\n    sched::thread::current()->set_clear_id(tidptr);\n    return sched::thread::current()->id();\n}\n#endif\n\n#define CLONE_THREAD           0x00010000\n#define CLONE_CHILD_SETTID     0x01000000\n#define CLONE_PARENT_SETTID    0x00100000\n#define CLONE_CHILD_CLEARTID   0x00200000\n\nextern sched::thread *clone_thread(unsigned long flags, void *child_stack, unsigned long newtls);\n\n#define __NR_sys_clone __NR_clone\n#ifdef __x86_64__\nint sys_clone(unsigned long flags, void *child_stack, int *ptid, int *ctid, unsigned long newtls)\n#endif\n#ifdef __aarch64__\nint sys_clone(unsigned long flags, void *child_stack, int *ptid, unsigned long newtls, int *ctid)\n#endif\n{   //\n    //We only support \"cloning\" of threads so fork() would fail but pthread_create() should\n    //succeed\n    if (!(flags & CLONE_THREAD)) {\n       errno = ENOSYS;\n       return -1;\n    }\n    //\n    //Validate we have non-empty stack\n    if (!child_stack) {\n       errno = EINVAL;\n       return -1;\n    }\n    //\n    //Validate ptid and ctid which we would be setting down if requested by these flags\n    if (((flags & CLONE_PARENT_SETTID) && !ptid) ||\n        ((flags & CLONE_CHILD_SETTID) && !ctid) ||\n        ((flags & CLONE_SETTLS) && !newtls)) {\n       errno = EFAULT;\n       return -1;\n    }\n\n    sched::thread *t = clone_thread(flags, child_stack, newtls);\n\n    //\n    //Store the child thread ID at the location pointed to by ptid\n    if ((flags & CLONE_PARENT_SETTID)) {\n       *ptid = t->id();\n    }\n    //\n    //Store the child thread ID at the location pointed to by ctid\n    if ((flags & CLONE_CHILD_SETTID)) {\n       *ctid = t->id();\n    }\n    //\n    //Clear (zero) the child thread ID at the location pointed to by child_tid\n    //in child memory when the child exits, and do a wakeup on the futex at that address\n    //See thread::complete()\n    if ((flags & CLONE_CHILD_CLEARTID)) {\n       t->set_clear_id(ctid);\n    }\n    t->start();\n\n    //\n    //The manual of sigprocmask has this to say about clone:\n    //\"Each of the threads in a process has its own signal mask.\n    // A child created via fork(2) inherits a copy of its parent's\n    // signal mask; the signal mask is preserved across execve(2).\"\n    //TODO: Does it mean new thread should inherit signal mask of the parent?\n    return t->id();\n}\n\nstruct clone_args {\n     u64 flags;\n     u64 pidfd;\n     u64 child_tid;\n     u64 parent_tid;\n     u64 exit_signal;\n     u64 stack;\n     u64 stack_size;\n     u64 tls;\n};\n\n\n#if CONF_syscall_sys_clone3\n#define __NR_sys_clone3 435\nstatic int sys_clone3(struct clone_args *args, size_t size)\n{\n    return sys_clone(\n       args->flags,\n       reinterpret_cast<void*>(args->stack) + args->stack_size,\n       reinterpret_cast<int*>(args->parent_tid),\n#ifdef __x86_64__\n       reinterpret_cast<int*>(args->child_tid),\n       args->tls);\n#endif\n#ifdef __aarch64__\n       args->tls,\n       reinterpret_cast<int*>(args->child_tid));\n#endif\n}\n#endif\n\n#define __NR_sys_ioctl __NR_ioctl\n//\n// We need to define explicit sys_ioctl that takes these 3 parameters to conform\n// to Linux signature of this system call. The underlying ioctl function which we delegate to\n// is variadic and takes slightly different paremeters and therefore cannot be used directly\n// as other system call implementations can.\n#define KERNEL_NCCS 19\n\n// This structure is exactly what glibc expects to receive when calling ioctl()\n// with TCGET and is defined in sysdeps/unix/sysv/linux/kernel_termios.h.\nstruct __kernel_termios {\n    tcflag_t c_iflag;\n    tcflag_t c_oflag;\n    tcflag_t c_cflag;\n    tcflag_t c_lflag;\n    cc_t c_line;\n    cc_t c_cc[KERNEL_NCCS];\n};\n\n#if CONF_syscall_sys_ioctl\nstatic int sys_ioctl(unsigned int fd, unsigned int command, unsigned long arg)\n{\n    if (command == TCGETS) {\n       //The termios structure is slightly different from the version of it used\n       //by the syscall so let us translate it manually\n       termios _termios;\n       auto ret = ioctl(fd, command, &_termios);\n       if (!ret) {\n           __kernel_termios *ktermios = reinterpret_cast<__kernel_termios*>(arg);\n           ktermios->c_iflag = _termios.c_iflag;\n           ktermios->c_oflag = _termios.c_oflag;\n           ktermios->c_cflag = _termios.c_cflag;\n           ktermios->c_lflag = _termios.c_lflag;\n           ktermios->c_line = _termios.c_line;\n           memcpy(&ktermios->c_cc[0], &_termios.c_cc[0], KERNEL_NCCS * sizeof (cc_t));\n       }\n       return ret;\n    } else {\n       return ioctl(fd, command, arg);\n    }\n}\n#endif\n\nstruct sys_sigset {\n    const sigset_t *ss;     /* Pointer to signal set */\n    size_t          ss_len; /* Size (in bytes) of object pointed to by 'ss' */\n};\n\n#if CONF_syscall_pselect6\nstatic int pselect6(int nfds, fd_set *readfds, fd_set *writefds,\n                   fd_set *exceptfds, struct timespec *timeout_ts,\n                   sys_sigset* sigmask)\n{\n    // As explained in the pselect(2) manual page, the system call pselect accepts\n    // pointer to a structure holding pointer to sigset_t and its size which is different\n    // from the glibc version of pselect().\n    // On top of this, the Linux pselect6() system call modifies its timeout argument\n    // unlike the glibc pselect() function. Our implementation below is to great extent\n    // similar to that of pselect() in core/select.cc\n    sigset_t origmask;\n    struct timeval timeout;\n\n    if (timeout_ts) {\n        timeout.tv_sec = timeout_ts->tv_sec;\n        timeout.tv_usec = timeout_ts->tv_nsec / 1000;\n    }\n\n    if (sigmask) {\n        sigprocmask(SIG_SETMASK, sigmask->ss, &origmask);\n    }\n\n    auto ret = select(nfds, readfds, writefds, exceptfds,\n                                        timeout_ts == NULL? NULL : &timeout);\n    if (sigmask) {\n        sigprocmask(SIG_SETMASK, &origmask, NULL);\n    }\n\n    if (timeout_ts) {\n        timeout_ts->tv_sec = timeout.tv_sec;\n        timeout_ts->tv_nsec = timeout.tv_usec * 1000;\n    }\n    return ret;\n}\n#endif\n\n#if CONF_syscall_tgkill\nstatic int tgkill(int tgid, int tid, int sig)\n{\n    //\n    // Given OSv supports sigle process only, we only support this syscall\n    // when thread group id is self (getpid()) or -1 (see https://linux.die.net/man/2/tgkill)\n    // AND tid points to the current thread (caller)\n    // Ideally we would want to delegate to pthread_kill() but there is no\n    // easy way to map tgid to pthread_t so we directly delegate to kill().\n    if ((tgid == -1 || tgid == getpid()) && (tid == gettid())) {\n        return kill(tgid, sig);\n    }\n\n    errno = ENOSYS;\n    return -1;\n}\n#endif\n\n#define __NR_sys_getdents64 __NR_getdents64\nextern \"C\" ssize_t sys_getdents64(int fd, void *dirp, size_t count);\n\nextern long arch_prctl(int code, unsigned long addr);\n\n#if CONF_syscall_sys_brk\n#define __NR_sys_brk __NR_brk\nvoid *get_program_break();\nstatic long sys_brk(void *addr)\n{\n    // The brk syscall is almost the same as the brk() function\n    // except it needs to return new program break on success\n    // and old one on failure\n    void *old_break = get_program_break();\n    if (!brk(addr)) {\n        return reinterpret_cast<long>(get_program_break());\n    } else {\n        return reinterpret_cast<long>(old_break);\n    }\n}\n#endif\n\n#define __NR_utimensat4 __NR_utimensat\nextern int utimensat4(int dirfd, const char *pathname, const struct timespec times[2], int flags);\n#endif\nTRACEPOINT(trace_syscall_futex, \"%d <= %p %d %d %p %p %d\", int, int *, int, int, const struct timespec *, int *, uint32_t);\n#if CONF_core_syscall\n#include <osv/syscall_tracepoints.cc>\n#endif\n\nOSV_LIBC_API long syscall(long number, ...)\n{\n    // Save FPU state and restore it at the end of this function\n    sched::fpu_lock fpu;\n    SCOPE_LOCK(fpu);\n\n    switch (number) {\n    SYSCALL6(futex, int *, int, int, const struct timespec *, int *, uint32_t);\n#if CONF_core_syscall\n#include <osv/syscalls.cc>\n#endif\n    }\n\n    debug_always(\"syscall(): unimplemented system call %d\\n\", number);\n    errno = ENOSYS;\n    return -1;\n}\nlong __syscall(long number, ...)  __attribute__((alias(\"syscall\")));\n\n#ifdef __x86_64__\n// In x86-64, a SYSCALL instruction has exactly 6 parameters, because this is the number of registers\n// alloted for passing them (additional parameters *cannot* be passed on the stack). So we can get\n// 7 arguments to this function (syscall number plus its 6 parameters). Because in the x86-64 ABI the\n// seventh argument is on the stack, we must pass the arguments explicitly to the syscall() function\n// and can't just call it without any arguments and hope everything will be passed on\nextern \"C\" long syscall_wrapper(long number, long p1, long p2, long p3, long p4, long p5, long p6)\n#endif\n#ifdef __aarch64__\n// In aarch64, the first 8 parameters to a procedure call are passed in the x0-x7 registers and\n// the parameters of syscall call (SVC intruction) in are passed in x0-x5 registers and syscall number\n// in x8 register before. To avoid shuffling the arguments around we make syscall_wrapper()\n// accept the syscall parameters as is but accept the syscall number as the last 7th argument which\n// the code in entry.S arranges.\nextern \"C\" long syscall_wrapper(long p1, long p2, long p3, long p4, long p5, long p6, long number)\n#endif\n{\n#ifdef __x86_64__\n    // Switch TLS register if necessary\n    arch::tls_switch tls_switch;\n#endif\n\n    int errno_backup = errno;\n    // syscall and function return value are in rax\n    auto ret = syscall(number, p1, p2, p3, p4, p5, p6);\n    int result = -errno;\n    errno = errno_backup;\n    if (ret < 0 && ret >= -4096) {\n        return result;\n    }\n    return ret;\n}\n\nextern \"C\" int is_selinux_enabled()\n{\n    return 0;\n}\n"
        },
        {
          "name": "loader.cc",
          "type": "blob",
          "size": 26.734375,
          "content": "/*\n * Copyright (C) 2013 Cloudius Systems, Ltd.\n *\n * This work is open source software, licensed under the terms of the\n * BSD license as described in the LICENSE file in the top-level directory.\n */\n\n#include <osv/drivers_config.h>\n#include <osv/kernel_config.h>\n#include \"fs/fs.hh\"\n#include <bsd/init.hh>\n#include <bsd/net.hh>\n#include <cctype>\n#include <osv/elf.hh>\n#include \"arch-tls.hh\"\n#include <osv/debug.hh>\n#include <osv/clock.hh>\n#include <osv/version.hh>\n\n#include \"smp.hh\"\n\n#ifdef __x86_64__\n#if CONF_drivers_acpi\n#include \"drivers/acpi.hh\"\n#endif\n#endif /* __x86_64__ */\n\n#include <osv/sched.hh>\n#include <osv/barrier.hh>\n#include \"arch.hh\"\n#include \"arch-setup.hh\"\n#include \"osv/trace.hh\"\n#include <osv/strace.hh>\n#include <osv/power.hh>\n#include <osv/rcu.hh>\n#include <osv/mempool.hh>\n#include <bsd/porting/networking.hh>\n#include <bsd/porting/shrinker.h>\n#include <bsd/porting/route.h>\n#include <osv/dhcp.hh>\n#include <osv/version.h>\n#include <osv/run.hh>\n#include <osv/shutdown.hh>\n#include <osv/commands.hh>\n#include <osv/boot.hh>\n#include <osv/sampler.hh>\n#include <osv/app.hh>\n#include <osv/firmware.hh>\n#if CONF_drivers_xen\n#include <osv/xen.hh>\n#endif\n#include <osv/options.hh>\n#include <dirent.h>\n#include <mntent.h>\n\n#include \"drivers/zfs.hh\"\n#include \"drivers/random.hh\"\n#include \"drivers/console.hh\"\n#include \"drivers/null.hh\"\n\n#include \"libc/network/__dns.hh\"\n#include <processor.hh>\n#include <dlfcn.h>\n#include <osv/string_utils.hh>\n\nusing namespace osv;\nusing namespace osv::clock::literals;\n\nasm(\".pushsection \\\".debug_gdb_scripts\\\", \\\"MS\\\",@progbits,1 \\n\"\n    \".byte 1 \\n\"\n    \".asciz \\\"scripts/loader.py\\\" \\n\"\n    \".popsection \\n\");\n\nelf::Elf64_Ehdr* elf_header __attribute__ ((aligned(8)));\n\nsize_t elf_size;\nvoid* elf_start;\nelf::tls_data tls_data;\n\nboot_time_chart boot_time;\n\nvoid setup_tls(elf::init_table inittab)\n{\n    tls_data = inittab.tls;\n    sched::init_tls(tls_data);\n\n    extern char tcb0[]; // defined by linker script\n    arch_setup_tls(tcb0, tls_data);\n}\n\nextern \"C\" {\n    void premain();\n    void vfs_init(void);\n    void pivot_rootfs(const char*);\n    void unmount_devfs();\n    int mount_zfs_rootfs(bool, bool);\n    int mount_rofs_rootfs(bool);\n    void rofs_disable_cache();\n    int mount_virtiofs_rootfs(bool);\n}\n\nvoid premain()\n{\n    arch_init_early_console();\n\n    /* besides reporting the OSV version, this string has the function\n       to check if the early console really works early enough,\n       without depending on prior initialization. */\n    debug_early(\"OSv \" OSV_VERSION \"\\n\");\n\n    arch_init_premain();\n\n#ifdef __x86_64__\n    auto elf_header_virt_address = (void*)elf_header + OSV_KERNEL_VM_SHIFT;\n#endif\n\n#ifdef __aarch64__\n    extern u64 kernel_vm_shift;\n    auto elf_header_virt_address = (void*)elf_header + kernel_vm_shift;\n#endif\n\n    auto inittab = elf::get_init(reinterpret_cast<elf::Elf64_Ehdr*>(\n        elf_header_virt_address));\n\n    if (inittab.tls.start == nullptr) {\n        debug_early(\"premain: failed to get TLS data from ELF\\n\");\n        arch::halt_no_interrupts();\n    }\n\n    setup_tls(inittab);\n    boot_time.event(3,\"TLS initialization\");\n    for (auto init = inittab.start; init < inittab.start + inittab.count; ++init) {\n        (*init)();\n    }\n    boot_time.event(\".init functions\");\n}\n\nint main(int loader_argc, char **loader_argv)\n{\n    smp_initial_find_current_cpu()->init_on_cpu();\n    void main_cont(int loader_argc, char** loader_argv);\n    sched::init([=] { main_cont(loader_argc, loader_argv); });\n}\n\nstatic bool opt_preload_zfs_library = false;\nstatic bool opt_extra_zfs_pools = false;\nstatic bool opt_disable_rofs_cache = false;\n#if CONF_memory_tracker\nstatic bool opt_leak = false;\n#endif\nstatic bool opt_noshutdown = false;\nbool opt_power_off_on_abort = false;\n#if CONF_tracepoints\nstatic bool opt_log_backtrace = false;\nstatic bool opt_list_tracepoints = false;\n#if CONF_tracepoints_strace\nstatic bool opt_strace = false;\n#endif\n#endif\nstatic bool opt_mount = true;\nstatic bool opt_pivot = true;\nstatic std::string opt_rootfs;\nstatic bool opt_random = true;\nstatic bool opt_init = true;\nstatic std::string opt_console = \"all\";\nstatic bool opt_verbose = false;\nstatic std::string opt_chdir;\nstatic bool opt_bootchart = false;\nstatic std::vector<std::string> opt_ip;\nstatic std::string opt_defaultgw;\nstatic std::string opt_nameserver;\nstatic std::string opt_redirect;\nstatic std::chrono::nanoseconds boot_delay;\nstd::vector<mntent> opt_mount_fs;\nbool opt_maxnic = false;\nint maxnic;\nbool opt_pci_disabled = false;\n\n#if CONF_tracepoints_sampler\nstatic int sampler_frequency;\nstatic bool opt_enable_sampler = false;\n#endif\n\nstatic void usage()\n{\n    printf(\n        \"OSv options:\\n\"\n        \"  --help                show help text\\n\"\n#if CONF_tracepoints\n#if CONF_tracepoints_sampler\n        \"  --sampler=arg         start stack sampling profiler\\n\"\n#endif\n        \"  --trace=arg           tracepoints to enable\\n\"\n        \"  --trace-backtrace     log backtraces in the tracepoint log\\n\"\n        \"  --trace-list          list available tracepoints\\n\"\n#if CONF_tracepoints_strace\n        \"  --strace              start a thread to print tracepoints to the console on the fly\\n\"\n#endif\n#endif\n#if CONF_memory_tracker\n        \"  --leak                start leak detector after boot\\n\"\n#endif\n        \"  --nomount             don't mount the root file system\\n\"\n        \"  --nopivot             do not pivot the root from bootfs to the root fs\\n\"\n        \"  --rootfs=arg          root filesystem to use (zfs, rofs, ramfs or virtiofs)\\n\"\n        \"  --assign-net          assign virtio network to the application\\n\"\n        \"  --maxnic=arg          maximum NIC number\\n\"\n        \"  --norandom            don't initialize any random device\\n\"\n        \"  --noshutdown          continue running after main() returns\\n\"\n        \"  --power-off-on-abort  use poweroff instead of halt if it's aborted\\n\"\n        \"  --noinit              don't run commands from /init\\n\"\n        \"  --verbose             be verbose, print debug messages\\n\"\n        \"  --console=arg         select console driver\\n\"\n        \"  --env=arg             set Unix-like environment variable (putenv())\\n\"\n        \"  --cwd=arg             set current working directory\\n\"\n        \"  --bootchart           perform a test boot measuring a time distribution of\\n\"\n        \"                        the various operations\\n\\n\"\n#if CONF_networking_stack\n        \"  --ip=arg              set static IP on NIC\\n\"\n        \"  --defaultgw=arg       set default gateway address\\n\"\n        \"  --nameserver=arg      set nameserver address\\n\"\n#endif\n        \"  --delay=arg (=0)      delay in seconds before boot\\n\"\n        \"  --redirect=arg        redirect stdout and stderr to file\\n\"\n        \"  --disable_rofs_cache  disable ROFS memory cache\\n\"\n        \"  --nopci               disable PCI enumeration\\n\"\n        \"  --extra-zfs-pools     import extra ZFS pools\\n\"\n        \"  --mount-fs=arg        mount extra filesystem, format:<fs_type,url,path>\\n\"\n        \"  --preload-zfs-library preload ZFS library from /usr/lib/fs\\n\\n\");\n}\n\nstatic void handle_parse_error(const std::string &message)\n{\n    printf(\"%s\\n\", message.c_str());\n    usage();\n    osv::poweroff();\n}\n\nstatic bool extract_option_flag(std::map<std::string,std::vector<std::string>> &options_values, const std::string &name)\n{\n    return options::extract_option_flag(options_values, name, handle_parse_error);\n}\n\nstatic void parse_options(int loader_argc, char** loader_argv)\n{\n    auto options_values = options::parse_options_values(loader_argc, loader_argv, handle_parse_error, false);\n\n    if (extract_option_flag(options_values, \"help\")) {\n        usage();\n    }\n\n#if CONF_memory_tracker\n    if (extract_option_flag(options_values, \"leak\")) {\n        opt_leak = true;\n    }\n#endif\n\n    if (extract_option_flag(options_values, \"disable_rofs_cache\")) {\n        opt_disable_rofs_cache = true;\n    }\n\n    if (extract_option_flag(options_values, \"preload-zfs-library\")) {\n        opt_preload_zfs_library = true;\n    }\n\n    if (extract_option_flag(options_values, \"extra-zfs-pools\")) {\n        opt_extra_zfs_pools = true;\n    }\n\n    if (extract_option_flag(options_values, \"noshutdown\")) {\n        opt_noshutdown = true;\n    }\n\n    if (extract_option_flag(options_values, \"power-off-on-abort\")) {\n        opt_power_off_on_abort = true;\n    }\n\n    if (options::option_value_exists(options_values, \"maxnic\")) {\n        opt_maxnic = true;\n        maxnic = options::extract_option_int_value(options_values, \"maxnic\", handle_parse_error);\n    }\n\n#if CONF_tracepoints\n    if (extract_option_flag(options_values, \"trace-backtrace\")) {\n        opt_log_backtrace = true;\n    }\n\n    if (extract_option_flag(options_values, \"trace-list\")) {\n        opt_list_tracepoints = true;\n    }\n#endif\n\n    if (extract_option_flag(options_values, \"verbose\")) {\n        opt_verbose = true;\n        enable_verbose();\n    }\n\n#if CONF_tracepoints_sampler\n    if (options::option_value_exists(options_values, \"sampler\")) {\n        sampler_frequency = options::extract_option_int_value(options_values, \"sampler\", handle_parse_error);\n        opt_enable_sampler = true;\n    }\n#endif\n\n    if (extract_option_flag(options_values, \"bootchart\")) {\n        opt_bootchart = true;\n    }\n\n#if CONF_tracepoints\n    if (options::option_value_exists(options_values, \"trace\")) {\n        auto tv = options::extract_option_values(options_values, \"trace\");\n        for (auto t : tv) {\n            std::vector<std::string> tmp;\n            osv::split(tmp, t, \" ,\", true);\n            for (auto t : tmp) {\n                enable_tracepoint(t);\n            }\n        }\n#if CONF_tracepoints_strace\n        if (extract_option_flag(options_values, \"strace\")) {\n            opt_strace = true;\n        }\n#endif\n    }\n#endif\n\n    opt_mount = !extract_option_flag(options_values, \"nomount\");\n    opt_pivot = !extract_option_flag(options_values, \"nopivot\");\n    opt_random = !extract_option_flag(options_values, \"norandom\");\n    opt_init = !extract_option_flag(options_values, \"noinit\");\n\n    if (options::option_value_exists(options_values, \"console\")) {\n        auto v = options::extract_option_values(options_values, \"console\");\n        if (v.size() > 1) {\n            printf(\"Ignoring '--console' options after the first.\");\n        }\n        opt_console = v.front();\n        debugf(\"console=%s\\n\", opt_console.c_str());\n    }\n\n    if (options::option_value_exists(options_values, \"rootfs\")) {\n        auto v = options::extract_option_values(options_values, \"rootfs\");\n        if (v.size() > 1) {\n            printf(\"Ignoring '--rootfs' options after the first.\");\n        }\n        opt_rootfs = v.front();\n    }\n\n    if (options::option_value_exists(options_values, \"mount-fs\")) {\n        auto mounts = options::extract_option_values(options_values, \"mount-fs\");\n        for (auto m : mounts) {\n            std::vector<std::string> tmp;\n            osv::split(tmp, m, \",\", true);\n            if (tmp.size() != 3 || tmp[0].empty() || tmp[1].empty() || tmp[2].empty()) {\n                printf(\"Ignoring value: '%s' for option mount-fs, expected in format: <fs_type,url,path>\\n\", m.c_str());\n                continue;\n            }\n            mntent mount = {\n                .mnt_fsname = strdup(tmp[1].c_str()),\n                .mnt_dir = strdup(tmp[2].c_str()),\n                .mnt_type = strdup(tmp[0].c_str()),\n                .mnt_opts = nullptr\n            };\n            opt_mount_fs.push_back(mount);\n        }\n    }\n\n    if (options::option_value_exists(options_values, \"env\")) {\n        for (auto t : options::extract_option_values(options_values, \"env\")) {\n            debugf(\"Setting in environment: %s\\n\", t.c_str());\n            putenv(strdup(t.c_str()));\n        }\n    }\n\n    if (options::option_value_exists(options_values, \"cwd\")) {\n        auto v = options::extract_option_values(options_values, \"cwd\");\n        if (v.size() > 1) {\n            printf(\"Ignoring '--cwd' options after the first.\");\n        }\n        opt_chdir = v.front();\n    }\n\n    if (options::option_value_exists(options_values, \"ip\")) {\n        opt_ip = options::extract_option_values(options_values, \"ip\");\n    }\n\n    if (options::option_value_exists(options_values, \"defaultgw\")) {\n        opt_defaultgw = options::extract_option_value(options_values, \"defaultgw\");\n    }\n\n    if (options::option_value_exists(options_values, \"nameserver\")) {\n        opt_nameserver = options::extract_option_value(options_values, \"nameserver\");\n    }\n\n    if (options::option_value_exists(options_values, \"redirect\")) {\n        opt_redirect = options::extract_option_value(options_values, \"redirect\");\n    }\n\n    if (options::option_value_exists(options_values, \"delay\")) {\n        boot_delay = std::chrono::duration_cast<std::chrono::nanoseconds>(1_s * options::extract_option_float_value(options_values, \"delay\", handle_parse_error));\n    } else {\n        boot_delay = std::chrono::duration_cast<std::chrono::nanoseconds>(1_s * 0.0f);\n    }\n\n    if (extract_option_flag(options_values, \"nopci\")) {\n        opt_pci_disabled = true;\n    }\n\n    if (!options_values.empty()) {\n        for (auto other_option : options_values) {\n            printf(\"unrecognized option: %s\\n\", other_option.first.c_str());\n        }\n\n        usage();\n        osv::poweroff();\n    }\n}\n\n// return the std::string and the commands_args poiting to them as a move\n#if HIDE_SYMBOLS < 1\n#include <iostream>\n#endif\nstd::vector<std::vector<std::string> > prepare_commands(char* app_cmdline)\n{\n    std::vector<std::vector<std::string> > commands;\n    bool ok;\n\n//When the kernel is linked in with full standard C++ library\n//and all symbols exposed, the std::cout needs to be initialized\n//early before any C++ application is executed. This is not necessary\n//when the kernel is built with all symbols but glibc and standard C++\n//library hidden.\n//For details please read comments of this commit a5e83688f1aa30498c5e270a6cdc04222ede8cb6\n#if HIDE_SYMBOLS < 1\n    std::cout << \"Cmdline: \" << app_cmdline << \"\\n\";\n#else\n    printf(\"Cmdline: %s\\n\", app_cmdline);\n#endif\n    commands = osv::parse_command_line(app_cmdline, ok);\n\n    if (!ok) {\n        puts(\"Failed to parse command line.\");\n        osv::poweroff();\n    }\n    if (commands.size() == 0) {\n        puts(\"This image has an empty command line. Nothing to run.\");\n        osv::poweroff();\n    }\n\n    return commands;\n}\n\nstatic std::string read_file(std::string fn)\n{\n    FILE *fp = fopen(fn.c_str(), \"r\");\n    if (!fp) {\n        return \"\";\n    }\n\n    size_t line_length = 0;\n    char *line_buffer = nullptr;\n    ssize_t read;\n    std::string content;\n    while ((read = getline(&line_buffer, &line_length, fp)) != -1) {\n        content += line_buffer;\n    }\n    free(line_buffer);\n    fclose(fp);\n\n    return content;\n}\n\nstatic void stop_all_remaining_app_threads()\n{\n    while(!application::unsafe_stop_and_abandon_other_threads()) {\n        usleep(100000);\n    }\n}\n\nstatic void load_zfs_library(std::function<void()> on_load_fun = nullptr)\n{\n    // Load and initialize ZFS filesystem driver implemented in libsolaris.so\n    const auto libsolaris_path = \"/usr/lib/fs/libsolaris.so\";\n    if (dlopen(libsolaris_path, RTLD_LAZY)) {\n        if (on_load_fun) {\n           on_load_fun();\n        }\n    } else {\n        debugf(\"Could not load and/or initialize %s.\\n\", libsolaris_path);\n    }\n}\n\nstatic void load_zfs_library_and_mount_zfs_root(const char* mount_error_msg, bool pivot_when_error = false)\n{\n    load_zfs_library([mount_error_msg, pivot_when_error]() {\n        zfsdev::zfsdev_init();\n        auto error = mount_zfs_rootfs(opt_pivot, opt_extra_zfs_pools);\n        if (error) {\n            debug(mount_error_msg);\n            if (pivot_when_error) {\n                // Continue with ramfs (already mounted)\n                // TODO: Avoid the hack of using pivot_rootfs() just for\n                // mounting the fstab entries.\n                pivot_rootfs(\"/\");\n            }\n        } else {\n            bsd_shrinker_init();\n            boot_time.event(\"ZFS mounted\");\n        }\n    });\n}\n\nvoid* do_main_thread(void *_main_args)\n{\n    auto app_cmdline = static_cast<char*>(_main_args);\n\n    if (!arch_setup_console(opt_console)) {\n        abort(\"Unknown console:%s\\n\", opt_console.c_str());\n    }\n    arch_init_drivers();\n    console::console_init();\n    nulldev::nulldev_init();\n    if (opt_random) {\n        randomdev::randomdev_init();\n    }\n    boot_time.event(\"drivers loaded\");\n\n    if (opt_mount) {\n        unmount_devfs();\n\n        if (opt_rootfs.compare(\"rofs\") == 0) {\n            auto error = mount_rofs_rootfs(opt_pivot);\n            if (error) {\n                debug(\"Could not mount rofs root filesystem.\\n\");\n            }\n\n            if (opt_disable_rofs_cache) {\n                debug(\"Disabling ROFS memory cache.\\n\");\n                rofs_disable_cache();\n            }\n            boot_time.event(\"ROFS mounted\");\n        } else if (opt_rootfs.compare(\"zfs\") == 0) {\n            load_zfs_library_and_mount_zfs_root(\"Could not mount zfs root filesystem.\\n\");\n        } else if (opt_rootfs.compare(\"ramfs\") == 0) {\n            // NOTE: The ramfs is already mounted, we just need to mount fstab\n            // entries. That's the only difference between this and --nomount.\n\n            // TODO: Avoid the hack of using pivot_rootfs() just for mounting\n            // the fstab entries.\n            pivot_rootfs(\"/\");\n        } else if (opt_rootfs.compare(\"virtiofs\") == 0) {\n            auto error = mount_virtiofs_rootfs(opt_pivot);\n            if (error) {\n                debug(\"Could not mount virtiofs root filesystem.\\n\");\n            }\n\n            boot_time.event(\"Virtio-fs mounted\");\n        } else {\n            // Auto-discovery: try rofs -> virtio-fs -> ZFS\n            if (mount_rofs_rootfs(opt_pivot) == 0) {\n                if (opt_disable_rofs_cache) {\n                    debug(\"Disabling ROFS memory cache.\\n\");\n                    rofs_disable_cache();\n                }\n                boot_time.event(\"ROFS mounted\");\n            } else if (mount_virtiofs_rootfs(opt_pivot) == 0) {\n                boot_time.event(\"Virtio-fs mounted\");\n            } else {\n                load_zfs_library_and_mount_zfs_root(\"Could not mount zfs root filesystem (while auto-discovering).\\n\", true);\n            }\n        }\n    }\n\n    if (opt_preload_zfs_library) {\n        load_zfs_library();\n    }\n\n#if CONF_networking_stack\n    bool has_if = false;\n    osv::for_each_if([&has_if] (std::string if_name) {\n        if (if_name == \"lo0\")\n            return;\n\n        has_if = true;\n        // Start DHCP by default and wait for an IP\n        if (osv::start_if(if_name, \"0.0.0.0\", \"255.255.255.0\") != 0 ||\n            osv::ifup(if_name) != 0)\n            debug(\"Could not initialize network interface.\\n\");\n    });\n    if (has_if) {\n#if CONF_networking_dhcp\n        if (opt_ip.size() == 0) {\n            dhcp_start(true);\n        } else {\n#endif\n            for (auto t : opt_ip) {\n                std::vector<std::string> tmp;\n                osv::split(tmp, t, \" ,\", true);\n                if (tmp.size() != 3)\n                    abort(\"incorrect parameter on --ip\");\n\n                printf(\"%s: %s\\n\",tmp[0].c_str(),tmp[1].c_str());\n\n                if (osv::start_if(tmp[0], tmp[1], tmp[2]) != 0)\n                    debug(\"Could not initialize network interface.\\n\");\n            }\n            if (opt_defaultgw.size() != 0) {\n                osv_route_add_network(\"0.0.0.0\",\n                                      \"0.0.0.0\",\n                                      opt_defaultgw.c_str());\n            }\n            if (opt_nameserver.size() != 0) {\n                auto addr = boost::asio::ip::address_v4::from_string(opt_nameserver);\n                osv::set_dns_config({addr}, std::vector<std::string>());\n            }\n#if CONF_networking_dhcp\n        }\n#endif\n    }\n\n    std::string if_ip;\n    auto nr_ips = 0;\n\n    osv::for_each_if([&](std::string if_name) {\n        if (if_name == \"lo0\")\n            return;\n        if_ip = osv::if_ip(if_name);\n        nr_ips++;\n    });\n    if (nr_ips == 1) {\n       setenv(\"OSV_IP\", if_ip.c_str(), 1);\n    }\n#endif\n\n    if (!opt_chdir.empty()) {\n        debugf(\"Chdir to: '%s'\\n\", opt_chdir.c_str());\n\n        if (chdir(opt_chdir.c_str()) != 0) {\n            perror(\"chdir\");\n        }\n        debug(\"chdir done\\n\");\n    }\n\n#if CONF_memory_tracker\n    if (opt_leak) {\n        debug(\"Enabling leak detector.\\n\");\n        memory::tracker_enabled = true;\n    }\n#endif\n\n    boot_time.event(\"Total time\");\n#ifdef __x86_64__\n    // Some hypervisors like firecracker when booting OSv\n    // look for this write to this port as a signal of end of\n    // boot time.\n    processor::outb(123, 0x3f0);\n#endif /* __x86_64__ */\n\n    if (opt_bootchart) {\n        boot_time.print_chart();\n    } else {\n        boot_time.print_total_time();\n    }\n\n    if (!opt_redirect.empty()) {\n        // redirect stdout and stdin to the given file, instead of the console\n        // use \">>filename\" to append, instead of replace, to a file.\n        bool append = (opt_redirect.substr(0, 2) == \">>\");\n        auto fn = opt_redirect.substr(append ? 2 : 0);\n        int fd = open(fn.c_str(),\n                O_WRONLY | O_CREAT | (append ? O_APPEND: O_TRUNC), 777);\n        if (fd < 0) {\n            perror(\"output redirection failed\");\n        } else {\n            printf(\"%s stdout and stderr to %s\\n\", (append ? \"Appending\" : \"Writing\"), fn.c_str());\n            close(1);\n            close(2);\n            dup(fd);\n            dup(fd);\n        }\n    }\n\n    auto commands = prepare_commands(app_cmdline);\n\n    // Run command lines in /init/* before the manual command line\n    if (opt_init) {\n        std::vector<std::vector<std::string>> init_commands;\n        struct dirent **namelist = nullptr;\n        int count = scandir(\"/init\", &namelist, NULL, alphasort);\n        for (int i = 0; i < count; i++) {\n            if (!strcmp(\".\", namelist[i]->d_name) ||\n                    !strcmp(\"..\", namelist[i]->d_name)) {\n                free(namelist[i]);\n                continue;\n            }\n            std::string fn(\"/init/\");\n            fn += namelist[i]->d_name;\n            auto cmdline = read_file(fn);\n            debugf(\"Running from %s: %s\\n\", fn.c_str(), cmdline.c_str());\n            bool ok;\n            auto new_commands = osv::parse_command_line(cmdline, ok);\n            free(namelist[i]);\n            if (ok) {\n                init_commands.insert(init_commands.end(),\n                        new_commands.begin(), new_commands.end());\n            }\n        }\n        free(namelist);\n        commands.insert(commands.begin(),\n                 init_commands.begin(), init_commands.end());\n    }\n\n    // run each payload in order\n    // Our parse_command_line() leaves at the end of each command a delimiter,\n    // can be '&' if we need to run this command in a new thread, or ';' or\n    // empty otherwise, to run in this thread. '&!' is the same as '&', but\n    // doesn't wait for the thread to finish before exiting OSv.\n    std::vector<shared_app_t> detached;\n    std::vector<shared_app_t> bg;\n    for (auto &it : commands) {\n        std::vector<std::string> newvec(it.begin(), std::prev(it.end()));\n        auto suffix = it.back();\n        try {\n            bool background = (suffix == \"&\") || (suffix == \"&!\");\n\n            shared_app_t app;\n            if (suffix == \"!\") {\n                app = application::run(newvec[0], newvec, false, nullptr, \"main\", stop_all_remaining_app_threads);\n            } else {\n                app = application::run(newvec);\n            }\n\n            if (suffix == \"&!\") {\n                detached.push_back(app);\n            } else if (!background) {\n                app->join();\n            } else {\n                bg.push_back(app);\n            }\n        } catch (const launch_error& e) {\n            fprintf(stderr, \"%s. Powering off.\\n\", e.what());\n            osv::poweroff();\n        }\n    }\n\n    for (auto app : bg) {\n        app->join();\n    }\n\n    for (auto app : detached) {\n        app->request_termination();\n        debugf(\"Requested termination of %s, waiting...\\n\", app->get_command().c_str());\n    }\n\n    application::join_all();\n    return nullptr;\n}\n\nvoid main_cont(int loader_argc, char** loader_argv)\n{\n    osv::firmware_probe();\n\n    debugf(\"Firmware vendor: %s\\n\", osv::firmware_vendor().c_str());\n\n    elf::create_main_program();\n\n    std::vector<std::vector<std::string> > cmds;\n\n    parse_options(loader_argc, loader_argv);\n\n    setenv(\"OSV_VERSION\", osv::version().c_str(), 1);\n\n#if CONF_drivers_xen\n    xen::irq_init();\n#endif\n    smp_launch();\n    setenv(\"OSV_CPUS\", std::to_string(sched::cpus.size()).c_str(), 1);\n    boot_time.event(\"SMP launched\");\n\n    auto end = osv::clock::uptime::now() + boot_delay;\n    while (end > osv::clock::uptime::now()) {\n        // spin\n    }\n\n    memory::enable_debug_allocator();\n\n#ifdef __x86_64__\n#if CONF_drivers_acpi\n    acpi::init();\n#endif\n#endif /* __x86_64__ */\n\n    if (sched::cpus.size() > sched::max_cpus) {\n        printf(\"Too many cpus, can't boot with greater than %u cpus.\\n\", sched::max_cpus);\n        poweroff();\n    }\n\n#if CONF_tracepoints\n    if (opt_list_tracepoints) {\n        list_all_tracepoints();\n    }\n\n    enable_trace();\n    if (opt_log_backtrace) {\n        // can only do this after smp_launch, otherwise the IDT is not initialized,\n        // and backtrace_safe() fails as soon as we get an exception\n        enable_backtraces();\n    }\n#if CONF_tracepoints_strace\n    if (opt_strace) {\n        start_strace();\n    }\n#endif\n#endif\n    sched::init_detached_threads_reaper();\n    elf::setup_missing_symbols_detector();\n\n    bsd_init();\n\n    vfs_init();\n    boot_time.event(\"VFS initialized\");\n    //ramdisk_init();\n\n#if CONF_networking_stack\n    net_init();\n    boot_time.event(\"Network initialized\");\n#endif\n\n    arch::irq_enable();\n\n#ifndef AARCH64_PORT_STUB\n#if CONF_tracepoints_sampler\n    if (opt_enable_sampler) {\n        prof::config config{std::chrono::nanoseconds(1000000000 / sampler_frequency)};\n        prof::start_sampler(config);\n    }\n#endif\n#endif /* !AARCH64_PORT_STUB */\n\n    // multiple programs can be run -> separate their arguments\n\n    pthread_t pthread;\n    // run the payload in a pthread, so pthread_self() etc. work\n    // start do_main_thread unpinned (== pinned to all cpus)\n    cpu_set_t cpuset;\n    CPU_ZERO(&cpuset);\n    for (size_t ii=0; ii<sched::cpus.size(); ii++) {\n        CPU_SET(ii, &cpuset);\n    }\n    pthread_attr_t attr;\n    pthread_attr_init(&attr);\n    pthread_attr_setaffinity_np(&attr, sizeof(cpuset), &cpuset);\n    pthread_create(&pthread, &attr, do_main_thread, (void *) __app_cmdline);\n    void* retval;\n    pthread_join(pthread, &retval);\n\n    if (opt_noshutdown) {\n        // If the --noshutdown option is given, continue running the system,\n        // and whatever threads might be running, even after main returns\n        debug(\"main() returned.\\n\");\n        sched::thread::wait_until([] { return false; });\n    }\n\n#if CONF_memory_tracker\n    if (memory::tracker_enabled) {\n        debug(\"Leak testing done. Please use 'osv leak show' in gdb to analyze results.\\n\");\n        osv::halt();\n    } else {\n#endif\n        osv::shutdown();\n#if CONF_memory_tracker\n    }\n#endif\n}\n\nint __loader_argc = 0;\nchar** __loader_argv = nullptr;\nchar* __app_cmdline = nullptr;\n"
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "musl",
          "type": "blob",
          "size": 0.01171875,
          "content": "musl_1.1.24/"
        },
        {
          "name": "musl_0.9.12",
          "type": "commit",
          "content": null
        },
        {
          "name": "musl_1.1.24",
          "type": "commit",
          "content": null
        },
        {
          "name": "runtime.cc",
          "type": "blob",
          "size": 15.5830078125,
          "content": "/*\n * Copyright (C) 2013 Cloudius Systems, Ltd.\n *\n * This work is open source software, licensed under the terms of the\n * BSD license as described in the LICENSE file in the top-level directory.\n */\n\n#include <osv/drivers_config.h>\n#include <osv/sched.hh>\n#include <osv/elf.hh>\n#include <stdlib.h>\n#include <cstring>\n#include <string.h>\n#include <exception>\n#include <sys/mman.h>\n#include <unistd.h>\n#include <link.h>\n#include <stdio.h>\n#include <sys/poll.h>\n#include <sys/ioctl.h>\n#include <errno.h>\n#include <sys/uio.h>\n#include <wchar.h>\n#include <locale.h>\n#include <libintl.h>\n#include <ctype.h>\n#include <wctype.h>\n#include <langinfo.h>\n#include <stdarg.h>\n#include <xlocale.h>\n#include <cassert>\n#include <sys/sysinfo.h>\n#include \"processor.hh\"\n#include <osv/debug.hh>\n#include <osv/mempool.hh>\n#include <osv/export.h>\n#include <pwd.h>\n#include <fcntl.h>\n#include <osv/barrier.hh>\n#include \"smp.hh\"\n#include \"bsd/sys/sys/sysctl.h\"\n#include <osv/power.hh>\n#include <sys/time.h>\n#include <osv/mmu.hh>\n#include \"libc/libc.hh\"\n#include <api/sys/times.h>\n#include <map>\n#include <boost/range/adaptor/reversed.hpp>\n#include <osv/align.hh>\n#include <osv/stubbing.hh>\n#if CONF_drivers_acpi\n#include \"drivers/pvpanic.hh\"\n#endif\n#include <api/sys/resource.h>\n#include <api/math.h>\n#include <osv/shutdown.hh>\n#include <osv/execinfo.hh>\n#include <osv/demangle.hh>\n#include <processor.hh>\n#include <grp.h>\n#include <unordered_map>\n#include <api/sys/prctl.h>\n#include <sys/wait.h>\n#include <pty.h>\n#include <osv/pid.h>\n#include <osv/kernel_config_lazy_stack.h>\n#include <osv/kernel_config_lazy_stack_invariant.h>\n\n// cxxabi.h from gcc 10 and earlier used to say that __cxa_finalize returns\n// an int, while it should return void (and does so on gcc 11). To allow us\n// to define __cxa_finalize with neither gcc 10 or 11 complaining, we need\n// to hide the declaration in the header file\n#define __cxa_finalize __cxa_finalize_ignore\n#include <cxxabi.h>\n#undef __cxa_finalize\n\n#define __LC_LAST 13\n\nvoid *__dso_handle;\n\nstatic void print_backtrace(void)\n{\n    void *addrs[128];\n    int len;\n\n    debug_ll(\"\\n[backtrace]\\n\");\n\n    len = backtrace_safe(addrs, 128);\n\n    /* Start with i=1 to skip abort(const char *)  */\n    for (int i = 1; i < len; i++) {\n        char name[1024];\n        void *addr = addrs[i] - INSTR_SIZE_MIN;\n        osv::lookup_name_demangled(addr, name, sizeof(name));\n        if (strncmp(name, \"abort+\", 6) == 0) {\n            // Skip abort() (which called abort(const char*) already skipped\n            continue;\n        }\n        debug_ll(\"0x%016lx <%s>\\n\", addr, name);\n    }\n}\n\nstatic std::atomic<bool> aborting { false };\n\nvoid abort()\n{\n    abort(\"Aborted\\n\");\n}\n\nvoid abort(const char *fmt, ...)\n{\n    bool expected = false;\n    if (!aborting.compare_exchange_strong(expected, true)) {\n        do {} while (true);\n    }\n\n#if CONF_lazy_stack\n    sched::ensure_next_stack_page_if_preemptable();\n#endif\n    arch::irq_disable();\n\n    static char msg[1024];\n    va_list ap;\n\n    va_start(ap, fmt);\n    vsnprintf(msg, sizeof(msg), fmt, ap);\n    va_end(ap);\n\n    debug_early(msg);\n    // backtrace requires threads to be available, and also\n    // ELF s_program to be initialized.\n    if (sched::thread::current() && elf::get_program() != nullptr) {\n        print_backtrace();\n    } else {\n        debug_early(\"Halting.\\n\");\n    }\n#ifndef AARCH64_PORT_STUB\n#if CONF_drivers_acpi\n    panic::pvpanic::panicked();\n#endif\n#endif /* !AARCH64_PORT_STUB */\n\n    if (opt_power_off_on_abort) {\n        osv::poweroff();\n    } else {\n        osv::halt();\n    }\n}\n\n// __assert_fail() is used by the assert() macros\nOSV_LIBC_API\nvoid __assert_fail(const char *expr, const char *file, unsigned int line, const char *func)\n{\n    abort(\"Assertion failed: %s (%s: %s: %d)\\n\", expr, file, func, line);\n}\n\n\n// __cxa_atexit and __cxa_finalize:\n// Gcc implements static constructors and destructors in shared-objects (DSO)\n// in the following way: Static constructors are added to a list DT_INIT_ARRAY\n// in the object, and we run these functions after loading the object. Gcc's\n// code for each constructor calls a function __cxxabiv1::__cxa_atexit (which\n// we need to implement here) to register a destructor, linked to this DSO.\n// Gcc also adds a single finalization function to DT_FINI_ARRAY (which we\n// call when unloading the DSO), which calls __cxxabiv1::__cxa_finalize\n// (which we need to implement here) - this function is supposed to call all\n// the destructors previously registered for the given DSO.\n//\n// This implementation is greatly simplified by the assumption that the kernel\n// never exits, so our code doesn't need to work during early initialization,\n// nor does __cxa_finalize(0) need to work.\ntypedef void (*destructor_t)(void *);\nstatic std::map<void *, std::vector<std::pair<destructor_t,void*>>> destructors;\nstatic mutex destructors_mutex;\nnamespace __cxxabiv1 {\nint __cxa_atexit(destructor_t destructor, void *arg, void *dso)\n{\n    // As explained above, don't remember the kernel's own destructors.\n    if (dso == &__dso_handle)\n        return 0;\n    SCOPE_LOCK(destructors_mutex);\n    destructors[dso].push_back(std::make_pair(destructor, arg));\n    return 0;\n}\n\nvoid __cxa_finalize(void *dso)\n{\n    if (!dso || dso == &__dso_handle) {\n        debug(\"__cxa_finalize() running kernel's destructors not supported\\n\");\n        return;\n    }\n    std::vector<std::pair<destructor_t,void*>> my_destructors;\n    WITH_LOCK(destructors_mutex) {\n        my_destructors = std::move(destructors[dso]);\n        destructors.erase(dso);\n    }\n    for (auto d : boost::adaptors::reverse(my_destructors)) {\n        d.first(d.second);\n    }\n    return;\n}\n}\n\nOSV_LIBC_API\nint getpagesize()\n{\n    return 4096;\n}\n\nOSV_LIBC_API\nint vfork()\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nOSV_LIBC_API\nint fork()\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nOSV_LIBC_API\npid_t setsid(void)\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nNO_SYS(OSV_LIBC_API int execvp(const char *, char *const []));\n\nOSV_LIBC_API\nint mlockall(int flags)\n{\n    WARN_STUBBED();\n    return 0;\n}\n\nOSV_LIBC_API\nint munlockall(void)\n{\n    WARN_STUBBED();\n    return 0;\n}\n\nOSV_LIBC_API\nint mlock(const void*, size_t)\n{\n    WARN_STUBBED();\n    return 0;\n}\n\nOSV_LIBC_API\nint munlock(const void*, size_t)\n{\n    WARN_STUBBED();\n    return 0;\n}\n\nNO_SYS(OSV_LIBC_API int mkfifo(const char*, mode_t));\nNO_SYS(OSV_LIBC_API int mkfifoat(int, const char *, mode_t));\n\nOSV_LIBC_API\nint posix_fadvise(int fd, off_t offset, off_t len, int advice)\n{\n    switch (advice) {\n    case POSIX_FADV_NORMAL:\n    case POSIX_FADV_SEQUENTIAL:\n    case POSIX_FADV_RANDOM:\n    case POSIX_FADV_NOREUSE:\n    case POSIX_FADV_WILLNEED:\n    case POSIX_FADV_DONTNEED:\n        return 0;\n    default:\n        return EINVAL;\n    }\n}\nLFS64(posix_fadvise) __attribute__((nothrow));\n\nOSV_LIBC_API\nint posix_fallocate(int fd, off_t offset, off_t len)\n{\n    return ENOSYS;\n}\nLFS64(posix_fallocate) __attribute__((nothrow));\n\nOSV_LIBC_API\nint getpid()\n{\n    return OSV_PID;\n}\n\n//    WCTDEF(alnum), WCTDEF(alpha), WCTDEF(blank), WCTDEF(cntrl),\n//    WCTDEF(digit), WCTDEF(graph), WCTDEF(lower), WCTDEF(print),\n//    WCTDEF(punct), WCTDEF(space), WCTDEF(upper), WCTDEF(xdigit),\n\n#include \"ctype-data.h\"\n\nstatic struct __locale_struct c_locale = {\n    { }, // __locales_data\n    c_locale_array + 128, // __ctype_b\n    c_tolower_array + 128, // __ctype_tolower\n    c_toupper_array + 128, // __ctype_toupper\n    { }, // __names\n};\n\nlocale_t __c_locale_ptr = &c_locale;\n\nOSV_LIBC_API\nvoid* __stack_chk_guard = reinterpret_cast<void*>(0x12345678abcdefull);\nextern \"C\" OSV_LIBC_API\nvoid __stack_chk_fail(void) {\n    abort(\"__stack_chk_fail(): Stack overflow detected. Aborting.\\n\");\n}\n\nnamespace {\n    bool all_categories(int category_mask)\n    {\n\treturn (category_mask | (1 << LC_ALL)) == (1 << __LC_LAST) - 1;\n    }\n}\n\nstruct __locale_data {\n    const void *values[0];\n};\n\n#define _NL_ITEM(category, index)   (((category) << 16) | (index))\n#define _NL_ITEM_CATEGORY(item)     ((int) (item) >> 16)\n#define _NL_ITEM_INDEX(item)        ((int) (item) & 0xffff)\n\n#define _NL_CTYPE_CLASS  0\n#define _NL_CTYPE_TOUPPER 1\n#define _NL_CTYPE_TOLOWER 3\n\nextern \"C\" OSV_LIBC_API\n__locale_t __newlocale(int category_mask, const char *locale, locale_t base)\n    __THROW\n{\n    if (category_mask == 1 << LC_ALL) {\n        category_mask = ((1 << __LC_LAST) - 1) & ~(1 << LC_ALL);\n    }\n    assert(locale);\n    if (base == &c_locale) {\n        base = NULL;\n    }\n    if ((base == NULL || all_categories(category_mask))\n            && (category_mask == 0 || strcmp(locale, \"C\") == 0)) {\n        return &c_locale;\n    }\n    struct __locale_struct result = base ? *base : c_locale;\n    if (category_mask == 0) {\n        auto result_ptr = new __locale_struct;\n        *result_ptr = result;\n        auto ctypes = result_ptr->__locales[LC_CTYPE]->values;\n        result_ptr->__ctype_b = (const unsigned short *)\n\t            ctypes[_NL_ITEM_INDEX(_NL_CTYPE_CLASS)] + 128;\n        result_ptr->__ctype_tolower = (const int *)\n\t            ctypes[_NL_ITEM_INDEX(_NL_CTYPE_TOLOWER)] + 128;\n        result_ptr->__ctype_toupper = (const int *)\n\t            ctypes[_NL_ITEM_INDEX(_NL_CTYPE_TOUPPER)] + 128;\n        return result_ptr;\n    }\n    errno = ENOENT;\n    return nullptr;\n}\n\nOSV_LIBC_API\nlong sysconf(int name)\n{\n    switch (name) {\n    case _SC_CLK_TCK: return CLOCKS_PER_SEC;\n    case _SC_PAGESIZE: return mmu::page_size;\n    case _SC_THREAD_STACK_MIN: return 16384;\n    case _SC_LINE_MAX: return 2048;\n    case _SC_THREAD_PROCESS_SHARED: return true;\n    case _SC_NPROCESSORS_ONLN: return sched::cpus.size();\n    case _SC_NPROCESSORS_CONF: return sched::cpus.size();\n    case _SC_PHYS_PAGES: return memory::phys_mem_size / memory::page_size;\n    case _SC_AVPHYS_PAGES: return memory::stats::free() / memory::page_size;\n    case _SC_GETPW_R_SIZE_MAX: return 1024;\n    case _SC_IOV_MAX: return KERN_IOV_MAX;\n    case _SC_THREAD_SAFE_FUNCTIONS: return 1;\n    case _SC_GETGR_R_SIZE_MAX: return 1;\n    case _SC_OPEN_MAX: return FDMAX;\n    case _SC_MINSIGSTKSZ: return MINSIGSTKSZ;\n    case _SC_SIGSTKSZ: return SIGSTKSZ;\n    default:\n        debugf(\"sysconf(): stubbed for parameter %ld\\n\", name);\n        errno = EINVAL;\n        return -1;\n    }\n}\n\nOSV_LIBC_API\nlong pathconf(const char *, int name)\n{\n    return fpathconf(-1, name);\n}\n\nOSV_LIBC_API\nlong fpathconf(int, int)\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nOSV_LIBC_API\nsize_t confstr(int name, char* buf, size_t len)\n{\n    const char* v = nullptr;\n    switch (name) {\n    case _CS_GNU_LIBC_VERSION: v = \"glibc 2.16\";\n    case _CS_GNU_LIBPTHREAD_VERSION: v = \"NPTL 2.16\";\n    // Skip _CS_PATH as it does not make sense in OSv\n    }\n\n    if (v) {\n        // Return how many bytes needed to store the value including the null terminator\n        auto ret = strlen(v) + 1;\n        if (len > 0 && buf) {\n            snprintf(buf, len, \"%s\", v);\n        }\n        return ret;\n    } else {\n        errno = EINVAL;\n        return 0;\n    }\n}\n\nOSV_LIBC_API\nFILE *popen(const char *command, const char *type)\n{\n    WARN_STUBBED();\n    return NULL;\n}\n\nOSV_LIBC_API\nint pclose(FILE *stream)\n{\n    return 0;\n}\n\nvoid exit(int status)\n{\n    debugf(\"program exited with status %ld\\n\", status);\n    osv::shutdown();\n}\n\n// \"The function _exit() is like exit(3), but does not call any functions\n// registered with atexit(3) or on_exit(3).\"\n//\n\nOSV_LIBC_API\nint atexit(void (*func)())\n{\n    // nothing to do\n    return 0;\n}\n\nOSV_LIBC_API\nint get_nprocs()\n{\n    return sysconf(_SC_NPROCESSORS_ONLN);\n}\n\nOSV_LIBC_API\nclock_t times(struct tms *buffer)\n{\n    using namespace std::chrono;\n    struct timespec ts;\n\n    clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ts);\n\n    typedef duration<u64, std::ratio<1, CLOCKS_PER_SEC>> clockseconds;\n    clockseconds time;\n    time = duration_cast<clockseconds>(seconds(ts.tv_sec) + nanoseconds(ts.tv_nsec));\n\n    if (buffer) {\n        buffer->tms_utime = time.count();\n        buffer->tms_stime = 0;\n        buffer->tms_cutime = 0;\n        buffer->tms_cstime = 0;\n        return buffer->tms_utime;\n    } else {\n        return time.count();\n    }\n}\n\nstatic int prio_find_thread(sched::thread **th, int which, int id)\n{\n    errno = 0;\n    if ((which == PRIO_USER) || (which == PRIO_PGRP)) {\n        *th = nullptr;\n        return 0;\n    }\n\n    if (which != PRIO_PROCESS) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    if (id == 0) {\n        *th = sched::thread::current();\n    } else {\n        *th = sched::thread::find_by_id(id);\n    }\n\n    if (!*th) {\n        errno = ESRCH;\n        return -1;\n    }\n    return 0;\n}\n\n// Our priority formula is osv_prio = e^(prio * k), where k is a constant.\n// We want osv_prio(20) = 86, and osv_prio(-20) = 1/86, as this gives the\n// best agreement with Linux's current interpretation of the nice values\n// (see tests/misc-setpriority.cc).\n//\n// So e^(20 * prio_k) = 86\n//    20 * prio_k = ln(86)\n//    prio_k = ln(86) / 20\n//\n// When we are given OSv prio, obviously, the inverse formula applies:\n//\n//    e^(prio * prio_k) = osv_prio\n//    prio * prio_k = ln(osv_prio)\n//    prio = ln(osv_prio) / prio_k\n//\nstatic constexpr float prio_k = log(86) / 20;\n\nOSV_LIBC_API\nint getpriority(int which, int id)\n{\n    sched::thread *th;\n    int ret = prio_find_thread(&th, which, id);\n    if (ret < 0) {\n        return ret;\n    }\n\n    // Case for which which is not a process and we should just return and not\n    // do anything\n    if (!th && !ret) {\n        return 0;\n    }\n\n    // We're not super concerned with speed during get/set priority, which we\n    // expect to be fairly rare. So we can use the stdlib math functions\n    // instead of any fast approximations.\n    int prio = logf(th->priority()) / prio_k;\n    if (prio < -20) {\n        prio = -20;\n    }\n    if (prio > 19) {\n        prio = 19;\n    }\n    return prio;\n}\n\nOSV_LIBC_API\nint setpriority(int which, int id, int prio)\n{\n    sched::thread *th;\n    int ret = prio_find_thread(&th, which, id);\n    if (ret < 0) {\n        return ret;\n    }\n    if (!th && !ret) {\n        return 0;\n    }\n\n    float p = expf(prio_k * prio);\n    th->set_priority(p);\n    return 0;\n}\n\nOSV_LIBC_API\nint initgroups(const char *user, gid_t group)\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nOSV_LIBC_API\nint prctl(int option, ...)\n{\n    switch (option) {\n    case PR_SET_DUMPABLE:\n        return 0;\n    }\n    errno = EINVAL;\n    return -1;\n}\n\nOSV_LIBC_API\nint daemon(int nochdir, int noclose)\n{\n    WARN_STUBBED();\n    return -1;\n}\n\nextern \"C\" OSV_LIBC_API\nint sysctl(int *, int, void *, size_t *, void *, size_t)\n{\n    WARN_STUBBED();\n    errno = ENOTDIR;\n    return -1;\n}\n\nextern \"C\" OSV_LIBC_API\nchar *tmpnam_r(char *s)\n{\n    return s ? tmpnam(s) : NULL;\n}\n\nOSV_LIBC_API\npid_t wait3(int *status, int options, struct rusage *usage)\n{\n    WARN_STUBBED();\n    errno = ECHILD;\n    return -1;\n}\n\nOSV_LIBC_API\npid_t wait4(pid_t pid, int *status, int options, struct rusage *usage)\n{\n    WARN_STUBBED();\n    errno = ECHILD;\n    return -1;\n}\n\nOSV_LIBC_API\nint getresuid(uid_t *ruid, uid_t *euid, uid_t *suid)\n{\n    WARN_STUBBED();\n    errno = ENOSYS;\n    return -1;\n}\n\nOSV_LIBC_API\nint getresgid(gid_t *rgid, gid_t *egid, gid_t *sgid)\n{\n    WARN_STUBBED();\n    errno = ENOSYS;\n    return -1;\n}\n\nOSV_LIBUTIL_API\nint openpty(int *amaster, int *aslave, char *name,\n           const struct termios *termp,\n           const struct winsize *winp)\n{\n    WARN_STUBBED();\n    errno = ENOENT;\n    return -1;\n}\n\nOSV_LIBUTIL_API\npid_t forkpty(int *amaster, char *name,\n             const struct termios *termp,\n             const struct winsize *winp)\n{\n    WARN_STUBBED();\n    errno = ENOENT;\n    return -1;\n}\n\nOSV_LIBC_API\nint nice(int inc)\n{\n    return setpriority(PRIO_PROCESS, 0, getpriority(PRIO_PROCESS, 0)+inc);\n}\n\nOSV_LIBC_API\nchar *ctermid(char *s)\n{\n    static char s2[L_ctermid];\n    WARN_STUBBED();\n    if (!s) s = s2;\n    *s = 0;\n    return s;\n}\n\n// OSv is always multi-threaded.\nOSV_LIBC_API\nchar __libc_single_threaded = 0;\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "syscalls",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "usr.manifest.skel",
          "type": "blob",
          "size": 0.32421875,
          "content": "[manifest]\n/libenviron.so: libenviron.so\n/tools/mount-fs.so: tools/mount/mount-fs.so\n/tools/umount.so: tools/mount/umount.so\n/usr/lib/libgcc_s.so.1: %(libgcc_s_dir)s/libgcc_s.so.1\n/&/etc/hosts: ../../static/&\n/etc/mnttab: ->/proc/mounts\n/etc/fstab: fstab\n/dev: ../../static\n/proc: ../../static\n/sys: ../../static\n/tmp: ../../static\n"
        },
        {
          "name": "usr_ramfs.manifest.skel",
          "type": "blob",
          "size": 0.32421875,
          "content": "[manifest]\n/libenviron.so: libenviron.so\n/tools/mount-fs.so: tools/mount/mount-fs.so\n/tools/umount.so: tools/mount/umount.so\n/usr/lib/libgcc_s.so.1: %(libgcc_s_dir)s/libgcc_s.so.1\n/&/etc/hosts: ../../static/&\n/etc/mnttab: ->/proc/mounts\n/etc/fstab: fstab\n/dev: ../../static\n/proc: ../../static\n/sys: ../../static\n/tmp: ../../static\n"
        },
        {
          "name": "usr_rofs.manifest.skel",
          "type": "blob",
          "size": 0.34375,
          "content": "[manifest]\n/libenviron.so: libenviron.so\n/tools/mount-fs.so: tools/mount/mount-fs.so\n/tools/umount.so: tools/mount/umount.so\n/usr/lib/libgcc_s.so.1: %(libgcc_s_dir)s/libgcc_s.so.1\n/&/etc/hosts: ../../static/&\n/etc/mnttab: ->/proc/mounts\n/etc/fstab: fstab\n/dev: ../../static\n/proc: ../../static\n/sys: ../../static\n/tmp: ../../static\n/data: ../../static\n"
        },
        {
          "name": "zfs_builder_bootfs.S",
          "type": "blob",
          "size": 0.1171875,
          "content": ".pushsection .data\n.global bootfs_start\n.hidden bootfs_start\nbootfs_start:\n.incbin \"zfs_builder_bootfs.bin\"\n.popsection\n"
        },
        {
          "name": "zfs_builder_bootfs.manifest.skel",
          "type": "blob",
          "size": 0.2578125,
          "content": "[manifest]\n/libuutil.so: libuutil.so\n/zpool.so: zpool.so\n/usr/lib/fs/libsolaris.so: libsolaris.so\n/libzfs.so: libzfs.so\n/zfs.so: zfs.so\n/tools/mkfs.so: tools/mkfs/mkfs.so\n/tools/cpiod.so: tools/cpiod/cpiod.so\n/usr/lib/libgcc_s.so.1: %(libgcc_s_dir)s/libgcc_s.so.1\n"
        }
      ]
    }
  ]
}