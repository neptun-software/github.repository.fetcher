{
  "metadata": {
    "timestamp": 1736709870916,
    "page": 356,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "SchedMD/slurm",
      "stars": 2797,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.4462890625,
          "content": "*.o\n*.la\n*.lo\n*.orig\n*.rej\n.*.swp\n.*.swo\n.deps\n.libs\n__pycache__\nMakefile\nautom4te.cache\n/api/full_version.map\n/compile_commands.json\n/config.h\n/config.h.in~\n/config.log\n/config.status\n/configure~\n/contribs/compile_commands.json\n/contribs/perlapi/libslurm/perl/Makefile.PL\n/contribs/perlapi/libslurmdb/perl/Makefile.PL\n/cscope.files\n/cscope.out\n/debian/autoreconf.*\n/debian/.debhelper\n/debian/debhelper-build-stamp\n/debian/files\n/debian/*.log\n/debian/*.substvars\n/debian/tmp\n/doc/html/*.html\n!/doc/html/review_release.html\n/etc/cgroup.release_common.example\n/etc/init.d.slurm\n/etc/init.d.slurmdbd\n/etc/slurmctld.service\n/etc/slurmd.service\n/etc/slurmdbd.service\n/libtool\n/slurm/slurm_version.h\n/slurm/stamp-h2\n/src/api/pmi_version.map\n/src/api/version.map\n/src/common/global_defaults.c\n/src/db_api/version.map\n/stamp-h1\n/src/sacct/sacct\n/src/sacctmgr/sacctmgr\n/src/salloc/salloc\n/src/sattach/sattach\n/src/sbatch/sbatch\n/src/sbcast/sbcast\n/src/scancel/scancel\n/src/scontrol/scontrol\n/src/sdiag/sdiag\n/src/sinfo/sinfo\n/src/slurmctld/slurmctld\n/src/slurmd/slurmd/slurmd\n/src/slurmd/slurmstepd/slurmstepd\n/src/slurmdbd/slurmdbd\n/src/sprio/sprio\n/src/squeue/squeue\n/src/sreport/sreport\n/src/srun/srun\n/src/sshare/sshare\n/src/sstat/sstat\n/src/strigger/strigger\n/src/sview/sview\n/testsuite/testsuite.conf\n/testsuite/testsuite.conf.sample\n/testsuite/expect/globals.*\n!/testsuite/expect/globals.local.sample.in\n/testsuite/expect/*.log*\n/testsuite/log\n/testsuite/python/pytest.ini\nTAGS\ntags\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8505859375,
          "content": "---\nexclude: configure|.+\\.in|.+\\.m4|LICENSE.OpenSSL\nrepos:\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: v5.0.0\n  hooks:\n  - id: check-merge-conflict\n  - id: end-of-file-fixer\n  - id: trailing-whitespace\n\n- repo: https://github.com/psf/black\n  rev: 24.10.0\n  hooks:\n  - id: black\n    language_version: python3\n\n- repo: https://github.com/pycqa/flake8\n  rev: 7.1.1\n  hooks:\n  - id: flake8\n    args: [--config, tools/flake8]\n\n- repo: https://github.com/codespell-project/codespell\n  rev: v2.3.0\n  hooks:\n  - id: codespell\n    exclude_types: [gif,tar,png,pdf,svg]\n    exclude: auxdir|expect/globals|jquery\\.min\\.js\n    args: [--config, tools/codespellrc]\n  - id: codespell\n    alias: codespell-apply\n    exclude_types: [gif,tar,png,pdf,svg]\n    exclude: auxdir|expect/globals|jquery\\.min\\.js\n    args: [--config, tools/codespellrc, -w]\n    stages: [manual]\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.1162109375,
          "content": "The Slurm authors are documented in doc/html/team.shtml,\nwhich is accessible at <https://slurm.schedmd.com/team.html>.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.5390625,
          "content": "NOTES FOR GITHUB DEVELOPERS\n---------------------------\n\nThe official issue tracker for Slurm is at\n  https://bugs.schedmd.com/\n\nWe welcome code contributions and patches, but **we do not accept Pull Requests\nthrough GitHub at this time.** Please submit patches as attachments to new\nbugs under the \"C - Contributions\" severity level.\n\nTARGET RELEASES\n---------------\nChanges involving adding new functionality, functional changes to the command\nline tools (either in adding new options, or changing the output formats), any\nRPC protocol changes or state file format modifications, and similar work is\nonly considered for inclusion on the master branch (which will become the next\nstable Slurm release).\n\nBug fixes themselves are considered for inclusion on the most recent stable\nrelease, although may be deferred to the next major release at the reviewers'\ndiscretion.\n\nAll contributed patches are subject to review by SchedMD.\n\nCODING GUIDELINES\n-----------------\nSlurm loosely follows the Linux Kernel style guidelines\n(https://www.kernel.org/doc/html/latest/process/coding-style.html).\nIf in doubt, please follow their example.\n\nA brief overview, with some notable exceptions:\n- Tabs not spaces, tabs are 8-spaces wide.\n- Lines should be less than 80-characters wide.\n- Except that error message and other log messages should not be broken up\n  mid-sentence. They should be split on a format sequence, comma, or period\n  instead. (This is to make it easier to grep for that string in the source\n  code at a later point.)\n- Use K&R style for braces.\n- Slurm does use typedef's for certain types, ignore Chapter 5 of the kernel\n  guidelines.\n- Comments can be in either C-style `/* comment */` or C++ style  `// comment`\n  formats. Follow the rest of Chapter 8's recommendations for multi-line\n  comments though.\n\nBUILD SYSTEM CHANGES\n--------------------\nPlease submit changes to `Makefile.am`, but not to `Makefile.in`. We will\nregenerate those files to minimize the differences in the commit. We want to\navoid noise generated by differences in libtool installations.\n\nChanges to `configure.ac` or `auxdir/*` will take additional time to review -\nSlurm is built on a wide variety of distributions and architectures, and even\nminor differences can cause unintended consequences.\n\nPATCH SUBMISSION\n----------------\nAn entry in `NEWS` should describe the change or new functionality.\n\nPlease break patches up into logically separate chunks, while ensuring that\neach patch can still be compiled. (Anticipate that a developer using `git\nbisect` may pick any intermediate commit at some point.)\n\nIf you decided to reformat a file, please submit non-functional changes\n(spelling corrections, formatting discrepancies) in a separate patch. This\nmakes reviewing substantially easier, and allows us to focus our attention on\nthe functional differences.\n\nIf you make an automated change (changing a function name, fixing a pervasive\nspelling mistake), please send the command/regex used to generate the changes\nalong with the patch, or note it in the commit message.\n\nWhile not required, we encourage use of `git format-patch` to generate the\npatch. This ensures the relevant author line and commit message stay attached.\nPlain `diff`'d output is also okay. In either case, please attach them to the\nbug for us to review. Spelling corrections or documentation improvements can be\nsuggested without attaching the patch as long as you describe their location.\n\nLEGAL\n-----\n\nWe ask that a contributor licensing agreement be signed for all substantial\ncontributions. Please see https://slurm.schedmd.com/contributor.html for\ndetails.\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 19.994140625,
          "content": "\t\t\t SLURM LICENSE AGREEMENT\n\nAll Slurm code and documentation is available under the GNU General Public\nLicense. Some tools in the \"contribs\" directory have other licenses. See\nthe documentation for individual contributed tools for details.\n\nIn addition, as a special exception, the copyright holders give permission\nto link the code of portions of this program with the OpenSSL library under\ncertain conditions as described in each individual source file, and distribute\nlinked combinations including the two. You must obey the GNU General Public\nLicense in all respects for all of the code used other than OpenSSL. If you\nmodify file(s) with this exception, you may extend this exception to your\nversion of the file(s), but you are not obligated to do so. If you do not\nwish to do so, delete this exception statement from your version. If you\ndelete this exception statement from all source files in the program, then\nalso delete it here.\n\nNO WARRANTY: Because the program is licensed free of charge, there is no\nwarranty for the program. See section 11 below for full details.\n\n=============================================================================\n\nOUR NOTICE AND TERMS OF AND CONDITIONS OF THE GNU GENERAL PUBLIC LICENSE\n\nAuspices\n\nPortions of this work were performed under the auspices of the U.S. Department\nof Energy by Lawrence Livermore National Laboratory under Contract\nDE-AC52-07NA27344.\n\nDisclaimer\n\nThis work was sponsored by an agency of the United States government.\nNeither the United States Government nor Lawrence Livermore National\nSecurity, LLC, nor any of their employees, makes any warranty, express\nor implied, or assumes any liability or responsibility for the accuracy,\ncompleteness, or usefulness of any information, apparatus, product, or\nprocess disclosed, or represents that its use would not infringe privately\nowned rights. References herein to any specific commercial products, process,\nor services by trade names, trademark, manufacturer or otherwise does not\nnecessarily constitute or imply its endorsement, recommendation, or\nfavoring by the United States Government or the Lawrence Livermore National\nSecurity, LLC. The views and opinions of authors expressed herein do not\nnecessarily state or reflect those of the United States government or\nLawrence Livermore National Security, LLC, and shall not be used for\nadvertising or product endorsement purposes.\n\n=============================================================================\n\n\t\t    GNU GENERAL PUBLIC LICENSE\n\t\t       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\t\t\t    Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Library General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n\t\t    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n\t\t\t    NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n\t\t     END OF TERMS AND CONDITIONS\n\n\t    How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program; if not, write to the Free Software\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA\n\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Library General\nPublic License instead of this License.\n"
        },
        {
          "name": "DISCLAIMER",
          "type": "blob",
          "size": 6.208984375,
          "content": "Slurm was produced at Lawrence Livermore National Laboratory in collaboration\nwith various organizations.\n\nCopyright (C) 2012-2013 Los Alamos National Security, LLC.\nCopyright (C) 2011 Trinity Centre for High Performance Computing\nCopyright (C) 2010-2015 SchedMD LLC\nCopyright (C) 2009-2013 CEA/DAM/DIF\nCopyright (C) 2009-2011 Centro Svizzero di Calcolo Scientifico (CSCS)\nCopyright (C) 2008-2011 Lawrence Livermore National Security\nCopyright (C) 2008 Vijay Ramasubramanian\nCopyright (C) 2007-2008 Red Hat, Inc.\nCopyright (C) 2007-2013 National University of Defense Technology, China\nCopyright (C) 2007-2015 Bull\nCopyright (C) 2005-2008 Hewlett-Packard Development Company, L.P.\nCopyright (C) 2004-2009, Marcus Holland-Moritz\nCopyright (C) 2002-2007 The Regents of the University of California\nCopyright (C) 2002-2003 Linux NetworX\nCopyright (C) 2002 University of Chicago\nCopyright (C) 2001, Paul Marquess\nCopyright (C) 2000 Markus Friedl\nCopyright (C) 1999, Kenneth Albanowski\nCopyright (C) 1998 Todd C. Miller <Todd.Miller@courtesan.com>\nCopyright (C) 1996-2003 Maximum Entropy Data Consultants Ltd,\nCopyright (C) 1995 Tatu Ylonen <ylo@cs.hut.fi>, Espoo, Finland\nCopyright (C) 1989-1994, 1996-1999, 2001 Free Software Foundation, Inc.\nMany other organizations contributed code and/or documentation without\nincluding a copyright notice.\n\nWritten by:\nAmjad Majid Ali (Colorado State University)\nPar Andersson (National Supercomputer Centre, Sweden)\nDon Albert (Bull)\nErnest Artiaga (Barcelona Supercomputer Center, Spain)\nDanny Auble (LLNL, SchedMD LLC)\nSusanne Balle (HP)\nAnton Blanchard (Samba)\nJanne Blomqvist (Aalto University, Finland)\nDavid Bremer (LLNL)\nJon Bringhurst (LANL)\nBill Brophy (Bull)\nHongjia Cao (National University of Defense Techonogy, China)\nDaniel Christians (HP)\nGilles Civario (Bull)\nChuck Clouston (Bull)\nJoseph Donaghy (LLNL)\nChris Dunlap (LLNL)\nJoey Ekstrom (LLNL/Bringham Young University)\nJosh England (TGS Management Corporation)\nKent Engstrom (National Supercomputer Centre, Sweden)\nJim Garlick (LLNL)\nDidier Gazen (Laboratoire d'Aerologie, France)\nRaphael Geissert (Debian)\nYiannis Georgiou (Bull)\nAndriy Grytsenko (Massive Solutions Limited, Ukraine)\nMark Grondona (LLNL)\nTakao Hatazaki (HP, Japan)\nMatthieu Hautreux (CEA, France)\nChris Holmes (HP)\nDavid Hoppner\nNathan Huff (North Dakota State University)\nDavid Jackson (Adaptive Computing)\nMorris Jette (LLNL, SchedMD LLC)\nKlaus Joas (University Karlsruhe, Germany)\nGreg Johnson (LANL)\nJason King (LLNL)\nAaron Knister (Environmental Protection Agency)\nNancy Kritkausky (Bull)\nRoman Kurakin (Institute of Natural Science and Ecology, Russia)\nEric Lin (Bull)\nDon Lipari (LLNL)\nPuenlap Lee (Bull)\nDennis Leepow\nBernard Li (Genome Sciences Centre, Canada)\nDonald Lipari (LLNL)\nSteven McDougall (SiCortex)\nDonna Mecozzi (LLNL)\nBjorn-Helge Mevik (University of Oslo, Norway)\nChris Morrone (LLNL)\nPere Munt (Barcelona Supercomputer Center, Spain)\nMichal Novotny (Masaryk University, Czech Republic)\nBryan O'Sullivan (Pathscale)\nGennaro Oliva (Institute of High Performance Computing and Networking, Italy)\nAlejandro Lucero Palau (Barcelona Supercomputer Center, Spain)\nDaniel Palermo (HP)\nDan Phung (LLNL/Columbia University)\nAshley Pittman (Quadrics, UK)\nVijay Ramasubramanian (University of Maryland)\nKrishnakumar Ravi[KK] (HP)\nPetter Reinholdtsen (University of Oslo, Norway)\nGerrit Renker (Swiss National Computer Centre)\nAndy Riebs (HP)\nAsier Roa (Barcelona Supercomputer Center, Spain)\nMiguel Ros (Barcelona Supercomputer Center, Spain)\nBeat Rubischon (DALCO AG, Switzerland)\nDan Rusak (Bull)\nEygene Ryabinkin (Kurchatov Institute, Russia)\nFederico Sacerdoti (D.E. Shaw)\nRod Schultz (Bull)\nTyler Strickland (University of Florida)\nJeff Squyres (LAM MPI)\nPrashanth Tamraparni (HP, India)\nJimmy Tang (Trinity College, Ireland)\nKevin Tew (LLNL/Bringham Young University)\nAdam Todorski (Rensselaer Polytechnic Institute)\nNathan Weeks (Iowa State University)\nTim Wickberg (Rensselaer Polytechnic Institute)\nRamiro Brito Willmersdorf (Universidade Federal de Pemambuco, Brazil)\nJay Windley (Linux NetworX)\nAnne-Marie Wunderlin (Bull)\n\nCODE-OCEC-09-009. All rights reserved.\n\nThis file is part of Slurm, a resource management program.\nFor details, see <https://slurm.schedmd.com/>.\nPlease also read the supplied file: DISCLAIMER.\n\nSlurm is free software; you can redistribute it and/or modify it under\nthe terms of the GNU General Public License as published by the Free\nSoftware Foundation; either version 2 of the License, or (at your option)\nany later version.\n\nSlurm is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\nFOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\ndetails.\n\nYou should have received a copy of the GNU General Public License along\nwith Slurm; if not, write to the Free Software Foundation, Inc.,\n51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\n\nOUR NOTICE AND TERMS OF AND CONDITIONS OF THE GNU GENERAL PUBLIC LICENSE\n\nOur Preamble Notice\n\nAuspices\n\nThis work performed under the auspices of the U.S. Department of Energy by\nLawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.\n\nDisclaimer\n\nThis work was sponsored by an agency of the United States government.\nNeither the United States Government nor Lawrence Livermore National\nSecurity, LLC, nor any of their employees, makes any warranty, express\nor implied, or assumes any liability or responsibility for the accuracy,\ncompleteness, or usefulness of any information, apparatus, product, or\nprocess disclosed, or represents that its use would not infringe privately\nowned rights. References herein to any specific commercial products, process,\nor services by trade names, trademark, manufacturer or otherwise does not\nnecessarily constitute or imply its endorsement, recommendation, or\nfavoring by the United States Government or the Lawrence Livermore National\nSecurity, LLC. The views and opinions of authors expressed herein do not\nnecessarily state or reflect those of the United States government or\nLawrence Livermore National Security, LLC, and shall not be used for\nadvertising or product endorsement purposes.\n\nThe precise terms and conditions for copying, distribution and modification\nis provided in the file named \"COPYING\" in this directory.\n"
        },
        {
          "name": "INSTALL",
          "type": "blob",
          "size": 9.34375,
          "content": "Copyright 1994, 1995, 1996, 1999, 2000, 2001, 2002 Free Software\nFoundation, Inc.\n\n   This file is free documentation; the Free Software Foundation gives\nunlimited permission to copy, distribute and modify it.\n\nBasic Installation\n==================\n\n   These are generic Linux installation instructions. Build instructions\nspecific to Slurm are available at\nhttps://slurm.schedmd.com/quickstart_admin.html\n(also found in the file doc/html/quickstart_admin.shtml).\n\n   The 'configure' shell script attempts to guess correct values for\nvarious system-dependent variables used during compilation.  It uses\nthose values to create a 'Makefile' in each directory of the package.\nIt may also create one or more '.h' files containing system-dependent\ndefinitions.  Finally, it creates a shell script 'config.status' that\nyou can run in the future to recreate the current configuration, and a\nfile 'config.log' containing compiler output (useful mainly for\ndebugging 'configure').\n\n   It can also use an optional file (typically called 'config.cache'\nand enabled with '--cache-file=config.cache' or simply '-C') that saves\nthe results of its tests to speed up reconfiguring.  (Caching is\ndisabled by default to prevent problems with accidental use of stale\ncache files.)\n\n   If you need to do unusual things to compile the package, please try\nto figure out how 'configure' could check whether to do them, and mail\ndiffs or instructions to the address given in the 'README' so they can\nbe considered for the next release.  If you are using the cache, and at\nsome point 'config.cache' contains results you don't want to keep, you\nmay remove or edit it.\n\n   The file 'configure.ac' (or 'configure.in') is used to create\n'configure' by a program called 'autoconf'.  You only need\n'configure.ac' if you want to change it or regenerate 'configure' using\na newer version of 'autoconf'.\n\nThe simplest way to build and install this package is:\n\n  1. 'cd' to the directory containing the package's source code and type\n     './configure' to configure the package for your system.  If you're\n     using 'csh' on an old version of System V, you might need to type\n     'sh ./configure' instead to prevent 'csh' from trying to execute\n     'configure' itself.\n\n     Running 'configure' takes awhile.  While running, it prints some\n     messages telling which features it is checking for.\n\n  2. Type 'make' to compile the package.\n\n  3. Optionally, type 'make check' to run any self-tests that come with\n     the package.\n\n  4. Type 'make install' to install the programs and any data files and\n     documentation.\n\n  5. You can remove the program binaries and object files from the\n     source code directory by typing 'make clean'.  To also remove the\n     files that 'configure' created (so you can compile the package for\n     a different kind of computer), type 'make distclean'.  There is\n     also a 'make maintainer-clean' target, but that is intended mainly\n     for the package's developers.  If you use it, you may have to get\n     all sorts of other programs in order to regenerate files that came\n     with the distribution.\n\nAlternate build and installation instructions for systems supporting RPM:\n\n  1. rpmbuild -ta slurm.*.tar.bz2\n  2. rpm --install <the appropriate RPM files>\n\nCompilers and Options\n=====================\n\n   Some systems require unusual options for compilation or linking that\nthe 'configure' script does not know about.  Run './configure --help'\nfor details on some of the pertinent environment variables.\n\n   You can give 'configure' initial values for variables by setting\nthem in the environment.  You can do that on the command line like this:\n\n     ./configure CC=c89 CFLAGS=-O2 LIBS=-lposix\n\n   *Note Defining Variables::, for more details.\n\nCompiling For Multiple Architectures\n====================================\n\n   You can compile the package for more than one kind of computer at the\nsame time, by placing the object files for each architecture in their\nown directory.  To do this, you must use a version of 'make' that\nsupports the 'VPATH' variable, such as GNU 'make'.  'cd' to the\ndirectory where you want the object files and executables to go and run\nthe 'configure' script.  'configure' automatically checks for the\nsource code in the directory that 'configure' is in and in '..'.\n\n   If you have to use a 'make' that does not support the 'VPATH'\nvariable, you have to compile the package for one architecture at a\ntime in the source code directory.  After you have installed the\npackage for one architecture, use 'make distclean' before reconfiguring\nfor another architecture.\n\nInstallation Names\n==================\n\n   By default, 'make install' will install the package's files in\n'/usr/local/bin', '/usr/local/man', etc.  You can specify an\ninstallation prefix other than '/usr/local' by giving 'configure' the\noption '--prefix=PATH'.\n\n   You can specify separate installation prefixes for\narchitecture-specific files and architecture-independent files.  If you\ngive 'configure' the option '--exec-prefix=PATH', the package will use\nPATH as the prefix for installing programs and libraries.\nDocumentation and other data files will still use the regular prefix.\n\n   In addition, if you use an unusual directory layout you can give\noptions like '--bindir=PATH' to specify different values for particular\nkinds of files.  Run 'configure --help' for a list of the directories\nyou can set and what kinds of files go in them.\n\n   If the package supports it, you can cause programs to be installed\nwith an extra prefix or suffix on their names by giving 'configure' the\noption '--program-prefix=PREFIX' or '--program-suffix=SUFFIX'.\n\nOptional Features\n=================\n\n   Some packages pay attention to '--enable-FEATURE' options to\n'configure', where FEATURE indicates an optional part of the package.\nThey may also pay attention to '--with-PACKAGE' options, where PACKAGE\nis something like 'gnu-ld' or 'x11' (for the X Window System).  Information\non any '--enable-' or '--with-' options that are supported can be found\nwith 'configure --help'.\n\n   For packages that use the X Window System, 'configure' can usually\nfind the X include and library files automatically, but if it doesn't,\nyou can use the 'configure' options '--x-includes=DIR' and\n'--x-libraries=DIR' to specify their locations.\n\nSpecifying the System Type\n==========================\n\n   There may be some features 'configure' cannot figure out\nautomatically, but needs to determine by the type of machine the package\nwill run on.  Usually, assuming the package is built to be run on the\n_same_ architectures, 'configure' can figure that out, but if it prints\na message saying it cannot guess the machine type, give it the\n'--build=TYPE' option.  TYPE can either be a short name for the system\ntype, such as 'sun4', or a canonical name which has the form:\n\n     CPU-COMPANY-SYSTEM\n\nwhere SYSTEM can have one of these forms:\n\n     OS KERNEL-OS\n\n   See the file 'config.sub' for the possible values of each field.  If\n'config.sub' isn't included in this package, then this package doesn't\nneed to know the machine type.\n\n   If you are _building_ compiler tools for cross-compiling, you should\nuse the '--target=TYPE' option to select the type of system they will\nproduce code for.\n\n   If you want to _use_ a cross compiler, that generates code for a\nplatform different from the build platform, you should specify the\n\"host\" platform (i.e., that on which the generated programs will\neventually be run) with '--host=TYPE'.\n\nSharing Defaults\n================\n\n   If you want to set default values for 'configure' scripts to share,\nyou can create a site shell script called 'config.site' that gives\ndefault values for variables like 'CC', 'cache_file', and 'prefix'.\n'configure' looks for 'PREFIX/share/config.site' if it exists, then\n'PREFIX/etc/config.site' if it exists.  Or, you can set the\n'CONFIG_SITE' environment variable to the location of the site script.\nA warning: not all 'configure' scripts look for a site script.\n\nDefining Variables\n==================\n\n   Variables not defined in a site shell script can be set in the\nenvironment passed to 'configure'.  However, some packages may run\nconfigure again during the build, and the customized values of these\nvariables may be lost.  In order to avoid this problem, you should set\nthem in the 'configure' command line, using 'VAR=value'.  For example:\n\n     ./configure CC=/usr/local2/bin/gcc\n\nwill cause the specified gcc to be used as the C compiler (unless it is\noverridden in the site shell script).\n\n'configure' Invocation\n======================\n\n   'configure' recognizes the following options to control how it\noperates.\n\n'--help'\n'-h'\n     Print a summary of the options to 'configure', and exit.\n\n'--version'\n'-V'\n     Print the version of Autoconf used to generate the 'configure'\n     script, and exit.\n\n'--cache-file=FILE'\n     Enable the cache: use and save the results of the tests in FILE,\n     traditionally 'config.cache'.  FILE defaults to '/dev/null' to\n     disable caching.\n\n'--config-cache'\n'-C'\n     Alias for '--cache-file=config.cache'.\n\n'--quiet'\n'--silent'\n'-q'\n     Do not print messages saying which checks are being made.  To\n     suppress all normal output, redirect it to '/dev/null' (any error\n     messages will still be shown).\n\n'--srcdir=DIR'\n     Look for the package's source code in directory DIR.  Usually\n     'configure' can determine that directory automatically.\n\n'configure' also accepts some other, not widely useful, options.  Run\n'configure --help' for more details.\n"
        },
        {
          "name": "LICENSE.OpenSSL",
          "type": "blob",
          "size": 8.3427734375,
          "content": "/* \n * (c) 2002, 2003, 2004 by Jason McLaughlin and Riadh Elloumi\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation; either version 2 of the\n * License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful, but\n * is provided AS IS, WITHOUT ANY WARRANTY; without even the implied\n * warranty of MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, and\n * NON-INFRINGEMENT.  See the GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n * MA 02110-1301  USA.\n *\n * In addition, as a special exception, the copyright holders give\n * permission to link the code of portions of this program with the\n * OpenSSL library under certain conditions as described in each\n * individual source file, and distribute linked combinations\n * including the two.\n * You must obey the GNU General Public License in all respects\n * for all of the code used other than OpenSSL.  If you modify\n * file(s) with this exception, you may extend this exception to your\n * version of the file(s), but you are not obligated to do so.  If you\n * do not wish to do so, delete this exception statement from your\n * version.  If you delete this exception statement from all source\n * files in the program, then also delete it here.\n */\n\nCertain source files in this program permit linking with the OpenSSL\nlibrary (http://www.openssl.org), which otherwise wouldn't be allowed\nunder the GPL.  For purposes of identifying OpenSSL, most source files\ngiving this permission limit it to versions of OpenSSL having a license\nidentical to that listed in this file (LICENSE.OpenSSL).  It is not\nnecessary for the copyright years to match between this file and the\nOpenSSL version in question.  However, note that because this file is\nan extension of the license statements of these source files, this file\nmay not be changed except with permission from all copyright holders\nof source files in this program which reference this file.\n\n\n  LICENSE ISSUES\n  ==============\n\n  The OpenSSL toolkit stays under a dual license, i.e. both the conditions of\n  the OpenSSL License and the original SSLeay license apply to the toolkit.\n  See below for the actual license texts. Actually both licenses are BSD-style\n  Open Source licenses. In case of any license issues related to OpenSSL\n  please contact openssl-core@openssl.org.\n\n  OpenSSL License\n  ---------------\n\n/* ====================================================================\n * Copyright (c) 1998-2001 The OpenSSL Project.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer. \n *\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in\n *    the documentation and/or other materials provided with the\n *    distribution.\n *\n * 3. All advertising materials mentioning features or use of this\n *    software must display the following acknowledgment:\n *    \"This product includes software developed by the OpenSSL Project\n *    for use in the OpenSSL Toolkit. (http://www.openssl.org/)\"\n *\n * 4. The names \"OpenSSL Toolkit\" and \"OpenSSL Project\" must not be used to\n *    endorse or promote products derived from this software without\n *    prior written permission. For written permission, please contact\n *    openssl-core@openssl.org.\n *\n * 5. Products derived from this software may not be called \"OpenSSL\"\n *    nor may \"OpenSSL\" appear in their names without prior written\n *    permission of the OpenSSL Project.\n *\n * 6. Redistributions of any form whatsoever must retain the following\n *    acknowledgment:\n *    \"This product includes software developed by the OpenSSL Project\n *    for use in the OpenSSL Toolkit (http://www.openssl.org/)\"\n *\n * THIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT ``AS IS'' AND ANY\n * EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE OpenSSL PROJECT OR\n * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n * OF THE POSSIBILITY OF SUCH DAMAGE.\n * ====================================================================\n *\n * This product includes cryptographic software written by Eric Young\n * (eay@cryptsoft.com).  This product includes software written by Tim\n * Hudson (tjh@cryptsoft.com).\n *\n */\n\n Original SSLeay License\n -----------------------\n\n/* Copyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)\n * All rights reserved.\n *\n * This package is an SSL implementation written\n * by Eric Young (eay@cryptsoft.com).\n * The implementation was written so as to conform with Netscapes SSL.\n * \n * This library is free for commercial and non-commercial use as long as\n * the following conditions are aheared to.  The following conditions\n * apply to all code found in this distribution, be it the RC4, RSA,\n * lhash, DES, etc., code; not just the SSL code.  The SSL documentation\n * included with this distribution is covered by the same copyright terms\n * except that the holder is Tim Hudson (tjh@cryptsoft.com).\n * \n * Copyright remains Eric Young's, and as such any Copyright notices in\n * the code are not to be removed.\n * If this package is used in a product, Eric Young should be given attribution\n * as the author of the parts of the library used.\n * This can be in the form of a textual message at program startup or\n * in documentation (online or textual) provided with the package.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. All advertising materials mentioning features or use of this software\n *    must display the following acknowledgement:\n *    \"This product includes cryptographic software written by\n *     Eric Young (eay@cryptsoft.com)\"\n *    The word 'cryptographic' can be left out if the rouines from the library\n *    being used are not cryptographic related :-).\n * 4. If you include any Windows specific code (or a derivative thereof) from \n *    the apps directory (application code) you must include an acknowledgement:\n *    \"This product includes software written by Tim Hudson (tjh@cryptsoft.com)\"\n * \n * THIS SOFTWARE IS PROVIDED BY ERIC YOUNG ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n * \n * The licence and distribution terms for any publically available version or\n * derivative of this code cannot be changed.  i.e. this code cannot simply be\n * copied and put under another distribution licence\n * [including the GNU Public Licence.]\n */\n"
        },
        {
          "name": "META",
          "type": "blob",
          "size": 0.890625,
          "content": "##\n# Metadata for RPM/TAR makefile targets\n##\n# See src/api/Makefile.am for guidance on setting API_ values\n##\n  Meta:\t\t1\n  Name:\t\tslurm\n  Major:\t25\n  Minor:\t05\n  Micro:\t0\n  Version:\t25.05.0\n  Release:\t0rc1\n\n##\n#  When making a new Major/Minor version update\n#  src/common/slurm_protocol_common.h\n#  with a new SLURM_PROTOCOL_VERSION signifing the old one and the version\n#  it was so the slurmdbd can continue to send the old protocol version.\n#\n#  NOTE: The API version can not be the same as the Slurm version above.  The\n#        version in the code is referenced as a uint16_t which if 1403 was the\n#        API_CURRENT it would go over the limit.  So keep is a relatively\n#        small number.\n#\n#  NOTE: The values below are used to set up environment variables in\n#        the config.h file that may be used throughout Slurm, so don't remove\n#\t them.\n##\n  API_CURRENT:\t43\n  API_AGE:\t0\n  API_REVISION:\t0\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 1.2763671875,
          "content": "\nAUTOMAKE_OPTIONS = foreign\nACLOCAL_AMFLAGS = -I auxdir\nSUBDIRS    = auxdir src testsuite doc etc\n\npkginclude_HEADERS =\t\t\\\n\tslurm/pmi.h\t\t\\\n\tslurm/slurm.h \t\t\\\n\tslurm/slurmdb.h \t\\\n\tslurm/slurm_errno.h\t\\\n\tslurm/slurm_version.h\t\\\n\tslurm/spank.h\n\nMAINTAINERCLEANFILES = \t\t\t\t\t\\\n\taclocal.m4 config.guess\t\t\t\t\\\n\tconfig.h.in config.sub configure install-sh \t\\\n\tltconfig ltmain.sh missing mkinstalldirs \t\\\n\tslurm/slurm_version.h\t\t\t\t\\\n\tstamp-h.in\n\nCONFIG_CLEAN_FILES = \"\"\n\n# Cleanup contribs with distclean/mrproper\ndistclean-contrib:\n\t@cd contribs && \\\n\t$(MAKE) distclean && \\\n\tcd ..;\n\ndistclean-local: distclean-contrib\n\t-(cd $(top_srcdir) && rm -rf autom4te*.cache autoscan.*)\n\t-(cd $(top_srcdir) && rm -rf $(PACKAGE)-*)\n\nmrproper: distclean-local clean\n\t-(cd $(top_srcdir) && rm -rf autom4te.cache config.h config.log)\n\t-(cd $(top_srcdir) && rm -rf config.status libtool stamp-h1)\n\t-(cd $(top_srcdir)/auxdir && rm -rf mkinstalldirs)\n\t-(cd $(top_srcdir)/slurm  && rm -rf stamp-h2 slurm_version.h)\n\t-find $(top_srcdir)/src -name \"Makefile\" -exec rm {} \\;\n\t-find $(top_srcdir) -depth -name \".deps\" -exec rm -rf {} \\;\n\ncontrib:\n\t@cd contribs && \\\n\t$(MAKE) && \\\n\tcd ..;\n\n\ninstall-contrib:\n\t@cd contribs && \\\n\t$(MAKE) DESTDIR=$(DESTDIR) install && \\\n\tcd ..;\n\nclean-contrib:\n\t@cd contribs && \\\n\t$(MAKE) clean && \\\n\tcd ..;\n"
        },
        {
          "name": "Makefile.in",
          "type": "blob",
          "size": 26.2548828125,
          "content": "# Makefile.in generated by automake 1.16.5 from Makefile.am.\n# @configure_input@\n\n# Copyright (C) 1994-2021 Free Software Foundation, Inc.\n\n# This Makefile.in is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY, to the extent permitted by law; without\n# even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n# PARTICULAR PURPOSE.\n\n@SET_MAKE@\n\nVPATH = @srcdir@\nam__is_gnu_make = { \\\n  if test -z '$(MAKELEVEL)'; then \\\n    false; \\\n  elif test -n '$(MAKE_HOST)'; then \\\n    true; \\\n  elif test -n '$(MAKE_VERSION)' && test -n '$(CURDIR)'; then \\\n    true; \\\n  else \\\n    false; \\\n  fi; \\\n}\nam__make_running_with_option = \\\n  case $${target_option-} in \\\n      ?) ;; \\\n      *) echo \"am__make_running_with_option: internal error: invalid\" \\\n              \"target option '$${target_option-}' specified\" >&2; \\\n         exit 1;; \\\n  esac; \\\n  has_opt=no; \\\n  sane_makeflags=$$MAKEFLAGS; \\\n  if $(am__is_gnu_make); then \\\n    sane_makeflags=$$MFLAGS; \\\n  else \\\n    case $$MAKEFLAGS in \\\n      *\\\\[\\ \\\t]*) \\\n        bs=\\\\; \\\n        sane_makeflags=`printf '%s\\n' \"$$MAKEFLAGS\" \\\n          | sed \"s/$$bs$$bs[$$bs $$bs\t]*//g\"`;; \\\n    esac; \\\n  fi; \\\n  skip_next=no; \\\n  strip_trailopt () \\\n  { \\\n    flg=`printf '%s\\n' \"$$flg\" | sed \"s/$$1.*$$//\"`; \\\n  }; \\\n  for flg in $$sane_makeflags; do \\\n    test $$skip_next = yes && { skip_next=no; continue; }; \\\n    case $$flg in \\\n      *=*|--*) continue;; \\\n        -*I) strip_trailopt 'I'; skip_next=yes;; \\\n      -*I?*) strip_trailopt 'I';; \\\n        -*O) strip_trailopt 'O'; skip_next=yes;; \\\n      -*O?*) strip_trailopt 'O';; \\\n        -*l) strip_trailopt 'l'; skip_next=yes;; \\\n      -*l?*) strip_trailopt 'l';; \\\n      -[dEDm]) skip_next=yes;; \\\n      -[JT]) skip_next=yes;; \\\n    esac; \\\n    case $$flg in \\\n      *$$target_option*) has_opt=yes; break;; \\\n    esac; \\\n  done; \\\n  test $$has_opt = yes\nam__make_dryrun = (target_option=n; $(am__make_running_with_option))\nam__make_keepgoing = (target_option=k; $(am__make_running_with_option))\npkgdatadir = $(datadir)/@PACKAGE@\npkgincludedir = $(includedir)/@PACKAGE@\npkglibdir = $(libdir)/@PACKAGE@\npkglibexecdir = $(libexecdir)/@PACKAGE@\nam__cd = CDPATH=\"$${ZSH_VERSION+.}$(PATH_SEPARATOR)\" && cd\ninstall_sh_DATA = $(install_sh) -c -m 644\ninstall_sh_PROGRAM = $(install_sh) -c\ninstall_sh_SCRIPT = $(install_sh) -c\nINSTALL_HEADER = $(INSTALL_DATA)\ntransform = $(program_transform_name)\nNORMAL_INSTALL = :\nPRE_INSTALL = :\nPOST_INSTALL = :\nNORMAL_UNINSTALL = :\nPRE_UNINSTALL = :\nPOST_UNINSTALL = :\nbuild_triplet = @build@\nhost_triplet = @host@\ntarget_triplet = @target@\nsubdir = .\nACLOCAL_M4 = $(top_srcdir)/aclocal.m4\nam__aclocal_m4_deps = $(top_srcdir)/auxdir/ax_check_compile_flag.m4 \\\n\t$(top_srcdir)/auxdir/ax_compare_version.m4 \\\n\t$(top_srcdir)/auxdir/ax_gcc_builtin.m4 \\\n\t$(top_srcdir)/auxdir/ax_have_epoll.m4 \\\n\t$(top_srcdir)/auxdir/ax_lib_hdf5.m4 \\\n\t$(top_srcdir)/auxdir/ax_pthread.m4 \\\n\t$(top_srcdir)/auxdir/gtk-2.0.m4 \\\n\t$(top_srcdir)/auxdir/libtool.m4 \\\n\t$(top_srcdir)/auxdir/ltoptions.m4 \\\n\t$(top_srcdir)/auxdir/ltsugar.m4 \\\n\t$(top_srcdir)/auxdir/ltversion.m4 \\\n\t$(top_srcdir)/auxdir/lt~obsolete.m4 \\\n\t$(top_srcdir)/auxdir/slurm.m4 \\\n\t$(top_srcdir)/auxdir/slurmrestd.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_affinity.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_c99.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_cgroup.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_curl.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_databases.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_debug.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_deprecated.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_env.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_freeipmi.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_hpe_slingshot.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_http_parser.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_hwloc.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_json.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_jwt.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_lua.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_lz4.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_man2html.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_munge.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_nvml.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ofed.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_oneapi.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_pam.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_pkgconfig.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_pmix.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_printf_null.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ptrace.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_rdkafka.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_readline.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_rsmi.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_s2n.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_selinux.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_setproctitle.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_sview.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_systemd.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ucx.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_uid_gid_size.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_x11.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_yaml.m4 $(top_srcdir)/configure.ac\nam__configure_deps = $(am__aclocal_m4_deps) $(CONFIGURE_DEPENDENCIES) \\\n\t$(ACLOCAL_M4)\nDIST_COMMON = $(srcdir)/Makefile.am $(top_srcdir)/configure \\\n\t$(am__configure_deps) $(pkginclude_HEADERS)\nam__CONFIG_DISTCLEAN_FILES = config.status config.cache config.log \\\n configure.lineno config.status.lineno\nmkinstalldirs = $(install_sh) -d\nCONFIG_HEADER = config.h $(top_builddir)/slurm/slurm_version.h\nCONFIG_CLEAN_VPATH_FILES =\nAM_V_P = $(am__v_P_@AM_V@)\nam__v_P_ = $(am__v_P_@AM_DEFAULT_V@)\nam__v_P_0 = false\nam__v_P_1 = :\nAM_V_GEN = $(am__v_GEN_@AM_V@)\nam__v_GEN_ = $(am__v_GEN_@AM_DEFAULT_V@)\nam__v_GEN_0 = @echo \"  GEN     \" $@;\nam__v_GEN_1 = \nAM_V_at = $(am__v_at_@AM_V@)\nam__v_at_ = $(am__v_at_@AM_DEFAULT_V@)\nam__v_at_0 = @\nam__v_at_1 = \nSOURCES =\nRECURSIVE_TARGETS = all-recursive check-recursive cscopelist-recursive \\\n\tctags-recursive dvi-recursive html-recursive info-recursive \\\n\tinstall-data-recursive install-dvi-recursive \\\n\tinstall-exec-recursive install-html-recursive \\\n\tinstall-info-recursive install-pdf-recursive \\\n\tinstall-ps-recursive install-recursive installcheck-recursive \\\n\tinstalldirs-recursive pdf-recursive ps-recursive \\\n\ttags-recursive uninstall-recursive\nam__can_run_installinfo = \\\n  case $$AM_UPDATE_INFO_DIR in \\\n    n|no|NO) false;; \\\n    *) (install-info --version) >/dev/null 2>&1;; \\\n  esac\nam__vpath_adj_setup = srcdirstrip=`echo \"$(srcdir)\" | sed 's|.|.|g'`;\nam__vpath_adj = case $$p in \\\n    $(srcdir)/*) f=`echo \"$$p\" | sed \"s|^$$srcdirstrip/||\"`;; \\\n    *) f=$$p;; \\\n  esac;\nam__strip_dir = f=`echo $$p | sed -e 's|^.*/||'`;\nam__install_max = 40\nam__nobase_strip_setup = \\\n  srcdirstrip=`echo \"$(srcdir)\" | sed 's/[].[^$$\\\\*|]/\\\\\\\\&/g'`\nam__nobase_strip = \\\n  for p in $$list; do echo \"$$p\"; done | sed -e \"s|$$srcdirstrip/||\"\nam__nobase_list = $(am__nobase_strip_setup); \\\n  for p in $$list; do echo \"$$p $$p\"; done | \\\n  sed \"s| $$srcdirstrip/| |;\"' / .*\\//!s/ .*/ ./; s,\\( .*\\)/[^/]*$$,\\1,' | \\\n  $(AWK) 'BEGIN { files[\".\"] = \"\" } { files[$$2] = files[$$2] \" \" $$1; \\\n    if (++n[$$2] == $(am__install_max)) \\\n      { print $$2, files[$$2]; n[$$2] = 0; files[$$2] = \"\" } } \\\n    END { for (dir in files) print dir, files[dir] }'\nam__base_list = \\\n  sed '$$!N;$$!N;$$!N;$$!N;$$!N;$$!N;$$!N;s/\\n/ /g' | \\\n  sed '$$!N;$$!N;$$!N;$$!N;s/\\n/ /g'\nam__uninstall_files_from_dir = { \\\n  test -z \"$$files\" \\\n    || { test ! -d \"$$dir\" && test ! -f \"$$dir\" && test ! -r \"$$dir\"; } \\\n    || { echo \" ( cd '$$dir' && rm -f\" $$files \")\"; \\\n         $(am__cd) \"$$dir\" && rm -f $$files; }; \\\n  }\nam__installdirs = \"$(DESTDIR)$(pkgincludedir)\"\nHEADERS = $(pkginclude_HEADERS)\nRECURSIVE_CLEAN_TARGETS = mostlyclean-recursive clean-recursive\t\\\n  distclean-recursive maintainer-clean-recursive\nam__recursive_targets = \\\n  $(RECURSIVE_TARGETS) \\\n  $(RECURSIVE_CLEAN_TARGETS) \\\n  $(am__extra_recursive_targets)\nAM_RECURSIVE_TARGETS = $(am__recursive_targets:-recursive=) TAGS CTAGS \\\n\tcscope\nam__tagged_files = $(HEADERS) $(SOURCES) $(TAGS_FILES) $(LISP) \\\n\tconfig.h.in\n# Read a list of newline-separated strings from the standard input,\n# and print each of them once, without duplicates.  Input order is\n# *not* preserved.\nam__uniquify_input = $(AWK) '\\\n  BEGIN { nonempty = 0; } \\\n  { items[$$0] = 1; nonempty = 1; } \\\n  END { if (nonempty) { for (i in items) print i; }; } \\\n'\n# Make sure the list of sources is unique.  This is necessary because,\n# e.g., the same source file might be shared among _SOURCES variables\n# for different programs/libraries.\nam__define_uniq_tagged_files = \\\n  list='$(am__tagged_files)'; \\\n  unique=`for i in $$list; do \\\n    if test -f \"$$i\"; then echo $$i; else echo $(srcdir)/$$i; fi; \\\n  done | $(am__uniquify_input)`\nDIST_SUBDIRS = $(SUBDIRS)\nACLOCAL = @ACLOCAL@\nAMTAR = @AMTAR@\nAM_DEFAULT_VERBOSITY = @AM_DEFAULT_VERBOSITY@\nAR = @AR@\nAR_FLAGS = @AR_FLAGS@\nAUTOCONF = @AUTOCONF@\nAUTOHEADER = @AUTOHEADER@\nAUTOMAKE = @AUTOMAKE@\nAWK = @AWK@\nBPF_CPPFLAGS = @BPF_CPPFLAGS@\nCC = @CC@\nCCDEPMODE = @CCDEPMODE@\nCFLAGS = @CFLAGS@\nCHECK_CFLAGS = @CHECK_CFLAGS@\nCHECK_LIBS = @CHECK_LIBS@\nCPP = @CPP@\nCPPFLAGS = @CPPFLAGS@\nCSCOPE = @CSCOPE@\nCTAGS = @CTAGS@\nCXX = @CXX@\nCXXCPP = @CXXCPP@\nCXXDEPMODE = @CXXDEPMODE@\nCXXFLAGS = @CXXFLAGS@\nCYGPATH_W = @CYGPATH_W@\nDEFS = @DEFS@\nDEPDIR = @DEPDIR@\nDLLTOOL = @DLLTOOL@\nDSYMUTIL = @DSYMUTIL@\nDUMPBIN = @DUMPBIN@\nECHO_C = @ECHO_C@\nECHO_N = @ECHO_N@\nECHO_T = @ECHO_T@\nEGREP = @EGREP@\nETAGS = @ETAGS@\nEXEEXT = @EXEEXT@\nFGREP = @FGREP@\nFILECMD = @FILECMD@\nFREEIPMI_CPPFLAGS = @FREEIPMI_CPPFLAGS@\nFREEIPMI_LDFLAGS = @FREEIPMI_LDFLAGS@\nFREEIPMI_LIBS = @FREEIPMI_LIBS@\nGLIB_CFLAGS = @GLIB_CFLAGS@\nGLIB_COMPILE_RESOURCES = @GLIB_COMPILE_RESOURCES@\nGLIB_GENMARSHAL = @GLIB_GENMARSHAL@\nGLIB_LIBS = @GLIB_LIBS@\nGLIB_MKENUMS = @GLIB_MKENUMS@\nGOBJECT_QUERY = @GOBJECT_QUERY@\nGREP = @GREP@\nGTK_CFLAGS = @GTK_CFLAGS@\nGTK_LIBS = @GTK_LIBS@\nH5CC = @H5CC@\nH5FC = @H5FC@\nHAVEMYSQLCONFIG = @HAVEMYSQLCONFIG@\nHAVE_MAN2HTML = @HAVE_MAN2HTML@\nHDF5_CC = @HDF5_CC@\nHDF5_CFLAGS = @HDF5_CFLAGS@\nHDF5_CPPFLAGS = @HDF5_CPPFLAGS@\nHDF5_FC = @HDF5_FC@\nHDF5_FFLAGS = @HDF5_FFLAGS@\nHDF5_FLIBS = @HDF5_FLIBS@\nHDF5_LDFLAGS = @HDF5_LDFLAGS@\nHDF5_LIBS = @HDF5_LIBS@\nHDF5_TYPE = @HDF5_TYPE@\nHDF5_VERSION = @HDF5_VERSION@\nHPE_SLINGSHOT_CFLAGS = @HPE_SLINGSHOT_CFLAGS@\nHTTP_PARSER_CPPFLAGS = @HTTP_PARSER_CPPFLAGS@\nHTTP_PARSER_LDFLAGS = @HTTP_PARSER_LDFLAGS@\nHWLOC_CPPFLAGS = @HWLOC_CPPFLAGS@\nHWLOC_LDFLAGS = @HWLOC_LDFLAGS@\nHWLOC_LIBS = @HWLOC_LIBS@\nINSTALL = @INSTALL@\nINSTALL_DATA = @INSTALL_DATA@\nINSTALL_PROGRAM = @INSTALL_PROGRAM@\nINSTALL_SCRIPT = @INSTALL_SCRIPT@\nINSTALL_STRIP_PROGRAM = @INSTALL_STRIP_PROGRAM@\nJSON_CPPFLAGS = @JSON_CPPFLAGS@\nJSON_LDFLAGS = @JSON_LDFLAGS@\nJWT_CPPFLAGS = @JWT_CPPFLAGS@\nJWT_LDFLAGS = @JWT_LDFLAGS@\nLD = @LD@\nLDFLAGS = @LDFLAGS@\nLIBCURL = @LIBCURL@\nLIBCURL_CPPFLAGS = @LIBCURL_CPPFLAGS@\nLIBOBJS = @LIBOBJS@\nLIBS = @LIBS@\nLIBTOOL = @LIBTOOL@\nLIB_SLURM = @LIB_SLURM@\nLIB_SLURM_BUILD = @LIB_SLURM_BUILD@\nLIPO = @LIPO@\nLN_S = @LN_S@\nLTLIBOBJS = @LTLIBOBJS@\nLT_SYS_LIBRARY_PATH = @LT_SYS_LIBRARY_PATH@\nLZ4_CPPFLAGS = @LZ4_CPPFLAGS@\nLZ4_LDFLAGS = @LZ4_LDFLAGS@\nLZ4_LIBS = @LZ4_LIBS@\nMAINT = @MAINT@\nMAKEINFO = @MAKEINFO@\nMANIFEST_TOOL = @MANIFEST_TOOL@\nMKDIR_P = @MKDIR_P@\nMUNGE_CPPFLAGS = @MUNGE_CPPFLAGS@\nMUNGE_DIR = @MUNGE_DIR@\nMUNGE_LDFLAGS = @MUNGE_LDFLAGS@\nMUNGE_LIBS = @MUNGE_LIBS@\nMYSQL_CFLAGS = @MYSQL_CFLAGS@\nMYSQL_LIBS = @MYSQL_LIBS@\nNM = @NM@\nNMEDIT = @NMEDIT@\nNUMA_LIBS = @NUMA_LIBS@\nNVML_CPPFLAGS = @NVML_CPPFLAGS@\nOBJCOPY = @OBJCOPY@\nOBJDUMP = @OBJDUMP@\nOBJEXT = @OBJEXT@\nOFED_CPPFLAGS = @OFED_CPPFLAGS@\nOFED_LDFLAGS = @OFED_LDFLAGS@\nOFED_LIBS = @OFED_LIBS@\nONEAPI_CPPFLAGS = @ONEAPI_CPPFLAGS@\nOTOOL = @OTOOL@\nOTOOL64 = @OTOOL64@\nPACKAGE = @PACKAGE@\nPACKAGE_BUGREPORT = @PACKAGE_BUGREPORT@\nPACKAGE_NAME = @PACKAGE_NAME@\nPACKAGE_STRING = @PACKAGE_STRING@\nPACKAGE_TARNAME = @PACKAGE_TARNAME@\nPACKAGE_URL = @PACKAGE_URL@\nPACKAGE_VERSION = @PACKAGE_VERSION@\nPAM_DIR = @PAM_DIR@\nPAM_LIBS = @PAM_LIBS@\nPATH_SEPARATOR = @PATH_SEPARATOR@\nPKG_CONFIG = @PKG_CONFIG@\nPKG_CONFIG_LIBDIR = @PKG_CONFIG_LIBDIR@\nPKG_CONFIG_PATH = @PKG_CONFIG_PATH@\nPMIX_V2_CPPFLAGS = @PMIX_V2_CPPFLAGS@\nPMIX_V2_LDFLAGS = @PMIX_V2_LDFLAGS@\nPMIX_V3_CPPFLAGS = @PMIX_V3_CPPFLAGS@\nPMIX_V3_LDFLAGS = @PMIX_V3_LDFLAGS@\nPMIX_V4_CPPFLAGS = @PMIX_V4_CPPFLAGS@\nPMIX_V4_LDFLAGS = @PMIX_V4_LDFLAGS@\nPMIX_V5_CPPFLAGS = @PMIX_V5_CPPFLAGS@\nPMIX_V5_LDFLAGS = @PMIX_V5_LDFLAGS@\nPROJECT = @PROJECT@\nPTHREAD_CC = @PTHREAD_CC@\nPTHREAD_CFLAGS = @PTHREAD_CFLAGS@\nPTHREAD_CXX = @PTHREAD_CXX@\nPTHREAD_LIBS = @PTHREAD_LIBS@\nRANLIB = @RANLIB@\nRDKAFKA_CPPFLAGS = @RDKAFKA_CPPFLAGS@\nRDKAFKA_LDFLAGS = @RDKAFKA_LDFLAGS@\nRDKAFKA_LIBS = @RDKAFKA_LIBS@\nREADLINE_LIBS = @READLINE_LIBS@\nRELEASE = @RELEASE@\nRSMI_CPPFLAGS = @RSMI_CPPFLAGS@\nS2N_CPPFLAGS = @S2N_CPPFLAGS@\nS2N_DIR = @S2N_DIR@\nS2N_LDFLAGS = @S2N_LDFLAGS@\nS2N_LIBS = @S2N_LIBS@\nSED = @SED@\nSET_MAKE = @SET_MAKE@\nSHELL = @SHELL@\nSLEEP_CMD = @SLEEP_CMD@\nSLURMCTLD_INTERFACES = @SLURMCTLD_INTERFACES@\nSLURMCTLD_PORT = @SLURMCTLD_PORT@\nSLURMCTLD_PORT_COUNT = @SLURMCTLD_PORT_COUNT@\nSLURMDBD_PORT = @SLURMDBD_PORT@\nSLURMD_INTERFACES = @SLURMD_INTERFACES@\nSLURMD_PORT = @SLURMD_PORT@\nSLURMRESTD_PORT = @SLURMRESTD_PORT@\nSLURM_API_AGE = @SLURM_API_AGE@\nSLURM_API_CURRENT = @SLURM_API_CURRENT@\nSLURM_API_MAJOR = @SLURM_API_MAJOR@\nSLURM_API_REVISION = @SLURM_API_REVISION@\nSLURM_API_VERSION = @SLURM_API_VERSION@\nSLURM_MAJOR = @SLURM_MAJOR@\nSLURM_MICRO = @SLURM_MICRO@\nSLURM_MINOR = @SLURM_MINOR@\nSLURM_PREFIX = @SLURM_PREFIX@\nSLURM_VERSION_NUMBER = @SLURM_VERSION_NUMBER@\nSLURM_VERSION_STRING = @SLURM_VERSION_STRING@\nSTRIP = @STRIP@\nSUCMD = @SUCMD@\nSYSTEMD_TASKSMAX_OPTION = @SYSTEMD_TASKSMAX_OPTION@\nUCX_CPPFLAGS = @UCX_CPPFLAGS@\nUCX_LDFLAGS = @UCX_LDFLAGS@\nUCX_LIBS = @UCX_LIBS@\nUTIL_LIBS = @UTIL_LIBS@\nVERSION = @VERSION@\nYAML_CPPFLAGS = @YAML_CPPFLAGS@\nYAML_LDFLAGS = @YAML_LDFLAGS@\n_libcurl_config = @_libcurl_config@\nabs_builddir = @abs_builddir@\nabs_srcdir = @abs_srcdir@\nabs_top_builddir = @abs_top_builddir@\nabs_top_srcdir = @abs_top_srcdir@\nac_ct_AR = @ac_ct_AR@\nac_ct_CC = @ac_ct_CC@\nac_ct_CXX = @ac_ct_CXX@\nac_ct_DUMPBIN = @ac_ct_DUMPBIN@\nac_have_man2html = @ac_have_man2html@\nam__include = @am__include@\nam__leading_dot = @am__leading_dot@\nam__quote = @am__quote@\nam__tar = @am__tar@\nam__untar = @am__untar@\nax_pthread_config = @ax_pthread_config@\nbindir = @bindir@\nbuild = @build@\nbuild_alias = @build_alias@\nbuild_cpu = @build_cpu@\nbuild_os = @build_os@\nbuild_vendor = @build_vendor@\nbuilddir = @builddir@\ndatadir = @datadir@\ndatarootdir = @datarootdir@\ndbus_CFLAGS = @dbus_CFLAGS@\ndbus_LIBS = @dbus_LIBS@\ndocdir = @docdir@\ndvidir = @dvidir@\nexec_prefix = @exec_prefix@\nhost = @host@\nhost_alias = @host_alias@\nhost_cpu = @host_cpu@\nhost_os = @host_os@\nhost_vendor = @host_vendor@\nhtmldir = @htmldir@\nincludedir = @includedir@\ninfodir = @infodir@\ninstall_sh = @install_sh@\nlibdir = @libdir@\nlibexecdir = @libexecdir@\nlibselinux_CFLAGS = @libselinux_CFLAGS@\nlibselinux_LIBS = @libselinux_LIBS@\nlocaledir = @localedir@\nlocalstatedir = @localstatedir@\nlua_CFLAGS = @lua_CFLAGS@\nlua_LIBS = @lua_LIBS@\nmandir = @mandir@\nmkdir_p = @mkdir_p@\noldincludedir = @oldincludedir@\npdfdir = @pdfdir@\npkgconfigdir = @pkgconfigdir@\nprefix = @prefix@\nprogram_transform_name = @program_transform_name@\npsdir = @psdir@\nrunstatedir = @runstatedir@\nsbindir = @sbindir@\nsharedstatedir = @sharedstatedir@\nsrcdir = @srcdir@\nsysconfdir = @sysconfdir@\nsystemdsystemunitdir = @systemdsystemunitdir@\ntarget = @target@\ntarget_alias = @target_alias@\ntarget_cpu = @target_cpu@\ntarget_os = @target_os@\ntarget_vendor = @target_vendor@\ntop_build_prefix = @top_build_prefix@\ntop_builddir = @top_builddir@\ntop_srcdir = @top_srcdir@\nAUTOMAKE_OPTIONS = foreign\nACLOCAL_AMFLAGS = -I auxdir\nSUBDIRS = auxdir src testsuite doc etc\npkginclude_HEADERS = \\\n\tslurm/pmi.h\t\t\\\n\tslurm/slurm.h \t\t\\\n\tslurm/slurmdb.h \t\\\n\tslurm/slurm_errno.h\t\\\n\tslurm/slurm_version.h\t\\\n\tslurm/spank.h\n\nMAINTAINERCLEANFILES = \\\n\taclocal.m4 config.guess\t\t\t\t\\\n\tconfig.h.in config.sub configure install-sh \t\\\n\tltconfig ltmain.sh missing mkinstalldirs \t\\\n\tslurm/slurm_version.h\t\t\t\t\\\n\tstamp-h.in\n\nCONFIG_CLEAN_FILES = \"\"\nall: config.h\n\t$(MAKE) $(AM_MAKEFLAGS) all-recursive\n\n.SUFFIXES:\nam--refresh: Makefile\n\t@:\n$(srcdir)/Makefile.in: @MAINTAINER_MODE_TRUE@ $(srcdir)/Makefile.am  $(am__configure_deps)\n\t@for dep in $?; do \\\n\t  case '$(am__configure_deps)' in \\\n\t    *$$dep*) \\\n\t      echo ' cd $(srcdir) && $(AUTOMAKE) --foreign'; \\\n\t      $(am__cd) $(srcdir) && $(AUTOMAKE) --foreign \\\n\t\t&& exit 0; \\\n\t      exit 1;; \\\n\t  esac; \\\n\tdone; \\\n\techo ' cd $(top_srcdir) && $(AUTOMAKE) --foreign Makefile'; \\\n\t$(am__cd) $(top_srcdir) && \\\n\t  $(AUTOMAKE) --foreign Makefile\nMakefile: $(srcdir)/Makefile.in $(top_builddir)/config.status\n\t@case '$?' in \\\n\t  *config.status*) \\\n\t    echo ' $(SHELL) ./config.status'; \\\n\t    $(SHELL) ./config.status;; \\\n\t  *) \\\n\t    echo ' cd $(top_builddir) && $(SHELL) ./config.status $@ $(am__maybe_remake_depfiles)'; \\\n\t    cd $(top_builddir) && $(SHELL) ./config.status $@ $(am__maybe_remake_depfiles);; \\\n\tesac;\n\n$(top_builddir)/config.status: $(top_srcdir)/configure $(CONFIG_STATUS_DEPENDENCIES)\n\t$(SHELL) ./config.status --recheck\n\n$(top_srcdir)/configure: @MAINTAINER_MODE_TRUE@ $(am__configure_deps)\n\t$(am__cd) $(srcdir) && $(AUTOCONF)\n$(ACLOCAL_M4): @MAINTAINER_MODE_TRUE@ $(am__aclocal_m4_deps)\n\t$(am__cd) $(srcdir) && $(ACLOCAL) $(ACLOCAL_AMFLAGS)\n$(am__aclocal_m4_deps):\n\nconfig.h: stamp-h1\n\t@test -f $@ || rm -f stamp-h1\n\t@test -f $@ || $(MAKE) $(AM_MAKEFLAGS) stamp-h1\n\nstamp-h1: $(srcdir)/config.h.in $(top_builddir)/config.status\n\t@rm -f stamp-h1\n\tcd $(top_builddir) && $(SHELL) ./config.status config.h\n$(srcdir)/config.h.in: @MAINTAINER_MODE_TRUE@ $(am__configure_deps) \n\t($(am__cd) $(top_srcdir) && $(AUTOHEADER))\n\trm -f stamp-h1\n\ttouch $@\n\nslurm/slurm_version.h: slurm/stamp-h2\n\t@test -f $@ || rm -f slurm/stamp-h2\n\t@test -f $@ || $(MAKE) $(AM_MAKEFLAGS) slurm/stamp-h2\n\nslurm/stamp-h2: $(top_srcdir)/slurm/slurm_version.h.in $(top_builddir)/config.status\n\t@rm -f slurm/stamp-h2\n\tcd $(top_builddir) && $(SHELL) ./config.status slurm/slurm_version.h\n\ndistclean-hdr:\n\t-rm -f config.h stamp-h1 slurm/slurm_version.h slurm/stamp-h2\ncontribs/perlapi/libslurm/perl/Makefile.PL: $(top_builddir)/config.status $(top_srcdir)/contribs/perlapi/libslurm/perl/Makefile.PL.in\n\tcd $(top_builddir) && $(SHELL) ./config.status $@\ncontribs/perlapi/libslurmdb/perl/Makefile.PL: $(top_builddir)/config.status $(top_srcdir)/contribs/perlapi/libslurmdb/perl/Makefile.PL.in\n\tcd $(top_builddir) && $(SHELL) ./config.status $@\n\nmostlyclean-libtool:\n\t-rm -f *.lo\n\nclean-libtool:\n\t-rm -rf .libs _libs\n\ndistclean-libtool:\n\t-rm -f libtool config.lt\ninstall-pkgincludeHEADERS: $(pkginclude_HEADERS)\n\t@$(NORMAL_INSTALL)\n\t@list='$(pkginclude_HEADERS)'; test -n \"$(pkgincludedir)\" || list=; \\\n\tif test -n \"$$list\"; then \\\n\t  echo \" $(MKDIR_P) '$(DESTDIR)$(pkgincludedir)'\"; \\\n\t  $(MKDIR_P) \"$(DESTDIR)$(pkgincludedir)\" || exit 1; \\\n\tfi; \\\n\tfor p in $$list; do \\\n\t  if test -f \"$$p\"; then d=; else d=\"$(srcdir)/\"; fi; \\\n\t  echo \"$$d$$p\"; \\\n\tdone | $(am__base_list) | \\\n\twhile read files; do \\\n\t  echo \" $(INSTALL_HEADER) $$files '$(DESTDIR)$(pkgincludedir)'\"; \\\n\t  $(INSTALL_HEADER) $$files \"$(DESTDIR)$(pkgincludedir)\" || exit $$?; \\\n\tdone\n\nuninstall-pkgincludeHEADERS:\n\t@$(NORMAL_UNINSTALL)\n\t@list='$(pkginclude_HEADERS)'; test -n \"$(pkgincludedir)\" || list=; \\\n\tfiles=`for p in $$list; do echo $$p; done | sed -e 's|^.*/||'`; \\\n\tdir='$(DESTDIR)$(pkgincludedir)'; $(am__uninstall_files_from_dir)\n\n# This directory's subdirectories are mostly independent; you can cd\n# into them and run 'make' without going through this Makefile.\n# To change the values of 'make' variables: instead of editing Makefiles,\n# (1) if the variable is set in 'config.status', edit 'config.status'\n#     (which will cause the Makefiles to be regenerated when you run 'make');\n# (2) otherwise, pass the desired values on the 'make' command line.\n$(am__recursive_targets):\n\t@fail=; \\\n\tif $(am__make_keepgoing); then \\\n\t  failcom='fail=yes'; \\\n\telse \\\n\t  failcom='exit 1'; \\\n\tfi; \\\n\tdot_seen=no; \\\n\ttarget=`echo $@ | sed s/-recursive//`; \\\n\tcase \"$@\" in \\\n\t  distclean-* | maintainer-clean-*) list='$(DIST_SUBDIRS)' ;; \\\n\t  *) list='$(SUBDIRS)' ;; \\\n\tesac; \\\n\tfor subdir in $$list; do \\\n\t  echo \"Making $$target in $$subdir\"; \\\n\t  if test \"$$subdir\" = \".\"; then \\\n\t    dot_seen=yes; \\\n\t    local_target=\"$$target-am\"; \\\n\t  else \\\n\t    local_target=\"$$target\"; \\\n\t  fi; \\\n\t  ($(am__cd) $$subdir && $(MAKE) $(AM_MAKEFLAGS) $$local_target) \\\n\t  || eval $$failcom; \\\n\tdone; \\\n\tif test \"$$dot_seen\" = \"no\"; then \\\n\t  $(MAKE) $(AM_MAKEFLAGS) \"$$target-am\" || exit 1; \\\n\tfi; test -z \"$$fail\"\n\nID: $(am__tagged_files)\n\t$(am__define_uniq_tagged_files); mkid -fID $$unique\ntags: tags-recursive\nTAGS: tags\n\ntags-am: $(TAGS_DEPENDENCIES) $(am__tagged_files)\n\tset x; \\\n\there=`pwd`; \\\n\tif ($(ETAGS) --etags-include --version) >/dev/null 2>&1; then \\\n\t  include_option=--etags-include; \\\n\t  empty_fix=.; \\\n\telse \\\n\t  include_option=--include; \\\n\t  empty_fix=; \\\n\tfi; \\\n\tlist='$(SUBDIRS)'; for subdir in $$list; do \\\n\t  if test \"$$subdir\" = .; then :; else \\\n\t    test ! -f $$subdir/TAGS || \\\n\t      set \"$$@\" \"$$include_option=$$here/$$subdir/TAGS\"; \\\n\t  fi; \\\n\tdone; \\\n\t$(am__define_uniq_tagged_files); \\\n\tshift; \\\n\tif test -z \"$(ETAGS_ARGS)$$*$$unique\"; then :; else \\\n\t  test -n \"$$unique\" || unique=$$empty_fix; \\\n\t  if test $$# -gt 0; then \\\n\t    $(ETAGS) $(ETAGSFLAGS) $(AM_ETAGSFLAGS) $(ETAGS_ARGS) \\\n\t      \"$$@\" $$unique; \\\n\t  else \\\n\t    $(ETAGS) $(ETAGSFLAGS) $(AM_ETAGSFLAGS) $(ETAGS_ARGS) \\\n\t      $$unique; \\\n\t  fi; \\\n\tfi\nctags: ctags-recursive\n\nCTAGS: ctags\nctags-am: $(TAGS_DEPENDENCIES) $(am__tagged_files)\n\t$(am__define_uniq_tagged_files); \\\n\ttest -z \"$(CTAGS_ARGS)$$unique\" \\\n\t  || $(CTAGS) $(CTAGSFLAGS) $(AM_CTAGSFLAGS) $(CTAGS_ARGS) \\\n\t     $$unique\n\nGTAGS:\n\there=`$(am__cd) $(top_builddir) && pwd` \\\n\t  && $(am__cd) $(top_srcdir) \\\n\t  && gtags -i $(GTAGS_ARGS) \"$$here\"\ncscope: cscope.files\n\ttest ! -s cscope.files \\\n\t  || $(CSCOPE) -b -q $(AM_CSCOPEFLAGS) $(CSCOPEFLAGS) -i cscope.files $(CSCOPE_ARGS)\nclean-cscope:\n\t-rm -f cscope.files\ncscope.files: clean-cscope cscopelist\ncscopelist: cscopelist-recursive\n\ncscopelist-am: $(am__tagged_files)\n\tlist='$(am__tagged_files)'; \\\n\tcase \"$(srcdir)\" in \\\n\t  [\\\\/]* | ?:[\\\\/]*) sdir=\"$(srcdir)\" ;; \\\n\t  *) sdir=$(subdir)/$(srcdir) ;; \\\n\tesac; \\\n\tfor i in $$list; do \\\n\t  if test -f \"$$i\"; then \\\n\t    echo \"$(subdir)/$$i\"; \\\n\t  else \\\n\t    echo \"$$sdir/$$i\"; \\\n\t  fi; \\\n\tdone >> $(top_builddir)/cscope.files\n\ndistclean-tags:\n\t-rm -f TAGS ID GTAGS GRTAGS GSYMS GPATH tags\n\t-rm -f cscope.out cscope.in.out cscope.po.out cscope.files\ncheck-am: all-am\ncheck: check-recursive\nall-am: Makefile $(HEADERS) config.h\ninstalldirs: installdirs-recursive\ninstalldirs-am:\n\tfor dir in \"$(DESTDIR)$(pkgincludedir)\"; do \\\n\t  test -z \"$$dir\" || $(MKDIR_P) \"$$dir\"; \\\n\tdone\ninstall: install-recursive\ninstall-exec: install-exec-recursive\ninstall-data: install-data-recursive\nuninstall: uninstall-recursive\n\ninstall-am: all-am\n\t@$(MAKE) $(AM_MAKEFLAGS) install-exec-am install-data-am\n\ninstallcheck: installcheck-recursive\ninstall-strip:\n\tif test -z '$(STRIP)'; then \\\n\t  $(MAKE) $(AM_MAKEFLAGS) INSTALL_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" \\\n\t    install_sh_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" INSTALL_STRIP_FLAG=-s \\\n\t      install; \\\n\telse \\\n\t  $(MAKE) $(AM_MAKEFLAGS) INSTALL_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" \\\n\t    install_sh_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" INSTALL_STRIP_FLAG=-s \\\n\t    \"INSTALL_PROGRAM_ENV=STRIPPROG='$(STRIP)'\" install; \\\n\tfi\nmostlyclean-generic:\n\nclean-generic:\n\ndistclean-generic:\n\t-test -z \"$(CONFIG_CLEAN_FILES)\" || rm -f $(CONFIG_CLEAN_FILES)\n\t-test . = \"$(srcdir)\" || test -z \"$(CONFIG_CLEAN_VPATH_FILES)\" || rm -f $(CONFIG_CLEAN_VPATH_FILES)\n\nmaintainer-clean-generic:\n\t@echo \"This command is intended for maintainers to use\"\n\t@echo \"it deletes files that may require special tools to rebuild.\"\n\t-test -z \"$(MAINTAINERCLEANFILES)\" || rm -f $(MAINTAINERCLEANFILES)\nclean: clean-recursive\n\nclean-am: clean-generic clean-libtool mostlyclean-am\n\ndistclean: distclean-recursive\n\t-rm -f $(am__CONFIG_DISTCLEAN_FILES)\n\t-rm -f Makefile\ndistclean-am: clean-am distclean-generic distclean-hdr \\\n\tdistclean-libtool distclean-local distclean-tags\n\ndvi: dvi-recursive\n\ndvi-am:\n\nhtml: html-recursive\n\nhtml-am:\n\ninfo: info-recursive\n\ninfo-am:\n\ninstall-data-am: install-pkgincludeHEADERS\n\ninstall-dvi: install-dvi-recursive\n\ninstall-dvi-am:\n\ninstall-exec-am:\n\ninstall-html: install-html-recursive\n\ninstall-html-am:\n\ninstall-info: install-info-recursive\n\ninstall-info-am:\n\ninstall-man:\n\ninstall-pdf: install-pdf-recursive\n\ninstall-pdf-am:\n\ninstall-ps: install-ps-recursive\n\ninstall-ps-am:\n\ninstallcheck-am:\n\nmaintainer-clean: maintainer-clean-recursive\n\t-rm -f $(am__CONFIG_DISTCLEAN_FILES)\n\t-rm -rf $(top_srcdir)/autom4te.cache\n\t-rm -f Makefile\nmaintainer-clean-am: distclean-am maintainer-clean-generic\n\nmostlyclean: mostlyclean-recursive\n\nmostlyclean-am: mostlyclean-generic mostlyclean-libtool\n\npdf: pdf-recursive\n\npdf-am:\n\nps: ps-recursive\n\nps-am:\n\nuninstall-am: uninstall-pkgincludeHEADERS\n\n.MAKE: $(am__recursive_targets) all install-am install-strip\n\n.PHONY: $(am__recursive_targets) CTAGS GTAGS TAGS all all-am \\\n\tam--refresh check check-am clean clean-cscope clean-generic \\\n\tclean-libtool cscope cscopelist-am ctags ctags-am distclean \\\n\tdistclean-generic distclean-hdr distclean-libtool \\\n\tdistclean-local distclean-tags dvi dvi-am html html-am info \\\n\tinfo-am install install-am install-data install-data-am \\\n\tinstall-dvi install-dvi-am install-exec install-exec-am \\\n\tinstall-html install-html-am install-info install-info-am \\\n\tinstall-man install-pdf install-pdf-am \\\n\tinstall-pkgincludeHEADERS install-ps install-ps-am \\\n\tinstall-strip installcheck installcheck-am installdirs \\\n\tinstalldirs-am maintainer-clean maintainer-clean-generic \\\n\tmostlyclean mostlyclean-generic mostlyclean-libtool pdf pdf-am \\\n\tps ps-am tags tags-am uninstall uninstall-am \\\n\tuninstall-pkgincludeHEADERS\n\n.PRECIOUS: Makefile\n\n\n# Cleanup contribs with distclean/mrproper\ndistclean-contrib:\n\t@cd contribs && \\\n\t$(MAKE) distclean && \\\n\tcd ..;\n\ndistclean-local: distclean-contrib\n\t-(cd $(top_srcdir) && rm -rf autom4te*.cache autoscan.*)\n\t-(cd $(top_srcdir) && rm -rf $(PACKAGE)-*)\n\nmrproper: distclean-local clean\n\t-(cd $(top_srcdir) && rm -rf autom4te.cache config.h config.log)\n\t-(cd $(top_srcdir) && rm -rf config.status libtool stamp-h1)\n\t-(cd $(top_srcdir)/auxdir && rm -rf mkinstalldirs)\n\t-(cd $(top_srcdir)/slurm  && rm -rf stamp-h2 slurm_version.h)\n\t-find $(top_srcdir)/src -name \"Makefile\" -exec rm {} \\;\n\t-find $(top_srcdir) -depth -name \".deps\" -exec rm -rf {} \\;\n\ncontrib:\n\t@cd contribs && \\\n\t$(MAKE) && \\\n\tcd ..;\n\ninstall-contrib:\n\t@cd contribs && \\\n\t$(MAKE) DESTDIR=$(DESTDIR) install && \\\n\tcd ..;\n\nclean-contrib:\n\t@cd contribs && \\\n\t$(MAKE) clean && \\\n\tcd ..;\n\n# Tell versions [3.59,3.63) of GNU make to not export all variables.\n# Otherwise a system limit (for SysV at least) may be exceeded.\n.NOEXPORT:\n"
        },
        {
          "name": "NEWS",
          "type": "blob",
          "size": 888.2685546875,
          "content": "This file describes changes in recent versions of Slurm. It primarily\ndocuments those changes that are of interest to users and administrators.\n\n* Changes in Slurm 25.05.0rc1\n=============================\n\n* Changes in Slurm 24.11.1\n==========================\n -- With client commands MIN_MEMORY will show mem_per_tres if specified.\n\n* Changes in Slurm 24.11.0\n==========================\n -- slurmctld - Reject arbitrary distribution jobs that do not specifying a task\n    count.\n -- Fix backwards compatibility of the RESPONSE_JOB_INFO RPC (used by squeue,\n    scontrol show job, etc.) with Slurm clients version 24.05 and below. This\n    was a regression in 24.11.0rc1.\n -- Do not let slurmctld/slurmd to start if there are more nodes defined in\n    slurm.conf than the maximum supported amount (64k nodes).\n -- slurmctld - Set job's exit code to 1 when a job fails with state\n    JOB_NODE_FAIL. This fixes \"sbatch --wait\" not being able to exit with error\n    code when a job fails for this reason in some cases.\n -- Fix certain reservation updates requested from 23.02 clients.\n -- slurmrestd - Fix populating non-required object fields of objects as '{}' in\n    JSON/YAML instead of 'null' causing compiled OpenAPI clients to reject\n    the response to 'GET /slurm/v0.0.40/jobs' due to validation failure of\n    '.jobs[].job_resources'.\n -- Fix issue where older versions of Slurm talking to a 24.11 dbd could\n    loose step accounting.\n -- Fix minor memory leaks.\n -- Fix bad memory reference when xstrchr fails to find char.\n -- Remove duplicate checks for a data structure.\n -- Fix race condition in stepmgr step completion handling.\n -- slurm.spec - add ability to specify patches to apply on the command line\n -- slurm.spec - add ability to supply extra version information\n -- Fix 24.11 HA issues.\n -- Fix requeued jobs keeping their priority until the decay thread happens.\n -- Fix potential memory corruption in select/cons_tres plugin.\n -- Avoid cache coherency issue on non-x86 platforms that could result in a\n    POSIX signal being ignored or an abort().\n -- slurmctld - Remove assertion in development builds that would trigger if\n    an outdated client attempted to connect.\n -- slurmd - Wait for PrologEpilogTimeout on reconfigure for prologs to finish.\n    This avoids a situation where the slurmd never detects that the prolog\n    completed.\n -- job_container/tmpfs - Setup x11 forwarding within the namespace.\n\n* Changes in Slurm 24.11.0rc2\n=============================\n -- slurmctld - fix memory leak when sending a DBD_JOB_START message.\n -- Fix issue with accounting rollup dealing with association tables.\n -- Fix minor memory leaks.\n -- Fix potential thread safety issues.\n -- Init mutex in burst_buffer plugins.\n -- slurmdbd - don't log errors when no changes occur from db requests.\n -- slurmcltd,slurmd - Avoid deadlock during reconfigure if too many POSIX\n    signals are received.\n\n* Changes in Slurm 24.11.0rc1\n=============================\n -- Improve error type logged from partial or incomplete reading from socket or\n    pipe to avoid potentially logging an error from a previous syscall.\n -- slurmrestd - Improve the handling of queries when unable to connect to\n    slurmdbd by providing responses when possible.\n -- slurmrestd,sackd,scrun - Avoid rare hangs related to I/O.\n -- scrun - Add support '--all' argument for kill subcommand.\n -- Remove srun --cpu-bind=rank.\n -- Add resource_spec/cpus and resource_spec/memory entry points in data_parser\n    to print the CpuSpecList and MemSpecLimit in sinfo --json.\n -- sinfo - Add '.sinfo[].resource_spec.cpus' and\n    '.sinfo[].resource_spec.memory' fields to print the CpuSpecList and\n    MemSpecLimit dumped by 'sinfo --{json|yaml}'.\n -- Increase efficiency of sending logs to syslog.\n -- Switch to new official YAML mime type \"application/yaml\" in compliance with\n    RFC9512 as primary mime type for YAML formatting.\n -- slurmrestd - Removed deprecated fields from the following endpoints:\n\t'.result' from 'POST /slurm/v0.0.42/job/submit'.\n\t'.job_id', '.step_id', '.job_submit_user_msg' from 'POST /slurm/v0.0.42/job/{job_id}'.\n\t'.job.exclusive', '.jobs[].exclusive' to 'POST /slurm/v0.0.42/job/submit'.\n\t'.jobs[].exclusive' from 'GET /slurm/v0.0.42/job/{job_id}'.\n\t'.jobs[].exclusive' from 'GET /slurm/v0.0.42/jobs'.\n\t'.job.oversubscribe', '.jobs[].oversubscribe' to 'POST /slurm/v0.0.42/job/submit'.\n\t'.jobs[].oversubscribe' from 'GET /slurm/v0.0.42/job/{job_id}'.\n\t'.jobs[].oversubscribe' from 'GET /slurm/v0.0.42/jobs'.\n -- scontrol - Removed deprecated fields '.jobs[].exclusive' and\n    '.jobs[].oversubscribe' from 'scontrol show jobs --{json|yaml}'.\n -- squeue - Removed deprecated fields '.jobs[].exclusive' and\n    '.jobs[].oversubscribe' from 'squeue --{json|yaml}'.\n -- Improve the way to run external commands and fork processes to avoid\n    non-async-signal safe calls between a fork and an exec. We fork ourselves\n    now and executes the commands in a safe environment. This includes spank\n    prolog/epilog executions.\n -- Improve MaxMemPerCPU enforcement when exclusive jobs request per node memory\n    and the partition has heterogeneous nodes.\n -- Remove a TOCTOU where multiple steps requesting an energy reading at the\n    same time could cause too frequent accesses to the drivers.\n -- Limit SwitchName to HOST_NAME_MAX chars length.\n -- For scancel --ctld and the following rest api endpoints:\n      'DELETE /slurm/v0.0.40/jobs'\n      'DELETE /slurm/v0.0.41/jobs'\n      'DELETE /slurm/v0.0.42/jobs'\n    Support array expressions in the responses to the client.\n -- salloc - Always output node names to the user when an allocation is granted.\n -- slurmrestd - Removed all v0.0.39 endpoints.\n -- select/linear - Reject jobs asking for GRES per job|socket|task or\n    cpus|mem per GRES.\n -- Add /nodes POST endpoint to REST API, supports multiple node update whereas\n    previously only single nodes could be updated through /node/<nodename>\n    endpoint:\n      'POST /slurm/v0.0.42/nodes'\n -- Do not allow changing or setting PreemptMode=GANG to a partition as this is\n    a cluster-wide option.\n -- Add \"%b\" as a file name pattern for the array task id modulo 10.\n -- Skip packing empty nodes when they are hidden during REQUEST_NODE_INFO RPC.\n -- accounting_storage/mysql - Avoid a fatal condition when the db server is\n    not reachable.\n -- Always lay out steps cyclically on nodes in an allocation.\n -- squeue - add priority by partition ('.jobs[].priority_by_partition') to\n    JSON and YAML output.\n -- slurmrestd - Add clarification to \"failed to open slurmdbd connection\" error\n    if the error was the result of an authentication failure.\n -- Make it so slurmctld responds to RPCs that have authentication errors with\n    the SLURM_PROTOCOL_AUTHENTICATION_ERROR error code.\n -- openapi/slurmctld - Display the correct error code instead of\n    \"Unspecified error\" if querying the following endpoints fails:\n      'GET /slurm/v0.0.40/diag/'\n      'GET /slurm/v0.0.41/diag/'\n      'GET /slurm/v0.0.42/diag/'\n      'GET /slurm/v0.0.40/licenses/'\n      'GET /slurm/v0.0.41/licenses/'\n      'GET /slurm/v0.0.42/licenses/'\n      'GET /slurm/v0.0.40/reconfigure'\n      'GET /slurm/v0.0.41/reconfigure'\n      'GET /slurm/v0.0.42/reconfigure'\n -- Fix how used cpus are tracked in a job allocation to allow the max number of\n    concurrent steps to run at a time if threads per core is greater than 1.\n -- In existing allocations SLURM_GPUS_PER_NODE environment variable will be\n    ignored by srun if --gpus is specified.\n -- When using --get-user-env explicitly or implicitly, check if PID or mnt\n    namespaces are disabled and fall back to old logic that does not rely on\n    them when they are not available.\n -- Removed non-functional option SLURM_PROLOG_CPU_MASK from TaskProlog which\n    was used to reset the affinity of a task based on the mask given.\n -- slurmrestd - Support passing of '-d latest' to load latest version of\n    data_parser plugin.\n -- sacct,sacctmgr,scontrol,sdiag,sinfo,squeue,sshare - Change response to\n    '--json=list' or '--yaml=list' to send list of plugins to stdout and\n    descriptive header to stderr to allow for easier parsing.\n -- slurmrestd - Change response to '-d list', '-a list' or '-s list' to send\n    list of plugins to stdout and descriptive header to stderr to allow for\n    easier parsing.\n -- sacct,sacctmgr,scontrol,sdiag,sinfo,squeue,sshare,slurmrestd - Avoid crash\n    when loading data_parser plugins fail due to NULL dereference.\n -- Add autodetected gpus to the output of slurmd -C\n -- Remove burst_buffer/lua call slurm.job_info_to_string().\n -- Add SchedulerParameters=bf_allow_magnetic_slot option. It allows jobs in\n    magnetic reservations to be planned by backfill scheduler.\n -- slurmrestd - Refuse to run as root, SlurmUser, and nobody(99).\n -- openapi/slurmctld - Revert regression that caused signaling jobs to cancel\n    entire job arrays instead of job array tasks:\n      'DELETE /slurm/v0.0.40/{job_id}'\n      'DELETE /slurm/v0.0.41/{job_id}'\n      'DELETE /slurm/v0.0.42/{job_id}'\n -- openapi/slurmctld - Support more formats for {job_id} including job steps:\n      'DELETE /slurm/v0.0.40/{job_id}'\n      'DELETE /slurm/v0.0.41/{job_id}'\n      'DELETE /slurm/v0.0.42/{job_id}'\n -- Alter scheduling of jobs at submission time to consider job submission time\n    and job id. This makes it so that that interactive jobs aren't allocated\n    resources before batch jobs when they have the same priority at submit time.\n -- Fix multi-cluster submissions with differing Switch plugins.\n -- slurmrestd - Change +prefer_refs flag to default in data_parser/v0.0.42\n    plugin. Add +minimize_refs flag to inline single referenced schemas in the\n    OpenAPI schema. This sets the default OpenAPI schema generation behavior of\n    data_parser/v0.0.42 to match v0.0.41+prefer_refs and v0.0.40 (without\n    flags).\n -- Fix LaunchParameters=batch_step_set_cpu_freq.\n -- Clearer seff warning message for running jobs.\n -- data_parser/v0.0.42 - Rename JOB_INFO field \"minimum_switches\" to\n    \"required_switches\" to reflect the actual behavior.\n -- data_parser/v0.0.42 - Rename ACCOUNT_CONDITION field \"association\" to\n    \"association\" to fix typo.\n -- cgroup/v2 - fix cgroup cleanup when running inside a container without write\n    permissions to /sys/fs/cgroup.\n -- cgroup/v2 - fix accounting of swap events detection.\n -- Fix gathering MaxRSS for jobs that run shorter than two jobacctgather\n    intervals. Get the metrics from cgroups memory.peak or\n    memory.max_usage_in_bytes where available.\n -- openapi/slurmctld - Set complex number support for the following fields:\n      .shares[][].fairshare.factor\n      .shares[][].fairshare.level\n    for endpoints:\n      'GET /slurm/v0.0.42/shares'\n    and for commands:\n      sshare --json\n      sshare --yaml\n -- data_parser/v0.0.42 - Avoid dumping \"Infinity\" for NO_VAL tagged \"number\"\n    fields.\n -- Add TopologyParam=TopoMaxSizeUnroll=# to allow --nodes=<min>-<max> for\n    topology/block.\n -- sacct - Respect --noheader for --batch-script and --env-vars.\n -- sacct - Remove extra newline in output from --batch-script and --env-vars.\n -- Add \"sacctmgr ping\" command to query status of slurmdbd.\n -- Generate an error message when a NodeSet name conflicts with a NodeName, and\n    prevent the controller from starting if such a conflict exists.\n -- slurmd - properly detect slurmd restarts in the energy gathering logic\n    which caused bad numbers in accounting.\n -- sackd - retry fetching slurm configs indefinitely in configless mode.\n -- job_submit/lua - Add \"assoc_qos\" attribute to job_desc to display all\n    potential QOS's for a job's association.\n -- job_submit/lua - Add slurm.get_qos_priority() function to retrieve the\n    given QOS's priority.\n -- sbcast - Add --nodelist option to specify where files are transmitted to\n -- sbcast - Add --no-allocation option to transmit files to nodes outside of a\n    job allocation\n -- Add DataParserParameters slurm.conf parameter to allow setting default\n    value for CLI --json and --yaml arguments.\n -- seff - improve step's max memory consumption report by using TresUsageInTot\n    and TresUsageInAve instead of overestimating the values.\n -- Enable RPC queueing for REQUEST_KILL_JOBS, which is used when scancel is\n    executed with --ctld flag.\n -- slurmdbd - Add -u option. This is used to determine if restarting the DBD\n    will result in database conversion.\n -- Fix srun inside an salloc in a federated cluster when using IPv6.\n -- Calculate the forwarding timeouts according to tree depth rather than\n    node count / tree width for each level. Fixes race conditions with same\n    timeouts between two consecutive node levels.\n -- Add ability to submit jobs with multiple QOS.\n -- Fix difference in behavior when swapping partition order in job submission.\n -- Improve PLANNED state detection for mixed nodes and updating state before\n    yielding backfill locks.\n -- Always consider partition priority tiers when deciding to try scheduling\n    jobs on submit.\n -- Prevent starting jobs without reservations on submit when there are pending\n    jobs with reservations that have flags FLEX or ANY_NODES that can be\n    scheduled on overlapping nodes.\n -- Prevent jobs that request both high and low priority tier partitions from\n    starting on submit in lower priority tier partitions if it could delay\n    pending jobs in higher priority tier partitions.\n -- scontrol - Wait for slurmctld to start reconfigure in foreground mode\n    before returning.\n -- Improve reconfigure handling on Linux to only close open file descriptors\n    to avoid long delays on systems with large RLIMIT_NOFILE settings.\n -- salloc - Removed --get-user-env option.\n -- Removed the instant on feature from switch/hpe_slingshot.\n -- Hardware collectives in switch/hpe_slingshot now requires enable_stepmgr.\n -- Allow backfill to plan jobs on nodes currently being used by exclusive user\n    or mcs jobs.\n -- Avoid miscaching IPv6 address to hostname lookups that could have caused\n    logs to have the incorrect hostname.\n -- scontrol - Add --json/--yaml support to listpids\n -- scontrol - Add liststeps\n -- scontrol - Add listjobs\n -- slurmrestd - Avoid connection to slurmdbd for the following endpoints:\n      GET /slurm/v0.0.42/jobs\n      GET /slurm/v0.0.42/job/{job_id}\n -- slurmctld - Changed incoming RPC handling to dedicated thread pool.\n -- job_container/tmpfs - Add EntireStepInNS option that will place the\n    slurmstepd process within the constructed namespace directly.\n -- scontrol show topo - Show aggregated block sizes when using topology/block.\n -- slurmrestd - Add more descriptive HTTP status for authentication failure\n    and connectivity errors with controller.\n -- slurmrestd - Improve reporting errors from slurmctld for job queries:\n      'GET /slurm/v0.0.41/{job_id}'\n      'GET /slurm/v0.0.41/jobs/'\n -- Avoid rejecting a step request that needs fewer gres than nodes in the\n    job allocation.\n -- slurmrestd - Tag the never populated '.jobs[].pid' field as deprecated for\n    the following endpoints:\n      'GET /slurm/v0.0.42/{job_id}'\n      'GET /slurm/v0.0.42/jobs/'\n -- scontrol,squeue - Tag the never populated '.jobs[].pid' field as deprecated\n    for the following:\n      'scontrol show jobs --json'\n      'scontrol show jobs --yaml'\n      'scontrol show job ${JOB_ID} --json'\n      'scontrol show job ${JOB_ID} --yaml'\n      'squeue --json'\n      'squeue --yaml'\n -- data_parser v0.0.42 - fix timestamp parsing regression introduced in in\n    v0.0.40 (eaf3b6631f), parsing of non iso 8601 style timestamps\n -- cgroup/v2 will detect some special container and namespaced setups and\n    will work with it.\n -- Support IPv6 in configless mode.\n -- Add SlurmctldParamters=ignore_constraint_validation to ignore\n    constraint/feature validation at submission.\n -- slurmrestd - Set '.pings[].mode' field as deprecated in the following\n    endpoints:\n      'GET /slurm/v0.0.42/ping'\n -- scontrol - Set '.pings[].mode' field as deprecated in the following\n    commands:\n      'scontrol ping --json'\n      'scontrol ping --yaml'\n -- slurmrestd - Set '.pings[].pinged' field as deprecated in the following\n    endpoints:\n      'GET /slurm/v0.0.42/ping'\n -- scontrol - Set '.pings[].pinged' field as deprecated in the following\n    commands:\n      'scontrol ping --json'\n      'scontrol ping --yaml'\n -- slurmrestd - Add '.pings[].primary' field to the following endpoints:\n      'GET /slurm/v0.0.42/ping'\n -- scontrol - Add '.pings[].primary' field to the following commands:\n      'scontrol ping --json'\n      'scontrol ping --yaml'\n -- slurmrestd - Add '.pings[].responding' field to the following endpoints:\n      'GET /slurm/v0.0.42/ping'\n -- scontrol - Add '.pings[].responding' field to the following commands:\n      'scontrol ping --json'\n      'scontrol ping --yaml'\n -- Prevent jobs without reservations from delaying jobs in reservations with\n    flags FLEX or ANY_NODES in the main scheduler.\n -- Fix allowing to ask for multiple different types of TRES when one of\n    them has a value of 0.\n -- slurmctld - Add a grace period to ensure the agent retry queue is properly\n    flushed during shutdown.\n -- Removed src/slurmrestd/plugins/openapi/slurmdbd/openapi.json from source\n    repository. slurmrest should always be used to generate a new OpenAPI\n    schema (aka openapi.json or openapi.yaml) after compilation.\n -- mpi/pmix - Fix potential deadlock and races with het jobs, and fix potential\n    memory and FDs leaks.\n -- Fix jobs with --gpus being rejected in some edge cases for partitions\n    where not all nodes have the same amount of GPUs and CPUs configured.\n -- In an extra constraints expression in a job request, do not allow an empty\n    string for a key or value.\n -- In an extra constraints expression in a job request, fix validation that\n    requests are separated by boolean operators.\n -- Add TaskPluginParam=OOMKillStep to kill the step as a whole when one task\n    OOMs.\n -- Fix scontrol show conf not showing all TaskPluginParam elements.\n -- slurmrestd - Add fields '.job.oom_kill_step' '.jobs[].oom_kill_step' to\n    'POST /slurm/v0.0.42/job/submit' and 'POST /slurm/v0.0.42/job/allocate'.\n -- Improve performance for _will_run_test().\n -- Add SchedulerParameters=bf_topopt_enable option to enable experimental hook\n    to control backfill.\n -- If a step fails to launch under certain conditions, set the step's state\n    to NODE_FAIL.\n -- sched/backfill - Fix certain situations where a job would not get a\n    planned time, which could lead to it being delayed by lower priority jobs.\n -- slurmrestd - Dump JSON \"null\" instead of \"{}\" (empty object) for\n    non-required fields in objects to avoid client compatibility issues for\n    v0.0.42 version tagged endpoints.\n -- sacct,sacctmgr,scontrol,sdiag,sinfo,squeue,sshare - Dump \"null\" instead\n    \"{}\" (empty object) for non-required fields in objects to avoid client\n    compatibility issues when run with --json or --yaml.\n\n* Changes in Slurm 24.05.5\n==========================\n -- Fix issue signaling cron jobs resulting in unintended requeues.\n -- Fix slurmctld memory leak in implementation of HealthCheckNodeState=CYCLE.\n -- job_container/tmpfs - Fix SLURM_CONF env variable not being properly set.\n -- sched/backfill - Fix job's time_limit being overwritten by time_min for job\n    arrays in some situations.\n -- RoutePart - fix segfault from incorrect memory allocation when node doesn't\n    exist in any partition.\n -- slurmctld - Fix crash when a job is evaluated for a reservation after\n    removal of a dynamic node.\n -- gpu/nvml - Attempt loading libnvidia-ml.so.1 as a fallback for failure in\n    loading libnvidia-ml.so.\n -- slurmrestd - Fix populating non-required object fields of objects as '{}' in\n    JSON/YAML instead of 'null' causing compiled OpenAPI clients to reject\n    the response to 'GET /slurm/v0.0.40/jobs' due to validation failure of\n    '.jobs[].job_resources'.\n -- Fix sstat/sattach protocol errors for steps on higher version slurmd's\n    (regressions since 20.11.0rc1 and 16.05.1rc1 respectively).\n -- slurmd - Avoid a crash when starting slurmd version 24.05 with\n    SlurmdSpoolDir files that have been upgraded to a newer major version of\n    Slurm. Log warnings instead.\n -- Fix race condition in stepmgr step completion handling.\n -- Fix slurmctld segfault with stepmgr and MpiParams when running a job array.\n -- Fix requeued jobs keeping their priority until the decay thread happens.\n\n* Changes in Slurm 24.05.4\n==========================\n -- Fix generic int sort functions.\n -- Fix user look up using possible unrealized uid in the dbd.\n -- Fix FreeBSD compile issue with tls/none plugin.\n -- slurmrestd - Fix regressions that allowed slurmrestd to be run as SlurmUser\n    when SlurmUser was not root.\n -- mpi/pmix fix race conditions with het jobs at step start/end which could\n    make srun to hang.\n -- Fix not showing some SelectTypeParameters in scontrol show config.\n -- Avoid assert when dumping removed certain fields in JSON/YAML.\n -- Improve how shards are scheduled with affinity in mind.\n -- Fix MaxJobsAccruePU not being respected when MaxJobsAccruePA is set\n    in the same QOS.\n -- Prevent backfill from planning jobs that use overlapping resources for the\n    same time slot if the job's time limit is less than bf_resolution.\n -- Fix memory leak when requesting typed gres and --[cpus|mem]-per-gpu.\n -- Prevent backfill from breaking out due to \"system state changed\" every 30\n    seconds if reservations use REPLACE or REPLACE_DOWN flags.\n -- slurmrestd - Make sure that scheduler_unset parameter defaults to true even\n    when the following flags are also set: show_duplicates, skip_steps,\n    disable_truncate_usage_time, run_away_jobs, whole_hetjob,\n    disable_whole_hetjob, disable_wait_for_result, usage_time_as_submit_time,\n    show_batch_script, and or show_job_environment. Additionally, always make\n    sure show_duplicates and disable_truncate_usage_time default to true when\n    the following flags are also set: scheduler_unset, scheduled_on_submit,\n    scheduled_by_main, scheduled_by_backfill, and or job_started. This effects\n    the following endpoints:\n      'GET /slurmdb/v0.0.40/jobs'\n      'GET /slurmdb/v0.0.41/jobs'\n -- Ignore --json and --yaml options for scontrol show config to prevent mixing\n    output types.\n -- Fix not considering nodes in reservations with Maintenance or Overlap flags\n    when creating new reservations with nodecnt or when they replace down nodes.\n -- Fix suspending/resuming steps running under a 23.02 slurmstepd process.\n -- Fix options like sprio --me and squeue --me for users with a uid greater\n    than 2147483647.\n -- fatal() if BlockSizes=0. This value is invalid and would otherwise cause the\n    slurmctld to crash.\n -- sacctmgr - Fix issue where clearing out a preemption list using\n    preempt='' would cause the given qos to no longer be preempt-able until set\n    again.\n -- Fix stepmgr creating job steps concurrently.\n -- data_parser/v0.0.40 - Avoid dumping \"Infinity\" for NO_VAL tagged \"number\"\n    fields.\n -- data_parser/v0.0.41 - Avoid dumping \"Infinity\" for NO_VAL tagged \"number\"\n    fields.\n -- slurmctld - Fix a potential leak while updating a reservation.\n -- slurmctld - Fix state save with reservation flags when a update fails.\n -- Fix reservation update issues with parameters Accounts and Users, when\n    using +/- signs.\n -- slurmrestd - Don't dump warning on empty wckeys in:\n      'GET /slurmdb/v0.0.40/config'\n      'GET /slurmdb/v0.0.41/config'\n -- Fix slurmd possibly leaving zombie processes on start up in configless when\n    the initial attempt to fetch the config fails.\n -- Fix crash when trying to drain a non-existing node (possibly deleted\n    before).\n -- slurmctld - fix segfault when calculating limit decay for jobs with an\n    invalid association.\n -- Fix IPMI energy gathering with multiple sensors.\n -- data_parser/v0.0.39 - Remove xassert requiring errors and warnings to have a\n    source string.\n -- slurmrestd - Prevent potential segfault when there is an error parsing an\n    array field which could lead to a double xfree. This applies to several\n    endpoints in data_parser v0.0.39, v0.0.40 and v0.0.41.\n -- scancel - Fix a regression from 23.11.6 where using both the --ctld and\n    --sibling options would cancel the federated job on all clusters instead of\n    only the cluster(s) specified by --sibling.\n -- accounting_storage/mysql - Fix bug when removing an association\n    specified with an empty partition.\n -- Fix setting multiple partition state restore on a job correctly.\n -- Fix difference in behavior when swapping partition order in job submission.\n -- Fix security issue in stepmgr that could permit an attacker to execute\n    processes under other users' jobs. CVE-2024-48936.\n\n* Changes in Slurm 24.05.3\n==========================\n -- data_parser/v0.0.40 - Added field descriptions\n -- slurmrestd - Avoid creating new slurmdbd connection per request to\n    '* /slurm/slurmctld/*/*' endpoints.\n -- Fix compilation issue with switch/hpe_slingshot plugin.\n -- Fix gres per task allocation with threads-per-core.\n -- data_parser/v0.0.41 - Added field descriptions\n -- slurmrestd - Change back generated OpenAPI schema for\n    `DELETE /slurm/v0.0.40/jobs/` to RequestBody instead of using parameters\n    for request. slurmrestd will continue accept endpoint requests via\n    RequestBody or HTTP query.\n -- topology/tree - Fix issues with switch distance optimization.\n -- Fix potential segfault of secondary slurmctld when falling back to the\n    primary when running with a JobComp plugin.\n -- Enable --json/--yaml=v0.0.39 options on client commands to dump data using\n    data_parser/v0.0.39 instead or outputting nothing.\n -- switch/hpe_slingshot - Fix issue that could result in a 0 length state file.\n -- Fix unnecessary message protocol downgrade for unregistered nodes.\n -- Fix unnecessarily packing alias addrs when terminating jobs with a mix of\n    non-cloud/dynamic nodes and powered down cloud/dynamic nodes.\n -- accounting_storage/mysql - Fix issue when deleting a qos that could remove\n    too many commas from the qos and/or delta_qos fields of the assoc table.\n -- slurmctld - Fix memory leak when using RestrictedCoresPerGPU.\n -- Fix allowing access to reservations without MaxStartDelay set.\n -- Fix regression introduced in 24.05.0rc1 breaking srun --send-libs parsing.\n -- Fix slurmd vsize memory leak when using job submission/allocation commands\n    that implicitly or explicitly use --get-user-env.\n -- slurmd - Fix node going into invalid state when using CPUSpecList and\n    setting CPUs to the # of cores on a multithreaded node\n -- Fix reboot asap nodes being considered in backfill after a restart.\n -- Fix --clusters/-M queries for clusters outside of a federation when\n    fed_display is configured.\n -- Fix scontrol allowing updating job with bad cpus-per-task value.\n -- sattach - Fix regression from 24.05.2 security fix leading to crash.\n -- mpi/pmix - Fix assertion when built under --enable-debug.\n\n* Changes in Slurm 24.05.2\n==========================\n -- Fix energy gathering rpc counter underflow in _rpc_acct_gather_energy when\n    more than 10 threads try to get energy at the same time. This prevented\n    the possibility to get energy from slurmd by any step until slurmd was\n    restarted, so losing energy accounting metrics in the node.\n -- accounting_storage/mysql - Fix issue where new user with wckey did not\n    have a default wckey sent to the slurmctld.\n -- slurmrestd - Prevent slurmrestd segfault when handling the following\n    endpoints when none of the optional parameters are specified:\n      'DELETE /slurm/v0.0.40/jobs'\n      'DELETE /slurm/v0.0.41/jobs'\n      'GET /slurm/v0.0.40/shares'\n      'GET /slurm/v0.0.41/shares'\n      'GET /slurmdb/v0.0.40/instance'\n      'GET /slurmdb/v0.0.41/instance'\n      'GET /slurmdb/v0.0.40/instances'\n      'GET /slurmdb/v0.0.41/instances'\n      'POST /slurm/v0.0.40/job/{job_id}'\n      'POST /slurm/v0.0.41/job/{job_id}'\n -- Fix IPMI energy gathering when no IPMIPowerSensors are specified in\n    acct_gather.conf. This situation resulted in an accounted energy of 0\n    for job steps.\n -- Fix a minor memory leak in slurmctld when updating a job dependency.\n -- scontrol,squeue - Fix regression that caused incorrect values for\n    multisocket nodes at '.jobs[].job_resources.nodes.allocation' for\n    'scontrol show jobs --(json|yaml)' and 'squeue --(json|yaml)'.\n -- slurmrestd - Fix regression that caused incorrect values for\n    multisocket nodes at '.jobs[].job_resources.nodes.allocation' to be dumped\n    with endpoints:\n      'GET /slurm/v0.0.41/job/{job_id}'\n      'GET /slurm/v0.0.41/jobs'\n -- jobcomp/filetxt - Fix truncation of job record lines > 1024 characters.\n -- Fixed regression that prevented compilation on FreeBSD hosts.\n -- switch/hpe_slingshot - Drain node on failure to delete CXI services.\n -- Fix a performance regression from 23.11.0 in cpu frequency handling when no\n    CpuFreqDef is defined.\n -- Fix one-task-per-sharing not working across multiple nodes.\n -- Fix inconsistent number of cpus when creating a reservation using the\n    TRESPerNode option.\n -- data_parser/v0.0.40+ - Fix job state parsing which could break filtering.\n -- Prevent cpus-per-task to be modified in jobs where a -c value has been\n    explicitly specified and the requested memory constraints implicitly\n    increase the number of CPUs to allocate.\n -- slurmrestd - Fix regression where args '-s v0.0.39,dbv0.0.39' and\n    '-d v0.0.39' would result in 'GET /openapi/v3' not registering as a valid\n    possible query resulting in 404 errors.\n -- slurmrestd - Fix memory leak for dbv0.0.39 jobs query which occurred if the\n    query parameters specified account, association, cluster, constraints,\n    format, groups, job_name, partition, qos, reason, reservation, state, users,\n    or wckey. This affects the following endpoints:\n      'GET /slurmdb/v0.0.39/jobs'\n -- slurmrestd - In the case the slurmdbd does not respond to a persistent\n    connection init message, prevent the closed fd from being used, and instead\n    emit an error or warning depending on if the connection was required.\n -- Fix 24.05.0 regression that caused the slurmdbd not to send back an error\n    message if there is an error initializing a persistent connection.\n -- Reduce latency of forwarded x11 packets.\n -- Add \"curr_dependency\" (representing the current dependency of the job)\n    and \"orig_dependency\" (representing the original requested dependency of\n    the job) fields to the job record in job_submit.lua (for job update) and\n    jobcomp.lua.\n -- Fix potential segfault of slurmctld configured with\n    SlurmctldParameters=enable_rpc_queue from happening on reconfigure.\n -- Fix potential segfault of slurmctld on its shutdown when rate limiting\n    is enabled.\n -- slurmrestd - Fix missing job environment for SLURM_JOB_NAME,\n    SLURM_OPEN_MODE, SLURM_JOB_DEPENDENCY, SLURM_PROFILE, SLURM_ACCTG_FREQ,\n    SLURM_NETWORK and SLURM_CPU_FREQ_REQ to match sbatch.\n -- Add missing bash-completions dependency to slurm-smd-client debian package.\n -- Fix bash-completions installation in debian packages.\n -- Fix GRES environment variable indices being incorrect when only using a\n    subset of all GPUs on a node and the --gres-flags=allow-task-sharing option\n -- Add missing mariadb/mysql client package dependency to debian package.\n -- Fail the debian package build early if mysql cannot be found.\n -- Prevent scontrol from segfaulting when requesting scontrol show reservation\n    --json or --yaml if there is an error retrieving reservations from the\n    slurmctld.\n -- switch/hpe_slingshot - Fix security issue around managing VNI access.\n    CVE-2024-42511.\n -- switch/nvidia_imex - Fix security issue managing IMEX channel access.\n    CVE-2024-42511.\n -- switch/nvidia_imex - Allow for compatibility with job_container/tmpfs.\n\n* Changes in Slurm 24.05.1\n==========================\n -- Fix slurmctld and slurmdbd potentially stopping instead of performing a\n    logrotate when receiving SIGUSR2 when using auth/slurm.\n -- switch/hpe_slingshot - Fix slurmctld crash when upgrading from 23.02.\n -- Fix \"Could not find group\" errors from validate_group() when using\n    AllowGroups with large /etc/group files.\n -- Prevent an assertion in debugging builds when triggering log rotation\n    in a backup slurmctld.\n -- Add AccountingStoreFlags=no_stdio which allows to not record the stdio\n    paths of the job when set.\n -- slurmrestd - Prevent a slurmrestd segfault when parsing the crontab field,\n    which was never usable. Now it explicitly ignores the value and emits a\n    warning if it is used for the following endpoints:\n      'POST /slurm/v0.0.39/job/{job_id}'\n      'POST /slurm/v0.0.39/job/submit'\n      'POST /slurm/v0.0.40/job/{job_id}'\n      'POST /slurm/v0.0.40/job/submit'\n      'POST /slurm/v0.0.41/job/{job_id}'\n      'POST /slurm/v0.0.41/job/submit'\n      'POST /slurm/v0.0.41/job/allocate'\n -- mpi/pmi2 - Fix communication issue leading to task launch failure with\n    \"invalid kvs seq from node\".\n -- Fix getting user environment when using sbatch with \"--get-user-env\" or\n    \"--export=\" when there is a user profile script that reads /proc.\n -- Prevent slurmd from crashing if acct_gather_energy/gpu is configured but\n    GresTypes is not configured.\n -- Do not log the following errors when AcctGatherEnergyType plugins are used\n    but a node does not have or cannot find sensors:\n    \"error: _get_joules_task: can't get info from slurmd\"\n    \"error: slurm_get_node_energy: Zero Bytes were transmitted or received\"\n    However, the following error will continue to be logged:\n    \"error: Can't get energy data. No power sensors are available. Try later\"\n -- sbatch, srun - Set SLURM_NETWORK environment variable if --network is set.\n -- Fix cloud nodes not being able to forward to nodes that restarted with new\n    IP addresses.\n -- Fix cwd not being set correctly when running a SPANK plugin with a\n    spank_user_init() hook and the new \"contain_spank\" option set.\n -- slurmctld - Avoid deadlock during shutdown when auth/slurm is active.\n -- Fix segfault in slurmctld with topology/block.\n -- sacct - Fix printing of job group for job steps.\n -- scrun - Log when an invalid environment variable causes the job submission\n    to be rejected.\n -- accounting_storage/mysql - Fix problem where listing or modifying an\n    association when specifying a qos list could hang or take a very long time.\n -- gpu/nvml - Fix gpuutil/gpumem only tracking last GPU in step. Now,\n    gpuutil/gpumem will record sums of all GPUS in the step.\n -- Fix error in scrontab jobs when using slurm.conf:PropagatePrioProcess=1.\n -- Fix slurmctld crash on a batch job submission with \"--nodes 0,...\".\n -- Fix dynamic IP address fanout forwarding when using auth/slurm.\n -- Restrict listening sockets in the mpi/pmix plugin and sattach to the\n    SrunPortRange.\n -- slurmrestd - Limit mime types returned from query to 'GET /openapi/v3' to\n    only return one mime type per serializer plugin to fix issues with OpenAPI\n    client generators that are unable to handle multiple mime type aliases.\n -- Fix many commands possibly reporting an \"Unexpected Message Received\" when\n    in reality the connection timed out.\n -- Prevent slurmctld from starting if there is not a json serializer present\n    and the extra_constraints feature is enabled.\n -- Fix heterogeneous job components not being signaled with scancel --ctld and\n    'DELETE slurm/v0.0.40/jobs' if the job ids are not explicitly given,\n    the heterogeneous job components match the given filters, and the\n    heterogeneous job leader does not match the given filters.\n -- Fix regression from 23.02 impeding job licenses from being cleared.\n -- Move error to log_flag which made _get_joules_task error to be logged to the\n    user when too many rpcs were queued in slurmd for gathering energy.\n -- For scancel --ctld and the associated rest api endpoints:\n      'DELETE /slurm/v0.0.40/jobs'\n      'DELETE /slurm/v0.0.41/jobs'\n    Fix canceling the final array task in a job array when the task is pending\n    and all array tasks have been split into separate job records. Previously\n    this task was not canceled.\n -- Fix power_save operation after recovering from a failed reconfigure.\n -- slurmctld - Skip removing the pidfile when running under systemd. In that\n    situation it is never created in the first place.\n -- Fix issue where altering the flags on a Slurm account (UsersAreCoords)\n    several limits on the account's association would be set to 0 in\n    Slurm's internal cache.\n -- Fix memory leak in the controller when relaying stepmgr step accounting to\n    the dbd.\n -- Fix segfault when submitting stepmgr jobs within an existing allocation.\n -- Added \"disable_slurm_hydra_bootstrap\" as a possible MpiParams parameter in\n    slurm.conf. Using this will disable env variable injection to allocations\n    for the following variables: I_MPI_HYDRA_BOOTSTRAP,\n    I_MPI_HYDRA_BOOTSTRAP_EXEC_EXTRA_ARGS, HYDRA_BOOTSTRAP,\n    HYDRA_LAUNCHER_EXTRA_ARGS.\n -- scrun - Delay shutdown until after start requested. This caused scrun\n    to never start or shutdown and hung forever when using --tty.\n -- Fix backup slurmctld potentially not running the agent when taking over as\n    the primary controller.\n -- Fix primary controller not running the agent when a reconfigure of the\n    slurmctld fails.\n -- slurmd - fix premature timeout waiting for REQUEST_LAUNCH_PROLOG with large\n    array jobs causing node to drain.\n -- jobcomp/{elasticsearch,kafka} - Avoid sending fields with invalid date/time.\n -- jobcomp/elasticsearch - Fix slurmctld memory leak from curl usage\n -- acct_gather_profile/influxdb - Fix slurmstepd memory leak from curl usage\n -- Fix 24.05.0 regression not deleting job hash dirs after MinJobAge.\n -- Fix filtering arguments being ignored when using squeue --json.\n -- switch/nvidia_imex - Move setup call after spank_init() to allow namespace\n    manipulation within the SPANK plugin.\n -- switch/nvidia_imex - Skip plugin operation if nvidia-caps-imex-channels\n    device is not present rather than preventing slurmd from starting.\n -- switch/nvidia_imex - Skip plugin operation if job_container/tmpfs\n    is configured due to incompatibility.\n -- switch/nvidia_imex - Remove any pre-existing channels when slurmd starts.\n -- rpc_queue - Add support for an optional rpc_queue.yaml configuration file.\n -- slurmrestd - Add new +prefer_refs flag to data_parser/v0.0.41 plugin. This\n    flag will avoid inlining single referenced schemas in the OpenAPI schema.\n\n* Changes in Slurm 24.05.0\n==========================\n -- Fix regression in rc1 causing power_save thread to spin continuously.\n -- Improve ctld_relay shutdown sequence.\n -- Fixed 'make distclean' behavior for contribs/perlapi.\n -- slurmrestd - Avoid ignoring numerical only endpoints during startup with\n    older libjson-c due to type parsing mismatching.\n -- Reject non-stepmgr job allocations requesting --resv-ports from the ctld.\n -- slurmrestd - Add fields '.job.resv_ports' '.jobs[].resv_ports' to\n    'POST /slurm/v0.0.41/job/submit' and 'POST /slurm/v0.0.41/job/allocate'.\n -- slurmstepd - Fix crash when cleaning up on shutdown with\n    --enable-memory-leak-debug.\n -- Fix segfault in switch/hpe_slingshot plugin due to initialization sequence.\n -- scrun - Fix regression in rc1 that caused scrun to crash.\n -- Prevent unnecessary log statement when free'ing ports.\n -- Fix regression in rc1 causing communication problems when sending large\n    responses from slurmctld.\n -- sreport - fix parsing of 'format=Planned' to prevent it from being\n    misinterpreted as 'PlannedDown'. 'PlannedDown' is now also known as\n    'PLNDDown' to match what is printed as the column title.\n -- topology/block - Always return an error when the segment size does not\n    match the system or job specification.\n -- Add previously missing timers for Prolog and Epilog scripts when RunInJob is\n    set.\n -- Show an error when PrologFlags RunInJob and Serial are used together.\n    PrologFlags=Serial is not compatible with how RunInJob operates.\n -- Fix memory leak on shutdown when using --enable-memory-leak-debug and\n    freeing cons_tres node usage.\n -- Rename src/stepmgr/gres_ctld.[ch] to src/stepmgr/gres_stepmgr.[ch].\n -- Fix various cosmetic issues with states in sinfo.\n -- slurmrestd - Avoid crash due to associations query.\n -- Calculate a job's min_cpus with consideration to --cpus-per-gpu.\n -- Fix scancel request when specifying individual array tasks in combination\n    with filtering options (in both regular and --interactive mode).\n -- Enable MaxStepCount in stepmgr.\n -- Enable AccountingStorageEnforce=nojobs,nosteps in stepmgr.\n -- Add AccountingStorageParameters=max_step_records to limit how many steps\n    are recorded in the database for each job -- excluding batch, extern, and\n    interactive steps.\n -- switch/hpe_slingshot - allocate VNIs on the controller for stepmgr jobs and\n    pass to the stepmgr for steps to use.\n -- switch/hpe_slingshot - fix assertion when restarting the controller.\n -- switch/hpe_slingshot - fix calculation of free vnis when restarting the\n    controller with running jobs.\n -- Improve default job reserve MPI port allocations that use overcommit or do\n    not specify a task count for stepmgr enabled jobs.\n -- Fix a regression in rc1 resulting in scrun occasionally deadlocking when\n    the --enable-memory-leak-debug configure option was used.\n -- topology/default - Prevent segfault in slurmctld on 'scontrol show topo'.\n -- slurmrestd - Avoid creating or requiring a connection to slurmdbd for the\n    'GET /openapi/v3' endpoint, fixing a regression in rc1.\n -- scrun - Fix setting and getting environment via SPANK plugins.\n -- sview - Fix nodes tab if a node has RestrictedCoresPerGPU configured.\n -- slurmrestd - Add --generate-openapi-spec argument.\n -- sview - Prevent segfault when retrieving slurmdbd configuration.\n -- Avoid canceling rejected heterogeneous jobs without job write lock.\n -- Fix slurmctld crash when reconfiguring with a PrologSlurmctld is running.\n -- Fix slurmctld crash after a job has been resized.\n\n* Changes in Slurm 24.05.0rc1\n=============================\n -- Make slurmstepd retry REQUEST_COMPLETE_BATCH_SCRIPT indefinitely.\n -- Always load serializer/json when using any data_parser plugins.\n -- slurmrestd - Reject single http query with multiple path requests.\n -- slurmrestd - Add time/planned field to slurmdb/v0.0.41/job/{job_id}.\n -- Improve Power Save's Resume/Suspend rate limiting.\n -- slurmrestd - Improve reliability under high memory pressure by closing\n    connections instead of forcing a fatal exit due to lack of memory.\n -- data_parser/v0.0.41 - Avoid aborting when invoking a not implemented\n    parser.\n -- data_parser/v0.0.41 - Fix how nice values are parsed for job submissions.\n -- data_parser/v0.0.41 - Fix regression where parsing error did not result in\n    invalid request being rejected.\n -- Print an error message in 'scontrol reboot' when a node reboot request\n    is ignored due to the current node state.\n -- squeue - Add \"--notme\" option.\n -- data_parser/v0.0.41 - change \"association.id\" to just include the int \"id\"\n    rather than include redundant assoc info (cluster, user, partition, account)\n    that's already included in the \"association\" object.\n -- data_parser/v0.0.41 - Improve parsing of numeric user id.\n -- data_parser/v0.0.41 - Improve parsing of numeric group id.\n -- slurmrestd - Generated openapi.json will only populate \"deprecated\" fields\n    if true. False is the default value and does not require being present.\n -- slurmrestd - Populate missing \"deprecated\" fields in  openapi.json.\n -- slurmrestd - Corrected deprecated fields in generated openapi.json not\n    getting populated.\n -- slurmrestd - Generated openapi.json will have reduced number of \"$ref\"\n    fields. Where there was only 1 reference for the schema, the \"$ref\" schema\n    will be directly populated in place.\n -- slurmrestd - Rename *_NO_VAL schemas in generated openapi.json to have\n    _struct and to pass along correct integer sizing when possible.\n -- slurmrestd - Correct description fields in generated openapi.json where\n    descriptions were not present or too generic.\n -- Remove support for Cray XC (\"cray_aries\") systems.\n -- Prevent backup slurmctld from taking over if the heartbeat file is\n    still being updated.  Failure to ping may have been due to clock skew.\n -- serializer/yaml - Converted to new parsing interface in libyaml to improve\n    parsing compatibility.\n -- Removed TopologyPlugin tree and dragonfly support from select/linear.\n    If those topology plugins are desired please switch to select/cons_tres.\n -- Changed slurmrestd.service to only listen on TCP socket by default.\n    Environments with existing drop-in units for the service may need\n    further adjustments to work after upgrading.\n -- Fix how gres are allocated per job when using multiple gres types.\n -- Log an error when UnkillableStepTimeout is less than five times\n    MessageTimeout.\n -- Avoid step gres dealloc count underflow errors after reconfiguring or\n    restarting slurmctld.\n -- Fix controller not validating periodic dynamic future registrations.\n -- Fix dynamic future nodes registering as new node when specifying -N<name>.\n -- Fix sbcast (or srun --bcast) --send-libs when it is used multiple times in\n    the same job. Previously, subsequent calls to sbcast --send-libs would\n    overwrite the libraries for the first executable.\n -- Add support for sbcast --preserve when job_container/tmpfs configured\n    (previously documented as unsupported).\n -- Changed the default value for UnkillableStepTimeout to 60 seconds or five\n    times the value of MessageTimeout, whichever is greater.\n -- slurmctld - Check if --deadline has been reached and not satisfied on held\n    jobs, otherwise they could remain without automatic cancellation until after\n    the job is released.\n -- scrun/slurmrestd/sackd - Avoid closing all listening sockets when\n    interrupted from signal such as SIGALRM. Normal shutdown remains unaffected.\n -- Remove systemd AbandonScope() logic for scope units as it is not needed.\n -- Fix GresUsed output from `scontrol show nodes --details` showing  GRES types\n    that are not configured on a node.\n -- slurmrestd - Fatal during start up when loading content plugin fails.\n -- slurmrestd - Reduce complexity in URL path matching.\n -- data_parser/v0.0.41 - Emit a warning instead of an error if a disabled\n    parser is invoked.\n -- Federation - allow client command operation when slurmdbd is unavailable.\n -- Enforce mutual exclusivity of --systemd and -D when launching daemons\n -- slurmctld - remove -d option\n -- burst_buffer/lua - Trigger a burst_buffer event for strigger when the\n    real_size function fails.\n -- burst_buffer/lua - Added two new hooks: slurm_bb_test_data_in and\n    slurm_bb_test_data_out. The syntax and use of the new hooks are documented\n    in etc/burst_buffer.lua.example. These are required to exist. slurmctld now\n    checks on startup if the burst_buffer.lua script loads and contains all\n    required hooks; slurmctld will exit with a fatal error if this is not\n    successful. Added PollInterval to burst_buffer.conf. Removed the arbitrary\n    limit of 512 copies of the script running simultaneously.\n -- sackd/slurmrestd/scrun - Avoid using empty string while logging unix socket\n    connections from a listening connection.\n -- Fix 20 character username limit from 'sacctmgr show events'\n -- Log an error if UsePss or NoShare are configured with a plugin other than\n    jobacct_gather/linux. In such case these parameters are ignored.\n -- helpers.conf - Added Flags=rebootless parameter allowing feature changes\n    without rebooting compute nodes.\n -- scontrol - Add new subcommand 'power' for node power control.\n -- data_parser/v0.0.41 - Implement parser of distribution for\n    /slurm/v0.0.41/job/submit.\n -- data_parser/v0.0.41 - Change distribution_plane_size field type from UINT16\n    to UINT16_NO_VAL for /slurm/v0.0.41/job/submit.\n -- topology/block - Replaced the BlockLevels with BlockSizes in topology.conf.\n -- Fix slurmd cgroup/v2 startup race with systemd and cgroupfs.\n -- Add SystemdTimeout= parameter in cgroup.conf.\n -- Add QOS limit MaxTRESRunMinsPerAccount.\n -- Add QOS limit MaxTRESRunMinsPerUser.\n -- jobcomp/{elasticsearch,kafka} - Send priority alongside the rest of fields.\n -- Add contain_spank option to SlurmdParameters. When set, spank_user_init(),\n    spank_task_post_fork(), and spank_task_exit() will execute within the\n    job_container/tmpfs plugin namespace.\n -- Update job reason appropriately when bf_licenses is used.\n -- slurmrestd - Tagged `script` field as deprecated in\n    'POST /slurm/v0.0.41/job/submit' in anticipation of removal in future\n    OpenAPI plugin versions.\n -- Fix salloc/sbatch/srun crashing with certain invalid nodelist requests.\n -- Optimize jobacctgather by not iterating every time over pids that have\n    already finished.\n -- Remote SPANK callbacks invoked by srun get called once instead of twice.\n -- auth/slurm - Support multiple keys through slurm.jwks.\n -- sched/backfill - Fix issue with bf_continue where a job partition request\n    could be incorrectly reset back to a partition that is no longer specified\n    after a job partition update processed during a lock yield time window.\n -- slurmrestd - Explicitly set process as dumpable (and ptrace-able) at\n    startup for systems where suid_dumpable is not 2.\n -- slurmrestd - Tag all /slurm/v0.0.39/ and /slurmdb/v0.0.39/ endpoints as\n    deprecated in anticipation of removal in Slurm 24.11.\n -- Add ELIGIBLE environment variable to jobcomp/script plugin.\n -- slurmrestd,sackd,scrun - Improve outgoing data efficiency using\n    non-contiguous write support in kernel.\n -- sackd - Add support for SACKD_DEBUG, SACKD_STDERR_DEBUG, and\n    SACKD_SYSLOG_DEBUG environment variables to control logging.\n -- mpi/pmi2 - PMI_process_mapping values have been adapted for executions\n    where arbitrary distribution/SLURM_HOSTFILE is used. Now it can take into\n    account multiple instances of the same node inside SLURM_HOSTFILE.\n -- Avoid wrong limit oriented (i.e. QosMaxGresPer*) job pending reason for jobs\n    actually pending on Resources when GPUs are requested per job.\n -- Fix --ntasks-per-node not being treated as a max count of tasks per node\n    when used in combination with --ntasks. --ntasks option will now take\n    precedence as it is documented.\n -- Accept X11 cookies that do not have a display number associated with it.\n -- Always use the QOS name for SLURM_JOB_QOS environment variables.\n    Previously the batch environment would use the description field,\n    which was usually equivalent to the name.\n -- slurmrestd - Add \"CRON_JOBS\" as possible flag value to the following:\n      'DELETE /slurm/v0.0.40/jobs' flags field.\n      'DELETE /slurm/v0.0.41/jobs' flags field.\n      'DELETE /slurm/v0.0.40/job/{job_id}?flags=' flags query parameter.\n      'DELETE /slurm/v0.0.41/job/{job_id}?flags=' flags query parameter.\n -- Fix ScronParameters=explicit_scancel when using the rest api DELETE jobs\n    query: if the CRON_JOBS flag is not used then cron jobs will not be\n    cancelled. The NO_CRON_JOBS flag is ignored in v0.0.40 and removed in\n    v0.0.41.\n -- Pass multi-partition job priorities to job for squeue to display.\n -- cgroup/v2 - Require dbus-1 version >= 1.11.16.\n -- Add RestrictedCoresPerGPU configuration option.\n -- Fix how ntasks is inferred from --cpus-per-task when using --nodes,\n    --threads-per-core, or --hint=nomultithread.\n -- For PreemptMode=CANCEL and PreemptMode=REQUEUE assume that job signalled\n    for GraceTime was preempted.\n -- slurmd - Retry fetching configs indefinitely during startup.\n -- Fix SPANK options not bing sent to remote context when --export was used.\n -- slurmrestd - Attempt to automatically convert enumerated string arrays with\n    incoming non-string values into strings. Add warning when incoming value for\n    enumerated string arrays can not be converted to string and silently ignore\n    instead of rejecting entire request.\n -- slurmrestd - Require `user` and `association_condition` fields to be\n    populated for requests to 'POST /slurmdb/v0.0.41/users_association'.\n -- Allow NodeSet names to be used in SuspendExcNodes.\n -- SuspendExcNodes=<nodes>:N now counts allocated nodes in N. The first N\n    powered up nodes in <nodes> are protected from being suspended.\n -- Add SlurmctldParameters=max_powered_nodes=N, which prevents powering up\n    nodes after the max is reached.\n -- Store output, error and input paths in the database and make them available\n    in accounting tools.\n -- slurmrestd - Add 'POST /slurm/v0.0.41/job/allocate' endpoint.\n -- Fix issues related to the extern step getting killed before other steps.\n    This includes the job_containter/tmpfs plugin not cleaning up.\n -- Add USER_DELETE reservation flag to allow users with access to a reservation\n    to delete it.\n -- Add CgroupPlugin=disabled to disable any interaction with Cgroups.\n -- slurmrestd - Add \"STEPMGR_ENABLED\" as possible flag value to the following:\n      'GET /slurm/v0.0.41/jobs' flags field.\n      'GET /slurm/v0.0.41/job/{job_id}' flags query parameter.\n -- scontrol,squeue - Added possible flags \"STEPMGR_ENABLED\" to '.jobs[].flags' for\n    'scontrol show jobs --{json|yaml}' and 'squeue --{json|yaml}' responses.\n -- Add SlurmctldParameters=enable_stepmgr to enable step management through\n    the slurmstepd instead of the controller.\n -- Avoid slurmstepd infinite loop waiting for tasks termination.\n -- Fix logging of JSON/YAML values in some messages where nothing would be\n    printed as the value instead of the actual JSONified version of the parsed\n    string.\n -- slurmrestd,sackd,scrun - Improve logic around handling kernel provided\n    buffer size of incoming data in files/sockets/pipes to avoid crashes.\n -- Add --segment to job allocation to be used in topology/block.\n -- Add --exclusive=topo for use with topology/block.\n -- Add ExclusiveTopo to a partition definition in slurm.conf.\n -- Add new 'BLOCKED' state to a node.\n -- Account coordinators may not increase association job limits above\n    parent ones\n -- Account coordinators can now suspend/resume jobs owned by member users.\n -- Add DisableCoordDBD slurmdbd configuration parameter to disable the\n    coordinator status in all slurmdbd interactions.\n -- slurmrestd - Added possible flags \"WithAssociations\" and \"WithCoordinators\"\n    to `.accounts[].flags` for \"GET /slurmdb/v0.0.41/accounts/\" and\n    \"POST /slurmdb/v0.0.41/accounts/\" endpoints.\n -- sacctmgr - Added possible flags \"WithAssociations\" and \"WithCoordinators\"\n    to `.accounts[].flags` for `sacctmgr show accounts --{json|yaml}` response.\n -- slurmrestd - Rename URL query parameter \"with_assocs\" to \"WithAssociations\"\n    for \"GET /slurmdb/v0.0.41/accounts?WithAssociations\".\n -- slurmrestd - Rename URL query parameter \"with_coords\" to \"WithCoordinators\"\n    for \"GET /slurmdb/v0.0.41/accounts?WithCoordinators\".\n -- slurmrestd - Rename URL query parameter \"with_deleted\" to \"deleted\"\n    for \"GET /slurmdb/v0.0.41/accounts?deleted\".\n -- slurmrestd - Added possible flags \"RemoveUsersAreCoords\" and\n    \"UsersAreCoords\" to `.accounts[].flags` for \"GET /slurmdb/v0.0.41/accounts/\"\n    and \"POST /slurmdb/v0.0.41/accounts/\" endpoints.\n -- sacctmgr - Added possible flags \"RemoveUsersAreCoords\" and \"UsersAreCoords\"\n    to `.accounts[].flags` for `sacctmgr show accounts --{json|yaml}` response.\n -- slurmrestd - Add URL query parameter \"UsersAreCoords\" and\n    \"RemoveUsersAreCoords\" for\n    \"GET /slurmdb/v0.0.41/accounts?UsersAreCoords&RemoveUsersAreCoords\".\n -- sacctmgr - Add new possible new flags \"NoUpdate\" and \"Exact\" to\n    '.associations[].flags' response from 'sacctmgr show assocs --{json|yaml}'.\n -- slurmrestd - Added possible flags \"NoUpdate\" and \"Exact\" to\n    `.associations[].flags` for \"GET /slurmdb/v0.0.41/associations/\"\n    and \"POST /slurmdb/v0.0.41/associations/\" endpoints.\n -- Fix false success of REQUEST_FORWARD_DATA RPC that made pmix to get out\n    of sync during initialization.\n -- slurmrestd - Allow startup when slurmdbd is not configured and avoid loading\n    slurmdbd specific plugins.\n -- Added PrologFlags=RunInJob to make prolog and epilog run inside the job\n    extern step to include it in the job's cgroup.\n -- Return '*' for the password field for nss_slurm instead of \"x\".\n -- slurmrestd - Add \"topo\" as possible value to the following:\n      'GET /slurm/v0.0.41/jobs' in '.jobs[].shared' field\n      'GET /slurm/v0.0.41/job/{job_id}' in '.jobs[].shared' field\n      'POST /slurm/v0.0.41/job/submit' in '.job.shared' and '.jobs[].shared'\n      'POST /slurm/v0.0.41/job/allocate' in '.job.shared' and '.jobs[].shared'\n -- sacctmgr - Added possible flags \"NoUsersAreCoords\" and \"UsersAreCoords\"\n    to `.accounts[].flags` for `sacctmgr show accounts --{json|yaml}` response.\n -- sacct - Add \"topo\" as possible value to output of 'sacct --{json|yaml}' to\n    '.jobs[].shared' field.\n -- squeue - Add \"topo\" as possible value to output of 'squeue --{json|yaml}' to\n    '.jobs[].shared' field.\n -- scontrol - Add \"topo\" as possible value to output of\n    'scontrol show jobs --{json|yaml}' to '.jobs[].shared' field.\n -- slurmrestd - Add \"topo\" as possible value to the following:\n      'GET /slurm/v0.0.41/jobs' in '.jobs[].exclusive' field\n      'GET /slurm/v0.0.41/job/{job_id}' in '.jobs[].exclusive' field\n      'POST /slurm/v0.0.41/job/submit' in '.job.exclusive' and\n        '.jobs[].exclusive'\n      'POST /slurm/v0.0.41/job/allocate' in '.job.exclusive' and\n        '.jobs[].exclusive'\n -- sacctmgr - Added possible flags \"RemoveUsersAreCoords\" and \"UsersAreCoords\"\n    to `.accounts[].flags` for `sacctmgr show accounts --{json|yaml}` response.\n -- sacct - Add \"topo\" as possible value to output of 'sacct --{json|yaml}' to\n    '.jobs[].exclusive' field.\n -- squeue - Add \"topo\" as possible value to output of 'squeue --{json|yaml}' to\n    '.jobs[].exclusive' field.\n -- scontrol - Add \"topo\" as possible value to output of\n    'scontrol show jobs --{json|yaml}' to '.jobs[].exclusive' field.\n -- slurmrestd - Add fields '.job.segment_size' and '.jobs[].segment_size' to\n    'POST /slurm/v0.0.41/job/submit' and 'POST /slurm/v0.0.41/job/allocate'.\n -- sacctmgr - Added possible flags \"NoUsersAreCoords\" and \"UsersAreCoords\"\n    to `.associations[].flags` for `sacctmgr show assocs --{json|yaml}`\n    response.\n -- slurmrestd - Added possible flags \"NoUsersAreCoords\" and \"UsersAreCoords\" to\n    `.associations[].flags` for \"GET /slurmdb/v0.0.41/associations/\"\n    and \"POST /slurmdb/v0.0.41/associations/\" endpoints.\n -- Add ability to reserve MPI ports at the job level for stepmgr jobs and\n    subdivide them at the step level.\n -- slurmrestd - Fix possible memory leak from failed job submissions to\n    'POST /slurm/v0.0.{39,40,41}/job/submit'.\n -- slurmrestd - Fix possible memory leak from failed job allocation requests to\n    'POST /slurm/v0.0.{39,40,41}/job/allocate'.\n\n* Changes in Slurm 23.11.11\n===========================\n\n* Changes in Slurm 23.11.10\n===========================\n -- switch/hpe_slingshot - Fix issue that could result in a 0 length state file.\n -- Fix unnecessary message protocol downgrade for unregistered nodes.\n -- Fix unnecessarily packing alias addrs when terminating jobs with a mix of\n    non-cloud/dynamic nodes and powered down cloud/dynamic nodes.\n -- Fix allowing access to reservations without MaxStartDelay set.\n -- Fix scontrol allowing updating job with bad cpus-per-task value.\n -- sattach - Fix regression from 23.11.9 security fix leading to crash.\n\n* Changes in Slurm 23.11.9\n==========================\n -- Fix many commands possibly reporting an \"Unexpected Message Received\" when\n    in reality the connection timed out.\n -- Fix heterogeneous job components not being signaled with scancel --ctld and\n    'DELETE slurm/v0.0.40/jobs' if the job ids are not explicitly given,\n    the heterogeneous job components match the given filters, and the\n    heterogeneous job leader does not match the given filters.\n -- Fix regression from 23.02 impeding job licenses from being cleared.\n -- Move error to log_flag which made _get_joules_task error to be logged to the\n    user when too many rpcs were queued in slurmd for gathering energy.\n -- slurmrestd - Prevent a slurmrestd segfault when modifying an association\n    without specifying max TRES limits in the request if those TRES\n    limits are currently defined in the association. This affects the following\n    fields of endpoint 'POST /slurmdb/v0.0.38/associations/':\n      'associations/max/tres/per/job'\n      'associations/max/tres/per/node'\n      'associations/max/tres/total'\n      'associations/max/tres/minutes/per/job'\n      'associations/max/tres/minutes/total'\n -- Fix power_save operation after recovering from a failed reconfigure.\n -- scrun - Delay shutdown until after start requested. This caused scrun\n    to never start or shutdown and hung forever when using --tty.\n -- Fix backup slurmctld potentially not running the agent when taking over as\n    the primary controller.\n -- Fix primary controller not running the agent when a reconfigure of the\n    slurmctld fails.\n -- jobcomp/{elasticsearch,kafka} - Avoid sending fields with invalid date/time.\n -- Fix energy gathering rpc counter underflow in _rpc_acct_gather_energy when\n    more than 10 threads try to get energy at the same time. This prevented\n    the possibility to get energy from slurmd by any step until slurmd was\n    restarted, so losing energy accounting metrics in the node.\n -- slurmrestd - Fix memory leak for dbv0.0.39 jobs query which occurred if the\n    query parameters specified account, association, cluster, constraints,\n    format, groups, job_name, partition, qos, reason, reservation, state, users,\n    or wckey. This affects the following endpoints:\n      'GET /slurmdb/v0.0.39/jobs'\n -- switch/hpe_slingshot - Fix security issue around managing VNI access.\n    CVE-2024-42511.\n\n* Changes in Slurm 23.11.8\n==========================\n -- Fix slurmctld crash when reconfiguring with a PrologSlurmctld is running.\n -- Fix slurmctld crash after a job has been resized.\n -- Fix slurmctld and slurmdbd potentially stopping instead of performing a\n    logrotate when receiving SIGUSR2 when using auth/slurm.\n -- Fix not having a disabled value for keepalive CommunicationParameters in\n    slurm.conf when these parameters are not set. This can log an error when\n    setting a socket, for example during slurmdbd registration with ctld.\n -- switch/hpe_slingshot - Fix slurmctld crash when upgrading from 23.02.\n -- Fix \"Could not find group\" errors from validate_group() when using\n    AllowGroups with large /etc/group files.\n -- slurmrestd - Prevent a slurmrestd segfault when parsing the crontab field,\n    which was never usable. Now it explicitly ignores the value and emits a\n    warning if it is used for the following endpoints:\n      'POST /slurm/v0.0.39/job/{job_id}'\n      'POST /slurm/v0.0.39/job/submit'\n      'POST /slurm/v0.0.40/job/{job_id}'\n      'POST /slurm/v0.0.40/job/submit'\n -- Fix getting user environment when using sbatch with \"--get-user-env\" or\n    \"--export=\" when there is a user profile script that reads /proc.\n -- Prevent slurmd from crashing if acct_gather_energy/gpu is configured but\n    GresTypes is not configured.\n -- Do not log the following errors when AcctGatherEnergyType plugins are used\n    but a node does not have or cannot find sensors:\n    \"error: _get_joules_task: can't get info from slurmd\"\n    \"error: slurm_get_node_energy: Zero Bytes were transmitted or received\"\n    However, the following error will continue to be logged:\n    \"error: Can't get energy data. No power sensors are available. Try later\"\n -- Fix cloud nodes not being able to forward to nodes that restarted with new\n    IP addresses.\n -- sacct - Fix printing of job group for job steps.\n -- Fix error in scrontab jobs when using slurm.conf:PropagatePrioProcess=1.\n -- Fix slurmctld crash on a batch job submission with \"--nodes 0,...\".\n -- Fix dynamic IP address fanout forwarding when using auth/slurm.\n\n* Changes in Slurm 23.11.7\n==========================\n -- slurmrestd - Correct OpenAPI specification for\n    'GET /slurm/v0.0.40/jobs/state' having response as null.\n -- Allow running jobs on overlapping partitions if jobs don't specify -s.\n -- Fix segfault when requesting a shared gres along with an exclusive\n    allocation.\n -- Fix regression in 23.02 where afternotok and afterok dependencies were\n    rejected for federated jobs not running on the origin cluster of the\n    submitting job.\n -- slurmctld - Disable job table locking while job state cache is active when\n    replying to `squeue --only-job-state` or `GET /slurm/v0.0.40/jobs/state`.\n -- Fix sanity check when setting tres-per-task on the job allocation as well as\n    the step.\n -- slurmrestd - Fix compatibility with auth/slurm.\n -- Fix issue where TRESRunMins gets off correct value if using\n    QOS UsageFactor != 1.\n -- slurmrestd - Require `user` and `association_condition` fields to be\n    populated for requests to 'POST /slurmdb/v0.0.40/users_association'.\n -- Avoid a slurmctld crash with extra_constraints enabled when a job requests\n    certain invalid --extra values.\n -- `scancel --ctld` and `DELETE /slurm/v0.0/40/jobs` - Fix support for job\n    array expressions (e.g. 1_[3-5]). Also fix signaling a single pending array\n    task (e.g. 1_10), which previously signaled the whole array job instead.\n -- Fix a possible slurmctld segfault when at some point we failed to create an\n    external launcher step.\n -- Allow the slurmctld to open a connection to the slurmdbd if the first\n    attempt fails due to a protocol error.\n -- mpi/cray_shasta - Fix launch for non-het-steps within a hetjob.\n -- sacct - Fix \"gpuutil\" TRES usage output being incorrect when using --units.\n -- Fix a rare deadlock on slurmctld shutdown or reconfigure.\n -- Fix issue that only left one thread on each core available when \"CPUs=\" is\n    configured to total thread count on multi-threaded hardware and no other\n    topology info (\"Sockets=\", \"CoresPerSocket\", etc.) is configured.\n -- Fix the external launcher step not being allocated a VNI when requested.\n -- jobcomp/kafka - Fix payload length when producing and sending a message.\n -- scrun - Avoid a crash if RunTimeDelete is called before the container\n    finishes.\n -- Save the slurmd's cred_state while reconfiguring to prevent the loss job\n    credentials.\n\n* Changes in Slurm 23.11.6\n==========================\n -- Avoid limiting sockets per node to one when using gres enforce-binding.\n -- slurmrestd - Avoid permission denied errors when attempting to listen on\n    the same port multiple times.\n -- Fix GRES reservations where the GRES has no topology\n    (no cores= in gres.conf).\n -- Ensure that thread_id_rpc is gone before priority_g_fini().\n -- Fix scontrol reboot timeout removing drain state from nodes.\n -- squeue - Print header on empty response to `--only-job-state`.\n -- Fix slurmrestd not ending job properly when xauth is not present and a x11\n    job is sent.\n -- Add experimental job state caching with\n    SchedulerParameters=enable_job_state_cache to speed up querying job states\n    with squeue --only-job-state.\n -- slurmrestd - Correct dumping of invalid ArrayJobIds returned from\n    'GET /slurm/v0.0.40/jobs/state'.\n -- squeue - Correct dumping of invalid ArrayJobIds returned from\n    `squeue --only-job-state --{json|yaml}`.\n -- If scancel --ctld is not used with --interactive, --sibling, or specific\n    step ids, then this option issues a single request to the slurmctld to\n    signal all jobs matching the specified filters. This greatly improves\n    the performance of slurmctld and scancel. The updated --ctld option also\n    fixes issues with the --partition or --reservation scancel options for jobs\n    that requested multiple partitions or reservations.\n -- slurmrestd - Give EINVAL error when failing to parse signal name to numeric\n    signal.\n -- slurmrestd - Allow ContentBody for all methods per RFC7230 even if ignored.\n -- slurmrestd - Add 'DELETE /slurm/v0.0.40/jobs' endpoint to allow bulk job\n    signaling via slurmctld.\n -- Fix combination of --nodelist and --exclude not always respecting the\n    excluded node list.\n -- Fix jobs incorrectly allocating nodes exclusively when started on a\n    partition that doesn't enforce it. This could happen if a multi-partition\n    job doesn't specify --exclusive and is evaluated first on a partition\n    configured with OverSubscribe=EXCLUSIVE but ends up starting in a partition\n    configured with OverSubscribe!=EXCLUSIVE evaluated afterwards.\n -- Setting GLOB_SILENCE flag no longer exposes old bugged behavior.\n -- Fix associations AssocGrpCPURunMinutes being incorrectly computed for\n    running jobs after a controller reconfiguration/restart.\n -- Fix scheduling jobs that request --gpus and nodes have different node\n    weights and different numbers of gpus.\n -- slurmrestd - Add \"NO_CRON_JOBS\" as possible flag value to the following:\n      'DELETE /slurm/v0.0.40/jobs' flags field.\n      'DELETE /slurm/v0.0.40/job/{job_id}?flags=' flags query parameter.\n -- Fix scontrol segfault/assert failure if the TRESPerNode parameter is used\n    when creating reservations.\n -- Avoid checking for wsrep_on when restoring streaming replication settings.\n -- Clarify in the logs that error \"1193 Unknown system variable 'wsrep_on'\" is\n    innocuous.\n -- accounting_storage/mysql - Fix problem when loading reservations from an\n    archive dump.\n -- slurmdbd - Fix minor race condition when sending updates to a shutdown\n    slurmctld.\n -- slurmctld - Fix invalid refusal of a reservation update.\n -- openapi - Fix memory leak of /meta/slurm/cluster response field.\n -- Fix memory leak when using auth/slurm and AuthInfo=use_client_ids.\n\n* Changes in Slurm 23.11.5\n==========================\n -- Fix Debian package build on systems that are not able to query the systemd\n    package.\n -- data_parser/v0.0.40 - Emit a warning instead of an error if a disabled\n    parser is invoked.\n -- slurmrestd - Improve handling when content plugins rely on parsers\n    that haven't been loaded.\n -- Fix old pending jobs dying (Slurm version 21.08.x and older) when upgrading\n    Slurm due to \"Invalid message version\" errors.\n -- Have client commands sleep for progressively longer periods when backed off\n    by the RPC rate limiting system.\n -- slurmctld - Ensure agent queue is flushed correctly at shutdown time.\n -- slurmdbd - correct lineage construction during assoc table conversion for\n    partition based associations.\n -- Add new RPCs and API call for faster querying of job states from slurmctld.\n -- slurmrestd - Add endpoint '/slurm/{data_parser}/jobs/state'.\n -- squeue - Add `--only-job-state` argument to use faster query of job states.\n -- Make a job requesting --no-requeue, or JobRequeue=0 in the slurm.conf,\n    supersede RequeueExit[Hold].\n -- Add sackd man page to the Debian package.\n -- Fix issues with tasks when a job was shrunk more than once.\n -- Fix reservation update validation that resulted in reject of correct\n    updates of reservation when the reservation was running jobs.\n -- Fix possible segfault when the backup slurmctld is asserting control.\n -- Fix regression introduced in 23.02.4 where slurmctld was not properly\n    tracking the total GRES selected for exclusive multi-node jobs, potentially\n    and incorrectly bypassing limits.\n -- Fix tracking of jobs typeless GRES count when multiple typed GRES with the\n    same name are also present in the job allocation. Otherwise, the job could\n    bypass limits configured for the typeless GRES.\n -- Fix tracking of jobs typeless GRES count when request specification has a\n    typeless GRES name first and then typed GRES of different names (i.e.\n    --gres=gpu:1,tmpfs:foo:2,tmpfs:bar:7). Otherwise, the job could bypass\n    limits configured for the generic of the typed one (tmpfs in the example).\n -- Fix batch step not having SLURM_CLUSTER_NAME filled in.\n -- slurmstepd - Avoid error during `--container` job cleanup about\n    RunTimeQuery never being configured. Results in cleanup where job steps not\n    fully started.\n -- Fix nodes not being rebooted when using salloc/sbatch/srun \"--reboot\" flag.\n -- Send scrun.lua in configless mode.\n -- Fix rejecting an interactive job whose extra constraint request cannot\n    immediately be satisfied.\n -- Fix regression in 23.11.0 when parsing LogTimeFormat=iso8601_ms that\n    prevented milliseconds from being printed.\n -- Fix issue where you could have a gpu allocated as well as a shard on that\n    gpu allocated at the same time.\n -- Fix slurmctld crashes when using extra constraints with job arrays.\n -- sackd/slurmrestd/scrun - Avoid memory leak on new unix socket connection.\n -- The failed node field is filled when a node fails but does not time out.\n -- topology/block - Implement topology_p_generate_node_ranking().\n -- slurmrestd - Remove requiring job script field and job component script\n    fields to both be populated in the `POST /slurm/v0.0.40/job/submit`\n    endpoint as there can only be one batch step script for a job.\n -- slurmrestd - When job script is provided in '.jobs[].script' and '.script'\n    fields, the '.script' field's value will be used in the\n    `POST /slurm/v0.0.40/job/submit` endpoint.\n -- slurmrestd - Reject HetJob submission missing or empty batch script for\n    first Het component in the `POST /slurm/v0.0.40/job/submit` endpoint.\n -- slurmrestd - Reject job when empty batch script submitted to the\n    POST /slurm/v0.0.40/job/submit` endpoint.\n -- Fix pam_slurm and pam_slurm_adopt when using auth/slurm.\n -- slurmrestd - Add 'cores_per_socket' field to\n    `POST /slurm/v0.0.40/job/submit` endpoint.\n -- Fix srun and other Slurm commands running within a \"configless\" salloc when\n    salloc itself fetched the config.\n -- Enforce binding with shared gres selection if requested.\n -- Fix job allocation failures when the requested tres type or name ends in\n    \"gres\" or \"license\".\n -- accounting_storage/mysql - Fix lineage string construction when adding a\n    user association with a partition.\n -- Fix sattach command.\n -- Fix ReconfigFlags. Due how reconfig was changed in 23.11, they will also\n    be used to influence the slurmctld startup as well.\n -- Fix starting slurmd in configless mode if MUNGE support was disabled.\n\n* Changes in Slurm 23.11.4\n==========================\n -- Fix a memory leak when updating partition nodes.\n -- Don't leave a partition around if it fails to create with scontrol.\n -- Fix segfault when creating partition with bad node list from scontrol.\n -- Fix preserving partition nodes on bad node list update from scontrol.\n -- Fix assertion in developer mode on a failed message unpack.\n -- Fix repeat POWER_DOWN requests making the nodes available for ping.\n -- Fix rebuilding job alias_list on restart when nodes are still powering up.\n -- Fix INVALID nodes running health check.\n -- Fix cloud/future nodes not setting addresses on invalid registration.\n -- scrun - Remove the requirement to set the SCRUN_WORKING_DIR environment\n    variable. This was a regression in 23.11.\n -- Add warning for using select/linear with topology/tree.\n    This combination will not be supported in the next major version.\n -- Fix health check program not being run after first pass of all nodes when\n    using MaxNodeCount.\n -- sacct - Set process exit code to one for all errors.\n -- Add SlurmctldParameters=disable_triggers option.\n -- Fix issue running steps when the allocation requested an exclusive\n    allocation shards along with shards.\n -- Fix cleaning up the sleep process and the cgroup of the extern step if\n    slurm_spank_task_post_fork returns an error.\n -- slurm_completion - Add missing --gres-flags= options\n    multiple-tasks-per-sharing and one-task-per-sharing.\n -- scrun - Avoid race condition that could cause outbound network\n    communications to incorrectly rejected with an incomplete packet error.\n -- scrun - Gracefully handle kernel giving invalid expected number of incoming\n    bytes for a connection causing incoming packet corruption resulting in\n    connection getting closed.\n -- srun - return 1 when a step launch fails\n -- scrun - Avoid race condition that could cause deadlock during shutdown.\n -- Fix scontrol listpids to work under dynamic node scenarios.\n -- Add --tres-bind to --help and --usage output.\n -- Add --gres-flags=allow-task-sharing to allow GPUs to still be accessible\n    among all tasks when binding GPUs to specific tasks.\n -- Fix issue with CUDA_VISIBLE_DEVICES showing the same MIG device for all\n    tasks when using MIGs with --tres-per-task or --gpus-per-task.\n -- slurmctld - Prevent a potential hang during shutdown/reconfigure if the\n    association cache thread was previously shut down.\n -- scrun - Avoid race condition that could cause scrun to hang during\n    shutdown when connections have pending events.\n -- scrun - Avoid excessive polling of connections during shutdown that could\n    needlessly cause 100% CPU usage on a thread.\n -- sbcast - Use user identity from broadcast credential instead of looking it\n    up locally on the node.\n -- scontrol - Remove \"abort\" option handling.\n -- Fix an error message referring to the wrong RPC.\n -- Fix memory leak on error when creating dynamic nodes.\n -- Fix a slurmctld segfault when a cloud/dynamic node changes hostname on\n    registration.\n -- Prevent a slurmctld deadlock if the gpu plugin fails to load when\n    creating a node.\n -- Change a slurmctld fatal() to an error() when attempting to create a\n    dynamic node with a global autodetect set in gres.conf.\n -- Fix leaving node records on error when creating nodes with scontrol.\n -- scrun/sackd - Avoid race condition where shutdown could deadlock.\n -- Fix a regression in 23.02.5 that caused pam_slurm_adopt to fail when\n    the user has multiple jobs on a node.\n -- Add GLOB_SILENCE flag that silences the error message which will display if\n    an include directive attempts to use the \"*\" wildcard.\n -- Fix jobs getting rejected when submitting with --gpus option from older\n    versions of job submission commands (23.02 and older).\n -- cgroup/v2 - Return 0 for VSZ. Kernel cgroups do not provide this metric.\n -- scrun - Avoid race condition where outbound RPCs could be corrupted.\n -- scrun - Avoid race condition that could cause a crash while compiled in\n    debug mode.\n -- gpu/rsmi - Disable gpu usage statistics when not using ROCM 6.0.0+\n -- Fix stuck processes and incorrect environment when using --get-user-env.\n -- Avoid segfault in the slurmdbd when TrackWCKey=no but you are still using\n    use WCKeys.\n -- Fix ctld segfault with TopologyParam=RoutePart and no partition defined.\n -- slurmctld - Fix missing --deadline handling for jobs not evaluated by the\n    schedulers (i.e. non-runnable, skipped for other reasons, etc.).\n -- Demote some eio related logs from error to verbose in user commands.  These\n    are not generally actionable by the user and are easily generated by port\n    scanning a machine running srun.\n -- Make sprio correctly print array tasks that have not yet been split out.\n -- topology/block - Restrict the number of last-level blocks in any allocation.\n -- slurmrestd - Treat multiple repeat URL query values as list.\n -- slurmrestd - Treat all URL query values as string by default to avoid\n    parser warnings.\n\n* Changes in Slurm 23.11.3\n==========================\n -- Fix debian/changelog file to reflect the correct version so the packages\n    are generated correctly.\n\n* Changes in Slurm 23.11.2\n==========================\n -- slurmrestd - Reject single http query with multiple path requests.\n -- Fix launching Singularity v4.x containers with srun --container by setting\n    .process.terminal to true in generated config.json when step has\n    pseudoterminal (--pty) requested.\n -- Fix loading in dynamic/cloud node jobs after net_cred expired.\n -- Fix cgroup null path error on slurmd/slurmstepd tear down.\n -- data_parser/v0.0.40 - Prevent failure if accounting is disabled, instead\n    issue a warning if needed data from the database can not be retrieved.\n -- openapi/slurmctld - Prevent failure if accounting is disabled.\n -- Prevent slurmscriptd processing delays from blocking other threads in\n    slurmctld while trying to launch various scripts. This is additional work\n    for a fix in 23.02.6.\n -- Fix memory leak when receiving alias addrs from controller.\n -- scontrol - Accept `scontrol token lifespan=infinite` to create tokens that\n    effectively do not expire.\n -- Avoid errors when Slurmdb accounting disabled when '--json' or '--yaml' is\n    invoked with CLI commands and slurmrestd. Add warnings when query would\n    have populated data from Slurmdb instead of errors.\n -- Fix slurmctld memory leak when running job with --tres-per-task=gres:shard:#\n -- Fix backfill trying to start jobs outside of backfill window.\n -- Fix oversubscription on partitions with PreemptMode=OFF.\n -- Preserve node reason on power up if the node is downed or drained.\n -- data_parser/v0.0.40 - Avoid aborting when invoking a not implemented\n    parser.\n -- data_parser/v0.0.40 - Fix how nice values are parsed for job submissions.\n -- data_parser/v0.0.40 - Fix regression where parsing error did not result in\n    invalid request being rejected.\n -- Fix segfault in front-end node registration.\n -- Prevent jobs using none typed gpus from being killed by the controller after\n    a reconfig or restart.\n -- Fix deadlock situation in the dbd when adding associations.\n -- Update default values of text/blob columns when updating from old mysql\n    versions in more situations.  This improves a previous fix to handle an\n    uncommon case when upgrading mysql/mariadb.\n -- Fix rpmbuild in openSUSE/SLES due to incorrect mariadb dependency.\n -- Fix compilation on RHEL 7.\n -- When upgrading the slurmdbd to 23.11, avoid generating a query to update\n    the association table that is larger than max_allowed_packet which would\n    result in an upgrade failure.\n -- Fix rare deadlock when a dynamic node registers at the same time that a\n    once per minute background task occurs.\n -- Fix build issue on 32-bit systems.\n -- data_parser/v0.0.40 - Fix enumerated strings in OpenAPI specification not\n    have type field specified.\n -- Improve scontrol show job -d information of used shared gres (shard/mps)\n    topology.\n -- Allow Slurm to compile without MUNGE if --without-munge is used as an\n    argument to configure.\n -- accounting_storage/mysql - Fix usage query to use new lineage column\n    instead of lft/rgt.\n -- slurmrestd - Improve handling of missing parsers when content plugins\n    expect parsers not loaded.\n -- slurmrestd - Correct parsing of StepIds when querying jobs.\n -- slurmrestd - Improve error from parsing failures of lists.\n -- slurmrestd - Improve parsing of singular values for lists.\n -- accounting_storage/mysql - Fix PrivateData=User when listing associations.\n -- Disable sorting of dynamic nodes to avoid issues when restarting with\n    heterogeneous jobs that cause jobs to abort on restart.\n -- Don't allow deletion of non-dynamic nodes.\n -- accounting_storage/mysql - Fix issue adding partition based associations.\n -- Respect non-\"slurm\" settings for I_MPI_HYDRA_BOOTSTRAP and HYDRA_BOOTSTRAP\n    and avoid injecting the --external-launcher option which will cause\n    mpirun/mpiexec to fail with an unexpected argument error.\n -- Fix bug where scontrol hold would change node count for jobs with\n    implicitly defined node counts.\n -- data_parser/v0.0.40 - Fix regression of support for \"hold\" in\n    job description.\n -- Avoid sending KILL RPCs to unresolvable POWERING_UP and POWERED_DOWN nodes.\n -- data_parser/v0.0.38 - Fix several potential NULL dereferences that could\n    cause slurmrestd to crash.\n -- Add --gres-flags=one-task-per-sharing. Do not allow different tasks in to be\n    allocated shared gres from the same sharing gres.\n -- Add SelectTypeParameters=ENFORCE_BINDING_GRES and ONE_TASK_PER_SHARING_GRES.\n    This gives default behavior for a job's --gres-flags.\n -- Alter the networking code to try connecting to the backup controllers\n    if the DNS lookup for the primary SlurmctldHost fails.\n -- Alter the name resolution to only log at verbose() in client commands\n    on failures. This allows for HA setups where the DNS entries are withdrawn\n    for some SlurmctldHost entries without flooding the user with errors.\n -- Prevent slurmscriptd PID leaks when running slurmctld in foreground mode.\n -- Open all slurmctld listening ports at startup, and persist throughout.\n    This also changes the backup slurmctld process to open the SlurmctldPort\n    range, instead of only the first.\n -- Fix backup slurmctld shutting down instead of resuming standby duty if it\n    took control.\n -- Fix race condition that delayed the primary slurmctld resuming when taking\n    control from a backup controller.\n -- srun - Ensure processed messages are meant for this job in case of a\n    rapidly-reused TCP port.\n -- srun - Prevent step launch failure while waiting for step allocation if\n    a stray message is received.\n -- Fix backup slurmctld to be able to respond to configless config file\n    requests correctly.\n -- Fix slurmctld crashing when recovering from a failed reconfigure.\n -- Fix slurmscriptd operation after recovering from a failed reconfigure.\n\n* Changes in Slurm 23.11.1\n==========================\n -- Fix scontrol update job=... TimeLimit+=/-= when used with a raw JobId of job\n    array element.\n -- Reject TimeLimit increment/decrement when called on job with\n    TimeLimit=UNLIMITED.\n -- Fix slurmctld segfault when reconfiguring after a job resize.\n -- Fix compilation on FreeBSD.\n -- Fix issue with requesting a job with --licenses as well as\n    --tres-per-task=license.\n -- slurmctld - Prevent segfault in getopt_long() with an invalid long option.\n -- Switch to man2html-base in Build-Depends for Debian package.\n -- slurmrestd - Added /meta/slurm/cluster field to responses.\n -- Adjust systemd service files to start daemons after remote-fs.target.\n -- Add \"--with selinux\" option to slurm.spec.\n -- Fix task/cgroup indexing tasks in cgroup plugins, which caused\n    jobacct/gather to match the gathered stats with the wrong task id.\n -- select/linear - Fix regression in 23.11 in which jobs that requested\n    --cpus-per-task were rejected.\n -- Fix crash in slurmstepd that can occur when launching tasks via mpi using\n    the pmi2 plugin and using the route/topology plugin.\n -- Fix sgather not gathering from all nodes when using CR_PACK_NODES/--m pack.\n -- Fix mysql query syntax error when getting jobs with private data.\n -- Fix sanity check to prevent deleting default account of users.\n -- data_parser/v0.0.40 - Fix the parsing for /slurmdb/v0.0.40/jobs exit_code\n    query parameter.\n -- Fix issue where TRES for energy wasn't always set before sending it to the\n    jobcomp plugin.\n -- jobcomp/[kafka|elastisearch] Print raw TRES values along with the\n    formatted versions as tres_[req|alloc]_raw.\n -- Fix inconsistencies with --cpu-bind/SLURM_CPU_BIND and --hint/SLURM_HINT.\n -- Fix ignoring invalid json in various subsystems.\n -- Remove shebang from bash completion script.\n -- Fix elapsed time in JobComp being set from invalid start and end times.\n -- Update service files to start slurmd, slurmctld, and slurmdbd after sssd.\n -- data_parser/v0.0.40 - Fix output of DefMemPerCpu, MaxMemPerCpu, and\n    max_shares.\n -- When determining a jobs index in the database don't wait if there are more\n    jobs waiting.\n -- If a job requests more shards which would allocate more than one sharing\n    GRES (gpu) per node refuse it unless SelectTypeparameters has\n    MULTIPLE_SHARING_GRES_PJ.\n -- Avoid refreshing the hwloc xml file when slurmd is reconfigured. This fixes\n    an issue seen with CoreSpecCount used on nodes with Intel E-cores.\n -- Trigger fatal exit when Slurm API function is called before slurm_init() is\n    called.\n -- slurmd - Fix issue with 'scontrol reconfigure' when started with '-c'.\n -- data_parser/v0.0.40 - Fix handling of negative job nice values.\n -- data_parser/v0.0.40 - Fill the \"id\" object for associations with the\n    cluster, account, partition, and user in addition to the assoc id.\n -- data_parser/v0.0.40 - Remove unusable cpu_binding_flags enums from\n    v00.0.40_job_desc_msg.\n -- Improve performance and resiliency of slurmscriptd shutdown on\n    'scontrol reconfigure'.\n -- slurmrestd - Job submissions that result in the following error codes\n    will be considered as successfully submitted (with a warning), instead\n    of returning an HTTP 500 error back:\n    ESLURM_NODES_BUSY, ESLURM_RESERVATION_BUSY, ESLURM_JOB_HELD,\n    ESLURM_NODE_NOT_AVAIL, ESLURM_QOS_THRES, ESLURM_ACCOUNTING_POLICY,\n    ESLURM_RESERVATION_NOT_USABLE, ESLURM_REQUESTED_PART_CONFIG_UNAVAILABLE,\n    ESLURM_BURST_BUFFER_WAIT, ESLURM_PARTITION_DOWN,\n    ESLURM_LICENSES_UNAVAILABLE.\n -- Fix issue with node appearing to reboot on every \"scontrol reconfigure\"\n    when slurmd was started with the '-b' flag.\n -- Fix a slurmctld fatal error when upgrading to 23.11 and changing from\n    select/cons_res to select/cons_tres at the same time.\n -- slurmctld - Fix subsequent reconfigure hanging after a failed reconfigure.\n -- slurmctld - Reject arbitrary distribution jobs that have a minimum node\n    count that differs from the number of unique nodes in the hostlist.\n -- Prevent slurmdbd errors when updating reservations with names containing\n    apostrophes.\n -- Prevent message extension attacks that could bypass the message hash.\n    CVE-2023-49933.\n -- Prevent SQL injection attacks in slurmdbd. CVE-2023-49934.\n -- Prevent message hash bypass in slurmd which can allow an attacker to reuse\n    root-level MUNGE tokens and escalate permissions. CVE-2023-49935.\n -- Prevent NULL pointer dereference on size_valp overflow. CVE-2023-49936.\n -- Prevent double-xfree() on error in _unpack_node_reg_resp().\n    CVE-2023-49937.\n\n* Changes in Slurm 23.11.0\n==========================\n -- For jobs that request --cpus-per-gpu, ensure that the --cpus-per-gpu request\n    is honored on every node in the and not just for the job as a whole.\n -- Fix \"srun -Z\" for cred/munge and cred/none.\n -- Fix listing available data_parser plugins for json and yaml when giving no\n    commands to scontrol or sacctmgr.\n -- data_parser/v0.0.40 - Fixed how deleted QOS and associations for jobs are\n    dumped.\n -- data_parser/v0.0.40 - Fix how errors and warnings are dumped.\n -- Print consistent errors when serializer plugin fails to load.\n -- data_parser/v0.0.40 - Fix parsing of flag arrays to allow multiple flags to\n    be set.\n -- slurmctld - Rework 'scontrol reconfigure' to avoid race conditions that\n    can result in stray jobs.\n -- slurmctld - Shave ~1 second off average reconfigure time by terminating\n    internal processing threads faster.\n -- Skip running slurmdbd -R if the connected cluster is 23.11 or newer.\n    This operation is nolonger relevant for 23.11.\n -- Fix segfault when updating node instance id/type without accounting enabled.\n -- Ensure slurmscriptd shuts down before slurmctld is stopped / reconfigured.\n -- Improve error handling and error messages in slurmctld to slurmscriptd\n    communications. This includes avoiding potential deadlock in slurmctld if\n    slurmscript dies unexpectedly.\n -- Do not hold batch jobs whose extra constraints cannot be immediately\n    satisfied, and set the state reason to \"Constraints\" instead of\n    \"BadConstraints\".\n -- Fix verbose log message printing a hex number instead of a job id.\n -- Upgrade rate limit parameters message from debug to info.\n -- Fix missing symbols for those linking to libslurm.\n -- Fix memory leak when getting and forwarding addrs from client.\n -- Fix xassert when forwarding to non-addressable nodes.\n -- Fix regression in 23.11.0rc1 where assocs were created with an incorrect\n    hierarchy for non-23.11 clusters.\n -- For SchedulerParameters=extra_constraints, prevent slurmctld segfault when\n    starting a slurmd with --extra for a node that did not previously set this.\n    This also ensures the extra constraints model works off the current node\n    state, not the prior state.\n -- Fix regression in 23.11.0rc1 where data_t would not decode negative float\n    values correctly, instead the absolute value was always returned.\n -- Fix issue where 'scontrol reconfigure' right as the controller was started\n    or reconfigured could lead to it shutting down completely.\n -- Fix --tres-per-task assertion.\n -- Fix a few issues when creating reservations.\n -- Fix slurmctld segfault when packing a job step loaded from a < 23.11 state.\n -- Fix a 32-bit compile issue.\n -- Add SchedulerParameters=time_min_as_soft_limit option.\n\n* Changes in Slurm 23.11.0rc1\n=============================\n -- task/affinity - remove Power7 cpu-specific workarounds.\n -- Remove SLURM_WORKING_CLUSTER env from batch and srun environments.\n -- cli_filter/lua - return nil for unset time options rather than the string\n    \"2982616-04:14:00\" (which is the internal macro \"NO_VAL\" represented as\n    time string).\n -- Remove 'none' plugins for all but auth and cred. scontrol show config\n    will report (null) now.\n -- Removed select/cons_res. Please update your configuration to\n    select/cons_tres.\n -- mpi/pmix - When aborted with status 0, avoid marking job/step as failed.\n -- Fixed typo on \"initialized\" for the description of ESLURM_PLUGIN_NOT_LOADED.\n -- Added max_submit_line_size to SchedulerParameters.\n -- Change TreeWidth default from 50 to 16.\n -- cgroup.conf - Removed deprecated parameters AllowedKmemSpace,\n    ConstrainKmemSpace, MaxKmemPercent, and MinKmemSpace.\n -- proctrack/cgroup - Add \"SignalChildrenProcesses=<yes|no>\" option to\n    cgroup.conf. This allows signals for cancelling, suspending, resuming, etc.\n    to be sent to children processes in a step/job rather than just the parent.\n -- Add PreemptParameters=suspend_grace_time parameter to control amount of\n    time between SIGTSTP and SIGSTOP signals when suspending jobs.\n -- job_submit/throttle - improve reset of submitted job counts per user in\n    order to better honor SchedulerParameters=jobs_per_user_per_hour=#.\n -- Load the user environment into a private pid namespace to avoid user scripts\n    leaving background processes on a node.\n -- scontrol show assoc_mgr will display Lineage instead of Lft for\n    associations.\n -- Add SlurmctldParameters=no_quick_restart to avoid a new slurmctld taking\n    over the old slurmctld on accident.\n -- Fix --cpus-per-gpu for step allocations, which was previously ignored for\n    job steps. --cpus-per-gpu implies --exact.\n -- Fix mutual exclusivity of --cpus-per-gpu and --cpus-per-task: fatal if both\n    options are requested in the commandline or both are requested in the\n    environment. If one option is requested in the command line, it will\n    override the other option in the environment.\n -- slurmrestd - openapi/dbv0.0.37 and openapi/v0.0.37 plugins have been\n    removed.\n -- slurmrestd - openapi/dbv0.0.38 and openapi/v0.0.38 plugins have been tagged\n    as deprecated.\n -- openapi/slurmctld - forked from openapi/v0.0.38.\n -- openapi/slurmdbd - forked from openapi/dbv0.0.38.\n -- data_parser/v0.0.40 - forked from data_parser/v0.0.39 plugin.\n -- data_parser/v0.0.40 - added OpenAPI schema generation of path parameters\n    and OperationIds.\n -- slurmrestd - added auto population of info/version field.\n -- openapi/slurmctld - convert to using data_parser plugins for all input and\n    output formatting.\n -- openapi/slurmdbd - convert to using data_parser plugins for all input and\n    output formatting.\n -- data_parser/v0.0.39 - skip empty string when parsing QOS ids.\n -- data_parser/v0.0.40 - skip empty string when parsing QOS ids.\n -- data_parser/v0.0.40 - log errors on every level of parsing on failure.\n -- sdiag - add --yaml and --json arg support to specify data_parser plugin.\n -- sacct - add --yaml and --json arg support to specify data_parser plugin.\n -- scontrol - add --yaml and --json arg support to specify data_parser plugin.\n -- sinfo - add --yaml and --json arg support to specify data_parser plugin.\n -- squeue - add --yaml and --json arg support to specify data_parser plugin.\n -- data_parser/v0.0.40 - add warnings for unknown fields during parsing.\n -- data_parser/v0.0.40 - add FAST parameter to allow requester to skip more\n    time intensive warning checks.\n -- Changed the default SelectType to select/cons_tres (from select/linear).\n -- Allow SlurmUser/root to use reservations without specific permissions.\n -- Fix sending step signals to nodes not allocated by the step.\n -- Remove CgroupAutomount= option from cgroup.conf.\n -- Add TopologyRoute=RoutePart to route communications based on partition node\n    lists.\n -- SPANK - added new spank_prepend_task_argv() function.\n -- slurmd - improve error logging at job startup during transition from slurmd\n    to slurmstepd.\n -- Added ability for configless to push Prolog and Epilog scripts to slurmds.\n -- Prolog and Epilog do not have to be fully qualified pathnames.\n -- Changed default value of PriorityType from priority/basic to\n    priority/multifactor.\n -- torque/mpiexec - Propagate exit code from launched process.\n -- slurmrestd - Add new rlimits fields for job submission.\n -- data_parser/v0.0.40 - convert job state field to flag array to provide\n    enumeration of values.\n -- sbatch - removed --export-file option (used with defunct Moab integration).\n -- Define SPANK options environment variables when --export=[NIL|NONE] is\n    specified.\n -- slurmrestd - Numeric input fields provided with a null formatted value will\n    now convert to zero (0) where it can be a valid value. This is expected to\n    be only be notable with job submission against v0.0.38 versioned endpoints\n    with job requests with fields provided with null values. These fields were\n    already rejected by v0.0.39+ endpoints, unless +complex parser value is\n    provided to v0.0.40+ endpoints.\n -- slurmrestd - Improve parsing of integers and floating point numbers when\n    handling incoming user provided numeric fields. Fields that would have not\n    rejected a number for a numeric field followed by other non-numeric\n    characters will now get rejected. This is expected to be only be notable\n    with job submission against v0.0.38 versioned endpoints with malformed job\n    requests.\n -- Reject reservation update if it will result in previously submitted\n    jobs losing access to the reservation.\n -- data_parser/v0.0.40 - output partition state when dumping partitions.\n -- Allow for a shared suffix to be used with the hostlist format. E.g.,\n    \"node[0001-0010]-int\".\n -- Fix perlapi build when using non-default libdir.\n -- Replace SRUN_CPUS_PER_TASK with SLURM_CPUS_PER_TASK and get back the\n    previous behavior before Slurm 22.05 since now we have the new external\n    launcher step.\n -- data_parser/v0.0.40 - Change v0.0.40_job_info response to tag exit_code\n    field as verbose job exit code object.\n -- data_parser/v0.0.40 - Change v0.0.40_job_info response to tag\n    derived_exit_code field as verbose job exit code object.\n -- Avoid database upgrade failures with galera by enabling streaming\n    replication for Galera 4 clusters during the upgrade process.\n -- job_container/tmpfs - disable plugin for nodes that are not listed in\n    job_container.conf when there is no global BasePath set.\n -- job_container/tmpfs - Add \"BasePath=none\" option to disable plugin on node\n    subsets when there is a global setting.\n -- Remove cloud_reg_addrs and make it default behavior.\n -- Remove NoAddrCache CommunicationParameter.\n -- Add QOS flag 'Relative'. If set the QOS limits will be treated as\n    percentages of a cluster/partition instead of absolutes.\n -- Remove FIRST_CORES flag from reservations.\n -- scontrol/sview - Remove comma separated CoreCnt option from reservations.\n -- scontrol/sview - Remove comma separated NodeCnt option from reservations.\n -- Add cloud instance id and instance type to node records. Can be viewed/\n    updated with scontrol.\n -- slurmd - add \"instance-id\", \"instance-type\", and \"extra\" options to allow\n    them to be set on startup.\n -- Add cloud instance accounting to database that can be viewed with 'sacctmgr\n    show instance'.\n -- openapi/v0.0.40 - add /instance and /instances endpoints.\n -- SelectTypeParameters=cr_cpu - Fix a log error \"CPU underflow\" at step\n    completion for steps that request --threads-per-core or\n    --hint=nomultithread.\n -- select/linear - fix task launch failure that sometimes occurred when\n    requesting --threads-per-core or --hint=nomultithread. This also fixes\n    memory calculation with one of these options and --mem-per-cpu:\n    Previously, memory = mem-per-cpu * all cpus including unusable threads.\n    Now, memory = mem-per-cpu * only usable threads. This behavior matches\n    the documentation and select/cons_tres.\n -- gpu/nvml - Reduce chances of NVML_ERROR_INSUFFICIENT_SIZE error when getting\n    gpu memory information.\n -- slurmrestd - Convert to generating OperationIDs based on path for all\n    v0.0.40 tagged paths.\n -- slurmrestd - Reduce memory used while dumping a job's stdio paths.\n -- slurmrestd - Jobs queried from data_parser/v0.0.40 from slurmdb will have\n    'step/id' field given as a string to match CLI formatting instead of an\n    object.\n -- sacct - Output in JSON or YAML output will will have the 'step/id' field\n    given as a string instead of an object.\n -- scontrol/squeue - Step output in JSON or YAML output will will have the\n    'id' field given as a string instead of an object.\n -- slurmrestd - For 'GET /slurmdb/v0.0.40/jobs' mimic default behavior for\n    handling of job start and end times as sacct when one or both fields are\n    not provided as a query parameter.\n -- openapi/slurmctld - Add 'GET /slurm/v0.0.40/shares' endpoint to dump same\n    output as sshare.\n -- sshare - add JSON/YAML support.\n -- data_parser/v0.0.40 - Remove \"required/memory\" output in json. It is\n    replaced by \"required/memory_per_cpu\" and \"required/memory_per_node\".\n -- slurmrestd - Add numeric id to all association identifiers to allow unique\n    identification where association has been deleted but is still referenced by\n    accounting record.\n -- slurmrestd - Add accounting, id, and comment fields to association dumps.\n -- slurmrestd - Removed usage field from association dumps which was never\n    populated. See accounting field for accounting usage records.\n -- slurmrestd - Default to not query associations or coordinators with\n    'GET /slurmdb/v0.0.40/accounts'.\n -- slurmrestd - Default to not query associations, wckeys or coordinators with\n    'GET /slurmdb/v0.0.40/user'.\n -- slurmrestd - Enforce user's default wckey on supplied list of user wckeys in\n    'POST /slurmdb/v0.0.40/user' queries to avoid conflicting or changed default\n    wckey from being ignored.\n -- slurmrestd - Enforce user's default wckey on supplied list of user wckeys in\n    'POST /slurmdb/v0.0.40/user' queries to avoid conflicting or changed default\n    wckey from being ignored.\n -- slurmrestd - 'POST /slurm/v0.0.40/job/submit' will return \"step_id\" as\n    string to provide descriptive step names (batch, extern, interactive, TBD)\n    for non-numeric steps.\n -- slurmrestd - Tagged \"result\" field from 'POST /slurm/v0.0.40/job/submit'\n    as deprecated.\n -- slurmrestd - Warning will be added for rejected job submissions with\n    submissions to 'POST /slurm/v0.0.40/job/submit'.\n -- slurmrestd - Tagged \"job_id\", \"step_id\", and \"job_submit_user_msg\" fields\n    from 'POST /slurm/v0.0.40/job/{job_id}' response as deprecated due their\n    only being valid for the first entry in the \"result\" field array.\n -- slurmrestd - Warning will be added for rejected job updates with\n    queries to 'POST /slurm/v0.0.40/job/{job_id}'.\n -- slurmrestd - Add SLURMRESTD_JSON and SLURMRESTD_YAML input environment\n    variables.\n -- slurmrestd - Correct issue where field and $ref description fields were not\n    getting populated for OpenAPI specification generation for queries to\n    'GET /openapi/v3' for v0.0.40 endpoints.\n -- slurmdbd - Check for innodb_redo_log_capacity instead of\n    innodb_log_file_size in MySQL 8.0.30+.\n -- slurmrestd - Fix log level requests SLURMRESTD_DEBUG and -v applying on top\n    of each other and the default logging level (info). -v now applies on top\n    of the default log level, and SLURMRESTD_DEBUG sets the log level if -v is\n    not given.\n -- slurmrestd - Allow SLURMRESTD_DEBUG=quiet or 0, which was previously denied.\n    Also deny negative values for SLURMRESTD_DEBUG, which previously set the\n    debug level to debug5.\n -- The backup slurmctld now checks that the heartbeat file exists in\n    StateSaveLocation before starting and attempting to assert control.\n    This avoids issues with misconfiguration, or the shared filesystem being\n    unavailable, that could previously have lead to all jobs being cancelled.\n -- The warning printed when using configure --without-PACKAGE has been changed\n    to a notice.\n -- Fix --cpu-freq with userspace governor and frequency ranges behavior.\n -- Fix --cpu-freq parsing with incorrect frequencies.\n -- PMIx support is nolonger built by default.  Passing --with-pmix option is\n    now required to build with PMIx.\n -- Use memory.current in cgroup/v2 instead of manually calculating RSS. This\n    makes accounting consistent with OOM Killer.\n -- Update slurmstepd processes with current SlurmctldHost settings, allowing\n    for controller changes without draining all compute jobs.\n -- Add format_stderr to LogTimeFormat of slurm.conf and slurmdbd.conf.\n -- slurmrestd - add `GET /slurm/v0.0.40/reconfigure` endpoint to allow\n    equivalent requests of `scontrol reconfigure`.\n -- sreport - cluster Utilization PlannedDown field now includes the time that\n    all nodes were in the POWERED_DOWN state instead of just cloud nodes.\n -- scontrol update partition now allows Nodes+=<node-list> and\n    Nodes-=<node-list> to add/delete nodes from the existing partition node\n    list. Nodes=+host1,-host2 is also allowed.\n -- sacctmgr - add --yaml and --json arg support to specify data_parser plugin.\n -- slurmrestd - Add last_update and last_backfill fields to response to\n    `GET /slurm/v0.0.40/job` and `GET /slurm/v0.0.40/jobs` queries.\n -- slurmrestd - Add last_update fields to response to\n    `GET /slurm/v0.0.40/node` and `GET /slurm/v0.0.40/nodes` queries.\n -- slurmrestd - Add last_update fields to response to\n    `GET /slurm/v0.0.40/partition` and `GET /slurm/v0.0.40/partitions` queries.\n -- slurmrestd - Add last_update fields to response to\n    `GET /slurm/v0.0.40/licenses` query.\n -- auth/jwt - fatal when jwt or jwks key files are writable by other.\n -- sacctmgr can now modify QOS's RawUsage to zero or a positive value.\n -- sdiag - Added statistics on why the main and backfill schedulers have\n    stopped evaluation on each scheduling cycle.\n -- openapi/v0.0.40 - add /{accounts,users}_association endpoints.\n -- slurm.spec - Add `--with yaml` argument to require YAML support.\n -- Add new rl_log_freq option to SlurmctldParameters to allow sites to limit\n    the number of 'RPC limit exceeded...' messages that are logged.\n -- Rename sbcast --fanout to --treewidth.\n -- Remove SLURM_NODE_ALIASES env variable.\n -- Enable fanout for dynamic and unaddresable cloud nodes.\n -- Fix how steps are dealloced in an allocation if the last step of an srun\n    never completes due to a node failure.\n -- Remove redundant database indexes.\n -- Add database index to suspend table to speed up archive/purges.\n -- When requesting --tres-per-task alter incorrect request for TRES,\n    it should be TRESType/TRESName not TRESType:TRESName.\n -- Make it so reservations can reserve GRES.\n -- switch/hpe_slingshot - Add disable_rdzv_get flag to disable rendezvous gets.\n -- slurmrestd - Avoid matching query URLs based on partial matches to an\n    existing endpoint, e.g. POST request to /slurm/v0.0.40/job was routed\n    to the handler of POST /slurm/v0.0.40/job/submit.\n -- Don't display old job_arrays/het_jobs in sacct if Job ID was reused.\n -- sbcast - use the specified --fanout value on all hops in message\n    forwarding; previously the specified fanout was only used on the first hop,\n    and additional hops used TreeWidth in slurm.conf.\n -- slurmrestd - remove logger prefix from '-s/-a list' options outputs.\n -- Fix fd socket name resolution which could flood log files at debug level.\n -- The rpmbuild \"--with mysql\" option has been removed. The rpm has long\n    required sql development libraries to build and the existence of this option\n    was confusing. The default behavior now is to always require one of the sql\n    development libraries.\n -- Add support for Debian packaging.\n -- switch/hpe_slingshot - Add support for collectives.\n -- Nodes with suspended jobs can now be displayed as MIXED.\n -- sview - Fix search by node state returning incorrect node list.\n -- Fix inconsistent handling of using cli and/or environment options for\n    tres_per_task=cpu:# and cpus_per_gpu.\n -- Requesting --cpus-per-task will now set SLURM_TRES_PER_TASK=cpu:# in the\n    environment.\n -- For some tres related environment variables such as SLURM_TRES_PER_TASK,\n    when srun requests a different value for that option, set these environment\n    variables to the value requested by srun. Previously these environment\n    variables were unchanged from the job allocation. This bug only affected the\n    output environment variables, not the actual step resource allocation.\n -- RoutePlugin=route/topology has been replaced with TopologyParam=RouteTree.\n -- If ThreadsPerCore in slurm.conf is configured with less\n    than the number of hardware threads, fix a bug where the task plugins used\n    fewer cores instead of using fewer threads per core.\n -- Fix arbitrary distribution allowing it to be used with salloc and sbatch and\n    fix how cpus are allocated to nodes.\n -- Allow nodes to reboot while node is drained or in a maintenance state.\n -- Allow scontrol reboot to use nodesets to filter nodes to reboot.\n -- Fix how the topology of typed gres gets updated.\n -- Changes to the Type option in gres.conf now can be applied with scontrol\n    reconfig.\n -- Allow for jobs that request a newly configured gres type to be queued\n    even when the needed slurmds have not yet registered.\n -- Kill recovered jobs that require unconfigured gres types.\n -- If keepalives are configured, enable them on all persistent connections.\n -- data_parser/v0.0.40 - add parsers for main/backfill cycle exit reasons.\n -- Configless - Also send Includes from configuration files not parsed by the\n    controller (i.e. from plugstack.conf).\n -- Add gpu/nrt plugin for nodes using Trainium/Inferentia devices.\n -- data_parser/v0.0.40 - Add START_RECEIVED to job flags in dumped output.\n -- SPANK - Failures from most spank functions (not epilog or exit) will now\n    cause the step to be marked as failed and the command (srun, salloc,\n    sbatch --wait) to return 1.\n -- data_parser/v0.0.40 - Fix how the \"INVALID\" nodes state is dumped.\n -- Add SchedulerParameters=extra_constraints. This enables various node\n    filtering options in the --extra flag of salloc, sbatch, and srun.\n -- Improve scontrol show node -d information of used shared gres (shard/mps)\n    topology.\n\n* Changes in Slurm 23.02.9\n==========================\n -- sattach - Fix regression from 23.02.8 security fix leading to crash.\n\n* Changes in Slurm 23.02.8\n==========================\n -- Fix rare deadlock when a dynamic node registers at the same time that a\n    once per minute background task occurs.\n -- Fix assertion in developer mode on a failed message unpack.\n -- switch/hpe_slingshot - Fix security issue around managing VNI access.\n    CVE-2024-42511.\n\n* Changes in Slurm 23.02.7\n==========================\n -- libslurm_nss - Avoid causing glibc to assert due to an unexpected return\n    from slurm_nss due to an error during lookup.\n -- Fix job requests with --tres-per-task sometimes resulting in bad allocations\n    that cannot run subsequent job steps.\n -- Fix issue with slurmd where srun fails to be warned when a node prolog\n    script runs beyond MsgTimeout set in slurm.conf.\n -- gres/shard - Fix plugin functions to have matching parameter orders.\n -- gpu/nvml - Fix issue that resulted in the wrong MIG devices being\n    constrained to a job\n -- gpu/nvml - Fix linking issue with MIGs that prevented multiple MIGs being\n    used in a single job for certain MIG configurations\n -- Add JobAcctGatherParams=DisableGPUAcct to disable gpu accounting.\n -- Fix file descriptor leak in slurmd when using acct_gather_energy/ipmi with\n    DCMI devices.\n -- sview - avoid crash when job has a node list string > 49 characters.\n -- Prevent slurmctld crash during reconfigure when packing job start messages.\n -- Preserve reason uid on reconfig.\n -- Update node reason with updated INVAL state reason if different from last\n    registration.\n -- acct_gather_energy/ipmi - Improve logging of DCMI issues.\n -- conmgr - Avoid NULL dereference when using auth/none.\n -- data_parser/v0.0.39 - Fixed how deleted QOS and associations for jobs are\n    dumped.\n -- burst_buffer/lua - fix stage in counter not decrementing when a job is\n    cancelled during stage in. This counter is used to enforce the limit of 128\n    scripts per stage.\n -- gpu/oneapi - Add support for new env vars ZE_FLAT_DEVICE_HIERARCHY and\n    ZE_ENABLE_PCI_ID_DEVICE_ORDER.\n -- data_parser/v0.0.39 - Fix how the \"INVALID\" nodes state is dumped.\n -- data_parser/v0.0.39 - Fix parsing of flag arrays to allow multiple flags to\n    be set.\n -- Avoid leaking sockets when an x11 application is closed in an allocation.\n -- Fix missing mutex unlock in group cache code which could cause slurmctld to\n    freeze.\n -- Fix scrontab monthly jobs possibly skipping a month if added near the end of\n    the month.\n -- Fix loading of the gpu account gather energy plugin.\n -- Fix slurmctld segfault when reconfiguring after a job resize.\n -- Fix crash in slurmstepd that can occur when launching tasks via mpi using\n    the pmi2 plugin and using the route/topology plugin.\n -- data_parser/v0.0.39 - skip empty string when parsing QOS ids.\n -- Fix \"qos <id> doesn't exist\" error message in assoc_mgr_update_assocs to\n    print the attempted new default qos, rather than the current default qos.\n -- Remove error message from assoc_mgr_update_assocs when purposefully\n    resetting the default qos.\n -- data_parser/v0.0.39 - Fix segfault when POSTing data with association usage.\n -- Prevent message extension attacks that could bypass the message hash.\n    CVE-2023-49933.\n -- Prevent message hash bypass in slurmd which can allow an attacker to reuse\n    root-level MUNGE tokens and escalate permissions. CVE-2023-49935.\n -- Prevent NULL pointer dereference on size_valp overflow. CVE-2023-49936.\n -- Prevent double-xfree() on error in _unpack_node_reg_resp(). CVE-2023-49937.\n -- Prevent modified sbcast RPCs from opening a file with the wrong group\n    permissions. CVE-2023-49938.\n\n* Changes in Slurm 23.02.6\n==========================\n -- Fix CpusPerTres= not upgreadable with scontrol update\n -- Fix unintentional gres removal when validating the gres job state.\n -- Fix --without-hpe-slingshot configure option.\n -- Fix cgroup v2 memory calculations when transparent huge pages are used.\n -- Fix parsing of sgather --timeout option.\n -- Fix regression from 22.05.0 that caused srun --cpu-bind \"=verbose\" and \"=v\"\n    options give different CPU bind masks.\n -- Fix \"_find_node_record: lookup failure for node\" error message appearing\n    for all dynamic nodes during reconfigure.\n -- Avoid segfault if loading serializer plugin fails.\n -- slurmrestd - Correct OpenAPI format for 'GET /slurm/v0.0.39/licenses'.\n -- slurmrestd - Correct OpenAPI format for 'GET /slurm/v0.0.39/job/{job_id}'.\n -- slurmrestd - Change format to multiple fields in 'GET\n    /slurmdb/v0.0.39/assocations' and 'GET /slurmdb/v0.0.39/qos' to handle\n    infinite and unset states.\n -- When a node fails in a job with --no-kill, preserve the extern step on the\n    remaining nodes to avoid breaking features that rely on the extern step\n    such as pam_slurm_adopt, x11, and job_container/tmpfs.\n -- auth/jwt - Ignore 'x5c' field in JWKS files.\n -- auth/jwt - Treat 'alg' field as optional in JWKS files.\n -- Allow job_desc.selinux_context to be read from the job_submit.lua script.\n -- Skip check in slurmstepd that causes a large number of errors in the munge\n    log: \"Unauthorized credential for client UID=0 GID=0\".  This error will\n    still appear on slurmd/slurmctld/slurmdbd start up and is not a cause for\n    concern.\n -- slurmctld - Allow startup with zero partitions.\n -- Fix some mig profile names in slurm not matching nvidia mig profiles.\n -- Prevent slurmscriptd processing delays from blocking other threads in\n    slurmctld while trying to launch {Prolog|Epilog}Slurmctld.\n -- Fix sacct printing ReqMem field when memory doesn't exist in requested TRES.\n -- Fix how heterogeneous steps in an allocation with CR_PACK_NODE or -mpack are\n    created.\n -- Fix slurmctld crash from race condition within job_submit_throttle plugin.\n -- Fix --with-systemdsystemunitdir when requesting a default location.\n -- Fix not being able to cancel an array task by the jobid (i.e. not\n    <jobid>_<taskid>) through scancel, job launch failure or prolog failure.\n -- Fix cancelling the whole array job when the array task is the meta job and\n    it fails job or prolog launch and is not requeable. Cancel only the\n    specific task instead.\n -- Fix regression in 21.08.2 where MailProg did not run for mail-type=end for\n    jobs with non-zero exit codes.\n -- Fix incorrect setting of memory.swap.max in cgroup/v2.\n -- Fix jobacctgather/cgroup collection of disk/io, gpumem, gpuutil TRES values.\n -- Fix -d singleton for heterogeneous jobs.\n -- Downgrade info logs about a job meeting a \"maximum node limit\" in the\n    select plugin to DebugFlags=SelectType. These info logs could spam the\n    slurmctld log file under certain circumstances.\n -- prep/script - Fix [Srun|Task]<Prolog|Epilog> missing SLURM_JOB_NODELIST.\n -- gres - Rebuild GRES core bitmap for nodes at startup. This fixes error:\n    \"Core bitmaps size mismatch on node [HOSTNAME]\", which causes jobs to enter\n    state \"Requested node configuration is not available\".\n -- slurmctd - Allow startup with zero nodes.\n -- Fix filesystem handling race conditions that could lead to an attacker\n    taking control of an arbitrary file, or removing entire directories'\n    contents. CVE-2023-41914.\n -- Return error when updating ArrayTaskThrottle on a non-ArrayJobId.\n\n* Changes in Slurm 23.02.5\n==========================\n -- Add the JobId to debug() messages indicating when cpus_per_task/mem_per_cpu\n    or pn_min_cpus are being automatically adjusted.\n -- Fix regression in 23.02.2 that caused slurmctld -R to crash on startup if\n    a node features plugin is configured.\n -- Fix and prevent reoccurring reservations from overlapping.\n -- job_container/tmpfs - Avoid attempts to share BasePath between nodes.\n -- Change the log message warning for rate limited users from verbose to info.\n -- With CR_Cpu_Memory, fix node selection for jobs that request gres and\n    --mem-per-cpu.\n -- Fix a regression from 22.05.7 in which some jobs were allocated too few\n    nodes, thus overcommitting cpus to some tasks.\n -- Fix a job being stuck in the completing state if the job ends while the\n    primary controller is down or unresponsive and the backup controller has\n    not yet taken over.\n -- Fix slurmctld segfault when a node registers with a configured CpuSpecList\n    while slurmctld configuration has the node without CpuSpecList.\n -- Fix cloud nodes getting stuck in POWERED_DOWN+NO_RESPOND state after not\n    registering by ResumeTimeout.\n -- slurmstepd - Avoid cleanup of config.json-less containers spooldir getting\n    skipped.\n -- slurmstepd - Cleanup per task generated environment for containers in\n    spooldir.\n -- Fix scontrol segfault when 'completing' command requested repeatedly in\n    interactive mode.\n -- Properly handle a race condition between bind() and listen() calls in the\n    network stack when running with SrunPortRange set.\n -- Federation - Fix revoked jobs being returned regardless of the -a/--all\n    option for privileged users.\n -- Federation - Fix canceling pending federated jobs from non-origin clusters\n    which could leave federated jobs orphaned from the origin cluster.\n -- Fix sinfo segfault when printing multiple clusters with --noheader option.\n -- Federation - fix clusters not syncing if clusters are added to a federation\n    before they have registered with the dbd.\n -- Change pmi2 plugin to honor the SrunPortRange option. This matches the new\n    behavior of the pmix plugin in 23.02.0. Note that neither of these plugins\n    makes use of the \"MpiParams=ports=\" option, and previously were only limited\n    by the systems ephemeral port range.\n -- node_features/helpers - Fix node selection for jobs requesting changeable\n    features with the '|' operator, which could prevent jobs from running on\n    some valid nodes.\n -- node_features/helpers - Fix inconsistent handling of '&' and '|', where an\n    AND'd feature was sometimes AND'd to all sets of features instead of just\n    the current set. E.g. \"foo|bar&baz\" was interpreted as {foo,baz} or\n    {bar,baz} instead of how it is documented: \"{foo} or {bar,baz}\".\n -- Fix job accounting so that when a job is requeued its allocated node count\n    is cleared. After the requeue, sacct will correctly show that the job has\n    0 AllocNodes while it is pending or if it is canceled before restarting.\n -- sacct - AllocCPUS now correctly shows 0 if a job has not yet received an\n    allocation or if the job was canceled before getting one.\n -- Fix intel oneapi autodetect: detect the /dev/dri/renderD[0-9]+ gpus, and do\n    not detect /dev/dri/card[0-9]+.\n -- Format batch, extern, interactive, and pending step ids into strings that\n    are human readable.\n -- Fix node selection for jobs that request --gpus and a number of tasks fewer\n    than gpus, which resulted in incorrectly rejecting these jobs.\n -- Remove MYSQL_OPT_RECONNECT completely.\n -- Fix cloud nodes in POWERING_UP state disappearing (getting set to FUTURE)\n    when an `scontrol reconfigure` happens.\n -- openapi/dbv0.0.39 - Avoid assert / segfault on missing coordinators list.\n -- slurmrestd - Correct memory leak while parsing OpenAPI specification\n    templates with server overrides.\n -- slurmrestd - Reduce memory usage when printing out job CPU frequency.\n -- Fix overwriting user node reason with system message.\n -- Remove --uid / --gid options from salloc and srun commands.\n -- Prevent deadlock when rpc_queue is enabled.\n -- slurmrestd - Correct OpenAPI specification generation bug where fields with\n    overlapping parent paths would not get generated.\n -- Fix memory leak as a result of a partition info query.\n -- Fix memory leak as a result of a job info query.\n -- slurmrestd - For 'GET /slurm/v0.0.39/node[s]', change format of node's\n    energy field \"current_watts\" to a dictionary to account for unset value\n    instead of dumping 4294967294.\n -- slurmrestd - For 'GET /slurm/v0.0.39/qos', change format of QOS's\n    field \"priority\" to a dictionary to account for unset value instead of\n    dumping 4294967294.\n -- slurmrestd - For 'GET /slurm/v0.0.39/job[s]', the 'return code' code field\n    in v0.0.39_job_exit_code will be set to -127 instead of being left unset\n    where job does not have a relevant return code.\n -- data_parser/v0.0.39 - Add required/memory_per_cpu and\n    required/memory_per_node to `sacct --json` and `sacct --yaml` and\n    'GET /slurmdb/v0.0.39/jobs' from slurmrestd.\n -- For step allocations, fix --gres=none sometimes not ignoring gres from the\n    job.\n -- Fix --exclusive jobs incorrectly gang-scheduling where they shouldn't.\n -- Fix allocations with CR_SOCKET, gres not assigned to a specific socket, and\n    block core distribion potentially allocating more sockets than required.\n -- gpu/oneapi - Store cores correctly so CPU affinity is tracked.\n -- Revert a change in 23.02.3 where Slurm would kill a script's process group\n    as soon as the script ended instead of waiting as long as any process in\n    that process group held the stdout/stderr file descriptors open. That change\n    broke some scripts that relied on the previous behavior. Setting time limits\n    for scripts (such as PrologEpilogTimeout) is strongly encouraged to avoid\n    Slurm waiting indefinitely for scripts to finish.\n -- Allow slurmdbd -R to work if the root assoc id is not 1.\n -- Fix slurmdbd -R not returning an error under certain conditions.\n -- slurmdbd - Avoid potential NULL pointer dereference in the mysql plugin.\n -- Revert a change in 23.02 where SLURM_NTASKS was no longer set in the job's\n    environment when --ntasks-per-node was requested.\n -- Limit periodic node registrations to 50 instead of the full TreeWidth.\n    Since unresolvable cloud/dynamic nodes must disable fanout by setting\n    TreeWidth to a large number, this would cause all nodes to register at\n    once.\n -- Fix regression in 23.02.3 which broken x11 forwarding for hosts when\n    MUNGE sends a localhost address in the encode host field. This is caused\n    when the node hostname is mapped to 127.0.0.1 (or similar) in /etc/hosts.\n -- openapi/[db]v0.0.39 - fix memory leak on parsing error.\n -- data_parser/v0.0.39 - fix updating qos for associations.\n -- openapi/dbv0.0.39 - fix updating values for associations with null users.\n -- Fix minor memory leak with --tres-per-task and licenses.\n -- Fix cyclic socket cpu distribution for tasks in a step where\n    --cpus-per-task < usable threads per core.\n\n* Changes in Slurm 23.02.4\n==========================\n -- Fix sbatch return code when --wait is requested on a job array.\n -- switch/hpe_slingshot - avoid segfault when running with old libcxi.\n -- Avoid slurmctld segfault when specifying AccountingStorageExternalHost.\n -- Fix collected GPUUtilization values for acct_gather_profile plugins.\n -- Fix slurmrestd handling of job hold/release operations.\n -- Make spank S_JOB_ARGV item value hold the requested command argv instead of\n    the srun --bcast value when --bcast requested (only in local context).\n -- Fix step running indefinitely when slurmctld takes more than MessageTimeout\n    to respond. Now, slurmctld will cancel the step when detected, preventing\n    following steps from getting stuck waiting for resources to be released.\n -- Fix regression to make job_desc.min_cpus accurate again in job_submit when\n    requesting a job with --ntasks-per-node.\n -- scontrol - Permit changes to StdErr and StdIn for pending jobs.\n -- scontrol - Reset std{err,in,out} when set to empty string.\n -- slurmrestd - mark environment as a required field for job submission\n    descriptions.\n -- slurmrestd - avoid dumping null in OpenAPI schema required fields.\n -- data_parser/v0.0.39 - avoid rejecting valid memory_per_node formatted as\n    dictionary provided with a job description.\n -- data_parser/v0.0.39 - avoid rejecting valid memory_per_cpu formatted as\n    dictionary provided with a job description.\n -- slurmrestd - Return HTTP error code 404 when job query fails.\n -- slurmrestd - Add return schema to error response to job and license query.\n -- Fix handling of ArrayTaskThrottle in backfill.\n -- Fix regression in 23.02.2 when checking gres state on slurmctld startup or\n    reconfigure. Gres changes in the configuration were not updated on slurmctld\n    startup. On startup or reconfigure, these messages were present in the log:\n    \"error: Attempt to change gres/gpu Count\".\n -- Fix potential double count of gres when dealing with limits.\n -- switch/hpe_slingshot - support alternate traffic class names with \"TC_\"\n    prefix.\n -- scrontab - Fix cutting off the final character of quoted variables.\n -- Fix slurmstepd segfault when ContainerPath is not set in oci.conf\n -- Change the log message warning for rate limited users from debug to verbose.\n -- Fixed an issue where jobs requesting licenses were incorrectly rejected.\n -- smail - Fix issues where e-mails at job completion were not being sent.\n -- scontrol/slurmctld - fix comma parsing when updating a reservation's nodes.\n -- cgroup/v2 - Avoid capturing log output for ebpf when constraining devices,\n    as this can lead to inadvertent failure if the log buffer is too small.\n -- Fix --gpu-bind=single binding tasks to wrong gpus, leading to some gpus\n    having more tasks than they should and other gpus being unused.\n -- Fix main scheduler loop not starting after failover to backup controller.\n -- Added error message when attempting to use sattach on batch or extern steps.\n -- Fix regression in 23.02 that causes slurmstepd to crash when srun requests\n    more than TreeWidth nodes in a step and uses the pmi2 or pmix plugin.\n -- Reject job ArrayTaskThrottle update requests from unprivileged users.\n -- data_parser/v0.0.39 - populate description fields of property objects in\n    generated OpenAPI specifications where defined.\n -- slurmstepd - Avoid segfault caused by ContainerPath not being terminated by\n    '/' in oci.conf.\n -- data_parser/v0.0.39 - Change v0.0.39_job_info response to tag exit_code\n    field as being complex instead of only an unsigned integer.\n -- job_container/tmpfs - Fix %h and %n substitution in BasePath where %h was\n    substituted as the NodeName instead of the hostname, and %n was substituted\n    as an empty string.\n -- Fix regression where --cpu-bind=verbose would override TaskPluginParam.\n -- scancel - Fix --clusters/-M for federations. Only filtered jobs (e.g. -A,\n    -u, -p, etc.) from the specified clusters will be canceled, rather than all\n    jobs in the federation. Specific jobids will still be routed to the origin\n    cluster for cancellation.\n -- Add SelectTypeParameters=LL_SHARED_GRES.\n\n* Changes in Slurm 23.02.3\n==========================\n -- Fix regression in 23.02.2 that ignored the partition DefCpuPerGPU setting\n    on the first pass of scheduling a job requesting --gpus --ntasks.\n -- openapi/dbv0.0.39/users - If a default account update failed, resulting in a\n    no-op, the query returned success without any warning. Now a warning is sent\n    back to the client that the default account wasn't modified.\n -- srun - fix issue creating regular and interactive steps because\n    *_PACK_GROUP* environment variables were incorrectly set on non-HetSteps.\n -- Fix dynamic nodes getting stuck in allocated states when reconfiguring.\n -- Avoid job write lock when nodes are dynamically added/removed.\n -- burst_buffer/lua - allow jobs to get scheduled sooner after\n    slurm_bb_data_in completes.\n -- mpi/pmix - fix regression introduced in 23.02.2 which caused PMIx shmem\n    backed files permissions to be incorrect.\n -- api/submit - fix memory leaks when submission of batch regular jobs or batch\n    HetJobs fails (response data is a return code).\n -- openapi/v0.0.39 - fix memory leak in _job_post_het_submit().\n -- Fix regression in 23.02.2 that set the SLURM_NTASKS environment variable\n    in sbatch jobs from --ntasks-per-node when --ntasks was not requested.\n -- Fix regression in 23.02 that caused sbatch jobs to set the wrong number\n    of tasks when requesting --ntasks-per-node without --ntasks, and also\n    requesting one of the following options: --sockets-per-node,\n    --cores-per-socket, --threads-per-core (or --hint=nomultithread), or\n    -B,--extra-node-info.\n -- Fix double counting suspended job counts on nodes when reconfiguring, which\n    prevented nodes with suspended jobs from being powered down or rebooted\n    once the jobs completed.\n -- Fix backfill not scheduling jobs submitted with --prefer and --constraint\n    properly.\n -- Avoid possible slurmctld segfault caused by race condition with already\n    completed slurmdbd_conn connections.\n -- Slurmdbd.conf checks included conf files for 0600 permissions\n -- slurmrestd - fix regression \"oversubscribe\" fields were removed from job\n    descriptions and submissions from v0.0.39 end points.\n -- accounting_storage/mysql - Query for individual QOS correctly when you have\n    more than 10.\n -- Add warning message about ignoring --tres-per-tasks=license when used\n    on a step.\n -- sshare - Fix command to work when using priority/basic.\n -- Avoid loading cli_filter plugins outside of salloc/sbatch/scron/srun. This\n    fixes a number of missing symbol problems that can manifest for executables\n    linked against libslurm (and not libslurmfull).\n -- Allow cloud_reg_addrs to update dynamically registered node's addrs on\n    subsequent registrations.\n -- switch/hpe_slingshot - Fix hetjob components being assigned different vnis.\n -- Revert a change in 22.05.5 that prevented tasks from sharing a core if\n    --cpus-per-task > threads per core, but caused incorrect accounting and cpu\n    binding. Instead, --ntasks-per-core=1 may be requested to prevent tasks from\n    sharing a core.\n -- Correctly send assoc_mgr lock to mcs plugin.\n -- Fix regression in 23.02 leading to error() messages being sent at INFO\n    instead of ERR in syslog.\n -- switch/hpe_slingshot - Fix bad instant-on data due to incorrect parsing of\n    data from jackaloped.\n -- Fix TresUsageIn[Tot|Ave] calculation for gres/gpumem and gres/gpuutil.\n -- Avoid unnecessary gres/gpumem and gres/gpuutil TRES position lookups.\n -- Fix issue in the gpu plugins where gpu frequencies would only be set if both\n    gpu memory and gpu frequencies were set, while one or the other suffices.\n -- Fix reservations group ACL's not working with the root group.\n -- slurmctld - Fix backup slurmctld crash when it takes control multiple times.\n -- Fix updating a job with a ReqNodeList greater than the job's node count.\n -- Fix inadvertent permission denied error for --task-prolog and --task-epilog\n    with filesystems mounted with root_squash.\n -- switch/hpe_slingshot - remove the unused vni_pids option.\n -- Fix missing detailed cpu and gres information in json/yaml output from\n    scontrol, squeue and sinfo.\n -- Fix regression in 23.02 that causes a failure to allocate job steps that\n    request --cpus-per-gpu and gpus with types.\n -- sacct - when printing PLANNED time, use end time instead of start time for\n    jobs cancelled before they started.\n -- Fix potentially waiting indefinitely for a defunct process to finish,\n    which affects various scripts including Prolog and Epilog. This could have\n    various symptoms, such as jobs getting stuck in a completing state.\n -- Hold the job with \"(Reservation ... invalid)\" state reason if the\n    reservation is not usable by the job.\n -- Fix losing list of reservations on job when updating job with list of\n    reservations and restarting the controller.\n -- Fix nodes resuming after down and drain state update requests from\n    clients older than 23.02.\n -- Fix advanced reservation creation/update when an association that should\n    have access to it is composed with partition(s).\n -- auth/jwt - Fix memory leak.\n -- sbatch - Added new --export=NIL option.\n -- Fix job layout calculations with --ntasks-per-gpu, especially when --nodes\n    has not been explicitly provided.\n -- Fix X11 forwarding for jobs submitted from the slurmctld host.\n -- When a job requests --no-kill and one or more nodes fail during the job,\n    fix subsequent job steps unable to use some of the remaining resources\n    allocated to the job.\n -- Fix shared gres allocation when using --tres-per-task with tasks that span\n    multiple sockets.\n\n* Changes in Slurm 23.02.2\n==========================\n -- Fix regression introduced with the migration to interfaces which caused\n    sshare to core dump. Sshare now initialized the priority context correctly\n    when calculating with PriorityFlags=NO_FAIR_TREE.\n -- Fix IPMI DCMI sensor initialization.\n -- For the select/cons_tres plugin, improve the best effort GPU to core\n    binding, for requests with per job task count (-n) and GPU (--gpus)\n    specification.\n -- scrontab - don't update the cron job tasks if the whole crontab file is\n    left untouched after opening it with \"scrontab -e\".\n -- mpi/pmix - avoid crashing when running PMIx v5.0 branch with shmem support.\n -- Fix building switch topology after a reconfig with the correct nodes.\n -- Allow a dynamic node to register with a reason, using --conf, when the\n    state is DOWN or DRAIN.\n -- Fix slurmd running tasks before RPC Prolog is run.\n -- Fix slurmd deadlock iff the controller were to give a bad alias_list.\n -- slurmrestd - correctly process job submission field \"exclusive\" with boolean\n    True or False.\n -- slurmrestd - correctly process job submission field \"exclusive\" with strings\n    \"true\" or \"false\".\n -- slurmctld/step_mgr - prevent non-allocatable steps from decrementing values\n    that weren't previously incremented when trying to allocate them.\n -- auth/jwt - Fix memory leak in slurmctld with 'scontrol token'.\n -- Fix shared gres (shard/mps) leak when using --tres-per-task\n -- Fix sacctmgr segfault when listing accounts with coordinators.\n -- slurmrestd - improve error logging when client connections experience\n    polling errors.\n -- slurmrestd - improve handling of sockets in different states of shutdown to\n    avoid infinite poll() loop causing a thread to max CPU usage until process\n    is killed.\n -- slurmrestd - avoid possible segfault caused by race condition of already\n    completed connections.\n -- mpi/cray_shasta - Fix PMI shared secret for hetjobs.\n -- gpu/oneapi - Fix CPU affinity handling.\n -- Fix dynamic nodes powering up when already up after adding/deleting nodes\n    when using power_save logic.\n -- slurmrestd - Add support for setting max connections.\n -- data_parser/v0.0.39 - fix sacct --json matching associations from a\n    different cluster.\n -- Fix segfault when clearing reqnodelist of a pending job.\n -- Fix memory leak of argv when submitting jobs via slurmrestd or CLI commands.\n -- slurmrestd - correct miscalculation of job argument count that could cause\n    memory leak when job submission fails.\n -- slurmdbd - add warning on startup if max_allowed_packet is too small.\n -- gpu/nvml - Remove E-cores from NVML's cpu affinity bitmap when\n    \"allow_ecores\" is not set in SlurmdParameters.\n -- Fix regression from 23.02.0rc1 causing a FrontEnd slurmd to assert fail on\n    startup and don't be configured with the appropriate port.\n -- Fix dynamic nodes not being sorted and not being included in topology,\n    which resulted in suboptimal dynamic node selection for jobs.\n -- Fix slurmstepd crash due to potential division by zero (SIGFPE) in certain\n    edge-cases using the PMIx plugin.\n -- Fix issue with PMIx HetJob requests where certain use-cases would end up\n    with communication errors due to incorrect PMIx hostname info setup.\n -- openapi/v0.0.39 - revert regression in job update requests to accept job\n    description for changes instead of requiring job description in \"job\" field.\n -- Fix regression in 23.02.0rc1 that caused a step to crash with a bad\n    --gpu-bind=single request.\n -- job_container/tmpfs - skip more in-depth attempt to clean up the base path\n    when not required.  This prevents unhelpful, and possibly misleading, debug2\n    messages when not using the new \"shared\" mode.\n -- gpu/nvml - Fix gpu usage when graphics processes are running on the gpu.\n -- slurmrestd - fix regression where \"exclusive\" field was removed from job\n    descriptions and submissions.\n -- Fix issue where requeued jobs had bad gres allocations leading to gres not\n    being deallocated at the end of the job, preventing other jobs from using\n    those resources.\n -- Fix regression in 23.02.0rc1 which caused incorrect values for\n    SLURM_TASKS_PER_NODE when the job requests --ntasks-per-node and --exclusive\n    or --ntasks-per-core=1 (or CR_ONE_TASK_PER_CORE) and without requesting\n    --ntasks. SLURM_TASKS_PER_NODE is used by mpirun, so this regression\n    caused mpirun to launch the wrong number of tasks and to sometimes fail to\n    launch tasks.\n -- Prevent jobs running on shards from being canceled on slurmctld restart.\n -- Fix SPANK prolog and epilog hooks that rely on slurm_init() for access to\n    internal Slurm API calls.\n -- oci.conf - Populate %m pattern with ContainerPath or SlurmdSpoolDir if\n    ContainerPath is not configured.\n -- Removed zero padding for numeric values in container spool directory names.\n -- Avoid creating an unused task-4294967295 directory in container spooldir.\n -- Cleanup container step directories at step completion.\n -- sacctmgr - Fix segfault when printing empty tres.\n -- srun - fix communication issue that prevented slurmctld from connecting to\n    an srun running outside of a compute node.\n\n* Changes in Slurm 23.02.1\n==========================\n -- job_container/tmpfs - cleanup job container even if namespace mount is\n    already unmounted.\n -- When cluster specific tables are be removed also remove the job_env_table\n    and job_script_table.\n -- Fix the way bf_max_job_test is applied to job arrays in backfill.\n -- data_parser/v0.0.39 - Avoid dumping -1 value or NULL when step's\n    consumed_energy is unset.\n -- scontrol - Fix showing Array Job Steps.\n -- scontrol - Fix showing Job HetStep.\n -- openapi/dbv0.0.38 - Fix not displaying an error when updating QOS or\n    associations fails.\n -- data_parser/v0.0.39 - Avoid crash while parsing composite structures.\n -- sched/backfill - fix deleted planned node staying in planned node bitmap.\n -- Fix nodes remaining as PLANNED after slurmctld save state recovery.\n -- Fix parsing of cgroup.controllers file with a blank line at the end.\n -- Add cgroup.conf EnableControllers option for cgroup/v2.\n -- Get correct cgroup root to allow slurmd to run in containers like Docker.\n -- Fix \"(null)\" cluster name in SLURM_WORKING_CLUSTER env.\n -- slurmctld - add missing PrivateData=jobs check to step ContainerID lookup\n    requests originated from 'scontrol show step container-id=<id>' or certain\n    scrun operations when container state can't be directly queried.\n -- Automatically sort the TaskPlugin list reverse-alphabetically. This\n    addresses an issue where cpu masks were reset if task/affinity was listed\n    before task/cgroup on cgroup/v2 systems with Linux kernel < 6.2.\n -- Fix some failed terminate job requests from a 23.02 slurmctld to a 22.05 or\n    21.08 slurmd.\n -- Fix compile issues on 32-bit systems.\n -- Fix nodes un-draining after being drained due to unkillable step.\n -- Fix remote licenses allowed percentages reset to 0 during upgrade.\n -- sacct - Avoid truncating time strings when using SLURM_TIME_FORMAT with\n    the --parsable option.\n -- data_parser/v0.0.39 - fix segfault when default qos is not set.\n -- Fix regression in 22.05.0rc1 that broke Nodes=ALL in a NodeSet.\n -- openapi/v0.0.39 - fix jobs submitted via slurmrestd being allocated fewer\n    CPUs than tasks when requesting multiple tasks.\n -- Fix job not being scheduled on valid nodes and potentially being rejected\n    when using parentheses at the beginning of square brackets in a feature\n    request, for example: \"feat1&[(feat2|feat3)]\".\n -- Fix a job being scheduled on nodes that do not match a feature request that\n    uses parentheses inside of brackets and requests additional features outside\n    of brackets, for example: \"feat1&[feat2|(feat3|feat4)]\".\n -- Fix regression in 23.02.0rc1 which made --gres-flags=enforce-binding no\n    longer enforce optimal core-gpu job placement.\n -- switch/hpe_slingshot - add option to disable VNI allocation per-job.\n -- switch/hpe_slingshot - restrict CXI services to the requesting user.\n -- switch/hpe_slingshot - Only output tcs once in SLINGSHOT_TCS env.\n -- switch/hpe_slingshot - Fix updating LEs and ACs limits.\n -- switch/hpe_slingshot - Use correct Max for EQs and CTs.\n -- switch/hpe_slingshot - support configuring network options per-job.\n -- switch/hpe_slingshot - retry destroying CXI service if necessary.\n -- Fix memory leak caused by job preemption when licenses are configured.\n -- mpi/pmix - Fix v5 to load correctly when libpmix.so isn't in the normal\n    lib path.\n -- data_parser/v0.0.39 - fix regression where \"memory_per_node\" would be\n    rejected for job submission.\n -- data_parser/v0.0.39 - fix regression where \"memory_per_cpu\" would be\n    rejected for job submission.\n -- slurmctld - add an assert to check for magic number presence before deleting\n    a partition record and clear the magic afterwards to better diagnose\n    potential memory problems.\n -- Clean up OCI containers task directories correctly.\n -- slurm.spec - add \"--with jwt\" option.\n -- scrun - Run under existing job when SLURM_JOB_ID is present.\n -- Prevent a slurmstepd crash when the I/O subsystem has hung.\n -- common/conmgr - fix memory leak of complete connection list.\n -- data_parser/v0.0.39 - fix memory leak when parsing every field in a struct.\n -- job_container/tmpfs - avoid printing extraneous error messages when running\n    a spank plugin that implements slurm_spank_job_prolog() or\n    slurm_spank_job_epilog().\n -- Fix srun < 23.02 always getting an \"exact\" core allocation.\n -- Prevent scontrol < 23.02 from setting MaxCPUsPerSocket to 0.\n -- Add ScronParameters=explicit_scancel and corresponding scancel --cron\n    option.\n\n* Changes in Slurm 23.02.0\n==========================\n -- scrun - Install into /bin instead of /sbin, which also ensures it is\n    included in the RPM packages.\n -- data_parser/v0.0.39 - avoid erroring on unknown association id.\n -- data_parser/v0.0.39 - avoid fatal while dumping TRES values.\n -- Improve error message for using --cpus-per-gpus without any GPUs.\n -- switch/hpe_slingshot - fix rolling upgrades from 22.05 to 23.02\n -- Change cgroup/v1 behavior when waiting for a pid to be moved by waiting some\n    time between retries. This helps with stray cgroup dirs on slow kernels.\n -- Workaround a bug in kernels < 3.18 with cpuset which randomly leaves stray\n    cgroups after jobs have ended.\n -- Rebuild the prepacked buf going to the slurmstepd if TRES changed.\n -- Add new 'make clean-contrib' target to build system to clean contribs dir.\n -- Treat newlines as delimiters for hostlist_create(). (This is used internally\n    by \"scontrol show hostlist\" and for handling SLURM_JOB_NODELIST.)\n -- scontrol - Print \"Invalid job id specified\" for 'scontrol show step ...'\n    when the job does not exist, rather than \"Unexpected error\".\n -- Handle mismatched TRES count from the slurmstepd's instead of fatal()'ing.\n -- Fix GPU setup on CRAY systems when using the CRAY_CUDA_MPS environment\n    variable. GPUs are now correctly detected in such scenarios.\n -- data_parser/v0.0.39 - improve flag handling to avoid flags having bits left\n    unset after parsing.\n -- topology/tree - Add new TopologyParam=SwitchAsNodeRank option to reorder\n    nodes based on switch layout. This can be useful if the naming convention\n    for the nodes does not natually map to the network topology.\n -- openapi/v0.0.38 - avoid signed math errors while dumping node resources.\n -- openapi/dbv0.0.39 - avoid error while dumping account coordinators.\n -- data_parser/v0.0.39 - correct dump of stats backfill mean table size.\n -- openapi/dbv0.0.39 - avoid error while adding account coordinators.\n -- scrun - catch invalid values of environment SCRUN_FILE_DEBUG.\n -- scrun - avoid memory leak due to invalid annotation.\n -- scrun - avoid false error when pidfile not requested.\n -- Do not constrain memory in task/cgroup unless CR_Memory is set.\n -- Fix the job prolog not running for jobs with the interactive step\n    (salloc jobs with LaunchParameters=use_interactive_step set in slurm.conf)\n    that were scheduled on powered down nodes. The prolog not running also\n    broke job_container/tmpfs, pam_slurm_adopt, and x11 forwarding.\n -- switch/hpe_slingshot - fix issues using 22.05 commands with 23.02 slurmd.\n -- switch/hpe_slingshot - avoid slurmd segfault if there is a protocol error.\n -- task/affinity - fix slurmd segfault when request launch task requests of\n    type \"--cpu-bind=[map,mask]_cpu:<list>\" have no <list> provided.\n -- salloc/sbatch/srun - error out if \"--cpu-bind=[map,mask]_cpu:<list>\" fails\n    to extract a list of cpus.\n -- job_container/tmpfs - cleanup job_mount when container creation fails.\n -- job_container/tmpfs - don't attempt to remove job_mount directory when it is\n    still mounted.\n -- Fix regression in rc1 causing sacctmgr to segfault when printing unrelated\n    fields.\n -- jobcomp/kafka - don't use the purge API if librdkafka < v1.0.0.\n -- Change shown start time of pending array job to be start time of earliest\n    pending array task.\n -- job_container/tmpfs - ensure that step_ns_fd is closed before cleaning up\n    the namespace.\n -- Fix assert when suspending or requeueing array tasks with scontrol.\n -- Fix federated job submissions.\n -- Fix sinfo returning non-zero exit code when querying specific clusters.\n -- openapi/v0.0.39 - correct OpenAPI schema for job update requests.\n -- openapi/v0.0.39 - prevent assertion on jobs endpoint by altering how the\n    \"memory_per_cpu\" and \"memory_per_node\" fields are managed.\n -- Fix regression in 23.02.0rc1 which caused slurmctld to segfault when\n    gres is added or removed in the configuration.\n -- Removed the default setting for GpuFreqDef. If unset, no attempt to change\n    the GPU frequency will be made if --gpu-freq is not set for the step.\n -- Fixed GpuFreqDef option. When set in slurm.conf, it will be used if\n    --gpu-freq was not explicitly set by the job step.\n -- Update database index for usage tables used for archive and purge.\n -- Fix configure script on FreeBSD.\n\n* Changes in Slurm 23.02.0rc1\n=============================\n -- Make scontrol reconfigure and sending a SIGHUP to the slurmctld behave the\n    same. If you were using SIGHUP as a 'lighter' scontrol reconfigure to rotate\n    logs please update your scripts to use SIGUSR2 instead.\n -- Add Account and QOS name type specifications for sprio output formatting.\n -- openapi/[db]v0.0.36 - plugins have been removed.\n -- openapi/[db]v0.0.37 - tagged as deprecated.\n -- openapi/[db]v0.0.39 - forked plugin openapi/[db]v0.0.38.\n -- Add SRUN_{ERROR,INPUT,OUTPUT} input environment variables for --error,\n    --input and --output options respectively.\n -- Add MaxCPUsPerSocket to partition configuration, similar to MaxCPUsPerNode.\n -- openapi/v0.0.39 - change nice request field from string to integer.\n -- sacctmgr - no longer force updates to the AdminComment, Comment, or\n    SystemComment to lower-case.\n -- openapi/dbv0.0.39 - more graceful handling of POSTs when expected field\n    lists are missing or unparsable.\n -- burst_buffer/lua - pass the job's UID and GID to slurm_bb_pre_run,\n    slurm_bb_data_in, slurm_bb_post_run, and slurm_bb_data_out in\n    burst_buffer.lua.\n -- openapi/v0.0.39 - add new field default_memory_per_node for partitions.\n -- Change cloud nodes to show by default. PrivateData=cloud is no longer\n    needed.\n -- Add -F/--future option to sinfo to display future nodes.\n -- openapi/dbv0.0.39 - resolve job user from uid when user is not provided.\n -- sacct/sinfo/squeue - use openapi/[db]v0.0.39 for --json and --yaml modes.\n -- sdiag - Add --json and --yaml arguments.\n -- Cgroupv2 plugin will not show \"Controller is not enabled\" error when started\n    from cmd.\n -- sreport - Count planned (FKA reserved) time for jobs running in IGNORE_JOBS\n    reservations. Previously was lumped into IDLE time.\n -- job_container/tmpfs - support running with an arbitrary list of private\n    mount points (/tmp and /dev/shm are nolonger required, but are the default).\n -- sacct - Rename 'Reserved' field to 'Planned' to match sreport and the\n    nomenclature of the 'Planned' node.\n -- oci.conf: Add %U as OCI pattern replacement to numeric user id.\n -- cli_filter/lua, jobcomp/lua, job_submit/lua - expose all Slurm error codes.\n -- jobcomp/elasticsearch - expose features field.\n -- jobcomp/elasticsearch - post non-NULL but empty string fields.\n -- Make advanced reservation flag MAINT not replace nodes, similar to\n    STATIC_ALLOC\n -- NVML - Add usage gathering for Nvidia gpus.\n -- node_features plugins - invalid users specified for AllowUserBoot will now\n    result in fatal() rather than just an error.\n -- job_container/tmpfs - Set more environment variables in InitScript.\n -- Make all cgroup directories created by Slurm owned by root.\n -- sbatch - add parsing of #PBS -d and #PBS -w.\n -- Avoid network receive error on heavily loaded machines where the network\n    operation can be restarted.\n -- Deprecate AllowedKmemSpace, ConstrainKmemSpace, MaxKmemPercent, and\n    MinKmemSpace.\n -- accounting_storage/mysql - change purge/archive to calculate record ages\n    based on end time, rather than start or submission times.\n -- Add strigger --draining and -R/--resume options.\n -- Allow updating SLURM_NTASKS environment variable (from scontrol update job).\n -- Limit het job license requests to the leader job only.\n -- Change --oversubscribe and --exclusive to be mutually exclusive for job\n    submission. Job submission commands will now fatal if both are set.\n    Previously, these options would override each other, with the last one in\n    the job submission command taking effect.\n -- job_submit/lua - add support for log_user() from slurm_job_modify().\n -- openapi/v0.0.39 - add submission of job->prefer value.\n -- Fix tasks binding to GPUs when using --ntasks-per-gpu and GPUs have\n    different core/socket affinity.\n -- Add support for padding StdOut/StdErr/StdIn format specifiers to scontrol\n    show job.\n--  Fix sacctmgr qos filter to properly select assocs by qos inheritance rules.\n -- Prevent slurmctld from starting with invalid jobcomp plugin.\n -- Fix `sinfo -i` and interactive `scontrol> show node` replies for nodes\n    going from powering down to powered down state.\n -- auth/jwt - support Azure (among other) JWKS files by preferring x5c field\n    over locally reconstructing an RSA256 key file.\n -- auth/jwt - add optional AuthAltParameters field \"userclaimfield=\" to allow\n    overriding \"sun\" claim to site specific field.\n -- scontrol - Requested TRES and allocated TRES will now always be printed when\n    showing jobs, instead of one TRES output that was either the requested or\n    allocated.\n -- Improve scheduling performance for dynamic nodes and nodes with features by\n    consolidating like config records.\n -- Expose argc and entire argv to job_submit and cli_filter plugins for jobs\n    submitted via salloc/srun or sbatch <script> (not via --wrap).\n -- Job command/script name is now packed with no arguments, thus clients\n    displaying job information will only show the command/script name.\n -- Make acct_gather_energy plugins handle slurmd reconfiguration and support\n    restart for gpu and xcc implementations.\n -- Fix --slurmd-debug to treat its argument as log level (as documented)\n    instead of previous approach with it being an offset to configured log\n    level.\n -- srun --slurmd-debug option is now only allowed for root and SlurmUser\n -- Change 'scontrol requeue' behavior for scron jobs to use cronspec to\n    determine the next start time.\n -- serializer/url-encoded - interpret query keys without a value (flags) to be\n    true instead of NULL.\n -- Add --autocomplete= option to all client commands.\n -- Allow for concurrent processing of job_submit_g_submit() and\n    job_submit_g_modify() calls.\n -- Allow jobs to queue even if the user is not in AllowGroups when\n    EnforcePartLimits=no is set. This ensures consistency for all the Partition\n    access controls, and matches the documented behavior for EnforcePartLimits.\n -- Fix srun tasks binding/allocation when using --ntasks-per-core option. Now,\n    --ntasks-per-core=1 implies --cpu-bind=cores and --ntasks-per-core>1 implies\n    --cpu-bind=threads.\n -- salloc/sbatch/srun check and abort if ntasks-per-core > threads-per-core.\n -- burst_buffer/lua - fix building heterogeneous job scripts where the\n    directive is not the default \"BB_LUA\".\n -- If a node is in a reservation add the reservation name to it for\n    scontrol/sinfo/sview.\n -- common/cgroup - improve possible TOCTOU situation when reading cgroup files.\n -- slurmctld will fatal() when reconfiguring the job_submit plugin fails.\n -- Add ResumeAfter=<secs> option to \"scontrol update nodename=\".\n -- slurmrestd - switch to returning UNPROCESSABLE_CONTENT when parsing\n    succeeds but an error about the actual contents causes a request to fail.\n -- slurmrestd - queries that result in empty contents will now be treated as\n    SUCCESS. While the query worked, nothing was returned, which allows callers\n    to determine how to then proceed.\n -- Add PowerDownOnIdle partition option.\n -- Make it so the [Allow|Deny]Accounts parameter for a partition is\n    hierarchical.\n -- Add the ability for a add (+=) or remove (-=) nodes from a reservation\n -- Fix several problems when creating/editing partitions in sview.\n -- Enhanced burst_buffer.lua - pass UID and GID to most hooks; pass a table\n    containing detailed job information to many hooks. See\n    etc/burst_buffer.lua.example for a complete list of changes.\n -- Add a new \"nodes=\" argument to scontrol setdebug to allow the debug level\n    on the slurmd processes to be temporarily altered.\n -- Add InfluxDBTimeout parameter to acct_gather.conf.\n -- job_container/tmpfs - add support for expanding %h and %n in BasePath.\n -- Prevent job submission/update with afterok/afternotok dependency set to\n    an unknown jobid.\n -- Change to a new FAIL_SIGNAL job state reason (instead of FAIL_LAUNCH) for\n    jobs that have raised a signal on setup.\n -- Add \"[jobid.stepid]\" prefix from slurmstepd and \"slurmscriptd\" prefix from\n    slurmcriptd to Syslog logging. Previously was only happening when logging\n    to a file.\n -- Make it so scrontab prints client-side the job_submit() err_msg (which can\n    be set i.e. by using the log_user() function for the lua plugin).\n -- Remove ability for reservation to have STATIC_ALLOC or MAINT flags and\n    REPLACE[_DOWN] flags simultaneously.\n -- Accept only one reoccurring flag when creating/updating any reservation.\n -- Remove ability to update a reservation to have a reoccurring flag if it\n    is a floating reservation.\n -- squeue - removed unused '%s' and 'SelectJobInfo' formats.\n -- Add purge and archive functionality for job environment and job batch script\n    records.\n -- srun - return an error if step suffers a node failure.\n -- squeue - align print format for exit and derived codes with that of other\n    components (<exit_status>:<signal_number>).\n -- Add new SlurmctldParameters=validate_nodeaddr_threads=<number> option to\n    allow concurrent hostname resolution at slurmctld startup.\n -- Have 'scontrol show hostlist -' read from stdin.\n -- Extend support for Include files to all \"configless\" client commands.\n -- Make node weight usable for powered down and rebooting nodes.\n -- node_features plugins - node_features_p_reboot_weight() function removed.\n -- Removed 'launch' plugin.\n -- Add \"Extra\" field to job to store extra information other than a comment.\n -- Add new AccountingStoreFlags=job_extra option to store a job's extra field\n    in the database.\n -- slurmrestd - add option to allow rest_auth/local to switch user id on first\n    user connection.\n -- oci.conf - add DisableHooks option.\n -- oci.conf - add SrunPath and SrunArgs options.\n -- oci.conf - add StdIODebug, SyslogDebug, FileDebug and DebugFlags options to\n    allow controlling container specific logging.\n -- oci.conf - remove requirement of RunTimeQuery when RunTimeRun is set.\n -- slurmstepd - cleanup generated environment file for containers when step\n    completes instead of deferring cleanup to OCI runtime.\n -- oci.conf - add configuration option \"IgnoreFileConfigJson=\" to allow a site\n    to choose to ignore config.json.\n -- oci.conf - Add PID (%p) pattern replacement.\n -- slurmrestd - correct ordering issue of saving changes to a container's\n    modified config.json where config changes by job modifying plugins would be\n    silently lost.\n -- slurmstepd - merge container config.json environment into job environment\n    and then overwrite config.json environment. Avoids instance where processes in\n    container will not have access to job environment variables.\n -- slurmstepd - defer creating container environment file until after all\n    plugin based modifications to the job environment are complete.\n -- oci.conf - modify configuration option \"CreateEnvFile=\" to support creating\n -- oci.conf - add RunTimeEnvExclude and EnvExclude.\n -- slurmstepd - fix container pattern bundle path replacement (%b) with\n    bundle path instead of spool dir path.\n -- oci.conf - add MountSpoolDir.\n -- slurmstepd - create per task spool directory per container to avoid\n    conflicts when there are more than 1 container tasks on any given node.\n -- mpi/pmix - set PMIX_SERVER_TMPDIR to container spool directory instead of\n    slurmd spool directory which caused PMIx to fail to load in containers.\n -- Add new \"defer_batch\" option to SchedulerParameters to only defer\n    scheduling for batch jobs.\n -- Reject jobs submitted with impossible --time, --deadline, and --begin\n    combinations at submission time\n -- Add new DebugFlags option 'JobComp' to replace 'Elasticsearch'.\n -- sacct - Add --array option to expand job arrays and display array tasks on\n    separate lines.\n -- Fix jobs submitted with a deadline never being cleared after the\n    reservation is done.\n -- Change srun/salloc to wait indefinitely for their allocations to be ready.\n -- Do not attempt to \"fix\" malformed input to 'scontrol show hostlist'.\n -- RSMI - Add usage gathering for AMD gpus (requires ROCM 5.5+).\n -- Add job's allocated nodes, features, oversubscribe, partition, and\n    reservation to SLURM_RESUME_FILE output for power saving.\n -- Automatically create directories for stdout/stderr output files. Paths may\n    use %j and related substitution characters as well.\n -- Add --tres-per-task to salloc/sbatch/srun.\n -- Add configurable job requeue limit parameter - MaxBatchRequeue - in\n    slurm.conf to permit changes from the old hard-coded value of 5.\n -- Add a new \"nodes=\" argument to \"scontrol setdebugflags\" as well.\n -- slurmd - add --authinfo option to allow AuthInfo options to be changed\n    during the configless startup.\n -- helpers.conf - Allow specification of node specific features.\n -- helpers.conf - Allow many features to one helper script.\n -- Allow nodefeatures plugin features to work with cloud nodes.\n -- squeue - removed --array-unique option.\n -- openapi/v0.0.39 - expand job stderr, stdin, and stdout path replacement\n    symbols when dumping job information via dump_job_info().\n -- Make slurmstepd cgroups constrained by total configured memory from\n    slurm.conf (NodeName=<> RealMemory=#) instead of total physical memory.\n -- node_features/helpers - add support for the OR and parentheses operators\n    in a --constraint expression.\n -- Fix race condition between PMIx authentication and slurmstepd task launches\n    that can lead to job launch failures.\n -- fatal() when [Prolog|Epilog]Slurmctld are defined but not executable.\n -- slurmctld - Add new RPC rate limiting feature. This is enabled through\n    SlurmctldParameters=rl_enable, otherwise disabled by default.\n -- Validate node registered active features are a super set of node's\n    currently active changeable features.\n -- On clusters without any PrologFlags options, batch jobs with failed prologs\n    nolonger generate an output file.\n -- sreport - print \"Top ALL Users\" for Top User report when topcount = -1.\n -- Add SLURM_JOB_START_TIME and SLURM_JOB_END_TIME environment variables.\n -- Add SuspendExcStates option to slurm.conf to avoid suspending/powering down\n    specific node states.\n -- job_container/tmpfs - Add \"Shared\" option to support shared namespaces.\n    This allows autofs to work with the job_container/tmpfs plugin when enabled.\n -- Fix incorrect min node estimation for pending jobs as displayed by client\n    commands (e.g. squeue, scontrol show job).\n -- Add support for DCMI power readings in IPMI plugin.\n -- Prevent the backfill counter of tested jobs being reset by sdiag -r.\n -- sacctmgr - Add --json and --yaml arguments.\n -- openapi/v0.0.39 - Conversion of parsing and dumping of data to\n    data_parser/v0.0.39 plugins. Significant restructuring of OpenAPI\n    specification compared to previous plugin version.\n -- openapi/dbv0.0.39 - Conversion of parsing and dumping of data to\n    data_parser/v0.0.39 plugins. Significant restructuring of OpenAPI\n    specification compared to previous plugin version.\n -- Validate --gpu-bind options more strictly.\n -- Fix slurmd segfault on bad EnergyIPMIPowerSensors= parameter.\n -- Allow for --nodelist to contain more nodes than required by --nodes.\n -- Add missing logic for JobCompParams configuration key pair to be available\n    for consumers of the get/print/write configuration API functions.\n -- mpi/cray_shasta - Add new PALS/PMI environment variables.\n -- Add cache around calls to getnameinfo().\n -- Add CommunicationParameters=getnameinfo_cache_timeout to tune or disable the\n    getnameinfo cache.\n -- Limit the number of successive times a batch job may be requeued due to a\n    prolog failure. This limit is defined by the value of the max_batch_requeue\n    parameter (default 5). Jobs over this limit will be put on admin hold.\n -- Rename \"nodes\" to \"nodes_resume\" in SLURM_RESUME_FILE job output.\n -- Rename \"all_nodes\" to \"all_nodes_resume\" in SLURM_RESUME_FILE output.\n -- Add new PrologFlags=ForceRequeueOnFail option to automatically requeue\n    batch jobs on Prolog failures regardless of the job --requeue setting.\n -- Add HealthCheckNodeState=NONDRAINED_IDLE option.\n -- Add 'explicit' to Flags in gres.conf\n -- Improve validation of --constraint expression syntax.\n -- srun - support job array ids as an argument to --jobid.\n -- Add jobcomp/kafka plugin.\n -- Automatically filter out E-Cores on Intel processors to avoid issues from\n    differing threads-per-core values within a single socket.\n -- Add LaunchParameters=ulimit_pam_adopt, which enables setting RLIMIT_RSS in\n    adopted processes.\n -- Add new PreemptParameters=reclaim_licenses option which will allow higher\n    priority jobs to preempt jobs to free up used licenses. (This is only\n    enabled for with PreemptModes of CANCEL and REQUEUE, as Slurm cannot\n    guarantee suspended jobs will release licenses correctly.)\n -- Make it so that the REQUEST_STEP_STAT handler only polls jobacct_gather\n    information once per RPC. This improves sstat results performance time.\n -- Fix sbcast --force option to work with --send-libs option. Now when --force\n    is set, library directories transmitted will overwrite pre-existing libraries\n    that were previously transmitted.\n -- hpe/slingshot - Add support for user requestible job VNIs.\n -- hpe/slingshot - Add support for user requestible single node vnis.\n -- hpe/slingshot - Add support for the instant-on feature.\n -- Add ability to update SuspendExc* parameters with scontrol.\n -- Add ability to preserve SuspendExc* parameters on reconfig with\n    ReconfigFlags=KeepPowerSaveSettings.\n -- Add ability to restore SuspendExc* parameters on restart with slurmctld -R\n    option.\n -- Fix leaving allocated gres on a non-cloud node after being allocated\n    from a powered down state after a slurmctld restart.\n -- 'scontrol update job' can now set a GRES specification to \"0\" to effectively\n    clear a GRES specification from a job.\n -- Jobs with old GRES that are no longer configured in any configuration files\n    can now be successfully updated to use currently configured GRES.\n -- Add tres_per_node to resource_allocation_response_msg to fix srun jobs\n    running with outdated GRES. This is necessary for srun jobs whose GRES are\n    updated while they are pending. By having tres_per_node in the\n    resourece_allocation_response_msg, slurmctld can send back the correct and\n    updated GRES, whereas without it, the srun job would use the old GRES.\n -- Cleaned up various \"warning\", \"Warning\", and \"WARNING\" messages with a new\n    warning() logging call. All will now print as \"warning: ...\".\n -- Add SLURM_JOB_OVERSUBSCRIBE environment variable for Epilog, Prolog,\n    EpilogSlurmctld, PrologSlurmctld, and mail output.\n -- Fix node reason time skew when setting a reboot message.\n -- Append ResumeTimeout message to an existing node reason instead of always\n    clearing it first.\n -- slurmrestd - added support for Bearer Authentication using auth/jwt.\n -- Add check to detect invalid HetJob component and abort job if identified.\n -- sched/backfill - fix job test against advanced reservations if job uses a\n    preemptable QOS with Flags=NoReserve.\n -- New command scrun has been added. scrun acts as an Open Container Initiative\n    (OCI) runtime proxy to run containers seamlessly via Slurm.\n -- Added support for Linux kernel user namespaces. Process user and group ids\n    are no longer used unless explicitly requested as an argument. They are\n    left as SLURM_AUTH_NOBODY (99) by default.\n\n* Changes in Slurm 22.05.12\n===========================\n\n* Changes in Slurm 22.05.11\n===========================\n -- Prevent message extension attacks that could bypass the message hash.\n    CVE-2023-49933.\n -- Prevent NULL pointer dereference on size_valp overflow. CVE-2023-49936.\n -- Prevent double-xfree() on error in _unpack_node_reg_resp().\n    CVE-2023-49937.\n -- Prevent modified sbcast RPCs from opening a file with the wrong group\n    permissions. CVE-2023-49938.\n\n* Changes in Slurm 22.05.10\n===========================\n -- Fix filesystem handling race conditions that could lead to an attacker\n    taking control of an arbitrary file, or removing entire directories'\n    contents. CVE-2023-41914.\n\n* Changes in Slurm 22.05.9\n==========================\n -- Allocate correct number of sockets when requesting gres and running with\n    CR_SOCKET*.\n -- Fix handling of --prefer for job arrays.\n -- Fix regression in 22.05.5 that causes some jobs that request\n    --ntasks-per-node to be incorrectly rejected.\n -- Fix slurmctld crash when a step requests fewer tasks than nodes.\n -- Fix incorrect task count in steps that request --ntasks-per-node and a node\n    count with a range (e.g. -N1-2).\n -- Fix some valid step requests hanging instead of running.\n -- slurmrestd - avoid possible race condition which would cause slurmrestd to\n    silently no longer accept new client connections.\n -- Fix GPU setup on CRAY systems when using the CRAY_CUDA_MPS environment\n    variable. GPUs are now correctly detected in such scenarios.\n -- Fix the job prolog not running for jobs with the interactive step\n    (salloc jobs with LaunchParameters=use_interactive_step set in slurm.conf)\n    that were scheduled on powered down nodes. The prolog not running also\n    broke job_container/tmpfs, pam_slurm_adopt, and x11 forwarding.\n -- task/affinity - fix slurmd segfault when request launch task requests of\n    type \"--cpu-bind=[map,mask]_cpu:<list>\" have no <list> provided.\n -- sched/backfill - fix segfault when removing a PLANNED node from system.\n -- sched/backfill - fix deleted planned node staying in planned node bitmap.\n -- Fix nodes remaining as PLANNED after slurmctld save state recovery.\n -- Fix regression in 22.05.0rc1 that broke Nodes=ALL in a NodeSet.\n -- Fix incorrect memory constraint when receiving a job from 20.11 that uses\n    cpu count for memory calculation.\n -- openapi/v0.0.[36-38] - avoid possible crash from jobs submitted with argv.\n -- openapi/v0.0.[36-38] - avoid possible crash from rejected jobs submitted\n    with batch_features.\n -- srun - fix regression in 22.05.7 that prevented slurmctld from connecting\n    to an srun running outside of a compute node.\n\n* Changes in Slurm 22.05.8\n==========================\n -- Fix potential deadlock at slurmctld startup when job has invalid qos.\n -- Avoid unnecessary call to clusteracct_storage_g_cluster_tres() when pinging\n    dynamic nodes. This avoids significant slowdowns for slurmctld when\n    ping_nodes() calls all nodes to re-register.\n -- openapi/dbv0.0.3[6-8] - fix segfault that could arrise from Slurm database\n    connection failing.\n -- Fix regression introduced in 22.05.0rc1 when updating a NodeName=<nodelist>\n    with NodeAddr and/or NodeHostname if the specified nodelist wasn't sorted.\n -- openapi/v0.0.38 - change type of nice field for job submissions to integer\n    from string.\n -- openapi/v0.0.38 - add oversubscribe option to job submission properties.\n -- openapi/v0.0.38 - fix incorrect data used to populate \"time/start\" field\n    for jobs.\n -- openapi/dbv0.0.38 - avoid dumping failure if preempt qos with level 0 is\n    provided by slurmdbd query.\n -- Avoid an fd leak when lib dir for sbcast fails to be created.\n -- common/slurmdbd_pack - fix env and script hash when unpacking a 21.08\n    dbd_job_start_msg_t.\n -- Fix a race between job_container/tmpfs, cncu, x11 setup and adoption of pids\n    in cray with pam_slurm_adopt.\n\n* Changes in Slurm 22.05.7\n==========================\n -- Fix slurmctlds in a federation not recovering a lost connection until a\n    slurmctld restart or a federation update.\n -- Fix incorrectly rejecting jobs that request GRES on multiple sockets and\n    --gres-flags=enforce-binding.\n -- Fix job core selection with --gres-flags=enforce-binding: this fixes cases\n    where enforce-binding was not respected.\n -- openapi/v0.0.38 - set assoc_id resolution failure as a debug log instead of\n    an error log.\n -- Fix issues when running in FrontEnd mode.\n -- Fix srun and salloc I/O code to set keepaliveinterval/keepalivetime on\n    connections.\n -- Fix overwrite race of cont_id in cgroup/v2 when using task/cgroup with\n    proctrack/cray_aries.\n -- Fix node remaining allocated after a reconfig with a completing job that\n    has an EpilogSlurmctld instance still running.\n -- openapi/dbv0.0.38 - fix a cast to a wrong type\n -- openapi/dbv0.0.38 - correct issues where modifying association fields were\n    ignored.\n -- openapi/dbv0.0.38 - correct issue where 16 bit integers were not able to be\n    unset.\n -- openapi/dbv0.0.38 - correct issue where 16 & 32 bit integers were not able\n    to be unset.\n -- Fix 'scontrol show hostlist' to read off a pipe correctly.\n -- Fix 'scontrol reconfigure' with configless enabled to send updated configs\n    to 21.08 nodes correctly. (22.05 nodes are unaffected.)\n -- Fix assertion and locks for dynamic node registrations with rpc queueing.\n -- rest_auth/local - avoid logging root access as an error but instead as a\n    normal info log.\n -- slurmrestd - switch users earlier on startup to avoid sockets being made as\n    root.\n -- slurmrestd - disable umask during socket creation as the authentication is\n    handled by Slurm instead of file ACLs.\n -- Fix sbcast, srun --bcast, sstat not working with cloud/dynamic nodes.\n -- sacctmgr - Allow removal of user's default account when AllowNoDefAcct=yes.\n -- Fix segfault caused by race condition when a reconfiguration is requested\n    while slurmd initializes.\n -- openapi/v0.0.38 - avoid division by zero causing slurmrestd to crash during\n    diag queries.\n -- Update default values for text/blob columns in the database if upgrading\n    to MariaDB >= 10.2.1 from a pre-10.2.1 version or from MySQL to avoid\n    sacctmgr failures.\n -- Fix several minor memory leaks in the cgroup/v2 plugin.\n -- Fix possible issue when enabling controllers with long names in cgroup/v2.\n -- Fix potential segfault in slurmd when using acct_gather_energy/ipmi.\n -- Fix controller being able to contact non-addressable step hosts.\n -- Allow setting SuspendTime to -1 when used on a partition.\n -- openapi/v0.0.38 - fix maximum_memory_per_node description typo.\n -- openapi/v0.0.38 - add maximum_memory_per_cpu to GET /partitions\n -- openapi/v0.0.38 - add default_memory_per_node to GET /partitions\n -- Fix dynamic node losing dynamic node status when changing state to FUTURE.\n -- Fix adoption into most recent job in pam_slurm_adopt and cgroup/v2.\n -- gres/shard - Fix plugin_name definition to print correctly in debug lines.\n\n* Changes in Slurm 22.05.6\n==========================\n -- Fix a partition's DisableRootJobs=no from preventing root jobs from working.\n -- Fix the number of allocated cpus for an auto-adjustment case in which the\n    job requests --ntasks-per-node and --mem (per-node) but the limit is\n    MaxMemPerCPU.\n -- Fix POWER_DOWN_FORCE request leaving node in completing state.\n -- Do not count magnetic reservation queue records towards backfill limits.\n -- Clarify error message when --send-libs=yes or BcastParameters=send_libs\n    fails to identify shared library files, and avoid creating an empty\n    \"<filename>_libs\" directory on the target filesystem.\n -- Fix missing CoreSpec on dynamic nodes upon slurmctld restart.\n -- Fix node state reporting when using specialized cores.\n -- Fix number of CPUs allocated if --cpus-per-gpu used.\n -- Add flag ignore_prefer_validation to not validate --prefer on a job.\n -- Fix salloc/sbatch SLURM_TASKS_PER_NODE output environment variable when the\n    number of tasks is not requested.\n -- Permit using wildcard magic cookies with X11 forwarding.\n -- cgroup/v2 - Add check for swap when running OOM check after task\n    termination.\n -- Fix deadlock caused by race condition when disabling power save with a\n    reconfigure.\n -- Fix memory leak in the dbd when container is sent to the database.\n -- openapi/dbv0.0.38 - correct dbv0.0.38_tres_info.\n -- Fix node SuspendTime, SuspendTimeout, ResumeTimeout being updated after\n    altering partition node lists with scontrol.\n -- jobcomp/elasticsearch - fix data_t memory leak after serialization.\n -- Fix issue where '*' wasn't accepted in gpu/cpu bind.\n -- Fix SLURM_GPUS_ON_NODE for shared GPU gres (MPS, shards).\n -- Add SLURM_SHARDS_ON_NODE environment variable for shards.\n -- Fix srun error with overcommit.\n -- Fix bug in core selection for the default cyclic distribution of tasks\n    across sockets, that resulted in random task launch failures.\n -- Fix core selection for steps requesting multiple tasks per core when\n    allocation contains more cores than required for step.\n -- gpu/nvml - Fix MIG minor number generation when GPU minor number\n    (/dev/nvidia[minor_number]) and index (as seen in nvidia-smi) do not match.\n -- Fix accrue time underflow errors after slurmctld reconfig or restart.\n -- Suppress errant errors from prolog_complete about being unable to locate\n    \"node:(null)\".\n -- Fix issue where shards were selected from multiple gpus and failed to\n    allocate.\n -- Fix step cpu count calculation when using --ntasks-per-gpu=.\n -- Fix overflow problems when validating array index parameters in slurmctld\n    and prevent a potential condition causing slurmctld to crash.\n -- Remove dependency on json-c in slurmctld when running with power saving.\n    Only the new \"SLURM_RESUME_FILE\" support relies on this, and it will be\n    disabled if json-c support is unavailable instead.\n\n* Changes in Slurm 22.05.5\n==========================\n -- Fix node becoming IDLE while in an invalid registration state.\n -- When a job is completing avoid potential dereference.\n -- Avoid setting preempt_time for a job erroneously.\n -- Fix situation where we don't requeue correctly when a job is finishing.\n -- job_container/tmpfs - Avoid leaking namespace file descriptor.\n -- common/slurm_opt - fix memory leak in client commands or slurmrestd when the\n    --chdir option is set after option reset.\n -- openapi/dbv0.0.38 - gracefully handle unknown associations assigned to jobs.\n -- openapi/dbv0.0.38 - query all associations to avoid errors while dumping\n    jobs.\n -- Load hash plugin at slurmstepd launch time to prevent issues loading the\n    plugin at step completion if the Slurm installation is upgraded.\n -- Fix gcc 12.2.1 compile errors.\n -- Fix future magnetic reservations preventing heterogeneous jobs from\n    starting.\n -- Prevent incorrect error message from being generated for operator/admins\n    using the 'scontrol top' command.\n -- slurmrestd - correct issue where larger requests could result in a single\n    byte getting removed from inside of the POST request.\n -- Fix regression in task count calculation for --ntasks-per-gpu with multiple\n    nodes.\n -- Update nvml plugin to match the unique id format for MIG devices in new\n    Nvidia drivers.\n -- Fix segfault on backup slurmdbd if no QoS is present in DB.\n -- Fix clang 11 compile errors.\n -- Fix task distribution calculations across sockets with\n    --distribution=cyclic.\n -- Fix task distribution calculations with --ntasks-per-gpu specified without\n    an explicit --ntasks value.\n -- Fix job arrays not showing correct features.\n -- Fix job having wrong features used when using preferred features.\n -- Fix task/cray_aries error finishing an interactive step, avoiding correct\n    cleanup.\n -- Correctly set max_nodes when --ntasks=1.\n -- Fix configure script on FreeBSD.\n\n* Changes in Slurm 22.05.4\n==========================\n -- Fix return code from salloc when the job is revoked prior to executing user\n    command.\n -- Fix minor memory leak when dealing with gres with multiple files.\n -- Fix printing for no_consume gres in scontrol show job.\n -- sinfo - Fix truncation of very large values when outputting memory.\n -- Fix multi-node step launch failure when nodes in the controller aren't in\n    natural order. This can happen with inconsistent node naming (such as\n    node15 and node052) or with dynamic nodes which can register in any order.\n -- job_container/tmpfs - Prevent reading the plugin config multiple times per\n    step.\n -- Fix wrong attempt of gres binding for gres w/out cores defined.\n -- Fix build to work with '--without-shared-libslurm' configure flag.\n -- Fix power_save mode when repeatedly configuring too fast.\n -- Fix sacct -I option.\n -- Prevent jobs from being scheduled on future nodes.\n -- Fix memory leak in slurmd happening on reconfigure when CPUSpecList used.\n -- Fix sacctmgr show event [min|max]cpus.\n -- Fix regression in 22.05.0rc1 where a prolog or epilog that redirected stdout\n    to a file could get erroneously killed, resulting in job launch failure\n    (for the prolog) and the node being drained.\n -- cgroup/v1 - Make a static variable to remove potential redundant checking\n    for if the system has swap or not.\n -- cgroup/v1 - Add check for swap when running OOM check after task\n    termination.\n -- job_submit/lua - add --prefer support\n -- cgroup/v1 - fix issue where sibling steps could incorrectly be accounted as\n    OOM when step memory limit was the same as the job allocation. Detect OOM\n    events via memory.oom_control oom_kill when exposed by the kernel instead of\n    subscribing notifications with eventfd.\n -- Fix accounting of oom_kill events in cgroup/v2 and task/cgroup.\n -- Fix segfault when slurmd reports less than configured gres with links after\n    a slurmctld restart.\n -- Fix TRES counts after node is deleted using scontrol.\n -- sched/backfill - properly handle multi-reservation HetJobs.\n -- sched/backfill - don't try to start HetJobs after system state change.\n -- openapi/v0.0.38 - add submission of job->prefer value.\n -- slurmdbd - become SlurmUser at the same point in logic as slurmctld to match\n    plugins initialization behavior. This avoids a fatal error when starting\n    slurmdbd as root and root cannot start the auth or accounting_storage\n    plugins (for example, if root cannot read the jwt key).\n -- Fix memory leak when attempting to update a job's features with invalid\n    features.\n -- Fix occasional slurmctld crash or hang in backfill due to invalid pointers.\n -- Fix segfault on Cray machines if cgroup cpuset is used in cgroup/v1.\n\n* Changes in Slurm 22.05.3\n==========================\n -- job_container/tmpfs - cleanup containers even when the .ns file isn't\n    mounted anymore.\n -- Ignore the bf_licenses option if using sched/builtin.\n -- Do not clear the job's requested QOS (qos_id) when ineligible due to QOS.\n -- Emit error and add fail-safe when job's qos_id changes unexpectedly.\n -- Fix timeout value in log.\n -- openapi/v0.0.38 - fix setting of DefaultTime when dumping a partition.\n -- openapi/dbv0.0.38 - correct parsing association QOS field.\n -- Fix LaunchParameters=mpir_use_nodeaddr.\n -- Fix various edge cases where accrue limits could be exceeded or cause\n    underflow error messages.\n -- Fix issue where a job requesting --ntasks and --nodes could be wrongly\n    rejected when spanning heterogeneous nodes.\n -- openapi/v0.0.38 - detect when partition PreemptMode is disabled\n -- openapi/v0.0.38 - add QOS flag to handle partition PreemptMode=within\n -- Add total_cpus and total_nodes values to the partition list in\n    the job_submit/lua plugin.\n -- openapi/dbv0.0.38 - reject and error on invalid flag values in well defined\n    flag fields.\n -- openapi/dbv0.0.38 - correct QOS preempt_mode flag requests being silently\n    ignored.\n -- accounting_storage/mysql - allow QOS preempt_mode flag updates when GANG\n    mode is requested.\n -- openapi/dbv0.0.38 - correct QOS flag modifications request being silently\n    ignored.\n -- sacct/sinfo/squeue - use openapi/[db]v0.0.38 for --json and --yaml modes.\n -- Improve error messages when using configless and fetching the config fails.\n -- Fix segfault when reboot_from_controller is configured and scontrol reboot\n    is used.\n -- Fix regression which prevented a cons_tres gpu job to be submitted to a\n    cons_tres cluster from a non-con_tres cluster.\n -- openapi/dbv0.0.38 - correct association QOS list parsing for updates.\n -- Fix rollup incorrectly divying up unused reservation time between\n    associations.\n -- slurmrestd - add SLURMRESTD_SECURITY=disable_unshare_files environment\n    variable.\n -- Update rsmi detection to handle new default library location.\n -- Fix header inclusion from slurmstepd manager code leading to multiple\n    definition errors when linking --without-shared-libslurm.\n -- slurm.spec - explicitly disable Link Time Optimization (LTO) to avoid\n    linking errors on systems where LTO-related RPM macros are enabled by\n    default and the binutils version has a bug.\n -- Fix issue in the api/step_io message writing logic leading to incorrect\n    behavior in API consuming clients like srun or sattach, including a segfault\n    when freeing IO buffers holding traffic from the tasks to the client.\n -- openapi/dbv0.0.38 - avoid job queries getting rejected when cluster is not\n    provided by client.\n -- openapi/dbv0.0.38 - accept job state filter as verbose names instead of\n    only numeric state ids.\n -- Fix regression in 22.05.0rc1: if slurmd shuts down while a prolog is\n    running, the job is cancelled and the node is drained.\n -- Wait up to PrologEpilogTimeout before shutting down slurmd to allow prolog\n    and epilog scripts to complete or timeout. Previously, slurmd waited 120\n    seconds before timing out and killing prolog and epilog scripts.\n -- GPU - Fix checking frequencies to check them all and not skip the last one.\n -- GPU - Fix logic to set frequencies properly when handling multiple GPUs.\n -- cgroup/v2 - Fix typo in error message.\n -- cgroup/v2 - More robust pattern search for events.\n -- Fix slurm_spank_job_[prolog|epilog] failures being masked if a Prolog or\n    Epilog script is defined (regression in 22.05.0rc1).\n -- When a job requested nodes and can't immediately start, only report to\n    the user (squeue/scontrol et al) if nodes are down in the requested list.\n -- openapi/dbv0.0.38 - Fix qos list/preempt not being parsed correctly.\n -- Fix dynamic nodes registrations mapping previously assigned nodes.\n -- Remove unnecessarily limit on count of 'shared' gres.\n -- Fix shared gres on CLOUD nodes not properly initializing.\n\n* Changes in Slurm 22.05.2\n==========================\n -- Fix a segfault in slurmctld when requesting gres in job arrays.\n -- Prevent jobs from launching on newly powered up nodes that register with\n    invalid config.\n -- Fix a segfault when there's no memory.swap.current interface in cgroup/v2.\n -- Fix memleak in cgroup/v2.\n\n* Changes in Slurm 22.05.1\n==========================\n -- Flush the list of Include config files on SIGHUP.\n -- Fix and update Slurm completion script.\n -- jobacct_gather/cgroup - Add VMem support both for cgroup v1 and v2.\n -- Allow subset of node state transitions when node is in INVAL state.\n -- Remove INVAL state from cloud node after being powered down.\n -- When showing reason UID in scontrol show node, use the authenticated UID\n    instead of the login UID.\n -- Fix calculation of reservation's NodeCnt when using dynamic nodes.\n -- Add SBATCH_{ERROR,INPUT,OUTPUT} input environment variables for --error,\n    --input and --output options respectively.\n -- Prevent oversubscription of licenses by the backfill scheduler when not\n    using the new \"bf_licenses\" option.\n -- Jobs with multiple nodes in a heterogeneous cluster now have access to all\n    the memory on each node by using --mem=0. Previously the memory limit was\n    set by the node with the least amount of memory.\n -- Don't limit the size of TaskProlog output (previously TaskProlog output was\n    limited to 4094 characters per line, which limited the size of exported\n    environment variables or logging to the task).\n -- Fix usage of possibly uninitialized buffer in proctrack/cgroup.\n -- Fix memleak in proctrack/cgroup proctrack_p_wait.\n -- Fix cloud/remote het srun jobs.\n -- Fix a segfault that may happen on gpu configured as no_consume.\n\n* Changes in Slurm 22.05.0\n==========================\n -- openapi/v0.0.38 - add group name to job info\n -- openapi/v0.0.38 - add container field to job description.\n -- openapi/v0.0.38 - add container to job submission.\n -- openapi/[db]v0.0.38 - add container field to job description.\n -- openapi/dbv0.0.38 - fix bug where QOS update set various limits to 0.\n -- openapi/dbv0.0.38 - properly initialize wckey record.\n -- openapi/dbv0.0.38 - properly initialize cluster record.\n -- openapi/dbv0.0.38 - gracefully update existing QOSs.\n -- Fix x11 forwarding with job_container/tmpfs and without home_xauthority.\n -- Fix reconfig of dynamic nodes with gres.\n -- Fix corner case issues when removing assocs/qos' while jobs are completing\n    and a reconfigure happens.\n -- Add SlurmdParameters=numa_node_as_socket to use the numa node as a socket.\n -- Avoid creating and referencing NULL script/env hash entries when not storing\n    the job script or job environment.\n -- slurmd - If a het component job fails to launch due to a node prolog or\n    other failure, properly handle the whole het job.\n -- Fix possible race condition while handling forwarded messages.\n -- Add new SchedulerParameters option \"bf_licenses\" to track licenses as\n    within the backfill scheduler.\n -- Fix resuming nodes not part of an allocation.\n -- Minor memory leak fixes.\n -- Use accept4() and pipe2() to ensure new file descriptors are always set\n    with close-on-exec flag.\n -- slurmctld - allow users to request tokens for themselves by name.\n -- srun - adjust output of \"--mpi=list\".\n -- Fix \"--gpu-bind=single:\" having wrong env variables.\n -- Sync missing pieces in slurmctld SIGHUP handler with respect to\n    REQUEST_RECONFIGURE RPC handler.\n -- Fixed the behavior of the --states=all option in squeue to actually show\n    all of the states.\n -- job_container - Don't constrain a job using --no-allocate.\n -- Fix slurmctld segfault when a step requests a gres without a file.\n -- Fix slurmctld segfault when cleaning up an overlapping step.\n -- Dynamic node fixes and updates.\n -- Added error logging when a node goes into an invalid state so that the user\n    can still see the reason even if the user set a custom reason beforehand.\n -- Remove redundant message when libdbus is found during configure.\n -- Fix pmix to honor SrunPortRange.\n -- Fix issue with ntasks_per_socket and ntasks_per_core with --exclusive\n -- openapi/v0.0.38 - change job parsing error message to reflect reality.\n -- Avoid segfault/assert when --thread-spec used with config_overrides\n -- Don't send SIGTERM to prematurely in run_command.\n -- Add logging to inform where networking errors are occurring on slurmd end.\n -- openapi/dbv0.0.38 - Enforce GET /association/ to dump only a single\n    association.\n -- openapi/dbv0.0.38 - Enforce DELETE /association/ to delete only a single\n    association.\n -- openapi/dbv0.0.38 - Add parameters to filter to GET /associations/.\n -- openapi/dbv0.0.38 - Add DELETE /associations using parameters to set filters.\n -- openapi/dbv0.0.38 - Fix plural form of delete association response schema.\n\n* Changes in Slurm 22.05.0rc1\n=============================\n -- gres/gpu - Avoid stripping GRES type field during normalization if any\n    other GRES have a defined type field.\n -- burst_buffer/datawarp - free bb_job after stage-out or teardown are done.\n -- acct_gather_energy_rsmi has been renamed acct_gather_energy_gpu.\n -- Remove support for (non-functional) --cpu-bind=boards.\n -- accounting_storage/mysql - ensure new non-HetJobs have het_job_offset NO_VAL\n    in the database and fix the same field when retrieving older bad records.\n -- PreemptMode now works as a condition for qos in sacctmgr.\n -- scancel - add \"--me\" option.\n -- gres/gpu - Fix configured/system-detected GRES match for some combinations\n    for which the sorting affected the expected selection result.\n -- openapi/v0.0.38 - Fork existing openapi/v0.0.37 plugin.\n -- openapi/dbv0.0.38 - Fork existing openapi/dbv0.0.37 plugin.\n -- openapi/v0.0.35 - Plugin has been removed.\n -- scrontab - Don't accept extra letters after a '@' repeating pattern.\n -- openapi/dbv0.0.38 - Add missing method POST for /associations/.\n -- Make DefMemPerCPU/MaxMemPerCPU and DefMemPerNode/MaxMemPerNode precedence\n    at the global level the same as in partition level, and print an error\n    if both of a pair are set.\n -- openapi/v0.0.38 - Allow strings for JobIds instead of only numerical JobIds\n    for GET, DELETE, and POST job methods.\n -- openapi/v0.0.38 - enable job priority field for job submissions and updates.\n -- openapi/v0.0.38 - request node states query includes MIXED state instead of\n    only allocated.\n -- openapi/dbv0.0.38 - Correct tree position of dbv0.0.38_job_step.\n -- Enforce all Slurm plugin requirements for plugins specified with absolute\n    path.\n -- Added --prefer option at job submission to allow for 'soft' constraints.\n -- Remove support for PMIx 1.x\n -- slurmrestd - Unlink unix sockets before binding to avoid errors where\n    previous run of slurmrestd did not properly cleanup the sockets.\n -- Add extra 'EnvironmentFile=-/etc/default/$service' setting to service files.\n -- slurmctld/agent - spawn more agent threads in a single _agent_retry().\n -- openapi/v0.0.38 - change job response types to more specific types than\n    generic string.\n -- srun - refuse to run on malformed SPANK environment variable.\n -- Allow jobs to pack onto nodes already rebooting with the desired features.\n -- Reset job start time after nodes are rebooted.\n -- Node features (if any) are passed to RebootProgram if run from slurmctld.\n -- Fix sending multiple features to RebootProgram.\n -- If a task/srun prolog fails don't allow the step to continue running.\n -- Fail srun when using invalid --cpu-bind options.\n -- cgroup/v1 - Set swappiness at job level instead of at root level.\n -- Fix issues where a step's GRES request could never be satisfied but the step\n    remained pending forever instead of being rejected.\n -- openapi/v0.0.38 - Remove errant extra space after JOB_CPUS_SET flag.\n -- slurmrestd - refuse to run with gid 0, or under SlurmUser's gid.\n -- Storing batch scripts and env vars are now in indexed tables using\n    substantially less disk space.  Those storing scripts in 21.08 will all\n    be moved and indexed automatically.\n -- Run MailProg through slurmscriptd instead of directly fork+exec()'ing\n    from slurmctld.\n -- Add acct_gather_interconnect/sysfs plugin.\n -- Fix gpus spanning more resources than needed when using --cpus-per-gpu.\n -- burst_buffer plugins - err_msg added to bb_p_job_validate().\n -- burst_buffer plugins - Send user specific error message if permission\n    denied due to AllowUsers or DenyUsers in burst_buffer.conf.\n -- Fatal if the mutually-exclusive JobAcctGatherParams options of UsePss and\n    NoShared are both defined.\n -- Future and Cloud nodes are treated as \"Planned Down\" in usage reports.\n -- Add \"condflags=open\" to sacctmgr show events to return open/currently down\n    events.\n -- Skip --mem-per-gpu impact on GRES availability when CR_MEMORY not set.\n -- Add reservation start time as a new schedulers sorting factor for magnetic\n    or multi-reservation job queue records.\n -- Improve Dynamic Future node startup to load in config with mapped nodename.\n -- Add new shard plugin for sharing gpus but not with mps.\n -- acct_gather_energy/xcc - add support for Lenovo SD650 V2.\n -- Remove cgroup_allowed_devices_file.conf support.\n -- sacct -f flag implies -c flag.\n -- Node state flags (DRAIN, FAILED, POWERING UP, etc.) will be cleared now if\n    node state is updated to FUTURE.\n -- Clear GRES environment variables for jobs or steps that request --gres=none.\n -- slurmctld - Avoid requiring environment to be set when container job is\n    specified.\n -- Move the KeepAliveTime option into CommunicationParameters.\n -- slurm.spec - stop explicitly packaging pkgconfig directory to avoid a\n    conflict with the pkgconfig package.\n -- Fix sacctmgr load dump printing incorrect default QOS when no value is set.\n -- Fix very early logging in the controller when daemonized\n -- Fix possibility of primary group going missing when running jobs submitted\n    after a user has switched primary groups (eg: with sg).\n -- Make it so srun no longer inherits SLURM_CPUS_PER_TASK. It now will only\n    inherit SRUN_CPUS_PER_TASK.\n -- Make HetJob signaling requests using the HetJobId+HetJobOffset format behave\n    the same as with direct JobId requests with regards to job state and\n    whole_hetjob considerations.\n -- scancel - avoid issuing a RPC for each HetJob non-leader components hit by\n    using filters (not using jobids) when a RPC is issued for their leader.\n -- Make slurmctld call the JobCompPlugin set location operation on SIGUSR2. As\n    a relevant consequence, the filetxt plugin reopens the file for potential\n    logrotation.\n -- openapi/v0.0.38 - added fields bf_table_size and bf_table_size_mean to\n    diag query.\n -- Handle scontrol setdebug[flags] and scontrol reconfigure in slurmscriptd.\n -- openapi/v0.0.38 - add /licenses endpoint.\n -- slurmrestd - only compile JWT authentication plugin if libjwt is present.\n -- Remove connect_timeout and timeout options from JobCompParams as there's no\n    longer a connectivity check happening in the jobcomp/elasticsearch plugin\n    when setting the location off of JobCompLoc.\n -- Add %n for NodeName substitution in SlurmdSpoolDir in nss_slurm.conf.\n -- job_container/tmpfs - add basic environment variables to InitScript.\n -- openapi/dbv0.0.38 - split security entries in openapi.json.\n -- openapi/v0.0.38 - Add schema for Slurm meta in responses.\n -- openapi/dbv0.0.38 - Add schema for Slurm meta in responses.\n -- openapi/v0.0.38 - Correct field \"errno\" to \"error_number\" in schema for\n    errors.\n -- openapi/dbv0.0.38 - add failure response contents in openapi.json.\n -- openapi/v0.0.38 - add failure response contents in openapi.json.\n -- openapi/dbv0.0.38 - add requestBody for /users/ in openapi.json.\n -- openapi/dbv0.0.38 - add requestBody for /accounts/ in openapi.json.\n -- openapi/dbv0.0.38 - add missing response field \"removed_associations\"\n    in openapi.json\n -- openapi/dbv0.0.38 - Correct type from object to array for user associations\n    list in openapi.json.\n -- openapi/dbv0.0.38 - Add missing field for tres minutes per qos in qos list\n    in openapi.json.\n -- openapi/dbv0.0.38 - Add missing field for name in qos list in openapi.json.\n -- openapi/dbv0.0.38 - Correct tres field in qos list in openapi.json.\n -- openapi/dbv0.0.38 - Correct het job details types in jobs in openapi.json\n -- openapi/dbv0.0.38 - Correct task type for job steps in openapi.json.\n -- openapi/dbv0.0.38 - Sync fields for errors to source in openapi.json.\n -- openapi/dbv0.0.38 - Add missing field for adding clusters in clusters list\n    in openapi.json.\n -- openapi/v0.0.38 - correct parameter styles from \"simple\" to \"form\".\n -- openapi/dbv0.0.38 - correct parameter styles from \"simple\" to \"form\".\n -- openapi - add flags to slurm_openapi_p_get_specification().\n -- openapi/v0.0.38 - use new operationId generation to ensure uniqueness.\n -- openapi/dbv0.0.38 - use new operationId generation to ensure uniqueness.\n -- slurmstepd - avoid possible race condition while updating step return code\n    during job startup.\n -- slurmstepd - report and log I/O setup failure using corresponding error\n    code during job start.\n -- Do not run the job if PrologSlurmctld times out.\n -- Fix SPANK plugin calls slurm_spank_job_prolog and slurm_spank_job_epilog\n    not properly respecting PrologEpilogTimeout.\n -- Add support for 'scontrol delete <ENTITY> <ID>' format alongside the already\n    expected 'scontrol delete <ENTITY>=<ID>'.\n -- Fix task/cgroup plugin which was not adding stepd to memory cgroup.\n -- preempt/qos - add support for WITHIN mode to allow for preemption between\n    jobs within the same qos.\n -- Fix sattach for interactive step.\n -- Fix srun -Z when using nss_slurm.\n -- Avoid memory leak in srun -Z.\n -- openapi/dbv0.0.38 - disable automatic lookup of all HetJob components on\n    specific job lookups.\n -- Add support for hourly reoccurring reservations.\n -- openapi/v0.0.38 - Fix misspelling of job parameter time_minimum.\n -- openapi/v0.0.38 - Fix misspelling of job parameter cpu_binding_hint.\n -- openapi/v0.0.38 - Fix misspelling of job parameter mcs_label\n -- openapi/dbv0.0.38 - Fix issue where association's QOS list consisted of IDs\n    instead of names.\n -- Allow nodes to be dynamically added and removed from the system.\n -- srun --overlap now allows the step to share all resources (CPUs, memory, and\n    GRES), where previously --overlap only allowed the step to share CPUs with\n    other steps.\n -- openapi/v0.0.38 - new format for how core and socket allocations are dumped\n    for jobs.\n -- openapi/v0.0.38 - add RPC call statistics to diag endpoint.\n -- openapi/[db]v0.0.36 - plugins have been marked as deprecated.\n -- sacct - allocations made by srun will now always display the allocation and\n    step(s). Previously, the allocation and step were combined when possible.\n -- Steps now allocate gres according to topo data.\n -- Add validation of numbers provided to --gpu-bind=map_gpu and\n    --gpu-bind=mask_gpu=.\n -- Fatal error if CgroupReleaseAgentDir is configured in cgroup.conf. The\n    option has long been obsolete.\n -- cons_tres - change definition of the \"least loaded node\" (LLN) to the\n    node with the greatest ratio of available cpus to total cpus.\n -- Fatal if more than one burst buffer plugin is configured.\n -- Added keepaliveinterval and keepaliveprobes options to\n    CommunicationParameters.\n -- Correctly failover to backup slurmdbd if the primary slurmdbd node crashes.\n -- Add support to ship Include configuration files with configless.\n -- Fix issues with track_script cleanup.\n -- Add new max_token_lifespan limit to AuthAltParameters.\n -- sacctmgr - allow Admins to update AdminComment and SystemComment fields.\n -- slurmd - Cache node features at startup and scontrol reconfig. It avoids\n    executing node_features/helpers scripts in the middle of a job. This clould\n    potentially affect job performance.\n -- Pass and use alias_list through credential instead of environment variable.\n -- Add ability to get host addresses from nss_slurm.\n -- Enable reverse fanout for cloud+alias_list jobs.\n -- Disallow slurm.conf node configurations with NodeName=ALL.\n -- Add support to delete/update nodes by specifying nodesets or the 'ALL'\n    keyword alongside the delete/update node message nodelist expression (i.e.\n    'scontrol delete/update NodeName=ALL' or 'scontrol delete/update\n    NodeName=ns1,nodes[1-3]').\n -- Add support for PMIx v4\n -- Add support for PMIx v5\n -- Correctly load potentially NULL values from slurmdbd archive files.\n -- Add slurmdbd.conf option AllowNoDefAcct to remove requirement for users to\n    have a default account.\n -- Fix issues related to users with very large uids.\n -- common/openapi - fix bug populating methods for parameter-less endpoint.\n -- slurmrestd/operations - fix memory leak when resolving bad path.\n -- sacctmgr - improve performance of query generation for archive load.\n -- sattach - allow connecting to interactive steps with JOBID.interactive\n -- Fix for --gpus-per-task parsing when using --cpus-per-gpu and multiple gpu\n    types in the same request.\n -- rest_auth/local - always log when new slurmdbd connection fails.\n -- openapi/dbv0.0.38 - gracefully update existing associations.\n -- Improve auto-detection of pmix\n -- openapi/dbv0.0.38 - Add missing method POST for /qos/.\n -- scrontab - On errors, print 1-index line numbers instead of 0-indexing them.\n -- openapi/dbv0.0.38 - Correct OpenAPI specification for diag request.\n -- openapi/dbv0.0.38 - reject requests with incorrect TRES specification.\n -- sacctmgr - reject requests with incorrect TRES specification.\n -- Correct issue where conversion to/from JSON/YAML may have resulted in empty\n    strings being replaced with strings containing \"null\" instead.\n -- Attempt to requeue jobs terminated by slurm.conf changes (node vanish, node\n    socket/core change, etc). Processes may still be running on excised nodes.\n    Admin should take precautions when removing nodes that have jobs on running\n    on them.\n -- Fix race with task/cgroup memory and jobacctgather/cgroup, the first was\n    removing the pid from the task_X cgroup directory.\n -- openapi/dbv0.0.38 - set default account org and desc to be account name.\n -- openapi/dbv0.0.38 - Allow strings for JobId instead of only numerical JobId\n    for GET job methods.\n -- Add switch/hpe_slingshot plugin.\n -- cloud_reg_addrs - use hostname from slurmd rather than from munge\n    credential for NodeHostName.\n -- Store assoc usage in parent assoc when deleted to preserve account\n    fairshare.\n -- CVE-2022-29500 - Prevent credential abuse.\n -- CVE-2022-29501 - Prevent abuse of REQUEST_FORWARD_DATA.\n -- CVE-2022-29502 - Correctly validate io keys.\n -- openapi/dbv0.0.38 - set with_deleted to false by default for /user[s].\n -- openapi/dbv0.0.38 - add with_deleted input parameter to GET /user[s].\n -- openapi/dbv0.0.38 - add deleted flag to /user[s] output.\n -- openapi/dbv0.0.38 - set with_deleted to false by default for GET /qos.\n -- openapi/dbv0.0.38 - add with_deleted input to GET /qos.\n -- openapi/dbv0.0.38 - set with_deleted to false by default for GET /account[s]\n -- openapi/dbv0.0.38 - add with_deleted input to GET /account[s].\n -- Include k12 hash of the RPC message body in the auth/munge tokens to\n    provide for additional communication resiliency.\n -- Allow job steps to continue to launch during OverTimeLimit.\n -- slurmctld - avoid crash when attempting to load job without a script.\n -- Fix exclusive jobs breaking MaxCPUsPerNode limit\n -- Error if ConstrainSwapSpace is set and system doesn't have the kernel with\n    CONFIG_MEMCG_SWAP set. This will avoid bad configurations.\n -- Add SlurmdParameters=numa_node_as_socket.\n -- Fix incorrect node allocation when using multiple counts with --constraint\n    and --ntasks-per-node.\n\n* Changes in Slurm 21.08.9\n==========================\n -- Fix cross-endian communication.\n -- Fix slurmd segfault when seeing authentication issues alongside a failed\n    message forward.\n -- Fix resuming nodes not part of an allocation.\n -- Fix \"--gpu-bind=single:\" having wrong env variables.\n -- Fix logic estimating when a job can start based on ANY_NODES / LICENSE_ONLY\n    reservations that could lead to an infinite loop in backfill.\n -- Fix a segfault that may happen on gpu configured as no_consume.\n -- Fix regression which prevented a cons_tres gpu job to be submitted to a\n    cons_tres cluster from a non-con_tres cluster.\n -- select/linear - fix regression introduced in 21.08.6 which prevented step\n    requests with --threads-per-core or --hint=nomultithread from being created.\n -- Fix gcc 12.2.1 compile errors.\n\n* Changes in Slurm 21.08.8-2\n============================\n -- Fix communication forwarding when running with a mix of patch and unpatched\n    slurmd processes.\n\n* Changes in Slurm 21.08.8\n==========================\n -- openapi/dbv0.0.37 - fix slurmrestd fatal() when deleting an association.\n -- Allow scontrol update <job> Gres=... to not require \"gres:\".\n -- Fix inconsistent reboot message appending behavior.\n -- Fix incorrect reason_time and reason_uid on reboot message.\n -- Fix \"scontrol reboot\" clearing node reason on ResumeTimeout.\n -- Fix ResumeTimeout error message missing when node already has reason set.\n -- Avoid \"running with local config\" error when conf server is provided by DNS.\n -- openapi/v0.0.37 - resolve job user name when not sent by slurmctld.\n -- openapi/dbv0.0.37 - Correct OpenAPI specification for diag request.\n -- Ignore power_down request when node is already powering down.\n -- CVE-2022-29500 - Prevent credential abuse.\n -- CVE-2022-29501 - Prevent abuse of REQUEST_FORWARD_DATA.\n -- CVE-2022-29502 - Correctly validate io keys.\n\n* Changes in Slurm 21.08.7\n==========================\n -- openapi/v0.0.37 - correct calculation for bf_queue_len_mean in /diag.\n -- Optimize sending down nodes in maintenance mode to the database when\n    removing reservations.\n -- Avoid shrinking a reservation when overlapping with downed nodes.\n -- Fix 'planned time' in rollups for jobs that were still pending when the\n    rollup happened.\n -- Prevent new elements from a job array from causing rerollups.\n -- Only check TRES limits against current usage for TRES requested by the job.\n -- Do not allocate shared gres (MPS) in whole-node allocations\n -- Fix minor memory leak when dealing with configless setups.\n -- Constrain slurmstepd to job/step cgroup like in previous versions of Slurm.\n -- Fix warnings on 32-bit compilers related to printf() formats.\n -- Fix memory leak when freeing kill_job_msg_t.\n -- Fix memory leak when using data_t.\n -- Fix reconfigure issues after disabling/reenabling the GANG PreemptMode.\n -- Fix race condition where a cgroup was being deleted while another step\n    was creating it.\n -- Set the slurmd port correctly if multi-slurmd\n -- openapi/v0.0.37 - Fix misspelling of account_gather_frequency in spec.\n -- openapi/v0.0.37 - Fix misspelling of cluster_constraint in spec.\n -- Fix FAIL mail not being sent if a job was cancelled due to preemption.\n -- slurmrestd - move debug logs for HTTP handling to be gated by debugflag\n    NETWORK to avoid unnecessary logging of communication contents.\n -- Fix issue with bad memory access when shrinking running steps.\n -- Fix various issues with internal job accounting with GRES when jobs are\n    shrunk.\n -- Fix ipmi polling on slurmd reconfig or restart.\n -- Fix srun crash when reserved ports are being used and het step fails\n    to launch.\n -- openapi/dbv0.0.37 - fix DELETE execution path on /user/{user_name}.\n -- slurmctld - Properly requeue all components of a het job if PrologSlurmctld\n    fails.\n -- rlimits - remove final calls to limit nofiles to 4096 but to instead use\n    the max possible nofiles in slurmd and slurmdbd.\n -- Fix slurmctld memory leak after a reconfigure with configless.\n -- Fix slurmd memory leak when fetching configless files.\n -- Allow the DBD agent to load large messages (up to MAX_BUF_SIZE) from state.\n -- Fix minor memory leak with cleaning up the extern step.\n -- Fix potential deadlock during slurmctld restart when there is a completing\n    job.\n -- slurmstepd - reduce user requested soft rlimits when they are above max\n    hard rlimits to avoid rlimit request being completely ignored and\n    processes using default limits.\n -- Fix memory leaks when job/step specifies a container.\n -- Fix Slurm user commands displaying available features as active features\n    when no features were active.\n -- Don't power down nodes that are rebooting.\n -- Clear pending node reboot on power down request.\n -- Ignore node registrations while node is powering down.\n -- Don't reboot any node that is power<ing|ed> down.\n -- Don't allow a node to reboot if it's marked for power down.\n -- Fix issuing reboot and downing when rebooting a powering up node.\n -- Clear DRAIN on node after failing to resume before ResumeTimeout.\n -- Prevent repeating power down if node fails to resume before ResumeTimeout.\n -- Fix federated cloud node communication with srun and cloud_dns.\n -- Fix jobs being scheduled on nodes marked to be powered_down when idle.\n -- Fix problem where a privileged user could not view array tasks specified by\n    <array_job_id>_<task_id> when PrivateData had the jobs value set.\n\n* Changes in Slurm 21.08.6\n==========================\n -- Handle typed shared GRES better in accounting.\n -- Fix plugin_name definitions in a number of plugins to improve logging.\n -- Close sbcast file transfers when job is cancelled.\n -- job_submit/lua - allow mail_type and mail_user fields to be modified.\n -- scrontab - fix handling of --gpus and --ntasks-per-gpu options.\n -- sched/backfill - fix job_queue_rec_t memory leak.\n -- Fix magnetic reservation logic in both main and backfill schedulers.\n -- job_container/tmpfs - fix memory leak when using InitScript.\n -- slurmrestd / openapi - fix memory leaks.\n -- Fix slurmctld segfault due to job array resv_list double free.\n -- Fix multi-reservation job testing logic.\n -- Fix slurmctld segfault due to insufficient job reservation parse validation.\n -- Fix main and backfill schedulers handling for already rejected job array.\n -- sched/backfill - restore resv_ptr after yielding locks.\n -- acct_gather_energy/xcc - appropriately close and destroy the IPMI context.\n -- Protect slurmstepd from making multiple calls to the cleanup logic.\n -- Prevent slurmstepd segfault at cleanup time in mpi_fini().\n -- Fix slurmctld sometimes hanging if shutdown while PrologSlurmctld or\n    EpilogSlurmctld were running and PrologEpilogTimeout is set in slurm.conf.\n -- Fix affinity of the batch step if batch host is different than the first\n    node in the allocation.\n -- slurmdbd - fix segfault after multiple failover/failback operations.\n -- Fix jobcomp filetxt job selection condition.\n -- Fix -f flag of sacct not being used.\n -- Select cores for job steps according to the socket distribution. Previously,\n    sockets were always filled before selecting cores from the next socket.\n -- Keep node in Future state if epilog completes while in Future state.\n -- Fix erroneous --constraint behavior by preventing multiple sets of brackets.\n -- Make ResetAccrueTime update the job's accrue_time to now.\n -- Fix sattach initialization with configless mode.\n -- Revert packing limit checks affecting pmi2.\n -- sacct - fixed assertion failure when using -c option and a federation\n    display\n -- Fix issue that allowed steps to overallocate the job's memory.\n -- Fix the sanity check mode of AutoDetect so that it actually works.\n -- Fix deallocated nodes that didn't actually launch a job from waiting for\n    Epilogslurmctld to complete before clearing completing node's state.\n -- Job should be in a completing state if EpilogSlurmctld when being requeued.\n -- Fix job not being requeued properly if all node epilog's completed before\n    EpilogSlurmctld finished.\n -- Keep job completing until EpilogSlurmctld is completed even when \"downing\"\n    a node.\n -- Fix handling reboot with multiple job features.\n -- Fix nodes getting powered down when creating new partitions.\n -- Fix bad bit_realloc which potentially could lead to bad memory access.\n -- slurmctld - remove limit on the number of open files.\n -- Fix bug where job_state file of size above 2GB wasn't saved without any\n    error message.\n -- Fix various issues with no_consume gres.\n -- Fix regression in 21.08.0rc1 where job steps failed to launch on systems\n    that reserved a CPU in a cgroup outside of Slurm (for example, on systems\n    with WekaIO).\n -- Fix OverTimeLimit not being reset on scontrol reconfigure when it is\n    removed from slurm.conf.\n -- serializer/yaml - use dynamic buffer to allow creation of YAML outputs\n    larger than 1MiB.\n -- Fix minor memory leak affecting openapi users at process termination.\n -- Fix batch jobs not resolving the username when nss_slurm is enabled.\n -- slurmrestd - Avoid slurmrestd ignoring invalid HTTP method if the response\n    serialized without error.\n -- openapi/dbv0.0.37 - Correct conditional that caused the diag output to\n    give an internal server error status on success.\n -- Make --mem-bind=sort work with task_affinity\n -- Fix sacctmgr to set MaxJobsAccruePer{User|Account} and MinPrioThres in\n    sacctmgr add qos, modify already worked correctly.\n -- job_container/tmpfs - avoid printing extraneous error messages in Prolog\n    and Epilog, and when the job completes.\n -- Fix step CPU memory allocation with --threads-per-core without --exact.\n -- Remove implicit --exact when --threads-per-core or --hint=nomultithread\n    is used.\n -- Do not allow a step to request more threads per core than the\n    allocation did.\n -- Remove implicit --exact when --cpus-per-task is used.\n\n* Changes in Slurm 21.08.5\n==========================\n -- Fix issue where typeless GRES node updates were not immediately reflected.\n -- Fix setting the default scrontab job working directory so that it's the home\n    of the different user (-u <user>) and not that of root or SlurmUser editor.\n -- Fix stepd not respecting SlurmdSyslogDebug.\n -- Fix concurrency issue with squeue.\n -- Fix job start time not being reset after launch when job is packed onto\n    already booting node.\n -- Fix updating SLURM_NODE_ALIASES for jobs packed onto powering up nodes.\n -- Cray - Fix issues with starting hetjobs.\n -- auth/jwks - Print fatal() message when jwks is configured but file could\n    not be opened.\n -- If sacctmgr has an association with an unknown qos as the default qos\n    print 'UNKN-###' instead of leaving a blank name.\n -- Correctly determine task count when giving --cpus-per-gpu, --gpus and\n    --ntasks-per-node without task count.\n -- slurmctld - Fix places where the global last_job_update was not being set\n    to the time of update when a job's reason and description were updated.\n -- slurmctld - Fix case where a job submitted with more than one partition\n    would not have its reason updated while waiting to start.\n -- Fix memory leak in node feature rebooting.\n -- Fix time limit permanetly set to 1 minute by backfill for job array tasks\n    higher than the first with QOS NoReserve flag and PreemptMode configured.\n -- Fix sacct -N to show jobs that started in the current second\n -- Fix issue on running steps where both SLURM_NTASKS_PER_TRES and\n    SLURM_NTASKS_PER_GPU are set.\n -- Handle oversubscription request correctly when also requesting\n    --ntasks-per-tres.\n -- Correctly detect when a step requests bad gres inside an allocation.\n -- slurmstepd - Correct possible deadlock when UnkillableStepTimeout triggers.\n -- srun - use maximum number of open files while handling job I/O.\n -- Fix writing to Xauthority files on root_squash NFS exports, which was\n    preventing X11 forwarding from completing setup.\n -- Fix regression in 21.08.0rc1 that broke --gres=none.\n -- Fix srun --cpus-per-task and --threads-per-core not implicitly setting\n    --exact. It was meant to work this way in 21.08.\n -- Fix regression in 21.08.0 that broke dynamic future nodes.\n -- Fix dynamic future nodes remembering active state on restart.\n -- Fix powered down nodes getting stuck in COMPLETING+POWERED_DOWN when job is\n    cancelled before nodes are powering up.\n\n* Changes in Slurm 21.08.4\n==========================\n -- Fix potential deadlock when using PMI v1.\n -- Fix tight loop sending DBD_SEND_MULT_JOB_START when the slurmctld has an\n    issue talking correctly to the DBD.\n -- Fix memory leak in step creation.\n -- Fix potential deadlock when shutting down slurmctld.\n -- Fix regression in 21.08 where multi-node steps that requested MemPerCPU\n    were not counted against the job's memory allocation on some nodes.\n -- Fix issue with select/cons_tres and the partition limit MaxCpusPerNode where\n    the limit was enforced for one less CPU than the configured value.\n -- jobacct_gather/common - compare Pss to Rss after scaling Pss to Rss units.\n -- Fix SLURM_NODE_ALIASES in RPC Prolog for batch jobs.\n -- Fix regression in 21.08 where slurmd and slurmstepd were not constrained\n    with CpuSpecList or CoreSpecCount.\n -- Fix cloud jobs running without powering up nodes after a reconfig/restart.\n -- CVE-2021-43337 - Fix security issue with new AccountingStoreFlags=job_script\n    and job_env options where users could request scripts and environments they\n    should not have been permitted to access.\n\n* Changes in Slurm 21.08.3\n==========================\n -- Return error to sacctmgr when running 'sacctmgr archive load' and the load\n    fails due to an invalid or corrupted file.\n -- slurmctld/gres_ctld - fix deallocation of typed GRES without device.\n -- scrontab - fix capturing the cronspec request in the job script.\n -- openapi/dbv0.0.37 - Add missing method POST for /associations/.\n -- If ALTER TABLE was already run, continue with database upgrade.\n -- slurmstepd - Gracefully handle RunTimeQuery returning no output.\n -- srun - automatically handle issues with races to listen() on an ephemeral\n    socket, and suppress otherwise needless error messages.\n -- Schedule sooner after Epilog completion with SchedulerParameters=defer.\n -- Improve performance for AccountingStoreFlags=job_env.\n -- Expose missing SLURMD_NODENAME and SLURM_NODEID to TaskEpilog environment.\n -- Bring slurm_completion.sh up to date with changes to commands.\n -- Fix issue where burst buffer stage-in could only start for one job in a job\n    array per scheduling cycle instead of bb_array_stage_cnt jobs per scheduling\n    cycle.\n -- Fix checking if the dependency is the same job for array jobs.\n -- Fix checking for circular dependencies with job arrays.\n -- Restore dependent job pointers on slurmctld startup to avoid race.\n -- openapi/v0.0.37 - Allow strings for JobIds instead of only numerical JobIds\n    for GET, DELETE, and POST job methods.\n -- openapi/dbv0.0.36 - Gracefully handle missing associations.\n -- openapi/dbv0.0.36 - Avoid restricting job association lookups to only\n    default associations.\n -- openapi/dbv0.0.37 - Gracefully handle missing associations.\n -- openapi/dbv0.0.37 - Avoid restricting job association lookups to only\n    default associations.\n -- Fix error in GPU frequency validation logic.\n -- Fix regression in 21.08.1 that broke federated jobs.\n -- Correctly handle requested GRES when used in job arrays.\n -- Fix error in pmix logic dealing with the incorrect size of buffer.\n -- Fix handling of no_consume GRES, add it to allocated job allocated TRES.\n -- Fix issue with typed GRES without Files= (bitmap).\n -- Fix job_submit/lua support for 'gres' which is now stored as a 'tres'\n    when requesting jobs so needs a 'gres' prefix.\n -- Fix regression where MPS would not deallocate from the node properly.\n -- Fix --gpu-bind=verbose to work correctly.\n -- Do not deny --constraint with special operators \"[]()|*\" when no changeable\n    features are requested, but continue to deny --constraint with special\n    operators when changeable features are requested.\n -- openapi/v0.0.{35,36,37} - prevent merging the slurmrestd environment\n    alongside a new job submission.\n -- openapi/dbv0.0.36 - Correct tree position of dbv0.0.36_job_step.\n -- openapi/dbv0.0.37 - Correct tree position of dbv0.0.37_job_step.\n -- openapi/v0.0.37 - enable job priority field for job submissions and updates.\n -- openapi/v0.0.37 - request node states query includes MIXED state instead of\n    only allocated.\n -- mpi/pmix - avoid job hanging until the time limit on PMIx agent failures.\n -- Correct inverted logic where reduced version matching applied to non-SPANK\n    plugins where it should have only applied to SPANK plugins.\n -- Fix issues where prologs would run in serial without PrologFlags=serial.\n -- Make sure a job coming in is initially considered for magnetic reservations.\n -- PMIx v1.1.4 and below are no longer supported.\n -- Add comment to service files about disabling logging through journald.\n -- Add SLURM_NODE_ALIASES env to RPC Prolog (PrologFlags=alloc) environment.\n -- Limit max_script_size to 512 MB.\n -- Fix shutdown of slurmdbd plugin to correctly notice when the agent thread\n    finishes.\n -- slurmdbd - fix issue with larger batch script files being sent to SlurmDBD\n    with AccountingStoreFlags=job_script that can lead to accounting data loss\n    as the resulting RPC generated can exceed internal limits and won't be\n    sent, preventing further communication with SlurmDBD.\n    This issue is indicated by \"error: Invalid msg_size\" in your log files.\n -- Fix compile issue with --without-shared-libslurm.\n\n* Changes in Slurm 21.08.2\n==========================\n -- slurmctld - fix how the max number of cores on a node in a partition are\n    calculated when the partition contains multi-socket nodes. This in turn\n    corrects certain jobs node count estimations displayed client-side.\n -- job_submit/cray_aries - fix \"craynetwork\" GRES specification after changes\n    introduced in 21.08.0rc1 that made TRES always have a type prefix.\n -- Ignore nonsensical check in the slurmd for [Pro|Epi]logSlurmctld.\n -- Fix writing to stderr/syslog when systemd runs slurmctld in the foreground.\n -- Fix locking around log level setting routines.\n -- Fix issue with updating job started with node range.\n -- Fix issue with nodes not clearing state in the database when the slurmctld\n    is started with clean-start.\n -- Fix hetjob components > 1 timing out due to InactiveLimit.\n -- Fix sprio printing -nan for normalized association priority if\n    PriorityWeightAssoc was not defined.\n -- Disallow FirstJobId=0.\n -- Preserve job start info in the database for a requeued job that hadn't\n    registered the first time in the database yet.\n -- Only send one message on prolog failure from the slurmd.\n -- Remove support for TaskAffinity=yes in cgroup.conf.\n -- accounting_storage/mysql - fix issue where querying jobs via sacct\n    --whole-hetjob=yes or slurmrestd (which automatically includes this flag)\n    could in some cases return more records than expected.\n -- Fix issue for preemption of job array task that makes afterok dependency\n    fail. Additionally, send emails when requeueing happens due to preemption.\n -- Fix sending requeue mail type.\n -- Properly resize a job's GRES bitmaps and counts when resizing the job.\n -- Fix node being able to transition to CLOUD state from non-cloud state.\n -- Fix regression introduced in 21.08.0rc1 which broke a step's ability to\n    inherit GRES from the job when the step didn't request GRES but the job did.\n -- Fix errors in logic when picking nodes based on bracketed anded constraints.\n    This also enforces the requirement to have a count when using such\n    constraints.\n -- Handle job resize better in the database.\n -- Exclude currently running, resized jobs from the runaway jobs list.\n -- Make it possible to shrink a job more than once.\n\n* Changes in Slurm 21.08.1\n==========================\n -- Fix potential memory leak if a problem happens while allocating GRES for\n    a job.\n -- If an overallocation of GRES happens terminate the creation of a job.\n -- AutoDetect=nvml: Fatal if no devices found in MIG mode.\n -- slurm.spec - fix querying for PMIx and UCX version.\n -- Print federation and cluster sacctmgr error messages to stderr.\n -- Fix off by one error in --gpu-bind=mask_gpu.\n -- Fix statement condition in http_parser autoconf macro.\n -- Fix statement condition in netloc autoconf macro.\n -- Add --gpu-bind=none to disable gpu binding when using --gpus-per-task.\n -- Handle the burst buffer state \"alloc-revoke\" which previously would not\n    display in the job correctly.\n -- Fix issue in the slurmstepd SPANK prolog/epilog handler where configuration\n    values were used before being initialized.\n -- Restore a step's ability to utilize all of an allocations memory if --mem=0.\n -- Fix --cpu-bind=verbose garbage taskid.\n -- Fix cgroup task affinity issues from garbage taskid info.\n -- Make gres_job_state_validate() client logging behavior as before 44466a4641.\n -- Fix steps with --hint overriding an allocation with --threads-per-core.\n -- Require requesting a GPU if --mem-per-gpu is requested.\n -- Return error early if a job is requesting --ntasks-per-gpu and no gpus or\n    task count.\n -- Properly clear out pending step if unavailable to run with available\n    resources.\n -- Kill all processes spawned by burst_buffer.lua including descendents.\n -- openapi/v0.0.{35,36,37} - Avoid setting default values of min_cpus,\n    job name, cwd, mail_type, and contiguous on job update.\n -- openapi/v0.0.{35,36,37} - Clear user hold on job update if hold=false.\n -- Prevent CRON_JOB flag from being cleared when loading job state.\n -- sacctmgr - Fix deleting WCKeys when not specifying a cluster.\n -- Fix getting memory for a step when the first node in the step isn't the\n    first node in the allocation.\n -- Make SelectTypeParameters=CR_Core_Memory default for cons_tres and cons_res.\n -- Correctly handle mutex unlocks in the gres code if failures happen.\n -- Give better error message if -m plane is given with no size.\n -- Fix --distribution=arbitrary for salloc.\n -- Fix jobcomp/script regression introduced in 21.08.0rc1 0c75b9ac9d.\n -- Only send the batch node in the step_hostlist in the job credential.\n -- When setting affinity for the batch step don't assume the batch host is node\n    0.\n -- In task/affinity better checking for node existence when laying out\n    affinity.\n -- slurmrestd - fix job submission with auth/jwt.\n -- Fix 'scontrol setdebug' not respecting slurm.conf logging configurations.\n\n* Changes in Slurm 21.08.0\n==========================\n -- Restored --gpu-bind=single:<ntasks> to check core affinity like\n    --gpu-bind=closest does. This removal of this behavior only was in rc2.\n -- slurmd - Fix assert failure on initialization due to bad node name.\n -- Fix error codes in cgroup/v1.\n -- Don't destroy the memory step outside fini, which leads to a double destroy\n    causing an error message.\n -- Add support for lua 5.4.\n -- Force cgroup.clone_children to 0 in slurm cgroup directories. This caused\n    issues in task cpuset plugin in systems with it enabled by default.\n -- Clear GRES HAS_TYPE flag when removing type name.\n -- Environment flags in gres.conf now override flags set by AutoDetect.\n -- Environment flags in gres.conf now apply to subsequent gres.conf lines where\n    Environment flags are not set.\n -- Set missing job_uid and job_gid members when preparing a kill_job_msg_t in\n    abort_job_on_node(), abort_job_on_nodes() and kill_job_on_node().\n -- Fix swappiness not being set in cgroups.\n -- Fix coordinators for new subaccounts.\n -- Fix coordinators when adding existing users with PrivateData=users.\n -- slurmctld - do not attempt to relinquish control to self.\n -- openapi/v0.0.37 - Honor kill_on_invalid_dependency as job parameter.\n -- Check max_gres when doing step allocation, fix for regression in rc2.\n -- SPANK plugins are now required to match the current Slurm version, and must\n    be recompiled for each new Slurm release.\n -- node_features/helpers - add ExecTime configuration option.\n -- srun - Fix force termination with -X.\n -- On slurmctld restart set node typed GRES counts correctly.\n -- Fix places where a step wasn't allocated in the slurmctld but wasn't ever\n    removed from the job.\n -- Fix step allocation memory when using --threads-per-core.\n -- Fix step allocations to consume all threads on a core when using\n    threads-per-core.\n -- Add check to validate cpu request on a step if --threads-per-core is given\n    and it is less than what the core on the node has in the allocation.\n -- Fix issue where a step could request more gres than the job had and the step\n    would hang forever. This bug was only introduced in 21.08.0rc2.\n -- Only print \\r\\n for logging messages on stderr when --pty has been\n    explicitly requested.\n -- Relax check on SPANK plugins to only require Slurm major + minor versions\n    to match.\n -- job_container/tmpfs - delegate handling of /dev/shm to the extern step\n    so new step launches will be attached correctly even after the slurmd\n    process has been restarted.\n -- Limit the wait time in proctrack_g_wait() to UnkillableStepTimeout instead\n    of a hardcoded value of 256 seconds, and limit the delay between tests to a\n    maximum of 32 seconds.\n -- fatal() on start if using job_container/tmpfs without PrologFlags=Contain.\n\n* Changes in Slurm 21.08.0rc2\n=============================\n -- Load bf_when_last_cycle from job state only if protocol version >= 21.08.\n -- Docs - remove man3 section entirely.\n -- Enable OCI container execution support as a technical preview.\n -- Set step memory when using MemPerGPU or DefMemPerGPU. Previously a step's\n    memory was not set even when it requested --mem-per-gpu and at least one\n    GPU.\n -- Add cli_filter.lua support in configless mode.\n -- Remove some of the MAX macro usages with return codes.\n -- Check that the step requests at least as many gres as nodes.\n -- sacct - Add --json and --yaml arguments.\n -- squeue - Add --json and --yaml arguments.\n -- sinfo - Add --json and --yaml arguments.\n -- Make job's SLURM_JOB_GPUS print global GPU IDs instead of MIG unique_ids.\n -- Fix miscounting of GPU envs in prolog/epilog if MultipleFiles was used.\n -- Support MIGs in prolog/epilog's CUDA_VISIBLE_DEVICES & co.\n -- Add SLURM_JOB_GPUS back into Prolog; add it to Epilog.\n -- Fix issue where the original executable, not the bcast'd version, was\n    executed with 'srun --bcast'.\n -- Fix memory leaks when cleaning up config_response_msg_t.\n -- sacct - print '-' header correctly for fields over 53-characters wide.\n -- openapi/dbv0.0.37 - replace \"REST\" with \"Slurm OpenAPI\" for plugin_name.\n -- openapi/v0.0.37 - replace \"REST\" with \"Slurm OpenAPI\" for plugin_name.\n -- configless - fix segfault on 'scontrol reconfigure'.\n -- Fix bad reference to step_ptr->job_ptr after step_ptr is freed.\n -- Fix bad reference to config_for_clients when shutting down slurmctld.\n -- Fix memory leak on gres_list_alloc when freeing steps.\n -- Fix memory leak on kill_job_msg_t->work_dir when freeing struct.\n -- Fix memory leak on slurmdb_step_rec_t->submit_line when freeing struct.\n -- Fix memory leak in the slurmdbd when requesting wckeys from all clusters.\n -- Use FREE_NULL_LIST instead of list_destroy.\n -- Fix bad pointer reference after bad unpack of jobacctinfo_t.\n -- If we made are running an interactive session we need to force track_steps.\n -- Disable OPOST flag when using --pty to avoid issues with Emac.\n -- Fix issue where extra bonus core was allocated in some situations.\n -- Avoid putting gres with count of 0 on a TRES req/alloc.\n -- Fix determining if a reservation is used or not.\n -- Fix memory in requested TRES when --mem-per-gpu is used.\n -- Changed ReqMem field in sacct to match memory from ReqTRES.\n -- Changed --gpu-bind=single:<ntasks> to no longer check core affinity like\n    --gpu-bind=closest does. This consequently affects --ntasks-per-gpu.\n\n* Changes in Slurm 21.08.0rc1\n=============================\n -- slurmrestd - add v0.0.37 OpenAPI plugin.\n -- slurmrestd/v0.0.37 - rename standard_in -> standard_input.\n -- slurmrestd/v0.0.37 - rename standard_out -> standard_output.\n -- slurmdbd - Improve log messages of more time than possible on rollups.\n -- Changed the --format handling for negative field widths (left justified)\n    to apply to the column headers as well as the printed fields.\n -- Add LimitFactor to the QOS. A float that is factored into an associations\n    [Grp|Max]TRES limits.  For example, if the LimitFactor is 2, then an\n    association with a GrpTRES of 30 CPUs, would be allowed to allocate 60\n    CPUs when running under this QOS.\n -- slurmrestd - Pass SLURM_NO_CHANGE_IN_DATA to client as 403 (Not Modified).\n -- slurmrestd/v0.0.37 - Add update_time field to Jobs query to allow clients\n    to only get jobs list based on change timestamp.\n -- Reset job eligible time when job is manually held.\n -- Add DEBUG_FLAG_JAG to improve logging related to job account gathering.\n -- Convert logging in account_gather/common to DEBUG_FLAG_JAG.\n -- Add more logging for jag_common_poll_data() when prec_extra() called.\n -- slurmrestd/v0.0.37 - add API to fetch reservation(s) info.\n -- Catch more errors in task/cgroup initialization and cleanup to avoid allowing\n    jobs to start when cgroups failure to configure correctly.\n -- Fix cgroup ns detection when using containers (e.g. LXC or Docker).\n -- Reset job's next_step_id counter to 0 after being requeued.\n -- Make scontrol exit with non-zero status after failing to delete a partition\n    or reservation.\n -- Make NtasksPerTRES optional in slurm_sprint_job_info().\n -- slurmrestd/v0.0.37 - Add update_time field to nodes query to allow clients\n    to only get nodes list based on change timestamp.\n -- common/parse_config - catch and propagate return codes when handling a match\n    on a key-value pattern. This implies error codes detected in the handlers\n    are now not ignored and users of _handle_keyvalue_match() can fatal().\n -- common/hostlist - fix hostlist_delete_nth() xassert() upper bound check.\n -- API change: Removed slurm_kill_job_msg and modified the function signature\n    for slurm_kill_job2. slurm_kill_job2 should be used instead of\n    slurm_kill_job_msg.\n -- Fix non-zero exit code for scontrol ping when all controllers are down.\n -- Enforce a valid configuration for AccountingStorageEnforce in slurm.conf.\n    If the configuration is invalid, then an error message will be printed and\n    the command or daemon (including slurmctld) will not run.\n -- slurmrestd/v0.0.37 - Add update_time field to partitions/reservations query\n    to allow clients to only get the entities list when something changed.\n -- slurmdbd.service - add \"After\" relationship to all common names for MariaDB\n    to reduce startup delays.\n -- slurmrestd/v0.0.37 - Correct displaying node states that are UNKNOWN.\n -- slurmrestd/v0.0.37 - Add flags to node states.\n -- Fix first job on fresh cluster not being assigned JobId=1 (or FirstJobId).\n -- squeue - make it so --nodelist is sensitive to --clusters.\n -- squeue - do --nodelist node validation in the same order as listing.\n -- Removed AccountingStoreJobComment option.  Please update your config to use\n    AccountingStoreFlags=job_comment instead.\n -- AccountingStoreFlags=job_script allows you to store the job's batch script.\n -- AccountingStoreFlags=job_env allows you to store the job's env vars.\n -- Add sacct -o SubmitLine to get the submit line of a job/step.\n -- Removed DefaultStorage{Host,Loc,Pass,Port,Type,User} options.\n -- Fix NtasksPerTRES delimiter from : to = in scontrol show job output.\n -- Removed CacheGroups, CheckpointType, JobCheckpointDir, MemLimitEnforce,\n    SchedulerPort, SchedulerRootFilter options.\n -- Make job accounting queries use consistent timeframes with and w/o jobs.\n -- --cpus-per-task and --threads-per-core now imply --exact.\n    This fixes issues where steps would be allocated the wrong number of CPUs.\n -- configure: the --with option handling has been made consistent across the\n    various optional libraries. Specifying --with-foo=/path/to/foo will only\n    check that directory for the applicable library (rather than, in some cases,\n    falling back to the default directories), and will always error the build\n    if the library is not found (instead of a mix of error messages and non-\n    fatal warning messages).\n -- configure: replace --with-rmsi_dir option with proper handling for\n    --with-rsmi=dir.\n -- Pass additional job environment variables to MailProg.\n -- Add SLURM_JOB_WORK_DIR to Prolog, Epilog.\n -- Removed sched/hold plugin.\n -- Fix srun overwriting SLURM_SUBMIT_DIR and SLURM_SUBMIT_HOST when within an\n    existing allocation.\n -- step_ctx code has been removed from the api.\n -- cli_filter/lua, jobcomp/lua, job_submit/lua now load their scripts from the\n    same directory as the slurm.conf file (and thus now will respect changes\n    to the SLURM_CONF environment variable).\n -- SPANK - call slurm_spank_init if defined without slurm_spank_slurmd_exit in\n    slurmd context.\n -- job_container/tmpfs - Remove need for .active file to allow salloc without\n    an interactive step to work.\n -- Add new 'PLANNED' state to a node to represent when the backfill scheduler\n    has it planned to be used in the future instead of showing as 'IDLE'.\n -- slurmd - Delay background node registration on every failure up to 128s on\n    startup.\n -- slurmctld - Always notify slurmd that node registration was accepted to\n    avoid slurmd needless attempting to re-register if there is configuration\n    issue.\n -- Put node into \"INVAL\" state upon registering with an invalid node\n    configuration. Node must register with a valid configuration to continue.\n -- Make --cpu-bind=threads default for --threads-per-core -- cli and env can\n    override.\n -- jobcomp/elasticsearch - Use data_t to serialize data. The plugin now has the\n    JSON-C library as a prerequisite.\n -- scrontab - create the temporary file under the TMPDIR environment variable\n    (if set), otherwise continue to use TmpFS as configured in slurm.conf.\n -- Add LastBusyTime to \"scontrol show nodes\" and slurmrestd nodes output,\n    which represents the time the node last had jobs on it.\n -- slurmd - allow multiple comma-separated controllers to be specified in\n    configless mode with --conf-server\n -- sacctmgr - changed column headings to \"ParentID\" and \"ParentName\" instead\n    of \"Par ID\" and \"Par Name\" respectively.\n -- Perl API - make sure man pages are installed under the --prefix given to\n    configure.\n -- Manually powering down of nodes with scontrol now ignores\n    SuspendExc<Nodes|Parts>.\n -- SALLOC_THREADS_PER_CORE and SBATCH_THREADS_PER_CORE have been added as\n    input environment variables for salloc and sbatch, respectively. They do\n    the same thing as --threads-per-core.\n -- Distinguish queued reboot requests (REBOOT) from issued reboots (REBOOT^).\n -- Set the maximum number of open files per process to 4096 to avoid\n    performance issues when closing the entire range with closeall().\n -- auth/jwt - add support for RS256 tokens.\n -- Relax reservation purge due to any invalid uid after creation time.\n -- Reject srun that requests both --exclusive and --overlap.\n -- service files - change dependency to network-online rather than just\n    network to ensure DNS and other services are available.\n -- RSMI: Fix incorrect PCI BDF bits.\n -- plugins/cli_filter - Convert to using data_t to serialize JSON.\n -- Fix testing array job after regaining locks in backfill.\n -- Don't display node's comment with \"scontrol show nodes\" unless set.\n -- Add \"Extra\" field to node to store extra information other than a comment.\n -- scrontab - Use /tmp instead of TmpFS if TMPDIR is not set.\n -- Add ResumeTimeout, SuspendTimeout and SuspendTime to Partitions.\n -- sreport - change to sorting TopUsage by the --tres option.\n -- slurmrestd - do not run allow operation as SlurmUser/root by default.\n -- Allow map_cpu and mask_cpu for non-whole node allocation.\n -- TaskPluginParam=verbose is now treated as a default. Previously it would be\n    applied regardless of the job specifying a --cpu-bind.\n -- Add \"node_reg_mem_percent\" SlurmctldParameter to define percentage of\n    memory nodes are allowed to register with.\n -- Show correct number of SocketsPerBoard in slurmd -C with hwloc2.\n -- Alter sreport's cluster utilization report column name from\n    'Reserved' to 'Planned' to match the nomenclature of the 'Planned' node.\n -- Add StateComplete format option to sinfo to show base_state+flags.\n -- \"scontrol show node\" now shows State as base_state+flags instead of\n    shortened state with flags appended. eg. IDLE# -> IDLE+POWERING_UP.\n    Also \"POWER\" state flag string is \"POWERED_DOWN\".\n -- slurmd/req - add missing job_env_t's het_job_id initialization off the\n    request in _rpc_{abort,terminate}_job(). This caused problems for Native\n    Cray builds when joining a CNCU job_container plugin with Epilog configured.\n -- Fix joining a CNCU job_container on a Native Cray build before executing the\n    UnkillableStepProgram for a HetJob step.\n -- slurmrestd/v0.0.35 - Plugin has been tagged as deprecated.\n -- srun - Job steps requiring more cores than available to be rejected unless\n    '--overlap' is specified.\n -- Add bf_node_space_size to SchedulerParameters.\n -- Add scontrol update node state=POWER_DOWN_FORCE and POWER_DOWN_ASAP as new\n    ways to power off and reset especially CLOUD nodes.\n -- Define and separate node power state transitions. Previously a powering\n    down node was in both states, POWERING_OFF and POWERED_OFF. These are now\n    separated.\n -- Create a new process called slurmscriptd which runs PrologSlurmctld and\n    EpilogSlurmctld. This avoids fork() calls from slurmctld, and can avoid\n    performance issues if the slurmctld has a large memory footprint.\n -- Added new Script option to DebugFlags for debugging slurmscriptd.\n -- scrontab - add ability to update crontab from a file or standard input.\n -- scrontab - add ability to set and expand variables.\n -- Pass JSON of job to node mappings to ResumeProgram.\n -- If running steps in an allocation with CR_PACK_NODE or -mpack the srun will\n    only attempt to allocate as much as needed from the allocation instead\n    of always trying to allocate every node in the allocation.\n -- Jobs that request the whole node now check to see if any gres are allocated.\n -- Rename SbcastParameters to BcastParameters.\n -- Make srun sensitive to BcastParameters.\n -- RSMI: Add gres_links_create_empty() and preserve RSMI enumeration order.\n -- GPUs: Use index instead of dev_num for CUDA_VISIBLE_DEVICES\n -- Don't run epilog on nodes if job never launched.\n -- QOS accrue limits only apply to the job QOS, not partition QOS.\n -- Add --gpu-bind=per_task:<gpus_per_task> option, --gpus-per-task will now\n    set this option by default.\n -- Treat any return code from SPANK plugin that is not SLURM_SUCCESS to be an\n    error or rejection.\n -- Print the statistics for extern step adopted processes in sstat.\n -- Fix SLURM_NODE_ALIASES to work for ipv6 node addrs.\n -- Add support for automatically detecting and broadcasting executable shared\n    object dependencies for sbcast and srun --bcast.\n -- Delay steps when memory already used instead of rejecting step request.\n\n* Changes in Slurm 20.11.10\n===========================\n -- Fix cross-endian communication.\n -- Fix slurmd segfault when seeing authentication issues alongside a failed\n    message forward.\n\n* Changes in Slurm 20.11.9\n==========================\n -- burst_buffer - add missing common directory to the Makefile SUBDIRS.\n -- sacct - fix truncation when printing jobidraw field.\n -- GRES - Fix loading state of jobs using --gpus to request gpus.\n -- Fix minor logic error in health check node state output\n -- Fix GCC 11.1 compiler warnings.\n -- Delay steps when memory already used instead of rejecting step request.\n -- Fix memory leak in the slurmdbd when requesting wckeys from all clusters.\n -- Fix determining if a reservation is used or not.\n -- openapi/v0.0.35 - Honor kill_on_invalid_dependency as job parameter.\n -- openapi/v0.0.36 - Honor kill_on_invalid_dependency as job parameter.\n -- Fix various issues dealing with updates on magnetic reservations that could\n    lead to abort slurmctld.\n -- openapi/v0.0.36 - Avoid setting default values of min_cpus, job name, cwd,\n    mail_type, and contiguous on job update.\n -- openapi/v0.0.36 - Clear user hold on job update if hold=false.\n -- Fix slurmctld segfault due to a bit_test() call with a MAINT+ANY_NODES\n    reservation NULL node_bitmap.\n -- Fix slurmctld segfault due to a bit_copy() call with a REPLACE+ANY_NODES\n    reservation NULL node_bitmap.\n -- Fix error in GPU frequency validation logic.\n -- Fix error in pmix logic dealing with the incorrect size of buffer.\n -- PMIx v1.1.4 and below are no longer supported.\n -- Fix shutdown of slurmdbd plugin to correctly notice when the agent thread\n    finishes.\n -- Fix slurmctld segfault due to job array --batch features double free.\n -- CVE-2022-29500 - Prevent credential abuse.\n -- CVE-2022-29501 - Prevent abuse of REQUEST_FORWARD_DATA.\n\n* Changes in Slurm 20.11.8\n==========================\n -- slurmctld - fix erroneous \"StepId=CORRUPT\" messages in error logs.\n -- Correct the error given when auth plugin fails to pack a credential.\n -- Fix unused-variable compiler warning on FreeBSD in fd_resolve_path().\n -- acct_gather_filesystem/lustre - only emit collection error once per step.\n -- srun - leave SLURM_DIST_UNKNOWN as default for --interactive.\n -- Add GRES environment variables (e.g., CUDA_VISIBLE_DEVICES) into the\n    interactive step, the same as is done for the batch step.\n -- Fix various potential deadlocks when altering objects in the database\n    dealing with every cluster in the database.\n -- slurmrestd - handle slurmdbd connection failures without segfaulting.\n -- slurmrestd - fix segfault for searches in slurmdb/v0.0.36/jobs.\n -- slurmrestd - remove (non-functioning) users query parameter for\n    slurmdb/v0.0.36/jobs from openapi.json\n -- slurmrestd - fix segfault in slurmrestd db/jobs with numeric queries\n -- slurmrestd - add argv handling for job/submit endpoint.\n -- srun - fix broken node step allocation in a heterogeneous allocation.\n -- Fail step creation if -n is not multiple of --ntasks-per-gpu.\n -- job_container/tmpfs - Fix slowdown on teardown.\n -- Fix problem with SlurmctldProlog where requeued jobs would never launch.\n -- job_container/tmpfs - Fix issue when restarting slurmd where the namespace\n    mount points could disappear.\n -- sacct - avoid truncating JobId at 34 characters.\n -- scancel - fix segfault when --wckey filtering option is used.\n -- select/cons_tres - Fix memory leak.\n -- Prevent file descriptor leak in job_container/tmpfs on slurmd restart.\n -- slurmrestd/dbv0.0.36 - Fix values dumped in job state/current and\n    job step state.\n -- slurmrestd/dbv0.0.36 - Correct description for previous state property.\n -- perlapi/libslurmdb - expose tres_req_str to job hash.\n -- scrontab - close and reopen temporary crontab file to deal with editors\n    that do not change the original file, but instead write out then rename\n    a new file.\n -- sstat - fix linking so that it will work when --without-shared-libslurm\n    was used to build Slurm.\n -- Clear allocated cpus for running steps in a job before handling requested\n    nodes on new step.\n -- Don't reject a step if not enough nodes are available. Instead, defer the\n    step until enough nodes are available to satisfy the request.\n -- Don't reject a step if it requests at least one specific node that is\n    already allocated to another step. Instead, defer the step until the\n    requested node(s) become available.\n -- slurmrestd - add description for slurmdb/job endpoint.\n -- Better handling of --mem=0.\n -- Ignore DefCpuPerGpu when --cpus-per-task given.\n -- sacct - fix segfault when printing StepId (or when using --long).\n\n* Changes in Slurm 20.11.7\n==========================\n -- slurmd - handle configless failures gracefully instead of hanging\n    indefinitely.\n -- select/cons_tres - fix Dragonfly topology not selecting nodes in the same\n    leaf switch when it should as well as requests with --switches option.\n -- Fix issue where certain step requests wouldn't run if the first node in the\n    job allocation was full and there were idle resources on other nodes in\n    the job allocation.\n -- Fix deadlock issue with <Prolog|Epilog>Slurmctld.\n -- torque/qstat - fix printf error message in output.\n -- When adding associations or wckeys avoid checking multiple times a user or\n    cluster name.\n -- Fix wrong jobacctgather information on a step on multiple nodes\n    due to timeouts sending its the information gathered on its node.\n -- Fix missing xstrdup which could result in slurmctld segfault on array jobs.\n -- Fix security issue in PrologSlurmctld and EpilogSlurmctld by always\n    prepending SPANK_ to all user-set environment variables. CVE-2021-31215.\n\n* Changes in Slurm 20.11.6\n==========================\n -- Fix sacct assert with the --qos option.\n -- Use pkg-config --atleast-version instead of --modversion for systemd.\n -- common/fd - fix getsockopt() call in fd_get_socket_error().\n -- Properly handle the return from fd_get_socket_error() in _conn_readable().\n -- cons_res - Fix issue where running jobs were not taken into consideration\n    when creating a reservation.\n -- Avoid a deadlock between job_list for_each and assoc QOS_LOCK.\n -- Fix TRESRunMins usage for partition qos on restart/reconfig.\n -- Fix printing of number of tasks on a completed job that didn't request\n    tasks.\n -- Fix updating GrpTRESRunMins when decrementing job time is bigger than it.\n -- Make it so we handle multithreaded allocations correctly when doing\n    --exclusive or --core-spec allocations.\n -- Fix incorrect round-up division in _pick_step_cores\n -- Use appropriate math to adjust cpu counts when --ntasks-per-core=1.\n -- cons_tres - Fix consideration of power downed nodes.\n -- cons_tres - Fix DefCpuPerGPU, increase cpus-per-task to match with\n    gpus-per-task * cpus-per-gpu.\n -- Fix under-cpu memory auto-adjustment when MaxMemPerCPU is set.\n -- Make it possible to override CR_CORE_DEFAULT_DIST_BLOCK.\n -- Perl API - fix retrieving/storing of slurm_step_id_t in job_step_info_t.\n -- Recover state of burst buffers when slurmctld is restarted to avoid skipping\n    burst buffer stages.\n -- Fix race condition in burst buffer plugin which caused a burst buffer\n    in stage-in to not get state saved if slurmctld stopped.\n -- auth/jwt - print an error if jwt_file= has not been set in slurmdbd.\n -- Fix RESV_DEL_HOLD not being a valid state when using squeue --states.\n -- Add missing squeue selectable states in valid states error message.\n -- Fix scheduling last array task multiple times on error, causing segfault.\n -- Fix issue where a step could be allocated more memory than the job when\n    dealing with --mem-per-cpu and --threads-per-core.\n -- Fix removing qos from assoc with -= can lead to assoc with no qos\n -- auth/jwt - fix segfault on invalid credential in slurmdbd due to\n    missing validate_slurm_user() function in context.\n -- Fix single Port= not being applied to range of nodes in slurm.conf\n -- Fix Jobs not requesting a tres are not starting because of that tres limit.\n -- acct_gather_energy/rapl - fix AveWatts calculation.\n -- job_container/tmpfs - Fix issues with cleanup and slurmd restarting on\n    running jobs.\n\n* Changes in Slurm 20.11.5\n==========================\n -- Fix main scheduler bug where bf_hetjob_prio truncates SchedulerParameters.\n -- Fix sacct not displaying UserCPU, SystemCPU and TotalCPU for large times.\n -- scrontab - fix to return the correct index for a bad #SCRON option.\n -- scrontab - fix memory leak when invalid option found in #SCRON line.\n -- Add errno for when a user requests multiple partitions and they are using\n    partition based associations.\n -- Fix issue where a job could run in a wrong partition when using\n    EnforcePartLimits=any and partition based associations.\n -- Remove possible deadlock when adding associations/wckeys in multiple\n    threads.\n -- When using PrologFlags=alloc make sure the correct Slurm version is set\n    in the credential.\n -- When sending a job a warning signal make sure we always send SIGCONT\n    beforehand.\n -- Fix issue where a batch job would continue running if a prolog failed on a\n    node that wasn't the batch host and requeuing was disabled.\n -- Fix issue where sometimes salloc/srun wouldn't get a message about a prolog\n    failure in the job's stdout.\n -- Requeue or kill job on a prolog failure when PrologFlags is not set.\n -- Fix race condition causing node reboots to get requeued before\n    ResumeTimeout expires.\n -- Preserve node boot_req_time on reconfigure.\n -- Preserve node power_save_req_time on reconfigure.\n -- Fix node reboots being queued and issued multiple times and preventing the\n    reboot to time out.\n -- Fix debug message related to GrpTRESRunMin (AssocGrpCPURunMinutesLimit).\n -- Fix run_command to exit correctly if track_script kills the calling thread.\n -- Only requeue a job when the PrologSlurmctld returns nonzero.\n -- When a job is signaled with SIGKILL make sure we flush all\n    prologs/setup scripts.\n -- Handle burst buffer scripts if the job is canceled while stage_in is\n    happening.\n -- When shutting down the slurmctld make note to ignore error message when\n    we have to kill a prolog/setup script we are tracking.\n -- scrontab - add support for the --open-mode option.\n -- acct_gather_profile/influxdb - avoid segfault on plugin shutdown if setup\n    has not completed successfully.\n -- Reduce delay in starting salloc allocations when running with prologs.\n -- Fix issue passing open fd's with [send|recv]msg.\n -- Alter AllocNodes check to work if the allocating node's domain doesn't\n    match the slurmctld's. This restores the pre-20.11 behavior.\n -- Fix slurmctld segfault if jobs from a prior version had the now-removed\n    INVALID_DEPEND state flag set and were allowed to run in 20.11.\n -- Add job_container/tmpfs plugin to give a method to provide a private /tmp\n    per job.\n -- Set the correct core affinity when using AutoDetect.\n -- Start relying on the conf again in xcpuinfo_mac_to_abs().\n -- Fix global_last_rollup assignment on job resizing.\n -- slurmrestd - hand over connection context on _on_message_complete().\n -- slurmrestd - mark \"environment\" as required for job submissions in schema.\n -- slurmrestd - Disable credential reuse on the same TCP connection. Pipelined\n    HTTP connections will have to provide authentication with every request.\n -- Avoid data conversion error on NULL strings in data_get_string_converted().\n -- Handle situation where slurmctld is too slow processing\n    REQUEST_COMPLETE_BATCH_SCRIPT and it gets resent from the slurmstepd.\n -- Fix sacct crashing with the --qos option\n\n* Changes in Slurm 20.11.4\n==========================\n -- Fix node selection for advanced reservations with features.\n -- mpi/pmix: Handle pipe failure better when using ucx.\n -- mpi/pmix: include PMIX_NODEID for each process entry.\n -- Fix job getting rejected after being requeued on same node that died.\n -- job_submit/lua - add \"network\" field.\n -- Fix situations when a reoccuring reservation could erroneously skip a\n    period.\n -- Ensure that a reservations [pro|epi]log are ran on reoccuring reservations.\n -- Fix threads-per-core memory allocation issue when using CR_CPU_MEMORY.\n -- Fix scheduling issue with --gpus.\n -- Fix gpu allocations that request --cpus-per-task.\n -- mpi/pmix: fixed print messages for all PMIXP_* macros\n -- Add mapping for XCPU to --signal option.\n -- Fix regression in 20.11 that prevented a full pass of the main scheduler\n    from ever executing.\n -- Work around a glibc bug in which \"0\" is incorrectly printed as \"nan\"\n    which will result in corrupted association state on restart.\n -- Fix regression in 20.11 which made slurmd incorrectly attempt to find the\n    parent slurmd address when not applicable and send incorrect reverse-tree\n    info to the slurmstepd.\n -- Fix cgroup ns detection when using containers (e.g. LXC or Docker).\n -- scrontab - change temporary file handling to work with emacs.\n\n* Changes in Slurm 20.11.3\n==========================\n -- Fix segfault when parsing bad \"#SBATCH hetjob\" directive.\n -- Allow countless gpu:<type> node GRES specifications in slurm.conf.\n -- PMIx - Don't set UCX_MEM_MMAP_RELOC for older version of UCX (pre 1.5).\n -- Don't green-light any GPU validation when core conversion fails.\n -- Allow updates to a reservation in the database that starts in the future.\n -- Better check/handling of primary key collision in reservation table.\n -- Improve reported error and logging in _build_node_list().\n -- Fix uninitialized variable in _rpc_file_bcast() which could lead to an\n    incorrect error return from sbcast / srun --bcast.\n -- mpi/cray_shasta - fix use-after-free on error in _multi_prog_parse().\n -- Cray - Handle setting correct prefix for cpuset cgroup with respects to\n    expected_usage_in_bytes.  This fixes Cray's OOM killer.\n -- mpi/pmix: Fix PMIx_Abort support.\n -- Don't reject jobs allocating more cores than tasks with MaxMemPerCPU.\n -- Fix false error message complaining about oversubscribe in cons_tres.\n -- scrontab - fix parsing of empty lines.\n -- Fix regression causing spank_process_option errors to be ignored.\n -- Avoid making multiple interactive steps.\n -- Fix corner case issues where step creation should fail.\n -- Fix job rejection when --gres is less than --gpus.\n -- Fix regression causing spank prolog/epilog not to be called unless the\n    spank plugin was loaded in slurmd context.\n -- Fix regression preventing SLURM_HINT=nomultithread from being used\n    to set defaults for salloc->srun, sbatch->srun sequence.\n -- Reject job credential if non-superuser sets the LAUNCH_NO_ALLOC flag.\n -- Make it so srun --no-allocate works again.\n -- jobacct_gather/linux - Don't count memory on tasks that have already\n    finished.\n -- Fix 19.05/20.02 batch steps talking with a 20.11 slurmctld.\n -- jobacct_gather/common - Do not process jobacct's with same taskid when\n    calling prec_extra.\n -- Cleanup all tracked jobacct tasks when extern step child process finishes.\n -- slurmrestd/dbv0.0.36 - Correct structure of dbv0.0.36_tres_list.\n -- Fix regression causing task/affinity and task/cgroup to be out of sync when\n    configured ThreadsPerCore is different than the physical threads per core.\n -- Fix situation when --gpus is given but not max nodes (-N1-1) in a job\n    allocation.\n -- Interactive step - ignore cpu bind and mem bind options, and do not set\n    the associated environment variables which lead to unexpected behavior\n    from srun commands launched within the interactive step.\n -- Handle exit code from pipe when using UCX with PMIx.\n -- Partially revert changes made in 20.11.0 to srun step behavior. This change\n    required steps to explicitly request resources, otherwise the minimal set\n    of resources required would be assigned. This broke OpenMPI's 'mpiexec'\n    alongside other use cases. This reverts the behavior such that all resources\n    on a node are assigned to the job step by default.\n -- srun - add a new --exact option, and deprecate the --whole option (which has\n    been restored as the default behavior).\n\n* Changes in Slurm 20.11.2\n==========================\n -- Fix older versions of sacct not working with 20.11.\n -- Fix slurmctld crash when using a pre-20.11 srun in a job allocation.\n -- Correct logic problem in _validate_user_access.\n -- Fix libpmi to initialize Slurm configuration correctly.\n\n* Changes in Slurm 20.11.1\n==========================\n -- Fix spelling of \"overcomited\" to \"overcomitted\" in sreport's cluster\n    utilization report.\n -- Silence debug message about shutting down backup controllers if none are\n    configured.\n -- Don't create interactive srun until PrologSlurmctld is done.\n -- Fix fd symlink path resolution.\n -- Fix slurmctld segfault on subnode reservation restore after node\n    configuration change.\n -- Fix resource allocation response message environment allocation size.\n -- Ensure that details->env_sup is NULL terminated.\n -- select/cray_aries - Correctly remove jobs/steps from blades using NPC.\n -- cons_tres - Avoid max_node_gres when entire node is allocated with\n    --ntasks-per-gpu.\n -- Allow NULL arg to data_get_type().\n -- In sreport have usage for a reservation contain all jobs that ran in the\n    reservation instead of just the ones that ran in the time specified. This\n    matches the report for the reservation is not truncated for a time period.\n -- Fix issue with sending wrong batch step id to a < 20.11 slurmd.\n -- Add a job's alloc_node to lua for job modification and completion.\n -- Fix regression getting a slurmdbd connection through the perl API.\n -- Stop the extern step terminate monitor right after proctrack_g_wait().\n -- Fix removing the normalized priority of assocs.\n -- slurmrestd/v0.0.36 - Use correct name for partition field:\n    \"min nodes per job\" -> \"min_nodes_per_job\".\n -- slurmrestd/v0.0.36 - Add node comment field.\n -- Fix regression marking cloud nodes as \"unexpectedly rebooted\" after\n    multiple boots.\n -- Fix slurmctld segfault in _slurm_rpc_job_step_create().\n -- slurmrestd/v0.0.36 - Filter node states against NODE_STATE_BASE to avoid\n    the extended states all being reported as \"invalid\".\n -- Fix race that can prevent the prolog for a requeued job from running.\n -- cli_filter - add \"type\" to readily distinguish between the CLI command in\n    use.\n -- smail - reduce sleep before seff to 5 seconds.\n -- Ensure SPANK prolog and epilog run without an explicit PlugStackConfig.\n -- Disable MySQL automatic reconnection.\n -- Fix allowing \"b\" after memory unit suffixes.\n -- Fix slurmctld segfault with reservations without licenses.\n -- Due to internal restructuring ahead of the 20.11 release, applications\n    calling libslurm MUST call slurm_init(NULL) before any API calls.\n    Otherwise the API call is likely to fail due to libslurm's internal\n    configuration not being available.\n -- slurm.spec - allow custom paths for PMIx and UCX install locations.\n -- Use rpath if enabled when testing for Mellanox's UCX libraries.\n -- slurmrestd/dbv0.0.36 - Change user query for associations to optional.\n -- slurmrestd/dbv0.0.36 - Change account query for associations to optional.\n -- mpi/pmix - change the error handler error message to be more useful.\n -- Add missing connection in acct_storage_p_{clear_stats, reconfig, shutdown}.\n -- Perl API - fix issue when running in configless mode.\n -- nss_slurm - avoid deadlock when stray sockets are found.\n -- Display correct value for ScronParameters in 'scontrol show config'.\n\n* Changes in Slurm 20.11.0\n==========================\n -- x11 forwarding: fix race on setup that prevented X11 forwarding from\n    working within the new Interactive Step.\n -- Fix various Coverity issues.\n -- cons_tres - Fix DefCpuPerGPU\n -- Make it so you can have a job with multiple partitions and multiple\n    reservations.\n -- Fix primary controller assert when shutting down backup controllers.\n -- Enforce invalid argument combinations with --ntasks-per-gpu\n -- slurmrestd/auth_local - Verify username on slurm_rest_auth_p_apply()\n -- Fix requeue of job on node failure.\n -- Prevent a job from requesting too much memory if it\n    requests MEM_PER_CPUS and --threads-per-core < the number of threads\n    on a core.\n -- slurmrestd - Avoid sending close header after body in\n    _operations_router_reject().\n -- slurmrestd - Set new job environment for SLURM_JOB_NAME, SLURM_OPEN_MODE,\n    SLURM_JOB_DEPENDENCY, SLURM_PROFILE, SLURM_ACCTG_FREQ, SLURM_NETWORK and\n    SLURM_CPU_FREQ_REQ to match sbatch.\n -- slurmrestd - Avoid defaulting open_mode to append for job submission.\n -- Fix \"scontrol takeover [backup]\" hangs when specifying a backup > 1.\n -- salloc now waits for PrologSlurmctld to finish before entering the shell.\n\n* Changes in Slurm 20.11.0rc2\n==============================\n -- MySQL - Remove potential race condition when sending updates to a cluster\n    and commit_delay used.\n -- Fixed regression in rc1 where sinfo et al would not show a node in a resv\n    state.\n -- select/linear will now allocate up to nodes RealMemory when configured with\n    SelectTypeParameters=CR_Memory and --mem=0 specified. Previous behavior was\n    no memory accounted and no memory limits implied to job.\n -- Remove unneeded lock check from running the slurmctld prolog for a job.\n -- Fix duplicate key error on clean starts after slurmctld is killed.\n -- Avoid double free of step_record_t in the slurmctld when node is removed\n    from config.\n -- Zero out step_record_t's magic when freed.\n -- Fix sacctmgr clearing QosLevel when trailing comma is used.\n -- slurmrestd - fix a fatal() error when connecting over IPv6.\n -- slurmrestd - add API to interface with slurmdbd.\n -- mpi/cray_shasta - fix PMI port parsing for non-contiguous port ranges.\n -- squeue and sinfo -O no longer repeat the last suffix specified.\n -- cons_tres - fix regression regarding gpus with --cpus-per-task.\n -- Avoid non-async-signal-safe functions calls in X11 forwarding which can\n    lead to the extern step terminating unexpectedly.\n -- Don't send job completion email for revoked federation jobs.\n -- Fix device or resource busy errors on cgroup cleanup on older kernels.\n -- Avoid binding to IPv6 wildcard address in slurmd if IPv6 is not explicitly\n    enabled.\n -- Make ntasks_per_gres work with cpus_per_task.\n -- Various alterations in reference to ntasks_per_tres.\n -- slurmrestd - multiple changes to make Slurm's OpenAPI spec compatible with\n    https://openapi-generator.tech/.\n -- nss_slurm - avoid loading slurm.conf to avoid issues on configless systems,\n    or systems with config files loaded on shared storage.\n -- scrontab - add cli_filter hooks.\n -- job_submit/lua - expose a \"cron_job\" flag to identify jobs submitted\n    through scrontab.\n -- PMIx - fix potential buffer overflows from use of unpackmem().\n    CVE-2020-27745.\n -- X11 forwarding - fix potential leak of the magic cookie when sent as an\n    argument to the xauth command. CVE-2020-27746.\n\n* Changes in Slurm 20.11.0rc1\n==============================\n -- Fix corner case issue with interrupted resource allocation requests.\n -- Pack all gres information in the slurmd to send to the stepd to help\n    reduce calls in the stepd to read gres.conf.\n -- The example systemd unit files have been changed to the \"simple\" type of\n    operation, and the daemon will now run in the foreground within systemd\n    instead of daemonizing itself.\n -- Add --gpu-bind=mask_gpu reusability functionality if tasks > elements.\n -- Add separate unversion libslurm_pmi.so library to use with libpmi.so.\n -- Configurations including CR_Socket and AllowSpecResourcesUsage=NO will now\n    fatal if there are no allocatable sockets due to core specialization.\n -- Make sacct get UID from database instead of from the username and a\n    system call. Add --use-local-uid option to sacct to use old behavior.\n -- Limit number of jobs updated by as_mysql_flush_jobs_on_cluster() to avoid\n    boot loop failures in slurmdbd.\n -- Add Autodetect option to NodeName line in gres.conf to override the global\n    Autodetect option.\n -- Add NetworkRaw debugflag.\n -- Make REQUEST_LAUNCH_PROLOG handler fail if PrologFlags includes Contain and\n    the credential has already expired when setting the memory limits.\n -- Reject jobs that request more nodes than provided in job credential if\n    PrologFlags includes Contain.\n -- Slurmdbd is now set to fatal if slurmdbd.conf file isn't owned by SlurmUser\n    or it's mode is not set to 0600.\n -- libsrun/opt - use slurm_option_reset() when ignoring ntasks_per_node.\n -- Removed \"regression\" script from testsuite. Please use regression.py.\n -- Avoid communication issues if TreeWidth greatly exceeds the node count\n    for a job.\n -- accounting_storage/filetxt has been removed as an option.\n -- Update and validate reservations after loading from state save.\n -- Update and validate reservations after setting node to down, drain or\n    updating node state.\n -- Change reservation selection order to attempt to reserve unreserved nodes\n    first, followed by reserved nodes under OVERLAP|MAINT reservations, and\n    finally all nodes in the partition for MAINT reservations.\n -- Add [Accounting]StorageParameters slurm[dbd].conf parameter.\n -- Improve detection and logging of incompatible options involving the\n    REPLACE[_DOWN] flags when creating/updating reservations.\n -- Export SLURMD_NODENAME envvar to HealthCheckProgram.\n -- SlurmctldParameters=user_resv_delete which allows any user able to run\n    in a reservation to delete it.\n -- Set default unit when parsing #BSUB -M to KB to match LSF documentation.\n -- slurmrestd - fatal() when accept() returns an unexpected result.\n -- slurmrestd - Parse multiple OpenAPI specifications for path resolution.\n -- slurmrestd - Add v0.0.36 OpenAPI plugin.\n -- slurmrestd/v0.0.36 - Add error schema.\n -- slurmrestd/v0.0.36 - return array of nodes instead of dictionary.\n -- slurmrestd/v0.0.36 - return array of partitions instead of dictionary\n -- slurmrestd/v0.0.36 - return -1 (integer) instead of INFINITE (as a string)\n -- slurmrestd/v0.0.36 - return array of pings instead of dictionary\n -- slurmrestd/v0.0.36 - Simplify possible signals for canceling jobs.\n -- slurmrestd/v0.0.36 - Simplify exclusive for jobs submissions.\n -- slurmrestd/v0.0.36 - Simplify nodes for jobs submissions.\n -- slurmrestd/v0.0.36 - Use \"/slurm/v0.0.36/\" as server instead of \"/\" to\n    simply naming for clients.\n -- Add 'scontrol update res=name skip' to skip the current/next reoccurring\n    reservation.\n -- Add ability for reservations to be accessed by Linux Groups.\n -- Let users submit to multiple reservations as they can partitions.\n -- Report a wider range of error codes for sbcast when opening a file.\n -- Rename acct_gather_energy/cray_aries to acct_gather_energy/pm_counters.\n -- Removed gres_alloc and gres_req from job_record_t.Tres should be used\n    instead.\n -- The JobCompLoc URL endpoint when the JobCompType=jobcomp/elasticsearch\n    plugin is enabled is now fully configurable and the plugin no longer appends\n    a hardcoded \"/slurm/jobcomp\" index and type suffix to it.\n -- Add check to the reservation create/update logic to prevent an inconsistent\n    state without nodes and with no ANY_NODES flag with either Licenses,\n    BurstBuffer and/or Watts.\n -- slurmrestd - allow the host to be optional when specifying the address to\n    listen on.\n -- slurmrestd - Log numerical service name when referencing host port pairs.\n -- slurmrestd - Log host port information in RFC3986 format.\n -- sview - Remove (long-broken) batch job submission option.\n -- Dynamic Future Nodes - slurmds started with -F[<feature>] will be\n    associated with a nodename in Slurm that matches the same hardware\n    configuration.\n -- SlurmctldParameters=cloud_reg_addrs - Cloud nodes automatically get\n    NodeAddr and NodeHostname set from slurmd registration.\n -- SlurmctldParameters=power_save[_min]_interval - Configure how often the\n    power save module looks to do work.\n -- Add CLOUD state to sinfo --state filter list.\n -- Add ability for sinfo state filtering to require all listed states.\n -- Add the \"Reserved\" license count to 'scontrol show licenses'.\n -- Don't display MailUser/MailType in scontrol show jobs if mail won't be sent.\n -- Throw an error and ignore CpuSpecList if it cannot be translated to bitmap\n    of number of CPUs size.\n -- Validate at submission that --hint is mutually exclusive with --cpu-bind,\n    --ntasks-per-core, --threads-per-core or -B.\n -- Make --exclusive the default with srun as a step adding --overlap to\n    reverse behavior.\n -- Add --whole option to srun to allocate all resources on a node\n    in an allocation.\n -- Allow --threads-per-core to influence task layout/binding.\n -- Remove support for \"default_gbytes\" option from SchedulerParameters.\n -- gres.conf - Add new MultipleFiles configuration entry to allow a single\n    GRES to manage multiple device files simultaneously.\n -- Fix scontrol write config to output OverSubscribe instead of Shared.\n -- job_submit/lua - print/access oversubscribe variable with \"oversubscribe\".\n -- Remove SallocDefaultCommand option.\n -- Add support for an \"Interactive Step\", designed to be used with salloc to\n    launch a terminal on an allocated compute node automatically.\n -- Add time specification: \"now-<x>\" (i.e. subtract from the present)\n -- Add IPv6 support. Must be explicitly enabled with EnableIPv6 in\n    CommunicationParameters.\n -- Add LaunchParameters=mpir_use_nodeaddr configuration option.\n -- Allow use of a target directory with \"srun --bcast\", and change the default\n    filename to include the node name as well.\n -- Set -fno-omit-frame-pointer compiler flag.\n -- Add --mail-type=INVALID_DEPEND option to salloc, sbatch, and srun.\n -- Fix passing names with commas to the slurmdbd.\n -- squeue - put sorted start times of \"N/A\" or 0 at the end of the list.\n -- Add correspond_after_task_cnt to SchedulerParameters\n -- Fix node's not being considered unresponsive/down for ResumeTimeout after\n    reboot or power_up.\n -- Change \"scontrol reboot ASAP\" to use next_state=resume logic.\n -- Exclude HetJobs from GANG scheduling operations.\n -- Add scrontab as a new command.\n -- Enable -lnodes=#:gpus=# in #PBS/qsub -l nodes syntax.\n -- Add admin-settable \"Comment\" field to each Node.\n -- Fix show runaway and/on hidden partitions for >= Operator.\n -- Add --ntasks-per-gpu option.\n -- Add --gpu-bind=single option.\n\n* Changes in Slurm 20.02.8\n==========================\n\n* Changes in Slurm 20.02.7\n==========================\n -- cons_tres - Fix DefCpuPerGPU\n -- select/cray_aries - Correctly remove jobs/steps from blades using NPC.\n -- Fix false positive oom-kill events on extern step termination when\n    jobacct_gather/cgroup configured.\n -- Ensure SPANK prolog and epilog run without an explicit PlugStackConfig.\n -- Fix missing xstrdup which could result in slurmctld segfault on array jobs.\n -- Fix security issue in PrologSlurmctld and EpilogSlurmctld by always\n    prepending SPANK_ to all user-set environment variables. CVE-2021-31215.\n\n* Changes in Slurm 20.02.6\n==========================\n -- Fix sbcast --fanout option.\n -- Tighten up keyword matching for --dependency.\n -- Fix \"squeue -S P\" not sorting by partition name.\n -- Fix segfault in slurmctld if group resolution fails during job credential\n    creation.\n -- sacctmgr - Honor PreserveCaseUser when creating users with load command.\n -- Avoid attempting to schedule jobs on magnetic reservations when they aren't\n    allowed.\n -- Always make sure we clear the magnetic flag from a job.\n -- In backfill avoid NULL pointer dereference.\n -- Fix Segfault at end of slurmctld if you have a magnetic reservation and\n    you shutdown the slurmctld.\n -- Silence security warning when a Slurm is trying a job for a\n    magnetic reservation.\n -- Have sacct exit correctly when a user/group id isn't valid.\n -- Remove extra \\n from invalid user/group id error message.\n -- Detect when extern steps trigger OOM events and mark extern step correctly.\n -- pam_slurm_adopt - permit root access to the node before reading the config\n    file, which will give root a chance to fix the config if missing or broken.\n -- Reset DefMemPerCPU, MaxMemPerCPU, and TaskPluginParam (among other minor\n    flags) on reconfigure.\n -- Fix incorrect memory handling of mail_user when updating mail_type=none.\n -- Handle mail_user and mail_type independently.\n -- Fix thread-safety issue with assoc_mgr_get_admin_level().\n -- Ignore step features if equal to job features\n -- Fix slurmstepd segfault caused by incorrect strtok() usage.\n -- CRAY - Remove unneeded ATP spank plugin from ansible playbook.\n -- Fix core selection for exclusive step on nodes where CPUs == Cores.\n -- Fix topology aware scheduling reservations.\n -- Fix loading cpus_per_task on a job from state file.\n -- When a partition has no nodes fix estimate of max cpus possible on a job\n    trying to run there.\n -- In cons_tres fix sorting functions to handle node/topo weight\n    correctly.\n -- Fix regression in 20.02.5 where you couldn't request constraints with a\n    simple & and a count.\n -- Limit the number of threads for servicing emails.\n -- Avoid possible double init race condition in assoc_mgr_lock().\n -- Add missing locks in slurm_cred_handle_reissue().\n -- Add missing locks in slurm_cred_revoked().\n -- Fix slurmctld segfault due to tight reconfigure RPC requests by serializing\n    the RPC handler processing logic.\n -- Use _exit() instead exit() after fork().\n -- Perl API - fix hang reading config in configless environments.\n -- slurmrestd - request detailed node information to populate GRES fields.\n -- slurmrestd - request detailed job information to populate GRES fields.\n -- Fix job license update bug on array tasks or hetjob components.\n -- Fix job partition update bug on array tasks or hetjob components.\n -- Fix slurmctld segfault on _pick_best_nodes() when processing a job request\n    with XOR'd constraints and no nodeset has the feature.\n -- Fix job requests rejected with incorrect NODE_CONFIG_UNAVAIL when nodes are\n    actually only busy due to an overlapping MAINT reservation.\n -- Fix sacctmgr allowing the deletion of a user's default account.\n -- Fix srun and other Slurm commands running within a \"configless\" salloc\n    terminal.\n -- MySQL - Correctly handle QOS deletion from association tables.\n -- Fix update of First_Cores flag in a reservation.\n -- Fix parsing of update reservation flags.\n -- Fix --switches for cons_tres.\n -- Retry connection on ETIMEDOUT in slurm_send_addr_recv_msgs.\n -- Fix wait for RPC_PROLOG_LAUNCH notification 2*MessageTimeout.\n -- Have slurm_send_addr_recv_msgs conn_timeout to match rpc_wait in slurmd.\n -- pam_slurm_adopt - operate correctly even if ConstrainRAMSpace is not\n    enabled on the node by falling back to the cpuset, devices, or freezer\n    subsystem instead.\n -- slurmrestd - use memmove() instead of memcpy() in string manipulation\n    to avoid bugs related to overlapping memory regions.\n -- slurmrestd - avoid xassert() failure on duplicated headers in request.\n -- Remove stale 'ReqNodeNotAvail, Reserved for maintenance' message from\n    pending jobs after a maintenance reservation ended.\n -- MySQL - Stop steps from printing when outside time range.\n -- Fixed kmem limit calculation to use MaxKmemPercent correctly.\n -- Fix initialization of cpuset.mems/cpus on uid cgroup subdir.\n -- MySQL - Remove potential race condition when sending updates to a cluster\n    and commit_delay used.\n -- Avoid double free of step_record_t in the slurmctld when node is removed\n    from config.\n -- cons_tres - fix regression regarding gpus with --cpus-per-task.\n -- Don't send job completion email for revoked federation jobs.\n -- PMIx - fix potential buffer overflows from use of unpackmem().\n    CVE-2020-27745.\n -- X11 forwarding - fix potential leak of the magic cookie when sent as an\n    argument to the xauth command. CVE-2020-27746.\n\n* Changes in Slurm 20.02.5\n==========================\n -- Fix leak of TRESRunMins when job time is changed with --time-min\n -- pam_slurm - explicitly initialize slurm config to support configless mode.\n -- scontrol - Fix exit code when creating/updating reservations with wrong\n    Flags.\n -- When a GRES has a no_consume flag, report 0 for allocated.\n -- Fix cgroup cleanup by jobacct_gather/cgroup.\n -- When creating reservations/jobs don't allow counts on a feature unless\n    using an XOR.\n -- Improve number of boards discovery\n -- Fix updating a reservation NodeCnt on a zero-count reservation.\n -- slurmrestd - provide an explicit error messages when PSK auth fails.\n -- cons_tres - fix job requesting single gres per-node getting two or more\n    nodes with less CPUs than requested per-task.\n -- cons_tres - fix calculation of cores when using gres and cpus-per-task.\n -- cons_tres - fix job not getting access to socket without GPU or with less\n    than --gpus-per-socket when not enough cpus available on required socket\n    and not using --gres-flags=enforce binding.\n -- Fix HDF5 type version build error.\n -- Fix creation of CoreCnt only reservations when the first node isn't\n    available.\n -- Fix wrong DBD Agent queue size in sdiag when using accounting_storage/none.\n -- Improve job constraints XOR option logic.\n -- Fix preemption of hetjobs when needed nodes not in leader component.\n -- Fix wrong bit_or() messing potential preemptor jobs node bitmap, causing\n    bad node deallocations and even allocation of nodes from other partitions.\n -- Fix double-deallocation of preempted non-leader hetjob components.\n -- slurmdbd - prevent truncation of the step nodelists over 4095.\n -- Fix nodes remaining in drain state state after rebooting with ASAP option.\n\n* Changes in Slurm 20.02.4\n==========================\n -- srun - suppress job step creation warning message when waiting on\n    PrologSlurmctld.\n -- slurmrestd - fix incorrect return values in data_list_for_each() functions.\n -- mpi/pmix - fix issue where HetJobs could fail to launch.\n -- slurmrestd - set content-type header in responses.\n -- Fix cons_res GRES overallocation for --gres-flags=disable-binding.\n -- Fix cons_res incorrectly filtering cores with respect to GRES locality for\n    --gres-flags=disable-binding requests.\n -- Fix regression where a dependency on multiple jobs in a single array using\n    underscores would only add the first job.\n -- slurmrestd - fix corrupted output due to incorrect use of memcpy().\n -- slurmrestd - address a number of minor Coverity warnings.\n -- Handle retry failure when slurmstepd is communicating with srun correctly.\n -- Fix jobacct_gather possibly duplicate stats when _is_a_lwp error shows up.\n -- Fix tasks binding to GRES which are closest to the allocated CPUs.\n -- Fix AMD GPU ROCM 3.5 support.\n -- Fix handling of job arrays in sacct when querying specific steps.\n -- slurmrestd - avoid fallback to local socket authentication if JWT\n    authentication is ill-formed.\n -- slurmrestd - restrict ability of requests to use different authentication\n    plugins.\n -- slurmrestd - unlink named unix sockets before closing.\n -- slurmrestd - fix invalid formatting in openapi.json.\n -- Fix batch jobs stuck in CF state on FrontEnd mode.\n -- Add a separate explicit error message when rejecting changes to active node\n    features.\n -- cons_common/job_test - fix slurmctld SIGABRT due to double-free.\n -- Fix updating reservations to set the duration correctly if updating the\n    start time.\n -- Fix update reservation to promiscuous mode.\n -- Fix override of job tasks count to max when ntasks-per-node present.\n -- Fix min CPUs per node not being at least CPUs per task requested.\n -- Fix CPUs allocated to match CPUs requested when requesting GRES and\n    threads per core equal to one.\n -- Fix NodeName config parsing with Boards and without CPUs.\n -- Ensure SLURM_JOB_USER and SLURM_JOB_UID are set in SrunProlog/Epilog.\n -- Fix error messages for certain invalid salloc/sbatch/srun options.\n -- pmi2 - clean up sockets at step termination.\n -- Fix 'scontrol hold' to work with 'JobName'.\n -- sbatch - handle --uid/--gid in #SBATCH directives properly.\n -- Fix race condition in job termination on slurmd.\n -- Print specific error messages if trying to run use certain\n    priority/multifactor factors that cannot work without SlurmDBD.\n -- Avoid partial GRES allocation when --gpus-per-job is not satisfied.\n -- Cray - Avoid referencing a variable outside of it's correct scope when\n    dealing with creating steps within a het job.\n -- slurmrestd - correctly handle larger addresses from accept().\n -- Avoid freeing wrong pointer with SlurmctldParameters=max_dbd_msg_action\n    with another option after that.\n -- Restore MCS label when suspended job is resumed.\n -- Fix insufficient lock levels.\n -- slurmrestd - use errno from job submission.\n -- Fix \"user\" filter for sacctmgr show transactions.\n -- Fix preemption logic.\n -- Fix no_consume GRES for exclusive (whole node) requests.\n -- Fix regression in 20.02 that caused an infinite loop in slurmctld when\n    requesting --distribution=plane for the job.\n -- Fix parsing of the --distribution option.\n -- Add CONF READ_LOCK to _handle_fed_send_job_sync.\n -- prep/script - always call slurmctld PrEp callback in _run_script().\n -- Fix node estimation for jobs that use GPUs or --cpus-per-task.\n -- Fix jobcomp, job_submit and cli_filter Lua implementation plugins causing\n    slurmctld and/or job submission CLI tools segfaults due to bad return\n    handling when the respective Lua script failed to load.\n -- Fix propagation of gpu options through hetjob components.\n -- Add SLURM_CLUSTERS environment variable to scancel.\n -- Fix packing/unpacking of \"unlinked\" jobs.\n -- Connect slurmstepd's stderr to srun for steps launched with --pty.\n -- Handle MPS correctly when doing exclusive allocations.\n -- slurmrestd - fix compiling against libhttpparser in a non-default path.\n -- slurmrestd - avoid compilation issues with libhttpparser < 2.6.\n -- Fix compile issues when compiling slurmrestd without --enable-debug.\n -- Reset idle time on a reservation that is getting purged.\n -- Fix reoccurring reservations that have Purge_comp= to keep correct\n    duration if they are purged.\n -- scontrol - changed the \"PROMISCUOUS\" flag to \"MAGNETIC\"\n -- Early return from epilog_set_env in case of no_consume.\n -- Fix cons_common/job_test start time discovery logic to prevent skewed\n    results between \"will run test\" executions.\n -- Ensure TRESRunMins limits are maintained during \"scontrol reconfigure\".\n -- Improve error message when host lookup fails.\n\n* Changes in Slurm 20.02.3\n==========================\n -- Factor in ntasks-per-core=1 with cons_tres.\n -- Fix formatting in error message in cons_tres.\n -- Fix calling stat on a NULL variable.\n -- Fix minor memory leak when using reservations with flags=first_cores.\n -- Fix gpu bind issue when CPUs=Cores and ThreadsPerCore > 1 on a node.\n -- Fix --mem-per-gpu for heterogeneous --gres requests.\n -- Fix slurmctld load order in load_all_part_state().\n -- Fix race condition not finding jobacct gather task cgroup entry.\n -- Suppress error message when selecting nodes on disjoint topologies.\n -- Improve performance of _pack_default_job_details() with large number of job\n    arguments.\n -- Fix archive loading previous to 17.11 jobs per-node req_mem.\n -- Fix regression validating that --gpus-per-socket requires --sockets-per-node\n    for steps. Should only validate allocation requests.\n -- error() instead of fatal() when parsing an invalid hostlist.\n -- nss_slurm - fix potential deadlock in slurmstepd on overloaded systems.\n -- cons_tres - fix --gres-flags=enforce-binding and related --cpus-per-gres.\n -- cons_tres - Allocate lowest numbered cores when filtering cores with gres.\n -- Fix getting system counts for named GRES/TRES.\n -- MySQL - Fix for handing typed GRES for association rollups.\n -- Fix step allocations when tasks_per_core > 1.\n -- Fix allocating more GRES than requested when asking for multiple GRES types.\n\n* Changes in Slurm 20.02.2\n==========================\n -- Fix slurmctld segfault when checking no_consume GRES node allocation counts.\n -- Fix resetting of cloud_dns on a reconfigure.\n -- squeue - change output for dependency column to use \"(null)\" instead of \"\"\n    for no dependencies as documented in the man page, and used by other columns.\n -- Clear node_cnt_wag after job update.\n -- Fix regression where AccountingStoreJobComment was not defaulting to 'yes'.\n -- Send registration message immediately after a node is resumed.\n -- Cray - Fix hetjobs when using only a single component in the step launch.\n -- Cray - Fix hetjobs launched without component 0.\n -- Cray - Quiet cookies missing message which is expected on for hetjobs.\n -- Fix handling of -m/--distribution options for across socket/2nd level by\n    task/affinity plugin.\n -- Fix grp_node_bitmap error when slurmctld started before slurmdbd.\n -- Fix scheduling issue when there are not enough nodes available to run a job\n    resulting in possible job starvation.\n -- Make it so mpi/cray_shasta appears in srun --mpi=list\n -- Don't requeue jobs that have been explicitly canceled.\n -- Fix error message for a regular user trying to update licenses on a running\n    job.\n -- Fix backup slurmctld handling for logrotation via SIGUSR2.\n -- Fix reservation feature specification when looking for inactive features\n    after active features fails.\n -- Prevent misleading error messages for reservation creation.\n -- Print message in scontrol when a request fails for not having enough nodes.\n -- Fix duplicate output in sacct with multiple resv events.\n -- auth/jwt - return correct gid for a given user. This was incorrectly\n    assuming the users's primary group name matched their username.\n -- slurmrestd - permit non-SlurmUser/root job submission.\n -- Use host IP if hostname unknown for job submission for allocating node.\n -- Fix issue with primary_slurmdbd_resumed_operation trigger not happening\n    on slurmctld restart.\n -- Fix race in acct_gather_interconnect/ofed on step termination.\n -- Fix typo of SlurmctldProlog -> PrologSlurmctld in error message.\n -- slurm.spec - add SuSE-specific dependencies for optional slurmrestd package.\n -- Fix FreeBSD build issues.\n -- Fixed sbatch not processing --ignore-pbs in batch script.\n -- Don't clear the qos_id of an invalid QOS.\n -- Allow a job that was once FAIL_[QOS|ACCOUNT] to be eligible again if\n    the qos|account limitation is remedied.\n -- Fix core reservations using the FLEX flag to allow use of resources\n    outside of the reservation allocation.\n -- Fix MPS without File with 1 GPU, and without GPUs.\n -- Add FreeBSD support to proctrack/pgid plugin.\n -- Fix remote dependency testing for meta job in job array.\n -- Fix preemption when dealing with a job array.\n -- Don't send remote non-pending singleton dependencies on federation update.\n -- slurmrestd - fix crash on empty query.\n -- Fix race condition which could lead to invalid references in backfill.\n -- Fix edge case in _remove_job_hash().\n -- Fix exit code when using --cluster/-M client options.\n -- Fix compilation issues in GCC10.\n -- Fix invalid references when federated job is revoked while in backfill loop.\n -- Fix distributing job steps across idle nodes within a job.\n -- Fix detected floating reservation overlapping.\n -- Break infinite loop in cons_tres dealing with incorrect tasks per tres\n    request resulting in slurmctld hang.\n -- Send the current (not the previous) reason for a pending job to client\n    commands like squeue/scontrol.\n -- Fix incorrect lock levels for select_g_reconfigure().\n -- Handle hidden nodes correctly in slurmrestd.\n -- Allow sacctmgr to use MaxSubmitP[U|A] as format options.\n -- Fix segfault when trying to delete a corrupted association.\n -- Fix setting ntasks-per-core when using --multithread.\n -- Only override job wait reason to priority if Reason=None or\n    Reason=Resources.\n -- Perl API / seff - fix missing symbol issue with accounting_storage/slurmdbd.\n -- slurm.spec - add --with cray_shasta option.\n -- Downgrade \"Node config differ..\" error message if config_overrides enabled.\n -- Add client error when using --gpus-per-socket without --sockets-per-node.\n -- Fix nvml/rsmi debug statements making it to stderr.\n -- NodeSets - fix slurmctld segfault in newer glibc if any nodes have no\n    defined features.\n -- ConfigLess - write out plugstack config to correct config file name in\n    the config cache.\n -- priority/multifactor - gracefully handle NULL list of associations or array\n    of siblings when calculating FairTree fairshare.\n -- Fix cons_tres --exclusive=user to allocate only requested number of CPUs.\n -- Add MySQL deadlock detection and automatic retry mechanism.\n -- Reject repeating floating reservations as they aren't supported.\n -- Fix testing of reservation flags that may be NO_VAL64.\n -- Fix _verify_node_state memory requested as --mem-per-gpu DefMemPerGPU.\n -- Fix DependencyNeverSatisfied not set as the job's state reason if\n    kill_invalid_depend or --kill-on-invalid-dep are used.\n -- pam_slurm_adopt - explicitly call slurm_conf_init().\n -- configless - fix plugstack.conf handling for client commands.\n -- Set SLURM_JOB_USER and SLURM_JOB_UID in task_epilog correctly.\n -- slurmrestd - authenticate job submissions by SlurmUser properly.\n\n* Changes in Slurm 20.02.1\n==========================\n -- Improve job state reason for jobs hitting partition_job_depth.\n -- Speed up testing of singleton dependencies.\n -- Fix negative loop bound in cons_tres.\n -- srun - capture the MPI plugin return code from mpi_hook_client_fini() and\n    use as final return code for step failure.\n -- Fix segfault in cli_filter/lua.\n -- Fix --gpu-bind=map_gpu reusability if tasks > elements.\n -- Make sure config_flags on a gres are sent to the slurmctld on node\n    registration.\n -- Prolog/Epilog - Fix missing GPU information.\n -- Fix segfault when using config parser for expanded lines.\n -- Fix bit overlap test function.\n -- Don't accrue time if job begin time is in the future.\n -- Remove accrue time when updating a job start/eligible time to the future.\n -- Fix regression in 20.02.0 that broke --depend=expand.\n -- Reset begin time on job release if it's not in the future.\n -- Fix for recovering burst buffers when using high-availability.\n -- Fix invalid read due to freeing an incorrectly allocated env array.\n -- Update slurmctld -i message to warn about losing data.\n -- Fix scontrol cancel_reboot so it clears the DRAIN flag and node reason for a\n    pending ASAP reboot.\n\n* Changes in Slurm 20.02.0\n==========================\n -- Fix minor memory leak in slurmd on reconfig.\n -- Fix invalid ptr reference when rolling up data in the database.\n -- Change shtml2html.py to require python3 for RHEL8 support, and match\n    man2html.py.\n -- slurm.spec - override \"hardening\" linker flags to ensure RHEL8 builds\n    in a usable manner.\n -- Fix type mismatches in the perl API.\n -- Prevent use of uninitialized slurmctld_diag_stats.\n -- Fixed various Coverity issues.\n -- Only show warning about root-less topology in daemons.\n -- Fix accounting of jobs in IGNORE_JOBS reservations.\n -- Fix issue with batch steps state not loading correctly when upgrading from\n    19.05.\n -- Deprecate max_depend_depth in SchedulerParameters and move it to\n    DependencyParameters.\n -- Silence erroneous error on slurmctld upgrade when loading federation state.\n -- Break infinite loop in cons_tres dealing with incorrect tasks per tres\n    request resulting in slurmctld hang.\n -- Improve handling of --gpus-per-task to make sure appropriate number of GPUs\n    is assigned to job.\n -- Fix seg fault on cons_res when requesting --spread-job.\n\n* Changes in Slurm 20.02.0rc1\n=============================\n -- sbatch - fix segfault when no newline at the end of a burst buffer file.\n -- Change scancel to only check job's base state when matching -t options.\n -- Save job dependency list in state files.\n -- cons_tres - allow jobs to be run on systems with root-less topologies.\n -- Restore pre-20.02pre1 PrologSlurmctld synchronization behavior to avoid\n    various race conditions, and ensure proper batch job launch.\n -- Add new slurmrestd command/daemon which implements the Slurm REST API.\n\n* Changes in Slurm 20.02.0pre1\n==============================\n -- Avoid possible race when 2 conf files are read at the same exact time.\n -- Add last and mean backfill table size to sdiag output.\n -- Add support for additional job submit environment variables:\n    SALLOC_MEM_PER_CPU, SALLOC_MEM_PER_NODE, SBATCH_MEM_PER_CPU and\n    SBATCH_MEM_PER_NODE.\n -- Add 'Agent thread count' stat to sdiag.\n -- Add sdiag -M, --clusters option.\n -- NodeName configurations with CPUs != Sockets*Cores or\n    Sockets*Cores*Threads will be rejected with fatal.\n -- Add scontrol write config <filename> option.\n -- Increase maximum number of hostlist ranges from 64k to 256k.\n -- Don't acquire unneeded locks in slurmctld _run_prolog thread.\n -- Fix sinfo/squeue sort by nodename/nodeaddr/hostname.\n -- Optimize getting wckey and associations usage.\n -- Keep SLURM_MPI_TYPE variable in srun when not set to 'none'.\n -- Remove slurm.spec-legacy packaging file.\n -- pam_slurm_adopt - with action_unknown=newest configured, pick a user job\n    even when failing to get cgroup mtime.\n -- Fix \"srun --export=\" parsing to handle nested commas.\n -- Add default \"reboot requested\" reason to nodes when rebooting with scontrol.\n -- Duplicate PartitionName entries in slurm.conf will now fatal() instead of\n    printing an error message and ignoring the successive records.\n -- Remove the smap command.\n -- Change exclusive behavior of a node to include all GRES on a node as well\n    as the cpus.\n -- Append \": reboot issued\" to node reason when reboot is issued from\n    controller. Previously only happened when nextstate was specified.\n -- Add default jobname of \"no-shell\" for salloc --no-shell.\n -- Save reservation state when automatically shrinking nodes.\n -- Add slurm.conf option MaxDBDMsgs to control how many messages will be\n    stored in the slurmctld before throwing them away when the slurmdbd is down.\n -- Change default SLURM_PMIX_TMPDIR to include user id to avoid potential\n    conflicts on development systems running multiple Slurm instances.\n -- Return a newly added ESLURM_DEFER error and set a job state reason to\n    FAIL_DEFER for immediate alloc requests if defer in SchedulerParameters.\n -- Make slurmctld fatal if unable to load a script or a job environment when\n    building the launch job message.\n -- Removed the checkpoint plugin interface and all associated API calls.\n -- Add job_get_grace_time() functions to preempt plugins and refactor\n    slurm_job_check_grace() to use them.\n -- Remove --disable-iso8601 configure option.\n -- Display StepId=<jobid>.batch instead of StepId=<jobid>.4294967294 in output\n    of \"scontrol show step\". (slurm_sprint_job_step_info())\n -- Make it so you can have a grace time when preempting by requeue.\n -- Translate MpiDefault=openmpi to functionally-equivalent MpiDefault=none,\n    and remove the mpi/openmpi plugin.\n -- burst_buffer/datawarp - add a set of % symbols that will be replaced by\n    job details. E.g., %d will be filled in with the WorkDir for the job.\n -- Fix sacctmgr show events to support node list ranges.\n -- Add SchedulerParameters option bf_one_resv_per_job to disallow adding more\n    than one backfill reservation per job.\n -- Allow sacctmgr to filter node events by states that are flags.\n -- Allow sacctmgr to filter node events by REBOOT state/flag.\n -- Add ability to set MailType and MailUser of job with scontrol.\n -- slurm_init_job_desc_msg() initializes mail_type as uint16_t. This allows\n    mail_type to be set to NONE with scontrol.\n -- Add new slurm_spank_log() function to print messages back to the user from\n    within a SPANK plugin. (This can be done with slurm_error() instead, but\n    that will always prepend \"error: \" to every message which may lead to\n    confusion.)\n -- Enforce specification of partition and ALL nodes with PART_NODES flag.\n -- Add 'promiscuous' flag to a reservation.\n -- Implement the idea of PURGE_COMP=timespec.\n -- SPANK - removed never-implemented slurm_spank_slurmd_init() interface. This\n    hook has always been accessible through slurm_spank_init() in the\n    S_CTX_SLURMD context instead.\n -- sbcast - add new BcastAddr option to NodeName lines to allow sbcast traffic\n    to flow over an alternate network path.\n -- Add auth/jwt plugin.\n -- Add new 'scontrol token' subcommand.\n -- PMIx - improve performance of proc map generation.\n -- For a heterogeneous job to be considered for preemption all components must\n    be eligible for preemption.\n -- Added JobCompParams to slurm.conf.\n -- Add configuration parameter DependencyParameters to slurm.conf.\n -- Deprecate kill_invalid_depend in SchedulerParameters and move it to new\n    DependencyParameters.\n -- Enable job dependencies for any job on any cluster in the same federation.\n -- Stricter escaping of strings sent to Elasticsearch.\n -- Allow clusters to be added automatically to db at startup of ctld.\n -- Add AccountingStorageExternalHost slurm.conf parameter.\n -- Add support for srun -M<cluster> --jobid=# for existing remote allocations.\n -- Remove LicensesUsed from 'scontrol show config'.\n -- sbatch - adjusted backoff times for \"--wait\" option to reduce load on\n    slurmctld. This results in a steady-state delay of 32s between queries,\n    instead of the prior 10s delay.\n -- Add SchedulerParameters option bf_running_job_reserve to add backfill\n    reservations for jobs running on whole nodes\n -- salloc/sbatch/srun - error on invalid --profile option strings.\n -- Remove max_job_bf option and replace with bf_max_job_test.\n -- Disable sbatch, salloc, srun --reboot for non-admins.\n -- jobcomp/elasticsearch - added connect_timeout and timeout options to\n    JobCompParams.\n -- SPANK - added support for S_JOB_GID in the job script context with\n    spank_get_item().\n -- Prolog/Epilog - add SLURM_JOB_GID environment variable.\n -- Add gpu/rsmi plugin to support AMD GPUs\n -- Make it so you can \"stack\" the energy plugins\n -- Add energy accounting plugin for AMD GPU\n\n* Changes in Slurm 19.05.9\n==========================\n\n* Changes in Slurm 19.05.8\n==========================\n -- sbatch - handle --uid/--gid in #SBATCH directives properly.\n -- Fix HDF5 type version build error.\n -- PMIx - fix potential buffer overflows from use of unpackmem().\n    CVE-2020-27745.\n -- X11 forwarding - fix potential leak of the magic cookie when sent as an\n    argument to the xauth command. CVE-2020-27746.\n\n* Changes in Slurm 19.05.7\n==========================\n -- Fix handling of -m/--distribution options for across socket/2nd level by\n    task/affinity plugin.\n -- Fix grp_node_bitmap error when slurmctld started before slurmdbd.\n -- Fix compilation issues in GCC10.\n -- Fix distributing job steps across idle nodes within a job.\n -- Break infinite loop in cons_tres dealing with incorrect tasks per tres\n    request resulting in slurmctld hang.\n -- priority/multifactor - gracefully handle NULL list of associations or array\n    of siblings when calculating FairTree fairshare.\n -- Fix cons_tres --exclusive=user to allocate only requested number of CPUs.\n -- Add MySQL deadlock detection and automatic retry mechanism.\n -- Fix _verify_node_state memory requested as --mem-per-gpu DefMemPerGPU.\n -- Factor in ntasks-per-core=1 with cons_tres.\n -- Fix formatting in error message in cons_tres.\n -- Fix gpu bind issue when CPUs=Cores and ThreadsPerCore > 1 on a node.\n -- Fix --mem-per-gpu for heterogeneous --gres requests.\n -- Fix slurmctld load order in load_all_part_state().\n -- Fix getting system counts for named GRES/TRES.\n -- MySQL - Fix for handing typed GRES for association rollups.\n -- Fix step allocations when tasks_per_core > 1.\n\n* Changes in Slurm 19.05.6\n==========================\n -- Fix OverMemoryKill.\n -- Fix memory leak in scontrol show config.\n -- Remove PART_NODES reservation flag after ignoring it at creation.\n -- Fix deprecation of MemLimitEnforce parameter.\n -- X11 forwarding - alter Xauthority regex to work when \"FamilyWild\" cookies\n    are present in the \"xauth list\" output.\n -- Fix memory leak when utilizing core reservations.\n -- Fix issue where adding WCKeys and then using them right away didn't always\n    work.\n -- Add cosmetic batch step to correct component in a hetjob.\n -- Fix to make scontrol write config create a usable config without editing.\n -- Fix memory leak when pinging backup controller.\n -- Fix issue with 'scontrol update' not enforcing all QoS / Association limits.\n -- Fix to properly schedule certain jobs with cons_tres plugin.\n -- Fix FIRST_CORES for reservations when using cons_tres.\n -- Fix sbcast -C argument parsing.\n -- Replace/deprecate max_job_bf with bf_max_job_test and print error message.\n -- sched/backfill - fix options parsing when bf_hetjob_prio enabled.\n -- Fix for --gpu-bind when no gpus requested.\n -- Fix sshare -l crash with large values.\n -- Fix printing NULL job and step pointers.\n -- Break infinite loop in cons_tres dealing with incorrect tasks per tres\n    request resulting in slurmctld hang.\n -- Improve handling of --gpus-per-task to make sure appropriate number of GPUs\n    is assigned to job.\n\n* Changes in Slurm 19.05.5\n==========================\n -- Fix both socket-[un]constrained GRES issues that would lead to incorrect\n    GRES allocations and GRES underflow errors at deallocation time.\n -- Reject unrunnable jobs submitted to reservations.\n -- Fix misleading error returned for immediate allocation requests when defer\n    in SchedulerParameters by decoupling defer from too fragmented logic.\n -- Fix printf format string error on FreeBSD.\n -- Fix parsing of delay_boot in controller when additional arguments follow it.\n -- Fix --ntasks-per-node in cons_tres.\n -- Fix array tasks getting same reject reason.\n -- Ignore DOWN/DRAIN partitions in reduce_completing_frag logic.\n -- Fix alloc_node validation when updating a job.\n -- Fix for requesting specific nodes when using cons_tres topology.\n -- Ensure x11 is setup before launching a job step.\n -- Fix incorrect SLURM_CLUSTER_NAME env var in batch step.\n -- Perl API - Fix undefined symbol for slurmdbd_pack_fini_msg.\n -- Install slurmdbd.conf.example with 0600 permissions to encourage secure\n    use. CVE-2019-19727.\n -- srun - do not continue with job launch if --uid fails. CVE-2019-19728.\n\n* Changes in Slurm 19.05.4\n==========================\n -- Don't allow empty string as a reservation name; generate a name if empty\n    string is provided.\n -- Fix salloc segfault when using --no-shell option.\n -- Fix divide by zero when normalizing partition priorities.\n -- Restore ability to set JobPriorityFactor to 0 on a partition.\n -- Fix multi-partition non-normalized job priorities.\n -- Adjust precedence between --mem-per-cpu and --mem-per-node to enforce\n    them as mutually exclusive. Specifying either on the command line will\n    now explicitly override any value inherited through the environment.\n -- Always print node's version, if it exists, in scontrol show nodes.\n -- sbatch - ensure SLURM_NTASKS_PER_NODE is exported when --ntasks-per-node\n    is set.\n -- slurmctld - fix memory leak when using DebugFlags=Reservation.\n -- Reset --mem and --mem-per-cpu options correctly when using --mem-per-gpu.\n -- Use correct function signature for step_set_env() in gres plugin interface.\n -- Restore pre-19.05 hostname handling behavior for AllocNodes by always\n    truncating to just the host portion and dropping any domain name portion\n    returned by gethostbyaddr().\n -- Fix abort initializing a configuration without acct_gather.conf.\n -- Fix GRES binding and CLOUD nodes GRES setup regressions.\n -- Make sview work with glib2 v2.62.\n -- Fix slurmctld abort when in developer mode and submitting to multiple\n    partitions with a bad QOS and not enforcing QOS.\n -- Enforce PART_NODES if only PartitionName is specified.\n -- Fix slurmd -G functionality.\n -- Fix build on 32-bit systems.\n -- Remove duplicate log entry on update job.\n -- sched/backfill - fix the estimated sched_nodes for multi-part jobs.\n -- slurm.spec - fix pmix_version global context macro.\n -- Fix cons_tres topology logic incorrectly evaluating insufficient resources.\n -- Fix job \"--switches=count@time\" option handling in cons_tres topology.\n -- scontrol - allow changes to the WorkDir for pending jobs.\n -- Enable coordinators to delete users if they only belong to accounts that\n    the coordinator is over.\n -- Fix regression on update from older versions with DefMemPerCPU.\n -- Fix issues with --gpu-bind while using cgroups.\n -- Suspend nodes after being down for SuspendTime.\n -- Fix rebooting nodes from skipping nextstate states on boot.\n -- Fix regression in reservation creation logic from 19.05.3 which would\n    incorrectly deny certain valid reservations from being created.\n -- slurmdbd - process sacct/sacctmgr job queries from older clients correctly.\n\n* Changes in Slurm 19.05.3-2\n============================\n -- Fix missing include for Cray Aries systems.\n\n* Changes in Slurm 19.05.3\n==========================\n -- Fix missing check from conversion of cray -> cray_aries.\n -- Improve job state reason string when required nodes are not available by\n    not including those that don't belong to the job partition.\n -- Set a more appropriate ESLURM_RESERVATION_MAINT job state reason for jobs\n    requesting feature(s) and required nodes are in a maintenance reservation.\n -- Fix logic to better handle maintenance reservations.\n -- Add spank options to cache in remote callback.\n -- Enforce the use of spank_option_getopt().\n -- Fix select plugins' will run test under-allocating nodes usage for\n    completing jobs.\n -- Nodes in COMPLETING state treated as being currently available for job\n    will-run test.\n -- Cray - fix contribs slurm.conf.j2 with updated cray_aries plugin names.\n -- job_submit/lua - fix problem where nil was expected for min_mem_per_cpu.\n -- Fix extra, unaccounted TRESRunMins usage created by heterogeneous jobs when\n    running with the priority/multifactor plugin.\n -- Detach threads once they are done to avoid having to join them\n    in track scripts code.\n -- Handle situation where a slurmctld tries to communicate with slurmdbd more\n    than once at the same time.\n -- Fix XOR/XAND features like cpu&fastio&[knl|westmere] to be resolved\n    correctly.\n -- Don't update [min|max]_exit_code on job array task requeue.\n -- Don't assume the first node of a job is the batch host when testing if the\n    job's allocated nodes are booted/ready.\n -- Make --batch=<feature> requests wait for all nodes to be booted so that it\n    can choose the batch host after the nodes have been booted -- possibly with\n    different features.\n -- Fix talking to batch host on it's protocol version when using --batch.\n -- gres/mic plugin - add missing fini() function to clean up plugin state.\n -- Move _validate_node_choice() before prolog/epilog check.\n -- Look forward one week while create new reservation.\n -- Set missing resv_desc.flags before call _select_nodes().\n -- Use correct start_time for TIME_FLOAT reservation in _job_overlap().\n -- Properly enforce a job's mem-per-cpu option when allocate the node\n    exclusively to that job.\n -- sched/backfill - clear estimated sched_nodes as done for start_time.\n -- Have safe_[read|write] handle EAGAIN and EINTR.\n -- Fix checking for flag with logical AND.\n -- Correct \"extern\" definition of variable if compiling with __APPLE__.\n -- Deprecate FastSchedule. FastSchedule will be removed in 20.02.\n    The FastSchedule=2 functionality (used for testing and development) has\n    been retained as the new SlurmdParameters=config_overrides option.\n -- Fix preemption issue when picking nodes for a feature job request.\n -- Fix race condition preventing held array job from getting a db_index.\n -- Fix select/cons_tres gres code infinite loop leaving slurmctld unresponsive.\n -- Remove redefinition of global variable in gres.c\n -- Fix issue where GPU devices are denied access when MPS is enabled.\n -- Fix uninitialized errors when compiling with CFLAGS=\"--coverage\".\n -- Fix scancel --full for proctrack/cgroups.\n -- Fix sdiag backfill last and mean queue length stats.\n -- Do not remove batch host when resizing/shrinking a batch job.\n -- nss_slurm - fix file descriptor leaks.\n -- Fix preemption for jobs using complex feature requests\n    (e.g. -C \"[rack1*2&rack2*4]\").\n -- Fix memory leaks in preemption when jobs request multiple features.\n -- Allow Operator users to show/fix runaways.\n -- Disallow coordinators to show/fix runaways.\n -- mpi/pmi2 - increase array len to avoid buffer size exceeded error.\n -- Preserve rebooting node's nextstate when updating state with scontrol.\n -- Fully merge slurm.conf and gres.conf before node_config_load().\n -- Remove FastSchedule dependence from gres.conf's AutoDetect=nvml.\n -- Forbid mix of typed and untyped GRES of same name in slurm.conf.\n -- cons_tres: Prevent creating a job without CPUs.\n -- Prevent underflow when filtering cores with gres.\n -- proctrack/cray_aries: use current pid instead of thread if we're in a fork.\n -- Fix missing check for prolog launch credential creation failure that can\n    lead to segfaults.\n\n* Changes in Slurm 19.05.2\n==========================\n -- Wrap END_TIMER{,2,3} macro definition in \"do {} while (0)\" block.\n -- Allow account coordinators to add users who don't already have an\n    association with any account.\n -- If only allowing particular alloc nodes in a partition, deny any request\n    coming from an alloc node of NULL.\n -- Prevent partial-load of plugins which can leave certain interfaces in\n    an inconsistent state.\n -- Remove stray __USE_GNU macro definitions from source.\n -- Fix loading fed state by backup on subsequent takeovers.\n -- Add missing job read lock when loading fed job state.\n -- Add missing fed_job_info jobs if fed state is lost.\n -- Do not build cgroup plugins on FreeBSD or NetBSD, and use proctrack/pgid\n    by default instead.\n -- Do not build switch/cray_aries plugin on FreeBSD, NetBSD, or macOS.\n -- Fix build on FreeBSD.\n -- Fix race condition in route/topology plugin.\n -- In munge decode set the alloc_node field to the text representation of an\n    IP address if the reverse lookup fails.\n -- Fix infinite loop in slurmstepd handling for nss_slurm REQUEST_GETGR RPC.\n -- Fix slurmstepd early assertion fail which prevented batch job launch or\n    tasks launch on non-Linux systems.\n -- Fix regression with SLURM_STEP_GPUS env var being renamed SLURM_STEP_GRES.\n -- Fix pmix v3 linking if no rpath is allowed on build.\n -- Fix sacctmgr error handling when removing associations and users.\n -- Allow sacctmgr to add users to WCKeys without having TrackWCKey set in the\n    slurm.conf.\n -- Allow sacctmgr to delete WCKeys from users.\n -- Change GRES type set by gpu/gpu_nvml plugin to be more specific - based\n    on device name instead of brand name.\n -- cli_filter - fix logic error with option lookup functions.\n -- Fix bad testing of NodeFeatures debug flag in contribs/cray.\n -- Cleanup track_script code to avoid race conditions and invalid memory\n    access.\n -- Fix jobs being killed after being requeued by preemption.\n -- Make register nodes verify correctly when using cons_tres.\n -- Fix srun --mem-per-cpu being ignored.\n -- Fix segfault in _update_job() under certain conditions.\n -- job_submit/lua - restore slurm.FAILURE as a synonym for slurm.ERROR.\n\n* Changes in Slurm 19.05.1-2\n============================\n -- Fix mistake in QOS time limit calculations for UsageFactor != 0 with any\n    combination of flags set.\n\n* Changes in Slurm 19.05.1\n==========================\n -- accounting_storage/mysql - fix incorrect function names in error messages.\n -- accounting_storage/slurmdbd - trigger an fsync() on the dbd.messages state\n    file to ensure it is committed to disk properly.\n -- Avoid JobHeldUser state reason from being updated at allocation time.\n -- Fix dump/load of rejected heterogeneous jobs.\n -- For heterogeneous jobs, do not count the each component against the QOS or\n    association job limit multiple times.\n -- Comment out documentation for the incomplete and currently unusable\n    burst_buffer/generic plugin.\n -- Add new error ESLURM_INVALID_TIME_MIN_LIMIT to make note when a time_min\n    limit is invalid based on timelimit.\n -- Correct slurmdb cluster record pack with NULL pointer input.\n -- Clearer error message for ESLURM_INVALID_TIME_MIN_LIMIT.\n -- Fix SchedulerParameter bf_min_prio_reserve error when not the last parameter\n -- When fixing runaway jobs, change to reroll from earliest submit time, and\n    never reroll from Unix epoch.\n -- Display submit time when running sacctmgr show runawayjobs and add format\n    option to display eligible time.\n -- jobcomp/elasticsearch - fix minor race related to JobCompLoc setup.\n -- For HetJobs, ensure SLURM_PACK_JOB_ID is set regardless of whether\n    PrologFlags=Alloc is enabled.\n -- Fix PriorityFlags regression with the mutation of FAIR_TREE to NO_FAIR_TREE.\n -- select/cons_res - fix debug flag SelectType handling in select_p_job_test.\n -- Fix sacctmgr archive dump commit confirmation.\n -- Prevent extra resources from being allocated when combining certain flags.\n -- Cray - fix template generator with update cray_aries plugin names.\n -- accounting_storage/slurmdbd - provide additional detail in several error\n    messages.\n -- Backfill - If a job has a time_limit guess the end time of a job better\n    if OverTimeLimit is Unlimited.\n -- Remove premature call to get system gpus before querying fake gpus that\n    should override the real.\n -- Fix segfault in epilog_set_env() when gres_devices is NULL.\n -- Fix (un)supported states in sacct.\n -- Adjust build system to no longer use the AC_FUNC_MALLOC autoconf macro.\n -- srun - restore the --cpu_bind option to srun.\n -- Add UsageFactorSafe QOS flag to control applying UsageFactor at\n    submission/scheduling time.\n -- Create missing reservations on DBD_MODIFY_RESV.\n -- Add error message when attempting to update association manager and object\n    doesn't exist.\n -- Fix security issue in accounting_storage/mysql plugin on archive file loads\n    by always escaping strings within the slurmdbd. CVE-2019-12838.\n\n* Changes in Slurm 19.05.0\n==========================\n -- Fix deprecated group by clause to use order by.\n -- NVML - Git rid of unneeded * when passing nvmlDevice_t to functions.\n -- NVML - Fix clang warning about unneeded variable initialization.\n -- NVML - remove unneeded {}.\n -- Add timers to new site_factor plugin APIs to warn of slow-running plugins,\n    which can lead to issues with throughput and responsiveness.\n -- X11 forwarding - ignore screen value for local DISPLAY.\n -- Add missing locks protecting slurmctld_config.server_thread_count access.\n -- Fix jobs stuck from FedJobLock when requeueing in a federation\n -- Fix requeueing job in a federation of clusters with differing associations\n -- sacctmgr - free memory before exiting in 'sacctmgr show runaway'.\n -- Fix seff showing memory overflow when steps tres mem usage is 0.\n -- Fix memory leaks in 'sacctmgr show runawayjobs'.\n -- Fix potential deadlock in nss_slurm.\n -- Fix memory leaks due to incomplete slurmdb_cluster_cond_t destructor.\n -- Alter reservation flags column in slurmdbd to use uint64_t instead of\n    uint16_t to ensure all current flags are saved correctly. Older releases\n    unfortunately could not store details for newer flags (using bits 17-32)\n    due to this field being silently truncated.\n -- Modify task layout with --overcommit option plus a heterogeneous job\n    allocation so that a cyclic task distribution can start happening before\n    all CPUs on all nodes are fully allocated. The number of tasks per node\n    will be unchanged from the previous algorithm, but tasks will be distributed\n    in a cyclic fashion first and then extra tasks placed on nodes with more\n    CPUs. Previously all CPUs would be fully allocated in a cyclic fashion,\n    then excess tasks distributed evenly across all allocated nodes.\n -- In select/cons_tres: Only allocate 1 CPU per node with the --overcommit\n    option.\n -- In select/cons_res: Only allocate 1 CPU per node with the --overcommit and\n    --nodelist options.\n -- Fix DefMemPer[CPU|Node] assignment on multi-partition job requests.\n -- Fix wrongly setting start_time to 0 for multi-part jobs.\n -- Upon archive file name collision, create new archive file instead of\n    overwriting the old one to prevent lost records.\n -- Limit archive files to 50000 records per file so that archiving large\n    databases will succeed.\n -- Remove stray newlines in SPANK plugin error messages.\n -- Fix archive loading events.\n -- In select/cons_res: Only allocate 1 CPU per node with the --overcommit and\n    --nodelist options.\n -- Fix main scheduler from potentially not running through whole queue.\n -- Fix variable initiation to avoid slurmctld abort.\n -- In partition preemption, sort preemptor jobs only if they overlap a\n    preemtable partition.\n -- cons_tres/dist_tasks - fix variable usage in cyclic distribution.\n -- cons_res/job_test - prevent a job from overallocating a node memory.\n -- cons_res/job_test - fix to consider a node's current allocated memory when\n    testing a job's memory request.\n -- Fix issue where multi-node job steps on cloud nodes wouldn't finish cleaning\n    up until the end of the job (rather than the end of the step).\n -- Fix packing pack_jobid in an sbcast.\n -- Fix GCC 9 compiler warnings.\n -- Add new job bit_flags of JOB_DEPENDENT.\n -- Make it so dependent jobs reset the AccrueTime and do not count against any\n    AccrueTime limits.\n -- Fix sacctmgr --parsable2 output for reservations and tres.\n -- In multi-node systems make sure GRES are found on node when not bound to\n    specific sockets.\n -- Fix gres-per-task logic for gres not bound to sockets.\n -- Fix issue when --gpus plus --cpus-per-gres was forcing socket binding\n    unnecessarily.\n -- Change event table's state column to handle 32bits.\n -- Prevent slurmctld from potential segfault after job_start_data() called\n    for completing job.\n -- Fix jobs getting on nodes with \"scontrol reboot asap\".\n -- Record node reboot events to database.\n -- Fix node reboot failure message getting to event table.\n -- Don't write \"(null)\" to event table when no event reason exists.\n -- Fix invalid memory read in cons_tres.\n -- Fix minor memory leak when clearing runaway jobs.\n -- Avoid flooding slurmctld and logging when prolog complete RPC errors occur.\n -- Fix slurmctld node_scheduler's feature_bitmap memory leak.\n -- Fatal when reading config if Alloc flag configured on FrontEnd mode.\n -- Modifications needed to run Federations with clusters running\n    different select/switch plugins.\n -- Fix Clang errors for zero initializing struct with nested arrays.\n -- Fix minor memory leak in pmi2.\n -- MySQL - Fix minor memory leak when querying suspended jobs fails.\n -- Fix seff human readable memory string for values below a megabyte.\n -- Avoid slurmctld abort if GRES defined in gres.conf, but not in the node\n    configuration of slurm.conf.\n -- Calculate task count for job with --gpus-per-task option, but no explicit\n    task count.\n\n* Changes in Slurm 19.05.0rc1\n=============================\n -- Set CUDA_VISIBLE_DEVICES environment variable in Prolog and Epilog for jobs\n    requesting gres/gpu.\n -- Remove '-U' argument - which was deprecated when '-A' was made the single\n    character option before the Slurm 2.1 release - as an alternative to\n    '--account' for salloc/sbatch/srun.\n -- Remove direct BLCR support and srun_cr.\n -- Make slurm_print_node_table only print a node's slurmd version if it is\n    different to the one reported by slurm_load_ctl_conf.\n -- Call gres plugin environment setup even if gres not requested in job.\n -- Do not set CUDA_VISIBLE_DEVICES=NoDevFiles when no gres requested.\n -- If GRES configuration data is unavailable from gres.conf, then use the\n    node's \"Gres=\" information slurm.conf. This will eliminate or minimize the\n    gres.conf file in many situations.\n -- Fix checking IPMI XCC raw command response length.\n -- jobacct_gather/common - improve lightweight process identification.\n -- Cloud/PowerSave Improvements:\n    - Better repsonsiveness to resuming and suspending.\n    - Powering down nodes not eligible to be allocated until after\n      SuspendTimeout.\n    - Powering down nodes put in \"Powering Down / %\" state until after\n      SuspendTimeout.\n -- Add idle_on_node_suspend SlurmctldParameter to make nodes idle regardless\n    of state when suspended.\n -- Add PowerSave DebugFlag for Suspend/Resume debugging.\n -- Changed \"scontrol reboot\" to not default to ALL nodes.\n -- Changed \"scontrol completing\" to include two new fields - EndTime and\n    CompletingTime.\n -- select/cons_tres - prevent job from overallocating a node memory.\n -- Refactor CLI option parsing for salloc/sbatch/srun into a central set of\n    functions in src/common/slurm_opt.c. Note that this new option parsing can\n    be stricter in a few specific situations - places that used to ignore\n    invalid options and still submit/launch a job or job step may return an\n    error() and refuse to proceed instead.\n -- Add preempt_send_user_signal SlurmctldParameter option to send user\n    signal (e.g. --signal=<SIG_NUM>) at preemption if it hasn't already been\n    sent.\n -- Add PreemptExemptTime parameter to slurm.conf and QOS to guarantee a\n    minimum runtime before preemption.\n -- Set job's preempt time for non-grace time preemptions.\n -- Add sinfo format option to show used gres.\n -- Add reboot_from_controller SlurmctldParameter to allow RebootProgram to be\n    run from the controller instead of the slurmds.\n -- Fix increasing of job size when extern steps exist.\n -- Reset GPU-related arguments to salloc/sbatch/srun for each separate\n    heterogeneous job component.\n -- Do not set \"(null)\" for SLURM_JOB_CONSTRAINTS when no constraints are set\n    in PrologSlurmctld/EpilogSlurmctld.\n -- Add SRUN_EXPORT_ENV as an input environment variable to srun.\n -- Return an error for invalid #SBATCH directives, and do not submit the job.\n -- Add S_JOB_ARRAY_ID and S_JOB_ARRAY_TASK_ID to spank_get_item().\n -- Change container_{g,p}_add_pid() to container_{g,p}_join() and remove the\n    'pid_t pid' argument.\n -- Add new site_factor plugin type to permit sites to build plugins to set\n    and modify the site priority factor value both initially on job submission,\n    and periodically every PriorityCalcPeriod.\n -- Rename Cray plugins cray_aries in preparation for Cray/Shasta.\n -- Allow Het Jobs to work on a Cray.\n -- Add new cli_filter plugin type to permit sites to build plugins to log,\n    modify, or reject CLI options within the salloc/sbatch/srun commands\n    themselves.\n -- Allocate nodes that are booting. Previously, nodes that were being booted\n    were off limits for allocation. This caused more nodes to be booted than\n    needed in a cloud environment.\n -- pam_slurm_adopt - inject SLURM_JOB_ID environment variable into adopted\n    processes.\n -- PMIx - use the Tree-based collective for empty fence operations.\n -- PMIx - replace use of the non-standard PMIX_VAL_SET macro with the\n    standardized PMIX_VALUE_LOAD macro.\n -- slurm.spec - change --without cray option to set configure option of\n    --enable-really-no-cray.\n -- slurm.spec - add new --with slurmsmwd option.\n -- pmi2: add mutex locking to all API calls to ensure thread-safety.\n -- Fix QOS usage factor to apply to TRES time limits and usage.\n -- Fix multi-cluster srun's with Select/Cray and other_cons_res.\n\n* Changes in Slurm 19.05.0pre3\n==============================\n -- Fix RPM packaging for accounting_storage/mysql.\n\n* Changes in Slurm 19.05.0pre2\n==============================\n -- Removed select/serial plugin.\n -- Remove 512-character line length limit in slurm_print_topo_record().\n    (Used by \"scontrol show topology\".)\n -- Removed crypto/openssl plugin.\n -- Tweak the sdiag gettimeofday() line format for greater clarity.\n -- Add support for SALLOC/SBATCH/SLURM_NO_KILL environment variables.\n    Add salloc/sbatch/srun support for optional \"--no-kill=off\" option to\n    disable the environment variables.\n -- Fix salloc and missing SLURM_NTASKS.\n -- Alter the backfill scheduler behavior to prevent it from scheduling lower\n    priority jobs on resources that become available during the backfill\n    scheduling cycle when bf_continue is enabled. This behavior was available\n    as the bf_ignore_newly_avail_nodes option in 18.08.4+, but is now enabled\n    by default. (The SchedulerParameters option of bf_ignore_newly_avail_nodes\n    is also now removed, although harmless if still set.)\n -- Make LaunchParameters=send_gids the default introducing the reverse option\n    \"disable_send_gids to go back to the original behavior.\n -- Limit pam_slurm_adopt to run only in the sshd context by default, for\n    security reasons. A new module option 'service=<name>' can be used to\n    allow a different PAM applications to work. The option 'service=*' can be\n    used to restore the old behavior of always performing the adopt logic\n    regardless of the PAM application context.\n -- pam_slurm_adopt: Use uid to determine whether root is logging.\n -- Remove sbatch --x11 option. Slurm's internal X11 forwarding is now only\n    supported from salloc, or an allocating srun command.\n -- Suppressed printing of job id in sbatch when quiet flag is set.\n -- Changed sreport 'SizesByAccount' and 'SizesByAccountAndWckey' default\n    behavior and added new 'AcctAsParent' option.\n -- Add ave watts to api and sview.\n -- Added printf attribute to setenvf() and corrected related warnings.\n -- Kill running/pending job is allocated GRES and that GRES has a \"File\"\n    configuration, and the GRES count changes.\n -- Add new DebugFlag=Accrue for accrue accounting debugging purposes.\n -- Change CryptoType option to CredType, and rename crypto/munge plugin to\n    cred/munge.\n -- Add slurmd -G option to print GRES configuration and exit. This is useful\n    for testing and debugging.\n -- Support GRES types that include numbers (e.g. \"--gres=gpu:123g:2\").\n -- Remove MemLimitEnforce parameter and move functionality into\n    JobAcctGatherParam=OverMemoryKill.\n -- sview - disable admin mode option (which would not work anyways) if the\n    user is not an admin in SlurmDBD.\n -- Remove joules reporting from sview and scontrol.\n -- Change the default fair share algorithm to \"fair tree\". The new\n    PriorityFlags option of NO_FAIR_TREE can be used to revert to \"classic\"\n    fair share scheduling instead.\n -- libslurmdb has been merged into libslurm.\n -- Added -b as a short option for --begin and removed the -b option which\n    was a left over artifact from the Moab compatibility work.\n -- Add ArrayTaskThrottle to \"scontrol show job\" output.\n -- Added SPRIO_FORMAT env variable to the sprio command.\n -- Add batch step at the beginning of a batch job so that squeue, sstat, and\n    sacct will show the batch step.\n -- Deprecated 32-bit builds.\n -- Make -l and -o mutually exclusive in saccct, squeue, sinfo, and sprio\n -- Disable running job expansion by default. A new SchedulerParameter of\n    permit_job_expansion has been added for sites that wish to re-enable it.\n -- Permit changing a job array's ArrayTaskThrottle value even if the job is\n    terminated (for job requeue).\n -- Add scontrol requeue option of \"Incomplete\" which will requeue jobs only if\n    they failed to complete with an exit code of zero.\n -- Modify GrpNodes limit to apply to unique nodes allocated (avoid double\n    counting nodes allocated to multiple jobs in the same QOS or association).\n -- If a job submit does NOT include --cpus-per-task option, then report the\n    value as \"N/A\" rather than always mapping the value to 1.\n -- X11 forwarding - use the raw value from gethostname() with xauth to avoid\n    authentication issues when Slurm has internally stripped off the domain\n    portion.\n -- Change how slurmd fills in the registration message version string from\n    PACKAGE_VERSION to SLURM_VERSION_STRING, affecting how the version is\n    displayed with sview, sinfo, scontrol and through the API.\n -- Remove autogen.sh script. Please use the autoreconf command instead.\n -- Disable a configuration of SelectTypeParameters=CR_ONE_TASK_PER_CORE with\n    SelectType=select/cons_tres. This will be addressed later.\n -- job_submit/lua - expose more fields off the partition record.\n -- task/cgroup - prevent setting a memory.soft_limit_in_bytes higher than the\n    memory.limit_in_bytes since the hard limit will take precedence anyway.\n -- If a GrpNodes limit is configured in an association, partition QOS or\n    job QOS then favor use of nodes already allocated to that entity. This\n    will result in the configured node \"Weight\" being incremented by one for\n    nodes which are not preferred. Consider adjusting configured node \"Weight\"\n    values to achieve the desired node preferences.\n -- Add full node state debug2 output to slurmdbd node up/down update\n -- Set CUDA_VISIBLE_DEVICES and CUDA_MPS_ACTIVE_THREAD_PERCENTAGE environment\n    variables in Prolog and Epilog for jobs requesting gres/mps.\n -- Added thresholds for backfill parameters.\n -- Fix for backfill sleep overflow when large values are set.\n -- Execute Epilog on nodes reliquished from job (i.e. job resized).\n -- Rename burst_buffer/cray plugin to burst_buffer/datawarp.\n -- X11 Forwarding - reimplement using new internal network forwarding RPCs.\n -- Remove slurm_jobcomp_get_errno and slurm_jobcomp_strerror from jobcomp\n    plugin API.\n -- Optimize backfill for checking max jobs per assoc, partition, user, etc.\n\n* Changes in Slurm 19.05.0pre1\n==============================\n -- Run epilog and clean up allocation when a job is resized to zero and its\n    resources transferred to another job (--depend=expand).\n -- If GRES are associated with specific sockets, identify those sockets in the\n    output of \"scontrol show node\". For example if all 4 GPUs on a node are\n    all associated with socket zero, then \"Gres=gpu:4(S:0)\". If associated\n    with sockets 0 and 1 then \"Gres=gpu:4(S:0-1)\". The information of which\n    specific GPUs are associated with specific GPUs is not reported, but only\n    available by parsing the gres.conf file.\n -- Add configuration parameter \"GpuFreqDef\" to control a job's default GPU\n    frequency.\n -- Add job flags to the database.  Currently used to determine which scheduler\n    scheduled the job.\n -- Add constraints/features to the database.\n -- Add last reason job didn't run before resources/priority to the database.\n -- Make it so we set the alloc_node in a resource allocation based on the auth\n    plugin instead of the rpc call.\n\n* Changes in Slurm 18.08.10\n===========================\n\n* Changes in Slurm 18.08.9\n==========================\n -- Wrap END_TIMER{,2,3} macro definition in \"do {} while (0)\" block.\n -- Make sview work with glib2 v2.62.\n -- Make Slurm compile on linux after sys/sysctl.h was deprecated.\n -- Install slurmdbd.conf.example with 0600 permissions to encourage secure\n    use. CVE-2019-19727.\n -- srun - do not continue with job launch if --uid fails. CVE-2019-19728.\n\n* Changes in Slurm 18.08.8\n==========================\n -- Update \"xauth list\" to use the same 10000ms timeout as the other xauth\n    commands.\n -- Fix issue in gres code to handle a gres cnt of 0.\n -- Don't purge jobs if backfill is running.\n -- Verify job is pending add/removing accrual time.\n -- Don't abort when the job doesn't have an association that was removed\n    before the job was able to make it to the database.\n -- Set state_reason if select_nodes() fails job for QOS or Account.\n -- Avoid seg_fault on referencing association without a valid_qos bitmap.\n -- If Association/QOS is removed on a pending job set that job as ineligible.\n -- When changing a jobs account/qos always make sure you remove the old limits.\n -- Don't reset a FAIL_QOS or FAIL_ACCOUNT job reason until the qos or\n    account changed.\n -- Restore \"sreport -T ALL\" functionality.\n -- Correctly typecast signals being sent through the api.\n -- Properly initialize structures throughout Slurm.\n -- Sync \"numtask\" squeue format option for jobs and steps to \"numtasks\".\n -- Fix sacct -PD to avoid CA before start jobs.\n -- Fix potential deadlock with backup slurmctld.\n -- Fixed issue with jobs not appearing in sacct after dependency satisfied.\n -- Fix showing non-eligible jobs when asking with -j and not -s.\n -- Fix issue with backfill scheduler scheduling tasks of an array\n    when not the head job.\n -- accounting_storage/mysql - fix SIGABRT in the archive load logic.\n -- accounting_storage/mysql - fix memory leak in the archive load logic.\n -- Limit records per single SQL statement when loading archived data.\n -- Fix unnecessary reloading of job submit plugins.\n -- Allow job submit plugins to be turned on/off with a reconfigure.\n -- Fix segfault when loading/unloading Lua job submit plugin multiple times.\n -- Fix printing duplicate error messages of jobs rejected by job submit plugin.\n -- Fix printing of job submit plugin messages of het jobs without pack id.\n -- Fix memory leak in group_cache.c\n -- Fix jobs stuck from FedJobLock when requeueing in a federation\n -- Fix requeueing job in a federation of clusters with differing associations\n -- sacctmgr - free memory before exiting in 'sacctmgr show runaway'.\n -- Fix seff showing memory overflow when steps tres mem usage is 0.\n -- Upon archive file name collision, create new archive file instead of\n    overwriting the old one to prevent lost records.\n -- Limit archive files to 50000 records per file so that archiving large\n    databases will succeed.\n -- Remove stray newlines in SPANK plugin error messages.\n -- Fix archive loading events.\n -- In select/cons_res: Only allocate 1 CPU per node with the --overcommit and\n    --nodelist options.\n -- Fix main scheduler from potentially not running through whole queue.\n -- cons_res/job_test - prevent a job from overallocating a node memory.\n -- cons_res/job_test - fix to consider a node's current allocated memory when\n    testing a job's memory request.\n -- Fix issue where multi-node job steps on cloud nodes wouldn't finish cleaning\n    up until the end of the job (rather than the end of the step).\n -- Fix issue with a 17.11 sbcast call to a 18.08 daemon.\n -- Add new job bit_flags of JOB_DEPENDENT.\n -- Make it so dependent jobs reset the AccrueTime and do not count against any\n    AccrueTime limits.\n -- Fix sacctmgr --parsable2 output for reservations and tres.\n -- Prevent slurmctld from potential segfault after job_start_data() called\n    for completing job.\n -- Fix jobs getting on nodes with \"scontrol reboot asap\".\n -- Record node reboot events to database.\n -- Fix node reboot failure message getting to event table.\n -- Don't write \"(null)\" to event table when no event reason exists.\n -- Fix minor memory leak when clearing runaway jobs.\n -- Avoid flooding slurmctld and logging when prolog complete RPC errors occur.\n -- Fix GCC 9 compiler warnings.\n -- Fix seff human readable memory string for values below a megabyte.\n -- Fix dump/load of rejected heterogeneous jobs.\n -- For heterogeneous jobs, do not count the each component against the QOS or\n    association job limit multiple times.\n -- slurmdbd - avoid reservation flag column corruption with the use of newer\n    flags, instead preserve the older flag fields that we can still fit in the\n    smallint field, and discard the rest.\n -- Fix security issue in accounting_storage/mysql plugin on archive file loads\n    by always escaping strings within the slurmdbd. CVE-2019-12838.\n\n* Changes in Slurm 18.08.7\n==========================\n -- Set debug statement to debug2 to avoid benign error messages.\n -- Add SchedulerParameters option of bf_hetjob_immediate to attempt to start\n    a heterogeneous job as soon as all of its components are determined able to\n    do so.\n -- Fix underflow causing decay thread to exit.\n -- Fix main scheduler not considering hetjobs when building the job queue.\n -- Fix regression for sacct to display old jobs without a start time.\n -- Fix setting correct number of gres topology bits.\n -- Update hetjobs pending state reason when appropriate.\n -- Fix accounting_storage/filetxt's understanding of TRES.\n -- Set Accrue time when not enforcing limits.\n -- Fix srun segfault when requesting a hetjob with test_exec or bcast options.\n -- Hide multipart priorities log message behind Priority debug flag.\n -- sched/backfill - Make hetjobs sensitive to bf_max_job_start.\n -- Fix slurmctld segfault due to job's partition pointer NULL dereference.\n -- Fix issue with OR'ed job dependencies.\n -- Add new job's bit_flags of INVALID_DEPEND to prevent rebuilding a job's\n    dependency string when it has at least one invalid and purged dependency.\n -- Promote federation unsynced siblings log message from debug to info.\n -- burst_buffer/cray - fix slurmctld SIGABRT due to illegal read/writes.\n -- burst_buffer/cray - fix memory leak due to unfreed job script content.\n -- node_features/knl_cray - fix script_argv use-after-free.\n -- burst_buffer/cray - fix script_argv use-after-free.\n -- Fix invalid reads of size 1 due to non null-terminated string reads.\n -- Add extra debug2 logs to identify why BadConstraints reason is set.\n\n* Changes in Slurm 18.08.6-2\n============================\n -- Remove deadlock situation when logging and --enable-debug is used.\n -- Fix RPM packaging for accounting_storage/mysql.\n\n* Changes in Slurm 18.08.6\n==========================\n -- Added parsing of -H flag with scancel.\n -- Fix slurmsmwd build on 32-bit systems.\n -- acct_gather_filesystem/lustre - add support for Lustre 2.12 client.\n -- Fix per-partition TRES factors/priority\n -- Fix per-partition NICE priority\n -- Fix partition access check validation for multi-partition job submissions.\n -- Prevent segfault on empty response in 'scontrol show dwstat'.\n -- node_features/knl_cray plugin - Preserve node's active features if it has\n    already booted when slurmctld daemon is reconfigured.\n -- Detect missing burst buffer script and reject job.\n -- GRES: Properly reset the topo_gres_cnt_alloc counter on slurmctld restart\n    to prevent underflow.\n -- Avoid errors from packing accounting_storage_mysql.so when RPM is built\n    with out mysql support.\n -- Remove deprecated -t option from slurmctld --help.\n -- acct_gather_filesystem/lustre - fix stats gathering.\n -- Enforce documented default usage start and end times when querying jobs from\n    the database.\n -- Fix issues when querying running jobs from the database.\n -- Deny sacct request where start time is later than the end time requested.\n -- Fix sacct verbose about time and states queried.\n -- burst_buffer/cray - allow 'scancel --hurry <jobid>' to tear down a burst\n    buffer that is currently staging data out.\n -- X11 forwarding - allow setup if the DISPLAY environment variable lacks\n    a screen number. (Permit both \"localhost:10.0\" and \"localhost:10\".)\n -- docs - change HTML title to include the page title or man page name.\n -- X11 forwarding - fix an unnecessary error message when using the\n    local_xauthority X11Parameters option.\n -- Add use_raw_hostname to X11Parameters.\n -- Fix smail so it passes job arrays to seff correctly.\n -- Don't check InactiveLimit for salloc --no-shell jobs.\n -- Add SALLOC_GRES and SBATCH_GRES as input to salloc/sbatch.\n -- Remove drain state when node doesn't reboot by ResumeTimeout.\n -- Fix considering \"resuming\" nodes in scheduling.\n -- Do not kill suspended jobs due to exceeding time limit.\n -- Add NoAddrCache CommunicationParameter.\n -- Don't ping powering up cloud nodes.\n -- Add cloud_dns SlurmctldParameter.\n -- Consider --sbindir configure option as the default path to find slurmstepd.\n -- Fix node state printing of DRAINED$\n -- Fix spamming dbd of down/drained nodes in maintenance reservation.\n -- Avoid buffer overflow in time_str2secs.\n -- Calculate suspended time for suspended steps.\n -- Add null check for step_ptr->step_node_bitmap in _pick_step_nodes.\n -- Fix multi-cluster srun issue after 'scontrol reconfigure' was called.\n -- Fix accessing response_cluster_rec outside of write locks.\n -- Fix Lua user messages not showing up on rejected submissions.\n -- Fix printing multi-line error messages on rejected submissions.\n\n* Changes in Slurm 18.08.5-2\n============================\n -- Fix Perl build for 32-bit systems.\n\n* Changes in Slurm 18.08.5\n==========================\n -- Backfill - If a job has a time_limit guess the end time of a job better\n    if OverTimeLimit is Unlimited.\n -- Fix \"sacctmgr show events event=cluster\"\n -- Fix sacctmgr show runawayjobs from sibling cluster\n -- Avoid bit offset of -1 in call to bit_nclear().\n -- Insure that \"hbm\" is a configured GresType on knl systems.\n -- Fix NodeFeaturesPlugins=node_features/knl_generic to allow other gres\n    other than knl.\n -- cons_res: Prevent overflow on multiply.\n -- Better debug for bad values in gres.conf.\n -- Fix double accounting of energy at end of job.\n -- Read gres.conf for cloud nodes on slurmctld.\n -- Don't assume the first node of a job is the batch host when purging jobs\n    from a node.\n -- Better debugging when a job doesn't have a job_resrcs ptr.\n -- Store ave watts in energy plugins.\n -- Add XCC plugin for reading Lenovo Power.\n -- Fix minor memory leak when scheduling rebootable nodes.\n -- Fix debug2 prefix for sched log.\n -- Fix printing correct SLURM_JOB_ACCOUNT_PACK_GROUP_* in env for a Het Job.\n -- sbatch - search current working directory first for job script.\n -- Make it so held jobs reset the AccrueTime and do not count against any\n    AccrueTime limits.\n -- Add SchedulerParameters option of bf_hetjob_prio=[min|avg|max] to alter the\n    job sorting algorithm for scheduling heterogeneous jobs.\n -- Fix initialization of assoc_mgr_locks and slurmctld_locks lock structures.\n -- Fix segfault with job arrays using X11 forwarding.\n -- Revert regression caused by e0ee1c7054 which caused negative values and\n    values starting with a decimal to be invalid for PriorityWeightTRES and\n    TRESBillingWeight.\n -- Fix possibility to update a job's reservation to none.\n -- Suppress connection errors to primary slurmdbd when backup dbd is active.\n -- Suppress connection errors to primary db when backup db kicks in\n -- Add missing fields for sacct --completion when using jobcomp/filetxt.\n -- Fix incorrect values set for UserCPU, SystemCPU, and TotalCPU sacct fields\n    when JobAcctGatherType=jobacct_gather/cgroup.\n -- Fixed srun from double printing invalid option msg twice.\n -- Remove unused -b flag from getopt call in sbatch.\n -- Disable reporting of node TRES in sreport.\n -- Re-enabling features combined by OR within parenthesis for non-knl setups.\n -- Prevent sending duplicate requests to reboot a node before ResumeTimeout.\n -- Down nodes that don't reboot by ResumeTimeout.\n -- Update seff to reflect API change from rss_max to tres_usage_in_max.\n -- Add missing TRES constants from perl API.\n -- Fix issue where sacct would return incorrect array tasks when querying\n    specific tasks.\n -- Add missing variables to slurmdb_stats_t in the perlapi.\n -- Fix nodes not getting reboot RPC when job requires reboot of nodes.\n -- Fix failing update the partition list of a job.\n -- Use slurm.conf gres ids instead of gres.conf names to get a gres type name.\n -- Add mitigation for a potential heap overflow on 32-bit systems in xmalloc.\n    CVE-2019-6438.\n\n* Changes in Slurm 18.08.4\n==========================\n -- burst_buffer/cray - avoid launching a job that would be immediately\n    cancelled due to a DataWarp failure.\n -- Fix message sent to user to display preempted instead of time limit when\n    a job is preempted.\n -- Fix memory leak when a failure happens processing a nodes gres config.\n -- Improve error message when failures happen processing a nodes gres config.\n -- When building rpms ignore redundant standard rpaths and insecure relative\n    rpaths, for RHEL based distros which use \"check-rpaths\" tool.\n -- Don't skip jobs in scontrol hold.\n -- Avoid locking the job_list when unneeded.\n -- Allow --cpu-bind=verbose to be used with SLURM_HINT environment variable.\n -- Make it so fixing runaway jobs will not alter the same job requeued\n    when not runaway.\n -- Avoid checking state when searching for runaway jobs.\n -- Remove redundant check for end time of job when searching for runaway jobs.\n -- Make sure that we properly check for runawayjobs where another job might\n    have the same id (for example, if a job was requeued) by also checking the\n    submit time.\n -- Add scontrol update job ResetAccrueTime to clear a job's time\n    previously accrued for priority.\n -- cons_res: Delay exiting cr_job_test until after cores/cpus are calculated\n    and distributed.\n -- Fix bug where binary in cwd would trump binary in PATH with test_exec.\n -- Fix check to test printf(\"%s\\n\", NULL); to not require\n    -Wno-format-truncation CFLAG.\n -- Fix JobAcctGatherParams=UsePss to report the correct usage.\n -- Fix minor memory leak in pmix plugin.\n -- Fix minor memory leak in slurmctld when reading configuration.\n -- Handle return codes correctly from pthread_* functions.\n -- Fix minor memory leak when a slurmd is unable to contact a slurmctld\n    when trying to register.\n -- Fix sreport sizesbyaccount report when using Flatview and accounts.\n -- Fix incorrect shift when dealing with node weights and scheduling.\n -- libslurm/perl - Fix segfault caused by incorrect hv_to_slurm_ctl_conf.\n -- Add qos and assoc options to confirmation dialogs.\n -- Handle updating identical license or partition information correctly.\n -- Makes sure accounts and QOS' are all lower case to match documentation\n    when read in from the slurm.conf file.\n -- Don't consider partitions without enough nodes in reservation,\n    main scheduler.\n -- Set SLURM_NTASKS correctly if having to determine from other options.\n -- Removed GCP scripts from contribs. Now located at:\n    https://github.com/SchedMD/slurm-gcp.\n -- Don't check existence of srun --prolog or --epilog executables when set to\n    \"none\" and SLURM_TEST_EXEC is used.\n -- Add \"P\" suffix support to job and step tres specifications.\n -- When doing a reconfigure handle QOS' GrpJobsAccrue correctly.\n -- Remove unneeded extra parentheses from sh5util.\n -- Fix jobacct_gather/cgroup to work correctly when more than one task is\n    started on a node.\n -- If requesting --ntasks-per-node with no tasks set tasks correctly.\n -- Accept modifiers for TRES originally added in 6f0342e0358.\n -- Don't remove reservation on slurmctld restart if nodes are removed from\n    configuration.\n -- Fix bad xfree in task/cgroup.\n -- Fix removing counters if a job array isn't subject to limits and is\n    canceled while pending.\n -- Make sure SLURM_NTASKS_PER_NODE is set correctly when env is overwritten\n    by the command line.\n -- Clean up step on a failed node correctly.\n -- mpi/pmix: Fixed the logging of collective state.\n -- mpi/pmix: Make multi-slurmd work correctly when using ring communication.\n -- mpi/pmix: Fix double invocation of the PMIx lib fence callback.\n -- mpi/pmix: Remove unneeded libpmix callback drop in tree-based coll.\n -- Fix race condition in route/topology when the slurmctld is reconfigured.\n -- In route/topology validate the slurmctld doesn't try to initialize the\n    node system.\n -- Fix issue when requesting invalid gres.\n -- Validate job_ptr in backfill before restoring preempt state.\n -- Fix issue when job's environment is minimal and only contains variables\n    Slurm is going to replace internally.\n -- When handling runaway jobs remove all usage before rollup to remove any\n    time that wasn't existent instead of just updating lines that have time\n    with a lesser time.\n -- salloc - set SLURM_NTASKS_PER_CORE and SLURM_NTASKS_PER_SOCKET in the\n    environment if the corresponding command line options are used.\n -- slurmd - fix handling of the -f flag to specify alternate config file\n    locations.\n -- Fix scheduling logic to avoid using nodes that require a reboot for KNL\n    node change when possible.\n -- Fix scheduling logic bug. There should have been a test for _not_\n    NODE_SET_REBOOT to continue.\n -- Fix a scheuling logic bug with respect to XOR operation support when there\n    are down nodes.\n -- If there is a constraint construct of the form \"[...&...]\"\n    then an error is generated if more than one of those specifications\n    contains KNL NUMA or MCDRAM modes.\n -- Fix stepd segfault race if slurmctld hasn't registered with the launching\n    slurmd yet delivering it's TRES list.\n -- Add SchedulerParameters option of bf_ignore_newly_avail_nodes to avoid\n    scheduling lower priority jobs on resources that become available during\n    the backfill scheduling cycle when bf_continue is enabled.\n -- Decrement message_connections in stepd code on error path correctly.\n -- Decrease an error message to be debug.\n -- Fix missing suffixes in squeue.\n -- pam_slurm_adopt - send an error message to the user if no Slurm jobs\n    can be located on the node.\n -- Run SlurmctldPrimaryOffProg when the primary slurmctld process shuts down.\n -- job_submit/lua: Add several slurmctld return codes.\n -- job_submit/lua: Add user/group info to jobs.\n -- Fix formatting issues when printing uint64_t.\n -- Bump RLIMIT_NOFILE for daemons in systemd services.\n -- Expand %x in job name in 'scontrol show job'.\n -- salloc/sbatch/srun - print warning if mutually exclusive options of --mem\n    and --mem-per-cpu are both set.\n\n* Changes in Slurm 18.08.3\n==========================\n -- Fix regression in 18.08.1 that caused dbd messages to not be queued up\n    when the dbd was down.\n -- Fix regression in 18.08.1 that can cause a slurmctld crash when splitting\n    job array elements.\n\n* Changes in Slurm 18.08.2\n==========================\n -- Correctly initialize variable in env_array_user_default().\n -- Remove race condition when signaling starting step.\n -- Fix issue where 17.11 job's using GRES in didn't initialize new 18.08\n    structures after unpack.\n -- Stop removing nodes once the minimum CPU or node count for the job is\n    reached in the cons_res plugin.\n -- Process any changes to MinJobAge and SlurmdTimeout in the slurmctld when\n    it is reconfigured to determine changes in its background timers.\n -- Use previous SlurmdTimeout in the slurmctld after a reconfigure to\n    determine the time a node has been down.\n -- Fix multi-cluster srun between clusters with different SelectType plugins.\n -- Fix removing job licenses on reconfig/restart when configured license\n    counts are 0.\n -- If a job requested multiple licenses and one license was removed then on\n    a reconfigure/restart all of the licenses -- including the valid ones\n    would be removed.\n -- Fix issue where job's license string wasn't updated after a restart when\n    licenses were removed or added.\n -- Add allow_zero_lic to SchedulerParameters.\n -- Avoid scheduling tasks in excess of ArrayTaskThrottle when canceling tasks\n    of an array.\n -- Fix jobs that request memory per node and task count that can't be\n    scheduled right away.\n -- Avoid infinite loop with jobacct_gather/linux when pids wrap around\n    /proc/sys/kernel/pid_max.\n -- Fix --parsable2 output for sacct and sstat commands to remove a stray\n    trailing delimiter.\n -- When modifying a user's name in sacctmgr enforce PreserveCaseUser.\n -- When adding a coordinator or user that was once deleted enforce\n    PreserveCaseUser.\n -- Correctly handle scenarios where a partitions MaxMemPerCPU is less than\n    a jobs --mem-per-cpu and also -c is greater than 1.\n -- Set AccrueTime correctly when MaxJobsAccrue is disabled and BeginTime has\n    not been established.\n -- Correctly account for job arrays for new {Max/Grp}JobsAccrue limits.\n\n* Changes in Slurm 18.08.1\n==========================\n -- Remove commented-out parts of man pages related to cons_tres work in 19.05,\n    as these were showing up on the web version due to a syntax error.\n -- Prevent slurmctld performance issues in main background loop if multiple\n    backup controllers are unavailable.\n -- Add missing user read association lock in burst_buffer/cray during init().\n -- Fix incorrect spacing for PartitionName lines in 'scontrol write config'.\n -- Fix creation of step hwloc xml file for after cpuset cgroup has been\n    created.\n -- Add userspace as a valid default governor.\n -- Add timers to group_cache_lookup so if going slow advise\n    LaunchParameters=send_gids.\n -- Fix SLURM_STEP_GRES=none to work correctly.\n -- Fix potential memory leak when a failure happens unpacking a ctld_multi_msg.\n -- Fix potential double free when a failure happens when unpacking a\n    node_registration_status_msg.\n -- Fix sacctmgr show runaways.\n -- Removed non-POSIX append operator from configure script for non-bash\n    support.\n -- Fix incorrect spacing for PartitionName lines in 'scontrol write config'.\n -- Fix sacct to not print huge reserve times when the job was never eligible.\n -- burst_buffer/cray - Add missing locks around assoc_mgr when timing out a\n    burst buffer.\n -- burst_buffer/cray - Update burst buffers when an association or qos\n    is removed from the system.\n -- Remove documentation for deprecated Cray/ALPS systems. Please switch to\n    Native Cray mode instead.\n -- Completely copy features when copying the list in the slurmctld.\n -- PMIX - Fix issue with packing processes when using an arbitrary task\n    distribution.\n -- Fix hostlists to be able to handle nodenames with '-' in them surrounded\n    by integers.\n -- Added sort option to sprio output.\n -- Fix correct job CPU count allocated.\n -- Fix sacctmgr setting GrpJobs limit when setting GrpJobsAccrue limit.\n -- Change the defaults to MemLimitEnforce=no and NoOverMemoryKill\n    (See RELEASE_NOTES).\n -- Prevent abort when using Cray node features plugin on non-knl.\n -- Add ability to reboot down nodes with scontrol reboot_nodes.\n -- Protect against sending to the slurmdbd if the connection has gone away.\n -- Fix invalid read when not using backup slurmctlds.\n -- Prevent acct coordinators from changing default acct on add user.\n -- Don't allow scontrol top do modify job priorities when priority == 1.\n -- slurmsmwd - change parsing code to handle systems with the svid or inst\n    fields set in xtconsumer output.\n -- Fix infinite loop in slurmctld if GRES is specified without a count.\n -- sacct: Print error when unknown arguments are found.\n -- Fix checking missing return codes when unpacking structures.\n -- Fix slurm.spec-legacy including slurmsmwd\n -- More explicit error message when cgroup oom-kill events detected.\n -- When updating an association and are unable to find parent association\n    initialize old fairshare association pointer correctly.\n -- Wrap slurm_cond_signal() calls with mutexes where needed.\n -- Fix correct timeout with resends in slurm_send_only_node_msg.\n -- Fix pam_slurm_adopt to honor action_adopt_failure.\n -- Have the slurmd recreate the hwloc xml file for the full system on restart.\n -- sdiag - correct the units for the gettimeofday() stat to microseconds.\n -- Set SLURM_CLUSTER_NAME environment variable in MailProg to the ClusterName.\n -- smail - use SLURM_CLUSTER_NAME environment variable.\n -- job_submit/lua - expose argc/argv options through lua interface.\n -- slurmdbd - prevent false-positive warning about innodb settings having\n    been set too low if they're actually set over 2GB.\n\n* Changes in Slurm 18.08.0\n==========================\n -- Fix segfault on job arrays when starting controller without dbd up.\n -- Fix pmi2 to build with gcc 8.0+.\n -- Remove the development snapshot of select/cons_tres plugin.\n -- Fix slurmd -C to not print benign error from xcpuinfo.\n -- Fix potential double locks in the assoc_mgr.\n -- Fix sacct truncate flag behavior Truncated pending jobs will always\n    return a start and end time set to the window end time, so elapsed\n    time is 0.\n -- Fix extern step hanging forever when canceled right after creation.\n -- sdiag - add slurmctld agent count.\n -- Remove requirement to have cgroup_allowed_devices_file.conf in order to\n    constrain devices. By default all devices are allowed and GRES, that are\n    associated with a device file, that are not requested are restricted.\n -- Fix proper alignment of clauses when determining if more nodes are needed\n    for an allocation.\n -- Fix race condition when canceling a federation job that just started\n    running.\n -- Prevent extra resources from being allocated when combining certain flags.\n -- Fix problem in task/affinity plugin that can lead to slurmd fatal()'ing\n    when using --hint=nomultithread.\n -- Fix left over socket file when step is ending and using pmi2 with\n    %n or %h in the spool dir.\n -- Don't remove hwloc full system xml file when shutting down the slurmd.\n -- Fix segfault that could happen with a het job when it was canceled while\n    starting.\n -- Fix scan-build false-positive warning about invalid memory access in the\n    _ping_controller() function.\n -- Add control_inx value to trigger_info_msg_t to permit future work in the\n    trigger management code to distinguish which of multiple backup controllers\n    has changed state.\n\n* Changes in Slurm 18.08.0rc1\n==============================\n -- Add TimelimitRaw sacct output field to display timelimit numbers.\n -- Fix job array preemption during backfill scheduling.\n -- Fix scontrol -o show assoc output.\n -- Add support for sacct --whole-hetjob=[yes|no] option.\n -- Make salloc handle node requests the same as sbatch.\n -- Add shutdown_on_reboot SlurmdParameter to control whether the Slurmd will\n    shutdown itself down or not when a reboot request is received.\n -- Add cancel_reboot scontrol option to cancel pending reboot of nodes.\n -- Make Users case insensitive in the database based on\n    Parameters=PreserveCaseUser in the slurmdbd.conf.\n -- Improve scheduling when dealing with node_features that could have a\n    boot delay.\n -- Fix issue if a step launch fails we don't get a bunch of '(null)' strings\n    in the step record for usage.\n -- Changed the default AuthType for slurmdbd to auth/munge.\n -- Make it so libpmi.so doesn't link to libslurm.so.$apiversion.\n -- Added 'remote-fs.target' to After directive of slurmd.service file.\n -- Fix filetxt plugin to handle it when you aren't running a jobacct_gather\n    plugin.\n -- Remove drain on node when reboot nextstate used.\n -- Speed up pack of job's qos.\n -- Fix race condition when trying to update reservation in the database.\n -- For the PrologFlags slurm.conf option, make NoHold mutually exclusive with\n    Contain and/or X11 options.\n -- Revise the handling of SlurmctldSyslogLevel and SlurmdSyslogLevel options\n    in slurm.conf and DebugLevelSyslog in slurmdbd.conf.\n -- Gate reading the cgroup.conf file.\n -- Gate reading the acct_gather_* plugins.\n -- Add sacctmgr options to prevent/manage job queue stuffing:\n    - GrpJobsAccrue=<max_jobs>\n      Maximum number of pending jobs in aggregate able to accrue age priority\n      for this association and all associations which are children of this\n      association. To clear a previously set value use the modify command with\n      a new value of -1.\n    - MaxJobsAccrue=<max_jobs>\n      Maximum number of pending jobs able to accrue age priority at any given\n      time for the given association. This is overridden if set directly on a\n      user. Default is the cluster's limit. To clear a previously set value use\n      the modify command with a new value of -1.\n    - MinPrioThreshold\n      Minimum priority required to reserve resources when scheduling.\n\n* Changes in Slurm 18.08.0pre2\n==============================\n -- Remove support for \"ChosLoc\" configuration parameter.\n -- Configuration parameters \"ControlMachine\", \"ControlAddr\", \"BackupController\"\n    and \"BackupAddr\" replaced by an ordered list of \"SlurmctldHost\" records\n    with the optional address appended to the name enclosed in parenthesis.\n    For example: \"SlurmctldHost=head(12.34.56.78)\". An arbitrary number of\n    backup servers can be configured.\n -- When a pending job's state includes \"UnavailableNodes\" do not include the\n    nodes in FUTURE state.\n -- Remove --immediate option from sbatch.\n -- Add infrastructure for per-job and per-step TRES parameters: tres-per-job,\n    tres-per-node, tres-per-socket, tres-per-task, cpus-per-tres, mem-per-tres,\n    tres-bind and tres-freq. These new parameters are not currently used, but\n    have been added to the appropriate RPCs.\n -- Add DefCpuPerGpu and DefMemPerGpu to global and per-partition configuration\n    parameters. Shown in scontrol/sview as \"JobDefaults=...\". NOTE: These\n    options are for future use and currently have no effect.\n -- Fix for setting always the correct status on job update in mysql\n -- Add ValidateMode configuration parameter to knl_cray.conf for static\n    MCDRAM/NUMA configurations.\n -- Fix security issue in accounting_storage/mysql plugin by always escaping\n    strings within the slurmdbd. CVE-2018-7033.\n -- Disable local PTY output processing when using 'srun --unbuffered'. This\n    prevents the PTY subsystem from inserting extraneous \\r characters into\n    the output stream.\n -- Change the column name for the %U (User ID) field in squeue to 'UID'.\n -- CRAY - Add CheckGhalQuiesce to the CommunicationParameters.\n -- When a process is core dumping, avoid terminating other processes in that\n    task group. This fixes a problem with writing out incomplete OpenMP core\n    files.\n -- CPU frequency management enhancements: If scaling_available_frequencies\n    file is not available, then derive values from scaling_min_freq and\n    scaling_max_freq values. If cpuinfo_cur_freq file is not available then\n    try to use scaling_cur_freq.\n -- Add pending jobs count to sdiag output.\n -- Fix update job function. There were some inconsistencies on the behavior\n    that caused time limits to be modified when swapping QOS, bad permissions\n    check for a coordinator and AllowQOS and DenyQOS were not enforced on\n    job update.\n -- Add configuration paramerers SlurmctldPrimaryOnProg and\n    SlurmctldPrimaryOffProg, which define programs to execute when a slurmctld\n    daemon becomes the primary server or goes from primary to backup mode.\n -- Add configuration paramerers SlurmctldAddr for use with virtual IP to manage\n    backup slurmctld daemons.\n -- Explicitly shutdown the slurmd process when instructed to reboot.\n -- Add ability to create/update partition with TRESBillingWeights through\n    scontrol.\n -- Calculate TRES billing values at submission so that billing limits can be\n    enforced at submission with QOS DenyOnLimit.\n -- Add node_features plugin function \"node_features_p_reboot_weight()\" to\n    return the node weight to be used for a compute node that requires reboot\n    for use (e.g. to change the NUMA mode of a KNL node).\n -- Add NodeRebootWeight parameter to knl.conf configuration file.\n -- Fix insecure handling of job requested gid field. CVE-2018-10995.\n -- Fix srun to return highest signal of any task.\n -- Completely remove \"gres\" field from step record. Use \"tres_per_node\",\n    \"tres_per_socket\", etc.\n -- Add \"Links\" parameter to gres.conf configuration file.\n -- Force slurm_mktime() to set tm_isdst to -1 so anyone using the function\n    doesn't forget to set it.\n -- burst_buffer.conf - Add SetExecHost flag to enable burst buffer access\n    from the login node for interactive jobs.\n -- Append \", with requeued tasks\" to job array \"end\" emails if any tasks in the\n    array were requeued. This is a hint to use \"sacct --duplicates\" to see the\n    whole picture of the array job.\n -- Add ResumeFailProgram slurm.conf option to specify a program that is called\n    when a node fails to respond by ResumeTimeout.\n -- Add new job pending reason of \"ReqNodeNotAvail, reserved for maintenance\".\n -- Remove AdminComment += syntax from 'scontrol update job'.\n -- sched/backfill: Reset job time limit if needed for deadline scheduling.\n -- For heterogeneous job component with required nodes, explicitly exclude\n    those nodes from all other job components.\n -- Add name of partition used to output of srun --test-only output (valuable\n    for jobs submitted to multiple partitions).\n -- If MailProg is not configured and \"/bin/mail\" (the default) does not exist,\n    but \"/usr/bin/mail\" does exist then use \"/usr/bin/mail\" as a default value.\n -- sdiag output now reports outgoing slurmctld message queue contents.\n -- Fix issue in performance when reading slurm conf having nodes with features.\n -- Make it so the slurmdbd's pid file gets created before initing\n    the database.\n -- Improve escaping special characters on user commands when specifying paths.\n -- Fix directory names with special char '\\' that are not handled correctly.\n -- Add salloc/sbatch/srun option of --gres-flags=disable-binding to disable\n    filtering of CPUs with respect to generic resource locality. This option is\n    currently required to use more CPUs than are bound to a GRES (i.e. if a GPU\n    is bound to the CPUs on one socket, but resources on more than one socket\n    are required to run the job). This option may permit a job to be allocated\n    resources sooner than otherwise possible, but may result in lower job\n    performance.\n -- SlurmDBD - Print warning if MySQL/MariaDB internal tuning is not at least\n    half of the recommended values.\n -- Move libpmi from src/api to contribs/pmi.\n -- Add ability to specify a node reason when rebooting nodes with \"scontrol\n    reboot\".\n -- Add nextstate option to \"scontrol reboot\" to dictate state of node after\n    reboot.\n -- Consider \"resuming\" (nextstate=resume) nodes as available in backfill\n    future scheduling and don't replace \"resuming\" nodes in reservations.\n -- Add the use of a xml file to help performance when using hwloc.\n\n* Changes in Slurm 18.08.0pre1\n==============================\n -- Add new burst buffer state of \"teardown-fail\" to indicate the burst buffer\n    teardown operation is failing on specific buffers. This changes the numeric\n    value of the BB_STATE_COMPLETE type. Any Slurm version 17.02 or 17.11 tool\n    used to report burst buffer state information will report a state of \"66\"\n    rather than \"complete\" for burst buffers which have been deleted, but still\n    exist in the slurmctld daemon's tables (a very short-lived situation).\n -- Multiple backup slurmctld daemons can be configured:\n    * Specify \"BackupController#=<hostname> and \"BackupAddr#=<address>\" to\n      identify up to 9 backup servers.\n    * Output format of \"scontrol ping\" and the daemon status at the end of\n      \"scontrol status\" is modified to report up status of the primary and all\n      backup servers.\n    * \"scontrol takeover [#]\" command can now identify the SlurmctldHost\n      index number. Default value is \"1\" (the first backup configured\n      SlurmctldHost).\n -- Enable jobs with zero node count for creation and/or deletion of persistent\n    burst buffers.\n    * The partition default MinNodes configuration parameter is now 0\n      (previously 1 node).\n    * Zero size jobs disabled for job arrays and heterogeneous jobs, but\n      supported for salloc, sbatch and srun commands.\n -- Add \"scontrol show dwstat\" command to display Cray burst buffer status.\n -- Add \"GetSysStatus\" option to burst_buffer.conf file. For burst_buffer/cray\n    this would indicate the location of the \"dwstat\" command.\n -- Add node and partition configuration options of \"CpuBind\" to control default\n    task binding. Modify the scontrol to report and modify these parameters.\n -- Add \"NumaCpuBind\" option to knl.conf file to automatically change a node's\n    CpuBind parameter based upon changes to a node's NUMA mode.\n -- Add sbatch \"--batch\" option to identify features required on batch node.\n    For example \"sbatch --batch=haswell ...\".\n -- Add \"BatchFeatures\" field to output of \"scontrol show job\".\n -- Add support for \"--bb\" option to sbatch command.\n -- Add new SystemComment field to job data structure and database. Currently\n    used for Burst Buffer error logs.\n -- Expand reservation \"flags\" field from 32 to 64 bits.\n -- Add job state flag of \"SIGNALING\" to avoid race condition with multiple\n    SIGSTOP/SIGCONT signals for the same job being active at the same time.\n -- Properly handle srun --will-run option when there are jobs in COMPLETING\n    state.\n -- Properly report who is signaling a step.\n -- Don't combine updated reservation records in sreport's reservation report.\n -- node_features plugin - Add support for XOR & XAND of job constraints (node\n    feature specifications).\n -- Add support for parenthesis in a job's constraint specification to group\n    like options together. For example\n    --constraint=\"[(knl&snc4&flat)*4&haswell*1]\" might be used to specify that\n    four nodes with the features \"knl\", \"snc4\" and \"flat\" plus one node with\n    the feature \"haswell\" are required.\n -- Improvements to how srun searches for the executable when using cwd.\n -- Now programs can be checked before execution if test_exec is set when using\n    multi-prog option.\n -- Report NodeFeatures plugin configuration with scontrol and sview commands.\n -- Add acct_gather_profile/influxdb plugin.\n -- Add new job state of SO/STAGE_OUT indicating that burst buffer stage-out\n    operation is in progress.\n -- Correct SLURM_NTASKS and SLURM_NPROCS environment variable for heterogeneous\n    job step. Report values representing full allocation.\n -- Expand advanced reservation feature specification to support parenthesis and\n    counts of nodes with specified features. Nodes with the feature currently\n    active will be preferred.\n -- Defer job signaling until prolog is completed\n -- Have the primary slurmctld wait until the backup has completely shutdown\n    before taking control.\n -- Fix issue where unpacking job state after TRES count changed could lead to\n    invalid reads.\n -- Heterogeneous job steps allocations supported with\n    * Open MPI (with Slurm's PMI2 and PMIx plugins) and\n    * Intel MPI (with Slurm's PMI2 plugin)\n -- Remove redundant function arguments from task plugins:\n    * Remove \"job_id\" field from task_p_slurmd_batch_request() function.\n    * Remove \"job_id\" field from task_p_slurmd_launch_request() function.\n    * Remove \"job_id\" field from task_p_slurmd_reserve_resources() function.\n -- Change function name from node_features_p_changible_feature() to\n    node_features_p_changeable_feature in node_features plugin.\n -- Add Slurm configuration file check logic using \"slurmctld -t\" command.\n\n* Changes in Slurm 17.11.14\n===========================\n\n* Changes in Slurm 17.11.13-2\n=============================\n -- Fix Perl build for 32-bit systems.\n\n* Changes in Slurm 17.11.13\n===========================\n -- Add mitigation for a potential heap overflow on 32-bit systems in xmalloc.\n    CVE-2019-6438.\n\n* Changes in Slurm 17.11.12\n===========================\n -- Fix regression in 17.11.10 that caused dbd messages to not be queued up\n    when the dbd was down.\n\n* Changes in Slurm 17.11.11\n===========================\n -- Correctly initialize variable in env_array_user_default().\n -- Correctly handle scenarios where a partitions MaxMemPerCPU is less than\n    a jobs --mem-per-cpu and also -c is greater than 1.\n\n* Changes in Slurm 17.11.10\n===========================\n -- Move priority_sort_part_tier from slurmctld to libslurm to make it possible\n    to run the regression tests 24.* without changing that code since it links\n    directly to the priority plugin where that function isn't defined.\n -- Fix issue where job time limits can increase to max walltime when updating\n    a job with scontrol.\n -- Fix invalid protocol_version manipulation on big endian platforms causing\n    srun and sattach to fail.\n -- Fix for QOS, Reservation and Alias env variables in srun.\n -- mpi/pmi2 - Backport 6a702158b49c4 from 18.08 to avoid dangerous detached\n    thread.\n -- When allowing heterogeneous steps make sure we copy all the options to\n    avoid copying strings that may be overwritten.\n -- Print correctly when sh5util finds and empty file.\n -- Fix sh5util to not seg fault on exit.\n -- Fix sh5util to check correctly for H5free_memory.\n -- Adjust OOM monitoring function in task/cgroup to prevent problems in\n    regression suite from leaked file descriptors.\n -- Fix issue with gres when defined with a type and no count\n    (i.e. gres=gpu/tesla) it would get a count of 0.\n -- Allow sstat to talk to slurmd's that are new in protocol version.\n -- Permit database names over 33 characters in accounting_storage/mysql.\n -- Fix negative values when profiling.\n -- Fix srun segfault caused by invalid memory reads on the env.\n -- Fix segfault on job arrays when starting controller without dbd up.\n -- Fix pmi2 to build with gcc 8.0+.\n -- Fix proper alignment of clauses when determining if more nodes are needed\n    for an allocation.\n -- Fix race condition when canceling a federation job that just started\n    running.\n -- Prevent extra resources from being allocated when combining certain flags.\n -- Fix problem in task/affinity plugin that can lead to slurmd fatal()'ing\n    when using --hint=nomultithread.\n -- Fix left over socket file when step is ending and using pmi2 with\n    %n or %h in the spool dir.\n -- Fix incorrect spacing for PartitionName lines in 'scontrol write config'.\n -- Fix sacct to not print huge reserve times when the job was never eligible.\n -- burst_buffer/cray - Add missing locks around assoc_mgr when timing out a\n    burst buffer.\n -- burst_buffer/cray - Update burst buffers when an association or qos\n    is removed from the system.\n -- If failed over to a backup controller, ensure the agent thread is launched\n    to handle deferred tasks.\n -- Fix correct job CPU count allocated.\n -- Protect against sending to the slurmdbd if the connection has gone away.\n -- Fix checking missing return codes when unpacking structures.\n -- Fix slurm.spec-legacy including slurmsmwd\n -- More explicit error message when cgroup oom-kill events detected.\n -- When updating an association and are unable to find parent association\n    initialize old fairshare association pointer correctly.\n -- Wrap slurm_cond_signal() calls with mutexes where needed.\n -- Fix correct timeout with resends in slurm_send_only_node_msg.\n -- Fix pam_slurm_adopt to honor action_adopt_failure.\n -- job_submit/lua - expose argc/argv options through lua interface.\n\n* Changes in Slurm 17.11.9-2\n============================\n -- Fix printing of node state \"drain + reboot\" (and other node state flags).\n -- Fix invalid read (segfault) when sorting multi-partition jobs.\n -- Move several new error() messages to debug() to keep them out of users'\n    srun output.\n\n* Changes in Slurm 17.11.9\n==========================\n -- Fix segfault in slurmctld when a job's node bitmap is NULL during a\n    scheduling cycle.  Primarily caused by EnforcePartLimits=ALL.\n -- Remove erroneous unlock in acct_gather_energy/ipmi.\n -- Enable support for hwloc version 2.0.1.\n -- Fix 'srun -q' (--qos) option handling.\n -- Fix socket communication issue that can lead to lost task completion\n    messages, which will cause a permanently stuck srun process.\n -- Handle creation of TMPDIR if environment variable is set or changed in\n    a task prolog script.\n -- Avoid node layout fragmentation if running with a fixed CPU count but\n    without Sockets and CoresPerSocket defined.\n -- burst_buffer/cray - Fix datawarp swap default pool overriding jobdw.\n -- Fix incorrect job priority assignment for multi-partition job with\n    different PriorityTier settings on the partitions.\n -- Fix sinfo to print correct node state.\n\n* Changes in Slurm 17.11.8\n==========================\n -- Fix incomplete RESPONSE_[RESOURCE|JOB_PACK]_ALLOCATION building path.\n -- Do not allocate nodes that were marked down due to the node not responding\n    by ResumeTimeout.\n -- task/cray plugin - search for \"mems\" cgroup information in the file\n    \"cpuset.mems\" then fall back to the file \"mems\".\n -- Fix ipmi profile debug uninitialized variable.\n -- Improve detection of Lua package on older RHEL distributions.\n -- PMIx: fixed the direct connect inline msg sending.\n -- MYSQL: Fix issue not handling all fields when loading an archive dump.\n -- Allow a job_submit plugin to change the admin_comment field during\n    job_submit_plugin_modify().\n -- job_submit/lua - fix access into reservation table.\n -- MySQL - Prevent deadlock caused by archive logic locking reads.\n -- Don't enforce MaxQueryTimeRange when requesting specific jobs.\n -- Modify --test-only logic to properly support jobs submitted to more than\n    one partition.\n -- Prevent slurmctld from abort when attempting to set non-existing\n    qos as def_qos_id.\n -- Add new job dependency type of \"afterburstbuffer\". The pending job will be\n    delayed until the first job completes execution and it's burst buffer\n    stage-out is completed.\n -- Reorder proctrack/task plugin load in the slurmstepd to match that of slurmd\n    and avoid race condition calling task before proctrack can introduce.\n -- Prevent reboot of a busy KNL node when requesting inactive features.\n -- Revert to previous behavior when requesting memory per cpu/node introduced\n    in 17.11.7.\n -- Fix to reinitialize previously adjusted job members to their original value\n    when validating the job memory in multi-partition requests.\n -- Fix _step_signal() from always returning SLURM_SUCCESS.\n -- Combine active and available node feature change logs on one line rather\n    than one line per node for performance reasons.\n -- Prevent occasionally leaking freezer cgroups.\n -- Fix potential segfault when closing the mpi/pmi2 plugin.\n -- Fix issues with --exclusive=[user|mcs] to work correctly\n    with preemption or when job requests a specific list of hosts.\n -- Make code compile with hdf5 1.10.2+\n -- mpi/pmix: Fixed the collectives canceling.\n -- SlurmDBD: improve error message handling on archive load failure.\n -- Fix incorrect locking when deleting reservations.\n -- Fix incorrect locking when setting up the power save module.\n -- Fix setting format output length for squeue when showing array jobs.\n -- Add xstrstr function.\n -- Fix printing out of --hint options in sbatch, salloc --help.\n -- Prevent possible divide by zero in _validate_time_limit().\n -- Add Delegate=yes to the slurmd.service file to prevent systemd from\n    interfering with the jobs' cgroup hierarchies.\n -- Change the backlog argument to the listen() syscall within srun to 4096\n    to match elsewhere in the code, and avoid communication problems at scale.\n\n* Changes in Slurm 17.11.7\n==========================\n -- Fix for possible slurmctld daemon abort with NULL pointer.\n -- Fix different issues when requesting memory per cpu/node.\n -- PMIx - override default paths at configure time if --with-pmix is used.\n -- Have sprio display jobs before eligible time when\n    PriorityFlags=ACCRUE_ALWAYS is set.\n -- Make sure locks are always in place when calling _post_qos_list().\n -- Notify srun and ctld when unkillable stepd exits.\n -- Fix slurmstepd deadlock in stepd cleanup caused by race condition in\n    the jobacct_gather fini() interfaces introduced in 17.11.6.\n -- Fix slurmstepd deadlock in PMIx startup.\n -- task/cgroup - fix invalid free() if the hwloc library does not return a\n    string as expected.\n -- Fix insecure handling of job requested gid field. CVE-2018-10995.\n -- Add --without x11 option to rpmbuild in slurm.spec.\n\n* Changes in Slurm 17.11.6\n==========================\n -- CRAY - Add slurmsmwd to the contribs/cray dir.\n -- sview - fix crash when closing any search dialog.\n -- Fix initialization of variable in stepd when using native x11.\n -- Fix reading slurm_io_init_msg to handle partial messages.\n -- Fix scontrol create res segfault when wrong user/account parameters given.\n -- Fix documentation for sacct on parameter -X (--allocations)\n -- Change TRES Weights debug messages to debug3.\n -- FreeBSD - assorted fixes to restore build.\n -- Fix for not tracking environment variables from unrelated different jobs.\n -- PMIX - Added the direct connect authentication.\n    When upgrading this may cause issues with jobs using pmix starting on mixed\n    slurmstepd versions where some are less than 17.11.6.\n -- Prevent the backup slurmctld from losing the active/available node\n    features list on takeover.\n -- Add documentation for fix IDLE*+POWER due to capmc stuck in Cray systems.\n -- Fix missing mutex unlock when prolog is failing on a node, leading to a\n    hung slurmd.\n -- Fix locking around Cray CCM prolog/epilog.\n -- Add missing fed_mgr read locks.\n -- Fix issue incorrectly setting a job time_start to 0 while requeueing.\n -- smail - remove stray '-s' from mail subject line.\n -- srun - prevent segfault if ClusterName setting is unset but\n    SLURM_WORKING_CLUSTER environment variable is defined.\n -- In configurator.html web pages change default configuration from\n    task/none to task/affinity plugin and from select/linear plugin to\n    select/cons_res plus CR_Core.\n -- Allow jobs to run beyond a FLEX reservation end time.\n -- Fix problem with wrongly set as Reservation job state_reason.\n -- Prevent bit_ffs() from returning value out of bitmap range.\n -- Improve performance of 'squeue -u' when PrivateData=jobs is enabled.\n -- Make UnavailableNodes value in job reason be correct for each job.\n -- Fix 'squeue -o %s' on Cray systems.\n -- Fix incorrect error thrown when cancelling part of a job array.\n -- Fix error code and scheduling problem for --exclusive=[user|mcs].\n -- Fix build when lz4 is in a non-standard location.\n -- Be able to force power_down of cloud node even if in power_save state.\n -- Allow cloud nodes to be recognized in Slurm when booted out of band.\n -- Fixes race condition in _pack_job_gres() when is called multiple times.\n -- Increase duration of \"sleep\" command used to keep extern step alive.\n -- Remove unsafe usage of pthread_cancel in slurmstepd that can lead to\n    to deadlock in glibc.\n -- Fix total TRES Billing on partitions.\n -- Don't tear down a BB if a node fails and --no-kill or resize of a job\n    happens.\n -- Remove unsafe usage of pthread_cancel in pmix plugin that can lead to\n    to deadlock in glibc.\n -- Fix fatal in controller when loading completed trigger\n -- Ignore reservation overlap at submission time.\n -- GRES type model and QOS limits documentation added\n -- slurmd - fix ABRT on SIGINT after reconfigure with MemSpecLimit set.\n -- PMIx - move two error messages on retry to debug level, and only display\n    the error after the retry count has been exceeded.\n -- Increase number of tries when sending responses to srun.\n -- Fix checkpointing requeued/completing jobs in a bad state which caused a\n    segfault on restart.\n -- Fix srun on ppc64 platforms.\n -- Prevent slurmd from starting steps if the Prolog returns an error when using\n    PrologFlags=alloc.\n -- priority/multifactor - prevent segfault running sprio if a partition has\n    just been deleted and PriorityFlags=CALCULATE_RUNNING is turned on.\n -- job_submit/lua - add ESLURM_INVALID_TIME_LIMIT return code value.\n -- job_submit/lua - print an error if the script calls log.user in\n    job_modify() instead of returning it to the next submitted job erroneously.\n -- select/linear - handle job resize correctly.\n -- select/cons_res - improve handling of --cores-per-socket requests.\n\n* Changes in Slurm 17.11.5\n==========================\n -- Fix cloud nodes getting stuck in DOWN+POWER_UP+NO_RESPOND state after not\n    responding by ResumeTimeout.\n -- Add job's array_task_cnt and user_name along with partitions\n    [max|def]_mem_per_[cpu|node], max_cpus_per_node, and max_share with the\n    SHARED_FORCE definition to the job_submit/lua plugin.\n -- srun - fix for SLURM_JOB_NUM_NODES env variable assignment.\n -- sacctmgr - fix runaway jobs identification.\n -- Fix for setting always the correct status on job update in mysql.\n -- Fix issue if running with an association manager cache (slurmdbd was down\n    when slurmctld was started) you could loose QOS usage information.\n -- CRAY - Fix spec file to work correctly.\n -- Set scontrol exit code to 1 if attempting to update a node state to DRAIN\n    or DOWN without specifying a reason.\n -- Fix race condition when running with an association manager cache\n    (slurmdbd was down when slurmctld was started).\n -- Print out missing SLURM_PERSIST_INIT slurmdbd message type.\n -- Fix two build errors related to use of the O_CLOEXEC flag with older glibc.\n -- Add Google Cloud Platform integration scripts into contribs directory.\n -- Fix minor potential memory leak in backfill plugin.\n -- Add missing node flags (maint/power/etc) to node states.\n -- Fix issue where job time limits may end up at 1 minute when using the\n    NoReserve flag on their QOS.\n -- Fix security issue in accounting_storage/mysql plugin by always escaping\n    strings within the slurmdbd. CVE-2018-7033.\n -- Soften messages about best_fit topology to debug2 to avoid alarm.\n -- Fix issue in sreport reservation utilization report to handle more\n    allocated time than 100% (Flex reservations).\n -- When a job is requesting a Flex reservation prefer the reservation's nodes\n    over any other nodes.\n\n* Changes in Slurm 17.11.4\n==========================\n -- Add fatal_abort() function to be able to get core dumps if we hit an\n    \"impossible\" edge case.\n -- Link slurmd against all libraries that slurmstepd links to.\n -- Fix limits enforce order when they're set at partition and other levels.\n -- Add slurm_load_single_node() function to the Perl API.\n -- slurm.spec - change dependency for --with lua to use pkgconfig.\n -- Fix small memory leaks in node_features plugins on reconfigure.\n -- slurmdbd - only permit requests to update resources from operators or\n    administrators.\n -- Fix handling of partial writes in io_init_msg_write_to_fd() which can\n    lead to job step launch failure under higher cluster loads.\n -- MYSQL - Fix to handle quotes in a given work_dir of a job.\n -- sbcast - fix a race condition that leads to \"Unspecified error\".\n -- Log that support for the ChosLoc configuration parameter will end in Slurm\n    version 18.08.\n -- Fix backfill performance issue where bf_min_prio_reserve was not respected.\n -- Fix MaxQueryTimeRange checks.\n -- Print MaxQueryTimeRange in \"sacctmgr show config\".\n -- Correctly check return codes when creating a step to check if needing to\n    wait to retry or not.\n -- Fix issue where a job could be denied by Reason=MaxMemPerLimit when not\n    requesting any tasks.\n -- In perl tools, fix for regexp that caused extra incorrectly shown results.\n -- Add some extra locks in fed_mgr to be extra safe.\n -- Minor memory leak fixes in the fed_mgr on slurmctld shutdown.\n -- Make sreport job reports also report duplicate jobs correctly.\n -- Fix issues restoring certain Partition configuration elements, especially\n    when ReconfigFlags=KeepPartInfo is enabled.\n -- Don't add TRES whose value is NO_VAL64 when building string line.\n -- Fix removing array jobs from hash in slurmctld.\n -- Print out missing user messages from jobsubmit plugin when srun/salloc are\n    waiting for an allocation.\n -- Handle --clusters=all as case insensitive.\n -- Only check requested clusters in federation when using --test-only\n    submission option.\n -- In the federation, make it so you can cancel stranded sibling jobs.\n -- Silence an error from PSS memory stat collection process.\n -- Requeue jobs allocated to nodes requested to DRAIN or FAIL if nodes are\n    POWER_SAVE or POWER_UP, preventing jobs to start on NHC-failed nodes.\n -- Make MAINT and OVERLAP resvervation flags order agnostic on overlap test.\n -- Preserve node features when slurmctld daemons reconfigured including active\n    and available KNL features.\n -- Prevent creation of multiple io_timeout threads within srun, which can\n    lead to fatal() messages when those unexpected and additional mutexes are\n    destroyed when srun shuts down.\n -- burst_buffer/cray - Prevent use of \"#DW create_persistent\" and\n    \"#DW destroy_persistent\" directives available in Cray CLE6.0UP06. This\n    will be supported in Slurm version 18.08. Use \"#BB\" directives until then.\n -- Fix task/cgroup affinity to behave correctly.\n -- FreeBSD - fix build on systems built with WITHOUT_KERBEROS.\n -- Fix to restore pn_min_memory calculated result to correctly enforce\n    MaxMemPerCPU setting on a partition when the job uses --mem.\n -- slurmdbd - prevent infinite loop if a QOS is set to preempt itself.\n -- Fix issue with log rotation for slurmstepd processes.\n\n* Changes in Slurm 17.11.3-2\n==========================\n -- Revert node_features changes in 17.11.3 that lead to various segfaults on\n    slurmctld startup.\n\n* Changes in Slurm 17.11.3\n==========================\n -- Send SIG_UME correctly to a step.\n -- Sort sreport's reservation report by cluster, time_start, resv_name instead\n    of cluster, resv_name, time_start.\n -- Avoid setting node in COMPLETING state indefinitely if the job initiating\n    the node reboot is cancelled while the reboot in in progress.\n -- Scheduling fix for changing node features without any NodeFeatures plugins.\n -- Improve logic when summarizing job arrays mail notifications.\n -- Add scontrol -F/--future option to display nodes in FUTURE state.\n -- Fix REASONABLE_BUF_SIZE to actually be 3/4 of MAX_BUF_SIZE.\n -- When a job array is preempting make it so tasks in the array don't wait\n    to preempt other possible jobs.\n -- Change free_buffer to FREE_NULL_BUFFER to prevent possible double free\n    in slurmstepd.\n -- node_feature/knl_cray - Fix memory leaks that occur when slurmctld\n    reconfigured.\n -- node_feature/knl_cray - Fix memory leak that can occur during normal\n    operation.\n -- Fix srun environment variables for --prolog script.\n -- Fix job array dependency with \"aftercorr\" option and some task arrays in\n    the first job fail. This fix lets all task array elements that can run\n    proceed rather than stopping all subsequent task array elements.\n -- Fix potential deadlock in the slurmctld when using list_for_each.\n -- Fix for possible memory corruption in srun when running heterogeneous job\n    steps.\n -- Fix job array dependency with \"aftercorr\" option and some task arrays in\n    the first job fail. This fix lets all task array elements that can run\n    proceed rather than stopping all subsequent task array elements.\n -- Fix output file containing \"%t\" (task ID) for heterogeneous job step to\n    be based upon global task ID rather than task ID for that component of the\n    heterogeneous job step.\n -- MYSQL - Fix potential abort when attempting to make an account a parent of\n    itself.\n -- Fix potentially uninitialized variable in slurmctld.\n -- MYSQL - Fix issue for multi-dimensional machines when using sacct to\n    find jobs that ran on specific nodes.\n -- Reject --acctg-freq at submit if invalid.\n -- Added info string on sh5util when deleting an empty file.\n -- Correct dragonfly topology support when job allocation specifies desired\n    switch count.\n -- Fix minor memory leak on an sbcast error path.\n -- Fix issues when starting the backup slurmdbd.\n -- Revert uid check when requesting a jobid from a pid.\n -- task/cgroup - add support to detect OOM_KILL cgroup events.\n -- Fix whole node allocation cpu counts when --hint=nomultihtread.\n -- Allow execution of task prolog/epilog when uid has access\n    rights by a secondary group id.\n -- Validate command existence on the srun *[pro|epi]log options\n    if LaunchParameter test_exec is set.\n -- Fix potential memory leak if clean starting and the TRES didn't change\n    from when last started.\n -- Fix for association MaxWall enforcement when none is given at submission.\n -- Add a job's allocated licenses to the [Pro|Epi]logSlurmctld.\n -- burst_buffer/cray: Attempts by job to create persistent burst buffer when\n    one already exists owned by a different user will be logged and the job\n    held.\n -- CRAY - Remove race in the core_spec where we add the slurmstepd to the\n    job container where if the step was canceled would also cancel the stepd\n    erroneously.\n -- Make sure the slurmstepd blocks signals like SIGTERM correctly.\n -- SPANK - When slurm_spank_init_post_opt() fails return error correctly.\n -- When revoking a sibling job in the federation we want to send a start\n    message before purging the job record to get the uid of the revoked job.\n -- Make JobAcctGatherParams options case-insensitive. Previously, UsePss\n    was the only correct capitialization; UsePSS or usepss were silently\n    ignored.\n -- Prevent pthread_atfork handlers from being added unnecessarily after\n    'scontrol reconfigure', which can eventually lead to a crash if too\n    many handlers have been registered.\n -- Better debug messages when MaxSubmitJobs is hit.\n -- Docs - update squeue man page to describe all possible job states.\n -- Prevent orphaned step_extern steps when a job is cancelled while the\n    prolog is still running.\n\n* Changes in Slurm 17.11.2\n==========================\n -- jobcomp/elasticsearch - append Content-Type to the HTTP header.\n -- MYSQL - Fix potential abort of slurmdbd when job has no TRES.\n -- Add advanced reservation flag of \"REPLACE_DOWN\" to replace DOWN or DRAINED\n    nodes.\n -- slurm.spec-legacy - add missing libslurmfull.so to slurm.files.\n -- Fix squeue job ID filtering for pending job array records.\n -- Fix potential deadlock in _run_prog() in power save code.\n -- MYSQL - Add dynamic_offset in the database to force range for auto\n    increment ids for the tres_table.\n -- MYSQL - Fix fallout from MySQL auto increment bug, see RELEASE_NOTES,\n    only affects current 17.11 users tracking licenses or GRES in the database.\n -- Refactor logging logic to avoid possible memory corruption on non-x86\n    architectures.\n -- Fix memory leak when getting jobs from the slurmdbd.\n -- Fix incorrect logic behind MemorySwappiness, and only set the value when\n    specified in the configuration.\n\n* Changes in Slurm 17.11.1-2\n============================\n -- MYSQL - Make index for pack_job_id\n\n* Changes in Slurm 17.11.1\n==========================\n -- Fix --with-shared-libslurm option to work correctly.\n -- Make it so only daemons log errors on configuration option duplicates.\n -- Fix for ConstrainDevices=yes to work correctly.\n -- Fix to purge old jobs using burst buffer if slurmctld daemon restarted\n    after the job's burst buffer work was already completed.\n -- Make logging prefix for slurmstepd to happen as soon as possible.\n -- mpi/pmix: Fix the job registration for the PMIx v2.1.\n -- Fix uid check for signaling a step with anything but SIGKILL.\n -- Return ESLURM_TRANSITION_STATE_NO_UPDATE instead of EAGAIN when trying to\n    signal a step that is still running a prolog.\n -- Update Cray slurm_playbook.yaml with latest recommended version.\n -- Only say a prolog is done running after the extern step is launched.\n -- Wait to start a batch step until the prolog and extern step are\n    fully ran/launched.  Only matters if running with\n    PrologFlags=[contain|alloc].\n -- Truncate a range for SlurmctldPort to FD_SETSIZE elements and throw an\n    error, otherwise network traffic may be lost due to poll() not detecting\n    traffic.\n -- Fix for srun --pack-group option that can reuse/corrupt memory.\n -- Fix handling ultra long hostlists in a hostfile.\n -- X11: fix xauth regex to handle '-' in hostnames again.\n -- Fix potential node reboot timeout problem for \"scontrol reboot\" command.\n -- Add ability for squeue to sort jobs by submit time.\n -- CRAY - Switch to standard pid files on Cray systems.\n -- Update jobcomp records on duplicate inserts.\n -- If unrecognized configuration file option found then print an appropriate\n    fatal error message rather than relying upon random errno value.\n -- Initialize job_desc_msg_t's instead of just memset'ing them.\n -- Fix divide by zero when job requests no tasks and more memory than\n    MaxMemPer{CPU|NODE}.\n -- Avoid changing Slurm internal errno on syslog() failures.\n -- BB - Only launch dependent jobs after the burst buffer is staged-out\n    completely instead of right after the parent job finishes.\n -- node_features/knl_generic - If plugin can not fully load then do not spawn\n    a background pthread (which will fail with invalid memory reference).\n -- Don't set the next jobid to give out to the highest jobid in the system on\n    controller startup. Just use the checkpointed next use jobid.\n -- Docs - add Slurm/PMIx and OpenMPI build notes to the mpi_guide page.\n -- Add lustre_no_flush option to LaunchParameters for Native Cray systems.\n -- Fix rpmbuild issue with rpm 4.13+ / Fedora 25+.\n -- sacct - fix the display for the NNodes field when using the --units option.\n -- Prevent possible double-xfree on a buffer in stepd_completion.\n -- Fix for record job state on successful allocation but failed reply message.\n -- Fill in the user_name field for batch jobs if not sent by the slurmctld.\n    (Which is the default behavior if LaunchParameters=send_gids is not\n    enabled.). This prevents job launch problems for sites using UsePAM=1.\n -- Handle syncing federated jobs that ran on non-origin clusters and were\n    cancelled while the origin cluster was down.\n -- Fix accessing variable outside of lock.\n -- slurm.spec: move libpmi to a separate package to solve a conflict with the\n    version provided by PMIx. This will require a separate change to PMIx as\n    well.\n -- X11 forwarding: change xauth handling to use hostname/unix:display format,\n    rather than localhost:display.\n -- mpi/pmix - Fix warning if not compiling with debug.\n\n* Changes in Slurm 17.11.0\n==========================\n -- Fix documentation for MaxQueryTimeRange option in slurmdbd.conf.\n -- Avoid srun abort trying to run on heterogeneous job component that has\n    ended.\n -- Add SLURM_PACK_JOB_ID,SLURM_PACK_JOB_OFFSET to PrologSlurmctld and\n    EpilogSlurmctld environment.\n -- Treat \":\" in #SBATCH arguments as fatal error. The \"#SBATCH packjob\" syntax\n    must be used instead.\n -- job_submit/lua plugin: expose pack_job fields to get.\n -- Prevent scheduling deadlock with multiple components of heterogeneous job\n    in different partitions (i.e. one heterogeneous job component is higher\n    priority in one partition and another component is lower priority in a\n    different partition).\n -- Fix for heterogeneous job starvation bug.\n -- Fix some slurmctld memory leaks.\n -- Add SLURM_PACK_JOB_NODELIST to PrologSlurmctld and EpilogSlurmctld\n    environment.\n -- If PrologSlurmctld fails for pack job leader then requeue or kill all\n    components of the job.\n -- Fix for multiple --pack-group srun arguments given out of order.\n -- Update slurm.conf(5) man page with updated example logrotate script.\n -- Add SchedulerParameters=whole_pack configuration parameter. If set, then\n    hold, release and cancel operations on any component of a heterogeneous job\n    will be applied to all components\n -- Handle FQDNs in xauth cookies for x11 display forwarding properly.\n -- For heterogeneous job steps, the srun --open-mode option default value will\n    be set to \"append\".\n -- Pack job scheduling list not being cleared between runs of the backfill\n    scheduler resulted in various anomalies.\n -- Fix that backward compat for pmix version < 1.1.5.\n -- Fix use-after-free that can lead to slurmstepd segfaulting when setting\n    ulimit values.\n -- Add heterogeneous job start data to sdiag output.\n -- X11 forwarding - handle systems with X11UseLocalhost=no set in sshd_config.\n -- Fix potential missing issue with missing symbols in gres plugins.\n -- Ignore querying clusters in federation that are down from status commands.\n -- Base federated jobs off of origin job and not the local cluster in API.\n -- Remove erroneous double '-' on rpath for libslurmfull.\n -- Remove version from libslurmfull and move it to $LIBDIR/slurm since the ABI\n    could change from one version to the other.\n -- Fix unused wall time for reservations.\n -- Convert old reservation records to insert unused wall into the rows.\n -- slurm.spec: further restructuring and improvements.\n -- Allow nodes state to be updated between FAIL and DRAIN.\n -- x11 forwarding: handle build with alternate location for libssh2.\n\n* Changes in Slurm 17.11.0rc3\n==============================\n -- Fix extern step to wait until launched before allowing job to start.\n -- Add missing locks around figuring out TRES when clean starting the\n    slurmctld.\n -- Cray modulefile: avoid removing /usr/bin from path on module unload.\n -- Make reoccurring reservations show up in the database.\n -- Adjust related resources (cpus, tasks, gres, mem, etc.) when updating\n    NumNodes with scontrol.\n -- Don't initialize MPI plugins for batch or extern steps.`\n -- slurm.spec - do not install a slurm.conf file under /etc/ld.so.conf.d.\n -- X11 forwarding - fix keepalive message generation code.\n -- If heterogeneous job step is unable to acquire MPI reserved ports then\n    avoid referencing NULL pointer. Retry assigning ports ONLY for\n    non-heterogeneous job steps.\n -- If any acct_gather_*_init fails fatal instead of error and keep going.\n -- launch/slurm plugin - Avoid using global variable for heterogeneous job\n    steps, which could corrupt memory.\n\n* Changes in Slurm 17.11.0rc2\n==============================\n -- Prevent slurmctld abort with NodeFeatures=knl_cray and non-KNL nodes lacking\n    any configured features.\n -- The --cpu_bind and --mem_bind options have been renamed to --cpu-bind\n    and --mem-bind for consistency with the rest of Slurm's options. Both\n    old and new syntaxes are supported for now.\n -- Add slurmdb_connection_commit to the slurmdb api to commit when needed.\n -- Add the federation api's to the slurmdb.h file.\n -- Add job functions to the db_api.\n -- Fix sacct to always use the db_api instead of sometimes calling functions\n    directly.\n -- Fix sacctmgr to always use the db_api instead of sometimes calling functions\n    directly.\n -- Fix sreport to always use the db_api instead of sometimes calling functions\n    directly.\n -- Make global uid to the db_api to minimize calls to getuid().\n -- Add support for HWLOC version 2.0.\n -- Added more validation logic for updates to node features.\n -- Added node_features_p_node_update_valid() function to node_features plugin.\n -- If a job is held due to bad constraints and a node's features change then\n    test the job again to see if can run with the new features.\n -- Added node_features_p_changible_feature() function to node_features plugin.\n -- Avoid rebooting a node if a job's requested feature is not under the control\n    of the node_features plugin and is not currently active.\n -- node_features/knl_generic plugin: Do not clear a node's non-KNL features\n    specified in slurm.conf.\n -- Added SchedulerParameters configuration option \"disable_hetero_steps\" to\n    disable job steps that span multiple components of a heterogeneous job.\n    Disabled by default except with mpi/none plugin. This limitation to be\n    removed in Slurm version 18.08.\n\n* Changes in Slurm 17.11.0rc1\n==============================\n -- Added the following jobcomp/script environment variables: CLUSTER,\n    DEPENDENCY, DERIVED_EC, EXITCODE, GROUPNAME, QOS, RESERVATION, USERNAME.\n    The format of LIMIT (job time limit) has been modified to D-HH:MM:SS.\n -- Fix QOS usage factor applying to individual TRES run minute usage.\n -- Print numbers using exponential format if required to fit in allocated\n    field width. The sacctmgr and sshare commands are impacted.\n -- Make it so a backup DBD doesn't attempt to create database tables and\n    relies on the primary to do so.\n -- By default have Slurm dynamically link to libslurm.so instead of static\n    linking.  If static linking is desired configure with\n    --without-shared-libslurm.\n -- Change --workdir in sbatch to be --chdir as in all other commands (salloc,\n    srun).\n -- Add WorkDir to the job record in the database.\n -- Make the UsageFactor of a QOS work when a qos has the nodecay flag.\n -- Add MaxQueryTimeRange option to slurmdbd.conf to limit accounting query\n    ranges when fetching job records.\n -- Add LaunchParameters=batch_step_set_cpu_freq to allow the setting of the cpu\n    frequency on the batch step.\n -- CRAY - Fix statically linked applications to CRAY's PMI.\n -- Fix - Raise an error back to the user when trying to update currently\n    unsupported core-based reservations.\n -- Do not print TmpDisk space as part of 'slurmd -C' line.\n -- Fix to test MaxMemPerCPU/Node partition limits when scheduling, previously\n    only checked on submit.\n -- Work for heterogeneous job support (complete solution in v17.11):\n    * Set SLURM_PROCID environment variable to reflect global task rank (needed\n      by MPI).\n    * Set SLURM_NTASKS environment variable to reflect global task count (needed\n      by MPI).\n    * In srun, if only some steps are allocated and one step allocation fails,\n      then delete all allocated steps.\n    * Get SPANK plungins working with heterogeneous jobs. The\n      spank_init_post_opt() function is executed once per job component.\n    * Modify sbcast command and srun's --bcast option to support heterogeneous\n      jobs.\n    * Set more environment variables for MPI: SLURM_GTIDS and SLURM_NODEID.\n    * Prevent a heterogeneous job allocation from including the same nodes in\n      multiple components (required by MPI jobs spanning components).\n    * Modify step create logic so that call components of a heterogeneous job\n      launched by a single srun command have the same step ID value.\n -- Modify output of \"--mpi=list\" to avoid duplicates for version numbers in\n    mpi/pmix plugin names.\n -- Allow nodes to be rebooted while in a maintenance reservation.\n -- Show nodes as down even when nodes are in a maintenance reservation.\n -- Harden the slurmctld HA stack to mitigate certain split-brain issues.\n -- Work for heterogeneous job support (complete solution in v17.11):\n    * Add burst buffer support.\n    * Remove srun's --mpi-combine option (always combined).\n    * Add SchedulerParameters configuration option \"enable_hetero_steps\" to\n      enable job steps that span multiple components of a heterogeneous job.\n      Disabled by default as most MPI implementations and Slurm configurations\n      are not currently supported. Limitation to be removed in Slurm version\n      18.08.\n    * Synchronize application launch across multiple components with debugger.\n    * Modify slurm_kill_job_step() to cancel all components of a heterogeneous\n      job step (used by MPI).\n    * Set SLURM_JOB_NUM_NODES environment variable as needed by MVAPICH.\n    * Base time limit upon the time that the latest job component is available\n      (after all nodes in all components booted and ready for use).\n -- Add cluster name to smail tool email header.\n -- Speedup arbitrary distribution algorithm.\n -- Modify \"srun --mpi=list\" output to match valid option input by removing the\n    \"mpi/\" prefix on each line of output.\n -- Automatically set the reservation's partition for the job if not the\n    cluster default.\n -- mpi/pmi2 plugin - vestigial pointer could be referenced at shutdown with\n    invalid memory reference resulting.\n -- Fix to _is_gres_cnt_zero() return false for improper input string\n -- Cleanup all pthread_create calls and replace with new slurm_thread_create\n    macro.\n -- Removed obsolete MPI plugins. Remaining options are openmpi, pmi2, pmix.\n -- Removed obsolete checkpoint/poe plugin.\n -- Process spank environment variable options before processing spank command\n    line options. Spank plugins should be able to handle option callbacks being\n    called multiple times.\n -- Add support for specialized cores with task/affinity plugin (previously\n    only supported with task/cgroup plugin).\n -- Add \"TaskPluginParam=SlurmdOffSpec\" option that will prevent the Slurm\n    compute node daemons (slurmd and slurmstepd) from executing on specialized\n    cores.\n -- CRAY - Make native mode default, use --disable-native-cray to use ALPS\n    instead of native Slurm.\n -- Add ability to prevent suspension of some count of nodes in a specified\n    range using the SuspendExcNodes configuration parameter.\n -- Add SLURM_WCKEY to PrologSlurmctld and EpilogSlurmctld  environment.\n -- Return user response string in response to successful job allocation request\n    not only on failure. Set in LUA using function 'slurm.user_msg(\"STRING\")'.\n -- Add 'scontrol write batch_script <jobid>' command to retrieve the batch\n    script for a given job.\n -- Remove option to display the batch script as part of 'scontrol show job'.\n -- On native Cray system the configured RebootProgram is executed on on the\n    head node by the slurmctld daemon rather than by the slurmd daemons on the\n    compute nodes. The \"capmc_resume\" program from \"contribs/cray\" can be used.\n -- Modify \"scontrol top\" command to accept a comma separated list of job IDs\n    as an argument rather than a single job ID.\n -- Add MemorySwappiness value to cgroup.conf.\n -- Add new \"billing\" TRES which allows jobs to be limited based on the job's\n    billable TRES calculated by the job's partition's TRESBillingWeights.\n -- sbatch - force line-buffered output so 'sbatch -W' returns the jobid\n    over a piped output immediately.\n -- Regular user use of \"scontrol top\" command is now disabled. Use the\n    configuration parameter \"SchedulerParameters=enable_user_top\" to enable\n    that functionality. The configuration parameter\n    \"SchedulerParameters=disable_user_top\" will be silently ignored.\n -- Add -TALL to sreport.\n -- Removed unused SlurmdPlugstack option and associated framework.\n -- Correct logic for line continuation in srun --multi-prog file.\n -- Add DBD Agent queue size to sdiag output.\n -- Add running job count to sdiag output.\n -- Print unix timestamps next to ASCII timestamps in sdiag output.\n -- In a job allocation spanning KNL and non-KNL nodes and requiring a reboot,\n    do not attempt to set default NUMA or MCDRAM modes on non-KNL nodes.\n -- Change default to let pending jobs run outside of reservation after\n    reservation is gone to put jobs in held state. Added NO_HOLD_JOBS_AFTER_END\n    reservation flag to use old default.\n -- When creating a reservation, validate the CoreCnt specification matches\n    the number of nodes listed.\n -- When creating a reservation, correct logic to ignoring job allocations on\n    request.\n -- Deprecate BLCR plugin, and do not build by default.\n -- Change sreport report titles from \"Use\" to \"Usage\"\n\n* Changes in Slurm 17.11.0pre2\n==============================\n -- Initial work for heterogeneous job support (complete solution in v17.11):\n    * Modified salloc, sbatch and srun commands to parse command line, job\n      script and environment variables to recognize requests for heterogeneous\n      jobs. Same commands also modified to set environment variables describing\n      each component of the heterogeneous job.\n    * Modified job allocate, batch job submit and job \"will-run\" requests to\n      pass a list of job specifications and get a list of responses.\n    * Modify slurmctld daemon to process a heterogeneous job request and create\n      multiple job records as needed.\n    * Added new fields to job record: pack_job_id, pack_job_offset and\n      pack_job_set (set of job IDs). Added to slurmctld state save/restore\n      logic and job information reported.\n    * Display new job fields in \"scontrol show job\" output.\n    * Modify squeue command to display heterogeneous job records using \"#+#\"\n      format. The squeue --job=# output lists all components of a heterogeneous\n      job.\n    * Modify scancel logic to cancel all components of a heterogeneous job with\n      a single request/RPC.\n    * Configuration parameter DebugFlags value of \"HeteroJobs\" added.\n    * Job requeue and suspend/resume modified to operate on all components of\n      a heterogeneous job with a single request/RPC.\n    * New web page added to describe heterogeneous jobs.\n    * Descriptions of new API added to man pages.\n    * Modified email notifications to only operate on the first job component.\n    * Purge heterogeneous job records at the same time and not by individual\n      components.\n    * Modified logic for heterogeneous jobs submitted to multiple clusters\n      (\"--clusters=...\") so the job will be routed to the cluster that is\n      expected to start all components earliest.\n    * Modified srun to create multiple job steps for heterogeneous job\n      allocations.\n    * Modified launch plugin to accept a pointer to job step options structure\n      rather than work from a single/common data structure.\n -- Improve backfill scheduling algorithm with respect to starting jobs as soon\n    as possible while avoiding advanced reservations.\n -- Add URG as an option to 'scancel --signal'.\n -- Check if the buffer returned from slurm_persist_msg_pack() isn't NULL.\n -- Modify all daemons to re-open log files on receipt of SIGUSR2 signal. This\n    is much than using SIGHUP to re-read the configuration file and rebuild\n    various tables.\n -- Add PrivateData=events configuration parameter\n -- Work for heterogeneous job support (complete solution in v17.11):\n    * Add pointer to job option structure to job_step_create_allocation()\n      function used by srun.\n    * Parallelize task launch for heterogeneous job allocations (initial work).\n    * Make packjobid, packjoboffset, and packjobidset fields available in squeue\n      output.\n    * Modify smap command to display heterogeneous job records using \"#+#\"\n      format.\n    * Add srun --pack-group and --mpi-combine options to control job step\n      launch behaviour (not fully implemented).\n    * Add pack job component ID to srun --label output (e.g. \"P0 1:\" for\n      job component 0 and task 1).\n    * jobcomp/elasticsearch: Add pack_job_id and pack_job_offset fields.\n    * sview: Modified to display pack job information.\n    * Major re-write of task state container logic to support for list of\n      containers rather than one container per srun command.\n    * Add some regression tests.\n    * Add srun pack job environment variables when performing job allocation.\n -- Set Reason=dependency over Reason=JobArrayTaskLimit for pending jobs.\n -- Add slurm.conf configuration parameters SlurmctldSyslogDebug and\n    SlurmdSyslogDebug to control which messages from the slurmctld and slurmd\n    daemons get written to syslog.\n -- Add slurmdbd.conf configuration parameter DebugLevelSyslog to control which\n    messages from the slurmdbd daemon get written to syslog.\n -- Fix handling of GroupUpdateForce option.\n -- Work for heterogeneous job support (complete solution in v17.11):\n    * Add support to sched/backfill for concurrent allocation of all pack job\n      components including support of --time-min option.\n    * Defer initiation of a heterogeneous job until a components can be started\n      at the same time, taking into consideration association and QOS limits\n      for the job as a whole.\n    * Perform limit check on heterogeneous job as a whole at submit time to\n      reject jobs that will never be able to run.\n    * Add pack_job_id and pack_job_offset to accounting database.\n    * Modified sacct to accept pack job ID specification using \"#+#\" notation.\n    * Modified sstat to accept pack job ID specification using \"#+#\" notation.\n -- Clear a job's \"wait reason\" value of BeginTime\" after that time has passed.\n    Previously a readon of \"BeginTime\" could be reported long after the job's\n    requested begin time had passed.\n -- Split group_info in slurm_ctl_conf_t into group_force and group_time.\n -- Work for heterogeneous job support (complete solution in v17.11):\n    * Fix I/O race condition on step termination for srun launching multiple\n      pack job groups.\n    * If prolog is running when attempting to signal a step, then return EAGAIN\n      and retry rather than simply returning SLURM_ERROR and aborting.\n    * Modify launch/slurm plugin to signal all components of a pack job rather\n      than just the one (modify to use a list of step context records).\n    * Add logic to support srun --mpi-combine option.\n    * Set up debugger data structures.\n    * Disable cancellation of individual component while the job is pending.\n    * Modify scontrol job hold/release and update to operate with heterogeneous\n      job id specification (e.g. \"scontrol hold 123+4\").\n    * If srun lacks application specification for some component, the next one\n      specified will be used for earlier components.\n\n* Changes in Slurm 17.11.0pre1\n==============================\n -- Interpret all format options in output/error file to log prolog errors. Prior\n    logic only supported \"%j\" (job ID) option.\n -- Add the configure option --with-shared-libslurm which will link to\n    libslurm.so instead of libslurm.o thus reducing the footprint of all the\n    binaries.\n -- In switch plugin, added plugin_id symbol to plugins and wrapped\n    switch_jobinfo_t with dynamic_plugin_data_t in interface calls in\n    order to pass switch information between clusters with different switch\n    types.\n -- Switch naming of acct_gather_infiniband to acct_gather_interconnect\n -- Make it so you can \"stack\" the interconnect plugins.\n -- Add a last_sched_eval timestamp to record when a job was last evaluated\n    by the main scheduler or backfill.\n -- Add scancel \"--hurry\" option to avoid staging out any burst buffer data.\n -- Simplify the sched plugin interface.\n -- Add new advanced reservation flags of \"weekday\" (repeat on each weekday;\n    Monday through Friday) and \"weekend\" (repeat on each weekend day; Saturday\n    and Sunday).\n -- Add new advanced reservation flag of \"flex\", which permits jobs requesting\n    the reservation to begin prior to the reservation's start time and use\n    resources inside or outside of the reservation. A typical use case is to\n    prevent jobs not explicitly requesting the reservation from using those\n    reserved resources rather than forcing jobs requesting the reservation to\n    use those resources in the time frame reserved.\n -- Add NoDecay flag to QOS.\n -- Node \"OS\" field expanded from \"sysname\" to \"sysname release version\" (e.g.\n    change from \"Linux\" to\n    \"Linux 4.8.0-28-generic #28-Ubuntu SMP Sat Feb 8 09:15:00 UTC 2017\").\n -- jobcomp/elasticsearch - Add \"job_name\" and \"wc_key\" fields to stored\n    information.\n -- jobcomp/filetxt - Add ArrayJobId, ArrayTaskId, ReservationName, Gres,\n    Account, QOS, WcKey, Cluster, SubmitTime, EligibleTime, DerivedExitCode and\n    ExitCode.\n -- scontrol modified to report core IDs for reservation containing individual\n    cores.\n -- MYSQL - Get rid of table join during rollup which speeds up the process\n    dramatically on large job/step tables.\n -- Add ability to define features on clusters for directing federated jobs to\n    different clusters.\n -- Add new RPC to process multiple federation RPCs in a single communication.\n -- Modify slurm_load_jobs() function to load job information from all clusters\n    in a federation.\n -- Add squeue --local and --sibling options to modify filtering of jobs on\n    federated clusters.\n -- Add SchedulerParameters option of bf_max_job_user_part to specify the\n    maximum number of jobs per user for any single partition. This differs from\n    bf_max_job_user in that a separate counter is applied to each partition\n    rather than having a single counter per user applied to all partitions.\n -- Modify backfill logic so that bf_max_job_user, bf_max_job_part and\n    bf_max_job_user_part options can all be used independently of each other.\n -- Add sprio -p/--partition option to filter jobs by partition name.\n -- Add partition name to job priority factor response message.\n -- Add sprio --local and --sibling options for use in federation of clusters.\n -- Add sprio \"%c\" format to print cluster name in federation mode.\n -- Modify sinfo logic to provided unified view of all nodes and partitions\n    in a federation, add --local option to only report local state information\n    even in a cluster, print cluster name with \"%V\" format option, and\n    optionally sort by cluster name.\n -- If a task in a parallel job fails and it was launched with the\n    --kill-on-bad-exit option then terminate the remaining tasks using the\n    SIGCONT, SIGTERM and SIGKILL signals rather than just sending SIGKILL.\n -- Include submit_time when doing the sort for job scheduling.\n -- Modify sacct to report all jobs in federation by default. Also add --local\n    option.\n -- Modify sacct to accept \"--cluster all\" option (in addition to the old\n    \"--cluster -1\", which is still accepted).\n -- Modify sreport to report all jobs in federation by default. Also add --local\n    option.\n -- sched/backfill: Improve assoc_limit_stop configuration parameter support.\n -- KNL features: Always keep active and available features in the same order:\n    first site-specific features, next MCDRAM modes, last NUMA modes.\n -- Changed default ProctrackType to cgroup.\n -- Add \"cluster_name\" field to node_info_t and partition_info_t data structure.\n    It is filled in only when the cluster is part of a federation and\n    SHOW_FEDERATION flag used.\n -- Functions slurm_load_node() slurm_load_partitions() modified to show all\n    nodes/partitions in a federation when the SHOW_FEDERATION flag is used.\n -- Add federated views to sview.\n -- Add --federation option to sacct, scontrol, sinfo, sprio, squeue, sreport to\n    show a federated view. Will show local view by default.\n -- Add FederationParameters=fed_display slurm.conf option to configure status\n    commands to display a federated view by default if the cluster is a member\n    of a federation.\n -- Log the down nodes whenever slurmctld restarts.\n -- Report that \"CPUs\" plus \"Boards\" in node configuration invalid only if the\n    CPUs value is not equal to the total thread count.\n -- Extend the output of the seff utility to also include the job's wall-clock\n    time.\n -- Add bf_max_time to SchedulerParameters.\n -- Add bf_max_job_assoc to SchedulerParameters.\n -- Add new SchedulerParameters option bf_window_linear to control the rate at\n    which the backfill test window expands. This can be used on a system with\n    a modest number of running jobs (hundreds of jobs) to help prevent expected\n    start times of pending jobs to get pushed forward in time. On systems with\n    large numbers of running jobs, performance of the backfill scheduler will\n    suffer and fewer jobs will be evaluated.\n -- Improve scheduling logic with respect to license use and node reboots.\n -- CRAY - Alter algorithm to come up with the SLURM_ID_HASH.\n -- Implement federated scheduling and federated status outputs.\n -- The '-q' option to srun has changed from being the short form of\n    '--quit-on-interrupt' to '--qos'.\n -- Change sched_min_interval default from 0 to 2 microseconds.\n\n* Changes in Slurm 17.02.12\n==========================\n -- Fix segfault in slurmdbd hourly rollup when having a job outside a\n    reservation, with no end_time set, from an assoc that's in a reservation.\n\n* Changes in Slurm 17.02.11\n==========================\n -- Fix insecure handling of user_name and gid fields. CVE-2018-10995.\n\n* Changes in Slurm 17.02.10\n==========================\n -- Fix updating of requested TRES memory.\n -- Cray modulefile: avoid removing /usr/bin from path on module unload.\n -- Fix issue when resetting the partition pointers on nodes.\n -- Show reason field in 'sinfo -R' when nodes is marked as failed.\n -- Fix potential of slurmstepd segfaulting when the extern step fails to start.\n -- Allow nodes state to be updated between FAIL and DRAIN.\n -- Avoid registering a job'd credential multiple times.\n -- Fix sbatch --wait to stop waiting after job is gone from memory.\n -- Fix memory leak of MailDomain configuration string when slurmctld daemon is\n    reconfigured.\n -- Fix to properly remove extern steps from the starting_steps list.\n -- Fix Slurm to work correctly with HDF5 1.10+.\n -- Add support in salloc/srun --bb option for \"access_mode\" in addition to\n    \"access\" for consistency with DW options.\n -- Fix potential deadlock in _run_prog() in power save code.\n -- MYSQL - Add dynamic_offset in the database to force range for auto\n    increment ids for the tres_table.\n -- Avoid setting node in COMPLETING state indefinitely if the job initiating\n    the node reboot is cancelled while the reboot in in progress.\n -- node_feature/knl_cray - Fix memory leaks that occur when slurmctld\n    reconfigured.\n -- node_feature/knl_cray - Fix memory leak that can occur during normal\n    operation.\n -- Fix job array dependency with \"aftercorr\" option and some task arrays in\n    the first job fail. This fix lets all task array elements that can run\n    proceed rather than stopping all subsequent task array elements.\n -- Fix whole node allocation cpu counts when --hint=nomultihtread.\n -- NRT - Fix issue when running on a HFI (p775) system with multiple protocols.\n -- Fix uninitialized variables when unpacking slurmdb_archive_cond_t.\n -- Fix security issue in accounting_storage/mysql plugin by always escaping\n    strings within the slurmdbd. CVE-2018-7033.\n\n* Changes in Slurm 17.02.9\n==========================\n -- When resuming powered down nodes, mark DOWN nodes right after ResumeTimeout\n    has been reached (previous logic would wait about one minute longer).\n -- Fix sreport not showing full column name for TRES Count.\n -- Fix slurmdb_reservations_get() giving wrong usage data when job's spanned\n    reservation that was modified.\n -- Fix sreport reservation utilization report showing bad data.\n -- Show all TRES' on a reservation in sreport reservation utilization report by\n    default.\n -- Fix sacctmgr show reservation handling \"end\" parameter.\n -- Work around issue with sysmacros.h and gcc7 / glibc 2.25.\n -- Fix layouts code to only allow setting a boolean.\n -- Fix sbatch --wait to keep waiting even if a message timeout occurs.\n -- CRAY - If configured with NodeFeatures=knl_cray and there are non-KNL\n    nodes which include no features the slurmctld will abort without\n    this patch when attempting strtok_r(NULL).\n -- Fix regression in 17.02.7 which would run the spank_task_privileged as\n    part of the slurmstepd instead of it's child process.\n -- Fix security issue in Prolog and Epilog by always prepending SPANK_ to\n    all user-set environment variables. CVE-2017-15566.\n\n* Changes in Slurm 17.02.8\n==========================\n -- Add 'slurmdbd:' to the accounting plugin to notify message is from dbd\n    instead of local.\n -- mpi/mvapich - Buffer being only partially cleared. No failures observed.\n -- Fix for job --switch option on dragonfly network.\n -- In salloc with --uid option, drop supplementary groups before changing UID.\n -- jobcomp/elasticsearch - strip any trailing slashes from JobCompLoc.\n -- jobcomp/elasticsearch - fix memory leak when transferring generated buffer.\n -- Prevent slurmstepd ABRT when parsing gres.conf CPUs.\n -- Fix sbatch --signal to signal all MPI ranks in a step instead of just those\n    on node 0.\n -- Check multiple partition limits when scheduling a job that were previously\n    only checked on submit.\n -- Cray: Avoid running application/step Node Health Check on the external\n    job step.\n -- Optimization enhancements for partition based job preemption.\n -- Address some build warnings from GCC 7.1, and one possible memory leak if\n    /proc is inaccessible.\n -- If creating/altering a core based reservation with scontrol/sview on a\n    remote cluster correctly determine the select type.\n -- Fix autoconf test for libcurl when clang is used.\n -- Fix default location for cgroup_allowed_devices_file.conf to use correct\n    default path.\n -- Document NewName option to sacctmgr.\n -- Reject a second PMI2_Init call within a single step to prevent slurmstepd\n    from hanging.\n -- Handle old 32bit values stored in the database for requested memory\n    correctly in sacct.\n -- Fix memory leaks in the task/cgroup plugin when constraining devices.\n -- Make extremely verbose info messages debug2 messages in the task/cgroup\n    plugin when constraining devices.\n -- Fix issue that would deny the stepd access to /dev/null where GRES has a\n    'type' but no file defined.\n -- Fix issue where the slurmstepd would fatal on job launch if you have no\n    gres listed in your slurm.conf but some in gres.conf.\n -- Fix validating time spec to correctly validate various time formats.\n -- Make scontrol work correctly with job update timelimit [+|-]=.\n -- Reduce the visibility of a number of warnings in _part_access_check.\n -- Prevent segfault in sacctmgr if no association name is specified for\n    an update command.\n -- burst_buffer/cray plugin modified to work with changes in Cray UP05\n    software release.\n -- Fix job reasons for jobs that are violating assoc MaxTRESPerNode limits.\n -- Fix segfault when unpacking a 16.05 slurm_cred in a 17.02 daemon.\n -- Fix setting TRES limits with case insensitive TRES names.\n -- Add alias for xstrncmp() -- slurm_xstrncmp().\n -- Fix sorting of case insensitive strings when using xstrcasecmp().\n -- Gracefully handle race condition when reading /proc as process exits.\n -- Avoid error on Cray duplicate setup of core specialization.\n -- Skip over undefined (hidden in Slurm) nodes in pbsnodes.\n -- Add empty hashes in perl api's slurm_load_node() for hidden nodes.\n -- CRAY - Add rpath logic to work for the alpscomm libs.\n -- Fixes for administrator extended TimeLimit (job reason & time limit reset).\n -- Fix gres selection on systems running select/linear.\n -- sview: Added window decorator for maximize,minimize,close buttons for all\n    systems.\n -- squeue: interpret negative length format specifiers as a request to\n    delimit values with spaces.\n -- Fix the torque pbsnodes wrapper script to parse a gres field with a type\n    set correctly.\n\n* Changes in Slurm 17.02.7\n==========================\n -- Fix deadlock if requesting to create more than 10000 reservations.\n -- Fix potential memory leak when creating partition name.\n -- Execute the HealthCheckProgram once when the slurmd daemon starts rather\n    than executing repeatedly until an exit code of 0 is returned.\n -- Set job/step start and end times to 0 when using --truncate and start > end.\n -- Make srun --pty option ignore EINTR allowing windows to resize.\n -- When resuming node only send one message to the slurmdbd.\n -- Modify srun --pty option to use configured SrunPortRange range.\n -- Fix issue with whole gres not being printed out with Slurm tools.\n -- Fix issue with multiple jobs from an array are prevented from starting.\n -- Fix for possible slurmctld abort with use of salloc/sbatch/srun\n    --gres-flags=enforce-binding option.\n -- Fix race condition when using jobacct_gather/cgroup where the memory of the\n    step wasn't always gathered correctly.\n -- Better debug when slurmdbd queue is filling up in the slurmctld.\n -- Fixed truncation on scontrol show config output.\n -- Serialize updates from from the dbd to the slurmctld.\n -- Fix memory leak in slurmctld when agent queue to the DBD has filled up.\n -- CRAY - Throttle step creation if trying to create too many steps at once.\n -- If failing after switch_g_job_init happened make sure switch_g_job_fini is\n    called.\n -- Fix minor memory leak if launch fails in the slurmstepd.\n -- Fix issue where UnkillableStepProgram if step was in an ending state.\n -- Fix bug when tracking multiple simultaneous spawned ping cycles.\n -- jobcomp/elasticsearch plugin now saves state of pending requests on\n    slurmctld daemon shutdown so then can be recovered on restart.\n -- Fix issue when an alternate munge key when communicating on a persistent\n    connection.\n -- Document inconsistent behavior of GroupUpdateForce option.\n -- Fix bug in selection of GRES bound to specific CPUs where the GRES count\n    is 2 or more. Previous logic could allocate CPUs not available to the job.\n -- Increase buffer to handle long /proc/<pid>/stat output so that Slurm can\n    read correct RSS value and take action on jobs using more memory than\n    requested.\n -- Fix srun job jobs that can run immediately to run in the highest priority\n    partition when multiple partitions are listed. scontrol show jobs can\n    potentially show the partition list in priority order.\n -- Fix starting controller if StateSaveLocation path didn't exist.\n -- Fix inherited association 'max' TRES limits combining multiple limits in\n    the tree.\n -- Sort TRES id's on limits when getting them from the database.\n -- Fix issue with pmi[2|x] when TreeWidth=1.\n -- Correct buffer size used in determining specialized cores to avoid possible\n    truncation of core specification and not reserving the specified cores.\n -- Close race condition on Slurm structures when setting DebugFlags.\n -- Make it so the cray/switch plugin grabs new DebugFlags on a reconfigure.\n -- Fix incorrect lock levels when creating or updating a reservation.\n -- Fix overlapping reservation resize.\n -- Add logic to help support Dell KNL systems where syscfg is different than\n    the normal Intel syscfg.\n -- CRAY - Fix BB to handle type= correctly, regression in 17.02.6.\n\n* Changes in Slurm 17.02.6\n==========================\n -- Fix configurator.easy.html to output the SelectTypeParameters line.\n -- If a job requests a specific memory requirement then gets something else\n    from the slurmctld make sure the step allocation is made aware of it.\n -- Fix missing initialization in slurmd.\n -- Fix potential degradation when running HTC (> 100 jobs a sec) like\n    workflows through the slurmd.\n -- Fix race condition which could leave a stepd hung on shutdown.\n -- CRAY - Add configuration for ATP to the ansible play script.\n -- Fix potential to corrupt DBD message.\n -- burst_buffer logic modified to support sizes in both SI and EIC size units\n    (e.g. M/MiB for powers of 1024, MB for powers of 1000).\n\n* Changes in Slurm 17.02.5\n==========================\n -- Prevent segfault if a job was blocked from running by a QOS that is then\n    deleted.\n -- Improve selection of jobs to preempt when there are multiple partitions\n    with jobs subject to preemption.\n -- Only set kmem limit when ConstrainKmemSpace=yes is set in cgroup.conf.\n -- Fix bug in task/affinity that could result in slurmd fatal error.\n -- Increase number of jobs that are tracked in the slurmd as finishing at one\n    time.\n -- Note when a job finishes in the slurmd to avoid a race when launching a\n    batch job takes longer than it takes to finish.\n -- Improve slurmd startup on large systems (> 10000 nodes)\n -- Add LaunchParameters option of cray_net_exclusive to control whether all\n    jobs on the cluster have exclusive access to their assigned nodes.\n -- Make sure srun inside an allocation gets --ntasks-per-[core|socket]\n    set correctly.\n -- Only make the extern step at job creation.\n -- Fix for job step task layout with --cpus-per-task option.\n -- Fix --ntasks-per-core option/environment variable parsing to set\n    the requested value, instead of always setting one (srun).\n -- Correct error message when ClusterName in configuration files does not match\n    the name in the slurmctld daemon's state save file.\n -- Better checking when a job is finishing to avoid underflow on job's\n    submitted to a QOS/association.\n -- Handle partition QOS submit limits correctly when a job is submitted to\n    more than 1 partition or when the partition is changed with scontrol.\n -- Performance boost for when Slurm is dealing with credentials.\n -- Fix race condition which could leave a stepd hung on shutdown.\n -- Add lua support for opensuse.\n\n* Changes in Slurm 17.02.4\n==========================\n -- Do not attempt to schedule jobs after changing the power cap if there are\n    already many active threads.\n -- Job expansion example in FAQ enhanced to demonstrate operation in\n    heterogeneous environments.\n -- Prevent scontrol crash when operating on array and no-array jobs at once.\n -- knl_cray plugin: Log incomplete capmc output for a node.\n -- knl_cray plugin: Change capmc parsing of mcdram_pct from string to number.\n -- Remove log files from test20.12.\n -- When rebooting a node and using the PrologFlags=alloc make sure the\n    prolog is ran after the reboot.\n -- node_features/knl_generic - If a node is rebooted for a pending job, but\n    fails to enter the desired NUMA and/or MCDRAM mode then drain the node and\n    requeue the job.\n -- node_features/knl_generic disable mode change unless RebootProgram\n    configured.\n -- Add new burst_buffer function bb_g_job_revoke_alloc() to be executed\n    if there was a failure after the initial resource allocation. Does not\n    release previously allocated resources.\n -- Test if the node_bitmap on a job is NULL when testing if the job's nodes\n    are ready.  This will be NULL is a job was revoked while beginning.\n -- Fix incorrect lock levels when testing when job will run or updating a job.\n -- Add missing locks to job_submit/pbs plugin when updating a jobs\n    dependencies.\n -- Add support for lua5.3\n -- Add min_memory_per_node|cpu to the job_submit/lua plugin to deal with lua\n    not being able to deal with pn_min_memory being a uint64_t.  Scripts are\n    urged to change to these new variables avoid issue.  If not set the\n    variables will be 'nil'.\n -- Calculate priority correctly when 'nice' is given.\n -- Fix minor typos in the documentation.\n -- node_features/knl_cray: Preserve non-KNL active features if slurmctld\n    reconfigured while node boot in progress.\n -- node_features/knl_generic: Do not repeatedly log errors when trying to read\n    KNL modes if not KNL system.\n -- Add missing QOS read lock to backfill scheduler.\n -- When doing a dlopen on liblua only attempt the version compiled against.\n -- Fix null-dereference in sreport cluster ulitization when configured with\n    memory-leak-debug.\n -- Fix Partition info in 'scontrol show node'. Previously duplicate partition\n    names, or Partitions the node did not belong to could be displayed.\n -- Fix it so the backup slurmdbd will take control correctly.\n -- Fix unsafe use of MAX() macro, which could result in problems cleaning up\n    accounting plugins in slurmd, or repeat job cancellation attempts in\n    scancel.\n -- Fix 'scontrol update reservation duration=unlimited' to set the duration\n    to 365-days (as is done elsewhere), rather than 49710 days.\n -- Check if variable given to scontrol show job is a valid jobid.\n -- Fix WithSubAccounts option to not include WithDeleted unless requested.\n -- Prevent a job tested on multiple partitions from being marked\n    WHOLE_NODE_USER.\n -- Prevent a race between completing jobs on a user-exclusive node from\n    leaving the node owned.\n -- When scheduling take the nodes in completing jobs out of the mix to reduce\n    fragmentation.  SchedulerParameters=reduce_completing_frag\n -- For jobs submitted to multiple partitions, report the job's earliest start\n    time for any partition.\n -- Backfill partitions that use QOS Grp limits to \"float\" better.\n -- node_features/knl_cray: don't clear configured GRES from non-KNL node.\n -- sacctmgr - prevent segfault in command when a request is denied due\n    to a insufficient privileges.\n -- Add warning about libcurl-devel not being installed during configure.\n -- Streamline job purge by handling file deletion on a separate thread.\n -- Always set RLIMIT_CORE to the maximum permitted for slurmd, to ensure\n    core files are created even on non-developer builds.\n -- Fix --ntasks-per-core option/environment variable parsing to set\n    the requested value, instead of always setting one.\n -- If trying to cancel a step that hasn't started yet for some reason return\n    a good return code.\n -- Fix issue with sacctmgr show where user=''\n\n* Changes in Slurm 17.02.3\n==========================\n -- Increase --cpu_bind and --mem_bind field length limits.\n -- Fix segfault when using AdminComment field with job arrays.\n -- Clear Dependency field when all dependencies are satisfied.\n -- Add --array-unique to squeue which will display one unique pending job\n    array element per line.\n -- Reset backfill timers correctly without skipping over them in certain\n    circumstances.\n -- When running the \"scontrol top\" command, make sure that all of the user's\n    jobs have a priority that is lower than the selected job. Previous logic\n    would permit other jobs with equal priority (no jobs with higher priority).\n -- Fix perl api so we always get an allocation when calling Slurm::new().\n -- Fix issue with cleaning up cpuset and devices cgroups when multiple steps\n    end at the same time.\n -- Document that PriorityFlags option of DEPTH_OBLIVIOUS precludes the use of\n    FAIR_TREE.\n -- Fix issue if an invalid message came in a Slurm daemon/command may abort.\n -- Make it impossible to use CR_CPU* along with CR_ONE_TASK_PER_CORE. The\n    options are mutually exclusive.\n -- ALPS - Fix scheduling when ALPS doesn't agree with Slurm on what nodes\n    are free.\n -- When removing a partition make sure it isn't part of a reservation.\n -- Fix seg fault if loading attempting to load non-existent burstbuffer plugin.\n -- Fix to backfill scheduling with respect to QOS and association limits. Jobs\n    submitted to multiple partitions are most likely to be effected.\n -- sched/backfill: Improve assoc_limit_stop configuration parameter support.\n -- CRAY - Add ansible play and README.\n -- sched/backfill: Fix bug related to advanced reservations and the need to\n    reboot nodes to change KNL mode.\n -- Preempt plugins - fix check for 'preempt_youngest_first' option.\n -- Preempt plugins - fix incorrect casts in preempt_youngest_first mode.\n -- Preempt/job_prio - fix incorrect casts in sort function.\n -- Fix to make task/affinity work with ldoms where there are more than 64\n    cpus on the node.\n -- When using node_features/knl_generic make it so the slurmd doesn't segfault\n    when shutting down.\n -- Fix potential double-xfree() when using job arrays that can lead to\n    slurmctld crashing.\n -- Fix priority/multifactor priorities on a slurmctld restart if not using\n    accounting_storage/[mysql|slurmdbd].\n -- Fix NULL dereference reported by CLANG.\n -- Update proctrack documentation to strongly encourage use of\n    proctrack/cgroup.\n -- Fix potential memory leak if job fails to begin after nodes have been\n    selected for a job.\n -- Handle a job that made it out of the select plugin without a job_resrcs\n    pointer.\n -- Fix potential race condition when persistent connections are being closed at\n    shutdown.\n -- Fix incorrect locks levels when submitting a batch job or updating a job\n    in general.\n -- CRAY - Move delay waiting for job cleanup to after we check once.\n -- MYSQL - Fix memory leak when loading archived jobs into the database.\n -- Fix potential race condition when starting the priority/multifactor plugin's\n    decay thread.\n -- Sanity check to make sure we have started a job in acct_policy.c before we\n    clear it as started.\n -- Allow reboot program to use arguments.\n -- Message Aggr - Remove race condition on slurmd shutdown with respects to\n    destroying a mutex.\n -- Fix updating job priority on multiple partitions to be correct.\n -- Don't remove admin comment when updating a job.\n -- Return error when bad separator is given for scontrol update job licenses.\n\n* Changes in Slurm 17.02.2\n==========================\n -- Update hyperlink to LBNL Node Health Check program.\n -- burst_buffer/cray - Add support for line continuation.\n -- If a job is cancelled by the user while it's allocated nodes are being\n    reconfigured (i.e. the capmc_resume program is rebooting nodes for the job)\n    and the node reconfiguration fails (i.e. the reboot fails), then don't\n    requeue the job but leave it in a cancelled state.\n -- capmc_resume (Cray resume node script) - Do not disable changing a node's\n    active features if SyscfgPath is configured in the knl.conf file.\n -- Improve the srun documentation for the --resv-ports option.\n -- burst_buffer/cray - Fix parsing for discontinuous allocated nodes. A job\n    allocation of \"20,22\" must be expressed as \"20\\n22\".\n -- Fix rare segfault when shutting down slurmctld and still sending data to\n    the database.\n -- Fix gres output of a job if it is updated while pending to be displayed\n    correctly with Slurm tools.\n -- Fix pam_slurm_adopt.\n -- Fix missing unlock when job_list doesn't exist when starting priority/\n    multifactor.\n -- Fix segfault if slurmctld is shutting down and the slurmdbd plugin was\n    in the middle of setting db_indexes.\n -- Add ESLURM_JOB_SETTING_DB_INX to errno to note when a job can't be updated\n    because the dbd is setting a db_index.\n -- Fix possible double insertion into database when a job is updated at the\n    moment the dbd is assigning a db_index.\n -- Fix memory error when updating a job's licenses.\n -- Fix seff to work correctly with non-standard perl installs.\n -- Export missing slurmdbd_defs_[init|fini] needed for libslurmdb.so to work.\n -- Fix sacct from returning way more than requested when querying against a job\n    array task id.\n -- Fix double read lock of tres when updating gres or licenses on a job.\n -- Make sure locks are always in place when calling\n    assoc_mgr_make_tres_str_from_array.\n -- Prevent slurmctld SEGV when creating reservation with duplicated name.\n -- Consider QOS flags Partition[Min|Max]Nodes when doing backfill.\n -- Fix slurmdbd_defs.c to not have half symbols go to libslurm.so and the\n    other half go to libslurmdb.so.\n -- Fix 'scontrol show jobs' to remove an errant newline when 'Switches' is\n    printed.\n -- Better code for handling memory required by a task on a heterogeneous\n    system.\n -- Fix regression in 17.02.0 with respects to GrpTresMins on a QOS or\n    Association.\n -- Cleanup to make make dist work.\n -- Schedule interactive jobs quicker.\n -- Perl API - correct value of MEM_PER_CPU constant to correctly handle\n    memory values.\n -- Fix 'flags' variable to be 32 bit from the old 16 bit value in the perl api.\n -- Export sched_nodes for a job in the perl api.\n -- Improve error output when updating a reservation that has already started.\n -- Fix --ntasks-per-node issue with srun so DenyOnLimit would work correctly.\n -- node_features/knl_cray plugin - Fix memory leak.\n -- Fix wrong cpu_per_task count issue on heterogeneous system when dealing with\n    steps.\n -- Fix double free issue when removing usage from an association with sacctmgr.\n -- Fix issue with SPANK plugins attempting to set null values as environment\n    variables, which leads to the command segfaulting on newer glibc versions.\n -- Fix race condition on slurmctld startup when plugins have not gone through\n    init() ahead of the rpc_manager processing incoming messages.\n -- job_submit/lua - expose admin_comment field.\n -- Allow AdminComment field to be set by the job_submit plugin.\n -- Allow AdminComment field to be changed by any Administrator.\n -- Fix key words in jobcomp select.\n -- MYSQL - Streamline job flush sql when doing a clean start on the slurmctld.\n -- Fix potential infinite loop when talking to the DBD when shutting down\n    the slurmctld.\n -- Fix MCS filter.\n -- Make it so pmix can be included in the plugin rpm without having to\n    specify --with-pmix.\n -- MYSQL - Fix initial load when not using he DBD.\n -- Fix scontrol top to not make jobs priority 0 (held).\n -- Downgrade info message about exceeding partition time limit to a debug2.\n\n* Changes in Slurm 17.02.1-2\n============================\n -- Replace clock_gettime with time(NULL) for very old systems without the call.\n\n* Changes in Slurm 17.02.1\n==========================\n -- Modify pam module to work when configured NodeName and NodeHostname differ.\n -- Update to sbatch/srun man pages to explain the \"filename pattern\" clearer\n -- Add %x to sbatch/srun filename pattern to represent the job name.\n -- job_submit/lua - Add job \"bitflags\" field.\n -- Update slurm.spec file to note obsolete RPMs.\n -- Fix deadlock scenario when dumping configuration in the slurmctld.\n -- Remove unneeded job lock when running assoc_mgr cache.  This lock could\n    cause potential deadlock when/if TRES changed in the database and the\n    slurmctld wasn't made aware of the change.  This would be very rare.\n -- Fix missing locks in gres logic to avoid potential memory race.\n -- If gres is NULL on a job don't try to process it when returning detailed\n    information about a job to scontrol.\n -- Fix print of consumed energy in sstat when no energy is being collected.\n -- Print formatted tres string when creating/updating a reservation.\n -- Fix issues with QOS flags Partition[Min|Max]Nodes to work correctly.\n -- Prevent manipulation of the cpu frequency and governor for batch or\n    extern steps. This addresses an issue where the batch step would\n    inadvertently set the cpu frequency maximum to the minimum value\n    supported on the node.\n -- Convert a slurmctd power management data structure from array to list in\n    order to eliminate the possibility of zombie child suspend/resume\n    processes.\n -- Burst_buffer/cray - Prevent slurmctld daemon abort if \"paths\" operation\n    fails. Now job will be held. Update job update time when held.\n -- Fix issues with QOS flags Partition[Min|Max]Nodes to work correctly.\n -- Refactor slurmctld agent logic to eliminate some pthreads.\n -- Added \"SyscfgTimeout\" parameter to knl.conf configuration file.\n -- Fix for CPU binding for job steps run under a batch job.\n\n* Changes in Slurm 17.02.0\n==========================\n -- job_submit/lua - Make \"immediate\" parameter available.\n -- Fix srun I/O race condition to eliminate a error message that might be\n    generated if the application exits with outstanding stdin.\n -- Fix regression when purging/archiving jobs/events.\n -- Add new job state JOB_OOM indicating Out Of Memory condition as detected\n    by task/cgroup plugin.\n -- If QOS has been added to the system go refigure out Deny/AllowQOS on\n    partitions.\n -- Deny job with duplicate GRES requested.\n -- Fix loading super old assoc_mgr usage without segfaulting.\n -- CRAY systems: Restore TaskPlugins order of task/cray before task/cgroup.\n -- Task/cray: Treat missing \"mems\" cgroup with \"debug\" messages rather than\n    \"error\" messages. The file may be missing at step termination due to a\n    change in how cgroups are released at job/step end.\n -- Fix for job constraint specification with counts, --ntasks-per-node value,\n    and no node count.\n -- Fix ordering of step task allocation to fill in a socket before going into\n    another one.\n -- Fix configure to not require C++\n -- job_submit/lua - Remove access to slurmctld internal reservation fields of\n    job_pend_cnt and job_run_cnt.\n -- Prevent job_time_limit enforcement from blocking other internal operations\n    if a large number of jobs need to be cancelled.\n -- Add 'preempt_youngest_order' option to preempt/partition_prio plugin.\n -- Fix controller being able to talk to a pre-released DBD.\n -- Added ability to override the invoking uid for \"scontrol update job\"\n    by specifying \"--uid=<uid>|-u <uid>\".\n -- Changed file broadcast \"offset\" from 32 to 64 bits in order to support files\n    over 2 GB.\n -- slurm.spec - do not install init scripts alongside systemd service files.\n\n* Changes in Slurm 17.02.0rc1\n==============================\n -- Add port info to 'sinfo' and 'scontrol show node'.\n -- Fix errant definition of USE_64BIT_BITSTR which can lead to core dumps.\n -- Move BatchScript to end of each job's information when using\n    \"scontrol -dd show job\" to make it more readable.\n -- Add SchedulerParameters configuration parameter of \"default_gbytes\", which\n    treats numeric only (no suffix) value for memory and tmp disk space as being\n    in units of Gigabytes. Mostly for compatibility with LSF.\n -- Fix race condition in srun/sattach logic which would prevent srun from\n    terminating.\n -- Bitstring operations are now 64bit instead of 32bit.\n -- Replace hweight() function in bitstring with faster version.\n -- scancel would treat a non-numeric argument as the name of jobs to be\n    cancelled (a non-documented feature). Cancelling jobs by name now require\n    the \"--jobname=\" command line argument.\n -- scancel modified to note that no jobs satisfy the filter options when the\n    --verbose option is used along with one or more job filters (e.g. \"--qos=\").\n -- Change _pack_cred to use pack_bit_str_hex instead of pack_bit_fmt for\n    better scalability and performance.\n -- Add BootTime configuration parameter to knl.conf file to optimize resource\n    allocations with respect to required node reboots.\n -- Add node_features_p_boot_time() to node_features plugin to optimize\n    scheduling with respect to node reboots.\n -- Avoid allocating resources to a job in the event that its run time plus boot\n    time (if needed) extent into an advanced reservation.\n -- Burst_buffer/cray - Avoid stage-out operation if job never started.\n -- node_features/knl_cray - Add capability to detected Uncorrectable Memory\n    Errors (UME) and if detected then log the event in all job and step stderr\n    with a message of the form:\n    error: *** STEP 1.2 ON tux1 UNCORRECTABLE MEMORY ERROR AT 2016-12-14T09:09:37 ***\n    Similar logic added to node_features/knl_generic in version 17.02.0pre4.\n -- If job is allocated nodes which are powered down, then reset job start time\n    when the nodes are ready and do not charge the job for power up time.\n -- Add the ability to purge transactions from the database.\n -- Add support for requeue'ing of federated jobs (BETA).\n -- Add support for interactive federated jobs (BETA).\n -- Add the ability to purge rolled up usage from the database.\n -- Properly set SLURM_JOB_GPUS environment variable for Prolog.\n\n* Changes in Slurm 17.02.0pre4\n==============================\n -- Add support for per-partitiion OverTimeLimit configuration.\n -- Add --mem_bind option of \"sort\" to run zonesort on KNL nodes at step start.\n -- Add LaunchParameters=mem_sort option to configure running of zonesort\n    by default at step startup.\n -- Add \"FreeSpace\" information for each pool to the \"scontrol show burstbuffer\"\n    output. Required changes to the burst_buffer_info_t data structure.\n -- Add new node state flag of NODE_STATE_REBOOT for node reboots triggered by\n    \"scontrol reboot\" commands. Previous logic re-used NODE_STATE_MAINT flag,\n    which could lead to inconsistencies. Add \"ASAP\" option to \"scontrol reboot\"\n    command that will drain a node in order to reboot it as soon as possible,\n    then return it to service.\n -- Allow unit conversion routine to convert 1024M to 1G.\n -- switch/cray plugin - change legacy spool directory location.\n -- Add new PriorityFlags option of INCR_ONLY, which prevents a job's priority\n    from being decremented.\n -- Make it so we don't purge job start messages until after we purge step\n    messages.  Hopefully this will reduce the number of messages lost when\n    filling up memory when the database/DBD is down.\n -- Added SchedulingParameters option of \"bf_job_part_count_reserve\". Jobs below\n    the specified threshold will not have resources reserved for them.\n -- If GRES are configured with file IDs, then \"scontrol -d show node\" will\n    not only identify the count of currently allocated GRES, but their specific\n    index numbers (e.g. \"GresUsed=gpu:alpha:2(IDX:0,2),gpu:beta:0(IDX:N/A)\").\n    Ditto for job information with \"scontrol -d show job\".\n -- Add new mcs/account plugin.\n -- Add \"GresEnforceBind=Yes\" to \"scontrol show job\" output if so configured.\n -- Add support for SALLOC_CONSTRAINT, SBATCH_CONSTRAINT and SLURM_CONSTRAINT\n    environment variables to set default constraints for salloc, sbatch and\n    srun commands respectively.\n -- Provide limited support for the MemSpecLimit configuration parameter without\n    the task/cgroup plugin.\n -- node_features/knl_generic - Add capability to detected Uncorrectable Memory\n    Errors (UME) and if detected then log the event in all job and step stderr\n    with a message of the form:\n    error: *** STEP 1.2 ON tux1 UNCORRECTABLE MEMORY ERROR AT 2016-12-14T09:09:37 ***\n -- Add SLURM_JOB_GID to TaskProlog environment.\n -- burst_buffer/cray - Remove leading zeros from node ID lists passed to\n    dw_wlm_cli program.\n -- Add \"Partitions\" field to \"scontrol show node\" output.\n -- Remove sched/wiki and sched/wiki2 plugins and associated code.\n -- Remove SchedulerRootFilter option and slurm_get_root_filter() API call.\n -- Add SchedulerParameters option of spec_cores_first to select specialized\n    cores from the lowest rather than highest number cores and sockets.\n -- Add PrologFlags option of Serial to disable concurrent launch of\n    Prolog and Epilog scripts.\n -- Fix security issue caused by insecure file path handling triggered by the\n    failure of a Prolog script. To exploit this a user needs to anticipate or\n    cause the Prolog to fail for their job. CVE-2016-10030.\n\n* Changes in Slurm 17.02.0pre3\n==============================\n -- Add srun host & PID to job step data structures.\n -- Avoid creating duplicate pending step records for the same srun command.\n -- Rewrite srun's logic for pending steps for better efficiency (fewer RPCs).\n -- Added new SchedulerParameters options step_retry_count and step_retry_time\n    to control scheduling behaviour of job steps waiting for resources.\n -- Optimize resource allocation logic for --spread-job job option.\n -- Modify cpu_bind and mem_bind map and mask options to accept a repetition\n    count to better support large task count. For example:\n    \"mask_mem:0x0f*2,0xf0*2\" is equivalent to \"mask_mem:0x0f,0x0f,0xf0,0xf0\".\n -- Add support for --mem_bind=prefer option to prefer, but not restrict memory\n    use to the identified NUMA node.\n -- Add mechanism to constrain kernel memory allocation using cgroups. New\n    cgroup.conf parameters added: ConstrainKmemSpace, MaxKmemPercent, and\n    MinKmemSpace.\n -- Correct invocation of man2html, which previously could cause FreeBSD builds\n    to hang.\n -- MYSQL - Unconditionally remove 'ignore' clause from 'alter ignore'.\n -- Modify service files to not start Slurm daemons until after Munge has been\n    started.\n    NOTE: If you are not using Munge, but are using the \"service\" scripts to\n    start Slurm daemons, then you will need to remove this check from the\n    etc/slurm*service scripts.\n -- Do not process SALLOC_HINT, SBATCH_HINT or SLURM_HINT environment variables\n    if any of the following salloc, sbatch or srun command line options are\n    specified: -B, --cpu_bind, --hint, --ntasks-per-core, or --threads-per-core.\n -- burst_buffer/cray: Accept new jobs on backup slurmctld daemon without access\n    to dw_wlm_cli command. No burst buffer actions will take place.\n -- Do not include SLURM_JOB_DERIVED_EC, SLURM_JOB_EXIT_CODE, or\n    SLURM_JOB_EXIT_CODE in PrologSlurmctld environment (not available yet).\n -- Cray - set task plugin to fatal() if task/cgroup is not loaded after\n    task/cray in the TaskPlugin settings.\n -- Remove separate slurm_blcr package. If Slurm is built with BLCR support,\n    the files will now be part of the main Slurm packages.\n -- Replace sjstat, seff and sjobexit RPM packages with a single \"contribs\"\n    package.\n -- Remove long since defunct slurmdb-direct scripts.\n -- Add SbcastParameters configuration option to control default file\n    destination directory and compression algorithm.\n -- Add new SchedulerParameter (max_array_tasks) to limit the maximum number of\n    tasks in a job array independently from the maximum task ID (MaxArraySize).\n -- Fix issue where number of nodes is not properly allocated when sbatch and\n    salloc are requested with -n tasks < hosts from -w hostlist or from -N.\n -- Add infrastructure for submitting federated jobs.\n\n* Changes in Slurm 17.02.0pre2\n==============================\n -- Add new RPC (REQUEST_EVENT_LOG) so that slurmd and slurmstepd can log events\n    through the slurmctld daemon.\n -- Remove sbatch --bb option. That option was never supported.\n -- Automatically clean up task/cgroup cpuset and devices cgroups after steps\n    are completed.\n -- Add federation read/write locks.\n -- Limit job purge run time to 1 second at a time.\n -- The database index for jobs is now 64 bits.  If you happen to be close to\n    4 billion jobs in your database you will want to update your slurmctld at\n    the same time as your slurmdbd to prevent roll over of this variable as\n    it is 32 bit previous versions of Slurm.\n -- Optionally lock slurmstepd in memory for performance reasons and to avoid\n    possible SIGBUS if the daemon is paged out at the time of a Slurm upgrade\n    (changing plugins). Controlled via new LaunchParameters options of\n    slurmstepd_memlock and slurmstepd_memlock_all.\n -- Add event trigger on burst buffer errors (see strigger man page,\n    --burst_buffer option).\n -- Add job AdminComment field which can only be set by a Slurm administrator.\n -- Add salloc, sbatch and srun option of --delay-boot=<time>, which will\n    temporarily delay booting nodes into the desired state for a job in the\n    hope of using nodes already in the proper state which will be available at\n    a later time.\n -- Add job burst_buffer_state and delay_boot fields to scontrol and squeue\n    output. Also add ability to modify delay_boot from scontrol.\n -- Fix for node's available TRES array getting filled in with configured GRES\n    model types.\n -- Log if job --bb option contains any unrecognized content.\n -- Display configured and allocated TRES for nodes in scontrol show nodes.\n -- Change all memory values (in MB) to uint64_t to accommodate > 2TB per node.\n -- Add MailDomain configuration parameter to qualify email addresses.\n -- Refactor the persistent connections within the federation code to use\n    the same logic that was found in the slurmdbd.  Now both functionalities\n    share the same code.\n -- Remove BlueGene/L and BlueGene/P support.\n -- Add \"flag\" field to launch_tasks_request_msg. Remove the following fields\n    (moved into flags): multi_prog, task_flags, user_managed_io, pty,\n    buffered_stdio, and labelio.\n -- Add protocol version to slurmd startup communications for slurmstepd to\n    permit changes in the protocol.\n\n* Changes in Slurm 17.02.0pre1\n==============================\n -- burst_buffer/cray - Add support for rounding up the size of a buffer request\n    if the DataWarp configuration \"equalize_fragments\" is used.\n -- Remove AIX support.\n -- Rename \"in\" to \"input\" in slurm_step_io_fds data structure defined in\n    slurm.h. This is needed to avoid breaking Python with by using one of its\n    keywords in a Slurm data structure.\n -- Remove eligible_time from jobcomp/elasticsearch.\n -- Enable the deletion of a QOS, even if no clusters have been added to the\n    database.\n -- SlurmDBD - change all timestamps to bigint from int to solve Y2038 problem.\n -- Add salloc/sbatch/srun --spread-job option to distribute tasks over as many\n    nodes as possible. This also treats the --ntasks-per-node option as a\n    maximum value.\n -- Add ConstrainKmemSpace to cgroup.conf, defaulting to yes, to allow\n    cgroup Kmem enforcement to be disabled while still using ConstrainRAMSpace.\n -- Add support for sbatch --bbf option to specify a burst buffer input file.\n -- Added burst buffer support for job arrays. Add new SchedulerParameters\n    configuration parameter of bb_array_stage_cnt=# to indicate how many pending\n    tasks of a job array should be made available for burst buffer resource\n    allocation.\n -- Fix small memory leak when a job fails to load from state save.\n -- Fix invalid read when attempting to delete clusters from database with\n    running jobs.\n -- Fix small memory leak when deleting clusters from database.\n -- Add SLURM_ARRAY_TASK_COUNT environment variable. Total number of tasks in a\n    job array (e.g. \"--array=2,4,8\" will set SLURM_ARRAY_TASK_COUNT=3).\n -- Add new sacctmgr commands: \"shutdown\" (shutdown the server), \"list stats\"\n    (get server statistics) \"clear stats\" (clear server statistics).\n -- Restructure job accounting query to use 'id_job in (1, 2, .. )' format\n    instead of logically equivalent 'id_job = 1 || id_job = 2 || ..' .\n -- Added start_delay field to jobcomp/elasticsearch.\n -- In order to support federated jobs, the MaxJobID configuration parameter\n    default value has been reduced from 2,147,418,112 to 67,043,328 and its\n    maximum value is now 67,108,863. Upon upgrading, any pre-existing jobs that\n    have a job ID above the new range will continue to run and new jobs will get\n    job IDs in the new range.\n -- Added infrastructure for setting up federations in database and establishing\n    connections between federation clusters.\n\n* Changes in Slurm 16.05.12\n===========================\n\n* Changes in Slurm 16.05.11\n===========================\n -- burst_buffer/cray - Add support for line continuation.\n -- If a job is cancelled by the user while it's allocated nodes are being\n    reconfigured (i.e. the capmc_resume program is rebooting nodes for the job)\n    and the node reconfiguration fails (i.e. the reboot fails), then don't\n    requeue the job but leave it in a cancelled state.\n -- capmc_resume (Cray resume node script) - Do not disable changing a node's\n    active features if SyscfgPath is configured in the knl.conf file.\n -- Fix memory error when updating a job's licenses.\n -- Fix double read lock of tres when updating gres or licenses on a job.\n -- Fix regression in 16.05.10 with respects to GrpTresMins on a QOS or\n    Association.\n -- ALPS - Fix scheduling when ALPS doesn't agree with Slurm on what nodes\n    are free.\n -- Fix seg fault if loading attempting to load non-existent burstbuffer plugin.\n -- Fix to backfill scheduling with respect to QOS and association limits. Jobs\n    submitted to multiple partitions are most likely to be effected.\n -- Avoid erroneous errno set by the mariadb 10.2 api.\n -- Fix security issue in Prolog and Epilog by always prepending SPANK_ to\n    all user-set environment variables. CVE-2017-15566.\n\n* Changes in Slurm 16.05.10-2\n=============================\n -- Replace clock_gettime with time(NULL) for very old systems without the call.\n\n* Changes in Slurm 16.05.10\n===========================\n -- Record job state as PREEMPTED instead of TIMEOUT when GraceTime is reached.\n -- task/cgroup - print warnings to stderr when --cpu_bind=verbose is enabled\n    and the requested processor affinity cannot be set.\n -- power/cray - Disable power cap get and set operations on DOWN nodes.\n -- Jobs preempted with PreemptMode=REQUEUE were incorrectly recorded as\n    REQUEUED in the accounting.\n -- PMIX - Use volatile specifier to avoid flag caching and lock the flag to\n    make sure it is protected.\n -- PMIX/PMI2 - Make it possible to use %n or %h in a spool dir.\n -- burst_buffer/cray - Support default pool which is not the first pool\n    reported by DataWarp and log in Slurm when pools that are added or removed\n    from DataWarp.\n -- Insure job does not start running before PrologSlurmctld is complete and\n    node is booted (all nodes for interactive job, at least first node for batch\n    job without burst buffers).\n -- Fix minor memory leak in the slurmctld when removing a QOS.\n -- burst_buffer/cray - Do not execute \"pre_run\" operation until after all nodes\n    are booted and ready for use.\n -- scontrol - return an error when attempting to use the +=/-+ syntax to\n    update a field where this is not appropriate.\n -- Fix task/affinity to work correctly with --ntasks-per-socket.\n -- Honor --ntasks-per-node and --ntasks option when used with job constraints\n    that contain node counts.\n -- Prevent deadlocked slurmstepd processes due to unsafe use of regcomp with\n    older glibc versions.\n -- Fix squeue when SLURM_BITSTR_LEN=0 is set in the user environment.\n -- Fix comments in acct_policy.c to reflect actual variables instead of\n    old ones.\n -- Fix correct variables when validating GrpTresMins on a QOS.\n -- Better debug output when a job is being held because of a GrpTRES[Run]Min\n    limits.\n -- Fix correct state reason when job can't run 'safely' because of an\n    association GrpWall limit.\n -- Squeue always loads new data if user_id option specified\n -- Fix for possible job ID parsing failure and abort.\n -- If node boot in progress when slurmctld daemon is restarted, then allow\n    sufficient time for reboot to complete and not prematurely DOWN the node as\n    \"Not responding\".\n -- For job resize, correct logic to build \"resize\" script with new values.\n    Previously the scripts were based upon the original job size.\n -- Fix squeue to not limit the size of partition, burst_buffer, exec_host, or\n    reason to 32 chars.\n -- Fix potential packing error when packing a NULL slurmdb_clus_res_rec_t.\n -- Fix potential packing errors when packing a NULL slurmdb_reservation_cond_t.\n -- Burst_buffer/cray - Prevent slurmctld daemon abort if \"paths\" operation\n    fails. Now job will be held. Update job update time when held.\n -- Fix issues with QOS flags Partition[Min|Max]Nodes to work correctly.\n -- Increase number of ResumePrograms that can be managed without leaving\n    zombie/orphan processes from 10 to 100.\n -- Refactor slurmctld agent logic to eliminate some pthreads.\n\n* Changes in Slurm 16.05.9\n==========================\n -- Fix parsing of SBCAST_COMPRESS environment variable in sbcast.\n -- Change some debug messages to errors in task/cgroup plugin.\n -- backfill scheduler: Stop trying to determine expected start time for a job\n    after 2 seconds of wall time. This can happen if there are many running jobs\n    and a pending job can not be started soon.\n -- Improve performance of cr_sort_part_rows() in cons_res plugin.\n -- CRAY - Fix dealock issue when updating accounting in the slurmctld and\n    scheduling a Datawarp job.\n -- Correct the job state accounting information for jobs requeued due to burst\n    buffer errors.\n -- burst_buffer/cray - Avoid \"pre_run\" operation if not using buffer (i.e.\n    just creating or deleting a persistent burst buffer).\n -- Fix slurm.spec file support for BlueGene builds.\n -- Fix missing TRES read lock in acct_policy_job_runnable_pre_select() code.\n -- Fix debug2 message printing value using wrong array index in\n    _qos_job_runnable_post_select().\n -- Prevent job timeout on node power up.\n -- MYSQL - Fix minor memory leak when querying steps and the sql fails.\n -- Make it so sacctmgr accepts column headers like MaxTRESPU and not MaxTRESP.\n -- Only look at SLURM_STEP_KILLED_MSG_NODE_ID on startup, to avoid race\n    condition later when looking at a steps env.\n -- Make backfill scheduler behave like regular scheduler in respect to\n    'assoc_limit_stop'.\n -- Allow a lower version client command to talk to a higher version controller\n    using the multi-cluster options (e.g. squeue -M<clsuter>).\n -- slurmctld/agent race condition fix: Prevent job launch while PrologSlurmctld\n    daemon is running or node boot in progress.\n -- MYSQL - Fix a few other minor memory leaks when uncommon failures occur.\n -- burst_buffer/cray - Fix race condition that could cause multiple batch job\n    launch requests resulting in drained nodes.\n -- Correct logic to purge old reservations.\n -- Fix DBD cache restore from previous versions.\n -- Fix to logic for getting expected start time of existing job ID with\n    explicit begin time that is in the past.\n -- Clear job's reason of \"BeginTime\" in a more timely fashion and/or prevents\n    them from being stuck in a PENDING state.\n -- Make sure acct policy limits imposed on a job are correct after requeue.\n\n* Changes in Slurm 16.05.8\n==========================\n -- Remove StoragePass from being printed out in the slurmdbd log at debug2\n    level.\n -- Defer PATH search for task program until launch in slurmstepd.\n -- Modify regression test1.89 to avoid leaving vestigial job. Also reduce\n    logging to reduce likelihood of Expect buffer overflow.\n -- Do not PATH search for mult-prog launches if LaunchParamters=test_exec is\n    enabled.\n -- Fix for possible infinite loop in select/cons_res plugin when trying to\n    satisfy a job's ntasks_per_core or socket specification.\n -- If job is held for bad constraints make it so once updated the job doesn't\n    go into JobAdminHeld.\n -- sched/backfill - Fix logic to reserve resources for jobs that require a\n    node reboot (i.e. to change KNL mode) in order to start.\n -- When unpacking a node or front_end record from state and the protocol\n    version is lower than the min version, set it to the min.\n -- Remove redundant lookup for part_ptr when updating a reservation's nodes.\n -- Fix memory and file descriptor leaks in slurmd daemon's sbcast logic.\n -- Do not allocate specialized cores to jobs using the --exclusive option.\n -- Cancel interactive job if Prolog failure with \"PrologFlags=contain\" or\n    \"PrologFlags=alloc\" configured. Send new error prolog failure message to\n    the salloc or srun command as needed.\n -- Prevent possible out-of-bounds read in slurmstepd on an invalid #! line.\n -- Fix check for PluginDir within slurmctld to work with multiple directories.\n -- Cancel interactive jobs automatically on communication error to launching\n    srun/salloc process.\n -- Fix security issue caused by insecure file path handling triggered by the\n    failure of a Prolog script. To exploit this a user needs to anticipate or\n    cause the Prolog to fail for their job. CVE-2016-10030.\n\n* Changes in Slurm 16.05.7\n==========================\n -- Fix issue in the priority/multifactor plugin where on a slurmctld restart,\n    where more time is accounted for than should be allowed.\n -- cray/busrt_buffer - If total_space in a pool decreases, reset used_space\n    rather than trying to account for buffer allocations in progress.\n -- cray/busrt_buffer - Fix for double counting of used_space at slurmctld\n    startup.\n -- Fix regression in 16.05.6 where if you request multiple cpus per task (-c2)\n    and request --ntasks-per-core=1 and only 1 task on the node\n    the slurmd would abort on an infinite loop fatal.\n -- cray/busrt_buffer - Internally track both allocated and unusable space.\n    The reported UsedSpace in a pool is now the allocated space (previously was\n    unusable space). Base available space on whichever value leaves least free\n    space.\n -- cray/burst_buffer - Preserve job ID and don't translate to job array ID.\n -- cray/burst_buffer - Update \"instance\" parsing to match updated dw_wlm_cli\n    output.\n -- sched/backfill - Insure we don't try to start a job that was already started\n    and requeued by the main scheduling logic.\n -- job_submit/lua - add access to the job features field in job_record.\n -- select/linear plugin modified to better support heterogeneous clusters when\n    topology/none is also configured.\n -- Permit cancellation of jobs in configuring state.\n -- acct_gather_energy/rapl - prevent segfault in slurmd from race to gather\n    data at slurmd startup.\n -- Integrate node_feature/knl_generic with \"hbm\" GRES information.\n -- Fix output routines to prevent rounding the TRES values for memory or BB.\n -- switch/cray plugin - fix use after free error.\n -- docs - elaborate on how way to clear TRES limits in sacctmgr.\n -- knl_cray plugin - Avoid abort from backup slurmctld at start time.\n -- cgroup plugins - fix two minor memory leaks.\n -- If a node is booting for some job, don't allocate additional jobs to the\n    node until the boot completes.\n -- testsuite - fix job id output in test17.39.\n -- Modify backfill algorithm to improve performance with large numbers of\n    running jobs. Group running jobs that end in a \"similar\" time frame using a\n    time window that grows exponentially rather than linearly. After one second\n    of wall time, simulate the termination of all remaining running jobs in\n    order to respond in a reasonable time frame.\n -- Fix slurm_job_cpus_allocated_str_on_node_id() API call.\n -- sched/backfill plugin: Make malloc match data type (defined as uint32_t and\n    allocated as int).\n -- srun - prevent segfault when terminating job step before step has launched.\n -- sacctmgr - prevent segfault when trying to reset usage for an invalid\n    account name.\n -- Make the openssl crypto plugin compile with openssl >= 1.1.\n -- Fix SuspendExcNodes and SuspendExcParts on slurmctld reconfiguration.\n -- sbcast - prevent segfault in slurmd due to race condition between file\n    transfers from separate jobs using zlib compression\n -- cray/burst_buffer - Increase time to synchronize operations between threads\n    from 5 to 60 seconds (\"setup\" operation time observed over 17 seconds).\n -- node_features/knl_cray - Fix possible race condition when changing node\n    state that could result in old KNL mode as an active features.\n -- Make sure if a job can't run because of resources we also check accounting\n    limits after the node selection to make sure it doesn't violate those limits\n    and if it does change the reason for waiting so we don't reserve resources\n    on jobs violating accounting limits.\n -- NRT - Make it so a system running against IBM's PE will work with PE\n    version 1.3.\n -- NRT - Make it so protocols pgas and test are allowed to be used.\n -- NRT - Make it so you can have more than 1 protocol listed in MP_MSG_API.\n -- cray/burst_buffer - If slurmctld daemon restarts with pending job and burst\n    buffer having unknown file stage-in status, teardown the buffer, defer the\n    job, and start stage-in over again.\n -- On state restore in the slurmctld don't overwrite the mem_spec_limit given\n    from the slurm.conf when using FastSchedule=0.\n -- Recognize a KNL's proper NUMA count (rather than setting it to the value\n    in slurm.conf) when using FastSchedule=0.\n -- Fix parsing in regression test1.92 for some prompts.\n -- sbcast - use slurmd's gid cache rather than a separate lookup.\n -- slurmd - return error if setgroups() call fails in _drop_privileges().\n -- Remove error messages about gres counts changing when a job is resized on\n    a slurmctld restart or reconfig, as they aren't really error messages.\n -- Fix possible memory corruption if a job is using GRES and changing size.\n -- jobcomp/elasticsearch - fix printf format for a value on 32-bit builds.\n -- task/cgroup - Change error message if CPU binding can not take place to\n    better identify the root cause of the problem.\n -- Fix issue where task/cgroup would not always honor --cpu_bind=threads.\n -- Fix race condition in with getgrouplist() in slurmd that can lead to\n    user accounts being granted access to incorrect group memberships during\n    job launch.\n\n* Changes in Slurm 16.05.6\n==========================\n -- Docs - the correct default value for GroupUpdateForce is 0.\n -- mpi/pmix - improve point to point communication performance.\n -- SlurmDB - include pending jobs in search during 'sacctmgr show runawayjobs'.\n -- Add client side out-of-range checks to --nice flag.\n -- Fix support for sbatch \"-W\" option, previously eeded to use \"--wait\".\n -- node_features/knl_cray plugin and capmc_suspend/resume programs modified to\n    sleep and retry capmc operations if the Cray State Manager is down. Added\n    CapmcRetries configuration parameter to knl_cray.conf.\n -- node_features/knl_cray plugin: Remove any KNL MCDRAM or NUMA features from\n    node's configuration if capmc does NOT report the node as being KNL.\n -- node_features/knl_cray plugin: drain any node not reported by\n    \"capmc node_status\" on startup or reconfig.\n -- node_features/knl_cray plugin: Substantially streamline and speed up logic\n    to load current node state on reconfigure failure or unexpected node boot.\n -- node_features/knl_cray plugin: Add separate thread to interact with capmc\n    in response to unexpected node reboots.\n -- node_features plugin - Add \"mode\" argument to node_features_p_node_xlate()\n    function to fix some bugs updating a node's features using the node update\n    RPC.\n -- node_features/knl_cray plugin: If the reconfiguration of nodes for an\n    interactive job fails, kill the job (it can't be requeued like a batch job).\n -- Testsuite - Added srun/salloc/sbatch tests with --use-min-nodes option.\n -- Fix typo when an error occurs when discovering pmix version on\n    configure.\n -- Fix configuring pmix support when you have your lib dir symlinked to lib64.\n -- Fix waiting reason if a job is waiting for a specific limit instead of\n    always just AccountingPolicy.\n -- Correct SchedulerParameters=bf_busy_nodes logic with respect to the job's\n    minimum node count. Previous logic would not decremement counter in some\n    locations and reject valid job request for not reaching minimum node count.\n -- Fix FreeBSD-11 build by using llabs() function in place of abs().\n -- Cray: The slurmd can manipulate the socket/core/thread values reported based\n    upon the configuration. The logic failed to consider select/cray with\n    SelectTypeParameters=other_cons_res as equivalent to select/cons_res.\n -- If a node's socket or core count are changed at registration time (e.g. a\n    KNL node's NUMA mode is changed), change it's board count to match.\n -- Prevent possible divide by zero in select/cons_res if a node's board count\n    is higher than it's socket count.\n -- Allow an advanced reservation to contain a license count of zero.\n -- Preserve non-KNL node features when updating the KNL node features for a\n    multi-node job in which the non-KNL node features vary by node.\n -- task/affinity plugin: Honor a job's --ntasks-per-socket and\n    --ntasks-per-core options in task binding.\n -- slurmd - do not print ClusterName when using 'slurmd -C'.\n -- Correct a bitmap test function (used only by the select/bluegene plugin).\n -- Do not propagate SLURM_UMASK environment variable to batch script.\n -- Added node_features/knl_generic plugin for KNL support on non-Cray systems.\n -- Cray: Prevent abort in backfill scheduling logic for requeued job that has\n    been cancelled while NHC is running.\n -- Improve reported estimates of start and end times for pending jobs.\n -- pbsnodes: Show OS value as \"unknown\" for down nodes.\n -- BlueGene - correctly scale node counts when enforcing MaxNodes limit take 2.\n -- Fix \"sbatch --hold\" to set JobHeldUser correctly instead of JobHeldAdmin.\n -- Cray - print warning that task/cgroup is required, and must be after\n    task/cray in the TaskPlugin settings.\n -- Document that node Weight takes precedence over load with LLN scheduling.\n -- Fix issue where gang scheduling could happen even with OverSubscribe=NO.\n -- Expose JOB_SHARED_* values to job_submit/lua plugin.\n -- Fix issue where number of nodes is not properly allocated when srun is\n    requested with -n tasks < hosts from -w hostlist.\n -- Update srun documentation for -N, -w and -m arbitrary.\n -- Fix bug that was clearing MAINT mode on nodes scheduled for reboot (bug\n    introduced in version 16.05.5 to address bug in overlapping reservations).\n -- Add logging of node reboot requests.\n -- Docs - remove recommendation for ReleaseAgent setting in cgroup.conf.\n -- Make sure a job cleans up completely if it has a node fail.  Mostly an\n    issue with gang scheduling.\n\n* Changes in Slurm 16.05.5\n==========================\n -- Fix accounting for jobs requeued after the previous job was finished.\n -- slurmstepd modified to pre-load all relevant plugins at startup to avoid\n    the possibility of modified plugins later resulting in inconsistent API\n    or data structures and a failure of slurmstepd.\n -- Export functions from parse_time.c in libslurm.so.\n -- Export unit convert functions from slurm_protocol_api.c in libslurm.so.\n -- Fix scancel to allow multiple steps from a job to be cancelled at once.\n -- Update and expand upgrade guide (in Quick Start Administrator web page).\n -- burst_buffer/cray: Requeue, but do not hold a job which fails the pre_run\n    operation.\n -- Insure reported expected job start time is not in the past for pending jobs.\n -- Add support for PMIx v2.\n -- mpi/pmix: support for passing TMPDIR path through info key\n -- Cray: update slurmconfgen_smw.py script to correctly identify service nodes\n    versus compute nodes.\n -- FreeBSD - fix build issue in knl_cray plugin.\n -- Corrections to gres.conf parsing logic.\n -- Make partition State independent of EnforcePartLimits value.\n -- Fix multipart srun submission with EnforcePartLimits=NO and job violating\n    the partition limits.\n -- Fix problem updating job state_reason.\n -- pmix - Provide HWLOC topology in the job-data if Slurm was configured\n    with hwloc.\n -- Cray - Fix issue restoring jobs when blade count increases due to hardware\n    reconfiguration.\n -- burst_buffer/cray - Hold job after 3 failed pre-run operations.\n -- sched/backfill - Check that a user's QOS is allowed to use a partition\n    before trying to schedule resources on that partition for the job.\n -- sacctmgr - Fix displaying nodenames when printing out events or\n    reservations.\n -- Fix mpiexec wrapper to accept task count with more than one digit.\n -- Add mpiexec man page to the script.\n -- Add salloc_wait_nodes option to the SchedulerParameters parameter in the\n    slurm.conf file controlling when the salloc command returns in relation to\n    when nodes are ready for use (i.e. booted).\n -- Handle case when slurmctld daemon restart while compute node reboot in\n    progress. Return node to service rather than setting DOWN.\n -- Preserve node \"RESERVATION\" state when one of multiple overlapping\n    reservations ends.\n -- Restructure srun command locking for task_exit processing logic for improved\n    parallelism.\n -- Modify srun task completion handling to only build the task/node string for\n    logging purposes if it is needed. Modified for performance purposes.\n -- Docs - update salloc/sbatch/srun man pages to mention corresponding\n    environment variables for --mem/--mem-per-cpu and allowed suffixes.\n -- Silence srun warning when overriding the job ntasks-per-node count\n    with a lower task count for the step.\n -- Docs - assorted spelling fixes.\n -- node_features/knl_cray: Fix bug where MCDRAM state could be taken from\n    capmc rather than cnselect.\n -- node_features/knl_cray: If a node is rebooted outside of Slurm's direction,\n    update it's active features with current MCDRAM and NUMA mode information.\n -- Restore ability to manually power down nodes, broken in 15.08.12.\n -- Don't log error for job end_time being zero if node health check is still\n    running.\n -- When powering up a node to change it's state (e.g. KNL NUMA or MCDRAM mode)\n    then pass to the ResumeProgram the job ID assigned to the nodes in the\n    SLURM_JOB_ID environment variable.\n -- Allow a node's PowerUp state flag to be cleared using update_node RPC.\n -- capmc_suspend/resume - If a request modify NUMA or MCDRAM state on a set of\n    nodes or reboot a set of nodes fails then just requeue the job and abort the\n    entire operation rather than trying to operate on individual nodes.\n -- node_features/knl_cray plugin: Increase default CapmcTimeout parameter from\n    10 to 60 seconds.\n -- Fix squeue filter by job license when a job has requested more than 1\n    license of a certain type.\n -- Fix bug in PMIX_Ring in the pmi2 plugin so that it supports singleton mode.\n    It also updates the testpmixring.c test program so it can be used to check\n    singleton runs.\n -- Automatically clean up task/cgroup cpuset and devices cgroups after steps are\n    completed.\n -- Testsuite - Fix test1.83 to handle gaps in node names properly.\n -- BlueGene - correctly scale node counts when enforcing MaxNodes limit.\n -- Make sure no attempt is made to schedule a requeued job until all steps are\n    cleaned (Node Health Check completes for all steps on a Cray).\n -- KNL: Correct task affinity logic for some NUMA modes.\n -- Add salloc/sbatch/srun --priority option of \"TOP\" to set job priority to\n    the highest possible value. This option is only available to Slurm operators\n    and administrators.\n -- Add salloc/sbatch/srun option --use-min-nodes to prefer smaller node counts\n    when a range of node counts is specified (e.g. \"-N 2-4\").\n -- Validate salloc/sbatch --wait-all-nodes argument.\n -- Add \"sbatch_wait_nodes\" to SchedulerParameters to control default sbatch\n    behaviour with respect to waiting for all allocated nodes to be ready for\n    use. Job can override the configuration option using the --wait-all-nodes=#\n    option.\n -- Prevent partition group access updates from resetting last_part_update when\n    no changes have been made. Prevents backfill scheduler from restarting\n    mid-cycle unnecessarily.\n -- Cray - add NHC_ABSOLUTELY_NO to never run NHC, even on certain edge cases\n    that it would otherwise be run on with NHC_NO.\n -- Ignore GRES/QOS updates that maintain the same value as before.\n -- mpi/pmix - prepare temp directory for application.\n -- Fix display for the nice and priority values in sprio/scontrol/squeue.\n\n* Changes in Slurm 16.05.4\n==========================\n -- Fix potential deadlock if running with message aggregation.\n -- Streamline when schedule() is called when running with message aggregation\n    on batch script completes.\n -- Fix incorrect casting when [un]packing derived_ec on slurmdb_job_rec_t.\n -- Document that persistent burst buffers can not be created or destroyed using\n    the salloc or srun --bb options.\n -- Add support for setting the SLURM_JOB_ACCOUNT, SLURM_JOB_QOS and\n    SLURM_JOB_RESERVAION environment variables are set for the salloc command.\n    Document the same environment variables for the salloc, sbatch and srun\n    commands in their man pages.\n -- Fix issue where sacctmgr load cluster.cfg wouldn't load associations\n    that had a partition in them.\n -- Don't return the extern step from sstat by default.\n -- In sstat print 'extern' instead of 4294967295 for the extern step.\n -- Make advanced reservations work properly with core specialization.\n -- Fix race condition in the account_gather plugin that could result in job\n    stuck in COMPLETING state.\n -- Regression test fixes if SelectTypePlugin not managing memory and no node\n    memory size set (defaults to 1 MB per node).\n -- Add missing partition write locks to _slurm_rpc_dump_nodes/node_single to\n    prevent a race condition leading to inconsistent sinfo results.\n -- Fix task:CPU binding logic for some processors. This bug was introduced\n    in version 16.05.1 to address KNL binding problem.\n -- Fix two minor memory leaks in slurmctld.\n -- Improve partition-specific limit logging from slurmctld daemon.\n -- Fix incorrect access check when using MaxNodes setting on the partition.\n -- Fix issue with sacctmgr when specifying a list of clusters to query.\n -- Fix issue when calculating future StartTime for a job.\n -- Make EnforcePartLimit support logic work with any ordering of partitions\n    in job submit request.\n -- Prevent restoration of wrong CPU governor and frequency when using\n    multiple task plugins.\n -- Prevent slurmd abort if hwloc library fails to populate the \"children\"\n    arrays (observed with hwloc version \"dev-333-g85ea6e4\").\n -- burst_buffer/cray: Add \"--groupid\" to DataWarp \"setup\" command.\n -- Fix lustre profiling putting it in the Filesystem dataset instead of the\n    Network dataset.\n -- Fix profiling documentation and code to match be consistent with\n    Filesystem instead of Lustre.\n -- Correct the way watts is calculated in the rapl plugin when using a poll\n    frequency other than AcctGatherNodeFreq.\n -- Don't about step launch if job reaches expected end time while node is\n    configuring/booting (NOTE: The job end time will be adjusted after node\n    becomes ready for use).\n -- Fix several print routines to respect a custom output delimiter when\n    printing NO_VAL or INFINITE.\n -- Correct documented configurations where --ntasks-per-core and\n    --ntasks-per-socket are supported.\n -- task/affinity plugin buffer allocated too small, can corrupt memory.\n\n* Changes in Slurm 16.05.3\n==========================\n -- Make it so the extern step uses a reverse tree when cleaning up.\n -- If extern step doesn't get added into the proctrack plugin make sure the\n    sleep is killed.\n -- Fix areas the slurmctld can segfault if an extern step is in the system\n    cleaning up on a restart.\n -- Prevent possible incorrect counting of GRES of a given type if a node has\n    the multiple \"types\" of a given GRES \"name\", which could over-subscribe\n    GRES of a given type.\n -- Add web links to Slurm Diamond Collectors (from Harvard University) and\n    collectd (from EDF).\n -- Add job_submit plugin for the \"reboot\" field.\n -- Make some more Slurm constants (INFINITE, NO_VAL64, etc.) available to\n    job_submit/lua plugins.\n -- Send in a -1 for a taskid into spank_task_post_fork for the extern_step.\n -- MYSQL - Slightly better logic if a job completion comes in with an end time\n    of 0.\n -- task/cgroup plugin is configured with ConstrainRAMSpace=yes, then set soft\n    memory limit to allocated memory limit (previously no soft limit was set).\n -- Document limitations in burst buffer use by the salloc command (possible\n    access problems from a login node).\n -- Fix proctrack plugin to only add the pid of a process once\n    (regression in 16.05.2).\n -- Fix for sstat to print correct info when requesting jobid.batch as part of\n    a comma-separated list.\n -- CRAY - Fix issue if pid has already been added to another job container.\n -- CRAY - Fix add of extern step to AELD.\n -- burstbufer/cray: avoid batch submit error condition if waiting for stagein.\n -- CRAY - Fix for reporting steps lingering after they are already finished.\n -- Testsuite - fix test1.29 / 17.15 for limits with values above 32-bits.\n -- CRAY - Simplify when a NHC is called on a step that has unkillable\n    processes.\n -- CRAY - If trying to kill a step and you have NHC_NO_STEPS set run NHC\n    anyway to attempt to log the backtraces of the potential\n    unkillable processes.\n -- Fix gang scheduling and license release logic if single node job killed on\n    bad node.\n -- Make scontrol show steps show the extern step correctly.\n -- Do not scheduled powered down nodes in FAILED state.\n -- Do not start slurmctld power_save thread until partition information is read\n    in order to prevent race condition that can result invalid pointer when\n    trying to resolve configured SuspendExcParts.\n -- Add SLURM_PENDING_STEP id so it won't be confused with SLURM_EXTERN_CONT.\n -- Fix for core selection with job --gres-flags=enforce-binding option.\n    Previous logic would in some cases allocate a job zero cores, resulting in\n    slurmctld abort.\n -- Minimize preempted jobs for configurations with multiple jobs per node.\n -- Improve partition AllowGroups caching. Update the table of UIDs permitted to\n    use a partition based upon it's AllowGroups configuration parameter as new\n    valid UIDs are found rather than looking up that user's group information\n    for every job they submit. If the user is now allowed to use the partition,\n    then do not check that user's group access again for 5 seconds.\n -- Add routing queue information to Slurm FAQ web page.\n -- Do not select_g_step_finish() a SLURM_PENDING_STEP step, as nothing has\n    been allocated for the step yet.\n -- Fixed race condition in PMIx Fence logic.\n -- Prevent slurmctld abort if job is killed or requeued while waiting for\n    reboot of its allocated compute nodes.\n -- Treat invalid user ID in AllowUserBoot option of knl.conf file as error\n    rather than fatal (log and do not exit).\n -- qsub - When doing the default output files for an array in qsub style\n    make them using the master job ID instead of the normal job ID.\n -- Create the extern step while creating the job instead of waiting until the\n    end of the job to do it.\n -- Always report a 0 exit code for the extern step instead of being canceled\n    or failed based on the signal that would always be killing it.\n -- Fix to allow users to update QOS of pending jobs.\n -- CRAY - Fix minor memory leak in switch plugin.\n -- CRAY - Change slurmconfgen_smw.py to skip over disabled nodes.\n -- Fix eligible_time for elasticsearch as well as add queue_wait\n    (difference between start of job and when it was eligible).\n\n\n* Changes in Slurm 16.05.2\n==========================\n -- CRAY - Fix issue where the proctrack plugin could hang if the container\n    id wasn't able to be made.\n -- Move test for job wait reason value of BurstBufferResources and\n    BurstBufferStageIn later in the scheduling logic.\n -- Document which srun options apply to only job, only step, or job and step\n    allocations.\n -- Use more compatible function to get thread name (>= 2.6.11).\n -- Fix order of job then step id when noting cleaning flag being set.\n -- Make it so the extern step sends a message with accounting information\n    back to the slurmctld.\n -- Make it so the extern step calls the select_g_step_start|finish functions.\n -- Don't print error when extern step is canceled because job is ending.\n -- Handle a few error codes when dealing with the extern step to make sure\n    we have the pids added to the system correctly.\n -- Add support for job dependencies with job array expressions. Previous logic\n    required listing each task of job array individually.\n -- Make sure tres_cnt is set before creating a slurmdb_assoc_usage_t.\n -- Prevent backfill scheduler from starting a second \"singleton\" job if another\n    one started during a backfill sleep.\n -- Fix for invalid array pointer when creating advanced reservation when job\n    allocations span heterogeneous nodes (differing core or socket counts).\n -- Fix hostlist_ranged_string_xmalloc_dims to correctly not put brackets on\n    hostlists when brackets == 0.\n -- Make sure we don't get brackets when making a range of reserved ports\n    for a step.\n -- Change fatal to an error if port ranges aren't correct when reading state\n    for steps.\n\n* Changes in Slurm 16.05.1\n==========================\n -- Fix __cplusplus macro in spank.h to allow compilation with C++.\n -- Fix compile issue with older glibc < 2.12\n -- Fix for starting batch step with mpi/pmix plugin.\n -- Fix for \"scontrol -dd show job\" with respect to displaying the specific\n    CPUs allocated to a job on each node. Prior logic would only display\n    the CPU information for the first node in the job allocation.\n -- Print correct return code on failure to update active node features\n    through sview.\n -- Allow QOS timelimit to override partition timelimit when EnforcePartLimits\n    is set to all/any.\n -- Make it so qsub will do a \"basename\" on a wrapped command for the output\n    and error files.\n -- Fix issue where slurmd could core when running the ipmi energy plugin.\n -- Documentation - clean up typos.\n -- Add logic so that slurmstepd can be launched under valgrind.\n -- Increase buffer size to read /proc/*/stat files.\n -- Fix for tracking job resource allocation when slurmctld is reconfigured\n    while Cray Node Health Check (NHC) is running. Previous logic would fail to\n    record the job's allocation then perform release operation upon NHC\n    completion, resulting in underflow error messages.\n -- Make \"scontrol show daemons\" work with long node names.\n -- CRAY - Collect energy using a uint64_t instead of uint32_t.\n -- Fix incorrect if statements when determining if the user has a default\n    account or wckey.\n -- Prevent job stuck in configuring state if slurmctld daemon restarted while\n    PrologSlurmctld is running. Also re-issue burst_buffer/pre-load operation\n    as needed.\n -- Correct task affinity support for FreeBSD.\n -- Fix for task affinity on KNL in SNC2/Flat mode.\n -- Recalculate a job's memory allocation after node reboot if job requests all\n    of a node's memory and FastSchedule=0 is configured. Intel KNL memory size\n    can change on reboot with various MCDRAM modes.\n -- Fix small memory leak when printing HealthCheckNodeState.\n -- Eliminate memory leaks when AuthInfo is configured.\n -- Improve sdiag output description in man page.\n -- Cray/capmc_resume script modify a node's features (as needed) when the\n    reinit (reboot) command is issued rather than wait for the nodes to change\n    to the \"on\" state.\n -- Correctly print ranges when using step values in job arrays.\n -- Allow from file names / paths over 256 characters when launching steps,\n    as well as spaces in the executable name.\n -- job_submit.license.lua example modified to send message back to user.\n -- Document job --mem=0 option means all memory on a node.\n -- Set SLURM_JOB_QOS environment variable to QOS name instead of description.\n -- knl_cray.conf file option of CnselectPath added.\n -- node_features/knl_cray plugin modified to get current node NUMA and MCDRAM\n    modes using cnselect command rather than capmc command.\n -- liblua - add SLES12 paths to runtime search list.\n -- Fix qsub default output and error files for task arrays.\n -- Fix qsub to set job_name correctly when wrapping a script (-b y)\n -- Cray - set EnforcePartLimits=any in slurm.conf template.\n\n* Changes in Slurm 16.05.0\n==========================\n -- Update seff to fix warnings with ncpus, and list slurm-perlapi dependency\n    in spec file.\n -- Fix testsuite to consistent use /usr/bin/env {bash,expect} construct.\n -- Cray - Ensure that step completion messages get to the database.\n -- Fix step cpus_per_task calculation for heterogeneous job allocation.\n -- Fix --with-json= configure option to use specified path.\n -- Add back thread_id to \"thread_id\" LogTimeFormat to distinguish between\n    multiple threads with the same name. Now displays thread name and id.\n -- Change how Slurm determines the NUMA count of a node. Ignore KNL NUMA\n    that only include memory.\n -- Cray - Fix node list parsing in capmc_suspend/resume programs.\n -- Fix sbatch #BSUB parsing for -W and -M options.\n -- Fix GRES task layout bug that could cause slurmctld to abort.\n -- Fix to --gres-flags=enforce-binding logic when multiple sockets needed.\n\n* Changes in Slurm 16.05.0rc2\n=============================\n -- Cray node shutdown/reboot scripts, perform operations on all nodes in one\n    capmc command. Only if that fails, issue the operations in parallel on\n    individual nodes. Required for scalability.\n -- Cleanup two minor Coverity warnings.\n -- Make it so the tres units in a job's formatted string are converted like\n    they are in a step.\n -- Correct partition's MaxCPUsPerNode enforcement when nodes are shared by\n    multiple partitions.\n -- node_feature/knl_cray - Prevent slurmctld GRES errors for \"hbm\" references.\n -- Display thread name instead of thread id and remove process name in stderr\n    logging for \"thread_id\" LogTimeFormat.\n -- Log IP address of bad incoming message to slurmctld.\n -- If a user requests tasks, nodes and ntasks-per-node and\n    tasks-per-node/nodes != tasks print warning and ignore ntasks-per-node.\n -- Release CPU \"owner\" file locks.\n -- Fix for job step memory allocation: Reject invalid step at submit time\n    rather than leaving it queued.\n -- Whenever possible, avoid allocating nodes that require a reboot.\n\n* Changes in Slurm 16.05.0rc1\n==============================\n -- Remove the SchedulerParameters option of \"assoc_limit_continue\", making it\n    the default value. Add option of \"assoc_limit_stop\". If \"assoc_limit_stop\"\n    is set and a job cannot start due to association limits, then do not attempt\n    to initiate any lower priority jobs in that partition. Setting this can\n   "
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 3.1533203125,
          "content": "Slurm Workload Manager\n--------------------------------------------------------\n\nThis is the Slurm Workload Manager. Slurm\nis an open-source cluster resource management and job scheduling system\nthat strives to be simple, scalable, portable, fault-tolerant, and\ninterconnect agnostic. Slurm currently has been tested only under Linux.\n\nAs a cluster resource manager, Slurm provides three key functions. First,\nit allocates exclusive and/or non-exclusive access to resources\n(compute nodes) to users for some duration of time so they can perform\nwork. Second, it provides a framework for starting, executing, and\nmonitoring work (normally a parallel job) on the set of allocated\nnodes. Finally, it arbitrates conflicting requests for resources by\nmanaging a queue of pending work.\n\nNOTES FOR GITHUB DEVELOPERS\n---------------------------\n\nThe official issue tracker for Slurm is at\n  https://bugs.schedmd.com/\n\nWe welcome code contributions and patches, but **we do not accept Pull Requests\nthrough Github at this time.** Please submit patches as attachments to new\nissues under the \"C - Contributions\" severity level.\n\nSOURCE DISTRIBUTION HIERARCHY\n-----------------------------\n\nThe top-level distribution directory contains this README as well as\nother high-level documentation files, and the scripts used to configure\nand build Slurm (see INSTALL). Subdirectories contain the source-code\nfor Slurm as well as a test suite and further documentation. A\nquick description of the subdirectories of the Slurm distribution follows:\n\n  src/        [ Slurm source ]\n     Slurm source code is further organized into self explanatory\n     subdirectories such as src/api, src/slurmctld, etc.\n\n  doc/        [ Slurm documentation ]\n     The documentation directory contains some latex, html, and ascii\n     text papers, READMEs, and guides. Manual pages for the Slurm\n     commands and configuration files are also under the doc/ directory.\n\n  etc/        [ Slurm configuration ]\n     The etc/ directory contains a sample config file, as well as\n     some scripts useful for running Slurm.\n\n  slurm/      [ Slurm include files ]\n     This directory contains installed include files, such as slurm.h\n     and slurm_errno.h, needed for compiling against the Slurm API.\n\n  testsuite/  [ Slurm test suite ]\n     The testsuite directory contains an extensive collection of tests written\n     for Check, Expect and Pytest.\n\n  auxdir/     [ autotools directory ]\n     Directory for autotools scripts and files used to configure and\n     build Slurm\n\n  contribs/   [ helpful tools outside of Slurm proper ]\n     Directory for anything that is outside of slurm proper such as a\n     different api or such.  To have this build you need to do a\n     make contrib/install-contrib.\n\nCOMPILING AND INSTALLING THE DISTRIBUTION\n-----------------------------------------\n\nPlease see the instructions at\n  https://slurm.schedmd.com/quickstart_admin.html\nExtensive documentation is available from our home page at\n  https://slurm.schedmd.com/slurm.html\n\nLEGAL\n-----\n\nSlurm is provided \"as is\" and with no warranty. This software is\ndistributed under the GNU General Public License, please see the files\nCOPYING, DISCLAIMER, and LICENSE.OpenSSL for details.\n"
        },
        {
          "name": "RELEASE_NOTES",
          "type": "blob",
          "size": 1.4580078125,
          "content": "RELEASE NOTES FOR SLURM VERSION 25.05\n\nIMPORTANT NOTES:\nIf using the slurmdbd (Slurm DataBase Daemon) you must update this first.\n\nNOTE: If using a backup DBD you must start the primary first to do any\ndatabase conversion, the backup will not start until this has happened.\n\nThe 24.05 slurmdbd will work with Slurm daemons of version 23.02 and above.\nYou will not need to update all clusters at the same time, but it is very\nimportant to update slurmdbd first and having it running before updating\nany other clusters making use of it.\n\nSlurm can be upgraded from version 23.11, 24.05 or 24.11 to version\n25.05 without loss of jobs or other state information. Upgrading directly from\nan earlier version of Slurm will result in loss of state information.\n\nAll SPANK plugins must be recompiled when upgrading from any Slurm version\nprior to 25.05.\n\nHIGHLIGHTS\n==========\n\nCONFIGURATION FILE CHANGES (see appropriate man page for details)\n=====================================================================\n\nCOMMAND CHANGES (see man pages for details)\n===========================================\n -- slurmdbd '-R' is no longer a valid option. lft/rgt logic was removed from\n    Slurm in 23.11.\n -- sreport - start times will be rounded down to the previous hour and the end\n    times will be rounded up to the next hour. Before, times for start and end\n    were being rounded to the nearest minute or hour which was not intuitive.\n\nAPI CHANGES\n===========\n\nSLURMRESTD CHANGES\n==================\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.2236328125,
          "content": "# Reporting Security Issues\n\nPlease contact <security@schedmd.com> to report potential security issues.\n\nSchedMD's [security policy](https://www.schedmd.com/security-policy/)\ngoverns how security issues within Slurm are managed.\n"
        },
        {
          "name": "aclocal.m4",
          "type": "blob",
          "size": 65.384765625,
          "content": "# generated automatically by aclocal 1.16.5 -*- Autoconf -*-\n\n# Copyright (C) 1996-2021 Free Software Foundation, Inc.\n\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY, to the extent permitted by law; without\n# even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n# PARTICULAR PURPOSE.\n\nm4_ifndef([AC_CONFIG_MACRO_DIRS], [m4_defun([_AM_CONFIG_MACRO_DIRS], [])m4_defun([AC_CONFIG_MACRO_DIRS], [_AM_CONFIG_MACRO_DIRS($@)])])\nm4_ifndef([AC_AUTOCONF_VERSION],\n  [m4_copy([m4_PACKAGE_VERSION], [AC_AUTOCONF_VERSION])])dnl\nm4_if(m4_defn([AC_AUTOCONF_VERSION]), [2.72],,\n[m4_warning([this file was generated for autoconf 2.72.\nYou have another version of autoconf.  It may work, but is not guaranteed to.\nIf you have problems, you may need to regenerate the build system entirely.\nTo do so, use the procedure documented by the package, typically 'autoreconf'.])])\n\n# Configure paths for GLIB\n# Owen Taylor     1997-2001\n\n# Increment this whenever this file is changed.\n#serial 4\n\ndnl AM_PATH_GLIB_2_0([MINIMUM-VERSION, [ACTION-IF-FOUND [, ACTION-IF-NOT-FOUND [, MODULES]]]])\ndnl Test for GLIB, and define GLIB_CFLAGS and GLIB_LIBS, if gmodule, gobject,\ndnl gthread, or gio is specified in MODULES, pass to pkg-config\ndnl\nAC_DEFUN([AM_PATH_GLIB_2_0],\n[dnl \ndnl Get the cflags and libraries from pkg-config\ndnl\n\ndnl We can't use PKG_PREREQ because that needs 0.29.\nm4_ifndef([PKG_PROG_PKG_CONFIG],\n          [pkg.m4 version 0.28 or later is required])\n\nAC_ARG_ENABLE(glibtest, [  --disable-glibtest      do not try to compile and run a test GLIB program],\n\t\t    , enable_glibtest=yes)\n\n  min_glib_version=ifelse([$1], [], [2.0.0], [$1])\n  pkg_config_args=\"glib-2.0 >= $min_glib_version\"\n  for module in . $4\n  do\n      case \"$module\" in\n         gmodule) \n             pkg_config_args=\"$pkg_config_args gmodule-2.0\"\n         ;;\n         gmodule-no-export) \n             pkg_config_args=\"$pkg_config_args gmodule-no-export-2.0\"\n         ;;\n         gobject) \n             pkg_config_args=\"$pkg_config_args gobject-2.0\"\n         ;;\n         gthread) \n             pkg_config_args=\"$pkg_config_args gthread-2.0\"\n         ;;\n         gio*) \n             pkg_config_args=\"$pkg_config_args $module-2.0\"\n         ;;\n      esac\n  done\n\n  PKG_PROG_PKG_CONFIG([0.16])\n\n  no_glib=\"\"\n\n  if test \"x$PKG_CONFIG\" = x ; then\n    no_glib=yes\n    PKG_CONFIG=no\n  fi\n\n  dnl For GLIB_CFLAGS and GLIB_LIBS\n  PKG_CHECK_MODULES([GLIB], [$pkg_config_args], [:], [:])\n\n  dnl For the tools\n  PKG_CHECK_VAR([GLIB_GENMARSHAL], [glib-2.0], [glib_genmarshal])\n  PKG_CHECK_VAR([GOBJECT_QUERY], [glib-2.0], [gobject_query])\n  PKG_CHECK_VAR([GLIB_MKENUMS], [glib-2.0], [glib_mkenums])\n  PKG_CHECK_VAR([GLIB_COMPILE_RESOURCES], [gio-2.0], [glib_compile_resources])\n\n  AC_MSG_CHECKING(for GLIB - version >= $min_glib_version)\n\n  if test x$PKG_CONFIG != xno ; then\n    ## don't try to run the test against uninstalled libtool libs\n    if $PKG_CONFIG --uninstalled $pkg_config_args; then\n\t  echo \"Will use uninstalled version of GLib found in PKG_CONFIG_PATH\"\n\t  enable_glibtest=no\n    fi\n\n    if $PKG_CONFIG --atleast-version $min_glib_version $pkg_config_args; then\n\t  :\n    else\n\t  no_glib=yes\n    fi\n  fi\n\n  if test x\"$no_glib\" = x ; then\n    glib_config_major_version=`$PKG_CONFIG --modversion glib-2.0 | \\\n           sed 's/\\([[0-9]]*\\).\\([[0-9]]*\\).\\([[0-9]]*\\)/\\1/'`\n    glib_config_minor_version=`$PKG_CONFIG --modversion glib-2.0 | \\\n           sed 's/\\([[0-9]]*\\).\\([[0-9]]*\\).\\([[0-9]]*\\)/\\2/'`\n    glib_config_micro_version=`$PKG_CONFIG --modversion glib-2.0 | \\\n           sed 's/\\([[0-9]]*\\).\\([[0-9]]*\\).\\([[0-9]]*\\)/\\3/'`\n    if test \"x$enable_glibtest\" = \"xyes\" ; then\n      ac_save_CFLAGS=\"$CFLAGS\"\n      ac_save_LIBS=\"$LIBS\"\n      CFLAGS=\"$CFLAGS $GLIB_CFLAGS\"\n      LIBS=\"$GLIB_LIBS $LIBS\"\ndnl\ndnl Now check if the installed GLib is sufficiently new. (Also sanity\ndnl checks the results of pkg-config to some extent)\ndnl\n      rm -f conf.glibtest\n      AC_RUN_IFELSE([AC_LANG_SOURCE([[\n#include <glib.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nint \nmain (void)\n{\n  unsigned int major, minor, micro;\n\n  fclose (fopen (\"conf.glibtest\", \"w\"));\n\n  if (sscanf(\"$min_glib_version\", \"%u.%u.%u\", &major, &minor, &micro) != 3) {\n     printf(\"%s, bad version string\\n\", \"$min_glib_version\");\n     exit(1);\n   }\n\n  if ((glib_major_version != $glib_config_major_version) ||\n      (glib_minor_version != $glib_config_minor_version) ||\n      (glib_micro_version != $glib_config_micro_version))\n    {\n      printf(\"\\n*** 'pkg-config --modversion glib-2.0' returned %d.%d.%d, but GLIB (%d.%d.%d)\\n\", \n             $glib_config_major_version, $glib_config_minor_version, $glib_config_micro_version,\n             glib_major_version, glib_minor_version, glib_micro_version);\n      printf (\"*** was found! If pkg-config was correct, then it is best\\n\");\n      printf (\"*** to remove the old version of GLib. You may also be able to fix the error\\n\");\n      printf(\"*** by modifying your LD_LIBRARY_PATH environment variable, or by editing\\n\");\n      printf(\"*** /etc/ld.so.conf. Make sure you have run ldconfig if that is\\n\");\n      printf(\"*** required on your system.\\n\");\n      printf(\"*** If pkg-config was wrong, set the environment variable PKG_CONFIG_PATH\\n\");\n      printf(\"*** to point to the correct configuration files\\n\");\n    } \n  else if ((glib_major_version != GLIB_MAJOR_VERSION) ||\n\t   (glib_minor_version != GLIB_MINOR_VERSION) ||\n           (glib_micro_version != GLIB_MICRO_VERSION))\n    {\n      printf(\"*** GLib header files (version %d.%d.%d) do not match\\n\",\n\t     GLIB_MAJOR_VERSION, GLIB_MINOR_VERSION, GLIB_MICRO_VERSION);\n      printf(\"*** library (version %d.%d.%d)\\n\",\n\t     glib_major_version, glib_minor_version, glib_micro_version);\n    }\n  else\n    {\n      if ((glib_major_version > major) ||\n        ((glib_major_version == major) && (glib_minor_version > minor)) ||\n        ((glib_major_version == major) && (glib_minor_version == minor) && (glib_micro_version >= micro)))\n      {\n        return 0;\n       }\n     else\n      {\n        printf(\"\\n*** An old version of GLib (%u.%u.%u) was found.\\n\",\n               glib_major_version, glib_minor_version, glib_micro_version);\n        printf(\"*** You need a version of GLib newer than %u.%u.%u. The latest version of\\n\",\n\t       major, minor, micro);\n        printf(\"*** GLib is always available from ftp://ftp.gtk.org.\\n\");\n        printf(\"***\\n\");\n        printf(\"*** If you have already installed a sufficiently new version, this error\\n\");\n        printf(\"*** probably means that the wrong copy of the pkg-config shell script is\\n\");\n        printf(\"*** being found. The easiest way to fix this is to remove the old version\\n\");\n        printf(\"*** of GLib, but you can also set the PKG_CONFIG environment to point to the\\n\");\n        printf(\"*** correct copy of pkg-config. (In this case, you will have to\\n\");\n        printf(\"*** modify your LD_LIBRARY_PATH environment variable, or edit /etc/ld.so.conf\\n\");\n        printf(\"*** so that the correct libraries are found at run-time))\\n\");\n      }\n    }\n  return 1;\n}\n]])],[],[no_glib=yes],[echo $ac_n \"cross compiling; assumed OK... $ac_c\"])\n       CFLAGS=\"$ac_save_CFLAGS\"\n       LIBS=\"$ac_save_LIBS\"\n     fi\n  fi\n  if test \"x$no_glib\" = x ; then\n     AC_MSG_RESULT(yes (version $glib_config_major_version.$glib_config_minor_version.$glib_config_micro_version))\n     ifelse([$2], , :, [$2])     \n  else\n     AC_MSG_RESULT(no)\n     if test \"$PKG_CONFIG\" = \"no\" ; then\n       echo \"*** A new enough version of pkg-config was not found.\"\n       echo \"*** See http://www.freedesktop.org/software/pkgconfig/\"\n     else\n       if test -f conf.glibtest ; then\n        :\n       else\n          echo \"*** Could not run GLib test program, checking why...\"\n          ac_save_CFLAGS=\"$CFLAGS\"\n          ac_save_LIBS=\"$LIBS\"\n          CFLAGS=\"$CFLAGS $GLIB_CFLAGS\"\n          LIBS=\"$LIBS $GLIB_LIBS\"\n          AC_LINK_IFELSE([AC_LANG_PROGRAM([[\n#include <glib.h>\n#include <stdio.h>\n]],      [[ return ((glib_major_version) || (glib_minor_version) || (glib_micro_version)); ]])],\n        [ echo \"*** The test program compiled, but did not run. This usually means\"\n          echo \"*** that the run-time linker is not finding GLib or finding the wrong\"\n          echo \"*** version of GLib. If it is not finding GLib, you'll need to set your\"\n          echo \"*** LD_LIBRARY_PATH environment variable, or edit /etc/ld.so.conf to point\"\n          echo \"*** to the installed location  Also, make sure you have run ldconfig if that\"\n          echo \"*** is required on your system\"\n\t  echo \"***\"\n          echo \"*** If you have an old version installed, it is best to remove it, although\"\n          echo \"*** you may also be able to get things to work by modifying LD_LIBRARY_PATH\" ],\n        [ echo \"*** The test program failed to compile or link. See the file config.log for the\"\n          echo \"*** exact error that occurred. This usually means GLib is incorrectly installed.\"])\n          CFLAGS=\"$ac_save_CFLAGS\"\n          LIBS=\"$ac_save_LIBS\"\n       fi\n     fi\n     GLIB_CFLAGS=\"\"\n     GLIB_LIBS=\"\"\n     GLIB_GENMARSHAL=\"\"\n     GOBJECT_QUERY=\"\"\n     GLIB_MKENUMS=\"\"\n     GLIB_COMPILE_RESOURCES=\"\"\n     ifelse([$3], , :, [$3])\n  fi\n  rm -f conf.glibtest\n])\n\n# pkg.m4 - Macros to locate and use pkg-config.   -*- Autoconf -*-\n# serial 12 (pkg-config-0.29.2)\n\ndnl Copyright © 2004 Scott James Remnant <scott@netsplit.com>.\ndnl Copyright © 2012-2015 Dan Nicholson <dbn.lists@gmail.com>\ndnl\ndnl This program is free software; you can redistribute it and/or modify\ndnl it under the terms of the GNU General Public License as published by\ndnl the Free Software Foundation; either version 2 of the License, or\ndnl (at your option) any later version.\ndnl\ndnl This program is distributed in the hope that it will be useful, but\ndnl WITHOUT ANY WARRANTY; without even the implied warranty of\ndnl MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\ndnl General Public License for more details.\ndnl\ndnl You should have received a copy of the GNU General Public License\ndnl along with this program; if not, write to the Free Software\ndnl Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\ndnl 02111-1307, USA.\ndnl\ndnl As a special exception to the GNU General Public License, if you\ndnl distribute this file as part of a program that contains a\ndnl configuration script generated by Autoconf, you may include it under\ndnl the same distribution terms that you use for the rest of that\ndnl program.\n\ndnl PKG_PREREQ(MIN-VERSION)\ndnl -----------------------\ndnl Since: 0.29\ndnl\ndnl Verify that the version of the pkg-config macros are at least\ndnl MIN-VERSION. Unlike PKG_PROG_PKG_CONFIG, which checks the user's\ndnl installed version of pkg-config, this checks the developer's version\ndnl of pkg.m4 when generating configure.\ndnl\ndnl To ensure that this macro is defined, also add:\ndnl m4_ifndef([PKG_PREREQ],\ndnl     [m4_fatal([must install pkg-config 0.29 or later before running autoconf/autogen])])\ndnl\ndnl See the \"Since\" comment for each macro you use to see what version\ndnl of the macros you require.\nm4_defun([PKG_PREREQ],\n[m4_define([PKG_MACROS_VERSION], [0.29.2])\nm4_if(m4_version_compare(PKG_MACROS_VERSION, [$1]), -1,\n    [m4_fatal([pkg.m4 version $1 or higher is required but ]PKG_MACROS_VERSION[ found])])\n])dnl PKG_PREREQ\n\ndnl PKG_PROG_PKG_CONFIG([MIN-VERSION])\ndnl ----------------------------------\ndnl Since: 0.16\ndnl\ndnl Search for the pkg-config tool and set the PKG_CONFIG variable to\ndnl first found in the path. Checks that the version of pkg-config found\ndnl is at least MIN-VERSION. If MIN-VERSION is not specified, 0.9.0 is\ndnl used since that's the first version where most current features of\ndnl pkg-config existed.\nAC_DEFUN([PKG_PROG_PKG_CONFIG],\n[m4_pattern_forbid([^_?PKG_[A-Z_]+$])\nm4_pattern_allow([^PKG_CONFIG(_(PATH|LIBDIR|SYSROOT_DIR|ALLOW_SYSTEM_(CFLAGS|LIBS)))?$])\nm4_pattern_allow([^PKG_CONFIG_(DISABLE_UNINSTALLED|TOP_BUILD_DIR|DEBUG_SPEW)$])\nAC_ARG_VAR([PKG_CONFIG], [path to pkg-config utility])\nAC_ARG_VAR([PKG_CONFIG_PATH], [directories to add to pkg-config's search path])\nAC_ARG_VAR([PKG_CONFIG_LIBDIR], [path overriding pkg-config's built-in search path])\n\nif test \"x$ac_cv_env_PKG_CONFIG_set\" != \"xset\"; then\n\tAC_PATH_TOOL([PKG_CONFIG], [pkg-config])\nfi\nif test -n \"$PKG_CONFIG\"; then\n\t_pkg_min_version=m4_default([$1], [0.9.0])\n\tAC_MSG_CHECKING([pkg-config is at least version $_pkg_min_version])\n\tif $PKG_CONFIG --atleast-pkgconfig-version $_pkg_min_version; then\n\t\tAC_MSG_RESULT([yes])\n\telse\n\t\tAC_MSG_RESULT([no])\n\t\tPKG_CONFIG=\"\"\n\tfi\nfi[]dnl\n])dnl PKG_PROG_PKG_CONFIG\n\ndnl PKG_CHECK_EXISTS(MODULES, [ACTION-IF-FOUND], [ACTION-IF-NOT-FOUND])\ndnl -------------------------------------------------------------------\ndnl Since: 0.18\ndnl\ndnl Check to see whether a particular set of modules exists. Similar to\ndnl PKG_CHECK_MODULES(), but does not set variables or print errors.\ndnl\ndnl Please remember that m4 expands AC_REQUIRE([PKG_PROG_PKG_CONFIG])\ndnl only at the first occurrence in configure.ac, so if the first place\ndnl it's called might be skipped (such as if it is within an \"if\", you\ndnl have to call PKG_CHECK_EXISTS manually\nAC_DEFUN([PKG_CHECK_EXISTS],\n[AC_REQUIRE([PKG_PROG_PKG_CONFIG])dnl\nif test -n \"$PKG_CONFIG\" && \\\n    AC_RUN_LOG([$PKG_CONFIG --exists --print-errors \"$1\"]); then\n  m4_default([$2], [:])\nm4_ifvaln([$3], [else\n  $3])dnl\nfi])\n\ndnl _PKG_CONFIG([VARIABLE], [COMMAND], [MODULES])\ndnl ---------------------------------------------\ndnl Internal wrapper calling pkg-config via PKG_CONFIG and setting\ndnl pkg_failed based on the result.\nm4_define([_PKG_CONFIG],\n[if test -n \"$$1\"; then\n    pkg_cv_[]$1=\"$$1\"\n elif test -n \"$PKG_CONFIG\"; then\n    PKG_CHECK_EXISTS([$3],\n                     [pkg_cv_[]$1=`$PKG_CONFIG --[]$2 \"$3\" 2>/dev/null`\n\t\t      test \"x$?\" != \"x0\" && pkg_failed=yes ],\n\t\t     [pkg_failed=yes])\n else\n    pkg_failed=untried\nfi[]dnl\n])dnl _PKG_CONFIG\n\ndnl _PKG_SHORT_ERRORS_SUPPORTED\ndnl ---------------------------\ndnl Internal check to see if pkg-config supports short errors.\nAC_DEFUN([_PKG_SHORT_ERRORS_SUPPORTED],\n[AC_REQUIRE([PKG_PROG_PKG_CONFIG])\nif $PKG_CONFIG --atleast-pkgconfig-version 0.20; then\n        _pkg_short_errors_supported=yes\nelse\n        _pkg_short_errors_supported=no\nfi[]dnl\n])dnl _PKG_SHORT_ERRORS_SUPPORTED\n\n\ndnl PKG_CHECK_MODULES(VARIABLE-PREFIX, MODULES, [ACTION-IF-FOUND],\ndnl   [ACTION-IF-NOT-FOUND])\ndnl --------------------------------------------------------------\ndnl Since: 0.4.0\ndnl\ndnl Note that if there is a possibility the first call to\ndnl PKG_CHECK_MODULES might not happen, you should be sure to include an\ndnl explicit call to PKG_PROG_PKG_CONFIG in your configure.ac\nAC_DEFUN([PKG_CHECK_MODULES],\n[AC_REQUIRE([PKG_PROG_PKG_CONFIG])dnl\nAC_ARG_VAR([$1][_CFLAGS], [C compiler flags for $1, overriding pkg-config])dnl\nAC_ARG_VAR([$1][_LIBS], [linker flags for $1, overriding pkg-config])dnl\n\npkg_failed=no\nAC_MSG_CHECKING([for $2])\n\n_PKG_CONFIG([$1][_CFLAGS], [cflags], [$2])\n_PKG_CONFIG([$1][_LIBS], [libs], [$2])\n\nm4_define([_PKG_TEXT], [Alternatively, you may set the environment variables $1[]_CFLAGS\nand $1[]_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.])\n\nif test $pkg_failed = yes; then\n        AC_MSG_RESULT([no])\n        _PKG_SHORT_ERRORS_SUPPORTED\n        if test $_pkg_short_errors_supported = yes; then\n                $1[]_PKG_ERRORS=`$PKG_CONFIG --short-errors --print-errors --cflags --libs \"$2\" 2>&1`\n        else\n                $1[]_PKG_ERRORS=`$PKG_CONFIG --print-errors --cflags --libs \"$2\" 2>&1`\n        fi\n        # Put the nasty error message in config.log where it belongs\n        echo \"$$1[]_PKG_ERRORS\" >&AS_MESSAGE_LOG_FD\n\n        m4_default([$4], [AC_MSG_ERROR(\n[Package requirements ($2) were not met:\n\n$$1_PKG_ERRORS\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\n_PKG_TEXT])[]dnl\n        ])\nelif test $pkg_failed = untried; then\n        AC_MSG_RESULT([no])\n        m4_default([$4], [AC_MSG_FAILURE(\n[The pkg-config script could not be found or is too old.  Make sure it\nis in your PATH or set the PKG_CONFIG environment variable to the full\npath to pkg-config.\n\n_PKG_TEXT\n\nTo get pkg-config, see <http://pkg-config.freedesktop.org/>.])[]dnl\n        ])\nelse\n        $1[]_CFLAGS=$pkg_cv_[]$1[]_CFLAGS\n        $1[]_LIBS=$pkg_cv_[]$1[]_LIBS\n        AC_MSG_RESULT([yes])\n        $3\nfi[]dnl\n])dnl PKG_CHECK_MODULES\n\n\ndnl PKG_CHECK_MODULES_STATIC(VARIABLE-PREFIX, MODULES, [ACTION-IF-FOUND],\ndnl   [ACTION-IF-NOT-FOUND])\ndnl ---------------------------------------------------------------------\ndnl Since: 0.29\ndnl\ndnl Checks for existence of MODULES and gathers its build flags with\ndnl static libraries enabled. Sets VARIABLE-PREFIX_CFLAGS from --cflags\ndnl and VARIABLE-PREFIX_LIBS from --libs.\ndnl\ndnl Note that if there is a possibility the first call to\ndnl PKG_CHECK_MODULES_STATIC might not happen, you should be sure to\ndnl include an explicit call to PKG_PROG_PKG_CONFIG in your\ndnl configure.ac.\nAC_DEFUN([PKG_CHECK_MODULES_STATIC],\n[AC_REQUIRE([PKG_PROG_PKG_CONFIG])dnl\n_save_PKG_CONFIG=$PKG_CONFIG\nPKG_CONFIG=\"$PKG_CONFIG --static\"\nPKG_CHECK_MODULES($@)\nPKG_CONFIG=$_save_PKG_CONFIG[]dnl\n])dnl PKG_CHECK_MODULES_STATIC\n\n\ndnl PKG_INSTALLDIR([DIRECTORY])\ndnl -------------------------\ndnl Since: 0.27\ndnl\ndnl Substitutes the variable pkgconfigdir as the location where a module\ndnl should install pkg-config .pc files. By default the directory is\ndnl $libdir/pkgconfig, but the default can be changed by passing\ndnl DIRECTORY. The user can override through the --with-pkgconfigdir\ndnl parameter.\nAC_DEFUN([PKG_INSTALLDIR],\n[m4_pushdef([pkg_default], [m4_default([$1], ['${libdir}/pkgconfig'])])\nm4_pushdef([pkg_description],\n    [pkg-config installation directory @<:@]pkg_default[@:>@])\nAC_ARG_WITH([pkgconfigdir],\n    [AS_HELP_STRING([--with-pkgconfigdir], pkg_description)],,\n    [with_pkgconfigdir=]pkg_default)\nAC_SUBST([pkgconfigdir], [$with_pkgconfigdir])\nm4_popdef([pkg_default])\nm4_popdef([pkg_description])\n])dnl PKG_INSTALLDIR\n\n\ndnl PKG_NOARCH_INSTALLDIR([DIRECTORY])\ndnl --------------------------------\ndnl Since: 0.27\ndnl\ndnl Substitutes the variable noarch_pkgconfigdir as the location where a\ndnl module should install arch-independent pkg-config .pc files. By\ndnl default the directory is $datadir/pkgconfig, but the default can be\ndnl changed by passing DIRECTORY. The user can override through the\ndnl --with-noarch-pkgconfigdir parameter.\nAC_DEFUN([PKG_NOARCH_INSTALLDIR],\n[m4_pushdef([pkg_default], [m4_default([$1], ['${datadir}/pkgconfig'])])\nm4_pushdef([pkg_description],\n    [pkg-config arch-independent installation directory @<:@]pkg_default[@:>@])\nAC_ARG_WITH([noarch-pkgconfigdir],\n    [AS_HELP_STRING([--with-noarch-pkgconfigdir], pkg_description)],,\n    [with_noarch_pkgconfigdir=]pkg_default)\nAC_SUBST([noarch_pkgconfigdir], [$with_noarch_pkgconfigdir])\nm4_popdef([pkg_default])\nm4_popdef([pkg_description])\n])dnl PKG_NOARCH_INSTALLDIR\n\n\ndnl PKG_CHECK_VAR(VARIABLE, MODULE, CONFIG-VARIABLE,\ndnl [ACTION-IF-FOUND], [ACTION-IF-NOT-FOUND])\ndnl -------------------------------------------\ndnl Since: 0.28\ndnl\ndnl Retrieves the value of the pkg-config variable for the given module.\nAC_DEFUN([PKG_CHECK_VAR],\n[AC_REQUIRE([PKG_PROG_PKG_CONFIG])dnl\nAC_ARG_VAR([$1], [value of $3 for $2, overriding pkg-config])dnl\n\n_PKG_CONFIG([$1], [variable=\"][$3][\"], [$2])\nAS_VAR_COPY([$1], [pkg_cv_][$1])\n\nAS_VAR_IF([$1], [\"\"], [$5], [$4])dnl\n])dnl PKG_CHECK_VAR\n\ndnl PKG_WITH_MODULES(VARIABLE-PREFIX, MODULES,\ndnl   [ACTION-IF-FOUND],[ACTION-IF-NOT-FOUND],\ndnl   [DESCRIPTION], [DEFAULT])\ndnl ------------------------------------------\ndnl\ndnl Prepare a \"--with-\" configure option using the lowercase\ndnl [VARIABLE-PREFIX] name, merging the behaviour of AC_ARG_WITH and\ndnl PKG_CHECK_MODULES in a single macro.\nAC_DEFUN([PKG_WITH_MODULES],\n[\nm4_pushdef([with_arg], m4_tolower([$1]))\n\nm4_pushdef([description],\n           [m4_default([$5], [build with ]with_arg[ support])])\n\nm4_pushdef([def_arg], [m4_default([$6], [auto])])\nm4_pushdef([def_action_if_found], [AS_TR_SH([with_]with_arg)=yes])\nm4_pushdef([def_action_if_not_found], [AS_TR_SH([with_]with_arg)=no])\n\nm4_case(def_arg,\n            [yes],[m4_pushdef([with_without], [--without-]with_arg)],\n            [m4_pushdef([with_without],[--with-]with_arg)])\n\nAC_ARG_WITH(with_arg,\n     AS_HELP_STRING(with_without, description[ @<:@default=]def_arg[@:>@]),,\n    [AS_TR_SH([with_]with_arg)=def_arg])\n\nAS_CASE([$AS_TR_SH([with_]with_arg)],\n            [yes],[PKG_CHECK_MODULES([$1],[$2],$3,$4)],\n            [auto],[PKG_CHECK_MODULES([$1],[$2],\n                                        [m4_n([def_action_if_found]) $3],\n                                        [m4_n([def_action_if_not_found]) $4])])\n\nm4_popdef([with_arg])\nm4_popdef([description])\nm4_popdef([def_arg])\n\n])dnl PKG_WITH_MODULES\n\ndnl PKG_HAVE_WITH_MODULES(VARIABLE-PREFIX, MODULES,\ndnl   [DESCRIPTION], [DEFAULT])\ndnl -----------------------------------------------\ndnl\ndnl Convenience macro to trigger AM_CONDITIONAL after PKG_WITH_MODULES\ndnl check._[VARIABLE-PREFIX] is exported as make variable.\nAC_DEFUN([PKG_HAVE_WITH_MODULES],\n[\nPKG_WITH_MODULES([$1],[$2],,,[$3],[$4])\n\nAM_CONDITIONAL([HAVE_][$1],\n               [test \"$AS_TR_SH([with_]m4_tolower([$1]))\" = \"yes\"])\n])dnl PKG_HAVE_WITH_MODULES\n\ndnl PKG_HAVE_DEFINE_WITH_MODULES(VARIABLE-PREFIX, MODULES,\ndnl   [DESCRIPTION], [DEFAULT])\ndnl ------------------------------------------------------\ndnl\ndnl Convenience macro to run AM_CONDITIONAL and AC_DEFINE after\ndnl PKG_WITH_MODULES check. HAVE_[VARIABLE-PREFIX] is exported as make\ndnl and preprocessor variable.\nAC_DEFUN([PKG_HAVE_DEFINE_WITH_MODULES],\n[\nPKG_HAVE_WITH_MODULES([$1],[$2],[$3],[$4])\n\nAS_IF([test \"$AS_TR_SH([with_]m4_tolower([$1]))\" = \"yes\"],\n        [AC_DEFINE([HAVE_][$1], 1, [Enable ]m4_tolower([$1])[ support])])\n])dnl PKG_HAVE_DEFINE_WITH_MODULES\n\n# Copyright (C) 2002-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_AUTOMAKE_VERSION(VERSION)\n# ----------------------------\n# Automake X.Y traces this macro to ensure aclocal.m4 has been\n# generated from the m4 files accompanying Automake X.Y.\n# (This private macro should not be called outside this file.)\nAC_DEFUN([AM_AUTOMAKE_VERSION],\n[am__api_version='1.16'\ndnl Some users find AM_AUTOMAKE_VERSION and mistake it for a way to\ndnl require some minimum version.  Point them to the right macro.\nm4_if([$1], [1.16.5], [],\n      [AC_FATAL([Do not call $0, use AM_INIT_AUTOMAKE([$1]).])])dnl\n])\n\n# _AM_AUTOCONF_VERSION(VERSION)\n# -----------------------------\n# aclocal traces this macro to find the Autoconf version.\n# This is a private macro too.  Using m4_define simplifies\n# the logic in aclocal, which can simply ignore this definition.\nm4_define([_AM_AUTOCONF_VERSION], [])\n\n# AM_SET_CURRENT_AUTOMAKE_VERSION\n# -------------------------------\n# Call AM_AUTOMAKE_VERSION and AM_AUTOMAKE_VERSION so they can be traced.\n# This function is AC_REQUIREd by AM_INIT_AUTOMAKE.\nAC_DEFUN([AM_SET_CURRENT_AUTOMAKE_VERSION],\n[AM_AUTOMAKE_VERSION([1.16.5])dnl\nm4_ifndef([AC_AUTOCONF_VERSION],\n  [m4_copy([m4_PACKAGE_VERSION], [AC_AUTOCONF_VERSION])])dnl\n_AM_AUTOCONF_VERSION(m4_defn([AC_AUTOCONF_VERSION]))])\n\n# AM_AUX_DIR_EXPAND                                         -*- Autoconf -*-\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# For projects using AC_CONFIG_AUX_DIR([foo]), Autoconf sets\n# $ac_aux_dir to '$srcdir/foo'.  In other projects, it is set to\n# '$srcdir', '$srcdir/..', or '$srcdir/../..'.\n#\n# Of course, Automake must honor this variable whenever it calls a\n# tool from the auxiliary directory.  The problem is that $srcdir (and\n# therefore $ac_aux_dir as well) can be either absolute or relative,\n# depending on how configure is run.  This is pretty annoying, since\n# it makes $ac_aux_dir quite unusable in subdirectories: in the top\n# source directory, any form will work fine, but in subdirectories a\n# relative path needs to be adjusted first.\n#\n# $ac_aux_dir/missing\n#    fails when called from a subdirectory if $ac_aux_dir is relative\n# $top_srcdir/$ac_aux_dir/missing\n#    fails if $ac_aux_dir is absolute,\n#    fails when called from a subdirectory in a VPATH build with\n#          a relative $ac_aux_dir\n#\n# The reason of the latter failure is that $top_srcdir and $ac_aux_dir\n# are both prefixed by $srcdir.  In an in-source build this is usually\n# harmless because $srcdir is '.', but things will broke when you\n# start a VPATH build or use an absolute $srcdir.\n#\n# So we could use something similar to $top_srcdir/$ac_aux_dir/missing,\n# iff we strip the leading $srcdir from $ac_aux_dir.  That would be:\n#   am_aux_dir='\\$(top_srcdir)/'`expr \"$ac_aux_dir\" : \"$srcdir//*\\(.*\\)\"`\n# and then we would define $MISSING as\n#   MISSING=\"\\${SHELL} $am_aux_dir/missing\"\n# This will work as long as MISSING is not called from configure, because\n# unfortunately $(top_srcdir) has no meaning in configure.\n# However there are other variables, like CC, which are often used in\n# configure, and could therefore not use this \"fixed\" $ac_aux_dir.\n#\n# Another solution, used here, is to always expand $ac_aux_dir to an\n# absolute PATH.  The drawback is that using absolute paths prevent a\n# configured tree to be moved without reconfiguration.\n\nAC_DEFUN([AM_AUX_DIR_EXPAND],\n[AC_REQUIRE([AC_CONFIG_AUX_DIR_DEFAULT])dnl\n# Expand $ac_aux_dir to an absolute path.\nam_aux_dir=`cd \"$ac_aux_dir\" && pwd`\n])\n\n# AM_CONDITIONAL                                            -*- Autoconf -*-\n\n# Copyright (C) 1997-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_CONDITIONAL(NAME, SHELL-CONDITION)\n# -------------------------------------\n# Define a conditional.\nAC_DEFUN([AM_CONDITIONAL],\n[AC_PREREQ([2.52])dnl\n m4_if([$1], [TRUE],  [AC_FATAL([$0: invalid condition: $1])],\n       [$1], [FALSE], [AC_FATAL([$0: invalid condition: $1])])dnl\nAC_SUBST([$1_TRUE])dnl\nAC_SUBST([$1_FALSE])dnl\n_AM_SUBST_NOTMAKE([$1_TRUE])dnl\n_AM_SUBST_NOTMAKE([$1_FALSE])dnl\nm4_define([_AM_COND_VALUE_$1], [$2])dnl\nif $2; then\n  $1_TRUE=\n  $1_FALSE='#'\nelse\n  $1_TRUE='#'\n  $1_FALSE=\nfi\nAC_CONFIG_COMMANDS_PRE(\n[if test -z \"${$1_TRUE}\" && test -z \"${$1_FALSE}\"; then\n  AC_MSG_ERROR([[conditional \"$1\" was never defined.\nUsually this means the macro was only invoked conditionally.]])\nfi])])\n\n# Copyright (C) 1999-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n\n# There are a few dirty hacks below to avoid letting 'AC_PROG_CC' be\n# written in clear, in which case automake, when reading aclocal.m4,\n# will think it sees a *use*, and therefore will trigger all it's\n# C support machinery.  Also note that it means that autoscan, seeing\n# CC etc. in the Makefile, will ask for an AC_PROG_CC use...\n\n\n# _AM_DEPENDENCIES(NAME)\n# ----------------------\n# See how the compiler implements dependency checking.\n# NAME is \"CC\", \"CXX\", \"OBJC\", \"OBJCXX\", \"UPC\", or \"GJC\".\n# We try a few techniques and use that to set a single cache variable.\n#\n# We don't AC_REQUIRE the corresponding AC_PROG_CC since the latter was\n# modified to invoke _AM_DEPENDENCIES(CC); we would have a circular\n# dependency, and given that the user is not expected to run this macro,\n# just rely on AC_PROG_CC.\nAC_DEFUN([_AM_DEPENDENCIES],\n[AC_REQUIRE([AM_SET_DEPDIR])dnl\nAC_REQUIRE([AM_OUTPUT_DEPENDENCY_COMMANDS])dnl\nAC_REQUIRE([AM_MAKE_INCLUDE])dnl\nAC_REQUIRE([AM_DEP_TRACK])dnl\n\nm4_if([$1], [CC],   [depcc=\"$CC\"   am_compiler_list=],\n      [$1], [CXX],  [depcc=\"$CXX\"  am_compiler_list=],\n      [$1], [OBJC], [depcc=\"$OBJC\" am_compiler_list='gcc3 gcc'],\n      [$1], [OBJCXX], [depcc=\"$OBJCXX\" am_compiler_list='gcc3 gcc'],\n      [$1], [UPC],  [depcc=\"$UPC\"  am_compiler_list=],\n      [$1], [GCJ],  [depcc=\"$GCJ\"  am_compiler_list='gcc3 gcc'],\n                    [depcc=\"$$1\"   am_compiler_list=])\n\nAC_CACHE_CHECK([dependency style of $depcc],\n               [am_cv_$1_dependencies_compiler_type],\n[if test -z \"$AMDEP_TRUE\" && test -f \"$am_depcomp\"; then\n  # We make a subdir and do the tests there.  Otherwise we can end up\n  # making bogus files that we don't know about and never remove.  For\n  # instance it was reported that on HP-UX the gcc test will end up\n  # making a dummy file named 'D' -- because '-MD' means \"put the output\n  # in D\".\n  rm -rf conftest.dir\n  mkdir conftest.dir\n  # Copy depcomp to subdir because otherwise we won't find it if we're\n  # using a relative directory.\n  cp \"$am_depcomp\" conftest.dir\n  cd conftest.dir\n  # We will build objects and dependencies in a subdirectory because\n  # it helps to detect inapplicable dependency modes.  For instance\n  # both Tru64's cc and ICC support -MD to output dependencies as a\n  # side effect of compilation, but ICC will put the dependencies in\n  # the current directory while Tru64 will put them in the object\n  # directory.\n  mkdir sub\n\n  am_cv_$1_dependencies_compiler_type=none\n  if test \"$am_compiler_list\" = \"\"; then\n     am_compiler_list=`sed -n ['s/^#*\\([a-zA-Z0-9]*\\))$/\\1/p'] < ./depcomp`\n  fi\n  am__universal=false\n  m4_case([$1], [CC],\n    [case \" $depcc \" in #(\n     *\\ -arch\\ *\\ -arch\\ *) am__universal=true ;;\n     esac],\n    [CXX],\n    [case \" $depcc \" in #(\n     *\\ -arch\\ *\\ -arch\\ *) am__universal=true ;;\n     esac])\n\n  for depmode in $am_compiler_list; do\n    # Setup a source with many dependencies, because some compilers\n    # like to wrap large dependency lists on column 80 (with \\), and\n    # we should not choose a depcomp mode which is confused by this.\n    #\n    # We need to recreate these files for each test, as the compiler may\n    # overwrite some of them when testing with obscure command lines.\n    # This happens at least with the AIX C compiler.\n    : > sub/conftest.c\n    for i in 1 2 3 4 5 6; do\n      echo '#include \"conftst'$i'.h\"' >> sub/conftest.c\n      # Using \": > sub/conftst$i.h\" creates only sub/conftst1.h with\n      # Solaris 10 /bin/sh.\n      echo '/* dummy */' > sub/conftst$i.h\n    done\n    echo \"${am__include} ${am__quote}sub/conftest.Po${am__quote}\" > confmf\n\n    # We check with '-c' and '-o' for the sake of the \"dashmstdout\"\n    # mode.  It turns out that the SunPro C++ compiler does not properly\n    # handle '-M -o', and we need to detect this.  Also, some Intel\n    # versions had trouble with output in subdirs.\n    am__obj=sub/conftest.${OBJEXT-o}\n    am__minus_obj=\"-o $am__obj\"\n    case $depmode in\n    gcc)\n      # This depmode causes a compiler race in universal mode.\n      test \"$am__universal\" = false || continue\n      ;;\n    nosideeffect)\n      # After this tag, mechanisms are not by side-effect, so they'll\n      # only be used when explicitly requested.\n      if test \"x$enable_dependency_tracking\" = xyes; then\n\tcontinue\n      else\n\tbreak\n      fi\n      ;;\n    msvc7 | msvc7msys | msvisualcpp | msvcmsys)\n      # This compiler won't grok '-c -o', but also, the minuso test has\n      # not run yet.  These depmodes are late enough in the game, and\n      # so weak that their functioning should not be impacted.\n      am__obj=conftest.${OBJEXT-o}\n      am__minus_obj=\n      ;;\n    none) break ;;\n    esac\n    if depmode=$depmode \\\n       source=sub/conftest.c object=$am__obj \\\n       depfile=sub/conftest.Po tmpdepfile=sub/conftest.TPo \\\n       $SHELL ./depcomp $depcc -c $am__minus_obj sub/conftest.c \\\n         >/dev/null 2>conftest.err &&\n       grep sub/conftst1.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep sub/conftst6.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep $am__obj sub/conftest.Po > /dev/null 2>&1 &&\n       ${MAKE-make} -s -f confmf > /dev/null 2>&1; then\n      # icc doesn't choke on unknown options, it will just issue warnings\n      # or remarks (even with -Werror).  So we grep stderr for any message\n      # that says an option was ignored or not supported.\n      # When given -MP, icc 7.0 and 7.1 complain thusly:\n      #   icc: Command line warning: ignoring option '-M'; no argument required\n      # The diagnosis changed in icc 8.0:\n      #   icc: Command line remark: option '-MP' not supported\n      if (grep 'ignoring option' conftest.err ||\n          grep 'not supported' conftest.err) >/dev/null 2>&1; then :; else\n        am_cv_$1_dependencies_compiler_type=$depmode\n        break\n      fi\n    fi\n  done\n\n  cd ..\n  rm -rf conftest.dir\nelse\n  am_cv_$1_dependencies_compiler_type=none\nfi\n])\nAC_SUBST([$1DEPMODE], [depmode=$am_cv_$1_dependencies_compiler_type])\nAM_CONDITIONAL([am__fastdep$1], [\n  test \"x$enable_dependency_tracking\" != xno \\\n  && test \"$am_cv_$1_dependencies_compiler_type\" = gcc3])\n])\n\n\n# AM_SET_DEPDIR\n# -------------\n# Choose a directory name for dependency files.\n# This macro is AC_REQUIREd in _AM_DEPENDENCIES.\nAC_DEFUN([AM_SET_DEPDIR],\n[AC_REQUIRE([AM_SET_LEADING_DOT])dnl\nAC_SUBST([DEPDIR], [\"${am__leading_dot}deps\"])dnl\n])\n\n\n# AM_DEP_TRACK\n# ------------\nAC_DEFUN([AM_DEP_TRACK],\n[AC_ARG_ENABLE([dependency-tracking], [dnl\nAS_HELP_STRING(\n  [--enable-dependency-tracking],\n  [do not reject slow dependency extractors])\nAS_HELP_STRING(\n  [--disable-dependency-tracking],\n  [speeds up one-time build])])\nif test \"x$enable_dependency_tracking\" != xno; then\n  am_depcomp=\"$ac_aux_dir/depcomp\"\n  AMDEPBACKSLASH='\\'\n  am__nodep='_no'\nfi\nAM_CONDITIONAL([AMDEP], [test \"x$enable_dependency_tracking\" != xno])\nAC_SUBST([AMDEPBACKSLASH])dnl\n_AM_SUBST_NOTMAKE([AMDEPBACKSLASH])dnl\nAC_SUBST([am__nodep])dnl\n_AM_SUBST_NOTMAKE([am__nodep])dnl\n])\n\n# Generate code to set up dependency tracking.              -*- Autoconf -*-\n\n# Copyright (C) 1999-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# _AM_OUTPUT_DEPENDENCY_COMMANDS\n# ------------------------------\nAC_DEFUN([_AM_OUTPUT_DEPENDENCY_COMMANDS],\n[{\n  # Older Autoconf quotes --file arguments for eval, but not when files\n  # are listed without --file.  Let's play safe and only enable the eval\n  # if we detect the quoting.\n  # TODO: see whether this extra hack can be removed once we start\n  # requiring Autoconf 2.70 or later.\n  AS_CASE([$CONFIG_FILES],\n          [*\\'*], [eval set x \"$CONFIG_FILES\"],\n          [*], [set x $CONFIG_FILES])\n  shift\n  # Used to flag and report bootstrapping failures.\n  am_rc=0\n  for am_mf\n  do\n    # Strip MF so we end up with the name of the file.\n    am_mf=`AS_ECHO([\"$am_mf\"]) | sed -e 's/:.*$//'`\n    # Check whether this is an Automake generated Makefile which includes\n    # dependency-tracking related rules and includes.\n    # Grep'ing the whole file directly is not great: AIX grep has a line\n    # limit of 2048, but all sed's we know have understand at least 4000.\n    sed -n 's,^am--depfiles:.*,X,p' \"$am_mf\" | grep X >/dev/null 2>&1 \\\n      || continue\n    am_dirpart=`AS_DIRNAME([\"$am_mf\"])`\n    am_filepart=`AS_BASENAME([\"$am_mf\"])`\n    AM_RUN_LOG([cd \"$am_dirpart\" \\\n      && sed -e '/# am--include-marker/d' \"$am_filepart\" \\\n        | $MAKE -f - am--depfiles]) || am_rc=$?\n  done\n  if test $am_rc -ne 0; then\n    AC_MSG_FAILURE([Something went wrong bootstrapping makefile fragments\n    for automatic dependency tracking.  If GNU make was not used, consider\n    re-running the configure script with MAKE=\"gmake\" (or whatever is\n    necessary).  You can also try re-running configure with the\n    '--disable-dependency-tracking' option to at least be able to build\n    the package (albeit without support for automatic dependency tracking).])\n  fi\n  AS_UNSET([am_dirpart])\n  AS_UNSET([am_filepart])\n  AS_UNSET([am_mf])\n  AS_UNSET([am_rc])\n  rm -f conftest-deps.mk\n}\n])# _AM_OUTPUT_DEPENDENCY_COMMANDS\n\n\n# AM_OUTPUT_DEPENDENCY_COMMANDS\n# -----------------------------\n# This macro should only be invoked once -- use via AC_REQUIRE.\n#\n# This code is only required when automatic dependency tracking is enabled.\n# This creates each '.Po' and '.Plo' makefile fragment that we'll need in\n# order to bootstrap the dependency handling code.\nAC_DEFUN([AM_OUTPUT_DEPENDENCY_COMMANDS],\n[AC_CONFIG_COMMANDS([depfiles],\n     [test x\"$AMDEP_TRUE\" != x\"\" || _AM_OUTPUT_DEPENDENCY_COMMANDS],\n     [AMDEP_TRUE=\"$AMDEP_TRUE\" MAKE=\"${MAKE-make}\"])])\n\n# Do all the work for Automake.                             -*- Autoconf -*-\n\n# Copyright (C) 1996-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# This macro actually does too much.  Some checks are only needed if\n# your package does certain things.  But this isn't really a big deal.\n\ndnl Redefine AC_PROG_CC to automatically invoke _AM_PROG_CC_C_O.\nm4_define([AC_PROG_CC],\nm4_defn([AC_PROG_CC])\n[_AM_PROG_CC_C_O\n])\n\n# AM_INIT_AUTOMAKE(PACKAGE, VERSION, [NO-DEFINE])\n# AM_INIT_AUTOMAKE([OPTIONS])\n# -----------------------------------------------\n# The call with PACKAGE and VERSION arguments is the old style\n# call (pre autoconf-2.50), which is being phased out.  PACKAGE\n# and VERSION should now be passed to AC_INIT and removed from\n# the call to AM_INIT_AUTOMAKE.\n# We support both call styles for the transition.  After\n# the next Automake release, Autoconf can make the AC_INIT\n# arguments mandatory, and then we can depend on a new Autoconf\n# release and drop the old call support.\nAC_DEFUN([AM_INIT_AUTOMAKE],\n[AC_PREREQ([2.65])dnl\nm4_ifdef([_$0_ALREADY_INIT],\n  [m4_fatal([$0 expanded multiple times\n]m4_defn([_$0_ALREADY_INIT]))],\n  [m4_define([_$0_ALREADY_INIT], m4_expansion_stack)])dnl\ndnl Autoconf wants to disallow AM_ names.  We explicitly allow\ndnl the ones we care about.\nm4_pattern_allow([^AM_[A-Z]+FLAGS$])dnl\nAC_REQUIRE([AM_SET_CURRENT_AUTOMAKE_VERSION])dnl\nAC_REQUIRE([AC_PROG_INSTALL])dnl\nif test \"`cd $srcdir && pwd`\" != \"`pwd`\"; then\n  # Use -I$(srcdir) only when $(srcdir) != ., so that make's output\n  # is not polluted with repeated \"-I.\"\n  AC_SUBST([am__isrc], [' -I$(srcdir)'])_AM_SUBST_NOTMAKE([am__isrc])dnl\n  # test to see if srcdir already configured\n  if test -f $srcdir/config.status; then\n    AC_MSG_ERROR([source directory already configured; run \"make distclean\" there first])\n  fi\nfi\n\n# test whether we have cygpath\nif test -z \"$CYGPATH_W\"; then\n  if (cygpath --version) >/dev/null 2>/dev/null; then\n    CYGPATH_W='cygpath -w'\n  else\n    CYGPATH_W=echo\n  fi\nfi\nAC_SUBST([CYGPATH_W])\n\n# Define the identity of the package.\ndnl Distinguish between old-style and new-style calls.\nm4_ifval([$2],\n[AC_DIAGNOSE([obsolete],\n             [$0: two- and three-arguments forms are deprecated.])\nm4_ifval([$3], [_AM_SET_OPTION([no-define])])dnl\n AC_SUBST([PACKAGE], [$1])dnl\n AC_SUBST([VERSION], [$2])],\n[_AM_SET_OPTIONS([$1])dnl\ndnl Diagnose old-style AC_INIT with new-style AM_AUTOMAKE_INIT.\nm4_if(\n  m4_ifset([AC_PACKAGE_NAME], [ok]):m4_ifset([AC_PACKAGE_VERSION], [ok]),\n  [ok:ok],,\n  [m4_fatal([AC_INIT should be called with package and version arguments])])dnl\n AC_SUBST([PACKAGE], ['AC_PACKAGE_TARNAME'])dnl\n AC_SUBST([VERSION], ['AC_PACKAGE_VERSION'])])dnl\n\n_AM_IF_OPTION([no-define],,\n[AC_DEFINE_UNQUOTED([PACKAGE], [\"$PACKAGE\"], [Name of package])\n AC_DEFINE_UNQUOTED([VERSION], [\"$VERSION\"], [Version number of package])])dnl\n\n# Some tools Automake needs.\nAC_REQUIRE([AM_SANITY_CHECK])dnl\nAC_REQUIRE([AC_ARG_PROGRAM])dnl\nAM_MISSING_PROG([ACLOCAL], [aclocal-${am__api_version}])\nAM_MISSING_PROG([AUTOCONF], [autoconf])\nAM_MISSING_PROG([AUTOMAKE], [automake-${am__api_version}])\nAM_MISSING_PROG([AUTOHEADER], [autoheader])\nAM_MISSING_PROG([MAKEINFO], [makeinfo])\nAC_REQUIRE([AM_PROG_INSTALL_SH])dnl\nAC_REQUIRE([AM_PROG_INSTALL_STRIP])dnl\nAC_REQUIRE([AC_PROG_MKDIR_P])dnl\n# For better backward compatibility.  To be removed once Automake 1.9.x\n# dies out for good.  For more background, see:\n# <https://lists.gnu.org/archive/html/automake/2012-07/msg00001.html>\n# <https://lists.gnu.org/archive/html/automake/2012-07/msg00014.html>\nAC_SUBST([mkdir_p], ['$(MKDIR_P)'])\n# We need awk for the \"check\" target (and possibly the TAP driver).  The\n# system \"awk\" is bad on some platforms.\nAC_REQUIRE([AC_PROG_AWK])dnl\nAC_REQUIRE([AC_PROG_MAKE_SET])dnl\nAC_REQUIRE([AM_SET_LEADING_DOT])dnl\n_AM_IF_OPTION([tar-ustar], [_AM_PROG_TAR([ustar])],\n\t      [_AM_IF_OPTION([tar-pax], [_AM_PROG_TAR([pax])],\n\t\t\t     [_AM_PROG_TAR([v7])])])\n_AM_IF_OPTION([no-dependencies],,\n[AC_PROVIDE_IFELSE([AC_PROG_CC],\n\t\t  [_AM_DEPENDENCIES([CC])],\n\t\t  [m4_define([AC_PROG_CC],\n\t\t\t     m4_defn([AC_PROG_CC])[_AM_DEPENDENCIES([CC])])])dnl\nAC_PROVIDE_IFELSE([AC_PROG_CXX],\n\t\t  [_AM_DEPENDENCIES([CXX])],\n\t\t  [m4_define([AC_PROG_CXX],\n\t\t\t     m4_defn([AC_PROG_CXX])[_AM_DEPENDENCIES([CXX])])])dnl\nAC_PROVIDE_IFELSE([AC_PROG_OBJC],\n\t\t  [_AM_DEPENDENCIES([OBJC])],\n\t\t  [m4_define([AC_PROG_OBJC],\n\t\t\t     m4_defn([AC_PROG_OBJC])[_AM_DEPENDENCIES([OBJC])])])dnl\nAC_PROVIDE_IFELSE([AC_PROG_OBJCXX],\n\t\t  [_AM_DEPENDENCIES([OBJCXX])],\n\t\t  [m4_define([AC_PROG_OBJCXX],\n\t\t\t     m4_defn([AC_PROG_OBJCXX])[_AM_DEPENDENCIES([OBJCXX])])])dnl\n])\n# Variables for tags utilities; see am/tags.am\nif test -z \"$CTAGS\"; then\n  CTAGS=ctags\nfi\nAC_SUBST([CTAGS])\nif test -z \"$ETAGS\"; then\n  ETAGS=etags\nfi\nAC_SUBST([ETAGS])\nif test -z \"$CSCOPE\"; then\n  CSCOPE=cscope\nfi\nAC_SUBST([CSCOPE])\n\nAC_REQUIRE([AM_SILENT_RULES])dnl\ndnl The testsuite driver may need to know about EXEEXT, so add the\ndnl 'am__EXEEXT' conditional if _AM_COMPILER_EXEEXT was seen.  This\ndnl macro is hooked onto _AC_COMPILER_EXEEXT early, see below.\nAC_CONFIG_COMMANDS_PRE(dnl\n[m4_provide_if([_AM_COMPILER_EXEEXT],\n  [AM_CONDITIONAL([am__EXEEXT], [test -n \"$EXEEXT\"])])])dnl\n\n# POSIX will say in a future version that running \"rm -f\" with no argument\n# is OK; and we want to be able to make that assumption in our Makefile\n# recipes.  So use an aggressive probe to check that the usage we want is\n# actually supported \"in the wild\" to an acceptable degree.\n# See automake bug#10828.\n# To make any issue more visible, cause the running configure to be aborted\n# by default if the 'rm' program in use doesn't match our expectations; the\n# user can still override this though.\nif rm -f && rm -fr && rm -rf; then : OK; else\n  cat >&2 <<'END'\nOops!\n\nYour 'rm' program seems unable to run without file operands specified\non the command line, even when the '-f' option is present.  This is contrary\nto the behaviour of most rm programs out there, and not conforming with\nthe upcoming POSIX standard: <http://austingroupbugs.net/view.php?id=542>\n\nPlease tell bug-automake@gnu.org about your system, including the value\nof your $PATH and any error possibly output before this message.  This\ncan help us improve future automake versions.\n\nEND\n  if test x\"$ACCEPT_INFERIOR_RM_PROGRAM\" = x\"yes\"; then\n    echo 'Configuration will proceed anyway, since you have set the' >&2\n    echo 'ACCEPT_INFERIOR_RM_PROGRAM variable to \"yes\"' >&2\n    echo >&2\n  else\n    cat >&2 <<'END'\nAborting the configuration process, to ensure you take notice of the issue.\n\nYou can download and install GNU coreutils to get an 'rm' implementation\nthat behaves properly: <https://www.gnu.org/software/coreutils/>.\n\nIf you want to complete the configuration process using your problematic\n'rm' anyway, export the environment variable ACCEPT_INFERIOR_RM_PROGRAM\nto \"yes\", and re-run configure.\n\nEND\n    AC_MSG_ERROR([Your 'rm' program is bad, sorry.])\n  fi\nfi\ndnl The trailing newline in this macro's definition is deliberate, for\ndnl backward compatibility and to allow trailing 'dnl'-style comments\ndnl after the AM_INIT_AUTOMAKE invocation. See automake bug#16841.\n])\n\ndnl Hook into '_AC_COMPILER_EXEEXT' early to learn its expansion.  Do not\ndnl add the conditional right here, as _AC_COMPILER_EXEEXT may be further\ndnl mangled by Autoconf and run in a shell conditional statement.\nm4_define([_AC_COMPILER_EXEEXT],\nm4_defn([_AC_COMPILER_EXEEXT])[m4_provide([_AM_COMPILER_EXEEXT])])\n\n# When config.status generates a header, we must update the stamp-h file.\n# This file resides in the same directory as the config header\n# that is generated.  The stamp files are numbered to have different names.\n\n# Autoconf calls _AC_AM_CONFIG_HEADER_HOOK (when defined) in the\n# loop where config.status creates the headers, so we can generate\n# our stamp files there.\nAC_DEFUN([_AC_AM_CONFIG_HEADER_HOOK],\n[# Compute $1's index in $config_headers.\n_am_arg=$1\n_am_stamp_count=1\nfor _am_header in $config_headers :; do\n  case $_am_header in\n    $_am_arg | $_am_arg:* )\n      break ;;\n    * )\n      _am_stamp_count=`expr $_am_stamp_count + 1` ;;\n  esac\ndone\necho \"timestamp for $_am_arg\" >`AS_DIRNAME([\"$_am_arg\"])`/stamp-h[]$_am_stamp_count])\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_PROG_INSTALL_SH\n# ------------------\n# Define $install_sh.\nAC_DEFUN([AM_PROG_INSTALL_SH],\n[AC_REQUIRE([AM_AUX_DIR_EXPAND])dnl\nif test x\"${install_sh+set}\" != xset; then\n  case $am_aux_dir in\n  *\\ * | *\\\t*)\n    install_sh=\"\\${SHELL} '$am_aux_dir/install-sh'\" ;;\n  *)\n    install_sh=\"\\${SHELL} $am_aux_dir/install-sh\"\n  esac\nfi\nAC_SUBST([install_sh])])\n\n# Copyright (C) 2003-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# Check whether the underlying file-system supports filenames\n# with a leading dot.  For instance MS-DOS doesn't.\nAC_DEFUN([AM_SET_LEADING_DOT],\n[rm -rf .tst 2>/dev/null\nmkdir .tst 2>/dev/null\nif test -d .tst; then\n  am__leading_dot=.\nelse\n  am__leading_dot=_\nfi\nrmdir .tst 2>/dev/null\nAC_SUBST([am__leading_dot])])\n\n# Add --enable-maintainer-mode option to configure.         -*- Autoconf -*-\n# From Jim Meyering\n\n# Copyright (C) 1996-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_MAINTAINER_MODE([DEFAULT-MODE])\n# ----------------------------------\n# Control maintainer-specific portions of Makefiles.\n# Default is to disable them, unless 'enable' is passed literally.\n# For symmetry, 'disable' may be passed as well.  Anyway, the user\n# can override the default with the --enable/--disable switch.\nAC_DEFUN([AM_MAINTAINER_MODE],\n[m4_case(m4_default([$1], [disable]),\n       [enable], [m4_define([am_maintainer_other], [disable])],\n       [disable], [m4_define([am_maintainer_other], [enable])],\n       [m4_define([am_maintainer_other], [enable])\n        m4_warn([syntax], [unexpected argument to AM@&t@_MAINTAINER_MODE: $1])])\nAC_MSG_CHECKING([whether to enable maintainer-specific portions of Makefiles])\n  dnl maintainer-mode's default is 'disable' unless 'enable' is passed\n  AC_ARG_ENABLE([maintainer-mode],\n    [AS_HELP_STRING([--]am_maintainer_other[-maintainer-mode],\n      am_maintainer_other[ make rules and dependencies not useful\n      (and sometimes confusing) to the casual installer])],\n    [USE_MAINTAINER_MODE=$enableval],\n    [USE_MAINTAINER_MODE=]m4_if(am_maintainer_other, [enable], [no], [yes]))\n  AC_MSG_RESULT([$USE_MAINTAINER_MODE])\n  AM_CONDITIONAL([MAINTAINER_MODE], [test $USE_MAINTAINER_MODE = yes])\n  MAINT=$MAINTAINER_MODE_TRUE\n  AC_SUBST([MAINT])dnl\n]\n)\n\n# Check to see how 'make' treats includes.\t            -*- Autoconf -*-\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_MAKE_INCLUDE()\n# -----------------\n# Check whether make has an 'include' directive that can support all\n# the idioms we need for our automatic dependency tracking code.\nAC_DEFUN([AM_MAKE_INCLUDE],\n[AC_MSG_CHECKING([whether ${MAKE-make} supports the include directive])\ncat > confinc.mk << 'END'\nam__doit:\n\t@echo this is the am__doit target >confinc.out\n.PHONY: am__doit\nEND\nam__include=\"#\"\nam__quote=\n# BSD make does it like this.\necho '.include \"confinc.mk\" # ignored' > confmf.BSD\n# Other make implementations (GNU, Solaris 10, AIX) do it like this.\necho 'include confinc.mk # ignored' > confmf.GNU\n_am_result=no\nfor s in GNU BSD; do\n  AM_RUN_LOG([${MAKE-make} -f confmf.$s && cat confinc.out])\n  AS_CASE([$?:`cat confinc.out 2>/dev/null`],\n      ['0:this is the am__doit target'],\n      [AS_CASE([$s],\n          [BSD], [am__include='.include' am__quote='\"'],\n          [am__include='include' am__quote=''])])\n  if test \"$am__include\" != \"#\"; then\n    _am_result=\"yes ($s style)\"\n    break\n  fi\ndone\nrm -f confinc.* confmf.*\nAC_MSG_RESULT([${_am_result}])\nAC_SUBST([am__include])])\nAC_SUBST([am__quote])])\n\n# Fake the existence of programs that GNU maintainers use.  -*- Autoconf -*-\n\n# Copyright (C) 1997-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_MISSING_PROG(NAME, PROGRAM)\n# ------------------------------\nAC_DEFUN([AM_MISSING_PROG],\n[AC_REQUIRE([AM_MISSING_HAS_RUN])\n$1=${$1-\"${am_missing_run}$2\"}\nAC_SUBST($1)])\n\n# AM_MISSING_HAS_RUN\n# ------------------\n# Define MISSING if not defined so far and test if it is modern enough.\n# If it is, set am_missing_run to use it, otherwise, to nothing.\nAC_DEFUN([AM_MISSING_HAS_RUN],\n[AC_REQUIRE([AM_AUX_DIR_EXPAND])dnl\nAC_REQUIRE_AUX_FILE([missing])dnl\nif test x\"${MISSING+set}\" != xset; then\n  MISSING=\"\\${SHELL} '$am_aux_dir/missing'\"\nfi\n# Use eval to expand $SHELL\nif eval \"$MISSING --is-lightweight\"; then\n  am_missing_run=\"$MISSING \"\nelse\n  am_missing_run=\n  AC_MSG_WARN(['missing' script is too old or missing])\nfi\n])\n\n# Helper functions for option handling.                     -*- Autoconf -*-\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# _AM_MANGLE_OPTION(NAME)\n# -----------------------\nAC_DEFUN([_AM_MANGLE_OPTION],\n[[_AM_OPTION_]m4_bpatsubst($1, [[^a-zA-Z0-9_]], [_])])\n\n# _AM_SET_OPTION(NAME)\n# --------------------\n# Set option NAME.  Presently that only means defining a flag for this option.\nAC_DEFUN([_AM_SET_OPTION],\n[m4_define(_AM_MANGLE_OPTION([$1]), [1])])\n\n# _AM_SET_OPTIONS(OPTIONS)\n# ------------------------\n# OPTIONS is a space-separated list of Automake options.\nAC_DEFUN([_AM_SET_OPTIONS],\n[m4_foreach_w([_AM_Option], [$1], [_AM_SET_OPTION(_AM_Option)])])\n\n# _AM_IF_OPTION(OPTION, IF-SET, [IF-NOT-SET])\n# -------------------------------------------\n# Execute IF-SET if OPTION is set, IF-NOT-SET otherwise.\nAC_DEFUN([_AM_IF_OPTION],\n[m4_ifset(_AM_MANGLE_OPTION([$1]), [$2], [$3])])\n\n# Copyright (C) 1999-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# _AM_PROG_CC_C_O\n# ---------------\n# Like AC_PROG_CC_C_O, but changed for automake.  We rewrite AC_PROG_CC\n# to automatically call this.\nAC_DEFUN([_AM_PROG_CC_C_O],\n[AC_REQUIRE([AM_AUX_DIR_EXPAND])dnl\nAC_REQUIRE_AUX_FILE([compile])dnl\nAC_LANG_PUSH([C])dnl\nAC_CACHE_CHECK(\n  [whether $CC understands -c and -o together],\n  [am_cv_prog_cc_c_o],\n  [AC_LANG_CONFTEST([AC_LANG_PROGRAM([])])\n  # Make sure it works both with $CC and with simple cc.\n  # Following AC_PROG_CC_C_O, we do the test twice because some\n  # compilers refuse to overwrite an existing .o file with -o,\n  # though they will create one.\n  am_cv_prog_cc_c_o=yes\n  for am_i in 1 2; do\n    if AM_RUN_LOG([$CC -c conftest.$ac_ext -o conftest2.$ac_objext]) \\\n         && test -f conftest2.$ac_objext; then\n      : OK\n    else\n      am_cv_prog_cc_c_o=no\n      break\n    fi\n  done\n  rm -f core conftest*\n  unset am_i])\nif test \"$am_cv_prog_cc_c_o\" != yes; then\n   # Losing compiler, so override with the script.\n   # FIXME: It is wrong to rewrite CC.\n   # But if we don't then we get into trouble of one sort or another.\n   # A longer-term fix would be to have automake use am__CC in this case,\n   # and then we could set am__CC=\"\\$(top_srcdir)/compile \\$(CC)\"\n   CC=\"$am_aux_dir/compile $CC\"\nfi\nAC_LANG_POP([C])])\n\n# For backward compatibility.\nAC_DEFUN_ONCE([AM_PROG_CC_C_O], [AC_REQUIRE([AC_PROG_CC])])\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_RUN_LOG(COMMAND)\n# -------------------\n# Run COMMAND, save the exit status in ac_status, and log it.\n# (This has been adapted from Autoconf's _AC_RUN_LOG macro.)\nAC_DEFUN([AM_RUN_LOG],\n[{ echo \"$as_me:$LINENO: $1\" >&AS_MESSAGE_LOG_FD\n   ($1) >&AS_MESSAGE_LOG_FD 2>&AS_MESSAGE_LOG_FD\n   ac_status=$?\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   (exit $ac_status); }])\n\n# Check to make sure that the build environment is sane.    -*- Autoconf -*-\n\n# Copyright (C) 1996-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_SANITY_CHECK\n# ---------------\nAC_DEFUN([AM_SANITY_CHECK],\n[AC_MSG_CHECKING([whether build environment is sane])\n# Reject unsafe characters in $srcdir or the absolute working directory\n# name.  Accept space and tab only in the latter.\nam_lf='\n'\ncase `pwd` in\n  *[[\\\\\\\"\\#\\$\\&\\'\\`$am_lf]]*)\n    AC_MSG_ERROR([unsafe absolute working directory name]);;\nesac\ncase $srcdir in\n  *[[\\\\\\\"\\#\\$\\&\\'\\`$am_lf\\ \\\t]]*)\n    AC_MSG_ERROR([unsafe srcdir value: '$srcdir']);;\nesac\n\n# Do 'set' in a subshell so we don't clobber the current shell's\n# arguments.  Must try -L first in case configure is actually a\n# symlink; some systems play weird games with the mod time of symlinks\n# (eg FreeBSD returns the mod time of the symlink's containing\n# directory).\nif (\n   am_has_slept=no\n   for am_try in 1 2; do\n     echo \"timestamp, slept: $am_has_slept\" > conftest.file\n     set X `ls -Lt \"$srcdir/configure\" conftest.file 2> /dev/null`\n     if test \"$[*]\" = \"X\"; then\n\t# -L didn't work.\n\tset X `ls -t \"$srcdir/configure\" conftest.file`\n     fi\n     if test \"$[*]\" != \"X $srcdir/configure conftest.file\" \\\n\t&& test \"$[*]\" != \"X conftest.file $srcdir/configure\"; then\n\n\t# If neither matched, then we have a broken ls.  This can happen\n\t# if, for instance, CONFIG_SHELL is bash and it inherits a\n\t# broken ls alias from the environment.  This has actually\n\t# happened.  Such a system could not be considered \"sane\".\n\tAC_MSG_ERROR([ls -t appears to fail.  Make sure there is not a broken\n  alias in your environment])\n     fi\n     if test \"$[2]\" = conftest.file || test $am_try -eq 2; then\n       break\n     fi\n     # Just in case.\n     sleep 1\n     am_has_slept=yes\n   done\n   test \"$[2]\" = conftest.file\n   )\nthen\n   # Ok.\n   :\nelse\n   AC_MSG_ERROR([newly created file is older than distributed files!\nCheck your system clock])\nfi\nAC_MSG_RESULT([yes])\n# If we didn't sleep, we still need to ensure time stamps of config.status and\n# generated files are strictly newer.\nam_sleep_pid=\nif grep 'slept: no' conftest.file >/dev/null 2>&1; then\n  ( sleep 1 ) &\n  am_sleep_pid=$!\nfi\nAC_CONFIG_COMMANDS_PRE(\n  [AC_MSG_CHECKING([that generated files are newer than configure])\n   if test -n \"$am_sleep_pid\"; then\n     # Hide warnings about reused PIDs.\n     wait $am_sleep_pid 2>/dev/null\n   fi\n   AC_MSG_RESULT([done])])\nrm -f conftest.file\n])\n\n# Copyright (C) 2009-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_SILENT_RULES([DEFAULT])\n# --------------------------\n# Enable less verbose build rules; with the default set to DEFAULT\n# (\"yes\" being less verbose, \"no\" or empty being verbose).\nAC_DEFUN([AM_SILENT_RULES],\n[AC_ARG_ENABLE([silent-rules], [dnl\nAS_HELP_STRING(\n  [--enable-silent-rules],\n  [less verbose build output (undo: \"make V=1\")])\nAS_HELP_STRING(\n  [--disable-silent-rules],\n  [verbose build output (undo: \"make V=0\")])dnl\n])\ncase $enable_silent_rules in @%:@ (((\n  yes) AM_DEFAULT_VERBOSITY=0;;\n   no) AM_DEFAULT_VERBOSITY=1;;\n    *) AM_DEFAULT_VERBOSITY=m4_if([$1], [yes], [0], [1]);;\nesac\ndnl\ndnl A few 'make' implementations (e.g., NonStop OS and NextStep)\ndnl do not support nested variable expansions.\ndnl See automake bug#9928 and bug#10237.\nam_make=${MAKE-make}\nAC_CACHE_CHECK([whether $am_make supports nested variables],\n   [am_cv_make_support_nested_variables],\n   [if AS_ECHO([['TRUE=$(BAR$(V))\nBAR0=false\nBAR1=true\nV=1\nam__doit:\n\t@$(TRUE)\n.PHONY: am__doit']]) | $am_make -f - >/dev/null 2>&1; then\n  am_cv_make_support_nested_variables=yes\nelse\n  am_cv_make_support_nested_variables=no\nfi])\nif test $am_cv_make_support_nested_variables = yes; then\n  dnl Using '$V' instead of '$(V)' breaks IRIX make.\n  AM_V='$(V)'\n  AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'\nelse\n  AM_V=$AM_DEFAULT_VERBOSITY\n  AM_DEFAULT_V=$AM_DEFAULT_VERBOSITY\nfi\nAC_SUBST([AM_V])dnl\nAM_SUBST_NOTMAKE([AM_V])dnl\nAC_SUBST([AM_DEFAULT_V])dnl\nAM_SUBST_NOTMAKE([AM_DEFAULT_V])dnl\nAC_SUBST([AM_DEFAULT_VERBOSITY])dnl\nAM_BACKSLASH='\\'\nAC_SUBST([AM_BACKSLASH])dnl\n_AM_SUBST_NOTMAKE([AM_BACKSLASH])dnl\n])\n\n# Copyright (C) 2001-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# AM_PROG_INSTALL_STRIP\n# ---------------------\n# One issue with vendor 'install' (even GNU) is that you can't\n# specify the program used to strip binaries.  This is especially\n# annoying in cross-compiling environments, where the build's strip\n# is unlikely to handle the host's binaries.\n# Fortunately install-sh will honor a STRIPPROG variable, so we\n# always use install-sh in \"make install-strip\", and initialize\n# STRIPPROG with the value of the STRIP variable (set by the user).\nAC_DEFUN([AM_PROG_INSTALL_STRIP],\n[AC_REQUIRE([AM_PROG_INSTALL_SH])dnl\n# Installed binaries are usually stripped using 'strip' when the user\n# run \"make install-strip\".  However 'strip' might not be the right\n# tool to use in cross-compilation environments, therefore Automake\n# will honor the 'STRIP' environment variable to overrule this program.\ndnl Don't test for $cross_compiling = yes, because it might be 'maybe'.\nif test \"$cross_compiling\" != no; then\n  AC_CHECK_TOOL([STRIP], [strip], :)\nfi\nINSTALL_STRIP_PROGRAM=\"\\$(install_sh) -c -s\"\nAC_SUBST([INSTALL_STRIP_PROGRAM])])\n\n# Copyright (C) 2006-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# _AM_SUBST_NOTMAKE(VARIABLE)\n# ---------------------------\n# Prevent Automake from outputting VARIABLE = @VARIABLE@ in Makefile.in.\n# This macro is traced by Automake.\nAC_DEFUN([_AM_SUBST_NOTMAKE])\n\n# AM_SUBST_NOTMAKE(VARIABLE)\n# --------------------------\n# Public sister of _AM_SUBST_NOTMAKE.\nAC_DEFUN([AM_SUBST_NOTMAKE], [_AM_SUBST_NOTMAKE($@)])\n\n# Check how to create a tarball.                            -*- Autoconf -*-\n\n# Copyright (C) 2004-2021 Free Software Foundation, Inc.\n#\n# This file is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# _AM_PROG_TAR(FORMAT)\n# --------------------\n# Check how to create a tarball in format FORMAT.\n# FORMAT should be one of 'v7', 'ustar', or 'pax'.\n#\n# Substitute a variable $(am__tar) that is a command\n# writing to stdout a FORMAT-tarball containing the directory\n# $tardir.\n#     tardir=directory && $(am__tar) > result.tar\n#\n# Substitute a variable $(am__untar) that extract such\n# a tarball read from stdin.\n#     $(am__untar) < result.tar\n#\nAC_DEFUN([_AM_PROG_TAR],\n[# Always define AMTAR for backward compatibility.  Yes, it's still used\n# in the wild :-(  We should find a proper way to deprecate it ...\nAC_SUBST([AMTAR], ['$${TAR-tar}'])\n\n# We'll loop over all known methods to create a tar archive until one works.\n_am_tools='gnutar m4_if([$1], [ustar], [plaintar]) pax cpio none'\n\nm4_if([$1], [v7],\n  [am__tar='$${TAR-tar} chof - \"$$tardir\"' am__untar='$${TAR-tar} xf -'],\n\n  [m4_case([$1],\n    [ustar],\n     [# The POSIX 1988 'ustar' format is defined with fixed-size fields.\n      # There is notably a 21 bits limit for the UID and the GID.  In fact,\n      # the 'pax' utility can hang on bigger UID/GID (see automake bug#8343\n      # and bug#13588).\n      am_max_uid=2097151 # 2^21 - 1\n      am_max_gid=$am_max_uid\n      # The $UID and $GID variables are not portable, so we need to resort\n      # to the POSIX-mandated id(1) utility.  Errors in the 'id' calls\n      # below are definitely unexpected, so allow the users to see them\n      # (that is, avoid stderr redirection).\n      am_uid=`id -u || echo unknown`\n      am_gid=`id -g || echo unknown`\n      AC_MSG_CHECKING([whether UID '$am_uid' is supported by ustar format])\n      if test $am_uid -le $am_max_uid; then\n         AC_MSG_RESULT([yes])\n      else\n         AC_MSG_RESULT([no])\n         _am_tools=none\n      fi\n      AC_MSG_CHECKING([whether GID '$am_gid' is supported by ustar format])\n      if test $am_gid -le $am_max_gid; then\n         AC_MSG_RESULT([yes])\n      else\n        AC_MSG_RESULT([no])\n        _am_tools=none\n      fi],\n\n  [pax],\n    [],\n\n  [m4_fatal([Unknown tar format])])\n\n  AC_MSG_CHECKING([how to create a $1 tar archive])\n\n  # Go ahead even if we have the value already cached.  We do so because we\n  # need to set the values for the 'am__tar' and 'am__untar' variables.\n  _am_tools=${am_cv_prog_tar_$1-$_am_tools}\n\n  for _am_tool in $_am_tools; do\n    case $_am_tool in\n    gnutar)\n      for _am_tar in tar gnutar gtar; do\n        AM_RUN_LOG([$_am_tar --version]) && break\n      done\n      am__tar=\"$_am_tar --format=m4_if([$1], [pax], [posix], [$1]) -chf - \"'\"$$tardir\"'\n      am__tar_=\"$_am_tar --format=m4_if([$1], [pax], [posix], [$1]) -chf - \"'\"$tardir\"'\n      am__untar=\"$_am_tar -xf -\"\n      ;;\n    plaintar)\n      # Must skip GNU tar: if it does not support --format= it doesn't create\n      # ustar tarball either.\n      (tar --version) >/dev/null 2>&1 && continue\n      am__tar='tar chf - \"$$tardir\"'\n      am__tar_='tar chf - \"$tardir\"'\n      am__untar='tar xf -'\n      ;;\n    pax)\n      am__tar='pax -L -x $1 -w \"$$tardir\"'\n      am__tar_='pax -L -x $1 -w \"$tardir\"'\n      am__untar='pax -r'\n      ;;\n    cpio)\n      am__tar='find \"$$tardir\" -print | cpio -o -H $1 -L'\n      am__tar_='find \"$tardir\" -print | cpio -o -H $1 -L'\n      am__untar='cpio -i -H $1 -d'\n      ;;\n    none)\n      am__tar=false\n      am__tar_=false\n      am__untar=false\n      ;;\n    esac\n\n    # If the value was cached, stop now.  We just wanted to have am__tar\n    # and am__untar set.\n    test -n \"${am_cv_prog_tar_$1}\" && break\n\n    # tar/untar a dummy directory, and stop if the command works.\n    rm -rf conftest.dir\n    mkdir conftest.dir\n    echo GrepMe > conftest.dir/file\n    AM_RUN_LOG([tardir=conftest.dir && eval $am__tar_ >conftest.tar])\n    rm -rf conftest.dir\n    if test -s conftest.tar; then\n      AM_RUN_LOG([$am__untar <conftest.tar])\n      AM_RUN_LOG([cat conftest.dir/file])\n      grep GrepMe conftest.dir/file >/dev/null 2>&1 && break\n    fi\n  done\n  rm -rf conftest.dir\n\n  AC_CACHE_VAL([am_cv_prog_tar_$1], [am_cv_prog_tar_$1=$_am_tool])\n  AC_MSG_RESULT([$am_cv_prog_tar_$1])])\n\nAC_SUBST([am__tar])\nAC_SUBST([am__untar])\n]) # _AM_PROG_TAR\n\nm4_include([auxdir/ax_check_compile_flag.m4])\nm4_include([auxdir/ax_compare_version.m4])\nm4_include([auxdir/ax_gcc_builtin.m4])\nm4_include([auxdir/ax_have_epoll.m4])\nm4_include([auxdir/ax_lib_hdf5.m4])\nm4_include([auxdir/ax_pthread.m4])\nm4_include([auxdir/gtk-2.0.m4])\nm4_include([auxdir/libtool.m4])\nm4_include([auxdir/ltoptions.m4])\nm4_include([auxdir/ltsugar.m4])\nm4_include([auxdir/ltversion.m4])\nm4_include([auxdir/lt~obsolete.m4])\nm4_include([auxdir/slurm.m4])\nm4_include([auxdir/slurmrestd.m4])\nm4_include([auxdir/x_ac_affinity.m4])\nm4_include([auxdir/x_ac_c99.m4])\nm4_include([auxdir/x_ac_cgroup.m4])\nm4_include([auxdir/x_ac_curl.m4])\nm4_include([auxdir/x_ac_databases.m4])\nm4_include([auxdir/x_ac_debug.m4])\nm4_include([auxdir/x_ac_deprecated.m4])\nm4_include([auxdir/x_ac_env.m4])\nm4_include([auxdir/x_ac_freeipmi.m4])\nm4_include([auxdir/x_ac_hpe_slingshot.m4])\nm4_include([auxdir/x_ac_http_parser.m4])\nm4_include([auxdir/x_ac_hwloc.m4])\nm4_include([auxdir/x_ac_json.m4])\nm4_include([auxdir/x_ac_jwt.m4])\nm4_include([auxdir/x_ac_lua.m4])\nm4_include([auxdir/x_ac_lz4.m4])\nm4_include([auxdir/x_ac_man2html.m4])\nm4_include([auxdir/x_ac_munge.m4])\nm4_include([auxdir/x_ac_nvml.m4])\nm4_include([auxdir/x_ac_ofed.m4])\nm4_include([auxdir/x_ac_oneapi.m4])\nm4_include([auxdir/x_ac_pam.m4])\nm4_include([auxdir/x_ac_pkgconfig.m4])\nm4_include([auxdir/x_ac_pmix.m4])\nm4_include([auxdir/x_ac_printf_null.m4])\nm4_include([auxdir/x_ac_ptrace.m4])\nm4_include([auxdir/x_ac_rdkafka.m4])\nm4_include([auxdir/x_ac_readline.m4])\nm4_include([auxdir/x_ac_rsmi.m4])\nm4_include([auxdir/x_ac_s2n.m4])\nm4_include([auxdir/x_ac_selinux.m4])\nm4_include([auxdir/x_ac_setproctitle.m4])\nm4_include([auxdir/x_ac_sview.m4])\nm4_include([auxdir/x_ac_systemd.m4])\nm4_include([auxdir/x_ac_ucx.m4])\nm4_include([auxdir/x_ac_uid_gid_size.m4])\nm4_include([auxdir/x_ac_x11.m4])\nm4_include([auxdir/x_ac_yaml.m4])\n"
        },
        {
          "name": "auxdir",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.h.in",
          "type": "blob",
          "size": 14.5849609375,
          "content": "/* config.h.in.  Generated from configure.ac by autoheader.  */\n\n/* Define if building universal (internal helper macro) */\n#undef AC_APPLE_UNIVERSAL_BUILD\n\n/* Define to 1 for debugger partial task attach support. */\n#undef DEBUGGER_PARTIAL_ATTACH\n\n/* Define to 1 if using glib-2.32.0 or higher */\n#undef GLIB_NEW_THREADS\n\n/* Define to 1 if using gtk+-2.14.0 or higher */\n#undef GTK2_USE_GET_FOCUS\n\n/* Define to 1 if using gtk+-2.10.0 or higher */\n#undef GTK2_USE_RADIO_SET\n\n/* Define to 1 if using gtk+-2.12.0 or higher */\n#undef GTK2_USE_TOOLTIP\n\n/* Use the 1.8 HDF5 API */\n#undef H5_NO_DEPRECATED_SYMBOLS\n\n/* Make sure we get the 1.8 HDF5 API */\n#undef H5_USE_18_API\n\n/* Define if you are compiling with bpf. */\n#undef HAVE_BPF\n\n/* Define to 1 if you have the 'cfmakeraw' function. */\n#undef HAVE_CFMAKERAW\n\n/* Define to 1 if you have the declaration of 'hstrerror', and to 0 if you\n   don't. */\n#undef HAVE_DECL_HSTRERROR\n\n/* Define to 1 if you have the declaration of 'strerror_r', and to 0 if you\n   don't. */\n#undef HAVE_DECL_STRERROR_R\n\n/* Define to 1 if you have the declaration of 'strsignal', and to 0 if you\n   don't. */\n#undef HAVE_DECL_STRSIGNAL\n\n/* Define to 1 if you have the declaration of 'sys_siglist', and to 0 if you\n   don't. */\n#undef HAVE_DECL_SYS_SIGLIST\n\n/* Define to 1 if you have the <dirent.h> header file. */\n#undef HAVE_DIRENT_H\n\n/* Define to 1 if you have the <dlfcn.h> header file. */\n#undef HAVE_DLFCN_H\n\n/* Define to 1 if you have the 'eaccess' function. */\n#undef HAVE_EACCESS\n\n/* Define to 1 if we have epoll(7) support */\n#undef HAVE_EPOLL\n\n/* Define to 1 if you have the <errno.h> header file. */\n#undef HAVE_ERRNO_H\n\n/* Define to 1 if you have the 'faccessat' function. */\n#undef HAVE_FACCESSAT\n\n/* Define to 1 if you have the 'fdatasync' function. */\n#undef HAVE_FDATASYNC\n\n/* Define to 1 if you have the <float.h> header file. */\n#undef HAVE_FLOAT_H\n\n/* Define to 1 if freeipmi library found */\n#undef HAVE_FREEIPMI\n\n/* Define to 1 if running slurmd on front-end only */\n#undef HAVE_FRONT_END\n\n/* Define to 1 if you have the 'getrandom' function. */\n#undef HAVE_GETRANDOM\n\n/* Define to 1 if you have the 'get_current_dir_name' function. */\n#undef HAVE_GET_CURRENT_DIR_NAME\n\n/* Defined if you have HDF5 support */\n#undef HAVE_HDF5\n\n/* Define to 1 if you have the 'hstrerror' function. */\n#undef HAVE_HSTRERROR\n\n/* Define if you are compiling with HTTP parser. */\n#undef HAVE_HTTP_PARSER\n\n/* Define to 1 if hwloc library found */\n#undef HAVE_HWLOC\n\n/* Define to 1 if you have the 'inet_aton' function. */\n#undef HAVE_INET_ATON\n\n/* Define to 1 if you have the 'inet_ntop' function. */\n#undef HAVE_INET_NTOP\n\n/* Define to 1 if you have the 'inet_pton' function. */\n#undef HAVE_INET_PTON\n\n/* Define to 1 if you have the <inttypes.h> header file. */\n#undef HAVE_INTTYPES_H\n\n/* Define if you are compiling with json. */\n#undef HAVE_JSON\n\n/* Define if headers in include/json-c. */\n#undef HAVE_JSON_C_INC\n\n/* Define if headers in include/json. */\n#undef HAVE_JSON_INC\n\n/* Define if you are compiling with jwt. */\n#undef HAVE_JWT\n\n/* Define to 1 if you have the <kstat.h> header file. */\n#undef HAVE_KSTAT_H\n\n/* Define to 1 if you have a functional curl library. */\n#undef HAVE_LIBCURL\n\n/* Define to 1 if you have the 'ucp' library (-lucp). */\n#undef HAVE_LIBUCP\n\n/* Define to 1 if you have the <limits.h> header file. */\n#undef HAVE_LIMITS_H\n\n/* Define to 1 if you have the <linux/sched.h> header file. */\n#undef HAVE_LINUX_SCHED_H\n\n/* Define to 1 if we have the Lua library */\n#undef HAVE_LUA\n\n/* Define to 1 if you have 'lz4' library (-llz4) */\n#undef HAVE_LZ4\n\n/* Define to 1 if you have the <mcheck.h> header file. */\n#undef HAVE_MCHECK_H\n\n/* Define to 1 if you have the 'memfd_create' function. */\n#undef HAVE_MEMFD_CREATE\n\n/* Define to 1 if NVML library has MIG support */\n#undef HAVE_MIG_SUPPORT\n\n/* Define to 1 if you have the 'mtrace' function. */\n#undef HAVE_MTRACE\n\n/* Define to 1 if using MySQL libaries */\n#undef HAVE_MYSQL\n\n/* Define to 1 if you have the <netdb.h> header file. */\n#undef HAVE_NETDB_H\n\n/* define if numa library installed */\n#undef HAVE_NUMA\n\n/* Define to 1 if NVML library found */\n#undef HAVE_NVML\n\n/* Define to 1 if ofed library found */\n#undef HAVE_OFED\n\n/* Define to 1 if using code with pma_query_via */\n#undef HAVE_OFED_PMA_QUERY_VIA\n\n/* Define to 1 if oneAPI library found */\n#undef HAVE_ONEAPI\n\n/* define if you have the PAM library */\n#undef HAVE_PAM\n\n/* Define to 1 if you have the <pam/pam_appl.h> header file. */\n#undef HAVE_PAM_PAM_APPL_H\n\n/* Define to 1 if you have the <paths.h> header file. */\n#undef HAVE_PATHS_H\n\n/* Define to 1 if pmix library found */\n#undef HAVE_PMIX\n\n/* Define if libc sets program_invocation_name */\n#undef HAVE_PROGRAM_INVOCATION_NAME\n\n/* Define if you have POSIX threads libraries and header files. */\n#undef HAVE_PTHREAD\n\n/* Define to 1 if you have the <pthread.h> header file. */\n#undef HAVE_PTHREAD_H\n\n/* Have PTHREAD_PRIO_INHERIT. */\n#undef HAVE_PTHREAD_PRIO_INHERIT\n\n/* Define to 1 if you have the 'ptrace64' function. */\n#undef HAVE_PTRACE64\n\n/* Define to 1 if you have the <pty.h> header file. */\n#undef HAVE_PTY_H\n\n/* Define to 1 if librdkafka library found */\n#undef HAVE_RDKAFKA\n\n/* Define if you are compiling with readline. */\n#undef HAVE_READLINE\n\n/* Define to 1 if RSMI library found */\n#undef HAVE_RSMI\n\n/* Define to 1 if s2n library found. */\n#undef HAVE_S2N\n\n/* Define to 1 if you have the <security/pam_appl.h> header file. */\n#undef HAVE_SECURITY_PAM_APPL_H\n\n/* Define to 1 if you have the 'setproctitle' function. */\n#undef HAVE_SETPROCTITLE\n\n/* Define to 1 if you have the 'setresuid' function. */\n#undef HAVE_SETRESUID\n\n/* Define to 1 if you have the <socket.h> header file. */\n#undef HAVE_SOCKET_H\n\n/* Define to 1 if you have the 'statfs' function. */\n#undef HAVE_STATFS\n\n/* Define to 1 if you have the 'statvfs' function. */\n#undef HAVE_STATVFS\n\n/* Define to 1 if you have the <stdbool.h> header file. */\n#undef HAVE_STDBOOL_H\n\n/* Define to 1 if you have the <stdint.h> header file. */\n#undef HAVE_STDINT_H\n\n/* Define to 1 if you have the <stdio.h> header file. */\n#undef HAVE_STDIO_H\n\n/* Define to 1 if you have the <stdlib.h> header file. */\n#undef HAVE_STDLIB_H\n\n/* Define to 1 if you have the 'strerror' function. */\n#undef HAVE_STRERROR\n\n/* Define if you have 'strerror_r'. */\n#undef HAVE_STRERROR_R\n\n/* Define to 1 if you have the <strings.h> header file. */\n#undef HAVE_STRINGS_H\n\n/* Define to 1 if you have the <string.h> header file. */\n#undef HAVE_STRING_H\n\n/* Define to 1 if you have the 'strlcpy' function. */\n#undef HAVE_STRLCPY\n\n/* Define to 1 if you have the 'strndup' function. */\n#undef HAVE_STRNDUP\n\n/* Define to 1 if you have the 'strsignal' function. */\n#undef HAVE_STRSIGNAL\n\n/* Define to 1 if the system has the type 'struct cxi_rsrc_use'. */\n#undef HAVE_STRUCT_CXI_RSRC_USE\n\n/* Define to 1 if you have the 'sysctlbyname' function. */\n#undef HAVE_SYSCTLBYNAME\n\n/* Define to 1 if you have the <sysint.h> header file. */\n#undef HAVE_SYSINT_H\n\n/* Define systemd presence */\n#undef HAVE_SYSTEMD\n\n/* Define to 1 if you have the <sys/dr.h> header file. */\n#undef HAVE_SYS_DR_H\n\n/* Define to 1 if you have the <sys/ipc.h> header file. */\n#undef HAVE_SYS_IPC_H\n\n/* Define to 1 if you have the <sys/prctl.h> header file. */\n#undef HAVE_SYS_PRCTL_H\n\n/* Define to 1 if you have the <sys/ptrace.h> header file. */\n#undef HAVE_SYS_PTRACE_H\n\n/* Define to 1 if you have the <sys/sem.h> header file. */\n#undef HAVE_SYS_SEM_H\n\n/* Define to 1 if you have the <sys/shm.h> header file. */\n#undef HAVE_SYS_SHM_H\n\n/* Define to 1 if you have the <sys/socket.h> header file. */\n#undef HAVE_SYS_SOCKET_H\n\n/* Define to 1 if you have the <sys/statfs.h> header file. */\n#undef HAVE_SYS_STATFS_H\n\n/* Define to 1 if you have the <sys/statvfs.h> header file. */\n#undef HAVE_SYS_STATVFS_H\n\n/* Define to 1 if you have the <sys/stat.h> header file. */\n#undef HAVE_SYS_STAT_H\n\n/* Define to 1 if you have the <sys/sysctl.h> header file. */\n#undef HAVE_SYS_SYSCTL_H\n\n/* Define to 1 if you have the <sys/syslog.h> header file. */\n#undef HAVE_SYS_SYSLOG_H\n\n/* Define to 1 if you have the <sys/systemcfg.h> header file. */\n#undef HAVE_SYS_SYSTEMCFG_H\n\n/* Define to 1 if you have the <sys/types.h> header file. */\n#undef HAVE_SYS_TYPES_H\n\n/* Define to 1 if you have the <sys/vfs.h> header file. */\n#undef HAVE_SYS_VFS_H\n\n/* Define to 1 if you have <sys/wait.h> that is POSIX.1 compatible. */\n#undef HAVE_SYS_WAIT_H\n\n/* Define to 1 if you have the <termcap.h> header file. */\n#undef HAVE_TERMCAP_H\n\n/* Define to 1 if ucx library found */\n#undef HAVE_UCX\n\n/* Define to 1 if you have the <unistd.h> header file. */\n#undef HAVE_UNISTD_H\n\n/* Define to 1 if you have the <utmp.h> header file. */\n#undef HAVE_UTMP_H\n\n/* Define to 1 if you have the <values.h> header file. */\n#undef HAVE_VALUES_H\n\n/* Define if you are compiling with libyaml parser. */\n#undef HAVE_YAML\n\n/* Define if you have __progname. */\n#undef HAVE__PROGNAME\n\n/* Define to 1 if the system has the `__builtin_bswap64' built-in function */\n#undef HAVE___BUILTIN_BSWAP64\n\n/* Define to 1 if the system has the `__builtin_clzll' built-in function */\n#undef HAVE___BUILTIN_CLZLL\n\n/* Define to 1 if the system has the `__builtin_ctzll' built-in function */\n#undef HAVE___BUILTIN_CTZLL\n\n/* Define to 1 if the system has the `__builtin_popcountll' built-in function\n   */\n#undef HAVE___BUILTIN_POPCOUNTLL\n\n/* Full path of libcxi.so */\n#undef HPE_SLINGSHOT_LIB\n\n/* Defined if libcurl supports AsynchDNS */\n#undef LIBCURL_FEATURE_ASYNCHDNS\n\n/* Defined if libcurl supports IDN */\n#undef LIBCURL_FEATURE_IDN\n\n/* Defined if libcurl supports IPv6 */\n#undef LIBCURL_FEATURE_IPV6\n\n/* Defined if libcurl supports KRB4 */\n#undef LIBCURL_FEATURE_KRB4\n\n/* Defined if libcurl supports libz */\n#undef LIBCURL_FEATURE_LIBZ\n\n/* Defined if libcurl supports NTLM */\n#undef LIBCURL_FEATURE_NTLM\n\n/* Defined if libcurl supports SSL */\n#undef LIBCURL_FEATURE_SSL\n\n/* Defined if libcurl supports SSPI */\n#undef LIBCURL_FEATURE_SSPI\n\n/* Defined if libcurl supports DICT */\n#undef LIBCURL_PROTOCOL_DICT\n\n/* Defined if libcurl supports FILE */\n#undef LIBCURL_PROTOCOL_FILE\n\n/* Defined if libcurl supports FTP */\n#undef LIBCURL_PROTOCOL_FTP\n\n/* Defined if libcurl supports FTPS */\n#undef LIBCURL_PROTOCOL_FTPS\n\n/* Defined if libcurl supports HTTP */\n#undef LIBCURL_PROTOCOL_HTTP\n\n/* Defined if libcurl supports HTTPS */\n#undef LIBCURL_PROTOCOL_HTTPS\n\n/* Defined if libcurl supports IMAP */\n#undef LIBCURL_PROTOCOL_IMAP\n\n/* Defined if libcurl supports LDAP */\n#undef LIBCURL_PROTOCOL_LDAP\n\n/* Defined if libcurl supports POP3 */\n#undef LIBCURL_PROTOCOL_POP3\n\n/* Defined if libcurl supports RTSP */\n#undef LIBCURL_PROTOCOL_RTSP\n\n/* Defined if libcurl supports SMTP */\n#undef LIBCURL_PROTOCOL_SMTP\n\n/* Defined if libcurl supports TELNET */\n#undef LIBCURL_PROTOCOL_TELNET\n\n/* Defined if libcurl supports TFTP */\n#undef LIBCURL_PROTOCOL_TFTP\n\n/* Define to 1 for --get-user-env to load user environment without .login */\n#undef LOAD_ENV_NO_LOGIN\n\n/* Define to the sub-directory where libtool stores uninstalled libraries. */\n#undef LT_OBJDIR\n\n/* Define to 1 if 'major', 'minor', and 'makedev' are declared in <mkdev.h>.\n   */\n#undef MAJOR_IN_MKDEV\n\n/* Define to 1 if 'major', 'minor', and 'makedev' are declared in\n   <sysmacros.h>. */\n#undef MAJOR_IN_SYSMACROS\n\n/* Define to 1 for memory leak debugging. */\n#undef MEMORY_LEAK_DEBUG\n\n/* Enable multiple slurmd on one node */\n#undef MULTIPLE_SLURMD\n\n/* Define to 1 if you are building a production release. */\n#undef NDEBUG\n\n/* Define to the address where bug reports for this package should be sent. */\n#undef PACKAGE_BUGREPORT\n\n/* Define to the full name of this package. */\n#undef PACKAGE_NAME\n\n/* Define to the full name and version of this package. */\n#undef PACKAGE_STRING\n\n/* Define to the one symbol short name of this package. */\n#undef PACKAGE_TARNAME\n\n/* Define to the home page for this package. */\n#undef PACKAGE_URL\n\n/* Define to the version of this package. */\n#undef PACKAGE_VERSION\n\n/* Define PAM module installation directory. */\n#undef PAM_DIR\n\n/* Define the project's name. */\n#undef PROJECT\n\n/* Define to necessary symbol if this constant uses a non-standard name on\n   your system. */\n#undef PTHREAD_CREATE_JOINABLE\n\n/* Define to 1 if ptrace takes five arguments. */\n#undef PTRACE_FIVE_ARGS\n\n/* Define the project's release. */\n#undef RELEASE\n\n/* Define to 1 for salloc to kill child processes at job termination */\n#undef SALLOC_KILL_CMD\n\n/* Define if you need setproctitle padding */\n#undef SETPROCTITLE_PS_PADDING\n\n/* Define to the setproctitle() emulation type */\n#undef SETPROCTITLE_STRATEGY\n\n/* The size of 'void *', as computed by sizeof. */\n#undef SIZEOF_VOID_P\n\n/* Define path to sleep command */\n#undef SLEEP_CMD\n\n/* Define the default port number for slurmctld */\n#undef SLURMCTLD_PORT\n\n/* Define the default port count for slurmctld */\n#undef SLURMCTLD_PORT_COUNT\n\n/* Define the default port number for slurmdbd */\n#undef SLURMDBD_PORT\n\n/* Define the default port number for slurmd */\n#undef SLURMD_PORT\n\n/* Define the default port number for slurmrestd */\n#undef SLURMRESTD_PORT\n\n/* API current age */\n#undef SLURM_API_AGE\n\n/* API current version */\n#undef SLURM_API_CURRENT\n\n/* API current major */\n#undef SLURM_API_MAJOR\n\n/* API current rev */\n#undef SLURM_API_REVISION\n\n/* Define the API's version */\n#undef SLURM_API_VERSION\n\n/* Define if your architecture's byteorder is big endian. */\n#undef SLURM_BIGENDIAN\n\n/* Define the project's major version. */\n#undef SLURM_MAJOR\n\n/* Define the project's micro version. */\n#undef SLURM_MICRO\n\n/* Define the project's minor version. */\n#undef SLURM_MINOR\n\n/* Define Slurm installation prefix */\n#undef SLURM_PREFIX\n\n/* Slurm Version Number */\n#undef SLURM_VERSION_NUMBER\n\n/* Define the project's version string. */\n#undef SLURM_VERSION_STRING\n\n/* Define to 1 if all of the C89 standard headers exist (not just the ones\n   required in a freestanding environment). This macro is provided for\n   backward compatibility; new code need not use it. */\n#undef STDC_HEADERS\n\n/* Define to 1 if strerror_r returns char *. */\n#undef STRERROR_R_CHAR_P\n\n/* Define path to su command */\n#undef SUCMD\n\n/* Define system dimension count */\n#undef SYSTEM_DIMENSIONS\n\n/* Define slurm_ prefix function aliases for plugins */\n#undef USE_ALIAS\n\n/* Define the project's version. */\n#undef VERSION\n\n/* Building with Linux cgroup support */\n#undef WITH_CGROUP\n\n/* Using internal Slurm SELinux support */\n#undef WITH_SELINUX\n\n/* Using internal Slurm X11 support */\n#undef WITH_SLURM_X11\n\n/* Define WORDS_BIGENDIAN to 1 if your processor stores words with the most\n   significant byte first (like Motorola and SPARC, unlike Intel). */\n#if defined AC_APPLE_UNIVERSAL_BUILD\n# if defined __BIG_ENDIAN__\n#  define WORDS_BIGENDIAN 1\n# endif\n#else\n# ifndef WORDS_BIGENDIAN\n#  undef WORDS_BIGENDIAN\n# endif\n#endif\n\n/* Define curl_free() as free() if our version of curl lacks curl_free. */\n#undef curl_free\n"
        },
        {
          "name": "configure",
          "type": "blob",
          "size": 957.6640625,
          "content": "#! /bin/sh\n# Guess values for system-dependent variables and create Makefiles.\n# Generated by GNU Autoconf 2.72 for slurm 25.05.\n#\n#\n# Copyright (C) 1992-1996, 1998-2017, 2020-2023 Free Software Foundation,\n# Inc.\n#\n#\n# This configure script is free software; the Free Software Foundation\n# gives unlimited permission to copy, distribute and modify it.\n## -------------------- ##\n## M4sh Initialization. ##\n## -------------------- ##\n\n# Be more Bourne compatible\nDUALCASE=1; export DUALCASE # for MKS sh\nif test ${ZSH_VERSION+y} && (emulate sh) >/dev/null 2>&1\nthen :\n  emulate sh\n  NULLCMD=:\n  # Pre-4.2 versions of Zsh do word splitting on ${1+\"$@\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '${1+\"$@\"}'='\"$@\"'\n  setopt NO_GLOB_SUBST\nelse case e in #(\n  e) case `(set -o) 2>/dev/null` in #(\n  *posix*) :\n    set -o posix ;; #(\n  *) :\n     ;;\nesac ;;\nesac\nfi\n\n\n\n# Reset variables that may have inherited troublesome values from\n# the environment.\n\n# IFS needs to be set, to space, tab, and newline, in precisely that order.\n# (If _AS_PATH_WALK were called with IFS unset, it would have the\n# side effect of setting IFS to empty, thus disabling word splitting.)\n# Quoting is to prevent editors from complaining about space-tab.\nas_nl='\n'\nexport as_nl\nIFS=\" \"\"\t$as_nl\"\n\nPS1='$ '\nPS2='> '\nPS4='+ '\n\n# Ensure predictable behavior from utilities with locale-dependent output.\nLC_ALL=C\nexport LC_ALL\nLANGUAGE=C\nexport LANGUAGE\n\n# We cannot yet rely on \"unset\" to work, but we need these variables\n# to be unset--not just set to an empty or harmless value--now, to\n# avoid bugs in old shells (e.g. pre-3.0 UWIN ksh).  This construct\n# also avoids known problems related to \"unset\" and subshell syntax\n# in other old shells (e.g. bash 2.01 and pdksh 5.2.14).\nfor as_var in BASH_ENV ENV MAIL MAILPATH CDPATH\ndo eval test \\${$as_var+y} \\\n  && ( (unset $as_var) || exit 1) >/dev/null 2>&1 && unset $as_var || :\ndone\n\n# Ensure that fds 0, 1, and 2 are open.\nif (exec 3>&0) 2>/dev/null; then :; else exec 0</dev/null; fi\nif (exec 3>&1) 2>/dev/null; then :; else exec 1>/dev/null; fi\nif (exec 3>&2)            ; then :; else exec 2>/dev/null; fi\n\n# The user is always right.\nif ${PATH_SEPARATOR+false} :; then\n  PATH_SEPARATOR=:\n  (PATH='/bin;/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 && {\n    (PATH='/bin:/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 ||\n      PATH_SEPARATOR=';'\n  }\nfi\n\n\n# Find who we are.  Look in the path if we contain no directory separator.\nas_myself=\ncase $0 in #((\n  *[\\\\/]* ) as_myself=$0 ;;\n  *) as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    test -r \"$as_dir$0\" && as_myself=$as_dir$0 && break\n  done\nIFS=$as_save_IFS\n\n     ;;\nesac\n# We did not find ourselves, most probably we were run as 'sh COMMAND'\n# in which case we are not to be found in the path.\nif test \"x$as_myself\" = x; then\n  as_myself=$0\nfi\nif test ! -f \"$as_myself\"; then\n  printf \"%s\\n\" \"$as_myself: error: cannot find myself; rerun with an absolute file name\" >&2\n  exit 1\nfi\n\n\n# Use a proper internal environment variable to ensure we don't fall\n  # into an infinite loop, continuously re-executing ourselves.\n  if test x\"${_as_can_reexec}\" != xno && test \"x$CONFIG_SHELL\" != x; then\n    _as_can_reexec=no; export _as_can_reexec;\n    # We cannot yet assume a decent shell, so we have to provide a\n# neutralization value for shells without unset; and this also\n# works around shells that cannot unset nonexistent variables.\n# Preserve -v and -x to the replacement shell.\nBASH_ENV=/dev/null\nENV=/dev/null\n(unset BASH_ENV) >/dev/null 2>&1 && unset BASH_ENV ENV\ncase $- in # ((((\n  *v*x* | *x*v* ) as_opts=-vx ;;\n  *v* ) as_opts=-v ;;\n  *x* ) as_opts=-x ;;\n  * ) as_opts= ;;\nesac\nexec $CONFIG_SHELL $as_opts \"$as_myself\" ${1+\"$@\"}\n# Admittedly, this is quite paranoid, since all the known shells bail\n# out after a failed 'exec'.\nprintf \"%s\\n\" \"$0: could not re-execute with $CONFIG_SHELL\" >&2\nexit 255\n  fi\n  # We don't want this to propagate to other subprocesses.\n          { _as_can_reexec=; unset _as_can_reexec;}\nif test \"x$CONFIG_SHELL\" = x; then\n  as_bourne_compatible=\"if test \\${ZSH_VERSION+y} && (emulate sh) >/dev/null 2>&1\nthen :\n  emulate sh\n  NULLCMD=:\n  # Pre-4.2 versions of Zsh do word splitting on \\${1+\\\"\\$@\\\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '\\${1+\\\"\\$@\\\"}'='\\\"\\$@\\\"'\n  setopt NO_GLOB_SUBST\nelse case e in #(\n  e) case \\`(set -o) 2>/dev/null\\` in #(\n  *posix*) :\n    set -o posix ;; #(\n  *) :\n     ;;\nesac ;;\nesac\nfi\n\"\n  as_required=\"as_fn_return () { (exit \\$1); }\nas_fn_success () { as_fn_return 0; }\nas_fn_failure () { as_fn_return 1; }\nas_fn_ret_success () { return 0; }\nas_fn_ret_failure () { return 1; }\n\nexitcode=0\nas_fn_success || { exitcode=1; echo as_fn_success failed.; }\nas_fn_failure && { exitcode=1; echo as_fn_failure succeeded.; }\nas_fn_ret_success || { exitcode=1; echo as_fn_ret_success failed.; }\nas_fn_ret_failure && { exitcode=1; echo as_fn_ret_failure succeeded.; }\nif ( set x; as_fn_ret_success y && test x = \\\"\\$1\\\" )\nthen :\n\nelse case e in #(\n  e) exitcode=1; echo positional parameters were not saved. ;;\nesac\nfi\ntest x\\$exitcode = x0 || exit 1\nblah=\\$(echo \\$(echo blah))\ntest x\\\"\\$blah\\\" = xblah || exit 1\ntest -x / || exit 1\"\n  as_suggested=\"  as_lineno_1=\";as_suggested=$as_suggested$LINENO;as_suggested=$as_suggested\" as_lineno_1a=\\$LINENO\n  as_lineno_2=\";as_suggested=$as_suggested$LINENO;as_suggested=$as_suggested\" as_lineno_2a=\\$LINENO\n  eval 'test \\\"x\\$as_lineno_1'\\$as_run'\\\" != \\\"x\\$as_lineno_2'\\$as_run'\\\" &&\n  test \\\"x\\`expr \\$as_lineno_1'\\$as_run' + 1\\`\\\" = \\\"x\\$as_lineno_2'\\$as_run'\\\"' || exit 1\n\n  test -n \\\"\\${ZSH_VERSION+set}\\${BASH_VERSION+set}\\\" || (\n    ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\n    ECHO=\\$ECHO\\$ECHO\\$ECHO\\$ECHO\\$ECHO\n    ECHO=\\$ECHO\\$ECHO\\$ECHO\\$ECHO\\$ECHO\\$ECHO\n    PATH=/empty FPATH=/empty; export PATH FPATH\n    test \\\"X\\`printf %s \\$ECHO\\`\\\" = \\\"X\\$ECHO\\\" \\\\\n      || test \\\"X\\`print -r -- \\$ECHO\\`\\\" = \\\"X\\$ECHO\\\" ) || exit 1\ntest \\$(( 1 + 1 )) = 2 || exit 1\"\n  if (eval \"$as_required\") 2>/dev/null\nthen :\n  as_have_required=yes\nelse case e in #(\n  e) as_have_required=no ;;\nesac\nfi\n  if test x$as_have_required = xyes && (eval \"$as_suggested\") 2>/dev/null\nthen :\n\nelse case e in #(\n  e) as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nas_found=false\nfor as_dir in /bin$PATH_SEPARATOR/usr/bin$PATH_SEPARATOR$PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n  as_found=:\n  case $as_dir in #(\n\t /*)\n\t   for as_base in sh bash ksh sh5; do\n\t     # Try only shells that exist, to save several forks.\n\t     as_shell=$as_dir$as_base\n\t     if { test -f \"$as_shell\" || test -f \"$as_shell.exe\"; } &&\n\t\t    as_run=a \"$as_shell\" -c \"$as_bourne_compatible\"\"$as_required\" 2>/dev/null\nthen :\n  CONFIG_SHELL=$as_shell as_have_required=yes\n\t\t   if as_run=a \"$as_shell\" -c \"$as_bourne_compatible\"\"$as_suggested\" 2>/dev/null\nthen :\n  break 2\nfi\nfi\n\t   done;;\n       esac\n  as_found=false\ndone\nIFS=$as_save_IFS\nif $as_found\nthen :\n\nelse case e in #(\n  e) if { test -f \"$SHELL\" || test -f \"$SHELL.exe\"; } &&\n\t      as_run=a \"$SHELL\" -c \"$as_bourne_compatible\"\"$as_required\" 2>/dev/null\nthen :\n  CONFIG_SHELL=$SHELL as_have_required=yes\nfi ;;\nesac\nfi\n\n\n      if test \"x$CONFIG_SHELL\" != x\nthen :\n  export CONFIG_SHELL\n             # We cannot yet assume a decent shell, so we have to provide a\n# neutralization value for shells without unset; and this also\n# works around shells that cannot unset nonexistent variables.\n# Preserve -v and -x to the replacement shell.\nBASH_ENV=/dev/null\nENV=/dev/null\n(unset BASH_ENV) >/dev/null 2>&1 && unset BASH_ENV ENV\ncase $- in # ((((\n  *v*x* | *x*v* ) as_opts=-vx ;;\n  *v* ) as_opts=-v ;;\n  *x* ) as_opts=-x ;;\n  * ) as_opts= ;;\nesac\nexec $CONFIG_SHELL $as_opts \"$as_myself\" ${1+\"$@\"}\n# Admittedly, this is quite paranoid, since all the known shells bail\n# out after a failed 'exec'.\nprintf \"%s\\n\" \"$0: could not re-execute with $CONFIG_SHELL\" >&2\nexit 255\nfi\n\n    if test x$as_have_required = xno\nthen :\n  printf \"%s\\n\" \"$0: This script requires a shell more modern than all\"\n  printf \"%s\\n\" \"$0: the shells that I found on your system.\"\n  if test ${ZSH_VERSION+y} ; then\n    printf \"%s\\n\" \"$0: In particular, zsh $ZSH_VERSION has bugs and should\"\n    printf \"%s\\n\" \"$0: be upgraded to zsh 4.3.4 or later.\"\n  else\n    printf \"%s\\n\" \"$0: Please tell bug-autoconf@gnu.org about your system,\n$0: including any error possibly output before this\n$0: message. Then install a modern shell, or manually run\n$0: the script under such a shell if you do have one.\"\n  fi\n  exit 1\nfi ;;\nesac\nfi\nfi\nSHELL=${CONFIG_SHELL-/bin/sh}\nexport SHELL\n# Unset more variables known to interfere with behavior of common tools.\nCLICOLOR_FORCE= GREP_OPTIONS=\nunset CLICOLOR_FORCE GREP_OPTIONS\n\n## --------------------- ##\n## M4sh Shell Functions. ##\n## --------------------- ##\n# as_fn_unset VAR\n# ---------------\n# Portably unset VAR.\nas_fn_unset ()\n{\n  { eval $1=; unset $1;}\n}\nas_unset=as_fn_unset\n\n\n# as_fn_set_status STATUS\n# -----------------------\n# Set $? to STATUS, without forking.\nas_fn_set_status ()\n{\n  return $1\n} # as_fn_set_status\n\n# as_fn_exit STATUS\n# -----------------\n# Exit the shell with STATUS, even in a \"trap 0\" or \"set -e\" context.\nas_fn_exit ()\n{\n  set +e\n  as_fn_set_status $1\n  exit $1\n} # as_fn_exit\n\n# as_fn_mkdir_p\n# -------------\n# Create \"$as_dir\" as a directory, including parents if necessary.\nas_fn_mkdir_p ()\n{\n\n  case $as_dir in #(\n  -*) as_dir=./$as_dir;;\n  esac\n  test -d \"$as_dir\" || eval $as_mkdir_p || {\n    as_dirs=\n    while :; do\n      case $as_dir in #(\n      *\\'*) as_qdir=`printf \"%s\\n\" \"$as_dir\" | sed \"s/'/'\\\\\\\\\\\\\\\\''/g\"`;; #'(\n      *) as_qdir=$as_dir;;\n      esac\n      as_dirs=\"'$as_qdir' $as_dirs\"\n      as_dir=`$as_dirname -- \"$as_dir\" ||\n$as_expr X\"$as_dir\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\n\t X\"$as_dir\" : 'X\\(//\\)[^/]' \\| \\\n\t X\"$as_dir\" : 'X\\(//\\)$' \\| \\\n\t X\"$as_dir\" : 'X\\(/\\)' \\| . 2>/dev/null ||\nprintf \"%s\\n\" X\"$as_dir\" |\n    sed '/^X\\(.*[^/]\\)\\/\\/*[^/][^/]*\\/*$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\/\\)[^/].*/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\/\\)$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\).*/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  s/.*/./; q'`\n      test -d \"$as_dir\" && break\n    done\n    test -z \"$as_dirs\" || eval \"mkdir $as_dirs\"\n  } || test -d \"$as_dir\" || as_fn_error $? \"cannot create directory $as_dir\"\n\n\n} # as_fn_mkdir_p\n\n# as_fn_executable_p FILE\n# -----------------------\n# Test if FILE is an executable regular file.\nas_fn_executable_p ()\n{\n  test -f \"$1\" && test -x \"$1\"\n} # as_fn_executable_p\n# as_fn_append VAR VALUE\n# ----------------------\n# Append the text in VALUE to the end of the definition contained in VAR. Take\n# advantage of any shell optimizations that allow amortized linear growth over\n# repeated appends, instead of the typical quadratic growth present in naive\n# implementations.\nif (eval \"as_var=1; as_var+=2; test x\\$as_var = x12\") 2>/dev/null\nthen :\n  eval 'as_fn_append ()\n  {\n    eval $1+=\\$2\n  }'\nelse case e in #(\n  e) as_fn_append ()\n  {\n    eval $1=\\$$1\\$2\n  } ;;\nesac\nfi # as_fn_append\n\n# as_fn_arith ARG...\n# ------------------\n# Perform arithmetic evaluation on the ARGs, and store the result in the\n# global $as_val. Take advantage of shells that can avoid forks. The arguments\n# must be portable across $(()) and expr.\nif (eval \"test \\$(( 1 + 1 )) = 2\") 2>/dev/null\nthen :\n  eval 'as_fn_arith ()\n  {\n    as_val=$(( $* ))\n  }'\nelse case e in #(\n  e) as_fn_arith ()\n  {\n    as_val=`expr \"$@\" || test $? -eq 1`\n  } ;;\nesac\nfi # as_fn_arith\n\n\n# as_fn_error STATUS ERROR [LINENO LOG_FD]\n# ----------------------------------------\n# Output \"`basename $0`: error: ERROR\" to stderr. If LINENO and LOG_FD are\n# provided, also output the error to LOG_FD, referencing LINENO. Then exit the\n# script with STATUS, using 1 if that was 0.\nas_fn_error ()\n{\n  as_status=$1; test $as_status -eq 0 && as_status=1\n  if test \"$4\"; then\n    as_lineno=${as_lineno-\"$3\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: $2\" >&$4\n  fi\n  printf \"%s\\n\" \"$as_me: error: $2\" >&2\n  as_fn_exit $as_status\n} # as_fn_error\n\nif expr a : '\\(a\\)' >/dev/null 2>&1 &&\n   test \"X`expr 00001 : '.*\\(...\\)'`\" = X001; then\n  as_expr=expr\nelse\n  as_expr=false\nfi\n\nif (basename -- /) >/dev/null 2>&1 && test \"X`basename -- / 2>&1`\" = \"X/\"; then\n  as_basename=basename\nelse\n  as_basename=false\nfi\n\nif (as_dir=`dirname -- /` && test \"X$as_dir\" = X/) >/dev/null 2>&1; then\n  as_dirname=dirname\nelse\n  as_dirname=false\nfi\n\nas_me=`$as_basename -- \"$0\" ||\n$as_expr X/\"$0\" : '.*/\\([^/][^/]*\\)/*$' \\| \\\n\t X\"$0\" : 'X\\(//\\)$' \\| \\\n\t X\"$0\" : 'X\\(/\\)' \\| . 2>/dev/null ||\nprintf \"%s\\n\" X/\"$0\" |\n    sed '/^.*\\/\\([^/][^/]*\\)\\/*$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\/\\(\\/\\/\\)$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\/\\(\\/\\).*/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  s/.*/./; q'`\n\n# Avoid depending upon Character Ranges.\nas_cr_letters='abcdefghijklmnopqrstuvwxyz'\nas_cr_LETTERS='ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nas_cr_Letters=$as_cr_letters$as_cr_LETTERS\nas_cr_digits='0123456789'\nas_cr_alnum=$as_cr_Letters$as_cr_digits\n\n\n  as_lineno_1=$LINENO as_lineno_1a=$LINENO\n  as_lineno_2=$LINENO as_lineno_2a=$LINENO\n  eval 'test \"x$as_lineno_1'$as_run'\" != \"x$as_lineno_2'$as_run'\" &&\n  test \"x`expr $as_lineno_1'$as_run' + 1`\" = \"x$as_lineno_2'$as_run'\"' || {\n  # Blame Lee E. McMahon (1931-1989) for sed's syntax.  :-)\n  sed -n '\n    p\n    /[$]LINENO/=\n  ' <$as_myself |\n    sed '\n      t clear\n      :clear\n      s/[$]LINENO.*/&-/\n      t lineno\n      b\n      :lineno\n      N\n      :loop\n      s/[$]LINENO\\([^'$as_cr_alnum'_].*\\n\\)\\(.*\\)/\\2\\1\\2/\n      t loop\n      s/-\\n.*//\n    ' >$as_me.lineno &&\n  chmod +x \"$as_me.lineno\" ||\n    { printf \"%s\\n\" \"$as_me: error: cannot create $as_me.lineno; rerun with a POSIX shell\" >&2; as_fn_exit 1; }\n\n  # If we had to re-execute with $CONFIG_SHELL, we're ensured to have\n  # already done that, so ensure we don't try to do so again and fall\n  # in an infinite loop.  This has already happened in practice.\n  _as_can_reexec=no; export _as_can_reexec\n  # Don't try to exec as it changes $[0], causing all sort of problems\n  # (the dirname of $[0] is not the place where we might find the\n  # original and so on.  Autoconf is especially sensitive to this).\n  . \"./$as_me.lineno\"\n  # Exit status is that of the last command.\n  exit\n}\n\n\n# Determine whether it's possible to make 'echo' print without a newline.\n# These variables are no longer used directly by Autoconf, but are AC_SUBSTed\n# for compatibility with existing Makefiles.\nECHO_C= ECHO_N= ECHO_T=\ncase `echo -n x` in #(((((\n-n*)\n  case `echo 'xy\\c'` in\n  *c*) ECHO_T='\t';;\t# ECHO_T is single tab character.\n  xy)  ECHO_C='\\c';;\n  *)   echo `echo ksh88 bug on AIX 6.1` > /dev/null\n       ECHO_T='\t';;\n  esac;;\n*)\n  ECHO_N='-n';;\nesac\n\n# For backward compatibility with old third-party macros, we provide\n# the shell variables $as_echo and $as_echo_n.  New code should use\n# AS_ECHO([\"message\"]) and AS_ECHO_N([\"message\"]), respectively.\nas_echo='printf %s\\n'\nas_echo_n='printf %s'\n\nrm -f conf$$ conf$$.exe conf$$.file\nif test -d conf$$.dir; then\n  rm -f conf$$.dir/conf$$.file\nelse\n  rm -f conf$$.dir\n  mkdir conf$$.dir 2>/dev/null\nfi\nif (echo >conf$$.file) 2>/dev/null; then\n  if ln -s conf$$.file conf$$ 2>/dev/null; then\n    as_ln_s='ln -s'\n    # ... but there are two gotchas:\n    # 1) On MSYS, both 'ln -s file dir' and 'ln file dir' fail.\n    # 2) DJGPP < 2.04 has no symlinks; 'ln -s' creates a wrapper executable.\n    # In both cases, we have to default to 'cp -pR'.\n    ln -s conf$$.file conf$$.dir 2>/dev/null && test ! -f conf$$.exe ||\n      as_ln_s='cp -pR'\n  elif ln conf$$.file conf$$ 2>/dev/null; then\n    as_ln_s=ln\n  else\n    as_ln_s='cp -pR'\n  fi\nelse\n  as_ln_s='cp -pR'\nfi\nrm -f conf$$ conf$$.exe conf$$.dir/conf$$.file conf$$.file\nrmdir conf$$.dir 2>/dev/null\n\nif mkdir -p . 2>/dev/null; then\n  as_mkdir_p='mkdir -p \"$as_dir\"'\nelse\n  test -d ./-p && rmdir ./-p\n  as_mkdir_p=false\nfi\n\nas_test_x='test -x'\nas_executable_p=as_fn_executable_p\n\n# Sed expression to map a string onto a valid CPP name.\nas_sed_cpp=\"y%*$as_cr_letters%P$as_cr_LETTERS%;s%[^_$as_cr_alnum]%_%g\"\nas_tr_cpp=\"eval sed '$as_sed_cpp'\" # deprecated\n\n# Sed expression to map a string onto a valid variable name.\nas_sed_sh=\"y%*+%pp%;s%[^_$as_cr_alnum]%_%g\"\nas_tr_sh=\"eval sed '$as_sed_sh'\" # deprecated\n\nSHELL=${CONFIG_SHELL-/bin/sh}\n\n\ntest -n \"$DJDIR\" || exec 7<&0 </dev/null\nexec 6>&1\n\n# Name of the host.\n# hostname on some systems (SVR3.2, old GNU/Linux) returns a bogus exit status,\n# so uname gets run too.\nac_hostname=`(hostname || uname -n) 2>/dev/null | sed 1q`\n\n#\n# Initializations.\n#\nac_default_prefix=/usr/local\nac_clean_files=\nac_config_libobj_dir=.\nLIBOBJS=\ncross_compiling=no\nsubdirs=\nMFLAGS=\nMAKEFLAGS=\n\n# Identity of this package.\nPACKAGE_NAME='slurm'\nPACKAGE_TARNAME='slurm'\nPACKAGE_VERSION='25.05'\nPACKAGE_STRING='slurm 25.05'\nPACKAGE_BUGREPORT=''\nPACKAGE_URL='https://slurm.schedmd.com'\n\nac_unique_file=\"configure.ac\"\n# Factoring default headers for most tests.\nac_includes_default=\"\\\n#include <stddef.h>\n#ifdef HAVE_STDIO_H\n# include <stdio.h>\n#endif\n#ifdef HAVE_STDLIB_H\n# include <stdlib.h>\n#endif\n#ifdef HAVE_STRING_H\n# include <string.h>\n#endif\n#ifdef HAVE_INTTYPES_H\n# include <inttypes.h>\n#endif\n#ifdef HAVE_STDINT_H\n# include <stdint.h>\n#endif\n#ifdef HAVE_STRINGS_H\n# include <strings.h>\n#endif\n#ifdef HAVE_SYS_TYPES_H\n# include <sys/types.h>\n#endif\n#ifdef HAVE_SYS_STAT_H\n# include <sys/stat.h>\n#endif\n#ifdef HAVE_UNISTD_H\n# include <unistd.h>\n#endif\"\n\nac_header_c_list=\nac_subst_vars='am__EXEEXT_FALSE\nam__EXEEXT_TRUE\nLTLIBOBJS\nLIBOBJS\nWITH_CURL_FALSE\nWITH_CURL_TRUE\nLIBCURL\nLIBCURL_CPPFLAGS\n_libcurl_config\nUTIL_LIBS\nWITH_MUNGE_FALSE\nWITH_MUNGE_TRUE\nMUNGE_DIR\nMUNGE_LDFLAGS\nMUNGE_CPPFLAGS\nMUNGE_LIBS\nWITH_SYSTEMD_UNITS_FALSE\nWITH_SYSTEMD_UNITS_TRUE\nsystemdsystemunitdir\nSYSTEMD_TASKSMAX_OPTION\nREADLINE_LIBS\nHAVE_MAN2HTML\nHAVE_MAN2HTML_FALSE\nHAVE_MAN2HTML_TRUE\nac_have_man2html\nHAVE_LUA_FALSE\nHAVE_LUA_TRUE\nlua_LIBS\nlua_CFLAGS\nSLURMRESTD_PORT\nWITH_SLURMRESTD_FALSE\nWITH_SLURMRESTD_TRUE\nSLURM_PREFIX\nSLURMCTLD_PORT_COUNT\nSLURMDBD_PORT\nSLURMD_PORT\nSLURMCTLD_PORT\nWITH_SWITCH_HPE_SLINGSHOT_FALSE\nWITH_SWITCH_HPE_SLINGSHOT_TRUE\nHPE_SLINGSHOT_CFLAGS\nBUILD_SVIEW_FALSE\nBUILD_SVIEW_TRUE\nGTK_LIBS\nGTK_CFLAGS\nGLIB_COMPILE_RESOURCES\nGLIB_MKENUMS\nGOBJECT_QUERY\nGLIB_GENMARSHAL\nGLIB_LIBS\nGLIB_CFLAGS\nHAVE_CHECK_FALSE\nHAVE_CHECK_TRUE\nCHECK_LIBS\nCHECK_CFLAGS\nWITH_DBUS_FALSE\nWITH_DBUS_TRUE\ndbus_LIBS\ndbus_CFLAGS\nWITH_BPF_FALSE\nWITH_BPF_TRUE\nBPF_CPPFLAGS\nWITH_CGROUP_FALSE\nWITH_CGROUP_TRUE\nLINUX_BUILD_FALSE\nLINUX_BUILD_TRUE\nWITH_S2N_FALSE\nWITH_S2N_TRUE\nS2N_LDFLAGS\nS2N_DIR\nS2N_CPPFLAGS\nS2N_LIBS\nWITH_RDKAFKA_FALSE\nWITH_RDKAFKA_TRUE\nRDKAFKA_LDFLAGS\nRDKAFKA_LIBS\nRDKAFKA_CPPFLAGS\nlibselinux_LIBS\nlibselinux_CFLAGS\nHAVE_UCX_FALSE\nHAVE_UCX_TRUE\nUCX_LIBS\nUCX_LDFLAGS\nUCX_CPPFLAGS\nBUILD_IPMI_FALSE\nBUILD_IPMI_TRUE\nFREEIPMI_LDFLAGS\nFREEIPMI_CPPFLAGS\nFREEIPMI_LIBS\nHAVE_PMIX_V5_FALSE\nHAVE_PMIX_V5_TRUE\nHAVE_PMIX_V4_FALSE\nHAVE_PMIX_V4_TRUE\nHAVE_PMIX_V3_FALSE\nHAVE_PMIX_V3_TRUE\nHAVE_PMIX_V2_FALSE\nHAVE_PMIX_V2_TRUE\nHAVE_PMIX_FALSE\nHAVE_PMIX_TRUE\nPMIX_V5_LDFLAGS\nPMIX_V5_CPPFLAGS\nPMIX_V4_LDFLAGS\nPMIX_V4_CPPFLAGS\nPMIX_V3_LDFLAGS\nPMIX_V3_CPPFLAGS\nPMIX_V2_LDFLAGS\nPMIX_V2_CPPFLAGS\nBUILD_ONEAPI_FALSE\nBUILD_ONEAPI_TRUE\nONEAPI_CPPFLAGS\nBUILD_RSMI_FALSE\nBUILD_RSMI_TRUE\nRSMI_CPPFLAGS\nBUILD_NVML_FALSE\nBUILD_NVML_TRUE\nNVML_CPPFLAGS\nHWLOC_LDFLAGS\nHWLOC_CPPFLAGS\nHWLOC_LIBS\nLZ4_LIBS\nLZ4_LDFLAGS\nLZ4_CPPFLAGS\nBUILD_HDF5_FALSE\nBUILD_HDF5_TRUE\nHDF5_TYPE\nHDF5_FLIBS\nHDF5_FFLAGS\nHDF5_FC\nHDF5_LIBS\nHDF5_LDFLAGS\nHDF5_CPPFLAGS\nHDF5_CFLAGS\nHDF5_CC\nHDF5_VERSION\nH5FC\nH5CC\nBUILD_OFED_FALSE\nBUILD_OFED_TRUE\nOFED_LDFLAGS\nOFED_CPPFLAGS\nOFED_LIBS\nPTHREAD_CFLAGS\nPTHREAD_LIBS\nPTHREAD_CXX\nPTHREAD_CC\nax_pthread_config\nCPP\nHAVE_EPOLL_FALSE\nHAVE_EPOLL_TRUE\nWITH_YAML_FALSE\nWITH_YAML_TRUE\nYAML_LDFLAGS\nYAML_CPPFLAGS\nWITH_HTTP_PARSER_FALSE\nWITH_HTTP_PARSER_TRUE\nHTTP_PARSER_LDFLAGS\nHTTP_PARSER_CPPFLAGS\nWITH_JWT_FALSE\nWITH_JWT_TRUE\nJWT_LDFLAGS\nJWT_CPPFLAGS\nWITH_JSON_PARSER_FALSE\nWITH_JSON_PARSER_TRUE\nJSON_LDFLAGS\nJSON_CPPFLAGS\nSLURMD_INTERFACES\nSLURMCTLD_INTERFACES\nLIB_SLURM_BUILD\nLIB_SLURM\nPAM_DIR\nHAVE_PAM_FALSE\nHAVE_PAM_TRUE\nPAM_LIBS\nHAVE_NUMA_FALSE\nHAVE_NUMA_TRUE\nNUMA_LIBS\nSUCMD\nSLEEP_CMD\nWITH_GNU_LD_FALSE\nWITH_GNU_LD_TRUE\nWITH_CXX_FALSE\nWITH_CXX_TRUE\nAR_FLAGS\nOBJCOPY\nWITH_PKG_CONFIG_FALSE\nWITH_PKG_CONFIG_TRUE\npkgconfigdir\nPKG_CONFIG_LIBDIR\nPKG_CONFIG_PATH\nPKG_CONFIG\nCXXCPP\nLT_SYS_LIBRARY_PATH\nOTOOL64\nOTOOL\nLIPO\nNMEDIT\nDSYMUTIL\nMANIFEST_TOOL\nRANLIB\nac_ct_AR\nAR\nDLLTOOL\nOBJDUMP\nFILECMD\nLN_S\nNM\nac_ct_DUMPBIN\nDUMPBIN\nLD\nFGREP\nEGREP\nGREP\nSED\nLIBTOOL\nam__fastdepCXX_FALSE\nam__fastdepCXX_TRUE\nCXXDEPMODE\nac_ct_CXX\nCXXFLAGS\nCXX\nWITH_MYSQL_FALSE\nWITH_MYSQL_TRUE\nMYSQL_CFLAGS\nMYSQL_LIBS\nam__fastdepCC_FALSE\nam__fastdepCC_TRUE\nCCDEPMODE\nam__nodep\nAMDEPBACKSLASH\nAMDEP_FALSE\nAMDEP_TRUE\nam__include\nDEPDIR\nOBJEXT\nEXEEXT\nac_ct_CC\nCPPFLAGS\nLDFLAGS\nCFLAGS\nCC\nHAVEMYSQLCONFIG\nMAINT\nMAINTAINER_MODE_FALSE\nMAINTAINER_MODE_TRUE\nAM_BACKSLASH\nAM_DEFAULT_VERBOSITY\nAM_DEFAULT_V\nAM_V\nCSCOPE\nETAGS\nCTAGS\nam__untar\nam__tar\nAMTAR\nam__leading_dot\nSET_MAKE\nAWK\nmkdir_p\nMKDIR_P\nINSTALL_STRIP_PROGRAM\nSTRIP\ninstall_sh\nMAKEINFO\nAUTOHEADER\nAUTOMAKE\nAUTOCONF\nACLOCAL\nPACKAGE\nCYGPATH_W\nam__isrc\nINSTALL_DATA\nINSTALL_SCRIPT\nINSTALL_PROGRAM\nSLURM_VERSION_STRING\nRELEASE\nSLURM_MICRO\nSLURM_MINOR\nSLURM_MAJOR\nSLURM_VERSION_NUMBER\nVERSION\nSLURM_API_REVISION\nSLURM_API_AGE\nSLURM_API_MAJOR\nSLURM_API_CURRENT\nSLURM_API_VERSION\nPROJECT\nDONT_BUILD_FALSE\nDONT_BUILD_TRUE\ntarget_os\ntarget_vendor\ntarget_cpu\ntarget\nhost_os\nhost_vendor\nhost_cpu\nhost\nbuild_os\nbuild_vendor\nbuild_cpu\nbuild\ntarget_alias\nhost_alias\nbuild_alias\nLIBS\nECHO_T\nECHO_N\nECHO_C\nDEFS\nmandir\nlocaledir\nlibdir\npsdir\npdfdir\ndvidir\nhtmldir\ninfodir\ndocdir\noldincludedir\nincludedir\nrunstatedir\nlocalstatedir\nsharedstatedir\nsysconfdir\ndatadir\ndatarootdir\nlibexecdir\nsbindir\nbindir\nprogram_transform_name\nprefix\nexec_prefix\nPACKAGE_URL\nPACKAGE_BUGREPORT\nPACKAGE_STRING\nPACKAGE_VERSION\nPACKAGE_TARNAME\nPACKAGE_NAME\nPATH_SEPARATOR\nSHELL\nam__quote'\nac_subst_files=''\nac_user_opts='\nenable_option_checking\nenable_silent_rules\nenable_maintainer_mode\nwith_rpath\nwith_mysql_config\nenable_dependency_tracking\nenable_shared\nenable_static\nwith_pic\nenable_fast_install\nwith_aix_soname\nwith_gnu_ld\nwith_sysroot\nenable_libtool_lock\nwith_pkgconfigdir\nenable_pkgconfig\nenable_pam\nwith_pam_dir\nwith_shared_libslurm\nenable_load_env_no_login\nwith_json\nwith_jwt\nwith_http_parser\nwith_yaml\nwith_dimensions\nwith_ofed\nwith_hdf5\nwith_lz4\nwith_hwloc\nwith_nvml\nwith_rsmi\nwith_oneapi\nwith_pmix\nwith_freeipmi\nwith_ucx\nenable_x11\nenable_selinux\nwith_rdkafka\nwith_s2n\nenable_cgroupv2\nwith_bpf\nenable_sview\nenable_glibtest\nenable_gtktest\nwith_hpe_slingshot\nenable_optimizations\nenable_developer\nenable_debug\nenable_memory_leak_debug\nenable_front_end\nenable_partial_attach\nenable_salloc_kill_cmd\nwith_slurmctld_port\nwith_slurmd_port\nwith_slurmdbd_port\nwith_slurmctld_port_count\nenable_slurmrestd\nwith_slurmrestd_port\nwith_lua\nwith_readline\nwith_systemdsystemunitdir\nwith_munge\nenable_multiple_slurmd\nwith_libcurl\nenable_deprecated\n'\n      ac_precious_vars='build_alias\nhost_alias\ntarget_alias\nCC\nCFLAGS\nLDFLAGS\nLIBS\nCPPFLAGS\nCXX\nCXXFLAGS\nCCC\nLT_SYS_LIBRARY_PATH\nCXXCPP\nPKG_CONFIG\nPKG_CONFIG_PATH\nPKG_CONFIG_LIBDIR\nCPP\nlibselinux_CFLAGS\nlibselinux_LIBS\ndbus_CFLAGS\ndbus_LIBS\nCHECK_CFLAGS\nCHECK_LIBS\nGLIB_CFLAGS\nGLIB_LIBS\nGLIB_GENMARSHAL\nGOBJECT_QUERY\nGLIB_MKENUMS\nGLIB_COMPILE_RESOURCES\nlua_CFLAGS\nlua_LIBS'\n\n\n# Initialize some variables set by options.\nac_init_help=\nac_init_version=false\nac_unrecognized_opts=\nac_unrecognized_sep=\n# The variables have the same names as the options, with\n# dashes changed to underlines.\ncache_file=/dev/null\nexec_prefix=NONE\nno_create=\nno_recursion=\nprefix=NONE\nprogram_prefix=NONE\nprogram_suffix=NONE\nprogram_transform_name=s,x,x,\nsilent=\nsite=\nsrcdir=\nverbose=\nx_includes=NONE\nx_libraries=NONE\n\n# Installation directory options.\n# These are left unexpanded so users can \"make install exec_prefix=/foo\"\n# and all the variables that are supposed to be based on exec_prefix\n# by default will actually change.\n# Use braces instead of parens because sh, perl, etc. also accept them.\n# (The list follows the same order as the GNU Coding Standards.)\nbindir='${exec_prefix}/bin'\nsbindir='${exec_prefix}/sbin'\nlibexecdir='${exec_prefix}/libexec'\ndatarootdir='${prefix}/share'\ndatadir='${datarootdir}'\nsysconfdir='${prefix}/etc'\nsharedstatedir='${prefix}/com'\nlocalstatedir='${prefix}/var'\nrunstatedir='${localstatedir}/run'\nincludedir='${prefix}/include'\noldincludedir='/usr/include'\ndocdir='${datarootdir}/doc/${PACKAGE_TARNAME}'\ninfodir='${datarootdir}/info'\nhtmldir='${docdir}'\ndvidir='${docdir}'\npdfdir='${docdir}'\npsdir='${docdir}'\nlibdir='${exec_prefix}/lib'\nlocaledir='${datarootdir}/locale'\nmandir='${datarootdir}/man'\n\nac_prev=\nac_dashdash=\nfor ac_option\ndo\n  # If the previous option needs an argument, assign it.\n  if test -n \"$ac_prev\"; then\n    eval $ac_prev=\\$ac_option\n    ac_prev=\n    continue\n  fi\n\n  case $ac_option in\n  *=?*) ac_optarg=`expr \"X$ac_option\" : '[^=]*=\\(.*\\)'` ;;\n  *=)   ac_optarg= ;;\n  *)    ac_optarg=yes ;;\n  esac\n\n  case $ac_dashdash$ac_option in\n  --)\n    ac_dashdash=yes ;;\n\n  -bindir | --bindir | --bindi | --bind | --bin | --bi)\n    ac_prev=bindir ;;\n  -bindir=* | --bindir=* | --bindi=* | --bind=* | --bin=* | --bi=*)\n    bindir=$ac_optarg ;;\n\n  -build | --build | --buil | --bui | --bu)\n    ac_prev=build_alias ;;\n  -build=* | --build=* | --buil=* | --bui=* | --bu=*)\n    build_alias=$ac_optarg ;;\n\n  -cache-file | --cache-file | --cache-fil | --cache-fi \\\n  | --cache-f | --cache- | --cache | --cach | --cac | --ca | --c)\n    ac_prev=cache_file ;;\n  -cache-file=* | --cache-file=* | --cache-fil=* | --cache-fi=* \\\n  | --cache-f=* | --cache-=* | --cache=* | --cach=* | --cac=* | --ca=* | --c=*)\n    cache_file=$ac_optarg ;;\n\n  --config-cache | -C)\n    cache_file=config.cache ;;\n\n  -datadir | --datadir | --datadi | --datad)\n    ac_prev=datadir ;;\n  -datadir=* | --datadir=* | --datadi=* | --datad=*)\n    datadir=$ac_optarg ;;\n\n  -datarootdir | --datarootdir | --datarootdi | --datarootd | --dataroot \\\n  | --dataroo | --dataro | --datar)\n    ac_prev=datarootdir ;;\n  -datarootdir=* | --datarootdir=* | --datarootdi=* | --datarootd=* \\\n  | --dataroot=* | --dataroo=* | --dataro=* | --datar=*)\n    datarootdir=$ac_optarg ;;\n\n  -disable-* | --disable-*)\n    ac_useropt=`expr \"x$ac_option\" : 'x-*disable-\\(.*\\)'`\n    # Reject names that are not valid shell variable names.\n    expr \"x$ac_useropt\" : \".*[^-+._$as_cr_alnum]\" >/dev/null &&\n      as_fn_error $? \"invalid feature name: '$ac_useropt'\"\n    ac_useropt_orig=$ac_useropt\n    ac_useropt=`printf \"%s\\n\" \"$ac_useropt\" | sed 's/[-+.]/_/g'`\n    case $ac_user_opts in\n      *\"\n\"enable_$ac_useropt\"\n\"*) ;;\n      *) ac_unrecognized_opts=\"$ac_unrecognized_opts$ac_unrecognized_sep--disable-$ac_useropt_orig\"\n\t ac_unrecognized_sep=', ';;\n    esac\n    eval enable_$ac_useropt=no ;;\n\n  -docdir | --docdir | --docdi | --doc | --do)\n    ac_prev=docdir ;;\n  -docdir=* | --docdir=* | --docdi=* | --doc=* | --do=*)\n    docdir=$ac_optarg ;;\n\n  -dvidir | --dvidir | --dvidi | --dvid | --dvi | --dv)\n    ac_prev=dvidir ;;\n  -dvidir=* | --dvidir=* | --dvidi=* | --dvid=* | --dvi=* | --dv=*)\n    dvidir=$ac_optarg ;;\n\n  -enable-* | --enable-*)\n    ac_useropt=`expr \"x$ac_option\" : 'x-*enable-\\([^=]*\\)'`\n    # Reject names that are not valid shell variable names.\n    expr \"x$ac_useropt\" : \".*[^-+._$as_cr_alnum]\" >/dev/null &&\n      as_fn_error $? \"invalid feature name: '$ac_useropt'\"\n    ac_useropt_orig=$ac_useropt\n    ac_useropt=`printf \"%s\\n\" \"$ac_useropt\" | sed 's/[-+.]/_/g'`\n    case $ac_user_opts in\n      *\"\n\"enable_$ac_useropt\"\n\"*) ;;\n      *) ac_unrecognized_opts=\"$ac_unrecognized_opts$ac_unrecognized_sep--enable-$ac_useropt_orig\"\n\t ac_unrecognized_sep=', ';;\n    esac\n    eval enable_$ac_useropt=\\$ac_optarg ;;\n\n  -exec-prefix | --exec_prefix | --exec-prefix | --exec-prefi \\\n  | --exec-pref | --exec-pre | --exec-pr | --exec-p | --exec- \\\n  | --exec | --exe | --ex)\n    ac_prev=exec_prefix ;;\n  -exec-prefix=* | --exec_prefix=* | --exec-prefix=* | --exec-prefi=* \\\n  | --exec-pref=* | --exec-pre=* | --exec-pr=* | --exec-p=* | --exec-=* \\\n  | --exec=* | --exe=* | --ex=*)\n    exec_prefix=$ac_optarg ;;\n\n  -gas | --gas | --ga | --g)\n    # Obsolete; use --with-gas.\n    with_gas=yes ;;\n\n  -help | --help | --hel | --he | -h)\n    ac_init_help=long ;;\n  -help=r* | --help=r* | --hel=r* | --he=r* | -hr*)\n    ac_init_help=recursive ;;\n  -help=s* | --help=s* | --hel=s* | --he=s* | -hs*)\n    ac_init_help=short ;;\n\n  -host | --host | --hos | --ho)\n    ac_prev=host_alias ;;\n  -host=* | --host=* | --hos=* | --ho=*)\n    host_alias=$ac_optarg ;;\n\n  -htmldir | --htmldir | --htmldi | --htmld | --html | --htm | --ht)\n    ac_prev=htmldir ;;\n  -htmldir=* | --htmldir=* | --htmldi=* | --htmld=* | --html=* | --htm=* \\\n  | --ht=*)\n    htmldir=$ac_optarg ;;\n\n  -includedir | --includedir | --includedi | --included | --include \\\n  | --includ | --inclu | --incl | --inc)\n    ac_prev=includedir ;;\n  -includedir=* | --includedir=* | --includedi=* | --included=* | --include=* \\\n  | --includ=* | --inclu=* | --incl=* | --inc=*)\n    includedir=$ac_optarg ;;\n\n  -infodir | --infodir | --infodi | --infod | --info | --inf)\n    ac_prev=infodir ;;\n  -infodir=* | --infodir=* | --infodi=* | --infod=* | --info=* | --inf=*)\n    infodir=$ac_optarg ;;\n\n  -libdir | --libdir | --libdi | --libd)\n    ac_prev=libdir ;;\n  -libdir=* | --libdir=* | --libdi=* | --libd=*)\n    libdir=$ac_optarg ;;\n\n  -libexecdir | --libexecdir | --libexecdi | --libexecd | --libexec \\\n  | --libexe | --libex | --libe)\n    ac_prev=libexecdir ;;\n  -libexecdir=* | --libexecdir=* | --libexecdi=* | --libexecd=* | --libexec=* \\\n  | --libexe=* | --libex=* | --libe=*)\n    libexecdir=$ac_optarg ;;\n\n  -localedir | --localedir | --localedi | --localed | --locale)\n    ac_prev=localedir ;;\n  -localedir=* | --localedir=* | --localedi=* | --localed=* | --locale=*)\n    localedir=$ac_optarg ;;\n\n  -localstatedir | --localstatedir | --localstatedi | --localstated \\\n  | --localstate | --localstat | --localsta | --localst | --locals)\n    ac_prev=localstatedir ;;\n  -localstatedir=* | --localstatedir=* | --localstatedi=* | --localstated=* \\\n  | --localstate=* | --localstat=* | --localsta=* | --localst=* | --locals=*)\n    localstatedir=$ac_optarg ;;\n\n  -mandir | --mandir | --mandi | --mand | --man | --ma | --m)\n    ac_prev=mandir ;;\n  -mandir=* | --mandir=* | --mandi=* | --mand=* | --man=* | --ma=* | --m=*)\n    mandir=$ac_optarg ;;\n\n  -nfp | --nfp | --nf)\n    # Obsolete; use --without-fp.\n    with_fp=no ;;\n\n  -no-create | --no-create | --no-creat | --no-crea | --no-cre \\\n  | --no-cr | --no-c | -n)\n    no_create=yes ;;\n\n  -no-recursion | --no-recursion | --no-recursio | --no-recursi \\\n  | --no-recurs | --no-recur | --no-recu | --no-rec | --no-re | --no-r)\n    no_recursion=yes ;;\n\n  -oldincludedir | --oldincludedir | --oldincludedi | --oldincluded \\\n  | --oldinclude | --oldinclud | --oldinclu | --oldincl | --oldinc \\\n  | --oldin | --oldi | --old | --ol | --o)\n    ac_prev=oldincludedir ;;\n  -oldincludedir=* | --oldincludedir=* | --oldincludedi=* | --oldincluded=* \\\n  | --oldinclude=* | --oldinclud=* | --oldinclu=* | --oldincl=* | --oldinc=* \\\n  | --oldin=* | --oldi=* | --old=* | --ol=* | --o=*)\n    oldincludedir=$ac_optarg ;;\n\n  -prefix | --prefix | --prefi | --pref | --pre | --pr | --p)\n    ac_prev=prefix ;;\n  -prefix=* | --prefix=* | --prefi=* | --pref=* | --pre=* | --pr=* | --p=*)\n    prefix=$ac_optarg ;;\n\n  -program-prefix | --program-prefix | --program-prefi | --program-pref \\\n  | --program-pre | --program-pr | --program-p)\n    ac_prev=program_prefix ;;\n  -program-prefix=* | --program-prefix=* | --program-prefi=* \\\n  | --program-pref=* | --program-pre=* | --program-pr=* | --program-p=*)\n    program_prefix=$ac_optarg ;;\n\n  -program-suffix | --program-suffix | --program-suffi | --program-suff \\\n  | --program-suf | --program-su | --program-s)\n    ac_prev=program_suffix ;;\n  -program-suffix=* | --program-suffix=* | --program-suffi=* \\\n  | --program-suff=* | --program-suf=* | --program-su=* | --program-s=*)\n    program_suffix=$ac_optarg ;;\n\n  -program-transform-name | --program-transform-name \\\n  | --program-transform-nam | --program-transform-na \\\n  | --program-transform-n | --program-transform- \\\n  | --program-transform | --program-transfor \\\n  | --program-transfo | --program-transf \\\n  | --program-trans | --program-tran \\\n  | --progr-tra | --program-tr | --program-t)\n    ac_prev=program_transform_name ;;\n  -program-transform-name=* | --program-transform-name=* \\\n  | --program-transform-nam=* | --program-transform-na=* \\\n  | --program-transform-n=* | --program-transform-=* \\\n  | --program-transform=* | --program-transfor=* \\\n  | --program-transfo=* | --program-transf=* \\\n  | --program-trans=* | --program-tran=* \\\n  | --progr-tra=* | --program-tr=* | --program-t=*)\n    program_transform_name=$ac_optarg ;;\n\n  -pdfdir | --pdfdir | --pdfdi | --pdfd | --pdf | --pd)\n    ac_prev=pdfdir ;;\n  -pdfdir=* | --pdfdir=* | --pdfdi=* | --pdfd=* | --pdf=* | --pd=*)\n    pdfdir=$ac_optarg ;;\n\n  -psdir | --psdir | --psdi | --psd | --ps)\n    ac_prev=psdir ;;\n  -psdir=* | --psdir=* | --psdi=* | --psd=* | --ps=*)\n    psdir=$ac_optarg ;;\n\n  -q | -quiet | --quiet | --quie | --qui | --qu | --q \\\n  | -silent | --silent | --silen | --sile | --sil)\n    silent=yes ;;\n\n  -runstatedir | --runstatedir | --runstatedi | --runstated \\\n  | --runstate | --runstat | --runsta | --runst | --runs \\\n  | --run | --ru | --r)\n    ac_prev=runstatedir ;;\n  -runstatedir=* | --runstatedir=* | --runstatedi=* | --runstated=* \\\n  | --runstate=* | --runstat=* | --runsta=* | --runst=* | --runs=* \\\n  | --run=* | --ru=* | --r=*)\n    runstatedir=$ac_optarg ;;\n\n  -sbindir | --sbindir | --sbindi | --sbind | --sbin | --sbi | --sb)\n    ac_prev=sbindir ;;\n  -sbindir=* | --sbindir=* | --sbindi=* | --sbind=* | --sbin=* \\\n  | --sbi=* | --sb=*)\n    sbindir=$ac_optarg ;;\n\n  -sharedstatedir | --sharedstatedir | --sharedstatedi \\\n  | --sharedstated | --sharedstate | --sharedstat | --sharedsta \\\n  | --sharedst | --shareds | --shared | --share | --shar \\\n  | --sha | --sh)\n    ac_prev=sharedstatedir ;;\n  -sharedstatedir=* | --sharedstatedir=* | --sharedstatedi=* \\\n  | --sharedstated=* | --sharedstate=* | --sharedstat=* | --sharedsta=* \\\n  | --sharedst=* | --shareds=* | --shared=* | --share=* | --shar=* \\\n  | --sha=* | --sh=*)\n    sharedstatedir=$ac_optarg ;;\n\n  -site | --site | --sit)\n    ac_prev=site ;;\n  -site=* | --site=* | --sit=*)\n    site=$ac_optarg ;;\n\n  -srcdir | --srcdir | --srcdi | --srcd | --src | --sr)\n    ac_prev=srcdir ;;\n  -srcdir=* | --srcdir=* | --srcdi=* | --srcd=* | --src=* | --sr=*)\n    srcdir=$ac_optarg ;;\n\n  -sysconfdir | --sysconfdir | --sysconfdi | --sysconfd | --sysconf \\\n  | --syscon | --sysco | --sysc | --sys | --sy)\n    ac_prev=sysconfdir ;;\n  -sysconfdir=* | --sysconfdir=* | --sysconfdi=* | --sysconfd=* | --sysconf=* \\\n  | --syscon=* | --sysco=* | --sysc=* | --sys=* | --sy=*)\n    sysconfdir=$ac_optarg ;;\n\n  -target | --target | --targe | --targ | --tar | --ta | --t)\n    ac_prev=target_alias ;;\n  -target=* | --target=* | --targe=* | --targ=* | --tar=* | --ta=* | --t=*)\n    target_alias=$ac_optarg ;;\n\n  -v | -verbose | --verbose | --verbos | --verbo | --verb)\n    verbose=yes ;;\n\n  -version | --version | --versio | --versi | --vers | -V)\n    ac_init_version=: ;;\n\n  -with-* | --with-*)\n    ac_useropt=`expr \"x$ac_option\" : 'x-*with-\\([^=]*\\)'`\n    # Reject names that are not valid shell variable names.\n    expr \"x$ac_useropt\" : \".*[^-+._$as_cr_alnum]\" >/dev/null &&\n      as_fn_error $? \"invalid package name: '$ac_useropt'\"\n    ac_useropt_orig=$ac_useropt\n    ac_useropt=`printf \"%s\\n\" \"$ac_useropt\" | sed 's/[-+.]/_/g'`\n    case $ac_user_opts in\n      *\"\n\"with_$ac_useropt\"\n\"*) ;;\n      *) ac_unrecognized_opts=\"$ac_unrecognized_opts$ac_unrecognized_sep--with-$ac_useropt_orig\"\n\t ac_unrecognized_sep=', ';;\n    esac\n    eval with_$ac_useropt=\\$ac_optarg ;;\n\n  -without-* | --without-*)\n    ac_useropt=`expr \"x$ac_option\" : 'x-*without-\\(.*\\)'`\n    # Reject names that are not valid shell variable names.\n    expr \"x$ac_useropt\" : \".*[^-+._$as_cr_alnum]\" >/dev/null &&\n      as_fn_error $? \"invalid package name: '$ac_useropt'\"\n    ac_useropt_orig=$ac_useropt\n    ac_useropt=`printf \"%s\\n\" \"$ac_useropt\" | sed 's/[-+.]/_/g'`\n    case $ac_user_opts in\n      *\"\n\"with_$ac_useropt\"\n\"*) ;;\n      *) ac_unrecognized_opts=\"$ac_unrecognized_opts$ac_unrecognized_sep--without-$ac_useropt_orig\"\n\t ac_unrecognized_sep=', ';;\n    esac\n    eval with_$ac_useropt=no ;;\n\n  --x)\n    # Obsolete; use --with-x.\n    with_x=yes ;;\n\n  -x-includes | --x-includes | --x-include | --x-includ | --x-inclu \\\n  | --x-incl | --x-inc | --x-in | --x-i)\n    ac_prev=x_includes ;;\n  -x-includes=* | --x-includes=* | --x-include=* | --x-includ=* | --x-inclu=* \\\n  | --x-incl=* | --x-inc=* | --x-in=* | --x-i=*)\n    x_includes=$ac_optarg ;;\n\n  -x-libraries | --x-libraries | --x-librarie | --x-librari \\\n  | --x-librar | --x-libra | --x-libr | --x-lib | --x-li | --x-l)\n    ac_prev=x_libraries ;;\n  -x-libraries=* | --x-libraries=* | --x-librarie=* | --x-librari=* \\\n  | --x-librar=* | --x-libra=* | --x-libr=* | --x-lib=* | --x-li=* | --x-l=*)\n    x_libraries=$ac_optarg ;;\n\n  -*) as_fn_error $? \"unrecognized option: '$ac_option'\nTry '$0 --help' for more information\"\n    ;;\n\n  *=*)\n    ac_envvar=`expr \"x$ac_option\" : 'x\\([^=]*\\)='`\n    # Reject names that are not valid shell variable names.\n    case $ac_envvar in #(\n      '' | [0-9]* | *[!_$as_cr_alnum]* )\n      as_fn_error $? \"invalid variable name: '$ac_envvar'\" ;;\n    esac\n    eval $ac_envvar=\\$ac_optarg\n    export $ac_envvar ;;\n\n  *)\n    # FIXME: should be removed in autoconf 3.0.\n    printf \"%s\\n\" \"$as_me: WARNING: you should use --build, --host, --target\" >&2\n    expr \"x$ac_option\" : \".*[^-._$as_cr_alnum]\" >/dev/null &&\n      printf \"%s\\n\" \"$as_me: WARNING: invalid host type: $ac_option\" >&2\n    : \"${build_alias=$ac_option} ${host_alias=$ac_option} ${target_alias=$ac_option}\"\n    ;;\n\n  esac\ndone\n\nif test -n \"$ac_prev\"; then\n  ac_option=--`echo $ac_prev | sed 's/_/-/g'`\n  as_fn_error $? \"missing argument to $ac_option\"\nfi\n\nif test -n \"$ac_unrecognized_opts\"; then\n  case $enable_option_checking in\n    no) ;;\n    fatal) as_fn_error $? \"unrecognized options: $ac_unrecognized_opts\" ;;\n    *)     printf \"%s\\n\" \"$as_me: WARNING: unrecognized options: $ac_unrecognized_opts\" >&2 ;;\n  esac\nfi\n\n# Check all directory arguments for consistency.\nfor ac_var in\texec_prefix prefix bindir sbindir libexecdir datarootdir \\\n\t\tdatadir sysconfdir sharedstatedir localstatedir includedir \\\n\t\toldincludedir docdir infodir htmldir dvidir pdfdir psdir \\\n\t\tlibdir localedir mandir runstatedir\ndo\n  eval ac_val=\\$$ac_var\n  # Remove trailing slashes.\n  case $ac_val in\n    */ )\n      ac_val=`expr \"X$ac_val\" : 'X\\(.*[^/]\\)' \\| \"X$ac_val\" : 'X\\(.*\\)'`\n      eval $ac_var=\\$ac_val;;\n  esac\n  # Be sure to have absolute directory names.\n  case $ac_val in\n    [\\\\/$]* | ?:[\\\\/]* )  continue;;\n    NONE | '' ) case $ac_var in *prefix ) continue;; esac;;\n  esac\n  as_fn_error $? \"expected an absolute directory name for --$ac_var: $ac_val\"\ndone\n\n# There might be people who depend on the old broken behavior: '$host'\n# used to hold the argument of --host etc.\n# FIXME: To remove some day.\nbuild=$build_alias\nhost=$host_alias\ntarget=$target_alias\n\n# FIXME: To remove some day.\nif test \"x$host_alias\" != x; then\n  if test \"x$build_alias\" = x; then\n    cross_compiling=maybe\n  elif test \"x$build_alias\" != \"x$host_alias\"; then\n    cross_compiling=yes\n  fi\nfi\n\nac_tool_prefix=\ntest -n \"$host_alias\" && ac_tool_prefix=$host_alias-\n\ntest \"$silent\" = yes && exec 6>/dev/null\n\n\nac_pwd=`pwd` && test -n \"$ac_pwd\" &&\nac_ls_di=`ls -di .` &&\nac_pwd_ls_di=`cd \"$ac_pwd\" && ls -di .` ||\n  as_fn_error $? \"working directory cannot be determined\"\ntest \"X$ac_ls_di\" = \"X$ac_pwd_ls_di\" ||\n  as_fn_error $? \"pwd does not report name of working directory\"\n\n\n# Find the source files, if location was not specified.\nif test -z \"$srcdir\"; then\n  ac_srcdir_defaulted=yes\n  # Try the directory containing this script, then the parent directory.\n  ac_confdir=`$as_dirname -- \"$as_myself\" ||\n$as_expr X\"$as_myself\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\n\t X\"$as_myself\" : 'X\\(//\\)[^/]' \\| \\\n\t X\"$as_myself\" : 'X\\(//\\)$' \\| \\\n\t X\"$as_myself\" : 'X\\(/\\)' \\| . 2>/dev/null ||\nprintf \"%s\\n\" X\"$as_myself\" |\n    sed '/^X\\(.*[^/]\\)\\/\\/*[^/][^/]*\\/*$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\/\\)[^/].*/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\/\\)$/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  /^X\\(\\/\\).*/{\n\t    s//\\1/\n\t    q\n\t  }\n\t  s/.*/./; q'`\n  srcdir=$ac_confdir\n  if test ! -r \"$srcdir/$ac_unique_file\"; then\n    srcdir=..\n  fi\nelse\n  ac_srcdir_defaulted=no\nfi\nif test ! -r \"$srcdir/$ac_unique_file\"; then\n  test \"$ac_srcdir_defaulted\" = yes && srcdir=\"$ac_confdir or ..\"\n  as_fn_error $? \"cannot find sources ($ac_unique_file) in $srcdir\"\nfi\nac_msg=\"sources are in $srcdir, but 'cd $srcdir' does not work\"\nac_abs_confdir=`(\n\tcd \"$srcdir\" && test -r \"./$ac_unique_file\" || as_fn_error $? \"$ac_msg\"\n\tpwd)`\n# When building in place, set srcdir=.\nif test \"$ac_abs_confdir\" = \"$ac_pwd\"; then\n  srcdir=.\nfi\n# Remove unnecessary trailing slashes from srcdir.\n# Double slashes in file names in object file debugging info\n# mess up M-x gdb in Emacs.\ncase $srcdir in\n*/) srcdir=`expr \"X$srcdir\" : 'X\\(.*[^/]\\)' \\| \"X$srcdir\" : 'X\\(.*\\)'`;;\nesac\nfor ac_var in $ac_precious_vars; do\n  eval ac_env_${ac_var}_set=\\${${ac_var}+set}\n  eval ac_env_${ac_var}_value=\\$${ac_var}\n  eval ac_cv_env_${ac_var}_set=\\${${ac_var}+set}\n  eval ac_cv_env_${ac_var}_value=\\$${ac_var}\ndone\n\n#\n# Report the --help message.\n#\nif test \"$ac_init_help\" = \"long\"; then\n  # Omit some internal or obsolete options to make the list less imposing.\n  # This message is too long to be a string in the A/UX 3.1 sh.\n  cat <<_ACEOF\n'configure' configures slurm 25.05 to adapt to many kinds of systems.\n\nUsage: $0 [OPTION]... [VAR=VALUE]...\n\nTo assign environment variables (e.g., CC, CFLAGS...), specify them as\nVAR=VALUE.  See below for descriptions of some of the useful variables.\n\nDefaults for the options are specified in brackets.\n\nConfiguration:\n  -h, --help              display this help and exit\n      --help=short        display options specific to this package\n      --help=recursive    display the short help of all the included packages\n  -V, --version           display version information and exit\n  -q, --quiet, --silent   do not print 'checking ...' messages\n      --cache-file=FILE   cache test results in FILE [disabled]\n  -C, --config-cache      alias for '--cache-file=config.cache'\n  -n, --no-create         do not create output files\n      --srcdir=DIR        find the sources in DIR [configure dir or '..']\n\nInstallation directories:\n  --prefix=PREFIX         install architecture-independent files in PREFIX\n                          [$ac_default_prefix]\n  --exec-prefix=EPREFIX   install architecture-dependent files in EPREFIX\n                          [PREFIX]\n\nBy default, 'make install' will install all the files in\n'$ac_default_prefix/bin', '$ac_default_prefix/lib' etc.  You can specify\nan installation prefix other than '$ac_default_prefix' using '--prefix',\nfor instance '--prefix=\\$HOME'.\n\nFor better control, use the options below.\n\nFine tuning of the installation directories:\n  --bindir=DIR            user executables [EPREFIX/bin]\n  --sbindir=DIR           system admin executables [EPREFIX/sbin]\n  --libexecdir=DIR        program executables [EPREFIX/libexec]\n  --sysconfdir=DIR        read-only single-machine data [PREFIX/etc]\n  --sharedstatedir=DIR    modifiable architecture-independent data [PREFIX/com]\n  --localstatedir=DIR     modifiable single-machine data [PREFIX/var]\n  --runstatedir=DIR       modifiable per-process data [LOCALSTATEDIR/run]\n  --libdir=DIR            object code libraries [EPREFIX/lib]\n  --includedir=DIR        C header files [PREFIX/include]\n  --oldincludedir=DIR     C header files for non-gcc [/usr/include]\n  --datarootdir=DIR       read-only arch.-independent data root [PREFIX/share]\n  --datadir=DIR           read-only architecture-independent data [DATAROOTDIR]\n  --infodir=DIR           info documentation [DATAROOTDIR/info]\n  --localedir=DIR         locale-dependent data [DATAROOTDIR/locale]\n  --mandir=DIR            man documentation [DATAROOTDIR/man]\n  --docdir=DIR            documentation root [DATAROOTDIR/doc/slurm]\n  --htmldir=DIR           html documentation [DOCDIR]\n  --dvidir=DIR            dvi documentation [DOCDIR]\n  --pdfdir=DIR            pdf documentation [DOCDIR]\n  --psdir=DIR             ps documentation [DOCDIR]\n_ACEOF\n\n  cat <<\\_ACEOF\n\nProgram names:\n  --program-prefix=PREFIX            prepend PREFIX to installed program names\n  --program-suffix=SUFFIX            append SUFFIX to installed program names\n  --program-transform-name=PROGRAM   run sed PROGRAM on installed program names\n\nSystem types:\n  --build=BUILD     configure for building on BUILD [guessed]\n  --host=HOST       cross-compile to build programs to run on HOST [BUILD]\n  --target=TARGET   configure for building compilers for TARGET [HOST]\n_ACEOF\nfi\n\nif test -n \"$ac_init_help\"; then\n  case $ac_init_help in\n     short | recursive ) echo \"Configuration of slurm 25.05:\";;\n   esac\n  cat <<\\_ACEOF\n\nOptional Features:\n  --disable-option-checking  ignore unrecognized --enable/--with options\n  --disable-FEATURE       do not include FEATURE (same as --enable-FEATURE=no)\n  --enable-FEATURE[=ARG]  include FEATURE [ARG=yes]\n  --enable-silent-rules   less verbose build output (undo: \"make V=1\")\n  --disable-silent-rules  verbose build output (undo: \"make V=0\")\n  --enable-maintainer-mode\n                          enable make rules and dependencies not useful (and\n                          sometimes confusing) to the casual installer\n  --enable-dependency-tracking\n                          do not reject slow dependency extractors\n  --disable-dependency-tracking\n                          speeds up one-time build\n  --enable-shared[=PKGS]  build shared libraries [default=yes]\n  --enable-static[=PKGS]  build static libraries [default=yes]\n  --enable-fast-install[=PKGS]\n                          optimize for fast installation [default=yes]\n  --disable-libtool-lock  avoid locking (might break parallel builds)\n  --enable-pkgconfig      Install the slurm.pc file\n  --enable-pam            enable PAM (Pluggable Authentication Modules)\n                          support\n  --enable-load-env-no-login\n                          enable --get-user-env option to load user\n                          environment without .login\n  --disable-x11           disable internal X11 support\n  --enable-selinux        enable internal SELinux support\n  --enable-cgroupv2       enable cgroupv2 support [default=auto]\n  --disable-sview         disable sview support\n  --disable-glibtest      do not try to compile and run a test GLIB program\n  --disable-gtktest       do not try to compile and run a test GTK+ program\n  --disable-optimizations disable optimizations (sets -O0)\n  --enable-developer      enable developer options (asserts, -Werror - also\n                          sets --enable-debug as well)\n  --disable-debug         disable debugging symbols and compile with\n                          optimizations\n  --enable-memory-leak-debug\n                          enable memory leak debugging code for development\n  --enable-front-end      enable slurmd operation on a front-end\n  --disable-partial-attach\n                          disable debugger partial task attach support\n  --enable-salloc-kill-cmd\n                          salloc should kill child processes at job\n                          termination\n  --disable-slurmrestd    disable slurmrestd support\n  --enable-multiple-slurmd\n                          enable multiple-slurmd support\n  --enable-deprecated     enable deprecated\n\nOptional Packages:\n  --with-PACKAGE[=ARG]    use PACKAGE [ARG=yes]\n  --without-PACKAGE       do not use PACKAGE (same as --with-PACKAGE=no)\n  --without-rpath         Do not include rpath in build\n  --with-mysql_config=PATH\n                          Specify path of directory where mysql_config binary\n                          exists\n  --with-pic[=PKGS]       try to use only PIC/non-PIC objects [default=use\n                          both]\n  --with-aix-soname=aix|svr4|both\n                          shared library versioning (aka \"SONAME\") variant to\n                          provide on AIX, [default=aix].\n  --with-gnu-ld           assume the C compiler uses GNU ld [default=no]\n  --with-sysroot[=DIR]    Search for dependent libraries within DIR (or the\n                          compiler's sysroot if not specified).\n  --with-pkgconfigdir     pkg-config installation directory\n                          ['${libdir}/pkgconfig']\n  --with-pam_dir=PATH     Specify path to PAM module installation\n  --without-shared-libslurm\n                          statically link to libslurm.o instead of the shared\n                          libslurm lib - can dramatically increase the\n                          footprint of Slurm.\n  --with-json=PATH        Specify path to json-c installation\n  --with-jwt=PATH         Specify path to jwt installation\n  --with-http-parser=PATH Specify path to HTTP Parser installation\n  --with-yaml=PATH        Specify path to libyaml installation\n  --with-dimensions=N     set system dimension count for generic computer\n                          system\n  --with-ofed=PATH        Specify path to ofed installation\n  --with-hdf5=yes/no/PATH location of h5cc or h5pcc for HDF5 configuration\n  --with-lz4=PATH         Specify path to liblz4 installation\n  --with-hwloc=PATH       Specify path to hwloc installation\n  --with-nvml=PATH        Specify path to CUDA installation\n  --with-rsmi=PATH        Specify path to rsmi installation\n  --with-oneapi=PATH      Specify path to oneAPI installation\n  --with-pmix=PATH        Specify path to pmix installation(s). Multiple\n                          version directories can be ':' delimited.\n  --with-freeipmi=PATH    Specify path to freeipmi installation\n  --with-ucx=PATH         Build with Unified Communication X library support\n  --with-rdkafka=PATH     Specify path to librdkafka installation\n  --with-s2n=PATH         Specify path to s2n installation\n  --with-bpf=PATH         Specify path to bpf header\n  --with-hpe-slingshot=PATH\n                          Specify path to HPE Slingshot installation dir\n  --with-slurmctld-port=N set slurmctld default port [6817]\n  --with-slurmd-port=N    set slurmd default port [6818]\n  --with-slurmdbd-port=N  set slurmdbd default port [6819]\n  --with-slurmctld-port-count=N\n                          set slurmctld default port count [1]\n  --with-slurmrestd-port=N\n                          set slurmrestd default port [6820]\n  --with-lua              enable lua plugin support\n  --without-readline      compile without readline support\n  --with-systemdsystemunitdir=DIR\n                          Directory for systemd service files\n  --with-munge=PATH       Specify path to munge installation\n  --with-libcurl=PREFIX   look for the curl library in PREFIX/lib and headers\n                          in PREFIX/include\n\nSome influential environment variables:\n  CC          C compiler command\n  CFLAGS      C compiler flags\n  LDFLAGS     linker flags, e.g. -L<lib dir> if you have libraries in a\n              nonstandard directory <lib dir>\n  LIBS        libraries to pass to the linker, e.g. -l<library>\n  CPPFLAGS    (Objective) C/C++ preprocessor flags, e.g. -I<include dir> if\n              you have headers in a nonstandard directory <include dir>\n  CXX         C++ compiler command\n  CXXFLAGS    C++ compiler flags\n  LT_SYS_LIBRARY_PATH\n              User-defined run-time library search path.\n  CXXCPP      C++ preprocessor\n  PKG_CONFIG  path to pkg-config utility\n  PKG_CONFIG_PATH\n              directories to add to pkg-config's search path\n  PKG_CONFIG_LIBDIR\n              path overriding pkg-config's built-in search path\n  CPP         C preprocessor\n  libselinux_CFLAGS\n              C compiler flags for libselinux, overriding pkg-config\n  libselinux_LIBS\n              linker flags for libselinux, overriding pkg-config\n  dbus_CFLAGS C compiler flags for dbus, overriding pkg-config\n  dbus_LIBS   linker flags for dbus, overriding pkg-config\n  CHECK_CFLAGS\n              C compiler flags for CHECK, overriding pkg-config\n  CHECK_LIBS  linker flags for CHECK, overriding pkg-config\n  GLIB_CFLAGS C compiler flags for GLIB, overriding pkg-config\n  GLIB_LIBS   linker flags for GLIB, overriding pkg-config\n  GLIB_GENMARSHAL\n              value of glib_genmarshal for glib-2.0, overriding pkg-config\n  GOBJECT_QUERY\n              value of gobject_query for glib-2.0, overriding pkg-config\n  GLIB_MKENUMS\n              value of glib_mkenums for glib-2.0, overriding pkg-config\n  GLIB_COMPILE_RESOURCES\n              value of glib_compile_resources for gio-2.0, overriding\n              pkg-config\n  lua_CFLAGS  C compiler flags for lua, overriding pkg-config\n  lua_LIBS    linker flags for lua, overriding pkg-config\n\nUse these variables to override the choices made by 'configure' or to help\nit to find libraries and programs with nonstandard names/locations.\n\nReport bugs to the package provider.\nslurm home page: <https://slurm.schedmd.com>.\n_ACEOF\nac_status=$?\nfi\n\nif test \"$ac_init_help\" = \"recursive\"; then\n  # If there are subdirs, report their specific --help.\n  for ac_dir in : $ac_subdirs_all; do test \"x$ac_dir\" = x: && continue\n    test -d \"$ac_dir\" ||\n      { cd \"$srcdir\" && ac_pwd=`pwd` && srcdir=. && test -d \"$ac_dir\"; } ||\n      continue\n    ac_builddir=.\n\ncase \"$ac_dir\" in\n.) ac_dir_suffix= ac_top_builddir_sub=. ac_top_build_prefix= ;;\n*)\n  ac_dir_suffix=/`printf \"%s\\n\" \"$ac_dir\" | sed 's|^\\.[\\\\/]||'`\n  # A \"..\" for each directory in $ac_dir_suffix.\n  ac_top_builddir_sub=`printf \"%s\\n\" \"$ac_dir_suffix\" | sed 's|/[^\\\\/]*|/..|g;s|/||'`\n  case $ac_top_builddir_sub in\n  \"\") ac_top_builddir_sub=. ac_top_build_prefix= ;;\n  *)  ac_top_build_prefix=$ac_top_builddir_sub/ ;;\n  esac ;;\nesac\nac_abs_top_builddir=$ac_pwd\nac_abs_builddir=$ac_pwd$ac_dir_suffix\n# for backward compatibility:\nac_top_builddir=$ac_top_build_prefix\n\ncase $srcdir in\n  .)  # We are building in place.\n    ac_srcdir=.\n    ac_top_srcdir=$ac_top_builddir_sub\n    ac_abs_top_srcdir=$ac_pwd ;;\n  [\\\\/]* | ?:[\\\\/]* )  # Absolute name.\n    ac_srcdir=$srcdir$ac_dir_suffix;\n    ac_top_srcdir=$srcdir\n    ac_abs_top_srcdir=$srcdir ;;\n  *) # Relative name.\n    ac_srcdir=$ac_top_build_prefix$srcdir$ac_dir_suffix\n    ac_top_srcdir=$ac_top_build_prefix$srcdir\n    ac_abs_top_srcdir=$ac_pwd/$srcdir ;;\nesac\nac_abs_srcdir=$ac_abs_top_srcdir$ac_dir_suffix\n\n    cd \"$ac_dir\" || { ac_status=$?; continue; }\n    # Check for configure.gnu first; this name is used for a wrapper for\n    # Metaconfig's \"Configure\" on case-insensitive file systems.\n    if test -f \"$ac_srcdir/configure.gnu\"; then\n      echo &&\n      $SHELL \"$ac_srcdir/configure.gnu\" --help=recursive\n    elif test -f \"$ac_srcdir/configure\"; then\n      echo &&\n      $SHELL \"$ac_srcdir/configure\" --help=recursive\n    else\n      printf \"%s\\n\" \"$as_me: WARNING: no configuration information is in $ac_dir\" >&2\n    fi || ac_status=$?\n    cd \"$ac_pwd\" || { ac_status=$?; break; }\n  done\nfi\n\ntest -n \"$ac_init_help\" && exit $ac_status\nif $ac_init_version; then\n  cat <<\\_ACEOF\nslurm configure 25.05\ngenerated by GNU Autoconf 2.72\n\nCopyright (C) 2023 Free Software Foundation, Inc.\nThis configure script is free software; the Free Software Foundation\ngives unlimited permission to copy, distribute and modify it.\n_ACEOF\n  exit\nfi\n\n## ------------------------ ##\n## Autoconf initialization. ##\n## ------------------------ ##\n\n# ac_fn_c_try_compile LINENO\n# --------------------------\n# Try to compile conftest.$ac_ext, and return whether this succeeded.\nac_fn_c_try_compile ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  rm -f conftest.$ac_objext conftest.beam\n  if { { ac_try=\"$ac_compile\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compile\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && {\n\t test -z \"$ac_c_werror_flag\" ||\n\t test ! -s conftest.err\n       } && test -s conftest.$ac_objext\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n\tac_retval=1 ;;\nesac\nfi\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_c_try_compile\n\n# ac_fn_c_try_link LINENO\n# -----------------------\n# Try to link conftest.$ac_ext, and return whether this succeeded.\nac_fn_c_try_link ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  rm -f conftest.$ac_objext conftest.beam conftest$ac_exeext\n  if { { ac_try=\"$ac_link\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && {\n\t test -z \"$ac_c_werror_flag\" ||\n\t test ! -s conftest.err\n       } && test -s conftest$ac_exeext && {\n\t test \"$cross_compiling\" = yes ||\n\t test -x conftest$ac_exeext\n       }\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n\tac_retval=1 ;;\nesac\nfi\n  # Delete the IPA/IPO (Inter Procedural Analysis/Optimization) information\n  # created by the PGI compiler (conftest_ipa8_conftest.oo), as it would\n  # interfere with the next link command; also delete a directory that is\n  # left behind by Apple's compiler.  We do this before executing the actions.\n  rm -rf conftest.dSYM conftest_ipa8_conftest.oo\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_c_try_link\n\n# ac_fn_cxx_try_compile LINENO\n# ----------------------------\n# Try to compile conftest.$ac_ext, and return whether this succeeded.\nac_fn_cxx_try_compile ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  rm -f conftest.$ac_objext conftest.beam\n  if { { ac_try=\"$ac_compile\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compile\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && {\n\t test -z \"$ac_cxx_werror_flag\" ||\n\t test ! -s conftest.err\n       } && test -s conftest.$ac_objext\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n\tac_retval=1 ;;\nesac\nfi\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_cxx_try_compile\n\n# ac_fn_c_check_header_compile LINENO HEADER VAR INCLUDES\n# -------------------------------------------------------\n# Tests whether HEADER exists and can be compiled using the include files in\n# INCLUDES, setting the cache variable VAR accordingly.\nac_fn_c_check_header_compile ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $2\" >&5\nprintf %s \"checking for $2... \" >&6; }\nif eval test \\${$3+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\n#include <$2>\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  eval \"$3=yes\"\nelse case e in #(\n  e) eval \"$3=no\" ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\neval ac_res=\\$$3\n\t       { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_res\" >&5\nprintf \"%s\\n\" \"$ac_res\" >&6; }\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n\n} # ac_fn_c_check_header_compile\n\n# ac_fn_c_check_func LINENO FUNC VAR\n# ----------------------------------\n# Tests whether FUNC exists, setting the cache variable VAR accordingly\nac_fn_c_check_func ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $2\" >&5\nprintf %s \"checking for $2... \" >&6; }\nif eval test \\${$3+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n/* Define $2 to an innocuous variant, in case <limits.h> declares $2.\n   For example, HP-UX 11i <limits.h> declares gettimeofday.  */\n#define $2 innocuous_$2\n\n/* System header to define __stub macros and hopefully few prototypes,\n   which can conflict with char $2 (void); below.  */\n\n#include <limits.h>\n#undef $2\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar $2 (void);\n/* The GNU C library defines this for functions which it implements\n    to always fail with ENOSYS.  Some functions are actually named\n    something starting with __ and the normal name is an alias.  */\n#if defined __stub_$2 || defined __stub___$2\nchoke me\n#endif\n\nint\nmain (void)\n{\nreturn $2 ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  eval \"$3=yes\"\nelse case e in #(\n  e) eval \"$3=no\" ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext ;;\nesac\nfi\neval ac_res=\\$$3\n\t       { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_res\" >&5\nprintf \"%s\\n\" \"$ac_res\" >&6; }\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n\n} # ac_fn_c_check_func\n\n# ac_fn_cxx_try_cpp LINENO\n# ------------------------\n# Try to preprocess conftest.$ac_ext, and return whether this succeeded.\nac_fn_cxx_try_cpp ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  if { { ac_try=\"$ac_cpp conftest.$ac_ext\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_cpp conftest.$ac_ext\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } > conftest.i && {\n\t test -z \"$ac_cxx_preproc_warn_flag$ac_cxx_werror_flag\" ||\n\t test ! -s conftest.err\n       }\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n    ac_retval=1 ;;\nesac\nfi\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_cxx_try_cpp\n\n# ac_fn_cxx_try_link LINENO\n# -------------------------\n# Try to link conftest.$ac_ext, and return whether this succeeded.\nac_fn_cxx_try_link ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  rm -f conftest.$ac_objext conftest.beam conftest$ac_exeext\n  if { { ac_try=\"$ac_link\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && {\n\t test -z \"$ac_cxx_werror_flag\" ||\n\t test ! -s conftest.err\n       } && test -s conftest$ac_exeext && {\n\t test \"$cross_compiling\" = yes ||\n\t test -x conftest$ac_exeext\n       }\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n\tac_retval=1 ;;\nesac\nfi\n  # Delete the IPA/IPO (Inter Procedural Analysis/Optimization) information\n  # created by the PGI compiler (conftest_ipa8_conftest.oo), as it would\n  # interfere with the next link command; also delete a directory that is\n  # left behind by Apple's compiler.  We do this before executing the actions.\n  rm -rf conftest.dSYM conftest_ipa8_conftest.oo\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_cxx_try_link\n\n# ac_fn_c_try_run LINENO\n# ----------------------\n# Try to run conftest.$ac_ext, and return whether this succeeded. Assumes that\n# executables *can* be run.\nac_fn_c_try_run ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  if { { ac_try=\"$ac_link\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && { ac_try='./conftest$ac_exeext'\n  { { case \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_try\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; }\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: program exited with status $ac_status\" >&5\n       printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n       ac_retval=$ac_status ;;\nesac\nfi\n  rm -rf conftest.dSYM conftest_ipa8_conftest.oo\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_c_try_run\n\n# ac_fn_check_decl LINENO SYMBOL VAR INCLUDES EXTRA-OPTIONS FLAG-VAR\n# ------------------------------------------------------------------\n# Tests whether SYMBOL is declared in INCLUDES, setting cache variable VAR\n# accordingly. Pass EXTRA-OPTIONS to the compiler, using FLAG-VAR.\nac_fn_check_decl ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  as_decl_name=`echo $2|sed 's/ *(.*//'`\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $as_decl_name is declared\" >&5\nprintf %s \"checking whether $as_decl_name is declared... \" >&6; }\nif eval test \\${$3+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) as_decl_use=`echo $2|sed -e 's/(/((/' -e 's/)/) 0&/' -e 's/,/) 0& (/g'`\n  eval ac_save_FLAGS=\\$$6\n  as_fn_append $6 \" $5\"\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\n#ifndef $as_decl_name\n#ifdef __cplusplus\n  (void) $as_decl_use;\n#else\n  (void) $as_decl_name;\n#endif\n#endif\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  eval \"$3=yes\"\nelse case e in #(\n  e) eval \"$3=no\" ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n  eval $6=\\$ac_save_FLAGS\n ;;\nesac\nfi\neval ac_res=\\$$3\n\t       { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_res\" >&5\nprintf \"%s\\n\" \"$ac_res\" >&6; }\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n\n} # ac_fn_check_decl\n\n# ac_fn_c_try_cpp LINENO\n# ----------------------\n# Try to preprocess conftest.$ac_ext, and return whether this succeeded.\nac_fn_c_try_cpp ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  if { { ac_try=\"$ac_cpp conftest.$ac_ext\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_cpp conftest.$ac_ext\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    grep -v '^ *+' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n    mv -f conftest.er1 conftest.err\n  fi\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } > conftest.i && {\n\t test -z \"$ac_c_preproc_warn_flag$ac_c_werror_flag\" ||\n\t test ! -s conftest.err\n       }\nthen :\n  ac_retval=0\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n    ac_retval=1 ;;\nesac\nfi\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_c_try_cpp\n\n# ac_fn_c_check_type LINENO TYPE VAR INCLUDES\n# -------------------------------------------\n# Tests whether TYPE exists after having included INCLUDES, setting cache\n# variable VAR accordingly.\nac_fn_c_check_type ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $2\" >&5\nprintf %s \"checking for $2... \" >&6; }\nif eval test \\${$3+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) eval \"$3=no\"\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nif (sizeof ($2))\n\t return 0;\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nif (sizeof (($2)))\n\t    return 0;\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) eval \"$3=yes\" ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\neval ac_res=\\$$3\n\t       { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_res\" >&5\nprintf \"%s\\n\" \"$ac_res\" >&6; }\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n\n} # ac_fn_c_check_type\n\n# ac_fn_c_compute_int LINENO EXPR VAR INCLUDES\n# --------------------------------------------\n# Tries to find the compile-time value of EXPR in a program that includes\n# INCLUDES, setting VAR accordingly. Returns whether the value could be\n# computed\nac_fn_c_compute_int ()\n{\n  as_lineno=${as_lineno-\"$1\"} as_lineno_stack=as_lineno_stack=$as_lineno_stack\n  if test \"$cross_compiling\" = yes; then\n    # Depending upon the size, compute the lo and hi bounds.\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nstatic int test_array [1 - 2 * !(($2) >= 0)];\ntest_array [0] = 0;\nreturn test_array [0];\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_lo=0 ac_mid=0\n  while :; do\n    cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nstatic int test_array [1 - 2 * !(($2) <= $ac_mid)];\ntest_array [0] = 0;\nreturn test_array [0];\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_hi=$ac_mid; break\nelse case e in #(\n  e) as_fn_arith $ac_mid + 1 && ac_lo=$as_val\n\t\t\tif test $ac_lo -le $ac_mid; then\n\t\t\t  ac_lo= ac_hi=\n\t\t\t  break\n\t\t\tfi\n\t\t\tas_fn_arith 2 '*' $ac_mid + 1 && ac_mid=$as_val ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n  done\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nstatic int test_array [1 - 2 * !(($2) < 0)];\ntest_array [0] = 0;\nreturn test_array [0];\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_hi=-1 ac_mid=-1\n  while :; do\n    cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nstatic int test_array [1 - 2 * !(($2) >= $ac_mid)];\ntest_array [0] = 0;\nreturn test_array [0];\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_lo=$ac_mid; break\nelse case e in #(\n  e) as_fn_arith '(' $ac_mid ')' - 1 && ac_hi=$as_val\n\t\t\tif test $ac_mid -le $ac_hi; then\n\t\t\t  ac_lo= ac_hi=\n\t\t\t  break\n\t\t\tfi\n\t\t\tas_fn_arith 2 '*' $ac_mid && ac_mid=$as_val ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n  done\nelse case e in #(\n  e) ac_lo= ac_hi= ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n# Binary search between lo and hi bounds.\nwhile test \"x$ac_lo\" != \"x$ac_hi\"; do\n  as_fn_arith '(' $ac_hi - $ac_lo ')' / 2 + $ac_lo && ac_mid=$as_val\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nint\nmain (void)\n{\nstatic int test_array [1 - 2 * !(($2) <= $ac_mid)];\ntest_array [0] = 0;\nreturn test_array [0];\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_hi=$ac_mid\nelse case e in #(\n  e) as_fn_arith '(' $ac_mid ')' + 1 && ac_lo=$as_val ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\ndone\ncase $ac_lo in #((\n?*) eval \"$3=\\$ac_lo\"; ac_retval=0 ;;\n'') ac_retval=1 ;;\nesac\n  else\n    cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$4\nstatic long int longval (void) { return $2; }\nstatic unsigned long int ulongval (void) { return $2; }\n#include <stdio.h>\n#include <stdlib.h>\nint\nmain (void)\n{\n\n  FILE *f = fopen (\"conftest.val\", \"w\");\n  if (! f)\n    return 1;\n  if (($2) < 0)\n    {\n      long int i = longval ();\n      if (i != ($2))\n\treturn 1;\n      fprintf (f, \"%ld\", i);\n    }\n  else\n    {\n      unsigned long int i = ulongval ();\n      if (i != ($2))\n\treturn 1;\n      fprintf (f, \"%lu\", i);\n    }\n  /* Do not output a trailing newline, as this causes \\r\\n confusion\n     on some platforms.  */\n  return ferror (f) || fclose (f) != 0;\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_run \"$LINENO\"\nthen :\n  echo >>conftest.val; read $3 <conftest.val; ac_retval=0\nelse case e in #(\n  e) ac_retval=1 ;;\nesac\nfi\nrm -f core *.core core.conftest.* gmon.out bb.out conftest$ac_exeext \\\n  conftest.$ac_objext conftest.beam conftest.$ac_ext\nrm -f conftest.val\n\n  fi\n  eval $as_lineno_stack; ${as_lineno_stack:+:} unset as_lineno\n  as_fn_set_status $ac_retval\n\n} # ac_fn_c_compute_int\nac_configure_args_raw=\nfor ac_arg\ndo\n  case $ac_arg in\n  *\\'*)\n    ac_arg=`printf \"%s\\n\" \"$ac_arg\" | sed \"s/'/'\\\\\\\\\\\\\\\\''/g\"` ;;\n  esac\n  as_fn_append ac_configure_args_raw \" '$ac_arg'\"\ndone\n\ncase $ac_configure_args_raw in\n  *$as_nl*)\n    ac_safe_unquote= ;;\n  *)\n    ac_unsafe_z='|&;<>()$`\\\\\"*?[ ''\t' # This string ends in space, tab.\n    ac_unsafe_a=\"$ac_unsafe_z#~\"\n    ac_safe_unquote=\"s/ '\\\\([^$ac_unsafe_a][^$ac_unsafe_z]*\\\\)'/ \\\\1/g\"\n    ac_configure_args_raw=`      printf \"%s\\n\" \"$ac_configure_args_raw\" | sed \"$ac_safe_unquote\"`;;\nesac\n\ncat >config.log <<_ACEOF\nThis file contains any messages produced by compilers while\nrunning configure, to aid debugging if configure makes a mistake.\n\nIt was created by slurm $as_me 25.05, which was\ngenerated by GNU Autoconf 2.72.  Invocation command line was\n\n  $ $0$ac_configure_args_raw\n\n_ACEOF\nexec 5>>config.log\n{\ncat <<_ASUNAME\n## --------- ##\n## Platform. ##\n## --------- ##\n\nhostname = `(hostname || uname -n) 2>/dev/null | sed 1q`\nuname -m = `(uname -m) 2>/dev/null || echo unknown`\nuname -r = `(uname -r) 2>/dev/null || echo unknown`\nuname -s = `(uname -s) 2>/dev/null || echo unknown`\nuname -v = `(uname -v) 2>/dev/null || echo unknown`\n\n/usr/bin/uname -p = `(/usr/bin/uname -p) 2>/dev/null || echo unknown`\n/bin/uname -X     = `(/bin/uname -X) 2>/dev/null     || echo unknown`\n\n/bin/arch              = `(/bin/arch) 2>/dev/null              || echo unknown`\n/usr/bin/arch -k       = `(/usr/bin/arch -k) 2>/dev/null       || echo unknown`\n/usr/convex/getsysinfo = `(/usr/convex/getsysinfo) 2>/dev/null || echo unknown`\n/usr/bin/hostinfo      = `(/usr/bin/hostinfo) 2>/dev/null      || echo unknown`\n/bin/machine           = `(/bin/machine) 2>/dev/null           || echo unknown`\n/usr/bin/oslevel       = `(/usr/bin/oslevel) 2>/dev/null       || echo unknown`\n/bin/universe          = `(/bin/universe) 2>/dev/null          || echo unknown`\n\n_ASUNAME\n\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    printf \"%s\\n\" \"PATH: $as_dir\"\n  done\nIFS=$as_save_IFS\n\n} >&5\n\ncat >&5 <<_ACEOF\n\n\n## ----------- ##\n## Core tests. ##\n## ----------- ##\n\n_ACEOF\n\n\n# Keep a trace of the command line.\n# Strip out --no-create and --no-recursion so they do not pile up.\n# Strip out --silent because we don't want to record it for future runs.\n# Also quote any args containing shell meta-characters.\n# Make two passes to allow for proper duplicate-argument suppression.\nac_configure_args=\nac_configure_args0=\nac_configure_args1=\nac_must_keep_next=false\nfor ac_pass in 1 2\ndo\n  for ac_arg\n  do\n    case $ac_arg in\n    -no-create | --no-c* | -n | -no-recursion | --no-r*) continue ;;\n    -q | -quiet | --quiet | --quie | --qui | --qu | --q \\\n    | -silent | --silent | --silen | --sile | --sil)\n      continue ;;\n    *\\'*)\n      ac_arg=`printf \"%s\\n\" \"$ac_arg\" | sed \"s/'/'\\\\\\\\\\\\\\\\''/g\"` ;;\n    esac\n    case $ac_pass in\n    1) as_fn_append ac_configure_args0 \" '$ac_arg'\" ;;\n    2)\n      as_fn_append ac_configure_args1 \" '$ac_arg'\"\n      if test $ac_must_keep_next = true; then\n\tac_must_keep_next=false # Got value, back to normal.\n      else\n\tcase $ac_arg in\n\t  *=* | --config-cache | -C | -disable-* | --disable-* \\\n\t  | -enable-* | --enable-* | -gas | --g* | -nfp | --nf* \\\n\t  | -q | -quiet | --q* | -silent | --sil* | -v | -verb* \\\n\t  | -with-* | --with-* | -without-* | --without-* | --x)\n\t    case \"$ac_configure_args0 \" in\n\t      \"$ac_configure_args1\"*\" '$ac_arg' \"* ) continue ;;\n\t    esac\n\t    ;;\n\t  -* ) ac_must_keep_next=true ;;\n\tesac\n      fi\n      as_fn_append ac_configure_args \" '$ac_arg'\"\n      ;;\n    esac\n  done\ndone\n{ ac_configure_args0=; unset ac_configure_args0;}\n{ ac_configure_args1=; unset ac_configure_args1;}\n\n# When interrupted or exit'd, cleanup temporary files, and complete\n# config.log.  We remove comments because anyway the quotes in there\n# would cause problems or look ugly.\n# WARNING: Use '\\'' to represent an apostrophe within the trap.\n# WARNING: Do not start the trap code with a newline, due to a FreeBSD 4.0 bug.\ntrap 'exit_status=$?\n  # Sanitize IFS.\n  IFS=\" \"\"\t$as_nl\"\n  # Save into config.log some information that might help in debugging.\n  {\n    echo\n\n    printf \"%s\\n\" \"## ---------------- ##\n## Cache variables. ##\n## ---------------- ##\"\n    echo\n    # The following way of writing the cache mishandles newlines in values,\n(\n  for ac_var in `(set) 2>&1 | sed -n '\\''s/^\\([a-zA-Z_][a-zA-Z0-9_]*\\)=.*/\\1/p'\\''`; do\n    eval ac_val=\\$$ac_var\n    case $ac_val in #(\n    *${as_nl}*)\n      case $ac_var in #(\n      *_cv_*) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: cache variable $ac_var contains a newline\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: cache variable $ac_var contains a newline\" >&2;} ;;\n      esac\n      case $ac_var in #(\n      _ | IFS | as_nl) ;; #(\n      BASH_ARGV | BASH_SOURCE) eval $ac_var= ;; #(\n      *) { eval $ac_var=; unset $ac_var;} ;;\n      esac ;;\n    esac\n  done\n  (set) 2>&1 |\n    case $as_nl`(ac_space='\\'' '\\''; set) 2>&1` in #(\n    *${as_nl}ac_space=\\ *)\n      sed -n \\\n\t\"s/'\\''/'\\''\\\\\\\\'\\'''\\''/g;\n\t  s/^\\\\([_$as_cr_alnum]*_cv_[_$as_cr_alnum]*\\\\)=\\\\(.*\\\\)/\\\\1='\\''\\\\2'\\''/p\"\n      ;; #(\n    *)\n      sed -n \"/^[_$as_cr_alnum]*_cv_[_$as_cr_alnum]*=/p\"\n      ;;\n    esac |\n    sort\n)\n    echo\n\n    printf \"%s\\n\" \"## ----------------- ##\n## Output variables. ##\n## ----------------- ##\"\n    echo\n    for ac_var in $ac_subst_vars\n    do\n      eval ac_val=\\$$ac_var\n      case $ac_val in\n      *\\'\\''*) ac_val=`printf \"%s\\n\" \"$ac_val\" | sed \"s/'\\''/'\\''\\\\\\\\\\\\\\\\'\\'''\\''/g\"`;;\n      esac\n      printf \"%s\\n\" \"$ac_var='\\''$ac_val'\\''\"\n    done | sort\n    echo\n\n    if test -n \"$ac_subst_files\"; then\n      printf \"%s\\n\" \"## ------------------- ##\n## File substitutions. ##\n## ------------------- ##\"\n      echo\n      for ac_var in $ac_subst_files\n      do\n\teval ac_val=\\$$ac_var\n\tcase $ac_val in\n\t*\\'\\''*) ac_val=`printf \"%s\\n\" \"$ac_val\" | sed \"s/'\\''/'\\''\\\\\\\\\\\\\\\\'\\'''\\''/g\"`;;\n\tesac\n\tprintf \"%s\\n\" \"$ac_var='\\''$ac_val'\\''\"\n      done | sort\n      echo\n    fi\n\n    if test -s confdefs.h; then\n      printf \"%s\\n\" \"## ----------- ##\n## confdefs.h. ##\n## ----------- ##\"\n      echo\n      cat confdefs.h\n      echo\n    fi\n    test \"$ac_signal\" != 0 &&\n      printf \"%s\\n\" \"$as_me: caught signal $ac_signal\"\n    printf \"%s\\n\" \"$as_me: exit $exit_status\"\n  } >&5\n  rm -f core *.core core.conftest.* &&\n    rm -f -r conftest* confdefs* conf$$* $ac_clean_files &&\n    exit $exit_status\n' 0\nfor ac_signal in 1 2 13 15; do\n  trap 'ac_signal='$ac_signal'; as_fn_exit 1' $ac_signal\ndone\nac_signal=0\n\n# confdefs.h avoids OS command line length limits that DEFS can exceed.\nrm -f -r conftest* confdefs.h\n\nprintf \"%s\\n\" \"/* confdefs.h */\" > confdefs.h\n\n# Predefined preprocessor variables.\n\nprintf \"%s\\n\" \"#define PACKAGE_NAME \\\"$PACKAGE_NAME\\\"\" >>confdefs.h\n\nprintf \"%s\\n\" \"#define PACKAGE_TARNAME \\\"$PACKAGE_TARNAME\\\"\" >>confdefs.h\n\nprintf \"%s\\n\" \"#define PACKAGE_VERSION \\\"$PACKAGE_VERSION\\\"\" >>confdefs.h\n\nprintf \"%s\\n\" \"#define PACKAGE_STRING \\\"$PACKAGE_STRING\\\"\" >>confdefs.h\n\nprintf \"%s\\n\" \"#define PACKAGE_BUGREPORT \\\"$PACKAGE_BUGREPORT\\\"\" >>confdefs.h\n\nprintf \"%s\\n\" \"#define PACKAGE_URL \\\"$PACKAGE_URL\\\"\" >>confdefs.h\n\n\n# Let the site file select an alternate cache file if it wants to.\n# Prefer an explicitly selected file to automatically selected ones.\nif test -n \"$CONFIG_SITE\"; then\n  ac_site_files=\"$CONFIG_SITE\"\nelif test \"x$prefix\" != xNONE; then\n  ac_site_files=\"$prefix/share/config.site $prefix/etc/config.site\"\nelse\n  ac_site_files=\"$ac_default_prefix/share/config.site $ac_default_prefix/etc/config.site\"\nfi\n\nfor ac_site_file in $ac_site_files\ndo\n  case $ac_site_file in #(\n  */*) :\n     ;; #(\n  *) :\n    ac_site_file=./$ac_site_file ;;\nesac\n  if test -f \"$ac_site_file\" && test -r \"$ac_site_file\"; then\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: loading site script $ac_site_file\" >&5\nprintf \"%s\\n\" \"$as_me: loading site script $ac_site_file\" >&6;}\n    sed 's/^/| /' \"$ac_site_file\" >&5\n    . \"$ac_site_file\" \\\n      || { { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"failed to load site script $ac_site_file\nSee 'config.log' for more details\" \"$LINENO\" 5; }\n  fi\ndone\n\nif test -r \"$cache_file\"; then\n  # Some versions of bash will fail to source /dev/null (special files\n  # actually), so we avoid doing that.  DJGPP emulates it as a regular file.\n  if test /dev/null != \"$cache_file\" && test -f \"$cache_file\"; then\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: loading cache $cache_file\" >&5\nprintf \"%s\\n\" \"$as_me: loading cache $cache_file\" >&6;}\n    case $cache_file in\n      [\\\\/]* | ?:[\\\\/]* ) . \"$cache_file\";;\n      *)                      . \"./$cache_file\";;\n    esac\n  fi\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: creating cache $cache_file\" >&5\nprintf \"%s\\n\" \"$as_me: creating cache $cache_file\" >&6;}\n  >$cache_file\nfi\n\n# Test code for whether the C compiler supports C89 (global declarations)\nac_c_conftest_c89_globals='\n/* Does the compiler advertise C89 conformance?\n   Do not test the value of __STDC__, because some compilers set it to 0\n   while being otherwise adequately conformant. */\n#if !defined __STDC__\n# error \"Compiler does not advertise C89 conformance\"\n#endif\n\n#include <stddef.h>\n#include <stdarg.h>\nstruct stat;\n/* Most of the following tests are stolen from RCS 5.7 src/conf.sh.  */\nstruct buf { int x; };\nstruct buf * (*rcsopen) (struct buf *, struct stat *, int);\nstatic char *e (char **p, int i)\n{\n  return p[i];\n}\nstatic char *f (char * (*g) (char **, int), char **p, ...)\n{\n  char *s;\n  va_list v;\n  va_start (v,p);\n  s = g (p, va_arg (v,int));\n  va_end (v);\n  return s;\n}\n\n/* C89 style stringification. */\n#define noexpand_stringify(a) #a\nconst char *stringified = noexpand_stringify(arbitrary+token=sequence);\n\n/* C89 style token pasting.  Exercises some of the corner cases that\n   e.g. old MSVC gets wrong, but not very hard. */\n#define noexpand_concat(a,b) a##b\n#define expand_concat(a,b) noexpand_concat(a,b)\nextern int vA;\nextern int vbee;\n#define aye A\n#define bee B\nint *pvA = &expand_concat(v,aye);\nint *pvbee = &noexpand_concat(v,bee);\n\n/* OSF 4.0 Compaq cc is some sort of almost-ANSI by default.  It has\n   function prototypes and stuff, but not \\xHH hex character constants.\n   These do not provoke an error unfortunately, instead are silently treated\n   as an \"x\".  The following induces an error, until -std is added to get\n   proper ANSI mode.  Curiously \\x00 != x always comes out true, for an\n   array size at least.  It is necessary to write \\x00 == 0 to get something\n   that is true only with -std.  */\nint osf4_cc_array ['\\''\\x00'\\'' == 0 ? 1 : -1];\n\n/* IBM C 6 for AIX is almost-ANSI by default, but it replaces macro parameters\n   inside strings and character constants.  */\n#define FOO(x) '\\''x'\\''\nint xlc6_cc_array[FOO(a) == '\\''x'\\'' ? 1 : -1];\n\nint test (int i, double x);\nstruct s1 {int (*f) (int a);};\nstruct s2 {int (*f) (double a);};\nint pairnames (int, char **, int *(*)(struct buf *, struct stat *, int),\n               int, int);'\n\n# Test code for whether the C compiler supports C89 (body of main).\nac_c_conftest_c89_main='\nok |= (argc == 0 || f (e, argv, 0) != argv[0] || f (e, argv, 1) != argv[1]);\n'\n\n# Test code for whether the C compiler supports C99 (global declarations)\nac_c_conftest_c99_globals='\n/* Does the compiler advertise C99 conformance? */\n#if !defined __STDC_VERSION__ || __STDC_VERSION__ < 199901L\n# error \"Compiler does not advertise C99 conformance\"\n#endif\n\n// See if C++-style comments work.\n\n#include <stdbool.h>\nextern int puts (const char *);\nextern int printf (const char *, ...);\nextern int dprintf (int, const char *, ...);\nextern void *malloc (size_t);\nextern void free (void *);\n\n// Check varargs macros.  These examples are taken from C99 6.10.3.5.\n// dprintf is used instead of fprintf to avoid needing to declare\n// FILE and stderr.\n#define debug(...) dprintf (2, __VA_ARGS__)\n#define showlist(...) puts (#__VA_ARGS__)\n#define report(test,...) ((test) ? puts (#test) : printf (__VA_ARGS__))\nstatic void\ntest_varargs_macros (void)\n{\n  int x = 1234;\n  int y = 5678;\n  debug (\"Flag\");\n  debug (\"X = %d\\n\", x);\n  showlist (The first, second, and third items.);\n  report (x>y, \"x is %d but y is %d\", x, y);\n}\n\n// Check long long types.\n#define BIG64 18446744073709551615ull\n#define BIG32 4294967295ul\n#define BIG_OK (BIG64 / BIG32 == 4294967297ull && BIG64 % BIG32 == 0)\n#if !BIG_OK\n  #error \"your preprocessor is broken\"\n#endif\n#if BIG_OK\n#else\n  #error \"your preprocessor is broken\"\n#endif\nstatic long long int bignum = -9223372036854775807LL;\nstatic unsigned long long int ubignum = BIG64;\n\nstruct incomplete_array\n{\n  int datasize;\n  double data[];\n};\n\nstruct named_init {\n  int number;\n  const wchar_t *name;\n  double average;\n};\n\ntypedef const char *ccp;\n\nstatic inline int\ntest_restrict (ccp restrict text)\n{\n  // Iterate through items via the restricted pointer.\n  // Also check for declarations in for loops.\n  for (unsigned int i = 0; *(text+i) != '\\''\\0'\\''; ++i)\n    continue;\n  return 0;\n}\n\n// Check varargs and va_copy.\nstatic bool\ntest_varargs (const char *format, ...)\n{\n  va_list args;\n  va_start (args, format);\n  va_list args_copy;\n  va_copy (args_copy, args);\n\n  const char *str = \"\";\n  int number = 0;\n  float fnumber = 0;\n\n  while (*format)\n    {\n      switch (*format++)\n\t{\n\tcase '\\''s'\\'': // string\n\t  str = va_arg (args_copy, const char *);\n\t  break;\n\tcase '\\''d'\\'': // int\n\t  number = va_arg (args_copy, int);\n\t  break;\n\tcase '\\''f'\\'': // float\n\t  fnumber = va_arg (args_copy, double);\n\t  break;\n\tdefault:\n\t  break;\n\t}\n    }\n  va_end (args_copy);\n  va_end (args);\n\n  return *str && number && fnumber;\n}\n'\n\n# Test code for whether the C compiler supports C99 (body of main).\nac_c_conftest_c99_main='\n  // Check bool.\n  _Bool success = false;\n  success |= (argc != 0);\n\n  // Check restrict.\n  if (test_restrict (\"String literal\") == 0)\n    success = true;\n  char *restrict newvar = \"Another string\";\n\n  // Check varargs.\n  success &= test_varargs (\"s, d'\\'' f .\", \"string\", 65, 34.234);\n  test_varargs_macros ();\n\n  // Check flexible array members.\n  struct incomplete_array *ia =\n    malloc (sizeof (struct incomplete_array) + (sizeof (double) * 10));\n  ia->datasize = 10;\n  for (int i = 0; i < ia->datasize; ++i)\n    ia->data[i] = i * 1.234;\n  // Work around memory leak warnings.\n  free (ia);\n\n  // Check named initializers.\n  struct named_init ni = {\n    .number = 34,\n    .name = L\"Test wide string\",\n    .average = 543.34343,\n  };\n\n  ni.number = 58;\n\n  int dynamic_array[ni.number];\n  dynamic_array[0] = argv[0][0];\n  dynamic_array[ni.number - 1] = 543;\n\n  // work around unused variable warnings\n  ok |= (!success || bignum == 0LL || ubignum == 0uLL || newvar[0] == '\\''x'\\''\n\t || dynamic_array[ni.number - 1] != 543);\n'\n\n# Test code for whether the C compiler supports C11 (global declarations)\nac_c_conftest_c11_globals='\n/* Does the compiler advertise C11 conformance? */\n#if !defined __STDC_VERSION__ || __STDC_VERSION__ < 201112L\n# error \"Compiler does not advertise C11 conformance\"\n#endif\n\n// Check _Alignas.\nchar _Alignas (double) aligned_as_double;\nchar _Alignas (0) no_special_alignment;\nextern char aligned_as_int;\nchar _Alignas (0) _Alignas (int) aligned_as_int;\n\n// Check _Alignof.\nenum\n{\n  int_alignment = _Alignof (int),\n  int_array_alignment = _Alignof (int[100]),\n  char_alignment = _Alignof (char)\n};\n_Static_assert (0 < -_Alignof (int), \"_Alignof is signed\");\n\n// Check _Noreturn.\nint _Noreturn does_not_return (void) { for (;;) continue; }\n\n// Check _Static_assert.\nstruct test_static_assert\n{\n  int x;\n  _Static_assert (sizeof (int) <= sizeof (long int),\n                  \"_Static_assert does not work in struct\");\n  long int y;\n};\n\n// Check UTF-8 literals.\n#define u8 syntax error!\nchar const utf8_literal[] = u8\"happens to be ASCII\" \"another string\";\n\n// Check duplicate typedefs.\ntypedef long *long_ptr;\ntypedef long int *long_ptr;\ntypedef long_ptr long_ptr;\n\n// Anonymous structures and unions -- taken from C11 6.7.2.1 Example 1.\nstruct anonymous\n{\n  union {\n    struct { int i; int j; };\n    struct { int k; long int l; } w;\n  };\n  int m;\n} v1;\n'\n\n# Test code for whether the C compiler supports C11 (body of main).\nac_c_conftest_c11_main='\n  _Static_assert ((offsetof (struct anonymous, i)\n\t\t   == offsetof (struct anonymous, w.k)),\n\t\t  \"Anonymous union alignment botch\");\n  v1.i = 2;\n  v1.w.k = 5;\n  ok |= v1.i != 5;\n'\n\n# Test code for whether the C compiler supports C11 (complete).\nac_c_conftest_c11_program=\"${ac_c_conftest_c89_globals}\n${ac_c_conftest_c99_globals}\n${ac_c_conftest_c11_globals}\n\nint\nmain (int argc, char **argv)\n{\n  int ok = 0;\n  ${ac_c_conftest_c89_main}\n  ${ac_c_conftest_c99_main}\n  ${ac_c_conftest_c11_main}\n  return ok;\n}\n\"\n\n# Test code for whether the C compiler supports C99 (complete).\nac_c_conftest_c99_program=\"${ac_c_conftest_c89_globals}\n${ac_c_conftest_c99_globals}\n\nint\nmain (int argc, char **argv)\n{\n  int ok = 0;\n  ${ac_c_conftest_c89_main}\n  ${ac_c_conftest_c99_main}\n  return ok;\n}\n\"\n\n# Test code for whether the C compiler supports C89 (complete).\nac_c_conftest_c89_program=\"${ac_c_conftest_c89_globals}\n\nint\nmain (int argc, char **argv)\n{\n  int ok = 0;\n  ${ac_c_conftest_c89_main}\n  return ok;\n}\n\"\n\n# Test code for whether the C++ compiler supports C++98 (global declarations)\nac_cxx_conftest_cxx98_globals='\n// Does the compiler advertise C++98 conformance?\n#if !defined __cplusplus || __cplusplus < 199711L\n# error \"Compiler does not advertise C++98 conformance\"\n#endif\n\n// These inclusions are to reject old compilers that\n// lack the unsuffixed header files.\n#include <cstdlib>\n#include <exception>\n\n// <cassert> and <cstring> are *not* freestanding headers in C++98.\nextern void assert (int);\nnamespace std {\n  extern int strcmp (const char *, const char *);\n}\n\n// Namespaces, exceptions, and templates were all added after \"C++ 2.0\".\nusing std::exception;\nusing std::strcmp;\n\nnamespace {\n\nvoid test_exception_syntax()\n{\n  try {\n    throw \"test\";\n  } catch (const char *s) {\n    // Extra parentheses suppress a warning when building autoconf itself,\n    // due to lint rules shared with more typical C programs.\n    assert (!(strcmp) (s, \"test\"));\n  }\n}\n\ntemplate <typename T> struct test_template\n{\n  T const val;\n  explicit test_template(T t) : val(t) {}\n  template <typename U> T add(U u) { return static_cast<T>(u) + val; }\n};\n\n} // anonymous namespace\n'\n\n# Test code for whether the C++ compiler supports C++98 (body of main)\nac_cxx_conftest_cxx98_main='\n  assert (argc);\n  assert (! argv[0]);\n{\n  test_exception_syntax ();\n  test_template<double> tt (2.0);\n  assert (tt.add (4) == 6.0);\n  assert (true && !false);\n}\n'\n\n# Test code for whether the C++ compiler supports C++11 (global declarations)\nac_cxx_conftest_cxx11_globals='\n// Does the compiler advertise C++ 2011 conformance?\n#if !defined __cplusplus || __cplusplus < 201103L\n# error \"Compiler does not advertise C++11 conformance\"\n#endif\n\nnamespace cxx11test\n{\n  constexpr int get_val() { return 20; }\n\n  struct testinit\n  {\n    int i;\n    double d;\n  };\n\n  class delegate\n  {\n  public:\n    delegate(int n) : n(n) {}\n    delegate(): delegate(2354) {}\n\n    virtual int getval() { return this->n; };\n  protected:\n    int n;\n  };\n\n  class overridden : public delegate\n  {\n  public:\n    overridden(int n): delegate(n) {}\n    virtual int getval() override final { return this->n * 2; }\n  };\n\n  class nocopy\n  {\n  public:\n    nocopy(int i): i(i) {}\n    nocopy() = default;\n    nocopy(const nocopy&) = delete;\n    nocopy & operator=(const nocopy&) = delete;\n  private:\n    int i;\n  };\n\n  // for testing lambda expressions\n  template <typename Ret, typename Fn> Ret eval(Fn f, Ret v)\n  {\n    return f(v);\n  }\n\n  // for testing variadic templates and trailing return types\n  template <typename V> auto sum(V first) -> V\n  {\n    return first;\n  }\n  template <typename V, typename... Args> auto sum(V first, Args... rest) -> V\n  {\n    return first + sum(rest...);\n  }\n}\n'\n\n# Test code for whether the C++ compiler supports C++11 (body of main)\nac_cxx_conftest_cxx11_main='\n{\n  // Test auto and decltype\n  auto a1 = 6538;\n  auto a2 = 48573953.4;\n  auto a3 = \"String literal\";\n\n  int total = 0;\n  for (auto i = a3; *i; ++i) { total += *i; }\n\n  decltype(a2) a4 = 34895.034;\n}\n{\n  // Test constexpr\n  short sa[cxx11test::get_val()] = { 0 };\n}\n{\n  // Test initializer lists\n  cxx11test::testinit il = { 4323, 435234.23544 };\n}\n{\n  // Test range-based for\n  int array[] = {9, 7, 13, 15, 4, 18, 12, 10, 5, 3,\n                 14, 19, 17, 8, 6, 20, 16, 2, 11, 1};\n  for (auto &x : array) { x += 23; }\n}\n{\n  // Test lambda expressions\n  using cxx11test::eval;\n  assert (eval ([](int x) { return x*2; }, 21) == 42);\n  double d = 2.0;\n  assert (eval ([&](double x) { return d += x; }, 3.0) == 5.0);\n  assert (d == 5.0);\n  assert (eval ([=](double x) mutable { return d += x; }, 4.0) == 9.0);\n  assert (d == 5.0);\n}\n{\n  // Test use of variadic templates\n  using cxx11test::sum;\n  auto a = sum(1);\n  auto b = sum(1, 2);\n  auto c = sum(1.0, 2.0, 3.0);\n}\n{\n  // Test constructor delegation\n  cxx11test::delegate d1;\n  cxx11test::delegate d2();\n  cxx11test::delegate d3(45);\n}\n{\n  // Test override and final\n  cxx11test::overridden o1(55464);\n}\n{\n  // Test nullptr\n  char *c = nullptr;\n}\n{\n  // Test template brackets\n  test_template<::test_template<int>> v(test_template<int>(12));\n}\n{\n  // Unicode literals\n  char const *utf8 = u8\"UTF-8 string \\u2500\";\n  char16_t const *utf16 = u\"UTF-8 string \\u2500\";\n  char32_t const *utf32 = U\"UTF-32 string \\u2500\";\n}\n'\n\n# Test code for whether the C compiler supports C++11 (complete).\nac_cxx_conftest_cxx11_program=\"${ac_cxx_conftest_cxx98_globals}\n${ac_cxx_conftest_cxx11_globals}\n\nint\nmain (int argc, char **argv)\n{\n  int ok = 0;\n  ${ac_cxx_conftest_cxx98_main}\n  ${ac_cxx_conftest_cxx11_main}\n  return ok;\n}\n\"\n\n# Test code for whether the C compiler supports C++98 (complete).\nac_cxx_conftest_cxx98_program=\"${ac_cxx_conftest_cxx98_globals}\nint\nmain (int argc, char **argv)\n{\n  int ok = 0;\n  ${ac_cxx_conftest_cxx98_main}\n  return ok;\n}\n\"\n\nas_fn_append ac_header_c_list \" stdio.h stdio_h HAVE_STDIO_H\"\nas_fn_append ac_header_c_list \" stdlib.h stdlib_h HAVE_STDLIB_H\"\nas_fn_append ac_header_c_list \" string.h string_h HAVE_STRING_H\"\nas_fn_append ac_header_c_list \" inttypes.h inttypes_h HAVE_INTTYPES_H\"\nas_fn_append ac_header_c_list \" stdint.h stdint_h HAVE_STDINT_H\"\nas_fn_append ac_header_c_list \" strings.h strings_h HAVE_STRINGS_H\"\nas_fn_append ac_header_c_list \" sys/stat.h sys_stat_h HAVE_SYS_STAT_H\"\nas_fn_append ac_header_c_list \" sys/types.h sys_types_h HAVE_SYS_TYPES_H\"\nas_fn_append ac_header_c_list \" unistd.h unistd_h HAVE_UNISTD_H\"\n\n# Auxiliary files required by this configure script.\nac_aux_files=\"ltmain.sh compile missing install-sh config.guess config.sub\"\n\n# Locations in which to look for auxiliary files.\nac_aux_dir_candidates=\"${srcdir}/auxdir\"\n\n# Search for a directory containing all of the required auxiliary files,\n# $ac_aux_files, from the $PATH-style list $ac_aux_dir_candidates.\n# If we don't find one directory that contains all the files we need,\n# we report the set of missing files from the *first* directory in\n# $ac_aux_dir_candidates and give up.\nac_missing_aux_files=\"\"\nac_first_candidate=:\nprintf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: looking for aux files: $ac_aux_files\" >&5\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nas_found=false\nfor as_dir in $ac_aux_dir_candidates\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n  as_found=:\n\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:  trying $as_dir\" >&5\n  ac_aux_dir_found=yes\n  ac_install_sh=\n  for ac_aux in $ac_aux_files\n  do\n    # As a special case, if \"install-sh\" is required, that requirement\n    # can be satisfied by any of \"install-sh\", \"install.sh\", or \"shtool\",\n    # and $ac_install_sh is set appropriately for whichever one is found.\n    if test x\"$ac_aux\" = x\"install-sh\"\n    then\n      if test -f \"${as_dir}install-sh\"; then\n        printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   ${as_dir}install-sh found\" >&5\n        ac_install_sh=\"${as_dir}install-sh -c\"\n      elif test -f \"${as_dir}install.sh\"; then\n        printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   ${as_dir}install.sh found\" >&5\n        ac_install_sh=\"${as_dir}install.sh -c\"\n      elif test -f \"${as_dir}shtool\"; then\n        printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   ${as_dir}shtool found\" >&5\n        ac_install_sh=\"${as_dir}shtool install -c\"\n      else\n        ac_aux_dir_found=no\n        if $ac_first_candidate; then\n          ac_missing_aux_files=\"${ac_missing_aux_files} install-sh\"\n        else\n          break\n        fi\n      fi\n    else\n      if test -f \"${as_dir}${ac_aux}\"; then\n        printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   ${as_dir}${ac_aux} found\" >&5\n      else\n        ac_aux_dir_found=no\n        if $ac_first_candidate; then\n          ac_missing_aux_files=\"${ac_missing_aux_files} ${ac_aux}\"\n        else\n          break\n        fi\n      fi\n    fi\n  done\n  if test \"$ac_aux_dir_found\" = yes; then\n    ac_aux_dir=\"$as_dir\"\n    break\n  fi\n  ac_first_candidate=false\n\n  as_found=false\ndone\nIFS=$as_save_IFS\nif $as_found\nthen :\n\nelse case e in #(\n  e) as_fn_error $? \"cannot find required auxiliary files:$ac_missing_aux_files\" \"$LINENO\" 5 ;;\nesac\nfi\n\n\n# These three variables are undocumented and unsupported,\n# and are intended to be withdrawn in a future Autoconf release.\n# They can cause serious problems if a builder's source tree is in a directory\n# whose full name contains unusual characters.\nif test -f \"${ac_aux_dir}config.guess\"; then\n  ac_config_guess=\"$SHELL ${ac_aux_dir}config.guess\"\nfi\nif test -f \"${ac_aux_dir}config.sub\"; then\n  ac_config_sub=\"$SHELL ${ac_aux_dir}config.sub\"\nfi\nif test -f \"$ac_aux_dir/configure\"; then\n  ac_configure=\"$SHELL ${ac_aux_dir}configure\"\nfi\n\n# Check that the precious variables saved in the cache have kept the same\n# value.\nac_cache_corrupted=false\nfor ac_var in $ac_precious_vars; do\n  eval ac_old_set=\\$ac_cv_env_${ac_var}_set\n  eval ac_new_set=\\$ac_env_${ac_var}_set\n  eval ac_old_val=\\$ac_cv_env_${ac_var}_value\n  eval ac_new_val=\\$ac_env_${ac_var}_value\n  case $ac_old_set,$ac_new_set in\n    set,)\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: '$ac_var' was set to '$ac_old_val' in the previous run\" >&5\nprintf \"%s\\n\" \"$as_me: error: '$ac_var' was set to '$ac_old_val' in the previous run\" >&2;}\n      ac_cache_corrupted=: ;;\n    ,set)\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: '$ac_var' was not set in the previous run\" >&5\nprintf \"%s\\n\" \"$as_me: error: '$ac_var' was not set in the previous run\" >&2;}\n      ac_cache_corrupted=: ;;\n    ,);;\n    *)\n      if test \"x$ac_old_val\" != \"x$ac_new_val\"; then\n\t# differences in whitespace do not lead to failure.\n\tac_old_val_w=`echo x $ac_old_val`\n\tac_new_val_w=`echo x $ac_new_val`\n\tif test \"$ac_old_val_w\" != \"$ac_new_val_w\"; then\n\t  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: '$ac_var' has changed since the previous run:\" >&5\nprintf \"%s\\n\" \"$as_me: error: '$ac_var' has changed since the previous run:\" >&2;}\n\t  ac_cache_corrupted=:\n\telse\n\t  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: warning: ignoring whitespace changes in '$ac_var' since the previous run:\" >&5\nprintf \"%s\\n\" \"$as_me: warning: ignoring whitespace changes in '$ac_var' since the previous run:\" >&2;}\n\t  eval $ac_var=\\$ac_old_val\n\tfi\n\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   former value:  '$ac_old_val'\" >&5\nprintf \"%s\\n\" \"$as_me:   former value:  '$ac_old_val'\" >&2;}\n\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}:   current value: '$ac_new_val'\" >&5\nprintf \"%s\\n\" \"$as_me:   current value: '$ac_new_val'\" >&2;}\n      fi;;\n  esac\n  # Pass precious variables to config.status.\n  if test \"$ac_new_set\" = set; then\n    case $ac_new_val in\n    *\\'*) ac_arg=$ac_var=`printf \"%s\\n\" \"$ac_new_val\" | sed \"s/'/'\\\\\\\\\\\\\\\\''/g\"` ;;\n    *) ac_arg=$ac_var=$ac_new_val ;;\n    esac\n    case \" $ac_configure_args \" in\n      *\" '$ac_arg' \"*) ;; # Avoid dups.  Use of quotes ensures accuracy.\n      *) as_fn_append ac_configure_args \" '$ac_arg'\" ;;\n    esac\n  fi\ndone\nif $ac_cache_corrupted; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: changes in the environment can compromise the build\" >&5\nprintf \"%s\\n\" \"$as_me: error: changes in the environment can compromise the build\" >&2;}\n  as_fn_error $? \"run '${MAKE-make} distclean' and/or 'rm $cache_file'\n\t    and start over\" \"$LINENO\" 5\nfi\n## -------------------- ##\n## Main body of script. ##\n## -------------------- ##\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\n\n\n\n\n\n\n\n  # Make sure we can run config.sub.\n$SHELL \"${ac_aux_dir}config.sub\" sun4 >/dev/null 2>&1 ||\n  as_fn_error $? \"cannot run $SHELL ${ac_aux_dir}config.sub\" \"$LINENO\" 5\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking build system type\" >&5\nprintf %s \"checking build system type... \" >&6; }\nif test ${ac_cv_build+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_build_alias=$build_alias\ntest \"x$ac_build_alias\" = x &&\n  ac_build_alias=`$SHELL \"${ac_aux_dir}config.guess\"`\ntest \"x$ac_build_alias\" = x &&\n  as_fn_error $? \"cannot guess build type; you must specify one\" \"$LINENO\" 5\nac_cv_build=`$SHELL \"${ac_aux_dir}config.sub\" $ac_build_alias` ||\n  as_fn_error $? \"$SHELL ${ac_aux_dir}config.sub $ac_build_alias failed\" \"$LINENO\" 5\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_build\" >&5\nprintf \"%s\\n\" \"$ac_cv_build\" >&6; }\ncase $ac_cv_build in\n*-*-*) ;;\n*) as_fn_error $? \"invalid value of canonical build\" \"$LINENO\" 5;;\nesac\nbuild=$ac_cv_build\nac_save_IFS=$IFS; IFS='-'\nset x $ac_cv_build\nshift\nbuild_cpu=$1\nbuild_vendor=$2\nshift; shift\n# Remember, the first character of IFS is used to create $*,\n# except with old shells:\nbuild_os=$*\nIFS=$ac_save_IFS\ncase $build_os in *\\ *) build_os=`echo \"$build_os\" | sed 's/ /-/g'`;; esac\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking host system type\" >&5\nprintf %s \"checking host system type... \" >&6; }\nif test ${ac_cv_host+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test \"x$host_alias\" = x; then\n  ac_cv_host=$ac_cv_build\nelse\n  ac_cv_host=`$SHELL \"${ac_aux_dir}config.sub\" $host_alias` ||\n    as_fn_error $? \"$SHELL ${ac_aux_dir}config.sub $host_alias failed\" \"$LINENO\" 5\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_host\" >&5\nprintf \"%s\\n\" \"$ac_cv_host\" >&6; }\ncase $ac_cv_host in\n*-*-*) ;;\n*) as_fn_error $? \"invalid value of canonical host\" \"$LINENO\" 5;;\nesac\nhost=$ac_cv_host\nac_save_IFS=$IFS; IFS='-'\nset x $ac_cv_host\nshift\nhost_cpu=$1\nhost_vendor=$2\nshift; shift\n# Remember, the first character of IFS is used to create $*,\n# except with old shells:\nhost_os=$*\nIFS=$ac_save_IFS\ncase $host_os in *\\ *) host_os=`echo \"$host_os\" | sed 's/ /-/g'`;; esac\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking target system type\" >&5\nprintf %s \"checking target system type... \" >&6; }\nif test ${ac_cv_target+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test \"x$target_alias\" = x; then\n  ac_cv_target=$ac_cv_host\nelse\n  ac_cv_target=`$SHELL \"${ac_aux_dir}config.sub\" $target_alias` ||\n    as_fn_error $? \"$SHELL ${ac_aux_dir}config.sub $target_alias failed\" \"$LINENO\" 5\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_target\" >&5\nprintf \"%s\\n\" \"$ac_cv_target\" >&6; }\ncase $ac_cv_target in\n*-*-*) ;;\n*) as_fn_error $? \"invalid value of canonical target\" \"$LINENO\" 5;;\nesac\ntarget=$ac_cv_target\nac_save_IFS=$IFS; IFS='-'\nset x $ac_cv_target\nshift\ntarget_cpu=$1\ntarget_vendor=$2\nshift; shift\n# Remember, the first character of IFS is used to create $*,\n# except with old shells:\ntarget_os=$*\nIFS=$ac_save_IFS\ncase $target_os in *\\ *) target_os=`echo \"$target_os\" | sed 's/ /-/g'`;; esac\n\n\n# The aliases save the names the user supplied, while $host etc.\n# will get canonicalized.\ntest -n \"$target_alias\" &&\n  test \"$program_prefix$program_suffix$program_transform_name\" = \\\n    NONENONEs,x,x, &&\n  program_prefix=${target_alias}-\n\n if test \"1\" = \"0\"; then\n  DONT_BUILD_TRUE=\n  DONT_BUILD_FALSE='#'\nelse\n  DONT_BUILD_TRUE='#'\n  DONT_BUILD_FALSE=\nfi\n\n\n# Determine project/version from META file.\n# Sets PACKAGE, VERSION, SLURM_VERSION\n\n#\n# Determine project/version from META file.\n#  These are substituted into the Makefile and config.h.\n#\nPROJECT=\"`perl -ne 'print,exit if s/^\\s*NAME:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\n\nprintf \"%s\\n\" \"#define PROJECT \\\"$PROJECT\\\"\" >>confdefs.h\n\n\n\n# Automake desires \"PACKAGE\" variable instead of PROJECT\nPACKAGE=$PROJECT\n\n## Build the API version\n## NOTE: We map API_MAJOR to be (API_CURRENT - API_AGE) to match the\n##  behavior of libtool in setting the library version number. For more\n##  information see src/api/Makefile.am\nfor name in CURRENT REVISION AGE; do\n   API=`perl -ne \"print,exit if s/^\\s*API_$name:\\s*(\\S*).*/\\1/i\" $srcdir/META`\n   eval SLURM_API_$name=$API\ndone\nSLURM_API_MAJOR=`expr $SLURM_API_CURRENT - $SLURM_API_AGE`\nSLURM_API_VERSION=`printf \"0x%02x%02x%02x\" ${SLURM_API_MAJOR#0} ${SLURM_API_AGE#0} ${SLURM_API_REVISION#0}`\n\n\nprintf \"%s\\n\" \"#define SLURM_API_VERSION $SLURM_API_VERSION\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_API_CURRENT $SLURM_API_CURRENT\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_API_MAJOR $SLURM_API_MAJOR\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_API_AGE $SLURM_API_AGE\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_API_REVISION $SLURM_API_REVISION\" >>confdefs.h\n\n\n\n\n\n\n\n# rpm make target needs Version in META, not major and minor version numbers\nVERSION=\"`perl -ne 'print,exit if s/^\\s*VERSION:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\n# If you ever use AM_INIT_AUTOMAKE(subdir-objects) do not define VERSION\n# since it will do it this automatically\n\nprintf \"%s\\n\" \"#define VERSION \\\"$VERSION\\\"\" >>confdefs.h\n\n\n\nSLURM_MAJOR=\"`perl -ne 'print,exit if s/^\\s*MAJOR:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\nSLURM_MINOR=\"`perl -ne 'print,exit if s/^\\s*MINOR:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\nSLURM_MICRO=\"`perl -ne 'print,exit if s/^\\s*MICRO:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\nRELEASE=\"`perl -ne 'print,exit if s/^\\s*RELEASE:\\s*(\\S*).*/\\1/i' $srcdir/META`\"\n\n# NOTE: SLURM_VERSION_NUMBER excludes any non-numeric component\n# (e.g. \"pre1\" in the MICRO), but may be suitable for the user determining\n# how to use the APIs or other differences.\nSLURM_VERSION_NUMBER=\"`printf \"0x%02x%02x%02x\" ${SLURM_MAJOR#0} ${SLURM_MINOR#0} ${SLURM_MICRO#0}`\"\n\nprintf \"%s\\n\" \"#define SLURM_VERSION_NUMBER $SLURM_VERSION_NUMBER\" >>confdefs.h\n\n\n\nif test \"$SLURM_MAJOR.$SLURM_MINOR.$SLURM_MICRO\" != \"$VERSION\"; then\n    as_fn_error $? \"META information is inconsistent: $VERSION != $SLURM_MAJOR.$SLURM_MINOR.$SLURM_MICRO!\" \"$LINENO\" 5\nfi\n\n# Check to see if we're on an unstable branch (no prereleases yet)\nif echo \"$RELEASE\" | grep -e \"UNSTABLE\"; then\n   DATE=`date +\"%Y%m%d%H%M\"`\n   SLURM_RELEASE=\"unstable svn build $DATE\"\n   SLURM_VERSION_STRING=\"$SLURM_MAJOR.$SLURM_MINOR ($SLURM_RELEASE)\"\nelse\n   SLURM_RELEASE=\"`echo $RELEASE | sed 's/^0\\.//'`\"\n   SLURM_VERSION_STRING=\"$SLURM_MAJOR.$SLURM_MINOR.$SLURM_MICRO\"\n   test $RELEASE = \"1\" || SLURM_VERSION_STRING=\"$SLURM_VERSION_STRING-$SLURM_RELEASE\"\nfi\n\nprintf \"%s\\n\" \"#define SLURM_MAJOR \\\"$SLURM_MAJOR\\\"\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_MINOR \\\"$SLURM_MINOR\\\"\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_MICRO \\\"$SLURM_MICRO\\\"\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define RELEASE \\\"$RELEASE\\\"\" >>confdefs.h\n\n\nprintf \"%s\\n\" \"#define SLURM_VERSION_STRING \\\"$SLURM_VERSION_STRING\\\"\" >>confdefs.h\n\n\n\n\n\n\n\n\n\n\nam__api_version='1.16'\n\n\n  # Find a good install program.  We prefer a C program (faster),\n# so one script is as good as another.  But avoid the broken or\n# incompatible versions:\n# SysV /etc/install, /usr/sbin/install\n# SunOS /usr/etc/install\n# IRIX /sbin/install\n# AIX /bin/install\n# AmigaOS /C/install, which installs bootblocks on floppy discs\n# AIX 4 /usr/bin/installbsd, which doesn't work without a -g flag\n# AFS /usr/afsws/bin/install, which mishandles nonexistent args\n# SVR4 /usr/ucb/install, which tries to use the nonexistent group \"staff\"\n# OS/2's system install, which has a completely different semantic\n# ./install, which can be erroneously created by make from ./install.sh.\n# Reject install programs that cannot install multiple files.\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for a BSD-compatible install\" >&5\nprintf %s \"checking for a BSD-compatible install... \" >&6; }\nif test -z \"$INSTALL\"; then\nif test ${ac_cv_path_install+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    # Account for fact that we put trailing slashes in our PATH walk.\ncase $as_dir in #((\n  ./ | /[cC]/* | \\\n  /etc/* | /usr/sbin/* | /usr/etc/* | /sbin/* | /usr/afsws/bin/* | \\\n  ?:[\\\\/]os2[\\\\/]install[\\\\/]* | ?:[\\\\/]OS2[\\\\/]INSTALL[\\\\/]* | \\\n  /usr/ucb/* ) ;;\n  *)\n    # OSF1 and SCO ODT 3.0 have their own names for install.\n    # Don't use installbsd from OSF since it installs stuff as root\n    # by default.\n    for ac_prog in ginstall scoinst install; do\n      for ac_exec_ext in '' $ac_executable_extensions; do\n\tif as_fn_executable_p \"$as_dir$ac_prog$ac_exec_ext\"; then\n\t  if test $ac_prog = install &&\n\t    grep dspmsg \"$as_dir$ac_prog$ac_exec_ext\" >/dev/null 2>&1; then\n\t    # AIX install.  It has an incompatible calling convention.\n\t    :\n\t  elif test $ac_prog = install &&\n\t    grep pwplus \"$as_dir$ac_prog$ac_exec_ext\" >/dev/null 2>&1; then\n\t    # program-specific install script used by HP pwplus--don't use.\n\t    :\n\t  else\n\t    rm -rf conftest.one conftest.two conftest.dir\n\t    echo one > conftest.one\n\t    echo two > conftest.two\n\t    mkdir conftest.dir\n\t    if \"$as_dir$ac_prog$ac_exec_ext\" -c conftest.one conftest.two \"`pwd`/conftest.dir/\" &&\n\t      test -s conftest.one && test -s conftest.two &&\n\t      test -s conftest.dir/conftest.one &&\n\t      test -s conftest.dir/conftest.two\n\t    then\n\t      ac_cv_path_install=\"$as_dir$ac_prog$ac_exec_ext -c\"\n\t      break 3\n\t    fi\n\t  fi\n\tfi\n      done\n    done\n    ;;\nesac\n\n  done\nIFS=$as_save_IFS\n\nrm -rf conftest.one conftest.two conftest.dir\n ;;\nesac\nfi\n  if test ${ac_cv_path_install+y}; then\n    INSTALL=$ac_cv_path_install\n  else\n    # As a last resort, use the slow shell script.  Don't cache a\n    # value for INSTALL within a source directory, because that will\n    # break other packages using the cache if that directory is\n    # removed, or if the value is a relative name.\n    INSTALL=$ac_install_sh\n  fi\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $INSTALL\" >&5\nprintf \"%s\\n\" \"$INSTALL\" >&6; }\n\n# Use test -z because SunOS4 sh mishandles braces in ${var-val}.\n# It thinks the first close brace ends the variable substitution.\ntest -z \"$INSTALL_PROGRAM\" && INSTALL_PROGRAM='${INSTALL}'\n\ntest -z \"$INSTALL_SCRIPT\" && INSTALL_SCRIPT='${INSTALL}'\n\ntest -z \"$INSTALL_DATA\" && INSTALL_DATA='${INSTALL} -m 644'\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether build environment is sane\" >&5\nprintf %s \"checking whether build environment is sane... \" >&6; }\n# Reject unsafe characters in $srcdir or the absolute working directory\n# name.  Accept space and tab only in the latter.\nam_lf='\n'\ncase `pwd` in\n  *[\\\\\\\"\\#\\$\\&\\'\\`$am_lf]*)\n    as_fn_error $? \"unsafe absolute working directory name\" \"$LINENO\" 5;;\nesac\ncase $srcdir in\n  *[\\\\\\\"\\#\\$\\&\\'\\`$am_lf\\ \\\t]*)\n    as_fn_error $? \"unsafe srcdir value: '$srcdir'\" \"$LINENO\" 5;;\nesac\n\n# Do 'set' in a subshell so we don't clobber the current shell's\n# arguments.  Must try -L first in case configure is actually a\n# symlink; some systems play weird games with the mod time of symlinks\n# (eg FreeBSD returns the mod time of the symlink's containing\n# directory).\nif (\n   am_has_slept=no\n   for am_try in 1 2; do\n     echo \"timestamp, slept: $am_has_slept\" > conftest.file\n     set X `ls -Lt \"$srcdir/configure\" conftest.file 2> /dev/null`\n     if test \"$*\" = \"X\"; then\n\t# -L didn't work.\n\tset X `ls -t \"$srcdir/configure\" conftest.file`\n     fi\n     if test \"$*\" != \"X $srcdir/configure conftest.file\" \\\n\t&& test \"$*\" != \"X conftest.file $srcdir/configure\"; then\n\n\t# If neither matched, then we have a broken ls.  This can happen\n\t# if, for instance, CONFIG_SHELL is bash and it inherits a\n\t# broken ls alias from the environment.  This has actually\n\t# happened.  Such a system could not be considered \"sane\".\n\tas_fn_error $? \"ls -t appears to fail.  Make sure there is not a broken\n  alias in your environment\" \"$LINENO\" 5\n     fi\n     if test \"$2\" = conftest.file || test $am_try -eq 2; then\n       break\n     fi\n     # Just in case.\n     sleep 1\n     am_has_slept=yes\n   done\n   test \"$2\" = conftest.file\n   )\nthen\n   # Ok.\n   :\nelse\n   as_fn_error $? \"newly created file is older than distributed files!\nCheck your system clock\" \"$LINENO\" 5\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n# If we didn't sleep, we still need to ensure time stamps of config.status and\n# generated files are strictly newer.\nam_sleep_pid=\nif grep 'slept: no' conftest.file >/dev/null 2>&1; then\n  ( sleep 1 ) &\n  am_sleep_pid=$!\nfi\n\nrm -f conftest.file\n\ntest \"$program_prefix\" != NONE &&\n  program_transform_name=\"s&^&$program_prefix&;$program_transform_name\"\n# Use a double $ so make ignores it.\ntest \"$program_suffix\" != NONE &&\n  program_transform_name=\"s&\\$&$program_suffix&;$program_transform_name\"\n# Double any \\ or $.\n# By default was 's,x,x', remove it if useless.\nac_script='s/[\\\\$]/&&/g;s/;s,x,x,$//'\nprogram_transform_name=`printf \"%s\\n\" \"$program_transform_name\" | sed \"$ac_script\"`\n\n\n# Expand $ac_aux_dir to an absolute path.\nam_aux_dir=`cd \"$ac_aux_dir\" && pwd`\n\n\n  if test x\"${MISSING+set}\" != xset; then\n  MISSING=\"\\${SHELL} '$am_aux_dir/missing'\"\nfi\n# Use eval to expand $SHELL\nif eval \"$MISSING --is-lightweight\"; then\n  am_missing_run=\"$MISSING \"\nelse\n  am_missing_run=\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: 'missing' script is too old or missing\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: 'missing' script is too old or missing\" >&2;}\nfi\n\nif test x\"${install_sh+set}\" != xset; then\n  case $am_aux_dir in\n  *\\ * | *\\\t*)\n    install_sh=\"\\${SHELL} '$am_aux_dir/install-sh'\" ;;\n  *)\n    install_sh=\"\\${SHELL} $am_aux_dir/install-sh\"\n  esac\nfi\n\n# Installed binaries are usually stripped using 'strip' when the user\n# run \"make install-strip\".  However 'strip' might not be the right\n# tool to use in cross-compilation environments, therefore Automake\n# will honor the 'STRIP' environment variable to overrule this program.\nif test \"$cross_compiling\" != no; then\n  if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}strip\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}strip; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_STRIP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$STRIP\"; then\n  ac_cv_prog_STRIP=\"$STRIP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_STRIP=\"${ac_tool_prefix}strip\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nSTRIP=$ac_cv_prog_STRIP\nif test -n \"$STRIP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $STRIP\" >&5\nprintf \"%s\\n\" \"$STRIP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_STRIP\"; then\n  ac_ct_STRIP=$STRIP\n  # Extract the first word of \"strip\", so it can be a program name with args.\nset dummy strip; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_STRIP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_STRIP\"; then\n  ac_cv_prog_ac_ct_STRIP=\"$ac_ct_STRIP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_STRIP=\"strip\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_STRIP=$ac_cv_prog_ac_ct_STRIP\nif test -n \"$ac_ct_STRIP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_STRIP\" >&5\nprintf \"%s\\n\" \"$ac_ct_STRIP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_STRIP\" = x; then\n    STRIP=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    STRIP=$ac_ct_STRIP\n  fi\nelse\n  STRIP=\"$ac_cv_prog_STRIP\"\nfi\n\nfi\nINSTALL_STRIP_PROGRAM=\"\\$(install_sh) -c -s\"\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for a race-free mkdir -p\" >&5\nprintf %s \"checking for a race-free mkdir -p... \" >&6; }\nif test -z \"$MKDIR_P\"; then\n  if test ${ac_cv_path_mkdir+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH$PATH_SEPARATOR/opt/sfw/bin\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in mkdir gmkdir; do\n\t for ac_exec_ext in '' $ac_executable_extensions; do\n\t   as_fn_executable_p \"$as_dir$ac_prog$ac_exec_ext\" || continue\n\t   case `\"$as_dir$ac_prog$ac_exec_ext\" --version 2>&1` in #(\n\t     'mkdir ('*'coreutils) '* | \\\n\t     *'BusyBox '* | \\\n\t     'mkdir (fileutils) '4.1*)\n\t       ac_cv_path_mkdir=$as_dir$ac_prog$ac_exec_ext\n\t       break 3;;\n\t   esac\n\t done\n       done\n  done\nIFS=$as_save_IFS\n ;;\nesac\nfi\n\n  test -d ./--version && rmdir ./--version\n  if test ${ac_cv_path_mkdir+y}; then\n    MKDIR_P=\"$ac_cv_path_mkdir -p\"\n  else\n    # As a last resort, use plain mkdir -p,\n    # in the hope it doesn't have the bugs of ancient mkdir.\n    MKDIR_P='mkdir -p'\n  fi\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $MKDIR_P\" >&5\nprintf \"%s\\n\" \"$MKDIR_P\" >&6; }\n\nfor ac_prog in gawk mawk nawk awk\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_AWK+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$AWK\"; then\n  ac_cv_prog_AWK=\"$AWK\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_AWK=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nAWK=$ac_cv_prog_AWK\nif test -n \"$AWK\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $AWK\" >&5\nprintf \"%s\\n\" \"$AWK\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$AWK\" && break\ndone\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether ${MAKE-make} sets \\$(MAKE)\" >&5\nprintf %s \"checking whether ${MAKE-make} sets \\$(MAKE)... \" >&6; }\nset x ${MAKE-make}\nac_make=`printf \"%s\\n\" \"$2\" | sed 's/+/p/g; s/[^a-zA-Z0-9_]/_/g'`\nif eval test \\${ac_cv_prog_make_${ac_make}_set+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat >conftest.make <<\\_ACEOF\nSHELL = /bin/sh\nall:\n\t@echo '@@@%%%=$(MAKE)=@@@%%%'\n_ACEOF\n# GNU make sometimes prints \"make[1]: Entering ...\", which would confuse us.\ncase `${MAKE-make} -f conftest.make 2>/dev/null` in\n  *@@@%%%=?*=@@@%%%*)\n    eval ac_cv_prog_make_${ac_make}_set=yes;;\n  *)\n    eval ac_cv_prog_make_${ac_make}_set=no;;\nesac\nrm -f conftest.make ;;\nesac\nfi\nif eval test \\$ac_cv_prog_make_${ac_make}_set = yes; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n  SET_MAKE=\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\n  SET_MAKE=\"MAKE=${MAKE-make}\"\nfi\n\nrm -rf .tst 2>/dev/null\nmkdir .tst 2>/dev/null\nif test -d .tst; then\n  am__leading_dot=.\nelse\n  am__leading_dot=_\nfi\nrmdir .tst 2>/dev/null\n\n# Check whether --enable-silent-rules was given.\nif test ${enable_silent_rules+y}\nthen :\n  enableval=$enable_silent_rules;\nfi\n\ncase $enable_silent_rules in # (((\n  yes) AM_DEFAULT_VERBOSITY=0;;\n   no) AM_DEFAULT_VERBOSITY=1;;\n    *) AM_DEFAULT_VERBOSITY=1;;\nesac\nam_make=${MAKE-make}\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $am_make supports nested variables\" >&5\nprintf %s \"checking whether $am_make supports nested variables... \" >&6; }\nif test ${am_cv_make_support_nested_variables+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if printf \"%s\\n\" 'TRUE=$(BAR$(V))\nBAR0=false\nBAR1=true\nV=1\nam__doit:\n\t@$(TRUE)\n.PHONY: am__doit' | $am_make -f - >/dev/null 2>&1; then\n  am_cv_make_support_nested_variables=yes\nelse\n  am_cv_make_support_nested_variables=no\nfi ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_make_support_nested_variables\" >&5\nprintf \"%s\\n\" \"$am_cv_make_support_nested_variables\" >&6; }\nif test $am_cv_make_support_nested_variables = yes; then\n    AM_V='$(V)'\n  AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'\nelse\n  AM_V=$AM_DEFAULT_VERBOSITY\n  AM_DEFAULT_V=$AM_DEFAULT_VERBOSITY\nfi\nAM_BACKSLASH='\\'\n\nif test \"`cd $srcdir && pwd`\" != \"`pwd`\"; then\n  # Use -I$(srcdir) only when $(srcdir) != ., so that make's output\n  # is not polluted with repeated \"-I.\"\n  am__isrc=' -I$(srcdir)'\n  # test to see if srcdir already configured\n  if test -f $srcdir/config.status; then\n    as_fn_error $? \"source directory already configured; run \\\"make distclean\\\" there first\" \"$LINENO\" 5\n  fi\nfi\n\n# test whether we have cygpath\nif test -z \"$CYGPATH_W\"; then\n  if (cygpath --version) >/dev/null 2>/dev/null; then\n    CYGPATH_W='cygpath -w'\n  else\n    CYGPATH_W=echo\n  fi\nfi\n\n\n# Define the identity of the package.\n PACKAGE='slurm'\n VERSION='25.05'\n\n\n# Some tools Automake needs.\n\nACLOCAL=${ACLOCAL-\"${am_missing_run}aclocal-${am__api_version}\"}\n\n\nAUTOCONF=${AUTOCONF-\"${am_missing_run}autoconf\"}\n\n\nAUTOMAKE=${AUTOMAKE-\"${am_missing_run}automake-${am__api_version}\"}\n\n\nAUTOHEADER=${AUTOHEADER-\"${am_missing_run}autoheader\"}\n\n\nMAKEINFO=${MAKEINFO-\"${am_missing_run}makeinfo\"}\n\n# For better backward compatibility.  To be removed once Automake 1.9.x\n# dies out for good.  For more background, see:\n# <https://lists.gnu.org/archive/html/automake/2012-07/msg00001.html>\n# <https://lists.gnu.org/archive/html/automake/2012-07/msg00014.html>\nmkdir_p='$(MKDIR_P)'\n\n# We need awk for the \"check\" target (and possibly the TAP driver).  The\n# system \"awk\" is bad on some platforms.\n# Always define AMTAR for backward compatibility.  Yes, it's still used\n# in the wild :-(  We should find a proper way to deprecate it ...\nAMTAR='$${TAR-tar}'\n\n\n# We'll loop over all known methods to create a tar archive until one works.\n_am_tools='gnutar  pax cpio none'\n\nam__tar='$${TAR-tar} chof - \"$$tardir\"' am__untar='$${TAR-tar} xf -'\n\n\n\n\n\n# Variables for tags utilities; see am/tags.am\nif test -z \"$CTAGS\"; then\n  CTAGS=ctags\nfi\n\nif test -z \"$ETAGS\"; then\n  ETAGS=etags\nfi\n\nif test -z \"$CSCOPE\"; then\n  CSCOPE=cscope\nfi\n\n\n\n# POSIX will say in a future version that running \"rm -f\" with no argument\n# is OK; and we want to be able to make that assumption in our Makefile\n# recipes.  So use an aggressive probe to check that the usage we want is\n# actually supported \"in the wild\" to an acceptable degree.\n# See automake bug#10828.\n# To make any issue more visible, cause the running configure to be aborted\n# by default if the 'rm' program in use doesn't match our expectations; the\n# user can still override this though.\nif rm -f && rm -fr && rm -rf; then : OK; else\n  cat >&2 <<'END'\nOops!\n\nYour 'rm' program seems unable to run without file operands specified\non the command line, even when the '-f' option is present.  This is contrary\nto the behaviour of most rm programs out there, and not conforming with\nthe upcoming POSIX standard: <http://austingroupbugs.net/view.php?id=542>\n\nPlease tell bug-automake@gnu.org about your system, including the value\nof your $PATH and any error possibly output before this message.  This\ncan help us improve future automake versions.\n\nEND\n  if test x\"$ACCEPT_INFERIOR_RM_PROGRAM\" = x\"yes\"; then\n    echo 'Configuration will proceed anyway, since you have set the' >&2\n    echo 'ACCEPT_INFERIOR_RM_PROGRAM variable to \"yes\"' >&2\n    echo >&2\n  else\n    cat >&2 <<'END'\nAborting the configuration process, to ensure you take notice of the issue.\n\nYou can download and install GNU coreutils to get an 'rm' implementation\nthat behaves properly: <https://www.gnu.org/software/coreutils/>.\n\nIf you want to complete the configuration process using your problematic\n'rm' anyway, export the environment variable ACCEPT_INFERIOR_RM_PROGRAM\nto \"yes\", and re-run configure.\n\nEND\n    as_fn_error $? \"Your 'rm' program is bad, sorry.\" \"$LINENO\" 5\n  fi\nfi\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether to enable maintainer-specific portions of Makefiles\" >&5\nprintf %s \"checking whether to enable maintainer-specific portions of Makefiles... \" >&6; }\n    # Check whether --enable-maintainer-mode was given.\nif test ${enable_maintainer_mode+y}\nthen :\n  enableval=$enable_maintainer_mode; USE_MAINTAINER_MODE=$enableval\nelse case e in #(\n  e) USE_MAINTAINER_MODE=no ;;\nesac\nfi\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $USE_MAINTAINER_MODE\" >&5\nprintf \"%s\\n\" \"$USE_MAINTAINER_MODE\" >&6; }\n   if test $USE_MAINTAINER_MODE = yes; then\n  MAINTAINER_MODE_TRUE=\n  MAINTAINER_MODE_FALSE='#'\nelse\n  MAINTAINER_MODE_TRUE='#'\n  MAINTAINER_MODE_FALSE=\nfi\n\n  MAINT=$MAINTAINER_MODE_TRUE\n\n\nac_config_headers=\"$ac_config_headers config.h\"\n\nac_config_headers=\"$ac_config_headers slurm/slurm_version.h\"\n\n\n\n  ac_with_rpath=yes\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether to include rpath in build\" >&5\nprintf %s \"checking whether to include rpath in build... \" >&6; }\n\n# Check whether --with-rpath was given.\nif test ${with_rpath+y}\nthen :\n  withval=$with_rpath;  case \"$withval\" in\n        yes) ac_with_rpath=yes ;;\n        no)  ac_with_rpath=no ;;\n        *)   { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: doh!\" >&5\nprintf \"%s\\n\" \"doh!\" >&6; }\n             as_fn_error $? \"bad value \\\"$withval\\\" for --without-rpath\" \"$LINENO\" 5 ;;\n        esac\n\n\nfi\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_with_rpath\" >&5\nprintf \"%s\\n\" \"$ac_with_rpath\" >&6; }\n\n\n\n\n\n\n\n\n\n\n\nDEPDIR=\"${am__leading_dot}deps\"\n\nac_config_commands=\"$ac_config_commands depfiles\"\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether ${MAKE-make} supports the include directive\" >&5\nprintf %s \"checking whether ${MAKE-make} supports the include directive... \" >&6; }\ncat > confinc.mk << 'END'\nam__doit:\n\t@echo this is the am__doit target >confinc.out\n.PHONY: am__doit\nEND\nam__include=\"#\"\nam__quote=\n# BSD make does it like this.\necho '.include \"confinc.mk\" # ignored' > confmf.BSD\n# Other make implementations (GNU, Solaris 10, AIX) do it like this.\necho 'include confinc.mk # ignored' > confmf.GNU\n_am_result=no\nfor s in GNU BSD; do\n  { echo \"$as_me:$LINENO: ${MAKE-make} -f confmf.$s && cat confinc.out\" >&5\n   (${MAKE-make} -f confmf.$s && cat confinc.out) >&5 2>&5\n   ac_status=$?\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   (exit $ac_status); }\n  case $?:`cat confinc.out 2>/dev/null` in #(\n  '0:this is the am__doit target') :\n    case $s in #(\n  BSD) :\n    am__include='.include' am__quote='\"' ;; #(\n  *) :\n    am__include='include' am__quote='' ;;\nesac ;; #(\n  *) :\n     ;;\nesac\n  if test \"$am__include\" != \"#\"; then\n    _am_result=\"yes ($s style)\"\n    break\n  fi\ndone\nrm -f confinc.* confmf.*\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: ${_am_result}\" >&5\nprintf \"%s\\n\" \"${_am_result}\" >&6; }\n\n# Check whether --enable-dependency-tracking was given.\nif test ${enable_dependency_tracking+y}\nthen :\n  enableval=$enable_dependency_tracking;\nfi\n\nif test \"x$enable_dependency_tracking\" != xno; then\n  am_depcomp=\"$ac_aux_dir/depcomp\"\n  AMDEPBACKSLASH='\\'\n  am__nodep='_no'\nfi\n if test \"x$enable_dependency_tracking\" != xno; then\n  AMDEP_TRUE=\n  AMDEP_FALSE='#'\nelse\n  AMDEP_TRUE='#'\n  AMDEP_FALSE=\nfi\n\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}gcc\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}gcc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}gcc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_CC\"; then\n  ac_ct_CC=$CC\n  # Extract the first word of \"gcc\", so it can be a program name with args.\nset dummy gcc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"gcc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nelse\n  CC=\"$ac_cv_prog_CC\"\nfi\n\nif test -z \"$CC\"; then\n          if test -n \"$ac_tool_prefix\"; then\n    # Extract the first word of \"${ac_tool_prefix}cc\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}cc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}cc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  fi\nfi\nif test -z \"$CC\"; then\n  # Extract the first word of \"cc\", so it can be a program name with args.\nset dummy cc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\n  ac_prog_rejected=no\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    if test \"$as_dir$ac_word$ac_exec_ext\" = \"/usr/ucb/cc\"; then\n       ac_prog_rejected=yes\n       continue\n     fi\n    ac_cv_prog_CC=\"cc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nif test $ac_prog_rejected = yes; then\n  # We found a bogon in the path, so make sure we never use it.\n  set dummy $ac_cv_prog_CC\n  shift\n  if test $# != 0; then\n    # We chose a different compiler from the bogus one.\n    # However, it has the same basename, so the bogon will be chosen\n    # first if we set CC to just the basename; use the full file name.\n    shift\n    ac_cv_prog_CC=\"$as_dir$ac_word${1+' '}$@\"\n  fi\nfi\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$CC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n  for ac_prog in cl.exe\n  do\n    # Extract the first word of \"$ac_tool_prefix$ac_prog\", so it can be a program name with args.\nset dummy $ac_tool_prefix$ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"$ac_tool_prefix$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n    test -n \"$CC\" && break\n  done\nfi\nif test -z \"$CC\"; then\n  ac_ct_CC=$CC\n  for ac_prog in cl.exe\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$ac_ct_CC\" && break\ndone\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nfi\n\nfi\nif test -z \"$CC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}clang\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}clang; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}clang\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_CC\"; then\n  ac_ct_CC=$CC\n  # Extract the first word of \"clang\", so it can be a program name with args.\nset dummy clang; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"clang\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nelse\n  CC=\"$ac_cv_prog_CC\"\nfi\n\nfi\n\n\ntest -z \"$CC\" && { { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"no acceptable C compiler found in \\$PATH\nSee 'config.log' for more details\" \"$LINENO\" 5; }\n\n# Provide some information about the compiler.\nprintf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for C compiler version\" >&5\nset X $ac_compile\nac_compiler=$2\nfor ac_option in --version -v -V -qversion -version; do\n  { { ac_try=\"$ac_compiler $ac_option >&5\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compiler $ac_option >&5\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    sed '10a\\\n... rest of stderr output deleted ...\n         10q' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n  fi\n  rm -f conftest.er1 conftest.err\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\ndone\n\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nac_clean_files_save=$ac_clean_files\nac_clean_files=\"$ac_clean_files a.out a.out.dSYM a.exe b.out\"\n# Try to create an executable without -o first, disregard a.out.\n# It will help us diagnose broken compilers, and finding out an intuition\n# of exeext.\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the C compiler works\" >&5\nprintf %s \"checking whether the C compiler works... \" >&6; }\nac_link_default=`printf \"%s\\n\" \"$ac_link\" | sed 's/ -o *conftest[^ ]*//'`\n\n# The possible output files:\nac_files=\"a.out conftest.exe conftest a.exe a_out.exe b.out conftest.*\"\n\nac_rmfiles=\nfor ac_file in $ac_files\ndo\n  case $ac_file in\n    *.$ac_ext | *.xcoff | *.tds | *.d | *.pdb | *.xSYM | *.bb | *.bbg | *.map | *.inf | *.dSYM | *.o | *.obj ) ;;\n    * ) ac_rmfiles=\"$ac_rmfiles $ac_file\";;\n  esac\ndone\nrm -f $ac_rmfiles\n\nif { { ac_try=\"$ac_link_default\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link_default\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\nthen :\n  # Autoconf-2.13 could set the ac_cv_exeext variable to 'no'.\n# So ignore a value of 'no', otherwise this would lead to 'EXEEXT = no'\n# in a Makefile.  We should not override ac_cv_exeext if it was cached,\n# so that the user can short-circuit this test for compilers unknown to\n# Autoconf.\nfor ac_file in $ac_files ''\ndo\n  test -f \"$ac_file\" || continue\n  case $ac_file in\n    *.$ac_ext | *.xcoff | *.tds | *.d | *.pdb | *.xSYM | *.bb | *.bbg | *.map | *.inf | *.dSYM | *.o | *.obj )\n\t;;\n    [ab].out )\n\t# We found the default executable, but exeext='' is most\n\t# certainly right.\n\tbreak;;\n    *.* )\n\tif test ${ac_cv_exeext+y} && test \"$ac_cv_exeext\" != no;\n\tthen :; else\n\t   ac_cv_exeext=`expr \"$ac_file\" : '[^.]*\\(\\..*\\)'`\n\tfi\n\t# We set ac_cv_exeext here because the later test for it is not\n\t# safe: cross compilers may not add the suffix if given an '-o'\n\t# argument, so we may need to know it at that point already.\n\t# Even if this section looks crufty: it has the advantage of\n\t# actually working.\n\tbreak;;\n    * )\n\tbreak;;\n  esac\ndone\ntest \"$ac_cv_exeext\" = no && ac_cv_exeext=\n\nelse case e in #(\n  e) ac_file='' ;;\nesac\nfi\nif test -z \"$ac_file\"\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nprintf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n{ { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error 77 \"C compiler cannot create executables\nSee 'config.log' for more details\" \"$LINENO\" 5; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; } ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for C compiler default output file name\" >&5\nprintf %s \"checking for C compiler default output file name... \" >&6; }\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_file\" >&5\nprintf \"%s\\n\" \"$ac_file\" >&6; }\nac_exeext=$ac_cv_exeext\n\nrm -f -r a.out a.out.dSYM a.exe conftest$ac_cv_exeext b.out\nac_clean_files=$ac_clean_files_save\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for suffix of executables\" >&5\nprintf %s \"checking for suffix of executables... \" >&6; }\nif { { ac_try=\"$ac_link\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\nthen :\n  # If both 'conftest.exe' and 'conftest' are 'present' (well, observable)\n# catch 'conftest.exe'.  For instance with Cygwin, 'ls conftest' will\n# work properly (i.e., refer to 'conftest.exe'), while it won't with\n# 'rm'.\nfor ac_file in conftest.exe conftest conftest.*; do\n  test -f \"$ac_file\" || continue\n  case $ac_file in\n    *.$ac_ext | *.xcoff | *.tds | *.d | *.pdb | *.xSYM | *.bb | *.bbg | *.map | *.inf | *.dSYM | *.o | *.obj ) ;;\n    *.* ) ac_cv_exeext=`expr \"$ac_file\" : '[^.]*\\(\\..*\\)'`\n\t  break;;\n    * ) break;;\n  esac\ndone\nelse case e in #(\n  e) { { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"cannot compute suffix of executables: cannot compile and link\nSee 'config.log' for more details\" \"$LINENO\" 5; } ;;\nesac\nfi\nrm -f conftest conftest$ac_cv_exeext\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_exeext\" >&5\nprintf \"%s\\n\" \"$ac_cv_exeext\" >&6; }\n\nrm -f conftest.$ac_ext\nEXEEXT=$ac_cv_exeext\nac_exeext=$EXEEXT\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n#include <stdio.h>\nint\nmain (void)\n{\nFILE *f = fopen (\"conftest.out\", \"w\");\n if (!f)\n  return 1;\n return ferror (f) || fclose (f) != 0;\n\n  ;\n  return 0;\n}\n_ACEOF\nac_clean_files=\"$ac_clean_files conftest.out\"\n# Check that the compiler produces executables we can run.  If not, either\n# the compiler is broken, or we cross compile.\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether we are cross compiling\" >&5\nprintf %s \"checking whether we are cross compiling... \" >&6; }\nif test \"$cross_compiling\" != yes; then\n  { { ac_try=\"$ac_link\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_link\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\n  if { ac_try='./conftest$ac_cv_exeext'\n  { { case \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_try\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; }; then\n    cross_compiling=no\n  else\n    if test \"$cross_compiling\" = maybe; then\n\tcross_compiling=yes\n    else\n\t{ { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error 77 \"cannot run C compiled programs.\nIf you meant to cross compile, use '--host'.\nSee 'config.log' for more details\" \"$LINENO\" 5; }\n    fi\n  fi\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $cross_compiling\" >&5\nprintf \"%s\\n\" \"$cross_compiling\" >&6; }\n\nrm -f conftest.$ac_ext conftest$ac_cv_exeext \\\n  conftest.o conftest.obj conftest.out\nac_clean_files=$ac_clean_files_save\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for suffix of object files\" >&5\nprintf %s \"checking for suffix of object files... \" >&6; }\nif test ${ac_cv_objext+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nrm -f conftest.o conftest.obj\nif { { ac_try=\"$ac_compile\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compile\") 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\nthen :\n  for ac_file in conftest.o conftest.obj conftest.*; do\n  test -f \"$ac_file\" || continue;\n  case $ac_file in\n    *.$ac_ext | *.xcoff | *.tds | *.d | *.pdb | *.xSYM | *.bb | *.bbg | *.map | *.inf | *.dSYM ) ;;\n    *) ac_cv_objext=`expr \"$ac_file\" : '.*\\.\\(.*\\)'`\n       break;;\n  esac\ndone\nelse case e in #(\n  e) printf \"%s\\n\" \"$as_me: failed program was:\" >&5\nsed 's/^/| /' conftest.$ac_ext >&5\n\n{ { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"cannot compute suffix of object files: cannot compile\nSee 'config.log' for more details\" \"$LINENO\" 5; } ;;\nesac\nfi\nrm -f conftest.$ac_cv_objext conftest.$ac_ext ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_objext\" >&5\nprintf \"%s\\n\" \"$ac_cv_objext\" >&6; }\nOBJEXT=$ac_cv_objext\nac_objext=$OBJEXT\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the compiler supports GNU C\" >&5\nprintf %s \"checking whether the compiler supports GNU C... \" >&6; }\nif test ${ac_cv_c_compiler_gnu+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n#ifndef __GNUC__\n       choke me\n#endif\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_compiler_gnu=yes\nelse case e in #(\n  e) ac_compiler_gnu=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\nac_cv_c_compiler_gnu=$ac_compiler_gnu\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_c_compiler_gnu\" >&5\nprintf \"%s\\n\" \"$ac_cv_c_compiler_gnu\" >&6; }\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\nif test $ac_compiler_gnu = yes; then\n  GCC=yes\nelse\n  GCC=\nfi\nac_test_CFLAGS=${CFLAGS+y}\nac_save_CFLAGS=$CFLAGS\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $CC accepts -g\" >&5\nprintf %s \"checking whether $CC accepts -g... \" >&6; }\nif test ${ac_cv_prog_cc_g+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_save_c_werror_flag=$ac_c_werror_flag\n   ac_c_werror_flag=yes\n   ac_cv_prog_cc_g=no\n   CFLAGS=\"-g\"\n   cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_g=yes\nelse case e in #(\n  e) CFLAGS=\"\"\n      cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) ac_c_werror_flag=$ac_save_c_werror_flag\n\t CFLAGS=\"-g\"\n\t cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_g=yes\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n   ac_c_werror_flag=$ac_save_c_werror_flag ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_g\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_g\" >&6; }\nif test $ac_test_CFLAGS; then\n  CFLAGS=$ac_save_CFLAGS\nelif test $ac_cv_prog_cc_g = yes; then\n  if test \"$GCC\" = yes; then\n    CFLAGS=\"-g -O2\"\n  else\n    CFLAGS=\"-g\"\n  fi\nelse\n  if test \"$GCC\" = yes; then\n    CFLAGS=\"-O2\"\n  else\n    CFLAGS=\n  fi\nfi\nac_prog_cc_stdc=no\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C11 features\" >&5\nprintf %s \"checking for $CC option to enable C11 features... \" >&6; }\nif test ${ac_cv_prog_cc_c11+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c11=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c11_program\n_ACEOF\nfor ac_arg in '' -std=gnu11\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c11=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c11\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c11\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c11\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c11\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c11\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c11\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c11\n  ac_prog_cc_stdc=c11 ;;\nesac\nfi\nfi\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C99 features\" >&5\nprintf %s \"checking for $CC option to enable C99 features... \" >&6; }\nif test ${ac_cv_prog_cc_c99+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c99=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c99_program\n_ACEOF\nfor ac_arg in '' -std=gnu99 -std=c99 -c99 -qlanglvl=extc1x -qlanglvl=extc99 -AC99 -D_STDC_C99=\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c99=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c99\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c99\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c99\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c99\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c99\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c99\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c99\n  ac_prog_cc_stdc=c99 ;;\nesac\nfi\nfi\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C89 features\" >&5\nprintf %s \"checking for $CC option to enable C89 features... \" >&6; }\nif test ${ac_cv_prog_cc_c89+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c89=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c89_program\n_ACEOF\nfor ac_arg in '' -qlanglvl=extc89 -qlanglvl=ansi -std -Ae \"-Aa -D_HPUX_SOURCE\" \"-Xc -D__EXTENSIONS__\"\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c89=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c89\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c89\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c89\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c89\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c89\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c89\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c89\n  ac_prog_cc_stdc=c89 ;;\nesac\nfi\nfi\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\n  ac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $CC understands -c and -o together\" >&5\nprintf %s \"checking whether $CC understands -c and -o together... \" >&6; }\nif test ${am_cv_prog_cc_c_o+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\n  # Make sure it works both with $CC and with simple cc.\n  # Following AC_PROG_CC_C_O, we do the test twice because some\n  # compilers refuse to overwrite an existing .o file with -o,\n  # though they will create one.\n  am_cv_prog_cc_c_o=yes\n  for am_i in 1 2; do\n    if { echo \"$as_me:$LINENO: $CC -c conftest.$ac_ext -o conftest2.$ac_objext\" >&5\n   ($CC -c conftest.$ac_ext -o conftest2.$ac_objext) >&5 2>&5\n   ac_status=$?\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   (exit $ac_status); } \\\n         && test -f conftest2.$ac_objext; then\n      : OK\n    else\n      am_cv_prog_cc_c_o=no\n      break\n    fi\n  done\n  rm -f core conftest*\n  unset am_i ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_prog_cc_c_o\" >&5\nprintf \"%s\\n\" \"$am_cv_prog_cc_c_o\" >&6; }\nif test \"$am_cv_prog_cc_c_o\" != yes; then\n   # Losing compiler, so override with the script.\n   # FIXME: It is wrong to rewrite CC.\n   # But if we don't then we get into trouble of one sort or another.\n   # A longer-term fix would be to have automake use am__CC in this case,\n   # and then we could set am__CC=\"\\$(top_srcdir)/compile \\$(CC)\"\n   CC=\"$am_aux_dir/compile $CC\"\nfi\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\ndepcc=\"$CC\"   am_compiler_list=\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking dependency style of $depcc\" >&5\nprintf %s \"checking dependency style of $depcc... \" >&6; }\nif test ${am_cv_CC_dependencies_compiler_type+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$AMDEP_TRUE\" && test -f \"$am_depcomp\"; then\n  # We make a subdir and do the tests there.  Otherwise we can end up\n  # making bogus files that we don't know about and never remove.  For\n  # instance it was reported that on HP-UX the gcc test will end up\n  # making a dummy file named 'D' -- because '-MD' means \"put the output\n  # in D\".\n  rm -rf conftest.dir\n  mkdir conftest.dir\n  # Copy depcomp to subdir because otherwise we won't find it if we're\n  # using a relative directory.\n  cp \"$am_depcomp\" conftest.dir\n  cd conftest.dir\n  # We will build objects and dependencies in a subdirectory because\n  # it helps to detect inapplicable dependency modes.  For instance\n  # both Tru64's cc and ICC support -MD to output dependencies as a\n  # side effect of compilation, but ICC will put the dependencies in\n  # the current directory while Tru64 will put them in the object\n  # directory.\n  mkdir sub\n\n  am_cv_CC_dependencies_compiler_type=none\n  if test \"$am_compiler_list\" = \"\"; then\n     am_compiler_list=`sed -n 's/^#*\\([a-zA-Z0-9]*\\))$/\\1/p' < ./depcomp`\n  fi\n  am__universal=false\n  case \" $depcc \" in #(\n     *\\ -arch\\ *\\ -arch\\ *) am__universal=true ;;\n     esac\n\n  for depmode in $am_compiler_list; do\n    # Setup a source with many dependencies, because some compilers\n    # like to wrap large dependency lists on column 80 (with \\), and\n    # we should not choose a depcomp mode which is confused by this.\n    #\n    # We need to recreate these files for each test, as the compiler may\n    # overwrite some of them when testing with obscure command lines.\n    # This happens at least with the AIX C compiler.\n    : > sub/conftest.c\n    for i in 1 2 3 4 5 6; do\n      echo '#include \"conftst'$i'.h\"' >> sub/conftest.c\n      # Using \": > sub/conftst$i.h\" creates only sub/conftst1.h with\n      # Solaris 10 /bin/sh.\n      echo '/* dummy */' > sub/conftst$i.h\n    done\n    echo \"${am__include} ${am__quote}sub/conftest.Po${am__quote}\" > confmf\n\n    # We check with '-c' and '-o' for the sake of the \"dashmstdout\"\n    # mode.  It turns out that the SunPro C++ compiler does not properly\n    # handle '-M -o', and we need to detect this.  Also, some Intel\n    # versions had trouble with output in subdirs.\n    am__obj=sub/conftest.${OBJEXT-o}\n    am__minus_obj=\"-o $am__obj\"\n    case $depmode in\n    gcc)\n      # This depmode causes a compiler race in universal mode.\n      test \"$am__universal\" = false || continue\n      ;;\n    nosideeffect)\n      # After this tag, mechanisms are not by side-effect, so they'll\n      # only be used when explicitly requested.\n      if test \"x$enable_dependency_tracking\" = xyes; then\n\tcontinue\n      else\n\tbreak\n      fi\n      ;;\n    msvc7 | msvc7msys | msvisualcpp | msvcmsys)\n      # This compiler won't grok '-c -o', but also, the minuso test has\n      # not run yet.  These depmodes are late enough in the game, and\n      # so weak that their functioning should not be impacted.\n      am__obj=conftest.${OBJEXT-o}\n      am__minus_obj=\n      ;;\n    none) break ;;\n    esac\n    if depmode=$depmode \\\n       source=sub/conftest.c object=$am__obj \\\n       depfile=sub/conftest.Po tmpdepfile=sub/conftest.TPo \\\n       $SHELL ./depcomp $depcc -c $am__minus_obj sub/conftest.c \\\n         >/dev/null 2>conftest.err &&\n       grep sub/conftst1.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep sub/conftst6.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep $am__obj sub/conftest.Po > /dev/null 2>&1 &&\n       ${MAKE-make} -s -f confmf > /dev/null 2>&1; then\n      # icc doesn't choke on unknown options, it will just issue warnings\n      # or remarks (even with -Werror).  So we grep stderr for any message\n      # that says an option was ignored or not supported.\n      # When given -MP, icc 7.0 and 7.1 complain thusly:\n      #   icc: Command line warning: ignoring option '-M'; no argument required\n      # The diagnosis changed in icc 8.0:\n      #   icc: Command line remark: option '-MP' not supported\n      if (grep 'ignoring option' conftest.err ||\n          grep 'not supported' conftest.err) >/dev/null 2>&1; then :; else\n        am_cv_CC_dependencies_compiler_type=$depmode\n        break\n      fi\n    fi\n  done\n\n  cd ..\n  rm -rf conftest.dir\nelse\n  am_cv_CC_dependencies_compiler_type=none\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_CC_dependencies_compiler_type\" >&5\nprintf \"%s\\n\" \"$am_cv_CC_dependencies_compiler_type\" >&6; }\nCCDEPMODE=depmode=$am_cv_CC_dependencies_compiler_type\n\n if\n  test \"x$enable_dependency_tracking\" != xno \\\n  && test \"$am_cv_CC_dependencies_compiler_type\" = gcc3; then\n  am__fastdepCC_TRUE=\n  am__fastdepCC_FALSE='#'\nelse\n  am__fastdepCC_TRUE='#'\n  am__fastdepCC_FALSE=\nfi\n\n\n\n\n\t#Check for MySQL\n\tac_have_mysql=\"no\"\n\t_x_ac_mysql_bin=\"\"\n\t### Check for mysql_config program\n\n# Check whether --with-mysql_config was given.\nif test ${with_mysql_config+y}\nthen :\n  withval=$with_mysql_config; if test \"x$with_mysql_config\" != xno && test \"x$with_mysql_config\" != xyes\nthen :\n  _x_ac_mysql_bin=\"$with_mysql_config\"\nfi\nfi\n\n\n\tif test -z \"$_x_ac_mysql_bin\"; then\n\t\tfor ac_prog in mysql_config mariadb_config\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_path_HAVEMYSQLCONFIG+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) case $HAVEMYSQLCONFIG in\n  [\\\\/]* | ?:[\\\\/]*)\n  ac_cv_path_HAVEMYSQLCONFIG=\"$HAVEMYSQLCONFIG\" # Let the user override the test with a path.\n  ;;\n  *)\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_path_HAVEMYSQLCONFIG=\"$as_dir$ac_word$ac_exec_ext\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\n  ;;\nesac ;;\nesac\nfi\nHAVEMYSQLCONFIG=$ac_cv_path_HAVEMYSQLCONFIG\nif test -n \"$HAVEMYSQLCONFIG\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $HAVEMYSQLCONFIG\" >&5\nprintf \"%s\\n\" \"$HAVEMYSQLCONFIG\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$HAVEMYSQLCONFIG\" && break\ndone\ntest -n \"$HAVEMYSQLCONFIG\" || HAVEMYSQLCONFIG=\"no\"\n\n\telse\n\t\tfor ac_prog in mysql_config mariadb_config\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_path_HAVEMYSQLCONFIG+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) case $HAVEMYSQLCONFIG in\n  [\\\\/]* | ?:[\\\\/]*)\n  ac_cv_path_HAVEMYSQLCONFIG=\"$HAVEMYSQLCONFIG\" # Let the user override the test with a path.\n  ;;\n  *)\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $_x_ac_mysql_bin\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_path_HAVEMYSQLCONFIG=\"$as_dir$ac_word$ac_exec_ext\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\n  ;;\nesac ;;\nesac\nfi\nHAVEMYSQLCONFIG=$ac_cv_path_HAVEMYSQLCONFIG\nif test -n \"$HAVEMYSQLCONFIG\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $HAVEMYSQLCONFIG\" >&5\nprintf \"%s\\n\" \"$HAVEMYSQLCONFIG\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$HAVEMYSQLCONFIG\" && break\ndone\ntest -n \"$HAVEMYSQLCONFIG\" || HAVEMYSQLCONFIG=\"no\"\n\n\tfi\n\n\tif test x$with_mysql_config = xno; then\n\t\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: support for mysql is disabled\" >&5\nprintf \"%s\\n\" \"$as_me: support for mysql is disabled\" >&6;}\n\telif test x$HAVEMYSQLCONFIG = xno; then\n\t\tif test -z \"$with_mysql_config\"; then\n\t\t\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: *** mysql_config not found. Evidently no MySQL development libs installed on system.\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: *** mysql_config not found. Evidently no MySQL development libs installed on system.\" >&2;}\n\t\telse\n\t\t\tas_fn_error $? \"*** mysql_config not found. Evidently no MySQL development libs installed on system.\" \"$LINENO\" 5\n\t\tfi\n\telse\n\t\t# check for mysql-5.0.0+\n\t\tmysql_config_major_version=`$HAVEMYSQLCONFIG --version | \\\n\t\t\tsed 's/\\([0-9]*\\).\\([0-9]*\\).\\([a-zA-Z0-9]*\\)/\\1/'`\n    \t\tmysql_config_minor_version=`$HAVEMYSQLCONFIG --version | \\\n\t\t\tsed 's/\\([0-9]*\\).\\([0-9]*\\).\\([a-zA-Z0-9]*\\)/\\2/'`\n    \t\tmysql_config_micro_version=`$HAVEMYSQLCONFIG --version | \\\n\t\t\tsed 's/\\([0-9]*\\).\\([0-9]*\\).\\([a-zA-Z0-9]*\\)/\\3/'`\n\n\t\tif test $mysql_config_major_version -lt 5; then\n\t\t\tif test -z \"$with_mysql_config\"; then\n\t\t\t\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: *** mysql-$mysql_config_major_version.$mysql_config_minor_version.$mysql_config_micro_version available, we need >= mysql-5.0.0 installed for the mysql interface.\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: *** mysql-$mysql_config_major_version.$mysql_config_minor_version.$mysql_config_micro_version available, we need >= mysql-5.0.0 installed for the mysql interface.\" >&2;}\n\t\t\telse\n\t\t\t\tas_fn_error $? \"*** mysql-$mysql_config_major_version.$mysql_config_minor_version.$mysql_config_micro_version available, we need >= mysql-5.0.0 installed for the mysql interface.\" \"$LINENO\" 5\n\t\t\tfi\n\t\t\tac_have_mysql=\"no\"\n\t\telse\n\t\t# mysql_config puts -I on the front of the dir.  We don't\n\t\t# want that so we remove it.\n\t\t\tMYSQL_CFLAGS=`$HAVEMYSQLCONFIG --include`\n\t\t\tMYSQL_LIBS=`$HAVEMYSQLCONFIG --libs_r`\n\t\t\tsave_CFLAGS=\"$CFLAGS\"\n\t\t\tsave_LIBS=\"$LIBS\"\n       \t\t\tCFLAGS=\"$MYSQL_CFLAGS $save_CFLAGS\"\n\t\t\tLIBS=\"$MYSQL_LIBS $save_LIBS\"\n\t\t\tcat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n\t\t\t\t\t   #include <mysql.h>\n\nint\nmain (void)\n{\n\n\t\t\t\t\t   MYSQL mysql;\n\t\t\t\t\t   (void) mysql_init(&mysql);\n\t\t\t\t\t   (void) mysql_close(&mysql);\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_have_mysql=\"yes\"\nelse case e in #(\n  e) ac_have_mysql=\"no\" ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n\t\t\tCFLAGS=\"$save_CFLAGS\"\n\t\t\tLIBS=\"$save_LIBS\"\n\t\t\tif test \"$ac_have_mysql\" = yes; then\n\t\t\t\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: MySQL $mysql_config_major_version.$mysql_config_minor_version.$mysql_config_micro_version test program built properly.\" >&5\nprintf \"%s\\n\" \"MySQL $mysql_config_major_version.$mysql_config_minor_version.$mysql_config_micro_version test program built properly.\" >&6; }\n\n\n\nprintf \"%s\\n\" \"#define HAVE_MYSQL 1\" >>confdefs.h\n\n\t\t\telse\n\t\t\t\tMYSQL_CFLAGS=\"\"\n\t\t\t\tMYSQL_LIBS=\"\"\n\t\t\t\tif test -z \"$with_mysql_config\"; then\n\t\t\t\t\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: *** MySQL test program execution failed. A thread-safe MySQL library is required.\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: *** MySQL test program execution failed. A thread-safe MySQL library is required.\" >&2;}\n\t\t\t\telse\n\t\t\t\t\tas_fn_error $? \"*** MySQL test program execution failed. A thread-safe MySQL library is required.\" \"$LINENO\" 5\n\t\t\t\tfi\n\t\t\tfi\n\t\tfi\n      \tfi\n\t if test x\"$ac_have_mysql\" = x\"yes\"; then\n  WITH_MYSQL_TRUE=\n  WITH_MYSQL_FALSE='#'\nelse\n  WITH_MYSQL_TRUE='#'\n  WITH_MYSQL_FALSE=\nfi\n\n\n\ncase \"$host\" in\n\t*darwin*)\nprintf \"%s\\n\" \"#define USE_ALIAS 0\" >>confdefs.h\n ;;\n\t*)\nprintf \"%s\\n\" \"#define USE_ALIAS 1\" >>confdefs.h\n ;;\nesac\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}gcc\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}gcc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}gcc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_CC\"; then\n  ac_ct_CC=$CC\n  # Extract the first word of \"gcc\", so it can be a program name with args.\nset dummy gcc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"gcc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nelse\n  CC=\"$ac_cv_prog_CC\"\nfi\n\nif test -z \"$CC\"; then\n          if test -n \"$ac_tool_prefix\"; then\n    # Extract the first word of \"${ac_tool_prefix}cc\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}cc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}cc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  fi\nfi\nif test -z \"$CC\"; then\n  # Extract the first word of \"cc\", so it can be a program name with args.\nset dummy cc; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\n  ac_prog_rejected=no\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    if test \"$as_dir$ac_word$ac_exec_ext\" = \"/usr/ucb/cc\"; then\n       ac_prog_rejected=yes\n       continue\n     fi\n    ac_cv_prog_CC=\"cc\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nif test $ac_prog_rejected = yes; then\n  # We found a bogon in the path, so make sure we never use it.\n  set dummy $ac_cv_prog_CC\n  shift\n  if test $# != 0; then\n    # We chose a different compiler from the bogus one.\n    # However, it has the same basename, so the bogon will be chosen\n    # first if we set CC to just the basename; use the full file name.\n    shift\n    ac_cv_prog_CC=\"$as_dir$ac_word${1+' '}$@\"\n  fi\nfi\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$CC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n  for ac_prog in cl.exe\n  do\n    # Extract the first word of \"$ac_tool_prefix$ac_prog\", so it can be a program name with args.\nset dummy $ac_tool_prefix$ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"$ac_tool_prefix$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n    test -n \"$CC\" && break\n  done\nfi\nif test -z \"$CC\"; then\n  ac_ct_CC=$CC\n  for ac_prog in cl.exe\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$ac_ct_CC\" && break\ndone\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nfi\n\nfi\nif test -z \"$CC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}clang\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}clang; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CC\"; then\n  ac_cv_prog_CC=\"$CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CC=\"${ac_tool_prefix}clang\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCC=$ac_cv_prog_CC\nif test -n \"$CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CC\" >&5\nprintf \"%s\\n\" \"$CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_CC\"; then\n  ac_ct_CC=$CC\n  # Extract the first word of \"clang\", so it can be a program name with args.\nset dummy clang; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CC+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CC\"; then\n  ac_cv_prog_ac_ct_CC=\"$ac_ct_CC\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CC=\"clang\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CC=$ac_cv_prog_ac_ct_CC\nif test -n \"$ac_ct_CC\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CC\" >&5\nprintf \"%s\\n\" \"$ac_ct_CC\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_CC\" = x; then\n    CC=\"\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CC=$ac_ct_CC\n  fi\nelse\n  CC=\"$ac_cv_prog_CC\"\nfi\n\nfi\n\n\ntest -z \"$CC\" && { { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"no acceptable C compiler found in \\$PATH\nSee 'config.log' for more details\" \"$LINENO\" 5; }\n\n# Provide some information about the compiler.\nprintf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for C compiler version\" >&5\nset X $ac_compile\nac_compiler=$2\nfor ac_option in --version -v -V -qversion -version; do\n  { { ac_try=\"$ac_compiler $ac_option >&5\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compiler $ac_option >&5\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    sed '10a\\\n... rest of stderr output deleted ...\n         10q' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n  fi\n  rm -f conftest.er1 conftest.err\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\ndone\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the compiler supports GNU C\" >&5\nprintf %s \"checking whether the compiler supports GNU C... \" >&6; }\nif test ${ac_cv_c_compiler_gnu+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n#ifndef __GNUC__\n       choke me\n#endif\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_compiler_gnu=yes\nelse case e in #(\n  e) ac_compiler_gnu=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\nac_cv_c_compiler_gnu=$ac_compiler_gnu\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_c_compiler_gnu\" >&5\nprintf \"%s\\n\" \"$ac_cv_c_compiler_gnu\" >&6; }\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\nif test $ac_compiler_gnu = yes; then\n  GCC=yes\nelse\n  GCC=\nfi\nac_test_CFLAGS=${CFLAGS+y}\nac_save_CFLAGS=$CFLAGS\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $CC accepts -g\" >&5\nprintf %s \"checking whether $CC accepts -g... \" >&6; }\nif test ${ac_cv_prog_cc_g+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_save_c_werror_flag=$ac_c_werror_flag\n   ac_c_werror_flag=yes\n   ac_cv_prog_cc_g=no\n   CFLAGS=\"-g\"\n   cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_g=yes\nelse case e in #(\n  e) CFLAGS=\"\"\n      cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) ac_c_werror_flag=$ac_save_c_werror_flag\n\t CFLAGS=\"-g\"\n\t cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_g=yes\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n   ac_c_werror_flag=$ac_save_c_werror_flag ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_g\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_g\" >&6; }\nif test $ac_test_CFLAGS; then\n  CFLAGS=$ac_save_CFLAGS\nelif test $ac_cv_prog_cc_g = yes; then\n  if test \"$GCC\" = yes; then\n    CFLAGS=\"-g -O2\"\n  else\n    CFLAGS=\"-g\"\n  fi\nelse\n  if test \"$GCC\" = yes; then\n    CFLAGS=\"-O2\"\n  else\n    CFLAGS=\n  fi\nfi\nac_prog_cc_stdc=no\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C11 features\" >&5\nprintf %s \"checking for $CC option to enable C11 features... \" >&6; }\nif test ${ac_cv_prog_cc_c11+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c11=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c11_program\n_ACEOF\nfor ac_arg in '' -std=gnu11\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c11=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c11\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c11\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c11\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c11\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c11\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c11\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c11\n  ac_prog_cc_stdc=c11 ;;\nesac\nfi\nfi\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C99 features\" >&5\nprintf %s \"checking for $CC option to enable C99 features... \" >&6; }\nif test ${ac_cv_prog_cc_c99+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c99=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c99_program\n_ACEOF\nfor ac_arg in '' -std=gnu99 -std=c99 -c99 -qlanglvl=extc1x -qlanglvl=extc99 -AC99 -D_STDC_C99=\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c99=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c99\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c99\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c99\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c99\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c99\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c99\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c99\n  ac_prog_cc_stdc=c99 ;;\nesac\nfi\nfi\nif test x$ac_prog_cc_stdc = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CC option to enable C89 features\" >&5\nprintf %s \"checking for $CC option to enable C89 features... \" >&6; }\nif test ${ac_cv_prog_cc_c89+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cc_c89=no\nac_save_CC=$CC\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_c_conftest_c89_program\n_ACEOF\nfor ac_arg in '' -qlanglvl=extc89 -qlanglvl=ansi -std -Ae \"-Aa -D_HPUX_SOURCE\" \"-Xc -D__EXTENSIONS__\"\ndo\n  CC=\"$ac_save_CC $ac_arg\"\n  if ac_fn_c_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cc_c89=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cc_c89\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCC=$ac_save_CC ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cc_c89\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cc_c89\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cc_c89\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cc_c89\" >&6; }\n     CC=\"$CC $ac_cv_prog_cc_c89\" ;;\nesac\nfi\n  ac_cv_prog_cc_stdc=$ac_cv_prog_cc_c89\n  ac_prog_cc_stdc=c89 ;;\nesac\nfi\nfi\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\n  ac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $CC understands -c and -o together\" >&5\nprintf %s \"checking whether $CC understands -c and -o together... \" >&6; }\nif test ${am_cv_prog_cc_c_o+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\n  # Make sure it works both with $CC and with simple cc.\n  # Following AC_PROG_CC_C_O, we do the test twice because some\n  # compilers refuse to overwrite an existing .o file with -o,\n  # though they will create one.\n  am_cv_prog_cc_c_o=yes\n  for am_i in 1 2; do\n    if { echo \"$as_me:$LINENO: $CC -c conftest.$ac_ext -o conftest2.$ac_objext\" >&5\n   ($CC -c conftest.$ac_ext -o conftest2.$ac_objext) >&5 2>&5\n   ac_status=$?\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   (exit $ac_status); } \\\n         && test -f conftest2.$ac_objext; then\n      : OK\n    else\n      am_cv_prog_cc_c_o=no\n      break\n    fi\n  done\n  rm -f core conftest*\n  unset am_i ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_prog_cc_c_o\" >&5\nprintf \"%s\\n\" \"$am_cv_prog_cc_c_o\" >&6; }\nif test \"$am_cv_prog_cc_c_o\" != yes; then\n   # Losing compiler, so override with the script.\n   # FIXME: It is wrong to rewrite CC.\n   # But if we don't then we get into trouble of one sort or another.\n   # A longer-term fix would be to have automake use am__CC in this case,\n   # and then we could set am__CC=\"\\$(top_srcdir)/compile \\$(CC)\"\n   CC=\"$am_aux_dir/compile $CC\"\nfi\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\ndepcc=\"$CC\"   am_compiler_list=\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking dependency style of $depcc\" >&5\nprintf %s \"checking dependency style of $depcc... \" >&6; }\nif test ${am_cv_CC_dependencies_compiler_type+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$AMDEP_TRUE\" && test -f \"$am_depcomp\"; then\n  # We make a subdir and do the tests there.  Otherwise we can end up\n  # making bogus files that we don't know about and never remove.  For\n  # instance it was reported that on HP-UX the gcc test will end up\n  # making a dummy file named 'D' -- because '-MD' means \"put the output\n  # in D\".\n  rm -rf conftest.dir\n  mkdir conftest.dir\n  # Copy depcomp to subdir because otherwise we won't find it if we're\n  # using a relative directory.\n  cp \"$am_depcomp\" conftest.dir\n  cd conftest.dir\n  # We will build objects and dependencies in a subdirectory because\n  # it helps to detect inapplicable dependency modes.  For instance\n  # both Tru64's cc and ICC support -MD to output dependencies as a\n  # side effect of compilation, but ICC will put the dependencies in\n  # the current directory while Tru64 will put them in the object\n  # directory.\n  mkdir sub\n\n  am_cv_CC_dependencies_compiler_type=none\n  if test \"$am_compiler_list\" = \"\"; then\n     am_compiler_list=`sed -n 's/^#*\\([a-zA-Z0-9]*\\))$/\\1/p' < ./depcomp`\n  fi\n  am__universal=false\n  case \" $depcc \" in #(\n     *\\ -arch\\ *\\ -arch\\ *) am__universal=true ;;\n     esac\n\n  for depmode in $am_compiler_list; do\n    # Setup a source with many dependencies, because some compilers\n    # like to wrap large dependency lists on column 80 (with \\), and\n    # we should not choose a depcomp mode which is confused by this.\n    #\n    # We need to recreate these files for each test, as the compiler may\n    # overwrite some of them when testing with obscure command lines.\n    # This happens at least with the AIX C compiler.\n    : > sub/conftest.c\n    for i in 1 2 3 4 5 6; do\n      echo '#include \"conftst'$i'.h\"' >> sub/conftest.c\n      # Using \": > sub/conftst$i.h\" creates only sub/conftst1.h with\n      # Solaris 10 /bin/sh.\n      echo '/* dummy */' > sub/conftst$i.h\n    done\n    echo \"${am__include} ${am__quote}sub/conftest.Po${am__quote}\" > confmf\n\n    # We check with '-c' and '-o' for the sake of the \"dashmstdout\"\n    # mode.  It turns out that the SunPro C++ compiler does not properly\n    # handle '-M -o', and we need to detect this.  Also, some Intel\n    # versions had trouble with output in subdirs.\n    am__obj=sub/conftest.${OBJEXT-o}\n    am__minus_obj=\"-o $am__obj\"\n    case $depmode in\n    gcc)\n      # This depmode causes a compiler race in universal mode.\n      test \"$am__universal\" = false || continue\n      ;;\n    nosideeffect)\n      # After this tag, mechanisms are not by side-effect, so they'll\n      # only be used when explicitly requested.\n      if test \"x$enable_dependency_tracking\" = xyes; then\n\tcontinue\n      else\n\tbreak\n      fi\n      ;;\n    msvc7 | msvc7msys | msvisualcpp | msvcmsys)\n      # This compiler won't grok '-c -o', but also, the minuso test has\n      # not run yet.  These depmodes are late enough in the game, and\n      # so weak that their functioning should not be impacted.\n      am__obj=conftest.${OBJEXT-o}\n      am__minus_obj=\n      ;;\n    none) break ;;\n    esac\n    if depmode=$depmode \\\n       source=sub/conftest.c object=$am__obj \\\n       depfile=sub/conftest.Po tmpdepfile=sub/conftest.TPo \\\n       $SHELL ./depcomp $depcc -c $am__minus_obj sub/conftest.c \\\n         >/dev/null 2>conftest.err &&\n       grep sub/conftst1.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep sub/conftst6.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep $am__obj sub/conftest.Po > /dev/null 2>&1 &&\n       ${MAKE-make} -s -f confmf > /dev/null 2>&1; then\n      # icc doesn't choke on unknown options, it will just issue warnings\n      # or remarks (even with -Werror).  So we grep stderr for any message\n      # that says an option was ignored or not supported.\n      # When given -MP, icc 7.0 and 7.1 complain thusly:\n      #   icc: Command line warning: ignoring option '-M'; no argument required\n      # The diagnosis changed in icc 8.0:\n      #   icc: Command line remark: option '-MP' not supported\n      if (grep 'ignoring option' conftest.err ||\n          grep 'not supported' conftest.err) >/dev/null 2>&1; then :; else\n        am_cv_CC_dependencies_compiler_type=$depmode\n        break\n      fi\n    fi\n  done\n\n  cd ..\n  rm -rf conftest.dir\nelse\n  am_cv_CC_dependencies_compiler_type=none\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_CC_dependencies_compiler_type\" >&5\nprintf \"%s\\n\" \"$am_cv_CC_dependencies_compiler_type\" >&6; }\nCCDEPMODE=depmode=$am_cv_CC_dependencies_compiler_type\n\n if\n  test \"x$enable_dependency_tracking\" != xno \\\n  && test \"$am_cv_CC_dependencies_compiler_type\" = gcc3; then\n  am__fastdepCC_TRUE=\n  am__fastdepCC_FALSE='#'\nelse\n  am__fastdepCC_TRUE='#'\n  am__fastdepCC_FALSE=\nfi\n\n\n\n\n\n\n\n\nac_ext=cpp\nac_cpp='$CXXCPP $CPPFLAGS'\nac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_cxx_compiler_gnu\nif test -z \"$CXX\"; then\n  if test -n \"$CCC\"; then\n    CXX=$CCC\n  else\n    if test -n \"$ac_tool_prefix\"; then\n  for ac_prog in g++ c++ gpp aCC CC cxx cc++ cl.exe FCC KCC RCC xlC_r xlC clang++\n  do\n    # Extract the first word of \"$ac_tool_prefix$ac_prog\", so it can be a program name with args.\nset dummy $ac_tool_prefix$ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_CXX+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$CXX\"; then\n  ac_cv_prog_CXX=\"$CXX\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_CXX=\"$ac_tool_prefix$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nCXX=$ac_cv_prog_CXX\nif test -n \"$CXX\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CXX\" >&5\nprintf \"%s\\n\" \"$CXX\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n    test -n \"$CXX\" && break\n  done\nfi\nif test -z \"$CXX\"; then\n  ac_ct_CXX=$CXX\n  for ac_prog in g++ c++ gpp aCC CC cxx cc++ cl.exe FCC KCC RCC xlC_r xlC clang++\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_CXX+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_CXX\"; then\n  ac_cv_prog_ac_ct_CXX=\"$ac_ct_CXX\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_CXX=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_CXX=$ac_cv_prog_ac_ct_CXX\nif test -n \"$ac_ct_CXX\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_CXX\" >&5\nprintf \"%s\\n\" \"$ac_ct_CXX\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$ac_ct_CXX\" && break\ndone\n\n  if test \"x$ac_ct_CXX\" = x; then\n    CXX=\"g++\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    CXX=$ac_ct_CXX\n  fi\nfi\n\n  fi\nfi\n# Provide some information about the compiler.\nprintf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for C++ compiler version\" >&5\nset X $ac_compile\nac_compiler=$2\nfor ac_option in --version -v -V -qversion; do\n  { { ac_try=\"$ac_compiler $ac_option >&5\"\ncase \"(($ac_try\" in\n  *\\\"* | *\\`* | *\\\\*) ac_try_echo=\\$ac_try;;\n  *) ac_try_echo=$ac_try;;\nesac\neval ac_try_echo=\"\\\"\\$as_me:${as_lineno-$LINENO}: $ac_try_echo\\\"\"\nprintf \"%s\\n\" \"$ac_try_echo\"; } >&5\n  (eval \"$ac_compiler $ac_option >&5\") 2>conftest.err\n  ac_status=$?\n  if test -s conftest.err; then\n    sed '10a\\\n... rest of stderr output deleted ...\n         10q' conftest.err >conftest.er1\n    cat conftest.er1 >&5\n  fi\n  rm -f conftest.er1 conftest.err\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\ndone\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the compiler supports GNU C++\" >&5\nprintf %s \"checking whether the compiler supports GNU C++... \" >&6; }\nif test ${ac_cv_cxx_compiler_gnu+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n#ifndef __GNUC__\n       choke me\n#endif\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n  ac_compiler_gnu=yes\nelse case e in #(\n  e) ac_compiler_gnu=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\nac_cv_cxx_compiler_gnu=$ac_compiler_gnu\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_cxx_compiler_gnu\" >&5\nprintf \"%s\\n\" \"$ac_cv_cxx_compiler_gnu\" >&6; }\nac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n\nif test $ac_compiler_gnu = yes; then\n  GXX=yes\nelse\n  GXX=\nfi\nac_test_CXXFLAGS=${CXXFLAGS+y}\nac_save_CXXFLAGS=$CXXFLAGS\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether $CXX accepts -g\" >&5\nprintf %s \"checking whether $CXX accepts -g... \" >&6; }\nif test ${ac_cv_prog_cxx_g+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_save_cxx_werror_flag=$ac_cxx_werror_flag\n   ac_cxx_werror_flag=yes\n   ac_cv_prog_cxx_g=no\n   CXXFLAGS=\"-g\"\n   cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cxx_g=yes\nelse case e in #(\n  e) CXXFLAGS=\"\"\n      cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) ac_cxx_werror_flag=$ac_save_cxx_werror_flag\n\t CXXFLAGS=\"-g\"\n\t cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cxx_g=yes\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n   ac_cxx_werror_flag=$ac_save_cxx_werror_flag ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cxx_g\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cxx_g\" >&6; }\nif test $ac_test_CXXFLAGS; then\n  CXXFLAGS=$ac_save_CXXFLAGS\nelif test $ac_cv_prog_cxx_g = yes; then\n  if test \"$GXX\" = yes; then\n    CXXFLAGS=\"-g -O2\"\n  else\n    CXXFLAGS=\"-g\"\n  fi\nelse\n  if test \"$GXX\" = yes; then\n    CXXFLAGS=\"-O2\"\n  else\n    CXXFLAGS=\n  fi\nfi\nac_prog_cxx_stdcxx=no\nif test x$ac_prog_cxx_stdcxx = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CXX option to enable C++11 features\" >&5\nprintf %s \"checking for $CXX option to enable C++11 features... \" >&6; }\nif test ${ac_cv_prog_cxx_cxx11+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cxx_cxx11=no\nac_save_CXX=$CXX\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_cxx_conftest_cxx11_program\n_ACEOF\nfor ac_arg in '' -std=gnu++11 -std=gnu++0x -std=c++11 -std=c++0x -qlanglvl=extended0x -AA\ndo\n  CXX=\"$ac_save_CXX $ac_arg\"\n  if ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cxx_cxx11=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cxx_cxx11\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCXX=$ac_save_CXX ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cxx_cxx11\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cxx_cxx11\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cxx_cxx11\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cxx_cxx11\" >&6; }\n     CXX=\"$CXX $ac_cv_prog_cxx_cxx11\" ;;\nesac\nfi\n  ac_cv_prog_cxx_stdcxx=$ac_cv_prog_cxx_cxx11\n  ac_prog_cxx_stdcxx=cxx11 ;;\nesac\nfi\nfi\nif test x$ac_prog_cxx_stdcxx = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $CXX option to enable C++98 features\" >&5\nprintf %s \"checking for $CXX option to enable C++98 features... \" >&6; }\nif test ${ac_cv_prog_cxx_cxx98+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_cv_prog_cxx_cxx98=no\nac_save_CXX=$CXX\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n$ac_cxx_conftest_cxx98_program\n_ACEOF\nfor ac_arg in '' -std=gnu++98 -std=c++98 -qlanglvl=extended -AA\ndo\n  CXX=\"$ac_save_CXX $ac_arg\"\n  if ac_fn_cxx_try_compile \"$LINENO\"\nthen :\n  ac_cv_prog_cxx_cxx98=$ac_arg\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam\n  test \"x$ac_cv_prog_cxx_cxx98\" != \"xno\" && break\ndone\nrm -f conftest.$ac_ext\nCXX=$ac_save_CXX ;;\nesac\nfi\n\nif test \"x$ac_cv_prog_cxx_cxx98\" = xno\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: unsupported\" >&5\nprintf \"%s\\n\" \"unsupported\" >&6; }\nelse case e in #(\n  e) if test \"x$ac_cv_prog_cxx_cxx98\" = x\nthen :\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none needed\" >&5\nprintf \"%s\\n\" \"none needed\" >&6; }\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_prog_cxx_cxx98\" >&5\nprintf \"%s\\n\" \"$ac_cv_prog_cxx_cxx98\" >&6; }\n     CXX=\"$CXX $ac_cv_prog_cxx_cxx98\" ;;\nesac\nfi\n  ac_cv_prog_cxx_stdcxx=$ac_cv_prog_cxx_cxx98\n  ac_prog_cxx_stdcxx=cxx98 ;;\nesac\nfi\nfi\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\ndepcc=\"$CXX\"  am_compiler_list=\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking dependency style of $depcc\" >&5\nprintf %s \"checking dependency style of $depcc... \" >&6; }\nif test ${am_cv_CXX_dependencies_compiler_type+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$AMDEP_TRUE\" && test -f \"$am_depcomp\"; then\n  # We make a subdir and do the tests there.  Otherwise we can end up\n  # making bogus files that we don't know about and never remove.  For\n  # instance it was reported that on HP-UX the gcc test will end up\n  # making a dummy file named 'D' -- because '-MD' means \"put the output\n  # in D\".\n  rm -rf conftest.dir\n  mkdir conftest.dir\n  # Copy depcomp to subdir because otherwise we won't find it if we're\n  # using a relative directory.\n  cp \"$am_depcomp\" conftest.dir\n  cd conftest.dir\n  # We will build objects and dependencies in a subdirectory because\n  # it helps to detect inapplicable dependency modes.  For instance\n  # both Tru64's cc and ICC support -MD to output dependencies as a\n  # side effect of compilation, but ICC will put the dependencies in\n  # the current directory while Tru64 will put them in the object\n  # directory.\n  mkdir sub\n\n  am_cv_CXX_dependencies_compiler_type=none\n  if test \"$am_compiler_list\" = \"\"; then\n     am_compiler_list=`sed -n 's/^#*\\([a-zA-Z0-9]*\\))$/\\1/p' < ./depcomp`\n  fi\n  am__universal=false\n  case \" $depcc \" in #(\n     *\\ -arch\\ *\\ -arch\\ *) am__universal=true ;;\n     esac\n\n  for depmode in $am_compiler_list; do\n    # Setup a source with many dependencies, because some compilers\n    # like to wrap large dependency lists on column 80 (with \\), and\n    # we should not choose a depcomp mode which is confused by this.\n    #\n    # We need to recreate these files for each test, as the compiler may\n    # overwrite some of them when testing with obscure command lines.\n    # This happens at least with the AIX C compiler.\n    : > sub/conftest.c\n    for i in 1 2 3 4 5 6; do\n      echo '#include \"conftst'$i'.h\"' >> sub/conftest.c\n      # Using \": > sub/conftst$i.h\" creates only sub/conftst1.h with\n      # Solaris 10 /bin/sh.\n      echo '/* dummy */' > sub/conftst$i.h\n    done\n    echo \"${am__include} ${am__quote}sub/conftest.Po${am__quote}\" > confmf\n\n    # We check with '-c' and '-o' for the sake of the \"dashmstdout\"\n    # mode.  It turns out that the SunPro C++ compiler does not properly\n    # handle '-M -o', and we need to detect this.  Also, some Intel\n    # versions had trouble with output in subdirs.\n    am__obj=sub/conftest.${OBJEXT-o}\n    am__minus_obj=\"-o $am__obj\"\n    case $depmode in\n    gcc)\n      # This depmode causes a compiler race in universal mode.\n      test \"$am__universal\" = false || continue\n      ;;\n    nosideeffect)\n      # After this tag, mechanisms are not by side-effect, so they'll\n      # only be used when explicitly requested.\n      if test \"x$enable_dependency_tracking\" = xyes; then\n\tcontinue\n      else\n\tbreak\n      fi\n      ;;\n    msvc7 | msvc7msys | msvisualcpp | msvcmsys)\n      # This compiler won't grok '-c -o', but also, the minuso test has\n      # not run yet.  These depmodes are late enough in the game, and\n      # so weak that their functioning should not be impacted.\n      am__obj=conftest.${OBJEXT-o}\n      am__minus_obj=\n      ;;\n    none) break ;;\n    esac\n    if depmode=$depmode \\\n       source=sub/conftest.c object=$am__obj \\\n       depfile=sub/conftest.Po tmpdepfile=sub/conftest.TPo \\\n       $SHELL ./depcomp $depcc -c $am__minus_obj sub/conftest.c \\\n         >/dev/null 2>conftest.err &&\n       grep sub/conftst1.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep sub/conftst6.h sub/conftest.Po > /dev/null 2>&1 &&\n       grep $am__obj sub/conftest.Po > /dev/null 2>&1 &&\n       ${MAKE-make} -s -f confmf > /dev/null 2>&1; then\n      # icc doesn't choke on unknown options, it will just issue warnings\n      # or remarks (even with -Werror).  So we grep stderr for any message\n      # that says an option was ignored or not supported.\n      # When given -MP, icc 7.0 and 7.1 complain thusly:\n      #   icc: Command line warning: ignoring option '-M'; no argument required\n      # The diagnosis changed in icc 8.0:\n      #   icc: Command line remark: option '-MP' not supported\n      if (grep 'ignoring option' conftest.err ||\n          grep 'not supported' conftest.err) >/dev/null 2>&1; then :; else\n        am_cv_CXX_dependencies_compiler_type=$depmode\n        break\n      fi\n    fi\n  done\n\n  cd ..\n  rm -rf conftest.dir\nelse\n  am_cv_CXX_dependencies_compiler_type=none\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $am_cv_CXX_dependencies_compiler_type\" >&5\nprintf \"%s\\n\" \"$am_cv_CXX_dependencies_compiler_type\" >&6; }\nCXXDEPMODE=depmode=$am_cv_CXX_dependencies_compiler_type\n\n if\n  test \"x$enable_dependency_tracking\" != xno \\\n  && test \"$am_cv_CXX_dependencies_compiler_type\" = gcc3; then\n  am__fastdepCXX_TRUE=\n  am__fastdepCXX_FALSE='#'\nelse\n  am__fastdepCXX_TRUE='#'\n  am__fastdepCXX_FALSE=\nfi\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether ${MAKE-make} sets \\$(MAKE)\" >&5\nprintf %s \"checking whether ${MAKE-make} sets \\$(MAKE)... \" >&6; }\nset x ${MAKE-make}\nac_make=`printf \"%s\\n\" \"$2\" | sed 's/+/p/g; s/[^a-zA-Z0-9_]/_/g'`\nif eval test \\${ac_cv_prog_make_${ac_make}_set+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat >conftest.make <<\\_ACEOF\nSHELL = /bin/sh\nall:\n\t@echo '@@@%%%=$(MAKE)=@@@%%%'\n_ACEOF\n# GNU make sometimes prints \"make[1]: Entering ...\", which would confuse us.\ncase `${MAKE-make} -f conftest.make 2>/dev/null` in\n  *@@@%%%=?*=@@@%%%*)\n    eval ac_cv_prog_make_${ac_make}_set=yes;;\n  *)\n    eval ac_cv_prog_make_${ac_make}_set=no;;\nesac\nrm -f conftest.make ;;\nesac\nfi\nif eval test \\$ac_cv_prog_make_${ac_make}_set = yes; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n  SET_MAKE=\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\n  SET_MAKE=\"MAKE=${MAKE-make}\"\nfi\n\ncase `pwd` in\n  *\\ * | *\\\t*)\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: Libtool does not cope well with whitespace in \\`pwd\\`\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: Libtool does not cope well with whitespace in \\`pwd\\`\" >&2;} ;;\nesac\n\n\n\nmacro_version='2.4.7'\nmacro_revision='2.4.7'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nltmain=$ac_aux_dir/ltmain.sh\n\n# Backslashify metacharacters that are still active within\n# double-quoted strings.\nsed_quote_subst='s/\\([\"`$\\\\]\\)/\\\\\\1/g'\n\n# Same as above, but do not quote variable references.\ndouble_quote_subst='s/\\([\"`\\\\]\\)/\\\\\\1/g'\n\n# Sed substitution to delay expansion of an escaped shell variable in a\n# double_quote_subst'ed string.\ndelay_variable_subst='s/\\\\\\\\\\\\\\\\\\\\\\$/\\\\\\\\\\\\$/g'\n\n# Sed substitution to delay expansion of an escaped single quote.\ndelay_single_quote_subst='s/'\\''/'\\'\\\\\\\\\\\\\\'\\''/g'\n\n# Sed substitution to avoid accidental globbing in evaled expressions\nno_glob_subst='s/\\*/\\\\\\*/g'\n\nECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to print strings\" >&5\nprintf %s \"checking how to print strings... \" >&6; }\n# Test print first, because it will be a builtin if present.\nif test \"X`( print -r -- -n ) 2>/dev/null`\" = X-n && \\\n   test \"X`print -r -- $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='print -r --'\nelif test \"X`printf %s $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='printf %s\\n'\nelse\n  # Use this function as a fallback that always works.\n  func_fallback_echo ()\n  {\n    eval 'cat <<_LTECHO_EOF\n$1\n_LTECHO_EOF'\n  }\n  ECHO='func_fallback_echo'\nfi\n\n# func_echo_all arg...\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"\"\n}\n\ncase $ECHO in\n  printf*) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: printf\" >&5\nprintf \"%s\\n\" \"printf\" >&6; } ;;\n  print*) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: print -r\" >&5\nprintf \"%s\\n\" \"print -r\" >&6; } ;;\n  *) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: cat\" >&5\nprintf \"%s\\n\" \"cat\" >&6; } ;;\nesac\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for a sed that does not truncate output\" >&5\nprintf %s \"checking for a sed that does not truncate output... \" >&6; }\nif test ${ac_cv_path_SED+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e)           ac_script=s/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/\n     for ac_i in 1 2 3 4 5 6 7; do\n       ac_script=\"$ac_script$as_nl$ac_script\"\n     done\n     echo \"$ac_script\" 2>/dev/null | sed 99q >conftest.sed\n     { ac_script=; unset ac_script;}\n     if test -z \"$SED\"; then\n  ac_path_SED_found=false\n  # Loop through the user's path and test for each of PROGNAME-LIST\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in sed gsed\n   do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      ac_path_SED=\"$as_dir$ac_prog$ac_exec_ext\"\n      as_fn_executable_p \"$ac_path_SED\" || continue\n# Check for GNU ac_path_SED and select it if it is found.\n  # Check for GNU $ac_path_SED\ncase `\"$ac_path_SED\" --version 2>&1` in #(\n*GNU*)\n  ac_cv_path_SED=\"$ac_path_SED\" ac_path_SED_found=:;;\n#(\n*)\n  ac_count=0\n  printf %s 0123456789 >\"conftest.in\"\n  while :\n  do\n    cat \"conftest.in\" \"conftest.in\" >\"conftest.tmp\"\n    mv \"conftest.tmp\" \"conftest.in\"\n    cp \"conftest.in\" \"conftest.nl\"\n    printf \"%s\\n\" '' >> \"conftest.nl\"\n    \"$ac_path_SED\" -f conftest.sed < \"conftest.nl\" >\"conftest.out\" 2>/dev/null || break\n    diff \"conftest.out\" \"conftest.nl\" >/dev/null 2>&1 || break\n    as_fn_arith $ac_count + 1 && ac_count=$as_val\n    if test $ac_count -gt ${ac_path_SED_max-0}; then\n      # Best one so far, save it but keep looking for a better one\n      ac_cv_path_SED=\"$ac_path_SED\"\n      ac_path_SED_max=$ac_count\n    fi\n    # 10*(2^10) chars as input seems more than enough\n    test $ac_count -gt 10 && break\n  done\n  rm -f conftest.in conftest.tmp conftest.nl conftest.out;;\nesac\n\n      $ac_path_SED_found && break 3\n    done\n  done\n  done\nIFS=$as_save_IFS\n  if test -z \"$ac_cv_path_SED\"; then\n    as_fn_error $? \"no acceptable sed could be found in \\$PATH\" \"$LINENO\" 5\n  fi\nelse\n  ac_cv_path_SED=$SED\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_path_SED\" >&5\nprintf \"%s\\n\" \"$ac_cv_path_SED\" >&6; }\n SED=\"$ac_cv_path_SED\"\n  rm -f conftest.sed\n\ntest -z \"$SED\" && SED=sed\nXsed=\"$SED -e 1s/^X//\"\n\n\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for grep that handles long lines and -e\" >&5\nprintf %s \"checking for grep that handles long lines and -e... \" >&6; }\nif test ${ac_cv_path_GREP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$GREP\"; then\n  ac_path_GREP_found=false\n  # Loop through the user's path and test for each of PROGNAME-LIST\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH$PATH_SEPARATOR/usr/xpg4/bin\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in grep ggrep\n   do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      ac_path_GREP=\"$as_dir$ac_prog$ac_exec_ext\"\n      as_fn_executable_p \"$ac_path_GREP\" || continue\n# Check for GNU ac_path_GREP and select it if it is found.\n  # Check for GNU $ac_path_GREP\ncase `\"$ac_path_GREP\" --version 2>&1` in #(\n*GNU*)\n  ac_cv_path_GREP=\"$ac_path_GREP\" ac_path_GREP_found=:;;\n#(\n*)\n  ac_count=0\n  printf %s 0123456789 >\"conftest.in\"\n  while :\n  do\n    cat \"conftest.in\" \"conftest.in\" >\"conftest.tmp\"\n    mv \"conftest.tmp\" \"conftest.in\"\n    cp \"conftest.in\" \"conftest.nl\"\n    printf \"%s\\n\" 'GREP' >> \"conftest.nl\"\n    \"$ac_path_GREP\" -e 'GREP$' -e '-(cannot match)-' < \"conftest.nl\" >\"conftest.out\" 2>/dev/null || break\n    diff \"conftest.out\" \"conftest.nl\" >/dev/null 2>&1 || break\n    as_fn_arith $ac_count + 1 && ac_count=$as_val\n    if test $ac_count -gt ${ac_path_GREP_max-0}; then\n      # Best one so far, save it but keep looking for a better one\n      ac_cv_path_GREP=\"$ac_path_GREP\"\n      ac_path_GREP_max=$ac_count\n    fi\n    # 10*(2^10) chars as input seems more than enough\n    test $ac_count -gt 10 && break\n  done\n  rm -f conftest.in conftest.tmp conftest.nl conftest.out;;\nesac\n\n      $ac_path_GREP_found && break 3\n    done\n  done\n  done\nIFS=$as_save_IFS\n  if test -z \"$ac_cv_path_GREP\"; then\n    as_fn_error $? \"no acceptable grep could be found in $PATH$PATH_SEPARATOR/usr/xpg4/bin\" \"$LINENO\" 5\n  fi\nelse\n  ac_cv_path_GREP=$GREP\nfi\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_path_GREP\" >&5\nprintf \"%s\\n\" \"$ac_cv_path_GREP\" >&6; }\n GREP=\"$ac_cv_path_GREP\"\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for egrep\" >&5\nprintf %s \"checking for egrep... \" >&6; }\nif test ${ac_cv_path_EGREP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if echo a | $GREP -E '(a|b)' >/dev/null 2>&1\n   then ac_cv_path_EGREP=\"$GREP -E\"\n   else\n     if test -z \"$EGREP\"; then\n  ac_path_EGREP_found=false\n  # Loop through the user's path and test for each of PROGNAME-LIST\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH$PATH_SEPARATOR/usr/xpg4/bin\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in egrep\n   do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      ac_path_EGREP=\"$as_dir$ac_prog$ac_exec_ext\"\n      as_fn_executable_p \"$ac_path_EGREP\" || continue\n# Check for GNU ac_path_EGREP and select it if it is found.\n  # Check for GNU $ac_path_EGREP\ncase `\"$ac_path_EGREP\" --version 2>&1` in #(\n*GNU*)\n  ac_cv_path_EGREP=\"$ac_path_EGREP\" ac_path_EGREP_found=:;;\n#(\n*)\n  ac_count=0\n  printf %s 0123456789 >\"conftest.in\"\n  while :\n  do\n    cat \"conftest.in\" \"conftest.in\" >\"conftest.tmp\"\n    mv \"conftest.tmp\" \"conftest.in\"\n    cp \"conftest.in\" \"conftest.nl\"\n    printf \"%s\\n\" 'EGREP' >> \"conftest.nl\"\n    \"$ac_path_EGREP\" 'EGREP$' < \"conftest.nl\" >\"conftest.out\" 2>/dev/null || break\n    diff \"conftest.out\" \"conftest.nl\" >/dev/null 2>&1 || break\n    as_fn_arith $ac_count + 1 && ac_count=$as_val\n    if test $ac_count -gt ${ac_path_EGREP_max-0}; then\n      # Best one so far, save it but keep looking for a better one\n      ac_cv_path_EGREP=\"$ac_path_EGREP\"\n      ac_path_EGREP_max=$ac_count\n    fi\n    # 10*(2^10) chars as input seems more than enough\n    test $ac_count -gt 10 && break\n  done\n  rm -f conftest.in conftest.tmp conftest.nl conftest.out;;\nesac\n\n      $ac_path_EGREP_found && break 3\n    done\n  done\n  done\nIFS=$as_save_IFS\n  if test -z \"$ac_cv_path_EGREP\"; then\n    as_fn_error $? \"no acceptable egrep could be found in $PATH$PATH_SEPARATOR/usr/xpg4/bin\" \"$LINENO\" 5\n  fi\nelse\n  ac_cv_path_EGREP=$EGREP\nfi\n\n   fi ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_path_EGREP\" >&5\nprintf \"%s\\n\" \"$ac_cv_path_EGREP\" >&6; }\n EGREP=\"$ac_cv_path_EGREP\"\n\n         EGREP_TRADITIONAL=$EGREP\n ac_cv_path_EGREP_TRADITIONAL=$EGREP\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for fgrep\" >&5\nprintf %s \"checking for fgrep... \" >&6; }\nif test ${ac_cv_path_FGREP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if echo 'ab*c' | $GREP -F 'ab*c' >/dev/null 2>&1\n   then ac_cv_path_FGREP=\"$GREP -F\"\n   else\n     if test -z \"$FGREP\"; then\n  ac_path_FGREP_found=false\n  # Loop through the user's path and test for each of PROGNAME-LIST\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH$PATH_SEPARATOR/usr/xpg4/bin\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in fgrep\n   do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      ac_path_FGREP=\"$as_dir$ac_prog$ac_exec_ext\"\n      as_fn_executable_p \"$ac_path_FGREP\" || continue\n# Check for GNU ac_path_FGREP and select it if it is found.\n  # Check for GNU $ac_path_FGREP\ncase `\"$ac_path_FGREP\" --version 2>&1` in #(\n*GNU*)\n  ac_cv_path_FGREP=\"$ac_path_FGREP\" ac_path_FGREP_found=:;;\n#(\n*)\n  ac_count=0\n  printf %s 0123456789 >\"conftest.in\"\n  while :\n  do\n    cat \"conftest.in\" \"conftest.in\" >\"conftest.tmp\"\n    mv \"conftest.tmp\" \"conftest.in\"\n    cp \"conftest.in\" \"conftest.nl\"\n    printf \"%s\\n\" 'FGREP' >> \"conftest.nl\"\n    \"$ac_path_FGREP\" FGREP < \"conftest.nl\" >\"conftest.out\" 2>/dev/null || break\n    diff \"conftest.out\" \"conftest.nl\" >/dev/null 2>&1 || break\n    as_fn_arith $ac_count + 1 && ac_count=$as_val\n    if test $ac_count -gt ${ac_path_FGREP_max-0}; then\n      # Best one so far, save it but keep looking for a better one\n      ac_cv_path_FGREP=\"$ac_path_FGREP\"\n      ac_path_FGREP_max=$ac_count\n    fi\n    # 10*(2^10) chars as input seems more than enough\n    test $ac_count -gt 10 && break\n  done\n  rm -f conftest.in conftest.tmp conftest.nl conftest.out;;\nesac\n\n      $ac_path_FGREP_found && break 3\n    done\n  done\n  done\nIFS=$as_save_IFS\n  if test -z \"$ac_cv_path_FGREP\"; then\n    as_fn_error $? \"no acceptable fgrep could be found in $PATH$PATH_SEPARATOR/usr/xpg4/bin\" \"$LINENO\" 5\n  fi\nelse\n  ac_cv_path_FGREP=$FGREP\nfi\n\n   fi ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_path_FGREP\" >&5\nprintf \"%s\\n\" \"$ac_cv_path_FGREP\" >&6; }\n FGREP=\"$ac_cv_path_FGREP\"\n\n\ntest -z \"$GREP\" && GREP=grep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Check whether --with-gnu-ld was given.\nif test ${with_gnu_ld+y}\nthen :\n  withval=$with_gnu_ld; test no = \"$withval\" || with_gnu_ld=yes\nelse case e in #(\n  e) with_gnu_ld=no ;;\nesac\nfi\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for ld used by $CC\" >&5\nprintf %s \"checking for ld used by $CC... \" >&6; }\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [\\\\/]* | ?:[\\\\/]*)\n      re_direlt='/[^/][^/]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for GNU ld\" >&5\nprintf %s \"checking for GNU ld... \" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for non-GNU ld\" >&5\nprintf %s \"checking for non-GNU ld... \" >&6; }\nfi\nif test ${lt_cv_path_LD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi ;;\nesac\nfi\n\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $LD\" >&5\nprintf \"%s\\n\" \"$LD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\ntest -z \"$LD\" && as_fn_error $? \"no acceptable ld found in \\$PATH\" \"$LINENO\" 5\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if the linker ($LD) is GNU ld\" >&5\nprintf %s \"checking if the linker ($LD) is GNU ld... \" >&6; }\nif test ${lt_cv_prog_gnu_ld+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) # I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_gnu_ld\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_gnu_ld\" >&6; }\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for BSD- or MS-compatible name lister (nm)\" >&5\nprintf %s \"checking for BSD- or MS-compatible name lister (nm)... \" >&6; }\nif test ${lt_cv_path_NM+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$NM\"; then\n  # Let the user override the test.\n  lt_cv_path_NM=$NM\nelse\n  lt_nm_to_check=${ac_tool_prefix}nm\n  if test -n \"$ac_tool_prefix\" && test \"$build\" = \"$host\"; then\n    lt_nm_to_check=\"$lt_nm_to_check nm\"\n  fi\n  for lt_tmp_nm in $lt_nm_to_check; do\n    lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n    for ac_dir in $PATH /usr/ccs/bin/elf /usr/ccs/bin /usr/ucb /bin; do\n      IFS=$lt_save_ifs\n      test -z \"$ac_dir\" && ac_dir=.\n      tmp_nm=$ac_dir/$lt_tmp_nm\n      if test -f \"$tmp_nm\" || test -f \"$tmp_nm$ac_exeext\"; then\n\t# Check to see if the nm accepts a BSD-compat flag.\n\t# Adding the 'sed 1q' prevents false positives on HP-UX, which says:\n\t#   nm: unknown option \"B\" ignored\n\t# Tru64's nm complains that /dev/null is an invalid object file\n\t# MSYS converts /dev/null to NUL, MinGW nm treats NUL as empty\n\tcase $build_os in\n\tmingw*) lt_bad_file=conftest.nm/nofile ;;\n\t*) lt_bad_file=/dev/null ;;\n\tesac\n\tcase `\"$tmp_nm\" -B $lt_bad_file 2>&1 | $SED '1q'` in\n\t*$lt_bad_file* | *'Invalid file or object type'*)\n\t  lt_cv_path_NM=\"$tmp_nm -B\"\n\t  break 2\n\t  ;;\n\t*)\n\t  case `\"$tmp_nm\" -p /dev/null 2>&1 | $SED '1q'` in\n\t  */dev/null*)\n\t    lt_cv_path_NM=\"$tmp_nm -p\"\n\t    break 2\n\t    ;;\n\t  *)\n\t    lt_cv_path_NM=${lt_cv_path_NM=\"$tmp_nm\"} # keep the first match, but\n\t    continue # so that we can try to find one that supports BSD flags\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n      fi\n    done\n    IFS=$lt_save_ifs\n  done\n  : ${lt_cv_path_NM=no}\nfi ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_path_NM\" >&5\nprintf \"%s\\n\" \"$lt_cv_path_NM\" >&6; }\nif test no != \"$lt_cv_path_NM\"; then\n  NM=$lt_cv_path_NM\nelse\n  # Didn't find any BSD compatible name lister, look for dumpbin.\n  if test -n \"$DUMPBIN\"; then :\n    # Let the user override the test.\n  else\n    if test -n \"$ac_tool_prefix\"; then\n  for ac_prog in dumpbin \"link -dump\"\n  do\n    # Extract the first word of \"$ac_tool_prefix$ac_prog\", so it can be a program name with args.\nset dummy $ac_tool_prefix$ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_DUMPBIN+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$DUMPBIN\"; then\n  ac_cv_prog_DUMPBIN=\"$DUMPBIN\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_DUMPBIN=\"$ac_tool_prefix$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nDUMPBIN=$ac_cv_prog_DUMPBIN\nif test -n \"$DUMPBIN\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $DUMPBIN\" >&5\nprintf \"%s\\n\" \"$DUMPBIN\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n    test -n \"$DUMPBIN\" && break\n  done\nfi\nif test -z \"$DUMPBIN\"; then\n  ac_ct_DUMPBIN=$DUMPBIN\n  for ac_prog in dumpbin \"link -dump\"\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_DUMPBIN+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_DUMPBIN\"; then\n  ac_cv_prog_ac_ct_DUMPBIN=\"$ac_ct_DUMPBIN\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_DUMPBIN=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_DUMPBIN=$ac_cv_prog_ac_ct_DUMPBIN\nif test -n \"$ac_ct_DUMPBIN\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_DUMPBIN\" >&5\nprintf \"%s\\n\" \"$ac_ct_DUMPBIN\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$ac_ct_DUMPBIN\" && break\ndone\n\n  if test \"x$ac_ct_DUMPBIN\" = x; then\n    DUMPBIN=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    DUMPBIN=$ac_ct_DUMPBIN\n  fi\nfi\n\n    case `$DUMPBIN -symbols -headers /dev/null 2>&1 | $SED '1q'` in\n    *COFF*)\n      DUMPBIN=\"$DUMPBIN -symbols -headers\"\n      ;;\n    *)\n      DUMPBIN=:\n      ;;\n    esac\n  fi\n\n  if test : != \"$DUMPBIN\"; then\n    NM=$DUMPBIN\n  fi\nfi\ntest -z \"$NM\" && NM=nm\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking the name lister ($NM) interface\" >&5\nprintf %s \"checking the name lister ($NM) interface... \" >&6; }\nif test ${lt_cv_nm_interface+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_nm_interface=\"BSD nm\"\n  echo \"int some_variable = 0;\" > conftest.$ac_ext\n  (eval echo \"\\\"\\$as_me:$LINENO: $ac_compile\\\"\" >&5)\n  (eval \"$ac_compile\" 2>conftest.err)\n  cat conftest.err >&5\n  (eval echo \"\\\"\\$as_me:$LINENO: $NM \\\\\\\"conftest.$ac_objext\\\\\\\"\\\"\" >&5)\n  (eval \"$NM \\\"conftest.$ac_objext\\\"\" 2>conftest.err > conftest.out)\n  cat conftest.err >&5\n  (eval echo \"\\\"\\$as_me:$LINENO: output\\\"\" >&5)\n  cat conftest.out >&5\n  if $GREP 'External.*some_variable' conftest.out > /dev/null; then\n    lt_cv_nm_interface=\"MS dumpbin\"\n  fi\n  rm -f conftest* ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_nm_interface\" >&5\nprintf \"%s\\n\" \"$lt_cv_nm_interface\" >&6; }\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether ln -s works\" >&5\nprintf %s \"checking whether ln -s works... \" >&6; }\nLN_S=$as_ln_s\nif test \"$LN_S\" = \"ln -s\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no, using $LN_S\" >&5\nprintf \"%s\\n\" \"no, using $LN_S\" >&6; }\nfi\n\n# find the maximum length of command line arguments\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking the maximum length of command line arguments\" >&5\nprintf %s \"checking the maximum length of command line arguments... \" >&6; }\nif test ${lt_cv_sys_max_cmd_len+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e)   i=0\n  teststring=ABCD\n\n  case $build_os in\n  msdosdjgpp*)\n    # On DJGPP, this test can blow up pretty badly due to problems in libc\n    # (any single argument exceeding 2000 bytes causes a buffer overrun\n    # during glob expansion).  Even if it were fixed, the result of this\n    # check would be larger than it should be.\n    lt_cv_sys_max_cmd_len=12288;    # 12K is about right\n    ;;\n\n  gnu*)\n    # Under GNU Hurd, this test is not required because there is\n    # no limit to the length of command line arguments.\n    # Libtool will interpret -1 as no limit whatsoever\n    lt_cv_sys_max_cmd_len=-1;\n    ;;\n\n  cygwin* | mingw* | cegcc*)\n    # On Win9x/ME, this test blows up -- it succeeds, but takes\n    # about 5 minutes as the teststring grows exponentially.\n    # Worse, since 9x/ME are not pre-emptively multitasking,\n    # you end up with a \"frozen\" computer, even though with patience\n    # the test eventually succeeds (with a max line length of 256k).\n    # Instead, let's just punt: use the minimum linelength reported by\n    # all of the supported platforms: 8192 (on NT/2K/XP).\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  mint*)\n    # On MiNT this can take a long time and run out of memory.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  amigaos*)\n    # On AmigaOS with pdksh, this test takes hours, literally.\n    # So we just punt and use a minimum line length of 8192.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  bitrig* | darwin* | dragonfly* | freebsd* | midnightbsd* | netbsd* | openbsd*)\n    # This has been around since 386BSD, at least.  Likely further.\n    if test -x /sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/sbin/sysctl -n kern.argmax`\n    elif test -x /usr/sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/usr/sbin/sysctl -n kern.argmax`\n    else\n      lt_cv_sys_max_cmd_len=65536\t# usable default for all BSDs\n    fi\n    # And add a safety zone\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    ;;\n\n  interix*)\n    # We know the value 262144 and hardcode it with a safety zone (like BSD)\n    lt_cv_sys_max_cmd_len=196608\n    ;;\n\n  os2*)\n    # The test takes a long time on OS/2.\n    lt_cv_sys_max_cmd_len=8192\n    ;;\n\n  osf*)\n    # Dr. Hans Ekkehard Plesser reports seeing a kernel panic running configure\n    # due to this test when exec_disable_arg_limit is 1 on Tru64. It is not\n    # nice to cause kernel panics so lets avoid the loop below.\n    # First set a reasonable default.\n    lt_cv_sys_max_cmd_len=16384\n    #\n    if test -x /sbin/sysconfig; then\n      case `/sbin/sysconfig -q proc exec_disable_arg_limit` in\n        *1*) lt_cv_sys_max_cmd_len=-1 ;;\n      esac\n    fi\n    ;;\n  sco3.2v5*)\n    lt_cv_sys_max_cmd_len=102400\n    ;;\n  sysv5* | sco5v6* | sysv4.2uw2*)\n    kargmax=`grep ARG_MAX /etc/conf/cf.d/stune 2>/dev/null`\n    if test -n \"$kargmax\"; then\n      lt_cv_sys_max_cmd_len=`echo $kargmax | $SED 's/.*[\t ]//'`\n    else\n      lt_cv_sys_max_cmd_len=32768\n    fi\n    ;;\n  *)\n    lt_cv_sys_max_cmd_len=`(getconf ARG_MAX) 2> /dev/null`\n    if test -n \"$lt_cv_sys_max_cmd_len\" && \\\n       test undefined != \"$lt_cv_sys_max_cmd_len\"; then\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    else\n      # Make teststring a little bigger before we do anything with it.\n      # a 1K string should be a reasonable start.\n      for i in 1 2 3 4 5 6 7 8; do\n        teststring=$teststring$teststring\n      done\n      SHELL=${SHELL-${CONFIG_SHELL-/bin/sh}}\n      # If test is not a shell built-in, we'll probably end up computing a\n      # maximum length that is only half of the actual maximum length, but\n      # we can't tell.\n      while { test X`env echo \"$teststring$teststring\" 2>/dev/null` \\\n\t         = \"X$teststring$teststring\"; } >/dev/null 2>&1 &&\n\t      test 17 != \"$i\" # 1/2 MB should be enough\n      do\n        i=`expr $i + 1`\n        teststring=$teststring$teststring\n      done\n      # Only check the string length outside the loop.\n      lt_cv_sys_max_cmd_len=`expr \"X$teststring\" : \".*\" 2>&1`\n      teststring=\n      # Add a significant safety factor because C++ compilers can tack on\n      # massive amounts of additional arguments before passing them to the\n      # linker.  It appears as though 1/2 is a usable value.\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 2`\n    fi\n    ;;\n  esac\n ;;\nesac\nfi\n\nif test -n \"$lt_cv_sys_max_cmd_len\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_sys_max_cmd_len\" >&5\nprintf \"%s\\n\" \"$lt_cv_sys_max_cmd_len\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: none\" >&5\nprintf \"%s\\n\" \"none\" >&6; }\nfi\nmax_cmd_len=$lt_cv_sys_max_cmd_len\n\n\n\n\n\n\n: ${CP=\"cp -f\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n\nif ( (MAIL=60; unset MAIL) || exit) >/dev/null 2>&1; then\n  lt_unset=unset\nelse\n  lt_unset=false\nfi\n\n\n\n\n\n# test EBCDIC or ASCII\ncase `echo X|tr X '\\101'` in\n A) # ASCII based system\n    # \\n is not interpreted correctly by Solaris 8 /usr/ucb/tr\n  lt_SP2NL='tr \\040 \\012'\n  lt_NL2SP='tr \\015\\012 \\040\\040'\n  ;;\n *) # EBCDIC based system\n  lt_SP2NL='tr \\100 \\n'\n  lt_NL2SP='tr \\r\\n \\100\\100'\n  ;;\nesac\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to convert $build file names to $host format\" >&5\nprintf %s \"checking how to convert $build file names to $host format... \" >&6; }\nif test ${lt_cv_to_host_file_cmd+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) case $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_w32\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_cygwin_to_w32\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_w32\n        ;;\n    esac\n    ;;\n  *-*-cygwin* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_cygwin\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_noop\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_cygwin\n        ;;\n    esac\n    ;;\n  * ) # unhandled hosts (and \"normal\" native builds)\n    lt_cv_to_host_file_cmd=func_convert_file_noop\n    ;;\nesac\n ;;\nesac\nfi\n\nto_host_file_cmd=$lt_cv_to_host_file_cmd\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_to_host_file_cmd\" >&5\nprintf \"%s\\n\" \"$lt_cv_to_host_file_cmd\" >&6; }\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to convert $build file names to toolchain format\" >&5\nprintf %s \"checking how to convert $build file names to toolchain format... \" >&6; }\nif test ${lt_cv_to_tool_file_cmd+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) #assume ordinary cross tools, or native build.\nlt_cv_to_tool_file_cmd=func_convert_file_noop\ncase $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_tool_file_cmd=func_convert_file_msys_to_w32\n        ;;\n    esac\n    ;;\nesac\n ;;\nesac\nfi\n\nto_tool_file_cmd=$lt_cv_to_tool_file_cmd\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_to_tool_file_cmd\" >&5\nprintf \"%s\\n\" \"$lt_cv_to_tool_file_cmd\" >&6; }\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $LD option to reload object files\" >&5\nprintf %s \"checking for $LD option to reload object files... \" >&6; }\nif test ${lt_cv_ld_reload_flag+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_ld_reload_flag='-r' ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_ld_reload_flag\" >&5\nprintf \"%s\\n\" \"$lt_cv_ld_reload_flag\" >&6; }\nreload_flag=$lt_cv_ld_reload_flag\ncase $reload_flag in\n\"\" | \" \"*) ;;\n*) reload_flag=\" $reload_flag\" ;;\nesac\nreload_cmds='$LD$reload_flag -o $output$reload_objs'\ncase $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    if test yes != \"$GCC\"; then\n      reload_cmds=false\n    fi\n    ;;\n  darwin*)\n    if test yes = \"$GCC\"; then\n      reload_cmds='$LTCC $LTCFLAGS -nostdlib $wl-r -o $output$reload_objs'\n    else\n      reload_cmds='$LD$reload_flag -o $output$reload_objs'\n    fi\n    ;;\nesac\n\n\n\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}file\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}file; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_FILECMD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$FILECMD\"; then\n  ac_cv_prog_FILECMD=\"$FILECMD\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_FILECMD=\"${ac_tool_prefix}file\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nFILECMD=$ac_cv_prog_FILECMD\nif test -n \"$FILECMD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $FILECMD\" >&5\nprintf \"%s\\n\" \"$FILECMD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_FILECMD\"; then\n  ac_ct_FILECMD=$FILECMD\n  # Extract the first word of \"file\", so it can be a program name with args.\nset dummy file; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_FILECMD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_FILECMD\"; then\n  ac_cv_prog_ac_ct_FILECMD=\"$ac_ct_FILECMD\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_FILECMD=\"file\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_FILECMD=$ac_cv_prog_ac_ct_FILECMD\nif test -n \"$ac_ct_FILECMD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_FILECMD\" >&5\nprintf \"%s\\n\" \"$ac_ct_FILECMD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_FILECMD\" = x; then\n    FILECMD=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    FILECMD=$ac_ct_FILECMD\n  fi\nelse\n  FILECMD=\"$ac_cv_prog_FILECMD\"\nfi\n\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}objdump\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}objdump; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_OBJDUMP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$OBJDUMP\"; then\n  ac_cv_prog_OBJDUMP=\"$OBJDUMP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_OBJDUMP=\"${ac_tool_prefix}objdump\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nOBJDUMP=$ac_cv_prog_OBJDUMP\nif test -n \"$OBJDUMP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $OBJDUMP\" >&5\nprintf \"%s\\n\" \"$OBJDUMP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_OBJDUMP\"; then\n  ac_ct_OBJDUMP=$OBJDUMP\n  # Extract the first word of \"objdump\", so it can be a program name with args.\nset dummy objdump; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_OBJDUMP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_OBJDUMP\"; then\n  ac_cv_prog_ac_ct_OBJDUMP=\"$ac_ct_OBJDUMP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_OBJDUMP=\"objdump\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_OBJDUMP=$ac_cv_prog_ac_ct_OBJDUMP\nif test -n \"$ac_ct_OBJDUMP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_OBJDUMP\" >&5\nprintf \"%s\\n\" \"$ac_ct_OBJDUMP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_OBJDUMP\" = x; then\n    OBJDUMP=\"false\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    OBJDUMP=$ac_ct_OBJDUMP\n  fi\nelse\n  OBJDUMP=\"$ac_cv_prog_OBJDUMP\"\nfi\n\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to recognize dependent libraries\" >&5\nprintf %s \"checking how to recognize dependent libraries... \" >&6; }\nif test ${lt_cv_deplibs_check_method+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_file_magic_cmd='$MAGIC_CMD'\nlt_cv_file_magic_test_file=\nlt_cv_deplibs_check_method='unknown'\n# Need to set the preceding variable on all platforms that support\n# interlibrary dependencies.\n# 'none' -- dependencies not supported.\n# 'unknown' -- same as none, but documents that we really don't know.\n# 'pass_all' -- all dependencies passed with no checks.\n# 'test_compile' -- check by making test program.\n# 'file_magic [[regex]]' -- check by looking for files in library path\n# that responds to the $file_magic_cmd with a given extended regex.\n# If you have 'file' or equivalent on your system and you're not sure\n# whether 'pass_all' will *always* work, you probably want this one.\n\ncase $host_os in\naix[4-9]*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbeos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbsdi[45]*)\n  lt_cv_deplibs_check_method='file_magic ELF [0-9][0-9]*-bit [ML]SB (shared object|dynamic lib)'\n  lt_cv_file_magic_cmd='$FILECMD -L'\n  lt_cv_file_magic_test_file=/shlib/libc.so\n  ;;\n\ncygwin*)\n  # func_win32_libid is a shell function defined in ltmain.sh\n  lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n  lt_cv_file_magic_cmd='func_win32_libid'\n  ;;\n\nmingw* | pw32*)\n  # Base MSYS/MinGW do not provide the 'file' command needed by\n  # func_win32_libid shell function, so use a weaker test based on 'objdump',\n  # unless we find 'file', for example because we are cross-compiling.\n  if ( file / ) >/dev/null 2>&1; then\n    lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n    lt_cv_file_magic_cmd='func_win32_libid'\n  else\n    # Keep this pattern in sync with the one in func_win32_libid.\n    lt_cv_deplibs_check_method='file_magic file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)'\n    lt_cv_file_magic_cmd='$OBJDUMP -f'\n  fi\n  ;;\n\ncegcc*)\n  # use the weaker test based on 'objdump'. See mingw*.\n  lt_cv_deplibs_check_method='file_magic file format pe-arm-.*little(.*architecture: arm)?'\n  lt_cv_file_magic_cmd='$OBJDUMP -f'\n  ;;\n\ndarwin* | rhapsody*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nfreebsd* | dragonfly* | midnightbsd*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    case $host_cpu in\n    i*86 )\n      # Not sure whether the presence of OpenBSD here was a mistake.\n      # Let's accept both of them until this is cleared up.\n      lt_cv_deplibs_check_method='file_magic (FreeBSD|OpenBSD|DragonFly)/i[3-9]86 (compact )?demand paged shared library'\n      lt_cv_file_magic_cmd=$FILECMD\n      lt_cv_file_magic_test_file=`echo /usr/lib/libc.so.*`\n      ;;\n    esac\n  else\n    lt_cv_deplibs_check_method=pass_all\n  fi\n  ;;\n\nhaiku*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nhpux10.20* | hpux11*)\n  lt_cv_file_magic_cmd=$FILECMD\n  case $host_cpu in\n  ia64*)\n    lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF-[0-9][0-9]) shared object file - IA64'\n    lt_cv_file_magic_test_file=/usr/lib/hpux32/libc.so\n    ;;\n  hppa*64*)\n    lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF[ -][0-9][0-9])(-bit)?( [LM]SB)? shared object( file)?[, -]* PA-RISC [0-9]\\.[0-9]'\n    lt_cv_file_magic_test_file=/usr/lib/pa20_64/libc.sl\n    ;;\n  *)\n    lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|PA-RISC[0-9]\\.[0-9]) shared library'\n    lt_cv_file_magic_test_file=/usr/lib/libc.sl\n    ;;\n  esac\n  ;;\n\ninterix[3-9]*)\n  # PIC code is broken on Interix 3.x, that's why |\\.a not |_pic\\.a here\n  lt_cv_deplibs_check_method='match_pattern /lib[^/]+(\\.so|\\.a)$'\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $LD in\n  *-32|*\"-32 \") libmagic=32-bit;;\n  *-n32|*\"-n32 \") libmagic=N32;;\n  *-64|*\"-64 \") libmagic=64-bit;;\n  *) libmagic=never-match;;\n  esac\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nnetbsd* | netbsdelf*-gnu)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    lt_cv_deplibs_check_method='match_pattern /lib[^/]+(\\.so\\.[0-9]+\\.[0-9]+|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[^/]+(\\.so|_pic\\.a)$'\n  fi\n  ;;\n\nnewos6*)\n  lt_cv_deplibs_check_method='file_magic ELF [0-9][0-9]*-bit [ML]SB (executable|dynamic lib)'\n  lt_cv_file_magic_cmd=$FILECMD\n  lt_cv_file_magic_test_file=/usr/lib/libnls.so\n  ;;\n\n*nto* | *qnx*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nopenbsd* | bitrig*)\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    lt_cv_deplibs_check_method='match_pattern /lib[^/]+(\\.so\\.[0-9]+\\.[0-9]+|\\.so|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[^/]+(\\.so\\.[0-9]+\\.[0-9]+|_pic\\.a)$'\n  fi\n  ;;\n\nosf3* | osf4* | osf5*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nrdos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsolaris*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv4 | sysv4.3*)\n  case $host_vendor in\n  motorola)\n    lt_cv_deplibs_check_method='file_magic ELF [0-9][0-9]*-bit [ML]SB (shared object|dynamic lib) M[0-9][0-9]* Version [0-9]'\n    lt_cv_file_magic_test_file=`echo /usr/lib/libc.so*`\n    ;;\n  ncr)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  sequent)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method='file_magic ELF [0-9][0-9]*-bit [LM]SB (shared object|dynamic lib )'\n    ;;\n  sni)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method=\"file_magic ELF [0-9][0-9]*-bit [LM]SB dynamic lib\"\n    lt_cv_file_magic_test_file=/lib/libc.so\n    ;;\n  siemens)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  pc)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  esac\n  ;;\n\ntpf*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nos2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nesac\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_deplibs_check_method\" >&5\nprintf \"%s\\n\" \"$lt_cv_deplibs_check_method\" >&6; }\n\nfile_magic_glob=\nwant_nocaseglob=no\nif test \"$build\" = \"$host\"; then\n  case $host_os in\n  mingw* | pw32*)\n    if ( shopt | grep nocaseglob ) >/dev/null 2>&1; then\n      want_nocaseglob=yes\n    else\n      file_magic_glob=`echo aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ | $SED -e \"s/\\(..\\)/s\\/[\\1]\\/[\\1]\\/g;/g\"`\n    fi\n    ;;\n  esac\nfi\n\nfile_magic_cmd=$lt_cv_file_magic_cmd\ndeplibs_check_method=$lt_cv_deplibs_check_method\ntest -z \"$deplibs_check_method\" && deplibs_check_method=unknown\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}dlltool\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}dlltool; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_DLLTOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$DLLTOOL\"; then\n  ac_cv_prog_DLLTOOL=\"$DLLTOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_DLLTOOL=\"${ac_tool_prefix}dlltool\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nDLLTOOL=$ac_cv_prog_DLLTOOL\nif test -n \"$DLLTOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $DLLTOOL\" >&5\nprintf \"%s\\n\" \"$DLLTOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_DLLTOOL\"; then\n  ac_ct_DLLTOOL=$DLLTOOL\n  # Extract the first word of \"dlltool\", so it can be a program name with args.\nset dummy dlltool; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_DLLTOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_DLLTOOL\"; then\n  ac_cv_prog_ac_ct_DLLTOOL=\"$ac_ct_DLLTOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_DLLTOOL=\"dlltool\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_DLLTOOL=$ac_cv_prog_ac_ct_DLLTOOL\nif test -n \"$ac_ct_DLLTOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_DLLTOOL\" >&5\nprintf \"%s\\n\" \"$ac_ct_DLLTOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_DLLTOOL\" = x; then\n    DLLTOOL=\"false\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    DLLTOOL=$ac_ct_DLLTOOL\n  fi\nelse\n  DLLTOOL=\"$ac_cv_prog_DLLTOOL\"\nfi\n\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to associate runtime and link libraries\" >&5\nprintf %s \"checking how to associate runtime and link libraries... \" >&6; }\nif test ${lt_cv_sharedlib_from_linklib_cmd+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_sharedlib_from_linklib_cmd='unknown'\n\ncase $host_os in\ncygwin* | mingw* | pw32* | cegcc*)\n  # two different shell functions defined in ltmain.sh;\n  # decide which one to use based on capabilities of $DLLTOOL\n  case `$DLLTOOL --help 2>&1` in\n  *--identify-strict*)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib\n    ;;\n  *)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib_fallback\n    ;;\n  esac\n  ;;\n*)\n  # fallback: assume linklib IS sharedlib\n  lt_cv_sharedlib_from_linklib_cmd=$ECHO\n  ;;\nesac\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_sharedlib_from_linklib_cmd\" >&5\nprintf \"%s\\n\" \"$lt_cv_sharedlib_from_linklib_cmd\" >&6; }\nsharedlib_from_linklib_cmd=$lt_cv_sharedlib_from_linklib_cmd\ntest -z \"$sharedlib_from_linklib_cmd\" && sharedlib_from_linklib_cmd=$ECHO\n\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  for ac_prog in ar\n  do\n    # Extract the first word of \"$ac_tool_prefix$ac_prog\", so it can be a program name with args.\nset dummy $ac_tool_prefix$ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_AR+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$AR\"; then\n  ac_cv_prog_AR=\"$AR\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_AR=\"$ac_tool_prefix$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nAR=$ac_cv_prog_AR\nif test -n \"$AR\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $AR\" >&5\nprintf \"%s\\n\" \"$AR\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n    test -n \"$AR\" && break\n  done\nfi\nif test -z \"$AR\"; then\n  ac_ct_AR=$AR\n  for ac_prog in ar\ndo\n  # Extract the first word of \"$ac_prog\", so it can be a program name with args.\nset dummy $ac_prog; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_AR+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_AR\"; then\n  ac_cv_prog_ac_ct_AR=\"$ac_ct_AR\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_AR=\"$ac_prog\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_AR=$ac_cv_prog_ac_ct_AR\nif test -n \"$ac_ct_AR\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_AR\" >&5\nprintf \"%s\\n\" \"$ac_ct_AR\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  test -n \"$ac_ct_AR\" && break\ndone\n\n  if test \"x$ac_ct_AR\" = x; then\n    AR=\"false\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    AR=$ac_ct_AR\n  fi\nfi\n\n: ${AR=ar}\n\n\n\n\n\n\n# Use ARFLAGS variable as AR's operation code to sync the variable naming with\n# Automake.  If both AR_FLAGS and ARFLAGS are specified, AR_FLAGS should have\n# higher priority because thats what people were doing historically (setting\n# ARFLAGS for automake and AR_FLAGS for libtool).  FIXME: Make the AR_FLAGS\n# variable obsoleted/removed.\n\ntest ${AR_FLAGS+y} || AR_FLAGS=${ARFLAGS-cr}\nlt_ar_flags=$AR_FLAGS\n\n\n\n\n\n\n# Make AR_FLAGS overridable by 'make ARFLAGS='.  Don't try to run-time override\n# by AR_FLAGS because that was never working and AR_FLAGS is about to die.\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for archiver @FILE support\" >&5\nprintf %s \"checking for archiver @FILE support... \" >&6; }\nif test ${lt_cv_ar_at_file+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_ar_at_file=no\n   cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_compile \"$LINENO\"\nthen :\n  echo conftest.$ac_objext > conftest.lst\n      lt_ar_try='$AR $AR_FLAGS libconftest.a @conftest.lst >&5'\n      { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$lt_ar_try\\\"\"; } >&5\n  (eval $lt_ar_try) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\n      if test 0 -eq \"$ac_status\"; then\n\t# Ensure the archiver fails upon bogus file names.\n\trm -f conftest.$ac_objext libconftest.a\n\t{ { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$lt_ar_try\\\"\"; } >&5\n  (eval $lt_ar_try) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\n\tif test 0 -ne \"$ac_status\"; then\n          lt_cv_ar_at_file=@\n        fi\n      fi\n      rm -f conftest.* libconftest.a\n\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam conftest.$ac_ext\n   ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_ar_at_file\" >&5\nprintf \"%s\\n\" \"$lt_cv_ar_at_file\" >&6; }\n\nif test no = \"$lt_cv_ar_at_file\"; then\n  archiver_list_spec=\nelse\n  archiver_list_spec=$lt_cv_ar_at_file\nfi\n\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}strip\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}strip; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_STRIP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$STRIP\"; then\n  ac_cv_prog_STRIP=\"$STRIP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_STRIP=\"${ac_tool_prefix}strip\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nSTRIP=$ac_cv_prog_STRIP\nif test -n \"$STRIP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $STRIP\" >&5\nprintf \"%s\\n\" \"$STRIP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_STRIP\"; then\n  ac_ct_STRIP=$STRIP\n  # Extract the first word of \"strip\", so it can be a program name with args.\nset dummy strip; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_STRIP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_STRIP\"; then\n  ac_cv_prog_ac_ct_STRIP=\"$ac_ct_STRIP\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_STRIP=\"strip\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_STRIP=$ac_cv_prog_ac_ct_STRIP\nif test -n \"$ac_ct_STRIP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_STRIP\" >&5\nprintf \"%s\\n\" \"$ac_ct_STRIP\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_STRIP\" = x; then\n    STRIP=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    STRIP=$ac_ct_STRIP\n  fi\nelse\n  STRIP=\"$ac_cv_prog_STRIP\"\nfi\n\ntest -z \"$STRIP\" && STRIP=:\n\n\n\n\n\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}ranlib\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}ranlib; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_RANLIB+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$RANLIB\"; then\n  ac_cv_prog_RANLIB=\"$RANLIB\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_RANLIB=\"${ac_tool_prefix}ranlib\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nRANLIB=$ac_cv_prog_RANLIB\nif test -n \"$RANLIB\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $RANLIB\" >&5\nprintf \"%s\\n\" \"$RANLIB\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_RANLIB\"; then\n  ac_ct_RANLIB=$RANLIB\n  # Extract the first word of \"ranlib\", so it can be a program name with args.\nset dummy ranlib; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_RANLIB+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_RANLIB\"; then\n  ac_cv_prog_ac_ct_RANLIB=\"$ac_ct_RANLIB\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_RANLIB=\"ranlib\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_RANLIB=$ac_cv_prog_ac_ct_RANLIB\nif test -n \"$ac_ct_RANLIB\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_RANLIB\" >&5\nprintf \"%s\\n\" \"$ac_ct_RANLIB\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_RANLIB\" = x; then\n    RANLIB=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    RANLIB=$ac_ct_RANLIB\n  fi\nelse\n  RANLIB=\"$ac_cv_prog_RANLIB\"\nfi\n\ntest -z \"$RANLIB\" && RANLIB=:\n\n\n\n\n\n\n# Determine commands to create old-style static archives.\nold_archive_cmds='$AR $AR_FLAGS $oldlib$oldobjs'\nold_postinstall_cmds='chmod 644 $oldlib'\nold_postuninstall_cmds=\n\nif test -n \"$RANLIB\"; then\n  case $host_os in\n  bitrig* | openbsd*)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB -t \\$tool_oldlib\"\n    ;;\n  *)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB \\$tool_oldlib\"\n    ;;\n  esac\n  old_archive_cmds=\"$old_archive_cmds~\\$RANLIB \\$tool_oldlib\"\nfi\n\ncase $host_os in\n  darwin*)\n    lock_old_archive_extraction=yes ;;\n  *)\n    lock_old_archive_extraction=no ;;\nesac\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n\n\n# Check for command to grab the raw symbol name followed by C symbol from nm.\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking command to parse $NM output from $compiler object\" >&5\nprintf %s \"checking command to parse $NM output from $compiler object... \" >&6; }\nif test ${lt_cv_sys_global_symbol_pipe+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e)\n# These are sane defaults that work on at least a few old systems.\n# [They come from Ultrix.  What could be older than Ultrix?!! ;)]\n\n# Character class describing NM global symbol codes.\nsymcode='[BCDEGRST]'\n\n# Regexp to match symbols that can be accessed directly from C.\nsympat='\\([_A-Za-z][_A-Za-z0-9]*\\)'\n\n# Define system-specific variables.\ncase $host_os in\naix*)\n  symcode='[BCDT]'\n  ;;\ncygwin* | mingw* | pw32* | cegcc*)\n  symcode='[ABCDGISTW]'\n  ;;\nhpux*)\n  if test ia64 = \"$host_cpu\"; then\n    symcode='[ABCDEGRST]'\n  fi\n  ;;\nirix* | nonstopux*)\n  symcode='[BCDEGRST]'\n  ;;\nosf*)\n  symcode='[BCDEGQRST]'\n  ;;\nsolaris*)\n  symcode='[BDRT]'\n  ;;\nsco3.2v5*)\n  symcode='[DT]'\n  ;;\nsysv4.2uw2*)\n  symcode='[DT]'\n  ;;\nsysv5* | sco5v6* | unixware* | OpenUNIX*)\n  symcode='[ABDT]'\n  ;;\nsysv4)\n  symcode='[DFNSTU]'\n  ;;\nesac\n\n# If we're using GNU nm, then use its standard symbol codes.\ncase `$NM -V 2>&1` in\n*GNU* | *'with BFD'*)\n  symcode='[ABCDGIRSTW]' ;;\nesac\n\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  # Gets list of data symbols to import.\n  lt_cv_sys_global_symbol_to_import=\"$SED -n -e 's/^I .* \\(.*\\)$/\\1/p'\"\n  # Adjust the below global symbol transforms to fixup imported variables.\n  lt_cdecl_hook=\" -e 's/^I .* \\(.*\\)$/extern __declspec(dllimport) char \\1;/p'\"\n  lt_c_name_hook=\" -e 's/^I .* \\(.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\"\n  lt_c_name_lib_hook=\"\\\n  -e 's/^I .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\\\n  -e 's/^I .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) 0},/p'\"\nelse\n  # Disable hooks by default.\n  lt_cv_sys_global_symbol_to_import=\n  lt_cdecl_hook=\n  lt_c_name_hook=\n  lt_c_name_lib_hook=\nfi\n\n# Transform an extracted symbol line into a proper C declaration.\n# Some systems (esp. on ia64) link data and code symbols differently,\n# so use this general approach.\nlt_cv_sys_global_symbol_to_cdecl=\"$SED -n\"\\\n$lt_cdecl_hook\\\n\" -e 's/^T .* \\(.*\\)$/extern int \\1();/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/extern char \\1;/p'\"\n\n# Transform an extracted symbol line into symbol name and symbol address\nlt_cv_sys_global_symbol_to_c_name_address=\"$SED -n\"\\\n$lt_c_name_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\n\n# Transform an extracted symbol line into symbol name with lib prefix and\n# symbol address.\nlt_cv_sys_global_symbol_to_c_name_address_lib_prefix=\"$SED -n\"\\\n$lt_c_name_lib_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) \\&\\1},/p'\"\n\n# Handle CRLF in mingw tool chain\nopt_cr=\ncase $build_os in\nmingw*)\n  opt_cr=`$ECHO 'x\\{0,1\\}' | tr x '\\015'` # option cr in regexp\n  ;;\nesac\n\n# Try without a prefix underscore, then with it.\nfor ac_symprfx in \"\" \"_\"; do\n\n  # Transform symcode, sympat, and symprfx into a raw symbol and a C symbol.\n  symxfrm=\"\\\\1 $ac_symprfx\\\\2 \\\\2\"\n\n  # Write the raw and C identifiers.\n  if test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n    # Fake it for dumpbin and say T for any non-static function,\n    # D for any global variable and I for any imported variable.\n    # Also find C++ and __fastcall symbols from MSVC++ or ICC,\n    # which start with @ or ?.\n    lt_cv_sys_global_symbol_pipe=\"$AWK '\"\\\n\"     {last_section=section; section=\\$ 3};\"\\\n\"     /^COFF SYMBOL TABLE/{for(i in hide) delete hide[i]};\"\\\n\"     /Section length .*#relocs.*(pick any)/{hide[last_section]=1};\"\\\n\"     /^ *Symbol name *: /{split(\\$ 0,sn,\\\":\\\"); si=substr(sn[2],2)};\"\\\n\"     /^ *Type *: code/{print \\\"T\\\",si,substr(si,length(prfx))};\"\\\n\"     /^ *Type *: data/{print \\\"I\\\",si,substr(si,length(prfx))};\"\\\n\"     \\$ 0!~/External *\\|/{next};\"\\\n\"     / 0+ UNDEF /{next}; / UNDEF \\([^|]\\)*()/{next};\"\\\n\"     {if(hide[section]) next};\"\\\n\"     {f=\\\"D\\\"}; \\$ 0~/\\(\\).*\\|/{f=\\\"T\\\"};\"\\\n\"     {split(\\$ 0,a,/\\||\\r/); split(a[2],s)};\"\\\n\"     s[1]~/^[@?]/{print f,s[1],s[1]; next};\"\\\n\"     s[1]~prfx {split(s[1],t,\\\"@\\\"); print f,t[1],substr(t[1],length(prfx))}\"\\\n\"     ' prfx=^$ac_symprfx\"\n  else\n    lt_cv_sys_global_symbol_pipe=\"$SED -n -e 's/^.*[\t ]\\($symcode$symcode*\\)[\t ][\t ]*$ac_symprfx$sympat$opt_cr$/$symxfrm/p'\"\n  fi\n  lt_cv_sys_global_symbol_pipe=\"$lt_cv_sys_global_symbol_pipe | $SED '/ __gnu_lto/d'\"\n\n  # Check to see that the pipe works correctly.\n  pipe_works=no\n\n  rm -f conftest*\n  cat > conftest.$ac_ext <<_LT_EOF\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nchar nm_test_var;\nvoid nm_test_func(void);\nvoid nm_test_func(void){}\n#ifdef __cplusplus\n}\n#endif\nint main(){nm_test_var='a';nm_test_func();return(0);}\n_LT_EOF\n\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    # Now try to grab the symbols.\n    nlist=conftest.nm\n    $ECHO \"$as_me:$LINENO: $NM conftest.$ac_objext | $lt_cv_sys_global_symbol_pipe > $nlist\" >&5\n    if eval \"$NM\" conftest.$ac_objext \\| \"$lt_cv_sys_global_symbol_pipe\" \\> $nlist 2>&5 && test -s \"$nlist\"; then\n      # Try sorting and uniquifying the output.\n      if sort \"$nlist\" | uniq > \"$nlist\"T; then\n\tmv -f \"$nlist\"T \"$nlist\"\n      else\n\trm -f \"$nlist\"T\n      fi\n\n      # Make sure that we snagged all the symbols we need.\n      if $GREP ' nm_test_var$' \"$nlist\" >/dev/null; then\n\tif $GREP ' nm_test_func$' \"$nlist\" >/dev/null; then\n\t  cat <<_LT_EOF > conftest.$ac_ext\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT_DLSYM_CONST\n#else\n# define LT_DLSYM_CONST const\n#endif\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n_LT_EOF\n\t  # Now generate the symbol file.\n\t  eval \"$lt_cv_sys_global_symbol_to_cdecl\"' < \"$nlist\" | $GREP -v main >> conftest.$ac_ext'\n\n\t  cat <<_LT_EOF >> conftest.$ac_ext\n\n/* The mapping between symbol names and symbols.  */\nLT_DLSYM_CONST struct {\n  const char *name;\n  void       *address;\n}\nlt__PROGRAM__LTX_preloaded_symbols[] =\n{\n  { \"@PROGRAM@\", (void *) 0 },\n_LT_EOF\n\t  $SED \"s/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/\" < \"$nlist\" | $GREP -v main >> conftest.$ac_ext\n\t  cat <<\\_LT_EOF >> conftest.$ac_ext\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt__PROGRAM__LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n_LT_EOF\n\t  # Now try linking the two files.\n\t  mv conftest.$ac_objext conftstm.$ac_objext\n\t  lt_globsym_save_LIBS=$LIBS\n\t  lt_globsym_save_CFLAGS=$CFLAGS\n\t  LIBS=conftstm.$ac_objext\n\t  CFLAGS=\"$CFLAGS$lt_prog_compiler_no_builtin_flag\"\n\t  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_link\\\"\"; } >&5\n  (eval $ac_link) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && test -s conftest$ac_exeext; then\n\t    pipe_works=yes\n\t  fi\n\t  LIBS=$lt_globsym_save_LIBS\n\t  CFLAGS=$lt_globsym_save_CFLAGS\n\telse\n\t  echo \"cannot find nm_test_func in $nlist\" >&5\n\tfi\n      else\n\techo \"cannot find nm_test_var in $nlist\" >&5\n      fi\n    else\n      echo \"cannot run $lt_cv_sys_global_symbol_pipe\" >&5\n    fi\n  else\n    echo \"$progname: failed program was:\" >&5\n    cat conftest.$ac_ext >&5\n  fi\n  rm -rf conftest* conftst*\n\n  # Do not use the global_symbol_pipe unless it works.\n  if test yes = \"$pipe_works\"; then\n    break\n  else\n    lt_cv_sys_global_symbol_pipe=\n  fi\ndone\n ;;\nesac\nfi\n\nif test -z \"$lt_cv_sys_global_symbol_pipe\"; then\n  lt_cv_sys_global_symbol_to_cdecl=\nfi\nif test -z \"$lt_cv_sys_global_symbol_pipe$lt_cv_sys_global_symbol_to_cdecl\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: failed\" >&5\nprintf \"%s\\n\" \"failed\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: ok\" >&5\nprintf \"%s\\n\" \"ok\" >&6; }\nfi\n\n# Response file support.\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  nm_file_list_spec='@'\nelif $NM --help 2>/dev/null | grep '[@]FILE' >/dev/null; then\n  nm_file_list_spec='@'\nfi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for sysroot\" >&5\nprintf %s \"checking for sysroot... \" >&6; }\n\n# Check whether --with-sysroot was given.\nif test ${with_sysroot+y}\nthen :\n  withval=$with_sysroot;\nelse case e in #(\n  e) with_sysroot=no ;;\nesac\nfi\n\n\nlt_sysroot=\ncase $with_sysroot in #(\n yes)\n   if test yes = \"$GCC\"; then\n     lt_sysroot=`$CC --print-sysroot 2>/dev/null`\n   fi\n   ;; #(\n /*)\n   lt_sysroot=`echo \"$with_sysroot\" | $SED -e \"$sed_quote_subst\"`\n   ;; #(\n no|'')\n   ;; #(\n *)\n   { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $with_sysroot\" >&5\nprintf \"%s\\n\" \"$with_sysroot\" >&6; }\n   as_fn_error $? \"The sysroot must be an absolute path.\" \"$LINENO\" 5\n   ;;\nesac\n\n { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: ${lt_sysroot:-no}\" >&5\nprintf \"%s\\n\" \"${lt_sysroot:-no}\" >&6; }\n\n\n\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for a working dd\" >&5\nprintf %s \"checking for a working dd... \" >&6; }\nif test ${ac_cv_path_lt_DD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\n: ${lt_DD:=$DD}\nif test -z \"$lt_DD\"; then\n  ac_path_lt_DD_found=false\n  # Loop through the user's path and test for each of PROGNAME-LIST\n  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_prog in dd\n   do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      ac_path_lt_DD=\"$as_dir$ac_prog$ac_exec_ext\"\n      as_fn_executable_p \"$ac_path_lt_DD\" || continue\nif \"$ac_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && ac_cv_path_lt_DD=\"$ac_path_lt_DD\" ac_path_lt_DD_found=:\nfi\n      $ac_path_lt_DD_found && break 3\n    done\n  done\n  done\nIFS=$as_save_IFS\n  if test -z \"$ac_cv_path_lt_DD\"; then\n    :\n  fi\nelse\n  ac_cv_path_lt_DD=$lt_DD\nfi\n\nrm -f conftest.i conftest2.i conftest.out ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_path_lt_DD\" >&5\nprintf \"%s\\n\" \"$ac_cv_path_lt_DD\" >&6; }\n\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to truncate binary pipes\" >&5\nprintf %s \"checking how to truncate binary pipes... \" >&6; }\nif test ${lt_cv_truncate_bin+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\nlt_cv_truncate_bin=\nif \"$ac_cv_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && lt_cv_truncate_bin=\"$ac_cv_path_lt_DD bs=4096 count=1\"\nfi\nrm -f conftest.i conftest2.i conftest.out\ntest -z \"$lt_cv_truncate_bin\" && lt_cv_truncate_bin=\"$SED -e 4q\" ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_truncate_bin\" >&5\nprintf \"%s\\n\" \"$lt_cv_truncate_bin\" >&6; }\n\n\n\n\n\n\n\n# Calculate cc_basename.  Skip known compiler wrappers and cross-prefix.\nfunc_cc_basename ()\n{\n    for cc_temp in $*\"\"; do\n      case $cc_temp in\n        compile | *[\\\\/]compile | ccache | *[\\\\/]ccache ) ;;\n        distcc | *[\\\\/]distcc | purify | *[\\\\/]purify ) ;;\n        \\-*) ;;\n        *) break;;\n      esac\n    done\n    func_cc_basename_result=`$ECHO \"$cc_temp\" | $SED \"s%.*/%%; s%^$host_alias-%%\"`\n}\n\n# Check whether --enable-libtool-lock was given.\nif test ${enable_libtool_lock+y}\nthen :\n  enableval=$enable_libtool_lock;\nfi\n\ntest no = \"$enable_libtool_lock\" || enable_libtool_lock=yes\n\n# Some flags need to be propagated to the compiler or linker for good\n# libtool support.\ncase $host in\nia64-*-hpux*)\n  # Find out what ABI is being produced by ac_compile, and set mode\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    case `$FILECMD conftest.$ac_objext` in\n      *ELF-32*)\n\tHPUX_IA64_MODE=32\n\t;;\n      *ELF-64*)\n\tHPUX_IA64_MODE=64\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n*-*-irix6*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '#line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    if test yes = \"$lt_cv_prog_gnu_ld\"; then\n      case `$FILECMD conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -melf32bsmip\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -melf32bmipn32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -melf64bmip\"\n\t;;\n      esac\n    else\n      case `$FILECMD conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -32\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -n32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -64\"\n\t  ;;\n      esac\n    fi\n  fi\n  rm -rf conftest*\n  ;;\n\nmips64*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '#line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    emul=elf\n    case `$FILECMD conftest.$ac_objext` in\n      *32-bit*)\n\temul=\"${emul}32\"\n\t;;\n      *64-bit*)\n\temul=\"${emul}64\"\n\t;;\n    esac\n    case `$FILECMD conftest.$ac_objext` in\n      *MSB*)\n\temul=\"${emul}btsmip\"\n\t;;\n      *LSB*)\n\temul=\"${emul}ltsmip\"\n\t;;\n    esac\n    case `$FILECMD conftest.$ac_objext` in\n      *N32*)\n\temul=\"${emul}n32\"\n\t;;\n    esac\n    LD=\"${LD-ld} -m $emul\"\n  fi\n  rm -rf conftest*\n  ;;\n\nx86_64-*kfreebsd*-gnu|x86_64-*linux*|powerpc*-*linux*| \\\ns390*-*linux*|s390*-*tpf*|sparc*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.  Note that the listed cases only cover the\n  # situations where additional linker options are needed (such as when\n  # doing 32-bit compilation for a host where ld defaults to 64-bit, or\n  # vice versa); the common cases where no linker options are needed do\n  # not appear in the list.\n  echo 'int i;' > conftest.$ac_ext\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    case `$FILECMD conftest.o` in\n      *32-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_i386_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    case `$FILECMD conftest.o` in\n\t      *x86-64*)\n\t\tLD=\"${LD-ld} -m elf32_x86_64\"\n\t\t;;\n\t      *)\n\t\tLD=\"${LD-ld} -m elf_i386\"\n\t\t;;\n\t    esac\n\t    ;;\n\t  powerpc64le-*linux*)\n\t    LD=\"${LD-ld} -m elf32lppclinux\"\n\t    ;;\n\t  powerpc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32ppclinux\"\n\t    ;;\n\t  s390x-*linux*)\n\t    LD=\"${LD-ld} -m elf_s390\"\n\t    ;;\n\t  sparc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32_sparc\"\n\t    ;;\n\tesac\n\t;;\n      *64-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_x86_64_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    LD=\"${LD-ld} -m elf_x86_64\"\n\t    ;;\n\t  powerpcle-*linux*)\n\t    LD=\"${LD-ld} -m elf64lppc\"\n\t    ;;\n\t  powerpc-*linux*)\n\t    LD=\"${LD-ld} -m elf64ppc\"\n\t    ;;\n\t  s390*-*linux*|s390*-*tpf*)\n\t    LD=\"${LD-ld} -m elf64_s390\"\n\t    ;;\n\t  sparc*-*linux*)\n\t    LD=\"${LD-ld} -m elf64_sparc\"\n\t    ;;\n\tesac\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n\n*-*-sco3.2v5*)\n  # On SCO OpenServer 5, we need -belf to get full-featured binaries.\n  SAVE_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS -belf\"\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the C compiler needs -belf\" >&5\nprintf %s \"checking whether the C compiler needs -belf... \" >&6; }\nif test ${lt_cv_cc_needs_belf+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n     cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  lt_cv_cc_needs_belf=yes\nelse case e in #(\n  e) lt_cv_cc_needs_belf=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n     ac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_cc_needs_belf\" >&5\nprintf \"%s\\n\" \"$lt_cv_cc_needs_belf\" >&6; }\n  if test yes != \"$lt_cv_cc_needs_belf\"; then\n    # this is probably gcc 2.8.0, egcs 1.0 or newer; no need for -belf\n    CFLAGS=$SAVE_CFLAGS\n  fi\n  ;;\n*-*solaris*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }; then\n    case `$FILECMD conftest.o` in\n    *64-bit*)\n      case $lt_cv_prog_gnu_ld in\n      yes*)\n        case $host in\n        i?86-*-solaris*|x86_64-*-solaris*)\n          LD=\"${LD-ld} -m elf_x86_64\"\n          ;;\n        sparc*-*-solaris*)\n          LD=\"${LD-ld} -m elf64_sparc\"\n          ;;\n        esac\n        # GNU ld 2.21 introduced _sol2 emulations.  Use them if available.\n        if ${LD-ld} -V | grep _sol2 >/dev/null 2>&1; then\n          LD=${LD-ld}_sol2\n        fi\n        ;;\n      *)\n\tif ${LD-ld} -64 -r -o conftest2.o conftest.o >/dev/null 2>&1; then\n\t  LD=\"${LD-ld} -64\"\n\tfi\n\t;;\n      esac\n      ;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\nesac\n\nneed_locks=$enable_libtool_lock\n\nif test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}mt\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}mt; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_MANIFEST_TOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$MANIFEST_TOOL\"; then\n  ac_cv_prog_MANIFEST_TOOL=\"$MANIFEST_TOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_MANIFEST_TOOL=\"${ac_tool_prefix}mt\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nMANIFEST_TOOL=$ac_cv_prog_MANIFEST_TOOL\nif test -n \"$MANIFEST_TOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $MANIFEST_TOOL\" >&5\nprintf \"%s\\n\" \"$MANIFEST_TOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_MANIFEST_TOOL\"; then\n  ac_ct_MANIFEST_TOOL=$MANIFEST_TOOL\n  # Extract the first word of \"mt\", so it can be a program name with args.\nset dummy mt; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_MANIFEST_TOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_MANIFEST_TOOL\"; then\n  ac_cv_prog_ac_ct_MANIFEST_TOOL=\"$ac_ct_MANIFEST_TOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_MANIFEST_TOOL=\"mt\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_MANIFEST_TOOL=$ac_cv_prog_ac_ct_MANIFEST_TOOL\nif test -n \"$ac_ct_MANIFEST_TOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_MANIFEST_TOOL\" >&5\nprintf \"%s\\n\" \"$ac_ct_MANIFEST_TOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_MANIFEST_TOOL\" = x; then\n    MANIFEST_TOOL=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    MANIFEST_TOOL=$ac_ct_MANIFEST_TOOL\n  fi\nelse\n  MANIFEST_TOOL=\"$ac_cv_prog_MANIFEST_TOOL\"\nfi\n\ntest -z \"$MANIFEST_TOOL\" && MANIFEST_TOOL=mt\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $MANIFEST_TOOL is a manifest tool\" >&5\nprintf %s \"checking if $MANIFEST_TOOL is a manifest tool... \" >&6; }\nif test ${lt_cv_path_mainfest_tool+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_path_mainfest_tool=no\n  echo \"$as_me:$LINENO: $MANIFEST_TOOL '-?'\" >&5\n  $MANIFEST_TOOL '-?' 2>conftest.err > conftest.out\n  cat conftest.err >&5\n  if $GREP 'Manifest Tool' conftest.out > /dev/null; then\n    lt_cv_path_mainfest_tool=yes\n  fi\n  rm -f conftest* ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_path_mainfest_tool\" >&5\nprintf \"%s\\n\" \"$lt_cv_path_mainfest_tool\" >&6; }\nif test yes != \"$lt_cv_path_mainfest_tool\"; then\n  MANIFEST_TOOL=:\nfi\n\n\n\n\n\n\n  case $host_os in\n    rhapsody* | darwin*)\n    if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}dsymutil\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}dsymutil; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_DSYMUTIL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$DSYMUTIL\"; then\n  ac_cv_prog_DSYMUTIL=\"$DSYMUTIL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_DSYMUTIL=\"${ac_tool_prefix}dsymutil\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nDSYMUTIL=$ac_cv_prog_DSYMUTIL\nif test -n \"$DSYMUTIL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $DSYMUTIL\" >&5\nprintf \"%s\\n\" \"$DSYMUTIL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_DSYMUTIL\"; then\n  ac_ct_DSYMUTIL=$DSYMUTIL\n  # Extract the first word of \"dsymutil\", so it can be a program name with args.\nset dummy dsymutil; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_DSYMUTIL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_DSYMUTIL\"; then\n  ac_cv_prog_ac_ct_DSYMUTIL=\"$ac_ct_DSYMUTIL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_DSYMUTIL=\"dsymutil\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_DSYMUTIL=$ac_cv_prog_ac_ct_DSYMUTIL\nif test -n \"$ac_ct_DSYMUTIL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_DSYMUTIL\" >&5\nprintf \"%s\\n\" \"$ac_ct_DSYMUTIL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_DSYMUTIL\" = x; then\n    DSYMUTIL=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    DSYMUTIL=$ac_ct_DSYMUTIL\n  fi\nelse\n  DSYMUTIL=\"$ac_cv_prog_DSYMUTIL\"\nfi\n\n    if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}nmedit\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}nmedit; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_NMEDIT+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$NMEDIT\"; then\n  ac_cv_prog_NMEDIT=\"$NMEDIT\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_NMEDIT=\"${ac_tool_prefix}nmedit\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nNMEDIT=$ac_cv_prog_NMEDIT\nif test -n \"$NMEDIT\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $NMEDIT\" >&5\nprintf \"%s\\n\" \"$NMEDIT\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_NMEDIT\"; then\n  ac_ct_NMEDIT=$NMEDIT\n  # Extract the first word of \"nmedit\", so it can be a program name with args.\nset dummy nmedit; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_NMEDIT+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_NMEDIT\"; then\n  ac_cv_prog_ac_ct_NMEDIT=\"$ac_ct_NMEDIT\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_NMEDIT=\"nmedit\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_NMEDIT=$ac_cv_prog_ac_ct_NMEDIT\nif test -n \"$ac_ct_NMEDIT\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_NMEDIT\" >&5\nprintf \"%s\\n\" \"$ac_ct_NMEDIT\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_NMEDIT\" = x; then\n    NMEDIT=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    NMEDIT=$ac_ct_NMEDIT\n  fi\nelse\n  NMEDIT=\"$ac_cv_prog_NMEDIT\"\nfi\n\n    if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}lipo\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}lipo; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_LIPO+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$LIPO\"; then\n  ac_cv_prog_LIPO=\"$LIPO\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_LIPO=\"${ac_tool_prefix}lipo\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nLIPO=$ac_cv_prog_LIPO\nif test -n \"$LIPO\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $LIPO\" >&5\nprintf \"%s\\n\" \"$LIPO\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_LIPO\"; then\n  ac_ct_LIPO=$LIPO\n  # Extract the first word of \"lipo\", so it can be a program name with args.\nset dummy lipo; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_LIPO+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_LIPO\"; then\n  ac_cv_prog_ac_ct_LIPO=\"$ac_ct_LIPO\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_LIPO=\"lipo\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_LIPO=$ac_cv_prog_ac_ct_LIPO\nif test -n \"$ac_ct_LIPO\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_LIPO\" >&5\nprintf \"%s\\n\" \"$ac_ct_LIPO\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_LIPO\" = x; then\n    LIPO=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    LIPO=$ac_ct_LIPO\n  fi\nelse\n  LIPO=\"$ac_cv_prog_LIPO\"\nfi\n\n    if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}otool\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}otool; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_OTOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$OTOOL\"; then\n  ac_cv_prog_OTOOL=\"$OTOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_OTOOL=\"${ac_tool_prefix}otool\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nOTOOL=$ac_cv_prog_OTOOL\nif test -n \"$OTOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $OTOOL\" >&5\nprintf \"%s\\n\" \"$OTOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_OTOOL\"; then\n  ac_ct_OTOOL=$OTOOL\n  # Extract the first word of \"otool\", so it can be a program name with args.\nset dummy otool; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_OTOOL+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_OTOOL\"; then\n  ac_cv_prog_ac_ct_OTOOL=\"$ac_ct_OTOOL\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_OTOOL=\"otool\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_OTOOL=$ac_cv_prog_ac_ct_OTOOL\nif test -n \"$ac_ct_OTOOL\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_OTOOL\" >&5\nprintf \"%s\\n\" \"$ac_ct_OTOOL\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_OTOOL\" = x; then\n    OTOOL=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    OTOOL=$ac_ct_OTOOL\n  fi\nelse\n  OTOOL=\"$ac_cv_prog_OTOOL\"\nfi\n\n    if test -n \"$ac_tool_prefix\"; then\n  # Extract the first word of \"${ac_tool_prefix}otool64\", so it can be a program name with args.\nset dummy ${ac_tool_prefix}otool64; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_OTOOL64+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$OTOOL64\"; then\n  ac_cv_prog_OTOOL64=\"$OTOOL64\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_OTOOL64=\"${ac_tool_prefix}otool64\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nOTOOL64=$ac_cv_prog_OTOOL64\nif test -n \"$OTOOL64\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $OTOOL64\" >&5\nprintf \"%s\\n\" \"$OTOOL64\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\nfi\nif test -z \"$ac_cv_prog_OTOOL64\"; then\n  ac_ct_OTOOL64=$OTOOL64\n  # Extract the first word of \"otool64\", so it can be a program name with args.\nset dummy otool64; ac_word=$2\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $ac_word\" >&5\nprintf %s \"checking for $ac_word... \" >&6; }\nif test ${ac_cv_prog_ac_ct_OTOOL64+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -n \"$ac_ct_OTOOL64\"; then\n  ac_cv_prog_ac_ct_OTOOL64=\"$ac_ct_OTOOL64\" # Let the user override the test.\nelse\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  case $as_dir in #(((\n    '') as_dir=./ ;;\n    */) ;;\n    *) as_dir=$as_dir/ ;;\n  esac\n    for ac_exec_ext in '' $ac_executable_extensions; do\n  if as_fn_executable_p \"$as_dir$ac_word$ac_exec_ext\"; then\n    ac_cv_prog_ac_ct_OTOOL64=\"otool64\"\n    printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: found $as_dir$ac_word$ac_exec_ext\" >&5\n    break 2\n  fi\ndone\n  done\nIFS=$as_save_IFS\n\nfi ;;\nesac\nfi\nac_ct_OTOOL64=$ac_cv_prog_ac_ct_OTOOL64\nif test -n \"$ac_ct_OTOOL64\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_ct_OTOOL64\" >&5\nprintf \"%s\\n\" \"$ac_ct_OTOOL64\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n  if test \"x$ac_ct_OTOOL64\" = x; then\n    OTOOL64=\":\"\n  else\n    case $cross_compiling:$ac_tool_warned in\nyes:)\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: using cross tools not prefixed with host triplet\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: using cross tools not prefixed with host triplet\" >&2;}\nac_tool_warned=yes ;;\nesac\n    OTOOL64=$ac_ct_OTOOL64\n  fi\nelse\n  OTOOL64=\"$ac_cv_prog_OTOOL64\"\nfi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for -single_module linker flag\" >&5\nprintf %s \"checking for -single_module linker flag... \" >&6; }\nif test ${lt_cv_apple_cc_single_mod+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_apple_cc_single_mod=no\n      if test -z \"$LT_MULTI_MODULE\"; then\n\t# By default we will add the -single_module flag. You can override\n\t# by either setting the environment variable LT_MULTI_MODULE\n\t# non-empty at configure time, or by adding -multi_module to the\n\t# link flags.\n\trm -rf libconftest.dylib*\n\techo \"int foo(void){return 1;}\" > conftest.c\n\techo \"$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n-dynamiclib -Wl,-single_module conftest.c\" >&5\n\t$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n\t  -dynamiclib -Wl,-single_module conftest.c 2>conftest.err\n        _lt_result=$?\n\t# If there is a non-empty error log, and \"single_module\"\n\t# appears in it, assume the flag caused a linker warning\n        if test -s conftest.err && $GREP single_module conftest.err; then\n\t  cat conftest.err >&5\n\t# Otherwise, if the output was created with a 0 exit code from\n\t# the compiler, it worked.\n\telif test -f libconftest.dylib && test 0 = \"$_lt_result\"; then\n\t  lt_cv_apple_cc_single_mod=yes\n\telse\n\t  cat conftest.err >&5\n\tfi\n\trm -rf libconftest.dylib*\n\trm -f conftest.*\n      fi ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_apple_cc_single_mod\" >&5\nprintf \"%s\\n\" \"$lt_cv_apple_cc_single_mod\" >&6; }\n\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for -exported_symbols_list linker flag\" >&5\nprintf %s \"checking for -exported_symbols_list linker flag... \" >&6; }\nif test ${lt_cv_ld_exported_symbols_list+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_ld_exported_symbols_list=no\n      save_LDFLAGS=$LDFLAGS\n      echo \"_main\" > conftest.sym\n      LDFLAGS=\"$LDFLAGS -Wl,-exported_symbols_list,conftest.sym\"\n      cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  lt_cv_ld_exported_symbols_list=yes\nelse case e in #(\n  e) lt_cv_ld_exported_symbols_list=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n\tLDFLAGS=$save_LDFLAGS\n     ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_ld_exported_symbols_list\" >&5\nprintf \"%s\\n\" \"$lt_cv_ld_exported_symbols_list\" >&6; }\n\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for -force_load linker flag\" >&5\nprintf %s \"checking for -force_load linker flag... \" >&6; }\nif test ${lt_cv_ld_force_load+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_ld_force_load=no\n      cat > conftest.c << _LT_EOF\nint forced_loaded() { return 2;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS -c -o conftest.o conftest.c\" >&5\n      $LTCC $LTCFLAGS -c -o conftest.o conftest.c 2>&5\n      echo \"$AR $AR_FLAGS libconftest.a conftest.o\" >&5\n      $AR $AR_FLAGS libconftest.a conftest.o 2>&5\n      echo \"$RANLIB libconftest.a\" >&5\n      $RANLIB libconftest.a 2>&5\n      cat > conftest.c << _LT_EOF\nint main() { return 0;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a\" >&5\n      $LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a 2>conftest.err\n      _lt_result=$?\n      if test -s conftest.err && $GREP force_load conftest.err; then\n\tcat conftest.err >&5\n      elif test -f conftest && test 0 = \"$_lt_result\" && $GREP forced_load conftest >/dev/null 2>&1; then\n\tlt_cv_ld_force_load=yes\n      else\n\tcat conftest.err >&5\n      fi\n        rm -f conftest.err libconftest.a conftest conftest.c\n        rm -rf conftest.dSYM\n     ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_ld_force_load\" >&5\nprintf \"%s\\n\" \"$lt_cv_ld_force_load\" >&6; }\n    case $host_os in\n    rhapsody* | darwin1.[012])\n      _lt_dar_allow_undefined='$wl-undefined ${wl}suppress' ;;\n    darwin1.*)\n      _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n    darwin*)\n      case $MACOSX_DEPLOYMENT_TARGET,$host in\n        10.[012],*|,*powerpc*-darwin[5-8]*)\n          _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n        *)\n          _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n      esac\n    ;;\n  esac\n    if test yes = \"$lt_cv_apple_cc_single_mod\"; then\n      _lt_dar_single_mod='$single_module'\n    fi\n    if test yes = \"$lt_cv_ld_exported_symbols_list\"; then\n      _lt_dar_export_syms=' $wl-exported_symbols_list,$output_objdir/$libname-symbols.expsym'\n    else\n      _lt_dar_export_syms='~$NMEDIT -s $output_objdir/$libname-symbols.expsym $lib'\n    fi\n    if test : != \"$DSYMUTIL\" && test no = \"$lt_cv_ld_force_load\"; then\n      _lt_dsymutil='~$DSYMUTIL $lib || :'\n    else\n      _lt_dsymutil=\n    fi\n    ;;\n  esac\n\n# func_munge_path_list VARIABLE PATH\n# -----------------------------------\n# VARIABLE is name of variable containing _space_ separated list of\n# directories to be munged by the contents of PATH, which is string\n# having a format:\n# \"DIR[:DIR]:\"\n#       string \"DIR[ DIR]\" will be prepended to VARIABLE\n# \":DIR[:DIR]\"\n#       string \"DIR[ DIR]\" will be appended to VARIABLE\n# \"DIRP[:DIRP]::[DIRA:]DIRA\"\n#       string \"DIRP[ DIRP]\" will be prepended to VARIABLE and string\n#       \"DIRA[ DIRA]\" will be appended to VARIABLE\n# \"DIR[:DIR]\"\n#       VARIABLE will be replaced by \"DIR[ DIR]\"\nfunc_munge_path_list ()\n{\n    case x$2 in\n    x)\n        ;;\n    *:)\n        eval $1=\\\"`$ECHO $2 | $SED 's/:/ /g'` \\$$1\\\"\n        ;;\n    x:*)\n        eval $1=\\\"\\$$1 `$ECHO $2 | $SED 's/:/ /g'`\\\"\n        ;;\n    *::*)\n        eval $1=\\\"\\$$1\\ `$ECHO $2 | $SED -e 's/.*:://' -e 's/:/ /g'`\\\"\n        eval $1=\\\"`$ECHO $2 | $SED -e 's/::.*//' -e 's/:/ /g'`\\ \\$$1\\\"\n        ;;\n    *)\n        eval $1=\\\"`$ECHO $2 | $SED 's/:/ /g'`\\\"\n        ;;\n    esac\n}\n\nac_header= ac_cache=\nfor ac_item in $ac_header_c_list\ndo\n  if test $ac_cache; then\n    ac_fn_c_check_header_compile \"$LINENO\" $ac_header ac_cv_header_$ac_cache \"$ac_includes_default\"\n    if eval test \\\"x\\$ac_cv_header_$ac_cache\\\" = xyes; then\n      printf \"%s\\n\" \"#define $ac_item 1\" >> confdefs.h\n    fi\n    ac_header= ac_cache=\n  elif test $ac_header; then\n    ac_cache=$ac_item\n  else\n    ac_header=$ac_item\n  fi\ndone\n\n\n\n\n\n\n\n\nif test $ac_cv_header_stdlib_h = yes && test $ac_cv_header_string_h = yes\nthen :\n\nprintf \"%s\\n\" \"#define STDC_HEADERS 1\" >>confdefs.h\n\nfi\nac_fn_c_check_header_compile \"$LINENO\" \"dlfcn.h\" \"ac_cv_header_dlfcn_h\" \"$ac_includes_default\n\"\nif test \"x$ac_cv_header_dlfcn_h\" = xyes\nthen :\n  printf \"%s\\n\" \"#define HAVE_DLFCN_H 1\" >>confdefs.h\n\nfi\n\n\n\n\nfunc_stripname_cnf ()\n{\n  case $2 in\n  .*) func_stripname_result=`$ECHO \"$3\" | $SED \"s%^$1%%; s%\\\\\\\\$2\\$%%\"`;;\n  *)  func_stripname_result=`$ECHO \"$3\" | $SED \"s%^$1%%; s%$2\\$%%\"`;;\n  esac\n} # func_stripname_cnf\n\n\n\n\n\n# Set options\n\n\n\n        enable_dlopen=no\n\n\n  enable_win32_dll=no\n\n\n            # Check whether --enable-shared was given.\nif test ${enable_shared+y}\nthen :\n  enableval=$enable_shared; p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_shared=yes ;;\n    no) enable_shared=no ;;\n    *)\n      enable_shared=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_shared=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac\nelse case e in #(\n  e) enable_shared=yes ;;\nesac\nfi\n\n\n\n\n\n\n\n\n\n  # Check whether --enable-static was given.\nif test ${enable_static+y}\nthen :\n  enableval=$enable_static; p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_static=yes ;;\n    no) enable_static=no ;;\n    *)\n     enable_static=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_static=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac\nelse case e in #(\n  e) enable_static=yes ;;\nesac\nfi\n\n\n\n\n\n\n\n\n\n\n# Check whether --with-pic was given.\nif test ${with_pic+y}\nthen :\n  withval=$with_pic; lt_p=${PACKAGE-default}\n    case $withval in\n    yes|no) pic_mode=$withval ;;\n    *)\n      pic_mode=default\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for lt_pkg in $withval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$lt_pkg\" = \"X$lt_p\"; then\n\t  pic_mode=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac\nelse case e in #(\n  e) pic_mode=default ;;\nesac\nfi\n\n\n\n\n\n\n\n\n  # Check whether --enable-fast-install was given.\nif test ${enable_fast_install+y}\nthen :\n  enableval=$enable_fast_install; p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_fast_install=yes ;;\n    no) enable_fast_install=no ;;\n    *)\n      enable_fast_install=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_fast_install=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac\nelse case e in #(\n  e) enable_fast_install=yes ;;\nesac\nfi\n\n\n\n\n\n\n\n\n  shared_archive_member_spec=\ncase $host,$enable_shared in\npower*-*-aix[5-9]*,yes)\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking which variant of shared library versioning to provide\" >&5\nprintf %s \"checking which variant of shared library versioning to provide... \" >&6; }\n\n# Check whether --with-aix-soname was given.\nif test ${with_aix_soname+y}\nthen :\n  withval=$with_aix_soname; case $withval in\n    aix|svr4|both)\n      ;;\n    *)\n      as_fn_error $? \"Unknown argument to --with-aix-soname\" \"$LINENO\" 5\n      ;;\n    esac\n    lt_cv_with_aix_soname=$with_aix_soname\nelse case e in #(\n  e) if test ${lt_cv_with_aix_soname+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_with_aix_soname=aix ;;\nesac\nfi\n\n    with_aix_soname=$lt_cv_with_aix_soname ;;\nesac\nfi\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $with_aix_soname\" >&5\nprintf \"%s\\n\" \"$with_aix_soname\" >&6; }\n  if test aix != \"$with_aix_soname\"; then\n    # For the AIX way of multilib, we name the shared archive member\n    # based on the bitwidth used, traditionally 'shr.o' or 'shr_64.o',\n    # and 'shr.imp' or 'shr_64.imp', respectively, for the Import File.\n    # Even when GNU compilers ignore OBJECT_MODE but need '-maix64' flag,\n    # the AIX toolchain works better with OBJECT_MODE set (default 32).\n    if test 64 = \"${OBJECT_MODE-32}\"; then\n      shared_archive_member_spec=shr_64\n    else\n      shared_archive_member_spec=shr\n    fi\n  fi\n  ;;\n*)\n  with_aix_soname=aix\n  ;;\nesac\n\n\n\n\n\n\n\n\n\n\n# This can be used to rebuild libtool when needed\nLIBTOOL_DEPS=$ltmain\n\n# Always use our own libtool.\nLIBTOOL='$(SHELL) $(top_builddir)/libtool'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest -z \"$LN_S\" && LN_S=\"ln -s\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nif test -n \"${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for objdir\" >&5\nprintf %s \"checking for objdir... \" >&6; }\nif test ${lt_cv_objdir+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) rm -f .libs 2>/dev/null\nmkdir .libs 2>/dev/null\nif test -d .libs; then\n  lt_cv_objdir=.libs\nelse\n  # MS-DOS does not allow filenames that begin with a dot.\n  lt_cv_objdir=_libs\nfi\nrmdir .libs 2>/dev/null ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_objdir\" >&5\nprintf \"%s\\n\" \"$lt_cv_objdir\" >&6; }\nobjdir=$lt_cv_objdir\n\n\n\n\n\nprintf \"%s\\n\" \"#define LT_OBJDIR \\\"$lt_cv_objdir/\\\"\" >>confdefs.h\n\n\n\n\ncase $host_os in\naix3*)\n  # AIX sometimes has problems with the GCC collect2 program.  For some\n  # reason, if we set the COLLECT_NAMES environment variable, the problems\n  # vanish in a puff of smoke.\n  if test set != \"${COLLECT_NAMES+set}\"; then\n    COLLECT_NAMES=\n    export COLLECT_NAMES\n  fi\n  ;;\nesac\n\n# Global variables:\nofile=libtool\ncan_build_shared=yes\n\n# All known linkers require a '.a' archive for static linking (except MSVC and\n# ICC, which need '.lib').\nlibext=a\n\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\nold_CC=$CC\nold_CFLAGS=$CFLAGS\n\n# Set sane defaults for various variables\ntest -z \"$CC\" && CC=cc\ntest -z \"$LTCC\" && LTCC=$CC\ntest -z \"$LTCFLAGS\" && LTCFLAGS=$CFLAGS\ntest -z \"$LD\" && LD=ld\ntest -z \"$ac_objext\" && ac_objext=o\n\nfunc_cc_basename $compiler\ncc_basename=$func_cc_basename_result\n\n\n# Only perform the check for file, if the check method requires it\ntest -z \"$MAGIC_CMD\" && MAGIC_CMD=file\ncase $deplibs_check_method in\nfile_magic*)\n  if test \"$file_magic_cmd\" = '$MAGIC_CMD'; then\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for ${ac_tool_prefix}file\" >&5\nprintf %s \"checking for ${ac_tool_prefix}file... \" >&6; }\nif test ${lt_cv_path_MAGIC_CMD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) case $MAGIC_CMD in\n[\\\\/*] |  ?:[\\\\/]*)\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  ac_dummy=\"/usr/bin$PATH_SEPARATOR$PATH\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/${ac_tool_prefix}file\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"${ac_tool_prefix}file\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac ;;\nesac\nfi\n\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $MAGIC_CMD\" >&5\nprintf \"%s\\n\" \"$MAGIC_CMD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n\n\n\nif test -z \"$lt_cv_path_MAGIC_CMD\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for file\" >&5\nprintf %s \"checking for file... \" >&6; }\nif test ${lt_cv_path_MAGIC_CMD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) case $MAGIC_CMD in\n[\\\\/*] |  ?:[\\\\/]*)\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  ac_dummy=\"/usr/bin$PATH_SEPARATOR$PATH\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/file\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"file\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac ;;\nesac\nfi\n\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $MAGIC_CMD\" >&5\nprintf \"%s\\n\" \"$MAGIC_CMD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\n\n\n  else\n    MAGIC_CMD=:\n  fi\nfi\n\n  fi\n  ;;\nesac\n\n# Use C for the default configuration in the libtool script\n\nlt_save_CC=$CC\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\n\n# Source file extension for C test sources.\nac_ext=c\n\n# Object file extension for compiled C test sources.\nobjext=o\nobjext=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"int some_variable = 0;\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='int main(){return(0);}'\n\n\n\n\n\n\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n\n# Save the default compiler, since it gets overwritten when the other\n# tags are being tested, and _LT_TAGVAR(compiler, []) is a NOP.\ncompiler_DEFAULT=$CC\n\n# save warnings/boilerplate of simple test code\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n\nlt_prog_compiler_no_builtin_flag=\n\nif test yes = \"$GCC\"; then\n  case $cc_basename in\n  nvcc*)\n    lt_prog_compiler_no_builtin_flag=' -Xcompiler -fno-builtin' ;;\n  *)\n    lt_prog_compiler_no_builtin_flag=' -fno-builtin' ;;\n  esac\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $compiler supports -fno-rtti -fno-exceptions\" >&5\nprintf %s \"checking if $compiler supports -fno-rtti -fno-exceptions... \" >&6; }\nif test ${lt_cv_prog_compiler_rtti_exceptions+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_rtti_exceptions=no\n   ac_outfile=conftest.$ac_objext\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"-fno-rtti -fno-exceptions\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [^ ]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&5)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&5\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       lt_cv_prog_compiler_rtti_exceptions=yes\n     fi\n   fi\n   $RM conftest*\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_rtti_exceptions\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_rtti_exceptions\" >&6; }\n\nif test yes = \"$lt_cv_prog_compiler_rtti_exceptions\"; then\n    lt_prog_compiler_no_builtin_flag=\"$lt_prog_compiler_no_builtin_flag -fno-rtti -fno-exceptions\"\nelse\n    :\nfi\n\nfi\n\n\n\n\n\n\n  lt_prog_compiler_wl=\nlt_prog_compiler_pic=\nlt_prog_compiler_static=\n\n\n  if test yes = \"$GCC\"; then\n    lt_prog_compiler_wl='-Wl,'\n    lt_prog_compiler_static='-static'\n\n    case $host_os in\n      aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\tlt_prog_compiler_static='-Bstatic'\n      fi\n      lt_prog_compiler_pic='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            lt_prog_compiler_pic='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            lt_prog_compiler_pic='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      lt_prog_compiler_pic='-DDLL_EXPORT'\n      case $host_os in\n      os2*)\n\tlt_prog_compiler_static='$wl-static'\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      lt_prog_compiler_pic='-fno-common'\n      ;;\n\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      lt_prog_compiler_static=\n      ;;\n\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t# +Z the default\n\t;;\n      *)\n\tlt_prog_compiler_pic='-fPIC'\n\t;;\n      esac\n      ;;\n\n    interix[3-9]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n\n    msdosdjgpp*)\n      # Just because we use GCC doesn't mean we suddenly get shared libraries\n      # on systems that don't support them.\n      lt_prog_compiler_can_build_shared=no\n      enable_shared=no\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      lt_prog_compiler_pic='-fPIC -shared'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\tlt_prog_compiler_pic=-Kconform_pic\n      fi\n      ;;\n\n    *)\n      lt_prog_compiler_pic='-fPIC'\n      ;;\n    esac\n\n    case $cc_basename in\n    nvcc*) # Cuda Compiler Driver 2.2\n      lt_prog_compiler_wl='-Xlinker '\n      if test -n \"$lt_prog_compiler_pic\"; then\n        lt_prog_compiler_pic=\"-Xcompiler $lt_prog_compiler_pic\"\n      fi\n      ;;\n    esac\n  else\n    # PORTME Check for flag to pass linker flags through the system compiler.\n    case $host_os in\n    aix*)\n      lt_prog_compiler_wl='-Wl,'\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\tlt_prog_compiler_static='-Bstatic'\n      else\n\tlt_prog_compiler_static='-bnso -bI:/lib/syscalls.exp'\n      fi\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      lt_prog_compiler_pic='-fno-common'\n      case $cc_basename in\n      nagfor*)\n        # NAG Fortran compiler\n        lt_prog_compiler_wl='-Wl,-Wl,,'\n        lt_prog_compiler_pic='-PIC'\n        lt_prog_compiler_static='-Bstatic'\n        ;;\n      esac\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      lt_prog_compiler_pic='-DDLL_EXPORT'\n      case $host_os in\n      os2*)\n\tlt_prog_compiler_static='$wl-static'\n\t;;\n      esac\n      ;;\n\n    hpux9* | hpux10* | hpux11*)\n      lt_prog_compiler_wl='-Wl,'\n      # PIC is the default for IA64 HP-UX and 64-bit HP-UX, but\n      # not for PA HP-UX.\n      case $host_cpu in\n      hppa*64*|ia64*)\n\t# +Z the default\n\t;;\n      *)\n\tlt_prog_compiler_pic='+Z'\n\t;;\n      esac\n      # Is there a better lt_prog_compiler_static that works with the bundled CC?\n      lt_prog_compiler_static='$wl-a ${wl}archive'\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      lt_prog_compiler_wl='-Wl,'\n      # PIC (with -KPIC) is the default.\n      lt_prog_compiler_static='-non_shared'\n      ;;\n\n    linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n      case $cc_basename in\n      # old Intel for x86_64, which still supported -KPIC.\n      ecc*)\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-KPIC'\n\tlt_prog_compiler_static='-static'\n        ;;\n      # flang / f18. f95 an alias for gfortran or flang on Debian\n      flang* | f18* | f95*)\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-fPIC'\n\tlt_prog_compiler_static='-static'\n        ;;\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-fPIC'\n\tlt_prog_compiler_static='-static'\n        ;;\n      # Lahey Fortran 8.1.\n      lf95*)\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='--shared'\n\tlt_prog_compiler_static='--static'\n\t;;\n      nagfor*)\n\t# NAG Fortran compiler\n\tlt_prog_compiler_wl='-Wl,-Wl,,'\n\tlt_prog_compiler_pic='-PIC'\n\tlt_prog_compiler_static='-Bstatic'\n\t;;\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-fPIC'\n\tlt_prog_compiler_static='-static'\n\t;;\n      pgcc* | pgf77* | pgf90* | pgf95* | pgfortran*)\n        # Portland Group compilers (*not* the Pentium gcc compiler,\n\t# which looks to be a dead project)\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-fpic'\n\tlt_prog_compiler_static='-Bstatic'\n        ;;\n      ccc*)\n        lt_prog_compiler_wl='-Wl,'\n        # All Alpha code is PIC.\n        lt_prog_compiler_static='-non_shared'\n        ;;\n      xl* | bgxl* | bgf* | mpixl*)\n\t# IBM XL C 8.0/Fortran 10.1, 11.1 on PPC and BlueGene\n\tlt_prog_compiler_wl='-Wl,'\n\tlt_prog_compiler_pic='-qpic'\n\tlt_prog_compiler_static='-qstaticlink'\n\t;;\n      *)\n\tcase `$CC -V 2>&1 | $SED 5q` in\n\t*Sun\\ Ceres\\ Fortran* | *Sun*Fortran*\\ [1-7].* | *Sun*Fortran*\\ 8.[0-3]*)\n\t  # Sun Fortran 8.3 passes all unrecognized flags to the linker\n\t  lt_prog_compiler_pic='-KPIC'\n\t  lt_prog_compiler_static='-Bstatic'\n\t  lt_prog_compiler_wl=''\n\t  ;;\n\t*Sun\\ F* | *Sun*Fortran*)\n\t  lt_prog_compiler_pic='-KPIC'\n\t  lt_prog_compiler_static='-Bstatic'\n\t  lt_prog_compiler_wl='-Qoption ld '\n\t  ;;\n\t*Sun\\ C*)\n\t  # Sun C 5.9\n\t  lt_prog_compiler_pic='-KPIC'\n\t  lt_prog_compiler_static='-Bstatic'\n\t  lt_prog_compiler_wl='-Wl,'\n\t  ;;\n        *Intel*\\ [CF]*Compiler*)\n\t  lt_prog_compiler_wl='-Wl,'\n\t  lt_prog_compiler_pic='-fPIC'\n\t  lt_prog_compiler_static='-static'\n\t  ;;\n\t*Portland\\ Group*)\n\t  lt_prog_compiler_wl='-Wl,'\n\t  lt_prog_compiler_pic='-fpic'\n\t  lt_prog_compiler_static='-Bstatic'\n\t  ;;\n\tesac\n\t;;\n      esac\n      ;;\n\n    newsos6)\n      lt_prog_compiler_pic='-KPIC'\n      lt_prog_compiler_static='-Bstatic'\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      lt_prog_compiler_pic='-fPIC -shared'\n      ;;\n\n    osf3* | osf4* | osf5*)\n      lt_prog_compiler_wl='-Wl,'\n      # All OSF/1 code is PIC.\n      lt_prog_compiler_static='-non_shared'\n      ;;\n\n    rdos*)\n      lt_prog_compiler_static='-non_shared'\n      ;;\n\n    solaris*)\n      lt_prog_compiler_pic='-KPIC'\n      lt_prog_compiler_static='-Bstatic'\n      case $cc_basename in\n      f77* | f90* | f95* | sunf77* | sunf90* | sunf95*)\n\tlt_prog_compiler_wl='-Qoption ld ';;\n      *)\n\tlt_prog_compiler_wl='-Wl,';;\n      esac\n      ;;\n\n    sunos4*)\n      lt_prog_compiler_wl='-Qoption ld '\n      lt_prog_compiler_pic='-PIC'\n      lt_prog_compiler_static='-Bstatic'\n      ;;\n\n    sysv4 | sysv4.2uw2* | sysv4.3*)\n      lt_prog_compiler_wl='-Wl,'\n      lt_prog_compiler_pic='-KPIC'\n      lt_prog_compiler_static='-Bstatic'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\tlt_prog_compiler_pic='-Kconform_pic'\n\tlt_prog_compiler_static='-Bstatic'\n      fi\n      ;;\n\n    sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n      lt_prog_compiler_wl='-Wl,'\n      lt_prog_compiler_pic='-KPIC'\n      lt_prog_compiler_static='-Bstatic'\n      ;;\n\n    unicos*)\n      lt_prog_compiler_wl='-Wl,'\n      lt_prog_compiler_can_build_shared=no\n      ;;\n\n    uts4*)\n      lt_prog_compiler_pic='-pic'\n      lt_prog_compiler_static='-Bstatic'\n      ;;\n\n    *)\n      lt_prog_compiler_can_build_shared=no\n      ;;\n    esac\n  fi\n\ncase $host_os in\n  # For platforms that do not support PIC, -DPIC is meaningless:\n  *djgpp*)\n    lt_prog_compiler_pic=\n    ;;\n  *)\n    lt_prog_compiler_pic=\"$lt_prog_compiler_pic -DPIC\"\n    ;;\nesac\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for $compiler option to produce PIC\" >&5\nprintf %s \"checking for $compiler option to produce PIC... \" >&6; }\nif test ${lt_cv_prog_compiler_pic+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_pic=$lt_prog_compiler_pic ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_pic\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_pic\" >&6; }\nlt_prog_compiler_pic=$lt_cv_prog_compiler_pic\n\n#\n# Check to make sure the PIC flag actually works.\n#\nif test -n \"$lt_prog_compiler_pic\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $compiler PIC flag $lt_prog_compiler_pic works\" >&5\nprintf %s \"checking if $compiler PIC flag $lt_prog_compiler_pic works... \" >&6; }\nif test ${lt_cv_prog_compiler_pic_works+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_pic_works=no\n   ac_outfile=conftest.$ac_objext\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"$lt_prog_compiler_pic -DPIC\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [^ ]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&5)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&5\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       lt_cv_prog_compiler_pic_works=yes\n     fi\n   fi\n   $RM conftest*\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_pic_works\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_pic_works\" >&6; }\n\nif test yes = \"$lt_cv_prog_compiler_pic_works\"; then\n    case $lt_prog_compiler_pic in\n     \"\" | \" \"*) ;;\n     *) lt_prog_compiler_pic=\" $lt_prog_compiler_pic\" ;;\n     esac\nelse\n    lt_prog_compiler_pic=\n     lt_prog_compiler_can_build_shared=no\nfi\n\nfi\n\n\n\n\n\n\n\n\n\n\n\n#\n# Check to make sure the static flag actually works.\n#\nwl=$lt_prog_compiler_wl eval lt_tmp_static_flag=\\\"$lt_prog_compiler_static\\\"\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $compiler static flag $lt_tmp_static_flag works\" >&5\nprintf %s \"checking if $compiler static flag $lt_tmp_static_flag works... \" >&6; }\nif test ${lt_cv_prog_compiler_static_works+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_static_works=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS $lt_tmp_static_flag\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&5\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         lt_cv_prog_compiler_static_works=yes\n       fi\n     else\n       lt_cv_prog_compiler_static_works=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_static_works\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_static_works\" >&6; }\n\nif test yes = \"$lt_cv_prog_compiler_static_works\"; then\n    :\nelse\n    lt_prog_compiler_static=\nfi\n\n\n\n\n\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $compiler supports -c -o file.$ac_objext\" >&5\nprintf %s \"checking if $compiler supports -c -o file.$ac_objext... \" >&6; }\nif test ${lt_cv_prog_compiler_c_o+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_c_o=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [^ ]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&5)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&5\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       lt_cv_prog_compiler_c_o=yes\n     fi\n   fi\n   chmod u+w . 2>&5\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_c_o\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_c_o\" >&6; }\n\n\n\n\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $compiler supports -c -o file.$ac_objext\" >&5\nprintf %s \"checking if $compiler supports -c -o file.$ac_objext... \" >&6; }\nif test ${lt_cv_prog_compiler_c_o+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler_c_o=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [^ ]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&5)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&5\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&5\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       lt_cv_prog_compiler_c_o=yes\n     fi\n   fi\n   chmod u+w . 2>&5\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler_c_o\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler_c_o\" >&6; }\n\n\n\n\nhard_links=nottested\nif test no = \"$lt_cv_prog_compiler_c_o\" && test no != \"$need_locks\"; then\n  # do not overwrite the value of need_locks provided by the user\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if we can lock with hard links\" >&5\nprintf %s \"checking if we can lock with hard links... \" >&6; }\n  hard_links=yes\n  $RM conftest*\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  touch conftest.a\n  ln conftest.a conftest.b 2>&5 || hard_links=no\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $hard_links\" >&5\nprintf \"%s\\n\" \"$hard_links\" >&6; }\n  if test no = \"$hard_links\"; then\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: WARNING: '$CC' does not support '-c -o', so 'make -j' may be unsafe\" >&5\nprintf \"%s\\n\" \"$as_me: WARNING: '$CC' does not support '-c -o', so 'make -j' may be unsafe\" >&2;}\n    need_locks=warn\n  fi\nelse\n  need_locks=no\nfi\n\n\n\n\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the $compiler linker ($LD) supports shared libraries\" >&5\nprintf %s \"checking whether the $compiler linker ($LD) supports shared libraries... \" >&6; }\n\n  runpath_var=\n  allow_undefined_flag=\n  always_export_symbols=no\n  archive_cmds=\n  archive_expsym_cmds=\n  compiler_needs_object=no\n  enable_shared_with_static_runtimes=no\n  export_dynamic_flag_spec=\n  export_symbols_cmds='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  hardcode_automatic=no\n  hardcode_direct=no\n  hardcode_direct_absolute=no\n  hardcode_libdir_flag_spec=\n  hardcode_libdir_separator=\n  hardcode_minus_L=no\n  hardcode_shlibpath_var=unsupported\n  inherit_rpath=no\n  link_all_deplibs=unknown\n  module_cmds=\n  module_expsym_cmds=\n  old_archive_from_new_cmds=\n  old_archive_from_expsyms_cmds=\n  thread_safe_flag_spec=\n  whole_archive_flag_spec=\n  # include_expsyms should be a list of space-separated symbols to be *always*\n  # included in the symbol list\n  include_expsyms=\n  # exclude_expsyms can be an extended regexp of symbols to exclude\n  # it will be wrapped by ' (' and ')$', so one must not match beginning or\n  # end of line.  Example: 'a|bc|.*d.*' will exclude the symbols 'a' and 'bc',\n  # as well as any symbol that contains 'd'.\n  exclude_expsyms='_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*'\n  # Although _GLOBAL_OFFSET_TABLE_ is a valid symbol C name, most a.out\n  # platforms (ab)use it in PIC code, but their linkers get confused if\n  # the symbol is explicitly referenced.  Since portable code cannot\n  # rely on this symbol name, it's probably fine to never include it in\n  # preloaded symbol tables.\n  # Exclude shared library initialization/finalization symbols.\n  extract_expsyms_cmds=\n\n  case $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    # FIXME: the MSVC++ and ICC port hasn't been tested in a loooong time\n    # When not using gcc, we currently assume that we are using\n    # Microsoft Visual C++ or Intel C++ Compiler.\n    if test yes != \"$GCC\"; then\n      with_gnu_ld=no\n    fi\n    ;;\n  interix*)\n    # we just hope/assume this is gcc and not c89 (= MSVC++ or ICC)\n    with_gnu_ld=yes\n    ;;\n  openbsd* | bitrig*)\n    with_gnu_ld=no\n    ;;\n  linux* | k*bsd*-gnu | gnu*)\n    link_all_deplibs=no\n    ;;\n  esac\n\n  ld_shlibs=yes\n\n  # On some targets, GNU ld is compatible enough with the native linker\n  # that we're better off using the native interface for both.\n  lt_use_gnu_ld_interface=no\n  if test yes = \"$with_gnu_ld\"; then\n    case $host_os in\n      aix*)\n\t# The AIX port of GNU ld has always aspired to compatibility\n\t# with the native linker.  However, as the warning in the GNU ld\n\t# block says, versions before 2.19.5* couldn't really create working\n\t# shared libraries, regardless of the interface used.\n\tcase `$LD -v 2>&1` in\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.19.5*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.[2-9]*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ [3-9]*) ;;\n\t  *)\n\t    lt_use_gnu_ld_interface=yes\n\t    ;;\n\tesac\n\t;;\n      *)\n\tlt_use_gnu_ld_interface=yes\n\t;;\n    esac\n  fi\n\n  if test yes = \"$lt_use_gnu_ld_interface\"; then\n    # If archive_cmds runs LD, not CC, wlarc should be empty\n    wlarc='$wl'\n\n    # Set some defaults for GNU ld with shared library support. These\n    # are reset later if shared libraries are not supported. Putting them\n    # here allows them to be overridden if necessary.\n    runpath_var=LD_RUN_PATH\n    hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n    export_dynamic_flag_spec='$wl--export-dynamic'\n    # ancient GNU ld didn't support --whole-archive et. al.\n    if $LD --help 2>&1 | $GREP 'no-whole-archive' > /dev/null; then\n      whole_archive_flag_spec=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n    else\n      whole_archive_flag_spec=\n    fi\n    supports_anon_versioning=no\n    case `$LD -v | $SED -e 's/([^)]\\+)\\s\\+//' 2>&1` in\n      *GNU\\ gold*) supports_anon_versioning=yes ;;\n      *\\ [01].* | *\\ 2.[0-9].* | *\\ 2.10.*) ;; # catch versions < 2.11\n      *\\ 2.11.93.0.2\\ *) supports_anon_versioning=yes ;; # RH7.3 ...\n      *\\ 2.11.92.0.12\\ *) supports_anon_versioning=yes ;; # Mandrake 8.2 ...\n      *\\ 2.11.*) ;; # other 2.11 versions\n      *) supports_anon_versioning=yes ;;\n    esac\n\n    # See if GNU ld supports shared libraries.\n    case $host_os in\n    aix[3-9]*)\n      # On AIX/PPC, the GNU linker is very broken\n      if test ia64 != \"$host_cpu\"; then\n\tld_shlibs=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: the GNU linker, at least up to release 2.19, is reported\n*** to be unable to reliably create shared libraries on AIX.\n*** Therefore, libtool is disabling shared libraries support.  If you\n*** really care for shared libraries, you may want to install binutils\n*** 2.20 or above, or modify your PATH so that a non-GNU linker is found.\n*** You will then need to restart the configuration process.\n\n_LT_EOF\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            archive_cmds='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            archive_expsym_cmds=''\n        ;;\n      m68k)\n            archive_cmds='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            hardcode_libdir_flag_spec='-L$libdir'\n            hardcode_minus_L=yes\n        ;;\n      esac\n      ;;\n\n    beos*)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\tallow_undefined_flag=unsupported\n\t# Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t# support --undefined.  This deserves some investigation.  FIXME\n\tarchive_cmds='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      else\n\tld_shlibs=no\n      fi\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # _LT_TAGVAR(hardcode_libdir_flag_spec, ) is actually meaningless,\n      # as there is no search path for DLLs.\n      hardcode_libdir_flag_spec='-L$libdir'\n      export_dynamic_flag_spec='$wl--export-all-symbols'\n      allow_undefined_flag=unsupported\n      always_export_symbols=no\n      enable_shared_with_static_runtimes=yes\n      export_symbols_cmds='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[BCDGRS][ ]/s/.*[ ]\\([^ ]*\\)/\\1 DATA/;s/^.*[ ]__nm__\\([^ ]*\\)[ ][^ ]*/\\1 DATA/;/^I[ ]/d;/^[AITW][ ]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      exclude_expsyms='[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname'\n\n      if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n        archive_cmds='$CC -shared $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t# If the export-symbols file already is a .def file, use it as\n\t# is; otherwise, prepend EXPORTS...\n\tarchive_expsym_cmds='if   test DEF = \"`$SED -n     -e '\\''s/^[\t ]*//'\\''     -e '\\''/^\\(;.*\\)*$/d'\\''     -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p'\\''     -e q     $export_symbols`\" ; then\n          cp $export_symbols $output_objdir/$soname.def;\n        else\n          echo EXPORTS > $output_objdir/$soname.def;\n          cat $export_symbols >> $output_objdir/$soname.def;\n        fi~\n        $CC -shared $output_objdir/$soname.def $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n      else\n\tld_shlibs=no\n      fi\n      ;;\n\n    haiku*)\n      archive_cmds='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      link_all_deplibs=yes\n      ;;\n\n    os2*)\n      hardcode_libdir_flag_spec='-L$libdir'\n      hardcode_minus_L=yes\n      allow_undefined_flag=unsupported\n      shrext_cmds=.dll\n      archive_cmds='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      archive_expsym_cmds='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      old_archive_From_new_cmds='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      enable_shared_with_static_runtimes=yes\n      file_list_spec='@'\n      ;;\n\n    interix[3-9]*)\n      hardcode_direct=no\n      hardcode_shlibpath_var=no\n      hardcode_libdir_flag_spec='$wl-rpath,$libdir'\n      export_dynamic_flag_spec='$wl-E'\n      # Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n      # Instead, shared libraries are loaded at an image base (0x10000000 by\n      # default) and relocated if they conflict, which is a slow very memory\n      # consuming and fragmenting process.  To avoid this, we pick a random,\n      # 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n      # time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n      archive_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      archive_expsym_cmds='$SED \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      ;;\n\n    gnu* | linux* | tpf* | k*bsd*-gnu | kopensolaris*-gnu)\n      tmp_diet=no\n      if test linux-dietlibc = \"$host_os\"; then\n\tcase $cc_basename in\n\t  diet\\ *) tmp_diet=yes;;\t# linux-dietlibc with static linking (!diet-dyn)\n\tesac\n      fi\n      if $LD --help 2>&1 | $EGREP ': supported targets:.* elf' > /dev/null \\\n\t && test no = \"$tmp_diet\"\n      then\n\ttmp_addflag=' $pic_flag'\n\ttmp_sharedflag='-shared'\n\tcase $cc_basename,$host_cpu in\n        pgcc*)\t\t\t\t# Portland Group C compiler\n\t  whole_archive_flag_spec='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag'\n\t  ;;\n\tpgf77* | pgf90* | pgf95* | pgfortran*)\n\t\t\t\t\t# Portland Group f77 and f90 compilers\n\t  whole_archive_flag_spec='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag -Mnomain' ;;\n\tecc*,ia64* | icc*,ia64*)\t# Intel C compiler on ia64\n\t  tmp_addflag=' -i_dynamic' ;;\n\tefc*,ia64* | ifort*,ia64*)\t# Intel Fortran compiler on ia64\n\t  tmp_addflag=' -i_dynamic -nofor_main' ;;\n\tifc* | ifort*)\t\t\t# Intel Fortran compiler\n\t  tmp_addflag=' -nofor_main' ;;\n\tlf95*)\t\t\t\t# Lahey Fortran 8.1\n\t  whole_archive_flag_spec=\n\t  tmp_sharedflag='--shared' ;;\n        nagfor*)                        # NAGFOR 5.3\n          tmp_sharedflag='-Wl,-shared' ;;\n\txl[cC]* | bgxl[cC]* | mpixl[cC]*) # IBM XL C 8.0 on PPC (deal with xlf below)\n\t  tmp_sharedflag='-qmkshrobj'\n\t  tmp_addflag= ;;\n\tnvcc*)\t# Cuda Compiler Driver 2.2\n\t  whole_archive_flag_spec='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  compiler_needs_object=yes\n\t  ;;\n\tesac\n\tcase `$CC -V 2>&1 | $SED 5q` in\n\t*Sun\\ C*)\t\t\t# Sun C 5.9\n\t  whole_archive_flag_spec='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  compiler_needs_object=yes\n\t  tmp_sharedflag='-G' ;;\n\t*Sun\\ F*)\t\t\t# Sun Fortran 8.3\n\t  tmp_sharedflag='-G' ;;\n\tesac\n\tarchive_cmds='$CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\n        if test yes = \"$supports_anon_versioning\"; then\n          archive_expsym_cmds='echo \"{ global:\" > $output_objdir/$libname.ver~\n            cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n            echo \"local: *; };\" >> $output_objdir/$libname.ver~\n            $CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n        fi\n\n\tcase $cc_basename in\n\ttcc*)\n\t  hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n\t  export_dynamic_flag_spec='-rdynamic'\n\t  ;;\n\txlf* | bgf* | bgxlf* | mpixlf*)\n\t  # IBM XL Fortran 10.1 on PPC cannot create shared libs itself\n\t  whole_archive_flag_spec='--whole-archive$convenience --no-whole-archive'\n\t  hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n\t  archive_cmds='$LD -shared $libobjs $deplibs $linker_flags -soname $soname -o $lib'\n\t  if test yes = \"$supports_anon_versioning\"; then\n\t    archive_expsym_cmds='echo \"{ global:\" > $output_objdir/$libname.ver~\n              cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n              echo \"local: *; };\" >> $output_objdir/$libname.ver~\n              $LD -shared $libobjs $deplibs $linker_flags -soname $soname -version-script $output_objdir/$libname.ver -o $lib'\n\t  fi\n\t  ;;\n\tesac\n      else\n        ld_shlibs=no\n      fi\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\tarchive_cmds='$LD -Bshareable $libobjs $deplibs $linker_flags -o $lib'\n\twlarc=\n      else\n\tarchive_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\tarchive_expsym_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      fi\n      ;;\n\n    solaris*)\n      if $LD -v 2>&1 | $GREP 'BFD 2\\.8' > /dev/null; then\n\tld_shlibs=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: The releases 2.8.* of the GNU linker cannot reliably\n*** create shared libraries on Solaris systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.9.1 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n      elif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\tarchive_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\tarchive_expsym_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\tld_shlibs=no\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX*)\n      case `$LD -v 2>&1` in\n        *\\ [01].* | *\\ 2.[0-9].* | *\\ 2.1[0-5].*)\n\tld_shlibs=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: Releases of the GNU linker prior to 2.16.91.0.3 cannot\n*** reliably create shared libraries on SCO systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.16.91.0.3 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n\t;;\n\t*)\n\t  # For security reasons, it is highly recommended that you always\n\t  # use absolute paths for naming shared libraries, and exclude the\n\t  # DT_RUNPATH tag from executables and libraries.  But doing so\n\t  # requires that you compile everything twice, which is a pain.\n\t  if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t    hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n\t    archive_cmds='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    archive_expsym_cmds='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t  else\n\t    ld_shlibs=no\n\t  fi\n\t;;\n      esac\n      ;;\n\n    sunos4*)\n      archive_cmds='$LD -assert pure-text -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      wlarc=\n      hardcode_direct=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    *)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\tarchive_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\tarchive_expsym_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\tld_shlibs=no\n      fi\n      ;;\n    esac\n\n    if test no = \"$ld_shlibs\"; then\n      runpath_var=\n      hardcode_libdir_flag_spec=\n      export_dynamic_flag_spec=\n      whole_archive_flag_spec=\n    fi\n  else\n    # PORTME fill in a description of your system's linker (not GNU ld)\n    case $host_os in\n    aix3*)\n      allow_undefined_flag=unsupported\n      always_export_symbols=yes\n      archive_expsym_cmds='$LD -o $output_objdir/$soname $libobjs $deplibs $linker_flags -bE:$export_symbols -T512 -H512 -bM:SRE~$AR $AR_FLAGS $lib $output_objdir/$soname'\n      # Note: this linker hardcodes the directories in LIBPATH if there\n      # are no directories specified by -L.\n      hardcode_minus_L=yes\n      if test yes = \"$GCC\" && test -z \"$lt_prog_compiler_static\"; then\n\t# Neither direct hardcoding nor static linking is supported with a\n\t# broken collect2.\n\thardcode_direct=unsupported\n      fi\n      ;;\n\n    aix[4-9]*)\n      if test ia64 = \"$host_cpu\"; then\n\t# On IA64, the linker does run time linking by default, so we don't\n\t# have to do anything special.\n\taix_use_runtimelinking=no\n\texp_sym_flag='-Bexport'\n\tno_entry_flag=\n      else\n\t# If we're using GNU nm, then we don't want the \"-C\" option.\n\t# -C means demangle to GNU nm, but means don't demangle to AIX nm.\n\t# Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n\t# weak defined symbols like other global defined symbols, whereas\n\t# GNU nm marks them as \"W\".\n\t# While the 'weak' keyword is ignored in the Export File, we need\n\t# it in the Import File for the 'aix-soname' feature, so we have\n\t# to replace the \"-B\" option with \"-P\" for AIX nm.\n\tif $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n\t  export_symbols_cmds='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && (substr(\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n\telse\n\t  export_symbols_cmds='`func_echo_all $NM | $SED -e '\\''s/B\\([^B]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"L\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && (substr(\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n\tfi\n\taix_use_runtimelinking=no\n\n\t# Test if we are trying to use run time linking or normal\n\t# AIX style linking. If -brtl is somewhere in LDFLAGS, we\n\t# have runtime linking enabled, and use it for executables.\n\t# For shared libraries, we enable/disable runtime linking\n\t# depending on the kind of the shared library created -\n\t# when \"with_aix_soname,aix_use_runtimelinking\" is:\n\t# \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\t# \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n\t#            lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a(lib.so.V) shared, rtl:no\n\t# \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\tcase $host_os in aix4.[23]|aix4.[23].*|aix[5-9]*)\n\t  for ld_flag in $LDFLAGS; do\n\t  if (test x-brtl = \"x$ld_flag\" || test x-Wl,-brtl = \"x$ld_flag\"); then\n\t    aix_use_runtimelinking=yes\n\t    break\n\t  fi\n\t  done\n\t  if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t    # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t    # so we don't have lib.a shared libs to link our executables.\n\t    # We have to force runtime linking in this case.\n\t    aix_use_runtimelinking=yes\n\t    LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t  fi\n\t  ;;\n\tesac\n\n\texp_sym_flag='-bexport'\n\tno_entry_flag='-bnoentry'\n      fi\n\n      # When large executables or shared objects are built, AIX ld can\n      # have problems creating the table of contents.  If linking a library\n      # or program results in \"error TOC overflow\" add -mminimal-toc to\n      # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n      # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n      archive_cmds=''\n      hardcode_direct=yes\n      hardcode_direct_absolute=yes\n      hardcode_libdir_separator=':'\n      link_all_deplibs=yes\n      file_list_spec='$wl-f,'\n      case $with_aix_soname,$aix_use_runtimelinking in\n      aix,*) ;; # traditional, no import file\n      svr4,* | *,yes) # use import file\n\t# The Import File defines what to hardcode.\n\thardcode_direct=no\n\thardcode_direct_absolute=no\n\t;;\n      esac\n\n      if test yes = \"$GCC\"; then\n\tcase $host_os in aix4.[012]|aix4.[012].*)\n\t# We only want to do this on AIX 4.2 and lower, the check\n\t# below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t   strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t  # We have reworked collect2\n\t  :\n\t  else\n\t  # We have old collect2\n\t  hardcode_direct=unsupported\n\t  # It fails to find uninstalled libraries when the uninstalled\n\t  # path is not listed in the libpath.  Setting hardcode_minus_L\n\t  # to unsupported forces relinking\n\t  hardcode_minus_L=yes\n\t  hardcode_libdir_flag_spec='-L$libdir'\n\t  hardcode_libdir_separator=\n\t  fi\n\t  ;;\n\tesac\n\tshared_flag='-shared'\n\tif test yes = \"$aix_use_runtimelinking\"; then\n\t  shared_flag=\"$shared_flag \"'$wl-G'\n\tfi\n\t# Need to ensure runtime linking is disabled for the traditional\n\t# shared library, or the linker may eventually find shared libraries\n\t# /with/ Import File - we do not want to mix them.\n\tshared_flag_aix='-shared'\n\tshared_flag_svr4='-shared $wl-G'\n      else\n\t# not using gcc\n\tif test ia64 = \"$host_cpu\"; then\n\t# VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t# chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n\telse\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag='$wl-G'\n\t  else\n\t    shared_flag='$wl-bM:SRE'\n\t  fi\n\t  shared_flag_aix='$wl-bM:SRE'\n\t  shared_flag_svr4='$wl-G'\n\tfi\n      fi\n\n      export_dynamic_flag_spec='$wl-bexpall'\n      # It seems that -bexpall does not export symbols beginning with\n      # underscore (_), so it is better to generate a list of symbols to export.\n      always_export_symbols=yes\n      if test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t# Warning - without using the other runtime loading flags (-brtl),\n\t# -berok will link without error, but may produce a broken library.\n\tallow_undefined_flag='-berok'\n        # Determine the default libpath from the value encoded in an\n        # empty executable.\n        if test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  if test ${lt_cv_aix_libpath_+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n\n  lt_aix_libpath_sed='\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }'\n  lt_cv_aix_libpath_=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$lt_cv_aix_libpath_\"; then\n    lt_cv_aix_libpath_=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n  if test -z \"$lt_cv_aix_libpath_\"; then\n    lt_cv_aix_libpath_=/usr/lib:/lib\n  fi\n   ;;\nesac\nfi\n\n  aix_libpath=$lt_cv_aix_libpath_\nfi\n\n        hardcode_libdir_flag_spec='$wl-blibpath:$libdir:'\"$aix_libpath\"\n        archive_expsym_cmds='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n      else\n\tif test ia64 = \"$host_cpu\"; then\n\t  hardcode_libdir_flag_spec='$wl-R $libdir:/usr/lib:/lib'\n\t  allow_undefined_flag=\"-z nodefs\"\n\t  archive_expsym_cmds=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n\telse\n\t # Determine the default libpath from the value encoded in an\n\t # empty executable.\n\t if test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  if test ${lt_cv_aix_libpath_+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n\n  lt_aix_libpath_sed='\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }'\n  lt_cv_aix_libpath_=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$lt_cv_aix_libpath_\"; then\n    lt_cv_aix_libpath_=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n  if test -z \"$lt_cv_aix_libpath_\"; then\n    lt_cv_aix_libpath_=/usr/lib:/lib\n  fi\n   ;;\nesac\nfi\n\n  aix_libpath=$lt_cv_aix_libpath_\nfi\n\n\t hardcode_libdir_flag_spec='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t  # Warning - without using the other run time loading flags,\n\t  # -berok will link without error, but may produce a broken library.\n\t  no_undefined_flag=' $wl-bernotok'\n\t  allow_undefined_flag=' $wl-berok'\n\t  if test yes = \"$with_gnu_ld\"; then\n\t    # We only use this code for GNU lds that support --whole-archive.\n\t    whole_archive_flag_spec='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t  else\n\t    # Exported symbols can be pulled into shared objects from archives\n\t    whole_archive_flag_spec='$convenience'\n\t  fi\n\t  archive_cmds_need_lc=yes\n\t  archive_expsym_cmds='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t  # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t  compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([, ]\\\\)%-berok\\\\1%g\"`'\n\t  if test svr4 != \"$with_aix_soname\"; then\n\t    # This is similar to how AIX traditionally builds its shared libraries.\n\t    archive_expsym_cmds=\"$archive_expsym_cmds\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t  fi\n\t  if test aix != \"$with_aix_soname\"; then\n\t    archive_expsym_cmds=\"$archive_expsym_cmds\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t  else\n\t    # used by -dlpreopen to get the symbols\n\t    archive_expsym_cmds=\"$archive_expsym_cmds\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t  fi\n\t  archive_expsym_cmds=\"$archive_expsym_cmds\"'~$RM -r $output_objdir/$realname.d'\n\tfi\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            archive_cmds='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            archive_expsym_cmds=''\n        ;;\n      m68k)\n            archive_cmds='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            hardcode_libdir_flag_spec='-L$libdir'\n            hardcode_minus_L=yes\n        ;;\n      esac\n      ;;\n\n    bsdi[45]*)\n      export_dynamic_flag_spec=-rdynamic\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # When not using gcc, we currently assume that we are using\n      # Microsoft Visual C++ or Intel C++ Compiler.\n      # hardcode_libdir_flag_spec is actually meaningless, as there is\n      # no search path for DLLs.\n      case $cc_basename in\n      cl* | icl*)\n\t# Native MSVC or ICC\n\thardcode_libdir_flag_spec=' '\n\tallow_undefined_flag=unsupported\n\talways_export_symbols=yes\n\tfile_list_spec='@'\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\tarchive_cmds='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\tarchive_expsym_cmds='if   test DEF = \"`$SED -n     -e '\\''s/^[\t ]*//'\\''     -e '\\''/^\\(;.*\\)*$/d'\\''     -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p'\\''     -e q     $export_symbols`\" ; then\n            cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n            echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n          else\n            $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n          fi~\n          $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n          linknames='\n\t# The linker will not automatically build a static lib if we build a DLL.\n\t# _LT_TAGVAR(old_archive_from_new_cmds, )='true'\n\tenable_shared_with_static_runtimes=yes\n\texclude_expsyms='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n\texport_symbols_cmds='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[BCDGRS][ ]/s/.*[ ]\\([^ ]*\\)/\\1,DATA/'\\'' | $SED -e '\\''/^[AITW][ ]/s/.*[ ]//'\\'' | sort | uniq > $export_symbols'\n\t# Don't use ranlib\n\told_postinstall_cmds='chmod 644 $oldlib'\n\tpostlink_cmds='lt_outputfile=\"@OUTPUT@\"~\n          lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n          case $lt_outputfile in\n            *.exe|*.EXE) ;;\n            *)\n              lt_outputfile=$lt_outputfile.exe\n              lt_tool_outputfile=$lt_tool_outputfile.exe\n              ;;\n          esac~\n          if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n            $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n            $RM \"$lt_outputfile.manifest\";\n          fi'\n\t;;\n      *)\n\t# Assume MSVC and ICC wrapper\n\thardcode_libdir_flag_spec=' '\n\tallow_undefined_flag=unsupported\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\tarchive_cmds='$CC -o $lib $libobjs $compiler_flags `func_echo_all \"$deplibs\" | $SED '\\''s/ -lc$//'\\''` -link -dll~linknames='\n\t# The linker will automatically build a .lib file if we build a DLL.\n\told_archive_from_new_cmds='true'\n\t# FIXME: Should let the user specify the lib program.\n\told_archive_cmds='lib -OUT:$oldlib$oldobjs$old_deplibs'\n\tenable_shared_with_static_runtimes=yes\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n\n\n  archive_cmds_need_lc=no\n  hardcode_direct=no\n  hardcode_automatic=yes\n  hardcode_shlibpath_var=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    whole_archive_flag_spec='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n\n  else\n    whole_archive_flag_spec=''\n  fi\n  link_all_deplibs=yes\n  allow_undefined_flag=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    archive_cmds=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    module_cmds=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    archive_expsym_cmds=\"$SED 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    module_expsym_cmds=\"$SED -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n\n  else\n  ld_shlibs=no\n  fi\n\n      ;;\n\n    dgux*)\n      archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      hardcode_libdir_flag_spec='-L$libdir'\n      hardcode_shlibpath_var=no\n      ;;\n\n    # FreeBSD 2.2.[012] allows us to include c++rt0.o to get C++ constructor\n    # support.  Future versions do this automatically, but an explicit c++rt0.o\n    # does not break anything, and helps significantly (at the cost of a little\n    # extra space).\n    freebsd2.2*)\n      archive_cmds='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags /usr/lib/c++rt0.o'\n      hardcode_libdir_flag_spec='-R$libdir'\n      hardcode_direct=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    # Unfortunately, older versions of FreeBSD 2 do not have this feature.\n    freebsd2.*)\n      archive_cmds='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      hardcode_direct=yes\n      hardcode_minus_L=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    # FreeBSD 3 and greater uses gcc -shared to do shared libraries.\n    freebsd* | dragonfly* | midnightbsd*)\n      archive_cmds='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n      hardcode_libdir_flag_spec='-R$libdir'\n      hardcode_direct=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    hpux9*)\n      if test yes = \"$GCC\"; then\n\tarchive_cmds='$RM $output_objdir/$soname~$CC -shared $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $libobjs $deplibs $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      else\n\tarchive_cmds='$RM $output_objdir/$soname~$LD -b +b $install_libdir -o $output_objdir/$soname $libobjs $deplibs $linker_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      fi\n      hardcode_libdir_flag_spec='$wl+b $wl$libdir'\n      hardcode_libdir_separator=:\n      hardcode_direct=yes\n\n      # hardcode_minus_L: Not really in the search PATH,\n      # but as the default location of the library.\n      hardcode_minus_L=yes\n      export_dynamic_flag_spec='$wl-E'\n      ;;\n\n    hpux10*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tarchive_cmds='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\tarchive_cmds='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\thardcode_libdir_flag_spec='$wl+b $wl$libdir'\n\thardcode_libdir_separator=:\n\thardcode_direct=yes\n\thardcode_direct_absolute=yes\n\texport_dynamic_flag_spec='$wl-E'\n\t# hardcode_minus_L: Not really in the search PATH,\n\t# but as the default location of the library.\n\thardcode_minus_L=yes\n      fi\n      ;;\n\n    hpux11*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tcase $host_cpu in\n\thppa*64*)\n\t  archive_cmds='$CC -shared $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  archive_cmds='$CC -shared $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  archive_cmds='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tesac\n      else\n\tcase $host_cpu in\n\thppa*64*)\n\t  archive_cmds='$CC -b $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  archive_cmds='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\n\t  # Older versions of the 11.00 compiler do not understand -b yet\n\t  # (HP92453-01 A.11.01.20 doesn't, HP92453-01 B.11.X.35175-35176.GP does)\n\t  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if $CC understands -b\" >&5\nprintf %s \"checking if $CC understands -b... \" >&6; }\nif test ${lt_cv_prog_compiler__b+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_prog_compiler__b=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS -b\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&5\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         lt_cv_prog_compiler__b=yes\n       fi\n     else\n       lt_cv_prog_compiler__b=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_compiler__b\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_compiler__b\" >&6; }\n\nif test yes = \"$lt_cv_prog_compiler__b\"; then\n    archive_cmds='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\nelse\n    archive_cmds='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\nfi\n\n\t  ;;\n\tesac\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\thardcode_libdir_flag_spec='$wl+b $wl$libdir'\n\thardcode_libdir_separator=:\n\n\tcase $host_cpu in\n\thppa*64*|ia64*)\n\t  hardcode_direct=no\n\t  hardcode_shlibpath_var=no\n\t  ;;\n\t*)\n\t  hardcode_direct=yes\n\t  hardcode_direct_absolute=yes\n\t  export_dynamic_flag_spec='$wl-E'\n\n\t  # hardcode_minus_L: Not really in the search PATH,\n\t  # but as the default location of the library.\n\t  hardcode_minus_L=yes\n\t  ;;\n\tesac\n      fi\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      if test yes = \"$GCC\"; then\n\tarchive_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t# Try to use the -exported_symbol ld option, if it does not\n\t# work, assume that -exports_file does not work either and\n\t# implicitly export all symbols.\n\t# This should be the same for all languages, so no per-tag cache variable.\n\t{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the $host_os linker accepts -exported_symbol\" >&5\nprintf %s \"checking whether the $host_os linker accepts -exported_symbol... \" >&6; }\nif test ${lt_cv_irix_exported_symbol+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) save_LDFLAGS=$LDFLAGS\n\t   LDFLAGS=\"$LDFLAGS -shared $wl-exported_symbol ${wl}foo $wl-update_registry $wl/dev/null\"\n\t   cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\nint foo (void) { return 0; }\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  lt_cv_irix_exported_symbol=yes\nelse case e in #(\n  e) lt_cv_irix_exported_symbol=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n           LDFLAGS=$save_LDFLAGS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_irix_exported_symbol\" >&5\nprintf \"%s\\n\" \"$lt_cv_irix_exported_symbol\" >&6; }\n\tif test yes = \"$lt_cv_irix_exported_symbol\"; then\n          archive_expsym_cmds='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations $wl-exports_file $wl$export_symbols -o $lib'\n\tfi\n\tlink_all_deplibs=no\n      else\n\tarchive_cmds='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\tarchive_expsym_cmds='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -exports_file $export_symbols -o $lib'\n      fi\n      archive_cmds_need_lc='no'\n      hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n      hardcode_libdir_separator=:\n      inherit_rpath=yes\n      link_all_deplibs=yes\n      ;;\n\n    linux*)\n      case $cc_basename in\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\tld_shlibs=yes\n\tarchive_cmds='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\thardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n\t;;\n      esac\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\tarchive_cmds='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'  # a.out\n      else\n\tarchive_cmds='$LD -shared -o $lib $libobjs $deplibs $linker_flags'      # ELF\n      fi\n      hardcode_libdir_flag_spec='-R$libdir'\n      hardcode_direct=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    newsos6)\n      archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      hardcode_direct=yes\n      hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n      hardcode_libdir_separator=:\n      hardcode_shlibpath_var=no\n      ;;\n\n    *nto* | *qnx*)\n      ;;\n\n    openbsd* | bitrig*)\n      if test -f /usr/libexec/ld.so; then\n\thardcode_direct=yes\n\thardcode_shlibpath_var=no\n\thardcode_direct_absolute=yes\n\tif test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n\t  archive_cmds='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  archive_expsym_cmds='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags $wl-retain-symbols-file,$export_symbols'\n\t  hardcode_libdir_flag_spec='$wl-rpath,$libdir'\n\t  export_dynamic_flag_spec='$wl-E'\n\telse\n\t  archive_cmds='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  hardcode_libdir_flag_spec='$wl-rpath,$libdir'\n\tfi\n      else\n\tld_shlibs=no\n      fi\n      ;;\n\n    os2*)\n      hardcode_libdir_flag_spec='-L$libdir'\n      hardcode_minus_L=yes\n      allow_undefined_flag=unsupported\n      shrext_cmds=.dll\n      archive_cmds='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      archive_expsym_cmds='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      old_archive_From_new_cmds='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      enable_shared_with_static_runtimes=yes\n      file_list_spec='@'\n      ;;\n\n    osf3*)\n      if test yes = \"$GCC\"; then\n\tallow_undefined_flag=' $wl-expect_unresolved $wl\\*'\n\tarchive_cmds='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n      else\n\tallow_undefined_flag=' -expect_unresolved \\*'\n\tarchive_cmds='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n      fi\n      archive_cmds_need_lc='no'\n      hardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n      hardcode_libdir_separator=:\n      ;;\n\n    osf4* | osf5*)\t# as osf3* with the addition of -msym flag\n      if test yes = \"$GCC\"; then\n\tallow_undefined_flag=' $wl-expect_unresolved $wl\\*'\n\tarchive_cmds='$CC -shared$allow_undefined_flag $pic_flag $libobjs $deplibs $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\thardcode_libdir_flag_spec='$wl-rpath $wl$libdir'\n      else\n\tallow_undefined_flag=' -expect_unresolved \\*'\n\tarchive_cmds='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\tarchive_expsym_cmds='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done; printf \"%s\\\\n\" \"-hidden\">> $lib.exp~\n          $CC -shared$allow_undefined_flag $wl-input $wl$lib.exp $compiler_flags $libobjs $deplibs -soname $soname `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~$RM $lib.exp'\n\n\t# Both c and cxx compiler support -rpath directly\n\thardcode_libdir_flag_spec='-rpath $libdir'\n      fi\n      archive_cmds_need_lc='no'\n      hardcode_libdir_separator=:\n      ;;\n\n    solaris*)\n      no_undefined_flag=' -z defs'\n      if test yes = \"$GCC\"; then\n\twlarc='$wl'\n\tarchive_cmds='$CC -shared $pic_flag $wl-z ${wl}text $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\tarchive_expsym_cmds='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n          $CC -shared $pic_flag $wl-z ${wl}text $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n      else\n\tcase `$CC -V 2>&1` in\n\t*\"Compilers 5.0\"*)\n\t  wlarc=''\n\t  archive_cmds='$LD -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  archive_expsym_cmds='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $LD -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $linker_flags~$RM $lib.exp'\n\t  ;;\n\t*)\n\t  wlarc='$wl'\n\t  archive_cmds='$CC -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  archive_expsym_cmds='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $CC -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n\t  ;;\n\tesac\n      fi\n      hardcode_libdir_flag_spec='-R$libdir'\n      hardcode_shlibpath_var=no\n      case $host_os in\n      solaris2.[0-5] | solaris2.[0-5].*) ;;\n      *)\n\t# The compiler driver will combine and reorder linker options,\n\t# but understands '-z linker_flag'.  GCC discards it without '$wl',\n\t# but is careful enough not to reorder.\n\t# Supported since Solaris 2.6 (maybe 2.5.1?)\n\tif test yes = \"$GCC\"; then\n\t  whole_archive_flag_spec='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\telse\n\t  whole_archive_flag_spec='-z allextract$convenience -z defaultextract'\n\tfi\n\t;;\n      esac\n      link_all_deplibs=yes\n      ;;\n\n    sunos4*)\n      if test sequent = \"$host_vendor\"; then\n\t# Use $CC to link under sequent, because it throws in some extra .o\n\t# files that make .init and .fini sections work.\n\tarchive_cmds='$CC -G $wl-h $soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\tarchive_cmds='$LD -assert pure-text -Bstatic -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      hardcode_libdir_flag_spec='-L$libdir'\n      hardcode_direct=yes\n      hardcode_minus_L=yes\n      hardcode_shlibpath_var=no\n      ;;\n\n    sysv4)\n      case $host_vendor in\n\tsni)\n\t  archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  hardcode_direct=yes # is this really true???\n\t;;\n\tsiemens)\n\t  ## LD is ld it makes a PLAMLIB\n\t  ## CC just makes a GrossModule.\n\t  archive_cmds='$LD -G -o $lib $libobjs $deplibs $linker_flags'\n\t  reload_cmds='$CC -r -o $output$reload_objs'\n\t  hardcode_direct=no\n        ;;\n\tmotorola)\n\t  archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  hardcode_direct=no #Motorola manual says yes, but my tests say they lie\n\t;;\n      esac\n      runpath_var='LD_RUN_PATH'\n      hardcode_shlibpath_var=no\n      ;;\n\n    sysv4.3*)\n      archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      hardcode_shlibpath_var=no\n      export_dynamic_flag_spec='-Bexport'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\tarchive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\thardcode_shlibpath_var=no\n\trunpath_var=LD_RUN_PATH\n\thardcode_runpath_var=yes\n\tld_shlibs=yes\n      fi\n      ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[01].[10]* | unixware7* | sco3.2v5.0.[024]*)\n      no_undefined_flag='$wl-z,text'\n      archive_cmds_need_lc=no\n      hardcode_shlibpath_var=no\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\tarchive_cmds='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\tarchive_expsym_cmds='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\tarchive_cmds='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\tarchive_expsym_cmds='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6*)\n      # Note: We CANNOT use -z defs as we might desire, because we do not\n      # link with -lc, and that would cause any symbols used from libc to\n      # always be unresolved, which means just about no library would\n      # ever link correctly.  If we're not using GNU ld we use -z text\n      # though, which does catch some bad symbols but isn't as heavy-handed\n      # as -z defs.\n      no_undefined_flag='$wl-z,text'\n      allow_undefined_flag='$wl-z,nodefs'\n      archive_cmds_need_lc=no\n      hardcode_shlibpath_var=no\n      hardcode_libdir_flag_spec='$wl-R,$libdir'\n      hardcode_libdir_separator=':'\n      link_all_deplibs=yes\n      export_dynamic_flag_spec='$wl-Bexport'\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\tarchive_cmds='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\tarchive_expsym_cmds='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\tarchive_cmds='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\tarchive_expsym_cmds='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    uts4*)\n      archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      hardcode_libdir_flag_spec='-L$libdir'\n      hardcode_shlibpath_var=no\n      ;;\n\n    *)\n      ld_shlibs=no\n      ;;\n    esac\n\n    if test sni = \"$host_vendor\"; then\n      case $host in\n      sysv4 | sysv4.2uw2* | sysv4.3* | sysv5*)\n\texport_dynamic_flag_spec='$wl-Blargedynsym'\n\t;;\n      esac\n    fi\n  fi\n\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ld_shlibs\" >&5\nprintf \"%s\\n\" \"$ld_shlibs\" >&6; }\ntest no = \"$ld_shlibs\" && can_build_shared=no\n\nwith_gnu_ld=$with_gnu_ld\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\n# Do we need to explicitly link libc?\n#\ncase \"x$archive_cmds_need_lc\" in\nx|xyes)\n  # Assume -lc should be added\n  archive_cmds_need_lc=yes\n\n  if test yes,yes = \"$GCC,$enable_shared\"; then\n    case $archive_cmds in\n    *'~'*)\n      # FIXME: we may have to deal with multi-command sequences.\n      ;;\n    '$CC '*)\n      # Test whether the compiler implicitly links with -lc since on some\n      # systems, -lgcc has to come before -lc. If gcc already passes -lc\n      # to ld, don't add -lc before -lgcc.\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether -lc should be explicitly linked in\" >&5\nprintf %s \"checking whether -lc should be explicitly linked in... \" >&6; }\nif test ${lt_cv_archive_cmds_need_lc+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) $RM conftest*\n\techo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n\tif { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_compile\\\"\"; } >&5\n  (eval $ac_compile) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } 2>conftest.err; then\n\t  soname=conftest\n\t  lib=conftest\n\t  libobjs=conftest.$ac_objext\n\t  deplibs=\n\t  wl=$lt_prog_compiler_wl\n\t  pic_flag=$lt_prog_compiler_pic\n\t  compiler_flags=-v\n\t  linker_flags=-v\n\t  verstring=\n\t  output_objdir=.\n\t  libname=conftest\n\t  lt_save_allow_undefined_flag=$allow_undefined_flag\n\t  allow_undefined_flag=\n\t  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$archive_cmds 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1\\\"\"; } >&5\n  (eval $archive_cmds 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; }\n\t  then\n\t    lt_cv_archive_cmds_need_lc=no\n\t  else\n\t    lt_cv_archive_cmds_need_lc=yes\n\t  fi\n\t  allow_undefined_flag=$lt_save_allow_undefined_flag\n\telse\n\t  cat conftest.err 1>&5\n\tfi\n\t$RM conftest*\n\t ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_archive_cmds_need_lc\" >&5\nprintf \"%s\\n\" \"$lt_cv_archive_cmds_need_lc\" >&6; }\n      archive_cmds_need_lc=$lt_cv_archive_cmds_need_lc\n      ;;\n    esac\n  fi\n  ;;\nesac\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking dynamic linker characteristics\" >&5\nprintf %s \"checking dynamic linker characteristics... \" >&6; }\n\nif test yes = \"$GCC\"; then\n  case $host_os in\n    darwin*) lt_awk_arg='/^libraries:/,/LR/' ;;\n    *) lt_awk_arg='/^libraries:/' ;;\n  esac\n  case $host_os in\n    mingw* | cegcc*) lt_sed_strip_eq='s|=\\([A-Za-z]:\\)|\\1|g' ;;\n    *) lt_sed_strip_eq='s|=/|/|g' ;;\n  esac\n  lt_search_path_spec=`$CC -print-search-dirs | awk $lt_awk_arg | $SED -e \"s/^libraries://\" -e $lt_sed_strip_eq`\n  case $lt_search_path_spec in\n  *\\;*)\n    # if the path contains \";\" then we assume it to be the separator\n    # otherwise default to the standard path separator (i.e. \":\") - it is\n    # assumed that no part of a normal pathname contains \";\" but that should\n    # okay in the real world where \";\" in dirpaths is itself problematic.\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED 's/;/ /g'`\n    ;;\n  *)\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED \"s/$PATH_SEPARATOR/ /g\"`\n    ;;\n  esac\n  # Ok, now we have the path, separated by spaces, we can step through it\n  # and add multilib dir if necessary...\n  lt_tmp_lt_search_path_spec=\n  lt_multi_os_dir=/`$CC $CPPFLAGS $CFLAGS $LDFLAGS -print-multi-os-directory 2>/dev/null`\n  # ...but if some path component already ends with the multilib dir we assume\n  # that all is fine and trust -print-search-dirs as is (GCC 4.2? or newer).\n  case \"$lt_multi_os_dir; $lt_search_path_spec \" in\n  \"/; \"* | \"/.; \"* | \"/./; \"* | *\"$lt_multi_os_dir \"* | *\"$lt_multi_os_dir/ \"*)\n    lt_multi_os_dir=\n    ;;\n  esac\n  for lt_sys_path in $lt_search_path_spec; do\n    if test -d \"$lt_sys_path$lt_multi_os_dir\"; then\n      lt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path$lt_multi_os_dir\"\n    elif test -n \"$lt_multi_os_dir\"; then\n      test -d \"$lt_sys_path\" && \\\n\tlt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path\"\n    fi\n  done\n  lt_search_path_spec=`$ECHO \"$lt_tmp_lt_search_path_spec\" | awk '\nBEGIN {RS = \" \"; FS = \"/|\\n\";} {\n  lt_foo = \"\";\n  lt_count = 0;\n  for (lt_i = NF; lt_i > 0; lt_i--) {\n    if ($lt_i != \"\" && $lt_i != \".\") {\n      if ($lt_i == \"..\") {\n        lt_count++;\n      } else {\n        if (lt_count == 0) {\n          lt_foo = \"/\" $lt_i lt_foo;\n        } else {\n          lt_count--;\n        }\n      }\n    }\n  }\n  if (lt_foo != \"\") { lt_freq[lt_foo]++; }\n  if (lt_freq[lt_foo] == 1) { print lt_foo; }\n}'`\n  # AWK program above erroneously prepends '/' to C:/dos/paths\n  # for these hosts.\n  case $host_os in\n    mingw* | cegcc*) lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" |\\\n      $SED 's|/\\([A-Za-z]:\\)|\\1|g'` ;;\n  esac\n  sys_lib_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $lt_NL2SP`\nelse\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\nfi\nlibrary_names_spec=\nlibname_spec='lib$name'\nsoname_spec=\nshrext_cmds=.so\npostinstall_cmds=\npostuninstall_cmds=\nfinish_cmds=\nfinish_eval=\nshlibpath_var=\nshlibpath_overrides_runpath=unknown\nversion_type=none\ndynamic_linker=\"$host_os ld.so\"\nsys_lib_dlsearch_path_spec=\"/lib /usr/lib\"\nneed_lib_prefix=unknown\nhardcode_into_libs=no\n\n# when you set need_version to no, make sure it does not cause -set_version\n# flags to be left without arguments\nneed_version=unknown\n\n\n\ncase $host_os in\naix3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname.a'\n  shlibpath_var=LIBPATH\n\n  # AIX 3 has no versioning support, so we append a major version to the name.\n  soname_spec='$libname$release$shared_ext$major'\n  ;;\n\naix[4-9]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  hardcode_into_libs=yes\n  if test ia64 = \"$host_cpu\"; then\n    # AIX 5 supports IA64\n    library_names_spec='$libname$release$shared_ext$major $libname$release$shared_ext$versuffix $libname$shared_ext'\n    shlibpath_var=LD_LIBRARY_PATH\n  else\n    # With GCC up to 2.95.x, collect2 would create an import file\n    # for dependence libraries.  The import file would start with\n    # the line '#! .'.  This would cause the generated library to\n    # depend on '.', always an invalid library.  This was fixed in\n    # development snapshots of GCC prior to 3.0.\n    case $host_os in\n      aix4 | aix4.[01] | aix4.[01].*)\n      if { echo '#if __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 97)'\n\t   echo ' yes '\n\t   echo '#endif'; } | $CC -E - | $GREP yes > /dev/null; then\n\t:\n      else\n\tcan_build_shared=no\n      fi\n      ;;\n    esac\n    # Using Import Files as archive members, it is possible to support\n    # filename-based versioning of shared library archives on AIX. While\n    # this would work for both with and without runtime linking, it will\n    # prevent static linking of such archives. So we do filename-based\n    # shared library versioning with .so extension only, which is used\n    # when both runtime linking and shared linking is enabled.\n    # Unfortunately, runtime linking may impact performance, so we do\n    # not want this to be the default eventually. Also, we use the\n    # versioned .so libs for executables only if there is the -brtl\n    # linker flag in LDFLAGS as well, or --with-aix-soname=svr4 only.\n    # To allow for filename-based versioning support, we need to create\n    # libNAME.so.V as an archive file, containing:\n    # *) an Import File, referring to the versioned filename of the\n    #    archive as well as the shared archive member, telling the\n    #    bitwidth (32 or 64) of that shared object, and providing the\n    #    list of exported symbols of that shared object, eventually\n    #    decorated with the 'weak' keyword\n    # *) the shared object with the F_LOADONLY flag set, to really avoid\n    #    it being seen by the linker.\n    # At run time we better use the real file rather than another symlink,\n    # but for link time we create the symlink libNAME.so -> libNAME.so.V\n\n    case $with_aix_soname,$aix_use_runtimelinking in\n    # AIX (on Power*) has no versioning support, so currently we cannot hardcode correct\n    # soname into executable. Probably we can add versioning support to\n    # collect2, so additional links can be useful in future.\n    aix,yes) # traditional libtool\n      dynamic_linker='AIX unversionable lib.so'\n      # If using run time linking (on AIX 4.2 or later) use lib<name>.so\n      # instead of lib<name>.a to let people know that these are not\n      # typical AIX shared libraries.\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      ;;\n    aix,no) # traditional AIX only\n      dynamic_linker='AIX lib.a(lib.so.V)'\n      # We preserve .a as extension for shared libraries through AIX4.2\n      # and later when we are not doing run time linking.\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      ;;\n    svr4,*) # full svr4 only\n      dynamic_linker=\"AIX lib.so.V($shared_archive_member_spec.o)\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,yes) # both, prefer svr4\n      dynamic_linker=\"AIX lib.so.V($shared_archive_member_spec.o), lib.a(lib.so.V)\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # unpreferred sharedlib libNAME.a needs extra handling\n      postinstall_cmds='test -n \"$linkname\" || linkname=\"$realname\"~func_stripname \"\" \".so\" \"$linkname\"~$install_shared_prog \"$dir/$func_stripname_result.$libext\" \"$destdir/$func_stripname_result.$libext\"~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib \"$destdir/$func_stripname_result.$libext\"'\n      postuninstall_cmds='for n in $library_names $old_library; do :; done~func_stripname \"\" \".so\" \"$n\"~test \"$func_stripname_result\" = \"$n\" || func_append rmfiles \" $odir/$func_stripname_result.$libext\"'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,no) # both, prefer aix\n      dynamic_linker=\"AIX lib.a(lib.so.V), lib.so.V($shared_archive_member_spec.o)\"\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      # unpreferred sharedlib libNAME.so.V and symlink libNAME.so need extra handling\n      postinstall_cmds='test -z \"$dlname\" || $install_shared_prog $dir/$dlname $destdir/$dlname~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib $destdir/$dlname~test -n \"$linkname\" || linkname=$realname~func_stripname \"\" \".a\" \"$linkname\"~(cd \"$destdir\" && $LN_S -f $dlname $func_stripname_result.so)'\n      postuninstall_cmds='test -z \"$dlname\" || func_append rmfiles \" $odir/$dlname\"~for n in $old_library $library_names; do :; done~func_stripname \"\" \".a\" \"$n\"~func_append rmfiles \" $odir/$func_stripname_result.so\"'\n      ;;\n    esac\n    shlibpath_var=LIBPATH\n  fi\n  ;;\n\namigaos*)\n  case $host_cpu in\n  powerpc)\n    # Since July 2007 AmigaOS4 officially supports .so libraries.\n    # When compiling the executable, add -use-dynld -Lsobjs: to the compileline.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    ;;\n  m68k)\n    library_names_spec='$libname.ixlibrary $libname.a'\n    # Create ${libname}_ixlibrary.a entries in /sys/libs.\n    finish_eval='for lib in `ls $libdir/*.ixlibrary 2>/dev/null`; do libname=`func_echo_all \"$lib\" | $SED '\\''s%^.*/\\([^/]*\\)\\.ixlibrary$%\\1%'\\''`; $RM /sys/libs/${libname}_ixlibrary.a; $show \"cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a\"; cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a || exit 1; done'\n    ;;\n  esac\n  ;;\n\nbeos*)\n  library_names_spec='$libname$shared_ext'\n  dynamic_linker=\"$host_os ld.so\"\n  shlibpath_var=LIBRARY_PATH\n  ;;\n\nbsdi[45]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/shlib /usr/lib /usr/X11/lib /usr/contrib/lib /lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=\"/shlib /usr/lib /usr/local/lib\"\n  # the default ld.so.conf also contains /usr/contrib/lib and\n  # /usr/X11R6/lib (/usr/X11 is a link to /usr/X11R6), but let us allow\n  # libtool to hard-code these into programs\n  ;;\n\ncygwin* | mingw* | pw32* | cegcc*)\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n\n  case $GCC,$cc_basename in\n  yes,*)\n    # gcc\n    library_names_spec='$libname.dll.a'\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname~\n      chmod a+x \\$dldir/$dlname~\n      if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n        eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n      fi'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n\n    case $host_os in\n    cygwin*)\n      # Cygwin DLLs use 'cyg' prefix rather than 'lib'\n      soname_spec='`echo $libname | $SED -e 's/^lib/cyg/'``echo $release | $SED -e 's/[.]/-/g'`$versuffix$shared_ext'\n\n      sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/lib/w32api\"\n      ;;\n    mingw* | cegcc*)\n      # MinGW DLLs use traditional 'lib' prefix\n      soname_spec='$libname`echo $release | $SED -e 's/[.]/-/g'`$versuffix$shared_ext'\n      ;;\n    pw32*)\n      # pw32 DLLs use 'pw' prefix rather than 'lib'\n      library_names_spec='`echo $libname | $SED -e 's/^lib/pw/'``echo $release | $SED -e 's/[.]/-/g'`$versuffix$shared_ext'\n      ;;\n    esac\n    dynamic_linker='Win32 ld.exe'\n    ;;\n\n  *,cl* | *,icl*)\n    # Native MSVC or ICC\n    libname_spec='$name'\n    soname_spec='$libname`echo $release | $SED -e 's/[.]/-/g'`$versuffix$shared_ext'\n    library_names_spec='$libname.dll.lib'\n\n    case $build_os in\n    mingw*)\n      sys_lib_search_path_spec=\n      lt_save_ifs=$IFS\n      IFS=';'\n      for lt_path in $LIB\n      do\n        IFS=$lt_save_ifs\n        # Let DOS variable expansion print the short 8.3 style file name.\n        lt_path=`cd \"$lt_path\" 2>/dev/null && cmd //C \"for %i in (\".\") do @echo %~si\"`\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec $lt_path\"\n      done\n      IFS=$lt_save_ifs\n      # Convert to MSYS style.\n      sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's|\\\\\\\\|/|g' -e 's| \\\\([a-zA-Z]\\\\):| /\\\\1|g' -e 's|^ ||'`\n      ;;\n    cygwin*)\n      # Convert to unix form, then to dos form, then back to unix form\n      # but this time dos style (no spaces!) so that the unix form looks\n      # like /cygdrive/c/PROGRA~1:/cygdr...\n      sys_lib_search_path_spec=`cygpath --path --unix \"$LIB\"`\n      sys_lib_search_path_spec=`cygpath --path --dos \"$sys_lib_search_path_spec\" 2>/dev/null`\n      sys_lib_search_path_spec=`cygpath --path --unix \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      ;;\n    *)\n      sys_lib_search_path_spec=$LIB\n      if $ECHO \"$sys_lib_search_path_spec\" | $GREP ';[c-zC-Z]:/' >/dev/null; then\n        # It is most probably a Windows format PATH.\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's/;/ /g'`\n      else\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      fi\n      # FIXME: find the short name or the path components, as spaces are\n      # common. (e.g. \"Program Files\" -> \"PROGRA~1\")\n      ;;\n    esac\n\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n    dynamic_linker='Win32 link.exe'\n    ;;\n\n  *)\n    # Assume MSVC and ICC wrapper\n    library_names_spec='$libname`echo $release | $SED -e 's/[.]/-/g'`$versuffix$shared_ext $libname.lib'\n    dynamic_linker='Win32 ld.exe'\n    ;;\n  esac\n  # FIXME: first we should search . and the directory the executable is in\n  shlibpath_var=PATH\n  ;;\n\ndarwin* | rhapsody*)\n  dynamic_linker=\"$host_os dyld\"\n  version_type=darwin\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$major$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$major$shared_ext'\n  shlibpath_overrides_runpath=yes\n  shlibpath_var=DYLD_LIBRARY_PATH\n  shrext_cmds='`test .$module = .yes && echo .so || echo .dylib`'\n\n  sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/local/lib\"\n  sys_lib_dlsearch_path_spec='/usr/local/lib /lib /usr/lib'\n  ;;\n\ndgux*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\nfreebsd* | dragonfly* | midnightbsd*)\n  # DragonFly does not have aout.  When/if they implement a new\n  # versioning mechanism, adjust this.\n  if test -x /usr/bin/objformat; then\n    objformat=`/usr/bin/objformat`\n  else\n    case $host_os in\n    freebsd[23].*) objformat=aout ;;\n    *) objformat=elf ;;\n    esac\n  fi\n  version_type=freebsd-$objformat\n  case $version_type in\n    freebsd-elf*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      soname_spec='$libname$release$shared_ext$major'\n      need_version=no\n      need_lib_prefix=no\n      ;;\n    freebsd-*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n      need_version=yes\n      ;;\n  esac\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_os in\n  freebsd2.*)\n    shlibpath_overrides_runpath=yes\n    ;;\n  freebsd3.[01]* | freebsdelf3.[01]*)\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  freebsd3.[2-9]* | freebsdelf3.[2-9]* | \\\n  freebsd4.[0-5] | freebsdelf4.[0-5] | freebsd4.1.1 | freebsdelf4.1.1)\n    shlibpath_overrides_runpath=no\n    hardcode_into_libs=yes\n    ;;\n  *) # from 4.6 on, and DragonFly\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  esac\n  ;;\n\nhaiku*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  dynamic_linker=\"$host_os runtime_loader\"\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_dlsearch_path_spec='/boot/home/config/lib /boot/common/lib /boot/system/lib'\n  hardcode_into_libs=yes\n  ;;\n\nhpux9* | hpux10* | hpux11*)\n  # Give a soname corresponding to the major version so that dld.sl refuses to\n  # link against other versions.\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  case $host_cpu in\n  ia64*)\n    shrext_cmds='.so'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.so\"\n    shlibpath_var=LD_LIBRARY_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    if test 32 = \"$HPUX_IA64_MODE\"; then\n      sys_lib_search_path_spec=\"/usr/lib/hpux32 /usr/local/lib/hpux32 /usr/local/lib\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux32\n    else\n      sys_lib_search_path_spec=\"/usr/lib/hpux64 /usr/local/lib/hpux64\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux64\n    fi\n    ;;\n  hppa*64*)\n    shrext_cmds='.sl'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=LD_LIBRARY_PATH # How should we handle SHLIB_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    sys_lib_search_path_spec=\"/usr/lib/pa20_64 /usr/ccs/lib/pa20_64\"\n    sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n    ;;\n  *)\n    shrext_cmds='.sl'\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=SHLIB_PATH\n    shlibpath_overrides_runpath=no # +s is required to enable SHLIB_PATH\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    ;;\n  esac\n  # HP-UX runs *really* slowly unless shared libraries are mode 555, ...\n  postinstall_cmds='chmod 555 $lib'\n  # or fails outright, so override atomically:\n  install_override_mode=555\n  ;;\n\ninterix[3-9]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  dynamic_linker='Interix 3.x ld.so.1 (PE, like ELF)'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $host_os in\n    nonstopux*) version_type=nonstopux ;;\n    *)\n\tif test yes = \"$lt_cv_prog_gnu_ld\"; then\n\t\tversion_type=linux # correct to gnu/linux during the next big refactor\n\telse\n\t\tversion_type=irix\n\tfi ;;\n  esac\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$release$shared_ext $libname$shared_ext'\n  case $host_os in\n  irix5* | nonstopux*)\n    libsuff= shlibsuff=\n    ;;\n  *)\n    case $LD in # libtool.m4 will add one of these switches to LD\n    *-32|*\"-32 \"|*-melf32bsmip|*\"-melf32bsmip \")\n      libsuff= shlibsuff= libmagic=32-bit;;\n    *-n32|*\"-n32 \"|*-melf32bmipn32|*\"-melf32bmipn32 \")\n      libsuff=32 shlibsuff=N32 libmagic=N32;;\n    *-64|*\"-64 \"|*-melf64bmip|*\"-melf64bmip \")\n      libsuff=64 shlibsuff=64 libmagic=64-bit;;\n    *) libsuff= shlibsuff= libmagic=never-match;;\n    esac\n    ;;\n  esac\n  shlibpath_var=LD_LIBRARY${shlibsuff}_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_search_path_spec=\"/usr/lib$libsuff /lib$libsuff /usr/local/lib$libsuff\"\n  sys_lib_dlsearch_path_spec=\"/usr/lib$libsuff /lib$libsuff\"\n  hardcode_into_libs=yes\n  ;;\n\n# No shared lib support for Linux oldld, aout, or coff.\nlinux*oldld* | linux*aout* | linux*coff*)\n  dynamic_linker=no\n  ;;\n\nlinux*android*)\n  version_type=none # Android doesn't support versioned libraries.\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext'\n  soname_spec='$libname$release$shared_ext'\n  finish_cmds=\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  dynamic_linker='Android linker'\n  # Don't embed -rpath directories since the linker doesn't support them.\n  hardcode_libdir_flag_spec='-L$libdir'\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -n $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n\n  # Some binutils ld are patched to set DT_RUNPATH\n  if test ${lt_cv_shlibpath_overrides_runpath+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) lt_cv_shlibpath_overrides_runpath=no\n    save_LDFLAGS=$LDFLAGS\n    save_libdir=$libdir\n    eval \"libdir=/foo; wl=\\\"$lt_prog_compiler_wl\\\"; \\\n\t LDFLAGS=\\\"\\$LDFLAGS $hardcode_libdir_flag_spec\\\"\"\n    cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  if  ($OBJDUMP -p conftest$ac_exeext) 2>/dev/null | grep \"RUNPATH.*$libdir\" >/dev/null\nthen :\n  lt_cv_shlibpath_overrides_runpath=yes\nfi\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n    LDFLAGS=$save_LDFLAGS\n    libdir=$save_libdir\n     ;;\nesac\nfi\n\n  shlibpath_overrides_runpath=$lt_cv_shlibpath_overrides_runpath\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  # Ideally, we could use ldconfig to report *all* directores which are\n  # searched for libraries, however this is still not possible.  Aside from not\n  # being certain /sbin/ldconfig is available, command\n  # 'ldconfig -N -X -v | grep ^/' on 64bit Fedora does not report /usr/lib64,\n  # even though it is searched at run-time.  Try to do the best guess by\n  # appending ld.so.conf contents (and includes) to the search path.\n  if test -f /etc/ld.so.conf; then\n    lt_ld_extra=`awk '/^include / { system(sprintf(\"cd /etc; cat %s 2>/dev/null\", \\$2)); skip = 1; } { if (!skip) print \\$0; skip = 0; }' < /etc/ld.so.conf | $SED -e 's/#.*//;/^[\t ]*hwcap[\t ]/d;s/[:,\t]/ /g;s/=[^=]*$//;s/=[^= ]* / /g;s/\"//g;/^$/d' | tr '\\n' ' '`\n    sys_lib_dlsearch_path_spec=\"/lib /usr/lib $lt_ld_extra\"\n  fi\n\n  # We used to test for /lib/ld.so.1 and disable shared libraries on\n  # powerpc, because MkLinux only supported shared libraries with the\n  # GNU dynamic linker.  Since this was broken with cross compilers,\n  # most powerpc-linux boxes support dynamic linking these days and\n  # people can always --disable-shared, the test was removed, and we\n  # assume the GNU/Linux dynamic linker is in use.\n  dynamic_linker='GNU/Linux ld.so'\n  ;;\n\nnetbsdelf*-gnu)\n  version_type=linux\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='${libname}${release}${shared_ext}$versuffix ${libname}${release}${shared_ext}$major ${libname}${shared_ext}'\n  soname_spec='${libname}${release}${shared_ext}$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='NetBSD ld.elf_so'\n  ;;\n\nnetbsd*)\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n    finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n    dynamic_linker='NetBSD (a.out) ld.so'\n  else\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    dynamic_linker='NetBSD ld.elf_so'\n  fi\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  ;;\n\nnewsos6)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\n*nto* | *qnx*)\n  version_type=qnx\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='ldqnx.so'\n  ;;\n\nopenbsd* | bitrig*)\n  version_type=sunos\n  sys_lib_dlsearch_path_spec=/usr/lib\n  need_lib_prefix=no\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    need_version=no\n  else\n    need_version=yes\n  fi\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\nos2*)\n  libname_spec='$name'\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n  # OS/2 can only load a DLL with a base name of 8 characters or less.\n  soname_spec='`test -n \"$os2dllname\" && libname=\"$os2dllname\";\n    v=$($ECHO $release$versuffix | tr -d .-);\n    n=$($ECHO $libname | cut -b -$((8 - ${#v})) | tr . _);\n    $ECHO $n$v`$shared_ext'\n  library_names_spec='${libname}_dll.$libext'\n  dynamic_linker='OS/2 ld.exe'\n  shlibpath_var=BEGINLIBPATH\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  postinstall_cmds='base_file=`basename \\$file`~\n    dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; $ECHO \\$dlname'\\''`~\n    dldir=$destdir/`dirname \\$dlpath`~\n    test -d \\$dldir || mkdir -p \\$dldir~\n    $install_prog $dir/$dlname \\$dldir/$dlname~\n    chmod a+x \\$dldir/$dlname~\n    if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n      eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n    fi'\n  postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; $ECHO \\$dlname'\\''`~\n    dlpath=$dir/\\$dldll~\n    $RM \\$dlpath'\n  ;;\n\nosf3* | osf4* | osf5*)\n  version_type=osf\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/usr/shlib /usr/ccs/lib /usr/lib/cmplrs/cc /usr/lib /usr/local/lib /var/shlib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  ;;\n\nrdos*)\n  dynamic_linker=no\n  ;;\n\nsolaris*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  # ldd complains unless libraries are executable\n  postinstall_cmds='chmod +x $lib'\n  ;;\n\nsunos4*)\n  version_type=sunos\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/usr/etc\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  if test yes = \"$with_gnu_ld\"; then\n    need_lib_prefix=no\n  fi\n  need_version=yes\n  ;;\n\nsysv4 | sysv4.3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_vendor in\n    sni)\n      shlibpath_overrides_runpath=no\n      need_lib_prefix=no\n      runpath_var=LD_RUN_PATH\n      ;;\n    siemens)\n      need_lib_prefix=no\n      ;;\n    motorola)\n      need_lib_prefix=no\n      need_version=no\n      shlibpath_overrides_runpath=no\n      sys_lib_search_path_spec='/lib /usr/lib /usr/ccs/lib'\n      ;;\n  esac\n  ;;\n\nsysv4*MP*)\n  if test -d /usr/nec; then\n    version_type=linux # correct to gnu/linux during the next big refactor\n    library_names_spec='$libname$shared_ext.$versuffix $libname$shared_ext.$major $libname$shared_ext'\n    soname_spec='$libname$shared_ext.$major'\n    shlibpath_var=LD_LIBRARY_PATH\n  fi\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  version_type=sco\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  if test yes = \"$with_gnu_ld\"; then\n    sys_lib_search_path_spec='/usr/local/lib /usr/gnu/lib /usr/ccs/lib /usr/lib /lib'\n  else\n    sys_lib_search_path_spec='/usr/ccs/lib /usr/lib'\n    case $host_os in\n      sco3.2v5*)\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec /lib\"\n\t;;\n    esac\n  fi\n  sys_lib_dlsearch_path_spec='/usr/lib'\n  ;;\n\ntpf*)\n  # TPF is a cross-target only.  Preferred cross-host = GNU/Linux.\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nuts4*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\n*)\n  dynamic_linker=no\n  ;;\nesac\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $dynamic_linker\" >&5\nprintf \"%s\\n\" \"$dynamic_linker\" >&6; }\ntest no = \"$dynamic_linker\" && can_build_shared=no\n\nvariables_saved_for_relink=\"PATH $shlibpath_var $runpath_var\"\nif test yes = \"$GCC\"; then\n  variables_saved_for_relink=\"$variables_saved_for_relink GCC_EXEC_PREFIX COMPILER_PATH LIBRARY_PATH\"\nfi\n\nif test set = \"${lt_cv_sys_lib_search_path_spec+set}\"; then\n  sys_lib_search_path_spec=$lt_cv_sys_lib_search_path_spec\nfi\n\nif test set = \"${lt_cv_sys_lib_dlsearch_path_spec+set}\"; then\n  sys_lib_dlsearch_path_spec=$lt_cv_sys_lib_dlsearch_path_spec\nfi\n\n# remember unaugmented sys_lib_dlsearch_path content for libtool script decls...\nconfigure_time_dlsearch_path=$sys_lib_dlsearch_path_spec\n\n# ... but it needs LT_SYS_LIBRARY_PATH munging for other configure-time code\nfunc_munge_path_list sys_lib_dlsearch_path_spec \"$LT_SYS_LIBRARY_PATH\"\n\n# to be used as default LT_SYS_LIBRARY_PATH value in generated libtool\nconfigure_time_lt_sys_library_path=$LT_SYS_LIBRARY_PATH\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to hardcode library paths into programs\" >&5\nprintf %s \"checking how to hardcode library paths into programs... \" >&6; }\nhardcode_action=\nif test -n \"$hardcode_libdir_flag_spec\" ||\n   test -n \"$runpath_var\" ||\n   test yes = \"$hardcode_automatic\"; then\n\n  # We can hardcode non-existent directories.\n  if test no != \"$hardcode_direct\" &&\n     # If the only mechanism to avoid hardcoding is shlibpath_var, we\n     # have to relink, otherwise we might link with an installed library\n     # when we should be linking with a yet-to-be-installed one\n     ## test no != \"$_LT_TAGVAR(hardcode_shlibpath_var, )\" &&\n     test no != \"$hardcode_minus_L\"; then\n    # Linking always hardcodes the temporary library directory.\n    hardcode_action=relink\n  else\n    # We can link without hardcoding, and we can hardcode nonexisting dirs.\n    hardcode_action=immediate\n  fi\nelse\n  # We cannot hardcode anything, or else we can only hardcode existing\n  # directories.\n  hardcode_action=unsupported\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $hardcode_action\" >&5\nprintf \"%s\\n\" \"$hardcode_action\" >&6; }\n\nif test relink = \"$hardcode_action\" ||\n   test yes = \"$inherit_rpath\"; then\n  # Fast installation is not supported\n  enable_fast_install=no\nelif test yes = \"$shlibpath_overrides_runpath\" ||\n     test no = \"$enable_shared\"; then\n  # Fast installation is not necessary\n  enable_fast_install=needless\nfi\n\n\n\n\n\n\n  if test yes != \"$enable_dlopen\"; then\n  enable_dlopen=unknown\n  enable_dlopen_self=unknown\n  enable_dlopen_self_static=unknown\nelse\n  lt_cv_dlopen=no\n  lt_cv_dlopen_libs=\n\n  case $host_os in\n  beos*)\n    lt_cv_dlopen=load_add_on\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ;;\n\n  mingw* | pw32* | cegcc*)\n    lt_cv_dlopen=LoadLibrary\n    lt_cv_dlopen_libs=\n    ;;\n\n  cygwin*)\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    ;;\n\n  darwin*)\n    # if libdl is installed we need to link against it\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for dlopen in -ldl\" >&5\nprintf %s \"checking for dlopen in -ldl... \" >&6; }\nif test ${ac_cv_lib_dl_dlopen+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_check_lib_save_LIBS=$LIBS\nLIBS=\"-ldl  $LIBS\"\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.\n   The 'extern \"C\"' is for builds by C++ compilers;\n   although this is not generally supported in C code supporting it here\n   has little cost and some practical benefit (sr 110532).  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar dlopen (void);\nint\nmain (void)\n{\nreturn dlopen ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_cv_lib_dl_dlopen=yes\nelse case e in #(\n  e) ac_cv_lib_dl_dlopen=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\nLIBS=$ac_check_lib_save_LIBS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_lib_dl_dlopen\" >&5\nprintf \"%s\\n\" \"$ac_cv_lib_dl_dlopen\" >&6; }\nif test \"x$ac_cv_lib_dl_dlopen\" = xyes\nthen :\n  lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl\nelse case e in #(\n  e)\n    lt_cv_dlopen=dyld\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n     ;;\nesac\nfi\n\n    ;;\n\n  tpf*)\n    # Don't try to run any link tests for TPF.  We know it's impossible\n    # because TPF is a cross-compiler, and we know how we open DSOs.\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=no\n    ;;\n\n  *)\n    ac_fn_c_check_func \"$LINENO\" \"shl_load\" \"ac_cv_func_shl_load\"\nif test \"x$ac_cv_func_shl_load\" = xyes\nthen :\n  lt_cv_dlopen=shl_load\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for shl_load in -ldld\" >&5\nprintf %s \"checking for shl_load in -ldld... \" >&6; }\nif test ${ac_cv_lib_dld_shl_load+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_check_lib_save_LIBS=$LIBS\nLIBS=\"-ldld  $LIBS\"\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.\n   The 'extern \"C\"' is for builds by C++ compilers;\n   although this is not generally supported in C code supporting it here\n   has little cost and some practical benefit (sr 110532).  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar shl_load (void);\nint\nmain (void)\n{\nreturn shl_load ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_cv_lib_dld_shl_load=yes\nelse case e in #(\n  e) ac_cv_lib_dld_shl_load=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\nLIBS=$ac_check_lib_save_LIBS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_lib_dld_shl_load\" >&5\nprintf \"%s\\n\" \"$ac_cv_lib_dld_shl_load\" >&6; }\nif test \"x$ac_cv_lib_dld_shl_load\" = xyes\nthen :\n  lt_cv_dlopen=shl_load lt_cv_dlopen_libs=-ldld\nelse case e in #(\n  e) ac_fn_c_check_func \"$LINENO\" \"dlopen\" \"ac_cv_func_dlopen\"\nif test \"x$ac_cv_func_dlopen\" = xyes\nthen :\n  lt_cv_dlopen=dlopen\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for dlopen in -ldl\" >&5\nprintf %s \"checking for dlopen in -ldl... \" >&6; }\nif test ${ac_cv_lib_dl_dlopen+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_check_lib_save_LIBS=$LIBS\nLIBS=\"-ldl  $LIBS\"\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.\n   The 'extern \"C\"' is for builds by C++ compilers;\n   although this is not generally supported in C code supporting it here\n   has little cost and some practical benefit (sr 110532).  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar dlopen (void);\nint\nmain (void)\n{\nreturn dlopen ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_cv_lib_dl_dlopen=yes\nelse case e in #(\n  e) ac_cv_lib_dl_dlopen=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\nLIBS=$ac_check_lib_save_LIBS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_lib_dl_dlopen\" >&5\nprintf \"%s\\n\" \"$ac_cv_lib_dl_dlopen\" >&6; }\nif test \"x$ac_cv_lib_dl_dlopen\" = xyes\nthen :\n  lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for dlopen in -lsvld\" >&5\nprintf %s \"checking for dlopen in -lsvld... \" >&6; }\nif test ${ac_cv_lib_svld_dlopen+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_check_lib_save_LIBS=$LIBS\nLIBS=\"-lsvld  $LIBS\"\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.\n   The 'extern \"C\"' is for builds by C++ compilers;\n   although this is not generally supported in C code supporting it here\n   has little cost and some practical benefit (sr 110532).  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar dlopen (void);\nint\nmain (void)\n{\nreturn dlopen ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_cv_lib_svld_dlopen=yes\nelse case e in #(\n  e) ac_cv_lib_svld_dlopen=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\nLIBS=$ac_check_lib_save_LIBS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_lib_svld_dlopen\" >&5\nprintf \"%s\\n\" \"$ac_cv_lib_svld_dlopen\" >&6; }\nif test \"x$ac_cv_lib_svld_dlopen\" = xyes\nthen :\n  lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-lsvld\nelse case e in #(\n  e) { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for dld_link in -ldld\" >&5\nprintf %s \"checking for dld_link in -ldld... \" >&6; }\nif test ${ac_cv_lib_dld_dld_link+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) ac_check_lib_save_LIBS=$LIBS\nLIBS=\"-ldld  $LIBS\"\ncat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\n/* Override any GCC internal prototype to avoid an error.\n   Use char because int might match the return type of a GCC\n   builtin and then its argument prototype would still apply.\n   The 'extern \"C\"' is for builds by C++ compilers;\n   although this is not generally supported in C code supporting it here\n   has little cost and some practical benefit (sr 110532).  */\n#ifdef __cplusplus\nextern \"C\"\n#endif\nchar dld_link (void);\nint\nmain (void)\n{\nreturn dld_link ();\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_c_try_link \"$LINENO\"\nthen :\n  ac_cv_lib_dld_dld_link=yes\nelse case e in #(\n  e) ac_cv_lib_dld_dld_link=no ;;\nesac\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\nLIBS=$ac_check_lib_save_LIBS ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $ac_cv_lib_dld_dld_link\" >&5\nprintf \"%s\\n\" \"$ac_cv_lib_dld_dld_link\" >&6; }\nif test \"x$ac_cv_lib_dld_dld_link\" = xyes\nthen :\n  lt_cv_dlopen=dld_link lt_cv_dlopen_libs=-ldld\nfi\n\n\t       ;;\nesac\nfi\n\n\t     ;;\nesac\nfi\n\n\t   ;;\nesac\nfi\n\n\t ;;\nesac\nfi\n\n       ;;\nesac\nfi\n\n    ;;\n  esac\n\n  if test no = \"$lt_cv_dlopen\"; then\n    enable_dlopen=no\n  else\n    enable_dlopen=yes\n  fi\n\n  case $lt_cv_dlopen in\n  dlopen)\n    save_CPPFLAGS=$CPPFLAGS\n    test yes = \"$ac_cv_header_dlfcn_h\" && CPPFLAGS=\"$CPPFLAGS -DHAVE_DLFCN_H\"\n\n    save_LDFLAGS=$LDFLAGS\n    wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $export_dynamic_flag_spec\\\"\n\n    save_LIBS=$LIBS\n    LIBS=\"$lt_cv_dlopen_libs $LIBS\"\n\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether a program can dlopen itself\" >&5\nprintf %s \"checking whether a program can dlopen itself... \" >&6; }\nif test ${lt_cv_dlopen_self+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) \t  if test yes = \"$cross_compiling\"; then :\n  lt_cv_dlopen_self=cross\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}\n_LT_EOF\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_link\\\"\"; } >&5\n  (eval $ac_link) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&5 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) lt_cv_dlopen_self=yes ;;\n      x$lt_dlneed_uscore) lt_cv_dlopen_self=yes ;;\n      x$lt_dlunknown|x*) lt_cv_dlopen_self=no ;;\n    esac\n  else :\n    # compilation failed\n    lt_cv_dlopen_self=no\n  fi\nfi\nrm -fr conftest*\n\n     ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_dlopen_self\" >&5\nprintf \"%s\\n\" \"$lt_cv_dlopen_self\" >&6; }\n\n    if test yes = \"$lt_cv_dlopen_self\"; then\n      wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $lt_prog_compiler_static\\\"\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether a statically linked program can dlopen itself\" >&5\nprintf %s \"checking whether a statically linked program can dlopen itself... \" >&6; }\nif test ${lt_cv_dlopen_self_static+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) \t  if test yes = \"$cross_compiling\"; then :\n  lt_cv_dlopen_self_static=cross\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}\n_LT_EOF\n  if { { eval echo \"\\\"\\$as_me\\\":${as_lineno-$LINENO}: \\\"$ac_link\\\"\"; } >&5\n  (eval $ac_link) 2>&5\n  ac_status=$?\n  printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: \\$? = $ac_status\" >&5\n  test $ac_status = 0; } && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&5 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) lt_cv_dlopen_self_static=yes ;;\n      x$lt_dlneed_uscore) lt_cv_dlopen_self_static=yes ;;\n      x$lt_dlunknown|x*) lt_cv_dlopen_self_static=no ;;\n    esac\n  else :\n    # compilation failed\n    lt_cv_dlopen_self_static=no\n  fi\nfi\nrm -fr conftest*\n\n       ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_dlopen_self_static\" >&5\nprintf \"%s\\n\" \"$lt_cv_dlopen_self_static\" >&6; }\n    fi\n\n    CPPFLAGS=$save_CPPFLAGS\n    LDFLAGS=$save_LDFLAGS\n    LIBS=$save_LIBS\n    ;;\n  esac\n\n  case $lt_cv_dlopen_self in\n  yes|no) enable_dlopen_self=$lt_cv_dlopen_self ;;\n  *) enable_dlopen_self=unknown ;;\n  esac\n\n  case $lt_cv_dlopen_self_static in\n  yes|no) enable_dlopen_self_static=$lt_cv_dlopen_self_static ;;\n  *) enable_dlopen_self_static=unknown ;;\n  esac\nfi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstriplib=\nold_striplib=\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether stripping libraries is possible\" >&5\nprintf %s \"checking whether stripping libraries is possible... \" >&6; }\nif test -z \"$STRIP\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nelse\n  if $STRIP -V 2>&1 | $GREP \"GNU strip\" >/dev/null; then\n    old_striplib=\"$STRIP --strip-debug\"\n    striplib=\"$STRIP --strip-unneeded\"\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n  else\n    case $host_os in\n    darwin*)\n      # FIXME - insert some real tests, host_os isn't really good enough\n      striplib=\"$STRIP -x\"\n      old_striplib=\"$STRIP -S\"\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n      ;;\n    freebsd*)\n      if $STRIP -V 2>&1 | $GREP \"elftoolchain\" >/dev/null; then\n        old_striplib=\"$STRIP --strip-debug\"\n        striplib=\"$STRIP --strip-unneeded\"\n        { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: yes\" >&5\nprintf \"%s\\n\" \"yes\" >&6; }\n      else\n        { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\n      fi\n      ;;\n    *)\n      { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\n      ;;\n    esac\n  fi\nfi\n\n\n\n\n\n\n\n\n\n\n\n\n  # Report what library types will actually be built\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if libtool supports shared libraries\" >&5\nprintf %s \"checking if libtool supports shared libraries... \" >&6; }\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $can_build_shared\" >&5\nprintf \"%s\\n\" \"$can_build_shared\" >&6; }\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether to build shared libraries\" >&5\nprintf %s \"checking whether to build shared libraries... \" >&6; }\n  test no = \"$can_build_shared\" && enable_shared=no\n\n  # On AIX, shared libraries and static libraries use the same namespace, and\n  # are all built from PIC.\n  case $host_os in\n  aix3*)\n    test yes = \"$enable_shared\" && enable_static=no\n    if test -n \"$RANLIB\"; then\n      archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n      postinstall_cmds='$RANLIB $lib'\n    fi\n    ;;\n\n  aix[4-9]*)\n    if test ia64 != \"$host_cpu\"; then\n      case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n      yes,aix,yes) ;;\t\t\t# shared object as lib.so file only\n      yes,svr4,*) ;;\t\t\t# shared object as lib.so archive member only\n      yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n      esac\n    fi\n    ;;\n  esac\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $enable_shared\" >&5\nprintf \"%s\\n\" \"$enable_shared\" >&6; }\n\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether to build static libraries\" >&5\nprintf %s \"checking whether to build static libraries... \" >&6; }\n  # Make sure either enable_shared or enable_static is yes.\n  test yes = \"$enable_shared\" || enable_static=yes\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $enable_static\" >&5\nprintf \"%s\\n\" \"$enable_static\" >&6; }\n\n\n\n\nfi\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\nCC=$lt_save_CC\n\n      if test -n \"$CXX\" && ( test no != \"$CXX\" &&\n    ( (test g++ = \"$CXX\" && `g++ -v >/dev/null 2>&1` ) ||\n    (test g++ != \"$CXX\"))); then\n  ac_ext=cpp\nac_cpp='$CXXCPP $CPPFLAGS'\nac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking how to run the C++ preprocessor\" >&5\nprintf %s \"checking how to run the C++ preprocessor... \" >&6; }\nif test -z \"$CXXCPP\"; then\n  if test ${ac_cv_prog_CXXCPP+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e)     # Double quotes because $CXX needs to be expanded\n    for CXXCPP in \"$CXX -E\" cpp /lib/cpp\n    do\n      ac_preproc_ok=false\nfor ac_cxx_preproc_warn_flag in '' yes\ndo\n  # Use a header file that comes with gcc, so configuring glibc\n  # with a fresh cross-compiler works.\n  # On the NeXT, cc -E runs the code through the compiler's parser,\n  # not just through cpp. \"Syntax error\" is here to catch this case.\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n#include <limits.h>\n\t\t     Syntax error\n_ACEOF\nif ac_fn_cxx_try_cpp \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) # Broken: fails on valid input.\ncontinue ;;\nesac\nfi\nrm -f conftest.err conftest.i conftest.$ac_ext\n\n  # OK, works on sane cases.  Now check whether nonexistent headers\n  # can be detected and how.\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n#include <ac_nonexistent.h>\n_ACEOF\nif ac_fn_cxx_try_cpp \"$LINENO\"\nthen :\n  # Broken: success on invalid input.\ncontinue\nelse case e in #(\n  e) # Passes both tests.\nac_preproc_ok=:\nbreak ;;\nesac\nfi\nrm -f conftest.err conftest.i conftest.$ac_ext\n\ndone\n# Because of 'break', _AC_PREPROC_IFELSE's cleaning code was skipped.\nrm -f conftest.i conftest.err conftest.$ac_ext\nif $ac_preproc_ok\nthen :\n  break\nfi\n\n    done\n    ac_cv_prog_CXXCPP=$CXXCPP\n   ;;\nesac\nfi\n  CXXCPP=$ac_cv_prog_CXXCPP\nelse\n  ac_cv_prog_CXXCPP=$CXXCPP\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $CXXCPP\" >&5\nprintf \"%s\\n\" \"$CXXCPP\" >&6; }\nac_preproc_ok=false\nfor ac_cxx_preproc_warn_flag in '' yes\ndo\n  # Use a header file that comes with gcc, so configuring glibc\n  # with a fresh cross-compiler works.\n  # On the NeXT, cc -E runs the code through the compiler's parser,\n  # not just through cpp. \"Syntax error\" is here to catch this case.\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n#include <limits.h>\n\t\t     Syntax error\n_ACEOF\nif ac_fn_cxx_try_cpp \"$LINENO\"\nthen :\n\nelse case e in #(\n  e) # Broken: fails on valid input.\ncontinue ;;\nesac\nfi\nrm -f conftest.err conftest.i conftest.$ac_ext\n\n  # OK, works on sane cases.  Now check whether nonexistent headers\n  # can be detected and how.\n  cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n#include <ac_nonexistent.h>\n_ACEOF\nif ac_fn_cxx_try_cpp \"$LINENO\"\nthen :\n  # Broken: success on invalid input.\ncontinue\nelse case e in #(\n  e) # Passes both tests.\nac_preproc_ok=:\nbreak ;;\nesac\nfi\nrm -f conftest.err conftest.i conftest.$ac_ext\n\ndone\n# Because of 'break', _AC_PREPROC_IFELSE's cleaning code was skipped.\nrm -f conftest.i conftest.err conftest.$ac_ext\nif $ac_preproc_ok\nthen :\n\nelse case e in #(\n  e) { { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: error: in '$ac_pwd':\" >&5\nprintf \"%s\\n\" \"$as_me: error: in '$ac_pwd':\" >&2;}\nas_fn_error $? \"C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\nSee 'config.log' for more details\" \"$LINENO\" 5; } ;;\nesac\nfi\n\nac_ext=c\nac_cpp='$CPP $CPPFLAGS'\nac_compile='$CC -c $CFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CC -o conftest$ac_exeext $CFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_c_compiler_gnu\n\nelse\n  _lt_caught_CXX_error=yes\nfi\n\nac_ext=cpp\nac_cpp='$CXXCPP $CPPFLAGS'\nac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'\nac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\nac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n\narchive_cmds_need_lc_CXX=no\nallow_undefined_flag_CXX=\nalways_export_symbols_CXX=no\narchive_expsym_cmds_CXX=\ncompiler_needs_object_CXX=no\nexport_dynamic_flag_spec_CXX=\nhardcode_direct_CXX=no\nhardcode_direct_absolute_CXX=no\nhardcode_libdir_flag_spec_CXX=\nhardcode_libdir_separator_CXX=\nhardcode_minus_L_CXX=no\nhardcode_shlibpath_var_CXX=unsupported\nhardcode_automatic_CXX=no\ninherit_rpath_CXX=no\nmodule_cmds_CXX=\nmodule_expsym_cmds_CXX=\nlink_all_deplibs_CXX=unknown\nold_archive_cmds_CXX=$old_archive_cmds\nreload_flag_CXX=$reload_flag\nreload_cmds_CXX=$reload_cmds\nno_undefined_flag_CXX=\nwhole_archive_flag_spec_CXX=\nenable_shared_with_static_runtimes_CXX=no\n\n# Source file extension for C++ test sources.\nac_ext=cpp\n\n# Object file extension for compiled C++ test sources.\nobjext=o\nobjext_CXX=$objext\n\n# No sense in running all these tests if we already determined that\n# the CXX compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_caught_CXX_error\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"int some_variable = 0;\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code='int main(int, char *[]) { return(0); }'\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n\n\n\n\n\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n\n\n  # save warnings/boilerplate of simple test code\n  ac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n\n  ac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_CFLAGS=$CFLAGS\n  lt_save_LD=$LD\n  lt_save_GCC=$GCC\n  GCC=$GXX\n  lt_save_with_gnu_ld=$with_gnu_ld\n  lt_save_path_LD=$lt_cv_path_LD\n  if test -n \"${lt_cv_prog_gnu_ldcxx+set}\"; then\n    lt_cv_prog_gnu_ld=$lt_cv_prog_gnu_ldcxx\n  else\n    $as_unset lt_cv_prog_gnu_ld\n  fi\n  if test -n \"${lt_cv_path_LDCXX+set}\"; then\n    lt_cv_path_LD=$lt_cv_path_LDCXX\n  else\n    $as_unset lt_cv_path_LD\n  fi\n  test -z \"${LDCXX+set}\" || LD=$LDCXX\n  CC=${CXX-\"c++\"}\n  CFLAGS=$CXXFLAGS\n  compiler=$CC\n  compiler_CXX=$CC\n  func_cc_basename $compiler\ncc_basename=$func_cc_basename_result\n\n\n  if test -n \"$compiler\"; then\n    # We don't want -fno-exception when compiling C++ code, so set the\n    # no_builtin_flag separately\n    if test yes = \"$GXX\"; then\n      lt_prog_compiler_no_builtin_flag_CXX=' -fno-builtin'\n    else\n      lt_prog_compiler_no_builtin_flag_CXX=\n    fi\n\n    if test yes = \"$GXX\"; then\n      # Set up default GNU C++ configuration\n\n\n\n# Check whether --with-gnu-ld was given.\nif test ${with_gnu_ld+y}\nthen :\n  withval=$with_gnu_ld; test no = \"$withval\" || with_gnu_ld=yes\nelse case e in #(\n  e) with_gnu_ld=no ;;\nesac\nfi\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for ld used by $CC\" >&5\nprintf %s \"checking for ld used by $CC... \" >&6; }\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [\\\\/]* | ?:[\\\\/]*)\n      re_direlt='/[^/][^/]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for GNU ld\" >&5\nprintf %s \"checking for GNU ld... \" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking for non-GNU ld\" >&5\nprintf %s \"checking for non-GNU ld... \" >&6; }\nfi\nif test ${lt_cv_path_LD+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi ;;\nesac\nfi\n\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $LD\" >&5\nprintf \"%s\\n\" \"$LD\" >&6; }\nelse\n  { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: no\" >&5\nprintf \"%s\\n\" \"no\" >&6; }\nfi\ntest -z \"$LD\" && as_fn_error $? \"no acceptable ld found in \\$PATH\" \"$LINENO\" 5\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking if the linker ($LD) is GNU ld\" >&5\nprintf %s \"checking if the linker ($LD) is GNU ld... \" >&6; }\nif test ${lt_cv_prog_gnu_ld+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) # I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac ;;\nesac\nfi\n{ printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: result: $lt_cv_prog_gnu_ld\" >&5\nprintf \"%s\\n\" \"$lt_cv_prog_gnu_ld\" >&6; }\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\n\n\n\n\n\n\n      # Check if GNU C++ uses GNU ld as the underlying linker, since the\n      # archiving commands below assume that GNU ld is being used.\n      if test yes = \"$with_gnu_ld\"; then\n        archive_cmds_CXX='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n        archive_expsym_cmds_CXX='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\n        hardcode_libdir_flag_spec_CXX='$wl-rpath $wl$libdir'\n        export_dynamic_flag_spec_CXX='$wl--export-dynamic'\n\n        # If archive_cmds runs LD, not CC, wlarc should be empty\n        # XXX I think wlarc can be eliminated in ltcf-cxx, but I need to\n        #     investigate it a little bit more. (MM)\n        wlarc='$wl'\n\n        # ancient GNU ld didn't support --whole-archive et. al.\n        if eval \"`$CC -print-prog-name=ld` --help 2>&1\" |\n\t  $GREP 'no-whole-archive' > /dev/null; then\n          whole_archive_flag_spec_CXX=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n        else\n          whole_archive_flag_spec_CXX=\n        fi\n      else\n        with_gnu_ld=no\n        wlarc=\n\n        # A generic and very simple default shared library creation\n        # command for GNU C++ for the case where it uses the native\n        # linker, instead of GNU ld.  If possible, this setting should\n        # overridden to take advantage of the native linker features on\n        # the platform it is being used on.\n        archive_cmds_CXX='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n      fi\n\n      # Commands to make compiler produce verbose output that lists\n      # what \"hidden\" libraries, object files and flags are used when\n      # linking a shared library.\n      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \" \\-L\"'\n\n    else\n      GXX=no\n      with_gnu_ld=no\n      wlarc=\n    fi\n\n    # PORTME: fill in a description of your system's C++ link characteristics\n    { printf \"%s\\n\" \"$as_me:${as_lineno-$LINENO}: checking whether the $compiler linker ($LD) supports shared libraries\" >&5\nprintf %s \"checking whether the $compiler linker ($LD) supports shared libraries... \" >&6; }\n    ld_shlibs_CXX=yes\n    case $host_os in\n      aix3*)\n        # FIXME: insert proper C++ library support\n        ld_shlibs_CXX=no\n        ;;\n      aix[4-9]*)\n        if test ia64 = \"$host_cpu\"; then\n          # On IA64, the linker does run time linking by default, so we don't\n          # have to do anything special.\n          aix_use_runtimelinking=no\n          exp_sym_flag='-Bexport'\n          no_entry_flag=\n        else\n          aix_use_runtimelinking=no\n\n          # Test if we are trying to use run time linking or normal\n          # AIX style linking. If -brtl is somewhere in LDFLAGS, we\n          # have runtime linking enabled, and use it for executables.\n          # For shared libraries, we enable/disable runtime linking\n          # depending on the kind of the shared library created -\n          # when \"with_aix_soname,aix_use_runtimelinking\" is:\n          # \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n          #            lib.a           static archive\n          # \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n          #            lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a(lib.so.V) shared, rtl:no\n          # \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a           static archive\n          case $host_os in aix4.[23]|aix4.[23].*|aix[5-9]*)\n\t    for ld_flag in $LDFLAGS; do\n\t      case $ld_flag in\n\t      *-brtl*)\n\t        aix_use_runtimelinking=yes\n\t        break\n\t        ;;\n\t      esac\n\t    done\n\t    if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t      # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t      # so we don't have lib.a shared libs to link our executables.\n\t      # We have to force runtime linking in this case.\n\t      aix_use_runtimelinking=yes\n\t      LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t    fi\n\t    ;;\n          esac\n\n          exp_sym_flag='-bexport'\n          no_entry_flag='-bnoentry'\n        fi\n\n        # When large executables or shared objects are built, AIX ld can\n        # have problems creating the table of contents.  If linking a library\n        # or program results in \"error TOC overflow\" add -mminimal-toc to\n        # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n        # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n        archive_cmds_CXX=''\n        hardcode_direct_CXX=yes\n        hardcode_direct_absolute_CXX=yes\n        hardcode_libdir_separator_CXX=':'\n        link_all_deplibs_CXX=yes\n        file_list_spec_CXX='$wl-f,'\n        case $with_aix_soname,$aix_use_runtimelinking in\n        aix,*) ;;\t# no import file\n        svr4,* | *,yes) # use import file\n          # The Import File defines what to hardcode.\n          hardcode_direct_CXX=no\n          hardcode_direct_absolute_CXX=no\n          ;;\n        esac\n\n        if test yes = \"$GXX\"; then\n          case $host_os in aix4.[012]|aix4.[012].*)\n          # We only want to do this on AIX 4.2 and lower, the check\n          # below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t     strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t    # We have reworked collect2\n\t    :\n\t  else\n\t    # We have old collect2\n\t    hardcode_direct_CXX=unsupported\n\t    # It fails to find uninstalled libraries when the uninstalled\n\t    # path is not listed in the libpath.  Setting hardcode_minus_L\n\t    # to unsupported forces relinking\n\t    hardcode_minus_L_CXX=yes\n\t    hardcode_libdir_flag_spec_CXX='-L$libdir'\n\t    hardcode_libdir_separator_CXX=\n\t  fi\n          esac\n          shared_flag='-shared'\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag=$shared_flag' $wl-G'\n\t  fi\n\t  # Need to ensure runtime linking is disabled for the traditional\n\t  # shared library, or the linker may eventually find shared libraries\n\t  # /with/ Import File - we do not want to mix them.\n\t  shared_flag_aix='-shared'\n\t  shared_flag_svr4='-shared $wl-G'\n        else\n          # not using gcc\n          if test ia64 = \"$host_cpu\"; then\n\t  # VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t  # chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n          else\n\t    if test yes = \"$aix_use_runtimelinking\"; then\n\t      shared_flag='$wl-G'\n\t    else\n\t      shared_flag='$wl-bM:SRE'\n\t    fi\n\t    shared_flag_aix='$wl-bM:SRE'\n\t    shared_flag_svr4='$wl-G'\n          fi\n        fi\n\n        export_dynamic_flag_spec_CXX='$wl-bexpall'\n        # It seems that -bexpall does not export symbols beginning with\n        # underscore (_), so it is better to generate a list of symbols to\n\t# export.\n        always_export_symbols_CXX=yes\n\tif test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n          # Warning - without using the other runtime loading flags (-brtl),\n          # -berok will link without error, but may produce a broken library.\n          # The \"-G\" linker flag allows undefined symbols.\n          no_undefined_flag_CXX='-bernotok'\n          # Determine the default libpath from the value encoded in an empty\n          # executable.\n          if test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  if test ${lt_cv_aix_libpath__CXX+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_link \"$LINENO\"\nthen :\n\n  lt_aix_libpath_sed='\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }'\n  lt_cv_aix_libpath__CXX=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$lt_cv_aix_libpath__CXX\"; then\n    lt_cv_aix_libpath__CXX=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n  if test -z \"$lt_cv_aix_libpath__CXX\"; then\n    lt_cv_aix_libpath__CXX=/usr/lib:/lib\n  fi\n   ;;\nesac\nfi\n\n  aix_libpath=$lt_cv_aix_libpath__CXX\nfi\n\n          hardcode_libdir_flag_spec_CXX='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\n          archive_expsym_cmds_CXX='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n        else\n          if test ia64 = \"$host_cpu\"; then\n\t    hardcode_libdir_flag_spec_CXX='$wl-R $libdir:/usr/lib:/lib'\n\t    allow_undefined_flag_CXX=\"-z nodefs\"\n\t    archive_expsym_cmds_CXX=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n          else\n\t    # Determine the default libpath from the value encoded in an\n\t    # empty executable.\n\t    if test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  if test ${lt_cv_aix_libpath__CXX+y}\nthen :\n  printf %s \"(cached) \" >&6\nelse case e in #(\n  e) cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n/* end confdefs.h.  */\n\nint\nmain (void)\n{\n\n  ;\n  return 0;\n}\n_ACEOF\nif ac_fn_cxx_try_link \"$LINENO\"\nthen :\n\n  lt_aix_libpath_sed='\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }'\n  lt_cv_aix_libpath__CXX=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$lt_cv_aix_libpath__CXX\"; then\n    lt_cv_aix_libpath__CXX=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi\nfi\nrm -f core conftest.err conftest.$ac_objext conftest.beam \\\n    conftest$ac_exeext conftest.$ac_ext\n  if test -z \"$lt_cv_aix_libpath__CXX\"; then\n    lt_cv_aix_libpath__CXX=/usr/lib:/lib\n  fi\n   ;;\nesac\nfi\n\n  aix_libpath=$lt_cv_aix_libpath__CXX\nfi\n\n\t    hardcode_libdir_flag_spec_CXX='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t    # Warning - without using the other run time loading flags,\n\t    # -berok will link without error, but may produce a broken library.\n\t    no_undefined_flag_CXX=' $wl-bernotok'\n\t    allow_undefined_flag_CXX=' $wl-berok'\n\t    if test yes = \"$with_gnu_ld\"; then\n\t      # We only use this code for GNU lds that support --whole-archive.\n\t      whole_archive_flag_spec_CXX='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    else\n\t      # Exported symbols can be pulled into shared objects from archives\n\t      whole_archive_flag_spec_CXX='$convenience'\n\t    fi\n\t    archive_cmds_need_lc_CXX=yes\n\t    archive_expsym_cmds_CXX='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t    # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t    compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([, ]\\\\)%-berok\\\\1%g\"`'\n\t    if test svr4 != \"$with_aix_soname\"; then\n\t      # This is similar to how AIX traditionally builds its shared\n\t      # libraries. Need -bnortl late, we may have -brtl in LDFLAGS.\n\t      archive_expsym_cmds_CXX=\"$archive_expsym_cmds_CXX\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t    fi\n\t    if test aix != \"$with_aix_soname\"; then\n\t      archive_expsym_cmds_CXX=\"$archive_expsym_cmds_CXX\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t    else\n\t      # used by -dlpreopen to get the symbols\n\t      archive_expsym_cmds_CXX=\"$archive_expsym_cmds_CXX\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t    fi\n\t    archive_expsym_cmds_CXX=\"$archive_expsym_cmds_CXX\"'~$RM -r $output_objdir/$realname.d'\n          fi\n        fi\n        ;;\n\n      beos*)\n\tif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t  allow_undefined_flag_CXX=unsupported\n\t  # Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t  # support --undefined.  This deserves some investigation.  FIXME\n\t  archive_cmds_CXX='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\telse\n\t  ld_shlibs_CXX=no\n\tfi\n\t;;\n\n      chorus*)\n        case $cc_basename in\n          *)\n\t  # FIXME: insert proper C++ library support\n\t  ld_shlibs_CXX=no\n\t  ;;\n        esac\n        ;;\n\n      cygwin* | mingw* | pw32* | cegcc*)\n\tcase $GXX,$cc_basename in\n\t,cl* | no,cl* | ,icl* | no,icl*)\n\t  # Native MSVC or ICC\n\t  # hardcode_libdir_flag_spec is actually meaningless, as there is\n\t  # no search path for DLLs.\n\t  hardcode_libdir_flag_spec_CXX=' '\n\t  allow_undefined_flag_CXX=unsupported\n\t  always_export_symbols_CXX=yes\n\t  file_list_spec_CXX='@'\n\t  # Tell ltmain to make .lib files, not .a files.\n\t  libext=lib\n\t  # Tell ltmain to make .dll files, not .so files.\n\t  shrext_cmds=.dll\n\t  # FIXME: Setting linknames here is a bad hack.\n\t  archive_cmds_CXX='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t  archive_expsym_cmds_CXX='if   test DEF = \"`$SED -n     -e '\\''s/^[\t ]*//'\\''     -e '\\''/^\\(;.*\\)*$/d'\\''     -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p'\\''     -e q     $export_symbols`\" ; then\n              cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n              echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n            else\n              $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n            fi~\n            $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n            linknames='\n\t  # The linker will not automatically build a static lib if we build a DLL.\n\t  # _LT_TAGVAR(old_archive_from_new_cmds, CXX)='true'\n\t  enable_shared_with_static_runtimes_CXX=yes\n\t  # Don't use ranlib\n\t  old_postinstall_cmds_CXX='chmod 644 $oldlib'\n\t  postlink_cmds_CXX='lt_outputfile=\"@OUTPUT@\"~\n            lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n            case $lt_outputfile in\n              *.exe|*.EXE) ;;\n              *)\n                lt_outputfile=$lt_outputfile.exe\n                lt_tool_outputfile=$lt_tool_outputfile.exe\n                ;;\n            esac~\n            func_to_tool_file \"$lt_outputfile\"~\n            if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n              $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n              $RM \"$lt_outputfile.manifest\";\n            fi'\n\t  ;;\n\t*)\n\t  # g++\n\t  # _LT_TAGVAR(hardcode_libdir_flag_spec, CXX) is actually meaningless,\n\t  # as there is no search path for DLLs.\n\t  hardcode_libdir_flag_spec_CXX='-L$libdir'\n\t  export_dynamic_flag_spec_CXX='$wl--export-all-symbols'\n\t  allow_undefined_flag_CXX=unsupported\n\t  always_export_symbols_CXX=no\n\t  enable_shared_with_static_runtimes_CXX=yes\n\n\t  if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n\t    archive_cmds_CXX='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t    # If the export-symbols file already is a .def file, use it as\n\t    # is; otherwise, prepend EXPORTS...\n\t    archive_expsym_cmds_CXX='if   test DEF = \"`$SED -n     -e '\\''s/^[\t ]*//'\\''     -e '\\''/^\\(;.*\\)*$/d'\\''     -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p'\\''     -e q     $export_symbols`\" ; then\n              cp $export_symbols $output_objdir/$soname.def;\n            else\n              echo EXPORTS > $output_objdir/$soname.def;\n              cat $export_symbols >> $output_objdir/$soname.def;\n            fi~\n            $CC -shared -nostdlib $output_objdir/$soname.def $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t  else\n\t    ld_shlibs_CXX=no\n\t  fi\n\t  ;;\n\tesac\n\t;;\n      darwin* | rhapsody*)\n\n\n  archive_cmds_need_lc_CXX=no\n  hardcode_direct_CXX=no\n  hardcode_automatic_CXX=yes\n  hardcode_shlibpath_var_CXX=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    whole_archive_flag_spec_CXX='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n\n  else\n    whole_archive_flag_spec_CXX=''\n  fi\n  link_all_deplibs_CXX=yes\n  allow_undefined_flag_CXX=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    archive_cmds_CXX=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    module_cmds_CXX=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    archive_expsym_cmds_CXX=\"$SED 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    module_expsym_cmds_CXX=\"$SED -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n       if test yes != \"$lt_cv_apple_cc_single_mod\"; then\n      archive_cmds_CXX=\"\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dsymutil\"\n      archive_expsym_cmds_CXX=\"$SED 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dar_export_syms$_lt_dsymutil\"\n    fi\n\n  else\n  ld_shlibs_CXX=no\n  fi\n\n\t;;\n\n      os2*)\n\thardcode_libdir_flag_spec_CXX='-L$libdir'\n\thardcode_minus_L_CXX=yes\n\tallow_undefined_flag_CXX=unsupported\n\tshrext_cmds=.dll\n\tarchive_cmds_CXX='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  emxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\tarchive_expsym_cmds_CXX='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  prefix_cmds=\"$SED\"~\n\t  if test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t    prefix_cmds=\"$prefix_cmds -e 1d\";\n\t  fi~\n\t  prefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\t  cat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\told_archive_From_new_cmds_CXX='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n\tenable_shared_with_static_runtimes_CXX=yes\n\tfile_list_spec_CXX='@'\n\t;;\n\n      dgux*)\n        case $cc_basename in\n          ec++*)\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n          ghcx*)\n\t    # Green Hills C++ Compiler\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n        esac\n        ;;\n\n      freebsd2.*)\n        # C++ shared libraries reported to be fairly broken before\n\t# switch to ELF\n        ld_shlibs_CXX=no\n        ;;\n\n      freebsd-elf*)\n        archive_cmds_need_lc_CXX=no\n        ;;\n\n      freebsd* | dragonfly* | midnightbsd*)\n        # FreeBSD 3 and later use GNU C++ and GNU ld with standard ELF\n        # conventions\n        ld_shlibs_CXX=yes\n        ;;\n\n      haiku*)\n        archive_cmds_CXX='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n        link_all_deplibs_CXX=yes\n        ;;\n\n      hpux9*)\n        hardcode_libdir_flag_spec_CXX='$wl+b $wl$libdir'\n        hardcode_libdir_separator_CXX=:\n        export_dynamic_flag_spec_CXX='$wl-E'\n        hardcode_direct_CXX=yes\n        hardcode_minus_L_CXX=yes # Not in the search PATH,\n\t\t\t\t             # but as the default\n\t\t\t\t             # location of the library.\n\n        case $cc_basename in\n          CC*)\n            # FIXME: insert proper C++ library support\n            ld_shlibs_CXX=no\n            ;;\n          aCC*)\n            archive_cmds_CXX='$RM $output_objdir/$soname~$CC -b $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            # Commands to make compiler produce verbose output that lists\n            # what \"hidden\" libraries, object files and flags are used when\n            # linking a shared library.\n            #\n            # There doesn't appear to be a way to prevent this compiler from\n            # explicitly linking system object files so we need to strip them\n            # from the output so that they don't get included in the library\n            # dependencies.\n            output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $EGREP \" \\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n            ;;\n          *)\n            if test yes = \"$GXX\"; then\n              archive_cmds_CXX='$RM $output_objdir/$soname~$CC -shared -nostdlib $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            else\n              # FIXME: insert proper C++ library support\n              ld_shlibs_CXX=no\n            fi\n            ;;\n        esac\n        ;;\n\n      hpux10*|hpux11*)\n        if test no = \"$with_gnu_ld\"; then\n\t  hardcode_libdir_flag_spec_CXX='$wl+b $wl$libdir'\n\t  hardcode_libdir_separator_CXX=:\n\n          case $host_cpu in\n            hppa*64*|ia64*)\n              ;;\n            *)\n\t      export_dynamic_flag_spec_CXX='$wl-E'\n              ;;\n          esac\n        fi\n        case $host_cpu in\n          hppa*64*|ia64*)\n            hardcode_direct_CXX=no\n            hardcode_shlibpath_var_CXX=no\n            ;;\n          *)\n            hardcode_direct_CXX=yes\n            hardcode_direct_absolute_CXX=yes\n            hardcode_minus_L_CXX=yes # Not in the search PATH,\n\t\t\t\t\t         # but as the default\n\t\t\t\t\t         # location of the library.\n            ;;\n        esac\n\n        case $cc_basename in\n          CC*)\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n          aCC*)\n\t    case $host_cpu in\n\t      hppa*64*)\n\t        archive_cmds_CXX='$CC -b $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      ia64*)\n\t        archive_cmds_CXX='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      *)\n\t        archive_cmds_CXX='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t    esac\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $GREP \" \\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        case $host_cpu in\n\t          hppa*64*)\n\t            archive_cmds_CXX='$CC -shared -nostdlib -fPIC $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          ia64*)\n\t            archive_cmds_CXX='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          *)\n\t            archive_cmds_CXX='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t        esac\n\t      fi\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      ld_shlibs_CXX=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      interix[3-9]*)\n\thardcode_direct_CXX=no\n\thardcode_shlibpath_var_CXX=no\n\thardcode_libdir_flag_spec_CXX='$wl-rpath,$libdir'\n\texport_dynamic_flag_spec_CXX='$wl-E'\n\t# Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n\t# Instead, shared libraries are loaded at an image base (0x10000000 by\n\t# default) and relocated if they conflict, which is a slow very memory\n\t# consuming and fragmenting process.  To avoid this, we pick a random,\n\t# 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n\t# time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n\tarchive_cmds_CXX='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\tarchive_expsym_cmds_CXX='$SED \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t;;\n      irix5* | irix6*)\n        case $cc_basename in\n          CC*)\n\t    # SGI C++\n\t    archive_cmds_CXX='$CC -shared -all -multigot $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -ar\", where \"CC\" is the IRIX C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    old_archive_cmds_CXX='$CC -ar -WR,-u -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        archive_cmds_CXX='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t      else\n\t        archive_cmds_CXX='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` -o $lib'\n\t      fi\n\t    fi\n\t    link_all_deplibs_CXX=yes\n\t    ;;\n        esac\n        hardcode_libdir_flag_spec_CXX='$wl-rpath $wl$libdir'\n        hardcode_libdir_separator_CXX=:\n        inherit_rpath_CXX=yes\n        ;;\n\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    archive_cmds_CXX='tempext=`echo $shared_ext | $SED -e '\\''s/\\([^()0-9A-Za-z{}]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\t    archive_expsym_cmds_CXX='tempext=`echo $shared_ext | $SED -e '\\''s/\\([^()0-9A-Za-z{}]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib $wl-retain-symbols-file,$export_symbols; mv \\$templib $lib'\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1 | $GREP \"ld\"`; rm -f libconftest$shared_ext; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\n\t    hardcode_libdir_flag_spec_CXX='$wl-rpath,$libdir'\n\t    export_dynamic_flag_spec_CXX='$wl--export-dynamic'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -Bstatic\", where \"CC\" is the KAI C++ compiler.\n\t    old_archive_cmds_CXX='$CC -Bstatic -o $oldlib $oldobjs'\n\t    ;;\n\t  icpc* | ecpc* )\n\t    # Intel C++\n\t    with_gnu_ld=yes\n\t    # version 8.0 and above of icpc choke on multiply defined symbols\n\t    # if we add $predep_objects and $postdep_objects, however 7.1 and\n\t    # earlier do not add the objects themselves.\n\t    case `$CC -V 2>&1` in\n\t      *\"Version 7.\"*)\n\t        archive_cmds_CXX='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\tarchive_expsym_cmds_CXX='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t      *)  # Version 8.0 or newer\n\t        tmp_idyn=\n\t        case $host_cpu in\n\t\t  ia64*) tmp_idyn=' -i_dynamic';;\n\t\tesac\n\t        archive_cmds_CXX='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\tarchive_expsym_cmds_CXX='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t    esac\n\t    archive_cmds_need_lc_CXX=no\n\t    hardcode_libdir_flag_spec_CXX='$wl-rpath,$libdir'\n\t    export_dynamic_flag_spec_CXX='$wl--export-dynamic'\n\t    whole_archive_flag_spec_CXX='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    ;;\n          pgCC* | pgcpp*)\n            # Portland Group C++ compiler\n\t    case `$CC -V` in\n\t    *pgCC\\ [1-5].* | *pgcpp\\ [1-5].*)\n\t      prelink_cmds_CXX='tpldir=Template.dir~\n               rm -rf $tpldir~\n               $CC --prelink_objects --instantiation_dir $tpldir $objs $libobjs $compile_deplibs~\n               compile_command=\"$compile_command `find $tpldir -name \\*.o | sort | $NL2SP`\"'\n\t      old_archive_cmds_CXX='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $oldobjs$old_deplibs~\n                $AR $AR_FLAGS $oldlib$oldobjs$old_deplibs `find $tpldir -name \\*.o | sort | $NL2SP`~\n                $RANLIB $oldlib'\n\t      archive_cmds_CXX='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      archive_expsym_cmds_CXX='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    *) # Version 6 and above use weak symbols\n\t      archive_cmds_CXX='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      archive_expsym_cmds_CXX='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    esac\n\n\t    hardcode_libdir_flag_spec_CXX='$wl--rpath $wl$libdir'\n\t    export_dynamic_flag_spec_CXX='$wl--export-dynamic'\n\t    whole_archive_flag_spec_CXX='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n            ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    archive_cmds_CXX='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    archive_expsym_cmds_CXX='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname  -o $lib $wl-retain-symbols-file $wl$export_symbols'\n\n\t    runpath_var=LD_RUN_PATH\n\t    hardcode_libdir_flag_spec_CXX='-rpath $libdir'\n\t    hardcode_libdir_separator_CXX=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld .*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"X$list\" | $Xsed'\n\t    ;;\n\t  xl* | mpixl* | bgxl*)\n\t    # IBM XL 8.0 on PPC, with GNU ld\n\t    hardcode_libdir_flag_spec_CXX='$wl-rpath $wl$libdir'\n\t    export_dynamic_flag_spec_CXX='$wl--export-dynamic'\n\t    archive_cmds_CXX='$CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    if test yes = \"$supports_anon_versioning\"; then\n\t      archive_expsym_cmds_CXX='echo \"{ global:\" > $output_objdir/$libname.ver~\n                cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n                echo \"local: *; };\" >> $output_objdir/$libname.ver~\n                $CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n\t    fi\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | $SED 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      no_undefined_flag_CXX=' -zdefs'\n\t      archive_cmds_CXX='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t      archive_expsym_cmds_CXX='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file $wl$export_symbols'\n\t      hardcode_libdir_flag_spec_CXX='-R$libdir'\n\t      whole_archive_flag_spec_CXX='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t      compiler_needs_object_CXX=yes\n\n\t      # Not sure whether something based on\n\t      # $CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1\n\t      # would be better.\n\t      output_verbose_link_cmd='func_echo_all'\n\n\t      # Archives containing C++ object files must be created using\n\t      # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t      # necessary to make sure instantiated templates are included\n\t      # in the archive.\n\t      old_archive_cmds_CXX='$CC -xar -o $oldlib $oldobjs'\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n\n      lynxos*)\n        # FIXME: insert proper C++ library support\n\tld_shlibs_CXX=no\n\t;;\n\n      m88k*)\n        # FIXME: insert proper C++ library support\n        ld_shlibs_CXX=no\n\t;;\n\n      mvs*)\n        case $cc_basename in\n          cxx*)\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n\t  *)\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n\tesac\n\t;;\n\n      netbsd*)\n        if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t  archive_cmds_CXX='$LD -Bshareable  -o $lib $predep_objects $libobjs $deplibs $postdep_objects $linker_flags'\n\t  wlarc=\n\t  hardcode_libdir_flag_spec_CXX='-R$libdir'\n\t  hardcode_direct_CXX=yes\n\t  hardcode_shlibpath_var_CXX=no\n\tfi\n\t# Workaround some broken pre-1.5 toolchains\n\toutput_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP conftest.$objext | $SED -e \"s:-lgcc -lc -lgcc::\"'\n\t;;\n\n      *nto* | *qnx*)\n        ld_shlibs_CXX=yes\n\t;;\n\n      openbsd* | bitrig*)\n\tif test -f /usr/libexec/ld.so; then\n\t  hardcode_direct_CXX=yes\n\t  hardcode_shlibpath_var_CXX=no\n\t  hardcode_direct_absolute_CXX=yes\n\t  archive_cmds_CXX='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n\t  hardcode_libdir_flag_spec_CXX='$wl-rpath,$libdir'\n\t  if test -z \"`echo __ELF__ | $CC -E - | grep __ELF__`\"; then\n\t    archive_expsym_cmds_CXX='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file,$export_symbols -o $lib'\n\t    export_dynamic_flag_spec_CXX='$wl-E'\n\t    whole_archive_flag_spec_CXX=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n\t  fi\n\t  output_verbose_link_cmd=func_echo_all\n\telse\n\t  ld_shlibs_CXX=no\n\tfi\n\t;;\n\n      osf3* | osf4* | osf5*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    archive_cmds_CXX='tempext=`echo $shared_ext | $SED -e '\\''s/\\([^()0-9A-Za-z{}]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo \"$lib\" | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\n\t    hardcode_libdir_flag_spec_CXX='$wl-rpath,$libdir'\n\t    hardcode_libdir_separator_CXX=:\n\n\t    # Archives containing C++ object files must be created using\n\t    # the KAI C++ compiler.\n\t    case $host in\n\t      osf3*) old_archive_cmds_CXX='$CC -Bstatic -o $oldlib $oldobjs' ;;\n\t      *) old_archive_cmds_CXX='$CC -o $oldlib $oldobjs' ;;\n\t    esac\n\t    ;;\n          RCC*)\n\t    # Rational C++ 2.4.1\n\t    # FIXME: insert proper C++ library support\n\t    ld_shlibs_CXX=no\n\t    ;;\n          cxx*)\n\t    case $host in\n\t      osf3*)\n\t        allow_undefined_flag_CXX=' $wl-expect_unresolved $wl\\*'\n\t        archive_cmds_CXX='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        hardcode_libdir_flag_spec_CXX='$wl-rpath $wl$libdir'\n\t\t;;\n\t      *)\n\t        allow_undefined_flag_CXX=' -expect_unresolved \\*'\n\t        archive_cmds_CXX='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        archive_expsym_cmds_CXX='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done~\n                  echo \"-hidden\">> $lib.exp~\n                  $CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname $wl-input $wl$lib.exp  `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~\n                  $RM $lib.exp'\n\t        hardcode_libdir_flag_spec_CXX='-rpath $libdir'\n\t\t;;\n\t    esac\n\n\t    hardcode_libdir_separator_CXX=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\" | $GREP -v \"ld:\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld.*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$o"
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 16.2666015625,
          "content": "# This file is to be processed with autoconf to generate a configure script\n\ndnl Prologue\ndnl\n\nAC_INIT([slurm],m4_esyscmd([perl -ne 'print,exit if s/^\\s*VERSION:\\s*(\\d*.\\d*).\\S*/\\1/i' ./META | sed 's/^v//' | tr '-' '_' | tr -d '\\n']),[],[],[https://slurm.schedmd.com])\nAC_PREREQ([2.59])\nAC_CONFIG_SRCDIR([configure.ac])\nAC_CONFIG_AUX_DIR([auxdir])\nAC_CONFIG_MACRO_DIR([auxdir])\nAC_CANONICAL_TARGET([])\n\ndnl the is a generic flag to avoid building things\nAM_CONDITIONAL(DONT_BUILD, test \"1\" = \"0\")\n\n# Determine project/version from META file.\n# Sets PACKAGE, VERSION, SLURM_VERSION\nX_AC_SLURM_VERSION\n\ndnl Initialize Automake\ndnl\ndnl If you ever change to use AM_INIT_AUTOMAKE(subdir-objects) edit\ndnl auxdir/slurm.m4 to not define VERSION\ndnl\nAM_INIT_AUTOMAKE(no-define no-dist)\nAM_MAINTAINER_MODE\nAC_CONFIG_HEADERS([config.h])\nAC_CONFIG_HEADERS([slurm/slurm_version.h])\n\nX_AC_RPATH\n\ndnl This sets the first compiler to be C instead of C++.\nX_AC_DATABASES\n\ndnl Check to see if this architecture should use slurm_* prefix function\ndnl aliases for plugins.\ndnl\ncase \"$host\" in\n\t*darwin*) AC_DEFINE(USE_ALIAS, 0,\n\t\t\t[Define slurm_ prefix function aliases for plugins]) ;;\n\t*)        AC_DEFINE(USE_ALIAS, 1,\n\t\t\t[Define slurm_ prefix function aliases for plugins]) ;;\nesac\n\ndnl Checks for programs.\ndnl\nAC_PROG_CC\nAC_PROG_CXX\nAC_PROG_MAKE_SET\nLT_INIT\nX_AC_PKGCONFIG\n\ndnl Find objcopy and setup path\nAC_CHECK_TARGET_TOOL([OBJCOPY], objcopy, [], [])\n\ndnl Silence warning: ar: 'u' modifier ignored since 'D' is the default\ndnl\nAC_SUBST(AR_FLAGS, [cr])\n\nAM_CONDITIONAL(WITH_CXX, test -n \"$ac_ct_CXX\")\nAM_CONDITIONAL(WITH_GNU_LD, test \"$with_gnu_ld\" = \"yes\")\n\nAC_PATH_PROG([SLEEP_CMD], [sleep], [/bin/sleep])\nAC_DEFINE_UNQUOTED([SLEEP_CMD], [\"$SLEEP_CMD\"], [Define path to sleep command])\n\nAC_PATH_PROG([SUCMD], [su], [/bin/su])\nAC_DEFINE_UNQUOTED([SUCMD], [\"$SUCMD\"], [Define path to su command])\n\ndnl Checks for libraries\ndnl Includes workaround to disable -Werror=builtin-declaration-mismatch which\ndnl will cause errors on newer GCC, and can then lead to incorrect results.\nold_CFLAGS=$CFLAGS\nCFLAGS=\"$CFLAGS -Wno-builtin-declaration-mismatch\"\nAC_SEARCH_LIBS([socket],        [socket])\nAC_SEARCH_LIBS([gethostbyname], [nsl])\nAC_SEARCH_LIBS([hstrerror],     [resolv])\nAC_SEARCH_LIBS([kstat_open],    [kstat])\nAC_SEARCH_LIBS([ns_initparse],  [resolv])\nAC_SEARCH_LIBS([log],\t\t[m])\nAC_SEARCH_LIBS([lrint],\t\t[m])\nAC_SEARCH_LIBS([timer_create],\t[rt])\nAC_SEARCH_LIBS([dlopen],\t[dl svdl])\nCFLAGS=$old_CFLAGS\n\ndnl Checks for header files.\ndnl\nAC_CHECK_HEADERS(mcheck.h values.h socket.h sys/socket.h  \\\n\t\t stdbool.h sys/ipc.h sys/shm.h sys/sem.h errno.h \\\n\t\t stdlib.h dirent.h pthread.h sys/prctl.h \\\n\t\t sysint.h inttypes.h termcap.h netdb.h sys/socket.h  \\\n\t\t sys/systemcfg.h sys/dr.h sys/vfs.h \\\n\t\t pam/pam_appl.h security/pam_appl.h sys/sysctl.h \\\n\t\t pty.h utmp.h \\\n\t\t sys/syslog.h linux/sched.h \\\n\t\t kstat.h paths.h limits.h sys/statfs.h sys/ptrace.h \\\n\t\t float.h sys/statvfs.h\n\t\t)\nAC_HEADER_SYS_WAIT\n\n# Workaround for transition of autoconf/glibc issues in deprecation of the\n# definitions major, minor, makedev by sys/types.h vs sys/sysmacros.h\nold_CFLAGS=$CFLAGS\nCFLAGS=\"$CFLAGS -Werror\"\nAC_HEADER_MAJOR\nCFLAGS=$old_CFLAGS\n\ndnl check to see if glibc's program_invocation_name is available:\ndnl\nX_AC_SLURM_PROGRAM_INVOCATION_NAME\n\ndnl Check if ptrace takes four or five arguments\ndnl\nX_AC_PTRACE\n\ndnl Check of sched_getaffinity exists and it's argument count\ndnl\nX_AC_AFFINITY\n\ndnl\ndnl Check for PAM module support\nX_AC_PAM\n\ndnl\ndnl Check to see how we link to libslurm\nX_AC_LIBSLURM\n\ndnl\ndnl Check if we want to load .login with sbatch --get-user-env option\nX_AC_ENV_LOGIC\n\ndnl Checks for types.\ndnl\nX_AC_SLURM_BIGENDIAN\n\ndnl Check for C99 compatibility\ndnl\nX_AC_C99\n\ndnl Force -fno-omit-frame-pointer compiler flag if available\ndnl\nAX_CHECK_COMPILE_FLAG([-fno-omit-frame-pointer],\n\t\t      [CFLAGS=\"$CFLAGS -fno-omit-frame-pointer\"])\n\ndnl check for presumed size of uid_t and gid_t\nX_AC_UID_GID_SIZE_CHECK\n\ndnl Check for JSON parser\nX_AC_JSON\n\ndnl Check for JWT library\nX_AC_JWT\n\ndnl Check for HTTP parser\nX_AC_HTTP_PARSER\n\ndnl Check for yaml parser\nX_AC_YAML\n\ndnl Check for epoll support\nAX_HAVE_EPOLL()\nif test \"x$ax_cv_have_epoll\" = \"xyes\"; then\n\tAC_DEFINE(HAVE_EPOLL, 1, [Define to 1 if we have epoll(7) support])\nfi\nAM_CONDITIONAL(HAVE_EPOLL, [test \"x$ax_cv_have_epoll\" = \"xyes\" ])\n\nAX_GCC_BUILTIN(__builtin_bswap64)\nAX_GCC_BUILTIN(__builtin_clzll)\nAX_GCC_BUILTIN(__builtin_ctzll)\nAX_GCC_BUILTIN(__builtin_popcountll)\n\n\ndnl checks for library functions.\ndnl\nAC_FUNC_STRERROR_R\nAC_CHECK_FUNCS( \\\n   fdatasync \\\n   hstrerror \\\n   strerror  \\\n   mtrace    \\\n   strndup   \\\n   strlcpy   \\\n   strsignal \\\n   inet_aton \\\n   inet_ntop \\\n   inet_pton \\\n   setproctitle \\\n   sysctlbyname \\\n   cfmakeraw \\\n   setresuid \\\n   get_current_dir_name \\\n   faccessat \\\n   eaccess \\\n   statvfs \\\n   statfs \\\n   memfd_create \\\n   getrandom \\\n)\n\nAC_CHECK_DECLS([hstrerror, strsignal, sys_siglist])\n\ndnl Skip pthread checks on macOS as support is always enabled,\ndnl and AX_PTHREAD will inject flags that will throw spurious warnings.\ncase \"$host\" in\n*-darwin*)\n\t;;\n*)\n\tAX_PTHREAD([], AC_MSG_ERROR([Error: Cannot figure out how to use pthreads!]))\n\t;;\nesac\n\nLDFLAGS=\"$LDFLAGS \"\nCFLAGS=\"$CFLAGS $PTHREAD_CFLAGS\"\nLIBS=\"$PTHREAD_LIBS $LIBS\"\n\nX_AC_DIMENSIONS\n\nX_AC_OFED\n\nAX_LIB_HDF5()\nAM_CONDITIONAL(BUILD_HDF5, test \"$with_hdf5\" = \"yes\")\n# Some systems don't configure HDF5 with --with-default-api-version=v18\n# which creates problems for slurm because slurm uses the 1.8 API.\n# For hdf5 1.8, define H5_NO_DEPRECATED_SYMBOLS, otherwise use H5_USE_18_API\n# to request the right api version.\nAX_COMPARE_VERSION($[HDF5_VERSION], [eq0], [1.8],\n\t[AC_DEFINE([H5_NO_DEPRECATED_SYMBOLS], [1], [Use the 1.8 HDF5 API])],\n\t[AC_DEFINE([H5_USE_18_API], [1], [Make sure we get the 1.8 HDF5 API])])\n\nX_AC_LZ4\nX_AC_HWLOC\nX_AC_NVML\nX_AC_RSMI\nX_AC_ONEAPI\nX_AC_PMIX\nX_AC_FREEIPMI\nX_AC_UCX\nX_AC_X11\nX_AC_SELINUX\nX_AC_RDKAFKA\nX_AC_S2N\n\nX_AC_CGROUP\nX_AC_BPF\nX_AC_DBUS\n\n#\n#  Tests for Check\n#\n\nPKG_CHECK_MODULES([CHECK], [check >= 0.9.8], [ac_have_check=\"yes\"], [ac_have_check=\"no\"])\nAM_CONDITIONAL(HAVE_CHECK, test \"x$ac_have_check\" = \"xyes\")\n\nX_AC_SVIEW\nX_AC_HPE_SLINGSHOT\n\ndnl checks for system services.\ndnl\n\n\ndnl checks for system-specific stuff.\ndnl\n\ndnl check for how to emulate setproctitle\ndnl\nX_AC_SETPROCTITLE\n\ndnl check for debug compilation\ndnl\nX_AC_DEBUG\n\ndnl check for slurmctld, slurmd and slurmdbd default ports,\ndnl and default number of slurmctld ports\ndnl\nX_AC_SLURM_PORTS([6817], [6818], [6819], [1])\n\n\ndnl add SLURM_PREFIX to config.h\ndnl\nif test \"x$prefix\" = \"xNONE\" ; then\n  AC_DEFINE_UNQUOTED(SLURM_PREFIX, \"/usr/local\", [Define Slurm installation prefix])\nelse\n  AC_DEFINE_UNQUOTED(SLURM_PREFIX, \"$prefix\", [Define Slurm installation prefix])\nfi\nAC_SUBST(SLURM_PREFIX)\n\nX_AC_SLURMRESTD([6820])\n\ndnl check for lua library\ndnl\nX_AC_LUA\n\ndnl check for presence of the man2html command\ndnl\nX_AC_MAN2HTML\nAM_CONDITIONAL(HAVE_MAN2HTML, test \"x$ac_have_man2html\" = \"xyes\")\nAC_SUBST(HAVE_MAN2HTML)\n\n\ndnl check if we can use standard printf functions\ndnl\nX_AC_PRINTF_NULL\n\ndnl Check for whether to include readline support\ndnl\nX_AC_READLINE\n\ndnl\ndnl Check for systemd presence, version and system unit dir\ndnl\nX_AC_SYSTEMD\n\ndnl\ndnl Check for compilation of Slurm auth modules:\ndnl\nX_AC_MUNGE\n\ndnl\ndnl Check if multiple-slurmd support is requested and define MULTIPLE_SLURMD\ndnl if it is.\ndnl\nAC_MSG_CHECKING(whether to enable multiple-slurmd support)\nAC_ARG_ENABLE([multiple-slurmd],\n  AS_HELP_STRING(--enable-multiple-slurmd,enable multiple-slurmd support),\n    [ case \"$enableval\" in\n      yes) multiple_slurmd=yes ;;\n      no)  multiple_slurmd=no ;;\n      *)   AC_MSG_ERROR([bad value \"$enableval\" for --enable-multiple-slurmd]);;\n    esac ]\n)\nif test \"x$multiple_slurmd\" = \"xyes\"; then\n  AC_DEFINE([MULTIPLE_SLURMD], [1], [Enable multiple slurmd on one node])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\nsavedLIBS=\"$LIBS\"\nLIBS=\"-lutil $LIBS\"\nAC_CHECK_LIB(util, openpty, [UTIL_LIBS=\"-lutil\"], [])\nAC_SUBST(UTIL_LIBS)\nLIBS=\"$savedLIBS\"\n\ndnl\ndnl Check for compilation of Slurm with CURL support:\ndnl\nLIBCURL_CHECK_CONFIG\n\ndnl Check word size so we can deprecate 32-bit systems\nAC_CHECK_SIZEOF([void *], 8)\n\ndnl This needs to come last so it can detect deprecated options in use.\nX_AC_DEPRECATED\n\ndnl All slurm Makefiles:\n\nAC_CONFIG_FILES([Makefile\n\t\t auxdir/Makefile\n\t\t contribs/Makefile\n\t\t contribs/lua/Makefile\n\t\t contribs/nss_slurm/Makefile\n\t\t contribs/openlava/Makefile\n\t\t contribs/pam/Makefile\n\t\t contribs/pam_slurm_adopt/Makefile\n\t\t contribs/perlapi/Makefile\n\t\t contribs/perlapi/libslurm/Makefile\n\t\t contribs/perlapi/libslurm/perl/Makefile.PL\n\t\t contribs/perlapi/libslurmdb/Makefile\n\t\t contribs/perlapi/libslurmdb/perl/Makefile.PL\n\t\t contribs/pmi/Makefile\n\t\t contribs/pmi2/Makefile\n\t\t contribs/seff/Makefile\n\t\t contribs/sgather/Makefile\n\t\t contribs/sjobexit/Makefile\n\t\t contribs/slurm_completion_help/Makefile\n\t\t contribs/torque/Makefile\n\t\t doc/Makefile\n\t\t doc/html/Makefile\n\t\t doc/html/configurator.easy.html\n\t\t doc/html/configurator.html\n\t\t doc/man/Makefile\n\t\t doc/man/man1/Makefile\n\t\t doc/man/man5/Makefile\n\t\t doc/man/man8/Makefile\n\t\t etc/Makefile\n\t\t src/Makefile\n\t\t src/api/Makefile\n\t\t src/bcast/Makefile\n\t\t src/common/Makefile\n\t\t src/conmgr/Makefile\n\t\t src/curl/Makefile\n\t\t src/database/Makefile\n\t\t src/interfaces/Makefile\n\t\t src/lua/Makefile\n\t\t src/plugins/Makefile\n\t\t src/plugins/accounting_storage/Makefile\n\t\t src/plugins/accounting_storage/common/Makefile\n\t\t src/plugins/accounting_storage/ctld_relay/Makefile\n\t\t src/plugins/accounting_storage/mysql/Makefile\n\t\t src/plugins/accounting_storage/slurmdbd/Makefile\n\t\t src/plugins/acct_gather_energy/Makefile\n\t\t src/plugins/acct_gather_energy/gpu/Makefile\n\t\t src/plugins/acct_gather_energy/ibmaem/Makefile\n\t\t src/plugins/acct_gather_energy/ipmi/Makefile\n\t\t src/plugins/acct_gather_energy/pm_counters/Makefile\n\t\t src/plugins/acct_gather_energy/rapl/Makefile\n\t\t src/plugins/acct_gather_energy/xcc/Makefile\n\t\t src/plugins/acct_gather_filesystem/Makefile\n\t\t src/plugins/acct_gather_filesystem/lustre/Makefile\n\t\t src/plugins/acct_gather_interconnect/Makefile\n\t\t src/plugins/acct_gather_interconnect/ofed/Makefile\n\t\t src/plugins/acct_gather_interconnect/sysfs/Makefile\n\t\t src/plugins/acct_gather_profile/Makefile\n\t\t src/plugins/acct_gather_profile/hdf5/Makefile\n\t\t src/plugins/acct_gather_profile/hdf5/sh5util/Makefile\n\t\t src/plugins/acct_gather_profile/influxdb/Makefile\n\t\t src/plugins/auth/Makefile\n\t\t src/plugins/auth/jwt/Makefile\n\t\t src/plugins/auth/munge/Makefile\n\t\t src/plugins/auth/none/Makefile\n\t\t src/plugins/auth/slurm/Makefile\n\t\t src/plugins/burst_buffer/Makefile\n\t\t src/plugins/burst_buffer/common/Makefile\n\t\t src/plugins/burst_buffer/datawarp/Makefile\n\t\t src/plugins/burst_buffer/lua/Makefile\n\t\t src/plugins/certmgr/Makefile\n\t\t src/plugins/certmgr/script/Makefile\n\t\t src/plugins/cgroup/Makefile\n\t\t src/plugins/cgroup/common/Makefile\n\t\t src/plugins/cgroup/v1/Makefile\n\t\t src/plugins/cgroup/v2/Makefile\n\t\t src/plugins/cli_filter/Makefile\n\t\t src/plugins/cli_filter/common/Makefile\n\t\t src/plugins/cli_filter/lua/Makefile\n\t\t src/plugins/cli_filter/syslog/Makefile\n\t\t src/plugins/cli_filter/user_defaults/Makefile\n\t\t src/plugins/cred/Makefile\n\t\t src/plugins/cred/common/Makefile\n\t\t src/plugins/cred/munge/Makefile\n\t\t src/plugins/cred/none/Makefile\n\t\t src/plugins/data_parser/Makefile\n\t\t src/plugins/data_parser/v0.0.40/Makefile\n\t\t src/plugins/data_parser/v0.0.41/Makefile\n\t\t src/plugins/data_parser/v0.0.42/Makefile\n\t\t src/plugins/data_parser/v0.0.43/Makefile\n\t\t src/plugins/gpu/Makefile\n\t\t src/plugins/gpu/common/Makefile\n\t\t src/plugins/gpu/generic/Makefile\n\t\t src/plugins/gpu/nrt/Makefile\n\t\t src/plugins/gpu/nvidia/Makefile\n\t\t src/plugins/gpu/nvml/Makefile\n\t\t src/plugins/gpu/oneapi/Makefile\n\t\t src/plugins/gpu/rsmi/Makefile\n\t\t src/plugins/gres/Makefile\n\t\t src/plugins/gres/common/Makefile\n\t\t src/plugins/gres/gpu/Makefile\n\t\t src/plugins/gres/mps/Makefile\n\t\t src/plugins/gres/nic/Makefile\n\t\t src/plugins/gres/shard/Makefile\n\t\t src/plugins/hash/Makefile\n\t\t src/plugins/hash/common_xkcp/Makefile\n\t\t src/plugins/hash/k12/Makefile\n\t\t src/plugins/hash/sha3/Makefile\n\t\t src/plugins/job_container/Makefile\n\t\t src/plugins/job_container/tmpfs/Makefile\n\t\t src/plugins/job_submit/Makefile\n\t\t src/plugins/job_submit/all_partitions/Makefile\n\t\t src/plugins/job_submit/defaults/Makefile\n\t\t src/plugins/job_submit/logging/Makefile\n\t\t src/plugins/job_submit/lua/Makefile\n\t\t src/plugins/job_submit/partition/Makefile\n\t\t src/plugins/job_submit/pbs/Makefile\n\t\t src/plugins/job_submit/require_timelimit/Makefile\n\t\t src/plugins/job_submit/throttle/Makefile\n\t\t src/plugins/jobacct_gather/Makefile\n\t\t src/plugins/jobacct_gather/cgroup/Makefile\n\t\t src/plugins/jobacct_gather/common/Makefile\n\t\t src/plugins/jobacct_gather/linux/Makefile\n\t\t src/plugins/jobcomp/Makefile\n\t\t src/plugins/jobcomp/common/Makefile\n\t\t src/plugins/jobcomp/elasticsearch/Makefile\n\t\t src/plugins/jobcomp/filetxt/Makefile\n\t\t src/plugins/jobcomp/kafka/Makefile\n\t\t src/plugins/jobcomp/lua/Makefile\n\t\t src/plugins/jobcomp/mysql/Makefile\n\t\t src/plugins/jobcomp/script/Makefile\n\t\t src/plugins/mcs/Makefile\n\t\t src/plugins/mcs/account/Makefile\n\t\t src/plugins/mcs/group/Makefile\n\t\t src/plugins/mcs/label/Makefile\n\t\t src/plugins/mcs/user/Makefile\n\t\t src/plugins/mpi/Makefile\n\t\t src/plugins/mpi/cray_shasta/Makefile\n\t\t src/plugins/mpi/pmi2/Makefile\n\t\t src/plugins/mpi/pmix/Makefile\n\t\t src/plugins/node_features/Makefile\n\t\t src/plugins/node_features/helpers/Makefile\n\t\t src/plugins/node_features/knl_generic/Makefile\n\t\t src/plugins/preempt/Makefile\n\t\t src/plugins/preempt/partition_prio/Makefile\n\t\t src/plugins/preempt/qos/Makefile\n\t\t src/plugins/prep/Makefile\n\t\t src/plugins/prep/script/Makefile\n\t\t src/plugins/priority/Makefile\n\t\t src/plugins/priority/basic/Makefile\n\t\t src/plugins/priority/multifactor/Makefile\n\t\t src/plugins/proctrack/Makefile\n\t\t src/plugins/proctrack/cgroup/Makefile\n\t\t src/plugins/proctrack/linuxproc/Makefile\n\t\t src/plugins/proctrack/pgid/Makefile\n\t\t src/plugins/sched/Makefile\n\t\t src/plugins/sched/backfill/Makefile\n\t\t src/plugins/sched/builtin/Makefile\n\t\t src/plugins/select/Makefile\n\t\t src/plugins/select/cons_tres/Makefile\n\t\t src/plugins/select/linear/Makefile\n\t\t src/plugins/serializer/Makefile\n\t\t src/plugins/serializer/json/Makefile\n\t\t src/plugins/serializer/url-encoded/Makefile\n\t\t src/plugins/serializer/yaml/Makefile\n\t\t src/plugins/site_factor/Makefile\n\t\t src/plugins/site_factor/example/Makefile\n\t\t src/plugins/switch/Makefile\n\t\t src/plugins/switch/hpe_slingshot/Makefile\n\t\t src/plugins/switch/nvidia_imex/Makefile\n\t\t src/plugins/task/Makefile\n\t\t src/plugins/task/affinity/Makefile\n\t\t src/plugins/task/cgroup/Makefile\n\t\t src/plugins/tls/Makefile\n\t\t src/plugins/tls/none/Makefile\n\t\t src/plugins/tls/s2n/Makefile\n\t\t src/plugins/topology/Makefile\n\t\t src/plugins/topology/3d_torus/Makefile\n\t\t src/plugins/topology/block/Makefile\n\t\t src/plugins/topology/common/Makefile\n\t\t src/plugins/topology/default/Makefile\n\t\t src/plugins/topology/tree/Makefile\n\t\t src/sacct/Makefile\n\t\t src/sackd/Makefile\n\t\t src/sacctmgr/Makefile\n\t\t src/salloc/Makefile\n\t\t src/sattach/Makefile\n\t\t src/scrun/Makefile\n\t\t src/sbatch/Makefile\n\t\t src/sbcast/Makefile\n\t\t src/scancel/Makefile\n\t\t src/scontrol/Makefile\n\t\t src/scrontab/Makefile\n\t\t src/sdiag/Makefile\n\t\t src/sinfo/Makefile\n\t\t src/slurmctld/Makefile\n\t\t src/slurmd/Makefile\n\t\t src/slurmd/common/Makefile\n\t\t src/slurmd/slurmd/Makefile\n\t\t src/slurmd/slurmstepd/Makefile\n\t\t src/slurmdbd/Makefile\n\t\t src/slurmrestd/Makefile\n\t\t src/slurmrestd/plugins/Makefile\n\t\t src/slurmrestd/plugins/auth/Makefile\n\t\t src/slurmrestd/plugins/auth/jwt/Makefile\n\t\t src/slurmrestd/plugins/auth/local/Makefile\n\t\t src/slurmrestd/plugins/openapi/Makefile\n\t\t src/slurmrestd/plugins/openapi/slurmctld/Makefile\n\t\t src/slurmrestd/plugins/openapi/slurmdbd/Makefile\n\t\t src/sprio/Makefile\n\t\t src/squeue/Makefile\n\t\t src/sreport/Makefile\n\t\t src/srun/Makefile\n\t\t src/sshare/Makefile\n\t\t src/sstat/Makefile\n\t\t src/stepmgr/Makefile\n\t\t src/strigger/Makefile\n\t\t src/sview/Makefile\n\t\t testsuite/Makefile\n\t\t testsuite/testsuite.conf.sample\n\t\t testsuite/expect/Makefile\n\t\t testsuite/slurm_unit/Makefile\n\t\t testsuite/slurm_unit/backfill/Makefile\n\t\t testsuite/slurm_unit/common/Makefile\n\t\t testsuite/slurm_unit/common/bitstring/Makefile\n\t\t testsuite/slurm_unit/common/hostlist/Makefile\n\t\t testsuite/slurm_unit/common/slurm_protocol_defs/Makefile\n\t\t testsuite/slurm_unit/common/slurm_protocol_pack/Makefile\n\t\t testsuite/slurm_unit/common/slurmdb_defs/Makefile\n\t\t testsuite/slurm_unit/common/slurmdb_pack/Makefile\n\t\t testsuite/slurm_unit/topology/Makefile\n\t\t ]\n)\n\nAC_OUTPUT\n"
        },
        {
          "name": "contribs",
          "type": "tree",
          "content": null
        },
        {
          "name": "debian",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "etc",
          "type": "tree",
          "content": null
        },
        {
          "name": "make_ref.include",
          "type": "blob",
          "size": 1.7138671875,
          "content": "# This is common code for a Makefile.am and creates $(LIB_REF) to be used\n# afterwards in noinst_LTLIBRARIES and EXTRA_slurmrestd_DEPENDENCIES\n#\n# usage\n#\n# REF = usage.txt\n# include $(top_srcdir)/make_ref.include\n# noinst_LTLIBRARIES [+]= $(LIB_REF)\n# EXTRA_$PROGRAMNAME_DEPENDENCIES [+]= $(LIB_REF)\n# $PROGRAMNAME_LDADD += $(LIB_REF)\n#\n# What the above lines do is include this file in a Makefile.am\n# It will insert usage.txt as a variable that the calling program can access\n# with the calls in src/common/ref.h.\n#\n# If I where doing this for the slurmrestd I would put 'slurmrestd' in for\n# $PROGRAMNAME i.e. EXTRA_slurmrestd_DEPENDENCIES, slurmrestd_LDADD.\n\n\nCLEANFILES = *.bino\n\nBIN_REF = $(REF:.txt=.bino)\n\n%.bino: %.txt\n\t$(AM_V_GEN)curr_dir=$(shell pwd); cd $(abs_srcdir); $(LD) -r -o \"$(abs_builddir)/$*.bino\" -z noexecstack --format=binary \"$(notdir $<)\"; cd $$curr_dir\n\t$(AM_V_at)@OBJCOPY@ --rename-section .data=.rodata,alloc,load,readonly,data,contents \"$*.bino\"\n\nlib_ref.lo: $(BIN_REF)\n\t$(AM_V_at)echo \"# $@ - a libtool object file\" >\"$@\"\n\t$(AM_V_at)echo \"# Generated by libtool\" >>\"$@\"\n\t$(AM_V_at)echo \"# (Not really... but we need libtool to believe it was.)\" >>\"$@\"\n\t$(AM_V_at)echo \"#\" >>\"$@\"\n\t$(AM_V_at)echo \"# Please DO NOT delete this file!\" >>\"$@\"\n\t$(AM_V_at)echo \"# It is necessary for linking the library.\" >>\"$@\"\n\t$(AM_V_at)echo >>\"$@\"\n\t$(AM_V_at)echo \"# Name of the PIC object.\" >>\"$@\"\n\t$(AM_V_at)echo \"pic_object='$(BIN_REF)'\" >>\"$@\"\n\t$(AM_V_at)echo >>\"$@\"\n\t$(AM_V_at)echo \"# Name of the non-PIC object\" >>\"$@\"\n\t$(AM_V_at)echo \"non_pic_object=''\" >>\"$@\"\n\t$(AM_V_at)echo >>\"$@\"\n\nLIB_REF = lib_ref.la\n\n# a blank lib_ref_la_SOURCES is needed for 'make cscope' to work correctly.\nlib_ref_la_SOURCES =\nlib_ref_la_LIBADD = lib_ref.lo\n"
        },
        {
          "name": "slurm.spec",
          "type": "blob",
          "size": 24.9990234375,
          "content": "Name:\t\tslurm\nVersion:\t24.11.0\n%define rel\t1\n%if %{defined patch} && %{undefined extraver}\n%define extraver .patched\n%endif\nRelease:\t%{rel}%{?extraver}%{?dist}\nSummary:\tSlurm Workload Manager\n\nGroup:\t\tSystem Environment/Base\nLicense:\tGPLv2+\nURL:\t\thttps://slurm.schedmd.com/\n\n# when the rel number is one, the directory name does not include it\n%if \"%{rel}\" == \"1\"\n%global slurm_source_dir %{name}-%{version}\n%else\n%global slurm_source_dir %{name}-%{version}-%{rel}\n%endif\n\nSource:\t\t%{slurm_source_dir}.tar.bz2\n%{lua: local patchnum=0\n  for pfile in string.gmatch(rpm.expand(\"%{?patch}\"), \"%S+\") do\n    print('Patch'..patchnum..':\\t'..pfile..'\\n')\n    patchnum=patchnum+1\n  end\n}\n\n# build options\t\t.rpmmacros options\tchange to default action\n# ====================  ====================\t========================\n# --prefix\t\t%_prefix path\t\tinstall path for commands, libraries, etc.\n# --with cray_shasta\t%_with_cray_shasta 1\tbuild for a Cray Shasta system\n# --with slurmrestd\t%_with_slurmrestd 1\tbuild slurmrestd\n# --with yaml\t\t%_with_yaml 1\t\tbuild with yaml serializer\n# --without debug\t%_without_debug 1\tdon't compile with debugging symbols\n# --with hdf5\t\t%_with_hdf5 path\trequire hdf5 support\n# --with hwloc\t\t%_with_hwloc 1\t\trequire hwloc support\n# --with libcurl\t%_with_libcurl 1\trequire libcurl support\n# --with lua\t\t%_with_lua path\t\tbuild Slurm lua bindings\n# --without munge\t%_without_munge 1\tdisable support for munge\n# --with numa\t\t%_with_numa 1\t\trequire NUMA support\n# --without pam\t\t%_without_pam 1\t\tdon't require pam-devel RPM to be installed\n# --without x11\t\t%_without_x11 1\t\tdisable internal X11 support\n# --with ucx\t\t%_with_ucx path\t\trequire ucx support\n# --with pmix\t\t%_with_pmix path\tbuild with pmix support\n# --with nvml\t\t%_with_nvml path\trequire nvml support\n# --with jwt\t\t%_with_jwt 1\t\trequire jwt support\n# --with freeipmi\t%_with_freeipmi 1\trequire freeipmi support\n# --with selinux\t%_with_selinux 1\tbuild with selinux support\n#\n\n#  Options that are off by default (enable with --with <opt>)\n%bcond_with cray_shasta\n%bcond_with slurmrestd\n%bcond_with multiple_slurmd\n%bcond_with pmix\n%bcond_with ucx\n\n# These options are only here to force there to be these on the build.\n# If they are not set they will still be compiled if the packages exist.\n%bcond_with hwloc\n%bcond_with hdf5\n%bcond_with libcurl\n%bcond_with lua\n%bcond_with numa\n%bcond_with nvml\n%bcond_with jwt\n%bcond_with yaml\n%bcond_with freeipmi\n\n# Use debug by default on all systems\n%bcond_without debug\n\n# Options enabled by default\n%bcond_without munge\n%bcond_without pam\n%bcond_without x11\n\n# Disable hardened builds. -z,now or -z,relro breaks the plugin stack\n%undefine _hardened_build\n%global _hardened_cflags \"-Wl,-z,lazy\"\n%global _hardened_ldflags \"-Wl,-z,lazy\"\n\n# Disable Link Time Optimization (LTO)\n%define _lto_cflags %{nil}\n\nBuildRequires:  autoconf\nBuildRequires:  automake\nBuildRequires:  gcc\nBuildRequires:  make\n%if %{defined suse_version}\nBuildRequires: pkg-config\n%else\n%if (0%{?rhel} != 7)\nBuildRequires:  pkgconf\n%else\nBuildRequires:  pkgconfig\n%endif\n%endif\n\n%if %{with munge}\nRequires: munge\nBuildRequires: munge-devel munge-libs\n%endif\n\nRequires: bash-completion\n\n%{?systemd_requires}\nBuildRequires: systemd\nBuildRequires: python3\nBuildRequires: readline-devel\nObsoletes: slurm-lua <= %{version}\nObsoletes: slurm-munge <= %{version}\nObsoletes: slurm-plugins <= %{version}\n\n# fake systemd support when building rpms on other platforms\n%{!?_unitdir: %global _unitdir /lib/systemd/systemd}\n\n%define use_mysql_devel %(perl -e '`rpm -q mysql-devel`; print !$?;')\n# Default for OpenSUSE/SLES builds\n%define use_libmariadb_devel %(perl -e '`rpm -q libmariadb-devel`; print !$?;')\n# Package name from the official MariaDB version\n%define use_MariaDB_devel %(perl -e '`rpm -q MariaDB-devel`; print !$?;')\n# Oracle mysql community\n%define use_mysql_community %(perl -e '`rpm -q mysql-community-devel`; print !$?;')\n# Oracle mysql commercial\n%define use_mysql_commercial %(perl -e '`rpm -q mysql-commercial-devel`; print !$?;')\n\n%if 0%{?use_mysql_devel}\nBuildRequires: mysql-devel >= 5.0.0\n%else\n%if 0%{?use_mysql_community}\nBuildRequires: mysql-community-devel >= 5.0.0\n%else\n%if 0%{?use_mysql_commercial}\nBuildRequires: mysql-commercial-devel >= 5.0.0\n%else\n%if 0%{?use_libmariadb_devel}\n# OpenSUSE/SLES has a different versioning scheme, so skip the version check\nBuildRequires: libmariadb-devel\n%else\n%if 0%{?use_MariaDB_devel}\nBuildRequires: MariaDB-devel >= 5.0.0\n%else\nBuildRequires: mariadb-devel >= 5.0.0\n%endif\n%endif\n%endif\n%endif\n%endif\n\nBuildRequires: perl(ExtUtils::MakeMaker)\n%if %{defined suse_version}\nBuildRequires: perl\n%else\nBuildRequires: perl-devel\n%endif\n\n%if %{with lua}\nBuildRequires: pkgconfig(lua) >= 5.1.0\n%endif\n\n%if %{with hwloc} && \"%{_with_hwloc}\" == \"--with-hwloc\"\nBuildRequires: hwloc-devel\n%endif\n\n%if %{with numa}\n%if %{defined suse_version}\nBuildRequires: libnuma-devel\n%else\nBuildRequires: numactl-devel\n%endif\n%endif\n\n%if %{with pmix} && \"%{_with_pmix}\" == \"--with-pmix\"\nBuildRequires: pmix\n%global pmix_version %(rpm -q pmix --qf \"%{RPMTAG_VERSION}\")\n%endif\n\n%if %{with ucx} && \"%{_with_ucx}\" == \"--with-ucx\"\nBuildRequires: ucx-devel\n%global ucx_version %(rpm -q ucx-devel --qf \"%{RPMTAG_VERSION}\")\n%endif\n\n%if %{with libcurl}\n%if %{defined suse_version}\nRequires: libcurl\n%else\nRequires: libcurl4\n%endif\nBuildRequires: libcurl-devel\n%endif\n\n%if %{with jwt}\nBuildRequires: libjwt-devel >= 1.10.0\nRequires: libjwt >= 1.10.0\n%endif\n\n%if %{with yaml}\nRequires: libyaml >= 0.2.5\nBuildRequires: libyaml-devel >= 0.2.5\n%endif\n\n%if %{with freeipmi}\nRequires: freeipmi\nBuildRequires: freeipmi-devel\n%endif\n\n%if %{with selinux}\nRequires: libselinux\nBuildRequires: libselinux-devel\n%endif\n\n#  Allow override of sysconfdir via _slurm_sysconfdir.\n#  Note 'global' instead of 'define' needed here to work around apparent\n#   bug in rpm macro scoping (or something...)\n%{!?_slurm_sysconfdir: %global _slurm_sysconfdir /etc/slurm}\n%define _sysconfdir %_slurm_sysconfdir\n\n#  Allow override of datadir via _slurm_datadir.\n%{!?_slurm_datadir: %global _slurm_datadir %{_prefix}/share}\n%define _datadir %{_slurm_datadir}\n\n#  Allow override of mandir via _slurm_mandir.\n%{!?_slurm_mandir: %global _slurm_mandir %{_datadir}/man}\n%define _mandir %{_slurm_mandir}\n\n#\n# Never allow rpm to strip binaries as this will break\n#  parallel debugging capability\n# Note that brp-compress does not compress man pages installed\n#  into non-standard locations (e.g. /usr/local)\n#\n%define __os_install_post /usr/lib/rpm/brp-compress\n%define debug_package %{nil}\n\n#\n# Should unpackaged files in a build root terminate a build?\n# Uncomment if needed again.\n#%define _unpackaged_files_terminate_build      0\n\n# Slurm may intentionally include empty manifest files, which will\n# cause errors with rpm 4.13 and on. Turn that check off.\n%define _empty_manifest_terminate_build 0\n\n# First we remove $prefix/local and then just prefix to make\n# sure we get the correct installdir\n%define _perlarch %(perl -e 'use Config; $T=$Config{installsitearch}; $P=$Config{installprefix}; $P1=\"$P/local\"; $T =~ s/$P1//; $T =~ s/$P//; print $T;')\n\n%define _perlman3 %(perl -e 'use Config; $T=$Config{installsiteman3dir}; $P=$Config{siteprefix}; $P1=\"$P/local\"; $T =~ s/$P1//; $T =~ s/$P//; print $T;')\n\n%define _perlarchlib %(perl -e 'use Config; $T=$Config{installarchlib}; $P=$Config{installprefix}; $P1=\"$P/local\"; $T =~ s/$P1//; $T =~ s/$P//; print $T;')\n\n%define _perldir %{_prefix}%{_perlarch}\n%define _perlman3dir %{_prefix}%{_perlman3}\n%define _perlarchlibdir %{_prefix}%{_perlarchlib}\n\n%description\nSlurm is an open source, fault-tolerant, and highly scalable\ncluster management and job scheduling system for Linux clusters.\nComponents include machine status, partition management,\njob management, scheduling and accounting modules\n\n%package perlapi\nSummary: Perl API to Slurm\nGroup: Development/System\nRequires: %{name}%{?_isa} = %{version}-%{release}\n%description perlapi\nPerl API package for Slurm.  This package includes the perl API to provide a\nhelpful interface to Slurm through Perl\n\n%package devel\nSummary: Development package for Slurm\nGroup: Development/System\nRequires: %{name}%{?_isa} = %{version}-%{release}\n%description devel\nDevelopment package for Slurm.  This package includes the header files\nand static libraries for the Slurm API\n\n%package example-configs\nSummary: Example config files for Slurm\nGroup: Development/System\n%description example-configs\nExample configuration files for Slurm.\n\n%package sackd\nSummary: Slurm authentication daemon\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\n%description sackd\nSlurm authentication daemon. Used on login nodes that are not running slurmd\ndaemons to allow authentication to the cluster.\n\n%package slurmctld\nSummary: Slurm controller daemon\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\n%if %{with pmix} && \"%{_with_pmix}\" == \"--with-pmix\"\nRequires: pmix = %{pmix_version}\n%endif\n%if %{with ucx} && \"%{_with_ucx}\" == \"--with-ucx\"\nRequires: ucx = %{ucx_version}\n%endif\n%description slurmctld\nSlurm controller daemon. Used to manage the job queue, schedule jobs,\nand dispatch RPC messages to the slurmd processon the compute nodes\nto launch jobs.\n\n%package slurmd\nSummary: Slurm compute node daemon\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\n%if %{with pmix} && \"%{_with_pmix}\" == \"--with-pmix\"\nRequires: pmix = %{pmix_version}\n%endif\n%if %{with ucx} && \"%{_with_ucx}\" == \"--with-ucx\"\nRequires: ucx = %{ucx_version}\n%endif\n%description slurmd\nSlurm compute node daemon. Used to launch jobs on compute nodes\n\n%package slurmdbd\nSummary: Slurm database daemon\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\nObsoletes: slurm-sql <= %{version}\n%description slurmdbd\nSlurm database daemon. Used to accept and process database RPCs and upload\ndatabase changes to slurmctld daemons on each cluster\n\n%package libpmi\nSummary: Slurm\\'s implementation of the pmi libraries\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\nConflicts: pmix-libpmi\n%description libpmi\nSlurm\\'s version of libpmi. For systems using Slurm, this version\nis preferred over the compatibility libraries shipped by the PMIx project.\n\n%package torque\nSummary: Torque/PBS wrappers for transition from Torque/PBS to Slurm\nGroup: Development/System\nRequires: slurm-perlapi\n%description torque\nTorque wrapper scripts used for helping migrate from Torque/PBS to Slurm\n\n%package openlava\nSummary: openlava/LSF wrappers for transition from OpenLava/LSF to Slurm\nGroup: Development/System\nRequires: slurm-perlapi\n%description openlava\nOpenLava wrapper scripts used for helping migrate from OpenLava/LSF to Slurm\n\n%package contribs\nSummary: Perl tool to print Slurm job state information\nGroup: Development/System\nRequires: %{name}%{?_isa} = %{version}-%{release}\nObsoletes: slurm-sjobexit <= %{version}\nObsoletes: slurm-sjstat <= %{version}\nObsoletes: slurm-seff <= %{version}\n%description contribs\nseff is a mail program used directly by the Slurm daemons. On completion of a\njob, wait for it's accounting information to be available and include that\ninformation in the email body.\nsjobexit is a slurm job exit code management tool. It enables users to alter\njob exit code information for completed jobs\nsjstat is a Perl tool to print Slurm job state information. The output is designed\nto give information on the resource usage and availablilty, as well as information\nabout jobs that are currently active on the machine. This output is built\nusing the Slurm utilities, sinfo, squeue and scontrol, the man pages for these\nutilities will provide more information and greater depth of understanding.\n\n%if %{with pam}\n%package pam_slurm\nSummary: PAM module for restricting access to compute nodes via Slurm\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\nBuildRequires: pam-devel\nObsoletes: pam_slurm <= %{version}\n%description pam_slurm\nThis module restricts access to compute nodes in a cluster where Slurm is in\nuse.  Access is granted to root, any user with an Slurm-launched job currently\nrunning on the node, or any user who has allocated resources on the node\naccording to the Slurm\n%endif\n\n%if %{with slurmrestd}\n%package slurmrestd\nSummary: Slurm REST API translator\nGroup: System Environment/Base\nRequires: %{name}%{?_isa} = %{version}-%{release}\nBuildRequires: http-parser-devel\n%if %{defined suse_version}\nBuildRequires: libjson-c-devel\n%else\nBuildRequires: json-c-devel\n%endif\n%description slurmrestd\nProvides a REST interface to Slurm.\n%endif\n\n#############################################################################\n\n%prep\n# when the rel number is one, the tarball filename does not include it\n%setup -n %{slurm_source_dir}\n%global _default_patch_fuzz 2\n%autopatch -p1\n\n%build\n%configure \\\n\t--with-systemdsystemunitdir=%{_unitdir} \\\n\t--enable-pkgconfig \\\n\t%{?_without_debug:--disable-debug} \\\n\t%{?_with_pam_dir} \\\n\t%{?_with_mysql_config} \\\n\t%{?_with_multiple_slurmd:--enable-multiple-slurmd} \\\n\t%{?_with_selinux:--enable-selinux} \\\n\t%{?_with_pmix} \\\n\t%{?_with_freeipmi} \\\n\t%{?_with_hdf5} \\\n\t%{?_with_hwloc} \\\n\t%{?_with_shared_libslurm} \\\n\t%{!?_with_slurmrestd:--disable-slurmrestd} \\\n\t%{?_without_x11:--disable-x11} \\\n\t%{?_with_libcurl} \\\n\t%{?_with_ucx} \\\n\t%{?_with_jwt} \\\n\t%{?_with_yaml} \\\n\t%{?_with_nvml} \\\n\t%{?_with_freeipmi} \\\n\t%{!?with_munge:--without-munge} \\\n\t%{?_with_cflags}\n\nmake %{?_smp_mflags}\n\n%install\n\n# Ignore redundant standard rpaths and insecure relative rpaths,\n# for RHEL based distros which use \"check-rpaths\" tool.\nexport QA_RPATHS=0x5\n\n# Strip out some dependencies\n\ncat > find-requires.sh <<'EOF'\nexec %{__find_requires} \"$@\" | grep -E -v '^libpmix.so|libevent|libnvidia-ml'\nEOF\nchmod +x find-requires.sh\n%global _use_internal_dependency_generator 0\n%global __find_requires %{_builddir}/%{buildsubdir}/find-requires.sh\n\nrm -rf %{buildroot}\nmake install DESTDIR=%{buildroot}\nmake install-contrib DESTDIR=%{buildroot}\n\n# Do not package Slurm's version of libpmi on Cray systems in the usual location.\n# Cray's version of libpmi should be used. Move it elsewhere if the site still\n# wants to use it with other MPI stacks.\n%if %{with cray_shasta}\n   mkdir %{buildroot}/%{_libdir}/slurmpmi\n   mv %{buildroot}/%{_libdir}/libpmi* %{buildroot}/%{_libdir}/slurmpmi\n%endif\n\ninstall -D -m644 etc/cgroup.conf.example %{buildroot}/%{_sysconfdir}/cgroup.conf.example\ninstall -D -m644 etc/prolog.example %{buildroot}/%{_sysconfdir}/prolog.example\ninstall -D -m644 etc/job_submit.lua.example %{buildroot}/%{_sysconfdir}/job_submit.lua.example\ninstall -D -m644 etc/slurm.conf.example %{buildroot}/%{_sysconfdir}/slurm.conf.example\ninstall -D -m600 etc/slurmdbd.conf.example %{buildroot}/%{_sysconfdir}/slurmdbd.conf.example\ninstall -D -m644 etc/cli_filter.lua.example %{buildroot}/%{_sysconfdir}/cli_filter.lua.example\ninstall -D -m755 contribs/sjstat %{buildroot}/%{_bindir}/sjstat\n\n# Delete unpackaged files:\nfind %{buildroot} -name '*.a' -exec rm {} \\;\nfind %{buildroot} -name '*.la' -exec rm {} \\;\nrm -f %{buildroot}/%{_libdir}/slurm/job_submit_defaults.so\nrm -f %{buildroot}/%{_libdir}/slurm/job_submit_logging.so\nrm -f %{buildroot}/%{_libdir}/slurm/job_submit_partition.so\nrm -f %{buildroot}/%{_libdir}/slurm/auth_none.so\nrm -f %{buildroot}/%{_libdir}/slurm/cred_none.so\nrm -f %{buildroot}/%{_sbindir}/sfree\nrm -f %{buildroot}/%{_sbindir}/slurm_epilog\nrm -f %{buildroot}/%{_sbindir}/slurm_prolog\nrm -f %{buildroot}/%{_sysconfdir}/init.d/slurm\nrm -f %{buildroot}/%{_sysconfdir}/init.d/slurmdbd\nrm -f %{buildroot}/%{_perldir}/auto/Slurm/.packlist\nrm -f %{buildroot}/%{_perldir}/auto/Slurm/Slurm.bs\nrm -f %{buildroot}/%{_perlarchlibdir}/perllocal.pod\nrm -f %{buildroot}/%{_perldir}/perllocal.pod\nrm -f %{buildroot}/%{_perldir}/auto/Slurmdb/.packlist\nrm -f %{buildroot}/%{_perldir}/auto/Slurmdb/Slurmdb.bs\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sacct\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sacctmgr\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/salloc\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sattach\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sbatch\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sbcast\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/scancel\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/scontrol\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/scrontab\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sdiag\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sinfo\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/slurmrestd\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sprio\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/squeue\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sreport\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/srun\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sshare\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/sstat\nrm -f %{buildroot}/%{_datadir}/bash-completion/completions/strigger\n\n# Build man pages that are generated directly by the tools\nrm -f %{buildroot}/%{_mandir}/man1/sjobexitmod.1\n%{buildroot}/%{_bindir}/sjobexitmod --roff > %{buildroot}/%{_mandir}/man1/sjobexitmod.1\nrm -f %{buildroot}/%{_mandir}/man1/sjstat.1\n%{buildroot}/%{_bindir}/sjstat --roff > %{buildroot}/%{_mandir}/man1/sjstat.1\n\nLIST=./pam.files\ntouch $LIST\n%if %{?with_pam_dir}0\n    test -f %{buildroot}/%{with_pam_dir}/pam_slurm.so\t&&\n\techo %{with_pam_dir}/pam_slurm.so\t>>$LIST\n    test -f %{buildroot}/%{with_pam_dir}/pam_slurm_adopt.so\t&&\n\techo %{with_pam_dir}/pam_slurm_adopt.so\t>>$LIST\n%else\n    test -f %{buildroot}/lib/security/pam_slurm.so\t&&\n\techo /lib/security/pam_slurm.so\t\t>>$LIST\n    test -f %{buildroot}/lib32/security/pam_slurm.so\t&&\n\techo /lib32/security/pam_slurm.so\t>>$LIST\n    test -f %{buildroot}/lib64/security/pam_slurm.so\t&&\n\techo /lib64/security/pam_slurm.so\t>>$LIST\n    test -f %{buildroot}/lib/security/pam_slurm_adopt.so\t\t&&\n\techo /lib/security/pam_slurm_adopt.so\t\t>>$LIST\n    test -f %{buildroot}/lib32/security/pam_slurm_adopt.so\t\t&&\n\techo /lib32/security/pam_slurm_adopt.so\t\t>>$LIST\n    test -f %{buildroot}/lib64/security/pam_slurm_adopt.so\t\t&&\n\techo /lib64/security/pam_slurm_adopt.so\t\t>>$LIST\n%endif\n#############################################################################\n\n%clean\nrm -rf %{buildroot}\n#############################################################################\n\n%files\n%defattr(-,root,root,0755)\n%{_datadir}/doc\n%{_bindir}/s*\n%exclude %{_bindir}/seff\n%exclude %{_bindir}/sjobexitmod\n%exclude %{_bindir}/sjstat\n%exclude %{_bindir}/smail\n%exclude %{_libdir}/libpmi*\n%{_libdir}/*.so*\n%{_libdir}/slurm/src/*\n%{_libdir}/slurm/*.so\n%exclude %{_libdir}/slurm/accounting_storage_mysql.so\n%exclude %{_libdir}/slurm/job_submit_pbs.so\n%exclude %{_libdir}/slurm/spank_pbs.so\n%{_mandir}\n%exclude %{_mandir}/man1/sjobexit*\n%exclude %{_mandir}/man1/sjstat*\n%dir %{_libdir}/slurm/src\n%{_datadir}/bash-completion/completions/slurm_completion.sh\n#############################################################################\n\n%files example-configs\n%defattr(-,root,root,0755)\n%dir %{_sysconfdir}\n%config %{_sysconfdir}/cgroup.conf.example\n%config %{_sysconfdir}/job_submit.lua.example\n%config %{_sysconfdir}/prolog.example\n%config %{_sysconfdir}/slurm.conf.example\n%config %{_sysconfdir}/slurmdbd.conf.example\n%config %{_sysconfdir}/cli_filter.lua.example\n#############################################################################\n\n%files devel\n%defattr(-,root,root)\n%dir %attr(0755,root,root)\n%dir %{_prefix}/include/slurm\n%{_prefix}/include/slurm/*\n%{_libdir}/pkgconfig/slurm.pc\n#############################################################################\n\n%files perlapi\n%defattr(-,root,root)\n%{_perldir}/Slurm.pm\n%{_perldir}/Slurm/Bitstr.pm\n%{_perldir}/Slurm/Constant.pm\n%{_perldir}/Slurm/Hostlist.pm\n%{_perldir}/auto/Slurm/Slurm.so\n%{_perldir}/Slurmdb.pm\n%{_perldir}/auto/Slurmdb/Slurmdb.so\n%{_perldir}/auto/Slurmdb/autosplit.ix\n%{_perlman3dir}/Slurm*\n\n#############################################################################\n\n%files sackd\n%defattr(-,root,root)\n%{_sbindir}/sackd\n%{_unitdir}/sackd.service\n#############################################################################\n\n%files slurmctld\n%defattr(-,root,root)\n%{_sbindir}/slurmctld\n%{_unitdir}/slurmctld.service\n#############################################################################\n\n%files slurmd\n%defattr(-,root,root)\n%{_sbindir}/slurmd\n%{_sbindir}/slurmstepd\n%{_unitdir}/slurmd.service\n#############################################################################\n\n%files slurmdbd\n%defattr(-,root,root)\n%{_sbindir}/slurmdbd\n%{_libdir}/slurm/accounting_storage_mysql.so\n%{_unitdir}/slurmdbd.service\n#############################################################################\n\n%files libpmi\n%defattr(-,root,root)\n%if %{with cray_shasta}\n%{_libdir}/slurmpmi/*\n%else\n%{_libdir}/libpmi*\n%endif\n#############################################################################\n\n%files torque\n%defattr(-,root,root)\n%{_bindir}/pbsnodes\n%{_bindir}/qalter\n%{_bindir}/qdel\n%{_bindir}/qhold\n%{_bindir}/qrerun\n%{_bindir}/qrls\n%{_bindir}/qstat\n%{_bindir}/qsub\n%{_bindir}/mpiexec\n%{_bindir}/generate_pbs_nodefile\n%{_libdir}/slurm/job_submit_pbs.so\n%{_libdir}/slurm/spank_pbs.so\n#############################################################################\n\n%files openlava\n%defattr(-,root,root)\n%{_bindir}/bjobs\n%{_bindir}/bkill\n%{_bindir}/bsub\n%{_bindir}/lsid\n\n#############################################################################\n\n%files contribs\n%defattr(-,root,root)\n%{_bindir}/seff\n%{_bindir}/sjobexitmod\n%{_bindir}/sjstat\n%{_bindir}/smail\n%{_mandir}/man1/sjstat*\n#############################################################################\n\n%if %{with pam}\n%files -f pam.files pam_slurm\n%defattr(-,root,root)\n%endif\n#############################################################################\n\n%if %{with slurmrestd}\n%files slurmrestd\n%{_sbindir}/slurmrestd\n%{_unitdir}/slurmrestd.service\n%endif\n#############################################################################\n\n%pre\n\n%post\n/sbin/ldconfig\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sacct}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sacctmgr}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,salloc}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sattach}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sbatch}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sbcast}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,scancel}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,scontrol}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,scrontab}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sdiag}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sinfo}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,slurmrestd}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sprio}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,squeue}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sreport}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,srun}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sshare}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,sstat}\nln -sf %{_datadir}/bash-completion/completions/{slurm_completion.sh,strigger}\n\n%preun\n\n%postun\n/sbin/ldconfig\nif [ $1 -eq 0 ]; then\n\trm -f %{_datadir}/bash-completion/completions/sacct\n\trm -f %{_datadir}/bash-completion/completions/sacctmgr\n\trm -f %{_datadir}/bash-completion/completions/salloc\n\trm -f %{_datadir}/bash-completion/completions/sattach\n\trm -f %{_datadir}/bash-completion/completions/sbatch\n\trm -f %{_datadir}/bash-completion/completions/sbcast\n\trm -f %{_datadir}/bash-completion/completions/scancel\n\trm -f %{_datadir}/bash-completion/completions/scontrol\n\trm -f %{_datadir}/bash-completion/completions/scrontab\n\trm -f %{_datadir}/bash-completion/completions/sdiag\n\trm -f %{_datadir}/bash-completion/completions/sinfo\n\trm -f %{_datadir}/bash-completion/completions/slurmrestd\n\trm -f %{_datadir}/bash-completion/completions/sprio\n\trm -f %{_datadir}/bash-completion/completions/squeue\n\trm -f %{_datadir}/bash-completion/completions/sreport\n\trm -f %{_datadir}/bash-completion/completions/srun\n\trm -f %{_datadir}/bash-completion/completions/sshare\n\trm -f %{_datadir}/bash-completion/completions/sstat\n\trm -f %{_datadir}/bash-completion/completions/strigger\nfi\n\n%post sackd\n%systemd_post sackd.service\n%preun sackd\n%systemd_preun sackd.service\n%postun sackd\n%systemd_postun_with_restart sackd.service\n\n%post slurmctld\n%systemd_post slurmctld.service\n%preun slurmctld\n%systemd_preun slurmctld.service\n%postun slurmctld\n%systemd_postun_with_restart slurmctld.service\n\n%post slurmd\n%systemd_post slurmd.service\n%preun slurmd\n%systemd_preun slurmd.service\n%postun slurmd\n%systemd_postun_with_restart slurmd.service\n\n%post slurmdbd\n%systemd_post slurmdbd.service\n%preun slurmdbd\n%systemd_preun slurmdbd.service\n%postun slurmdbd\n%systemd_postun_with_restart slurmdbd.service\n%if %{defined patch}\n%changelog\n* %(date \"+%a %b %d %Y\") %{?packager} - %{version}-%{release}\n- Includes patch: %{patch}\n%endif\n"
        },
        {
          "name": "slurm",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "testsuite",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}