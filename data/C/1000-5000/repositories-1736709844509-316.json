{
  "metadata": {
    "timestamp": 1736709844509,
    "page": 316,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "FreeRTOS/FreeRTOS-Kernel",
      "stars": 2937,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.333984375,
          "content": "# Normalize line endings and whitespace\nddd1e30018e74ad293cda0635018d636a6657f57\n\n# Convert tabs to spaces (4)\n8c77117c32e49a5070cd85e8920c36723997e465\n\n# Apply uncrustify rules\n587a83d647619bb0a508661c7bb4d6df89851582\n2c530ba5c352fdf420d1b13709a3970f04e9e6c6\n718178c68a1c863dd1a2eac7aea326a789d3bc52\na5dbc2b1de17e5468420d5a928d7392d799780e2\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.013671875,
          "content": "*   text=auto\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.380859375,
          "content": "[submodule \"ThirdParty/FreeRTOS-Kernel-Partner-Supported-Ports\"]\n\tpath = portable/ThirdParty/Partner-Supported-Ports\n\turl = https://github.com/FreeRTOS/FreeRTOS-Kernel-Partner-Supported-Ports\n[submodule \"ThirdParty/FreeRTOS-Kernel-Community-Supported-Ports\"]\n\tpath = portable/ThirdParty/Community-Supported-Ports\n\turl = https://github.com/FreeRTOS/FreeRTOS-Kernel-Community-Supported-Ports\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 19.642578125,
          "content": "cmake_minimum_required(VERSION 3.15)\n\n# User is responsible to one mandatory option:\n#   FREERTOS_PORT, if not specified and native port detected, uses the native compile.\n#\n# User is responsible for one library target:\n#   freertos_config ,typically an INTERFACE library\n#\n# DEPRECATED: FREERTOS_CONFIG_FILE_DIRECTORY - but still supported if no freertos_config defined for now.\n#             May be removed at some point in the future.\n#\n# User can choose which heap implementation to use (either the implementations\n# included with FreeRTOS [1..5] or a custom implementation) by providing the\n# option FREERTOS_HEAP. When dynamic allocation is used, the user must specify a\n# heap implementation. If the option is not set, the cmake will use no heap\n# implementation (e.g. when only static allocation is used).\n\n# `freertos_config` target defines the path to FreeRTOSConfig.h and optionally other freertos based config files\nif(NOT TARGET freertos_config )\n    if (NOT DEFINED FREERTOS_CONFIG_FILE_DIRECTORY )\n\n        message(FATAL_ERROR \" freertos_config target not specified.  Please specify a cmake target that defines the include directory for FreeRTOSConfig.h:\\n\"\n            \"  add_library(freertos_config INTERFACE)\\n\"\n            \"  target_include_directories(freertos_config SYSTEM\\n\"\n            \"    INTERFACE\\n\"\n            \"      include) # The config file directory\\n\"\n            \"  target_compile_definitions(freertos_config\\n\"\n            \"    PUBLIC\\n\"\n            \"    projCOVERAGE_TEST=0)\\n\")\n    else()\n        message(WARNING \" Using deprecated 'FREERTOS_CONFIG_FILE_DIRECTORY' - please update your project CMakeLists.txt file:\\n\"\n            \"  add_library(freertos_config INTERFACE)\\n\"\n            \"  target_include_directories(freertos_config SYSTEM\\n\"\n            \"    INTERFACE\\n\"\n            \"      include) # The config file directory\\n\"\n            \"  target_compile_definitions(freertos_config\\n\"\n            \"    PUBLIC\\n\"\n            \"    projCOVERAGE_TEST=0)\\n\")\n    endif()\nendif()\n\n# FreeRTOS port option\nif(NOT FREERTOS_PORT)\n    message(WARNING \" FREERTOS_PORT is not set. Please specify it from top-level CMake file (example):\\n\"\n        \"  set(FREERTOS_PORT GCC_ARM_CM4F CACHE STRING \\\"\\\")\\n\"\n        \" or from CMake command line option:\\n\"\n        \"  -DFREERTOS_PORT=GCC_ARM_CM4F\\n\"\n        \" \\n\"\n        \" Available port options:\\n\"\n        \" A_CUSTOM_PORT                    - Compiler: User Defined  Target: User Defined\\n\"\n        \" BCC_16BIT_DOS_FLSH186            - Compiler: BCC           Target: 16 bit DOS Flsh186\\n\"\n        \" BCC_16BIT_DOS_PC                 - Compiler: BCC           Target: 16 bit DOS PC\\n\"\n        \" CCS_ARM_CM3                      - Compiler: CCS           Target: ARM Cortex-M3\\n\"\n        \" CCS_ARM_CM4F                     - Compiler: CCS           Target: ARM Cortex-M4 with FPU\\n\"\n        \" CCS_ARM_CR4                      - Compiler: CCS           Target: ARM Cortex-R4\\n\"\n        \" CCS_MSP430X                      - Compiler: CCS           Target: MSP430X\\n\"\n        \" CODEWARRIOR_COLDFIRE_V1          - Compiler: CoreWarrior   Target: ColdFire V1\\n\"\n        \" CODEWARRIOR_COLDFIRE_V2          - Compiler: CoreWarrior   Target: ColdFire V2\\n\"\n        \" CODEWARRIOR_HCS12                - Compiler: CoreWarrior   Target: HCS12\\n\"\n        \" GCC_ARM_CA9                      - Compiler: GCC           Target: ARM Cortex-A9\\n\"\n        \" GCC_ARM_AARCH64                  - Compiler: GCC           Target: ARM v8-A\\n\"\n        \" GCC_ARM_AARCH64_SRE              - Compiler: GCC           Target: ARM v8-A SRE\\n\"\n        \" GCC_ARM_CM0                      - Compiler: GCC           Target: ARM Cortex-M0\\n\"\n        \" GCC_ARM_CM3                      - Compiler: GCC           Target: ARM Cortex-M3\\n\"\n        \" GCC_ARM_CM3_MPU                  - Compiler: GCC           Target: ARM Cortex-M3 with MPU\\n\"\n        \" GCC_ARM_CM4_MPU                  - Compiler: GCC           Target: ARM Cortex-M4 with MPU\\n\"\n        \" GCC_ARM_CM4F                     - Compiler: GCC           Target: ARM Cortex-M4 with FPU\\n\"\n        \" GCC_ARM_CM7                      - Compiler: GCC           Target: ARM Cortex-M7\\n\"\n        \" GCC_ARM_CM23_NONSECURE           - Compiler: GCC           Target: ARM Cortex-M23 non-secure\\n\"\n        \" GCC_ARM_CM23_SECURE              - Compiler: GCC           Target: ARM Cortex-M23 secure\\n\"\n        \" GCC_ARM_CM23_NTZ_NONSECURE       - Compiler: GCC           Target: ARM Cortex-M23 non-trustzone non-secure\\n\"\n        \" GCC_ARM_CM33_NONSECURE           - Compiler: GCC           Target: ARM Cortex-M33 non-secure\\n\"\n        \" GCC_ARM_CM33_SECURE              - Compiler: GCC           Target: ARM Cortex-M33 secure\\n\"\n        \" GCC_ARM_CM33_NTZ_NONSECURE       - Compiler: GCC           Target: ARM Cortex-M33 non-trustzone non-secure\\n\"\n        \" GCC_ARM_CM33_TFM                 - Compiler: GCC           Target: ARM Cortex-M33 non-secure for TF-M\\n\"\n        \" GCC_ARM_CM35P_NONSECURE          - Compiler: GCC           Target: ARM Cortex-M35P non-secure\\n\"\n        \" GCC_ARM_CM35P_SECURE             - Compiler: GCC           Target: ARM Cortex-M35P secure\\n\"\n        \" GCC_ARM_CM35P_NTZ_NONSECURE      - Compiler: GCC           Target: ARM Cortex-M35P non-trustzone non-secure\\n\"\n        \" GCC_ARM_CM55_NONSECURE           - Compiler: GCC           Target: ARM Cortex-M55 non-secure\\n\"\n        \" GCC_ARM_CM55_SECURE              - Compiler: GCC           Target: ARM Cortex-M55 secure\\n\"\n        \" GCC_ARM_CM55_NTZ_NONSECURE       - Compiler: GCC           Target: ARM Cortex-M55 non-trustzone non-secure\\n\"\n        \" GCC_ARM_CM55_TFM                 - Compiler: GCC           Target: ARM Cortex-M55 non-secure for TF-M\\n\"\n        \" GCC_ARM_CM85_NONSECURE           - Compiler: GCC           Target: ARM Cortex-M85 non-secure\\n\"\n        \" GCC_ARM_CM85_SECURE              - Compiler: GCC           Target: ARM Cortex-M85 secure\\n\"\n        \" GCC_ARM_CM85_NTZ_NONSECURE       - Compiler: GCC           Target: ARM Cortex-M85 non-trustzone non-secure\\n\"\n        \" GCC_ARM_CM85_TFM                 - Compiler: GCC           Target: ARM Cortex-M85 non-secure for TF-M\\n\"\n        \" GCC_ARM_CR5                      - Compiler: GCC           Target: ARM Cortex-R5\\n\"\n        \" GCC_ARM_CRX_MPU                  - Compiler: GCC           Target: ARM Cortex-Rx with MPU\\n\"\n        \" GCC_ARM_CRX_NOGIC                - Compiler: GCC           Target: ARM Cortex-Rx no GIC\\n\"\n        \" GCC_ARM7_AT91FR40008             - Compiler: GCC           Target: ARM7 Atmel AT91R40008\\n\"\n        \" GCC_ARM7_AT91SAM7S               - Compiler: GCC           Target: ARM7 Atmel AT91SAM7S\\n\"\n        \" GCC_ARM7_LPC2000                 - Compiler: GCC           Target: ARM7 LPC2000\\n\"\n        \" GCC_ARM7_LPC23XX                 - Compiler: GCC           Target: ARM7 LPC23xx\\n\"\n        \" GCC_ATMEGA323                    - Compiler: GCC           Target: ATMega323\\n\"\n        \" GCC_AVR32_UC3                    - Compiler: GCC           Target: AVR32 UC3\\n\"\n        \" GCC_COLDFIRE_V2                  - Compiler: GCC           Target: ColdFire V2\\n\"\n        \" GCC_CORTUS_APS3                  - Compiler: GCC           Target: CORTUS APS3\\n\"\n        \" GCC_H8S2329                      - Compiler: GCC           Target: H8S2329\\n\"\n        \" GCC_HCS12                        - Compiler: GCC           Target: HCS12\\n\"\n        \" GCC_IA32_FLAT                    - Compiler: GCC           Target: IA32 flat\\n\"\n        \" GCC_MICROBLAZE                   - Compiler: GCC           Target: MicroBlaze\\n\"\n        \" GCC_MICROBLAZE_V8                - Compiler: GCC           Target: MicroBlaze V8\\n\"\n        \" GCC_MICROBLAZE_V9                - Compiler: GCC           Target: MicroBlaze V9\\n\"\n        \" GCC_MSP430F449                   - Compiler: GCC           Target: MSP430F449\\n\"\n        \" GCC_NIOSII                       - Compiler: GCC           Target: NiosII\\n\"\n        \" GCC_PPC405_XILINX                - Compiler: GCC           Target: Xilinx PPC405\\n\"\n        \" GCC_PPC440_XILINX                - Compiler: GCC           Target: Xilinx PPC440\\n\"\n        \" GCC_RISC_V                       - Compiler: GCC           Target: RISC-V\\n\"\n        \" GCC_RISC_V_PULPINO_VEGA_RV32M1RM - Compiler: GCC           Target: RISC-V Pulpino Vega RV32M1RM\\n\"\n        \" GCC_RISC_V_GENERIC               - Compiler: GCC           Target: RISC-V with FREERTOS_RISCV_EXTENSION\\n\"\n        \" GCC_RL78                         - Compiler: GCC           Target: Renesas RL78\\n\"\n        \" GCC_RX100                        - Compiler: GCC           Target: Renesas RX100\\n\"\n        \" GCC_RX200                        - Compiler: GCC           Target: Renesas RX200\\n\"\n        \" GCC_RX600                        - Compiler: GCC           Target: Renesas RX600\\n\"\n        \" GCC_RX600_V2                     - Compiler: GCC           Target: Renesas RX600 v2\\n\"\n        \" GCC_RX700_V3_DPFPU               - Compiler: GCC           Target: Renesas RX700 v3 with DPFPU\\n\"\n        \" GCC_STR75X                       - Compiler: GCC           Target: STR75x\\n\"\n        \" GCC_TRICORE_1782                 - Compiler: GCC           Target: TriCore 1782\\n\"\n        \" GCC_ARC_EM_HS                    - Compiler: GCC           Target: DesignWare ARC EM HS\\n\"\n        \" GCC_ARC_V1                       - Compiler: GCC           Target: DesignWare ARC v1\\n\"\n        \" GCC_ATMEGA                       - Compiler: GCC           Target: ATmega\\n\"\n        \" GCC_POSIX                        - Compiler: GCC           Target: Posix\\n\"\n        \" GCC_RP2040                       - Compiler: GCC           Target: RP2040 ARM Cortex-M0+\\n\"\n        \" GCC_XTENSA_ESP32                 - Compiler: GCC           Target: Xtensa ESP32\\n\"\n        \" GCC_AVRDX                        - Compiler: GCC           Target: AVRDx\\n\"\n        \" GCC_AVR_MEGA0                    - Compiler: GCC           Target: AVR Mega0\\n\"\n        \" IAR_78K0K                        - Compiler: IAR           Target: Renesas 78K0K\\n\"\n        \" IAR_ARM_CA5_NOGIC                - Compiler: IAR           Target: ARM Cortex-A5 no GIC\\n\"\n        \" IAR_ARM_CA9                      - Compiler: IAR           Target: ARM Cortex-A9\\n\"\n        \" IAR_ARM_CM0                      - Compiler: IAR           Target: ARM Cortex-M0\\n\"\n        \" IAR_ARM_CM3                      - Compiler: IAR           Target: ARM Cortex-M3\\n\"\n        \" IAR_ARM_CM4F                     - Compiler: IAR           Target: ARM Cortex-M4 with FPU\\n\"\n        \" IAR_ARM_CM4F_MPU                 - Compiler: IAR           Target: ARM Cortex-M4 with FPU and MPU\\n\"\n        \" IAR_ARM_CM7                      - Compiler: IAR           Target: ARM Cortex-M7\\n\"\n        \" IAR_ARM_CM23_NONSECURE           - Compiler: IAR           Target: ARM Cortex-M23 non-secure\\n\"\n        \" IAR_ARM_CM23_SECURE              - Compiler: IAR           Target: ARM Cortex-M23 secure\\n\"\n        \" IAR_ARM_CM23_NTZ_NONSECURE       - Compiler: IAR           Target: ARM Cortex-M23 non-trustzone non-secure\\n\"\n        \" IAR_ARM_CM33_NONSECURE           - Compiler: IAR           Target: ARM Cortex-M33 non-secure\\n\"\n        \" IAR_ARM_CM33_SECURE              - Compiler: IAR           Target: ARM Cortex-M33 secure\\n\"\n        \" IAR_ARM_CM33_NTZ_NONSECURE       - Compiler: IAR           Target: ARM Cortex-M33 non-trustzone non-secure\\n\"\n        \" IAR_ARM_CM33_TFM                 - Compiler: IAR           Target: ARM Cortex-M33 non-secure for TF-M\\n\"\n        \" IAR_ARM_CM35P_NONSECURE          - Compiler: IAR           Target: ARM Cortex-M35P non-secure\\n\"\n        \" IAR_ARM_CM35P_SECURE             - Compiler: IAR           Target: ARM Cortex-M35P secure\\n\"\n        \" IAR_ARM_CM35P_NTZ_NONSECURE      - Compiler: IAR           Target: ARM Cortex-M35P non-trustzone non-secure\\n\"\n        \" IAR_ARM_CM55_NONSECURE           - Compiler: IAR           Target: ARM Cortex-M55 non-secure\\n\"\n        \" IAR_ARM_CM55_SECURE              - Compiler: IAR           Target: ARM Cortex-M55 secure\\n\"\n        \" IAR_ARM_CM55_NTZ_NONSECURE       - Compiler: IAR           Target: ARM Cortex-M55 non-trustzone non-secure\\n\"\n        \" IAR_ARM_CM55_TFM                 - Compiler: IAR           Target: ARM Cortex-M55 non-secure for TF-M\\n\"\n        \" IAR_ARM_CM85_NONSECURE           - Compiler: IAR           Target: ARM Cortex-M85 non-secure\\n\"\n        \" IAR_ARM_CM85_SECURE              - Compiler: IAR           Target: ARM Cortex-M85 secure\\n\"\n        \" IAR_ARM_CM85_NTZ_NONSECURE       - Compiler: IAR           Target: ARM Cortex-M85 non-trustzone non-secure\\n\"\n        \" IAR_ARM_CM85_TFM                 - Compiler: IAR           Target: ARM Cortex-M85 non-secure for TF-M\\n\"\n        \" IAR_ARM_CRX_NOGIC                - Compiler: IAR           Target: ARM Cortex-Rx no GIC\\n\"\n        \" IAR_ATMEGA323                    - Compiler: IAR           Target: ATMega323\\n\"\n        \" IAR_ATMEL_SAM7S64                - Compiler: IAR           Target: Atmel SAM7S64\\n\"\n        \" IAR_ATMEL_SAM9XE                 - Compiler: IAR           Target: Atmel SAM9XE\\n\"\n        \" IAR_AVR_AVRDX                    - Compiler: IAR           Target: AVRDx\\n\"\n        \" IAR_AVR_MEGA0                    - Compiler: IAR           Target: AVR Mega0\\n\"\n        \" IAR_AVR32_UC3                    - Compiler: IAR           Target: AVR32 UC3\\n\"\n        \" IAR_LPC2000                      - Compiler: IAR           Target: LPC2000\\n\"\n        \" IAR_MSP430                       - Compiler: IAR           Target: MSP430\\n\"\n        \" IAR_MSP430X                      - Compiler: IAR           Target: MSP430X\\n\"\n        \" IAR_RISC_V                       - Compiler: IAR           Target: RISC-V\\n\"\n        \" IAR_RISC_V_GENERIC               - Compiler: IAR           Target: RISC-V with FREERTOS_RISCV_EXTENSION\\n\"\n        \" IAR_RL78                         - Compiler: IAR           Target: Renesas RL78\\n\"\n        \" IAR_RX100                        - Compiler: IAR           Target: Renesas RX100\\n\"\n        \" IAR_RX600                        - Compiler: IAR           Target: Renesas RX600\\n\"\n        \" IAR_RX700_V3_DPFPU               - Compiler: IAR           Target: Renesas RX700 v3 with DPFPU\\n\"\n        \" IAR_RX_V2                        - Compiler: IAR           Target: Renesas RX v2\\n\"\n        \" IAR_STR71X                       - Compiler: IAR           Target: STR71x\\n\"\n        \" IAR_STR75X                       - Compiler: IAR           Target: STR75x\\n\"\n        \" IAR_STR91X                       - Compiler: IAR           Target: STR91x\\n\"\n        \" IAR_V850ES_FX3                   - Compiler: IAR           Target: Renesas V850ES/Fx3\\n\"\n        \" IAR_V850ES_HX3                   - Compiler: IAR           Target: Renesas V850ES/Hx3\\n\"\n        \" MIKROC_ARM_CM4F                  - Compiler: MikroC        Target: ARM Cortex-M4 with FPU\\n\"\n        \" MPLAB_PIC18F                     - Compiler: MPLAB         Target: PIC18F\\n\"\n        \" MPLAB_PIC24                      - Compiler: MPLAB         Target: PIC24\\n\"\n        \" MPLAB_PIC32MEC14XX               - Compiler: MPLAB         Target: PIC32MEC14xx\\n\"\n        \" MPLAB_PIC32MX                    - Compiler: MPLAB         Target: PIC32MX\\n\"\n        \" MPLAB_PIC32MZ                    - Compiler: MPLAB         Target: PIC32MZ\\n\"\n        \" MSVC_MINGW                       - Compiler: MSVC or MinGW Target: x86\\n\"\n        \" OWATCOM_16BIT_DOS_FLSH186        - Compiler: Open Watcom   Target: 16 bit DOS Flsh186\\n\"\n        \" OWATCOM_16BIT_DOS_PC             - Compiler: Open Watcom   Target: 16 bit DOS PC\\n\"\n        \" PARADIGM_TERN_EE_LARGE           - Compiler: Paradigm      Target: Tern EE large\\n\"\n        \" PARADIGM_TERN_EE_SMALL           - Compiler: Paradigm      Target: Tern EE small\\n\"\n        \" RENESAS_RX100                    - Compiler: Renesas       Target: RX100\\n\"\n        \" RENESAS_RX200                    - Compiler: Renesas       Target: RX200\\n\"\n        \" RENESAS_RX600                    - Compiler: Renesas       Target: RX600\\n\"\n        \" RENESAS_RX600_V2                 - Compiler: Renesas       Target: RX600 v2\\n\"\n        \" RENESAS_RX700_V3_DPFPU           - Compiler: Renesas       Target: RX700 v3 with DPFPU\\n\"\n        \" RENESAS_SH2A_FPU                 - Compiler: Renesas       Target: SH2A with FPU\\n\"\n        \" ROWLEY_MSP430F449                - Compiler: Rowley        Target: MSP430F449\\n\"\n        \" RVDS_ARM_CA9                     - Compiler: RVDS          Target: ARM Cortex-A9\\n\"\n        \" RVDS_ARM_CM0                     - Compiler: RVDS          Target: ARM Cortex-M0\\n\"\n        \" RVDS_ARM_CM3                     - Compiler: RVDS          Target: ARM Cortex-M3\\n\"\n        \" RVDS_ARM_CM4_MPU                 - Compiler: RVDS          Target: ARM Cortex-M4 with MPU\\n\"\n        \" RVDS_ARM_CM4F                    - Compiler: RVDS          Target: ARM Cortex-M4 with FPU\\n\"\n        \" RVDS_ARM_CM7                     - Compiler: RVDS          Target: ARM Cortex-M7\\n\"\n        \" RVDS_ARM7_LPC21XX                - Compiler: RVDS          Target: ARM7 LPC21xx\\n\"\n        \" SDCC_CYGNAL                      - Compiler: SDCC          Target: Cygnal\\n\"\n        \" SOFTUNE_MB91460                  - Compiler: Softune       Target: MB91460\\n\"\n        \" SOFTUNE_MB96340                  - Compiler: Softune       Target: MB96340\\n\"\n        \" TASKING_ARM_CM4F                 - Compiler: Tasking       Target: ARM Cortex-M4 with FPU\\n\"\n        \" TEMPLATE                         - Compiler: HOST          Target: None\\n\"\n        \" CDK_THEAD_CK802                  - Compiler: CDK           Target: T-head CK802\\n\"\n        \" XCC_XTENSA                       - Compiler: XCC           Target: Xtensa\\n\"\n        \" WIZC_PIC18                       - Compiler: WizC          Target: PIC18\")\n    # Native FREERTOS_PORT for Linux and Windows MINGW builds\n    if(UNIX)\n        message(STATUS \" Auto-Detected Unix, setting FREERTOS_PORT=GCC_POSIX\")\n        set(FREERTOS_PORT GCC_POSIX CACHE STRING \"FreeRTOS port name\")\n    elseif(MINGW)\n        message(STATUS \" Auto-Detected MINGW, setting FREERTOS_PORT=MSVC_MINGW\")\n        set(FREERTOS_PORT MSVC_MINGW CACHE STRING \"FreeRTOS port name\")\n    endif()\nelseif((FREERTOS_PORT STREQUAL \"A_CUSTOM_PORT\") AND (NOT TARGET freertos_kernel_port) )\n    message(FATAL_ERROR \" FREERTOS_PORT is set to A_CUSTOM_PORT. Please specify the custom port target with all necessary files. For example:\\n\"\n    \" Assuming a directory of:\\n\"\n    \"  FreeRTOSCustomPort/\\n\"\n    \"    CMakeLists.txt\\n\"\n    \"    port.c\\n\"\n    \"    portmacro.h\\n\"\n    \" Where FreeRTOSCustomPort/CMakeLists.txt is a modified version of:\\n\"\n    \"   add_library(freertos_kernel_port OBJECT)\\n\"\n    \"   target_sources(freertos_kernel_port\\n\"\n    \"     PRIVATE\\n\"\n    \"       port.c\\n\"\n    \"       portmacro.h)\\n\"\n    \"   add_library(freertos_kernel_port_headers INTERFACE)\\n\"\n    \"     target_include_directories(freertos_kernel_port_headers INTERFACE \\n\"\n    \"      .)\\n\"\n    \"   target_link_libraries(freertos_kernel_port\\n\"\n    \"     PRIVATE\\n\"\n    \"       freertos_kernel_port_headers\\n\"\n    \"       freertos_kernel_include)\")\nendif()\n\nadd_library(freertos_kernel STATIC)\n\n########################################################################\nadd_subdirectory(include)\nadd_subdirectory(portable)\n\ntarget_sources(freertos_kernel PRIVATE\n    croutine.c\n    event_groups.c\n    list.c\n    queue.c\n    stream_buffer.c\n    tasks.c\n    timers.c\n)\n\nif (DEFINED FREERTOS_HEAP )\n    # User specified a heap implementation add heap implementation to freertos_kernel.\n    target_sources(freertos_kernel PRIVATE\n        # If FREERTOS_HEAP is digit between 1 .. 5 - it is heap number, otherwise - it is path to custom heap source file\n        $<IF:$<BOOL:$<FILTER:${FREERTOS_HEAP},EXCLUDE,^[1-5]$>>,${FREERTOS_HEAP},portable/MemMang/heap_${FREERTOS_HEAP}.c>\n    )\nendif()\n\n\ntarget_link_libraries(freertos_kernel\n    PUBLIC\n        freertos_kernel_include\n        freertos_kernel_port_headers\n    PRIVATE\n        freertos_kernel_port\n\n)\n\n########################################################################\n"
        },
        {
          "name": "GitHub-FreeRTOS-Kernel-Home.url",
          "type": "blob",
          "size": 0.14453125,
          "content": "[{000214A0-0000-0000-C000-000000000046}]\nProp3=19,2\n[InternetShortcut]\nURL=https://github.com/FreeRTOS/FreeRTOS-Kernel\nIconIndex=0\nIDList=\nHotKey=0\n"
        },
        {
          "name": "History.txt",
          "type": "blob",
          "size": 167.2177734375,
          "content": "Documentation and download available at https://www.FreeRTOS.org/\n\nChanges between FreeRTOS V11.0.1 and FreeRTOS V11.1.0 released April 22, 2024\n\n    + Add ARMv7-R port with Memory Protection Unit (MPU) support.\n    + Add Memory Protection Unit (MPU) support to the Cortex-M0 port.\n    + Add stream batching buffer. A stream batching buffer differs from a stream\n      buffer when a task reads from a non-empty buffer:\n      - The task reading from a non-empty stream buffer returns immediately\n        regardless of the amount of data in the buffer.\n      - The task reading from a non-empty steam batching buffer blocks until the\n        amount of data in the buffer exceeds the trigger level or the block time\n        expires.\n      We thank @cperkulator for their contribution.\n    + Add the ability to change task notification index for stream buffers. We\n      thank @glemco for their contribution.\n    + Add xStreamBufferResetFromISR and xMessageBufferResetFromISR APIs to reset\n      stream buffer and message buffer from an Interrupt Service Routine (ISR).\n      We thank @HagaiMoshe for their contribution.\n    + Update all the FreeRTOS APIs to use configSTACK_DEPTH_TYPE for stack type.\n      We thank @feilipu for their contribution.\n    + Update vTaskEndScheduler to delete the timer and idle tasks,\n      once the scheduler is stopped.\n    + Make xTaskGetCurrentTaskHandleForCore() available to the single core\n      scheduler. We thank @Dazza0 for their contribution.\n    + Update uxTaskGetSystemState to not use the pxIndex member of the List_t\n      structure while iterating ready tasks list. The reason is that pxIndex\n      member must only used to select next ready task to run. We thank\n      @gemarcano for their inputs.\n    + Add a config option to the FreeRTOS SMP Kernel to set the default core\n      affinity mask for tasks created without an affinity mask. We thank @go2sh\n      for their contribution.\n    + Add configUSE_EVENT_GROUPS and configUSE_STREAM_BUFFERS configuration\n      constants to control the inclusion of event group and stream buffer\n      functionalities.\n    + Code changes to comply with MISRA C 2012.\n    + Add 64-bit support to the FreeRTOS Windows Simulator port. We thank @watsk\n      and @josesimoes for their contributions.\n    + Add support for 64-bit Microblaze processor to the MicroblazeV9 port. We\n      thank @mubinsyed for their contribution.\n    + Add support for MSP430 Embedded Application Binary Interface (EABI) to\n      the MSP430F449 port to make it work with both MSP430 GCC and MSPGCC\n      compilers. We thank @Forty-Bot for their contribution.\n    + Update xPortIsAuthorizedToAccessBuffer() on FreeRTOS ports with MPU\n      support to grant an unprivileged task access to all the memory before the\n      scheduler is started.\n    + Update the POSIX port to pass the FreeRTOS task name to pthread for\n      readable output in debuggers. We thank @Mixaill for their contribution.\n    + Update the POSIX port to ignore the user specified stack memory and only\n      pass the stack size to the pthread API to avoid errors caused when stack size\n      is smaller than the minimum. We thank @cmorgnaBE for their\n      contribution.\n    + Update the POSIX port to use a timer thread for tick interrupts instead of\n      POSIX timers to address issues with signal handling in non-FreeRTOS\n      pthreads. We thank @cmorgnaBE for their contribution.\n    + Update ARM_TFM port to support TF-Mv2.0.0 release of trusted-firmware-m.\n      We thanks @urutva for their contribution.\n    + Remove redundant constant pools in ARMv8 ports. We thank @urutva for their\n      contribution.\n    + Add APIs to reset the internal state of kernel modules. These APIs are\n      primarily intended to be used in the testing frameworks that restart the\n      scheduler.\n    + Use kernel provided implementations of vApplicationGetIdleTaskMemory() and\n      vApplicationGetTimerTaskMemory() in the RP2040 port. We thank @dpslwk for\n      their contribution.\n    + Fix atomic enter/exit critical section macro definitions in atomic.h for\n      ports that support nested interrupts. We thank @sebunger for their\n      contribution.\n    + Fix compiler warnings in the MSP430F449 port when compiled with the\n      MSP430 GCC compiler. We thank @Forty-Bot for their contribution.\n    + Update the scheduler suspension usage in ulTaskGenericNotifyTake and\n      xTaskGenericNotifyWait() to enhance code readability. We thank @Dazza0 for\n      their contribution.\n    + Add support for latest version of MPU wrappers( mpu_wrappers_v2) in CMake.\n      We thank @IsaacDynamo for their contribution.\n    + Update CMake support to create only one static library containing both the\n      kernel common code and the kernel port code. We thank @barnatahmed for\n      their contribution.\n\nChanges between FreeRTOS V11.0.0 and FreeRTOS V11.0.1 released December 21, 2023\n\n    + Updated the SBOM file.\n\nChanges between FreeRTOS V10.6.2 and FreeRTOS V11.0.0 released December 18, 2023\n\n    + SMP merged into the mainline:  While FreeRTOS introduced Asymmetric\n      Multiprocessing (AMP) support in 2017, FreeRTOS Version 11.0.0 is the\n      first to merge Symmetric Multiprocessing (SMP) support into the mainline\n      release. SMP enables one instance of the FreeRTOS Kernel to schedule tasks\n      across multiple identical processor cores.  We thank Mike Bruno and Jerry\n      McCarthy of XMOS and, Darian Liang, Sudeep Mohanty and Zim Kalinowski of\n      Espressif Systems for their contributions.\n    + Switch MISRA compliance checking from PC Lint to Coverity, and update from\n      MISRA C:2004 to MISRA C:2012.\n    + Add a template FreeRTOSConfig.h, inclusive of an abbreviated explanation of\n      each configuration item. Application writers can use this template as a\n      starting point to create the FreeRTOSConfig.h file for their application.\n    + Add a template FreeRTOS port which can be used as a starting point for\n      developing a new FreeRTOS port.\n    + Add bounds checking and obfuscation to internal heap block pointers in\n      heap_4.c and heap_5.c to help catch pointer corruptions. The application can\n      enable these checks by setting configENABLE_HEAP_PROTECTOR to 1 in their\n      FreeRTOSConfig.h. We thank @oliverlavery for their contribution.\n    + Update vTaskList and vTaskGetRunTimeStats APIs to replace the use of sprintf\n      with snprintf.\n    + Add trace macros to ports that enable tracing the interaction of ISRs with\n      scheduler events. We thank @conara for their contribution.\n    + Add trace macros that enable tracing of entering and exiting all APIs. We\n      thank @Techcore123 for their contribution.\n    + Add uxTaskBasePriorityGet and uxTaskBasePriorityGetFromISR APIs to get the\n      base priority of a task. The base priority of a task is the priority that\n      was last assigned to the task - which due to priority inheritance, may not\n      be the current priority of the task.\n    + Add pdTICKS_TO_MS macro to convert time in FreeRTOS ticks to time in\n      milliseconds. We thank @Dazza0 for their contribution.\n    + Add default implementations of vApplicationGetIdleTaskMemory and\n      vApplicationGetTimerTaskMemory. The application can enable these default\n      implementations by setting configKERNEL_PROVIDED_STATIC_MEMORY to 1 in their\n      FreeRTOSConfig.h. We thank @mdnr-g for their contribution.\n    + Update vTaskGetInfo to include start and end of the stack whenever both\n      values are available. We thank @vinceburns for their contribution.\n    + Prevent tasks waiting for a notification from being resumed by calls to\n      vTaskResume or vTaskResumeFromISR. We thank @Moral-Hao for their\n      contribution.\n    + Add asserts to validate that the application has correctly installed\n      FreeRTOS handlers for PendSV and SVCall interrupts on Cortex-M devices.\n      We thank @jefftenney for their contribution.\n    + Rename ARM_CA53_64_BIT and ARM_CA53_64_BIT_SRE ports to Arm_AARCH64 and\n      Arm_AARCH64_SRE respectively as these ports are applicable to all AArch64\n      architecture. We thank @urutva for their contribution.\n    + Add CMake support to allow the application writer to select the RISC-V\n      chip extension. We thank @JoeBenczarski for their contribution.\n    + Add CMake support to allow the application writer to build an application\n      with static allocation only. We thank @conara for their contribution.\n    + Make taskYIELD available to unprivileged tasks for ARMv8-M ports.\n    + Update Cortex-M23 ports to not use PSPLIM_NS. We thank @urutva for their\n      contribution.\n    + Update the SysTick setup code for ARMv8-M ports to first configure the clock\n      source and then enable SysTick. This is needed to address a bug in QEMU\n      versions older than 7.0.0, which causes an emulation error if SysTick is\n      enabled without first selecting a valid clock source. We thank @jefftenney\n      for their contribution.\n    + Add the port-optimized task selection algorithm optionally available for\n      ARMv7-M ports to the ARMv8-M ports. We thank @jefftenney for their\n      contribution.\n    + Improve the speed of pvPortMalloc in heap_4.c and heap_5.c by removing\n      unnecessary steps while splitting a large memory block into two. We thank\n      @Moral-Hao for their contribution.\n    + Shorten the critical section in pvPortMalloc in heap_2.c, heap_4.c and\n      heap_5.c by moving the size calculation out of the critical section. We thank\n      @Moral-Hao for their contribution.\n    + Update xTaskNotifyWait and ulTaskNotifyTake to remove the non-deterministic\n      operation of traversing a linked link from a critical section. We thank\n      @karver8 for their contribution.\n    + Fix stack end and stack size computation in POSIX port to meet the stack\n      alignment requirements on MacOS. We thank @tegimeki for their contribution.\n    + Update the vTaskPrioritySet implementation to use the new priority when the\n      task has inherited priority from a mutex it is holding, and the new priority\n      is bigger than the inherited priority. We thank @Moral-Hao for their\n      contribution.\n    + Add stack alignment adjustment if stack grows upwards. We thank @ivq for\n      their contribution.\n    + Fix pxTopOfStack calculation in configINIT_TLS_BLOCK when picolib C is\n      selected as the C library implementation to ensure that\n      pxPortInitialiseStack does not overwrite the data in the TLS block portion\n      of the stack. We thank @bebebib-rs for their contribution.\n    + Fix vPortEndScheduler() for the MSVC port so that the function\n      prvProcessSimulatedInterrupts is not stuck in an infinite loop when the\n      scheduler is stopped. We thank @Ju1He1 for their contribution.\n    + Add the Pull Request (PR) Process explaining the stages a PR goes through.\n\nChanges between FreeRTOS V10.6.1 and FreeRTOS V10.6.2 released November 29, 2023\n\n\t+ Add the following improvements to the new MPU wrapper (mpu_wrappers_v2.c)\n\t  introduced in version 10.6.0:\n\t  - Introduce Access Control List (ACL) feature to allow the application\n\t    writer to control an unprivileged task’s access to kernel objects.\n\t  - Update the system call entry mechanism to only require one Supervisor\n\t    Call (SVC) instruction.\n\t  - Wrap parameters for system calls with more than four parameters in a\n\t    struct to avoid special handling during system call entry.\n\t  - Fix 2 possible integer overflows.\n\t  - Convert some asserts to run time parameter checks.\n\nChanges between FreeRTOS V10.6.0 and FreeRTOS V10.6.1 released August 17, 2023\n\n\t+ Add runtime parameter checks to functions in mpu_wrappers_v2.c file.\n\t  The same checks are already performed in API implementations using\n\t  asserts.\n\t  We thank the following people for their inputs in these changes:\n\t  - Lan Luo, Zixia Liu of School of Computer Science and Technology,\n\t    Anhui University of Technology, China.\n\t  - Xinwen Fu of Department of Computer Science, University of\n\t    Massachusetts Lowell, USA.\n\t  - Xinhui Shao, Yumeng Wei, Huaiyu Yan, Zhen Ling of School of\n\t    Computer Science and Engineering, Southeast University, China.\n\nChanges between FreeRTOS V10.5.1 and FreeRTOS 10.6.0 released July 13, 2023\n\n\t+ Add a new MPU wrapper that places additional restrictions on unprivileged\n\t  tasks. The following is the list of changes introduced with the new MPU\n\t  wrapper:\n\n\t  1. Opaque and indirectly verifiable integers for kernel object handles:\n\t     All the kernel object handles (for example, queue handles) are now\n\t     opaque integers. Previously object handles were raw pointers.\n\t  2. Save the task context in Task Control Block (TCB): When a task is\n\t     swapped out by the scheduler, the task's context is now saved in its\n\t     TCB. Previously the task's context was saved on its stack.\n\t  3. Execute system calls on a separate privileged only stack: FreeRTOS\n\t     system calls, which execute with elevated privilege, now use a\n\t     separate privileged only stack. Previously system calls used the\n\t     calling task's stack. The application writer can control the size of\n\t     the system call stack using new configSYSTEM_CALL_STACK_SIZE config\n\t     macro.\n\t  4. Memory bounds checks: FreeRTOS system calls which accept a pointer\n\t     and de-reference it, now verify that the calling task has required\n\t     permissions to access the memory location referenced by the pointer.\n\t  5. System calls restrictions: The following system calls are no longer\n\t     available to unprivileged tasks:\n\t      - vQueueDelete\n\t      - xQueueCreateMutex\n\t      - xQueueCreateMutexStatic\n\t      - xQueueCreateCountingSemaphore\n\t      - xQueueCreateCountingSemaphoreStatic\n\t      - xQueueGenericCreate\n\t      - xQueueGenericCreateStatic\n\t      - xQueueCreateSet\n\t      - xQueueRemoveFromSet\n\t      - xQueueGenericReset\n\t      - xTaskCreate\n\t      - xTaskCreateStatic\n\t      - vTaskDelete\n\t      - vTaskPrioritySet\n\t      - vTaskSuspendAll\n\t      - xTaskResumeAll\n\t      - xTaskGetHandle\n\t      - xTaskCallApplicationTaskHook\n\t      - vTaskList\n\t      - vTaskGetRunTimeStats\n\t      - xTaskCatchUpTicks\n\t      - xEventGroupCreate\n\t      - xEventGroupCreateStatic\n\t      - vEventGroupDelete\n\t      - xStreamBufferGenericCreate\n\t      - xStreamBufferGenericCreateStatic\n\t      - vStreamBufferDelete\n\t      - xStreamBufferReset\n\t     Also, an unprivileged task can no longer use vTaskSuspend to suspend\n\t     any task other than itself.\n\n\t  We thank the following people for their inputs in these enhancements:\n\t    - David Reiss of Meta Platforms, Inc.\n\t    - Lan Luo, Xinhui Shao, Yumeng Wei, Zixia Liu, Huaiyu Yan and Zhen Ling\n\t      of School of Computer Science and Engineering, Southeast University,\n\t      China.\n\t    - Xinwen Fu of Department of Computer Science, University of\n\t      Massachusetts Lowell, USA.\n\t    - Yueqi Chen, Zicheng Wang, Minghao Lin, Jiahe Wang of University of\n\t      Colorado Boulder, USA.\n\t+ Add Cortex-M35P port. Contributed by @urutva.\n\t+ Add embedded extension (RV32E) support to the IAR RISC-V port.\n\t+ Add ulTaskGetRunTimeCounter and ulTaskGetRunTimePercent APIs. Contributed by\n\t  @chrisnc.\n\t+ Add APIs to get the application supplied buffers from statically\n\t  created kernel objects. The following new APIs are added:\n\t  - xTaskGetStaticBuffers\n\t  - xQueueGetStaticBuffers\n\t  - xQueueGenericGetStaticBuffers\n\t  - xSemaphoreGetStaticBuffer\n\t  - xEventGroupGetStaticBuffer\n\t  - xStreamBufferGetStaticBuffers\n\t  - xMessageBufferGetStaticBuffers\n\t  These APIs enable the application writer to obtain static buffers from\n\t  the kernel object and free/reuse them at the time of deletion. Earlier\n\t  the application writer had to maintain the association of static buffers\n\t  and the kernel object in the application. Contributed by @Dazza0.\n\t+ Add Thread Local Storage (TLS) support using picolibc function. Contributed\n\t  by @keith-packard.\n\t+ Add configTICK_TYPE_WIDTH_IN_BITS to configure TickType_t data type. As a result,\n\t  the number of bits in an event group also increases with big data type. Contributed\n\t  by @Hadatko.\n\t+ Update eTaskGetState and uxTaskGetSystemState to return eReady for pending ready\n\t  tasks. Contributed by @Dazza0.\n\t+ Update heap_4 and heap_5 to add padding only if the resulting block is not\n\t  already aligned.\n\t+ Fix the scheduler logic in a couple of places to not preempt a task when an\n\t  equal priority task becomes ready.\n\t+ Add macros used in FreeRTOS-Plus libraries. Contributed by @Holden.\n\t+ Fix clang compiler warnings. Contributed by @phelter.\n\t+ Add assertions to ARMv8-M ports to detect when FreeRTOS APIs are called from\n\t  interrupts with priority higher than the configMAX_SYSCALL_INTERRUPT_PRIORITY.\n\t  Contributed by @urutva.\n\t+ Add xPortIsInsideInterrupt API to ARM_CM0 ports.\n\t+ Fix build warning in MSP430X port when large data model is used.\n\t+ Add the ability to use Cortex-R5 port on the parts without FPU.\n\t+ Fix build warning in heap implementations on PIC24/dsPIC.\n\t+ Update interrupt priority asserts for Cortex-M ports so that these do not fire\n\t  on QEMU which does not implement PRIO bits.\n\t+ Update ARMv7-M ports to ensure that kernel interrupts run at the lowest priority.\n\t  configKERNEL_INTERRUPT_PRIORITY is now obsolete for ARMv7-M ports and brings\n\t  these ports inline with the newer ARMv8-M ports. Contributed by @chrisnc.\n\t+ Fix build issue in POSIX GCC port on Windows Subsystem for Linux (WSL). Contributed\n\t  by @jacky309.\n\t+ Add portMEMORY_BARRIER to Microblaze port. Contributed by @bbain.\n\t+ Add portPOINTER_SIZE_TYPE definition for ATmega port. Contributed by @jputcu.\n\t+ Multiple improvements in the CMake support. Contributed by @phelte and @cookpate.\n\nChanges between FreeRTOS V10.5.0 and FreeRTOS V10.5.1 released November 16 2022\n\t+ Updated the kernel version in manifest and SBOM\n\nChanges between FreeRTOS V10.4.6 and FreeRTOS V10.5.0 released September 16 2022\n\n\t+ ARMv7-M and ARMv8-M MPU ports: It was possible for a third party that\n\t  already independently gained the ability to execute injected code to\n\t  read from or write to arbitrary addresses by passing a negative argument\n\t  as the xIndex parameter to pvTaskGetThreadLocalStoragePointer() or\n\t  vTaskSetThreadLocalStoragePointer respectively. A check has been added to\n\t  ensure that passing a negative argument as the xIndex parameter does not\n\t  cause arbitrary read or write.\n\t  We thank Certibit Consulting, LLC for reporting this issue.\n\t+ ARMv7-M and ARMv8-M MPU ports: It was possible for an unprivileged task\n\t  to invoke any function with privilege by passing it as a parameter to\n\t  MPU_xTaskCreate, MPU_xTaskCreateStatic, MPU_xTimerCreate,\n\t  MPU_xTimerCreateStatic, or MPU_xTimerPendFunctionCall. MPU_xTaskCreate\n\t  and MPU_xTaskCreateStatic have been updated to only allow creation of\n\t  unprivileged tasks. MPU_xTimerCreate, MPU_xTimerCreateStatic and\n\t  MPU_xTimerPendFunctionCall APIs have been removed.\n\t  We thank Huazhong University of Science and Technology for reporting\n\t  this issue.\n\t+ ARMv7-M and ARMv8-M MPU ports: It was possible for a third party that\n\t  already independently gained the ability to execute injected code to\n\t  achieve further privilege escalation by branching directly inside a\n\t  FreeRTOS MPU API wrapper function with a manually crafted stack frame.\n\t  The local stack variable `xRunningPrivileged` has been removed so that\n\t  a manually crafted stack frame cannot be used for privilege escalation\n\t  by branching directly inside a FreeRTOS MPU API wrapper.\n\t  We thank Certibit Consulting, LLC, Huazhong University of Science and\n\t  Technology and the SecLab team at Northeastern University for reporting\n\t  this issue.\n\t+ ARMv7-M MPU ports: It was possible to configure overlapping memory\n\t  protection unit (MPU) regions such that an unprivileged task could access\n\t  privileged data. The kernel now uses highest numbered MPU regions for\n\t  kernel protections to prevent such MPU configurations.\n\t  We thank the SecLab team at Northeastern University for reporting this\n\t  issue.\n\t+ Add support for ARM Cortex-M55.\n\t+ Add support for ARM Cortex-M85. Contributed by @gbrtth.\n\t+ Add vectored mode interrupt support to the RISC-V port.\n\t+ Add support for RV32E extension (Embedded Profile) in RISC-V GCC port.\n\t  Contributed by @Limoto.\n\t+ Heap improvements:\n\t  - Add a check to heap_2 to track if a memory block is allocated to\n\t    the application or not. The MSB of the size field is used for this\n\t    purpose. The same check already exists in heap_4 and heap_5. This\n\t    check prevents double free errors.\n\t  - Add a new flag configHEAP_CLEAR_MEMORY_ON_FREE to heap_2, heap_4\n\t    and heap_5. If the flag is set in FreeRTOSConfig.h then memory freed using\n\t    vPortFree() is automatically cleared to zero.\n\t  - Add a new API pvPortCalloc to heap_2, heap_4 and heap_5 which has the same\n\t    signature as the standard library calloc function.\n\t  - Update the pointer types to portPOINTER_SIZE_TYPE. Contributed by\n\t    @Octaviarius.\n\t+ Add the ability to override send and receive completed callbacks for each\n\t  instance of a stream buffer or message buffer. Earlier there could be\n\t  one send and one receive callback for all instances of stream and message\n\t  buffers. Having separate callbacks per instance allows different message\n\t  and stream buffers to be used differently - for example, some for inter core\n\t  communication and others for same core communication.\n\t  The feature can be controlled by setting  the configuration option\n\t  configUSE_SB_COMPLETED_CALLBACK in FreeRTOSConfig.h. When the option is set to 1,\n\t  APIs xStreamBufferCreateWithCallback() or xStreamBufferCreateStaticWithCallback()\n\t  (and likewise APIs for message buffer) can be used to create a stream buffer\n\t  or message buffer instance with application provided callback overrides. When\n\t  the option is set to 0, then the default callbacks as defined by\n\t  sbSEND_COMPLETED() and sbRECEIVE_COMPLETED() macros are invoked. To maintain\n\t  backwards compatibility, configUSE_SB_COMPLETED_CALLBACK defaults to 0. The\n\t  functionality is currently not supported for MPU enabled ports.\n\t+ Generalize the FreeRTOS's Thread Local Storage (TLS) support so that it\n\t  is not tied to newlib and can be used with other c-runtime libraries also.\n\t  The default behavior for newlib support is kept same for backward\n\t  compatibility.\n\t+ Add support to build and link FreeRTOS using CMake build system. Contributed\n\t  by @yhsb2k.\n\t+ Add support to generate Software Bill of Materials (SBOM) for every release.\n\t+ Add support for 16 MPU regions to the GCC Cortex-M33 ports.\n\t+ Add ARM Cortex-M7 r0p0/r0p1 Errata 837070 workaround to ARM CM4 MPU ports.\n\t  The application writer needs to define configENABLE_ERRATA_837070_WORKAROUND\n\t  when using CM4 MPU ports on a Cortex-M7 r0p0/r0p1 core.\n\t+ Add configSYSTICK_CLOCK_HZ to Cortex-M0 ports. This is needed to support\n\t  the case when the SysTick timer is not clocked from the same source as the CPU.\n\t+ Add hardware stack protection support to MicroBlazeV9 port. This ensures that\n\t  the CPU immediately raises Stack Protection Violation exception as soon as any\n\t  task violates its stack limits. Contributed by @uecasm.\n\t+ Introduce the configUSE_MINI_LIST_ITEM configuration option. When this\n\t  option is set to 1, ListItem_t and MiniLitItem_t remain separate types.\n\t  However, when configUSE_MINI_LIST_ITEM == 0, MiniLitItem_t and ListItem_t\n\t  are both typedefs of the same struct xLIST_ITEM. This addresses some issues\n\t  observed when strict-aliasing and link time optimization are enabled.\n\t  To maintain backwards compatibility, configUSE_MINI_LIST_ITEM defaults to 1.\n\t+ Simplify prvInitialiseNewTask to memset newly allocated TCB structures\n\t  to zero, and remove code that set individual structure members to zero.\n\t+ Add prototype for prvPortYieldFromISR to the POSIX port so that it builds\n\t  without any warning with -Wmissing-prototypes compiler option.\n\t+ Add top of stack and end of stack to the task info report obtained using\n\t  vTaskGetInfo(). Contributed by @shreyasbharath.\n\t+ Add a cap to the cRxLock and cTxLock members of the queue data structure.\n\t  These locks count the number items received and sent to the queue while\n\t  the queue was locked. These are later used to unblock tasks waiting on\n\t  the queue when the queue is unlocked. This PR caps the values of the\n\t  cRxLock and cTxLock to the number of tasks in the system because we cannot\n\t  unblock more tasks than there are in the system. Note that the same assert\n\t  could still be triggered is the application creates more than 127 tasks.\n\t+ Changed uxAutoReload parameter in timer functions to xAutoReload.  The\n\t  type is now BaseType_t.  This matches the type of pdTRUE and pdFALSE.\n\t  The new function xTimerGetAutoReload() provides the auto-reload state as\n\t  a BaseType_t.  The legacy function uxTimerGetAutoReload is retained with the\n\t  original UBaseType_t return value.\n\t+ Fix support for user implementations of tickless idle that call\n\t  vTaskStepTick() with xExpectedIdleTime ticks to step. The new code\n\t  ensures xTickCount reaches xNextTaskUnblockTime inside xTaskIncrementTick()\n\t  instead of inside vTaskStepTick(). This fixes the typical case where a task\n\t  wakes up one tick late and a rare case assertion failure when xTickCount\\\n\t  rolls over. Contributed by @jefftenney.\n\t+ Fix deadlock in event groups when pvPortMalloc and vPortFree functions\n\t  are protected with a mutex. Contributed by @clemenskresser.\n\t+ Fix a warning in tasks.c when compiled with -Wduplicated-branches\n\t  GCC option. Contributed by @pierrenoel-bouteville-act.\n\t+ Fix compilation error in tasks.c when configSUPPORT_DYNAMIC_ALLOCATION\n\t  is set to zero. Contributed by @rdpoor.\n\t+ Fix prvWriteMessageToBuffer() function in stream_buffer.c so that it correctly\n\t  copies length on big endian platforms too.\n\t+ Remove the need for  INCLUDE_vTaskSuspend to be set to 1\n\t  when configUSE_TICKLESS_IDLE is enabled. Contributed by @pramithkv.\n\t+ Update the RL78 IAR port to the latest version of IAR which uses the\n\t  industry standard ELF format as opposed to earlier UBROF object format.\n\t  Contributed by @felipe-iar.\n\t+ Add tick type is atomic flag when tick count is 16-bit to PIC24 port. This\n\t  allows the PIC24 family of 16 bit processors to read the tick count without\n\t  a critical section when the tick count is also 16 bits.\n\t+ Fix offset-out-of-range errors for GCC CM3/CM4 mpu ports when\n\t  Link Time Optimization is enabled. Contributed by @niniemann.\n\t+ Remove #error when RISC-V port is compiled on a 64-bit RISC-V platform.\n\t  Contributed by @cmdrf.\n\t+ Fix ullPortInterruptNesting alignment in Cortex-A53 port so that it is\n\t  8-byte aligned. This fixes the unaligned access exception. Contributed\n\t  by @Atomar25.\n\t+ Fix  Interrupt Handler Register Function and Exception Process in NiosII\n\t  Port. Contributed by @ghost.\n\t+ Change FreeRTOS IRQ Handler for Cortex-A53 SRE port to store and restore\n\t  interrupt acknowledge register. This ensures that the SRE port behavior\n\t  matches the Memory Mapped IO port. Contributed by @sviaunxp.\n\t+ Update the uncrustify config file to match the version of the uncrustify\n\t  used in the CI Action. Also, pin the version of uncrustify in CI. Contributed\n\t  by @swaldhoer.\n\nChanges between FreeRTOS V10.4.5 and FreeRTOS V10.4.6 released November 12 2021\n\n\t+ ARMv7-M and ARMv8-M MPU ports – prevent non-kernel code from calling the\n\t  internal functions xPortRaisePrivilege and vPortResetPrivilege by changing\n\t  them to macros.\n\t+ Introduce a new config configALLOW_UNPRIVILEGED_CRITICAL_SECTIONS which\n\t  enables developers to prevent critical sections from unprivileged tasks.\n\t  It defaults to 1 for backward compatibility. Application should set it to\n\t  0 to disable critical sections from unprivileged tasks.\n\nChanges between FreeRTOS V10.4.4 and FreeRTOS V10.4.5 released September 10 2021\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.4.5.html\n\n\t+ Introduce configRUN_TIME_COUNTER_TYPE which enables developers to define\n\t  the type used to hold run time statistic counters. Defaults to uint32_t\n\t  for backward compatibility. #define configRUN_TIME_COUNTER_TYPE to a type\n\t  (for example, uint64_t) in FreeRTOSConfig.h to override the default.\n\t+ Introduce ulTaskGetIdleRunTimePercent() to complement the pre-existing\n\t  ulTaskGetIdleRunTimeCounter(). Whereas the pre-existing function returns\n\t  the raw run time counter value, the new function returns the percentage of\n\t  the entire run time consumed by the idle task. Note the amount of idle\n\t  time is only a good measure of the slack time in a system if there are no\n\t  other tasks executing at the idle priority, tickless idle is not used, and\n\t  configIDLE_SHOULD_YIELD is set to 0.\n\t+ ARMv8-M secure-side port:  Tasks that call secure functions from the\n\t  non-secure side of an ARMv8-M MCU (ARM Cortex-M23 and Cortex-M33) have two\n\t  contexts - one on the non-secure side and one on the secure-side. Previous\n\t  versions of the FreeRTOS ARMv8-M secure-side ports allocated the structures\n\t  that reference secure-side contexts at run time.  Now the structures are\n\t  allocated statically at compile time.  The change necessitates the\n\t  introduction of the secureconfigMAX_SECURE_CONTEXTS configuration constant,\n\t  which sets the number of statically allocated secure contexts.\n\t  secureconfigMAX_SECURE_CONTEXTS defaults to 8 if left undefined.\n\t  Applications that only use FreeRTOS code on the non-secure side, such as\n\t  those running third-party code on the secure side, are not affected by\n\t  this change.\n\nChanges between FreeRTOS V10.4.3 and FreeRTOS V10.4.4 released May 28 2021\n\t+ Minor performance improvements to xTaskIncrementTick() achieved by providing\n\t  macro versions of uxListRemove() and vListInsertEnd().\n\t+ Minor refactor of timers.c that obsoletes the need for the\n\t  tmrCOMMAND_START_DONT_TRACE macro and removes the need for timers.c to\n\t  post to its own event queue.  A consequence of this change is that auto-\n\t  reload timers that miss their intended next execution time will execute\n\t  again immediately rather than executing again the next time the command\n\t  queue is processed.  (thanks Jeff Tenney).\n\t+ Fix a race condition in the message buffer implementation.  The\n\t  underlying cause was that length and data bytes are written and read as\n\t  two distinct operations, which both modify the size of the buffer. If a\n\t  context switch occurs after adding or removing the length bytes, but\n\t  before adding or removing the data bytes, then another task may observe\n\t  the message buffer in an invalid state.\n\t+ The xTaskCreate() and xTaskCreateStatic() functions accept a task priority\n\t  as an input parameter.  The priority has always been silently capped to\n\t  (configMAX_PRIORITIES - 1) should it be set to a value above that priority.\n\t  Now values above that priority will also trigger a configASSERT() failure.\n\t+ Replace configASSERT( pcQueueName ) in vQueueAddToRegistry with a NULL\n\t  pointer check.\n\t+ Introduce the configSTACK_ALLOCATION_FROM_SEPARATE_HEAP configuration\n\t  constant that enables the stack allocated to tasks to come from a heap other\n\t  than the heap used by other memory allocations.  This enables stacks to be\n\t  placed within special regions, such as fast tightly coupled memory.\n\t+ If there is an attempt to add the same queue or semaphore handle to the\n\t  queue registry more than once then prior versions would create two separate\n\t  entries.  Now if this is done the first entry is overwritten rather than\n\t  duplicated.\n\t+ Update the ESP32 port and TF-M (Trusted Firmware M)code to the latest from\n\t  their respective repositories.\n\t+ Correct a build error in the POSIX port.\n\t+ Additional minor formatting updates, including replacing tabs with spaces\n\t  in more files.\n\t+ Other minor updates include adding additional configASSERT() checks and\n\t  correcting and improving code comments.\n\t+ Go look at the smp branch to see the progress towards the Symmetric\n\t  Multiprocessing Kernel. https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/smp\n\nChanges between FreeRTOS V10.4.2 and FreeRTOS V10.4.3 released December 14 2020\n\n\tV10.4.3 is included in the 202012.00 LTS release.  Learn more at https:/freertos.org/lts-libraries.html\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.4.x.html\n\n\t+ Changes to improve robustness and consistency for buffer allocation in\n\t  the heap, queue and stream buffer.\n\t+ The following functions can no longer be called from unprivileged code.\n\t  - xTaskCreateRestricted\n\t  - xTaskCreateRestrictedStatic\n\t  - vTaskAllocateMPURegions\n\n\nChanges between FreeRTOS V10.4.1 and FreeRTOS V10.4.2 released November 10 2020\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.4.x.html\n\n\t+ Fix an issue in the ARMv8-M ports that caused BASEPRI to be masked\n\t  between the first task starting to execute and that task making\n\t  a FreeRTOS API call.\n\t+ Introduced xTaskDelayUntil(), which is functionally equivalent to\n\t  vTaskDelayUntil(), with the addition of returning a value to\n\t  indicating whether or not the function placed the calling task into\n\t  the Blocked state or not.\n\t+ Update WolfSSL to 4.5.0 and add the FIPS ready demo.\n\t+ Add support for ESP IDF 4.2 to ThirdParty Xtensa port.\n\t+ Re-introduce uxTopUsedPriority to support OpenOCD debugging.\n\t+ Convert most dependent libraries in FreeRTOS/FreeRTOS to submodules.\n\t+ Various general maintenance and improvements to MISRA compliance.\n\n\nChanges between FreeRTOS V10.4.0 and FreeRTOS V10.4.1 released September 17 2020\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.4.x.html\n\n\t+ Fixed an incorrectly named parameter that prevented the\n\t  ulTaskNotifyTakeIndexed macro compiling, and the name space clash in the\n\t  test code that prevented this error causing test failures.\n\n\nChanges between FreeRTOS V10.3.1 and FreeRTOS V10.4.0 released September 10 2020\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.4.x.html\n\n\tMajor enhancements:\n\n\t+ Task notifications:  Prior to FreeRTOS V10.4.0 each created task had a\n\t  single direct to task notification.  From FreeRTOS V10.4.0 each task has\n\t  an array of notifications.  The direct to task notification API has been\n\t  extended with API functions postfixed with \"Indexed\" to enable the API to\n\t  operate on a task notification at any array index.  See\n\t  https://www.freertos.org/RTOS-task-notifications.html for more information.\n\t+ Kernel ports that support memory protection units (MPUs): The ARMv7-M and\n\t  ARMv8-M MPU ports now support a privilege access only heap. The ARMv7-M\n\t  MPU ports now support devices that have 16 MPU regions, have the ability\n\t  to override default memory attributes for privileged code and data\n\t  regions, and have the ability to place the FreeRTOS kernel code outside of\n\t  the Flash memory. The ARMv8-M MPU ports now support tickless idle mode.\n\t  See https://www.freertos.org/FreeRTOS-MPU-memory-protection-unit.html\n\t  for more information.\n\n\tAdditional noteworthy updates:\n\n\t+ Code formatting is now automated to facilitate the increase in\n\t  collaborative development in Git.  The auto-formated code is not identical\n\t  to the original formatting conventions.  Most notably spaces are now used\n\t  in place of tabs.\n\t+ The prototypes for callback functions (those that start with \"Application\",\n\t  such as vApplicationStackOverflowHook()) are now in the FreeRTOS header\n\t  files, removing the need for application writers to add prototypes into\n\t  the C files in which they define the functions.\n\t+ New Renesas RXv3 port layer.\n\t+ Updates to the Synopsys ARC code, including support for EM and HS cores,\n\t  and updated BSP.\n\t+ Added new POSIX port layer that allows FreeRTOS to run on Linux hosts in\n\t  the same way the Windows port layer enables FreeRTOS to run on Windows\n\t  hosts.\n\t+ Many other minor optimisations and enhancements. For full details\n\t  see https://github.com/FreeRTOS/FreeRTOS-Kernel/commits/main\n\n\nChanges between FreeRTOS V10.3.0 and FreeRTOS V10.3.1 released February 18 2020\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.3.x.html\n\n\t+ ./FreeRTOS-Labs directory was removed from this file. The libraries it\n\tcontained are now available as a separate download.\n\nChanges between FreeRTOS V10.2.1 and FreeRTOS V10.3.0 released February 7 2020\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V10.3.x.html\n\n\tNew and updated kernel ports:\n\n\t+ Added RISC-V port for the IAR compiler.\n\t+ Update the Windows simulator port to use a synchronous object to prevent\n\t  a user reported error whereby a task continues to run for a short time\n\t  after being moved to the Blocked state.  Note we were not able to\n\t  replicate the reported issue and it likely depends on your CPU model.\n\t+ Correct alignment of stack top in RISC-V port when\n\t  configISR_STACK_SIZE_WORDS is defined to a non zero value, which causes\n\t  the interrupt stack to be statically allocated.\n\t+ The RISC-V machine timer compare register can now be for any HART, whereas\n\t  previously it was always assumed FreeRTOS was running on HART 0.\n\t+ Update the sequence used to update the 64-bit machine timer\n\t  compare register on 32-bit cores to match that suggested in RISC-V\n\t  documentation.\n\t+ Added tickless low power modes into the ARM, IAR and GCC Cortex-M0 compiler\n\t  ports.\n\t+ Updated the behaviour of the ARMv7-M MPU (Memory Protection Unit) ports to\n\t  match that of the ARMv8-M ports whereby privilege escalations can only\n\t  originate from within the kernel's own memory segment.  Added\n\t  configENFORCE_SYSTEM_CALLS_FROM_KERNEL_ONLY configuration constant.\n\t+ Update existing MPU ports to correctly disable the MPU before it is\n\t  updated.\n\t+ Added contributed port and demo application for a T-Head (formally C-SKY)\n\t  microcontroller.\n\n\tNew API functions:\n\n\t+ Added the vPortGetHeapStats() API function which returns information on\n\t  the heap_4 and heap_5 state.\n\t+ Added xTaskCatchUpTicks(), which corrects the tick count value after the\n\t  application code has held interrupts disabled for an extended period.\n\t+ Added xTaskNotifyValueClear() API function.\n\t+ Added uxTimerGetReloadMode() API function.\n\n\tOther miscellaneous changes:\n\t+ Change type of uxPendedTicks from UBaseType_t to TickType_t to ensure it\n\t  has the same type as variables with which it is compared to, and therefore\n\t  also renamed the variable xPendingTicks.\n\t+ Update Keil projects that use the MPU so memory regions come from linker\n\t  script (scatter file) variables instead of being hard coded.\n\t+ Added LPC51U68 Cortex-M0+ demos for GCC (MCUXpresso), Keil and IAR\n\t  compilers.\n\t+ Added CORTEX_MPU_STM32L4_Discovery_Keil_STM32Cube demo.\n\t+ Added LPC54018 MPU demo.\n\t+ Rename xTaskGetIdleRunTimeCounter() to ulTaskGetIdleRunTimeCounter().\n\n\nChanges between FreeRTOS V10.2.1 and FreeRTOS V10.2.0 released May 13 2019:\n\n\t+ Added ARM Cortex-M23 port layer to complement the pre-existing ARM\n\t  Cortex-M33 port layer.\n\t+ The RISC-V port now automatically switches between 32-bit and 64-bit\n\t  cores.\n\t+ Introduced the portMEMORY_BARRIER macro to prevent instruction re-ordering\n\t  when GCC link time optimisation is used.\n\t+ Introduced the portDONT_DISCARD macro to the ARMv8-M ports to try and\n\t  prevent the secure side builds from removing symbols required by the\n\t  non secure side build.\n\t+ Introduced the portARCH_NAME to provide additional data to select semi-\n\t  automated build environments.\n\t+ Cortex-M33 and Cortex-M23 ports now correctly disable the MPU before\n\t  updating the MPU registers.\n\n\t+ Added Nuvoton NuMaker-PFM-M2351 ARM Cortex-M23 demo.\n\t+ Added LPC55S69 ARM Cortex-M33 demo.\n\t+ Added an STM32 dual core AMP stress test demo.\n\n\nChanges between FreeRTOS V10.1.1 and FreeRTOS V10.2.0 released February 25 2019:\n\n\t+ Added GCC RISC-V MCU port with three separate demo applications.\n\t+ Included pre-existing ARM Cortex-M33 (ARMv8-M) GCC/ARMclang and IAR ports\n\t  with Keil simulator demo.\n\t+ Update the method used to detect if a timer is active.  Previously the\n\t  timer was deemed to be inactive if it was not referenced from a list.\n\t  However, when a timer is updated it is temporarily removed from, then\n\t  re-added to a list, so now the timer's active status is stored separately.\n\t+ Add vTimerSetReloadMode(), xTaskGetIdleRunTimeCounter(), and\n\t  xTaskGetApplicationTaskTagFromISR() API functions.\n\t+ Updated third party Xtensa port so it is MIT licensed.\n\t+ Added configINCLUDE_PLATFORM_H_INSTEAD_OF_IODEFINE_H to the Renesas\n\t  compiler RX600v2 port to enable switching between platform.h and\n\t  iodefine.h includes within that port's port.c file.\n\t+ Removed the 'FromISR' functions from the MPU ports as ISRs run privileged\n\t  anyway.\n\t+ Added uxTaskGetStackHighWaterMark2() function to enable the return type to\n\t  be changed without breaking backward compatibility.\n\t  uxTaskGetStackHighWaterMark() returns a UBaseType_t as always,\n\t  uxTaskGetStackHighWaterMark2() returns configSTACK_DEPTH_TYPE to allow the\n\t  user to determine the return type.\n\t+ Fixed issues in memory protected ports related to different combinations\n\t  of static memory only and dynamic memory only builds.  As a result the\n\t  definition of tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE became more\n\t  complex and was moved to FreeRTOS.h with a table explaining its definition.\n\t+ Added a 'get task tag from ISR' function.\n\t+ Change the method used to determine if a timer is active or not from just\n\t  seeing if it is referenced from the active timer list to storing its\n\t  active state explicitly.  The change prevents the timer reporting that it\n\t  is inactive while it is being moved from one list to another.\n\t+ The pcName parameter passed into the task create functions can be NULL,\n\t  previously a name had to be provided.\n\t+ When using tickless idle, prvResetNextTaskUnblockTime() is now only called\n\t  in xTaskRemoveFromEventList() if the scheduler is not suspended.\n\t+ Introduced portHAS_STACK_OVERFLOW_CHECKING, which should be set to 1 for\n\t  FreeRTOS ports that run on architectures that have stack limit registers.\n\n\nChanges between FreeRTOS V10.1.0 and FreeRTOS V10.1.1 released 7 September 2018\n\n\t+ Reverted a few structure name changes that broke several kernel aware\n\t  debugger plug-ins.\n\t+ Updated to the latest trace recorder code.\n\t+ Fixed some formatting in the FreeRTOS+TCP TCP/IP stack code.\n\t+ Reverted moving some variables from file to function scope as doing so\n\t  broke debug scenarios that require the static qualifier to be removed.\n\nChanges between FreeRTOS V10.0.1 and FreeRTOS V10.1.0 released 22 August 2018\n\n\tFreeRTOS Kernel Changes:\n\n\t+ Update lint checked MISRA compliance to use the latest MISRA standard, was\n\t  previously using the original MISRA standard.\n\t+ Updated all object handles (TaskHandle_t, QueueHandle_t, etc.) to be\n\t  unique types instead of void pointers, improving type safety.  (this was\n\t  attempted some years back but had to be backed out due to bugs in some\n\t  debuggers).  Note this required the pvContainer member of a ListItem_t\n\t  struct to be renamed - set configENABLE_BACKWARD_COMPATIBILITY to 1 if\n\t  this causes an issue.\n\t+ Added configUSE_POSIX_ERRNO to enable per task POSIX style errno\n\t  functionality in a more user friendly way - previously the generic thread\n\t  local storage feature was used for this purpose.\n\t+ Added Xtensa port and demo application for the XCC compiler.\n\t+ Changed the implementation of vPortEndScheduler() for the Win32 port to\n\t  simply call exit( 0 ).\n\t+ Bug fix in vPortEnableInterrupt() for the GCC Microblaze port to protect\n\t  the read modify write access to an internal Microblaze register.\n\t+ Fix minor niggles when the MPU is used with regards to prototype\n\t  differences, static struct size differences, etc.\n\t+ The usStackHighWaterMark member of the TaskStatus_t structure now has type\n\t  configSTACK_DEPTH_TYPE in place of uint16_t - that change should have been\n\t  made when the configSTACK_DEPTH_TYPE type (which gets around the previous\n\t  16-bit limit on stack size specifications) was introduced.\n\t+ Added the xMessageBufferNextLengthBytes() API function and likewise stream\n\t  buffer equivalent.\n\t+ Introduce configMESSAGE_BUFFER_LENGTH_TYPE to allow the number of bytes\n\t  used to hold the length of a message in the message buffer to be reduced.\n\t  configMESSAGE_BUFFER_LENGTH_TYPE default to size_t, but if, for example,\n\t  messages can never be more than 255 bytes it could be set to uint8_t,\n\t  saving 3 bytes each time a message is written into the message buffer\n\t  (assuming sizeof( size_t ) is 4).\n\t+ Updated the StaticTimer_t structure to ensure it matches the size of the\n\t  Timer_t structure when the size of TaskFunction_t does not equal the size\n\t  of void *.\n\t+ Update various Xilinx demos to use 2018.1 version of the SDK tools.\n\t+ Various updates to demo tasks to maintain test coverage.\n\t+ FreeRTOS+UDP was removed in FreeRTOS V10.1.0 as it was replaced by\n\t  FreeRTOS+TCP, which was brought into the main download in FreeRTOS\n\t  V10.0.0.  FreeRTOS+TCP can be configured as a UDP only stack, and\n\t  FreeRTOS+UDP does not contain the patches applied to FreeRTOS+TCP.\n\n\tFreeRTOS+TCP Changes:\n\n\t+ Multiple security improvements and fixes in packet parsing routines, DNS\n\t  caching, and TCP sequence number and ID generation.\n\t+ Disable NBNS and LLMNR by default.\n\t+ Add TCP hang protection by default.\n\n\tWe thank Ori Karliner of Zimperium zLabs Team for reporting these issues.\n\n\nChanges between FreeRTOS V10.0.0 and FreeRTOS V10.0.1, released December 20 2017\n\n\t+ Fix position of \"#if defined( __cplusplus )\" in stream_buffer.h.\n\t+ Correct declarations of MPU_xQueuePeek() and MPU_xQueueSemaphoreTake() in\n\t  mpu_prototypes.h.\n\t+ Correct formatting in vTaskList() helper function when it prints the state\n\t  of the currently executing task.\n\t+ Introduce #error if stream_buffer.c is built without\n\t  configUSE_TASK_NOTIFICATIONS set to 1.\n\t+ Update FreeRTOS+TCP to V2.0.0\n\t\t- Improve the formatting of text that displays the available netword\n\t\t  interfaces when FreeRTOS+TCP is used on Windows with WinPCap.\n\t\t- Introduce ipconfigSOCKET_HAS_USER_WAKE_CALLBACK option to enable a user\n\t\t  definable callback to execute when data arrives on a socket.\n\nChanges between FreeRTOS V9.0.1 and FreeRTOS V10.0.0:\n\n\tThe FreeRTOS kernel is now MIT licensed: https://www.FreeRTOS.org/license\n\n\tNew Features and components:\n\n\t+ Stream Buffers - see https://www.FreeRTOS.org/RTOS-stream-buffer-example.html\n\t+ Message Buffers - see https://www.FreeRTOS.org//RTOS-message-buffer-example.html\n\t+ Move FreeRTOS+TCP into the main repository, along with the basic Win32\n\t  TCP demo FreeRTOS_Plus_TCP_Minimal_Windows_Simulator.\n\n\tNew ports or demos:\n\n\t+ Added demo for TI SimpleLink CC3220 MCU.\n\t+ Added MPU and non MPU projects for Microchip CEC and MEC 17xx and 51xx\n\t  MCUs.\n\t+ Added CORTEX_MPU_Static_Simulator_Keil_GCC demo to test static allocation\n\t  in the MPU port.\n\n\tFixes or enhancements:\n\n\t+ Cortex-M ports push additional register prior to calling\n\t  vTaskSwitchContext to ensure 8-byte alignment is maintained.  Only\n\t  important if a user defined tick hook function performs an operation that\n\t  requires 8-byte alignment.\n\t+ Optimisations to the implementation of the standard tickless idle mode on\n\t  Cortex-M devices.\n\t+ Improvements to the Win32 port including using higher priority threads.\n\t+ Ensure interrupt stack alignment on PIC32 ports.\n\t+ Updated GCC TriCore port to build with later compiler versions.\n\t+ Update mpu_wrappers.c to support static allocation.\n\t+ The uxNumberOfItems member of List_t is now volatile - solving an issue\n\t  when the IAR compiler was used with maximum optimization.\n\t+ Introduced configRECORD_STACK_HIGH_ADDRESS.  When set to 1 the stack start\n\t  address is saved into each task's TCB (assuming stack grows down).\n\t+ Introduced configINCLUDE_FREERTOS_TASK_C_ADDITIONS_H to allow user defined\n\t  functionality, and user defined initialisation, to be added to FreeRTOS's\n\t  tasks.c source file.  When configINCLUDE_FREERTOS_TASK_C_ADDITIONS_H is\n\t  set to 1 a user provided header file called freertos_task_c_additions.h\n\t  will be included at the bottom of tasks.c.  Functions defined in that\n\t  header file can call freertos_tasks_c_additions_init(), which in turn\n\t  calls a macro called FREERTOS_TASKS_C_ADDITIONS_INIT(), if it is defined.\n\t  FREERTOS_TASKS_C_ADDITIONS_INIT() can be defined in FreeRTOSConfig.h.\n\t+ Introduced configPRE_SUPPRESS_TICKS_AND_SLEEP_PROCESSING( x ) which can be\n\t  defined by a user in FreeRTOSConfig.h.  The macro is called before\n\t  assessing whether to enter tickless idle mode or not.  If the macro sets\n\t  x to zero then tickless idle mode will not be entered.  This allows users\n\t  to abort tickless idle mode entry before the tickless idle function is\n\t  even called - previously it was only possible to abort from within the\n\t  tickless idle function itself.\n\t+ Added configPRINTF(), which can be defined by users to allow all libraries\n\t  to use the same print formatter.\n\t+ Introduced configMAX() and configMIN() macros which default to standard\n\t  max( x, y ) and min( x, y ) macro behaviour, but can be overridden if the\n\t  application writer defines the same macros in FreeRTOSConfig.h.\n\t+ Corrected the definition of StaticTask_t in the case where\n\t  INCLUDE_xTaskAbortDelay is set to 1.\n\t+ Introduced configTIMER_SERVICE_TASK_NAME and configIDLE_TASK_NAME, both of\n\t  which can be defined to strings in FreeRTOSConfig.h to change the default\n\t  names of the timer service and idle tasks respectively.\n\t+ Only fill the stack of a newly created task with a known value if stack\n\t  checking, or high water mark checking/viewing, is in use - removing the\n\t  dependency on memset() in other cases.\n\t+ Introduced xTaskCreateRestrictedStatic() so static allocation can be used\n\t  with the MPU.\n\t+ Ensure suspended tasks cannot be unsuspended by a received task\n\t  notification.\n\t+ Fix race condition in vTaskSetTimeOutState().\n\t+ Updated trace recorder files to the latest version.\n\nChanges since FreeRTOS V9.0.0:\n\n\t+ Priority dis-inheritance behaviour has been enhanced in the case where a\n\t  task that attempted to take a mutex that was held by a lower priority task\n\t  timed out before it was able to obtain the mutex (causing the task that\n\t  holds the mutex to have its priority raised, then lowered again, in\n\t  accordance with the priority inheritance protocol).\n\t+ Split the overloaded xQueueGenericReceive() function into three separate\n\t  dedicated functions.\n\t+ Allow the default human readable text names given to the Idle and Timer\n\t  tasks to be overridden by defining the configIDLE_TASK_NAME and\n\t  configTIMER_SERVICE_TASK_NAME definitions respectively in FreeRTOSConfig.h.\n\t+ Introduced configINITIAL_TICK_COUNT to allow the tick count to take a\n\t  value of than than 0 when the system boots.  This can be useful for\n\t  testing purposes - although setting configUSE_16_BIT_TICKS to 1 can also\n\t  be used to test frequent tick overflows.\n\t+ Ensure the Cortex-M SysTick count is cleared to zero before starting the\n\t  first task.\n\t+ Add configASSERT() into ARM Cortex-M ports to check the number of priority\n\t  bit settings.\n\t+ Clear the 'control' register before starting ARM Cortex-M4F ports in case\n\t  the FPU is used before the scheduler is started.  This just saves a few\n\t  bytes on the main stack as it prevents space being left for a later save\n\t  of FPU registers.\n\t+ Added xSemaphoreGetMutexHolderFromISR().\n\t+ Corrected use of portNVIC_PENDSVSET to portNVIC_PENDSVSET_BIT in MPU ports.\n\t+ Introduced configSTACK_DEPTH_TYPE to allow users to change the type used\n\t  to specify the stack size when using xTaskCreate().  For historic reasons,\n\t  when FreeRTOS was only used on small MCUs, the type was set to uint16_t,\n\t  but that can be too restrictive when FreeRTOS is used on larger\n\t  processors.  configSTACK_DEPTH_TYPE defaults to uint16_t.\n\t  xTaskCreateStatic(), being a newer function, used a uint32_t.\n\t+ Increase the priority of the Windows threads used by the Win32 port.  As\n\t  all the threads run on the same core, and the threads run with very high\n\t  priority, there is a risk that the host will become unresponsive, so also\n\t  prevent the Windows port executing on single core hosts.\n\nChanges between FreeRTOS V9.0.0 and FreeRTOS V9.0.0rc2 released May 25 2016:\n\n\tSee https://www.FreeRTOS.org/FreeRTOS-V9.html\n\n\tRTOS kernel updates:\n\n\t+ The prototype of the new xTaskCreateStatic() API function was modified to\n\t  remove a parameter and improve compatibility with other new\n\t  \"CreateStatic()\" API functions.  The stack size parameter in\n\t  xTaskCreateStatic() is now uint32_t, which changes the prototype of the\n\t  callback functions.  See the following URL:\n\t  https://www.FreeRTOS.org/xTaskCreateStatic.html\n\t+ GCC ARM Cortex-A port:  Introduced the configUSE_TASK_FPU_SUPPORT\n\t  constant.  When configUSE_TASK_FPU_SUPPORT is set to 2 every task is\n\t  automatically given a floating point (FPU) context.\n\t+ GCC ARM Cortex-A port:  It is now possible to automatically save and\n\t  restore all floating point (FPU) registers on entry to each potentially\n\t  nested interrupt by defining vApplicationFPUSafeIRQHandler() instead of\n\t  vApplicationIRQHandler().\n\t+ All ARM Cortex-M3/4F/7 ports:  Clear the least significant bit of the task\n\t  entry address placed onto the stack of a task when the task is created for\n\t  strict compliance with the ARM Cortex-M3/4/7 architecture documentation\n\t  (no noticeable effect unless using the QMEU emulator).\n\t+ Added GCC and Keil ARM Cortex-M4F MPU ports - previously the MPU was only\n\t  supported on ARM Cortex-M3.\n\t+ ARM Cortex-M3/4F MPU ports:  Update to fully support the FreeRTOS V9.0.0\n\t  API (other than static object creation) and added the\n\t  FreeRTOS/Demo/CORTEX_MPU_Simulator_Keil_GCC demo application to\n\t  demonstrate how to use the updated MPU port.\n\t+ All ARM Cortex-M3/4F/7 ports:  Add additional barrier instructions to the\n\t  default low power tickless implementation.\n\t+ All ARM Cortex-M0 ports:  Prevent an item being left on the stack of the\n\t  first task that executes.\n\t+ Win32 ports:  Reduce the amount of stack used and change the way Windows\n\t  threads are deleted to increase the maximum execution time.\n\t+ Add an ARM Cortex-M4F port for the MikroC compiler.  Ensure to read the\n\t  documentation page for this port before use.\n\t+ MPS430X IAR port:  Update to be compatible with the latest EW430 tools\n\t  release.\n\t+ IAR32 GCC port:  Correct vPortExitCritical() when\n\t  configMAX_API_CALL_INTERRUPT_PRIORITY == portMAX_PRIORITY.\n\t+ For consistency vTaskGetTaskInfo() now has the alias vTaskGetInfo(),\n\t  xTaskGetTaskHandle() now has the alias xTaskGetHandle() and\n\t  pcQueueGetQueueName() now has an alias pcQueueGetName().\n\t+ Fix various errors in comments and compiler warnings.\n\n\tDemo application updates:\n\n\t+ Update Atmel Studio projects to use Atmel Studio 7.\n\t+ Update Xilinx SDK projects to use the 2016.1 version of the SDK.\n\t+ Remove dependency on legacy IO libraries from the PIC32 demos.\n\t+ Move the Xilinx UltraScale Cortex-R5 demo into the main distribution.\n\t+ Update the MSP432 libraries to the latest version.\n\t+ Add Microchip CEC1302 (ARM Cortex-M4F) demos for GCC, Keil and MikroC\n\t  compilers.\n\t+ Move the Atmel SAMA5D2 demo into the main distribution.\n\nChanges between FreeRTOS V9.0.0rc1 and FreeRTOS V9.0.0rc2 (release candidate 2)\nreleased March 30 2016:\n\n\tNOTE - See https://www.FreeRTOS.org/FreeRTOS-V9.html for details\n\n\t+ The functions that create RTOS objects using static memory allocation have\n\t  been simplified and will not revert to using dynamic allocation if a\n\t  buffer is passed into a function as NULL.\n\t+ Introduced the configSUPPORT_DYNAMIC_ALLOCATION configuration constant to\n\t  allow a FreeRTOS application to be built without a heap even being being\n\t  defined. The Win32 example located in the\n\t  /FreeRTOS/demo/WIN32-MSVC-Static-Allocation-Only directory is provided as\n\t  a reference for projects that do not include a FreeRTOS heap.\n\t+ Minor run-time optimisations.\n\t+ Two new low power tickless implementations that target Silicon Labs EFM32\n\t  microcontrollers.\n\t+ Addition of the xTimerGetPeriod() and xTimerGetExpireTime() API functions.\n\nChanges between FreeRTOS V8.2.3 and FreeRTOS V9.0.0rc1 (release candidate 1)\nreleased February 19 2016:\n\n\tRTOS Kernel Updates:\n\n\t+ Major new feature - tasks, semaphores, queues, timers and event groups can\n\t  now be created using statically allocated memory, so without any calls to\n\t  pvPortMalloc().\n\t+ Major new features - Added the xTaskAbortDelay() API function which allows\n\t  one task to force another task to immediately leave the Blocked state,\n\t  even if the event the blocked task is waiting for has not occurred, or the\n\t  blocked task's timeout has not expired.\n\t+ Updates necessary to allow FreeRTOS to run on 64-bit architectures.\n\t+ Added vApplicationDaemonTaskStartupHook() which executes when the RTOS\n\t  daemon task (which used to be called the timer service task) starts\n\t  running.  This is useful if the application includes initialisation code\n\t  that would benefit from executing after the scheduler has been started.\n\t+ Added the xTaskGetTaskHandle() API function, which obtains a task handle\n\t  from the task's name.  xTaskGetTaskHandle() uses multiple string compare\n\t  operations, so it is recommended that it is called only once per task.\n\t  The handle returned by xTaskGetTaskHandle() can then be stored locally for\n\t  later re-use.\n\t+ Added the pcQueueGetQueueName() API function, which obtains the name of\n\t  a queue from the queue's handle.\n\t+ Tickless idling (for low power applications) can now also be used when\n\t  configUSE_PREEMPTION is 0.\n\t+ If one task deletes another task, then the stack and TCB of the deleted\n\t  task is now freed immediately.  If a task deletes itself, then the stack\n\t  and TCB of the deleted task are freed by the Idle task as before.\n\t+ If a task notification is used to unblock a task from an ISR, but the\n\t  xHigherPriorityTaskWoken parameter is not used, then pend a context switch\n\t  that will then occur during the next tick interrupt.\n\t+ Heap_1.c and Heap_2.c now use the configAPPLICATION_ALLOCATED_HEAP\n\t  settings, which previously was only used by heap_4.c.\n\t  configAPPLICATION_ALLOCATED_HEAP allows the application writer to declare\n\t  the array that will be used as the FreeRTOS heap, and in-so-doing, place\n\t  the heap at a specific memory location.\n\t+ TaskStatus_t structures are used to obtain details of a task.\n\t  TaskStatus_t now includes the bae address of the task's stack.\n\t+ Added the vTaskGetTaskInfo() API function, which returns a TaskStatus_t\n\t  structure that contains information about a single task.  Previously this\n\t  information could only be obtained for all the tasks at once, as an array\n\t  of TaskStatus_t structures.\n\t+ Added the uxSemaphoreGetCount() API function.\n\t+ Replicate previous Cortex-M4F and Cortex-M7 optimisations in some\n\t  Cortex-M3 port layers.\n\n\tDemo Application Updates:\n\n\tFurther demo applications will be added prior to the final FreeRTOS V9\n\trelease.\n\n\t+ Updated SAM4L Atmel Studio project to use Atmel Studio 7.\n\t+ Added ARM Cortex-A53 64-bit port.\n\t+ Added a port and demo for the ARM Cortex-A53 64-bit cores on the Xilinx\n\t  Ultrascale MPSoC.\n\t+ Added Cortex-M7 SAME70 GCC demo.\n\t+ Added EFM32 Giant and Wonder Gecko demos.\n\n\nChanges between V8.2.2 and V8.2.3 released October 16, 2015\n\n\tRTOS kernel updates:\n\n\t+ Fix bug identified in a modification made in V8.2.2 to the software timer\n\t  code that allows tickless low power applications to sleep indefinitely\n\t  when software timers are used.\n\t+ Simplify and improve efficiency of stack overflow checking.\n\t+ Add xTaskNotifyStateClear() API function.\n\t+ New IAR and GCC Cortex-R ports for microprocessors that do not use an ARM\n\t  generic interrupt controller (GIC).\n\t+ New PIC32MEC14xx port.\n\t+ Add support for PIC32MZ EF parts (with floating point) into the PIC32MZ\n\t  port.\n\t+ Zynq7000 port layer now declares the functions that setup and clear the\n\t  tick interrupt as weak symbols so they can be overridden by the\n\t  application, and uses a global XScuGic object so the same object can be\n\t  used by the application code.\n\t+ Introduced configUSE_TASK_FPU_SUPPORT, although the PIC32MZ EF port is\n\t  currently the only port that uses it.\n\t+ Updates to RL78 and 78K0 IAR port layers to improve support for\n\t  combinations of memory models.\n\t+ Minor updates to heap_5.c to remove compiler warnings generated by some\n\t  compilers.\n\t+ License simplifications.  See /FreeRTOS/License/license.txt in the\n\t  official distribution.\n\n\tFreeRTOS+ updates:\n\n\t+ Update directory names to use WolfSSL instead of CyaSSL, inline with\n\t  WolfSSL's re-branding.\n\t+ Update to latest WolfSSL code.\n\t+ Update to latest FreeRTOS+Trace recorder code.\n\t+ Add in the FreeRTOS+Trace recorder library required for streaming trace.\n\n\tDemo application changes:\n\n\t+ Add demo applications for Renesas RZ/T (Cortex-R), PIC32MZ EF (PIC32 with\n\t  floating point hardware), PIC32MEC14xx, RX71M, RX113 and RX231.\n\t+ General tidy up of spelling and compiler warnings.\n\n\nChanges between V8.2.1 and V8.2.2 released August 12, 2015\n\n\tRTOS kernel updates:\n\n\t+ Added Intel IA32/x86 32-bit port.\n\t+ General maintenance.\n\t+ PRIVILEGED_FUNCTION and PRIVILEGED_DATA macros, which are used in memory\n\t  protected systems, have been added to the newer event group and software\n\t  timer functions.\n\t+ Add the errno definitions used by FreeRTOS+ components into projdefs.h.\n\t+ Remove the restriction that prevented tick-less idle implementations\n\t  waiting indefinitely when software timers were used in the same\n\t  application.\n\t+ Introduce xTaskNotifyAndQueryFromISR() as the interrupt safe version of\n\t  xTaskNotifyAndQuery().\n\t+ Add additional NOPs to the MSP430X port layers to ensure strict compliance\n\t  with the hardware documentation.\n\t+ Microblaze port: Added option for port optimised task selection.\n\t+ Microblaze port: Previously tasks inherited the exception enable state\n\t  at the time the task was created.  Now all tasks are created with\n\t  exceptions enabled if the Microblaze design supports exceptions.\n\t+ Windows port: Add additional safe guards to ensure the correct start up\n\t  sequence and thread switching timing.\n\t+ Windows port: Improve the implementation of the port optimised task\n\t  selection assembly code.\n\t+ Update heap_4 and heap_5 to allow use on 64-bit processors.\n\t+ Simplify the code that creates a queue.\n\t+ General improved tick-less idle behaviour.\n\t+ Ensure none of the variables in the common kernel files are initialised to\n\t  anything other than zero.\n\t+ Correct calculation of xHeapStructSize in heap_4 and heap_5.\n\n\tDemo application updates:\n\n\t+ Added demo project for the new IA32/x86 port that targets the Galileo\n\t  hardware.\n\t+ Added MSP430FR5969 demos (previously provided as a separate download).\n\t+ Added FreeRTOS BSP repository for automatic creation of FreeRTOS\n\t  applications in the Xilinx SDK.\n\t+ Added Atmel Studio / GCC project for the SAMV71 (ARM Cortex-M7)\n\t+ Update Xilinx SDK projects to use version 2015.2 of the SDK.\n\t+ Remove Microblaze demos that were using obsolete tools.\n\t+ Add MSP43FR5969 IAR and CCS demos.\n\n\tFreeRTOS+ Updates:\n\n\t+ Updated FreeRTOS+Trace recorder library, which requires an update to the\n\t  FreeRTOS+Trace application.\n\t+ Added Reliance Edge source code and demo application.  Reliance edge is\n\t  a fail safe transactional file system ideal for applications that require\n\t  file storage, and especially when high reliability is essential.\n\t+ Introduce configAPPLICATION_PROVIDES_cOutputBuffer to allow FreeRTOS+CLI\n\t  users to place the output buffer at a fixed memory address.\n\t+ Improve the NetworkInterface.c file provided for the Windows port of\n\t  FreeRTOS+UDP.\n\nChanges between V8.2.0 and V8.2.1 released 24th March 2015.\n\n\tRTOS kernel updates:\n\n\t+ Added user definable and flexible thread local storage facility.\n\t+ Added vTimerSetTimerID() API function to complement the pvTimerGetTimerID()\n\t  function to allow the timer's ID to be used as timer local storage.\n\t+ Fixed a potential issue related to the use of queue sets from an ISR.\n\t+ Some updates to the Xilinx Microblaze GCC port.\n\t+ Added ARM Cortex-M4F port for Texas Instruments Code Composer Studio.\n\t+ Added ARM Cortex-M7 r0p1 port layer for IAR, GCC and Keil which contains a\n\t  minor errata work around.  All other ARM Cortex-M7 core revisions should\n\t  use the ARM Cortex-M4F port.\n\t+ Exclude the whole of croutine.c if configUSE_CO_ROUTINES is set to 0.\n\t+ Change some data types from uint32_t to size_t in preparation for 64-bit\n\t  Windows port.\n\t+ Update the PIC32 port to remove deprecation warnings output by the latest\n\t  XC32 compilers.\n\t+ Fix bug when xQueueOverwrite() and xQueueOverwrite() from ISR are used to\n\t  overwrite items in two queues that are part of the same set.\n\n\tDemo application updates:\n\n\t+ Added demo application for TI's ARM Cortex-M4F based MSP432\n\t  microcontroller using IAR, Keil and CCS compilers.\n\t+ Added demo application for STM32F ARM Cortex-M7 based microcontroller\n\t  using IAR and Keil.\n\t+ Added demo application for Atmel SAMV71 ARM Cortex-M7 based\n\t  microcontroller using IAR and Keil.\n\t+ Added Microblaze demo that uses the 2014.4 version of the Xilinx SDK and\n\t  runs on the KC705 evaluation board (Kintex FPGA).\n\nChanges between V8.1.2 and V8.2.0 released 16th January 2015\n\n\tChanges between release candidate 1 and the official release are restricted\n\tto maintenance only.\n\n\tSignificant RTOS kernel updates:\n\n\t+ MAJOR NEW FEATURE!  Task notifications.  Please see the following URL for\n\t  details: https://www.FreeRTOS.org/RTOS-task-notifications.html\n\t+ NEW HEADER FILE REQUIRED!  Obsolete definitions have been separated into\n\t  a new header file called FreeRTOS/Source/include/deprecated_definitions.h.\n\t  This header file must be present to build.  Note some of the obsolete\n\t  definitions are still used by very old demo application projects.\n\n\tOther RTOS kernel updates:\n\n\t+ Made xSemaphoreGiveFromISR() a function rather than a macro that calls\n\t  xQueueGenericSendFromISR().  This allows for major performance\n\t  enhancements at the expense of some additional code size if both functions\n\t  are used in the same application.  NOTE:  In most uses cases such use of\n\t  a semaphore can now be replaced with a task notification which is smaller\n\t  and faster still.\n\t+ The TCB is now always allocated such that the task's stack grows away from\n\t  the TCB (improves debugging of stack overflows as the overflow will not\n\t  overwrite the task's name).\n\t+ GCC, IAR and Keil Cortex-M4F ports now use more inlining (performance\n\t  enhancements at the cost of a little additional code space).\n\t+ Queues are now allocated with a single call to pvPortMalloc() which\n\t  allocates both the queue structure and the queue storage area.\n\t+ Introduced a new critical section macro for reading the tick count that\n\t  defines away to nothing in cases where the width of the tick allows the\n\t  tick count to be read atomically (performance benefits - especially when\n\t  optimisation is on).\n\t+ Introduced configAPPLICATION_ALLOCATED_HEAP in heap_4.c to allow the\n\t  application writer to provide their own heap array - and in so doing\n\t  control the location of the heap.\n\t+ Introduced configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES which, when set, will\n\t  include known values in both list and list item structures.  The values\n\t  are intended to assist debugging.  If the values get overwritten then it\n\t  is likely application code has written over RAM used by the kernel.\n\t+ configASSERT()s in all Cortex-M ports used to test the lowest 5 bits of\n\t  the interrupt control register to detect taskENTER_CRITICAL() being called\n\t  from an interrupt.  This has been changed to test all 8 bits.\n\t+ Introduced uxTaskPriorityGetFromISR().\n\t+ Microblze V8 port now tests XPAR_MICROBLAZE_0_USE_FPU for inequality to 0\n\t  rather than equality to 1, and 2 and 3 are also valid values.\n\t+ Cortex-A5 GIC-less port no longer passes the address of the interrupting\n\t  peripheral into the interrupt handler.\n\t+ Fix an issue in FreeRTOS-MPU where an attempt was made to free the stack\n\t  belonging to a task when the task was deleted, even when the stack was\n\t  allocated statically.\n\t+ Utility (helper) functions that format task statistic information into\n\t  human readable tables now pad task names with spaces to ensure columns\n\t  line up correctly even where task name lengths vary greatly.\n\t+ Update FreeRTOS+Trace recorder library to version 2.7.0.\n\n\tDemo application updates:\n\n\t+ Added two new standard demo task sets:  IntSemTest and TaskNotify.\n\t+ Added port and demo application for Atmel SAMA5D4 Cortex-A5 MPU.\n\t+ Added demo application for Altera Cyclone V Cortex-A9 MPU.\n\t+ Updated Zynq demo to use version 2014.4 of Xilinx's SDK and added in\n\t  demo tasks for new RTOS features.\n\t+ Updated Atmel SAM4E and SAM4S demos to include a lot of additional test\n\t  and demo tasks.\n\t+ Fixed a corner case issue in Atmel SAM4L low power tickless\n\t  implementation, and added button interrupt handling.\n\t+ Make the interrupt queue tests more tolerant to heave CPU loads.\n\t+ Updated MSVC FreeRTOS simulator demo to include the latest standard test\n\t  and demo tasks.\n\t+ Updated MingW/Eclipse FreeRTOS simulator demo to match the FreeRTOS MSVC\n\t  simulator demo.\n\t+ Updated all demos that use FreeRTOS+Trace to work with the latest trace\n\t  recorder code.\n\n\nChanges between V8.1.1 and V8.1.2 released September 2nd 2014\n\n\tMove the defaulting of configUSE_PORT_OPTIMISED_TASK_SELECTION into the\n\tindividual port layers where necessary so it does not affect ports that do\n\tnot support the definition.\n\nChanges between V8.1.0 and V8.1.1 released August 29th 2014\n\n\tBy popular requests - a minor patch to V8.1.0 to re-instate the ability to\n\tgive a mutex type semaphore (with priority inheritance) from an interrupt\n\thandler.\n\nChanges between V8.0.1 and V8.1.0 released August 26th 2014\n\n\tFreeRTOS scheduler, kernel, demo and test updates:\n\n\t+ Improved the priority inheritance algorithms to assist integration with\n\t  off the shelf middleware that may hold multiple mutexes simultaneously.\n\t+ Introduce heap_5.c, which is similar to heap_4.c but allows the heap to\n\t  span multiple non-contiguous memory regions.\n\t+ Updated all Cortex-A9 ports to help trap a couple of common usage errors -\n\t  the first being when a task incorrectly attempts to exit its implementing\n\t  function and the second being when a non interrupt safe API function is\n\t  called from an interrupt.\n\t+ Update all Cortex-A9 ports to remove obsolete mode switches prior to\n\t  restoring a task context.\n\t+ configUSE_PORT_OPTIMISED_TASK_SELECTION now defaults to 1 instead of 0.\n\t+ Update all Cortex-M3/4F ports to trap a non interrupt safe API function\n\t  being called from an interrupt handler.\n\t+ Simplify the alignment checks in heap_4.c.\n\t+ Update the MSVC Windows simulator demo to use heap_5.c in place of\n\t  heap_4.c to ensure end users have an example to refer to.\n\t+ Updated standard demo test code to test the new priority inheritance\n\t  algorithms.\n\t+ Updated the standard demo tasks to make use of stdint and the FreeRTOS\n\t  specific typedefs that were introduced in FreeRTOS V8.0.0.\n\t+ Introduce the pdMS_TO_TICKS() macro as a more user friendly and intuitive\n\t  alternative to pdTICKS_PER_MS - both of which can be used to convert a\n\t  time specified in milliseconds to a time specified in RTOS ticks.\n\t+ Fix a bug in the Tasking compiler's Cortex-M port that resulted in an\n\t  incorrect value being written to the basepri register.  This only effects\n\t  users of the Tasking compiler.\n\t+ Update the Zynq demo to use version 2014.2 of the SDK and add in an lwIP\n\t  example that demonstrates lwIP being used with both its raw and sockets\n\t  interfaces.\n\t+ Updated the CCS Cortex-R4 port to enable it to be built with the latest\n\t  CCS compiler.\n\n\tNew ports and demo applications:\n\n\t+ Two Renesas RX64M ports (RXv2 core) and demos introduced, one for the GCC\n\t  compiler and one for the Renesas compiler.  Both demos use e2 studio.\n\t+ Generic IAR Cortex-A5 port (without any reliance on a GIC) introduced.\n\t  The new port is demonstrated on an Atmel SAMA5D3 XPlained board.\n\n\tFreeRTOS+ component updates:\n\n\t+ Update CyaSSL to the latest version.\n\t+ Updated the FreeRTOS+ components supplied directly by Real Time Engineers\n\t  Ltd. to make use of stdint and the FreeRTOS specific typedefs that were\n\t  introduced in FreeRTOS V8.0.0.\n\t+ Rework and simplify the FreeRTOS+FAT SL RAM disk driver.\n\n\tMiscellaneous updates and maintenance:\n\n\t+ Update the IAR and DS-5/ARM RZ demos to target the official RZ RSK\n\t  hardware in place of the previously targeted Renesas internal (not\n\t  publicly available) hardware.\n\t+ Various other maintenance tasks.\n\n\nChanges between V8.0.0 and V8.0.1 released 2nd May 2014\n\n\t+ Minor fixes to the event group functionality that was released in V8.0.0.\n\t  The 'clear bits from ISR' functionality is now implemented using a\n\t  deferred interrupt callback instead of a function, and the 'wait bits' and\n\t  'task sync' functions now correctly clear internal control bits before\n\t  returning a value in every possible path through the respective functions.\n\t+ Ensure the updating of internal control data is protected by a critical\n\t  section after a task is deleted or suspended.\n\t+ Minor fixes to FreeRTOS+FAT SL - namely seeking beyond the end of a file\n\t  when the offset was not a multiple of the sector size.\n\t+ Ensure Cortex-A9 system registers are only ever accessed as 32-bit values,\n\t  even when only the lest significant byte of the register is implemented.\n\n\tOther updates:\n\n\t+ Updated the XMC4200 IAR project so it links with version 7.x of the IAR\n\t  tools.\n\t+ Add RL78L1C demo.\n\t+ Add pcTimerGetName() API function.\n\t+ Call _reclaim_reent() when a task is deleted if configUSE_NEWLIB_REENTRANT\n\t  is defined.\n\nChanges between V7.6.0 and V8.0.0 released 19th Feb 2014\n\n\thttps://www.FreeRTOS.org/upgrading-to-FreeRTOS-V8.html\n\n\tFreeRTOS V8.x.x is a drop-in compatible replacement for FreeRTOS V7.x.x,\n\talthough a change to the type used to reference character strings may result\n\tin application code generating a few (easily clearable) compiler warnings\n\tafter the upgrade, and an updated typedef naming convention means use of the\n\told typedef names is now discouraged.\n\tSee https://www.FreeRTOS.org/upgrading-to-FreeRTOS-V8.html for full\n\tinformation.\n\n\tNew features and functionality:\n\n\t+ Event groups - see https://www.FreeRTOS.org/FreeRTOS-Event-Groups.html\n\t+ Centralised deferred interrupt processing - see\n\t  https://www.FreeRTOS.org/xTimerPendFunctionCallFromISR.html\n\n\tOther updates:\n\n\t+ Previously, when a task left the Blocked state, a context switch was\n\t  performed if the priority of the unblocked task was greater than or equal\n\t  to the priority of the Running task.  Now a context switch is only\n\t  performed if the priority of the unblocked task is greater than the\n\t  priority of the Running task.\n\t+ New low power tickless demonstration project that targets the ST STM32L\n\t  microcontroller - see\n\t  https://www.FreeRTOS.org/STM32L-discovery-low-power-tickless-RTOS-demo.html\n\t+ Add xPortGetMinimumEverFreeHeapSize() to heap_4.c.\n\t+ Small change to the tickless low power implementation on the SAM4L to\n\t  ensure the alarm value (compare match value) cannot be set to zero when a\n\t  tickless period is exited due to an interrupt originating from a source\n\t  other than the RTOS tick.\n\t+ Update the GCC/Eclipse Win32 simulator demo to make better use of Eclipse\n\t  resource filters and match the functionality of the MSVC equivalent.\n\t+ xTaskIsTaskSuspended() is no longer a public function.  Use\n\t  eTaskGetState() in its place.\n\t+ Improved trace macros, including tracing of heap usage.\n\t+ Remove one level of indirection when accepting interrupts on the PIC32MZ.\n\t+ Add Cortex-A9 GCC port layer.\n\t+ Add Xilinx Zynq demo application.\n\n\nChanges between V7.5.3 and V7.6.0 released 18th November 2013\n\n\tV7.6.0 changes some behaviour when the co-operative scheduler is used (when\n\tconfigUSE_PREEMPTION is set to 0).  It is important to note that the\n\tbehaviour of the pre-emptive scheduler is unchanged - the following\n\tdescription only applies when configUSE_PREEMPTION is set to 0:\n\n\tWHEN configUSE_PREEMPTION IS SET TO 0 (which is in a small minority of\n\tcases) a context switch will now only occur when a task places itself into\n\tthe Blocked state, or explicitly calls taskYIELD().  This differs from\n\tprevious versions, where a context switch would also occur when implicitly\n\tmoving a higher priority task out of the Blocked state.  For example,\n\tpreviously, WHEN PREEMPTION WAS TURNED OFF, if task A unblocks task B by\n\twriting to a queue, then the scheduler would switch to the higher priority\n\ttask.  Now, WHEN PREEMPTION IS TURNED OFF, if task A unblocks task B by\n\twriting to a queue, task B will not start running until task A enters the\n\tBlocked state or task A calls taskYIELD().  [If configUSE_PREEMPTION is not\n\tset to 0, so the normal pre-emptive scheduler is being used, then task B\n\twill start running immediately that it is moved out of the Blocked state].\n\n\tOther changes:\n\n\t+ Added a port layer and a demo project for the new PIC32MZ architecture.\n\t+ Update the PIC32MX port layer to re-introduce some ehb instructions that\n\t  were previously removed, add the ability to catch interrupt stack\n\t  overflows (previously only task stack overflows were trapped), and also\n\t  add the ability to catch an application task incorrectly attempting to\n\t  return from its implementing function.\n\t+ Make dramatic improvements to the performance of the Win32 simulator port\n\t  layer.\n\t+ Ensure tasks that are blocked indefinitely report their state as Blocked\n\t  instead of Suspended.\n\t+ Slight improvement to the Cortex-M4F port layers where previously one\n\t  register was inadvertently being saved twice.\n\t+ Introduce the xSemaphoreCreateBinary() API function to ensure consistency\n\t  in the semantics of how each semaphore type is created.  It is no longer\n\t  recommended to use vSemaphoreCreateBinary() (the version prefixed with a\n\t  'v'), although it will remain in the code for backward compatibility.\n\t+ Update the Cortex-M0 port layers to allow the scheduler to be started\n\t  without using the SVC handler.\n\t+ Added a build configuration to the PIC32MX MPLAB X demo project that\n\t  targets the PIC32 USB II starter kit.  Previously all the build\n\t  configurations required the Explorer 16 hardware.\n\t+ Some of the standard demo tasks have been updated to ensure they execute\n\t  correctly with the updated co-operative scheduling behaviour.\n\t+ Added comprehensive demo for the Atmel SAM4E, including use of\n\t  FreeRTOS+UDP, FreeRTOS+FAT SL and FreeRTOS+CLI.\n\n\tFreeRTOS+ Changes:\n\n\t+ Minor maintenance on FreeRTOS+UDP.\n\nChanges between V7.5.2 and V7.5.3 released October 14 2013\n\n\tKernel changes:\n\n\t+ Prior to V7.5.x yields requested from the tick hook would occur in the\n\t  same tick interrupt - revert to that original behaviour.\n\t+ New API function uxQueueSpacesAvailable().\n\t+ Introduced the prvTaskExitError() function to Cortex-M0, Cortex-M3/4\n\t  and Cortex-M4F ports.  prvTaskExitError() is used to trap tasks that\n\t  attempt to return from their implementing functions (tasks should call\n\t  vTaskDelete( NULL ); if they want to exit).\n\t+ The Cortex-M0 version of portSET_INTERRUPT_MASK_FROM_ISR and\n\t  portCLEAR_INTERRUPT_MASK_FROM_ISR are now fully nestable.\n\t+ Improved behaviour and robustness of the default Cortex-M tickless idle\n\t  behaviour.\n\t+ Add workaround for silicon errata PMU_CM001 in Infineon XMC4000 devices to\n\t  all Cortex-M4F ports.\n\t+ Add Cortex-M0 port for Keil.\n\t+ Updated Cortus port.\n\t+ Ensure _impure_ptr is initialised before the scheduler is started.\n\t  Previously it was not set until the first context switch.\n\n\tFreeRTOS+ changes:\n\n\t+ Update FreeRTOS+UDP to V1.0.1 - including direct integration of the\n\t  FreeRTOS+Nabto task, improvements to the DHCP behaviour, and a correction\n\t  to the test that prevents the network event hook being called on the first\n\t  network down event.  The FreeRTOS+UDP change history is maintained\n\t  separately.\n\t+ Correct the __NVIC_PRIO_BITS setting in the LPC18xx.h header files\n\t  provided in the NXP CMSIS library, then update the interrupts used by the\n\t  LPC18xx demos accordingly.\n\t+ Replace double quotes (\") with single quotes (') in FreeRTOS+CLI help\n\t  strings to ensure the strings can be used with the JSON descriptions used\n\t  in the FreeRTOS+Nabto demos.\n\n\tDemo and miscellaneous changes:\n\n\t+ Added demo for the Atmel SAMD20 Cortex-M0+.  The demo includes\n\t  FreeRTOS+CLI\n\t+ Added a demo for the Infineon Cortex-M0 that can be built with the IAR\n\t  Keil and GCC tools.\n\t+ Updated the Infineon XMC4000 demos for IAR, Keil, GCC and Tasking tools,\n\t  with additional build configurations to directly support the XMC4200 and\n\t  XMC4400 devices, in addition to the previously supported XMC4500.\n\t+ Updated the demo application.\n\t+ Added additional trace macros traceMALLOC and traceFREE to track heap\n\t  usage.\n\nChanges between V7.5.0 and V7.5.2 released July 24 2013\n\n\tV7.5.2 makes the new Cortex-M vPortCheckInterruptPriority() function\n\tcompatible with the STM32 standard peripheral driver library, and adds\n\tan extra critical section to the default low power tickless mode\n\timplementation.  Only users of the STM32 peripheral library or the default\n\ttickless implementation need update from version 7.5.0.\n\nChanges between V7.4.2 and V7.5.0 released July 19 2013\n\n\tV7.5.0 is a major upgrade that includes multiple scheduling and efficiency\n\timprovements, and some new API functions.\n\n\tCompatibility information for FreeRTOS users:\n\t  FreeRTOS V7.5.0 is backward compatible with FreeRTOS V7.4.0 with one\n\t  exception; the vTaskList() and vTaskGetRunTimeStats() functions are now\n\t  considered legacy, having been replaced by the single uxTaskGetSystemState()\n\t  function.  configUSE_STATS_FORMATTING_FUNCTIONS must be set to 1 in\n\t  FreeRTOSConfig.h for vTaskList() and vTaskGetRunTimeStats() to be\n\t  available.\n\n\tCompatibility information for FreeRTOS port writers:\n\t  vTaskIncrementTick() is now called xTaskIncrementTick() (because it now\n\t  returns a value).\n\n\tHeadline changes:\n\n\t+ Multiple scheduling and efficiency improvements.\n\t+ Core kernel files now pass PC-Lint V8 static checking without outputting\n\t  any warnings (information on the test conditions will follow).\n\n\tNew API functions:\n\n\t+ uxTaskGetSystemState() https://www.FreeRTOS.org/uxTaskGetSystemState.html\n\t+ xQueueOverwrite() https://www.FreeRTOS.org/xQueueOverwrite.html\n\t+ xQueueOverwriteFromISR()\n\t+ xQueuePeekFromISR()\n\n\tThe following ports and demos, which were previously available separately,\n\tare now incorporated into the main FreeRTOS zip file download:\n\n\t+ ARM Cortex-A9 IAR\n\t+ ARM Cortex-A9 ARM compiler\n\t+ Renesas RZ\n\t+ Microsemi SmartFusion2\n\n\tNew FreeRTOSConfig.h settings\n\thttps://freertos.org/a00110.html\n\n\t+ configUSE_TIME_SLICING\n\t+ configUSE_NEWLIB_REENTRANT\n\t+ configUSE_STATS_FORMATTING_FUNCTIONS\n\t+ configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS\n\n\tOther changes:\n\n\t+ (MPU port only) The configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS\n\t  options provides a mechanism that allows application writers to execute\n\t  certain functions in privileged mode even when a task is running in user\n\t  mode.\n\t+ Ports that support interrupt nesting now include a configASSERT() that\n\t  will trigger if an interrupt safe FreeRTOS function is called from an\n\t  interrupt that has a priority designated as above the maximum system/API\n\t  call interrupt priority.\n\t+ The included FreeRTOS+Trace recorder code has been updated to the latest\n\t  version, and the demo applications that use the trace recorder code have\n\t  been updated accordingly.\n\t+ The FreeRTOS Windows Simulator (MSVC version only) has been updated to\n\t  include a new basic 'blinky' build option in addition to the original\n\t  comprehensive build option.\n\t+ Improve RAM usage efficiency of heap_4.c and heap_2.c.\n\t+ Prevent heap_4.c from attempting to free memory blocks that were not\n\t  allocated by heap_4.c, or have already been freed.\n\t+ As FreeRTOS now comes with FreeRTOS+FAT SL (donated by HCC) the Chan FATfs\n\t  files have been removed from FreeRTOS/Demo/Common.\n\t+ Fix build error when R4 port is build in co-operative mode.\n\t+ Multiple port and demo application maintenance activities.\n\nChanges between V7.4.1 and V7.4.2 released May 1 2013\n\n\tNOTE: There are no changes in the FreeRTOS kernel between V7.4.1 and V7.4.2\n\n\t+ Added FreeRTOS+FAT SL source code and demo project.  The demo project\n\t  runs in the FreeRTOS Windows simulator for easy and hardware independent\n\t  experimentation and evaluation.  See https://www.FreeRTOS.org/fat_sl\n\nChanges between V7.4.0 and V7.4.1 released April 18 2013\n\n\t+ To ensure strict conformance with the spec and ensure compatibility with\n\t  future chips data and instruction barrier instructions have been added to\n\t  the yield macros of Cortex-M and Cortex-R port layers.  For efficiency\n\t  the Cortex-M port layer \"yield\" and \"yield\" from ISR are now implemented\n\t  separately as the barrier instructions are not required in the ISR case.\n\t+ Added FreeRTOS+UDP into main download.\n\t+ Reorganised the FreeRTOS+ directory so it now matches the FreeRTOS\n\t  directory with Source and Demo subdirectories.\n\t+ Implemented the Berkeley sockets select() function in FreeRTOS+UDP.\n\t+ Changed (unsigned) casting in calls to standard library functions with\n\t  (size_t) casting.\n\t+ Added the Atmel SAM4L and Renesas RX100 demos that demonstrates the\n\t  tickless (tick suppression) low power FreeRTOS features.\n\t+ Add a new RL78 IAR demo that targets numerous new RL78 chips and\n\t  evaluation boards.\n\t+ Adjusted stack alignment on RX200 ports to ensure an assert was not\n\t  falsely triggered when configASSERT() is defined.\n\t+ Updated the Cortex_M4F_Infineon_XMC4500_IAR demo to build with the latest\n\t  version of EWARM.\n\t+ Corrected header comments in the het.c and het.h files (RM48/TMS570 demo).\n\n\nChanges between V7.3.0 and V7.4.0 released February 20 2013\n\n\t+ New feature:  Queue sets.  See:\n\t  https://www.FreeRTOS.org/Pend-on-multiple-rtos-objects.html\n\t+ Overhauled the default tickless idle mode implementation provided with the\n\t  ARM Cortex-M3 port layers.\n\t+ Enhanced tickless support in the core kernel code with the introduction of\n\t  the configEXPECTED_IDLE_TIME_BEFORE_SLEEP macro and the\n\t  eTaskConfirmSleepModeStatus() function.\n\t+ Added the QueueSet.c common demo/test file.  Several demo applications\n\t  have been updated to use the new demo/test tasks.\n\t+ Removed reliance on the PLIB libraries from the MPLAB PIC32 port layer and\n\t  demo applications.\n\t+ Added the FreeRTOS+Trace recorder code to the MSVC Win32 demo.\n\t+ Renamed eTaskStateGet() to eTaskGetState() for consistency, and added a\n\t  pre-processor macro for backward compatibility with the previous name.\n\t+ Updated functions implemented in the core queue.c source file to allow\n\t  queue.h to be included from the .c file directly (this prevents compiler\n\t  warnings that were generated by some compilers).\n\t+ Updated the CCS Cortex-R4 port layer to replace the CLZ assembler function\n\t  with the CLZ compiler intrinsic that is provided by the latest versions of\n\t  the CCS ARM compiler.\n\t+ Updated all heap_x.c implementations to replace the structure that was\n\t  used to ensure the start of the heap was aligned with a more portable\n\t  direct C code implementation.\n\t+ Added support for PIC24 devices that include EDS.\n\t+ Minor optimisations to the PIC32 port layer.\n\t+ Minor changes to tasks.c that allow the state viewer plug-ins to display\n\t  additional information.\n\t+ Bug fix:  Update prvProcessReceivedCommands() in timers.c to remove an\n\t  issue that could occur if the priority of the timer daemon task was set\n\t  below the priority of tasks that used timer services.\n\t+ Update the FreeRTOS+Trace recorder code to the latest version.\n\nChanges between V7.2.0 and V7.3.0 released October 31 2012\n\n\t+ Added ability to override the default scheduler task selection mechanism\n\t  with implementations that make use of architecture specific instructions.\n\t+ Added ability to suppress tick interrupts during idle time, and in so\n\t  doing, provide the ability to make use of architecture specific low power\n\t  functionality.\n\t+ Added the portSUPPRESS_TICKS_AND_SLEEP() macro and vTaskStepTick() helper\n\t  function.\n\t+ Added the configSYSTICK_CLOCK_HZ configuration constant.\n\t+ Reworked the Cortex-M3 and Cortex-M4F port layers for GCC, Keil and IAR to\n\t  directly support basic power saving functionality.\n\t+ Added hooks to allow basic power saving to be augmented in the application\n\t  by making use of chip specific functionality.\n\t+ Minor change to allow mutex type semaphores to be used from interrupts\n\t  (which would not be a normal usage model for a mutex).\n\t+ Change the behaviour of the interrupt safe interrupt mask save and restore\n\t  macros in the Cortex-M ports.  The save macro now returns the previous\n\t  mask value.  The restore macro now uses the previous mask value.  These\n\t  changes are not necessary for the kernel's own implementation, and are\n\t  made purely because the macros were being used by application writers.\n\t+ Added eTaskStateGet() API function.\n\t+ Added port specific optimisations to the PIC32 port layer, and updated the\n\t  PIC32 demo applications to make use of this new feature.\n\t+ Added port specific optimisations to the Win32 simulator port.\n\t+ Added new ports and demo applications for the TI Hercules RM48 and TMS570\n\t  safety microcontrollers.\n\t+ Added SAM3 demos targeting the ATSAM3S-EK2 and ATSAM3X-EK evaluation\n\t  boards.\n\t+ Updated the PIC32 MPLAB X project to manually set the compiler include\n\t  paths instead of using the IDE entry box following reports that the\n\t  include paths were somehow being deleted.\n\t+ Improved character handling in FreeRTOS+CLI.\n\nChanges between V7.1.1 and V7.2.0 released 14 August 2012\n\n\tFreeRTOS V7.2.0 is backward compatible with FreeRTOS V7.1.2.\n\n\t+ Added a FreeRTOS+ sub-directory.  The directory contains some FreeRTOS+\n\t  source code, and example projects that use the FreeRTOS Win32 simulator.\n\t+ Added a new example heap allocation implementation (heap_4.c) that\n\t  includes memory block coalescence.\n\t+ Added a demo that targets the Atmel SAM4S Cortex-M4 based microcontroller.\n\t  The demo is preconfigured to build using the free Atmel Studio 6 IDE and\n\t  GCC compiler.\n\t+ Added xSemaphoreTakeFromISR() implementation.\n\t+ The last parameter in ISR safe FreeRTOS queue and semaphore functions\n\t  (xHigherPriorityTaskWoken) is now optional and can be set to NULL if it\n\t  is not required.\n\t+ Update the IAR and MSP430X ports to clear all lower power mode bits before\n\t  exiting the tick interrupt [bug fix].\n\t+ Allow xQueueReset() to be used, even when the queues event lists are not\n\t  empty.\n\t+ Added a vQueueDelete() handler for the FreeRTOS MPU port (this was\n\t  previously missing).\n\t+ Updated the vPortSVCHandler() functions in the FreeRTOS MPU port layer to\n\t  ensure it compiles with the latest ARM GCC compilers from Linaro.\n\t+ Updated the prvReadGP() function in the NIOS II port to ensure the compiler\n\t  can choose any register for the functions parameter (required at high\n\t  compiler optimisation levels).\n\t+ Add #error macros into the Keil and IAR Cortex-M ports to ensure they\n\t  cannot be built if the user has set configMAX_SYSCALL_INTERRUPT_PRIORITY\n\t  to 0.\n\t+ Added comments in the FreeRTOSConfig.h files associated with Cortex-M3 and\n\t  Cortex-M4 demos stating that the configMAX_SYSCALL_INTERRUPT_PRIORITY\n\t  parameter must not be set to 0.\n\t+ Introduce new INCLUDE_xQueueGetMutexHolder configuration constant\n\t  (defaulted to 0).\n\t+ Added two new list handling macros - for internal use only in upcoming new\n\t  products.\n\t+ Removed all mention of the legacy vTaskStartTrace and ulTaskEndTrace\n\t  macros.  FreeRTOS+Trace supersedes the legacy trace.\n\t+ Added a configASSERT() into the vPortFree() function in heap_1.c as it is\n\t  invalid for the function to be called.\n\t+ Made the xRxLock and xTxLock members of the queue structure volatile.\n\t  This is probably not necessary, and is included as a precautionary\n\t  measure.\n\t+ Modify the assert() that checks to see if the priority passed into an\n\t  xTaskCreate() function is within valid bounds to permit the assert to be\n\t  used in the FreeRTOS MPU port.\n\t+ The software timer service (daemon) task is now created in a way that\n\t  to ensure compatibility with FreeRTOS MPU.\n\nChanges between V7.1.0 and V7.1.1 released May 1 2012\n\n\tNew ports:\n\n\tThe following ports are brand new:\n\t+ Cortex-M3 Tasking\n\n\tThe following ports have been available as separate downloads for a number\n\tof months, but are now included in the main FreeRTOS download.\n\t+ Cortex-M0 IAR\n\t+ Cortex-M0 GCC\n\t+ Cortex-M4F GCC (with full floating point support)\n\n\n\tNew demos:\n\n\tThe following demos are brand new:\n\t+ Renesas RX63N RDK (Renesas compiler)\n\n\tThe following demos have been available as separate downloads for a number\n\tof months, but are now included in the main FreeRTOS download.\n\t+ NXP LPC1114 GCC/LPCXpresso\n\t+ ST STM32F0518 IAR\n\t+ Infineon XMC4500 GCC/Atollic\n\t+ Infineon XMC4500 IAR\n\t+ Infineon XMC4500 Keil\n\t+ Infineon XMC4500 Tasking\n\n\n\tKernel miscellaneous / maintenance:\n\n\t+ Introduced the portSETUP_TCB() macro to remove the requirement for the\n\t  Windows simulator to use the traceTASK_CREATE() macro, leaving the trace\n\t  macro available for use by FreeRTOS+Trace (https://www.FreeRTOS.org/trace).\n\t+ Added a new trace macro, traceMOVE_TASK_TO_READY_STATE(), to allow future\n\t  FreeRTOS+Trace versions to provide even more information to users.\n\t+ Updated the FreeRTOS MPU port to be correct for changes that were\n\t  introduced in FreeRTOS V7.1.0.\n\t+ Introduced the xQueueReset() API function.\n\t+ Introduced the xSemaphoreGetMutexHolder() API function.\n\t+ Tidy up various port implementations to add the static key word where\n\t  appropriate, and remove obsolete code.\n\t+ Slight change to the initial stack frame given to the RX600 ports to allow\n\t  them to be used in the Eclipse based E2Studio IDE without confusing GDB.\n\t+ Correct the alignment given to the initial stack of Cortex-M4F tasks.\n\t+ Added a NOP following each DINT instruction on MSP430 devices for strict\n\t  conformance with the instructions on using DINT.\n\t+ Changed the implementation of thread deletes in the Win32 port to prevent\n\t  the port making use of the traceTASK_DELETE() trace macros - leaving this\n\t  macro free for use by FreeRTOS+Trace.\n\t+ Made some benign changes to the RX600 Renesas compiler port layer to\n\t  ensure the code can be built to a library without essential code being\n\t  removed by the linker.\n\t+ Reverted the change in the name of the uxTaskNumber variable made in\n\t  V7.1.0 as it broke the IAR plug-in.\n\n\n\tDemo miscellaneous / maintenance:\n\n\t+ The command interpreter has now been formally released as FreeRTOS+CLI,\n\t  and been moved out of the main FreeRTOS download, to instead be available\n\t  from the FreeRTOS+ Ecosystem site https://www.FreeRTOS.org/plus.\n\t+ flash_timer.c/h has been added to the list of standard demo tasks.  This\n\t  performs the same functionality as the flash.c tasks, but using software\n\t  timers in place of tasks.\n\t+ Upgraded the PIC32 demo as follows:  Changes to how the library functions\n\t  are called necessitated by the new compiler version, addition of MPLAB X\n\t  project with PIC32MX360, PIC32MX460 and PIC32MX795 configurations,\n\t  addition of simply blinky demo, updated FreeRTOSConfig.h to include more\n\t  parameters, addition of hook function stubs.\n\t+ The MSP430X IAR and CCS demos have been updated to ensure the power\n\t  settings are correct for the configured CPU frequency.\n\t+ Rowley CrossWorks projects have been updated to correct the \"multiple\n\t  definition of ...\" warnings introduced when the toolchain was updated.\n\t+ Updated various FreeRTOSConfig.h header files associated with projects\n\t  that build with Eclipse to include a #error statement informing the user\n\t  that the CreateProjectDirectoryStructure.bat batch file needs to be\n\t  executed before the projects can be opened.\n\t+ Renamed directories that included \"CCS4\" in their name to remove the '4'\n\t  and instead just be \"CCS\".  This is because the demo was updated and\n\t  tested to also work with later Code Composer Studio versions.\n\t+ Updated the TCP/IP periodic timer frequency in numerous uIP demos to be\n\t  50ms instead of 500ms.\n\nChanges between V7.0.2 and V7.1.0 released December 13 2011\n\n\tNew ports:\n\n\t+ Cortex-M4F IAR port.\n\t+ Cortex-M4F Keil/RVDS port.\n\t+ TriCore GCC port.\n\n\tNew demos:\n\n\t+ NXP LPC4350 using the Keil MDK, and demonstrated on a Hitex development\n\t  board.\n\t+ ST STM32F407 using the IAR Embedded Workbench for ARM, and demonstrated on\n\t  the IAR STM32F407ZG-SK starter kit.\n\t+ Infineon TriCore TC1782, using the GCC compiler, demonstrated on the\n\t  TriBoard TC1782 evaluation board.\n\t+ Renesas RX630, using the Renesas compiler and HEW, demonstrated on an\n\t  RX630 RSK (Renesas Starter Kit).\n\n\tMiscellaneous / maintenance:\n\n\t+ Removed all calls to printf() from the K60/IAR Kinetis demo so the project\n\t  can execute stand alone - without being connected to the debugger.\n\t+ Completed the command interpreter framework.  Command handlers now receive\n\t  the entire command string, giving them direct access to parameters.\n\t  Utility functions are provided to check the number of parameters, and\n\t  return parameter sub-strings.\n\t+ The previously documented fix for the bug in xTaskResumeFromISR() that\n\t  effected (only) ports supporting interrupt nesting has now been\n\t  incorporated into the main release.\n\t+ The portALIGNMENT_ASSERT_pxCurrentTCB() definition has been added to allow\n\t  specific ports to skip the second stack alignment check when a task is\n\t  created.  This is because the second check is not appropriate for some\n\t  ports - including the new TriCore port where the checked pointer does not\n\t  actually point to a stack.\n\t+ The portCLEAN_UP_TCB() macro has been added to allow port specific clean\n\t  up when a task is deleted - again this is required by the TriCore port.\n\t+ Various other minor changes to ensure warning free builds on a growing\n\t  number of microcontroller and toolchain platforms.  This includes a\n\t  (benign) correction to the prototype of the\n\t  vApplicationStackOverflowHook() definition found in lots of recent demos.\n\n\tTrace system:\n\n\t+ The legacy trace mechanism has been completely removed - it has been\n\t  obsolete for the years since the trace macros were introduced.  The\n\t  configuration constant configUSE_TRACE_FACILITY is now used to optionally\n\t  include additional queue and task information.  The additional information\n\t  is intended to make the trace mechanism more generic, and allow the trace\n\t  output to provide more information.  When configUSE_TRACE_FACILITY is set\n\t  to 1:\n\t\t- the queue structure includes an additional member to hold the queue\n\t\t  type, which can be base, mutex, counting semaphore, binary semaphore\n\t\t  or recursive mutex.\n\t\t- the queue structure includes an additional member to hold a queue\n\t\t  number.  A trace tool can set and query the queue number for its own\n\t\t  purposes.  The kernel does not use the queue number itself.\n\t\t- the TCB structure includes an additional member to hold a task number\n\t\t  number.  A trace tool can set and query the task number for its own\n\t\t  purposes.  The kernel does not use the task number itself.\n\t+ Queues and all types of semaphores are now automatically allocated their\n\t  type as they are created.\n\t+ Added two new trace macros - traceTASK_PRIORITY_INHERIT() and\n\t  traskTASK_PRIORITY_DISINHERIT().\n\t+ Updated the traceQUEUE_CREATE_FAILED() macro to take a parameter that\n\t  indicates the type of queue, mutex, or semaphore that failed to be\n\t  created.\n\t+ The position from which traceCREATE_MUTEX() is called has been moved from\n\t  after the call to xQueueGenericSend() [within the same function] to before\n\t  the call.  This ensures the trace events occur in the correct order.\n\t+ The value passed into tracePRIORITY_SET() has been corrected for the case\n\t  where vTaskPrioritySet() is called with a null parameter.\n\nChanges between V7.0.1 and V7.0.2 released September 20 2011\n\n\tNew ports:\n\n\t+ The official FreeRTOS Renesas RX200 port and demo application have been\n\t  incorporated into the main FreeRTOS zip file download.\n\t+ The official FreeRTOS Renesas RL78 port and demo application have been\n\t  incorporated into the main FreeRTOS zip file download.\n\t+ The official FreeRTOS Freescale Kinetis K60 tower demo application has\n\t  been incorporated into the main FreeRTOS zip file download.  This includes\n\t  an embedded web server example.\n\t+ A new Microblaze V8 port layer has been created to replace the older, now\n\t  deprecated, port layer.  The V8 port supports V8.x of the Microblaze IP,\n\t  including exceptions, caches, and the floating point unit.  A new\n\t  Microblaze demo has also been added to demonstrate the new Microblaze V8\n\t  port layer.  The demo application was created using V13.1 of the Xilinx\n\t  EDK, and includes a basic embedded web server that uses lwIP V1.4.0.\n\t+ The official FreeRTOS Fujitsu FM3 MB9A310 demo application has been\n\t  incorporated into the main FreeRTOS zip file download.  Projects are\n\t  provided for both the IAR and Keil toolchains.\n\n\n\tAPI additions:\n\n\t+ xTaskGetIdleTaskHandle() has been added.\n\t+ xTaskGetTimerDaemonTaskHandle() has been added.\n\t+ pcTaskGetTaskName() has been added.\n\t+ vSemaphoreDelete() macro has been added to make it obvious how to delete\n\t  a semaphore.  In previous versions vQueueDelete() had to be used.\n\t+ vTaskCleanUpResources() has been removed.  It has been obsolete for a\n\t  while.\n\t+ portPOINTER_SIZE_TYPE has been introduced to prevent compiler warnings\n\t  being generated when the size of a pointer does not match the size of\n\t  the stack type.  This will (has already) be used in new ports, but will\n\t  not be retrofitted to existing ports until the existing port itself is\n\t  updated.\n\n\tOther updates and news:\n\n\t+ The core files have all been modified to tighten the coding standard even\n\t  further.  These are style, not functional changes.\n\t+ All ARM7 port layers have been slightly modified to prevent erroneous\n\t  assert() failures when tasks are created and configASSERT() is defined.\n\t+ All ARM IAR projects have been updated to build with the latest V6.2.x\n\t  versions of the IAR Embedded Workbench for ARM tools (EWARM).  This was\n\t  necessary due to a change in the way EWARM uses the CMSIS libraries.\n\t+ The PIC32 port layer has been updated in preparation for V2 of the C32\n\t  compiler.\n\t+ The old Virtex-4 Microblaze demo has been marked as deprecated.  Please\n\t  use the brand new Spartan-6 port and demo in its place.\n\t+ The bones of a new generic command interpreter is located in\n\t  FreeRTOS/Demo/Common/Utils/CommandInterpreter.c.  This is still a work in\n\t  progress, and not documented.  It is however already in use.  It will be\n\t  documented in full when the projects that are already using it are\n\t  completed.\n\t+ A couple of new standard demos have been included.  First, a version of\n\t  flop.c called sp_flop.c.  This is similar to flop.c, but uses single\n\t  precision floats in place of double precision doubles.  This allows the\n\t  for testing ports to processors that have only single precision floating\n\t  point units, and revert to using emulated calculations whenever a double\n\t  is used.  Second, comtest_strings.c has been included to allow the test\n\t  of UART drivers when an entire string is transmitted at once.  The\n\t  previous comtest.c only used single character transmission and reception.\n\t+ lwIP V1.4.0 is now included in the FreeRTOS/Demo/Common directory, and\n\t  used by a couple of new demos.\n\nChanges between V7.0.0 and V7.0.1 released May 13 2011\n\n\t+ Added a Fujitsu FM3 demo application for both the IAR and Keil tool\n\t  chains.\n\t+ Added a SmartFusion demo application for all of the IAR, Keil and\n\t  SoftConsole (GCC/Eclipse) tool chains.\n\t+ Updated the RX600 port and demo applications to take into account the\n\t  different semantics required when using the latest (V1.0.2.0) version of\n\t  the Renesas compiler.\n\t+ Modified the RX600 Ethernet driver slightly to make it more robust under\n\t  heavy load, and updated the uIP handling task to make use of the FreeRTOS\n\t  software timers.\n\t+ Slightly changed the PIC32 port layer to move an ehb instruction in line\n\t  with the recommendations of the MIPS core manual, and ensure 8 byte stack\n\t  alignment is truly always obtained.\n\t+ Changed the behaviour when tasks are suspended before the scheduler has\n\t  been started.  Before, there needed to be at least one task that was not\n\t  in the suspended state.  This is no longer the case.\n\nChanges between V6.1.1 and V7.0.0 released April 8 2011\n\n\tFreeRTOS V7.0.0 is backward compatible with FreeRTOS V6.x.x\n\n\tMain changes:\n\n\t+ Introduced a new software timer implementation.\n\t+ Introduced a new common demo application file to exercise the new timer\n\t  implementation.\n\t+ Updated the Win32/MSVC simulator project to include the new software timer\n\t  demo tasks and software timer tick hook test.  Much simpler software timer\n\t  demonstrations are included in the demo projects for both of the new ports\n\t  (MSP430X with CCS4 and STM32 with TrueStudio).\n\t+ Various enhancements to the kernel implementation in tasks.c.  These are\n\t  transparent to users and do not effect the pre-existing API.\n\t+ Added calls to configASSERT() within the kernel code.  configASSERT() is\n\t  functionally equivalent to the standard C assert() macro, but does not\n\t  rely on the compiler providing assert.h.\n\n\tOther changes:\n\n\t+ Updated the MSP430X IAR port and demo project to include support for the\n\t  medium memory model.\n\t+ Added a demo project for the MSP430X that targets the MSP430X Discovery\n\t  board and uses the Code Composer Studio 4 tools.  This demo includes use\n\t  of the new software timer implementation.\n\t+ Added an STM32F100RB demo project that targets the STM32 Discovery Board\n\t  and uses the TrueStudio Eclipse based IDE from Atollic.\n\t+ Removed some compiler warnings from the PSoC demo application.\n\t+ Updated the PIC32 port layer to ensure the\n\t  configMAX_SYSCALL_INTERRUPT_PRIORITY constant works as expected no matter\n\t  what its value is (within the valid range set by the microcontroller\n\t  kernel).\n\t+ Updated the PIC24, dsPIC and PIC32 projects so they work with the latest\n\t  MPLAB compiler versions from Microchip.\n\t+ Various cosmetic changes to prepare for a standards compliance statement\n\t  that will be published after the software release.\n\n\nChanges between V6.1.0 and V6.1.1 released January 14 2011\n\n\t+ Added two new Windows simulator ports.  One uses the free Microsoft Visual\n\t  Studio 2010 express edition, and the other the free MingW/Eclipse\n\t  environment.  Demo projects are provided for both.\n\t+ Added three demo projects for the PSoC 5 (CYAC5588).  These are for the\n\t  GCC, Keil, and RVDS build tools, and all use the PSoC Creator IDE.\n\t+ Added a demo for the low power STM32L152 microcontroller using the IAR\n\t  Embedded Workbench.\n\t+ Added a new port for the MSP430X core using the IAR Embedded Workbench.\n\t+ Updated all the RX62N demo projects that target the Renesas Demonstration\n\t  Kit (RDK) to take into account the reversed LED wiring on later hardware\n\t  revisions, and the new J-Link debug interface DLL.\n\t+ Updated all the RX62N demo projects so the IO page served by the example\n\t  embedded web server works with all web browsers.\n\t+ Updated the Red Suite projects to work with the up coming Red Suite\n\t  release, and to use a more recent version of the CMSIS libraries.\n\t+ Added the traceTAKE_MUTEX_RECURSIVE_FAILED() trace macro.\n\t+ Removed the (pointless) parameter from the traceTASK_CREATE_FAILED()\n\t  trace macro.\n\t+ Introduced the portALT_GET_RUN_TIME_COUNTER_VALUE() macro to compliment\n\t  the already existing portGET_RUN_TIME_COUNTER_VALUE().  This allows for\n\t  more flexibility in how the time base for the run time statistics feature\n\t  can be implemented.\n\t+ Added a \"cpsie i\" instruction before the \"svc 0\" instruction used to start\n\t  the scheduler in each of the Cortex M3 ports.  This is to ensure that\n\t  interrupts are globally enabled prior to the \"svc 0\" instruction being\n\t  executed in cases where interrupts are left disabled by the C start up\n\t  code.\n\t+ Slight optimisation in the run time stats calculation.\n\nChanges between V6.0.5 and V6.1.0 released October 6 2010\n\n\t+ Added xTaskGetTickCountFromISR() function.\n\t+ Modified vTaskSuspend() to allow tasks that have just been created to be\n\t  immediately suspended even when the kernel has not been started.  This\n\t  allows them to effectively start in the Suspended state - a feature that\n\t  has been asked for on numerous occasions to assist with initialisation\n\t  procedures.\n\t+ Added ports for the Renesas RX62N using IAR, GCC and Renesas tool suites.\n\t+ Added a STM32F103 demo application that uses the Rowley tools.\n\t+ Under specific conditions xFreeBytesRemaining within heap_2.c could end up\n\t  with an incorrect\tvalue.  This has been fixed.\n\t+ xTaskCreateGeneric() has a parameter that can be used to pass the handle\n\t  of the task just created out to the calling task.  The assignment to this\n\t  parameter has been moved to ensure it is assigned prior to the newly\n\t  created having any possibility of executing.  This takes into account the\n\t  case where the assignment is made to a global variable that is accessed by\n\t  the newly created task.\n\t+ Fixed some build time compiler warnings in various FreeTCPIP (based on\n\t  uIP) files.\n\t+ Fixed some build time compiler warnings in Demo/Common/Minimal/IntQueue.c.\n\nChanges between V6.0.4 and V6.0.5 released May 17 2010\n\n\t+ Added port and demo application for the Cortus APS3 processor.\n\nChanges between V6.0.3 and V6.0.4 released March 14 2010\n\n\t+ All the contributed files that were located in the Demo/Unsupported_Demos\n\t  directory have been removed.  These files are instead now available in the\n\t  new  Community Contributions section of the FreeRTOS website.  See\n\t  https://www.FreeRTOS.org/RTOS-contributed-ports.html\n\t+ The project file located in the Demo/CORTEX_STM32F107_GCC_Rowley directory\n\t  has been upgraded to use V2.x of the Rowley Crossworks STM32 support\n\t  package.\n\t+ An initial Energy Micro EFM32 demo has been included.  This will be\n\t  updated over the coming months to make better use of the low power modes\n\t  the EFM32 provides.\n\nChanges between V6.0.2 and V6.0.3 released February 26 2010\n\n\t+ SuperH SH7216 (SH2A-FPU) port and demo application added.\n\t+ Slight modification made to the default implementation of\n\t  pvPortMallocAligned() and vPortFreeAligned() macros so by default they\n\t  just call pvPortMalloc() and vPortFree().  The macros are only needed to\n\t  be defined when a memory protection unit (MPU) is being used - and then\n\t  only depending on other configuration settings.\n\nChanges between V6.0.1 and V6.0.2 released January 9th 2010\n\n\t+ Changed all GCC ARM 7 ports to use 0 as the SWI instruction parameter.\n\t  Previously the parameter was blank and therefore only an implicit 0 but\n\t  newer GCC releases do not permit this.\n\t+ Updated IAR SAM7S and SAM7X ports to work with IAR V5.40.\n\t+ Changed the stack alignment requirement for PIC32 from 4 bytes to 8 bytes.\n\t+ Updated prvListTaskWithinSingleList() is it works on processors where the\n\t  stack grows up from low memory.\n\t+ Corrected some comments.\n\t+ Updated the startup file for the RVDS LPC21xx demo.\n\nChanges between V6.0.0 and V6.0.1 released November 15th 2009\n\n\t+ Altered pxPortInitialiseStack() for all Cortex-M3 ports to ensure the\n\t  stack pointer is where the compiler expects it to be when a task first\n\t  starts executing.\n\n\t  The following minor changes only effect the Cortex-M3 MPU port:\n\n\t+ portRESET_PRIVILEGE() assembly macro updated to include a clobber list.\n\t+ Added prototypes for all the privileged function wrappers to ensure no\n\t  compile time warnings are generated no matter what the warning level\n\t  setting.\n\t+ Corrected the name of portSVC_prvRaisePrivilege to\n\t  portSVC_RAISE_PRIVILEGE.\n\t+ Added conditional compilation into xTaskGenericCreate() to prevent some\n\t  compilers issuing warnings when portPRIVILEGE_BIT is defined as zero.\n\n\nChanges between V5.4.2 and V6.0.0 released October 16th 2009\n\n\tFreeRTOS V6 is backward compatible with FreeRTOS V5.x.\n\n\tMain changes:\n\n\t+ FreeRTOS V6 is the first version to include memory protection unit (MPU)\n\t  support.  Two ports now exist for the Cortex M3, the standard FreeRTOS\n\t  which does not include MPU support, and FreeRTOS-MPU which does.\n\t+ xTaskCreateRestricted() and vTaskAllocateMPURegions() API functions added\n\t  in support of FreeRTOS-MPU.\n\t+ Wording for the GPL exception has been (hopefully) clarified.  Also the\n\t  license.txt file included in the download has been fixed (the previous\n\t  version contained some corruption).\n\n\tOther changes:\n\n\t+ New API function xPortGetFreeHeapSize() added to heap_1.c and heap_2.c.\n\t+ ARM7 GCC demo interrupt service routines wrappers have been modified to\n\t  call the C portion using an __asm statement.  This prevents the function\n\t  call being inlined at higher optimisation levels.\n\t+ ARM7 ports now automatically set the THUMB bit if necessary when\n\t  setting up the initial stack of a task - removing the need for\n\t  THUMB_INTERWORK to be defined.  This also allows THUMB mode and ARM mode\n\t  tasks to be mixed more easily.\n\t+ All ARM7/9 ports now have portBYTE_ALIGNMENT set to 8 by default.\n\t+ Various demo application project files have been updated to be up to date\n\t  with the latest IDE versions.\n\t+ The linker scripts used with command line GCC demos have been updated to\n\t  include an eh_frame section to allow their use with the latest Yagarto\n\t  release.  Likewise the demo makefiles have been updated to include\n\t  command line options to reduce or eliminate the eh_frame section all\n\t  together.\n\t+ The definition of portBYTE_ALIGNMENT_MASK has been moved out of the\n\t  various memory allocation files and into the common portable.h header\n\t  file.\n\t+ Removed unnecessary use of portLONG, portSHORT and portCHAR.\n\t+ Added LM3Sxxxx demo for Rowley CrossWorks.\n\t+ Posix simulator has been upgraded - see the corresponding WEB page on the\n\t  FreeRTOS.org site.\n\n\nChanges between V5.4.1 and V5.4.2 released August 9th 2009\n\n\t+ Added a new port and demo app for the Altera Nios2 soft core.\n\t+ Added LPC1768 demo for IAR.\n\t+ Added a USB CDC demo to all LPC1768 demos (Code Red, CrossWorks and IAR).\n\t+ Changed clock frequency of LPC1768 demos to 99MHz.\n\nChanges between V5.4.0 and V5.4.1 released July 25th 2009\n\n\t+ New hook function added.  vApplicationMallocFailedHook() is (optionally)\n\t  called if pvPortMalloc() returns NULL.\n\t+ Additional casting added to xTaskCheckForTimeOut().  This prevents\n\t  problems that can arise should configUSE_16_BIT_TICKS be set to 1 on a\n\t  32 bit architecture (which would probably be a mistake, anyway).\n\t+ Corrected the parameter passed to NVIC_SetPriority() to set the MAC\n\t  interrupt priority in both LPC1768 demos.\n\t+ Decreased the default setting of configMINIMAL_STACK_SIZE in the PIC32\n\t  demo application to ensure the heap space was not completely consumed\n\t  before the scheduler was started.\n\nChanges between V5.3.1 and V5.4.0 released July 13th 2009\n\n\t+ Added Virtex5 / PPC440 port and demos.\n\t+ Replaced the LPC1766 Red Suite demo with an LPC1768 Red Suite demo.  The\n\t  original demo was configured to use engineering samples of the CPU.  The\n\t  new demo has an improved Ethernet driver.\n\t+ Added LPC1768 Rowley demo with zero copy Ethernet driver.\n\t+ Reworked byte alignment code to ensure 8 byte alignment works correctly.\n\t+ Set configUSE_16_BIT_TICKS to 0 in the PPC405 demo projects.\n\t+ Changed the initial stack setup for the PPC405 to ensure the small data\n\t  area pointers are setup correctly.\n\nChanges between V5.3.0 and V5.3.1 released June 21st 2009\n\n\t+ Added ColdFire V1 MCF51CN128 port and WEB server demo.\n\t+ Added STM32 Connectivity Line STM32107 Cortex M3 WEB server demo.\n\t+ Changed the Cortex M3 port.c asm statements to __asm so it can be\n\t  compiled using Rowley CrossWorks V2 in its default configuration.\n\t+ Updated the Posix/Linux simulator contributed port.\n\nChanges between V5.2.0 and V5.3.0 released June 1st 2009\n\n\tMain changes:\n\n\t+ Added new (optional) feature that gathers statistics on the amount of CPU\n\t  time used by each task.\n\t+ Added a new demo application for the Atmel AT91SAM3U Cortex-M3 based\n\t  microcontroller.\n\t+ Added a new demo application for the NXP LPC1766 Cortex-M3 based\n\t  microcontroller.\n\t+ Added a contributed port/demo that allows FreeRTOS to be 'simulated' in a\n\t  Linux environment.\n\n\tMinor changes:\n\t+ Updated the Stellaris uIP WEB server demos to include the new run time\n\t  statistics gathering feature - and include a served WEB page that\n\t  presents the information in a tabular format.\n\t+ Added in the lwIP port layer for the Coldfire MCF52259.\n\t+ Updated the CrossWorks LPC2368 WEB server to include an image in the\n\t  served content.\n\t+ Changed some of the timing in the initialisation of the LPC2368 MAC to\n\t  permit its use on all part revisions.\n\t+ Minor modifications to the core uIP code to remove some compiler warnings.\n\t+ Added xTaskGetApplicationTaskTag() function and updated the OpenWatcom\n\t  demo to make use of the new function.\n\t+ Added contributed demos for AVR32 AP7000, STM32 Primer 2 and STM32 using\n\t  Rowley Crossworks.\n\t+ Heap_1.c and Heap_2.c used to define structures for the purpose of data\n\t  alignment.  These have been converted to unions to save a few bytes of\n\t  RAM that would otherwise be wasted.\n\t+ Remove the call to strncpy() used to copy the task name into the TCB when\n\t  the maximum task name is configured to be 1 byte long.\n\nChanges between V5.1.2 and V5.2.0 released March 14th 2009\n\n\t+ Optimised the queue send and receive functions (also used by semaphores).\n\t+ Replaced the standard critical sections used to protect BIOS calls in the\n\t  PC port to instead use scheduler locks.  This is because the BIOS calls\n\t  always return with interrupts enabled.\n\t+ Corrected unclosed comments in boot.s.\n\nChanges between V5.1.1 and V5.1.2 released February 9th 2009\n\n\t+ Added NEC V850ES port and demo.\n\t+ Added NEC 78K0R port and demo.\n\t+ Added MCF52259 port and demo.\n\t+ Added the AT91SAM9XE port and demo.\n\t+ Updated the MCF52233 FEC driver to work around a silicon bug that\n\t  prevents the part auto negotiating some network parameters.\n\t+ Minor modifications to the MCF52233 makefile to permit it to be used\n\t  on Linux hosts.\n\t+ Updated the STM32 primer files to allow them to be built with the latest\n\t  version of the RIDE tools.\n\t+ Updated the threads.js Java script used for kernel aware debugging in\n\t  the Rowley CrossWorks IDE.\n\n\nChanges between V5.1.0 and V5.1.1 released November 20, 2008\n\n\t+ Added Coldfire MCF52233 WEB server demo using GCC and Eclipse.\n\t+ Added IAR MSP430 port and demo.\n\t+ Corrected several compiler time issues that had crept in as tool versions\n\t  change.\n\t+ Included FreeRTOS-uIP - a faster uIP.  This is not yet complete.\n\nChanges between V5.0.4 and V5.1.0 released October 24, 2008\n\n\t+ Added a new port and demo application for the ColdFire V2 core using the\n\t  CodeWarrior development tools.\n\t+ Replaced the ARM7 demo that used the old (and now no longer supported)\n\t  Keil compiler with a new port that uses the new Keil/RVDS combo.\n\t+ Stack overflow checking now works for stacks that grow up from low\n\t  memory (PIC24 and dsPIC).\n\t+ BUG FIX - set the PIC32 definition of portSTACK_GROWTH to the correct\n\t  value of -1.\n\t+ MSP430 port layers have been updated to permit tasks to place the\n\t  microcontroller into power down modes 1 to 3.  The demo applications have\n\t  likewise been updated to demonstrate the new feature.\n\t+ Replaced the two separate MSP430/Rowley port layers with a single and more\n\t  flexible version.\n\t+ Added more contributed ports, including ports for NEC and SAM9\n\t  microcontrollers.\n\t+ Changed the linker script used in the LPC2368 Eclipse demo.\n\nChanges between V5.0.3 and V5.0.4 released September 22, 2008\n\n\t+ Completely re-written port for ColdFire GCC.\n\t+ Bug fix:  All Cortex M3 ports have a minor change to the code that sets\n\t  the pending interrupt.\n\t+ Some header files require that FreeRTOS.h be included prior to their\n\t  inclusion.  #error message have been added to all such header file\n\t  informing users to the cause of the compilation error should the headers\n\t  not be included in the correct order.\n\nChanges between V5.0.2 and V5.0.3 released July 31, 2008\n\n\tChanges relating to the Cortex M3:\n\n\t+ Added configMAX_SYSCALL_INTERRUPT_PRIORITY usage to all the Cortex M3\n\t  ports and demos.  See the port documentation pages on the FreeRTOS.org\n\t  WEB site for full usage information.\n\t+ Improved efficiency of Cortex M3 port even further.\n\t+ Ensure the Cortex M3 port works no matter where the vector table is\n\t  located.\n\t+ Added the IntQTimer demo/test tasks to a demo project for each CM3 port\n\t  (Keil, GCC and IAR) to test the new configMAX_SYSCALL_INTERRUPT_PRIORITY\n\t  functionality.\n\t+ Added the mainINCLUDE_WEB_SERVER definition to the LM3SXXXX IAR and Keil\n\t  projects to allow the WEB server to be conditionally excluded from the\n\t  build and therefore allow use of the KickStart (code size limited)\n\t  compiler version.\n\n\tOther changes:\n\n\t+ Moved the PIC24 and dsPIC versions of vPortYield() from the C file to\n\t  an assembly file to allow use with all MPLAB compiler versions.  This also\n\t  allows the omit-frame-pointer optimisation to be turned off.\n\nChanges between V5.0.0 and V5.0.2 released May 30, 2008\n\n\t+ Updated the PIC32 port to allow queue API calls to be used from\n\t  interrupts above the kernel interrupt priority, and to allow full\n\t  interrupt nesting.  Task stack usages has also been reduced.\n\t+ Added a new PowerPC port that demonstrates how the trace macros can be\n\t  used to allow the use of a floating point co-processor.  The\n\t  traceTASK_SWITCHED_OUT() and traceTASK_SWITCHED_INT() macros are used to\n\t  save and restore the floating point context respectively for those tasks\n\t  that actually use floating point operations.\n\t+ BUG FIX:  The first PPC405 port contained a bug in that it did not leave\n\t  adequate space above the stack for the backchain to be saved when a task\n\t  started to execute for the first time.\n\t+ Updated queue.c to add in the means to allow interrupt nesting and for\n\t  queue API functions to be called from interrupts that have a priority\n\t  above the kernel priority.  This is only supported on PIC32 ports thus\n\t  far.\n\t+ Fixed the compiler warnings that were generated when the latest version\n\t  of WinAVR was used.\n\t+ Remove all inline usage of 'inline' from the core kernel code.\n\t+ Added the queue registry feature.  The queue registry is provided as a\n\t  means for kernel aware debuggers to locate queue definitions.  It has no\n\t  purpose unless you are using a kernel aware debugger.  The queue registry\n\t  will only be used when configQUEUE_REGISTRY_SIZE is greater than zero.\n\t+ Added the ST Cortex-M3 drivers into the Demo/Common/Drivers directory to\n\t  prevent them from having to be included in multiple demos.\n\t+ Added a Keil STM32 demo application.\n\t+ Changed the blocktim.c test files as it is no longer legitimate for all\n\t  ports to call queue API functions from within a critical section.\n\t+ Added the IntQueue.c test file to test the calling of queue API functions\n\t  from different interrupt priority levels, and test interrupt nesting.\n\nChanges between V5.0.0 and V5.0.1\n\n\t+ V5.0.1 was a customer specific release.\n\nChanges between V4.8.0 and V5.0.0 released April 15, 2008\n\n\t*** VERY IMPORTANT INFORMATION ON UPGRADING TO FREERTOS.ORG V5.0.0 ***\n\n\tThe parameters to the functions xQueueSendFromISR(), xQueueSendToFrontFromISR(),\n\txQueueSendToBackFromISR() and xSemaphoreGiveFromISR() have changed.  You must\n\tupdate all calls to these functions to use the new calling convention!  Your\n\tcompiler might not issue any type mismatch warnings!\n\n\n\tOther changes:\n\n\t+ Support added for the new Luminary Micro LM3S3768 and LM3S3748 Cortex-M3\n\t  microcontrollers.\n\t+ New task hook feature added.\n\t+ PowerPC demo updated to use version 10.1 of the Xilinx EDK.\n\t+ Efficiency gains within the PIC32 port layer.\n\nChanges between V4.7.2 and V4.8.0 released March 26 2008\n\n\t+ Added a Virtex4 PowerPC 405 port and demo application.\n\t+ Added optional stack overflow checking and new\n\t  uxTaskGetStackHighWaterMark() function.\n\t+ Added new xQueueIsQueueEmptyFromISR(), xQueueIsQueueFullFromISR() and\n\t  uxQueueMessagesWaitingFromISR() API functions.\n\t+ Efficiency improvements to the Cortex-M3 port layer.  NOTE: This\n\t  requires that an SVC handler be installed in the application.\n\t+ Efficiency improvements to the queue send and receive functions.\n\t+ Added new trace macros.  These are application definable to provide\n\t  a flexible trace facility.\n\t+ Implemented the configKERNEL_INTERRUPT_PRIORITY within the Keil Cortex\n\t  M3 port layer (bringing it up to the same standard as the IAR and GCC\n\t  versions).\n\t+ Ports that used the arm-stellaris-eabi-gcc tools have been converted to\n\t  use the arm-non-eabi-gcc tools.\n\nChanges between V4.7.1 and V4.7.2 released February 21, 2008\n\n\t+ Added Fujitsu MB91460 port and demo.\n\t+ Added Fujitsu MB96340 port and demo.\n\t+ Tidied up the capitalisation of include files to facilitate builds on\n\t  Linux hosts.\n\t+ Removed some redundant casting that was generating warnings - but was\n\t  included to remove warnings on other compilers.\n\nChanges between V4.7.0 and V4.7.1 released February 3, 2008\n\n\t+ Updated all IAR ARM projects to use V5.11 of the IAR Embedded Workbench\n\t  for ARM.\n\t+ Introduced recursive semaphore feature.\n\t+ Updated LPC2368 demos to take into account silicon bugs in old chip\n\t  revisions.\n\t+ Updated STR9 uIP port to manually set the net mask and gateway addresses.\n\t+ Updating demos to allow more to run with the co-operative scheduler.\n\t+ Fixed co-operative scheduler behaviour upon the occurrence of a tick\n\t  interrupt while the scheduler was suspended.\n\t+ Updated documentation contained within semphr.h.\n\t+ ARM7 GCC ports no longer use the IRQ attribute.\n\nChanges between V4.6.1 and V4.7.0 released December 6, 2007\n\n\t+ Introduced the counting semaphore macros and demo source files.  The\n          Open Watcom PC project has been updated to include the new demo.  See\n          the online documentation for more information.\n\t+ Introduced the 'alternative' queue handling API and demo source files.\n\t  The Open Watcom PC project has been updated to include the new demo\n\t  source files.  See the online documentation for more information.\n\t+ Added AT91SAM7X Eclipse demo project.\n\t+ Added the STM32 primer demo project for the GCC compiler and Ride IDE.\n\t+ Removed the .lock files that were mistakenly included in the V4.6.1\n\t  eclipse workspaces.\n\nChanges between V4.6.0 and V4.6.1 released November 5 2007\n\n\t+ Added support for the MIPS M4K based PIC32.\n\t+ Added 'extern \"C\"' to all the header files to facilitate use with C++.\n\nChanges between V4.5.0 and V4.6.0 released October 28 2007\n\n\t+ Changed the method used to force a context switch within an ISR for the\n\t  ARM7/9 GCC ports only.  The portENTER_SWITCHING_ISR() and\n\t  portEXIT_SWITCHING_ISR() macros are no longer supported.  This is to\n\t  ensure correct behaviour no matter which GCC version is used, with or\n\t  without the -fomit-frame-pointer option, and at all optimisation levels.\n\t+ Corrected the prototype for xQueueGenericSend() within queue.h.\n\nChanges between V4.4.0 and V4.5.0 released September 17 2007\n\n\t+ Added the xQueueSendToFront(), xQueueSendToBack() and xQueuePeek()\n\t  functionality.  These should now be used in preference to the old\n\t  xQueueSend() function - which is maintained for backward compatibility.\n\t+ Added Mutex functionality.  The behaviour of mutexes is subtly different\n\t  to the already existing binary semaphores as mutexes automatically\n\t  include a priority inheritance mechanism.\n\t+ Added the GenQTest.c and QPeek.c to test and demonstrate the behaviour\n\t  of the new functionality.\n\t+ Updated the LM3Sxxxx and PC ports to include the new GenQTest.c and\n\t  QPeek.c files.\n\t+ Updated the GCC port for the Cortex M3 to include the\n\t  configKERNEL_INTERRUPT_PRIORITY functionality.  This was previously only\n\t  included in the IAR port.\n\t+ Optimised the GCC and IAR port layer code - specifically the context\n\t  switch code.\n\t+ Consolidated the LM3Sxxxx EK demos for all development tools into a\n\t  single project that automatically detects which version of the EK the\n\t  application is executing on.\n\t+ Added Eclipse support for LM3Sxxxx evaluation kits.\n\t+ Added Eclipse support for the Keil LPC2368 evaluation kit.\n\t+ Added the Demo/Drivers directory to hold code that is common to multiple\n\t  demo application projects.\n\t+ Included some minor bug fixes in the uIP 1.0 code.\n\t+ Added an lwIP demo for the STR9 - thanks ST for assistance.\n\t+ Updated the AVR32 port to ensure correct behaviour with full compiler\n\t  optimisation.\n\t+ Included binaries for OpenOCD FTDI and parallel port interfaces.\n\nChanges between V4.4.0 and V4.3.1 released July 31, 2007\n\n\t+ Added AVR32 UC3B demo application.\n\t+ Updated AVR32 UC3A port and demo applications.\n\t+ Added IAR lwIP demo for AVR32 UC3A.\n\t+ Updated listGET_OWNER_OF_NEXT_ENTRY() to assist compiler optimisation\n\t  (thanks Niu Yong for making the suggestion).\n\t+ Added xTaskGetSchedulerState() API function.\n\t+ BUG FIX:  Corrected behaviour when tasks that are blocked indefinitely\n\t  have their block time adjusted (within xQueueSend() and xQueueReceive()),\n\t  and are the subject of a call the vTaskResume() when they are not\n\t  actually in the Suspended state (thanks Dan Searles for reporting the\n\t  issues).\n\n\nChanges between V4.3.0 and V4.3.1 released June 11, 2007\n\n\t+ Added STMicroelectronics STM32 Cortex-M3 demo application.\n\t+ Updated ustdlib.c for the GCC LM3S6965 demo.\n\nChanges between V4.2.1 and V4.3.0 released June 5, 2007\n\n\t+ Introduced configKERNEL_INTERRUPT_PRIORITY to the IAR Cortex-M3, PIC24\n\t  and dsPIC ports.  See the LM3S6965 and PIC24 demo application\n\t  documentation pages for more information.\n\t+ Updated the PIC24 and dsPIC demos to build with V3.0 of the PIC30 GCC\n\t  tools, and changed the demo applications.\n\t+ Added demos for the new Ethernet and CAN enabled Luminary Micro Stellaris\n\t  microcontrollers.\n\t+ Corrected bug in uIP the demos that prevented frames of approximately 1480\n\t  bytes and over from being transmitted.\n\t+ Included the LPC2368/uIP/Rowley demo into the main FreeRTOS.org\n\t  download.\n\t+ Update to WizC PIC18 port to permit its use with version 14 of the\n\t  compiler.  Thanks Marcel!\n\nChanges between V4.2.1 and V4.2.0 released April 2, 2007\n\n\t+ Added AVR32 AT32UC3A ports for GCC and IAR.\n\t+ Added -fomit-frame-pointer option to lwIP SAM7X demo makefile.\n\t+ Moved location of call to LCD_Init() in STR9 demo to ensure it is only\n\t  called after the scheduler has been started.\n\nChanges between V4.1.3 and V4.2.0 released February 8, 2007\n\n\t+ Changes to both task.c and queue.c as a result of testing performed on\n\t  the SafeRTOS code base.\n\t+ Added Cortex-M3 LM3S811 demos for GCC and IAR tools.\n\nChanges between V4.1.2 and V4.1.3 released November 19, 2006\n\n\t+ Added STR750 ARM7 port using the Raisonance RIDE/GCC tools.\n\t+ Added -fomit-frame-pointer option to Rowley ARM7 demos as work around\n\t  to GCC bug at some optimisation levels.\n\t+ Altered the way the heap is defined in the LM3S811 Keil demo to prevent\n\t  the RAM usage from counting toward the code size limit calculation.\n\t+ CO-ROUTINE BUG FIX:  Removed the call to prvIsQueueEmpty from within\n\t  xQueueCRReceive as it exited with interrupts enabled.  Thanks Paul Katz.\n\t+ Tasks that block on events with a timeout of portMAX_DELAY are now\n\t  blocked indefinitely if configINCLUDE_vTaskSuspend is defined.\n\t  Previously portMAX_DELAY was just the longest block time possible. This\n\t  is still the case if configINCLUDE_vTaskSuspend is not defined.\n\t+ Minor changes to some demo application files.\n\nChanges between V4.1.1 and V4.1.2 released October 21, 2006\n\n\t+ Added 16bit PIC ports and demos.\n\t+ Added STR750 port and demo.\n\n\nChanges between V4.1.0 and V4.1.1 released September 24, 2006\n\n\t+ Added the Luminary Micro Stellaris LM3S811 demo application.\n\nChanges between V4.0.5 and V4.1.0 released August 28, 2006\n\n\t+ Prior to V4.1.0, under certain documented circumstances, it was possible\n\t  for xQueueSend() and xQueueReceive() to return without having completed\n\t  and without their block time expiring.  The block time effectively\n\t  stated a maximum block time, and the return value of the function needed\n\t  to be checked to determine the reason for returning.  This is no longer\n\t  the case as the functions will only return once the block time has\n\t  expired or they are able to complete their operation.  It is therefore no\n\t  longer necessary to wrap calls within loops.\n\t+ Changed the critical section handling in the IAR AVR port to correct the\n\t  behaviour when used with later compiler versions.\n\t+ Added the LPC2138 CrossWorks demo into the zip file.  Previously this was\n\t  only available as a separate download.\n\t+ Modified the AVR demo applications to demonstrate the use of co-routines.\n\nChanges between V4.0.4 and V4.0.5 released August 13, 2006\n\n\t+ Introduced API function xTaskResumeFromISR().  Same functionality as\n\t  xTaskResume(), but can be called from within an interrupt service routine.\n\t+ Optimised vListInsert() in the case when the wake time is the maximum\n\t  tick count value.\n\t+ Bug fix:  The 'value' of the event list item is updated when the priority\n\t  of a task is changed.  Previously only the priority of the TCB itself was\n\t  changed.\n\t+ vTaskPrioritySet() and vTaskResume() no longer use the event list item.\n\t  This has not been necessary since V4.0.1 when the xMissedYield handling\n\t  was added.\n\t+ Lowered the PCLK setting on the ARM9 STR9 demo from 96MHz to 48MHz.\n\t+ When ending the scheduler - do not try to attempt a context switch when\n\t  deleting the current task.\n\t+ SAM7X EMAC drivers:  Corrected the Rx frame length mask when obtaining\n\t  the length from the rx descriptor.\n\n\nChanges between V4.0.3 and V4.0.4 released June 22, 2006\n\n\t+ Added a port and demo application for the STR9 ARM9 based processors from\n\t  ST.\n\t+ Slight optimisation to the vTaskPrioritySet() function.\n\t+ Included the latest uIP version (1.0) in the demo/common/ethernet\n\t  directory.\n\nChanges between V4.0.2 and V4.0.3 released June 7, 2006\n\n\t+ Added a port and demo application for the Cortex-M3 target using the IAR\n\t  development tools.\n\t+ The ARM Cortex-m3 Rowley projects have been updated to use V1.6 of the\n\t  CrossStudio tools.\n\t+ The heap size defined for the lwIP Rowley demo has been reduced so that\n\t  the project will link correctly when using the command line GCC tools\n\t  also.  The makefile has also been modified to allow debugging.\n\t+ The lwIP Rowley demo not includes a 'kernel aware' debug window.\n\t+ The uIP Rowley project has been updated to build with V1.6 of CrossWorks.\n\t+ The second set of tasks in the blockQ demo were created the wrong way\n\t  around (inconsistent to the description in the file).  This has been\n\t  corrected.\n\nChanges between V4.0.1 and V4.0.2 released May 28, 2006\n\n\t+ Port and demo application added for the Tern Ethernet Engine controller.\n\t+ Port and demo application added for MC9S12 using GCC, thanks to\n\t  Jefferson \"imajeff\" Smith.\n\t+ The function vTaskList() now suspends the scheduler rather than disabling\n\t  interrupts during the creation of the task list.\n\t+ Allow a task to delete itself by passing in its own handle.  Previously\n\t  this could only be done by passing in NULL.\n\t+ Corrected the value passed to the WDG_PeriodValueConfig() library\n\t  function in the STR71x demo.\n\t+ The tick hook function is now called only within a tick isr.  Previously\n\t  it was also called when the tick function was called during the scheduler\n\t  unlocking process.\n\t+ The EMAC driver in the SAM7X lwIP demo has been made more robust as per\n\t  the thread: https://sourceforge.net/forum/message.php?msg_id=3714405\n\t+ In the PC ports:  Add function prvSetTickFrequencyDefault() to set the\n\t  DOS tick back to its proper value when the scheduler exits.  Thanks\n\t  Raynald!\n\t+ In the Borland x86 ports there was a mistake in the portFIRST_CONTEXT\n\t  macro where the BP register was not popped from the stack correctly.  The\n\t  BP value would never get used so this did not cause a problem, but it has\n\t  been corrected all the same.\n\n\nChanges between V4.0.0 and V4.0.1 released April 7 2006\n\n\t+ Improved the ARM CORTEX M3 ports so they now only have to service\n\t  pendSV interrupts.\n\t+ Added a Luminary Micro port and demo for use with Rowley CrossWorks.\n\t+ Added the xMissedYield handling to tasks.c.\n\nChanges between V3.2.4 and V4.0.0\n\n\tMajor changes:\n\n\t+ Added new RTOS port for Luminary Micros ARM CORTEX M3 microcontrollers.\n\t+ Added new co-routine functionality.\n\n\tOther kernel changes:\n\n\t+ An optional tick hook call is now included in the tick function.\n\t+ Introduced the xMiniListItem structure and removed the list pxHead\n\t  member in order to reduce RAM usage.\n\t+ Added the following definitions to the FreeRTOSConfig.h file included\n\t  with every port:\n\t\tconfigUSE_TICK_HOOK\n\t\tconfigUSE_CO_ROUTINES\n\t\tconfigMAX_CO_ROUTINE_PRIORITIES\n\t+ The volatile qualification has been changed on the list members to allow\n\t  the task.c code to be tidied up a bit.\n\t+ The scheduler can now be started even if no tasks have been created!\n\t  This is to allow co-routines to run when there are no tasks.\n\t+ A task being woken by an event will now preempt the currently running task\n\t  even if its priority is only equal to the currently running task.\n\n\tPort and demo application changes:\n\n\t+ Updated the WinAVR demo to compile with the latest version of WinAVR\n\t  with no warnings generated.\n\t+ Changed the WinAVR makefile to make chars signed - needed for the\n\t  co-routine code if BaseType_t is set to char.\n\t+ Added new demo application file crflash.c.  This demonstrates co-routine\n\t  functionality including passing data between co-routines.\n\t+ Added new demo application file crhook.c.  This demonstrates co-routine\n\t  and tick hook functionality including passing data between and ISR and\n\t  a co-routine.\n\t+ Some NOP's were missing following stmdb{}^ instructions in various ARM7\n\t  ports.  These have been added.\n\t+ Updated the Open Watcom PC demo project to include the crflash and crhook\n\t  demo co-routines as an example of their use.\n\t+ Updated the H8S demo to compile with the latest version of GCC.\n\t+ Updated the SAM7X EMAC drivers to take into account the hardware errata\n\t  regarding lost packets.\n\t+ Changed the default MAC address used by some WEB server demos as the\n\t  original addresses used was not liked by some routers.\n\t+ Modified the SAM7X/IAR startup code slightly to prevent it hanging on\n\t  some systems when the code is executed using a j-link debugger.  The\n\t  j-link macro file configures the PLL before the code executes so\n\t  attempting to configure it again in the startup code was causing a\n\t  problem for some user.  Now a check is performed first to see if the\n\t  PLL is already set up.\n\t+ GCC port now contain all assembler code in a single asm block rather than\n\t  individual blocks as before.\n\t+ GCC LPC2000 code now explicitly uses R0 rather than letting the assembler\n\t  choose the register to use as a temporary register during the context\n\t  switch.\n\t+ Added portNOP() macro.\n\t+ The compare match load value on LPC2000 ports now has 1 added to correct\n\t  the value used.\n\t+ The minimal stack depth has been increased slightly on the WIZC PIC18\n\t  port.\n\nChanges between V3.2.3 and V3.2.4\n\n\t+ Modified the GCC ARM7 port layer to allow use with GCC V4.0.0 and above.\n\t  Many thanks to Glen Biagioni for the provided update.\n\t+ Added a new Microblaze port and demo application.\n\t+ Modified the SAM7X EMAC demo to default to use the MII interface rather\n\t  than the RMII interface.\n\t+ Modified the startup sequence of the SAM7X demo slightly to allow the\n\t  EMAC longer to auto negotiate.\n\nChanges between V3.2.2 and V3.2.3\n\n\t+ Added MII interface support to the SAM7X EMAC peripheral driver.\n\t  Previously versions worked with the RMII interface only.\n\t+ Added command line GCC support to the SAM7X lwIP demo.  Previously the\n\t  project could only be built using the CrossWorks IDE.  Modifications to\n\t  this end include the addition of a standard makefile and linker script to\n\t  the download, and some adjustments to the stacks allocated to each task.\n\t+ Changed the page returned by the lwIP WEB server demo to display the\n\t  task status table rather than the TCP/IP statistics.\n\t+ Corrected the capitalisation of some header file includes and makefile\n\t  dependencies to facilitate use on Linux host computers.\n\t+ The various LPC2000 ports had a mistake in the timer setup where the\n\t  prescale value was written to T0_PC instead of T0_PR.  This would have\n\t  no effect unless a prescale value was actually required.  This has been\n\t  corrected.\n\nChanges between V3.2.1 and V3.2.2 - Released 23 September, 2005\n\n\t+ Added an IAR port for the Philips LPC2129\n\t+ The Atmel ARM7 IAR demo project files are now saved in the IAR Embedded\n\t  Workbench V4.30a format.\n\t+ Updated the J-Link macro file included with the SAM7X uIP demo project\n\t  to allow the demo board to be reset over the J-Link.\n\nChanges between V3.2.0 and V3.2.1 - Released 1 September, 2005\n\n\t+ Added lwIP demo for AT91SAM7X using Rowley tools.\n\t+ Added uIP demo for AT91SAM7X using IAR tools.\n\t+ Added function xTaskGetCurrentTaskHandle().\n\t+ Renamed events.h to mevents.h to prevent it conflicting with the events.h\n\t  generated automatically by the HCS12 processor expert utility.  events.h\n\t  is only used by the PC demo application.\n\t+ Both PIC18 ports now initialise the TBLPTRU to 0 as this is the value\n\t  expected by the compiler, and the compilers do not write to this\n\t  register.\n\t+ The HCS12 banked model demo now creates the 'suicide' tasks immediately\n\t  prior to starting the scheduler.  These tasks should be the last tasks to\n\t  get started in order for the test to function correctly.\n\nChanges between V3.1.1 and V3.2.0 - Released 29 June, 2005\n\n\tV3.2.0 introduces two new MSP430 ports and corrects a minor kernel\n\tissues.  Thanks to Ares.qi for his input.\n\n\t+ Added two MSP430 ports that use the Rowley CrossWorks development tools.\n\t  One port just mirrors the existing GCC port.  The other port was provided\n\t  by Milos Prokic.  Thanks!\n\t+ V3.2.0 corrects the behavior when vTaskPrioritySet() or vTaskResume()\n\t  are called while the scheduler is locked (by a call to\n\t  vTaskSuspendAll()).  When this is done the subject task now starts to\n\t  execute immediately when the scheduler is unlocked if it has the highest\n\t  priority that is ready to run.  Previously there was a possibility that\n\t  the task would not run until the next RTOS tick or call to portYIELD().\n\t+ Another similar small correction ensures that in the case where more than\n\t  one task is blocked on a semaphore or queue, the task with the highest\n\t  priority is guaranteed to be unblocked first.\n\t+ Added a couple of more test tasks to the PC demo which cover the points\n\t  above.\n\nChanges between V3.1.0 and V3.1.1 - Released 21st June, 2005\n\n\tThis release updates the HCS12 port.  The common kernel code\n\tremains unchanged.\n\n\t+ Updated the HCS12 port to support banking and introduced a demo\n\t  application for the MC9S12DP256.  The new demo application is\n\t  located in the Demo/HCS12_CodeWarrior_banked directory.\n\t+ The name of the directory containing the MC9S12F32 demo application\n\t  has been changed to Demo/HCS12_CodeWarrior_small (as in 'small'\n\t  memory model).\n\t+ MC9S12F32 demo updated slightly to use the PLL.  The CPU speed for the\n\t  demo application is now 24MHz.  Previously it was 8MHz.\n\t+ The demo application file Demo/Common/Minimal/death.c has a slight\n\t  alteration to prevent it using floating point variables.\n\n\nChanges between V3.0.0 and V3.1.0 - Released 11th June, 2005\n\n\t+ Added new ports for ST Microsystems STR71x, and Freescale HCS12\n\t  microcontrollers.  Currently the HCS12 port is limited to the small\n\t  memory model.  Large memory models will be supported in the next\n\t  release.\n\t+ PIC18 wizC port updated.  Thanks to Marcel van Lieshout for his\n\t  continuing contribution.\n\t+ The accuracy of the AVR port timer setup has been improved.  Thanks to\n\t  Thomas Krutmann for this contribution.\n\t+ Added a new conditional compilation macro configIDLE_SHOULD_YIELD.\n\t  See the WEB documentation for details.\n\t+ Updated the CrossWorks uIP demo to build with V1.4 of CrossWorks.\n\t+ Slight modification to the SAM7 release build configuration to correct\n\t  an include path definition.\n\t+ Updated the MPLAB PIC18 documentation to provide extra details on linker\n\t  file configuration.\n\nChanges between V3.0.0 and V2.6.1 - Released 23rd April, 2005\n\n\tV3.0.0 includes many enhancements, so this history list is broken into\n\tsubsections as follows:\n\n\t\tAPI changes\n\t\tNew ports\n\t\tDirectory name changes\n\t\tKernel and miscellaneous changes changes\n\n\t- API changes\n\n\t\t+ Each port now defines BaseType_t as the data type that is most\n\t\t  efficient for that architecture.  The type BaseType_t is used\n\t\t  extensively in API calls necessitating the following changes to the\n\t\t  FreeRTOS API function prototypes.\n\n\t\t  See the \"New for V3.0.0\" section of the FreeRTOS online\n\t\t  documentation for full details of API changes.\n\n\t- New ports\n\n\t\t+ The AT91FR40008 ARM7 port contributed by John Feller is now included\n\t\t  in the download (thanks John!).\n\t\t+ The PIC18 port for the wizC/fedC compiler contributed by Marcel van\n\t\t  Lieshout is now included in the download (thanks Marcel!).\n\t\t+ The IAR port for the AVR microcontroller has been upgraded to V3.0.0\n\t\t  and is now a supported port.\n\n\t- Directory name changes\n\n\t\tFor consistency, and to allow integration of the new ports, the\n\t\tfollowing directory names have been changed.\n\n\t\t+ The source/portable/GCC/ARM7 directory has been renamed\n\t\t  source/portable/GCC/ARM7_LPC2000 so it is compatible with the naming\n\t\t  of other GCC ARM7 ports.\n\t\t+ The Demo/PIC directory has been renamed Demo/PIC18_MPLAB to\n\t\t  accommodate the wizC/fedC PIC port.\n\t\t+ The demo applications for the two AVR ports no longer share the same\n\t\t  directory.  The WinAVR demo is in the Demo/AVR_ATMega323_WinAVR\n\t\t  directory and the IAR port in the Demo/AVR_ATMega323_IAR directory.\n\n\n\t- Kernel and miscellaneous changes changes\n\n\t\t  See the \"New for V3.0.0\" section of the FreeRTOS online\n\t\t  documentation for more information.\n\n\t\t+ Previously 'portmacro.h' contained some user editable definitions\n\t\t  relating to the user application, and some fixed definitions relating\n\t\t  specifically to the port being used.  The application specific\n\t\t  definitions have been removed from 'portmacro.h' and placed inside a\n\t\t  new header file called 'FreeRTOSConfig.h'.  'portmacro.h' should now\n\t\t  never be modified by the user.  A 'FreeRTOSConfig.h' is now included\n\t\t  in each of FreeRTOS/Demo subdirectories - as it's settings relate to\n\t\t  the demo application rather than being specific to the port.\n\t\t+ Introduced configUSE_IDLE_HOOK in idle task.\n\t\t+ The idle task will yield when another idle priority task is ready to\n\t\t  run. Previously the idle task would run to the end of its time slice\n\t\t  regardless.\n\t\t+ The idle task is now created when the scheduler is started.  This\n\t\t  requires less stack than the previous scheme where it was created upon\n\t\t  creation of the first application task.\n\t\t+ The function usPortCheckFreeStackSpace() has been renamed\n\t\t  usTaskCheckFreeStackSpace() and moved from the portable layer to\n\t\t  tasks.c.\n\t\t+ Corrected spelling of portMINMAL_STACK_SIZE to portMINIMAL_STACK_SIZE.\n\t\t+ The portheap.c file included with the AVR port has been deleted.  The\n\t\t  AVR demo now uses the standard heap1 sample memory allocator.\n\t\t+ The GCC AVR port is now build using the standard make utility.  The\n\t\t  batch files used previously have been deleted.  This means a recent\n\t\t  version of WinAVR is required in order to create a binary suitable for\n\t\t  source level debugging.\n\t\t+ vTaskStartScheduler() no longer takes the configUSE_PREEMPTION\n\t\t  constant as a parameter.  Instead the constant is used directly within\n\t\t  tasks.c  and no parameter is required.\n\t\t+ The header file 'FreeRTOS.h' has been created and is used to include\n\t\t  'projdefs.h', 'FreeRTOSConfig.h' and 'portable.h' in the necessary\n\t\t  order.  FreeRTOS.h can now be included in place of these other\n\t\t  headers.\n\t\t+ The header file 'errors.h' has been deleted.  The definitions it\n\t\t  contained are now located within 'projdefs.h'.\n\t\t+ pvPortMalloc() now takes a size_t parameter as per the ANSI malloc().\n\t\t  Previously an unsigned short was used.\n\t\t+ When resuming the scheduler a yield is performed if either a tick has\n\t\t  been missed, or a task is moved from the pending ready list into a\n\t\t  ready list.  Previously a yield was not performed on this second\n\t\t  condition.\n\t\t+ In heap1.c an overflow check has been added to ensure the next free\n\t\t  byte variable does not wrap around.\n\t\t+ Introduced the portTASK_FUNCTION() and portTASK_FUNCTION_PROTO()\n\t\t  macros.\n\t\t+ The MPLAB PIC port now saved the TABLAT register in interrupt service\n\t\t  routines.\n\nChanges between V2.6.0 and V2.6.1 - Released Feb 22, 2005\n\n\tThis version adds support for the H8 processor.\n\n\tOther changes:\n\n\t+ tskMAX_TASK_NAME_LEN removed from the task.h header and added to each\n\t  individual portmacro.h file as portMAX_TASK_NAME_LEN.  This allows RAM\n\t  limited ports to allocate fewer characters to the task name.\n\t+ AVR port - Replaced the inb() and outb() functions with direct memory\n\t  access.  This allows the port to be built with the 20050414 build of\n\t  WinAVR.\n\t+ GCC LPC2106 port - removed the 'static' from the definition of\n\t  vNonPreemptiveTick() to allow the demo to link when using the cooperative\n\t  scheduler.\n\t+ GCC LPC2106 port - Corrected the optimisation options in the batch files\n\t  ROM_THUMB.bat, RAM_THUMB.bat, ROM_ARM.bat and RAM_ARM.bat.  The lower case\n\t  -o is replaced by an uppercase -O.\n\t+ Tasks.c - The strcpy call has been removed when copying across the task\n\t  name into the TCB.\n\t+ Updated the trace visualisation to always be 4 byte aligned so it can be\n\t  used on ARM architectures.\n\t+ There are now two tracecon executables (that convert the trace file binary\n\t  into an ASCII file).  One for big endian targets and one for little endian\n\t  targets.\n\t+ Added ucTasksDeleted variable to prevent vTaskSuspendAll() being called\n\t  too often in the idle task.\n\t+ SAM7 USB driver - Replaced the duplicated RX_DATA_BK0 in the interrupt\n\t  mask with the RX_DATA_BK1.\n\n\nChanges between V2.5.5 and V2.6.0 - Released January 16, 2005\n\n\t+ Added the API function vTaskDelayUntil().  The demo app file\n\t  Demo/Common/Minimal/flash.c has been updated to demonstrate its use.\n\t+ Added INCLUDE_vTaskDelay conditional compilation.\n\t+ Changed the name of the Demo/ARM7_AtmelSAM7S64_IAR directory to\n\t  Demo/ARM7_AT91SAM7S64_IAR for consistency.\n\t+ Modified the AT91SAM7S USB driver to allow descriptors that have\n\t  a length that is an exact multiple of the FIFO to be transmitted.\n\nChanges between V2.5.4 and V2.5.5 - Released January 3, 2005\n\n\tThis version adds support for the Atmel SAM7 ARM7 microcontrollers\n\talong with the IAR development tools.\n\n\tOther changes:\n\n\t+ Renamed the Demo/ARM7 directory to Demo/ARM7_LPC2106_GCC.\n\t+ Renamed the Demo/ARM7_Keil directory to Demo/ARM7_LPC2129_Keil.\n\t+ Modified the Philips ARM7 serial interrupt service routines to only\n\t  process one interrupt per call.  This seems to enable the ISR to\n\t  operate more quickly.\n\t+ Removed the 'far' keyword from the Open Watcom portable layer source\n\t  files.  This allows their use with V1.3 of Open Watcom.\n\t+ Minor modifications to the SDCC build files to allow their use under\n\t  Linux.  Thanks to Frieder Ferlemann for this contribution.\n\t+ Small change to sTaskCreate() to allow a context switch even when\n\t  pxCreatedTask is NULL.  Thanks to Kamil for this contribution.\n\t+ inline keyword removed from vTaskSwitchContext() and VTaskIncrementTick()\n\t  definitions.\n\nChanges between V2.5.3 and V2.5.4 - Released Dec 1, 2004\n\n\tThis is an important maintenance release.\n\n\tThe function cTaskResumeAll() has been modified so it can be used safely\n\tprior to the kernel being initialised.  This was an issue as\n\tcTaskResumeAll() is called from pvPortMalloc().  Thanks to Daniel Braun\n\tfor highlighting this issue.\n\nChanges between V2.5.2 and V2.5.3 - Released Nov 2, 2004\n\n\tThe critical section handling functions have been changed for the GCC ARM7\n\tport.   Some optimisation levels use the stack differently to others.  This\n\tmeans the interrupt flags cannot always be stored on the stack and are\n\tinstead now stored in a variable, which is then saved as part of the\n\ttasks context.  This allows the GCC ARM7 port to be used at all\n\toptimisation levels - including -Os.\n\n\tOther minor changes:\n\n\t+ MSP430 definition of usCriticalNesting now uses the volatile qualifier.\n\t  This is probably not required but added just in case.\n\nChanges between V2.5.1 and V2.5.2 - Released Oct 26, 2004\n\n\t+ Added the Keil ARM7 port.\n\t+ Slight modification to comtest.c to make the delay periods more random.\n\t  This creates a better test condition.\n\nChanges between V2.5.0 and V2.5.1 - Released Oct 9, 2004\n\n\t+ Added the MSP430 port.\n\t+ Extra comments added to the GCC ARM7 port.c and portISR.c files.\n\t+ The memory pool allocated within heap_1.c has been placed within a\n\t  structure to ensure correct memory alignment on 32bit systems.\n\t+ Within the GCC ARM7 serial drivers an extra check is made to ensure\n\t  the post to the queue was successful if then attempting immediately\n\t  retrieve the posted character.\n\t+ Changed the name of the constant portTICKS_PER_MS to portTICK_PERIOD_MS\n\t  as the old name was misleading.\n\n\nChanges between V2.4.2 and V2.5.0 - Released Aug 12, 2004\n\n\tThe RTOS source code download now includes three separate memory allocation\n\tschemes - so you can choose the most appropriate for your application.\n\tThese are found in the Source/Portable/MemMang directory.  The demo\n\tapplication projects have also been updated to demonstrate the new schemes.\n\tSee the \"Memory Management\" page of the API documentation for more details.\n\n\t+ Added heap_1.c, heap_2.c and heap_3.c in the Source/Portable/MemMang\n\t  directory.\n\t+ Replaced the portheap.c files for each demo application with one of the\n\t  new memory allocation files.\n\t+ Updated the portmacro.h file for each demo application to include the\n\t  constants required for the new memory allocators: portTOTAL_HEAP_SIZE and\n\t  portBYTE_ALIGNMENT.\n\t+ Added a new test to the ARM7 demo application that tests the operation\n\t  of the heap_2 memory allocator.\n\n\nChanges between V2.4.1 and V2.4.2 - Released July 14, 2004\n\n\t+ The ARM7 port now supports THUMB mode.\n\t+ Modification to the ARM7 demo application serial port driver.\n\nChanges between V2.4.0 and V2.4.1 - Released July 2, 2004\n\n\t+ Rationalised the ARM7 port version of portEXIT_CRITICAL() -\n\t  improvements provided by Bill Knight.\n\t+ Made demo serial driver more complete and robust.\n\n\nChanges between V2.4.0 and V2.3.1 - Released June 30, 2004\n\n\t+ Added the first ARM7 port - thanks to Bill Knight for the assistance\n\t  provided.\n\t+ Added extra files to the Demo/Common/Minimal directory.  These are\n\t  equivalent to their Demo/Common/Full counterparts but with the\n\t  calls to the functions defined in print.c removed.\n\t+ Added TABLAT to the list of registers saved as part of a PIC18 context.\n\nChanges between V2.3.0 and V2.3.1 - Released June 25, 2004\n\n\t+ Changed the way the vector table is defined to be more portable.\n\t+ Corrected the definitions of SPH and SPL in portmacro.s90.\n\t  The previous definitions prevented V2.3.0 operating if the iom323.h\n\t  header file was included in portmacro.s90.\n\nChanges between V2.2.0 and V2.3.0 - Released June 19, 2004\n\n\t+ Added an AVR port that uses the IAR compiler.\n\t+ Explicit use of 'signed' qualifier on plain char types.\n\t+ Modified the Open Watcom project files to use 'signed' as the\n\t  default char type.\n\t+ Changed odd calculation of initial pxTopOfStack value when\n\t  portSTACK_GROWTH < 0.\n\t+ Added inline qualifier to context switch functions within task.c.\n\t  Ports that do not support the (non ANSI) inline keyword have the\n\t  inline #define'd away in  their respective portmacro.h files.\n\nChanges between V2.1.1 and V2.2.0 - Released May 18, 2004\n\n\t+ Added Cygnal 8051 port.\n\t+ PCLATU and PCLATH are now saved as part of the PIC18 context.  This\n\t  allows function pointers to be used within tasks.  Thanks to Javier\n\t  Espeche for the enhancement.\n\t+ Minor changes to demo application files to reduce stack usage.\n\t+ Minor changes to prevent compiler warnings when compiling the new port.\n\nChanges between V2.1.0 and V2.1.1 - Released March 12, 2004\n\n\t+ Bug fix - pxCurrentTCB is now initialised before the call to\n\t  prvInitialiseTaskLists().  Previously pxCurrentTCB could be accessed\n\t  while null during the initialisation sequence.  Thanks to Giuseppe\n\t  Franco for the correction.\n\nChanges between V2.0.0 and V2.1.0 - Released Feb 29, 2004\n\n\tV2.1.0 has significant reworks that greatly reduce the amount of time\n\tthe kernel has interrupts disabled.  The first section of modifications\n\tlisted here must be taken into account by users.  The second section\n\tare related to the kernel implementation and as such are transparent.\n\n\tSection1 :\n\n\t+ The typedef TickType_t has been introduced.  All delay times should\n\t  now use a variable of type TickType_t in place of the unsigned long's\n\t  used previously.  API function prototypes have been updated\n\t  appropriately.\n\t+ The configuration macro USE_16_BIT_TICKS has been introduced.  If set\n\t  to 1 TickType_t is defined as an unsigned short.  If set to 0\n\t  TickType_t is defined as an unsigned long.  See the configuration\n\t  section of the API documentation for more details.\n\t+ The configuration macro INCLUDE_vTaskSuspendAll is now obsolete.\n\t+ vTaskResumeAll() has been renamed cTaskResumeAll() as it now returns a\n\t  value (see the API documentation).\n\t+ ulTaskGetTickCount() has been renamed xTaskGetTickCount() as the type\n\t  it returns now depends on the USE_16_BIT_TICKS definition.\n\t+ cQueueReceive() must now >never< be used from within an ISR.  Use the new\n\t  cQueueReceiveFromISR() function instead.\n\n\tSection 2:\n\n\t+ A mechanism has been introduced that allows a queue to be accessed by\n\t  a task and ISR simultaneously.\n\t+ A \"pending ready\" queue has been introduced that enables interrupts to\n\t  be processed when the scheduler is suspended.\n\t+ The list implementation has been improved to provide faster item\n\t  removal.\n\t+ The scheduler now makes use of the scheduler suspend mechanism in places\n\t  where previously interrupts were disabled.\n\nChanges between V1.2.6 and V2.0.0 - Released Jan 31, 2004\n\n\t+ Introduced new API functions:\n\t\tvTaskPriorityGet ()\n\t\tvTaskPrioritySet ()\n\t\tvTaskSuspend ()\n\t\tvTaskResume ()\n\t\tvTaskSuspendAll ()\n\t\tvTaskResumeAll ()\n\t+ Added conditional compilation options that allow the components of the\n\t  kernel that are unused by an application to be excluded from the build.\n\t  See the Configuration section on the WEB site for more information (on\n\t  the API pages).  The macros have been added to each portmacro.h file (\n\t  sometimes called prtmacro.h).\n\t+ Rearranged tasks.c.\n\t+ Added demo application file dynamic.c.\n\t+ Updated the PC demo application to make use of dynamic.c.\n\t+ Updated the documentation contained in the kernel header files.\n\t+ Creating a task now causes a context switch if the task being created\n\t  has a higher priority than the calling task - assuming the kernel is\n\t  running.\n\t+ vTaskDelete() now only causes a context switch if the calling task is\n\t  the task being deleted.\n\nChanges between V1.2.5 and V1.2.6 - Released December 31, 2003\n\n\tBarring the change to the interrupt vector (PIC port) these are minor\n\tenhancements.\n\n\t+ The interrupt vector used for the PIC master ISR has been changed from\n\t  0x18 to 0x08 - where it should have always been.  The incorrect address\n\t  still works but probably executes a number of NOP's before getting to the\n\t  ISR.\n\t+ Changed the baud rate used by the AVR demo application to 38400.  This\n\t  has an error percentage of less than one percent with an 8MHz clock.\n\t+ Raised the priority of the Rx task in demo\\full\\comtest.c.  This only\n\t  affects the Flashlite and PC ports.  This was done to prevent the Rx\n\t  buffer becoming full.\n\t+ Reverted the Flashlite COM port driver back so it does not use the DMA.\n\t  The DMA appears to miss characters under stress.  The Borland Flashlite\n\t  port was also calculating a register value incorrectly resulting in the\n\t  wrong DMA source address being used.  The same code worked fine when\n\t  compiling with Open Watcom.  Other minor enhancements were made to the\n\t  interrupt handling.\n\t+ Modified the PIC serial Rx ISR to check for and clear overrun errors.\n\t  Overrun errors seem to prevent any further characters being received.\n\t+ The PIC demo projects now have some optimisation switched on.\n\n\nChanges between V1.2.4 and V1.2.5\n\n\tSmall fix made to the PIC specific port.c file described below.\n\n\t+ Introduced portGLOBAL_INTERRUPT_FLAG definition to test the global\n\t  interrupt flag setting.  Using the two bits defined within\n\t  portINITAL_INTERRUPT_STATE was causing the w register to get clobbered\n\t  before the test was performed.\n\nChanges between V1.2.3 and V1.2.4\n\n\tV1.2.4 contains a release version of the PIC18 port.\n\tAn optional exception has been included with the GPL.  See the licensing\n\tsection of www.FreeRTOS.org for details.\n\n\t+ The function xPortInitMinimal() has been renamed to\n\t  xSerialPortInitMinimal() and the function xPortInit() has been renamed\n\t  to xSerialPortInit().\n\t+ The function sSerialPutChar() has been renamed cSerialPutChar() and\n\t  the function return type changed to portCHAR.\n\t+ The integer and flop tasks now include calls to tskYIELD(), allowing\n\t  them to be used with the cooperative scheduler.\n\t+ All the demo applications now use the integer and comtest tasks when the\n \t  cooperative scheduler is being used.  Previously they were only used with\n\t  the preemptive scheduler.\n\t+ Minor changes made to operation of minimal versions of comtest.c and\n\t  integer.c.\n\t+ The ATMega port definition of portCPU_CLOSK_HZ definition changed to\n\t  8MHz base 10, previously it base 16.\n\n\n\nChanges between V1.2.2a and V1.2.3\n\n\tThe only change of any significance is to the license, which has changed\n\tfrom the Open Software License to the GNU GPL.\n\n\tThe zip file also contains a pre-release version of the PIC18 port.  This\n\thas not yet completed testing and as such does not constitute part of the\n\tV1.2.3 release.  It is still however covered by the GNU GPL.\n\n\tThere are minor source code changes to accommodate the PIC C compiler.\n\tThese mainly involve more explicit casting.\n\n\t+ sTaskCreate() has been modified slightly to make use of the\n\t  portSTACK_GROWTH macro.  This is required for the PIC port where the\n\t  stack grows in the opposite direction to the other existing ports.\n\t+ prvCheckTasksWaitingTermination() has been modified slightly to bring\n\t  the decrementing of usCurrentNumberOfTasks within the critical section,\n\t  where it should have been since the creation of an eight bit port.\n\nChanges between V1.2.2 and V1.2.2a\n\n\tThe makefile and buildcoff.bat files included with the AVR demo application\n\thave been modified for use with the September 2003 build of WinAVR.  No\n\tsource files have changed.\n\nChanges between V1.2.1 and V1.2.2\n\n\tThere are only minor changes here to allow the PC and Flashlite 186 ports\n\tto use the Borland V4.52 compiler, as supplied with the Flashlite 186\n\tdevelopment kit.\n\n\t+ Introduced a BCC directory under source\\portable.  This contains all the\n\t  files specific to the Borland compiler port.\n\t+ Corrected the macro naming of portMS_PER_TICK to portTICKS_PER_MS.\n\t+ Modified comtest.c to increase the rate at which the string is\n\t  transmitted and received on the serial port.  The Flashlite 186 demo\n\t  app baud rate has also been increased.\n\t+ The values of the constants used in both integer.c files have been\n          increased to force the Borland compiler to use 32 bit values.  The\n          Borland optimiser placed the previous values in 16 bit registers, and in\n          So doing invalidated the test.\n\nChanges between V1.2.0 and V1.2.1\n\n\tThis version includes some minor changes to the list implementation aimed\n\tat improving the context switch time - with is now approximately 10% faster.\n\tChanges include the removal of some null pointer assignment checks.  These\n\twere redundant where the scheduler uses the list functions, but means any\n\tuser application choosing to use the same list functions must now check\n\tthat no NULL pointers are passed as a parameter.\n\n\tThe Flashlite 186 serial port driver has also been modified to use a DMA\n\tchannel for transmissions.  The serial driver is fully functional but still\n\tunder development.  Flashlite users may prefer to use V1.2.0 for now.\n\n\tDetails:\n\n\t+ Changed the baud rate for the ATMega323 serial test from 19200 to 57600.\n\t+ Use vSerialPutString() instead of single character puts in\n\t  Demo\\Full\\Comtest.c.  This allows the use of the flashlite DMA serial\n\t  driver.  Also the check variable only stops incrementing after two\n\t  consecutive failures.\n\t+ semtest.c creates four tasks, two of which operate at the idle priority.\n\t  The tasks that operate at the idle priority now use a lower expected\n\t  count than those running at a higher priority.  This prevents the low\n\t  priority tasks from signalling an error because they have not been\n\t  scheduled enough time for each of them to count the shared variable to\n\t  the higher original value.\n\t+ The flashlite 186 serial driver now uses a DMA channel for transmissions.\n\t+ Removed the volatile modifier from the list function parameters.  This was\n\t  only ever included to prevent compiler warnings.  Now warnings are\n\t  removed by casting parameters where the calls are made.\n\t+ prvListGetOwnerOfNextEntry() and prvListGetOwnerOfHeadEntry() have been\n\t  removed from list.c and added as macros in list.h.\n\t+ usNumberOfItems has been added to the list structure.  This removes the\n\t  need for a pointer comparison when checking if a list is empty, and so\n\t  is slightly faster.\n\t+ Removed the NULL check in vListRemove().  This makes the call faster but\n\t  necessitates any application code utilising the list implementation to\n\t  ensure NULL pointers are not passed.\n\t+ Renamed portTICKS_PER_MS definition to portMS_PER_TICK (milli seconds\n\t  per tick).  This is what it always should have been.\n\nChanges between V1.01 and V1.2.0\n\n\tThe majority of these changes were made to accommodate the 8bit AVR port.\n\tThe scheduler workings have not changed, but some of the data types used\n\thave been made more friendly to an eight bit environment.\n\n\tDetails:\n\n\t+ Changed the version numbering format.\n\t+ Added AVR port.\n\t+ Split the directory demo\\common into demo\\common\\minimal and\n\t  demo\\common\\full.  The files in the full directory are for systems with\n\t  a display (currently PC and Flashlite 186 demo's).  The files in the\n\t  minimal directory are for systems with limited RAM and no display\n\t  (currently MegaAVR).\n\t+ Minor changes to demo application function prototypes to make more use\n\t  of 8bit data types.\n\t+ Within the scheduler itself the following functions have slightly\n\t  modified declarations to make use of 8bit data types where possible:\n\t\txQueueCreate(),\n\t\tsQueueReceive(),\n\t\tsQUeueReceive(),\n\t\tusQueueMessageWaiting(),\n\t\tsQueueSendFromISR(),\n\t\tsSemaphoreTake(),\n\t\tsSemaphoreGive(),\n\t\tsSemaphoreGiveFromISR(),\n\t\tsTaskCreate(),\n\t\tsTaskMoveFromEventList().\n\n\t  Where the return type has changed the function name has also changed in\n\t  accordance with the naming convention.  For example\n\t  usQueueMessageWaiting() has become ucQueueMessageWaiting().\n\t+ The definition tskMAX_PRIORITIES has been moved from task.h to\n\t  portmacro.h and renamed portMAX_PRIORITIES.  This allows different\n\t  ports to allocate a different maximum number of priorities.\n\t+ By default the trace facility is off, previously USE_TRACE_FACILITY\n\t  was defined.\n\t+ comtest.c now uses a pseudo random delay between sends.  This allows for\n\t  better testing as the interrupts do not arrive at regular intervals.\n\t+ Minor change to the Flashlite serial port driver.  The driver is written\n\t  to demonstrate the scheduler and is not written to be efficient.\n\n\n\nChanges between V1.00 and V1.01\n\n\tThese changes improve the ports.  The scheduler itself has not changed.\n\n\tImproved context switch mechanism used when performing a context\n\tswitch from an ISR (both the tick ISR and the serial comms ISR's within\n\tthe demo application).  The new mechanism is faster and uses less stack.\n\n\tThe assembler file portasm.asm has been replaced by a header file\n\tportasm.h.  This includes a few assembler macro definitions.\n\n\tAll saving and restoring of registers onto/off of the stack is now handled\n\tby the compiler.  This means the initial stack setup for a task has to\n\tmimic the stack used by the compiler, which is different for debug and\n\trelease builds.\n\n\tSlightly changed the operation of the demo application, details below.\n\n\tDetails:\n\n\t+ portSWITCH_CONTEXT() replaced by vPortFirstContext().\n\t+ pxPortInitialiseStack() modified to replicate the stack used by the\n\t  compiler.\n\t+ portasm.asm file removed.\n\t+ portasm.h introduced.  This contains macro definitions for\n\t  portSWITCH_CONTEXT() and portFIRST_CONTEXT().\n\t+ Context switch from ISR now uses the compiler generated interrupt\n\t  mechanism.  This is done simply by calling portSWITCH_CONTEXT and leaving\n\t  the save/restore to compiler generated code.\n\t+ Calls to taskYIELD() during ISR's have been replaced by calling the\n\t  simpler and faster portSWITCH_CONTEXT().\n\t+ The Flashlite 186 port now uses 186 instruction set (used to use 80x86\n\t  instructions only).\n\t+ The blocking queue tasks within the demo application did not operate\n\t  quite as described.  This has been corrected.\n\t+ The priority of the comtest Rx task within the demo application has been\n\t  lowered.  Received characters are now processed (read from the queue) at\n\t  the idle priority, allowing low priority tasks to run evenly at times of\n\t  a high communications overhead.\n\t+ Prevent the call to kbhit() in main.c for debug builds as the debugger\n\t  seems to have problems stepping over the call.  This if for the PC port\n\t  only.\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.01171875,
          "content": "MIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MISRA.md",
          "type": "blob",
          "size": 4.9140625,
          "content": "# MISRA Compliance\n\nFreeRTOS-Kernel conforms to [MISRA C:2012](https://www.misra.org.uk/misra-c)\nguidelines, with the deviations listed below. Compliance is checked with\nCoverity static analysis version 2023.6.1. Since the FreeRTOS kernel is\ndesigned for small-embedded devices, it needs to have a very small memory\nfootprint and has to be efficient. To achieve that and to increase the\nperformance, it deviates from some MISRA rules. The specific deviations,\nsuppressed inline, are listed below.\n\nAdditionally, [MISRA configuration file](examples/coverity/coverity_misra.config)\ncontains project wide deviations.\n\n### Suppressed with Coverity Comments\nTo find the violation references in the source files run grep on the source code\nwith ( Assuming rule 8.4 violation; with justification in point 1 ):\n```\ngrep 'MISRA Ref 8.4.1' . -rI\n```\n\n#### Dir 4.7\nMISRA C:2012 Dir 4.7: If a function returns error information, then that error\ninformation shall be tested.\n\n_Ref 4.7.1_\n - `taskENTER_CRITICAL_FROM_ISR` returns the interrupt mask and not any error\n    information. Therefore, there is no need test the return value.\n\n#### Rule 8.4\n\nMISRA C:2012 Rule 8.4: A compatible declaration shall be visible when an\nobject or function with external linkage is defined.\n\n_Ref 8.4.1_\n - pxCurrentTCB(s) is defined with external linkage but it is only referenced\n   from the assembly code in the port files. Therefore, adding a declaration in\n   header file is not useful as the assembly code will still need to declare it\n   separately.\n\n_Ref 8.4.2_\n - xQueueRegistry is defined with external linkage because it is accessed by the\n   kernel unit tests. It is not meant to be directly accessed by the application\n   and therefore, not declared in a header file.\n\n#### Rule 8.6\n\nMISRA C:2012 Rule 8.6: An identifier with external linkage shall have exactly\none external definition.\n\n_Ref 8.6.1_\n - This rule prohibits an identifier with external linkage to have multiple\n   definitions or no definition. FreeRTOS hook functions are implemented in\n   the application and therefore, have no definition in the Kernel code.\n\n#### Rule 11.1\nMISRA C:2012 Rule 11.1: Conversions shall not be performed between a pointer to\nfunction and any other type.\n\n_Ref 11.1.1_\n - The pointer to function is casted into void to avoid unused parameter\n   compiler warning when Stream Buffer's Tx and Rx Completed callback feature is\n   not used.\n\n#### Rule 11.3\n\nMISRA C:2012 Rule 11.3: A cast shall not be performed between a pointer to\nobject type and a pointer to a different object type.\n\n_Ref 11.3.1_\n - This rule prohibits casting a pointer to object into a pointer to a\n   different object because it may result in an incorrectly aligned pointer,\n   leading to undefined behavior. Even if the casting produces a correctly\n   aligned pointer, the behavior may be still undefined if the pointer is\n   used to access an object. FreeRTOS deliberately creates external aliases\n   for all the kernel object types (StaticEventGroup_t, StaticQueue_t,\n   StaticStreamBuffer_t, StaticTimer_t and StaticTask_t) for data hiding\n   purposes. The internal object types and the corresponding external\n   aliases are guaranteed to have the same size and alignment which is\n   checked using configASSERT.\n\n\n#### Rule 11.5\n\nMISRA C:2012 Rule 11.5: A conversion should not be performed from pointer to\nvoid into pointer to object.\nThis rule prohibits conversion of a pointer to void into a pointer to\nobject because it may result in an incorrectly aligned pointer leading\nto undefined behavior.\n\n_Ref 11.5.1_\n - The memory blocks returned by pvPortMalloc() are guaranteed to meet the\n   architecture alignment requirements specified by portBYTE_ALIGNMENT.\n   The casting of the pointer to void returned by pvPortMalloc() is,\n   therefore, safe because it is guaranteed to be aligned.\n\n_Ref 11.5.2_\n - The conversion from a pointer to void into a pointer to EventGroup_t is\n   safe because it is a pointer to EventGroup_t, which is returned to the\n   application at the time of event group creation for data hiding\n   purposes.\n\n_Ref 11.5.3_\n - The conversion from a pointer to void in list macros for list item owner\n   is safe because the type of the pointer stored and retrieved is the\n   same.\n\n_Ref 11.5.4_\n - The conversion from a pointer to void into a pointer to EventGroup_t is\n   safe because it is a pointer to EventGroup_t, which is passed as a\n   parameter to the xTimerPendFunctionCallFromISR API when the callback is\n   pended.\n\n_Ref 11.5.5_\n - The conversion from a pointer to void into a pointer to uint8_t is safe\n   because data storage buffers are implemented as uint8_t arrays for the\n   ease of sizing, alignment and access.\n\n#### Rule 21.6\n\nMISRA C-2012 Rule 21.6: The Standard Library input/output functions shall not\nbe used.\n\n_Ref 21.6.1_\n - The Standard Library function snprintf is used in vTaskListTasks and\n   vTaskGetRunTimeStatistics APIs, both of which are utility functions only and\n   are not considered part of core kernel implementation.\n"
        },
        {
          "name": "Quick_Start_Guide.url",
          "type": "blob",
          "size": 0.13671875,
          "content": "[InternetShortcut]\nURL=https://www.FreeRTOS.org/FreeRTOS-quick-start-guide.html\nIDList=\n[{000214A0-0000-0000-C000-000000000046}]\nProp3=19,2\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.35546875,
          "content": "[![CMock Unit Tests](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml/badge.svg?branch=main&event=push)](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml?query=branch%3Amain+event%3Apush+workflow%3A%22CMock+Unit+Tests%22++)\n[![codecov](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel/badge.svg?branch=main)](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel)\n\n## Getting started\n\nThis repository contains FreeRTOS kernel source/header files and kernel\nports only. This repository is referenced as a submodule in\n[FreeRTOS/FreeRTOS](https://github.com/FreeRTOS/FreeRTOS)\nrepository, which contains pre-configured demo application projects under\n```FreeRTOS/Demo``` directory.\n\nThe easiest way to use FreeRTOS is to start with one of the pre-configured demo\napplication projects.  That way you will have the correct FreeRTOS source files\nincluded, and the correct include paths configured. Once a demo application is\nbuilding and executing you can remove the demo application files, and start to\nadd in your own application source files.  See the\n[FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide)\nfor detailed instructions and other useful links.\n\nAdditionally, for FreeRTOS kernel feature information refer to the\n[Developer Documentation](https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/00-Developer-docs),\nand [API Reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle).\n\nAlso for contributing and creating a Pull Request please refer to\n[the instructions here](.github/CONTRIBUTING.md#contributing-via-pull-request).\n\n**FreeRTOS-Kernel V11.1.0\n[source code](https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/V11.1.0) is part\nof the\n[FreeRTOS 202406.00 LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/tree/202406-LTS)\nrelease.**\n\n### Getting help\n\nIf you have any questions or need assistance troubleshooting your FreeRTOS project,\nwe have an active community that can help on the\n[FreeRTOS Community Support Forum](https://forums.freertos.org).\n\n## To consume FreeRTOS-Kernel\n\n### Consume with CMake\n\nIf using CMake, it is recommended to use this repository using FetchContent.\nAdd the following into your project's main or a subdirectory's `CMakeLists.txt`:\n\n- Define the source and version/tag you want to use:\n\n```cmake\nFetchContent_Declare( freertos_kernel\n  GIT_REPOSITORY https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n  GIT_TAG        main #Note: Best practice to use specific git-hash or tagged version\n)\n```\n\nIn case you prefer to add it as a git submodule, do:\n\n```bash\ngit submodule add https://github.com/FreeRTOS/FreeRTOS-Kernel.git <path of the submodule>\ngit submodule update --init\n```\n\n- Add a freertos_config library (typically an INTERFACE library) The following assumes the directory structure:\n  - `include/FreeRTOSConfig.h`\n\n```cmake\nadd_library(freertos_config INTERFACE)\n\ntarget_include_directories(freertos_config SYSTEM\nINTERFACE\n    include\n)\n\ntarget_compile_definitions(freertos_config\n  INTERFACE\n    projCOVERAGE_TEST=0\n)\n```\n\nIn case you installed FreeRTOS-Kernel as a submodule, you will have to add it as a subdirectory:\n\n```cmake\nadd_subdirectory(${FREERTOS_PATH})\n```\n\n- Configure the FreeRTOS-Kernel and make it available\n  - this particular example supports a native and cross-compiled build option.\n\n```cmake\nset( FREERTOS_HEAP \"4\" CACHE STRING \"\" FORCE)\n# Select the native compile PORT\nset( FREERTOS_PORT \"GCC_POSIX\" CACHE STRING \"\" FORCE)\n# Select the cross-compile PORT\nif (CMAKE_CROSSCOMPILING)\n  set(FREERTOS_PORT \"GCC_ARM_CA9\" CACHE STRING \"\" FORCE)\nendif()\n\nFetchContent_MakeAvailable(freertos_kernel)\n```\n\n- In case of cross compilation, you should also add the following to `freertos_config`:\n\n```cmake\ntarget_compile_definitions(freertos_config INTERFACE ${definitions})\ntarget_compile_options(freertos_config INTERFACE ${options})\n```\n\n### Consuming stand-alone - Cloning this repository\n\nTo clone using HTTPS:\n\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n```\n\nUsing SSH:\n\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS-Kernel.git\n```\n\n## Repository structure\n\n- The root of this repository contains the three files that are common to\nevery port - list.c, queue.c and tasks.c.  The kernel is contained within these\nthree files.  croutine.c implements the optional co-routine functionality - which\nis normally only used on very memory limited systems.\n\n- The ```./portable``` directory contains the files that are specific to a particular microcontroller and/or compiler.\nSee the readme file in the ```./portable``` directory for more information.\n\n- The ```./include``` directory contains the real time kernel header files.\n\n- The ```./template_configuration``` directory contains a sample `FreeRTOSConfig.h` to help jumpstart a new project.\nSee the [FreeRTOSConfig.h](examples/template_configuration/FreeRTOSConfig.h) file for instructions.\n\n### Code Formatting\n\nFreeRTOS files are formatted using the\n\"[uncrustify](https://github.com/uncrustify/uncrustify)\" tool.\nThe configuration file used by uncrustify can be found in the\n[FreeRTOS/CI-CD-GitHub-Actions's](https://github.com/FreeRTOS/CI-CD-Github-Actions)\n[uncrustify.cfg](https://github.com/FreeRTOS/CI-CD-Github-Actions/tree/main/formatting)\nfile.\n\n### Line Endings\n\nFile checked into the FreeRTOS-Kernel repository use unix-style LF line endings\nfor the best compatibility with git.\n\nFor optimal compatibility with Microsoft Windows tools, it is best to enable\nthe git autocrlf feature. You can enable this setting for the current\nrepository using the following command:\n\n```\ngit config core.autocrlf true\n```\n\n### Git History Optimizations\n\nSome commits in this repository perform large refactors which touch many lines\nand lead to unwanted behavior when using the `git blame` command. You can\nconfigure git to ignore the list of large refactor commits in this repository\nwith the following command:\n\n```\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```\n\n### Spelling and Formatting\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com),\ncommonly referred to as VSCode, when working on the FreeRTOS-Kernel.\nThe FreeRTOS-Kernel also uses [cSpell](https://cspell.org/) as part of its\nspelling check. The config file for which can be found at [cspell.config.yaml](cspell.config.yaml)\nThere is additionally a\n[cSpell plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)\nthat can be used as well.\n*[.cSpellWords.txt](.github/.cSpellWords.txt)* contains words that are not\ntraditionally found in an English dictionary. It is used by the spellchecker\nto verify the various jargon, variable names, and other odd words used in the\nFreeRTOS code base are correct. If your pull request fails to pass the spelling\nand you believe this is a mistake, then add the word to\n*[.cSpellWords.txt](.github/.cSpellWords.txt)*. When adding a word please\nthen sort the list, which can be done by running the bash command:\n`sort -u .cSpellWords.txt -o .cSpellWords.txt`\nNote that only the FreeRTOS-Kernel Source Files, [include](include),\n[portable/MemMang](portable/MemMang), and [portable/Common](portable/Common)\nfiles are checked for proper spelling, and formatting at this time.\n\n## Third Party Tools\nVisit [this link](.github/third_party_tools.md) for detailed information about\nthird-party tools with FreeRTOS support.\n"
        },
        {
          "name": "croutine.c",
          "type": "blob",
          "size": 16.994140625,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"croutine.h\"\n\n/* Remove the whole file if co-routines are not being used. */\n#if ( configUSE_CO_ROUTINES != 0 )\n\n/*\n * Some kernel aware debuggers require data to be viewed to be global, rather\n * than file scope.\n */\n    #ifdef portREMOVE_STATIC_QUALIFIER\n        #define static\n    #endif\n\n\n/* Lists for ready and blocked co-routines. --------------------*/\n    static List_t pxReadyCoRoutineLists[ configMAX_CO_ROUTINE_PRIORITIES ]; /**< Prioritised ready co-routines. */\n    static List_t xDelayedCoRoutineList1;                                   /**< Delayed co-routines. */\n    static List_t xDelayedCoRoutineList2;                                   /**< Delayed co-routines (two lists are used - one for delays that have overflowed the current tick count. */\n    static List_t * pxDelayedCoRoutineList = NULL;                          /**< Points to the delayed co-routine list currently being used. */\n    static List_t * pxOverflowDelayedCoRoutineList = NULL;                  /**< Points to the delayed co-routine list currently being used to hold co-routines that have overflowed the current tick count. */\n    static List_t xPendingReadyCoRoutineList;                               /**< Holds co-routines that have been readied by an external event.  They cannot be added directly to the ready lists as the ready lists cannot be accessed by interrupts. */\n\n/* Other file private variables. --------------------------------*/\n    CRCB_t * pxCurrentCoRoutine = NULL;\n    static UBaseType_t uxTopCoRoutineReadyPriority = ( UBaseType_t ) 0U;\n    static TickType_t xCoRoutineTickCount = ( TickType_t ) 0U;\n    static TickType_t xLastTickCount = ( TickType_t ) 0U;\n    static TickType_t xPassedTicks = ( TickType_t ) 0U;\n\n/* The initial state of the co-routine when it is created. */\n    #define corINITIAL_STATE    ( 0 )\n\n/*\n * Place the co-routine represented by pxCRCB into the appropriate ready queue\n * for the priority.  It is inserted at the end of the list.\n *\n * This macro accesses the co-routine ready lists and therefore must not be\n * used from within an ISR.\n */\n    #define prvAddCoRoutineToReadyQueue( pxCRCB )                                                                               \\\n    do {                                                                                                                        \\\n        if( ( pxCRCB )->uxPriority > uxTopCoRoutineReadyPriority )                                                              \\\n        {                                                                                                                       \\\n            uxTopCoRoutineReadyPriority = ( pxCRCB )->uxPriority;                                                               \\\n        }                                                                                                                       \\\n        vListInsertEnd( ( List_t * ) &( pxReadyCoRoutineLists[ ( pxCRCB )->uxPriority ] ), &( ( pxCRCB )->xGenericListItem ) ); \\\n    } while( 0 )\n\n/*\n * Utility to ready all the lists used by the scheduler.  This is called\n * automatically upon the creation of the first co-routine.\n */\n    static void prvInitialiseCoRoutineLists( void );\n\n/*\n * Co-routines that are readied by an interrupt cannot be placed directly into\n * the ready lists (there is no mutual exclusion).  Instead they are placed in\n * in the pending ready list in order that they can later be moved to the ready\n * list by the co-routine scheduler.\n */\n    static void prvCheckPendingReadyList( void );\n\n/*\n * Macro that looks at the list of co-routines that are currently delayed to\n * see if any require waking.\n *\n * Co-routines are stored in the queue in the order of their wake time -\n * meaning once one co-routine has been found whose timer has not expired\n * we need not look any further down the list.\n */\n    static void prvCheckDelayedList( void );\n\n/*-----------------------------------------------------------*/\n\n    BaseType_t xCoRoutineCreate( crCOROUTINE_CODE pxCoRoutineCode,\n                                 UBaseType_t uxPriority,\n                                 UBaseType_t uxIndex )\n    {\n        BaseType_t xReturn;\n        CRCB_t * pxCoRoutine;\n\n        traceENTER_xCoRoutineCreate( pxCoRoutineCode, uxPriority, uxIndex );\n\n        /* Allocate the memory that will store the co-routine control block. */\n        /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        pxCoRoutine = ( CRCB_t * ) pvPortMalloc( sizeof( CRCB_t ) );\n\n        if( pxCoRoutine )\n        {\n            /* If pxCurrentCoRoutine is NULL then this is the first co-routine to\n            * be created and the co-routine data structures need initialising. */\n            if( pxCurrentCoRoutine == NULL )\n            {\n                pxCurrentCoRoutine = pxCoRoutine;\n                prvInitialiseCoRoutineLists();\n            }\n\n            /* Check the priority is within limits. */\n            if( uxPriority >= configMAX_CO_ROUTINE_PRIORITIES )\n            {\n                uxPriority = configMAX_CO_ROUTINE_PRIORITIES - 1;\n            }\n\n            /* Fill out the co-routine control block from the function parameters. */\n            pxCoRoutine->uxState = corINITIAL_STATE;\n            pxCoRoutine->uxPriority = uxPriority;\n            pxCoRoutine->uxIndex = uxIndex;\n            pxCoRoutine->pxCoRoutineFunction = pxCoRoutineCode;\n\n            /* Initialise all the other co-routine control block parameters. */\n            vListInitialiseItem( &( pxCoRoutine->xGenericListItem ) );\n            vListInitialiseItem( &( pxCoRoutine->xEventListItem ) );\n\n            /* Set the co-routine control block as a link back from the ListItem_t.\n             * This is so we can get back to the containing CRCB from a generic item\n             * in a list. */\n            listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xGenericListItem ), pxCoRoutine );\n            listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xEventListItem ), pxCoRoutine );\n\n            /* Event lists are always in priority order. */\n            listSET_LIST_ITEM_VALUE( &( pxCoRoutine->xEventListItem ), ( ( TickType_t ) configMAX_CO_ROUTINE_PRIORITIES - ( TickType_t ) uxPriority ) );\n\n            /* Now the co-routine has been initialised it can be added to the ready\n             * list at the correct priority. */\n            prvAddCoRoutineToReadyQueue( pxCoRoutine );\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n        }\n\n        traceRETURN_xCoRoutineCreate( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    void vCoRoutineAddToDelayedList( TickType_t xTicksToDelay,\n                                     List_t * pxEventList )\n    {\n        TickType_t xTimeToWake;\n\n        traceENTER_vCoRoutineAddToDelayedList( xTicksToDelay, pxEventList );\n\n        /* Calculate the time to wake - this may overflow but this is\n         * not a problem. */\n        xTimeToWake = xCoRoutineTickCount + xTicksToDelay;\n\n        /* We must remove ourselves from the ready list before adding\n         * ourselves to the blocked list as the same list item is used for\n         * both lists. */\n        ( void ) uxListRemove( ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );\n\n        /* The list item will be inserted in wake time order. */\n        listSET_LIST_ITEM_VALUE( &( pxCurrentCoRoutine->xGenericListItem ), xTimeToWake );\n\n        if( xTimeToWake < xCoRoutineTickCount )\n        {\n            /* Wake time has overflowed.  Place this item in the\n             * overflow list. */\n            vListInsert( ( List_t * ) pxOverflowDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );\n        }\n        else\n        {\n            /* The wake time has not overflowed, so we can use the\n             * current block list. */\n            vListInsert( ( List_t * ) pxDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );\n        }\n\n        if( pxEventList )\n        {\n            /* Also add the co-routine to an event list.  If this is done then the\n             * function must be called with interrupts disabled. */\n            vListInsert( pxEventList, &( pxCurrentCoRoutine->xEventListItem ) );\n        }\n\n        traceRETURN_vCoRoutineAddToDelayedList();\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvCheckPendingReadyList( void )\n    {\n        /* Are there any co-routines waiting to get moved to the ready list?  These\n         * are co-routines that have been readied by an ISR.  The ISR cannot access\n         * the ready lists itself. */\n        while( listLIST_IS_EMPTY( &xPendingReadyCoRoutineList ) == pdFALSE )\n        {\n            CRCB_t * pxUnblockedCRCB;\n\n            /* The pending ready list can be accessed by an ISR. */\n            portDISABLE_INTERRUPTS();\n            {\n                pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyCoRoutineList ) );\n                ( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );\n            }\n            portENABLE_INTERRUPTS();\n\n            ( void ) uxListRemove( &( pxUnblockedCRCB->xGenericListItem ) );\n            prvAddCoRoutineToReadyQueue( pxUnblockedCRCB );\n        }\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvCheckDelayedList( void )\n    {\n        CRCB_t * pxCRCB;\n\n        xPassedTicks = xTaskGetTickCount() - xLastTickCount;\n\n        while( xPassedTicks )\n        {\n            xCoRoutineTickCount++;\n            xPassedTicks--;\n\n            /* If the tick count has overflowed we need to swap the ready lists. */\n            if( xCoRoutineTickCount == 0 )\n            {\n                List_t * pxTemp;\n\n                /* Tick count has overflowed so we need to swap the delay lists.  If there are\n                 * any items in pxDelayedCoRoutineList here then there is an error! */\n                pxTemp = pxDelayedCoRoutineList;\n                pxDelayedCoRoutineList = pxOverflowDelayedCoRoutineList;\n                pxOverflowDelayedCoRoutineList = pxTemp;\n            }\n\n            /* See if this tick has made a timeout expire. */\n            while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )\n            {\n                pxCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedCoRoutineList );\n\n                if( xCoRoutineTickCount < listGET_LIST_ITEM_VALUE( &( pxCRCB->xGenericListItem ) ) )\n                {\n                    /* Timeout not yet expired. */\n                    break;\n                }\n\n                portDISABLE_INTERRUPTS();\n                {\n                    /* The event could have occurred just before this critical\n                     *  section.  If this is the case then the generic list item will\n                     *  have been moved to the pending ready list and the following\n                     *  line is still valid.  Also the pvContainer parameter will have\n                     *  been set to NULL so the following lines are also valid. */\n                    ( void ) uxListRemove( &( pxCRCB->xGenericListItem ) );\n\n                    /* Is the co-routine waiting on an event also? */\n                    if( pxCRCB->xEventListItem.pxContainer )\n                    {\n                        ( void ) uxListRemove( &( pxCRCB->xEventListItem ) );\n                    }\n                }\n                portENABLE_INTERRUPTS();\n\n                prvAddCoRoutineToReadyQueue( pxCRCB );\n            }\n        }\n\n        xLastTickCount = xCoRoutineTickCount;\n    }\n/*-----------------------------------------------------------*/\n\n    void vCoRoutineSchedule( void )\n    {\n        traceENTER_vCoRoutineSchedule();\n\n        /* Only run a co-routine after prvInitialiseCoRoutineLists() has been\n         * called.  prvInitialiseCoRoutineLists() is called automatically when a\n         * co-routine is created. */\n        if( pxDelayedCoRoutineList != NULL )\n        {\n            /* See if any co-routines readied by events need moving to the ready lists. */\n            prvCheckPendingReadyList();\n\n            /* See if any delayed co-routines have timed out. */\n            prvCheckDelayedList();\n\n            /* Find the highest priority queue that contains ready co-routines. */\n            while( listLIST_IS_EMPTY( &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) ) )\n            {\n                if( uxTopCoRoutineReadyPriority == 0 )\n                {\n                    /* No more co-routines to check. */\n                    return;\n                }\n\n                --uxTopCoRoutineReadyPriority;\n            }\n\n            /* listGET_OWNER_OF_NEXT_ENTRY walks through the list, so the co-routines\n             * of the same priority get an equal share of the processor time. */\n            listGET_OWNER_OF_NEXT_ENTRY( pxCurrentCoRoutine, &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) );\n\n            /* Call the co-routine. */\n            ( pxCurrentCoRoutine->pxCoRoutineFunction )( pxCurrentCoRoutine, pxCurrentCoRoutine->uxIndex );\n        }\n\n        traceRETURN_vCoRoutineSchedule();\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvInitialiseCoRoutineLists( void )\n    {\n        UBaseType_t uxPriority;\n\n        for( uxPriority = 0; uxPriority < configMAX_CO_ROUTINE_PRIORITIES; uxPriority++ )\n        {\n            vListInitialise( ( List_t * ) &( pxReadyCoRoutineLists[ uxPriority ] ) );\n        }\n\n        vListInitialise( ( List_t * ) &xDelayedCoRoutineList1 );\n        vListInitialise( ( List_t * ) &xDelayedCoRoutineList2 );\n        vListInitialise( ( List_t * ) &xPendingReadyCoRoutineList );\n\n        /* Start with pxDelayedCoRoutineList using list1 and the\n         * pxOverflowDelayedCoRoutineList using list2. */\n        pxDelayedCoRoutineList = &xDelayedCoRoutineList1;\n        pxOverflowDelayedCoRoutineList = &xDelayedCoRoutineList2;\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xCoRoutineRemoveFromEventList( const List_t * pxEventList )\n    {\n        CRCB_t * pxUnblockedCRCB;\n        BaseType_t xReturn;\n\n        traceENTER_xCoRoutineRemoveFromEventList( pxEventList );\n\n        /* This function is called from within an interrupt.  It can only access\n         * event lists and the pending ready list.  This function assumes that a\n         * check has already been made to ensure pxEventList is not empty. */\n        pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );\n        ( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );\n        vListInsertEnd( ( List_t * ) &( xPendingReadyCoRoutineList ), &( pxUnblockedCRCB->xEventListItem ) );\n\n        if( pxUnblockedCRCB->uxPriority >= pxCurrentCoRoutine->uxPriority )\n        {\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n\n        traceRETURN_xCoRoutineRemoveFromEventList( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n/*\n * Reset state in this file. This state is normally initialized at start up.\n * This function must be called by the application before restarting the\n * scheduler.\n */\n    void vCoRoutineResetState( void )\n    {\n        /* Lists for ready and blocked co-routines. */\n        pxDelayedCoRoutineList = NULL;\n        pxOverflowDelayedCoRoutineList = NULL;\n\n        /* Other file private variables. */\n        pxCurrentCoRoutine = NULL;\n        uxTopCoRoutineReadyPriority = ( UBaseType_t ) 0U;\n        xCoRoutineTickCount = ( TickType_t ) 0U;\n        xLastTickCount = ( TickType_t ) 0U;\n        xPassedTicks = ( TickType_t ) 0U;\n    }\n/*-----------------------------------------------------------*/\n\n#endif /* configUSE_CO_ROUTINES == 0 */\n"
        },
        {
          "name": "cspell.config.yaml",
          "type": "blob",
          "size": 0.64453125,
          "content": "---\n$schema: https://raw.githubusercontent.com/streetsidesoftware/cspell/main/cspell.schema.json\nversion: '0.2'\n# Allows things like stringLength\nallowCompoundWords: true\n\n# Read files not to spell check from the git ignore\nuseGitignore: true\n\n#  Language settings for C\nlanguageSettings:\n  - caseSensitive: false\n    enabled: true\n    languageId: c\n    locale: \"*\"\n\n# Add a dictionary, and the path to the word list\ndictionaryDefinitions:\n  - name: freertos-words\n    path: '.github/.cSpellWords.txt'\n    addWords: true\n\ndictionaries:\n  - freertos-words\n\n# Paths and files to ignore\nignorePaths:\n  - 'dependency'\n  - 'docs'\n  - 'ThirdParty'\n  - 'History.txt'\n"
        },
        {
          "name": "event_groups.c",
          "type": "blob",
          "size": 35.1826171875,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n/* Standard includes. */\n#include <stdlib.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers. That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"timers.h\"\n#include \"event_groups.h\"\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined\n * for the header files above, but not in this file, in order to generate the\n * correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* This entire source file will be skipped if the application is not configured\n * to include event groups functionality. This #if is closed at the very bottom\n * of this file. If you want to include event groups then ensure\n * configUSE_EVENT_GROUPS is set to 1 in FreeRTOSConfig.h. */\n#if ( configUSE_EVENT_GROUPS == 1 )\n\n    typedef struct EventGroupDef_t\n    {\n        EventBits_t uxEventBits;\n        List_t xTasksWaitingForBits; /**< List of tasks waiting for a bit to be set. */\n\n        #if ( configUSE_TRACE_FACILITY == 1 )\n            UBaseType_t uxEventGroupNumber;\n        #endif\n\n        #if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n            uint8_t ucStaticallyAllocated; /**< Set to pdTRUE if the event group is statically allocated to ensure no attempt is made to free the memory. */\n        #endif\n    } EventGroup_t;\n\n/*-----------------------------------------------------------*/\n\n/*\n * Test the bits set in uxCurrentEventBits to see if the wait condition is met.\n * The wait condition is defined by xWaitForAllBits.  If xWaitForAllBits is\n * pdTRUE then the wait condition is met if all the bits set in uxBitsToWaitFor\n * are also set in uxCurrentEventBits.  If xWaitForAllBits is pdFALSE then the\n * wait condition is met if any of the bits set in uxBitsToWait for are also set\n * in uxCurrentEventBits.\n */\n    static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits,\n                                            const EventBits_t uxBitsToWaitFor,\n                                            const BaseType_t xWaitForAllBits ) PRIVILEGED_FUNCTION;\n\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n        EventGroupHandle_t xEventGroupCreateStatic( StaticEventGroup_t * pxEventGroupBuffer )\n        {\n            EventGroup_t * pxEventBits;\n\n            traceENTER_xEventGroupCreateStatic( pxEventGroupBuffer );\n\n            /* A StaticEventGroup_t object must be provided. */\n            configASSERT( pxEventGroupBuffer );\n\n            #if ( configASSERT_DEFINED == 1 )\n            {\n                /* Sanity check that the size of the structure used to declare a\n                 * variable of type StaticEventGroup_t equals the size of the real\n                 * event group structure. */\n                volatile size_t xSize = sizeof( StaticEventGroup_t );\n                configASSERT( xSize == sizeof( EventGroup_t ) );\n            }\n            #endif /* configASSERT_DEFINED */\n\n            /* The user has provided a statically allocated event group - use it. */\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            pxEventBits = ( EventGroup_t * ) pxEventGroupBuffer;\n\n            if( pxEventBits != NULL )\n            {\n                pxEventBits->uxEventBits = 0;\n                vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );\n\n                #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n                {\n                    /* Both static and dynamic allocation can be used, so note that\n                     * this event group was created statically in case the event group\n                     * is later deleted. */\n                    pxEventBits->ucStaticallyAllocated = pdTRUE;\n                }\n                #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n                traceEVENT_GROUP_CREATE( pxEventBits );\n            }\n            else\n            {\n                /* xEventGroupCreateStatic should only ever be called with\n                 * pxEventGroupBuffer pointing to a pre-allocated (compile time\n                 * allocated) StaticEventGroup_t variable. */\n                traceEVENT_GROUP_CREATE_FAILED();\n            }\n\n            traceRETURN_xEventGroupCreateStatic( pxEventBits );\n\n            return pxEventBits;\n        }\n\n    #endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n\n        EventGroupHandle_t xEventGroupCreate( void )\n        {\n            EventGroup_t * pxEventBits;\n\n            traceENTER_xEventGroupCreate();\n\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxEventBits = ( EventGroup_t * ) pvPortMalloc( sizeof( EventGroup_t ) );\n\n            if( pxEventBits != NULL )\n            {\n                pxEventBits->uxEventBits = 0;\n                vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );\n\n                #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n                {\n                    /* Both static and dynamic allocation can be used, so note this\n                     * event group was allocated statically in case the event group is\n                     * later deleted. */\n                    pxEventBits->ucStaticallyAllocated = pdFALSE;\n                }\n                #endif /* configSUPPORT_STATIC_ALLOCATION */\n\n                traceEVENT_GROUP_CREATE( pxEventBits );\n            }\n            else\n            {\n                traceEVENT_GROUP_CREATE_FAILED();\n            }\n\n            traceRETURN_xEventGroupCreate( pxEventBits );\n\n            return pxEventBits;\n        }\n\n    #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup,\n                                 const EventBits_t uxBitsToSet,\n                                 const EventBits_t uxBitsToWaitFor,\n                                 TickType_t xTicksToWait )\n    {\n        EventBits_t uxOriginalBitValue, uxReturn;\n        EventGroup_t * pxEventBits = xEventGroup;\n        BaseType_t xAlreadyYielded;\n        BaseType_t xTimeoutOccurred = pdFALSE;\n\n        traceENTER_xEventGroupSync( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTicksToWait );\n\n        configASSERT( ( uxBitsToWaitFor & eventEVENT_BITS_CONTROL_BYTES ) == 0 );\n        configASSERT( uxBitsToWaitFor != 0 );\n        #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n        {\n            configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n        }\n        #endif\n\n        vTaskSuspendAll();\n        {\n            uxOriginalBitValue = pxEventBits->uxEventBits;\n\n            ( void ) xEventGroupSetBits( xEventGroup, uxBitsToSet );\n\n            if( ( ( uxOriginalBitValue | uxBitsToSet ) & uxBitsToWaitFor ) == uxBitsToWaitFor )\n            {\n                /* All the rendezvous bits are now set - no need to block. */\n                uxReturn = ( uxOriginalBitValue | uxBitsToSet );\n\n                /* Rendezvous always clear the bits.  They will have been cleared\n                 * already unless this is the only task in the rendezvous. */\n                pxEventBits->uxEventBits &= ~uxBitsToWaitFor;\n\n                xTicksToWait = 0;\n            }\n            else\n            {\n                if( xTicksToWait != ( TickType_t ) 0 )\n                {\n                    traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor );\n\n                    /* Store the bits that the calling task is waiting for in the\n                     * task's event list item so the kernel knows when a match is\n                     * found.  Then enter the blocked state. */\n                    vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | eventCLEAR_EVENTS_ON_EXIT_BIT | eventWAIT_FOR_ALL_BITS ), xTicksToWait );\n\n                    /* This assignment is obsolete as uxReturn will get set after\n                     * the task unblocks, but some compilers mistakenly generate a\n                     * warning about uxReturn being returned without being set if the\n                     * assignment is omitted. */\n                    uxReturn = 0;\n                }\n                else\n                {\n                    /* The rendezvous bits were not set, but no block time was\n                     * specified - just return the current event bit value. */\n                    uxReturn = pxEventBits->uxEventBits;\n                    xTimeoutOccurred = pdTRUE;\n                }\n            }\n        }\n        xAlreadyYielded = xTaskResumeAll();\n\n        if( xTicksToWait != ( TickType_t ) 0 )\n        {\n            if( xAlreadyYielded == pdFALSE )\n            {\n                taskYIELD_WITHIN_API();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* The task blocked to wait for its required bits to be set - at this\n             * point either the required bits were set or the block time expired.  If\n             * the required bits were set they will have been stored in the task's\n             * event list item, and they should now be retrieved then cleared. */\n            uxReturn = uxTaskResetEventItemValue();\n\n            if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )\n            {\n                /* The task timed out, just return the current event bit value. */\n                taskENTER_CRITICAL();\n                {\n                    uxReturn = pxEventBits->uxEventBits;\n\n                    /* Although the task got here because it timed out before the\n                     * bits it was waiting for were set, it is possible that since it\n                     * unblocked another task has set the bits.  If this is the case\n                     * then it needs to clear the bits before exiting. */\n                    if( ( uxReturn & uxBitsToWaitFor ) == uxBitsToWaitFor )\n                    {\n                        pxEventBits->uxEventBits &= ~uxBitsToWaitFor;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                xTimeoutOccurred = pdTRUE;\n            }\n            else\n            {\n                /* The task unblocked because the bits were set. */\n            }\n\n            /* Control bits might be set as the task had blocked should not be\n             * returned. */\n            uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;\n        }\n\n        traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred );\n\n        /* Prevent compiler warnings when trace macros are not used. */\n        ( void ) xTimeoutOccurred;\n\n        traceRETURN_xEventGroupSync( uxReturn );\n\n        return uxReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup,\n                                     const EventBits_t uxBitsToWaitFor,\n                                     const BaseType_t xClearOnExit,\n                                     const BaseType_t xWaitForAllBits,\n                                     TickType_t xTicksToWait )\n    {\n        EventGroup_t * pxEventBits = xEventGroup;\n        EventBits_t uxReturn, uxControlBits = 0;\n        BaseType_t xWaitConditionMet, xAlreadyYielded;\n        BaseType_t xTimeoutOccurred = pdFALSE;\n\n        traceENTER_xEventGroupWaitBits( xEventGroup, uxBitsToWaitFor, xClearOnExit, xWaitForAllBits, xTicksToWait );\n\n        /* Check the user is not attempting to wait on the bits used by the kernel\n         * itself, and that at least one bit is being requested. */\n        configASSERT( xEventGroup );\n        configASSERT( ( uxBitsToWaitFor & eventEVENT_BITS_CONTROL_BYTES ) == 0 );\n        configASSERT( uxBitsToWaitFor != 0 );\n        #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n        {\n            configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n        }\n        #endif\n\n        vTaskSuspendAll();\n        {\n            const EventBits_t uxCurrentEventBits = pxEventBits->uxEventBits;\n\n            /* Check to see if the wait condition is already met or not. */\n            xWaitConditionMet = prvTestWaitCondition( uxCurrentEventBits, uxBitsToWaitFor, xWaitForAllBits );\n\n            if( xWaitConditionMet != pdFALSE )\n            {\n                /* The wait condition has already been met so there is no need to\n                 * block. */\n                uxReturn = uxCurrentEventBits;\n                xTicksToWait = ( TickType_t ) 0;\n\n                /* Clear the wait bits if requested to do so. */\n                if( xClearOnExit != pdFALSE )\n                {\n                    pxEventBits->uxEventBits &= ~uxBitsToWaitFor;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else if( xTicksToWait == ( TickType_t ) 0 )\n            {\n                /* The wait condition has not been met, but no block time was\n                 * specified, so just return the current value. */\n                uxReturn = uxCurrentEventBits;\n                xTimeoutOccurred = pdTRUE;\n            }\n            else\n            {\n                /* The task is going to block to wait for its required bits to be\n                 * set.  uxControlBits are used to remember the specified behaviour of\n                 * this call to xEventGroupWaitBits() - for use when the event bits\n                 * unblock the task. */\n                if( xClearOnExit != pdFALSE )\n                {\n                    uxControlBits |= eventCLEAR_EVENTS_ON_EXIT_BIT;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                if( xWaitForAllBits != pdFALSE )\n                {\n                    uxControlBits |= eventWAIT_FOR_ALL_BITS;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                /* Store the bits that the calling task is waiting for in the\n                 * task's event list item so the kernel knows when a match is\n                 * found.  Then enter the blocked state. */\n                vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | uxControlBits ), xTicksToWait );\n\n                /* This is obsolete as it will get set after the task unblocks, but\n                 * some compilers mistakenly generate a warning about the variable\n                 * being returned without being set if it is not done. */\n                uxReturn = 0;\n\n                traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );\n            }\n        }\n        xAlreadyYielded = xTaskResumeAll();\n\n        if( xTicksToWait != ( TickType_t ) 0 )\n        {\n            if( xAlreadyYielded == pdFALSE )\n            {\n                taskYIELD_WITHIN_API();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* The task blocked to wait for its required bits to be set - at this\n             * point either the required bits were set or the block time expired.  If\n             * the required bits were set they will have been stored in the task's\n             * event list item, and they should now be retrieved then cleared. */\n            uxReturn = uxTaskResetEventItemValue();\n\n            if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )\n            {\n                taskENTER_CRITICAL();\n                {\n                    /* The task timed out, just return the current event bit value. */\n                    uxReturn = pxEventBits->uxEventBits;\n\n                    /* It is possible that the event bits were updated between this\n                     * task leaving the Blocked state and running again. */\n                    if( prvTestWaitCondition( uxReturn, uxBitsToWaitFor, xWaitForAllBits ) != pdFALSE )\n                    {\n                        if( xClearOnExit != pdFALSE )\n                        {\n                            pxEventBits->uxEventBits &= ~uxBitsToWaitFor;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    xTimeoutOccurred = pdTRUE;\n                }\n                taskEXIT_CRITICAL();\n            }\n            else\n            {\n                /* The task unblocked because the bits were set. */\n            }\n\n            /* The task blocked so control bits may have been set. */\n            uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;\n        }\n\n        traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred );\n\n        /* Prevent compiler warnings when trace macros are not used. */\n        ( void ) xTimeoutOccurred;\n\n        traceRETURN_xEventGroupWaitBits( uxReturn );\n\n        return uxReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    EventBits_t xEventGroupClearBits( EventGroupHandle_t xEventGroup,\n                                      const EventBits_t uxBitsToClear )\n    {\n        EventGroup_t * pxEventBits = xEventGroup;\n        EventBits_t uxReturn;\n\n        traceENTER_xEventGroupClearBits( xEventGroup, uxBitsToClear );\n\n        /* Check the user is not attempting to clear the bits used by the kernel\n         * itself. */\n        configASSERT( xEventGroup );\n        configASSERT( ( uxBitsToClear & eventEVENT_BITS_CONTROL_BYTES ) == 0 );\n\n        taskENTER_CRITICAL();\n        {\n            traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear );\n\n            /* The value returned is the event group value prior to the bits being\n             * cleared. */\n            uxReturn = pxEventBits->uxEventBits;\n\n            /* Clear the bits. */\n            pxEventBits->uxEventBits &= ~uxBitsToClear;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xEventGroupClearBits( uxReturn );\n\n        return uxReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( INCLUDE_xTimerPendFunctionCall == 1 ) && ( configUSE_TIMERS == 1 ) )\n\n        BaseType_t xEventGroupClearBitsFromISR( EventGroupHandle_t xEventGroup,\n                                                const EventBits_t uxBitsToClear )\n        {\n            BaseType_t xReturn;\n\n            traceENTER_xEventGroupClearBitsFromISR( xEventGroup, uxBitsToClear );\n\n            traceEVENT_GROUP_CLEAR_BITS_FROM_ISR( xEventGroup, uxBitsToClear );\n            xReturn = xTimerPendFunctionCallFromISR( vEventGroupClearBitsCallback, ( void * ) xEventGroup, ( uint32_t ) uxBitsToClear, NULL );\n\n            traceRETURN_xEventGroupClearBitsFromISR( xReturn );\n\n            return xReturn;\n        }\n\n    #endif /* if ( ( configUSE_TRACE_FACILITY == 1 ) && ( INCLUDE_xTimerPendFunctionCall == 1 ) && ( configUSE_TIMERS == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n    EventBits_t xEventGroupGetBitsFromISR( EventGroupHandle_t xEventGroup )\n    {\n        UBaseType_t uxSavedInterruptStatus;\n        EventGroup_t const * const pxEventBits = xEventGroup;\n        EventBits_t uxReturn;\n\n        traceENTER_xEventGroupGetBitsFromISR( xEventGroup );\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n        {\n            uxReturn = pxEventBits->uxEventBits;\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_xEventGroupGetBitsFromISR( uxReturn );\n\n        return uxReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup,\n                                    const EventBits_t uxBitsToSet )\n    {\n        ListItem_t * pxListItem;\n        ListItem_t * pxNext;\n        ListItem_t const * pxListEnd;\n        List_t const * pxList;\n        EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits, uxReturnBits;\n        EventGroup_t * pxEventBits = xEventGroup;\n        BaseType_t xMatchFound = pdFALSE;\n\n        traceENTER_xEventGroupSetBits( xEventGroup, uxBitsToSet );\n\n        /* Check the user is not attempting to set the bits used by the kernel\n         * itself. */\n        configASSERT( xEventGroup );\n        configASSERT( ( uxBitsToSet & eventEVENT_BITS_CONTROL_BYTES ) == 0 );\n\n        pxList = &( pxEventBits->xTasksWaitingForBits );\n        pxListEnd = listGET_END_MARKER( pxList );\n        vTaskSuspendAll();\n        {\n            traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet );\n\n            pxListItem = listGET_HEAD_ENTRY( pxList );\n\n            /* Set the bits. */\n            pxEventBits->uxEventBits |= uxBitsToSet;\n\n            /* See if the new bit value should unblock any tasks. */\n            while( pxListItem != pxListEnd )\n            {\n                pxNext = listGET_NEXT( pxListItem );\n                uxBitsWaitedFor = listGET_LIST_ITEM_VALUE( pxListItem );\n                xMatchFound = pdFALSE;\n\n                /* Split the bits waited for from the control bits. */\n                uxControlBits = uxBitsWaitedFor & eventEVENT_BITS_CONTROL_BYTES;\n                uxBitsWaitedFor &= ~eventEVENT_BITS_CONTROL_BYTES;\n\n                if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )\n                {\n                    /* Just looking for single bit being set. */\n                    if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )\n                    {\n                        xMatchFound = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) == uxBitsWaitedFor )\n                {\n                    /* All bits are set. */\n                    xMatchFound = pdTRUE;\n                }\n                else\n                {\n                    /* Need all bits to be set, but not all the bits were set. */\n                }\n\n                if( xMatchFound != pdFALSE )\n                {\n                    /* The bits match.  Should the bits be cleared on exit? */\n                    if( ( uxControlBits & eventCLEAR_EVENTS_ON_EXIT_BIT ) != ( EventBits_t ) 0 )\n                    {\n                        uxBitsToClear |= uxBitsWaitedFor;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* Store the actual event flag value in the task's event list\n                     * item before removing the task from the event list.  The\n                     * eventUNBLOCKED_DUE_TO_BIT_SET bit is set so the task knows\n                     * that is was unblocked due to its required bits matching, rather\n                     * than because it timed out. */\n                    vTaskRemoveFromUnorderedEventList( pxListItem, pxEventBits->uxEventBits | eventUNBLOCKED_DUE_TO_BIT_SET );\n                }\n\n                /* Move onto the next list item.  Note pxListItem->pxNext is not\n                 * used here as the list item may have been removed from the event list\n                 * and inserted into the ready/pending reading list. */\n                pxListItem = pxNext;\n            }\n\n            /* Clear any bits that matched when the eventCLEAR_EVENTS_ON_EXIT_BIT\n             * bit was set in the control word. */\n            pxEventBits->uxEventBits &= ~uxBitsToClear;\n\n            /* Snapshot resulting bits. */\n            uxReturnBits = pxEventBits->uxEventBits;\n        }\n        ( void ) xTaskResumeAll();\n\n        traceRETURN_xEventGroupSetBits( uxReturnBits );\n\n        return uxReturnBits;\n    }\n/*-----------------------------------------------------------*/\n\n    void vEventGroupDelete( EventGroupHandle_t xEventGroup )\n    {\n        EventGroup_t * pxEventBits = xEventGroup;\n        const List_t * pxTasksWaitingForBits;\n\n        traceENTER_vEventGroupDelete( xEventGroup );\n\n        configASSERT( pxEventBits );\n\n        pxTasksWaitingForBits = &( pxEventBits->xTasksWaitingForBits );\n\n        vTaskSuspendAll();\n        {\n            traceEVENT_GROUP_DELETE( xEventGroup );\n\n            while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )\n            {\n                /* Unblock the task, returning 0 as the event list is being deleted\n                 * and cannot therefore have any bits set. */\n                configASSERT( pxTasksWaitingForBits->xListEnd.pxNext != ( const ListItem_t * ) &( pxTasksWaitingForBits->xListEnd ) );\n                vTaskRemoveFromUnorderedEventList( pxTasksWaitingForBits->xListEnd.pxNext, eventUNBLOCKED_DUE_TO_BIT_SET );\n            }\n        }\n        ( void ) xTaskResumeAll();\n\n        #if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )\n        {\n            /* The event group can only have been allocated dynamically - free\n             * it again. */\n            vPortFree( pxEventBits );\n        }\n        #elif ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n        {\n            /* The event group could have been allocated statically or\n             * dynamically, so check before attempting to free the memory. */\n            if( pxEventBits->ucStaticallyAllocated == ( uint8_t ) pdFALSE )\n            {\n                vPortFree( pxEventBits );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n        traceRETURN_vEventGroupDelete();\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n        BaseType_t xEventGroupGetStaticBuffer( EventGroupHandle_t xEventGroup,\n                                               StaticEventGroup_t ** ppxEventGroupBuffer )\n        {\n            BaseType_t xReturn;\n            EventGroup_t * pxEventBits = xEventGroup;\n\n            traceENTER_xEventGroupGetStaticBuffer( xEventGroup, ppxEventGroupBuffer );\n\n            configASSERT( pxEventBits );\n            configASSERT( ppxEventGroupBuffer );\n\n            #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n            {\n                /* Check if the event group was statically allocated. */\n                if( pxEventBits->ucStaticallyAllocated == ( uint8_t ) pdTRUE )\n                {\n                    /* MISRA Ref 11.3.1 [Misaligned access] */\n                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n                    /* coverity[misra_c_2012_rule_11_3_violation] */\n                    *ppxEventGroupBuffer = ( StaticEventGroup_t * ) pxEventBits;\n                    xReturn = pdTRUE;\n                }\n                else\n                {\n                    xReturn = pdFALSE;\n                }\n            }\n            #else /* configSUPPORT_DYNAMIC_ALLOCATION */\n            {\n                /* Event group must have been statically allocated. */\n                /* MISRA Ref 11.3.1 [Misaligned access] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n                /* coverity[misra_c_2012_rule_11_3_violation] */\n                *ppxEventGroupBuffer = ( StaticEventGroup_t * ) pxEventBits;\n                xReturn = pdTRUE;\n            }\n            #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n            traceRETURN_xEventGroupGetStaticBuffer( xReturn );\n\n            return xReturn;\n        }\n    #endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n/* For internal use only - execute a 'set bits' command that was pended from\n * an interrupt. */\n    void vEventGroupSetBitsCallback( void * pvEventGroup,\n                                     uint32_t ulBitsToSet )\n    {\n        traceENTER_vEventGroupSetBitsCallback( pvEventGroup, ulBitsToSet );\n\n        /* MISRA Ref 11.5.4 [Callback function parameter] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        ( void ) xEventGroupSetBits( pvEventGroup, ( EventBits_t ) ulBitsToSet );\n\n        traceRETURN_vEventGroupSetBitsCallback();\n    }\n/*-----------------------------------------------------------*/\n\n/* For internal use only - execute a 'clear bits' command that was pended from\n * an interrupt. */\n    void vEventGroupClearBitsCallback( void * pvEventGroup,\n                                       uint32_t ulBitsToClear )\n    {\n        traceENTER_vEventGroupClearBitsCallback( pvEventGroup, ulBitsToClear );\n\n        /* MISRA Ref 11.5.4 [Callback function parameter] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        ( void ) xEventGroupClearBits( pvEventGroup, ( EventBits_t ) ulBitsToClear );\n\n        traceRETURN_vEventGroupClearBitsCallback();\n    }\n/*-----------------------------------------------------------*/\n\n    static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits,\n                                            const EventBits_t uxBitsToWaitFor,\n                                            const BaseType_t xWaitForAllBits )\n    {\n        BaseType_t xWaitConditionMet = pdFALSE;\n\n        if( xWaitForAllBits == pdFALSE )\n        {\n            /* Task only has to wait for one bit within uxBitsToWaitFor to be\n             * set.  Is one already set? */\n            if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )\n            {\n                xWaitConditionMet = pdTRUE;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            /* Task has to wait for all the bits in uxBitsToWaitFor to be set.\n             * Are they set already? */\n            if( ( uxCurrentEventBits & uxBitsToWaitFor ) == uxBitsToWaitFor )\n            {\n                xWaitConditionMet = pdTRUE;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        return xWaitConditionMet;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( INCLUDE_xTimerPendFunctionCall == 1 ) && ( configUSE_TIMERS == 1 ) )\n\n        BaseType_t xEventGroupSetBitsFromISR( EventGroupHandle_t xEventGroup,\n                                              const EventBits_t uxBitsToSet,\n                                              BaseType_t * pxHigherPriorityTaskWoken )\n        {\n            BaseType_t xReturn;\n\n            traceENTER_xEventGroupSetBitsFromISR( xEventGroup, uxBitsToSet, pxHigherPriorityTaskWoken );\n\n            traceEVENT_GROUP_SET_BITS_FROM_ISR( xEventGroup, uxBitsToSet );\n            xReturn = xTimerPendFunctionCallFromISR( vEventGroupSetBitsCallback, ( void * ) xEventGroup, ( uint32_t ) uxBitsToSet, pxHigherPriorityTaskWoken );\n\n            traceRETURN_xEventGroupSetBitsFromISR( xReturn );\n\n            return xReturn;\n        }\n\n    #endif /* if ( ( configUSE_TRACE_FACILITY == 1 ) && ( INCLUDE_xTimerPendFunctionCall == 1 ) && ( configUSE_TIMERS == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n        UBaseType_t uxEventGroupGetNumber( void * xEventGroup )\n        {\n            UBaseType_t xReturn;\n\n            /* MISRA Ref 11.5.2 [Opaque pointer] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            EventGroup_t const * pxEventBits = ( EventGroup_t * ) xEventGroup;\n\n            traceENTER_uxEventGroupGetNumber( xEventGroup );\n\n            if( xEventGroup == NULL )\n            {\n                xReturn = 0;\n            }\n            else\n            {\n                xReturn = pxEventBits->uxEventGroupNumber;\n            }\n\n            traceRETURN_uxEventGroupGetNumber( xReturn );\n\n            return xReturn;\n        }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n        void vEventGroupSetNumber( void * xEventGroup,\n                                   UBaseType_t uxEventGroupNumber )\n        {\n            traceENTER_vEventGroupSetNumber( xEventGroup, uxEventGroupNumber );\n\n            /* MISRA Ref 11.5.2 [Opaque pointer] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            ( ( EventGroup_t * ) xEventGroup )->uxEventGroupNumber = uxEventGroupNumber;\n\n            traceRETURN_vEventGroupSetNumber();\n        }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n/* This entire source file will be skipped if the application is not configured\n * to include event groups functionality. If you want to include event groups\n * then ensure configUSE_EVENT_GROUPS is set to 1 in FreeRTOSConfig.h. */\n#endif /* configUSE_EVENT_GROUPS == 1 */\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "list.c",
          "type": "blob",
          "size": 9.916015625,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n\n#include <stdlib.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers.  That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n#include \"FreeRTOS.h\"\n#include \"list.h\"\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be\n * defined for the header files above, but not in this file, in order to\n * generate the correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/*-----------------------------------------------------------\n* PUBLIC LIST API documented in list.h\n*----------------------------------------------------------*/\n\nvoid vListInitialise( List_t * const pxList )\n{\n    traceENTER_vListInitialise( pxList );\n\n    /* The list structure contains a list item which is used to mark the\n     * end of the list.  To initialise the list the list end is inserted\n     * as the only list entry. */\n    pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );\n\n    listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( &( pxList->xListEnd ) );\n\n    /* The list end value is the highest possible value in the list to\n     * ensure it remains at the end of the list. */\n    pxList->xListEnd.xItemValue = portMAX_DELAY;\n\n    /* The list end next and previous pointers point to itself so we know\n     * when the list is empty. */\n    pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );\n    pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );\n\n    /* Initialize the remaining fields of xListEnd when it is a proper ListItem_t */\n    #if ( configUSE_MINI_LIST_ITEM == 0 )\n    {\n        pxList->xListEnd.pvOwner = NULL;\n        pxList->xListEnd.pxContainer = NULL;\n        listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( &( pxList->xListEnd ) );\n    }\n    #endif\n\n    pxList->uxNumberOfItems = ( UBaseType_t ) 0U;\n\n    /* Write known values into the list if\n     * configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */\n    listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList );\n    listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList );\n\n    traceRETURN_vListInitialise();\n}\n/*-----------------------------------------------------------*/\n\nvoid vListInitialiseItem( ListItem_t * const pxItem )\n{\n    traceENTER_vListInitialiseItem( pxItem );\n\n    /* Make sure the list item is not recorded as being on a list. */\n    pxItem->pxContainer = NULL;\n\n    /* Write known values into the list item if\n     * configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */\n    listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );\n    listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );\n\n    traceRETURN_vListInitialiseItem();\n}\n/*-----------------------------------------------------------*/\n\nvoid vListInsertEnd( List_t * const pxList,\n                     ListItem_t * const pxNewListItem )\n{\n    ListItem_t * const pxIndex = pxList->pxIndex;\n\n    traceENTER_vListInsertEnd( pxList, pxNewListItem );\n\n    /* Only effective when configASSERT() is also defined, these tests may catch\n     * the list data structures being overwritten in memory.  They will not catch\n     * data errors caused by incorrect configuration or use of FreeRTOS. */\n    listTEST_LIST_INTEGRITY( pxList );\n    listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );\n\n    /* Insert a new list item into pxList, but rather than sort the list,\n     * makes the new list item the last item to be removed by a call to\n     * listGET_OWNER_OF_NEXT_ENTRY(). */\n    pxNewListItem->pxNext = pxIndex;\n    pxNewListItem->pxPrevious = pxIndex->pxPrevious;\n\n    /* Only used during decision coverage testing. */\n    mtCOVERAGE_TEST_DELAY();\n\n    pxIndex->pxPrevious->pxNext = pxNewListItem;\n    pxIndex->pxPrevious = pxNewListItem;\n\n    /* Remember which list the item is in. */\n    pxNewListItem->pxContainer = pxList;\n\n    ( pxList->uxNumberOfItems ) = ( UBaseType_t ) ( pxList->uxNumberOfItems + 1U );\n\n    traceRETURN_vListInsertEnd();\n}\n/*-----------------------------------------------------------*/\n\nvoid vListInsert( List_t * const pxList,\n                  ListItem_t * const pxNewListItem )\n{\n    ListItem_t * pxIterator;\n    const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;\n\n    traceENTER_vListInsert( pxList, pxNewListItem );\n\n    /* Only effective when configASSERT() is also defined, these tests may catch\n     * the list data structures being overwritten in memory.  They will not catch\n     * data errors caused by incorrect configuration or use of FreeRTOS. */\n    listTEST_LIST_INTEGRITY( pxList );\n    listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );\n\n    /* Insert the new list item into the list, sorted in xItemValue order.\n     *\n     * If the list already contains a list item with the same item value then the\n     * new list item should be placed after it.  This ensures that TCBs which are\n     * stored in ready lists (all of which have the same xItemValue value) get a\n     * share of the CPU.  However, if the xItemValue is the same as the back marker\n     * the iteration loop below will not end.  Therefore the value is checked\n     * first, and the algorithm slightly modified if necessary. */\n    if( xValueOfInsertion == portMAX_DELAY )\n    {\n        pxIterator = pxList->xListEnd.pxPrevious;\n    }\n    else\n    {\n        /* *** NOTE ***********************************************************\n        *  If you find your application is crashing here then likely causes are\n        *  listed below.  In addition see https://www.freertos.org/Why-FreeRTOS/FAQs for\n        *  more tips, and ensure configASSERT() is defined!\n        *  https://www.FreeRTOS.org/a00110.html#configASSERT\n        *\n        *   1) Stack overflow -\n        *      see https://www.FreeRTOS.org/Stacks-and-stack-overflow-checking.html\n        *   2) Incorrect interrupt priority assignment, especially on Cortex-M\n        *      parts where numerically high priority values denote low actual\n        *      interrupt priorities, which can seem counter intuitive.  See\n        *      https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html and the definition\n        *      of configMAX_SYSCALL_INTERRUPT_PRIORITY on\n        *      https://www.FreeRTOS.org/a00110.html\n        *   3) Calling an API function from within a critical section or when\n        *      the scheduler is suspended, or calling an API function that does\n        *      not end in \"FromISR\" from an interrupt.\n        *   4) Using a queue or semaphore before it has been initialised or\n        *      before the scheduler has been started (are interrupts firing\n        *      before vTaskStartScheduler() has been called?).\n        *   5) If the FreeRTOS port supports interrupt nesting then ensure that\n        *      the priority of the tick interrupt is at or below\n        *      configMAX_SYSCALL_INTERRUPT_PRIORITY.\n        **********************************************************************/\n\n        for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext )\n        {\n            /* There is nothing to do here, just iterating to the wanted\n             * insertion position.\n             * IF YOU FIND YOUR CODE STUCK HERE, SEE THE NOTE JUST ABOVE.\n             */\n        }\n    }\n\n    pxNewListItem->pxNext = pxIterator->pxNext;\n    pxNewListItem->pxNext->pxPrevious = pxNewListItem;\n    pxNewListItem->pxPrevious = pxIterator;\n    pxIterator->pxNext = pxNewListItem;\n\n    /* Remember which list the item is in.  This allows fast removal of the\n     * item later. */\n    pxNewListItem->pxContainer = pxList;\n\n    ( pxList->uxNumberOfItems ) = ( UBaseType_t ) ( pxList->uxNumberOfItems + 1U );\n\n    traceRETURN_vListInsert();\n}\n/*-----------------------------------------------------------*/\n\n\nUBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )\n{\n    /* The list item knows which list it is in.  Obtain the list from the list\n     * item. */\n    List_t * const pxList = pxItemToRemove->pxContainer;\n\n    traceENTER_uxListRemove( pxItemToRemove );\n\n    pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;\n    pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;\n\n    /* Only used during decision coverage testing. */\n    mtCOVERAGE_TEST_DELAY();\n\n    /* Make sure the index is left pointing to a valid item. */\n    if( pxList->pxIndex == pxItemToRemove )\n    {\n        pxList->pxIndex = pxItemToRemove->pxPrevious;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    pxItemToRemove->pxContainer = NULL;\n    ( pxList->uxNumberOfItems ) = ( UBaseType_t ) ( pxList->uxNumberOfItems - 1U );\n\n    traceRETURN_uxListRemove( pxList->uxNumberOfItems );\n\n    return pxList->uxNumberOfItems;\n}\n/*-----------------------------------------------------------*/\n"
        },
        {
          "name": "manifest.yml",
          "type": "blob",
          "size": 0.08984375,
          "content": "name : \"FreeRTOS-Kernel\"\nversion: \"V11.0.1+\"\ndescription: \"FreeRTOS Kernel.\"\nlicense: \"MIT\"\n"
        },
        {
          "name": "portable",
          "type": "tree",
          "content": null
        },
        {
          "name": "queue.c",
          "type": "blob",
          "size": 125.2236328125,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n#include <stdlib.h>\n#include <string.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers.  That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"queue.h\"\n\n#if ( configUSE_CO_ROUTINES == 1 )\n    #include \"croutine.h\"\n#endif\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined\n * for the header files above, but not in this file, in order to generate the\n * correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n\n/* Constants used with the cRxLock and cTxLock structure members. */\n#define queueUNLOCKED             ( ( int8_t ) -1 )\n#define queueLOCKED_UNMODIFIED    ( ( int8_t ) 0 )\n#define queueINT8_MAX             ( ( int8_t ) 127 )\n\n/* When the Queue_t structure is used to represent a base queue its pcHead and\n * pcTail members are used as pointers into the queue storage area.  When the\n * Queue_t structure is used to represent a mutex pcHead and pcTail pointers are\n * not necessary, and the pcHead pointer is set to NULL to indicate that the\n * structure instead holds a pointer to the mutex holder (if any).  Map alternative\n * names to the pcHead and structure member to ensure the readability of the code\n * is maintained.  The QueuePointers_t and SemaphoreData_t types are used to form\n * a union as their usage is mutually exclusive dependent on what the queue is\n * being used for. */\n#define uxQueueType               pcHead\n#define queueQUEUE_IS_MUTEX       NULL\n\ntypedef struct QueuePointers\n{\n    int8_t * pcTail;     /**< Points to the byte at the end of the queue storage area.  Once more byte is allocated than necessary to store the queue items, this is used as a marker. */\n    int8_t * pcReadFrom; /**< Points to the last place that a queued item was read from when the structure is used as a queue. */\n} QueuePointers_t;\n\ntypedef struct SemaphoreData\n{\n    TaskHandle_t xMutexHolder;        /**< The handle of the task that holds the mutex. */\n    UBaseType_t uxRecursiveCallCount; /**< Maintains a count of the number of times a recursive mutex has been recursively 'taken' when the structure is used as a mutex. */\n} SemaphoreData_t;\n\n/* Semaphores do not actually store or copy data, so have an item size of\n * zero. */\n#define queueSEMAPHORE_QUEUE_ITEM_LENGTH    ( ( UBaseType_t ) 0 )\n#define queueMUTEX_GIVE_BLOCK_TIME          ( ( TickType_t ) 0U )\n\n#if ( configUSE_PREEMPTION == 0 )\n\n/* If the cooperative scheduler is being used then a yield should not be\n * performed just because a higher priority task has been woken. */\n    #define queueYIELD_IF_USING_PREEMPTION()\n#else\n    #if ( configNUMBER_OF_CORES == 1 )\n        #define queueYIELD_IF_USING_PREEMPTION()    portYIELD_WITHIN_API()\n    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n        #define queueYIELD_IF_USING_PREEMPTION()    vTaskYieldWithinAPI()\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n#endif\n\n/*\n * Definition of the queue used by the scheduler.\n * Items are queued by copy, not reference.  See the following link for the\n * rationale: https://www.FreeRTOS.org/Embedded-RTOS-Queues.html\n */\ntypedef struct QueueDefinition /* The old naming convention is used to prevent breaking kernel aware debuggers. */\n{\n    int8_t * pcHead;           /**< Points to the beginning of the queue storage area. */\n    int8_t * pcWriteTo;        /**< Points to the free next place in the storage area. */\n\n    union\n    {\n        QueuePointers_t xQueue;     /**< Data required exclusively when this structure is used as a queue. */\n        SemaphoreData_t xSemaphore; /**< Data required exclusively when this structure is used as a semaphore. */\n    } u;\n\n    List_t xTasksWaitingToSend;             /**< List of tasks that are blocked waiting to post onto this queue.  Stored in priority order. */\n    List_t xTasksWaitingToReceive;          /**< List of tasks that are blocked waiting to read from this queue.  Stored in priority order. */\n\n    volatile UBaseType_t uxMessagesWaiting; /**< The number of items currently in the queue. */\n    UBaseType_t uxLength;                   /**< The length of the queue defined as the number of items it will hold, not the number of bytes. */\n    UBaseType_t uxItemSize;                 /**< The size of each items that the queue will hold. */\n\n    volatile int8_t cRxLock;                /**< Stores the number of items received from the queue (removed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */\n    volatile int8_t cTxLock;                /**< Stores the number of items transmitted to the queue (added to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */\n\n    #if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n        uint8_t ucStaticallyAllocated; /**< Set to pdTRUE if the memory used by the queue was statically allocated to ensure no attempt is made to free the memory. */\n    #endif\n\n    #if ( configUSE_QUEUE_SETS == 1 )\n        struct QueueDefinition * pxQueueSetContainer;\n    #endif\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n        UBaseType_t uxQueueNumber;\n        uint8_t ucQueueType;\n    #endif\n} xQUEUE;\n\n/* The old xQUEUE name is maintained above then typedefed to the new Queue_t\n * name below to enable the use of older kernel aware debuggers. */\ntypedef xQUEUE Queue_t;\n\n/*-----------------------------------------------------------*/\n\n/*\n * The queue registry is just a means for kernel aware debuggers to locate\n * queue structures.  It has no other purpose so is an optional component.\n */\n#if ( configQUEUE_REGISTRY_SIZE > 0 )\n\n/* The type stored within the queue registry array.  This allows a name\n * to be assigned to each queue making kernel aware debugging a little\n * more user friendly. */\n    typedef struct QUEUE_REGISTRY_ITEM\n    {\n        const char * pcQueueName;\n        QueueHandle_t xHandle;\n    } xQueueRegistryItem;\n\n/* The old xQueueRegistryItem name is maintained above then typedefed to the\n * new xQueueRegistryItem name below to enable the use of older kernel aware\n * debuggers. */\n    typedef xQueueRegistryItem QueueRegistryItem_t;\n\n/* The queue registry is simply an array of QueueRegistryItem_t structures.\n * The pcQueueName member of a structure being NULL is indicative of the\n * array position being vacant. */\n\n/* MISRA Ref 8.4.2 [Declaration shall be visible] */\n/* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-84 */\n/* coverity[misra_c_2012_rule_8_4_violation] */\n    PRIVILEGED_DATA QueueRegistryItem_t xQueueRegistry[ configQUEUE_REGISTRY_SIZE ];\n\n#endif /* configQUEUE_REGISTRY_SIZE */\n\n/*\n * Unlocks a queue locked by a call to prvLockQueue.  Locking a queue does not\n * prevent an ISR from adding or removing items to the queue, but does prevent\n * an ISR from removing tasks from the queue event lists.  If an ISR finds a\n * queue is locked it will instead increment the appropriate queue lock count\n * to indicate that a task may require unblocking.  When the queue in unlocked\n * these lock counts are inspected, and the appropriate action taken.\n */\nstatic void prvUnlockQueue( Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;\n\n/*\n * Uses a critical section to determine if there is any data in a queue.\n *\n * @return pdTRUE if the queue contains no items, otherwise pdFALSE.\n */\nstatic BaseType_t prvIsQueueEmpty( const Queue_t * pxQueue ) PRIVILEGED_FUNCTION;\n\n/*\n * Uses a critical section to determine if there is any space in a queue.\n *\n * @return pdTRUE if there is no space, otherwise pdFALSE;\n */\nstatic BaseType_t prvIsQueueFull( const Queue_t * pxQueue ) PRIVILEGED_FUNCTION;\n\n/*\n * Copies an item into the queue, either at the front of the queue or the\n * back of the queue.\n */\nstatic BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue,\n                                      const void * pvItemToQueue,\n                                      const BaseType_t xPosition ) PRIVILEGED_FUNCTION;\n\n/*\n * Copies an item out of a queue.\n */\nstatic void prvCopyDataFromQueue( Queue_t * const pxQueue,\n                                  void * const pvBuffer ) PRIVILEGED_FUNCTION;\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n/*\n * Checks to see if a queue is a member of a queue set, and if so, notifies\n * the queue set that the queue contains data.\n */\n    static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;\n#endif\n\n/*\n * Called after a Queue_t structure has been allocated either statically or\n * dynamically to fill in the structure's members.\n */\nstatic void prvInitialiseNewQueue( const UBaseType_t uxQueueLength,\n                                   const UBaseType_t uxItemSize,\n                                   uint8_t * pucQueueStorage,\n                                   const uint8_t ucQueueType,\n                                   Queue_t * pxNewQueue ) PRIVILEGED_FUNCTION;\n\n/*\n * Mutexes are a special type of queue.  When a mutex is created, first the\n * queue is created, then prvInitialiseMutex() is called to configure the queue\n * as a mutex.\n */\n#if ( configUSE_MUTEXES == 1 )\n    static void prvInitialiseMutex( Queue_t * pxNewQueue ) PRIVILEGED_FUNCTION;\n#endif\n\n#if ( configUSE_MUTEXES == 1 )\n\n/*\n * If a task waiting for a mutex causes the mutex holder to inherit a\n * priority, but the waiting task times out, then the holder should\n * disinherit the priority - but only down to the highest priority of any\n * other tasks that are waiting for the same mutex.  This function returns\n * that priority.\n */\n    static UBaseType_t prvGetHighestPriorityOfWaitToReceiveList( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;\n#endif\n/*-----------------------------------------------------------*/\n\n/*\n * Macro to mark a queue as locked.  Locking a queue prevents an ISR from\n * accessing the queue event lists.\n */\n#define prvLockQueue( pxQueue )                            \\\n    taskENTER_CRITICAL();                                  \\\n    {                                                      \\\n        if( ( pxQueue )->cRxLock == queueUNLOCKED )        \\\n        {                                                  \\\n            ( pxQueue )->cRxLock = queueLOCKED_UNMODIFIED; \\\n        }                                                  \\\n        if( ( pxQueue )->cTxLock == queueUNLOCKED )        \\\n        {                                                  \\\n            ( pxQueue )->cTxLock = queueLOCKED_UNMODIFIED; \\\n        }                                                  \\\n    }                                                      \\\n    taskEXIT_CRITICAL()\n\n/*\n * Macro to increment cTxLock member of the queue data structure. It is\n * capped at the number of tasks in the system as we cannot unblock more\n * tasks than the number of tasks in the system.\n */\n#define prvIncrementQueueTxLock( pxQueue, cTxLock )                           \\\n    do {                                                                      \\\n        const UBaseType_t uxNumberOfTasks = uxTaskGetNumberOfTasks();         \\\n        if( ( UBaseType_t ) ( cTxLock ) < uxNumberOfTasks )                   \\\n        {                                                                     \\\n            configASSERT( ( cTxLock ) != queueINT8_MAX );                     \\\n            ( pxQueue )->cTxLock = ( int8_t ) ( ( cTxLock ) + ( int8_t ) 1 ); \\\n        }                                                                     \\\n    } while( 0 )\n\n/*\n * Macro to increment cRxLock member of the queue data structure. It is\n * capped at the number of tasks in the system as we cannot unblock more\n * tasks than the number of tasks in the system.\n */\n#define prvIncrementQueueRxLock( pxQueue, cRxLock )                           \\\n    do {                                                                      \\\n        const UBaseType_t uxNumberOfTasks = uxTaskGetNumberOfTasks();         \\\n        if( ( UBaseType_t ) ( cRxLock ) < uxNumberOfTasks )                   \\\n        {                                                                     \\\n            configASSERT( ( cRxLock ) != queueINT8_MAX );                     \\\n            ( pxQueue )->cRxLock = ( int8_t ) ( ( cRxLock ) + ( int8_t ) 1 ); \\\n        }                                                                     \\\n    } while( 0 )\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueGenericReset( QueueHandle_t xQueue,\n                               BaseType_t xNewQueue )\n{\n    BaseType_t xReturn = pdPASS;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueGenericReset( xQueue, xNewQueue );\n\n    configASSERT( pxQueue );\n\n    if( ( pxQueue != NULL ) &&\n        ( pxQueue->uxLength >= 1U ) &&\n        /* Check for multiplication overflow. */\n        ( ( SIZE_MAX / pxQueue->uxLength ) >= pxQueue->uxItemSize ) )\n    {\n        taskENTER_CRITICAL();\n        {\n            pxQueue->u.xQueue.pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );\n            pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;\n            pxQueue->pcWriteTo = pxQueue->pcHead;\n            pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - 1U ) * pxQueue->uxItemSize );\n            pxQueue->cRxLock = queueUNLOCKED;\n            pxQueue->cTxLock = queueUNLOCKED;\n\n            if( xNewQueue == pdFALSE )\n            {\n                /* If there are tasks blocked waiting to read from the queue, then\n                 * the tasks will remain blocked as after this function exits the queue\n                 * will still be empty.  If there are tasks blocked waiting to write to\n                 * the queue, then one should be unblocked as after this function exits\n                 * it will be possible to write to it. */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        queueYIELD_IF_USING_PREEMPTION();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* Ensure the event queues start in the correct state. */\n                vListInitialise( &( pxQueue->xTasksWaitingToSend ) );\n                vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );\n            }\n        }\n        taskEXIT_CRITICAL();\n    }\n    else\n    {\n        xReturn = pdFAIL;\n    }\n\n    configASSERT( xReturn != pdFAIL );\n\n    /* A value is returned for calling semantic consistency with previous\n     * versions. */\n    traceRETURN_xQueueGenericReset( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n    QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength,\n                                             const UBaseType_t uxItemSize,\n                                             uint8_t * pucQueueStorage,\n                                             StaticQueue_t * pxStaticQueue,\n                                             const uint8_t ucQueueType )\n    {\n        Queue_t * pxNewQueue = NULL;\n\n        traceENTER_xQueueGenericCreateStatic( uxQueueLength, uxItemSize, pucQueueStorage, pxStaticQueue, ucQueueType );\n\n        /* The StaticQueue_t structure and the queue storage area must be\n         * supplied. */\n        configASSERT( pxStaticQueue );\n\n        if( ( uxQueueLength > ( UBaseType_t ) 0 ) &&\n            ( pxStaticQueue != NULL ) &&\n\n            /* A queue storage area should be provided if the item size is not 0, and\n             * should not be provided if the item size is 0. */\n            ( !( ( pucQueueStorage != NULL ) && ( uxItemSize == 0U ) ) ) &&\n            ( !( ( pucQueueStorage == NULL ) && ( uxItemSize != 0U ) ) ) )\n        {\n            #if ( configASSERT_DEFINED == 1 )\n            {\n                /* Sanity check that the size of the structure used to declare a\n                 * variable of type StaticQueue_t or StaticSemaphore_t equals the size of\n                 * the real queue and semaphore structures. */\n                volatile size_t xSize = sizeof( StaticQueue_t );\n\n                /* This assertion cannot be branch covered in unit tests */\n                configASSERT( xSize == sizeof( Queue_t ) ); /* LCOV_EXCL_BR_LINE */\n                ( void ) xSize;                             /* Prevent unused variable warning when configASSERT() is not defined. */\n            }\n            #endif /* configASSERT_DEFINED */\n\n            /* The address of a statically allocated queue was passed in, use it.\n             * The address of a statically allocated storage area was also passed in\n             * but is already set. */\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            pxNewQueue = ( Queue_t * ) pxStaticQueue;\n\n            #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n            {\n                /* Queues can be allocated either statically or dynamically, so\n                 * note this queue was allocated statically in case the queue is\n                 * later deleted. */\n                pxNewQueue->ucStaticallyAllocated = pdTRUE;\n            }\n            #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n            prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );\n        }\n        else\n        {\n            configASSERT( pxNewQueue );\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xQueueGenericCreateStatic( pxNewQueue );\n\n        return pxNewQueue;\n    }\n\n#endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n    BaseType_t xQueueGenericGetStaticBuffers( QueueHandle_t xQueue,\n                                              uint8_t ** ppucQueueStorage,\n                                              StaticQueue_t ** ppxStaticQueue )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_xQueueGenericGetStaticBuffers( xQueue, ppucQueueStorage, ppxStaticQueue );\n\n        configASSERT( pxQueue );\n        configASSERT( ppxStaticQueue );\n\n        #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n        {\n            /* Check if the queue was statically allocated. */\n            if( pxQueue->ucStaticallyAllocated == ( uint8_t ) pdTRUE )\n            {\n                if( ppucQueueStorage != NULL )\n                {\n                    *ppucQueueStorage = ( uint8_t * ) pxQueue->pcHead;\n                }\n\n                /* MISRA Ref 11.3.1 [Misaligned access] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n                /* coverity[misra_c_2012_rule_11_3_violation] */\n                *ppxStaticQueue = ( StaticQueue_t * ) pxQueue;\n                xReturn = pdTRUE;\n            }\n            else\n            {\n                xReturn = pdFALSE;\n            }\n        }\n        #else /* configSUPPORT_DYNAMIC_ALLOCATION */\n        {\n            /* Queue must have been statically allocated. */\n            if( ppucQueueStorage != NULL )\n            {\n                *ppucQueueStorage = ( uint8_t * ) pxQueue->pcHead;\n            }\n\n            *ppxStaticQueue = ( StaticQueue_t * ) pxQueue;\n            xReturn = pdTRUE;\n        }\n        #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n        traceRETURN_xQueueGenericGetStaticBuffers( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n\n    QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength,\n                                       const UBaseType_t uxItemSize,\n                                       const uint8_t ucQueueType )\n    {\n        Queue_t * pxNewQueue = NULL;\n        size_t xQueueSizeInBytes;\n        uint8_t * pucQueueStorage;\n\n        traceENTER_xQueueGenericCreate( uxQueueLength, uxItemSize, ucQueueType );\n\n        if( ( uxQueueLength > ( UBaseType_t ) 0 ) &&\n            /* Check for multiplication overflow. */\n            ( ( SIZE_MAX / uxQueueLength ) >= uxItemSize ) &&\n            /* Check for addition overflow. */\n            ( ( SIZE_MAX - sizeof( Queue_t ) ) >= ( size_t ) ( uxQueueLength * uxItemSize ) ) )\n        {\n            /* Allocate enough space to hold the maximum number of items that\n             * can be in the queue at any time.  It is valid for uxItemSize to be\n             * zero in the case the queue is used as a semaphore. */\n            xQueueSizeInBytes = ( size_t ) ( ( size_t ) uxQueueLength * ( size_t ) uxItemSize );\n\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );\n\n            if( pxNewQueue != NULL )\n            {\n                /* Jump past the queue structure to find the location of the queue\n                 * storage area. */\n                pucQueueStorage = ( uint8_t * ) pxNewQueue;\n                pucQueueStorage += sizeof( Queue_t );\n\n                #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n                {\n                    /* Queues can be created either statically or dynamically, so\n                     * note this task was created dynamically in case it is later\n                     * deleted. */\n                    pxNewQueue->ucStaticallyAllocated = pdFALSE;\n                }\n                #endif /* configSUPPORT_STATIC_ALLOCATION */\n\n                prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );\n            }\n            else\n            {\n                traceQUEUE_CREATE_FAILED( ucQueueType );\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            configASSERT( pxNewQueue );\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xQueueGenericCreate( pxNewQueue );\n\n        return pxNewQueue;\n    }\n\n#endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\nstatic void prvInitialiseNewQueue( const UBaseType_t uxQueueLength,\n                                   const UBaseType_t uxItemSize,\n                                   uint8_t * pucQueueStorage,\n                                   const uint8_t ucQueueType,\n                                   Queue_t * pxNewQueue )\n{\n    /* Remove compiler warnings about unused parameters should\n     * configUSE_TRACE_FACILITY not be set to 1. */\n    ( void ) ucQueueType;\n\n    if( uxItemSize == ( UBaseType_t ) 0 )\n    {\n        /* No RAM was allocated for the queue storage area, but PC head cannot\n         * be set to NULL because NULL is used as a key to say the queue is used as\n         * a mutex.  Therefore just set pcHead to point to the queue as a benign\n         * value that is known to be within the memory map. */\n        pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;\n    }\n    else\n    {\n        /* Set the head to the start of the queue storage area. */\n        pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;\n    }\n\n    /* Initialise the queue members as described where the queue type is\n     * defined. */\n    pxNewQueue->uxLength = uxQueueLength;\n    pxNewQueue->uxItemSize = uxItemSize;\n    ( void ) xQueueGenericReset( pxNewQueue, pdTRUE );\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n    {\n        pxNewQueue->ucQueueType = ucQueueType;\n    }\n    #endif /* configUSE_TRACE_FACILITY */\n\n    #if ( configUSE_QUEUE_SETS == 1 )\n    {\n        pxNewQueue->pxQueueSetContainer = NULL;\n    }\n    #endif /* configUSE_QUEUE_SETS */\n\n    traceQUEUE_CREATE( pxNewQueue );\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    static void prvInitialiseMutex( Queue_t * pxNewQueue )\n    {\n        if( pxNewQueue != NULL )\n        {\n            /* The queue create function will set all the queue structure members\n            * correctly for a generic queue, but this function is creating a\n            * mutex.  Overwrite those members that need to be set differently -\n            * in particular the information required for priority inheritance. */\n            pxNewQueue->u.xSemaphore.xMutexHolder = NULL;\n            pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;\n\n            /* In case this is a recursive mutex. */\n            pxNewQueue->u.xSemaphore.uxRecursiveCallCount = 0;\n\n            traceCREATE_MUTEX( pxNewQueue );\n\n            /* Start with the semaphore in the expected state. */\n            ( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );\n        }\n        else\n        {\n            traceCREATE_MUTEX_FAILED();\n        }\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n\n    QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )\n    {\n        QueueHandle_t xNewQueue;\n        const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;\n\n        traceENTER_xQueueCreateMutex( ucQueueType );\n\n        xNewQueue = xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );\n        prvInitialiseMutex( ( Queue_t * ) xNewQueue );\n\n        traceRETURN_xQueueCreateMutex( xNewQueue );\n\n        return xNewQueue;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n\n    QueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType,\n                                           StaticQueue_t * pxStaticQueue )\n    {\n        QueueHandle_t xNewQueue;\n        const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;\n\n        traceENTER_xQueueCreateMutexStatic( ucQueueType, pxStaticQueue );\n\n        /* Prevent compiler warnings about unused parameters if\n         * configUSE_TRACE_FACILITY does not equal 1. */\n        ( void ) ucQueueType;\n\n        xNewQueue = xQueueGenericCreateStatic( uxMutexLength, uxMutexSize, NULL, pxStaticQueue, ucQueueType );\n        prvInitialiseMutex( ( Queue_t * ) xNewQueue );\n\n        traceRETURN_xQueueCreateMutexStatic( xNewQueue );\n\n        return xNewQueue;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )\n\n    TaskHandle_t xQueueGetMutexHolder( QueueHandle_t xSemaphore )\n    {\n        TaskHandle_t pxReturn;\n        Queue_t * const pxSemaphore = ( Queue_t * ) xSemaphore;\n\n        traceENTER_xQueueGetMutexHolder( xSemaphore );\n\n        configASSERT( xSemaphore );\n\n        /* This function is called by xSemaphoreGetMutexHolder(), and should not\n         * be called directly.  Note:  This is a good way of determining if the\n         * calling task is the mutex holder, but not a good way of determining the\n         * identity of the mutex holder, as the holder may change between the\n         * following critical section exiting and the function returning. */\n        taskENTER_CRITICAL();\n        {\n            if( pxSemaphore->uxQueueType == queueQUEUE_IS_MUTEX )\n            {\n                pxReturn = pxSemaphore->u.xSemaphore.xMutexHolder;\n            }\n            else\n            {\n                pxReturn = NULL;\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xQueueGetMutexHolder( pxReturn );\n\n        return pxReturn;\n    }\n\n#endif /* if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )\n\n    TaskHandle_t xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore )\n    {\n        TaskHandle_t pxReturn;\n\n        traceENTER_xQueueGetMutexHolderFromISR( xSemaphore );\n\n        configASSERT( xSemaphore );\n\n        /* Mutexes cannot be used in interrupt service routines, so the mutex\n         * holder should not change in an ISR, and therefore a critical section is\n         * not required here. */\n        if( ( ( Queue_t * ) xSemaphore )->uxQueueType == queueQUEUE_IS_MUTEX )\n        {\n            pxReturn = ( ( Queue_t * ) xSemaphore )->u.xSemaphore.xMutexHolder;\n        }\n        else\n        {\n            pxReturn = NULL;\n        }\n\n        traceRETURN_xQueueGetMutexHolderFromISR( pxReturn );\n\n        return pxReturn;\n    }\n\n#endif /* if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_RECURSIVE_MUTEXES == 1 )\n\n    BaseType_t xQueueGiveMutexRecursive( QueueHandle_t xMutex )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxMutex = ( Queue_t * ) xMutex;\n\n        traceENTER_xQueueGiveMutexRecursive( xMutex );\n\n        configASSERT( pxMutex );\n\n        /* If this is the task that holds the mutex then xMutexHolder will not\n         * change outside of this task.  If this task does not hold the mutex then\n         * pxMutexHolder can never coincidentally equal the tasks handle, and as\n         * this is the only condition we are interested in it does not matter if\n         * pxMutexHolder is accessed simultaneously by another task.  Therefore no\n         * mutual exclusion is required to test the pxMutexHolder variable. */\n        if( pxMutex->u.xSemaphore.xMutexHolder == xTaskGetCurrentTaskHandle() )\n        {\n            traceGIVE_MUTEX_RECURSIVE( pxMutex );\n\n            /* uxRecursiveCallCount cannot be zero if xMutexHolder is equal to\n             * the task handle, therefore no underflow check is required.  Also,\n             * uxRecursiveCallCount is only modified by the mutex holder, and as\n             * there can only be one, no mutual exclusion is required to modify the\n             * uxRecursiveCallCount member. */\n            ( pxMutex->u.xSemaphore.uxRecursiveCallCount )--;\n\n            /* Has the recursive call count unwound to 0? */\n            if( pxMutex->u.xSemaphore.uxRecursiveCallCount == ( UBaseType_t ) 0 )\n            {\n                /* Return the mutex.  This will automatically unblock any other\n                 * task that might be waiting to access the mutex. */\n                ( void ) xQueueGenericSend( pxMutex, NULL, queueMUTEX_GIVE_BLOCK_TIME, queueSEND_TO_BACK );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            /* The mutex cannot be given because the calling task is not the\n             * holder. */\n            xReturn = pdFAIL;\n\n            traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex );\n        }\n\n        traceRETURN_xQueueGiveMutexRecursive( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_RECURSIVE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_RECURSIVE_MUTEXES == 1 )\n\n    BaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex,\n                                         TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxMutex = ( Queue_t * ) xMutex;\n\n        traceENTER_xQueueTakeMutexRecursive( xMutex, xTicksToWait );\n\n        configASSERT( pxMutex );\n\n        /* Comments regarding mutual exclusion as per those within\n         * xQueueGiveMutexRecursive(). */\n\n        traceTAKE_MUTEX_RECURSIVE( pxMutex );\n\n        if( pxMutex->u.xSemaphore.xMutexHolder == xTaskGetCurrentTaskHandle() )\n        {\n            ( pxMutex->u.xSemaphore.uxRecursiveCallCount )++;\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = xQueueSemaphoreTake( pxMutex, xTicksToWait );\n\n            /* pdPASS will only be returned if the mutex was successfully\n             * obtained.  The calling task may have entered the Blocked state\n             * before reaching here. */\n            if( xReturn != pdFAIL )\n            {\n                ( pxMutex->u.xSemaphore.uxRecursiveCallCount )++;\n            }\n            else\n            {\n                traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex );\n            }\n        }\n\n        traceRETURN_xQueueTakeMutexRecursive( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_RECURSIVE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n\n    QueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount,\n                                                       const UBaseType_t uxInitialCount,\n                                                       StaticQueue_t * pxStaticQueue )\n    {\n        QueueHandle_t xHandle = NULL;\n\n        traceENTER_xQueueCreateCountingSemaphoreStatic( uxMaxCount, uxInitialCount, pxStaticQueue );\n\n        if( ( uxMaxCount != 0U ) &&\n            ( uxInitialCount <= uxMaxCount ) )\n        {\n            xHandle = xQueueGenericCreateStatic( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticQueue, queueQUEUE_TYPE_COUNTING_SEMAPHORE );\n\n            if( xHandle != NULL )\n            {\n                ( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;\n\n                traceCREATE_COUNTING_SEMAPHORE();\n            }\n            else\n            {\n                traceCREATE_COUNTING_SEMAPHORE_FAILED();\n            }\n        }\n        else\n        {\n            configASSERT( xHandle );\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xQueueCreateCountingSemaphoreStatic( xHandle );\n\n        return xHandle;\n    }\n\n#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n\n    QueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount,\n                                                 const UBaseType_t uxInitialCount )\n    {\n        QueueHandle_t xHandle = NULL;\n\n        traceENTER_xQueueCreateCountingSemaphore( uxMaxCount, uxInitialCount );\n\n        if( ( uxMaxCount != 0U ) &&\n            ( uxInitialCount <= uxMaxCount ) )\n        {\n            xHandle = xQueueGenericCreate( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_COUNTING_SEMAPHORE );\n\n            if( xHandle != NULL )\n            {\n                ( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;\n\n                traceCREATE_COUNTING_SEMAPHORE();\n            }\n            else\n            {\n                traceCREATE_COUNTING_SEMAPHORE_FAILED();\n            }\n        }\n        else\n        {\n            configASSERT( xHandle );\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xQueueCreateCountingSemaphore( xHandle );\n\n        return xHandle;\n    }\n\n#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueGenericSend( QueueHandle_t xQueue,\n                              const void * const pvItemToQueue,\n                              TickType_t xTicksToWait,\n                              const BaseType_t xCopyPosition )\n{\n    BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;\n    TimeOut_t xTimeOut;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueGenericSend( xQueue, pvItemToQueue, xTicksToWait, xCopyPosition );\n\n    configASSERT( pxQueue );\n    configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );\n    configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );\n    #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n    {\n        configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n    }\n    #endif\n\n    for( ; ; )\n    {\n        taskENTER_CRITICAL();\n        {\n            /* Is there room on the queue now?  The running task must be the\n             * highest priority task wanting to access the queue.  If the head item\n             * in the queue is to be overwritten then it does not matter if the\n             * queue is full. */\n            if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )\n            {\n                traceQUEUE_SEND( pxQueue );\n\n                #if ( configUSE_QUEUE_SETS == 1 )\n                {\n                    const UBaseType_t uxPreviousMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n                    xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );\n\n                    if( pxQueue->pxQueueSetContainer != NULL )\n                    {\n                        if( ( xCopyPosition == queueOVERWRITE ) && ( uxPreviousMessagesWaiting != ( UBaseType_t ) 0 ) )\n                        {\n                            /* Do not notify the queue set as an existing item\n                             * was overwritten in the queue so the number of items\n                             * in the queue has not changed. */\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                        else if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )\n                        {\n                            /* The queue is a member of a queue set, and posting\n                             * to the queue set caused a higher priority task to\n                             * unblock. A context switch is required. */\n                            queueYIELD_IF_USING_PREEMPTION();\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        /* If there was a task waiting for data to arrive on the\n                         * queue then unblock it now. */\n                        if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                        {\n                            if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                            {\n                                /* The unblocked task has a priority higher than\n                                 * our own so yield immediately.  Yes it is ok to\n                                 * do this from within the critical section - the\n                                 * kernel takes care of that. */\n                                queueYIELD_IF_USING_PREEMPTION();\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else if( xYieldRequired != pdFALSE )\n                        {\n                            /* This path is a special case that will only get\n                             * executed if the task was holding multiple mutexes\n                             * and the mutexes were given back in an order that is\n                             * different to that in which they were taken. */\n                            queueYIELD_IF_USING_PREEMPTION();\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                }\n                #else /* configUSE_QUEUE_SETS */\n                {\n                    xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );\n\n                    /* If there was a task waiting for data to arrive on the\n                     * queue then unblock it now. */\n                    if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                    {\n                        if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                        {\n                            /* The unblocked task has a priority higher than\n                             * our own so yield immediately.  Yes it is ok to do\n                             * this from within the critical section - the kernel\n                             * takes care of that. */\n                            queueYIELD_IF_USING_PREEMPTION();\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else if( xYieldRequired != pdFALSE )\n                    {\n                        /* This path is a special case that will only get\n                         * executed if the task was holding multiple mutexes and\n                         * the mutexes were given back in an order that is\n                         * different to that in which they were taken. */\n                        queueYIELD_IF_USING_PREEMPTION();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #endif /* configUSE_QUEUE_SETS */\n\n                taskEXIT_CRITICAL();\n\n                traceRETURN_xQueueGenericSend( pdPASS );\n\n                return pdPASS;\n            }\n            else\n            {\n                if( xTicksToWait == ( TickType_t ) 0 )\n                {\n                    /* The queue was full and no block time is specified (or\n                     * the block time has expired) so leave now. */\n                    taskEXIT_CRITICAL();\n\n                    /* Return to the original privilege level before exiting\n                     * the function. */\n                    traceQUEUE_SEND_FAILED( pxQueue );\n                    traceRETURN_xQueueGenericSend( errQUEUE_FULL );\n\n                    return errQUEUE_FULL;\n                }\n                else if( xEntryTimeSet == pdFALSE )\n                {\n                    /* The queue was full and a block time was specified so\n                     * configure the timeout structure. */\n                    vTaskInternalSetTimeOutState( &xTimeOut );\n                    xEntryTimeSet = pdTRUE;\n                }\n                else\n                {\n                    /* Entry time was already set. */\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        /* Interrupts and other tasks can send to and receive from the queue\n         * now the critical section has been exited. */\n\n        vTaskSuspendAll();\n        prvLockQueue( pxQueue );\n\n        /* Update the timeout state to see if it has expired yet. */\n        if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )\n        {\n            if( prvIsQueueFull( pxQueue ) != pdFALSE )\n            {\n                traceBLOCKING_ON_QUEUE_SEND( pxQueue );\n                vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );\n\n                /* Unlocking the queue means queue events can effect the\n                 * event list. It is possible that interrupts occurring now\n                 * remove this task from the event list again - but as the\n                 * scheduler is suspended the task will go onto the pending\n                 * ready list instead of the actual ready list. */\n                prvUnlockQueue( pxQueue );\n\n                /* Resuming the scheduler will move tasks from the pending\n                 * ready list into the ready list - so it is feasible that this\n                 * task is already in the ready list before it yields - in which\n                 * case the yield will not cause a context switch unless there\n                 * is also a higher priority task in the pending ready list. */\n                if( xTaskResumeAll() == pdFALSE )\n                {\n                    taskYIELD_WITHIN_API();\n                }\n            }\n            else\n            {\n                /* Try again. */\n                prvUnlockQueue( pxQueue );\n                ( void ) xTaskResumeAll();\n            }\n        }\n        else\n        {\n            /* The timeout has expired. */\n            prvUnlockQueue( pxQueue );\n            ( void ) xTaskResumeAll();\n\n            traceQUEUE_SEND_FAILED( pxQueue );\n            traceRETURN_xQueueGenericSend( errQUEUE_FULL );\n\n            return errQUEUE_FULL;\n        }\n    }\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue,\n                                     const void * const pvItemToQueue,\n                                     BaseType_t * const pxHigherPriorityTaskWoken,\n                                     const BaseType_t xCopyPosition )\n{\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueGenericSendFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken, xCopyPosition );\n\n    configASSERT( pxQueue );\n    configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );\n    configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );\n\n    /* RTOS ports that support interrupt nesting have the concept of a maximum\n     * system call (or maximum API call) interrupt priority.  Interrupts that are\n     * above the maximum system call priority are kept permanently enabled, even\n     * when the RTOS kernel is in a critical section, but cannot make any calls to\n     * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h\n     * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n     * failure if a FreeRTOS API function is called from an interrupt that has been\n     * assigned a priority above the configured maximum system call priority.\n     * Only FreeRTOS functions that end in FromISR can be called from interrupts\n     * that have been assigned a priority at or (logically) below the maximum\n     * system call interrupt priority.  FreeRTOS maintains a separate interrupt\n     * safe API to ensure interrupt entry is as fast and as simple as possible.\n     * More information (albeit Cortex-M specific) is provided on the following\n     * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n    portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n    /* Similar to xQueueGenericSend, except without blocking if there is no room\n     * in the queue.  Also don't directly wake a task that was blocked on a queue\n     * read, instead return a flag to say whether a context switch is required or\n     * not (i.e. has a task with a higher priority than us been woken by this\n     * post). */\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n    {\n        if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )\n        {\n            const int8_t cTxLock = pxQueue->cTxLock;\n            const UBaseType_t uxPreviousMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n            traceQUEUE_SEND_FROM_ISR( pxQueue );\n\n            /* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a\n             *  semaphore or mutex.  That means prvCopyDataToQueue() cannot result\n             *  in a task disinheriting a priority and prvCopyDataToQueue() can be\n             *  called here even though the disinherit function does not check if\n             *  the scheduler is suspended before accessing the ready lists. */\n            ( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );\n\n            /* The event list is not altered if the queue is locked.  This will\n             * be done when the queue is unlocked later. */\n            if( cTxLock == queueUNLOCKED )\n            {\n                #if ( configUSE_QUEUE_SETS == 1 )\n                {\n                    if( pxQueue->pxQueueSetContainer != NULL )\n                    {\n                        if( ( xCopyPosition == queueOVERWRITE ) && ( uxPreviousMessagesWaiting != ( UBaseType_t ) 0 ) )\n                        {\n                            /* Do not notify the queue set as an existing item\n                             * was overwritten in the queue so the number of items\n                             * in the queue has not changed. */\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                        else if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )\n                        {\n                            /* The queue is a member of a queue set, and posting\n                             * to the queue set caused a higher priority task to\n                             * unblock.  A context switch is required. */\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                        {\n                            if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                            {\n                                /* The task waiting has a higher priority so\n                                 *  record that a context switch is required. */\n                                if( pxHigherPriorityTaskWoken != NULL )\n                                {\n                                    *pxHigherPriorityTaskWoken = pdTRUE;\n                                }\n                                else\n                                {\n                                    mtCOVERAGE_TEST_MARKER();\n                                }\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                }\n                #else /* configUSE_QUEUE_SETS */\n                {\n                    if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                    {\n                        if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                        {\n                            /* The task waiting has a higher priority so record that a\n                             * context switch is required. */\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* Not used in this path. */\n                    ( void ) uxPreviousMessagesWaiting;\n                }\n                #endif /* configUSE_QUEUE_SETS */\n            }\n            else\n            {\n                /* Increment the lock count so the task that unlocks the queue\n                 * knows that data was posted while it was locked. */\n                prvIncrementQueueTxLock( pxQueue, cTxLock );\n            }\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );\n            xReturn = errQUEUE_FULL;\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xQueueGenericSendFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueGiveFromISR( QueueHandle_t xQueue,\n                              BaseType_t * const pxHigherPriorityTaskWoken )\n{\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueGiveFromISR( xQueue, pxHigherPriorityTaskWoken );\n\n    /* Similar to xQueueGenericSendFromISR() but used with semaphores where the\n     * item size is 0.  Don't directly wake a task that was blocked on a queue\n     * read, instead return a flag to say whether a context switch is required or\n     * not (i.e. has a task with a higher priority than us been woken by this\n     * post). */\n\n    configASSERT( pxQueue );\n\n    /* xQueueGenericSendFromISR() should be used instead of xQueueGiveFromISR()\n     * if the item size is not 0. */\n    configASSERT( pxQueue->uxItemSize == 0 );\n\n    /* Normally a mutex would not be given from an interrupt, especially if\n     * there is a mutex holder, as priority inheritance makes no sense for an\n     * interrupts, only tasks. */\n    configASSERT( !( ( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX ) && ( pxQueue->u.xSemaphore.xMutexHolder != NULL ) ) );\n\n    /* RTOS ports that support interrupt nesting have the concept of a maximum\n     * system call (or maximum API call) interrupt priority.  Interrupts that are\n     * above the maximum system call priority are kept permanently enabled, even\n     * when the RTOS kernel is in a critical section, but cannot make any calls to\n     * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h\n     * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n     * failure if a FreeRTOS API function is called from an interrupt that has been\n     * assigned a priority above the configured maximum system call priority.\n     * Only FreeRTOS functions that end in FromISR can be called from interrupts\n     * that have been assigned a priority at or (logically) below the maximum\n     * system call interrupt priority.  FreeRTOS maintains a separate interrupt\n     * safe API to ensure interrupt entry is as fast and as simple as possible.\n     * More information (albeit Cortex-M specific) is provided on the following\n     * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n    portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n    {\n        const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n        /* When the queue is used to implement a semaphore no data is ever\n         * moved through the queue but it is still valid to see if the queue 'has\n         * space'. */\n        if( uxMessagesWaiting < pxQueue->uxLength )\n        {\n            const int8_t cTxLock = pxQueue->cTxLock;\n\n            traceQUEUE_SEND_FROM_ISR( pxQueue );\n\n            /* A task can only have an inherited priority if it is a mutex\n             * holder - and if there is a mutex holder then the mutex cannot be\n             * given from an ISR.  As this is the ISR version of the function it\n             * can be assumed there is no mutex holder and no need to determine if\n             * priority disinheritance is needed.  Simply increase the count of\n             * messages (semaphores) available. */\n            pxQueue->uxMessagesWaiting = ( UBaseType_t ) ( uxMessagesWaiting + ( UBaseType_t ) 1 );\n\n            /* The event list is not altered if the queue is locked.  This will\n             * be done when the queue is unlocked later. */\n            if( cTxLock == queueUNLOCKED )\n            {\n                #if ( configUSE_QUEUE_SETS == 1 )\n                {\n                    if( pxQueue->pxQueueSetContainer != NULL )\n                    {\n                        if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )\n                        {\n                            /* The semaphore is a member of a queue set, and\n                             * posting to the queue set caused a higher priority\n                             * task to unblock.  A context switch is required. */\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                        {\n                            if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                            {\n                                /* The task waiting has a higher priority so\n                                 *  record that a context switch is required. */\n                                if( pxHigherPriorityTaskWoken != NULL )\n                                {\n                                    *pxHigherPriorityTaskWoken = pdTRUE;\n                                }\n                                else\n                                {\n                                    mtCOVERAGE_TEST_MARKER();\n                                }\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                }\n                #else /* configUSE_QUEUE_SETS */\n                {\n                    if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                    {\n                        if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                        {\n                            /* The task waiting has a higher priority so record that a\n                             * context switch is required. */\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #endif /* configUSE_QUEUE_SETS */\n            }\n            else\n            {\n                /* Increment the lock count so the task that unlocks the queue\n                 * knows that data was posted while it was locked. */\n                prvIncrementQueueTxLock( pxQueue, cTxLock );\n            }\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );\n            xReturn = errQUEUE_FULL;\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xQueueGiveFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueReceive( QueueHandle_t xQueue,\n                          void * const pvBuffer,\n                          TickType_t xTicksToWait )\n{\n    BaseType_t xEntryTimeSet = pdFALSE;\n    TimeOut_t xTimeOut;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueReceive( xQueue, pvBuffer, xTicksToWait );\n\n    /* Check the pointer is not NULL. */\n    configASSERT( ( pxQueue ) );\n\n    /* The buffer into which data is received can only be NULL if the data size\n     * is zero (so no data is copied into the buffer). */\n    configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );\n\n    /* Cannot block if the scheduler is suspended. */\n    #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n    {\n        configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n    }\n    #endif\n\n    for( ; ; )\n    {\n        taskENTER_CRITICAL();\n        {\n            const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n            /* Is there data in the queue now?  To be running the calling task\n             * must be the highest priority task wanting to access the queue. */\n            if( uxMessagesWaiting > ( UBaseType_t ) 0 )\n            {\n                /* Data available, remove one item. */\n                prvCopyDataFromQueue( pxQueue, pvBuffer );\n                traceQUEUE_RECEIVE( pxQueue );\n                pxQueue->uxMessagesWaiting = ( UBaseType_t ) ( uxMessagesWaiting - ( UBaseType_t ) 1 );\n\n                /* There is now space in the queue, were any tasks waiting to\n                 * post to the queue?  If so, unblock the highest priority waiting\n                 * task. */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        queueYIELD_IF_USING_PREEMPTION();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                taskEXIT_CRITICAL();\n\n                traceRETURN_xQueueReceive( pdPASS );\n\n                return pdPASS;\n            }\n            else\n            {\n                if( xTicksToWait == ( TickType_t ) 0 )\n                {\n                    /* The queue was empty and no block time is specified (or\n                     * the block time has expired) so leave now. */\n                    taskEXIT_CRITICAL();\n\n                    traceQUEUE_RECEIVE_FAILED( pxQueue );\n                    traceRETURN_xQueueReceive( errQUEUE_EMPTY );\n\n                    return errQUEUE_EMPTY;\n                }\n                else if( xEntryTimeSet == pdFALSE )\n                {\n                    /* The queue was empty and a block time was specified so\n                     * configure the timeout structure. */\n                    vTaskInternalSetTimeOutState( &xTimeOut );\n                    xEntryTimeSet = pdTRUE;\n                }\n                else\n                {\n                    /* Entry time was already set. */\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        /* Interrupts and other tasks can send to and receive from the queue\n         * now the critical section has been exited. */\n\n        vTaskSuspendAll();\n        prvLockQueue( pxQueue );\n\n        /* Update the timeout state to see if it has expired yet. */\n        if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )\n        {\n            /* The timeout has not expired.  If the queue is still empty place\n             * the task on the list of tasks waiting to receive from the queue. */\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );\n                vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );\n                prvUnlockQueue( pxQueue );\n\n                if( xTaskResumeAll() == pdFALSE )\n                {\n                    taskYIELD_WITHIN_API();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* The queue contains data again.  Loop back to try and read the\n                 * data. */\n                prvUnlockQueue( pxQueue );\n                ( void ) xTaskResumeAll();\n            }\n        }\n        else\n        {\n            /* Timed out.  If there is no data in the queue exit, otherwise loop\n             * back and attempt to read the data. */\n            prvUnlockQueue( pxQueue );\n            ( void ) xTaskResumeAll();\n\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                traceQUEUE_RECEIVE_FAILED( pxQueue );\n                traceRETURN_xQueueReceive( errQUEUE_EMPTY );\n\n                return errQUEUE_EMPTY;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n    }\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue,\n                                TickType_t xTicksToWait )\n{\n    BaseType_t xEntryTimeSet = pdFALSE;\n    TimeOut_t xTimeOut;\n    Queue_t * const pxQueue = xQueue;\n\n    #if ( configUSE_MUTEXES == 1 )\n        BaseType_t xInheritanceOccurred = pdFALSE;\n    #endif\n\n    traceENTER_xQueueSemaphoreTake( xQueue, xTicksToWait );\n\n    /* Check the queue pointer is not NULL. */\n    configASSERT( ( pxQueue ) );\n\n    /* Check this really is a semaphore, in which case the item size will be\n     * 0. */\n    configASSERT( pxQueue->uxItemSize == 0 );\n\n    /* Cannot block if the scheduler is suspended. */\n    #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n    {\n        configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n    }\n    #endif\n\n    for( ; ; )\n    {\n        taskENTER_CRITICAL();\n        {\n            /* Semaphores are queues with an item size of 0, and where the\n             * number of messages in the queue is the semaphore's count value. */\n            const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;\n\n            /* Is there data in the queue now?  To be running the calling task\n             * must be the highest priority task wanting to access the queue. */\n            if( uxSemaphoreCount > ( UBaseType_t ) 0 )\n            {\n                traceQUEUE_RECEIVE( pxQueue );\n\n                /* Semaphores are queues with a data size of zero and where the\n                 * messages waiting is the semaphore's count.  Reduce the count. */\n                pxQueue->uxMessagesWaiting = ( UBaseType_t ) ( uxSemaphoreCount - ( UBaseType_t ) 1 );\n\n                #if ( configUSE_MUTEXES == 1 )\n                {\n                    if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )\n                    {\n                        /* Record the information required to implement\n                         * priority inheritance should it become necessary. */\n                        pxQueue->u.xSemaphore.xMutexHolder = pvTaskIncrementMutexHeldCount();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #endif /* configUSE_MUTEXES */\n\n                /* Check to see if other tasks are blocked waiting to give the\n                 * semaphore, and if so, unblock the highest priority such task. */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        queueYIELD_IF_USING_PREEMPTION();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                taskEXIT_CRITICAL();\n\n                traceRETURN_xQueueSemaphoreTake( pdPASS );\n\n                return pdPASS;\n            }\n            else\n            {\n                if( xTicksToWait == ( TickType_t ) 0 )\n                {\n                    /* The semaphore count was 0 and no block time is specified\n                     * (or the block time has expired) so exit now. */\n                    taskEXIT_CRITICAL();\n\n                    traceQUEUE_RECEIVE_FAILED( pxQueue );\n                    traceRETURN_xQueueSemaphoreTake( errQUEUE_EMPTY );\n\n                    return errQUEUE_EMPTY;\n                }\n                else if( xEntryTimeSet == pdFALSE )\n                {\n                    /* The semaphore count was 0 and a block time was specified\n                     * so configure the timeout structure ready to block. */\n                    vTaskInternalSetTimeOutState( &xTimeOut );\n                    xEntryTimeSet = pdTRUE;\n                }\n                else\n                {\n                    /* Entry time was already set. */\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        /* Interrupts and other tasks can give to and take from the semaphore\n         * now the critical section has been exited. */\n\n        vTaskSuspendAll();\n        prvLockQueue( pxQueue );\n\n        /* Update the timeout state to see if it has expired yet. */\n        if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )\n        {\n            /* A block time is specified and not expired.  If the semaphore\n             * count is 0 then enter the Blocked state to wait for a semaphore to\n             * become available.  As semaphores are implemented with queues the\n             * queue being empty is equivalent to the semaphore count being 0. */\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );\n\n                #if ( configUSE_MUTEXES == 1 )\n                {\n                    if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )\n                    {\n                        taskENTER_CRITICAL();\n                        {\n                            xInheritanceOccurred = xTaskPriorityInherit( pxQueue->u.xSemaphore.xMutexHolder );\n                        }\n                        taskEXIT_CRITICAL();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #endif /* if ( configUSE_MUTEXES == 1 ) */\n\n                vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );\n                prvUnlockQueue( pxQueue );\n\n                if( xTaskResumeAll() == pdFALSE )\n                {\n                    taskYIELD_WITHIN_API();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* There was no timeout and the semaphore count was not 0, so\n                 * attempt to take the semaphore again. */\n                prvUnlockQueue( pxQueue );\n                ( void ) xTaskResumeAll();\n            }\n        }\n        else\n        {\n            /* Timed out. */\n            prvUnlockQueue( pxQueue );\n            ( void ) xTaskResumeAll();\n\n            /* If the semaphore count is 0 exit now as the timeout has\n             * expired.  Otherwise return to attempt to take the semaphore that is\n             * known to be available.  As semaphores are implemented by queues the\n             * queue being empty is equivalent to the semaphore count being 0. */\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                #if ( configUSE_MUTEXES == 1 )\n                {\n                    /* xInheritanceOccurred could only have be set if\n                     * pxQueue->uxQueueType == queueQUEUE_IS_MUTEX so no need to\n                     * test the mutex type again to check it is actually a mutex. */\n                    if( xInheritanceOccurred != pdFALSE )\n                    {\n                        taskENTER_CRITICAL();\n                        {\n                            UBaseType_t uxHighestWaitingPriority;\n\n                            /* This task blocking on the mutex caused another\n                             * task to inherit this task's priority.  Now this task\n                             * has timed out the priority should be disinherited\n                             * again, but only as low as the next highest priority\n                             * task that is waiting for the same mutex. */\n                            uxHighestWaitingPriority = prvGetHighestPriorityOfWaitToReceiveList( pxQueue );\n\n                            /* vTaskPriorityDisinheritAfterTimeout uses the uxHighestWaitingPriority\n                             * parameter to index pxReadyTasksLists when adding the task holding\n                             * mutex to the ready list for its new priority. Coverity thinks that\n                             * it can result in out-of-bounds access which is not true because\n                             * uxHighestWaitingPriority, as returned by prvGetHighestPriorityOfWaitToReceiveList,\n                             * is capped at ( configMAX_PRIORITIES - 1 ). */\n                            /* coverity[overrun] */\n                            vTaskPriorityDisinheritAfterTimeout( pxQueue->u.xSemaphore.xMutexHolder, uxHighestWaitingPriority );\n                        }\n                        taskEXIT_CRITICAL();\n                    }\n                }\n                #endif /* configUSE_MUTEXES */\n\n                traceQUEUE_RECEIVE_FAILED( pxQueue );\n                traceRETURN_xQueueSemaphoreTake( errQUEUE_EMPTY );\n\n                return errQUEUE_EMPTY;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n    }\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueuePeek( QueueHandle_t xQueue,\n                       void * const pvBuffer,\n                       TickType_t xTicksToWait )\n{\n    BaseType_t xEntryTimeSet = pdFALSE;\n    TimeOut_t xTimeOut;\n    int8_t * pcOriginalReadPosition;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueuePeek( xQueue, pvBuffer, xTicksToWait );\n\n    /* Check the pointer is not NULL. */\n    configASSERT( ( pxQueue ) );\n\n    /* The buffer into which data is received can only be NULL if the data size\n     * is zero (so no data is copied into the buffer. */\n    configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );\n\n    /* Cannot block if the scheduler is suspended. */\n    #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n    {\n        configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );\n    }\n    #endif\n\n    for( ; ; )\n    {\n        taskENTER_CRITICAL();\n        {\n            const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n            /* Is there data in the queue now?  To be running the calling task\n             * must be the highest priority task wanting to access the queue. */\n            if( uxMessagesWaiting > ( UBaseType_t ) 0 )\n            {\n                /* Remember the read position so it can be reset after the data\n                 * is read from the queue as this function is only peeking the\n                 * data, not removing it. */\n                pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;\n\n                prvCopyDataFromQueue( pxQueue, pvBuffer );\n                traceQUEUE_PEEK( pxQueue );\n\n                /* The data is not being removed, so reset the read pointer. */\n                pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;\n\n                /* The data is being left in the queue, so see if there are\n                 * any other tasks waiting for the data. */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                    {\n                        /* The task waiting has a higher priority than this task. */\n                        queueYIELD_IF_USING_PREEMPTION();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                taskEXIT_CRITICAL();\n\n                traceRETURN_xQueuePeek( pdPASS );\n\n                return pdPASS;\n            }\n            else\n            {\n                if( xTicksToWait == ( TickType_t ) 0 )\n                {\n                    /* The queue was empty and no block time is specified (or\n                     * the block time has expired) so leave now. */\n                    taskEXIT_CRITICAL();\n\n                    traceQUEUE_PEEK_FAILED( pxQueue );\n                    traceRETURN_xQueuePeek( errQUEUE_EMPTY );\n\n                    return errQUEUE_EMPTY;\n                }\n                else if( xEntryTimeSet == pdFALSE )\n                {\n                    /* The queue was empty and a block time was specified so\n                     * configure the timeout structure ready to enter the blocked\n                     * state. */\n                    vTaskInternalSetTimeOutState( &xTimeOut );\n                    xEntryTimeSet = pdTRUE;\n                }\n                else\n                {\n                    /* Entry time was already set. */\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        /* Interrupts and other tasks can send to and receive from the queue\n         * now that the critical section has been exited. */\n\n        vTaskSuspendAll();\n        prvLockQueue( pxQueue );\n\n        /* Update the timeout state to see if it has expired yet. */\n        if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )\n        {\n            /* Timeout has not expired yet, check to see if there is data in the\n            * queue now, and if not enter the Blocked state to wait for data. */\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                traceBLOCKING_ON_QUEUE_PEEK( pxQueue );\n                vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );\n                prvUnlockQueue( pxQueue );\n\n                if( xTaskResumeAll() == pdFALSE )\n                {\n                    taskYIELD_WITHIN_API();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* There is data in the queue now, so don't enter the blocked\n                 * state, instead return to try and obtain the data. */\n                prvUnlockQueue( pxQueue );\n                ( void ) xTaskResumeAll();\n            }\n        }\n        else\n        {\n            /* The timeout has expired.  If there is still no data in the queue\n             * exit, otherwise go back and try to read the data again. */\n            prvUnlockQueue( pxQueue );\n            ( void ) xTaskResumeAll();\n\n            if( prvIsQueueEmpty( pxQueue ) != pdFALSE )\n            {\n                traceQUEUE_PEEK_FAILED( pxQueue );\n                traceRETURN_xQueuePeek( errQUEUE_EMPTY );\n\n                return errQUEUE_EMPTY;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n    }\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue,\n                                 void * const pvBuffer,\n                                 BaseType_t * const pxHigherPriorityTaskWoken )\n{\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueReceiveFromISR( xQueue, pvBuffer, pxHigherPriorityTaskWoken );\n\n    configASSERT( pxQueue );\n    configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );\n\n    /* RTOS ports that support interrupt nesting have the concept of a maximum\n     * system call (or maximum API call) interrupt priority.  Interrupts that are\n     * above the maximum system call priority are kept permanently enabled, even\n     * when the RTOS kernel is in a critical section, but cannot make any calls to\n     * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h\n     * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n     * failure if a FreeRTOS API function is called from an interrupt that has been\n     * assigned a priority above the configured maximum system call priority.\n     * Only FreeRTOS functions that end in FromISR can be called from interrupts\n     * that have been assigned a priority at or (logically) below the maximum\n     * system call interrupt priority.  FreeRTOS maintains a separate interrupt\n     * safe API to ensure interrupt entry is as fast and as simple as possible.\n     * More information (albeit Cortex-M specific) is provided on the following\n     * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n    portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n    {\n        const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n        /* Cannot block in an ISR, so check there is data available. */\n        if( uxMessagesWaiting > ( UBaseType_t ) 0 )\n        {\n            const int8_t cRxLock = pxQueue->cRxLock;\n\n            traceQUEUE_RECEIVE_FROM_ISR( pxQueue );\n\n            prvCopyDataFromQueue( pxQueue, pvBuffer );\n            pxQueue->uxMessagesWaiting = ( UBaseType_t ) ( uxMessagesWaiting - ( UBaseType_t ) 1 );\n\n            /* If the queue is locked the event list will not be modified.\n             * Instead update the lock count so the task that unlocks the queue\n             * will know that an ISR has removed data while the queue was\n             * locked. */\n            if( cRxLock == queueUNLOCKED )\n            {\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        /* The task waiting has a higher priority than us so\n                         * force a context switch. */\n                        if( pxHigherPriorityTaskWoken != NULL )\n                        {\n                            *pxHigherPriorityTaskWoken = pdTRUE;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* Increment the lock count so the task that unlocks the queue\n                 * knows that data was removed while it was locked. */\n                prvIncrementQueueRxLock( pxQueue, cRxLock );\n            }\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = pdFAIL;\n            traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue );\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xQueueReceiveFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,\n                              void * const pvBuffer )\n{\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n    int8_t * pcOriginalReadPosition;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueuePeekFromISR( xQueue, pvBuffer );\n\n    configASSERT( pxQueue );\n    configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );\n    configASSERT( pxQueue->uxItemSize != 0 ); /* Can't peek a semaphore. */\n\n    /* RTOS ports that support interrupt nesting have the concept of a maximum\n     * system call (or maximum API call) interrupt priority.  Interrupts that are\n     * above the maximum system call priority are kept permanently enabled, even\n     * when the RTOS kernel is in a critical section, but cannot make any calls to\n     * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h\n     * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n     * failure if a FreeRTOS API function is called from an interrupt that has been\n     * assigned a priority above the configured maximum system call priority.\n     * Only FreeRTOS functions that end in FromISR can be called from interrupts\n     * that have been assigned a priority at or (logically) below the maximum\n     * system call interrupt priority.  FreeRTOS maintains a separate interrupt\n     * safe API to ensure interrupt entry is as fast and as simple as possible.\n     * More information (albeit Cortex-M specific) is provided on the following\n     * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n    portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n    {\n        /* Cannot block in an ISR, so check there is data available. */\n        if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )\n        {\n            traceQUEUE_PEEK_FROM_ISR( pxQueue );\n\n            /* Remember the read position so it can be reset as nothing is\n             * actually being removed from the queue. */\n            pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;\n            prvCopyDataFromQueue( pxQueue, pvBuffer );\n            pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = pdFAIL;\n            traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue );\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xQueuePeekFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue )\n{\n    UBaseType_t uxReturn;\n\n    traceENTER_uxQueueMessagesWaiting( xQueue );\n\n    configASSERT( xQueue );\n\n    portBASE_TYPE_ENTER_CRITICAL();\n    {\n        uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;\n    }\n    portBASE_TYPE_EXIT_CRITICAL();\n\n    traceRETURN_uxQueueMessagesWaiting( uxReturn );\n\n    return uxReturn;\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )\n{\n    UBaseType_t uxReturn;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_uxQueueSpacesAvailable( xQueue );\n\n    configASSERT( pxQueue );\n\n    portBASE_TYPE_ENTER_CRITICAL();\n    {\n        uxReturn = ( UBaseType_t ) ( pxQueue->uxLength - pxQueue->uxMessagesWaiting );\n    }\n    portBASE_TYPE_EXIT_CRITICAL();\n\n    traceRETURN_uxQueueSpacesAvailable( uxReturn );\n\n    return uxReturn;\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue )\n{\n    UBaseType_t uxReturn;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_uxQueueMessagesWaitingFromISR( xQueue );\n\n    configASSERT( pxQueue );\n    uxReturn = pxQueue->uxMessagesWaiting;\n\n    traceRETURN_uxQueueMessagesWaitingFromISR( uxReturn );\n\n    return uxReturn;\n}\n/*-----------------------------------------------------------*/\n\nvoid vQueueDelete( QueueHandle_t xQueue )\n{\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_vQueueDelete( xQueue );\n\n    configASSERT( pxQueue );\n    traceQUEUE_DELETE( pxQueue );\n\n    #if ( configQUEUE_REGISTRY_SIZE > 0 )\n    {\n        vQueueUnregisterQueue( pxQueue );\n    }\n    #endif\n\n    #if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )\n    {\n        /* The queue can only have been allocated dynamically - free it\n         * again. */\n        vPortFree( pxQueue );\n    }\n    #elif ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n    {\n        /* The queue could have been allocated statically or dynamically, so\n         * check before attempting to free the memory. */\n        if( pxQueue->ucStaticallyAllocated == ( uint8_t ) pdFALSE )\n        {\n            vPortFree( pxQueue );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    #else /* if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) ) */\n    {\n        /* The queue must have been statically allocated, so is not going to be\n         * deleted.  Avoid compiler warnings about the unused parameter. */\n        ( void ) pxQueue;\n    }\n    #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n\n    traceRETURN_vQueueDelete();\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    UBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue )\n    {\n        traceENTER_uxQueueGetQueueNumber( xQueue );\n\n        traceRETURN_uxQueueGetQueueNumber( ( ( Queue_t * ) xQueue )->uxQueueNumber );\n\n        return ( ( Queue_t * ) xQueue )->uxQueueNumber;\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    void vQueueSetQueueNumber( QueueHandle_t xQueue,\n                               UBaseType_t uxQueueNumber )\n    {\n        traceENTER_vQueueSetQueueNumber( xQueue, uxQueueNumber );\n\n        ( ( Queue_t * ) xQueue )->uxQueueNumber = uxQueueNumber;\n\n        traceRETURN_vQueueSetQueueNumber();\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    uint8_t ucQueueGetQueueType( QueueHandle_t xQueue )\n    {\n        traceENTER_ucQueueGetQueueType( xQueue );\n\n        traceRETURN_ucQueueGetQueueType( ( ( Queue_t * ) xQueue )->ucQueueType );\n\n        return ( ( Queue_t * ) xQueue )->ucQueueType;\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxQueueGetQueueItemSize( QueueHandle_t xQueue ) /* PRIVILEGED_FUNCTION */\n{\n    traceENTER_uxQueueGetQueueItemSize( xQueue );\n\n    traceRETURN_uxQueueGetQueueItemSize( ( ( Queue_t * ) xQueue )->uxItemSize );\n\n    return ( ( Queue_t * ) xQueue )->uxItemSize;\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxQueueGetQueueLength( QueueHandle_t xQueue ) /* PRIVILEGED_FUNCTION */\n{\n    traceENTER_uxQueueGetQueueLength( xQueue );\n\n    traceRETURN_uxQueueGetQueueLength( ( ( Queue_t * ) xQueue )->uxLength );\n\n    return ( ( Queue_t * ) xQueue )->uxLength;\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    static UBaseType_t prvGetHighestPriorityOfWaitToReceiveList( const Queue_t * const pxQueue )\n    {\n        UBaseType_t uxHighestPriorityOfWaitingTasks;\n\n        /* If a task waiting for a mutex causes the mutex holder to inherit a\n         * priority, but the waiting task times out, then the holder should\n         * disinherit the priority - but only down to the highest priority of any\n         * other tasks that are waiting for the same mutex.  For this purpose,\n         * return the priority of the highest priority task that is waiting for the\n         * mutex. */\n        if( listCURRENT_LIST_LENGTH( &( pxQueue->xTasksWaitingToReceive ) ) > 0U )\n        {\n            uxHighestPriorityOfWaitingTasks = ( UBaseType_t ) ( ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) listGET_ITEM_VALUE_OF_HEAD_ENTRY( &( pxQueue->xTasksWaitingToReceive ) ) );\n        }\n        else\n        {\n            uxHighestPriorityOfWaitingTasks = tskIDLE_PRIORITY;\n        }\n\n        return uxHighestPriorityOfWaitingTasks;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\nstatic BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue,\n                                      const void * pvItemToQueue,\n                                      const BaseType_t xPosition )\n{\n    BaseType_t xReturn = pdFALSE;\n    UBaseType_t uxMessagesWaiting;\n\n    /* This function is called from a critical section. */\n\n    uxMessagesWaiting = pxQueue->uxMessagesWaiting;\n\n    if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )\n    {\n        #if ( configUSE_MUTEXES == 1 )\n        {\n            if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )\n            {\n                /* The mutex is no longer being held. */\n                xReturn = xTaskPriorityDisinherit( pxQueue->u.xSemaphore.xMutexHolder );\n                pxQueue->u.xSemaphore.xMutexHolder = NULL;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* configUSE_MUTEXES */\n    }\n    else if( xPosition == queueSEND_TO_BACK )\n    {\n        ( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize );\n        pxQueue->pcWriteTo += pxQueue->uxItemSize;\n\n        if( pxQueue->pcWriteTo >= pxQueue->u.xQueue.pcTail )\n        {\n            pxQueue->pcWriteTo = pxQueue->pcHead;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        ( void ) memcpy( ( void * ) pxQueue->u.xQueue.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize );\n        pxQueue->u.xQueue.pcReadFrom -= pxQueue->uxItemSize;\n\n        if( pxQueue->u.xQueue.pcReadFrom < pxQueue->pcHead )\n        {\n            pxQueue->u.xQueue.pcReadFrom = ( pxQueue->u.xQueue.pcTail - pxQueue->uxItemSize );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        if( xPosition == queueOVERWRITE )\n        {\n            if( uxMessagesWaiting > ( UBaseType_t ) 0 )\n            {\n                /* An item is not being added but overwritten, so subtract\n                 * one from the recorded number of items in the queue so when\n                 * one is added again below the number of recorded items remains\n                 * correct. */\n                --uxMessagesWaiting;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n\n    pxQueue->uxMessagesWaiting = ( UBaseType_t ) ( uxMessagesWaiting + ( UBaseType_t ) 1 );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvCopyDataFromQueue( Queue_t * const pxQueue,\n                                  void * const pvBuffer )\n{\n    if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )\n    {\n        pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;\n\n        if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )\n        {\n            pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( size_t ) pxQueue->uxItemSize );\n    }\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvUnlockQueue( Queue_t * const pxQueue )\n{\n    /* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED. */\n\n    /* The lock counts contains the number of extra data items placed or\n     * removed from the queue while the queue was locked.  When a queue is\n     * locked items can be added or removed, but the event lists cannot be\n     * updated. */\n    taskENTER_CRITICAL();\n    {\n        int8_t cTxLock = pxQueue->cTxLock;\n\n        /* See if data was added to the queue while it was locked. */\n        while( cTxLock > queueLOCKED_UNMODIFIED )\n        {\n            /* Data was posted while the queue was locked.  Are any tasks\n             * blocked waiting for data to become available? */\n            #if ( configUSE_QUEUE_SETS == 1 )\n            {\n                if( pxQueue->pxQueueSetContainer != NULL )\n                {\n                    if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )\n                    {\n                        /* The queue is a member of a queue set, and posting to\n                         * the queue set caused a higher priority task to unblock.\n                         * A context switch is required. */\n                        vTaskMissedYield();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    /* Tasks that are removed from the event list will get\n                     * added to the pending ready list as the scheduler is still\n                     * suspended. */\n                    if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                    {\n                        if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                        {\n                            /* The task waiting has a higher priority so record that a\n                             * context switch is required. */\n                            vTaskMissedYield();\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    else\n                    {\n                        break;\n                    }\n                }\n            }\n            #else /* configUSE_QUEUE_SETS */\n            {\n                /* Tasks that are removed from the event list will get added to\n                 * the pending ready list as the scheduler is still suspended. */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                    {\n                        /* The task waiting has a higher priority so record that\n                         * a context switch is required. */\n                        vTaskMissedYield();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    break;\n                }\n            }\n            #endif /* configUSE_QUEUE_SETS */\n\n            --cTxLock;\n        }\n\n        pxQueue->cTxLock = queueUNLOCKED;\n    }\n    taskEXIT_CRITICAL();\n\n    /* Do the same for the Rx lock. */\n    taskENTER_CRITICAL();\n    {\n        int8_t cRxLock = pxQueue->cRxLock;\n\n        while( cRxLock > queueLOCKED_UNMODIFIED )\n        {\n            if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n            {\n                if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                {\n                    vTaskMissedYield();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                --cRxLock;\n            }\n            else\n            {\n                break;\n            }\n        }\n\n        pxQueue->cRxLock = queueUNLOCKED;\n    }\n    taskEXIT_CRITICAL();\n}\n/*-----------------------------------------------------------*/\n\nstatic BaseType_t prvIsQueueEmpty( const Queue_t * pxQueue )\n{\n    BaseType_t xReturn;\n\n    taskENTER_CRITICAL();\n    {\n        if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )\n        {\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n    }\n    taskEXIT_CRITICAL();\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )\n{\n    BaseType_t xReturn;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueIsQueueEmptyFromISR( xQueue );\n\n    configASSERT( pxQueue );\n\n    if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )\n    {\n        xReturn = pdTRUE;\n    }\n    else\n    {\n        xReturn = pdFALSE;\n    }\n\n    traceRETURN_xQueueIsQueueEmptyFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nstatic BaseType_t prvIsQueueFull( const Queue_t * pxQueue )\n{\n    BaseType_t xReturn;\n\n    taskENTER_CRITICAL();\n    {\n        if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )\n        {\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n    }\n    taskEXIT_CRITICAL();\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )\n{\n    BaseType_t xReturn;\n    Queue_t * const pxQueue = xQueue;\n\n    traceENTER_xQueueIsQueueFullFromISR( xQueue );\n\n    configASSERT( pxQueue );\n\n    if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )\n    {\n        xReturn = pdTRUE;\n    }\n    else\n    {\n        xReturn = pdFALSE;\n    }\n\n    traceRETURN_xQueueIsQueueFullFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_CO_ROUTINES == 1 )\n\n    BaseType_t xQueueCRSend( QueueHandle_t xQueue,\n                             const void * pvItemToQueue,\n                             TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_xQueueCRSend( xQueue, pvItemToQueue, xTicksToWait );\n\n        /* If the queue is already full we may have to block.  A critical section\n         * is required to prevent an interrupt removing something from the queue\n         * between the check to see if the queue is full and blocking on the queue. */\n        portDISABLE_INTERRUPTS();\n        {\n            if( prvIsQueueFull( pxQueue ) != pdFALSE )\n            {\n                /* The queue is full - do we want to block or just leave without\n                 * posting? */\n                if( xTicksToWait > ( TickType_t ) 0 )\n                {\n                    /* As this is called from a coroutine we cannot block directly, but\n                     * return indicating that we need to block. */\n                    vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToSend ) );\n                    portENABLE_INTERRUPTS();\n                    return errQUEUE_BLOCKED;\n                }\n                else\n                {\n                    portENABLE_INTERRUPTS();\n                    return errQUEUE_FULL;\n                }\n            }\n        }\n        portENABLE_INTERRUPTS();\n\n        portDISABLE_INTERRUPTS();\n        {\n            if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )\n            {\n                /* There is room in the queue, copy the data into the queue. */\n                prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );\n                xReturn = pdPASS;\n\n                /* Were any co-routines waiting for data to become available? */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                {\n                    /* In this instance the co-routine could be placed directly\n                     * into the ready list as we are within a critical section.\n                     * Instead the same pending ready list mechanism is used as if\n                     * the event were caused from within an interrupt. */\n                    if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                    {\n                        /* The co-routine waiting has a higher priority so record\n                         * that a yield might be appropriate. */\n                        xReturn = errQUEUE_YIELD;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                xReturn = errQUEUE_FULL;\n            }\n        }\n        portENABLE_INTERRUPTS();\n\n        traceRETURN_xQueueCRSend( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_CO_ROUTINES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_CO_ROUTINES == 1 )\n\n    BaseType_t xQueueCRReceive( QueueHandle_t xQueue,\n                                void * pvBuffer,\n                                TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_xQueueCRReceive( xQueue, pvBuffer, xTicksToWait );\n\n        /* If the queue is already empty we may have to block.  A critical section\n         * is required to prevent an interrupt adding something to the queue\n         * between the check to see if the queue is empty and blocking on the queue. */\n        portDISABLE_INTERRUPTS();\n        {\n            if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )\n            {\n                /* There are no messages in the queue, do we want to block or just\n                 * leave with nothing? */\n                if( xTicksToWait > ( TickType_t ) 0 )\n                {\n                    /* As this is a co-routine we cannot block directly, but return\n                     * indicating that we need to block. */\n                    vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToReceive ) );\n                    portENABLE_INTERRUPTS();\n                    return errQUEUE_BLOCKED;\n                }\n                else\n                {\n                    portENABLE_INTERRUPTS();\n                    return errQUEUE_FULL;\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        portENABLE_INTERRUPTS();\n\n        portDISABLE_INTERRUPTS();\n        {\n            if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )\n            {\n                /* Data is available from the queue. */\n                pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;\n\n                if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )\n                {\n                    pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                --( pxQueue->uxMessagesWaiting );\n                ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );\n\n                xReturn = pdPASS;\n\n                /* Were any co-routines waiting for space to become available? */\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    /* In this instance the co-routine could be placed directly\n                     * into the ready list as we are within a critical section.\n                     * Instead the same pending ready list mechanism is used as if\n                     * the event were caused from within an interrupt. */\n                    if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        xReturn = errQUEUE_YIELD;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                xReturn = pdFAIL;\n            }\n        }\n        portENABLE_INTERRUPTS();\n\n        traceRETURN_xQueueCRReceive( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_CO_ROUTINES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_CO_ROUTINES == 1 )\n\n    BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue,\n                                    const void * pvItemToQueue,\n                                    BaseType_t xCoRoutinePreviouslyWoken )\n    {\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_xQueueCRSendFromISR( xQueue, pvItemToQueue, xCoRoutinePreviouslyWoken );\n\n        /* Cannot block within an ISR so if there is no space on the queue then\n         * exit without doing anything. */\n        if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )\n        {\n            prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );\n\n            /* We only want to wake one co-routine per ISR, so check that a\n             * co-routine has not already been woken. */\n            if( xCoRoutinePreviouslyWoken == pdFALSE )\n            {\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )\n                {\n                    if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )\n                    {\n                        return pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xQueueCRSendFromISR( xCoRoutinePreviouslyWoken );\n\n        return xCoRoutinePreviouslyWoken;\n    }\n\n#endif /* configUSE_CO_ROUTINES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_CO_ROUTINES == 1 )\n\n    BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue,\n                                       void * pvBuffer,\n                                       BaseType_t * pxCoRoutineWoken )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_xQueueCRReceiveFromISR( xQueue, pvBuffer, pxCoRoutineWoken );\n\n        /* We cannot block from an ISR, so check there is data available. If\n         * not then just leave without doing anything. */\n        if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )\n        {\n            /* Copy the data from the queue. */\n            pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;\n\n            if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )\n            {\n                pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            --( pxQueue->uxMessagesWaiting );\n            ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );\n\n            if( ( *pxCoRoutineWoken ) == pdFALSE )\n            {\n                if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )\n                {\n                    if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )\n                    {\n                        *pxCoRoutineWoken = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = pdFAIL;\n        }\n\n        traceRETURN_xQueueCRReceiveFromISR( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_CO_ROUTINES */\n/*-----------------------------------------------------------*/\n\n#if ( configQUEUE_REGISTRY_SIZE > 0 )\n\n    void vQueueAddToRegistry( QueueHandle_t xQueue,\n                              const char * pcQueueName )\n    {\n        UBaseType_t ux;\n        QueueRegistryItem_t * pxEntryToWrite = NULL;\n\n        traceENTER_vQueueAddToRegistry( xQueue, pcQueueName );\n\n        configASSERT( xQueue );\n\n        if( pcQueueName != NULL )\n        {\n            /* See if there is an empty space in the registry.  A NULL name denotes\n             * a free slot. */\n            for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )\n            {\n                /* Replace an existing entry if the queue is already in the registry. */\n                if( xQueue == xQueueRegistry[ ux ].xHandle )\n                {\n                    pxEntryToWrite = &( xQueueRegistry[ ux ] );\n                    break;\n                }\n                /* Otherwise, store in the next empty location */\n                else if( ( pxEntryToWrite == NULL ) && ( xQueueRegistry[ ux ].pcQueueName == NULL ) )\n                {\n                    pxEntryToWrite = &( xQueueRegistry[ ux ] );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n\n        if( pxEntryToWrite != NULL )\n        {\n            /* Store the information on this queue. */\n            pxEntryToWrite->pcQueueName = pcQueueName;\n            pxEntryToWrite->xHandle = xQueue;\n\n            traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );\n        }\n\n        traceRETURN_vQueueAddToRegistry();\n    }\n\n#endif /* configQUEUE_REGISTRY_SIZE */\n/*-----------------------------------------------------------*/\n\n#if ( configQUEUE_REGISTRY_SIZE > 0 )\n\n    const char * pcQueueGetName( QueueHandle_t xQueue )\n    {\n        UBaseType_t ux;\n        const char * pcReturn = NULL;\n\n        traceENTER_pcQueueGetName( xQueue );\n\n        configASSERT( xQueue );\n\n        /* Note there is nothing here to protect against another task adding or\n         * removing entries from the registry while it is being searched. */\n\n        for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )\n        {\n            if( xQueueRegistry[ ux ].xHandle == xQueue )\n            {\n                pcReturn = xQueueRegistry[ ux ].pcQueueName;\n                break;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        traceRETURN_pcQueueGetName( pcReturn );\n\n        return pcReturn;\n    }\n\n#endif /* configQUEUE_REGISTRY_SIZE */\n/*-----------------------------------------------------------*/\n\n#if ( configQUEUE_REGISTRY_SIZE > 0 )\n\n    void vQueueUnregisterQueue( QueueHandle_t xQueue )\n    {\n        UBaseType_t ux;\n\n        traceENTER_vQueueUnregisterQueue( xQueue );\n\n        configASSERT( xQueue );\n\n        /* See if the handle of the queue being unregistered in actually in the\n         * registry. */\n        for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )\n        {\n            if( xQueueRegistry[ ux ].xHandle == xQueue )\n            {\n                /* Set the name to NULL to show that this slot if free again. */\n                xQueueRegistry[ ux ].pcQueueName = NULL;\n\n                /* Set the handle to NULL to ensure the same queue handle cannot\n                 * appear in the registry twice if it is added, removed, then\n                 * added again. */\n                xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;\n                break;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        traceRETURN_vQueueUnregisterQueue();\n    }\n\n#endif /* configQUEUE_REGISTRY_SIZE */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TIMERS == 1 )\n\n    void vQueueWaitForMessageRestricted( QueueHandle_t xQueue,\n                                         TickType_t xTicksToWait,\n                                         const BaseType_t xWaitIndefinitely )\n    {\n        Queue_t * const pxQueue = xQueue;\n\n        traceENTER_vQueueWaitForMessageRestricted( xQueue, xTicksToWait, xWaitIndefinitely );\n\n        /* This function should not be called by application code hence the\n         * 'Restricted' in its name.  It is not part of the public API.  It is\n         * designed for use by kernel code, and has special calling requirements.\n         * It can result in vListInsert() being called on a list that can only\n         * possibly ever have one item in it, so the list will be fast, but even\n         * so it should be called with the scheduler locked and not from a critical\n         * section. */\n\n        /* Only do anything if there are no messages in the queue.  This function\n         *  will not actually cause the task to block, just place it on a blocked\n         *  list.  It will not block until the scheduler is unlocked - at which\n         *  time a yield will be performed.  If an item is added to the queue while\n         *  the queue is locked, and the calling task blocks on the queue, then the\n         *  calling task will be immediately unblocked when the queue is unlocked. */\n        prvLockQueue( pxQueue );\n\n        if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0U )\n        {\n            /* There is nothing in the queue, block for the specified period. */\n            vTaskPlaceOnEventListRestricted( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait, xWaitIndefinitely );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        prvUnlockQueue( pxQueue );\n\n        traceRETURN_vQueueWaitForMessageRestricted();\n    }\n\n#endif /* configUSE_TIMERS */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_QUEUE_SETS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n\n    QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength )\n    {\n        QueueSetHandle_t pxQueue;\n\n        traceENTER_xQueueCreateSet( uxEventQueueLength );\n\n        pxQueue = xQueueGenericCreate( uxEventQueueLength, ( UBaseType_t ) sizeof( Queue_t * ), queueQUEUE_TYPE_SET );\n\n        traceRETURN_xQueueCreateSet( pxQueue );\n\n        return pxQueue;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n    BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore,\n                               QueueSetHandle_t xQueueSet )\n    {\n        BaseType_t xReturn;\n\n        traceENTER_xQueueAddToSet( xQueueOrSemaphore, xQueueSet );\n\n        taskENTER_CRITICAL();\n        {\n            if( ( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer != NULL )\n            {\n                /* Cannot add a queue/semaphore to more than one queue set. */\n                xReturn = pdFAIL;\n            }\n            else if( ( ( Queue_t * ) xQueueOrSemaphore )->uxMessagesWaiting != ( UBaseType_t ) 0 )\n            {\n                /* Cannot add a queue/semaphore to a queue set if there are already\n                 * items in the queue/semaphore. */\n                xReturn = pdFAIL;\n            }\n            else\n            {\n                ( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer = xQueueSet;\n                xReturn = pdPASS;\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xQueueAddToSet( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n    BaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore,\n                                    QueueSetHandle_t xQueueSet )\n    {\n        BaseType_t xReturn;\n        Queue_t * const pxQueueOrSemaphore = ( Queue_t * ) xQueueOrSemaphore;\n\n        traceENTER_xQueueRemoveFromSet( xQueueOrSemaphore, xQueueSet );\n\n        if( pxQueueOrSemaphore->pxQueueSetContainer != xQueueSet )\n        {\n            /* The queue was not a member of the set. */\n            xReturn = pdFAIL;\n        }\n        else if( pxQueueOrSemaphore->uxMessagesWaiting != ( UBaseType_t ) 0 )\n        {\n            /* It is dangerous to remove a queue from a set when the queue is\n             * not empty because the queue set will still hold pending events for\n             * the queue. */\n            xReturn = pdFAIL;\n        }\n        else\n        {\n            taskENTER_CRITICAL();\n            {\n                /* The queue is no longer contained in the set. */\n                pxQueueOrSemaphore->pxQueueSetContainer = NULL;\n            }\n            taskEXIT_CRITICAL();\n            xReturn = pdPASS;\n        }\n\n        traceRETURN_xQueueRemoveFromSet( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n    QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet,\n                                                TickType_t const xTicksToWait )\n    {\n        QueueSetMemberHandle_t xReturn = NULL;\n\n        traceENTER_xQueueSelectFromSet( xQueueSet, xTicksToWait );\n\n        ( void ) xQueueReceive( ( QueueHandle_t ) xQueueSet, &xReturn, xTicksToWait );\n\n        traceRETURN_xQueueSelectFromSet( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n    QueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet )\n    {\n        QueueSetMemberHandle_t xReturn = NULL;\n\n        traceENTER_xQueueSelectFromSetFromISR( xQueueSet );\n\n        ( void ) xQueueReceiveFromISR( ( QueueHandle_t ) xQueueSet, &xReturn, NULL );\n\n        traceRETURN_xQueueSelectFromSetFromISR( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_QUEUE_SETS == 1 )\n\n    static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue )\n    {\n        Queue_t * pxQueueSetContainer = pxQueue->pxQueueSetContainer;\n        BaseType_t xReturn = pdFALSE;\n\n        /* This function must be called form a critical section. */\n\n        /* The following line is not reachable in unit tests because every call\n         * to prvNotifyQueueSetContainer is preceded by a check that\n         * pxQueueSetContainer != NULL */\n        configASSERT( pxQueueSetContainer ); /* LCOV_EXCL_BR_LINE */\n        configASSERT( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength );\n\n        if( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength )\n        {\n            const int8_t cTxLock = pxQueueSetContainer->cTxLock;\n\n            traceQUEUE_SET_SEND( pxQueueSetContainer );\n\n            /* The data copied is the handle of the queue that contains data. */\n            xReturn = prvCopyDataToQueue( pxQueueSetContainer, &pxQueue, queueSEND_TO_BACK );\n\n            if( cTxLock == queueUNLOCKED )\n            {\n                if( listLIST_IS_EMPTY( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) == pdFALSE )\n                {\n                    if( xTaskRemoveFromEventList( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) != pdFALSE )\n                    {\n                        /* The task waiting has a higher priority. */\n                        xReturn = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                prvIncrementQueueTxLock( pxQueueSetContainer, cTxLock );\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        return xReturn;\n    }\n\n#endif /* configUSE_QUEUE_SETS */\n"
        },
        {
          "name": "stream_buffer.c",
          "type": "blob",
          "size": 73.5537109375,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n/* Standard includes. */\n#include <string.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers.  That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"stream_buffer.h\"\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined\n * for the header files above, but not in this file, in order to generate the\n * correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* This entire source file will be skipped if the application is not configured\n * to include stream buffer functionality. This #if is closed at the very bottom\n * of this file. If you want to include stream buffers then ensure\n * configUSE_STREAM_BUFFERS is set to 1 in FreeRTOSConfig.h. */\n#if ( configUSE_STREAM_BUFFERS == 1 )\n\n    #if ( configUSE_TASK_NOTIFICATIONS != 1 )\n        #error configUSE_TASK_NOTIFICATIONS must be set to 1 to build stream_buffer.c\n    #endif\n\n    #if ( INCLUDE_xTaskGetCurrentTaskHandle != 1 )\n        #error INCLUDE_xTaskGetCurrentTaskHandle must be set to 1 to build stream_buffer.c\n    #endif\n\n/* If the user has not provided application specific Rx notification macros,\n * or #defined the notification macros away, then provide default implementations\n * that uses task notifications. */\n    #ifndef sbRECEIVE_COMPLETED\n        #define sbRECEIVE_COMPLETED( pxStreamBuffer )                                 \\\n    do                                                                                \\\n    {                                                                                 \\\n        vTaskSuspendAll();                                                            \\\n        {                                                                             \\\n            if( ( pxStreamBuffer )->xTaskWaitingToSend != NULL )                      \\\n            {                                                                         \\\n                ( void ) xTaskNotifyIndexed( ( pxStreamBuffer )->xTaskWaitingToSend,  \\\n                                             ( pxStreamBuffer )->uxNotificationIndex, \\\n                                             ( uint32_t ) 0,                          \\\n                                             eNoAction );                             \\\n                ( pxStreamBuffer )->xTaskWaitingToSend = NULL;                        \\\n            }                                                                         \\\n        }                                                                             \\\n        ( void ) xTaskResumeAll();                                                    \\\n    } while( 0 )\n    #endif /* sbRECEIVE_COMPLETED */\n\n/* If user has provided a per-instance receive complete callback, then\n * invoke the callback else use the receive complete macro which is provided by default for all instances.\n */\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n        #define prvRECEIVE_COMPLETED( pxStreamBuffer )                                           \\\n    do {                                                                                         \\\n        if( ( pxStreamBuffer )->pxReceiveCompletedCallback != NULL )                             \\\n        {                                                                                        \\\n            ( pxStreamBuffer )->pxReceiveCompletedCallback( ( pxStreamBuffer ), pdFALSE, NULL ); \\\n        }                                                                                        \\\n        else                                                                                     \\\n        {                                                                                        \\\n            sbRECEIVE_COMPLETED( ( pxStreamBuffer ) );                                           \\\n        }                                                                                        \\\n    } while( 0 )\n    #else /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n        #define prvRECEIVE_COMPLETED( pxStreamBuffer )    sbRECEIVE_COMPLETED( ( pxStreamBuffer ) )\n    #endif /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n\n    #ifndef sbRECEIVE_COMPLETED_FROM_ISR\n        #define sbRECEIVE_COMPLETED_FROM_ISR( pxStreamBuffer,                                \\\n                                              pxHigherPriorityTaskWoken )                    \\\n    do {                                                                                     \\\n        UBaseType_t uxSavedInterruptStatus;                                                  \\\n                                                                                             \\\n        uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();                              \\\n        {                                                                                    \\\n            if( ( pxStreamBuffer )->xTaskWaitingToSend != NULL )                             \\\n            {                                                                                \\\n                ( void ) xTaskNotifyIndexedFromISR( ( pxStreamBuffer )->xTaskWaitingToSend,  \\\n                                                    ( pxStreamBuffer )->uxNotificationIndex, \\\n                                                    ( uint32_t ) 0,                          \\\n                                                    eNoAction,                               \\\n                                                    ( pxHigherPriorityTaskWoken ) );         \\\n                ( pxStreamBuffer )->xTaskWaitingToSend = NULL;                               \\\n            }                                                                                \\\n        }                                                                                    \\\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );                                \\\n    } while( 0 )\n    #endif /* sbRECEIVE_COMPLETED_FROM_ISR */\n\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n        #define prvRECEIVE_COMPLETED_FROM_ISR( pxStreamBuffer,                                                           \\\n                                               pxHigherPriorityTaskWoken )                                               \\\n    do {                                                                                                                 \\\n        if( ( pxStreamBuffer )->pxReceiveCompletedCallback != NULL )                                                     \\\n        {                                                                                                                \\\n            ( pxStreamBuffer )->pxReceiveCompletedCallback( ( pxStreamBuffer ), pdTRUE, ( pxHigherPriorityTaskWoken ) ); \\\n        }                                                                                                                \\\n        else                                                                                                             \\\n        {                                                                                                                \\\n            sbRECEIVE_COMPLETED_FROM_ISR( ( pxStreamBuffer ), ( pxHigherPriorityTaskWoken ) );                           \\\n        }                                                                                                                \\\n    } while( 0 )\n    #else /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n        #define prvRECEIVE_COMPLETED_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken ) \\\n    sbRECEIVE_COMPLETED_FROM_ISR( ( pxStreamBuffer ), ( pxHigherPriorityTaskWoken ) )\n    #endif /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n\n/* If the user has not provided an application specific Tx notification macro,\n * or #defined the notification macro away, then provide a default\n * implementation that uses task notifications.\n */\n    #ifndef sbSEND_COMPLETED\n        #define sbSEND_COMPLETED( pxStreamBuffer )                                  \\\n    vTaskSuspendAll();                                                              \\\n    {                                                                               \\\n        if( ( pxStreamBuffer )->xTaskWaitingToReceive != NULL )                     \\\n        {                                                                           \\\n            ( void ) xTaskNotifyIndexed( ( pxStreamBuffer )->xTaskWaitingToReceive, \\\n                                         ( pxStreamBuffer )->uxNotificationIndex,   \\\n                                         ( uint32_t ) 0,                            \\\n                                         eNoAction );                               \\\n            ( pxStreamBuffer )->xTaskWaitingToReceive = NULL;                       \\\n        }                                                                           \\\n    }                                                                               \\\n    ( void ) xTaskResumeAll()\n    #endif /* sbSEND_COMPLETED */\n\n/* If user has provided a per-instance send completed callback, then\n * invoke the callback else use the send complete macro which is provided by default for all instances.\n */\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n        #define prvSEND_COMPLETED( pxStreamBuffer )                                           \\\n    do {                                                                                      \\\n        if( ( pxStreamBuffer )->pxSendCompletedCallback != NULL )                             \\\n        {                                                                                     \\\n            ( pxStreamBuffer )->pxSendCompletedCallback( ( pxStreamBuffer ), pdFALSE, NULL ); \\\n        }                                                                                     \\\n        else                                                                                  \\\n        {                                                                                     \\\n            sbSEND_COMPLETED( ( pxStreamBuffer ) );                                           \\\n        }                                                                                     \\\n    } while( 0 )\n    #else /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n        #define prvSEND_COMPLETED( pxStreamBuffer )    sbSEND_COMPLETED( ( pxStreamBuffer ) )\n    #endif /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n\n\n    #ifndef sbSEND_COMPLETE_FROM_ISR\n        #define sbSEND_COMPLETE_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken )          \\\n    do {                                                                                       \\\n        UBaseType_t uxSavedInterruptStatus;                                                    \\\n                                                                                               \\\n        uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();                                \\\n        {                                                                                      \\\n            if( ( pxStreamBuffer )->xTaskWaitingToReceive != NULL )                            \\\n            {                                                                                  \\\n                ( void ) xTaskNotifyIndexedFromISR( ( pxStreamBuffer )->xTaskWaitingToReceive, \\\n                                                    ( pxStreamBuffer )->uxNotificationIndex,   \\\n                                                    ( uint32_t ) 0,                            \\\n                                                    eNoAction,                                 \\\n                                                    ( pxHigherPriorityTaskWoken ) );           \\\n                ( pxStreamBuffer )->xTaskWaitingToReceive = NULL;                              \\\n            }                                                                                  \\\n        }                                                                                      \\\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );                                  \\\n    } while( 0 )\n    #endif /* sbSEND_COMPLETE_FROM_ISR */\n\n\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n        #define prvSEND_COMPLETE_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken )                                \\\n    do {                                                                                                              \\\n        if( ( pxStreamBuffer )->pxSendCompletedCallback != NULL )                                                     \\\n        {                                                                                                             \\\n            ( pxStreamBuffer )->pxSendCompletedCallback( ( pxStreamBuffer ), pdTRUE, ( pxHigherPriorityTaskWoken ) ); \\\n        }                                                                                                             \\\n        else                                                                                                          \\\n        {                                                                                                             \\\n            sbSEND_COMPLETE_FROM_ISR( ( pxStreamBuffer ), ( pxHigherPriorityTaskWoken ) );                            \\\n        }                                                                                                             \\\n    } while( 0 )\n    #else /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n        #define prvSEND_COMPLETE_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken ) \\\n    sbSEND_COMPLETE_FROM_ISR( ( pxStreamBuffer ), ( pxHigherPriorityTaskWoken ) )\n    #endif /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n\n/* The number of bytes used to hold the length of a message in the buffer. */\n    #define sbBYTES_TO_STORE_MESSAGE_LENGTH    ( sizeof( configMESSAGE_BUFFER_LENGTH_TYPE ) )\n\n/* Bits stored in the ucFlags field of the stream buffer. */\n    #define sbFLAGS_IS_MESSAGE_BUFFER          ( ( uint8_t ) 1 ) /* Set if the stream buffer was created as a message buffer, in which case it holds discrete messages rather than a stream. */\n    #define sbFLAGS_IS_STATICALLY_ALLOCATED    ( ( uint8_t ) 2 ) /* Set if the stream buffer was created using statically allocated memory. */\n    #define sbFLAGS_IS_BATCHING_BUFFER         ( ( uint8_t ) 4 ) /* Set if the stream buffer was created as a batching buffer, meaning the receiver task will only unblock when the trigger level exceededs. */\n\n/*-----------------------------------------------------------*/\n\n/* Structure that hold state information on the buffer. */\ntypedef struct StreamBufferDef_t\n{\n    volatile size_t xTail;                       /* Index to the next item to read within the buffer. */\n    volatile size_t xHead;                       /* Index to the next item to write within the buffer. */\n    size_t xLength;                              /* The length of the buffer pointed to by pucBuffer. */\n    size_t xTriggerLevelBytes;                   /* The number of bytes that must be in the stream buffer before a task that is waiting for data is unblocked. */\n    volatile TaskHandle_t xTaskWaitingToReceive; /* Holds the handle of a task waiting for data, or NULL if no tasks are waiting. */\n    volatile TaskHandle_t xTaskWaitingToSend;    /* Holds the handle of a task waiting to send data to a message buffer that is full. */\n    uint8_t * pucBuffer;                         /* Points to the buffer itself - that is - the RAM that stores the data passed through the buffer. */\n    uint8_t ucFlags;\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n        UBaseType_t uxStreamBufferNumber; /* Used for tracing purposes. */\n    #endif\n\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n        StreamBufferCallbackFunction_t pxSendCompletedCallback;    /* Optional callback called on send complete. sbSEND_COMPLETED is called if this is NULL. */\n        StreamBufferCallbackFunction_t pxReceiveCompletedCallback; /* Optional callback called on receive complete.  sbRECEIVE_COMPLETED is called if this is NULL. */\n    #endif\n    UBaseType_t uxNotificationIndex;                               /* The index we are using for notification, by default tskDEFAULT_INDEX_TO_NOTIFY. */\n} StreamBuffer_t;\n\n/*\n * The number of bytes available to be read from the buffer.\n */\nstatic size_t prvBytesInBuffer( const StreamBuffer_t * const pxStreamBuffer ) PRIVILEGED_FUNCTION;\n\n/*\n * Add xCount bytes from pucData into the pxStreamBuffer's data storage area.\n * This function does not update the buffer's xHead pointer, so multiple writes\n * may be chained together \"atomically\". This is useful for Message Buffers where\n * the length and data bytes are written in two separate chunks, and we don't want\n * the reader to see the buffer as having grown until after all data is copied over.\n * This function takes a custom xHead value to indicate where to write to (necessary\n * for chaining) and returns the the resulting xHead position.\n * To mark the write as complete, manually set the buffer's xHead field with the\n * returned xHead from this function.\n */\nstatic size_t prvWriteBytesToBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                     const uint8_t * pucData,\n                                     size_t xCount,\n                                     size_t xHead ) PRIVILEGED_FUNCTION;\n\n/*\n * If the stream buffer is being used as a message buffer, then reads an entire\n * message out of the buffer.  If the stream buffer is being used as a stream\n * buffer then read as many bytes as possible from the buffer.\n * prvReadBytesFromBuffer() is called to actually extract the bytes from the\n * buffer's data storage area.\n */\nstatic size_t prvReadMessageFromBuffer( StreamBuffer_t * pxStreamBuffer,\n                                        void * pvRxData,\n                                        size_t xBufferLengthBytes,\n                                        size_t xBytesAvailable ) PRIVILEGED_FUNCTION;\n\n/*\n * If the stream buffer is being used as a message buffer, then writes an entire\n * message to the buffer.  If the stream buffer is being used as a stream\n * buffer then write as many bytes as possible to the buffer.\n * prvWriteBytestoBuffer() is called to actually send the bytes to the buffer's\n * data storage area.\n */\nstatic size_t prvWriteMessageToBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                       const void * pvTxData,\n                                       size_t xDataLengthBytes,\n                                       size_t xSpace,\n                                       size_t xRequiredSpace ) PRIVILEGED_FUNCTION;\n\n/*\n * Copies xCount bytes from the pxStreamBuffer's data storage area to pucData.\n * This function does not update the buffer's xTail pointer, so multiple reads\n * may be chained together \"atomically\". This is useful for Message Buffers where\n * the length and data bytes are read in two separate chunks, and we don't want\n * the writer to see the buffer as having more free space until after all data is\n * copied over, especially if we have to abort the read due to insufficient receiving space.\n * This function takes a custom xTail value to indicate where to read from (necessary\n * for chaining) and returns the the resulting xTail position.\n * To mark the read as complete, manually set the buffer's xTail field with the\n * returned xTail from this function.\n */\nstatic size_t prvReadBytesFromBuffer( StreamBuffer_t * pxStreamBuffer,\n                                      uint8_t * pucData,\n                                      size_t xCount,\n                                      size_t xTail ) PRIVILEGED_FUNCTION;\n\n/*\n * Called by both pxStreamBufferCreate() and pxStreamBufferCreateStatic() to\n * initialise the members of the newly created stream buffer structure.\n */\nstatic void prvInitialiseNewStreamBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                          uint8_t * const pucBuffer,\n                                          size_t xBufferSizeBytes,\n                                          size_t xTriggerLevelBytes,\n                                          uint8_t ucFlags,\n                                          StreamBufferCallbackFunction_t pxSendCompletedCallback,\n                                          StreamBufferCallbackFunction_t pxReceiveCompletedCallback ) PRIVILEGED_FUNCTION;\n\n/*-----------------------------------------------------------*/\n    #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n    StreamBufferHandle_t xStreamBufferGenericCreate( size_t xBufferSizeBytes,\n                                                     size_t xTriggerLevelBytes,\n                                                     BaseType_t xStreamBufferType,\n                                                     StreamBufferCallbackFunction_t pxSendCompletedCallback,\n                                                     StreamBufferCallbackFunction_t pxReceiveCompletedCallback )\n    {\n        void * pvAllocatedMemory;\n        uint8_t ucFlags;\n\n        traceENTER_xStreamBufferGenericCreate( xBufferSizeBytes, xTriggerLevelBytes, xStreamBufferType, pxSendCompletedCallback, pxReceiveCompletedCallback );\n\n        /* In case the stream buffer is going to be used as a message buffer\n         * (that is, it will hold discrete messages with a little meta data that\n         * says how big the next message is) check the buffer will be large enough\n         * to hold at least one message. */\n        if( xStreamBufferType == sbTYPE_MESSAGE_BUFFER )\n        {\n            /* Is a message buffer but not statically allocated. */\n            ucFlags = sbFLAGS_IS_MESSAGE_BUFFER;\n            configASSERT( xBufferSizeBytes > sbBYTES_TO_STORE_MESSAGE_LENGTH );\n        }\n        else if( xStreamBufferType == sbTYPE_STREAM_BATCHING_BUFFER )\n        {\n            /* Is a batching buffer but not statically allocated. */\n            ucFlags = sbFLAGS_IS_BATCHING_BUFFER;\n            configASSERT( xBufferSizeBytes > 0 );\n        }\n        else\n        {\n            /* Not a message buffer and not statically allocated. */\n            ucFlags = 0;\n            configASSERT( xBufferSizeBytes > 0 );\n        }\n\n        configASSERT( xTriggerLevelBytes <= xBufferSizeBytes );\n\n        /* A trigger level of 0 would cause a waiting task to unblock even when\n         * the buffer was empty. */\n        if( xTriggerLevelBytes == ( size_t ) 0 )\n        {\n            xTriggerLevelBytes = ( size_t ) 1;\n        }\n\n        /* A stream buffer requires a StreamBuffer_t structure and a buffer.\n         * Both are allocated in a single call to pvPortMalloc().  The\n         * StreamBuffer_t structure is placed at the start of the allocated memory\n         * and the buffer follows immediately after.  The requested size is\n         * incremented so the free space is returned as the user would expect -\n         * this is a quirk of the implementation that means otherwise the free\n         * space would be reported as one byte smaller than would be logically\n         * expected. */\n        if( xBufferSizeBytes < ( xBufferSizeBytes + 1U + sizeof( StreamBuffer_t ) ) )\n        {\n            xBufferSizeBytes++;\n            pvAllocatedMemory = pvPortMalloc( xBufferSizeBytes + sizeof( StreamBuffer_t ) );\n        }\n        else\n        {\n            pvAllocatedMemory = NULL;\n        }\n\n        if( pvAllocatedMemory != NULL )\n        {\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            prvInitialiseNewStreamBuffer( ( StreamBuffer_t * ) pvAllocatedMemory,                         /* Structure at the start of the allocated memory. */\n                                                                                                          /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n                                                                                                          /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                                                                                                          /* coverity[misra_c_2012_rule_11_5_violation] */\n                                          ( ( uint8_t * ) pvAllocatedMemory ) + sizeof( StreamBuffer_t ), /* Storage area follows. */\n                                          xBufferSizeBytes,\n                                          xTriggerLevelBytes,\n                                          ucFlags,\n                                          pxSendCompletedCallback,\n                                          pxReceiveCompletedCallback );\n\n            traceSTREAM_BUFFER_CREATE( ( ( StreamBuffer_t * ) pvAllocatedMemory ), xStreamBufferType );\n        }\n        else\n        {\n            traceSTREAM_BUFFER_CREATE_FAILED( xStreamBufferType );\n        }\n\n        traceRETURN_xStreamBufferGenericCreate( pvAllocatedMemory );\n\n        /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        return ( StreamBufferHandle_t ) pvAllocatedMemory;\n    }\n    #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n    StreamBufferHandle_t xStreamBufferGenericCreateStatic( size_t xBufferSizeBytes,\n                                                           size_t xTriggerLevelBytes,\n                                                           BaseType_t xStreamBufferType,\n                                                           uint8_t * const pucStreamBufferStorageArea,\n                                                           StaticStreamBuffer_t * const pxStaticStreamBuffer,\n                                                           StreamBufferCallbackFunction_t pxSendCompletedCallback,\n                                                           StreamBufferCallbackFunction_t pxReceiveCompletedCallback )\n    {\n        /* MISRA Ref 11.3.1 [Misaligned access] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n        /* coverity[misra_c_2012_rule_11_3_violation] */\n        StreamBuffer_t * const pxStreamBuffer = ( StreamBuffer_t * ) pxStaticStreamBuffer;\n        StreamBufferHandle_t xReturn;\n        uint8_t ucFlags;\n\n        traceENTER_xStreamBufferGenericCreateStatic( xBufferSizeBytes, xTriggerLevelBytes, xStreamBufferType, pucStreamBufferStorageArea, pxStaticStreamBuffer, pxSendCompletedCallback, pxReceiveCompletedCallback );\n\n        configASSERT( pucStreamBufferStorageArea );\n        configASSERT( pxStaticStreamBuffer );\n        configASSERT( xTriggerLevelBytes <= xBufferSizeBytes );\n\n        /* A trigger level of 0 would cause a waiting task to unblock even when\n         * the buffer was empty. */\n        if( xTriggerLevelBytes == ( size_t ) 0 )\n        {\n            xTriggerLevelBytes = ( size_t ) 1;\n        }\n\n        /* In case the stream buffer is going to be used as a message buffer\n         * (that is, it will hold discrete messages with a little meta data that\n         * says how big the next message is) check the buffer will be large enough\n         * to hold at least one message. */\n\n        if( xStreamBufferType == sbTYPE_MESSAGE_BUFFER )\n        {\n            /* Statically allocated message buffer. */\n            ucFlags = sbFLAGS_IS_MESSAGE_BUFFER | sbFLAGS_IS_STATICALLY_ALLOCATED;\n            configASSERT( xBufferSizeBytes > sbBYTES_TO_STORE_MESSAGE_LENGTH );\n        }\n        else if( xStreamBufferType == sbTYPE_STREAM_BATCHING_BUFFER )\n        {\n            /* Statically allocated batching buffer. */\n            ucFlags = sbFLAGS_IS_BATCHING_BUFFER | sbFLAGS_IS_STATICALLY_ALLOCATED;\n            configASSERT( xBufferSizeBytes > 0 );\n        }\n        else\n        {\n            /* Statically allocated stream buffer. */\n            ucFlags = sbFLAGS_IS_STATICALLY_ALLOCATED;\n        }\n\n        #if ( configASSERT_DEFINED == 1 )\n        {\n            /* Sanity check that the size of the structure used to declare a\n             * variable of type StaticStreamBuffer_t equals the size of the real\n             * message buffer structure. */\n            volatile size_t xSize = sizeof( StaticStreamBuffer_t );\n            configASSERT( xSize == sizeof( StreamBuffer_t ) );\n        }\n        #endif /* configASSERT_DEFINED */\n\n        if( ( pucStreamBufferStorageArea != NULL ) && ( pxStaticStreamBuffer != NULL ) )\n        {\n            prvInitialiseNewStreamBuffer( pxStreamBuffer,\n                                          pucStreamBufferStorageArea,\n                                          xBufferSizeBytes,\n                                          xTriggerLevelBytes,\n                                          ucFlags,\n                                          pxSendCompletedCallback,\n                                          pxReceiveCompletedCallback );\n\n            /* Remember this was statically allocated in case it is ever deleted\n             * again. */\n            pxStreamBuffer->ucFlags |= sbFLAGS_IS_STATICALLY_ALLOCATED;\n\n            traceSTREAM_BUFFER_CREATE( pxStreamBuffer, xStreamBufferType );\n\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            xReturn = ( StreamBufferHandle_t ) pxStaticStreamBuffer;\n        }\n        else\n        {\n            xReturn = NULL;\n            traceSTREAM_BUFFER_CREATE_STATIC_FAILED( xReturn, xStreamBufferType );\n        }\n\n        traceRETURN_xStreamBufferGenericCreateStatic( xReturn );\n\n        return xReturn;\n    }\n    #endif /* ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n    BaseType_t xStreamBufferGetStaticBuffers( StreamBufferHandle_t xStreamBuffer,\n                                              uint8_t ** ppucStreamBufferStorageArea,\n                                              StaticStreamBuffer_t ** ppxStaticStreamBuffer )\n    {\n        BaseType_t xReturn;\n        StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n\n        traceENTER_xStreamBufferGetStaticBuffers( xStreamBuffer, ppucStreamBufferStorageArea, ppxStaticStreamBuffer );\n\n        configASSERT( pxStreamBuffer );\n        configASSERT( ppucStreamBufferStorageArea );\n        configASSERT( ppxStaticStreamBuffer );\n\n        if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_STATICALLY_ALLOCATED ) != ( uint8_t ) 0 )\n        {\n            *ppucStreamBufferStorageArea = pxStreamBuffer->pucBuffer;\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            *ppxStaticStreamBuffer = ( StaticStreamBuffer_t * ) pxStreamBuffer;\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n\n        traceRETURN_xStreamBufferGetStaticBuffers( xReturn );\n\n        return xReturn;\n    }\n    #endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\nvoid vStreamBufferDelete( StreamBufferHandle_t xStreamBuffer )\n{\n    StreamBuffer_t * pxStreamBuffer = xStreamBuffer;\n\n    traceENTER_vStreamBufferDelete( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    traceSTREAM_BUFFER_DELETE( xStreamBuffer );\n\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_STATICALLY_ALLOCATED ) == ( uint8_t ) pdFALSE )\n    {\n        #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n        {\n            /* Both the structure and the buffer were allocated using a single call\n            * to pvPortMalloc(), hence only one call to vPortFree() is required. */\n            vPortFree( ( void * ) pxStreamBuffer );\n        }\n        #else\n        {\n            /* Should not be possible to get here, ucFlags must be corrupt.\n             * Force an assert. */\n            configASSERT( xStreamBuffer == ( StreamBufferHandle_t ) ~0 );\n        }\n        #endif\n    }\n    else\n    {\n        /* The structure and buffer were not allocated dynamically and cannot be\n         * freed - just scrub the structure so future use will assert. */\n        ( void ) memset( pxStreamBuffer, 0x00, sizeof( StreamBuffer_t ) );\n    }\n\n    traceRETURN_vStreamBufferDelete();\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferReset( StreamBufferHandle_t xStreamBuffer )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn = pdFAIL;\n    StreamBufferCallbackFunction_t pxSendCallback = NULL, pxReceiveCallback = NULL;\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n        UBaseType_t uxStreamBufferNumber;\n    #endif\n\n    traceENTER_xStreamBufferReset( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n    {\n        /* Store the stream buffer number so it can be restored after the\n         * reset. */\n        uxStreamBufferNumber = pxStreamBuffer->uxStreamBufferNumber;\n    }\n    #endif\n\n    /* Can only reset a message buffer if there are no tasks blocked on it. */\n    taskENTER_CRITICAL();\n    {\n        if( ( pxStreamBuffer->xTaskWaitingToReceive == NULL ) && ( pxStreamBuffer->xTaskWaitingToSend == NULL ) )\n        {\n            #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n            {\n                pxSendCallback = pxStreamBuffer->pxSendCompletedCallback;\n                pxReceiveCallback = pxStreamBuffer->pxReceiveCompletedCallback;\n            }\n            #endif\n\n            prvInitialiseNewStreamBuffer( pxStreamBuffer,\n                                          pxStreamBuffer->pucBuffer,\n                                          pxStreamBuffer->xLength,\n                                          pxStreamBuffer->xTriggerLevelBytes,\n                                          pxStreamBuffer->ucFlags,\n                                          pxSendCallback,\n                                          pxReceiveCallback );\n\n            #if ( configUSE_TRACE_FACILITY == 1 )\n            {\n                pxStreamBuffer->uxStreamBufferNumber = uxStreamBufferNumber;\n            }\n            #endif\n\n            traceSTREAM_BUFFER_RESET( xStreamBuffer );\n\n            xReturn = pdPASS;\n        }\n    }\n    taskEXIT_CRITICAL();\n\n    traceRETURN_xStreamBufferReset( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferResetFromISR( StreamBufferHandle_t xStreamBuffer )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn = pdFAIL;\n    StreamBufferCallbackFunction_t pxSendCallback = NULL, pxReceiveCallback = NULL;\n    UBaseType_t uxSavedInterruptStatus;\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n        UBaseType_t uxStreamBufferNumber;\n    #endif\n\n    traceENTER_xStreamBufferResetFromISR( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n    {\n        /* Store the stream buffer number so it can be restored after the\n         * reset. */\n        uxStreamBufferNumber = pxStreamBuffer->uxStreamBufferNumber;\n    }\n    #endif\n\n    /* Can only reset a message buffer if there are no tasks blocked on it. */\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n    {\n        if( ( pxStreamBuffer->xTaskWaitingToReceive == NULL ) && ( pxStreamBuffer->xTaskWaitingToSend == NULL ) )\n        {\n            #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n            {\n                pxSendCallback = pxStreamBuffer->pxSendCompletedCallback;\n                pxReceiveCallback = pxStreamBuffer->pxReceiveCompletedCallback;\n            }\n            #endif\n\n            prvInitialiseNewStreamBuffer( pxStreamBuffer,\n                                          pxStreamBuffer->pucBuffer,\n                                          pxStreamBuffer->xLength,\n                                          pxStreamBuffer->xTriggerLevelBytes,\n                                          pxStreamBuffer->ucFlags,\n                                          pxSendCallback,\n                                          pxReceiveCallback );\n\n            #if ( configUSE_TRACE_FACILITY == 1 )\n            {\n                pxStreamBuffer->uxStreamBufferNumber = uxStreamBufferNumber;\n            }\n            #endif\n\n            traceSTREAM_BUFFER_RESET_FROM_ISR( xStreamBuffer );\n\n            xReturn = pdPASS;\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xStreamBufferResetFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferSetTriggerLevel( StreamBufferHandle_t xStreamBuffer,\n                                         size_t xTriggerLevel )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn;\n\n    traceENTER_xStreamBufferSetTriggerLevel( xStreamBuffer, xTriggerLevel );\n\n    configASSERT( pxStreamBuffer );\n\n    /* It is not valid for the trigger level to be 0. */\n    if( xTriggerLevel == ( size_t ) 0 )\n    {\n        xTriggerLevel = ( size_t ) 1;\n    }\n\n    /* The trigger level is the number of bytes that must be in the stream\n     * buffer before a task that is waiting for data is unblocked. */\n    if( xTriggerLevel < pxStreamBuffer->xLength )\n    {\n        pxStreamBuffer->xTriggerLevelBytes = xTriggerLevel;\n        xReturn = pdPASS;\n    }\n    else\n    {\n        xReturn = pdFALSE;\n    }\n\n    traceRETURN_xStreamBufferSetTriggerLevel( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferSpacesAvailable( StreamBufferHandle_t xStreamBuffer )\n{\n    const StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xSpace;\n    size_t xOriginalTail;\n\n    traceENTER_xStreamBufferSpacesAvailable( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    /* The code below reads xTail and then xHead.  This is safe if the stream\n     * buffer is updated once between the two reads - but not if the stream buffer\n     * is updated more than once between the two reads - hence the loop. */\n    do\n    {\n        xOriginalTail = pxStreamBuffer->xTail;\n        xSpace = pxStreamBuffer->xLength + pxStreamBuffer->xTail;\n        xSpace -= pxStreamBuffer->xHead;\n    } while( xOriginalTail != pxStreamBuffer->xTail );\n\n    xSpace -= ( size_t ) 1;\n\n    if( xSpace >= pxStreamBuffer->xLength )\n    {\n        xSpace -= pxStreamBuffer->xLength;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    traceRETURN_xStreamBufferSpacesAvailable( xSpace );\n\n    return xSpace;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferBytesAvailable( StreamBufferHandle_t xStreamBuffer )\n{\n    const StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReturn;\n\n    traceENTER_xStreamBufferBytesAvailable( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    xReturn = prvBytesInBuffer( pxStreamBuffer );\n\n    traceRETURN_xStreamBufferBytesAvailable( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferSend( StreamBufferHandle_t xStreamBuffer,\n                          const void * pvTxData,\n                          size_t xDataLengthBytes,\n                          TickType_t xTicksToWait )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReturn, xSpace = 0;\n    size_t xRequiredSpace = xDataLengthBytes;\n    TimeOut_t xTimeOut;\n    size_t xMaxReportedSpace = 0;\n\n    traceENTER_xStreamBufferSend( xStreamBuffer, pvTxData, xDataLengthBytes, xTicksToWait );\n\n    configASSERT( pvTxData );\n    configASSERT( pxStreamBuffer );\n\n    /* The maximum amount of space a stream buffer will ever report is its length\n     * minus 1. */\n    xMaxReportedSpace = pxStreamBuffer->xLength - ( size_t ) 1;\n\n    /* This send function is used to write to both message buffers and stream\n     * buffers.  If this is a message buffer then the space needed must be\n     * increased by the amount of bytes needed to store the length of the\n     * message. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xRequiredSpace += sbBYTES_TO_STORE_MESSAGE_LENGTH;\n\n        /* Overflow? */\n        configASSERT( xRequiredSpace > xDataLengthBytes );\n\n        /* If this is a message buffer then it must be possible to write the\n         * whole message. */\n        if( xRequiredSpace > xMaxReportedSpace )\n        {\n            /* The message would not fit even if the entire buffer was empty,\n             * so don't wait for space. */\n            xTicksToWait = ( TickType_t ) 0;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        /* If this is a stream buffer then it is acceptable to write only part\n         * of the message to the buffer.  Cap the length to the total length of\n         * the buffer. */\n        if( xRequiredSpace > xMaxReportedSpace )\n        {\n            xRequiredSpace = xMaxReportedSpace;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n\n    if( xTicksToWait != ( TickType_t ) 0 )\n    {\n        vTaskSetTimeOutState( &xTimeOut );\n\n        do\n        {\n            /* Wait until the required number of bytes are free in the message\n             * buffer. */\n            taskENTER_CRITICAL();\n            {\n                xSpace = xStreamBufferSpacesAvailable( pxStreamBuffer );\n\n                if( xSpace < xRequiredSpace )\n                {\n                    /* Clear notification state as going to wait for space. */\n                    ( void ) xTaskNotifyStateClearIndexed( NULL, pxStreamBuffer->uxNotificationIndex );\n\n                    /* Should only be one writer. */\n                    configASSERT( pxStreamBuffer->xTaskWaitingToSend == NULL );\n                    pxStreamBuffer->xTaskWaitingToSend = xTaskGetCurrentTaskHandle();\n                }\n                else\n                {\n                    taskEXIT_CRITICAL();\n                    break;\n                }\n            }\n            taskEXIT_CRITICAL();\n\n            traceBLOCKING_ON_STREAM_BUFFER_SEND( xStreamBuffer );\n            ( void ) xTaskNotifyWaitIndexed( pxStreamBuffer->uxNotificationIndex, ( uint32_t ) 0, ( uint32_t ) 0, NULL, xTicksToWait );\n            pxStreamBuffer->xTaskWaitingToSend = NULL;\n        } while( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE );\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    if( xSpace == ( size_t ) 0 )\n    {\n        xSpace = xStreamBufferSpacesAvailable( pxStreamBuffer );\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    xReturn = prvWriteMessageToBuffer( pxStreamBuffer, pvTxData, xDataLengthBytes, xSpace, xRequiredSpace );\n\n    if( xReturn > ( size_t ) 0 )\n    {\n        traceSTREAM_BUFFER_SEND( xStreamBuffer, xReturn );\n\n        /* Was a task waiting for the data? */\n        if( prvBytesInBuffer( pxStreamBuffer ) >= pxStreamBuffer->xTriggerLevelBytes )\n        {\n            prvSEND_COMPLETED( pxStreamBuffer );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n        traceSTREAM_BUFFER_SEND_FAILED( xStreamBuffer );\n    }\n\n    traceRETURN_xStreamBufferSend( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferSendFromISR( StreamBufferHandle_t xStreamBuffer,\n                                 const void * pvTxData,\n                                 size_t xDataLengthBytes,\n                                 BaseType_t * const pxHigherPriorityTaskWoken )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReturn, xSpace;\n    size_t xRequiredSpace = xDataLengthBytes;\n\n    traceENTER_xStreamBufferSendFromISR( xStreamBuffer, pvTxData, xDataLengthBytes, pxHigherPriorityTaskWoken );\n\n    configASSERT( pvTxData );\n    configASSERT( pxStreamBuffer );\n\n    /* This send function is used to write to both message buffers and stream\n     * buffers.  If this is a message buffer then the space needed must be\n     * increased by the amount of bytes needed to store the length of the\n     * message. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xRequiredSpace += sbBYTES_TO_STORE_MESSAGE_LENGTH;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    xSpace = xStreamBufferSpacesAvailable( pxStreamBuffer );\n    xReturn = prvWriteMessageToBuffer( pxStreamBuffer, pvTxData, xDataLengthBytes, xSpace, xRequiredSpace );\n\n    if( xReturn > ( size_t ) 0 )\n    {\n        /* Was a task waiting for the data? */\n        if( prvBytesInBuffer( pxStreamBuffer ) >= pxStreamBuffer->xTriggerLevelBytes )\n        {\n            /* MISRA Ref 4.7.1 [Return value shall be checked] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n            /* coverity[misra_c_2012_directive_4_7_violation] */\n            prvSEND_COMPLETE_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    traceSTREAM_BUFFER_SEND_FROM_ISR( xStreamBuffer, xReturn );\n    traceRETURN_xStreamBufferSendFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nstatic size_t prvWriteMessageToBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                       const void * pvTxData,\n                                       size_t xDataLengthBytes,\n                                       size_t xSpace,\n                                       size_t xRequiredSpace )\n{\n    size_t xNextHead = pxStreamBuffer->xHead;\n    configMESSAGE_BUFFER_LENGTH_TYPE xMessageLength;\n\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        /* This is a message buffer, as opposed to a stream buffer. */\n\n        /* Convert xDataLengthBytes to the message length type. */\n        xMessageLength = ( configMESSAGE_BUFFER_LENGTH_TYPE ) xDataLengthBytes;\n\n        /* Ensure the data length given fits within configMESSAGE_BUFFER_LENGTH_TYPE. */\n        configASSERT( ( size_t ) xMessageLength == xDataLengthBytes );\n\n        if( xSpace >= xRequiredSpace )\n        {\n            /* There is enough space to write both the message length and the message\n             * itself into the buffer.  Start by writing the length of the data, the data\n             * itself will be written later in this function. */\n            xNextHead = prvWriteBytesToBuffer( pxStreamBuffer, ( const uint8_t * ) &( xMessageLength ), sbBYTES_TO_STORE_MESSAGE_LENGTH, xNextHead );\n        }\n        else\n        {\n            /* Not enough space, so do not write data to the buffer. */\n            xDataLengthBytes = 0;\n        }\n    }\n    else\n    {\n        /* This is a stream buffer, as opposed to a message buffer, so writing a\n         * stream of bytes rather than discrete messages.  Plan to write as many\n         * bytes as possible. */\n        xDataLengthBytes = configMIN( xDataLengthBytes, xSpace );\n    }\n\n    if( xDataLengthBytes != ( size_t ) 0 )\n    {\n        /* Write the data to the buffer. */\n        /* MISRA Ref 11.5.5 [Void pointer assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        pxStreamBuffer->xHead = prvWriteBytesToBuffer( pxStreamBuffer, ( const uint8_t * ) pvTxData, xDataLengthBytes, xNextHead );\n    }\n\n    return xDataLengthBytes;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferReceive( StreamBufferHandle_t xStreamBuffer,\n                             void * pvRxData,\n                             size_t xBufferLengthBytes,\n                             TickType_t xTicksToWait )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReceivedLength = 0, xBytesAvailable, xBytesToStoreMessageLength;\n\n    traceENTER_xStreamBufferReceive( xStreamBuffer, pvRxData, xBufferLengthBytes, xTicksToWait );\n\n    configASSERT( pvRxData );\n    configASSERT( pxStreamBuffer );\n\n    /* This receive function is used by both message buffers, which store\n     * discrete messages, and stream buffers, which store a continuous stream of\n     * bytes.  Discrete messages include an additional\n     * sbBYTES_TO_STORE_MESSAGE_LENGTH bytes that hold the length of the\n     * message. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xBytesToStoreMessageLength = sbBYTES_TO_STORE_MESSAGE_LENGTH;\n    }\n    else if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_BATCHING_BUFFER ) != ( uint8_t ) 0 )\n    {\n        /* Force task to block if the batching buffer contains less bytes than\n         * the trigger level. */\n        xBytesToStoreMessageLength = pxStreamBuffer->xTriggerLevelBytes;\n    }\n    else\n    {\n        xBytesToStoreMessageLength = 0;\n    }\n\n    if( xTicksToWait != ( TickType_t ) 0 )\n    {\n        /* Checking if there is data and clearing the notification state must be\n         * performed atomically. */\n        taskENTER_CRITICAL();\n        {\n            xBytesAvailable = prvBytesInBuffer( pxStreamBuffer );\n\n            /* If this function was invoked by a message buffer read then\n             * xBytesToStoreMessageLength holds the number of bytes used to hold\n             * the length of the next discrete message.  If this function was\n             * invoked by a stream buffer read then xBytesToStoreMessageLength will\n             * be 0. If this function was invoked by a stream batch buffer read\n             * then xBytesToStoreMessageLength will be xTriggerLevelBytes value\n             * for the buffer.*/\n            if( xBytesAvailable <= xBytesToStoreMessageLength )\n            {\n                /* Clear notification state as going to wait for data. */\n                ( void ) xTaskNotifyStateClearIndexed( NULL, pxStreamBuffer->uxNotificationIndex );\n\n                /* Should only be one reader. */\n                configASSERT( pxStreamBuffer->xTaskWaitingToReceive == NULL );\n                pxStreamBuffer->xTaskWaitingToReceive = xTaskGetCurrentTaskHandle();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        if( xBytesAvailable <= xBytesToStoreMessageLength )\n        {\n            /* Wait for data to be available. */\n            traceBLOCKING_ON_STREAM_BUFFER_RECEIVE( xStreamBuffer );\n            ( void ) xTaskNotifyWaitIndexed( pxStreamBuffer->uxNotificationIndex, ( uint32_t ) 0, ( uint32_t ) 0, NULL, xTicksToWait );\n            pxStreamBuffer->xTaskWaitingToReceive = NULL;\n\n            /* Recheck the data available after blocking. */\n            xBytesAvailable = prvBytesInBuffer( pxStreamBuffer );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        xBytesAvailable = prvBytesInBuffer( pxStreamBuffer );\n    }\n\n    /* Whether receiving a discrete message (where xBytesToStoreMessageLength\n     * holds the number of bytes used to store the message length) or a stream of\n     * bytes (where xBytesToStoreMessageLength is zero), the number of bytes\n     * available must be greater than xBytesToStoreMessageLength to be able to\n     * read bytes from the buffer. */\n    if( xBytesAvailable > xBytesToStoreMessageLength )\n    {\n        xReceivedLength = prvReadMessageFromBuffer( pxStreamBuffer, pvRxData, xBufferLengthBytes, xBytesAvailable );\n\n        /* Was a task waiting for space in the buffer? */\n        if( xReceivedLength != ( size_t ) 0 )\n        {\n            traceSTREAM_BUFFER_RECEIVE( xStreamBuffer, xReceivedLength );\n            prvRECEIVE_COMPLETED( xStreamBuffer );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        traceSTREAM_BUFFER_RECEIVE_FAILED( xStreamBuffer );\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    traceRETURN_xStreamBufferReceive( xReceivedLength );\n\n    return xReceivedLength;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferNextMessageLengthBytes( StreamBufferHandle_t xStreamBuffer )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReturn, xBytesAvailable;\n    configMESSAGE_BUFFER_LENGTH_TYPE xTempReturn;\n\n    traceENTER_xStreamBufferNextMessageLengthBytes( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    /* Ensure the stream buffer is being used as a message buffer. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xBytesAvailable = prvBytesInBuffer( pxStreamBuffer );\n\n        if( xBytesAvailable > sbBYTES_TO_STORE_MESSAGE_LENGTH )\n        {\n            /* The number of bytes available is greater than the number of bytes\n             * required to hold the length of the next message, so another message\n             * is available. */\n            ( void ) prvReadBytesFromBuffer( pxStreamBuffer, ( uint8_t * ) &xTempReturn, sbBYTES_TO_STORE_MESSAGE_LENGTH, pxStreamBuffer->xTail );\n            xReturn = ( size_t ) xTempReturn;\n        }\n        else\n        {\n            /* The minimum amount of bytes in a message buffer is\n             * ( sbBYTES_TO_STORE_MESSAGE_LENGTH + 1 ), so if xBytesAvailable is\n             * less than sbBYTES_TO_STORE_MESSAGE_LENGTH the only other valid\n             * value is 0. */\n            configASSERT( xBytesAvailable == 0 );\n            xReturn = 0;\n        }\n    }\n    else\n    {\n        xReturn = 0;\n    }\n\n    traceRETURN_xStreamBufferNextMessageLengthBytes( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nsize_t xStreamBufferReceiveFromISR( StreamBufferHandle_t xStreamBuffer,\n                                    void * pvRxData,\n                                    size_t xBufferLengthBytes,\n                                    BaseType_t * const pxHigherPriorityTaskWoken )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    size_t xReceivedLength = 0, xBytesAvailable, xBytesToStoreMessageLength;\n\n    traceENTER_xStreamBufferReceiveFromISR( xStreamBuffer, pvRxData, xBufferLengthBytes, pxHigherPriorityTaskWoken );\n\n    configASSERT( pvRxData );\n    configASSERT( pxStreamBuffer );\n\n    /* This receive function is used by both message buffers, which store\n     * discrete messages, and stream buffers, which store a continuous stream of\n     * bytes.  Discrete messages include an additional\n     * sbBYTES_TO_STORE_MESSAGE_LENGTH bytes that hold the length of the\n     * message. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xBytesToStoreMessageLength = sbBYTES_TO_STORE_MESSAGE_LENGTH;\n    }\n    else\n    {\n        xBytesToStoreMessageLength = 0;\n    }\n\n    xBytesAvailable = prvBytesInBuffer( pxStreamBuffer );\n\n    /* Whether receiving a discrete message (where xBytesToStoreMessageLength\n     * holds the number of bytes used to store the message length) or a stream of\n     * bytes (where xBytesToStoreMessageLength is zero), the number of bytes\n     * available must be greater than xBytesToStoreMessageLength to be able to\n     * read bytes from the buffer. */\n    if( xBytesAvailable > xBytesToStoreMessageLength )\n    {\n        xReceivedLength = prvReadMessageFromBuffer( pxStreamBuffer, pvRxData, xBufferLengthBytes, xBytesAvailable );\n\n        /* Was a task waiting for space in the buffer? */\n        if( xReceivedLength != ( size_t ) 0 )\n        {\n            /* MISRA Ref 4.7.1 [Return value shall be checked] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n            /* coverity[misra_c_2012_directive_4_7_violation] */\n            prvRECEIVE_COMPLETED_FROM_ISR( pxStreamBuffer, pxHigherPriorityTaskWoken );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    traceSTREAM_BUFFER_RECEIVE_FROM_ISR( xStreamBuffer, xReceivedLength );\n    traceRETURN_xStreamBufferReceiveFromISR( xReceivedLength );\n\n    return xReceivedLength;\n}\n/*-----------------------------------------------------------*/\n\nstatic size_t prvReadMessageFromBuffer( StreamBuffer_t * pxStreamBuffer,\n                                        void * pvRxData,\n                                        size_t xBufferLengthBytes,\n                                        size_t xBytesAvailable )\n{\n    size_t xCount, xNextMessageLength;\n    configMESSAGE_BUFFER_LENGTH_TYPE xTempNextMessageLength;\n    size_t xNextTail = pxStreamBuffer->xTail;\n\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        /* A discrete message is being received.  First receive the length\n         * of the message. */\n        xNextTail = prvReadBytesFromBuffer( pxStreamBuffer, ( uint8_t * ) &xTempNextMessageLength, sbBYTES_TO_STORE_MESSAGE_LENGTH, xNextTail );\n        xNextMessageLength = ( size_t ) xTempNextMessageLength;\n\n        /* Reduce the number of bytes available by the number of bytes just\n         * read out. */\n        xBytesAvailable -= sbBYTES_TO_STORE_MESSAGE_LENGTH;\n\n        /* Check there is enough space in the buffer provided by the\n         * user. */\n        if( xNextMessageLength > xBufferLengthBytes )\n        {\n            /* The user has provided insufficient space to read the message. */\n            xNextMessageLength = 0;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    else\n    {\n        /* A stream of bytes is being received (as opposed to a discrete\n         * message), so read as many bytes as possible. */\n        xNextMessageLength = xBufferLengthBytes;\n    }\n\n    /* Use the minimum of the wanted bytes and the available bytes. */\n    xCount = configMIN( xNextMessageLength, xBytesAvailable );\n\n    if( xCount != ( size_t ) 0 )\n    {\n        /* Read the actual data and update the tail to mark the data as officially consumed. */\n        /* MISRA Ref 11.5.5 [Void pointer assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        pxStreamBuffer->xTail = prvReadBytesFromBuffer( pxStreamBuffer, ( uint8_t * ) pvRxData, xCount, xNextTail );\n    }\n\n    return xCount;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferIsEmpty( StreamBufferHandle_t xStreamBuffer )\n{\n    const StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn;\n    size_t xTail;\n\n    traceENTER_xStreamBufferIsEmpty( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    /* True if no bytes are available. */\n    xTail = pxStreamBuffer->xTail;\n\n    if( pxStreamBuffer->xHead == xTail )\n    {\n        xReturn = pdTRUE;\n    }\n    else\n    {\n        xReturn = pdFALSE;\n    }\n\n    traceRETURN_xStreamBufferIsEmpty( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferIsFull( StreamBufferHandle_t xStreamBuffer )\n{\n    BaseType_t xReturn;\n    size_t xBytesToStoreMessageLength;\n    const StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n\n    traceENTER_xStreamBufferIsFull( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    /* This generic version of the receive function is used by both message\n     * buffers, which store discrete messages, and stream buffers, which store a\n     * continuous stream of bytes.  Discrete messages include an additional\n     * sbBYTES_TO_STORE_MESSAGE_LENGTH bytes that hold the length of the message. */\n    if( ( pxStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) != ( uint8_t ) 0 )\n    {\n        xBytesToStoreMessageLength = sbBYTES_TO_STORE_MESSAGE_LENGTH;\n    }\n    else\n    {\n        xBytesToStoreMessageLength = 0;\n    }\n\n    /* True if the available space equals zero. */\n    if( xStreamBufferSpacesAvailable( xStreamBuffer ) <= xBytesToStoreMessageLength )\n    {\n        xReturn = pdTRUE;\n    }\n    else\n    {\n        xReturn = pdFALSE;\n    }\n\n    traceRETURN_xStreamBufferIsFull( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferSendCompletedFromISR( StreamBufferHandle_t xStreamBuffer,\n                                              BaseType_t * pxHigherPriorityTaskWoken )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n\n    traceENTER_xStreamBufferSendCompletedFromISR( xStreamBuffer, pxHigherPriorityTaskWoken );\n\n    configASSERT( pxStreamBuffer );\n\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n    {\n        if( ( pxStreamBuffer )->xTaskWaitingToReceive != NULL )\n        {\n            ( void ) xTaskNotifyIndexedFromISR( ( pxStreamBuffer )->xTaskWaitingToReceive,\n                                                ( pxStreamBuffer )->uxNotificationIndex,\n                                                ( uint32_t ) 0,\n                                                eNoAction,\n                                                pxHigherPriorityTaskWoken );\n            ( pxStreamBuffer )->xTaskWaitingToReceive = NULL;\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xStreamBufferSendCompletedFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xStreamBufferReceiveCompletedFromISR( StreamBufferHandle_t xStreamBuffer,\n                                                 BaseType_t * pxHigherPriorityTaskWoken )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n    BaseType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n\n    traceENTER_xStreamBufferReceiveCompletedFromISR( xStreamBuffer, pxHigherPriorityTaskWoken );\n\n    configASSERT( pxStreamBuffer );\n\n    /* MISRA Ref 4.7.1 [Return value shall be checked] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n    /* coverity[misra_c_2012_directive_4_7_violation] */\n    uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n    {\n        if( ( pxStreamBuffer )->xTaskWaitingToSend != NULL )\n        {\n            ( void ) xTaskNotifyIndexedFromISR( ( pxStreamBuffer )->xTaskWaitingToSend,\n                                                ( pxStreamBuffer )->uxNotificationIndex,\n                                                ( uint32_t ) 0,\n                                                eNoAction,\n                                                pxHigherPriorityTaskWoken );\n            ( pxStreamBuffer )->xTaskWaitingToSend = NULL;\n            xReturn = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n    }\n    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xStreamBufferReceiveCompletedFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nstatic size_t prvWriteBytesToBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                     const uint8_t * pucData,\n                                     size_t xCount,\n                                     size_t xHead )\n{\n    size_t xFirstLength;\n\n    configASSERT( xCount > ( size_t ) 0 );\n\n    /* Calculate the number of bytes that can be added in the first write -\n     * which may be less than the total number of bytes that need to be added if\n     * the buffer will wrap back to the beginning. */\n    xFirstLength = configMIN( pxStreamBuffer->xLength - xHead, xCount );\n\n    /* Write as many bytes as can be written in the first write. */\n    configASSERT( ( xHead + xFirstLength ) <= pxStreamBuffer->xLength );\n    ( void ) memcpy( ( void * ) ( &( pxStreamBuffer->pucBuffer[ xHead ] ) ), ( const void * ) pucData, xFirstLength );\n\n    /* If the number of bytes written was less than the number that could be\n     * written in the first write... */\n    if( xCount > xFirstLength )\n    {\n        /* ...then write the remaining bytes to the start of the buffer. */\n        configASSERT( ( xCount - xFirstLength ) <= pxStreamBuffer->xLength );\n        ( void ) memcpy( ( void * ) pxStreamBuffer->pucBuffer, ( const void * ) &( pucData[ xFirstLength ] ), xCount - xFirstLength );\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    xHead += xCount;\n\n    if( xHead >= pxStreamBuffer->xLength )\n    {\n        xHead -= pxStreamBuffer->xLength;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    return xHead;\n}\n/*-----------------------------------------------------------*/\n\nstatic size_t prvReadBytesFromBuffer( StreamBuffer_t * pxStreamBuffer,\n                                      uint8_t * pucData,\n                                      size_t xCount,\n                                      size_t xTail )\n{\n    size_t xFirstLength;\n\n    configASSERT( xCount != ( size_t ) 0 );\n\n    /* Calculate the number of bytes that can be read - which may be\n     * less than the number wanted if the data wraps around to the start of\n     * the buffer. */\n    xFirstLength = configMIN( pxStreamBuffer->xLength - xTail, xCount );\n\n    /* Obtain the number of bytes it is possible to obtain in the first\n     * read.  Asserts check bounds of read and write. */\n    configASSERT( xFirstLength <= xCount );\n    configASSERT( ( xTail + xFirstLength ) <= pxStreamBuffer->xLength );\n    ( void ) memcpy( ( void * ) pucData, ( const void * ) &( pxStreamBuffer->pucBuffer[ xTail ] ), xFirstLength );\n\n    /* If the total number of wanted bytes is greater than the number\n     * that could be read in the first read... */\n    if( xCount > xFirstLength )\n    {\n        /* ...then read the remaining bytes from the start of the buffer. */\n        ( void ) memcpy( ( void * ) &( pucData[ xFirstLength ] ), ( void * ) ( pxStreamBuffer->pucBuffer ), xCount - xFirstLength );\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    /* Move the tail pointer to effectively remove the data read from the buffer. */\n    xTail += xCount;\n\n    if( xTail >= pxStreamBuffer->xLength )\n    {\n        xTail -= pxStreamBuffer->xLength;\n    }\n\n    return xTail;\n}\n/*-----------------------------------------------------------*/\n\nstatic size_t prvBytesInBuffer( const StreamBuffer_t * const pxStreamBuffer )\n{\n    /* Returns the distance between xTail and xHead. */\n    size_t xCount;\n\n    xCount = pxStreamBuffer->xLength + pxStreamBuffer->xHead;\n    xCount -= pxStreamBuffer->xTail;\n\n    if( xCount >= pxStreamBuffer->xLength )\n    {\n        xCount -= pxStreamBuffer->xLength;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    return xCount;\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvInitialiseNewStreamBuffer( StreamBuffer_t * const pxStreamBuffer,\n                                          uint8_t * const pucBuffer,\n                                          size_t xBufferSizeBytes,\n                                          size_t xTriggerLevelBytes,\n                                          uint8_t ucFlags,\n                                          StreamBufferCallbackFunction_t pxSendCompletedCallback,\n                                          StreamBufferCallbackFunction_t pxReceiveCompletedCallback )\n{\n    /* Assert here is deliberately writing to the entire buffer to ensure it can\n     * be written to without generating exceptions, and is setting the buffer to a\n     * known value to assist in development/debugging. */\n    #if ( configASSERT_DEFINED == 1 )\n    {\n        /* The value written just has to be identifiable when looking at the\n         * memory.  Don't use 0xA5 as that is the stack fill value and could\n         * result in confusion as to what is actually being observed. */\n        #define STREAM_BUFFER_BUFFER_WRITE_VALUE    ( 0x55 )\n        configASSERT( memset( pucBuffer, ( int ) STREAM_BUFFER_BUFFER_WRITE_VALUE, xBufferSizeBytes ) == pucBuffer );\n    }\n    #endif\n\n    ( void ) memset( ( void * ) pxStreamBuffer, 0x00, sizeof( StreamBuffer_t ) );\n    pxStreamBuffer->pucBuffer = pucBuffer;\n    pxStreamBuffer->xLength = xBufferSizeBytes;\n    pxStreamBuffer->xTriggerLevelBytes = xTriggerLevelBytes;\n    pxStreamBuffer->ucFlags = ucFlags;\n    pxStreamBuffer->uxNotificationIndex = tskDEFAULT_INDEX_TO_NOTIFY;\n    #if ( configUSE_SB_COMPLETED_CALLBACK == 1 )\n    {\n        pxStreamBuffer->pxSendCompletedCallback = pxSendCompletedCallback;\n        pxStreamBuffer->pxReceiveCompletedCallback = pxReceiveCompletedCallback;\n    }\n    #else\n    {\n        /* MISRA Ref 11.1.1 [Object type casting] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-111 */\n        /* coverity[misra_c_2012_rule_11_1_violation] */\n        ( void ) pxSendCompletedCallback;\n\n        /* MISRA Ref 11.1.1 [Object type casting] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-111 */\n        /* coverity[misra_c_2012_rule_11_1_violation] */\n        ( void ) pxReceiveCompletedCallback;\n    }\n    #endif /* if ( configUSE_SB_COMPLETED_CALLBACK == 1 ) */\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxStreamBufferGetStreamBufferNotificationIndex( StreamBufferHandle_t xStreamBuffer )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n\n    traceENTER_uxStreamBufferGetStreamBufferNotificationIndex( xStreamBuffer );\n\n    configASSERT( pxStreamBuffer );\n\n    traceRETURN_uxStreamBufferGetStreamBufferNotificationIndex( pxStreamBuffer->uxNotificationIndex );\n\n    return pxStreamBuffer->uxNotificationIndex;\n}\n/*-----------------------------------------------------------*/\n\nvoid vStreamBufferSetStreamBufferNotificationIndex( StreamBufferHandle_t xStreamBuffer,\n                                                    UBaseType_t uxNotificationIndex )\n{\n    StreamBuffer_t * const pxStreamBuffer = xStreamBuffer;\n\n    traceENTER_vStreamBufferSetStreamBufferNotificationIndex( xStreamBuffer, uxNotificationIndex );\n\n    configASSERT( pxStreamBuffer );\n\n    /* There should be no task waiting otherwise we'd never resume them. */\n    configASSERT( pxStreamBuffer->xTaskWaitingToReceive == NULL );\n    configASSERT( pxStreamBuffer->xTaskWaitingToSend == NULL );\n\n    /* Check that the task notification index is valid. */\n    configASSERT( uxNotificationIndex < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n    pxStreamBuffer->uxNotificationIndex = uxNotificationIndex;\n\n    traceRETURN_vStreamBufferSetStreamBufferNotificationIndex();\n}\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n    UBaseType_t uxStreamBufferGetStreamBufferNumber( StreamBufferHandle_t xStreamBuffer )\n    {\n        traceENTER_uxStreamBufferGetStreamBufferNumber( xStreamBuffer );\n\n        traceRETURN_uxStreamBufferGetStreamBufferNumber( xStreamBuffer->uxStreamBufferNumber );\n\n        return xStreamBuffer->uxStreamBufferNumber;\n    }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n    void vStreamBufferSetStreamBufferNumber( StreamBufferHandle_t xStreamBuffer,\n                                             UBaseType_t uxStreamBufferNumber )\n    {\n        traceENTER_vStreamBufferSetStreamBufferNumber( xStreamBuffer, uxStreamBufferNumber );\n\n        xStreamBuffer->uxStreamBufferNumber = uxStreamBufferNumber;\n\n        traceRETURN_vStreamBufferSetStreamBufferNumber();\n    }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n    uint8_t ucStreamBufferGetStreamBufferType( StreamBufferHandle_t xStreamBuffer )\n    {\n        traceENTER_ucStreamBufferGetStreamBufferType( xStreamBuffer );\n\n        traceRETURN_ucStreamBufferGetStreamBufferType( ( uint8_t ) ( xStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) );\n\n        return( ( uint8_t ) ( xStreamBuffer->ucFlags & sbFLAGS_IS_MESSAGE_BUFFER ) );\n    }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n/* This entire source file will be skipped if the application is not configured\n * to include stream buffer functionality. This #if is closed at the very bottom\n * of this file. If you want to include stream buffers then ensure\n * configUSE_STREAM_BUFFERS is set to 1 in FreeRTOSConfig.h. */\n#endif /* configUSE_STREAM_BUFFERS == 1 */\n"
        },
        {
          "name": "tasks.c",
          "type": "blob",
          "size": 349.77734375,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n/* Standard includes. */\n#include <stdlib.h>\n#include <string.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers.  That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"timers.h\"\n#include \"stack_macros.h\"\n\n/* The default definitions are only available for non-MPU ports. The\n * reason is that the stack alignment requirements vary for different\n * architectures.*/\n#if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configKERNEL_PROVIDED_STATIC_MEMORY == 1 ) && ( portUSING_MPU_WRAPPERS != 0 ) )\n    #error configKERNEL_PROVIDED_STATIC_MEMORY cannot be set to 1 when using an MPU port. The vApplicationGet*TaskMemory() functions must be provided manually.\n#endif\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined\n * for the header files above, but not in this file, in order to generate the\n * correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n/* Set configUSE_STATS_FORMATTING_FUNCTIONS to 2 to include the stats formatting\n * functions but without including stdio.h here. */\n#if ( configUSE_STATS_FORMATTING_FUNCTIONS == 1 )\n\n/* At the bottom of this file are two optional functions that can be used\n * to generate human readable text from the raw data generated by the\n * uxTaskGetSystemState() function.  Note the formatting functions are provided\n * for convenience only, and are NOT considered part of the kernel. */\n    #include <stdio.h>\n#endif /* configUSE_STATS_FORMATTING_FUNCTIONS == 1 ) */\n\n#if ( configUSE_PREEMPTION == 0 )\n\n/* If the cooperative scheduler is being used then a yield should not be\n * performed just because a higher priority task has been woken. */\n    #define taskYIELD_TASK_CORE_IF_USING_PREEMPTION( pxTCB )\n    #define taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB )\n#else\n\n    #if ( configNUMBER_OF_CORES == 1 )\n\n/* This macro requests the running task pxTCB to yield. In single core\n * scheduler, a running task always runs on core 0 and portYIELD_WITHIN_API()\n * can be used to request the task running on core 0 to yield. Therefore, pxTCB\n * is not used in this macro. */\n        #define taskYIELD_TASK_CORE_IF_USING_PREEMPTION( pxTCB ) \\\n    do {                                                         \\\n        ( void ) ( pxTCB );                                      \\\n        portYIELD_WITHIN_API();                                  \\\n    } while( 0 )\n\n        #define taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB ) \\\n    do {                                                        \\\n        if( pxCurrentTCB->uxPriority < ( pxTCB )->uxPriority )  \\\n        {                                                       \\\n            portYIELD_WITHIN_API();                             \\\n        }                                                       \\\n        else                                                    \\\n        {                                                       \\\n            mtCOVERAGE_TEST_MARKER();                           \\\n        }                                                       \\\n    } while( 0 )\n\n    #else /* if ( configNUMBER_OF_CORES == 1 ) */\n\n/* Yield the core on which this task is running. */\n        #define taskYIELD_TASK_CORE_IF_USING_PREEMPTION( pxTCB )    prvYieldCore( ( pxTCB )->xTaskRunState )\n\n/* Yield for the task if a running task has priority lower than this task. */\n        #define taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB )     prvYieldForTask( pxTCB )\n\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n#endif /* if ( configUSE_PREEMPTION == 0 ) */\n\n/* Values that can be assigned to the ucNotifyState member of the TCB. */\n#define taskNOT_WAITING_NOTIFICATION              ( ( uint8_t ) 0 ) /* Must be zero as it is the initialised value. */\n#define taskWAITING_NOTIFICATION                  ( ( uint8_t ) 1 )\n#define taskNOTIFICATION_RECEIVED                 ( ( uint8_t ) 2 )\n\n/*\n * The value used to fill the stack of a task when the task is created.  This\n * is used purely for checking the high water mark for tasks.\n */\n#define tskSTACK_FILL_BYTE                        ( 0xa5U )\n\n/* Bits used to record how a task's stack and TCB were allocated. */\n#define tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB    ( ( uint8_t ) 0 )\n#define tskSTATICALLY_ALLOCATED_STACK_ONLY        ( ( uint8_t ) 1 )\n#define tskSTATICALLY_ALLOCATED_STACK_AND_TCB     ( ( uint8_t ) 2 )\n\n/* If any of the following are set then task stacks are filled with a known\n * value so the high water mark can be determined.  If none of the following are\n * set then don't fill the stack so there is no unnecessary dependency on memset. */\n#if ( ( configCHECK_FOR_STACK_OVERFLOW > 1 ) || ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark2 == 1 ) )\n    #define tskSET_NEW_STACKS_TO_KNOWN_VALUE    1\n#else\n    #define tskSET_NEW_STACKS_TO_KNOWN_VALUE    0\n#endif\n\n/*\n * Macros used by vListTask to indicate which state a task is in.\n */\n#define tskRUNNING_CHAR      ( 'X' )\n#define tskBLOCKED_CHAR      ( 'B' )\n#define tskREADY_CHAR        ( 'R' )\n#define tskDELETED_CHAR      ( 'D' )\n#define tskSUSPENDED_CHAR    ( 'S' )\n\n/*\n * Some kernel aware debuggers require the data the debugger needs access to be\n * global, rather than file scope.\n */\n#ifdef portREMOVE_STATIC_QUALIFIER\n    #define static\n#endif\n\n/* The name allocated to the Idle task.  This can be overridden by defining\n * configIDLE_TASK_NAME in FreeRTOSConfig.h. */\n#ifndef configIDLE_TASK_NAME\n    #define configIDLE_TASK_NAME    \"IDLE\"\n#endif\n\n#if ( configUSE_PORT_OPTIMISED_TASK_SELECTION == 0 )\n\n/* If configUSE_PORT_OPTIMISED_TASK_SELECTION is 0 then task selection is\n * performed in a generic way that is not optimised to any particular\n * microcontroller architecture. */\n\n/* uxTopReadyPriority holds the priority of the highest priority ready\n * state task. */\n    #define taskRECORD_READY_PRIORITY( uxPriority ) \\\n    do {                                            \\\n        if( ( uxPriority ) > uxTopReadyPriority )   \\\n        {                                           \\\n            uxTopReadyPriority = ( uxPriority );    \\\n        }                                           \\\n    } while( 0 ) /* taskRECORD_READY_PRIORITY */\n\n/*-----------------------------------------------------------*/\n\n    #if ( configNUMBER_OF_CORES == 1 )\n        #define taskSELECT_HIGHEST_PRIORITY_TASK()                                       \\\n    do {                                                                                 \\\n        UBaseType_t uxTopPriority = uxTopReadyPriority;                                  \\\n                                                                                         \\\n        /* Find the highest priority queue that contains ready tasks. */                 \\\n        while( listLIST_IS_EMPTY( &( pxReadyTasksLists[ uxTopPriority ] ) ) != pdFALSE ) \\\n        {                                                                                \\\n            configASSERT( uxTopPriority );                                               \\\n            --uxTopPriority;                                                             \\\n        }                                                                                \\\n                                                                                         \\\n        /* listGET_OWNER_OF_NEXT_ENTRY indexes through the list, so the tasks of \\\n         * the  same priority get an equal share of the processor time. */                    \\\n        listGET_OWNER_OF_NEXT_ENTRY( pxCurrentTCB, &( pxReadyTasksLists[ uxTopPriority ] ) ); \\\n        uxTopReadyPriority = uxTopPriority;                                                   \\\n    } while( 0 ) /* taskSELECT_HIGHEST_PRIORITY_TASK */\n    #else /* if ( configNUMBER_OF_CORES == 1 ) */\n\n        #define taskSELECT_HIGHEST_PRIORITY_TASK( xCoreID )    prvSelectHighestPriorityTask( xCoreID )\n\n    #endif /* if ( configNUMBER_OF_CORES == 1 ) */\n\n/*-----------------------------------------------------------*/\n\n/* Define away taskRESET_READY_PRIORITY() and portRESET_READY_PRIORITY() as\n * they are only required when a port optimised method of task selection is\n * being used. */\n    #define taskRESET_READY_PRIORITY( uxPriority )\n    #define portRESET_READY_PRIORITY( uxPriority, uxTopReadyPriority )\n\n#else /* configUSE_PORT_OPTIMISED_TASK_SELECTION */\n\n/* If configUSE_PORT_OPTIMISED_TASK_SELECTION is 1 then task selection is\n * performed in a way that is tailored to the particular microcontroller\n * architecture being used. */\n\n/* A port optimised version is provided.  Call the port defined macros. */\n    #define taskRECORD_READY_PRIORITY( uxPriority )    portRECORD_READY_PRIORITY( ( uxPriority ), uxTopReadyPriority )\n\n/*-----------------------------------------------------------*/\n\n    #define taskSELECT_HIGHEST_PRIORITY_TASK()                                                  \\\n    do {                                                                                        \\\n        UBaseType_t uxTopPriority;                                                              \\\n                                                                                                \\\n        /* Find the highest priority list that contains ready tasks. */                         \\\n        portGET_HIGHEST_PRIORITY( uxTopPriority, uxTopReadyPriority );                          \\\n        configASSERT( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ uxTopPriority ] ) ) > 0 ); \\\n        listGET_OWNER_OF_NEXT_ENTRY( pxCurrentTCB, &( pxReadyTasksLists[ uxTopPriority ] ) );   \\\n    } while( 0 )\n\n/*-----------------------------------------------------------*/\n\n/* A port optimised version is provided, call it only if the TCB being reset\n * is being referenced from a ready list.  If it is referenced from a delayed\n * or suspended list then it won't be in a ready list. */\n    #define taskRESET_READY_PRIORITY( uxPriority )                                                     \\\n    do {                                                                                               \\\n        if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ ( uxPriority ) ] ) ) == ( UBaseType_t ) 0 ) \\\n        {                                                                                              \\\n            portRESET_READY_PRIORITY( ( uxPriority ), ( uxTopReadyPriority ) );                        \\\n        }                                                                                              \\\n    } while( 0 )\n\n#endif /* configUSE_PORT_OPTIMISED_TASK_SELECTION */\n\n/*-----------------------------------------------------------*/\n\n/* pxDelayedTaskList and pxOverflowDelayedTaskList are switched when the tick\n * count overflows. */\n#define taskSWITCH_DELAYED_LISTS()                                                \\\n    do {                                                                          \\\n        List_t * pxTemp;                                                          \\\n                                                                                  \\\n        /* The delayed tasks list should be empty when the lists are switched. */ \\\n        configASSERT( ( listLIST_IS_EMPTY( pxDelayedTaskList ) ) );               \\\n                                                                                  \\\n        pxTemp = pxDelayedTaskList;                                               \\\n        pxDelayedTaskList = pxOverflowDelayedTaskList;                            \\\n        pxOverflowDelayedTaskList = pxTemp;                                       \\\n        xNumOfOverflows = ( BaseType_t ) ( xNumOfOverflows + 1 );                 \\\n        prvResetNextTaskUnblockTime();                                            \\\n    } while( 0 )\n\n/*-----------------------------------------------------------*/\n\n/*\n * Place the task represented by pxTCB into the appropriate ready list for\n * the task.  It is inserted at the end of the list.\n */\n#define prvAddTaskToReadyList( pxTCB )                                                                     \\\n    do {                                                                                                   \\\n        traceMOVED_TASK_TO_READY_STATE( pxTCB );                                                           \\\n        taskRECORD_READY_PRIORITY( ( pxTCB )->uxPriority );                                                \\\n        listINSERT_END( &( pxReadyTasksLists[ ( pxTCB )->uxPriority ] ), &( ( pxTCB )->xStateListItem ) ); \\\n        tracePOST_MOVED_TASK_TO_READY_STATE( pxTCB );                                                      \\\n    } while( 0 )\n/*-----------------------------------------------------------*/\n\n/*\n * Several functions take a TaskHandle_t parameter that can optionally be NULL,\n * where NULL is used to indicate that the handle of the currently executing\n * task should be used in place of the parameter.  This macro simply checks to\n * see if the parameter is NULL and returns a pointer to the appropriate TCB.\n */\n#define prvGetTCBFromHandle( pxHandle )    ( ( ( pxHandle ) == NULL ) ? pxCurrentTCB : ( pxHandle ) )\n\n/* The item value of the event list item is normally used to hold the priority\n * of the task to which it belongs (coded to allow it to be held in reverse\n * priority order).  However, it is occasionally borrowed for other purposes.  It\n * is important its value is not updated due to a task priority change while it is\n * being used for another purpose.  The following bit definition is used to inform\n * the scheduler that the value should not be changed - in which case it is the\n * responsibility of whichever module is using the value to ensure it gets set back\n * to its original value when it is released. */\n#if ( configTICK_TYPE_WIDTH_IN_BITS == TICK_TYPE_WIDTH_16_BITS )\n    #define taskEVENT_LIST_ITEM_VALUE_IN_USE    ( ( uint16_t ) 0x8000U )\n#elif ( configTICK_TYPE_WIDTH_IN_BITS == TICK_TYPE_WIDTH_32_BITS )\n    #define taskEVENT_LIST_ITEM_VALUE_IN_USE    ( ( uint32_t ) 0x80000000U )\n#elif ( configTICK_TYPE_WIDTH_IN_BITS == TICK_TYPE_WIDTH_64_BITS )\n    #define taskEVENT_LIST_ITEM_VALUE_IN_USE    ( ( uint64_t ) 0x8000000000000000U )\n#endif\n\n/* Indicates that the task is not actively running on any core. */\n#define taskTASK_NOT_RUNNING           ( ( BaseType_t ) ( -1 ) )\n\n/* Indicates that the task is actively running but scheduled to yield. */\n#define taskTASK_SCHEDULED_TO_YIELD    ( ( BaseType_t ) ( -2 ) )\n\n/* Returns pdTRUE if the task is actively running and not scheduled to yield. */\n#if ( configNUMBER_OF_CORES == 1 )\n    #define taskTASK_IS_RUNNING( pxTCB )                          ( ( ( pxTCB ) == pxCurrentTCB ) ? ( pdTRUE ) : ( pdFALSE ) )\n    #define taskTASK_IS_RUNNING_OR_SCHEDULED_TO_YIELD( pxTCB )    ( ( ( pxTCB ) == pxCurrentTCB ) ? ( pdTRUE ) : ( pdFALSE ) )\n#else\n    #define taskTASK_IS_RUNNING( pxTCB )                          ( ( ( ( pxTCB )->xTaskRunState >= ( BaseType_t ) 0 ) && ( ( pxTCB )->xTaskRunState < ( BaseType_t ) configNUMBER_OF_CORES ) ) ? ( pdTRUE ) : ( pdFALSE ) )\n    #define taskTASK_IS_RUNNING_OR_SCHEDULED_TO_YIELD( pxTCB )    ( ( ( pxTCB )->xTaskRunState != taskTASK_NOT_RUNNING ) ? ( pdTRUE ) : ( pdFALSE ) )\n#endif\n\n/* Indicates that the task is an Idle task. */\n#define taskATTRIBUTE_IS_IDLE    ( UBaseType_t ) ( 1U << 0U )\n\n#if ( ( configNUMBER_OF_CORES > 1 ) && ( portCRITICAL_NESTING_IN_TCB == 1 ) )\n    #define portGET_CRITICAL_NESTING_COUNT( xCoreID )          ( pxCurrentTCBs[ ( xCoreID ) ]->uxCriticalNesting )\n    #define portSET_CRITICAL_NESTING_COUNT( xCoreID, x )       ( pxCurrentTCBs[ ( xCoreID ) ]->uxCriticalNesting = ( x ) )\n    #define portINCREMENT_CRITICAL_NESTING_COUNT( xCoreID )    ( pxCurrentTCBs[ ( xCoreID ) ]->uxCriticalNesting++ )\n    #define portDECREMENT_CRITICAL_NESTING_COUNT( xCoreID )    ( pxCurrentTCBs[ ( xCoreID ) ]->uxCriticalNesting-- )\n#endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( portCRITICAL_NESTING_IN_TCB == 1 ) ) */\n\n#define taskBITS_PER_BYTE    ( ( size_t ) 8 )\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n/* Yields the given core. This must be called from a critical section and xCoreID\n * must be valid. This macro is not required in single core since there is only\n * one core to yield. */\n    #define prvYieldCore( xCoreID )                                                          \\\n    do {                                                                                     \\\n        if( ( xCoreID ) == ( BaseType_t ) portGET_CORE_ID() )                                \\\n        {                                                                                    \\\n            /* Pending a yield for this core since it is in the critical section. */         \\\n            xYieldPendings[ ( xCoreID ) ] = pdTRUE;                                          \\\n        }                                                                                    \\\n        else                                                                                 \\\n        {                                                                                    \\\n            /* Request other core to yield if it is not requested before. */                 \\\n            if( pxCurrentTCBs[ ( xCoreID ) ]->xTaskRunState != taskTASK_SCHEDULED_TO_YIELD ) \\\n            {                                                                                \\\n                portYIELD_CORE( xCoreID );                                                   \\\n                pxCurrentTCBs[ ( xCoreID ) ]->xTaskRunState = taskTASK_SCHEDULED_TO_YIELD;   \\\n            }                                                                                \\\n        }                                                                                    \\\n    } while( 0 )\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\n/*\n * Task control block.  A task control block (TCB) is allocated for each task,\n * and stores task state information, including a pointer to the task's context\n * (the task's run time environment, including register values)\n */\ntypedef struct tskTaskControlBlock       /* The old naming convention is used to prevent breaking kernel aware debuggers. */\n{\n    volatile StackType_t * pxTopOfStack; /**< Points to the location of the last item placed on the tasks stack.  THIS MUST BE THE FIRST MEMBER OF THE TCB STRUCT. */\n\n    #if ( portUSING_MPU_WRAPPERS == 1 )\n        xMPU_SETTINGS xMPUSettings; /**< The MPU settings are defined as part of the port layer.  THIS MUST BE THE SECOND MEMBER OF THE TCB STRUCT. */\n    #endif\n\n    #if ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 )\n        UBaseType_t uxCoreAffinityMask; /**< Used to link the task to certain cores.  UBaseType_t must have greater than or equal to the number of bits as configNUMBER_OF_CORES. */\n    #endif\n\n    ListItem_t xStateListItem;                  /**< The list that the state list item of a task is reference from denotes the state of that task (Ready, Blocked, Suspended ). */\n    ListItem_t xEventListItem;                  /**< Used to reference a task from an event list. */\n    UBaseType_t uxPriority;                     /**< The priority of the task.  0 is the lowest priority. */\n    StackType_t * pxStack;                      /**< Points to the start of the stack. */\n    #if ( configNUMBER_OF_CORES > 1 )\n        volatile BaseType_t xTaskRunState;      /**< Used to identify the core the task is running on, if the task is running. Otherwise, identifies the task's state - not running or yielding. */\n        UBaseType_t uxTaskAttributes;           /**< Task's attributes - currently used to identify the idle tasks. */\n    #endif\n    char pcTaskName[ configMAX_TASK_NAME_LEN ]; /**< Descriptive name given to the task when created.  Facilitates debugging only. */\n\n    #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n        BaseType_t xPreemptionDisable; /**< Used to prevent the task from being preempted. */\n    #endif\n\n    #if ( ( portSTACK_GROWTH > 0 ) || ( configRECORD_STACK_HIGH_ADDRESS == 1 ) )\n        StackType_t * pxEndOfStack; /**< Points to the highest valid address for the stack. */\n    #endif\n\n    #if ( portCRITICAL_NESTING_IN_TCB == 1 )\n        UBaseType_t uxCriticalNesting; /**< Holds the critical section nesting depth for ports that do not maintain their own count in the port layer. */\n    #endif\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n        UBaseType_t uxTCBNumber;  /**< Stores a number that increments each time a TCB is created.  It allows debuggers to determine when a task has been deleted and then recreated. */\n        UBaseType_t uxTaskNumber; /**< Stores a number specifically for use by third party trace code. */\n    #endif\n\n    #if ( configUSE_MUTEXES == 1 )\n        UBaseType_t uxBasePriority; /**< The priority last assigned to the task - used by the priority inheritance mechanism. */\n        UBaseType_t uxMutexesHeld;\n    #endif\n\n    #if ( configUSE_APPLICATION_TASK_TAG == 1 )\n        TaskHookFunction_t pxTaskTag;\n    #endif\n\n    #if ( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )\n        void * pvThreadLocalStoragePointers[ configNUM_THREAD_LOCAL_STORAGE_POINTERS ];\n    #endif\n\n    #if ( configGENERATE_RUN_TIME_STATS == 1 )\n        configRUN_TIME_COUNTER_TYPE ulRunTimeCounter; /**< Stores the amount of time the task has spent in the Running state. */\n    #endif\n\n    #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n        configTLS_BLOCK_TYPE xTLSBlock; /**< Memory block used as Thread Local Storage (TLS) Block for the task. */\n    #endif\n\n    #if ( configUSE_TASK_NOTIFICATIONS == 1 )\n        volatile uint32_t ulNotifiedValue[ configTASK_NOTIFICATION_ARRAY_ENTRIES ];\n        volatile uint8_t ucNotifyState[ configTASK_NOTIFICATION_ARRAY_ENTRIES ];\n    #endif\n\n    /* See the comments in FreeRTOS.h with the definition of\n     * tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE. */\n    #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n        uint8_t ucStaticallyAllocated; /**< Set to pdTRUE if the task is a statically allocated to ensure no attempt is made to free the memory. */\n    #endif\n\n    #if ( INCLUDE_xTaskAbortDelay == 1 )\n        uint8_t ucDelayAborted;\n    #endif\n\n    #if ( configUSE_POSIX_ERRNO == 1 )\n        int iTaskErrno;\n    #endif\n} tskTCB;\n\n/* The old tskTCB name is maintained above then typedefed to the new TCB_t name\n * below to enable the use of older kernel aware debuggers. */\ntypedef tskTCB TCB_t;\n\n#if ( configNUMBER_OF_CORES == 1 )\n    /* MISRA Ref 8.4.1 [Declaration shall be visible] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-84 */\n    /* coverity[misra_c_2012_rule_8_4_violation] */\n    portDONT_DISCARD PRIVILEGED_DATA TCB_t * volatile pxCurrentTCB = NULL;\n#else\n    /* MISRA Ref 8.4.1 [Declaration shall be visible] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-84 */\n    /* coverity[misra_c_2012_rule_8_4_violation] */\n    portDONT_DISCARD PRIVILEGED_DATA TCB_t * volatile pxCurrentTCBs[ configNUMBER_OF_CORES ];\n    #define pxCurrentTCB    xTaskGetCurrentTaskHandle()\n#endif\n\n/* Lists for ready and blocked tasks. --------------------\n * xDelayedTaskList1 and xDelayedTaskList2 could be moved to function scope but\n * doing so breaks some kernel aware debuggers and debuggers that rely on removing\n * the static qualifier. */\nPRIVILEGED_DATA static List_t pxReadyTasksLists[ configMAX_PRIORITIES ]; /**< Prioritised ready tasks. */\nPRIVILEGED_DATA static List_t xDelayedTaskList1;                         /**< Delayed tasks. */\nPRIVILEGED_DATA static List_t xDelayedTaskList2;                         /**< Delayed tasks (two lists are used - one for delays that have overflowed the current tick count. */\nPRIVILEGED_DATA static List_t * volatile pxDelayedTaskList;              /**< Points to the delayed task list currently being used. */\nPRIVILEGED_DATA static List_t * volatile pxOverflowDelayedTaskList;      /**< Points to the delayed task list currently being used to hold tasks that have overflowed the current tick count. */\nPRIVILEGED_DATA static List_t xPendingReadyList;                         /**< Tasks that have been readied while the scheduler was suspended.  They will be moved to the ready list when the scheduler is resumed. */\n\n#if ( INCLUDE_vTaskDelete == 1 )\n\n    PRIVILEGED_DATA static List_t xTasksWaitingTermination; /**< Tasks that have been deleted - but their memory not yet freed. */\n    PRIVILEGED_DATA static volatile UBaseType_t uxDeletedTasksWaitingCleanUp = ( UBaseType_t ) 0U;\n\n#endif\n\n#if ( INCLUDE_vTaskSuspend == 1 )\n\n    PRIVILEGED_DATA static List_t xSuspendedTaskList; /**< Tasks that are currently suspended. */\n\n#endif\n\n/* Global POSIX errno. Its value is changed upon context switching to match\n * the errno of the currently running task. */\n#if ( configUSE_POSIX_ERRNO == 1 )\n    int FreeRTOS_errno = 0;\n#endif\n\n/* Other file private variables. --------------------------------*/\nPRIVILEGED_DATA static volatile UBaseType_t uxCurrentNumberOfTasks = ( UBaseType_t ) 0U;\nPRIVILEGED_DATA static volatile TickType_t xTickCount = ( TickType_t ) configINITIAL_TICK_COUNT;\nPRIVILEGED_DATA static volatile UBaseType_t uxTopReadyPriority = tskIDLE_PRIORITY;\nPRIVILEGED_DATA static volatile BaseType_t xSchedulerRunning = pdFALSE;\nPRIVILEGED_DATA static volatile TickType_t xPendedTicks = ( TickType_t ) 0U;\nPRIVILEGED_DATA static volatile BaseType_t xYieldPendings[ configNUMBER_OF_CORES ] = { pdFALSE };\nPRIVILEGED_DATA static volatile BaseType_t xNumOfOverflows = ( BaseType_t ) 0;\nPRIVILEGED_DATA static UBaseType_t uxTaskNumber = ( UBaseType_t ) 0U;\nPRIVILEGED_DATA static volatile TickType_t xNextTaskUnblockTime = ( TickType_t ) 0U; /* Initialised to portMAX_DELAY before the scheduler starts. */\nPRIVILEGED_DATA static TaskHandle_t xIdleTaskHandles[ configNUMBER_OF_CORES ];       /**< Holds the handles of the idle tasks.  The idle tasks are created automatically when the scheduler is started. */\n\n/* Improve support for OpenOCD. The kernel tracks Ready tasks via priority lists.\n * For tracking the state of remote threads, OpenOCD uses uxTopUsedPriority\n * to determine the number of priority lists to read back from the remote target. */\nstatic const volatile UBaseType_t uxTopUsedPriority = configMAX_PRIORITIES - 1U;\n\n/* Context switches are held pending while the scheduler is suspended.  Also,\n * interrupts must not manipulate the xStateListItem of a TCB, or any of the\n * lists the xStateListItem can be referenced from, if the scheduler is suspended.\n * If an interrupt needs to unblock a task while the scheduler is suspended then it\n * moves the task's event list item into the xPendingReadyList, ready for the\n * kernel to move the task from the pending ready list into the real ready list\n * when the scheduler is unsuspended.  The pending ready list itself can only be\n * accessed from a critical section.\n *\n * Updates to uxSchedulerSuspended must be protected by both the task lock and the ISR lock\n * and must not be done from an ISR. Reads must be protected by either lock and may be done\n * from either an ISR or a task. */\nPRIVILEGED_DATA static volatile UBaseType_t uxSchedulerSuspended = ( UBaseType_t ) 0U;\n\n#if ( configGENERATE_RUN_TIME_STATS == 1 )\n\n/* Do not move these variables to function scope as doing so prevents the\n * code working with debuggers that need to remove the static qualifier. */\nPRIVILEGED_DATA static configRUN_TIME_COUNTER_TYPE ulTaskSwitchedInTime[ configNUMBER_OF_CORES ] = { 0U };    /**< Holds the value of a timer/counter the last time a task was switched in. */\nPRIVILEGED_DATA static volatile configRUN_TIME_COUNTER_TYPE ulTotalRunTime[ configNUMBER_OF_CORES ] = { 0U }; /**< Holds the total amount of execution time as defined by the run time counter clock. */\n\n#endif\n\n/*-----------------------------------------------------------*/\n\n/* File private functions. --------------------------------*/\n\n/*\n * Creates the idle tasks during scheduler start.\n */\nstatic BaseType_t prvCreateIdleTasks( void );\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n/*\n * Checks to see if another task moved the current task out of the ready\n * list while it was waiting to enter a critical section and yields, if so.\n */\n    static void prvCheckForRunStateChange( void );\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n/*\n * Yields a core, or cores if multiple priorities are not allowed to run\n * simultaneously, to allow the task pxTCB to run.\n */\n    static void prvYieldForTask( const TCB_t * pxTCB );\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n/*\n * Selects the highest priority available task for the given core.\n */\n    static void prvSelectHighestPriorityTask( BaseType_t xCoreID );\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n/**\n * Utility task that simply returns pdTRUE if the task referenced by xTask is\n * currently in the Suspended state, or pdFALSE if the task referenced by xTask\n * is in any other state.\n */\n#if ( INCLUDE_vTaskSuspend == 1 )\n\n    static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask ) PRIVILEGED_FUNCTION;\n\n#endif /* INCLUDE_vTaskSuspend */\n\n/*\n * Utility to ready all the lists used by the scheduler.  This is called\n * automatically upon the creation of the first task.\n */\nstatic void prvInitialiseTaskLists( void ) PRIVILEGED_FUNCTION;\n\n/*\n * The idle task, which as all tasks is implemented as a never ending loop.\n * The idle task is automatically created and added to the ready lists upon\n * creation of the first user task.\n *\n * In the FreeRTOS SMP, configNUMBER_OF_CORES - 1 passive idle tasks are also\n * created to ensure that each core has an idle task to run when no other\n * task is available to run.\n *\n * The portTASK_FUNCTION_PROTO() macro is used to allow port/compiler specific\n * language extensions.  The equivalent prototype for these functions are:\n *\n * void prvIdleTask( void *pvParameters );\n * void prvPassiveIdleTask( void *pvParameters );\n *\n */\nstatic portTASK_FUNCTION_PROTO( prvIdleTask, pvParameters ) PRIVILEGED_FUNCTION;\n#if ( configNUMBER_OF_CORES > 1 )\n    static portTASK_FUNCTION_PROTO( prvPassiveIdleTask, pvParameters ) PRIVILEGED_FUNCTION;\n#endif\n\n/*\n * Utility to free all memory allocated by the scheduler to hold a TCB,\n * including the stack pointed to by the TCB.\n *\n * This does not free memory allocated by the task itself (i.e. memory\n * allocated by calls to pvPortMalloc from within the tasks application code).\n */\n#if ( INCLUDE_vTaskDelete == 1 )\n\n    static void prvDeleteTCB( TCB_t * pxTCB ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * Used only by the idle task.  This checks to see if anything has been placed\n * in the list of tasks waiting to be deleted.  If so the task is cleaned up\n * and its TCB deleted.\n */\nstatic void prvCheckTasksWaitingTermination( void ) PRIVILEGED_FUNCTION;\n\n/*\n * The currently executing task is entering the Blocked state.  Add the task to\n * either the current or the overflow delayed task list.\n */\nstatic void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait,\n                                            const BaseType_t xCanBlockIndefinitely ) PRIVILEGED_FUNCTION;\n\n/*\n * Fills an TaskStatus_t structure with information on each task that is\n * referenced from the pxList list (which may be a ready list, a delayed list,\n * a suspended list, etc.).\n *\n * THIS FUNCTION IS INTENDED FOR DEBUGGING ONLY, AND SHOULD NOT BE CALLED FROM\n * NORMAL APPLICATION CODE.\n */\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    static UBaseType_t prvListTasksWithinSingleList( TaskStatus_t * pxTaskStatusArray,\n                                                     List_t * pxList,\n                                                     eTaskState eState ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * Searches pxList for a task with name pcNameToQuery - returning a handle to\n * the task if it is found, or NULL if the task is not found.\n */\n#if ( INCLUDE_xTaskGetHandle == 1 )\n\n    static TCB_t * prvSearchForNameWithinSingleList( List_t * pxList,\n                                                     const char pcNameToQuery[] ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * When a task is created, the stack of the task is filled with a known value.\n * This function determines the 'high water mark' of the task stack by\n * determining how much of the stack remains at the original preset value.\n */\n#if ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark2 == 1 ) )\n\n    static configSTACK_DEPTH_TYPE prvTaskCheckFreeStackSpace( const uint8_t * pucStackByte ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * Return the amount of time, in ticks, that will pass before the kernel will\n * next move a task from the Blocked state to the Running state or before the\n * tick count overflows (whichever is earlier).\n *\n * This conditional compilation should use inequality to 0, not equality to 1.\n * This is to ensure portSUPPRESS_TICKS_AND_SLEEP() can be called when user\n * defined low power mode implementations require configUSE_TICKLESS_IDLE to be\n * set to a value other than 1.\n */\n#if ( configUSE_TICKLESS_IDLE != 0 )\n\n    static TickType_t prvGetExpectedIdleTime( void ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * Set xNextTaskUnblockTime to the time at which the next Blocked state task\n * will exit the Blocked state.\n */\nstatic void prvResetNextTaskUnblockTime( void ) PRIVILEGED_FUNCTION;\n\n#if ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 )\n\n/*\n * Helper function used to pad task names with spaces when printing out\n * human readable tables of task information.\n */\n    static char * prvWriteNameToBuffer( char * pcBuffer,\n                                        const char * pcTaskName ) PRIVILEGED_FUNCTION;\n\n#endif\n\n/*\n * Called after a Task_t structure has been allocated either statically or\n * dynamically to fill in the structure's members.\n */\nstatic void prvInitialiseNewTask( TaskFunction_t pxTaskCode,\n                                  const char * const pcName,\n                                  const configSTACK_DEPTH_TYPE uxStackDepth,\n                                  void * const pvParameters,\n                                  UBaseType_t uxPriority,\n                                  TaskHandle_t * const pxCreatedTask,\n                                  TCB_t * pxNewTCB,\n                                  const MemoryRegion_t * const xRegions ) PRIVILEGED_FUNCTION;\n\n/*\n * Called after a new task has been created and initialised to place the task\n * under the control of the scheduler.\n */\nstatic void prvAddNewTaskToReadyList( TCB_t * pxNewTCB ) PRIVILEGED_FUNCTION;\n\n/*\n * Create a task with static buffer for both TCB and stack. Returns a handle to\n * the task if it is created successfully. Otherwise, returns NULL.\n */\n#if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n    static TCB_t * prvCreateStaticTask( TaskFunction_t pxTaskCode,\n                                        const char * const pcName,\n                                        const configSTACK_DEPTH_TYPE uxStackDepth,\n                                        void * const pvParameters,\n                                        UBaseType_t uxPriority,\n                                        StackType_t * const puxStackBuffer,\n                                        StaticTask_t * const pxTaskBuffer,\n                                        TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;\n#endif /* #if ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n\n/*\n * Create a restricted task with static buffer for both TCB and stack. Returns\n * a handle to the task if it is created successfully. Otherwise, returns NULL.\n */\n#if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n    static TCB_t * prvCreateRestrictedStaticTask( const TaskParameters_t * const pxTaskDefinition,\n                                                  TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;\n#endif /* #if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) ) */\n\n/*\n * Create a restricted task with static buffer for task stack and allocated buffer\n * for TCB. Returns a handle to the task if it is created successfully. Otherwise,\n * returns NULL.\n */\n#if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n    static TCB_t * prvCreateRestrictedTask( const TaskParameters_t * const pxTaskDefinition,\n                                            TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;\n#endif /* #if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */\n\n/*\n * Create a task with allocated buffer for both TCB and stack. Returns a handle to\n * the task if it is created successfully. Otherwise, returns NULL.\n */\n#if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n    static TCB_t * prvCreateTask( TaskFunction_t pxTaskCode,\n                                  const char * const pcName,\n                                  const configSTACK_DEPTH_TYPE uxStackDepth,\n                                  void * const pvParameters,\n                                  UBaseType_t uxPriority,\n                                  TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;\n#endif /* #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) */\n\n/*\n * freertos_tasks_c_additions_init() should only be called if the user definable\n * macro FREERTOS_TASKS_C_ADDITIONS_INIT() is defined, as that is the only macro\n * called by the function.\n */\n#ifdef FREERTOS_TASKS_C_ADDITIONS_INIT\n\n    static void freertos_tasks_c_additions_init( void ) PRIVILEGED_FUNCTION;\n\n#endif\n\n#if ( configUSE_PASSIVE_IDLE_HOOK == 1 )\n    extern void vApplicationPassiveIdleHook( void );\n#endif /* #if ( configUSE_PASSIVE_IDLE_HOOK == 1 ) */\n\n#if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) )\n\n/*\n * Convert the snprintf return value to the number of characters\n * written. The following are the possible cases:\n *\n * 1. The buffer supplied to snprintf is large enough to hold the\n *    generated string. The return value in this case is the number\n *    of characters actually written, not counting the terminating\n *    null character.\n * 2. The buffer supplied to snprintf is NOT large enough to hold\n *    the generated string. The return value in this case is the\n *    number of characters that would have been written if the\n *    buffer had been sufficiently large, not counting the\n *    terminating null character.\n * 3. Encoding error. The return value in this case is a negative\n *    number.\n *\n * From 1 and 2 above ==> Only when the return value is non-negative\n * and less than the supplied buffer length, the string has been\n * completely written.\n */\n    static size_t prvSnprintfReturnValueToCharsWritten( int iSnprintfReturnValue,\n                                                        size_t n );\n\n#endif /* #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n    static void prvCheckForRunStateChange( void )\n    {\n        UBaseType_t uxPrevCriticalNesting;\n        const TCB_t * pxThisTCB;\n        BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n        /* This must only be called from within a task. */\n        portASSERT_IF_IN_ISR();\n\n        /* This function is always called with interrupts disabled\n         * so this is safe. */\n        pxThisTCB = pxCurrentTCBs[ xCoreID ];\n\n        while( pxThisTCB->xTaskRunState == taskTASK_SCHEDULED_TO_YIELD )\n        {\n            /* We are only here if we just entered a critical section\n            * or if we just suspended the scheduler, and another task\n            * has requested that we yield.\n            *\n            * This is slightly complicated since we need to save and restore\n            * the suspension and critical nesting counts, as well as release\n            * and reacquire the correct locks. And then, do it all over again\n            * if our state changed again during the reacquisition. */\n            uxPrevCriticalNesting = portGET_CRITICAL_NESTING_COUNT( xCoreID );\n\n            if( uxPrevCriticalNesting > 0U )\n            {\n                portSET_CRITICAL_NESTING_COUNT( xCoreID, 0U );\n                portRELEASE_ISR_LOCK( xCoreID );\n            }\n            else\n            {\n                /* The scheduler is suspended. uxSchedulerSuspended is updated\n                 * only when the task is not requested to yield. */\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            portRELEASE_TASK_LOCK( xCoreID );\n            portMEMORY_BARRIER();\n            configASSERT( pxThisTCB->xTaskRunState == taskTASK_SCHEDULED_TO_YIELD );\n\n            portENABLE_INTERRUPTS();\n\n            /* Enabling interrupts should cause this core to immediately service\n             * the pending interrupt and yield. After servicing the pending interrupt,\n             * the task needs to re-evaluate its run state within this loop, as\n             * other cores may have requested this task to yield, potentially altering\n             * its run state. */\n\n            portDISABLE_INTERRUPTS();\n\n            xCoreID = ( BaseType_t ) portGET_CORE_ID();\n            portGET_TASK_LOCK( xCoreID );\n            portGET_ISR_LOCK( xCoreID );\n\n            portSET_CRITICAL_NESTING_COUNT( xCoreID, uxPrevCriticalNesting );\n\n            if( uxPrevCriticalNesting == 0U )\n            {\n                portRELEASE_ISR_LOCK( xCoreID );\n            }\n        }\n    }\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n    static void prvYieldForTask( const TCB_t * pxTCB )\n    {\n        BaseType_t xLowestPriorityToPreempt;\n        BaseType_t xCurrentCoreTaskPriority;\n        BaseType_t xLowestPriorityCore = ( BaseType_t ) -1;\n        BaseType_t xCoreID;\n        const BaseType_t xCurrentCoreID = portGET_CORE_ID();\n\n        #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n            BaseType_t xYieldCount = 0;\n        #endif /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n\n        /* This must be called from a critical section. */\n        configASSERT( portGET_CRITICAL_NESTING_COUNT( xCurrentCoreID ) > 0U );\n\n        #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n\n            /* No task should yield for this one if it is a lower priority\n             * than priority level of currently ready tasks. */\n            if( pxTCB->uxPriority >= uxTopReadyPriority )\n        #else\n            /* Yield is not required for a task which is already running. */\n            if( taskTASK_IS_RUNNING( pxTCB ) == pdFALSE )\n        #endif\n        {\n            xLowestPriorityToPreempt = ( BaseType_t ) pxTCB->uxPriority;\n\n            /* xLowestPriorityToPreempt will be decremented to -1 if the priority of pxTCB\n             * is 0. This is ok as we will give system idle tasks a priority of -1 below. */\n            --xLowestPriorityToPreempt;\n\n            for( xCoreID = ( BaseType_t ) 0; xCoreID < ( BaseType_t ) configNUMBER_OF_CORES; xCoreID++ )\n            {\n                xCurrentCoreTaskPriority = ( BaseType_t ) pxCurrentTCBs[ xCoreID ]->uxPriority;\n\n                /* System idle tasks are being assigned a priority of tskIDLE_PRIORITY - 1 here. */\n                if( ( pxCurrentTCBs[ xCoreID ]->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) != 0U )\n                {\n                    xCurrentCoreTaskPriority = ( BaseType_t ) ( xCurrentCoreTaskPriority - 1 );\n                }\n\n                if( ( taskTASK_IS_RUNNING( pxCurrentTCBs[ xCoreID ] ) != pdFALSE ) && ( xYieldPendings[ xCoreID ] == pdFALSE ) )\n                {\n                    #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                        if( taskTASK_IS_RUNNING( pxTCB ) == pdFALSE )\n                    #endif\n                    {\n                        if( xCurrentCoreTaskPriority <= xLowestPriorityToPreempt )\n                        {\n                            #if ( configUSE_CORE_AFFINITY == 1 )\n                                if( ( pxTCB->uxCoreAffinityMask & ( ( UBaseType_t ) 1U << ( UBaseType_t ) xCoreID ) ) != 0U )\n                            #endif\n                            {\n                                #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n                                    if( pxCurrentTCBs[ xCoreID ]->xPreemptionDisable == pdFALSE )\n                                #endif\n                                {\n                                    xLowestPriorityToPreempt = xCurrentCoreTaskPriority;\n                                    xLowestPriorityCore = xCoreID;\n                                }\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n\n                    #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                    {\n                        /* Yield all currently running non-idle tasks with a priority lower than\n                         * the task that needs to run. */\n                        if( ( xCurrentCoreTaskPriority > ( ( BaseType_t ) tskIDLE_PRIORITY - 1 ) ) &&\n                            ( xCurrentCoreTaskPriority < ( BaseType_t ) pxTCB->uxPriority ) )\n                        {\n                            prvYieldCore( xCoreID );\n                            xYieldCount++;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    #endif /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n\n            #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                if( ( xYieldCount == 0 ) && ( xLowestPriorityCore >= 0 ) )\n            #else /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n                if( xLowestPriorityCore >= 0 )\n            #endif /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n            {\n                prvYieldCore( xLowestPriorityCore );\n            }\n\n            #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                /* Verify that the calling core always yields to higher priority tasks. */\n                if( ( ( pxCurrentTCBs[ xCurrentCoreID ]->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) == 0U ) &&\n                    ( pxTCB->uxPriority > pxCurrentTCBs[ xCurrentCoreID ]->uxPriority ) )\n                {\n                    configASSERT( ( xYieldPendings[ xCurrentCoreID ] == pdTRUE ) ||\n                                  ( taskTASK_IS_RUNNING( pxCurrentTCBs[ xCurrentCoreID ] ) == pdFALSE ) );\n                }\n            #endif\n        }\n    }\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n    static void prvSelectHighestPriorityTask( BaseType_t xCoreID )\n    {\n        UBaseType_t uxCurrentPriority = uxTopReadyPriority;\n        BaseType_t xTaskScheduled = pdFALSE;\n        BaseType_t xDecrementTopPriority = pdTRUE;\n        TCB_t * pxTCB = NULL;\n\n        #if ( configUSE_CORE_AFFINITY == 1 )\n            const TCB_t * pxPreviousTCB = NULL;\n        #endif\n        #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n            BaseType_t xPriorityDropped = pdFALSE;\n        #endif\n\n        /* This function should be called when scheduler is running. */\n        configASSERT( xSchedulerRunning == pdTRUE );\n\n        /* A new task is created and a running task with the same priority yields\n         * itself to run the new task. When a running task yields itself, it is still\n         * in the ready list. This running task will be selected before the new task\n         * since the new task is always added to the end of the ready list.\n         * The other problem is that the running task still in the same position of\n         * the ready list when it yields itself. It is possible that it will be selected\n         * earlier then other tasks which waits longer than this task.\n         *\n         * To fix these problems, the running task should be put to the end of the\n         * ready list before searching for the ready task in the ready list. */\n        if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxCurrentTCBs[ xCoreID ]->uxPriority ] ),\n                                     &pxCurrentTCBs[ xCoreID ]->xStateListItem ) == pdTRUE )\n        {\n            ( void ) uxListRemove( &pxCurrentTCBs[ xCoreID ]->xStateListItem );\n            vListInsertEnd( &( pxReadyTasksLists[ pxCurrentTCBs[ xCoreID ]->uxPriority ] ),\n                            &pxCurrentTCBs[ xCoreID ]->xStateListItem );\n        }\n\n        while( xTaskScheduled == pdFALSE )\n        {\n            #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n            {\n                if( uxCurrentPriority < uxTopReadyPriority )\n                {\n                    /* We can't schedule any tasks, other than idle, that have a\n                     * priority lower than the priority of a task currently running\n                     * on another core. */\n                    uxCurrentPriority = tskIDLE_PRIORITY;\n                }\n            }\n            #endif\n\n            if( listLIST_IS_EMPTY( &( pxReadyTasksLists[ uxCurrentPriority ] ) ) == pdFALSE )\n            {\n                const List_t * const pxReadyList = &( pxReadyTasksLists[ uxCurrentPriority ] );\n                const ListItem_t * pxEndMarker = listGET_END_MARKER( pxReadyList );\n                ListItem_t * pxIterator;\n\n                /* The ready task list for uxCurrentPriority is not empty, so uxTopReadyPriority\n                 * must not be decremented any further. */\n                xDecrementTopPriority = pdFALSE;\n\n                for( pxIterator = listGET_HEAD_ENTRY( pxReadyList ); pxIterator != pxEndMarker; pxIterator = listGET_NEXT( pxIterator ) )\n                {\n                    /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                    /* coverity[misra_c_2012_rule_11_5_violation] */\n                    pxTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxIterator );\n\n                    #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                    {\n                        /* When falling back to the idle priority because only one priority\n                         * level is allowed to run at a time, we should ONLY schedule the true\n                         * idle tasks, not user tasks at the idle priority. */\n                        if( uxCurrentPriority < uxTopReadyPriority )\n                        {\n                            if( ( pxTCB->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) == 0U )\n                            {\n                                continue;\n                            }\n                        }\n                    }\n                    #endif /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n\n                    if( pxTCB->xTaskRunState == taskTASK_NOT_RUNNING )\n                    {\n                        #if ( configUSE_CORE_AFFINITY == 1 )\n                            if( ( pxTCB->uxCoreAffinityMask & ( ( UBaseType_t ) 1U << ( UBaseType_t ) xCoreID ) ) != 0U )\n                        #endif\n                        {\n                            /* If the task is not being executed by any core swap it in. */\n                            pxCurrentTCBs[ xCoreID ]->xTaskRunState = taskTASK_NOT_RUNNING;\n                            #if ( configUSE_CORE_AFFINITY == 1 )\n                                pxPreviousTCB = pxCurrentTCBs[ xCoreID ];\n                            #endif\n                            pxTCB->xTaskRunState = xCoreID;\n                            pxCurrentTCBs[ xCoreID ] = pxTCB;\n                            xTaskScheduled = pdTRUE;\n                        }\n                    }\n                    else if( pxTCB == pxCurrentTCBs[ xCoreID ] )\n                    {\n                        configASSERT( ( pxTCB->xTaskRunState == xCoreID ) || ( pxTCB->xTaskRunState == taskTASK_SCHEDULED_TO_YIELD ) );\n\n                        #if ( configUSE_CORE_AFFINITY == 1 )\n                            if( ( pxTCB->uxCoreAffinityMask & ( ( UBaseType_t ) 1U << ( UBaseType_t ) xCoreID ) ) != 0U )\n                        #endif\n                        {\n                            /* The task is already running on this core, mark it as scheduled. */\n                            pxTCB->xTaskRunState = xCoreID;\n                            xTaskScheduled = pdTRUE;\n                        }\n                    }\n                    else\n                    {\n                        /* This task is running on the core other than xCoreID. */\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    if( xTaskScheduled != pdFALSE )\n                    {\n                        /* A task has been selected to run on this core. */\n                        break;\n                    }\n                }\n            }\n            else\n            {\n                if( xDecrementTopPriority != pdFALSE )\n                {\n                    uxTopReadyPriority--;\n                    #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n                    {\n                        xPriorityDropped = pdTRUE;\n                    }\n                    #endif\n                }\n            }\n\n            /* There are configNUMBER_OF_CORES Idle tasks created when scheduler started.\n             * The scheduler should be able to select a task to run when uxCurrentPriority\n             * is tskIDLE_PRIORITY. uxCurrentPriority is never decreased to value blow\n             * tskIDLE_PRIORITY. */\n            if( uxCurrentPriority > tskIDLE_PRIORITY )\n            {\n                uxCurrentPriority--;\n            }\n            else\n            {\n                /* This function is called when idle task is not created. Break the\n                 * loop to prevent uxCurrentPriority overrun. */\n                break;\n            }\n        }\n\n        #if ( configRUN_MULTIPLE_PRIORITIES == 0 )\n        {\n            if( xTaskScheduled == pdTRUE )\n            {\n                if( xPriorityDropped != pdFALSE )\n                {\n                    /* There may be several ready tasks that were being prevented from running because there was\n                     * a higher priority task running. Now that the last of the higher priority tasks is no longer\n                     * running, make sure all the other idle tasks yield. */\n                    BaseType_t x;\n\n                    for( x = ( BaseType_t ) 0; x < ( BaseType_t ) configNUMBER_OF_CORES; x++ )\n                    {\n                        if( ( pxCurrentTCBs[ x ]->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) != 0U )\n                        {\n                            prvYieldCore( x );\n                        }\n                    }\n                }\n            }\n        }\n        #endif /* #if ( configRUN_MULTIPLE_PRIORITIES == 0 ) */\n\n        #if ( configUSE_CORE_AFFINITY == 1 )\n        {\n            if( xTaskScheduled == pdTRUE )\n            {\n                if( ( pxPreviousTCB != NULL ) && ( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxPreviousTCB->uxPriority ] ), &( pxPreviousTCB->xStateListItem ) ) != pdFALSE ) )\n                {\n                    /* A ready task was just evicted from this core. See if it can be\n                     * scheduled on any other core. */\n                    UBaseType_t uxCoreMap = pxPreviousTCB->uxCoreAffinityMask;\n                    BaseType_t xLowestPriority = ( BaseType_t ) pxPreviousTCB->uxPriority;\n                    BaseType_t xLowestPriorityCore = -1;\n                    BaseType_t x;\n\n                    if( ( pxPreviousTCB->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) != 0U )\n                    {\n                        xLowestPriority = xLowestPriority - 1;\n                    }\n\n                    if( ( uxCoreMap & ( ( UBaseType_t ) 1U << ( UBaseType_t ) xCoreID ) ) != 0U )\n                    {\n                        /* pxPreviousTCB was removed from this core and this core is not excluded\n                         * from it's core affinity mask.\n                         *\n                         * pxPreviousTCB is preempted by the new higher priority task\n                         * pxCurrentTCBs[ xCoreID ]. When searching a new core for pxPreviousTCB,\n                         * we do not need to look at the cores on which pxCurrentTCBs[ xCoreID ]\n                         * is allowed to run. The reason is - when more than one cores are\n                         * eligible for an incoming task, we preempt the core with the minimum\n                         * priority task. Because this core (i.e. xCoreID) was preempted for\n                         * pxCurrentTCBs[ xCoreID ], this means that all the others cores\n                         * where pxCurrentTCBs[ xCoreID ] can run, are running tasks with priority\n                         * no lower than pxPreviousTCB's priority. Therefore, the only cores where\n                         * which can be preempted for pxPreviousTCB are the ones where\n                         * pxCurrentTCBs[ xCoreID ] is not allowed to run (and obviously,\n                         * pxPreviousTCB is allowed to run).\n                         *\n                         * This is an optimization which reduces the number of cores needed to be\n                         * searched for pxPreviousTCB to run. */\n                        uxCoreMap &= ~( pxCurrentTCBs[ xCoreID ]->uxCoreAffinityMask );\n                    }\n                    else\n                    {\n                        /* pxPreviousTCB's core affinity mask is changed and it is no longer\n                         * allowed to run on this core. Searching all the cores in pxPreviousTCB's\n                         * new core affinity mask to find a core on which it can run. */\n                    }\n\n                    uxCoreMap &= ( ( 1U << configNUMBER_OF_CORES ) - 1U );\n\n                    for( x = ( ( BaseType_t ) configNUMBER_OF_CORES - 1 ); x >= ( BaseType_t ) 0; x-- )\n                    {\n                        UBaseType_t uxCore = ( UBaseType_t ) x;\n                        BaseType_t xTaskPriority;\n\n                        if( ( uxCoreMap & ( ( UBaseType_t ) 1U << uxCore ) ) != 0U )\n                        {\n                            xTaskPriority = ( BaseType_t ) pxCurrentTCBs[ uxCore ]->uxPriority;\n\n                            if( ( pxCurrentTCBs[ uxCore ]->uxTaskAttributes & taskATTRIBUTE_IS_IDLE ) != 0U )\n                            {\n                                xTaskPriority = xTaskPriority - ( BaseType_t ) 1;\n                            }\n\n                            uxCoreMap &= ~( ( UBaseType_t ) 1U << uxCore );\n\n                            if( ( xTaskPriority < xLowestPriority ) &&\n                                ( taskTASK_IS_RUNNING( pxCurrentTCBs[ uxCore ] ) != pdFALSE ) &&\n                                ( xYieldPendings[ uxCore ] == pdFALSE ) )\n                            {\n                                #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n                                    if( pxCurrentTCBs[ uxCore ]->xPreemptionDisable == pdFALSE )\n                                #endif\n                                {\n                                    xLowestPriority = xTaskPriority;\n                                    xLowestPriorityCore = ( BaseType_t ) uxCore;\n                                }\n                            }\n                        }\n                    }\n\n                    if( xLowestPriorityCore >= 0 )\n                    {\n                        prvYieldCore( xLowestPriorityCore );\n                    }\n                }\n            }\n        }\n        #endif /* #if ( configUSE_CORE_AFFINITY == 1 ) */\n    }\n\n#endif /* ( configNUMBER_OF_CORES > 1 ) */\n\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n    static TCB_t * prvCreateStaticTask( TaskFunction_t pxTaskCode,\n                                        const char * const pcName,\n                                        const configSTACK_DEPTH_TYPE uxStackDepth,\n                                        void * const pvParameters,\n                                        UBaseType_t uxPriority,\n                                        StackType_t * const puxStackBuffer,\n                                        StaticTask_t * const pxTaskBuffer,\n                                        TaskHandle_t * const pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n\n        configASSERT( puxStackBuffer != NULL );\n        configASSERT( pxTaskBuffer != NULL );\n\n        #if ( configASSERT_DEFINED == 1 )\n        {\n            /* Sanity check that the size of the structure used to declare a\n             * variable of type StaticTask_t equals the size of the real task\n             * structure. */\n            volatile size_t xSize = sizeof( StaticTask_t );\n            configASSERT( xSize == sizeof( TCB_t ) );\n            ( void ) xSize; /* Prevent unused variable warning when configASSERT() is not used. */\n        }\n        #endif /* configASSERT_DEFINED */\n\n        if( ( pxTaskBuffer != NULL ) && ( puxStackBuffer != NULL ) )\n        {\n            /* The memory used for the task's TCB and stack are passed into this\n             * function - use them. */\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            pxNewTCB = ( TCB_t * ) pxTaskBuffer;\n            ( void ) memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );\n            pxNewTCB->pxStack = ( StackType_t * ) puxStackBuffer;\n\n            #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n            {\n                /* Tasks can be created statically or dynamically, so note this\n                 * task was created statically in case the task is later deleted. */\n                pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_AND_TCB;\n            }\n            #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */\n\n            prvInitialiseNewTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );\n        }\n        else\n        {\n            pxNewTCB = NULL;\n        }\n\n        return pxNewTCB;\n    }\n/*-----------------------------------------------------------*/\n\n    TaskHandle_t xTaskCreateStatic( TaskFunction_t pxTaskCode,\n                                    const char * const pcName,\n                                    const configSTACK_DEPTH_TYPE uxStackDepth,\n                                    void * const pvParameters,\n                                    UBaseType_t uxPriority,\n                                    StackType_t * const puxStackBuffer,\n                                    StaticTask_t * const pxTaskBuffer )\n    {\n        TaskHandle_t xReturn = NULL;\n        TCB_t * pxNewTCB;\n\n        traceENTER_xTaskCreateStatic( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, puxStackBuffer, pxTaskBuffer );\n\n        pxNewTCB = prvCreateStaticTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, puxStackBuffer, pxTaskBuffer, &xReturn );\n\n        if( pxNewTCB != NULL )\n        {\n            #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = configTASK_DEFAULT_CORE_AFFINITY;\n            }\n            #endif\n\n            prvAddNewTaskToReadyList( pxNewTCB );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTaskCreateStatic( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n        TaskHandle_t xTaskCreateStaticAffinitySet( TaskFunction_t pxTaskCode,\n                                                   const char * const pcName,\n                                                   const configSTACK_DEPTH_TYPE uxStackDepth,\n                                                   void * const pvParameters,\n                                                   UBaseType_t uxPriority,\n                                                   StackType_t * const puxStackBuffer,\n                                                   StaticTask_t * const pxTaskBuffer,\n                                                   UBaseType_t uxCoreAffinityMask )\n        {\n            TaskHandle_t xReturn = NULL;\n            TCB_t * pxNewTCB;\n\n            traceENTER_xTaskCreateStaticAffinitySet( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, puxStackBuffer, pxTaskBuffer, uxCoreAffinityMask );\n\n            pxNewTCB = prvCreateStaticTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, puxStackBuffer, pxTaskBuffer, &xReturn );\n\n            if( pxNewTCB != NULL )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = uxCoreAffinityMask;\n\n                prvAddNewTaskToReadyList( pxNewTCB );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            traceRETURN_xTaskCreateStaticAffinitySet( xReturn );\n\n            return xReturn;\n        }\n    #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n#endif /* SUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n#if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )\n    static TCB_t * prvCreateRestrictedStaticTask( const TaskParameters_t * const pxTaskDefinition,\n                                                  TaskHandle_t * const pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n\n        configASSERT( pxTaskDefinition->puxStackBuffer != NULL );\n        configASSERT( pxTaskDefinition->pxTaskBuffer != NULL );\n\n        if( ( pxTaskDefinition->puxStackBuffer != NULL ) && ( pxTaskDefinition->pxTaskBuffer != NULL ) )\n        {\n            /* Allocate space for the TCB.  Where the memory comes from depends\n             * on the implementation of the port malloc function and whether or\n             * not static allocation is being used. */\n            pxNewTCB = ( TCB_t * ) pxTaskDefinition->pxTaskBuffer;\n            ( void ) memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );\n\n            /* Store the stack location in the TCB. */\n            pxNewTCB->pxStack = pxTaskDefinition->puxStackBuffer;\n\n            #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n            {\n                /* Tasks can be created statically or dynamically, so note this\n                 * task was created statically in case the task is later deleted. */\n                pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_AND_TCB;\n            }\n            #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */\n\n            prvInitialiseNewTask( pxTaskDefinition->pvTaskCode,\n                                  pxTaskDefinition->pcName,\n                                  pxTaskDefinition->usStackDepth,\n                                  pxTaskDefinition->pvParameters,\n                                  pxTaskDefinition->uxPriority,\n                                  pxCreatedTask, pxNewTCB,\n                                  pxTaskDefinition->xRegions );\n        }\n        else\n        {\n            pxNewTCB = NULL;\n        }\n\n        return pxNewTCB;\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTaskCreateRestrictedStatic( const TaskParameters_t * const pxTaskDefinition,\n                                            TaskHandle_t * pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskCreateRestrictedStatic( pxTaskDefinition, pxCreatedTask );\n\n        configASSERT( pxTaskDefinition != NULL );\n\n        pxNewTCB = prvCreateRestrictedStaticTask( pxTaskDefinition, pxCreatedTask );\n\n        if( pxNewTCB != NULL )\n        {\n            #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = configTASK_DEFAULT_CORE_AFFINITY;\n            }\n            #endif\n\n            prvAddNewTaskToReadyList( pxNewTCB );\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n        }\n\n        traceRETURN_xTaskCreateRestrictedStatic( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n        BaseType_t xTaskCreateRestrictedStaticAffinitySet( const TaskParameters_t * const pxTaskDefinition,\n                                                           UBaseType_t uxCoreAffinityMask,\n                                                           TaskHandle_t * pxCreatedTask )\n        {\n            TCB_t * pxNewTCB;\n            BaseType_t xReturn;\n\n            traceENTER_xTaskCreateRestrictedStaticAffinitySet( pxTaskDefinition, uxCoreAffinityMask, pxCreatedTask );\n\n            configASSERT( pxTaskDefinition != NULL );\n\n            pxNewTCB = prvCreateRestrictedStaticTask( pxTaskDefinition, pxCreatedTask );\n\n            if( pxNewTCB != NULL )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = uxCoreAffinityMask;\n\n                prvAddNewTaskToReadyList( pxNewTCB );\n                xReturn = pdPASS;\n            }\n            else\n            {\n                xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n            }\n\n            traceRETURN_xTaskCreateRestrictedStaticAffinitySet( xReturn );\n\n            return xReturn;\n        }\n    #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n#endif /* ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )\n    static TCB_t * prvCreateRestrictedTask( const TaskParameters_t * const pxTaskDefinition,\n                                            TaskHandle_t * const pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n\n        configASSERT( pxTaskDefinition->puxStackBuffer );\n\n        if( pxTaskDefinition->puxStackBuffer != NULL )\n        {\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );\n\n            if( pxNewTCB != NULL )\n            {\n                ( void ) memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );\n\n                /* Store the stack location in the TCB. */\n                pxNewTCB->pxStack = pxTaskDefinition->puxStackBuffer;\n\n                #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n                {\n                    /* Tasks can be created statically or dynamically, so note\n                     * this task had a statically allocated stack in case it is\n                     * later deleted.  The TCB was allocated dynamically. */\n                    pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_ONLY;\n                }\n                #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */\n\n                prvInitialiseNewTask( pxTaskDefinition->pvTaskCode,\n                                      pxTaskDefinition->pcName,\n                                      pxTaskDefinition->usStackDepth,\n                                      pxTaskDefinition->pvParameters,\n                                      pxTaskDefinition->uxPriority,\n                                      pxCreatedTask, pxNewTCB,\n                                      pxTaskDefinition->xRegions );\n            }\n        }\n        else\n        {\n            pxNewTCB = NULL;\n        }\n\n        return pxNewTCB;\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTaskCreateRestricted( const TaskParameters_t * const pxTaskDefinition,\n                                      TaskHandle_t * pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskCreateRestricted( pxTaskDefinition, pxCreatedTask );\n\n        pxNewTCB = prvCreateRestrictedTask( pxTaskDefinition, pxCreatedTask );\n\n        if( pxNewTCB != NULL )\n        {\n            #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = configTASK_DEFAULT_CORE_AFFINITY;\n            }\n            #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n            prvAddNewTaskToReadyList( pxNewTCB );\n\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n        }\n\n        traceRETURN_xTaskCreateRestricted( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n        BaseType_t xTaskCreateRestrictedAffinitySet( const TaskParameters_t * const pxTaskDefinition,\n                                                     UBaseType_t uxCoreAffinityMask,\n                                                     TaskHandle_t * pxCreatedTask )\n        {\n            TCB_t * pxNewTCB;\n            BaseType_t xReturn;\n\n            traceENTER_xTaskCreateRestrictedAffinitySet( pxTaskDefinition, uxCoreAffinityMask, pxCreatedTask );\n\n            pxNewTCB = prvCreateRestrictedTask( pxTaskDefinition, pxCreatedTask );\n\n            if( pxNewTCB != NULL )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = uxCoreAffinityMask;\n\n                prvAddNewTaskToReadyList( pxNewTCB );\n\n                xReturn = pdPASS;\n            }\n            else\n            {\n                xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n            }\n\n            traceRETURN_xTaskCreateRestrictedAffinitySet( xReturn );\n\n            return xReturn;\n        }\n    #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n\n#endif /* portUSING_MPU_WRAPPERS */\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n    static TCB_t * prvCreateTask( TaskFunction_t pxTaskCode,\n                                  const char * const pcName,\n                                  const configSTACK_DEPTH_TYPE uxStackDepth,\n                                  void * const pvParameters,\n                                  UBaseType_t uxPriority,\n                                  TaskHandle_t * const pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n\n        /* If the stack grows down then allocate the stack then the TCB so the stack\n         * does not grow into the TCB.  Likewise if the stack grows up then allocate\n         * the TCB then the stack. */\n        #if ( portSTACK_GROWTH > 0 )\n        {\n            /* Allocate space for the TCB.  Where the memory comes from depends on\n             * the implementation of the port malloc function and whether or not static\n             * allocation is being used. */\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );\n\n            if( pxNewTCB != NULL )\n            {\n                ( void ) memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );\n\n                /* Allocate space for the stack used by the task being created.\n                 * The base of the stack memory stored in the TCB so the task can\n                 * be deleted later if required. */\n                /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                /* coverity[misra_c_2012_rule_11_5_violation] */\n                pxNewTCB->pxStack = ( StackType_t * ) pvPortMallocStack( ( ( ( size_t ) uxStackDepth ) * sizeof( StackType_t ) ) );\n\n                if( pxNewTCB->pxStack == NULL )\n                {\n                    /* Could not allocate the stack.  Delete the allocated TCB. */\n                    vPortFree( pxNewTCB );\n                    pxNewTCB = NULL;\n                }\n            }\n        }\n        #else /* portSTACK_GROWTH */\n        {\n            StackType_t * pxStack;\n\n            /* Allocate space for the stack used by the task being created. */\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxStack = pvPortMallocStack( ( ( ( size_t ) uxStackDepth ) * sizeof( StackType_t ) ) );\n\n            if( pxStack != NULL )\n            {\n                /* Allocate space for the TCB. */\n                /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                /* coverity[misra_c_2012_rule_11_5_violation] */\n                pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );\n\n                if( pxNewTCB != NULL )\n                {\n                    ( void ) memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );\n\n                    /* Store the stack location in the TCB. */\n                    pxNewTCB->pxStack = pxStack;\n                }\n                else\n                {\n                    /* The stack cannot be used as the TCB was not created.  Free\n                     * it again. */\n                    vPortFreeStack( pxStack );\n                }\n            }\n            else\n            {\n                pxNewTCB = NULL;\n            }\n        }\n        #endif /* portSTACK_GROWTH */\n\n        if( pxNewTCB != NULL )\n        {\n            #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n            {\n                /* Tasks can be created statically or dynamically, so note this\n                 * task was created dynamically in case it is later deleted. */\n                pxNewTCB->ucStaticallyAllocated = tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB;\n            }\n            #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */\n\n            prvInitialiseNewTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );\n        }\n\n        return pxNewTCB;\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTaskCreate( TaskFunction_t pxTaskCode,\n                            const char * const pcName,\n                            const configSTACK_DEPTH_TYPE uxStackDepth,\n                            void * const pvParameters,\n                            UBaseType_t uxPriority,\n                            TaskHandle_t * const pxCreatedTask )\n    {\n        TCB_t * pxNewTCB;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskCreate( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, pxCreatedTask );\n\n        pxNewTCB = prvCreateTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, pxCreatedTask );\n\n        if( pxNewTCB != NULL )\n        {\n            #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = configTASK_DEFAULT_CORE_AFFINITY;\n            }\n            #endif\n\n            prvAddNewTaskToReadyList( pxNewTCB );\n            xReturn = pdPASS;\n        }\n        else\n        {\n            xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n        }\n\n        traceRETURN_xTaskCreate( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n        BaseType_t xTaskCreateAffinitySet( TaskFunction_t pxTaskCode,\n                                           const char * const pcName,\n                                           const configSTACK_DEPTH_TYPE uxStackDepth,\n                                           void * const pvParameters,\n                                           UBaseType_t uxPriority,\n                                           UBaseType_t uxCoreAffinityMask,\n                                           TaskHandle_t * const pxCreatedTask )\n        {\n            TCB_t * pxNewTCB;\n            BaseType_t xReturn;\n\n            traceENTER_xTaskCreateAffinitySet( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, uxCoreAffinityMask, pxCreatedTask );\n\n            pxNewTCB = prvCreateTask( pxTaskCode, pcName, uxStackDepth, pvParameters, uxPriority, pxCreatedTask );\n\n            if( pxNewTCB != NULL )\n            {\n                /* Set the task's affinity before scheduling it. */\n                pxNewTCB->uxCoreAffinityMask = uxCoreAffinityMask;\n\n                prvAddNewTaskToReadyList( pxNewTCB );\n                xReturn = pdPASS;\n            }\n            else\n            {\n                xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;\n            }\n\n            traceRETURN_xTaskCreateAffinitySet( xReturn );\n\n            return xReturn;\n        }\n    #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n#endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\nstatic void prvInitialiseNewTask( TaskFunction_t pxTaskCode,\n                                  const char * const pcName,\n                                  const configSTACK_DEPTH_TYPE uxStackDepth,\n                                  void * const pvParameters,\n                                  UBaseType_t uxPriority,\n                                  TaskHandle_t * const pxCreatedTask,\n                                  TCB_t * pxNewTCB,\n                                  const MemoryRegion_t * const xRegions )\n{\n    StackType_t * pxTopOfStack;\n    UBaseType_t x;\n\n    #if ( portUSING_MPU_WRAPPERS == 1 )\n        /* Should the task be created in privileged mode? */\n        BaseType_t xRunPrivileged;\n\n        if( ( uxPriority & portPRIVILEGE_BIT ) != 0U )\n        {\n            xRunPrivileged = pdTRUE;\n        }\n        else\n        {\n            xRunPrivileged = pdFALSE;\n        }\n        uxPriority &= ~portPRIVILEGE_BIT;\n    #endif /* portUSING_MPU_WRAPPERS == 1 */\n\n    /* Avoid dependency on memset() if it is not required. */\n    #if ( tskSET_NEW_STACKS_TO_KNOWN_VALUE == 1 )\n    {\n        /* Fill the stack with a known value to assist debugging. */\n        ( void ) memset( pxNewTCB->pxStack, ( int ) tskSTACK_FILL_BYTE, ( size_t ) uxStackDepth * sizeof( StackType_t ) );\n    }\n    #endif /* tskSET_NEW_STACKS_TO_KNOWN_VALUE */\n\n    /* Calculate the top of stack address.  This depends on whether the stack\n     * grows from high memory to low (as per the 80x86) or vice versa.\n     * portSTACK_GROWTH is used to make the result positive or negative as required\n     * by the port. */\n    #if ( portSTACK_GROWTH < 0 )\n    {\n        pxTopOfStack = &( pxNewTCB->pxStack[ uxStackDepth - ( configSTACK_DEPTH_TYPE ) 1 ] );\n        pxTopOfStack = ( StackType_t * ) ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );\n\n        /* Check the alignment of the calculated top of stack is correct. */\n        configASSERT( ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack & ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) == 0U ) );\n\n        #if ( configRECORD_STACK_HIGH_ADDRESS == 1 )\n        {\n            /* Also record the stack's high address, which may assist\n             * debugging. */\n            pxNewTCB->pxEndOfStack = pxTopOfStack;\n        }\n        #endif /* configRECORD_STACK_HIGH_ADDRESS */\n    }\n    #else /* portSTACK_GROWTH */\n    {\n        pxTopOfStack = pxNewTCB->pxStack;\n        pxTopOfStack = ( StackType_t * ) ( ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack ) + portBYTE_ALIGNMENT_MASK ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );\n\n        /* Check the alignment of the calculated top of stack is correct. */\n        configASSERT( ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack & ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) == 0U ) );\n\n        /* The other extreme of the stack space is required if stack checking is\n         * performed. */\n        pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( uxStackDepth - ( configSTACK_DEPTH_TYPE ) 1 );\n    }\n    #endif /* portSTACK_GROWTH */\n\n    /* Store the task name in the TCB. */\n    if( pcName != NULL )\n    {\n        for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )\n        {\n            pxNewTCB->pcTaskName[ x ] = pcName[ x ];\n\n            /* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than\n             * configMAX_TASK_NAME_LEN characters just in case the memory after the\n             * string is not accessible (extremely unlikely). */\n            if( pcName[ x ] == ( char ) 0x00 )\n            {\n                break;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        /* Ensure the name string is terminated in the case that the string length\n         * was greater or equal to configMAX_TASK_NAME_LEN. */\n        pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1U ] = '\\0';\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    /* This is used as an array index so must ensure it's not too large. */\n    configASSERT( uxPriority < configMAX_PRIORITIES );\n\n    if( uxPriority >= ( UBaseType_t ) configMAX_PRIORITIES )\n    {\n        uxPriority = ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) 1U;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    pxNewTCB->uxPriority = uxPriority;\n    #if ( configUSE_MUTEXES == 1 )\n    {\n        pxNewTCB->uxBasePriority = uxPriority;\n    }\n    #endif /* configUSE_MUTEXES */\n\n    vListInitialiseItem( &( pxNewTCB->xStateListItem ) );\n    vListInitialiseItem( &( pxNewTCB->xEventListItem ) );\n\n    /* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get\n     * back to  the containing TCB from a generic item in a list. */\n    listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );\n\n    /* Event lists are always in priority order. */\n    listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority );\n    listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );\n\n    #if ( portUSING_MPU_WRAPPERS == 1 )\n    {\n        vPortStoreTaskMPUSettings( &( pxNewTCB->xMPUSettings ), xRegions, pxNewTCB->pxStack, uxStackDepth );\n    }\n    #else\n    {\n        /* Avoid compiler warning about unreferenced parameter. */\n        ( void ) xRegions;\n    }\n    #endif\n\n    #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n    {\n        /* Allocate and initialize memory for the task's TLS Block. */\n        configINIT_TLS_BLOCK( pxNewTCB->xTLSBlock, pxTopOfStack );\n    }\n    #endif\n\n    /* Initialize the TCB stack to look as if the task was already running,\n     * but had been interrupted by the scheduler.  The return address is set\n     * to the start of the task function. Once the stack has been initialised\n     * the top of stack variable is updated. */\n    #if ( portUSING_MPU_WRAPPERS == 1 )\n    {\n        /* If the port has capability to detect stack overflow,\n         * pass the stack end address to the stack initialization\n         * function as well. */\n        #if ( portHAS_STACK_OVERFLOW_CHECKING == 1 )\n        {\n            #if ( portSTACK_GROWTH < 0 )\n            {\n                pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxNewTCB->pxStack, pxTaskCode, pvParameters, xRunPrivileged, &( pxNewTCB->xMPUSettings ) );\n            }\n            #else /* portSTACK_GROWTH */\n            {\n                pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxNewTCB->pxEndOfStack, pxTaskCode, pvParameters, xRunPrivileged, &( pxNewTCB->xMPUSettings ) );\n            }\n            #endif /* portSTACK_GROWTH */\n        }\n        #else /* portHAS_STACK_OVERFLOW_CHECKING */\n        {\n            pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged, &( pxNewTCB->xMPUSettings ) );\n        }\n        #endif /* portHAS_STACK_OVERFLOW_CHECKING */\n    }\n    #else /* portUSING_MPU_WRAPPERS */\n    {\n        /* If the port has capability to detect stack overflow,\n         * pass the stack end address to the stack initialization\n         * function as well. */\n        #if ( portHAS_STACK_OVERFLOW_CHECKING == 1 )\n        {\n            #if ( portSTACK_GROWTH < 0 )\n            {\n                pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxNewTCB->pxStack, pxTaskCode, pvParameters );\n            }\n            #else /* portSTACK_GROWTH */\n            {\n                pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxNewTCB->pxEndOfStack, pxTaskCode, pvParameters );\n            }\n            #endif /* portSTACK_GROWTH */\n        }\n        #else /* portHAS_STACK_OVERFLOW_CHECKING */\n        {\n            pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );\n        }\n        #endif /* portHAS_STACK_OVERFLOW_CHECKING */\n    }\n    #endif /* portUSING_MPU_WRAPPERS */\n\n    /* Initialize task state and task attributes. */\n    #if ( configNUMBER_OF_CORES > 1 )\n    {\n        pxNewTCB->xTaskRunState = taskTASK_NOT_RUNNING;\n\n        /* Is this an idle task? */\n        if( ( ( TaskFunction_t ) pxTaskCode == ( TaskFunction_t ) prvIdleTask ) || ( ( TaskFunction_t ) pxTaskCode == ( TaskFunction_t ) prvPassiveIdleTask ) )\n        {\n            pxNewTCB->uxTaskAttributes |= taskATTRIBUTE_IS_IDLE;\n        }\n    }\n    #endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n    if( pxCreatedTask != NULL )\n    {\n        /* Pass the handle out in an anonymous way.  The handle can be used to\n         * change the created task's priority, delete the created task, etc.*/\n        *pxCreatedTask = ( TaskHandle_t ) pxNewTCB;\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n}\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES == 1 )\n\n    static void prvAddNewTaskToReadyList( TCB_t * pxNewTCB )\n    {\n        /* Ensure interrupts don't access the task lists while the lists are being\n         * updated. */\n        taskENTER_CRITICAL();\n        {\n            uxCurrentNumberOfTasks = ( UBaseType_t ) ( uxCurrentNumberOfTasks + 1U );\n\n            if( pxCurrentTCB == NULL )\n            {\n                /* There are no other tasks, or all the other tasks are in\n                 * the suspended state - make this the current task. */\n                pxCurrentTCB = pxNewTCB;\n\n                if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )\n                {\n                    /* This is the first task to be created so do the preliminary\n                     * initialisation required.  We will not recover if this call\n                     * fails, but we will report the failure. */\n                    prvInitialiseTaskLists();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* If the scheduler is not already running, make this task the\n                 * current task if it is the highest priority task to be created\n                 * so far. */\n                if( xSchedulerRunning == pdFALSE )\n                {\n                    if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )\n                    {\n                        pxCurrentTCB = pxNewTCB;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n\n            uxTaskNumber++;\n\n            #if ( configUSE_TRACE_FACILITY == 1 )\n            {\n                /* Add a counter into the TCB for tracing only. */\n                pxNewTCB->uxTCBNumber = uxTaskNumber;\n            }\n            #endif /* configUSE_TRACE_FACILITY */\n            traceTASK_CREATE( pxNewTCB );\n\n            prvAddTaskToReadyList( pxNewTCB );\n\n            portSETUP_TCB( pxNewTCB );\n        }\n        taskEXIT_CRITICAL();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            /* If the created task is of a higher priority than the current task\n             * then it should run now. */\n            taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxNewTCB );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n\n#else /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    static void prvAddNewTaskToReadyList( TCB_t * pxNewTCB )\n    {\n        /* Ensure interrupts don't access the task lists while the lists are being\n         * updated. */\n        taskENTER_CRITICAL();\n        {\n            uxCurrentNumberOfTasks++;\n\n            if( xSchedulerRunning == pdFALSE )\n            {\n                if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )\n                {\n                    /* This is the first task to be created so do the preliminary\n                     * initialisation required.  We will not recover if this call\n                     * fails, but we will report the failure. */\n                    prvInitialiseTaskLists();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                /* All the cores start with idle tasks before the SMP scheduler\n                 * is running. Idle tasks are assigned to cores when they are\n                 * created in prvCreateIdleTasks(). */\n            }\n\n            uxTaskNumber++;\n\n            #if ( configUSE_TRACE_FACILITY == 1 )\n            {\n                /* Add a counter into the TCB for tracing only. */\n                pxNewTCB->uxTCBNumber = uxTaskNumber;\n            }\n            #endif /* configUSE_TRACE_FACILITY */\n            traceTASK_CREATE( pxNewTCB );\n\n            prvAddTaskToReadyList( pxNewTCB );\n\n            portSETUP_TCB( pxNewTCB );\n\n            if( xSchedulerRunning != pdFALSE )\n            {\n                /* If the created task is of a higher priority than another\n                 * currently running task and preemption is on then it should\n                 * run now. */\n                taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxNewTCB );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL();\n    }\n\n#endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) )\n\n    static size_t prvSnprintfReturnValueToCharsWritten( int iSnprintfReturnValue,\n                                                        size_t n )\n    {\n        size_t uxCharsWritten;\n\n        if( iSnprintfReturnValue < 0 )\n        {\n            /* Encoding error - Return 0 to indicate that nothing\n             * was written to the buffer. */\n            uxCharsWritten = 0;\n        }\n        else if( iSnprintfReturnValue >= ( int ) n )\n        {\n            /* This is the case when the supplied buffer is not\n             * large to hold the generated string. Return the\n             * number of characters actually written without\n             * counting the terminating NULL character. */\n            uxCharsWritten = n - 1U;\n        }\n        else\n        {\n            /* Complete string was written to the buffer. */\n            uxCharsWritten = ( size_t ) iSnprintfReturnValue;\n        }\n\n        return uxCharsWritten;\n    }\n\n#endif /* #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskDelete == 1 )\n\n    void vTaskDelete( TaskHandle_t xTaskToDelete )\n    {\n        TCB_t * pxTCB;\n        BaseType_t xDeleteTCBInIdleTask = pdFALSE;\n        BaseType_t xTaskIsRunningOrYielding;\n\n        traceENTER_vTaskDelete( xTaskToDelete );\n\n        taskENTER_CRITICAL();\n        {\n            /* If null is passed in here then it is the calling task that is\n             * being deleted. */\n            pxTCB = prvGetTCBFromHandle( xTaskToDelete );\n            configASSERT( pxTCB != NULL );\n\n            /* Remove task from the ready/delayed list. */\n            if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n            {\n                taskRESET_READY_PRIORITY( pxTCB->uxPriority );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* Is the task waiting on an event also? */\n            if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )\n            {\n                ( void ) uxListRemove( &( pxTCB->xEventListItem ) );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* Increment the uxTaskNumber also so kernel aware debuggers can\n             * detect that the task lists need re-generating.  This is done before\n             * portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will\n             * not return. */\n            uxTaskNumber++;\n\n            /* Use temp variable as distinct sequence points for reading volatile\n             * variables prior to a logical operator to ensure compliance with\n             * MISRA C 2012 Rule 13.5. */\n            xTaskIsRunningOrYielding = taskTASK_IS_RUNNING_OR_SCHEDULED_TO_YIELD( pxTCB );\n\n            /* If the task is running (or yielding), we must add it to the\n             * termination list so that an idle task can delete it when it is\n             * no longer running. */\n            if( ( xSchedulerRunning != pdFALSE ) && ( xTaskIsRunningOrYielding != pdFALSE ) )\n            {\n                /* A running task or a task which is scheduled to yield is being\n                 * deleted. This cannot complete when the task is still running\n                 * on a core, as a context switch to another task is required.\n                 * Place the task in the termination list. The idle task will check\n                 * the termination list and free up any memory allocated by the\n                 * scheduler for the TCB and stack of the deleted task. */\n                vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );\n\n                /* Increment the ucTasksDeleted variable so the idle task knows\n                 * there is a task that has been deleted and that it should therefore\n                 * check the xTasksWaitingTermination list. */\n                ++uxDeletedTasksWaitingCleanUp;\n\n                /* Call the delete hook before portPRE_TASK_DELETE_HOOK() as\n                 * portPRE_TASK_DELETE_HOOK() does not return in the Win32 port. */\n                traceTASK_DELETE( pxTCB );\n\n                /* Delete the task TCB in idle task. */\n                xDeleteTCBInIdleTask = pdTRUE;\n\n                /* The pre-delete hook is primarily for the Windows simulator,\n                 * in which Windows specific clean up operations are performed,\n                 * after which it is not possible to yield away from this task -\n                 * hence xYieldPending is used to latch that a context switch is\n                 * required. */\n                #if ( configNUMBER_OF_CORES == 1 )\n                    portPRE_TASK_DELETE_HOOK( pxTCB, &( xYieldPendings[ 0 ] ) );\n                #else\n                    portPRE_TASK_DELETE_HOOK( pxTCB, &( xYieldPendings[ pxTCB->xTaskRunState ] ) );\n                #endif\n\n                /* In the case of SMP, it is possible that the task being deleted\n                 * is running on another core. We must evict the task before\n                 * exiting the critical section to ensure that the task cannot\n                 * take an action which puts it back on ready/state/event list,\n                 * thereby nullifying the delete operation. Once evicted, the\n                 * task won't be scheduled ever as it will no longer be on the\n                 * ready list. */\n                #if ( configNUMBER_OF_CORES > 1 )\n                {\n                    if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                    {\n                        if( pxTCB->xTaskRunState == ( BaseType_t ) portGET_CORE_ID() )\n                        {\n                            configASSERT( uxSchedulerSuspended == 0 );\n                            taskYIELD_WITHIN_API();\n                        }\n                        else\n                        {\n                            prvYieldCore( pxTCB->xTaskRunState );\n                        }\n                    }\n                }\n                #endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n            }\n            else\n            {\n                --uxCurrentNumberOfTasks;\n                traceTASK_DELETE( pxTCB );\n\n                /* Reset the next expected unblock time in case it referred to\n                 * the task that has just been deleted. */\n                prvResetNextTaskUnblockTime();\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        /* If the task is not deleting itself, call prvDeleteTCB from outside of\n         * critical section. If a task deletes itself, prvDeleteTCB is called\n         * from prvCheckTasksWaitingTermination which is called from Idle task. */\n        if( xDeleteTCBInIdleTask != pdTRUE )\n        {\n            prvDeleteTCB( pxTCB );\n        }\n\n        /* Force a reschedule if it is the currently running task that has just\n         * been deleted. */\n        #if ( configNUMBER_OF_CORES == 1 )\n        {\n            if( xSchedulerRunning != pdFALSE )\n            {\n                if( pxTCB == pxCurrentTCB )\n                {\n                    configASSERT( uxSchedulerSuspended == 0 );\n                    taskYIELD_WITHIN_API();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n        traceRETURN_vTaskDelete();\n    }\n\n#endif /* INCLUDE_vTaskDelete */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_xTaskDelayUntil == 1 )\n\n    BaseType_t xTaskDelayUntil( TickType_t * const pxPreviousWakeTime,\n                                const TickType_t xTimeIncrement )\n    {\n        TickType_t xTimeToWake;\n        BaseType_t xAlreadyYielded, xShouldDelay = pdFALSE;\n\n        traceENTER_xTaskDelayUntil( pxPreviousWakeTime, xTimeIncrement );\n\n        configASSERT( pxPreviousWakeTime );\n        configASSERT( ( xTimeIncrement > 0U ) );\n\n        vTaskSuspendAll();\n        {\n            /* Minor optimisation.  The tick count cannot change in this\n             * block. */\n            const TickType_t xConstTickCount = xTickCount;\n\n            configASSERT( uxSchedulerSuspended == 1U );\n\n            /* Generate the tick time at which the task wants to wake. */\n            xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;\n\n            if( xConstTickCount < *pxPreviousWakeTime )\n            {\n                /* The tick count has overflowed since this function was\n                 * lasted called.  In this case the only time we should ever\n                 * actually delay is if the wake time has also  overflowed,\n                 * and the wake time is greater than the tick time.  When this\n                 * is the case it is as if neither time had overflowed. */\n                if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )\n                {\n                    xShouldDelay = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                /* The tick time has not overflowed.  In this case we will\n                 * delay if either the wake time has overflowed, and/or the\n                 * tick time is less than the wake time. */\n                if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )\n                {\n                    xShouldDelay = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n\n            /* Update the wake time ready for the next call. */\n            *pxPreviousWakeTime = xTimeToWake;\n\n            if( xShouldDelay != pdFALSE )\n            {\n                traceTASK_DELAY_UNTIL( xTimeToWake );\n\n                /* prvAddCurrentTaskToDelayedList() needs the block time, not\n                 * the time to wake, so subtract the current tick count. */\n                prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        xAlreadyYielded = xTaskResumeAll();\n\n        /* Force a reschedule if xTaskResumeAll has not already done so, we may\n         * have put ourselves to sleep. */\n        if( xAlreadyYielded == pdFALSE )\n        {\n            taskYIELD_WITHIN_API();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTaskDelayUntil( xShouldDelay );\n\n        return xShouldDelay;\n    }\n\n#endif /* INCLUDE_xTaskDelayUntil */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskDelay == 1 )\n\n    void vTaskDelay( const TickType_t xTicksToDelay )\n    {\n        BaseType_t xAlreadyYielded = pdFALSE;\n\n        traceENTER_vTaskDelay( xTicksToDelay );\n\n        /* A delay time of zero just forces a reschedule. */\n        if( xTicksToDelay > ( TickType_t ) 0U )\n        {\n            vTaskSuspendAll();\n            {\n                configASSERT( uxSchedulerSuspended == 1U );\n\n                traceTASK_DELAY();\n\n                /* A task that is removed from the event list while the\n                 * scheduler is suspended will not get placed in the ready\n                 * list or removed from the blocked list until the scheduler\n                 * is resumed.\n                 *\n                 * This task cannot be in an event list as it is the currently\n                 * executing task. */\n                prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );\n            }\n            xAlreadyYielded = xTaskResumeAll();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        /* Force a reschedule if xTaskResumeAll has not already done so, we may\n         * have put ourselves to sleep. */\n        if( xAlreadyYielded == pdFALSE )\n        {\n            taskYIELD_WITHIN_API();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskDelay();\n    }\n\n#endif /* INCLUDE_vTaskDelay */\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_eTaskGetState == 1 ) || ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_xTaskAbortDelay == 1 ) )\n\n    eTaskState eTaskGetState( TaskHandle_t xTask )\n    {\n        eTaskState eReturn;\n        List_t const * pxStateList;\n        List_t const * pxEventList;\n        List_t const * pxDelayedList;\n        List_t const * pxOverflowedDelayedList;\n        const TCB_t * const pxTCB = xTask;\n\n        traceENTER_eTaskGetState( xTask );\n\n        configASSERT( pxTCB != NULL );\n\n        #if ( configNUMBER_OF_CORES == 1 )\n            if( pxTCB == pxCurrentTCB )\n            {\n                /* The task calling this function is querying its own state. */\n                eReturn = eRunning;\n            }\n            else\n        #endif\n        {\n            taskENTER_CRITICAL();\n            {\n                pxStateList = listLIST_ITEM_CONTAINER( &( pxTCB->xStateListItem ) );\n                pxEventList = listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) );\n                pxDelayedList = pxDelayedTaskList;\n                pxOverflowedDelayedList = pxOverflowDelayedTaskList;\n            }\n            taskEXIT_CRITICAL();\n\n            if( pxEventList == &xPendingReadyList )\n            {\n                /* The task has been placed on the pending ready list, so its\n                 * state is eReady regardless of what list the task's state list\n                 * item is currently placed on. */\n                eReturn = eReady;\n            }\n            else if( ( pxStateList == pxDelayedList ) || ( pxStateList == pxOverflowedDelayedList ) )\n            {\n                /* The task being queried is referenced from one of the Blocked\n                 * lists. */\n                eReturn = eBlocked;\n            }\n\n            #if ( INCLUDE_vTaskSuspend == 1 )\n                else if( pxStateList == &xSuspendedTaskList )\n                {\n                    /* The task being queried is referenced from the suspended\n                     * list.  Is it genuinely suspended or is it blocked\n                     * indefinitely? */\n                    if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL )\n                    {\n                        #if ( configUSE_TASK_NOTIFICATIONS == 1 )\n                        {\n                            BaseType_t x;\n\n                            /* The task does not appear on the event list item of\n                             * and of the RTOS objects, but could still be in the\n                             * blocked state if it is waiting on its notification\n                             * rather than waiting on an object.  If not, is\n                             * suspended. */\n                            eReturn = eSuspended;\n\n                            for( x = ( BaseType_t ) 0; x < ( BaseType_t ) configTASK_NOTIFICATION_ARRAY_ENTRIES; x++ )\n                            {\n                                if( pxTCB->ucNotifyState[ x ] == taskWAITING_NOTIFICATION )\n                                {\n                                    eReturn = eBlocked;\n                                    break;\n                                }\n                            }\n                        }\n                        #else /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n                        {\n                            eReturn = eSuspended;\n                        }\n                        #endif /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n                    }\n                    else\n                    {\n                        eReturn = eBlocked;\n                    }\n                }\n            #endif /* if ( INCLUDE_vTaskSuspend == 1 ) */\n\n            #if ( INCLUDE_vTaskDelete == 1 )\n                else if( ( pxStateList == &xTasksWaitingTermination ) || ( pxStateList == NULL ) )\n                {\n                    /* The task being queried is referenced from the deleted\n                     * tasks list, or it is not referenced from any lists at\n                     * all. */\n                    eReturn = eDeleted;\n                }\n            #endif\n\n            else\n            {\n                #if ( configNUMBER_OF_CORES == 1 )\n                {\n                    /* If the task is not in any other state, it must be in the\n                     * Ready (including pending ready) state. */\n                    eReturn = eReady;\n                }\n                #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                {\n                    if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                    {\n                        /* Is it actively running on a core? */\n                        eReturn = eRunning;\n                    }\n                    else\n                    {\n                        /* If the task is not in any other state, it must be in the\n                         * Ready (including pending ready) state. */\n                        eReturn = eReady;\n                    }\n                }\n                #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n            }\n        }\n\n        traceRETURN_eTaskGetState( eReturn );\n\n        return eReturn;\n    }\n\n#endif /* INCLUDE_eTaskGetState */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_uxTaskPriorityGet == 1 )\n\n    UBaseType_t uxTaskPriorityGet( const TaskHandle_t xTask )\n    {\n        TCB_t const * pxTCB;\n        UBaseType_t uxReturn;\n\n        traceENTER_uxTaskPriorityGet( xTask );\n\n        portBASE_TYPE_ENTER_CRITICAL();\n        {\n            /* If null is passed in here then it is the priority of the task\n             * that called uxTaskPriorityGet() that is being queried. */\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            uxReturn = pxTCB->uxPriority;\n        }\n        portBASE_TYPE_EXIT_CRITICAL();\n\n        traceRETURN_uxTaskPriorityGet( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* INCLUDE_uxTaskPriorityGet */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_uxTaskPriorityGet == 1 )\n\n    UBaseType_t uxTaskPriorityGetFromISR( const TaskHandle_t xTask )\n    {\n        TCB_t const * pxTCB;\n        UBaseType_t uxReturn;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_uxTaskPriorityGetFromISR( xTask );\n\n        /* RTOS ports that support interrupt nesting have the concept of a\n         * maximum  system call (or maximum API call) interrupt priority.\n         * Interrupts that are  above the maximum system call priority are keep\n         * permanently enabled, even when the RTOS kernel is in a critical section,\n         * but cannot make any calls to FreeRTOS API functions.  If configASSERT()\n         * is defined in FreeRTOSConfig.h then\n         * portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n         * failure if a FreeRTOS API function is called from an interrupt that has\n         * been assigned a priority above the configured maximum system call\n         * priority.  Only FreeRTOS functions that end in FromISR can be called\n         * from interrupts  that have been assigned a priority at or (logically)\n         * below the maximum system call interrupt priority.  FreeRTOS maintains a\n         * separate interrupt safe API to ensure interrupt entry is as fast and as\n         * simple as possible.  More information (albeit Cortex-M specific) is\n         * provided on the following link:\n         * https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n        portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n        {\n            /* If null is passed in here then it is the priority of the calling\n             * task that is being queried. */\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            uxReturn = pxTCB->uxPriority;\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_uxTaskPriorityGetFromISR( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* INCLUDE_uxTaskPriorityGet */\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_uxTaskPriorityGet == 1 ) && ( configUSE_MUTEXES == 1 ) )\n\n    UBaseType_t uxTaskBasePriorityGet( const TaskHandle_t xTask )\n    {\n        TCB_t const * pxTCB;\n        UBaseType_t uxReturn;\n\n        traceENTER_uxTaskBasePriorityGet( xTask );\n\n        portBASE_TYPE_ENTER_CRITICAL();\n        {\n            /* If null is passed in here then it is the base priority of the task\n             * that called uxTaskBasePriorityGet() that is being queried. */\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            uxReturn = pxTCB->uxBasePriority;\n        }\n        portBASE_TYPE_EXIT_CRITICAL();\n\n        traceRETURN_uxTaskBasePriorityGet( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* #if ( ( INCLUDE_uxTaskPriorityGet == 1 ) && ( configUSE_MUTEXES == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_uxTaskPriorityGet == 1 ) && ( configUSE_MUTEXES == 1 ) )\n\n    UBaseType_t uxTaskBasePriorityGetFromISR( const TaskHandle_t xTask )\n    {\n        TCB_t const * pxTCB;\n        UBaseType_t uxReturn;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_uxTaskBasePriorityGetFromISR( xTask );\n\n        /* RTOS ports that support interrupt nesting have the concept of a\n         * maximum  system call (or maximum API call) interrupt priority.\n         * Interrupts that are  above the maximum system call priority are keep\n         * permanently enabled, even when the RTOS kernel is in a critical section,\n         * but cannot make any calls to FreeRTOS API functions.  If configASSERT()\n         * is defined in FreeRTOSConfig.h then\n         * portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n         * failure if a FreeRTOS API function is called from an interrupt that has\n         * been assigned a priority above the configured maximum system call\n         * priority.  Only FreeRTOS functions that end in FromISR can be called\n         * from interrupts  that have been assigned a priority at or (logically)\n         * below the maximum system call interrupt priority.  FreeRTOS maintains a\n         * separate interrupt safe API to ensure interrupt entry is as fast and as\n         * simple as possible.  More information (albeit Cortex-M specific) is\n         * provided on the following link:\n         * https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n        portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n        {\n            /* If null is passed in here then it is the base priority of the calling\n             * task that is being queried. */\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            uxReturn = pxTCB->uxBasePriority;\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_uxTaskBasePriorityGetFromISR( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* #if ( ( INCLUDE_uxTaskPriorityGet == 1 ) && ( configUSE_MUTEXES == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskPrioritySet == 1 )\n\n    void vTaskPrioritySet( TaskHandle_t xTask,\n                           UBaseType_t uxNewPriority )\n    {\n        TCB_t * pxTCB;\n        UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;\n        BaseType_t xYieldRequired = pdFALSE;\n\n        #if ( configNUMBER_OF_CORES > 1 )\n            BaseType_t xYieldForTask = pdFALSE;\n        #endif\n\n        traceENTER_vTaskPrioritySet( xTask, uxNewPriority );\n\n        configASSERT( uxNewPriority < configMAX_PRIORITIES );\n\n        /* Ensure the new priority is valid. */\n        if( uxNewPriority >= ( UBaseType_t ) configMAX_PRIORITIES )\n        {\n            uxNewPriority = ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) 1U;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        taskENTER_CRITICAL();\n        {\n            /* If null is passed in here then it is the priority of the calling\n             * task that is being changed. */\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            traceTASK_PRIORITY_SET( pxTCB, uxNewPriority );\n\n            #if ( configUSE_MUTEXES == 1 )\n            {\n                uxCurrentBasePriority = pxTCB->uxBasePriority;\n            }\n            #else\n            {\n                uxCurrentBasePriority = pxTCB->uxPriority;\n            }\n            #endif\n\n            if( uxCurrentBasePriority != uxNewPriority )\n            {\n                /* The priority change may have readied a task of higher\n                 * priority than a running task. */\n                if( uxNewPriority > uxCurrentBasePriority )\n                {\n                    #if ( configNUMBER_OF_CORES == 1 )\n                    {\n                        if( pxTCB != pxCurrentTCB )\n                        {\n                            /* The priority of a task other than the currently\n                             * running task is being raised.  Is the priority being\n                             * raised above that of the running task? */\n                            if( uxNewPriority > pxCurrentTCB->uxPriority )\n                            {\n                                xYieldRequired = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        else\n                        {\n                            /* The priority of the running task is being raised,\n                             * but the running task must already be the highest\n                             * priority task able to run so no yield is required. */\n                        }\n                    }\n                    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                    {\n                        /* The priority of a task is being raised so\n                         * perform a yield for this task later. */\n                        xYieldForTask = pdTRUE;\n                    }\n                    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n                }\n                else if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                {\n                    /* Setting the priority of a running task down means\n                     * there may now be another task of higher priority that\n                     * is ready to execute. */\n                    #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n                        if( pxTCB->xPreemptionDisable == pdFALSE )\n                    #endif\n                    {\n                        xYieldRequired = pdTRUE;\n                    }\n                }\n                else\n                {\n                    /* Setting the priority of any other task down does not\n                     * require a yield as the running task must be above the\n                     * new priority of the task being modified. */\n                }\n\n                /* Remember the ready list the task might be referenced from\n                 * before its uxPriority member is changed so the\n                 * taskRESET_READY_PRIORITY() macro can function correctly. */\n                uxPriorityUsedOnEntry = pxTCB->uxPriority;\n\n                #if ( configUSE_MUTEXES == 1 )\n                {\n                    /* Only change the priority being used if the task is not\n                     * currently using an inherited priority or the new priority\n                     * is bigger than the inherited priority. */\n                    if( ( pxTCB->uxBasePriority == pxTCB->uxPriority ) || ( uxNewPriority > pxTCB->uxPriority ) )\n                    {\n                        pxTCB->uxPriority = uxNewPriority;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* The base priority gets set whatever. */\n                    pxTCB->uxBasePriority = uxNewPriority;\n                }\n                #else /* if ( configUSE_MUTEXES == 1 ) */\n                {\n                    pxTCB->uxPriority = uxNewPriority;\n                }\n                #endif /* if ( configUSE_MUTEXES == 1 ) */\n\n                /* Only reset the event list item value if the value is not\n                 * being used for anything else. */\n                if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == ( ( TickType_t ) 0U ) )\n                {\n                    listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxNewPriority ) );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                /* If the task is in the blocked or suspended list we need do\n                 * nothing more than change its priority variable. However, if\n                 * the task is in a ready list it needs to be removed and placed\n                 * in the list appropriate to its new priority. */\n                if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )\n                {\n                    /* The task is currently in its ready list - remove before\n                     * adding it to its new ready list.  As we are in a critical\n                     * section we can do this even if the scheduler is suspended. */\n                    if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n                    {\n                        /* It is known that the task is in its ready list so\n                         * there is no need to check again and the port level\n                         * reset macro can be called directly. */\n                        portRESET_READY_PRIORITY( uxPriorityUsedOnEntry, uxTopReadyPriority );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    prvAddTaskToReadyList( pxTCB );\n                }\n                else\n                {\n                    #if ( configNUMBER_OF_CORES == 1 )\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                    #else\n                    {\n                        /* It's possible that xYieldForTask was already set to pdTRUE because\n                         * its priority is being raised. However, since it is not in a ready list\n                         * we don't actually need to yield for it. */\n                        xYieldForTask = pdFALSE;\n                    }\n                    #endif\n                }\n\n                if( xYieldRequired != pdFALSE )\n                {\n                    /* The running task priority is set down. Request the task to yield. */\n                    taskYIELD_TASK_CORE_IF_USING_PREEMPTION( pxTCB );\n                }\n                else\n                {\n                    #if ( configNUMBER_OF_CORES > 1 )\n                        if( xYieldForTask != pdFALSE )\n                        {\n                            /* The priority of the task is being raised. If a running\n                             * task has priority lower than this task, it should yield\n                             * for this task. */\n                            taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB );\n                        }\n                        else\n                    #endif /* if ( configNUMBER_OF_CORES > 1 ) */\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n\n                /* Remove compiler warning about unused variables when the port\n                 * optimised task selection is not being used. */\n                ( void ) uxPriorityUsedOnEntry;\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTaskPrioritySet();\n    }\n\n#endif /* INCLUDE_vTaskPrioritySet */\n/*-----------------------------------------------------------*/\n\n#if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n    void vTaskCoreAffinitySet( const TaskHandle_t xTask,\n                               UBaseType_t uxCoreAffinityMask )\n    {\n        TCB_t * pxTCB;\n        BaseType_t xCoreID;\n\n        traceENTER_vTaskCoreAffinitySet( xTask, uxCoreAffinityMask );\n\n        taskENTER_CRITICAL();\n        {\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            pxTCB->uxCoreAffinityMask = uxCoreAffinityMask;\n\n            if( xSchedulerRunning != pdFALSE )\n            {\n                if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                {\n                    xCoreID = ( BaseType_t ) pxTCB->xTaskRunState;\n\n                    /* If the task can no longer run on the core it was running,\n                     * request the core to yield. */\n                    if( ( uxCoreAffinityMask & ( ( UBaseType_t ) 1U << ( UBaseType_t ) xCoreID ) ) == 0U )\n                    {\n                        prvYieldCore( xCoreID );\n                    }\n                }\n                else\n                {\n                    #if ( configUSE_PREEMPTION == 1 )\n                    {\n                        /* The SMP scheduler requests a core to yield when a ready\n                         * task is able to run. It is possible that the core affinity\n                         * of the ready task is changed before the requested core\n                         * can select it to run. In that case, the task may not be\n                         * selected by the previously requested core due to core affinity\n                         * constraint and the SMP scheduler must select a new core to\n                         * yield for the task. */\n                        prvYieldForTask( xTask );\n                    }\n                    #else /* #if( configUSE_PREEMPTION == 1 ) */\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                    #endif /* #if( configUSE_PREEMPTION == 1 ) */\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTaskCoreAffinitySet();\n    }\n#endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n    UBaseType_t vTaskCoreAffinityGet( ConstTaskHandle_t xTask )\n    {\n        const TCB_t * pxTCB;\n        UBaseType_t uxCoreAffinityMask;\n\n        traceENTER_vTaskCoreAffinityGet( xTask );\n\n        portBASE_TYPE_ENTER_CRITICAL();\n        {\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            uxCoreAffinityMask = pxTCB->uxCoreAffinityMask;\n        }\n        portBASE_TYPE_EXIT_CRITICAL();\n\n        traceRETURN_vTaskCoreAffinityGet( uxCoreAffinityMask );\n\n        return uxCoreAffinityMask;\n    }\n#endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n\n    void vTaskPreemptionDisable( const TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskPreemptionDisable( xTask );\n\n        taskENTER_CRITICAL();\n        {\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            pxTCB->xPreemptionDisable = pdTRUE;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTaskPreemptionDisable();\n    }\n\n#endif /* #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n\n    void vTaskPreemptionEnable( const TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        BaseType_t xCoreID;\n\n        traceENTER_vTaskPreemptionEnable( xTask );\n\n        taskENTER_CRITICAL();\n        {\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            pxTCB->xPreemptionDisable = pdFALSE;\n\n            if( xSchedulerRunning != pdFALSE )\n            {\n                if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                {\n                    xCoreID = ( BaseType_t ) pxTCB->xTaskRunState;\n                    prvYieldCore( xCoreID );\n                }\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTaskPreemptionEnable();\n    }\n\n#endif /* #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskSuspend == 1 )\n\n    void vTaskSuspend( TaskHandle_t xTaskToSuspend )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskSuspend( xTaskToSuspend );\n\n        taskENTER_CRITICAL();\n        {\n            /* If null is passed in here then it is the running task that is\n             * being suspended. */\n            pxTCB = prvGetTCBFromHandle( xTaskToSuspend );\n            configASSERT( pxTCB != NULL );\n\n            traceTASK_SUSPEND( pxTCB );\n\n            /* Remove task from the ready/delayed list and place in the\n             * suspended list. */\n            if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n            {\n                taskRESET_READY_PRIORITY( pxTCB->uxPriority );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* Is the task waiting on an event also? */\n            if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )\n            {\n                ( void ) uxListRemove( &( pxTCB->xEventListItem ) );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );\n\n            #if ( configUSE_TASK_NOTIFICATIONS == 1 )\n            {\n                BaseType_t x;\n\n                for( x = ( BaseType_t ) 0; x < ( BaseType_t ) configTASK_NOTIFICATION_ARRAY_ENTRIES; x++ )\n                {\n                    if( pxTCB->ucNotifyState[ x ] == taskWAITING_NOTIFICATION )\n                    {\n                        /* The task was blocked to wait for a notification, but is\n                         * now suspended, so no notification was received. */\n                        pxTCB->ucNotifyState[ x ] = taskNOT_WAITING_NOTIFICATION;\n                    }\n                }\n            }\n            #endif /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n\n            /* In the case of SMP, it is possible that the task being suspended\n             * is running on another core. We must evict the task before\n             * exiting the critical section to ensure that the task cannot\n             * take an action which puts it back on ready/state/event list,\n             * thereby nullifying the suspend operation. Once evicted, the\n             * task won't be scheduled before it is resumed as it will no longer\n             * be on the ready list. */\n            #if ( configNUMBER_OF_CORES > 1 )\n            {\n                if( xSchedulerRunning != pdFALSE )\n                {\n                    /* Reset the next expected unblock time in case it referred to the\n                     * task that is now in the Suspended state. */\n                    prvResetNextTaskUnblockTime();\n\n                    if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                    {\n                        if( pxTCB->xTaskRunState == ( BaseType_t ) portGET_CORE_ID() )\n                        {\n                            /* The current task has just been suspended. */\n                            configASSERT( uxSchedulerSuspended == 0 );\n                            vTaskYieldWithinAPI();\n                        }\n                        else\n                        {\n                            prvYieldCore( pxTCB->xTaskRunState );\n                        }\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            #endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n        }\n        taskEXIT_CRITICAL();\n\n        #if ( configNUMBER_OF_CORES == 1 )\n        {\n            UBaseType_t uxCurrentListLength;\n\n            if( xSchedulerRunning != pdFALSE )\n            {\n                /* Reset the next expected unblock time in case it referred to the\n                 * task that is now in the Suspended state. */\n                taskENTER_CRITICAL();\n                {\n                    prvResetNextTaskUnblockTime();\n                }\n                taskEXIT_CRITICAL();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            if( pxTCB == pxCurrentTCB )\n            {\n                if( xSchedulerRunning != pdFALSE )\n                {\n                    /* The current task has just been suspended. */\n                    configASSERT( uxSchedulerSuspended == 0 );\n                    portYIELD_WITHIN_API();\n                }\n                else\n                {\n                    /* The scheduler is not running, but the task that was pointed\n                     * to by pxCurrentTCB has just been suspended and pxCurrentTCB\n                     * must be adjusted to point to a different task. */\n\n                    /* Use a temp variable as a distinct sequence point for reading\n                     * volatile variables prior to a comparison to ensure compliance\n                     * with MISRA C 2012 Rule 13.2. */\n                    uxCurrentListLength = listCURRENT_LIST_LENGTH( &xSuspendedTaskList );\n\n                    if( uxCurrentListLength == uxCurrentNumberOfTasks )\n                    {\n                        /* No other tasks are ready, so set pxCurrentTCB back to\n                         * NULL so when the next task is created pxCurrentTCB will\n                         * be set to point to it no matter what its relative priority\n                         * is. */\n                        pxCurrentTCB = NULL;\n                    }\n                    else\n                    {\n                        vTaskSwitchContext();\n                    }\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n        traceRETURN_vTaskSuspend();\n    }\n\n#endif /* INCLUDE_vTaskSuspend */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskSuspend == 1 )\n\n    static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )\n    {\n        BaseType_t xReturn = pdFALSE;\n        const TCB_t * const pxTCB = xTask;\n\n        /* Accesses xPendingReadyList so must be called from a critical\n         * section. */\n\n        /* It does not make sense to check if the calling task is suspended. */\n        configASSERT( xTask );\n\n        /* Is the task being resumed actually in the suspended list? */\n        if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )\n        {\n            /* Has the task already been resumed from within an ISR? */\n            if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )\n            {\n                /* Is it in the suspended list because it is in the Suspended\n                 * state, or because it is blocked with no timeout? */\n                if( listIS_CONTAINED_WITHIN( NULL, &( pxTCB->xEventListItem ) ) != pdFALSE )\n                {\n                    #if ( configUSE_TASK_NOTIFICATIONS == 1 )\n                    {\n                        BaseType_t x;\n\n                        /* The task does not appear on the event list item of\n                         * and of the RTOS objects, but could still be in the\n                         * blocked state if it is waiting on its notification\n                         * rather than waiting on an object.  If not, is\n                         * suspended. */\n                        xReturn = pdTRUE;\n\n                        for( x = ( BaseType_t ) 0; x < ( BaseType_t ) configTASK_NOTIFICATION_ARRAY_ENTRIES; x++ )\n                        {\n                            if( pxTCB->ucNotifyState[ x ] == taskWAITING_NOTIFICATION )\n                            {\n                                xReturn = pdFALSE;\n                                break;\n                            }\n                        }\n                    }\n                    #else /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n                    {\n                        xReturn = pdTRUE;\n                    }\n                    #endif /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        return xReturn;\n    }\n\n#endif /* INCLUDE_vTaskSuspend */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskSuspend == 1 )\n\n    void vTaskResume( TaskHandle_t xTaskToResume )\n    {\n        TCB_t * const pxTCB = xTaskToResume;\n\n        traceENTER_vTaskResume( xTaskToResume );\n\n        /* It does not make sense to resume the calling task. */\n        configASSERT( xTaskToResume );\n\n        #if ( configNUMBER_OF_CORES == 1 )\n\n            /* The parameter cannot be NULL as it is impossible to resume the\n             * currently executing task. */\n            if( ( pxTCB != pxCurrentTCB ) && ( pxTCB != NULL ) )\n        #else\n\n            /* The parameter cannot be NULL as it is impossible to resume the\n             * currently executing task. It is also impossible to resume a task\n             * that is actively running on another core but it is not safe\n             * to check their run state here. Therefore, we get into a critical\n             * section and check if the task is actually suspended or not. */\n            if( pxTCB != NULL )\n        #endif\n        {\n            taskENTER_CRITICAL();\n            {\n                if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )\n                {\n                    traceTASK_RESUME( pxTCB );\n\n                    /* The ready list can be accessed even if the scheduler is\n                     * suspended because this is inside a critical section. */\n                    ( void ) uxListRemove( &( pxTCB->xStateListItem ) );\n                    prvAddTaskToReadyList( pxTCB );\n\n                    /* This yield may not cause the task just resumed to run,\n                     * but will leave the lists in the correct state for the\n                     * next yield. */\n                    taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            taskEXIT_CRITICAL();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskResume();\n    }\n\n#endif /* INCLUDE_vTaskSuspend */\n\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )\n\n    BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )\n    {\n        BaseType_t xYieldRequired = pdFALSE;\n        TCB_t * const pxTCB = xTaskToResume;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_xTaskResumeFromISR( xTaskToResume );\n\n        configASSERT( xTaskToResume );\n\n        /* RTOS ports that support interrupt nesting have the concept of a\n         * maximum  system call (or maximum API call) interrupt priority.\n         * Interrupts that are  above the maximum system call priority are keep\n         * permanently enabled, even when the RTOS kernel is in a critical section,\n         * but cannot make any calls to FreeRTOS API functions.  If configASSERT()\n         * is defined in FreeRTOSConfig.h then\n         * portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n         * failure if a FreeRTOS API function is called from an interrupt that has\n         * been assigned a priority above the configured maximum system call\n         * priority.  Only FreeRTOS functions that end in FromISR can be called\n         * from interrupts  that have been assigned a priority at or (logically)\n         * below the maximum system call interrupt priority.  FreeRTOS maintains a\n         * separate interrupt safe API to ensure interrupt entry is as fast and as\n         * simple as possible.  More information (albeit Cortex-M specific) is\n         * provided on the following link:\n         * https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n        portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n        {\n            if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )\n            {\n                traceTASK_RESUME_FROM_ISR( pxTCB );\n\n                /* Check the ready lists can be accessed. */\n                if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n                {\n                    #if ( configNUMBER_OF_CORES == 1 )\n                    {\n                        /* Ready lists can be accessed so move the task from the\n                         * suspended list to the ready list directly. */\n                        if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                        {\n                            xYieldRequired = pdTRUE;\n\n                            /* Mark that a yield is pending in case the user is not\n                             * using the return value to initiate a context switch\n                             * from the ISR using the port specific portYIELD_FROM_ISR(). */\n                            xYieldPendings[ 0 ] = pdTRUE;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n                    ( void ) uxListRemove( &( pxTCB->xStateListItem ) );\n                    prvAddTaskToReadyList( pxTCB );\n                }\n                else\n                {\n                    /* The delayed or ready lists cannot be accessed so the task\n                     * is held in the pending ready list until the scheduler is\n                     * unsuspended. */\n                    vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );\n                }\n\n                #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_PREEMPTION == 1 ) )\n                {\n                    prvYieldForTask( pxTCB );\n\n                    if( xYieldPendings[ portGET_CORE_ID() ] != pdFALSE )\n                    {\n                        xYieldRequired = pdTRUE;\n                    }\n                }\n                #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_PREEMPTION == 1 ) ) */\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_xTaskResumeFromISR( xYieldRequired );\n\n        return xYieldRequired;\n    }\n\n#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */\n/*-----------------------------------------------------------*/\n\nstatic BaseType_t prvCreateIdleTasks( void )\n{\n    BaseType_t xReturn = pdPASS;\n    BaseType_t xCoreID;\n    char cIdleName[ configMAX_TASK_NAME_LEN ] = { 0 };\n    TaskFunction_t pxIdleTaskFunction = NULL;\n    BaseType_t xIdleTaskNameIndex;\n    BaseType_t xIdleNameLen;\n    BaseType_t xCopyLen;\n\n    configASSERT( ( configIDLE_TASK_NAME != NULL ) && ( configMAX_TASK_NAME_LEN > 3 ) );\n\n    /* The length of the idle task name is limited to the minimum of the length\n     * of configIDLE_TASK_NAME and configMAX_TASK_NAME_LEN - 2, keeping space\n     * for the core ID suffix and the null-terminator. */\n    xIdleNameLen = strlen( configIDLE_TASK_NAME );\n    xCopyLen = xIdleNameLen < ( configMAX_TASK_NAME_LEN - 2 ) ? xIdleNameLen : ( configMAX_TASK_NAME_LEN - 2 );\n\n    for( xIdleTaskNameIndex = ( BaseType_t ) 0; xIdleTaskNameIndex < xCopyLen; xIdleTaskNameIndex++ )\n    {\n        cIdleName[ xIdleTaskNameIndex ] = configIDLE_TASK_NAME[ xIdleTaskNameIndex ];\n    }\n\n    /* Ensure null termination. */\n    cIdleName[ xIdleTaskNameIndex ] = '\\0';\n\n    /* Add each idle task at the lowest priority. */\n    for( xCoreID = ( BaseType_t ) 0; xCoreID < ( BaseType_t ) configNUMBER_OF_CORES; xCoreID++ )\n    {\n        #if ( configNUMBER_OF_CORES == 1 )\n        {\n            pxIdleTaskFunction = prvIdleTask;\n        }\n        #else /* #if (  configNUMBER_OF_CORES == 1 ) */\n        {\n            /* In the FreeRTOS SMP, configNUMBER_OF_CORES - 1 passive idle tasks\n             * are also created to ensure that each core has an idle task to\n             * run when no other task is available to run. */\n            if( xCoreID == 0 )\n            {\n                pxIdleTaskFunction = prvIdleTask;\n            }\n            else\n            {\n                pxIdleTaskFunction = prvPassiveIdleTask;\n            }\n        }\n        #endif /* #if (  configNUMBER_OF_CORES == 1 ) */\n\n        /* Update the idle task name with suffix to differentiate the idle tasks.\n         * This function is not required in single core FreeRTOS since there is\n         * only one idle task. */\n        #if ( configNUMBER_OF_CORES > 1 )\n        {\n            /* Append the idle task number to the end of the name. */\n            cIdleName[ xIdleTaskNameIndex ] = ( char ) ( xCoreID + '0' );\n            cIdleName[ xIdleTaskNameIndex + 1 ] = '\\0';\n        }\n        #endif /* if ( configNUMBER_OF_CORES > 1 ) */\n\n        #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n        {\n            StaticTask_t * pxIdleTaskTCBBuffer = NULL;\n            StackType_t * pxIdleTaskStackBuffer = NULL;\n            configSTACK_DEPTH_TYPE uxIdleTaskStackSize;\n\n            /* The Idle task is created using user provided RAM - obtain the\n             * address of the RAM then create the idle task. */\n            #if ( configNUMBER_OF_CORES == 1 )\n            {\n                vApplicationGetIdleTaskMemory( &pxIdleTaskTCBBuffer, &pxIdleTaskStackBuffer, &uxIdleTaskStackSize );\n            }\n            #else\n            {\n                if( xCoreID == 0 )\n                {\n                    vApplicationGetIdleTaskMemory( &pxIdleTaskTCBBuffer, &pxIdleTaskStackBuffer, &uxIdleTaskStackSize );\n                }\n                else\n                {\n                    vApplicationGetPassiveIdleTaskMemory( &pxIdleTaskTCBBuffer, &pxIdleTaskStackBuffer, &uxIdleTaskStackSize, ( BaseType_t ) ( xCoreID - 1 ) );\n                }\n            }\n            #endif /* if ( configNUMBER_OF_CORES == 1 ) */\n            xIdleTaskHandles[ xCoreID ] = xTaskCreateStatic( pxIdleTaskFunction,\n                                                             cIdleName,\n                                                             uxIdleTaskStackSize,\n                                                             ( void * ) NULL,\n                                                             portPRIVILEGE_BIT, /* In effect ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), but tskIDLE_PRIORITY is zero. */\n                                                             pxIdleTaskStackBuffer,\n                                                             pxIdleTaskTCBBuffer );\n\n            if( xIdleTaskHandles[ xCoreID ] != NULL )\n            {\n                xReturn = pdPASS;\n            }\n            else\n            {\n                xReturn = pdFAIL;\n            }\n        }\n        #else /* if ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n        {\n            /* The Idle task is being created using dynamically allocated RAM. */\n            xReturn = xTaskCreate( pxIdleTaskFunction,\n                                   cIdleName,\n                                   configMINIMAL_STACK_SIZE,\n                                   ( void * ) NULL,\n                                   portPRIVILEGE_BIT, /* In effect ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), but tskIDLE_PRIORITY is zero. */\n                                   &xIdleTaskHandles[ xCoreID ] );\n        }\n        #endif /* configSUPPORT_STATIC_ALLOCATION */\n\n        /* Break the loop if any of the idle task is failed to be created. */\n        if( xReturn != pdPASS )\n        {\n            break;\n        }\n        else\n        {\n            #if ( configNUMBER_OF_CORES == 1 )\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n            #else\n            {\n                /* Assign idle task to each core before SMP scheduler is running. */\n                xIdleTaskHandles[ xCoreID ]->xTaskRunState = xCoreID;\n                pxCurrentTCBs[ xCoreID ] = xIdleTaskHandles[ xCoreID ];\n            }\n            #endif\n        }\n    }\n\n    return xReturn;\n}\n\n/*-----------------------------------------------------------*/\n\nvoid vTaskStartScheduler( void )\n{\n    BaseType_t xReturn;\n\n    traceENTER_vTaskStartScheduler();\n\n    #if ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 )\n    {\n        /* Sanity check that the UBaseType_t must have greater than or equal to\n         * the number of bits as confNUMBER_OF_CORES. */\n        configASSERT( ( sizeof( UBaseType_t ) * taskBITS_PER_BYTE ) >= configNUMBER_OF_CORES );\n    }\n    #endif /* #if ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 ) */\n\n    xReturn = prvCreateIdleTasks();\n\n    #if ( configUSE_TIMERS == 1 )\n    {\n        if( xReturn == pdPASS )\n        {\n            xReturn = xTimerCreateTimerTask();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    #endif /* configUSE_TIMERS */\n\n    if( xReturn == pdPASS )\n    {\n        /* freertos_tasks_c_additions_init() should only be called if the user\n         * definable macro FREERTOS_TASKS_C_ADDITIONS_INIT() is defined, as that is\n         * the only macro called by the function. */\n        #ifdef FREERTOS_TASKS_C_ADDITIONS_INIT\n        {\n            freertos_tasks_c_additions_init();\n        }\n        #endif\n\n        /* Interrupts are turned off here, to ensure a tick does not occur\n         * before or during the call to xPortStartScheduler().  The stacks of\n         * the created tasks contain a status word with interrupts switched on\n         * so interrupts will automatically get re-enabled when the first task\n         * starts to run. */\n        portDISABLE_INTERRUPTS();\n\n        #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n        {\n            /* Switch C-Runtime's TLS Block to point to the TLS\n             * block specific to the task that will run first. */\n            configSET_TLS_BLOCK( pxCurrentTCB->xTLSBlock );\n        }\n        #endif\n\n        xNextTaskUnblockTime = portMAX_DELAY;\n        xSchedulerRunning = pdTRUE;\n        xTickCount = ( TickType_t ) configINITIAL_TICK_COUNT;\n\n        /* If configGENERATE_RUN_TIME_STATS is defined then the following\n         * macro must be defined to configure the timer/counter used to generate\n         * the run time counter time base.   NOTE:  If configGENERATE_RUN_TIME_STATS\n         * is set to 0 and the following line fails to build then ensure you do not\n         * have portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() defined in your\n         * FreeRTOSConfig.h file. */\n        portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();\n\n        traceTASK_SWITCHED_IN();\n\n        traceSTARTING_SCHEDULER( xIdleTaskHandles );\n\n        /* Setting up the timer tick is hardware specific and thus in the\n         * portable interface. */\n\n        /* The return value for xPortStartScheduler is not required\n         * hence using a void datatype. */\n        ( void ) xPortStartScheduler();\n\n        /* In most cases, xPortStartScheduler() will not return. If it\n         * returns pdTRUE then there was not enough heap memory available\n         * to create either the Idle or the Timer task. If it returned\n         * pdFALSE, then the application called xTaskEndScheduler().\n         * Most ports don't implement xTaskEndScheduler() as there is\n         * nothing to return to. */\n    }\n    else\n    {\n        /* This line will only be reached if the kernel could not be started,\n         * because there was not enough FreeRTOS heap to create the idle task\n         * or the timer task. */\n        configASSERT( xReturn != errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY );\n    }\n\n    /* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,\n     * meaning xIdleTaskHandles are not used anywhere else. */\n    ( void ) xIdleTaskHandles;\n\n    /* OpenOCD makes use of uxTopUsedPriority for thread debugging. Prevent uxTopUsedPriority\n     * from getting optimized out as it is no longer used by the kernel. */\n    ( void ) uxTopUsedPriority;\n\n    traceRETURN_vTaskStartScheduler();\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskEndScheduler( void )\n{\n    traceENTER_vTaskEndScheduler();\n\n    #if ( INCLUDE_vTaskDelete == 1 )\n    {\n        BaseType_t xCoreID;\n\n        #if ( configUSE_TIMERS == 1 )\n        {\n            /* Delete the timer task created by the kernel. */\n            vTaskDelete( xTimerGetTimerDaemonTaskHandle() );\n        }\n        #endif /* #if ( configUSE_TIMERS == 1 ) */\n\n        /* Delete Idle tasks created by the kernel.*/\n        for( xCoreID = 0; xCoreID < ( BaseType_t ) configNUMBER_OF_CORES; xCoreID++ )\n        {\n            vTaskDelete( xIdleTaskHandles[ xCoreID ] );\n        }\n\n        /* Idle task is responsible for reclaiming the resources of the tasks in\n         * xTasksWaitingTermination list. Since the idle task is now deleted and\n         * no longer going to run, we need to reclaim resources of all the tasks\n         * in the xTasksWaitingTermination list. */\n        prvCheckTasksWaitingTermination();\n    }\n    #endif /* #if ( INCLUDE_vTaskDelete == 1 ) */\n\n    /* Stop the scheduler interrupts and call the portable scheduler end\n     * routine so the original ISRs can be restored if necessary.  The port\n     * layer must ensure interrupts enable  bit is left in the correct state. */\n    portDISABLE_INTERRUPTS();\n    xSchedulerRunning = pdFALSE;\n\n    /* This function must be called from a task and the application is\n     * responsible for deleting that task after the scheduler is stopped. */\n    vPortEndScheduler();\n\n    traceRETURN_vTaskEndScheduler();\n}\n/*----------------------------------------------------------*/\n\nvoid vTaskSuspendAll( void )\n{\n    traceENTER_vTaskSuspendAll();\n\n    #if ( configNUMBER_OF_CORES == 1 )\n    {\n        /* A critical section is not required as the variable is of type\n         * BaseType_t. Each task maintains its own context, and a context switch\n         * cannot occur if the variable is non zero. So, as long as the writing\n         * from the register back into the memory is atomic, it is not a\n         * problem.\n         *\n         * Consider the following scenario, which starts with\n         * uxSchedulerSuspended at zero.\n         *\n         * 1. load uxSchedulerSuspended into register.\n         * 2. Now a context switch causes another task to run, and the other\n         *    task uses the same variable. The other task will see the variable\n         *    as zero because the variable has not yet been updated by the\n         *    original task. Eventually the original task runs again. **That can\n         *    only happen when uxSchedulerSuspended is once again zero**. When\n         *    the original task runs again, the contents of the CPU registers\n         *    are restored to exactly how they were when it was switched out -\n         *    therefore the value it read into the register still matches the\n         *    value of the uxSchedulerSuspended variable.\n         *\n         * 3. increment register.\n         * 4. store register into uxSchedulerSuspended. The value restored to\n         *    uxSchedulerSuspended will be the correct value of 1, even though\n         *    the variable was used by other tasks in the mean time.\n         */\n\n        /* portSOFTWARE_BARRIER() is only implemented for emulated/simulated ports that\n         * do not otherwise exhibit real time behaviour. */\n        portSOFTWARE_BARRIER();\n\n        /* The scheduler is suspended if uxSchedulerSuspended is non-zero.  An increment\n         * is used to allow calls to vTaskSuspendAll() to nest. */\n        uxSchedulerSuspended = ( UBaseType_t ) ( uxSchedulerSuspended + 1U );\n\n        /* Enforces ordering for ports and optimised compilers that may otherwise place\n         * the above increment elsewhere. */\n        portMEMORY_BARRIER();\n    }\n    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n    {\n        UBaseType_t ulState;\n        BaseType_t xCoreID;\n\n        /* This must only be called from within a task. */\n        portASSERT_IF_IN_ISR();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            /* Writes to uxSchedulerSuspended must be protected by both the task AND ISR locks.\n             * We must disable interrupts before we grab the locks in the event that this task is\n             * interrupted and switches context before incrementing uxSchedulerSuspended.\n             * It is safe to re-enable interrupts after releasing the ISR lock and incrementing\n             * uxSchedulerSuspended since that will prevent context switches. */\n            ulState = portSET_INTERRUPT_MASK();\n\n            xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            /* This must never be called from inside a critical section. */\n            configASSERT( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0 );\n\n            /* portSOFTWARE_BARRIER() is only implemented for emulated/simulated ports that\n             * do not otherwise exhibit real time behaviour. */\n            portSOFTWARE_BARRIER();\n\n            portGET_TASK_LOCK( xCoreID );\n\n            /* uxSchedulerSuspended is increased after prvCheckForRunStateChange. The\n             * purpose is to prevent altering the variable when fromISR APIs are readying\n             * it. */\n            if( uxSchedulerSuspended == 0U )\n            {\n                prvCheckForRunStateChange();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* Query the coreID again as prvCheckForRunStateChange may have\n             * caused the task to get scheduled on a different core. The correct\n             * task lock for the core is acquired in prvCheckForRunStateChange. */\n            xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            portGET_ISR_LOCK( xCoreID );\n\n            /* The scheduler is suspended if uxSchedulerSuspended is non-zero. An increment\n             * is used to allow calls to vTaskSuspendAll() to nest. */\n            ++uxSchedulerSuspended;\n            portRELEASE_ISR_LOCK( xCoreID );\n\n            portCLEAR_INTERRUPT_MASK( ulState );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n    }\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    traceRETURN_vTaskSuspendAll();\n}\n\n/*----------------------------------------------------------*/\n\n#if ( configUSE_TICKLESS_IDLE != 0 )\n\n    static TickType_t prvGetExpectedIdleTime( void )\n    {\n        TickType_t xReturn;\n        BaseType_t xHigherPriorityReadyTasks = pdFALSE;\n\n        /* xHigherPriorityReadyTasks takes care of the case where\n         * configUSE_PREEMPTION is 0, so there may be tasks above the idle priority\n         * task that are in the Ready state, even though the idle task is\n         * running. */\n        #if ( configUSE_PORT_OPTIMISED_TASK_SELECTION == 0 )\n        {\n            if( uxTopReadyPriority > tskIDLE_PRIORITY )\n            {\n                xHigherPriorityReadyTasks = pdTRUE;\n            }\n        }\n        #else\n        {\n            const UBaseType_t uxLeastSignificantBit = ( UBaseType_t ) 0x01;\n\n            /* When port optimised task selection is used the uxTopReadyPriority\n             * variable is used as a bit map.  If bits other than the least\n             * significant bit are set then there are tasks that have a priority\n             * above the idle priority that are in the Ready state.  This takes\n             * care of the case where the co-operative scheduler is in use. */\n            if( uxTopReadyPriority > uxLeastSignificantBit )\n            {\n                xHigherPriorityReadyTasks = pdTRUE;\n            }\n        }\n        #endif /* if ( configUSE_PORT_OPTIMISED_TASK_SELECTION == 0 ) */\n\n        if( pxCurrentTCB->uxPriority > tskIDLE_PRIORITY )\n        {\n            xReturn = 0;\n        }\n        else if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > 1U )\n        {\n            /* There are other idle priority tasks in the ready state.  If\n             * time slicing is used then the very next tick interrupt must be\n             * processed. */\n            xReturn = 0;\n        }\n        else if( xHigherPriorityReadyTasks != pdFALSE )\n        {\n            /* There are tasks in the Ready state that have a priority above the\n             * idle priority.  This path can only be reached if\n             * configUSE_PREEMPTION is 0. */\n            xReturn = 0;\n        }\n        else\n        {\n            xReturn = xNextTaskUnblockTime;\n            xReturn -= xTickCount;\n        }\n\n        return xReturn;\n    }\n\n#endif /* configUSE_TICKLESS_IDLE */\n/*----------------------------------------------------------*/\n\nBaseType_t xTaskResumeAll( void )\n{\n    TCB_t * pxTCB = NULL;\n    BaseType_t xAlreadyYielded = pdFALSE;\n\n    traceENTER_xTaskResumeAll();\n\n    #if ( configNUMBER_OF_CORES > 1 )\n        if( xSchedulerRunning != pdFALSE )\n    #endif\n    {\n        /* It is possible that an ISR caused a task to be removed from an event\n         * list while the scheduler was suspended.  If this was the case then the\n         * removed task will have been added to the xPendingReadyList.  Once the\n         * scheduler has been resumed it is safe to move all the pending ready\n         * tasks from this list into their appropriate ready list. */\n        taskENTER_CRITICAL();\n        {\n            const BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            /* If uxSchedulerSuspended is zero then this function does not match a\n             * previous call to vTaskSuspendAll(). */\n            configASSERT( uxSchedulerSuspended != 0U );\n\n            uxSchedulerSuspended = ( UBaseType_t ) ( uxSchedulerSuspended - 1U );\n            portRELEASE_TASK_LOCK( xCoreID );\n\n            if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n            {\n                if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )\n                {\n                    /* Move any readied tasks from the pending list into the\n                     * appropriate ready list. */\n                    while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )\n                    {\n                        /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                        /* coverity[misra_c_2012_rule_11_5_violation] */\n                        pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );\n                        listREMOVE_ITEM( &( pxTCB->xEventListItem ) );\n                        portMEMORY_BARRIER();\n                        listREMOVE_ITEM( &( pxTCB->xStateListItem ) );\n                        prvAddTaskToReadyList( pxTCB );\n\n                        #if ( configNUMBER_OF_CORES == 1 )\n                        {\n                            /* If the moved task has a priority higher than the current\n                             * task then a yield must be performed. */\n                            if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                            {\n                                xYieldPendings[ xCoreID ] = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                        {\n                            /* All appropriate tasks yield at the moment a task is added to xPendingReadyList.\n                             * If the current core yielded then vTaskSwitchContext() has already been called\n                             * which sets xYieldPendings for the current core to pdTRUE. */\n                        }\n                        #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n                    }\n\n                    if( pxTCB != NULL )\n                    {\n                        /* A task was unblocked while the scheduler was suspended,\n                         * which may have prevented the next unblock time from being\n                         * re-calculated, in which case re-calculate it now.  Mainly\n                         * important for low power tickless implementations, where\n                         * this can prevent an unnecessary exit from low power\n                         * state. */\n                        prvResetNextTaskUnblockTime();\n                    }\n\n                    /* If any ticks occurred while the scheduler was suspended then\n                     * they should be processed now.  This ensures the tick count does\n                     * not  slip, and that any delayed tasks are resumed at the correct\n                     * time.\n                     *\n                     * It should be safe to call xTaskIncrementTick here from any core\n                     * since we are in a critical section and xTaskIncrementTick itself\n                     * protects itself within a critical section. Suspending the scheduler\n                     * from any core causes xTaskIncrementTick to increment uxPendedCounts. */\n                    {\n                        TickType_t xPendedCounts = xPendedTicks; /* Non-volatile copy. */\n\n                        if( xPendedCounts > ( TickType_t ) 0U )\n                        {\n                            do\n                            {\n                                if( xTaskIncrementTick() != pdFALSE )\n                                {\n                                    /* Other cores are interrupted from\n                                     * within xTaskIncrementTick(). */\n                                    xYieldPendings[ xCoreID ] = pdTRUE;\n                                }\n                                else\n                                {\n                                    mtCOVERAGE_TEST_MARKER();\n                                }\n\n                                --xPendedCounts;\n                            } while( xPendedCounts > ( TickType_t ) 0U );\n\n                            xPendedTicks = 0;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n\n                    if( xYieldPendings[ xCoreID ] != pdFALSE )\n                    {\n                        #if ( configUSE_PREEMPTION != 0 )\n                        {\n                            xAlreadyYielded = pdTRUE;\n                        }\n                        #endif /* #if ( configUSE_PREEMPTION != 0 ) */\n\n                        #if ( configNUMBER_OF_CORES == 1 )\n                        {\n                            taskYIELD_TASK_CORE_IF_USING_PREEMPTION( pxCurrentTCB );\n                        }\n                        #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL();\n    }\n\n    traceRETURN_xTaskResumeAll( xAlreadyYielded );\n\n    return xAlreadyYielded;\n}\n/*-----------------------------------------------------------*/\n\nTickType_t xTaskGetTickCount( void )\n{\n    TickType_t xTicks;\n\n    traceENTER_xTaskGetTickCount();\n\n    /* Critical section required if running on a 16 bit processor. */\n    portTICK_TYPE_ENTER_CRITICAL();\n    {\n        xTicks = xTickCount;\n    }\n    portTICK_TYPE_EXIT_CRITICAL();\n\n    traceRETURN_xTaskGetTickCount( xTicks );\n\n    return xTicks;\n}\n/*-----------------------------------------------------------*/\n\nTickType_t xTaskGetTickCountFromISR( void )\n{\n    TickType_t xReturn;\n    UBaseType_t uxSavedInterruptStatus;\n\n    traceENTER_xTaskGetTickCountFromISR();\n\n    /* RTOS ports that support interrupt nesting have the concept of a maximum\n     * system call (or maximum API call) interrupt priority.  Interrupts that are\n     * above the maximum system call priority are kept permanently enabled, even\n     * when the RTOS kernel is in a critical section, but cannot make any calls to\n     * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h\n     * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n     * failure if a FreeRTOS API function is called from an interrupt that has been\n     * assigned a priority above the configured maximum system call priority.\n     * Only FreeRTOS functions that end in FromISR can be called from interrupts\n     * that have been assigned a priority at or (logically) below the maximum\n     * system call  interrupt priority.  FreeRTOS maintains a separate interrupt\n     * safe API to ensure interrupt entry is as fast and as simple as possible.\n     * More information (albeit Cortex-M specific) is provided on the following\n     * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n    portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n    uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();\n    {\n        xReturn = xTickCount;\n    }\n    portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );\n\n    traceRETURN_xTaskGetTickCountFromISR( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nUBaseType_t uxTaskGetNumberOfTasks( void )\n{\n    traceENTER_uxTaskGetNumberOfTasks();\n\n    /* A critical section is not required because the variables are of type\n     * BaseType_t. */\n    traceRETURN_uxTaskGetNumberOfTasks( uxCurrentNumberOfTasks );\n\n    return uxCurrentNumberOfTasks;\n}\n/*-----------------------------------------------------------*/\n\nchar * pcTaskGetName( TaskHandle_t xTaskToQuery )\n{\n    TCB_t * pxTCB;\n\n    traceENTER_pcTaskGetName( xTaskToQuery );\n\n    /* If null is passed in here then the name of the calling task is being\n     * queried. */\n    pxTCB = prvGetTCBFromHandle( xTaskToQuery );\n    configASSERT( pxTCB != NULL );\n\n    traceRETURN_pcTaskGetName( &( pxTCB->pcTaskName[ 0 ] ) );\n\n    return &( pxTCB->pcTaskName[ 0 ] );\n}\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_xTaskGetHandle == 1 )\n    static TCB_t * prvSearchForNameWithinSingleList( List_t * pxList,\n                                                     const char pcNameToQuery[] )\n    {\n        TCB_t * pxReturn = NULL;\n        TCB_t * pxTCB = NULL;\n        UBaseType_t x;\n        char cNextChar;\n        BaseType_t xBreakLoop;\n        const ListItem_t * pxEndMarker = listGET_END_MARKER( pxList );\n        ListItem_t * pxIterator;\n\n        /* This function is called with the scheduler suspended. */\n\n        if( listCURRENT_LIST_LENGTH( pxList ) > ( UBaseType_t ) 0 )\n        {\n            for( pxIterator = listGET_HEAD_ENTRY( pxList ); pxIterator != pxEndMarker; pxIterator = listGET_NEXT( pxIterator ) )\n            {\n                /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                /* coverity[misra_c_2012_rule_11_5_violation] */\n                pxTCB = listGET_LIST_ITEM_OWNER( pxIterator );\n\n                /* Check each character in the name looking for a match or\n                 * mismatch. */\n                xBreakLoop = pdFALSE;\n\n                for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )\n                {\n                    cNextChar = pxTCB->pcTaskName[ x ];\n\n                    if( cNextChar != pcNameToQuery[ x ] )\n                    {\n                        /* Characters didn't match. */\n                        xBreakLoop = pdTRUE;\n                    }\n                    else if( cNextChar == ( char ) 0x00 )\n                    {\n                        /* Both strings terminated, a match must have been\n                         * found. */\n                        pxReturn = pxTCB;\n                        xBreakLoop = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    if( xBreakLoop != pdFALSE )\n                    {\n                        break;\n                    }\n                }\n\n                if( pxReturn != NULL )\n                {\n                    /* The handle has been found. */\n                    break;\n                }\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        return pxReturn;\n    }\n\n#endif /* INCLUDE_xTaskGetHandle */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_xTaskGetHandle == 1 )\n\n    TaskHandle_t xTaskGetHandle( const char * pcNameToQuery )\n    {\n        UBaseType_t uxQueue = configMAX_PRIORITIES;\n        TCB_t * pxTCB;\n\n        traceENTER_xTaskGetHandle( pcNameToQuery );\n\n        /* Task names will be truncated to configMAX_TASK_NAME_LEN - 1 bytes. */\n        configASSERT( strlen( pcNameToQuery ) < configMAX_TASK_NAME_LEN );\n\n        vTaskSuspendAll();\n        {\n            /* Search the ready lists. */\n            do\n            {\n                uxQueue--;\n                pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) &( pxReadyTasksLists[ uxQueue ] ), pcNameToQuery );\n\n                if( pxTCB != NULL )\n                {\n                    /* Found the handle. */\n                    break;\n                }\n            } while( uxQueue > ( UBaseType_t ) tskIDLE_PRIORITY );\n\n            /* Search the delayed lists. */\n            if( pxTCB == NULL )\n            {\n                pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) pxDelayedTaskList, pcNameToQuery );\n            }\n\n            if( pxTCB == NULL )\n            {\n                pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) pxOverflowDelayedTaskList, pcNameToQuery );\n            }\n\n            #if ( INCLUDE_vTaskSuspend == 1 )\n            {\n                if( pxTCB == NULL )\n                {\n                    /* Search the suspended list. */\n                    pxTCB = prvSearchForNameWithinSingleList( &xSuspendedTaskList, pcNameToQuery );\n                }\n            }\n            #endif\n\n            #if ( INCLUDE_vTaskDelete == 1 )\n            {\n                if( pxTCB == NULL )\n                {\n                    /* Search the deleted list. */\n                    pxTCB = prvSearchForNameWithinSingleList( &xTasksWaitingTermination, pcNameToQuery );\n                }\n            }\n            #endif\n        }\n        ( void ) xTaskResumeAll();\n\n        traceRETURN_xTaskGetHandle( pxTCB );\n\n        return pxTCB;\n    }\n\n#endif /* INCLUDE_xTaskGetHandle */\n/*-----------------------------------------------------------*/\n\n#if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n    BaseType_t xTaskGetStaticBuffers( TaskHandle_t xTask,\n                                      StackType_t ** ppuxStackBuffer,\n                                      StaticTask_t ** ppxTaskBuffer )\n    {\n        BaseType_t xReturn;\n        TCB_t * pxTCB;\n\n        traceENTER_xTaskGetStaticBuffers( xTask, ppuxStackBuffer, ppxTaskBuffer );\n\n        configASSERT( ppuxStackBuffer != NULL );\n        configASSERT( ppxTaskBuffer != NULL );\n\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE == 1 )\n        {\n            if( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB )\n            {\n                *ppuxStackBuffer = pxTCB->pxStack;\n                /* MISRA Ref 11.3.1 [Misaligned access] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n                /* coverity[misra_c_2012_rule_11_3_violation] */\n                *ppxTaskBuffer = ( StaticTask_t * ) pxTCB;\n                xReturn = pdTRUE;\n            }\n            else if( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_ONLY )\n            {\n                *ppuxStackBuffer = pxTCB->pxStack;\n                *ppxTaskBuffer = NULL;\n                xReturn = pdTRUE;\n            }\n            else\n            {\n                xReturn = pdFALSE;\n            }\n        }\n        #else /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE == 1 */\n        {\n            *ppuxStackBuffer = pxTCB->pxStack;\n            *ppxTaskBuffer = ( StaticTask_t * ) pxTCB;\n            xReturn = pdTRUE;\n        }\n        #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE == 1 */\n\n        traceRETURN_xTaskGetStaticBuffers( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    UBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray,\n                                      const UBaseType_t uxArraySize,\n                                      configRUN_TIME_COUNTER_TYPE * const pulTotalRunTime )\n    {\n        UBaseType_t uxTask = 0, uxQueue = configMAX_PRIORITIES;\n\n        traceENTER_uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, pulTotalRunTime );\n\n        vTaskSuspendAll();\n        {\n            /* Is there a space in the array for each task in the system? */\n            if( uxArraySize >= uxCurrentNumberOfTasks )\n            {\n                /* Fill in an TaskStatus_t structure with information on each\n                 * task in the Ready state. */\n                do\n                {\n                    uxQueue--;\n                    uxTask = ( UBaseType_t ) ( uxTask + prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &( pxReadyTasksLists[ uxQueue ] ), eReady ) );\n                } while( uxQueue > ( UBaseType_t ) tskIDLE_PRIORITY );\n\n                /* Fill in an TaskStatus_t structure with information on each\n                 * task in the Blocked state. */\n                uxTask = ( UBaseType_t ) ( uxTask + prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), ( List_t * ) pxDelayedTaskList, eBlocked ) );\n                uxTask = ( UBaseType_t ) ( uxTask + prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), ( List_t * ) pxOverflowDelayedTaskList, eBlocked ) );\n\n                #if ( INCLUDE_vTaskDelete == 1 )\n                {\n                    /* Fill in an TaskStatus_t structure with information on\n                     * each task that has been deleted but not yet cleaned up. */\n                    uxTask = ( UBaseType_t ) ( uxTask + prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &xTasksWaitingTermination, eDeleted ) );\n                }\n                #endif\n\n                #if ( INCLUDE_vTaskSuspend == 1 )\n                {\n                    /* Fill in an TaskStatus_t structure with information on\n                     * each task in the Suspended state. */\n                    uxTask = ( UBaseType_t ) ( uxTask + prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &xSuspendedTaskList, eSuspended ) );\n                }\n                #endif\n\n                #if ( configGENERATE_RUN_TIME_STATS == 1 )\n                {\n                    if( pulTotalRunTime != NULL )\n                    {\n                        #ifdef portALT_GET_RUN_TIME_COUNTER_VALUE\n                            portALT_GET_RUN_TIME_COUNTER_VALUE( ( *pulTotalRunTime ) );\n                        #else\n                            *pulTotalRunTime = ( configRUN_TIME_COUNTER_TYPE ) portGET_RUN_TIME_COUNTER_VALUE();\n                        #endif\n                    }\n                }\n                #else /* if ( configGENERATE_RUN_TIME_STATS == 1 ) */\n                {\n                    if( pulTotalRunTime != NULL )\n                    {\n                        *pulTotalRunTime = 0;\n                    }\n                }\n                #endif /* if ( configGENERATE_RUN_TIME_STATS == 1 ) */\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        ( void ) xTaskResumeAll();\n\n        traceRETURN_uxTaskGetSystemState( uxTask );\n\n        return uxTask;\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*----------------------------------------------------------*/\n\n#if ( INCLUDE_xTaskGetIdleTaskHandle == 1 )\n\n    #if ( configNUMBER_OF_CORES == 1 )\n        TaskHandle_t xTaskGetIdleTaskHandle( void )\n        {\n            traceENTER_xTaskGetIdleTaskHandle();\n\n            /* If xTaskGetIdleTaskHandle() is called before the scheduler has been\n             * started, then xIdleTaskHandles will be NULL. */\n            configASSERT( ( xIdleTaskHandles[ 0 ] != NULL ) );\n\n            traceRETURN_xTaskGetIdleTaskHandle( xIdleTaskHandles[ 0 ] );\n\n            return xIdleTaskHandles[ 0 ];\n        }\n    #endif /* if ( configNUMBER_OF_CORES == 1 ) */\n\n    TaskHandle_t xTaskGetIdleTaskHandleForCore( BaseType_t xCoreID )\n    {\n        traceENTER_xTaskGetIdleTaskHandleForCore( xCoreID );\n\n        /* Ensure the core ID is valid. */\n        configASSERT( taskVALID_CORE_ID( xCoreID ) == pdTRUE );\n\n        /* If xTaskGetIdleTaskHandle() is called before the scheduler has been\n         * started, then xIdleTaskHandles will be NULL. */\n        configASSERT( ( xIdleTaskHandles[ xCoreID ] != NULL ) );\n\n        traceRETURN_xTaskGetIdleTaskHandleForCore( xIdleTaskHandles[ xCoreID ] );\n\n        return xIdleTaskHandles[ xCoreID ];\n    }\n\n#endif /* INCLUDE_xTaskGetIdleTaskHandle */\n/*----------------------------------------------------------*/\n\n/* This conditional compilation should use inequality to 0, not equality to 1.\n * This is to ensure vTaskStepTick() is available when user defined low power mode\n * implementations require configUSE_TICKLESS_IDLE to be set to a value other than\n * 1. */\n#if ( configUSE_TICKLESS_IDLE != 0 )\n\n    void vTaskStepTick( TickType_t xTicksToJump )\n    {\n        TickType_t xUpdatedTickCount;\n\n        traceENTER_vTaskStepTick( xTicksToJump );\n\n        /* Correct the tick count value after a period during which the tick\n         * was suppressed.  Note this does *not* call the tick hook function for\n         * each stepped tick. */\n        xUpdatedTickCount = xTickCount + xTicksToJump;\n        configASSERT( xUpdatedTickCount <= xNextTaskUnblockTime );\n\n        if( xUpdatedTickCount == xNextTaskUnblockTime )\n        {\n            /* Arrange for xTickCount to reach xNextTaskUnblockTime in\n             * xTaskIncrementTick() when the scheduler resumes.  This ensures\n             * that any delayed tasks are resumed at the correct time. */\n            configASSERT( uxSchedulerSuspended != ( UBaseType_t ) 0U );\n            configASSERT( xTicksToJump != ( TickType_t ) 0 );\n\n            /* Prevent the tick interrupt modifying xPendedTicks simultaneously. */\n            taskENTER_CRITICAL();\n            {\n                xPendedTicks++;\n            }\n            taskEXIT_CRITICAL();\n            xTicksToJump--;\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        xTickCount += xTicksToJump;\n\n        traceINCREASE_TICK_COUNT( xTicksToJump );\n        traceRETURN_vTaskStepTick();\n    }\n\n#endif /* configUSE_TICKLESS_IDLE */\n/*----------------------------------------------------------*/\n\nBaseType_t xTaskCatchUpTicks( TickType_t xTicksToCatchUp )\n{\n    BaseType_t xYieldOccurred;\n\n    traceENTER_xTaskCatchUpTicks( xTicksToCatchUp );\n\n    /* Must not be called with the scheduler suspended as the implementation\n     * relies on xPendedTicks being wound down to 0 in xTaskResumeAll(). */\n    configASSERT( uxSchedulerSuspended == ( UBaseType_t ) 0U );\n\n    /* Use xPendedTicks to mimic xTicksToCatchUp number of ticks occurring when\n     * the scheduler is suspended so the ticks are executed in xTaskResumeAll(). */\n    vTaskSuspendAll();\n\n    /* Prevent the tick interrupt modifying xPendedTicks simultaneously. */\n    taskENTER_CRITICAL();\n    {\n        xPendedTicks += xTicksToCatchUp;\n    }\n    taskEXIT_CRITICAL();\n    xYieldOccurred = xTaskResumeAll();\n\n    traceRETURN_xTaskCatchUpTicks( xYieldOccurred );\n\n    return xYieldOccurred;\n}\n/*----------------------------------------------------------*/\n\n#if ( INCLUDE_xTaskAbortDelay == 1 )\n\n    BaseType_t xTaskAbortDelay( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB = xTask;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskAbortDelay( xTask );\n\n        configASSERT( pxTCB != NULL );\n\n        vTaskSuspendAll();\n        {\n            /* A task can only be prematurely removed from the Blocked state if\n             * it is actually in the Blocked state. */\n            if( eTaskGetState( xTask ) == eBlocked )\n            {\n                xReturn = pdPASS;\n\n                /* Remove the reference to the task from the blocked list.  An\n                 * interrupt won't touch the xStateListItem because the\n                 * scheduler is suspended. */\n                ( void ) uxListRemove( &( pxTCB->xStateListItem ) );\n\n                /* Is the task waiting on an event also?  If so remove it from\n                 * the event list too.  Interrupts can touch the event list item,\n                 * even though the scheduler is suspended, so a critical section\n                 * is used. */\n                taskENTER_CRITICAL();\n                {\n                    if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )\n                    {\n                        ( void ) uxListRemove( &( pxTCB->xEventListItem ) );\n\n                        /* This lets the task know it was forcibly removed from the\n                         * blocked state so it should not re-evaluate its block time and\n                         * then block again. */\n                        pxTCB->ucDelayAborted = ( uint8_t ) pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                /* Place the unblocked task into the appropriate ready list. */\n                prvAddTaskToReadyList( pxTCB );\n\n                /* A task being unblocked cannot cause an immediate context\n                 * switch if preemption is turned off. */\n                #if ( configUSE_PREEMPTION == 1 )\n                {\n                    #if ( configNUMBER_OF_CORES == 1 )\n                    {\n                        /* Preemption is on, but a context switch should only be\n                         * performed if the unblocked task has a priority that is\n                         * higher than the currently executing task. */\n                        if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                        {\n                            /* Pend the yield to be performed when the scheduler\n                             * is unsuspended. */\n                            xYieldPendings[ 0 ] = pdTRUE;\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                    {\n                        taskENTER_CRITICAL();\n                        {\n                            prvYieldForTask( pxTCB );\n                        }\n                        taskEXIT_CRITICAL();\n                    }\n                    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n                }\n                #endif /* #if ( configUSE_PREEMPTION == 1 ) */\n            }\n            else\n            {\n                xReturn = pdFAIL;\n            }\n        }\n        ( void ) xTaskResumeAll();\n\n        traceRETURN_xTaskAbortDelay( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* INCLUDE_xTaskAbortDelay */\n/*----------------------------------------------------------*/\n\nBaseType_t xTaskIncrementTick( void )\n{\n    TCB_t * pxTCB;\n    TickType_t xItemValue;\n    BaseType_t xSwitchRequired = pdFALSE;\n\n    traceENTER_xTaskIncrementTick();\n\n    /* Called by the portable layer each time a tick interrupt occurs.\n     * Increments the tick then checks to see if the new tick value will cause any\n     * tasks to be unblocked. */\n    traceTASK_INCREMENT_TICK( xTickCount );\n\n    /* Tick increment should occur on every kernel timer event. Core 0 has the\n     * responsibility to increment the tick, or increment the pended ticks if the\n     * scheduler is suspended.  If pended ticks is greater than zero, the core that\n     * calls xTaskResumeAll has the responsibility to increment the tick. */\n    if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n    {\n        /* Minor optimisation.  The tick count cannot change in this\n         * block. */\n        const TickType_t xConstTickCount = xTickCount + ( TickType_t ) 1;\n\n        /* Increment the RTOS tick, switching the delayed and overflowed\n         * delayed lists if it wraps to 0. */\n        xTickCount = xConstTickCount;\n\n        if( xConstTickCount == ( TickType_t ) 0U )\n        {\n            taskSWITCH_DELAYED_LISTS();\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        /* See if this tick has made a timeout expire.  Tasks are stored in\n         * the  queue in the order of their wake time - meaning once one task\n         * has been found whose block time has not expired there is no need to\n         * look any further down the list. */\n        if( xConstTickCount >= xNextTaskUnblockTime )\n        {\n            for( ; ; )\n            {\n                if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )\n                {\n                    /* The delayed list is empty.  Set xNextTaskUnblockTime\n                     * to the maximum possible value so it is extremely\n                     * unlikely that the\n                     * if( xTickCount >= xNextTaskUnblockTime ) test will pass\n                     * next time through. */\n                    xNextTaskUnblockTime = portMAX_DELAY;\n                    break;\n                }\n                else\n                {\n                    /* The delayed list is not empty, get the value of the\n                     * item at the head of the delayed list.  This is the time\n                     * at which the task at the head of the delayed list must\n                     * be removed from the Blocked state. */\n                    /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                    /* coverity[misra_c_2012_rule_11_5_violation] */\n                    pxTCB = listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );\n                    xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );\n\n                    if( xConstTickCount < xItemValue )\n                    {\n                        /* It is not time to unblock this item yet, but the\n                         * item value is the time at which the task at the head\n                         * of the blocked list must be removed from the Blocked\n                         * state -  so record the item value in\n                         * xNextTaskUnblockTime. */\n                        xNextTaskUnblockTime = xItemValue;\n                        break;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* It is time to remove the item from the Blocked state. */\n                    listREMOVE_ITEM( &( pxTCB->xStateListItem ) );\n\n                    /* Is the task waiting on an event also?  If so remove\n                     * it from the event list. */\n                    if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )\n                    {\n                        listREMOVE_ITEM( &( pxTCB->xEventListItem ) );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* Place the unblocked task into the appropriate ready\n                     * list. */\n                    prvAddTaskToReadyList( pxTCB );\n\n                    /* A task being unblocked cannot cause an immediate\n                     * context switch if preemption is turned off. */\n                    #if ( configUSE_PREEMPTION == 1 )\n                    {\n                        #if ( configNUMBER_OF_CORES == 1 )\n                        {\n                            /* Preemption is on, but a context switch should\n                             * only be performed if the unblocked task's\n                             * priority is higher than the currently executing\n                             * task.\n                             * The case of equal priority tasks sharing\n                             * processing time (which happens when both\n                             * preemption and time slicing are on) is\n                             * handled below.*/\n                            if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                            {\n                                xSwitchRequired = pdTRUE;\n                            }\n                            else\n                            {\n                                mtCOVERAGE_TEST_MARKER();\n                            }\n                        }\n                        #else /* #if( configNUMBER_OF_CORES == 1 ) */\n                        {\n                            prvYieldForTask( pxTCB );\n                        }\n                        #endif /* #if( configNUMBER_OF_CORES == 1 ) */\n                    }\n                    #endif /* #if ( configUSE_PREEMPTION == 1 ) */\n                }\n            }\n        }\n\n        /* Tasks of equal priority to the currently running task will share\n         * processing time (time slice) if preemption is on, and the application\n         * writer has not explicitly turned time slicing off. */\n        #if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )\n        {\n            #if ( configNUMBER_OF_CORES == 1 )\n            {\n                if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > 1U )\n                {\n                    xSwitchRequired = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n            {\n                BaseType_t xCoreID;\n\n                for( xCoreID = 0; xCoreID < ( ( BaseType_t ) configNUMBER_OF_CORES ); xCoreID++ )\n                {\n                    if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCBs[ xCoreID ]->uxPriority ] ) ) > 1U )\n                    {\n                        xYieldPendings[ xCoreID ] = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n            }\n            #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n        }\n        #endif /* #if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) ) */\n\n        #if ( configUSE_TICK_HOOK == 1 )\n        {\n            /* Guard against the tick hook being called when the pended tick\n             * count is being unwound (when the scheduler is being unlocked). */\n            if( xPendedTicks == ( TickType_t ) 0 )\n            {\n                vApplicationTickHook();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* configUSE_TICK_HOOK */\n\n        #if ( configUSE_PREEMPTION == 1 )\n        {\n            #if ( configNUMBER_OF_CORES == 1 )\n            {\n                /* For single core the core ID is always 0. */\n                if( xYieldPendings[ 0 ] != pdFALSE )\n                {\n                    xSwitchRequired = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n            {\n                BaseType_t xCoreID, xCurrentCoreID;\n                xCurrentCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n                for( xCoreID = 0; xCoreID < ( BaseType_t ) configNUMBER_OF_CORES; xCoreID++ )\n                {\n                    #if ( configUSE_TASK_PREEMPTION_DISABLE == 1 )\n                        if( pxCurrentTCBs[ xCoreID ]->xPreemptionDisable == pdFALSE )\n                    #endif\n                    {\n                        if( xYieldPendings[ xCoreID ] != pdFALSE )\n                        {\n                            if( xCoreID == xCurrentCoreID )\n                            {\n                                xSwitchRequired = pdTRUE;\n                            }\n                            else\n                            {\n                                prvYieldCore( xCoreID );\n                            }\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n                    }\n                }\n            }\n            #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n        }\n        #endif /* #if ( configUSE_PREEMPTION == 1 ) */\n    }\n    else\n    {\n        xPendedTicks += 1U;\n\n        /* The tick hook gets called at regular intervals, even if the\n         * scheduler is locked. */\n        #if ( configUSE_TICK_HOOK == 1 )\n        {\n            vApplicationTickHook();\n        }\n        #endif\n    }\n\n    traceRETURN_xTaskIncrementTick( xSwitchRequired );\n\n    return xSwitchRequired;\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_APPLICATION_TASK_TAG == 1 )\n\n    void vTaskSetApplicationTaskTag( TaskHandle_t xTask,\n                                     TaskHookFunction_t pxHookFunction )\n    {\n        TCB_t * xTCB;\n\n        traceENTER_vTaskSetApplicationTaskTag( xTask, pxHookFunction );\n\n        /* If xTask is NULL then it is the task hook of the calling task that is\n         * getting set. */\n        if( xTask == NULL )\n        {\n            xTCB = ( TCB_t * ) pxCurrentTCB;\n        }\n        else\n        {\n            xTCB = xTask;\n        }\n\n        /* Save the hook function in the TCB.  A critical section is required as\n         * the value can be accessed from an interrupt. */\n        taskENTER_CRITICAL();\n        {\n            xTCB->pxTaskTag = pxHookFunction;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTaskSetApplicationTaskTag();\n    }\n\n#endif /* configUSE_APPLICATION_TASK_TAG */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_APPLICATION_TASK_TAG == 1 )\n\n    TaskHookFunction_t xTaskGetApplicationTaskTag( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        TaskHookFunction_t xReturn;\n\n        traceENTER_xTaskGetApplicationTaskTag( xTask );\n\n        /* If xTask is NULL then set the calling task's hook. */\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        /* Save the hook function in the TCB.  A critical section is required as\n         * the value can be accessed from an interrupt. */\n        taskENTER_CRITICAL();\n        {\n            xReturn = pxTCB->pxTaskTag;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xTaskGetApplicationTaskTag( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_APPLICATION_TASK_TAG */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_APPLICATION_TASK_TAG == 1 )\n\n    TaskHookFunction_t xTaskGetApplicationTaskTagFromISR( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        TaskHookFunction_t xReturn;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_xTaskGetApplicationTaskTagFromISR( xTask );\n\n        /* If xTask is NULL then set the calling task's hook. */\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        /* Save the hook function in the TCB.  A critical section is required as\n         * the value can be accessed from an interrupt. */\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();\n        {\n            xReturn = pxTCB->pxTaskTag;\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_xTaskGetApplicationTaskTagFromISR( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_APPLICATION_TASK_TAG */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_APPLICATION_TASK_TAG == 1 )\n\n    BaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask,\n                                             void * pvParameter )\n    {\n        TCB_t * xTCB;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskCallApplicationTaskHook( xTask, pvParameter );\n\n        /* If xTask is NULL then we are calling our own task hook. */\n        if( xTask == NULL )\n        {\n            xTCB = pxCurrentTCB;\n        }\n        else\n        {\n            xTCB = xTask;\n        }\n\n        if( xTCB->pxTaskTag != NULL )\n        {\n            xReturn = xTCB->pxTaskTag( pvParameter );\n        }\n        else\n        {\n            xReturn = pdFAIL;\n        }\n\n        traceRETURN_xTaskCallApplicationTaskHook( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_APPLICATION_TASK_TAG */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES == 1 )\n    void vTaskSwitchContext( void )\n    {\n        traceENTER_vTaskSwitchContext();\n\n        if( uxSchedulerSuspended != ( UBaseType_t ) 0U )\n        {\n            /* The scheduler is currently suspended - do not allow a context\n             * switch. */\n            xYieldPendings[ 0 ] = pdTRUE;\n        }\n        else\n        {\n            xYieldPendings[ 0 ] = pdFALSE;\n            traceTASK_SWITCHED_OUT();\n\n            #if ( configGENERATE_RUN_TIME_STATS == 1 )\n            {\n                #ifdef portALT_GET_RUN_TIME_COUNTER_VALUE\n                    portALT_GET_RUN_TIME_COUNTER_VALUE( ulTotalRunTime[ 0 ] );\n                #else\n                    ulTotalRunTime[ 0 ] = portGET_RUN_TIME_COUNTER_VALUE();\n                #endif\n\n                /* Add the amount of time the task has been running to the\n                 * accumulated time so far.  The time the task started running was\n                 * stored in ulTaskSwitchedInTime.  Note that there is no overflow\n                 * protection here so count values are only valid until the timer\n                 * overflows.  The guard against negative values is to protect\n                 * against suspect run time stat counter implementations - which\n                 * are provided by the application, not the kernel. */\n                if( ulTotalRunTime[ 0 ] > ulTaskSwitchedInTime[ 0 ] )\n                {\n                    pxCurrentTCB->ulRunTimeCounter += ( ulTotalRunTime[ 0 ] - ulTaskSwitchedInTime[ 0 ] );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                ulTaskSwitchedInTime[ 0 ] = ulTotalRunTime[ 0 ];\n            }\n            #endif /* configGENERATE_RUN_TIME_STATS */\n\n            /* Check for stack overflow, if configured. */\n            taskCHECK_FOR_STACK_OVERFLOW();\n\n            /* Before the currently running task is switched out, save its errno. */\n            #if ( configUSE_POSIX_ERRNO == 1 )\n            {\n                pxCurrentTCB->iTaskErrno = FreeRTOS_errno;\n            }\n            #endif\n\n            /* Select a new task to run using either the generic C or port\n             * optimised asm code. */\n            /* MISRA Ref 11.5.3 [Void pointer assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            taskSELECT_HIGHEST_PRIORITY_TASK();\n            traceTASK_SWITCHED_IN();\n\n            /* Macro to inject port specific behaviour immediately after\n             * switching tasks, such as setting an end of stack watchpoint\n             * or reconfiguring the MPU. */\n            portTASK_SWITCH_HOOK( pxCurrentTCB );\n\n            /* After the new task is switched in, update the global errno. */\n            #if ( configUSE_POSIX_ERRNO == 1 )\n            {\n                FreeRTOS_errno = pxCurrentTCB->iTaskErrno;\n            }\n            #endif\n\n            #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n            {\n                /* Switch C-Runtime's TLS Block to point to the TLS\n                 * Block specific to this task. */\n                configSET_TLS_BLOCK( pxCurrentTCB->xTLSBlock );\n            }\n            #endif\n        }\n\n        traceRETURN_vTaskSwitchContext();\n    }\n#else /* if ( configNUMBER_OF_CORES == 1 ) */\n    void vTaskSwitchContext( BaseType_t xCoreID )\n    {\n        traceENTER_vTaskSwitchContext();\n\n        /* Acquire both locks:\n         * - The ISR lock protects the ready list from simultaneous access by\n         *   both other ISRs and tasks.\n         * - We also take the task lock to pause here in case another core has\n         *   suspended the scheduler. We don't want to simply set xYieldPending\n         *   and move on if another core suspended the scheduler. We should only\n         *   do that if the current core has suspended the scheduler. */\n\n        portGET_TASK_LOCK( xCoreID ); /* Must always acquire the task lock first. */\n        portGET_ISR_LOCK( xCoreID );\n        {\n            /* vTaskSwitchContext() must never be called from within a critical section.\n             * This is not necessarily true for single core FreeRTOS, but it is for this\n             * SMP port. */\n            configASSERT( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0 );\n\n            if( uxSchedulerSuspended != ( UBaseType_t ) 0U )\n            {\n                /* The scheduler is currently suspended - do not allow a context\n                 * switch. */\n                xYieldPendings[ xCoreID ] = pdTRUE;\n            }\n            else\n            {\n                xYieldPendings[ xCoreID ] = pdFALSE;\n                traceTASK_SWITCHED_OUT();\n\n                #if ( configGENERATE_RUN_TIME_STATS == 1 )\n                {\n                    #ifdef portALT_GET_RUN_TIME_COUNTER_VALUE\n                        portALT_GET_RUN_TIME_COUNTER_VALUE( ulTotalRunTime[ xCoreID ] );\n                    #else\n                        ulTotalRunTime[ xCoreID ] = portGET_RUN_TIME_COUNTER_VALUE();\n                    #endif\n\n                    /* Add the amount of time the task has been running to the\n                     * accumulated time so far.  The time the task started running was\n                     * stored in ulTaskSwitchedInTime.  Note that there is no overflow\n                     * protection here so count values are only valid until the timer\n                     * overflows.  The guard against negative values is to protect\n                     * against suspect run time stat counter implementations - which\n                     * are provided by the application, not the kernel. */\n                    if( ulTotalRunTime[ xCoreID ] > ulTaskSwitchedInTime[ xCoreID ] )\n                    {\n                        pxCurrentTCBs[ xCoreID ]->ulRunTimeCounter += ( ulTotalRunTime[ xCoreID ] - ulTaskSwitchedInTime[ xCoreID ] );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    ulTaskSwitchedInTime[ xCoreID ] = ulTotalRunTime[ xCoreID ];\n                }\n                #endif /* configGENERATE_RUN_TIME_STATS */\n\n                /* Check for stack overflow, if configured. */\n                taskCHECK_FOR_STACK_OVERFLOW();\n\n                /* Before the currently running task is switched out, save its errno. */\n                #if ( configUSE_POSIX_ERRNO == 1 )\n                {\n                    pxCurrentTCBs[ xCoreID ]->iTaskErrno = FreeRTOS_errno;\n                }\n                #endif\n\n                /* Select a new task to run. */\n                taskSELECT_HIGHEST_PRIORITY_TASK( xCoreID );\n                traceTASK_SWITCHED_IN();\n\n                /* Macro to inject port specific behaviour immediately after\n                 * switching tasks, such as setting an end of stack watchpoint\n                 * or reconfiguring the MPU. */\n                portTASK_SWITCH_HOOK( pxCurrentTCBs[ portGET_CORE_ID() ] );\n\n                /* After the new task is switched in, update the global errno. */\n                #if ( configUSE_POSIX_ERRNO == 1 )\n                {\n                    FreeRTOS_errno = pxCurrentTCBs[ xCoreID ]->iTaskErrno;\n                }\n                #endif\n\n                #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n                {\n                    /* Switch C-Runtime's TLS Block to point to the TLS\n                     * Block specific to this task. */\n                    configSET_TLS_BLOCK( pxCurrentTCBs[ xCoreID ]->xTLSBlock );\n                }\n                #endif\n            }\n        }\n        portRELEASE_ISR_LOCK( xCoreID );\n        portRELEASE_TASK_LOCK( xCoreID );\n\n        traceRETURN_vTaskSwitchContext();\n    }\n#endif /* if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\nvoid vTaskPlaceOnEventList( List_t * const pxEventList,\n                            const TickType_t xTicksToWait )\n{\n    traceENTER_vTaskPlaceOnEventList( pxEventList, xTicksToWait );\n\n    configASSERT( pxEventList );\n\n    /* THIS FUNCTION MUST BE CALLED WITH THE\n     * SCHEDULER SUSPENDED AND THE QUEUE BEING ACCESSED LOCKED. */\n\n    /* Place the event list item of the TCB in the appropriate event list.\n     * This is placed in the list in priority order so the highest priority task\n     * is the first to be woken by the event.\n     *\n     * Note: Lists are sorted in ascending order by ListItem_t.xItemValue.\n     * Normally, the xItemValue of a TCB's ListItem_t members is:\n     *      xItemValue = ( configMAX_PRIORITIES - uxPriority )\n     * Therefore, the event list is sorted in descending priority order.\n     *\n     * The queue that contains the event list is locked, preventing\n     * simultaneous access from interrupts. */\n    vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );\n\n    prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );\n\n    traceRETURN_vTaskPlaceOnEventList();\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskPlaceOnUnorderedEventList( List_t * pxEventList,\n                                     const TickType_t xItemValue,\n                                     const TickType_t xTicksToWait )\n{\n    traceENTER_vTaskPlaceOnUnorderedEventList( pxEventList, xItemValue, xTicksToWait );\n\n    configASSERT( pxEventList );\n\n    /* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by\n     * the event groups implementation. */\n    configASSERT( uxSchedulerSuspended != ( UBaseType_t ) 0U );\n\n    /* Store the item value in the event list item.  It is safe to access the\n     * event list item here as interrupts won't access the event list item of a\n     * task that is not in the Blocked state. */\n    listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );\n\n    /* Place the event list item of the TCB at the end of the appropriate event\n     * list.  It is safe to access the event list here because it is part of an\n     * event group implementation - and interrupts don't access event groups\n     * directly (instead they access them indirectly by pending function calls to\n     * the task level). */\n    listINSERT_END( pxEventList, &( pxCurrentTCB->xEventListItem ) );\n\n    prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );\n\n    traceRETURN_vTaskPlaceOnUnorderedEventList();\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TIMERS == 1 )\n\n    void vTaskPlaceOnEventListRestricted( List_t * const pxEventList,\n                                          TickType_t xTicksToWait,\n                                          const BaseType_t xWaitIndefinitely )\n    {\n        traceENTER_vTaskPlaceOnEventListRestricted( pxEventList, xTicksToWait, xWaitIndefinitely );\n\n        configASSERT( pxEventList );\n\n        /* This function should not be called by application code hence the\n         * 'Restricted' in its name.  It is not part of the public API.  It is\n         * designed for use by kernel code, and has special calling requirements -\n         * it should be called with the scheduler suspended. */\n\n\n        /* Place the event list item of the TCB in the appropriate event list.\n         * In this case it is assume that this is the only task that is going to\n         * be waiting on this event list, so the faster vListInsertEnd() function\n         * can be used in place of vListInsert. */\n        listINSERT_END( pxEventList, &( pxCurrentTCB->xEventListItem ) );\n\n        /* If the task should block indefinitely then set the block time to a\n         * value that will be recognised as an indefinite delay inside the\n         * prvAddCurrentTaskToDelayedList() function. */\n        if( xWaitIndefinitely != pdFALSE )\n        {\n            xTicksToWait = portMAX_DELAY;\n        }\n\n        traceTASK_DELAY_UNTIL( ( xTickCount + xTicksToWait ) );\n        prvAddCurrentTaskToDelayedList( xTicksToWait, xWaitIndefinitely );\n\n        traceRETURN_vTaskPlaceOnEventListRestricted();\n    }\n\n#endif /* configUSE_TIMERS */\n/*-----------------------------------------------------------*/\n\nBaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )\n{\n    TCB_t * pxUnblockedTCB;\n    BaseType_t xReturn;\n\n    traceENTER_xTaskRemoveFromEventList( pxEventList );\n\n    /* THIS FUNCTION MUST BE CALLED FROM A CRITICAL SECTION.  It can also be\n     * called from a critical section within an ISR. */\n\n    /* The event list is sorted in priority order, so the first in the list can\n     * be removed as it is known to be the highest priority.  Remove the TCB from\n     * the delayed list, and add it to the ready list.\n     *\n     * If an event is for a queue that is locked then this function will never\n     * get called - the lock count on the queue will get modified instead.  This\n     * means exclusive access to the event list is guaranteed here.\n     *\n     * This function assumes that a check has already been made to ensure that\n     * pxEventList is not empty. */\n    /* MISRA Ref 11.5.3 [Void pointer assignment] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n    /* coverity[misra_c_2012_rule_11_5_violation] */\n    pxUnblockedTCB = listGET_OWNER_OF_HEAD_ENTRY( pxEventList );\n    configASSERT( pxUnblockedTCB );\n    listREMOVE_ITEM( &( pxUnblockedTCB->xEventListItem ) );\n\n    if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n    {\n        listREMOVE_ITEM( &( pxUnblockedTCB->xStateListItem ) );\n        prvAddTaskToReadyList( pxUnblockedTCB );\n\n        #if ( configUSE_TICKLESS_IDLE != 0 )\n        {\n            /* If a task is blocked on a kernel object then xNextTaskUnblockTime\n             * might be set to the blocked task's time out time.  If the task is\n             * unblocked for a reason other than a timeout xNextTaskUnblockTime is\n             * normally left unchanged, because it is automatically reset to a new\n             * value when the tick count equals xNextTaskUnblockTime.  However if\n             * tickless idling is used it might be more important to enter sleep mode\n             * at the earliest possible time - so reset xNextTaskUnblockTime here to\n             * ensure it is updated at the earliest possible time. */\n            prvResetNextTaskUnblockTime();\n        }\n        #endif\n    }\n    else\n    {\n        /* The delayed and ready lists cannot be accessed, so hold this task\n         * pending until the scheduler is resumed. */\n        listINSERT_END( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );\n    }\n\n    #if ( configNUMBER_OF_CORES == 1 )\n    {\n        if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )\n        {\n            /* Return true if the task removed from the event list has a higher\n             * priority than the calling task.  This allows the calling task to know if\n             * it should force a context switch now. */\n            xReturn = pdTRUE;\n\n            /* Mark that a yield is pending in case the user is not using the\n             * \"xHigherPriorityTaskWoken\" parameter to an ISR safe FreeRTOS function. */\n            xYieldPendings[ 0 ] = pdTRUE;\n        }\n        else\n        {\n            xReturn = pdFALSE;\n        }\n    }\n    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n    {\n        xReturn = pdFALSE;\n\n        #if ( configUSE_PREEMPTION == 1 )\n        {\n            prvYieldForTask( pxUnblockedTCB );\n\n            if( xYieldPendings[ portGET_CORE_ID() ] != pdFALSE )\n            {\n                xReturn = pdTRUE;\n            }\n        }\n        #endif /* #if ( configUSE_PREEMPTION == 1 ) */\n    }\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    traceRETURN_xTaskRemoveFromEventList( xReturn );\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem,\n                                        const TickType_t xItemValue )\n{\n    TCB_t * pxUnblockedTCB;\n\n    traceENTER_vTaskRemoveFromUnorderedEventList( pxEventListItem, xItemValue );\n\n    /* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by\n     * the event flags implementation. */\n    configASSERT( uxSchedulerSuspended != ( UBaseType_t ) 0U );\n\n    /* Store the new item value in the event list. */\n    listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );\n\n    /* Remove the event list form the event flag.  Interrupts do not access\n     * event flags. */\n    /* MISRA Ref 11.5.3 [Void pointer assignment] */\n    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n    /* coverity[misra_c_2012_rule_11_5_violation] */\n    pxUnblockedTCB = listGET_LIST_ITEM_OWNER( pxEventListItem );\n    configASSERT( pxUnblockedTCB );\n    listREMOVE_ITEM( pxEventListItem );\n\n    #if ( configUSE_TICKLESS_IDLE != 0 )\n    {\n        /* If a task is blocked on a kernel object then xNextTaskUnblockTime\n         * might be set to the blocked task's time out time.  If the task is\n         * unblocked for a reason other than a timeout xNextTaskUnblockTime is\n         * normally left unchanged, because it is automatically reset to a new\n         * value when the tick count equals xNextTaskUnblockTime.  However if\n         * tickless idling is used it might be more important to enter sleep mode\n         * at the earliest possible time - so reset xNextTaskUnblockTime here to\n         * ensure it is updated at the earliest possible time. */\n        prvResetNextTaskUnblockTime();\n    }\n    #endif\n\n    /* Remove the task from the delayed list and add it to the ready list.  The\n     * scheduler is suspended so interrupts will not be accessing the ready\n     * lists. */\n    listREMOVE_ITEM( &( pxUnblockedTCB->xStateListItem ) );\n    prvAddTaskToReadyList( pxUnblockedTCB );\n\n    #if ( configNUMBER_OF_CORES == 1 )\n    {\n        if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )\n        {\n            /* The unblocked task has a priority above that of the calling task, so\n             * a context switch is required.  This function is called with the\n             * scheduler suspended so xYieldPending is set so the context switch\n             * occurs immediately that the scheduler is resumed (unsuspended). */\n            xYieldPendings[ 0 ] = pdTRUE;\n        }\n    }\n    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n    {\n        #if ( configUSE_PREEMPTION == 1 )\n        {\n            taskENTER_CRITICAL();\n            {\n                prvYieldForTask( pxUnblockedTCB );\n            }\n            taskEXIT_CRITICAL();\n        }\n        #endif\n    }\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    traceRETURN_vTaskRemoveFromUnorderedEventList();\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )\n{\n    traceENTER_vTaskSetTimeOutState( pxTimeOut );\n\n    configASSERT( pxTimeOut );\n    taskENTER_CRITICAL();\n    {\n        pxTimeOut->xOverflowCount = xNumOfOverflows;\n        pxTimeOut->xTimeOnEntering = xTickCount;\n    }\n    taskEXIT_CRITICAL();\n\n    traceRETURN_vTaskSetTimeOutState();\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskInternalSetTimeOutState( TimeOut_t * const pxTimeOut )\n{\n    traceENTER_vTaskInternalSetTimeOutState( pxTimeOut );\n\n    /* For internal use only as it does not use a critical section. */\n    pxTimeOut->xOverflowCount = xNumOfOverflows;\n    pxTimeOut->xTimeOnEntering = xTickCount;\n\n    traceRETURN_vTaskInternalSetTimeOutState();\n}\n/*-----------------------------------------------------------*/\n\nBaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut,\n                                 TickType_t * const pxTicksToWait )\n{\n    BaseType_t xReturn;\n\n    traceENTER_xTaskCheckForTimeOut( pxTimeOut, pxTicksToWait );\n\n    configASSERT( pxTimeOut );\n    configASSERT( pxTicksToWait );\n\n    taskENTER_CRITICAL();\n    {\n        /* Minor optimisation.  The tick count cannot change in this block. */\n        const TickType_t xConstTickCount = xTickCount;\n        const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;\n\n        #if ( INCLUDE_xTaskAbortDelay == 1 )\n            if( pxCurrentTCB->ucDelayAborted != ( uint8_t ) pdFALSE )\n            {\n                /* The delay was aborted, which is not the same as a time out,\n                 * but has the same result. */\n                pxCurrentTCB->ucDelayAborted = ( uint8_t ) pdFALSE;\n                xReturn = pdTRUE;\n            }\n            else\n        #endif\n\n        #if ( INCLUDE_vTaskSuspend == 1 )\n            if( *pxTicksToWait == portMAX_DELAY )\n            {\n                /* If INCLUDE_vTaskSuspend is set to 1 and the block time\n                 * specified is the maximum block time then the task should block\n                 * indefinitely, and therefore never time out. */\n                xReturn = pdFALSE;\n            }\n            else\n        #endif\n\n        if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) )\n        {\n            /* The tick count is greater than the time at which\n             * vTaskSetTimeout() was called, but has also overflowed since\n             * vTaskSetTimeOut() was called.  It must have wrapped all the way\n             * around and gone past again. This passed since vTaskSetTimeout()\n             * was called. */\n            xReturn = pdTRUE;\n            *pxTicksToWait = ( TickType_t ) 0;\n        }\n        else if( xElapsedTime < *pxTicksToWait )\n        {\n            /* Not a genuine timeout. Adjust parameters for time remaining. */\n            *pxTicksToWait -= xElapsedTime;\n            vTaskInternalSetTimeOutState( pxTimeOut );\n            xReturn = pdFALSE;\n        }\n        else\n        {\n            *pxTicksToWait = ( TickType_t ) 0;\n            xReturn = pdTRUE;\n        }\n    }\n    taskEXIT_CRITICAL();\n\n    traceRETURN_xTaskCheckForTimeOut( xReturn );\n\n    return xReturn;\n}\n/*-----------------------------------------------------------*/\n\nvoid vTaskMissedYield( void )\n{\n    traceENTER_vTaskMissedYield();\n\n    /* Must be called from within a critical section. */\n    xYieldPendings[ portGET_CORE_ID() ] = pdTRUE;\n\n    traceRETURN_vTaskMissedYield();\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    UBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask )\n    {\n        UBaseType_t uxReturn;\n        TCB_t const * pxTCB;\n\n        traceENTER_uxTaskGetTaskNumber( xTask );\n\n        if( xTask != NULL )\n        {\n            pxTCB = xTask;\n            uxReturn = pxTCB->uxTaskNumber;\n        }\n        else\n        {\n            uxReturn = 0U;\n        }\n\n        traceRETURN_uxTaskGetTaskNumber( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    void vTaskSetTaskNumber( TaskHandle_t xTask,\n                             const UBaseType_t uxHandle )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskSetTaskNumber( xTask, uxHandle );\n\n        if( xTask != NULL )\n        {\n            pxTCB = xTask;\n            pxTCB->uxTaskNumber = uxHandle;\n        }\n\n        traceRETURN_vTaskSetTaskNumber();\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n/*\n * -----------------------------------------------------------\n * The passive idle task.\n * ----------------------------------------------------------\n *\n * The passive idle task is used for all the additional cores in a SMP\n * system. There must be only 1 active idle task and the rest are passive\n * idle tasks.\n *\n * The portTASK_FUNCTION() macro is used to allow port/compiler specific\n * language extensions.  The equivalent prototype for this function is:\n *\n * void prvPassiveIdleTask( void *pvParameters );\n */\n\n#if ( configNUMBER_OF_CORES > 1 )\n    static portTASK_FUNCTION( prvPassiveIdleTask, pvParameters )\n    {\n        ( void ) pvParameters;\n\n        taskYIELD();\n\n        for( ; configCONTROL_INFINITE_LOOP(); )\n        {\n            #if ( configUSE_PREEMPTION == 0 )\n            {\n                /* If we are not using preemption we keep forcing a task switch to\n                 * see if any other task has become available.  If we are using\n                 * preemption we don't need to do this as any task becoming available\n                 * will automatically get the processor anyway. */\n                taskYIELD();\n            }\n            #endif /* configUSE_PREEMPTION */\n\n            #if ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) )\n            {\n                /* When using preemption tasks of equal priority will be\n                 * timesliced.  If a task that is sharing the idle priority is ready\n                 * to run then the idle task should yield before the end of the\n                 * timeslice.\n                 *\n                 * A critical region is not required here as we are just reading from\n                 * the list, and an occasional incorrect value will not matter.  If\n                 * the ready list at the idle priority contains one more task than the\n                 * number of idle tasks, which is equal to the configured numbers of cores\n                 * then a task other than the idle task is ready to execute. */\n                if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) configNUMBER_OF_CORES )\n                {\n                    taskYIELD();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            #endif /* ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) ) */\n\n            #if ( configUSE_PASSIVE_IDLE_HOOK == 1 )\n            {\n                /* Call the user defined function from within the idle task.  This\n                 * allows the application designer to add background functionality\n                 * without the overhead of a separate task.\n                 *\n                 * This hook is intended to manage core activity such as disabling cores that go idle.\n                 *\n                 * NOTE: vApplicationPassiveIdleHook() MUST NOT, UNDER ANY CIRCUMSTANCES,\n                 * CALL A FUNCTION THAT MIGHT BLOCK. */\n                vApplicationPassiveIdleHook();\n            }\n            #endif /* configUSE_PASSIVE_IDLE_HOOK */\n        }\n    }\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n/*\n * -----------------------------------------------------------\n * The idle task.\n * ----------------------------------------------------------\n *\n * The portTASK_FUNCTION() macro is used to allow port/compiler specific\n * language extensions.  The equivalent prototype for this function is:\n *\n * void prvIdleTask( void *pvParameters );\n *\n */\n\nstatic portTASK_FUNCTION( prvIdleTask, pvParameters )\n{\n    /* Stop warnings. */\n    ( void ) pvParameters;\n\n    /** THIS IS THE RTOS IDLE TASK - WHICH IS CREATED AUTOMATICALLY WHEN THE\n     * SCHEDULER IS STARTED. **/\n\n    /* In case a task that has a secure context deletes itself, in which case\n     * the idle task is responsible for deleting the task's secure context, if\n     * any. */\n    portALLOCATE_SECURE_CONTEXT( configMINIMAL_SECURE_STACK_SIZE );\n\n    #if ( configNUMBER_OF_CORES > 1 )\n    {\n        /* SMP all cores start up in the idle task. This initial yield gets the application\n         * tasks started. */\n        taskYIELD();\n    }\n    #endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n    for( ; configCONTROL_INFINITE_LOOP(); )\n    {\n        /* See if any tasks have deleted themselves - if so then the idle task\n         * is responsible for freeing the deleted task's TCB and stack. */\n        prvCheckTasksWaitingTermination();\n\n        #if ( configUSE_PREEMPTION == 0 )\n        {\n            /* If we are not using preemption we keep forcing a task switch to\n             * see if any other task has become available.  If we are using\n             * preemption we don't need to do this as any task becoming available\n             * will automatically get the processor anyway. */\n            taskYIELD();\n        }\n        #endif /* configUSE_PREEMPTION */\n\n        #if ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) )\n        {\n            /* When using preemption tasks of equal priority will be\n             * timesliced.  If a task that is sharing the idle priority is ready\n             * to run then the idle task should yield before the end of the\n             * timeslice.\n             *\n             * A critical region is not required here as we are just reading from\n             * the list, and an occasional incorrect value will not matter.  If\n             * the ready list at the idle priority contains one more task than the\n             * number of idle tasks, which is equal to the configured numbers of cores\n             * then a task other than the idle task is ready to execute. */\n            if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) configNUMBER_OF_CORES )\n            {\n                taskYIELD();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) ) */\n\n        #if ( configUSE_IDLE_HOOK == 1 )\n        {\n            /* Call the user defined function from within the idle task. */\n            vApplicationIdleHook();\n        }\n        #endif /* configUSE_IDLE_HOOK */\n\n        /* This conditional compilation should use inequality to 0, not equality\n         * to 1.  This is to ensure portSUPPRESS_TICKS_AND_SLEEP() is called when\n         * user defined low power mode  implementations require\n         * configUSE_TICKLESS_IDLE to be set to a value other than 1. */\n        #if ( configUSE_TICKLESS_IDLE != 0 )\n        {\n            TickType_t xExpectedIdleTime;\n\n            /* It is not desirable to suspend then resume the scheduler on\n             * each iteration of the idle task.  Therefore, a preliminary\n             * test of the expected idle time is performed without the\n             * scheduler suspended.  The result here is not necessarily\n             * valid. */\n            xExpectedIdleTime = prvGetExpectedIdleTime();\n\n            if( xExpectedIdleTime >= ( TickType_t ) configEXPECTED_IDLE_TIME_BEFORE_SLEEP )\n            {\n                vTaskSuspendAll();\n                {\n                    /* Now the scheduler is suspended, the expected idle\n                     * time can be sampled again, and this time its value can\n                     * be used. */\n                    configASSERT( xNextTaskUnblockTime >= xTickCount );\n                    xExpectedIdleTime = prvGetExpectedIdleTime();\n\n                    /* Define the following macro to set xExpectedIdleTime to 0\n                     * if the application does not want\n                     * portSUPPRESS_TICKS_AND_SLEEP() to be called. */\n                    configPRE_SUPPRESS_TICKS_AND_SLEEP_PROCESSING( xExpectedIdleTime );\n\n                    if( xExpectedIdleTime >= ( TickType_t ) configEXPECTED_IDLE_TIME_BEFORE_SLEEP )\n                    {\n                        traceLOW_POWER_IDLE_BEGIN();\n                        portSUPPRESS_TICKS_AND_SLEEP( xExpectedIdleTime );\n                        traceLOW_POWER_IDLE_END();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                ( void ) xTaskResumeAll();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* configUSE_TICKLESS_IDLE */\n\n        #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_PASSIVE_IDLE_HOOK == 1 ) )\n        {\n            /* Call the user defined function from within the idle task.  This\n             * allows the application designer to add background functionality\n             * without the overhead of a separate task.\n             *\n             * This hook is intended to manage core activity such as disabling cores that go idle.\n             *\n             * NOTE: vApplicationPassiveIdleHook() MUST NOT, UNDER ANY CIRCUMSTANCES,\n             * CALL A FUNCTION THAT MIGHT BLOCK. */\n            vApplicationPassiveIdleHook();\n        }\n        #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_PASSIVE_IDLE_HOOK == 1 ) ) */\n    }\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TICKLESS_IDLE != 0 )\n\n    eSleepModeStatus eTaskConfirmSleepModeStatus( void )\n    {\n        #if ( INCLUDE_vTaskSuspend == 1 )\n            /* The idle task exists in addition to the application tasks. */\n            const UBaseType_t uxNonApplicationTasks = configNUMBER_OF_CORES;\n        #endif /* INCLUDE_vTaskSuspend */\n\n        eSleepModeStatus eReturn = eStandardSleep;\n\n        traceENTER_eTaskConfirmSleepModeStatus();\n\n        /* This function must be called from a critical section. */\n\n        if( listCURRENT_LIST_LENGTH( &xPendingReadyList ) != 0U )\n        {\n            /* A task was made ready while the scheduler was suspended. */\n            eReturn = eAbortSleep;\n        }\n        else if( xYieldPendings[ portGET_CORE_ID() ] != pdFALSE )\n        {\n            /* A yield was pended while the scheduler was suspended. */\n            eReturn = eAbortSleep;\n        }\n        else if( xPendedTicks != 0U )\n        {\n            /* A tick interrupt has already occurred but was held pending\n             * because the scheduler is suspended. */\n            eReturn = eAbortSleep;\n        }\n\n        #if ( INCLUDE_vTaskSuspend == 1 )\n            else if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == ( uxCurrentNumberOfTasks - uxNonApplicationTasks ) )\n            {\n                /* If all the tasks are in the suspended list (which might mean they\n                 * have an infinite block time rather than actually being suspended)\n                 * then it is safe to turn all clocks off and just wait for external\n                 * interrupts. */\n                eReturn = eNoTasksWaitingTimeout;\n            }\n        #endif /* INCLUDE_vTaskSuspend */\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_eTaskConfirmSleepModeStatus( eReturn );\n\n        return eReturn;\n    }\n\n#endif /* configUSE_TICKLESS_IDLE */\n/*-----------------------------------------------------------*/\n\n#if ( configNUM_THREAD_LOCAL_STORAGE_POINTERS != 0 )\n\n    void vTaskSetThreadLocalStoragePointer( TaskHandle_t xTaskToSet,\n                                            BaseType_t xIndex,\n                                            void * pvValue )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskSetThreadLocalStoragePointer( xTaskToSet, xIndex, pvValue );\n\n        if( ( xIndex >= 0 ) &&\n            ( xIndex < ( BaseType_t ) configNUM_THREAD_LOCAL_STORAGE_POINTERS ) )\n        {\n            pxTCB = prvGetTCBFromHandle( xTaskToSet );\n            configASSERT( pxTCB != NULL );\n            pxTCB->pvThreadLocalStoragePointers[ xIndex ] = pvValue;\n        }\n\n        traceRETURN_vTaskSetThreadLocalStoragePointer();\n    }\n\n#endif /* configNUM_THREAD_LOCAL_STORAGE_POINTERS */\n/*-----------------------------------------------------------*/\n\n#if ( configNUM_THREAD_LOCAL_STORAGE_POINTERS != 0 )\n\n    void * pvTaskGetThreadLocalStoragePointer( TaskHandle_t xTaskToQuery,\n                                               BaseType_t xIndex )\n    {\n        void * pvReturn = NULL;\n        TCB_t * pxTCB;\n\n        traceENTER_pvTaskGetThreadLocalStoragePointer( xTaskToQuery, xIndex );\n\n        if( ( xIndex >= 0 ) &&\n            ( xIndex < ( BaseType_t ) configNUM_THREAD_LOCAL_STORAGE_POINTERS ) )\n        {\n            pxTCB = prvGetTCBFromHandle( xTaskToQuery );\n            configASSERT( pxTCB != NULL );\n\n            pvReturn = pxTCB->pvThreadLocalStoragePointers[ xIndex ];\n        }\n        else\n        {\n            pvReturn = NULL;\n        }\n\n        traceRETURN_pvTaskGetThreadLocalStoragePointer( pvReturn );\n\n        return pvReturn;\n    }\n\n#endif /* configNUM_THREAD_LOCAL_STORAGE_POINTERS */\n/*-----------------------------------------------------------*/\n\n#if ( portUSING_MPU_WRAPPERS == 1 )\n\n    void vTaskAllocateMPURegions( TaskHandle_t xTaskToModify,\n                                  const MemoryRegion_t * const pxRegions )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskAllocateMPURegions( xTaskToModify, pxRegions );\n\n        /* If null is passed in here then we are modifying the MPU settings of\n         * the calling task. */\n        pxTCB = prvGetTCBFromHandle( xTaskToModify );\n        configASSERT( pxTCB != NULL );\n\n        vPortStoreTaskMPUSettings( &( pxTCB->xMPUSettings ), pxRegions, NULL, 0 );\n\n        traceRETURN_vTaskAllocateMPURegions();\n    }\n\n#endif /* portUSING_MPU_WRAPPERS */\n/*-----------------------------------------------------------*/\n\nstatic void prvInitialiseTaskLists( void )\n{\n    UBaseType_t uxPriority;\n\n    for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )\n    {\n        vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );\n    }\n\n    vListInitialise( &xDelayedTaskList1 );\n    vListInitialise( &xDelayedTaskList2 );\n    vListInitialise( &xPendingReadyList );\n\n    #if ( INCLUDE_vTaskDelete == 1 )\n    {\n        vListInitialise( &xTasksWaitingTermination );\n    }\n    #endif /* INCLUDE_vTaskDelete */\n\n    #if ( INCLUDE_vTaskSuspend == 1 )\n    {\n        vListInitialise( &xSuspendedTaskList );\n    }\n    #endif /* INCLUDE_vTaskSuspend */\n\n    /* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList\n     * using list2. */\n    pxDelayedTaskList = &xDelayedTaskList1;\n    pxOverflowDelayedTaskList = &xDelayedTaskList2;\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvCheckTasksWaitingTermination( void )\n{\n    /** THIS FUNCTION IS CALLED FROM THE RTOS IDLE TASK **/\n\n    #if ( INCLUDE_vTaskDelete == 1 )\n    {\n        TCB_t * pxTCB;\n\n        /* uxDeletedTasksWaitingCleanUp is used to prevent taskENTER_CRITICAL()\n         * being called too often in the idle task. */\n        while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )\n        {\n            #if ( configNUMBER_OF_CORES == 1 )\n            {\n                taskENTER_CRITICAL();\n                {\n                    {\n                        /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                        /* coverity[misra_c_2012_rule_11_5_violation] */\n                        pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );\n                        ( void ) uxListRemove( &( pxTCB->xStateListItem ) );\n                        --uxCurrentNumberOfTasks;\n                        --uxDeletedTasksWaitingCleanUp;\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                prvDeleteTCB( pxTCB );\n            }\n            #else /* #if( configNUMBER_OF_CORES == 1 ) */\n            {\n                pxTCB = NULL;\n\n                taskENTER_CRITICAL();\n                {\n                    /* For SMP, multiple idles can be running simultaneously\n                     * and we need to check that other idles did not cleanup while we were\n                     * waiting to enter the critical section. */\n                    if( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )\n                    {\n                        /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                        /* coverity[misra_c_2012_rule_11_5_violation] */\n                        pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );\n\n                        if( pxTCB->xTaskRunState == taskTASK_NOT_RUNNING )\n                        {\n                            ( void ) uxListRemove( &( pxTCB->xStateListItem ) );\n                            --uxCurrentNumberOfTasks;\n                            --uxDeletedTasksWaitingCleanUp;\n                        }\n                        else\n                        {\n                            /* The TCB to be deleted still has not yet been switched out\n                             * by the scheduler, so we will just exit this loop early and\n                             * try again next time. */\n                            taskEXIT_CRITICAL();\n                            break;\n                        }\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                if( pxTCB != NULL )\n                {\n                    prvDeleteTCB( pxTCB );\n                }\n            }\n            #endif /* #if( configNUMBER_OF_CORES == 1 ) */\n        }\n    }\n    #endif /* INCLUDE_vTaskDelete */\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    void vTaskGetInfo( TaskHandle_t xTask,\n                       TaskStatus_t * pxTaskStatus,\n                       BaseType_t xGetFreeStackSpace,\n                       eTaskState eState )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_vTaskGetInfo( xTask, pxTaskStatus, xGetFreeStackSpace, eState );\n\n        /* xTask is NULL then get the state of the calling task. */\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        pxTaskStatus->xHandle = pxTCB;\n        pxTaskStatus->pcTaskName = ( const char * ) &( pxTCB->pcTaskName[ 0 ] );\n        pxTaskStatus->uxCurrentPriority = pxTCB->uxPriority;\n        pxTaskStatus->pxStackBase = pxTCB->pxStack;\n        #if ( ( portSTACK_GROWTH > 0 ) || ( configRECORD_STACK_HIGH_ADDRESS == 1 ) )\n            pxTaskStatus->pxTopOfStack = ( StackType_t * ) pxTCB->pxTopOfStack;\n            pxTaskStatus->pxEndOfStack = pxTCB->pxEndOfStack;\n        #endif\n        pxTaskStatus->xTaskNumber = pxTCB->uxTCBNumber;\n\n        #if ( ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 ) )\n        {\n            pxTaskStatus->uxCoreAffinityMask = pxTCB->uxCoreAffinityMask;\n        }\n        #endif\n\n        #if ( configUSE_MUTEXES == 1 )\n        {\n            pxTaskStatus->uxBasePriority = pxTCB->uxBasePriority;\n        }\n        #else\n        {\n            pxTaskStatus->uxBasePriority = 0;\n        }\n        #endif\n\n        #if ( configGENERATE_RUN_TIME_STATS == 1 )\n        {\n            pxTaskStatus->ulRunTimeCounter = pxTCB->ulRunTimeCounter;\n        }\n        #else\n        {\n            pxTaskStatus->ulRunTimeCounter = ( configRUN_TIME_COUNTER_TYPE ) 0;\n        }\n        #endif\n\n        /* Obtaining the task state is a little fiddly, so is only done if the\n         * value of eState passed into this function is eInvalid - otherwise the\n         * state is just set to whatever is passed in. */\n        if( eState != eInvalid )\n        {\n            if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n            {\n                pxTaskStatus->eCurrentState = eRunning;\n            }\n            else\n            {\n                pxTaskStatus->eCurrentState = eState;\n\n                #if ( INCLUDE_vTaskSuspend == 1 )\n                {\n                    /* If the task is in the suspended list then there is a\n                     *  chance it is actually just blocked indefinitely - so really\n                     *  it should be reported as being in the Blocked state. */\n                    if( eState == eSuspended )\n                    {\n                        vTaskSuspendAll();\n                        {\n                            if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )\n                            {\n                                pxTaskStatus->eCurrentState = eBlocked;\n                            }\n                            else\n                            {\n                                #if ( configUSE_TASK_NOTIFICATIONS == 1 )\n                                {\n                                    BaseType_t x;\n\n                                    /* The task does not appear on the event list item of\n                                     * and of the RTOS objects, but could still be in the\n                                     * blocked state if it is waiting on its notification\n                                     * rather than waiting on an object.  If not, is\n                                     * suspended. */\n                                    for( x = ( BaseType_t ) 0; x < ( BaseType_t ) configTASK_NOTIFICATION_ARRAY_ENTRIES; x++ )\n                                    {\n                                        if( pxTCB->ucNotifyState[ x ] == taskWAITING_NOTIFICATION )\n                                        {\n                                            pxTaskStatus->eCurrentState = eBlocked;\n                                            break;\n                                        }\n                                    }\n                                }\n                                #endif /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */\n                            }\n                        }\n                        ( void ) xTaskResumeAll();\n                    }\n                }\n                #endif /* INCLUDE_vTaskSuspend */\n\n                /* Tasks can be in pending ready list and other state list at the\n                 * same time. These tasks are in ready state no matter what state\n                 * list the task is in. */\n                taskENTER_CRITICAL();\n                {\n                    if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) != pdFALSE )\n                    {\n                        pxTaskStatus->eCurrentState = eReady;\n                    }\n                }\n                taskEXIT_CRITICAL();\n            }\n        }\n        else\n        {\n            pxTaskStatus->eCurrentState = eTaskGetState( pxTCB );\n        }\n\n        /* Obtaining the stack space takes some time, so the xGetFreeStackSpace\n         * parameter is provided to allow it to be skipped. */\n        if( xGetFreeStackSpace != pdFALSE )\n        {\n            #if ( portSTACK_GROWTH > 0 )\n            {\n                pxTaskStatus->usStackHighWaterMark = prvTaskCheckFreeStackSpace( ( uint8_t * ) pxTCB->pxEndOfStack );\n            }\n            #else\n            {\n                pxTaskStatus->usStackHighWaterMark = prvTaskCheckFreeStackSpace( ( uint8_t * ) pxTCB->pxStack );\n            }\n            #endif\n        }\n        else\n        {\n            pxTaskStatus->usStackHighWaterMark = 0;\n        }\n\n        traceRETURN_vTaskGetInfo();\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TRACE_FACILITY == 1 )\n\n    static UBaseType_t prvListTasksWithinSingleList( TaskStatus_t * pxTaskStatusArray,\n                                                     List_t * pxList,\n                                                     eTaskState eState )\n    {\n        UBaseType_t uxTask = 0;\n        const ListItem_t * pxEndMarker = listGET_END_MARKER( pxList );\n        ListItem_t * pxIterator;\n        TCB_t * pxTCB = NULL;\n\n        if( listCURRENT_LIST_LENGTH( pxList ) > ( UBaseType_t ) 0 )\n        {\n            /* Populate an TaskStatus_t structure within the\n             * pxTaskStatusArray array for each task that is referenced from\n             * pxList.  See the definition of TaskStatus_t in task.h for the\n             * meaning of each TaskStatus_t structure member. */\n            for( pxIterator = listGET_HEAD_ENTRY( pxList ); pxIterator != pxEndMarker; pxIterator = listGET_NEXT( pxIterator ) )\n            {\n                /* MISRA Ref 11.5.3 [Void pointer assignment] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n                /* coverity[misra_c_2012_rule_11_5_violation] */\n                pxTCB = listGET_LIST_ITEM_OWNER( pxIterator );\n\n                vTaskGetInfo( ( TaskHandle_t ) pxTCB, &( pxTaskStatusArray[ uxTask ] ), pdTRUE, eState );\n                uxTask++;\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        return uxTask;\n    }\n\n#endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark2 == 1 ) )\n\n    static configSTACK_DEPTH_TYPE prvTaskCheckFreeStackSpace( const uint8_t * pucStackByte )\n    {\n        configSTACK_DEPTH_TYPE uxCount = 0U;\n\n        while( *pucStackByte == ( uint8_t ) tskSTACK_FILL_BYTE )\n        {\n            pucStackByte -= portSTACK_GROWTH;\n            uxCount++;\n        }\n\n        uxCount /= ( configSTACK_DEPTH_TYPE ) sizeof( StackType_t );\n\n        return uxCount;\n    }\n\n#endif /* ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark2 == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_uxTaskGetStackHighWaterMark2 == 1 )\n\n/* uxTaskGetStackHighWaterMark() and uxTaskGetStackHighWaterMark2() are the\n * same except for their return type.  Using configSTACK_DEPTH_TYPE allows the\n * user to determine the return type.  It gets around the problem of the value\n * overflowing on 8-bit types without breaking backward compatibility for\n * applications that expect an 8-bit return type. */\n    configSTACK_DEPTH_TYPE uxTaskGetStackHighWaterMark2( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        uint8_t * pucEndOfStack;\n        configSTACK_DEPTH_TYPE uxReturn;\n\n        traceENTER_uxTaskGetStackHighWaterMark2( xTask );\n\n        /* uxTaskGetStackHighWaterMark() and uxTaskGetStackHighWaterMark2() are\n         * the same except for their return type.  Using configSTACK_DEPTH_TYPE\n         * allows the user to determine the return type.  It gets around the\n         * problem of the value overflowing on 8-bit types without breaking\n         * backward compatibility for applications that expect an 8-bit return\n         * type. */\n\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        #if portSTACK_GROWTH < 0\n        {\n            pucEndOfStack = ( uint8_t * ) pxTCB->pxStack;\n        }\n        #else\n        {\n            pucEndOfStack = ( uint8_t * ) pxTCB->pxEndOfStack;\n        }\n        #endif\n\n        uxReturn = prvTaskCheckFreeStackSpace( pucEndOfStack );\n\n        traceRETURN_uxTaskGetStackHighWaterMark2( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* INCLUDE_uxTaskGetStackHighWaterMark2 */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_uxTaskGetStackHighWaterMark == 1 )\n\n    UBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        uint8_t * pucEndOfStack;\n        UBaseType_t uxReturn;\n\n        traceENTER_uxTaskGetStackHighWaterMark( xTask );\n\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        #if portSTACK_GROWTH < 0\n        {\n            pucEndOfStack = ( uint8_t * ) pxTCB->pxStack;\n        }\n        #else\n        {\n            pucEndOfStack = ( uint8_t * ) pxTCB->pxEndOfStack;\n        }\n        #endif\n\n        uxReturn = ( UBaseType_t ) prvTaskCheckFreeStackSpace( pucEndOfStack );\n\n        traceRETURN_uxTaskGetStackHighWaterMark( uxReturn );\n\n        return uxReturn;\n    }\n\n#endif /* INCLUDE_uxTaskGetStackHighWaterMark */\n/*-----------------------------------------------------------*/\n\n#if ( INCLUDE_vTaskDelete == 1 )\n\n    static void prvDeleteTCB( TCB_t * pxTCB )\n    {\n        /* This call is required specifically for the TriCore port.  It must be\n         * above the vPortFree() calls.  The call is also used by ports/demos that\n         * want to allocate and clean RAM statically. */\n        portCLEAN_UP_TCB( pxTCB );\n\n        #if ( configUSE_C_RUNTIME_TLS_SUPPORT == 1 )\n        {\n            /* Free up the memory allocated for the task's TLS Block. */\n            configDEINIT_TLS_BLOCK( pxTCB->xTLSBlock );\n        }\n        #endif\n\n        #if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )\n        {\n            /* The task can only have been allocated dynamically - free both\n             * the stack and TCB. */\n            vPortFreeStack( pxTCB->pxStack );\n            vPortFree( pxTCB );\n        }\n        #elif ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )\n        {\n            /* The task could have been allocated statically or dynamically, so\n             * check what was statically allocated before trying to free the\n             * memory. */\n            if( pxTCB->ucStaticallyAllocated == tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB )\n            {\n                /* Both the stack and TCB were allocated dynamically, so both\n                 * must be freed. */\n                vPortFreeStack( pxTCB->pxStack );\n                vPortFree( pxTCB );\n            }\n            else if( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_ONLY )\n            {\n                /* Only the stack was statically allocated, so the TCB is the\n                 * only memory that must be freed. */\n                vPortFree( pxTCB );\n            }\n            else\n            {\n                /* Neither the stack nor the TCB were allocated dynamically, so\n                 * nothing needs to be freed. */\n                configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB );\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n    }\n\n#endif /* INCLUDE_vTaskDelete */\n/*-----------------------------------------------------------*/\n\nstatic void prvResetNextTaskUnblockTime( void )\n{\n    if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )\n    {\n        /* The new current delayed list is empty.  Set xNextTaskUnblockTime to\n         * the maximum possible value so it is  extremely unlikely that the\n         * if( xTickCount >= xNextTaskUnblockTime ) test will pass until\n         * there is an item in the delayed list. */\n        xNextTaskUnblockTime = portMAX_DELAY;\n    }\n    else\n    {\n        /* The new current delayed list is not empty, get the value of\n         * the item at the head of the delayed list.  This is the time at\n         * which the task at the head of the delayed list should be removed\n         * from the Blocked state. */\n        xNextTaskUnblockTime = listGET_ITEM_VALUE_OF_HEAD_ENTRY( pxDelayedTaskList );\n    }\n}\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_xTaskGetCurrentTaskHandle == 1 ) || ( configUSE_RECURSIVE_MUTEXES == 1 ) ) || ( configNUMBER_OF_CORES > 1 )\n\n    #if ( configNUMBER_OF_CORES == 1 )\n        TaskHandle_t xTaskGetCurrentTaskHandle( void )\n        {\n            TaskHandle_t xReturn;\n\n            traceENTER_xTaskGetCurrentTaskHandle();\n\n            /* A critical section is not required as this is not called from\n             * an interrupt and the current TCB will always be the same for any\n             * individual execution thread. */\n            xReturn = pxCurrentTCB;\n\n            traceRETURN_xTaskGetCurrentTaskHandle( xReturn );\n\n            return xReturn;\n        }\n    #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n        TaskHandle_t xTaskGetCurrentTaskHandle( void )\n        {\n            TaskHandle_t xReturn;\n            UBaseType_t uxSavedInterruptStatus;\n\n            traceENTER_xTaskGetCurrentTaskHandle();\n\n            uxSavedInterruptStatus = portSET_INTERRUPT_MASK();\n            {\n                xReturn = pxCurrentTCBs[ portGET_CORE_ID() ];\n            }\n            portCLEAR_INTERRUPT_MASK( uxSavedInterruptStatus );\n\n            traceRETURN_xTaskGetCurrentTaskHandle( xReturn );\n\n            return xReturn;\n        }\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    TaskHandle_t xTaskGetCurrentTaskHandleForCore( BaseType_t xCoreID )\n    {\n        TaskHandle_t xReturn = NULL;\n\n        traceENTER_xTaskGetCurrentTaskHandleForCore( xCoreID );\n\n        if( taskVALID_CORE_ID( xCoreID ) != pdFALSE )\n        {\n            #if ( configNUMBER_OF_CORES == 1 )\n                xReturn = pxCurrentTCB;\n            #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                xReturn = pxCurrentTCBs[ xCoreID ];\n            #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n        }\n\n        traceRETURN_xTaskGetCurrentTaskHandleForCore( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* ( ( INCLUDE_xTaskGetCurrentTaskHandle == 1 ) || ( configUSE_RECURSIVE_MUTEXES == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )\n\n    BaseType_t xTaskGetSchedulerState( void )\n    {\n        BaseType_t xReturn;\n\n        traceENTER_xTaskGetSchedulerState();\n\n        if( xSchedulerRunning == pdFALSE )\n        {\n            xReturn = taskSCHEDULER_NOT_STARTED;\n        }\n        else\n        {\n            #if ( configNUMBER_OF_CORES > 1 )\n                taskENTER_CRITICAL();\n            #endif\n            {\n                if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n                {\n                    xReturn = taskSCHEDULER_RUNNING;\n                }\n                else\n                {\n                    xReturn = taskSCHEDULER_SUSPENDED;\n                }\n            }\n            #if ( configNUMBER_OF_CORES > 1 )\n                taskEXIT_CRITICAL();\n            #endif\n        }\n\n        traceRETURN_xTaskGetSchedulerState( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    BaseType_t xTaskPriorityInherit( TaskHandle_t const pxMutexHolder )\n    {\n        TCB_t * const pxMutexHolderTCB = pxMutexHolder;\n        BaseType_t xReturn = pdFALSE;\n\n        traceENTER_xTaskPriorityInherit( pxMutexHolder );\n\n        /* If the mutex is taken by an interrupt, the mutex holder is NULL. Priority\n         * inheritance is not applied in this scenario. */\n        if( pxMutexHolder != NULL )\n        {\n            /* If the holder of the mutex has a priority below the priority of\n             * the task attempting to obtain the mutex then it will temporarily\n             * inherit the priority of the task attempting to obtain the mutex. */\n            if( pxMutexHolderTCB->uxPriority < pxCurrentTCB->uxPriority )\n            {\n                /* Adjust the mutex holder state to account for its new\n                 * priority.  Only reset the event list item value if the value is\n                 * not being used for anything else. */\n                if( ( listGET_LIST_ITEM_VALUE( &( pxMutexHolderTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == ( ( TickType_t ) 0U ) )\n                {\n                    listSET_LIST_ITEM_VALUE( &( pxMutexHolderTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                /* If the task being modified is in the ready state it will need\n                 * to be moved into a new list. */\n                if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxMutexHolderTCB->uxPriority ] ), &( pxMutexHolderTCB->xStateListItem ) ) != pdFALSE )\n                {\n                    if( uxListRemove( &( pxMutexHolderTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n                    {\n                        /* It is known that the task is in its ready list so\n                         * there is no need to check again and the port level\n                         * reset macro can be called directly. */\n                        portRESET_READY_PRIORITY( pxMutexHolderTCB->uxPriority, uxTopReadyPriority );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* Inherit the priority before being moved into the new list. */\n                    pxMutexHolderTCB->uxPriority = pxCurrentTCB->uxPriority;\n                    prvAddTaskToReadyList( pxMutexHolderTCB );\n                    #if ( configNUMBER_OF_CORES > 1 )\n                    {\n                        /* The priority of the task is raised. Yield for this task\n                         * if it is not running. */\n                        if( taskTASK_IS_RUNNING( pxMutexHolderTCB ) != pdTRUE )\n                        {\n                            prvYieldForTask( pxMutexHolderTCB );\n                        }\n                    }\n                    #endif /* if ( configNUMBER_OF_CORES > 1 ) */\n                }\n                else\n                {\n                    /* Just inherit the priority. */\n                    pxMutexHolderTCB->uxPriority = pxCurrentTCB->uxPriority;\n                }\n\n                traceTASK_PRIORITY_INHERIT( pxMutexHolderTCB, pxCurrentTCB->uxPriority );\n\n                /* Inheritance occurred. */\n                xReturn = pdTRUE;\n            }\n            else\n            {\n                if( pxMutexHolderTCB->uxBasePriority < pxCurrentTCB->uxPriority )\n                {\n                    /* The base priority of the mutex holder is lower than the\n                     * priority of the task attempting to take the mutex, but the\n                     * current priority of the mutex holder is not lower than the\n                     * priority of the task attempting to take the mutex.\n                     * Therefore the mutex holder must have already inherited a\n                     * priority, but inheritance would have occurred if that had\n                     * not been the case. */\n                    xReturn = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTaskPriorityInherit( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )\n    {\n        TCB_t * const pxTCB = pxMutexHolder;\n        BaseType_t xReturn = pdFALSE;\n\n        traceENTER_xTaskPriorityDisinherit( pxMutexHolder );\n\n        if( pxMutexHolder != NULL )\n        {\n            /* A task can only have an inherited priority if it holds the mutex.\n             * If the mutex is held by a task then it cannot be given from an\n             * interrupt, and if a mutex is given by the holding task then it must\n             * be the running state task. */\n            configASSERT( pxTCB == pxCurrentTCB );\n            configASSERT( pxTCB->uxMutexesHeld );\n            ( pxTCB->uxMutexesHeld )--;\n\n            /* Has the holder of the mutex inherited the priority of another\n             * task? */\n            if( pxTCB->uxPriority != pxTCB->uxBasePriority )\n            {\n                /* Only disinherit if no other mutexes are held. */\n                if( pxTCB->uxMutexesHeld == ( UBaseType_t ) 0 )\n                {\n                    /* A task can only have an inherited priority if it holds\n                     * the mutex.  If the mutex is held by a task then it cannot be\n                     * given from an interrupt, and if a mutex is given by the\n                     * holding task then it must be the running state task.  Remove\n                     * the holding task from the ready list. */\n                    if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n                    {\n                        portRESET_READY_PRIORITY( pxTCB->uxPriority, uxTopReadyPriority );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* Disinherit the priority before adding the task into the\n                     * new  ready list. */\n                    traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );\n                    pxTCB->uxPriority = pxTCB->uxBasePriority;\n\n                    /* Reset the event list item value.  It cannot be in use for\n                     * any other purpose if this task is running, and it must be\n                     * running to give back the mutex. */\n                    listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxTCB->uxPriority );\n                    prvAddTaskToReadyList( pxTCB );\n                    #if ( configNUMBER_OF_CORES > 1 )\n                    {\n                        /* The priority of the task is dropped. Yield the core on\n                         * which the task is running. */\n                        if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                        {\n                            prvYieldCore( pxTCB->xTaskRunState );\n                        }\n                    }\n                    #endif /* if ( configNUMBER_OF_CORES > 1 ) */\n\n                    /* Return true to indicate that a context switch is required.\n                     * This is only actually required in the corner case whereby\n                     * multiple mutexes were held and the mutexes were given back\n                     * in an order different to that in which they were taken.\n                     * If a context switch did not occur when the first mutex was\n                     * returned, even if a task was waiting on it, then a context\n                     * switch should occur when the last mutex is returned whether\n                     * a task is waiting on it or not. */\n                    xReturn = pdTRUE;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTaskPriorityDisinherit( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    void vTaskPriorityDisinheritAfterTimeout( TaskHandle_t const pxMutexHolder,\n                                              UBaseType_t uxHighestPriorityWaitingTask )\n    {\n        TCB_t * const pxTCB = pxMutexHolder;\n        UBaseType_t uxPriorityUsedOnEntry, uxPriorityToUse;\n        const UBaseType_t uxOnlyOneMutexHeld = ( UBaseType_t ) 1;\n\n        traceENTER_vTaskPriorityDisinheritAfterTimeout( pxMutexHolder, uxHighestPriorityWaitingTask );\n\n        if( pxMutexHolder != NULL )\n        {\n            /* If pxMutexHolder is not NULL then the holder must hold at least\n             * one mutex. */\n            configASSERT( pxTCB->uxMutexesHeld );\n\n            /* Determine the priority to which the priority of the task that\n             * holds the mutex should be set.  This will be the greater of the\n             * holding task's base priority and the priority of the highest\n             * priority task that is waiting to obtain the mutex. */\n            if( pxTCB->uxBasePriority < uxHighestPriorityWaitingTask )\n            {\n                uxPriorityToUse = uxHighestPriorityWaitingTask;\n            }\n            else\n            {\n                uxPriorityToUse = pxTCB->uxBasePriority;\n            }\n\n            /* Does the priority need to change? */\n            if( pxTCB->uxPriority != uxPriorityToUse )\n            {\n                /* Only disinherit if no other mutexes are held.  This is a\n                 * simplification in the priority inheritance implementation.  If\n                 * the task that holds the mutex is also holding other mutexes then\n                 * the other mutexes may have caused the priority inheritance. */\n                if( pxTCB->uxMutexesHeld == uxOnlyOneMutexHeld )\n                {\n                    /* If a task has timed out because it already holds the\n                     * mutex it was trying to obtain then it cannot of inherited\n                     * its own priority. */\n                    configASSERT( pxTCB != pxCurrentTCB );\n\n                    /* Disinherit the priority, remembering the previous\n                     * priority to facilitate determining the subject task's\n                     * state. */\n                    traceTASK_PRIORITY_DISINHERIT( pxTCB, uxPriorityToUse );\n                    uxPriorityUsedOnEntry = pxTCB->uxPriority;\n                    pxTCB->uxPriority = uxPriorityToUse;\n\n                    /* Only reset the event list item value if the value is not\n                     * being used for anything else. */\n                    if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == ( ( TickType_t ) 0U ) )\n                    {\n                        listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriorityToUse );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n\n                    /* If the running task is not the task that holds the mutex\n                     * then the task that holds the mutex could be in either the\n                     * Ready, Blocked or Suspended states.  Only remove the task\n                     * from its current state list if it is in the Ready state as\n                     * the task's priority is going to change and there is one\n                     * Ready list per priority. */\n                    if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )\n                    {\n                        if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n                        {\n                            /* It is known that the task is in its ready list so\n                             * there is no need to check again and the port level\n                             * reset macro can be called directly. */\n                            portRESET_READY_PRIORITY( pxTCB->uxPriority, uxTopReadyPriority );\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n\n                        prvAddTaskToReadyList( pxTCB );\n                        #if ( configNUMBER_OF_CORES > 1 )\n                        {\n                            /* The priority of the task is dropped. Yield the core on\n                             * which the task is running. */\n                            if( taskTASK_IS_RUNNING( pxTCB ) == pdTRUE )\n                            {\n                                prvYieldCore( pxTCB->xTaskRunState );\n                            }\n                        }\n                        #endif /* if ( configNUMBER_OF_CORES > 1 ) */\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskPriorityDisinheritAfterTimeout();\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n/* If not in a critical section then yield immediately.\n * Otherwise set xYieldPendings to true to wait to\n * yield until exiting the critical section.\n */\n    void vTaskYieldWithinAPI( void )\n    {\n        UBaseType_t ulState;\n\n        traceENTER_vTaskYieldWithinAPI();\n\n        ulState = portSET_INTERRUPT_MASK();\n        {\n            const BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0U )\n            {\n                portYIELD();\n            }\n            else\n            {\n                xYieldPendings[ xCoreID ] = pdTRUE;\n            }\n        }\n        portCLEAR_INTERRUPT_MASK( ulState );\n\n        traceRETURN_vTaskYieldWithinAPI();\n    }\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n/*-----------------------------------------------------------*/\n\n#if ( ( portCRITICAL_NESTING_IN_TCB == 1 ) && ( configNUMBER_OF_CORES == 1 ) )\n\n    void vTaskEnterCritical( void )\n    {\n        traceENTER_vTaskEnterCritical();\n\n        portDISABLE_INTERRUPTS();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            ( pxCurrentTCB->uxCriticalNesting )++;\n\n            /* This is not the interrupt safe version of the enter critical\n             * function so  assert() if it is being called from an interrupt\n             * context.  Only API functions that end in \"FromISR\" can be used in an\n             * interrupt.  Only assert if the critical nesting count is 1 to\n             * protect against recursive calls if the assert function also uses a\n             * critical section. */\n            if( pxCurrentTCB->uxCriticalNesting == 1U )\n            {\n                portASSERT_IF_IN_ISR();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskEnterCritical();\n    }\n\n#endif /* #if ( ( portCRITICAL_NESTING_IN_TCB == 1 ) && ( configNUMBER_OF_CORES == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n    void vTaskEnterCritical( void )\n    {\n        traceENTER_vTaskEnterCritical();\n\n        portDISABLE_INTERRUPTS();\n        {\n            const BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            if( xSchedulerRunning != pdFALSE )\n            {\n                if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0U )\n                {\n                    portGET_TASK_LOCK( xCoreID );\n                    portGET_ISR_LOCK( xCoreID );\n                }\n\n                portINCREMENT_CRITICAL_NESTING_COUNT( xCoreID );\n\n                /* This is not the interrupt safe version of the enter critical\n                 * function so  assert() if it is being called from an interrupt\n                 * context.  Only API functions that end in \"FromISR\" can be used in an\n                 * interrupt.  Only assert if the critical nesting count is 1 to\n                 * protect against recursive calls if the assert function also uses a\n                 * critical section. */\n                if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 1U )\n                {\n                    portASSERT_IF_IN_ISR();\n\n                    if( uxSchedulerSuspended == 0U )\n                    {\n                        /* The only time there would be a problem is if this is called\n                         * before a context switch and vTaskExitCritical() is called\n                         * after pxCurrentTCB changes. Therefore this should not be\n                         * used within vTaskSwitchContext(). */\n                        prvCheckForRunStateChange();\n                    }\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        traceRETURN_vTaskEnterCritical();\n    }\n\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n    UBaseType_t vTaskEnterCriticalFromISR( void )\n    {\n        UBaseType_t uxSavedInterruptStatus = 0;\n        const BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n        traceENTER_vTaskEnterCriticalFromISR();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();\n\n            if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0U )\n            {\n                portGET_ISR_LOCK( xCoreID );\n            }\n\n            portINCREMENT_CRITICAL_NESTING_COUNT( xCoreID );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskEnterCriticalFromISR( uxSavedInterruptStatus );\n\n        return uxSavedInterruptStatus;\n    }\n\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( portCRITICAL_NESTING_IN_TCB == 1 ) && ( configNUMBER_OF_CORES == 1 ) )\n\n    void vTaskExitCritical( void )\n    {\n        traceENTER_vTaskExitCritical();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            /* If pxCurrentTCB->uxCriticalNesting is zero then this function\n             * does not match a previous call to vTaskEnterCritical(). */\n            configASSERT( pxCurrentTCB->uxCriticalNesting > 0U );\n\n            /* This function should not be called in ISR. Use vTaskExitCriticalFromISR\n             * to exit critical section from ISR. */\n            portASSERT_IF_IN_ISR();\n\n            if( pxCurrentTCB->uxCriticalNesting > 0U )\n            {\n                ( pxCurrentTCB->uxCriticalNesting )--;\n\n                if( pxCurrentTCB->uxCriticalNesting == 0U )\n                {\n                    portENABLE_INTERRUPTS();\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskExitCritical();\n    }\n\n#endif /* #if ( ( portCRITICAL_NESTING_IN_TCB == 1 ) && ( configNUMBER_OF_CORES == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n    void vTaskExitCritical( void )\n    {\n        const BaseType_t xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n        traceENTER_vTaskExitCritical();\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            /* If critical nesting count is zero then this function\n             * does not match a previous call to vTaskEnterCritical(). */\n            configASSERT( portGET_CRITICAL_NESTING_COUNT( xCoreID ) > 0U );\n\n            /* This function should not be called in ISR. Use vTaskExitCriticalFromISR\n             * to exit critical section from ISR. */\n            portASSERT_IF_IN_ISR();\n\n            if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) > 0U )\n            {\n                portDECREMENT_CRITICAL_NESTING_COUNT( xCoreID );\n\n                if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0U )\n                {\n                    BaseType_t xYieldCurrentTask;\n\n                    /* Get the xYieldPending stats inside the critical section. */\n                    xYieldCurrentTask = xYieldPendings[ xCoreID ];\n\n                    portRELEASE_ISR_LOCK( xCoreID );\n                    portRELEASE_TASK_LOCK( xCoreID );\n                    portENABLE_INTERRUPTS();\n\n                    /* When a task yields in a critical section it just sets\n                     * xYieldPending to true. So now that we have exited the\n                     * critical section check if xYieldPending is true, and\n                     * if so yield. */\n                    if( xYieldCurrentTask != pdFALSE )\n                    {\n                        portYIELD();\n                    }\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskExitCritical();\n    }\n\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( configNUMBER_OF_CORES > 1 )\n\n    void vTaskExitCriticalFromISR( UBaseType_t uxSavedInterruptStatus )\n    {\n        BaseType_t xCoreID;\n\n        traceENTER_vTaskExitCriticalFromISR( uxSavedInterruptStatus );\n\n        if( xSchedulerRunning != pdFALSE )\n        {\n            xCoreID = ( BaseType_t ) portGET_CORE_ID();\n\n            /* If critical nesting count is zero then this function\n             * does not match a previous call to vTaskEnterCritical(). */\n            configASSERT( portGET_CRITICAL_NESTING_COUNT( xCoreID ) > 0U );\n\n            if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) > 0U )\n            {\n                portDECREMENT_CRITICAL_NESTING_COUNT( xCoreID );\n\n                if( portGET_CRITICAL_NESTING_COUNT( xCoreID ) == 0U )\n                {\n                    portRELEASE_ISR_LOCK( xCoreID );\n                    portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskExitCriticalFromISR();\n    }\n\n#endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 )\n\n    static char * prvWriteNameToBuffer( char * pcBuffer,\n                                        const char * pcTaskName )\n    {\n        size_t x;\n\n        /* Start by copying the entire string. */\n        ( void ) strcpy( pcBuffer, pcTaskName );\n\n        /* Pad the end of the string with spaces to ensure columns line up when\n         * printed out. */\n        for( x = strlen( pcBuffer ); x < ( size_t ) ( ( size_t ) configMAX_TASK_NAME_LEN - 1U ); x++ )\n        {\n            pcBuffer[ x ] = ' ';\n        }\n\n        /* Terminate. */\n        pcBuffer[ x ] = ( char ) 0x00;\n\n        /* Return the new end of string. */\n        return &( pcBuffer[ x ] );\n    }\n\n#endif /* ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) )\n\n    void vTaskListTasks( char * pcWriteBuffer,\n                         size_t uxBufferLength )\n    {\n        TaskStatus_t * pxTaskStatusArray;\n        size_t uxConsumedBufferLength = 0;\n        size_t uxCharsWrittenBySnprintf;\n        int iSnprintfReturnValue;\n        BaseType_t xOutputBufferFull = pdFALSE;\n        UBaseType_t uxArraySize, x;\n        char cStatus;\n\n        traceENTER_vTaskListTasks( pcWriteBuffer, uxBufferLength );\n\n        /*\n         * PLEASE NOTE:\n         *\n         * This function is provided for convenience only, and is used by many\n         * of the demo applications.  Do not consider it to be part of the\n         * scheduler.\n         *\n         * vTaskListTasks() calls uxTaskGetSystemState(), then formats part of the\n         * uxTaskGetSystemState() output into a human readable table that\n         * displays task: names, states, priority, stack usage and task number.\n         * Stack usage specified as the number of unused StackType_t words stack can hold\n         * on top of stack - not the number of bytes.\n         *\n         * vTaskListTasks() has a dependency on the snprintf() C library function that\n         * might bloat the code size, use a lot of stack, and provide different\n         * results on different platforms.  An alternative, tiny, third party,\n         * and limited functionality implementation of snprintf() is provided in\n         * many of the FreeRTOS/Demo sub-directories in a file called\n         * printf-stdarg.c (note printf-stdarg.c does not provide a full\n         * snprintf() implementation!).\n         *\n         * It is recommended that production systems call uxTaskGetSystemState()\n         * directly to get access to raw stats data, rather than indirectly\n         * through a call to vTaskListTasks().\n         */\n\n\n        /* Make sure the write buffer does not contain a string. */\n        *pcWriteBuffer = ( char ) 0x00;\n\n        /* Take a snapshot of the number of tasks in case it changes while this\n         * function is executing. */\n        uxArraySize = uxCurrentNumberOfTasks;\n\n        /* Allocate an array index for each task.  NOTE!  if\n         * configSUPPORT_DYNAMIC_ALLOCATION is set to 0 then pvPortMalloc() will\n         * equate to NULL. */\n        /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        pxTaskStatusArray = pvPortMalloc( uxCurrentNumberOfTasks * sizeof( TaskStatus_t ) );\n\n        if( pxTaskStatusArray != NULL )\n        {\n            /* Generate the (binary) data. */\n            uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, NULL );\n\n            /* Create a human readable table from the binary data. */\n            for( x = 0; x < uxArraySize; x++ )\n            {\n                switch( pxTaskStatusArray[ x ].eCurrentState )\n                {\n                    case eRunning:\n                        cStatus = tskRUNNING_CHAR;\n                        break;\n\n                    case eReady:\n                        cStatus = tskREADY_CHAR;\n                        break;\n\n                    case eBlocked:\n                        cStatus = tskBLOCKED_CHAR;\n                        break;\n\n                    case eSuspended:\n                        cStatus = tskSUSPENDED_CHAR;\n                        break;\n\n                    case eDeleted:\n                        cStatus = tskDELETED_CHAR;\n                        break;\n\n                    case eInvalid: /* Fall through. */\n                    default:       /* Should not get here, but it is included\n                                    * to prevent static checking errors. */\n                        cStatus = ( char ) 0x00;\n                        break;\n                }\n\n                /* Is there enough space in the buffer to hold task name? */\n                if( ( uxConsumedBufferLength + configMAX_TASK_NAME_LEN ) <= uxBufferLength )\n                {\n                    /* Write the task name to the string, padding with spaces so it\n                     * can be printed in tabular form more easily. */\n                    pcWriteBuffer = prvWriteNameToBuffer( pcWriteBuffer, pxTaskStatusArray[ x ].pcTaskName );\n                    /* Do not count the terminating null character. */\n                    uxConsumedBufferLength = uxConsumedBufferLength + ( configMAX_TASK_NAME_LEN - 1U );\n\n                    /* Is there space left in the buffer? -1 is done because snprintf\n                     * writes a terminating null character. So we are essentially\n                     * checking if the buffer has space to write at least one non-null\n                     * character. */\n                    if( uxConsumedBufferLength < ( uxBufferLength - 1U ) )\n                    {\n                        /* Write the rest of the string. */\n                        #if ( ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 ) )\n                            /* MISRA Ref 21.6.1 [snprintf for utility] */\n                            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                            /* coverity[misra_c_2012_rule_21_6_violation] */\n                            iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                             uxBufferLength - uxConsumedBufferLength,\n                                                             \"\\t%c\\t%u\\t%u\\t%u\\t0x%x\\r\\n\",\n                                                             cStatus,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].uxCurrentPriority,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].usStackHighWaterMark,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].xTaskNumber,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].uxCoreAffinityMask );\n                        #else /* ( ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 ) ) */\n                            /* MISRA Ref 21.6.1 [snprintf for utility] */\n                            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                            /* coverity[misra_c_2012_rule_21_6_violation] */\n                            iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                             uxBufferLength - uxConsumedBufferLength,\n                                                             \"\\t%c\\t%u\\t%u\\t%u\\r\\n\",\n                                                             cStatus,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].uxCurrentPriority,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].usStackHighWaterMark,\n                                                             ( unsigned int ) pxTaskStatusArray[ x ].xTaskNumber );\n                        #endif /* ( ( configUSE_CORE_AFFINITY == 1 ) && ( configNUMBER_OF_CORES > 1 ) ) */\n                        uxCharsWrittenBySnprintf = prvSnprintfReturnValueToCharsWritten( iSnprintfReturnValue, uxBufferLength - uxConsumedBufferLength );\n\n                        uxConsumedBufferLength += uxCharsWrittenBySnprintf;\n                        pcWriteBuffer += uxCharsWrittenBySnprintf;\n                    }\n                    else\n                    {\n                        xOutputBufferFull = pdTRUE;\n                    }\n                }\n                else\n                {\n                    xOutputBufferFull = pdTRUE;\n                }\n\n                if( xOutputBufferFull == pdTRUE )\n                {\n                    break;\n                }\n            }\n\n            /* Free the array again.  NOTE!  If configSUPPORT_DYNAMIC_ALLOCATION\n             * is 0 then vPortFree() will be #defined to nothing. */\n            vPortFree( pxTaskStatusArray );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskListTasks();\n    }\n\n#endif /* ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) ) */\n/*----------------------------------------------------------*/\n\n#if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) && ( configUSE_TRACE_FACILITY == 1 ) )\n\n    void vTaskGetRunTimeStatistics( char * pcWriteBuffer,\n                                    size_t uxBufferLength )\n    {\n        TaskStatus_t * pxTaskStatusArray;\n        size_t uxConsumedBufferLength = 0;\n        size_t uxCharsWrittenBySnprintf;\n        int iSnprintfReturnValue;\n        BaseType_t xOutputBufferFull = pdFALSE;\n        UBaseType_t uxArraySize, x;\n        configRUN_TIME_COUNTER_TYPE ulTotalTime = 0;\n        configRUN_TIME_COUNTER_TYPE ulStatsAsPercentage;\n\n        traceENTER_vTaskGetRunTimeStatistics( pcWriteBuffer, uxBufferLength );\n\n        /*\n         * PLEASE NOTE:\n         *\n         * This function is provided for convenience only, and is used by many\n         * of the demo applications.  Do not consider it to be part of the\n         * scheduler.\n         *\n         * vTaskGetRunTimeStatistics() calls uxTaskGetSystemState(), then formats part\n         * of the uxTaskGetSystemState() output into a human readable table that\n         * displays the amount of time each task has spent in the Running state\n         * in both absolute and percentage terms.\n         *\n         * vTaskGetRunTimeStatistics() has a dependency on the snprintf() C library\n         * function that might bloat the code size, use a lot of stack, and\n         * provide different results on different platforms.  An alternative,\n         * tiny, third party, and limited functionality implementation of\n         * snprintf() is provided in many of the FreeRTOS/Demo sub-directories in\n         * a file called printf-stdarg.c (note printf-stdarg.c does not provide\n         * a full snprintf() implementation!).\n         *\n         * It is recommended that production systems call uxTaskGetSystemState()\n         * directly to get access to raw stats data, rather than indirectly\n         * through a call to vTaskGetRunTimeStatistics().\n         */\n\n        /* Make sure the write buffer does not contain a string. */\n        *pcWriteBuffer = ( char ) 0x00;\n\n        /* Take a snapshot of the number of tasks in case it changes while this\n         * function is executing. */\n        uxArraySize = uxCurrentNumberOfTasks;\n\n        /* Allocate an array index for each task.  NOTE!  If\n         * configSUPPORT_DYNAMIC_ALLOCATION is set to 0 then pvPortMalloc() will\n         * equate to NULL. */\n        /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        pxTaskStatusArray = pvPortMalloc( uxCurrentNumberOfTasks * sizeof( TaskStatus_t ) );\n\n        if( pxTaskStatusArray != NULL )\n        {\n            /* Generate the (binary) data. */\n            uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, &ulTotalTime );\n\n            /* For percentage calculations. */\n            ulTotalTime /= ( ( configRUN_TIME_COUNTER_TYPE ) 100U );\n\n            /* Avoid divide by zero errors. */\n            if( ulTotalTime > 0U )\n            {\n                /* Create a human readable table from the binary data. */\n                for( x = 0; x < uxArraySize; x++ )\n                {\n                    /* What percentage of the total run time has the task used?\n                     * This will always be rounded down to the nearest integer.\n                     * ulTotalRunTime has already been divided by 100. */\n                    ulStatsAsPercentage = pxTaskStatusArray[ x ].ulRunTimeCounter / ulTotalTime;\n\n                    /* Is there enough space in the buffer to hold task name? */\n                    if( ( uxConsumedBufferLength + configMAX_TASK_NAME_LEN ) <= uxBufferLength )\n                    {\n                        /* Write the task name to the string, padding with\n                         * spaces so it can be printed in tabular form more\n                         * easily. */\n                        pcWriteBuffer = prvWriteNameToBuffer( pcWriteBuffer, pxTaskStatusArray[ x ].pcTaskName );\n                        /* Do not count the terminating null character. */\n                        uxConsumedBufferLength = uxConsumedBufferLength + ( configMAX_TASK_NAME_LEN - 1U );\n\n                        /* Is there space left in the buffer? -1 is done because snprintf\n                         * writes a terminating null character. So we are essentially\n                         * checking if the buffer has space to write at least one non-null\n                         * character. */\n                        if( uxConsumedBufferLength < ( uxBufferLength - 1U ) )\n                        {\n                            if( ulStatsAsPercentage > 0U )\n                            {\n                                #ifdef portLU_PRINTF_SPECIFIER_REQUIRED\n                                {\n                                    /* MISRA Ref 21.6.1 [snprintf for utility] */\n                                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                                    /* coverity[misra_c_2012_rule_21_6_violation] */\n                                    iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                                     uxBufferLength - uxConsumedBufferLength,\n                                                                     \"\\t%lu\\t\\t%lu%%\\r\\n\",\n                                                                     pxTaskStatusArray[ x ].ulRunTimeCounter,\n                                                                     ulStatsAsPercentage );\n                                }\n                                #else /* ifdef portLU_PRINTF_SPECIFIER_REQUIRED */\n                                {\n                                    /* sizeof( int ) == sizeof( long ) so a smaller\n                                     * printf() library can be used. */\n                                    /* MISRA Ref 21.6.1 [snprintf for utility] */\n                                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                                    /* coverity[misra_c_2012_rule_21_6_violation] */\n                                    iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                                     uxBufferLength - uxConsumedBufferLength,\n                                                                     \"\\t%u\\t\\t%u%%\\r\\n\",\n                                                                     ( unsigned int ) pxTaskStatusArray[ x ].ulRunTimeCounter,\n                                                                     ( unsigned int ) ulStatsAsPercentage );\n                                }\n                                #endif /* ifdef portLU_PRINTF_SPECIFIER_REQUIRED */\n                            }\n                            else\n                            {\n                                /* If the percentage is zero here then the task has\n                                 * consumed less than 1% of the total run time. */\n                                #ifdef portLU_PRINTF_SPECIFIER_REQUIRED\n                                {\n                                    /* MISRA Ref 21.6.1 [snprintf for utility] */\n                                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                                    /* coverity[misra_c_2012_rule_21_6_violation] */\n                                    iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                                     uxBufferLength - uxConsumedBufferLength,\n                                                                     \"\\t%lu\\t\\t<1%%\\r\\n\",\n                                                                     pxTaskStatusArray[ x ].ulRunTimeCounter );\n                                }\n                                #else\n                                {\n                                    /* sizeof( int ) == sizeof( long ) so a smaller\n                                     * printf() library can be used. */\n                                    /* MISRA Ref 21.6.1 [snprintf for utility] */\n                                    /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-216 */\n                                    /* coverity[misra_c_2012_rule_21_6_violation] */\n                                    iSnprintfReturnValue = snprintf( pcWriteBuffer,\n                                                                     uxBufferLength - uxConsumedBufferLength,\n                                                                     \"\\t%u\\t\\t<1%%\\r\\n\",\n                                                                     ( unsigned int ) pxTaskStatusArray[ x ].ulRunTimeCounter );\n                                }\n                                #endif /* ifdef portLU_PRINTF_SPECIFIER_REQUIRED */\n                            }\n\n                            uxCharsWrittenBySnprintf = prvSnprintfReturnValueToCharsWritten( iSnprintfReturnValue, uxBufferLength - uxConsumedBufferLength );\n                            uxConsumedBufferLength += uxCharsWrittenBySnprintf;\n                            pcWriteBuffer += uxCharsWrittenBySnprintf;\n                        }\n                        else\n                        {\n                            xOutputBufferFull = pdTRUE;\n                        }\n                    }\n                    else\n                    {\n                        xOutputBufferFull = pdTRUE;\n                    }\n\n                    if( xOutputBufferFull == pdTRUE )\n                    {\n                        break;\n                    }\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            /* Free the array again.  NOTE!  If configSUPPORT_DYNAMIC_ALLOCATION\n             * is 0 then vPortFree() will be #defined to nothing. */\n            vPortFree( pxTaskStatusArray );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_vTaskGetRunTimeStatistics();\n    }\n\n#endif /* ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) ) */\n/*-----------------------------------------------------------*/\n\nTickType_t uxTaskResetEventItemValue( void )\n{\n    TickType_t uxReturn;\n\n    traceENTER_uxTaskResetEventItemValue();\n\n    uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );\n\n    /* Reset the event list item to its normal value - so it can be used with\n     * queues and semaphores. */\n    listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) );\n\n    traceRETURN_uxTaskResetEventItemValue( uxReturn );\n\n    return uxReturn;\n}\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_MUTEXES == 1 )\n\n    TaskHandle_t pvTaskIncrementMutexHeldCount( void )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_pvTaskIncrementMutexHeldCount();\n\n        pxTCB = pxCurrentTCB;\n\n        /* If xSemaphoreCreateMutex() is called before any tasks have been created\n         * then pxCurrentTCB will be NULL. */\n        if( pxTCB != NULL )\n        {\n            ( pxTCB->uxMutexesHeld )++;\n        }\n\n        traceRETURN_pvTaskIncrementMutexHeldCount( pxTCB );\n\n        return pxTCB;\n    }\n\n#endif /* configUSE_MUTEXES */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    uint32_t ulTaskGenericNotifyTake( UBaseType_t uxIndexToWaitOn,\n                                      BaseType_t xClearCountOnExit,\n                                      TickType_t xTicksToWait )\n    {\n        uint32_t ulReturn;\n        BaseType_t xAlreadyYielded, xShouldBlock = pdFALSE;\n\n        traceENTER_ulTaskGenericNotifyTake( uxIndexToWaitOn, xClearCountOnExit, xTicksToWait );\n\n        configASSERT( uxIndexToWaitOn < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* If the notification count is zero, and if we are willing to wait for a\n         * notification, then block the task and wait. */\n        if( ( pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] == 0U ) && ( xTicksToWait > ( TickType_t ) 0 ) )\n        {\n            /* We suspend the scheduler here as prvAddCurrentTaskToDelayedList is a\n             * non-deterministic operation. */\n            vTaskSuspendAll();\n            {\n                /* We MUST enter a critical section to atomically check if a notification\n                 * has occurred and set the flag to indicate that we are waiting for\n                 * a notification. If we do not do so, a notification sent from an ISR\n                 * will get lost. */\n                taskENTER_CRITICAL();\n                {\n                    /* Only block if the notification count is not already non-zero. */\n                    if( pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] == 0U )\n                    {\n                        /* Mark this task as waiting for a notification. */\n                        pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] = taskWAITING_NOTIFICATION;\n\n                        /* Arrange to wait for a notification. */\n                        xShouldBlock = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                /* We are now out of the critical section but the scheduler is still\n                 * suspended, so we are safe to do non-deterministic operations such\n                 * as prvAddCurrentTaskToDelayedList. */\n                if( xShouldBlock == pdTRUE )\n                {\n                    traceTASK_NOTIFY_TAKE_BLOCK( uxIndexToWaitOn );\n                    prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            xAlreadyYielded = xTaskResumeAll();\n\n            /* Force a reschedule if xTaskResumeAll has not already done so. */\n            if( ( xShouldBlock == pdTRUE ) && ( xAlreadyYielded == pdFALSE ) )\n            {\n                taskYIELD_WITHIN_API();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        taskENTER_CRITICAL();\n        {\n            traceTASK_NOTIFY_TAKE( uxIndexToWaitOn );\n            ulReturn = pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ];\n\n            if( ulReturn != 0U )\n            {\n                if( xClearCountOnExit != pdFALSE )\n                {\n                    pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] = ( uint32_t ) 0U;\n                }\n                else\n                {\n                    pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] = ulReturn - ( uint32_t ) 1;\n                }\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n\n            pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] = taskNOT_WAITING_NOTIFICATION;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_ulTaskGenericNotifyTake( ulReturn );\n\n        return ulReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    BaseType_t xTaskGenericNotifyWait( UBaseType_t uxIndexToWaitOn,\n                                       uint32_t ulBitsToClearOnEntry,\n                                       uint32_t ulBitsToClearOnExit,\n                                       uint32_t * pulNotificationValue,\n                                       TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn, xAlreadyYielded, xShouldBlock = pdFALSE;\n\n        traceENTER_xTaskGenericNotifyWait( uxIndexToWaitOn, ulBitsToClearOnEntry, ulBitsToClearOnExit, pulNotificationValue, xTicksToWait );\n\n        configASSERT( uxIndexToWaitOn < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* If the task hasn't received a notification, and if we are willing to wait\n         * for it, then block the task and wait. */\n        if( ( pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] != taskNOTIFICATION_RECEIVED ) && ( xTicksToWait > ( TickType_t ) 0 ) )\n        {\n            /* We suspend the scheduler here as prvAddCurrentTaskToDelayedList is a\n             * non-deterministic operation. */\n            vTaskSuspendAll();\n            {\n                /* We MUST enter a critical section to atomically check and update the\n                 * task notification value. If we do not do so, a notification from\n                 * an ISR will get lost. */\n                taskENTER_CRITICAL();\n                {\n                    /* Only block if a notification is not already pending. */\n                    if( pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] != taskNOTIFICATION_RECEIVED )\n                    {\n                        /* Clear bits in the task's notification value as bits may get\n                         * set by the notifying task or interrupt. This can be used\n                         * to clear the value to zero. */\n                        pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] &= ~ulBitsToClearOnEntry;\n\n                        /* Mark this task as waiting for a notification. */\n                        pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] = taskWAITING_NOTIFICATION;\n\n                        /* Arrange to wait for a notification. */\n                        xShouldBlock = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                taskEXIT_CRITICAL();\n\n                /* We are now out of the critical section but the scheduler is still\n                 * suspended, so we are safe to do non-deterministic operations such\n                 * as prvAddCurrentTaskToDelayedList. */\n                if( xShouldBlock == pdTRUE )\n                {\n                    traceTASK_NOTIFY_WAIT_BLOCK( uxIndexToWaitOn );\n                    prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            xAlreadyYielded = xTaskResumeAll();\n\n            /* Force a reschedule if xTaskResumeAll has not already done so. */\n            if( ( xShouldBlock == pdTRUE ) && ( xAlreadyYielded == pdFALSE ) )\n            {\n                taskYIELD_WITHIN_API();\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        taskENTER_CRITICAL();\n        {\n            traceTASK_NOTIFY_WAIT( uxIndexToWaitOn );\n\n            if( pulNotificationValue != NULL )\n            {\n                /* Output the current notification value, which may or may not\n                 * have changed. */\n                *pulNotificationValue = pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ];\n            }\n\n            /* If ucNotifyValue is set then either the task never entered the\n             * blocked state (because a notification was already pending) or the\n             * task unblocked because of a notification.  Otherwise the task\n             * unblocked because of a timeout. */\n            if( pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] != taskNOTIFICATION_RECEIVED )\n            {\n                /* A notification was not received. */\n                xReturn = pdFALSE;\n            }\n            else\n            {\n                /* A notification was already pending or a notification was\n                 * received while the task was waiting. */\n                pxCurrentTCB->ulNotifiedValue[ uxIndexToWaitOn ] &= ~ulBitsToClearOnExit;\n                xReturn = pdTRUE;\n            }\n\n            pxCurrentTCB->ucNotifyState[ uxIndexToWaitOn ] = taskNOT_WAITING_NOTIFICATION;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xTaskGenericNotifyWait( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify,\n                                   UBaseType_t uxIndexToNotify,\n                                   uint32_t ulValue,\n                                   eNotifyAction eAction,\n                                   uint32_t * pulPreviousNotificationValue )\n    {\n        TCB_t * pxTCB;\n        BaseType_t xReturn = pdPASS;\n        uint8_t ucOriginalNotifyState;\n\n        traceENTER_xTaskGenericNotify( xTaskToNotify, uxIndexToNotify, ulValue, eAction, pulPreviousNotificationValue );\n\n        configASSERT( uxIndexToNotify < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n        configASSERT( xTaskToNotify );\n        pxTCB = xTaskToNotify;\n\n        taskENTER_CRITICAL();\n        {\n            if( pulPreviousNotificationValue != NULL )\n            {\n                *pulPreviousNotificationValue = pxTCB->ulNotifiedValue[ uxIndexToNotify ];\n            }\n\n            ucOriginalNotifyState = pxTCB->ucNotifyState[ uxIndexToNotify ];\n\n            pxTCB->ucNotifyState[ uxIndexToNotify ] = taskNOTIFICATION_RECEIVED;\n\n            switch( eAction )\n            {\n                case eSetBits:\n                    pxTCB->ulNotifiedValue[ uxIndexToNotify ] |= ulValue;\n                    break;\n\n                case eIncrement:\n                    ( pxTCB->ulNotifiedValue[ uxIndexToNotify ] )++;\n                    break;\n\n                case eSetValueWithOverwrite:\n                    pxTCB->ulNotifiedValue[ uxIndexToNotify ] = ulValue;\n                    break;\n\n                case eSetValueWithoutOverwrite:\n\n                    if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )\n                    {\n                        pxTCB->ulNotifiedValue[ uxIndexToNotify ] = ulValue;\n                    }\n                    else\n                    {\n                        /* The value could not be written to the task. */\n                        xReturn = pdFAIL;\n                    }\n\n                    break;\n\n                case eNoAction:\n\n                    /* The task is being notified without its notify value being\n                     * updated. */\n                    break;\n\n                default:\n\n                    /* Should not get here if all enums are handled.\n                     * Artificially force an assert by testing a value the\n                     * compiler can't assume is const. */\n                    configASSERT( xTickCount == ( TickType_t ) 0 );\n\n                    break;\n            }\n\n            traceTASK_NOTIFY( uxIndexToNotify );\n\n            /* If the task is in the blocked state specifically to wait for a\n             * notification then unblock it now. */\n            if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )\n            {\n                listREMOVE_ITEM( &( pxTCB->xStateListItem ) );\n                prvAddTaskToReadyList( pxTCB );\n\n                /* The task should not have been on an event list. */\n                configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );\n\n                #if ( configUSE_TICKLESS_IDLE != 0 )\n                {\n                    /* If a task is blocked waiting for a notification then\n                     * xNextTaskUnblockTime might be set to the blocked task's time\n                     * out time.  If the task is unblocked for a reason other than\n                     * a timeout xNextTaskUnblockTime is normally left unchanged,\n                     * because it will automatically get reset to a new value when\n                     * the tick count equals xNextTaskUnblockTime.  However if\n                     * tickless idling is used it might be more important to enter\n                     * sleep mode at the earliest possible time - so reset\n                     * xNextTaskUnblockTime here to ensure it is updated at the\n                     * earliest possible time. */\n                    prvResetNextTaskUnblockTime();\n                }\n                #endif\n\n                /* Check if the notified task has a priority above the currently\n                 * executing task. */\n                taskYIELD_ANY_CORE_IF_USING_PREEMPTION( pxTCB );\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xTaskGenericNotify( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify,\n                                          UBaseType_t uxIndexToNotify,\n                                          uint32_t ulValue,\n                                          eNotifyAction eAction,\n                                          uint32_t * pulPreviousNotificationValue,\n                                          BaseType_t * pxHigherPriorityTaskWoken )\n    {\n        TCB_t * pxTCB;\n        uint8_t ucOriginalNotifyState;\n        BaseType_t xReturn = pdPASS;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_xTaskGenericNotifyFromISR( xTaskToNotify, uxIndexToNotify, ulValue, eAction, pulPreviousNotificationValue, pxHigherPriorityTaskWoken );\n\n        configASSERT( xTaskToNotify );\n        configASSERT( uxIndexToNotify < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* RTOS ports that support interrupt nesting have the concept of a\n         * maximum  system call (or maximum API call) interrupt priority.\n         * Interrupts that are  above the maximum system call priority are keep\n         * permanently enabled, even when the RTOS kernel is in a critical section,\n         * but cannot make any calls to FreeRTOS API functions.  If configASSERT()\n         * is defined in FreeRTOSConfig.h then\n         * portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n         * failure if a FreeRTOS API function is called from an interrupt that has\n         * been assigned a priority above the configured maximum system call\n         * priority.  Only FreeRTOS functions that end in FromISR can be called\n         * from interrupts  that have been assigned a priority at or (logically)\n         * below the maximum system call interrupt priority.  FreeRTOS maintains a\n         * separate interrupt safe API to ensure interrupt entry is as fast and as\n         * simple as possible.  More information (albeit Cortex-M specific) is\n         * provided on the following link:\n         * https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n        portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n        pxTCB = xTaskToNotify;\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n        {\n            if( pulPreviousNotificationValue != NULL )\n            {\n                *pulPreviousNotificationValue = pxTCB->ulNotifiedValue[ uxIndexToNotify ];\n            }\n\n            ucOriginalNotifyState = pxTCB->ucNotifyState[ uxIndexToNotify ];\n            pxTCB->ucNotifyState[ uxIndexToNotify ] = taskNOTIFICATION_RECEIVED;\n\n            switch( eAction )\n            {\n                case eSetBits:\n                    pxTCB->ulNotifiedValue[ uxIndexToNotify ] |= ulValue;\n                    break;\n\n                case eIncrement:\n                    ( pxTCB->ulNotifiedValue[ uxIndexToNotify ] )++;\n                    break;\n\n                case eSetValueWithOverwrite:\n                    pxTCB->ulNotifiedValue[ uxIndexToNotify ] = ulValue;\n                    break;\n\n                case eSetValueWithoutOverwrite:\n\n                    if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )\n                    {\n                        pxTCB->ulNotifiedValue[ uxIndexToNotify ] = ulValue;\n                    }\n                    else\n                    {\n                        /* The value could not be written to the task. */\n                        xReturn = pdFAIL;\n                    }\n\n                    break;\n\n                case eNoAction:\n\n                    /* The task is being notified without its notify value being\n                     * updated. */\n                    break;\n\n                default:\n\n                    /* Should not get here if all enums are handled.\n                     * Artificially force an assert by testing a value the\n                     * compiler can't assume is const. */\n                    configASSERT( xTickCount == ( TickType_t ) 0 );\n                    break;\n            }\n\n            traceTASK_NOTIFY_FROM_ISR( uxIndexToNotify );\n\n            /* If the task is in the blocked state specifically to wait for a\n             * notification then unblock it now. */\n            if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )\n            {\n                /* The task should not have been on an event list. */\n                configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );\n\n                if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n                {\n                    listREMOVE_ITEM( &( pxTCB->xStateListItem ) );\n                    prvAddTaskToReadyList( pxTCB );\n\n                    #if ( configUSE_TICKLESS_IDLE != 0 )\n                    {\n                        /* If a task is blocked waiting for a notification then\n                         * xNextTaskUnblockTime might be set to the blocked task's time\n                         * out time.  If the task is unblocked for a reason other than\n                         * a timeout xNextTaskUnblockTime is normally left unchanged,\n                         * because it will automatically get reset to a new value when\n                         * the tick count equals xNextTaskUnblockTime.  However if\n                         * tickless idling is used it might be more important to enter\n                         * sleep mode at the earliest possible time - so reset\n                         * xNextTaskUnblockTime here to ensure it is updated at the\n                         * earliest possible time. */\n                        prvResetNextTaskUnblockTime();\n                    }\n                    #endif\n                }\n                else\n                {\n                    /* The delayed and ready lists cannot be accessed, so hold\n                     * this task pending until the scheduler is resumed. */\n                    listINSERT_END( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );\n                }\n\n                #if ( configNUMBER_OF_CORES == 1 )\n                {\n                    if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                    {\n                        /* The notified task has a priority above the currently\n                         * executing task so a yield is required. */\n                        if( pxHigherPriorityTaskWoken != NULL )\n                        {\n                            *pxHigherPriorityTaskWoken = pdTRUE;\n                        }\n\n                        /* Mark that a yield is pending in case the user is not\n                         * using the \"xHigherPriorityTaskWoken\" parameter to an ISR\n                         * safe FreeRTOS function. */\n                        xYieldPendings[ 0 ] = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                {\n                    #if ( configUSE_PREEMPTION == 1 )\n                    {\n                        prvYieldForTask( pxTCB );\n\n                        if( xYieldPendings[ portGET_CORE_ID() ] == pdTRUE )\n                        {\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                        }\n                    }\n                    #endif /* if ( configUSE_PREEMPTION == 1 ) */\n                }\n                #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n            }\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_xTaskGenericNotifyFromISR( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    void vTaskGenericNotifyGiveFromISR( TaskHandle_t xTaskToNotify,\n                                        UBaseType_t uxIndexToNotify,\n                                        BaseType_t * pxHigherPriorityTaskWoken )\n    {\n        TCB_t * pxTCB;\n        uint8_t ucOriginalNotifyState;\n        UBaseType_t uxSavedInterruptStatus;\n\n        traceENTER_vTaskGenericNotifyGiveFromISR( xTaskToNotify, uxIndexToNotify, pxHigherPriorityTaskWoken );\n\n        configASSERT( xTaskToNotify );\n        configASSERT( uxIndexToNotify < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* RTOS ports that support interrupt nesting have the concept of a\n         * maximum  system call (or maximum API call) interrupt priority.\n         * Interrupts that are  above the maximum system call priority are keep\n         * permanently enabled, even when the RTOS kernel is in a critical section,\n         * but cannot make any calls to FreeRTOS API functions.  If configASSERT()\n         * is defined in FreeRTOSConfig.h then\n         * portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion\n         * failure if a FreeRTOS API function is called from an interrupt that has\n         * been assigned a priority above the configured maximum system call\n         * priority.  Only FreeRTOS functions that end in FromISR can be called\n         * from interrupts  that have been assigned a priority at or (logically)\n         * below the maximum system call interrupt priority.  FreeRTOS maintains a\n         * separate interrupt safe API to ensure interrupt entry is as fast and as\n         * simple as possible.  More information (albeit Cortex-M specific) is\n         * provided on the following link:\n         * https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */\n        portASSERT_IF_INTERRUPT_PRIORITY_INVALID();\n\n        pxTCB = xTaskToNotify;\n\n        /* MISRA Ref 4.7.1 [Return value shall be checked] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#dir-47 */\n        /* coverity[misra_c_2012_directive_4_7_violation] */\n        uxSavedInterruptStatus = ( UBaseType_t ) taskENTER_CRITICAL_FROM_ISR();\n        {\n            ucOriginalNotifyState = pxTCB->ucNotifyState[ uxIndexToNotify ];\n            pxTCB->ucNotifyState[ uxIndexToNotify ] = taskNOTIFICATION_RECEIVED;\n\n            /* 'Giving' is equivalent to incrementing a count in a counting\n             * semaphore. */\n            ( pxTCB->ulNotifiedValue[ uxIndexToNotify ] )++;\n\n            traceTASK_NOTIFY_GIVE_FROM_ISR( uxIndexToNotify );\n\n            /* If the task is in the blocked state specifically to wait for a\n             * notification then unblock it now. */\n            if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )\n            {\n                /* The task should not have been on an event list. */\n                configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );\n\n                if( uxSchedulerSuspended == ( UBaseType_t ) 0U )\n                {\n                    listREMOVE_ITEM( &( pxTCB->xStateListItem ) );\n                    prvAddTaskToReadyList( pxTCB );\n\n                    #if ( configUSE_TICKLESS_IDLE != 0 )\n                    {\n                        /* If a task is blocked waiting for a notification then\n                         * xNextTaskUnblockTime might be set to the blocked task's time\n                         * out time.  If the task is unblocked for a reason other than\n                         * a timeout xNextTaskUnblockTime is normally left unchanged,\n                         * because it will automatically get reset to a new value when\n                         * the tick count equals xNextTaskUnblockTime.  However if\n                         * tickless idling is used it might be more important to enter\n                         * sleep mode at the earliest possible time - so reset\n                         * xNextTaskUnblockTime here to ensure it is updated at the\n                         * earliest possible time. */\n                        prvResetNextTaskUnblockTime();\n                    }\n                    #endif\n                }\n                else\n                {\n                    /* The delayed and ready lists cannot be accessed, so hold\n                     * this task pending until the scheduler is resumed. */\n                    listINSERT_END( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );\n                }\n\n                #if ( configNUMBER_OF_CORES == 1 )\n                {\n                    if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )\n                    {\n                        /* The notified task has a priority above the currently\n                         * executing task so a yield is required. */\n                        if( pxHigherPriorityTaskWoken != NULL )\n                        {\n                            *pxHigherPriorityTaskWoken = pdTRUE;\n                        }\n\n                        /* Mark that a yield is pending in case the user is not\n                         * using the \"xHigherPriorityTaskWoken\" parameter in an ISR\n                         * safe FreeRTOS function. */\n                        xYieldPendings[ 0 ] = pdTRUE;\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #else /* #if ( configNUMBER_OF_CORES == 1 ) */\n                {\n                    #if ( configUSE_PREEMPTION == 1 )\n                    {\n                        prvYieldForTask( pxTCB );\n\n                        if( xYieldPendings[ portGET_CORE_ID() ] == pdTRUE )\n                        {\n                            if( pxHigherPriorityTaskWoken != NULL )\n                            {\n                                *pxHigherPriorityTaskWoken = pdTRUE;\n                            }\n                        }\n                    }\n                    #endif /* #if ( configUSE_PREEMPTION == 1 ) */\n                }\n                #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n            }\n        }\n        taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );\n\n        traceRETURN_vTaskGenericNotifyGiveFromISR();\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    BaseType_t xTaskGenericNotifyStateClear( TaskHandle_t xTask,\n                                             UBaseType_t uxIndexToClear )\n    {\n        TCB_t * pxTCB;\n        BaseType_t xReturn;\n\n        traceENTER_xTaskGenericNotifyStateClear( xTask, uxIndexToClear );\n\n        configASSERT( uxIndexToClear < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* If null is passed in here then it is the calling task that is having\n         * its notification state cleared. */\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        taskENTER_CRITICAL();\n        {\n            if( pxTCB->ucNotifyState[ uxIndexToClear ] == taskNOTIFICATION_RECEIVED )\n            {\n                pxTCB->ucNotifyState[ uxIndexToClear ] = taskNOT_WAITING_NOTIFICATION;\n                xReturn = pdPASS;\n            }\n            else\n            {\n                xReturn = pdFAIL;\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_xTaskGenericNotifyStateClear( xReturn );\n\n        return xReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configUSE_TASK_NOTIFICATIONS == 1 )\n\n    uint32_t ulTaskGenericNotifyValueClear( TaskHandle_t xTask,\n                                            UBaseType_t uxIndexToClear,\n                                            uint32_t ulBitsToClear )\n    {\n        TCB_t * pxTCB;\n        uint32_t ulReturn;\n\n        traceENTER_ulTaskGenericNotifyValueClear( xTask, uxIndexToClear, ulBitsToClear );\n\n        configASSERT( uxIndexToClear < configTASK_NOTIFICATION_ARRAY_ENTRIES );\n\n        /* If null is passed in here then it is the calling task that is having\n         * its notification state cleared. */\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        taskENTER_CRITICAL();\n        {\n            /* Return the notification as it was before the bits were cleared,\n             * then clear the bit mask. */\n            ulReturn = pxTCB->ulNotifiedValue[ uxIndexToClear ];\n            pxTCB->ulNotifiedValue[ uxIndexToClear ] &= ~ulBitsToClear;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_ulTaskGenericNotifyValueClear( ulReturn );\n\n        return ulReturn;\n    }\n\n#endif /* configUSE_TASK_NOTIFICATIONS */\n/*-----------------------------------------------------------*/\n\n#if ( configGENERATE_RUN_TIME_STATS == 1 )\n\n    configRUN_TIME_COUNTER_TYPE ulTaskGetRunTimeCounter( const TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_ulTaskGetRunTimeCounter( xTask );\n\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        traceRETURN_ulTaskGetRunTimeCounter( pxTCB->ulRunTimeCounter );\n\n        return pxTCB->ulRunTimeCounter;\n    }\n\n#endif /* if ( configGENERATE_RUN_TIME_STATS == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( configGENERATE_RUN_TIME_STATS == 1 )\n\n    configRUN_TIME_COUNTER_TYPE ulTaskGetRunTimePercent( const TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n        configRUN_TIME_COUNTER_TYPE ulTotalTime, ulReturn;\n\n        traceENTER_ulTaskGetRunTimePercent( xTask );\n\n        ulTotalTime = ( configRUN_TIME_COUNTER_TYPE ) portGET_RUN_TIME_COUNTER_VALUE();\n\n        /* For percentage calculations. */\n        ulTotalTime /= ( configRUN_TIME_COUNTER_TYPE ) 100;\n\n        /* Avoid divide by zero errors. */\n        if( ulTotalTime > ( configRUN_TIME_COUNTER_TYPE ) 0 )\n        {\n            pxTCB = prvGetTCBFromHandle( xTask );\n            configASSERT( pxTCB != NULL );\n\n            ulReturn = pxTCB->ulRunTimeCounter / ulTotalTime;\n        }\n        else\n        {\n            ulReturn = 0;\n        }\n\n        traceRETURN_ulTaskGetRunTimePercent( ulReturn );\n\n        return ulReturn;\n    }\n\n#endif /* if ( configGENERATE_RUN_TIME_STATS == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( INCLUDE_xTaskGetIdleTaskHandle == 1 ) )\n\n    configRUN_TIME_COUNTER_TYPE ulTaskGetIdleRunTimeCounter( void )\n    {\n        configRUN_TIME_COUNTER_TYPE ulReturn = 0;\n        BaseType_t i;\n\n        traceENTER_ulTaskGetIdleRunTimeCounter();\n\n        for( i = 0; i < ( BaseType_t ) configNUMBER_OF_CORES; i++ )\n        {\n            ulReturn += xIdleTaskHandles[ i ]->ulRunTimeCounter;\n        }\n\n        traceRETURN_ulTaskGetIdleRunTimeCounter( ulReturn );\n\n        return ulReturn;\n    }\n\n#endif /* if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( INCLUDE_xTaskGetIdleTaskHandle == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( INCLUDE_xTaskGetIdleTaskHandle == 1 ) )\n\n    configRUN_TIME_COUNTER_TYPE ulTaskGetIdleRunTimePercent( void )\n    {\n        configRUN_TIME_COUNTER_TYPE ulTotalTime, ulReturn;\n        configRUN_TIME_COUNTER_TYPE ulRunTimeCounter = 0;\n        BaseType_t i;\n\n        traceENTER_ulTaskGetIdleRunTimePercent();\n\n        ulTotalTime = portGET_RUN_TIME_COUNTER_VALUE() * configNUMBER_OF_CORES;\n\n        /* For percentage calculations. */\n        ulTotalTime /= ( configRUN_TIME_COUNTER_TYPE ) 100;\n\n        /* Avoid divide by zero errors. */\n        if( ulTotalTime > ( configRUN_TIME_COUNTER_TYPE ) 0 )\n        {\n            for( i = 0; i < ( BaseType_t ) configNUMBER_OF_CORES; i++ )\n            {\n                ulRunTimeCounter += xIdleTaskHandles[ i ]->ulRunTimeCounter;\n            }\n\n            ulReturn = ulRunTimeCounter / ulTotalTime;\n        }\n        else\n        {\n            ulReturn = 0;\n        }\n\n        traceRETURN_ulTaskGetIdleRunTimePercent( ulReturn );\n\n        return ulReturn;\n    }\n\n#endif /* if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( INCLUDE_xTaskGetIdleTaskHandle == 1 ) ) */\n/*-----------------------------------------------------------*/\n\nstatic void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait,\n                                            const BaseType_t xCanBlockIndefinitely )\n{\n    TickType_t xTimeToWake;\n    const TickType_t xConstTickCount = xTickCount;\n    List_t * const pxDelayedList = pxDelayedTaskList;\n    List_t * const pxOverflowDelayedList = pxOverflowDelayedTaskList;\n\n    #if ( INCLUDE_xTaskAbortDelay == 1 )\n    {\n        /* About to enter a delayed list, so ensure the ucDelayAborted flag is\n         * reset to pdFALSE so it can be detected as having been set to pdTRUE\n         * when the task leaves the Blocked state. */\n        pxCurrentTCB->ucDelayAborted = ( uint8_t ) pdFALSE;\n    }\n    #endif\n\n    /* Remove the task from the ready list before adding it to the blocked list\n     * as the same list item is used for both lists. */\n    if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )\n    {\n        /* The current task must be in a ready list, so there is no need to\n         * check, and the port reset macro can be called directly. */\n        portRESET_READY_PRIORITY( pxCurrentTCB->uxPriority, uxTopReadyPriority );\n    }\n    else\n    {\n        mtCOVERAGE_TEST_MARKER();\n    }\n\n    #if ( INCLUDE_vTaskSuspend == 1 )\n    {\n        if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )\n        {\n            /* Add the task to the suspended task list instead of a delayed task\n             * list to ensure it is not woken by a timing event.  It will block\n             * indefinitely. */\n            listINSERT_END( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );\n        }\n        else\n        {\n            /* Calculate the time at which the task should be woken if the event\n             * does not occur.  This may overflow but this doesn't matter, the\n             * kernel will manage it correctly. */\n            xTimeToWake = xConstTickCount + xTicksToWait;\n\n            /* The list item will be inserted in wake time order. */\n            listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );\n\n            if( xTimeToWake < xConstTickCount )\n            {\n                /* Wake time has overflowed.  Place this item in the overflow\n                 * list. */\n                traceMOVED_TASK_TO_OVERFLOW_DELAYED_LIST();\n                vListInsert( pxOverflowDelayedList, &( pxCurrentTCB->xStateListItem ) );\n            }\n            else\n            {\n                /* The wake time has not overflowed, so the current block list\n                 * is used. */\n                traceMOVED_TASK_TO_DELAYED_LIST();\n                vListInsert( pxDelayedList, &( pxCurrentTCB->xStateListItem ) );\n\n                /* If the task entering the blocked state was placed at the\n                 * head of the list of blocked tasks then xNextTaskUnblockTime\n                 * needs to be updated too. */\n                if( xTimeToWake < xNextTaskUnblockTime )\n                {\n                    xNextTaskUnblockTime = xTimeToWake;\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n        }\n    }\n    #else /* INCLUDE_vTaskSuspend */\n    {\n        /* Calculate the time at which the task should be woken if the event\n         * does not occur.  This may overflow but this doesn't matter, the kernel\n         * will manage it correctly. */\n        xTimeToWake = xConstTickCount + xTicksToWait;\n\n        /* The list item will be inserted in wake time order. */\n        listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );\n\n        if( xTimeToWake < xConstTickCount )\n        {\n            traceMOVED_TASK_TO_OVERFLOW_DELAYED_LIST();\n            /* Wake time has overflowed.  Place this item in the overflow list. */\n            vListInsert( pxOverflowDelayedList, &( pxCurrentTCB->xStateListItem ) );\n        }\n        else\n        {\n            traceMOVED_TASK_TO_DELAYED_LIST();\n            /* The wake time has not overflowed, so the current block list is used. */\n            vListInsert( pxDelayedList, &( pxCurrentTCB->xStateListItem ) );\n\n            /* If the task entering the blocked state was placed at the head of the\n             * list of blocked tasks then xNextTaskUnblockTime needs to be updated\n             * too. */\n            if( xTimeToWake < xNextTaskUnblockTime )\n            {\n                xNextTaskUnblockTime = xTimeToWake;\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n\n        /* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */\n        ( void ) xCanBlockIndefinitely;\n    }\n    #endif /* INCLUDE_vTaskSuspend */\n}\n/*-----------------------------------------------------------*/\n\n#if ( portUSING_MPU_WRAPPERS == 1 )\n\n    xMPU_SETTINGS * xTaskGetMPUSettings( TaskHandle_t xTask )\n    {\n        TCB_t * pxTCB;\n\n        traceENTER_xTaskGetMPUSettings( xTask );\n\n        pxTCB = prvGetTCBFromHandle( xTask );\n        configASSERT( pxTCB != NULL );\n\n        traceRETURN_xTaskGetMPUSettings( &( pxTCB->xMPUSettings ) );\n\n        return &( pxTCB->xMPUSettings );\n    }\n\n#endif /* portUSING_MPU_WRAPPERS */\n/*-----------------------------------------------------------*/\n\n/* Code below here allows additional code to be inserted into this source file,\n * especially where access to file scope functions and data is needed (for example\n * when performing module tests). */\n\n#ifdef FREERTOS_MODULE_TEST\n    #include \"tasks_test_access_functions.h\"\n#endif\n\n\n#if ( configINCLUDE_FREERTOS_TASK_C_ADDITIONS_H == 1 )\n\n    #include \"freertos_tasks_c_additions.h\"\n\n    #ifdef FREERTOS_TASKS_C_ADDITIONS_INIT\n        static void freertos_tasks_c_additions_init( void )\n        {\n            FREERTOS_TASKS_C_ADDITIONS_INIT();\n        }\n    #endif\n\n#endif /* if ( configINCLUDE_FREERTOS_TASK_C_ADDITIONS_H == 1 ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configKERNEL_PROVIDED_STATIC_MEMORY == 1 ) && ( portUSING_MPU_WRAPPERS == 0 ) )\n\n/*\n * This is the kernel provided implementation of vApplicationGetIdleTaskMemory()\n * to provide the memory that is used by the Idle task. It is used when\n * configKERNEL_PROVIDED_STATIC_MEMORY is set to 1. The application can provide\n * it's own implementation of vApplicationGetIdleTaskMemory by setting\n * configKERNEL_PROVIDED_STATIC_MEMORY to 0 or leaving it undefined.\n */\n    void vApplicationGetIdleTaskMemory( StaticTask_t ** ppxIdleTaskTCBBuffer,\n                                        StackType_t ** ppxIdleTaskStackBuffer,\n                                        configSTACK_DEPTH_TYPE * puxIdleTaskStackSize )\n    {\n        static StaticTask_t xIdleTaskTCB;\n        static StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ];\n\n        *ppxIdleTaskTCBBuffer = &( xIdleTaskTCB );\n        *ppxIdleTaskStackBuffer = &( uxIdleTaskStack[ 0 ] );\n        *puxIdleTaskStackSize = configMINIMAL_STACK_SIZE;\n    }\n\n    #if ( configNUMBER_OF_CORES > 1 )\n\n        void vApplicationGetPassiveIdleTaskMemory( StaticTask_t ** ppxIdleTaskTCBBuffer,\n                                                   StackType_t ** ppxIdleTaskStackBuffer,\n                                                   configSTACK_DEPTH_TYPE * puxIdleTaskStackSize,\n                                                   BaseType_t xPassiveIdleTaskIndex )\n        {\n            static StaticTask_t xIdleTaskTCBs[ configNUMBER_OF_CORES - 1 ];\n            static StackType_t uxIdleTaskStacks[ configNUMBER_OF_CORES - 1 ][ configMINIMAL_STACK_SIZE ];\n\n            *ppxIdleTaskTCBBuffer = &( xIdleTaskTCBs[ xPassiveIdleTaskIndex ] );\n            *ppxIdleTaskStackBuffer = &( uxIdleTaskStacks[ xPassiveIdleTaskIndex ][ 0 ] );\n            *puxIdleTaskStackSize = configMINIMAL_STACK_SIZE;\n        }\n\n    #endif /* #if ( configNUMBER_OF_CORES > 1 ) */\n\n#endif /* #if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configKERNEL_PROVIDED_STATIC_MEMORY == 1 ) && ( portUSING_MPU_WRAPPERS == 0 ) ) */\n/*-----------------------------------------------------------*/\n\n#if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configKERNEL_PROVIDED_STATIC_MEMORY == 1 ) && ( portUSING_MPU_WRAPPERS == 0 ) && ( configUSE_TIMERS == 1 ) )\n\n/*\n * This is the kernel provided implementation of vApplicationGetTimerTaskMemory()\n * to provide the memory that is used by the Timer service task. It is used when\n * configKERNEL_PROVIDED_STATIC_MEMORY is set to 1. The application can provide\n * it's own implementation of vApplicationGetTimerTaskMemory by setting\n * configKERNEL_PROVIDED_STATIC_MEMORY to 0 or leaving it undefined.\n */\n    void vApplicationGetTimerTaskMemory( StaticTask_t ** ppxTimerTaskTCBBuffer,\n                                         StackType_t ** ppxTimerTaskStackBuffer,\n                                         configSTACK_DEPTH_TYPE * puxTimerTaskStackSize )\n    {\n        static StaticTask_t xTimerTaskTCB;\n        static StackType_t uxTimerTaskStack[ configTIMER_TASK_STACK_DEPTH ];\n\n        *ppxTimerTaskTCBBuffer = &( xTimerTaskTCB );\n        *ppxTimerTaskStackBuffer = &( uxTimerTaskStack[ 0 ] );\n        *puxTimerTaskStackSize = configTIMER_TASK_STACK_DEPTH;\n    }\n\n#endif /* #if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configKERNEL_PROVIDED_STATIC_MEMORY == 1 ) && ( portUSING_MPU_WRAPPERS == 0 ) && ( configUSE_TIMERS == 1 ) ) */\n/*-----------------------------------------------------------*/\n\n/*\n * Reset the state in this file. This state is normally initialized at start up.\n * This function must be called by the application before restarting the\n * scheduler.\n */\nvoid vTaskResetState( void )\n{\n    BaseType_t xCoreID;\n\n    /* Task control block. */\n    #if ( configNUMBER_OF_CORES == 1 )\n    {\n        pxCurrentTCB = NULL;\n    }\n    #endif /* #if ( configNUMBER_OF_CORES == 1 ) */\n\n    #if ( INCLUDE_vTaskDelete == 1 )\n    {\n        uxDeletedTasksWaitingCleanUp = ( UBaseType_t ) 0U;\n    }\n    #endif /* #if ( INCLUDE_vTaskDelete == 1 ) */\n\n    #if ( configUSE_POSIX_ERRNO == 1 )\n    {\n        FreeRTOS_errno = 0;\n    }\n    #endif /* #if ( configUSE_POSIX_ERRNO == 1 ) */\n\n    /* Other file private variables. */\n    uxCurrentNumberOfTasks = ( UBaseType_t ) 0U;\n    xTickCount = ( TickType_t ) configINITIAL_TICK_COUNT;\n    uxTopReadyPriority = tskIDLE_PRIORITY;\n    xSchedulerRunning = pdFALSE;\n    xPendedTicks = ( TickType_t ) 0U;\n\n    for( xCoreID = 0; xCoreID < configNUMBER_OF_CORES; xCoreID++ )\n    {\n        xYieldPendings[ xCoreID ] = pdFALSE;\n    }\n\n    xNumOfOverflows = ( BaseType_t ) 0;\n    uxTaskNumber = ( UBaseType_t ) 0U;\n    xNextTaskUnblockTime = ( TickType_t ) 0U;\n\n    uxSchedulerSuspended = ( UBaseType_t ) 0U;\n\n    #if ( configGENERATE_RUN_TIME_STATS == 1 )\n    {\n        for( xCoreID = 0; xCoreID < configNUMBER_OF_CORES; xCoreID++ )\n        {\n            ulTaskSwitchedInTime[ xCoreID ] = 0U;\n            ulTotalRunTime[ xCoreID ] = 0U;\n        }\n    }\n    #endif /* #if ( configGENERATE_RUN_TIME_STATS == 1 ) */\n}\n/*-----------------------------------------------------------*/\n"
        },
        {
          "name": "timers.c",
          "type": "blob",
          "size": 55.2822265625,
          "content": "/*\n * FreeRTOS Kernel <DEVELOPMENT BRANCH>\n * Copyright (C) 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy of\n * this software and associated documentation files (the \"Software\"), to deal in\n * the Software without restriction, including without limitation the rights to\n * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n * the Software, and to permit persons to whom the Software is furnished to do so,\n * subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n * https://www.FreeRTOS.org\n * https://github.com/FreeRTOS\n *\n */\n\n/* Standard includes. */\n#include <stdlib.h>\n\n/* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining\n * all the API functions to use the MPU wrappers.  That should only be done when\n * task.h is included from an application file. */\n#define MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n#include \"queue.h\"\n#include \"timers.h\"\n\n#if ( INCLUDE_xTimerPendFunctionCall == 1 ) && ( configUSE_TIMERS == 0 )\n    #error configUSE_TIMERS must be set to 1 to make the xTimerPendFunctionCall() function available.\n#endif\n\n/* The MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined\n * for the header files above, but not in this file, in order to generate the\n * correct privileged Vs unprivileged linkage and placement. */\n#undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE\n\n\n/* This entire source file will be skipped if the application is not configured\n * to include software timer functionality.  This #if is closed at the very bottom\n * of this file.  If you want to include software timer functionality then ensure\n * configUSE_TIMERS is set to 1 in FreeRTOSConfig.h. */\n#if ( configUSE_TIMERS == 1 )\n\n/* Misc definitions. */\n    #define tmrNO_DELAY                    ( ( TickType_t ) 0U )\n    #define tmrMAX_TIME_BEFORE_OVERFLOW    ( ( TickType_t ) -1 )\n\n/* The name assigned to the timer service task. This can be overridden by\n * defining configTIMER_SERVICE_TASK_NAME in FreeRTOSConfig.h. */\n    #ifndef configTIMER_SERVICE_TASK_NAME\n        #define configTIMER_SERVICE_TASK_NAME    \"Tmr Svc\"\n    #endif\n\n    #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n\n/* The core affinity assigned to the timer service task on SMP systems.\n * This can be overridden by defining configTIMER_SERVICE_TASK_CORE_AFFINITY in FreeRTOSConfig.h. */\n        #ifndef configTIMER_SERVICE_TASK_CORE_AFFINITY\n            #define configTIMER_SERVICE_TASK_CORE_AFFINITY    tskNO_AFFINITY\n        #endif\n    #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n\n/* Bit definitions used in the ucStatus member of a timer structure. */\n    #define tmrSTATUS_IS_ACTIVE                  ( 0x01U )\n    #define tmrSTATUS_IS_STATICALLY_ALLOCATED    ( 0x02U )\n    #define tmrSTATUS_IS_AUTORELOAD              ( 0x04U )\n\n/* The definition of the timers themselves. */\n    typedef struct tmrTimerControl                                               /* The old naming convention is used to prevent breaking kernel aware debuggers. */\n    {\n        const char * pcTimerName;                                                /**< Text name.  This is not used by the kernel, it is included simply to make debugging easier. */\n        ListItem_t xTimerListItem;                                               /**< Standard linked list item as used by all kernel features for event management. */\n        TickType_t xTimerPeriodInTicks;                                          /**< How quickly and often the timer expires. */\n        void * pvTimerID;                                                        /**< An ID to identify the timer.  This allows the timer to be identified when the same callback is used for multiple timers. */\n        portTIMER_CALLBACK_ATTRIBUTE TimerCallbackFunction_t pxCallbackFunction; /**< The function that will be called when the timer expires. */\n        #if ( configUSE_TRACE_FACILITY == 1 )\n            UBaseType_t uxTimerNumber;                                           /**< An ID assigned by trace tools such as FreeRTOS+Trace */\n        #endif\n        uint8_t ucStatus;                                                        /**< Holds bits to say if the timer was statically allocated or not, and if it is active or not. */\n    } xTIMER;\n\n/* The old xTIMER name is maintained above then typedefed to the new Timer_t\n * name below to enable the use of older kernel aware debuggers. */\n    typedef xTIMER Timer_t;\n\n/* The definition of messages that can be sent and received on the timer queue.\n * Two types of message can be queued - messages that manipulate a software timer,\n * and messages that request the execution of a non-timer related callback.  The\n * two message types are defined in two separate structures, xTimerParametersType\n * and xCallbackParametersType respectively. */\n    typedef struct tmrTimerParameters\n    {\n        TickType_t xMessageValue; /**< An optional value used by a subset of commands, for example, when changing the period of a timer. */\n        Timer_t * pxTimer;        /**< The timer to which the command will be applied. */\n    } TimerParameter_t;\n\n\n    typedef struct tmrCallbackParameters\n    {\n        portTIMER_CALLBACK_ATTRIBUTE\n        PendedFunction_t pxCallbackFunction; /* << The callback function to execute. */\n        void * pvParameter1;                 /* << The value that will be used as the callback functions first parameter. */\n        uint32_t ulParameter2;               /* << The value that will be used as the callback functions second parameter. */\n    } CallbackParameters_t;\n\n/* The structure that contains the two message types, along with an identifier\n * that is used to determine which message type is valid. */\n    typedef struct tmrTimerQueueMessage\n    {\n        BaseType_t xMessageID; /**< The command being sent to the timer service task. */\n        union\n        {\n            TimerParameter_t xTimerParameters;\n\n            /* Don't include xCallbackParameters if it is not going to be used as\n             * it makes the structure (and therefore the timer queue) larger. */\n            #if ( INCLUDE_xTimerPendFunctionCall == 1 )\n                CallbackParameters_t xCallbackParameters;\n            #endif /* INCLUDE_xTimerPendFunctionCall */\n        } u;\n    } DaemonTaskMessage_t;\n\n/* The list in which active timers are stored.  Timers are referenced in expire\n * time order, with the nearest expiry time at the front of the list.  Only the\n * timer service task is allowed to access these lists.\n * xActiveTimerList1 and xActiveTimerList2 could be at function scope but that\n * breaks some kernel aware debuggers, and debuggers that reply on removing the\n * static qualifier. */\n    PRIVILEGED_DATA static List_t xActiveTimerList1;\n    PRIVILEGED_DATA static List_t xActiveTimerList2;\n    PRIVILEGED_DATA static List_t * pxCurrentTimerList;\n    PRIVILEGED_DATA static List_t * pxOverflowTimerList;\n\n/* A queue that is used to send commands to the timer service task. */\n    PRIVILEGED_DATA static QueueHandle_t xTimerQueue = NULL;\n    PRIVILEGED_DATA static TaskHandle_t xTimerTaskHandle = NULL;\n\n/*-----------------------------------------------------------*/\n\n/*\n * Initialise the infrastructure used by the timer service task if it has not\n * been initialised already.\n */\n    static void prvCheckForValidListAndQueue( void ) PRIVILEGED_FUNCTION;\n\n/*\n * The timer service task (daemon).  Timer functionality is controlled by this\n * task.  Other tasks communicate with the timer service task using the\n * xTimerQueue queue.\n */\n    static portTASK_FUNCTION_PROTO( prvTimerTask, pvParameters ) PRIVILEGED_FUNCTION;\n\n/*\n * Called by the timer service task to interpret and process a command it\n * received on the timer queue.\n */\n    static void prvProcessReceivedCommands( void ) PRIVILEGED_FUNCTION;\n\n/*\n * Insert the timer into either xActiveTimerList1, or xActiveTimerList2,\n * depending on if the expire time causes a timer counter overflow.\n */\n    static BaseType_t prvInsertTimerInActiveList( Timer_t * const pxTimer,\n                                                  const TickType_t xNextExpiryTime,\n                                                  const TickType_t xTimeNow,\n                                                  const TickType_t xCommandTime ) PRIVILEGED_FUNCTION;\n\n/*\n * Reload the specified auto-reload timer.  If the reloading is backlogged,\n * clear the backlog, calling the callback for each additional reload.  When\n * this function returns, the next expiry time is after xTimeNow.\n */\n    static void prvReloadTimer( Timer_t * const pxTimer,\n                                TickType_t xExpiredTime,\n                                const TickType_t xTimeNow ) PRIVILEGED_FUNCTION;\n\n/*\n * An active timer has reached its expire time.  Reload the timer if it is an\n * auto-reload timer, then call its callback.\n */\n    static void prvProcessExpiredTimer( const TickType_t xNextExpireTime,\n                                        const TickType_t xTimeNow ) PRIVILEGED_FUNCTION;\n\n/*\n * The tick count has overflowed.  Switch the timer lists after ensuring the\n * current timer list does not still reference some timers.\n */\n    static void prvSwitchTimerLists( void ) PRIVILEGED_FUNCTION;\n\n/*\n * Obtain the current tick count, setting *pxTimerListsWereSwitched to pdTRUE\n * if a tick count overflow occurred since prvSampleTimeNow() was last called.\n */\n    static TickType_t prvSampleTimeNow( BaseType_t * const pxTimerListsWereSwitched ) PRIVILEGED_FUNCTION;\n\n/*\n * If the timer list contains any active timers then return the expire time of\n * the timer that will expire first and set *pxListWasEmpty to false.  If the\n * timer list does not contain any timers then return 0 and set *pxListWasEmpty\n * to pdTRUE.\n */\n    static TickType_t prvGetNextExpireTime( BaseType_t * const pxListWasEmpty ) PRIVILEGED_FUNCTION;\n\n/*\n * If a timer has expired, process it.  Otherwise, block the timer service task\n * until either a timer does expire or a command is received.\n */\n    static void prvProcessTimerOrBlockTask( const TickType_t xNextExpireTime,\n                                            BaseType_t xListWasEmpty ) PRIVILEGED_FUNCTION;\n\n/*\n * Called after a Timer_t structure has been allocated either statically or\n * dynamically to fill in the structure's members.\n */\n    static void prvInitialiseNewTimer( const char * const pcTimerName,\n                                       const TickType_t xTimerPeriodInTicks,\n                                       const BaseType_t xAutoReload,\n                                       void * const pvTimerID,\n                                       TimerCallbackFunction_t pxCallbackFunction,\n                                       Timer_t * pxNewTimer ) PRIVILEGED_FUNCTION;\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTimerCreateTimerTask( void )\n    {\n        BaseType_t xReturn = pdFAIL;\n\n        traceENTER_xTimerCreateTimerTask();\n\n        /* This function is called when the scheduler is started if\n         * configUSE_TIMERS is set to 1.  Check that the infrastructure used by the\n         * timer service task has been created/initialised.  If timers have already\n         * been created then the initialisation will already have been performed. */\n        prvCheckForValidListAndQueue();\n\n        if( xTimerQueue != NULL )\n        {\n            #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) )\n            {\n                #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n                {\n                    StaticTask_t * pxTimerTaskTCBBuffer = NULL;\n                    StackType_t * pxTimerTaskStackBuffer = NULL;\n                    configSTACK_DEPTH_TYPE uxTimerTaskStackSize;\n\n                    vApplicationGetTimerTaskMemory( &pxTimerTaskTCBBuffer, &pxTimerTaskStackBuffer, &uxTimerTaskStackSize );\n                    xTimerTaskHandle = xTaskCreateStaticAffinitySet( prvTimerTask,\n                                                                     configTIMER_SERVICE_TASK_NAME,\n                                                                     uxTimerTaskStackSize,\n                                                                     NULL,\n                                                                     ( ( UBaseType_t ) configTIMER_TASK_PRIORITY ) | portPRIVILEGE_BIT,\n                                                                     pxTimerTaskStackBuffer,\n                                                                     pxTimerTaskTCBBuffer,\n                                                                     configTIMER_SERVICE_TASK_CORE_AFFINITY );\n\n                    if( xTimerTaskHandle != NULL )\n                    {\n                        xReturn = pdPASS;\n                    }\n                }\n                #else /* if ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n                {\n                    xReturn = xTaskCreateAffinitySet( prvTimerTask,\n                                                      configTIMER_SERVICE_TASK_NAME,\n                                                      configTIMER_TASK_STACK_DEPTH,\n                                                      NULL,\n                                                      ( ( UBaseType_t ) configTIMER_TASK_PRIORITY ) | portPRIVILEGE_BIT,\n                                                      configTIMER_SERVICE_TASK_CORE_AFFINITY,\n                                                      &xTimerTaskHandle );\n                }\n                #endif /* configSUPPORT_STATIC_ALLOCATION */\n            }\n            #else /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n            {\n                #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n                {\n                    StaticTask_t * pxTimerTaskTCBBuffer = NULL;\n                    StackType_t * pxTimerTaskStackBuffer = NULL;\n                    configSTACK_DEPTH_TYPE uxTimerTaskStackSize;\n\n                    vApplicationGetTimerTaskMemory( &pxTimerTaskTCBBuffer, &pxTimerTaskStackBuffer, &uxTimerTaskStackSize );\n                    xTimerTaskHandle = xTaskCreateStatic( prvTimerTask,\n                                                          configTIMER_SERVICE_TASK_NAME,\n                                                          uxTimerTaskStackSize,\n                                                          NULL,\n                                                          ( ( UBaseType_t ) configTIMER_TASK_PRIORITY ) | portPRIVILEGE_BIT,\n                                                          pxTimerTaskStackBuffer,\n                                                          pxTimerTaskTCBBuffer );\n\n                    if( xTimerTaskHandle != NULL )\n                    {\n                        xReturn = pdPASS;\n                    }\n                }\n                #else /* if ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n                {\n                    xReturn = xTaskCreate( prvTimerTask,\n                                           configTIMER_SERVICE_TASK_NAME,\n                                           configTIMER_TASK_STACK_DEPTH,\n                                           NULL,\n                                           ( ( UBaseType_t ) configTIMER_TASK_PRIORITY ) | portPRIVILEGE_BIT,\n                                           &xTimerTaskHandle );\n                }\n                #endif /* configSUPPORT_STATIC_ALLOCATION */\n            }\n            #endif /* #if ( ( configNUMBER_OF_CORES > 1 ) && ( configUSE_CORE_AFFINITY == 1 ) ) */\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        configASSERT( xReturn );\n\n        traceRETURN_xTimerCreateTimerTask( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n\n        TimerHandle_t xTimerCreate( const char * const pcTimerName,\n                                    const TickType_t xTimerPeriodInTicks,\n                                    const BaseType_t xAutoReload,\n                                    void * const pvTimerID,\n                                    TimerCallbackFunction_t pxCallbackFunction )\n        {\n            Timer_t * pxNewTimer;\n\n            traceENTER_xTimerCreate( pcTimerName, xTimerPeriodInTicks, xAutoReload, pvTimerID, pxCallbackFunction );\n\n            /* MISRA Ref 11.5.1 [Malloc memory assignment] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n            /* coverity[misra_c_2012_rule_11_5_violation] */\n            pxNewTimer = ( Timer_t * ) pvPortMalloc( sizeof( Timer_t ) );\n\n            if( pxNewTimer != NULL )\n            {\n                /* Status is thus far zero as the timer is not created statically\n                 * and has not been started.  The auto-reload bit may get set in\n                 * prvInitialiseNewTimer. */\n                pxNewTimer->ucStatus = 0x00;\n                prvInitialiseNewTimer( pcTimerName, xTimerPeriodInTicks, xAutoReload, pvTimerID, pxCallbackFunction, pxNewTimer );\n            }\n\n            traceRETURN_xTimerCreate( pxNewTimer );\n\n            return pxNewTimer;\n        }\n\n    #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n\n        TimerHandle_t xTimerCreateStatic( const char * const pcTimerName,\n                                          const TickType_t xTimerPeriodInTicks,\n                                          const BaseType_t xAutoReload,\n                                          void * const pvTimerID,\n                                          TimerCallbackFunction_t pxCallbackFunction,\n                                          StaticTimer_t * pxTimerBuffer )\n        {\n            Timer_t * pxNewTimer;\n\n            traceENTER_xTimerCreateStatic( pcTimerName, xTimerPeriodInTicks, xAutoReload, pvTimerID, pxCallbackFunction, pxTimerBuffer );\n\n            #if ( configASSERT_DEFINED == 1 )\n            {\n                /* Sanity check that the size of the structure used to declare a\n                 * variable of type StaticTimer_t equals the size of the real timer\n                 * structure. */\n                volatile size_t xSize = sizeof( StaticTimer_t );\n                configASSERT( xSize == sizeof( Timer_t ) );\n                ( void ) xSize; /* Prevent unused variable warning when configASSERT() is not defined. */\n            }\n            #endif /* configASSERT_DEFINED */\n\n            /* A pointer to a StaticTimer_t structure MUST be provided, use it. */\n            configASSERT( pxTimerBuffer );\n            /* MISRA Ref 11.3.1 [Misaligned access] */\n            /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n            /* coverity[misra_c_2012_rule_11_3_violation] */\n            pxNewTimer = ( Timer_t * ) pxTimerBuffer;\n\n            if( pxNewTimer != NULL )\n            {\n                /* Timers can be created statically or dynamically so note this\n                 * timer was created statically in case it is later deleted.  The\n                 * auto-reload bit may get set in prvInitialiseNewTimer(). */\n                pxNewTimer->ucStatus = ( uint8_t ) tmrSTATUS_IS_STATICALLY_ALLOCATED;\n\n                prvInitialiseNewTimer( pcTimerName, xTimerPeriodInTicks, xAutoReload, pvTimerID, pxCallbackFunction, pxNewTimer );\n            }\n\n            traceRETURN_xTimerCreateStatic( pxNewTimer );\n\n            return pxNewTimer;\n        }\n\n    #endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    static void prvInitialiseNewTimer( const char * const pcTimerName,\n                                       const TickType_t xTimerPeriodInTicks,\n                                       const BaseType_t xAutoReload,\n                                       void * const pvTimerID,\n                                       TimerCallbackFunction_t pxCallbackFunction,\n                                       Timer_t * pxNewTimer )\n    {\n        /* 0 is not a valid value for xTimerPeriodInTicks. */\n        configASSERT( ( xTimerPeriodInTicks > 0 ) );\n\n        /* Ensure the infrastructure used by the timer service task has been\n         * created/initialised. */\n        prvCheckForValidListAndQueue();\n\n        /* Initialise the timer structure members using the function\n         * parameters. */\n        pxNewTimer->pcTimerName = pcTimerName;\n        pxNewTimer->xTimerPeriodInTicks = xTimerPeriodInTicks;\n        pxNewTimer->pvTimerID = pvTimerID;\n        pxNewTimer->pxCallbackFunction = pxCallbackFunction;\n        vListInitialiseItem( &( pxNewTimer->xTimerListItem ) );\n\n        if( xAutoReload != pdFALSE )\n        {\n            pxNewTimer->ucStatus |= ( uint8_t ) tmrSTATUS_IS_AUTORELOAD;\n        }\n\n        traceTIMER_CREATE( pxNewTimer );\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTimerGenericCommandFromTask( TimerHandle_t xTimer,\n                                             const BaseType_t xCommandID,\n                                             const TickType_t xOptionalValue,\n                                             BaseType_t * const pxHigherPriorityTaskWoken,\n                                             const TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn = pdFAIL;\n        DaemonTaskMessage_t xMessage;\n\n        ( void ) pxHigherPriorityTaskWoken;\n\n        traceENTER_xTimerGenericCommandFromTask( xTimer, xCommandID, xOptionalValue, pxHigherPriorityTaskWoken, xTicksToWait );\n\n        configASSERT( xTimer );\n\n        /* Send a message to the timer service task to perform a particular action\n         * on a particular timer definition. */\n        if( xTimerQueue != NULL )\n        {\n            /* Send a command to the timer service task to start the xTimer timer. */\n            xMessage.xMessageID = xCommandID;\n            xMessage.u.xTimerParameters.xMessageValue = xOptionalValue;\n            xMessage.u.xTimerParameters.pxTimer = xTimer;\n\n            configASSERT( xCommandID < tmrFIRST_FROM_ISR_COMMAND );\n\n            if( xCommandID < tmrFIRST_FROM_ISR_COMMAND )\n            {\n                if( xTaskGetSchedulerState() == taskSCHEDULER_RUNNING )\n                {\n                    xReturn = xQueueSendToBack( xTimerQueue, &xMessage, xTicksToWait );\n                }\n                else\n                {\n                    xReturn = xQueueSendToBack( xTimerQueue, &xMessage, tmrNO_DELAY );\n                }\n            }\n\n            traceTIMER_COMMAND_SEND( xTimer, xCommandID, xOptionalValue, xReturn );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTimerGenericCommandFromTask( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTimerGenericCommandFromISR( TimerHandle_t xTimer,\n                                            const BaseType_t xCommandID,\n                                            const TickType_t xOptionalValue,\n                                            BaseType_t * const pxHigherPriorityTaskWoken,\n                                            const TickType_t xTicksToWait )\n    {\n        BaseType_t xReturn = pdFAIL;\n        DaemonTaskMessage_t xMessage;\n\n        ( void ) xTicksToWait;\n\n        traceENTER_xTimerGenericCommandFromISR( xTimer, xCommandID, xOptionalValue, pxHigherPriorityTaskWoken, xTicksToWait );\n\n        configASSERT( xTimer );\n\n        /* Send a message to the timer service task to perform a particular action\n         * on a particular timer definition. */\n        if( xTimerQueue != NULL )\n        {\n            /* Send a command to the timer service task to start the xTimer timer. */\n            xMessage.xMessageID = xCommandID;\n            xMessage.u.xTimerParameters.xMessageValue = xOptionalValue;\n            xMessage.u.xTimerParameters.pxTimer = xTimer;\n\n            configASSERT( xCommandID >= tmrFIRST_FROM_ISR_COMMAND );\n\n            if( xCommandID >= tmrFIRST_FROM_ISR_COMMAND )\n            {\n                xReturn = xQueueSendToBackFromISR( xTimerQueue, &xMessage, pxHigherPriorityTaskWoken );\n            }\n\n            traceTIMER_COMMAND_SEND( xTimer, xCommandID, xOptionalValue, xReturn );\n        }\n        else\n        {\n            mtCOVERAGE_TEST_MARKER();\n        }\n\n        traceRETURN_xTimerGenericCommandFromISR( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    TaskHandle_t xTimerGetTimerDaemonTaskHandle( void )\n    {\n        traceENTER_xTimerGetTimerDaemonTaskHandle();\n\n        /* If xTimerGetTimerDaemonTaskHandle() is called before the scheduler has been\n         * started, then xTimerTaskHandle will be NULL. */\n        configASSERT( ( xTimerTaskHandle != NULL ) );\n\n        traceRETURN_xTimerGetTimerDaemonTaskHandle( xTimerTaskHandle );\n\n        return xTimerTaskHandle;\n    }\n/*-----------------------------------------------------------*/\n\n    TickType_t xTimerGetPeriod( TimerHandle_t xTimer )\n    {\n        Timer_t * pxTimer = xTimer;\n\n        traceENTER_xTimerGetPeriod( xTimer );\n\n        configASSERT( xTimer );\n\n        traceRETURN_xTimerGetPeriod( pxTimer->xTimerPeriodInTicks );\n\n        return pxTimer->xTimerPeriodInTicks;\n    }\n/*-----------------------------------------------------------*/\n\n    void vTimerSetReloadMode( TimerHandle_t xTimer,\n                              const BaseType_t xAutoReload )\n    {\n        Timer_t * pxTimer = xTimer;\n\n        traceENTER_vTimerSetReloadMode( xTimer, xAutoReload );\n\n        configASSERT( xTimer );\n        taskENTER_CRITICAL();\n        {\n            if( xAutoReload != pdFALSE )\n            {\n                pxTimer->ucStatus |= ( uint8_t ) tmrSTATUS_IS_AUTORELOAD;\n            }\n            else\n            {\n                pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_AUTORELOAD );\n            }\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTimerSetReloadMode();\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTimerGetReloadMode( TimerHandle_t xTimer )\n    {\n        Timer_t * pxTimer = xTimer;\n        BaseType_t xReturn;\n\n        traceENTER_xTimerGetReloadMode( xTimer );\n\n        configASSERT( xTimer );\n        portBASE_TYPE_ENTER_CRITICAL();\n        {\n            if( ( pxTimer->ucStatus & tmrSTATUS_IS_AUTORELOAD ) == 0U )\n            {\n                /* Not an auto-reload timer. */\n                xReturn = pdFALSE;\n            }\n            else\n            {\n                /* Is an auto-reload timer. */\n                xReturn = pdTRUE;\n            }\n        }\n        portBASE_TYPE_EXIT_CRITICAL();\n\n        traceRETURN_xTimerGetReloadMode( xReturn );\n\n        return xReturn;\n    }\n\n    UBaseType_t uxTimerGetReloadMode( TimerHandle_t xTimer )\n    {\n        UBaseType_t uxReturn;\n\n        traceENTER_uxTimerGetReloadMode( xTimer );\n\n        uxReturn = ( UBaseType_t ) xTimerGetReloadMode( xTimer );\n\n        traceRETURN_uxTimerGetReloadMode( uxReturn );\n\n        return uxReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    TickType_t xTimerGetExpiryTime( TimerHandle_t xTimer )\n    {\n        Timer_t * pxTimer = xTimer;\n        TickType_t xReturn;\n\n        traceENTER_xTimerGetExpiryTime( xTimer );\n\n        configASSERT( xTimer );\n        xReturn = listGET_LIST_ITEM_VALUE( &( pxTimer->xTimerListItem ) );\n\n        traceRETURN_xTimerGetExpiryTime( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n        BaseType_t xTimerGetStaticBuffer( TimerHandle_t xTimer,\n                                          StaticTimer_t ** ppxTimerBuffer )\n        {\n            BaseType_t xReturn;\n            Timer_t * pxTimer = xTimer;\n\n            traceENTER_xTimerGetStaticBuffer( xTimer, ppxTimerBuffer );\n\n            configASSERT( ppxTimerBuffer != NULL );\n\n            if( ( pxTimer->ucStatus & tmrSTATUS_IS_STATICALLY_ALLOCATED ) != 0U )\n            {\n                /* MISRA Ref 11.3.1 [Misaligned access] */\n                /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-113 */\n                /* coverity[misra_c_2012_rule_11_3_violation] */\n                *ppxTimerBuffer = ( StaticTimer_t * ) pxTimer;\n                xReturn = pdTRUE;\n            }\n            else\n            {\n                xReturn = pdFALSE;\n            }\n\n            traceRETURN_xTimerGetStaticBuffer( xReturn );\n\n            return xReturn;\n        }\n    #endif /* configSUPPORT_STATIC_ALLOCATION */\n/*-----------------------------------------------------------*/\n\n    const char * pcTimerGetName( TimerHandle_t xTimer )\n    {\n        Timer_t * pxTimer = xTimer;\n\n        traceENTER_pcTimerGetName( xTimer );\n\n        configASSERT( xTimer );\n\n        traceRETURN_pcTimerGetName( pxTimer->pcTimerName );\n\n        return pxTimer->pcTimerName;\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvReloadTimer( Timer_t * const pxTimer,\n                                TickType_t xExpiredTime,\n                                const TickType_t xTimeNow )\n    {\n        /* Insert the timer into the appropriate list for the next expiry time.\n         * If the next expiry time has already passed, advance the expiry time,\n         * call the callback function, and try again. */\n        while( prvInsertTimerInActiveList( pxTimer, ( xExpiredTime + pxTimer->xTimerPeriodInTicks ), xTimeNow, xExpiredTime ) != pdFALSE )\n        {\n            /* Advance the expiry time. */\n            xExpiredTime += pxTimer->xTimerPeriodInTicks;\n\n            /* Call the timer callback. */\n            traceTIMER_EXPIRED( pxTimer );\n            pxTimer->pxCallbackFunction( ( TimerHandle_t ) pxTimer );\n        }\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvProcessExpiredTimer( const TickType_t xNextExpireTime,\n                                        const TickType_t xTimeNow )\n    {\n        /* MISRA Ref 11.5.3 [Void pointer assignment] */\n        /* More details at: https://github.com/FreeRTOS/FreeRTOS-Kernel/blob/main/MISRA.md#rule-115 */\n        /* coverity[misra_c_2012_rule_11_5_violation] */\n        Timer_t * const pxTimer = ( Timer_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxCurrentTimerList );\n\n        /* Remove the timer from the list of active timers.  A check has already\n         * been performed to ensure the list is not empty. */\n\n        ( void ) uxListRemove( &( pxTimer->xTimerListItem ) );\n\n        /* If the timer is an auto-reload timer then calculate the next\n         * expiry time and re-insert the timer in the list of active timers. */\n        if( ( pxTimer->ucStatus & tmrSTATUS_IS_AUTORELOAD ) != 0U )\n        {\n            prvReloadTimer( pxTimer, xNextExpireTime, xTimeNow );\n        }\n        else\n        {\n            pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_ACTIVE );\n        }\n\n        /* Call the timer callback. */\n        traceTIMER_EXPIRED( pxTimer );\n        pxTimer->pxCallbackFunction( ( TimerHandle_t ) pxTimer );\n    }\n/*-----------------------------------------------------------*/\n\n    static portTASK_FUNCTION( prvTimerTask, pvParameters )\n    {\n        TickType_t xNextExpireTime;\n        BaseType_t xListWasEmpty;\n\n        /* Just to avoid compiler warnings. */\n        ( void ) pvParameters;\n\n        #if ( configUSE_DAEMON_TASK_STARTUP_HOOK == 1 )\n        {\n            /* Allow the application writer to execute some code in the context of\n             * this task at the point the task starts executing.  This is useful if the\n             * application includes initialisation code that would benefit from\n             * executing after the scheduler has been started. */\n            vApplicationDaemonTaskStartupHook();\n        }\n        #endif /* configUSE_DAEMON_TASK_STARTUP_HOOK */\n\n        for( ; configCONTROL_INFINITE_LOOP(); )\n        {\n            /* Query the timers list to see if it contains any timers, and if so,\n             * obtain the time at which the next timer will expire. */\n            xNextExpireTime = prvGetNextExpireTime( &xListWasEmpty );\n\n            /* If a timer has expired, process it.  Otherwise, block this task\n             * until either a timer does expire, or a command is received. */\n            prvProcessTimerOrBlockTask( xNextExpireTime, xListWasEmpty );\n\n            /* Empty the command queue. */\n            prvProcessReceivedCommands();\n        }\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvProcessTimerOrBlockTask( const TickType_t xNextExpireTime,\n                                            BaseType_t xListWasEmpty )\n    {\n        TickType_t xTimeNow;\n        BaseType_t xTimerListsWereSwitched;\n\n        vTaskSuspendAll();\n        {\n            /* Obtain the time now to make an assessment as to whether the timer\n             * has expired or not.  If obtaining the time causes the lists to switch\n             * then don't process this timer as any timers that remained in the list\n             * when the lists were switched will have been processed within the\n             * prvSampleTimeNow() function. */\n            xTimeNow = prvSampleTimeNow( &xTimerListsWereSwitched );\n\n            if( xTimerListsWereSwitched == pdFALSE )\n            {\n                /* The tick count has not overflowed, has the timer expired? */\n                if( ( xListWasEmpty == pdFALSE ) && ( xNextExpireTime <= xTimeNow ) )\n                {\n                    ( void ) xTaskResumeAll();\n                    prvProcessExpiredTimer( xNextExpireTime, xTimeNow );\n                }\n                else\n                {\n                    /* The tick count has not overflowed, and the next expire\n                     * time has not been reached yet.  This task should therefore\n                     * block to wait for the next expire time or a command to be\n                     * received - whichever comes first.  The following line cannot\n                     * be reached unless xNextExpireTime > xTimeNow, except in the\n                     * case when the current timer list is empty. */\n                    if( xListWasEmpty != pdFALSE )\n                    {\n                        /* The current timer list is empty - is the overflow list\n                         * also empty? */\n                        xListWasEmpty = listLIST_IS_EMPTY( pxOverflowTimerList );\n                    }\n\n                    vQueueWaitForMessageRestricted( xTimerQueue, ( xNextExpireTime - xTimeNow ), xListWasEmpty );\n\n                    if( xTaskResumeAll() == pdFALSE )\n                    {\n                        /* Yield to wait for either a command to arrive, or the\n                         * block time to expire.  If a command arrived between the\n                         * critical section being exited and this yield then the yield\n                         * will not cause the task to block. */\n                        taskYIELD_WITHIN_API();\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n            }\n            else\n            {\n                ( void ) xTaskResumeAll();\n            }\n        }\n    }\n/*-----------------------------------------------------------*/\n\n    static TickType_t prvGetNextExpireTime( BaseType_t * const pxListWasEmpty )\n    {\n        TickType_t xNextExpireTime;\n\n        /* Timers are listed in expiry time order, with the head of the list\n         * referencing the task that will expire first.  Obtain the time at which\n         * the timer with the nearest expiry time will expire.  If there are no\n         * active timers then just set the next expire time to 0.  That will cause\n         * this task to unblock when the tick count overflows, at which point the\n         * timer lists will be switched and the next expiry time can be\n         * re-assessed.  */\n        *pxListWasEmpty = listLIST_IS_EMPTY( pxCurrentTimerList );\n\n        if( *pxListWasEmpty == pdFALSE )\n        {\n            xNextExpireTime = listGET_ITEM_VALUE_OF_HEAD_ENTRY( pxCurrentTimerList );\n        }\n        else\n        {\n            /* Ensure the task unblocks when the tick count rolls over. */\n            xNextExpireTime = ( TickType_t ) 0U;\n        }\n\n        return xNextExpireTime;\n    }\n/*-----------------------------------------------------------*/\n\n    static TickType_t prvSampleTimeNow( BaseType_t * const pxTimerListsWereSwitched )\n    {\n        TickType_t xTimeNow;\n        PRIVILEGED_DATA static TickType_t xLastTime = ( TickType_t ) 0U;\n\n        xTimeNow = xTaskGetTickCount();\n\n        if( xTimeNow < xLastTime )\n        {\n            prvSwitchTimerLists();\n            *pxTimerListsWereSwitched = pdTRUE;\n        }\n        else\n        {\n            *pxTimerListsWereSwitched = pdFALSE;\n        }\n\n        xLastTime = xTimeNow;\n\n        return xTimeNow;\n    }\n/*-----------------------------------------------------------*/\n\n    static BaseType_t prvInsertTimerInActiveList( Timer_t * const pxTimer,\n                                                  const TickType_t xNextExpiryTime,\n                                                  const TickType_t xTimeNow,\n                                                  const TickType_t xCommandTime )\n    {\n        BaseType_t xProcessTimerNow = pdFALSE;\n\n        listSET_LIST_ITEM_VALUE( &( pxTimer->xTimerListItem ), xNextExpiryTime );\n        listSET_LIST_ITEM_OWNER( &( pxTimer->xTimerListItem ), pxTimer );\n\n        if( xNextExpiryTime <= xTimeNow )\n        {\n            /* Has the expiry time elapsed between the command to start/reset a\n             * timer was issued, and the time the command was processed? */\n            if( ( ( TickType_t ) ( xTimeNow - xCommandTime ) ) >= pxTimer->xTimerPeriodInTicks )\n            {\n                /* The time between a command being issued and the command being\n                 * processed actually exceeds the timers period.  */\n                xProcessTimerNow = pdTRUE;\n            }\n            else\n            {\n                vListInsert( pxOverflowTimerList, &( pxTimer->xTimerListItem ) );\n            }\n        }\n        else\n        {\n            if( ( xTimeNow < xCommandTime ) && ( xNextExpiryTime >= xCommandTime ) )\n            {\n                /* If, since the command was issued, the tick count has overflowed\n                 * but the expiry time has not, then the timer must have already passed\n                 * its expiry time and should be processed immediately. */\n                xProcessTimerNow = pdTRUE;\n            }\n            else\n            {\n                vListInsert( pxCurrentTimerList, &( pxTimer->xTimerListItem ) );\n            }\n        }\n\n        return xProcessTimerNow;\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvProcessReceivedCommands( void )\n    {\n        DaemonTaskMessage_t xMessage = { 0 };\n        Timer_t * pxTimer;\n        BaseType_t xTimerListsWereSwitched;\n        TickType_t xTimeNow;\n\n        while( xQueueReceive( xTimerQueue, &xMessage, tmrNO_DELAY ) != pdFAIL )\n        {\n            #if ( INCLUDE_xTimerPendFunctionCall == 1 )\n            {\n                /* Negative commands are pended function calls rather than timer\n                 * commands. */\n                if( xMessage.xMessageID < ( BaseType_t ) 0 )\n                {\n                    const CallbackParameters_t * const pxCallback = &( xMessage.u.xCallbackParameters );\n\n                    /* The timer uses the xCallbackParameters member to request a\n                     * callback be executed.  Check the callback is not NULL. */\n                    configASSERT( pxCallback );\n\n                    /* Call the function. */\n                    pxCallback->pxCallbackFunction( pxCallback->pvParameter1, pxCallback->ulParameter2 );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n            }\n            #endif /* INCLUDE_xTimerPendFunctionCall */\n\n            /* Commands that are positive are timer commands rather than pended\n             * function calls. */\n            if( xMessage.xMessageID >= ( BaseType_t ) 0 )\n            {\n                /* The messages uses the xTimerParameters member to work on a\n                 * software timer. */\n                pxTimer = xMessage.u.xTimerParameters.pxTimer;\n\n                if( listIS_CONTAINED_WITHIN( NULL, &( pxTimer->xTimerListItem ) ) == pdFALSE )\n                {\n                    /* The timer is in a list, remove it. */\n                    ( void ) uxListRemove( &( pxTimer->xTimerListItem ) );\n                }\n                else\n                {\n                    mtCOVERAGE_TEST_MARKER();\n                }\n\n                traceTIMER_COMMAND_RECEIVED( pxTimer, xMessage.xMessageID, xMessage.u.xTimerParameters.xMessageValue );\n\n                /* In this case the xTimerListsWereSwitched parameter is not used, but\n                 *  it must be present in the function call.  prvSampleTimeNow() must be\n                 *  called after the message is received from xTimerQueue so there is no\n                 *  possibility of a higher priority task adding a message to the message\n                 *  queue with a time that is ahead of the timer daemon task (because it\n                 *  pre-empted the timer daemon task after the xTimeNow value was set). */\n                xTimeNow = prvSampleTimeNow( &xTimerListsWereSwitched );\n\n                switch( xMessage.xMessageID )\n                {\n                    case tmrCOMMAND_START:\n                    case tmrCOMMAND_START_FROM_ISR:\n                    case tmrCOMMAND_RESET:\n                    case tmrCOMMAND_RESET_FROM_ISR:\n                        /* Start or restart a timer. */\n                        pxTimer->ucStatus |= ( uint8_t ) tmrSTATUS_IS_ACTIVE;\n\n                        if( prvInsertTimerInActiveList( pxTimer, xMessage.u.xTimerParameters.xMessageValue + pxTimer->xTimerPeriodInTicks, xTimeNow, xMessage.u.xTimerParameters.xMessageValue ) != pdFALSE )\n                        {\n                            /* The timer expired before it was added to the active\n                             * timer list.  Process it now. */\n                            if( ( pxTimer->ucStatus & tmrSTATUS_IS_AUTORELOAD ) != 0U )\n                            {\n                                prvReloadTimer( pxTimer, xMessage.u.xTimerParameters.xMessageValue + pxTimer->xTimerPeriodInTicks, xTimeNow );\n                            }\n                            else\n                            {\n                                pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_ACTIVE );\n                            }\n\n                            /* Call the timer callback. */\n                            traceTIMER_EXPIRED( pxTimer );\n                            pxTimer->pxCallbackFunction( ( TimerHandle_t ) pxTimer );\n                        }\n                        else\n                        {\n                            mtCOVERAGE_TEST_MARKER();\n                        }\n\n                        break;\n\n                    case tmrCOMMAND_STOP:\n                    case tmrCOMMAND_STOP_FROM_ISR:\n                        /* The timer has already been removed from the active list. */\n                        pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_ACTIVE );\n                        break;\n\n                    case tmrCOMMAND_CHANGE_PERIOD:\n                    case tmrCOMMAND_CHANGE_PERIOD_FROM_ISR:\n                        pxTimer->ucStatus |= ( uint8_t ) tmrSTATUS_IS_ACTIVE;\n                        pxTimer->xTimerPeriodInTicks = xMessage.u.xTimerParameters.xMessageValue;\n                        configASSERT( ( pxTimer->xTimerPeriodInTicks > 0 ) );\n\n                        /* The new period does not really have a reference, and can\n                         * be longer or shorter than the old one.  The command time is\n                         * therefore set to the current time, and as the period cannot\n                         * be zero the next expiry time can only be in the future,\n                         * meaning (unlike for the xTimerStart() case above) there is\n                         * no fail case that needs to be handled here. */\n                        ( void ) prvInsertTimerInActiveList( pxTimer, ( xTimeNow + pxTimer->xTimerPeriodInTicks ), xTimeNow, xTimeNow );\n                        break;\n\n                    case tmrCOMMAND_DELETE:\n                        #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )\n                        {\n                            /* The timer has already been removed from the active list,\n                             * just free up the memory if the memory was dynamically\n                             * allocated. */\n                            if( ( pxTimer->ucStatus & tmrSTATUS_IS_STATICALLY_ALLOCATED ) == ( uint8_t ) 0 )\n                            {\n                                vPortFree( pxTimer );\n                            }\n                            else\n                            {\n                                pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_ACTIVE );\n                            }\n                        }\n                        #else /* if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) */\n                        {\n                            /* If dynamic allocation is not enabled, the memory\n                             * could not have been dynamically allocated. So there is\n                             * no need to free the memory - just mark the timer as\n                             * \"not active\". */\n                            pxTimer->ucStatus &= ( ( uint8_t ) ~tmrSTATUS_IS_ACTIVE );\n                        }\n                        #endif /* configSUPPORT_DYNAMIC_ALLOCATION */\n                        break;\n\n                    default:\n                        /* Don't expect to get here. */\n                        break;\n                }\n            }\n        }\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvSwitchTimerLists( void )\n    {\n        TickType_t xNextExpireTime;\n        List_t * pxTemp;\n\n        /* The tick count has overflowed.  The timer lists must be switched.\n         * If there are any timers still referenced from the current timer list\n         * then they must have expired and should be processed before the lists\n         * are switched. */\n        while( listLIST_IS_EMPTY( pxCurrentTimerList ) == pdFALSE )\n        {\n            xNextExpireTime = listGET_ITEM_VALUE_OF_HEAD_ENTRY( pxCurrentTimerList );\n\n            /* Process the expired timer.  For auto-reload timers, be careful to\n             * process only expirations that occur on the current list.  Further\n             * expirations must wait until after the lists are switched. */\n            prvProcessExpiredTimer( xNextExpireTime, tmrMAX_TIME_BEFORE_OVERFLOW );\n        }\n\n        pxTemp = pxCurrentTimerList;\n        pxCurrentTimerList = pxOverflowTimerList;\n        pxOverflowTimerList = pxTemp;\n    }\n/*-----------------------------------------------------------*/\n\n    static void prvCheckForValidListAndQueue( void )\n    {\n        /* Check that the list from which active timers are referenced, and the\n         * queue used to communicate with the timer service, have been\n         * initialised. */\n        taskENTER_CRITICAL();\n        {\n            if( xTimerQueue == NULL )\n            {\n                vListInitialise( &xActiveTimerList1 );\n                vListInitialise( &xActiveTimerList2 );\n                pxCurrentTimerList = &xActiveTimerList1;\n                pxOverflowTimerList = &xActiveTimerList2;\n\n                #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\n                {\n                    /* The timer queue is allocated statically in case\n                     * configSUPPORT_DYNAMIC_ALLOCATION is 0. */\n                    PRIVILEGED_DATA static StaticQueue_t xStaticTimerQueue;\n                    PRIVILEGED_DATA static uint8_t ucStaticTimerQueueStorage[ ( size_t ) configTIMER_QUEUE_LENGTH * sizeof( DaemonTaskMessage_t ) ];\n\n                    xTimerQueue = xQueueCreateStatic( ( UBaseType_t ) configTIMER_QUEUE_LENGTH, ( UBaseType_t ) sizeof( DaemonTaskMessage_t ), &( ucStaticTimerQueueStorage[ 0 ] ), &xStaticTimerQueue );\n                }\n                #else\n                {\n                    xTimerQueue = xQueueCreate( ( UBaseType_t ) configTIMER_QUEUE_LENGTH, ( UBaseType_t ) sizeof( DaemonTaskMessage_t ) );\n                }\n                #endif /* if ( configSUPPORT_STATIC_ALLOCATION == 1 ) */\n\n                #if ( configQUEUE_REGISTRY_SIZE > 0 )\n                {\n                    if( xTimerQueue != NULL )\n                    {\n                        vQueueAddToRegistry( xTimerQueue, \"TmrQ\" );\n                    }\n                    else\n                    {\n                        mtCOVERAGE_TEST_MARKER();\n                    }\n                }\n                #endif /* configQUEUE_REGISTRY_SIZE */\n            }\n            else\n            {\n                mtCOVERAGE_TEST_MARKER();\n            }\n        }\n        taskEXIT_CRITICAL();\n    }\n/*-----------------------------------------------------------*/\n\n    BaseType_t xTimerIsTimerActive( TimerHandle_t xTimer )\n    {\n        BaseType_t xReturn;\n        Timer_t * pxTimer = xTimer;\n\n        traceENTER_xTimerIsTimerActive( xTimer );\n\n        configASSERT( xTimer );\n\n        /* Is the timer in the list of active timers? */\n        portBASE_TYPE_ENTER_CRITICAL();\n        {\n            if( ( pxTimer->ucStatus & tmrSTATUS_IS_ACTIVE ) == 0U )\n            {\n                xReturn = pdFALSE;\n            }\n            else\n            {\n                xReturn = pdTRUE;\n            }\n        }\n        portBASE_TYPE_EXIT_CRITICAL();\n\n        traceRETURN_xTimerIsTimerActive( xReturn );\n\n        return xReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    void * pvTimerGetTimerID( const TimerHandle_t xTimer )\n    {\n        Timer_t * const pxTimer = xTimer;\n        void * pvReturn;\n\n        traceENTER_pvTimerGetTimerID( xTimer );\n\n        configASSERT( xTimer );\n\n        taskENTER_CRITICAL();\n        {\n            pvReturn = pxTimer->pvTimerID;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_pvTimerGetTimerID( pvReturn );\n\n        return pvReturn;\n    }\n/*-----------------------------------------------------------*/\n\n    void vTimerSetTimerID( TimerHandle_t xTimer,\n                           void * pvNewID )\n    {\n        Timer_t * const pxTimer = xTimer;\n\n        traceENTER_vTimerSetTimerID( xTimer, pvNewID );\n\n        configASSERT( xTimer );\n\n        taskENTER_CRITICAL();\n        {\n            pxTimer->pvTimerID = pvNewID;\n        }\n        taskEXIT_CRITICAL();\n\n        traceRETURN_vTimerSetTimerID();\n    }\n/*-----------------------------------------------------------*/\n\n    #if ( INCLUDE_xTimerPendFunctionCall == 1 )\n\n        BaseType_t xTimerPendFunctionCallFromISR( PendedFunction_t xFunctionToPend,\n                                                  void * pvParameter1,\n                                                  uint32_t ulParameter2,\n                                                  BaseType_t * pxHigherPriorityTaskWoken )\n        {\n            DaemonTaskMessage_t xMessage;\n            BaseType_t xReturn;\n\n            traceENTER_xTimerPendFunctionCallFromISR( xFunctionToPend, pvParameter1, ulParameter2, pxHigherPriorityTaskWoken );\n\n            /* Complete the message with the function parameters and post it to the\n             * daemon task. */\n            xMessage.xMessageID = tmrCOMMAND_EXECUTE_CALLBACK_FROM_ISR;\n            xMessage.u.xCallbackParameters.pxCallbackFunction = xFunctionToPend;\n            xMessage.u.xCallbackParameters.pvParameter1 = pvParameter1;\n            xMessage.u.xCallbackParameters.ulParameter2 = ulParameter2;\n\n            xReturn = xQueueSendFromISR( xTimerQueue, &xMessage, pxHigherPriorityTaskWoken );\n\n            tracePEND_FUNC_CALL_FROM_ISR( xFunctionToPend, pvParameter1, ulParameter2, xReturn );\n            traceRETURN_xTimerPendFunctionCallFromISR( xReturn );\n\n            return xReturn;\n        }\n\n    #endif /* INCLUDE_xTimerPendFunctionCall */\n/*-----------------------------------------------------------*/\n\n    #if ( INCLUDE_xTimerPendFunctionCall == 1 )\n\n        BaseType_t xTimerPendFunctionCall( PendedFunction_t xFunctionToPend,\n                                           void * pvParameter1,\n                                           uint32_t ulParameter2,\n                                           TickType_t xTicksToWait )\n        {\n            DaemonTaskMessage_t xMessage;\n            BaseType_t xReturn;\n\n            traceENTER_xTimerPendFunctionCall( xFunctionToPend, pvParameter1, ulParameter2, xTicksToWait );\n\n            /* This function can only be called after a timer has been created or\n             * after the scheduler has been started because, until then, the timer\n             * queue does not exist. */\n            configASSERT( xTimerQueue );\n\n            /* Complete the message with the function parameters and post it to the\n             * daemon task. */\n            xMessage.xMessageID = tmrCOMMAND_EXECUTE_CALLBACK;\n            xMessage.u.xCallbackParameters.pxCallbackFunction = xFunctionToPend;\n            xMessage.u.xCallbackParameters.pvParameter1 = pvParameter1;\n            xMessage.u.xCallbackParameters.ulParameter2 = ulParameter2;\n\n            xReturn = xQueueSendToBack( xTimerQueue, &xMessage, xTicksToWait );\n\n            tracePEND_FUNC_CALL( xFunctionToPend, pvParameter1, ulParameter2, xReturn );\n            traceRETURN_xTimerPendFunctionCall( xReturn );\n\n            return xReturn;\n        }\n\n    #endif /* INCLUDE_xTimerPendFunctionCall */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n        UBaseType_t uxTimerGetTimerNumber( TimerHandle_t xTimer )\n        {\n            traceENTER_uxTimerGetTimerNumber( xTimer );\n\n            traceRETURN_uxTimerGetTimerNumber( ( ( Timer_t * ) xTimer )->uxTimerNumber );\n\n            return ( ( Timer_t * ) xTimer )->uxTimerNumber;\n        }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n    #if ( configUSE_TRACE_FACILITY == 1 )\n\n        void vTimerSetTimerNumber( TimerHandle_t xTimer,\n                                   UBaseType_t uxTimerNumber )\n        {\n            traceENTER_vTimerSetTimerNumber( xTimer, uxTimerNumber );\n\n            ( ( Timer_t * ) xTimer )->uxTimerNumber = uxTimerNumber;\n\n            traceRETURN_vTimerSetTimerNumber();\n        }\n\n    #endif /* configUSE_TRACE_FACILITY */\n/*-----------------------------------------------------------*/\n\n/*\n * Reset the state in this file. This state is normally initialized at start up.\n * This function must be called by the application before restarting the\n * scheduler.\n */\n    void vTimerResetState( void )\n    {\n        xTimerQueue = NULL;\n        xTimerTaskHandle = NULL;\n    }\n/*-----------------------------------------------------------*/\n\n/* This entire source file will be skipped if the application is not configured\n * to include software timer functionality.  If you want to include software timer\n * functionality then ensure configUSE_TIMERS is set to 1 in FreeRTOSConfig.h. */\n#endif /* configUSE_TIMERS == 1 */\n"
        }
      ]
    }
  ]
}