{
  "metadata": {
    "timestamp": 1736710177276,
    "page": 860,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Maratyszcza/NNPACK",
      "stars": 1682,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2001953125,
          "content": "# Ninja files\nbuild.ninja\n\n# Build objects and artifacts\ndeps/\nbuild/\nbuild-*/\nbin/\nlib/\nout/\nobj/\nlibs/\n*.pyc\n*.pyo\n\n# System files\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.640625,
          "content": "language: c\ncompiler: clang\ninstall:\n - git clone https://github.com/ninja-build/ninja.git /tmp/ninja\n - pushd /tmp/ninja\n - git checkout release\n - python configure.py --bootstrap\n - mkdir -p $HOME/.local/bin\n - install -m 755 /tmp/ninja/ninja $HOME/.local/bin/ninja\n - popd\n - export PATH=$HOME/.local/bin:$PATH\n - pip install --user git+https://github.com/Maratyszcza/PeachPy\n - pip install --user git+https://github.com/Maratyszcza/confu\nbefore_script:\n - confu setup\n - python ./configure.py --toolchain=clang --backend=$BACKEND\n - ninja\nscript:\n - ninja smoketest\naddons:\n  apt:\n    packages:\n    - python-pip\nenv:\n - BACKEND=psimd\n - BACKEND=scalar\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 36.693359375,
          "content": "CMAKE_MINIMUM_REQUIRED(VERSION 2.8.12 FATAL_ERROR)\n\nINCLUDE(GNUInstallDirs)\nINCLUDE(CheckCSourceCompiles)\n\n# ---[ Project and semantic versioning.\nPROJECT(NNPACK C CXX ASM)\n\n# ---[ Options.\nSET(NNPACK_BACKEND \"auto\" CACHE STRING \"Backend for micro-kernels implementation\")\nSET_PROPERTY(CACHE NNPACK_BACKEND PROPERTY STRINGS auto psimd scalar)\nOPTION(NNPACK_CONVOLUTION_ONLY \"Build only NNPACK functions for convolutional layer\" OFF)\nOPTION(NNPACK_INFERENCE_ONLY \"Build only NNPACK functions for inference\" OFF)\nOPTION(NNPACK_CUSTOM_THREADPOOL \"Build NNPACK for custom thread pool\" OFF)\nSET(NNPACK_LIBRARY_TYPE \"default\" CACHE STRING \"Type of library (shared, static, or default) to build\")\nSET_PROPERTY(CACHE NNPACK_LIBRARY_TYPE PROPERTY STRINGS default static shared)\nOPTION(NNPACK_BUILD_TESTS \"Build NNPACK unit tests\" ON)\n\n# ---[ CMake options\nIF(NNPACK_BUILD_TESTS)\n  ENABLE_TESTING()\nENDIF()\n\nMACRO(NNPACK_TARGET_ENABLE_C99 target)\n  IF(${CMAKE_VERSION} VERSION_LESS \"3.1\")\n    IF(NOT MSVC)\n      TARGET_COMPILE_OPTIONS(${target} PRIVATE -std=c99)\n    ENDIF()\n  ELSE()\n    SET_TARGET_PROPERTIES(${target} PROPERTIES\n      C_STANDARD 99\n      C_EXTENSIONS YES)\n  ENDIF()\nENDMACRO()\n\nMACRO(NNPACK_TARGET_ENABLE_CXX11 target)\n  IF(${CMAKE_VERSION} VERSION_LESS \"3.1\")\n    IF(NOT MSVC)\n      TARGET_COMPILE_OPTIONS(${target} PRIVATE -std=gnu++11)\n    ENDIF()\n  ELSE()\n    SET_TARGET_PROPERTIES(${target} PROPERTIES\n      CXX_STANDARD 11\n      CXX_STANDARD_REQUIRED YES\n      CXX_EXTENSIONS YES)\n  ENDIF()\nENDMACRO()\n\n# --- [ Determine target processor\nSET(NNPACK_TARGET_PROCESSOR \"${CMAKE_SYSTEM_PROCESSOR}\")\nIF(CMAKE_SYSTEM_NAME STREQUAL \"Darwin\" AND CMAKE_OSX_ARCHITECTURES MATCHES \"^(x86_64|arm64)$\")\n  SET(NNPACK_TARGET_PROCESSOR \"${CMAKE_OSX_ARCHITECTURES}\")\nENDIF()\n\n# ---[ Build flags\nIF(NOT CMAKE_SYSTEM_PROCESSOR)\n  IF(NOT IOS)\n    MESSAGE(WARNING \"CMAKE_SYSTEM_PROCESSOR is not defined, automatic configuration may choose suboptimal options\")\n  ENDIF()\nELSEIF(NOT NNPACK_TARGET_PROCESSOR MATCHES \"^(i686|x86_64|armv5te|armv7-a|armv7l|armv7|armv7s|aarch64|arm64|arm64e)$\")\n  MESSAGE(FATAL_ERROR \"Unrecognized NNPACK_TARGET_PROCESSOR = ${NNPACK_TARGET_PROCESSOR}\")\nENDIF()\n\nIF(NOT CMAKE_SYSTEM_NAME)\n  MESSAGE(FATAL_ERROR \"CMAKE_SYSTEM_NAME not defined\")\nELSEIF(NOT CMAKE_SYSTEM_NAME MATCHES \"^(Darwin|Linux|Android)$\")\n  # ---[ iOS/tvOS/watchOS cross-compilation support begins in CMake 3.14\n  IF(${CMAKE_VERSION} VERSION_GREATER_EQUAL \"3.14\" AND NOT CMAKE_SYSTEM_NAME STREQUAL \"iOS\")\n    MESSAGE(FATAL_ERROR \"Unrecognized CMAKE_SYSTEM_NAME = ${CMAKE_SYSTEM_NAME}\")\n  ENDIF()\nENDIF()\n\nIF(NNPACK_BACKEND STREQUAL \"auto\")\n  IF(IOS)\n    IF(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(armv7|armv7s|arm64|arm64e|aarch64)$\")\n      SET(NNPACK_BACKEND \"neon\")\n    ELSE()\n      SET(NNPACK_BACKEND \"psimd\")\n    ENDIF()\n  ELSEIF(CMAKE_SYSTEM_NAME STREQUAL \"Emscripten\")\n    SET(NNPACK_BACKEND \"scalar\")\n  ELSEIF(NOT CMAKE_SYSTEM_PROCESSOR)\n    MESSAGE(WARNING \"CMAKE_SYSTEM_PROCESSOR is not defined, using PSIMD backend\")    \n    SET(NNPACK_BACKEND \"psimd\")\n  ELSEIF(NNPACK_TARGET_PROCESSOR STREQUAL \"x86_64\" AND NOT CMAKE_SYSTEM_NAME STREQUAL \"Android\")\n    # ---[ CMAKE_SYSTEM_PROCESSOR will show x86_64 when we're compiling on 32 bit systems on 64 bit cpus\n    CHECK_C_SOURCE_COMPILES(\"\n      #if ! (defined(__i386) || defined(_M_IX86))\n        #error AVX only on x86_64\n      #endif\n      int main() {\n        return 0;\n      }\" NNPACK_ARCH_IS_X86_32)\n    IF(NNPACK_ARCH_IS_X86_32)\n      MESSAGE(STATUS \"compiling for x86_32 on a 64bit machine, use to PSIMD backend\")\n      SET(NNPACK_BACKEND \"psimd\")\n    ELSE()\n      # ---[ now we know it is a \"real\" x86-64 system\n      SET(NNPACK_BACKEND \"x86-64\")\n    ENDIF()\n  ELSEIF(NNPACK_TARGET_PROCESSOR MATCHES \"^(armv5te|armv7-a|armv7l|aarch64|arm64)$\")\n    SET(NNPACK_BACKEND \"neon\")\n  ELSE()\n    SET(NNPACK_BACKEND \"psimd\")\n  ENDIF()\nENDIF()\n\nIF(NNPACK_BACKEND STREQUAL \"x86-64\")\n  # ---[ We need a Python interpreter to build PeachPy sources for x86-64\n  FIND_PACKAGE(PythonInterp)\n  IF(NOT PYTHONINTERP_FOUND)\n    MESSAGE(STATUS \"Python interpreter not found; and PeachPy sources for x86-64 backend can't be built without it. Fall back to PSIMD backend\")\n    SET(NNPACK_BACKEND \"psimd\")\n  ENDIF()\nENDIF()\n\nMESSAGE(STATUS \"NNPACK backend is ${NNPACK_BACKEND}\")\n\n# ---[ Download deps\nSET(CONFU_DEPENDENCIES_SOURCE_DIR ${CMAKE_SOURCE_DIR}/deps\n  CACHE PATH \"Confu-style dependencies source directory\")\nSET(CONFU_DEPENDENCIES_BINARY_DIR ${CMAKE_BINARY_DIR}/deps\n  CACHE PATH \"Confu-style dependencies binary directory\")\n\nIF(NNPACK_BACKEND STREQUAL \"x86-64\")\n  IF(NOT DEFINED PYTHON_SIX_SOURCE_DIR)\n    MESSAGE(STATUS \"Downloading six (Python package) to ${CONFU_DEPENDENCIES_SOURCE_DIR}/six (define PYTHON_SIX_SOURCE_DIR to avoid it)\")\n    CONFIGURE_FILE(cmake/DownloadSix.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/six-download/CMakeLists.txt\")\n    EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n      WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/six-download\")\n    EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n      WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/six-download\")\n    SET(PYTHON_SIX_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/six\" CACHE STRING \"six (Python package) source directory\")\n  ENDIF()\n\n  IF(NOT DEFINED PYTHON_ENUM_SOURCE_DIR)\n    IF(${PYTHON_VERSION_STRING} VERSION_LESS 3.4)\n      # ---[ Python < 3.4 does not natively support enums, and needs a polyfill\n      MESSAGE(STATUS \"Downloading enum (Python package) to ${CONFU_DEPENDENCIES_SOURCE_DIR}/enum (define PYTHON_ENUM_SOURCE_DIR to avoid it)\")\n      CONFIGURE_FILE(cmake/DownloadEnum.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/enum-download/CMakeLists.txt\")\n      EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n        WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/enum-download\")\n      EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n        WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/enum-download\")\n      SET(PYTHON_ENUM_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/enum\" CACHE STRING \"enum (Python package) source directory\")\n    ELSE()\n      SET(PYTHON_ENUM_SOURCE_DIR \"\" CACHE STRING \"enum (Python package) source directory\")\n    ENDIF()\n  ENDIF()\n\n  IF(NOT DEFINED PYTHON_PEACHPY_SOURCE_DIR)\n    # ---[ PeachPy requires Opcodes for installation\n    IF(NOT DEFINED PYTHON_OPCODES_SOURCE_DIR)\n      MESSAGE(STATUS \"Downloading opcodes (Python package) to ${CONFU_DEPENDENCIES_SOURCE_DIR}/opcodes (define PYTHON_OPCODES_SOURCE_DIR to avoid it)\")\n      CONFIGURE_FILE(cmake/DownloadOpcodes.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/opcodes-download/CMakeLists.txt\")\n      EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n        WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/opcodes-download\")\n      EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n        WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/opcodes-download\")\n      SET(PYTHON_OPCODES_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/opcodes\" CACHE STRING \"opcodes (Python package) source directory\")\n    ENDIF()\n\n    MESSAGE(STATUS \"Downloading PeachPy (Python package) to ${CONFU_DEPENDENCIES_SOURCE_DIR}/peachpy (define PYTHON_PEACHPY_SOURCE_DIR to avoid it)\")\n    CONFIGURE_FILE(cmake/DownloadPeachPy.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/peachpy-download/CMakeLists.txt\")\n    EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n      WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/peachpy-download\")\n    EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n      WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/peachpy-download\")\n    SET(PYTHON_PEACHPY_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/peachpy\" CACHE STRING \"PeachPy (Python package) source directory\")\n  ENDIF()\n\n  IF(${PYTHON_VERSION_STRING} VERSION_LESS 3.4)\n    # ---[ Python < 3.4 does not natively support enums, and needs a polyfill\n    SET(PEACHPY_PYTHONPATH \"${PYTHON_SIX_SOURCE_DIR}:${PYTHON_ENUM_SOURCE_DIR}:${PYTHON_PEACHPY_SOURCE_DIR}\")\n  ELSE()\n    SET(PEACHPY_PYTHONPATH \"${PYTHON_SIX_SOURCE_DIR}:${PYTHON_PEACHPY_SOURCE_DIR}\")\n  ENDIF()\nENDIF()\n\nIF(NOT DEFINED CPUINFO_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading cpuinfo to ${CONFU_DEPENDENCIES_SOURCE_DIR}/cpuinfo (define CPUINFO_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadCpuinfo.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/cpuinfo-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/cpuinfo-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/cpuinfo-download\")\n  SET(CPUINFO_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/cpuinfo\" CACHE STRING \"cpuinfo source directory\")\nENDIF()\n\nIF(NOT DEFINED FP16_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading FP16 to ${CONFU_DEPENDENCIES_SOURCE_DIR}/fp16 (define FP16_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadFP16.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/fp16-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/fp16-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/fp16-download\")\n  SET(FP16_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/fp16\" CACHE STRING \"FP16 source directory\")\nENDIF()\n\nIF(NOT DEFINED FXDIV_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading FXdiv to ${CONFU_DEPENDENCIES_SOURCE_DIR}/fxdiv (define FXDIV_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadFXdiv.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/fxdiv-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/fxdiv-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/fxdiv-download\")\n  SET(FXDIV_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/fxdiv\" CACHE STRING \"FXdiv source directory\")\nENDIF()\n\nIF(NOT DEFINED PSIMD_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading PSimd to ${CONFU_DEPENDENCIES_SOURCE_DIR}/psimd (define PSIMD_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadPSimd.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/psimd-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/psimd-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/psimd-download\")\n  SET(PSIMD_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/psimd\" CACHE STRING \"PSimd source directory\")\nENDIF()\n\nIF(NOT DEFINED PTHREADPOOL_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading pthreadpool to ${CONFU_DEPENDENCIES_SOURCE_DIR}/pthreadpool (define PTHREADPOOL_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadPThreadPool.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/pthreadpool-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/pthreadpool-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/pthreadpool-download\")\n  SET(PTHREADPOOL_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/pthreadpool\" CACHE STRING \"pthreadpool source directory\")\nENDIF()\n\nIF(NNPACK_BUILD_TESTS AND NOT DEFINED GOOGLETEST_SOURCE_DIR)\n  MESSAGE(STATUS \"Downloading Google Test to ${CONFU_DEPENDENCIES_SOURCE_DIR}/googletest (define GOOGLETEST_SOURCE_DIR to avoid it)\")\n  CONFIGURE_FILE(cmake/DownloadGoogleTest.cmake \"${CONFU_DEPENDENCIES_BINARY_DIR}/googletest-download/CMakeLists.txt\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" -G \"${CMAKE_GENERATOR}\" .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/googletest-download\")\n  EXECUTE_PROCESS(COMMAND \"${CMAKE_COMMAND}\" --build .\n    WORKING_DIRECTORY \"${CONFU_DEPENDENCIES_BINARY_DIR}/googletest-download\")\n  SET(GOOGLETEST_SOURCE_DIR \"${CONFU_DEPENDENCIES_SOURCE_DIR}/googletest\" CACHE STRING \"Google Test source directory\")\nENDIF()\n\n# ---[ NNPACK library\nSET(NNPACK_INIT_SRCS src/init.c)\nSET(NNPACK_LAYER_SRCS src/convolution-inference.c)\nIF(NOT NNPACK_CONVOLUTION_ONLY)\n  LIST(APPEND NNPACK_LAYER_SRCS\n    src/fully-connected-inference.c\n    src/pooling-output.c\n    src/relu-output.c\n    src/softmax-output.c)\n  IF(NOT NNPACK_INFERENCE_ONLY)\n    LIST(APPEND NNPACK_LAYER_SRCS\n      src/fully-connected-output.c\n      src/relu-input-gradient.c)\n  ENDIF()\nENDIF()\nIF(NOT NNPACK_INFERENCE_ONLY)\n  LIST(APPEND NNPACK_LAYER_SRCS\n    src/convolution-input-gradient.c\n    src/convolution-kernel-gradient.c\n    src/convolution-output.c)\nENDIF()\n\nSET(NNPACK_REFERENCE_LAYERS_SRCS\n  src/ref/convolution-output.c\n  src/ref/convolution-input-gradient.c\n  src/ref/convolution-kernel.c\n  src/ref/fully-connected-output.c\n  src/ref/max-pooling-output.c\n  src/ref/softmax-output.c\n  src/ref/relu-output.c\n  src/ref/relu-input-gradient.c)\n\nSET(NNPACK_REFERENCE_FFT_SRCS\n  src/ref/fft/aos.c\n  src/ref/fft/soa.c\n  src/ref/fft/forward-real.c\n  src/ref/fft/forward-dualreal.c\n  src/ref/fft/inverse-real.c\n  src/ref/fft/inverse-dualreal.c)\n\nIF(NNPACK_BACKEND STREQUAL \"x86-64\")\n  SET(NNPACK_BACKEND_SRCS\n    # Transformations\n    src/x86_64-fma/2d-fourier-8x8.py\n    src/x86_64-fma/2d-fourier-16x16.py\n    src/x86_64-fma/2d-winograd-8x8-3x3.py\n    # Tuple GEMM\n    src/x86_64-fma/blas/s8gemm.py\n    src/x86_64-fma/blas/c8gemm.py\n    src/x86_64-fma/blas/s4c6gemm.py\n    # Direct convolution\n    src/x86_64-fma/blas/conv1x1.py\n    # BLAS microkernels\n    src/x86_64-fma/blas/sgemm.py)\n  IF(NOT NNPACK_CONVOLUTION_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # Pooling\n      src/x86_64-fma/max-pooling.py\n      # ReLU\n      src/x86_64-fma/relu.py\n      # Softmax\n      src/x86_64-fma/softmax.py\n      src/x86_64-fma/softmax.c\n      # BLAS microkernels\n      src/x86_64-fma/blas/sdotxf.py\n      src/x86_64-fma/blas/shdotxf.py)\n  ENDIF()\nELSEIF(NNPACK_BACKEND STREQUAL \"scalar\")\n  SET(NNPACK_BACKEND_SRCS\n    # Transformations\n    src/scalar/2d-fourier-8x8.c\n    src/scalar/2d-fourier-16x16.c\n    src/scalar/2d-winograd-8x8-3x3.c\n    # Tuple GEMM\n    src/scalar/blas/s2gemm.c\n    src/scalar/blas/cgemm-conjb.c\n    # Direct convolution\n    src/scalar/blas/conv1x1.c\n    # BLAS microkernels\n    src/scalar/blas/sgemm.c)\n  IF(NOT NNPACK_CONVOLUTION_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # ReLU and Softmax\n      src/scalar/relu.c\n      src/scalar/softmax.c\n      # BLAS microkernels\n      src/scalar/blas/sdotxf.c\n      src/scalar/blas/shdotxf.c)\n  ENDIF()\n  IF(NOT NNPACK_INFERENCE_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # Tuple GEMM\n      src/scalar/blas/s2gemm-transc.c\n      src/scalar/blas/cgemm.c\n      src/scalar/blas/cgemm-conjb-transc.c)\n  ENDIF()\nELSEIF(NNPACK_BACKEND STREQUAL \"neon\")\n  SET(NNPACK_BACKEND_SRCS\n    # Transformations\n    src/psimd/2d-fourier-8x8.c\n    src/psimd/2d-fourier-16x16.c\n    src/neon/2d-winograd-8x8-3x3.c\n    src/neon/2d-winograd-8x8-3x3-fp16.c\n    # Tuple GEMM\n    src/neon/blas/h4gemm.c\n    src/neon/blas/s4gemm.c\n    src/neon/blas/c4gemm-conjb.c\n    src/neon/blas/s4c2gemm-conjb.c\n    # Direct convolution\n    src/neon/blas/conv1x1.c\n    # BLAS microkernels\n    src/neon/blas/sgemm.c)\n  IF(CMAKE_SYSTEM_PROCESSOR MATCHES \"^armv\")\n    # 32-bit ARM (armv7, armv7-a, armv7l, etc)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # BLAS microkernels\n      src/neon/blas/h4gemm-aarch32.S\n      src/neon/blas/s4gemm-aarch32.S\n      src/neon/blas/sgemm-aarch32.S)\n  ENDIF()\n  IF(NOT NNPACK_CONVOLUTION_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # ReLU\n      src/neon/relu.c\n      # Softmax\n      src/psimd/softmax.c\n      # BLAS microkernels\n      src/neon/blas/sdotxf.c\n      src/psimd/blas/shdotxf.c)\n  ENDIF()\n  IF(NOT NNPACK_INFERENCE_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # Tuple GEMM\n      src/neon/blas/c4gemm.c\n      src/neon/blas/s4c2gemm.c\n      src/neon/blas/c4gemm-conjb-transc.c\n      src/neon/blas/s4c2gemm-conjb-transc.c)\n  ENDIF()\nELSEIF(NNPACK_BACKEND STREQUAL \"psimd\")\n  SET(NNPACK_BACKEND_SRCS\n    # Transformations\n    src/psimd/2d-fourier-8x8.c\n    src/psimd/2d-fourier-16x16.c\n    src/psimd/2d-winograd-8x8-3x3.c\n    # Tuple GEMM\n    src/psimd/blas/s4gemm.c\n    src/psimd/blas/c4gemm-conjb.c\n    src/psimd/blas/s4c2gemm-conjb.c\n    # Direct convolution\n    src/psimd/blas/conv1x1.c\n    # BLAS microkernels\n    src/psimd/blas/sgemm.c)\n  IF(NOT NNPACK_CONVOLUTION_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # ReLU\n      src/psimd/relu.c\n      # Softmax\n      src/psimd/softmax.c\n      # BLAS microkernels\n      src/psimd/blas/sdotxf.c\n      src/psimd/blas/shdotxf.c)\n  ENDIF()\n  IF(NOT NNPACK_INFERENCE_ONLY)\n    LIST(APPEND NNPACK_BACKEND_SRCS\n      # Tuple GEMM\n      src/psimd/blas/c4gemm.c\n      src/psimd/blas/s4c2gemm.c\n      src/psimd/blas/c4gemm-conjb-transc.c\n      src/psimd/blas/s4c2gemm-conjb-transc.c)\n  ENDIF()\nENDIF()\n\nFILE(GLOB_RECURSE PEACHPY_POTENTIAL_DEPS \"src/*.py\")\n\nSET(NNPACK_BACKEND_PEACHPY_OBJS)\nIF(NNPACK_BACKEND STREQUAL \"x86-64\")\n  SET(NNPACK_BACKEND_C_SRCS)\n  IF(CMAKE_SYSTEM_NAME STREQUAL \"Darwin\" OR CMAKE_SYSTEM_NAME STREQUAL \"iOS\")\n    SET(PEACHPY_IMAGE_FORMAT mach-o)\n  ELSE()\n    SET(PEACHPY_IMAGE_FORMAT elf)\n  ENDIF()\n  FOREACH(src ${NNPACK_BACKEND_SRCS})\n    GET_FILENAME_COMPONENT(src_ext ${src} EXT)\n    IF(src_ext STREQUAL \".py\")\n      SET(obj \"${PROJECT_BINARY_DIR}/${src}${CMAKE_C_OUTPUT_EXTENSION}\")\n      GET_FILENAME_COMPONENT(obj_dir ${obj} DIRECTORY)\n      FILE(MAKE_DIRECTORY ${obj_dir})\n      ADD_CUSTOM_COMMAND(\n        OUTPUT ${obj}\n        COMMAND \"PYTHONPATH=${PEACHPY_PYTHONPATH}\"\n          ${PYTHON_EXECUTABLE} -m peachpy.x86_64\n            -mabi=sysv -g4 -mimage-format=${PEACHPY_IMAGE_FORMAT}\n            \"-I${PROJECT_SOURCE_DIR}/src\" \"-I${PROJECT_SOURCE_DIR}/src/x86_64-fma\" \"-I${FP16_SOURCE_DIR}/include\"\n            -o ${obj} \"${PROJECT_SOURCE_DIR}/${src}\"\n        DEPENDS ${NNPACK_BACKEND_PEACHPY_OBJS})\n      LIST(APPEND NNPACK_BACKEND_PEACHPY_OBJS ${obj})\n    ELSE()\n      LIST(APPEND NNPACK_BACKEND_C_SRCS ${src})\n    ENDIF()\n  ENDFOREACH(src)\nELSE()\n  SET(NNPACK_BACKEND_C_SRCS ${NNPACK_BACKEND_SRCS})\nENDIF()\n\nIF(NNPACK_LIBRARY_TYPE STREQUAL \"default\")\n  ADD_LIBRARY(nnpack ${NNPACK_INIT_SRCS} ${NNPACK_LAYER_SRCS} ${NNPACK_BACKEND_C_SRCS} ${NNPACK_BACKEND_PEACHPY_OBJS})\nELSEIF(NNPACK_LIBRARY_TYPE STREQUAL \"shared\")\n  ADD_LIBRARY(nnpack SHARED ${NNPACK_INIT_SRCS} ${NNPACK_LAYER_SRCS} ${NNPACK_BACKEND_C_SRCS} ${NNPACK_BACKEND_PEACHPY_OBJS})\nELSEIF(NNPACK_LIBRARY_TYPE STREQUAL \"static\")\n  ADD_LIBRARY(nnpack STATIC ${NNPACK_INIT_SRCS} ${NNPACK_LAYER_SRCS} ${NNPACK_BACKEND_C_SRCS} ${NNPACK_BACKEND_PEACHPY_OBJS})\nELSE()\n  MESSAGE(FATAL_ERROR \"Unsupported NNPACK library type \\\"${NNPACK_LIBRARY_TYPE}\\\". Must be \\\"static\\\", \\\"shared\\\", or \\\"default\\\"\")\nENDIF()\nNNPACK_TARGET_ENABLE_C99(nnpack)\nIF(IOS OR CMAKE_SYSTEM_PROCESSOR MATCHES \"^(armv5te|armv7-a|armv7l)$\")\n  IF(IOS AND NNPACK_BACKEND STREQUAL \"neon\")\n    SET_PROPERTY(SOURCE ${NNPACK_BACKEND_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -mfpu=neon-vfpv4 \")\n  ELSE()\n    SET_PROPERTY(SOURCE ${NNPACK_BACKEND_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -mfpu=neon-fp16 \")\n  ENDIF()\n\n  INCLUDE(CheckCCompilerFlag)\n  CHECK_C_COMPILER_FLAG(-mfp16-format=ieee COMPILER_SUPPORTS_FP16_FORMAT)\n  IF(COMPILER_SUPPORTS_FP16_FORMAT)\n    SET_PROPERTY(SOURCE ${NNPACK_BACKEND_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -mfp16-format=ieee \")\n  ENDIF()\nENDIF()\nSET_PROPERTY(SOURCE ${NNPACK_INIT_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -Os \")\nIF(NOT CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n  SET_PROPERTY(SOURCE ${NNPACK_LAYER_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -O2 \")\nENDIF()\nIF(NOT CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n  SET_PROPERTY(SOURCE ${NNPACK_BACKEND_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS \" -O3 \")\nENDIF()\nTARGET_INCLUDE_DIRECTORIES(nnpack PUBLIC include)\nTARGET_INCLUDE_DIRECTORIES(nnpack PRIVATE src)\nIF(NNPACK_BACKEND STREQUAL \"psimd\")\n  TARGET_COMPILE_DEFINITIONS(nnpack PRIVATE NNP_BACKEND_PSIMD=1)\nELSEIF(NNPACK_BACKEND STREQUAL \"scalar\")\n  TARGET_COMPILE_DEFINITIONS(nnpack PRIVATE NNP_BACKEND_SCALAR=1)\nENDIF()\nIF(NNPACK_CONVOLUTION_ONLY)\n  TARGET_COMPILE_DEFINITIONS(nnpack PUBLIC NNP_CONVOLUTION_ONLY=1)\nELSE()\n  TARGET_COMPILE_DEFINITIONS(nnpack PUBLIC NNP_CONVOLUTION_ONLY=0)\nENDIF()\nIF(NNPACK_INFERENCE_ONLY)\n  TARGET_COMPILE_DEFINITIONS(nnpack PUBLIC NNP_INFERENCE_ONLY=1)\nELSE()\n  TARGET_COMPILE_DEFINITIONS(nnpack PUBLIC NNP_INFERENCE_ONLY=0)\nENDIF()\nSET_TARGET_PROPERTIES(nnpack PROPERTIES PUBLIC_HEADER include/nnpack.h)\n\nADD_LIBRARY(nnpack_reference_layers STATIC ${NNPACK_REFERENCE_LAYERS_SRCS})\nNNPACK_TARGET_ENABLE_C99(nnpack_reference_layers)\nTARGET_INCLUDE_DIRECTORIES(nnpack_reference_layers PUBLIC include)\n\n# ---[ Configure cpuinfo\nIF(NOT TARGET cpuinfo)\n  SET(CPUINFO_BUILD_TOOLS OFF CACHE BOOL \"\")\n  SET(CPUINFO_BUILD_UNIT_TESTS OFF CACHE BOOL \"\")\n  SET(CPUINFO_BUILD_MOCK_TESTS OFF CACHE BOOL \"\")\n  SET(CPUINFO_BUILD_BENCHMARKS OFF CACHE BOOL \"\")\n  ADD_SUBDIRECTORY(\n    \"${CPUINFO_SOURCE_DIR}\"\n    \"${CONFU_DEPENDENCIES_BINARY_DIR}/cpuinfo\")\nENDIF()\nTARGET_LINK_LIBRARIES(nnpack PRIVATE cpuinfo)\n\n# ---[ Configure pthreadpool\nIF(NOT TARGET pthreadpool)\n  SET(PTHREADPOOL_BUILD_TESTS OFF CACHE BOOL \"\")\n  SET(PTHREADPOOL_BUILD_BENCHMARKS OFF CACHE BOOL \"\")\n  ADD_SUBDIRECTORY(\n    \"${PTHREADPOOL_SOURCE_DIR}\"\n    \"${CONFU_DEPENDENCIES_BINARY_DIR}/pthreadpool\")\nENDIF()\nIF(NNPACK_CUSTOM_THREADPOOL)\n  # Depend on pthreadpool interface, but not on implementation.\n  # This is used when NNPACK user (e.g. Caffe2) provides its own threadpool implementation.\n  TARGET_LINK_LIBRARIES(nnpack PUBLIC pthreadpool_interface)\nELSE()\n  TARGET_LINK_LIBRARIES(nnpack PUBLIC pthreadpool)\nENDIF()\nTARGET_LINK_LIBRARIES(nnpack_reference_layers PUBLIC pthreadpool)\n\n# ---[ Configure FXdiv\nIF(NOT TARGET fxdiv)\n  SET(FXDIV_BUILD_TESTS OFF CACHE BOOL \"\")\n  SET(FXDIV_BUILD_BENCHMARKS OFF CACHE BOOL \"\")\n  ADD_SUBDIRECTORY(\n    \"${FXDIV_SOURCE_DIR}\"\n    \"${CONFU_DEPENDENCIES_BINARY_DIR}/fxdiv\")\nENDIF()\nTARGET_LINK_LIBRARIES(nnpack PRIVATE fxdiv)\n\n# ---[ Configure psimd\nIF(NOT TARGET psimd)\n  ADD_SUBDIRECTORY(\n    \"${PSIMD_SOURCE_DIR}\"\n    \"${CONFU_DEPENDENCIES_BINARY_DIR}/psimd\")\nENDIF()\nTARGET_LINK_LIBRARIES(nnpack PRIVATE psimd)\n\n# ---[ Configure FP16\nIF(NOT TARGET fp16)\n  SET(FP16_BUILD_TESTS OFF CACHE BOOL \"\")\n  SET(FP16_BUILD_BENCHMARKS OFF CACHE BOOL \"\")\n  ADD_SUBDIRECTORY(\n    \"${FP16_SOURCE_DIR}\"\n    \"${CONFU_DEPENDENCIES_BINARY_DIR}/fp16\")\nENDIF()\nTARGET_LINK_LIBRARIES(nnpack PRIVATE fp16)\nTARGET_LINK_LIBRARIES(nnpack_reference_layers PUBLIC fp16)\n\nINSTALL(TARGETS nnpack\n    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    PUBLIC_HEADER DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\nIF(NNPACK_BUILD_TESTS)\n  # ---[ Build google test\n  IF(NOT TARGET gtest)\n    SET(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE)\n    ADD_SUBDIRECTORY(\n      \"${GOOGLETEST_SOURCE_DIR}\"\n      \"${CONFU_DEPENDENCIES_BINARY_DIR}/googletest\")\n  ENDIF()\n\n  ADD_EXECUTABLE(convolution-inference-smoketest test/convolution-inference/smoke.cc)\n  NNPACK_TARGET_ENABLE_CXX11(convolution-inference-smoketest)\n  TARGET_INCLUDE_DIRECTORIES(convolution-inference-smoketest PRIVATE test)\n  TARGET_LINK_LIBRARIES(convolution-inference-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n  ADD_TEST(convolution-inference-smoketest convolution-inference-smoketest)\n\n  ADD_EXECUTABLE(convolution-inference-alexnet-test test/convolution-inference/alexnet.cc)\n  NNPACK_TARGET_ENABLE_CXX11(convolution-inference-alexnet-test)\n  TARGET_INCLUDE_DIRECTORIES(convolution-inference-alexnet-test PRIVATE test)\n  TARGET_LINK_LIBRARIES(convolution-inference-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n  ADD_TEST(convolution-inference-alexnet convolution-inference-alexnet-test)\n\n  ADD_EXECUTABLE(convolution-inference-overfeat-test test/convolution-inference/overfeat-fast.cc)\n  NNPACK_TARGET_ENABLE_CXX11(convolution-inference-overfeat-test)\n  TARGET_INCLUDE_DIRECTORIES(convolution-inference-overfeat-test PRIVATE test)\n  TARGET_LINK_LIBRARIES(convolution-inference-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n  ADD_TEST(convolution-inference-overfeat convolution-inference-overfeat-test)\n\n  ADD_EXECUTABLE(convolution-inference-vgg-test test/convolution-inference/vgg-a.cc)\n  NNPACK_TARGET_ENABLE_CXX11(convolution-inference-vgg-test)\n  TARGET_INCLUDE_DIRECTORIES(convolution-inference-vgg-test PRIVATE test)\n  TARGET_LINK_LIBRARIES(convolution-inference-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n  ADD_TEST(convolution-inference-vgg convolution-inference-vgg-test)\n\n  IF(NOT NNPACK_INFERENCE_ONLY)\n    ADD_EXECUTABLE(convolution-output-smoketest test/convolution-output/smoke.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-output-smoketest)\n    TARGET_INCLUDE_DIRECTORIES(convolution-output-smoketest PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-output-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-output-smoketest convolution-output-smoketest)\n\n    ADD_EXECUTABLE(convolution-output-alexnet-test test/convolution-output/alexnet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-output-alexnet-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-output-alexnet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-output-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-output-alexnet convolution-output-alexnet-test)\n\n    ADD_EXECUTABLE(convolution-output-overfeat-test test/convolution-output/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-output-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-output-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-output-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-output-overfeat convolution-output-overfeat-test)\n\n    ADD_EXECUTABLE(convolution-output-vgg-test test/convolution-output/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-output-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-output-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-output-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-output-vgg convolution-output-vgg-test)\n\n    ADD_EXECUTABLE(convolution-input-gradient-smoketest test/convolution-input-gradient/smoke.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-input-gradient-smoketest)\n    TARGET_INCLUDE_DIRECTORIES(convolution-input-gradient-smoketest PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-input-gradient-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-input-gradient-smoketest convolution-input-gradient-smoketest)\n\n    ADD_EXECUTABLE(convolution-input-gradient-alexnet-test test/convolution-input-gradient/alexnet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-input-gradient-alexnet-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-input-gradient-alexnet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-input-gradient-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-input-gradient-alexnet convolution-input-gradient-alexnet-test)\n\n    ADD_EXECUTABLE(convolution-input-gradient-overfeat-test test/convolution-input-gradient/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-input-gradient-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-input-gradient-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-input-gradient-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-input-gradient-overfeat convolution-input-gradient-overfeat-test)\n\n    ADD_EXECUTABLE(convolution-input-gradient-vgg-test test/convolution-input-gradient/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-input-gradient-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-input-gradient-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-input-gradient-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-input-gradient-vgg convolution-input-gradient-vgg-test)\n\n    ADD_EXECUTABLE(convolution-kernel-gradient-smoketest test/convolution-kernel-gradient/smoke.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-kernel-gradient-smoketest)\n    TARGET_INCLUDE_DIRECTORIES(convolution-kernel-gradient-smoketest PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-kernel-gradient-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-kernel-gradient-smoketest convolution-kernel-gradient-smoketest)\n\n    ADD_EXECUTABLE(convolution-kernel-gradient-alexnet-test test/convolution-kernel-gradient/alexnet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-kernel-gradient-alexnet-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-kernel-gradient-alexnet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-kernel-gradient-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-kernel-gradient-alexnet convolution-kernel-gradient-alexnet-test)\n\n    ADD_EXECUTABLE(convolution-kernel-gradient-overfeat-test test/convolution-kernel-gradient/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-kernel-gradient-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-kernel-gradient-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-kernel-gradient-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-kernel-gradient-overfeat convolution-kernel-gradient-overfeat-test)\n\n    ADD_EXECUTABLE(convolution-kernel-gradient-vgg-test test/convolution-kernel-gradient/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(convolution-kernel-gradient-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(convolution-kernel-gradient-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(convolution-kernel-gradient-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(convolution-kernel-gradient-vgg convolution-kernel-gradient-vgg-test)\n  ENDIF()\n\n  IF(NOT NNPACK_CONVOLUTION_ONLY)\n    ADD_EXECUTABLE(fully-connected-inference-alexnet-test test/fully-connected-inference/alexnet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(fully-connected-inference-alexnet-test)\n    TARGET_INCLUDE_DIRECTORIES(fully-connected-inference-alexnet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(fully-connected-inference-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(fully-connected-inference-alexnet fully-connected-inference-alexnet-test)\n\n    ADD_EXECUTABLE(fully-connected-inference-overfeat-test test/fully-connected-inference/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(fully-connected-inference-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(fully-connected-inference-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(fully-connected-inference-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(fully-connected-inference-overfeat fully-connected-inference-overfeat-test)\n\n    ADD_EXECUTABLE(fully-connected-inference-vgg-test test/fully-connected-inference/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(fully-connected-inference-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(fully-connected-inference-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(fully-connected-inference-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(fully-connected-inference-vgg fully-connected-inference-vgg-test)\n\n    IF(NOT NNPACK_INFERENCE_ONLY)\n      ADD_EXECUTABLE(fully-connected-output-smoketest test/fully-connected-output/smoke.cc)\n      NNPACK_TARGET_ENABLE_CXX11(fully-connected-output-smoketest)\n      TARGET_INCLUDE_DIRECTORIES(fully-connected-output-smoketest PRIVATE test)\n      TARGET_LINK_LIBRARIES(fully-connected-output-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(fully-connected-output-smoketest fully-connected-output-smoketest)\n\n      ADD_EXECUTABLE(fully-connected-output-alexnet-test test/fully-connected-output/alexnet.cc)\n      NNPACK_TARGET_ENABLE_CXX11(fully-connected-output-alexnet-test)\n      TARGET_INCLUDE_DIRECTORIES(fully-connected-output-alexnet-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(fully-connected-output-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(fully-connected-output-alexnet fully-connected-output-alexnet-test)\n\n      ADD_EXECUTABLE(fully-connected-output-overfeat-test test/fully-connected-output/overfeat-fast.cc)\n      NNPACK_TARGET_ENABLE_CXX11(fully-connected-output-overfeat-test)\n      TARGET_INCLUDE_DIRECTORIES(fully-connected-output-overfeat-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(fully-connected-output-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(fully-connected-output-overfeat fully-connected-output-overfeat-test)\n\n      ADD_EXECUTABLE(fully-connected-output-vgg-test test/fully-connected-output/vgg-a.cc)\n      NNPACK_TARGET_ENABLE_CXX11(fully-connected-output-vgg-test)\n      TARGET_INCLUDE_DIRECTORIES(fully-connected-output-vgg-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(fully-connected-output-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(fully-connected-output-vgg fully-connected-output-vgg-test)\n    ENDIF()\n\n    ADD_EXECUTABLE(max-pooling-output-smoketest test/max-pooling-output/smoke.cc)\n    NNPACK_TARGET_ENABLE_CXX11(max-pooling-output-smoketest)\n    TARGET_INCLUDE_DIRECTORIES(max-pooling-output-smoketest PRIVATE test)\n    TARGET_LINK_LIBRARIES(max-pooling-output-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(max-pooling-output-smoketest max-pooling-output-smoketest)\n\n    ADD_EXECUTABLE(max-pooling-output-overfeat-test test/max-pooling-output/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(max-pooling-output-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(max-pooling-output-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(max-pooling-output-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(max-pooling-output-overfeat max-pooling-output-overfeat-test)\n\n    ADD_EXECUTABLE(max-pooling-output-vgg-test test/max-pooling-output/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(max-pooling-output-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(max-pooling-output-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(max-pooling-output-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(max-pooling-output-vgg max-pooling-output-vgg-test)\n\n    ADD_EXECUTABLE(relu-output-alexnet-test test/relu-output/alexnet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(relu-output-alexnet-test)\n    TARGET_INCLUDE_DIRECTORIES(relu-output-alexnet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(relu-output-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(relu-output-alexnet relu-output-alexnet-test)\n\n    ADD_EXECUTABLE(relu-output-overfeat-test test/relu-output/overfeat-fast.cc)\n    NNPACK_TARGET_ENABLE_CXX11(relu-output-overfeat-test)\n    TARGET_INCLUDE_DIRECTORIES(relu-output-overfeat-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(relu-output-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(relu-output-overfeat relu-output-overfeat-test)\n\n    ADD_EXECUTABLE(relu-output-vgg-test test/relu-output/vgg-a.cc)\n    NNPACK_TARGET_ENABLE_CXX11(relu-output-vgg-test)\n    TARGET_INCLUDE_DIRECTORIES(relu-output-vgg-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(relu-output-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(relu-output-vgg relu-output-vgg-test)\n\n    IF(NOT NNPACK_INFERENCE_ONLY)\n      ADD_EXECUTABLE(relu-input-gradient-alexnet-test test/relu-input-gradient/alexnet.cc)\n      NNPACK_TARGET_ENABLE_CXX11(relu-input-gradient-alexnet-test)\n      TARGET_INCLUDE_DIRECTORIES(relu-input-gradient-alexnet-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(relu-input-gradient-alexnet-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(relu-input-gradient-alexnet relu-input-gradient-alexnet-test)\n\n      ADD_EXECUTABLE(relu-input-gradient-overfeat-test test/relu-input-gradient/overfeat-fast.cc)\n      NNPACK_TARGET_ENABLE_CXX11(relu-input-gradient-overfeat-test)\n      TARGET_INCLUDE_DIRECTORIES(relu-input-gradient-overfeat-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(relu-input-gradient-overfeat-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(relu-input-gradient-overfeat relu-input-gradient-overfeat-test)\n\n      ADD_EXECUTABLE(relu-input-gradient-vgg-test test/relu-input-gradient/vgg-a.cc)\n      NNPACK_TARGET_ENABLE_CXX11(relu-input-gradient-vgg-test)\n      TARGET_INCLUDE_DIRECTORIES(relu-input-gradient-vgg-test PRIVATE test)\n      TARGET_LINK_LIBRARIES(relu-input-gradient-vgg-test PRIVATE nnpack nnpack_reference_layers gtest)\n      ADD_TEST(relu-input-gradient-vgg relu-input-gradient-vgg-test)\n    ENDIF()\n\n    ADD_EXECUTABLE(softmax-output-smoketest test/softmax-output/smoke.cc)\n    NNPACK_TARGET_ENABLE_CXX11(softmax-output-smoketest)\n    TARGET_INCLUDE_DIRECTORIES(softmax-output-smoketest PRIVATE test)\n    TARGET_LINK_LIBRARIES(softmax-output-smoketest PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(softmax-output-smoketest softmax-output-smoketest)\n\n    ADD_EXECUTABLE(softmax-output-imagenet-test test/softmax-output/imagenet.cc)\n    NNPACK_TARGET_ENABLE_CXX11(softmax-output-imagenet-test)\n    TARGET_INCLUDE_DIRECTORIES(softmax-output-imagenet-test PRIVATE test)\n    TARGET_LINK_LIBRARIES(softmax-output-imagenet-test PRIVATE nnpack nnpack_reference_layers gtest)\n    ADD_TEST(softmax-output-imagenet softmax-output-imagenet-test)\n  ENDIF()\nENDIF()\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.3203125,
          "content": "Copyright (c) 2017 Facebook Inc.\nCopyright (c) 2015-2017, Georgia Institute of Technology\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.046875,
          "content": "<p align=\"center\"><img src=\"https://maratyszcza.github.io/NNPACK/NNPACK.png\" alt=\"NNPACK Logo\" title=\"NNPACK\"/></p>\n\n# NNPACK\n\n[![BSD (2 clause) License](https://img.shields.io/badge/License-BSD%202--Clause%20%22Simplified%22%20License-blue.svg)](https://github.com/Maratyszcza/NNPACK/blob/master/LICENSE)\n[![Build Status](https://img.shields.io/travis/Maratyszcza/NNPACK.svg)](https://travis-ci.org/Maratyszcza/NNPACK)\n\nNNPACK is an acceleration package for neural network computations. NNPACK aims to provide high-performance implementations of convnet layers for multi-core CPUs.\n\nNNPACK is not intended to be directly used by machine learning researchers; instead it provides low-level performance primitives leveraged in leading deep learning frameworks, such as [PyTorch](http://pytorch.org/), [Caffe2](https://caffe2.ai/), [MXNet](http://mxnet.io), \n[tiny-dnn](https://tiny-dnn.readthedocs.io/), [Caffe](http://caffe.berkeleyvision.org/), [Torch](http://torch.ch/), and [Darknet](https://pjreddie.com/darknet/).\n\n## Platforms and requirements\n\n| Environment  | Architecture  | CPU requirements                 |\n| ------------ | ------------- | -------------------------------- |\n| Linux        | x86-64        | AVX2 and 3-level cache hierarchy |\n| Linux        | ARM           | NEON                             |\n| Linux        | ARM64         |                                  |\n| macOS        | x86-64        | AVX2 and 3-level cache hierarchy |\n| Android      | ARM           | NEON                             |\n| Android      | ARM64         |                                  |\n| Android      | x86           |                                  |\n| Android      | x86-64        |                                  |\n| iOS          | ARM           |                                  |\n| iOS          | ARM64         |                                  |\n| Emscripten   | Asm.js        |                                  |\n| Emscripten   | WebAssembly   |                                  |\n\n## Features\n\n- Multiple algorithms for convolutional layers:\n  - Fast convolution based on Fourier transform (for kernels up to 16x16 without stride)\n  - Fast convolution based on Winograd transform (for 3x3 kernels without stride)\n  - Implicit matrix-matrix multiplication algorithm (no limitations)\n  - Direct convolution algorithm (for 1x1 kernels without stride)\n- Multi-threaded SIMD-aware implementations of neural network layers\n- Implemented in C99 and Python without external dependencies\n- Extensive coverage with unit tests\n\n## Layers\n\n- Convolutional layer\n  - Inference-optimized forward propagation (`nnp_convolution_inference`)\n  - Training-optimized forward propagation (`nnp_convolution_output`)\n  - Training-optimized backward input gradient update (`nnp_convolution_input_gradient`)\n  - Training-optimized backward kernel gradient update (`nnp_convolution_kernel_gradient`)\n- Fully-connected layer\n  - Inference-optimized forward propagation (`nnp_fully_connected_inference` and `nnp_fully_connected_inference_f16f32` version for FP16 weights)\n  - Training-optimized forward propagation (`nnp_fully_connected_output`)\n- Max pooling layer\n  - Forward propagation, both for training and inference, (`nnp_max_pooling_output`)\n- ReLU layer (with parametrized negative slope)\n  - Forward propagation, both for training and inference, optionally in-place, (`nnp_relu_output`)\n  - Backward input gradient update (`nnp_relu_input_gradient`)\n- Softmax layer\n  - Forward propagation, both for training and inference, optionally in-place (`nnp_softmax_output`)\n\n## Building\n\nFor most users, the recommended way to build NNPACK is through CMake:\n\n```bash\nmkdir build\ncd build\ncmake -G Ninja ..\nninja\n```\n\nNote: if `ninja` is not available on your system, configure without `-G Ninja`, and use `make` instead of `ninja`.\n\n## Building NNPACK - Using vcpkg\n\nYou can download and install NNPACK using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install NNPACK\n\nThe NNPACK port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Cross-compilation for Android\n\nTo cross-compile for Android, add extra configuration options for `cmake`: `-DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake` (where `$ANDROID_NDK` is the path to Android NDK directorory, e.g. `/opt/android-ndk-r15c`) **AND** arguments from the table below\n\n| ABI         | Extra cmake args                                    | Restrictions               |\n| ----------- | --------------------------------------------------- | -------------------------- |\n| armeabi     | `-DANDROID_ABI=armeabi -DANDROID_TOOLCHAIN=gcc`     | Requires CPU with ARM NEON |\n| armeabi-v7a | `-DANDROID_ABI=armeabi-v7a -DANDROID_TOOLCHAIN=gcc` | Requires CPU with ARM NEON |\n| arm64-v8a   | `-DANDROID_ABI=arm64-v8a -DANDROID_TOOLCHAIN=clang` | Requires clang toolchain   |\n| x86         | `-DANDROID_ABI=x86`                                 |                            |\n| x86_64      | `-DANDROID_ABI=x86_64`                              |                            |\n\nNotes:\n- On **armeabi** and **armeabi-v7a** `nnp_initialize` will fail with `nnp_status_unsupported_hardware` if the mobile CPU does not support ARM NEON. Don't set `-DANDROID_ARM_NEON=1` for NNPACK compilation as it can make `nnp_initialize` crash on CPUs without ARM NEON.\n- NNPACK builds for **armeabi** and **armeabi-v7a** are up to 2x slower if you use **clang** toolchain.\n- **mips** and **mips64** are not supported, and we have no plans to add it (pull request would be welcome, though)\n- **x86_64** build will use generic 128-bit (SSE2) micro-kernels rather than AVX2 micro-kernels in native build\n\n## Ecosystem\n\n### Deep Learning Frameworks\n- [PyTorch](http://pytorch.org/) supports NNPACK on mobile for inference in convolutional layers.\n- [TVM](https://tvm.apache.org/) supports NNPACK for inference in convolutional layers. See [these instructions](https://github.com/apache/incubator-tvm/blob/master/docs/install/nnpack.md) to enable NNPACK in TVM.\n- [MXNet](http://mxnet.io) supports NNPACK for inference in convolutional layers, fully-connected, and max-pooling layers. See [MXNet wiki](https://mxnet.incubator.apache.org/how_to/nnpack.html) for configuration instructions and performance benchmarks).\n- [Caffe2](http://caffe2.ai) supports NNPACK for inference in convolutional layers.\n- [darknet-nnpack](https://github.com/thomaspark-pkj/darknet-nnpack) - fork of [Darknet](https://pjreddie.com/darknet/) framework with NNPACK support.\n- [tiny-dnn](https://github.com/tiny-dnn/tiny-dnn) - header-only deep learning framework in C++11, which natively supports NNPACK.\n- [Maratyszcza/caffe](https://github.com/Maratyszcza/caffe) - up-to-date integration of NNPACK (convolutional, fully-connected, max-pooling, and ReLU layers) into Caffe based on `nnpack-pr` branch in [ajtulloch/caffe](https://github.com/ajtulloch/caffe/tree/nnpack-pr).\n- [Maratyszcza/caffe-nnpack](https://github.com/Maratyszcza/caffe-nnpack) - older and unmaintained integration of NNPACK (convolutional layers only) into Caffe.\n- [szagoruyko/nnpack.torch](https://github.com/szagoruyko/nnpack.torch) - integration of NNPACK into Lua Torch via ffi\n- See also discussion in [Issue #1](https://github.com/Maratyszcza/NNPACK/issues/1)\n\n### Languages and Environments\n- [nnpack-windows](https://github.com/zeno40/nnpack-windows) - unofficial port for Windows\n- [node-nnpack](https://www.npmjs.com/package/node-nnpack) - Node.js bindings\n- [peterhj/libnnpack](https://github.com/peterhj/libnnpack) - Rust bindings\n\n### Users\n\n- [Facebook](https://www.facebook.com) uses NNPACK in production.\n- [Prisma](https://prisma-ai.com) uses NNPACK in the mobile app.\n\n## Acknowledgements\n\n[![HPC Garage logo](https://github.com/Maratyszcza/PeachPy/blob/master/logo/hpcgarage.png)](http://hpcgarage.org)\n[![Georgia Tech College of Computing logo](https://github.com/Maratyszcza/PeachPy/blob/master/logo/college-of-computing.gif)](http://www.cse.gatech.edu/)\n\nThe library is developed by [Marat Dukhan](http://www.maratdukhan.com) of Georgia Tech with extensive advice from [Nicolas Vasilache](https://research.facebook.com/nicolas-vasilache) and [Soumith Chintala](http://soumith.ch/) of Facebook Artificial Intelligence Research. [Andrew Tulloch](http://tullo.ch/) of Facebook Artificial Intelligence Research contributed Caffe integration. We thank [Andrew Lavin](https://github.com/andravin) for fruitful discussions on Winograd transform-based implementations. NNPACK is a research project at [Richard Vuduc](http://vuduc.org)'s HPC Garage lab in the Georgia Institute of Technology, College of Computing, School of Computational Science and Engineering.\n\nThis material is based upon work supported by the U.S. National Science Foundation (NSF) Award Number 1339745. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of NSF.\n"
        },
        {
          "name": "bench",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark.py",
          "type": "blob",
          "size": 7.7099609375,
          "content": "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\n\ndef extract_time(line, prefix):\n\tif line.startswith(prefix):\n\t\tline = line[len(prefix):].lstrip()\n\t\tline = line[:line.index(\" ms\")].rstrip()\n\t\treturn line\n\n\ndef convolution(mode, batch_size, input_channels, output_channels, image_size, kernel_size, padding, algorithm, transform_strategy=None, threads=None, verbose=False, use_selldr=False):\n\timport subprocess\n\tif use_selldr:\n\t\timport os\n\t\timport sys\n\t\tnacl_sdk_dir = os.getenv(\"NACL_SDK_ROOT\")\n\t\tif nacl_sdk_dir is None:\n\t\t\tprint(\"Error: can not find Native Client SDK: set NACL_SDK_ROOT envorinment variable and try again\", file=sys.stderr)\n\t\t\tsys.exit(1)\n\t\tbenchmark_args = [os.path.join(nacl_sdk_dir, \"tools\", \"sel_ldr.py\"), \"--\",\n\t\t\t\"bin/convolution-benchmark\"]\n\telse:\n\t\tbenchmark_args = [\"bin/convolution-benchmark\"]\n\tbenchmark_args += [\n\t\t\"-m\", mode,\n\t\t\"-b\", str(batch_size),\n\t\t\"-ic\", str(input_channels),\n\t\t\"-oc\", str(output_channels),\n\t\t\"-is\", str(image_size[0]), str(image_size[1]),\n\t\t\"-ip\", str(padding),\n\t\t\"-ks\", str(kernel_size[0]), str(kernel_size[1]),\n\t\t\"-a\", algorithm\n\t]\n\tif mode == \"inference\" and transform_strategy is not None:\n\t\tbenchmark_args += [\"-ts\", transform_strategy]\n\tif threads is not None:\n\t\tbenchmark_args += [\"-t\", str(threads)]\n\tbenchmark = subprocess.Popen(benchmark_args, stdout=subprocess.PIPE)\n\tbenchmark_stdout, _ = benchmark.communicate()\n\tif benchmark.returncode == 0:\n\t\toutput_lines = [line for line in benchmark_stdout.splitlines() if len(line)]\n\t\ttotal, input_transform, kernel_transform, output_transform, block_multiplication, overhead = None, None, None, None, None, None\n\t\tfor output_line in output_lines:\n\t\t\ttotal = total or extract_time(output_line, \"Time:\")\n\t\t\tinput_transform = input_transform or extract_time(output_line, \"Input transform:\")\n\t\t\tkernel_transform = kernel_transform or extract_time(output_line, \"Kernel transform:\")\n\t\t\toutput_transform = output_transform or extract_time(output_line, \"Output transform:\")\n\t\t\tblock_multiplication = block_multiplication or extract_time(output_line, \"Block multiplication:\")\n\t\t\toverhead = overhead or extract_time(output_line, \"Overhead:\")\n\t\tif verbose:\n\t\t\treturn (total, input_transform, kernel_transform, output_transform, block_multiplication, overhead)\n\t\telse:\n\t\t\treturn (total,)\n\ndef fully_connected(mode, batch_size, input_channels, output_channels, threads=None, verbose=False, use_selldr=False):\n\timport subprocess\n\tif use_selldr:\n\t\timport os\n\t\timport sys\n\t\tnacl_sdk_dir = os.getenv(\"NACL_SDK_ROOT\")\n\t\tif nacl_sdk_dir is None:\n\t\t\tprint(\"Error: can not find Native Client SDK: set NACL_SDK_ROOT envorinment variable and try again\", file=sys.stderr)\n\t\t\tsys.exit(1)\n\t\tbenchmark_args = [os.path.join(nacl_sdk_dir, \"tools\", \"sel_ldr.py\"), \"--\",\n\t\t\t\"bin/fully-connected-benchmark\"]\n\telse:\n\t\tbenchmark_args = [\"bin/fully-connected-benchmark\"]\n\tbenchmark_args += [\n\t\t\"-m\", mode,\n\t\t\"-b\", str(batch_size),\n\t\t\"-ic\", str(input_channels),\n\t\t\"-oc\", str(output_channels)\n\t]\n\tif threads is not None:\n\t\tbenchmark_args += [\"-t\", str(threads)]\n\tbenchmark = subprocess.Popen(benchmark_args, stdout=subprocess.PIPE)\n\tbenchmark_stdout, _ = benchmark.communicate()\n\tif benchmark.returncode == 0:\n\t\toutput_lines = [line for line in benchmark_stdout.splitlines() if len(line)]\n\t\ttotal, input_transform, kernel_transform, block_multiplication, overhead = None, None, None, None, None\n\t\tfor output_line in output_lines:\n\t\t\ttotal = total or extract_time(output_line, \"Time:\")\n\t\t\tinput_transform = input_transform or extract_time(output_line, \"Input packing:\")\n\t\t\tkernel_transform = kernel_transform or extract_time(output_line, \"Kernel packing:\")\n\t\t\tblock_multiplication = block_multiplication or extract_time(output_line, \"Block multiplication:\")\n\t\t\toverhead = overhead or extract_time(output_line, \"Overhead:\")\n\t\tif verbose:\n\t\t\treturn (total, input_transform, kernel_transform, block_multiplication, overhead)\n\t\telse:\n\t\t\treturn (total,)\n\noverfeat_fast_layers = [\n\t(\"conv2\",   96,  256, (24, 24), (5, 5), 0),\n\t(\"conv3\",  256,  512, (12, 12), (3, 3), 1),\n\t(\"conv4\",  512, 1024, (12, 12), (3, 3), 1),\n\t(\"conv5\", 1024, 1024, (12, 12), (3, 3), 1),\n\t(\"fc6\", 36864, 3072),\n\t(\"fc7\",  3072, 4096),\n\t(\"fc8\",  4096, 1000),\n]\n\nalexnet_layers = [\n\t(\"conv2\",  64, 192, (27, 27), (5, 5), 2),\n\t(\"conv3\", 192, 384, (13, 13), (3, 3), 1),\n\t(\"conv4\", 384, 256, (13, 13), (3, 3), 1),\n\t(\"conv5\", 256, 256, (13, 13), (3, 3), 1),\n\t(\"fc6\", 12544, 4096),\n\t(\"fc7\",  4096, 4096),\n\t(\"fc8\",  4096, 1000),\n]\n\nvgg_a_layers = [\n\t(\"conv1\",     3,  64, (224, 224), (3, 3), 1),\n\t(\"conv2\",    64, 128, (112, 112), (3, 3), 1),\n\t(\"conv3.1\", 128, 256,   (56, 56), (3, 3), 1),\n\t(\"conv3.2\", 256, 256,   (56, 56), (3, 3), 1),\n\t(\"conv4.1\", 256, 512,   (28, 28), (3, 3), 1),\n\t(\"conv4.2\", 512, 512,   (28, 28), (3, 3), 1),\n\t(\"conv5\",   512, 512,   (14, 14), (3, 3), 1),\n\t(\"fc6\", 25088, 4096),\n\t(\"fc7\",  4096, 4096),\n\t(\"fc8\",  4096, 1000),\n]\n\t\t\nif __name__ == \"__main__\":\n\timport argparse\n\n\tparser = argparse.ArgumentParser(\n\t\tdescription=\"NNPACK benchmarking script\")\n\tparser.add_argument(\"--enable-selldr\", dest=\"use_selldr\", action=\"store_true\")\n\tparser.add_argument(\"-l\", \"--layer\", dest=\"layer\", required=True, choices=[\"convolution\", \"fully-connected\", \"pooling\"])\n\tparser.add_argument(\"-n\", \"--network\", dest=\"network\", required=True, choices=[\"vgg-a\", \"alexnet\", \"overfeat-fast\"])\n\tparser.add_argument(\"-m\", \"--mode\", dest=\"mode\", required=True, choices=[\"inference\", \"output\", \"input-gradient\", \"kernel-gradient\"])\n\tparser.add_argument(\"--transform-strategy\", dest=\"transform_strategy\", default=\"compute\", choices=[\"compute\", \"precompute\"])\n\tparser.add_argument(\"-b\", \"--batch\", dest=\"batch\", type=int)\n\tparser.add_argument(\"-t\", \"--threads\", dest=\"threads\")\n\tparser.add_argument(\"-v\", \"--verbose\", dest=\"verbose\", action=\"store_true\", default=False)\n\n\toptions = parser.parse_args()\n\n\tnetwork_layers, default_batch = {\n\t\t\"vgg-a\": (vgg_a_layers, 64),\n\t\t\"alexnet\": (alexnet_layers, 128),\n\t\t\"overfeat-fast\": (overfeat_fast_layers, 128)\n\t}[options.network]\n\tlayer_prefix = {\n\t\t\"convolution\": \"conv\",\n\t\t\"fully-connected\": \"fc\",\n\t\t\"pooling\": \"pool\"\n\t}[options.layer]\n\tnetwork_layers = [layer for layer in network_layers if layer[0].startswith(layer_prefix)]\n\n\tbatch = default_batch\n\tif options.batch is not None:\n\t\tbatch = options.batch\n\t\tif batch != 1 and options.mode == \"inference\":\n\t\t\traise ValueError(\"Non-unit batch {batch} is not allowed in inference mode\".format(batch=batch))\n\telif options.mode == \"inference\":\n\t\tbatch = 1\n\tif options.transform_strategy is not None:\n\t\tif options.layer != \"convolution\":\n\t\t\traise ValueError(\"Transform strategy {transform_strategy} is meaningless for non-convolutional layers\".format(transform_strategy=transform_strategy))\n\t\telif options.mode != \"inference\":\n\t\t\traise ValueError(\"Transform strategy {transform_strategy} is meaningless in non-inference mode\".format(transform_strategy=transform_strategy))\n\n\tif options.layer == \"convolution\":\n\t\tfor name, input_channels, output_channels, image_size, kernel_size, padding in network_layers:\n\t\t\tmeasurements = [name]\n\t\t\tfor algorithm in [\"implicit-gemm\", \"ft8x8\", \"ft16x16\", \"wt8x8\"]:\n\t\t\t\tif algorithm.startswith(\"wt\") and kernel_size != (3, 3):\n\t\t\t\t\tcontinue\n\n\t\t\t\tmeasurements += list(convolution(options.mode, batch, input_channels, output_channels,\n\t\t\t\t\timage_size, kernel_size, padding, algorithm,\n\t\t\t\t\ttransform_strategy=options.transform_strategy,\n\t\t\t\t\tthreads=options.threads, verbose=options.verbose, use_selldr=options.use_selldr))\n\t\t\tprint(\"\\t\".join(map(str, measurements)))\n\telif options.layer == \"fully-connected\":\n\t\tfor name, input_channels, output_channels in network_layers:\n\t\t\tmeasurements = fully_connected(options.mode, batch, input_channels, output_channels,\n\t\t\t\tthreads=options.threads, verbose=options.verbose, use_selldr=options.use_selldr)\n\t\t\tprint(\"{name}\\t{measurements}\".format(name=name, measurements=\"\\t\".join(measurements)))\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.py",
          "type": "blob",
          "size": 22.01171875,
          "content": "#!/usr/bin/env python\n\n\nimport confu\nparser = confu.standard_parser()\nparser.add_argument(\"--backend\", dest=\"backend\", default=\"auto\",\n                    choices=[\"auto\", \"psimd\", \"scalar\"])\nparser.add_argument(\"--inference-only\", dest=\"inference_only\", default=False,\n                    action=\"store_true\",\n                    help=\"Build only inference/forward pass functions to reduce library size\")\nparser.add_argument(\"--convolution-only\", dest=\"convolution_only\", default=False,\n                    action=\"store_true\",\n                    help=\"Build only convolution functions to reduce library size\")\n\n\ndef main(args):\n    options = parser.parse_args(args)\n\n    backend = options.backend\n    if backend == \"auto\":\n        if options.target.is_x86_64:\n            backend = \"x86_64\"\n        elif options.target.is_arm or options.target.is_arm64:\n            backend = \"arm\"\n        elif options.target.is_emscripten:\n            backend = \"scalar\"\n        else:\n            backend = \"psimd\"\n\n    build = confu.Build.from_options(options)\n\n    macros = dict()\n    if backend == \"psimd\":\n        macros[\"NNP_BACKEND_PSIMD\"] = 1\n    if backend == \"scalar\":\n        macros[\"NNP_BACKEND_SCALAR\"] = 1\n    export_macros = dict()\n    export_macros[\"NNP_CONVOLUTION_ONLY\"] = int(options.convolution_only)\n    export_macros[\"NNP_INFERENCE_ONLY\"] = int(options.inference_only)\n    macros.update(export_macros)\n\n    build.export_cpath(\"include\", [\"nnpack.h\"])\n\n    with build.options(source_dir=\"src\", macros=macros,\n            deps={\n                (build.deps.pthreadpool, build.deps.cpuinfo, build.deps.fxdiv, build.deps.fp16): any,\n                build.deps.psimd: backend == \"psimd\" or backend == \"arm\",\n            },\n            extra_include_dirs={\n                (\"src\", \"src/ref\"): any,\n                \"src/x86_64-fma\": options.target.is_x86_64\n            }):\n\n        nnpack_objects = [\n            build.cc(\"init.c\"),\n            build.cc(\"convolution-inference.c\"),\n        ]\n        if not options.convolution_only:\n            # Fully-connected, pooling, Softmax, ReLU layers\n            nnpack_objects += [\n                build.cc(\"fully-connected-inference.c\"),\n                build.cc(\"pooling-output.c\"),\n                build.cc(\"softmax-output.c\"),\n                build.cc(\"relu-output.c\"),\n            ]\n            if not options.inference_only:\n                # Training functions for fully-connected and ReLU layers\n                nnpack_objects += [\n                    build.cc(\"fully-connected-output.c\"),\n                    build.cc(\"relu-input-gradient.c\"),\n                ]\n\n        if not options.inference_only:\n            # Training functions for convolutional layer\n            nnpack_objects += [\n                build.cc(\"convolution-output.c\"),\n                build.cc(\"convolution-input-gradient.c\"),\n                build.cc(\"convolution-kernel-gradient.c\"),\n            ]\n\n        if backend == \"x86_64\":\n            arch_nnpack_objects = [\n                # Transformations\n                build.peachpy(\"x86_64-fma/2d-fourier-8x8.py\"),\n                build.peachpy(\"x86_64-fma/2d-fourier-16x16.py\"),\n                build.peachpy(\"x86_64-fma/2d-winograd-8x8-3x3.py\"),\n                # Tuple GEMM\n                build.peachpy(\"x86_64-fma/blas/s8gemm.py\"),\n                build.peachpy(\"x86_64-fma/blas/c8gemm.py\"),\n                build.peachpy(\"x86_64-fma/blas/s4c6gemm.py\"),\n                # Direct convolution\n                build.peachpy(\"x86_64-fma/blas/conv1x1.py\"),\n                # BLAS microkernels\n                build.peachpy(\"x86_64-fma/blas/sgemm.py\"),\n            ]\n            if not options.convolution_only:\n                arch_nnpack_objects += [\n                    # Activations\n                    build.peachpy(\"x86_64-fma/softmax.py\"),\n                    build.cc(\"x86_64-fma/softmax.c\"),\n                    build.peachpy(\"x86_64-fma/relu.py\"),\n                    # Pooling\n                    build.peachpy(\"x86_64-fma/max-pooling.py\"),\n                    # BLAS microkernels\n                    build.peachpy(\"x86_64-fma/blas/sdotxf.py\"),\n                    build.peachpy(\"x86_64-fma/blas/shdotxf.py\"),\n                ]\n        elif backend == \"scalar\":\n            arch_nnpack_objects = [\n                # Transformations\n                build.cc(\"scalar/2d-fourier-8x8.c\"),\n                build.cc(\"scalar/2d-fourier-16x16.c\"),\n                build.cc(\"scalar/2d-winograd-8x8-3x3.c\"),\n                # Tuple GEMM\n                build.cc(\"scalar/blas/s2gemm.c\"),\n                build.cc(\"scalar/blas/cgemm-conjb.c\"),\n                # Direct convolution\n                build.cc(\"scalar/blas/conv1x1.c\"),\n                # BLAS microkernels\n                build.cc(\"scalar/blas/sgemm.c\"),\n            ]\n            if not options.inference_only:\n                arch_nnpack_objects += [\n                    # Tuple GEMM\n                    build.cc(\"scalar/blas/s2gemm-transc.c\"),\n                    build.cc(\"scalar/blas/cgemm.c\"),\n                    build.cc(\"scalar/blas/cgemm-conjb-transc.c\"),\n                ]\n            if not options.convolution_only:\n                arch_nnpack_objects += [\n                    # Activations\n                    build.cc(\"scalar/relu.c\"),\n                    build.cc(\"scalar/softmax.c\"),\n                    # BLAS microkernels\n                    build.cc(\"scalar/blas/sdotxf.c\"),\n                    build.cc(\"scalar/blas/shdotxf.c\"),\n                ]\n        elif backend == \"arm\":\n            from confu import arm\n            with build.options(isa=arm.neon+arm.fp16 if options.target.is_arm else None):\n                arch_nnpack_objects = [\n                    # Transformations\n                    build.cc(\"psimd/2d-fourier-8x8.c\"),\n                    build.cc(\"psimd/2d-fourier-16x16.c\"),\n                    build.cc(\"neon/2d-winograd-8x8-3x3.c\"),\n                    build.cc(\"neon/2d-winograd-8x8-3x3-fp16.c\"),\n                    # Tuple GEMM\n                    build.cc(\"neon/blas/h4gemm.c\"),\n                    build.cc(\"neon/blas/s4gemm.c\"),\n                    build.cc(\"neon/blas/c4gemm-conjb.c\"),\n                    build.cc(\"neon/blas/s4c2gemm-conjb.c\"),\n                    # Direct convolution\n                    build.cc(\"neon/blas/conv1x1.c\"),\n                    # BLAS microkernels\n                    build.cc(\"neon/blas/sgemm.c\"),\n                ]\n                if not options.inference_only:\n                    arch_nnpack_objects += [\n                        # Transformations\n                        build.cc(\"psimd/2d-winograd-8x8-3x3.c\"),\n                        # Tuple GEMM\n                        build.cc(\"neon/blas/c4gemm.c\"),\n                        build.cc(\"neon/blas/s4c2gemm.c\"),\n                        build.cc(\"neon/blas/c4gemm-conjb-transc.c\"),\n                        build.cc(\"neon/blas/s4c2gemm-conjb-transc.c\"),\n                    ]\n                if not options.convolution_only:\n                    arch_nnpack_objects += [\n                        # ReLU and Softmax\n                        build.cc(\"neon/relu.c\"),\n                        build.cc(\"psimd/softmax.c\"),\n                        # BLAS microkernels\n                        build.cc(\"neon/blas/sdotxf.c\"),\n                        build.cc(\"psimd/blas/shdotxf.c\"),\n                    ]\n            if options.target.is_arm:\n                # Functions implemented in assembly\n                arch_nnpack_objects += [\n                    build.cc(\"neon/blas/h4gemm-aarch32.S\"),\n                    build.cc(\"neon/blas/s4gemm-aarch32.S\"),\n                    build.cc(\"neon/blas/sgemm-aarch32.S\"),\n                ]\n        elif backend == \"psimd\":\n            arch_nnpack_objects = [\n                # Transformations\n                build.cc(\"psimd/2d-fourier-8x8.c\"),\n                build.cc(\"psimd/2d-fourier-16x16.c\"),\n                build.cc(\"psimd/2d-winograd-8x8-3x3.c\"),\n                # Tuple GEMM\n                build.cc(\"psimd/blas/s4gemm.c\"),\n                build.cc(\"psimd/blas/c4gemm-conjb.c\"),\n                build.cc(\"psimd/blas/s4c2gemm-conjb.c\"),\n                # Direct convolution\n                build.cc(\"psimd/blas/conv1x1.c\"),\n                # BLAS microkernels\n                build.cc(\"psimd/blas/sgemm.c\"),\n            ]\n            if not options.inference_only:\n                arch_nnpack_objects += [\n                    # Tuple GEMM\n                    build.cc(\"psimd/blas/c4gemm.c\"),\n                    build.cc(\"psimd/blas/s4c2gemm.c\"),\n                    build.cc(\"psimd/blas/c4gemm-conjb-transc.c\"),\n                    build.cc(\"psimd/blas/s4c2gemm-conjb-transc.c\"),\n                ]\n            if not options.convolution_only:\n                arch_nnpack_objects += [\n                    # Activations\n                    build.cc(\"psimd/relu.c\"),\n                    build.cc(\"psimd/softmax.c\"),\n                    # BLAS microkernels\n                    build.cc(\"psimd/blas/sdotxf.c\"),\n                    build.cc(\"psimd/blas/shdotxf.c\"),\n                ]\n\n        reference_layer_objects = [\n            build.cc(\"ref/convolution-output.c\"),\n            build.cc(\"ref/convolution-input-gradient.c\"),\n            build.cc(\"ref/convolution-kernel.c\"),\n            build.cc(\"ref/fully-connected-output.c\"),\n            build.cc(\"ref/max-pooling-output.c\"),\n            build.cc(\"ref/softmax-output.c\"),\n            build.cc(\"ref/relu-output.c\"),\n            build.cc(\"ref/relu-input-gradient.c\"),\n        ]\n\n        reference_fft_objects = [\n            build.cc(\"ref/fft/aos.c\"),\n            build.cc(\"ref/fft/soa.c\"),\n            build.cc(\"ref/fft/forward-real.c\"),\n            build.cc(\"ref/fft/forward-dualreal.c\"),\n            build.cc(\"ref/fft/inverse-real.c\"),\n            build.cc(\"ref/fft/inverse-dualreal.c\"),\n        ]\n\n        if backend == \"x86_64\":\n            arch_fft_stub_objects = [\n                build.peachpy(\"x86_64-fma/fft-soa.py\"),\n                build.peachpy(\"x86_64-fma/fft-aos.py\"),\n                build.peachpy(\"x86_64-fma/fft-dualreal.py\"),\n                build.peachpy(\"x86_64-fma/ifft-dualreal.py\"),\n                build.peachpy(\"x86_64-fma/fft-real.py\"),\n                build.peachpy(\"x86_64-fma/ifft-real.py\"),\n            ]\n\n            arch_winograd_stub_objects = [\n                build.peachpy(\"x86_64-fma/winograd-f6k3.py\"),\n            ]\n\n            arch_math_stub_objects = [\n            ]\n        elif backend == \"scalar\":\n            arch_fft_stub_objects = [\n                build.cc(\"scalar/fft-aos.c\"),\n                build.cc(\"scalar/fft-soa.c\"),\n                build.cc(\"scalar/fft-real.c\"),\n                build.cc(\"scalar/fft-dualreal.c\"),\n            ]\n\n            arch_winograd_stub_objects = [\n                build.cc(\"scalar/winograd-f6k3.c\"),\n            ]\n        elif backend == \"psimd\" or backend == \"arm\":\n            arch_fft_stub_objects = [\n                build.cc(\"psimd/fft-aos.c\"),\n                build.cc(\"psimd/fft-soa.c\"),\n                build.cc(\"psimd/fft-real.c\"),\n                build.cc(\"psimd/fft-dualreal.c\"),\n            ]\n\n            if backend == \"psimd\":\n                arch_winograd_stub_objects = [\n                    build.cc(\"psimd/winograd-f6k3.c\"),\n                ]\n            else:\n                # ARM NEON Winograd transform optionally uses FP16 storage\n                with build.options(isa=arm.neon+arm.fp16 if options.target.is_arm else None):\n                    arch_winograd_stub_objects = [\n                        build.cc(\"neon/winograd-f6k3.c\"),\n                    ]\n\n            arch_math_stub_objects = [\n                build.cc(\"psimd/exp.c\"),\n            ]\n\n        fft_objects = reference_fft_objects + arch_fft_stub_objects\n\n        nnpack_objects = nnpack_objects + arch_nnpack_objects\n\n        build.static_library(\"nnpack\", nnpack_objects)\n\n    # Build tests for micro-kernels. Link to the micro-kernels implementations\n    with build.options(source_dir=\"test\", extra_include_dirs=\"test\",\n            deps={\n                (build.deps.googletest, build.deps.cpuinfo, build.deps.clog, build.deps.fp16): any,\n                \"log\": build.target.is_android}):\n\n        build.unittest(\"fourier-reference-test\",\n            reference_fft_objects + [build.cxx(\"fourier/reference.cc\")])\n\n        if backend == \"x86_64\":\n            build.smoketest(\"fourier-test\",\n                reference_fft_objects + arch_fft_stub_objects + [build.cxx(\"fourier/x86_64-avx2.cc\")])\n\n            build.smoketest(\"winograd-test\",\n                arch_winograd_stub_objects + arch_nnpack_objects + [build.cxx(\"winograd/x86_64-fma3.cc\")])\n\n            build.smoketest(\"sgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"sgemm/x86_64-fma3.cc\")])\n        elif backend == \"psimd\":\n            build.smoketest(\"fourier-test\",\n                reference_fft_objects + arch_fft_stub_objects + [build.cxx(\"fourier/psimd.cc\")])\n\n            build.smoketest(\"winograd-test\",\n                arch_winograd_stub_objects + arch_nnpack_objects + [build.cxx(\"winograd/psimd.cc\")])\n\n            build.smoketest(\"sgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"sgemm/psimd.cc\")])\n        elif backend == \"arm\":\n            # No ARM-specific Fourier implementation; use PSIMD\n            build.smoketest(\"fourier-test\",\n                reference_fft_objects + arch_fft_stub_objects + [build.cxx(\"fourier/psimd.cc\")])\n\n            build.smoketest(\"winograd-test\",\n                arch_winograd_stub_objects + arch_nnpack_objects + [build.cxx(\"winograd/neon.cc\")])\n\n            build.smoketest(\"sgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"sgemm/neon.cc\")])\n\n            build.smoketest(\"sxgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"sxgemm/neon.cc\")])\n\n            build.smoketest(\"hxgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"hxgemm/neon.cc\")])\n        elif backend == \"scalar\":\n            build.smoketest(\"fourier-test\",\n                reference_fft_objects + arch_fft_stub_objects + [build.cxx(\"fourier/scalar.cc\")])\n\n            build.smoketest(\"winograd-test\",\n                arch_winograd_stub_objects + arch_nnpack_objects + [build.cxx(\"winograd/scalar.cc\")])\n\n            build.smoketest(\"sgemm-test\",\n                arch_nnpack_objects + [build.cxx(\"sgemm/scalar.cc\")])\n\n    # Build test for layers. Link to the library.\n    with build.options(source_dir=\"test\", include_dirs=\"test\", deps={\n                (build, build.deps.pthreadpool, build.deps.cpuinfo, build.deps.clog, build.deps.googletest.core, build.deps.fp16): any,\n                \"rt\": build.target.is_linux,\n                \"log\": build.target.is_android,\n            }):\n\n        if not options.inference_only:\n            build.smoketest(\"convolution-output-smoketest\",\n                reference_layer_objects + [build.cxx(\"convolution-output/smoke.cc\")])\n            build.unittest(\"convolution-output-alexnet-test\",\n                reference_layer_objects + [build.cxx(\"convolution-output/alexnet.cc\")])\n            build.unittest(\"convolution-output-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"convolution-output/vgg-a.cc\")])\n            build.unittest(\"convolution-output-overfeat-fast-test\",\n                reference_layer_objects + [build.cxx(\"convolution-output/overfeat-fast.cc\")])\n\n            build.smoketest(\"convolution-input-gradient-smoketest\",\n                reference_layer_objects + [build.cxx(\"convolution-input-gradient/smoke.cc\")])\n            build.unittest(\"convolution-input-gradient-alexnet-test\",\n                reference_layer_objects + [build.cxx(\"convolution-input-gradient/alexnet.cc\")])\n            build.unittest(\"convolution-input-gradient-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"convolution-input-gradient/vgg-a.cc\")])\n            build.unittest(\"convolution-input-gradient-overfeat-fast-test\",\n                reference_layer_objects + [build.cxx(\"convolution-input-gradient/overfeat-fast.cc\")])\n\n            build.smoketest(\"convolution-kernel-gradient-smoketest\",\n                reference_layer_objects + [build.cxx(\"convolution-kernel-gradient/smoke.cc\")])\n            build.unittest(\"convolution-kernel-gradient-alexnet-test\",\n                reference_layer_objects + [build.cxx(\"convolution-kernel-gradient/alexnet.cc\")])\n            build.unittest(\"convolution-kernel-gradient-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"convolution-kernel-gradient/vgg-a.cc\")])\n            build.unittest(\"convolution-kernel-gradient-overfeat-fast-test\",\n                reference_layer_objects + [build.cxx(\"convolution-kernel-gradient/overfeat-fast.cc\")])\n\n        build.smoketest(\"convolution-inference-smoketest\",\n            reference_layer_objects + [build.cxx(\"convolution-inference/smoke.cc\")])\n        build.unittest(\"convolution-inference-alexnet-test\",\n            reference_layer_objects + [build.cxx(\"convolution-inference/alexnet.cc\")])\n        build.unittest(\"convolution-inference-vgg-a-test\",\n            reference_layer_objects + [build.cxx(\"convolution-inference/vgg-a.cc\")])\n        build.unittest(\"convolution-inference-overfeat-fast-test\",\n            reference_layer_objects + [build.cxx(\"convolution-inference/overfeat-fast.cc\")])\n\n        if not options.convolution_only:\n            build.unittest(\"fully-connected-inference-alexnet-test\",\n                reference_layer_objects + [build.cxx(\"fully-connected-inference/alexnet.cc\")])\n            build.unittest(\"fully-connected-inference-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"fully-connected-inference/vgg-a.cc\")])\n            build.unittest(\"fully-connected-inference-overfeat-fast-test\",\n                reference_layer_objects + [build.cxx(\"fully-connected-inference/overfeat-fast.cc\")])\n\n            if not options.inference_only:\n                build.smoketest(\"fully-connected-output-smoketest\",\n                    reference_layer_objects + [build.cxx(\"fully-connected-output/smoke.cc\")])\n                build.unittest(\"fully-connected-output-alexnet-test\",\n                    reference_layer_objects + [build.cxx(\"fully-connected-output/alexnet.cc\")])\n                build.unittest(\"fully-connected-output-vgg-a-test\",\n                    reference_layer_objects + [build.cxx(\"fully-connected-output/vgg-a.cc\")])\n                build.unittest(\"fully-connected-output-overfeat-fast-test\",\n                    reference_layer_objects + [build.cxx(\"fully-connected-output/overfeat-fast.cc\")])\n\n            build.smoketest(\"max-pooling-output-smoketest\",\n                reference_layer_objects + [build.cxx(\"max-pooling-output/smoke.cc\")])\n            build.unittest(\"max-pooling-output-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"max-pooling-output/vgg-a.cc\")])\n            build.unittest(\"max-pooling-output-overfeat-fast\",\n                reference_layer_objects + [build.cxx(\"max-pooling-output/overfeat-fast.cc\")])\n\n            build.unittest(\"relu-output-alexnet-test\",\n                reference_layer_objects + [build.cxx(\"relu-output/alexnet.cc\")])\n            build.unittest(\"relu-output-vgg-a-test\",\n                reference_layer_objects + [build.cxx(\"relu-output/vgg-a.cc\")])\n            build.unittest(\"relu-output-overfeat-fast-test\",\n                reference_layer_objects + [build.cxx(\"relu-output/overfeat-fast.cc\")])\n\n            if not options.inference_only:\n                build.unittest(\"relu-input-gradient-alexnet-test\",\n                    reference_layer_objects + [build.cxx(\"relu-input-gradient/alexnet.cc\")])\n                build.unittest(\"relu-input-gradient-vgg-a-test\",\n                    reference_layer_objects + [build.cxx(\"relu-input-gradient/vgg-a.cc\")])\n                build.unittest(\"relu-input-gradient-overfeat-fast-test\",\n                    reference_layer_objects + [build.cxx(\"relu-input-gradient/overfeat-fast.cc\")])\n\n            build.smoketest(\"softmax-output-smoketest\",\n                reference_layer_objects + [build.cxx(\"softmax-output/smoke.cc\")])\n            build.unittest(\"softmax-output-imagenet-test\",\n                reference_layer_objects + [build.cxx(\"softmax-output/imagenet.cc\")])\n\n    # Build automatic benchmarks\n    with build.options(source_dir=\"bench\", extra_include_dirs=[\"bench\", \"test\"], macros=macros, deps={\n            (build, build.deps.pthreadpool, build.deps.cpuinfo, build.deps.clog, build.deps.fp16, build.deps.googlebenchmark): all,\n            \"rt\": build.target.is_linux,\n            \"log\": build.target.is_android}):\n\n        build.benchmark(\"convolution-inference-bench\", build.cxx(\"convolution-inference.cc\"))\n        build.benchmark(\"sgemm-bench\", build.cxx(\"sgemm.cc\"))\n        build.benchmark(\"sxgemm-bench\", build.cxx(\"sxgemm.cc\"))\n        build.benchmark(\"hxgemm-bench\", build.cxx(\"hxgemm.cc\"))\n        build.benchmark(\"conv1x1-bench\", build.cxx(\"conv1x1.cc\"))\n        build.benchmark(\"winograd-bench\", build.cxx(\"winograd.cc\"))\n\n    # Build benchmarking utilities\n    if not options.inference_only and not build.target.is_android:\n        with build.options(source_dir=\"bench\", extra_include_dirs=\"bench\", macros=macros, deps={\n                (build, build.deps.pthreadpool, build.deps.cpuinfo, build.deps.clog): all,\n                \"rt\": build.target.is_linux,\n                \"log\": build.target.is_android}):\n\n            support_objects = [build.cc(\"median.c\")]\n            if build.target.is_x86_64:\n                support_objects += [build.peachpy(\"memread.py\")]\n            else:\n                support_objects += [build.cc(\"memread.c\")]\n            if build.target.is_linux and build.target.is_x86_64:\n                support_objects += [build.cc(\"perf_counter.c\")]\n\n            build.executable(\"transform-benchmark\",\n                [build.cc(\"transform.c\")] + support_objects)\n\n            build.executable(\"convolution-benchmark\",\n                [build.cc(\"convolution.c\")] + support_objects)\n\n            if not options.convolution_only:\n                build.executable(\"fully-connected-benchmark\",\n                    [build.cc(\"fully-connected.c\")] + support_objects)\n\n                build.executable(\"pooling-benchmark\",\n                    [build.cc(\"pooling.c\")] + support_objects)\n\n                build.executable(\"relu-benchmark\",\n                    [build.cc(\"relu.c\")] + support_objects)\n\n    return build\n\nif __name__ == \"__main__\":\n    import sys\n    main(sys.argv[1:]).generate()\n"
        },
        {
          "name": "confu.yaml",
          "type": "blob",
          "size": 0.482421875,
          "content": "name: nnpack\ntitle: Neural Networks acceleration PACKage\nlicense: Simplified BSD\ndeps:\n  - name: pthreadpool\n    url:  https://github.com/Maratyszcza/pthreadpool.git\n  - name: cpuinfo\n    url:  https://github.com/pytorch/cpuinfo.git\n  - name: fxdiv\n    url:  https://github.com/Maratyszcza/FXdiv.git\n  - name: fp16\n    url:  https://github.com/Maratyszcza/FP16.git\n  - name: psimd\n    url:  https://github.com/Maratyszcza/psimd.git\n  - name: clog\n  - name: googletest\n  - name: googlebenchmark\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "logo",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "web",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}