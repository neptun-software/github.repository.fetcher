{
  "metadata": {
    "timestamp": 1736709698131,
    "page": 71,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mackron/miniaudio",
      "stars": 4245,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.21484375,
          "content": "\\#issues/\n_private/\nexamples/build/vc6/\nexamples/build/vc15/\nexamples/build/bin/\ntests/_build/bin/\ntests/_build/res/output/\ntests/_build/tcc/\ntests/_build/vc6/\ntests/_build/vc15/\ntools/_build/\n*.vcxproj.user\n.vs/\n.idea/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "CHANGES.md",
          "type": "blob",
          "size": 64.79296875,
          "content": "v0.11.21 - 2023-11-15\n=====================\n* Add new ma_device_notification_type_unlocked notification. This is used on Web and will be fired after the user has performed a gesture and thus unlocked the ability to play audio.\n* Web: Fix an error where the buffer size is incorrectly calculated.\n* Core Audio: Fix a -Wshadow warning.\n\n\nv0.11.20 - 2023-11-10\n=====================\n* Fix a compilation error with iOS.\n* Fix an error when dynamically linking libraries when forcing the UWP build on desktop.\n\n\nv0.11.19 - 2023-11-04\n=====================\n* Fix a bug where `ma_decoder_init_file()` can incorrectly return successfully.\n* Fix a crash when using a node with more than 2 outputs.\n* Fix a bug where `ma_standard_sample_rate_11025` uses the incorrect rate.\n* Fix a bug in `ma_noise` where only white noise would be generated even when specifying pink or Brownian.\n* Fix an SSE related bug when converting from mono streams.\n* Documentation fixes.\n* Remove the use of some deprecated functions.\n* Improvements to runtime linking on Apple platforms.\n* Web / Emscripten: Audio will no longer attempt to unlock in response to the \"touchstart\" event. This addresses an issue with iOS and Safari. This results in a change of behavior if you were previously depending on starting audio when the user's finger first touches the screen. Audio will now only unlock when the user's finger is lifted. See this discussion for details: https://github.com/mackron/miniaudio/issues/759\n* Web / Emscripten: Fix an error when using a sample rate of 0 in the device config.\n\n\nv0.11.18 - 2023-08-07\n=====================\n* Fix some AIFF compatibility issues.\n* Fix an error where the cursor of a Vorbis stream is incorrectly incremented.\n* Add support for setting a callback on an `ma_engine` object that get's fired after it processes a chunk of audio. This allows applications to do things such as apply a post-processing effect or output the audio to a file.\n* Add `ma_engine_get_volume()`.\n* Add `ma_sound_get_time_in_milliseconds()`.\n* Decouple `MA_API` and `MA_PRIVATE`. This relaxes applications from needing to define both of them if they're only wanting to redefine one.\n* Decoding backends will now have their onInitFile/W and onInitMemory initialization routines used where appropriate if they're defined.\n* Increase the accuracy of the linear resampler when setting the ratio with `ma_linear_resampler_set_rate_ratio()`.\n* Fix erroneous output with the linear resampler when in/out rates are the same.\n* AAudio: Fix an error where the buffer size is not configured correctly which sometimes results in excessively high latency.\n* ALSA: Fix a possible error when stopping and restarting a device.\n* PulseAudio: Minor changes to stream flags.\n* Win32: Fix an error where `CoUninialize()` is being called when the corresponding `CoInitializeEx()` fails.\n* Web / Emscripten: Add support for AudioWorklets. This is opt-in and can be enabled by defining `MA_ENABLE_AUDIO_WORKLETS`. You must compile with `-sAUDIO_WORKLET=1 -sWASM_WORKERS=1 -sASYNCIFY` for this to work. Requires at least Emscripten v3.1.32.\n\n\nv0.11.17 - 2023-05-27\n=====================\n* Fix compilation errors with MA_USE_STDINT.\n* Fix a possible runtime error with Windows 95/98.\n* Fix a very minor linting warning in VS2022.\n* Add support for AIFF/AIFC decoding.\n* Add support for RIFX decoding.\n* Work around some bad code generation by Clang.\n* Amalgamations of dr_wav, dr_flac, dr_mp3 and c89atomic have been updated so that they're now fully namespaced. This allows each of these libraries to be able to be used alongside miniaudio without any conflicts. In addition, some duplicate code, such as sized type declarations, result codes, etc. has been removed.\n\n\nv0.11.16 - 2023-05-15\n=====================\n* Fix a memory leak with `ma_sound_init_copy()`.\n* Improve performance of `ma_sound_init_*()` when using the `ASYNC | DECODE` flag combination.\n\n\nv0.11.15 - 2023-04-30\n=====================\n* Fix a bug where initialization of a duplex device fails on some backends.\n* Fix a bug in ma_gainer where smoothing isn't applied correctly thus resulting in glitching.\n* Add support for volume smoothing to sounds when changing the volume with `ma_sound_set_volume()`. To use this, you must configure it via the `volumeSmoothTimeInPCMFrames` member of ma_sound_config and use `ma_sound_init_ex()` to initialize your sound. Smoothing is disabled by default.\n* WASAPI: Fix a possible buffer overrun when initializing a device.\n* WASAPI: Make device initialization more robust by improving the handling of the querying of the internal data format.\n\n\nv0.11.14 - 2023-03-29\n=====================\n* Fix some pedantic warnings when compiling with GCC.\n* Fix some crashes with the WAV decoder when loading an invalid file.\n* Fix a channel mapping error with PipeWire which results in no audio being output.\n* Add support for using `ma_pcm_rb` as a data source.\n* Silence some C89 compatibility warnings with Clang.\n* The `pBytesRead` parameter of the VFS onRead callback is now pre-initialized to zero.\n\n\nv0.11.13 - 2023-03-23\n=====================\n* Fix compilation errors with the C++ build.\n* Fix compilation errors when WIN32_LEAN_AND_MEAN is defined.\n\n\nv0.11.12 - 2023-03-19\n=====================\n* Fix a bug with data source ranges which resulted in data being read from outside the range.\n* Fix a crash due to a race condition in the resource manager.\n* Fix a crash with some backends when rerouting the playback side of a duplex device.\n* Fix some bugs with initialization of POSIX threads.\n* Fix a bug where sounds are not resampled when `MA_SOUND_NO_PITCH` is used.\n* Fix a bug where changing the range of a data source would result in no audio being read.\n* Fix a bug where asynchronously loaded data sources via the resources manager would reset ranges and loop points.\n* Fix some Wimplicit-fallthrough warnings.\n* Add support for Windows 95/98.\n* Add support for configuring the stack size of resource manager job threads.\n* Add support for callback notifications when a sound reaches the end.\n* Optimizations to the high level API.\n* Remove the old runtime linking system for pthread. The `MA_USE_RUNTIME_LINKING_FOR_PTHREAD` option is no longer used.\n* WASAPI: Fix a crash when starting a device while it's in the process of rerouting.\n* Windows: Remove the Windows-specific default memcpy(), malloc(), etc.\n\n\nv0.11.11 - 2022-11-04\n=====================\n* Silence an unused variable warning.\n* Remove references to ccall() from the Empscripten build.\n* Improve Android detection.\n* WASAPI: Some minor improvements to overrun recovery for capture and duplex modes.\n\n\nv0.11.10 - 2022-10-20\n=====================\n* Add support for setting the device notification callback when initializing an engine object.\n* Add support for more than 2 outputs to splitter nodes.\n* Fix a crash when initializing a channel converter.\n* Fix a channel mapping error where weights are calculated incorrectly.\n* Fix an unaligned access error.\n* Fix logging with the C++ build.\n* Fix some undefined behavior errors, including some memset()'s to null pointers of 0 bytes.\n* Fix logging of device info for loopback devices.\n* WASAPI: Fix an error where 32-bit formats are not properly detected.\n* WASAPI: Fix a bug where the device is not drained when stopped.\n* WASAPI: Fix an issue with loopback mode that results in waiting indefinitely and the callback never getting fired.\n* WASAPI: Add support for the Avrt API to specify the audio thread's latency sensitivity requirements. Use the `deviceConfig.wasapi.usage` configuration option.\n* PulseAudio: Pass the requested sample rate, if set, to PulseAudio so that it uses the requested sample rate internally rather than always using miniaudio's resampler.\n* PulseAudio: Fix a rare null pointer dereference.\n* ALSA: Fix a potential crash on older versions of Linux.\n* Core Audio: Fix a very unlikely memory leak.\n* Core Audio: Update a deprecated symbol.\n* AAudio: Fix an error where the wrong tokens are being used for usage, content types and input preset hints.\n* WebAudio: Do some cleanup of the internal global JavaScript object when the last context has been uninitialized.\n* Win32: Fix an error when the channel mask reported by Windows is all zero.\n* Various documentation fixes.\n* Bring dr_wav, dr_flac and dr_mp3 up-to-date with latest versions.\n\n\nv0.11.9 - 2022-04-20\n====================\n* Fix some bugs where looping doesn't work with the resource manager.\n* Fix a crash when seeking a sound.\n* Fix a subtle bug the results in a glitch when looping a decoder when resampling is being applied.\n* Fix an issue where chaining streams would not result in a seamless transition.\n* Add a new flag called MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_UNKNOWN_LENGTH for use with resource managed data sources. This flag is used as a hint to the resource manager that the length of the data source is unknown and calling ma_data_source_get_length_in_pcm_frames() should be avoided.\n* Add support for resetting a resampler. This is useful for resetting the internal timer and clearing the internal cache for when you want to seek the input sound source back to the start.\n* Add support for clearing the cache from biquads and low-pass filters.\n\n\nv0.11.8 - 2022-02-12\n====================\n* PulseAudio: Work around bugs in PipeWire:\n  - PipeWire is returning AUX channels for stereo streams instead of FL/FR. This workaround forces FL/FR for stereo streams.\n  - PipeWire will glitch when the buffer size is too small, but still well within reasonable limits. To work around this bug, the default buffer size on PulseAudio backends is now 25ms. You can override this in the device config. This bug does not exist with regular PulseAudio, but the new default buffer size will still apply because I'm not aware of a good way to detect if PipeWire is being used. If anybody has advice on how to detect this, I'm happy to listen!\n* DirectSound: Increase the minimum period size from 20ms to 30ms.\n* Return `MA_SUCCESS` from `ma_device_start()` and `ma_device_stopped()` if the device is already started or stopped respectively.\n* Fix an incorrect assertion in the data converter.\n* Fix a compilation error with ARM builds.\n\n\nv0.11.7 - 2022-02-06\n====================\n* Fix an error when seeking to the end of a WAV file.\n* Fix a memory leak with low-pass, high-pass and band-pass filters.\n* Fix some bugs in the FLAC decoder.\n* Fix a -Wundef warning\n\n\nv0.11.6 - 2022-01-22\n====================\n* WASAPI: Fix a bug where the device is not stopped when an error occurrs when writing to a playback device.\n* PulseAudio: Fix a rare crash due to a division by zero.\n* The node graph can now be used as a node. This allows node graphs to be connected to other node graphs.\n* Fix a crash with high-pass and band-pass filters.\n* Fix an audio glitch when mixing engine nodes (ma_sound and ma_sound_group).\n* Add some new helper APIs for cursor and length retrieval:\n  - ma_data_source_get_cursor_in_seconds()\n  - ma_data_source_get_length_in_seconds()\n  - ma_sound_get_cursor_in_seconds()\n  - ma_sound_get_length_in_seconds()\n\n\nv0.11.5 - 2022-01-16\n====================\n* WASAPI: Fix a bug in duplex mode when the capture and playback devices have different native sample rates.\n* AAudio: Add support for automatic stream routing.\n* iOS: The interruption_began notification now automatically calls `ma_device_stop()`. This allows `ma_device_start()` to work as expected when called from interruption_ended.\n* iOS: Fix a bug that results in a deadlock when stopping the device in response to the interruption_begain or interruption_ended notifications.\n* Fix a bug with fixed sized callbacks that results in glitches in duplex mode.\n* Fix a bug that results in a deadlock when starting a device.\n* ma_engine_play_sound_ex() is now publicly visible.\n* Add validation to ma_sound_set_pitch() to prevent negative pitches.\n* Add validation to resamplers to prevent negative ratios.\n\n\n---------------------------------------------------------------------------------------------------\n\nv0.11.4 - 2022-01-12\n  - AAudio: Add initial support for automatic stream routing.\n  - Add support for initializing an encoder from a VFS.\n  - Fix a bug when initializing an encoder from a file where the file handle does not get closed in\n    the event of an error.\n\nv0.11.3 - 2022-01-07\n  - Add a new flag for nodes called MA_NODE_FLAG_SILENT_OUTPUT which tells miniaudio that the\n    output of the node should always be treated as silence. This gives miniaudio an optimization\n    opportunity by skipping mixing of those nodes. Useful for special nodes that need to have\n    their outputs wired up to the graph so they're processed, but don't want the output to\n    contribute to the final mix.\n  - Add support for fixed sized callbacks. With this change, the data callback will be fired with\n    a consistent frame count based on the periodSizeInFrames or periodSizeInMilliseconds config\n    variable (depending on which one is used). If the period size is not specified, the backend's\n    internal period size will be used. Under the hood this uses an intermediary buffer which\n    introduces a small inefficiency. To avoid this you can use the `noFixedSizedCallback` config\n    variable and set it to true. This will make the callback equivalent to the way it was before\n    this change and will avoid the intermediary buffer, but the data callback could get fired with\n    an inconsistent frame count which might cause problems where certain operations need to operate\n    on fixed sized chunks.\n  - Change the logging system to always process debug log messages. This is useful for allowing\n    debug and test builds of applications to output debug information that can later be passed on\n    for debugging in miniaudio. To filter out these messages, just filter against the log level\n    which will be MA_LOG_LEVEL_DEBUG.\n  - Change the wav decoder to pick the closest format to the source file by default if no preferred\n    format is specified.\n  - Fix a bug where ma_device_get_info() and ma_device_get_name() return an error.\n  - Fix a bug where ma_data_source_read_pcm_frames() can return MA_AT_END even when some data has\n    been read. MA_AT_END should only be returned when nothing has been read.\n  - PulseAudio: Fix some bugs where starting and stopping a device can result in a deadlock.\n\nv0.11.2 - 2021-12-31\n  - Add a new device notification system to replace the stop callback. The stop callback is still\n    in place, but will be removed in version 0.12. New code should use the notificationCallback\n    member in the device config instead of stopCallback.\n  - Fix a bug where the stopped notification doesn't get fired.\n  - iOS: The IO buffer size is now configured based on the device's configured period size.\n  - WebAudio: Optimizations to some JavaScript code.\n\nv0.11.1 - 2021-12-27\n  - Result codes are now declared as an enum rather than #defines.\n  - Channel positions (MA_CHANNEL_*) are now declared as an enum rather than #defines.\n  - Add ma_device_get_info() for retrieving device information from an initialized device.\n  - Add ma_device_get_name() for retrieving the name of an initialized device.\n  - Add support for setting the directional attenuation factor to sounds and groups.\n  - Fix a crash when passing in NULL for the pEngine parameter of ma_engine_init().\n  - Fix a bug where the node graph will output silence if a node has zero input connections.\n  - Fix a bug in the engine where sounds in front of the listener are too loud.\n  - AAudio: Fix an incorrect assert.\n  - AAudio: Fix a bug that resulted in exclusive mode always resulting in initialization failure.\n  - AAudio: Fix a bug that resulted in a capture device incorrectly being detected as disconnected.\n  - OpenSL: Fix an error when initializing a device with a non-NULL device ID.\n  - OpenSL: Fix some bugs with device initialization.\n\nv0.11.0 - 2021-12-18\n  - Add a node graph system for advanced mixing and effect processing.\n  - Add a resource manager for loading and streaming sounds.\n  - Add a high level engine API for sound management and mixing. This wraps around the node graph\n    and resource manager.\n  - Add support for custom resmplers.\n  - Add ma_decoder_get_data_format().\n  - Add support for disabling denormals on the audio thread.\n  - Add a delay/echo effect called ma_delay.\n  - Add a stereo pan effect called ma_panner.\n  - Add a spataializer effect called ma_spatializer.\n  - Add support for amplification for device master volume.\n  - Remove dependency on MA_MAX_CHANNELS from filters and data conversion.\n  - Increase MA_MAX_CHANNELS from 32 to 254.\n  - API CHANGE: Changes have been made to the way custom data sources are made. See documentation\n    on how to implement custom data sources.\n  - API CHANGE: Remove ma_data_source_map() and ma_data_source_unmap()\n  - API CHANGE: Remove the `loop` parameter from ma_data_source_read_pcm_frames(). Use\n    ma_data_source_set_looping() to enable or disable looping.\n  - API CHANGE: Remove ma_channel_mix_mode_planar_blend. Use ma_channel_mix_mode_rectangular instead.\n  - API CHANGE: Remove MA_MIN_SAMPLE_RATE and MA_MAX_SAMPLE_RATE. Use ma_standard_sample_rate_min\n    and ma_standard_sample_rate_max instead.\n  - API CHANGE: Changes have been made to the ma_device_info structure. See documentation for\n    details of these changes.\n  - API CHANGE: Remove the `shareMode` parameter from ma_context_get_device_info().\n  - API CHANGE: Rename noPreZeroedOutputBuffer to noPreSilencedOutputBuffer in the device config.\n  - API CHANGE: Remove pBufferOut parameter from ring buffer commit functions.\n  - API CHANGE: Remove ma_zero_pcm_frames(). Use ma_silence_pcm_frames() instead.\n  - API CHANGE: Change ma_clip_samples_f32() to take input and output buffers rather than working\n    exclusively in-place.\n  - API CHANGE: Remove ma_clip_pcm_frames_f32(). Use ma_clip_samples_f32() or ma_clip_pcm_frames()\n    instead.\n  - API CHANGE: Remove the onLog callback from the context config and replaced with a more\n    flexible system. See the documentation for how to use logging.\n  - API CHANGE: Remove MA_LOG_LEVEL_VERBOSE and add MA_LOG_LEVEL_DEBUG. Logs using the\n    MA_LOG_LEVEL_DEBUG logging level will only be output when miniaudio is compiled with the\n    MA_DEBUG_OUTPUT option.\n  - API CHANGE: MA_LOG_LEVEL has been removed. All log levels will be posted, except for\n    MA_LOG_LEVEL_DEBUG which will only be output when MA_DEBUG_OUTPUT is enabled.\n  - API CHANGE: Rename ma_resource_format to ma_encoding_format.\n  - API CHANGE: Remove all encoding-specific initialization routines for decoders. Use the\n    encodingFormat properties in the decoder config instead.\n  - API CHANGE: Change ma_decoder_get_length_in_pcm_frames() to return a result code and output the\n    number of frames read via an output parameter.\n  - API CHANGE: Allocation callbacks must now implement the onRealloc() callback.\n  - API CHANGE: Remove ma_get_standard_channel_map() and add ma_channel_map_init_standard().\n  - API CHANGE: Rename ma_channel_map_valid() to ma_channel_map_is_valid().\n  - API CHANGE: Rename ma_channel_map_equal() to ma_channel_map_is_equal().\n  - API CHANGE: Rename ma_channel_map_blank() to ma_channel_map_is_blank().\n  - API CHANGE: Remove the Speex resampler. Use a custom resampler instead.\n  - API CHANGE: Change the following resampler APIs to return a result code and output their result\n    via an output parameter:\n    - ma_linear_resampler_get_required_input_frame_count()\n    - ma_linear_resampler_get_expected_output_frame_count()\n    - ma_resampler_get_required_input_frame_count()\n    - ma_resampler_get_expected_output_frame_count()\n  - API CHANGE: Update relevant init/uninit functions to take a pointer to allocation callbacks.\n  - API CHANGE: Remove ma_scale_buffer_size()\n  - API CHANGE: Update ma_encoder_write_pcm_frames() to return a result code and output the number\n    of frames written via an output parameter.\n  - API CHANGE: Update ma_noise_read_pcm_frames() to return a result code and output the number of\n    frames read via an output parameter.\n  - API CHANGE: Update ma_waveform_read_pcm_frames() to return a result code and output the number\n    of frames read via an output parameter.\n  - API CHANGE: Remove The MA_STATE_* and add ma_device_state_* enums.\n  - API CHANGE: Rename ma_factor_to_gain_db() to ma_volume_linear_to_db().\n  - API CHANGE: Rename ma_gain_db_to_factor() to ma_volume_db_to_linear().\n  - API CHANGE: Rename ma_device_set_master_gain_db() to ma_device_set_master_volume_db().\n  - API CHANGE: Rename ma_device_get_master_gain_db() to ma_device_get_master_volume_db()\n\nv0.10.43 - 2021-12-10\n  - ALSA: Fix use of uninitialized variables.\n  - ALSA: Fix enumeration of devices that support both playback and capture.\n  - PulseAudio: Fix a possible division by zero.\n  - WebAudio: Fix errors in strict mode.\n\nv0.10.42 - 2021-08-22\n  - Fix a possible deadlock when stopping devices.\n\nv0.10.41 - 2021-08-15\n  - Core Audio: Fix some deadlock errors.\n\nv0.10.40 - 2021-07-23\n  - Fix a bug when converting from stereo to mono.\n  - PulseAudio: Fix a glitch when pausing and resuming a device.\n\nv0.10.39 - 2021-07-20\n  - Core Audio: Fix a deadlock when the default device is changed.\n  - Core Audio: Fix compilation errors on macOS and iOS.\n  - PulseAudio: Fix a bug where the stop callback is not fired when a device is unplugged.\n  - PulseAudio: Fix a null pointer dereference.\n\nv0.10.38 - 2021-07-14\n  - Fix a linking error when MA_DEBUG_OUTPUT is not enabled.\n  - Fix an error where ma_log_postv() does not return a value.\n  - OpenSL: Fix a bug with setting of stream types and recording presets.\n\n0.10.37 - 2021-07-06\n  - Fix a bug with log message formatting.\n  - Fix build when compiling with MA_NO_THREADING.\n  - Minor updates to channel mapping.\n\n0.10.36 - 2021-07-03\n  - Add support for custom decoding backends.\n  - Fix some bugs with the Vorbis decoder.\n  - PulseAudio: Fix a bug with channel mapping.\n  - PulseAudio: Fix a bug where miniaudio does not fall back to a supported format when PulseAudio\n    defaults to a format not known to miniaudio.\n  - OpenSL: Fix a crash when initializing a capture device when a recording preset other than the\n    default is specified.\n  - Silence some warnings when compiling with MA_DEBUG_OUTPUT\n  - Improvements to logging. See the `ma_log` API for details. The logCallback variable used by\n    ma_context has been deprecated and will be replaced with the new system in version 0.11.\n    - Initialize an `ma_log` object with `ma_log_init()`.\n    - Register a callback with `ma_log_register_callback()`.\n    - In the context config, set `pLog` to your `ma_log` object and stop using `logCallback`.\n  - Prep work for some upcoming changes to data sources. These changes are still compatible with\n    existing code, however code will need to be updated in preparation for version 0.11 which will\n    be breaking. You should make these changes now for any custom data sources:\n    - Change your base data source object from `ma_data_source_callbacks` to `ma_data_source_base`.\n    - Call `ma_data_source_init()` for your base object in your custom data source's initialization\n      routine. This takes a config object which includes a pointer to a vtable which is now where\n      your custom callbacks are defined.\n    - Call `ma_data_source_uninit()` in your custom data source's uninitialization routine. This\n      doesn't currently do anything, but it placeholder in case some future uninitialization code\n      is required to be added at a later date.\n\nv0.10.35 - 2021-04-27\n  - Fix the C++ build.\n\nv0.10.34 - 2021-04-26\n  - WASAPI: Fix a bug where a result code is not getting checked at initialization time.\n  - WASAPI: Bug fixes for loopback mode.\n  - ALSA: Fix a possible deadlock when stopping devices.\n  - Mark devices as default on the null backend.\n\nv0.10.33 - 2021-04-04\n  - Core Audio: Fix a memory leak.\n  - Core Audio: Fix a bug where the performance profile is not being used by playback devices.\n  - JACK: Fix loading of 64-bit JACK on Windows.\n  - Fix a calculation error and add a safety check to the following APIs to prevent a division by zero:\n    - ma_calculate_buffer_size_in_milliseconds_from_frames()\n    - ma_calculate_buffer_size_in_frames_from_milliseconds()\n  - Fix compilation errors relating to c89atomic.\n  - Update FLAC decoder.\n\nv0.10.32 - 2021-02-23\n  - WASAPI: Fix a deadlock in exclusive mode.\n  - WASAPI: No longer return an error from ma_context_get_device_info() when an exclusive mode format\n    cannot be retrieved.\n  - WASAPI: Attempt to fix some bugs with device uninitialization.\n  - PulseAudio: Yet another refactor, this time to remove the dependency on `pa_threaded_mainloop`.\n  - Web Audio: Fix a bug on Chrome and any other browser using the same engine.\n  - Web Audio: Automatically start the device on some user input if the device has been started. This\n    is to work around Google's policy of not starting audio if no user input has yet been performed.\n  - Fix a bug where thread handles are not being freed.\n  - Fix some static analysis warnings in FLAC, WAV and MP3 decoders.\n  - Fix a warning due to referencing _MSC_VER when it is undefined.\n  - Update to latest version of c89atomic.\n  - Internal refactoring to migrate over to the new backend callback system for the following backends:\n    - PulseAudio\n    - ALSA\n    - Core Audio\n    - AAudio\n    - OpenSL|ES\n    - OSS\n    - audio(4)\n    - sndio\n\nv0.10.31 - 2021-01-17\n  - Make some functions const correct.\n  - Update ma_data_source_read_pcm_frames() to initialize pFramesRead to 0 for safety.\n  - Add the MA_ATOMIC annotation for use with variables that should be used atomically and remove unnecessary volatile qualifiers.\n  - Add support for enabling only specific backends at compile time. This is the reverse of the pre-existing system. With the new\n    system, all backends are first disabled with `MA_ENABLE_ONLY_SPECIFIC_BACKENDS`, which is then followed with `MA_ENABLE_*`. The\n    old system where you disable backends with `MA_NO_*` still exists and is still the default.\n\nv0.10.30 - 2021-01-10\n  - Fix a crash in ma_audio_buffer_read_pcm_frames().\n  - Update spinlock APIs to take a volatile parameter as input.\n  - Silence some unused parameter warnings.\n  - Fix a warning on GCC when compiling as C++.\n\nv0.10.29 - 2020-12-26\n  - Fix some subtle multi-threading bugs on non-x86 platforms.\n  - Fix a bug resulting in superfluous memory allocations when enumerating devices.\n  - Core Audio: Fix a compilation error when compiling for iOS.\n\nv0.10.28 - 2020-12-16\n  - Fix a crash when initializing a POSIX thread.\n  - OpenSL|ES: Respect the MA_NO_RUNTIME_LINKING option.\n\nv0.10.27 - 2020-12-04\n  - Add support for dynamically configuring some properties of `ma_noise` objects post-initialization.\n  - Add support for configuring the channel mixing mode in the device config.\n  - Fix a bug with simple channel mixing mode (drop or silence excess channels).\n  - Fix some bugs with trying to access uninitialized variables.\n  - Fix some errors with stopping devices for synchronous backends where the backend's stop callback would get fired twice.\n  - Fix a bug in the decoder due to using an uninitialized variable.\n  - Fix some data race errors.\n\nv0.10.26 - 2020-11-24\n  - WASAPI: Fix a bug where the exclusive mode format may not be retrieved correctly due to accessing freed memory.\n  - Fix a bug with ma_waveform where glitching occurs after changing frequency.\n  - Fix compilation with OpenWatcom.\n  - Fix compilation with TCC.\n  - Fix compilation with Digital Mars.\n  - Fix compilation warnings.\n  - Remove bitfields from public structures to aid in binding maintenance.\n\nv0.10.25 - 2020-11-15\n  - PulseAudio: Fix a bug where the stop callback isn't fired.\n  - WebAudio: Fix an error that occurs when Emscripten increases the size of it's heap.\n  - Custom Backends: Change the onContextInit and onDeviceInit callbacks to take a parameter which is a pointer to the config that was\n    passed into ma_context_init() and ma_device_init(). This replaces the deviceType parameter of onDeviceInit.\n  - Fix compilation warnings on older versions of GCC.\n\nv0.10.24 - 2020-11-10\n  - Fix a bug where initialization of a backend can fail due to some bad state being set from a prior failed attempt at initializing a\n    lower priority backend.\n\nv0.10.23 - 2020-11-09\n  - AAudio: Add support for configuring a playback stream's usage.\n  - Fix a compilation error when all built-in asynchronous backends are disabled at compile time.\n  - Fix compilation errors when compiling as C++.\n\nv0.10.22 - 2020-11-08\n  - Add support for custom backends.\n  - Add support for detecting default devices during device enumeration and with `ma_context_get_device_info()`.\n  - Refactor to the PulseAudio backend. This simplifies the implementation and fixes a capture bug.\n  - ALSA: Fix a bug in `ma_context_get_device_info()` where the PCM handle is left open in the event of an error.\n  - Core Audio: Further improvements to sample rate selection.\n  - Core Audio: Fix some bugs with capture mode.\n  - OpenSL: Add support for configuring stream types and recording presets.\n  - AAudio: Add support for configuring content types and input presets.\n  - Fix bugs in `ma_decoder_init_file*()` where the file handle is not closed after a decoding error.\n  - Fix some compilation warnings on GCC and Clang relating to the Speex resampler.\n  - Fix a compilation error for the Linux build when the ALSA and JACK backends are both disabled.\n  - Fix a compilation error for the BSD build.\n  - Fix some compilation errors on older versions of GCC.\n  - Add documentation for `MA_NO_RUNTIME_LINKING`.\n\nv0.10.21 - 2020-10-30\n  - Add ma_is_backend_enabled() and ma_get_enabled_backends() for retrieving enabled backends at run-time.\n  - WASAPI: Fix a copy and paste bug relating to loopback mode.\n  - Core Audio: Fix a bug when using multiple contexts.\n  - Core Audio: Fix a compilation warning.\n  - Core Audio: Improvements to sample rate selection.\n  - Core Audio: Improvements to format/channels/rate selection when requesting defaults.\n  - Core Audio: Add notes regarding the Apple notarization process.\n  - Fix some bugs due to null pointer dereferences.\n\nv0.10.20 - 2020-10-06\n  - Fix build errors with UWP.\n  - Minor documentation updates.\n\nv0.10.19 - 2020-09-22\n  - WASAPI: Return an error when exclusive mode is requested, but the native format is not supported by miniaudio.\n  - Fix a bug where ma_decoder_seek_to_pcm_frames() never returns MA_SUCCESS even though it was successful.\n  - Store the sample rate in the `ma_lpf` and `ma_hpf` structures.\n\nv0.10.18 - 2020-08-30\n  - Fix build errors with VC6.\n  - Fix a bug in channel converter for s32 format.\n  - Change channel converter configs to use the default channel map instead of a blank channel map when no channel map is specified when initializing the\n    config. This fixes an issue where the optimized mono expansion path would never get used.\n  - Use a more appropriate default format for FLAC decoders. This will now use ma_format_s16 when the FLAC is encoded as 16-bit.\n  - Update FLAC decoder.\n  - Update links to point to the new repository location (https://github.com/mackron/miniaudio).\n\nv0.10.17 - 2020-08-28\n  - Fix an error where the WAV codec is incorrectly excluded from the build depending on which compile time options are set.\n  - Fix a bug in ma_audio_buffer_read_pcm_frames() where it isn't returning the correct number of frames processed.\n  - Fix compilation error on Android.\n  - Core Audio: Fix a bug with full-duplex mode.\n  - Add ma_decoder_get_cursor_in_pcm_frames().\n  - Update WAV codec.\n\nv0.10.16 - 2020-08-14\n  - WASAPI: Fix a potential crash due to using an uninitialized variable.\n  - OpenSL: Enable runtime linking.\n  - OpenSL: Fix a multithreading bug when initializing and uninitializing multiple contexts at the same time.\n  - iOS: Improvements to device enumeration.\n  - Fix a crash in ma_data_source_read_pcm_frames() when the output frame count parameter is NULL.\n  - Fix a bug in ma_data_source_read_pcm_frames() where looping doesn't work.\n  - Fix some compilation warnings on Windows when both DirectSound and WinMM are disabled.\n  - Fix some compilation warnings when no decoders are enabled.\n  - Add ma_audio_buffer_get_available_frames().\n  - Add ma_decoder_get_available_frames().\n  - Add sample rate to ma_data_source_get_data_format().\n  - Change volume APIs to take 64-bit frame counts.\n  - Updates to documentation.\n\nv0.10.15 - 2020-07-15\n  - Fix a bug when converting bit-masked channel maps to miniaudio channel maps. This affects the WASAPI and OpenSL backends.\n\nv0.10.14 - 2020-07-14\n  - Fix compilation errors on Android.\n  - Fix compilation errors with -march=armv6.\n  - Updates to the documentation.\n\nv0.10.13 - 2020-07-11\n  - Fix some potential buffer overflow errors with channel maps when channel counts are greater than MA_MAX_CHANNELS.\n  - Fix compilation error on Emscripten.\n  - Silence some unused function warnings.\n  - Increase the default buffer size on the Web Audio backend. This fixes glitching issues on some browsers.\n  - Bring FLAC decoder up-to-date with dr_flac.\n  - Bring MP3 decoder up-to-date with dr_mp3.\n\nv0.10.12 - 2020-07-04\n  - Fix compilation errors on the iOS build.\n\nv0.10.11 - 2020-06-28\n  - Fix some bugs with device tracking on Core Audio.\n  - Updates to documentation.\n\nv0.10.10 - 2020-06-26\n  - Add include guard for the implementation section.\n  - Mark ma_device_sink_info_callback() as static.\n  - Fix compilation errors with MA_NO_DECODING and MA_NO_ENCODING.\n  - Fix compilation errors with MA_NO_DEVICE_IO\n\nv0.10.9 - 2020-06-24\n  - Amalgamation of dr_wav, dr_flac and dr_mp3. With this change, including the header section of these libraries before the implementation of miniaudio is no\n    longer required. Decoding of WAV, FLAC and MP3 should be supported seamlessly without any additional libraries. Decoders can be excluded from the build\n    with the following options:\n    - MA_NO_WAV\n    - MA_NO_FLAC\n    - MA_NO_MP3\n    If you get errors about multiple definitions you need to either enable the options above, move the implementation of dr_wav, dr_flac and/or dr_mp3 to before\n    the implementation of miniaudio, or update dr_wav, dr_flac and/or dr_mp3.\n  - Changes to the internal atomics library. This has been replaced with c89atomic.h which is embedded within this file.\n  - Fix a bug when a decoding backend reports configurations outside the limits of miniaudio's decoder abstraction.\n  - Fix the UWP build.\n  - Fix the Core Audio build.\n  - Fix the -std=c89 build on GCC.\n\nv0.10.8 - 2020-06-22\n  - Remove dependency on ma_context from mutexes.\n  - Change ma_data_source_read_pcm_frames() to return a result code and output the frames read as an output parameter.\n  - Change ma_data_source_seek_pcm_frames() to return a result code and output the frames seeked as an output parameter.\n  - Change ma_audio_buffer_unmap() to return MA_AT_END when the end has been reached. This should be considered successful.\n  - Change playback.pDeviceID and capture.pDeviceID to constant pointers in ma_device_config.\n  - Add support for initializing decoders from a virtual file system object. This is achieved via the ma_vfs API and allows the application to customize file\n    IO for the loading and reading of raw audio data. Passing in NULL for the VFS will use defaults. New APIs:\n    - ma_decoder_init_vfs()\n    - ma_decoder_init_vfs_wav()\n    - ma_decoder_init_vfs_flac()\n    - ma_decoder_init_vfs_mp3()\n    - ma_decoder_init_vfs_vorbis()\n    - ma_decoder_init_vfs_w()\n    - ma_decoder_init_vfs_wav_w()\n    - ma_decoder_init_vfs_flac_w()\n    - ma_decoder_init_vfs_mp3_w()\n    - ma_decoder_init_vfs_vorbis_w()\n  - Add support for memory mapping to ma_data_source.\n    - ma_data_source_map()\n    - ma_data_source_unmap()\n  - Add ma_offset_pcm_frames_ptr() and ma_offset_pcm_frames_const_ptr() which can be used for offsetting a pointer by a specified number of PCM frames.\n  - Add initial implementation of ma_yield() which is useful for spin locks which will be used in some upcoming work.\n  - Add documentation for log levels.\n  - The ma_event API has been made public in preparation for some uncoming work.\n  - Fix a bug in ma_decoder_seek_to_pcm_frame() where the internal sample rate is not being taken into account for determining the seek location.\n  - Fix some bugs with the linear resampler when dynamically changing the sample rate.\n  - Fix compilation errors with MA_NO_DEVICE_IO.\n  - Fix some warnings with GCC and -std=c89.\n  - Fix some formatting warnings with GCC and -Wall and -Wpedantic.\n  - Fix some warnings with VC6.\n  - Minor optimization to ma_copy_pcm_frames(). This is now a no-op when the input and output buffers are the same.\n\nv0.10.7 - 2020-05-25\n  - Fix a compilation error in the C++ build.\n  - Silence a warning.\n\nv0.10.6 - 2020-05-24\n  - Change ma_clip_samples_f32() and ma_clip_pcm_frames_f32() to take a 64-bit sample/frame count.\n  - Change ma_zero_pcm_frames() to clear to 128 for ma_format_u8.\n  - Add ma_silence_pcm_frames() which replaces ma_zero_pcm_frames(). ma_zero_pcm_frames() will be removed in version 0.11.\n  - Add support for u8, s24 and s32 formats to ma_channel_converter.\n  - Add compile-time and run-time version querying.\n    - MA_VERSION_MINOR\n    - MA_VERSION_MAJOR\n    - MA_VERSION_REVISION\n    - MA_VERSION_STRING\n    - ma_version()\n    - ma_version_string()\n  - Add ma_audio_buffer for reading raw audio data directly from memory.\n  - Fix a bug in shuffle mode in ma_channel_converter.\n  - Fix compilation errors in certain configurations for ALSA and PulseAudio.\n  - The data callback now initializes the output buffer to 128 when the playback sample format is ma_format_u8.\n\nv0.10.5 - 2020-05-05\n  - Change ma_zero_pcm_frames() to take a 64-bit frame count.\n  - Add ma_copy_pcm_frames().\n  - Add MA_NO_GENERATION build option to exclude the `ma_waveform` and `ma_noise` APIs from the build.\n  - Add support for formatted logging to the VC6 build.\n  - Fix a crash in the linear resampler when LPF order is 0.\n  - Fix compilation errors and warnings with older versions of Visual Studio.\n  - Minor documentation updates.\n\nv0.10.4 - 2020-04-12\n  - Fix a data conversion bug when converting from the client format to the native device format.\n\nv0.10.3 - 2020-04-07\n  - Bring up to date with breaking changes to dr_mp3.\n  - Remove MA_NO_STDIO. This was causing compilation errors and the maintenance cost versus practical benefit is no longer worthwhile.\n  - Fix a bug with data conversion where it was unnecessarily converting to s16 or f32 and then straight back to the original format.\n  - Fix compilation errors and warnings with Visual Studio 2005.\n  - ALSA: Disable ALSA's automatic data conversion by default and add configuration options to the device config:\n    - alsa.noAutoFormat\n    - alsa.noAutoChannels\n    - alsa.noAutoResample\n  - WASAPI: Add some overrun recovery for ma_device_type_capture devices.\n\nv0.10.2 - 2020-03-22\n  - Decorate some APIs with MA_API which were missed in the previous version.\n  - Fix a bug in ma_linear_resampler_set_rate() and ma_linear_resampler_set_rate_ratio().\n\nv0.10.1 - 2020-03-17\n  - Add MA_API decoration. This can be customized by defining it before including miniaudio.h.\n  - Fix a bug where opening a file would return a success code when in fact it failed.\n  - Fix compilation errors with Visual Studio 6 and 2003.\n  - Fix warnings on macOS.\n\nv0.10.0 - 2020-03-07\n  - API CHANGE: Refactor data conversion APIs\n    - ma_format_converter has been removed. Use ma_convert_pcm_frames_format() instead.\n    - ma_channel_router has been replaced with ma_channel_converter.\n    - ma_src has been replaced with ma_resampler\n    - ma_pcm_converter has been replaced with ma_data_converter\n  - API CHANGE: Add support for custom memory allocation callbacks. The following APIs have been updated to take an extra parameter for the allocation\n    callbacks:\n    - ma_malloc()\n    - ma_realloc()\n    - ma_free()\n    - ma_aligned_malloc()\n    - ma_aligned_free()\n    - ma_rb_init() / ma_rb_init_ex()\n    - ma_pcm_rb_init() / ma_pcm_rb_init_ex()\n  - API CHANGE: Simplify latency specification in device configurations. The bufferSizeInFrames and bufferSizeInMilliseconds parameters have been replaced with\n    periodSizeInFrames and periodSizeInMilliseconds respectively. The previous variables defined the size of the entire buffer, whereas the new ones define the\n    size of a period. The following APIs have been removed since they are no longer relevant:\n    - ma_get_default_buffer_size_in_milliseconds()\n    - ma_get_default_buffer_size_in_frames()\n  - API CHANGE: ma_device_set_stop_callback() has been removed. If you require a stop callback, you must now set it via the device config just like the data\n    callback.\n  - API CHANGE: The ma_sine_wave API has been replaced with ma_waveform. The following APIs have been removed:\n    - ma_sine_wave_init()\n    - ma_sine_wave_read_f32()\n    - ma_sine_wave_read_f32_ex()\n  - API CHANGE: ma_convert_frames() has been updated to take an extra parameter which is the size of the output buffer in PCM frames. Parameters have also been\n    reordered.\n  - API CHANGE: ma_convert_frames_ex() has been changed to take a pointer to a ma_data_converter_config object to specify the input and output formats to\n    convert between.\n  - API CHANGE: ma_calculate_frame_count_after_src() has been renamed to ma_calculate_frame_count_after_resampling().\n  - Add support for the following filters:\n    - Biquad (ma_biquad)\n    - First order low-pass (ma_lpf1)\n    - Second order low-pass (ma_lpf2)\n    - Low-pass with configurable order (ma_lpf)\n    - First order high-pass (ma_hpf1)\n    - Second order high-pass (ma_hpf2)\n    - High-pass with configurable order (ma_hpf)\n    - Second order band-pass (ma_bpf2)\n    - Band-pass with configurable order (ma_bpf)\n    - Second order peaking EQ (ma_peak2)\n    - Second order notching (ma_notch2)\n    - Second order low shelf (ma_loshelf2)\n    - Second order high shelf (ma_hishelf2)\n  - Add waveform generation API (ma_waveform) with support for the following:\n    - Sine\n    - Square\n    - Triangle\n    - Sawtooth\n  - Add noise generation API (ma_noise) with support for the following:\n    - White\n    - Pink\n    - Brownian\n  - Add encoding API (ma_encoder). This only supports outputting to WAV files via dr_wav.\n  - Add ma_result_description() which is used to retrieve a human readable description of a given result code.\n  - Result codes have been changed. Binding maintainers will need to update their result code constants.\n  - More meaningful result codes are now returned when a file fails to open.\n  - Internal functions have all been made static where possible.\n  - Fix potential crash when ma_device object's are not aligned to MA_SIMD_ALIGNMENT.\n  - Fix a bug in ma_decoder_get_length_in_pcm_frames() where it was returning the length based on the internal sample rate rather than the output sample rate.\n  - Fix bugs in some backends where the device is not drained properly in ma_device_stop().\n  - Improvements to documentation.\n\nv0.9.10 - 2020-01-15\n  - Fix compilation errors due to #if/#endif mismatches.\n  - WASAPI: Fix a bug where automatic stream routing is being performed for devices that are initialized with an explicit device ID.\n  - iOS: Fix a crash on device uninitialization.\n\nv0.9.9 - 2020-01-09\n  - Fix compilation errors with MinGW.\n  - Fix compilation errors when compiling on Apple platforms.\n  - WASAPI: Add support for disabling hardware offloading.\n  - WASAPI: Add support for disabling automatic stream routing.\n  - Core Audio: Fix bugs in the case where the internal device uses deinterleaved buffers.\n  - Core Audio: Add support for controlling the session category (AVAudioSessionCategory) and options (AVAudioSessionCategoryOptions).\n  - JACK: Fix bug where incorrect ports are connected.\n\nv0.9.8 - 2019-10-07\n  - WASAPI: Fix a potential deadlock when starting a full-duplex device.\n  - WASAPI: Enable automatic resampling by default. Disable with config.wasapi.noAutoConvertSRC.\n  - Core Audio: Fix bugs with automatic stream routing.\n  - Add support for controlling whether or not the content of the output buffer passed in to the data callback is pre-initialized\n    to zero. By default it will be initialized to zero, but this can be changed by setting noPreZeroedOutputBuffer in the device\n    config. Setting noPreZeroedOutputBuffer to true will leave the contents undefined.\n  - Add support for clipping samples after the data callback has returned. This only applies when the playback sample format is\n    configured as ma_format_f32. If you are doing clipping yourself, you can disable this overhead by setting noClip to true in\n    the device config.\n  - Add support for master volume control for devices.\n    - Use ma_device_set_master_volume() to set the volume to a factor between 0 and 1, where 0 is silence and 1 is full volume.\n    - Use ma_device_set_master_volume_db() to set the volume in decibels where 0 is full volume and < 0 reduces the volume.\n  - Fix warnings emitted by GCC when `__inline__` is undefined or defined as nothing.\n\nv0.9.7 - 2019-08-28\n  - Add support for loopback mode (WASAPI only).\n    - To use this, set the device type to ma_device_type_loopback, and then fill out the capture section of the device config.\n    - If you need to capture from a specific output device, set the capture device ID to that of a playback device.\n  - Fix a crash when an error is posted in ma_device_init().\n  - Fix a compilation error when compiling for ARM architectures.\n  - Fix a bug with the audio(4) backend where the device is incorrectly being opened in non-blocking mode.\n  - Fix memory leaks in the Core Audio backend.\n  - Minor refactoring to the WinMM, ALSA, PulseAudio, OSS, audio(4), sndio and null backends.\n\nv0.9.6 - 2019-08-04\n  - Add support for loading decoders using a wchar_t string for file paths.\n  - Don't trigger an assert when ma_device_start() is called on a device that is already started. This will now log a warning\n    and return MA_INVALID_OPERATION. The same applies for ma_device_stop().\n  - Try fixing an issue with PulseAudio taking a long time to start playback.\n  - Fix a bug in ma_convert_frames() and ma_convert_frames_ex().\n  - Fix memory leaks in the WASAPI backend.\n  - Fix a compilation error with Visual Studio 2010.\n\nv0.9.5 - 2019-05-21\n  - Add logging to ma_dlopen() and ma_dlsym().\n  - Add ma_decoder_get_length_in_pcm_frames().\n  - Fix a bug with capture on the OpenSL|ES backend.\n  - Fix a bug with the ALSA backend where a device would not restart after being stopped.\n\nv0.9.4 - 2019-05-06\n  - Add support for C89. With this change, miniaudio should compile clean with GCC/Clang with \"-std=c89 -ansi -pedantic\" and\n    Microsoft compilers back to VC6. Other compilers should also work, but have not been tested.\n\nv0.9.3 - 2019-04-19\n  - Fix compiler errors on GCC when compiling with -std=c99.\n\nv0.9.2 - 2019-04-08\n  - Add support for per-context user data.\n  - Fix a potential bug with context configs.\n  - Fix some bugs with PulseAudio.\n\nv0.9.1 - 2019-03-17\n  - Fix a bug where the output buffer is not getting zeroed out before calling the data callback. This happens when\n    the device is running in passthrough mode (not doing any data conversion).\n  - Fix an issue where the data callback is getting called too frequently on the WASAPI and DirectSound backends.\n  - Fix error on the UWP build.\n  - Fix a build error on Apple platforms.\n\nv0.9 - 2019-03-06\n  - Rebranded to \"miniaudio\". All namespaces have been renamed from \"mal\" to \"ma\".\n  - API CHANGE: ma_device_init() and ma_device_config_init() have changed significantly:\n    - The device type, device ID and user data pointer have moved from ma_device_init() to the config.\n    - All variations of ma_device_config_init_*() have been removed in favor of just ma_device_config_init().\n    - ma_device_config_init() now takes only one parameter which is the device type. All other properties need\n      to be set on the returned object directly.\n    - The onDataCallback and onStopCallback members of ma_device_config have been renamed to \"dataCallback\"\n      and \"stopCallback\".\n    - The ID of the physical device is now split into two: one for the playback device and the other for the\n      capture device. This is required for full-duplex. These are named \"pPlaybackDeviceID\" and \"pCaptureDeviceID\".\n  - API CHANGE: The data callback has changed. It now uses a unified callback for all device types rather than\n    being separate for each. It now takes two pointers - one containing input data and the other output data. This\n    design in required for full-duplex. The return value is now void instead of the number of frames written. The\n    new callback looks like the following:\n        void data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount);\n  - API CHANGE: Remove the log callback parameter from ma_context_config_init(). With this change,\n    ma_context_config_init() now takes no parameters and the log callback is set via the structure directly. The\n    new policy for config initialization is that only mandatory settings are passed in to *_config_init(). The\n    \"onLog\" member of ma_context_config has been renamed to \"logCallback\".\n  - API CHANGE: Remove ma_device_get_buffer_size_in_bytes().\n  - API CHANGE: Rename decoding APIs to \"pcm_frames\" convention.\n    - mal_decoder_read()          -> ma_decoder_read_pcm_frames()\n    - mal_decoder_seek_to_frame() -> ma_decoder_seek_to_pcm_frame()\n  - API CHANGE: Rename sine wave reading APIs to f32 convention.\n    - mal_sine_wave_read()    -> ma_sine_wave_read_f32()\n    - mal_sine_wave_read_ex() -> ma_sine_wave_read_f32_ex()\n  - API CHANGE: Remove some deprecated APIs\n    - mal_device_set_recv_callback()\n    - mal_device_set_send_callback()\n    - mal_src_set_input_sample_rate()\n    - mal_src_set_output_sample_rate()\n  - API CHANGE: Add log level to the log callback. New signature:\n    - void on_log(ma_context* pContext, ma_device* pDevice, ma_uint32 logLevel, const char* message)\n  - API CHANGE: Changes to result codes. Constants have changed and unused codes have been removed. If you're\n    a binding mainainer you will need to update your result code constants.\n  - API CHANGE: Change the order of the ma_backend enums to priority order. If you are a binding maintainer, you\n    will need to update.\n  - API CHANGE: Rename mal_dsp to ma_pcm_converter. All functions have been renamed from mal_dsp_*() to\n    ma_pcm_converter_*(). All structures have been renamed from mal_dsp* to ma_pcm_converter*.\n  - API CHANGE: Reorder parameters of ma_decoder_read_pcm_frames() to be consistent with the new parameter order scheme.\n  - The resampling algorithm has been changed from sinc to linear. The rationale for this is that the sinc implementation\n    is too inefficient right now. This will hopefully be improved at a later date.\n  - Device initialization will no longer fall back to shared mode if exclusive mode is requested but is unusable.\n    With this change, if you request an device in exclusive mode, but exclusive mode is not supported, it will not\n    automatically fall back to shared mode. The client will need to reinitialize the device in shared mode if that's\n    what they want.\n  - Add ring buffer API. This is ma_rb and ma_pcm_rb, the difference being that ma_rb operates on bytes and\n    ma_pcm_rb operates on PCM frames.\n  - Add Web Audio backend. This is used when compiling with Emscripten. The SDL backend, which was previously\n    used for web support, will be removed in a future version.\n  - Add AAudio backend (Android Audio). This is the new priority backend for Android. Support for AAudio starts\n    with Android 8. OpenSL|ES is used as a fallback for older versions of Android.\n  - Remove OpenAL and SDL backends.\n  - Fix a possible deadlock when rapidly stopping the device after it has started.\n  - Update documentation.\n  - Change licensing to a choice of public domain _or_ MIT-0 (No Attribution).\n\nv0.8.14 - 2018-12-16\n  - Core Audio: Fix a bug where the device state is not set correctly after stopping.\n  - Add support for custom weights to the channel router.\n  - Update decoders to use updated APIs in dr_flac, dr_mp3 and dr_wav.\n\nv0.8.13 - 2018-12-04\n  - Core Audio: Fix a bug with channel mapping.\n  - Fix a bug with channel routing where the back/left and back/right channels have the wrong weight.\n\nv0.8.12 - 2018-11-27\n  - Drop support for SDL 1.2. The Emscripten build now requires \"-s USE_SDL=2\".\n  - Fix a linking error with ALSA.\n  - Fix a bug on iOS where the device name is not set correctly.\n\nv0.8.11 - 2018-11-21\n  - iOS bug fixes.\n  - Minor tweaks to PulseAudio.\n\nv0.8.10 - 2018-10-21\n  - Core Audio: Fix a hang when uninitializing a device.\n  - Fix a bug where an incorrect value is returned from mal_device_stop().\n\nv0.8.9 - 2018-09-28\n  - Fix a bug with the SDL backend where device initialization fails.\n\nv0.8.8 - 2018-09-14\n  - Fix Linux build with the ALSA backend.\n  - Minor documentation fix.\n\nv0.8.7 - 2018-09-12\n  - Fix a bug with UWP detection.\n\nv0.8.6 - 2018-08-26\n  - Automatically switch the internal device when the default device is unplugged. Note that this is still in the\n    early stages and not all backends handle this the same way. As of this version, this will not detect a default\n    device switch when changed from the operating system's audio preferences (unless the backend itself handles\n    this automatically). This is not supported in exclusive mode.\n  - WASAPI and Core Audio: Add support for stream routing. When the application is using a default device and the\n    user switches the default device via the operating system's audio preferences, miniaudio will automatically switch\n    the internal device to the new default. This is not supported in exclusive mode.\n  - WASAPI: Add support for hardware offloading via IAudioClient2. Only supported on Windows 8 and newer.\n  - WASAPI: Add support for low-latency shared mode via IAudioClient3. Only supported on Windows 10 and newer.\n  - Add support for compiling the UWP build as C.\n  - mal_device_set_recv_callback() and mal_device_set_send_callback() have been deprecated. You must now set this\n    when the device is initialized with mal_device_init*(). These will be removed in version 0.9.0.\n\nv0.8.5 - 2018-08-12\n  - Add support for specifying the size of a device's buffer in milliseconds. You can still set the buffer size in\n    frames if that suits you. When bufferSizeInFrames is 0, bufferSizeInMilliseconds will be used. If both are non-0\n    then bufferSizeInFrames will take priority. If both are set to 0 the default buffer size is used.\n  - Add support for the audio(4) backend to OpenBSD.\n  - Fix a bug with the ALSA backend that was causing problems on Raspberry Pi. This significantly improves the\n    Raspberry Pi experience.\n  - Fix a bug where an incorrect number of samples is returned from sinc resampling.\n  - Add support for setting the value to be passed to internal calls to CoInitializeEx().\n  - WASAPI and WinMM: Stop the device when it is unplugged.\n\nv0.8.4 - 2018-08-06\n  - Add sndio backend for OpenBSD.\n  - Add audio(4) backend for NetBSD.\n  - Drop support for the OSS backend on everything except FreeBSD and DragonFly BSD.\n  - Formats are now native-endian (were previously little-endian).\n  - Mark some APIs as deprecated:\n    - mal_src_set_input_sample_rate() and mal_src_set_output_sample_rate() are replaced with mal_src_set_sample_rate().\n    - mal_dsp_set_input_sample_rate() and mal_dsp_set_output_sample_rate() are replaced with mal_dsp_set_sample_rate().\n  - Fix a bug when capturing using the WASAPI backend.\n  - Fix some aliasing issues with resampling, specifically when increasing the sample rate.\n  - Fix warnings.\n\nv0.8.3 - 2018-07-15\n  - Fix a crackling bug when resampling in capture mode.\n  - Core Audio: Fix a bug where capture does not work.\n  - ALSA: Fix a bug where the worker thread can get stuck in an infinite loop.\n  - PulseAudio: Fix a bug where mal_context_init() succeeds when PulseAudio is unusable.\n  - JACK: Fix a bug where mal_context_init() succeeds when JACK is unusable.\n\nv0.8.2 - 2018-07-07\n  - Fix a bug on macOS with Core Audio where the internal callback is not called.\n\nv0.8.1 - 2018-07-06\n  - Fix compilation errors and warnings.\n\nv0.8 - 2018-07-05\n  - Changed MAL_IMPLEMENTATION to MINI_AL_IMPLEMENTATION for consistency with other libraries. The old\n    way is still supported for now, but you should update as it may be removed in the future.\n  - API CHANGE: Replace device enumeration APIs. mal_enumerate_devices() has been replaced with\n    mal_context_get_devices(). An additional low-level device enumration API has been introduced called\n    mal_context_enumerate_devices() which uses a callback to report devices.\n  - API CHANGE: Rename mal_get_sample_size_in_bytes() to mal_get_bytes_per_sample() and add\n    mal_get_bytes_per_frame().\n  - API CHANGE: Replace mal_device_config.preferExclusiveMode with mal_device_config.shareMode.\n    - This new config can be set to mal_share_mode_shared (default) or mal_share_mode_exclusive.\n  - API CHANGE: Remove excludeNullDevice from mal_context_config.alsa.\n  - API CHANGE: Rename MAL_MAX_SAMPLE_SIZE_IN_BYTES to MAL_MAX_PCM_SAMPLE_SIZE_IN_BYTES.\n  - API CHANGE: Change the default channel mapping to the standard Microsoft mapping.\n  - API CHANGE: Remove backend-specific result codes.\n  - API CHANGE: Changes to the format conversion APIs (mal_pcm_f32_to_s16(), etc.)\n  - Add support for Core Audio (Apple).\n  - Add support for PulseAudio.\n    - This is the highest priority backend on Linux (higher priority than ALSA) since it is commonly\n      installed by default on many of the popular distros and offer's more seamless integration on\n      platforms where PulseAudio is used. In addition, if PulseAudio is installed and running (which\n      is extremely common), it's better to just use PulseAudio directly rather than going through the\n      \"pulse\" ALSA plugin (which is what the \"default\" ALSA device is likely set to).\n  - Add support for JACK.\n  - Remove dependency on asound.h for the ALSA backend. This means the ALSA development packages are no\n    longer required to build miniaudio.\n  - Remove dependency on dsound.h for the DirectSound backend. This fixes build issues with some\n    distributions of MinGW.\n  - Remove dependency on audioclient.h for the WASAPI backend. This fixes build issues with some\n    distributions of MinGW.\n  - Add support for dithering to format conversion.\n  - Add support for configuring the priority of the worker thread.\n  - Add a sine wave generator.\n  - Improve efficiency of sample rate conversion.\n  - Introduce the notion of standard channel maps. Use mal_get_standard_channel_map().\n  - Introduce the notion of default device configurations. A default config uses the same configuration\n    as the backend's internal device, and as such results in a pass-through data transmission pipeline.\n  - Add support for passing in NULL for the device config in mal_device_init(), which uses a default\n    config. This requires manually calling mal_device_set_send/recv_callback().\n  - Add support for decoding from raw PCM data (mal_decoder_init_raw(), etc.)\n  - Make mal_device_init_ex() more robust.\n  - Make some APIs more const-correct.\n  - Fix errors with SDL detection on Apple platforms.\n  - Fix errors with OpenAL detection.\n  - Fix some memory leaks.\n  - Fix a bug with opening decoders from memory.\n  - Early work on SSE2, AVX2 and NEON optimizations.\n  - Miscellaneous bug fixes.\n  - Documentation updates.\n\nv0.7 - 2018-02-25\n  - API CHANGE: Change mal_src_read_frames() and mal_dsp_read_frames() to use 64-bit sample counts.\n  - Add decoder APIs for loading WAV, FLAC, Vorbis and MP3 files.\n  - Allow opening of devices without a context.\n    - In this case the context is created and managed internally by the device.\n  - Change the default channel mapping to the same as that used by FLAC.\n  - Fix build errors with macOS.\n\nv0.6c - 2018-02-12\n  - Fix build errors with BSD/OSS.\n\nv0.6b - 2018-02-03\n  - Fix some warnings when compiling with Visual C++.\n\nv0.6a - 2018-01-26\n  - Fix errors with channel mixing when increasing the channel count.\n  - Improvements to the build system for the OpenAL backend.\n  - Documentation fixes.\n\nv0.6 - 2017-12-08\n  - API CHANGE: Expose and improve mutex APIs. If you were using the mutex APIs before this version you'll\n    need to update.\n  - API CHANGE: SRC and DSP callbacks now take a pointer to a mal_src and mal_dsp object respectively.\n  - API CHANGE: Improvements to event and thread APIs. These changes make these APIs more consistent.\n  - Add support for SDL and Emscripten.\n  - Simplify the build system further for when development packages for various backends are not installed.\n    With this change, when the compiler supports __has_include, backends without the relevant development\n    packages installed will be ignored. This fixes the build for old versions of MinGW.\n  - Fixes to the Android build.\n  - Add mal_convert_frames(). This is a high-level helper API for performing a one-time, bulk conversion of\n    audio data to a different format.\n  - Improvements to f32 -> u8/s16/s24/s32 conversion routines.\n  - Fix a bug where the wrong value is returned from mal_device_start() for the OpenSL backend.\n  - Fixes and improvements for Raspberry Pi.\n  - Warning fixes.\n\nv0.5 - 2017-11-11\n  - API CHANGE: The mal_context_init() function now takes a pointer to a mal_context_config object for\n    configuring the context. The works in the same kind of way as the device config. The rationale for this\n    change is to give applications better control over context-level properties, add support for backend-\n    specific configurations, and support extensibility without breaking the API.\n  - API CHANGE: The alsa.preferPlugHW device config variable has been removed since it's not really useful for\n    anything anymore.\n  - ALSA: By default, device enumeration will now only enumerate over unique card/device pairs. Applications\n    can enable verbose device enumeration by setting the alsa.useVerboseDeviceEnumeration context config\n    variable.\n  - ALSA: When opening a device in shared mode (the default), the dmix/dsnoop plugin will be prioritized. If\n    this fails it will fall back to the hw plugin. With this change the preferExclusiveMode config is now\n    honored. Note that this does not happen when alsa.useVerboseDeviceEnumeration is set to true (see above)\n    which is by design.\n  - ALSA: Add support for excluding the \"null\" device using the alsa.excludeNullDevice context config variable.\n  - ALSA: Fix a bug with channel mapping which causes an assertion to fail.\n  - Fix errors with enumeration when pInfo is set to NULL.\n  - OSS: Fix a bug when starting a device when the client sends 0 samples for the initial buffer fill.\n\nv0.4 - 2017-11-05\n  - API CHANGE: The log callback is now per-context rather than per-device and as is thus now passed to\n    mal_context_init(). The rationale for this change is that it allows applications to capture diagnostic\n    messages at the context level. Previously this was only available at the device level.\n  - API CHANGE: The device config passed to mal_device_init() is now const.\n  - Added support for OSS which enables support on BSD platforms.\n  - Added support for WinMM (waveOut/waveIn).\n  - Added support for UWP (Universal Windows Platform) applications. Currently C++ only.\n  - Added support for exclusive mode for selected backends. Currently supported on WASAPI.\n  - POSIX builds no longer require explicit linking to libpthread (-lpthread).\n  - ALSA: Explicit linking to libasound (-lasound) is no longer required.\n  - ALSA: Latency improvements.\n  - ALSA: Use MMAP mode where available. This can be disabled with the alsa.noMMap config.\n  - ALSA: Use \"hw\" devices instead of \"plughw\" devices by default. This can be disabled with the\n    alsa.preferPlugHW config.\n  - WASAPI is now the highest priority backend on Windows platforms.\n  - Fixed an error with sample rate conversion which was causing crackling when capturing.\n  - Improved error handling.\n  - Improved compiler support.\n  - Miscellaneous bug fixes.\n\nv0.3 - 2017-06-19\n  - API CHANGE: Introduced the notion of a context. The context is the highest level object and is required for\n    enumerating and creating devices. Now, applications must first create a context, and then use that to\n    enumerate and create devices. The reason for this change is to ensure device enumeration and creation is\n    tied to the same backend. In addition, some backends are better suited to this design.\n  - API CHANGE: Removed the rewinding APIs because they're too inconsistent across the different backends, hard\n    to test and maintain, and just generally unreliable.\n  - Added helper APIs for initializing mal_device_config objects.\n  - Null Backend: Fixed a crash when recording.\n  - Fixed build for UWP.\n  - Added support for f32 formats to the OpenSL|ES backend.\n  - Added initial implementation of the WASAPI backend.\n  - Added initial implementation of the OpenAL backend.\n  - Added support for low quality linear sample rate conversion.\n  - Added early support for basic channel mapping.\n\nv0.2 - 2016-10-28\n  - API CHANGE: Add user data pointer as the last parameter to mal_device_init(). The rationale for this\n    change is to ensure the logging callback has access to the user data during initialization.\n  - API CHANGE: Have device configuration properties be passed to mal_device_init() via a structure. Rationale:\n    1) The number of parameters is just getting too much.\n    2) It makes it a bit easier to add new configuration properties in the future. In particular, there's a\n       chance there will be support added for backend-specific properties.\n  - Dropped support for f64, A-law and Mu-law formats since they just aren't common enough to justify the\n    added maintenance cost.\n  - DirectSound: Increased the default buffer size for capture devices.\n  - Added initial implementation of the OpenSL|ES backend.\n\nv0.1 - 2016-10-21\n  - Initial versioned release."
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.1865234375,
          "content": "Contributing to miniaudio\n=========================\nFirst of all, thanks for stopping by! This document will explain a few things to consider when contributing to\nminiaudio.\n\n\nFound a Bug?\n------------\nIf you've found a bug you can create a bug report [here on GitHub](https://github.com/mackron/miniaudio/issues).\nThe more information you can provide, the quicker I'll be able to get it fixed. Sample programs and files help a\nlot, as does a detailed list of steps I can follow to reproduce the problem.\n\nYou can also submit a pull request which, provided your fix is correct and well written, is the quickest way to\nget the bug fixed. See the next section for guidance on pull requests.\n\n\nPull Requests\n-------------\nIf you want to do actual development on miniaudio, pull requests are the best place to start. Just don't do any\nsignificant work without talking to me first. If I don't like it, it won't be merged. You can find me via email,\n[Discord](https://discord.gg/9vpqbjU) and [Twitter](https://twitter.com/mackron).\n\nAlways base your pull request branch on the \"dev\" branch. The master branch contains the latest release, which\nmeans your pull request may not be including the lastest in-development changes which may result in unnecessary\nconflicts.\n\nI need to review your pull requests before merging. If your pull request is non-trivial, try to break it up into\nlogical bite sized commits to make it easier for review, but make sure every commit compiles. Obviously this is\nnot always easy to do in practice, but just keep it in mind.\n\nWhen it comes to coding style I'm fairly relaxed, but be professional and respect the existing coding style,\nregardless of whether or not you like it. It's no big deal if something slips, but try to keep it in mind. Some\nthings in particular:\n  * C89. `/*...*/` style comments and variables declared at the top of the code block are the main thing.\n  * Spaces instead of tabs. 4 spaces per tab.\n  * Don't add a third party dependency. If you do this I'll immediately reject your pull request.\n\nI'm not going to outline specific coding styles - just look at the existing code and use common sense.\n\nIf you want to submit a pull request for any of the dr_* libraries in the \"extras\" folder, please submit the pull\nrequest to the [dr_libs repository](https://github.com/mackron/dr_libs).\n\n\nRespect the Goals of the Project\n--------------------------------\nWhen making a contribution, please respect the primary goals of the project. These are the points of difference\nthat make miniaudio unique and it's important they're maintained and respected.\n\n  * miniaudio is *single file*. Do not split your work into multiple files thinking I'll be impressed with your\n    modular design - I won't, and your contribution will be immediately rejected.\n  * miniaudio has *no external dependencies*. You might think your helping by adding some cool new feature via\n    some external library. You're not helping, and your contribution will be immediately rejected.\n  * miniaudio is *public domain*. Don't add any code that's taken directly from licensed code.\n  \n\n\nLicensing and Credits\n---------------------\nminiaudio is dual licensed as a choice of public domain or MIT-0 (No Attribution), so you need to agree to release\nyour contributions as such. I also do not maintain a credit/contributions list. If you don't like this you should\nnot contribute to this project.\n\n\nPredictable Questions\n---------------------\n### \"Would you consider splitting out [some section of code] into it's own file?\"\nNo, the idea is to keep everything in one place. It would be nice in specific cases to split out specific sections\nof the code, such as the resampler, for example. However, this will completely violate one of the major goals of the\nproject - to have a complete audio library contained within a single file.\n\n### \"Would you consider adding support for CMake [or my favourite build system]?\"\nNo, the whole point of having the code contained entirely within a single file and not have any external dependencies\nis to make it easy to add to your source tree without needing any extra build system integration. There is no need to\nincur the cost of maintaining build systems in miniaudio.\n\n### \"Would you consider feature XYZ? It requires C11, but don't worry, all compilers support it.\"\nOne of the philosophies of miniaudio is that it should just work, and that includes compilation environment. There's\nno real reason to not support older compilers. Newer versions of C will not add anything of any significance\nthat cannot already be done in C89.\n\n### \"Will you consider adding a third license option such as [my favourite license]?\"\nNo, the idea is to keep licensing simple. That's why miniaudio is public domain - to avoid as much license friction\nas possible. However, some regions do not recognize public domain, so therefore an alternative license, MIT No\nAttribution, is included as an added option. There is no need to make the licensing situation any more confusing.\n\n### \"Is there a list of contributors? Will my name be added to any kind of list?\"\nNo, there's no credit list as it just adds extra maintenance work and it's too easy to accidentally and unfairly\nforget to add a contributor. A list of contributors can be retrieved from the Git log and also GitHub itself.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.5361328125,
          "content": "This software is available as a choice of the following licenses. Choose\nwhichever you prefer.\n\n===============================================================================\nALTERNATIVE 1 - Public Domain (www.unlicense.org)\n===============================================================================\nThis is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or distribute this\nsoftware, either in source code form or as a compiled binary, for any purpose,\ncommercial or non-commercial, and by any means.\n\nIn jurisdictions that recognize copyright laws, the author or authors of this\nsoftware dedicate any and all copyright interest in the software to the public\ndomain. We make this dedication for the benefit of the public at large and to\nthe detriment of our heirs and successors. We intend this dedication to be an\novert act of relinquishment in perpetuity of all present and future rights to\nthis software under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\nACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to <http://unlicense.org/>\n\n===============================================================================\nALTERNATIVE 2 - MIT No Attribution\n===============================================================================\nCopyright 2023 David Reid\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.8681640625,
          "content": "<h1 align=\"center\">\n    <a href=\"https://miniaud.io\"><img src=\"https://miniaud.io/img/miniaudio_wide.png\" alt=\"miniaudio\" width=\"1280\"></a>\n    <br>\n</h1>\n\n<h4 align=\"center\">An audio playback and capture library in a single source file.</h4>\n\n<p align=\"center\">\n    <a href=\"https://discord.gg/9vpqbjU\"><img src=\"https://img.shields.io/discord/712952679415939085?label=discord&logo=discord&style=flat-square\" alt=\"discord\"></a>\n    <a href=\"https://fosstodon.org/@mackron\"><img src=\"https://img.shields.io/mastodon/follow/109293691403797709?color=blue&domain=https%3A%2F%2Ffosstodon.org&label=mastodon&logo=mastodon&style=flat-square\" alt=\"mastodon\"></a>\n    <a href=\"https://www.reddit.com/r/miniaudio\"><img src=\"https://img.shields.io/reddit/subreddit-subscribers/miniaudio?label=r%2Fminiaudio&logo=reddit&style=flat-square\" alt=\"reddit\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"#features\">Features</a> -\n    <a href=\"#examples\">Examples</a> -\n    <a href=\"#building\">Building</a> -\n    <a href=\"#documentation\">Documentation</a> -\n    <a href=\"#supported-platforms\">Supported Platforms</a> -\n    <a href=\"#license\">License</a>\n</p>\n\nminiaudio is written in C with no dependencies except the standard library and should compile clean on all major\ncompilers without the need to install any additional development packages. All major desktop and mobile platforms\nare supported.\n\n\nFeatures\n========\n- Simple build system with no external dependencies.\n- Simple and flexible API.\n- Low-level API for direct access to raw audio data.\n- High-level API for sound management, mixing, effects and optional 3D spatialization.\n- Flexible node graph system for advanced mixing and effect processing.\n- Resource management for loading sound files.\n- Decoding, with built-in support for WAV, FLAC and MP3, in addition to being able to plug in custom decoders.\n- Encoding (WAV only).\n- Data conversion.\n- Resampling, including custom resamplers.\n- Channel mapping.\n- Basic generation of waveforms and noise.\n- Basic effects and filters.\n\nRefer to the [Programming Manual](https://miniaud.io/docs/manual/) for a more complete description of\navailable features in miniaudio.\n\n\nExamples\n========\n\nThis example shows one way to play a sound using the high level API.\n\n```c\n#define MINIAUDIO_IMPLEMENTATION\n#include \"miniaudio.h\"\n\n#include <stdio.h>\n\nint main()\n{\n    ma_result result;\n    ma_engine engine;\n\n    result = ma_engine_init(NULL, &engine);\n    if (result != MA_SUCCESS) {\n        return -1;\n    }\n\n    ma_engine_play_sound(&engine, \"sound.wav\", NULL);\n\n    printf(\"Press Enter to quit...\");\n    getchar();\n\n    ma_engine_uninit(&engine);\n\n    return 0;\n}\n```\n\nThis example shows how to decode and play a sound using the low level API.\n\n```c\n#define MINIAUDIO_IMPLEMENTATION\n#include \"miniaudio.h\"\n\n#include <stdio.h>\n\nvoid data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount)\n{\n    ma_decoder* pDecoder = (ma_decoder*)pDevice->pUserData;\n    if (pDecoder == NULL) {\n        return;\n    }\n\n    ma_decoder_read_pcm_frames(pDecoder, pOutput, frameCount, NULL);\n\n    (void)pInput;\n}\n\nint main(int argc, char** argv)\n{\n    ma_result result;\n    ma_decoder decoder;\n    ma_device_config deviceConfig;\n    ma_device device;\n\n    if (argc < 2) {\n        printf(\"No input file.\\n\");\n        return -1;\n    }\n\n    result = ma_decoder_init_file(argv[1], NULL, &decoder);\n    if (result != MA_SUCCESS) {\n        return -2;\n    }\n\n    deviceConfig = ma_device_config_init(ma_device_type_playback);\n    deviceConfig.playback.format   = decoder.outputFormat;\n    deviceConfig.playback.channels = decoder.outputChannels;\n    deviceConfig.sampleRate        = decoder.outputSampleRate;\n    deviceConfig.dataCallback      = data_callback;\n    deviceConfig.pUserData         = &decoder;\n\n    if (ma_device_init(NULL, &deviceConfig, &device) != MA_SUCCESS) {\n        printf(\"Failed to open playback device.\\n\");\n        ma_decoder_uninit(&decoder);\n        return -3;\n    }\n\n    if (ma_device_start(&device) != MA_SUCCESS) {\n        printf(\"Failed to start playback device.\\n\");\n        ma_device_uninit(&device);\n        ma_decoder_uninit(&decoder);\n        return -4;\n    }\n\n    printf(\"Press Enter to quit...\");\n    getchar();\n\n    ma_device_uninit(&device);\n    ma_decoder_uninit(&decoder);\n\n    return 0;\n}\n```\n\nMore examples can be found in the [examples](examples) folder or online here: https://miniaud.io/docs/examples/\n\n\nBuilding\n========\nDo the following in one source file:\n```c\n#define MINIAUDIO_IMPLEMENTATION\n#include \"miniaudio.h\"\n```\nThen just compile. There's no need to install any dependencies. On Windows and macOS there's no need to link\nto anything. On Linux just link to `-lpthread`, `-lm` and `-ldl`. On BSD just link to `-lpthread` and `-lm`.\nOn iOS you need to compile as Objective-C.\n\nIf you get errors about undefined references to `__sync_val_compare_and_swap_8`, `__atomic_load_8`, etc. you\nneed to link with `-latomic`.\n\nIf you prefer separate .h and .c files, you can find a split version of miniaudio in the extras/miniaudio_split\nfolder. From here you can use miniaudio as a traditional .c and .h library - just add miniaudio.c to your source\ntree like any other source file and include miniaudio.h like a normal header. If you prefer compiling as a\nsingle translation unit (AKA unity builds), you can just #include the .c file in your main source file:\n```c\n#include \"miniaudio.c\"\n```\nNote that the split version is auto-generated using a tool and is based on the main file in the root directory.\nIf you want to contribute, please make the change in the main file.\n\nABI compatibility is not guaranteed between versions so take care if compiling as a DLL/SO. The suggested way\nto integrate miniaudio is by adding it directly to your source tree.\n\n\nDocumentation\n=============\nOnline documentation can be found here: https://miniaud.io/docs/\n\nDocumentation can also be found at the top of [miniaudio.h](https://raw.githubusercontent.com/mackron/miniaudio/master/miniaudio.h)\nwhich is always the most up-to-date and authoritive source of information on how to use miniaudio. All other\ndocumentation is generated from this in-code documentation.\n\n\nSupported Platforms\n===================\n- Windows\n- macOS, iOS\n- Linux\n- FreeBSD / OpenBSD / NetBSD\n- Android\n- Raspberry Pi\n- Emscripten / HTML5\n\nminiaudio should compile clean on other platforms, but it will not include any support for playback or capture\nby default. To support that, you would need to implement a custom backend. You can do this without needing to\nmodify the miniaudio source code. See the [custom_backend](examples/custom_backend.c) example.\n\nBackends\n--------\n- WASAPI\n- DirectSound\n- WinMM\n- Core Audio (Apple)\n- ALSA\n- PulseAudio\n- JACK\n- sndio (OpenBSD)\n- audio(4) (NetBSD and OpenBSD)\n- OSS (FreeBSD)\n- AAudio (Android 8.0+)\n- OpenSL|ES (Android only)\n- Web Audio (Emscripten)\n- Null (Silence)\n- Custom\n\n\nLicense\n=======\nYour choice of either public domain or [MIT No Attribution](https://github.com/aws/mit-0).\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "extras",
          "type": "tree",
          "content": null
        },
        {
          "name": "miniaudio.h",
          "type": "blob",
          "size": 3891.619140625,
          "content": "/*\nAudio playback and capture library. Choice of public domain or MIT-0. See license statements at the end of this file.\nminiaudio - v0.11.21 - 2023-11-15\n\nDavid Reid - mackron@gmail.com\n\nWebsite:       https://miniaud.io\nDocumentation: https://miniaud.io/docs\nGitHub:        https://github.com/mackron/miniaudio\n*/\n\n/*\n1. Introduction\n===============\nminiaudio is a single file library for audio playback and capture. To use it, do the following in\none .c file:\n\n    ```c\n    #define MINIAUDIO_IMPLEMENTATION\n    #include \"miniaudio.h\"\n    ```\n\nYou can do `#include \"miniaudio.h\"` in other parts of the program just like any other header.\n\nminiaudio includes both low level and high level APIs. The low level API is good for those who want\nto do all of their mixing themselves and only require a light weight interface to the underlying\naudio device. The high level API is good for those who have complex mixing and effect requirements.\n\nIn miniaudio, objects are transparent structures. Unlike many other libraries, there are no handles\nto opaque objects which means you need to allocate memory for objects yourself. In the examples\npresented in this documentation you will often see objects declared on the stack. You need to be\ncareful when translating these examples to your own code so that you don't accidentally declare\nyour objects on the stack and then cause them to become invalid once the function returns. In\naddition, you must ensure the memory address of your objects remain the same throughout their\nlifetime. You therefore cannot be making copies of your objects.\n\nA config/init pattern is used throughout the entire library. The idea is that you set up a config\nobject and pass that into the initialization routine. The advantage to this system is that the\nconfig object can be initialized with logical defaults and new properties added to it without\nbreaking the API. The config object can be allocated on the stack and does not need to be\nmaintained after initialization of the corresponding object.\n\n\n1.1. Low Level API\n------------------\nThe low level API gives you access to the raw audio data of an audio device. It supports playback,\ncapture, full-duplex and loopback (WASAPI only). You can enumerate over devices to determine which\nphysical device(s) you want to connect to.\n\nThe low level API uses the concept of a \"device\" as the abstraction for physical devices. The idea\nis that you choose a physical device to emit or capture audio from, and then move data to/from the\ndevice when miniaudio tells you to. Data is delivered to and from devices asynchronously via a\ncallback which you specify when initializing the device.\n\nWhen initializing the device you first need to configure it. The device configuration allows you to\nspecify things like the format of the data delivered via the callback, the size of the internal\nbuffer and the ID of the device you want to emit or capture audio from.\n\nOnce you have the device configuration set up you can initialize the device. When initializing a\ndevice you need to allocate memory for the device object beforehand. This gives the application\ncomplete control over how the memory is allocated. In the example below we initialize a playback\ndevice on the stack, but you could allocate it on the heap if that suits your situation better.\n\n    ```c\n    void data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount)\n    {\n        // In playback mode copy data to pOutput. In capture mode read data from pInput. In full-duplex mode, both\n        // pOutput and pInput will be valid and you can move data from pInput into pOutput. Never process more than\n        // frameCount frames.\n    }\n\n    int main()\n    {\n        ma_device_config config = ma_device_config_init(ma_device_type_playback);\n        config.playback.format   = ma_format_f32;   // Set to ma_format_unknown to use the device's native format.\n        config.playback.channels = 2;               // Set to 0 to use the device's native channel count.\n        config.sampleRate        = 48000;           // Set to 0 to use the device's native sample rate.\n        config.dataCallback      = data_callback;   // This function will be called when miniaudio needs more data.\n        config.pUserData         = pMyCustomData;   // Can be accessed from the device object (device.pUserData).\n\n        ma_device device;\n        if (ma_device_init(NULL, &config, &device) != MA_SUCCESS) {\n            return -1;  // Failed to initialize the device.\n        }\n\n        ma_device_start(&device);     // The device is sleeping by default so you'll need to start it manually.\n\n        // Do something here. Probably your program's main loop.\n\n        ma_device_uninit(&device);\n        return 0;\n    }\n    ```\n\nIn the example above, `data_callback()` is where audio data is written and read from the device.\nThe idea is in playback mode you cause sound to be emitted from the speakers by writing audio data\nto the output buffer (`pOutput` in the example). In capture mode you read data from the input\nbuffer (`pInput`) to extract sound captured by the microphone. The `frameCount` parameter tells you\nhow many frames can be written to the output buffer and read from the input buffer. A \"frame\" is\none sample for each channel. For example, in a stereo stream (2 channels), one frame is 2\nsamples: one for the left, one for the right. The channel count is defined by the device config.\nThe size in bytes of an individual sample is defined by the sample format which is also specified\nin the device config. Multi-channel audio data is always interleaved, which means the samples for\neach frame are stored next to each other in memory. For example, in a stereo stream the first pair\nof samples will be the left and right samples for the first frame, the second pair of samples will\nbe the left and right samples for the second frame, etc.\n\nThe configuration of the device is defined by the `ma_device_config` structure. The config object\nis always initialized with `ma_device_config_init()`. It's important to always initialize the\nconfig with this function as it initializes it with logical defaults and ensures your program\ndoesn't break when new members are added to the `ma_device_config` structure. The example above\nuses a fairly simple and standard device configuration. The call to `ma_device_config_init()` takes\na single parameter, which is whether or not the device is a playback, capture, duplex or loopback\ndevice (loopback devices are not supported on all backends). The `config.playback.format` member\nsets the sample format which can be one of the following (all formats are native-endian):\n\n    +---------------+----------------------------------------+---------------------------+\n    | Symbol        | Description                            | Range                     |\n    +---------------+----------------------------------------+---------------------------+\n    | ma_format_f32 | 32-bit floating point                  | [-1, 1]                   |\n    | ma_format_s16 | 16-bit signed integer                  | [-32768, 32767]           |\n    | ma_format_s24 | 24-bit signed integer (tightly packed) | [-8388608, 8388607]       |\n    | ma_format_s32 | 32-bit signed integer                  | [-2147483648, 2147483647] |\n    | ma_format_u8  | 8-bit unsigned integer                 | [0, 255]                  |\n    +---------------+----------------------------------------+---------------------------+\n\nThe `config.playback.channels` member sets the number of channels to use with the device. The\nchannel count cannot exceed MA_MAX_CHANNELS. The `config.sampleRate` member sets the sample rate\n(which must be the same for both playback and capture in full-duplex configurations). This is\nusually set to 44100 or 48000, but can be set to anything. It's recommended to keep this between\n8000 and 384000, however.\n\nNote that leaving the format, channel count and/or sample rate at their default values will result\nin the internal device's native configuration being used which is useful if you want to avoid the\noverhead of miniaudio's automatic data conversion.\n\nIn addition to the sample format, channel count and sample rate, the data callback and user data\npointer are also set via the config. The user data pointer is not passed into the callback as a\nparameter, but is instead set to the `pUserData` member of `ma_device` which you can access\ndirectly since all miniaudio structures are transparent.\n\nInitializing the device is done with `ma_device_init()`. This will return a result code telling you\nwhat went wrong, if anything. On success it will return `MA_SUCCESS`. After initialization is\ncomplete the device will be in a stopped state. To start it, use `ma_device_start()`.\nUninitializing the device will stop it, which is what the example above does, but you can also stop\nthe device with `ma_device_stop()`. To resume the device simply call `ma_device_start()` again.\nNote that it's important to never stop or start the device from inside the callback. This will\nresult in a deadlock. Instead you set a variable or signal an event indicating that the device\nneeds to stop and handle it in a different thread. The following APIs must never be called inside\nthe callback:\n\n    ```c\n    ma_device_init()\n    ma_device_init_ex()\n    ma_device_uninit()\n    ma_device_start()\n    ma_device_stop()\n    ```\n\nYou must never try uninitializing and reinitializing a device inside the callback. You must also\nnever try to stop and start it from inside the callback. There are a few other things you shouldn't\ndo in the callback depending on your requirements, however this isn't so much a thread-safety\nthing, but rather a real-time processing thing which is beyond the scope of this introduction.\n\nThe example above demonstrates the initialization of a playback device, but it works exactly the\nsame for capture. All you need to do is change the device type from `ma_device_type_playback` to\n`ma_device_type_capture` when setting up the config, like so:\n\n    ```c\n    ma_device_config config = ma_device_config_init(ma_device_type_capture);\n    config.capture.format   = MY_FORMAT;\n    config.capture.channels = MY_CHANNEL_COUNT;\n    ```\n\nIn the data callback you just read from the input buffer (`pInput` in the example above) and leave\nthe output buffer alone (it will be set to NULL when the device type is set to\n`ma_device_type_capture`).\n\nThese are the available device types and how you should handle the buffers in the callback:\n\n    +-------------------------+--------------------------------------------------------+\n    | Device Type             | Callback Behavior                                      |\n    +-------------------------+--------------------------------------------------------+\n    | ma_device_type_playback | Write to output buffer, leave input buffer untouched.  |\n    | ma_device_type_capture  | Read from input buffer, leave output buffer untouched. |\n    | ma_device_type_duplex   | Read from input buffer, write to output buffer.        |\n    | ma_device_type_loopback | Read from input buffer, leave output buffer untouched. |\n    +-------------------------+--------------------------------------------------------+\n\nYou will notice in the example above that the sample format and channel count is specified\nseparately for playback and capture. This is to support different data formats between the playback\nand capture devices in a full-duplex system. An example may be that you want to capture audio data\nas a monaural stream (one channel), but output sound to a stereo speaker system. Note that if you\nuse different formats between playback and capture in a full-duplex configuration you will need to\nconvert the data yourself. There are functions available to help you do this which will be\nexplained later.\n\nThe example above did not specify a physical device to connect to which means it will use the\noperating system's default device. If you have multiple physical devices connected and you want to\nuse a specific one you will need to specify the device ID in the configuration, like so:\n\n    ```c\n    config.playback.pDeviceID = pMyPlaybackDeviceID;    // Only if requesting a playback or duplex device.\n    config.capture.pDeviceID = pMyCaptureDeviceID;      // Only if requesting a capture, duplex or loopback device.\n    ```\n\nTo retrieve the device ID you will need to perform device enumeration, however this requires the\nuse of a new concept called the \"context\". Conceptually speaking the context sits above the device.\nThere is one context to many devices. The purpose of the context is to represent the backend at a\nmore global level and to perform operations outside the scope of an individual device. Mainly it is\nused for performing run-time linking against backend libraries, initializing backends and\nenumerating devices. The example below shows how to enumerate devices.\n\n    ```c\n    ma_context context;\n    if (ma_context_init(NULL, 0, NULL, &context) != MA_SUCCESS) {\n        // Error.\n    }\n\n    ma_device_info* pPlaybackInfos;\n    ma_uint32 playbackCount;\n    ma_device_info* pCaptureInfos;\n    ma_uint32 captureCount;\n    if (ma_context_get_devices(&context, &pPlaybackInfos, &playbackCount, &pCaptureInfos, &captureCount) != MA_SUCCESS) {\n        // Error.\n    }\n\n    // Loop over each device info and do something with it. Here we just print the name with their index. You may want\n    // to give the user the opportunity to choose which device they'd prefer.\n    for (ma_uint32 iDevice = 0; iDevice < playbackCount; iDevice += 1) {\n        printf(\"%d - %s\\n\", iDevice, pPlaybackInfos[iDevice].name);\n    }\n\n    ma_device_config config = ma_device_config_init(ma_device_type_playback);\n    config.playback.pDeviceID = &pPlaybackInfos[chosenPlaybackDeviceIndex].id;\n    config.playback.format    = MY_FORMAT;\n    config.playback.channels  = MY_CHANNEL_COUNT;\n    config.sampleRate         = MY_SAMPLE_RATE;\n    config.dataCallback       = data_callback;\n    config.pUserData          = pMyCustomData;\n\n    ma_device device;\n    if (ma_device_init(&context, &config, &device) != MA_SUCCESS) {\n        // Error\n    }\n\n    ...\n\n    ma_device_uninit(&device);\n    ma_context_uninit(&context);\n    ```\n\nThe first thing we do in this example is initialize a `ma_context` object with `ma_context_init()`.\nThe first parameter is a pointer to a list of `ma_backend` values which are used to override the\ndefault backend priorities. When this is NULL, as in this example, miniaudio's default priorities\nare used. The second parameter is the number of backends listed in the array pointed to by the\nfirst parameter. The third parameter is a pointer to a `ma_context_config` object which can be\nNULL, in which case defaults are used. The context configuration is used for setting the logging\ncallback, custom memory allocation callbacks, user-defined data and some backend-specific\nconfigurations.\n\nOnce the context has been initialized you can enumerate devices. In the example above we use the\nsimpler `ma_context_get_devices()`, however you can also use a callback for handling devices by\nusing `ma_context_enumerate_devices()`. When using `ma_context_get_devices()` you provide a pointer\nto a pointer that will, upon output, be set to a pointer to a buffer containing a list of\n`ma_device_info` structures. You also provide a pointer to an unsigned integer that will receive\nthe number of items in the returned buffer. Do not free the returned buffers as their memory is\nmanaged internally by miniaudio.\n\nThe `ma_device_info` structure contains an `id` member which is the ID you pass to the device\nconfig. It also contains the name of the device which is useful for presenting a list of devices\nto the user via the UI.\n\nWhen creating your own context you will want to pass it to `ma_device_init()` when initializing the\ndevice. Passing in NULL, like we do in the first example, will result in miniaudio creating the\ncontext for you, which you don't want to do since you've already created a context. Note that\ninternally the context is only tracked by it's pointer which means you must not change the location\nof the `ma_context` object. If this is an issue, consider using `malloc()` to allocate memory for\nthe context.\n\n\n1.2. High Level API\n-------------------\nThe high level API consists of three main parts:\n\n  * Resource management for loading and streaming sounds.\n  * A node graph for advanced mixing and effect processing.\n  * A high level \"engine\" that wraps around the resource manager and node graph.\n\nThe resource manager (`ma_resource_manager`) is used for loading sounds. It supports loading sounds\nfully into memory and also streaming. It will also deal with reference counting for you which\navoids the same sound being loaded multiple times.\n\nThe node graph is used for mixing and effect processing. The idea is that you connect a number of\nnodes into the graph by connecting each node's outputs to another node's inputs. Each node can\nimplement it's own effect. By chaining nodes together, advanced mixing and effect processing can\nbe achieved.\n\nThe engine encapsulates both the resource manager and the node graph to create a simple, easy to\nuse high level API. The resource manager and node graph APIs are covered in more later sections of\nthis manual.\n\nThe code below shows how you can initialize an engine using it's default configuration.\n\n    ```c\n    ma_result result;\n    ma_engine engine;\n\n    result = ma_engine_init(NULL, &engine);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to initialize the engine.\n    }\n    ```\n\nThis creates an engine instance which will initialize a device internally which you can access with\n`ma_engine_get_device()`. It will also initialize a resource manager for you which can be accessed\nwith `ma_engine_get_resource_manager()`. The engine itself is a node graph (`ma_node_graph`) which\nmeans you can pass a pointer to the engine object into any of the `ma_node_graph` APIs (with a\ncast). Alternatively, you can use `ma_engine_get_node_graph()` instead of a cast.\n\nNote that all objects in miniaudio, including the `ma_engine` object in the example above, are\ntransparent structures. There are no handles to opaque structures in miniaudio which means you need\nto be mindful of how you declare them. In the example above we are declaring it on the stack, but\nthis will result in the struct being invalidated once the function encapsulating it returns. If\nallocating the engine on the heap is more appropriate, you can easily do so with a standard call\nto `malloc()` or whatever heap allocation routine you like:\n\n    ```c\n    ma_engine* pEngine = malloc(sizeof(*pEngine));\n    ```\n\nThe `ma_engine` API uses the same config/init pattern used all throughout miniaudio. To configure\nan engine, you can fill out a `ma_engine_config` object and pass it into the first parameter of\n`ma_engine_init()`:\n\n    ```c\n    ma_result result;\n    ma_engine engine;\n    ma_engine_config engineConfig;\n\n    engineConfig = ma_engine_config_init();\n    engineConfig.pResourceManager = &myCustomResourceManager;   // <-- Initialized as some earlier stage.\n\n    result = ma_engine_init(&engineConfig, &engine);\n    if (result != MA_SUCCESS) {\n        return result;\n    }\n    ```\n\nThis creates an engine instance using a custom config. In this particular example it's showing how\nyou can specify a custom resource manager rather than having the engine initialize one internally.\nThis is particularly useful if you want to have multiple engine's share the same resource manager.\n\nThe engine must be uninitialized with `ma_engine_uninit()` when it's no longer needed.\n\nBy default the engine will be started, but nothing will be playing because no sounds have been\ninitialized. The easiest but least flexible way of playing a sound is like so:\n\n    ```c\n    ma_engine_play_sound(&engine, \"my_sound.wav\", NULL);\n    ```\n\nThis plays what miniaudio calls an \"inline\" sound. It plays the sound once, and then puts the\ninternal sound up for recycling. The last parameter is used to specify which sound group the sound\nshould be associated with which will be explained later. This particular way of playing a sound is\nsimple, but lacks flexibility and features. A more flexible way of playing a sound is to first\ninitialize a sound:\n\n    ```c\n    ma_result result;\n    ma_sound sound;\n\n    result = ma_sound_init_from_file(&engine, \"my_sound.wav\", 0, NULL, NULL, &sound);\n    if (result != MA_SUCCESS) {\n        return result;\n    }\n\n    ma_sound_start(&sound);\n    ```\n\nThis returns a `ma_sound` object which represents a single instance of the specified sound file. If\nyou want to play the same file multiple times simultaneously, you need to create one sound for each\ninstance.\n\nSounds should be uninitialized with `ma_sound_uninit()`.\n\nSounds are not started by default. Start a sound with `ma_sound_start()` and stop it with\n`ma_sound_stop()`. When a sound is stopped, it is not rewound to the start. Use\n`ma_sound_seek_to_pcm_frame(&sound, 0)` to seek back to the start of a sound. By default, starting\nand stopping sounds happens immediately, but sometimes it might be convenient to schedule the sound\nthe be started and/or stopped at a specific time. This can be done with the following functions:\n\n    ```c\n    ma_sound_set_start_time_in_pcm_frames()\n    ma_sound_set_start_time_in_milliseconds()\n    ma_sound_set_stop_time_in_pcm_frames()\n    ma_sound_set_stop_time_in_milliseconds()\n    ```\n\nThe start/stop time needs to be specified based on the absolute timer which is controlled by the\nengine. The current global time time in PCM frames can be retrieved with\n`ma_engine_get_time_in_pcm_frames()`. The engine's global time can be changed with\n`ma_engine_set_time_in_pcm_frames()` for synchronization purposes if required. Note that scheduling\na start time still requires an explicit call to `ma_sound_start()` before anything will play:\n\n    ```c\n    ma_sound_set_start_time_in_pcm_frames(&sound, ma_engine_get_time_in_pcm_frames(&engine) + (ma_engine_get_sample_rate(&engine) * 2);\n    ma_sound_start(&sound);\n    ```\n\nThe third parameter of `ma_sound_init_from_file()` is a set of flags that control how the sound be\nloaded and a few options on which features should be enabled for that sound. By default, the sound\nis synchronously loaded fully into memory straight from the file system without any kind of\ndecoding. If you want to decode the sound before storing it in memory, you need to specify the\n`MA_SOUND_FLAG_DECODE` flag. This is useful if you want to incur the cost of decoding at an earlier\nstage, such as a loading stage. Without this option, decoding will happen dynamically at mixing\ntime which might be too expensive on the audio thread.\n\nIf you want to load the sound asynchronously, you can specify the `MA_SOUND_FLAG_ASYNC` flag. This\nwill result in `ma_sound_init_from_file()` returning quickly, but the sound will not start playing\nuntil the sound has had some audio decoded.\n\nThe fourth parameter is a pointer to sound group. A sound group is used as a mechanism to organise\nsounds into groups which have their own effect processing and volume control. An example is a game\nwhich might have separate groups for sfx, voice and music. Each of these groups have their own\nindependent volume control. Use `ma_sound_group_init()` or `ma_sound_group_init_ex()` to initialize\na sound group.\n\nSounds and sound groups are nodes in the engine's node graph and can be plugged into any `ma_node`\nAPI. This makes it possible to connect sounds and sound groups to effect nodes to produce complex\neffect chains.\n\nA sound can have it's volume changed with `ma_sound_set_volume()`. If you prefer decibel volume\ncontrol you can use `ma_volume_db_to_linear()` to convert from decibel representation to linear.\n\nPanning and pitching is supported with `ma_sound_set_pan()` and `ma_sound_set_pitch()`. If you know\na sound will never have it's pitch changed with `ma_sound_set_pitch()` or via the doppler effect,\nyou can specify the `MA_SOUND_FLAG_NO_PITCH` flag when initializing the sound for an optimization.\n\nBy default, sounds and sound groups have spatialization enabled. If you don't ever want to\nspatialize your sounds, initialize the sound with the `MA_SOUND_FLAG_NO_SPATIALIZATION` flag. The\nspatialization model is fairly simple and is roughly on feature parity with OpenAL. HRTF and\nenvironmental occlusion are not currently supported, but planned for the future. The supported\nfeatures include:\n\n  * Sound and listener positioning and orientation with cones\n  * Attenuation models: none, inverse, linear and exponential\n  * Doppler effect\n\nSounds can be faded in and out with `ma_sound_set_fade_in_pcm_frames()`.\n\nTo check if a sound is currently playing, you can use `ma_sound_is_playing()`. To check if a sound\nis at the end, use `ma_sound_at_end()`. Looping of a sound can be controlled with\n`ma_sound_set_looping()`. Use `ma_sound_is_looping()` to check whether or not the sound is looping.\n\n\n\n2. Building\n===========\nminiaudio should work cleanly out of the box without the need to download or install any\ndependencies. See below for platform-specific details.\n\nNote that GCC and Clang require `-msse2`, `-mavx2`, etc. for SIMD optimizations.\n\nIf you get errors about undefined references to `__sync_val_compare_and_swap_8`, `__atomic_load_8`,\netc. you need to link with `-latomic`.\n\n\n2.1. Windows\n------------\nThe Windows build should compile cleanly on all popular compilers without the need to configure any\ninclude paths nor link to any libraries.\n\nThe UWP build may require linking to mmdevapi.lib if you get errors about an unresolved external\nsymbol for `ActivateAudioInterfaceAsync()`.\n\n\n2.2. macOS and iOS\n------------------\nThe macOS build should compile cleanly without the need to download any dependencies nor link to\nany libraries or frameworks. The iOS build needs to be compiled as Objective-C and will need to\nlink the relevant frameworks but should compile cleanly out of the box with Xcode. Compiling\nthrough the command line requires linking to `-lpthread` and `-lm`.\n\nDue to the way miniaudio links to frameworks at runtime, your application may not pass Apple's\nnotarization process. To fix this there are two options. The first is to use the\n`MA_NO_RUNTIME_LINKING` option, like so:\n\n    ```c\n    #ifdef __APPLE__\n        #define MA_NO_RUNTIME_LINKING\n    #endif\n    #define MINIAUDIO_IMPLEMENTATION\n    #include \"miniaudio.h\"\n    ```\n\nThis will require linking with `-framework CoreFoundation -framework CoreAudio -framework AudioToolbox`.\nIf you get errors about AudioToolbox, try with `-framework AudioUnit` instead. You may get this when\nusing older versions of iOS. Alternatively, if you would rather keep using runtime linking you can\nadd the following to your entitlements.xcent file:\n\n    ```\n    <key>com.apple.security.cs.allow-dyld-environment-variables</key>\n    <true/>\n    <key>com.apple.security.cs.allow-unsigned-executable-memory</key>\n    <true/>\n    ```\n\nSee this discussion for more info: https://github.com/mackron/miniaudio/issues/203.\n\n\n2.3. Linux\n----------\nThe Linux build only requires linking to `-ldl`, `-lpthread` and `-lm`. You do not need any\ndevelopment packages. You may need to link with `-latomic` if you're compiling for 32-bit ARM.\n\n\n2.4. BSD\n--------\nThe BSD build only requires linking to `-lpthread` and `-lm`. NetBSD uses audio(4), OpenBSD uses\nsndio and FreeBSD uses OSS. You may need to link with `-latomic` if you're compiling for 32-bit\nARM.\n\n\n2.5. Android\n------------\nAAudio is the highest priority backend on Android. This should work out of the box without needing\nany kind of compiler configuration. Support for AAudio starts with Android 8 which means older\nversions will fall back to OpenSL|ES which requires API level 16+.\n\nThere have been reports that the OpenSL|ES backend fails to initialize on some Android based\ndevices due to `dlopen()` failing to open \"libOpenSLES.so\". If this happens on your platform\nyou'll need to disable run-time linking with `MA_NO_RUNTIME_LINKING` and link with -lOpenSLES.\n\n\n2.6. Emscripten\n---------------\nThe Emscripten build emits Web Audio JavaScript directly and should compile cleanly out of the box.\nYou cannot use `-std=c*` compiler flags, nor `-ansi`.\n\nYou can enable the use of AudioWorkets by defining `MA_ENABLE_AUDIO_WORKLETS` and then compiling\nwith the following options:\n\n    -sAUDIO_WORKLET=1 -sWASM_WORKERS=1 -sASYNCIFY\n\nAn example for compiling with AudioWorklet support might look like this:\n\n    emcc program.c -o bin/program.html -DMA_ENABLE_AUDIO_WORKLETS -sAUDIO_WORKLET=1 -sWASM_WORKERS=1 -sASYNCIFY\n\nTo run locally, you'll need to use emrun:\n\n    emrun bin/program.html\n\n\n\n2.7. Build Options\n------------------\n`#define` these options before including miniaudio.h.\n\n    +----------------------------------+--------------------------------------------------------------------+\n    | Option                           | Description                                                        |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_WASAPI                     | Disables the WASAPI backend.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_DSOUND                     | Disables the DirectSound backend.                                  |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_WINMM                      | Disables the WinMM backend.                                        |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_ALSA                       | Disables the ALSA backend.                                         |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_PULSEAUDIO                 | Disables the PulseAudio backend.                                   |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_JACK                       | Disables the JACK backend.                                         |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_COREAUDIO                  | Disables the Core Audio backend.                                   |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_SNDIO                      | Disables the sndio backend.                                        |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_AUDIO4                     | Disables the audio(4) backend.                                     |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_OSS                        | Disables the OSS backend.                                          |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_AAUDIO                     | Disables the AAudio backend.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_OPENSL                     | Disables the OpenSL|ES backend.                                    |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_WEBAUDIO                   | Disables the Web Audio backend.                                    |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_NULL                       | Disables the null backend.                                         |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_ONLY_SPECIFIC_BACKENDS | Disables all backends by default and requires `MA_ENABLE_*` to     |\n    |                                  | enable specific backends.                                          |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_WASAPI                 | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the WASAPI backend.                                         |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_DSOUND                 | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the DirectSound backend.                                    |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_WINMM                  | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the WinMM backend.                                          |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_ALSA                   | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the ALSA backend.                                           |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_PULSEAUDIO             | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the PulseAudio backend.                                     |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_JACK                   | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the JACK backend.                                           |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_COREAUDIO              | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the Core Audio backend.                                     |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_SNDIO                  | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the sndio backend.                                          |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_AUDIO4                 | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the audio(4) backend.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_OSS                    | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the OSS backend.                                            |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_AAUDIO                 | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the AAudio backend.                                         |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_OPENSL                 | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the OpenSL|ES backend.                                      |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_WEBAUDIO               | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the Web Audio backend.                                      |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_ENABLE_NULL                   | Used in conjunction with MA_ENABLE_ONLY_SPECIFIC_BACKENDS to       |\n    |                                  | enable the null backend.                                           |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_DECODING                   | Disables decoding APIs.                                            |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_ENCODING                   | Disables encoding APIs.                                            |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_WAV                        | Disables the built-in WAV decoder and encoder.                     |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_FLAC                       | Disables the built-in FLAC decoder.                                |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_MP3                        | Disables the built-in MP3 decoder.                                 |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_DEVICE_IO                  | Disables playback and recording. This will disable `ma_context`    |\n    |                                  | and `ma_device` APIs. This is useful if you only want to use       |\n    |                                  | miniaudio's data conversion and/or decoding APIs.                  |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_RESOURCE_MANAGER           | Disables the resource manager. When using the engine this will     |\n    |                                  | also disable the following functions:                              |\n    |                                  |                                                                    |\n    |                                  | ```                                                                |\n    |                                  | ma_sound_init_from_file()                                          |\n    |                                  | ma_sound_init_from_file_w()                                        |\n    |                                  | ma_sound_init_copy()                                               |\n    |                                  | ma_engine_play_sound_ex()                                          |\n    |                                  | ma_engine_play_sound()                                             |\n    |                                  | ```                                                                |\n    |                                  |                                                                    |\n    |                                  | The only way to initialize a `ma_sound` object is to initialize it |\n    |                                  | from a data source.                                                |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_NODE_GRAPH                 | Disables the node graph API. This will also disable the engine API |\n    |                                  | because it depends on the node graph.                              |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_ENGINE                     | Disables the engine API.                                           |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_THREADING                  | Disables the `ma_thread`, `ma_mutex`, `ma_semaphore` and           |\n    |                                  | `ma_event` APIs. This option is useful if you only need to use     |\n    |                                  | miniaudio for data conversion, decoding and/or encoding. Some      |\n    |                                  | families of APIs require threading which means the following       |\n    |                                  | options must also be set:                                          |\n    |                                  |                                                                    |\n    |                                  |     ```                                                            |\n    |                                  |     MA_NO_DEVICE_IO                                                |\n    |                                  |     ```                                                            |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_GENERATION                 | Disables generation APIs such a `ma_waveform` and `ma_noise`.      |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_SSE2                       | Disables SSE2 optimizations.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_AVX2                       | Disables AVX2 optimizations.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_NEON                       | Disables NEON optimizations.                                       |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_NO_RUNTIME_LINKING            | Disables runtime linking. This is useful for passing Apple's       |\n    |                                  | notarization process. When enabling this, you may need to avoid    |\n    |                                  | using `-std=c89` or `-std=c99` on Linux builds or else you may end |\n    |                                  | up with compilation errors due to conflicts with `timespec` and    |\n    |                                  | `timeval` data types.                                              |\n    |                                  |                                                                    |\n    |                                  | You may need to enable this if your target platform does not allow |\n    |                                  | runtime linking via `dlopen()`.                                    |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_DEBUG_OUTPUT                  | Enable `printf()` output of debug logs (`MA_LOG_LEVEL_DEBUG`).     |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_COINIT_VALUE                  | Windows only. The value to pass to internal calls to               |\n    |                                  | `CoInitializeEx()`. Defaults to `COINIT_MULTITHREADED`.            |\n    +----------------------------------+--------------------------------------------------------------------+\n    | MA_API                           | Controls how public APIs should be decorated. Default is `extern`. |\n    +----------------------------------+--------------------------------------------------------------------+\n\n\n3. Definitions\n==============\nThis section defines common terms used throughout miniaudio. Unfortunately there is often ambiguity\nin the use of terms throughout the audio space, so this section is intended to clarify how miniaudio\nuses each term.\n\n3.1. Sample\n-----------\nA sample is a single unit of audio data. If the sample format is f32, then one sample is one 32-bit\nfloating point number.\n\n3.2. Frame / PCM Frame\n----------------------\nA frame is a group of samples equal to the number of channels. For a stereo stream a frame is 2\nsamples, a mono frame is 1 sample, a 5.1 surround sound frame is 6 samples, etc. The terms \"frame\"\nand \"PCM frame\" are the same thing in miniaudio. Note that this is different to a compressed frame.\nIf ever miniaudio needs to refer to a compressed frame, such as a FLAC frame, it will always\nclarify what it's referring to with something like \"FLAC frame\".\n\n3.3. Channel\n------------\nA stream of monaural audio that is emitted from an individual speaker in a speaker system, or\nreceived from an individual microphone in a microphone system. A stereo stream has two channels (a\nleft channel, and a right channel), a 5.1 surround sound system has 6 channels, etc. Some audio\nsystems refer to a channel as a complex audio stream that's mixed with other channels to produce\nthe final mix - this is completely different to miniaudio's use of the term \"channel\" and should\nnot be confused.\n\n3.4. Sample Rate\n----------------\nThe sample rate in miniaudio is always expressed in Hz, such as 44100, 48000, etc. It's the number\nof PCM frames that are processed per second.\n\n3.5. Formats\n------------\nThroughout miniaudio you will see references to different sample formats:\n\n    +---------------+----------------------------------------+---------------------------+\n    | Symbol        | Description                            | Range                     |\n    +---------------+----------------------------------------+---------------------------+\n    | ma_format_f32 | 32-bit floating point                  | [-1, 1]                   |\n    | ma_format_s16 | 16-bit signed integer                  | [-32768, 32767]           |\n    | ma_format_s24 | 24-bit signed integer (tightly packed) | [-8388608, 8388607]       |\n    | ma_format_s32 | 32-bit signed integer                  | [-2147483648, 2147483647] |\n    | ma_format_u8  | 8-bit unsigned integer                 | [0, 255]                  |\n    +---------------+----------------------------------------+---------------------------+\n\nAll formats are native-endian.\n\n\n\n4. Data Sources\n===============\nThe data source abstraction in miniaudio is used for retrieving audio data from some source. A few\nexamples include `ma_decoder`, `ma_noise` and `ma_waveform`. You will need to be familiar with data\nsources in order to make sense of some of the higher level concepts in miniaudio.\n\nThe `ma_data_source` API is a generic interface for reading from a data source. Any object that\nimplements the data source interface can be plugged into any `ma_data_source` function.\n\nTo read data from a data source:\n\n    ```c\n    ma_result result;\n    ma_uint64 framesRead;\n\n    result = ma_data_source_read_pcm_frames(pDataSource, pFramesOut, frameCount, &framesRead);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to read data from the data source.\n    }\n    ```\n\nIf you don't need the number of frames that were successfully read you can pass in `NULL` to the\n`pFramesRead` parameter. If this returns a value less than the number of frames requested it means\nthe end of the file has been reached. `MA_AT_END` will be returned only when the number of frames\nread is 0.\n\nWhen calling any data source function, with the exception of `ma_data_source_init()` and\n`ma_data_source_uninit()`, you can pass in any object that implements a data source. For example,\nyou could plug in a decoder like so:\n\n    ```c\n    ma_result result;\n    ma_uint64 framesRead;\n    ma_decoder decoder;   // <-- This would be initialized with `ma_decoder_init_*()`.\n\n    result = ma_data_source_read_pcm_frames(&decoder, pFramesOut, frameCount, &framesRead);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to read data from the decoder.\n    }\n    ```\n\nIf you want to seek forward you can pass in `NULL` to the `pFramesOut` parameter. Alternatively you\ncan use `ma_data_source_seek_pcm_frames()`.\n\nTo seek to a specific PCM frame:\n\n    ```c\n    result = ma_data_source_seek_to_pcm_frame(pDataSource, frameIndex);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to seek to PCM frame.\n    }\n    ```\n\nYou can retrieve the total length of a data source in PCM frames, but note that some data sources\nmay not have the notion of a length, such as noise and waveforms, and others may just not have a\nway of determining the length such as some decoders. To retrieve the length:\n\n    ```c\n    ma_uint64 length;\n\n    result = ma_data_source_get_length_in_pcm_frames(pDataSource, &length);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to retrieve the length.\n    }\n    ```\n\nCare should be taken when retrieving the length of a data source where the underlying decoder is\npulling data from a data stream with an undefined length, such as internet radio or some kind of\nbroadcast. If you do this, `ma_data_source_get_length_in_pcm_frames()` may never return.\n\nThe current position of the cursor in PCM frames can also be retrieved:\n\n    ```c\n    ma_uint64 cursor;\n\n    result = ma_data_source_get_cursor_in_pcm_frames(pDataSource, &cursor);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to retrieve the cursor.\n    }\n    ```\n\nYou will often need to know the data format that will be returned after reading. This can be\nretrieved like so:\n\n    ```c\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_channel channelMap[MA_MAX_CHANNELS];\n\n    result = ma_data_source_get_data_format(pDataSource, &format, &channels, &sampleRate, channelMap, MA_MAX_CHANNELS);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to retrieve data format.\n    }\n    ```\n\nIf you do not need a specific data format property, just pass in NULL to the respective parameter.\n\nThere may be cases where you want to implement something like a sound bank where you only want to\nread data within a certain range of the underlying data. To do this you can use a range:\n\n    ```c\n    result = ma_data_source_set_range_in_pcm_frames(pDataSource, rangeBegInFrames, rangeEndInFrames);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to set the range.\n    }\n    ```\n\nThis is useful if you have a sound bank where many sounds are stored in the same file and you want\nthe data source to only play one of those sub-sounds. Note that once the range is set, everything\nthat takes a position, such as cursors and loop points, should always be relatvie to the start of\nthe range. When the range is set, any previously defined loop point will be reset.\n\nCustom loop points can also be used with data sources. By default, data sources will loop after\nthey reach the end of the data source, but if you need to loop at a specific location, you can do\nthe following:\n\n    ```c\n    result = ma_data_set_loop_point_in_pcm_frames(pDataSource, loopBegInFrames, loopEndInFrames);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to set the loop point.\n    }\n    ```\n\nThe loop point is relative to the current range.\n\nIt's sometimes useful to chain data sources together so that a seamless transition can be achieved.\nTo do this, you can use chaining:\n\n    ```c\n    ma_decoder decoder1;\n    ma_decoder decoder2;\n\n    // ... initialize decoders with ma_decoder_init_*() ...\n\n    result = ma_data_source_set_next(&decoder1, &decoder2);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to set the next data source.\n    }\n\n    result = ma_data_source_read_pcm_frames(&decoder1, pFramesOut, frameCount, pFramesRead);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to read from the decoder.\n    }\n    ```\n\nIn the example above we're using decoders. When reading from a chain, you always want to read from\nthe top level data source in the chain. In the example above, `decoder1` is the top level data\nsource in the chain. When `decoder1` reaches the end, `decoder2` will start seamlessly without any\ngaps.\n\nNote that when looping is enabled, only the current data source will be looped. You can loop the\nentire chain by linking in a loop like so:\n\n    ```c\n    ma_data_source_set_next(&decoder1, &decoder2);  // decoder1 -> decoder2\n    ma_data_source_set_next(&decoder2, &decoder1);  // decoder2 -> decoder1 (loop back to the start).\n    ```\n\nNote that setting up chaining is not thread safe, so care needs to be taken if you're dynamically\nchanging links while the audio thread is in the middle of reading.\n\nDo not use `ma_decoder_seek_to_pcm_frame()` as a means to reuse a data source to play multiple\ninstances of the same sound simultaneously. This can be extremely inefficient depending on the type\nof data source and can result in glitching due to subtle changes to the state of internal filters.\nInstead, initialize multiple data sources for each instance.\n\n\n4.1. Custom Data Sources\n------------------------\nYou can implement a custom data source by implementing the functions in `ma_data_source_vtable`.\nYour custom object must have `ma_data_source_base` as it's first member:\n\n    ```c\n    struct my_data_source\n    {\n        ma_data_source_base base;\n        ...\n    };\n    ```\n\nIn your initialization routine, you need to call `ma_data_source_init()` in order to set up the\nbase object (`ma_data_source_base`):\n\n    ```c\n    static ma_result my_data_source_read(ma_data_source* pDataSource, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead)\n    {\n        // Read data here. Output in the same format returned by my_data_source_get_data_format().\n    }\n\n    static ma_result my_data_source_seek(ma_data_source* pDataSource, ma_uint64 frameIndex)\n    {\n        // Seek to a specific PCM frame here. Return MA_NOT_IMPLEMENTED if seeking is not supported.\n    }\n\n    static ma_result my_data_source_get_data_format(ma_data_source* pDataSource, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap)\n    {\n        // Return the format of the data here.\n    }\n\n    static ma_result my_data_source_get_cursor(ma_data_source* pDataSource, ma_uint64* pCursor)\n    {\n        // Retrieve the current position of the cursor here. Return MA_NOT_IMPLEMENTED and set *pCursor to 0 if there is no notion of a cursor.\n    }\n\n    static ma_result my_data_source_get_length(ma_data_source* pDataSource, ma_uint64* pLength)\n    {\n        // Retrieve the length in PCM frames here. Return MA_NOT_IMPLEMENTED and set *pLength to 0 if there is no notion of a length or if the length is unknown.\n    }\n\n    static ma_data_source_vtable g_my_data_source_vtable =\n    {\n        my_data_source_read,\n        my_data_source_seek,\n        my_data_source_get_data_format,\n        my_data_source_get_cursor,\n        my_data_source_get_length\n    };\n\n    ma_result my_data_source_init(my_data_source* pMyDataSource)\n    {\n        ma_result result;\n        ma_data_source_config baseConfig;\n\n        baseConfig = ma_data_source_config_init();\n        baseConfig.vtable = &g_my_data_source_vtable;\n\n        result = ma_data_source_init(&baseConfig, &pMyDataSource->base);\n        if (result != MA_SUCCESS) {\n            return result;\n        }\n\n        // ... do the initialization of your custom data source here ...\n\n        return MA_SUCCESS;\n    }\n\n    void my_data_source_uninit(my_data_source* pMyDataSource)\n    {\n        // ... do the uninitialization of your custom data source here ...\n\n        // You must uninitialize the base data source.\n        ma_data_source_uninit(&pMyDataSource->base);\n    }\n    ```\n\nNote that `ma_data_source_init()` and `ma_data_source_uninit()` are never called directly outside\nof the custom data source. It's up to the custom data source itself to call these within their own\ninit/uninit functions.\n\n\n\n5. Engine\n=========\nThe `ma_engine` API is a high level API for managing and mixing sounds and effect processing. The\n`ma_engine` object encapsulates a resource manager and a node graph, both of which will be\nexplained in more detail later.\n\nSounds are called `ma_sound` and are created from an engine. Sounds can be associated with a mixing\ngroup called `ma_sound_group` which are also created from the engine. Both `ma_sound` and\n`ma_sound_group` objects are nodes within the engine's node graph.\n\nWhen the engine is initialized, it will normally create a device internally. If you would rather\nmanage the device yourself, you can do so and just pass a pointer to it via the engine config when\nyou initialize the engine. You can also just use the engine without a device, which again can be\nconfigured via the engine config.\n\nThe most basic way to initialize the engine is with a default config, like so:\n\n    ```c\n    ma_result result;\n    ma_engine engine;\n\n    result = ma_engine_init(NULL, &engine);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to initialize the engine.\n    }\n    ```\n\nThis will result in the engine initializing a playback device using the operating system's default\ndevice. This will be sufficient for many use cases, but if you need more flexibility you'll want to\nconfigure the engine with an engine config:\n\n    ```c\n    ma_result result;\n    ma_engine engine;\n    ma_engine_config engineConfig;\n\n    engineConfig = ma_engine_config_init();\n    engineConfig.pDevice = &myDevice;\n\n    result = ma_engine_init(&engineConfig, &engine);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to initialize the engine.\n    }\n    ```\n\nIn the example above we're passing in a pre-initialized device. Since the caller is the one in\ncontrol of the device's data callback, it's their responsibility to manually call\n`ma_engine_read_pcm_frames()` from inside their data callback:\n\n    ```c\n    void playback_data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount)\n    {\n        ma_engine_read_pcm_frames(&g_Engine, pOutput, frameCount, NULL);\n    }\n    ```\n\nYou can also use the engine independent of a device entirely:\n\n    ```c\n    ma_result result;\n    ma_engine engine;\n    ma_engine_config engineConfig;\n\n    engineConfig = ma_engine_config_init();\n    engineConfig.noDevice   = MA_TRUE;\n    engineConfig.channels   = 2;        // Must be set when not using a device.\n    engineConfig.sampleRate = 48000;    // Must be set when not using a device.\n\n    result = ma_engine_init(&engineConfig, &engine);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to initialize the engine.\n    }\n    ```\n\nNote that when you're not using a device, you must set the channel count and sample rate in the\nconfig or else miniaudio won't know what to use (miniaudio will use the device to determine this\nnormally). When not using a device, you need to use `ma_engine_read_pcm_frames()` to process audio\ndata from the engine. This kind of setup is useful if you want to do something like offline\nprocessing or want to use a different audio system for playback such as SDL.\n\nWhen a sound is loaded it goes through a resource manager. By default the engine will initialize a\nresource manager internally, but you can also specify a pre-initialized resource manager:\n\n    ```c\n    ma_result result;\n    ma_engine engine1;\n    ma_engine engine2;\n    ma_engine_config engineConfig;\n\n    engineConfig = ma_engine_config_init();\n    engineConfig.pResourceManager = &myResourceManager;\n\n    ma_engine_init(&engineConfig, &engine1);\n    ma_engine_init(&engineConfig, &engine2);\n    ```\n\nIn this example we are initializing two engines, both of which are sharing the same resource\nmanager. This is especially useful for saving memory when loading the same file across multiple\nengines. If you were not to use a shared resource manager, each engine instance would use their own\nwhich would result in any sounds that are used between both engine's being loaded twice. By using\na shared resource manager, it would only be loaded once. Using multiple engine's is useful when you\nneed to output to multiple playback devices, such as in a local multiplayer game where each player\nis using their own set of headphones.\n\nBy default an engine will be in a started state. To make it so the engine is not automatically\nstarted you can configure it as such:\n\n    ```c\n    engineConfig.noAutoStart = MA_TRUE;\n\n    // The engine will need to be started manually.\n    ma_engine_start(&engine);\n\n    // Later on the engine can be stopped with ma_engine_stop().\n    ma_engine_stop(&engine);\n    ```\n\nThe concept of starting or stopping an engine is only relevant when using the engine with a\ndevice. Attempting to start or stop an engine that is not associated with a device will result in\n`MA_INVALID_OPERATION`.\n\nThe master volume of the engine can be controlled with `ma_engine_set_volume()` which takes a\nlinear scale, with 0 resulting in silence and anything above 1 resulting in amplification. If you\nprefer decibel based volume control, use `ma_volume_db_to_linear()` to convert from dB to linear.\n\nWhen a sound is spatialized, it is done so relative to a listener. An engine can be configured to\nhave multiple listeners which can be configured via the config:\n\n    ```c\n    engineConfig.listenerCount = 2;\n    ```\n\nThe maximum number of listeners is restricted to `MA_ENGINE_MAX_LISTENERS`. By default, when a\nsound is spatialized, it will be done so relative to the closest listener. You can also pin a sound\nto a specific listener which will be explained later. Listener's have a position, direction, cone,\nand velocity (for doppler effect). A listener is referenced by an index, the meaning of which is up\nto the caller (the index is 0 based and cannot go beyond the listener count, minus 1). The\nposition, direction and velocity are all specified in absolute terms:\n\n    ```c\n    ma_engine_listener_set_position(&engine, listenerIndex, worldPosX, worldPosY, worldPosZ);\n    ```\n\nThe direction of the listener represents it's forward vector. The listener's up vector can also be\nspecified and defaults to +1 on the Y axis.\n\n    ```c\n    ma_engine_listener_set_direction(&engine, listenerIndex, forwardX, forwardY, forwardZ);\n    ma_engine_listener_set_world_up(&engine, listenerIndex, 0, 1, 0);\n    ```\n\nThe engine supports directional attenuation. The listener can have a cone the controls how sound is\nattenuated based on the listener's direction. When a sound is between the inner and outer cones, it\nwill be attenuated between 1 and the cone's outer gain:\n\n    ```c\n    ma_engine_listener_set_cone(&engine, listenerIndex, innerAngleInRadians, outerAngleInRadians, outerGain);\n    ```\n\nWhen a sound is inside the inner code, no directional attenuation is applied. When the sound is\noutside of the outer cone, the attenuation will be set to `outerGain` in the example above. When\nthe sound is in between the inner and outer cones, the attenuation will be interpolated between 1\nand the outer gain.\n\nThe engine's coordinate system follows the OpenGL coordinate system where positive X points right,\npositive Y points up and negative Z points forward.\n\nThe simplest and least flexible way to play a sound is like so:\n\n    ```c\n    ma_engine_play_sound(&engine, \"my_sound.wav\", pGroup);\n    ```\n\nThis is a \"fire and forget\" style of function. The engine will manage the `ma_sound` object\ninternally. When the sound finishes playing, it'll be put up for recycling. For more flexibility\nyou'll want to initialize a sound object:\n\n    ```c\n    ma_sound sound;\n\n    result = ma_sound_init_from_file(&engine, \"my_sound.wav\", flags, pGroup, NULL, &sound);\n    if (result != MA_SUCCESS) {\n        return result;  // Failed to load sound.\n    }\n    ```\n\nSounds need to be uninitialized with `ma_sound_uninit()`.\n\nThe example above loads a sound from a file. If the resource manager has been disabled you will not\nbe able to use this function and instead you'll need to initialize a sound directly from a data\nsource:\n\n    ```c\n    ma_sound sound;\n\n    result = ma_sound_init_from_data_source(&engine, &dataSource, flags, pGroup, &sound);\n    if (result != MA_SUCCESS) {\n        return result;\n    }\n    ```\n\nEach `ma_sound` object represents a single instance of the sound. If you want to play the same\nsound multiple times at the same time, you need to initialize a separate `ma_sound` object.\n\nFor the most flexibility when initializing sounds, use `ma_sound_init_ex()`. This uses miniaudio's\nstandard config/init pattern:\n\n    ```c\n    ma_sound sound;\n    ma_sound_config soundConfig;\n\n    soundConfig = ma_sound_config_init();\n    soundConfig.pFilePath   = NULL; // Set this to load from a file path.\n    soundConfig.pDataSource = NULL; // Set this to initialize from an existing data source.\n    soundConfig.pInitialAttachment = &someNodeInTheNodeGraph;\n    soundConfig.initialAttachmentInputBusIndex = 0;\n    soundConfig.channelsIn  = 1;\n    soundConfig.channelsOut = 0;    // Set to 0 to use the engine's native channel count.\n\n    result = ma_sound_init_ex(&soundConfig, &sound);\n    if (result != MA_SUCCESS) {\n        return result;\n    }\n    ```\n\nIn the example above, the sound is being initialized without a file nor a data source. This is\nvalid, in which case the sound acts as a node in the middle of the node graph. This means you can\nconnect other sounds to this sound and allow it to act like a sound group. Indeed, this is exactly\nwhat a `ma_sound_group` is.\n\nWhen loading a sound, you specify a set of flags that control how the sound is loaded and what\nfeatures are enabled for that sound. When no flags are set, the sound will be fully loaded into\nmemory in exactly the same format as how it's stored on the file system. The resource manager will\nallocate a block of memory and then load the file directly into it. When reading audio data, it\nwill be decoded dynamically on the fly. In order to save processing time on the audio thread, it\nmight be beneficial to pre-decode the sound. You can do this with the `MA_SOUND_FLAG_DECODE` flag:\n\n    ```c\n    ma_sound_init_from_file(&engine, \"my_sound.wav\", MA_SOUND_FLAG_DECODE, pGroup, NULL, &sound);\n    ```\n\nBy default, sounds will be loaded synchronously, meaning `ma_sound_init_*()` will not return until\nthe sound has been fully loaded. If this is prohibitive you can instead load sounds asynchronously\nby specifying the `MA_SOUND_FLAG_ASYNC` flag:\n\n    ```c\n    ma_sound_init_from_file(&engine, \"my_sound.wav\", MA_SOUND_FLAG_DECODE | MA_SOUND_FLAG_ASYNC, pGroup, NULL, &sound);\n    ```\n\nThis will result in `ma_sound_init_*()` returning quickly, but the sound won't yet have been fully\nloaded. When you start the sound, it won't output anything until some sound is available. The sound\nwill start outputting audio before the sound has been fully decoded when the `MA_SOUND_FLAG_DECODE`\nis specified.\n\nIf you need to wait for an asynchronously loaded sound to be fully loaded, you can use a fence. A\nfence in miniaudio is a simple synchronization mechanism which simply blocks until it's internal\ncounter hit's zero. You can specify a fence like so:\n\n    ```c\n    ma_result result;\n    ma_fence fence;\n    ma_sound sounds[4];\n\n    result = ma_fence_init(&fence);\n    if (result != MA_SUCCESS) {\n        return result;\n    }\n\n    // Load some sounds asynchronously.\n    for (int iSound = 0; iSound < 4; iSound += 1) {\n        ma_sound_init_from_file(&engine, mySoundFilesPaths[iSound], MA_SOUND_FLAG_DECODE | MA_SOUND_FLAG_ASYNC, pGroup, &fence, &sounds[iSound]);\n    }\n\n    // ... do some other stuff here in the mean time ...\n\n    // Wait for all sounds to finish loading.\n    ma_fence_wait(&fence);\n    ```\n\nIf loading the entire sound into memory is prohibitive, you can also configure the engine to stream\nthe audio data:\n\n    ```c\n    ma_sound_init_from_file(&engine, \"my_sound.wav\", MA_SOUND_FLAG_STREAM, pGroup, NULL, &sound);\n    ```\n\nWhen streaming sounds, 2 seconds worth of audio data is stored in memory. Although it should work\nfine, it's inefficient to use streaming for short sounds. Streaming is useful for things like music\ntracks in games.\n\nWhen loading a sound from a file path, the engine will reference count the file to prevent it from\nbeing loaded if it's already in memory. When you uninitialize a sound, the reference count will be\ndecremented, and if it hits zero, the sound will be unloaded from memory. This reference counting\nsystem is not used for streams. The engine will use a 64-bit hash of the file name when comparing\nfile paths which means there's a small chance you might encounter a name collision. If this is an\nissue, you'll need to use a different name for one of the colliding file paths, or just not load\nfrom files and instead load from a data source.\n\nYou can use `ma_sound_init_copy()` to initialize a copy of another sound. Note, however, that this\nonly works for sounds that were initialized with `ma_sound_init_from_file()` and without the\n`MA_SOUND_FLAG_STREAM` flag.\n\nWhen you initialize a sound, if you specify a sound group the sound will be attached to that group\nautomatically. If you set it to NULL, it will be automatically attached to the engine's endpoint.\nIf you would instead rather leave the sound unattached by default, you can can specify the\n`MA_SOUND_FLAG_NO_DEFAULT_ATTACHMENT` flag. This is useful if you want to set up a complex node\ngraph.\n\nSounds are not started by default. To start a sound, use `ma_sound_start()`. Stop a sound with\n`ma_sound_stop()`.\n\nSounds can have their volume controlled with `ma_sound_set_volume()` in the same way as the\nengine's master volume.\n\nSounds support stereo panning and pitching. Set the pan with `ma_sound_set_pan()`. Setting the pan\nto 0 will result in an unpanned sound. Setting it to -1 will shift everything to the left, whereas\n+1 will shift it to the right. The pitch can be controlled with `ma_sound_set_pitch()`. A larger\nvalue will result in a higher pitch. The pitch must be greater than 0.\n\nThe engine supports 3D spatialization of sounds. By default sounds will have spatialization\nenabled, but if a sound does not need to be spatialized it's best to disable it. There are two ways\nto disable spatialization of a sound:\n\n    ```c\n    // Disable spatialization at initialization time via a flag:\n    ma_sound_init_from_file(&engine, \"my_sound.wav\", MA_SOUND_FLAG_NO_SPATIALIZATION, NULL, NULL, &sound);\n\n    // Dynamically disable or enable spatialization post-initialization:\n    ma_sound_set_spatialization_enabled(&sound, isSpatializationEnabled);\n    ```\n\nBy default sounds will be spatialized based on the closest listener. If a sound should always be\nspatialized relative to a specific listener it can be pinned to one:\n\n    ```c\n    ma_sound_set_pinned_listener_index(&sound, listenerIndex);\n    ```\n\nLike listeners, sounds have a position. By default, the position of a sound is in absolute space,\nbut it can be changed to be relative to a listener:\n\n    ```c\n    ma_sound_set_positioning(&sound, ma_positioning_relative);\n    ```\n\nNote that relative positioning of a sound only makes sense if there is either only one listener, or\nthe sound is pinned to a specific listener. To set the position of a sound:\n\n    ```c\n    ma_sound_set_position(&sound, posX, posY, posZ);\n    ```\n\nThe direction works the same way as a listener and represents the sound's forward direction:\n\n    ```c\n    ma_sound_set_direction(&sound, forwardX, forwardY, forwardZ);\n    ```\n\nSound's also have a cone for controlling directional attenuation. This works exactly the same as\nlisteners:\n\n    ```c\n    ma_sound_set_cone(&sound, innerAngleInRadians, outerAngleInRadians, outerGain);\n    ```\n\nThe velocity of a sound is used for doppler effect and can be set as such:\n\n    ```c\n    ma_sound_set_velocity(&sound, velocityX, velocityY, velocityZ);\n    ```\n\nThe engine supports different attenuation models which can be configured on a per-sound basis. By\ndefault the attenuation model is set to `ma_attenuation_model_inverse` which is the equivalent to\nOpenAL's `AL_INVERSE_DISTANCE_CLAMPED`. Configure the attenuation model like so:\n\n    ```c\n    ma_sound_set_attenuation_model(&sound, ma_attenuation_model_inverse);\n    ```\n\nThe supported attenuation models include the following:\n\n    +----------------------------------+----------------------------------------------+\n    | ma_attenuation_model_none        | No distance attenuation.                     |\n    +----------------------------------+----------------------------------------------+\n    | ma_attenuation_model_inverse     | Equivalent to `AL_INVERSE_DISTANCE_CLAMPED`. |\n    +----------------------------------+----------------------------------------------+\n    | ma_attenuation_model_linear      | Linear attenuation.                          |\n    +----------------------------------+----------------------------------------------+\n    | ma_attenuation_model_exponential | Exponential attenuation.                     |\n    +----------------------------------+----------------------------------------------+\n\nTo control how quickly a sound rolls off as it moves away from the listener, you need to configure\nthe rolloff:\n\n    ```c\n    ma_sound_set_rolloff(&sound, rolloff);\n    ```\n\nYou can control the minimum and maximum gain to apply from spatialization:\n\n    ```c\n    ma_sound_set_min_gain(&sound, minGain);\n    ma_sound_set_max_gain(&sound, maxGain);\n    ```\n\nLikewise, in the calculation of attenuation, you can control the minimum and maximum distances for\nthe attenuation calculation. This is useful if you want to ensure sounds don't drop below a certain\nvolume after the listener moves further away and to have sounds play a maximum volume when the\nlistener is within a certain distance:\n\n    ```c\n    ma_sound_set_min_distance(&sound, minDistance);\n    ma_sound_set_max_distance(&sound, maxDistance);\n    ```\n\nThe engine's spatialization system supports doppler effect. The doppler factor can be configure on\na per-sound basis like so:\n\n    ```c\n    ma_sound_set_doppler_factor(&sound, dopplerFactor);\n    ```\n\nYou can fade sounds in and out with `ma_sound_set_fade_in_pcm_frames()` and\n`ma_sound_set_fade_in_milliseconds()`. Set the volume to -1 to use the current volume as the\nstarting volume:\n\n    ```c\n    // Fade in over 1 second.\n    ma_sound_set_fade_in_milliseconds(&sound, 0, 1, 1000);\n\n    // ... sometime later ...\n\n    // Fade out over 1 second, starting from the current volume.\n    ma_sound_set_fade_in_milliseconds(&sound, -1, 0, 1000);\n    ```\n\nBy default sounds will start immediately, but sometimes for timing and synchronization purposes it\ncan be useful to schedule a sound to start or stop:\n\n    ```c\n    // Start the sound in 1 second from now.\n    ma_sound_set_start_time_in_pcm_frames(&sound, ma_engine_get_time_in_pcm_frames(&engine) + (ma_engine_get_sample_rate(&engine) * 1));\n\n    // Stop the sound in 2 seconds from now.\n    ma_sound_set_stop_time_in_pcm_frames(&sound, ma_engine_get_time_in_pcm_frames(&engine) + (ma_engine_get_sample_rate(&engine) * 2));\n    ```\n\nNote that scheduling a start time still requires an explicit call to `ma_sound_start()` before\nanything will play.\n\nThe time is specified in global time which is controlled by the engine. You can get the engine's\ncurrent time with `ma_engine_get_time_in_pcm_frames()`. The engine's global time is incremented\nautomatically as audio data is read, but it can be reset with `ma_engine_set_time_in_pcm_frames()`\nin case it needs to be resynchronized for some reason.\n\nTo determine whether or not a sound is currently playing, use `ma_sound_is_playing()`. This will\ntake the scheduled start and stop times into account.\n\nWhether or not a sound should loop can be controlled with `ma_sound_set_looping()`. Sounds will not\nbe looping by default. Use `ma_sound_is_looping()` to determine whether or not a sound is looping.\n\nUse `ma_sound_at_end()` to determine whether or not a sound is currently at the end. For a looping\nsound this should never return true. Alternatively, you can configure a callback that will be fired\nwhen the sound reaches the end. Note that the callback is fired from the audio thread which means\nyou cannot be uninitializing sound from the callback. To set the callback you can use\n`ma_sound_set_end_callback()`. Alternatively, if you're using `ma_sound_init_ex()`, you can pass it\ninto the config like so:\n\n    ```c\n    soundConfig.endCallback = my_end_callback;\n    soundConfig.pEndCallbackUserData = pMyEndCallbackUserData;\n    ```\n\nThe end callback is declared like so:\n\n    ```c\n    void my_end_callback(void* pUserData, ma_sound* pSound)\n    {\n        ...\n    }\n    ```\n\nInternally a sound wraps around a data source. Some APIs exist to control the underlying data\nsource, mainly for convenience:\n\n    ```c\n    ma_sound_seek_to_pcm_frame(&sound, frameIndex);\n    ma_sound_get_data_format(&sound, &format, &channels, &sampleRate, pChannelMap, channelMapCapacity);\n    ma_sound_get_cursor_in_pcm_frames(&sound, &cursor);\n    ma_sound_get_length_in_pcm_frames(&sound, &length);\n    ```\n\nSound groups have the same API as sounds, only they are called `ma_sound_group`, and since they do\nnot have any notion of a data source, anything relating to a data source is unavailable.\n\nInternally, sound data is loaded via the `ma_decoder` API which means by default it only supports\nfile formats that have built-in support in miniaudio. You can extend this to support any kind of\nfile format through the use of custom decoders. To do this you'll need to use a self-managed\nresource manager and configure it appropriately. See the \"Resource Management\" section below for\ndetails on how to set this up.\n\n\n6. Resource Management\n======================\nMany programs will want to manage sound resources for things such as reference counting and\nstreaming. This is supported by miniaudio via the `ma_resource_manager` API.\n\nThe resource manager is mainly responsible for the following:\n\n  * Loading of sound files into memory with reference counting.\n  * Streaming of sound data.\n\nWhen loading a sound file, the resource manager will give you back a `ma_data_source` compatible\nobject called `ma_resource_manager_data_source`. This object can be passed into any\n`ma_data_source` API which is how you can read and seek audio data. When loading a sound file, you\nspecify whether or not you want the sound to be fully loaded into memory (and optionally\npre-decoded) or streamed. When loading into memory, you can also specify whether or not you want\nthe data to be loaded asynchronously.\n\nThe example below is how you can initialize a resource manager using it's default configuration:\n\n    ```c\n    ma_resource_manager_config config;\n    ma_resource_manager resourceManager;\n\n    config = ma_resource_manager_config_init();\n    result = ma_resource_manager_init(&config, &resourceManager);\n    if (result != MA_SUCCESS) {\n        ma_device_uninit(&device);\n        printf(\"Failed to initialize the resource manager.\");\n        return -1;\n    }\n    ```\n\nYou can configure the format, channels and sample rate of the decoded audio data. By default it\nwill use the file's native data format, but you can configure it to use a consistent format. This\nis useful for offloading the cost of data conversion to load time rather than dynamically\nconverting at mixing time. To do this, you configure the decoded format, channels and sample rate\nlike the code below:\n\n    ```c\n    config = ma_resource_manager_config_init();\n    config.decodedFormat     = device.playback.format;\n    config.decodedChannels   = device.playback.channels;\n    config.decodedSampleRate = device.sampleRate;\n    ```\n\nIn the code above, the resource manager will be configured so that any decoded audio data will be\npre-converted at load time to the device's native data format. If instead you used defaults and\nthe data format of the file did not match the device's data format, you would need to convert the\ndata at mixing time which may be prohibitive in high-performance and large scale scenarios like\ngames.\n\nInternally the resource manager uses the `ma_decoder` API to load sounds. This means by default it\nonly supports decoders that are built into miniaudio. It's possible to support additional encoding\nformats through the use of custom decoders. To do so, pass in your `ma_decoding_backend_vtable`\nvtables into the resource manager config:\n\n    ```c\n    ma_decoding_backend_vtable* pCustomBackendVTables[] =\n    {\n        &g_ma_decoding_backend_vtable_libvorbis,\n        &g_ma_decoding_backend_vtable_libopus\n    };\n\n    ...\n\n    resourceManagerConfig.ppCustomDecodingBackendVTables = pCustomBackendVTables;\n    resourceManagerConfig.customDecodingBackendCount     = sizeof(pCustomBackendVTables) / sizeof(pCustomBackendVTables[0]);\n    resourceManagerConfig.pCustomDecodingBackendUserData = NULL;\n    ```\n\nThis system can allow you to support any kind of file format. See the \"Decoding\" section for\ndetails on how to implement custom decoders. The miniaudio repository includes examples for Opus\nvia libopus and libopusfile and Vorbis via libvorbis and libvorbisfile.\n\nAsynchronicity is achieved via a job system. When an operation needs to be performed, such as the\ndecoding of a page, a job will be posted to a queue which will then be processed by a job thread.\nBy default there will be only one job thread running, but this can be configured, like so:\n\n    ```c\n    config = ma_resource_manager_config_init();\n    config.jobThreadCount = MY_JOB_THREAD_COUNT;\n    ```\n\nBy default job threads are managed internally by the resource manager, however you can also self\nmanage your job threads if, for example, you want to integrate the job processing into your\nexisting job infrastructure, or if you simply don't like the way the resource manager does it. To\ndo this, just set the job thread count to 0 and process jobs manually. To process jobs, you first\nneed to retrieve a job using `ma_resource_manager_next_job()` and then process it using\n`ma_job_process()`:\n\n    ```c\n    config = ma_resource_manager_config_init();\n    config.jobThreadCount = 0;                            // Don't manage any job threads internally.\n    config.flags = MA_RESOURCE_MANAGER_FLAG_NON_BLOCKING; // Optional. Makes `ma_resource_manager_next_job()` non-blocking.\n\n    // ... Initialize your custom job threads ...\n\n    void my_custom_job_thread(...)\n    {\n        for (;;) {\n            ma_job job;\n            ma_result result = ma_resource_manager_next_job(pMyResourceManager, &job);\n            if (result != MA_SUCCESS) {\n                if (result == MA_NO_DATA_AVAILABLE) {\n                    // No jobs are available. Keep going. Will only get this if the resource manager was initialized\n                    // with MA_RESOURCE_MANAGER_FLAG_NON_BLOCKING.\n                    continue;\n                } else if (result == MA_CANCELLED) {\n                    // MA_JOB_TYPE_QUIT was posted. Exit.\n                    break;\n                } else {\n                    // Some other error occurred.\n                    break;\n                }\n            }\n\n            ma_job_process(&job);\n        }\n    }\n    ```\n\nIn the example above, the `MA_JOB_TYPE_QUIT` event is the used as the termination\nindicator, but you can use whatever you would like to terminate the thread. The call to\n`ma_resource_manager_next_job()` is blocking by default, but can be configured to be non-blocking\nby initializing the resource manager with the `MA_RESOURCE_MANAGER_FLAG_NON_BLOCKING` configuration\nflag. Note that the `MA_JOB_TYPE_QUIT` will never be removed from the job queue. This\nis to give every thread the opportunity to catch the event and terminate naturally.\n\nWhen loading a file, it's sometimes convenient to be able to customize how files are opened and\nread instead of using standard `fopen()`, `fclose()`, etc. which is what miniaudio will use by\ndefault. This can be done by setting `pVFS` member of the resource manager's config:\n\n    ```c\n    // Initialize your custom VFS object. See documentation for VFS for information on how to do this.\n    my_custom_vfs vfs = my_custom_vfs_init();\n\n    config = ma_resource_manager_config_init();\n    config.pVFS = &vfs;\n    ```\n\nThis is particularly useful in programs like games where you want to read straight from an archive\nrather than the normal file system. If you do not specify a custom VFS, the resource manager will\nuse the operating system's normal file operations.\n\nTo load a sound file and create a data source, call `ma_resource_manager_data_source_init()`. When\nloading a sound you need to specify the file path and options for how the sounds should be loaded.\nBy default a sound will be loaded synchronously. The returned data source is owned by the caller\nwhich means the caller is responsible for the allocation and freeing of the data source. Below is\nan example for initializing a data source:\n\n    ```c\n    ma_resource_manager_data_source dataSource;\n    ma_result result = ma_resource_manager_data_source_init(pResourceManager, pFilePath, flags, &dataSource);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    // ...\n\n    // A ma_resource_manager_data_source object is compatible with the `ma_data_source` API. To read data, just call\n    // the `ma_data_source_read_pcm_frames()` like you would with any normal data source.\n    result = ma_data_source_read_pcm_frames(&dataSource, pDecodedData, frameCount, &framesRead);\n    if (result != MA_SUCCESS) {\n        // Failed to read PCM frames.\n    }\n\n    // ...\n\n    ma_resource_manager_data_source_uninit(&dataSource);\n    ```\n\nThe `flags` parameter specifies how you want to perform loading of the sound file. It can be a\ncombination of the following flags:\n\n    ```\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_DECODE\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_ASYNC\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_WAIT_INIT\n    ```\n\nWhen no flags are specified (set to 0), the sound will be fully loaded into memory, but not\ndecoded, meaning the raw file data will be stored in memory, and then dynamically decoded when\n`ma_data_source_read_pcm_frames()` is called. To instead decode the audio data before storing it in\nmemory, use the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_DECODE` flag. By default, the sound file will\nbe loaded synchronously, meaning `ma_resource_manager_data_source_init()` will only return after\nthe entire file has been loaded. This is good for simplicity, but can be prohibitively slow. You\ncan instead load the sound asynchronously using the `MA_RESOURCE_MANAGER_DATA_SOURCE_ASYNC` flag.\nThis will result in `ma_resource_manager_data_source_init()` returning quickly, but no data will be\nreturned by `ma_data_source_read_pcm_frames()` until some data is available. When no data is\navailable because the asynchronous decoding hasn't caught up, `MA_BUSY` will be returned by\n`ma_data_source_read_pcm_frames()`.\n\nFor large sounds, it's often prohibitive to store the entire file in memory. To mitigate this, you\ncan instead stream audio data which you can do by specifying the\n`MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM` flag. When streaming, data will be decoded in 1\nsecond pages. When a new page needs to be decoded, a job will be posted to the job queue and then\nsubsequently processed in a job thread.\n\nFor in-memory sounds, reference counting is used to ensure the data is loaded only once. This means\nmultiple calls to `ma_resource_manager_data_source_init()` with the same file path will result in\nthe file data only being loaded once. Each call to `ma_resource_manager_data_source_init()` must be\nmatched up with a call to `ma_resource_manager_data_source_uninit()`. Sometimes it can be useful\nfor a program to register self-managed raw audio data and associate it with a file path. Use the\n`ma_resource_manager_register_*()` and `ma_resource_manager_unregister_*()` APIs to do this.\n`ma_resource_manager_register_decoded_data()` is used to associate a pointer to raw, self-managed\ndecoded audio data in the specified data format with the specified name. Likewise,\n`ma_resource_manager_register_encoded_data()` is used to associate a pointer to raw self-managed\nencoded audio data (the raw file data) with the specified name. Note that these names need not be\nactual file paths. When `ma_resource_manager_data_source_init()` is called (without the\n`MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM` flag), the resource manager will look for these\nexplicitly registered data buffers and, if found, will use it as the backing data for the data\nsource. Note that the resource manager does *not* make a copy of this data so it is up to the\ncaller to ensure the pointer stays valid for it's lifetime. Use\n`ma_resource_manager_unregister_data()` to unregister the self-managed data. You can also use\n`ma_resource_manager_register_file()` and `ma_resource_manager_unregister_file()` to register and\nunregister a file. It does not make sense to use the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM`\nflag with a self-managed data pointer.\n\n\n6.1. Asynchronous Loading and Synchronization\n---------------------------------------------\nWhen loading asynchronously, it can be useful to poll whether or not loading has finished. Use\n`ma_resource_manager_data_source_result()` to determine this. For in-memory sounds, this will\nreturn `MA_SUCCESS` when the file has been *entirely* decoded. If the sound is still being decoded,\n`MA_BUSY` will be returned. Otherwise, some other error code will be returned if the sound failed\nto load. For streaming data sources, `MA_SUCCESS` will be returned when the first page has been\ndecoded and the sound is ready to be played. If the first page is still being decoded, `MA_BUSY`\nwill be returned. Otherwise, some other error code will be returned if the sound failed to load.\n\nIn addition to polling, you can also use a simple synchronization object called a \"fence\" to wait\nfor asynchronously loaded sounds to finish. This is called `ma_fence`. The advantage to using a\nfence is that it can be used to wait for a group of sounds to finish loading rather than waiting\nfor sounds on an individual basis. There are two stages to loading a sound:\n\n  * Initialization of the internal decoder; and\n  * Completion of decoding of the file (the file is fully decoded)\n\nYou can specify separate fences for each of the different stages. Waiting for the initialization\nof the internal decoder is important for when you need to know the sample format, channels and\nsample rate of the file.\n\nThe example below shows how you could use a fence when loading a number of sounds:\n\n    ```c\n    // This fence will be released when all sounds are finished loading entirely.\n    ma_fence fence;\n    ma_fence_init(&fence);\n\n    // This will be passed into the initialization routine for each sound.\n    ma_resource_manager_pipeline_notifications notifications = ma_resource_manager_pipeline_notifications_init();\n    notifications.done.pFence = &fence;\n\n    // Now load a bunch of sounds:\n    for (iSound = 0; iSound < soundCount; iSound += 1) {\n        ma_resource_manager_data_source_init(pResourceManager, pSoundFilePaths[iSound], flags, &notifications, &pSoundSources[iSound]);\n    }\n\n    // ... DO SOMETHING ELSE WHILE SOUNDS ARE LOADING ...\n\n    // Wait for loading of sounds to finish.\n    ma_fence_wait(&fence);\n    ```\n\nIn the example above we used a fence for waiting until the entire file has been fully decoded. If\nyou only need to wait for the initialization of the internal decoder to complete, you can use the\n`init` member of the `ma_resource_manager_pipeline_notifications` object:\n\n    ```c\n    notifications.init.pFence = &fence;\n    ```\n\nIf a fence is not appropriate for your situation, you can instead use a callback that is fired on\nan individual sound basis. This is done in a very similar way to fences:\n\n    ```c\n    typedef struct\n    {\n        ma_async_notification_callbacks cb;\n        void* pMyData;\n    } my_notification;\n\n    void my_notification_callback(ma_async_notification* pNotification)\n    {\n        my_notification* pMyNotification = (my_notification*)pNotification;\n\n        // Do something in response to the sound finishing loading.\n    }\n\n    ...\n\n    my_notification myCallback;\n    myCallback.cb.onSignal = my_notification_callback;\n    myCallback.pMyData     = pMyData;\n\n    ma_resource_manager_pipeline_notifications notifications = ma_resource_manager_pipeline_notifications_init();\n    notifications.done.pNotification = &myCallback;\n\n    ma_resource_manager_data_source_init(pResourceManager, \"my_sound.wav\", flags, &notifications, &mySound);\n    ```\n\nIn the example above we just extend the `ma_async_notification_callbacks` object and pass an\ninstantiation into the `ma_resource_manager_pipeline_notifications` in the same way as we did with\nthe fence, only we set `pNotification` instead of `pFence`. You can set both of these at the same\ntime and they should both work as expected. If using the `pNotification` system, you need to ensure\nyour `ma_async_notification_callbacks` object stays valid.\n\n\n\n6.2. Resource Manager Implementation Details\n--------------------------------------------\nResources are managed in two main ways:\n\n  * By storing the entire sound inside an in-memory buffer (referred to as a data buffer)\n  * By streaming audio data on the fly (referred to as a data stream)\n\nA resource managed data source (`ma_resource_manager_data_source`) encapsulates a data buffer or\ndata stream, depending on whether or not the data source was initialized with the\n`MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM` flag. If so, it will make use of a\n`ma_resource_manager_data_stream` object. Otherwise it will use a `ma_resource_manager_data_buffer`\nobject. Both of these objects are data sources which means they can be used with any\n`ma_data_source_*()` API.\n\nAnother major feature of the resource manager is the ability to asynchronously decode audio files.\nThis relieves the audio thread of time-consuming decoding which can negatively affect scalability\ndue to the audio thread needing to complete it's work extremely quickly to avoid glitching.\nAsynchronous decoding is achieved through a job system. There is a central multi-producer,\nmulti-consumer, fixed-capacity job queue. When some asynchronous work needs to be done, a job is\nposted to the queue which is then read by a job thread. The number of job threads can be\nconfigured for improved scalability, and job threads can all run in parallel without needing to\nworry about the order of execution (how this is achieved is explained below).\n\nWhen a sound is being loaded asynchronously, playback can begin before the sound has been fully\ndecoded. This enables the application to start playback of the sound quickly, while at the same\ntime allowing to resource manager to keep loading in the background. Since there may be less\nthreads than the number of sounds being loaded at a given time, a simple scheduling system is used\nto keep decoding time balanced and fair. The resource manager solves this by splitting decoding\ninto chunks called pages. By default, each page is 1 second long. When a page has been decoded, a\nnew job will be posted to start decoding the next page. By dividing up decoding into pages, an\nindividual sound shouldn't ever delay every other sound from having their first page decoded. Of\ncourse, when loading many sounds at the same time, there will always be an amount of time required\nto process jobs in the queue so in heavy load situations there will still be some delay. To\ndetermine if a data source is ready to have some frames read, use\n`ma_resource_manager_data_source_get_available_frames()`. This will return the number of frames\navailable starting from the current position.\n\n\n6.2.1. Job Queue\n----------------\nThe resource manager uses a job queue which is multi-producer, multi-consumer, and fixed-capacity.\nThis job queue is not currently lock-free, and instead uses a spinlock to achieve thread-safety.\nOnly a fixed number of jobs can be allocated and inserted into the queue which is done through a\nlock-free data structure for allocating an index into a fixed sized array, with reference counting\nfor mitigation of the ABA problem. The reference count is 32-bit.\n\nFor many types of jobs it's important that they execute in a specific order. In these cases, jobs\nare executed serially. For the resource manager, serial execution of jobs is only required on a\nper-object basis (per data buffer or per data stream). Each of these objects stores an execution\ncounter. When a job is posted it is associated with an execution counter. When the job is\nprocessed, it checks if the execution counter of the job equals the execution counter of the\nowning object and if so, processes the job. If the counters are not equal, the job will be posted\nback onto the job queue for later processing. When the job finishes processing the execution order\nof the main object is incremented. This system means the no matter how many job threads are\nexecuting, decoding of an individual sound will always get processed serially. The advantage to\nhaving multiple threads comes into play when loading multiple sounds at the same time.\n\nThe resource manager's job queue is not 100% lock-free and will use a spinlock to achieve\nthread-safety for a very small section of code. This is only relevant when the resource manager\nuses more than one job thread. If only using a single job thread, which is the default, the\nlock should never actually wait in practice. The amount of time spent locking should be quite\nshort, but it's something to be aware of for those who have pedantic lock-free requirements and\nneed to use more than one job thread. There are plans to remove this lock in a future version.\n\nIn addition, posting a job will release a semaphore, which on Win32 is implemented with\n`ReleaseSemaphore` and on POSIX platforms via a condition variable:\n\n    ```c\n    pthread_mutex_lock(&pSemaphore->lock);\n    {\n        pSemaphore->value += 1;\n        pthread_cond_signal(&pSemaphore->cond);\n    }\n    pthread_mutex_unlock(&pSemaphore->lock);\n    ```\n\nAgain, this is relevant for those with strict lock-free requirements in the audio thread. To avoid\nthis, you can use non-blocking mode (via the `MA_JOB_QUEUE_FLAG_NON_BLOCKING`\nflag) and implement your own job processing routine (see the \"Resource Manager\" section above for\ndetails on how to do this).\n\n\n\n6.2.2. Data Buffers\n-------------------\nWhen the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM` flag is excluded at initialization time, the\nresource manager will try to load the data into an in-memory data buffer. Before doing so, however,\nit will first check if the specified file is already loaded. If so, it will increment a reference\ncounter and just use the already loaded data. This saves both time and memory. When the data buffer\nis uninitialized, the reference counter will be decremented. If the counter hits zero, the file\nwill be unloaded. This is a detail to keep in mind because it could result in excessive loading and\nunloading of a sound. For example, the following sequence will result in a file be loaded twice,\nonce after the other:\n\n    ```c\n    ma_resource_manager_data_source_init(pResourceManager, \"my_file\", ..., &myDataBuffer0); // Refcount = 1. Initial load.\n    ma_resource_manager_data_source_uninit(&myDataBuffer0);                                 // Refcount = 0. Unloaded.\n\n    ma_resource_manager_data_source_init(pResourceManager, \"my_file\", ..., &myDataBuffer1); // Refcount = 1. Reloaded because previous uninit() unloaded it.\n    ma_resource_manager_data_source_uninit(&myDataBuffer1);                                 // Refcount = 0. Unloaded.\n    ```\n\nA binary search tree (BST) is used for storing data buffers as it has good balance between\nefficiency and simplicity. The key of the BST is a 64-bit hash of the file path that was passed\ninto `ma_resource_manager_data_source_init()`. The advantage of using a hash is that it saves\nmemory over storing the entire path, has faster comparisons, and results in a mostly balanced BST\ndue to the random nature of the hash. The disadvantages are that file names are case-sensitive and\nthere's a small chance of name collisions. If case-sensitivity is an issue, you should normalize\nyour file names to upper- or lower-case before initializing your data sources. If name collisions\nbecome an issue, you'll need to change the name of one of the colliding names or just not use the\nresource manager.\n\nWhen a sound file has not already been loaded and the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_ASYNC`\nflag is excluded, the file will be decoded synchronously by the calling thread. There are two\noptions for controlling how the audio is stored in the data buffer - encoded or decoded. When the\n`MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_DECODE` option is excluded, the raw file data will be stored\nin memory. Otherwise the sound will be decoded before storing it in memory. Synchronous loading is\na very simple and standard process of simply adding an item to the BST, allocating a block of\nmemory and then decoding (if `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_DECODE` is specified).\n\nWhen the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_ASYNC` flag is specified, loading of the data buffer\nis done asynchronously. In this case, a job is posted to the queue to start loading and then the\nfunction immediately returns, setting an internal result code to `MA_BUSY`. This result code is\nreturned when the program calls `ma_resource_manager_data_source_result()`. When decoding has fully\ncompleted `MA_SUCCESS` will be returned. This can be used to know if loading has fully completed.\n\nWhen loading asynchronously, a single job is posted to the queue of the type\n`MA_JOB_TYPE_RESOURCE_MANAGER_LOAD_DATA_BUFFER_NODE`. This involves making a copy of the file path and\nassociating it with job. When the job is processed by the job thread, it will first load the file\nusing the VFS associated with the resource manager. When using a custom VFS, it's important that it\nbe completely thread-safe because it will be used from one or more job threads at the same time.\nIndividual files should only ever be accessed by one thread at a time, however. After opening the\nfile via the VFS, the job will determine whether or not the file is being decoded. If not, it\nsimply allocates a block of memory and loads the raw file contents into it and returns. On the\nother hand, when the file is being decoded, it will first allocate a decoder on the heap and\ninitialize it. Then it will check if the length of the file is known. If so it will allocate a\nblock of memory to store the decoded output and initialize it to silence. If the size is unknown,\nit will allocate room for one page. After memory has been allocated, the first page will be\ndecoded. If the sound is shorter than a page, the result code will be set to `MA_SUCCESS` and the\ncompletion event will be signalled and loading is now complete. If, however, there is more to\ndecode, a job with the code `MA_JOB_TYPE_RESOURCE_MANAGER_PAGE_DATA_BUFFER_NODE` is posted. This job\nwill decode the next page and perform the same process if it reaches the end. If there is more to\ndecode, the job will post another `MA_JOB_TYPE_RESOURCE_MANAGER_PAGE_DATA_BUFFER_NODE` job which will\nkeep on happening until the sound has been fully decoded. For sounds of an unknown length, each\npage will be linked together as a linked list. Internally this is implemented via the\n`ma_paged_audio_buffer` object.\n\n\n6.2.3. Data Streams\n-------------------\nData streams only ever store two pages worth of data for each instance. They are most useful for\nlarge sounds like music tracks in games that would consume too much memory if fully decoded in\nmemory. After every frame from a page has been read, a job will be posted to load the next page\nwhich is done from the VFS.\n\nFor data streams, the `MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_ASYNC` flag will determine whether or\nnot initialization of the data source waits until the two pages have been decoded. When unset,\n`ma_resource_manager_data_source_init()` will wait until the two pages have been loaded, otherwise\nit will return immediately.\n\nWhen frames are read from a data stream using `ma_resource_manager_data_source_read_pcm_frames()`,\n`MA_BUSY` will be returned if there are no frames available. If there are some frames available,\nbut less than the number requested, `MA_SUCCESS` will be returned, but the actual number of frames\nread will be less than the number requested. Due to the asynchronous nature of data streams,\nseeking is also asynchronous. If the data stream is in the middle of a seek, `MA_BUSY` will be\nreturned when trying to read frames.\n\nWhen `ma_resource_manager_data_source_read_pcm_frames()` results in a page getting fully consumed\na job is posted to load the next page. This will be posted from the same thread that called\n`ma_resource_manager_data_source_read_pcm_frames()`.\n\nData streams are uninitialized by posting a job to the queue, but the function won't return until\nthat job has been processed. The reason for this is that the caller owns the data stream object and\ntherefore miniaudio needs to ensure everything completes before handing back control to the caller.\nAlso, if the data stream is uninitialized while pages are in the middle of decoding, they must\ncomplete before destroying any underlying object and the job system handles this cleanly.\n\nNote that when a new page needs to be loaded, a job will be posted to the resource manager's job\nthread from the audio thread. You must keep in mind the details mentioned in the \"Job Queue\"\nsection above regarding locking when posting an event if you require a strictly lock-free audio\nthread.\n\n\n\n7. Node Graph\n=============\nminiaudio's routing infrastructure follows a node graph paradigm. The idea is that you create a\nnode whose outputs are attached to inputs of another node, thereby creating a graph. There are\ndifferent types of nodes, with each node in the graph processing input data to produce output,\nwhich is then fed through the chain. Each node in the graph can apply their own custom effects. At\nthe start of the graph will usually be one or more data source nodes which have no inputs and\ninstead pull their data from a data source. At the end of the graph is an endpoint which represents\nthe end of the chain and is where the final output is ultimately extracted from.\n\nEach node has a number of input buses and a number of output buses. An output bus from a node is\nattached to an input bus of another. Multiple nodes can connect their output buses to another\nnode's input bus, in which case their outputs will be mixed before processing by the node. Below is\na diagram that illustrates a hypothetical node graph setup:\n\n    ```\n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data flows left to right >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\n    +---------------+                              +-----------------+\n    | Data Source 1 =----+    +----------+    +----= Low Pass Filter =----+\n    +---------------+    |    |          =----+    +-----------------+    |    +----------+\n                         +----= Splitter |                                +----= ENDPOINT |\n    +---------------+    |    |          =----+    +-----------------+    |    +----------+\n    | Data Source 2 =----+    +----------+    +----=  Echo / Delay   =----+\n    +---------------+                              +-----------------+\n    ```\n\nIn the above graph, it starts with two data sources whose outputs are attached to the input of a\nsplitter node. It's at this point that the two data sources are mixed. After mixing, the splitter\nperforms it's processing routine and produces two outputs which is simply a duplication of the\ninput stream. One output is attached to a low pass filter, whereas the other output is attached to\na echo/delay. The outputs of the the low pass filter and the echo are attached to the endpoint, and\nsince they're both connected to the same input bus, they'll be mixed.\n\nEach input bus must be configured to accept the same number of channels, but the number of channels\nused by input buses can be different to the number of channels for output buses in which case\nminiaudio will automatically convert the input data to the output channel count before processing.\nThe number of channels of an output bus of one node must match the channel count of the input bus\nit's attached to. The channel counts cannot be changed after the node has been initialized. If you\nattempt to attach an output bus to an input bus with a different channel count, attachment will\nfail.\n\nTo use a node graph, you first need to initialize a `ma_node_graph` object. This is essentially a\ncontainer around the entire graph. The `ma_node_graph` object is required for some thread-safety\nissues which will be explained later. A `ma_node_graph` object is initialized using miniaudio's\nstandard config/init system:\n\n    ```c\n    ma_node_graph_config nodeGraphConfig = ma_node_graph_config_init(myChannelCount);\n\n    result = ma_node_graph_init(&nodeGraphConfig, NULL, &nodeGraph);    // Second parameter is a pointer to allocation callbacks.\n    if (result != MA_SUCCESS) {\n        // Failed to initialize node graph.\n    }\n    ```\n\nWhen you initialize the node graph, you're specifying the channel count of the endpoint. The\nendpoint is a special node which has one input bus and one output bus, both of which have the\nsame channel count, which is specified in the config. Any nodes that connect directly to the\nendpoint must be configured such that their output buses have the same channel count. When you read\naudio data from the node graph, it'll have the channel count you specified in the config. To read\ndata from the graph:\n\n    ```c\n    ma_uint32 framesRead;\n    result = ma_node_graph_read_pcm_frames(&nodeGraph, pFramesOut, frameCount, &framesRead);\n    if (result != MA_SUCCESS) {\n        // Failed to read data from the node graph.\n    }\n    ```\n\nWhen you read audio data, miniaudio starts at the node graph's endpoint node which then pulls in\ndata from it's input attachments, which in turn recursively pull in data from their inputs, and so\non. At the start of the graph there will be some kind of data source node which will have zero\ninputs and will instead read directly from a data source. The base nodes don't literally need to\nread from a `ma_data_source` object, but they will always have some kind of underlying object that\nsources some kind of audio. The `ma_data_source_node` node can be used to read from a\n`ma_data_source`. Data is always in floating-point format and in the number of channels you\nspecified when the graph was initialized. The sample rate is defined by the underlying data sources.\nIt's up to you to ensure they use a consistent and appropriate sample rate.\n\nThe `ma_node` API is designed to allow custom nodes to be implemented with relative ease, but\nminiaudio includes a few stock nodes for common functionality. This is how you would initialize a\nnode which reads directly from a data source (`ma_data_source_node`) which is an example of one\nof the stock nodes that comes with miniaudio:\n\n    ```c\n    ma_data_source_node_config config = ma_data_source_node_config_init(pMyDataSource);\n\n    ma_data_source_node dataSourceNode;\n    result = ma_data_source_node_init(&nodeGraph, &config, NULL, &dataSourceNode);\n    if (result != MA_SUCCESS) {\n        // Failed to create data source node.\n    }\n    ```\n\nThe data source node will use the output channel count to determine the channel count of the output\nbus. There will be 1 output bus and 0 input buses (data will be drawn directly from the data\nsource). The data source must output to floating-point (`ma_format_f32`) or else an error will be\nreturned from `ma_data_source_node_init()`.\n\nBy default the node will not be attached to the graph. To do so, use `ma_node_attach_output_bus()`:\n\n    ```c\n    result = ma_node_attach_output_bus(&dataSourceNode, 0, ma_node_graph_get_endpoint(&nodeGraph), 0);\n    if (result != MA_SUCCESS) {\n        // Failed to attach node.\n    }\n    ```\n\nThe code above connects the data source node directly to the endpoint. Since the data source node\nhas only a single output bus, the index will always be 0. Likewise, the endpoint only has a single\ninput bus which means the input bus index will also always be 0.\n\nTo detach a specific output bus, use `ma_node_detach_output_bus()`. To detach all output buses, use\n`ma_node_detach_all_output_buses()`. If you want to just move the output bus from one attachment to\nanother, you do not need to detach first. You can just call `ma_node_attach_output_bus()` and it'll\ndeal with it for you.\n\nLess frequently you may want to create a specialized node. This will be a node where you implement\nyour own processing callback to apply a custom effect of some kind. This is similar to initializing\none of the stock node types, only this time you need to specify a pointer to a vtable containing a\npointer to the processing function and the number of input and output buses. Example:\n\n    ```c\n    static void my_custom_node_process_pcm_frames(ma_node* pNode, const float** ppFramesIn, ma_uint32* pFrameCountIn, float** ppFramesOut, ma_uint32* pFrameCountOut)\n    {\n        // Do some processing of ppFramesIn (one stream of audio data per input bus)\n        const float* pFramesIn_0 = ppFramesIn[0]; // Input bus @ index 0.\n        const float* pFramesIn_1 = ppFramesIn[1]; // Input bus @ index 1.\n        float* pFramesOut_0 = ppFramesOut[0];     // Output bus @ index 0.\n\n        // Do some processing. On input, `pFrameCountIn` will be the number of input frames in each\n        // buffer in `ppFramesIn` and `pFrameCountOut` will be the capacity of each of the buffers\n        // in `ppFramesOut`. On output, `pFrameCountIn` should be set to the number of input frames\n        // your node consumed and `pFrameCountOut` should be set the number of output frames that\n        // were produced.\n        //\n        // You should process as many frames as you can. If your effect consumes input frames at the\n        // same rate as output frames (always the case, unless you're doing resampling), you need\n        // only look at `ppFramesOut` and process that exact number of frames. If you're doing\n        // resampling, you'll need to be sure to set both `pFrameCountIn` and `pFrameCountOut`\n        // properly.\n    }\n\n    static ma_node_vtable my_custom_node_vtable =\n    {\n        my_custom_node_process_pcm_frames, // The function that will be called to process your custom node. This is where you'd implement your effect processing.\n        NULL,   // Optional. A callback for calculating the number of input frames that are required to process a specified number of output frames.\n        2,      // 2 input buses.\n        1,      // 1 output bus.\n        0       // Default flags.\n    };\n\n    ...\n\n    // Each bus needs to have a channel count specified. To do this you need to specify the channel\n    // counts in an array and then pass that into the node config.\n    ma_uint32 inputChannels[2];     // Equal in size to the number of input channels specified in the vtable.\n    ma_uint32 outputChannels[1];    // Equal in size to the number of output channels specified in the vtable.\n\n    inputChannels[0]  = channelsIn;\n    inputChannels[1]  = channelsIn;\n    outputChannels[0] = channelsOut;\n\n    ma_node_config nodeConfig = ma_node_config_init();\n    nodeConfig.vtable          = &my_custom_node_vtable;\n    nodeConfig.pInputChannels  = inputChannels;\n    nodeConfig.pOutputChannels = outputChannels;\n\n    ma_node_base node;\n    result = ma_node_init(&nodeGraph, &nodeConfig, NULL, &node);\n    if (result != MA_SUCCESS) {\n        // Failed to initialize node.\n    }\n    ```\n\nWhen initializing a custom node, as in the code above, you'll normally just place your vtable in\nstatic space. The number of input and output buses are specified as part of the vtable. If you need\na variable number of buses on a per-node bases, the vtable should have the relevant bus count set\nto `MA_NODE_BUS_COUNT_UNKNOWN`. In this case, the bus count should be set in the node config:\n\n    ```c\n    static ma_node_vtable my_custom_node_vtable =\n    {\n        my_custom_node_process_pcm_frames, // The function that will be called process your custom node. This is where you'd implement your effect processing.\n        NULL,   // Optional. A callback for calculating the number of input frames that are required to process a specified number of output frames.\n        MA_NODE_BUS_COUNT_UNKNOWN,  // The number of input buses is determined on a per-node basis.\n        1,      // 1 output bus.\n        0       // Default flags.\n    };\n\n    ...\n\n    ma_node_config nodeConfig = ma_node_config_init();\n    nodeConfig.vtable          = &my_custom_node_vtable;\n    nodeConfig.inputBusCount   = myBusCount;        // <-- Since the vtable specifies MA_NODE_BUS_COUNT_UNKNOWN, the input bus count should be set here.\n    nodeConfig.pInputChannels  = inputChannels;     // <-- Make sure there are nodeConfig.inputBusCount elements in this array.\n    nodeConfig.pOutputChannels = outputChannels;    // <-- The vtable specifies 1 output bus, so there must be 1 element in this array.\n    ```\n\nIn the above example it's important to never set the `inputBusCount` and `outputBusCount` members\nto anything other than their defaults if the vtable specifies an explicit count. They can only be\nset if the vtable specifies MA_NODE_BUS_COUNT_UNKNOWN in the relevant bus count.\n\nMost often you'll want to create a structure to encapsulate your node with some extra data. You\nneed to make sure the `ma_node_base` object is your first member of the structure:\n\n    ```c\n    typedef struct\n    {\n        ma_node_base base; // <-- Make sure this is always the first member.\n        float someCustomData;\n    } my_custom_node;\n    ```\n\nBy doing this, your object will be compatible with all `ma_node` APIs and you can attach it to the\ngraph just like any other node.\n\nIn the custom processing callback (`my_custom_node_process_pcm_frames()` in the example above), the\nnumber of channels for each bus is what was specified by the config when the node was initialized\nwith `ma_node_init()`. In addition, all attachments to each of the input buses will have been\npre-mixed by miniaudio. The config allows you to specify different channel counts for each\nindividual input and output bus. It's up to the effect to handle it appropriate, and if it can't,\nreturn an error in it's initialization routine.\n\nCustom nodes can be assigned some flags to describe their behaviour. These are set via the vtable\nand include the following:\n\n    +-----------------------------------------+---------------------------------------------------+\n    | Flag Name                               | Description                                       |\n    +-----------------------------------------+---------------------------------------------------+\n    | MA_NODE_FLAG_PASSTHROUGH                | Useful for nodes that do not do any kind of audio |\n    |                                         | processing, but are instead used for tracking     |\n    |                                         | time, handling events, etc. Also used by the      |\n    |                                         | internal endpoint node. It reads directly from    |\n    |                                         | the input bus to the output bus. Nodes with this  |\n    |                                         | flag must have exactly 1 input bus and 1 output   |\n    |                                         | bus, and both buses must have the same channel    |\n    |                                         | counts.                                           |\n    +-----------------------------------------+---------------------------------------------------+\n    | MA_NODE_FLAG_CONTINUOUS_PROCESSING      | Causes the processing callback to be called even  |\n    |                                         | when no data is available to be read from input   |\n    |                                         | attachments. When a node has at least one input   |\n    |                                         | bus, but there are no inputs attached or the      |\n    |                                         | inputs do not deliver any data, the node's        |\n    |                                         | processing callback will not get fired. This flag |\n    |                                         | will make it so the callback is always fired      |\n    |                                         | regardless of whether or not any input data is    |\n    |                                         | received. This is useful for effects like         |\n    |                                         | echos where there will be a tail of audio data    |\n    |                                         | that still needs to be processed even when the    |\n    |                                         | original data sources have reached their ends. It |\n    |                                         | may also be useful for nodes that must always     |\n    |                                         | have their processing callback fired when there   |\n    |                                         | are no inputs attached.                           |\n    +-----------------------------------------+---------------------------------------------------+\n    | MA_NODE_FLAG_ALLOW_NULL_INPUT           | Used in conjunction with                          |\n    |                                         | `MA_NODE_FLAG_CONTINUOUS_PROCESSING`. When this   |\n    |                                         | is set, the `ppFramesIn` parameter of the         |\n    |                                         | processing callback will be set to NULL when      |\n    |                                         | there are no input frames are available. When     |\n    |                                         | this is unset, silence will be posted to the      |\n    |                                         | processing callback.                              |\n    +-----------------------------------------+---------------------------------------------------+\n    | MA_NODE_FLAG_DIFFERENT_PROCESSING_RATES | Used to tell miniaudio that input and output      |\n    |                                         | frames are processed at different rates. You      |\n    |                                         | should set this for any nodes that perform        |\n    |                                         | resampling.                                       |\n    +-----------------------------------------+---------------------------------------------------+\n    | MA_NODE_FLAG_SILENT_OUTPUT              | Used to tell miniaudio that a node produces only  |\n    |                                         | silent output. This is useful for nodes where you |\n    |                                         | don't want the output to contribute to the final  |\n    |                                         | mix. An example might be if you want split your   |\n    |                                         | stream and have one branch be output to a file.   |\n    |                                         | When using this flag, you should avoid writing to |\n    |                                         | the output buffer of the node's processing        |\n    |                                         | callback because miniaudio will ignore it anyway. |\n    +-----------------------------------------+---------------------------------------------------+\n\n\nIf you need to make a copy of an audio stream for effect processing you can use a splitter node\ncalled `ma_splitter_node`. This takes has 1 input bus and splits the stream into 2 output buses.\nYou can use it like this:\n\n    ```c\n    ma_splitter_node_config splitterNodeConfig = ma_splitter_node_config_init(channels);\n\n    ma_splitter_node splitterNode;\n    result = ma_splitter_node_init(&nodeGraph, &splitterNodeConfig, NULL, &splitterNode);\n    if (result != MA_SUCCESS) {\n        // Failed to create node.\n    }\n\n    // Attach your output buses to two different input buses (can be on two different nodes).\n    ma_node_attach_output_bus(&splitterNode, 0, ma_node_graph_get_endpoint(&nodeGraph), 0); // Attach directly to the endpoint.\n    ma_node_attach_output_bus(&splitterNode, 1, &myEffectNode,                          0); // Attach to input bus 0 of some effect node.\n    ```\n\nThe volume of an output bus can be configured on a per-bus basis:\n\n    ```c\n    ma_node_set_output_bus_volume(&splitterNode, 0, 0.5f);\n    ma_node_set_output_bus_volume(&splitterNode, 1, 0.5f);\n    ```\n\nIn the code above we're using the splitter node from before and changing the volume of each of the\ncopied streams.\n\nYou can start and stop a node with the following:\n\n    ```c\n    ma_node_set_state(&splitterNode, ma_node_state_started);    // The default state.\n    ma_node_set_state(&splitterNode, ma_node_state_stopped);\n    ```\n\nBy default the node is in a started state, but since it won't be connected to anything won't\nactually be invoked by the node graph until it's connected. When you stop a node, data will not be\nread from any of it's input connections. You can use this property to stop a group of sounds\natomically.\n\nYou can configure the initial state of a node in it's config:\n\n    ```c\n    nodeConfig.initialState = ma_node_state_stopped;\n    ```\n\nNote that for the stock specialized nodes, all of their configs will have a `nodeConfig` member\nwhich is the config to use with the base node. This is where the initial state can be configured\nfor specialized nodes:\n\n    ```c\n    dataSourceNodeConfig.nodeConfig.initialState = ma_node_state_stopped;\n    ```\n\nWhen using a specialized node like `ma_data_source_node` or `ma_splitter_node`, be sure to not\nmodify the `vtable` member of the `nodeConfig` object.\n\n\n7.1. Timing\n-----------\nThe node graph supports starting and stopping nodes at scheduled times. This is especially useful\nfor data source nodes where you want to get the node set up, but only start playback at a specific\ntime. There are two clocks: local and global.\n\nA local clock is per-node, whereas the global clock is per graph. Scheduling starts and stops can\nonly be done based on the global clock because the local clock will not be running while the node\nis stopped. The global clocks advances whenever `ma_node_graph_read_pcm_frames()` is called. On the\nother hand, the local clock only advances when the node's processing callback is fired, and is\nadvanced based on the output frame count.\n\nTo retrieve the global time, use `ma_node_graph_get_time()`. The global time can be set with\n`ma_node_graph_set_time()` which might be useful if you want to do seeking on a global timeline.\nGetting and setting the local time is similar. Use `ma_node_get_time()` to retrieve the local time,\nand `ma_node_set_time()` to set the local time. The global and local times will be advanced by the\naudio thread, so care should be taken to avoid data races. Ideally you should avoid calling these\noutside of the node processing callbacks which are always run on the audio thread.\n\nThere is basic support for scheduling the starting and stopping of nodes. You can only schedule one\nstart and one stop at a time. This is mainly intended for putting nodes into a started or stopped\nstate in a frame-exact manner. Without this mechanism, starting and stopping of a node is limited\nto the resolution of a call to `ma_node_graph_read_pcm_frames()` which would typically be in blocks\nof several milliseconds. The following APIs can be used for scheduling node states:\n\n    ```c\n    ma_node_set_state_time()\n    ma_node_get_state_time()\n    ```\n\nThe time is absolute and must be based on the global clock. An example is below:\n\n    ```c\n    ma_node_set_state_time(&myNode, ma_node_state_started, sampleRate*1);   // Delay starting to 1 second.\n    ma_node_set_state_time(&myNode, ma_node_state_stopped, sampleRate*5);   // Delay stopping to 5 seconds.\n    ```\n\nAn example for changing the state using a relative time.\n\n    ```c\n    ma_node_set_state_time(&myNode, ma_node_state_started, sampleRate*1 + ma_node_graph_get_time(&myNodeGraph));\n    ma_node_set_state_time(&myNode, ma_node_state_stopped, sampleRate*5 + ma_node_graph_get_time(&myNodeGraph));\n    ```\n\nNote that due to the nature of multi-threading the times may not be 100% exact. If this is an\nissue, consider scheduling state changes from within a processing callback. An idea might be to\nhave some kind of passthrough trigger node that is used specifically for tracking time and handling\nevents.\n\n\n\n7.2. Thread Safety and Locking\n------------------------------\nWhen processing audio, it's ideal not to have any kind of locking in the audio thread. Since it's\nexpected that `ma_node_graph_read_pcm_frames()` would be run on the audio thread, it does so\nwithout the use of any locks. This section discusses the implementation used by miniaudio and goes\nover some of the compromises employed by miniaudio to achieve this goal. Note that the current\nimplementation may not be ideal - feedback and critiques are most welcome.\n\nThe node graph API is not *entirely* lock-free. Only `ma_node_graph_read_pcm_frames()` is expected\nto be lock-free. Attachment, detachment and uninitialization of nodes use locks to simplify the\nimplementation, but are crafted in a way such that such locking is not required when reading audio\ndata from the graph. Locking in these areas are achieved by means of spinlocks.\n\nThe main complication with keeping `ma_node_graph_read_pcm_frames()` lock-free stems from the fact\nthat a node can be uninitialized, and it's memory potentially freed, while in the middle of being\nprocessed on the audio thread. There are times when the audio thread will be referencing a node,\nwhich means the uninitialization process of a node needs to make sure it delays returning until the\naudio thread is finished so that control is not handed back to the caller thereby giving them a\nchance to free the node's memory.\n\nWhen the audio thread is processing a node, it does so by reading from each of the output buses of\nthe node. In order for a node to process data for one of it's output buses, it needs to read from\neach of it's input buses, and so on an so forth. It follows that once all output buses of a node\nare detached, the node as a whole will be disconnected and no further processing will occur unless\nit's output buses are reattached, which won't be happening when the node is being uninitialized.\nBy having `ma_node_detach_output_bus()` wait until the audio thread is finished with it, we can\nsimplify a few things, at the expense of making `ma_node_detach_output_bus()` a bit slower. By\ndoing this, the implementation of `ma_node_uninit()` becomes trivial - just detach all output\nnodes, followed by each of the attachments to each of it's input nodes, and then do any final clean\nup.\n\nWith the above design, the worst-case scenario is `ma_node_detach_output_bus()` taking as long as\nit takes to process the output bus being detached. This will happen if it's called at just the\nwrong moment where the audio thread has just iterated it and has just started processing. The\ncaller of `ma_node_detach_output_bus()` will stall until the audio thread is finished, which\nincludes the cost of recursively processing it's inputs. This is the biggest compromise made with\nthe approach taken by miniaudio for it's lock-free processing system. The cost of detaching nodes\nearlier in the pipeline (data sources, for example) will be cheaper than the cost of detaching\nhigher level nodes, such as some kind of final post-processing endpoint. If you need to do mass\ndetachments, detach starting from the lowest level nodes and work your way towards the final\nendpoint node (but don't try detaching the node graph's endpoint). If the audio thread is not\nrunning, detachment will be fast and detachment in any order will be the same. The reason nodes\nneed to wait for their input attachments to complete is due to the potential for desyncs between\ndata sources. If the node was to terminate processing mid way through processing it's inputs,\nthere's a chance that some of the underlying data sources will have been read, but then others not.\nThat will then result in a potential desynchronization when detaching and reattaching higher-level\nnodes. A possible solution to this is to have an option when detaching to terminate processing\nbefore processing all input attachments which should be fairly simple.\n\nAnother compromise, albeit less significant, is locking when attaching and detaching nodes. This\nlocking is achieved by means of a spinlock in order to reduce memory overhead. A lock is present\nfor each input bus and output bus. When an output bus is connected to an input bus, both the output\nbus and input bus is locked. This locking is specifically for attaching and detaching across\ndifferent threads and does not affect `ma_node_graph_read_pcm_frames()` in any way. The locking and\nunlocking is mostly self-explanatory, but a slightly less intuitive aspect comes into it when\nconsidering that iterating over attachments must not break as a result of attaching or detaching a\nnode while iteration is occurring.\n\nAttaching and detaching are both quite simple. When an output bus of a node is attached to an input\nbus of another node, it's added to a linked list. Basically, an input bus is a linked list, where\neach item in the list is and output bus. We have some intentional (and convenient) restrictions on\nwhat can done with the linked list in order to simplify the implementation. First of all, whenever\nsomething needs to iterate over the list, it must do so in a forward direction. Backwards iteration\nis not supported. Also, items can only be added to the start of the list.\n\nThe linked list is a doubly-linked list where each item in the list (an output bus) holds a pointer\nto the next item in the list, and another to the previous item. A pointer to the previous item is\nonly required for fast detachment of the node - it is never used in iteration. This is an\nimportant property because it means from the perspective of iteration, attaching and detaching of\nan item can be done with a single atomic assignment. This is exploited by both the attachment and\ndetachment process. When attaching the node, the first thing that is done is the setting of the\nlocal \"next\" and \"previous\" pointers of the node. After that, the item is \"attached\" to the list\nby simply performing an atomic exchange with the head pointer. After that, the node is \"attached\"\nto the list from the perspective of iteration. Even though the \"previous\" pointer of the next item\nhasn't yet been set, from the perspective of iteration it's been attached because iteration will\nonly be happening in a forward direction which means the \"previous\" pointer won't actually ever get\nused. The same general process applies to detachment. See `ma_node_attach_output_bus()` and\n`ma_node_detach_output_bus()` for the implementation of this mechanism.\n\n\n\n8. Decoding\n===========\nThe `ma_decoder` API is used for reading audio files. Decoders are completely decoupled from\ndevices and can be used independently. Built-in support is included for the following formats:\n\n    +---------+\n    | Format  |\n    +---------+\n    | WAV     |\n    | MP3     |\n    | FLAC    |\n    +---------+\n\nYou can disable the built-in decoders by specifying one or more of the following options before the\nminiaudio implementation:\n\n    ```c\n    #define MA_NO_WAV\n    #define MA_NO_MP3\n    #define MA_NO_FLAC\n    ```\n\nminiaudio supports the ability to plug in custom decoders. See the section below for details on how\nto use custom decoders.\n\nA decoder can be initialized from a file with `ma_decoder_init_file()`, a block of memory with\n`ma_decoder_init_memory()`, or from data delivered via callbacks with `ma_decoder_init()`. Here is\nan example for loading a decoder from a file:\n\n    ```c\n    ma_decoder decoder;\n    ma_result result = ma_decoder_init_file(\"MySong.mp3\", NULL, &decoder);\n    if (result != MA_SUCCESS) {\n        return false;   // An error occurred.\n    }\n\n    ...\n\n    ma_decoder_uninit(&decoder);\n    ```\n\nWhen initializing a decoder, you can optionally pass in a pointer to a `ma_decoder_config` object\n(the `NULL` argument in the example above) which allows you to configure the output format, channel\ncount, sample rate and channel map:\n\n    ```c\n    ma_decoder_config config = ma_decoder_config_init(ma_format_f32, 2, 48000);\n    ```\n\nWhen passing in `NULL` for decoder config in `ma_decoder_init*()`, the output format will be the\nsame as that defined by the decoding backend.\n\nData is read from the decoder as PCM frames. This will output the number of PCM frames actually\nread. If this is less than the requested number of PCM frames it means you've reached the end. The\nreturn value will be `MA_AT_END` if no samples have been read and the end has been reached.\n\n    ```c\n    ma_result result = ma_decoder_read_pcm_frames(pDecoder, pFrames, framesToRead, &framesRead);\n    if (framesRead < framesToRead) {\n        // Reached the end.\n    }\n    ```\n\nYou can also seek to a specific frame like so:\n\n    ```c\n    ma_result result = ma_decoder_seek_to_pcm_frame(pDecoder, targetFrame);\n    if (result != MA_SUCCESS) {\n        return false;   // An error occurred.\n    }\n    ```\n\nIf you want to loop back to the start, you can simply seek back to the first PCM frame:\n\n    ```c\n    ma_decoder_seek_to_pcm_frame(pDecoder, 0);\n    ```\n\nWhen loading a decoder, miniaudio uses a trial and error technique to find the appropriate decoding\nbackend. This can be unnecessarily inefficient if the type is already known. In this case you can\nuse `encodingFormat` variable in the device config to specify a specific encoding format you want\nto decode:\n\n    ```c\n    decoderConfig.encodingFormat = ma_encoding_format_wav;\n    ```\n\nSee the `ma_encoding_format` enum for possible encoding formats.\n\nThe `ma_decoder_init_file()` API will try using the file extension to determine which decoding\nbackend to prefer.\n\n\n8.1. Custom Decoders\n--------------------\nIt's possible to implement a custom decoder and plug it into miniaudio. This is extremely useful\nwhen you want to use the `ma_decoder` API, but need to support an encoding format that's not one of\nthe stock formats supported by miniaudio. This can be put to particularly good use when using the\n`ma_engine` and/or `ma_resource_manager` APIs because they use `ma_decoder` internally. If, for\nexample, you wanted to support Opus, you can do so with a custom decoder (there if a reference\nOpus decoder in the \"extras\" folder of the miniaudio repository which uses libopus + libopusfile).\n\nA custom decoder must implement a data source. A vtable called `ma_decoding_backend_vtable` needs\nto be implemented which is then passed into the decoder config:\n\n    ```c\n    ma_decoding_backend_vtable* pCustomBackendVTables[] =\n    {\n        &g_ma_decoding_backend_vtable_libvorbis,\n        &g_ma_decoding_backend_vtable_libopus\n    };\n\n    ...\n\n    decoderConfig = ma_decoder_config_init_default();\n    decoderConfig.pCustomBackendUserData = NULL;\n    decoderConfig.ppCustomBackendVTables = pCustomBackendVTables;\n    decoderConfig.customBackendCount     = sizeof(pCustomBackendVTables) / sizeof(pCustomBackendVTables[0]);\n    ```\n\nThe `ma_decoding_backend_vtable` vtable has the following functions:\n\n    ```\n    onInit\n    onInitFile\n    onInitFileW\n    onInitMemory\n    onUninit\n    ```\n\nThere are only two functions that must be implemented - `onInit` and `onUninit`. The other\nfunctions can be implemented for a small optimization for loading from a file path or memory. If\nthese are not specified, miniaudio will deal with it for you via a generic implementation.\n\nWhen you initialize a custom data source (by implementing the `onInit` function in the vtable) you\nwill need to output a pointer to a `ma_data_source` which implements your custom decoder. See the\nsection about data sources for details on how to implement this. Alternatively, see the\n\"custom_decoders\" example in the miniaudio repository.\n\nThe `onInit` function takes a pointer to some callbacks for the purpose of reading raw audio data\nfrom some arbitrary source. You'll use these functions to read from the raw data and perform the\ndecoding. When you call them, you will pass in the `pReadSeekTellUserData` pointer to the relevant\nparameter.\n\nThe `pConfig` parameter in `onInit` can be used to configure the backend if appropriate. It's only\nused as a hint and can be ignored. However, if any of the properties are relevant to your decoder,\nan optimal implementation will handle the relevant properties appropriately.\n\nIf memory allocation is required, it should be done so via the specified allocation callbacks if\npossible (the `pAllocationCallbacks` parameter).\n\nIf an error occurs when initializing the decoder, you should leave `ppBackend` unset, or set to\nNULL, and make sure everything is cleaned up appropriately and an appropriate result code returned.\nWhen multiple custom backends are specified, miniaudio will cycle through the vtables in the order\nthey're listed in the array that's passed into the decoder config so it's important that your\ninitialization routine is clean.\n\nWhen a decoder is uninitialized, the `onUninit` callback will be fired which will give you an\nopportunity to clean up and internal data.\n\n\n\n9. Encoding\n===========\nThe `ma_encoding` API is used for writing audio files. The only supported output format is WAV.\nThis can be disabled by specifying the following option before the implementation of miniaudio:\n\n    ```c\n    #define MA_NO_WAV\n    ```\n\nAn encoder can be initialized to write to a file with `ma_encoder_init_file()` or from data\ndelivered via callbacks with `ma_encoder_init()`. Below is an example for initializing an encoder\nto output to a file.\n\n    ```c\n    ma_encoder_config config = ma_encoder_config_init(ma_encoding_format_wav, FORMAT, CHANNELS, SAMPLE_RATE);\n    ma_encoder encoder;\n    ma_result result = ma_encoder_init_file(\"my_file.wav\", &config, &encoder);\n    if (result != MA_SUCCESS) {\n        // Error\n    }\n\n    ...\n\n    ma_encoder_uninit(&encoder);\n    ```\n\nWhen initializing an encoder you must specify a config which is initialized with\n`ma_encoder_config_init()`. Here you must specify the file type, the output sample format, output\nchannel count and output sample rate. The following file types are supported:\n\n    +------------------------+-------------+\n    | Enum                   | Description |\n    +------------------------+-------------+\n    | ma_encoding_format_wav | WAV         |\n    +------------------------+-------------+\n\nIf the format, channel count or sample rate is not supported by the output file type an error will\nbe returned. The encoder will not perform data conversion so you will need to convert it before\noutputting any audio data. To output audio data, use `ma_encoder_write_pcm_frames()`, like in the\nexample below:\n\n    ```c\n    ma_uint64 framesWritten;\n    result = ma_encoder_write_pcm_frames(&encoder, pPCMFramesToWrite, framesToWrite, &framesWritten);\n    if (result != MA_SUCCESS) {\n        ... handle error ...\n    }\n    ```\n\nThe `framesWritten` variable will contain the number of PCM frames that were actually written. This\nis optionally and you can pass in `NULL` if you need this.\n\nEncoders must be uninitialized with `ma_encoder_uninit()`.\n\n\n\n10. Data Conversion\n===================\nA data conversion API is included with miniaudio which supports the majority of data conversion\nrequirements. This supports conversion between sample formats, channel counts (with channel\nmapping) and sample rates.\n\n\n10.1. Sample Format Conversion\n------------------------------\nConversion between sample formats is achieved with the `ma_pcm_*_to_*()`, `ma_pcm_convert()` and\n`ma_convert_pcm_frames_format()` APIs. Use `ma_pcm_*_to_*()` to convert between two specific\nformats. Use `ma_pcm_convert()` to convert based on a `ma_format` variable. Use\n`ma_convert_pcm_frames_format()` to convert PCM frames where you want to specify the frame count\nand channel count as a variable instead of the total sample count.\n\n\n10.1.1. Dithering\n-----------------\nDithering can be set using the ditherMode parameter.\n\nThe different dithering modes include the following, in order of efficiency:\n\n    +-----------+--------------------------+\n    | Type      | Enum Token               |\n    +-----------+--------------------------+\n    | None      | ma_dither_mode_none      |\n    | Rectangle | ma_dither_mode_rectangle |\n    | Triangle  | ma_dither_mode_triangle  |\n    +-----------+--------------------------+\n\nNote that even if the dither mode is set to something other than `ma_dither_mode_none`, it will be\nignored for conversions where dithering is not needed. Dithering is available for the following\nconversions:\n\n    ```\n    s16 -> u8\n    s24 -> u8\n    s32 -> u8\n    f32 -> u8\n    s24 -> s16\n    s32 -> s16\n    f32 -> s16\n    ```\n\nNote that it is not an error to pass something other than ma_dither_mode_none for conversions where\ndither is not used. It will just be ignored.\n\n\n\n10.2. Channel Conversion\n------------------------\nChannel conversion is used for channel rearrangement and conversion from one channel count to\nanother. The `ma_channel_converter` API is used for channel conversion. Below is an example of\ninitializing a simple channel converter which converts from mono to stereo.\n\n    ```c\n    ma_channel_converter_config config = ma_channel_converter_config_init(\n        ma_format,                      // Sample format\n        1,                              // Input channels\n        NULL,                           // Input channel map\n        2,                              // Output channels\n        NULL,                           // Output channel map\n        ma_channel_mix_mode_default);   // The mixing algorithm to use when combining channels.\n\n    result = ma_channel_converter_init(&config, NULL, &converter);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n    ```\n\nTo perform the conversion simply call `ma_channel_converter_process_pcm_frames()` like so:\n\n    ```c\n    ma_result result = ma_channel_converter_process_pcm_frames(&converter, pFramesOut, pFramesIn, frameCount);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n    ```\n\nIt is up to the caller to ensure the output buffer is large enough to accommodate the new PCM\nframes.\n\nInput and output PCM frames are always interleaved. Deinterleaved layouts are not supported.\n\n\n10.2.1. Channel Mapping\n-----------------------\nIn addition to converting from one channel count to another, like the example above, the channel\nconverter can also be used to rearrange channels. When initializing the channel converter, you can\noptionally pass in channel maps for both the input and output frames. If the channel counts are the\nsame, and each channel map contains the same channel positions with the exception that they're in\na different order, a simple shuffling of the channels will be performed. If, however, there is not\na 1:1 mapping of channel positions, or the channel counts differ, the input channels will be mixed\nbased on a mixing mode which is specified when initializing the `ma_channel_converter_config`\nobject.\n\nWhen converting from mono to multi-channel, the mono channel is simply copied to each output\nchannel. When going the other way around, the audio of each output channel is simply averaged and\ncopied to the mono channel.\n\nIn more complicated cases blending is used. The `ma_channel_mix_mode_simple` mode will drop excess\nchannels and silence extra channels. For example, converting from 4 to 2 channels, the 3rd and 4th\nchannels will be dropped, whereas converting from 2 to 4 channels will put silence into the 3rd and\n4th channels.\n\nThe `ma_channel_mix_mode_rectangle` mode uses spacial locality based on a rectangle to compute a\nsimple distribution between input and output. Imagine sitting in the middle of a room, with\nspeakers on the walls representing channel positions. The `MA_CHANNEL_FRONT_LEFT` position can be\nthought of as being in the corner of the front and left walls.\n\nFinally, the `ma_channel_mix_mode_custom_weights` mode can be used to use custom user-defined\nweights. Custom weights can be passed in as the last parameter of\n`ma_channel_converter_config_init()`.\n\nPredefined channel maps can be retrieved with `ma_channel_map_init_standard()`. This takes a\n`ma_standard_channel_map` enum as it's first parameter, which can be one of the following:\n\n    +-----------------------------------+-----------------------------------------------------------+\n    | Name                              | Description                                               |\n    +-----------------------------------+-----------------------------------------------------------+\n    | ma_standard_channel_map_default   | Default channel map used by miniaudio. See below.         |\n    | ma_standard_channel_map_microsoft | Channel map used by Microsoft's bitfield channel maps.    |\n    | ma_standard_channel_map_alsa      | Default ALSA channel map.                                 |\n    | ma_standard_channel_map_rfc3551   | RFC 3551. Based on AIFF.                                  |\n    | ma_standard_channel_map_flac      | FLAC channel map.                                         |\n    | ma_standard_channel_map_vorbis    | Vorbis channel map.                                       |\n    | ma_standard_channel_map_sound4    | FreeBSD's sound(4).                                       |\n    | ma_standard_channel_map_sndio     | sndio channel map. http://www.sndio.org/tips.html.        |\n    | ma_standard_channel_map_webaudio  | https://webaudio.github.io/web-audio-api/#ChannelOrdering |\n    +-----------------------------------+-----------------------------------------------------------+\n\nBelow are the channel maps used by default in miniaudio (`ma_standard_channel_map_default`):\n\n    +---------------+---------------------------------+\n    | Channel Count | Mapping                         |\n    +---------------+---------------------------------+\n    | 1 (Mono)      | 0: MA_CHANNEL_MONO              |\n    +---------------+---------------------------------+\n    | 2 (Stereo)    | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT       |\n    +---------------+---------------------------------+\n    | 3             | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER      |\n    +---------------+---------------------------------+\n    | 4 (Surround)  | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER <br> |\n    |               | 3: MA_CHANNEL_BACK_CENTER       |\n    +---------------+---------------------------------+\n    | 5             | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER <br> |\n    |               | 3: MA_CHANNEL_BACK_LEFT    <br> |\n    |               | 4: MA_CHANNEL_BACK_RIGHT        |\n    +---------------+---------------------------------+\n    | 6 (5.1)       | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER <br> |\n    |               | 3: MA_CHANNEL_LFE          <br> |\n    |               | 4: MA_CHANNEL_SIDE_LEFT    <br> |\n    |               | 5: MA_CHANNEL_SIDE_RIGHT        |\n    +---------------+---------------------------------+\n    | 7             | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER <br> |\n    |               | 3: MA_CHANNEL_LFE          <br> |\n    |               | 4: MA_CHANNEL_BACK_CENTER  <br> |\n    |               | 4: MA_CHANNEL_SIDE_LEFT    <br> |\n    |               | 5: MA_CHANNEL_SIDE_RIGHT        |\n    +---------------+---------------------------------+\n    | 8 (7.1)       | 0: MA_CHANNEL_FRONT_LEFT   <br> |\n    |               | 1: MA_CHANNEL_FRONT_RIGHT  <br> |\n    |               | 2: MA_CHANNEL_FRONT_CENTER <br> |\n    |               | 3: MA_CHANNEL_LFE          <br> |\n    |               | 4: MA_CHANNEL_BACK_LEFT    <br> |\n    |               | 5: MA_CHANNEL_BACK_RIGHT   <br> |\n    |               | 6: MA_CHANNEL_SIDE_LEFT    <br> |\n    |               | 7: MA_CHANNEL_SIDE_RIGHT        |\n    +---------------+---------------------------------+\n    | Other         | All channels set to 0. This     |\n    |               | is equivalent to the same       |\n    |               | mapping as the device.          |\n    +---------------+---------------------------------+\n\n\n\n10.3. Resampling\n----------------\nResampling is achieved with the `ma_resampler` object. To create a resampler object, do something\nlike the following:\n\n    ```c\n    ma_resampler_config config = ma_resampler_config_init(\n        ma_format_s16,\n        channels,\n        sampleRateIn,\n        sampleRateOut,\n        ma_resample_algorithm_linear);\n\n    ma_resampler resampler;\n    ma_result result = ma_resampler_init(&config, &resampler);\n    if (result != MA_SUCCESS) {\n        // An error occurred...\n    }\n    ```\n\nDo the following to uninitialize the resampler:\n\n    ```c\n    ma_resampler_uninit(&resampler);\n    ```\n\nThe following example shows how data can be processed\n\n    ```c\n    ma_uint64 frameCountIn  = 1000;\n    ma_uint64 frameCountOut = 2000;\n    ma_result result = ma_resampler_process_pcm_frames(&resampler, pFramesIn, &frameCountIn, pFramesOut, &frameCountOut);\n    if (result != MA_SUCCESS) {\n        // An error occurred...\n    }\n\n    // At this point, frameCountIn contains the number of input frames that were consumed and frameCountOut contains the\n    // number of output frames written.\n    ```\n\nTo initialize the resampler you first need to set up a config (`ma_resampler_config`) with\n`ma_resampler_config_init()`. You need to specify the sample format you want to use, the number of\nchannels, the input and output sample rate, and the algorithm.\n\nThe sample format can be either `ma_format_s16` or `ma_format_f32`. If you need a different format\nyou will need to perform pre- and post-conversions yourself where necessary. Note that the format\nis the same for both input and output. The format cannot be changed after initialization.\n\nThe resampler supports multiple channels and is always interleaved (both input and output). The\nchannel count cannot be changed after initialization.\n\nThe sample rates can be anything other than zero, and are always specified in hertz. They should be\nset to something like 44100, etc. The sample rate is the only configuration property that can be\nchanged after initialization.\n\nThe miniaudio resampler has built-in support for the following algorithms:\n\n    +-----------+------------------------------+\n    | Algorithm | Enum Token                   |\n    +-----------+------------------------------+\n    | Linear    | ma_resample_algorithm_linear |\n    | Custom    | ma_resample_algorithm_custom |\n    +-----------+------------------------------+\n\nThe algorithm cannot be changed after initialization.\n\nProcessing always happens on a per PCM frame basis and always assumes interleaved input and output.\nDe-interleaved processing is not supported. To process frames, use\n`ma_resampler_process_pcm_frames()`. On input, this function takes the number of output frames you\ncan fit in the output buffer and the number of input frames contained in the input buffer. On\noutput these variables contain the number of output frames that were written to the output buffer\nand the number of input frames that were consumed in the process. You can pass in NULL for the\ninput buffer in which case it will be treated as an infinitely large buffer of zeros. The output\nbuffer can also be NULL, in which case the processing will be treated as seek.\n\nThe sample rate can be changed dynamically on the fly. You can change this with explicit sample\nrates with `ma_resampler_set_rate()` and also with a decimal ratio with\n`ma_resampler_set_rate_ratio()`. The ratio is in/out.\n\nSometimes it's useful to know exactly how many input frames will be required to output a specific\nnumber of frames. You can calculate this with `ma_resampler_get_required_input_frame_count()`.\nLikewise, it's sometimes useful to know exactly how many frames would be output given a certain\nnumber of input frames. You can do this with `ma_resampler_get_expected_output_frame_count()`.\n\nDue to the nature of how resampling works, the resampler introduces some latency. This can be\nretrieved in terms of both the input rate and the output rate with\n`ma_resampler_get_input_latency()` and `ma_resampler_get_output_latency()`.\n\n\n10.3.1. Resampling Algorithms\n-----------------------------\nThe choice of resampling algorithm depends on your situation and requirements.\n\n\n10.3.1.1. Linear Resampling\n---------------------------\nThe linear resampler is the fastest, but comes at the expense of poorer quality. There is, however,\nsome control over the quality of the linear resampler which may make it a suitable option depending\non your requirements.\n\nThe linear resampler performs low-pass filtering before or after downsampling or upsampling,\ndepending on the sample rates you're converting between. When decreasing the sample rate, the\nlow-pass filter will be applied before downsampling. When increasing the rate it will be performed\nafter upsampling. By default a fourth order low-pass filter will be applied. This can be configured\nvia the `lpfOrder` configuration variable. Setting this to 0 will disable filtering.\n\nThe low-pass filter has a cutoff frequency which defaults to half the sample rate of the lowest of\nthe input and output sample rates (Nyquist Frequency).\n\nThe API for the linear resampler is the same as the main resampler API, only it's called\n`ma_linear_resampler`.\n\n\n10.3.2. Custom Resamplers\n-------------------------\nYou can implement a custom resampler by using the `ma_resample_algorithm_custom` resampling\nalgorithm and setting a vtable in the resampler config:\n\n    ```c\n    ma_resampler_config config = ma_resampler_config_init(..., ma_resample_algorithm_custom);\n    config.pBackendVTable = &g_customResamplerVTable;\n    ```\n\nCustom resamplers are useful if the stock algorithms are not appropriate for your use case. You\nneed to implement the required functions in `ma_resampling_backend_vtable`. Note that not all\nfunctions in the vtable need to be implemented, but if it's possible to implement, they should be.\n\nYou can use the `ma_linear_resampler` object for an example on how to implement the vtable. The\n`onGetHeapSize` callback is used to calculate the size of any internal heap allocation the custom\nresampler will need to make given the supplied config. When you initialize the resampler via the\n`onInit` callback, you'll be given a pointer to a heap allocation which is where you should store\nthe heap allocated data. You should not free this data in `onUninit` because miniaudio will manage\nit for you.\n\nThe `onProcess` callback is where the actual resampling takes place. On input, `pFrameCountIn`\npoints to a variable containing the number of frames in the `pFramesIn` buffer and\n`pFrameCountOut` points to a variable containing the capacity in frames of the `pFramesOut` buffer.\nOn output, `pFrameCountIn` should be set to the number of input frames that were fully consumed,\nwhereas `pFrameCountOut` should be set to the number of frames that were written to `pFramesOut`.\n\nThe `onSetRate` callback is optional and is used for dynamically changing the sample rate. If\ndynamic rate changes are not supported, you can set this callback to NULL.\n\nThe `onGetInputLatency` and `onGetOutputLatency` functions are used for retrieving the latency in\ninput and output rates respectively. These can be NULL in which case latency calculations will be\nassumed to be NULL.\n\nThe `onGetRequiredInputFrameCount` callback is used to give miniaudio a hint as to how many input\nframes are required to be available to produce the given number of output frames. Likewise, the\n`onGetExpectedOutputFrameCount` callback is used to determine how many output frames will be\nproduced given the specified number of input frames. miniaudio will use these as a hint, but they\nare optional and can be set to NULL if you're unable to implement them.\n\n\n\n10.4. General Data Conversion\n-----------------------------\nThe `ma_data_converter` API can be used to wrap sample format conversion, channel conversion and\nresampling into one operation. This is what miniaudio uses internally to convert between the format\nrequested when the device was initialized and the format of the backend's native device. The API\nfor general data conversion is very similar to the resampling API. Create a `ma_data_converter`\nobject like this:\n\n    ```c\n    ma_data_converter_config config = ma_data_converter_config_init(\n        inputFormat,\n        outputFormat,\n        inputChannels,\n        outputChannels,\n        inputSampleRate,\n        outputSampleRate\n    );\n\n    ma_data_converter converter;\n    ma_result result = ma_data_converter_init(&config, NULL, &converter);\n    if (result != MA_SUCCESS) {\n        // An error occurred...\n    }\n    ```\n\nIn the example above we use `ma_data_converter_config_init()` to initialize the config, however\nthere's many more properties that can be configured, such as channel maps and resampling quality.\nSomething like the following may be more suitable depending on your requirements:\n\n    ```c\n    ma_data_converter_config config = ma_data_converter_config_init_default();\n    config.formatIn = inputFormat;\n    config.formatOut = outputFormat;\n    config.channelsIn = inputChannels;\n    config.channelsOut = outputChannels;\n    config.sampleRateIn = inputSampleRate;\n    config.sampleRateOut = outputSampleRate;\n    ma_channel_map_init_standard(ma_standard_channel_map_flac, config.channelMapIn, sizeof(config.channelMapIn)/sizeof(config.channelMapIn[0]), config.channelCountIn);\n    config.resampling.linear.lpfOrder = MA_MAX_FILTER_ORDER;\n    ```\n\nDo the following to uninitialize the data converter:\n\n    ```c\n    ma_data_converter_uninit(&converter, NULL);\n    ```\n\nThe following example shows how data can be processed\n\n    ```c\n    ma_uint64 frameCountIn  = 1000;\n    ma_uint64 frameCountOut = 2000;\n    ma_result result = ma_data_converter_process_pcm_frames(&converter, pFramesIn, &frameCountIn, pFramesOut, &frameCountOut);\n    if (result != MA_SUCCESS) {\n        // An error occurred...\n    }\n\n    // At this point, frameCountIn contains the number of input frames that were consumed and frameCountOut contains the number\n    // of output frames written.\n    ```\n\nThe data converter supports multiple channels and is always interleaved (both input and output).\nThe channel count cannot be changed after initialization.\n\nSample rates can be anything other than zero, and are always specified in hertz. They should be set\nto something like 44100, etc. The sample rate is the only configuration property that can be\nchanged after initialization, but only if the `resampling.allowDynamicSampleRate` member of\n`ma_data_converter_config` is set to `MA_TRUE`. To change the sample rate, use\n`ma_data_converter_set_rate()` or `ma_data_converter_set_rate_ratio()`. The ratio must be in/out.\nThe resampling algorithm cannot be changed after initialization.\n\nProcessing always happens on a per PCM frame basis and always assumes interleaved input and output.\nDe-interleaved processing is not supported. To process frames, use\n`ma_data_converter_process_pcm_frames()`. On input, this function takes the number of output frames\nyou can fit in the output buffer and the number of input frames contained in the input buffer. On\noutput these variables contain the number of output frames that were written to the output buffer\nand the number of input frames that were consumed in the process. You can pass in NULL for the\ninput buffer in which case it will be treated as an infinitely large\nbuffer of zeros. The output buffer can also be NULL, in which case the processing will be treated\nas seek.\n\nSometimes it's useful to know exactly how many input frames will be required to output a specific\nnumber of frames. You can calculate this with `ma_data_converter_get_required_input_frame_count()`.\nLikewise, it's sometimes useful to know exactly how many frames would be output given a certain\nnumber of input frames. You can do this with `ma_data_converter_get_expected_output_frame_count()`.\n\nDue to the nature of how resampling works, the data converter introduces some latency if resampling\nis required. This can be retrieved in terms of both the input rate and the output rate with\n`ma_data_converter_get_input_latency()` and `ma_data_converter_get_output_latency()`.\n\n\n\n11. Filtering\n=============\n\n11.1. Biquad Filtering\n----------------------\nBiquad filtering is achieved with the `ma_biquad` API. Example:\n\n    ```c\n    ma_biquad_config config = ma_biquad_config_init(ma_format_f32, channels, b0, b1, b2, a0, a1, a2);\n    ma_result result = ma_biquad_init(&config, &biquad);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    ...\n\n    ma_biquad_process_pcm_frames(&biquad, pFramesOut, pFramesIn, frameCount);\n    ```\n\nBiquad filtering is implemented using transposed direct form 2. The numerator coefficients are b0,\nb1 and b2, and the denominator coefficients are a0, a1 and a2. The a0 coefficient is required and\ncoefficients must not be pre-normalized.\n\nSupported formats are `ma_format_s16` and `ma_format_f32`. If you need to use a different format\nyou need to convert it yourself beforehand. When using `ma_format_s16` the biquad filter will use\nfixed point arithmetic. When using `ma_format_f32`, floating point arithmetic will be used.\n\nInput and output frames are always interleaved.\n\nFiltering can be applied in-place by passing in the same pointer for both the input and output\nbuffers, like so:\n\n    ```c\n    ma_biquad_process_pcm_frames(&biquad, pMyData, pMyData, frameCount);\n    ```\n\nIf you need to change the values of the coefficients, but maintain the values in the registers you\ncan do so with `ma_biquad_reinit()`. This is useful if you need to change the properties of the\nfilter while keeping the values of registers valid to avoid glitching. Do not use\n`ma_biquad_init()` for this as it will do a full initialization which involves clearing the\nregisters to 0. Note that changing the format or channel count after initialization is invalid and\nwill result in an error.\n\n\n11.2. Low-Pass Filtering\n------------------------\nLow-pass filtering is achieved with the following APIs:\n\n    +---------+------------------------------------------+\n    | API     | Description                              |\n    +---------+------------------------------------------+\n    | ma_lpf1 | First order low-pass filter              |\n    | ma_lpf2 | Second order low-pass filter             |\n    | ma_lpf  | High order low-pass filter (Butterworth) |\n    +---------+------------------------------------------+\n\nLow-pass filter example:\n\n    ```c\n    ma_lpf_config config = ma_lpf_config_init(ma_format_f32, channels, sampleRate, cutoffFrequency, order);\n    ma_result result = ma_lpf_init(&config, &lpf);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    ...\n\n    ma_lpf_process_pcm_frames(&lpf, pFramesOut, pFramesIn, frameCount);\n    ```\n\nSupported formats are `ma_format_s16` and` ma_format_f32`. If you need to use a different format\nyou need to convert it yourself beforehand. Input and output frames are always interleaved.\n\nFiltering can be applied in-place by passing in the same pointer for both the input and output\nbuffers, like so:\n\n    ```c\n    ma_lpf_process_pcm_frames(&lpf, pMyData, pMyData, frameCount);\n    ```\n\nThe maximum filter order is limited to `MA_MAX_FILTER_ORDER` which is set to 8. If you need more,\nyou can chain first and second order filters together.\n\n    ```c\n    for (iFilter = 0; iFilter < filterCount; iFilter += 1) {\n        ma_lpf2_process_pcm_frames(&lpf2[iFilter], pMyData, pMyData, frameCount);\n    }\n    ```\n\nIf you need to change the configuration of the filter, but need to maintain the state of internal\nregisters you can do so with `ma_lpf_reinit()`. This may be useful if you need to change the sample\nrate and/or cutoff frequency dynamically while maintaining smooth transitions. Note that changing the\nformat or channel count after initialization is invalid and will result in an error.\n\nThe `ma_lpf` object supports a configurable order, but if you only need a first order filter you\nmay want to consider using `ma_lpf1`. Likewise, if you only need a second order filter you can use\n`ma_lpf2`. The advantage of this is that they're lighter weight and a bit more efficient.\n\nIf an even filter order is specified, a series of second order filters will be processed in a\nchain. If an odd filter order is specified, a first order filter will be applied, followed by a\nseries of second order filters in a chain.\n\n\n11.3. High-Pass Filtering\n-------------------------\nHigh-pass filtering is achieved with the following APIs:\n\n    +---------+-------------------------------------------+\n    | API     | Description                               |\n    +---------+-------------------------------------------+\n    | ma_hpf1 | First order high-pass filter              |\n    | ma_hpf2 | Second order high-pass filter             |\n    | ma_hpf  | High order high-pass filter (Butterworth) |\n    +---------+-------------------------------------------+\n\nHigh-pass filters work exactly the same as low-pass filters, only the APIs are called `ma_hpf1`,\n`ma_hpf2` and `ma_hpf`. See example code for low-pass filters for example usage.\n\n\n11.4. Band-Pass Filtering\n-------------------------\nBand-pass filtering is achieved with the following APIs:\n\n    +---------+-------------------------------+\n    | API     | Description                   |\n    +---------+-------------------------------+\n    | ma_bpf2 | Second order band-pass filter |\n    | ma_bpf  | High order band-pass filter   |\n    +---------+-------------------------------+\n\nBand-pass filters work exactly the same as low-pass filters, only the APIs are called `ma_bpf2` and\n`ma_hpf`. See example code for low-pass filters for example usage. Note that the order for\nband-pass filters must be an even number which means there is no first order band-pass filter,\nunlike low-pass and high-pass filters.\n\n\n11.5. Notch Filtering\n---------------------\nNotch filtering is achieved with the following APIs:\n\n    +-----------+------------------------------------------+\n    | API       | Description                              |\n    +-----------+------------------------------------------+\n    | ma_notch2 | Second order notching filter             |\n    +-----------+------------------------------------------+\n\n\n11.6. Peaking EQ Filtering\n-------------------------\nPeaking filtering is achieved with the following APIs:\n\n    +----------+------------------------------------------+\n    | API      | Description                              |\n    +----------+------------------------------------------+\n    | ma_peak2 | Second order peaking filter              |\n    +----------+------------------------------------------+\n\n\n11.7. Low Shelf Filtering\n-------------------------\nLow shelf filtering is achieved with the following APIs:\n\n    +-------------+------------------------------------------+\n    | API         | Description                              |\n    +-------------+------------------------------------------+\n    | ma_loshelf2 | Second order low shelf filter            |\n    +-------------+------------------------------------------+\n\nWhere a high-pass filter is used to eliminate lower frequencies, a low shelf filter can be used to\njust turn them down rather than eliminate them entirely.\n\n\n11.8. High Shelf Filtering\n--------------------------\nHigh shelf filtering is achieved with the following APIs:\n\n    +-------------+------------------------------------------+\n    | API         | Description                              |\n    +-------------+------------------------------------------+\n    | ma_hishelf2 | Second order high shelf filter           |\n    +-------------+------------------------------------------+\n\nThe high shelf filter has the same API as the low shelf filter, only you would use `ma_hishelf`\ninstead of `ma_loshelf`. Where a low shelf filter is used to adjust the volume of low frequencies,\nthe high shelf filter does the same thing for high frequencies.\n\n\n\n\n12. Waveform and Noise Generation\n=================================\n\n12.1. Waveforms\n---------------\nminiaudio supports generation of sine, square, triangle and sawtooth waveforms. This is achieved\nwith the `ma_waveform` API. Example:\n\n    ```c\n    ma_waveform_config config = ma_waveform_config_init(\n        FORMAT,\n        CHANNELS,\n        SAMPLE_RATE,\n        ma_waveform_type_sine,\n        amplitude,\n        frequency);\n\n    ma_waveform waveform;\n    ma_result result = ma_waveform_init(&config, &waveform);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    ...\n\n    ma_waveform_read_pcm_frames(&waveform, pOutput, frameCount);\n    ```\n\nThe amplitude, frequency, type, and sample rate can be changed dynamically with\n`ma_waveform_set_amplitude()`, `ma_waveform_set_frequency()`, `ma_waveform_set_type()`, and\n`ma_waveform_set_sample_rate()` respectively.\n\nYou can invert the waveform by setting the amplitude to a negative value. You can use this to\ncontrol whether or not a sawtooth has a positive or negative ramp, for example.\n\nBelow are the supported waveform types:\n\n    +---------------------------+\n    | Enum Name                 |\n    +---------------------------+\n    | ma_waveform_type_sine     |\n    | ma_waveform_type_square   |\n    | ma_waveform_type_triangle |\n    | ma_waveform_type_sawtooth |\n    +---------------------------+\n\n\n\n12.2. Noise\n-----------\nminiaudio supports generation of white, pink and Brownian noise via the `ma_noise` API. Example:\n\n    ```c\n    ma_noise_config config = ma_noise_config_init(\n        FORMAT,\n        CHANNELS,\n        ma_noise_type_white,\n        SEED,\n        amplitude);\n\n    ma_noise noise;\n    ma_result result = ma_noise_init(&config, &noise);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    ...\n\n    ma_noise_read_pcm_frames(&noise, pOutput, frameCount);\n    ```\n\nThe noise API uses simple LCG random number generation. It supports a custom seed which is useful\nfor things like automated testing requiring reproducibility. Setting the seed to zero will default\nto `MA_DEFAULT_LCG_SEED`.\n\nThe amplitude and seed can be changed dynamically with `ma_noise_set_amplitude()` and\n`ma_noise_set_seed()` respectively.\n\nBy default, the noise API will use different values for different channels. So, for example, the\nleft side in a stereo stream will be different to the right side. To instead have each channel use\nthe same random value, set the `duplicateChannels` member of the noise config to true, like so:\n\n    ```c\n    config.duplicateChannels = MA_TRUE;\n    ```\n\nBelow are the supported noise types.\n\n    +------------------------+\n    | Enum Name              |\n    +------------------------+\n    | ma_noise_type_white    |\n    | ma_noise_type_pink     |\n    | ma_noise_type_brownian |\n    +------------------------+\n\n\n\n13. Audio Buffers\n=================\nminiaudio supports reading from a buffer of raw audio data via the `ma_audio_buffer` API. This can\nread from memory that's managed by the application, but can also handle the memory management for\nyou internally. Memory management is flexible and should support most use cases.\n\nAudio buffers are initialized using the standard configuration system used everywhere in miniaudio:\n\n    ```c\n    ma_audio_buffer_config config = ma_audio_buffer_config_init(\n        format,\n        channels,\n        sizeInFrames,\n        pExistingData,\n        &allocationCallbacks);\n\n    ma_audio_buffer buffer;\n    result = ma_audio_buffer_init(&config, &buffer);\n    if (result != MA_SUCCESS) {\n        // Error.\n    }\n\n    ...\n\n    ma_audio_buffer_uninit(&buffer);\n    ```\n\nIn the example above, the memory pointed to by `pExistingData` will *not* be copied and is how an\napplication can do self-managed memory allocation. If you would rather make a copy of the data, use\n`ma_audio_buffer_init_copy()`. To uninitialize the buffer, use `ma_audio_buffer_uninit()`.\n\nSometimes it can be convenient to allocate the memory for the `ma_audio_buffer` structure and the\nraw audio data in a contiguous block of memory. That is, the raw audio data will be located\nimmediately after the `ma_audio_buffer` structure. To do this, use\n`ma_audio_buffer_alloc_and_init()`:\n\n    ```c\n    ma_audio_buffer_config config = ma_audio_buffer_config_init(\n        format,\n        channels,\n        sizeInFrames,\n        pExistingData,\n        &allocationCallbacks);\n\n    ma_audio_buffer* pBuffer\n    result = ma_audio_buffer_alloc_and_init(&config, &pBuffer);\n    if (result != MA_SUCCESS) {\n        // Error\n    }\n\n    ...\n\n    ma_audio_buffer_uninit_and_free(&buffer);\n    ```\n\nIf you initialize the buffer with `ma_audio_buffer_alloc_and_init()` you should uninitialize it\nwith `ma_audio_buffer_uninit_and_free()`. In the example above, the memory pointed to by\n`pExistingData` will be copied into the buffer, which is contrary to the behavior of\n`ma_audio_buffer_init()`.\n\nAn audio buffer has a playback cursor just like a decoder. As you read frames from the buffer, the\ncursor moves forward. The last parameter (`loop`) can be used to determine if the buffer should\nloop. The return value is the number of frames actually read. If this is less than the number of\nframes requested it means the end has been reached. This should never happen if the `loop`\nparameter is set to true. If you want to manually loop back to the start, you can do so with with\n`ma_audio_buffer_seek_to_pcm_frame(pAudioBuffer, 0)`. Below is an example for reading data from an\naudio buffer.\n\n    ```c\n    ma_uint64 framesRead = ma_audio_buffer_read_pcm_frames(pAudioBuffer, pFramesOut, desiredFrameCount, isLooping);\n    if (framesRead < desiredFrameCount) {\n        // If not looping, this means the end has been reached. This should never happen in looping mode with valid input.\n    }\n    ```\n\nSometimes you may want to avoid the cost of data movement between the internal buffer and the\noutput buffer. Instead you can use memory mapping to retrieve a pointer to a segment of data:\n\n    ```c\n    void* pMappedFrames;\n    ma_uint64 frameCount = frameCountToTryMapping;\n    ma_result result = ma_audio_buffer_map(pAudioBuffer, &pMappedFrames, &frameCount);\n    if (result == MA_SUCCESS) {\n        // Map was successful. The value in frameCount will be how many frames were _actually_ mapped, which may be\n        // less due to the end of the buffer being reached.\n        ma_copy_pcm_frames(pFramesOut, pMappedFrames, frameCount, pAudioBuffer->format, pAudioBuffer->channels);\n\n        // You must unmap the buffer.\n        ma_audio_buffer_unmap(pAudioBuffer, frameCount);\n    }\n    ```\n\nWhen you use memory mapping, the read cursor is increment by the frame count passed in to\n`ma_audio_buffer_unmap()`. If you decide not to process every frame you can pass in a value smaller\nthan the value returned by `ma_audio_buffer_map()`. The disadvantage to using memory mapping is\nthat it does not handle looping for you. You can determine if the buffer is at the end for the\npurpose of looping with `ma_audio_buffer_at_end()` or by inspecting the return value of\n`ma_audio_buffer_unmap()` and checking if it equals `MA_AT_END`. You should not treat `MA_AT_END`\nas an error when returned by `ma_audio_buffer_unmap()`.\n\n\n\n14. Ring Buffers\n================\nminiaudio supports lock free (single producer, single consumer) ring buffers which are exposed via\nthe `ma_rb` and `ma_pcm_rb` APIs. The `ma_rb` API operates on bytes, whereas the `ma_pcm_rb`\noperates on PCM frames. They are otherwise identical as `ma_pcm_rb` is just a wrapper around\n`ma_rb`.\n\nUnlike most other APIs in miniaudio, ring buffers support both interleaved and deinterleaved\nstreams. The caller can also allocate their own backing memory for the ring buffer to use\ninternally for added flexibility. Otherwise the ring buffer will manage it's internal memory for\nyou.\n\nThe examples below use the PCM frame variant of the ring buffer since that's most likely the one\nyou will want to use. To initialize a ring buffer, do something like the following:\n\n    ```c\n    ma_pcm_rb rb;\n    ma_result result = ma_pcm_rb_init(FORMAT, CHANNELS, BUFFER_SIZE_IN_FRAMES, NULL, NULL, &rb);\n    if (result != MA_SUCCESS) {\n        // Error\n    }\n    ```\n\nThe `ma_pcm_rb_init()` function takes the sample format and channel count as parameters because\nit's the PCM variant of the ring buffer API. For the regular ring buffer that operates on bytes you\nwould call `ma_rb_init()` which leaves these out and just takes the size of the buffer in bytes\ninstead of frames. The fourth parameter is an optional pre-allocated buffer and the fifth parameter\nis a pointer to a `ma_allocation_callbacks` structure for custom memory allocation routines.\nPassing in `NULL` for this results in `MA_MALLOC()` and `MA_FREE()` being used.\n\nUse `ma_pcm_rb_init_ex()` if you need a deinterleaved buffer. The data for each sub-buffer is\noffset from each other based on the stride. To manage your sub-buffers you can use\n`ma_pcm_rb_get_subbuffer_stride()`, `ma_pcm_rb_get_subbuffer_offset()` and\n`ma_pcm_rb_get_subbuffer_ptr()`.\n\nUse `ma_pcm_rb_acquire_read()` and `ma_pcm_rb_acquire_write()` to retrieve a pointer to a section\nof the ring buffer. You specify the number of frames you need, and on output it will set to what\nwas actually acquired. If the read or write pointer is positioned such that the number of frames\nrequested will require a loop, it will be clamped to the end of the buffer. Therefore, the number\nof frames you're given may be less than the number you requested.\n\nAfter calling `ma_pcm_rb_acquire_read()` or `ma_pcm_rb_acquire_write()`, you do your work on the\nbuffer and then \"commit\" it with `ma_pcm_rb_commit_read()` or `ma_pcm_rb_commit_write()`. This is\nwhere the read/write pointers are updated. When you commit you need to pass in the buffer that was\nreturned by the earlier call to `ma_pcm_rb_acquire_read()` or `ma_pcm_rb_acquire_write()` and is\nonly used for validation. The number of frames passed to `ma_pcm_rb_commit_read()` and\n`ma_pcm_rb_commit_write()` is what's used to increment the pointers, and can be less that what was\noriginally requested.\n\nIf you want to correct for drift between the write pointer and the read pointer you can use a\ncombination of `ma_pcm_rb_pointer_distance()`, `ma_pcm_rb_seek_read()` and\n`ma_pcm_rb_seek_write()`. Note that you can only move the pointers forward, and you should only\nmove the read pointer forward via the consumer thread, and the write pointer forward by the\nproducer thread. If there is too much space between the pointers, move the read pointer forward. If\nthere is too little space between the pointers, move the write pointer forward.\n\nYou can use a ring buffer at the byte level instead of the PCM frame level by using the `ma_rb`\nAPI. This is exactly the same, only you will use the `ma_rb` functions instead of `ma_pcm_rb` and\ninstead of frame counts you will pass around byte counts.\n\nThe maximum size of the buffer in bytes is `0x7FFFFFFF-(MA_SIMD_ALIGNMENT-1)` due to the most\nsignificant bit being used to encode a loop flag and the internally managed buffers always being\naligned to `MA_SIMD_ALIGNMENT`.\n\nNote that the ring buffer is only thread safe when used by a single consumer thread and single\nproducer thread.\n\n\n\n15. Backends\n============\nThe following backends are supported by miniaudio. These are listed in order of default priority.\nWhen no backend is specified when initializing a context or device, miniaudio will attempt to use\neach of these backends in the order listed in the table below.\n\nNote that backends that are not usable by the build target will not be included in the build. For\nexample, ALSA, which is specific to Linux, will not be included in the Windows build.\n\n    +-------------+-----------------------+--------------------------------------------------------+\n    | Name        | Enum Name             | Supported Operating Systems                            |\n    +-------------+-----------------------+--------------------------------------------------------+\n    | WASAPI      | ma_backend_wasapi     | Windows Vista+                                         |\n    | DirectSound | ma_backend_dsound     | Windows XP+                                            |\n    | WinMM       | ma_backend_winmm      | Windows 95+                                            |\n    | Core Audio  | ma_backend_coreaudio  | macOS, iOS                                             |\n    | sndio       | ma_backend_sndio      | OpenBSD                                                |\n    | audio(4)    | ma_backend_audio4     | NetBSD, OpenBSD                                        |\n    | OSS         | ma_backend_oss        | FreeBSD                                                |\n    | PulseAudio  | ma_backend_pulseaudio | Cross Platform (disabled on Windows, BSD and Android)  |\n    | ALSA        | ma_backend_alsa       | Linux                                                  |\n    | JACK        | ma_backend_jack       | Cross Platform (disabled on BSD and Android)           |\n    | AAudio      | ma_backend_aaudio     | Android 8+                                             |\n    | OpenSL ES   | ma_backend_opensl     | Android (API level 16+)                                |\n    | Web Audio   | ma_backend_webaudio   | Web (via Emscripten)                                   |\n    | Custom      | ma_backend_custom     | Cross Platform                                         |\n    | Null        | ma_backend_null       | Cross Platform (not used on Web)                       |\n    +-------------+-----------------------+--------------------------------------------------------+\n\nSome backends have some nuance details you may want to be aware of.\n\n15.1. WASAPI\n------------\n- Low-latency shared mode will be disabled when using an application-defined sample rate which is\n  different to the device's native sample rate. To work around this, set `wasapi.noAutoConvertSRC`\n  to true in the device config. This is due to IAudioClient3_InitializeSharedAudioStream() failing\n  when the `AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM` flag is specified. Setting wasapi.noAutoConvertSRC\n  will result in miniaudio's internal resampler being used instead which will in turn enable the\n  use of low-latency shared mode.\n\n15.2. PulseAudio\n----------------\n- If you experience bad glitching/noise on Arch Linux, consider this fix from the Arch wiki:\n  https://wiki.archlinux.org/index.php/PulseAudio/Troubleshooting#Glitches,_skips_or_crackling.\n  Alternatively, consider using a different backend such as ALSA.\n\n15.3. Android\n-------------\n- To capture audio on Android, remember to add the RECORD_AUDIO permission to your manifest:\n  `<uses-permission android:name=\"android.permission.RECORD_AUDIO\" />`\n- With OpenSL|ES, only a single ma_context can be active at any given time. This is due to a\n  limitation with OpenSL|ES.\n- With AAudio, only default devices are enumerated. This is due to AAudio not having an enumeration\n  API (devices are enumerated through Java). You can however perform your own device enumeration\n  through Java and then set the ID in the ma_device_id structure (ma_device_id.aaudio) and pass it\n  to ma_device_init().\n- The backend API will perform resampling where possible. The reason for this as opposed to using\n  miniaudio's built-in resampler is to take advantage of any potential device-specific\n  optimizations the driver may implement.\n\nBSD\n---\n- The sndio backend is currently only enabled on OpenBSD builds.\n- The audio(4) backend is supported on OpenBSD, but you may need to disable sndiod before you can\n  use it.\n\n15.4. UWP\n---------\n- UWP only supports default playback and capture devices.\n- UWP requires the Microphone capability to be enabled in the application's manifest (Package.appxmanifest):\n\n    ```\n    <Package ...>\n        ...\n        <Capabilities>\n            <DeviceCapability Name=\"microphone\" />\n        </Capabilities>\n    </Package>\n    ```\n\n15.5. Web Audio / Emscripten\n----------------------------\n- You cannot use `-std=c*` compiler flags, nor `-ansi`. This only applies to the Emscripten build.\n- The first time a context is initialized it will create a global object called \"miniaudio\" whose\n  primary purpose is to act as a factory for device objects.\n- Currently the Web Audio backend uses ScriptProcessorNode's, but this may need to change later as\n  they've been deprecated.\n- Google has implemented a policy in their browsers that prevent automatic media output without\n  first receiving some kind of user input. The following web page has additional details:\n  https://developers.google.com/web/updates/2017/09/autoplay-policy-changes. Starting the device\n  may fail if you try to start playback without first handling some kind of user input.\n\n\n\n16. Optimization Tips\n=====================\nSee below for some tips on improving performance.\n\n16.1. Low Level API\n-------------------\n- In the data callback, if your data is already clipped prior to copying it into the output buffer,\n  set the `noClip` config option in the device config to true. This will disable miniaudio's built\n  in clipping function.\n- By default, miniaudio will pre-silence the data callback's output buffer. If you know that you\n  will always write valid data to the output buffer you can disable pre-silencing by setting the\n  `noPreSilence` config option in the device config to true.\n\n16.2. High Level API\n--------------------\n- If a sound does not require doppler or pitch shifting, consider disabling pitching by\n  initializing the sound with the `MA_SOUND_FLAG_NO_PITCH` flag.\n- If a sound does not require spatialization, disable it by initializing the sound with the\n  `MA_SOUND_FLAG_NO_SPATIALIZATION` flag. It can be re-enabled again post-initialization with\n  `ma_sound_set_spatialization_enabled()`.\n- If you know all of your sounds will always be the same sample rate, set the engine's sample\n  rate to match that of the sounds. Likewise, if you're using a self-managed resource manager,\n  consider setting the decoded sample rate to match your sounds. By configuring everything to\n  use a consistent sample rate, sample rate conversion can be avoided.\n\n\n\n17. Miscellaneous Notes\n=======================\n- Automatic stream routing is enabled on a per-backend basis. Support is explicitly enabled for\n  WASAPI and Core Audio, however other backends such as PulseAudio may naturally support it, though\n  not all have been tested.\n- When compiling with VC6 and earlier, decoding is restricted to files less than 2GB in size. This\n  is due to 64-bit file APIs not being available.\n*/\n\n#ifndef miniaudio_h\n#define miniaudio_h\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#define MA_STRINGIFY(x)     #x\n#define MA_XSTRINGIFY(x)    MA_STRINGIFY(x)\n\n#define MA_VERSION_MAJOR    0\n#define MA_VERSION_MINOR    11\n#define MA_VERSION_REVISION 21\n#define MA_VERSION_STRING   MA_XSTRINGIFY(MA_VERSION_MAJOR) \".\" MA_XSTRINGIFY(MA_VERSION_MINOR) \".\" MA_XSTRINGIFY(MA_VERSION_REVISION)\n\n#if defined(_MSC_VER) && !defined(__clang__)\n    #pragma warning(push)\n    #pragma warning(disable:4201)   /* nonstandard extension used: nameless struct/union */\n    #pragma warning(disable:4214)   /* nonstandard extension used: bit field types other than int */\n    #pragma warning(disable:4324)   /* structure was padded due to alignment specifier */\n#elif defined(__clang__) || (defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)))\n    #pragma GCC diagnostic push\n    #pragma GCC diagnostic ignored \"-Wpedantic\" /* For ISO C99 doesn't support unnamed structs/unions [-Wpedantic] */\n    #if defined(__clang__)\n        #pragma GCC diagnostic ignored \"-Wc11-extensions\"   /* anonymous unions are a C11 extension */\n    #endif\n#endif\n\n\n\n#if defined(__LP64__) || defined(_WIN64) || (defined(__x86_64__) && !defined(__ILP32__)) || defined(_M_X64) || defined(__ia64) || defined(_M_IA64) || defined(__aarch64__) || defined(_M_ARM64) || defined(__powerpc64__)\n    #define MA_SIZEOF_PTR   8\n#else\n    #define MA_SIZEOF_PTR   4\n#endif\n\n#include <stddef.h> /* For size_t. */\n\n/* Sized types. */\n#if defined(MA_USE_STDINT)\n    #include <stdint.h>\n    typedef int8_t   ma_int8;\n    typedef uint8_t  ma_uint8;\n    typedef int16_t  ma_int16;\n    typedef uint16_t ma_uint16;\n    typedef int32_t  ma_int32;\n    typedef uint32_t ma_uint32;\n    typedef int64_t  ma_int64;\n    typedef uint64_t ma_uint64;\n#else\n    typedef   signed char           ma_int8;\n    typedef unsigned char           ma_uint8;\n    typedef   signed short          ma_int16;\n    typedef unsigned short          ma_uint16;\n    typedef   signed int            ma_int32;\n    typedef unsigned int            ma_uint32;\n    #if defined(_MSC_VER) && !defined(__clang__)\n        typedef   signed __int64    ma_int64;\n        typedef unsigned __int64    ma_uint64;\n    #else\n        #if defined(__clang__) || (defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6)))\n            #pragma GCC diagnostic push\n            #pragma GCC diagnostic ignored \"-Wlong-long\"\n            #if defined(__clang__)\n                #pragma GCC diagnostic ignored \"-Wc++11-long-long\"\n            #endif\n        #endif\n        typedef   signed long long  ma_int64;\n        typedef unsigned long long  ma_uint64;\n        #if defined(__clang__) || (defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6)))\n            #pragma GCC diagnostic pop\n        #endif\n    #endif\n#endif  /* MA_USE_STDINT */\n\n#if MA_SIZEOF_PTR == 8\n    typedef ma_uint64           ma_uintptr;\n#else\n    typedef ma_uint32           ma_uintptr;\n#endif\n\ntypedef ma_uint8    ma_bool8;\ntypedef ma_uint32   ma_bool32;\n#define MA_TRUE     1\n#define MA_FALSE    0\n\n/* These float types are not used universally by miniaudio. It's to simplify some macro expansion for atomic types. */\ntypedef float       ma_float;\ntypedef double      ma_double;\n\ntypedef void* ma_handle;\ntypedef void* ma_ptr;\n\n/*\nma_proc is annoying because when compiling with GCC we get pendantic warnings about converting\nbetween `void*` and `void (*)()`. We can't use `void (*)()` with MSVC however, because we'll get\nwarning C4191 about \"type cast between incompatible function types\". To work around this I'm going\nto use a different data type depending on the compiler.\n*/\n#if defined(__GNUC__)\ntypedef void (*ma_proc)(void);\n#else\ntypedef void* ma_proc;\n#endif\n\n#if defined(_MSC_VER) && !defined(_WCHAR_T_DEFINED)\ntypedef ma_uint16 wchar_t;\n#endif\n\n/* Define NULL for some compilers. */\n#ifndef NULL\n#define NULL 0\n#endif\n\n#if defined(SIZE_MAX)\n    #define MA_SIZE_MAX    SIZE_MAX\n#else\n    #define MA_SIZE_MAX    0xFFFFFFFF  /* When SIZE_MAX is not defined by the standard library just default to the maximum 32-bit unsigned integer. */\n#endif\n\n\n/* Platform/backend detection. */\n#if defined(_WIN32) || defined(__COSMOPOLITAN__)\n    #define MA_WIN32\n    #if defined(MA_FORCE_UWP) || (defined(WINAPI_FAMILY) && ((defined(WINAPI_FAMILY_PC_APP) && WINAPI_FAMILY == WINAPI_FAMILY_PC_APP) || (defined(WINAPI_FAMILY_PHONE_APP) && WINAPI_FAMILY == WINAPI_FAMILY_PHONE_APP)))\n        #define MA_WIN32_UWP\n    #elif defined(WINAPI_FAMILY) && (defined(WINAPI_FAMILY_GAMES) && WINAPI_FAMILY == WINAPI_FAMILY_GAMES)\n        #define MA_WIN32_GDK\n    #else\n        #define MA_WIN32_DESKTOP\n    #endif\n#endif\n#if !defined(_WIN32)    /* If it's not Win32, assume POSIX. */\n    #define MA_POSIX\n\n    /*\n    Use the MA_NO_PTHREAD_IN_HEADER option at your own risk. This is intentionally undocumented.\n    You can use this to avoid including pthread.h in the header section. The downside is that it\n    results in some fixed sized structures being declared for the various types that are used in\n    miniaudio. The risk here is that these types might be too small for a given platform. This\n    risk is yours to take and no support will be offered if you enable this option.\n    */\n    #ifndef MA_NO_PTHREAD_IN_HEADER\n        #include <pthread.h>    /* Unfortunate #include, but needed for pthread_t, pthread_mutex_t and pthread_cond_t types. */\n        typedef pthread_t       ma_pthread_t;\n        typedef pthread_mutex_t ma_pthread_mutex_t;\n        typedef pthread_cond_t  ma_pthread_cond_t;\n    #else\n        typedef ma_uintptr      ma_pthread_t;\n        typedef union           ma_pthread_mutex_t { char __data[40]; ma_uint64 __alignment; } ma_pthread_mutex_t;\n        typedef union           ma_pthread_cond_t  { char __data[48]; ma_uint64 __alignment; } ma_pthread_cond_t;\n    #endif\n\n    #if defined(__unix__)\n        #define MA_UNIX\n    #endif\n    #if defined(__linux__)\n        #define MA_LINUX\n    #endif\n    #if defined(__APPLE__)\n        #define MA_APPLE\n    #endif\n    #if defined(__DragonFly__) || defined(__FreeBSD__) || defined(__NetBSD__) || defined(__OpenBSD__)\n        #define MA_BSD\n    #endif\n    #if defined(__ANDROID__)\n        #define MA_ANDROID\n    #endif\n    #if defined(__EMSCRIPTEN__)\n        #define MA_EMSCRIPTEN\n    #endif\n    #if defined(__ORBIS__)\n        #define MA_ORBIS\n    #endif\n    #if defined(__PROSPERO__)\n        #define MA_PROSPERO\n    #endif\n    #if defined(__NX__)\n        #define MA_NX\n    #endif\n    #if defined(__BEOS__) || defined(__HAIKU__)\n        #define MA_BEOS\n    #endif\n    #if defined(__HAIKU__)\n        #define MA_HAIKU\n    #endif\n#endif\n\n#if defined(__has_c_attribute)\n    #if __has_c_attribute(fallthrough)\n        #define MA_FALLTHROUGH [[fallthrough]]\n    #endif\n#endif\n#if !defined(MA_FALLTHROUGH) && defined(__has_attribute) && (defined(__clang__) || defined(__GNUC__))\n    #if __has_attribute(fallthrough)\n        #define MA_FALLTHROUGH __attribute__((fallthrough))\n    #endif\n#endif\n#if !defined(MA_FALLTHROUGH)\n    #define MA_FALLTHROUGH ((void)0)\n#endif\n\n#ifdef _MSC_VER\n    #define MA_INLINE __forceinline\n\n    /* noinline was introduced in Visual Studio 2005. */\n    #if _MSC_VER >= 1400\n        #define MA_NO_INLINE __declspec(noinline)\n    #else\n        #define MA_NO_INLINE\n    #endif\n#elif defined(__GNUC__)\n    /*\n    I've had a bug report where GCC is emitting warnings about functions possibly not being inlineable. This warning happens when\n    the __attribute__((always_inline)) attribute is defined without an \"inline\" statement. I think therefore there must be some\n    case where \"__inline__\" is not always defined, thus the compiler emitting these warnings. When using -std=c89 or -ansi on the\n    command line, we cannot use the \"inline\" keyword and instead need to use \"__inline__\". In an attempt to work around this issue\n    I am using \"__inline__\" only when we're compiling in strict ANSI mode.\n    */\n    #if defined(__STRICT_ANSI__)\n        #define MA_GNUC_INLINE_HINT __inline__\n    #else\n        #define MA_GNUC_INLINE_HINT inline\n    #endif\n\n    #if (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 2)) || defined(__clang__)\n        #define MA_INLINE MA_GNUC_INLINE_HINT __attribute__((always_inline))\n        #define MA_NO_INLINE __attribute__((noinline))\n    #else\n        #define MA_INLINE MA_GNUC_INLINE_HINT\n        #define MA_NO_INLINE __attribute__((noinline))\n    #endif\n#elif defined(__WATCOMC__)\n    #define MA_INLINE __inline\n    #define MA_NO_INLINE\n#else\n    #define MA_INLINE\n    #define MA_NO_INLINE\n#endif\n\n/* MA_DLL is not officially supported. You're on your own if you want to use this. */\n#if defined(MA_DLL)\n    #if defined(_WIN32)\n        #define MA_DLL_IMPORT  __declspec(dllimport)\n        #define MA_DLL_EXPORT  __declspec(dllexport)\n        #define MA_DLL_PRIVATE static\n    #else\n        #if defined(__GNUC__) && __GNUC__ >= 4\n            #define MA_DLL_IMPORT  __attribute__((visibility(\"default\")))\n            #define MA_DLL_EXPORT  __attribute__((visibility(\"default\")))\n            #define MA_DLL_PRIVATE __attribute__((visibility(\"hidden\")))\n        #else\n            #define MA_DLL_IMPORT\n            #define MA_DLL_EXPORT\n            #define MA_DLL_PRIVATE static\n        #endif\n    #endif\n#endif\n\n#if !defined(MA_API)\n    #if defined(MA_DLL)\n        #if defined(MINIAUDIO_IMPLEMENTATION) || defined(MA_IMPLEMENTATION)\n            #define MA_API  MA_DLL_EXPORT\n        #else\n            #define MA_API  MA_DLL_IMPORT\n        #endif\n    #else\n        #define MA_API extern\n    #endif\n#endif\n\n#if !defined(MA_STATIC)\n    #if defined(MA_DLL)\n        #define MA_PRIVATE MA_DLL_PRIVATE\n    #else\n        #define MA_PRIVATE static\n    #endif\n#endif\n\n\n/* SIMD alignment in bytes. Currently set to 32 bytes in preparation for future AVX optimizations. */\n#define MA_SIMD_ALIGNMENT  32\n\n/*\nSpecial wchar_t type to ensure any structures in the public sections that reference it have a\nconsistent size across all platforms.\n\nOn Windows, wchar_t is 2 bytes, whereas everywhere else it's 4 bytes. Since Windows likes to use\nwchar_t for it's IDs, we need a special explicitly sized wchar type that is always 2 bytes on all\nplatforms.\n*/\n#if !defined(MA_POSIX) && defined(MA_WIN32)\ntypedef wchar_t     ma_wchar_win32;\n#else\ntypedef ma_uint16   ma_wchar_win32;\n#endif\n\n\n\n/*\nLogging Levels\n==============\nLog levels are only used to give logging callbacks some context as to the severity of a log message\nso they can do filtering. All log levels will be posted to registered logging callbacks. If you\ndon't want to output a certain log level you can discriminate against the log level in the callback.\n\nMA_LOG_LEVEL_DEBUG\n    Used for debugging. Useful for debug and test builds, but should be disabled in release builds.\n\nMA_LOG_LEVEL_INFO\n    Informational logging. Useful for debugging. This will never be called from within the data\n    callback.\n\nMA_LOG_LEVEL_WARNING\n    Warnings. You should enable this in you development builds and action them when encounted. These\n    logs usually indicate a potential problem or misconfiguration, but still allow you to keep\n    running. This will never be called from within the data callback.\n\nMA_LOG_LEVEL_ERROR\n    Error logging. This will be fired when an operation fails and is subsequently aborted. This can\n    be fired from within the data callback, in which case the device will be stopped. You should\n    always have this log level enabled.\n*/\ntypedef enum\n{\n    MA_LOG_LEVEL_DEBUG   = 4,\n    MA_LOG_LEVEL_INFO    = 3,\n    MA_LOG_LEVEL_WARNING = 2,\n    MA_LOG_LEVEL_ERROR   = 1\n} ma_log_level;\n\n/*\nVariables needing to be accessed atomically should be declared with this macro for two reasons:\n\n    1) It allows people who read the code to identify a variable as such; and\n    2) It forces alignment on platforms where it's required or optimal.\n\nNote that for x86/64, alignment is not strictly necessary, but does have some performance\nimplications. Where supported by the compiler, alignment will be used, but otherwise if the CPU\narchitecture does not require it, it will simply leave it unaligned. This is the case with old\nversions of Visual Studio, which I've confirmed with at least VC6.\n*/\n#if !defined(_MSC_VER) && defined (__STDC_VERSION__) && (__STDC_VERSION__ >= 201112L)\n    #include <stdalign.h>\n    #define MA_ATOMIC(alignment, type)            _Alignas(alignment) type\n#else\n    #if defined(__GNUC__)\n        /* GCC-style compilers. */\n        #define MA_ATOMIC(alignment, type)        type __attribute__((aligned(alignment)))\n    #elif defined(_MSC_VER) && _MSC_VER > 1200  /* 1200 = VC6. Alignment not supported, but not necessary because x86 is the only supported target. */\n        /* MSVC. */\n        #define MA_ATOMIC(alignment, type)        __declspec(align(alignment)) type\n    #else\n        /* Other compilers. */\n        #define MA_ATOMIC(alignment, type)        type\n    #endif\n#endif\n\ntypedef struct ma_context ma_context;\ntypedef struct ma_device ma_device;\n\ntypedef ma_uint8 ma_channel;\ntypedef enum\n{\n    MA_CHANNEL_NONE               = 0,\n    MA_CHANNEL_MONO               = 1,\n    MA_CHANNEL_FRONT_LEFT         = 2,\n    MA_CHANNEL_FRONT_RIGHT        = 3,\n    MA_CHANNEL_FRONT_CENTER       = 4,\n    MA_CHANNEL_LFE                = 5,\n    MA_CHANNEL_BACK_LEFT          = 6,\n    MA_CHANNEL_BACK_RIGHT         = 7,\n    MA_CHANNEL_FRONT_LEFT_CENTER  = 8,\n    MA_CHANNEL_FRONT_RIGHT_CENTER = 9,\n    MA_CHANNEL_BACK_CENTER        = 10,\n    MA_CHANNEL_SIDE_LEFT          = 11,\n    MA_CHANNEL_SIDE_RIGHT         = 12,\n    MA_CHANNEL_TOP_CENTER         = 13,\n    MA_CHANNEL_TOP_FRONT_LEFT     = 14,\n    MA_CHANNEL_TOP_FRONT_CENTER   = 15,\n    MA_CHANNEL_TOP_FRONT_RIGHT    = 16,\n    MA_CHANNEL_TOP_BACK_LEFT      = 17,\n    MA_CHANNEL_TOP_BACK_CENTER    = 18,\n    MA_CHANNEL_TOP_BACK_RIGHT     = 19,\n    MA_CHANNEL_AUX_0              = 20,\n    MA_CHANNEL_AUX_1              = 21,\n    MA_CHANNEL_AUX_2              = 22,\n    MA_CHANNEL_AUX_3              = 23,\n    MA_CHANNEL_AUX_4              = 24,\n    MA_CHANNEL_AUX_5              = 25,\n    MA_CHANNEL_AUX_6              = 26,\n    MA_CHANNEL_AUX_7              = 27,\n    MA_CHANNEL_AUX_8              = 28,\n    MA_CHANNEL_AUX_9              = 29,\n    MA_CHANNEL_AUX_10             = 30,\n    MA_CHANNEL_AUX_11             = 31,\n    MA_CHANNEL_AUX_12             = 32,\n    MA_CHANNEL_AUX_13             = 33,\n    MA_CHANNEL_AUX_14             = 34,\n    MA_CHANNEL_AUX_15             = 35,\n    MA_CHANNEL_AUX_16             = 36,\n    MA_CHANNEL_AUX_17             = 37,\n    MA_CHANNEL_AUX_18             = 38,\n    MA_CHANNEL_AUX_19             = 39,\n    MA_CHANNEL_AUX_20             = 40,\n    MA_CHANNEL_AUX_21             = 41,\n    MA_CHANNEL_AUX_22             = 42,\n    MA_CHANNEL_AUX_23             = 43,\n    MA_CHANNEL_AUX_24             = 44,\n    MA_CHANNEL_AUX_25             = 45,\n    MA_CHANNEL_AUX_26             = 46,\n    MA_CHANNEL_AUX_27             = 47,\n    MA_CHANNEL_AUX_28             = 48,\n    MA_CHANNEL_AUX_29             = 49,\n    MA_CHANNEL_AUX_30             = 50,\n    MA_CHANNEL_AUX_31             = 51,\n    MA_CHANNEL_LEFT               = MA_CHANNEL_FRONT_LEFT,\n    MA_CHANNEL_RIGHT              = MA_CHANNEL_FRONT_RIGHT,\n    MA_CHANNEL_POSITION_COUNT     = (MA_CHANNEL_AUX_31 + 1)\n} _ma_channel_position; /* Do not use `_ma_channel_position` directly. Use `ma_channel` instead. */\n\ntypedef enum\n{\n    MA_SUCCESS                        =  0,\n    MA_ERROR                          = -1,  /* A generic error. */\n    MA_INVALID_ARGS                   = -2,\n    MA_INVALID_OPERATION              = -3,\n    MA_OUT_OF_MEMORY                  = -4,\n    MA_OUT_OF_RANGE                   = -5,\n    MA_ACCESS_DENIED                  = -6,\n    MA_DOES_NOT_EXIST                 = -7,\n    MA_ALREADY_EXISTS                 = -8,\n    MA_TOO_MANY_OPEN_FILES            = -9,\n    MA_INVALID_FILE                   = -10,\n    MA_TOO_BIG                        = -11,\n    MA_PATH_TOO_LONG                  = -12,\n    MA_NAME_TOO_LONG                  = -13,\n    MA_NOT_DIRECTORY                  = -14,\n    MA_IS_DIRECTORY                   = -15,\n    MA_DIRECTORY_NOT_EMPTY            = -16,\n    MA_AT_END                         = -17,\n    MA_NO_SPACE                       = -18,\n    MA_BUSY                           = -19,\n    MA_IO_ERROR                       = -20,\n    MA_INTERRUPT                      = -21,\n    MA_UNAVAILABLE                    = -22,\n    MA_ALREADY_IN_USE                 = -23,\n    MA_BAD_ADDRESS                    = -24,\n    MA_BAD_SEEK                       = -25,\n    MA_BAD_PIPE                       = -26,\n    MA_DEADLOCK                       = -27,\n    MA_TOO_MANY_LINKS                 = -28,\n    MA_NOT_IMPLEMENTED                = -29,\n    MA_NO_MESSAGE                     = -30,\n    MA_BAD_MESSAGE                    = -31,\n    MA_NO_DATA_AVAILABLE              = -32,\n    MA_INVALID_DATA                   = -33,\n    MA_TIMEOUT                        = -34,\n    MA_NO_NETWORK                     = -35,\n    MA_NOT_UNIQUE                     = -36,\n    MA_NOT_SOCKET                     = -37,\n    MA_NO_ADDRESS                     = -38,\n    MA_BAD_PROTOCOL                   = -39,\n    MA_PROTOCOL_UNAVAILABLE           = -40,\n    MA_PROTOCOL_NOT_SUPPORTED         = -41,\n    MA_PROTOCOL_FAMILY_NOT_SUPPORTED  = -42,\n    MA_ADDRESS_FAMILY_NOT_SUPPORTED   = -43,\n    MA_SOCKET_NOT_SUPPORTED           = -44,\n    MA_CONNECTION_RESET               = -45,\n    MA_ALREADY_CONNECTED              = -46,\n    MA_NOT_CONNECTED                  = -47,\n    MA_CONNECTION_REFUSED             = -48,\n    MA_NO_HOST                        = -49,\n    MA_IN_PROGRESS                    = -50,\n    MA_CANCELLED                      = -51,\n    MA_MEMORY_ALREADY_MAPPED          = -52,\n\n    /* General non-standard errors. */\n    MA_CRC_MISMATCH                   = -100,\n\n    /* General miniaudio-specific errors. */\n    MA_FORMAT_NOT_SUPPORTED           = -200,\n    MA_DEVICE_TYPE_NOT_SUPPORTED      = -201,\n    MA_SHARE_MODE_NOT_SUPPORTED       = -202,\n    MA_NO_BACKEND                     = -203,\n    MA_NO_DEVICE                      = -204,\n    MA_API_NOT_FOUND                  = -205,\n    MA_INVALID_DEVICE_CONFIG          = -206,\n    MA_LOOP                           = -207,\n    MA_BACKEND_NOT_ENABLED            = -208,\n\n    /* State errors. */\n    MA_DEVICE_NOT_INITIALIZED         = -300,\n    MA_DEVICE_ALREADY_INITIALIZED     = -301,\n    MA_DEVICE_NOT_STARTED             = -302,\n    MA_DEVICE_NOT_STOPPED             = -303,\n\n    /* Operation errors. */\n    MA_FAILED_TO_INIT_BACKEND         = -400,\n    MA_FAILED_TO_OPEN_BACKEND_DEVICE  = -401,\n    MA_FAILED_TO_START_BACKEND_DEVICE = -402,\n    MA_FAILED_TO_STOP_BACKEND_DEVICE  = -403\n} ma_result;\n\n\n#define MA_MIN_CHANNELS                 1\n#ifndef MA_MAX_CHANNELS\n#define MA_MAX_CHANNELS                 254\n#endif\n\n#ifndef MA_MAX_FILTER_ORDER\n#define MA_MAX_FILTER_ORDER             8\n#endif\n\ntypedef enum\n{\n    ma_stream_format_pcm = 0\n} ma_stream_format;\n\ntypedef enum\n{\n    ma_stream_layout_interleaved = 0,\n    ma_stream_layout_deinterleaved\n} ma_stream_layout;\n\ntypedef enum\n{\n    ma_dither_mode_none = 0,\n    ma_dither_mode_rectangle,\n    ma_dither_mode_triangle\n} ma_dither_mode;\n\ntypedef enum\n{\n    /*\n    I like to keep these explicitly defined because they're used as a key into a lookup table. When items are\n    added to this, make sure there are no gaps and that they're added to the lookup table in ma_get_bytes_per_sample().\n    */\n    ma_format_unknown = 0,     /* Mainly used for indicating an error, but also used as the default for the output format for decoders. */\n    ma_format_u8      = 1,\n    ma_format_s16     = 2,     /* Seems to be the most widely supported format. */\n    ma_format_s24     = 3,     /* Tightly packed. 3 bytes per sample. */\n    ma_format_s32     = 4,\n    ma_format_f32     = 5,\n    ma_format_count\n} ma_format;\n\ntypedef enum\n{\n    /* Standard rates need to be in priority order. */\n    ma_standard_sample_rate_48000  = 48000,     /* Most common */\n    ma_standard_sample_rate_44100  = 44100,\n\n    ma_standard_sample_rate_32000  = 32000,     /* Lows */\n    ma_standard_sample_rate_24000  = 24000,\n    ma_standard_sample_rate_22050  = 22050,\n\n    ma_standard_sample_rate_88200  = 88200,     /* Highs */\n    ma_standard_sample_rate_96000  = 96000,\n    ma_standard_sample_rate_176400 = 176400,\n    ma_standard_sample_rate_192000 = 192000,\n\n    ma_standard_sample_rate_16000  = 16000,     /* Extreme lows */\n    ma_standard_sample_rate_11025  = 11025,\n    ma_standard_sample_rate_8000   = 8000,\n\n    ma_standard_sample_rate_352800 = 352800,    /* Extreme highs */\n    ma_standard_sample_rate_384000 = 384000,\n\n    ma_standard_sample_rate_min    = ma_standard_sample_rate_8000,\n    ma_standard_sample_rate_max    = ma_standard_sample_rate_384000,\n    ma_standard_sample_rate_count  = 14         /* Need to maintain the count manually. Make sure this is updated if items are added to enum. */\n} ma_standard_sample_rate;\n\n\ntypedef enum\n{\n    ma_channel_mix_mode_rectangular = 0,   /* Simple averaging based on the plane(s) the channel is sitting on. */\n    ma_channel_mix_mode_simple,            /* Drop excess channels; zeroed out extra channels. */\n    ma_channel_mix_mode_custom_weights,    /* Use custom weights specified in ma_channel_converter_config. */\n    ma_channel_mix_mode_default = ma_channel_mix_mode_rectangular\n} ma_channel_mix_mode;\n\ntypedef enum\n{\n    ma_standard_channel_map_microsoft,\n    ma_standard_channel_map_alsa,\n    ma_standard_channel_map_rfc3551,   /* Based off AIFF. */\n    ma_standard_channel_map_flac,\n    ma_standard_channel_map_vorbis,\n    ma_standard_channel_map_sound4,    /* FreeBSD's sound(4). */\n    ma_standard_channel_map_sndio,     /* www.sndio.org/tips.html */\n    ma_standard_channel_map_webaudio = ma_standard_channel_map_flac, /* https://webaudio.github.io/web-audio-api/#ChannelOrdering. Only 1, 2, 4 and 6 channels are defined, but can fill in the gaps with logical assumptions. */\n    ma_standard_channel_map_default = ma_standard_channel_map_microsoft\n} ma_standard_channel_map;\n\ntypedef enum\n{\n    ma_performance_profile_low_latency = 0,\n    ma_performance_profile_conservative\n} ma_performance_profile;\n\n\ntypedef struct\n{\n    void* pUserData;\n    void* (* onMalloc)(size_t sz, void* pUserData);\n    void* (* onRealloc)(void* p, size_t sz, void* pUserData);\n    void  (* onFree)(void* p, void* pUserData);\n} ma_allocation_callbacks;\n\ntypedef struct\n{\n    ma_int32 state;\n} ma_lcg;\n\n\n/*\nAtomics.\n\nThese are typesafe structures to prevent errors as a result of forgetting to reference variables atomically. It's too\neasy to introduce subtle bugs where you accidentally do a regular assignment instead of an atomic load/store, etc. By\nusing a struct we can enforce the use of atomics at compile time.\n\nThese types are declared in the header section because we need to reference them in structs below, but functions for\nusing them are only exposed in the implementation section. I do not want these to be part of the public API.\n\nThere's a few downsides to this system. The first is that you need to declare a new struct for each type. Below are\nsome macros to help with the declarations. They will be named like so:\n\n    ma_atomic_uint32 - atomic ma_uint32\n    ma_atomic_int32  - atomic ma_int32\n    ma_atomic_uint64 - atomic ma_uint64\n    ma_atomic_float  - atomic float\n    ma_atomic_bool32 - atomic ma_bool32\n\nThe other downside is that atomic pointers are extremely messy. You need to declare a new struct for each specific\ntype of pointer you need to make atomic. For example, an atomic ma_node* will look like this:\n\n    MA_ATOMIC_SAFE_TYPE_IMPL_PTR(node)\n\nWhich will declare a type struct that's named like so:\n\n    ma_atomic_ptr_node\n\nFunctions to use the atomic types are declared in the implementation section. All atomic functions are prefixed with\nthe name of the struct. For example:\n\n    ma_atomic_uint32_set() - Atomic store of ma_uint32\n    ma_atomic_uint32_get() - Atomic load of ma_uint32\n    etc.\n\nFor pointer types it's the same, which makes them a bit messy to use due to the length of each function name, but in\nreturn you get type safety and enforcement of atomic operations.\n*/\n#define MA_ATOMIC_SAFE_TYPE_DECL(c89TypeExtension, typeSize, type) \\\n    typedef struct \\\n    { \\\n        MA_ATOMIC(typeSize, ma_##type) value; \\\n    } ma_atomic_##type; \\\n\n#define MA_ATOMIC_SAFE_TYPE_DECL_PTR(type) \\\n    typedef struct \\\n    { \\\n        MA_ATOMIC(MA_SIZEOF_PTR, ma_##type*) value; \\\n    } ma_atomic_ptr_##type; \\\n\nMA_ATOMIC_SAFE_TYPE_DECL(32,  4, uint32)\nMA_ATOMIC_SAFE_TYPE_DECL(i32, 4, int32)\nMA_ATOMIC_SAFE_TYPE_DECL(64,  8, uint64)\nMA_ATOMIC_SAFE_TYPE_DECL(f32, 4, float)\nMA_ATOMIC_SAFE_TYPE_DECL(32,  4, bool32)\n\n\n/* Spinlocks are 32-bit for compatibility reasons. */\ntypedef ma_uint32 ma_spinlock;\n\n#ifndef MA_NO_THREADING\n    /* Thread priorities should be ordered such that the default priority of the worker thread is 0. */\n    typedef enum\n    {\n        ma_thread_priority_idle     = -5,\n        ma_thread_priority_lowest   = -4,\n        ma_thread_priority_low      = -3,\n        ma_thread_priority_normal   = -2,\n        ma_thread_priority_high     = -1,\n        ma_thread_priority_highest  =  0,\n        ma_thread_priority_realtime =  1,\n        ma_thread_priority_default  =  0\n    } ma_thread_priority;\n\n    #if defined(MA_POSIX)\n        typedef ma_pthread_t ma_thread;\n    #elif defined(MA_WIN32)\n        typedef ma_handle ma_thread;\n    #endif\n\n    #if defined(MA_POSIX)\n        typedef ma_pthread_mutex_t ma_mutex;\n    #elif defined(MA_WIN32)\n        typedef ma_handle ma_mutex;\n    #endif\n\n    #if defined(MA_POSIX)\n        typedef struct\n        {\n            ma_uint32 value;\n            ma_pthread_mutex_t lock;\n            ma_pthread_cond_t cond;\n        } ma_event;\n    #elif defined(MA_WIN32)\n        typedef ma_handle ma_event;\n    #endif\n\n    #if defined(MA_POSIX)\n        typedef struct\n        {\n            int value;\n            ma_pthread_mutex_t lock;\n            ma_pthread_cond_t cond;\n        } ma_semaphore;\n    #elif defined(MA_WIN32)\n        typedef ma_handle ma_semaphore;\n    #endif\n#else\n    /* MA_NO_THREADING is set which means threading is disabled. Threading is required by some API families. If any of these are enabled we need to throw an error. */\n    #ifndef MA_NO_DEVICE_IO\n        #error \"MA_NO_THREADING cannot be used without MA_NO_DEVICE_IO\";\n    #endif\n#endif  /* MA_NO_THREADING */\n\n\n/*\nRetrieves the version of miniaudio as separated integers. Each component can be NULL if it's not required.\n*/\nMA_API void ma_version(ma_uint32* pMajor, ma_uint32* pMinor, ma_uint32* pRevision);\n\n/*\nRetrieves the version of miniaudio as a string which can be useful for logging purposes.\n*/\nMA_API const char* ma_version_string(void);\n\n\n/**************************************************************************************************************************************************************\n\nLogging\n\n**************************************************************************************************************************************************************/\n#include <stdarg.h> /* For va_list. */\n\n#if defined(__has_attribute)\n    #if __has_attribute(format)\n        #define MA_ATTRIBUTE_FORMAT(fmt, va) __attribute__((format(printf, fmt, va)))\n    #endif\n#endif\n#ifndef MA_ATTRIBUTE_FORMAT\n#define MA_ATTRIBUTE_FORMAT(fmt, va)\n#endif\n\n#ifndef MA_MAX_LOG_CALLBACKS\n#define MA_MAX_LOG_CALLBACKS    4\n#endif\n\n\n/*\nThe callback for handling log messages.\n\n\nParameters\n----------\npUserData (in)\n    The user data pointer that was passed into ma_log_register_callback().\n\nlogLevel (in)\n    The log level. This can be one of the following:\n\n    +----------------------+\n    | Log Level            |\n    +----------------------+\n    | MA_LOG_LEVEL_DEBUG   |\n    | MA_LOG_LEVEL_INFO    |\n    | MA_LOG_LEVEL_WARNING |\n    | MA_LOG_LEVEL_ERROR   |\n    +----------------------+\n\npMessage (in)\n    The log message.\n*/\ntypedef void (* ma_log_callback_proc)(void* pUserData, ma_uint32 level, const char* pMessage);\n\ntypedef struct\n{\n    ma_log_callback_proc onLog;\n    void* pUserData;\n} ma_log_callback;\n\nMA_API ma_log_callback ma_log_callback_init(ma_log_callback_proc onLog, void* pUserData);\n\n\ntypedef struct\n{\n    ma_log_callback callbacks[MA_MAX_LOG_CALLBACKS];\n    ma_uint32 callbackCount;\n    ma_allocation_callbacks allocationCallbacks;    /* Need to store these persistently because ma_log_postv() might need to allocate a buffer on the heap. */\n#ifndef MA_NO_THREADING\n    ma_mutex lock;  /* For thread safety just to make it easier and safer for the logging implementation. */\n#endif\n} ma_log;\n\nMA_API ma_result ma_log_init(const ma_allocation_callbacks* pAllocationCallbacks, ma_log* pLog);\nMA_API void ma_log_uninit(ma_log* pLog);\nMA_API ma_result ma_log_register_callback(ma_log* pLog, ma_log_callback callback);\nMA_API ma_result ma_log_unregister_callback(ma_log* pLog, ma_log_callback callback);\nMA_API ma_result ma_log_post(ma_log* pLog, ma_uint32 level, const char* pMessage);\nMA_API ma_result ma_log_postv(ma_log* pLog, ma_uint32 level, const char* pFormat, va_list args);\nMA_API ma_result ma_log_postf(ma_log* pLog, ma_uint32 level, const char* pFormat, ...) MA_ATTRIBUTE_FORMAT(3, 4);\n\n\n/**************************************************************************************************************************************************************\n\nBiquad Filtering\n\n**************************************************************************************************************************************************************/\ntypedef union\n{\n    float    f32;\n    ma_int32 s32;\n} ma_biquad_coefficient;\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    double b0;\n    double b1;\n    double b2;\n    double a0;\n    double a1;\n    double a2;\n} ma_biquad_config;\n\nMA_API ma_biquad_config ma_biquad_config_init(ma_format format, ma_uint32 channels, double b0, double b1, double b2, double a0, double a1, double a2);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_biquad_coefficient b0;\n    ma_biquad_coefficient b1;\n    ma_biquad_coefficient b2;\n    ma_biquad_coefficient a1;\n    ma_biquad_coefficient a2;\n    ma_biquad_coefficient* pR1;\n    ma_biquad_coefficient* pR2;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_biquad;\n\nMA_API ma_result ma_biquad_get_heap_size(const ma_biquad_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_biquad_init_preallocated(const ma_biquad_config* pConfig, void* pHeap, ma_biquad* pBQ);\nMA_API ma_result ma_biquad_init(const ma_biquad_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_biquad* pBQ);\nMA_API void ma_biquad_uninit(ma_biquad* pBQ, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_biquad_reinit(const ma_biquad_config* pConfig, ma_biquad* pBQ);\nMA_API ma_result ma_biquad_clear_cache(ma_biquad* pBQ);\nMA_API ma_result ma_biquad_process_pcm_frames(ma_biquad* pBQ, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_biquad_get_latency(const ma_biquad* pBQ);\n\n\n/**************************************************************************************************************************************************************\n\nLow-Pass Filtering\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    double q;\n} ma_lpf1_config, ma_lpf2_config;\n\nMA_API ma_lpf1_config ma_lpf1_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency);\nMA_API ma_lpf2_config ma_lpf2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, double q);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_biquad_coefficient a;\n    ma_biquad_coefficient* pR1;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_lpf1;\n\nMA_API ma_result ma_lpf1_get_heap_size(const ma_lpf1_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_lpf1_init_preallocated(const ma_lpf1_config* pConfig, void* pHeap, ma_lpf1* pLPF);\nMA_API ma_result ma_lpf1_init(const ma_lpf1_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_lpf1* pLPF);\nMA_API void ma_lpf1_uninit(ma_lpf1* pLPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_lpf1_reinit(const ma_lpf1_config* pConfig, ma_lpf1* pLPF);\nMA_API ma_result ma_lpf1_clear_cache(ma_lpf1* pLPF);\nMA_API ma_result ma_lpf1_process_pcm_frames(ma_lpf1* pLPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_lpf1_get_latency(const ma_lpf1* pLPF);\n\ntypedef struct\n{\n    ma_biquad bq;   /* The second order low-pass filter is implemented as a biquad filter. */\n} ma_lpf2;\n\nMA_API ma_result ma_lpf2_get_heap_size(const ma_lpf2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_lpf2_init_preallocated(const ma_lpf2_config* pConfig, void* pHeap, ma_lpf2* pHPF);\nMA_API ma_result ma_lpf2_init(const ma_lpf2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_lpf2* pLPF);\nMA_API void ma_lpf2_uninit(ma_lpf2* pLPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_lpf2_reinit(const ma_lpf2_config* pConfig, ma_lpf2* pLPF);\nMA_API ma_result ma_lpf2_clear_cache(ma_lpf2* pLPF);\nMA_API ma_result ma_lpf2_process_pcm_frames(ma_lpf2* pLPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_lpf2_get_latency(const ma_lpf2* pLPF);\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    ma_uint32 order;    /* If set to 0, will be treated as a passthrough (no filtering will be applied). */\n} ma_lpf_config;\n\nMA_API ma_lpf_config ma_lpf_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, ma_uint32 order);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_uint32 lpf1Count;\n    ma_uint32 lpf2Count;\n    ma_lpf1* pLPF1;\n    ma_lpf2* pLPF2;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_lpf;\n\nMA_API ma_result ma_lpf_get_heap_size(const ma_lpf_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_lpf_init_preallocated(const ma_lpf_config* pConfig, void* pHeap, ma_lpf* pLPF);\nMA_API ma_result ma_lpf_init(const ma_lpf_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_lpf* pLPF);\nMA_API void ma_lpf_uninit(ma_lpf* pLPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_lpf_reinit(const ma_lpf_config* pConfig, ma_lpf* pLPF);\nMA_API ma_result ma_lpf_clear_cache(ma_lpf* pLPF);\nMA_API ma_result ma_lpf_process_pcm_frames(ma_lpf* pLPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_lpf_get_latency(const ma_lpf* pLPF);\n\n\n/**************************************************************************************************************************************************************\n\nHigh-Pass Filtering\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    double q;\n} ma_hpf1_config, ma_hpf2_config;\n\nMA_API ma_hpf1_config ma_hpf1_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency);\nMA_API ma_hpf2_config ma_hpf2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, double q);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_biquad_coefficient a;\n    ma_biquad_coefficient* pR1;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_hpf1;\n\nMA_API ma_result ma_hpf1_get_heap_size(const ma_hpf1_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_hpf1_init_preallocated(const ma_hpf1_config* pConfig, void* pHeap, ma_hpf1* pLPF);\nMA_API ma_result ma_hpf1_init(const ma_hpf1_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_hpf1* pHPF);\nMA_API void ma_hpf1_uninit(ma_hpf1* pHPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_hpf1_reinit(const ma_hpf1_config* pConfig, ma_hpf1* pHPF);\nMA_API ma_result ma_hpf1_process_pcm_frames(ma_hpf1* pHPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_hpf1_get_latency(const ma_hpf1* pHPF);\n\ntypedef struct\n{\n    ma_biquad bq;   /* The second order high-pass filter is implemented as a biquad filter. */\n} ma_hpf2;\n\nMA_API ma_result ma_hpf2_get_heap_size(const ma_hpf2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_hpf2_init_preallocated(const ma_hpf2_config* pConfig, void* pHeap, ma_hpf2* pHPF);\nMA_API ma_result ma_hpf2_init(const ma_hpf2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_hpf2* pHPF);\nMA_API void ma_hpf2_uninit(ma_hpf2* pHPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_hpf2_reinit(const ma_hpf2_config* pConfig, ma_hpf2* pHPF);\nMA_API ma_result ma_hpf2_process_pcm_frames(ma_hpf2* pHPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_hpf2_get_latency(const ma_hpf2* pHPF);\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    ma_uint32 order;    /* If set to 0, will be treated as a passthrough (no filtering will be applied). */\n} ma_hpf_config;\n\nMA_API ma_hpf_config ma_hpf_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, ma_uint32 order);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_uint32 hpf1Count;\n    ma_uint32 hpf2Count;\n    ma_hpf1* pHPF1;\n    ma_hpf2* pHPF2;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_hpf;\n\nMA_API ma_result ma_hpf_get_heap_size(const ma_hpf_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_hpf_init_preallocated(const ma_hpf_config* pConfig, void* pHeap, ma_hpf* pLPF);\nMA_API ma_result ma_hpf_init(const ma_hpf_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_hpf* pHPF);\nMA_API void ma_hpf_uninit(ma_hpf* pHPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_hpf_reinit(const ma_hpf_config* pConfig, ma_hpf* pHPF);\nMA_API ma_result ma_hpf_process_pcm_frames(ma_hpf* pHPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_hpf_get_latency(const ma_hpf* pHPF);\n\n\n/**************************************************************************************************************************************************************\n\nBand-Pass Filtering\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    double q;\n} ma_bpf2_config;\n\nMA_API ma_bpf2_config ma_bpf2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, double q);\n\ntypedef struct\n{\n    ma_biquad bq;   /* The second order band-pass filter is implemented as a biquad filter. */\n} ma_bpf2;\n\nMA_API ma_result ma_bpf2_get_heap_size(const ma_bpf2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_bpf2_init_preallocated(const ma_bpf2_config* pConfig, void* pHeap, ma_bpf2* pBPF);\nMA_API ma_result ma_bpf2_init(const ma_bpf2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_bpf2* pBPF);\nMA_API void ma_bpf2_uninit(ma_bpf2* pBPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_bpf2_reinit(const ma_bpf2_config* pConfig, ma_bpf2* pBPF);\nMA_API ma_result ma_bpf2_process_pcm_frames(ma_bpf2* pBPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_bpf2_get_latency(const ma_bpf2* pBPF);\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double cutoffFrequency;\n    ma_uint32 order;    /* If set to 0, will be treated as a passthrough (no filtering will be applied). */\n} ma_bpf_config;\n\nMA_API ma_bpf_config ma_bpf_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double cutoffFrequency, ma_uint32 order);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 bpf2Count;\n    ma_bpf2* pBPF2;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_bpf;\n\nMA_API ma_result ma_bpf_get_heap_size(const ma_bpf_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_bpf_init_preallocated(const ma_bpf_config* pConfig, void* pHeap, ma_bpf* pBPF);\nMA_API ma_result ma_bpf_init(const ma_bpf_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_bpf* pBPF);\nMA_API void ma_bpf_uninit(ma_bpf* pBPF, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_bpf_reinit(const ma_bpf_config* pConfig, ma_bpf* pBPF);\nMA_API ma_result ma_bpf_process_pcm_frames(ma_bpf* pBPF, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_bpf_get_latency(const ma_bpf* pBPF);\n\n\n/**************************************************************************************************************************************************************\n\nNotching Filter\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double q;\n    double frequency;\n} ma_notch2_config, ma_notch_config;\n\nMA_API ma_notch2_config ma_notch2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double q, double frequency);\n\ntypedef struct\n{\n    ma_biquad bq;\n} ma_notch2;\n\nMA_API ma_result ma_notch2_get_heap_size(const ma_notch2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_notch2_init_preallocated(const ma_notch2_config* pConfig, void* pHeap, ma_notch2* pFilter);\nMA_API ma_result ma_notch2_init(const ma_notch2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_notch2* pFilter);\nMA_API void ma_notch2_uninit(ma_notch2* pFilter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_notch2_reinit(const ma_notch2_config* pConfig, ma_notch2* pFilter);\nMA_API ma_result ma_notch2_process_pcm_frames(ma_notch2* pFilter, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_notch2_get_latency(const ma_notch2* pFilter);\n\n\n/**************************************************************************************************************************************************************\n\nPeaking EQ Filter\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double gainDB;\n    double q;\n    double frequency;\n} ma_peak2_config, ma_peak_config;\n\nMA_API ma_peak2_config ma_peak2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double gainDB, double q, double frequency);\n\ntypedef struct\n{\n    ma_biquad bq;\n} ma_peak2;\n\nMA_API ma_result ma_peak2_get_heap_size(const ma_peak2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_peak2_init_preallocated(const ma_peak2_config* pConfig, void* pHeap, ma_peak2* pFilter);\nMA_API ma_result ma_peak2_init(const ma_peak2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_peak2* pFilter);\nMA_API void ma_peak2_uninit(ma_peak2* pFilter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_peak2_reinit(const ma_peak2_config* pConfig, ma_peak2* pFilter);\nMA_API ma_result ma_peak2_process_pcm_frames(ma_peak2* pFilter, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_peak2_get_latency(const ma_peak2* pFilter);\n\n\n/**************************************************************************************************************************************************************\n\nLow Shelf Filter\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double gainDB;\n    double shelfSlope;\n    double frequency;\n} ma_loshelf2_config, ma_loshelf_config;\n\nMA_API ma_loshelf2_config ma_loshelf2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double gainDB, double shelfSlope, double frequency);\n\ntypedef struct\n{\n    ma_biquad bq;\n} ma_loshelf2;\n\nMA_API ma_result ma_loshelf2_get_heap_size(const ma_loshelf2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_loshelf2_init_preallocated(const ma_loshelf2_config* pConfig, void* pHeap, ma_loshelf2* pFilter);\nMA_API ma_result ma_loshelf2_init(const ma_loshelf2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_loshelf2* pFilter);\nMA_API void ma_loshelf2_uninit(ma_loshelf2* pFilter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_loshelf2_reinit(const ma_loshelf2_config* pConfig, ma_loshelf2* pFilter);\nMA_API ma_result ma_loshelf2_process_pcm_frames(ma_loshelf2* pFilter, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_loshelf2_get_latency(const ma_loshelf2* pFilter);\n\n\n/**************************************************************************************************************************************************************\n\nHigh Shelf Filter\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double gainDB;\n    double shelfSlope;\n    double frequency;\n} ma_hishelf2_config, ma_hishelf_config;\n\nMA_API ma_hishelf2_config ma_hishelf2_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double gainDB, double shelfSlope, double frequency);\n\ntypedef struct\n{\n    ma_biquad bq;\n} ma_hishelf2;\n\nMA_API ma_result ma_hishelf2_get_heap_size(const ma_hishelf2_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_hishelf2_init_preallocated(const ma_hishelf2_config* pConfig, void* pHeap, ma_hishelf2* pFilter);\nMA_API ma_result ma_hishelf2_init(const ma_hishelf2_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_hishelf2* pFilter);\nMA_API void ma_hishelf2_uninit(ma_hishelf2* pFilter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_hishelf2_reinit(const ma_hishelf2_config* pConfig, ma_hishelf2* pFilter);\nMA_API ma_result ma_hishelf2_process_pcm_frames(ma_hishelf2* pFilter, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_uint32 ma_hishelf2_get_latency(const ma_hishelf2* pFilter);\n\n\n\n/*\nDelay\n*/\ntypedef struct\n{\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_uint32 delayInFrames;\n    ma_bool32 delayStart;       /* Set to true to delay the start of the output; false otherwise. */\n    float wet;                  /* 0..1. Default = 1. */\n    float dry;                  /* 0..1. Default = 1. */\n    float decay;                /* 0..1. Default = 0 (no feedback). Feedback decay. Use this for echo. */\n} ma_delay_config;\n\nMA_API ma_delay_config ma_delay_config_init(ma_uint32 channels, ma_uint32 sampleRate, ma_uint32 delayInFrames, float decay);\n\n\ntypedef struct\n{\n    ma_delay_config config;\n    ma_uint32 cursor;               /* Feedback is written to this cursor. Always equal or in front of the read cursor. */\n    ma_uint32 bufferSizeInFrames;\n    float* pBuffer;\n} ma_delay;\n\nMA_API ma_result ma_delay_init(const ma_delay_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_delay* pDelay);\nMA_API void ma_delay_uninit(ma_delay* pDelay, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_delay_process_pcm_frames(ma_delay* pDelay, void* pFramesOut, const void* pFramesIn, ma_uint32 frameCount);\nMA_API void ma_delay_set_wet(ma_delay* pDelay, float value);\nMA_API float ma_delay_get_wet(const ma_delay* pDelay);\nMA_API void ma_delay_set_dry(ma_delay* pDelay, float value);\nMA_API float ma_delay_get_dry(const ma_delay* pDelay);\nMA_API void ma_delay_set_decay(ma_delay* pDelay, float value);\nMA_API float ma_delay_get_decay(const ma_delay* pDelay);\n\n\n/* Gainer for smooth volume changes. */\ntypedef struct\n{\n    ma_uint32 channels;\n    ma_uint32 smoothTimeInFrames;\n} ma_gainer_config;\n\nMA_API ma_gainer_config ma_gainer_config_init(ma_uint32 channels, ma_uint32 smoothTimeInFrames);\n\n\ntypedef struct\n{\n    ma_gainer_config config;\n    ma_uint32 t;\n    float masterVolume;\n    float* pOldGains;\n    float* pNewGains;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_gainer;\n\nMA_API ma_result ma_gainer_get_heap_size(const ma_gainer_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_gainer_init_preallocated(const ma_gainer_config* pConfig, void* pHeap, ma_gainer* pGainer);\nMA_API ma_result ma_gainer_init(const ma_gainer_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_gainer* pGainer);\nMA_API void ma_gainer_uninit(ma_gainer* pGainer, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_gainer_process_pcm_frames(ma_gainer* pGainer, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_result ma_gainer_set_gain(ma_gainer* pGainer, float newGain);\nMA_API ma_result ma_gainer_set_gains(ma_gainer* pGainer, float* pNewGains);\nMA_API ma_result ma_gainer_set_master_volume(ma_gainer* pGainer, float volume);\nMA_API ma_result ma_gainer_get_master_volume(const ma_gainer* pGainer, float* pVolume);\n\n\n\n/* Stereo panner. */\ntypedef enum\n{\n    ma_pan_mode_balance = 0,    /* Does not blend one side with the other. Technically just a balance. Compatible with other popular audio engines and therefore the default. */\n    ma_pan_mode_pan             /* A true pan. The sound from one side will \"move\" to the other side and blend with it. */\n} ma_pan_mode;\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_pan_mode mode;\n    float pan;\n} ma_panner_config;\n\nMA_API ma_panner_config ma_panner_config_init(ma_format format, ma_uint32 channels);\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_pan_mode mode;\n    float pan;  /* -1..1 where 0 is no pan, -1 is left side, +1 is right side. Defaults to 0. */\n} ma_panner;\n\nMA_API ma_result ma_panner_init(const ma_panner_config* pConfig, ma_panner* pPanner);\nMA_API ma_result ma_panner_process_pcm_frames(ma_panner* pPanner, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API void ma_panner_set_mode(ma_panner* pPanner, ma_pan_mode mode);\nMA_API ma_pan_mode ma_panner_get_mode(const ma_panner* pPanner);\nMA_API void ma_panner_set_pan(ma_panner* pPanner, float pan);\nMA_API float ma_panner_get_pan(const ma_panner* pPanner);\n\n\n\n/* Fader. */\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n} ma_fader_config;\n\nMA_API ma_fader_config ma_fader_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate);\n\ntypedef struct\n{\n    ma_fader_config config;\n    float volumeBeg;            /* If volumeBeg and volumeEnd is equal to 1, no fading happens (ma_fader_process_pcm_frames() will run as a passthrough). */\n    float volumeEnd;\n    ma_uint64 lengthInFrames;   /* The total length of the fade. */\n    ma_int64  cursorInFrames;   /* The current time in frames. Incremented by ma_fader_process_pcm_frames(). Signed because it'll be offset by startOffsetInFrames in set_fade_ex(). */\n} ma_fader;\n\nMA_API ma_result ma_fader_init(const ma_fader_config* pConfig, ma_fader* pFader);\nMA_API ma_result ma_fader_process_pcm_frames(ma_fader* pFader, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API void ma_fader_get_data_format(const ma_fader* pFader, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate);\nMA_API void ma_fader_set_fade(ma_fader* pFader, float volumeBeg, float volumeEnd, ma_uint64 lengthInFrames);\nMA_API void ma_fader_set_fade_ex(ma_fader* pFader, float volumeBeg, float volumeEnd, ma_uint64 lengthInFrames, ma_int64 startOffsetInFrames);\nMA_API float ma_fader_get_current_volume(const ma_fader* pFader);\n\n\n\n/* Spatializer. */\ntypedef struct\n{\n    float x;\n    float y;\n    float z;\n} ma_vec3f;\n\ntypedef struct\n{\n    ma_vec3f v;\n    ma_spinlock lock;\n} ma_atomic_vec3f;\n\ntypedef enum\n{\n    ma_attenuation_model_none,          /* No distance attenuation and no spatialization. */\n    ma_attenuation_model_inverse,       /* Equivalent to OpenAL's AL_INVERSE_DISTANCE_CLAMPED. */\n    ma_attenuation_model_linear,        /* Linear attenuation. Equivalent to OpenAL's AL_LINEAR_DISTANCE_CLAMPED. */\n    ma_attenuation_model_exponential    /* Exponential attenuation. Equivalent to OpenAL's AL_EXPONENT_DISTANCE_CLAMPED. */\n} ma_attenuation_model;\n\ntypedef enum\n{\n    ma_positioning_absolute,\n    ma_positioning_relative\n} ma_positioning;\n\ntypedef enum\n{\n    ma_handedness_right,\n    ma_handedness_left\n} ma_handedness;\n\n\ntypedef struct\n{\n    ma_uint32 channelsOut;\n    ma_channel* pChannelMapOut;\n    ma_handedness handedness;   /* Defaults to right. Forward is -1 on the Z axis. In a left handed system, forward is +1 on the Z axis. */\n    float coneInnerAngleInRadians;\n    float coneOuterAngleInRadians;\n    float coneOuterGain;\n    float speedOfSound;\n    ma_vec3f worldUp;\n} ma_spatializer_listener_config;\n\nMA_API ma_spatializer_listener_config ma_spatializer_listener_config_init(ma_uint32 channelsOut);\n\n\ntypedef struct\n{\n    ma_spatializer_listener_config config;\n    ma_atomic_vec3f position;  /* The absolute position of the listener. */\n    ma_atomic_vec3f direction; /* The direction the listener is facing. The world up vector is config.worldUp. */\n    ma_atomic_vec3f velocity;\n    ma_bool32 isEnabled;\n\n    /* Memory management. */\n    ma_bool32 _ownsHeap;\n    void* _pHeap;\n} ma_spatializer_listener;\n\nMA_API ma_result ma_spatializer_listener_get_heap_size(const ma_spatializer_listener_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_spatializer_listener_init_preallocated(const ma_spatializer_listener_config* pConfig, void* pHeap, ma_spatializer_listener* pListener);\nMA_API ma_result ma_spatializer_listener_init(const ma_spatializer_listener_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_uninit(ma_spatializer_listener* pListener, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_channel* ma_spatializer_listener_get_channel_map(ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_cone(ma_spatializer_listener* pListener, float innerAngleInRadians, float outerAngleInRadians, float outerGain);\nMA_API void ma_spatializer_listener_get_cone(const ma_spatializer_listener* pListener, float* pInnerAngleInRadians, float* pOuterAngleInRadians, float* pOuterGain);\nMA_API void ma_spatializer_listener_set_position(ma_spatializer_listener* pListener, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_listener_get_position(const ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_direction(ma_spatializer_listener* pListener, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_listener_get_direction(const ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_velocity(ma_spatializer_listener* pListener, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_listener_get_velocity(const ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_speed_of_sound(ma_spatializer_listener* pListener, float speedOfSound);\nMA_API float ma_spatializer_listener_get_speed_of_sound(const ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_world_up(ma_spatializer_listener* pListener, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_listener_get_world_up(const ma_spatializer_listener* pListener);\nMA_API void ma_spatializer_listener_set_enabled(ma_spatializer_listener* pListener, ma_bool32 isEnabled);\nMA_API ma_bool32 ma_spatializer_listener_is_enabled(const ma_spatializer_listener* pListener);\n\n\ntypedef struct\n{\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    ma_channel* pChannelMapIn;\n    ma_attenuation_model attenuationModel;\n    ma_positioning positioning;\n    ma_handedness handedness;           /* Defaults to right. Forward is -1 on the Z axis. In a left handed system, forward is +1 on the Z axis. */\n    float minGain;\n    float maxGain;\n    float minDistance;\n    float maxDistance;\n    float rolloff;\n    float coneInnerAngleInRadians;\n    float coneOuterAngleInRadians;\n    float coneOuterGain;\n    float dopplerFactor;                /* Set to 0 to disable doppler effect. */\n    float directionalAttenuationFactor; /* Set to 0 to disable directional attenuation. */\n    float minSpatializationChannelGain; /* The minimal scaling factor to apply to channel gains when accounting for the direction of the sound relative to the listener. Must be in the range of 0..1. Smaller values means more aggressive directional panning, larger values means more subtle directional panning. */\n    ma_uint32 gainSmoothTimeInFrames;   /* When the gain of a channel changes during spatialization, the transition will be linearly interpolated over this number of frames. */\n} ma_spatializer_config;\n\nMA_API ma_spatializer_config ma_spatializer_config_init(ma_uint32 channelsIn, ma_uint32 channelsOut);\n\n\ntypedef struct\n{\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    ma_channel* pChannelMapIn;\n    ma_attenuation_model attenuationModel;\n    ma_positioning positioning;\n    ma_handedness handedness;           /* Defaults to right. Forward is -1 on the Z axis. In a left handed system, forward is +1 on the Z axis. */\n    float minGain;\n    float maxGain;\n    float minDistance;\n    float maxDistance;\n    float rolloff;\n    float coneInnerAngleInRadians;\n    float coneOuterAngleInRadians;\n    float coneOuterGain;\n    float dopplerFactor;                /* Set to 0 to disable doppler effect. */\n    float directionalAttenuationFactor; /* Set to 0 to disable directional attenuation. */\n    ma_uint32 gainSmoothTimeInFrames;   /* When the gain of a channel changes during spatialization, the transition will be linearly interpolated over this number of frames. */\n    ma_atomic_vec3f position;\n    ma_atomic_vec3f direction;\n    ma_atomic_vec3f velocity;  /* For doppler effect. */\n    float dopplerPitch; /* Will be updated by ma_spatializer_process_pcm_frames() and can be used by higher level functions to apply a pitch shift for doppler effect. */\n    float minSpatializationChannelGain;\n    ma_gainer gainer;   /* For smooth gain transitions. */\n    float* pNewChannelGainsOut; /* An offset of _pHeap. Used by ma_spatializer_process_pcm_frames() to store new channel gains. The number of elements in this array is equal to config.channelsOut. */\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_spatializer;\n\nMA_API ma_result ma_spatializer_get_heap_size(const ma_spatializer_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_spatializer_init_preallocated(const ma_spatializer_config* pConfig, void* pHeap, ma_spatializer* pSpatializer);\nMA_API ma_result ma_spatializer_init(const ma_spatializer_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_uninit(ma_spatializer* pSpatializer, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_spatializer_process_pcm_frames(ma_spatializer* pSpatializer, ma_spatializer_listener* pListener, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_result ma_spatializer_set_master_volume(ma_spatializer* pSpatializer, float volume);\nMA_API ma_result ma_spatializer_get_master_volume(const ma_spatializer* pSpatializer, float* pVolume);\nMA_API ma_uint32 ma_spatializer_get_input_channels(const ma_spatializer* pSpatializer);\nMA_API ma_uint32 ma_spatializer_get_output_channels(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_attenuation_model(ma_spatializer* pSpatializer, ma_attenuation_model attenuationModel);\nMA_API ma_attenuation_model ma_spatializer_get_attenuation_model(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_positioning(ma_spatializer* pSpatializer, ma_positioning positioning);\nMA_API ma_positioning ma_spatializer_get_positioning(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_rolloff(ma_spatializer* pSpatializer, float rolloff);\nMA_API float ma_spatializer_get_rolloff(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_min_gain(ma_spatializer* pSpatializer, float minGain);\nMA_API float ma_spatializer_get_min_gain(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_max_gain(ma_spatializer* pSpatializer, float maxGain);\nMA_API float ma_spatializer_get_max_gain(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_min_distance(ma_spatializer* pSpatializer, float minDistance);\nMA_API float ma_spatializer_get_min_distance(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_max_distance(ma_spatializer* pSpatializer, float maxDistance);\nMA_API float ma_spatializer_get_max_distance(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_cone(ma_spatializer* pSpatializer, float innerAngleInRadians, float outerAngleInRadians, float outerGain);\nMA_API void ma_spatializer_get_cone(const ma_spatializer* pSpatializer, float* pInnerAngleInRadians, float* pOuterAngleInRadians, float* pOuterGain);\nMA_API void ma_spatializer_set_doppler_factor(ma_spatializer* pSpatializer, float dopplerFactor);\nMA_API float ma_spatializer_get_doppler_factor(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_directional_attenuation_factor(ma_spatializer* pSpatializer, float directionalAttenuationFactor);\nMA_API float ma_spatializer_get_directional_attenuation_factor(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_position(ma_spatializer* pSpatializer, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_get_position(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_direction(ma_spatializer* pSpatializer, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_get_direction(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_set_velocity(ma_spatializer* pSpatializer, float x, float y, float z);\nMA_API ma_vec3f ma_spatializer_get_velocity(const ma_spatializer* pSpatializer);\nMA_API void ma_spatializer_get_relative_position_and_direction(const ma_spatializer* pSpatializer, const ma_spatializer_listener* pListener, ma_vec3f* pRelativePos, ma_vec3f* pRelativeDir);\n\n\n\n/************************************************************************************************************************************************************\n*************************************************************************************************************************************************************\n\nDATA CONVERSION\n===============\n\nThis section contains the APIs for data conversion. You will find everything here for channel mapping, sample format conversion, resampling, etc.\n\n*************************************************************************************************************************************************************\n************************************************************************************************************************************************************/\n\n/**************************************************************************************************************************************************************\n\nResampling\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRateIn;\n    ma_uint32 sampleRateOut;\n    ma_uint32 lpfOrder;         /* The low-pass filter order. Setting this to 0 will disable low-pass filtering. */\n    double    lpfNyquistFactor; /* 0..1. Defaults to 1. 1 = Half the sampling frequency (Nyquist Frequency), 0.5 = Quarter the sampling frequency (half Nyquest Frequency), etc. */\n} ma_linear_resampler_config;\n\nMA_API ma_linear_resampler_config ma_linear_resampler_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);\n\ntypedef struct\n{\n    ma_linear_resampler_config config;\n    ma_uint32 inAdvanceInt;\n    ma_uint32 inAdvanceFrac;\n    ma_uint32 inTimeInt;\n    ma_uint32 inTimeFrac;\n    union\n    {\n        float* f32;\n        ma_int16* s16;\n    } x0; /* The previous input frame. */\n    union\n    {\n        float* f32;\n        ma_int16* s16;\n    } x1; /* The next input frame. */\n    ma_lpf lpf;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_linear_resampler;\n\nMA_API ma_result ma_linear_resampler_get_heap_size(const ma_linear_resampler_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_linear_resampler_init_preallocated(const ma_linear_resampler_config* pConfig, void* pHeap, ma_linear_resampler* pResampler);\nMA_API ma_result ma_linear_resampler_init(const ma_linear_resampler_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_linear_resampler* pResampler);\nMA_API void ma_linear_resampler_uninit(ma_linear_resampler* pResampler, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_linear_resampler_process_pcm_frames(ma_linear_resampler* pResampler, const void* pFramesIn, ma_uint64* pFrameCountIn, void* pFramesOut, ma_uint64* pFrameCountOut);\nMA_API ma_result ma_linear_resampler_set_rate(ma_linear_resampler* pResampler, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);\nMA_API ma_result ma_linear_resampler_set_rate_ratio(ma_linear_resampler* pResampler, float ratioInOut);\nMA_API ma_uint64 ma_linear_resampler_get_input_latency(const ma_linear_resampler* pResampler);\nMA_API ma_uint64 ma_linear_resampler_get_output_latency(const ma_linear_resampler* pResampler);\nMA_API ma_result ma_linear_resampler_get_required_input_frame_count(const ma_linear_resampler* pResampler, ma_uint64 outputFrameCount, ma_uint64* pInputFrameCount);\nMA_API ma_result ma_linear_resampler_get_expected_output_frame_count(const ma_linear_resampler* pResampler, ma_uint64 inputFrameCount, ma_uint64* pOutputFrameCount);\nMA_API ma_result ma_linear_resampler_reset(ma_linear_resampler* pResampler);\n\n\ntypedef struct ma_resampler_config ma_resampler_config;\n\ntypedef void ma_resampling_backend;\ntypedef struct\n{\n    ma_result (* onGetHeapSize                )(void* pUserData, const ma_resampler_config* pConfig, size_t* pHeapSizeInBytes);\n    ma_result (* onInit                       )(void* pUserData, const ma_resampler_config* pConfig, void* pHeap, ma_resampling_backend** ppBackend);\n    void      (* onUninit                     )(void* pUserData, ma_resampling_backend* pBackend, const ma_allocation_callbacks* pAllocationCallbacks);\n    ma_result (* onProcess                    )(void* pUserData, ma_resampling_backend* pBackend, const void* pFramesIn, ma_uint64* pFrameCountIn, void* pFramesOut, ma_uint64* pFrameCountOut);\n    ma_result (* onSetRate                    )(void* pUserData, ma_resampling_backend* pBackend, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);                 /* Optional. Rate changes will be disabled. */\n    ma_uint64 (* onGetInputLatency            )(void* pUserData, const ma_resampling_backend* pBackend);                                                            /* Optional. Latency will be reported as 0. */\n    ma_uint64 (* onGetOutputLatency           )(void* pUserData, const ma_resampling_backend* pBackend);                                                            /* Optional. Latency will be reported as 0. */\n    ma_result (* onGetRequiredInputFrameCount )(void* pUserData, const ma_resampling_backend* pBackend, ma_uint64 outputFrameCount, ma_uint64* pInputFrameCount);   /* Optional. Latency mitigation will be disabled. */\n    ma_result (* onGetExpectedOutputFrameCount)(void* pUserData, const ma_resampling_backend* pBackend, ma_uint64 inputFrameCount, ma_uint64* pOutputFrameCount);   /* Optional. Latency mitigation will be disabled. */\n    ma_result (* onReset                      )(void* pUserData, ma_resampling_backend* pBackend);\n} ma_resampling_backend_vtable;\n\ntypedef enum\n{\n    ma_resample_algorithm_linear = 0,    /* Fastest, lowest quality. Optional low-pass filtering. Default. */\n    ma_resample_algorithm_custom,\n} ma_resample_algorithm;\n\nstruct ma_resampler_config\n{\n    ma_format format;   /* Must be either ma_format_f32 or ma_format_s16. */\n    ma_uint32 channels;\n    ma_uint32 sampleRateIn;\n    ma_uint32 sampleRateOut;\n    ma_resample_algorithm algorithm;    /* When set to ma_resample_algorithm_custom, pBackendVTable will be used. */\n    ma_resampling_backend_vtable* pBackendVTable;\n    void* pBackendUserData;\n    struct\n    {\n        ma_uint32 lpfOrder;\n    } linear;\n};\n\nMA_API ma_resampler_config ma_resampler_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut, ma_resample_algorithm algorithm);\n\ntypedef struct\n{\n    ma_resampling_backend* pBackend;\n    ma_resampling_backend_vtable* pBackendVTable;\n    void* pBackendUserData;\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRateIn;\n    ma_uint32 sampleRateOut;\n    union\n    {\n        ma_linear_resampler linear;\n    } state;    /* State for stock resamplers so we can avoid a malloc. For stock resamplers, pBackend will point here. */\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_resampler;\n\nMA_API ma_result ma_resampler_get_heap_size(const ma_resampler_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_resampler_init_preallocated(const ma_resampler_config* pConfig, void* pHeap, ma_resampler* pResampler);\n\n/*\nInitializes a new resampler object from a config.\n*/\nMA_API ma_result ma_resampler_init(const ma_resampler_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_resampler* pResampler);\n\n/*\nUninitializes a resampler.\n*/\nMA_API void ma_resampler_uninit(ma_resampler* pResampler, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nConverts the given input data.\n\nBoth the input and output frames must be in the format specified in the config when the resampler was initialized.\n\nOn input, [pFrameCountOut] contains the number of output frames to process. On output it contains the number of output frames that\nwere actually processed, which may be less than the requested amount which will happen if there's not enough input data. You can use\nma_resampler_get_expected_output_frame_count() to know how many output frames will be processed for a given number of input frames.\n\nOn input, [pFrameCountIn] contains the number of input frames contained in [pFramesIn]. On output it contains the number of whole\ninput frames that were actually processed. You can use ma_resampler_get_required_input_frame_count() to know how many input frames\nyou should provide for a given number of output frames. [pFramesIn] can be NULL, in which case zeroes will be used instead.\n\nIf [pFramesOut] is NULL, a seek is performed. In this case, if [pFrameCountOut] is not NULL it will seek by the specified number of\noutput frames. Otherwise, if [pFramesCountOut] is NULL and [pFrameCountIn] is not NULL, it will seek by the specified number of input\nframes. When seeking, [pFramesIn] is allowed to NULL, in which case the internal timing state will be updated, but no input will be\nprocessed. In this case, any internal filter state will be updated as if zeroes were passed in.\n\nIt is an error for [pFramesOut] to be non-NULL and [pFrameCountOut] to be NULL.\n\nIt is an error for both [pFrameCountOut] and [pFrameCountIn] to be NULL.\n*/\nMA_API ma_result ma_resampler_process_pcm_frames(ma_resampler* pResampler, const void* pFramesIn, ma_uint64* pFrameCountIn, void* pFramesOut, ma_uint64* pFrameCountOut);\n\n\n/*\nSets the input and output sample rate.\n*/\nMA_API ma_result ma_resampler_set_rate(ma_resampler* pResampler, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);\n\n/*\nSets the input and output sample rate as a ratio.\n\nThe ration is in/out.\n*/\nMA_API ma_result ma_resampler_set_rate_ratio(ma_resampler* pResampler, float ratio);\n\n/*\nRetrieves the latency introduced by the resampler in input frames.\n*/\nMA_API ma_uint64 ma_resampler_get_input_latency(const ma_resampler* pResampler);\n\n/*\nRetrieves the latency introduced by the resampler in output frames.\n*/\nMA_API ma_uint64 ma_resampler_get_output_latency(const ma_resampler* pResampler);\n\n/*\nCalculates the number of whole input frames that would need to be read from the client in order to output the specified\nnumber of output frames.\n\nThe returned value does not include cached input frames. It only returns the number of extra frames that would need to be\nread from the input buffer in order to output the specified number of output frames.\n*/\nMA_API ma_result ma_resampler_get_required_input_frame_count(const ma_resampler* pResampler, ma_uint64 outputFrameCount, ma_uint64* pInputFrameCount);\n\n/*\nCalculates the number of whole output frames that would be output after fully reading and consuming the specified number of\ninput frames.\n*/\nMA_API ma_result ma_resampler_get_expected_output_frame_count(const ma_resampler* pResampler, ma_uint64 inputFrameCount, ma_uint64* pOutputFrameCount);\n\n/*\nResets the resampler's timer and clears it's internal cache.\n*/\nMA_API ma_result ma_resampler_reset(ma_resampler* pResampler);\n\n\n/**************************************************************************************************************************************************************\n\nChannel Conversion\n\n**************************************************************************************************************************************************************/\ntypedef enum\n{\n    ma_channel_conversion_path_unknown,\n    ma_channel_conversion_path_passthrough,\n    ma_channel_conversion_path_mono_out,    /* Converting to mono. */\n    ma_channel_conversion_path_mono_in,     /* Converting from mono. */\n    ma_channel_conversion_path_shuffle,     /* Simple shuffle. Will use this when all channels are present in both input and output channel maps, but just in a different order. */\n    ma_channel_conversion_path_weights      /* Blended based on weights. */\n} ma_channel_conversion_path;\n\ntypedef enum\n{\n    ma_mono_expansion_mode_duplicate = 0,   /* The default. */\n    ma_mono_expansion_mode_average,         /* Average the mono channel across all channels. */\n    ma_mono_expansion_mode_stereo_only,     /* Duplicate to the left and right channels only and ignore the others. */\n    ma_mono_expansion_mode_default = ma_mono_expansion_mode_duplicate\n} ma_mono_expansion_mode;\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    const ma_channel* pChannelMapIn;\n    const ma_channel* pChannelMapOut;\n    ma_channel_mix_mode mixingMode;\n    ma_bool32 calculateLFEFromSpatialChannels;  /* When an output LFE channel is present, but no input LFE, set to true to set the output LFE to the average of all spatial channels (LR, FR, etc.). Ignored when an input LFE is present. */\n    float** ppWeights;  /* [in][out]. Only used when mixingMode is set to ma_channel_mix_mode_custom_weights. */\n} ma_channel_converter_config;\n\nMA_API ma_channel_converter_config ma_channel_converter_config_init(ma_format format, ma_uint32 channelsIn, const ma_channel* pChannelMapIn, ma_uint32 channelsOut, const ma_channel* pChannelMapOut, ma_channel_mix_mode mixingMode);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    ma_channel_mix_mode mixingMode;\n    ma_channel_conversion_path conversionPath;\n    ma_channel* pChannelMapIn;\n    ma_channel* pChannelMapOut;\n    ma_uint8* pShuffleTable;    /* Indexed by output channel index. */\n    union\n    {\n        float**    f32;\n        ma_int32** s16;\n    } weights;  /* [in][out] */\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_channel_converter;\n\nMA_API ma_result ma_channel_converter_get_heap_size(const ma_channel_converter_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_channel_converter_init_preallocated(const ma_channel_converter_config* pConfig, void* pHeap, ma_channel_converter* pConverter);\nMA_API ma_result ma_channel_converter_init(const ma_channel_converter_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_channel_converter* pConverter);\nMA_API void ma_channel_converter_uninit(ma_channel_converter* pConverter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_channel_converter_process_pcm_frames(ma_channel_converter* pConverter, void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount);\nMA_API ma_result ma_channel_converter_get_input_channel_map(const ma_channel_converter* pConverter, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_channel_converter_get_output_channel_map(const ma_channel_converter* pConverter, ma_channel* pChannelMap, size_t channelMapCap);\n\n\n/**************************************************************************************************************************************************************\n\nData Conversion\n\n**************************************************************************************************************************************************************/\ntypedef struct\n{\n    ma_format formatIn;\n    ma_format formatOut;\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    ma_uint32 sampleRateIn;\n    ma_uint32 sampleRateOut;\n    ma_channel* pChannelMapIn;\n    ma_channel* pChannelMapOut;\n    ma_dither_mode ditherMode;\n    ma_channel_mix_mode channelMixMode;\n    ma_bool32 calculateLFEFromSpatialChannels;  /* When an output LFE channel is present, but no input LFE, set to true to set the output LFE to the average of all spatial channels (LR, FR, etc.). Ignored when an input LFE is present. */\n    float** ppChannelWeights;  /* [in][out]. Only used when mixingMode is set to ma_channel_mix_mode_custom_weights. */\n    ma_bool32 allowDynamicSampleRate;\n    ma_resampler_config resampling;\n} ma_data_converter_config;\n\nMA_API ma_data_converter_config ma_data_converter_config_init_default(void);\nMA_API ma_data_converter_config ma_data_converter_config_init(ma_format formatIn, ma_format formatOut, ma_uint32 channelsIn, ma_uint32 channelsOut, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);\n\n\ntypedef enum\n{\n    ma_data_converter_execution_path_passthrough,       /* No conversion. */\n    ma_data_converter_execution_path_format_only,       /* Only format conversion. */\n    ma_data_converter_execution_path_channels_only,     /* Only channel conversion. */\n    ma_data_converter_execution_path_resample_only,     /* Only resampling. */\n    ma_data_converter_execution_path_resample_first,    /* All conversions, but resample as the first step. */\n    ma_data_converter_execution_path_channels_first     /* All conversions, but channels as the first step. */\n} ma_data_converter_execution_path;\n\ntypedef struct\n{\n    ma_format formatIn;\n    ma_format formatOut;\n    ma_uint32 channelsIn;\n    ma_uint32 channelsOut;\n    ma_uint32 sampleRateIn;\n    ma_uint32 sampleRateOut;\n    ma_dither_mode ditherMode;\n    ma_data_converter_execution_path executionPath; /* The execution path the data converter will follow when processing. */\n    ma_channel_converter channelConverter;\n    ma_resampler resampler;\n    ma_bool8 hasPreFormatConversion;\n    ma_bool8 hasPostFormatConversion;\n    ma_bool8 hasChannelConverter;\n    ma_bool8 hasResampler;\n    ma_bool8 isPassthrough;\n\n    /* Memory management. */\n    ma_bool8 _ownsHeap;\n    void* _pHeap;\n} ma_data_converter;\n\nMA_API ma_result ma_data_converter_get_heap_size(const ma_data_converter_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_data_converter_init_preallocated(const ma_data_converter_config* pConfig, void* pHeap, ma_data_converter* pConverter);\nMA_API ma_result ma_data_converter_init(const ma_data_converter_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_data_converter* pConverter);\nMA_API void ma_data_converter_uninit(ma_data_converter* pConverter, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_data_converter_process_pcm_frames(ma_data_converter* pConverter, const void* pFramesIn, ma_uint64* pFrameCountIn, void* pFramesOut, ma_uint64* pFrameCountOut);\nMA_API ma_result ma_data_converter_set_rate(ma_data_converter* pConverter, ma_uint32 sampleRateIn, ma_uint32 sampleRateOut);\nMA_API ma_result ma_data_converter_set_rate_ratio(ma_data_converter* pConverter, float ratioInOut);\nMA_API ma_uint64 ma_data_converter_get_input_latency(const ma_data_converter* pConverter);\nMA_API ma_uint64 ma_data_converter_get_output_latency(const ma_data_converter* pConverter);\nMA_API ma_result ma_data_converter_get_required_input_frame_count(const ma_data_converter* pConverter, ma_uint64 outputFrameCount, ma_uint64* pInputFrameCount);\nMA_API ma_result ma_data_converter_get_expected_output_frame_count(const ma_data_converter* pConverter, ma_uint64 inputFrameCount, ma_uint64* pOutputFrameCount);\nMA_API ma_result ma_data_converter_get_input_channel_map(const ma_data_converter* pConverter, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_data_converter_get_output_channel_map(const ma_data_converter* pConverter, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_data_converter_reset(ma_data_converter* pConverter);\n\n\n/************************************************************************************************************************************************************\n\nFormat Conversion\n\n************************************************************************************************************************************************************/\nMA_API void ma_pcm_u8_to_s16(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_u8_to_s24(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_u8_to_s32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_u8_to_f32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s16_to_u8(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s16_to_s24(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s16_to_s32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s16_to_f32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s24_to_u8(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s24_to_s16(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s24_to_s32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s24_to_f32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s32_to_u8(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s32_to_s16(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s32_to_s24(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_s32_to_f32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_f32_to_u8(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_f32_to_s16(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_f32_to_s24(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_f32_to_s32(void* pOut, const void* pIn, ma_uint64 count, ma_dither_mode ditherMode);\nMA_API void ma_pcm_convert(void* pOut, ma_format formatOut, const void* pIn, ma_format formatIn, ma_uint64 sampleCount, ma_dither_mode ditherMode);\nMA_API void ma_convert_pcm_frames_format(void* pOut, ma_format formatOut, const void* pIn, ma_format formatIn, ma_uint64 frameCount, ma_uint32 channels, ma_dither_mode ditherMode);\n\n/*\nDeinterleaves an interleaved buffer.\n*/\nMA_API void ma_deinterleave_pcm_frames(ma_format format, ma_uint32 channels, ma_uint64 frameCount, const void* pInterleavedPCMFrames, void** ppDeinterleavedPCMFrames);\n\n/*\nInterleaves a group of deinterleaved buffers.\n*/\nMA_API void ma_interleave_pcm_frames(ma_format format, ma_uint32 channels, ma_uint64 frameCount, const void** ppDeinterleavedPCMFrames, void* pInterleavedPCMFrames);\n\n\n/************************************************************************************************************************************************************\n\nChannel Maps\n\n************************************************************************************************************************************************************/\n/*\nThis is used in the shuffle table to indicate that the channel index is undefined and should be ignored.\n*/\n#define MA_CHANNEL_INDEX_NULL   255\n\n/*\nRetrieves the channel position of the specified channel in the given channel map.\n\nThe pChannelMap parameter can be null, in which case miniaudio's default channel map will be assumed.\n*/\nMA_API ma_channel ma_channel_map_get_channel(const ma_channel* pChannelMap, ma_uint32 channelCount, ma_uint32 channelIndex);\n\n/*\nInitializes a blank channel map.\n\nWhen a blank channel map is specified anywhere it indicates that the native channel map should be used.\n*/\nMA_API void ma_channel_map_init_blank(ma_channel* pChannelMap, ma_uint32 channels);\n\n/*\nHelper for retrieving a standard channel map.\n\nThe output channel map buffer must have a capacity of at least `channelMapCap`.\n*/\nMA_API void ma_channel_map_init_standard(ma_standard_channel_map standardChannelMap, ma_channel* pChannelMap, size_t channelMapCap, ma_uint32 channels);\n\n/*\nCopies a channel map.\n\nBoth input and output channel map buffers must have a capacity of at at least `channels`.\n*/\nMA_API void ma_channel_map_copy(ma_channel* pOut, const ma_channel* pIn, ma_uint32 channels);\n\n/*\nCopies a channel map if one is specified, otherwise copies the default channel map.\n\nThe output buffer must have a capacity of at least `channels`. If not NULL, the input channel map must also have a capacity of at least `channels`.\n*/\nMA_API void ma_channel_map_copy_or_default(ma_channel* pOut, size_t channelMapCapOut, const ma_channel* pIn, ma_uint32 channels);\n\n\n/*\nDetermines whether or not a channel map is valid.\n\nA blank channel map is valid (all channels set to MA_CHANNEL_NONE). The way a blank channel map is handled is context specific, but\nis usually treated as a passthrough.\n\nInvalid channel maps:\n  - A channel map with no channels\n  - A channel map with more than one channel and a mono channel\n\nThe channel map buffer must have a capacity of at least `channels`.\n*/\nMA_API ma_bool32 ma_channel_map_is_valid(const ma_channel* pChannelMap, ma_uint32 channels);\n\n/*\nHelper for comparing two channel maps for equality.\n\nThis assumes the channel count is the same between the two.\n\nBoth channels map buffers must have a capacity of at least `channels`.\n*/\nMA_API ma_bool32 ma_channel_map_is_equal(const ma_channel* pChannelMapA, const ma_channel* pChannelMapB, ma_uint32 channels);\n\n/*\nHelper for determining if a channel map is blank (all channels set to MA_CHANNEL_NONE).\n\nThe channel map buffer must have a capacity of at least `channels`.\n*/\nMA_API ma_bool32 ma_channel_map_is_blank(const ma_channel* pChannelMap, ma_uint32 channels);\n\n/*\nHelper for determining whether or not a channel is present in the given channel map.\n\nThe channel map buffer must have a capacity of at least `channels`.\n*/\nMA_API ma_bool32 ma_channel_map_contains_channel_position(ma_uint32 channels, const ma_channel* pChannelMap, ma_channel channelPosition);\n\n/*\nFind a channel position in the given channel map. Returns MA_TRUE if the channel is found; MA_FALSE otherwise. The\nindex of the channel is output to `pChannelIndex`.\n\nThe channel map buffer must have a capacity of at least `channels`.\n*/\nMA_API ma_bool32 ma_channel_map_find_channel_position(ma_uint32 channels, const ma_channel* pChannelMap, ma_channel channelPosition, ma_uint32* pChannelIndex);\n\n/*\nGenerates a string representing the given channel map.\n\nThis is for printing and debugging purposes, not serialization/deserialization.\n\nReturns the length of the string, not including the null terminator.\n*/\nMA_API size_t ma_channel_map_to_string(const ma_channel* pChannelMap, ma_uint32 channels, char* pBufferOut, size_t bufferCap);\n\n/*\nRetrieves a human readable version of a channel position.\n*/\nMA_API const char* ma_channel_position_to_string(ma_channel channel);\n\n\n/************************************************************************************************************************************************************\n\nConversion Helpers\n\n************************************************************************************************************************************************************/\n\n/*\nHigh-level helper for doing a full format conversion in one go. Returns the number of output frames. Call this with pOut set to NULL to\ndetermine the required size of the output buffer. frameCountOut should be set to the capacity of pOut. If pOut is NULL, frameCountOut is\nignored.\n\nA return value of 0 indicates an error.\n\nThis function is useful for one-off bulk conversions, but if you're streaming data you should use the ma_data_converter APIs instead.\n*/\nMA_API ma_uint64 ma_convert_frames(void* pOut, ma_uint64 frameCountOut, ma_format formatOut, ma_uint32 channelsOut, ma_uint32 sampleRateOut, const void* pIn, ma_uint64 frameCountIn, ma_format formatIn, ma_uint32 channelsIn, ma_uint32 sampleRateIn);\nMA_API ma_uint64 ma_convert_frames_ex(void* pOut, ma_uint64 frameCountOut, const void* pIn, ma_uint64 frameCountIn, const ma_data_converter_config* pConfig);\n\n\n/************************************************************************************************************************************************************\n\nData Source\n\n************************************************************************************************************************************************************/\ntypedef void ma_data_source;\n\n#define MA_DATA_SOURCE_SELF_MANAGED_RANGE_AND_LOOP_POINT    0x00000001\n\ntypedef struct\n{\n    ma_result (* onRead)(ma_data_source* pDataSource, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\n    ma_result (* onSeek)(ma_data_source* pDataSource, ma_uint64 frameIndex);\n    ma_result (* onGetDataFormat)(ma_data_source* pDataSource, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\n    ma_result (* onGetCursor)(ma_data_source* pDataSource, ma_uint64* pCursor);\n    ma_result (* onGetLength)(ma_data_source* pDataSource, ma_uint64* pLength);\n    ma_result (* onSetLooping)(ma_data_source* pDataSource, ma_bool32 isLooping);\n    ma_uint32 flags;\n} ma_data_source_vtable;\n\ntypedef ma_data_source* (* ma_data_source_get_next_proc)(ma_data_source* pDataSource);\n\ntypedef struct\n{\n    const ma_data_source_vtable* vtable;\n} ma_data_source_config;\n\nMA_API ma_data_source_config ma_data_source_config_init(void);\n\n\ntypedef struct\n{\n    const ma_data_source_vtable* vtable;\n    ma_uint64 rangeBegInFrames;\n    ma_uint64 rangeEndInFrames;             /* Set to -1 for unranged (default). */\n    ma_uint64 loopBegInFrames;              /* Relative to rangeBegInFrames. */\n    ma_uint64 loopEndInFrames;              /* Relative to rangeBegInFrames. Set to -1 for the end of the range. */\n    ma_data_source* pCurrent;               /* When non-NULL, the data source being initialized will act as a proxy and will route all operations to pCurrent. Used in conjunction with pNext/onGetNext for seamless chaining. */\n    ma_data_source* pNext;                  /* When set to NULL, onGetNext will be used. */\n    ma_data_source_get_next_proc onGetNext; /* Will be used when pNext is NULL. If both are NULL, no next will be used. */\n    MA_ATOMIC(4, ma_bool32) isLooping;\n} ma_data_source_base;\n\nMA_API ma_result ma_data_source_init(const ma_data_source_config* pConfig, ma_data_source* pDataSource);\nMA_API void ma_data_source_uninit(ma_data_source* pDataSource);\nMA_API ma_result ma_data_source_read_pcm_frames(ma_data_source* pDataSource, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);   /* Must support pFramesOut = NULL in which case a forward seek should be performed. */\nMA_API ma_result ma_data_source_seek_pcm_frames(ma_data_source* pDataSource, ma_uint64 frameCount, ma_uint64* pFramesSeeked); /* Can only seek forward. Equivalent to ma_data_source_read_pcm_frames(pDataSource, NULL, frameCount, &framesRead); */\nMA_API ma_result ma_data_source_seek_to_pcm_frame(ma_data_source* pDataSource, ma_uint64 frameIndex);\nMA_API ma_result ma_data_source_get_data_format(ma_data_source* pDataSource, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_data_source_get_cursor_in_pcm_frames(ma_data_source* pDataSource, ma_uint64* pCursor);\nMA_API ma_result ma_data_source_get_length_in_pcm_frames(ma_data_source* pDataSource, ma_uint64* pLength);    /* Returns MA_NOT_IMPLEMENTED if the length is unknown or cannot be determined. Decoders can return this. */\nMA_API ma_result ma_data_source_get_cursor_in_seconds(ma_data_source* pDataSource, float* pCursor);\nMA_API ma_result ma_data_source_get_length_in_seconds(ma_data_source* pDataSource, float* pLength);\nMA_API ma_result ma_data_source_set_looping(ma_data_source* pDataSource, ma_bool32 isLooping);\nMA_API ma_bool32 ma_data_source_is_looping(const ma_data_source* pDataSource);\nMA_API ma_result ma_data_source_set_range_in_pcm_frames(ma_data_source* pDataSource, ma_uint64 rangeBegInFrames, ma_uint64 rangeEndInFrames);\nMA_API void ma_data_source_get_range_in_pcm_frames(const ma_data_source* pDataSource, ma_uint64* pRangeBegInFrames, ma_uint64* pRangeEndInFrames);\nMA_API ma_result ma_data_source_set_loop_point_in_pcm_frames(ma_data_source* pDataSource, ma_uint64 loopBegInFrames, ma_uint64 loopEndInFrames);\nMA_API void ma_data_source_get_loop_point_in_pcm_frames(const ma_data_source* pDataSource, ma_uint64* pLoopBegInFrames, ma_uint64* pLoopEndInFrames);\nMA_API ma_result ma_data_source_set_current(ma_data_source* pDataSource, ma_data_source* pCurrentDataSource);\nMA_API ma_data_source* ma_data_source_get_current(const ma_data_source* pDataSource);\nMA_API ma_result ma_data_source_set_next(ma_data_source* pDataSource, ma_data_source* pNextDataSource);\nMA_API ma_data_source* ma_data_source_get_next(const ma_data_source* pDataSource);\nMA_API ma_result ma_data_source_set_next_callback(ma_data_source* pDataSource, ma_data_source_get_next_proc onGetNext);\nMA_API ma_data_source_get_next_proc ma_data_source_get_next_callback(const ma_data_source* pDataSource);\n\n\ntypedef struct\n{\n    ma_data_source_base ds;\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_uint64 cursor;\n    ma_uint64 sizeInFrames;\n    const void* pData;\n} ma_audio_buffer_ref;\n\nMA_API ma_result ma_audio_buffer_ref_init(ma_format format, ma_uint32 channels, const void* pData, ma_uint64 sizeInFrames, ma_audio_buffer_ref* pAudioBufferRef);\nMA_API void ma_audio_buffer_ref_uninit(ma_audio_buffer_ref* pAudioBufferRef);\nMA_API ma_result ma_audio_buffer_ref_set_data(ma_audio_buffer_ref* pAudioBufferRef, const void* pData, ma_uint64 sizeInFrames);\nMA_API ma_uint64 ma_audio_buffer_ref_read_pcm_frames(ma_audio_buffer_ref* pAudioBufferRef, void* pFramesOut, ma_uint64 frameCount, ma_bool32 loop);\nMA_API ma_result ma_audio_buffer_ref_seek_to_pcm_frame(ma_audio_buffer_ref* pAudioBufferRef, ma_uint64 frameIndex);\nMA_API ma_result ma_audio_buffer_ref_map(ma_audio_buffer_ref* pAudioBufferRef, void** ppFramesOut, ma_uint64* pFrameCount);\nMA_API ma_result ma_audio_buffer_ref_unmap(ma_audio_buffer_ref* pAudioBufferRef, ma_uint64 frameCount);    /* Returns MA_AT_END if the end has been reached. This should be considered successful. */\nMA_API ma_bool32 ma_audio_buffer_ref_at_end(const ma_audio_buffer_ref* pAudioBufferRef);\nMA_API ma_result ma_audio_buffer_ref_get_cursor_in_pcm_frames(const ma_audio_buffer_ref* pAudioBufferRef, ma_uint64* pCursor);\nMA_API ma_result ma_audio_buffer_ref_get_length_in_pcm_frames(const ma_audio_buffer_ref* pAudioBufferRef, ma_uint64* pLength);\nMA_API ma_result ma_audio_buffer_ref_get_available_frames(const ma_audio_buffer_ref* pAudioBufferRef, ma_uint64* pAvailableFrames);\n\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_uint64 sizeInFrames;\n    const void* pData;  /* If set to NULL, will allocate a block of memory for you. */\n    ma_allocation_callbacks allocationCallbacks;\n} ma_audio_buffer_config;\n\nMA_API ma_audio_buffer_config ma_audio_buffer_config_init(ma_format format, ma_uint32 channels, ma_uint64 sizeInFrames, const void* pData, const ma_allocation_callbacks* pAllocationCallbacks);\n\ntypedef struct\n{\n    ma_audio_buffer_ref ref;\n    ma_allocation_callbacks allocationCallbacks;\n    ma_bool32 ownsData;             /* Used to control whether or not miniaudio owns the data buffer. If set to true, pData will be freed in ma_audio_buffer_uninit(). */\n    ma_uint8 _pExtraData[1];        /* For allocating a buffer with the memory located directly after the other memory of the structure. */\n} ma_audio_buffer;\n\nMA_API ma_result ma_audio_buffer_init(const ma_audio_buffer_config* pConfig, ma_audio_buffer* pAudioBuffer);\nMA_API ma_result ma_audio_buffer_init_copy(const ma_audio_buffer_config* pConfig, ma_audio_buffer* pAudioBuffer);\nMA_API ma_result ma_audio_buffer_alloc_and_init(const ma_audio_buffer_config* pConfig, ma_audio_buffer** ppAudioBuffer);  /* Always copies the data. Doesn't make sense to use this otherwise. Use ma_audio_buffer_uninit_and_free() to uninit. */\nMA_API void ma_audio_buffer_uninit(ma_audio_buffer* pAudioBuffer);\nMA_API void ma_audio_buffer_uninit_and_free(ma_audio_buffer* pAudioBuffer);\nMA_API ma_uint64 ma_audio_buffer_read_pcm_frames(ma_audio_buffer* pAudioBuffer, void* pFramesOut, ma_uint64 frameCount, ma_bool32 loop);\nMA_API ma_result ma_audio_buffer_seek_to_pcm_frame(ma_audio_buffer* pAudioBuffer, ma_uint64 frameIndex);\nMA_API ma_result ma_audio_buffer_map(ma_audio_buffer* pAudioBuffer, void** ppFramesOut, ma_uint64* pFrameCount);\nMA_API ma_result ma_audio_buffer_unmap(ma_audio_buffer* pAudioBuffer, ma_uint64 frameCount);    /* Returns MA_AT_END if the end has been reached. This should be considered successful. */\nMA_API ma_bool32 ma_audio_buffer_at_end(const ma_audio_buffer* pAudioBuffer);\nMA_API ma_result ma_audio_buffer_get_cursor_in_pcm_frames(const ma_audio_buffer* pAudioBuffer, ma_uint64* pCursor);\nMA_API ma_result ma_audio_buffer_get_length_in_pcm_frames(const ma_audio_buffer* pAudioBuffer, ma_uint64* pLength);\nMA_API ma_result ma_audio_buffer_get_available_frames(const ma_audio_buffer* pAudioBuffer, ma_uint64* pAvailableFrames);\n\n\n/*\nPaged Audio Buffer\n==================\nA paged audio buffer is made up of a linked list of pages. It's expandable, but not shrinkable. It\ncan be used for cases where audio data is streamed in asynchronously while allowing data to be read\nat the same time.\n\nThis is lock-free, but not 100% thread safe. You can append a page and read from the buffer across\nsimultaneously across different threads, however only one thread at a time can append, and only one\nthread at a time can read and seek.\n*/\ntypedef struct ma_paged_audio_buffer_page ma_paged_audio_buffer_page;\nstruct ma_paged_audio_buffer_page\n{\n    MA_ATOMIC(MA_SIZEOF_PTR, ma_paged_audio_buffer_page*) pNext;\n    ma_uint64 sizeInFrames;\n    ma_uint8 pAudioData[1];\n};\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_paged_audio_buffer_page head;                                /* Dummy head for the lock-free algorithm. Always has a size of 0. */\n    MA_ATOMIC(MA_SIZEOF_PTR, ma_paged_audio_buffer_page*) pTail;    /* Never null. Initially set to &head. */\n} ma_paged_audio_buffer_data;\n\nMA_API ma_result ma_paged_audio_buffer_data_init(ma_format format, ma_uint32 channels, ma_paged_audio_buffer_data* pData);\nMA_API void ma_paged_audio_buffer_data_uninit(ma_paged_audio_buffer_data* pData, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_paged_audio_buffer_page* ma_paged_audio_buffer_data_get_head(ma_paged_audio_buffer_data* pData);\nMA_API ma_paged_audio_buffer_page* ma_paged_audio_buffer_data_get_tail(ma_paged_audio_buffer_data* pData);\nMA_API ma_result ma_paged_audio_buffer_data_get_length_in_pcm_frames(ma_paged_audio_buffer_data* pData, ma_uint64* pLength);\nMA_API ma_result ma_paged_audio_buffer_data_allocate_page(ma_paged_audio_buffer_data* pData, ma_uint64 pageSizeInFrames, const void* pInitialData, const ma_allocation_callbacks* pAllocationCallbacks, ma_paged_audio_buffer_page** ppPage);\nMA_API ma_result ma_paged_audio_buffer_data_free_page(ma_paged_audio_buffer_data* pData, ma_paged_audio_buffer_page* pPage, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_paged_audio_buffer_data_append_page(ma_paged_audio_buffer_data* pData, ma_paged_audio_buffer_page* pPage);\nMA_API ma_result ma_paged_audio_buffer_data_allocate_and_append_page(ma_paged_audio_buffer_data* pData, ma_uint32 pageSizeInFrames, const void* pInitialData, const ma_allocation_callbacks* pAllocationCallbacks);\n\n\ntypedef struct\n{\n    ma_paged_audio_buffer_data* pData;  /* Must not be null. */\n} ma_paged_audio_buffer_config;\n\nMA_API ma_paged_audio_buffer_config ma_paged_audio_buffer_config_init(ma_paged_audio_buffer_data* pData);\n\n\ntypedef struct\n{\n    ma_data_source_base ds;\n    ma_paged_audio_buffer_data* pData;              /* Audio data is read from here. Cannot be null. */\n    ma_paged_audio_buffer_page* pCurrent;\n    ma_uint64 relativeCursor;                       /* Relative to the current page. */\n    ma_uint64 absoluteCursor;\n} ma_paged_audio_buffer;\n\nMA_API ma_result ma_paged_audio_buffer_init(const ma_paged_audio_buffer_config* pConfig, ma_paged_audio_buffer* pPagedAudioBuffer);\nMA_API void ma_paged_audio_buffer_uninit(ma_paged_audio_buffer* pPagedAudioBuffer);\nMA_API ma_result ma_paged_audio_buffer_read_pcm_frames(ma_paged_audio_buffer* pPagedAudioBuffer, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);   /* Returns MA_AT_END if no more pages available. */\nMA_API ma_result ma_paged_audio_buffer_seek_to_pcm_frame(ma_paged_audio_buffer* pPagedAudioBuffer, ma_uint64 frameIndex);\nMA_API ma_result ma_paged_audio_buffer_get_cursor_in_pcm_frames(ma_paged_audio_buffer* pPagedAudioBuffer, ma_uint64* pCursor);\nMA_API ma_result ma_paged_audio_buffer_get_length_in_pcm_frames(ma_paged_audio_buffer* pPagedAudioBuffer, ma_uint64* pLength);\n\n\n\n/************************************************************************************************************************************************************\n\nRing Buffer\n\n************************************************************************************************************************************************************/\ntypedef struct\n{\n    void* pBuffer;\n    ma_uint32 subbufferSizeInBytes;\n    ma_uint32 subbufferCount;\n    ma_uint32 subbufferStrideInBytes;\n    MA_ATOMIC(4, ma_uint32) encodedReadOffset;  /* Most significant bit is the loop flag. Lower 31 bits contains the actual offset in bytes. Must be used atomically. */\n    MA_ATOMIC(4, ma_uint32) encodedWriteOffset; /* Most significant bit is the loop flag. Lower 31 bits contains the actual offset in bytes. Must be used atomically. */\n    ma_bool8 ownsBuffer;                        /* Used to know whether or not miniaudio is responsible for free()-ing the buffer. */\n    ma_bool8 clearOnWriteAcquire;               /* When set, clears the acquired write buffer before returning from ma_rb_acquire_write(). */\n    ma_allocation_callbacks allocationCallbacks;\n} ma_rb;\n\nMA_API ma_result ma_rb_init_ex(size_t subbufferSizeInBytes, size_t subbufferCount, size_t subbufferStrideInBytes, void* pOptionalPreallocatedBuffer, const ma_allocation_callbacks* pAllocationCallbacks, ma_rb* pRB);\nMA_API ma_result ma_rb_init(size_t bufferSizeInBytes, void* pOptionalPreallocatedBuffer, const ma_allocation_callbacks* pAllocationCallbacks, ma_rb* pRB);\nMA_API void ma_rb_uninit(ma_rb* pRB);\nMA_API void ma_rb_reset(ma_rb* pRB);\nMA_API ma_result ma_rb_acquire_read(ma_rb* pRB, size_t* pSizeInBytes, void** ppBufferOut);\nMA_API ma_result ma_rb_commit_read(ma_rb* pRB, size_t sizeInBytes);\nMA_API ma_result ma_rb_acquire_write(ma_rb* pRB, size_t* pSizeInBytes, void** ppBufferOut);\nMA_API ma_result ma_rb_commit_write(ma_rb* pRB, size_t sizeInBytes);\nMA_API ma_result ma_rb_seek_read(ma_rb* pRB, size_t offsetInBytes);\nMA_API ma_result ma_rb_seek_write(ma_rb* pRB, size_t offsetInBytes);\nMA_API ma_int32 ma_rb_pointer_distance(ma_rb* pRB);    /* Returns the distance between the write pointer and the read pointer. Should never be negative for a correct program. Will return the number of bytes that can be read before the read pointer hits the write pointer. */\nMA_API ma_uint32 ma_rb_available_read(ma_rb* pRB);\nMA_API ma_uint32 ma_rb_available_write(ma_rb* pRB);\nMA_API size_t ma_rb_get_subbuffer_size(ma_rb* pRB);\nMA_API size_t ma_rb_get_subbuffer_stride(ma_rb* pRB);\nMA_API size_t ma_rb_get_subbuffer_offset(ma_rb* pRB, size_t subbufferIndex);\nMA_API void* ma_rb_get_subbuffer_ptr(ma_rb* pRB, size_t subbufferIndex, void* pBuffer);\n\n\ntypedef struct\n{\n    ma_data_source_base ds;\n    ma_rb rb;\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate; /* Not required for the ring buffer itself, but useful for associating the data with some sample rate, particularly for data sources. */\n} ma_pcm_rb;\n\nMA_API ma_result ma_pcm_rb_init_ex(ma_format format, ma_uint32 channels, ma_uint32 subbufferSizeInFrames, ma_uint32 subbufferCount, ma_uint32 subbufferStrideInFrames, void* pOptionalPreallocatedBuffer, const ma_allocation_callbacks* pAllocationCallbacks, ma_pcm_rb* pRB);\nMA_API ma_result ma_pcm_rb_init(ma_format format, ma_uint32 channels, ma_uint32 bufferSizeInFrames, void* pOptionalPreallocatedBuffer, const ma_allocation_callbacks* pAllocationCallbacks, ma_pcm_rb* pRB);\nMA_API void ma_pcm_rb_uninit(ma_pcm_rb* pRB);\nMA_API void ma_pcm_rb_reset(ma_pcm_rb* pRB);\nMA_API ma_result ma_pcm_rb_acquire_read(ma_pcm_rb* pRB, ma_uint32* pSizeInFrames, void** ppBufferOut);\nMA_API ma_result ma_pcm_rb_commit_read(ma_pcm_rb* pRB, ma_uint32 sizeInFrames);\nMA_API ma_result ma_pcm_rb_acquire_write(ma_pcm_rb* pRB, ma_uint32* pSizeInFrames, void** ppBufferOut);\nMA_API ma_result ma_pcm_rb_commit_write(ma_pcm_rb* pRB, ma_uint32 sizeInFrames);\nMA_API ma_result ma_pcm_rb_seek_read(ma_pcm_rb* pRB, ma_uint32 offsetInFrames);\nMA_API ma_result ma_pcm_rb_seek_write(ma_pcm_rb* pRB, ma_uint32 offsetInFrames);\nMA_API ma_int32 ma_pcm_rb_pointer_distance(ma_pcm_rb* pRB); /* Return value is in frames. */\nMA_API ma_uint32 ma_pcm_rb_available_read(ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_available_write(ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_get_subbuffer_size(ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_get_subbuffer_stride(ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_get_subbuffer_offset(ma_pcm_rb* pRB, ma_uint32 subbufferIndex);\nMA_API void* ma_pcm_rb_get_subbuffer_ptr(ma_pcm_rb* pRB, ma_uint32 subbufferIndex, void* pBuffer);\nMA_API ma_format ma_pcm_rb_get_format(const ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_get_channels(const ma_pcm_rb* pRB);\nMA_API ma_uint32 ma_pcm_rb_get_sample_rate(const ma_pcm_rb* pRB);\nMA_API void ma_pcm_rb_set_sample_rate(ma_pcm_rb* pRB, ma_uint32 sampleRate);\n\n\n/*\nThe idea of the duplex ring buffer is to act as the intermediary buffer when running two asynchronous devices in a duplex set up. The\ncapture device writes to it, and then a playback device reads from it.\n\nAt the moment this is just a simple naive implementation, but in the future I want to implement some dynamic resampling to seamlessly\nhandle desyncs. Note that the API is work in progress and may change at any time in any version.\n\nThe size of the buffer is based on the capture side since that's what'll be written to the buffer. It is based on the capture period size\nin frames. The internal sample rate of the capture device is also needed in order to calculate the size.\n*/\ntypedef struct\n{\n    ma_pcm_rb rb;\n} ma_duplex_rb;\n\nMA_API ma_result ma_duplex_rb_init(ma_format captureFormat, ma_uint32 captureChannels, ma_uint32 sampleRate, ma_uint32 captureInternalSampleRate, ma_uint32 captureInternalPeriodSizeInFrames, const ma_allocation_callbacks* pAllocationCallbacks, ma_duplex_rb* pRB);\nMA_API ma_result ma_duplex_rb_uninit(ma_duplex_rb* pRB);\n\n\n/************************************************************************************************************************************************************\n\nMiscellaneous Helpers\n\n************************************************************************************************************************************************************/\n/*\nRetrieves a human readable description of the given result code.\n*/\nMA_API const char* ma_result_description(ma_result result);\n\n/*\nmalloc()\n*/\nMA_API void* ma_malloc(size_t sz, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\ncalloc()\n*/\nMA_API void* ma_calloc(size_t sz, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nrealloc()\n*/\nMA_API void* ma_realloc(void* p, size_t sz, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nfree()\n*/\nMA_API void ma_free(void* p, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nPerforms an aligned malloc, with the assumption that the alignment is a power of 2.\n*/\nMA_API void* ma_aligned_malloc(size_t sz, size_t alignment, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nFree's an aligned malloc'd buffer.\n*/\nMA_API void ma_aligned_free(void* p, const ma_allocation_callbacks* pAllocationCallbacks);\n\n/*\nRetrieves a friendly name for a format.\n*/\nMA_API const char* ma_get_format_name(ma_format format);\n\n/*\nBlends two frames in floating point format.\n*/\nMA_API void ma_blend_f32(float* pOut, float* pInA, float* pInB, float factor, ma_uint32 channels);\n\n/*\nRetrieves the size of a sample in bytes for the given format.\n\nThis API is efficient and is implemented using a lookup table.\n\nThread Safety: SAFE\n  This API is pure.\n*/\nMA_API ma_uint32 ma_get_bytes_per_sample(ma_format format);\nstatic MA_INLINE ma_uint32 ma_get_bytes_per_frame(ma_format format, ma_uint32 channels) { return ma_get_bytes_per_sample(format) * channels; }\n\n/*\nConverts a log level to a string.\n*/\nMA_API const char* ma_log_level_to_string(ma_uint32 logLevel);\n\n\n\n\n/************************************************************************************************************************************************************\n\nSynchronization\n\n************************************************************************************************************************************************************/\n/*\nLocks a spinlock.\n*/\nMA_API ma_result ma_spinlock_lock(volatile ma_spinlock* pSpinlock);\n\n/*\nLocks a spinlock, but does not yield() when looping.\n*/\nMA_API ma_result ma_spinlock_lock_noyield(volatile ma_spinlock* pSpinlock);\n\n/*\nUnlocks a spinlock.\n*/\nMA_API ma_result ma_spinlock_unlock(volatile ma_spinlock* pSpinlock);\n\n\n#ifndef MA_NO_THREADING\n\n/*\nCreates a mutex.\n\nA mutex must be created from a valid context. A mutex is initially unlocked.\n*/\nMA_API ma_result ma_mutex_init(ma_mutex* pMutex);\n\n/*\nDeletes a mutex.\n*/\nMA_API void ma_mutex_uninit(ma_mutex* pMutex);\n\n/*\nLocks a mutex with an infinite timeout.\n*/\nMA_API void ma_mutex_lock(ma_mutex* pMutex);\n\n/*\nUnlocks a mutex.\n*/\nMA_API void ma_mutex_unlock(ma_mutex* pMutex);\n\n\n/*\nInitializes an auto-reset event.\n*/\nMA_API ma_result ma_event_init(ma_event* pEvent);\n\n/*\nUninitializes an auto-reset event.\n*/\nMA_API void ma_event_uninit(ma_event* pEvent);\n\n/*\nWaits for the specified auto-reset event to become signalled.\n*/\nMA_API ma_result ma_event_wait(ma_event* pEvent);\n\n/*\nSignals the specified auto-reset event.\n*/\nMA_API ma_result ma_event_signal(ma_event* pEvent);\n#endif  /* MA_NO_THREADING */\n\n\n/*\nFence\n=====\nThis locks while the counter is larger than 0. Counter can be incremented and decremented by any\nthread, but care needs to be taken when waiting. It is possible for one thread to acquire the\nfence just as another thread returns from ma_fence_wait().\n\nThe idea behind a fence is to allow you to wait for a group of operations to complete. When an\noperation starts, the counter is incremented which locks the fence. When the operation completes,\nthe fence will be released which decrements the counter. ma_fence_wait() will block until the\ncounter hits zero.\n\nIf threading is disabled, ma_fence_wait() will spin on the counter.\n*/\ntypedef struct\n{\n#ifndef MA_NO_THREADING\n    ma_event e;\n#endif\n    ma_uint32 counter;\n} ma_fence;\n\nMA_API ma_result ma_fence_init(ma_fence* pFence);\nMA_API void ma_fence_uninit(ma_fence* pFence);\nMA_API ma_result ma_fence_acquire(ma_fence* pFence);    /* Increment counter. */\nMA_API ma_result ma_fence_release(ma_fence* pFence);    /* Decrement counter. */\nMA_API ma_result ma_fence_wait(ma_fence* pFence);       /* Wait for counter to reach 0. */\n\n\n\n/*\nNotification callback for asynchronous operations.\n*/\ntypedef void ma_async_notification;\n\ntypedef struct\n{\n    void (* onSignal)(ma_async_notification* pNotification);\n} ma_async_notification_callbacks;\n\nMA_API ma_result ma_async_notification_signal(ma_async_notification* pNotification);\n\n\n/*\nSimple polling notification.\n\nThis just sets a variable when the notification has been signalled which is then polled with ma_async_notification_poll_is_signalled()\n*/\ntypedef struct\n{\n    ma_async_notification_callbacks cb;\n    ma_bool32 signalled;\n} ma_async_notification_poll;\n\nMA_API ma_result ma_async_notification_poll_init(ma_async_notification_poll* pNotificationPoll);\nMA_API ma_bool32 ma_async_notification_poll_is_signalled(const ma_async_notification_poll* pNotificationPoll);\n\n\n/*\nEvent Notification\n\nThis uses an ma_event. If threading is disabled (MA_NO_THREADING), initialization will fail.\n*/\ntypedef struct\n{\n    ma_async_notification_callbacks cb;\n#ifndef MA_NO_THREADING\n    ma_event e;\n#endif\n} ma_async_notification_event;\n\nMA_API ma_result ma_async_notification_event_init(ma_async_notification_event* pNotificationEvent);\nMA_API ma_result ma_async_notification_event_uninit(ma_async_notification_event* pNotificationEvent);\nMA_API ma_result ma_async_notification_event_wait(ma_async_notification_event* pNotificationEvent);\nMA_API ma_result ma_async_notification_event_signal(ma_async_notification_event* pNotificationEvent);\n\n\n\n\n/************************************************************************************************************************************************************\n\nJob Queue\n\n************************************************************************************************************************************************************/\n\n/*\nSlot Allocator\n--------------\nThe idea of the slot allocator is for it to be used in conjunction with a fixed sized buffer. You use the slot allocator to allocator an index that can be used\nas the insertion point for an object.\n\nSlots are reference counted to help mitigate the ABA problem in the lock-free queue we use for tracking jobs.\n\nThe slot index is stored in the low 32 bits. The reference counter is stored in the high 32 bits:\n\n    +-----------------+-----------------+\n    | 32 Bits         | 32 Bits         |\n    +-----------------+-----------------+\n    | Reference Count | Slot Index      |\n    +-----------------+-----------------+\n*/\ntypedef struct\n{\n    ma_uint32 capacity;    /* The number of slots to make available. */\n} ma_slot_allocator_config;\n\nMA_API ma_slot_allocator_config ma_slot_allocator_config_init(ma_uint32 capacity);\n\n\ntypedef struct\n{\n    MA_ATOMIC(4, ma_uint32) bitfield;   /* Must be used atomically because the allocation and freeing routines need to make copies of this which must never be optimized away by the compiler. */\n} ma_slot_allocator_group;\n\ntypedef struct\n{\n    ma_slot_allocator_group* pGroups;   /* Slots are grouped in chunks of 32. */\n    ma_uint32* pSlots;                  /* 32 bits for reference counting for ABA mitigation. */\n    ma_uint32 count;                    /* Allocation count. */\n    ma_uint32 capacity;\n\n    /* Memory management. */\n    ma_bool32 _ownsHeap;\n    void* _pHeap;\n} ma_slot_allocator;\n\nMA_API ma_result ma_slot_allocator_get_heap_size(const ma_slot_allocator_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_slot_allocator_init_preallocated(const ma_slot_allocator_config* pConfig, void* pHeap, ma_slot_allocator* pAllocator);\nMA_API ma_result ma_slot_allocator_init(const ma_slot_allocator_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_slot_allocator* pAllocator);\nMA_API void ma_slot_allocator_uninit(ma_slot_allocator* pAllocator, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_slot_allocator_alloc(ma_slot_allocator* pAllocator, ma_uint64* pSlot);\nMA_API ma_result ma_slot_allocator_free(ma_slot_allocator* pAllocator, ma_uint64 slot);\n\n\ntypedef struct ma_job ma_job;\n\n/*\nCallback for processing a job. Each job type will have their own processing callback which will be\ncalled by ma_job_process().\n*/\ntypedef ma_result (* ma_job_proc)(ma_job* pJob);\n\n/* When a job type is added here an callback needs to be added go \"g_jobVTable\" in the implementation section. */\ntypedef enum\n{\n    /* Miscellaneous. */\n    MA_JOB_TYPE_QUIT = 0,\n    MA_JOB_TYPE_CUSTOM,\n\n    /* Resource Manager. */\n    MA_JOB_TYPE_RESOURCE_MANAGER_LOAD_DATA_BUFFER_NODE,\n    MA_JOB_TYPE_RESOURCE_MANAGER_FREE_DATA_BUFFER_NODE,\n    MA_JOB_TYPE_RESOURCE_MANAGER_PAGE_DATA_BUFFER_NODE,\n    MA_JOB_TYPE_RESOURCE_MANAGER_LOAD_DATA_BUFFER,\n    MA_JOB_TYPE_RESOURCE_MANAGER_FREE_DATA_BUFFER,\n    MA_JOB_TYPE_RESOURCE_MANAGER_LOAD_DATA_STREAM,\n    MA_JOB_TYPE_RESOURCE_MANAGER_FREE_DATA_STREAM,\n    MA_JOB_TYPE_RESOURCE_MANAGER_PAGE_DATA_STREAM,\n    MA_JOB_TYPE_RESOURCE_MANAGER_SEEK_DATA_STREAM,\n\n    /* Device. */\n    MA_JOB_TYPE_DEVICE_AAUDIO_REROUTE,\n\n    /* Count. Must always be last. */\n    MA_JOB_TYPE_COUNT\n} ma_job_type;\n\nstruct ma_job\n{\n    union\n    {\n        struct\n        {\n            ma_uint16 code;         /* Job type. */\n            ma_uint16 slot;         /* Index into a ma_slot_allocator. */\n            ma_uint32 refcount;\n        } breakup;\n        ma_uint64 allocation;\n    } toc;  /* 8 bytes. We encode the job code into the slot allocation data to save space. */\n    MA_ATOMIC(8, ma_uint64) next; /* refcount + slot for the next item. Does not include the job code. */\n    ma_uint32 order;    /* Execution order. Used to create a data dependency and ensure a job is executed in order. Usage is contextual depending on the job type. */\n\n    union\n    {\n        /* Miscellaneous. */\n        struct\n        {\n            ma_job_proc proc;\n            ma_uintptr data0;\n            ma_uintptr data1;\n        } custom;\n\n        /* Resource Manager */\n        union\n        {\n            struct\n            {\n                /*ma_resource_manager**/ void* pResourceManager;\n                /*ma_resource_manager_data_buffer_node**/ void* pDataBufferNode;\n                char* pFilePath;\n                wchar_t* pFilePathW;\n                ma_uint32 flags;                                /* Resource manager data source flags that were used when initializing the data buffer. */\n                ma_async_notification* pInitNotification;       /* Signalled when the data buffer has been initialized and the format/channels/rate can be retrieved. */\n                ma_async_notification* pDoneNotification;       /* Signalled when the data buffer has been fully decoded. Will be passed through to MA_JOB_TYPE_RESOURCE_MANAGER_PAGE_DATA_BUFFER_NODE when decoding. */\n                ma_fence* pInitFence;                           /* Released when initialization of the decoder is complete. */\n                ma_fence* pDoneFence;                           /* Released if initialization of the decoder fails. Passed through to PAGE_DATA_BUFFER_NODE untouched if init is successful. */\n            } loadDataBufferNode;\n            struct\n            {\n                /*ma_resource_manager**/ void* pResourceManager;\n                /*ma_resource_manager_data_buffer_node**/ void* pDataBufferNode;\n                ma_async_notification* pDoneNotification;\n                ma_fence* pDoneFence;\n            } freeDataBufferNode;\n            struct\n            {\n                /*ma_resource_manager**/ void* pResourceManager;\n                /*ma_resource_manager_data_buffer_node**/ void* pDataBufferNode;\n                /*ma_decoder**/ void* pDecoder;\n                ma_async_notification* pDoneNotification;       /* Signalled when the data buffer has been fully decoded. */\n                ma_fence* pDoneFence;                           /* Passed through from LOAD_DATA_BUFFER_NODE and released when the data buffer completes decoding or an error occurs. */\n            } pageDataBufferNode;\n\n            struct\n            {\n                /*ma_resource_manager_data_buffer**/ void* pDataBuffer;\n                ma_async_notification* pInitNotification;       /* Signalled when the data buffer has been initialized and the format/channels/rate can be retrieved. */\n                ma_async_notification* pDoneNotification;       /* Signalled when the data buffer has been fully decoded. */\n                ma_fence* pInitFence;                           /* Released when the data buffer has been initialized and the format/channels/rate can be retrieved. */\n                ma_fence* pDoneFence;                           /* Released when the data buffer has been fully decoded. */\n                ma_uint64 rangeBegInPCMFrames;\n                ma_uint64 rangeEndInPCMFrames;\n                ma_uint64 loopPointBegInPCMFrames;\n                ma_uint64 loopPointEndInPCMFrames;\n                ma_uint32 isLooping;\n            } loadDataBuffer;\n            struct\n            {\n                /*ma_resource_manager_data_buffer**/ void* pDataBuffer;\n                ma_async_notification* pDoneNotification;\n                ma_fence* pDoneFence;\n            } freeDataBuffer;\n\n            struct\n            {\n                /*ma_resource_manager_data_stream**/ void* pDataStream;\n                char* pFilePath;                            /* Allocated when the job is posted, freed by the job thread after loading. */\n                wchar_t* pFilePathW;                        /* ^ As above ^. Only used if pFilePath is NULL. */\n                ma_uint64 initialSeekPoint;\n                ma_async_notification* pInitNotification;   /* Signalled after the first two pages have been decoded and frames can be read from the stream. */\n                ma_fence* pInitFence;\n            } loadDataStream;\n            struct\n            {\n                /*ma_resource_manager_data_stream**/ void* pDataStream;\n                ma_async_notification* pDoneNotification;\n                ma_fence* pDoneFence;\n            } freeDataStream;\n            struct\n            {\n                /*ma_resource_manager_data_stream**/ void* pDataStream;\n                ma_uint32 pageIndex;                    /* The index of the page to decode into. */\n            } pageDataStream;\n            struct\n            {\n                /*ma_resource_manager_data_stream**/ void* pDataStream;\n                ma_uint64 frameIndex;\n            } seekDataStream;\n        } resourceManager;\n\n        /* Device. */\n        union\n        {\n            union\n            {\n                struct\n                {\n                    /*ma_device**/ void* pDevice;\n                    /*ma_device_type*/ ma_uint32 deviceType;\n                } reroute;\n            } aaudio;\n        } device;\n    } data;\n};\n\nMA_API ma_job ma_job_init(ma_uint16 code);\nMA_API ma_result ma_job_process(ma_job* pJob);\n\n\n/*\nWhen set, ma_job_queue_next() will not wait and no semaphore will be signaled in\nma_job_queue_post(). ma_job_queue_next() will return MA_NO_DATA_AVAILABLE if nothing is available.\n\nThis flag should always be used for platforms that do not support multithreading.\n*/\ntypedef enum\n{\n    MA_JOB_QUEUE_FLAG_NON_BLOCKING = 0x00000001\n} ma_job_queue_flags;\n\ntypedef struct\n{\n    ma_uint32 flags;\n    ma_uint32 capacity; /* The maximum number of jobs that can fit in the queue at a time. */\n} ma_job_queue_config;\n\nMA_API ma_job_queue_config ma_job_queue_config_init(ma_uint32 flags, ma_uint32 capacity);\n\n\ntypedef struct\n{\n    ma_uint32 flags;                /* Flags passed in at initialization time. */\n    ma_uint32 capacity;             /* The maximum number of jobs that can fit in the queue at a time. Set by the config. */\n    MA_ATOMIC(8, ma_uint64) head;   /* The first item in the list. Required for removing from the top of the list. */\n    MA_ATOMIC(8, ma_uint64) tail;   /* The last item in the list. Required for appending to the end of the list. */\n#ifndef MA_NO_THREADING\n    ma_semaphore sem;               /* Only used when MA_JOB_QUEUE_FLAG_NON_BLOCKING is unset. */\n#endif\n    ma_slot_allocator allocator;\n    ma_job* pJobs;\n#ifndef MA_USE_EXPERIMENTAL_LOCK_FREE_JOB_QUEUE\n    ma_spinlock lock;\n#endif\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_job_queue;\n\nMA_API ma_result ma_job_queue_get_heap_size(const ma_job_queue_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_job_queue_init_preallocated(const ma_job_queue_config* pConfig, void* pHeap, ma_job_queue* pQueue);\nMA_API ma_result ma_job_queue_init(const ma_job_queue_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_job_queue* pQueue);\nMA_API void ma_job_queue_uninit(ma_job_queue* pQueue, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_job_queue_post(ma_job_queue* pQueue, const ma_job* pJob);\nMA_API ma_result ma_job_queue_next(ma_job_queue* pQueue, ma_job* pJob); /* Returns MA_CANCELLED if the next job is a quit job. */\n\n\n\n/************************************************************************************************************************************************************\n*************************************************************************************************************************************************************\n\nDEVICE I/O\n==========\n\nThis section contains the APIs for device playback and capture. Here is where you'll find ma_device_init(), etc.\n\n*************************************************************************************************************************************************************\n************************************************************************************************************************************************************/\n#ifndef MA_NO_DEVICE_IO\n/* Some backends are only supported on certain platforms. */\n#if defined(MA_WIN32)\n    #define MA_SUPPORT_WASAPI\n\n    #if defined(MA_WIN32_DESKTOP)   /* DirectSound and WinMM backends are only supported on desktops. */\n        #define MA_SUPPORT_DSOUND\n        #define MA_SUPPORT_WINMM\n\n        /* Don't enable JACK here if compiling with Cosmopolitan. It'll be enabled in the Linux section below. */\n        #if !defined(__COSMOPOLITAN__)\n            #define MA_SUPPORT_JACK    /* JACK is technically supported on Windows, but I don't know how many people use it in practice... */\n        #endif\n    #endif\n#endif\n#if defined(MA_UNIX) && !defined(MA_ORBIS) && !defined(MA_PROSPERO)\n    #if defined(MA_LINUX)\n        #if !defined(MA_ANDROID) && !defined(__COSMOPOLITAN__)   /* ALSA is not supported on Android. */\n            #define MA_SUPPORT_ALSA\n        #endif\n    #endif\n    #if !defined(MA_BSD) && !defined(MA_ANDROID) && !defined(MA_EMSCRIPTEN)\n        #define MA_SUPPORT_PULSEAUDIO\n        #define MA_SUPPORT_JACK\n    #endif\n    #if defined(__OpenBSD__)        /* <-- Change this to \"#if defined(MA_BSD)\" to enable sndio on all BSD flavors. */\n        #define MA_SUPPORT_SNDIO    /* sndio is only supported on OpenBSD for now. May be expanded later if there's demand. */\n    #endif\n    #if defined(__NetBSD__) || defined(__OpenBSD__)\n        #define MA_SUPPORT_AUDIO4   /* Only support audio(4) on platforms with known support. */\n    #endif\n    #if defined(__FreeBSD__) || defined(__DragonFly__)\n        #define MA_SUPPORT_OSS      /* Only support OSS on specific platforms with known support. */\n    #endif\n#endif\n#if defined(MA_ANDROID)\n    #define MA_SUPPORT_AAUDIO\n    #define MA_SUPPORT_OPENSL\n#endif\n#if defined(MA_APPLE)\n    #define MA_SUPPORT_COREAUDIO\n#endif\n#if defined(MA_EMSCRIPTEN)\n    #define MA_SUPPORT_WEBAUDIO\n#endif\n\n/* All platforms should support custom backends. */\n#define MA_SUPPORT_CUSTOM\n\n/* Explicitly disable the Null backend for Emscripten because it uses a background thread which is not properly supported right now. */\n#if !defined(MA_EMSCRIPTEN)\n#define MA_SUPPORT_NULL\n#endif\n\n\n#if defined(MA_SUPPORT_WASAPI) && !defined(MA_NO_WASAPI) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_WASAPI))\n    #define MA_HAS_WASAPI\n#endif\n#if defined(MA_SUPPORT_DSOUND) && !defined(MA_NO_DSOUND) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_DSOUND))\n    #define MA_HAS_DSOUND\n#endif\n#if defined(MA_SUPPORT_WINMM) && !defined(MA_NO_WINMM) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_WINMM))\n    #define MA_HAS_WINMM\n#endif\n#if defined(MA_SUPPORT_ALSA) && !defined(MA_NO_ALSA) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_ALSA))\n    #define MA_HAS_ALSA\n#endif\n#if defined(MA_SUPPORT_PULSEAUDIO) && !defined(MA_NO_PULSEAUDIO) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_PULSEAUDIO))\n    #define MA_HAS_PULSEAUDIO\n#endif\n#if defined(MA_SUPPORT_JACK) && !defined(MA_NO_JACK) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_JACK))\n    #define MA_HAS_JACK\n#endif\n#if defined(MA_SUPPORT_COREAUDIO) && !defined(MA_NO_COREAUDIO) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_COREAUDIO))\n    #define MA_HAS_COREAUDIO\n#endif\n#if defined(MA_SUPPORT_SNDIO) && !defined(MA_NO_SNDIO) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_SNDIO))\n    #define MA_HAS_SNDIO\n#endif\n#if defined(MA_SUPPORT_AUDIO4) && !defined(MA_NO_AUDIO4) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_AUDIO4))\n    #define MA_HAS_AUDIO4\n#endif\n#if defined(MA_SUPPORT_OSS) && !defined(MA_NO_OSS) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_OSS))\n    #define MA_HAS_OSS\n#endif\n#if defined(MA_SUPPORT_AAUDIO) && !defined(MA_NO_AAUDIO) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_AAUDIO))\n    #define MA_HAS_AAUDIO\n#endif\n#if defined(MA_SUPPORT_OPENSL) && !defined(MA_NO_OPENSL) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_OPENSL))\n    #define MA_HAS_OPENSL\n#endif\n#if defined(MA_SUPPORT_WEBAUDIO) && !defined(MA_NO_WEBAUDIO) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_WEBAUDIO))\n    #define MA_HAS_WEBAUDIO\n#endif\n#if defined(MA_SUPPORT_CUSTOM) && !defined(MA_NO_CUSTOM) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_CUSTOM))\n    #define MA_HAS_CUSTOM\n#endif\n#if defined(MA_SUPPORT_NULL) && !defined(MA_NO_NULL) && (!defined(MA_ENABLE_ONLY_SPECIFIC_BACKENDS) || defined(MA_ENABLE_NULL))\n    #define MA_HAS_NULL\n#endif\n\ntypedef enum\n{\n    ma_device_state_uninitialized = 0,\n    ma_device_state_stopped       = 1,  /* The device's default state after initialization. */\n    ma_device_state_started       = 2,  /* The device is started and is requesting and/or delivering audio data. */\n    ma_device_state_starting      = 3,  /* Transitioning from a stopped state to started. */\n    ma_device_state_stopping      = 4   /* Transitioning from a started state to stopped. */\n} ma_device_state;\n\nMA_ATOMIC_SAFE_TYPE_DECL(i32, 4, device_state)\n\n\n#ifdef MA_SUPPORT_WASAPI\n/* We need a IMMNotificationClient object for WASAPI. */\ntypedef struct\n{\n    void* lpVtbl;\n    ma_uint32 counter;\n    ma_device* pDevice;\n} ma_IMMNotificationClient;\n#endif\n\n/* Backend enums must be in priority order. */\ntypedef enum\n{\n    ma_backend_wasapi,\n    ma_backend_dsound,\n    ma_backend_winmm,\n    ma_backend_coreaudio,\n    ma_backend_sndio,\n    ma_backend_audio4,\n    ma_backend_oss,\n    ma_backend_pulseaudio,\n    ma_backend_alsa,\n    ma_backend_jack,\n    ma_backend_aaudio,\n    ma_backend_opensl,\n    ma_backend_webaudio,\n    ma_backend_custom,  /* <-- Custom backend, with callbacks defined by the context config. */\n    ma_backend_null     /* <-- Must always be the last item. Lowest priority, and used as the terminator for backend enumeration. */\n} ma_backend;\n\n#define MA_BACKEND_COUNT (ma_backend_null+1)\n\n\n/*\nDevice job thread. This is used by backends that require asynchronous processing of certain\noperations. It is not used by all backends.\n\nThe device job thread is made up of a thread and a job queue. You can post a job to the thread with\nma_device_job_thread_post(). The thread will do the processing of the job.\n*/\ntypedef struct\n{\n    ma_bool32 noThread; /* Set this to true if you want to process jobs yourself. */\n    ma_uint32 jobQueueCapacity;\n    ma_uint32 jobQueueFlags;\n} ma_device_job_thread_config;\n\nMA_API ma_device_job_thread_config ma_device_job_thread_config_init(void);\n\ntypedef struct\n{\n    ma_thread thread;\n    ma_job_queue jobQueue;\n    ma_bool32 _hasThread;\n} ma_device_job_thread;\n\nMA_API ma_result ma_device_job_thread_init(const ma_device_job_thread_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_device_job_thread* pJobThread);\nMA_API void ma_device_job_thread_uninit(ma_device_job_thread* pJobThread, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_device_job_thread_post(ma_device_job_thread* pJobThread, const ma_job* pJob);\nMA_API ma_result ma_device_job_thread_next(ma_device_job_thread* pJobThread, ma_job* pJob);\n\n\n\n/* Device notification types. */\ntypedef enum\n{\n    ma_device_notification_type_started,\n    ma_device_notification_type_stopped,\n    ma_device_notification_type_rerouted,\n    ma_device_notification_type_interruption_began,\n    ma_device_notification_type_interruption_ended,\n    ma_device_notification_type_unlocked\n} ma_device_notification_type;\n\ntypedef struct\n{\n    ma_device* pDevice;\n    ma_device_notification_type type;\n    union\n    {\n        struct\n        {\n            int _unused;\n        } started;\n        struct\n        {\n            int _unused;\n        } stopped;\n        struct\n        {\n            int _unused;\n        } rerouted;\n        struct\n        {\n            int _unused;\n        } interruption;\n    } data;\n} ma_device_notification;\n\n/*\nThe notification callback for when the application should be notified of a change to the device.\n\nThis callback is used for notifying the application of changes such as when the device has started,\nstopped, rerouted or an interruption has occurred. Note that not all backends will post all\nnotification types. For example, some backends will perform automatic stream routing without any\nkind of notification to the host program which means miniaudio will never know about it and will\nnever be able to fire the rerouted notification. You should keep this in mind when designing your\nprogram.\n\nThe stopped notification will *not* get fired when a device is rerouted.\n\n\nParameters\n----------\npNotification (in)\n    A pointer to a structure containing information about the event. Use the `pDevice` member of\n    this object to retrieve the relevant device. The `type` member can be used to discriminate\n    against each of the notification types.\n\n\nRemarks\n-------\nDo not restart or uninitialize the device from the callback.\n\nNot all notifications will be triggered by all backends, however the started and stopped events\nshould be reliable for all backends. Some backends do not have a good way to detect device\nstoppages due to unplugging the device which may result in the stopped callback not getting\nfired. This has been observed with at least one BSD variant.\n\nThe rerouted notification is fired *after* the reroute has occurred. The stopped notification will\n*not* get fired when a device is rerouted. The following backends are known to do automatic stream\nrerouting, but do not have a way to be notified of the change:\n\n  * DirectSound\n\nThe interruption notifications are used on mobile platforms for detecting when audio is interrupted\ndue to things like an incoming phone call. Currently this is only implemented on iOS. None of the\nAndroid backends will report this notification.\n*/\ntypedef void (* ma_device_notification_proc)(const ma_device_notification* pNotification);\n\n\n/*\nThe callback for processing audio data from the device.\n\nThe data callback is fired by miniaudio whenever the device needs to have more data delivered to a playback device, or when a capture device has some data\navailable. This is called as soon as the backend asks for more data which means it may be called with inconsistent frame counts. You cannot assume the\ncallback will be fired with a consistent frame count.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the relevant device.\n\npOutput (out)\n    A pointer to the output buffer that will receive audio data that will later be played back through the speakers. This will be non-null for a playback or\n    full-duplex device and null for a capture and loopback device.\n\npInput (in)\n    A pointer to the buffer containing input data from a recording device. This will be non-null for a capture, full-duplex or loopback device and null for a\n    playback device.\n\nframeCount (in)\n    The number of PCM frames to process. Note that this will not necessarily be equal to what you requested when you initialized the device. The\n    `periodSizeInFrames` and `periodSizeInMilliseconds` members of the device config are just hints, and are not necessarily exactly what you'll get. You must\n    not assume this will always be the same value each time the callback is fired.\n\n\nRemarks\n-------\nYou cannot stop and start the device from inside the callback or else you'll get a deadlock. You must also not uninitialize the device from inside the\ncallback. The following APIs cannot be called from inside the callback:\n\n    ma_device_init()\n    ma_device_init_ex()\n    ma_device_uninit()\n    ma_device_start()\n    ma_device_stop()\n\nThe proper way to stop the device is to call `ma_device_stop()` from a different thread, normally the main application thread.\n*/\ntypedef void (* ma_device_data_proc)(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount);\n\n\n\n\n/*\nDEPRECATED. Use ma_device_notification_proc instead.\n\nThe callback for when the device has been stopped.\n\nThis will be called when the device is stopped explicitly with `ma_device_stop()` and also called implicitly when the device is stopped through external forces\nsuch as being unplugged or an internal error occurring.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device that has just stopped.\n\n\nRemarks\n-------\nDo not restart or uninitialize the device from the callback.\n*/\ntypedef void (* ma_stop_proc)(ma_device* pDevice);  /* DEPRECATED. Use ma_device_notification_proc instead. */\n\ntypedef enum\n{\n    ma_device_type_playback = 1,\n    ma_device_type_capture  = 2,\n    ma_device_type_duplex   = ma_device_type_playback | ma_device_type_capture, /* 3 */\n    ma_device_type_loopback = 4\n} ma_device_type;\n\ntypedef enum\n{\n    ma_share_mode_shared = 0,\n    ma_share_mode_exclusive\n} ma_share_mode;\n\n/* iOS/tvOS/watchOS session categories. */\ntypedef enum\n{\n    ma_ios_session_category_default = 0,        /* AVAudioSessionCategoryPlayAndRecord. */\n    ma_ios_session_category_none,               /* Leave the session category unchanged. */\n    ma_ios_session_category_ambient,            /* AVAudioSessionCategoryAmbient */\n    ma_ios_session_category_solo_ambient,       /* AVAudioSessionCategorySoloAmbient */\n    ma_ios_session_category_playback,           /* AVAudioSessionCategoryPlayback */\n    ma_ios_session_category_record,             /* AVAudioSessionCategoryRecord */\n    ma_ios_session_category_play_and_record,    /* AVAudioSessionCategoryPlayAndRecord */\n    ma_ios_session_category_multi_route         /* AVAudioSessionCategoryMultiRoute */\n} ma_ios_session_category;\n\n/* iOS/tvOS/watchOS session category options */\ntypedef enum\n{\n    ma_ios_session_category_option_mix_with_others                            = 0x01,   /* AVAudioSessionCategoryOptionMixWithOthers */\n    ma_ios_session_category_option_duck_others                                = 0x02,   /* AVAudioSessionCategoryOptionDuckOthers */\n    ma_ios_session_category_option_allow_bluetooth                            = 0x04,   /* AVAudioSessionCategoryOptionAllowBluetooth */\n    ma_ios_session_category_option_default_to_speaker                         = 0x08,   /* AVAudioSessionCategoryOptionDefaultToSpeaker */\n    ma_ios_session_category_option_interrupt_spoken_audio_and_mix_with_others = 0x11,   /* AVAudioSessionCategoryOptionInterruptSpokenAudioAndMixWithOthers */\n    ma_ios_session_category_option_allow_bluetooth_a2dp                       = 0x20,   /* AVAudioSessionCategoryOptionAllowBluetoothA2DP */\n    ma_ios_session_category_option_allow_air_play                             = 0x40,   /* AVAudioSessionCategoryOptionAllowAirPlay */\n} ma_ios_session_category_option;\n\n/* OpenSL stream types. */\ntypedef enum\n{\n    ma_opensl_stream_type_default = 0,              /* Leaves the stream type unset. */\n    ma_opensl_stream_type_voice,                    /* SL_ANDROID_STREAM_VOICE */\n    ma_opensl_stream_type_system,                   /* SL_ANDROID_STREAM_SYSTEM */\n    ma_opensl_stream_type_ring,                     /* SL_ANDROID_STREAM_RING */\n    ma_opensl_stream_type_media,                    /* SL_ANDROID_STREAM_MEDIA */\n    ma_opensl_stream_type_alarm,                    /* SL_ANDROID_STREAM_ALARM */\n    ma_opensl_stream_type_notification              /* SL_ANDROID_STREAM_NOTIFICATION */\n} ma_opensl_stream_type;\n\n/* OpenSL recording presets. */\ntypedef enum\n{\n    ma_opensl_recording_preset_default = 0,         /* Leaves the input preset unset. */\n    ma_opensl_recording_preset_generic,             /* SL_ANDROID_RECORDING_PRESET_GENERIC */\n    ma_opensl_recording_preset_camcorder,           /* SL_ANDROID_RECORDING_PRESET_CAMCORDER */\n    ma_opensl_recording_preset_voice_recognition,   /* SL_ANDROID_RECORDING_PRESET_VOICE_RECOGNITION */\n    ma_opensl_recording_preset_voice_communication, /* SL_ANDROID_RECORDING_PRESET_VOICE_COMMUNICATION */\n    ma_opensl_recording_preset_voice_unprocessed    /* SL_ANDROID_RECORDING_PRESET_UNPROCESSED */\n} ma_opensl_recording_preset;\n\n/* WASAPI audio thread priority characteristics. */\ntypedef enum\n{\n    ma_wasapi_usage_default = 0,\n    ma_wasapi_usage_games,\n    ma_wasapi_usage_pro_audio,\n} ma_wasapi_usage;\n\n/* AAudio usage types. */\ntypedef enum\n{\n    ma_aaudio_usage_default = 0,                    /* Leaves the usage type unset. */\n    ma_aaudio_usage_media,                          /* AAUDIO_USAGE_MEDIA */\n    ma_aaudio_usage_voice_communication,            /* AAUDIO_USAGE_VOICE_COMMUNICATION */\n    ma_aaudio_usage_voice_communication_signalling, /* AAUDIO_USAGE_VOICE_COMMUNICATION_SIGNALLING */\n    ma_aaudio_usage_alarm,                          /* AAUDIO_USAGE_ALARM */\n    ma_aaudio_usage_notification,                   /* AAUDIO_USAGE_NOTIFICATION */\n    ma_aaudio_usage_notification_ringtone,          /* AAUDIO_USAGE_NOTIFICATION_RINGTONE */\n    ma_aaudio_usage_notification_event,             /* AAUDIO_USAGE_NOTIFICATION_EVENT */\n    ma_aaudio_usage_assistance_accessibility,       /* AAUDIO_USAGE_ASSISTANCE_ACCESSIBILITY */\n    ma_aaudio_usage_assistance_navigation_guidance, /* AAUDIO_USAGE_ASSISTANCE_NAVIGATION_GUIDANCE */\n    ma_aaudio_usage_assistance_sonification,        /* AAUDIO_USAGE_ASSISTANCE_SONIFICATION */\n    ma_aaudio_usage_game,                           /* AAUDIO_USAGE_GAME */\n    ma_aaudio_usage_assitant,                       /* AAUDIO_USAGE_ASSISTANT */\n    ma_aaudio_usage_emergency,                      /* AAUDIO_SYSTEM_USAGE_EMERGENCY */\n    ma_aaudio_usage_safety,                         /* AAUDIO_SYSTEM_USAGE_SAFETY */\n    ma_aaudio_usage_vehicle_status,                 /* AAUDIO_SYSTEM_USAGE_VEHICLE_STATUS */\n    ma_aaudio_usage_announcement                    /* AAUDIO_SYSTEM_USAGE_ANNOUNCEMENT */\n} ma_aaudio_usage;\n\n/* AAudio content types. */\ntypedef enum\n{\n    ma_aaudio_content_type_default = 0,             /* Leaves the content type unset. */\n    ma_aaudio_content_type_speech,                  /* AAUDIO_CONTENT_TYPE_SPEECH */\n    ma_aaudio_content_type_music,                   /* AAUDIO_CONTENT_TYPE_MUSIC */\n    ma_aaudio_content_type_movie,                   /* AAUDIO_CONTENT_TYPE_MOVIE */\n    ma_aaudio_content_type_sonification             /* AAUDIO_CONTENT_TYPE_SONIFICATION */\n} ma_aaudio_content_type;\n\n/* AAudio input presets. */\ntypedef enum\n{\n    ma_aaudio_input_preset_default = 0,             /* Leaves the input preset unset. */\n    ma_aaudio_input_preset_generic,                 /* AAUDIO_INPUT_PRESET_GENERIC */\n    ma_aaudio_input_preset_camcorder,               /* AAUDIO_INPUT_PRESET_CAMCORDER */\n    ma_aaudio_input_preset_voice_recognition,       /* AAUDIO_INPUT_PRESET_VOICE_RECOGNITION */\n    ma_aaudio_input_preset_voice_communication,     /* AAUDIO_INPUT_PRESET_VOICE_COMMUNICATION */\n    ma_aaudio_input_preset_unprocessed,             /* AAUDIO_INPUT_PRESET_UNPROCESSED */\n    ma_aaudio_input_preset_voice_performance        /* AAUDIO_INPUT_PRESET_VOICE_PERFORMANCE */\n} ma_aaudio_input_preset;\n\ntypedef enum\n{\n    ma_aaudio_allow_capture_default = 0,            /* Leaves the allowed capture policy unset. */\n    ma_aaudio_allow_capture_by_all,                 /* AAUDIO_ALLOW_CAPTURE_BY_ALL */\n    ma_aaudio_allow_capture_by_system,              /* AAUDIO_ALLOW_CAPTURE_BY_SYSTEM */\n    ma_aaudio_allow_capture_by_none                 /* AAUDIO_ALLOW_CAPTURE_BY_NONE */\n} ma_aaudio_allowed_capture_policy;\n\ntypedef union\n{\n    ma_int64 counter;\n    double counterD;\n} ma_timer;\n\ntypedef union\n{\n    ma_wchar_win32 wasapi[64];      /* WASAPI uses a wchar_t string for identification. */\n    ma_uint8 dsound[16];            /* DirectSound uses a GUID for identification. */\n    /*UINT_PTR*/ ma_uint32 winmm;   /* When creating a device, WinMM expects a Win32 UINT_PTR for device identification. In practice it's actually just a UINT. */\n    char alsa[256];                 /* ALSA uses a name string for identification. */\n    char pulse[256];                /* PulseAudio uses a name string for identification. */\n    int jack;                       /* JACK always uses default devices. */\n    char coreaudio[256];            /* Core Audio uses a string for identification. */\n    char sndio[256];                /* \"snd/0\", etc. */\n    char audio4[256];               /* \"/dev/audio\", etc. */\n    char oss[64];                   /* \"dev/dsp0\", etc. \"dev/dsp\" for the default device. */\n    ma_int32 aaudio;                /* AAudio uses a 32-bit integer for identification. */\n    ma_uint32 opensl;               /* OpenSL|ES uses a 32-bit unsigned integer for identification. */\n    char webaudio[32];              /* Web Audio always uses default devices for now, but if this changes it'll be a GUID. */\n    union\n    {\n        int i;\n        char s[256];\n        void* p;\n    } custom;                       /* The custom backend could be anything. Give them a few options. */\n    int nullbackend;                /* The null backend uses an integer for device IDs. */\n} ma_device_id;\n\n\ntypedef struct ma_context_config    ma_context_config;\ntypedef struct ma_device_config     ma_device_config;\ntypedef struct ma_backend_callbacks ma_backend_callbacks;\n\n#define MA_DATA_FORMAT_FLAG_EXCLUSIVE_MODE (1U << 1)    /* If set, this is supported in exclusive mode. Otherwise not natively supported by exclusive mode. */\n\n#ifndef MA_MAX_DEVICE_NAME_LENGTH\n#define MA_MAX_DEVICE_NAME_LENGTH   255\n#endif\n\ntypedef struct\n{\n    /* Basic info. This is the only information guaranteed to be filled in during device enumeration. */\n    ma_device_id id;\n    char name[MA_MAX_DEVICE_NAME_LENGTH + 1];   /* +1 for null terminator. */\n    ma_bool32 isDefault;\n\n    ma_uint32 nativeDataFormatCount;\n    struct\n    {\n        ma_format format;       /* Sample format. If set to ma_format_unknown, all sample formats are supported. */\n        ma_uint32 channels;     /* If set to 0, all channels are supported. */\n        ma_uint32 sampleRate;   /* If set to 0, all sample rates are supported. */\n        ma_uint32 flags;        /* A combination of MA_DATA_FORMAT_FLAG_* flags. */\n    } nativeDataFormats[/*ma_format_count * ma_standard_sample_rate_count * MA_MAX_CHANNELS*/ 64];  /* Not sure how big to make this. There can be *many* permutations for virtual devices which can support anything. */\n} ma_device_info;\n\nstruct ma_device_config\n{\n    ma_device_type deviceType;\n    ma_uint32 sampleRate;\n    ma_uint32 periodSizeInFrames;\n    ma_uint32 periodSizeInMilliseconds;\n    ma_uint32 periods;\n    ma_performance_profile performanceProfile;\n    ma_bool8 noPreSilencedOutputBuffer; /* When set to true, the contents of the output buffer passed into the data callback will be left undefined rather than initialized to silence. */\n    ma_bool8 noClip;                    /* When set to true, the contents of the output buffer passed into the data callback will not be clipped after returning. Only applies when the playback sample format is f32. */\n    ma_bool8 noDisableDenormals;        /* Do not disable denormals when firing the data callback. */\n    ma_bool8 noFixedSizedCallback;      /* Disables strict fixed-sized data callbacks. Setting this to true will result in the period size being treated only as a hint to the backend. This is an optimization for those who don't need fixed sized callbacks. */\n    ma_device_data_proc dataCallback;\n    ma_device_notification_proc notificationCallback;\n    ma_stop_proc stopCallback;\n    void* pUserData;\n    ma_resampler_config resampling;\n    struct\n    {\n        const ma_device_id* pDeviceID;\n        ma_format format;\n        ma_uint32 channels;\n        ma_channel* pChannelMap;\n        ma_channel_mix_mode channelMixMode;\n        ma_bool32 calculateLFEFromSpatialChannels;  /* When an output LFE channel is present, but no input LFE, set to true to set the output LFE to the average of all spatial channels (LR, FR, etc.). Ignored when an input LFE is present. */\n        ma_share_mode shareMode;\n    } playback;\n    struct\n    {\n        const ma_device_id* pDeviceID;\n        ma_format format;\n        ma_uint32 channels;\n        ma_channel* pChannelMap;\n        ma_channel_mix_mode channelMixMode;\n        ma_bool32 calculateLFEFromSpatialChannels;  /* When an output LFE channel is present, but no input LFE, set to true to set the output LFE to the average of all spatial channels (LR, FR, etc.). Ignored when an input LFE is present. */\n        ma_share_mode shareMode;\n    } capture;\n\n    struct\n    {\n        ma_wasapi_usage usage;              /* When configured, uses Avrt APIs to set the thread characteristics. */\n        ma_bool8 noAutoConvertSRC;          /* When set to true, disables the use of AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM. */\n        ma_bool8 noDefaultQualitySRC;       /* When set to true, disables the use of AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY. */\n        ma_bool8 noAutoStreamRouting;       /* Disables automatic stream routing. */\n        ma_bool8 noHardwareOffloading;      /* Disables WASAPI's hardware offloading feature. */\n        ma_uint32 loopbackProcessID;        /* The process ID to include or exclude for loopback mode. Set to 0 to capture audio from all processes. Ignored when an explicit device ID is specified. */\n        ma_bool8 loopbackProcessExclude;    /* When set to true, excludes the process specified by loopbackProcessID. By default, the process will be included. */\n    } wasapi;\n    struct\n    {\n        ma_bool32 noMMap;           /* Disables MMap mode. */\n        ma_bool32 noAutoFormat;     /* Opens the ALSA device with SND_PCM_NO_AUTO_FORMAT. */\n        ma_bool32 noAutoChannels;   /* Opens the ALSA device with SND_PCM_NO_AUTO_CHANNELS. */\n        ma_bool32 noAutoResample;   /* Opens the ALSA device with SND_PCM_NO_AUTO_RESAMPLE. */\n    } alsa;\n    struct\n    {\n        const char* pStreamNamePlayback;\n        const char* pStreamNameCapture;\n    } pulse;\n    struct\n    {\n        ma_bool32 allowNominalSampleRateChange; /* Desktop only. When enabled, allows changing of the sample rate at the operating system level. */\n    } coreaudio;\n    struct\n    {\n        ma_opensl_stream_type streamType;\n        ma_opensl_recording_preset recordingPreset;\n        ma_bool32 enableCompatibilityWorkarounds;\n    } opensl;\n    struct\n    {\n        ma_aaudio_usage usage;\n        ma_aaudio_content_type contentType;\n        ma_aaudio_input_preset inputPreset;\n        ma_aaudio_allowed_capture_policy allowedCapturePolicy;\n        ma_bool32 noAutoStartAfterReroute;\n        ma_bool32 enableCompatibilityWorkarounds;\n    } aaudio;\n};\n\n\n/*\nThe callback for handling device enumeration. This is fired from `ma_context_enumerate_devices()`.\n\n\nParameters\n----------\npContext (in)\n    A pointer to the context performing the enumeration.\n\ndeviceType (in)\n    The type of the device being enumerated. This will always be either `ma_device_type_playback` or `ma_device_type_capture`.\n\npInfo (in)\n    A pointer to a `ma_device_info` containing the ID and name of the enumerated device. Note that this will not include detailed information about the device,\n    only basic information (ID and name). The reason for this is that it would otherwise require opening the backend device to probe for the information which\n    is too inefficient.\n\npUserData (in)\n    The user data pointer passed into `ma_context_enumerate_devices()`.\n*/\ntypedef ma_bool32 (* ma_enum_devices_callback_proc)(ma_context* pContext, ma_device_type deviceType, const ma_device_info* pInfo, void* pUserData);\n\n\n/*\nDescribes some basic details about a playback or capture device.\n*/\ntypedef struct\n{\n    const ma_device_id* pDeviceID;\n    ma_share_mode shareMode;\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_channel channelMap[MA_MAX_CHANNELS];\n    ma_uint32 periodSizeInFrames;\n    ma_uint32 periodSizeInMilliseconds;\n    ma_uint32 periodCount;\n} ma_device_descriptor;\n\n/*\nThese are the callbacks required to be implemented for a backend. These callbacks are grouped into two parts: context and device. There is one context\nto many devices. A device is created from a context.\n\nThe general flow goes like this:\n\n  1) A context is created with `onContextInit()`\n     1a) Available devices can be enumerated with `onContextEnumerateDevices()` if required.\n     1b) Detailed information about a device can be queried with `onContextGetDeviceInfo()` if required.\n  2) A device is created from the context that was created in the first step using `onDeviceInit()`, and optionally a device ID that was\n     selected from device enumeration via `onContextEnumerateDevices()`.\n  3) A device is started or stopped with `onDeviceStart()` / `onDeviceStop()`\n  4) Data is delivered to and from the device by the backend. This is always done based on the native format returned by the prior call\n     to `onDeviceInit()`. Conversion between the device's native format and the format requested by the application will be handled by\n     miniaudio internally.\n\nInitialization of the context is quite simple. You need to do any necessary initialization of internal objects and then output the\ncallbacks defined in this structure.\n\nOnce the context has been initialized you can initialize a device. Before doing so, however, the application may want to know which\nphysical devices are available. This is where `onContextEnumerateDevices()` comes in. This is fairly simple. For each device, fire the\ngiven callback with, at a minimum, the basic information filled out in `ma_device_info`. When the callback returns `MA_FALSE`, enumeration\nneeds to stop and the `onContextEnumerateDevices()` function returns with a success code.\n\nDetailed device information can be retrieved from a device ID using `onContextGetDeviceInfo()`. This takes as input the device type and ID,\nand on output returns detailed information about the device in `ma_device_info`. The `onContextGetDeviceInfo()` callback must handle the\ncase when the device ID is NULL, in which case information about the default device needs to be retrieved.\n\nOnce the context has been created and the device ID retrieved (if using anything other than the default device), the device can be created.\nThis is a little bit more complicated than initialization of the context due to it's more complicated configuration. When initializing a\ndevice, a duplex device may be requested. This means a separate data format needs to be specified for both playback and capture. On input,\nthe data format is set to what the application wants. On output it's set to the native format which should match as closely as possible to\nthe requested format. The conversion between the format requested by the application and the device's native format will be handled\ninternally by miniaudio.\n\nOn input, if the sample format is set to `ma_format_unknown`, the backend is free to use whatever sample format it desires, so long as it's\nsupported by miniaudio. When the channel count is set to 0, the backend should use the device's native channel count. The same applies for\nsample rate. For the channel map, the default should be used when `ma_channel_map_is_blank()` returns true (all channels set to\n`MA_CHANNEL_NONE`). On input, the `periodSizeInFrames` or `periodSizeInMilliseconds` option should always be set. The backend should\ninspect both of these variables. If `periodSizeInFrames` is set, it should take priority, otherwise it needs to be derived from the period\nsize in milliseconds (`periodSizeInMilliseconds`) and the sample rate, keeping in mind that the sample rate may be 0, in which case the\nsample rate will need to be determined before calculating the period size in frames. On output, all members of the `ma_device_descriptor`\nobject should be set to a valid value, except for `periodSizeInMilliseconds` which is optional (`periodSizeInFrames` *must* be set).\n\nStarting and stopping of the device is done with `onDeviceStart()` and `onDeviceStop()` and should be self-explanatory. If the backend uses\nasynchronous reading and writing, `onDeviceStart()` and `onDeviceStop()` should always be implemented.\n\nThe handling of data delivery between the application and the device is the most complicated part of the process. To make this a bit\neasier, some helper callbacks are available. If the backend uses a blocking read/write style of API, the `onDeviceRead()` and\n`onDeviceWrite()` callbacks can optionally be implemented. These are blocking and work just like reading and writing from a file. If the\nbackend uses a callback for data delivery, that callback must call `ma_device_handle_backend_data_callback()` from within it's callback.\nThis allows miniaudio to then process any necessary data conversion and then pass it to the miniaudio data callback.\n\nIf the backend requires absolute flexibility with it's data delivery, it can optionally implement the `onDeviceDataLoop()` callback\nwhich will allow it to implement the logic that will run on the audio thread. This is much more advanced and is completely optional.\n\nThe audio thread should run data delivery logic in a loop while `ma_device_get_state() == ma_device_state_started` and no errors have been\nencountered. Do not start or stop the device here. That will be handled from outside the `onDeviceDataLoop()` callback.\n\nThe invocation of the `onDeviceDataLoop()` callback will be handled by miniaudio. When you start the device, miniaudio will fire this\ncallback. When the device is stopped, the `ma_device_get_state() == ma_device_state_started` condition will fail and the loop will be terminated\nwhich will then fall through to the part that stops the device. For an example on how to implement the `onDeviceDataLoop()` callback,\nlook at `ma_device_audio_thread__default_read_write()`. Implement the `onDeviceDataLoopWakeup()` callback if you need a mechanism to\nwake up the audio thread.\n\nIf the backend supports an optimized retrieval of device information from an initialized `ma_device` object, it should implement the\n`onDeviceGetInfo()` callback. This is optional, in which case it will fall back to `onContextGetDeviceInfo()` which is less efficient.\n*/\nstruct ma_backend_callbacks\n{\n    ma_result (* onContextInit)(ma_context* pContext, const ma_context_config* pConfig, ma_backend_callbacks* pCallbacks);\n    ma_result (* onContextUninit)(ma_context* pContext);\n    ma_result (* onContextEnumerateDevices)(ma_context* pContext, ma_enum_devices_callback_proc callback, void* pUserData);\n    ma_result (* onContextGetDeviceInfo)(ma_context* pContext, ma_device_type deviceType, const ma_device_id* pDeviceID, ma_device_info* pDeviceInfo);\n    ma_result (* onDeviceInit)(ma_device* pDevice, const ma_device_config* pConfig, ma_device_descriptor* pDescriptorPlayback, ma_device_descriptor* pDescriptorCapture);\n    ma_result (* onDeviceUninit)(ma_device* pDevice);\n    ma_result (* onDeviceStart)(ma_device* pDevice);\n    ma_result (* onDeviceStop)(ma_device* pDevice);\n    ma_result (* onDeviceRead)(ma_device* pDevice, void* pFrames, ma_uint32 frameCount, ma_uint32* pFramesRead);\n    ma_result (* onDeviceWrite)(ma_device* pDevice, const void* pFrames, ma_uint32 frameCount, ma_uint32* pFramesWritten);\n    ma_result (* onDeviceDataLoop)(ma_device* pDevice);\n    ma_result (* onDeviceDataLoopWakeup)(ma_device* pDevice);\n    ma_result (* onDeviceGetInfo)(ma_device* pDevice, ma_device_type type, ma_device_info* pDeviceInfo);\n};\n\nstruct ma_context_config\n{\n    ma_log* pLog;\n    ma_thread_priority threadPriority;\n    size_t threadStackSize;\n    void* pUserData;\n    ma_allocation_callbacks allocationCallbacks;\n    struct\n    {\n        ma_bool32 useVerboseDeviceEnumeration;\n    } alsa;\n    struct\n    {\n        const char* pApplicationName;\n        const char* pServerName;\n        ma_bool32 tryAutoSpawn; /* Enables autospawning of the PulseAudio daemon if necessary. */\n    } pulse;\n    struct\n    {\n        ma_ios_session_category sessionCategory;\n        ma_uint32 sessionCategoryOptions;\n        ma_bool32 noAudioSessionActivate;   /* iOS only. When set to true, does not perform an explicit [[AVAudioSession sharedInstace] setActive:true] on initialization. */\n        ma_bool32 noAudioSessionDeactivate; /* iOS only. When set to true, does not perform an explicit [[AVAudioSession sharedInstace] setActive:false] on uninitialization. */\n    } coreaudio;\n    struct\n    {\n        const char* pClientName;\n        ma_bool32 tryStartServer;\n    } jack;\n    ma_backend_callbacks custom;\n};\n\n/* WASAPI specific structure for some commands which must run on a common thread due to bugs in WASAPI. */\ntypedef struct\n{\n    int code;\n    ma_event* pEvent;   /* This will be signalled when the event is complete. */\n    union\n    {\n        struct\n        {\n            int _unused;\n        } quit;\n        struct\n        {\n            ma_device_type deviceType;\n            void* pAudioClient;\n            void** ppAudioClientService;\n            ma_result* pResult; /* The result from creating the audio client service. */\n        } createAudioClient;\n        struct\n        {\n            ma_device* pDevice;\n            ma_device_type deviceType;\n        } releaseAudioClient;\n    } data;\n} ma_context_command__wasapi;\n\nstruct ma_context\n{\n    ma_backend_callbacks callbacks;\n    ma_backend backend;                 /* DirectSound, ALSA, etc. */\n    ma_log* pLog;\n    ma_log log; /* Only used if the log is owned by the context. The pLog member will be set to &log in this case. */\n    ma_thread_priority threadPriority;\n    size_t threadStackSize;\n    void* pUserData;\n    ma_allocation_callbacks allocationCallbacks;\n    ma_mutex deviceEnumLock;            /* Used to make ma_context_get_devices() thread safe. */\n    ma_mutex deviceInfoLock;            /* Used to make ma_context_get_device_info() thread safe. */\n    ma_uint32 deviceInfoCapacity;       /* Total capacity of pDeviceInfos. */\n    ma_uint32 playbackDeviceInfoCount;\n    ma_uint32 captureDeviceInfoCount;\n    ma_device_info* pDeviceInfos;       /* Playback devices first, then capture. */\n\n    union\n    {\n#ifdef MA_SUPPORT_WASAPI\n        struct\n        {\n            ma_thread commandThread;\n            ma_mutex commandLock;\n            ma_semaphore commandSem;\n            ma_uint32 commandIndex;\n            ma_uint32 commandCount;\n            ma_context_command__wasapi commands[4];\n            ma_handle hAvrt;\n            ma_proc AvSetMmThreadCharacteristicsA;\n            ma_proc AvRevertMmThreadcharacteristics;\n            ma_handle hMMDevapi;\n            ma_proc ActivateAudioInterfaceAsync;\n        } wasapi;\n#endif\n#ifdef MA_SUPPORT_DSOUND\n        struct\n        {\n            ma_handle hDSoundDLL;\n            ma_proc DirectSoundCreate;\n            ma_proc DirectSoundEnumerateA;\n            ma_proc DirectSoundCaptureCreate;\n            ma_proc DirectSoundCaptureEnumerateA;\n        } dsound;\n#endif\n#ifdef MA_SUPPORT_WINMM\n        struct\n        {\n            ma_handle hWinMM;\n            ma_proc waveOutGetNumDevs;\n            ma_proc waveOutGetDevCapsA;\n            ma_proc waveOutOpen;\n            ma_proc waveOutClose;\n            ma_proc waveOutPrepareHeader;\n            ma_proc waveOutUnprepareHeader;\n            ma_proc waveOutWrite;\n            ma_proc waveOutReset;\n            ma_proc waveInGetNumDevs;\n            ma_proc waveInGetDevCapsA;\n            ma_proc waveInOpen;\n            ma_proc waveInClose;\n            ma_proc waveInPrepareHeader;\n            ma_proc waveInUnprepareHeader;\n            ma_proc waveInAddBuffer;\n            ma_proc waveInStart;\n            ma_proc waveInReset;\n        } winmm;\n#endif\n#ifdef MA_SUPPORT_ALSA\n        struct\n        {\n            ma_handle asoundSO;\n            ma_proc snd_pcm_open;\n            ma_proc snd_pcm_close;\n            ma_proc snd_pcm_hw_params_sizeof;\n            ma_proc snd_pcm_hw_params_any;\n            ma_proc snd_pcm_hw_params_set_format;\n            ma_proc snd_pcm_hw_params_set_format_first;\n            ma_proc snd_pcm_hw_params_get_format_mask;\n            ma_proc snd_pcm_hw_params_set_channels;\n            ma_proc snd_pcm_hw_params_set_channels_near;\n            ma_proc snd_pcm_hw_params_set_channels_minmax;\n            ma_proc snd_pcm_hw_params_set_rate_resample;\n            ma_proc snd_pcm_hw_params_set_rate;\n            ma_proc snd_pcm_hw_params_set_rate_near;\n            ma_proc snd_pcm_hw_params_set_buffer_size_near;\n            ma_proc snd_pcm_hw_params_set_periods_near;\n            ma_proc snd_pcm_hw_params_set_access;\n            ma_proc snd_pcm_hw_params_get_format;\n            ma_proc snd_pcm_hw_params_get_channels;\n            ma_proc snd_pcm_hw_params_get_channels_min;\n            ma_proc snd_pcm_hw_params_get_channels_max;\n            ma_proc snd_pcm_hw_params_get_rate;\n            ma_proc snd_pcm_hw_params_get_rate_min;\n            ma_proc snd_pcm_hw_params_get_rate_max;\n            ma_proc snd_pcm_hw_params_get_buffer_size;\n            ma_proc snd_pcm_hw_params_get_periods;\n            ma_proc snd_pcm_hw_params_get_access;\n            ma_proc snd_pcm_hw_params_test_format;\n            ma_proc snd_pcm_hw_params_test_channels;\n            ma_proc snd_pcm_hw_params_test_rate;\n            ma_proc snd_pcm_hw_params;\n            ma_proc snd_pcm_sw_params_sizeof;\n            ma_proc snd_pcm_sw_params_current;\n            ma_proc snd_pcm_sw_params_get_boundary;\n            ma_proc snd_pcm_sw_params_set_avail_min;\n            ma_proc snd_pcm_sw_params_set_start_threshold;\n            ma_proc snd_pcm_sw_params_set_stop_threshold;\n            ma_proc snd_pcm_sw_params;\n            ma_proc snd_pcm_format_mask_sizeof;\n            ma_proc snd_pcm_format_mask_test;\n            ma_proc snd_pcm_get_chmap;\n            ma_proc snd_pcm_state;\n            ma_proc snd_pcm_prepare;\n            ma_proc snd_pcm_start;\n            ma_proc snd_pcm_drop;\n            ma_proc snd_pcm_drain;\n            ma_proc snd_pcm_reset;\n            ma_proc snd_device_name_hint;\n            ma_proc snd_device_name_get_hint;\n            ma_proc snd_card_get_index;\n            ma_proc snd_device_name_free_hint;\n            ma_proc snd_pcm_mmap_begin;\n            ma_proc snd_pcm_mmap_commit;\n            ma_proc snd_pcm_recover;\n            ma_proc snd_pcm_readi;\n            ma_proc snd_pcm_writei;\n            ma_proc snd_pcm_avail;\n            ma_proc snd_pcm_avail_update;\n            ma_proc snd_pcm_wait;\n            ma_proc snd_pcm_nonblock;\n            ma_proc snd_pcm_info;\n            ma_proc snd_pcm_info_sizeof;\n            ma_proc snd_pcm_info_get_name;\n            ma_proc snd_pcm_poll_descriptors;\n            ma_proc snd_pcm_poll_descriptors_count;\n            ma_proc snd_pcm_poll_descriptors_revents;\n            ma_proc snd_config_update_free_global;\n\n            ma_mutex internalDeviceEnumLock;\n            ma_bool32 useVerboseDeviceEnumeration;\n        } alsa;\n#endif\n#ifdef MA_SUPPORT_PULSEAUDIO\n        struct\n        {\n            ma_handle pulseSO;\n            ma_proc pa_mainloop_new;\n            ma_proc pa_mainloop_free;\n            ma_proc pa_mainloop_quit;\n            ma_proc pa_mainloop_get_api;\n            ma_proc pa_mainloop_iterate;\n            ma_proc pa_mainloop_wakeup;\n            ma_proc pa_threaded_mainloop_new;\n            ma_proc pa_threaded_mainloop_free;\n            ma_proc pa_threaded_mainloop_start;\n            ma_proc pa_threaded_mainloop_stop;\n            ma_proc pa_threaded_mainloop_lock;\n            ma_proc pa_threaded_mainloop_unlock;\n            ma_proc pa_threaded_mainloop_wait;\n            ma_proc pa_threaded_mainloop_signal;\n            ma_proc pa_threaded_mainloop_accept;\n            ma_proc pa_threaded_mainloop_get_retval;\n            ma_proc pa_threaded_mainloop_get_api;\n            ma_proc pa_threaded_mainloop_in_thread;\n            ma_proc pa_threaded_mainloop_set_name;\n            ma_proc pa_context_new;\n            ma_proc pa_context_unref;\n            ma_proc pa_context_connect;\n            ma_proc pa_context_disconnect;\n            ma_proc pa_context_set_state_callback;\n            ma_proc pa_context_get_state;\n            ma_proc pa_context_get_sink_info_list;\n            ma_proc pa_context_get_source_info_list;\n            ma_proc pa_context_get_sink_info_by_name;\n            ma_proc pa_context_get_source_info_by_name;\n            ma_proc pa_operation_unref;\n            ma_proc pa_operation_get_state;\n            ma_proc pa_channel_map_init_extend;\n            ma_proc pa_channel_map_valid;\n            ma_proc pa_channel_map_compatible;\n            ma_proc pa_stream_new;\n            ma_proc pa_stream_unref;\n            ma_proc pa_stream_connect_playback;\n            ma_proc pa_stream_connect_record;\n            ma_proc pa_stream_disconnect;\n            ma_proc pa_stream_get_state;\n            ma_proc pa_stream_get_sample_spec;\n            ma_proc pa_stream_get_channel_map;\n            ma_proc pa_stream_get_buffer_attr;\n            ma_proc pa_stream_set_buffer_attr;\n            ma_proc pa_stream_get_device_name;\n            ma_proc pa_stream_set_write_callback;\n            ma_proc pa_stream_set_read_callback;\n            ma_proc pa_stream_set_suspended_callback;\n            ma_proc pa_stream_set_moved_callback;\n            ma_proc pa_stream_is_suspended;\n            ma_proc pa_stream_flush;\n            ma_proc pa_stream_drain;\n            ma_proc pa_stream_is_corked;\n            ma_proc pa_stream_cork;\n            ma_proc pa_stream_trigger;\n            ma_proc pa_stream_begin_write;\n            ma_proc pa_stream_write;\n            ma_proc pa_stream_peek;\n            ma_proc pa_stream_drop;\n            ma_proc pa_stream_writable_size;\n            ma_proc pa_stream_readable_size;\n\n            /*pa_mainloop**/ ma_ptr pMainLoop;\n            /*pa_context**/ ma_ptr pPulseContext;\n            char* pApplicationName; /* Set when the context is initialized. Used by devices for their local pa_context objects. */\n            char* pServerName;      /* Set when the context is initialized. Used by devices for their local pa_context objects. */\n        } pulse;\n#endif\n#ifdef MA_SUPPORT_JACK\n        struct\n        {\n            ma_handle jackSO;\n            ma_proc jack_client_open;\n            ma_proc jack_client_close;\n            ma_proc jack_client_name_size;\n            ma_proc jack_set_process_callback;\n            ma_proc jack_set_buffer_size_callback;\n            ma_proc jack_on_shutdown;\n            ma_proc jack_get_sample_rate;\n            ma_proc jack_get_buffer_size;\n            ma_proc jack_get_ports;\n            ma_proc jack_activate;\n            ma_proc jack_deactivate;\n            ma_proc jack_connect;\n            ma_proc jack_port_register;\n            ma_proc jack_port_name;\n            ma_proc jack_port_get_buffer;\n            ma_proc jack_free;\n\n            char* pClientName;\n            ma_bool32 tryStartServer;\n        } jack;\n#endif\n#ifdef MA_SUPPORT_COREAUDIO\n        struct\n        {\n            ma_handle hCoreFoundation;\n            ma_proc CFStringGetCString;\n            ma_proc CFRelease;\n\n            ma_handle hCoreAudio;\n            ma_proc AudioObjectGetPropertyData;\n            ma_proc AudioObjectGetPropertyDataSize;\n            ma_proc AudioObjectSetPropertyData;\n            ma_proc AudioObjectAddPropertyListener;\n            ma_proc AudioObjectRemovePropertyListener;\n\n            ma_handle hAudioUnit;  /* Could possibly be set to AudioToolbox on later versions of macOS. */\n            ma_proc AudioComponentFindNext;\n            ma_proc AudioComponentInstanceDispose;\n            ma_proc AudioComponentInstanceNew;\n            ma_proc AudioOutputUnitStart;\n            ma_proc AudioOutputUnitStop;\n            ma_proc AudioUnitAddPropertyListener;\n            ma_proc AudioUnitGetPropertyInfo;\n            ma_proc AudioUnitGetProperty;\n            ma_proc AudioUnitSetProperty;\n            ma_proc AudioUnitInitialize;\n            ma_proc AudioUnitRender;\n\n            /*AudioComponent*/ ma_ptr component;\n            ma_bool32 noAudioSessionDeactivate; /* For tracking whether or not the iOS audio session should be explicitly deactivated. Set from the config in ma_context_init__coreaudio(). */\n        } coreaudio;\n#endif\n#ifdef MA_SUPPORT_SNDIO\n        struct\n        {\n            ma_handle sndioSO;\n            ma_proc sio_open;\n            ma_proc sio_close;\n            ma_proc sio_setpar;\n            ma_proc sio_getpar;\n            ma_proc sio_getcap;\n            ma_proc sio_start;\n            ma_proc sio_stop;\n            ma_proc sio_read;\n            ma_proc sio_write;\n            ma_proc sio_onmove;\n            ma_proc sio_nfds;\n            ma_proc sio_pollfd;\n            ma_proc sio_revents;\n            ma_proc sio_eof;\n            ma_proc sio_setvol;\n            ma_proc sio_onvol;\n            ma_proc sio_initpar;\n        } sndio;\n#endif\n#ifdef MA_SUPPORT_AUDIO4\n        struct\n        {\n            int _unused;\n        } audio4;\n#endif\n#ifdef MA_SUPPORT_OSS\n        struct\n        {\n            int versionMajor;\n            int versionMinor;\n        } oss;\n#endif\n#ifdef MA_SUPPORT_AAUDIO\n        struct\n        {\n            ma_handle hAAudio; /* libaaudio.so */\n            ma_proc AAudio_createStreamBuilder;\n            ma_proc AAudioStreamBuilder_delete;\n            ma_proc AAudioStreamBuilder_setDeviceId;\n            ma_proc AAudioStreamBuilder_setDirection;\n            ma_proc AAudioStreamBuilder_setSharingMode;\n            ma_proc AAudioStreamBuilder_setFormat;\n            ma_proc AAudioStreamBuilder_setChannelCount;\n            ma_proc AAudioStreamBuilder_setSampleRate;\n            ma_proc AAudioStreamBuilder_setBufferCapacityInFrames;\n            ma_proc AAudioStreamBuilder_setFramesPerDataCallback;\n            ma_proc AAudioStreamBuilder_setDataCallback;\n            ma_proc AAudioStreamBuilder_setErrorCallback;\n            ma_proc AAudioStreamBuilder_setPerformanceMode;\n            ma_proc AAudioStreamBuilder_setUsage;\n            ma_proc AAudioStreamBuilder_setContentType;\n            ma_proc AAudioStreamBuilder_setInputPreset;\n            ma_proc AAudioStreamBuilder_setAllowedCapturePolicy;\n            ma_proc AAudioStreamBuilder_openStream;\n            ma_proc AAudioStream_close;\n            ma_proc AAudioStream_getState;\n            ma_proc AAudioStream_waitForStateChange;\n            ma_proc AAudioStream_getFormat;\n            ma_proc AAudioStream_getChannelCount;\n            ma_proc AAudioStream_getSampleRate;\n            ma_proc AAudioStream_getBufferCapacityInFrames;\n            ma_proc AAudioStream_getFramesPerDataCallback;\n            ma_proc AAudioStream_getFramesPerBurst;\n            ma_proc AAudioStream_requestStart;\n            ma_proc AAudioStream_requestStop;\n            ma_device_job_thread jobThread; /* For processing operations outside of the error callback, specifically device disconnections and rerouting. */\n        } aaudio;\n#endif\n#ifdef MA_SUPPORT_OPENSL\n        struct\n        {\n            ma_handle libOpenSLES;\n            ma_handle SL_IID_ENGINE;\n            ma_handle SL_IID_AUDIOIODEVICECAPABILITIES;\n            ma_handle SL_IID_ANDROIDSIMPLEBUFFERQUEUE;\n            ma_handle SL_IID_RECORD;\n            ma_handle SL_IID_PLAY;\n            ma_handle SL_IID_OUTPUTMIX;\n            ma_handle SL_IID_ANDROIDCONFIGURATION;\n            ma_proc   slCreateEngine;\n        } opensl;\n#endif\n#ifdef MA_SUPPORT_WEBAUDIO\n        struct\n        {\n            int _unused;\n        } webaudio;\n#endif\n#ifdef MA_SUPPORT_NULL\n        struct\n        {\n            int _unused;\n        } null_backend;\n#endif\n    };\n\n    union\n    {\n#if defined(MA_WIN32)\n        struct\n        {\n            /*HMODULE*/ ma_handle hOle32DLL;\n            ma_proc CoInitialize;\n            ma_proc CoInitializeEx;\n            ma_proc CoUninitialize;\n            ma_proc CoCreateInstance;\n            ma_proc CoTaskMemFree;\n            ma_proc PropVariantClear;\n            ma_proc StringFromGUID2;\n\n            /*HMODULE*/ ma_handle hUser32DLL;\n            ma_proc GetForegroundWindow;\n            ma_proc GetDesktopWindow;\n\n            /*HMODULE*/ ma_handle hAdvapi32DLL;\n            ma_proc RegOpenKeyExA;\n            ma_proc RegCloseKey;\n            ma_proc RegQueryValueExA;\n\n            /*HRESULT*/ long CoInitializeResult;\n        } win32;\n#endif\n#ifdef MA_POSIX\n        struct\n        {\n            int _unused;\n        } posix;\n#endif\n        int _unused;\n    };\n};\n\nstruct ma_device\n{\n    ma_context* pContext;\n    ma_device_type type;\n    ma_uint32 sampleRate;\n    ma_atomic_device_state state;               /* The state of the device is variable and can change at any time on any thread. Must be used atomically. */\n    ma_device_data_proc onData;                 /* Set once at initialization time and should not be changed after. */\n    ma_device_notification_proc onNotification; /* Set once at initialization time and should not be changed after. */\n    ma_stop_proc onStop;                        /* DEPRECATED. Use the notification callback instead. Set once at initialization time and should not be changed after. */\n    void* pUserData;                            /* Application defined data. */\n    ma_mutex startStopLock;\n    ma_event wakeupEvent;\n    ma_event startEvent;\n    ma_event stopEvent;\n    ma_thread thread;\n    ma_result workResult;                       /* This is set by the worker thread after it's finished doing a job. */\n    ma_bool8 isOwnerOfContext;                  /* When set to true, uninitializing the device will also uninitialize the context. Set to true when NULL is passed into ma_device_init(). */\n    ma_bool8 noPreSilencedOutputBuffer;\n    ma_bool8 noClip;\n    ma_bool8 noDisableDenormals;\n    ma_bool8 noFixedSizedCallback;\n    ma_atomic_float masterVolumeFactor;         /* Linear 0..1. Can be read and written simultaneously by different threads. Must be used atomically. */\n    ma_duplex_rb duplexRB;                      /* Intermediary buffer for duplex device on asynchronous backends. */\n    struct\n    {\n        ma_resample_algorithm algorithm;\n        ma_resampling_backend_vtable* pBackendVTable;\n        void* pBackendUserData;\n        struct\n        {\n            ma_uint32 lpfOrder;\n        } linear;\n    } resampling;\n    struct\n    {\n        ma_device_id* pID;                  /* Set to NULL if using default ID, otherwise set to the address of \"id\". */\n        ma_device_id id;                    /* If using an explicit device, will be set to a copy of the ID used for initialization. Otherwise cleared to 0. */\n        char name[MA_MAX_DEVICE_NAME_LENGTH + 1];                     /* Maybe temporary. Likely to be replaced with a query API. */\n        ma_share_mode shareMode;            /* Set to whatever was passed in when the device was initialized. */\n        ma_format format;\n        ma_uint32 channels;\n        ma_channel channelMap[MA_MAX_CHANNELS];\n        ma_format internalFormat;\n        ma_uint32 internalChannels;\n        ma_uint32 internalSampleRate;\n        ma_channel internalChannelMap[MA_MAX_CHANNELS];\n        ma_uint32 internalPeriodSizeInFrames;\n        ma_uint32 internalPeriods;\n        ma_channel_mix_mode channelMixMode;\n        ma_bool32 calculateLFEFromSpatialChannels;\n        ma_data_converter converter;\n        void* pIntermediaryBuffer;          /* For implementing fixed sized buffer callbacks. Will be null if using variable sized callbacks. */\n        ma_uint32 intermediaryBufferCap;\n        ma_uint32 intermediaryBufferLen;    /* How many valid frames are sitting in the intermediary buffer. */\n        void* pInputCache;                  /* In external format. Can be null. */\n        ma_uint64 inputCacheCap;\n        ma_uint64 inputCacheConsumed;\n        ma_uint64 inputCacheRemaining;\n    } playback;\n    struct\n    {\n        ma_device_id* pID;                  /* Set to NULL if using default ID, otherwise set to the address of \"id\". */\n        ma_device_id id;                    /* If using an explicit device, will be set to a copy of the ID used for initialization. Otherwise cleared to 0. */\n        char name[MA_MAX_DEVICE_NAME_LENGTH + 1];                     /* Maybe temporary. Likely to be replaced with a query API. */\n        ma_share_mode shareMode;            /* Set to whatever was passed in when the device was initialized. */\n        ma_format format;\n        ma_uint32 channels;\n        ma_channel channelMap[MA_MAX_CHANNELS];\n        ma_format internalFormat;\n        ma_uint32 internalChannels;\n        ma_uint32 internalSampleRate;\n        ma_channel internalChannelMap[MA_MAX_CHANNELS];\n        ma_uint32 internalPeriodSizeInFrames;\n        ma_uint32 internalPeriods;\n        ma_channel_mix_mode channelMixMode;\n        ma_bool32 calculateLFEFromSpatialChannels;\n        ma_data_converter converter;\n        void* pIntermediaryBuffer;          /* For implementing fixed sized buffer callbacks. Will be null if using variable sized callbacks. */\n        ma_uint32 intermediaryBufferCap;\n        ma_uint32 intermediaryBufferLen;    /* How many valid frames are sitting in the intermediary buffer. */\n    } capture;\n\n    union\n    {\n#ifdef MA_SUPPORT_WASAPI\n        struct\n        {\n            /*IAudioClient**/ ma_ptr pAudioClientPlayback;\n            /*IAudioClient**/ ma_ptr pAudioClientCapture;\n            /*IAudioRenderClient**/ ma_ptr pRenderClient;\n            /*IAudioCaptureClient**/ ma_ptr pCaptureClient;\n            /*IMMDeviceEnumerator**/ ma_ptr pDeviceEnumerator;      /* Used for IMMNotificationClient notifications. Required for detecting default device changes. */\n            ma_IMMNotificationClient notificationClient;\n            /*HANDLE*/ ma_handle hEventPlayback;                    /* Auto reset. Initialized to signaled. */\n            /*HANDLE*/ ma_handle hEventCapture;                     /* Auto reset. Initialized to unsignaled. */\n            ma_uint32 actualBufferSizeInFramesPlayback;             /* Value from GetBufferSize(). internalPeriodSizeInFrames is not set to the _actual_ buffer size when low-latency shared mode is being used due to the way the IAudioClient3 API works. */\n            ma_uint32 actualBufferSizeInFramesCapture;\n            ma_uint32 originalPeriodSizeInFrames;\n            ma_uint32 originalPeriodSizeInMilliseconds;\n            ma_uint32 originalPeriods;\n            ma_performance_profile originalPerformanceProfile;\n            ma_uint32 periodSizeInFramesPlayback;\n            ma_uint32 periodSizeInFramesCapture;\n            void* pMappedBufferCapture;\n            ma_uint32 mappedBufferCaptureCap;\n            ma_uint32 mappedBufferCaptureLen;\n            void* pMappedBufferPlayback;\n            ma_uint32 mappedBufferPlaybackCap;\n            ma_uint32 mappedBufferPlaybackLen;\n            ma_atomic_bool32 isStartedCapture;                      /* Can be read and written simultaneously across different threads. Must be used atomically, and must be 32-bit. */\n            ma_atomic_bool32 isStartedPlayback;                     /* Can be read and written simultaneously across different threads. Must be used atomically, and must be 32-bit. */\n            ma_uint32 loopbackProcessID;\n            ma_bool8 loopbackProcessExclude;\n            ma_bool8 noAutoConvertSRC;                              /* When set to true, disables the use of AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM. */\n            ma_bool8 noDefaultQualitySRC;                           /* When set to true, disables the use of AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY. */\n            ma_bool8 noHardwareOffloading;\n            ma_bool8 allowCaptureAutoStreamRouting;\n            ma_bool8 allowPlaybackAutoStreamRouting;\n            ma_bool8 isDetachedPlayback;\n            ma_bool8 isDetachedCapture;\n            ma_wasapi_usage usage;\n            void* hAvrtHandle;\n            ma_mutex rerouteLock;\n        } wasapi;\n#endif\n#ifdef MA_SUPPORT_DSOUND\n        struct\n        {\n            /*LPDIRECTSOUND*/ ma_ptr pPlayback;\n            /*LPDIRECTSOUNDBUFFER*/ ma_ptr pPlaybackPrimaryBuffer;\n            /*LPDIRECTSOUNDBUFFER*/ ma_ptr pPlaybackBuffer;\n            /*LPDIRECTSOUNDCAPTURE*/ ma_ptr pCapture;\n            /*LPDIRECTSOUNDCAPTUREBUFFER*/ ma_ptr pCaptureBuffer;\n        } dsound;\n#endif\n#ifdef MA_SUPPORT_WINMM\n        struct\n        {\n            /*HWAVEOUT*/ ma_handle hDevicePlayback;\n            /*HWAVEIN*/ ma_handle hDeviceCapture;\n            /*HANDLE*/ ma_handle hEventPlayback;\n            /*HANDLE*/ ma_handle hEventCapture;\n            ma_uint32 fragmentSizeInFrames;\n            ma_uint32 iNextHeaderPlayback;             /* [0,periods). Used as an index into pWAVEHDRPlayback. */\n            ma_uint32 iNextHeaderCapture;              /* [0,periods). Used as an index into pWAVEHDRCapture. */\n            ma_uint32 headerFramesConsumedPlayback;    /* The number of PCM frames consumed in the buffer in pWAVEHEADER[iNextHeader]. */\n            ma_uint32 headerFramesConsumedCapture;     /* ^^^ */\n            /*WAVEHDR**/ ma_uint8* pWAVEHDRPlayback;   /* One instantiation for each period. */\n            /*WAVEHDR**/ ma_uint8* pWAVEHDRCapture;    /* One instantiation for each period. */\n            ma_uint8* pIntermediaryBufferPlayback;\n            ma_uint8* pIntermediaryBufferCapture;\n            ma_uint8* _pHeapData;                      /* Used internally and is used for the heap allocated data for the intermediary buffer and the WAVEHDR structures. */\n        } winmm;\n#endif\n#ifdef MA_SUPPORT_ALSA\n        struct\n        {\n            /*snd_pcm_t**/ ma_ptr pPCMPlayback;\n            /*snd_pcm_t**/ ma_ptr pPCMCapture;\n            /*struct pollfd**/ void* pPollDescriptorsPlayback;\n            /*struct pollfd**/ void* pPollDescriptorsCapture;\n            int pollDescriptorCountPlayback;\n            int pollDescriptorCountCapture;\n            int wakeupfdPlayback;   /* eventfd for waking up from poll() when the playback device is stopped. */\n            int wakeupfdCapture;    /* eventfd for waking up from poll() when the capture device is stopped. */\n            ma_bool8 isUsingMMapPlayback;\n            ma_bool8 isUsingMMapCapture;\n        } alsa;\n#endif\n#ifdef MA_SUPPORT_PULSEAUDIO\n        struct\n        {\n            /*pa_mainloop**/ ma_ptr pMainLoop;\n            /*pa_context**/ ma_ptr pPulseContext;\n            /*pa_stream**/ ma_ptr pStreamPlayback;\n            /*pa_stream**/ ma_ptr pStreamCapture;\n        } pulse;\n#endif\n#ifdef MA_SUPPORT_JACK\n        struct\n        {\n            /*jack_client_t**/ ma_ptr pClient;\n            /*jack_port_t**/ ma_ptr* ppPortsPlayback;\n            /*jack_port_t**/ ma_ptr* ppPortsCapture;\n            float* pIntermediaryBufferPlayback; /* Typed as a float because JACK is always floating point. */\n            float* pIntermediaryBufferCapture;\n        } jack;\n#endif\n#ifdef MA_SUPPORT_COREAUDIO\n        struct\n        {\n            ma_uint32 deviceObjectIDPlayback;\n            ma_uint32 deviceObjectIDCapture;\n            /*AudioUnit*/ ma_ptr audioUnitPlayback;\n            /*AudioUnit*/ ma_ptr audioUnitCapture;\n            /*AudioBufferList**/ ma_ptr pAudioBufferList;   /* Only used for input devices. */\n            ma_uint32 audioBufferCapInFrames;               /* Only used for input devices. The capacity in frames of each buffer in pAudioBufferList. */\n            ma_event stopEvent;\n            ma_uint32 originalPeriodSizeInFrames;\n            ma_uint32 originalPeriodSizeInMilliseconds;\n            ma_uint32 originalPeriods;\n            ma_performance_profile originalPerformanceProfile;\n            ma_bool32 isDefaultPlaybackDevice;\n            ma_bool32 isDefaultCaptureDevice;\n            ma_bool32 isSwitchingPlaybackDevice;   /* <-- Set to true when the default device has changed and miniaudio is in the process of switching. */\n            ma_bool32 isSwitchingCaptureDevice;    /* <-- Set to true when the default device has changed and miniaudio is in the process of switching. */\n            void* pNotificationHandler;             /* Only used on mobile platforms. Obj-C object for handling route changes. */\n        } coreaudio;\n#endif\n#ifdef MA_SUPPORT_SNDIO\n        struct\n        {\n            ma_ptr handlePlayback;\n            ma_ptr handleCapture;\n            ma_bool32 isStartedPlayback;\n            ma_bool32 isStartedCapture;\n        } sndio;\n#endif\n#ifdef MA_SUPPORT_AUDIO4\n        struct\n        {\n            int fdPlayback;\n            int fdCapture;\n        } audio4;\n#endif\n#ifdef MA_SUPPORT_OSS\n        struct\n        {\n            int fdPlayback;\n            int fdCapture;\n        } oss;\n#endif\n#ifdef MA_SUPPORT_AAUDIO\n        struct\n        {\n            /*AAudioStream**/ ma_ptr pStreamPlayback;\n            /*AAudioStream**/ ma_ptr pStreamCapture;\n            ma_aaudio_usage usage;\n            ma_aaudio_content_type contentType;\n            ma_aaudio_input_preset inputPreset;\n            ma_aaudio_allowed_capture_policy allowedCapturePolicy;\n            ma_bool32 noAutoStartAfterReroute;\n        } aaudio;\n#endif\n#ifdef MA_SUPPORT_OPENSL\n        struct\n        {\n            /*SLObjectItf*/ ma_ptr pOutputMixObj;\n            /*SLOutputMixItf*/ ma_ptr pOutputMix;\n            /*SLObjectItf*/ ma_ptr pAudioPlayerObj;\n            /*SLPlayItf*/ ma_ptr pAudioPlayer;\n            /*SLObjectItf*/ ma_ptr pAudioRecorderObj;\n            /*SLRecordItf*/ ma_ptr pAudioRecorder;\n            /*SLAndroidSimpleBufferQueueItf*/ ma_ptr pBufferQueuePlayback;\n            /*SLAndroidSimpleBufferQueueItf*/ ma_ptr pBufferQueueCapture;\n            ma_bool32 isDrainingCapture;\n            ma_bool32 isDrainingPlayback;\n            ma_uint32 currentBufferIndexPlayback;\n            ma_uint32 currentBufferIndexCapture;\n            ma_uint8* pBufferPlayback;      /* This is malloc()'d and is used for storing audio data. Typed as ma_uint8 for easy offsetting. */\n            ma_uint8* pBufferCapture;\n        } opensl;\n#endif\n#ifdef MA_SUPPORT_WEBAUDIO\n        struct\n        {\n            /* AudioWorklets path. */\n            /* EMSCRIPTEN_WEBAUDIO_T */ int audioContext;\n            /* EMSCRIPTEN_WEBAUDIO_T */ int audioWorklet;\n            float* pIntermediaryBuffer;\n            void* pStackBuffer;\n            ma_result initResult;   /* Set to MA_BUSY while initialization is in progress. */\n            int deviceIndex;        /* We store the device in a list on the JavaScript side. This is used to map our C object to the JS object. */\n        } webaudio;\n#endif\n#ifdef MA_SUPPORT_NULL\n        struct\n        {\n            ma_thread deviceThread;\n            ma_event operationEvent;\n            ma_event operationCompletionEvent;\n            ma_semaphore operationSemaphore;\n            ma_uint32 operation;\n            ma_result operationResult;\n            ma_timer timer;\n            double priorRunTime;\n            ma_uint32 currentPeriodFramesRemainingPlayback;\n            ma_uint32 currentPeriodFramesRemainingCapture;\n            ma_uint64 lastProcessedFramePlayback;\n            ma_uint64 lastProcessedFrameCapture;\n            ma_atomic_bool32 isStarted; /* Read and written by multiple threads. Must be used atomically, and must be 32-bit for compiler compatibility. */\n        } null_device;\n#endif\n    };\n};\n#if defined(_MSC_VER) && !defined(__clang__)\n    #pragma warning(pop)\n#elif defined(__clang__) || (defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)))\n    #pragma GCC diagnostic pop  /* For ISO C99 doesn't support unnamed structs/unions [-Wpedantic] */\n#endif\n\n/*\nInitializes a `ma_context_config` object.\n\n\nReturn Value\n------------\nA `ma_context_config` initialized to defaults.\n\n\nRemarks\n-------\nYou must always use this to initialize the default state of the `ma_context_config` object. Not using this will result in your program breaking when miniaudio\nis updated and new members are added to `ma_context_config`. It also sets logical defaults.\n\nYou can override members of the returned object by changing it's members directly.\n\n\nSee Also\n--------\nma_context_init()\n*/\nMA_API ma_context_config ma_context_config_init(void);\n\n/*\nInitializes a context.\n\nThe context is used for selecting and initializing an appropriate backend and to represent the backend at a more global level than that of an individual\ndevice. There is one context to many devices, and a device is created from a context. A context is required to enumerate devices.\n\n\nParameters\n----------\nbackends (in, optional)\n    A list of backends to try initializing, in priority order. Can be NULL, in which case it uses default priority order.\n\nbackendCount (in, optional)\n    The number of items in `backend`. Ignored if `backend` is NULL.\n\npConfig (in, optional)\n    The context configuration.\n\npContext (in)\n    A pointer to the context object being initialized.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. Do not call this function across multiple threads as some backends read and write to global state.\n\n\nRemarks\n-------\nWhen `backends` is NULL, the default priority order will be used. Below is a list of backends in priority order:\n\n    |-------------|-----------------------|--------------------------------------------------------|\n    | Name        | Enum Name             | Supported Operating Systems                            |\n    |-------------|-----------------------|--------------------------------------------------------|\n    | WASAPI      | ma_backend_wasapi     | Windows Vista+                                         |\n    | DirectSound | ma_backend_dsound     | Windows XP+                                            |\n    | WinMM       | ma_backend_winmm      | Windows XP+ (may work on older versions, but untested) |\n    | Core Audio  | ma_backend_coreaudio  | macOS, iOS                                             |\n    | ALSA        | ma_backend_alsa       | Linux                                                  |\n    | PulseAudio  | ma_backend_pulseaudio | Cross Platform (disabled on Windows, BSD and Android)  |\n    | JACK        | ma_backend_jack       | Cross Platform (disabled on BSD and Android)           |\n    | sndio       | ma_backend_sndio      | OpenBSD                                                |\n    | audio(4)    | ma_backend_audio4     | NetBSD, OpenBSD                                        |\n    | OSS         | ma_backend_oss        | FreeBSD                                                |\n    | AAudio      | ma_backend_aaudio     | Android 8+                                             |\n    | OpenSL|ES   | ma_backend_opensl     | Android (API level 16+)                                |\n    | Web Audio   | ma_backend_webaudio   | Web (via Emscripten)                                   |\n    | Null        | ma_backend_null       | Cross Platform (not used on Web)                       |\n    |-------------|-----------------------|--------------------------------------------------------|\n\nThe context can be configured via the `pConfig` argument. The config object is initialized with `ma_context_config_init()`. Individual configuration settings\ncan then be set directly on the structure. Below are the members of the `ma_context_config` object.\n\n    pLog\n        A pointer to the `ma_log` to post log messages to. Can be NULL if the application does not\n        require logging. See the `ma_log` API for details on how to use the logging system.\n\n    threadPriority\n        The desired priority to use for the audio thread. Allowable values include the following:\n\n        |--------------------------------------|\n        | Thread Priority                      |\n        |--------------------------------------|\n        | ma_thread_priority_idle              |\n        | ma_thread_priority_lowest            |\n        | ma_thread_priority_low               |\n        | ma_thread_priority_normal            |\n        | ma_thread_priority_high              |\n        | ma_thread_priority_highest (default) |\n        | ma_thread_priority_realtime          |\n        | ma_thread_priority_default           |\n        |--------------------------------------|\n\n    threadStackSize\n        The desired size of the stack for the audio thread. Defaults to the operating system's default.\n\n    pUserData\n        A pointer to application-defined data. This can be accessed from the context object directly such as `context.pUserData`.\n\n    allocationCallbacks\n        Structure containing custom allocation callbacks. Leaving this at defaults will cause it to use MA_MALLOC, MA_REALLOC and MA_FREE. These allocation\n        callbacks will be used for anything tied to the context, including devices.\n\n    alsa.useVerboseDeviceEnumeration\n        ALSA will typically enumerate many different devices which can be intrusive and not user-friendly. To combat this, miniaudio will enumerate only unique\n        card/device pairs by default. The problem with this is that you lose a bit of flexibility and control. Setting alsa.useVerboseDeviceEnumeration makes\n        it so the ALSA backend includes all devices. Defaults to false.\n\n    pulse.pApplicationName\n        PulseAudio only. The application name to use when initializing the PulseAudio context with `pa_context_new()`.\n\n    pulse.pServerName\n        PulseAudio only. The name of the server to connect to with `pa_context_connect()`.\n\n    pulse.tryAutoSpawn\n        PulseAudio only. Whether or not to try automatically starting the PulseAudio daemon. Defaults to false. If you set this to true, keep in mind that\n        miniaudio uses a trial and error method to find the most appropriate backend, and this will result in the PulseAudio daemon starting which may be\n        intrusive for the end user.\n\n    coreaudio.sessionCategory\n        iOS only. The session category to use for the shared AudioSession instance. Below is a list of allowable values and their Core Audio equivalents.\n\n        |-----------------------------------------|-------------------------------------|\n        | miniaudio Token                         | Core Audio Token                    |\n        |-----------------------------------------|-------------------------------------|\n        | ma_ios_session_category_ambient         | AVAudioSessionCategoryAmbient       |\n        | ma_ios_session_category_solo_ambient    | AVAudioSessionCategorySoloAmbient   |\n        | ma_ios_session_category_playback        | AVAudioSessionCategoryPlayback      |\n        | ma_ios_session_category_record          | AVAudioSessionCategoryRecord        |\n        | ma_ios_session_category_play_and_record | AVAudioSessionCategoryPlayAndRecord |\n        | ma_ios_session_category_multi_route     | AVAudioSessionCategoryMultiRoute    |\n        | ma_ios_session_category_none            | AVAudioSessionCategoryAmbient       |\n        | ma_ios_session_category_default         | AVAudioSessionCategoryAmbient       |\n        |-----------------------------------------|-------------------------------------|\n\n    coreaudio.sessionCategoryOptions\n        iOS only. Session category options to use with the shared AudioSession instance. Below is a list of allowable values and their Core Audio equivalents.\n\n        |---------------------------------------------------------------------------|------------------------------------------------------------------|\n        | miniaudio Token                                                           | Core Audio Token                                                 |\n        |---------------------------------------------------------------------------|------------------------------------------------------------------|\n        | ma_ios_session_category_option_mix_with_others                            | AVAudioSessionCategoryOptionMixWithOthers                        |\n        | ma_ios_session_category_option_duck_others                                | AVAudioSessionCategoryOptionDuckOthers                           |\n        | ma_ios_session_category_option_allow_bluetooth                            | AVAudioSessionCategoryOptionAllowBluetooth                       |\n        | ma_ios_session_category_option_default_to_speaker                         | AVAudioSessionCategoryOptionDefaultToSpeaker                     |\n        | ma_ios_session_category_option_interrupt_spoken_audio_and_mix_with_others | AVAudioSessionCategoryOptionInterruptSpokenAudioAndMixWithOthers |\n        | ma_ios_session_category_option_allow_bluetooth_a2dp                       | AVAudioSessionCategoryOptionAllowBluetoothA2DP                   |\n        | ma_ios_session_category_option_allow_air_play                             | AVAudioSessionCategoryOptionAllowAirPlay                         |\n        |---------------------------------------------------------------------------|------------------------------------------------------------------|\n\n    coreaudio.noAudioSessionActivate\n        iOS only. When set to true, does not perform an explicit [[AVAudioSession sharedInstace] setActive:true] on initialization.\n\n    coreaudio.noAudioSessionDeactivate\n        iOS only. When set to true, does not perform an explicit [[AVAudioSession sharedInstace] setActive:false] on uninitialization.\n\n    jack.pClientName\n        The name of the client to pass to `jack_client_open()`.\n\n    jack.tryStartServer\n        Whether or not to try auto-starting the JACK server. Defaults to false.\n\n\nIt is recommended that only a single context is active at any given time because it's a bulky data structure which performs run-time linking for the\nrelevant backends every time it's initialized.\n\nThe location of the context cannot change throughout it's lifetime. Consider allocating the `ma_context` object with `malloc()` if this is an issue. The\nreason for this is that a pointer to the context is stored in the `ma_device` structure.\n\n\nExample 1 - Default Initialization\n----------------------------------\nThe example below shows how to initialize the context using the default configuration.\n\n```c\nma_context context;\nma_result result = ma_context_init(NULL, 0, NULL, &context);\nif (result != MA_SUCCESS) {\n    // Error.\n}\n```\n\n\nExample 2 - Custom Configuration\n--------------------------------\nThe example below shows how to initialize the context using custom backend priorities and a custom configuration. In this hypothetical example, the program\nwants to prioritize ALSA over PulseAudio on Linux. They also want to avoid using the WinMM backend on Windows because it's latency is too high. They also\nwant an error to be returned if no valid backend is available which they achieve by excluding the Null backend.\n\nFor the configuration, the program wants to capture any log messages so they can, for example, route it to a log file and user interface.\n\n```c\nma_backend backends[] = {\n    ma_backend_alsa,\n    ma_backend_pulseaudio,\n    ma_backend_wasapi,\n    ma_backend_dsound\n};\n\nma_log log;\nma_log_init(&log);\nma_log_register_callback(&log, ma_log_callback_init(my_log_callbac, pMyLogUserData));\n\nma_context_config config = ma_context_config_init();\nconfig.pLog = &log; // Specify a custom log object in the config so any logs that are posted from ma_context_init() are captured.\n\nma_context context;\nma_result result = ma_context_init(backends, sizeof(backends)/sizeof(backends[0]), &config, &context);\nif (result != MA_SUCCESS) {\n    // Error.\n    if (result == MA_NO_BACKEND) {\n        // Couldn't find an appropriate backend.\n    }\n}\n\n// You could also attach a log callback post-initialization:\nma_log_register_callback(ma_context_get_log(&context), ma_log_callback_init(my_log_callback, pMyLogUserData));\n```\n\n\nSee Also\n--------\nma_context_config_init()\nma_context_uninit()\n*/\nMA_API ma_result ma_context_init(const ma_backend backends[], ma_uint32 backendCount, const ma_context_config* pConfig, ma_context* pContext);\n\n/*\nUninitializes a context.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. Do not call this function across multiple threads as some backends read and write to global state.\n\n\nRemarks\n-------\nResults are undefined if you call this while any device created by this context is still active.\n\n\nSee Also\n--------\nma_context_init()\n*/\nMA_API ma_result ma_context_uninit(ma_context* pContext);\n\n/*\nRetrieves the size of the ma_context object.\n\nThis is mainly for the purpose of bindings to know how much memory to allocate.\n*/\nMA_API size_t ma_context_sizeof(void);\n\n/*\nRetrieves a pointer to the log object associated with this context.\n\n\nRemarks\n-------\nPass the returned pointer to `ma_log_post()`, `ma_log_postv()` or `ma_log_postf()` to post a log\nmessage.\n\nYou can attach your own logging callback to the log with `ma_log_register_callback()`\n\n\nReturn Value\n------------\nA pointer to the `ma_log` object that the context uses to post log messages. If some error occurs,\nNULL will be returned.\n*/\nMA_API ma_log* ma_context_get_log(ma_context* pContext);\n\n/*\nEnumerates over every device (both playback and capture).\n\nThis is a lower-level enumeration function to the easier to use `ma_context_get_devices()`. Use `ma_context_enumerate_devices()` if you would rather not incur\nan internal heap allocation, or it simply suits your code better.\n\nNote that this only retrieves the ID and name/description of the device. The reason for only retrieving basic information is that it would otherwise require\nopening the backend device in order to probe it for more detailed information which can be inefficient. Consider using `ma_context_get_device_info()` for this,\nbut don't call it from within the enumeration callback.\n\nReturning false from the callback will stop enumeration. Returning true will continue enumeration.\n\n\nParameters\n----------\npContext (in)\n    A pointer to the context performing the enumeration.\n\ncallback (in)\n    The callback to fire for each enumerated device.\n\npUserData (in)\n    A pointer to application-defined data passed to the callback.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nSafe. This is guarded using a simple mutex lock.\n\n\nRemarks\n-------\nDo _not_ assume the first enumerated device of a given type is the default device.\n\nSome backends and platforms may only support default playback and capture devices.\n\nIn general, you should not do anything complicated from within the callback. In particular, do not try initializing a device from within the callback. Also,\ndo not try to call `ma_context_get_device_info()` from within the callback.\n\nConsider using `ma_context_get_devices()` for a simpler and safer API, albeit at the expense of an internal heap allocation.\n\n\nExample 1 - Simple Enumeration\n------------------------------\nma_bool32 ma_device_enum_callback(ma_context* pContext, ma_device_type deviceType, const ma_device_info* pInfo, void* pUserData)\n{\n    printf(\"Device Name: %s\\n\", pInfo->name);\n    return MA_TRUE;\n}\n\nma_result result = ma_context_enumerate_devices(&context, my_device_enum_callback, pMyUserData);\nif (result != MA_SUCCESS) {\n    // Error.\n}\n\n\nSee Also\n--------\nma_context_get_devices()\n*/\nMA_API ma_result ma_context_enumerate_devices(ma_context* pContext, ma_enum_devices_callback_proc callback, void* pUserData);\n\n/*\nRetrieves basic information about every active playback and/or capture device.\n\nThis function will allocate memory internally for the device lists and return a pointer to them through the `ppPlaybackDeviceInfos` and `ppCaptureDeviceInfos`\nparameters. If you do not want to incur the overhead of these allocations consider using `ma_context_enumerate_devices()` which will instead use a callback.\n\n\nParameters\n----------\npContext (in)\n    A pointer to the context performing the enumeration.\n\nppPlaybackDeviceInfos (out)\n    A pointer to a pointer that will receive the address of a buffer containing the list of `ma_device_info` structures for playback devices.\n\npPlaybackDeviceCount (out)\n    A pointer to an unsigned integer that will receive the number of playback devices.\n\nppCaptureDeviceInfos (out)\n    A pointer to a pointer that will receive the address of a buffer containing the list of `ma_device_info` structures for capture devices.\n\npCaptureDeviceCount (out)\n    A pointer to an unsigned integer that will receive the number of capture devices.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. Since each call to this function invalidates the pointers from the previous call, you should not be calling this simultaneously across multiple\nthreads. Instead, you need to make a copy of the returned data with your own higher level synchronization.\n\n\nRemarks\n-------\nIt is _not_ safe to assume the first device in the list is the default device.\n\nYou can pass in NULL for the playback or capture lists in which case they'll be ignored.\n\nThe returned pointers will become invalid upon the next call this this function, or when the context is uninitialized. Do not free the returned pointers.\n\n\nSee Also\n--------\nma_context_get_devices()\n*/\nMA_API ma_result ma_context_get_devices(ma_context* pContext, ma_device_info** ppPlaybackDeviceInfos, ma_uint32* pPlaybackDeviceCount, ma_device_info** ppCaptureDeviceInfos, ma_uint32* pCaptureDeviceCount);\n\n/*\nRetrieves information about a device of the given type, with the specified ID and share mode.\n\n\nParameters\n----------\npContext (in)\n    A pointer to the context performing the query.\n\ndeviceType (in)\n    The type of the device being queried. Must be either `ma_device_type_playback` or `ma_device_type_capture`.\n\npDeviceID (in)\n    The ID of the device being queried.\n\npDeviceInfo (out)\n    A pointer to the `ma_device_info` structure that will receive the device information.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nSafe. This is guarded using a simple mutex lock.\n\n\nRemarks\n-------\nDo _not_ call this from within the `ma_context_enumerate_devices()` callback.\n\nIt's possible for a device to have different information and capabilities depending on whether or not it's opened in shared or exclusive mode. For example, in\nshared mode, WASAPI always uses floating point samples for mixing, but in exclusive mode it can be anything. Therefore, this function allows you to specify\nwhich share mode you want information for. Note that not all backends and devices support shared or exclusive mode, in which case this function will fail if\nthe requested share mode is unsupported.\n\nThis leaves pDeviceInfo unmodified in the result of an error.\n*/\nMA_API ma_result ma_context_get_device_info(ma_context* pContext, ma_device_type deviceType, const ma_device_id* pDeviceID, ma_device_info* pDeviceInfo);\n\n/*\nDetermines if the given context supports loopback mode.\n\n\nParameters\n----------\npContext (in)\n    A pointer to the context getting queried.\n\n\nReturn Value\n------------\nMA_TRUE if the context supports loopback mode; MA_FALSE otherwise.\n*/\nMA_API ma_bool32 ma_context_is_loopback_supported(ma_context* pContext);\n\n\n\n/*\nInitializes a device config with default settings.\n\n\nParameters\n----------\ndeviceType (in)\n    The type of the device this config is being initialized for. This must set to one of the following:\n\n    |-------------------------|\n    | Device Type             |\n    |-------------------------|\n    | ma_device_type_playback |\n    | ma_device_type_capture  |\n    | ma_device_type_duplex   |\n    | ma_device_type_loopback |\n    |-------------------------|\n\n\nReturn Value\n------------\nA new device config object with default settings. You will typically want to adjust the config after this function returns. See remarks.\n\n\nThread Safety\n-------------\nSafe.\n\n\nCallback Safety\n---------------\nSafe, but don't try initializing a device in a callback.\n\n\nRemarks\n-------\nThe returned config will be initialized to defaults. You will normally want to customize a few variables before initializing the device. See Example 1 for a\ntypical configuration which sets the sample format, channel count, sample rate, data callback and user data. These are usually things you will want to change\nbefore initializing the device.\n\nSee `ma_device_init()` for details on specific configuration options.\n\n\nExample 1 - Simple Configuration\n--------------------------------\nThe example below is what a program will typically want to configure for each device at a minimum. Notice how `ma_device_config_init()` is called first, and\nthen the returned object is modified directly. This is important because it ensures that your program continues to work as new configuration options are added\nto the `ma_device_config` structure.\n\n```c\nma_device_config config = ma_device_config_init(ma_device_type_playback);\nconfig.playback.format   = ma_format_f32;\nconfig.playback.channels = 2;\nconfig.sampleRate        = 48000;\nconfig.dataCallback      = ma_data_callback;\nconfig.pUserData         = pMyUserData;\n```\n\n\nSee Also\n--------\nma_device_init()\nma_device_init_ex()\n*/\nMA_API ma_device_config ma_device_config_init(ma_device_type deviceType);\n\n\n/*\nInitializes a device.\n\nA device represents a physical audio device. The idea is you send or receive audio data from the device to either play it back through a speaker, or capture it\nfrom a microphone. Whether or not you should send or receive data from the device (or both) depends on the type of device you are initializing which can be\nplayback, capture, full-duplex or loopback. (Note that loopback mode is only supported on select backends.) Sending and receiving audio data to and from the\ndevice is done via a callback which is fired by miniaudio at periodic time intervals.\n\nThe frequency at which data is delivered to and from a device depends on the size of it's period. The size of the period can be defined in terms of PCM frames\nor milliseconds, whichever is more convenient. Generally speaking, the smaller the period, the lower the latency at the expense of higher CPU usage and\nincreased risk of glitching due to the more frequent and granular data deliver intervals. The size of a period will depend on your requirements, but\nminiaudio's defaults should work fine for most scenarios. If you're building a game you should leave this fairly small, whereas if you're building a simple\nmedia player you can make it larger. Note that the period size you request is actually just a hint - miniaudio will tell the backend what you want, but the\nbackend is ultimately responsible for what it gives you. You cannot assume you will get exactly what you ask for.\n\nWhen delivering data to and from a device you need to make sure it's in the correct format which you can set through the device configuration. You just set the\nformat that you want to use and miniaudio will perform all of the necessary conversion for you internally. When delivering data to and from the callback you\ncan assume the format is the same as what you requested when you initialized the device. See Remarks for more details on miniaudio's data conversion pipeline.\n\n\nParameters\n----------\npContext (in, optional)\n    A pointer to the context that owns the device. This can be null, in which case it creates a default context internally.\n\npConfig (in)\n    A pointer to the device configuration. Cannot be null. See remarks for details.\n\npDevice (out)\n    A pointer to the device object being initialized.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. It is not safe to call this function simultaneously for different devices because some backends depend on and mutate global state. The same applies to\ncalling this at the same time as `ma_device_uninit()`.\n\n\nCallback Safety\n---------------\nUnsafe. It is not safe to call this inside any callback.\n\n\nRemarks\n-------\nSetting `pContext` to NULL will result in miniaudio creating a default context internally and is equivalent to passing in a context initialized like so:\n\n    ```c\n    ma_context_init(NULL, 0, NULL, &context);\n    ```\n\nDo not set `pContext` to NULL if you are needing to open multiple devices. You can, however, use NULL when initializing the first device, and then use\ndevice.pContext for the initialization of other devices.\n\nThe device can be configured via the `pConfig` argument. The config object is initialized with `ma_device_config_init()`. Individual configuration settings can\nthen be set directly on the structure. Below are the members of the `ma_device_config` object.\n\n    deviceType\n        Must be `ma_device_type_playback`, `ma_device_type_capture`, `ma_device_type_duplex` of `ma_device_type_loopback`.\n\n    sampleRate\n        The sample rate, in hertz. The most common sample rates are 48000 and 44100. Setting this to 0 will use the device's native sample rate.\n\n    periodSizeInFrames\n        The desired size of a period in PCM frames. If this is 0, `periodSizeInMilliseconds` will be used instead. If both are 0 the default buffer size will\n        be used depending on the selected performance profile. This value affects latency. See below for details.\n\n    periodSizeInMilliseconds\n        The desired size of a period in milliseconds. If this is 0, `periodSizeInFrames` will be used instead. If both are 0 the default buffer size will be\n        used depending on the selected performance profile. The value affects latency. See below for details.\n\n    periods\n        The number of periods making up the device's entire buffer. The total buffer size is `periodSizeInFrames` or `periodSizeInMilliseconds` multiplied by\n        this value. This is just a hint as backends will be the ones who ultimately decide how your periods will be configured.\n\n    performanceProfile\n        A hint to miniaudio as to the performance requirements of your program. Can be either `ma_performance_profile_low_latency` (default) or\n        `ma_performance_profile_conservative`. This mainly affects the size of default buffers and can usually be left at it's default value.\n\n    noPreSilencedOutputBuffer\n        When set to true, the contents of the output buffer passed into the data callback will be left undefined. When set to false (default), the contents of\n        the output buffer will be cleared the zero. You can use this to avoid the overhead of zeroing out the buffer if you can guarantee that your data\n        callback will write to every sample in the output buffer, or if you are doing your own clearing.\n\n    noClip\n        When set to true, the contents of the output buffer are left alone after returning and it will be left up to the backend itself to decide whether or\n        not to clip. When set to false (default), the contents of the output buffer passed into the data callback will be clipped after returning. This only\n        applies when the playback sample format is f32.\n\n    noDisableDenormals\n        By default, miniaudio will disable denormals when the data callback is called. Setting this to true will prevent the disabling of denormals.\n\n    noFixedSizedCallback\n        Allows miniaudio to fire the data callback with any frame count. When this is set to false (the default), the data callback will be fired with a\n        consistent frame count as specified by `periodSizeInFrames` or `periodSizeInMilliseconds`. When set to true, miniaudio will fire the callback with\n        whatever the backend requests, which could be anything.\n\n    dataCallback\n        The callback to fire whenever data is ready to be delivered to or from the device.\n\n    notificationCallback\n        The callback to fire when something has changed with the device, such as whether or not it has been started or stopped.\n\n    pUserData\n        The user data pointer to use with the device. You can access this directly from the device object like `device.pUserData`.\n\n    resampling.algorithm\n        The resampling algorithm to use when miniaudio needs to perform resampling between the rate specified by `sampleRate` and the device's native rate. The\n        default value is `ma_resample_algorithm_linear`, and the quality can be configured with `resampling.linear.lpfOrder`.\n\n    resampling.pBackendVTable\n        A pointer to an optional vtable that can be used for plugging in a custom resampler.\n\n    resampling.pBackendUserData\n        A pointer that will passed to callbacks in pBackendVTable.\n\n    resampling.linear.lpfOrder\n        The linear resampler applies a low-pass filter as part of it's processing for anti-aliasing. This setting controls the order of the filter. The higher\n        the value, the better the quality, in general. Setting this to 0 will disable low-pass filtering altogether. The maximum value is\n        `MA_MAX_FILTER_ORDER`. The default value is `min(4, MA_MAX_FILTER_ORDER)`.\n\n    playback.pDeviceID\n        A pointer to a `ma_device_id` structure containing the ID of the playback device to initialize. Setting this NULL (default) will use the system's\n        default playback device. Retrieve the device ID from the `ma_device_info` structure, which can be retrieved using device enumeration.\n\n    playback.format\n        The sample format to use for playback. When set to `ma_format_unknown` the device's native format will be used. This can be retrieved after\n        initialization from the device object directly with `device.playback.format`.\n\n    playback.channels\n        The number of channels to use for playback. When set to 0 the device's native channel count will be used. This can be retrieved after initialization\n        from the device object directly with `device.playback.channels`.\n\n    playback.pChannelMap\n        The channel map to use for playback. When left empty, the device's native channel map will be used. This can be retrieved after initialization from the\n        device object direct with `device.playback.pChannelMap`. When set, the buffer should contain `channels` items.\n\n    playback.shareMode\n        The preferred share mode to use for playback. Can be either `ma_share_mode_shared` (default) or `ma_share_mode_exclusive`. Note that if you specify\n        exclusive mode, but it's not supported by the backend, initialization will fail. You can then fall back to shared mode if desired by changing this to\n        ma_share_mode_shared and reinitializing.\n\n    capture.pDeviceID\n        A pointer to a `ma_device_id` structure containing the ID of the capture device to initialize. Setting this NULL (default) will use the system's\n        default capture device. Retrieve the device ID from the `ma_device_info` structure, which can be retrieved using device enumeration.\n\n    capture.format\n        The sample format to use for capture. When set to `ma_format_unknown` the device's native format will be used. This can be retrieved after\n        initialization from the device object directly with `device.capture.format`.\n\n    capture.channels\n        The number of channels to use for capture. When set to 0 the device's native channel count will be used. This can be retrieved after initialization\n        from the device object directly with `device.capture.channels`.\n\n    capture.pChannelMap\n        The channel map to use for capture. When left empty, the device's native channel map will be used. This can be retrieved after initialization from the\n        device object direct with `device.capture.pChannelMap`. When set, the buffer should contain `channels` items.\n\n    capture.shareMode\n        The preferred share mode to use for capture. Can be either `ma_share_mode_shared` (default) or `ma_share_mode_exclusive`. Note that if you specify\n        exclusive mode, but it's not supported by the backend, initialization will fail. You can then fall back to shared mode if desired by changing this to\n        ma_share_mode_shared and reinitializing.\n\n    wasapi.noAutoConvertSRC\n        WASAPI only. When set to true, disables WASAPI's automatic resampling and forces the use of miniaudio's resampler. Defaults to false.\n\n    wasapi.noDefaultQualitySRC\n        WASAPI only. Only used when `wasapi.noAutoConvertSRC` is set to false. When set to true, disables the use of `AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY`.\n        You should usually leave this set to false, which is the default.\n\n    wasapi.noAutoStreamRouting\n        WASAPI only. When set to true, disables automatic stream routing on the WASAPI backend. Defaults to false.\n\n    wasapi.noHardwareOffloading\n        WASAPI only. When set to true, disables the use of WASAPI's hardware offloading feature. Defaults to false.\n\n    alsa.noMMap\n        ALSA only. When set to true, disables MMap mode. Defaults to false.\n\n    alsa.noAutoFormat\n        ALSA only. When set to true, disables ALSA's automatic format conversion by including the SND_PCM_NO_AUTO_FORMAT flag. Defaults to false.\n\n    alsa.noAutoChannels\n        ALSA only. When set to true, disables ALSA's automatic channel conversion by including the SND_PCM_NO_AUTO_CHANNELS flag. Defaults to false.\n\n    alsa.noAutoResample\n        ALSA only. When set to true, disables ALSA's automatic resampling by including the SND_PCM_NO_AUTO_RESAMPLE flag. Defaults to false.\n\n    pulse.pStreamNamePlayback\n        PulseAudio only. Sets the stream name for playback.\n\n    pulse.pStreamNameCapture\n        PulseAudio only. Sets the stream name for capture.\n\n    coreaudio.allowNominalSampleRateChange\n        Core Audio only. Desktop only. When enabled, allows the sample rate of the device to be changed at the operating system level. This\n        is disabled by default in order to prevent intrusive changes to the user's system. This is useful if you want to use a sample rate\n        that is known to be natively supported by the hardware thereby avoiding the cost of resampling. When set to true, miniaudio will\n        find the closest match between the sample rate requested in the device config and the sample rates natively supported by the\n        hardware. When set to false, the sample rate currently set by the operating system will always be used.\n\n    opensl.streamType\n        OpenSL only. Explicitly sets the stream type. If left unset (`ma_opensl_stream_type_default`), the\n        stream type will be left unset. Think of this as the type of audio you're playing.\n\n    opensl.recordingPreset\n        OpenSL only. Explicitly sets the type of recording your program will be doing. When left\n        unset, the recording preset will be left unchanged.\n\n    aaudio.usage\n        AAudio only. Explicitly sets the nature of the audio the program will be consuming. When\n        left unset, the usage will be left unchanged.\n\n    aaudio.contentType\n        AAudio only. Sets the content type. When left unset, the content type will be left unchanged.\n\n    aaudio.inputPreset\n        AAudio only. Explicitly sets the type of recording your program will be doing. When left\n        unset, the input preset will be left unchanged.\n\n    aaudio.noAutoStartAfterReroute\n        AAudio only. Controls whether or not the device should be automatically restarted after a\n        stream reroute. When set to false (default) the device will be restarted automatically;\n        otherwise the device will be stopped.\n\n\nOnce initialized, the device's config is immutable. If you need to change the config you will need to initialize a new device.\n\nAfter initializing the device it will be in a stopped state. To start it, use `ma_device_start()`.\n\nIf both `periodSizeInFrames` and `periodSizeInMilliseconds` are set to zero, it will default to `MA_DEFAULT_PERIOD_SIZE_IN_MILLISECONDS_LOW_LATENCY` or\n`MA_DEFAULT_PERIOD_SIZE_IN_MILLISECONDS_CONSERVATIVE`, depending on whether or not `performanceProfile` is set to `ma_performance_profile_low_latency` or\n`ma_performance_profile_conservative`.\n\nIf you request exclusive mode and the backend does not support it an error will be returned. For robustness, you may want to first try initializing the device\nin exclusive mode, and then fall back to shared mode if required. Alternatively you can just request shared mode (the default if you leave it unset in the\nconfig) which is the most reliable option. Some backends do not have a practical way of choosing whether or not the device should be exclusive or not (ALSA,\nfor example) in which case it just acts as a hint. Unless you have special requirements you should try avoiding exclusive mode as it's intrusive to the user.\nStarting with Windows 10, miniaudio will use low-latency shared mode where possible which may make exclusive mode unnecessary.\n\nWhen sending or receiving data to/from a device, miniaudio will internally perform a format conversion to convert between the format specified by the config\nand the format used internally by the backend. If you pass in 0 for the sample format, channel count, sample rate _and_ channel map, data transmission will run\non an optimized pass-through fast path. You can retrieve the format, channel count and sample rate by inspecting the `playback/capture.format`,\n`playback/capture.channels` and `sampleRate` members of the device object.\n\nWhen compiling for UWP you must ensure you call this function on the main UI thread because the operating system may need to present the user with a message\nasking for permissions. Please refer to the official documentation for ActivateAudioInterfaceAsync() for more information.\n\nALSA Specific: When initializing the default device, requesting shared mode will try using the \"dmix\" device for playback and the \"dsnoop\" device for capture.\nIf these fail it will try falling back to the \"hw\" device.\n\n\nExample 1 - Simple Initialization\n---------------------------------\nThis example shows how to initialize a simple playback device using a standard configuration. If you are just needing to do simple playback from the default\nplayback device this is usually all you need.\n\n```c\nma_device_config config = ma_device_config_init(ma_device_type_playback);\nconfig.playback.format   = ma_format_f32;\nconfig.playback.channels = 2;\nconfig.sampleRate        = 48000;\nconfig.dataCallback      = ma_data_callback;\nconfig.pMyUserData       = pMyUserData;\n\nma_device device;\nma_result result = ma_device_init(NULL, &config, &device);\nif (result != MA_SUCCESS) {\n    // Error\n}\n```\n\n\nExample 2 - Advanced Initialization\n-----------------------------------\nThis example shows how you might do some more advanced initialization. In this hypothetical example we want to control the latency by setting the buffer size\nand period count. We also want to allow the user to be able to choose which device to output from which means we need a context so we can perform device\nenumeration.\n\n```c\nma_context context;\nma_result result = ma_context_init(NULL, 0, NULL, &context);\nif (result != MA_SUCCESS) {\n    // Error\n}\n\nma_device_info* pPlaybackDeviceInfos;\nma_uint32 playbackDeviceCount;\nresult = ma_context_get_devices(&context, &pPlaybackDeviceInfos, &playbackDeviceCount, NULL, NULL);\nif (result != MA_SUCCESS) {\n    // Error\n}\n\n// ... choose a device from pPlaybackDeviceInfos ...\n\nma_device_config config = ma_device_config_init(ma_device_type_playback);\nconfig.playback.pDeviceID       = pMyChosenDeviceID;    // <-- Get this from the `id` member of one of the `ma_device_info` objects returned by ma_context_get_devices().\nconfig.playback.format          = ma_format_f32;\nconfig.playback.channels        = 2;\nconfig.sampleRate               = 48000;\nconfig.dataCallback             = ma_data_callback;\nconfig.pUserData                = pMyUserData;\nconfig.periodSizeInMilliseconds = 10;\nconfig.periods                  = 3;\n\nma_device device;\nresult = ma_device_init(&context, &config, &device);\nif (result != MA_SUCCESS) {\n    // Error\n}\n```\n\n\nSee Also\n--------\nma_device_config_init()\nma_device_uninit()\nma_device_start()\nma_context_init()\nma_context_get_devices()\nma_context_enumerate_devices()\n*/\nMA_API ma_result ma_device_init(ma_context* pContext, const ma_device_config* pConfig, ma_device* pDevice);\n\n/*\nInitializes a device without a context, with extra parameters for controlling the configuration of the internal self-managed context.\n\nThis is the same as `ma_device_init()`, only instead of a context being passed in, the parameters from `ma_context_init()` are passed in instead. This function\nallows you to configure the internally created context.\n\n\nParameters\n----------\nbackends (in, optional)\n    A list of backends to try initializing, in priority order. Can be NULL, in which case it uses default priority order.\n\nbackendCount (in, optional)\n    The number of items in `backend`. Ignored if `backend` is NULL.\n\npContextConfig (in, optional)\n    The context configuration.\n\npConfig (in)\n    A pointer to the device configuration. Cannot be null. See remarks for details.\n\npDevice (out)\n    A pointer to the device object being initialized.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. It is not safe to call this function simultaneously for different devices because some backends depend on and mutate global state. The same applies to\ncalling this at the same time as `ma_device_uninit()`.\n\n\nCallback Safety\n---------------\nUnsafe. It is not safe to call this inside any callback.\n\n\nRemarks\n-------\nYou only need to use this function if you want to configure the context differently to it's defaults. You should never use this function if you want to manage\nyour own context.\n\nSee the documentation for `ma_context_init()` for information on the different context configuration options.\n\n\nSee Also\n--------\nma_device_init()\nma_device_uninit()\nma_device_config_init()\nma_context_init()\n*/\nMA_API ma_result ma_device_init_ex(const ma_backend backends[], ma_uint32 backendCount, const ma_context_config* pContextConfig, const ma_device_config* pConfig, ma_device* pDevice);\n\n/*\nUninitializes a device.\n\nThis will explicitly stop the device. You do not need to call `ma_device_stop()` beforehand, but it's harmless if you do.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device to stop.\n\n\nReturn Value\n------------\nNothing\n\n\nThread Safety\n-------------\nUnsafe. As soon as this API is called the device should be considered undefined.\n\n\nCallback Safety\n---------------\nUnsafe. It is not safe to call this inside any callback. Doing this will result in a deadlock.\n\n\nSee Also\n--------\nma_device_init()\nma_device_stop()\n*/\nMA_API void ma_device_uninit(ma_device* pDevice);\n\n\n/*\nRetrieves a pointer to the context that owns the given device.\n*/\nMA_API ma_context* ma_device_get_context(ma_device* pDevice);\n\n/*\nHelper function for retrieving the log object associated with the context that owns this device.\n*/\nMA_API ma_log* ma_device_get_log(ma_device* pDevice);\n\n\n/*\nRetrieves information about the device.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose information is being retrieved.\n\ntype (in)\n    The device type. This parameter is required for duplex devices. When retrieving device\n    information, you are doing so for an individual playback or capture device.\n\npDeviceInfo (out)\n    A pointer to the `ma_device_info` that will receive the device information.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. This should be considered unsafe because it may be calling into the backend which may or\nmay not be safe.\n\n\nCallback Safety\n---------------\nUnsafe. You should avoid calling this in the data callback because it may call into the backend\nwhich may or may not be safe.\n*/\nMA_API ma_result ma_device_get_info(ma_device* pDevice, ma_device_type type, ma_device_info* pDeviceInfo);\n\n\n/*\nRetrieves the name of the device.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose information is being retrieved.\n\ntype (in)\n    The device type. This parameter is required for duplex devices. When retrieving device\n    information, you are doing so for an individual playback or capture device.\n\npName (out)\n    A pointer to the buffer that will receive the name.\n\nnameCap (in)\n    The capacity of the output buffer, including space for the null terminator.\n\npLengthNotIncludingNullTerminator (out, optional)\n    A pointer to the variable that will receive the length of the name, not including the null\n    terminator.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nUnsafe. This should be considered unsafe because it may be calling into the backend which may or\nmay not be safe.\n\n\nCallback Safety\n---------------\nUnsafe. You should avoid calling this in the data callback because it may call into the backend\nwhich may or may not be safe.\n\n\nRemarks\n-------\nIf the name does not fully fit into the output buffer, it'll be truncated. You can pass in NULL to\n`pName` if you want to first get the length of the name for the purpose of memory allocation of the\noutput buffer. Allocating a buffer of size `MA_MAX_DEVICE_NAME_LENGTH + 1` should be enough for\nmost cases and will avoid the need for the inefficiency of calling this function twice.\n\nThis is implemented in terms of `ma_device_get_info()`.\n*/\nMA_API ma_result ma_device_get_name(ma_device* pDevice, ma_device_type type, char* pName, size_t nameCap, size_t* pLengthNotIncludingNullTerminator);\n\n\n/*\nStarts the device. For playback devices this begins playback. For capture devices it begins recording.\n\nUse `ma_device_stop()` to stop the device.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device to start.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nSafe. It's safe to call this from any thread with the exception of the callback thread.\n\n\nCallback Safety\n---------------\nUnsafe. It is not safe to call this inside any callback.\n\n\nRemarks\n-------\nFor a playback device, this will retrieve an initial chunk of audio data from the client before returning. The reason for this is to ensure there is valid\naudio data in the buffer, which needs to be done before the device begins playback.\n\nThis API waits until the backend device has been started for real by the worker thread. It also waits on a mutex for thread-safety.\n\nDo not call this in any callback.\n\n\nSee Also\n--------\nma_device_stop()\n*/\nMA_API ma_result ma_device_start(ma_device* pDevice);\n\n/*\nStops the device. For playback devices this stops playback. For capture devices it stops recording.\n\nUse `ma_device_start()` to start the device again.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device to stop.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error code otherwise.\n\n\nThread Safety\n-------------\nSafe. It's safe to call this from any thread with the exception of the callback thread.\n\n\nCallback Safety\n---------------\nUnsafe. It is not safe to call this inside any callback. Doing this will result in a deadlock.\n\n\nRemarks\n-------\nThis API needs to wait on the worker thread to stop the backend device properly before returning. It also waits on a mutex for thread-safety. In addition, some\nbackends need to wait for the device to finish playback/recording of the current fragment which can take some time (usually proportionate to the buffer size\nthat was specified at initialization time).\n\nBackends are required to either pause the stream in-place or drain the buffer if pausing is not possible. The reason for this is that stopping the device and\nthe resuming it with ma_device_start() (which you might do when your program loses focus) may result in a situation where those samples are never output to the\nspeakers or received from the microphone which can in turn result in de-syncs.\n\nDo not call this in any callback.\n\n\nSee Also\n--------\nma_device_start()\n*/\nMA_API ma_result ma_device_stop(ma_device* pDevice);\n\n/*\nDetermines whether or not the device is started.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose start state is being retrieved.\n\n\nReturn Value\n------------\nTrue if the device is started, false otherwise.\n\n\nThread Safety\n-------------\nSafe. If another thread calls `ma_device_start()` or `ma_device_stop()` at this same time as this function is called, there's a very small chance the return\nvalue will be out of sync.\n\n\nCallback Safety\n---------------\nSafe. This is implemented as a simple accessor.\n\n\nSee Also\n--------\nma_device_start()\nma_device_stop()\n*/\nMA_API ma_bool32 ma_device_is_started(const ma_device* pDevice);\n\n\n/*\nRetrieves the state of the device.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose state is being retrieved.\n\n\nReturn Value\n------------\nThe current state of the device. The return value will be one of the following:\n\n    +-------------------------------+------------------------------------------------------------------------------+\n    | ma_device_state_uninitialized | Will only be returned if the device is in the middle of initialization.      |\n    +-------------------------------+------------------------------------------------------------------------------+\n    | ma_device_state_stopped       | The device is stopped. The initial state of the device after initialization. |\n    +-------------------------------+------------------------------------------------------------------------------+\n    | ma_device_state_started       | The device started and requesting and/or delivering audio data.              |\n    +-------------------------------+------------------------------------------------------------------------------+\n    | ma_device_state_starting      | The device is in the process of starting.                                    |\n    +-------------------------------+------------------------------------------------------------------------------+\n    | ma_device_state_stopping      | The device is in the process of stopping.                                    |\n    +-------------------------------+------------------------------------------------------------------------------+\n\n\nThread Safety\n-------------\nSafe. This is implemented as a simple accessor. Note that if the device is started or stopped at the same time as this function is called,\nthere's a possibility the return value could be out of sync. See remarks.\n\n\nCallback Safety\n---------------\nSafe. This is implemented as a simple accessor.\n\n\nRemarks\n-------\nThe general flow of a devices state goes like this:\n\n    ```\n    ma_device_init()  -> ma_device_state_uninitialized -> ma_device_state_stopped\n    ma_device_start() -> ma_device_state_starting      -> ma_device_state_started\n    ma_device_stop()  -> ma_device_state_stopping      -> ma_device_state_stopped\n    ```\n\nWhen the state of the device is changed with `ma_device_start()` or `ma_device_stop()` at this same time as this function is called, the\nvalue returned by this function could potentially be out of sync. If this is significant to your program you need to implement your own\nsynchronization.\n*/\nMA_API ma_device_state ma_device_get_state(const ma_device* pDevice);\n\n\n/*\nPerforms post backend initialization routines for setting up internal data conversion.\n\nThis should be called whenever the backend is initialized. The only time this should be called from\noutside of miniaudio is if you're implementing a custom backend, and you would only do it if you\nare reinitializing the backend due to rerouting or reinitializing for some reason.\n\n\nParameters\n----------\npDevice [in]\n    A pointer to the device.\n\ndeviceType [in]\n    The type of the device that was just reinitialized.\n\npPlaybackDescriptor [in]\n    The descriptor of the playback device containing the internal data format and buffer sizes.\n\npPlaybackDescriptor [in]\n    The descriptor of the capture device containing the internal data format and buffer sizes.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other error otherwise.\n\n\nThread Safety\n-------------\nUnsafe. This will be reinitializing internal data converters which may be in use by another thread.\n\n\nCallback Safety\n---------------\nUnsafe. This will be reinitializing internal data converters which may be in use by the callback.\n\n\nRemarks\n-------\nFor a duplex device, you can call this for only one side of the system. This is why the deviceType\nis specified as a parameter rather than deriving it from the device.\n\nYou do not need to call this manually unless you are doing a custom backend, in which case you need\nonly do it if you're manually performing rerouting or reinitialization.\n*/\nMA_API ma_result ma_device_post_init(ma_device* pDevice, ma_device_type deviceType, const ma_device_descriptor* pPlaybackDescriptor, const ma_device_descriptor* pCaptureDescriptor);\n\n\n/*\nSets the master volume factor for the device.\n\nThe volume factor must be between 0 (silence) and 1 (full volume). Use `ma_device_set_master_volume_db()` to use decibel notation, where 0 is full volume and\nvalues less than 0 decreases the volume.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose volume is being set.\n\nvolume (in)\n    The new volume factor. Must be >= 0.\n\n\nReturn Value\n------------\nMA_SUCCESS if the volume was set successfully.\nMA_INVALID_ARGS if pDevice is NULL.\nMA_INVALID_ARGS if volume is negative.\n\n\nThread Safety\n-------------\nSafe. This just sets a local member of the device object.\n\n\nCallback Safety\n---------------\nSafe. If you set the volume in the data callback, that data written to the output buffer will have the new volume applied.\n\n\nRemarks\n-------\nThis applies the volume factor across all channels.\n\nThis does not change the operating system's volume. It only affects the volume for the given `ma_device` object's audio stream.\n\n\nSee Also\n--------\nma_device_get_master_volume()\nma_device_set_master_volume_db()\nma_device_get_master_volume_db()\n*/\nMA_API ma_result ma_device_set_master_volume(ma_device* pDevice, float volume);\n\n/*\nRetrieves the master volume factor for the device.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose volume factor is being retrieved.\n\npVolume (in)\n    A pointer to the variable that will receive the volume factor. The returned value will be in the range of [0, 1].\n\n\nReturn Value\n------------\nMA_SUCCESS if successful.\nMA_INVALID_ARGS if pDevice is NULL.\nMA_INVALID_ARGS if pVolume is NULL.\n\n\nThread Safety\n-------------\nSafe. This just a simple member retrieval.\n\n\nCallback Safety\n---------------\nSafe.\n\n\nRemarks\n-------\nIf an error occurs, `*pVolume` will be set to 0.\n\n\nSee Also\n--------\nma_device_set_master_volume()\nma_device_set_master_volume_gain_db()\nma_device_get_master_volume_gain_db()\n*/\nMA_API ma_result ma_device_get_master_volume(ma_device* pDevice, float* pVolume);\n\n/*\nSets the master volume for the device as gain in decibels.\n\nA gain of 0 is full volume, whereas a gain of < 0 will decrease the volume.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose gain is being set.\n\ngainDB (in)\n    The new volume as gain in decibels. Must be less than or equal to 0, where 0 is full volume and anything less than 0 decreases the volume.\n\n\nReturn Value\n------------\nMA_SUCCESS if the volume was set successfully.\nMA_INVALID_ARGS if pDevice is NULL.\nMA_INVALID_ARGS if the gain is > 0.\n\n\nThread Safety\n-------------\nSafe. This just sets a local member of the device object.\n\n\nCallback Safety\n---------------\nSafe. If you set the volume in the data callback, that data written to the output buffer will have the new volume applied.\n\n\nRemarks\n-------\nThis applies the gain across all channels.\n\nThis does not change the operating system's volume. It only affects the volume for the given `ma_device` object's audio stream.\n\n\nSee Also\n--------\nma_device_get_master_volume_gain_db()\nma_device_set_master_volume()\nma_device_get_master_volume()\n*/\nMA_API ma_result ma_device_set_master_volume_db(ma_device* pDevice, float gainDB);\n\n/*\nRetrieves the master gain in decibels.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to the device whose gain is being retrieved.\n\npGainDB (in)\n    A pointer to the variable that will receive the gain in decibels. The returned value will be <= 0.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful.\nMA_INVALID_ARGS if pDevice is NULL.\nMA_INVALID_ARGS if pGainDB is NULL.\n\n\nThread Safety\n-------------\nSafe. This just a simple member retrieval.\n\n\nCallback Safety\n---------------\nSafe.\n\n\nRemarks\n-------\nIf an error occurs, `*pGainDB` will be set to 0.\n\n\nSee Also\n--------\nma_device_set_master_volume_db()\nma_device_set_master_volume()\nma_device_get_master_volume()\n*/\nMA_API ma_result ma_device_get_master_volume_db(ma_device* pDevice, float* pGainDB);\n\n\n/*\nCalled from the data callback of asynchronous backends to allow miniaudio to process the data and fire the miniaudio data callback.\n\n\nParameters\n----------\npDevice (in)\n    A pointer to device whose processing the data callback.\n\npOutput (out)\n    A pointer to the buffer that will receive the output PCM frame data. On a playback device this must not be NULL. On a duplex device\n    this can be NULL, in which case pInput must not be NULL.\n\npInput (in)\n    A pointer to the buffer containing input PCM frame data. On a capture device this must not be NULL. On a duplex device this can be\n    NULL, in which case `pOutput` must not be NULL.\n\nframeCount (in)\n    The number of frames being processed.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful; any other result code otherwise.\n\n\nThread Safety\n-------------\nThis function should only ever be called from the internal data callback of the backend. It is safe to call this simultaneously between a\nplayback and capture device in duplex setups.\n\n\nCallback Safety\n---------------\nDo not call this from the miniaudio data callback. It should only ever be called from the internal data callback of the backend.\n\n\nRemarks\n-------\nIf both `pOutput` and `pInput` are NULL, and error will be returned. In duplex scenarios, both `pOutput` and `pInput` can be non-NULL, in\nwhich case `pInput` will be processed first, followed by `pOutput`.\n\nIf you are implementing a custom backend, and that backend uses a callback for data delivery, you'll need to call this from inside that\ncallback.\n*/\nMA_API ma_result ma_device_handle_backend_data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount);\n\n\n/*\nCalculates an appropriate buffer size from a descriptor, native sample rate and performance profile.\n\nThis function is used by backends for helping determine an appropriately sized buffer to use with\nthe device depending on the values of `periodSizeInFrames` and `periodSizeInMilliseconds` in the\n`pDescriptor` object. Since buffer size calculations based on time depends on the sample rate, a\nbest guess at the device's native sample rate is also required which is where `nativeSampleRate`\ncomes in. In addition, the performance profile is also needed for cases where both the period size\nin frames and milliseconds are both zero.\n\n\nParameters\n----------\npDescriptor (in)\n    A pointer to device descriptor whose `periodSizeInFrames` and `periodSizeInMilliseconds` members\n    will be used for the calculation of the buffer size.\n\nnativeSampleRate (in)\n    The device's native sample rate. This is only ever used when the `periodSizeInFrames` member of\n    `pDescriptor` is zero. In this case, `periodSizeInMilliseconds` will be used instead, in which\n    case a sample rate is required to convert to a size in frames.\n\nperformanceProfile (in)\n    When both the `periodSizeInFrames` and `periodSizeInMilliseconds` members of `pDescriptor` are\n    zero, miniaudio will fall back to a buffer size based on the performance profile. The profile\n    to use for this calculation is determine by this parameter.\n\n\nReturn Value\n------------\nThe calculated buffer size in frames.\n\n\nThread Safety\n-------------\nThis is safe so long as nothing modifies `pDescriptor` at the same time. However, this function\nshould only ever be called from within the backend's device initialization routine and therefore\nshouldn't have any multithreading concerns.\n\n\nCallback Safety\n---------------\nThis is safe to call within the data callback, but there is no reason to ever do this.\n\n\nRemarks\n-------\nIf `nativeSampleRate` is zero, this function will fall back to `pDescriptor->sampleRate`. If that\nis also zero, `MA_DEFAULT_SAMPLE_RATE` will be used instead.\n*/\nMA_API ma_uint32 ma_calculate_buffer_size_in_frames_from_descriptor(const ma_device_descriptor* pDescriptor, ma_uint32 nativeSampleRate, ma_performance_profile performanceProfile);\n\n\n\n/*\nRetrieves a friendly name for a backend.\n*/\nMA_API const char* ma_get_backend_name(ma_backend backend);\n\n/*\nRetrieves the backend enum from the given name.\n*/\nMA_API ma_result ma_get_backend_from_name(const char* pBackendName, ma_backend* pBackend);\n\n/*\nDetermines whether or not the given backend is available by the compilation environment.\n*/\nMA_API ma_bool32 ma_is_backend_enabled(ma_backend backend);\n\n/*\nRetrieves compile-time enabled backends.\n\n\nParameters\n----------\npBackends (out, optional)\n    A pointer to the buffer that will receive the enabled backends. Set to NULL to retrieve the backend count. Setting\n    the capacity of the buffer to `MA_BUFFER_COUNT` will guarantee it's large enough for all backends.\n\nbackendCap (in)\n    The capacity of the `pBackends` buffer.\n\npBackendCount (out)\n    A pointer to the variable that will receive the enabled backend count.\n\n\nReturn Value\n------------\nMA_SUCCESS if successful.\nMA_INVALID_ARGS if `pBackendCount` is NULL.\nMA_NO_SPACE if the capacity of `pBackends` is not large enough.\n\nIf `MA_NO_SPACE` is returned, the `pBackends` buffer will be filled with `*pBackendCount` values.\n\n\nThread Safety\n-------------\nSafe.\n\n\nCallback Safety\n---------------\nSafe.\n\n\nRemarks\n-------\nIf you want to retrieve the number of backends so you can determine the capacity of `pBackends` buffer, you can call\nthis function with `pBackends` set to NULL.\n\nThis will also enumerate the null backend. If you don't want to include this you need to check for `ma_backend_null`\nwhen you enumerate over the returned backends and handle it appropriately. Alternatively, you can disable it at\ncompile time with `MA_NO_NULL`.\n\nThe returned backends are determined based on compile time settings, not the platform it's currently running on. For\nexample, PulseAudio will be returned if it was enabled at compile time, even when the user doesn't actually have\nPulseAudio installed.\n\n\nExample 1\n---------\nThe example below retrieves the enabled backend count using a fixed sized buffer allocated on the stack. The buffer is\ngiven a capacity of `MA_BACKEND_COUNT` which will guarantee it'll be large enough to store all available backends.\nSince `MA_BACKEND_COUNT` is always a relatively small value, this should be suitable for most scenarios.\n\n```\nma_backend enabledBackends[MA_BACKEND_COUNT];\nsize_t enabledBackendCount;\n\nresult = ma_get_enabled_backends(enabledBackends, MA_BACKEND_COUNT, &enabledBackendCount);\nif (result != MA_SUCCESS) {\n    // Failed to retrieve enabled backends. Should never happen in this example since all inputs are valid.\n}\n```\n\n\nSee Also\n--------\nma_is_backend_enabled()\n*/\nMA_API ma_result ma_get_enabled_backends(ma_backend* pBackends, size_t backendCap, size_t* pBackendCount);\n\n/*\nDetermines whether or not loopback mode is support by a backend.\n*/\nMA_API ma_bool32 ma_is_loopback_supported(ma_backend backend);\n\n#endif  /* MA_NO_DEVICE_IO */\n\n\n\n/************************************************************************************************************************************************************\n\nUtilities\n\n************************************************************************************************************************************************************/\n\n/*\nCalculates a buffer size in milliseconds from the specified number of frames and sample rate.\n*/\nMA_API ma_uint32 ma_calculate_buffer_size_in_milliseconds_from_frames(ma_uint32 bufferSizeInFrames, ma_uint32 sampleRate);\n\n/*\nCalculates a buffer size in frames from the specified number of milliseconds and sample rate.\n*/\nMA_API ma_uint32 ma_calculate_buffer_size_in_frames_from_milliseconds(ma_uint32 bufferSizeInMilliseconds, ma_uint32 sampleRate);\n\n/*\nCopies PCM frames from one buffer to another.\n*/\nMA_API void ma_copy_pcm_frames(void* dst, const void* src, ma_uint64 frameCount, ma_format format, ma_uint32 channels);\n\n/*\nCopies silent frames into the given buffer.\n\nRemarks\n-------\nFor all formats except `ma_format_u8`, the output buffer will be filled with 0. For `ma_format_u8` it will be filled with 128. The reason for this is that it\nmakes more sense for the purpose of mixing to initialize it to the center point.\n*/\nMA_API void ma_silence_pcm_frames(void* p, ma_uint64 frameCount, ma_format format, ma_uint32 channels);\n\n\n/*\nOffsets a pointer by the specified number of PCM frames.\n*/\nMA_API void* ma_offset_pcm_frames_ptr(void* p, ma_uint64 offsetInFrames, ma_format format, ma_uint32 channels);\nMA_API const void* ma_offset_pcm_frames_const_ptr(const void* p, ma_uint64 offsetInFrames, ma_format format, ma_uint32 channels);\nstatic MA_INLINE float* ma_offset_pcm_frames_ptr_f32(float* p, ma_uint64 offsetInFrames, ma_uint32 channels) { return (float*)ma_offset_pcm_frames_ptr((void*)p, offsetInFrames, ma_format_f32, channels); }\nstatic MA_INLINE const float* ma_offset_pcm_frames_const_ptr_f32(const float* p, ma_uint64 offsetInFrames, ma_uint32 channels) { return (const float*)ma_offset_pcm_frames_const_ptr((const void*)p, offsetInFrames, ma_format_f32, channels); }\n\n\n/*\nClips samples.\n*/\nMA_API void ma_clip_samples_u8(ma_uint8* pDst, const ma_int16* pSrc, ma_uint64 count);\nMA_API void ma_clip_samples_s16(ma_int16* pDst, const ma_int32* pSrc, ma_uint64 count);\nMA_API void ma_clip_samples_s24(ma_uint8* pDst, const ma_int64* pSrc, ma_uint64 count);\nMA_API void ma_clip_samples_s32(ma_int32* pDst, const ma_int64* pSrc, ma_uint64 count);\nMA_API void ma_clip_samples_f32(float* pDst, const float* pSrc, ma_uint64 count);\nMA_API void ma_clip_pcm_frames(void* pDst, const void* pSrc, ma_uint64 frameCount, ma_format format, ma_uint32 channels);\n\n/*\nHelper for applying a volume factor to samples.\n\nNote that the source and destination buffers can be the same, in which case it'll perform the operation in-place.\n*/\nMA_API void ma_copy_and_apply_volume_factor_u8(ma_uint8* pSamplesOut, const ma_uint8* pSamplesIn, ma_uint64 sampleCount, float factor);\nMA_API void ma_copy_and_apply_volume_factor_s16(ma_int16* pSamplesOut, const ma_int16* pSamplesIn, ma_uint64 sampleCount, float factor);\nMA_API void ma_copy_and_apply_volume_factor_s24(void* pSamplesOut, const void* pSamplesIn, ma_uint64 sampleCount, float factor);\nMA_API void ma_copy_and_apply_volume_factor_s32(ma_int32* pSamplesOut, const ma_int32* pSamplesIn, ma_uint64 sampleCount, float factor);\nMA_API void ma_copy_and_apply_volume_factor_f32(float* pSamplesOut, const float* pSamplesIn, ma_uint64 sampleCount, float factor);\n\nMA_API void ma_apply_volume_factor_u8(ma_uint8* pSamples, ma_uint64 sampleCount, float factor);\nMA_API void ma_apply_volume_factor_s16(ma_int16* pSamples, ma_uint64 sampleCount, float factor);\nMA_API void ma_apply_volume_factor_s24(void* pSamples, ma_uint64 sampleCount, float factor);\nMA_API void ma_apply_volume_factor_s32(ma_int32* pSamples, ma_uint64 sampleCount, float factor);\nMA_API void ma_apply_volume_factor_f32(float* pSamples, ma_uint64 sampleCount, float factor);\n\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames_u8(ma_uint8* pFramesOut, const ma_uint8* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames_s16(ma_int16* pFramesOut, const ma_int16* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames_s24(void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames_s32(ma_int32* pFramesOut, const ma_int32* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames_f32(float* pFramesOut, const float* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_copy_and_apply_volume_factor_pcm_frames(void* pFramesOut, const void* pFramesIn, ma_uint64 frameCount, ma_format format, ma_uint32 channels, float factor);\n\nMA_API void ma_apply_volume_factor_pcm_frames_u8(ma_uint8* pFrames, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_apply_volume_factor_pcm_frames_s16(ma_int16* pFrames, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_apply_volume_factor_pcm_frames_s24(void* pFrames, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_apply_volume_factor_pcm_frames_s32(ma_int32* pFrames, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_apply_volume_factor_pcm_frames_f32(float* pFrames, ma_uint64 frameCount, ma_uint32 channels, float factor);\nMA_API void ma_apply_volume_factor_pcm_frames(void* pFrames, ma_uint64 frameCount, ma_format format, ma_uint32 channels, float factor);\n\nMA_API void ma_copy_and_apply_volume_factor_per_channel_f32(float* pFramesOut, const float* pFramesIn, ma_uint64 frameCount, ma_uint32 channels, float* pChannelGains);\n\n\nMA_API void ma_copy_and_apply_volume_and_clip_samples_u8(ma_uint8* pDst, const ma_int16* pSrc, ma_uint64 count, float volume);\nMA_API void ma_copy_and_apply_volume_and_clip_samples_s16(ma_int16* pDst, const ma_int32* pSrc, ma_uint64 count, float volume);\nMA_API void ma_copy_and_apply_volume_and_clip_samples_s24(ma_uint8* pDst, const ma_int64* pSrc, ma_uint64 count, float volume);\nMA_API void ma_copy_and_apply_volume_and_clip_samples_s32(ma_int32* pDst, const ma_int64* pSrc, ma_uint64 count, float volume);\nMA_API void ma_copy_and_apply_volume_and_clip_samples_f32(float* pDst, const float* pSrc, ma_uint64 count, float volume);\nMA_API void ma_copy_and_apply_volume_and_clip_pcm_frames(void* pDst, const void* pSrc, ma_uint64 frameCount, ma_format format, ma_uint32 channels, float volume);\n\n\n/*\nHelper for converting a linear factor to gain in decibels.\n*/\nMA_API float ma_volume_linear_to_db(float factor);\n\n/*\nHelper for converting gain in decibels to a linear factor.\n*/\nMA_API float ma_volume_db_to_linear(float gain);\n\n\n/*\nMixes the specified number of frames in floating point format with a volume factor.\n\nThis will run on an optimized path when the volume is equal to 1.\n*/\nMA_API ma_result ma_mix_pcm_frames_f32(float* pDst, const float* pSrc, ma_uint64 frameCount, ma_uint32 channels, float volume);\n\n\n\n\n/************************************************************************************************************************************************************\n\nVFS\n===\n\nThe VFS object (virtual file system) is what's used to customize file access. This is useful in cases where stdio FILE* based APIs may not be entirely\nappropriate for a given situation.\n\n************************************************************************************************************************************************************/\ntypedef void      ma_vfs;\ntypedef ma_handle ma_vfs_file;\n\ntypedef enum\n{\n    MA_OPEN_MODE_READ  = 0x00000001,\n    MA_OPEN_MODE_WRITE = 0x00000002\n} ma_open_mode_flags;\n\ntypedef enum\n{\n    ma_seek_origin_start,\n    ma_seek_origin_current,\n    ma_seek_origin_end  /* Not used by decoders. */\n} ma_seek_origin;\n\ntypedef struct\n{\n    ma_uint64 sizeInBytes;\n} ma_file_info;\n\ntypedef struct\n{\n    ma_result (* onOpen) (ma_vfs* pVFS, const char* pFilePath, ma_uint32 openMode, ma_vfs_file* pFile);\n    ma_result (* onOpenW)(ma_vfs* pVFS, const wchar_t* pFilePath, ma_uint32 openMode, ma_vfs_file* pFile);\n    ma_result (* onClose)(ma_vfs* pVFS, ma_vfs_file file);\n    ma_result (* onRead) (ma_vfs* pVFS, ma_vfs_file file, void* pDst, size_t sizeInBytes, size_t* pBytesRead);\n    ma_result (* onWrite)(ma_vfs* pVFS, ma_vfs_file file, const void* pSrc, size_t sizeInBytes, size_t* pBytesWritten);\n    ma_result (* onSeek) (ma_vfs* pVFS, ma_vfs_file file, ma_int64 offset, ma_seek_origin origin);\n    ma_result (* onTell) (ma_vfs* pVFS, ma_vfs_file file, ma_int64* pCursor);\n    ma_result (* onInfo) (ma_vfs* pVFS, ma_vfs_file file, ma_file_info* pInfo);\n} ma_vfs_callbacks;\n\nMA_API ma_result ma_vfs_open(ma_vfs* pVFS, const char* pFilePath, ma_uint32 openMode, ma_vfs_file* pFile);\nMA_API ma_result ma_vfs_open_w(ma_vfs* pVFS, const wchar_t* pFilePath, ma_uint32 openMode, ma_vfs_file* pFile);\nMA_API ma_result ma_vfs_close(ma_vfs* pVFS, ma_vfs_file file);\nMA_API ma_result ma_vfs_read(ma_vfs* pVFS, ma_vfs_file file, void* pDst, size_t sizeInBytes, size_t* pBytesRead);\nMA_API ma_result ma_vfs_write(ma_vfs* pVFS, ma_vfs_file file, const void* pSrc, size_t sizeInBytes, size_t* pBytesWritten);\nMA_API ma_result ma_vfs_seek(ma_vfs* pVFS, ma_vfs_file file, ma_int64 offset, ma_seek_origin origin);\nMA_API ma_result ma_vfs_tell(ma_vfs* pVFS, ma_vfs_file file, ma_int64* pCursor);\nMA_API ma_result ma_vfs_info(ma_vfs* pVFS, ma_vfs_file file, ma_file_info* pInfo);\nMA_API ma_result ma_vfs_open_and_read_file(ma_vfs* pVFS, const char* pFilePath, void** ppData, size_t* pSize, const ma_allocation_callbacks* pAllocationCallbacks);\n\ntypedef struct\n{\n    ma_vfs_callbacks cb;\n    ma_allocation_callbacks allocationCallbacks;    /* Only used for the wchar_t version of open() on non-Windows platforms. */\n} ma_default_vfs;\n\nMA_API ma_result ma_default_vfs_init(ma_default_vfs* pVFS, const ma_allocation_callbacks* pAllocationCallbacks);\n\n\n\ntypedef ma_result (* ma_read_proc)(void* pUserData, void* pBufferOut, size_t bytesToRead, size_t* pBytesRead);\ntypedef ma_result (* ma_seek_proc)(void* pUserData, ma_int64 offset, ma_seek_origin origin);\ntypedef ma_result (* ma_tell_proc)(void* pUserData, ma_int64* pCursor);\n\n\n\n#if !defined(MA_NO_DECODING) || !defined(MA_NO_ENCODING)\ntypedef enum\n{\n    ma_encoding_format_unknown = 0,\n    ma_encoding_format_wav,\n    ma_encoding_format_flac,\n    ma_encoding_format_mp3,\n    ma_encoding_format_vorbis\n} ma_encoding_format;\n#endif\n\n/************************************************************************************************************************************************************\n\nDecoding\n========\n\nDecoders are independent of the main device API. Decoding APIs can be called freely inside the device's data callback, but they are not thread safe unless\nyou do your own synchronization.\n\n************************************************************************************************************************************************************/\n#ifndef MA_NO_DECODING\ntypedef struct ma_decoder ma_decoder;\n\n\ntypedef struct\n{\n    ma_format preferredFormat;\n    ma_uint32 seekPointCount;   /* Set to > 0 to generate a seektable if the decoding backend supports it. */\n} ma_decoding_backend_config;\n\nMA_API ma_decoding_backend_config ma_decoding_backend_config_init(ma_format preferredFormat, ma_uint32 seekPointCount);\n\n\ntypedef struct\n{\n    ma_result (* onInit      )(void* pUserData, ma_read_proc onRead, ma_seek_proc onSeek, ma_tell_proc onTell, void* pReadSeekTellUserData, const ma_decoding_backend_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_data_source** ppBackend);\n    ma_result (* onInitFile  )(void* pUserData, const char* pFilePath, const ma_decoding_backend_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_data_source** ppBackend);               /* Optional. */\n    ma_result (* onInitFileW )(void* pUserData, const wchar_t* pFilePath, const ma_decoding_backend_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_data_source** ppBackend);            /* Optional. */\n    ma_result (* onInitMemory)(void* pUserData, const void* pData, size_t dataSize, const ma_decoding_backend_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_data_source** ppBackend);  /* Optional. */\n    void      (* onUninit    )(void* pUserData, ma_data_source* pBackend, const ma_allocation_callbacks* pAllocationCallbacks);\n} ma_decoding_backend_vtable;\n\n\ntypedef ma_result (* ma_decoder_read_proc)(ma_decoder* pDecoder, void* pBufferOut, size_t bytesToRead, size_t* pBytesRead);         /* Returns the number of bytes read. */\ntypedef ma_result (* ma_decoder_seek_proc)(ma_decoder* pDecoder, ma_int64 byteOffset, ma_seek_origin origin);\ntypedef ma_result (* ma_decoder_tell_proc)(ma_decoder* pDecoder, ma_int64* pCursor);\n\ntypedef struct\n{\n    ma_format format;      /* Set to 0 or ma_format_unknown to use the stream's internal format. */\n    ma_uint32 channels;    /* Set to 0 to use the stream's internal channels. */\n    ma_uint32 sampleRate;  /* Set to 0 to use the stream's internal sample rate. */\n    ma_channel* pChannelMap;\n    ma_channel_mix_mode channelMixMode;\n    ma_dither_mode ditherMode;\n    ma_resampler_config resampling;\n    ma_allocation_callbacks allocationCallbacks;\n    ma_encoding_format encodingFormat;\n    ma_uint32 seekPointCount;   /* When set to > 0, specifies the number of seek points to use for the generation of a seek table. Not all decoding backends support this. */\n    ma_decoding_backend_vtable** ppCustomBackendVTables;\n    ma_uint32 customBackendCount;\n    void* pCustomBackendUserData;\n} ma_decoder_config;\n\nstruct ma_decoder\n{\n    ma_data_source_base ds;\n    ma_data_source* pBackend;                   /* The decoding backend we'll be pulling data from. */\n    const ma_decoding_backend_vtable* pBackendVTable; /* The vtable for the decoding backend. This needs to be stored so we can access the onUninit() callback. */\n    void* pBackendUserData;\n    ma_decoder_read_proc onRead;\n    ma_decoder_seek_proc onSeek;\n    ma_decoder_tell_proc onTell;\n    void* pUserData;\n    ma_uint64 readPointerInPCMFrames;      /* In output sample rate. Used for keeping track of how many frames are available for decoding. */\n    ma_format outputFormat;\n    ma_uint32 outputChannels;\n    ma_uint32 outputSampleRate;\n    ma_data_converter converter;    /* Data conversion is achieved by running frames through this. */\n    void* pInputCache;              /* In input format. Can be null if it's not needed. */\n    ma_uint64 inputCacheCap;        /* The capacity of the input cache. */\n    ma_uint64 inputCacheConsumed;   /* The number of frames that have been consumed in the cache. Used for determining the next valid frame. */\n    ma_uint64 inputCacheRemaining;  /* The number of valid frames remaining in the cahce. */\n    ma_allocation_callbacks allocationCallbacks;\n    union\n    {\n        struct\n        {\n            ma_vfs* pVFS;\n            ma_vfs_file file;\n        } vfs;\n        struct\n        {\n            const ma_uint8* pData;\n            size_t dataSize;\n            size_t currentReadPos;\n        } memory;               /* Only used for decoders that were opened against a block of memory. */\n    } data;\n};\n\nMA_API ma_decoder_config ma_decoder_config_init(ma_format outputFormat, ma_uint32 outputChannels, ma_uint32 outputSampleRate);\nMA_API ma_decoder_config ma_decoder_config_init_default(void);\n\nMA_API ma_result ma_decoder_init(ma_decoder_read_proc onRead, ma_decoder_seek_proc onSeek, void* pUserData, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\nMA_API ma_result ma_decoder_init_memory(const void* pData, size_t dataSize, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\nMA_API ma_result ma_decoder_init_vfs(ma_vfs* pVFS, const char* pFilePath, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\nMA_API ma_result ma_decoder_init_vfs_w(ma_vfs* pVFS, const wchar_t* pFilePath, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\nMA_API ma_result ma_decoder_init_file(const char* pFilePath, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\nMA_API ma_result ma_decoder_init_file_w(const wchar_t* pFilePath, const ma_decoder_config* pConfig, ma_decoder* pDecoder);\n\n/*\nUninitializes a decoder.\n*/\nMA_API ma_result ma_decoder_uninit(ma_decoder* pDecoder);\n\n/*\nReads PCM frames from the given decoder.\n\nThis is not thread safe without your own synchronization.\n*/\nMA_API ma_result ma_decoder_read_pcm_frames(ma_decoder* pDecoder, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\n\n/*\nSeeks to a PCM frame based on it's absolute index.\n\nThis is not thread safe without your own synchronization.\n*/\nMA_API ma_result ma_decoder_seek_to_pcm_frame(ma_decoder* pDecoder, ma_uint64 frameIndex);\n\n/*\nRetrieves the decoder's output data format.\n*/\nMA_API ma_result ma_decoder_get_data_format(ma_decoder* pDecoder, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\n\n/*\nRetrieves the current position of the read cursor in PCM frames.\n*/\nMA_API ma_result ma_decoder_get_cursor_in_pcm_frames(ma_decoder* pDecoder, ma_uint64* pCursor);\n\n/*\nRetrieves the length of the decoder in PCM frames.\n\nDo not call this on streams of an undefined length, such as internet radio.\n\nIf the length is unknown or an error occurs, 0 will be returned.\n\nThis will always return 0 for Vorbis decoders. This is due to a limitation with stb_vorbis in push mode which is what miniaudio\nuses internally.\n\nFor MP3's, this will decode the entire file. Do not call this in time critical scenarios.\n\nThis function is not thread safe without your own synchronization.\n*/\nMA_API ma_result ma_decoder_get_length_in_pcm_frames(ma_decoder* pDecoder, ma_uint64* pLength);\n\n/*\nRetrieves the number of frames that can be read before reaching the end.\n\nThis calls `ma_decoder_get_length_in_pcm_frames()` so you need to be aware of the rules for that function, in\nparticular ensuring you do not call it on streams of an undefined length, such as internet radio.\n\nIf the total length of the decoder cannot be retrieved, such as with Vorbis decoders, `MA_NOT_IMPLEMENTED` will be\nreturned.\n*/\nMA_API ma_result ma_decoder_get_available_frames(ma_decoder* pDecoder, ma_uint64* pAvailableFrames);\n\n/*\nHelper for opening and decoding a file into a heap allocated block of memory. Free the returned pointer with ma_free(). On input,\npConfig should be set to what you want. On output it will be set to what you got.\n*/\nMA_API ma_result ma_decode_from_vfs(ma_vfs* pVFS, const char* pFilePath, ma_decoder_config* pConfig, ma_uint64* pFrameCountOut, void** ppPCMFramesOut);\nMA_API ma_result ma_decode_file(const char* pFilePath, ma_decoder_config* pConfig, ma_uint64* pFrameCountOut, void** ppPCMFramesOut);\nMA_API ma_result ma_decode_memory(const void* pData, size_t dataSize, ma_decoder_config* pConfig, ma_uint64* pFrameCountOut, void** ppPCMFramesOut);\n\n#endif  /* MA_NO_DECODING */\n\n\n/************************************************************************************************************************************************************\n\nEncoding\n========\n\nEncoders do not perform any format conversion for you. If your target format does not support the format, and error will be returned.\n\n************************************************************************************************************************************************************/\n#ifndef MA_NO_ENCODING\ntypedef struct ma_encoder ma_encoder;\n\ntypedef ma_result (* ma_encoder_write_proc)           (ma_encoder* pEncoder, const void* pBufferIn, size_t bytesToWrite, size_t* pBytesWritten);\ntypedef ma_result (* ma_encoder_seek_proc)            (ma_encoder* pEncoder, ma_int64 offset, ma_seek_origin origin);\ntypedef ma_result (* ma_encoder_init_proc)            (ma_encoder* pEncoder);\ntypedef void      (* ma_encoder_uninit_proc)          (ma_encoder* pEncoder);\ntypedef ma_result (* ma_encoder_write_pcm_frames_proc)(ma_encoder* pEncoder, const void* pFramesIn, ma_uint64 frameCount, ma_uint64* pFramesWritten);\n\ntypedef struct\n{\n    ma_encoding_format encodingFormat;\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_allocation_callbacks allocationCallbacks;\n} ma_encoder_config;\n\nMA_API ma_encoder_config ma_encoder_config_init(ma_encoding_format encodingFormat, ma_format format, ma_uint32 channels, ma_uint32 sampleRate);\n\nstruct ma_encoder\n{\n    ma_encoder_config config;\n    ma_encoder_write_proc onWrite;\n    ma_encoder_seek_proc onSeek;\n    ma_encoder_init_proc onInit;\n    ma_encoder_uninit_proc onUninit;\n    ma_encoder_write_pcm_frames_proc onWritePCMFrames;\n    void* pUserData;\n    void* pInternalEncoder;\n    union\n    {\n        struct\n        {\n            ma_vfs* pVFS;\n            ma_vfs_file file;\n        } vfs;\n    } data;\n};\n\nMA_API ma_result ma_encoder_init(ma_encoder_write_proc onWrite, ma_encoder_seek_proc onSeek, void* pUserData, const ma_encoder_config* pConfig, ma_encoder* pEncoder);\nMA_API ma_result ma_encoder_init_vfs(ma_vfs* pVFS, const char* pFilePath, const ma_encoder_config* pConfig, ma_encoder* pEncoder);\nMA_API ma_result ma_encoder_init_vfs_w(ma_vfs* pVFS, const wchar_t* pFilePath, const ma_encoder_config* pConfig, ma_encoder* pEncoder);\nMA_API ma_result ma_encoder_init_file(const char* pFilePath, const ma_encoder_config* pConfig, ma_encoder* pEncoder);\nMA_API ma_result ma_encoder_init_file_w(const wchar_t* pFilePath, const ma_encoder_config* pConfig, ma_encoder* pEncoder);\nMA_API void ma_encoder_uninit(ma_encoder* pEncoder);\nMA_API ma_result ma_encoder_write_pcm_frames(ma_encoder* pEncoder, const void* pFramesIn, ma_uint64 frameCount, ma_uint64* pFramesWritten);\n\n#endif /* MA_NO_ENCODING */\n\n\n/************************************************************************************************************************************************************\n\nGeneration\n\n************************************************************************************************************************************************************/\n#ifndef MA_NO_GENERATION\ntypedef enum\n{\n    ma_waveform_type_sine,\n    ma_waveform_type_square,\n    ma_waveform_type_triangle,\n    ma_waveform_type_sawtooth\n} ma_waveform_type;\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    ma_waveform_type type;\n    double amplitude;\n    double frequency;\n} ma_waveform_config;\n\nMA_API ma_waveform_config ma_waveform_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, ma_waveform_type type, double amplitude, double frequency);\n\ntypedef struct\n{\n    ma_data_source_base ds;\n    ma_waveform_config config;\n    double advance;\n    double time;\n} ma_waveform;\n\nMA_API ma_result ma_waveform_init(const ma_waveform_config* pConfig, ma_waveform* pWaveform);\nMA_API void ma_waveform_uninit(ma_waveform* pWaveform);\nMA_API ma_result ma_waveform_read_pcm_frames(ma_waveform* pWaveform, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_waveform_seek_to_pcm_frame(ma_waveform* pWaveform, ma_uint64 frameIndex);\nMA_API ma_result ma_waveform_set_amplitude(ma_waveform* pWaveform, double amplitude);\nMA_API ma_result ma_waveform_set_frequency(ma_waveform* pWaveform, double frequency);\nMA_API ma_result ma_waveform_set_type(ma_waveform* pWaveform, ma_waveform_type type);\nMA_API ma_result ma_waveform_set_sample_rate(ma_waveform* pWaveform, ma_uint32 sampleRate);\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_uint32 sampleRate;\n    double dutyCycle;\n    double amplitude;\n    double frequency;\n} ma_pulsewave_config;\n\nMA_API ma_pulsewave_config ma_pulsewave_config_init(ma_format format, ma_uint32 channels, ma_uint32 sampleRate, double dutyCycle, double amplitude, double frequency);\n\ntypedef struct\n{\n    ma_waveform waveform;\n    ma_pulsewave_config config;\n} ma_pulsewave;\n\nMA_API ma_result ma_pulsewave_init(const ma_pulsewave_config* pConfig, ma_pulsewave* pWaveform);\nMA_API void ma_pulsewave_uninit(ma_pulsewave* pWaveform);\nMA_API ma_result ma_pulsewave_read_pcm_frames(ma_pulsewave* pWaveform, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_pulsewave_seek_to_pcm_frame(ma_pulsewave* pWaveform, ma_uint64 frameIndex);\nMA_API ma_result ma_pulsewave_set_amplitude(ma_pulsewave* pWaveform, double amplitude);\nMA_API ma_result ma_pulsewave_set_frequency(ma_pulsewave* pWaveform, double frequency);\nMA_API ma_result ma_pulsewave_set_sample_rate(ma_pulsewave* pWaveform, ma_uint32 sampleRate);\nMA_API ma_result ma_pulsewave_set_duty_cycle(ma_pulsewave* pWaveform, double dutyCycle);\n\ntypedef enum\n{\n    ma_noise_type_white,\n    ma_noise_type_pink,\n    ma_noise_type_brownian\n} ma_noise_type;\n\n\ntypedef struct\n{\n    ma_format format;\n    ma_uint32 channels;\n    ma_noise_type type;\n    ma_int32 seed;\n    double amplitude;\n    ma_bool32 duplicateChannels;\n} ma_noise_config;\n\nMA_API ma_noise_config ma_noise_config_init(ma_format format, ma_uint32 channels, ma_noise_type type, ma_int32 seed, double amplitude);\n\ntypedef struct\n{\n    ma_data_source_base ds;\n    ma_noise_config config;\n    ma_lcg lcg;\n    union\n    {\n        struct\n        {\n            double** bin;\n            double* accumulation;\n            ma_uint32* counter;\n        } pink;\n        struct\n        {\n            double* accumulation;\n        } brownian;\n    } state;\n\n    /* Memory management. */\n    void* _pHeap;\n    ma_bool32 _ownsHeap;\n} ma_noise;\n\nMA_API ma_result ma_noise_get_heap_size(const ma_noise_config* pConfig, size_t* pHeapSizeInBytes);\nMA_API ma_result ma_noise_init_preallocated(const ma_noise_config* pConfig, void* pHeap, ma_noise* pNoise);\nMA_API ma_result ma_noise_init(const ma_noise_config* pConfig, const ma_allocation_callbacks* pAllocationCallbacks, ma_noise* pNoise);\nMA_API void ma_noise_uninit(ma_noise* pNoise, const ma_allocation_callbacks* pAllocationCallbacks);\nMA_API ma_result ma_noise_read_pcm_frames(ma_noise* pNoise, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_noise_set_amplitude(ma_noise* pNoise, double amplitude);\nMA_API ma_result ma_noise_set_seed(ma_noise* pNoise, ma_int32 seed);\nMA_API ma_result ma_noise_set_type(ma_noise* pNoise, ma_noise_type type);\n\n#endif  /* MA_NO_GENERATION */\n\n\n\n/************************************************************************************************************************************************************\n\nResource Manager\n\n************************************************************************************************************************************************************/\n/* The resource manager cannot be enabled if there is no decoder. */\n#if !defined(MA_NO_RESOURCE_MANAGER) && defined(MA_NO_DECODING)\n#define MA_NO_RESOURCE_MANAGER\n#endif\n\n#ifndef MA_NO_RESOURCE_MANAGER\ntypedef struct ma_resource_manager                  ma_resource_manager;\ntypedef struct ma_resource_manager_data_buffer_node ma_resource_manager_data_buffer_node;\ntypedef struct ma_resource_manager_data_buffer      ma_resource_manager_data_buffer;\ntypedef struct ma_resource_manager_data_stream      ma_resource_manager_data_stream;\ntypedef struct ma_resource_manager_data_source      ma_resource_manager_data_source;\n\ntypedef enum\n{\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_STREAM         = 0x00000001,   /* When set, does not load the entire data source in memory. Disk I/O will happen on job threads. */\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_DECODE         = 0x00000002,   /* Decode data before storing in memory. When set, decoding is done at the resource manager level rather than the mixing thread. Results in faster mixing, but higher memory usage. */\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_ASYNC          = 0x00000004,   /* When set, the resource manager will load the data source asynchronously. */\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_WAIT_INIT      = 0x00000008,   /* When set, waits for initialization of the underlying data source before returning from ma_resource_manager_data_source_init(). */\n    MA_RESOURCE_MANAGER_DATA_SOURCE_FLAG_UNKNOWN_LENGTH = 0x00000010    /* Gives the resource manager a hint that the length of the data source is unknown and calling `ma_data_source_get_length_in_pcm_frames()` should be avoided. */\n} ma_resource_manager_data_source_flags;\n\n\n/*\nPipeline notifications used by the resource manager. Made up of both an async notification and a fence, both of which are optional.\n*/\ntypedef struct\n{\n    ma_async_notification* pNotification;\n    ma_fence* pFence;\n} ma_resource_manager_pipeline_stage_notification;\n\ntypedef struct\n{\n    ma_resource_manager_pipeline_stage_notification init;    /* Initialization of the decoder. */\n    ma_resource_manager_pipeline_stage_notification done;    /* Decoding fully completed. */\n} ma_resource_manager_pipeline_notifications;\n\nMA_API ma_resource_manager_pipeline_notifications ma_resource_manager_pipeline_notifications_init(void);\n\n\n\n/* BEGIN BACKWARDS COMPATIBILITY */\n/* TODO: Remove this block in version 0.12. */\n#if 1\n#define ma_resource_manager_job                         ma_job\n#define ma_resource_manager_job_init                    ma_job_init\n#define MA_JOB_TYPE_RESOURCE_MANAGER_QUEUE_FLAG_NON_BLOCKING MA_JOB_QUEUE_FLAG_NON_BLOCKING\n#define ma_resource_manager_job_queue_config            ma_job_queue_config\n#define ma_resource_manager_job_queue_config_init       ma_job_queue_config_init\n#define ma_resource_manager_job_queue                   ma_job_queue\n#define ma_resource_manager_job_queue_get_heap_size     ma_job_queue_get_heap_size\n#define ma_resource_manager_job_queue_init_preallocated ma_job_queue_init_preallocated\n#define ma_resource_manager_job_queue_init              ma_job_queue_init\n#define ma_resource_manager_job_queue_uninit            ma_job_queue_uninit\n#define ma_resource_manager_job_queue_post              ma_job_queue_post\n#define ma_resource_manager_job_queue_next              ma_job_queue_next\n#endif\n/* END BACKWARDS COMPATIBILITY */\n\n\n\n\n/* Maximum job thread count will be restricted to this, but this may be removed later and replaced with a heap allocation thereby removing any limitation. */\n#ifndef MA_RESOURCE_MANAGER_MAX_JOB_THREAD_COUNT\n#define MA_RESOURCE_MANAGER_MAX_JOB_THREAD_COUNT    64\n#endif\n\ntypedef enum\n{\n    /* Indicates ma_resource_manager_next_job() should not block. Only valid when the job thread count is 0. */\n    MA_RESOURCE_MANAGER_FLAG_NON_BLOCKING = 0x00000001,\n\n    /* Disables any kind of multithreading. Implicitly enables MA_RESOURCE_MANAGER_FLAG_NON_BLOCKING. */\n    MA_RESOURCE_MANAGER_FLAG_NO_THREADING = 0x00000002\n} ma_resource_manager_flags;\n\ntypedef struct\n{\n    const char* pFilePath;\n    const wchar_t* pFilePathW;\n    const ma_resource_manager_pipeline_notifications* pNotifications;\n    ma_uint64 initialSeekPointInPCMFrames;\n    ma_uint64 rangeBegInPCMFrames;\n    ma_uint64 rangeEndInPCMFrames;\n    ma_uint64 loopPointBegInPCMFrames;\n    ma_uint64 loopPointEndInPCMFrames;\n    ma_bool32 isLooping;\n    ma_uint32 flags;\n} ma_resource_manager_data_source_config;\n\nMA_API ma_resource_manager_data_source_config ma_resource_manager_data_source_config_init(void);\n\n\ntypedef enum\n{\n    ma_resource_manager_data_supply_type_unknown = 0,   /* Used for determining whether or the data supply has been initialized. */\n    ma_resource_manager_data_supply_type_encoded,       /* Data supply is an encoded buffer. Connector is ma_decoder. */\n    ma_resource_manager_data_supply_type_decoded,       /* Data supply is a decoded buffer. Connector is ma_audio_buffer. */\n    ma_resource_manager_data_supply_type_decoded_paged  /* Data supply is a linked list of decoded buffers. Connector is ma_paged_audio_buffer. */\n} ma_resource_manager_data_supply_type;\n\ntypedef struct\n{\n    MA_ATOMIC(4, ma_resource_manager_data_supply_type) type;    /* Read and written from different threads so needs to be accessed atomically. */\n    union\n    {\n        struct\n        {\n            const void* pData;\n            size_t sizeInBytes;\n        } encoded;\n        struct\n        {\n            const void* pData;\n            ma_uint64 totalFrameCount;\n            ma_uint64 decodedFrameCount;\n            ma_format format;\n            ma_uint32 channels;\n            ma_uint32 sampleRate;\n        } decoded;\n        struct\n        {\n            ma_paged_audio_buffer_data data;\n            ma_uint64 decodedFrameCount;\n            ma_uint32 sampleRate;\n        } decodedPaged;\n    } backend;\n} ma_resource_manager_data_supply;\n\nstruct ma_resource_manager_data_buffer_node\n{\n    ma_uint32 hashedName32;                         /* The hashed name. This is the key. */\n    ma_uint32 refCount;\n    MA_ATOMIC(4, ma_result) result;                 /* Result from asynchronous loading. When loading set to MA_BUSY. When fully loaded set to MA_SUCCESS. When deleting set to MA_UNAVAILABLE. */\n    MA_ATOMIC(4, ma_uint32) executionCounter;       /* For allocating execution orders for jobs. */\n    MA_ATOMIC(4, ma_uint32) executionPointer;       /* For managing the order of execution for asynchronous jobs relating to this object. Incremented as jobs complete processing. */\n    ma_bool32 isDataOwnedByResourceManager;         /* Set to true when the underlying data buffer was allocated the resource manager. Set to false if it is owned by the application (via ma_resource_manager_register_*()). */\n    ma_resource_manager_data_supply data;\n    ma_resource_manager_data_buffer_node* pParent;\n    ma_resource_manager_data_buffer_node* pChildLo;\n    ma_resource_manager_data_buffer_node* pChildHi;\n};\n\nstruct ma_resource_manager_data_buffer\n{\n    ma_data_source_base ds;                         /* Base data source. A data buffer is a data source. */\n    ma_resource_manager* pResourceManager;          /* A pointer to the resource manager that owns this buffer. */\n    ma_resource_manager_data_buffer_node* pNode;    /* The data node. This is reference counted and is what supplies the data. */\n    ma_uint32 flags;                                /* The flags that were passed used to initialize the buffer. */\n    MA_ATOMIC(4, ma_uint32) executionCounter;       /* For allocating execution orders for jobs. */\n    MA_ATOMIC(4, ma_uint32) executionPointer;       /* For managing the order of execution for asynchronous jobs relating to this object. Incremented as jobs complete processing. */\n    ma_uint64 seekTargetInPCMFrames;                /* Only updated by the public API. Never written nor read from the job thread. */\n    ma_bool32 seekToCursorOnNextRead;               /* On the next read we need to seek to the frame cursor. */\n    MA_ATOMIC(4, ma_result) result;                 /* Keeps track of a result of decoding. Set to MA_BUSY while the buffer is still loading. Set to MA_SUCCESS when loading is finished successfully. Otherwise set to some other code. */\n    MA_ATOMIC(4, ma_bool32) isLooping;              /* Can be read and written by different threads at the same time. Must be used atomically. */\n    ma_atomic_bool32 isConnectorInitialized;        /* Used for asynchronous loading to ensure we don't try to initialize the connector multiple times while waiting for the node to fully load. */\n    union\n    {\n        ma_decoder decoder;                 /* Supply type is ma_resource_manager_data_supply_type_encoded */\n        ma_audio_buffer buffer;             /* Supply type is ma_resource_manager_data_supply_type_decoded */\n        ma_paged_audio_buffer pagedBuffer;  /* Supply type is ma_resource_manager_data_supply_type_decoded_paged */\n    } connector;    /* Connects this object to the node's data supply. */\n};\n\nstruct ma_resource_manager_data_stream\n{\n    ma_data_source_base ds;                     /* Base data source. A data stream is a data source. */\n    ma_resource_manager* pResourceManager;      /* A pointer to the resource manager that owns this data stream. */\n    ma_uint32 flags;                            /* The flags that were passed used to initialize the stream. */\n    ma_decoder decoder;                         /* Used for filling pages with data. This is only ever accessed by the job thread. The public API should never touch this. */\n    ma_bool32 isDecoderInitialized;             /* Required for determining whether or not the decoder should be uninitialized in MA_JOB_TYPE_RESOURCE_MANAGER_FREE_DATA_STREAM. */\n    ma_uint64 totalLengthInPCMFrames;           /* This is calculated when first loaded by the MA_JOB_TYPE_RESOURCE_MANAGER_LOAD_DATA_STREAM. */\n    ma_uint32 relativeCursor;                   /* The playback cursor, relative to the current page. Only ever accessed by the public API. Never accessed by the job thread. */\n    MA_ATOMIC(8, ma_uint64) absoluteCursor;     /* The playback cursor, in absolute position starting from the start of the file. */\n    ma_uint32 currentPageIndex;                 /* Toggles between 0 and 1. Index 0 is the first half of pPageData. Index 1 is the second half. Only ever accessed by the public API. Never accessed by the job thread. */\n    MA_ATOMIC(4, ma_uint32) executionCounter;   /* For allocating execution orders for jobs. */\n    MA_ATOMIC(4, ma_uint32) executionPointer;   /* For managing the order of execution for asynchronous jobs relating to this object. Incremented as jobs complete processing. */\n\n    /* Written by the public API, read by the job thread. */\n    MA_ATOMIC(4, ma_bool32) isLooping;          /* Whether or not the stream is looping. It's important to set the looping flag at the data stream level for smooth loop transitions. */\n\n    /* Written by the job thread, read by the public API. */\n    void* pPageData;                            /* Buffer containing the decoded data of each page. Allocated once at initialization time. */\n    MA_ATOMIC(4, ma_uint32) pageFrameCount[2];  /* The number of valid PCM frames in each page. Used to determine the last valid frame. */\n\n    /* Written and read by both the public API and the job thread. These must be atomic. */\n    MA_ATOMIC(4, ma_result) result;             /* Result from asynchronous loading. When loading set to MA_BUSY. When initialized set to MA_SUCCESS. When deleting set to MA_UNAVAILABLE. If an error occurs when loading, set to an error code. */\n    MA_ATOMIC(4, ma_bool32) isDecoderAtEnd;     /* Whether or not the decoder has reached the end. */\n    MA_ATOMIC(4, ma_bool32) isPageValid[2];     /* Booleans to indicate whether or not a page is valid. Set to false by the public API, set to true by the job thread. Set to false as the pages are consumed, true when they are filled. */\n    MA_ATOMIC(4, ma_bool32) seekCounter;        /* When 0, no seeking is being performed. When > 0, a seek is being performed and reading should be delayed with MA_BUSY. */\n};\n\nstruct ma_resource_manager_data_source\n{\n    union\n    {\n        ma_resource_manager_data_buffer buffer;\n        ma_resource_manager_data_stream stream;\n    } backend;  /* Must be the first item because we need the first item to be the data source callbacks for the buffer or stream. */\n\n    ma_uint32 flags;                          /* The flags that were passed in to ma_resource_manager_data_source_init(). */\n    MA_ATOMIC(4, ma_uint32) executionCounter;     /* For allocating execution orders for jobs. */\n    MA_ATOMIC(4, ma_uint32) executionPointer;     /* For managing the order of execution for asynchronous jobs relating to this object. Incremented as jobs complete processing. */\n};\n\ntypedef struct\n{\n    ma_allocation_callbacks allocationCallbacks;\n    ma_log* pLog;\n    ma_format decodedFormat;        /* The decoded format to use. Set to ma_format_unknown (default) to use the file's native format. */\n    ma_uint32 decodedChannels;      /* The decoded channel count to use. Set to 0 (default) to use the file's native channel count. */\n    ma_uint32 decodedSampleRate;    /* the decoded sample rate to use. Set to 0 (default) to use the file's native sample rate. */\n    ma_uint32 jobThreadCount;       /* Set to 0 if you want to self-manage your job threads. Defaults to 1. */\n    size_t jobThreadStackSize;\n    ma_uint32 jobQueueCapacity;     /* The maximum number of jobs that can fit in the queue at a time. Defaults to MA_JOB_TYPE_RESOURCE_MANAGER_QUEUE_CAPACITY. Cannot be zero. */\n    ma_uint32 flags;\n    ma_vfs* pVFS;                   /* Can be NULL in which case defaults will be used. */\n    ma_decoding_backend_vtable** ppCustomDecodingBackendVTables;\n    ma_uint32 customDecodingBackendCount;\n    void* pCustomDecodingBackendUserData;\n} ma_resource_manager_config;\n\nMA_API ma_resource_manager_config ma_resource_manager_config_init(void);\n\nstruct ma_resource_manager\n{\n    ma_resource_manager_config config;\n    ma_resource_manager_data_buffer_node* pRootDataBufferNode;      /* The root buffer in the binary tree. */\n#ifndef MA_NO_THREADING\n    ma_mutex dataBufferBSTLock;                                     /* For synchronizing access to the data buffer binary tree. */\n    ma_thread jobThreads[MA_RESOURCE_MANAGER_MAX_JOB_THREAD_COUNT]; /* The threads for executing jobs. */\n#endif\n    ma_job_queue jobQueue;                                          /* Multi-consumer, multi-producer job queue for managing jobs for asynchronous decoding and streaming. */\n    ma_default_vfs defaultVFS;                                      /* Only used if a custom VFS is not specified. */\n    ma_log log;                                                     /* Only used if no log was specified in the config. */\n};\n\n/* Init. */\nMA_API ma_result ma_resource_manager_init(const ma_resource_manager_config* pConfig, ma_resource_manager* pResourceManager);\nMA_API void ma_resource_manager_uninit(ma_resource_manager* pResourceManager);\nMA_API ma_log* ma_resource_manager_get_log(ma_resource_manager* pResourceManager);\n\n/* Registration. */\nMA_API ma_result ma_resource_manager_register_file(ma_resource_manager* pResourceManager, const char* pFilePath, ma_uint32 flags);\nMA_API ma_result ma_resource_manager_register_file_w(ma_resource_manager* pResourceManager, const wchar_t* pFilePath, ma_uint32 flags);\nMA_API ma_result ma_resource_manager_register_decoded_data(ma_resource_manager* pResourceManager, const char* pName, const void* pData, ma_uint64 frameCount, ma_format format, ma_uint32 channels, ma_uint32 sampleRate);  /* Does not copy. Increments the reference count if already exists and returns MA_SUCCESS. */\nMA_API ma_result ma_resource_manager_register_decoded_data_w(ma_resource_manager* pResourceManager, const wchar_t* pName, const void* pData, ma_uint64 frameCount, ma_format format, ma_uint32 channels, ma_uint32 sampleRate);\nMA_API ma_result ma_resource_manager_register_encoded_data(ma_resource_manager* pResourceManager, const char* pName, const void* pData, size_t sizeInBytes);    /* Does not copy. Increments the reference count if already exists and returns MA_SUCCESS. */\nMA_API ma_result ma_resource_manager_register_encoded_data_w(ma_resource_manager* pResourceManager, const wchar_t* pName, const void* pData, size_t sizeInBytes);\nMA_API ma_result ma_resource_manager_unregister_file(ma_resource_manager* pResourceManager, const char* pFilePath);\nMA_API ma_result ma_resource_manager_unregister_file_w(ma_resource_manager* pResourceManager, const wchar_t* pFilePath);\nMA_API ma_result ma_resource_manager_unregister_data(ma_resource_manager* pResourceManager, const char* pName);\nMA_API ma_result ma_resource_manager_unregister_data_w(ma_resource_manager* pResourceManager, const wchar_t* pName);\n\n/* Data Buffers. */\nMA_API ma_result ma_resource_manager_data_buffer_init_ex(ma_resource_manager* pResourceManager, const ma_resource_manager_data_source_config* pConfig, ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_init(ma_resource_manager* pResourceManager, const char* pFilePath, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_init_w(ma_resource_manager* pResourceManager, const wchar_t* pFilePath, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_init_copy(ma_resource_manager* pResourceManager, const ma_resource_manager_data_buffer* pExistingDataBuffer, ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_uninit(ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_read_pcm_frames(ma_resource_manager_data_buffer* pDataBuffer, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_resource_manager_data_buffer_seek_to_pcm_frame(ma_resource_manager_data_buffer* pDataBuffer, ma_uint64 frameIndex);\nMA_API ma_result ma_resource_manager_data_buffer_get_data_format(ma_resource_manager_data_buffer* pDataBuffer, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_resource_manager_data_buffer_get_cursor_in_pcm_frames(ma_resource_manager_data_buffer* pDataBuffer, ma_uint64* pCursor);\nMA_API ma_result ma_resource_manager_data_buffer_get_length_in_pcm_frames(ma_resource_manager_data_buffer* pDataBuffer, ma_uint64* pLength);\nMA_API ma_result ma_resource_manager_data_buffer_result(const ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_set_looping(ma_resource_manager_data_buffer* pDataBuffer, ma_bool32 isLooping);\nMA_API ma_bool32 ma_resource_manager_data_buffer_is_looping(const ma_resource_manager_data_buffer* pDataBuffer);\nMA_API ma_result ma_resource_manager_data_buffer_get_available_frames(ma_resource_manager_data_buffer* pDataBuffer, ma_uint64* pAvailableFrames);\n\n/* Data Streams. */\nMA_API ma_result ma_resource_manager_data_stream_init_ex(ma_resource_manager* pResourceManager, const ma_resource_manager_data_source_config* pConfig, ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_init(ma_resource_manager* pResourceManager, const char* pFilePath, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_init_w(ma_resource_manager* pResourceManager, const wchar_t* pFilePath, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_uninit(ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_read_pcm_frames(ma_resource_manager_data_stream* pDataStream, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_resource_manager_data_stream_seek_to_pcm_frame(ma_resource_manager_data_stream* pDataStream, ma_uint64 frameIndex);\nMA_API ma_result ma_resource_manager_data_stream_get_data_format(ma_resource_manager_data_stream* pDataStream, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_resource_manager_data_stream_get_cursor_in_pcm_frames(ma_resource_manager_data_stream* pDataStream, ma_uint64* pCursor);\nMA_API ma_result ma_resource_manager_data_stream_get_length_in_pcm_frames(ma_resource_manager_data_stream* pDataStream, ma_uint64* pLength);\nMA_API ma_result ma_resource_manager_data_stream_result(const ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_set_looping(ma_resource_manager_data_stream* pDataStream, ma_bool32 isLooping);\nMA_API ma_bool32 ma_resource_manager_data_stream_is_looping(const ma_resource_manager_data_stream* pDataStream);\nMA_API ma_result ma_resource_manager_data_stream_get_available_frames(ma_resource_manager_data_stream* pDataStream, ma_uint64* pAvailableFrames);\n\n/* Data Sources. */\nMA_API ma_result ma_resource_manager_data_source_init_ex(ma_resource_manager* pResourceManager, const ma_resource_manager_data_source_config* pConfig, ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_init(ma_resource_manager* pResourceManager, const char* pName, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_init_w(ma_resource_manager* pResourceManager, const wchar_t* pName, ma_uint32 flags, const ma_resource_manager_pipeline_notifications* pNotifications, ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_init_copy(ma_resource_manager* pResourceManager, const ma_resource_manager_data_source* pExistingDataSource, ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_uninit(ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_read_pcm_frames(ma_resource_manager_data_source* pDataSource, void* pFramesOut, ma_uint64 frameCount, ma_uint64* pFramesRead);\nMA_API ma_result ma_resource_manager_data_source_seek_to_pcm_frame(ma_resource_manager_data_source* pDataSource, ma_uint64 frameIndex);\nMA_API ma_result ma_resource_manager_data_source_get_data_format(ma_resource_manager_data_source* pDataSource, ma_format* pFormat, ma_uint32* pChannels, ma_uint32* pSampleRate, ma_channel* pChannelMap, size_t channelMapCap);\nMA_API ma_result ma_resource_manager_data_source_get_cursor_in_pcm_frames(ma_resource_manager_data_source* pDataSource, ma_uint64* pCursor);\nMA_API ma_result ma_resource_manager_data_source_get_length_in_pcm_frames(ma_resource_manager_data_source* pDataSource, ma_uint64* pLength);\nMA_API ma_result ma_resource_manager_data_source_result(const ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_set_looping(ma_resource_manager_data_source* pDataSource, ma_bool32 isLooping);\nMA_API ma_bool32 ma_resource_manager_data_source_is_looping(const ma_resource_manager_data_source* pDataSource);\nMA_API ma_result ma_resource_manager_data_source_get_available_frames(ma_resource_manager_data_source* pDataSource, ma_uint64* pAvailableFrames);\n\n/* Job management. */\nMA_API ma_result ma_resource_manager_post_job(ma_resource_manager* pResourceManager, const ma_job* pJob);\nMA_API ma_result ma_resource_manager_post_job_quit(ma_resource_manager* pResourceManager);  /* Helper for posting a quit job. */\nMA_API ma_result ma_resource_manager_next_job(ma_resource_manager* pResourceManager, ma_job* pJob);\nMA_API ma_result ma_resource_manager_process_job(ma_resource_manager* pResourceManager, ma_job* pJob);  /* DEPRECATED. Use ma_job_process(). Will be removed in version 0.12. */\nMA_API ma_result ma_resource_manager_process_next_job(ma_resource_manager* pResourceManager);   /* Returns MA_CANCELLED if a MA_JOB_TYPE_QUIT job is found. In non-blocking mode, returns MA_NO_DATA_AVAILABLE if no jobs are available. */\n#endif  /* MA_NO_RESOURCE_MANAGER */\n\n\n\n/************************************************************************************************************************************************************\n\nNode Graph\n\n************************************************************************************************************************************************************/\n#ifndef MA_NO_NODE_GRAPH\n/* Must never exceed 254. */\n#ifndef MA_MAX_NODE_BUS_COUNT\n#define MA_MAX_NODE_BUS_COUNT       254\n#endif\n\n/* Used internally by miniaudio for memory management. Must never exceed MA_MAX_NODE_BUS_COUNT. */\n#ifndef MA_MAX_NODE_LOCAL_BUS_COUNT\n#define MA_MAX_NODE_LOCAL_BUS_COUNT 2\n#endif\n\n/* Use this when the bus count is determined by the node instance rather than the vtable. */\n#define MA_NODE_BUS_COUNT_UNKNOWN   255\n\ntypedef struct ma_node_graph ma_node_graph;\ntypedef void ma_node;\n\n\n/* Node flags. */\ntypedef enum\n{\n    MA_NODE_FLAG_PASSTHROUGH                = 0x00000001,\n    MA_NODE_FLAG_CONTINUOUS_PROCESSING      = 0x00000002,\n    MA_NODE_FLAG_ALLOW_NULL_INPUT           = 0x00000004,\n    MA_NODE_FLAG_DIFFERENT_PROCESSING_RATES = 0x00000008,\n    MA_NODE_FLAG_SILENT_OUTPUT              = 0x00000010\n} ma_node_flags;\n\n\n/* The playback state of a node. Either started or stopped. */\ntypedef enum\n{\n    ma_node_state_started = 0,\n    ma_node_state_stopped = 1\n} ma_node_state;\n\n\ntypedef struct\n{\n    /*\n    Extended processing callback. This callback is used for effects that process input and output\n    at different rates (i.e. they perform resampling). This is similar to the simple version, only\n    they take two separate frame counts: one for input, and one for output.\n\n    On input, `pFrameCountOut` is equal to the capacity of the output buffer for each bus, whereas\n    `pFrameCountIn` will be equal to the number of PCM frames in each of the buffers in `ppFramesIn`.\n\n    On output, set `pFrameCountOut` to the number of PCM frames that were actually output and set\n    `pFrameCountIn` to the number of input frames that were consumed.\n    */\n    void (* onProcess)(ma_node* pNode, const float** ppFramesIn, ma_uint32* pFrameCountIn, float** ppFramesOut, ma_uint32* pFrameCountOut);\n\n    /*\n    A callback for retrieving the number of a input frames that are required to output the\n    specified number of output frames. You would only want to implement this when the node performs\n    resampling. This is optional, even for nodes that perform resampling, but it does offer a\n    small reduction in latency as it allows miniaudio to calculate the exact number of input frames\n    to read at a time instead of having to estimate.\n    */\n    ma_result (* onGetRequiredInputFrameCount)(ma_node* pNode, ma_uint32 outputFrameCount, ma_uint32* pInputFrameCount);\n\n    /*\n    The number of input buses. This is how many sub-buffers will be contained in the `ppFramesIn`\n    parameters of the callbacks above.\n    */\n    ma_uint8 inputBusCount;\n\n    /*\n    The number of output buses. This is how many sub-buffers will be contained in the `ppFramesOut`\n    parameters of the callbacks above.\n    */\n    ma_uint8 outputBusCount;\n\n    /*\n    Flags describing characteristics of the node. This is currently just a placeholder for some\n    ideas for later on.\n    */\n    ma_uint32 flags;\n} ma_node_vtable;\n\ntypedef struct\n{\n    const ma_node_vtable* vtable;       /* Should never be null. Initialization of the node will fail if so. */\n    ma_node_state initialState;         /* Defaults to ma_node_state_started. */\n    ma_uint32 inputBusCount;            /* Only used if the vtable specifies an input bus count of `MA_NODE_BUS_COUNT_UNKNOWN`, otherwise must be set to `MA_NODE_BUS_COUNT_UNKNOWN` (default). */\n    ma_uint32 outputBusCount;           /* Only used if the vtable specifies an output bus count of `MA_NODE_BUS_COUNT_UNKNOWN`, otherwise  be set to `MA_NODE_BUS_COUNT_UNKNOWN` (default). */\n    const ma_uint32* pInputChannels;    /* The number of elements are determined by the input bus count as determined by the vtable, or `inputBusCount` if the vtable specifies `MA_NODE_BUS_COUNT_UNKNOWN`. */\n    const ma_uint32* pOutputChannels;   /* The number of elements are determined by the output bus count as determined by the vtable, or `outputBusCount` if the vtable specifies `MA_NODE_BUS_COUNT_UNKNOWN`. */\n} ma_node_config;\n\nMA_API ma_node_config ma_node_config_init(void);\n\n\n/*\nA node has multiple output buses. An output bus is attached to an input bus as an item in a linked\nlist. Think of the input bus as a linked list, with the output bus being an item in that list.\n*/\ntypedef struct ma_node_output_bus ma_node_output_bus;\nstruct ma_node_output_bus\n{\n    /* Immutable. */\n    ma_node* pNode;                                         /* The node that owns this output bus. The input node. Will be null for dummy head and tail nodes. */\n    ma_uint8 outputBusIndex;                                /* The index of the output bus on pNode that this output bus represents. */\n    ma_uint8 channels;                                      /* The number of channels in the audio stream for this bus. */\n\n    /* Mutable via multiple threads. Must be used atomically. The weird ordering here is for packing reasons. */\n    ma_uint8 inputNodeInputBusIndex;                        /* The index of the input bus on the input. Required for detaching. Will only be used within the spinlock so does not need to be atomic. */\n    MA_ATOMIC(4, ma_uint32) flags;                          /* Some state flags for tracking the read state of the output buffer. A combination of MA_NODE_OUTPUT_BUS_FLAG_*. */\n    MA_ATOMIC(4, ma_uint32) refCount;                       /* Reference count for some thread-safety when detaching. */\n    MA_ATOMIC(4, ma_bool32) isAttached;                     /* This is used to prevent iteration of nodes that are in the middle of being detached. Used for thread safety. */\n    MA_ATOMIC(4, ma_spinlock) lock;                         /* Unfortunate lock, but significantly simplifies the implementation. Required for thread-safe attaching and detaching. */\n    MA_ATOMIC(4, float) volume;                             /* Linear. */\n    MA_ATOMIC(MA_SIZEOF_PTR, ma_node_output_bus*) pNext;    /* If null, it's the tail node or detached. */\n    MA_ATOMIC(MA_SIZEOF_PTR, ma_node_output_bus*) pPrev;    /* If null, it's the head node or detached. */\n    MA_ATOMIC(MA_SIZEOF_PTR, ma_node*) pInputNode;          /* The node that this output bus is attached to. Required for detaching. */\n};\n\n/*\nA node has multiple input buses. The output buses of a node are connecting to the input busses of\nanother. An input bus is essentially just a linked list of output buses.\n*/\ntypedef struct ma_node_input_bus ma_node_input_bus;\nstruct ma_node_input_bus\n{\n    /* Mutable via multiple threads. */\n    ma_node_output_bus head;                /* Dummy head node for simplifying some lock-free thread-safety stuff. */\n    MA_ATOMIC(4, ma_uint32) nextCounter;    /* This is used to determine whether or not the input bus is finding the next node in the list. Used for thread safety when detaching output buses. */\n    MA_ATOMIC(4, ma_spinlock) lock;         /* Unfortunate lock, but significantly simplifies the implementation. Required for thread-safe attaching and detaching. */\n\n    /* Set once at startup. */\n    ma_uint8 channels;                      /* The number of channels in the audio stream for this bus. */\n};\n\n\ntypedef struct ma_node_base ma_node_base;\nstruct ma_node_base\n{\n    /* These variables are set once at startup. */\n    ma_node_graph* pNodeGraph;              /* The graph this node belongs to. */\n    const ma_node_vtable* vtable;\n    float* pCachedData;                     /* Allocated on the heap. Fixed size. Needs to be stored on the heap because reading from output buses is done in separate function calls. */\n    ma_uint16 cachedDataCapInFramesPerBus;  /* The capacity of the input data cache in frames, per bus. */\n\n    /* These variables are read and written only from the audio thread. */\n    ma_uint16 cachedFrameCountOut;\n    ma_uint16 cachedFrameCountIn;\n    ma_uint16 consumedFrameCountIn;\n\n    /* These variables are read and written between different threads. */\n    MA_ATOMIC(4, ma_node_state) state;      /* When set to stopped, nothing will be read, regardless of the times in stateTimes. */\n    MA_ATOMIC(8, ma_uint64) stateTimes[2];  /* Indexed by ma_node_state. Specifies the time based on the global clock that a node should be considered to be in the relevant state. */\n    MA_ATOMIC(8, ma_uint64) localTime;      /* The node's local clock. This is just a running sum of the number of output frames that have been processed. Can be modified by any thread with `ma_node_set_time()`. */\n    ma_uin"
        },
        {
          "name": "research",
          "type": "tree",
          "content": null
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}